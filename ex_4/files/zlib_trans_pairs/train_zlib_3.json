[
    {
        "translation": {
            "en": "Dâ€™Arcy, Aoife, 1978- author.",
            "zh": "D'Arcyï¼ŒAoifeï¼Œ1978-ä½œè€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "median, 54, 69, 550, 745, 746, 749, 755",
            "zh": "ä¸­ä½æ•°ï¼Œ 54ï¼Œ 69ï¼Œ 550ï¼Œ 745ï¼Œ 746ï¼Œ 749ï¼Œ 755"
        }
    },
    {
        "translation": {
            "en": "However, as the Î´s vanish, the learning signal attenuates, and this can slow down the rate at which the early layers of the network learn.",
            "zh": "ç„¶è€Œï¼Œéšç€Î´sçš„æ¶ˆå¤±ï¼Œå­¦ä¹ ä¿¡å·ä¼šè¡°å‡ï¼Œè¿™å¯èƒ½ä¼šå‡æ…¢ç½‘ç»œæ—©æœŸå±‚çš„å­¦ä¹ é€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, it has not been possible for the SDSS to develop a solution to automatically categorize galaxies into the different morphological groupsâ€”for example, spiral galaxies or elliptical galaxies.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼ŒSDSSä¸å¯èƒ½å¼€å‘å‡ºä¸€ç§è§£å†³æ–¹æ¡ˆæ¥è‡ªåŠ¨å°†æ˜Ÿç³»åˆ†ç±»ä¸ºä¸åŒçš„å½¢æ€ç»„ï¼Œä¾‹å¦‚èºæ—‹æ˜Ÿç³»æˆ–æ¤­åœ†æ˜Ÿç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The Î¸ represents the inner angle between the vector emanating from the origin to instance d1 and the vector emanating from the origin to instance d2; and (b) shows d1 and d2 normalized to the unit circle.",
            "zh": "ï¼ˆaï¼‰ Î¸è¡¨ç¤ºä»åŸç‚¹åˆ°å®ä¾‹d1çš„å‘é‡ä¸ä»åŸç‚¹åˆ°å®ä¾‹d2çš„å‘é‡ä¹‹é—´çš„å†…è§’;ï¼ˆbï¼‰ æ˜¾ç¤ºå½’ä¸€åŒ–ä¸ºå•ä½åœ†çš„ d1 å’Œ d2ã€‚"
        }
    },
    {
        "translation": {
            "en": "which gives an average of 1.931. For ğ’3 the distances are",
            "zh": "å¹³å‡å€¼ä¸º 1.931ã€‚å¯¹äº C3ï¼Œè·ç¦»ä¸º"
        }
    },
    {
        "translation": {
            "en": "The state representation is simple, with each cell that an agent can occupy in the grid world defining a state.",
            "zh": "çŠ¶æ€è¡¨ç¤ºå¾ˆç®€å•ï¼Œä»£ç†åœ¨ç½‘æ ¼ä¸–ç•Œä¸­å¯ä»¥å æ®çš„æ¯ä¸ªå•å…ƒæ ¼éƒ½å®šä¹‰äº†ä¸€ä¸ªçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, which impurity measure should be used, Gini or entropy? The best advice that we can give is that it is good practice in building decision tree models to try out different impurity metrics and compare the results to see which suits a dataset best.",
            "zh": "é‚£ä¹ˆï¼Œåº”è¯¥ä½¿ç”¨å“ªç§æ‚è´¨åº¦é‡ï¼ŒåŸºå°¼ç³»æ•°è¿˜æ˜¯ç†µå‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥ç»™å‡ºçš„æœ€ä½³å»ºè®®æ˜¯ï¼Œåœ¨æ„å»ºå†³ç­–æ ‘æ¨¡å‹æ—¶ï¼Œå°è¯•ä¸åŒçš„æ‚è´¨æŒ‡æ ‡å¹¶æ¯”è¾ƒç»“æœä»¥æŸ¥çœ‹æœ€é€‚åˆæ•°æ®é›†æ˜¯ä¸€ç§å¾ˆå¥½çš„åšæ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.22â€…â€…â€…(a) A plot of the bike rental dataset from Table 4.15[166]. (b)â€“(e) Visualizations of the prediction models trained in the early iterations of the gradient boosting process. (f) The final ensemble model trained after 20 iterations of gradient boosting.",
            "zh": "4.22 ï¼ˆaï¼‰ è¡¨4.15[166]ä¸­çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†å›¾ã€‚ï¼ˆbï¼‰â€“ï¼ˆeï¼‰ åœ¨æ¢¯åº¦æå‡è¿‡ç¨‹çš„æ—©æœŸè¿­ä»£ä¸­è®­ç»ƒçš„é¢„æµ‹æ¨¡å‹çš„å¯è§†åŒ–ã€‚ï¼ˆfï¼‰ ç»è¿‡ 20 æ¬¡æ¢¯åº¦æå‡è¿­ä»£åè®­ç»ƒçš„æœ€ç»ˆé›†æˆæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first thing that should always be done is a careful examination of a set of summary statistics describing the members of each cluster.",
            "zh": "é¦–å…ˆè¦åšçš„æ˜¯ä»”ç»†æ£€æŸ¥ä¸€ç»„æè¿°æ¯ä¸ªé›†ç¾¤æˆå‘˜çš„æ±‡æ€»ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.7986",
            "zh": "-0.7986"
        }
    },
    {
        "translation": {
            "en": "11.4â€…â€…â€…Extensions and Variations",
            "zh": "11.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "0.31",
            "zh": "0.31"
        }
    },
    {
        "translation": {
            "en": "Figure 8.42",
            "zh": "å›¾ 8.42"
        }
    },
    {
        "translation": {
            "en": "standard scores, 87, 717",
            "zh": "æ ‡å‡†åˆ†æ•°ï¼Œ87,717"
        }
    },
    {
        "translation": {
            "en": "The number of instances in the smallest group is the under-sampling target size.",
            "zh": "æœ€å°ç»„ä¸­çš„å®ä¾‹æ•°æ˜¯æ¬ é‡‡æ ·ç›®æ ‡å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the overall network output of 1.7 has no particular meaning.",
            "zh": "å› æ­¤ï¼Œ1.7 çš„æ•´ä½“ç½‘ç»œè¾“å‡ºæ²¡æœ‰ç‰¹åˆ«çš„æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapman, Pete, Julian Clinton, Randy Kerber, Thomas Khabaza, Thomas Reinartz, Colin Shearer, and Rudiger Wirth. 2000. CRISP-DM 1.0 Step-by-step data mining guide, Technical report, CRISP-DM consortium.",
            "zh": "æŸ¥æ™®æ›¼ã€çš®ç‰¹ã€æœ±åˆ©å®‰Â·å…‹æ—é¡¿ã€å…°è¿ªÂ·ç§‘è´å°”ã€æ‰˜é©¬æ–¯Â·å“ˆå·´æ‰ã€æ‰˜é©¬æ–¯Â·è±çº³èŒ¨ã€ç§‘æ—Â·å¸Œå‹’å’Œå•è¿ªæ ¼Â·æ²ƒæ–¯ã€‚2000. CRISP-DM 1.0 åˆ†æ­¥æ•°æ®æŒ–æ˜æŒ‡å—ï¼ŒæŠ€æœ¯æŠ¥å‘Šï¼ŒCRISP-DM è”ç›Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "5. See Goodfellow et al. (2016, p. 195) for relevant references.",
            "zh": "5. å‚è§ Goodfellow et al. ï¼ˆ2016ï¼Œ p. 195ï¼‰ çš„ç›¸å…³å‚è€ƒèµ„æ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two types of inductive bias that a machine learning algorithm can use, a restriction bias and a preference bias.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•å¯ä»¥ä½¿ç”¨ä¸¤ç§ç±»å‹çš„å½’çº³åå·®ï¼Œå³é™åˆ¶åå·®å’Œåå¥½åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "From Table 8.5[428], for Neuron 8, âˆ‚a/âˆ‚z = 0.2492.",
            "zh": "ä»è¡¨8.5[428]ä¸­ï¼Œå¯¹äºç¥ç»å…ƒ8ï¼Œâˆ‚a/âˆ‚z = 0.2492ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The image below shows an ROC curve for each model. Each curve has a point missing.",
            "zh": "ï¼ˆaï¼‰ ä¸‹å›¾æ˜¾ç¤ºäº†æ¯ä¸ªæ¨¡å‹çš„ ROC æ›²çº¿ã€‚æ¯æ¡æ›²çº¿éƒ½ç¼ºå°‘ä¸€ä¸ªç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are well-known, reasonably effective approaches to clustering.",
            "zh": "è¿™äº›æ˜¯ä¼—æ‰€å‘¨çŸ¥çš„ã€ç›¸å½“æœ‰æ•ˆçš„èšç±»æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "From a computational point of view it makes no difference, as long as consistency is maintained in notation and computation.",
            "zh": "ä»è®¡ç®—çš„è§’åº¦æ¥çœ‹ï¼Œåªè¦åœ¨ç¬¦å·å’Œè®¡ç®—ä¸­ä¿æŒä¸€è‡´æ€§ï¼Œå°±æ²¡æœ‰åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is what we try to achieve in reinforcement learning.",
            "zh": "è¿™å°±æ˜¯æˆ‘ä»¬åœ¨å¼ºåŒ–å­¦ä¹ ä¸­è¯•å›¾å®ç°çš„ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "greedy action selection policy, 641, 656, 680",
            "zh": "è´ªå©ªè¡ŒåŠ¨é€‰æ‹©ç­–ç•¥ï¼Œ641ã€656ã€680"
        }
    },
    {
        "translation": {
            "en": "From a programming perspective, we would recommend Charniak (2019) as an introduction to programming deep learning models using TensorFlow, and Trask (2019) provides a great introduction to implementing neural networks using Numpy.",
            "zh": "ä»ç¼–ç¨‹çš„è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬æ¨è Charniak ï¼ˆ2019ï¼‰ ä½œä¸ºä½¿ç”¨ TensorFlow ç¼–ç¨‹æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä»‹ç»ï¼Œè€Œ Trask ï¼ˆ2019ï¼‰ åˆ™æä¾›äº†ä½¿ç”¨ Nupy å®ç°ç¥ç»ç½‘ç»œçš„ç²¾å½©ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "mixing time, 300",
            "zh": "æ··åˆæ—¶é—´ï¼Œ300"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows the possible transitions between states in TwentyTwos based on these actions.",
            "zh": "å›¾11.3[648]æ˜¾ç¤ºäº†åŸºäºè¿™äº›åŠ¨ä½œçš„TwentyTwosä¸­çŠ¶æ€ä¹‹é—´çš„å¯èƒ½è½¬æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.9â€…â€…â€…The confusion matrix for the logistic regression model that distinguished between only the spiral galaxy types (classification accuracy: 68.225%, average class accuracy: 56.621%).",
            "zh": "13.9 ä»…åŒºåˆ†èºæ—‹æ˜Ÿç³»ç±»å‹çš„é€»è¾‘å›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š68.225%ï¼Œå¹³å‡åˆ†ç±»å‡†ç¡®ç‡ï¼š56.621%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the weighted sum for this neuron for the input vector",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—è¾“å…¥å‘é‡çš„è¯¥ç¥ç»å…ƒçš„åŠ æƒå’Œ"
        }
    },
    {
        "translation": {
            "en": "(b) A range normalization that generates data in the range (âˆ’1,1)",
            "zh": "ï¼ˆbï¼‰ èŒƒå›´å½’ä¸€åŒ–ï¼Œç”ŸæˆèŒƒå›´ ï¼ˆâˆ’1,1ï¼‰ ä¸­çš„æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19",
            "zh": "å›¾ 7.19"
        }
    },
    {
        "translation": {
            "en": "levels, 34",
            "zh": "çº§åˆ«ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "8.13â€…â€…â€…The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places, and with the (binned) target feature represented using one-hot encoding.",
            "zh": "8.13 è”åˆå¾ªç¯ç”µå‚ç¯å¢ƒå› ç´ å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„èŒƒå›´å½’ä¸€åŒ–å°æ—¶æ ·æœ¬ï¼Œå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼Œå¹¶ç”¨å•çƒ­ç¼–ç è¡¨ç¤ºï¼ˆåˆ†æ¡£ï¼‰ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "FPR, 548",
            "zh": "FPRï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "RNN, 499",
            "zh": "RNNï¼Œ499"
        }
    },
    {
        "translation": {
            "en": "Figure 10.2",
            "zh": "å›¾ 10.2"
        }
    },
    {
        "translation": {
            "en": "A prediction model is going to be built for in-line quality assurance in a factory that manufactures electronic components for the automotive industry.",
            "zh": "å°†å»ºç«‹ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œç”¨äºä¸ºæ±½è½¦è¡Œä¸šåˆ¶é€ ç”µå­å…ƒä»¶çš„å·¥å‚æä¾›åœ¨çº¿è´¨é‡ä¿è¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "cubic function, 766",
            "zh": "ä¸‰æ¬¡å‡½æ•°ï¼Œ766"
        }
    },
    {
        "translation": {
            "en": "A neuron functions as an all-or-none switch: if the electrical stimuli gathered by its dendrites are strong enough, the neuron transmits an electrical pulse, known as an action potential, along its axon; otherwise it has no output.",
            "zh": "ç¥ç»å…ƒèµ·ç€å…¨æœ‰æˆ–å…¨æ— å¼€å…³çš„ä½œç”¨ï¼šå¦‚æœæ ‘çªèšé›†çš„ç”µåˆºæ¿€è¶³å¤Ÿå¼ºï¼Œç¥ç»å…ƒå°±ä¼šæ²¿ç€å…¶è½´çªä¼ è¾“ç”µè„‰å†²ï¼Œç§°ä¸ºåŠ¨ä½œç”µä½;å¦åˆ™å®ƒæ²¡æœ‰è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm described here does not have an explicit aggregation step, as do the bagging and boosting algorithms described previously (in which individual model predictions were combined through averaging or voting).",
            "zh": "è¿™é‡Œæè¿°çš„æ¢¯åº¦æå‡ç®—æ³•æ²¡æœ‰æ˜ç¡®çš„èšåˆæ­¥éª¤ï¼Œå°±åƒå‰é¢æè¿°çš„è£…è¢‹å’Œæå‡ç®—æ³•ä¸€æ ·ï¼ˆå…¶ä¸­é€šè¿‡å¹³å‡æˆ–æŠ•ç¥¨ç»„åˆå•ä¸ªæ¨¡å‹é¢„æµ‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "aggregate features, 35",
            "zh": "èšåˆç‰¹å¾ï¼Œ35"
        }
    },
    {
        "translation": {
            "en": "Missing values can also arise for legitimate reasons, however.",
            "zh": "ä½†æ˜¯ï¼Œç”±äºæ­£å½“åŸå› ï¼Œä¹Ÿå¯èƒ½å‡ºç°ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, when a neuron uses the logistic function as an activation function, then these two models are identical.",
            "zh": "äº‹å®ä¸Šï¼Œå½“ç¥ç»å…ƒä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°æ—¶ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can now calculate the probability for CPI = high as",
            "zh": "æˆ‘ä»¬ç°åœ¨å¯ä»¥è®¡ç®— CPI = é«˜çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "The characteristic appearance of the decision boundaries is related to the representations used within the models and the inductive biases that the algorithms used to build them encode.",
            "zh": "å†³ç­–è¾¹ç•Œçš„ç‰¹å¾å¤–è§‚ä¸æ¨¡å‹ä¸­ä½¿ç”¨çš„è¡¨ç¤ºä»¥åŠç”¨äºæ„å»ºæ¨¡å‹çš„ç®—æ³•ç¼–ç çš„å½’çº³åå·®æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The null hypothesis that we adopt for this test is that the feature does not have a significant impact on the model.",
            "zh": "æˆ‘ä»¬åœ¨æ­¤æ£€éªŒä¸­é‡‡ç”¨çš„åŸå‡è®¾æ˜¯è¯¥ç‰¹å¾å¯¹æ¨¡å‹æ²¡æœ‰æ˜¾è‘—å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Î±0 is an initial learning rate (this is typically quite large, e.g., 1.0), c is a constant that controls how quickly the learning rate decays (the value of this parameter depends on how quickly the algorithm converges, but it is often set to quite a large value, e.g., 100), and Ï„ is the current iteration of the gradient descent algorithm.",
            "zh": "å…¶ä¸­ Î±0 æ˜¯åˆå§‹å­¦ä¹ ç‡ï¼ˆé€šå¸¸ç›¸å½“å¤§ï¼Œä¾‹å¦‚ 1.0ï¼‰ï¼Œc æ˜¯æ§åˆ¶å­¦ä¹ ç‡è¡°å‡é€Ÿåº¦çš„å¸¸æ•°ï¼ˆæ­¤å‚æ•°çš„å€¼å–å†³äºç®—æ³•æ”¶æ•›çš„é€Ÿåº¦ï¼Œä½†å®ƒé€šå¸¸è®¾ç½®ä¸ºç›¸å½“å¤§çš„å€¼ï¼Œä¾‹å¦‚ 100ï¼‰ï¼ŒÏ„ æ˜¯æ¢¯åº¦ä¸‹é™ç®—æ³•çš„å½“å‰è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "People grow older, inflation drives up salaries, the content of the spam emails changes, and the way people use technologies changes.",
            "zh": "äººä»¬å˜è€ï¼Œé€šè´§è†¨èƒ€æ¨é«˜äº†å·¥èµ„ï¼Œåƒåœ¾é‚®ä»¶çš„å†…å®¹å‘ç”Ÿäº†å˜åŒ–ï¼Œäººä»¬ä½¿ç”¨æŠ€æœ¯çš„æ–¹å¼ä¹Ÿå‘ç”Ÿäº†å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "When experience replay is used, each time an agent uses an action-value network QW to select and take an action, at, in a state, st, earning a reward, rt, and moving the agent to a new state, st+1, an instance of the form s = st, a = at, r = rt, sâ€² = st+1 is added to a replay memory, .",
            "zh": "ä½¿ç”¨ä½“éªŒå›æ”¾æ—¶ï¼Œæ¯æ¬¡æ™ºèƒ½ä½“ä½¿ç”¨åŠ¨ä½œå€¼ç½‘ç»œ QW é€‰æ‹©å¹¶æ‰§è¡Œæ“ä½œæ—¶ï¼Œåœ¨çŠ¶æ€ stï¼Œè·å¾—å¥–åŠ±ï¼Œrtï¼Œå¹¶å°†æ™ºèƒ½ä½“ç§»åŠ¨åˆ°æ–°çŠ¶æ€ st+1ï¼Œs = stï¼Œ a = atï¼Œ r = rtï¼Œ sâ€² = st+1 å½¢å¼çš„å®ä¾‹è¢«æ·»åŠ åˆ°å›æ”¾å†…å­˜ä¸­ï¼Œ ."
        }
    },
    {
        "translation": {
            "en": "If we donâ€™t know whether the patient has meningitis, then knowing that the patient has a headache may increase the probability we assign to the patient of suffering from a fever.",
            "zh": "å¦‚æœæˆ‘ä»¬ä¸çŸ¥é“æ‚£è€…æ˜¯å¦æ‚£æœ‰è„‘è†œç‚ï¼Œé‚£ä¹ˆçŸ¥é“æ‚£è€…å¤´ç—›å¯èƒ½ä¼šå¢åŠ æˆ‘ä»¬åˆ†é…ç»™æ‚£è€…å‘çƒ§çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The underlying distribution of churners and non-churners within the larger AT customer base, however, is much different.",
            "zh": "ç„¶è€Œï¼Œåœ¨æ›´å¤§çš„ATå®¢æˆ·ç¾¤ä¸­ï¼Œæµå¤±è€…å’Œéæµå¤±è€…çš„åŸºæœ¬åˆ†å¸ƒå´å¤§ä¸ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) The employee ID numbers of the academic staff at a university.",
            "zh": "ï¼ˆdï¼‰ å¤§å­¦å­¦æœ¯äººå‘˜çš„é›‡å‘˜èº«ä»½è¯å·ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the assumption of conditional independence extends the coverage of a naive Bayes model and allows it to generalize beyond the contents of the training data, naive Bayes models still do not have complete coverage of the set of all possible queries.",
            "zh": "å°½ç®¡æ¡ä»¶ç‹¬ç«‹æ€§çš„å‡è®¾æ‰©å±•äº†æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„è¦†ç›–èŒƒå›´ï¼Œå¹¶å…è®¸å®ƒæ³›åŒ–åˆ°è®­ç»ƒæ•°æ®çš„å†…å®¹ä¹‹å¤–ï¼Œä½†æœ´ç´ è´å¶æ–¯æ¨¡å‹ä»ç„¶æ²¡æœ‰å®Œå…¨è¦†ç›–æ‰€æœ‰å¯èƒ½çš„æŸ¥è¯¢é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this if we compare the Euclidean and Manhattan distances between instances d12 and d5 with the Euclidean and Manhattan distances between instances d12 and d17 (SPEED = 5.25, AGILITY = 9.50). Figure 5.2(b)[186] plots the Manhattan and Euclidean distances between these pairs of instances.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†å®ä¾‹ d12 å’Œ d5 ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—å’Œæ›¼å“ˆé¡¿è·ç¦»ä¸å®ä¾‹ d12 å’Œ d17 ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—å’Œæ›¼å“ˆé¡¿è·ç¦»è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸€ç‚¹ï¼ˆSPEED = 5.25ï¼Œæ•æ· = 9.50ï¼‰ã€‚å›¾5.2ï¼ˆbï¼‰[186]ç»˜åˆ¶äº†è¿™ä¸¤å¯¹å®ä¾‹ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦»å’Œæ¬§å‡ é‡Œå¾—è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.00153726",
            "zh": "0.00153726"
        }
    },
    {
        "translation": {
            "en": "Precision and recall can be collapsed to a single performance measure known as the F1 measure,6 which offers a useful alternative to the simpler misclassification rate. The F1 measure is the harmonic mean of precision and recall and is defined as",
            "zh": "ç²¾ç¡®åº¦å’Œå¬å›ç‡å¯ä»¥æŠ˜å ä¸ºç§°ä¸º F1 åº¦é‡çš„å•ä¸ªæ€§èƒ½åº¦é‡ï¼Œ6 å®ƒä¸ºæ›´ç®€å•çš„é”™è¯¯åˆ†ç±»ç‡æä¾›äº†æœ‰ç”¨çš„æ›¿ä»£æ–¹æ¡ˆã€‚F1 åº¦é‡æ˜¯ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„è°æ³¢å¹³å‡å€¼ï¼Œå®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Given this context, the processing of the forget gate would be as follows (note that in this calculation hxt is augmented with a bias input 1):",
            "zh": "åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ï¼Œé—å¿˜é—¨çš„å¤„ç†å¦‚ä¸‹ï¼ˆè¯·æ³¨æ„ï¼Œåœ¨æ­¤è®¡ç®—ä¸­ï¼Œhxt ç”¨åç½®è¾“å…¥ 1 è¿›è¡Œå¢å¼ºï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "In the complementary scenario, the model makes an incorrect prediction and the maximum probability in is assigned to the incorrect category.",
            "zh": "åœ¨äº’è¡¥æ–¹æ¡ˆä¸­ï¼Œæ¨¡å‹åšå‡ºé”™è¯¯çš„é¢„æµ‹ï¼Œå¹¶å°†æœ€å¤§æ¦‚ç‡åˆ†é…ç»™ä¸æ­£ç¡®çš„ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.18â€…â€…â€…A set of scatter plots illustrating the curse of dimensionality.",
            "zh": "5.18 ä¸€ç»„æ•£ç‚¹å›¾ï¼Œè¯´æ˜ç»´åº¦çš„è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The player asking the questions wins by guessing who is on the card within a small number of questions and loses otherwise.",
            "zh": "æå‡ºé—®é¢˜çš„ç©å®¶é€šè¿‡åœ¨å°‘æ•°é—®é¢˜ä¸­çŒœæµ‹è°åœ¨å¡ç‰‡ä¸Šè€Œè·èƒœï¼Œå¦åˆ™å°±è¾“äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The derivative of a function can be understood as the slope of the graph of the function at each point on the graph.",
            "zh": "å‡½æ•°çš„å¯¼æ•°å¯ä»¥ç†è§£ä¸ºå‡½æ•°å›¾åœ¨å›¾ä¸Šæ¯ä¸ªç‚¹çš„æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "eligibility traces, 655",
            "zh": "èµ„æ ¼è·Ÿè¸ªï¼Œ655"
        }
    },
    {
        "translation": {
            "en": "As a result, irrespective of the width of the input x, the activation vectors for these layers will be the same size as the cell state c, and so the dimensions of the vectors in the elementwise operations that update the cell state will match.",
            "zh": "å› æ­¤ï¼Œæ— è®ºè¾“å…¥ x çš„å®½åº¦å¦‚ä½•ï¼Œè¿™äº›å±‚çš„æ¿€æ´»å‘é‡éƒ½å°†ä¸å•å…ƒçŠ¶æ€ c çš„å¤§å°ç›¸åŒï¼Œå› æ­¤æ›´æ–°å•å…ƒæ ¼çŠ¶æ€çš„å…ƒç´ æ“ä½œä¸­çš„å‘é‡ç»´åº¦å°†åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.10[271] shows the definition of some of the standard probability distributionsâ€”the normal, exponential, and mixture of Gaussians distributionsâ€”that are commonly used in probabilistic prediction models, and Figure 6.3[270] illustrates the shapes of the density curves of these distributions.",
            "zh": "è¡¨6.10[271]æ˜¾ç¤ºäº†æ¦‚ç‡é¢„æµ‹æ¨¡å‹ä¸­å¸¸ç”¨çš„ä¸€äº›æ ‡å‡†æ¦‚ç‡åˆ†å¸ƒï¼ˆæ­£æ€åˆ†å¸ƒã€æŒ‡æ•°åˆ†å¸ƒå’Œæ··åˆåˆ†å¸ƒï¼‰çš„å®šä¹‰ï¼Œå›¾6.3[270]è¯´æ˜äº†è¿™äº›åˆ†å¸ƒçš„å¯†åº¦æ›²çº¿çš„å½¢çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, if Neurons 6 and 7 are dead, then no error gradients will be backpropagated past this layer of neurons and the network is essentially reduced to a perceptron network composed of just Neuron 8, as none of the other neurons will have their input weights updated during training.",
            "zh": "åŒæ ·ï¼Œå¦‚æœç¥ç»å…ƒ 6 å’Œ 7 æ˜¯æ­»çš„ï¼Œé‚£ä¹ˆæ²¡æœ‰è¯¯å·®æ¢¯åº¦ä¼šåå‘ä¼ æ’­è¶…è¿‡è¿™ä¸€å±‚ç¥ç»å…ƒï¼Œå¹¶ä¸”ç½‘ç»œåŸºæœ¬ä¸Šè¢«ç®€åŒ–ä¸ºä»…ç”±ç¥ç»å…ƒ 8 ç»„æˆçš„æ„ŸçŸ¥å™¨ç½‘ç»œï¼Œå› ä¸ºå…¶ä»–ç¥ç»å…ƒéƒ½ä¸ä¼šåœ¨è®­ç»ƒæœŸé—´æ›´æ–°å…¶è¾“å…¥æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.7458",
            "zh": "0.7458"
        }
    },
    {
        "translation": {
            "en": "The basis of this theory was that complex behavior emerges from the interactions between massive numbers of highly interconnected neurons rather than from complex processing within neurons.",
            "zh": "è¯¥ç†è®ºçš„åŸºç¡€æ˜¯ï¼Œå¤æ‚è¡Œä¸ºæ¥è‡ªå¤§é‡é«˜åº¦äº’è¿çš„ç¥ç»å…ƒä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œè€Œä¸æ˜¯ç¥ç»å…ƒå†…éƒ¨çš„å¤æ‚å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A better choice, and our recommended default, is random sampling, which randomly selects a proportion of s% of the instances from a large dataset to create a smaller set. Random sampling is a good choice in most cases, as the random nature of the selection of instances should avoid introducing bias.",
            "zh": "æ›´å¥½çš„é€‰æ‹©ï¼ˆä¹Ÿæ˜¯æˆ‘ä»¬æ¨èçš„é»˜è®¤å€¼ï¼‰æ˜¯éšæœºæŠ½æ ·ï¼Œå®ƒä»å¤§å‹æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€å®šæ¯”ä¾‹çš„ s% å®ä¾‹ä»¥åˆ›å»ºè¾ƒå°çš„é›†åˆã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒéšæœºæŠ½æ ·æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼Œå› ä¸ºé€‰æ‹©å®ä¾‹çš„éšæœºæ€§åº”é¿å…å¼•å…¥åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.8",
            "zh": "å›¾ 11.8"
        }
    },
    {
        "translation": {
            "en": "clustering evaluation internal criterion, 608",
            "zh": "èšç±»è¯„ä¼°å†…éƒ¨å‡†åˆ™ï¼Œ608"
        }
    },
    {
        "translation": {
            "en": "ME2E2ERR_U/G/R/I/Z",
            "zh": "ME2E2ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Description",
            "zh": "æè¿°"
        }
    },
    {
        "translation": {
            "en": "However, naively initializing weights can result in unstable behavior within the dynamics of a network during training, resulting in saturated activation functions (as a consequence of z values becoming too large or small) or unstable error gradients.",
            "zh": "ç„¶è€Œï¼Œå¹¼ç¨šåœ°åˆå§‹åŒ–æƒé‡å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒæœŸé—´ç½‘ç»œåŠ¨æ€ä¸­çš„è¡Œä¸ºä¸ç¨³å®šï¼Œä»è€Œå¯¼è‡´æ¿€æ´»å‡½æ•°é¥±å’Œï¼ˆç”±äº z å€¼å˜å¾—è¿‡å¤§æˆ–è¿‡å°ï¼‰æˆ–ä¸ç¨³å®šçš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "These values immediately suggest that the model is better at predicting the ham level (TNR) than it is at predicting the spam level (TPR).",
            "zh": "è¿™äº›å€¼ç«‹å³è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹ç«è…¿æ°´å¹³ ï¼ˆTNRï¼‰ æ–¹é¢æ¯”åœ¨é¢„æµ‹åƒåœ¾é‚®ä»¶æ°´å¹³ ï¼ˆTPRï¼‰ æ–¹é¢æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if these backpropagated Î´s came from hidden neurons, then they were also calculated as a product of the weighted sum of the Î´s backpropagated to those hidden neurons and the âˆ‚ak/âˆ‚zk term for those neurons.",
            "zh": "ç„¶è€Œï¼Œå¦‚æœè¿™äº›åå‘ä¼ æ’­çš„Î´æ¥è‡ªéšè—çš„ç¥ç»å…ƒï¼Œé‚£ä¹ˆå®ƒä»¬ä¹Ÿè¢«è®¡ç®—ä¸ºåå‘ä¼ æ’­åˆ°è¿™äº›éšè—ç¥ç»å…ƒçš„Î´sçš„åŠ æƒå’Œè¿™äº›ç¥ç»å…ƒçš„âˆ‚ak/âˆ‚zké¡¹çš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "36. Loss functions are discussed in much more detail in Chapters 7[311] and 8[381]. We can view the gradient boosting process as equivalent to the gradient descent process described in those chapters.",
            "zh": "36. æŸå¤±å‡½æ•°åœ¨ç¬¬7ç« [311]å’Œç¬¬8ç« [381]ä¸­æœ‰æ›´è¯¦ç»†çš„è®¨è®ºã€‚æˆ‘ä»¬å¯ä»¥å°†æ¢¯åº¦æå‡è¿‡ç¨‹è§†ä¸ºç­‰åŒäºè¿™äº›ç« èŠ‚ä¸­æè¿°çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.4571",
            "zh": "0.4571"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5[273] illustrates how outliers affect normal and student-t distributions.",
            "zh": "å›¾ 6.5[273] è¯´æ˜äº†å¼‚å¸¸å€¼å¦‚ä½•å½±å“æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ t åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "0.0694",
            "zh": "0.0694"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, a probability distribution for three binary features A, B, and C. The probability for a joint event in this domain P(A,B,C) can be decomposed using the chain rule in the following way:",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸‰ä¸ªäºŒå…ƒç‰¹å¾ Aã€B å’Œ C çš„æ¦‚ç‡åˆ†å¸ƒã€‚å¯ä»¥ä½¿ç”¨é“¾å¼æ³•åˆ™æŒ‰ä»¥ä¸‹æ–¹å¼åˆ†è§£æ­¤åŸŸä¸­è”åˆäº‹ä»¶çš„æ¦‚ç‡ Pï¼ˆAï¼ŒBï¼ŒCï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "This model gave the best prediction accuracy and offered the potential for very fast classification times, which was attractive for integration into the SDSS pipeline.",
            "zh": "è¯¥æ¨¡å‹æä¾›äº†æœ€ä½³çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œå¹¶æä¾›äº†éå¸¸å¿«çš„åˆ†ç±»æ—¶é—´çš„æ½œåŠ›ï¼Œè¿™å¯¹äºé›†æˆåˆ° SDSS ç®¡é“ä¸­å¾ˆæœ‰å¸å¼•åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.29",
            "zh": "å›¾ 8.29"
        }
    },
    {
        "translation": {
            "en": "If this test succeeds, the algorithm descends to a leaf node of this subtree, using the same process it used to find the original leaf node (Line 9).",
            "zh": "å¦‚æœæ­¤æµ‹è¯•æˆåŠŸï¼Œåˆ™ç®—æ³•å°†ä¸‹é™åˆ°æ­¤å­æ ‘çš„å¶èŠ‚ç‚¹ï¼Œä½¿ç”¨ä¸æŸ¥æ‰¾åŸå§‹å¶èŠ‚ç‚¹ç›¸åŒçš„è¿‡ç¨‹ï¼ˆç¬¬ 9 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equal-width binning is simple and intuitive, and can work well in practice.",
            "zh": "ç­‰å®½åˆ†ç®±ç®€å•ç›´è§‚ï¼Œåœ¨å®è·µä¸­å¯ä»¥å¾ˆå¥½åœ°å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Ester, Martin, Hans-Peter Kriegel, JÃ¶rg Sander, and Xiaowei Xu. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proceedings of the second international conference on knowledge discovery and data mining KDD, Vol. 96, 226â€“231.",
            "zh": "Esterã€Martinã€Hans-Peter Kriegelã€JÃ¶rg Sander å’Œ Xiaowei Xuã€‚1996. ä¸€ç§åŸºäºå¯†åº¦çš„ç®—æ³•ï¼Œç”¨äºå‘ç°å…·æœ‰å™ªå£°çš„å¤§å‹ç©ºé—´æ•°æ®åº“ä¸­çš„èšç±»ã€‚åœ¨ç¬¬äºŒå±ŠçŸ¥è¯†å‘ç°å’Œæ•°æ®æŒ–æ˜å›½é™…ä¼šè®®è®ºæ–‡é›† KDD ä¸­ï¼Œç¬¬ 96 å·ï¼Œç¬¬ 226-231 é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "23. The inverse of the identity matrix ğ•€ is ğ•€. Therefore, if there is no covariance between the features, both the covariance and the inverse covariance matrix will be equal to ğ•€.",
            "zh": "23. å•ä½çŸ©é˜µ I çš„å€’æ•°æ˜¯ Iã€‚å› æ­¤ï¼Œå¦‚æœç‰¹å¾ä¹‹é—´æ²¡æœ‰åæ–¹å·®ï¼Œåˆ™åæ–¹å·®å’Œé€†åæ–¹å·®çŸ©é˜µéƒ½å°†ç­‰äº Iã€‚"
        }
    },
    {
        "translation": {
            "en": "The Gini index is 0 when all the instances in the dataset have the same target level, and it is when there are k possible target levels with equal likelihood.",
            "zh": "å½“æ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹éƒ½å…·æœ‰ç›¸åŒçš„ç›®æ ‡æ°´å¹³æ—¶ï¼ŒåŸºå°¼æŒ‡æ•°ä¸º 0ï¼Œå¹¶ä¸”å½“æœ‰ k ä¸ªå¯èƒ½çš„ç›®æ ‡æ°´å¹³å…·æœ‰ç›¸ç­‰çš„å¯èƒ½æ€§æ—¶ï¼ŒåŸºå°¼æŒ‡æ•°ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "A large change in the root mean squared error value would flag that the model had gone stale.",
            "zh": "å‡æ–¹æ ¹è¯¯å·®å€¼çš„è¾ƒå¤§å˜åŒ–å°†è¡¨æ˜æ¨¡å‹å·²è¿‡æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each element in a matrix is identified by two indices, the row index and then the column index. For example,",
            "zh": "çŸ©é˜µä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½ç”±ä¸¤ä¸ªç´¢å¼•æ ‡è¯†ï¼Œå³è¡Œç´¢å¼•å’Œåˆ—ç´¢å¼•ã€‚ä¾‹å¦‚"
        }
    },
    {
        "translation": {
            "en": "The dealer encourages you to play again, but you know that youâ€™ve got to know when to walk away, so you head off with an extra dollar in your pocket.",
            "zh": "åº„å®¶é¼“åŠ±ä½ å†ç©ä¸€æ¬¡ï¼Œä½†ä½ çŸ¥é“ä½ å¿…é¡»çŸ¥é“ä»€ä¹ˆæ—¶å€™è¯¥èµ°å¼€ï¼Œæ‰€ä»¥ä½ å£è¢‹é‡Œå¤šäº†ä¸€å—é’±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(d)[151] depicts one of the problems that can arise when a variance measure is used to split a continuous target feature.",
            "zh": "å›¾ 4.15ï¼ˆdï¼‰[151] æè¿°äº†ä½¿ç”¨æ–¹å·®åº¦é‡åˆ†å‰²è¿ç»­ç›®æ ‡ç‰¹å¾æ—¶å¯èƒ½å‡ºç°çš„é—®é¢˜ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(c)[151] shows that the instances have been gathered into two groups that have a relatively low variance compared with the single group in Figure 4.15(b)[151].",
            "zh": "å›¾4.15ï¼ˆcï¼‰[151]æ˜¾ç¤ºï¼Œä¸å›¾4.15ï¼ˆbï¼‰[151]ä¸­çš„å•ç»„ç›¸æ¯”ï¼Œè¿™äº›å®ä¾‹è¢«æ”¶é›†åˆ°ä¸¤ç»„ï¼Œæ–¹å·®ç›¸å¯¹è¾ƒä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, matrix multiplication is associative (i.e., X(YZ) is equal to (XY)Z); this means that we can rewrite Equation (8.9)[395]",
            "zh": "ç„¶è€Œï¼ŒçŸ©é˜µä¹˜æ³•æ˜¯å…³è”çš„ï¼ˆå³ Xï¼ˆYZï¼‰ ç­‰äº ï¼ˆXYï¼‰Zï¼‰;è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é‡å†™æ–¹ç¨‹ï¼ˆ8.9ï¼‰[395]"
        }
    },
    {
        "translation": {
            "en": "0.45",
            "zh": "0.45"
        }
    },
    {
        "translation": {
            "en": "As the name suggests, the mixture of Gaussians distribution is the distribution that results when a number of normal (or Gaussian) distributions are merged.",
            "zh": "é¡¾åæ€ä¹‰ï¼Œé«˜æ–¯åˆ†å¸ƒçš„æ··åˆæ˜¯åˆå¹¶å¤šä¸ªæ­£æ€ï¼ˆæˆ–é«˜æ–¯ï¼‰åˆ†å¸ƒæ—¶äº§ç”Ÿçš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "8.15â€…â€…â€…An illustration of the forward propagation of d2 through the network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "8.15 d2 é€šè¿‡ç½‘ç»œå‘å‰ä¼ æ’­çš„å›¾ç¤ºï¼Œæ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ï¼Œä»¥åŠç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒæ€»å’Œ z å’Œæ¿€æ´»å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "No Free Lunch Theorem, 13, 736",
            "zh": "æ²¡æœ‰å…è´¹çš„åˆé¤å®šç†ï¼Œ13,736"
        }
    },
    {
        "translation": {
            "en": "A family of error-based machine learning algorithms takes the same approach. A parameterized prediction model is initialized with a set of random parameters, and an error function is used to judge how well this initial model performs when making predictions for instances in a training dataset. Based on the value of the error function, the parameters are iteratively adjusted to create a more and more accurate model.",
            "zh": "ä¸€ç³»åˆ—åŸºäºé”™è¯¯çš„æœºå™¨å­¦ä¹ ç®—æ³•é‡‡ç”¨ç›¸åŒçš„æ–¹æ³•ã€‚å‚æ•°åŒ–é¢„æµ‹æ¨¡å‹ä½¿ç”¨ä¸€ç»„éšæœºå‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œè¯¯å·®å‡½æ•°ç”¨äºåˆ¤æ–­è¯¥åˆå§‹æ¨¡å‹åœ¨å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹è¿›è¡Œé¢„æµ‹æ—¶çš„è¡¨ç°ã€‚æ ¹æ®è¯¯å·®å‡½æ•°çš„å€¼ï¼Œå¯¹å‚æ•°è¿›è¡Œè¿­ä»£è°ƒæ•´ï¼Œä»¥åˆ›å»ºè¶Šæ¥è¶Šå‡†ç¡®çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean, on the other hand, emphasizes the importance of smaller values and so can give a slightly more realistic measure of how well a model is performing.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œè°æ³¢å‡å€¼å¼ºè°ƒè¾ƒå°å€¼çš„é‡è¦æ€§ï¼Œå› æ­¤å¯ä»¥æ›´çœŸå®åœ°è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "One way we can reduce the impact of this is that for each categorical feature we transform, we can reduce the number of newly added features by one by assuming that a zero in all the new features implies that the original feature had the final level.",
            "zh": "æˆ‘ä»¬å¯ä»¥å‡å°‘è¿™ç§å½±å“çš„ä¸€ç§æ–¹æ³•æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬è½¬æ¢çš„æ¯ä¸ªåˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ–°æ·»åŠ çš„ç‰¹å¾æ•°é‡å‡å°‘ 1ï¼Œæ–¹æ³•æ˜¯å‡è®¾æ‰€æœ‰æ–°ç‰¹å¾ä¸­çš„é›¶æ„å‘³ç€åŸå§‹ç‰¹å¾å…·æœ‰æœ€ç»ˆçº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two ways that an episode can end: an agent can either land successfully or crash.",
            "zh": "å‰§é›†æœ‰ä¸¤ç§ç»“æŸæ–¹å¼ï¼šç‰¹å·¥å¯ä»¥æˆåŠŸç€é™†æˆ–å æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This will make the model appear much more accurate than it will actually be when deployed.",
            "zh": "è¿™å°†ä½¿æ¨¡å‹çœ‹èµ·æ¥æ¯”éƒ¨ç½²æ—¶å®é™…å‡†ç¡®å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Hunter, Elizabeth, Brian Mac Namee, and John Kelleher. 2018. An open-data-driven agent-based model to simulate infectious disease outbreaks. PloS One 13 (12): 0208775.",
            "zh": "äº¨ç‰¹ã€ä¼Šä¸½èç™½ã€å¸ƒè±æ©Â·éº¦å…‹Â·çº³æ¢…å’Œçº¦ç¿°Â·å‡¯è±èµ«ã€‚2018. åŸºäºå¼€æ”¾æ•°æ®é©±åŠ¨çš„åŸºäºæ™ºèƒ½ä½“çš„æ¨¡å‹ï¼Œç”¨äºæ¨¡æ‹Ÿä¼ æŸ“ç—…æš´å‘.å…¬å…±ç§‘å­¦å›¾ä¹¦é¦†ä¸€å·13ï¼ˆ12ï¼‰ï¼š0208775ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, if we apply Equation (7.23)[339] to the instance RPM = 650 and VIBRATION = 240, which is below the decision boundary in Figure 7.10(b)[340], we get",
            "zh": "ç›¸åï¼Œå¦‚æœæˆ‘ä»¬å°†æ–¹ç¨‹ï¼ˆ7.23ï¼‰[339]åº”ç”¨äºRPM = 650å’ŒVIBRATION = 240ï¼ˆä½äºå›¾7.10ï¼ˆbï¼‰[340]ä¸­çš„å†³ç­–è¾¹ç•Œï¼‰çš„å®ä¾‹ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "To choose which action to take in a given state the agent uses a policy.",
            "zh": "è‹¥è¦é€‰æ‹©åœ¨ç»™å®šçŠ¶æ€ä¸‹è¦æ‰§è¡Œçš„æ“ä½œï¼Œä»£ç†ä½¿ç”¨ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wished to evaluate the performance of a prediction model built to estimate the daily energy demand in a residential building based on features describing the family that lives in the house, the weather on a given day, and the time of the year.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬å¸Œæœ›è¯„ä¼°ä¸€ä¸ªé¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨æ ¹æ®æè¿°å±…ä½åœ¨æˆ¿å±‹ä¸­çš„å®¶åº­ã€ç»™å®šæ—¥æœŸçš„å¤©æ°”å’Œä¸€å¹´ä¸­çš„æ—¶é—´çš„ç‰¹å¾æ¥ä¼°è®¡ä½å®…æ¥¼çš„æ¯æ—¥èƒ½æºéœ€æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is not feasible for an analytics practitioner to learn everything about the businesses with which they work as they will probably move quickly between different areas of an organization, or even different industries.",
            "zh": "å¯¹äºåˆ†æä»ä¸šè€…æ¥è¯´ï¼Œäº†è§£ä»–ä»¬æ‰€ä»äº‹çš„ä¼ä¸šçš„æ‰€æœ‰ä¿¡æ¯æ˜¯ä¸å¯è¡Œçš„ï¼Œå› ä¸ºä»–ä»¬å¯èƒ½ä¼šåœ¨ç»„ç»‡çš„ä¸åŒé¢†åŸŸç”šè‡³ä¸åŒçš„è¡Œä¸šä¹‹é—´å¿«é€Ÿç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "ongoing model validation, 579, 702",
            "zh": "æ­£åœ¨è¿›è¡Œçš„æ¨¡å‹éªŒè¯ï¼Œ579,702"
        }
    },
    {
        "translation": {
            "en": "For categorical features we are interested primarily in frequency counts and proportions.",
            "zh": "å¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬ä¸»è¦å¯¹é¢‘ç‡è®¡æ•°å’Œæ¯”ä¾‹æ„Ÿå…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the ID3 algorithm we created a leaf node when there were no instances left in the partition being processed (Line 1), when there were no features left on which to split the data (Line 1), or when we had created a pure partition of the dataset with respect to the target feature levels (Line 1).",
            "zh": "åœ¨ ID3 ç®—æ³•ä¸­ï¼Œå½“æ­£åœ¨å¤„ç†çš„åˆ†åŒºä¸­æ²¡æœ‰å‰©ä½™å®ä¾‹æ—¶ï¼ˆç¬¬ 1 è¡Œï¼‰ï¼Œå½“æ²¡æœ‰å‰©ä½™çš„ç‰¹å¾å¯ä»¥æ‹†åˆ†æ•°æ®æ—¶ï¼ˆç¬¬ 1 è¡Œï¼‰ï¼Œæˆ–è€…å½“æˆ‘ä»¬åˆ›å»ºäº†ç›¸å¯¹äºç›®æ ‡ç‰¹å¾çº§åˆ«çš„æ•°æ®é›†çš„çº¯åˆ†åŒºæ—¶ï¼ˆç¬¬ 1 è¡Œï¼‰ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "event, 246, 757, 758, 758",
            "zh": "äº‹ä»¶ï¼Œ 246ï¼Œ 757ï¼Œ 758ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "The number of instances placed in each bin is simply the total number of instances divided by the number of bins, b.",
            "zh": "æ”¾ç½®åœ¨æ¯ä¸ª bin ä¸­çš„å®ä¾‹æ•°åªæ˜¯å®ä¾‹æ€»æ•°é™¤ä»¥ bã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.90)[486] and Equation (8.91)[486] illustrate how the feature map generated by the neurons in Figure 8.33[484] changes if the filter used by the neurons to process the example input is changed.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.90ï¼‰[486]å’Œæ–¹ç¨‹ï¼ˆ8.91ï¼‰[486]è¯´æ˜äº†å¦‚æœç¥ç»å…ƒç”¨äºå¤„ç†ç¤ºä¾‹è¾“å…¥çš„è¿‡æ»¤å™¨å‘ç”Ÿå˜åŒ–ï¼Œå›¾8.33[484]ä¸­çš„ç¥ç»å…ƒç”Ÿæˆçš„ç‰¹å¾å›¾å°†å¦‚ä½•å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note, however, that in the section on Handling Categorical Target features, we switch to the term logit to refer to the output of the weight sum in a neuron and update the notation to reflect this switch; see the previous notation section on Categorical Targets for more details.",
            "zh": "ä½†æ˜¯è¯·æ³¨æ„ï¼Œåœ¨å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ‡æ¢åˆ°æœ¯è¯­ logit æ¥æŒ‡ä»£ç¥ç»å…ƒä¸­æƒé‡æ€»å’Œçš„è¾“å‡ºï¼Œå¹¶æ›´æ–°ç¬¦å·ä»¥åæ˜ æ­¤åˆ‡æ¢;æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…å‰é¢å…³äºåˆ†ç±»ç›®æ ‡çš„è¡¨ç¤ºæ³•éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Appendix B[757] provides a comprehensive introduction to these aspects of probability theory, so we recommend that readers unfamiliar with them review this appendix before continuing with this chapter.",
            "zh": "é™„å½•B[757]å…¨é¢ä»‹ç»äº†æ¦‚ç‡è®ºçš„è¿™äº›æ–¹é¢ï¼Œå› æ­¤æˆ‘ä»¬å»ºè®®ä¸ç†Ÿæ‚‰å®ƒä»¬çš„è¯»è€…åœ¨ç»§ç»­æœ¬ç« ä¹‹å‰å…ˆæŸ¥çœ‹æœ¬é™„å½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "MDP, 645",
            "zh": "MDPï¼Œ645"
        }
    },
    {
        "translation": {
            "en": "To calculate the distance between the query instance and the hyperplane defined by the node indexing d15 (the boundaryDist function on Line 8), we use only the AGILITY feature, as it is the splitting feature at this node.",
            "zh": "ä¸ºäº†è®¡ç®—æŸ¥è¯¢å®ä¾‹ä¸èŠ‚ç‚¹ç´¢å¼• d15ï¼ˆç¬¬ 8 è¡Œçš„ boundaryDist å‡½æ•°ï¼‰å®šä¹‰çš„è¶…å¹³é¢ä¹‹é—´çš„è·ç¦»ï¼Œæˆ‘ä»¬åªä½¿ç”¨ AGILITY ç‰¹å¾ï¼Œå› ä¸ºå®ƒæ˜¯è¯¥èŠ‚ç‚¹çš„æ‹†åˆ†ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Chapter 2[23] we described the process of moving from a business problem to an analytics solution and, from there, to the design and construction of an analytics base table (ABT).",
            "zh": "åœ¨ç¬¬ 2 ç« [23]ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†ä»ä¸šåŠ¡é—®é¢˜è½¬å‘åˆ†æè§£å†³æ–¹æ¡ˆçš„è¿‡ç¨‹ï¼Œä»¥åŠä»é‚£é‡Œåˆ°åˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ çš„è®¾è®¡å’Œæ„å»ºçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this approach, an instance is chosen randomly (following a uniform distribution) from the dataset as the first centroid.",
            "zh": "åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œä»æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå®ä¾‹ï¼ˆéµå¾ªå‡åŒ€åˆ†å¸ƒï¼‰ä½œä¸ºç¬¬ä¸€ä¸ªè´¨å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Every instance in this ABT should have that value, and this feature was removed from the ABT.",
            "zh": "æ­¤ ABT ä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½åº”å…·æœ‰è¯¥å€¼ï¼Œå¹¶ä¸”æ­¤åŠŸèƒ½å·²ä» ABT ä¸­åˆ é™¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even with this cautious strategy, in an evaluation in which an agent plays a bout of 1,000 hands of TwentyTwos 100,000 times, this player will on average earn a profit of $198 Â± 24 in 1,000 hands.",
            "zh": "å³ä½¿é‡‡ç”¨è¿™ç§è°¨æ…çš„ç­–ç•¥ï¼Œåœ¨ç»çºªäººç© 1,000 æ‰‹ 100,000 æ¬¡ TwentyTwos çš„è¯„ä¼°ä¸­ï¼Œè¯¥ç©å®¶åœ¨ 1,000 æ‰‹ç‰Œä¸­å¹³å‡èµšå– 198 ç¾å…ƒÂ± 24 ç¾å…ƒçš„åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "loss, 168, 625",
            "zh": "æŸå¤±ï¼Œ 168ï¼Œ 625"
        }
    },
    {
        "translation": {
            "en": "This means that the Euclidean difference is more influenced by a single large difference in one feature rather than a lot of small differences across a set of features, whereas the opposite is true of Manhattan distance.",
            "zh": "è¿™æ„å‘³ç€æ¬§å‡ é‡Œå¾—å·®åˆ†æ›´å¤šåœ°å—ä¸€ä¸ªç‰¹å¾çš„å•ä¸ªå¤§å·®å¼‚çš„å½±å“ï¼Œè€Œä¸æ˜¯ä¸€ç»„ç‰¹å¾ä¹‹é—´çš„è®¸å¤šå°å·®å¼‚ï¼Œè€Œæ›¼å“ˆé¡¿è·ç¦»åˆ™ç›¸åã€‚"
        }
    },
    {
        "translation": {
            "en": "Gradient boosting then iteratively adds new models to the ensemble.",
            "zh": "ç„¶åï¼Œæ¢¯åº¦æå‡ä¼šè¿­ä»£åœ°å°†æ–°æ¨¡å‹æ·»åŠ åˆ°æ•´ä½“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see the reason for this in Table 6.3[264], where there are still some probabilities equal to zero, for example, P(CH = none | Â¬fr).",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨è¡¨ 6.3[264] ä¸­çœ‹åˆ°å…¶åŸå› ï¼Œå…¶ä¸­ä»ç„¶æœ‰ä¸€äº›æ¦‚ç‡ç­‰äºé›¶ï¼Œä¾‹å¦‚ï¼ŒPï¼ˆCH = none | Â¬frï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.13",
            "zh": "è¡¨ 9.13"
        }
    },
    {
        "translation": {
            "en": "Similarly, the correlation matrix is just a normalized version of the covariance matrix and shows the correlation between each pair of features:",
            "zh": "ç±»ä¼¼åœ°ï¼Œç›¸å…³çŸ©é˜µåªæ˜¯åæ–¹å·®çŸ©é˜µçš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå¹¶æ˜¾ç¤ºæ¯å¯¹ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 11.9",
            "zh": "å›¾ 11.9"
        }
    },
    {
        "translation": {
            "en": "extract-transform-load, 42, 702",
            "zh": "æå–-è½¬æ¢-åŠ è½½ï¼Œ 42ï¼Œ 702"
        }
    },
    {
        "translation": {
            "en": "Figure 4.8",
            "zh": "å›¾ 4.8"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18(a)[226] plots a one-dimensional dataset consisting of 29 instances spread evenly between 0.0 and 3.0.",
            "zh": "å›¾ 5.18ï¼ˆaï¼‰[226] ç»˜åˆ¶äº†ä¸€ä¸ªç”± 29 ä¸ªå®ä¾‹ç»„æˆçš„ä¸€ç»´æ•°æ®é›†ï¼Œè¿™äº›å®ä¾‹å‡åŒ€åˆ†å¸ƒåœ¨ 0.0 å’Œ 3.0 ä¹‹é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the instances in Table 6.15[283] are ordered in ascending order based on the magnitude of their original LOAN AMOUNT value.",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨ 6.15[283] ä¸­çš„å®ä¾‹æ ¹æ®å…¶åŸå§‹ LOAN AMOUNT å€¼çš„å¤§å°æŒ‰å‡åºæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "Strang, Gilbert. 2016. Introduction to linear algebra, 5th ed. Wellesley-Cambridge Press.",
            "zh": "æ–¯ç‰¹æœ—ï¼Œå‰å°”ä¼¯ç‰¹ã€‚2016. çº¿æ€§ä»£æ•°å¯¼è®ºï¼Œç¬¬ 5 ç‰ˆï¼ŒéŸ¦å°”æ–¯åˆ©-å‰‘æ¡¥å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.1â€…â€…â€…A game of find the lady: (a) the cards used; (b) the cards dealt facedown on a table; (c) the initial likelihoods of the queen ending up in each position; and (d) a revised set of likelihoods for the position of the queen based on evidence collected.",
            "zh": "6.1 å¯»æ‰¾å¥³å£«çš„æ¸¸æˆï¼šï¼ˆaï¼‰ä½¿ç”¨çš„ç‰Œ;ï¼ˆbï¼‰ åœ¨æ¡Œå­ä¸Šå‘ç‰Œé¢æœä¸‹;ï¼ˆcï¼‰ å¥³ç‹æœ€ç»ˆæ‹…ä»»æ¯ä¸ªèŒä½çš„æœ€åˆå¯èƒ½æ€§;ï¼ˆdï¼‰æ ¹æ®æ”¶é›†åˆ°çš„è¯æ®ï¼Œå¯¹å¥³ç‹èŒä½çš„ä¸€ç³»åˆ—å¯èƒ½æ€§è¿›è¡Œäº†ä¿®è®¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the heights of the players in the extended basketball team in Figure A.2[746], the mode is 140, as it is the only value that appears twice.",
            "zh": "å¯¹äºå›¾ A.2[746] ä¸­æ‰©å±•ç¯®çƒé˜Ÿä¸­çƒå‘˜çš„èº«é«˜ï¼Œè¯¥æ¨¡å¼ä¸º 140ï¼Œå› ä¸ºå®ƒæ˜¯å”¯ä¸€å‡ºç°ä¸¤æ¬¡çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Weights and standard errors for each feature in the office rentals model.",
            "zh": "åŠå…¬å®¤ç§Ÿèµæ¨¡å‹ä¸­æ¯ä¸ªè¦ç´ çš„æƒé‡å’Œæ ‡å‡†è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we present describe how different data types can be handled, how overfitting can be avoided using decision tree pruning, and how multiple prediction models can be combined in ensembles to improve prediction accuracy.",
            "zh": "æˆ‘ä»¬ä»‹ç»çš„è¿™ç§æ ‡å‡†æ–¹æ³•çš„æ‰©å±•å’Œå˜ä½“æè¿°äº†å¦‚ä½•å¤„ç†ä¸åŒçš„æ•°æ®ç±»å‹ï¼Œå¦‚ä½•ä½¿ç”¨å†³ç­–æ ‘ä¿®å‰ªæ¥é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œä»¥åŠå¦‚ä½•å°†å¤šä¸ªé¢„æµ‹æ¨¡å‹ç»„åˆæˆé›†æˆä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if you were to randomly select a card from the set shown in Figure 4.5(a)[124], you would have zero uncertainty, as you would know for sure that you would select an ace of spades.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä½ ä»å›¾4.5ï¼ˆaï¼‰[124]æ‰€ç¤ºçš„ç‰Œé›†ä¸­éšæœºé€‰æ‹©ä¸€å¼ ç‰Œï¼Œä½ çš„ä¸ç¡®å®šæ€§ä¸ºé›¶ï¼Œå› ä¸ºä½ è‚¯å®šçŸ¥é“ä½ ä¼šé€‰æ‹©é»‘æ¡ƒAã€‚"
        }
    },
    {
        "translation": {
            "en": "The population mean of a feature is usually denoted by Î¼, and in general, given a sufficiently large sample, we use the sample mean Ä as a point estimate of Î¼.",
            "zh": "ç‰¹å¾çš„æ€»ä½“å‡å€¼é€šå¸¸ç”¨ Î¼ è¡¨ç¤ºï¼Œé€šå¸¸ï¼Œç»™å®šè¶³å¤Ÿå¤§çš„æ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ·æœ¬å‡å€¼ Ä ä½œä¸º Î¼ çš„ç‚¹ä¼°è®¡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "To create a sample that is larger than the size of the group that we are sampling from, we use random sampling with replacement.",
            "zh": "ä¸ºäº†åˆ›å»ºä¸€ä¸ªå¤§äºæˆ‘ä»¬æŠ½æ ·çš„ç»„å¤§å°çš„æ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºæŠ½æ ·å’Œæ›¿æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on this comparison, a performance measure can be used to capture, numerically, how well the predictions made by the model match those that were expected.",
            "zh": "åŸºäºè¿™ç§æ¯”è¾ƒï¼Œå¯ä»¥ä½¿ç”¨æ€§èƒ½åº¦é‡å€¼ä»æ•°å€¼ä¸Šæ•è·æ¨¡å‹æ‰€åšçš„é¢„æµ‹ä¸é¢„æœŸé¢„æµ‹çš„åŒ¹é…ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4â€ƒExtensions and Variations",
            "zh": "9.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "sample covariance, 81",
            "zh": "æ ·æœ¬åæ–¹å·®ï¼Œ81"
        }
    },
    {
        "translation": {
            "en": "42. Technically, what a convolution network is actually calculating should be called a cross-correlation (Charniak, 2019, p. 52), but we ignore this technicality for the purposes of this discussion.",
            "zh": "42. ä»æŠ€æœ¯ä¸Šè®²ï¼Œå·ç§¯ç½‘ç»œå®é™…è®¡ç®—çš„å†…å®¹åº”è¯¥ç§°ä¸ºäº’ç›¸å…³ï¼ˆCharniakï¼Œ2019 å¹´ï¼Œç¬¬ 52 é¡µï¼‰ï¼Œä½†å‡ºäºæœ¬è®¨è®ºçš„ç›®çš„ï¼Œæˆ‘ä»¬å¿½ç•¥äº†è¿™ç§æŠ€æœ¯æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The values in Table 9.8[554] are based on these figures.",
            "zh": "è¡¨9.8[554]ä¸­çš„å€¼åŸºäºè¿™äº›æ•°å­—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was referred to as the under-sampled training set.",
            "zh": "è¿™è¢«ç§°ä¸ºæ¬ æ ·æœ¬è®­ç»ƒé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5",
            "zh": "å›¾ 2.5"
        }
    },
    {
        "translation": {
            "en": "Using the equivalence defined in Equation (8.14)[408], this product of three terms can be simplified",
            "zh": "ä½¿ç”¨ç­‰å¼ï¼ˆ8.14ï¼‰[408]ä¸­å®šä¹‰çš„ç­‰ä»·æ€§ï¼Œå¯ä»¥ç®€åŒ–ä¸‰ä¸ªé¡¹çš„ä¹˜ç§¯"
        }
    },
    {
        "translation": {
            "en": "knowledge elicitation, 31",
            "zh": "çŸ¥è¯†è·å–ï¼Œ 31"
        }
    },
    {
        "translation": {
            "en": "Figure 12.2",
            "zh": "å›¾ 12.2"
        }
    },
    {
        "translation": {
            "en": "Figure 8.22[450] illustrates this new network architecture.",
            "zh": "å›¾ 8.22[450] è¯´æ˜äº†è¿™ç§æ–°çš„ç½‘ç»œæ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(a)[620] shows these distances and is referred to as a distance matrix.9 The pair of instances in the dataset that are closest together are then selected and combined into a cluster.",
            "zh": "è¡¨ 10.5ï¼ˆaï¼‰[620] æ˜¾ç¤ºäº†è¿™äº›è·ç¦»ï¼Œç§°ä¸ºè·ç¦»çŸ©é˜µ.9 ç„¶åé€‰æ‹©æ•°æ®é›†ä¸­æœ€æ¥è¿‘çš„ä¸€å¯¹å®ä¾‹å¹¶å°†å…¶ç»„åˆæˆä¸€ä¸ªé›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next section provides a case study of the process for converting a business problem into a set of candidate analytics solutions.",
            "zh": "ä¸‹ä¸€èŠ‚å°†æä¾›å°†ä¸šåŠ¡é—®é¢˜è½¬æ¢ä¸ºä¸€ç»„å€™é€‰åˆ†æè§£å†³æ–¹æ¡ˆçš„è¿‡ç¨‹çš„æ¡ˆä¾‹ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The state of the decision tree after the ğ’Ÿ8 partition has been split using SLOPE.",
            "zh": "ä½¿ç”¨ SLOPE æ‹†åˆ† D8 åˆ†åŒºåçš„å†³ç­–æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "SKYIVAR_U/G/R/I/Z",
            "zh": "SKYIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "We present an approach in which we first develop a set of domain concepts that describe the prediction subject, and then expand these into concrete descriptive features.",
            "zh": "æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œå…¶ä¸­æˆ‘ä»¬é¦–å…ˆå¼€å‘ä¸€ç»„æè¿°é¢„æµ‹ä¸»é¢˜çš„é¢†åŸŸæ¦‚å¿µï¼Œç„¶åå°†è¿™äº›æ¦‚å¿µæ‰©å±•ä¸ºå…·ä½“çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the first query instance, q1, the output of the support vector machine model is:",
            "zh": "å¯¹äºç¬¬ä¸€ä¸ªæŸ¥è¯¢å®ä¾‹ q1ï¼Œæ”¯æŒå‘é‡æœºæ¨¡å‹çš„è¾“å‡ºä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "The main difference between the McCulloch and Pitts model and modern artificial neurons is that the thresholding function is replaced by other functions.",
            "zh": "McCulloch å’Œ Pitts æ¨¡å‹ä¸ç°ä»£äººå·¥ç¥ç»å…ƒä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºé˜ˆå€¼å‡½æ•°è¢«å…¶ä»–å‡½æ•°å–ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this unit each of these weight matrices has dimensions 2 Ã— 4.",
            "zh": "åœ¨è¿™ä¸ªå•ä½ä¸­ï¼Œæ¯ä¸ªæƒé‡çŸ©é˜µçš„ç»´åº¦ä¸º 2 Ã— 4ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that pruning typically affects the lower parts of the decision tree, where noisy training data is most likely to cause overfitting.",
            "zh": "åŸå› æ˜¯ä¿®å‰ªé€šå¸¸ä¼šå½±å“å†³ç­–æ ‘çš„ä¸‹éƒ¨ï¼Œå…¶ä¸­å˜ˆæ‚çš„è®­ç»ƒæ•°æ®æœ€æœ‰å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.1",
            "zh": "å›¾ 10.1"
        }
    },
    {
        "translation": {
            "en": "Throughout the early stages of the project, Ross had been consciously working on developing his situational fluency.",
            "zh": "åœ¨é¡¹ç›®çš„æ—©æœŸé˜¶æ®µï¼Œç½—æ–¯ä¸€ç›´åœ¨æœ‰æ„è¯†åœ°åŠªåŠ›æé«˜ä»–çš„æƒ…å¢ƒæµç•…æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in the drug dosage prediction problem, we cannot say by how many milligrams we expect the model to be incorrect based on the mean squared error values.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨è¯ç‰©å‰‚é‡é¢„æµ‹é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬ä¸èƒ½æ ¹æ®å‡æ–¹è¯¯å·®å€¼æ¥åˆ¤æ–­æˆ‘ä»¬æœŸæœ›æ¨¡å‹ä¸æ­£ç¡®çš„æ¯«å…‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather, the algorithm finds a hierarchical agglomeration (or grouping) of the instances in a dataset that can then be used to cluster the instances into any number of groups.",
            "zh": "ç›¸åï¼Œè¯¥ç®—æ³•åœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾å®ä¾‹çš„åˆ†å±‚èšé›†ï¼ˆæˆ–åˆ†ç»„ï¼‰ï¼Œç„¶åå¯ç”¨äºå°†å®ä¾‹èšç±»ä¸ºä»»æ„æ•°é‡çš„ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6.2â€ƒMonitoring model output distribution changesâ€ƒAn alternative to using changing model performance is to use changes in the distribution of model outputs as a signal for concept drift.",
            "zh": "9.4.6.2 ç›‘æµ‹æ¨¡å‹è¾“å‡ºåˆ†å¸ƒå˜åŒ– ä½¿ç”¨æ¨¡å‹æ€§èƒ½å˜åŒ–çš„å¦ä¸€ç§æ–¹æ³•æ˜¯å°†æ¨¡å‹è¾“å‡ºåˆ†å¸ƒçš„å˜åŒ–ç”¨ä½œæ¦‚å¿µæ¼‚ç§»çš„ä¿¡å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the filter dimensions, finding the appropriate stride for a given dataset involves trial-and-error experimentation.",
            "zh": "ä¸ç­›é€‰å™¨ç»´åº¦ç±»ä¼¼ï¼Œä¸ºç»™å®šæ•°æ®é›†æ‰¾åˆ°é€‚å½“çš„æ­¥å¹…æ¶‰åŠè¯•é”™è¯•éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Bar plot of the continuous TRAINING EXPENSES feature from Table A.1[750].",
            "zh": "è¡¨A.1[750]ä¸­è¿ç»­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This distance is 2.75, which is greater than best-distance (we can see this in Figure 5.10(b)[201], as the hyperplane defined at the node indexing d15 does not intersect with the target hypersphere).",
            "zh": "è¯¥è·ç¦»ä¸º 2.75ï¼Œå¤§äºæœ€ä½³è·ç¦»ï¼ˆæˆ‘ä»¬å¯ä»¥åœ¨å›¾ 5.10ï¼ˆbï¼‰[201] ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸ºåœ¨èŠ‚ç‚¹ç´¢å¼• d15 å¤„å®šä¹‰çš„è¶…å¹³é¢ä¸ä¸ç›®æ ‡è¶…çƒç›¸äº¤ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although there are four sets of connections in this network (input to hidden, hidden to output, hidden to buffer, and buffer to hidden), there are only three weight matrices in the network.",
            "zh": "å°½ç®¡è¯¥ç½‘ç»œä¸­æœ‰å››ç»„è¿æ¥ï¼ˆè¾“å…¥åˆ°éšè—ã€éšè—åˆ°è¾“å‡ºã€éšè—åˆ°ç¼“å†²åŒºå’Œç¼“å†²åŒºåˆ°éšè—ï¼‰ï¼Œä½†ç½‘ç»œä¸­åªæœ‰ä¸‰ä¸ªæƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "8.20â€…â€…â€…A plot showing how the sum of squared errors of the ReLU network changed during training when Î± = 0.2.",
            "zh": "8.20 å½“ Î± = 0.2 æ—¶ï¼ŒReLU ç½‘ç»œçš„å¹³æ–¹è¯¯å·®å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–çš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The boosting algorithm presented here can be easily adapted to work with continuous targets by changing the weight update rules to be based on error rather than misclassification, and in this case the aggregation calculates a weighted mean prediction from the base models in the ensemble.31",
            "zh": "é€šè¿‡å°†æƒé‡æ›´æ–°è§„åˆ™æ›´æ”¹ä¸ºåŸºäºè¯¯å·®è€Œä¸æ˜¯é”™è¯¯åˆ†ç±»ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°è°ƒæ•´æ­¤å¤„ä»‹ç»çš„æå‡ç®—æ³•ä»¥å¤„ç†è¿ç»­ç›®æ ‡ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œèšåˆä»é›†æˆä¸­çš„åŸºæœ¬æ¨¡å‹è®¡ç®—åŠ æƒå¹³å‡é¢„æµ‹31ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ioffe, Sergey, and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the thirty-second international conference on machine learning, 448â€“456. JMLR.",
            "zh": "çº¦è²ã€è°¢å°”ç›–å’Œå…‹é‡Œæ–¯è’‚å®‰Â·å¡æ ¼è¿ªã€‚2015. æ‰¹é‡å½’ä¸€åŒ–ï¼šé€šè¿‡å‡å°‘å†…éƒ¨åå˜é‡åç§»æ¥åŠ é€Ÿæ·±åº¦ç½‘ç»œè®­ç»ƒã€‚åœ¨ç¬¬ä¸‰åäºŒå±Šæœºå™¨å­¦ä¹ å›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œ448-456ã€‚JMLRã€‚"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce the fundamental concepts of probability theory that are used in probability-based machine learning algorithms. Specifically, we present the basics of calculating probabilities based on relative frequencies, calculating conditional probabilities, the probability product rule, the probability chain rule, and the Theorem of Total Probability.",
            "zh": "åœ¨æœ¬é™„å½•ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ä½¿ç”¨çš„æ¦‚ç‡è®ºçš„åŸºæœ¬æ¦‚å¿µã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»‹ç»äº†åŸºäºç›¸å¯¹é¢‘ç‡è®¡ç®—æ¦‚ç‡ã€è®¡ç®—æ¡ä»¶æ¦‚ç‡ã€æ¦‚ç‡ä¹˜ç§¯è§„åˆ™ã€æ¦‚ç‡é“¾è§„åˆ™å’Œæ€»æ¦‚ç‡å®šç†çš„åŸºç¡€çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.3â€ƒDesigning the Analytics Base Table",
            "zh": "2.3 è®¾è®¡åˆ†æåŸºè¡¨"
        }
    },
    {
        "translation": {
            "en": "Also, each arrow is labeled with the weight that the neuron receiving the activation flowing along that connection applies to that activation during the weighted sum calculation.",
            "zh": "æ­¤å¤–ï¼Œæ¯ä¸ªç®­å¤´éƒ½æ ‡æœ‰åœ¨åŠ æƒå’Œè®¡ç®—æœŸé—´æ¥æ”¶æ²¿è¯¥è¿æ¥æµåŠ¨çš„æ¿€æ´»çš„ç¥ç»å…ƒåº”ç”¨äºè¯¥æ¿€æ´»çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comparing these results to the information gain calculated using entropy (see Table 4.4[137]), we can see that although the resulting numbers are different, the relative ranking of the features is the sameâ€”in both cases ELEVATION has the highest information gain.",
            "zh": "å°†è¿™äº›ç»“æœä¸ä½¿ç”¨ç†µè®¡ç®—çš„ä¿¡æ¯å¢ç›Šè¿›è¡Œæ¯”è¾ƒï¼ˆè§è¡¨4.4[137]ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡ç»“æœæ•°å­—ä¸åŒï¼Œä½†ç‰¹å¾çš„ç›¸å¯¹æ’åæ˜¯ç›¸åŒçš„â€”â€”åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼ŒELEVATIONçš„ä¿¡æ¯å¢ç›Šæœ€é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The key component of the gradient descent algorithm presented in this chapter is the use of differentiation to compute the slope of the error surface.",
            "zh": "æœ¬ç« ä»‹ç»çš„æ¢¯åº¦ä¸‹é™ç®—æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†æ˜¯ä½¿ç”¨å¾®åˆ†æ¥è®¡ç®—è¯¯å·®é¢çš„æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "FREQ",
            "zh": "é¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "Glasses",
            "zh": "çœ¼é•œ"
        }
    },
    {
        "translation": {
            "en": "18. This means that the distribution over the target feature will be different between a training set sample and the full population.",
            "zh": "18. è¿™æ„å‘³ç€è®­ç»ƒé›†æ ·æœ¬å’Œæ•´ä¸ªæ€»ä½“ä¹‹é—´ç›®æ ‡ç‰¹å¾çš„åˆ†å¸ƒå°†ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The density of the marked unit hypercube is now (there are only 4 instances inside the hypercube).",
            "zh": "æ ‡è®°å•ä½è¶…ç«‹æ–¹ä½“çš„å¯†åº¦ç°åœ¨ä¸ºï¼ˆè¶…ç«‹æ–¹ä½“å†…åªæœ‰ 4 ä¸ªå®ä¾‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some cases, the size of the interval is defined as part of the problem we are trying to solve, or there may be a natural interval to use because of the domain.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒåŒºé—´çš„å¤§å°è¢«å®šä¹‰ä¸ºæˆ‘ä»¬è¯•å›¾è§£å†³çš„é—®é¢˜çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–è€…ç”±äºåŸŸçš„åŸå› ï¼Œå¯èƒ½æœ‰ä¸€ä¸ªè‡ªç„¶åŒºé—´å¯ä»¥ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.4â€ƒInductive Bias Versus Sample Bias",
            "zh": "1.4 ç”µæ„Ÿåå·®ä¸æ ·æœ¬åå·®"
        }
    },
    {
        "translation": {
            "en": "For example, in Figure 2.4[35] the levels of the CREDIT RATING feature are {aa, a, b, c} and the levels of the GENDER feature are {male, female}.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å›¾2.4[35]ä¸­ï¼Œä¿¡ç”¨è¯„çº§ç‰¹å¾çš„çº§åˆ«ä¸º{aaï¼Œaï¼Œbï¼Œc}ï¼Œæ€§åˆ«ç‰¹å¾çš„çº§åˆ«ä¸º{ç”·æ€§ï¼Œå¥³æ€§}ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some of the topics that, space permitting, we would have included are batch normalization (Ioffe and Szegedy, 2015), which can speed up the training of very deep networks; algorithms that adaptively adjust the learning rate parameter such as Adam (Kingma and Ba, 2014); and more recent neural network architectures such as Generative Adversarial Networks (Goodfellow et al., 2014), and attention-based architectures, such as the Transformer (Vaswani et al., 2017).",
            "zh": "åœ¨ç©ºé—´å…è®¸çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†åŒ…æ‹¬çš„ä¸€äº›ä¸»é¢˜æ˜¯æ‰¹é‡å½’ä¸€åŒ–ï¼ˆIoffe å’Œ Szegedyï¼Œ2015 å¹´ï¼‰ï¼Œå®ƒå¯ä»¥åŠ å¿«éå¸¸æ·±åº¦ç½‘ç»œçš„è®­ç»ƒ;è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç‡å‚æ•°çš„ç®—æ³•ï¼Œå¦‚Adamï¼ˆKingmaå’ŒBaï¼Œ2014ï¼‰;ä»¥åŠæœ€è¿‘çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¦‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGoodfellowç­‰äººï¼Œ2014å¹´ï¼‰ï¼Œä»¥åŠåŸºäºæ³¨æ„åŠ›çš„æ¶æ„ï¼Œå¦‚Transformerï¼ˆVaswaniç­‰äººï¼Œ2017å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Preface to the 1st Edition",
            "zh": "ç¬¬ä¸€ç‰ˆå‰è¨€"
        }
    },
    {
        "translation": {
            "en": "It is clear from the values along the diagonal, the true positives and true negatives, that the model is doing a reasonably good job of making accurate predictions. We can actually calculate the misclassification rate directly from the confusion matrix as follows:",
            "zh": "ä»æ²¿å¯¹è§’çº¿çš„å€¼ã€çœŸæ­£å€¼å’ŒçœŸè´Ÿå€¼ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œè¯¥æ¨¡å‹åœ¨åšå‡ºå‡†ç¡®é¢„æµ‹æ–¹é¢åšå¾—ç›¸å½“å¥½ã€‚æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥ç›´æ¥ä»æ··æ·†çŸ©é˜µä¸­è®¡ç®—é”™è¯¯åˆ†ç±»ç‡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "max, 489",
            "zh": "æœ€å¤§å€¼ï¼Œ489"
        }
    },
    {
        "translation": {
            "en": "We also present two course paths that focus on the context of predictive data analytics.",
            "zh": "æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸¤æ¡è¯¾ç¨‹è·¯å¾„ï¼Œé‡ç‚¹ä»‹ç»é¢„æµ‹æ•°æ®åˆ†æçš„èƒŒæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Policies rely on being able to assess the expected return of taking an action in a particular state, and an action-value function can be used to calculate this.6",
            "zh": "ç­–ç•¥ä¾èµ–äºèƒ½å¤Ÿè¯„ä¼°åœ¨ç‰¹å®šçŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥ï¼Œè€Œè¡ŒåŠ¨ä»·å€¼å‡½æ•°å¯ç”¨äºè®¡ç®—æ­¤å›æŠ¥6ã€‚"
        }
    },
    {
        "translation": {
            "en": "8â€…â€…â€…Deep Learning",
            "zh": "8 æ·±åº¦å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "3. A city tax service has performed a clustering of individual taxpayers using k-means clustering in order to better understand groups that might exist within their taxpayer base. The clustering has divided the taxpayers into three clusters. Four descriptive features have been used to describe each taxpayer:",
            "zh": "3. ä¸€å®¶åŸå¸‚ç¨åŠ¡å±€ä½¿ç”¨ k-means èšç±»å¯¹ä¸ªäººçº³ç¨äººè¿›è¡Œäº†èšç±»ï¼Œä»¥ä¾¿æ›´å¥½åœ°äº†è§£å…¶çº³ç¨äººç¾¤ä½“ä¸­å¯èƒ½å­˜åœ¨çš„ç¾¤ä½“ã€‚è¯¥é›†ç¾¤å°†çº³ç¨äººåˆ†ä¸ºä¸‰ä¸ªé›†ç¾¤ã€‚æˆ‘ä»¬ç”¨å››ä¸ªæè¿°æ€§ç‰¹å¾æ¥æè¿°æ¯ä¸ªçº³ç¨äººï¼š"
        }
    },
    {
        "translation": {
            "en": "where w Â·d is the dot product of the vectors w and d. The dot product of two vectors is the sum of the products of their corresponding elements.",
            "zh": "å…¶ä¸­ w Â·d æ˜¯å‘é‡ w å’Œ d çš„ç‚¹ç§¯ã€‚ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯æ˜¯å®ƒä»¬å¯¹åº”å…ƒç´ çš„ä¹˜ç§¯ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor algorithm delays abstracting from the data until it is asked to make a prediction.",
            "zh": "æœ€è¿‘é‚»ç®—æ³•ä¼šå»¶è¿Ÿä»æ•°æ®ä¸­æŠ½è±¡å‡ºæ¥ï¼Œç›´åˆ°è¢«è¦æ±‚è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gleick, James. 2011. The information: A history, a theory, a flood. HarperCollins UK.",
            "zh": "æ ¼è±å…‹ï¼Œè©¹å§†æ–¯ã€‚2011. ä¿¡æ¯ï¼šå†å²ã€ç†è®ºã€æ´ªæ°´.è‹±å›½å“ˆç€æŸ¯æ—æ–¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantage of this index ordering becomes clear when we describe how matrix multiplications can be used to speed up the training and inference in neural networks (see Section 8.2.3[390]).",
            "zh": "å½“æˆ‘ä»¬æè¿°å¦‚ä½•ä½¿ç”¨çŸ©é˜µä¹˜æ³•æ¥åŠ é€Ÿç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œæ¨ç†æ—¶ï¼Œè¿™ç§ç´¢å¼•æ’åºçš„ä¼˜åŠ¿å°±å˜å¾—å¾ˆæ˜æ˜¾äº†ï¼ˆå‚è§ç¬¬ 8.2.3 èŠ‚[390]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "nodes, 286",
            "zh": "èŠ‚ç‚¹ï¼Œ286"
        }
    },
    {
        "translation": {
            "en": "Figure 3.6",
            "zh": "å›¾ 3.6"
        }
    },
    {
        "translation": {
            "en": "The algorithm was first proposed, however, as an approach to playing video games in which the only inputs were screenshots of the game.",
            "zh": "ç„¶è€Œï¼Œè¯¥ç®—æ³•æœ€åˆæ˜¯ä½œä¸ºä¸€ç§ç©è§†é¢‘æ¸¸æˆçš„æ–¹æ³•æå‡ºçš„ï¼Œå…¶ä¸­å”¯ä¸€çš„è¾“å…¥æ˜¯æ¸¸æˆçš„å±å¹•æˆªå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If for di the average intra-cluster distance, a(i), is much smaller than the average inter-cluster distance to members of the nearest next cluster, b(i), then the silhouette width, s(i), will be close to 1 and we can be confident that di really belongs to the cluster in which it has been placed.",
            "zh": "å¦‚æœå¯¹äº diï¼Œå¹³å‡ç°‡å†…è·ç¦» aï¼ˆiï¼‰ è¿œå°äºåˆ°æœ€è¿‘çš„ä¸‹ä¸€ä¸ªç°‡ bï¼ˆiï¼‰ æˆå‘˜çš„å¹³å‡ç°‡é—´è·ç¦»ï¼Œåˆ™è½®å»“å®½åº¦ sï¼ˆiï¼‰ å°†æ¥è¿‘ 1ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿¡ di ç¡®å®å±äºæ”¾ç½®å®ƒçš„ç°‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sum of a probability distribution must equal 1.0.",
            "zh": "æ¦‚ç‡åˆ†å¸ƒçš„æ€»å’Œå¿…é¡»ç­‰äº 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "It should be no surprise to learn that the derivative of the function with respect to x also gives us the slope of the function at that value of x.",
            "zh": "çŸ¥é“å‡½æ•°ç›¸å¯¹äº x çš„å¯¼æ•°ä¹Ÿä¸ºæˆ‘ä»¬æä¾›äº†å‡½æ•°åœ¨ x å€¼å¤„çš„æ–œç‡ï¼Œè¿™åº”è¯¥ä¸è¶³ä¸ºå¥‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Logistic regression models also produce confidences along with the predictions, which was attractive to Edwin as it meant that he could build tests into the pipeline that would redirect galaxies with low confidence classifications for manual confirmation of the predictions made by the automated system.",
            "zh": "é€»è¾‘å›å½’æ¨¡å‹è¿˜å¯ä»¥åœ¨é¢„æµ‹çš„åŒæ—¶äº§ç”Ÿç½®ä¿¡åº¦ï¼Œè¿™å¯¹ Edwin å¾ˆæœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºè¿™æ„å‘³ç€ä»–å¯ä»¥åœ¨ç®¡é“ä¸­æ„å»ºæµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•å°†é‡å®šå‘å…·æœ‰ä½ç½®ä¿¡åº¦åˆ†ç±»çš„æ˜Ÿç³»ï¼Œä»¥ä¾¿æ‰‹åŠ¨ç¡®è®¤è‡ªåŠ¨åŒ–ç³»ç»Ÿåšå‡ºçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is growing empirical evidence that creating deeper networks improves the generalization ability of models across a number of tasks.5 However, adding depth to a network comes with a cost.",
            "zh": "è¶Šæ¥è¶Šå¤šçš„ç»éªŒè¯æ®è¡¨æ˜ï¼Œåˆ›å»ºæ›´æ·±çš„ç½‘ç»œå¯ä»¥æé«˜æ¨¡å‹åœ¨è®¸å¤šä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›.5 ç„¶è€Œï¼Œå¢åŠ ç½‘ç»œçš„æ·±åº¦æ˜¯æœ‰ä»£ä»·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The normal distribution is a member of this location-scale family, with the mean Î¼ specifying the location, and the standard deviation Ïƒ acting as the scale parameter.",
            "zh": "æ­£æ€åˆ†å¸ƒæ˜¯æ­¤ä½ç½®å°ºåº¦ç³»åˆ—çš„æˆå‘˜ï¼Œå‡å€¼Î¼æŒ‡å®šä½ç½®ï¼Œæ ‡å‡†å·®Ïƒå……å½“å°ºåº¦å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a 1-NN model has the flexibility to model a discontinuous decision surface; however, it runs into time and space complexity issues as the number of instances grows.",
            "zh": "ä¾‹å¦‚ï¼Œ1-NN æ¨¡å‹å¯ä»¥çµæ´»åœ°å¯¹ä¸è¿ç»­çš„å†³ç­–é¢è¿›è¡Œå»ºæ¨¡;ä½†æ˜¯ï¼Œéšç€å®ä¾‹æ•°é‡çš„å¢åŠ ï¼Œå®ƒä¼šé‡åˆ°æ—¶é—´å’Œç©ºé—´å¤æ‚æ€§é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the Î´ values you calculated above, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., âˆ‚â„°/âˆ‚w3,2, âˆ‚â„°/âˆ‚w3,0, âˆ‚â„°/âˆ‚w2,1, âˆ‚â„°/âˆ‚w2,0).",
            "zh": "ä½¿ç”¨ä¸Šé¢è®¡ç®—çš„Î´å€¼ï¼Œè®¡ç®—ç½‘ç»œè¯¯å·®å¯¹ç½‘ç»œæ¯ä¸ªæƒé‡å˜åŒ–çš„æ•æ„Ÿåº¦ï¼ˆå³ âˆ‚E/âˆ‚w3,2ã€âˆ‚E/âˆ‚w3,0ã€âˆ‚E/âˆ‚w2,1ã€âˆ‚E/âˆ‚w2,0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, the total error of the model on the dataset, measured here by the sum of squared errors, has dropped slightly from 0.17921847 to 0.17896823, an error reduction of 0.00025024.",
            "zh": "æ­¤å¤–ï¼Œæ•°æ®é›†ä¸Šæ¨¡å‹çš„æ€»è¯¯å·®ï¼ˆæ­¤å¤„é€šè¿‡å¹³æ–¹è¯¯å·®ä¹‹å’Œæµ‹é‡ï¼‰ä» 0.17921847 ç•¥å¾®ä¸‹é™åˆ° 0.17896823ï¼Œè¯¯å·®å‡å°‘äº† 0.00025024ã€‚"
        }
    },
    {
        "translation": {
            "en": "We saw in Section 9.4.2[547] how the true positive rate (TPR) and true negative rate (TNR) can be calculated from a confusion matrix.",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬ 9.4.2[547] èŠ‚ä¸­çœ‹åˆ°äº†å¦‚ä½•ä»æ··æ·†çŸ©é˜µè®¡ç®—çœŸé˜³æ€§ç‡ ï¼ˆTPRï¼‰ å’ŒçœŸé˜´æ€§ç‡ ï¼ˆTNRï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "one-hot encoding, 463",
            "zh": "å•çƒ­ç¼–ç ï¼Œ463"
        }
    },
    {
        "translation": {
            "en": "GÃ¤denfors, Peter. 2004. Conceptual spaces: The geometry of thought. MIT Press.",
            "zh": "GÃ¤denforsï¼Œå½¼å¾—ã€‚2004. æ¦‚å¿µç©ºé—´ï¼šæ€æƒ³çš„å‡ ä½•å­¦.éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "These calculations make it apparent that even in this small example domain, the calculation of a probability becomes computationally complex very quickly, particularly when we need to sum out one or more features.",
            "zh": "è¿™äº›è®¡ç®—æ¸…æ¥šåœ°è¡¨æ˜ï¼Œå³ä½¿åœ¨è¿™ä¸ªå°ç¤ºä¾‹åŸŸä¸­ï¼Œæ¦‚ç‡çš„è®¡ç®—ä¹Ÿå¾ˆå¿«å˜å¾—éå¸¸å¤æ‚ï¼Œç‰¹åˆ«æ˜¯å½“æˆ‘ä»¬éœ€è¦æ€»ç»“ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Business",
            "zh": "å•†"
        }
    },
    {
        "translation": {
            "en": "Table 13.9",
            "zh": "è¡¨ 13.9"
        }
    },
    {
        "translation": {
            "en": "P_MG",
            "zh": "P_MG"
        }
    },
    {
        "translation": {
            "en": "27. Question 5 in the Exercises section at the end of this chapter explores bagging and random forest ensemble models in more detail, and worked examples are provided in the solution.",
            "zh": "27. æœ¬ç« æœ«å°¾çš„â€œç»ƒä¹ â€éƒ¨åˆ†çš„é—®é¢˜ 5 æ›´è¯¦ç»†åœ°æ¢è®¨äº†è£…è¢‹å’Œéšæœºæ£®æ—é›†æˆæ¨¡å‹ï¼Œå¹¶åœ¨è§£å†³æ–¹æ¡ˆä¸­æä¾›äº†å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Interpretability: In many instances a business will not be happy to simply accept the predictions made by a model and incorporate these into their decision making.",
            "zh": "å¯è§£é‡Šæ€§ï¼šåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œä¼ä¸šä¸ä¼šä¹äºç®€å•åœ°æ¥å—æ¨¡å‹åšå‡ºçš„é¢„æµ‹å¹¶å°†å…¶çº³å…¥å†³ç­–ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this network, for the neurons in the first hidden layer nin(HL1) = 2 and for neurons in all the other hidden layers nin = 100.",
            "zh": "åœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œå¯¹äºç¬¬ä¸€ä¸ªéšè—å±‚ä¸­çš„ç¥ç»å…ƒï¼Œninï¼ˆHL1ï¼‰ = 2ï¼Œå¯¹äºæ‰€æœ‰å…¶ä»–éšè—å±‚ä¸­çš„ç¥ç»å…ƒï¼Œnin = 100ã€‚"
        }
    },
    {
        "translation": {
            "en": "(long)â€ expands on the â€œP.D.A.",
            "zh": "ï¼ˆlongï¼‰â€œæ‰©å±•äº†â€P.D.A."
        }
    },
    {
        "translation": {
            "en": "Recall that is the reward received when state st+1 is reached from state st after taking action at.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œè¿™æ˜¯åœ¨é‡‡å–è¡ŒåŠ¨åä»çŠ¶æ€ st åˆ°è¾¾çŠ¶æ€ st+1 æ—¶æ”¶åˆ°çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.8[79] shows two examples of using stacked bar plots.",
            "zh": "å›¾3.8[79]æ˜¾ç¤ºäº†ä½¿ç”¨å †å æ¡å½¢å›¾çš„ä¸¤ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Equation (4.2)[129] and Equation (4.3)[129], we can now formally define information gain made from splitting the dataset ğ’Ÿ using the feature d",
            "zh": "ä½¿ç”¨æ–¹ç¨‹ï¼ˆ4.2ï¼‰[129]å’Œæ–¹ç¨‹ï¼ˆ4.3ï¼‰[129]ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨ç‰¹å¾dæ­£å¼å®šä¹‰é€šè¿‡æ‹†åˆ†æ•°æ®é›†Dè·å¾—çš„ä¿¡æ¯å¢ç›Š"
        }
    },
    {
        "translation": {
            "en": "Typically, the number of basis functions in Ï• is larger than the number of descriptive features, so the application of the basis functions moves the data into a higher-dimensional space.",
            "zh": "é€šå¸¸ï¼ŒÏ† ä¸­åŸºå‡½æ•°çš„æ•°é‡å¤§äºæè¿°æ€§ç‰¹å¾çš„æ•°é‡ï¼Œå› æ­¤åŸºå‡½æ•°çš„åº”ç”¨ä¼šå°†æ•°æ®ç§»åŠ¨åˆ°æ›´é«˜ç»´çš„ç©ºé—´ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3.1â€…â€…â€…Backpropagation: The General Structure of the Algorithm",
            "zh": "8.3.1 åå‘ä¼ æ’­ï¼šç®—æ³•çš„ä¸€èˆ¬ç»“æ„"
        }
    },
    {
        "translation": {
            "en": "However, all these models learn a boundary.",
            "zh": "ä½†æ˜¯ï¼Œæ‰€æœ‰è¿™äº›æ¨¡å‹éƒ½å­¦ä¹ äº†ä¸€ä¸ªè¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "In TwentyTwos the player has two actions available to them in each non-terminal state: Stick or Twist.",
            "zh": "åœ¨ã€ŠTwentyTwosã€‹ä¸­ï¼Œç©å®¶åœ¨æ¯ä¸ªéç»ˆç«¯çŠ¶æ€ä¸‹æœ‰ä¸¤ä¸ªåŠ¨ä½œå¯ä¾›ä»–ä»¬ä½¿ç”¨ï¼šStickæˆ–Twistã€‚"
        }
    },
    {
        "translation": {
            "en": "The cell provides a path that carries the activations of the network forward through the time-steps as the network processes a sequence.",
            "zh": "è¯¥å•å…ƒæä¾›äº†ä¸€æ¡è·¯å¾„ï¼Œå½“ç½‘ç»œå¤„ç†åºåˆ—æ—¶ï¼Œè¯¥è·¯å¾„é€šè¿‡æ—¶é—´æ­¥é•¿å°†ç½‘ç»œçš„æ¿€æ´»å‘å‰æ¨è¿›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Geometrically, the dot product can be interpreted as equivalent to the cosine of the angle between the two vectors multiplied by the length of the two vectors:",
            "zh": "ä»å‡ ä½•ä¸Šè®²ï¼Œç‚¹ç§¯å¯ä»¥è§£é‡Šä¸ºç­‰ä»·äºä¸¤ä¸ªå‘é‡ä¹‹é—´è§’åº¦çš„ä½™å¼¦ä¹˜ä»¥ä¸¤ä¸ªå‘é‡çš„é•¿åº¦ï¼š"
        }
    },
    {
        "translation": {
            "en": "13.1â€ƒBusiness Understanding",
            "zh": "13.1 ä¸šåŠ¡ç†è§£"
        }
    },
    {
        "translation": {
            "en": "proportions, 749",
            "zh": "æ¯”ä¾‹ï¼Œ749"
        }
    },
    {
        "translation": {
            "en": "For example, an event in this domain would be represented as Dice1 = , Dice2 = .",
            "zh": "ä¾‹å¦‚ï¼Œæ­¤åŸŸä¸­çš„äº‹ä»¶å°†è¡¨ç¤ºä¸º Dice1 = ï¼Œ Dice2 = ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gaussian radial basis kernel, 366",
            "zh": "é«˜æ–¯å¾„å‘åŸºæ ¸ï¼Œ366"
        }
    },
    {
        "translation": {
            "en": "DERED_U/G/R/I/Z",
            "zh": "DERED_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "On the basis of these distances, each instance in is assigned to one of these clusters, as shown in the column labeled Cluster.",
            "zh": "æ ¹æ®è¿™äº›è·ç¦»ï¼Œå°†ä¸­çš„æ¯ä¸ªå®ä¾‹åˆ†é…ç»™å…¶ä¸­ä¸€ä¸ªé›†ç¾¤ï¼Œå¦‚æ ‡è®°ä¸ºâ€œé›†ç¾¤â€çš„åˆ—ä¸­æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "simple linear regression, 314, 732, 735",
            "zh": "ç®€å•çº¿æ€§å›å½’ï¼Œ 314ï¼Œ 732ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "Further, to aid in presentation we have rounded the activations for each layer to four decimal places and used these rounded activations as inputs to the later calculations.",
            "zh": "æ­¤å¤–ï¼Œä¸ºäº†ä¾¿äºæ¼”ç¤ºï¼Œæˆ‘ä»¬å°†æ¯å±‚çš„æ¿€æ´»å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼Œå¹¶å°†è¿™äº›å››èˆäº”å…¥çš„æ¿€æ´»ç”¨ä½œåç»­è®¡ç®—çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use lowercase letters with subscripts to iterate across values in the domain of a feature.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰ä¸‹æ ‡çš„å°å†™å­—æ¯æ¥è¿­ä»£ç‰¹å¾åŸŸä¸­çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also performed a simple first-pass feature selection using the 3-level model to see which features might stand out as predictive of galaxy morphology.",
            "zh": "Jocelynè¿˜ä½¿ç”¨3çº§æ¨¡å‹è¿›è¡Œäº†ç®€å•çš„é¦–æ¬¡ç‰¹å¾é€‰æ‹©ï¼Œä»¥æŸ¥çœ‹å“ªäº›ç‰¹å¾å¯èƒ½çªå‡ºåœ°é¢„æµ‹æ˜Ÿç³»å½¢æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.7",
            "zh": "è¡¨ 13.7"
        }
    },
    {
        "translation": {
            "en": "batch size, 417",
            "zh": "æ‰¹é‡å¤§å°ï¼Œ417"
        }
    },
    {
        "translation": {
            "en": "1. local receptive fields;",
            "zh": "1.å±€éƒ¨æ„Ÿå—é‡;"
        }
    },
    {
        "translation": {
            "en": "The type of the claim and amount of the claim are raw features calculated directly from a claims table contained in one of the insurance companyâ€™s operational databases.",
            "zh": "ç´¢èµ”ç±»å‹å’Œç´¢èµ”é‡‘é¢æ˜¯ç›´æ¥ä»ä¿é™©å…¬å¸è¿è¥æ•°æ®åº“ä¹‹ä¸€ä¸­åŒ…å«çš„ç´¢èµ”è¡¨è®¡ç®—çš„åŸå§‹è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This neuron has two large negative weights (w4,0 = âˆ’0.19 and w4,2 = âˆ’0.13).",
            "zh": "è¯¥ç¥ç»å…ƒæœ‰ä¸¤ä¸ªå¤§çš„è´Ÿæƒé‡ï¼ˆw4,0 = -0.19 å’Œ w4,2 = -0.13ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of a data issue due to valid data, so if this occurs for features in an ABT, it should be noted in the data quality plan.",
            "zh": "è¿™æ˜¯ç”±äºæœ‰æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®é—®é¢˜çš„ç¤ºä¾‹ï¼Œå› æ­¤ï¼Œå¦‚æœ ABT ä¸­çš„è¦ç´ å‡ºç°è¿™ç§æƒ…å†µï¼Œåˆ™åº”åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­æ³¨æ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customerâ€™s age",
            "zh": "å®¢æˆ·çš„å¹´é¾„"
        }
    },
    {
        "translation": {
            "en": "Using pruning, Ross was able to increase the average class accuracy on the hold-out test set to 79.03%, a significant improvement over the previous model. Table 12.3[699] shows the confusion matrix from this test. The confusion matrix shows that this model was slightly more accurate when classifying instances with the non-churn target level than with the churn target level. Based on these, results Ross was confident that this tree was a good solution for the AT churn prediction problem.",
            "zh": "ä½¿ç”¨ä¿®å‰ªï¼ŒRoss èƒ½å¤Ÿå°†ä¿æŒæµ‹è¯•é›†çš„å¹³å‡ç±»å‡†ç¡®ç‡æé«˜åˆ° 79.03%ï¼Œä¸ä¹‹å‰çš„æ¨¡å‹ç›¸æ¯”æœ‰äº†æ˜¾ç€æ”¹è¿›ã€‚è¡¨12.3[699]æ˜¾ç¤ºäº†è¯¥æµ‹è¯•çš„æ··æ·†çŸ©é˜µã€‚æ··æ·†çŸ©é˜µæ˜¾ç¤ºï¼Œåœ¨å¯¹å…·æœ‰éæµå¤±ç›®æ ‡çº§åˆ«çš„å®ä¾‹è¿›è¡Œåˆ†ç±»æ—¶ï¼Œæ­¤æ¨¡å‹çš„å‡†ç¡®æ€§ç•¥é«˜äºä½¿ç”¨æµå¤±ç›®æ ‡çº§åˆ«ã€‚åŸºäºè¿™äº›ç»“æœï¼ŒRoss ç¡®ä¿¡è¿™æ£µæ ‘æ˜¯ AT æµå¤±é¢„æµ‹é—®é¢˜çš„è‰¯å¥½è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning scenarios where episodes involve long sequences of actions, balancing exploration and exploitation is even more important.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ åœºæ™¯ä¸­ï¼Œå‰§é›†æ¶‰åŠé•¿åºåˆ—çš„åŠ¨ä½œï¼Œå¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨æ›´ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This performance is based on a stratified hold-out test set, which contains the same number of churners and non-churners.",
            "zh": "æ­¤æ€§èƒ½åŸºäºåˆ†å±‚ä¿ç•™æµ‹è¯•é›†ï¼Œè¯¥æµ‹è¯•é›†åŒ…å«ç›¸åŒæ•°é‡çš„æµå¤±è€…å’Œéæµå¤±è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is one partition created for each possible test result, which contains the training instances that returned that result.",
            "zh": "ä¸ºæ¯ä¸ªå¯èƒ½çš„æµ‹è¯•ç»“æœåˆ›å»ºä¸€ä¸ªåˆ†åŒºï¼Œå…¶ä¸­åŒ…å«è¿”å›è¯¥ç»“æœçš„è®­ç»ƒå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "co-absence (CA), how often a false value occurred for the same feature in both the query data q and the data for the comparison user (d1 or d2)",
            "zh": "å…±ç¼º ï¼ˆCAï¼‰ï¼ŒåŒä¸€è¦ç´ åœ¨æŸ¥è¯¢æ•°æ® q å’Œæ¯”è¾ƒç”¨æˆ·ï¼ˆd1 æˆ– d2ï¼‰çš„æ•°æ®ä¸­å‡ºç° false å€¼çš„é¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "The levels are none, guarantor, and coapplicant.",
            "zh": "çº§åˆ«ä¸ºæ— ã€æ‹…ä¿äººå’Œå…±åŒç”³è¯·äººã€‚"
        }
    },
    {
        "translation": {
            "en": "Confusion matrices, however, cannot be ordered and so cannot be used to rank the performance of the set of models.",
            "zh": "ä½†æ˜¯ï¼Œæ··æ·†çŸ©é˜µä¸èƒ½æ’åºï¼Œå› æ­¤ä¸èƒ½ç”¨äºå¯¹æ¨¡å‹é›†çš„æ€§èƒ½è¿›è¡Œæ’åã€‚"
        }
    },
    {
        "translation": {
            "en": "value function, 642",
            "zh": "å€¼å‡½æ•°ï¼Œ642"
        }
    },
    {
        "translation": {
            "en": "2. Increases the weights for the instances misclassified by the model using",
            "zh": "2. å¢åŠ æ¨¡å‹é”™è¯¯åˆ†ç±»çš„å®ä¾‹çš„æƒé‡"
        }
    },
    {
        "translation": {
            "en": "8.8â€…â€…â€…The per example error after each weight has been updated once, the per example âˆ‚â„°/âˆ‚a8, and the sum of squared errors for the model.",
            "zh": "8.8 æ¯ä¸ªæƒé‡æ›´æ–°ä¸€æ¬¡åçš„æ¯ä¸ªç¤ºä¾‹è¯¯å·®ã€æ¯ä¸ªç¤ºä¾‹ âˆ‚E/âˆ‚a8 ä»¥åŠæ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "long short-term memory, 508",
            "zh": "é•¿çŸ­æœŸè®°å¿†ï¼Œ508"
        }
    },
    {
        "translation": {
            "en": "The sigmoid activation function outputs values in the range 0 to 1 so that the multiplication of the cell state by the sigmoid layer activations has the effect of pushing all the cell state activations that have a corresponding sigmoid activation near 0 to 0 (i.e., these activations are forgotten) and all the cell state activations that have a corresponding sigmoid activation near 1 to be maintained (i.e., they are remembered) and propagated forward.",
            "zh": "sigmoid æ¿€æ´»å‡½æ•°è¾“å‡º 0 åˆ° 1 èŒƒå›´å†…çš„å€¼ï¼Œå› æ­¤ç»†èƒçŠ¶æ€ä¹˜ä»¥ sigmoid å±‚æ¿€æ´»å…·æœ‰å°†æ‰€æœ‰å…·æœ‰ç›¸åº” s å½¢æ¿€æ´»çš„ç»†èƒçŠ¶æ€æ¿€æ´»æ¨æ¥è¿‘ 0 åˆ° 0ï¼ˆå³ï¼Œè¿™äº›æ¿€æ´»è¢«é—å¿˜ï¼‰å’Œæ‰€æœ‰åœ¨ 1 é™„è¿‘å…·æœ‰ç›¸åº” s å½¢æ¿€æ´»çš„ç»†èƒçŠ¶æ€æ¿€æ´»ï¼ˆå³ ä»–ä»¬è¢«è®°ä½ï¼‰å¹¶å‘å‰ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s step through Equation (5.16)[219] bit by bit.",
            "zh": "è®©æˆ‘ä»¬ä¸€ç‚¹ä¸€ç‚¹åœ°å®Œæˆç­‰å¼ï¼ˆ5.16ï¼‰[219]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.33[484] illustrates how the local receptive fields of a set of neurons can be organized so that together they cover the entirety of the input.",
            "zh": "å›¾8.33[484]è¯´æ˜äº†å¦‚ä½•ç»„ç»‡ä¸€ç»„ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ï¼Œä»¥ä¾¿å®ƒä»¬ä¸€èµ·è¦†ç›–æ•´ä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Should it be based on the distance between the centroids of two clusters, or the distance between the two closest instances in two clusters, or the average distance between all instances in two clusters, or some other method?",
            "zh": "å®ƒåº”è¯¥åŸºäºä¸¤ä¸ªèšç±»çš„è´¨å¿ƒä¹‹é—´çš„è·ç¦»ï¼Œè¿˜æ˜¯ä¸¤ä¸ªèšç±»ä¸­ä¸¤ä¸ªæœ€è¿‘å®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼Œè¿˜æ˜¯ä¸¤ä¸ªèšç±»ä¸­æ‰€æœ‰å®ä¾‹ä¹‹é—´çš„å¹³å‡è·ç¦»ï¼Œè¿˜æ˜¯å…¶ä»–æ–¹æ³•ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16",
            "zh": "å›¾ 8.16"
        }
    },
    {
        "translation": {
            "en": "In this chapter we are going to see how this type of reasoning can be implemented as a machine learning algorithm.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•å°†è¿™ç§ç±»å‹çš„æ¨ç†å®ç°ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. See Section 3.4[69].",
            "zh": "6. å‚è§ç¬¬ 3.4 èŠ‚[69]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cards are worth their number value, with picture cards worth 10, and aces always worth 11 (this is one of the simplifications of this version of the game).",
            "zh": "å¡ç‰Œå€¼å…¶æ•°å­—å€¼ï¼Œå›¾ç‰‡å¡å€¼ 10ï¼ŒA æ€»å€¼ 11ï¼ˆè¿™æ˜¯æ­¤ç‰ˆæœ¬æ¸¸æˆçš„ç®€åŒ–ä¹‹ä¸€ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ReLU in the first layer has a 3-by-1 receptive field, and there is a stride of 1 used in this layer.",
            "zh": "ç¬¬ä¸€å±‚çš„ ReLU å…·æœ‰ 3Ã—1 çš„æ„Ÿå—é‡ï¼Œå¹¶ä¸”è¯¥å±‚ä½¿ç”¨çš„æ­¥å¹…ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, in order to maintain the sampling density of the feature space as the number of descriptive features increases, we need to dramatically, indeed, exponentially, increase the number of instances.",
            "zh": "å› æ­¤ï¼Œä¸ºäº†éšç€æè¿°æ€§ç‰¹å¾æ•°é‡çš„å¢åŠ è€Œä¿æŒç‰¹å¾ç©ºé—´çš„é‡‡æ ·å¯†åº¦ï¼Œæˆ‘ä»¬éœ€è¦å¤§å¹…å¢åŠ å®ä¾‹çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.6â€ƒFurther Reading",
            "zh": "7.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "In terms of using deep learning for a machine learning task, the first question to ask is whether deep learning is really necessary or appropriate.",
            "zh": "åœ¨å°†æ·±åº¦å­¦ä¹ ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡æ–¹é¢ï¼Œé¦–å…ˆè¦é—®çš„é—®é¢˜æ˜¯æ·±åº¦å­¦ä¹ æ˜¯å¦çœŸçš„å¿…è¦æˆ–åˆé€‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "From Table 11.3[661] we can see the Q values of the actions available to the agent from the starting state: Q(0-3,up) = âˆ’0.308, Q(0-3,down) = 0.247, Q(0-3,left) = 0.963, and Q(0-3,right) = 0.455.",
            "zh": "ä»è¡¨ 11.3[661] ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»èµ·å§‹çŠ¶æ€å¼€å§‹ä»£ç†å¯ç”¨çš„æ“ä½œçš„ Q å€¼ï¼šQï¼ˆ0-3ï¼Œupï¼‰ = âˆ’0.308ï¼ŒQï¼ˆ0-3ï¼Œdownï¼‰ = 0.247ï¼ŒQï¼ˆ0-3ï¼Œleftï¼‰ = 0.963ï¼ŒQï¼ˆ0-3ï¼Œrightï¼‰ = 0.455ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hastie, T., R. Tibshirani, and J. Friedman. 2001. The elements of statistical learning. Springer.",
            "zh": "Hastieï¼Œ T.ã€R. Tibshirani å’Œ J. Friedmanã€‚2001. ç»Ÿè®¡å­¦ä¹ çš„è¦ç´ .æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "It should also be noted that the range of values for the binary logarithm of a probability, [âˆ’âˆ, 0], is much larger than those taken by the probability itself [0,1].",
            "zh": "è¿˜åº”è¯¥æ³¨æ„çš„æ˜¯ï¼Œæ¦‚ç‡çš„äºŒè¿›åˆ¶å¯¹æ•° [âˆ’âˆï¼Œ 0] çš„å€¼èŒƒå›´æ¯”æ¦‚ç‡æœ¬èº« [0,1] å–çš„å€¼èŒƒå›´å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "The output of this layer of neurons is a vector mask, in which each element in the vector is in the range [0,1].",
            "zh": "è¿™å±‚ç¥ç»å…ƒçš„è¾“å‡ºæ˜¯ä¸€ä¸ªå‘é‡æ©ç ï¼Œå…¶ä¸­å‘é‡ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½åœ¨ [0,1] èŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Successful applications of propensity modeling include predicting the likelihood of customers to leave one mobile phone operator for another, to respond to particular marketing efforts, or to buy different products.",
            "zh": "å€¾å‘å»ºæ¨¡çš„æˆåŠŸåº”ç”¨åŒ…æ‹¬é¢„æµ‹å®¢æˆ·ç¦»å¼€ä¸€ä¸ªç§»åŠ¨ç”µè¯è¿è¥å•†åˆ°å¦ä¸€ä¸ªç§»åŠ¨ç”µè¯è¿è¥å•†çš„å¯èƒ½æ€§ï¼Œå“åº”ç‰¹å®šçš„è¥é”€å·¥ä½œæˆ–è´­ä¹°ä¸åŒçš„äº§å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can build a model ensemble using any type of prediction modelâ€”or indeed, a mixture of model types.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•ç±»å‹çš„é¢„æµ‹æ¨¡å‹ï¼ˆæˆ–è€…å®é™…ä¸Šæ˜¯æ¨¡å‹ç±»å‹çš„æ··åˆï¼‰æ¥æ„å»ºæ¨¡å‹é›†æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "There was no obvious relationship, so Jocelyn was confident that removing rows containing missing values would not affect one target level more than the others.",
            "zh": "ä¸¤è€…ä¹‹é—´æ²¡æœ‰æ˜æ˜¾çš„å…³ç³»ï¼Œå› æ­¤ Jocelyn ç¡®ä¿¡åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œä¸ä¼šå¯¹æŸä¸ªç›®æ ‡çº§åˆ«äº§ç”Ÿæ¯”å…¶ä»–ç›®æ ‡çº§åˆ«æ›´å¤§çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "k-medoids clustering, 601",
            "zh": "K-Medoidsèšç±»ï¼Œ601"
        }
    },
    {
        "translation": {
            "en": "We return subsequently to this vanishing z dynamic to explain in more detail how it arises.",
            "zh": "æˆ‘ä»¬éšåå›åˆ°è¿™ä¸ªæ¶ˆå¤±çš„ z åŠ¨æ€ï¼Œæ›´è¯¦ç»†åœ°è§£é‡Šå®ƒæ˜¯å¦‚ä½•äº§ç”Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Investigation of this issue with the business revealed that nothing had gone wrong during the ABT generation process, and that ci refers to car insurance.",
            "zh": "å¯¹ä¼ä¸šå¯¹æ­¤é—®é¢˜çš„è°ƒæŸ¥æ˜¾ç¤ºï¼Œåœ¨ ABT ç”Ÿæˆè¿‡ç¨‹ä¸­æ²¡æœ‰ä»»ä½•é—®é¢˜ï¼Œci æŒ‡çš„æ˜¯æ±½è½¦ä¿é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.3",
            "zh": "è¡¨ 6.3"
        }
    },
    {
        "translation": {
            "en": "Histograms that follow a normal distribution can also be described as unimodal because they have a single peak around the central tendency.",
            "zh": "éµå¾ªæ­£æ€åˆ†å¸ƒçš„ç›´æ–¹å›¾ä¹Ÿå¯ä»¥æè¿°ä¸ºå•å³°ï¼Œå› ä¸ºå®ƒä»¬åœ¨ä¸­å¿ƒè¶‹åŠ¿é™„è¿‘æœ‰ä¸€ä¸ªå³°ã€‚"
        }
    },
    {
        "translation": {
            "en": "smoothing, 243, 265, 266, 282",
            "zh": "å¹³æ»‘ï¼Œ 243ï¼Œ 265ï¼Œ 266ï¼Œ 282"
        }
    },
    {
        "translation": {
            "en": "In order to plan the expedition for the next day, you decide that you need to classify the animal so that you can determine whether it is dangerous to approach it or not.",
            "zh": "ä¸ºäº†è®¡åˆ’ç¬¬äºŒå¤©çš„æ¢é™©ï¼Œæ‚¨å†³å®šéœ€è¦å¯¹åŠ¨ç‰©è¿›è¡Œåˆ†ç±»ï¼Œä»¥ä¾¿ç¡®å®šæ¥è¿‘å®ƒæ˜¯å¦å±é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) What target level would a weighted k-NN model with k = 5 and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query, return for the query?",
            "zh": "ï¼ˆcï¼‰ k = 5 å¹¶ä½¿ç”¨é‚»åŸŸå’ŒæŸ¥è¯¢ä¹‹é—´æ¬§å‡ é‡Œå¾—è·ç¦»å¹³æ–¹çš„å€’æ•°åŠ æƒæ–¹æ¡ˆçš„åŠ æƒæ–¹æ¡ˆï¼ŒæŸ¥è¯¢çš„ç›®æ ‡æ°´å¹³æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "If we are calculating the probability of a single event given some evidence, then calculating P(Y) directly from the data using Equation (6.2)[248] is the easier option.",
            "zh": "å¦‚æœæˆ‘ä»¬åœ¨ç»™å®šä¸€äº›è¯æ®çš„æƒ…å†µä¸‹è®¡ç®—å•ä¸ªäº‹ä»¶çš„æ¦‚ç‡ï¼Œé‚£ä¹ˆä½¿ç”¨æ–¹ç¨‹ï¼ˆ6.2ï¼‰[248]ç›´æ¥ä»æ•°æ®ä¸­è®¡ç®—Pï¼ˆYï¼‰æ˜¯æ›´ç®€å•çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the four figures in Figure 8.23[453] uses side-by-side violin plots32 to illustrate the distribution of a network property (weights, weighted sums, activations, or Î´s) across the five hidden layers in the architecture during the first training iteration.",
            "zh": "å›¾ 8.23[453] ä¸­çš„å››ä¸ªå›¾ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä½¿ç”¨å¹¶æ’çš„å°æç´å›¾32æ¥è¯´æ˜åœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œç½‘ç»œå±æ€§ï¼ˆæƒé‡ã€åŠ æƒå’Œã€æ¿€æ´»æˆ– Î´ï¼‰åœ¨æ¶æ„ä¸­äº”ä¸ªéšè—å±‚ä¸­çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "All standard PDFs have parameters that alter the shape of the density curve defining that distribution.",
            "zh": "æ‰€æœ‰æ ‡å‡† PDF éƒ½å…·æœ‰æ”¹å˜å®šä¹‰è¯¥åˆ†å¸ƒçš„å¯†åº¦æ›²çº¿å½¢çŠ¶çš„å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "K2 score, 293",
            "zh": "K2 åˆ†æ•°ï¼Œ293"
        }
    },
    {
        "translation": {
            "en": "ethics, 47",
            "zh": "ä¼¦ç†å­¦ï¼Œ47"
        }
    },
    {
        "translation": {
            "en": "The probability of a joint event is simply the relative frequency of the joint event within the dataset.",
            "zh": "è”åˆäº‹ä»¶çš„æ¦‚ç‡åªæ˜¯æ•°æ®é›†ä¸­è”åˆäº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, assuming that we continue to train the network on just our small sample dataset with Î± = 0.2 and updating the weights after each pass through our data, then the training of the network would converge to an SSE < 0.0001 after 7,656 epochs.22 Table 8.9[433] lists the model predictions for each of the examples and the calculation of the sum of squared errors once training has converged.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬ç»§ç»­åœ¨Î± = 0.2çš„å°æ ·æœ¬æ•°æ®é›†ä¸Šè®­ç»ƒç½‘ç»œï¼Œå¹¶åœ¨æ¯æ¬¡é€šè¿‡æˆ‘ä»¬çš„æ•°æ®åæ›´æ–°æƒé‡ï¼Œé‚£ä¹ˆç½‘ç»œçš„è®­ç»ƒå°†åœ¨7,656ä¸ªå‘¨æœŸåæ”¶æ•›åˆ°SSE <0.0001.22è¡¨8.9[433]åˆ—å‡ºäº†æ¯ä¸ªç¤ºä¾‹çš„æ¨¡å‹é¢„æµ‹ä»¥åŠè®­ç»ƒæ”¶æ•›åè¯¯å·®å¹³æ–¹å’Œçš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "FAQ: Did the user read the frequently asked questions page?",
            "zh": "å¸¸è§é—®é¢˜è§£ç­”ï¼šç”¨æˆ·æ˜¯å¦é˜…è¯»äº†å¸¸è§é—®é¢˜é¡µé¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "mixture of Gaussians distribution, 270, 274",
            "zh": "é«˜æ–¯åˆ†å¸ƒçš„æ··åˆï¼Œ270,274"
        }
    },
    {
        "translation": {
            "en": "Features that have no correlation are said to be independent.",
            "zh": "æ²¡æœ‰ç›¸å…³æ€§çš„ç‰¹å¾è¢«ç§°ä¸ºç‹¬ç«‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the error gradient (the derivative) becomes too large, then the weights will be updated by a large amount, and the resulting changes in the output of a neuron, from one iteration to the next, will be so large that the training will become unstable.28 Conversely, if weights are very small (too close to 0), then the error gradient will tend to vanish, and the weight updates will be so small that training the network will take an inordinate amount of time.",
            "zh": "å¦‚æœè¯¯å·®æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰å˜å¾—å¤ªå¤§ï¼Œé‚£ä¹ˆæƒé‡å°†å¤§é‡æ›´æ–°ï¼Œå¹¶ä¸”ä»ä¸€æ¬¡è¿­ä»£åˆ°ä¸‹ä¸€æ¬¡è¿­ä»£çš„ç¥ç»å…ƒè¾“å‡ºçš„æœ€ç»ˆå˜åŒ–å°†å¦‚æ­¤ä¹‹å¤§ï¼Œä»¥è‡³äºè®­ç»ƒå°†å˜å¾—ä¸ç¨³å®š.28ç›¸åï¼Œå¦‚æœæƒé‡éå¸¸å°ï¼ˆå¤ªæ¥è¿‘0ï¼‰ï¼Œé‚£ä¹ˆè¯¯å·®æ¢¯åº¦å°†è¶‹äºæ¶ˆå¤±ï¼Œ è€Œä¸”æƒé‡æ›´æ–°å°†å¦‚æ­¤ä¹‹å°ï¼Œä»¥è‡³äºè®­ç»ƒç½‘ç»œå°†èŠ±è´¹è¿‡å¤šçš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customer retention team contacts these customers with special offers designed to entice them to stay with AT.",
            "zh": "å®¢æˆ·ä¿ç•™å›¢é˜Ÿä¼šé€šè¿‡ç‰¹åˆ«ä¼˜æƒ è”ç³»è¿™äº›å®¢æˆ·ï¼Œä»¥å¸å¼•ä»–ä»¬ç•™åœ¨ AT å…¬å¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some cases the observation period and outcome period are measured over the same time for all prediction subjects.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè§‚å¯ŸæœŸå’Œç»“æœæœŸæ˜¯åœ¨åŒä¸€æ—¶é—´æµ‹é‡æ‰€æœ‰é¢„æµ‹å¯¹è±¡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, on the basis of cumulative gain scores, which model would you recommend the company use for the pre-annotation filtering task?",
            "zh": "æœ€åï¼Œæ ¹æ®ç´¯ç§¯å¢ç›Šåˆ†æ•°ï¼Œæ‚¨ä¼šæ¨èå…¬å¸ä½¿ç”¨å“ªç§æ¨¡å‹è¿›è¡Œé¢„æ³¨é‡Šè¿‡æ»¤ä»»åŠ¡ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figures 3.10(c)[80] and 3.10(d)[80] show a similar pair of visualizations for the HEIGHT and POSITION features. Figure 3.10(d)[80] is typical of a series of box plots showing a strong relationship between a continuous and a categorical feature. We can see that the average height of centers is above that of forwards, which in turn is above that of guards. Although the whiskers show that there is some overlap between the three groups, they do appear to be well separated.",
            "zh": "å›¾ 3.10ï¼ˆcï¼‰[80] å’Œ 3.10ï¼ˆdï¼‰[80] æ˜¾ç¤ºäº† HEIGHT å’Œ POSITION ç‰¹å¾çš„ä¸€å¯¹ç±»ä¼¼å¯è§†åŒ–ã€‚å›¾3.10ï¼ˆdï¼‰[80]æ˜¯ä¸€ç³»åˆ—ç®±å½¢å›¾çš„å…¸å‹ç‰¹å¾ï¼Œæ˜¾ç¤ºäº†è¿ç»­ç‰¹å¾å’Œåˆ†ç±»ç‰¹å¾ä¹‹é—´çš„å¼ºå…³ç³»ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸­é”‹çš„å¹³å‡èº«é«˜é«˜äºå‰é”‹ï¼Œè€Œå‰é”‹åˆé«˜äºåå«ã€‚å°½ç®¡èƒ¡é¡»æ˜¾ç¤ºè¿™ä¸‰ç»„ä¹‹é—´å­˜åœ¨ä¸€äº›é‡å ï¼Œä½†å®ƒä»¬ä¼¼ä¹ç¡®å®åˆ†å¼€å¾—å¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that the decision boundaries in these examples are equally positioned between positive and negative instances, which is a consequence of the fact that decision boundaries satisfy these constraints.",
            "zh": "è¯·æ³¨æ„ï¼Œè¿™äº›ç¤ºä¾‹ä¸­çš„å†³ç­–è¾¹ç•Œåœ¨æ­£å®ä¾‹å’Œè´Ÿå®ä¾‹ä¹‹é—´ä½ç½®ç›¸åŒï¼Œè¿™æ˜¯å†³ç­–è¾¹ç•Œæ»¡è¶³è¿™äº›çº¦æŸçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "The easiest way to handle a continuous descriptive feature in a decision tree is to define a threshold within the range of values that the continuous feature can take and to use this threshold to partition the instances on the basis of whether their values for the feature are above or below the threshold.13 The only challenge is to determine the best threshold to use.",
            "zh": "åœ¨å†³ç­–æ ‘ä¸­å¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾çš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨è¿ç»­ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å€¼èŒƒå›´å†…å®šä¹‰ä¸€ä¸ªé˜ˆå€¼ï¼Œå¹¶ä½¿ç”¨æ­¤é˜ˆå€¼æ ¹æ®å®ä¾‹çš„ç‰¹å¾å€¼æ˜¯é«˜äºè¿˜æ˜¯ä½äºé˜ˆå€¼æ¥å¯¹å®ä¾‹è¿›è¡Œåˆ†åŒºã€‚13 å”¯ä¸€çš„æŒ‘æˆ˜æ˜¯ç¡®å®šè¦ä½¿ç”¨çš„æœ€ä½³é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The changing values of TPR and TNR for the test data shown in Table 9.13[560] as the threshold is altered; and (b) points in ROC space for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "ï¼ˆaï¼‰ è¡¨9.13[560]æ‰€ç¤ºæµ‹è¯•æ•°æ®çš„TPRå’ŒTNRå€¼éšç€é˜ˆå€¼çš„æ”¹å˜è€Œå˜åŒ–;ï¼ˆbï¼‰ ROC ç©ºé—´ä¸­é˜ˆå€¼ä¸º 0.25ã€0.5 å’Œ 0.75 çš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. The instances have been arranged in an order that leads to a nice dendrogram visualization, and this was also the order used in the distance matrices to make it easy to follow the combination of instances into clusters.",
            "zh": "10. å®ä¾‹çš„æ’åˆ—é¡ºåºå¯¼è‡´äº†è‰¯å¥½çš„æ ‘çŠ¶å›¾å¯è§†åŒ–ï¼Œè¿™ä¹Ÿæ˜¯è·ç¦»çŸ©é˜µä¸­ä½¿ç”¨çš„é¡ºåºï¼Œä»¥ä¾¿äºå°†å®ä¾‹ç»„åˆæˆé›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "The outliers present in the CLAIM AMOUNT and AMOUNT RECEIVED features could be easily handled using a clamp transformation.",
            "zh": "CLAIM AMOUNT å’Œ AMOUNT RECEIVED ç‰¹å¾ä¸­å­˜åœ¨çš„å¼‚å¸¸å€¼å¯ä»¥ä½¿ç”¨é’³ä½å˜æ¢è½»æ¾å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was a reasonably straightforward process with just a few issues that needed discussion.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªç›¸å½“ç®€å•çš„è¿‡ç¨‹ï¼Œåªæœ‰å‡ ä¸ªé—®é¢˜éœ€è¦è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAG_U/G/R/I/Z",
            "zh": "PETROMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems 27: Annual conference on neural information processing systems 2014, December 8â€“13, 2014, Montreal, Quebec, Canada, 2672â€“2680.",
            "zh": "Goodfellowã€Ianã€Jean Pouget-Abadieã€Mehdi Mirzaã€Bing Xuã€David Warde-Farleyã€Sherjil Ozairã€Aaron Courville å’Œ Yoshua Bengioã€‚2014. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ.ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±• 27ï¼š2014 å¹´ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¹´ä¼šï¼Œ2014 å¹´ 12 æœˆ 8 æ—¥è‡³ 13 æ—¥ï¼ŒåŠ æ‹¿å¤§é­åŒ—å…‹çœè’™ç‰¹åˆ©å°”ï¼Œ2672â€“2680ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the factors in Equation (6.15)[259], we calculate the posterior distribution for meningitis given the query instance using Equation (6.14)[258] as",
            "zh": "ä½¿ç”¨ç­‰å¼ï¼ˆ6.15ï¼‰[259]ä¸­çš„å› å­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç­‰å¼ï¼ˆ6.14ï¼‰[258]è®¡ç®—ç»™å®šæŸ¥è¯¢å®ä¾‹çš„è„‘è†œç‚çš„åéªŒåˆ†å¸ƒï¼Œå¦‚ä¸‹æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "(a) The set of cards after the wind blows over the one on the right; (b) the revised likelihoods for the position of the queen based on this new evidence; and (c) the final positions of the cards in the game.",
            "zh": "ï¼ˆaï¼‰ é£å¹è¿‡å³è¾¹çš„é‚£å¥—ç‰Œ;ï¼ˆbï¼‰ æ ¹æ®è¿™äº›æ–°è¯æ®ä¿®è®¢å¥³ç‹èŒä½çš„å¯èƒ½æ€§;åŠï¼ˆcï¼‰ç‰Œåœ¨æ¸¸æˆä¸­çš„æœ€ç»ˆä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although weight initialization is clearly important, at present relatively little is known in principle about how to select a good set of initial weights.",
            "zh": "å°½ç®¡æƒé‡åˆå§‹åŒ–æ˜¾ç„¶å¾ˆé‡è¦ï¼Œä½†ç›®å‰åŸåˆ™ä¸Šå¯¹å¦‚ä½•é€‰æ‹©ä¸€ç»„å¥½çš„åˆå§‹æƒé‡çŸ¥ä¹‹ç”šå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.8",
            "zh": "å›¾ 2.8"
        }
    },
    {
        "translation": {
            "en": "1,900",
            "zh": "1,900"
        }
    },
    {
        "translation": {
            "en": "In order to update the weights on the connections coming into a neuron, we must connect the rate of change of the error of the network to changes in each weight.",
            "zh": "ä¸ºäº†æ›´æ–°è¿›å…¥ç¥ç»å…ƒçš„è¿æ¥çš„æƒé‡ï¼Œæˆ‘ä»¬å¿…é¡»å°†ç½‘ç»œè¯¯å·®çš„å˜åŒ–ç‡ä¸æ¯ä¸ªæƒé‡çš„å˜åŒ–è”ç³»èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.3.3â€ƒMeasuring gain and liftâ€ƒIn scenarios in which we have a positive target level that we are especially interested in (for example, spam emails, fraudulent transactions, or customers who will respond to an offer), it can often be useful to focus in on how well a model is making predictions for just those instances, rather than how well the model is distinguishing between two target levels.",
            "zh": "9.4.3.3 è¡¡é‡å¢ç›Šå’Œæå‡ åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªæˆ‘ä»¬ç‰¹åˆ«æ„Ÿå…´è¶£çš„ç§¯æç›®æ ‡æ°´å¹³ï¼ˆä¾‹å¦‚ï¼Œåƒåœ¾é‚®ä»¶ã€æ¬ºè¯ˆæ˜“æˆ–å°†å“åº”æŠ¥ä»·çš„å®¢æˆ·ï¼‰çš„æƒ…å†µä¸‹ï¼Œå…³æ³¨æ¨¡å‹å¯¹è¿™äº›å®ä¾‹çš„é¢„æµ‹ç¨‹åº¦ï¼Œè€Œä¸æ˜¯æ¨¡å‹åŒºåˆ†ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„ç¨‹åº¦ï¼Œé€šå¸¸æ˜¯æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithms, Worked Examples, and Case Studies",
            "zh": "ç®—æ³•ã€å·¥ä½œç¤ºä¾‹å’Œæ¡ˆä¾‹ç ”ç©¶"
        }
    },
    {
        "translation": {
            "en": "We will see in forthcoming chapters that using binning to transform a continuous feature into a categorical feature is often the easiest way for some of the machine learning approaches to handle a continuous feature.",
            "zh": "åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ï¼Œä½¿ç”¨åˆ†ç®±å°†è¿ç»­ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾é€šå¸¸æ˜¯æŸäº›æœºå™¨å­¦ä¹ æ–¹æ³•å¤„ç†è¿ç»­ç‰¹å¾çš„æœ€ç®€å•æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. Interested readers might find Tempel et al. (2011), Ball et al. (2004) and Banerji et al. (2010) good references on this topic.",
            "zh": "12. æœ‰å…´è¶£çš„è¯»è€…å¯èƒ½ä¼šå‘ç° Tempel et al. ï¼ˆ2011ï¼‰ã€Ball et al. ï¼ˆ2004ï¼‰ å’Œ Banerji et al. ï¼ˆ2010ï¼‰ å…³äºè¿™ä¸€ä¸»é¢˜çš„è‰¯å¥½å‚è€ƒèµ„æ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first is related to anti-discrimination legislation.",
            "zh": "ç¬¬ä¸€ä¸ªé—®é¢˜ä¸åæ­§è§†ç«‹æ³•æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm works in exactly the same way for larger, more complicated datasets; there is simply more computation involved. Since it was first proposed, there have been many modifications to the original ID3 algorithm to handle variations that are common in real-world datasets. We explore the most important of these modifications in the following sections.",
            "zh": "ID3 ç®—æ³•çš„å·¥ä½œæ–¹å¼ä¸æ›´å¤§ã€æ›´å¤æ‚çš„æ•°æ®é›†å®Œå…¨ç›¸åŒ;åªæ˜¯æ¶‰åŠæ›´å¤šçš„è®¡ç®—ã€‚è‡ªé¦–æ¬¡æå‡ºä»¥æ¥ï¼Œå¯¹åŸå§‹ ID3 ç®—æ³•è¿›è¡Œäº†è®¸å¤šä¿®æ”¹ï¼Œä»¥å¤„ç†ç°å®ä¸–ç•Œæ•°æ®é›†ä¸­å¸¸è§çš„å˜åŒ–ã€‚æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹å„èŠ‚ä¸­æ¢è®¨è¿™äº›ä¿®æ”¹ä¸­æœ€é‡è¦çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.5â€…â€…â€…Modeling points in time using an observation period and an outcome period.",
            "zh": "2.5 ä½¿ç”¨è§‚å¯ŸæœŸå’Œç»“æœæœŸå¯¹æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Deep Q networks are a temporal-difference based approach that use a deep neural network to learn a generalize action-value function.",
            "zh": "æ·±åº¦ Q ç½‘ç»œæ˜¯ä¸€ç§åŸºäºæ—¶é—´å·®åˆ†çš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¹¿ä¹‰åŠ¨ä½œå€¼å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neapolitan, Richard E. 2004. Learning Bayesian networks. Pearson Prentice Hall.",
            "zh": "é‚£ä¸å‹’æ–¯äººï¼Œç†æŸ¥å¾· E. 2004 å¹´ã€‚å­¦ä¹ è´å¶æ–¯ç½‘ç»œã€‚çš®å°”é€ŠÂ·æ™®ä¼¦è’‚æ–¯Â·éœå°”ï¼ˆPearson Prentice Hallï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because of the dense fog, it is not possible for her to see the way to her destination at the bottom of the valley.",
            "zh": "ç”±äºæµ“é›¾ï¼Œå¥¹æ— æ³•çœ‹åˆ°å±±è°·åº•éƒ¨é€šå¾€ç›®çš„åœ°çš„è·¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "35. Learning rate values are typically in (0, 1], and gradient boosting implementations that use a learning rate often refer to it as incremental shrinkage.",
            "zh": "35. å­¦ä¹ ç‡å€¼é€šå¸¸åœ¨ ï¼ˆ0ï¼Œ 1ï¼‰ ä¸­ï¼Œä½¿ç”¨å­¦ä¹ ç‡çš„æ¢¯åº¦æå‡å®ç°é€šå¸¸å°†å…¶ç§°ä¸ºå¢é‡æ”¶ç¼©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Different randomly selected starting points can lead to different, often sub-optimal, clusterings.",
            "zh": "éšæœºé€‰æ‹©çš„ä¸åŒèµ·ç‚¹å¯èƒ½å¯¼è‡´ä¸åŒçš„ã€é€šå¸¸æ˜¯æ¬¡ä¼˜çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This error is then backpropagated through the unrolled network, in the same way that â„°t=3 is backpropagated in Figure 8.39[506] resulting in a single error gradient for each weight in Wyh and three separate error gradients for each weight in Whh and Whx.",
            "zh": "ç„¶åï¼Œè¯¥è¯¯å·®é€šè¿‡å±•å¼€çš„ç½‘ç»œè¿›è¡Œåå‘ä¼ æ’­ï¼Œå°±åƒå›¾8.39[506]ä¸­Et=3çš„åå‘ä¼ æ’­æ–¹å¼ä¸€æ ·ï¼Œå¯¼è‡´Wyhä¸­çš„æ¯ä¸ªæƒé‡éƒ½æœ‰ä¸€ä¸ªè¯¯å·®æ¢¯åº¦ï¼ŒWhhå’ŒWhxä¸­çš„æ¯ä¸ªæƒé‡éƒ½æœ‰ä¸‰ä¸ªå•ç‹¬çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.5",
            "zh": "è¡¨ 7.5"
        }
    },
    {
        "translation": {
            "en": "(2015) introduced the Parametric ReLU (PReLU) for which the main distinction from the Leaky ReLU was that rather than using a fixed predefined gradient for z â‰¤ 0, this gradient can be learned as a parameter for each neuron in the network.",
            "zh": "ï¼ˆ2015ï¼‰å¼•å…¥äº†å‚æ•°åŒ–ReLUï¼ˆPReLUï¼‰ï¼Œå…¶ä¸Leaky ReLUçš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œè¯¥æ¢¯åº¦å¯ä»¥ä½œä¸ºç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„å‚æ•°æ¥å­¦ä¹ ï¼Œè€Œä¸æ˜¯ä½¿ç”¨zâ‰¤0çš„å›ºå®šé¢„å®šä¹‰æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2.2â€…â€…â€…Measuring Error",
            "zh": "7.2.2 æµ‹é‡è¯¯å·®"
        }
    },
    {
        "translation": {
            "en": "Guo, Yanming, Yu Liu, Ard Oerlemans, Songyang Lao, Song Wu, and Michael S. Lew. 2016. Deep learning for visual understanding: A review. Neurocomputing 187: 27â€“48.",
            "zh": "Guoï¼Œ Yanmingï¼Œ Yu Liuï¼Œ Ard Oerlemansï¼Œ Songyang Laoï¼Œ Song Wuï¼Œ and Michael S. Lew.2016. è§†è§‰ç†è§£çš„æ·±åº¦å­¦ä¹ ï¼šç»¼è¿°.ç¥ç»è®¡ç®—187ï¼š27-48ã€‚"
        }
    },
    {
        "translation": {
            "en": "As well as being simple to understand and computationally efficient, it is also quite effective and often a good solution to clustering problems.",
            "zh": "é™¤äº†æ˜“äºç†è§£å’Œè®¡ç®—æ•ˆç‡é«˜ä¹‹å¤–ï¼Œå®ƒè¿˜éå¸¸æœ‰æ•ˆï¼Œé€šå¸¸æ˜¯èšç±»é—®é¢˜çš„å¥½æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we simply sum the values in the cells containing h, in other words, the cells in the first column of the distribution.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€å¯¹åŒ…å« h çš„å•å…ƒæ ¼ä¸­çš„å€¼æ±‚å’Œï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯åˆ†å¸ƒç¬¬ä¸€åˆ—ä¸­çš„å•å…ƒæ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "CPT, 286",
            "zh": "CPTï¼Œ286"
        }
    },
    {
        "translation": {
            "en": "Second, performance measured using hold-out sampling can be misleading if we happen to make a lucky split of the data that places the difficult instances into the training set and the easy ones into the test set.",
            "zh": "å…¶æ¬¡ï¼Œå¦‚æœæˆ‘ä»¬ç¢°å·§å¹¸è¿åœ°å°†æ•°æ®æ‹†åˆ†ï¼Œå°†å›°éš¾çš„å®ä¾‹æ”¾å…¥è®­ç»ƒé›†ï¼Œå°†ç®€å•çš„å®ä¾‹æ”¾å…¥æµ‹è¯•é›†ï¼Œåˆ™ä½¿ç”¨ä¿æŒæŠ½æ ·æµ‹é‡çš„æ€§èƒ½å¯èƒ½ä¼šäº§ç”Ÿè¯¯å¯¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "false negative rate, 548",
            "zh": "å‡é˜´æ€§ç‡ï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "The process used to calculate the term âˆ‚â„°/âˆ‚ak for a neuron k is dependent on whether the neuron is in the output layer or in one of the hidden layers of the network.",
            "zh": "ç”¨äºè®¡ç®—ç¥ç»å…ƒ k çš„æœ¯è¯­ âˆ‚E/âˆ‚ak çš„è¿‡ç¨‹å–å†³äºç¥ç»å…ƒæ˜¯åœ¨è¾“å‡ºå±‚è¿˜æ˜¯åœ¨ç½‘ç»œçš„éšè—å±‚ä¹‹ä¸€ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the standard practice in deep learning is to use mini-batch gradient descent.",
            "zh": "å› æ­¤ï¼Œæ·±åº¦å­¦ä¹ çš„æ ‡å‡†åšæ³•æ˜¯ä½¿ç”¨å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "P(t = l) is simply the relative frequency with which the target feature takes the level l in a dataset.",
            "zh": "Pï¼ˆt = lï¼‰ åªæ˜¯ç›®æ ‡è¦ç´ åœ¨æ•°æ®é›†ä¸­è¾¾åˆ° l çº§çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. The use of the kernel trick is key in writing efficient implementations of the support vector machine approach to predictive modelling. The kernel trick is based on the fact that the result of a kernel function applied to a support vector and a query instance is equivalent to the result of calculating the dot product between the support vector and the query instance after a specific set of basis functions have been applied to bothâ€”in other words, kernel(d, q) = Ï•(d) Â· Ï•(q).",
            "zh": "4. æ ¸æŠ€å·§çš„ä½¿ç”¨æ˜¯ç¼–å†™æ”¯æŒå‘é‡æœºé¢„æµ‹å»ºæ¨¡æ–¹æ³•çš„æœ‰æ•ˆå®ç°çš„å…³é”®ã€‚å†…æ ¸æŠ€å·§åŸºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³åº”ç”¨äºæ”¯æŒå‘é‡å’ŒæŸ¥è¯¢å®ä¾‹çš„å†…æ ¸å‡½æ•°çš„ç»“æœç­‰æ•ˆäºåœ¨å°†ä¸€ç»„ç‰¹å®šçš„åŸºå‡½æ•°åº”ç”¨äºæ”¯æŒå‘é‡å’ŒæŸ¥è¯¢å®ä¾‹ä¹‹åè®¡ç®—ç‚¹ç§¯çš„ç»“æœï¼Œæ¢å¥è¯è¯´ï¼Œ å†…æ ¸ï¼ˆdï¼Œ qï¼‰ = Ï†ï¼ˆdï¼‰ Â·Ï†ï¼ˆqï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other important distinction that is often made between classification models is whether they are generative or discriminative.",
            "zh": "åˆ†ç±»æ¨¡å‹ä¹‹é—´ç»å¸¸å‡ºç°çš„å¦ä¸€ä¸ªé‡è¦åŒºåˆ«æ˜¯å®ƒä»¬æ˜¯ç”Ÿæˆæ€§çš„è¿˜æ˜¯æ­§è§†æ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gleick (2011) provides an excellent and accessible introduction to information theory and its history. Shannon and Weaver (1949) is taken as the foundational book in information theory, and Cover and Thomas (1991) is a well-regarded textbook on the topic. MacKay (2003) is an excellent textbook on information theory and machine learning.",
            "zh": "Gleickï¼ˆ2011ï¼‰å¯¹ä¿¡æ¯è®ºåŠå…¶å†å²è¿›è¡Œäº†å‡ºè‰²ä¸”æ˜“äºç†è§£çš„ä»‹ç»ã€‚Shannon and Weaver ï¼ˆ1949ï¼‰ è¢«è®¤ä¸ºæ˜¯ä¿¡æ¯è®ºçš„åŸºç¡€ä¹¦ç±ï¼Œè€Œ Cover and Thomas ï¼ˆ1991ï¼‰ æ˜¯ä¸€æœ¬å…³äºè¯¥ä¸»é¢˜çš„å¹¿å—å¥½è¯„çš„æ•™ç§‘ä¹¦ã€‚MacKay ï¼ˆ2003ï¼‰æ˜¯ä¸€æœ¬å…³äºä¿¡æ¯è®ºå’Œæœºå™¨å­¦ä¹ çš„ä¼˜ç§€æ•™ç§‘ä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the sum of squared errors for this network for this example.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè®¡ç®—æ­¤ç½‘ç»œçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "range normalization, 87, 87, 101, 206, 322, 340, 342, 374, 375, 421, 422",
            "zh": "èŒƒå›´å½’ä¸€åŒ–ï¼Œ 87ï¼Œ 87ï¼Œ 101ï¼Œ 206ï¼Œ 322ï¼Œ 340ï¼Œ 342ï¼Œ 374ï¼Œ 375ï¼Œ 421ï¼Œ 422"
        }
    },
    {
        "translation": {
            "en": "The right side of Figure 8.5[392] illustrates the sequence of matrix operations that this network would carry out to process a single input vector.",
            "zh": "å›¾ 8.5[392] çš„å³ä¾§è¯´æ˜äº†è¯¥ç½‘ç»œä¸ºå¤„ç†å•ä¸ªè¾“å…¥å‘é‡è€Œæ‰§è¡Œçš„çŸ©é˜µæ“ä½œåºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEALTH: Health spending as a percentage of GDP",
            "zh": "å«ç”Ÿï¼šå«ç”Ÿæ”¯å‡ºå å›½å†…ç”Ÿäº§æ€»å€¼çš„ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "Eventually, the algorithm will converge to a point on the error surface where any subsequent changes to weights do not lead to a noticeably better model (within some tolerance).",
            "zh": "æœ€ç»ˆï¼Œè¯¥ç®—æ³•å°†æ”¶æ•›åˆ°è¯¯å·®æ›²é¢ä¸Šçš„ä¸€ä¸ªç‚¹ï¼Œåœ¨è¯¥ç‚¹ä¸Šï¼Œä»»ä½•åç»­çš„æƒé‡å˜åŒ–éƒ½ä¸ä¼šå¯¼è‡´æ˜æ˜¾æ›´å¥½çš„æ¨¡å‹ï¼ˆåœ¨ä¸€å®šçš„å…¬å·®èŒƒå›´å†…ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These missing values are due to valid data, so they do not need to be handled but should instead be recorded in the data quality plan.",
            "zh": "è¿™äº›ç¼ºå¤±å€¼æ˜¯ç”±äºæœ‰æ•ˆæ•°æ®é€ æˆçš„ï¼Œå› æ­¤ä¸éœ€è¦å¤„ç†å®ƒä»¬ï¼Œè€Œåº”è®°å½•åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will, however, be specific in distinguishing between metrics and indexes.",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬å°†å…·ä½“åŒºåˆ†æŒ‡æ ‡å’Œç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "These were all as the business expected.",
            "zh": "è¿™äº›éƒ½ç¬¦åˆä¼ä¸šçš„é¢„æœŸã€‚"
        }
    },
    {
        "translation": {
            "en": "where d is a set of descriptive features for an instance; w is the set of weights in the model; and the good and faulty generator target feature levels are represented as 0 and 1 respectively. Figure 7.11(b)[341] shows the value of Equation (7.24)[341] for every possible value of RPM and VIBRATION. This surface is known as a decision surface.",
            "zh": "å…¶ä¸­ d æ˜¯å®ä¾‹çš„ä¸€ç»„æè¿°æ€§ç‰¹å¾;w æ˜¯æ¨¡å‹ä¸­çš„æƒé‡é›†;è‰¯å¥½å’Œæ•…éšœç”Ÿæˆå™¨ç›®æ ‡ç‰¹å¾çº§åˆ«åˆ†åˆ«è¡¨ç¤ºä¸º 0 å’Œ 1ã€‚å›¾7.11ï¼ˆbï¼‰[341]æ˜¾ç¤ºäº†RPMå’ŒVIBRATIONæ¯ä¸ªå¯èƒ½å€¼çš„å…¬å¼ï¼ˆ7.24ï¼‰[341]çš„å€¼ã€‚æ­¤æ›²é¢ç§°ä¸ºå†³ç­–æ›²é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that the misclassification rate doesnâ€™t change that much as the threshold changes.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¯¯åˆ†ç±»ç‡çš„å˜åŒ–ä¸ä¼šéšç€é˜ˆå€¼çš„å˜åŒ–è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Edge of Tomorrow",
            "zh": "â€”â€”ã€Šæ˜æ—¥è¾¹ç¼˜ã€‹"
        }
    },
    {
        "translation": {
            "en": "In other words, small changes in descriptive features result in small changes in the target feature.",
            "zh": "æ¢è¨€ä¹‹ï¼Œæè¿°æ€§ç‰¹å¾çš„å¾®å°å˜åŒ–ä¼šå¯¼è‡´ç›®æ ‡ç‰¹å¾çš„å¾®å°å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "This calculation is known as a weighted sum because it involves summing the weighted inputs.",
            "zh": "æ­¤è®¡ç®—ç§°ä¸ºåŠ æƒæ€»å’Œï¼Œå› ä¸ºå®ƒæ¶‰åŠå¯¹åŠ æƒè¾“å…¥æ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Full details of all the data tables available from the SDSS are available at skyserver.sdss3.org/dr9/en/help/docs/tabledesc.asp.",
            "zh": "SDSSæä¾›çš„æ‰€æœ‰æ•°æ®è¡¨çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯å¯åœ¨ skyserver.sdss3.org/dr9/en/help/docs/tabledesc.asp ä¸Šæ‰¾åˆ°ã€‚"
        }
    },
    {
        "translation": {
            "en": "data subject, 40",
            "zh": "æ•°æ®ä¸»ä½“ï¼Œ40"
        }
    },
    {
        "translation": {
            "en": "At this point Ross just made note of these outliers as something he might have to deal with during the modeling phase.",
            "zh": "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼ŒRoss åªæ˜¯æ³¨æ„åˆ°äº†è¿™äº›å¼‚å¸¸å€¼ï¼Œè¿™æ˜¯ä»–åœ¨å»ºæ¨¡é˜¶æ®µå¯èƒ½å¿…é¡»å¤„ç†çš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see from the information in Table 4.4[137] that ELEVATION has the largest information gain of the three features and therefore is selected by the algorithm at the root node of the tree.",
            "zh": "ä»è¡¨4.4[137]ä¸­çš„ä¿¡æ¯å¯ä»¥çœ‹å‡ºï¼ŒELEVATIONåœ¨ä¸‰ä¸ªç‰¹å¾ä¸­å…·æœ‰æœ€å¤§çš„ä¿¡æ¯å¢ç›Šï¼Œå› æ­¤æ˜¯ç”±ç®—æ³•åœ¨æ ‘çš„æ ¹èŠ‚ç‚¹å¤„é€‰æ‹©çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The design of the book is informed by our many years of experience in teaching machine learning, and the approach and material in the book has been developed and â€œroad-testedâ€ in the classroom. In writing this book, we have adopted the following guiding principles to make the material accessible:",
            "zh": "æœ¬ä¹¦çš„è®¾è®¡åŸºäºæˆ‘ä»¬å¤šå¹´çš„æœºå™¨å­¦ä¹ æ•™å­¦ç»éªŒï¼Œä¹¦ä¸­çš„æ–¹æ³•å’Œææ–™å·²ç»åœ¨è¯¾å ‚ä¸Šå¼€å‘å’Œâ€œé“è·¯æµ‹è¯•â€ã€‚åœ¨æ’°å†™æœ¬ä¹¦æ—¶ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼Œä½¿ææ–™æ˜“äºè®¿é—®ï¼š"
        }
    },
    {
        "translation": {
            "en": "A model could be built to predict the amount most likely to be paid out by an insurance company after having investigated a claim.",
            "zh": "å¯ä»¥å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ä¿é™©å…¬å¸åœ¨è°ƒæŸ¥ç´¢èµ”åæœ€æœ‰å¯èƒ½æ”¯ä»˜çš„é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. To fully understand how a model is performing, it can often be useful to look beyond a single performance measure.",
            "zh": "3. ä¸ºäº†å……åˆ†äº†è§£æ¨¡å‹çš„æ€§èƒ½ï¼Œè¶…è¶Šå•ä¸€çš„æ€§èƒ½åº¦é‡é€šå¸¸å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The business was interested in the features that were selected as important to the tree, and there was a good deal of discussion on the omission of the features describing customersâ€™ interactions with AT customer care (these had been the basis of the organizationâ€™s previous model).",
            "zh": "è¯¥ä¸šåŠ¡éƒ¨é—¨å¯¹è¢«é€‰ä¸ºå¯¹æ ‘å¾ˆé‡è¦çš„ç‰¹å¾æ„Ÿå…´è¶£ï¼Œå¹¶ä¸”å¯¹çœç•¥æè¿°å®¢æˆ·ä¸ AT å®¢æˆ·æœåŠ¡äº¤äº’çš„ç‰¹å¾è¿›è¡Œäº†å¤§é‡è®¨è®ºï¼ˆè¿™äº›æ˜¯è¯¥ç»„ç»‡å…ˆå‰æ¨¡å‹çš„åŸºç¡€ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from this test is shown in Table 13.8[724].",
            "zh": "è¯¥æµ‹è¯•çš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.8[724]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "As part of a medical decision making system, a prediction system that can automatically determine the orientation of chest X-rays (the orientations can be lateral or frontal) is built.4 Based on a full dataset of 1,000 instances, we decide to evaluate the performance of this system with classification accuracy using 5-fold cross validation.",
            "zh": "ä½œä¸ºåŒ»ç–—å†³ç­–ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ä»¥è‡ªåŠ¨ç¡®å®šèƒ¸éƒ¨Xå…‰ç‰‡æ–¹å‘ï¼ˆæ–¹å‘å¯ä»¥æ˜¯æ¨ªå‘æˆ–æ­£é¢ï¼‰çš„é¢„æµ‹ç³»ç»Ÿ.4åŸºäº1,000ä¸ªå®ä¾‹çš„å®Œæ•´æ•°æ®é›†ï¼Œæˆ‘ä»¬å†³å®šä½¿ç”¨5å€äº¤å‰éªŒè¯æ¥è¯„ä¼°è¯¥ç³»ç»Ÿçš„æ€§èƒ½å’Œåˆ†ç±»ç²¾åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data quality report tables are shown in Table 12.2[694].",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šè¡¨å¦‚è¡¨12.2[694]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The accuracy for the model associated with the confusion matrix shown in Table 9.5[551] is 91%, while for the model associated with the confusion matrix shown in Table 9.6[551], the accuracy is just 78%.",
            "zh": "ä¸è¡¨9.5[551]æ‰€ç¤ºçš„æ··æ·†çŸ©é˜µç›¸å…³çš„æ¨¡å‹çš„å‡†ç¡®ç‡ä¸º91%ï¼Œè€Œå¯¹äºä¸è¡¨9.6[551]æ‰€ç¤ºçš„æ··æ·†çŸ©é˜µç›¸å…³çš„æ¨¡å‹ï¼Œå‡†ç¡®ç‡ä»…ä¸º78%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Due to the inclusion of the squared term, the root mean squared error tends to overestimate error slightly as it overemphasizes individual large errors. An alternative measure that addresses this problem is the mean absolute error (MAE), which does not include a squared term.22 Mean absolute error is calculated as",
            "zh": "ç”±äºåŒ…å«å¹³æ–¹é¡¹ï¼Œå‡æ–¹æ ¹è¯¯å·®å¾€å¾€ä¼šç•¥å¾®é«˜ä¼°è¯¯å·®ï¼Œå› ä¸ºå®ƒè¿‡åˆ†å¼ºè°ƒå•ä¸ªå¤§è¯¯å·®ã€‚è§£å†³æ­¤é—®é¢˜çš„å¦ä¸€ç§åº¦é‡æ˜¯å¹³å‡ç»å¯¹è¯¯å·® ï¼ˆMAEï¼‰ï¼Œå®ƒä¸åŒ…æ‹¬å¹³æ–¹é¡¹ã€‚22 å¹³å‡ç»å¯¹è¯¯å·®çš„è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "Once we have stored the instances in a dataset in a k-d tree, we can use the tree to quickly retrieve the nearest neighbor for a query instance.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬å°†å®ä¾‹å­˜å‚¨åœ¨ k-d æ ‘çš„æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨è¯¥æ ‘å¿«é€Ÿæ£€ç´¢æŸ¥è¯¢å®ä¾‹çš„æœ€è¿‘é‚»å±…ã€‚"
        }
    },
    {
        "translation": {
            "en": "After lengthy discussion, both Jocelyn and Edwin agreed that in order for the system to be useful, a classification accuracy of approximately 80% would be required.",
            "zh": "ç»è¿‡é•¿æ—¶é—´çš„è®¨è®ºï¼ŒJocelyn å’Œ Edwin ä¸€è‡´è®¤ä¸ºï¼Œä¸ºäº†ä½¿è¯¥ç³»ç»Ÿæœ‰ç”¨ï¼Œéœ€è¦å¤§çº¦ 80% çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16[430] shows the network with each neuron labeled with its corresponding Î´.",
            "zh": "å›¾8.16[430]æ˜¾ç¤ºäº†æ¯ä¸ªç¥ç»å…ƒéƒ½æ ‡æœ‰å…¶ç›¸åº”Î´çš„ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "7. See Section 4.2.3[127].",
            "zh": "7. å‚è§ç¬¬ 4.2.3 èŠ‚[127]ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the second tree that he built, Ross employed post-pruning using reduced error pruning,8 which used the validation partition that was created from the initial dataset.",
            "zh": "åœ¨ä»–æ„å»ºçš„ç¬¬äºŒæ£µæ ‘ä¸­ï¼ŒRoss ä½¿ç”¨å‡å°‘è¯¯å·®ä¿®å‰ª 8 è¿›è¡Œåä¿®å‰ªï¼Œè¯¥ä¿®å‰ªä½¿ç”¨ä»åˆå§‹æ•°æ®é›†åˆ›å»ºçš„éªŒè¯åˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, the general rule that is induced from a sample may not be true for all instances in a population.",
            "zh": "æ¢è¨€ä¹‹ï¼Œä»æ ·æœ¬ä¸­å¾—å‡ºçš„ä¸€èˆ¬è§„åˆ™å¯èƒ½ä¸é€‚ç”¨äºæ€»ä½“ä¸­çš„æ‰€æœ‰å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.24",
            "zh": "å›¾ 7.24"
        }
    },
    {
        "translation": {
            "en": "So, for example, Figure 9.15(b)[569] shows that by the 4th decile (40% of the test data), 66.667% of the spam emails in the entire test set will have been identified.",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œå›¾ 9.15ï¼ˆbï¼‰[569] æ˜¾ç¤ºï¼Œåˆ°ç¬¬ 4 ä¸ªååˆ†ä½æ•°ï¼ˆå æµ‹è¯•æ•°æ®çš„ 40%ï¼‰æ—¶ï¼Œæ•´ä¸ªæµ‹è¯•é›†ä¸­ 66.667% çš„åƒåœ¾é‚®ä»¶å°†è¢«è¯†åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each machine learning algorithm uses different model selection criteria to drive its search for the best predictive model.",
            "zh": "æ¯ç§æœºå™¨å­¦ä¹ ç®—æ³•éƒ½ä½¿ç”¨ä¸åŒçš„æ¨¡å‹é€‰æ‹©æ ‡å‡†æ¥æ¨åŠ¨å…¶å¯¹æœ€ä½³é¢„æµ‹æ¨¡å‹çš„æœç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Together these descriptive features will make up the ABT.",
            "zh": "è¿™äº›æè¿°æ€§ç‰¹å¾å°†å…±åŒæ„æˆ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "22. The conditional independence relationship between any two nodes in a Bayesian network can be specified using the framework of d-separation (the â€œdâ€ stands for directed) (Pearl, 1988). We donâ€™t discuss d-separation in this book as it is not required for our discussion.",
            "zh": "22. è´å¶æ–¯ç½‘ç»œä¸­ä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹å…³ç³»å¯ä»¥ä½¿ç”¨ d åˆ†ç¦»æ¡†æ¶ï¼ˆâ€œdâ€ä»£è¡¨æœ‰å‘ï¼‰æ¥æŒ‡å®šï¼ˆPearlï¼Œ1988ï¼‰ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰è®¨è®º d-åˆ†ç¦»ï¼Œå› ä¸ºæˆ‘ä»¬çš„è®¨è®ºä¸éœ€è¦å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "1. They build multiple different models from the same dataset by inducing each model using a modified version of the dataset.",
            "zh": "1. ä»–ä»¬é€šè¿‡ä½¿ç”¨æ•°æ®é›†çš„ä¿®æ”¹ç‰ˆæœ¬è¯±å¯¼æ¯ä¸ªæ¨¡å‹ï¼Œä»åŒä¸€æ•°æ®é›†æ„å»ºå¤šä¸ªä¸åŒçš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is done by incrementally adapting the dataset used to train the models.",
            "zh": "è¿™æ˜¯é€šè¿‡é€æ­¥è°ƒæ•´ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•°æ®é›†æ¥å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customer retention team monitors the number of calls made to the AT customer support center by each customer and identifies the customers who make a large number of customer support calls as churn risks.",
            "zh": "å®¢æˆ·ä¿ç•™å›¢é˜Ÿç›‘æ§æ¯ä¸ªå®¢æˆ·å‘ AT å®¢æˆ·æ”¯æŒä¸­å¿ƒæ‹¨æ‰“çš„ç”µè¯æ•°é‡ï¼Œå¹¶å°†æ‹¨æ‰“å¤§é‡å®¢æˆ·æ”¯æŒç”µè¯çš„å®¢æˆ·è¯†åˆ«ä¸ºæµå¤±é£é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conversely, a proportion of (100 âˆ’ i)/100 values in a sample take values larger than the ith percentile.",
            "zh": "ç›¸åï¼Œæ ·æœ¬ä¸­ ï¼ˆ100 âˆ’ iï¼‰/100 ä¸ªå€¼çš„æ¯”ä¾‹å–çš„å€¼å¤§äºç¬¬ i ä¸ªç™¾åˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The coordinate systems defined by the Mahalanobis distance using the covariance matrix for the dataset in Figure 5.15(c)[219] using three different origins: (a) (50,50); (b) (63,71); and (c) (42,35). The ellipses in each figure plot the 1, 3, and 5 unit distance contours.",
            "zh": "ä½¿ç”¨å›¾5.15ï¼ˆcï¼‰[219]ä¸­æ•°æ®é›†çš„åæ–¹å·®çŸ©é˜µå®šä¹‰çš„é©¬æ°è·ç¦»çš„åæ ‡ç³»ï¼Œä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„åŸç‚¹ï¼šï¼ˆaï¼‰ï¼ˆ50,50ï¼‰;ï¼ˆbï¼‰ï¼ˆ63,71ï¼‰;ä»¥åŠï¼ˆcï¼‰ï¼ˆ42,35ï¼‰ã€‚æ¯ä¸ªå›¾ä¸­çš„æ¤­åœ†ç»˜åˆ¶äº† 1ã€3 å’Œ 5 å•ä½è·ç¦»ç­‰å€¼çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the current estimate is higher than the actual return, then the estimate is lowered slightly, and vice versa.",
            "zh": "å¦‚æœå½“å‰ä¼°è®¡å€¼é«˜äºå®é™…å›æŠ¥ï¼Œåˆ™ä¼°è®¡å€¼ä¼šç•¥æœ‰é™ä½ï¼Œåä¹‹äº¦ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Structure of the Book",
            "zh": "æœ¬ä¹¦çš„ç»“æ„"
        }
    },
    {
        "translation": {
            "en": "To help with situational fluency for this scenario, here is a brief outline of how companies interact with the revenue commission.",
            "zh": "ä¸ºäº†å¸®åŠ©åœ¨è¿™ç§æƒ…å†µç•…åœ°äº†è§£æƒ…å†µï¼Œä»¥ä¸‹æ˜¯å…¬å¸å¦‚ä½•ä¸æ”¶å…¥å§”å‘˜ä¼šäº’åŠ¨çš„ç®€è¦æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.60",
            "zh": "0.60"
        }
    },
    {
        "translation": {
            "en": "How does the business currently work?",
            "zh": "è¯¥ä¸šåŠ¡ç›®å‰å¦‚ä½•è¿ä½œï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "2.4.3â€ƒHandling Time",
            "zh": "2.4.3 å¤„ç†æ—¶é—´"
        }
    },
    {
        "translation": {
            "en": "For example, in the churn prediction example, correctly classifying a customer as likely to churn is worth the same as correctly classifying a customer as not likely to churn.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å®¢æˆ·æµå¤±é¢„æµ‹ç¤ºä¾‹ä¸­ï¼Œå°†å®¢æˆ·æ­£ç¡®åˆ†ç±»ä¸ºå¯èƒ½æµå¤±ä¸æ­£ç¡®å°†å®¢æˆ·åˆ†ç±»ä¸ºä¸å¤ªå¯èƒ½æµå¤±çš„ä»·å€¼ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset has been prepared by an analytics team who are developing a model as a decision support tool for doctors.16 The goal of the model is to classify individuals into groups on the basis of their risk of suffering a stroke STROKE RISK.",
            "zh": "è¯¥æ•°æ®é›†ç”±ä¸€ä¸ªåˆ†æå›¢é˜Ÿå‡†å¤‡ï¼Œä»–ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªæ¨¡å‹ä½œä¸ºåŒ»ç”Ÿçš„å†³ç­–æ”¯æŒå·¥å…·.16 è¯¥æ¨¡å‹çš„ç›®æ ‡æ˜¯æ ¹æ®ä¸ªäººæ‚£ä¸­é£çš„é£é™©å°†ä¸ªäººåˆ†ç±»ä¸ºä¸­é£é£é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can illustrate the speed up in training that can be achieved by switching a network from using the logistic activation function to a rectified linear activation function if we compare the number of epochs required for the network from the worked example to converge to an SSE < 0.0001 when it uses ReLUs instead of logistic units.",
            "zh": "å¦‚æœæˆ‘ä»¬æ¯”è¾ƒç½‘ç»œä»å·¥ä½œç¤ºä¾‹æ”¶æ•›åˆ° SSE æ‰€éœ€çš„çºªå…ƒæ•°ï¼Œå½“å®ƒä½¿ç”¨ ReLU è€Œä¸æ˜¯é€»è¾‘å•å…ƒæ—¶ï¼Œ< 0.0001ï¼Œæˆ‘ä»¬å¯ä»¥è¯´æ˜é€šè¿‡å°†ç½‘ç»œä»ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°åˆ‡æ¢åˆ°ä¿®æ­£çº¿æ€§æ¿€æ´»å‡½æ•°å¯ä»¥å®ç°çš„è®­ç»ƒé€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a categorical feature storing gender with a cardinality of 6 is worthy of further investigation.",
            "zh": "ä¾‹å¦‚ï¼Œå­˜å‚¨åŸºæ•°ä¸º 6 çš„æ€§åˆ«çš„åˆ†ç±»ç‰¹å¾å€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "and spending time designing the evaluation process correctly.",
            "zh": "å¹¶èŠ±æ—¶é—´æ­£ç¡®è®¾è®¡è¯„ä¼°è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "artificial neuron, 383",
            "zh": "äººå·¥ç¥ç»å…ƒï¼Œ383"
        }
    },
    {
        "translation": {
            "en": "outliers, 63, 65, 87, 91, 94, 696, 745, 755",
            "zh": "å¼‚å¸¸å€¼ã€63ã€65ã€87ã€91ã€94ã€696ã€745ã€755"
        }
    },
    {
        "translation": {
            "en": "3.3.3â€ƒOutliers",
            "zh": "3.3.3 å¼‚å¸¸å€¼"
        }
    },
    {
        "translation": {
            "en": "However, this is not the only vector of error gradients that are backpropagated; recall, the âˆ‚â„°t/âˆ‚ctâˆ’1 is also backpropagated to the previous time-step.",
            "zh": "ç„¶è€Œï¼Œè¿™å¹¶ä¸æ˜¯åå‘ä¼ æ’­çš„è¯¯å·®æ¢¯åº¦çš„å”¯ä¸€å‘é‡;å›æƒ³ä¸€ä¸‹ï¼Œâˆ‚Et/âˆ‚ctâˆ’1 ä¹Ÿè¢«åå‘ä¼ æ’­åˆ°ä¸Šä¸€ä¸ªæ—¶é—´æ­¥é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The speed of a car during a journey along a minor road before joining a highway and finally coming to a sudden halt; and (b) the acceleration, the derivative of speed with respect to time, for this journey.",
            "zh": "ï¼ˆaï¼‰ æ±½è½¦åœ¨è¿›å…¥é«˜é€Ÿå…¬è·¯å¹¶æœ€ç»ˆçªç„¶åœä¸‹æ¥ä¹‹å‰æ²¿ä¸€æ¡å°è·¯è¡Œé©¶æ—¶çš„é€Ÿåº¦;ï¼ˆbï¼‰åŠ é€Ÿåº¦ï¼Œå³é€Ÿåº¦ç›¸å¯¹äºæ—¶é—´çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The name inverted dropout comes from this division of the non-zeroed activations by the Ï parameter.",
            "zh": "å€’ç½®è¾å­¦çš„åç§°æ¥è‡ªéå½’é›¶æ¿€æ´»é™¤ä»¥ Ï å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The disadvantage is that these approaches can struggle to learn very long-term strategies in which reward does not accrue until long after actions have been taken.",
            "zh": "ç¼ºç‚¹æ˜¯ï¼Œè¿™äº›æ–¹æ³•å¯èƒ½å¾ˆéš¾å­¦ä¹ éå¸¸é•¿æœŸçš„ç­–ç•¥ï¼Œåœ¨è¿™äº›ç­–ç•¥ä¸­ï¼Œå¥–åŠ±ç›´åˆ°é‡‡å–è¡ŒåŠ¨å¾ˆä¹…ä¹‹åæ‰ä¼šç´¯ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "sequential gradient descent, 415",
            "zh": "é¡ºåºæ¢¯åº¦ä¸‹é™ï¼Œ415"
        }
    },
    {
        "translation": {
            "en": "Figure 4.1[118] shows the set of cards that we will use for our game.",
            "zh": "å›¾ 4.1[118] æ˜¾ç¤ºäº†æˆ‘ä»¬å°†ç”¨äºæ¸¸æˆçš„å¡ç‰Œé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given a large population of independent models, an ensemble can be very accurate, even if the individual models in the ensemble perform only marginally better than random guessing.",
            "zh": "ç»™å®šå¤§é‡ç‹¬ç«‹æ¨¡å‹ï¼Œå³ä½¿é›†æˆä¸­çš„å•ä¸ªæ¨¡å‹ä»…æ¯”éšæœºçŒœæµ‹ç•¥å¥½ï¼Œé›†æˆä¹Ÿå¯ä»¥éå¸¸å‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, if the entire training set is presented to this model, its performance will appear to be perfect.",
            "zh": "å› æ­¤ï¼Œå¦‚æœå°†æ•´ä¸ªè®­ç»ƒé›†å‘ˆç°ç»™æ­¤æ¨¡å‹ï¼Œåˆ™å…¶æ€§èƒ½å°†çœ‹èµ·æ¥å¾ˆå®Œç¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of the z values and activations of each neuron during the forward pass of the backpropagation algorithm. This figure is based on Figure 6.5 of Kelleher (2019).",
            "zh": "åœ¨åå‘ä¼ æ’­ç®—æ³•çš„å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„ z å€¼å’Œæ¿€æ´»ã€‚è¯¥æ•°å­—åŸºäºKelleherï¼ˆ2019ï¼‰çš„å›¾6.5ã€‚"
        }
    },
    {
        "translation": {
            "en": "The online store would like to cluster their customers to see if they could define meaningful groups to whom they could target special offers. The table below shows a distance matrix calculated using the Jaccard similarity measure (see Section 5.4.5[211]). A number of items have been left out of this matrix (indicated by ??).",
            "zh": "åœ¨çº¿å•†åº—å¸Œæœ›å°†ä»–ä»¬çš„å®¢æˆ·èšé›†åœ¨ä¸€èµ·ï¼Œçœ‹çœ‹ä»–ä»¬æ˜¯å¦å¯ä»¥å®šä¹‰æœ‰æ„ä¹‰çš„ç¾¤ä½“ï¼Œä»–ä»¬å¯ä»¥é’ˆå¯¹è¿™äº›ç¾¤ä½“æä¾›ç‰¹åˆ«ä¼˜æƒ ã€‚ä¸‹è¡¨æ˜¾ç¤ºäº†ä½¿ç”¨ Jaccard ç›¸ä¼¼åº¦åº¦é‡è®¡ç®—çš„è·ç¦»çŸ©é˜µï¼ˆå‚è§ç¬¬ 5.4.5 èŠ‚ [211]ï¼‰ã€‚è®¸å¤šé¡¹ç›®å·²è¢«æ’é™¤åœ¨è¯¥çŸ©é˜µä¹‹å¤–ï¼ˆç”¨ ï¼Ÿï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Table 5.5",
            "zh": "è¡¨ 5.5"
        }
    },
    {
        "translation": {
            "en": "Spectrography data may be useful in galaxy classification because different galaxy types are likely to emit different amounts of different light wavelengths, so spectrograms might be a good indicator for galaxy type.",
            "zh": "å…‰è°±å­¦æ•°æ®å¯èƒ½åœ¨æ˜Ÿç³»åˆ†ç±»ä¸­æœ‰ç”¨ï¼Œå› ä¸ºä¸åŒçš„æ˜Ÿç³»ç±»å‹å¯èƒ½ä¼šå‘å°„ä¸åŒæ•°é‡çš„ä¸åŒæ³¢é•¿çš„å…‰ï¼Œå› æ­¤å…‰è°±å›¾å¯èƒ½æ˜¯æ˜Ÿç³»ç±»å‹çš„ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "incremental shrinkage, 168",
            "zh": "å¢é‡æ”¶ç¼©ç‡ï¼Œ168"
        }
    },
    {
        "translation": {
            "en": "To complete the process of building the ensemble model, the algorithm continues to iteratively calculate errors and train new models to predict these errors, which are added as correction terms to the previous model output.",
            "zh": "ä¸ºäº†å®Œæˆæ„å»ºé›†æˆæ¨¡å‹çš„è¿‡ç¨‹ï¼Œè¯¥ç®—æ³•å°†ç»§ç»­è¿­ä»£è®¡ç®—è¯¯å·®å¹¶è®­ç»ƒæ–°æ¨¡å‹æ¥é¢„æµ‹è¿™äº›è¯¯å·®ï¼Œè¿™äº›è¯¯å·®å°†ä½œä¸ºæ ¡æ­£é¡¹æ·»åŠ åˆ°ä»¥å‰çš„æ¨¡å‹è¾“å‡ºä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1.2â€ƒk-Fold cross validationâ€ƒWhen k-fold cross validation is used, the available data is divided into k equal-sized folds (or partitions), and k separate evaluation experiments are performed.",
            "zh": "9.4.1.2 k-foldäº¤å‰éªŒè¯ å½“ä½¿ç”¨k-foldäº¤å‰éªŒè¯æ—¶ï¼Œå¯ç”¨æ•°æ®è¢«åˆ†æˆkä¸ªå¤§å°ç›¸ç­‰çš„æŠ˜å ï¼ˆæˆ–åˆ†åŒºï¼‰ï¼Œå¹¶è¿›è¡Œkä¸ªå•ç‹¬çš„è¯„ä¼°å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "max pooling, 490",
            "zh": "æœ€å¤§æ± åŒ–ï¼Œ490"
        }
    },
    {
        "translation": {
            "en": "10. Many systems use values like âˆ’ 9,999 to indicate that values are actually missing.",
            "zh": "10. è®¸å¤šç³»ç»Ÿä½¿ç”¨ âˆ’ 9,999 ç­‰å€¼æ¥è¡¨ç¤ºå®é™…ç¼ºå°‘å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapelle, Olivier, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-supervised learning (Chapelle, O. et al., eds.; 2006) [book reviews]. IEEE Transactions on Neural Networks 20 (3): 542â€“542.",
            "zh": "Chapelleã€Olivierã€Bernhard Scholkopf å’Œ Alexander Zienã€‚2009. åŠç›‘ç£å­¦ä¹  ï¼ˆChapelleï¼Œ O. et al.ï¼Œ eds.; 2006ï¼‰ [ä¹¦è¯„].IEEEç¥ç»ç½‘ç»œæ±‡åˆŠ20ï¼ˆ3ï¼‰ï¼š542â€“542ã€‚"
        }
    },
    {
        "translation": {
            "en": "Aside from the fact that the logarithm function returns negative numbers, the magnitude of the numbers it returns is ideal as a measure of entropy: large numbers for low probabilities and small numbers (near zero) for high probabilities.",
            "zh": "é™¤äº†å¯¹æ•°å‡½æ•°è¿”å›è´Ÿæ•°è¿™ä¸€äº‹å®ä¹‹å¤–ï¼Œå®ƒè¿”å›çš„æ•°å­—çš„å¤§å°æ˜¯ç†æƒ³çš„ç†µåº¦é‡ï¼šå¤§æ•°è¡¨ç¤ºä½æ¦‚ç‡ï¼Œå°æ•°ï¼ˆæ¥è¿‘é›¶ï¼‰è¡¨ç¤ºé«˜æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "churn prediction, 584, 685",
            "zh": "æµå¤±é¢„æµ‹ï¼Œ584,685"
        }
    },
    {
        "translation": {
            "en": "Just as we did when we played Guess Who, an effective way to generate a prediction is to carry out a series of tests on the values of the descriptive features describing a query instance and use the answers to these tests to determine the prediction.",
            "zh": "å°±åƒæˆ‘ä»¬åœ¨ç© Guess Who æ—¶æ‰€åšçš„é‚£æ ·ï¼Œç”Ÿæˆé¢„æµ‹çš„æœ‰æ•ˆæ–¹æ³•æ˜¯å¯¹æè¿°æŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾çš„å€¼æ‰§è¡Œä¸€ç³»åˆ—æµ‹è¯•ï¼Œå¹¶ä½¿ç”¨è¿™äº›æµ‹è¯•çš„ç­”æ¡ˆæ¥ç¡®å®šé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The normal distribution (also known as a Gaussian distribution) is so important that it is worth spending a little extra time discussing its characteristics. Standard probability distributions have associated probability density functions, which define the characteristics of the distribution. The probability density function for the normal distribution is",
            "zh": "æ­£æ€åˆ†å¸ƒï¼ˆä¹Ÿç§°ä¸ºé«˜æ–¯åˆ†å¸ƒï¼‰éå¸¸é‡è¦ï¼Œå€¼å¾—èŠ±ä¸€ç‚¹é¢å¤–çš„æ—¶é—´è®¨è®ºå…¶ç‰¹å¾ã€‚æ ‡å‡†æ¦‚ç‡åˆ†å¸ƒå…·æœ‰å…³è”çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å®šä¹‰äº†åˆ†å¸ƒçš„ç‰¹å¾ã€‚æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "Type",
            "zh": "ç±»å‹"
        }
    },
    {
        "translation": {
            "en": "However, decision trees are often used in model ensembles due to the sensitivity of tree induction to changes in the dataset, and this is why we introduced model ensembles in this chapter.",
            "zh": "ç„¶è€Œï¼Œç”±äºæ ‘å½’çº³å¯¹æ•°æ®é›†å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œå†³ç­–æ ‘ç»å¸¸ç”¨äºæ¨¡å‹é›†æˆï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨æœ¬ç« ä¸­å¼•å…¥æ¨¡å‹é›†æˆçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculated posterior probabilities indicate that it is a certainty that the patient does not have meningitis!",
            "zh": "è®¡ç®—å‡ºçš„åéªŒæ¦‚ç‡è¡¨æ˜ï¼Œæ‚£è€…æ²¡æœ‰è„‘è†œç‚æ˜¯è‚¯å®šçš„ï¼"
        }
    },
    {
        "translation": {
            "en": "(a) The information gain (calculated using entropy) of the feature AGE at the root node of the tree is 0.247. A colleague has suggested that the STUDENT feature would be better at the root node of the tree. Show that this is not the case.",
            "zh": "ï¼ˆaï¼‰ æ ‘æ ¹èŠ‚ç‚¹å¤„ç‰¹å¾AGEçš„ä¿¡æ¯å¢ç›Šï¼ˆä½¿ç”¨ç†µè®¡ç®—ï¼‰ä¸º0.247ã€‚ä¸€ä½åŒäº‹å»ºè®®ï¼Œåœ¨æ ‘çš„æ ¹èŠ‚ç‚¹ä¸Šä½¿ç”¨ STUDENT åŠŸèƒ½ä¼šæ›´å¥½ã€‚è¡¨æ˜äº‹å®å¹¶éå¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first detail that Jocelyn needed to agree on with Edwin was the set of categories into which sky objects should be categorized.",
            "zh": "Jocelyn éœ€è¦ä¸ Edwin è¾¾æˆä¸€è‡´çš„ç¬¬ä¸€ä¸ªç»†èŠ‚æ˜¯å¤©ç©ºå¤©ä½“åº”è¯¥è¢«å½’ç±»çš„ä¸€ç»„ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The search finishes when it reaches the root node and both its branches have been either searched or pruned.",
            "zh": "å½“æœç´¢åˆ°è¾¾æ ¹èŠ‚ç‚¹å¹¶ä¸”å…¶ä¸¤ä¸ªåˆ†æ”¯éƒ½å·²æœç´¢æˆ–ä¿®å‰ªæ—¶ï¼Œæœç´¢ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision boundary learned by the logistic regression model best matches the underlying decision boundary for the dataset in the first column, the decision tree model seems most appropriate for the dataset in the second column, and the k-NN model appears best for the dataset in the third column.",
            "zh": "é€»è¾‘å›å½’æ¨¡å‹å­¦ä¹ çš„å†³ç­–è¾¹ç•Œä¸ç¬¬ä¸€åˆ—ä¸­æ•°æ®é›†çš„åŸºç¡€å†³ç­–è¾¹ç•Œæœ€åŒ¹é…ï¼Œå†³ç­–æ ‘æ¨¡å‹ä¼¼ä¹æœ€é€‚åˆç¬¬äºŒåˆ—ä¸­çš„æ•°æ®é›†ï¼Œè€Œ k-NN æ¨¡å‹æœ€é€‚åˆç¬¬ä¸‰åˆ—ä¸­çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in medical applications, a prediction that a patient has a disease is much more important than a prediction that a patient does not.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—åº”ç”¨ä¸­ï¼Œé¢„æµ‹æ‚£è€…æ‚£æœ‰ç–¾ç—…æ¯”é¢„æµ‹æ‚£è€…æ²¡æœ‰ç–¾ç—…è¦é‡è¦å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "13. This is simply the definition of expectation as defined in probability theory for any random variable: , where X is a random variable, x1 to xk are the possible values of the random variable, and p1 to pk are the probabilities of these different values occurring.",
            "zh": "13. è¿™åªæ˜¯æ¦‚ç‡è®ºä¸­å¯¹ä»»ä½•éšæœºå˜é‡çš„æœŸæœ›å®šä¹‰ï¼šå…¶ä¸­ X æ˜¯éšæœºå˜é‡ï¼Œx1 åˆ° xk æ˜¯éšæœºå˜é‡çš„å¯èƒ½å€¼ï¼Œp1 åˆ° pk æ˜¯è¿™äº›ä¸åŒå€¼å‘ç”Ÿçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "When a model predicts a continuous target, the target range is divided into bins, and the distribution of values into these bins is used in the calculation.",
            "zh": "å½“æ¨¡å‹é¢„æµ‹è¿ç»­ç›®æ ‡æ—¶ï¼Œç›®æ ‡èŒƒå›´è¢«åˆ’åˆ†ä¸ºæ¡æŸ±ï¼Œå¹¶åœ¨è®¡ç®—ä¸­ä½¿ç”¨è¿™äº›æ¡æŸ±ä¸­çš„å€¼åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices for the baseline models.",
            "zh": "åŸºçº¿æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "XGBoost, 171",
            "zh": "XGBoostï¼Œ 171"
        }
    },
    {
        "translation": {
            "en": "identity function, 624",
            "zh": "æ’ç­‰å‡½æ•°ï¼Œ624"
        }
    },
    {
        "translation": {
            "en": "What is happening here is that, as Bayesâ€™ Theorem states, when calculating a posterior prediction, we weight the likelihood of the evidence given the prediction by the prior of the prediction.",
            "zh": "è¿™é‡Œå‘ç”Ÿçš„äº‹æƒ…æ˜¯ï¼Œæ­£å¦‚è´å¶æ–¯å®šç†æ‰€æŒ‡å‡ºçš„é‚£æ ·ï¼Œåœ¨è®¡ç®—åéªŒé¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡é¢„æµ‹çš„å…ˆéªŒæ¥åŠ æƒç»™å®šé¢„æµ‹çš„è¯æ®çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "At a certain point in training, further adjustments to the weights will not result in significant changes to the network error, and the convergence criterion specifies a decision process whereby we decide when to stop training.",
            "zh": "åœ¨è®­ç»ƒçš„æŸä¸ªç‚¹ä¸Šï¼Œå¯¹æƒé‡çš„è¿›ä¸€æ­¥è°ƒæ•´ä¸ä¼šå¯¼è‡´ç½‘ç»œè¯¯å·®çš„é‡å¤§å˜åŒ–ï¼Œæ”¶æ•›å‡†åˆ™æŒ‡å®šäº†ä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œæˆ‘ä»¬é€šè¿‡è¯¥è¿‡ç¨‹å†³å®šä½•æ—¶åœæ­¢è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This gives a state representation with six states to represent all possible combinations of the value of the cards in the playerâ€™s hand and the value of the dealerâ€™s visible card: PL-DL, PM-DL, PH-DL, PL-DH, PM-DH, and PH-DH.",
            "zh": "è¿™ç»™å‡ºäº†ä¸€ä¸ªå…·æœ‰å…­ç§çŠ¶æ€çš„çŠ¶æ€è¡¨ç¤ºï¼Œä»¥è¡¨ç¤ºç©å®¶æ‰‹ä¸­çš„ç‰Œå€¼å’Œåº„å®¶å¯è§ç‰Œçš„ä»·å€¼çš„æ‰€æœ‰å¯èƒ½ç»„åˆï¼šPL-DLã€PM-DLã€PH-DLã€PL-DHã€PM-DH å’Œ PH-DHã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the gradient for the max function (âˆ‚a/âˆ‚z) for the max value is 1, because the output of the activation function will be linear for small changes in the input value that achieved the max (i.e., it will change by the same amount as that input value is changed).",
            "zh": "æ­¤å¤–ï¼Œæœ€å¤§å€¼çš„æœ€å¤§å€¼ ï¼ˆâˆ‚a/âˆ‚zï¼‰ çš„æ¢¯åº¦ä¸º 1ï¼Œå› ä¸ºæ¿€æ´»å‡½æ•°çš„è¾“å‡ºå¯¹äºè¾¾åˆ°æœ€å¤§å€¼çš„è¾“å…¥å€¼çš„å¾®å°å˜åŒ–å°†æ˜¯çº¿æ€§çš„ï¼ˆå³ï¼Œå®ƒå°†éšç€è¾“å…¥å€¼çš„å˜åŒ–è€Œå˜åŒ–ç›¸åŒçš„é‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "To monitor the ongoing performance of a model, we need a signal that indicates that something has changed. There are three sources from which we can extract such a signal:",
            "zh": "ä¸ºäº†ç›‘æ§æ¨¡å‹çš„æŒç»­æ€§èƒ½ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¿¡å·æ¥æŒ‡ç¤ºæŸäº›ä¸œè¥¿å‘ç”Ÿäº†å˜åŒ–ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸‰ä¸ªæ¥æºä¸­æå–è¿™æ ·çš„ä¿¡å·ï¼š"
        }
    },
    {
        "translation": {
            "en": "We use this dataset to illustrate training a deep feedforward network.",
            "zh": "æˆ‘ä»¬ç”¨è¿™ä¸ªæ•°æ®é›†æ¥è¯´æ˜æ·±åº¦å‰é¦ˆç½‘ç»œçš„è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "INCOME",
            "zh": "æ”¶å…¥"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the 5-level logistic regression model (classification accuracy: 77.528%, average class accuracy: 43.018%).",
            "zh": "5çº§logisticå›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š77.528%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š43.018%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the error of a regression tree in making a prediction for a query instance is the difference between the mean of the training instances that reached the leaf node that returns the prediction and the correct value that should have been returned for that query.",
            "zh": "è¿™æ„å‘³ç€å›å½’æ ‘åœ¨å¯¹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹æ—¶çš„é”™è¯¯æ˜¯åˆ°è¾¾è¿”å›é¢„æµ‹çš„å¶èŠ‚ç‚¹çš„è®­ç»ƒå®ä¾‹çš„å¹³å‡å€¼ä¸åº”ä¸ºè¯¥æŸ¥è¯¢è¿”å›çš„æ­£ç¡®å€¼ä¹‹é—´çš„å·®å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.167",
            "zh": "0.167"
        }
    },
    {
        "translation": {
            "en": "This is why the variance of the z values rapidly increases as we move forward through the network as shown in Figure 8.24(b)[454].",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“æˆ‘ä»¬åœ¨ç½‘ç»œä¸­å‰è¿›æ—¶ï¼Œzå€¼çš„æ–¹å·®ä¼šè¿…é€Ÿå¢åŠ ï¼Œå¦‚å›¾8.24ï¼ˆbï¼‰[454]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.92)[489] and Equation (8.93)[489] each list a filter weight matrix and the feature map generated by using a set of neurons to process our example input in Equation (8.84)[478] after the input has had padding applied and using a stride length of 1.",
            "zh": "ç­‰å¼ï¼ˆ8.92ï¼‰[489]å’Œç­‰å¼ï¼ˆ8.93ï¼‰[489]åˆ†åˆ«åˆ—å‡ºäº†ä¸€ä¸ªæ»¤æ³¢å™¨æƒé‡çŸ©é˜µå’Œç‰¹å¾å›¾ï¼Œè¯¥çŸ©é˜µæ˜¯ä½¿ç”¨ä¸€ç»„ç¥ç»å…ƒåœ¨åº”ç”¨å¡«å……å¹¶ä½¿ç”¨æ­¥å¹…é•¿åº¦1åå¤„ç†ç­‰å¼ï¼ˆ8.84ï¼‰[478]ä¸­çš„ç¤ºä¾‹è¾“å…¥è€Œç”Ÿæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 11.4[665] shows the same portion of the action-value table shown in Table 11.3[661] after the final episode has completed.",
            "zh": "è¡¨11.4[665]æ˜¾ç¤ºäº†æœ€åä¸€é›†ç»“æŸåè¡¨11.3[661]ä¸­æ˜¾ç¤ºçš„åŠ¨ä½œå€¼è¡¨çš„ç›¸åŒéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dot product of F and G, written F Â·G (and thus named) is equivalent to the matrix product FGâŠº",
            "zh": "F å’Œ G çš„ç‚¹ç§¯ï¼Œå†™æˆ F Â·Gï¼ˆå› æ­¤å¾—åï¼‰ç­‰ä»·äºçŸ©é˜µç§¯ FGâŠº"
        }
    },
    {
        "translation": {
            "en": "CASE STUDIES AND CONCLUSIONS",
            "zh": "æ¡ˆä¾‹ç ”ç©¶å’Œç»“è®º"
        }
    },
    {
        "translation": {
            "en": "This was confirmed with the business in this case, and this value was treated as an invalid outlier and replaced with a missing value.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸šåŠ¡éƒ¨é—¨ç¡®è®¤äº†è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”æ­¤å€¼è¢«è§†ä¸ºæ— æ•ˆçš„å¼‚å¸¸å€¼ï¼Œå¹¶æ›¿æ¢ä¸ºç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using satellite photos of their competitorâ€™s premises, the retailer was able to count the number of cars in the competitorâ€™s parking lots and use this as a proxy measure of activity within the competitorâ€™s stores!",
            "zh": "åˆ©ç”¨ç«äº‰å¯¹æ‰‹åœºæ‰€çš„å«æ˜Ÿç…§ç‰‡ï¼Œé›¶å”®å•†èƒ½å¤Ÿè®¡ç®—ç«äº‰å¯¹æ‰‹åœè½¦åœºçš„æ±½è½¦æ•°é‡ï¼Œå¹¶å°†å…¶ç”¨ä½œç«äº‰å¯¹æ‰‹å•†åº—å†…æ´»åŠ¨çš„ä»£ç†æŒ‡æ ‡ï¼"
        }
    },
    {
        "translation": {
            "en": "One consequence of this observation is that naive Bayes models are not really suitable for predicting continuous targets.",
            "zh": "è¿™ä¸€è§‚å¯Ÿç»“æœçš„ä¸€ä¸ªç»“æœæ˜¯ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹å¹¶ä¸çœŸæ­£é€‚åˆé¢„æµ‹è¿ç»­ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the AT team felt that a customer beginning to frequently call other networks would be a good indicator of churn, but a suitable data feature could not be extracted to capture this.",
            "zh": "ä¾‹å¦‚ï¼ŒAT å›¢é˜Ÿè®¤ä¸ºï¼Œå®¢æˆ·å¼€å§‹é¢‘ç¹å‘¼å«å…¶ä»–ç½‘ç»œå°†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å®¢æˆ·æµå¤±æŒ‡æ ‡ï¼Œä½†æ— æ³•æå–åˆé€‚çš„æ•°æ®ç‰¹å¾æ¥æ•è·è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The purpose of the second part of the evaluation was to encourage confidence in the models that Jocelyn had built among the SDSS scientists.",
            "zh": "è¯„ä¼°çš„ç¬¬äºŒéƒ¨åˆ†çš„ç›®çš„æ˜¯é¼“åŠ±å¯¹ SDSS ç§‘å­¦å®¶å»ºç«‹çš„ Jocelyn æ¨¡å‹çš„ä¿¡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.12",
            "zh": "å›¾ 10.12"
        }
    },
    {
        "translation": {
            "en": "The fact that active customers were defined as current customers means that they were all active on the same dateâ€”namely, whatever day the ABT was generated.",
            "zh": "æ´»è·ƒå®¢æˆ·è¢«å®šä¹‰ä¸ºå½“å‰å®¢æˆ·è¿™ä¸€äº‹å®æ„å‘³ç€ä»–ä»¬éƒ½åœ¨åŒä¸€å¤©å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œå³ç”Ÿæˆ ABT çš„ä»»ä½•ä¸€å¤©ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the discussion in this section, however, we assume that biases are initialized to 0.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºæœ¬èŠ‚çš„è®¨è®ºï¼Œæˆ‘ä»¬å‡è®¾åå·®åˆå§‹åŒ–ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10 shows how the representational capacity of a neural network increases as more layers are added to the network.",
            "zh": "å›¾ 8.10 æ˜¾ç¤ºäº†ç¥ç»ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›å¦‚ä½•éšç€æ›´å¤šå±‚æ·»åŠ åˆ°ç½‘ç»œä¸­è€Œå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The squares overlaying connections coming out of a neuron illustrate the regions of the input space that the neurons activate on: neurons output high activations in response to inputs patterns from the white region in the corresponding square, and low (or no activations) in response to input patterns from the gray regions in the corresponding square.",
            "zh": "è¦†ç›–æ¥è‡ªç¥ç»å…ƒçš„è¿æ¥çš„æ–¹å—è¯´æ˜äº†ç¥ç»å…ƒæ¿€æ´»çš„è¾“å…¥ç©ºé—´åŒºåŸŸï¼šç¥ç»å…ƒå“åº”æ¥è‡ªç›¸åº”æ–¹å—ä¸­ç™½è‰²åŒºåŸŸçš„è¾“å…¥æ¨¡å¼è¾“å‡ºé«˜æ¿€æ´»ï¼Œè€Œå“åº”æ¥è‡ªç›¸åº”æ–¹å—ä¸­ç°è‰²åŒºåŸŸçš„è¾“å…¥æ¨¡å¼çš„ä½æ¿€æ´»ï¼ˆæˆ–æ— æ¿€æ´»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Pareto charts, 752",
            "zh": "å¸•ç´¯æ‰˜å›¾ï¼Œ752"
        }
    },
    {
        "translation": {
            "en": "Taking advantage of this information, the randomly selected weights are adjusted slightly in the direction of the error surface gradient to move to a new position on the error surface.",
            "zh": "åˆ©ç”¨æ­¤ä¿¡æ¯ï¼Œéšæœºé€‰æ‹©çš„æƒé‡åœ¨è¯¯å·®è¡¨é¢æ¢¯åº¦æ–¹å‘ä¸Šç•¥å¾®è°ƒæ•´ï¼Œä»¥ç§»åŠ¨åˆ°è¯¯å·®è¡¨é¢ä¸Šçš„æ–°ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that we can define an infinite number of distance metrics is not merely an academic curiosity.",
            "zh": "äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰æ— é™æ•°é‡çš„è·ç¦»æŒ‡æ ‡ï¼Œè¿™ä¸ä»…ä»…æ˜¯ä¸€ç§å­¦æœ¯ä¸Šçš„å¥½å¥‡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "stratification feature, 93",
            "zh": "åˆ†å±‚ç‰¹å¾ï¼Œ93"
        }
    },
    {
        "translation": {
            "en": "Figure 5.20[230] illustrates how filter selection fits into the model induction process. It is important to remember that feature selection can be used in conjunction with almost any machine learning algorithm, not just similarity-based approaches. Feature selection is appropriate when there are large numbers of features, so we do not present a worked example here. We do, however, discuss the application of feature selection in the case study in Chapter 13[703].",
            "zh": "å›¾ 5.20[230] è¯´æ˜äº†æ»¤æ³¢å™¨é€‰æ‹©å¦‚ä½•é€‚åº”æ¨¡å‹å½’çº³è¿‡ç¨‹ã€‚é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œç‰¹å¾é€‰æ‹©å¯ä»¥ä¸å‡ ä¹ä»»ä½•æœºå™¨å­¦ä¹ ç®—æ³•ç»“åˆä½¿ç”¨ï¼Œè€Œä¸ä»…ä»…æ˜¯åŸºäºç›¸ä¼¼æ€§çš„æ–¹æ³•ã€‚å½“æœ‰å¤§é‡ç‰¹å¾æ—¶ï¼Œç‰¹å¾é€‰æ‹©æ˜¯åˆé€‚çš„ï¼Œå› æ­¤æˆ‘ä»¬åœ¨è¿™é‡Œä¸æä¾›å·¥ä½œç¤ºä¾‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ç¡®å®åœ¨ç¬¬13ç« [703]çš„æ¡ˆä¾‹ç ”ç©¶ä¸­è®¨è®ºäº†ç‰¹å¾é€‰æ‹©çš„åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics moving from data to insight to decision.",
            "zh": "é¢„æµ‹æ€§æ•°æ®åˆ†æä»æ•°æ®åˆ°æ´å¯Ÿå†åˆ°å†³ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these saturated regions the derivative of the logistic function is approximately 0.",
            "zh": "åœ¨è¿™äº›é¥±å’ŒåŒºåŸŸä¸­ï¼Œé€»è¾‘å‡½æ•°çš„å¯¼æ•°çº¦ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Have begun the feature selection exercise by removing some features from the ABT.",
            "zh": "2. é€šè¿‡ä» ABT ä¸­åˆ é™¤ä¸€äº›åŠŸèƒ½æ¥å¼€å§‹åŠŸèƒ½é€‰æ‹©ç»ƒä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is often known as pre-pruning.",
            "zh": "è¿™é€šå¸¸ç§°ä¸ºé¢„ä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "In convolutional neural networks, sub-sampling is done using sub-sampling layers.",
            "zh": "åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œå­é‡‡æ ·æ˜¯ä½¿ç”¨å­é‡‡æ ·å±‚å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The multinomial logistic regression18 model is an extension that handles categorical target features with more than two levels.",
            "zh": "å¤šé¡¹å¼é€»è¾‘å›å½’18 æ¨¡å‹æ˜¯ä¸€ä¸ªæ‰©å±•ï¼Œç”¨äºå¤„ç†å…·æœ‰ä¸¤ä¸ªä»¥ä¸Šçº§åˆ«çš„åˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, recurrent neural networks are designed to process sequential data that may have long distances between dependent features in the input sequence.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œé€’å½’ç¥ç»ç½‘ç»œæ—¨åœ¨å¤„ç†åºåˆ—ä¸­ç›¸å…³ç‰¹å¾ä¹‹é—´å¯èƒ½å…·æœ‰è¾ƒé•¿è·ç¦»çš„é¡ºåºæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This gives us a way to choose between a set of different decision trees that are all consistent with a set of training instances.",
            "zh": "è¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§åœ¨ä¸€ç»„ä¸åŒçš„å†³ç­–æ ‘ä¹‹é—´è¿›è¡Œé€‰æ‹©çš„æ–¹æ³•ï¼Œè¿™äº›å†³ç­–æ ‘éƒ½ä¸ä¸€ç»„è®­ç»ƒå®ä¾‹ä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "z-transform, 87",
            "zh": "z å˜æ¢ï¼Œ87"
        }
    },
    {
        "translation": {
            "en": "(a) Frames from an episode early in the training process in which the agent performs poorly. (b) Frames from an episode near the end of the learning process where the agent is starting to be very effective. (c) Changing episode returns during DQN training. The gray line shows a 50-episode moving average to better highlight the trend.",
            "zh": "ï¼ˆaï¼‰ åœ¨è®­ç»ƒè¿‡ç¨‹æ—©æœŸï¼Œä»£ç†è¡¨ç°ä¸ä½³çš„æƒ…èŠ‚ã€‚ï¼ˆbï¼‰ åœ¨å­¦ä¹ è¿‡ç¨‹æ¥è¿‘å°¾å£°æ—¶ï¼Œæ™ºèƒ½ä½“å¼€å§‹å˜å¾—éå¸¸æœ‰æ•ˆçš„ä¸€é›†çš„å¸§ã€‚ï¼ˆcï¼‰ åœ¨ DQN è®­ç»ƒæœŸé—´æ›´æ”¹å‰§é›†è¿”å›ã€‚ç°çº¿æ˜¾ç¤º 50 é›†çš„ç§»åŠ¨å¹³å‡çº¿ï¼Œä»¥æ›´å¥½åœ°çªå‡ºè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. There are many applications of predictive analytics in healthcare, and predicting readmittance rates for diabetes patients, as well as patients suffering from other issues, is well studied, for example, by Rubin (2015) and Kansagara et al. (2011).",
            "zh": "12. é¢„æµ‹åˆ†æåœ¨åŒ»ç–—ä¿å¥ä¸­æœ‰è®¸å¤šåº”ç”¨ï¼Œä¾‹å¦‚ï¼ŒRubin ï¼ˆ2015ï¼‰ å’Œ Kansagara ç­‰äºº ï¼ˆ2011ï¼‰ å¯¹é¢„æµ‹ç³–å°¿ç—…æ‚£è€…ä»¥åŠæ‚£æœ‰å…¶ä»–é—®é¢˜çš„æ‚£è€…çš„å†å…¥é™¢ç‡è¿›è¡Œäº†å……åˆ†ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we might sample the weights from a normal distribution with mean Î¼ = 0.0 and Ïƒ = 0.01.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä»å‡å€¼ Î¼ = 0.0 ä¸” Ïƒ = 0.01 çš„æ­£æ€åˆ†å¸ƒä¸­å¯¹æƒé‡è¿›è¡Œé‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that we need to be able to bin the features of any query instances appropriately before we make predictions for them.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œåœ¨å¯¹ä»»ä½•æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿé€‚å½“åœ°å¯¹å®ƒä»¬çš„åŠŸèƒ½è¿›è¡Œåˆ†ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, this dataset is not based on precise measurements of stroke risk.",
            "zh": "æ­¤å¤–ï¼Œè¯¥æ•°æ®é›†å¹¶éåŸºäºå¯¹ä¸­é£é£é™©çš„ç²¾ç¡®æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In our example, the target feature, FRAUD, is binary, so we need to define two conditional probabilities for each value in the domain of the new descriptive feature: P(AB = x | fr) and P(AB = x | Â¬fr).",
            "zh": "åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œç›®æ ‡ç‰¹å¾ FRAUD æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¸ºæ–°æè¿°æ€§ç‰¹å¾åŸŸä¸­çš„æ¯ä¸ªå€¼å®šä¹‰ä¸¤ä¸ªæ¡ä»¶æ¦‚ç‡ï¼šPï¼ˆAB = x | frï¼‰ å’Œ Pï¼ˆAB = x | Â¬frï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is known as the No Free Lunch Theorem (Wolpert, 1996).",
            "zh": "è¿™è¢«ç§°ä¸ºâ€œæ²¡æœ‰å…è´¹çš„åˆé¤å®šç†â€ï¼ˆWolpertï¼Œ1996ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "interval size, 276",
            "zh": "é—´éš”å¤§å°ï¼Œ276"
        }
    },
    {
        "translation": {
            "en": "4.11â€…â€…â€…A dataset listing the number of bike rentals per day.",
            "zh": "4.11 åˆ—å‡ºæ¯å¤©è‡ªè¡Œè½¦ç§Ÿèµæ¬¡æ•°çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "temporal-difference learning, 637, 638, 654, 654, 676",
            "zh": "æ—¶å·®å­¦ä¹ ï¼Œ 637ï¼Œ 638ï¼Œ 654ï¼Œ 654ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "An illustration of three different one-versus-all prediction models for the customer type dataset in Table 7.11[359], with three target levels: (a) single (squares), (b) business (triangles), and (c) family (crosses).",
            "zh": "è¡¨ 7.11[359] ä¸­å®¢æˆ·ç±»å‹æ•°æ®é›†çš„ä¸‰ç§ä¸åŒçš„ä¸€å¯¹ä¸€é¢„æµ‹æ¨¡å‹çš„å›¾ç¤ºï¼Œå…·æœ‰ä¸‰ä¸ªç›®æ ‡çº§åˆ«ï¼šï¼ˆaï¼‰ å•ï¼ˆæ­£æ–¹å½¢ï¼‰ã€ï¼ˆbï¼‰ ä¸šåŠ¡ï¼ˆä¸‰è§’å½¢ï¼‰å’Œ ï¼ˆcï¼‰ ç³»åˆ—ï¼ˆäº¤å‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gini coefficient, 294, 563, 586, 590",
            "zh": "åŸºå°¼ç³»æ•°ï¼Œ294,563,586,590"
        }
    },
    {
        "translation": {
            "en": "Hence for a PReLU i, the activation function is defined as",
            "zh": "å› æ­¤ï¼Œå¯¹äº PReLU iï¼Œæ¿€æ´»å‡½æ•°å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "BienaymÃ© formula, 455",
            "zh": "BienaymÃ© å…¬å¼ï¼Œ455"
        }
    },
    {
        "translation": {
            "en": "CLASS",
            "zh": "ç±»"
        }
    },
    {
        "translation": {
            "en": "An effective way in which to do this is to start by defining a set of domain concepts in collaboration with the business, and then designing features that express these concepts in order to form the actual ABT.",
            "zh": "è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œä¸€ä¸ªæœ‰æ•ˆçš„æ–¹æ³•æ˜¯é¦–å…ˆä¸ä¸šåŠ¡éƒ¨é—¨åˆä½œå®šä¹‰ä¸€ç»„é¢†åŸŸæ¦‚å¿µï¼Œç„¶åè®¾è®¡è¡¨è¾¾è¿™äº›æ¦‚å¿µçš„åŠŸèƒ½ï¼Œä»¥å½¢æˆå®é™…çš„ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.88)[482] shows some other sets of weights that our example neurons could use.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.88ï¼‰[482]æ˜¾ç¤ºäº†æˆ‘ä»¬çš„ç¤ºä¾‹ç¥ç»å…ƒå¯ä»¥ä½¿ç”¨çš„å…¶ä»–ä¸€äº›æƒé‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the relative ranking of the likelihood of the target levels are, to a certain extent, robust to errors in the calculation of the exact probabilities.13",
            "zh": "å› æ­¤ï¼Œç›®æ ‡æ°´å¹³å¯èƒ½æ€§çš„ç›¸å¯¹æ’åºåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯¹ç²¾ç¡®æ¦‚ç‡è®¡ç®—ä¸­çš„è¯¯å·®å…·æœ‰é²æ£’æ€§13ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons in this network use a logistic activation function, what would be the output of Neuron 5 if the network received the input vector: Neuron 1 = 0.7 and Neuron 2 = 0.3?",
            "zh": "ï¼ˆaï¼‰ å‡è®¾è¯¥ç½‘ç»œä¸­çš„å¤„ç†ç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœç½‘ç»œæ¥æ”¶åˆ°è¾“å…¥å‘é‡ï¼šç¥ç»å…ƒ 1 = 0.7 å’Œç¥ç»å…ƒ 2 = 0.3ï¼Œç¥ç»å…ƒ 5 çš„è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Table 9.1",
            "zh": "è¡¨ 9.1"
        }
    },
    {
        "translation": {
            "en": "presence-absence, 214",
            "zh": "å­˜åœ¨-ç¼ºå¸­ï¼Œ214"
        }
    },
    {
        "translation": {
            "en": "5.6â€…â€…â€…Further Reading",
            "zh": "5.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "B.1â€…â€…â€…Probability Basics",
            "zh": "B.1 æ¦‚ç‡åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "(a) Minimum, maximum, and range",
            "zh": "ï¼ˆaï¼‰ æœ€å°å€¼ã€æœ€å¤§å€¼å’ŒèŒƒå›´"
        }
    },
    {
        "translation": {
            "en": "In some cases we may wish to avoid this reduction in dimensionality between the input and the feature map.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›é¿å…è¾“å…¥å’Œç‰¹å¾å›¾ä¹‹é—´çš„è¿™ç§ç»´åº¦é™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This algorithm assumes an episodic scenario in which the agent will repeat multiple episodes of the task that is performing (for example, multiple iterations of a game or attempts to navigate an environment).",
            "zh": "æ­¤ç®—æ³•å‡å®šä¸€ä¸ªæƒ…èŠ‚åœºæ™¯ï¼Œåœ¨è¯¥åœºæ™¯ä¸­ï¼Œä»£ç†å°†é‡å¤æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡çš„å¤šä¸ªæƒ…èŠ‚ï¼ˆä¾‹å¦‚ï¼Œæ¸¸æˆçš„å¤šæ¬¡è¿­ä»£æˆ–å°è¯•å¯¼èˆªç¯å¢ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem of gradients becoming too large is known as exploding gradients.",
            "zh": "æ¢¯åº¦å˜å¾—å¤ªå¤§çš„é—®é¢˜ç§°ä¸ºæ¢¯åº¦çˆ†ç‚¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.29)[416] and Equation (8.30)[416] work for mini-batch training in much the same way as they do for batch training; the only difference is that the summation in Equation (8.29)[416] is over the examples in the mini-batch rather than the entire dataset.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.29ï¼‰[416]å’Œæ–¹ç¨‹ï¼ˆ8.30ï¼‰[416]åœ¨å°æ‰¹é‡è®­ç»ƒä¸­çš„ä½œç”¨ä¸åœ¨æ‰¹å¤„ç†è®­ç»ƒä¸­çš„ä½œç”¨å¤§è‡´ç›¸åŒ;å”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œç­‰å¼ï¼ˆ8.29ï¼‰[416]ä¸­çš„æ€»å’Œæ˜¯å°æ‰¹é‡ä¸­çš„ç¤ºä¾‹ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The downside, however, is that such measures do not directly measure the performance of the model, and consequently, a high stability index may reflect a change in the underlying population rather than a change in model performance.",
            "zh": "ç„¶è€Œï¼Œç¼ºç‚¹æ˜¯è¿™äº›æªæ–½ä¸èƒ½ç›´æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œå› æ­¤ï¼Œé«˜ç¨³å®šæ€§æŒ‡æ•°å¯èƒ½åæ˜ äº†åŸºç¡€ç¾¤ä½“çš„å˜åŒ–ï¼Œè€Œä¸æ˜¯æ¨¡å‹æ€§èƒ½çš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "In all three cases the question we would like to answer is, are instance B, located at at (30,70), and instance C, located at (70,70), likely to be from the same population from which the dataset has been sampled?",
            "zh": "åœ¨è¿™ä¸‰ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³è¦å›ç­”çš„é—®é¢˜æ˜¯ï¼Œä½äº ï¼ˆ30,70ï¼‰ çš„å®ä¾‹ B å’Œä½äº ï¼ˆ70,70ï¼‰ çš„å®ä¾‹ C æ˜¯å¦å¯èƒ½æ¥è‡ªä»ä¸­æŠ½å–æ•°æ®é›†çš„åŒä¸€æ€»ä½“ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Then the results of these three calculations are summed together along with the bias, to generate a single scalar value that is pushed through the activation function and then stored in the feature map.44 Equation (8.99)[493] lists a 2-by-2-by-3 filter that has been annotated to indicate which parts of the filter are applied to which channel",
            "zh": "ç„¶åï¼Œå°†è¿™ä¸‰ä¸ªè®¡ç®—çš„ç»“æœä¸åå·®ç›¸åŠ ï¼Œç”Ÿæˆä¸€ä¸ªå•ä¸ªæ ‡é‡å€¼ï¼Œè¯¥æ ‡é‡å€¼é€šè¿‡æ¿€æ´»å‡½æ•°æ¨é€ï¼Œç„¶åå­˜å‚¨åœ¨ç‰¹å¾å›¾ä¸­.44 å…¬å¼ï¼ˆ8.99ï¼‰[493]åˆ—å‡ºäº†ä¸€ä¸ª2Ã—2Ã—3æ»¤æ³¢å™¨ï¼Œè¯¥æ»¤æ³¢å™¨å·²è¢«æ³¨é‡Šä»¥æŒ‡ç¤ºæ»¤æ³¢å™¨çš„å“ªäº›éƒ¨åˆ†åº”ç”¨äºå“ªä¸ªé€šé“"
        }
    },
    {
        "translation": {
            "en": "The optimal values for the weights are the ones that allow the model to best capture the relationship between the descriptive features and a target feature.",
            "zh": "æƒé‡çš„æœ€ä½³å€¼æ˜¯å…è®¸æ¨¡å‹æœ€å¥½åœ°æ•è·æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we discuss common and useful extensions to the basic multivariable linear regression with gradient descent approach described in Section 7.3[319].",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºç¬¬ 7.3 èŠ‚[319] ä¸­æè¿°çš„å…·æœ‰æ¢¯åº¦ä¸‹é™æ–¹æ³•çš„åŸºæœ¬å¤šå˜é‡çº¿æ€§å›å½’çš„å¸¸è§ä¸”æœ‰ç”¨çš„æ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The year is 1798, and you are Lieutenant-Colonel David Collins of HMS Calcutta exploring the region around Hawkesbury River, in New South Wales.",
            "zh": "è¿™ä¸€å¹´æ˜¯ 1798 å¹´ï¼Œä½ æ˜¯ HMS åŠ å°”å„ç­”çš„å¤§å«æŸ¯æ—æ–¯ä¸­æ ¡ï¼Œæ­£åœ¨æ¢ç´¢æ–°å—å¨å°”å£«å·éœå…‹æ–¯ä¼¯é‡Œæ²³å‘¨å›´çš„åœ°åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "The probabilities needed by a naive Bayes prediction model, calculated from the data in Table 6.2[263].",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.2[263]ä¸­çš„æ•°æ®è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset.",
            "zh": "åœ¨æ²¡æœ‰ç›®æ ‡ç‰¹å¾çš„æƒ…å†µä¸‹ä½¿ç”¨æ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¹¶å¯¹æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¸­çš„åº•å±‚ç»“æ„è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The technical term for this splitting of the data into smaller and smaller sets based on larger and larger sets of conditions is data fragmentation.",
            "zh": "æ ¹æ®è¶Šæ¥è¶Šå¤§çš„æ¡ä»¶é›†å°†æ•°æ®æ‹†åˆ†ä¸ºè¶Šæ¥è¶Šå°çš„é›†åˆçš„æŠ€æœ¯æœ¯è¯­æ˜¯æ•°æ®ç¢ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two tools that can be useful for this are the covariance matrix and the correlation matrix.",
            "zh": "ä¸ºæ­¤ï¼Œæœ‰ä¸¤ä¸ªå·¥å…·æ˜¯åæ–¹å·®çŸ©é˜µå’Œç›¸å…³çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4",
            "zh": "å›¾ 1.4"
        }
    },
    {
        "translation": {
            "en": "Figure 4.16",
            "zh": "å›¾ 4.16"
        }
    },
    {
        "translation": {
            "en": "Essentially, here we are using Bayesâ€™ Theorem to invert the dependencies between the nodes.",
            "zh": "ä»æœ¬è´¨ä¸Šè®²ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è´å¶æ–¯å®šç†æ¥åè½¬èŠ‚ç‚¹ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that we have a range of parameterized distributions to choose from means that in order to define a probability density function (PDF), we must",
            "zh": "äº‹å®ä¸Šï¼Œæˆ‘ä»¬æœ‰ä¸€ç³»åˆ—å‚æ•°åŒ–åˆ†å¸ƒå¯ä¾›é€‰æ‹©ï¼Œè¿™æ„å‘³ç€ä¸ºäº†å®šä¹‰æ¦‚ç‡å¯†åº¦å‡½æ•° ï¼ˆPDFï¼‰ï¼Œæˆ‘ä»¬å¿…é¡»"
        }
    },
    {
        "translation": {
            "en": "Inverse probability reasons from effects to causes: if we know that a particular event has occurred, then we can increase the probability that one or more of the events that could cause the observed event have also happened.",
            "zh": "ä»ç»“æœåˆ°åŸå› çš„åæ¦‚ç‡åŸå› ï¼šå¦‚æœæˆ‘ä»¬çŸ¥é“æŸä¸ªç‰¹å®šäº‹ä»¶å·²ç»å‘ç”Ÿï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å¢åŠ å¯èƒ½å¯¼è‡´è§‚å¯Ÿåˆ°çš„äº‹ä»¶çš„ä¸€ä¸ªæˆ–å¤šä¸ªäº‹ä»¶ä¹Ÿå‘ç”Ÿçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "These features contained no actual information, so should be removed from the dataset.",
            "zh": "è¿™äº›è¦ç´ ä¸åŒ…å«ä»»ä½•å®é™…ä¿¡æ¯ï¼Œå› æ­¤åº”ä»æ•°æ®é›†ä¸­åˆ é™¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder model is a special type of feedforward neural network that is trained to reproduce its inputs at its output layer.",
            "zh": "è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œç»è¿‡è®­ç»ƒå¯ä»¥åœ¨å…¶è¾“å‡ºå±‚é‡ç°å…¶è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this, we first introduce the term Î”wi,k to denote the sum of the error gradients for the weight wi,k over one complete pass through all the examples in the training dataset.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥æœ¯è¯­ Î”wiï¼Œk æ¥è¡¨ç¤ºæƒé‡ wiï¼Œk åœ¨è®­ç»ƒæ•°æ®é›†ä¸­æ‰€æœ‰ç¤ºä¾‹ä¸­ä¸€æ¬¡å®Œæ•´ä¼ é€’ä¸­çš„è¯¯å·®æ¢¯åº¦ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„é¢†åŸŸæ¦‚å¿µå’Œç›¸å…³åŠŸèƒ½çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Michie, D. 1961. Trial and error. In Science survey, part 2, eds. S. A. Barnett and A. McLaren, 129â€“145. Penguin.",
            "zh": "ç±³å¥‡ï¼ŒD. 1961 å¹´ã€‚åå¤è¯•éªŒã€‚åœ¨ç§‘å­¦è°ƒæŸ¥ä¸­ï¼Œç¬¬ 2 éƒ¨åˆ†ï¼Œç¼–è¾‘ SA Barnett å’Œ A. McLarenï¼Œ129-145ã€‚ä¼é¹…ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. This is known as the No Free Lunch Theorem (Wolpert, 1996).",
            "zh": "10. è¿™è¢«ç§°ä¸ºâ€œæ²¡æœ‰å…è´¹çš„åˆé¤â€å®šç†ï¼ˆWolpertï¼Œ1996ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examples of using small multiple bar plot visualizations to illustrate the relationship between two categorical features: (a) the CAREER STAGE and SHOE SPONSOR features; and (b) the POSITION and SHOE SPONSOR features. All data comes from Table 3.7[73].",
            "zh": "ä½¿ç”¨å°çš„å¤šæ¡å½¢å›¾å¯è§†åŒ–æ¥è¯´æ˜ä¸¤ä¸ªåˆ†ç±»ç‰¹å¾ä¹‹é—´çš„å…³ç³»çš„ç¤ºä¾‹ï¼šï¼ˆaï¼‰ CAREER STAGE å’Œ SHOE SPONSOR ç‰¹å¾;ä»¥åŠ ï¼ˆbï¼‰ POSITION å’Œ SHOE SPONSOR åŠŸèƒ½ã€‚æ‰€æœ‰æ•°æ®å‡æ¥è‡ªè¡¨3.7[73]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Since the first edition of this book was released in 2015, things have been moving very fast in the world of machine learning.",
            "zh": "è‡ª 2015 å¹´æœ¬ä¹¦ç¬¬ä¸€ç‰ˆå‘å¸ƒä»¥æ¥ï¼Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„å‘å±•éå¸¸è¿…é€Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "price prediction, 3",
            "zh": "ä»·æ ¼é¢„æµ‹ï¼Œ3"
        }
    },
    {
        "translation": {
            "en": "When we normalize the features in a dataset, we control for the variation across the variances of features and ensure that each feature can contribute equally to the distance metric.",
            "zh": "å½“æˆ‘ä»¬å¯¹æ•°æ®é›†ä¸­çš„è¦ç´ è¿›è¡Œå½’ä¸€åŒ–æ—¶ï¼Œæˆ‘ä»¬ä¼šæ§åˆ¶è¦ç´ æ–¹å·®çš„å˜åŒ–ï¼Œå¹¶ç¡®ä¿æ¯ä¸ªè¦ç´ å¯¹è·ç¦»æŒ‡æ ‡çš„è´¡çŒ®ç›¸ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.4[426] shows the calculation of the per example error for the four examples and the sum of squared errors for the model.",
            "zh": "è¡¨ 8.4[426] æ˜¾ç¤ºäº†å››ä¸ªç¤ºä¾‹çš„æ¯ä¸ªç¤ºä¾‹è¯¯å·®çš„è®¡ç®—ç»“æœä»¥åŠæ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the instances in the dataset are sorted according to the values of the continuous feature.",
            "zh": "é¦–å…ˆï¼Œæ ¹æ®è¿ç»­ç‰¹å¾çš„å€¼å¯¹æ•°æ®é›†ä¸­çš„å®ä¾‹è¿›è¡Œæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "The process is then repeated for each branch using the relevant partition of the training set in place of the full training set and with the selected test feature excluded from further testing.",
            "zh": "ç„¶åï¼Œä½¿ç”¨è®­ç»ƒé›†çš„ç›¸å…³åˆ†åŒºä»£æ›¿å®Œæ•´çš„è®­ç»ƒé›†ï¼Œå¹¶å°†æ‰€é€‰æµ‹è¯•ç‰¹å¾æ’é™¤åœ¨è¿›ä¸€æ­¥æµ‹è¯•ä¹‹å¤–ï¼Œå¯¹æ¯ä¸ªåˆ†æ”¯é‡å¤è¯¥è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.3",
            "zh": "å›¾ 10.3"
        }
    },
    {
        "translation": {
            "en": "(c) If you used a 4-NN model, what class would be assigned to the mystery animal? Would this be a good value for k for this dataset?",
            "zh": "ï¼ˆcï¼‰å¦‚æœä½ ä½¿ç”¨4-NNæ¨¡å‹ï¼Œç¥ç§˜åŠ¨ç‰©ä¼šè¢«åˆ†é…åˆ°ä»€ä¹ˆç±»åˆ«ï¼Ÿå¯¹äºè¿™ä¸ªæ•°æ®é›†æ¥è¯´ï¼Œè¿™å¯¹ k æ¥è¯´æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å€¼å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The standard range for the exponential distribution is from zero upward (i.e., the density assigned to values less than zero is zero).",
            "zh": "æŒ‡æ•°åˆ†å¸ƒçš„æ ‡å‡†èŒƒå›´æ˜¯ä»é›¶å¼€å§‹ï¼ˆå³ï¼Œåˆ†é…ç»™å°äºé›¶çš„å€¼çš„å¯†åº¦ä¸ºé›¶ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A flag is also included to indicate that the claimant has had at least one claim refused in the past, because this might be indicative of a pattern of making speculative claims.",
            "zh": "è¿˜åŒ…æ‹¬ä¸€ä¸ªæ ‡å¿—ï¼Œè¡¨æ˜ç´¢èµ”äººè¿‡å»è‡³å°‘æœ‰ä¸€é¡¹ç´¢èµ”è¢«æ‹’ç»ï¼Œå› ä¸ºè¿™å¯èƒ½è¡¨æ˜æå‡ºæŠ•æœºæ€§ç´¢èµ”çš„æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "on-policy reinforcement learning, 664, 676",
            "zh": "æ”¿ç­–å¼ºåŒ–å­¦ä¹ ï¼Œ664,676"
        }
    },
    {
        "translation": {
            "en": "Bâ€…â€…â€…Introduction to Probability for Machine Learning",
            "zh": "B æœºå™¨å­¦ä¹ æ¦‚ç‡è®º"
        }
    },
    {
        "translation": {
            "en": "The second-to-last layer is a dense fully connected layer (i.e., each neuron in this layer receives the complete feature maps generated by Filters 3 and 4 as input) that feeds forward to the softmax output layer.",
            "zh": "å€’æ•°ç¬¬äºŒå±‚æ˜¯ä¸€ä¸ªå¯†é›†çš„å…¨è¿æ¥å±‚ï¼ˆå³ï¼Œè¯¥å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶ç”±è¿‡æ»¤å™¨ 3 å’Œ 4 ç”Ÿæˆçš„å®Œæ•´ç‰¹å¾å›¾ä½œä¸ºè¾“å…¥ï¼‰ï¼Œå®ƒè½¬å‘åˆ° softmax è¾“å‡ºå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Together this set of neurons could determine whether the visual feature occurred anywhere in the screen.",
            "zh": "è¿™ç»„ç¥ç»å…ƒä¸€èµ·å¯ä»¥ç¡®å®šè§†è§‰ç‰¹å¾æ˜¯å¦å‘ç”Ÿåœ¨å±å¹•çš„ä»»ä½•ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.16â€…â€…â€…The Î´s for each of the neurons in the network for Example 2.",
            "zh": "8.16 ç¤ºä¾‹ 2 ä¸­ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„ Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "All these examples have two things in common.",
            "zh": "æ‰€æœ‰è¿™äº›ä¾‹å­éƒ½æœ‰ä¸¤ä¸ªå…±åŒç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The learning rate, Î±, in the gradient descent algorithm determines the size of the adjustment made to each weight at each step in the process.",
            "zh": "æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­çš„å­¦ä¹ ç‡ Î± å†³å®šäº†åœ¨è¿‡ç¨‹ä¸­æ¯ä¸ªæ­¥éª¤å¯¹æ¯ä¸ªæƒé‡æ‰€åšçš„è°ƒæ•´å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the 1936 election Literary Digest ran one of the largest pre-election polls in the U.S. To run the poll Literary Digest created a list of 10 million names by integrating every telephone directory in the U.S., and a number of other sources, and then mailing everyone on the list a mock ballot and asking them to return the ballot to the magazine.",
            "zh": "åœ¨1936å¹´çš„é€‰ä¸¾ä¸­ï¼Œã€Šæ–‡å­¦æ–‡æ‘˜ã€‹è¿›è¡Œäº†ç¾å›½æœ€å¤§çš„é€‰ä¸¾å‰æ°‘æ„è°ƒæŸ¥ä¹‹ä¸€ã€‚ä¸ºäº†è¿›è¡Œæ°‘æ„è°ƒæŸ¥ï¼Œã€Šæ–‡å­¦æ–‡æ‘˜ã€‹é€šè¿‡æ•´åˆç¾å›½çš„æ‰€æœ‰ç”µè¯ç°¿å’Œè®¸å¤šå…¶ä»–æ¥æºï¼Œåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«1000ä¸‡ä¸ªåå­—çš„åå•ï¼Œç„¶åå‘åå•ä¸Šçš„æ¯ä¸ªäººé‚®å¯„ä¸€å¼ æ¨¡æ‹Ÿé€‰ç¥¨ï¼Œå¹¶è¦æ±‚ä»–ä»¬å°†é€‰ç¥¨é€€è¿˜ç»™æ‚å¿—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This could be handled reasonably easily using an imputation approach,6 but Ross held off on performing this at this stage.",
            "zh": "ä½¿ç”¨æ’è¡¥æ–¹æ³•å¯ä»¥ç›¸å½“å®¹æ˜“åœ°å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œ6 ä½† Ross åœ¨è¿™ä¸ªé˜¶æ®µæ¨è¿Ÿäº†æ‰§è¡Œæ­¤æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "7.11â€…â€…â€…A dataset of customers of a large national retail chain.",
            "zh": "7.11 ä¸€å®¶å¤§å‹å…¨å›½æ€§é›¶å”®è¿é”åº—çš„å®¢æˆ·æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Examine the descriptive features in the dataset and list the features that you would exclude before you would use the dataset to build a predictive model. For each feature you decide to exclude, explain why you have made this decision.",
            "zh": "ï¼ˆbï¼‰ æ£€æŸ¥æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾ï¼Œå¹¶åˆ—å‡ºåœ¨ä½¿ç”¨æ•°æ®é›†æ„å»ºé¢„æµ‹æ¨¡å‹ä¹‹å‰è¦æ’é™¤çš„ç‰¹å¾ã€‚å¯¹äºæ‚¨å†³å®šæ’é™¤çš„æ¯ä¸ªåŠŸèƒ½ï¼Œè¯·è§£é‡Šæ‚¨åšå‡ºæ­¤å†³å®šçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that at each decision node, the algorithm will select the feature that partitions the dataset to most reduce the weighted variance of the partitions.",
            "zh": "è¿™æ„å‘³ç€åœ¨æ¯ä¸ªå†³ç­–èŠ‚ç‚¹ä¸Šï¼Œç®—æ³•å°†é€‰æ‹©å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºçš„ç‰¹å¾ï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘åˆ†åŒºçš„åŠ æƒæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Gaeltacht towns people speak the native Irish language rather than English (spoken in the rest of the country).",
            "zh": "åœ¨ç›–å°”å¡”èµ«ç‰¹é•‡ï¼Œäººä»¬è¯´çš„æ˜¯çˆ±å°”å…°æœ¬åœŸè¯­è¨€ï¼Œè€Œä¸æ˜¯è‹±è¯­ï¼ˆåœ¨è¯¥å›½å…¶ä»–åœ°åŒºä½¿ç”¨ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "When a profit matrix is available, however, profit is a very effective performance measure to use.",
            "zh": "ç„¶è€Œï¼Œå½“åˆ©æ¶¦çŸ©é˜µå¯ç”¨æ—¶ï¼Œåˆ©æ¶¦æ˜¯ä¸€ç§éå¸¸æœ‰æ•ˆçš„ç»©æ•ˆè¡¡é‡æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.9â€…â€…â€…A dataset describing grass growth on Irish farms in July 2012.",
            "zh": "7.9 æè¿°2012å¹´7æœˆçˆ±å°”å…°å†œåœºè‰ç”Ÿé•¿æƒ…å†µçš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fourth part of the book covers the Deployment phases of CRISP-DM. Chapters 12[685] and 13[703] present case studies describing specific predictive analytics projects from Business Understanding up to Deployment. These case studies demonstrate how everything described in the preceding chapters comes together in a successful predictive data analytics project.",
            "zh": "æœ¬ä¹¦çš„ç¬¬å››éƒ¨åˆ†ä»‹ç»äº† CRISP-DM çš„éƒ¨ç½²é˜¶æ®µã€‚ç¬¬ 12 ç« [685] å’Œ 13[703] ä»‹ç»äº†ä»ä¸šåŠ¡ç†è§£åˆ°éƒ¨ç½²çš„ç‰¹å®šé¢„æµ‹åˆ†æé¡¹ç›®çš„æ¡ˆä¾‹ç ”ç©¶ã€‚è¿™äº›æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†å‰å‡ ç« ä¸­æè¿°çš„æ‰€æœ‰å†…å®¹å¦‚ä½•æ•´åˆåˆ°ä¸€ä¸ªæˆåŠŸçš„é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "A feature can take one or more values from a domain, and we can find out the likelihood of a feature taking any particular value using a probability function, P().",
            "zh": "ä¸€ä¸ªç‰¹å¾å¯ä»¥ä»åŸŸä¸­è·å–ä¸€ä¸ªæˆ–å¤šä¸ªå€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¦‚ç‡å‡½æ•° Pï¼ˆï¼‰ æ‰¾å‡ºç‰¹å¾è·å–ä»»ä½•ç‰¹å®šå€¼çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The joint probability distribution for the four binary features from Table B.2[760] (HEADACHE, FEVER, VOMITING, and MENINGITIS) would be written as",
            "zh": "è¡¨B.2[760]ï¼ˆå¤´ç—›ã€å‘çƒ§ã€å‘•åå’Œè„‘è†œç‚ï¼‰ä¸­å››ä¸ªäºŒå…ƒç‰¹å¾çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå°†å†™ä¸º"
        }
    },
    {
        "translation": {
            "en": "Leshno, Moshe, Vladimir Ya Lin, Allan Pinkus, and Shimon Schocken. 1993. Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks 6: 861â€“867.",
            "zh": "è±ä»€è¯ºã€æ‘©è¥¿ã€å¼—æ‹‰åŸºç±³å°”Â·äºšæ—ã€è‰¾ä¼¦Â·å¹³åº“æ–¯å’Œè¥¿è’™Â·è‚–è‚¯ã€‚1993. å…·æœ‰éå¤šé¡¹å¼æ¿€æ´»å‡½æ•°çš„å¤šå±‚å‰é¦ˆç½‘ç»œå¯ä»¥è¿‘ä¼¼ä»»ä½•å‡½æ•°.ç¥ç»ç½‘ç»œ 6ï¼š861â€“867ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.5",
            "zh": "è¡¨ 13.5"
        }
    },
    {
        "translation": {
            "en": "Adding extra descriptive features that give a more complete picture of a domain concept can lead to better predictive models.",
            "zh": "æ·»åŠ é¢å¤–çš„æè¿°æ€§ç‰¹å¾ï¼Œä½¿é¢†åŸŸæ¦‚å¿µæ›´å…¨é¢åœ°äº†è§£ï¼Œå¯ä»¥äº§ç”Ÿæ›´å¥½çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first type of error gradient is the rate of change of the network error with respect to changes in the weighted sum calculation of a neuron.",
            "zh": "ç¬¬ä¸€ç§ç±»å‹çš„è¯¯å·®æ¢¯åº¦æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒåŠ æƒå’Œè®¡ç®—å˜åŒ–çš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main advantage of decision tree models is that they are interpretable.",
            "zh": "å†³ç­–æ ‘æ¨¡å‹çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å®ƒä»¬æ˜¯å¯è§£é‡Šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we have multiple target levels, the structure of the confusion matrix shown in Figure 9.2[538] no longer fits the data. Similarly, the notion of thinking about a positive level and a negative level doesnâ€™t apply any more. The confusion matrix can, however, be easily extended to handle multiple target levels by including a row and column for each one. Table 9.17[572] shows the structure of a confusion matrix for a multinomial prediction problem in which the target feature has l levels.",
            "zh": "å¦‚æœæˆ‘ä»¬æœ‰å¤šä¸ªç›®æ ‡æ°´å¹³ï¼Œåˆ™å›¾9.2[538]æ‰€ç¤ºçš„æ··æ·†çŸ©é˜µçš„ç»“æ„ä¸å†é€‚åˆæ•°æ®ã€‚åŒæ ·ï¼Œæ€è€ƒç§¯ææ°´å¹³å’Œæ¶ˆææ°´å¹³çš„æ¦‚å¿µä¸å†é€‚ç”¨ã€‚ä½†æ˜¯ï¼Œæ··æ·†çŸ©é˜µå¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰©å±•ä¸ºå¤„ç†å¤šä¸ªç›®æ ‡çº§åˆ«ï¼Œæ–¹æ³•æ˜¯ä¸ºæ¯ä¸ªç›®æ ‡çº§åˆ«åŒ…å«ä¸€è¡Œå’Œä¸€åˆ—ã€‚è¡¨ 9.17[572] æ˜¾ç¤ºäº†å¤šé¡¹å¼é¢„æµ‹é—®é¢˜çš„æ··æ·†çŸ©é˜µç»“æ„ï¼Œå…¶ä¸­ç›®æ ‡ç‰¹å¾å…·æœ‰ l çº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "When the car changes speed, the action has an immediate effect on the carâ€™s progress in the current time-step. If the car is stationary, taking the action to move left or right has no effect on the carâ€™s position. If the car is moving slowly, then moving left or right moves the car one cell in that direction at that time-step, but not any distance forward. If the car is moving fast, then moving left or right moves the car one cell in that direction at that time-step and one cell forward.",
            "zh": "å½“æ±½è½¦æ”¹å˜é€Ÿåº¦æ—¶ï¼Œè¯¥åŠ¨ä½œä¼šç«‹å³å½±å“æ±½è½¦åœ¨å½“å‰æ—¶é—´æ­¥é•¿ä¸­çš„è¿›åº¦ã€‚å¦‚æœæ±½è½¦é™æ­¢ä¸åŠ¨ï¼Œåˆ™å‘å·¦æˆ–å‘å³ç§»åŠ¨çš„åŠ¨ä½œå¯¹æ±½è½¦çš„ä½ç½®æ²¡æœ‰å½±å“ã€‚å¦‚æœæ±½è½¦ç§»åŠ¨ç¼“æ…¢ï¼Œåˆ™å‘å·¦æˆ–å‘å³ç§»åŠ¨ä¼šä½¿æ±½è½¦åœ¨è¯¥æ—¶é—´æ­¥é•¿ä¸Šæ²¿è¯¥æ–¹å‘ç§»åŠ¨ä¸€ä¸ªå•å…ƒæ ¼ï¼Œä½†ä¸ä¼šå‘å‰ç§»åŠ¨ä»»ä½•è·ç¦»ã€‚å¦‚æœæ±½è½¦ç§»åŠ¨å¾—å¾ˆå¿«ï¼Œé‚£ä¹ˆå‘å·¦æˆ–å‘å³ç§»åŠ¨ä¼šä½¿æ±½è½¦åœ¨è¯¥æ—¶é—´æ­¥é•¿ä¸Šå‘è¯¥æ–¹å‘ç§»åŠ¨ä¸€ä¸ªå•å…ƒæ ¼ï¼Œå¹¶åœ¨è¯¥æ—¶é—´æ­¥é•¿ä¸Šç§»åŠ¨ä¸€ä¸ªå•å…ƒæ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.3â€…â€…â€…Partial Derivatives",
            "zh": "C.3 åå¯¼æ•°"
        }
    },
    {
        "translation": {
            "en": "There are three descriptive features in the dataset. STREAM is a binary feature that describes whether or not there is a stream in the area. SLOPE describes the steepness of the terrain in an area and has the levels flat, moderate, and steep. ELEVATION describes the elevation of an area and has the levels low, medium, high, and highest.",
            "zh": "æ•°æ®é›†ä¸­æœ‰ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾ã€‚STREAM æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶è¦ç´ ï¼Œç”¨äºæè¿°è¯¥åŒºåŸŸä¸­æ˜¯å¦å­˜åœ¨æµã€‚SLOPE æè¿°äº†ä¸€ä¸ªåŒºåŸŸä¸­åœ°å½¢çš„é™¡å³­ç¨‹åº¦ï¼Œå¹¶å…·æœ‰å¹³å¦ã€ä¸­ç­‰å’Œé™¡å³­çš„çº§åˆ«ã€‚ELEVATION æè¿°åŒºåŸŸçš„é«˜ç¨‹ï¼Œå¹¶å…·æœ‰ä½ã€ä¸­ã€é«˜å’Œæœ€é«˜çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "APPENDICES",
            "zh": "é™„å½•"
        }
    },
    {
        "translation": {
            "en": "EEG, 353",
            "zh": "è„‘ç”µå›¾ï¼Œ353"
        }
    },
    {
        "translation": {
            "en": "0.57",
            "zh": "0.57"
        }
    },
    {
        "translation": {
            "en": "Lift captures this more formally.",
            "zh": "Lift æ›´æ­£å¼åœ°æ•æ‰åˆ°äº†è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.5â€…â€…â€…Summary",
            "zh": "5.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Data quality issues due to invalid data typically arise because of errors in the process used to generate an ABT, usually in relation to calculating derived features.",
            "zh": "ç”±äºæ— æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜é€šå¸¸æ˜¯ç”±äºç”¨äºç”Ÿæˆ ABT çš„è¿‡ç¨‹ä¸­çš„é”™è¯¯è€Œå¼•èµ·çš„ï¼Œé€šå¸¸ä¸è®¡ç®—æ´¾ç”Ÿç‰¹å¾æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal that the agent is being trained to achieve is to learn to drive as far as possible in the shortest amount of time possible without crashing. The car moves forward along an infinite highway, and an episode ends if the car crashes into a barrier or another car.",
            "zh": "æ™ºèƒ½ä½“æ­£åœ¨æ¥å—è®­ç»ƒä»¥å®ç°çš„ç›®æ ‡æ˜¯å­¦ä¼šåœ¨å°½å¯èƒ½çŸ­çš„æ—¶é—´å†…å°½å¯èƒ½è¿œåœ°é©¾é©¶è€Œä¸ä¼šæ’è½¦ã€‚æ±½è½¦æ²¿ç€æ— é™çš„é«˜é€Ÿå…¬è·¯å‘å‰è¡Œé©¶ï¼Œå¦‚æœæ±½è½¦æ’ä¸Šéšœç¢ç‰©æˆ–å¦ä¸€è¾†è½¦ï¼Œåˆ™ä¸€é›†ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, it is very important to perform a second evaluation in which the test data reflect the actual distribution of target feature values in the business scenario.",
            "zh": "å› æ­¤ï¼Œè¿›è¡Œç¬¬äºŒæ¬¡è¯„ä¼°éå¸¸é‡è¦ï¼Œå…¶ä¸­æµ‹è¯•æ•°æ®åæ˜ äº†ä¸šåŠ¡åœºæ™¯ä¸­ç›®æ ‡ç‰¹å¾å€¼çš„å®é™…åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.2[183] lists an example dataset containing two descriptive features, the SPEED and AGILITY ratings for college athletes (both measures out of 10), and one target feature that lists whether the athletes were drafted to a professional team.1 We can represent this dataset in a feature space by taking each of the descriptive features to be the axes of a coordinate system.",
            "zh": "è¡¨ 5.2[183] åˆ—å‡ºäº†ä¸€ä¸ªç¤ºä¾‹æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œå³å¤§å­¦è¿åŠ¨å‘˜çš„é€Ÿåº¦å’Œæ•æ·æ€§è¯„çº§ï¼ˆå‡ä¸º 10 åˆ†ï¼‰ï¼Œä»¥åŠä¸€ä¸ªåˆ—å‡ºè¿åŠ¨å‘˜æ˜¯å¦è¢«é€‰å…¥ä¸“ä¸šå›¢é˜Ÿçš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this if we compare the dimensionality of the features maps in Equation (8.90)[486] and Equation (8.91)[486] with the number of neurons shown in Figure 8.33[484].",
            "zh": "å¦‚æœæˆ‘ä»¬å°†ç­‰å¼ï¼ˆ8.90ï¼‰[486]å’Œç­‰å¼ï¼ˆ8.91ï¼‰[486]ä¸­ç‰¹å¾å›¾çš„ç»´æ•°ä¸å›¾8.33[484]æ‰€ç¤ºçš„ç¥ç»å…ƒæ•°é‡è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "An imbalanced dataset is a dataset that contains significantly more instances of one target level than another.",
            "zh": "ä¸å¹³è¡¡æ•°æ®é›†æ˜¯æŒ‡åŒ…å«ä¸€ä¸ªç›®æ ‡çº§åˆ«çš„å®ä¾‹æ˜æ˜¾å¤šäºå¦ä¸€ä¸ªç›®æ ‡çº§åˆ«çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "You have been asked by a San Francisco property investment company to create a predictive model that will generate house price estimates for properties they are considering purchasing as rental properties.",
            "zh": "æ—§é‡‘å±±ä¸€å®¶æˆ¿åœ°äº§æŠ•èµ„å…¬å¸è¦æ±‚æ‚¨åˆ›å»ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†ä¸ºä»–ä»¬æ­£åœ¨è€ƒè™‘è´­ä¹°çš„å‡ºç§Ÿç‰©ä¸šç”Ÿæˆæˆ¿ä»·ä¼°ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.3",
            "zh": "è¡¨ 13.3"
        }
    },
    {
        "translation": {
            "en": "So, grouping galaxies by morphological type is a fundamentally important step in analyzing the characteristics of galaxies.",
            "zh": "å› æ­¤ï¼ŒæŒ‰å½¢æ€ç±»å‹å¯¹æ˜Ÿç³»è¿›è¡Œåˆ†ç»„æ˜¯åˆ†ææ˜Ÿç³»ç‰¹å¾çš„åŸºæœ¬é‡è¦æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we set the number of bins to a high numberâ€”for example, 10 or moreâ€”then, just because there are more bin boundaries, it is more likely that at least some of our bins will align with interesting features of the distribution of the original continuous feature. This means that our binning categories will provide a better representation of this distribution. However, the more bins we have, the fewer instances we will have in each bin. Indeed, as the number of bins grows, we can end up with empty bins.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†æ¡æŸ±çš„æ•°é‡è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒé«˜çš„æ•°å­—ï¼ˆä¾‹å¦‚ï¼Œ10 ä¸ªæˆ–æ›´å¤šï¼‰ï¼Œé‚£ä¹ˆï¼Œä»…ä»…å› ä¸ºæœ‰æ›´å¤šçš„æ¡æŸ±è¾¹ç•Œï¼Œå°±æ›´æœ‰å¯èƒ½è‡³å°‘æœ‰ä¸€äº›æ¡æŸ±ä¸åŸå§‹è¿ç»­ç‰¹å¾åˆ†å¸ƒçš„æœ‰è¶£ç‰¹å¾å¯¹é½ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„åˆ†ç®±ç±»åˆ«å°†æ›´å¥½åœ°è¡¨ç¤ºæ­¤åˆ†å¸ƒã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬æ‹¥æœ‰çš„ bin è¶Šå¤šï¼Œæ¯ä¸ª bin ä¸­çš„å®ä¾‹å°±è¶Šå°‘ã€‚äº‹å®ä¸Šï¼Œéšç€åƒåœ¾ç®±æ•°é‡çš„å¢åŠ ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯èƒ½ä¼šå¾—åˆ°ç©ºåƒåœ¾ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just like descriptive features, target features are based on a domain concept, and we must determine what actual implementation is useful, feasible, and correct according to the specifics of the domain in question.",
            "zh": "å°±åƒæè¿°æ€§ç‰¹å¾ä¸€æ ·ï¼Œç›®æ ‡ç‰¹å¾ä¹Ÿæ˜¯åŸºäºé¢†åŸŸæ¦‚å¿µçš„ï¼Œæˆ‘ä»¬å¿…é¡»æ ¹æ®æ‰€è®¨è®ºé¢†åŸŸçš„å…·ä½“æƒ…å†µæ¥ç¡®å®šå“ªäº›å®é™…å®ç°æ˜¯æœ‰ç”¨çš„ã€å¯è¡Œçš„å’Œæ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that for the example in Figure 8.39[506] we would sum three error gradients for each weight in Wyh and six error gradients for each weight in Whh and each weight in Wyx.",
            "zh": "è¿™æ„å‘³ç€ï¼Œå¯¹äºå›¾ 8.39[506] ä¸­çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†å¯¹ Wyh ä¸­çš„æ¯ä¸ªæƒé‡çš„ä¸‰ä¸ªè¯¯å·®æ¢¯åº¦æ±‚å’Œï¼Œå¯¹ Whh ä¸­çš„æ¯ä¸ªæƒé‡å’Œ Wyx ä¸­çš„æ¯ä¸ªæƒé‡çš„å…­ä¸ªè¯¯å·®æ¢¯åº¦æ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For the first of these terms, P(h | m), only three instances in the dataset fulfill the condition of m (d5, d8 and d10).",
            "zh": "å¯¹äºè¿™äº›é¡¹ä¸­çš„ç¬¬ä¸€ä¸ªé¡¹ Pï¼ˆh | mï¼‰ï¼Œæ•°æ®é›†ä¸­åªæœ‰ä¸‰ä¸ªå®ä¾‹æ»¡è¶³ m çš„æ¡ä»¶ï¼ˆd5ã€d8 å’Œ d10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the mini-batch of examples listed in Table 8.13[464] through the network in Figure 8.27[465].",
            "zh": "è¡¨8.13[464]ä¸­åˆ—å‡ºçš„å°æ‰¹é‡ç¤ºä¾‹é€šè¿‡å›¾8.27[465]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many cases, although it may be possible to say that some outcomes are more desirable than others, it is simply not possible to quantify this.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå°½ç®¡å¯ä»¥è¯´æŸäº›ç»“æœæ¯”å…¶ä»–ç»“æœæ›´å¯å–ï¼Œä½†æ ¹æœ¬æ— æ³•é‡åŒ–è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.6",
            "zh": "å›¾ 11.6"
        }
    },
    {
        "translation": {
            "en": "By summing the weight updates across the neurons that use it, we retain a single consistent weight for all the neurons.",
            "zh": "é€šè¿‡å¯¹ä½¿ç”¨å®ƒçš„ç¥ç»å…ƒçš„æƒé‡æ›´æ–°æ±‚å’Œï¼Œæˆ‘ä»¬ä¸ºæ‰€æœ‰ç¥ç»å…ƒä¿ç•™äº†ä¸€ä¸ªä¸€è‡´çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "first",
            "zh": "ç¬¬ä¸€"
        }
    },
    {
        "translation": {
            "en": "In this example we might also include the number of claims made by the claimant in the last three months, the average number of claims made by the claimant per year, and the ratio of the average number of claims made by the claimant per year to the claims made by the claimant in the last twelve months.",
            "zh": "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åŒ…æ‹¬ç´¢èµ”äººåœ¨è¿‡å»ä¸‰ä¸ªæœˆå†…æå‡ºçš„ç´¢èµ”æ•°é‡ã€ç´¢èµ”äººæ¯å¹´æå‡ºçš„å¹³å‡ç´¢èµ”æ•°é‡ï¼Œä»¥åŠç´¢èµ”äººæ¯å¹´æå‡ºçš„å¹³å‡ç´¢èµ”æ•°é‡ä¸ç´¢èµ”äººåœ¨è¿‡å»åäºŒä¸ªæœˆå†…æå‡ºçš„ç´¢èµ”çš„æ¯”ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "ME1E1ERR_U/G/R/I/Z",
            "zh": "ME1E1ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "policy-based reinforcement learning, 643",
            "zh": "åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œ643"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity is an especially useful measure of similarity when the descriptive features describing instances in a dataset are related to each other.",
            "zh": "å½“æè¿°æ•°æ®é›†ä¸­å®ä¾‹çš„æè¿°æ€§ç‰¹å¾ç›¸äº’å…³è”æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼åº¦æ˜¯è¡¡é‡ç›¸ä¼¼åº¦çš„ç‰¹åˆ«æœ‰ç”¨çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this example, the weight matrices were randomly initialized from the range [âˆ’0.5,+0.5]",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæƒé‡çŸ©é˜µæ˜¯ä» [âˆ’0.5ï¼Œ+0.5] èŒƒå›´éšæœºåˆå§‹åŒ–çš„"
        }
    },
    {
        "translation": {
            "en": "Bostrom, Nick. 2003. Ethical issues in advanced artificial intelligence. In Science fiction and philosophy: From time travel to superintelligence, 277â€“284. Wiley-Blackwell.",
            "zh": "åšæ–¯ç‰¹ç½—å§†ï¼Œå°¼å…‹ã€‚2003. å…ˆè¿›äººå·¥æ™ºèƒ½ä¸­çš„ä¼¦ç†é—®é¢˜.åœ¨ç§‘å¹»å°è¯´å’Œå“²å­¦ä¸­ï¼šä»æ—¶é—´æ—…è¡Œåˆ°è¶…çº§æ™ºèƒ½ï¼Œ277-284ã€‚å¨åˆ©-å¸ƒè±å…‹å¨å°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "To find the optimal set of weights, we begin with a set of random weight values that corresponds to some random point on the error surface.",
            "zh": "ä¸ºäº†æ‰¾åˆ°æœ€ä½³æƒé‡é›†ï¼Œæˆ‘ä»¬ä»ä¸€ç»„éšæœºæƒé‡å€¼å¼€å§‹ï¼Œè¿™äº›å€¼å¯¹åº”äºè¯¯å·®æ›²é¢ä¸Šçš„æŸä¸ªéšæœºç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.10",
            "zh": "è¡¨ 9.10"
        }
    },
    {
        "translation": {
            "en": "Figure B.1",
            "zh": "å›¾ B.1"
        }
    },
    {
        "translation": {
            "en": "7.4â€ƒExtensions and Variations",
            "zh": "7.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Each normal distribution has a different mean but the same standard deviation.",
            "zh": "æ¯ä¸ªæ­£æ€åˆ†å¸ƒå…·æœ‰ä¸åŒçš„å‡å€¼ï¼Œä½†æ ‡å‡†å·®ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "distance metric, 184, 231",
            "zh": "è·ç¦»å…¬åˆ¶ï¼Œ 184ï¼Œ 231"
        }
    },
    {
        "translation": {
            "en": "The whiskey dataset after the descriptive features have been normalized.",
            "zh": "æè¿°æ€§ç‰¹å¾å½’ä¸€åŒ–åçš„å¨å£«å¿Œæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "These individual delta contributions are then summed so that the weight update rule (Equation (7.33)[346]) can be applied, in this example using a learning rate of 0.02.",
            "zh": "ç„¶åå°†è¿™äº›å•ç‹¬çš„å¢é‡è´¡çŒ®ç›¸åŠ ï¼Œä»¥ä¾¿å¯ä»¥åº”ç”¨æƒé‡æ›´æ–°è§„åˆ™ï¼ˆç­‰å¼ ï¼ˆ7.33ï¼‰[346]ï¼‰ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œå­¦ä¹ ç‡ä¸º 0.02ã€‚"
        }
    },
    {
        "translation": {
            "en": "The line in Figure 1.3(b)[15] represents one model of the relationship between the AGE and INCOME features.",
            "zh": "å›¾1.3ï¼ˆbï¼‰[15]ä¸­çš„çº¿ä»£è¡¨äº†å¹´é¾„å’Œæ”¶å…¥ç‰¹å¾ä¹‹é—´å…³ç³»çš„ä¸€ä¸ªæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "two-stage model, 722, 725",
            "zh": "ä¸¤çº§å‹å·ï¼Œ722ã€725"
        }
    },
    {
        "translation": {
            "en": "5.13â€…â€…â€…The AGE and RATING feature space for the whiskey dataset. The location of the query instance is indicated by the ? symbol. The circle plotted with a dashed line demarcates the border of the neighborhood around the query when k = 3. The three nearest neighbors to the query are labeled with their ID values.",
            "zh": "5.13 å¨å£«å¿Œæ•°æ®é›†çš„ AGE å’Œ RATING ç‰¹å¾ç©ºé—´ã€‚æŸ¥è¯¢å®ä¾‹çš„ä½ç½®ç”± ï¼Ÿè±¡å¾ã€‚å½“ k = 3 æ—¶ï¼Œç”¨è™šçº¿ç»˜åˆ¶çš„åœ†åœˆåˆ’å®šäº†æŸ¥è¯¢å‘¨å›´é‚»åŸŸçš„è¾¹ç•Œã€‚æŸ¥è¯¢çš„ä¸‰ä¸ªæœ€è¿‘é‚»åŸŸæ ‡æœ‰å…¶ ID å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Should we count one missed payment as a default or, to avoid predicting that good customers will default, should we consider a customer to have defaulted only after they miss three consecutive payments?",
            "zh": "æˆ‘ä»¬æ˜¯å¦åº”è¯¥å°†ä¸€æ¬¡é”™è¿‡çš„ä»˜æ¬¾è§†ä¸ºè¿çº¦ï¼Œæˆ–è€…ä¸ºäº†é¿å…é¢„æµ‹å¥½å®¢æˆ·ä¼šè¿çº¦ï¼Œæˆ‘ä»¬æ˜¯å¦åº”è¯¥è®¤ä¸ºå®¢æˆ·ä»…åœ¨è¿ç»­é”™è¿‡ä¸‰æ¬¡ä»˜æ¬¾åæ‰è¿çº¦ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "More recent attempts to do this include Segata et al.",
            "zh": "æœ€è¿‘å°è¯•è¿™æ ·åšçš„åŒ…æ‹¬ Segata ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "HELPFORUM: Did the user post a question on the help forum?",
            "zh": "HELPFORUMï¼šç”¨æˆ·æ˜¯å¦åœ¨å¸®åŠ©è®ºå›ä¸Šå‘å¸ƒäº†é—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "3.7â€…â€…â€…Examples of using small multiple bar plot visualizations to illustrate the relationship between two categorical features: (a) the CAREER STAGE and SHOE SPONSOR features; and (b) the POSITION and SHOE SPONSOR features. All data comes from Table 3.7[73].",
            "zh": "3.7 ä½¿ç”¨å°å¤šæ¡å½¢å›¾å¯è§†åŒ–æ¥è¯´æ˜ä¸¤ä¸ªåˆ†ç±»ç‰¹å¾ä¹‹é—´çš„å…³ç³»çš„ç¤ºä¾‹ï¼šï¼ˆaï¼‰ CAREER STAGE å’Œ SHOE SPONSOR ç‰¹å¾;ä»¥åŠ ï¼ˆbï¼‰ POSITION å’Œ SHOE SPONSOR åŠŸèƒ½ã€‚æ‰€æœ‰æ•°æ®å‡æ¥è‡ªè¡¨3.7[73]ã€‚"
        }
    },
    {
        "translation": {
            "en": "With all model ensembles, however, the cost of their high performance is increased learning and model complexity.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºæ‰€æœ‰æ¨¡å‹é›†æˆï¼Œå…¶é«˜æ€§èƒ½çš„ä»£ä»·æ˜¯å¢åŠ äº†å­¦ä¹ å’Œæ¨¡å‹å¤æ‚æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The initial weights in the auto-encoder are randomly initialized, and therefore it should not be a surprise that these reconstructions bear no resemblance to the original images and are basically noise.",
            "zh": "è‡ªåŠ¨ç¼–ç å™¨ä¸­çš„åˆå§‹æƒé‡æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œå› æ­¤è¿™äº›é‡å»ºä¸åŸå§‹å›¾åƒæ²¡æœ‰ç›¸ä¼¼ä¹‹å¤„å¹¶ä¸”åŸºæœ¬ä¸Šæ˜¯å™ªå£°ä¹Ÿå°±ä¸è¶³ä¸ºå¥‡äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes there are very specific relationships in a dataset that we want to maintain in a sample.",
            "zh": "æœ‰æ—¶ï¼Œæ•°æ®é›†ä¸­å­˜åœ¨æˆ‘ä»¬æƒ³è¦åœ¨æ ·æœ¬ä¸­ç»´æŠ¤çš„éå¸¸å…·ä½“çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In most cases random sampling will maintain distributions; however, if there are one or more levels of a categorical feature that only a very small proportion of instances in a dataset have, there is a chance that these will be omitted or underrepresented by random sampling.",
            "zh": "åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒéšæœºæŠ½æ ·å°†ä¿æŒåˆ†å¸ƒ;ä½†æ˜¯ï¼Œå¦‚æœæ•°æ®é›†ä¸­åªæœ‰æå°‘æ•°å®ä¾‹å…·æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªç±»åˆ«ç‰¹å¾çº§åˆ«ï¼Œåˆ™éšæœºæŠ½æ ·å¯èƒ½ä¼šå¿½ç•¥è¿™äº›çº§åˆ«æˆ–è¡¨ç¤ºä¸è¶³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jim and Martha always go shopping separately. If Jim does the shopping he buys wine, but not always. If Martha does the shopping, she buys wine, but not always. If Jim tells Martha that he has done the shopping, then Martha doesnâ€™t go shopping, but sometimes Jim forgets to tell Martha, and so sometimes both Jim and Martha go shopping.",
            "zh": "å‰å§†å’Œç›èæ€»æ˜¯åˆ†å¼€å»è´­ç‰©ã€‚å¦‚æœå‰å§†å»è´­ç‰©ï¼Œä»–ä¼šä¹°é…’ï¼Œä½†å¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚å¦‚æœç›èå»è´­ç‰©ï¼Œå¥¹ä¼šä¹°é…’ï¼Œä½†å¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚å¦‚æœå‰å§†å‘Šè¯‰ç›èä»–å·²ç»ä¹°å®Œäº†ä¸œè¥¿ï¼Œé‚£ä¹ˆç›èå°±ä¸ä¼šå»è´­ç‰©ï¼Œä½†æœ‰æ—¶å‰å§†å¿˜è®°å‘Šè¯‰ç›èï¼Œæ‰€ä»¥æœ‰æ—¶å‰å§†å’Œç›èéƒ½å»è´­ç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.14[565] shows an example for the email classification problem predictions given in Table 9.11[557].",
            "zh": "è¡¨9.14[565]æ˜¾ç¤ºäº†è¡¨9.11[557]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶åˆ†ç±»é—®é¢˜é¢„æµ‹ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is one, non-obvious, aspect of this example that is particularly interesting.",
            "zh": "è¿™ä¸ªä¾‹å­æœ‰ä¸€ä¸ªä¸æ˜æ˜¾çš„æ–¹é¢ç‰¹åˆ«æœ‰è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "When training a support vector machine, we wish to find a hyperplane that distinguishes between the two target levels, âˆ’ 1 and + 1. So, the required constraints required by the training process are",
            "zh": "åœ¨è®­ç»ƒæ”¯æŒå‘é‡æœºæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªåŒºåˆ†ä¸¤ä¸ªç›®æ ‡æ°´å¹³ âˆ’ 1 å’Œ + 1 çš„è¶…å¹³é¢ã€‚å› æ­¤ï¼Œè®­ç»ƒè¿‡ç¨‹æ‰€éœ€çš„çº¦æŸæ˜¯"
        }
    },
    {
        "translation": {
            "en": "Consequently, the plot of values for HL1 is generated from a much smaller sample of weight values than the plots for the other hidden layers.",
            "zh": "å› æ­¤ï¼ŒHL1 çš„å€¼å›¾æ˜¯ä»æ¯”å…¶ä»–éšè—å±‚çš„å›¾å°å¾—å¤šçš„æƒé‡å€¼æ ·æœ¬ç”Ÿæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Now, imagine a scenario in which the model makes a correct prediction and the maximum probability in is assigned to the correct category.",
            "zh": "ç°åœ¨ï¼Œå‡è®¾æ¨¡å‹åšå‡ºæ­£ç¡®çš„é¢„æµ‹ï¼Œå¹¶å°†æœ€å¤§æ¦‚ç‡åˆ†é…ç»™æ­£ç¡®çš„ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, for example, a number of non-modifiable risk factors such as age and gender.",
            "zh": "ä¾‹å¦‚ï¼Œæœ‰è®¸å¤šä¸å¯æ”¹å˜çš„é£é™©å› ç´ ï¼Œä¾‹å¦‚å¹´é¾„å’Œæ€§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "This elementwise product is depicted in Figure 8.40[509] by the âŠ™ symbol at the intersection of the cell state and the output of the forget gate sigmoid layer in the top-left of the figure.",
            "zh": "å›¾8.40[509]ä¸­ï¼Œè¯¥å…ƒç´ ä¹˜ç§¯ç”±å›¾å·¦ä¸Šè§’çš„å•å…ƒçŠ¶æ€å’Œé—å¿˜é—¨Så½¢ç»“æ™¶å±‚è¾“å‡ºäº¤ç‚¹å¤„çš„âŠ™ç¬¦å·è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "sampling, 87, 91",
            "zh": "é‡‡æ ·ï¼Œ 87ï¼Œ 91"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3",
            "zh": "å›¾ 11.3"
        }
    },
    {
        "translation": {
            "en": "One way to do this (similar to the ranking and pruning approach described previously) is to use a filter to evaluate the predictiveness of each candidate set of features and select the most predictive one.",
            "zh": "ä¸€ç§æ–¹æ³•ï¼ˆç±»ä¼¼äºå‰é¢æè¿°çš„æ’åå’Œä¿®å‰ªæ–¹æ³•ï¼‰æ˜¯ä½¿ç”¨è¿‡æ»¤å™¨æ¥è¯„ä¼°æ¯ç»„å€™é€‰ç‰¹å¾çš„é¢„æµ‹æ€§ï¼Œå¹¶é€‰æ‹©æœ€å…·é¢„æµ‹æ€§çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once these three conditions hold (stationary distribution, ergodicity, and independent states), the samples generated will eventually converge with the distribution, and it is appropriate to use Gibbs sampling.",
            "zh": "ä¸€æ—¦è¿™ä¸‰ä¸ªæ¡ä»¶ï¼ˆç¨³æ€åˆ†å¸ƒã€éå†æ€§å’Œç‹¬ç«‹çŠ¶æ€ï¼‰æˆç«‹ï¼Œç”Ÿæˆçš„æ ·æœ¬æœ€ç»ˆå°†ä¸åˆ†å¸ƒæ”¶æ•›ï¼Œä½¿ç”¨å‰å¸ƒæ–¯é‡‡æ ·æ˜¯åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The GOOD BEHAVIOR feature has a value of true if the prisoner had not committed any infringements during incarceration, the AGE < 30 has a value of true if the prisoner was under 30 years of age when granted parole, and the DRUG DEPENDENT feature is true if the prisoner had a drug addiction at the time of parole.",
            "zh": "å¦‚æœå›šçŠ¯åœ¨ç›‘ç¦æœŸé—´æ²¡æœ‰çŠ¯ä»»ä½•ä¾µæƒè¡Œä¸ºï¼Œåˆ™ GOOD BEHAVIOR ç‰¹å¾çš„å€¼ä¸º trueï¼Œå¦‚æœå›šçŠ¯åœ¨è·å¾—å‡é‡Šæ—¶æœªæ»¡ 30 å²ï¼Œåˆ™ AGE < 30 çš„å€¼ä¸º trueï¼Œå¦‚æœå›šçŠ¯åœ¨å‡é‡Šæ—¶å¸æ¯’æˆç˜¾ï¼Œåˆ™ DRUG DEPENDENT ç‰¹å¾ä¸º trueã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.9",
            "zh": "è¡¨ 7.9"
        }
    },
    {
        "translation": {
            "en": "Using a sparse representation can reduce the energy consumed by a network (Reagen et al., 2017) and is also more biologically plausible (Glorot et al., 2011).",
            "zh": "ä½¿ç”¨ç¨€ç–è¡¨ç¤ºå¯ä»¥å‡å°‘ç½‘ç»œæ¶ˆè€—çš„èƒ½é‡ï¼ˆReagenç­‰äººï¼Œ2017ï¼‰ï¼Œå¹¶ä¸”åœ¨ç”Ÿç‰©å­¦ä¸Šä¹Ÿæ›´åˆç†ï¼ˆGlorotç­‰äººï¼Œ2011ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bejar, J., U. CortÃ©s, and M. Poch. 1991. LINNEO+: A classification methodology for ill-structured domains, Research report RT-93-10-R, Dept. Llenguatges i Sistemes Informatics, Universitat PolitÃ¨cnica de Catalunya.",
            "zh": "Bejarï¼Œ J.ï¼Œ U. CortÃ©sï¼Œ å’Œ M. Poch.1991. LINNEO+ï¼šç»“æ„ä¸è‰¯åŸŸçš„åˆ†ç±»æ–¹æ³•ï¼Œç ”ç©¶æŠ¥å‘ŠRT-93-10-Rï¼ŒåŠ æ³°ç½—å°¼äºšç†å·¥å¤§å­¦ä¿¡æ¯å­¦ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. In order to allow this dataset fit on one page, only a subset of the features described in the domain concept diagrams in Figures 2.9[43], 2.10[44], and 2.11[45] are included.",
            "zh": "1. ä¸ºäº†ä½¿è¯¥æ•°æ®é›†é€‚åˆä¸€é¡µï¼Œä»…åŒ…å«å›¾ 2.9[43]ã€2.10[44] å’Œ 2.11[45] ä¸­é¢†åŸŸæ¦‚å¿µå›¾ä¸­æè¿°çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if you ask Question 2, and we answer yes, you can be sure that we have picked Brian without asking any more questions.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨é—®é—®é¢˜ 2ï¼Œè€Œæˆ‘ä»¬çš„å›ç­”æ˜¯è‚¯å®šçš„ï¼Œæ‚¨å¯ä»¥ç¡®å®šæˆ‘ä»¬å·²ç»é€‰æ‹©äº† Brianï¼Œè€Œæ— éœ€å†é—®ä»»ä½•é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Directly solving the large series of simultaneous equations that arise from the Bellman optimality equation for MDPs of interesting scale, however, is computationally very expensive and requires full knowledge of the dynamics of an MDP for a given scenario that can be unavailable in practice.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºå…·æœ‰æœ‰è¶£è§„æ¨¡çš„ MDPï¼Œç›´æ¥æ±‚è§£ç”±è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹äº§ç”Ÿçš„å¤§é‡è”ç«‹æ–¹ç¨‹åœ¨è®¡ç®—ä¸Šéå¸¸æ˜‚è´µï¼Œå¹¶ä¸”éœ€è¦å……åˆ†äº†è§£ç»™å®šåœºæ™¯ä¸‹çš„ MDP åŠ¨åŠ›å­¦ï¼Œè€Œè¿™åœ¨å®è·µä¸­å¯èƒ½ä¸å¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In predictive data analytics we use a broad definition of the word prediction.",
            "zh": "åœ¨é¢„æµ‹æ•°æ®åˆ†æä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œé¢„æµ‹â€ä¸€è¯çš„å¹¿ä¹‰å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Aphra",
            "zh": "é˜¿èŠ™æ‹‰"
        }
    },
    {
        "translation": {
            "en": "9,235",
            "zh": "9,235"
        }
    },
    {
        "translation": {
            "en": "Table 6.4[265] shows the relevant probabilities needed to make a prediction for this query and the calculation of the scores for each possible prediction.",
            "zh": "è¡¨ 6.4[265] æ˜¾ç¤ºäº†å¯¹æ­¤æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ä»¥åŠæ¯ä¸ªå¯èƒ½é¢„æµ‹çš„åˆ†æ•°è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian network, 243, 265, 285, 304, 732, 733, 735",
            "zh": "è´å¶æ–¯ç½‘ç»œï¼Œ 243ï¼Œ 265ï¼Œ 285ï¼Œ 304ï¼Œ 732ï¼Œ 733ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "As a result, a topic can be included in a course by covering just the first part of a chapter (Big Idea, fundamentals, standard algorithm, and worked example); and thenâ€”time permittingâ€”the coverage of the topic can be extended to some or all of the material in the second part.",
            "zh": "å› æ­¤ï¼Œåªéœ€æ¶µç›–ä¸€ç« çš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆå¤§åˆ›æ„ã€åŸºç¡€çŸ¥è¯†ã€æ ‡å‡†ç®—æ³•å’Œå·¥ä½œç¤ºä¾‹ï¼‰å³å¯å°†ä¸»é¢˜åŒ…å«åœ¨è¯¾ç¨‹ä¸­;ç„¶åï¼Œå¦‚æœæ—¶é—´å…è®¸ï¼Œè¯¥ä¸»é¢˜çš„è¦†ç›–èŒƒå›´å¯ä»¥æ‰©å±•åˆ°ç¬¬äºŒéƒ¨åˆ†çš„éƒ¨åˆ†æˆ–å…¨éƒ¨ææ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main disadvantage is that programming is a skill that takes time and effort to learn.",
            "zh": "ä¸»è¦ç¼ºç‚¹æ˜¯ç¼–ç¨‹æ˜¯ä¸€é¡¹éœ€è¦æ—¶é—´å’Œç²¾åŠ›æ¥å­¦ä¹ çš„æŠ€èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.13[560] shows how the predictions made for test instances change as the threshold changes.",
            "zh": "è¡¨ 9.13[560] æ˜¾ç¤ºäº†å¯¹æµ‹è¯•å®ä¾‹æ‰€åšçš„é¢„æµ‹å¦‚ä½•éšç€é˜ˆå€¼çš„å˜åŒ–è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "stationary distribution, 299",
            "zh": "ç¨³æ€åˆ†å¸ƒï¼Œ299"
        }
    },
    {
        "translation": {
            "en": "For the value of the visible card dealt to the dealer, just two levels (low and high) are modeled",
            "zh": "å¯¹äºå‘ç»™åº„å®¶çš„å¯è§ç‰Œçš„ä»·å€¼ï¼Œåªå»ºæ¨¡äº†ä¸¤ä¸ªçº§åˆ«ï¼ˆä½å’Œé«˜ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The amount of sub-sampling applied is dependent on the dimensions of the receptive fields of the neurons; for example, using non-overlapping 2-by-2 receptive fields, the output from a sub-sampling layer will have half the number of rows and columns as the feature map input to the layer.",
            "zh": "åº”ç”¨çš„å­é‡‡æ ·é‡å–å†³äºç¥ç»å…ƒæ„Ÿå—é‡çš„å°ºå¯¸;ä¾‹å¦‚ï¼Œä½¿ç”¨ä¸é‡å çš„ 2Ã—2 æ„Ÿå—é‡ï¼Œå­é‡‡æ ·å›¾å±‚çš„è¾“å‡ºå°†å…·æœ‰ä¸€åŠçš„è¡Œæ•°å’Œåˆ—æ•°ä½œä¸ºå›¾å±‚çš„ç‰¹å¾å›¾è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "missing indicator feature, 69",
            "zh": "ç¼ºå°‘æŒ‡ç¤ºå™¨åŠŸèƒ½ï¼Œ69"
        }
    },
    {
        "translation": {
            "en": "This weight initialization heuristic is known as He initialization (or sometimes it is called Kaiming initialization) and is defined as follows:",
            "zh": "è¿™ç§æƒé‡åˆå§‹åŒ–å¯å‘å¼ç§°ä¸º He åˆå§‹åŒ–ï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸º Kaim åˆå§‹åŒ–ï¼‰ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "To illustrate how information gain ratio is computed, we compute the information gain ratio for the descriptive features STREAM, SLOPE, and ELEVATION in the vegetation classification dataset in Table 4.3[136]. We already know the information gain for these features (see Table 4.4[137])",
            "zh": "ä¸ºäº†è¯´æ˜å¦‚ä½•è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”ï¼Œæˆ‘ä»¬è®¡ç®—äº†è¡¨4.3[136]ä¸­æ¤è¢«åˆ†ç±»æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾STREAMã€SLOPEå’ŒELEVATIONçš„ä¿¡æ¯å¢ç›Šæ¯”ã€‚æˆ‘ä»¬å·²ç»çŸ¥é“è¿™äº›ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼ˆè§è¡¨4.4[137]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "As well as being required to select appropriate performance measures to use when evaluating trained models, we also need to ensure that we are using the appropriate evaluation experiment design. The goal here is to ensure that we calculate the best estimate of how a prediction model will perform when actually deployed in the wild. In this section we will describe the most important evaluation experiment designs and indicate when each is most appropriate.",
            "zh": "é™¤äº†åœ¨è¯„ä¼°è®­ç»ƒæ¨¡å‹æ—¶éœ€è¦é€‰æ‹©é€‚å½“çš„æ€§èƒ½åº¦é‡å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ç¡®ä¿æˆ‘ä»¬ä½¿ç”¨é€‚å½“çš„è¯„ä¼°å®éªŒè®¾è®¡ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯ç¡®ä¿æˆ‘ä»¬è®¡ç®—å‡ºé¢„æµ‹æ¨¡å‹åœ¨å®é™…éƒ¨ç½²åœ¨é‡å¤–æ—¶çš„è¡¨ç°çš„æœ€ä½³ä¼°è®¡ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æè¿°æœ€é‡è¦çš„è¯„ä¼°å®éªŒè®¾è®¡ï¼Œå¹¶æŒ‡å‡ºæ¯ç§å®éªŒè®¾è®¡ä½•æ—¶æœ€åˆé€‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence using the softmax function, the activation of each neuron is dependent on the size of its z value relative to the z values of the other neurons in the output layer.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨ softmax å‡½æ•°ï¼Œæ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»å–å†³äºå…¶ z å€¼ç›¸å¯¹äºè¾“å‡ºå±‚ä¸­å…¶ä»–ç¥ç»å…ƒçš„ z å€¼çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Interval: Values that allow ordering and subtraction, but do not allow other arithmetic operations (e.g., date, time)",
            "zh": "é—´éš”ï¼šå…è®¸æ’åºå’Œå‡æ³•ï¼Œä½†ä¸å…è®¸å…¶ä»–ç®—æœ¯è¿ç®—ï¼ˆä¾‹å¦‚æ—¥æœŸã€æ—¶é—´ï¼‰çš„å€¼"
        }
    },
    {
        "translation": {
            "en": "However, this still requires the selection of a set of initial approaches.",
            "zh": "ä½†æ˜¯ï¼Œè¿™ä»ç„¶éœ€è¦é€‰æ‹©ä¸€ç»„åˆå§‹æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "uniform distribution, 59",
            "zh": "å‡åŒ€åˆ†å¸ƒï¼Œ59"
        }
    },
    {
        "translation": {
            "en": "For example, if we decreased the dimension of our filter to a 2-by-2 dimension then we would need to increase the set of neurons to a 5-by-5 layer in order to cover the input, and this would result in a 5-by-5 feature map.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°†è¿‡æ»¤å™¨çš„ç»´åº¦é™ä½åˆ° 2Ã—2 çš„ç»´åº¦ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦å°†ç¥ç»å…ƒé›†å¢åŠ åˆ° 5Ã—5 å±‚ä»¥è¦†ç›–è¾“å…¥ï¼Œè¿™å°†äº§ç”Ÿ 5Ã—5 çš„ç‰¹å¾å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "linear, 386, 625",
            "zh": "çº¿æ€§ï¼Œ 386ï¼Œ 625"
        }
    },
    {
        "translation": {
            "en": "On the other hand, k nearest neighbor models are very slow to make predictions as they must perform a comparison of a query instance to every instance in a, typically large, training set.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œk ä¸ªæœ€è¿‘é‚»æ¨¡å‹çš„é¢„æµ‹é€Ÿåº¦éå¸¸æ…¢ï¼Œå› ä¸ºå®ƒä»¬å¿…é¡»å°†æŸ¥è¯¢å®ä¾‹ä¸è®­ç»ƒé›†ä¸­çš„æ¯ä¸ªå®ä¾‹ï¼ˆé€šå¸¸æ˜¯å¤§å‹è®­ç»ƒé›†ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "9.14â€…â€…â€…Tabulating the workings required to generate a K-S statistic.",
            "zh": "9.14 å°†ç”Ÿæˆ K-S ç»Ÿè®¡é‡æ‰€éœ€çš„å·¥ä½œé‡åˆ¶æˆè¡¨æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.5",
            "zh": "å›¾ 5.5"
        }
    },
    {
        "translation": {
            "en": "In fact, the predictions produced by a similarity-based model will change depending on the exact Minkowski distance used (i.e., p = 1,2,â€¦,âˆ).",
            "zh": "äº‹å®ä¸Šï¼ŒåŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹äº§ç”Ÿçš„é¢„æµ‹å°†æ ¹æ®æ‰€ä½¿ç”¨çš„ç¡®åˆ‡é—µå¯å¤«æ–¯åŸºè·ç¦»ï¼ˆå³ p = 1,2,...,âˆï¼‰è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The neurons in this network all use the logistic function as their activation function, and so the derivative of this function is given by Equation (8.15)[408].",
            "zh": "è¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒéƒ½ä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºå®ƒä»¬çš„æ¿€æ´»å‡½æ•°ï¼Œå› æ­¤è¯¥å‡½æ•°çš„å¯¼æ•°ç”±æ–¹ç¨‹ï¼ˆ8.15ï¼‰[408]ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "intra-cluster distance, 608",
            "zh": "é›†ç¾¤å†…è·ç¦»ï¼Œ608"
        }
    },
    {
        "translation": {
            "en": "0.34",
            "zh": "0.34"
        }
    },
    {
        "translation": {
            "en": "From these values we can see that the error gradient will be able to flow backward through Neurons 8, 7, and 6 without being scaled down by the multiplication by âˆ‚a/âˆ‚z in the Î´ calculations.",
            "zh": "ä»è¿™äº›å€¼ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¯¯å·®æ¢¯åº¦å°†èƒ½å¤Ÿå‘åæµè¿‡ç¥ç»å…ƒ 8ã€7 å’Œ 6ï¼Œè€Œä¸ä¼šåœ¨Î´è®¡ç®—ä¸­è¢«ä¹˜ä»¥ âˆ‚a/âˆ‚z ç¼©å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is much easier to select initial weights for normalized feature values than for raw feature values, as the range in which weights for normalized feature values might reasonably fall (particularly for the intercept weight, w[0]) is much better defined than the corresponding range when raw feature values are used.",
            "zh": "ä¸ºå½’ä¸€åŒ–ç‰¹å¾å€¼é€‰æ‹©åˆå§‹æƒé‡æ¯”ä¸ºåŸå§‹ç‰¹å¾å€¼é€‰æ‹©åˆå§‹æƒé‡è¦å®¹æ˜“å¾—å¤šï¼Œå› ä¸ºå½’ä¸€åŒ–ç‰¹å¾å€¼çš„æƒé‡å¯èƒ½åˆç†ä¸‹é™çš„èŒƒå›´ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºæˆªè·æƒé‡ w[0]ï¼‰æ¯”ä½¿ç”¨åŸå§‹ç‰¹å¾å€¼æ—¶çš„ç›¸åº”èŒƒå›´å®šä¹‰å¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Edwin and Jocelyn discussed how fast the model built would need to be to allow its inclusion in the existing SDSS pipeline.",
            "zh": "æœ€åï¼ŒEdwin å’Œ Jocelyn è®¨è®ºäº†æ„å»ºæ¨¡å‹çš„é€Ÿåº¦éœ€è¦å¤šå¿«æ‰èƒ½å°†å…¶åŒ…å«åœ¨ç°æœ‰çš„ SDSS ç®¡é“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, the number of channels in the input to this layer would be equal to the number of filters in the preceding convolutional layer.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥å±‚è¾“å…¥ä¸­çš„é€šé“æ•°å°†ç­‰äºå‰ä¸€ä¸ªå·ç§¯å±‚ä¸­çš„æ»¤æ³¢å™¨æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Caruana et al.",
            "zh": "å¡é²é˜¿çº³ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "MRRCCERR_U/G/R/I/Z",
            "zh": "MRRCCERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Bayes, Thomas, 248",
            "zh": "è´å¶æ–¯ï¼Œæ‰˜é©¬æ–¯ï¼Œ248"
        }
    },
    {
        "translation": {
            "en": "pre-pruning, 155, 169",
            "zh": "é¢„ä¿®å‰ªï¼Œ 155ï¼Œ 169"
        }
    },
    {
        "translation": {
            "en": "So âˆ‘iP(mi) = P(m) + P(Â¬m).",
            "zh": "æ‰€ä»¥âˆ‘iPï¼ˆmiï¼‰ = Pï¼ˆmï¼‰ + Pï¼ˆÂ¬mï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ayres, Ian. 2008. Super crunchers: Why thinking-by-numbers is the new way to be smart. Bantam.",
            "zh": "è‰¾å°”æ–¯ï¼Œä¼Šæ©ã€‚2008. è¶…çº§ç´§ç¼©è€…ï¼šä¸ºä»€ä¹ˆç”¨æ•°å­—æ€è€ƒæ˜¯å˜å¾—èªæ˜çš„æ–°æ–¹æ³•ã€‚çŸ®è„šé¸¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "and then, if required, Do they have long hair?",
            "zh": "ç„¶åï¼Œå¦‚æœéœ€è¦ï¼Œä»–ä»¬æœ‰é•¿å‘å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The mean squared error allows us to rank the performance of multiple models on a prediction problem with a continuous target. Mean squared error values fall in the range [0,âˆ], and smaller values indicate better model performance.",
            "zh": "å‡æ–¹è¯¯å·®å…è®¸æˆ‘ä»¬åœ¨å…·æœ‰è¿ç»­ç›®æ ‡çš„é¢„æµ‹é—®é¢˜ä¸Šå¯¹å¤šä¸ªæ¨¡å‹çš„æ€§èƒ½è¿›è¡Œæ’åã€‚å‡æ–¹è¯¯å·®å€¼åœ¨ [0ï¼Œâˆ] èŒƒå›´å†…ï¼Œå€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4.3â€…â€…â€…â€…Box Plots",
            "zh": "A.4.3 ç®±å½¢å›¾"
        }
    },
    {
        "translation": {
            "en": "The effect of using different numbers of bins when using binning to convert a continuous feature into a categorical feature.",
            "zh": "ä½¿ç”¨åˆ†ç®±å°†è¿ç»­è¦ç´ è½¬æ¢ä¸ºåˆ†ç±»è¦ç´ æ—¶ä½¿ç”¨ä¸åŒæ•°é‡çš„æ¡æŸ±çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance can be understood as defining an orthonormal coordinate system with (1) an origin at the instance we are calculating the distance from (a in Equation (5.16)[219]); (2) a primary axis aligned with the direction of the greatest spread in the dataset; and (3) the units of all the axes scaled so that the dataset has unit variance along each axis.",
            "zh": "é©¬æ°è·ç¦»å¯ä»¥ç†è§£ä¸ºå®šä¹‰ä¸€ä¸ªæ­£äº¤åæ ‡ç³»ï¼Œå…¶ç‰¹ç‚¹æ˜¯ï¼šï¼ˆ1ï¼‰åœ¨æˆ‘ä»¬è®¡ç®—è·ç¦»çš„å®ä¾‹å¤„æœ‰ä¸€ä¸ªåŸç‚¹ï¼ˆæ–¹ç¨‹ï¼ˆ5.16ï¼‰[219]ä¸­çš„aï¼‰;ï¼ˆ2ï¼‰ä¸æ•°æ®é›†ä¸­æœ€å¤§ä¼ æ’­æ–¹å‘å¯¹é½çš„ä¸»è½´;ï¼ˆ3ï¼‰æ‰€æœ‰è½´çš„å•ä½ç¼©æ”¾ï¼Œä½¿æ•°æ®é›†æ²¿æ¯ä¸ªè½´å…·æœ‰å•ä½æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having performed this initial analysis, Jocelyn met again with Edwin and Ted to discuss the data quality issues and, more generally, to review the domain concepts outlined in Figure 13.2[708] so as to begin designing the actual descriptive features that would populate the ABT.",
            "zh": "åœ¨è¿›è¡Œäº†åˆæ­¥åˆ†æä¹‹åï¼ŒJocelyn å†æ¬¡ä¸ Edwin å’Œ Ted ä¼šé¢ï¼Œè®¨è®ºæ•°æ®è´¨é‡é—®é¢˜ï¼Œå¹¶æ›´å¹¿æ³›åœ°å›é¡¾å›¾ 13.2[708] ä¸­æ¦‚è¿°çš„é¢†åŸŸæ¦‚å¿µï¼Œä»¥ä¾¿å¼€å§‹è®¾è®¡å°†å¡«å…… ABT çš„å®é™…æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "MIL. SPEND, the percentage of GDP spent on the military",
            "zh": "MIL. æ”¯å‡ºï¼Œç”¨äºå†›äº‹çš„ GDP ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "(c) Design a reward function for this scenario.",
            "zh": "ï¼ˆcï¼‰ ä¸ºè¿™ç§æƒ…å†µè®¾è®¡ä¸€ä¸ªå¥–åŠ±å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The domain concepts are those areas that the business believes have an impact on a customerâ€™s decision to churn.",
            "zh": "é¢†åŸŸæ¦‚å¿µæ˜¯ä¼ä¸šè®¤ä¸ºå¯¹å®¢æˆ·å®¢æˆ·æµå¤±å†³ç­–æœ‰å½±å“çš„é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "If we divide both sides of this equation by the prior probability on the left-hand side, P(Y), we get",
            "zh": "å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªæ–¹ç¨‹çš„ä¸¤è¾¹é™¤ä»¥å·¦ä¾§çš„å…ˆéªŒæ¦‚ç‡ Pï¼ˆYï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "Table B.1[758] lists a small dataset of instances from the sample space shown in Figure B.1[757]. We will use this example dataset to illustrate how to map the terminology of probability into the language of predictive analytics:",
            "zh": "è¡¨B.1[758]åˆ—å‡ºäº†å›¾B.1[757]æ‰€ç¤ºæ ·æœ¬ç©ºé—´ä¸­çš„ä¸€å°éƒ¨åˆ†å®ä¾‹æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ­¤ç¤ºä¾‹æ•°æ®é›†æ¥è¯´æ˜å¦‚ä½•å°†æ¦‚ç‡æœ¯è¯­æ˜ å°„åˆ°é¢„æµ‹åˆ†æçš„è¯­è¨€ä¸­ï¼š"
        }
    },
    {
        "translation": {
            "en": "S-I-R models, 644",
            "zh": "S-I-R å‹å·ï¼Œ644"
        }
    },
    {
        "translation": {
            "en": "One of the things that makes learning the structure of a Bayesian network so difficult is that it is possible to define several different Bayesian networks as representations for the same full joint probability distribution.",
            "zh": "å­¦ä¹ è´å¶æ–¯ç½‘ç»œç»“æ„å¦‚æ­¤å›°éš¾çš„åŸå› ä¹‹ä¸€æ˜¯ï¼Œå¯ä»¥å°†å‡ ä¸ªä¸åŒçš„è´å¶æ–¯ç½‘ç»œå®šä¹‰ä¸ºç›¸åŒå®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒçš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "It is also possible to directly illustrate the hierarchical nature of AHC using a dendrogram.",
            "zh": "ä¹Ÿå¯ä»¥ä½¿ç”¨æ ‘çŠ¶å›¾ç›´æ¥è¯´æ˜AHCçš„å±‚æ¬¡ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simple linear regression model we looked at in Section 7.2.1[312] handled only a single descriptive feature. Interesting problems in predictive analytics, however, are multivariable4 in nature. Fortunately, extending the simple linear regression model to a multivariable linear regression model is straightforward. We can define a multivariable linear regression model as",
            "zh": "æˆ‘ä»¬åœ¨ Section 7.2.1[312] ä¸­æŸ¥çœ‹çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹åªå¤„ç†äº†ä¸€ä¸ªæè¿°æ€§ç‰¹å¾ã€‚ç„¶è€Œï¼Œé¢„æµ‹åˆ†æä¸­æœ‰è¶£çš„é—®é¢˜æœ¬è´¨ä¸Šæ˜¯å¤šå˜é‡çš„4ã€‚å¹¸è¿çš„æ˜¯ï¼Œå°†ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹æ‰©å±•åˆ°å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹å¾ˆç®€å•ã€‚æˆ‘ä»¬å¯ä»¥å°†å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "This is a row vector that is created by subtracting each descriptive feature value of instance b from the corresponding feature values of a.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªè¡Œå‘é‡ï¼Œé€šè¿‡ä»å®ä¾‹ b çš„ç›¸åº”ç‰¹å¾å€¼ä¸­å‡å»å®ä¾‹ b çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾å€¼è€Œåˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive: a predictive descriptive feature provides information that is useful in estimating the correct value of a target feature.",
            "zh": "é¢„æµ‹æ€§ï¼šé¢„æµ‹æ€§æè¿°æ€§ç‰¹å¾æä¾›çš„ä¿¡æ¯å¯ç”¨äºä¼°è®¡ç›®æ ‡ç‰¹å¾çš„æ­£ç¡®å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "SHOP FREQUENCY",
            "zh": "åº—é“ºé¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "The network schematic on the right of Figure 8.37[502] illustrates the details of how neurons within the different layers of a specific example simple recurrent network are connected.",
            "zh": "å›¾8.37[502]å³ä¾§çš„ç½‘ç»œç¤ºæ„å›¾è¯´æ˜äº†ç‰¹å®šç¤ºä¾‹ç®€å•å¾ªç¯ç½‘ç»œçš„ä¸åŒå±‚å†…çš„ç¥ç»å…ƒå¦‚ä½•è¿æ¥çš„ç»†èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "range, 747",
            "zh": "èŒƒå›´ï¼Œ747"
        }
    },
    {
        "translation": {
            "en": "6.4.4â€…â€…â€…Bayesian Networks",
            "zh": "6.4.4 è´å¶æ–¯ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "Unsupervised learning presents us with a more complicated evaluation challenge than supervised learning.",
            "zh": "æ— ç›‘ç£å­¦ä¹ ç»™æˆ‘ä»¬å¸¦æ¥äº†æ¯”ç›‘ç£å­¦ä¹ æ›´å¤æ‚çš„è¯„ä¼°æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the instances have been sorted, we look for adjacent pairs that have different target levels. In Table 4.9[147] we can see that four pairs of adjacent instances have a transition between the target levels: instances d2 and d4, d4 and d3, d3 and d7, and d1 and d5. The boundary value between each of these pairs is simply the average of their ELEVATION values:",
            "zh": "å¯¹å®ä¾‹è¿›è¡Œæ’åºåï¼Œæˆ‘ä»¬å°†æŸ¥æ‰¾å…·æœ‰ä¸åŒç›®æ ‡çº§åˆ«çš„ç›¸é‚»å¯¹ã€‚åœ¨è¡¨ 4.9[147] ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å››å¯¹ç›¸é‚»å®ä¾‹åœ¨ç›®æ ‡çº§åˆ«ä¹‹é—´æœ‰è½¬æ¢ï¼šå®ä¾‹ d2 å’Œ d4ã€d4 å’Œ d3ã€d3 å’Œ d7 ä»¥åŠ d1 å’Œ d5ã€‚è¿™äº›å¯¹ä¹‹é—´çš„è¾¹ç•Œå€¼åªæ˜¯å…¶ ELEVATION å€¼çš„å¹³å‡å€¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "The information gain ratio is computed by dividing the information gain of a feature by the amount of information used to determine the value of the feature",
            "zh": "ä¿¡æ¯å¢ç›Šæ¯”çš„è®¡ç®—æ–¹æ³•æ˜¯å°†ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šé™¤ä»¥ç”¨äºç¡®å®šç‰¹å¾å€¼çš„ä¿¡æ¯é‡"
        }
    },
    {
        "translation": {
            "en": "3. One of the best-known and earliest applications of solving a problem by reducing the sum of squared errors occurred in 1801, when Carl Friedrich Gauss used it to minimize the measurement error in astronomical data and by doing so was able to extrapolate the position of the dwarf planet Ceres, which had recently been found but then was lost behind the glare of the sun.",
            "zh": "3. é€šè¿‡å‡å°‘å¹³æ–¹è¯¯å·®ä¹‹å’Œæ¥è§£å†³é—®é¢˜çš„æœ€è‘—åå’Œæœ€æ—©çš„åº”ç”¨ä¹‹ä¸€å‘ç”Ÿåœ¨ 1801 å¹´ï¼Œå½“æ—¶å¡å°”Â·å¼—é‡Œå¾·é‡Œå¸ŒÂ·é«˜æ–¯ ï¼ˆCarl Friedrich Gaussï¼‰ ç”¨å®ƒæ¥æœ€å°åŒ–å¤©æ–‡æ•°æ®ä¸­çš„æµ‹é‡è¯¯å·®ï¼Œå¹¶ç”±æ­¤èƒ½å¤Ÿæ¨æ–­å‡ºçŸ®è¡Œæ˜Ÿè°·ç¥æ˜Ÿçš„ä½ç½®ï¼Œè¿™é¢—è¡Œæ˜Ÿæœ€è¿‘è¢«å‘ç°ï¼Œä½†åæ¥æ¶ˆå¤±åœ¨å¤ªé˜³çš„çœ©å…‰åé¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "di refers to the descriptive features of the ith instance in a dataset.",
            "zh": "di æ˜¯æŒ‡æ•°æ®é›†ä¸­ç¬¬ i ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm is the most well-known approach to clustering.",
            "zh": "k-means èšç±»ç®—æ³•æ˜¯æœ€è‘—åçš„èšç±»æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "data management tools, 42",
            "zh": "æ•°æ®ç®¡ç†å·¥å…·ï¼Œ42"
        }
    },
    {
        "translation": {
            "en": "5.4.4â€…â€…â€…Predicting Continuous Targets",
            "zh": "5.4.4 é¢„æµ‹è¿ç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "After it has been trained to accurately encode its inputs into a low-dimensional space and then decode them back into the original feature space, an auto-encoder can be used for feature generation by focusing on the output of the first encoder part of the network.",
            "zh": "åœ¨è®­ç»ƒå…¶è¾“å…¥å‡†ç¡®ç¼–ç åˆ°ä½ç»´ç©ºé—´ï¼Œç„¶åå°†å®ƒä»¬è§£ç å›åŸå§‹ç‰¹å¾ç©ºé—´åï¼Œè‡ªåŠ¨ç¼–ç å™¨å¯ä»¥é€šè¿‡å…³æ³¨ç½‘ç»œç¬¬ä¸€ä¸ªç¼–ç å™¨éƒ¨åˆ†çš„è¾“å‡ºæ¥ç”¨äºç‰¹å¾ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "We use a subscript to identify the particular neuron that the Î´ is associated with; for example, Î´i is the Î´ for neuron i and is equivalent to the term .",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ä¸‹æ ‡æ¥è¯†åˆ«ä¸Î´ç›¸å…³çš„ç‰¹å®šç¥ç»å…ƒ;ä¾‹å¦‚ï¼ŒÎ´i æ˜¯ç¥ç»å…ƒ i çš„Î´ï¼Œç­‰ä»·äºé¡¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Long short-term memory (LSTM) networks have addressed instability in the propagation of weights through a sequential model by removing this repeated multiplication by the shared weights.",
            "zh": "é•¿çŸ­æœŸè®°å¿† ï¼ˆLSTMï¼‰ ç½‘ç»œé€šè¿‡é¡ºåºæ¨¡å‹æ¶ˆé™¤äº†å…±äº«æƒé‡çš„é‡å¤ä¹˜æ³•ï¼Œè§£å†³äº†æƒé‡ä¼ æ’­çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance is different from the other distance metrics we have looked at because it allows us to take into account how spread out the instances in a dataset are when judging similarities.",
            "zh": "é©¬æ°è·ç¦»ä¸æˆ‘ä»¬ç ”ç©¶è¿‡çš„å…¶ä»–è·ç¦»æŒ‡æ ‡ä¸åŒï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬åœ¨åˆ¤æ–­ç›¸ä¼¼æ€§æ—¶è€ƒè™‘æ•°æ®é›†ä¸­å®ä¾‹çš„åˆ†å¸ƒç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The silhouette described in the previous section, however, can be used effectively to achieve the latter, and this approach to choosing k is described in this section.",
            "zh": "ç„¶è€Œï¼Œä¸Šä¸€èŠ‚ä¸­æè¿°çš„è½®å»“å¯ä»¥æœ‰æ•ˆåœ°ç”¨äºå®ç°åè€…ï¼Œæœ¬èŠ‚å°†ä»‹ç»è¿™ç§é€‰æ‹© k çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SPEED and AGILITY ratings for 20 college athletes and whether they were drafted by a professional team.",
            "zh": "20 åå¤§å­¦è¿åŠ¨å‘˜çš„é€Ÿåº¦å’Œæ•æ·æ€§è¯„çº§ï¼Œä»¥åŠä»–ä»¬æ˜¯å¦ç”±ä¸“ä¸šå›¢é˜Ÿé€‰æ‹”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Modeling points in time for a scenario with no real outcome period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "å¯¹æ²¡æœ‰å®é™…ç»“æœå‘¨æœŸçš„åœºæ™¯çš„æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªå®¢æˆ·ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.8â€…â€…â€…The profit matrix for the payday loan credit scoring problem.",
            "zh": "9.8 å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜çš„åˆ©æ¶¦çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "KlubiÄka, Filip, Giancarlo D. Salton, and John D. Kelleher. 2018. Is it worth it? Budget-related evaluation metrics for model selection. In Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018).",
            "zh": "KlubiÄkaã€Filipã€Giancarlo D. Salton å’Œ John D. Kelleherã€‚2018. å€¼å¾—å—ï¼Ÿç”¨äºæ¨¡å‹é€‰æ‹©çš„é¢„ç®—ç›¸å…³è¯„ä¼°æŒ‡æ ‡ã€‚ç¬¬åä¸€å±Šè¯­è¨€èµ„æºä¸è¯„ä¼°å›½é™…ä¼šè®®ï¼ˆLREC 2018ï¼‰è®ºæ–‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, for any instance that is actually on the decision boundary, the RPM and VIBRATION values satisfy the equality in Equation (7.23)[339].",
            "zh": "å› æ­¤ï¼Œå¯¹äºä»»ä½•å®é™…ä½äºå†³ç­–è¾¹ç•Œä¸Šçš„å®ä¾‹ï¼ŒRPM å’Œ VIBRATION å€¼æ»¡è¶³ç­‰å¼ ï¼ˆ7.23ï¼‰[339] ä¸­çš„ç›¸ç­‰æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.13[296] illustrates a Bayesian network with a topology that encodes this causal theory.",
            "zh": "å›¾6.13[296]æ˜¾ç¤ºäº†ä¸€ä¸ªè´å¶æ–¯ç½‘ç»œï¼Œå…¶æ‹“æ‰‘ç»“æ„ç¼–ç äº†è¿™ç§å› æœç†è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, under Claimant Links, the Links with Other Claims and Links with Current Claim domain subconcepts highlight the fact that the links to or from this claimant can be broken down into links related to the current claim and links relating to other claims.",
            "zh": "åŒæ ·ï¼Œåœ¨â€œç´¢èµ”äººé“¾æ¥â€ä¸‹ï¼Œâ€œä¸å…¶ä»–æƒåˆ©è¦æ±‚çš„é“¾æ¥â€å’Œâ€œä¸å½“å‰æƒåˆ©è¦æ±‚åŸŸçš„é“¾æ¥â€å­æ¦‚å¿µçªå‡ºäº†è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³ä¸è¯¥ç´¢èµ”äººä¹‹é—´çš„é“¾æ¥å¯ä»¥åˆ†è§£ä¸ºä¸å½“å‰ç´¢èµ”ç›¸å…³çš„é“¾æ¥å’Œä¸å…¶ä»–ç´¢èµ”ç›¸å…³çš„é“¾æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, in each iteration of the training algorithm we will complete a single epoch (a single pass through our four examples and hence through the full dataset), and there will be a single weight update per epoch.",
            "zh": "å› æ­¤ï¼Œåœ¨è®­ç»ƒç®—æ³•çš„æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬å°†å®Œæˆä¸€ä¸ª epochï¼ˆé€šè¿‡æˆ‘ä»¬çš„å››ä¸ªç¤ºä¾‹è¿›è¡Œä¸€æ¬¡ä¼ é€’ï¼Œä»è€Œé€šè¿‡æ•´ä¸ªæ•°æ®é›†ï¼‰ï¼Œå¹¶ä¸”æ¯ä¸ª epoch å°†æœ‰ä¸€ä¸ªæƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we discuss extensions and variations of the naive Bayes model that increase its ability to generalize and avoid overfitting (smoothing) and that allow it to handle continuous descriptive features. We also describe Bayesian networks, which are a probability-based modeling approach that allows us to include more subtle assumptions in a model than the global assumption of conditional independence between all descriptive features that the naive Bayes model makes.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºæœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ‰©å±•å’Œå˜ä½“ï¼Œè¿™äº›æ‰©å±•å’Œå˜ä½“æé«˜äº†å…¶æ³›åŒ–å’Œé¿å…è¿‡åº¦æ‹Ÿåˆï¼ˆå¹³æ»‘ï¼‰çš„èƒ½åŠ›ï¼Œå¹¶å…è®¸å®ƒå¤„ç†è¿ç»­çš„æè¿°æ€§ç‰¹å¾ã€‚æˆ‘ä»¬è¿˜æè¿°äº†è´å¶æ–¯ç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¦‚ç‡çš„å»ºæ¨¡æ–¹æ³•ï¼Œå®ƒå…è®¸æˆ‘ä»¬åœ¨æ¨¡å‹ä¸­åŒ…å«æ¯”æœ´ç´ è´å¶æ–¯æ¨¡å‹æ‰€åšçš„æ‰€æœ‰æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§çš„å…¨å±€å‡è®¾æ›´å¾®å¦™çš„å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "business problem, 23",
            "zh": "ä¸šåŠ¡é—®é¢˜ï¼Œ 23"
        }
    },
    {
        "translation": {
            "en": "Occamâ€™s razor, 123, 292",
            "zh": "å¥¥å¡å§†å‰ƒåˆ€ï¼Œ123,292"
        }
    },
    {
        "translation": {
            "en": "46. This example is taken from (Mahalunkar and Kelleher, 2018), which reports on experiments that use formal grammars to understand the representational capacity of recurrent neural networks to model long-distance dependencies.",
            "zh": "46. è¿™ä¸ªä¾‹å­å–è‡ªï¼ˆMahalunkar and Kelleherï¼Œ 2018ï¼‰ï¼Œå®ƒæŠ¥å‘Šäº†ä½¿ç”¨å½¢å¼è¯­æ³•æ¥ç†è§£é€’å½’ç¥ç»ç½‘ç»œå¯¹é•¿è·ç¦»ä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡çš„è¡¨ç¤ºèƒ½åŠ›çš„å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, the third dimension of a filter is referred to as the depth of the filter, with the term channel specifically used to describe the depth of the data representation of a color image.",
            "zh": "é€šå¸¸ï¼Œæ»¤æ³¢å™¨çš„ç¬¬ä¸‰ä¸ªç»´åº¦ç§°ä¸ºæ»¤æ³¢å™¨çš„æ·±åº¦ï¼Œæœ¯è¯­é€šé“ä¸“é—¨ç”¨äºæè¿°å½©è‰²å›¾åƒçš„æ•°æ®è¡¨ç¤ºçš„æ·±åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Out of the candidate models shown, the third model from the top (with w[1] set to 0.62), passes most closely through the actual dataset and is the one that most accurately fits the relationship between office sizes and office rental pricesâ€”but how do we measure this formally?",
            "zh": "åœ¨æ‰€ç¤ºçš„å€™é€‰æ¨¡å‹ä¸­ï¼Œä»é¡¶éƒ¨å¼€å§‹çš„ç¬¬ä¸‰ä¸ªæ¨¡å‹ï¼ˆw[1] è®¾ç½®ä¸º 0.62ï¼‰æœ€æ¥è¿‘å®é™…æ•°æ®é›†ï¼Œå¹¶ä¸”æœ€å‡†ç¡®åœ°æ‹ŸåˆåŠå…¬å®¤è§„æ¨¡å’ŒåŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ä¹‹é—´çš„å…³ç³»â€”â€”ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•æ­£å¼è¡¡é‡è¿™ä¸€ç‚¹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature LOC and the target feature, PREFCHANNEL.",
            "zh": "ï¼ˆcï¼‰ ä¸‹é¢çš„å¯è§†åŒ–å›¾è¯´æ˜äº†åˆ†ç±»ç‰¹å¾ LOC ä¸ç›®æ ‡ç‰¹å¾ PREFCHANNEL ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2â€…â€…â€…The different question sequences that can follow in a game of Guess Who beginning with the question Does the person wear glasses?",
            "zh": "4.2 çŒœçŒœè°æ¸¸æˆä¸­å¯ä»¥éµå¾ªçš„ä¸åŒé—®é¢˜åºåˆ—ï¼Œä»é—®é¢˜å¼€å§‹ï¼šè¿™ä¸ªäººæˆ´çœ¼é•œå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "In cases in which a subtree is deemed to be overfitting, pruning the subtree means replacing the subtree with a leaf node that makes a prediction on the basis of the majority target feature level (or average target feature value) of the dataset created by merging the instances from all the leaf nodes in the subtree.",
            "zh": "åœ¨å­æ ‘è¢«è§†ä¸ºè¿‡æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œä¿®å‰ªå­æ ‘æ„å‘³ç€å°†å­æ ‘æ›¿æ¢ä¸ºå¶èŠ‚ç‚¹ï¼Œè¯¥å¶èŠ‚ç‚¹æ ¹æ®é€šè¿‡åˆå¹¶å­æ ‘ä¸­æ‰€æœ‰å¶èŠ‚ç‚¹çš„å®ä¾‹åˆ›å»ºçš„æ•°æ®é›†çš„å¤§å¤šæ•°ç›®æ ‡ç‰¹å¾çº§åˆ«ï¼ˆæˆ–å¹³å‡ç›®æ ‡ç‰¹å¾å€¼ï¼‰è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because a single consistent model cannot be found on the basis of the sample training dataset alone, we say that machine learning is fundamentally an ill-posed problem.",
            "zh": "å› ä¸ºä»…åŸºäºæ ·æœ¬è®­ç»ƒæ•°æ®é›†æ— æ³•æ‰¾åˆ°ä¸€ä¸ªå•ä¸€çš„ä¸€è‡´æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´æœºå™¨å­¦ä¹ ä»æ ¹æœ¬ä¸Šè¯´æ˜¯ä¸€ä¸ªç—…æ€çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "CMODELFLUX_U/G/R/I/Z",
            "zh": "CMODELFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "In this way the revenue commission hopes to maximize the yield from the audits that it performs.",
            "zh": "é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ”¶å…¥å§”å‘˜ä¼šå¸Œæœ›æœ€å¤§é™åº¦åœ°æé«˜å…¶æ‰§è¡Œçš„å®¡è®¡çš„æ”¶ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "1. a dot product between the information stored in the memory buffer (the hidden layer activations from the previous time-step encoded as vector htâˆ’1) and the weight matrix for the weights on the connections from the memory buffer to the hidden neurons;",
            "zh": "1. å­˜å‚¨åœ¨å†…å­˜ç¼“å†²åŒºä¸­çš„ä¿¡æ¯ï¼ˆç¼–ç ä¸ºå‘é‡ HT-1 çš„å‰ä¸€ä¸ªæ—¶é—´æ­¥é•¿çš„éšè—å±‚æ¿€æ´»ï¼‰ä¸ä»å†…å­˜ç¼“å†²åŒºåˆ°éšè—ç¥ç»å…ƒçš„è¿æ¥ä¸Šçš„æƒé‡çš„æƒé‡çŸ©é˜µä¹‹é—´çš„ç‚¹ç§¯;"
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic index, 558, 561, 586, 593",
            "zh": "æ¥æ”¶æœºå·¥ä½œç‰¹å¾æŒ‡æ•°ï¼Œ558ã€561ã€586ã€593"
        }
    },
    {
        "translation": {
            "en": "In fact, swallows migrate to warmer countries, windmills are made to spin by wind, and tall people often choose to play basketball because of the advantage their height gives them in that game.",
            "zh": "äº‹å®ä¸Šï¼Œç‡•å­ä¼šè¿å¾™åˆ°æ¸©æš–çš„å›½å®¶ï¼Œé£è½¦ä¼šè¢«é£å¹åŠ¨ï¼Œé«˜ä¸ªå­ç»å¸¸é€‰æ‹©æ‰“ç¯®çƒï¼Œå› ä¸ºä»–ä»¬çš„èº«é«˜åœ¨æ¯”èµ›ä¸­ç»™ä»–ä»¬å¸¦æ¥äº†ä¼˜åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of a greedy action selection policy.",
            "zh": "è¿™æ˜¯è´ªå©ªæ“ä½œé€‰æ‹©ç­–ç•¥çš„ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Observation and outcome periods defined by an event rather than by a fixed point in time (each line represents a prediction subject, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "ç”±äº‹ä»¶è€Œä¸æ˜¯ç”±å›ºå®šæ—¶é—´ç‚¹å®šä¹‰çš„è§‚æµ‹å’Œç»“æœå‘¨æœŸï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ä¸»é¢˜ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can measure the sampling density across a feature space in terms of the average density of a unit hypercube26 in the feature space.",
            "zh": "æˆ‘ä»¬å¯ä»¥æ ¹æ®ç‰¹å¾ç©ºé—´ä¸­å•ä½è¶…ç«‹æ–¹ä½“ 26 çš„å¹³å‡å¯†åº¦æ¥æµ‹é‡ç‰¹å¾ç©ºé—´ä¸­çš„é‡‡æ ·å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Preparation",
            "zh": "åˆ¶å¤‡"
        }
    },
    {
        "translation": {
            "en": "We will use an example from social science to illustrate how to construct a causal graph using this hybrid approach. In this example, we will build a Bayesian network that enables us to predict the level of corruption in a country based on a number of macroeconomic and social descriptive features. Table 6.18[295] lists some countries described using the following features:26",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨ç¤¾ä¼šç§‘å­¦ä¸­çš„ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨è¿™ç§æ··åˆæ–¹æ³•æ„å»ºå› æœå›¾ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªè´å¶æ–¯ç½‘ç»œï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ ¹æ®ä¸€äº›å®è§‚ç»æµå’Œç¤¾ä¼šæè¿°æ€§ç‰¹å¾æ¥é¢„æµ‹ä¸€ä¸ªå›½å®¶çš„è…è´¥ç¨‹åº¦ã€‚è¡¨6.18[295]åˆ—å‡ºäº†ä¸€äº›ä½¿ç”¨ä»¥ä¸‹ç‰¹å¾æè¿°çš„å›½å®¶ï¼š26"
        }
    },
    {
        "translation": {
            "en": "The 6 and 9 partitions each contain just one instance.",
            "zh": "6 å’Œ 9 åˆ†åŒºå„åªåŒ…å«ä¸€ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "measures of similarity, 181",
            "zh": "ç›¸ä¼¼åº¦é‡ï¼Œ181"
        }
    },
    {
        "translation": {
            "en": "(b) If you used a 1-NN model, what class would be assigned to the mystery animal?",
            "zh": "ï¼ˆä¹™ï¼‰å‡å¦‚ä½ ä½¿ç”¨1-NNæ¨¡å‹ï¼Œç¥ç§˜åŠ¨ç‰©ä¼šè¢«åˆ†åˆ°ä»€ä¹ˆç±»åˆ«ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "error rate, 155",
            "zh": "é”™è¯¯ç‡ï¼Œ155"
        }
    },
    {
        "translation": {
            "en": "To illustrate how this is done, we use a modified version of the vegetation classification dataset given in Table 4.3[136] in which the ELEVATION feature now contains actual elevations in feet.",
            "zh": "ä¸ºäº†è¯´æ˜å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¡¨ 4.3[136] ä¸­ç»™å‡ºçš„æ¤è¢«åˆ†ç±»æ•°æ®é›†çš„ä¿®æ”¹ç‰ˆæœ¬ï¼Œå…¶ä¸­ ELEVATION è¦ç´ ç°åœ¨åŒ…å«ä»¥è‹±å°ºä¸ºå•ä½çš„å®é™…é«˜ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is relatively standard in image processing to use ReLUs for the network, and so we assume throughout this section that the neurons use the rectified linear function as their activation function.",
            "zh": "åœ¨å›¾åƒå¤„ç†ä¸­ï¼Œå°† ReLU ç”¨äºç½‘ç»œæ˜¯ç›¸å¯¹æ ‡å‡†çš„ï¼Œå› æ­¤æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­å‡è®¾ç¥ç»å…ƒä½¿ç”¨æ ¡æ­£çš„çº¿æ€§å‡½æ•°ä½œä¸ºå®ƒä»¬çš„æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. In fact,it can be argued that a preference toward shallower decision trees is a good idea in general and can be viewed as following Occamâ€™s razor. Occamâ€™s razor is the principle of keeping theories as simple as possible. It is named after a 14th-century Franciscan monk, William of Occam (sometimes spelled Ockham), who was one of the first to formulate this principle. The razor in the title comes from the idea of shaving off any unnecessary assumptions from a theory.",
            "zh": "2. äº‹å®ä¸Šï¼Œå¯ä»¥è¯´ï¼Œåçˆ±è¾ƒæµ…çš„å†³ç­–æ ‘æ€»ä½“ä¸Šæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå¯ä»¥è¢«è§†ä¸ºéµå¾ªå¥¥å¡å§†å‰ƒåˆ€ã€‚å¥¥å¡å§†å‰ƒåˆ€æ˜¯ä¿æŒç†è®ºå°½å¯èƒ½ç®€å•çš„åŸåˆ™ã€‚å®ƒä»¥ 14 ä¸–çºªçš„æ–¹æµå„ä¼šä¿®é“å£«å¥¥å¡å§†çš„å¨å»‰ï¼ˆæœ‰æ—¶æ‹¼å†™ä¸ºå¥¥å¡å§†ï¼‰çš„åå­—å‘½åï¼Œä»–æ˜¯æœ€æ—©åˆ¶å®šè¿™ä¸€åŸåˆ™çš„äººä¹‹ä¸€ã€‚æ ‡é¢˜ä¸­çš„å‰ƒé¡»åˆ€æ¥è‡ªä»ç†è®ºä¸­å»é™¤ä»»ä½•ä¸å¿…è¦çš„å‡è®¾çš„æƒ³æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors is a particularly convenient error function to use because the model errors on different examples and also the errors on different outputs (e.g., consider a network that has multiple neurons in the output layer) are independent and therefore the overall error is just the sum of the individual errors.",
            "zh": "å¹³æ–¹è¯¯å·®ä¹‹å’Œæ˜¯ä¸€ä¸ªç‰¹åˆ«æ–¹ä¾¿ä½¿ç”¨çš„è¯¯å·®å‡½æ•°ï¼Œå› ä¸ºä¸åŒç¤ºä¾‹ä¸Šçš„æ¨¡å‹è¯¯å·®ä»¥åŠä¸åŒè¾“å‡ºä¸Šçš„è¯¯å·®ï¼ˆä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªåœ¨è¾“å‡ºå±‚ä¸­æœ‰å¤šä¸ªç¥ç»å…ƒçš„ç½‘ç»œï¼‰æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤æ€»ä½“è¯¯å·®åªæ˜¯å•ä¸ªè¯¯å·®çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2.3â€ƒAverage class accuracyâ€ƒClassification accuracy can mask poor performance.",
            "zh": "9.4.2.3 å¹³å‡ç±»å‡†ç¡®ç‡ åˆ†ç±»å‡†ç¡®åº¦å¯ä»¥æ©ç›–æ€§èƒ½ä¸ä½³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Anscombeâ€™s quartet, 84",
            "zh": "å®‰æ–¯ç§‘å§†çš„å››é‡å¥ï¼Œ84"
        }
    },
    {
        "translation": {
            "en": "6.1â€ƒBig Idea",
            "zh": "6.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "Table 8.1",
            "zh": "è¡¨ 8.1"
        }
    },
    {
        "translation": {
            "en": "Wrapper approaches are more computationally expensive than filters, as they involve training multiple models during each iteration.",
            "zh": "åŒ…è£…å™¨æ–¹æ³•çš„è®¡ç®—æˆæœ¬é«˜äºè¿‡æ»¤å™¨ï¼Œå› ä¸ºå®ƒä»¬æ¶‰åŠåœ¨æ¯æ¬¡è¿­ä»£æœŸé—´è®­ç»ƒå¤šä¸ªæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate the vector of gradients âˆ‚â„°t/âˆ‚htâˆ’1, we first need to calculate the error gradient with respect to changes in hxt for each of the four layers of neurons that receive hxt as input: the forget gate sigmoid layer, the input gate sigmoid layer, the input gate tanh layer, and the output gate sigmoid layer.",
            "zh": "ä¸ºäº†è®¡ç®—æ¢¯åº¦å‘é‡ âˆ‚Et/âˆ‚htâˆ’1ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è®¡ç®—æ¥æ”¶ hxt ä½œä¸ºè¾“å…¥çš„å››å±‚ç¥ç»å…ƒä¸­æ¯ä¸€å±‚çš„ hxt å˜åŒ–çš„è¯¯å·®æ¢¯åº¦ï¼šå¿˜è®°é—¨ S å½¢ç»“è‚ å±‚ã€è¾“å…¥é—¨ S å½¢ç»“è‚ å±‚ã€è¾“å…¥é—¨ Tanh å±‚å’Œè¾“å‡ºé—¨ S å½¢ç»“è‚ å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(b)[620] shows an updated distance matrix including 10.",
            "zh": "è¡¨10.5ï¼ˆbï¼‰[620]æ˜¾ç¤ºäº†åŒ…æ‹¬10åœ¨å†…çš„æ›´æ–°è·ç¦»çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7",
            "zh": "å›¾ 4.7"
        }
    },
    {
        "translation": {
            "en": "That said, filter approaches are faster and often result in models with good accuracy.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼Œæ»¤æ³¢æ–¹æ³•é€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”é€šå¸¸ä¼šäº§ç”Ÿå…·æœ‰è‰¯å¥½ç²¾åº¦çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, feature selection is a particularly important process for nearest neighbor algorithms.",
            "zh": "å› æ­¤ï¼Œç‰¹å¾é€‰æ‹©å¯¹äºæœ€è¿‘é‚»ç®—æ³•æ¥è¯´æ˜¯ä¸€ä¸ªç‰¹åˆ«é‡è¦çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.9â€…â€…â€…Example of using small multiple histograms to visualize the relationship between a categorical feature and a continuous feature. All examples use data from the professional basketball team dataset in Table 3.7[73]: (a) a histogram of the AGE feature; (b) a histogram of the HEIGHT feature; (c) histograms of the AGE feature for instances displaying each level of the POSITION feature; and (d) histograms of the HEIGHT feature for instances displaying each level of the POSITION feature.",
            "zh": "3.9 ä½¿ç”¨å°çš„å¤šä¸ªç›´æ–¹å›¾å¯è§†åŒ–åˆ†ç±»ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ä¹‹é—´å…³ç³»çš„ç¤ºä¾‹ã€‚æ‰€æœ‰ç¤ºä¾‹å‡ä½¿ç”¨è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†çš„æ•°æ®ï¼šï¼ˆaï¼‰AGEç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆbï¼‰ é«˜åº¦ç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆcï¼‰ æ˜¾ç¤º POSITION ç‰¹å¾æ¯ä¸ªçº§åˆ«çš„å®ä¾‹çš„ AGE ç‰¹å¾ç›´æ–¹å›¾;ä»¥åŠ ï¼ˆdï¼‰ æ˜¾ç¤º POSITION ç‰¹å¾æ¯ä¸ªçº§åˆ«çš„å®ä¾‹çš„ HEIGHT ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "She generated two possible target features from the data provided.",
            "zh": "å¥¹æ ¹æ®æä¾›çš„æ•°æ®ç”Ÿæˆäº†ä¸¤ä¸ªå¯èƒ½çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.8[398] illustrates the distinction between linearly separable and non-linearly separable functions, using examples from Boolean logic: AND, OR, and XOR functions.",
            "zh": "å›¾ 8.8[398] ä½¿ç”¨å¸ƒå°”é€»è¾‘ç¤ºä¾‹è¯´æ˜äº†çº¿æ€§å¯åˆ†ç¦»å‡½æ•°å’Œéçº¿æ€§å¯åˆ†ç¦»å‡½æ•°ä¹‹é—´çš„åŒºåˆ«ï¼šANDã€OR å’Œ XOR å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Quinn, Graham E., Chai H. Shin, Maureen G. Maguire, and Richard A. Stone. 1999. Myopia and ambient lighting at night. Nature 399 (6732): 113â€“114. http://dx.doi.org/10.1038/20094.",
            "zh": "å¥å› ã€æ ¼é›·å„å§† E.ã€æŸ´ H. è¾›ã€è«ç³ G. é©¬å¥å°”å’Œç†æŸ¥å¾· A. æ–¯é€šã€‚1999. è¿‘è§†å’Œå¤œé—´ç¯å¢ƒç…§æ˜.è‡ªç„¶399ï¼ˆ6732ï¼‰ï¼š113-114ã€‚http://dx.doi.org/10.1038/20094ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is also an array of modifiable risk factors, including alcohol and drug use, unhealthy diet, stress and depression, and lack of physical exercise.",
            "zh": "è¿˜æœ‰ä¸€ç³»åˆ—å¯æ”¹å˜çš„é£é™©å› ç´ ï¼ŒåŒ…æ‹¬é…—é…’å’Œå¸æ¯’ã€ä¸å¥åº·çš„é¥®é£Ÿã€å‹åŠ›å’ŒæŠ‘éƒä»¥åŠç¼ºä¹ä½“è‚²é”»ç‚¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In generating this figure we have assumed that the algorithm selected the features to split on using the following ordering over the features: SPEED, AGILITY.",
            "zh": "åœ¨ç”Ÿæˆæ­¤å›¾æ—¶ï¼Œæˆ‘ä»¬å‡è®¾ç®—æ³•ä½¿ç”¨ä»¥ä¸‹ç‰¹å¾æ’åºæ¥é€‰æ‹©è¦æ‹†åˆ†çš„ç‰¹å¾ï¼šé€Ÿåº¦ã€æ•æ·æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, at each node the algorithm will choose the feature to split on by selecting the feature with the lowest weighted variance for the target feature",
            "zh": "å› æ­¤ï¼Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šï¼Œç®—æ³•å°†é€šè¿‡é€‰æ‹©ç›®æ ‡ç‰¹å¾åŠ æƒæ–¹å·®æœ€ä½çš„ç‰¹å¾æ¥é€‰æ‹©è¦æ‹†åˆ†çš„ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the 5-level two-stage model (classification accuracy: 79.410%, average class accuracy: 53.118%).",
            "zh": "5çº§ä¸¤é˜¶æ®µæ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š79.410%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š53.118%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Appendix D is a new section covering the fundamentals of linear algebra that underpin the new chapter on deep learning.",
            "zh": "é™„å½• D æ˜¯ä¸€ä¸ªæ–°ç« èŠ‚ï¼Œæ¶µç›–äº†çº¿æ€§ä»£æ•°çš„åŸºç¡€çŸ¥è¯†ï¼Œæ”¯æ’‘äº†æ·±åº¦å­¦ä¹ çš„æ–°ç« èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "FIBER2FLUXIVAR_U/G/R/I/Z",
            "zh": "FIBER2FLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "5.4.5.4â€ƒSummaryâ€ƒIn this section we have introduced a number of commonly used metrics and indexes for judging similarity between instances in a feature space.",
            "zh": "5.4.5.4 å°ç»“ åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€äº›å¸¸ç”¨çš„æŒ‡æ ‡å’Œç´¢å¼•ï¼Œç”¨äºåˆ¤æ–­ç‰¹å¾ç©ºé—´ä¸­å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we increase the number of descriptive features, the dimensionality of the feature space increases.",
            "zh": "å¦‚æœæˆ‘ä»¬å¢åŠ æè¿°æ€§ç‰¹å¾çš„æ•°é‡ï¼Œç‰¹å¾ç©ºé—´çš„ç»´æ•°å°±ä¼šå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "d_r0",
            "zh": "d_r0"
        }
    },
    {
        "translation": {
            "en": "In this example, is it better to classify a galaxy that should be other as an elliptical galaxy or vice versa?",
            "zh": "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå°†ä¸€ä¸ªåº”è¯¥æ˜¯å…¶ä»–æ˜Ÿç³»çš„æ˜Ÿç³»å½’ç±»ä¸ºæ¤­åœ†æ˜Ÿç³»æ›´å¥½ï¼Œåä¹‹äº¦ç„¶å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "In either case, the search continues from the new node as before.",
            "zh": "æ— è®ºå“ªç§æƒ…å†µï¼Œæœç´¢éƒ½ä¼šåƒä»¥å‰ä¸€æ ·ä»æ–°èŠ‚ç‚¹ç»§ç»­ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.18(e)[226] we have, again, maintained the sampling density (the density of the marked unit hypercube is ) at the expense of a very large increase in the number of instancesâ€”there are 29 Ã— 29 Ã— 29 = 24,389 instances in this figure!",
            "zh": "åœ¨å›¾ 5.18ï¼ˆeï¼‰[226] ä¸­ï¼Œæˆ‘ä»¬å†æ¬¡ä¿æŒäº†é‡‡æ ·å¯†åº¦ï¼ˆæ ‡è®°å•ä½è¶…ç«‹æ–¹ä½“çš„å¯†åº¦ä¸º ï¼‰ï¼Œä½†ä»£ä»·æ˜¯å®ä¾‹æ•°é‡çš„å¤§å¹…å¢åŠ â€”â€”æ­¤å›¾ä¸­æœ‰ 29 ä¸ªÃ— 29 ä¸ªÃ— 29 = 24,389 ä¸ªå®ä¾‹ï¼"
        }
    },
    {
        "translation": {
            "en": "Price Prediction: Businesses such as hotel chains, airlines, and online retailers need to constantly adjust their prices in order to maximize returns based on factors such as seasonal changes, shifting customer demand, and the occurrence of special events. Predictive analytics models can be trained to predict optimal prices on the basis of historical sales records. Businesses can then use these predictions as an input into their pricing strategy decisions.",
            "zh": "ä»·æ ¼é¢„æµ‹ï¼šè¿é”é…’åº—ã€èˆªç©ºå…¬å¸å’Œåœ¨çº¿é›¶å”®å•†ç­‰ä¼ä¸šéœ€è¦ä¸æ–­è°ƒæ•´ä»·æ ¼ï¼Œä»¥ä¾¿æ ¹æ®å­£èŠ‚å˜åŒ–ã€å®¢æˆ·éœ€æ±‚å˜åŒ–å’Œç‰¹æ®Šäº‹ä»¶çš„å‘ç”Ÿç­‰å› ç´ å®ç°å›æŠ¥æœ€å¤§åŒ–ã€‚å¯ä»¥è®­ç»ƒé¢„æµ‹åˆ†ææ¨¡å‹ï¼Œä»¥æ ¹æ®å†å²é”€å”®è®°å½•é¢„æµ‹æœ€ä½³ä»·æ ¼ã€‚ç„¶åï¼Œä¼ä¸šå¯ä»¥å°†è¿™äº›é¢„æµ‹ç”¨ä½œå…¶å®šä»·ç­–ç•¥å†³ç­–çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use a value from a PDF as a relative measure of likelihood because when the interval is very small, the actual area under a PDF curve for that interval can be approximated (with a small error proportional to the width of the interval) by the height of the PDF curve at the center of the interval multiplied by the width of the interval.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ PDF ä¸­çš„å€¼ä½œä¸ºä¼¼ç„¶çš„ç›¸å¯¹åº¦é‡ï¼Œå› ä¸ºå½“åŒºé—´éå¸¸å°æ—¶ï¼Œè¯¥åŒºé—´çš„ PDF æ›²çº¿ä¸‹çš„å®é™…é¢ç§¯å¯ä»¥è¿‘ä¼¼ï¼ˆä¸åŒºé—´å®½åº¦æˆæ­£æ¯”çš„å°è¯¯å·®ï¼‰ä¹˜ä»¥åŒºé—´ä¸­å¿ƒçš„ PDF æ›²çº¿é«˜åº¦ä¹˜ä»¥åŒºé—´çš„å®½åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "chain rule (differentiation), 312, 325, 345, 381, 410, 413, 435, 731, 765, 768",
            "zh": "é“¾å¼æ³•åˆ™ï¼ˆå¾®åˆ†ï¼‰ï¼Œ 312ï¼Œ 325ï¼Œ 345ï¼Œ 381ï¼Œ 410ï¼Œ 413ï¼Œ 435ï¼Œ 731ï¼Œ 765ï¼Œ 768"
        }
    },
    {
        "translation": {
            "en": "symmetry criterion, 184, 211",
            "zh": "å¯¹ç§°å‡†åˆ™ï¼Œ184,211"
        }
    },
    {
        "translation": {
            "en": "If we compare this decision tree to the decision tree generated using information gain (see Figure 4.11[141]), it is obvious that the structure of the two trees is very different.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªå†³ç­–æ ‘ä¸ä½¿ç”¨ä¿¡æ¯å¢ç›Šç”Ÿæˆçš„å†³ç­–æ ‘è¿›è¡Œæ¯”è¾ƒï¼ˆè§å›¾4.11[141]ï¼‰ï¼Œå¾ˆæ˜æ˜¾ï¼Œè¿™ä¸¤ä¸ªæ ‘çš„ç»“æ„éå¸¸ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4(b)[190] illustrates the decision boundary within the feature space for the two target levels in the college athlete dataset.",
            "zh": "å›¾ 5.4ï¼ˆbï¼‰[190] è¯´æ˜äº†å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†ä¸­ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„ç‰¹å¾ç©ºé—´å†…çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "4.17â€…â€…â€…The final decision tree induced from the dataset in Table 4.11[152]. To illustrate how the tree generates predictions, this tree lists the instances that ended up at each leaf node and the prediction (PRED.) made by each leaf node.",
            "zh": "4.17 ä»è¡¨4.11[152]ä¸­çš„æ•°æ®é›†ä¸­å¾—å‡ºçš„æœ€ç»ˆå†³ç­–æ ‘ã€‚ä¸ºäº†è¯´æ˜æ ‘å¦‚ä½•ç”Ÿæˆé¢„æµ‹ï¼Œæ­¤æ ‘åˆ—å‡ºäº†æœ€ç»ˆå‡ºç°åœ¨æ¯ä¸ªå¶èŠ‚ç‚¹ä¸Šçš„å®ä¾‹ä»¥åŠæ¯ä¸ªå¶èŠ‚ç‚¹æ‰€åšçš„é¢„æµ‹ ï¼ˆPRED.ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many of these methods make an assumption that a good clustering is a clustering in which the instances that belong to a given cluster are very close together, whereas the instances that belong to different clusters are far apart.",
            "zh": "å…¶ä¸­è®¸å¤šæ–¹æ³•éƒ½å‡è®¾ä¸€ä¸ªå¥½çš„èšç±»æ˜¯ä¸€ç§èšç±»ï¼Œå…¶ä¸­å±äºç»™å®šèšç±»çš„å®ä¾‹éå¸¸æ¥è¿‘ï¼Œè€Œå±äºä¸åŒèšç±»çš„å®ä¾‹ç›¸è·å¾ˆè¿œã€‚"
        }
    },
    {
        "translation": {
            "en": "This has the advantage that the outputs of the network do not have to be transformed back into the original target feature range.",
            "zh": "è¿™æ ·åšçš„ä¼˜ç‚¹æ˜¯ï¼Œç½‘ç»œçš„è¾“å‡ºä¸å¿…è½¬æ¢å›åŸå§‹ç›®æ ‡ç‰¹å¾èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The insurance claims fraud scenario we have been discussing throughout this section is a good example of this.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­è®¨è®ºçš„ä¿é™©ç´¢èµ”æ¬ºè¯ˆåœºæ™¯å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.2â€…â€…â€…Probability Distributions and Summing Out",
            "zh": "B.2 æ¦‚ç‡åˆ†å¸ƒå’Œæ±‚å’Œ"
        }
    },
    {
        "translation": {
            "en": "49. Forthis discussion we treat all neurons in an unrolled network that use the same set of weights as instances of the same neuron; for example, for a neuron in the hidden layer, a different instance of that neuron will occur in each time-step.",
            "zh": "49. åœ¨è¿™æ¬¡è®¨è®ºä¸­ï¼Œæˆ‘ä»¬å°†å±•å¼€ç½‘ç»œä¸­ä½¿ç”¨ç›¸åŒæƒé‡é›†çš„æ‰€æœ‰ç¥ç»å…ƒè§†ä¸ºåŒä¸€ç¥ç»å…ƒçš„å®ä¾‹;ä¾‹å¦‚ï¼Œå¯¹äºéšè—å±‚ä¸­çš„ç¥ç»å…ƒï¼Œè¯¥ç¥ç»å…ƒçš„ä¸åŒå®ä¾‹å°†åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸­å‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "z-score, 87",
            "zh": "Z-åˆ†æ•°ï¼Œ87"
        }
    },
    {
        "translation": {
            "en": "Figure 4.10[140] illustrates the state of the decision tree after 8 has been split.",
            "zh": "å›¾ 4.10[140] è¯´æ˜äº† 8 æ‹†åˆ†åå†³ç­–æ ‘çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Twenty people flip a fair coin. What is the probability that at least four of them will get heads?",
            "zh": "ï¼ˆcï¼‰ äºŒåä¸ªäººæ·ä¸€æšå…¬å¹³çš„ç¡¬å¸ã€‚ä»–ä»¬ä¸­è‡³å°‘æœ‰å››ä¸ªäººè·å¾—å¤´éƒ¨çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "11. The MAP prediction is the prediction mechanism that we assume throughout this book. An alternative mechanism is the Bayesian optimal classifier, but we wonâ€™t discuss it in this text. See Mitchell (1997) for more details.",
            "zh": "11. MAPé¢„æµ‹æ˜¯æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­å‡è®¾çš„é¢„æµ‹æœºåˆ¶ã€‚å¦ä¸€ç§æœºåˆ¶æ˜¯è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨ï¼Œä½†æœ¬æ–‡ä¸­æˆ‘ä»¬ä¸ä¼šè®¨è®ºå®ƒã€‚è¯¦è§Mitchell ï¼ˆ1997ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are also very grateful to the anonymous reviewers who provided insightful and helpful comments on early drafts of the manuscript.",
            "zh": "æˆ‘ä»¬ä¹Ÿéå¸¸æ„Ÿè°¢åŒ¿åå®¡ç¨¿äººï¼Œä»–ä»¬å¯¹æ‰‹ç¨¿çš„æ—©æœŸè‰ç¨¿æä¾›äº†æœ‰è§åœ°å’Œæœ‰ç›Šçš„æ„è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "MODULE 2",
            "zh": "æ¨¡å— 2"
        }
    },
    {
        "translation": {
            "en": "These new features can then be used to encode a level of the original categorical descriptive feature by setting the value of the new feature corresponding to the level of the categorical feature to 1 and the other new continuous features to 0.",
            "zh": "ç„¶åï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›æ–°ç‰¹å¾å¯¹åŸå§‹åˆ†ç±»æè¿°æ€§ç‰¹å¾çš„çº§åˆ«è¿›è¡Œç¼–ç ï¼Œæ–¹æ³•æ˜¯å°†ä¸åˆ†ç±»ç‰¹å¾çº§åˆ«å¯¹åº”çš„æ–°ç‰¹å¾çš„å€¼è®¾ç½®ä¸º 1ï¼Œå¹¶å°†å…¶ä»–æ–°çš„è¿ç»­ç‰¹å¾è®¾ç½®ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the constraints and optimization criterion have been defined, the solution to the constrained quadratic optimization process will identify and define all the components in Equation (7.41)[363] (the support vectors, w 0, and the Î± parameters) for the optimal decision boundary.",
            "zh": "ä¸€æ—¦å®šä¹‰äº†çº¦æŸæ¡ä»¶å’Œä¼˜åŒ–å‡†åˆ™ï¼Œçº¦æŸäºŒæ¬¡ä¼˜åŒ–è¿‡ç¨‹çš„è§£å°†è¯†åˆ«å¹¶å®šä¹‰æ–¹ç¨‹ï¼ˆ7.41ï¼‰[363]ä¸­çš„æ‰€æœ‰åˆ†é‡ï¼ˆæ”¯æŒå‘é‡ã€w 0 å’Œ Î± å‚æ•°ï¼‰ä»¥è·å¾—æœ€ä¼˜å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Compare the sentences â€œThe dog in that house is aggressiveâ€ with â€œThe dogs in that house are aggressive.â€ In the first sentence, the subject of the sentence is singular, dog, and so we use the singular form of the verb is; in the second sentence, the subject is plural, dogs, and so we use the plural form of the verb are.46 Processing data of this type requires a model that has the capacity to remember relevant information from earlier in the sequence.",
            "zh": "æ¯”è¾ƒå¥å­â€œé‚£æ‰€æˆ¿å­é‡Œçš„ç‹—å¾ˆæœ‰æ”»å‡»æ€§â€å’Œâ€œé‚£æ‰€æˆ¿å­é‡Œçš„ç‹—å¾ˆæœ‰æ”»å‡»æ€§â€ã€‚åœ¨ç¬¬ä¸€å¥è¯ä¸­ï¼Œå¥å­çš„ä¸»è¯­æ˜¯å•æ•°ï¼Œç‹—ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨åŠ¨è¯çš„å•æ•°å½¢å¼æ˜¯;åœ¨ç¬¬äºŒå¥è¯ä¸­ï¼Œä¸»è¯­æ˜¯å¤æ•°ï¼Œç‹—ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨åŠ¨è¯çš„å¤æ•°å½¢å¼are.46å¤„ç†è¿™ç§ç±»å‹çš„æ•°æ®éœ€è¦ä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè®°ä½åºåˆ—ä¸­å‰é¢çš„ç›¸å…³ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we will generate two sets of error gradients when we backpropagate through an elementwise vector product, one for each branch of data that flows into the product.",
            "zh": "è¿™æ„å‘³ç€å½“æˆ‘ä»¬é€šè¿‡é€å…ƒç´ å‘é‡ä¹˜ç§¯åå‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¸¤ç»„è¯¯å·®æ¢¯åº¦ï¼Œæ¯ç»„ç”¨äºæµå…¥ä¹˜ç§¯çš„æ¯ä¸ªæ•°æ®åˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "What evaluation process will we follow? What performance measures will we use? Is the model fit for purpose?",
            "zh": "æˆ‘ä»¬å°†éµå¾ªä»€ä¹ˆè¯„ä¼°æµç¨‹ï¼Ÿæˆ‘ä»¬å°†ä½¿ç”¨å“ªäº›ç»©æ•ˆè¡¡é‡æ ‡å‡†ï¼Ÿè¯¥æ¨¡å‹æ˜¯å¦é€‚åˆç›®çš„ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "partial derivative, 312, 318, 381, 765, 768",
            "zh": "åå¯¼æ•°ï¼Œ 312ï¼Œ 318ï¼Œ 381ï¼Œ 765ï¼Œ 768"
        }
    },
    {
        "translation": {
            "en": "where dec refers to a particular decile. Table 9.16[568] shows how gain is calculated for each decile in the email classification test set. The number of positive and negative instances in each decile is shown. Based on these numbers, the gain for each decile is calculated using Equation (9.19)[567] (the calculation of some other measures are also included in this table, and these will be explained shortly).",
            "zh": "å…¶ä¸­ dec æ˜¯æŒ‡ç‰¹å®šçš„ååˆ†ä½æ•°ã€‚è¡¨ 9.16[568] æ˜¾ç¤ºäº†å¦‚ä½•è®¡ç®—ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†ä¸­æ¯ä¸ªååˆ†ä½æ•°çš„å¢ç›Šã€‚æ˜¾ç¤ºäº†æ¯ä¸ªååˆ†ä½æ•°ä¸­çš„æ­£å®ä¾‹å’Œè´Ÿå®ä¾‹æ•°ã€‚æ ¹æ®è¿™äº›æ•°å­—ï¼Œä½¿ç”¨å…¬å¼ï¼ˆ9.19ï¼‰[567]è®¡ç®—æ¯ä¸ªååˆ†ä½æ•°çš„å¢ç›Šï¼ˆæ­¤è¡¨ä¸­è¿˜åŒ…æ‹¬å…¶ä»–ä¸€äº›æµ‹é‡å€¼çš„è®¡ç®—ï¼Œè¿™äº›æµ‹é‡å€¼å°†åœ¨ç¨åè§£é‡Šï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The â€¡ symbol marks the path of processing that generates the candidate cell update, prior to the filtering by the vector mask (see Equation (8.111)[511]).",
            "zh": "â€¡ ç¬¦å·æ ‡è®°åœ¨çŸ¢é‡æ©ç è¿‡æ»¤ä¹‹å‰ç”Ÿæˆå€™é€‰å•å…ƒæ ¼æ›´æ–°çš„å¤„ç†è·¯å¾„ï¼ˆå‚è§å…¬å¼ ï¼ˆ8.111ï¼‰[511]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the second value in ctâˆ’1 is also 1 but this is multiplied by an ft value near zero resulting in a câ€¡ value of 0.002472623.",
            "zh": "ä½†æ˜¯ï¼Œctâˆ’1 ä¸­çš„ç¬¬äºŒä¸ªå€¼ä¹Ÿæ˜¯ 1ï¼Œä½†å°†å…¶ä¹˜ä»¥æ¥è¿‘é›¶çš„ ft å€¼ï¼Œå¾—å‡º câ€¡ å€¼ä¸º 0.002472623ã€‚"
        }
    },
    {
        "translation": {
            "en": "In contrast to stratified sampling, sometimes we would like a sample to contain different relative frequencies of the levels of a particular feature than the distribution in the original dataset. For example, we may wish to create a sample in which the levels of a particular categorical feature are represented equally, rather than with whatever distribution they had in the original dataset. To do this, we can use under-sampling or over-sampling.",
            "zh": "ä¸åˆ†å±‚æŠ½æ ·ç›¸æ¯”ï¼Œæœ‰æ—¶æˆ‘ä»¬å¸Œæœ›æ ·æœ¬åŒ…å«ä¸åŸå§‹æ•°æ®é›†ä¸­çš„åˆ†å¸ƒä¸åŒçš„ç‰¹å®šç‰¹å¾æ°´å¹³çš„ç›¸å¯¹é¢‘ç‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åˆ›å»ºä¸€ä¸ªæ ·æœ¬ï¼Œå…¶ä¸­ç‰¹å®šåˆ†ç±»ç‰¹å¾çš„æ°´å¹³æ˜¯å¹³ç­‰çš„ï¼Œè€Œä¸æ˜¯ç”¨å®ƒä»¬åœ¨åŸå§‹æ•°æ®é›†ä¸­çš„ä»»ä½•åˆ†å¸ƒæ¥è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¬ é‡‡æ ·æˆ–è¿‡é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "It also highlights the fact that the nearest neighbor algorithm uses multiple local models to create an implicit global model to map from the descriptive feature values to the target feature.",
            "zh": "å®ƒè¿˜å¼ºè°ƒäº†ä¸€ä¸ªäº‹å®ï¼Œå³æœ€è¿‘é‚»ç®—æ³•ä½¿ç”¨å¤šä¸ªå±€éƒ¨æ¨¡å‹æ¥åˆ›å»ºä¸€ä¸ªéšå¼å…¨å±€æ¨¡å‹ï¼Œä»¥ä»æè¿°æ€§ç‰¹å¾å€¼æ˜ å°„åˆ°ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "With this minimal information temporal-difference learning can be used to learn sophisticated, long-term behaviors.",
            "zh": "æœ‰äº†è¿™ä¸ªæœ€å°çš„ä¿¡æ¯ï¼Œæ—¶é—´å·®å¼‚å­¦ä¹ å°±å¯ä»¥ç”¨æ¥å­¦ä¹ å¤æ‚çš„ã€é•¿æœŸçš„è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The most important rule in evaluating models is not to use the same data sample both to evaluate the performance of a predictive model and to train it.",
            "zh": "è¯„ä¼°æ¨¡å‹æ—¶æœ€é‡è¦çš„è§„åˆ™æ˜¯ä¸è¦ä½¿ç”¨ç›¸åŒçš„æ•°æ®æ ·æœ¬æ¥è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½å¹¶å¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Hochreiter, Sepp, and JÃ¼rgen Schmidhuber. 1997. Long short-term memory. Neural Computation 9 (8): 1735â€“1780.",
            "zh": "Hochreiterã€Sepp å’Œ JÃ¼rgen Schmidhuberã€‚1997. é•¿çŸ­æœŸè®°å¿†.ç¥ç»è®¡ç®— 9 ï¼ˆ8ï¼‰ï¼š1735â€“1780ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other key differentiating factor between reinforcement learning and the other approaches we have looked at in this book is that reinforcement learning relies less on using a dataset to drive learning and more on the ability to repeatedly attempt tasks in an environment.",
            "zh": "å¼ºåŒ–å­¦ä¹ ä¸æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ç ”ç©¶çš„å…¶ä»–æ–¹æ³•ä¹‹é—´çš„å¦ä¸€ä¸ªå…³é”®åŒºåˆ«å› ç´ æ˜¯ï¼Œå¼ºåŒ–å­¦ä¹ è¾ƒå°‘ä¾èµ–äºä½¿ç”¨æ•°æ®é›†æ¥æ¨åŠ¨å­¦ä¹ ï¼Œè€Œæ›´å¤šåœ°ä¾èµ–äºåœ¨ç¯å¢ƒä¸­é‡å¤å°è¯•ä»»åŠ¡çš„èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "similarity index, 212, 231",
            "zh": "ç›¸ä¼¼åº¦æŒ‡æ•°ï¼Œ 212ï¼Œ 231"
        }
    },
    {
        "translation": {
            "en": "This is the case because there were no instances in 8 that had a value of moderate for the SLOPE feature.",
            "zh": "ä¹‹æ‰€ä»¥å‡ºç°è¿™ç§æƒ…å†µï¼Œæ˜¯å› ä¸º 8 ä¸­æ²¡æœ‰ SLOPE ç‰¹å¾çš„å€¼ä¸º moderate çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, before we can use the gradient descent algorithm to update the weights of a neuron in a hidden layer of the network, we must calculate a measure of how the neuron contributed to the overall error of the network at the output layer.",
            "zh": "å› æ­¤ï¼Œåœ¨ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ›´æ–°ç½‘ç»œéšè—å±‚ä¸­ç¥ç»å…ƒçš„æƒé‡ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»è®¡ç®—å‡ºç¥ç»å…ƒå¦‚ä½•å¯¼è‡´è¾“å‡ºå±‚ç½‘ç»œæ•´ä½“è¯¯å·®çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Further, deep learning generally requires relatively powerful computer hardware.",
            "zh": "æ­¤å¤–ï¼Œæ·±åº¦å­¦ä¹ é€šå¸¸éœ€è¦ç›¸å¯¹å¼ºå¤§çš„è®¡ç®—æœºç¡¬ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The insights that these prediction models produce are used to help organizations make data-driven decisions.",
            "zh": "è¿™äº›é¢„æµ‹æ¨¡å‹äº§ç”Ÿçš„è§è§£ç”¨äºå¸®åŠ©ç»„ç»‡åšå‡ºæ•°æ®é©±åŠ¨çš„å†³ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection is a popular alternative to forward sequential selection.",
            "zh": "å‘åé¡ºåºé€‰æ‹©æ˜¯å‰å‘é¡ºåºé€‰æ‹©çš„å¸¸ç”¨æ›¿ä»£æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A last point to make about this example is that careful examination of Table 7.3[331] shows why such a low learning rate is used in this example.",
            "zh": "å…³äºè¿™ä¸ªä¾‹å­çš„æœ€åä¸€ç‚¹æ˜¯ï¼Œä»”ç»†æ£€æŸ¥è¡¨7.3[331]å¯ä»¥çœ‹å‡ºä¸ºä»€ä¹ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­ä½¿ç”¨äº†å¦‚æ­¤ä½çš„å­¦ä¹ ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7(a)[76] shows an example for the CAREER STAGE and SHOE SPONSOR features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "å›¾3.7ï¼ˆaï¼‰[76]æ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­çš„CAREER STAGEå’ŒSHOE SPONSORç‰¹å¾çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The definition of the student-t probability density function uses the gamma function, Î“(), which is a standard statistical function.16 The student-t distribution is a member of the location-scale family of distributions.17 These distributions take two parameters: a location parameter Ï•, which specifies the position of the peak density of the distribution, and a non-negative scale parameter Ï, which specifies how spread out the distribution is; the higher the scale the more spread out the distribution.",
            "zh": "å­¦ç”Ÿ-t æ¦‚ç‡å¯†åº¦å‡½æ•°çš„å®šä¹‰ä½¿ç”¨ä¼½é©¬å‡½æ•° Î“ï¼ˆï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ç»Ÿè®¡å‡½æ•°ã€‚16 å­¦ç”Ÿ-t åˆ†å¸ƒæ˜¯ä½ç½®å°ºåº¦åˆ†å¸ƒæ—çš„æˆå‘˜ã€‚17 è¿™äº›åˆ†å¸ƒé‡‡ç”¨ä¸¤ä¸ªå‚æ•°ï¼šä½ç½®å‚æ•° Ï†ï¼Œå®ƒæŒ‡å®šåˆ†å¸ƒçš„å³°å€¼å¯†åº¦çš„ä½ç½®ï¼Œä»¥åŠéè´Ÿå°ºåº¦å‚æ•° Ïï¼Œ æŒ‡å®šåˆ†å¸ƒçš„åˆ†å¸ƒç¨‹åº¦;æ¯”ä¾‹è¶Šé«˜ï¼Œåˆ†å¸ƒè¶Šåˆ†æ•£ã€‚"
        }
    },
    {
        "translation": {
            "en": "leave-one-out cross validation, 545",
            "zh": "ç•™ä¸€äº¤å‰éªŒè¯ï¼Œ545"
        }
    },
    {
        "translation": {
            "en": "One of the most common uses of basis functions in linear regression is to train models to capture polynomial relationships.",
            "zh": "åŸºå‡½æ•°åœ¨çº¿æ€§å›å½’ä¸­æœ€å¸¸è§çš„ç”¨é€”ä¹‹ä¸€æ˜¯è®­ç»ƒæ¨¡å‹ä»¥æ•è·å¤šé¡¹å¼å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some functions are not defined in terms of just one variable.",
            "zh": "æœ‰äº›å‡½æ•°ä¸æ˜¯ä»…æ ¹æ®ä¸€ä¸ªå˜é‡å®šä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, the network in Figure 8.4[390] has three layers.",
            "zh": "å› æ­¤ï¼Œå›¾8.4[390]ä¸­çš„ç½‘ç»œæœ‰ä¸‰å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each instance in the dataset is then assigned to be a member of the cluster, i, to whose cluster centroid, ci, it is closest.",
            "zh": "ç„¶åï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½è¢«æŒ‡å®šä¸ºèšç±» i çš„æˆå‘˜ï¼Œè¯¥èšç±»è´¨å¿ƒ ci æœ€æ¥è¿‘å…¶èšç±»è´¨å¿ƒ ciã€‚"
        }
    },
    {
        "translation": {
            "en": "7.7â€…â€…â€…An extended version of the generators dataset from Table 7.6[339].",
            "zh": "7.7 è¡¨7.6[339]ä¸­ç”Ÿæˆå™¨æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "density curve, 61",
            "zh": "å¯†åº¦æ›²çº¿ï¼Œ61"
        }
    },
    {
        "translation": {
            "en": "This process continues until k evaluation experiments have been conducted and k sets of performance measures have been recorded.",
            "zh": "è¿™ä¸ªè¿‡ç¨‹ä¸€ç›´æŒç»­åˆ°è¿›è¡Œäº† k ä¸ªè¯„ä¼°å®éªŒå¹¶è®°å½•äº† k ç»„æ€§èƒ½æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This probability, which is 0.4, can be counted directly from the dataset.",
            "zh": "è¿™ä¸ªæ¦‚ç‡æ˜¯ 0.4ï¼Œå¯ä»¥ç›´æ¥ä»æ•°æ®é›†ä¸­è®¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What prediction will the decision tree generated in Part (a) of this question return for the following query?",
            "zh": "ï¼ˆbï¼‰ æœ¬é—®é¢˜ï¼ˆaï¼‰éƒ¨åˆ†ç”Ÿæˆçš„å†³ç­–æ ‘å¯¹ä»¥ä¸‹æŸ¥è¯¢å°†è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "6.4.4.1â€ƒBuilding Bayesian networksâ€ƒBayesian networks can be constructed by hand or learned from data.",
            "zh": "6.4.4.1 æ„å»ºè´å¶æ–¯ç½‘ç»œ è´å¶æ–¯ç½‘ç»œå¯ä»¥æ‰‹å·¥æ„å»ºï¼Œä¹Ÿå¯ä»¥ä»æ•°æ®ä¸­å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Acme Telephonica (AT) is a mobile phone operator that has customers across every state of the USA.",
            "zh": "Acme Telephonica ï¼ˆATï¼‰ æ˜¯ä¸€å®¶ç§»åŠ¨ç”µè¯è¿è¥å•†ï¼Œå®¢æˆ·éå¸ƒç¾å›½å„å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Galaxy Zoo project started in 2007 and since then has collected millions of classifications of hundreds of thousands of galaxies.",
            "zh": "é“¶æ²³åŠ¨ç‰©å›­é¡¹ç›®å§‹äº2007å¹´ï¼Œä»é‚£æ—¶èµ·å·²ç»æ”¶é›†äº†æ•°åä¸‡ä¸ªæ˜Ÿç³»çš„æ•°ç™¾ä¸‡ä¸ªåˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in Figure 8.42[516] the vector of error gradients âˆ‚â„°/âˆ‚ot is calculated using an elementwise addition of âˆ‚â„°t/âˆ‚ot and âˆ‚â„°t+1/âˆ‚ht",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å›¾ 8.42[516] ä¸­ï¼Œè¯¯å·®æ¢¯åº¦ âˆ‚E/âˆ‚ot çš„å‘é‡æ˜¯ä½¿ç”¨ âˆ‚Et/âˆ‚ot å’Œ âˆ‚Et+1/âˆ‚ht çš„å…ƒç´ ç›¸åŠ æ¥è®¡ç®—çš„"
        }
    },
    {
        "translation": {
            "en": "NUMHANDSETS",
            "zh": "NUMPHONESæ‰‹æœº"
        }
    },
    {
        "translation": {
            "en": "13. The bins created when equal-frequency binning is used are equivalent to percentiles (discussed in Section A.1[745]).",
            "zh": "13. ä½¿ç”¨ç­‰é¢‘åˆ†æ¡£æ—¶äº§ç”Ÿçš„åˆ†æ¡£ç­‰åŒäºç™¾åˆ†ä½æ•°ï¼ˆåœ¨ç¬¬ A.1 èŠ‚ [745] ä¸­è®¨è®ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The question of which is the best one to use, however, still remains.",
            "zh": "ç„¶è€Œï¼Œå“ªä¸ªæ˜¯æœ€å¥½çš„ä½¿ç”¨çš„é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. To save space, throughout this chapter, named features are denoted by the uppercase initial letters of their names (e.g., the MENINGITIS feature is denoted M). If a named feature is binary, we use either the lowercase initial letter of the feature name to denote that the feature is true or the lowercase initial letter preceded by the Â¬ symbol to denote that it is false (e.g., m denotes MENINGITIS = true, and Â¬m denotes MENINGITIS = false).",
            "zh": "3. ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œåœ¨æœ¬ç« ä¸­ï¼Œå‘½åç‰¹å¾ç”¨å…¶åç§°çš„å¤§å†™é¦–å­—æ¯è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œè„‘è†œç‚ç‰¹å¾è¡¨ç¤ºä¸º Mï¼‰ã€‚å¦‚æœå‘½åç‰¹å¾æ˜¯äºŒè¿›åˆ¶çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹å¾åç§°çš„å°å†™é¦–å­—æ¯è¡¨ç¤ºè¯¥ç‰¹å¾ä¸ºçœŸï¼Œæˆ–è€…ä½¿ç”¨å°å†™çš„é¦–å­—æ¯å‰é¢åŠ ä¸Š Â¬ ç¬¦å·è¡¨ç¤ºå®ƒæ˜¯å‡çš„ï¼ˆä¾‹å¦‚ï¼Œm è¡¨ç¤ºè„‘è†œç‚ = çœŸï¼ŒÎ¼m è¡¨ç¤ºè„‘è†œç‚ = å‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The training dataset is then partitioned using the test.",
            "zh": "ç„¶åä½¿ç”¨æµ‹è¯•å¯¹è®­ç»ƒæ•°æ®é›†è¿›è¡Œåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "1.5â€ƒWhat Can Go Wrong with Machine Learning?",
            "zh": "1.5 æœºå™¨å­¦ä¹ ä¼šå‡ºä»€ä¹ˆé—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "16. The ROC index is in fact equivalent to the Wilcoxon-Mann-Whitney statistic used in significance testing.",
            "zh": "16. ROCæŒ‡æ•°å®é™…ä¸Šç­‰åŒäºæ˜¾è‘—æ€§æ£€éªŒä¸­ä½¿ç”¨çš„Wilcoxon-Mann-Whitneyç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cybenko, George. 1989. Approximation by superpositions of sigmoids. Mathematics of Control, Signals and Systems 2: 303â€“314.",
            "zh": "èµ›å®¾ç§‘ï¼Œä¹”æ²»ã€‚1989. é€šè¿‡sigmoidså åŠ çš„è¿‘ä¼¼ã€‚æ§åˆ¶ã€ä¿¡å·å’Œç³»ç»Ÿæ•°å­¦ 2ï¼š303â€“314ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kollar, Daphne, and Nir Friedman. 2009. Probabilistic graphical models: Principles and techniques. MIT Press.",
            "zh": "ç§‘æ‹‰å°”ã€è¾¾èŠ™å¦®å’Œå°¼å°”å¼—é‡Œå¾·æ›¼ã€‚2009. æ¦‚ç‡å›¾å½¢æ¨¡å‹ï¼šåŸç†å’ŒæŠ€æœ¯.éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "and the product required to calculate the probability of any joint event in the domain using these four factors is",
            "zh": "ä½¿ç”¨è¿™å››ä¸ªå› å­è®¡ç®—åŸŸä¸­ä»»ä½•è”åˆäº‹ä»¶çš„æ¦‚ç‡æ‰€éœ€çš„ä¹˜ç§¯æ˜¯"
        }
    },
    {
        "translation": {
            "en": "In Section 8.2.1[384] we described how adding a dummy feature d[0] = 1 to the input vector of a neuron and also including the y-intercept term (or bias term) from the equation of a line as part of the weight vector of the neuron, as w[0], permitted us to calculate the weighted sum of the neuron using a single dot product between the weight vector and the input vector.",
            "zh": "åœ¨ç¬¬ 8.2.1 èŠ‚[384]ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•å°†è™šæ‹Ÿç‰¹å¾ d[0] = 1 æ·»åŠ åˆ°ç¥ç»å…ƒçš„è¾“å…¥å‘é‡ä¸­ï¼Œå¹¶å°†çº¿æ–¹ç¨‹ä¸­çš„ y æˆªè·é¡¹ï¼ˆæˆ–åå·®é¡¹ï¼‰ä½œä¸ºç¥ç»å…ƒæƒé‡å‘é‡çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚ w[0]ï¼Œå…è®¸æˆ‘ä»¬ä½¿ç”¨æƒé‡å‘é‡å’Œè¾“å…¥å‘é‡ä¹‹é—´çš„å•ç‚¹ç§¯è®¡ç®—ç¥ç»å…ƒçš„åŠ æƒå’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The support vectors are highlighted in Figure 7.23[364] for each of the decision boundaries shown.",
            "zh": "å›¾7.23[364]ä¸­çªå‡ºæ˜¾ç¤ºäº†æ‰€ç¤ºæ¯ä¸ªå†³ç­–è¾¹ç•Œçš„æ”¯æŒå‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the transformation implemented by the single weight matrix, generated by the product of weight matrices of the linear layers, will also implement a linear transformation on the input data.",
            "zh": "æ­¤å¤–ï¼Œç”±çº¿æ€§å±‚çš„æƒé‡çŸ©é˜µä¹˜ç§¯ç”Ÿæˆçš„å•ä¸ªæƒé‡çŸ©é˜µå®ç°çš„å˜æ¢ä¹Ÿå°†å¯¹è¾“å…¥æ•°æ®å®ç°çº¿æ€§å˜æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "fat tails, 272",
            "zh": "è‚¥å°¾å·´ï¼Œ272"
        }
    },
    {
        "translation": {
            "en": "Table 4.12",
            "zh": "è¡¨ 4.12"
        }
    },
    {
        "translation": {
            "en": "Find the lady is a card game that hucksters have been using to earn money from unsuspecting marks for centuries.1 In a game, the dealer holds three cardsâ€”one queen and two aces (as shown in Figure 6.1(a)[244])â€”and, typically with a little bit of flair, quickly drops these cards facedown onto a table.",
            "zh": "â€œå¯»æ‰¾å¥³å£«â€æ˜¯ä¸€ç§çº¸ç‰Œæ¸¸æˆï¼Œå‡ ä¸ªä¸–çºªä»¥æ¥ï¼Œå°è´©ä»¬ä¸€ç›´ç”¨å®ƒæ¥ä»æ¯«æ— æˆ’å¿ƒçš„æ ‡è®°ä¸­èµšé’±.1åœ¨æ¸¸æˆä¸­ï¼Œåº„å®¶æŒæœ‰ä¸‰å¼ ç‰Œâ€”â€”ä¸€å¼ çš‡åç‰Œå’Œä¸¤å¼ Aç‰Œï¼ˆå¦‚å›¾6.1ï¼ˆaï¼‰[244]æ‰€ç¤ºï¼‰â€”â€”å¹¶ä¸”é€šå¸¸æœ‰ä¸€ç‚¹å¤©èµ‹ï¼Œè¿…é€Ÿå°†è¿™äº›ç‰Œé¢æœä¸‹æ‰”åˆ°æ¡Œå­ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Intra-cluster distance; (b) inter-cluster distance; (c) a good clustering; and (d) a bad clustering.",
            "zh": "ï¼ˆaï¼‰ é›†ç¾¤å†…è·ç¦»;ï¼ˆbï¼‰ é›†ç¾¤é—´è·ç¦»;ï¼ˆcï¼‰ è‰¯å¥½çš„èšç±»;ï¼ˆdï¼‰èšç±»ä¸è‰¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.1(a)[314] shows a scatter plot of the office rentals dataset with RENTAL PRICE on the vertical (or y) axis and SIZE on the horizontal (or x) axis.",
            "zh": "å›¾7.1ï¼ˆaï¼‰[314]æ˜¾ç¤ºäº†å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œå…¶ä¸­RENTAL PRICEåœ¨å‚ç›´ï¼ˆæˆ–yï¼‰è½´ä¸Šï¼ŒSIZEåœ¨æ°´å¹³ï¼ˆæˆ–xï¼‰è½´ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "4.3.1â€…â€…â€…A Worked Example: Predicting Vegetation Distributions",
            "zh": "4.3.1 å·¥ä½œç¤ºä¾‹ï¼šé¢„æµ‹æ¤è¢«åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "However, as the distribution of values in the continuous feature moves away from a uniform distribution, then some bins will end up with very few instances in them, and other bins will have a lot of instances in them.",
            "zh": "ä½†æ˜¯ï¼Œéšç€è¿ç»­ç‰¹å¾ä¸­å€¼çš„åˆ†å¸ƒè¿œç¦»å‡åŒ€åˆ†å¸ƒï¼Œå› æ­¤æŸäº›æ¡æŸ±ä¸­å°†åŒ…å«å¾ˆå°‘çš„å®ä¾‹ï¼Œè€Œå…¶ä»–æ¡æŸ±ä¸­å°†åŒ…å«å¤§é‡å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, B., P. Cunningham, S. Byrne, and O. I. Corrigan. 2002. The problem of bias in training data in regression problems in medical decision support. Artificial Intelligence in Medicine 24 (1): 51â€“70.",
            "zh": "Mac Nameeï¼Œ B.ã€P. Cunninghamã€S. Byrne å’Œ O. I. Corriganã€‚2002. åŒ»ç–—å†³ç­–æ”¯æŒä¸­å›å½’é—®é¢˜ä¸­çš„è®­ç»ƒæ•°æ®åå·®é—®é¢˜.åŒ»å­¦äººå·¥æ™ºèƒ½24ï¼ˆ1ï¼‰ï¼š51-70ã€‚"
        }
    },
    {
        "translation": {
            "en": "Guisan, Antoine, and Niklaus E. Zimmermann. 2000. Predictive habitat distribution models in ecology. Ecological Modelling 135 (2): 147â€“186.",
            "zh": "Guisanã€Antoine å’Œ Niklaus E. Zimmermannã€‚2000. ç”Ÿæ€å­¦ä¸­çš„é¢„æµ‹ç”Ÿå¢ƒåˆ†å¸ƒæ¨¡å‹.ç”Ÿæ€å»ºæ¨¡135ï¼ˆ2ï¼‰ï¼š147-186ã€‚"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1986. Induction of decision trees. Machine Learning 1 (1): 81â€“106.",
            "zh": "æ˜†å…°ï¼ŒJ.ç½—æ–¯ã€‚1986. å†³ç­–æ ‘çš„å½’çº³ã€‚æœºå™¨å­¦ä¹  1 ï¼ˆ1ï¼‰ï¼š81â€“106ã€‚"
        }
    },
    {
        "translation": {
            "en": "quadratic function, 352, 766",
            "zh": "äºŒæ¬¡å‡½æ•°ï¼Œ 352ï¼Œ 766"
        }
    },
    {
        "translation": {
            "en": "Three Laws of Robotics, 677",
            "zh": "æœºå™¨äººä¸‰å®šå¾‹ï¼Œ677"
        }
    },
    {
        "translation": {
            "en": "As a result, a generative model may outperform a discriminative model when trained on a small dataset with good prior knowledge.",
            "zh": "å› æ­¤ï¼Œå½“åœ¨å…·æœ‰è‰¯å¥½å…ˆéªŒçŸ¥è¯†çš„å°å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼Œç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½å¯èƒ½ä¼˜äºåˆ¤åˆ«æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This phenomenon is known as the vanishing gradient problem, because in deep networks the Î´ terms tend toward zero and vanish as we propagate the Î´s back to the early layers.",
            "zh": "è¿™ç§ç°è±¡è¢«ç§°ä¸ºæ¶ˆå¤±æ¢¯åº¦é—®é¢˜ï¼Œå› ä¸ºåœ¨æ·±åº¦ç½‘ç»œä¸­ï¼ŒÎ´é¡¹è¶‹å‘äºé›¶ï¼Œå½“æˆ‘ä»¬å°†Î´ä¼ æ’­å›æ—©æœŸå±‚æ—¶ï¼Œæ¢¯åº¦é¡¹å°±ä¼šæ¶ˆå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "If both these weights are > 1, then the error gradient term will get larger each time it is multiplied; conversely, if both these weights are < 1, then the error gradient term will get smaller each time it is multiplied.",
            "zh": "å¦‚æœè¿™ä¸¤ä¸ªæƒé‡éƒ½> 1ï¼Œåˆ™è¯¯å·®æ¢¯åº¦é¡¹æ¯æ¬¡ä¹˜ä»¥æ—¶éƒ½ä¼šå˜å¤§;ç›¸åï¼Œå¦‚æœè¿™ä¸¤ä¸ªæƒé‡éƒ½< 1ï¼Œåˆ™è¯¯å·®æ¢¯åº¦é¡¹æ¯æ¬¡ç›¸ä¹˜éƒ½ä¼šå˜å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a medical diagnosis scenario, we would require that a prediction model be very accurate in its diagnoses and, in particular, never incorrectly predict that a sick patient is healthy, as that patient will then leave the health-care system and could subsequently develop serious complications.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦è¯Šæ–­åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬è¦æ±‚é¢„æµ‹æ¨¡å‹çš„è¯Šæ–­éå¸¸å‡†ç¡®ï¼Œç‰¹åˆ«æ˜¯æ°¸è¿œä¸è¦é”™è¯¯åœ°é¢„æµ‹ç—…äººæ˜¯å¥åº·çš„ï¼Œå› ä¸ºè¯¥ç—…äººéšåå°†ç¦»å¼€åŒ»ç–—ä¿å¥ç³»ç»Ÿï¼Œéšåå¯èƒ½å‡ºç°ä¸¥é‡çš„å¹¶å‘ç—‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that for space considerations we have rounded Î´8 to four decimal places, and we will round the Î´s for other neurons similarly and use the rounded values in our calculations so that the results of the calculations match the numbers that are presented on the page.",
            "zh": "è¯·æ³¨æ„ï¼Œå‡ºäºç©ºé—´è€ƒè™‘ï¼Œæˆ‘ä»¬å°† Î´8 å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼Œæˆ‘ä»¬å°†ä»¥ç±»ä¼¼çš„æ–¹å¼å¯¹å…¶ä»–ç¥ç»å…ƒçš„ Î´ è¿›è¡Œå››èˆäº”å…¥ï¼Œå¹¶åœ¨è®¡ç®—ä¸­ä½¿ç”¨èˆå…¥å€¼ï¼Œä»¥ä¾¿è®¡ç®—ç»“æœä¸é¡µé¢ä¸Šæ˜¾ç¤ºçš„æ•°å­—ç›¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The top left cell in the confusion matrix, labeled TP, shows the number of instances in a test set that have a positive target feature value that were also predicted by the model to have a positive target feature value.",
            "zh": "æ··æ·†çŸ©é˜µä¸­æ ‡è®°ä¸º TP çš„å·¦ä¸Šè§’å•å…ƒæ ¼æ˜¾ç¤ºæµ‹è¯•é›†ä¸­å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹æ•°ï¼Œè¿™äº›å®ä¾‹ä¹Ÿè¢«æ¨¡å‹é¢„æµ‹ä¸ºå…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Obviously, the differences between them make them more or less appropriate for a given dataset, and it often requires some experiments to figure out which is the best one for a given problem.",
            "zh": "æ˜¾ç„¶ï¼Œå®ƒä»¬ä¹‹é—´çš„å·®å¼‚ä½¿å®ƒä»¬æˆ–å¤šæˆ–å°‘é€‚åˆç»™å®šçš„æ•°æ®é›†ï¼Œå¹¶ä¸”é€šå¸¸éœ€è¦ä¸€äº›å®éªŒæ¥ç¡®å®šå“ªä¸ªæ˜¯ç»™å®šé—®é¢˜çš„æœ€ä½³æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.2â€…â€…â€…The first draft of the domain concepts diagram developed by Jocelyn for the galaxy classification task.",
            "zh": "13.2 Jocelynä¸ºæ˜Ÿç³»åˆ†ç±»ä»»åŠ¡å¼€å‘çš„é¢†åŸŸæ¦‚å¿µå›¾åˆç¨¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The motivation for highlighting the calculation of the weighted sum and activations during the forward pass of the algorithm is that these values are stored in memory after they are calculated and then used as part of the calculations involved in the backpropagation of the error gradients during the backward pass of the algorithm.",
            "zh": "åœ¨ç®—æ³•çš„å‰å‘ä¼ é€’æœŸé—´çªå‡ºæ˜¾ç¤ºåŠ æƒå’Œå’Œæ¿€æ´»çš„è®¡ç®—çš„åŠ¨æœºæ˜¯ï¼Œè¿™äº›å€¼åœ¨è®¡ç®—åå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œç„¶åç”¨ä½œç®—æ³•å‘åä¼ é€’æœŸé—´è¯¯å·®æ¢¯åº¦åå‘ä¼ æ’­æ‰€æ¶‰åŠçš„è®¡ç®—çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the input happens to be a color image, then we can distinguish the different layers of depth by the color channels.",
            "zh": "å¦‚æœè¾“å…¥æ°å¥½æ˜¯å½©è‰²å›¾åƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡é¢œè‰²é€šé“åŒºåˆ†ä¸åŒçš„æ·±åº¦å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "convex surface, 318",
            "zh": "å‡¸é¢ï¼Œ318"
        }
    },
    {
        "translation": {
            "en": "Furthermore, to align with most explanations of recurrent neural networks, in the subsequent discussion we adopt the following conventions: x denotes an input; h denotes a hidden layer; and y denotes the output from the network.",
            "zh": "æ­¤å¤–ï¼Œä¸ºäº†ä¸å¤§å¤šæ•°å¯¹é€’å½’ç¥ç»ç½‘ç»œçš„è§£é‡Šä¿æŒä¸€è‡´ï¼Œåœ¨éšåçš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹çº¦å®šï¼šx è¡¨ç¤ºè¾“å…¥;h è¡¨ç¤ºéšè—å±‚;y è¡¨ç¤ºç½‘ç»œçš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.11",
            "zh": "è¡¨ 6.11"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of Î± = 0.1, calculate the updated values for each of the weights in the network (w3,2,w3,0,,w2,1,w2,0) after the processing of this single training example.",
            "zh": "å‡è®¾å­¦ä¹ ç‡ä¸º Î± = 0.1ï¼Œåœ¨å¤„ç†å®Œæ­¤è®­ç»ƒç¤ºä¾‹åï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªæƒé‡ ï¼ˆw3,2ï¼Œw3,0ï¼Œï¼Œw2,1ï¼Œw2,0ï¼‰ çš„æ›´æ–°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "agent, 639",
            "zh": "ç‰¹å·¥ï¼Œ639"
        }
    },
    {
        "translation": {
            "en": "Rather than waiting for the episode to complete to find out the actual return of taking action at in state st, the update rule uses the current estimate of the expected return, QÏ€(st+1,at+1).",
            "zh": "æ›´æ–°è§„åˆ™ä¸æ˜¯ç­‰å¾…å‰§é›†å®Œæˆæ¥æ‰¾å‡ºåœ¨çŠ¶æ€ st å¤„æ‰§è¡Œæ“ä½œçš„å®é™…å›æŠ¥ï¼Œè€Œæ˜¯ä½¿ç”¨é¢„æœŸå›æŠ¥çš„å½“å‰ä¼°è®¡å€¼ QÏ€ï¼ˆst+1ï¼Œat+1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "20. This is just a slight modification of Equation (11.23)[655].",
            "zh": "20. è¿™åªæ˜¯å¯¹ç­‰å¼ï¼ˆ11.23ï¼‰[655]çš„è½»å¾®ä¿®æ”¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "state generation function, 640, 673",
            "zh": "çŠ¶æ€ç”Ÿæˆå‡½æ•°ï¼Œ640,673"
        }
    },
    {
        "translation": {
            "en": "Following this policy will lead to the best outcomes on the basis of current knowledge, but does not allow any opportunities for learning.",
            "zh": "éµå¾ªæ­¤æ”¿ç­–å°†åœ¨å½“å‰çŸ¥è¯†çš„åŸºç¡€ä¸Šå–å¾—æœ€ä½³ç»“æœï¼Œä½†ä¸å…è®¸ä»»ä½•å­¦ä¹ æœºä¼šã€‚"
        }
    },
    {
        "translation": {
            "en": "On top of the inductive bias encoded in a machine learning algorithm, we also bias the outcome of a predictive data analytics project in lots of other ways. Consider the following questions:",
            "zh": "é™¤äº†æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ç¼–ç çš„å½’çº³åå·®ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä»¥è®¸å¤šå…¶ä»–æ–¹å¼å¯¹é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®çš„ç»“æœäº§ç”Ÿåå·®ã€‚è¯·è€ƒè™‘ä»¥ä¸‹é—®é¢˜ï¼š"
        }
    },
    {
        "translation": {
            "en": "Although the task of inducing the optimal network structure from data is strictly intractable, algorithms that encode various assumptions exist that allow good models to be learned.",
            "zh": "å°½ç®¡ä»æ•°æ®ä¸­å½’çº³å‡ºæœ€ä½³ç½‘ç»œç»“æ„çš„ä»»åŠ¡éå¸¸æ£˜æ‰‹ï¼Œä½†å­˜åœ¨ç¼–ç å„ç§å‡è®¾çš„ç®—æ³•ï¼Œå¯ä»¥å­¦ä¹ è‰¯å¥½çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling can divide the full data into training, validation, and test sets.",
            "zh": "ä¿æŒæŠ½æ ·å¯ä»¥å°†å®Œæ•´æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "To understand how gradient descent works, imagine a hiker unlucky enough to be stranded on the side of a valley on a foggy day.",
            "zh": "è¦äº†è§£æ¢¯åº¦ä¸‹é™çš„å·¥ä½œåŸç†ï¼Œè¯·æƒ³è±¡ä¸€ä¸ªå¾’æ­¥æ—…è¡Œè€…ä¸å¹¸åœ¨å¤§é›¾å¤©è¢«å›°åœ¨å±±è°·çš„ä¸€ä¾§ã€‚"
        }
    },
    {
        "translation": {
            "en": "consistent model, 6, 7, 121, 141",
            "zh": "ä¸€è‡´å‹å·ï¼Œ6ã€7ã€121ã€141"
        }
    },
    {
        "translation": {
            "en": "CLAIMS; NUMBER OF CLAIMS BY CLAIMANT IN LAST 3 MONTHS: NUM.",
            "zh": "ç´¢èµ”;ç´¢èµ”äººåœ¨è¿‡å»3ä¸ªæœˆå†…çš„ç´¢èµ”æ•°é‡ï¼šNUMã€‚"
        }
    },
    {
        "translation": {
            "en": "The first big term we come to in the equation is [a[1] âˆ’ b[1],â€¦, a[m] âˆ’ b[m .",
            "zh": "æˆ‘ä»¬åœ¨æ–¹ç¨‹ä¸­å¾—å‡ºçš„ç¬¬ä¸€ä¸ªå¤§é¡¹æ˜¯ [a[1] âˆ’ b[1],..., a[m] âˆ’ b[m ."
        }
    },
    {
        "translation": {
            "en": "4.12â€…â€…â€…The vegetation classification decision tree generated using information gain ratio.",
            "zh": "4.12 åˆ©ç”¨ä¿¡æ¯å¢ç›Šæ¯”ç”Ÿæˆçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "After these values have been found, a simple policy that gives a zero probability to any action that does not give the maximum return available from a state and a non-zero probability to any action (there might be more than one) that does lead to the maximum return available from that state is an optimal policy to use with any MDP.",
            "zh": "æ‰¾åˆ°è¿™äº›å€¼åï¼Œä¸€ä¸ªç®€å•çš„ç­–ç•¥æ˜¯ï¼Œå¯¹äºä»»ä½•æœªæä¾›çŠ¶æ€å¯ç”¨æœ€å¤§å›æŠ¥çš„æ“ä½œï¼Œä»¥åŠä¸ºä»»ä½•æ“ä½œï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰æä¾›éé›¶æ¦‚ç‡ï¼Œè¯¥æ“ä½œï¼ˆå¯èƒ½ä¸æ­¢ä¸€ä¸ªï¼‰å¯ä»è¯¥çŠ¶æ€è·å¾—æœ€å¤§å›æŠ¥ï¼Œæ˜¯ç”¨äºä»»ä½• MDP çš„æœ€ä½³ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. âˆ‚â„°/âˆ‚ai is positive when ai > ti (see Equation (8.20)[411]); and",
            "zh": "1. âˆ‚å½“ ai > ti æ—¶ï¼ŒE/âˆ‚ai ä¸ºæ­£ï¼ˆè§ç­‰å¼ ï¼ˆ8.20ï¼‰[411]ï¼‰;å’Œ"
        }
    },
    {
        "translation": {
            "en": "Evaluation, 17, 19, 534, 698, 725, 730",
            "zh": "è¯„ä»·ï¼Œ 17ï¼Œ 19ï¼Œ 534ï¼Œ 698ï¼Œ 725ï¼Œ 730"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE feature would be to use imputation.",
            "zh": "SOFT TISSUE åŠŸèƒ½æ˜¯ä½¿ç”¨æ’è¡¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Pearl, Judea. 1988. Probabilistic reasoning in intelligent systems: Networks of plausible inference. Morgan Kaufmann.",
            "zh": "çç ï¼ŒçŠ¹å¤ªã€‚1988. æ™ºèƒ½ç³»ç»Ÿä¸­çš„æ¦‚ç‡æ¨ç†ï¼šä¼¼æ˜¯è€Œéçš„æ¨ç†ç½‘ç»œ.æ‘©æ ¹Â·è€ƒå¤«æ›¼ï¼ˆMorgan Kaufmannï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "To generate these partitions for an iteration of the Îµ0 bootstrap, a random selection of m instances is taken from the full dataset to generate a test set, and the remaining instances are used as the training set.",
            "zh": "ä¸ºäº†ä¸º Îµ0 å¼•å¯¼ç¨‹åºçš„è¿­ä»£ç”Ÿæˆè¿™äº›åˆ†åŒºï¼Œä»å®Œæ•´æ•°æ®é›†ä¸­éšæœºé€‰æ‹© m ä¸ªå®ä¾‹æ¥ç”Ÿæˆæµ‹è¯•é›†ï¼Œå…¶ä½™å®ä¾‹ç”¨ä½œè®­ç»ƒé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.17â€…â€…â€…The relevant smoothed probabilities, from Table 6.16[284], needed by the naive Bayes model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, AB = 759.07, and LA = 8,000, and the calculation of the scores for each candidate prediction.",
            "zh": "6.17 æœ´ç´ è´å¶æ–¯æ¨¡å‹éœ€è¦è¡¨6.16[284]ä¸­çš„ç›¸å…³å¹³æ»‘æ¦‚ç‡ï¼Œä»¥ä¾¿å¯¹CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹ã€AB = 759.07 å’Œ LA = 8,000 çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå€™é€‰é¢„æµ‹çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The gain in a particular decile can be interpreted as a measure of how much better than random guessing the predictions made by a model are.",
            "zh": "ç‰¹å®šååˆ†ä½æ•°çš„å¢ç›Šå¯ä»¥è§£é‡Šä¸ºè¡¡é‡æ¨¡å‹æ‰€åšçš„é¢„æµ‹æ¯”éšæœºçŒœæµ‹å¥½å¤šå°‘çš„æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In everyday usage, the word prediction has a temporal aspectâ€”we predict what will happen in the future.",
            "zh": "åœ¨æ—¥å¸¸ä½¿ç”¨ä¸­ï¼Œé¢„æµ‹è¿™ä¸ªè¯æœ‰ä¸€ä¸ªæ—¶é—´æ–¹é¢â€”â€”æˆ‘ä»¬é¢„æµ‹æœªæ¥ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "For categorical features, we should first examine the mode, 2nd mode, mode %, and 2nd mode % in the categorical features table in the data quality report.",
            "zh": "å¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬åº”è¯¥é¦–å…ˆæ£€æŸ¥æ•°æ®è´¨é‡æŠ¥å‘Šçš„åˆ†ç±»ç‰¹å¾è¡¨ä¸­çš„æ¨¡å¼ã€ç¬¬äºŒæ¨¡å¼ã€æ¨¡å¼%å’Œç¬¬äºŒæ¨¡å¼%ã€‚"
        }
    },
    {
        "translation": {
            "en": "random forest, 159, 159, 171, 175",
            "zh": "éšæœºæ£®æ—ï¼Œ 159ï¼Œ 159ï¼Œ 171ï¼Œ 175"
        }
    },
    {
        "translation": {
            "en": "behavior policy, 657, 659, 664",
            "zh": "è¡Œä¸ºæ”¿ç­–ï¼Œ 657ï¼Œ 659ï¼Œ 664"
        }
    },
    {
        "translation": {
            "en": "In contrast, the predictions made at the leaf nodes of this subtree are incorrect for d2 and d5 (because these patients are female, the prediction made is gen which does not match the validation dataset), so the error rate for the leaf nodes of this subtree is 0 + 2 = 2.",
            "zh": "ç›¸åï¼Œåœ¨è¯¥å­æ ‘çš„å¶èŠ‚ç‚¹ä¸Šæ‰€åšçš„é¢„æµ‹å¯¹äº d2 å’Œ d5 æ˜¯ä¸æ­£ç¡®çš„ï¼ˆå› ä¸ºè¿™äº›æ‚£è€…æ˜¯å¥³æ€§ï¼Œæ‰€ä»¥æ‰€åšçš„é¢„æµ‹æ˜¯ä¸éªŒè¯æ•°æ®é›†ä¸åŒ¹é…çš„ genï¼‰ï¼Œå› æ­¤è¯¥å­æ ‘çš„å¶èŠ‚ç‚¹çš„é”™è¯¯ç‡ä¸º 0 + 2 = 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "The way to solve this problem is to visualize intervals rather than specific values, and this is what a histogram does.",
            "zh": "è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æ˜¯å¯è§†åŒ–åŒºé—´è€Œä¸æ˜¯ç‰¹å®šå€¼ï¼Œè¿™å°±æ˜¯ç›´æ–¹å›¾çš„ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A sample test set with prediction scores and resulting predictions based on different threshold values.",
            "zh": "å…·æœ‰é¢„æµ‹åˆ†æ•°å’ŒåŸºäºä¸åŒé˜ˆå€¼çš„é¢„æµ‹ç»“æœçš„ç¤ºä¾‹æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The book provides case studies illustrating the application of machine learning within the industry context of data analytics, which also makes it a suitable text for practitioners looking for an introduction to the field and a textbook for industry training courses in these areas.",
            "zh": "æœ¬ä¹¦æä¾›äº†æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯´æ˜äº†æœºå™¨å­¦ä¹ åœ¨æ•°æ®åˆ†æè¡Œä¸šèƒŒæ™¯ä¸‹çš„åº”ç”¨ï¼Œè¿™ä¹Ÿä½¿å…¶æˆä¸ºå¯»æ‰¾è¯¥é¢†åŸŸä»‹ç»çš„ä»ä¸šè€…çš„åˆé€‚æ•™æï¼Œä¹Ÿæ˜¯è¿™äº›é¢†åŸŸè¡Œä¸šåŸ¹è®­è¯¾ç¨‹çš„æ•™ç§‘ä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "As you know that the card is not in the position on the right, the likelihood that you had associated with this position is redistributed among the other two possibilities.",
            "zh": "å¦‚æ‚¨æ‰€çŸ¥ï¼Œè¿™å¼ ç‰Œä¸åœ¨å³ä¾§çš„ä½ç½®ï¼Œå› æ­¤æ‚¨ä¸è¯¥ä½ç½®å…³è”çš„å¯èƒ½æ€§å°†é‡æ–°åˆ†é…ç»™å…¶ä»–ä¸¤ç§å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The representation of a network as a sequence of matrix operations provides a transparent view on the depth of the network: a network depth is equal to the number of layers that have a weight matrix associated with them. This is why the input layer is not counted as part of the depth of the network.",
            "zh": "å°†ç½‘ç»œè¡¨ç¤ºä¸ºä¸€ç³»åˆ—çŸ©é˜µæ“ä½œæä¾›äº†ç½‘ç»œæ·±åº¦çš„é€æ˜è§†å›¾ï¼šç½‘ç»œæ·±åº¦ç­‰äºå…·æœ‰ä¸ä¹‹å…³è”çš„æƒé‡çŸ©é˜µçš„å±‚æ•°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¾“å…¥å±‚ä¸è®¡å…¥ç½‘ç»œæ·±åº¦çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the variance of the Î´s values across for the neurons in the first hidden layer in the first iteration of training.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—è®­ç»ƒç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ç¬¬ä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„ Î´s å€¼çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.8",
            "zh": "å›¾ A.8"
        }
    },
    {
        "translation": {
            "en": "In statistics it is very important to understand the difference between a population and a sample.",
            "zh": "åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œäº†è§£æ€»ä½“å’Œæ ·æœ¬ä¹‹é—´çš„å·®å¼‚éå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "vector, 216, 771",
            "zh": "çŸ¢é‡ï¼Œ 216ï¼Œ 771"
        }
    },
    {
        "translation": {
            "en": "The non-leaf nodes in the trees list the ID of the instance the node indexes and the feature and value pair that define the hyperplane partition on the feature space defined by the node.",
            "zh": "æ ‘ä¸­çš„éå¶èŠ‚ç‚¹åˆ—å‡ºäº†å®ä¾‹çš„ IDã€èŠ‚ç‚¹ç´¢å¼•ä»¥åŠå®šä¹‰èŠ‚ç‚¹å®šä¹‰çš„ç‰¹å¾ç©ºé—´ä¸Šçš„è¶…å¹³é¢åˆ†åŒºçš„ç‰¹å¾å’Œå€¼å¯¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Shannon worked for AT&T Bell Labs, where he worked on the efficient encoding of messages for telephone communication.",
            "zh": "Shannon æ›¾åœ¨ AT&T è´å°”å®éªŒå®¤å·¥ä½œï¼Œåœ¨é‚£é‡Œä»–è‡´åŠ›äºå¯¹ç”µè¯é€šä¿¡çš„æ¶ˆæ¯è¿›è¡Œé«˜æ•ˆç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, the set of events that fulfill the conditions for each conditional probability in the sequence, and hence that are considered when we compute the probability, get smaller and smaller as more and more conditions are added.",
            "zh": "å› æ­¤ï¼Œéšç€æ·»åŠ çš„æ¡ä»¶è¶Šæ¥è¶Šå¤šï¼Œæ»¡è¶³åºåˆ—ä¸­æ¯ä¸ªæ¡ä»¶æ¦‚ç‡æ¡ä»¶çš„äº‹ä»¶é›†ï¼ˆå› æ­¤åœ¨è®¡ç®—æ¦‚ç‡æ—¶è€ƒè™‘çš„äº‹ä»¶é›†ï¼‰å˜å¾—è¶Šæ¥è¶Šå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, the ABT was composed of a mixture of continuous and categorical descriptive features and had a categorical target feature.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒABTç”±è¿ç»­å’Œåˆ†ç±»æè¿°æ€§ç‰¹å¾çš„æ··åˆç»„æˆï¼Œå¹¶å…·æœ‰åˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data, however, like everything else in the world, is not constant.",
            "zh": "ç„¶è€Œï¼Œä¸ä¸–ç•Œä¸Šå…¶ä»–ä¸€åˆ‡äº‹ç‰©ä¸€æ ·ï¼Œæ•°æ®å¹¶ä¸æ˜¯æ’å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. Recall that in Section 3.2[55] we discussed the 68âˆ’95âˆ’99.7 rule associated with the normal distribution. This approach to handling outliers is based directly on this rule.",
            "zh": "6. å›æƒ³ä¸€ä¸‹ï¼Œåœ¨ç¬¬ 3.2 èŠ‚[55]ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸æ­£æ€åˆ†å¸ƒç›¸å…³çš„ 68âˆ’95âˆ’99.7 è§„åˆ™ã€‚è¿™ç§å¤„ç†å¼‚å¸¸å€¼çš„æ–¹æ³•ç›´æ¥åŸºäºæ­¤è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the calculation of the softmax activation for Neuron 8 and example d1 is 1.113661238/3.326635258 â‰ˆ 0.3348.",
            "zh": "ä¾‹å¦‚ï¼ŒNeuron 8 å’Œç¤ºä¾‹ d1 çš„ softmax æ¿€æ´»è®¡ç®—ä¸º 1.113661238/3.326635258 â‰ˆ 0.3348ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for each neuron i that neuron k connects forward to",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºç¥ç»å…ƒ k å‘å‰è¿æ¥åˆ°çš„æ¯ä¸ªç¥ç»å…ƒ i"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm, like many other clustering algorithms, requires that the analyst choose the value for k as an input to the algorithm.",
            "zh": "ä¸è®¸å¤šå…¶ä»–èšç±»ç®—æ³•ä¸€æ ·ï¼Œk å‡å€¼èšç±»ç®—æ³•è¦æ±‚åˆ†æäººå‘˜é€‰æ‹© k çš„å€¼ä½œä¸ºç®—æ³•çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The transactional record of calls made by individuals, stretching back over a time horizon of 18 months",
            "zh": "ä¸ªäººæ‹¨æ‰“ç”µè¯çš„äº¤æ˜“è®°å½•ï¼Œå¯ä»¥è¿½æº¯åˆ° 18 ä¸ªæœˆçš„æ—¶é—´è·¨åº¦"
        }
    },
    {
        "translation": {
            "en": "This analysis will eliminate some solutions altogether and for those solutions that appear feasible will generate a list of the data and capacity required for successful implementation.",
            "zh": "è¿™ç§åˆ†æå°†å®Œå…¨æ¶ˆé™¤ä¸€äº›è§£å†³æ–¹æ¡ˆï¼Œå¯¹äºé‚£äº›çœ‹èµ·æ¥å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œå°†ç”ŸæˆæˆåŠŸå®æ–½æ‰€éœ€çš„æ•°æ®å’Œå®¹é‡åˆ—è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5â€…â€…â€…Example scatter plots for pairs of features from the dataset in Table 3.7[73], showing (a) the strong positive covariance between HEIGHT and WEIGHT; (b) the strong negative covariance between SPONSORSHIP EARNINGS and AGE; and (c) the lack of strong covariance between HEIGHT and AGE.",
            "zh": "3.5 è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­ç‰¹å¾å¯¹çš„ç¤ºä¾‹æ•£ç‚¹å›¾ï¼Œæ˜¾ç¤ºï¼ˆaï¼‰èº«é«˜å’Œä½“é‡ä¹‹é—´çš„å¼ºæ­£åæ–¹å·®;ï¼ˆbï¼‰èµåŠ©æ”¶å…¥ä¸å¹´é¾„ä¹‹é—´çš„å¼ºè´Ÿåæ–¹å·®;ï¼ˆcï¼‰èº«é«˜å’Œå¹´é¾„ä¹‹é—´ç¼ºä¹å¼ºåæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Chapter 14 discusses a range of fundamental topics in machine learning and highlights that the selection of an appropriate machine learning approach for a given task involves factors beyond model accuracyâ€”we must also match the characteristics of the model to the needs of the business.",
            "zh": "æœ€åï¼Œç¬¬ 14 ç« è®¨è®ºäº†æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ç³»åˆ—åŸºæœ¬ä¸»é¢˜ï¼Œå¹¶å¼ºè°ƒä¸ºç»™å®šä»»åŠ¡é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ–¹æ³•æ¶‰åŠæ¨¡å‹å‡†ç¡®æ€§ä¹‹å¤–çš„å› ç´ â€”â€”æˆ‘ä»¬è¿˜å¿…é¡»å°†æ¨¡å‹çš„ç‰¹å¾ä¸ä¸šåŠ¡éœ€æ±‚ç›¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.33",
            "zh": "0.33"
        }
    },
    {
        "translation": {
            "en": "8.3.2â€ƒBackpropagation: Backpropagating the Error Gradients",
            "zh": "8.3.2 åå‘ä¼ æ’­ï¼šåå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "where levels(t) is the set of levels in the domain of the target feature t; and P(t = l) is the probability of a randomly selected instance having the target feature level l.",
            "zh": "å…¶ä¸­ levelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡è¦ç´  t åŸŸä¸­çš„çº§åˆ«é›†;Pï¼ˆt = lï¼‰ æ˜¯éšæœºé€‰æ‹©çš„å®ä¾‹å…·æœ‰ç›®æ ‡ç‰¹å¾çº§åˆ« l çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another commonly used measure of impurity is the Gini index",
            "zh": "å¦ä¸€ä¸ªå¸¸ç”¨çš„æ‚è´¨è¡¡é‡æ ‡å‡†æ˜¯åŸºå°¼ç³»æ•°"
        }
    },
    {
        "translation": {
            "en": "Table 5.7[208] lists the dataset from Table 5.5[204] after we have applied range normalization using a range of [0,1] to the SALARY and AGE features. When we normalize the features in a dataset, we also need to normalize the features in any query instances using the same normalization process and parameters. We normalize the query instance with SALARY =56,000 and AGE = 35 as follows:",
            "zh": "è¡¨ 5.7[208] åˆ—å‡ºäº†è¡¨ 5.5[204] ä¸­çš„æ•°æ®é›†ï¼Œä¹‹åæˆ‘ä»¬ä½¿ç”¨ [0,1] çš„èŒƒå›´å¯¹ SALARY å’Œ AGE ç‰¹å¾è¿›è¡Œäº†èŒƒå›´å½’ä¸€åŒ–ã€‚å½“æˆ‘ä»¬å¯¹æ•°æ®é›†ä¸­çš„ç‰¹å¾è¿›è¡Œè§„èŒƒåŒ–æ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä½¿ç”¨ç›¸åŒçš„è§„èŒƒåŒ–è¿‡ç¨‹å’Œå‚æ•°å¯¹ä»»ä½•æŸ¥è¯¢å®ä¾‹ä¸­çš„ç‰¹å¾è¿›è¡Œè§„èŒƒåŒ–ã€‚æˆ‘ä»¬å¯¹ SALARY =56,000 å’Œ AGE = 35 çš„æŸ¥è¯¢å®ä¾‹è¿›è¡Œè§„èŒƒåŒ–ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Features following a normal distribution are characterized by a strong tendency toward a central value and symmetrical variation to either side of this central tendency.",
            "zh": "éµå¾ªæ­£æ€åˆ†å¸ƒçš„ç‰¹å¾æ˜¯å‘ä¸­å¿ƒå€¼çš„å¼ºçƒˆè¶‹åŠ¿å’Œè¯¥ä¸­å¿ƒè¶‹åŠ¿ä¸¤ä¾§çš„å¯¹ç§°å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, rather than using full connectivity between layers (as we have done so far), we might decide to constrain the connectivity between layers so that each neuron in one layer connects only to a subset of the neurons in the next layer.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å†³å®šé™åˆ¶å±‚ä¹‹é—´çš„è¿æ¥ï¼Œä»¥ä¾¿ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä»…è¿æ¥åˆ°ä¸‹ä¸€å±‚ä¸­çš„ç¥ç»å…ƒå­é›†ï¼Œè€Œä¸æ˜¯åœ¨å±‚ä¹‹é—´ä½¿ç”¨å®Œå…¨è¿æ¥ï¼ˆæ­£å¦‚æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢æ‰€åšçš„é‚£æ ·ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kansagara, Devan, Honora Englander, Amanda Salanitro, David Kagen, Cecelia Theobald, Michele Freeman, and Sunil Kripalani. 2011. Risk prediction models for hospital readmission: A systematic review. JAMA 306 (15): 1688â€“1698.",
            "zh": "Kansagaraã€Devanã€Honora Englanderã€Amanda Salanitroã€David Kagenã€Cecelia Theobaldã€Michele Freeman å’Œ Sunil Kripalaniã€‚2011. å†å…¥é™¢é£é™©é¢„æµ‹æ¨¡å‹ï¼šç³»ç»Ÿè¯„ä»·.ç¾å›½åŒ»å­¦ä¼šæ‚å¿— 306 ï¼ˆ15ï¼‰ï¼š1688â€“1698ã€‚"
        }
    },
    {
        "translation": {
            "en": "In comparison with a box plot, an individual histogram provides more information; for example, histograms show the distribution of the values of a feature.",
            "zh": "ä¸ç®±å½¢å›¾ç›¸æ¯”ï¼Œå•ä¸ªç›´æ–¹å›¾æä¾›äº†æ›´å¤šä¿¡æ¯;ä¾‹å¦‚ï¼Œç›´æ–¹å›¾æ˜¾ç¤ºè¦ç´ å€¼çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting classification accuracies (average class accuracies and classification accuracies are the same in this case because the dataset is balanced) from the 10-fold cross validation experiment were 73.965%, 78.805%, and 78.226% for the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "å¯¹äºkæœ€è¿‘é‚»ã€é€»è¾‘å›å½’å’Œæ”¯æŒå‘é‡æœºæ¨¡å‹ï¼Œ10å€äº¤å‰éªŒè¯å®éªŒå¾—åˆ°çš„åˆ†ç±»ç²¾åº¦ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¹³å‡ç±»ç²¾åº¦å’Œåˆ†ç±»ç²¾åº¦ç›¸åŒï¼Œå› ä¸ºæ•°æ®é›†æ˜¯å¹³è¡¡çš„ï¼‰åˆ†åˆ«ä¸º73.965%ã€78.805%å’Œ78.226%ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is interesting because there are no instances listed in Table 4.3[136] where SLOPE = moderate and VEGETATION = chapparal. This example illustrates one way in which the predictions made by the model generalize beyond the dataset. Whether the generalizations made by the model are correct will depend on whether the assumptions used in generating the model (i.e., the inductive bias) are appropriate.",
            "zh": "è¿™å¾ˆæœ‰è¶£ï¼Œå› ä¸ºè¡¨ 4.3[136] ä¸­æ²¡æœ‰åˆ—å‡º SLOPE = ä¸­ç­‰ä¸” VEGETATION = chapparal çš„å®ä¾‹ã€‚æ­¤ç¤ºä¾‹è¯´æ˜äº†æ¨¡å‹æ‰€åšçš„é¢„æµ‹åœ¨æ•°æ®é›†ä¹‹å¤–æ³›åŒ–çš„ä¸€ç§æ–¹å¼ã€‚æ¨¡å‹çš„æ¦‚æ‹¬æ˜¯å¦æ­£ç¡®å°†å–å†³äºç”Ÿæˆæ¨¡å‹æ—¶ä½¿ç”¨çš„å‡è®¾ï¼ˆå³å½’çº³åå·®ï¼‰æ˜¯å¦åˆé€‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The pattern that is evident in the two examples presented above continues as the threshold value is modified: as the threshold increases, TPR decreases and TNR increases, and as the threshold decreases, the opposite occurs.",
            "zh": "åœ¨ä¸Šé¢çš„ä¸¤ä¸ªç¤ºä¾‹ä¸­æ˜¾è€Œæ˜“è§çš„æ¨¡å¼éšç€é˜ˆå€¼çš„ä¿®æ”¹è€Œç»§ç»­ï¼šéšç€é˜ˆå€¼çš„å¢åŠ ï¼ŒTPR é™ä½ï¼ŒTNR å¢åŠ ï¼Œè€Œéšç€é˜ˆå€¼çš„é™ä½ï¼Œæƒ…å†µæ­£å¥½ç›¸åã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that more features contribute to the predictions made by the model has the effect that the weight updates get spread out across more weights because more weights will have been involved in the prediction and hence will have contributed to the error.",
            "zh": "æ›´å¤šçš„ç‰¹å¾æœ‰åŠ©äºæ¨¡å‹åšå‡ºçš„é¢„æµ‹ï¼Œè¿™ä¸€äº‹å®çš„æ•ˆæœæ˜¯ï¼Œæƒé‡æ›´æ–°ä¼šåˆ†æ•£åˆ°æ›´å¤šçš„æƒé‡ä¸­ï¼Œå› ä¸ºé¢„æµ‹ä¸­å°†æ¶‰åŠæ›´å¤šçš„æƒé‡ï¼Œå› æ­¤ä¼šå¯¼è‡´è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Large-scale sky scanning projects are being used to map the whole of the night sky in intricate detail.",
            "zh": "å¤§è§„æ¨¡çš„å¤©ç©ºæ‰«æé¡¹ç›®è¢«ç”¨äºç»˜åˆ¶æ•´ä¸ªå¤œç©ºçš„å¤æ‚ç»†èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "An answer to Question 1, Is it a man?, splits the game domain into two sets of equal size: one containing Brian and John and one containing Aphra and Aoife.",
            "zh": "å¯¹é—®é¢˜ 1 çš„å›ç­”æ˜¯ï¼Œå®ƒæ˜¯ä¸€ä¸ªç”·äººå—ï¼Ÿï¼Œå°†æ¸¸æˆåŸŸåˆ†æˆä¸¤ç»„å¤§å°ç›¸ç­‰çš„é›†åˆï¼šä¸€ç»„åŒ…å« Brian å’Œ Johnï¼Œå¦ä¸€ç»„åŒ…å« Aphra å’Œ Aoifeã€‚"
        }
    },
    {
        "translation": {
            "en": "www.machinelearningbook.com",
            "zh": "www.machinelearningbook.com"
        }
    },
    {
        "translation": {
            "en": "On one hand, this analysis reveals that the variance of z is dependent on the number of inputs the neuron receives, nin; in general, the larger the number of inputs, the larger the variance.",
            "zh": "ä¸€æ–¹é¢ï¼Œè¯¥åˆ†æè¡¨æ˜ z çš„æ–¹å·®å–å†³äºç¥ç»å…ƒæ¥æ”¶çš„è¾“å…¥æ•°é‡ nin;ä¸€èˆ¬æ¥è¯´ï¼Œè¾“å…¥æ•°é‡è¶Šå¤§ï¼Œæ–¹å·®è¶Šå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Deployment",
            "zh": "éƒ¨ç½²"
        }
    },
    {
        "translation": {
            "en": "light tails, 272",
            "zh": "å…‰å°¾ï¼Œ272"
        }
    },
    {
        "translation": {
            "en": "In this case the customer contacting the company to cancel their service is the key event in time.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®¢æˆ·è”ç³»å…¬å¸å–æ¶ˆä»–ä»¬çš„æœåŠ¡æ˜¯åŠæ—¶çš„å…³é”®äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.12â€…â€…â€…(a) A complete ROC curve for the email classification example; and (b) a selection of ROC curves for different models trained on the same prediction task.",
            "zh": "9.12 ï¼ˆaï¼‰ ç”µå­é‚®ä»¶åˆ†ç±»ç¤ºä¾‹çš„å®Œæ•´ ROC æ›²çº¿;ï¼ˆbï¼‰ä¸ºåœ¨åŒä¸€é¢„æµ‹ä»»åŠ¡ä¸Šè®­ç»ƒçš„ä¸åŒæ¨¡å‹é€‰æ‹©ROCæ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.3â€…â€…â€…Handling Categorical Descriptive Features",
            "zh": "7.4.3 å¤„ç†åˆ†ç±»æè¿°æ€§ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "15. We introduce variance in Section A.1.2[746], and although we extend the formal definition of variance here to include a dataset parameter ğ’Ÿâ€”we do this to explicitly highlight the fact that we are calculating the variance of a feature within a particular dataset, usually the dataset at a node in the treeâ€”the measure of variance we are using is identical to the variance defined in Equation (A.3)[747].",
            "zh": "15. æˆ‘ä»¬åœ¨A.1.2[746]èŠ‚ä¸­å¼•å…¥äº†æ–¹å·®ï¼Œå°½ç®¡æˆ‘ä»¬åœ¨è¿™é‡Œæ‰©å±•äº†æ–¹å·®çš„æ­£å¼å®šä¹‰ï¼Œä»¥åŒ…æ‹¬æ•°æ®é›†å‚æ•°Dï¼Œä½†æˆ‘ä»¬è¿™æ ·åšæ˜¯ä¸ºäº†æ˜ç¡®å¼ºè°ƒæˆ‘ä»¬æ­£åœ¨è®¡ç®—ç‰¹å®šæ•°æ®é›†ä¸­ç‰¹å¾çš„æ–¹å·®ï¼Œé€šå¸¸æ˜¯æ ‘ä¸­èŠ‚ç‚¹ä¸Šçš„æ•°æ®é›†ï¼Œä½†æˆ‘ä»¬ä½¿ç”¨çš„æ–¹å·®åº¦é‡ä¸æ–¹ç¨‹ï¼ˆA.3ï¼‰[747]ä¸­å®šä¹‰çš„æ–¹å·®ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Bellman Equations, 653",
            "zh": "è´å°”æ›¼æ–¹ç¨‹ï¼Œ653"
        }
    },
    {
        "translation": {
            "en": "Although this may seem like an insignificant difference, the fact that both features now cover the same range has a huge impact on the performance of a similarity-based prediction model that uses this data.",
            "zh": "å°½ç®¡è¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªå¾®ä¸è¶³é“çš„å·®å¼‚ï¼Œä½†ä¸¤ä¸ªç‰¹å¾ç°åœ¨è¦†ç›–ç›¸åŒçš„èŒƒå›´è¿™ä¸€äº‹å®å¯¹ä½¿ç”¨æ­¤æ•°æ®çš„åŸºäºç›¸ä¼¼æ€§çš„é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½äº§ç”Ÿäº†å·¨å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "where k(q) is the prediction of the model for the query q given the parameter of the model k; levels(t) is the set of levels in the domain of the target feature, and l is an element of this set; i iterates over the instances di in increasing distance from the query q; ti is the value of the target feature for instance di; and Î´(ti,l) is the Kronecker delta function, which takes two parameters and returns 1 if they are equal and 0 otherwise.",
            "zh": "å…¶ä¸­ kï¼ˆqï¼‰ æ˜¯ç»™å®šæ¨¡å‹ k å‚æ•°çš„æŸ¥è¯¢ q çš„æ¨¡å‹é¢„æµ‹;levelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡ç‰¹å¾åŸŸä¸­çš„çº§åˆ«é›†ï¼Œl æ˜¯è¯¥é›†åˆä¸­çš„å…ƒç´ ;i éå†å®ä¾‹ diï¼Œä»¥å¢åŠ ä¸æŸ¥è¯¢ q çš„è·ç¦»;ti æ˜¯ç›®æ ‡ç‰¹å¾çš„å€¼ï¼Œä¾‹å¦‚ di;Î´ï¼ˆtiï¼Œlï¼‰ æ˜¯ Kronecker delta å‡½æ•°ï¼Œå®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼Œå¦‚æœå®ƒä»¬ç›¸ç­‰ï¼Œåˆ™è¿”å› 1ï¼Œå¦åˆ™è¿”å› 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Over the next two iterations, two more pairs of instances from the original dataset are combined into clusters: d5 and d19 into 11, and d7 and d23 into 12.",
            "zh": "åœ¨æ¥ä¸‹æ¥çš„ä¸¤æ¬¡è¿­ä»£ä¸­ï¼ŒåŸå§‹æ•°æ®é›†ä¸­çš„å¦å¤–ä¸¤å¯¹å®ä¾‹è¢«åˆå¹¶åˆ°é›†ç¾¤ä¸­ï¼šd5 å’Œ d19 åˆå¹¶ä¸º 11ï¼Œd7 å’Œ d23 åˆå¹¶ä¸º 12ã€‚"
        }
    },
    {
        "translation": {
            "en": "Câ€…â€…â€…Differentiation Techniques for Machine Learning",
            "zh": "C æœºå™¨å­¦ä¹ çš„å¾®åˆ†æŠ€æœ¯"
        }
    },
    {
        "translation": {
            "en": "This is useful information that the business can use to attempt to devise other churn handling strategies in parallel to using this model to create call lists for the retention team.",
            "zh": "è¿™æ˜¯æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä¼ä¸šå¯ä»¥ä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥å°è¯•è®¾è®¡å…¶ä»–æµå¤±å¤„ç†ç­–ç•¥ï¼ŒåŒæ—¶ä½¿ç”¨æ­¤æ¨¡å‹ä¸ºä¿ç•™å›¢é˜Ÿåˆ›å»ºå‘¼å«åˆ—è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The R2 measure",
            "zh": "R2 åº¦é‡"
        }
    },
    {
        "translation": {
            "en": "Anton, H., and C. Rorres. 2010. Elementary linear algebra: Applications version. Wiley. http://books.google.ie/books?id=1PJ-WHepeBsC.",
            "zh": "å®‰ä¸œï¼ŒH. å’Œ C. ç½—é›·æ–¯ã€‚2010. åˆç­‰çº¿æ€§ä»£æ•°ï¼šåº”ç”¨ç‰ˆ.å¨åˆ©ã€‚http://books.google.ie/books?id=1PJ-WHepeBsCã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix (SPLOM) shows scatter plots for a whole collection of features arranged into a matrix.",
            "zh": "æ•£ç‚¹å›¾çŸ©é˜µ ï¼ˆSPLOMï¼‰ æ˜¾ç¤ºæ’åˆ—æˆçŸ©é˜µçš„æ•´ä¸ªè¦ç´ é›†åˆçš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prioritization given by the information gain values is extremely helpful for dealing with this.",
            "zh": "ä¿¡æ¯å¢ç›Šå€¼ç»™å‡ºçš„ä¼˜å…ˆçº§å¯¹äºå¤„ç†æ­¤é—®é¢˜éå¸¸æœ‰å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another approach to scaling nearest neighbor models is to remove redundant or noisy instances from the dataset in which we search for neighbors.",
            "zh": "æ‰©å±•æœ€è¿‘é‚»æ¨¡å‹çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä»æˆ‘ä»¬æœç´¢é‚»åŸŸçš„æ•°æ®é›†ä¸­åˆ é™¤å†—ä½™æˆ–å˜ˆæ‚çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For different recurring fees, customers received different-sized bundles of call time.",
            "zh": "å¯¹äºä¸åŒçš„ç»å¸¸æ€§è´¹ç”¨ï¼Œå®¢æˆ·ä¼šæ”¶åˆ°ä¸åŒå¤§å°çš„é€šè¯æ—¶é—´æ†ç»‘åŒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "lucky split, 543, 586",
            "zh": "å¹¸è¿æ–¯æ™®åˆ©ç‰¹ï¼Œ 543ï¼Œ 586"
        }
    },
    {
        "translation": {
            "en": "The final attendance at a match is not available until midway through the game, so if we were trying to make predictions before kickoff, this feature would not be feasible.",
            "zh": "æ¯”èµ›çš„æœ€ç»ˆä¸Šåº§ç‡è¦åˆ°æ¯”èµ›è¿›è¡Œåˆ°ä¸€åŠæ—¶æ‰èƒ½è·å¾—ï¼Œå› æ­¤å¦‚æœæˆ‘ä»¬è¯•å›¾åœ¨å¼€çƒå‰è¿›è¡Œé¢„æµ‹ï¼Œåˆ™æ­¤åŠŸèƒ½å°†ä¸å¯è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "0.02999",
            "zh": "0.02999"
        }
    },
    {
        "translation": {
            "en": "The real skill in developing situational fluency is determining how much knowledge about the application domain the analytics professional requires in order to complete the project successfully.",
            "zh": "å‘å±•æƒ…å¢ƒæµç•…æ€§çš„çœŸæ­£æŠ€èƒ½æ˜¯ç¡®å®šåˆ†æä¸“ä¸šäººå‘˜éœ€è¦å¤šå°‘å…³äºåº”ç”¨é¢†åŸŸçš„çŸ¥è¯†æ‰èƒ½æˆåŠŸå®Œæˆé¡¹ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the model the value of w0 is âˆ’ 0.0216, and the values of the Î± parameters are âŸ¨1.6811,0.2384,0.2055,1.7139âŸ©. What predictions would this model make for the following query instances?",
            "zh": "åœ¨æ¨¡å‹ä¸­ï¼Œw0 çš„å€¼ä¸º âˆ’ 0.0216ï¼ŒÎ±å‚æ•°çš„å€¼ä¸º âŸ¨1.6811,0.2384,0.2055,1.7139âŸ©ã€‚æ­¤æ¨¡å‹å°†å¯¹ä»¥ä¸‹æŸ¥è¯¢å®ä¾‹åšå‡ºå“ªäº›é¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The instances shown in Figure 5.14(a)[218] are based on this mobile telecoms scenario.",
            "zh": "å›¾5.14ï¼ˆaï¼‰[218]ä¸­æ‰€ç¤ºçš„å®ä¾‹åŸºäºæ­¤ç§»åŠ¨ç”µä¿¡åœºæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22(b)[361] shows a similar diagram but with a different decision boundary, which has a much larger margin.",
            "zh": "å›¾7.22ï¼ˆbï¼‰[361]æ˜¾ç¤ºäº†ä¸€ä¸ªç±»ä¼¼çš„å›¾è¡¨ï¼Œä½†å†³ç­–è¾¹ç•Œä¸åŒï¼Œå…¶ä½™é‡è¦å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that in generating the feature map for each of these equations, we have applied the rectified linear activation function to the results of the weighted sum of each receptive field and the filter.43",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨ä¸ºæ¯ä¸ªæ–¹ç¨‹ç”Ÿæˆç‰¹å¾å›¾æ—¶ï¼Œæˆ‘ä»¬å·²å°†ä¿®æ­£çº¿æ€§æ¿€æ´»å‡½æ•°åº”ç”¨äºæ¯ä¸ªæ„Ÿå—é‡å’Œæ»¤æ³¢å™¨çš„åŠ æƒå’Œçš„ç»“æœ43ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.18",
            "zh": "è¡¨ 6.18"
        }
    },
    {
        "translation": {
            "en": "0.2466",
            "zh": "0.2466"
        }
    },
    {
        "translation": {
            "en": "Once distributions have been fitted to the data, we can extend the naive Bayes domain representation to include the PDFs.",
            "zh": "ä¸€æ—¦åˆ†å¸ƒæ‹Ÿåˆåˆ°æ•°æ®ä¸­ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ‰©å±•æœ´ç´ è´å¶æ–¯åŸŸè¡¨ç¤ºä»¥åŒ…æ‹¬ PDFã€‚"
        }
    },
    {
        "translation": {
            "en": "generative model, 733",
            "zh": "ç”Ÿæˆæ¨¡å‹ï¼Œ733"
        }
    },
    {
        "translation": {
            "en": "Edwin agreed with both of these suggestions.",
            "zh": "åŸƒå¾·æ¸©åŒæ„è¿™ä¸¤ä¸ªå»ºè®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.13[157] lists a validation dataset for this domain, and Figure 4.19[158] illustrates how this validation dataset is used to perform reduced error pruning.",
            "zh": "è¡¨ 4.13[157] åˆ—å‡ºäº†è¯¥åŸŸçš„éªŒè¯æ•°æ®é›†ï¼Œå›¾ 4.19[158] è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨æ­¤éªŒè¯æ•°æ®é›†æ‰§è¡Œå‡å°‘é”™è¯¯ä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "A simple bicycle demand predictions dataset and the workings of the first iterations of training a gradient boosting model.",
            "zh": "ä¸€ä¸ªç®€å•çš„è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®é›†å’Œè®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹çš„ç¬¬ä¸€æ¬¡è¿­ä»£çš„å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use ğ•„ to refer to a model.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ M æ¥æŒ‡ä»£æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.7",
            "zh": "è¡¨ 7.7"
        }
    },
    {
        "translation": {
            "en": "Table 6.13",
            "zh": "è¡¨ 6.13"
        }
    },
    {
        "translation": {
            "en": "A predictive model overfits the training set when at least some of the predictions it returns are based on spurious patterns present in the training data used to induce the model.",
            "zh": "å½“é¢„æµ‹æ¨¡å‹è¿”å›çš„è‡³å°‘ä¸€äº›é¢„æµ‹åŸºäºç”¨äºè¯±å¯¼æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„è™šå‡æ¨¡å¼æ—¶ï¼Œé¢„æµ‹æ¨¡å‹ä¼šè¿‡åº¦æ‹Ÿåˆè®­ç»ƒé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second phenomenon is that there is a difference in the number of times that each pixel in the image is used as an input to a neuron in the grid.",
            "zh": "ç¬¬äºŒä¸ªç°è±¡æ˜¯ï¼Œå›¾åƒä¸­æ¯ä¸ªåƒç´ è¢«ç”¨ä½œç½‘æ ¼ä¸­ç¥ç»å…ƒè¾“å…¥çš„æ¬¡æ•°å­˜åœ¨å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The absence of ground truth, as discussed in the previous section, makes this choice notoriously difficult.",
            "zh": "æ­£å¦‚ä¸Šä¸€èŠ‚æ‰€è®¨è®ºçš„ï¼Œç¼ºä¹åŸºæœ¬äº‹å®ä½¿å¾—è¿™ç§é€‰æ‹©å˜å¾—éå¸¸å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross further divided this dataset into three randomly sampled partitionsâ€”a training partition (50%), a validation partition (20%) and a test partition (30%). The training partition was used as the core training data for the prediction models built. The validation partition was used for tuning tasks, and the test partition was used for nothing other than a final test of the model to evaluate its performance.",
            "zh": "Ross è¿›ä¸€æ­¥å°†è¯¥æ•°æ®é›†åˆ†ä¸ºä¸‰ä¸ªéšæœºæŠ½æ ·åˆ†åŒºâ€”â€”è®­ç»ƒåˆ†åŒº ï¼ˆ50%ï¼‰ã€éªŒè¯åˆ†åŒº ï¼ˆ20%ï¼‰ å’Œæµ‹è¯•åˆ†åŒº ï¼ˆ30%ï¼‰ã€‚è®­ç»ƒåˆ†åŒºè¢«ç”¨ä½œæ„å»ºçš„é¢„æµ‹æ¨¡å‹çš„æ ¸å¿ƒè®­ç»ƒæ•°æ®ã€‚éªŒè¯åˆ†åŒºç”¨äºè°ƒæ•´ä»»åŠ¡ï¼Œè€Œæµ‹è¯•åˆ†åŒºä»…ç”¨äºå¯¹æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•ä»¥è¯„ä¼°å…¶æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the variance of the Î´s across for the neurons in the last hidden layer in the first iteration of training.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—è®­ç»ƒç¬¬ä¸€æ¬¡è¿­ä»£ä¸­æœ€åä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„ Î´s æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is a slight shift in emphasis here from evaluating the performance of one model, to evaluating the performance of a set of k models.",
            "zh": "è¿™é‡Œçš„é‡ç‚¹ç•¥æœ‰å˜åŒ–ï¼Œä»è¯„ä¼°ä¸€ä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œåˆ°è¯„ä¼°ä¸€ç»„ k ä¸ªæ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are different ways in which a test set can be constructed from a dataset, but the simplest is to use what is referred to as a hold-out test set. A hold-out test set is created by randomly sampling a portion of the data in the ABT we created in the Data Preparation phase. This random sample is never used in the training process but reserved until after the model has been trained, when we would like to evaluate its performance. Figure 9.1[536] illustrates this process.",
            "zh": "ä»æ•°æ®é›†æ„å»ºæµ‹è¯•é›†çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œä½†æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨æ‰€è°“çš„ä¿ç•™æµ‹è¯•é›†ã€‚é€šè¿‡éšæœºæŠ½å–æˆ‘ä»¬åœ¨æ•°æ®å‡†å¤‡é˜¶æ®µåˆ›å»ºçš„ ABT ä¸­çš„éƒ¨åˆ†æ•°æ®æ¥åˆ›å»ºä¿ç•™æµ‹è¯•é›†ã€‚è¿™ä¸ªéšæœºæ ·æœ¬æ°¸è¿œä¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨ï¼Œè€Œæ˜¯ä¿ç•™åˆ°æ¨¡å‹è®­ç»ƒå®Œæ¯•åï¼Œæˆ‘ä»¬æƒ³è¯„ä¼°å®ƒçš„æ€§èƒ½ã€‚å›¾ 9.1[536] è¯´æ˜äº†è¿™ä¸€è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35[497] presents a schematic of how two convolutional layers might be sequenced in a simple convolutional neural network.",
            "zh": "å›¾ 8.35[497] æ˜¾ç¤ºäº†å¦‚ä½•åœ¨ç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œä¸­å¯¹ä¸¤ä¸ªå·ç§¯å±‚è¿›è¡Œæµ‹åºçš„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.4[660] shows a grid world in which an agent must traverse an environment fraught with dangers.",
            "zh": "å›¾ 11.4[660] æ˜¾ç¤ºäº†ä¸€ä¸ªç½‘æ ¼ä¸–ç•Œï¼Œåœ¨è¿™ä¸ªä¸–ç•Œä¸­ï¼Œæ™ºèƒ½ä½“å¿…é¡»ç©¿è¶Šä¸€ä¸ªå……æ»¡å±é™©çš„ç¯å¢ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "CLUMPTHICKNESS",
            "zh": "ç»“å—åšåº¦"
        }
    },
    {
        "translation": {
            "en": "Schematic of the typical sequences of layers found in a convolutional neural network.",
            "zh": "åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­å‘ç°çš„å…¸å‹å±‚åºåˆ—çš„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "equal-frequency binning, 89, 91, 102, 280, 294, 307",
            "zh": "ç­‰é¢‘åˆ†æ¡£ï¼Œ 89ï¼Œ 91ï¼Œ 102ï¼Œ 280ï¼Œ 294ï¼Œ 307"
        }
    },
    {
        "translation": {
            "en": "This reflects the fact that if we use a bigger sample, we can be more confident in our approximations of the characteristics of the full population.",
            "zh": "è¿™åæ˜ äº†è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å¦‚æœæˆ‘ä»¬ä½¿ç”¨æ›´å¤§çš„æ ·æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ•´ä¸ªæ€»ä½“ç‰¹å¾çš„è¿‘ä¼¼å€¼æ›´æœ‰ä¿¡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "31. In this case, we chose to standardize the features in the data rather than range-normalize them, in order to align the data configurations used to generate the plots in this section with the assumptions made in the accompanying mathematical analysis.",
            "zh": "31. åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€‰æ‹©å¯¹æ•°æ®ä¸­çš„ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè€Œä¸æ˜¯å¯¹å®ƒä»¬è¿›è¡ŒèŒƒå›´å½’ä¸€åŒ–ï¼Œä»¥ä¾¿ä½¿ç”¨äºç”Ÿæˆæœ¬èŠ‚ä¸­ç»˜å›¾çš„æ•°æ®é…ç½®ä¸éšé™„çš„æ•°å­¦åˆ†æä¸­æ‰€åšçš„å‡è®¾ä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.11â€…â€…â€…The final vegetation classification decision tree.",
            "zh": "4.11 æœ€ç»ˆçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.1",
            "zh": "è¡¨ 7.1"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23",
            "zh": "å›¾ 8.23"
        }
    },
    {
        "translation": {
            "en": "12.1â€ƒBusiness Understanding",
            "zh": "12.1 ä¸šåŠ¡ç†è§£"
        }
    },
    {
        "translation": {
            "en": "ME1E2ERR_U/G/R/I/Z",
            "zh": "ME1E2ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "cosine, 216",
            "zh": "ä½™å¼¦ï¼Œ 216"
        }
    },
    {
        "translation": {
            "en": "The existence of N rays was first hinted at in an experiment performed at the lab that was designed to answer questions about the exact nature of the recently discovered X-ray radiation.",
            "zh": "Nå°„çº¿çš„å­˜åœ¨æœ€åˆæ˜¯åœ¨å®éªŒå®¤è¿›è¡Œçš„ä¸€é¡¹å®éªŒä¸­æš—ç¤ºçš„ï¼Œè¯¥å®éªŒæ—¨åœ¨å›ç­”æœ‰å…³æœ€è¿‘å‘ç°çš„Xå°„çº¿è¾å°„çš„ç¡®åˆ‡æ€§è´¨çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently they are pure sets, and these partitions can be converted into leaf nodes.",
            "zh": "å› æ­¤ï¼Œå®ƒä»¬æ˜¯çº¯é›†åˆï¼Œè¿™äº›åˆ†åŒºå¯ä»¥è½¬æ¢ä¸ºå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This tree results in a slightly lower classification accuracy on the test partition, 78.5%, but is very easy to interpretâ€”the key features in determining churn are clearly AVGOVERBUNDLEMINS, BILLAMOUNTCHANGEPCT, and HANDSETAGE.",
            "zh": "æ­¤æ ‘å¯¼è‡´æµ‹è¯•åˆ†åŒºçš„åˆ†ç±»å‡†ç¡®ç‡ç•¥ä½ï¼Œä¸º 78.5%ï¼Œä½†éå¸¸æ˜“äºè§£é‡Š â€” ç¡®å®šæµå¤±çš„å…³é”®ç‰¹å¾æ˜¾ç„¶æ˜¯ AVGOVERBUNDLEMINSã€BILLAMOUNTCHANGEPCT å’Œ HANDSETAGEã€‚"
        }
    },
    {
        "translation": {
            "en": "ENERGY",
            "zh": "èƒ½æº"
        }
    },
    {
        "translation": {
            "en": "Bertsekas (2017) is also an excellent and detailed textbook that covers the fundamentals of reinforcement learning, with a leaning toward solutions based on dynamic programming.",
            "zh": "Bertsekasï¼ˆ2017ï¼‰ä¹Ÿæ˜¯ä¸€æœ¬ä¼˜ç§€è€Œè¯¦ç»†çš„æ•™ç§‘ä¹¦ï¼Œæ¶µç›–äº†å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œå€¾å‘äºåŸºäºåŠ¨æ€è§„åˆ’çš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The max pooling units have a receptive field of 2-by-1, and there is no overlap between the receptive fields of the max pooling units.",
            "zh": "æœ€å¤§æ± åŒ–å•å…ƒçš„æ„Ÿå—é‡ä¸º 2Ã—1ï¼Œå¹¶ä¸”æœ€å¤§æ± åŒ–å•å…ƒçš„æ„Ÿå—é‡ä¹‹é—´æ²¡æœ‰é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "Friedman, J., J. Bently, and R. Finkel. 1977. An algorithm for finding the best matches in logarithmic expected time. ACM Transactions on Mathematical Software 3 (3): 209â€“226.",
            "zh": "å¼—é‡Œå¾·æ›¼ï¼ŒJ.ï¼ŒJ.æœ¬ç‰¹åˆ©å’ŒR.èŠ¬å…‹å°”ã€‚1977. ä¸€ç§åœ¨å¯¹æ•°é¢„æœŸæ—¶é—´å†…å¯»æ‰¾æœ€ä½³åŒ¹é…çš„ç®—æ³•ã€‚ACM æ•°å­¦è½¯ä»¶æ±‡åˆŠ 3 ï¼ˆ3ï¼‰ï¼š209â€“226ã€‚"
        }
    },
    {
        "translation": {
            "en": "replicated training set, 160",
            "zh": "å¤åˆ¶è®­ç»ƒé›†ï¼Œ160"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the sum of squared errors for the set of predictions generated in Part (a).",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—ï¼ˆaï¼‰éƒ¨åˆ†ä¸­ç”Ÿæˆçš„ä¸€ç»„é¢„æµ‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "In TwentyTwos the player tries to collect a hand of cards that have a total value higher than the total value of the cards in the dealerâ€™s hand, but not exceeding 22â€”a player is said to go bust when they exceed 22.",
            "zh": "åœ¨ TwentyTwos ä¸­ï¼Œç©å®¶è¯•å›¾æ”¶é›†ä¸€æ‰‹æ€»ä»·å€¼é«˜äºåº„å®¶æ‰‹ä¸­ç‰Œæ€»ä»·å€¼ä½†ä¸è¶…è¿‡ 22 çš„ç‰Œâ€”â€”å½“ç©å®¶è¶…è¿‡ 22 æ—¶ï¼Œæ®è¯´ç©å®¶ä¼šç ´äº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a k-NN model trained on a churn prediction problem.",
            "zh": "é’ˆå¯¹æµå¤±é¢„æµ‹é—®é¢˜è®­ç»ƒçš„ k-NN æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Which customers were most likely to churn in the near future?",
            "zh": "å“ªäº›å®¢æˆ·æœ€æœ‰å¯èƒ½åœ¨ä¸ä¹…çš„å°†æ¥æµå¤±ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Franklin, Janet, Paul McCullough, and Curtis Gray. 2000. Terrain variables used for predictive mapping of vegetation communities in Southern California. In Terrain analysis: Principles and applications, eds. John P. Wilson and John C. Gallant. Wiley.",
            "zh": "å¯Œå…°å…‹æ—ã€çå¦®ç‰¹ã€ä¿ç½—Â·éº¦å¡æ´›å’ŒæŸ¯è’‚æ–¯Â·æ ¼é›·ã€‚2000. ç”¨äºå—åŠ å·æ¤è¢«ç¾¤è½é¢„æµ‹æµ‹ç»˜çš„åœ°å½¢å˜é‡.åœ¨ã€Šåœ°å½¢åˆ†æï¼šåŸç†å’Œåº”ç”¨ã€‹ä¸­ï¼ŒJohn P. Wilson å’Œ John C. Gallant ç¼–è¾‘ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov statistic, 563, 583",
            "zh": "Kolmogorov-Smirnovç»Ÿè®¡ï¼Œ563,583"
        }
    },
    {
        "translation": {
            "en": "feature, 45, 758",
            "zh": "åŠŸèƒ½ï¼Œ 45ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "In Line 7[476] the elementwise multiplication of the vector containing the activations of the neurons in the layer and the DropMask vector is performed (we use the notation âŠ™ to denote an elementwise product).39 In the updated activation vector a(l)â€² generated by this multiplication, the activations for all the neurons whose position in the activation vector correspond with a 0 value in DropMask will be 0.",
            "zh": "åœ¨ç¬¬ 7 è¡Œ[476] ä¸­ï¼Œå¯¹åŒ…å«å±‚ä¸­ç¥ç»å…ƒæ¿€æ´»çš„å‘é‡å’Œ DropMask å‘é‡è¿›è¡Œé€å…ƒç´ ä¹˜æ³•ï¼ˆæˆ‘ä»¬ä½¿ç”¨ç¬¦å· âŠ™ è¡¨ç¤ºé€å…ƒç´ ä¹˜ç§¯ï¼‰.39 åœ¨ç”±æ­¤ä¹˜æ³•ç”Ÿæˆçš„æ›´æ–°æ¿€æ´»å‘é‡ aï¼ˆlï¼‰â€² ä¸­ï¼Œæ‰€æœ‰ç¥ç»å…ƒçš„æ¿€æ´»åœ¨æ¿€æ´»å‘é‡ä¸­çš„ä½ç½®ä¸ DropMask ä¸­çš„ 0 å€¼ç›¸å¯¹åº”ï¼Œå°†ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the larger the variance of a feature, the less weight the difference between the values for that feature will contribute to the distance calculation.",
            "zh": "é¦–å…ˆï¼Œè¦ç´ çš„æ–¹å·®è¶Šå¤§ï¼Œè¯¥è¦ç´ å€¼ä¹‹é—´çš„å·®å¯¹è·ç¦»è®¡ç®—çš„å½±å“å°±è¶Šå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A grid world environment is defined by a rectangular grid in which an agent occupies a single cell and can move horizontally or vertically, one cell at a time, across the world.",
            "zh": "ç½‘æ ¼ä¸–ç•Œç¯å¢ƒç”±çŸ©å½¢ç½‘æ ¼å®šä¹‰ï¼Œå…¶ä¸­ä»£ç†å æ®å•ä¸ªåƒå…ƒï¼Œå¹¶ä¸”å¯ä»¥æ°´å¹³æˆ–å‚ç›´ç§»åŠ¨ï¼Œä¸€æ¬¡ä¸€ä¸ªåƒå…ƒï¼Œéå¸ƒæ•´ä¸ªä¸–ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This section covers the reasonably simple adjustments that must be made to the multivariable linear regression with gradient descent algorithm to handle categorical target features, in particular, logistic regression.",
            "zh": "æœ¬èŠ‚ä»‹ç»å¿…é¡»å¯¹å…·æœ‰æ¢¯åº¦ä¸‹é™ç®—æ³•çš„å¤šå˜é‡çº¿æ€§å›å½’è¿›è¡Œç›¸å½“ç®€å•çš„è°ƒæ•´ï¼Œä»¥å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼Œç‰¹åˆ«æ˜¯é€»è¾‘å›å½’ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4.5â€ƒModel Ensembles",
            "zh": "4.4.5 æ¨¡å‹é›†åˆ"
        }
    },
    {
        "translation": {
            "en": "The matrix in the middle of Equation (8.95)[491] represents the 3-by-3 sub-sampling layer.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.95ï¼‰[491]ä¸­é—´çš„çŸ©é˜µè¡¨ç¤º3Ã—3å­é‡‡æ ·å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "As the error rate of the root node of the subtree is higher than the error rate of the leaf nodes, the tree is not pruned.",
            "zh": "ç”±äºå­æ ‘æ ¹èŠ‚ç‚¹çš„é”™è¯¯ç‡é«˜äºå¶èŠ‚ç‚¹çš„é”™è¯¯ç‡ï¼Œå› æ­¤ä¸ä¼šä¿®å‰ªæ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The product of two vectors of the same dimensions is known as the dot product. For example, given two row vectors F and G, both of which have dimensions 1 Ã— 3",
            "zh": "ä¸¤ä¸ªç›¸åŒç»´åº¦çš„å‘é‡çš„ä¹˜ç§¯ç§°ä¸ºç‚¹ç§¯ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸¤ä¸ªè¡Œå‘é‡ F å’Œ Gï¼Œå®ƒä»¬çš„ç»´åº¦åˆ†åˆ«ä¸º 1 Ã— 3"
        }
    },
    {
        "translation": {
            "en": "Each subfigure highlights the local receptive field in the input of the highlighted neuron in the set of neurons.",
            "zh": "æ¯ä¸ªå­å›¾çªå‡ºæ˜¾ç¤ºäº†ä¸€ç»„ç¥ç»å…ƒä¸­çªå‡ºæ˜¾ç¤ºçš„ç¥ç»å…ƒè¾“å…¥ä¸­çš„å±€éƒ¨æ„Ÿå—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.7â€…â€…â€…The out-of-time sampling process.",
            "zh": "9.7 ä¸åˆæ—¶å®œçš„æŠ½æ ·è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "fail",
            "zh": "å¤±è´¥"
        }
    },
    {
        "translation": {
            "en": "In defining target features, it is especially important to seek input from domain experts.",
            "zh": "åœ¨å®šä¹‰ç›®æ ‡ç‰¹å¾æ—¶ï¼Œå¯»æ±‚é¢†åŸŸä¸“å®¶çš„æ„è§å°¤ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are based on the concepts of a feature space and measures of similarity within this feature space. We have claimed that this is a very natural way for humans to think, and indeed, there is evidence from cognitive science to support a geometric basis to human thought (GÃ¤denfors, 2004). GÃ¤denfors (2004) also provides an excellent introduction and overview of distance metrics.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹åŸºäºç‰¹å¾ç©ºé—´çš„æ¦‚å¿µå’Œè¯¥ç‰¹å¾ç©ºé—´å†…ç›¸ä¼¼æ€§çš„åº¦é‡ã€‚æˆ‘ä»¬å£°ç§°è¿™æ˜¯äººç±»æ€ç»´çš„ä¸€ç§éå¸¸è‡ªç„¶çš„æ–¹å¼ï¼Œäº‹å®ä¸Šï¼Œè®¤çŸ¥ç§‘å­¦çš„è¯æ®æ”¯æŒäººç±»æ€ç»´çš„å‡ ä½•åŸºç¡€ï¼ˆGÃ¤denforsï¼Œ2004ï¼‰ã€‚GÃ¤denforsï¼ˆ2004ï¼‰ä¹Ÿå¯¹è·ç¦»æŒ‡æ ‡è¿›è¡Œäº†å¾ˆå¥½çš„ä»‹ç»å’Œæ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The four factors required to represent the full joint distribution over the features HEADACHE, FEVER, VOMITING, and MENINGITIS (when the first three are assumed to be conditionally independent given MENINGITIS) can be stated as",
            "zh": "è¡¨ç¤ºå¤´ç—›ã€å‘çƒ­ã€å‘•åå’Œè„‘è†œç‚ç‰¹å¾çš„å®Œæ•´å…³èŠ‚åˆ†å¸ƒæ‰€éœ€çš„å››ä¸ªå› ç´ ï¼ˆå½“å‰ä¸‰ä¸ªå› ç´ è¢«å‡å®šä¸ºæœ‰æ¡ä»¶ç‹¬ç«‹äºè„‘è†œç‚æ—¶ï¼‰å¯ä»¥è¡¨ç¤ºä¸º"
        }
    },
    {
        "translation": {
            "en": "1. Many computational models have the ability of universal approximation of bounded continuous functions; this property is not unique to neural networks (Reed and Marks, 1999). However, these results are still important because they show that neural networks with at least one hidden layer do have the representational capacity to approximate most functions that we would like them to. If neural networks were not capable of universal approximation, then they would be much less useful for prediction.",
            "zh": "1.è®¸å¤šè®¡ç®—æ¨¡å‹å…·æœ‰æœ‰ç•Œè¿ç»­å‡½æ•°çš„æ™®éé€¼è¿‘èƒ½åŠ›;è¿™ç§ç‰¹æ€§å¹¶éç¥ç»ç½‘ç»œæ‰€ç‹¬æœ‰ï¼ˆReed and Marksï¼Œ 1999ï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›ç»“æœä»ç„¶å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä»¬è¡¨æ˜ï¼Œå…·æœ‰è‡³å°‘ä¸€ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œç¡®å®å…·æœ‰è¿‘ä¼¼æˆ‘ä»¬å¸Œæœ›å®ƒä»¬å®ç°çš„å¤§å¤šæ•°å‡½æ•°çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å¦‚æœç¥ç»ç½‘ç»œä¸èƒ½è¿›è¡Œæ™®éè¿‘ä¼¼ï¼Œé‚£ä¹ˆå®ƒä»¬å¯¹é¢„æµ‹çš„ç”¨å¤„å°±ä¼šå°å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "In this book we do not describe this step of the process in detail.23 Instead, we focus on explaining how the process is set up and how the training process reflects the inductive bias of searching for the separating hyperplane with the maximum margin.",
            "zh": "åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰è¯¦ç»†æè¿°è¯¥è¿‡ç¨‹çš„è¿™ä¸€æ­¥éª¤.23 ç›¸åï¼Œæˆ‘ä»¬ä¸“æ³¨äºè§£é‡Šè¯¥è¿‡ç¨‹æ˜¯å¦‚ä½•å»ºç«‹çš„ï¼Œä»¥åŠè®­ç»ƒè¿‡ç¨‹å¦‚ä½•åæ˜ æœç´¢å…·æœ‰æœ€å¤§ä½™é‡çš„åˆ†ç¦»è¶…å¹³é¢çš„å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Plots of the logistic function and its derivative. This figure is Figure 4.6 of Kelleher (2019) and is used here with permission.",
            "zh": "é€»è¾‘å‡½æ•°åŠå…¶å¯¼æ•°çš„å›¾ã€‚æ­¤å›¾æ˜¯ Kelleher ï¼ˆ2019ï¼‰ çš„å›¾ 4.6ï¼Œç»è®¸å¯åœ¨æ­¤å¤„ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection has the advantage that it allows for the inclusion of sets of interacting features that individually may not be predictive (because all features are included at the beginning), with the extra computational cost of evaluating larger feature subsets.",
            "zh": "å‘åé¡ºåºé€‰æ‹©çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒå…è®¸åŒ…å«ä¸€ç»„ç›¸äº’ä½œç”¨çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å•ç‹¬å¯èƒ½æ— æ³•é¢„æµ‹ï¼ˆå› ä¸ºæ‰€æœ‰ç‰¹å¾éƒ½åŒ…å«åœ¨å¼€å§‹æ—¶ï¼‰ï¼Œå¹¶ä¸”è¯„ä¼°æ›´å¤§çš„ç‰¹å¾å­é›†ä¼šäº§ç”Ÿé¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, Neuron 3 illustrates that even with the heuristic of setting the bias weights to 0.1, a ReLU may still not activate to every (or in extreme cases any) input pattern.",
            "zh": "å› æ­¤ï¼ŒNeuron 3 è¡¨æ˜ï¼Œå³ä½¿é‡‡ç”¨å°†åç½®æƒé‡è®¾ç½®ä¸º 0.1 çš„å¯å‘å¼æ–¹æ³•ï¼ŒReLU å¯èƒ½ä»ç„¶æ— æ³•æ¿€æ´»åˆ°æ¯ä¸ªï¼ˆæˆ–åœ¨æç«¯æƒ…å†µä¸‹ä»»ä½•ï¼‰è¾“å…¥æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.30",
            "zh": "å›¾ 8.30"
        }
    },
    {
        "translation": {
            "en": "For example, in a customer churn scenario, we might use details of customer behavior from one year to build a training set and details of customer behavior from a subsequent year to build a test set.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å®¢æˆ·æµå¤±åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨ä¸€å¹´çš„å®¢æˆ·è¡Œä¸ºè¯¦ç»†ä¿¡æ¯æ¥æ„å»ºè®­ç»ƒé›†ï¼Œå¹¶ä½¿ç”¨ä¸‹ä¸€å¹´çš„å®¢æˆ·è¡Œä¸ºè¯¦ç»†ä¿¡æ¯æ¥æ„å»ºæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.19[441] illustrates the forward pass for d2 through the ReLU network.",
            "zh": "å›¾ 8.19[441] è¯´æ˜äº† d2 é€šè¿‡ ReLU ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "MAE, 577",
            "zh": "æ¢…ï¼Œ577"
        }
    },
    {
        "translation": {
            "en": "A new model, Î”2, is trained to predict these errors on the basis of the original descriptive feature values.",
            "zh": "è®­ç»ƒæ–°æ¨¡å‹ Î”2 ä»¥æ ¹æ®åŸå§‹æè¿°æ€§ç‰¹å¾å€¼é¢„æµ‹è¿™äº›è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "True Positive (TP): an instance in the test set that had a positive target feature value and that was predicted to have a positive target feature value",
            "zh": "çœŸé˜³æ€§ ï¼ˆTPï¼‰ï¼šæµ‹è¯•é›†ä¸­å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼ä¸”é¢„æµ‹å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "Each iteration of the for loop (Lines 4[420] to 31[420]) involves the processing of a single mini-batch, including both a forward and backward pass of the algorithm and a single set of weight updates.",
            "zh": "for å¾ªç¯çš„æ¯æ¬¡è¿­ä»£ï¼ˆç¬¬ 4 è¡Œ [420] åˆ° 31[420]ï¼‰éƒ½æ¶‰åŠå•ä¸ªå°æ‰¹é‡çš„å¤„ç†ï¼ŒåŒ…æ‹¬ç®—æ³•çš„æ­£å‘å’Œå‘åä¼ é€’ä»¥åŠä¸€ç»„æƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "BMI: The patientâ€™s body mass index (BMI) which is calculated as where weight is measured in kilograms and height in meters.",
            "zh": "BMIï¼šæ‚£è€…çš„ä½“é‡æŒ‡æ•° ï¼ˆBMIï¼‰ï¼Œè®¡ç®—ä¸ºä»¥å…¬æ–¤ä¸ºå•ä½æµ‹é‡ä½“é‡ï¼Œä»¥ç±³ä¸ºå•ä½æµ‹é‡èº«é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have introduced information theory as a method of determining the shortest sequence of descriptive feature tests required to make a prediction.",
            "zh": "æˆ‘ä»¬å¼•å…¥äº†ä¿¡æ¯è®ºä½œä¸ºç¡®å®šè¿›è¡Œé¢„æµ‹æ‰€éœ€çš„æœ€çŸ­æè¿°æ€§ç‰¹å¾æµ‹è¯•åºåˆ—çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6",
            "zh": "å›¾ 6.6"
        }
    },
    {
        "translation": {
            "en": "6.7â€…â€…â€…Exercises",
            "zh": "6.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "(short) (broad)â€ is another one-semester machine learning course.",
            "zh": "ï¼ˆçŸ­ï¼‰ï¼ˆbroadï¼‰â€œæ˜¯å¦ä¸€é—¨ä¸ºæœŸä¸€å­¦æœŸçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.7",
            "zh": "è¡¨ 3.7"
        }
    },
    {
        "translation": {
            "en": "3.4â€…â€…â€…An illustration of the 68â€“95â€“99.7 rule. The gray region defines the area where 95% of values in a sample are expected.",
            "zh": "3.4 68-95-99.7è§„åˆ™çš„ä¾‹è¯ã€‚ç°è‰²åŒºåŸŸå®šä¹‰äº†æ ·æœ¬ä¸­ 95% çš„å€¼çš„é¢„æœŸåŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "30. For more on the standardization of inputs, see the discussion on data preprocessing at the start of the worked example in Section 8.3.5[421].",
            "zh": "30. æœ‰å…³è¾“å…¥æ ‡å‡†åŒ–çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ç¬¬ 8.3.5 èŠ‚ [421] ä¸­å·¥ä½œç¤ºä¾‹å¼€å¤´å…³äºæ•°æ®é¢„å¤„ç†çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The median is another very useful measure of the central tendency of a sample.",
            "zh": "ä¸­ä½æ•°æ˜¯è¡¡é‡æ ·æœ¬é›†ä¸­è¶‹åŠ¿çš„å¦ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, error gradients with respect to the cell state, c, are not repeatedly multiplied by a (weight) term that is shared across time-steps, and so these gradients are relatively stable as they flow backward along the cell state path.",
            "zh": "å› æ­¤ï¼Œä¸å•å…ƒçŠ¶æ€ c ç›¸å…³çš„è¯¯å·®æ¢¯åº¦ä¸ä¼šé‡å¤ä¹˜ä»¥è·¨æ—¶é—´æ­¥é•¿å…±äº«çš„ï¼ˆæƒé‡ï¼‰é¡¹ï¼Œå› æ­¤è¿™äº›æ¢¯åº¦åœ¨æ²¿å•å…ƒçŠ¶æ€è·¯å¾„å‘åæµåŠ¨æ—¶ç›¸å¯¹ç¨³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The sequence of convolving a filter over an input, then applying a non-linear activation function, and finally sub-sampling the resulting feature maps is relatively standard in most modern convolutional networks, and often this sequence of operations is taken as defining a convolutional layer.",
            "zh": "åœ¨å¤§å¤šæ•°ç°ä»£å·ç§¯ç½‘ç»œä¸­ï¼Œå¯¹è¾“å…¥è¿›è¡Œå·ç§¯æ»¤æ³¢å™¨ï¼Œç„¶ååº”ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæœ€åå¯¹ç”Ÿæˆçš„ç‰¹å¾å›¾è¿›è¡Œå­é‡‡æ ·çš„é¡ºåºæ˜¯ç›¸å¯¹æ ‡å‡†çš„ï¼Œå¹¶ä¸”é€šå¸¸å°†æ­¤æ“ä½œåºåˆ—è§†ä¸ºå®šä¹‰å·ç§¯å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Grid worlds have long been used as a good way to illustrate the operation of reinforcement learning algorithms, and we will use this type of example in this section.",
            "zh": "é•¿æœŸä»¥æ¥ï¼Œç½‘æ ¼ä¸–ç•Œä¸€ç›´è¢«ç”¨ä½œè¯´æ˜å¼ºåŒ–å­¦ä¹ ç®—æ³•æ“ä½œçš„å¥½æ–¹æ³•ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬èŠ‚ä¸­ä½¿ç”¨è¿™ç§ç±»å‹çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These books are suitable as reference texts for experienced practitioners and postgraduate researchers in machine learning.",
            "zh": "è¿™äº›ä¹¦ç±é€‚åˆä½œä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸç»éªŒä¸°å¯Œçš„ä»ä¸šè€…å’Œç ”ç©¶ç”Ÿç ”ç©¶äººå‘˜çš„å‚è€ƒä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dominance is reflected in the ranking of the instances as neighbors.",
            "zh": "è¿™ç§ä¼˜åŠ¿åæ˜ åœ¨å®ä¾‹ä½œä¸ºé‚»å±…çš„æ’åä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Depending on how the value of the dealerâ€™s hand that results from this compares to the value of the playerâ€™s hand the agent will move into one of the terminal states: LOSE, TIE, WIN, or TWENTYTWO.",
            "zh": "æ ¹æ®ç”±æ­¤äº§ç”Ÿçš„åº„å®¶æ‰‹ç‰Œçš„ä»·å€¼ä¸ç©å®¶æ‰‹ç‰Œçš„ä»·å€¼çš„æ¯”è¾ƒæƒ…å†µï¼Œä»£ç†å°†è¿›å…¥æœ€ç»ˆçŠ¶æ€ä¹‹ä¸€ï¼šLOSEã€TIEã€WIN æˆ– TWENTYTWOã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout this chapter we use rt to refer to the reward received after taking an action, at, at time-step t.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ rt æ¥æŒ‡ä»£åœ¨æ—¶é—´æ­¥é•¿ t å¤„é‡‡å–è¡ŒåŠ¨åè·å¾—çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "couple",
            "zh": "å¤«å¦‡"
        }
    },
    {
        "translation": {
            "en": "The volume of data involved. The amount of data that is available to an analytics project is important because (a) some modern datasets are so large that they can stretch even state-of-the-art machine learning tools; and (b) conversely, very small datasets can limit our ability to evaluate the expected performance of a model after deployment.",
            "zh": "æ¶‰åŠçš„æ•°æ®é‡ã€‚å¯ç”¨äºåˆ†æé¡¹ç›®çš„æ•°æ®é‡å¾ˆé‡è¦ï¼Œå› ä¸º ï¼ˆaï¼‰ ä¸€äº›ç°ä»£æ•°æ®é›†éå¸¸å¤§ï¼Œç”šè‡³å¯ä»¥æ‰©å±•æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ å·¥å…·;ï¼ˆbï¼‰ç›¸åï¼Œéå¸¸å°çš„æ•°æ®é›†ä¼šé™åˆ¶æˆ‘ä»¬åœ¨éƒ¨ç½²åè¯„ä¼°æ¨¡å‹é¢„æœŸæ€§èƒ½çš„èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "A logistic regression model has been trained to classify digits as either 0 or 1. The weights in this model are as follows:",
            "zh": "é€»è¾‘å›å½’æ¨¡å‹å·²ç»è¿‡è®­ç»ƒï¼Œå¯å°†æ•°å­—åˆ†ç±»ä¸º 0 æˆ– 1ã€‚è¯¥æ¨¡å‹ä¸­çš„æƒé‡å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "So, the only thing that needs to be taken into account in the state representation is the total value of the cards in the playerâ€™s hand and the value of the visible card dealt to the dealer.",
            "zh": "å› æ­¤ï¼Œåœ¨çŠ¶æ€è¡¨ç¤ºä¸­å”¯ä¸€éœ€è¦è€ƒè™‘çš„æ˜¯ç©å®¶æ‰‹ä¸­çš„ç‰Œçš„æ€»ä»·å€¼ä»¥åŠå‘ç»™åº„å®¶çš„å¯è§ç‰Œçš„ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "R, 222, 276",
            "zh": "Rï¼Œ222,276"
        }
    },
    {
        "translation": {
            "en": "The size of the individual normal density curves is proportional to the weight for that normal used in the mixture.",
            "zh": "å•ä¸ªæ³•çº¿å¯†åº¦æ›²çº¿çš„å¤§å°ä¸æ··åˆç‰©ä¸­ä½¿ç”¨çš„æ³•çº¿çš„é‡é‡æˆæ­£æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate the probability P(h | f) from P(H,F,V,M), we sum the values in all the cells where h and f are the case (the top four cells in the first column).",
            "zh": "ä¸ºäº†ä» Pï¼ˆHï¼ŒFï¼ŒVï¼ŒMï¼‰ è®¡ç®—æ¦‚ç‡ Pï¼ˆh | fï¼‰ï¼Œæˆ‘ä»¬å°† h å’Œ f ä¸ºæƒ…å†µçš„æ‰€æœ‰å•å…ƒæ ¼ï¼ˆç¬¬ä¸€åˆ—ä¸­çš„å‰å››ä¸ªå•å…ƒæ ¼ï¼‰ä¸­çš„å€¼ç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the 68âˆ’95âˆ’99.7 rule. The gray region defines the area where 95% of values in a sample are expected.",
            "zh": "68âˆ’95âˆ’99.7 è§„åˆ™çš„å›¾ç¤ºã€‚ç°è‰²åŒºåŸŸå®šä¹‰äº†æ ·æœ¬ä¸­ 95% çš„å€¼çš„é¢„æœŸåŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Freund and Schapire (1995) introduced the AdaBoost algorithm, which is one of the seminal boosting algorithms.",
            "zh": "Freund å’Œ Schapire ï¼ˆ1995ï¼‰ å¼•å…¥äº† AdaBoost ç®—æ³•ï¼Œè¿™æ˜¯å¼€åˆ›æ€§çš„æå‡ç®—æ³•ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before attempting this conversion, Ross had to fully understand the business objectives of AT.",
            "zh": "åœ¨å°è¯•è¿™ç§è½¬æ¢ä¹‹å‰ï¼ŒRoss å¿…é¡»å……åˆ†äº†è§£ AT çš„ä¸šåŠ¡ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can help analysts know where to focus when investigating the data quality reports and visualizations created describing each cluster.",
            "zh": "è¿™å¯ä»¥å¸®åŠ©åˆ†æäººå‘˜çŸ¥é“åœ¨è°ƒæŸ¥æè¿°æ¯ä¸ªé›†ç¾¤çš„æ•°æ®è´¨é‡æŠ¥å‘Šå’Œå¯è§†åŒ–æ•ˆæœæ—¶åº”è¯¥å…³æ³¨å“ªé‡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "subagging, 159",
            "zh": "ä¸‹å¡ï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "Because of this, Jocelyn suspected that there would be a large amount of redundancy in the data as the measurements in the different bands were likely to be highly correlated.",
            "zh": "æ­£å› ä¸ºå¦‚æ­¤ï¼ŒJocelyn æ€€ç–‘æ•°æ®ä¸­ä¼šå­˜åœ¨å¤§é‡å†—ä½™ï¼Œå› ä¸ºä¸åŒæ³¢æ®µçš„æµ‹é‡ç»“æœå¯èƒ½é«˜åº¦ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the different iterations of backpropagation during backpropagation through time.",
            "zh": "åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­åå‘ä¼ æ’­çš„ä¸åŒè¿­ä»£çš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "de Fermat, Pierre, 243",
            "zh": "å¾·Â·è´¹é©¬ï¼Œçš®åŸƒå°”ï¼Œ243"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the bike rental dataset from Table 4.14[162].",
            "zh": "ï¼ˆaï¼‰ è¡¨4.14[162]ä¸­çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.72",
            "zh": "0.72"
        }
    },
    {
        "translation": {
            "en": "Training a logistic regression model using this set of basis functions leads to the following model:",
            "zh": "ä½¿ç”¨è¿™ç»„åŸºå‡½æ•°è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹å¯ç”Ÿæˆä»¥ä¸‹æ¨¡å‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Acceleration is a measure of the rate of change of speed over time.",
            "zh": "åŠ é€Ÿåº¦æ˜¯é€Ÿåº¦éšæ—¶é—´å˜åŒ–ç‡çš„é‡åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can recalculate all the elements of the joint probability distribution using the product of these four factors:",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™å››ä¸ªå› å­çš„ä¹˜ç§¯é‡æ–°è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒçš„æ‰€æœ‰å…ƒç´ ï¼š"
        }
    },
    {
        "translation": {
            "en": "This is not always the case, and making any of these partitions too small can result in a poor evaluation.",
            "zh": "æƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤ï¼Œä½¿è¿™äº›åˆ†åŒºä¸­çš„ä»»ä½•ä¸€ä¸ªéƒ½å¤ªå°éƒ½å¯èƒ½å¯¼è‡´è¯„ä¼°ä¸ä½³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problems of outliers and skewed distributions is clearly visible in these distributions.",
            "zh": "åœ¨è¿™äº›åˆ†å¸ƒä¸­ï¼Œå¼‚å¸¸å€¼å’Œåæ€åˆ†å¸ƒçš„é—®é¢˜æ¸…æ™°å¯è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision tree in Figure 4.4(b)[122] would have returned the same prediction for the query instance. Indeed, both of the decision trees in Figures 4.4(a)[122] and 4.4(b)[122] are consistent with the dataset in Table 4.2[121] and can generalize sufficiently to make predictions for query instances like the one considered in our example. The fact that there are, at least, two decision trees that can do this raises the question: How do we decide which is the best decision tree to use?",
            "zh": "å›¾ 4.4ï¼ˆbï¼‰[122] ä¸­çš„å†³ç­–æ ‘å°†è¿”å›æŸ¥è¯¢å®ä¾‹çš„ç›¸åŒé¢„æµ‹ã€‚äº‹å®ä¸Šï¼Œå›¾4.4ï¼ˆaï¼‰[122]å’Œå›¾4.4ï¼ˆbï¼‰[122]ä¸­çš„å†³ç­–æ ‘éƒ½ä¸è¡¨4.2[121]ä¸­çš„æ•°æ®é›†ä¸€è‡´ï¼Œå¹¶ä¸”å¯ä»¥å……åˆ†æ³›åŒ–ï¼Œä»¥ä¾¿å¯¹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œå°±åƒæˆ‘ä»¬ç¤ºä¾‹ä¸­è€ƒè™‘çš„é‚£æ ·ã€‚äº‹å®ä¸Šï¼Œè‡³å°‘æœ‰ä¸¤æ£µå†³ç­–æ ‘å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¿™å°±æå‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•å†³å®šä½¿ç”¨å“ªç§å†³ç­–æ ‘æ˜¯æœ€å¥½çš„ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This leaf node indexes instance d12 (SPEED = 5.00, AGILITY = 2.50).",
            "zh": "æ­¤å¶èŠ‚ç‚¹ä¸ºå®ä¾‹ d12 ï¼ˆSPEED = 5.00ï¼Œ AGILITY = 2.50ï¼‰ ç¼–åˆ¶ç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "GINI COEF measures the equality in a society, where a larger Gini coefficient indicates a more unequal society.",
            "zh": "åŸºå°¼ç³»æ•°COEFè¡¡é‡ä¸€ä¸ªç¤¾ä¼šçš„å¹³ç­‰ï¼ŒåŸºå°¼ç³»æ•°è¶Šå¤§ï¼Œè¡¨æ˜ç¤¾ä¼šè¶Šä¸å¹³ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "sub-sampling layers, 489",
            "zh": "å­é‡‡æ ·å±‚ï¼Œ489"
        }
    },
    {
        "translation": {
            "en": "One of the most commonly used processes for predictive data analytics projects is the Cross Industry Standard Process for Data Mining (CRISP-DM).12 Key features of the CRISP-DM process that make it attractive to data analytics practitioners are that it is non-proprietary; it is application, industry, and tool neutral; and it explicitly views the data analytics process from both an application-focused and a technical perspective.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®æœ€å¸¸ç”¨çš„æµç¨‹ä¹‹ä¸€æ˜¯æ•°æ®æŒ–æ˜çš„è·¨è¡Œä¸šæ ‡å‡†æµç¨‹ ï¼ˆCRISP-DMï¼‰.12 CRISP-DM æµç¨‹çš„ä¸»è¦ç‰¹ç‚¹ä½¿å…¶å¯¹æ•°æ®åˆ†æä»ä¸šè€…å…·æœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒæ˜¯éä¸“æœ‰çš„;å®ƒæ˜¯åº”ç”¨ã€è¡Œä¸šå’Œå·¥å…·ä¸­ç«‹çš„;å®ƒæ˜ç¡®åœ°ä»ä»¥åº”ç”¨ç¨‹åºä¸ºä¸­å¿ƒçš„å’ŒæŠ€æœ¯è§’åº¦çœ‹å¾…æ•°æ®åˆ†æè¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "where",
            "zh": "å“ªé‡Œ"
        }
    },
    {
        "translation": {
            "en": "These histograms show a slight tendency for centers to be a little older than guards and forwards, but the relationship does not appear very strong, as each of the smaller histograms are similar to the overall uniform distribution of the AGE feature.",
            "zh": "è¿™äº›ç›´æ–¹å›¾æ˜¾ç¤ºï¼Œä¸­é”‹æ¯”åå«å’Œå‰é”‹ç¨å¤§ä¸€äº›ï¼Œä½†è¿™ç§å…³ç³»ä¼¼ä¹ä¸æ˜¯å¾ˆå¼ºï¼Œå› ä¸ºæ¯ä¸ªè¾ƒå°çš„ç›´æ–¹å›¾éƒ½ç±»ä¼¼äº AGE ç‰¹å¾çš„æ•´ä½“å‡åŒ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature, PRICE, lists the prices that these properties were sold for in dollars.",
            "zh": "ç›®æ ‡è¦ç´  PRICE åˆ—å‡ºäº†è¿™äº›å±æ€§ä»¥ç¾å…ƒä¸ºå•ä½çš„é”€å”®ä»·æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "11. The co-occurrence of multiple missing values in a row is something that it is hard to find through summary analysis of the data and one of the reasons analytics practitioners should always eyeball extracts from a dataset during the data exploration process.",
            "zh": "11. é€šè¿‡å¯¹æ•°æ®çš„æ€»ç»“åˆ†æå¾ˆéš¾å‘ç°è¿ç»­å¤šä¸ªç¼ºå¤±å€¼çš„å…±ç°ï¼Œè¿™ä¹Ÿæ˜¯åˆ†æä»ä¸šè€…åœ¨æ•°æ®æ¢ç´¢è¿‡ç¨‹ä¸­åº”å§‹ç»ˆå…³æ³¨æ•°æ®é›†ä¸­æå–çš„å†…å®¹çš„åŸå› ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.6",
            "zh": "è¡¨ 9.6"
        }
    },
    {
        "translation": {
            "en": "domain, 34, 757",
            "zh": "åŸŸï¼Œ 34ï¼Œ 757"
        }
    },
    {
        "translation": {
            "en": "The table that follows shows a historical dataset that has been collected for this task.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸ºæ­¤ä»»åŠ¡æ”¶é›†çš„å†å²æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The members of the rival school basketball team from Figure A.3[747] ordered by height.",
            "zh": "å›¾A.3[747]ä¸­æ•Œå¯¹å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜æŒ‰èº«é«˜æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "McGrayne, Sharon Bertsch. 2011. The theory that would not die: How Bayesâ€™ rule cracked the enigma code, hunted down Russian submarines, and emerged triumphant from two centuries of controversy. Yale University Press.",
            "zh": "éº¦å…‹æ ¼é›·æ©ï¼Œèæœ—Â·ä¼¯å¥‡ã€‚2011. ä¸ä¼šæ¶ˆäº¡çš„ç†è®ºï¼šè´å¶æ–¯è§„åˆ™å¦‚ä½•ç ´è§£è°œå›¢å¯†ç ï¼Œè¿½æ•ä¿„ç½—æ–¯æ½œè‰‡ï¼Œå¹¶åœ¨ä¸¤ä¸ªä¸–çºªçš„äº‰è®®ä¸­å–å¾—èƒœåˆ©ã€‚è€¶é²å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Relative rarity, on the other hand, refers to scenarios in which the proportion of examples of the majority target levels in a dataset is much higher than the proportion of examples of the minority target level, but there is actually no shortage of examples of the minority target level.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œç›¸å¯¹ç¨€æœ‰æ€§æ˜¯æŒ‡æ•°æ®é›†ä¸­å¤šæ•°ç›®æ ‡æ°´å¹³çš„æ ·æœ¬æ¯”ä¾‹è¿œé«˜äºå°‘æ•°ç›®æ ‡æ°´å¹³çš„æ ·æœ¬æ¯”ä¾‹ï¼Œä½†å®é™…ä¸Šä¸ä¹å°‘æ•°ç›®æ ‡æ°´å¹³çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "bottleneck layer, 624, 628",
            "zh": "ç“¶é¢ˆå±‚ï¼Œ 624ï¼Œ 628"
        }
    },
    {
        "translation": {
            "en": "Good",
            "zh": "å¥½"
        }
    },
    {
        "translation": {
            "en": "The iterations of reduced error pruning for the decision tree in Figure 4.18[156] using the validation set in Table 4.13[157]. The subtree that is being considered for pruning in each iteration is highlighted in black. The prediction returned by each non-leaf node is listed in square brackets. The error rate for each node is given in parantheses.",
            "zh": "ä½¿ç”¨è¡¨4.13[157]ä¸­çš„éªŒè¯é›†å¯¹å†³ç­–æ ‘è¿›è¡Œå‡å°‘è¯¯å·®ä¿®å‰ªçš„è¿­ä»£[156]ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­è€ƒè™‘ä¿®å‰ªçš„å­æ ‘ä»¥é»‘è‰²çªå‡ºæ˜¾ç¤ºã€‚æ¯ä¸ªéå¶èŠ‚ç‚¹è¿”å›çš„é¢„æµ‹åˆ—åœ¨æ–¹æ‹¬å·ä¸­ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„é”™è¯¯ç‡ä»¥å‚æ•°å½¢å¼ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In the optimal control domain in which the Bellman optimality equations were originally conceived, solutions are calculated using dynamic programming.",
            "zh": "åœ¨æœ€åˆæ„æƒ³è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹çš„æœ€ä¼˜æ§åˆ¶åŸŸä¸­ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’è®¡ç®—è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both of these strategies depend on a reasonable sampling density of the training instances across the feature space.",
            "zh": "è¿™ä¸¤ç§ç­–ç•¥éƒ½ä¾èµ–äºæ•´ä¸ªç‰¹å¾ç©ºé—´ä¸­è®­ç»ƒå®ä¾‹çš„åˆç†é‡‡æ ·å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The confusion matrix for a k-NN model trained on the payday loan credit scoring problem (average class accuracyHM = 83.824%); and (b) the confusion matrix for a decision tree model trained on the payday loan credit scoring problem (average class accuracyHM = 80.761%).",
            "zh": "ï¼ˆaï¼‰ åœ¨å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜ä¸Šè®­ç»ƒçš„ k-NN æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡HM = 83.824%ï¼‰;ï¼ˆbï¼‰åœ¨å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜ä¸Šè®­ç»ƒçš„å†³ç­–æ ‘æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡HM = 80.761%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.29[475] illustrates how different small networks are generated for each training example by randomly dropping neurons from the original large network.",
            "zh": "å›¾ 8.29[475] è¯´æ˜äº†å¦‚ä½•é€šè¿‡ä»åŸå§‹å¤§ç½‘ç»œä¸­éšæœºä¸¢å¼ƒç¥ç»å…ƒæ¥ä¸ºæ¯ä¸ªè®­ç»ƒç¤ºä¾‹ç”Ÿæˆä¸åŒçš„å°ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "At this point in the motor insurance fraud detection project, we have decided to proceed with the proposed claim prediction solution, in which a model will be built that can predict the likelihood that an insurance claim is fraudulent.",
            "zh": "åœ¨æ±½è½¦ä¿é™©æ¬ºè¯ˆæ£€æµ‹é¡¹ç›®çš„è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬å†³å®šç»§ç»­ä½¿ç”¨æ‹Ÿè®®çš„ç´¢èµ”é¢„æµ‹è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­å°†å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ä¿é™©ç´¢èµ”æ¬ºè¯ˆçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The flow of information in Figure 8.40[509] is from left to right.",
            "zh": "å›¾8.40[509]ä¸­çš„ä¿¡æ¯æµæ˜¯ä»å·¦åˆ°å³çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.1â€ƒArtificial Neurons",
            "zh": "8.2.1 äººå·¥ç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "After taking this action (Line 14[666]) and recording the reward, r0 = âˆ’1, and next state, s1 = 0-2, the behavior policy is used to select the next action that the agent will take (Line 14[666]).",
            "zh": "åœ¨æ‰§è¡Œæ­¤æ“ä½œï¼ˆç¬¬ 14 è¡Œ [666]ï¼‰å¹¶è®°å½•å¥–åŠ± r0 = âˆ’1 å’Œä¸‹ä¸€ä¸ªçŠ¶æ€ s1 = 0-2 åï¼Œè¡Œä¸ºç­–ç•¥ç”¨äºé€‰æ‹©ä»£ç†å°†æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªæ“ä½œï¼ˆç¬¬ 14 è¡Œ[666]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. Although we didnâ€™t mention it explicitly in other cases where we mentioned random sampling, we meant random sampling without replacement.",
            "zh": "14. è™½ç„¶æˆ‘ä»¬åœ¨æåˆ°éšæœºæŠ½æ ·çš„å…¶ä»–æƒ…å†µä¸‹æ²¡æœ‰æ˜ç¡®æåˆ°å®ƒï¼Œä½†æˆ‘ä»¬æŒ‡çš„æ˜¯æ²¡æœ‰æ›¿æ¢çš„éšæœºæŠ½æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Library of Congress Cataloging-in-Publication Data",
            "zh": "ç¾å›½å›½ä¼šå›¾ä¹¦é¦†å‡ºç‰ˆç¼–ç›®æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "(a) Some of the model predictions are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "ï¼ˆaï¼‰ ä¸Šè¡¨ä¸­ç¼ºå°‘ä¸€äº›æ¨¡å‹é¢„æµ‹ï¼ˆæ ‡æœ‰ï¼Ÿï¼‰ã€‚è®¡ç®—è¿™äº›ã€‚"
        }
    },
    {
        "translation": {
            "en": "These factors aside, the effectiveness of descriptive feature selection metrics can vary from domain to domain.",
            "zh": "æ’‡å¼€è¿™äº›å› ç´ ä¸è°ˆï¼Œæè¿°æ€§ç‰¹å¾é€‰æ‹©æŒ‡æ ‡çš„æœ‰æ•ˆæ€§å¯èƒ½å› åŸŸè€Œå¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This information should help if the model is to be rebuilt to address the fact that it has gone stale.",
            "zh": "å¦‚æœè¦é‡å»ºæ¨¡å‹ä»¥è§£å†³æ¨¡å‹å·²ç»è¿‡æ—¶çš„äº‹å®ï¼Œåˆ™æ­¤ä¿¡æ¯åº”è¯¥ä¼šæœ‰æ‰€å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "If she repeats this process over and over again, she will make steady progress down the mountain until eventually she arrives at the bottom.",
            "zh": "å¦‚æœå¥¹ä¸€éåˆä¸€éåœ°é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå¥¹å°±ä¼šç¨³æ­¥ä¸‹å±±ï¼Œç›´åˆ°æœ€ç»ˆåˆ°è¾¾å±±è„šä¸‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.24â€…â€…â€…(a) The journey across an error surface; and (b) the changing sums of squared errors during this journey.",
            "zh": "7.24 ï¼ˆaï¼‰ ç©¿è¶Šè¯¯å·®é¢çš„æ—…ç¨‹;ï¼ˆbï¼‰åœ¨æ­¤è¿‡ç¨‹ä¸­å¹³æ–¹è¯¯å·®å’Œçš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "An advantage of the lazy learning strategy, however, is that similarity-based machine learning approaches are robust to concept drift.",
            "zh": "ç„¶è€Œï¼Œæƒ°æ€§å­¦ä¹ ç­–ç•¥çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯ï¼ŒåŸºäºç›¸ä¼¼æ€§çš„æœºå™¨å­¦ä¹ æ–¹æ³•å¯¹æ¦‚å¿µæ¼‚ç§»å…·æœ‰é²æ£’æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words we must backpropagate the error back through the previous states of the network.",
            "zh": "æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¿…é¡»é€šè¿‡ç½‘ç»œçš„å…ˆå‰çŠ¶æ€å°†é”™è¯¯åå‘ä¼ æ’­å›æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note also that the weight matrix labels on the left of the figure are also the correct neuron labels for the weighted sum Z and activation matrix rows on that line.",
            "zh": "å¦è¯·æ³¨æ„ï¼Œå›¾å·¦ä¾§çš„æƒé‡çŸ©é˜µæ ‡ç­¾ä¹Ÿæ˜¯è¯¥çº¿ä¸ŠåŠ æƒæ€»å’Œ Z å’Œæ¿€æ´»çŸ©é˜µè¡Œçš„æ­£ç¡®ç¥ç»å…ƒæ ‡ç­¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each iteration of this for loop propagates the activations for the mini-batch forward through the next layer of the network.",
            "zh": "æ­¤ for å¾ªç¯çš„æ¯æ¬¡è¿­ä»£éƒ½ä¼šå°†å°æ‰¹é‡çš„æ¿€æ´»å‘å‰ä¼ æ’­åˆ°ç½‘ç»œçš„ä¸‹ä¸€å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce a simple model of linear regression, some metrics for measuring the error of a model, and the concept of an error surface.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ã€ä¸€äº›ç”¨äºæµ‹é‡æ¨¡å‹è¯¯å·®çš„æŒ‡æ ‡ä»¥åŠè¯¯å·®é¢çš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5",
            "zh": "å›¾ 11.5"
        }
    },
    {
        "translation": {
            "en": "The bottom row illustrates the operations carried out in the output layer of the network.",
            "zh": "åº•è¡Œè¯´æ˜äº†åœ¨ç½‘ç»œè¾“å‡ºå±‚ä¸­æ‰§è¡Œçš„æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why this set has very high entropy.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™ä¸ªé›†åˆå…·æœ‰éå¸¸é«˜çš„ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "We recommend that, in general, when calculating average class accuracy, the harmonic mean should be used rather than the arithmetic mean.",
            "zh": "æˆ‘ä»¬å»ºè®®ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œåœ¨è®¡ç®—å¹³å‡ç±»ç²¾åº¦æ—¶ï¼Œåº”ä½¿ç”¨è°æ³¢å¹³å‡å€¼è€Œä¸æ˜¯ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prediction subject defines the basic level at which predictions are made, and each row in the ABT will represent one instance of the prediction subjectâ€”the phrase one-row-per-subject is often used to describe this structure.",
            "zh": "é¢„æµ‹ä¸»ä½“å®šä¹‰äº†è¿›è¡Œé¢„æµ‹çš„åŸºæœ¬çº§åˆ«ï¼ŒABT ä¸­çš„æ¯ä¸€è¡Œå°†ä»£è¡¨é¢„æµ‹ä¸»ä½“çš„ä¸€ä¸ªå®ä¾‹ - çŸ­è¯­ one-row-per subject é€šå¸¸ç”¨äºæè¿°è¿™ç§ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "All these factors taken together indicated that decision trees were an appropriate modeling choice for this problem.",
            "zh": "æ‰€æœ‰è¿™äº›å› ç´ åŠ åœ¨ä¸€èµ·è¡¨æ˜ï¼Œå†³ç­–æ ‘æ˜¯è¿™ä¸ªé—®é¢˜çš„åˆé€‚å»ºæ¨¡é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The path taken from the root node to a leaf node when we search the tree with a query SPEED = 6.00, AGILITY = 3.50; and (b) the ? marks the location of the query, and the dashed circle plots the extent of the target, and for convenience in the discussion, we have labeled some of the nodes with the IDs of the instances they index (12, 15, 18, and 21).",
            "zh": "ï¼ˆaï¼‰ å½“æˆ‘ä»¬ä½¿ç”¨æŸ¥è¯¢ SPEED = 6.00ï¼Œ AGILITY = 3.50 æœç´¢æ ‘æ—¶ï¼Œä»æ ¹èŠ‚ç‚¹åˆ°å¶èŠ‚ç‚¹çš„è·¯å¾„;åŠ ï¼ˆbï¼‰ ï¼Ÿæ ‡è®°æŸ¥è¯¢çš„ä½ç½®ï¼Œè™šçº¿åœ†åœˆç»˜åˆ¶ç›®æ ‡çš„èŒƒå›´ï¼Œä¸ºäº†æ–¹ä¾¿è®¨è®ºï¼Œæˆ‘ä»¬ç”¨å®ƒä»¬ç´¢å¼•çš„å®ä¾‹çš„ IDï¼ˆ12ã€15ã€18 å’Œ 21ï¼‰æ ‡è®°äº†ä¸€äº›èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This removes the scaling of the Î´s by the derivative of the activation function, and so in this instance these vanishing gradients are caused by both the repeated multiplication by small weights during backpropagation and the fact that the calculation of a Î´ for a neuron involves a weighted sum calculation33 that in this network configuration results in the variance of the Î´s shrinking as they are backpropagated through the layers.",
            "zh": "è¿™æ¶ˆé™¤äº†æ¿€æ´»å‡½æ•°å¯¼æ•°å¯¹ Î´ çš„ç¼©æ”¾ï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™äº›æ¶ˆå¤±çš„æ¢¯åº¦æ˜¯ç”±åå‘ä¼ æ’­æœŸé—´å°æƒé‡çš„é‡å¤ä¹˜æ³•å¼•èµ·çš„ï¼Œä»¥åŠç¥ç»å…ƒÎ´çš„è®¡ç®—æ¶‰åŠåŠ æƒå’Œè®¡ç®—33ï¼Œåœ¨è¿™ç§ç½‘ç»œé…ç½®ä¸­ï¼Œå½“å®ƒä»¬é€šè¿‡å±‚åå‘ä¼ æ’­æ—¶ï¼Œä¼šå¯¼è‡´ Î´ çš„æ–¹å·®ç¼©å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "So the large positive reward achieved when moving to the terminal state can only impact the Q value of the state that immediately preceded it.",
            "zh": "å› æ­¤ï¼Œåœ¨ç§»åŠ¨åˆ°æœ€ç»ˆçŠ¶æ€æ—¶è·å¾—çš„å¤§é‡æ­£å¥–åŠ±åªèƒ½å½±å“ç´§æ¥å…¶ä¹‹å‰çŠ¶æ€çš„ Q å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even if we discretized each of these 7 characteristics allowing just 5 levels (very low, low, medium, high, and very high), which would be a gross approximation, this would lead to 75 = 16,807 possible states.",
            "zh": "å³ä½¿æˆ‘ä»¬å¯¹è¿™ 7 ä¸ªç‰¹å¾ä¸­çš„æ¯ä¸€ä¸ªéƒ½è¿›è¡Œç¦»æ•£åŒ–ï¼Œåªå…è®¸ 5 ä¸ªçº§åˆ«ï¼ˆéå¸¸ä½ã€ä½ã€ä¸­ã€é«˜å’Œéå¸¸é«˜ï¼‰ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªç²—ç•¥çš„è¿‘ä¼¼å€¼ï¼Œè¿™å°†å¯¼è‡´ 75 = 16,807 ä¸ªå¯èƒ½çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "List of Tables",
            "zh": "è¡¨æ ¼åˆ—è¡¨"
        }
    },
    {
        "translation": {
            "en": "Figure 10.16",
            "zh": "å›¾ 10.16"
        }
    },
    {
        "translation": {
            "en": "Non-parametric models are more flexible but can struggle with large datasets.",
            "zh": "éå‚æ•°æ¨¡å‹æ›´çµæ´»ï¼Œä½†åœ¨å¤„ç†å¤§å‹æ•°æ®é›†æ—¶å¯èƒ½é‡åˆ°å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tanimoto similarity, 223",
            "zh": "è°·æœ¬ç›¸ä¼¼åº¦ï¼Œ223"
        }
    },
    {
        "translation": {
            "en": "Also, we will use subscripts on uppercase letters to iterate over events.",
            "zh": "æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¤§å†™å­—æ¯çš„ä¸‹æ ‡æ¥è¿­ä»£äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once Jocelyn had populated the ABT, she generated a data quality report (the initial data quality report covered the data in the raw SDSS dataset only, so a second one was required that covered the actual ABT) and performed an in-depth analysis of the characteristics of each descriptive feature. An extract from this data quality report is shown in Table 13.4[716].",
            "zh": "Jocelyn å¡«å…… ABT åï¼Œå¥¹ç”Ÿæˆäº†æ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆåˆå§‹æ•°æ®è´¨é‡æŠ¥å‘Šä»…æ¶µç›–åŸå§‹ SDSS æ•°æ®é›†ä¸­çš„æ•°æ®ï¼Œå› æ­¤éœ€è¦ç¬¬äºŒä»½æŠ¥å‘Šæ¥æ¶µç›–å®é™… ABTï¼‰ï¼Œå¹¶å¯¹æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ç‰¹å¾è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è¯¥æ•°æ®è´¨é‡æŠ¥å‘Šçš„æ‘˜å½•å¦‚è¡¨13.4[716]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Franklin, Janet. 2009. Mapping species distributions: Spatial inference and prediction (ecology, biodiversity and conservation). Cambridge University Press.",
            "zh": "å¯Œå…°å…‹æ—ï¼Œçå¦®ç‰¹ã€‚2009. ç»˜åˆ¶ç‰©ç§åˆ†å¸ƒå›¾ï¼šç©ºé—´æ¨æ–­å’Œé¢„æµ‹ï¼ˆç”Ÿæ€å­¦ã€ç”Ÿç‰©å¤šæ ·æ€§å’Œä¿æŠ¤ï¼‰ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplest approach to normalization is range normalization, which performs a linear scaling of the original values of the continuous feature into a given range.",
            "zh": "å½’ä¸€åŒ–çš„æœ€ç®€å•æ–¹æ³•æ˜¯èŒƒå›´å½’ä¸€åŒ–ï¼Œå®ƒå°†è¿ç»­ç‰¹å¾çš„åŸå§‹å€¼çº¿æ€§ç¼©æ”¾åˆ°ç»™å®šèŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "breast cancer, 109",
            "zh": "ä¹³è…ºç™Œï¼Œ109"
        }
    },
    {
        "translation": {
            "en": "11.8â€…â€…â€…Framing the action-value function as a prediction problem.",
            "zh": "11.8 å°†åŠ¨ä½œå€¼å‡½æ•°æ„å»ºä¸ºé¢„æµ‹é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In backward sequential selection, we start with a feature subset including all the possible features in a dataset (shown on the right of Figure 5.19[228]).",
            "zh": "åœ¨å‘åé¡ºåºé€‰æ‹©ä¸­ï¼Œæˆ‘ä»¬ä»åŒ…å«æ•°æ®é›†ä¸­æ‰€æœ‰å¯èƒ½ç‰¹å¾çš„ç‰¹å¾å­é›†å¼€å§‹ï¼ˆå¦‚å›¾ 5.19[228] å³ä¾§æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we initialize the network with the same initial set of weights that we used in Section 8.3.5 [421] and use the same data, training regime, and learning rate (Î± = 0.2), then the ReLU version of the network converges to an SSE < 0.0001 in just 424 epochs, as compared with the 7,656 epochs required to train the logistic network.",
            "zh": "å¦‚æœæˆ‘ä»¬ä½¿ç”¨åœ¨ç¬¬ 8.3.5 èŠ‚ [421] ä¸­ä½¿ç”¨çš„ç›¸åŒåˆå§‹æƒé‡é›†åˆå§‹åŒ–ç½‘ç»œï¼Œå¹¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®ã€è®­ç»ƒæœºåˆ¶å’Œå­¦ä¹ ç‡ ï¼ˆÎ± = 0.2ï¼‰ï¼Œé‚£ä¹ˆç½‘ç»œçš„ ReLU ç‰ˆæœ¬åªéœ€ 424 ä¸ªå‘¨æœŸå³å¯æ”¶æ•›åˆ° SSE < 0.0001ï¼Œè€Œè®­ç»ƒé€»è¾‘ç½‘ç»œéœ€è¦ 7,656 ä¸ªå‘¨æœŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The potential difficulty in learning the class conditional densities, relative to the posterior class probabilities, is exacerbated in situations where we have a lot of descriptive features because, as the dimensionality of d increases, we will need more and more data to create good estimates for P(tl|d).",
            "zh": "ç›¸å¯¹äºåéªŒç±»æ¦‚ç‡ï¼Œå­¦ä¹ ç±»æ¡ä»¶å¯†åº¦çš„æ½œåœ¨å›°éš¾åœ¨æˆ‘ä»¬æœ‰å¾ˆå¤šæè¿°æ€§ç‰¹å¾çš„æƒ…å†µä¸‹ä¼šåŠ å‰§ï¼Œå› ä¸ºéšç€ d çš„ç»´æ•°å¢åŠ ï¼Œæˆ‘ä»¬å°†éœ€è¦è¶Šæ¥è¶Šå¤šçš„æ•°æ®æ¥åˆ›å»ºå¯¹ Pï¼ˆtl|dï¼‰ çš„è‰¯å¥½ä¼°è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because we start sampling from a random state, however, we do not know whether the initial state is an appropriate state from which to start generating samples.",
            "zh": "ä½†æ˜¯ï¼Œç”±äºæˆ‘ä»¬ä»éšæœºçŠ¶æ€å¼€å§‹é‡‡æ ·ï¼Œå› æ­¤æˆ‘ä»¬ä¸çŸ¥é“åˆå§‹çŠ¶æ€æ˜¯å¦æ˜¯å¼€å§‹ç”Ÿæˆæ ·æœ¬çš„é€‚å½“çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Ï• is a set of basis functions applied to the descriptive features d, and w is a set of weights containing one weight for each member of Ï•.",
            "zh": "å…¶ä¸­ Ï† æ˜¯åº”ç”¨äºæè¿°æ€§ç‰¹å¾ D çš„ä¸€ç»„åŸºå‡½æ•°ï¼ŒW æ˜¯ä¸€ç»„æƒé‡ï¼Œå…¶ä¸­åŒ…å« Ï† çš„æ¯ä¸ªæˆå‘˜çš„ä¸€ä¸ªæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cardinality of the CREDITCARD and REGIONTYPE categorical features were higher than expected (the histograms for these features are shown in Figures 12.2(b)[695] and 12.2(c)[695]).",
            "zh": "CREDITCARDå’ŒREGIONTYPEåˆ†ç±»ç‰¹å¾çš„åŸºæ•°é«˜äºé¢„æœŸï¼ˆè¿™äº›ç‰¹å¾çš„ç›´æ–¹å›¾å¦‚å›¾12.2ï¼ˆbï¼‰[695]å’Œ12.2ï¼ˆcï¼‰[695]æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "inter-quartile range, 70, 749, 755",
            "zh": "å››åˆ†ä½è·ï¼Œ 70ï¼Œ 749ï¼Œ 755"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7",
            "zh": "å›¾ 7.7"
        }
    },
    {
        "translation": {
            "en": "A dataset of customers of a large national retail chain.",
            "zh": "ä¸€å®¶å¤§å‹å…¨å›½æ€§é›¶å”®è¿é”åº—çš„å®¢æˆ·æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.3â€…â€…â€…The vegetation classification dataset.",
            "zh": "4.3 æ¤è¢«åˆ†ç±»æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for a hidden neuron k, ak only indirectly affects â„°, via the effect it has on the activations of downstream neurons that the ak is directly propagated to (and the chain reaction that these subsequent activations have on still later neuron activations).",
            "zh": "ç„¶è€Œï¼Œå¯¹äºä¸€ä¸ªéšè—çš„ç¥ç»å…ƒkï¼Œakåªæ˜¯é—´æ¥å½±å“Eï¼Œé€šè¿‡å®ƒå¯¹akç›´æ¥ä¼ æ’­åˆ°çš„ä¸‹æ¸¸ç¥ç»å…ƒçš„æ¿€æ´»çš„å½±å“ï¼ˆä»¥åŠè¿™äº›åç»­æ¿€æ´»å¯¹åæ¥çš„ç¥ç»å…ƒæ¿€æ´»çš„è¿é”ååº”ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chang, Winston. 2012. R graphics cookbook: Practical recipes for visualizing data. Oâ€™Reilly Media.",
            "zh": "å¼ ï¼Œæ¸©æ–¯é¡¿ã€‚2012. R å›¾å½¢è¯´æ˜ä¹¦ï¼šå¯è§†åŒ–æ•°æ®çš„å®ç”¨æ–¹æ³•ã€‚O'Reilly åª’ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first two of these probabilities are easy to calculate.",
            "zh": "è¿™äº›æ¦‚ç‡ä¸­çš„å‰ä¸¤ä¸ªå¾ˆå®¹æ˜“è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "We also took our first steps toward building predictive models in this chapter when we looked at correlation. A descriptive feature that correlates strongly with a target feature would be a good place to start building a predictive model, and we return to correlations in later chapters. Examining correlation between features as part of data exploration allows us to add extra outcomes to the list at the beginning of this section:",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œå½“æˆ‘ä»¬ç ”ç©¶ç›¸å…³æ€§æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿè¿ˆå‡ºäº†æ„å»ºé¢„æµ‹æ¨¡å‹çš„ç¬¬ä¸€æ­¥ã€‚ä¸ç›®æ ‡ç‰¹å¾å¯†åˆ‡ç›¸å…³çš„æè¿°æ€§ç‰¹å¾å°†æ˜¯å¼€å§‹æ„å»ºé¢„æµ‹æ¨¡å‹çš„å¥½åœ°æ–¹ï¼Œæˆ‘ä»¬å°†åœ¨åé¢çš„ç« èŠ‚ä¸­è¿”å›ç›¸å…³æ€§ã€‚ä½œä¸ºæ•°æ®æ¢ç´¢çš„ä¸€éƒ¨åˆ†ï¼Œæ£€æŸ¥è¦ç´ ä¹‹é—´çš„ç›¸å…³æ€§å…è®¸æˆ‘ä»¬å°†é¢å¤–çš„ç»“æœæ·»åŠ åˆ°æœ¬èŠ‚å¼€å¤´çš„åˆ—è¡¨ä¸­ï¼š"
        }
    },
    {
        "translation": {
            "en": "9.9â€…â€…â€…Prediction score distributions for two different prediction models. The distributions in (a) are much better separated than those in (b).",
            "zh": "9.9 ä¸¤ç§ä¸åŒé¢„æµ‹æ¨¡å‹çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒã€‚ï¼ˆaï¼‰ä¸­çš„åˆ†å¸ƒæ¯”ï¼ˆbï¼‰ä¸­çš„åˆ†å¸ƒåˆ†ç¦»å¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "23. The K2 score is named after the K2 algorithm, one of the earliest and best-known algorithms for learning Bayesian networks (Cooper and Herskovits, 1992).",
            "zh": "23. K2 åˆ†æ•°ä»¥ K2 ç®—æ³•å‘½åï¼ŒK2 ç®—æ³•æ˜¯å­¦ä¹ è´å¶æ–¯ç½‘ç»œæœ€æ—©å’Œæœ€è‘—åçš„ç®—æ³•ä¹‹ä¸€ï¼ˆCooper å’Œ Herskovitsï¼Œ1992 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A schematic of the internal structure of a long short-term memory unit.",
            "zh": "é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„å†…éƒ¨ç»“æ„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to formally measure the fit of a linear regression model with a set of training data, we require an error function.",
            "zh": "ä¸ºäº†æ­£å¼æµ‹é‡çº¿æ€§å›å½’æ¨¡å‹ä¸ä¸€ç»„è®­ç»ƒæ•°æ®çš„æ‹Ÿåˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¯¯å·®å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the sum of squared errors function is changed slightly to",
            "zh": "è¿™æ„å‘³ç€å¹³æ–¹è¯¯å·®å’Œå‡½æ•°ç•¥å¾®æ›´æ”¹ä¸º"
        }
    },
    {
        "translation": {
            "en": "5.4â€…â€…â€…The extended version of the college athletes dataset.",
            "zh": "5.4 å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.7",
            "zh": "è¡¨ 5.7"
        }
    },
    {
        "translation": {
            "en": "prediction score, 556, 574",
            "zh": "é¢„æµ‹å¾—åˆ†ï¼Œ556,574"
        }
    },
    {
        "translation": {
            "en": "We then use the updated Î´s to backpropagate the error gradients to the preceding layer and also for the weight update calculations.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´æ–°çš„ Î´ å°†è¯¯å·®æ¢¯åº¦åå‘ä¼ æ’­åˆ°å‰ä¸€å±‚ï¼Œå¹¶ç”¨äºæƒé‡æ›´æ–°è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.37[502] illustrates the architecture of a simple recurrent network.",
            "zh": "å›¾ 8.37[502] è¯´æ˜äº†ç®€å•å¾ªç¯ç½‘ç»œçš„æ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Most people will remain in the SUSCEPTIBLE state indefinitely, P(S S) = 0.98, but with a small probability, P(S I) = 0.02, can transition to the INFECTED state.",
            "zh": "å¤§å¤šæ•°äººå°†æ— é™æœŸåœ°ä¿æŒæ˜“æ„ŸçŠ¶æ€ï¼ŒPï¼ˆS Sï¼‰ = 0.98ï¼Œä½†æ¦‚ç‡å¾ˆå°ï¼ŒPï¼ˆS Iï¼‰ = 0.02ï¼Œå¯ä»¥è¿‡æ¸¡åˆ°æ„ŸæŸ“çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, even when the gradients are defined, very large gradients are a problem.",
            "zh": "ä½†æ˜¯ï¼Œå³ä½¿å®šä¹‰äº†æ¢¯åº¦ï¼Œéå¸¸å¤§çš„æ¢¯åº¦ä¹Ÿæ˜¯ä¸€ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a dataset may record whether or not someone liked a movie, a customer bought a product, or someone visited a particular webpage.",
            "zh": "ä¾‹å¦‚ï¼Œæ•°æ®é›†å¯ä»¥è®°å½•æ˜¯å¦æœ‰äººå–œæ¬¢ç”µå½±ã€å®¢æˆ·æ˜¯å¦è´­ä¹°äº†äº§å“æˆ–æ˜¯å¦æœ‰äººè®¿é—®äº†ç‰¹å®šç½‘é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "The for loop on Lines 12[420] to 14[420] is where the variables used to store these totals are initialized.",
            "zh": "ç¬¬ 12[420] è¡Œåˆ° 14[420] ä¸Šçš„ for å¾ªç¯æ˜¯ç”¨äºå­˜å‚¨è¿™äº›æ€»æ•°çš„å˜é‡åˆå§‹åŒ–çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is also possible, however, for this function to be more elaborate when the observations over multiple time-steps are accumulated into a state.1 Using states instead of observations, Equation (11.1)[639] can be restated2",
            "zh": "ç„¶è€Œï¼Œå½“å¤šä¸ªæ—¶é—´æ­¥é•¿ä¸Šçš„è§‚æµ‹å€¼ç´¯ç§¯æˆä¸€ä¸ªçŠ¶æ€æ—¶ï¼Œè¿™ä¸ªå‡½æ•°ä¹Ÿæœ‰å¯èƒ½æ›´å¤æ‚.1ä½¿ç”¨çŠ¶æ€è€Œä¸æ˜¯è§‚æµ‹å€¼ï¼Œæ–¹ç¨‹ï¼ˆ11.1ï¼‰[639]å¯ä»¥é‡è¿°2"
        }
    },
    {
        "translation": {
            "en": "0.5015",
            "zh": "0.5015"
        }
    },
    {
        "translation": {
            "en": "clamp transformation, 70, 715",
            "zh": "é’³ä½è½¬æ¢ï¼Œ 70ï¼Œ 715"
        }
    },
    {
        "translation": {
            "en": "Confident that your study will help you, you lay a dollar down to play a game, ready to guess that the queen is in the position on the right.",
            "zh": "ä½ ç›¸ä¿¡ä½ çš„ç ”ç©¶ä¼šå¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œäºæ˜¯ä½ æ”¾ä¸‹ä¸€ç¾å…ƒæ¥ç©ä¸€ä¸ªæ¸¸æˆï¼Œå‡†å¤‡çŒœæµ‹å¥³ç‹åœ¨å³è¾¹çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.4[64] shows the structure of a data quality plan.",
            "zh": "è¡¨3.4[64]æ˜¾ç¤ºäº†æ•°æ®è´¨é‡è®¡åˆ’çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Smyth, B., and M. Keane. 1995. Remembering to forget: A competence preserving case deletion policy for case-based reasoning systems. In The fourteenth international joint conference on artificial intelligence (IJCAI-95), ed. C. Mellish, 337â€“382. ACM.",
            "zh": "å²å¯†æ–¯ï¼ŒB. å’Œ M. åŸºæ©ã€‚1995. è®°ä½å¿˜è®°ï¼šåŸºäºæ¡ˆä¾‹çš„æ¨ç†ç³»ç»Ÿçš„èƒ½åŠ›ä¿ç•™æ¡ˆä¾‹åˆ é™¤ç­–ç•¥ã€‚ç¬¬åå››å±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®ï¼ˆIJCAI-95ï¼‰ï¼ŒC. Mellishç¼–è¾‘ï¼Œ337-382ã€‚ACMã€‚"
        }
    },
    {
        "translation": {
            "en": "k-fold cross validation, 543, 611",
            "zh": "K-fold äº¤å‰éªŒè¯ï¼Œ 543ï¼Œ 611"
        }
    },
    {
        "translation": {
            "en": "Support vector machines (SVM) are another approach to predictive modeling that is based on error-based learning.",
            "zh": "æ”¯æŒå‘é‡æœº ï¼ˆSVMï¼‰ æ˜¯å¦ä¸€ç§åŸºäºåŸºäºè¯¯å·®çš„å­¦ä¹ çš„é¢„æµ‹å»ºæ¨¡æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we were to include the interval width when calculating conditional probabilities for a continuous descriptive feature in a naive Bayes prediction model, using Equation (6.16)[261], we would multiply the value returned by the PDF by the same interval width each time we calculated the likelihood score for a level of the target feature. Consequently, we can drop this multiplication and just use the value returned by the PDF as a relative measure of the likelihood that the feature takes a specific value.",
            "zh": "å¦‚æœæˆ‘ä»¬åœ¨æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹ä¸­è®¡ç®—è¿ç»­æè¿°æ€§ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡æ—¶åŒ…æ‹¬åŒºé—´å®½åº¦ï¼Œä½¿ç”¨æ–¹ç¨‹ ï¼ˆ6.16ï¼‰[261]ï¼Œæ¯æ¬¡è®¡ç®—ç›®æ ‡ç‰¹å¾æ°´å¹³çš„ä¼¼ç„¶åˆ†æ•°æ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šå°† PDF è¿”å›çš„å€¼ä¹˜ä»¥ç›¸åŒçš„åŒºé—´å®½åº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ”¾å¼ƒæ­¤ä¹˜æ³•ï¼Œè€Œä»…ä½¿ç”¨ PDF è¿”å›çš„å€¼ä½œä¸ºç‰¹å¾é‡‡ç”¨ç‰¹å®šå€¼çš„å¯èƒ½æ€§çš„ç›¸å¯¹åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, it preferences features with many levels because these features split the data into many small subsets, which tend to be pure irrespective of any correlation between the descriptive feature and the target feature.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œå®ƒä¼˜å…ˆé€‰æ‹©å…·æœ‰å¤šä¸ªçº§åˆ«çš„ç‰¹å¾ï¼Œå› ä¸ºè¿™äº›ç‰¹å¾å°†æ•°æ®æ‹†åˆ†ä¸ºè®¸å¤šå°å­é›†ï¼Œè¿™äº›å­é›†å¾€å¾€æ˜¯çº¯çš„ï¼Œè€Œä¸ç®¡æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„ä»»ä½•ç›¸å…³æ€§å¦‚ä½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we were to simply add these together, the positive and negative errors would effectively cancel each other out.",
            "zh": "å¦‚æœæˆ‘ä»¬ç®€å•åœ°å°†è¿™äº›åŠ åœ¨ä¸€èµ·ï¼Œæ­£è¯¯å·®å’Œè´Ÿè¯¯å·®å°†æœ‰æ•ˆåœ°ç›¸äº’æŠµæ¶ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Worked example illustrating the dataflow through a multilayer, multifilter CNN.",
            "zh": "å·¥ä½œç¤ºä¾‹è¯´æ˜äº†é€šè¿‡å¤šå±‚ã€å¤šæ»¤æ³¢å™¨ CNN çš„æ•°æ®æµã€‚"
        }
    },
    {
        "translation": {
            "en": "We say that features with this kind of relationship are positively covariant.",
            "zh": "æˆ‘ä»¬è¯´å…·æœ‰è¿™ç§å…³ç³»çš„ç‰¹å¾æ˜¯æ­£åå˜çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we originally tried to calculate probabilities for this query, a problem arose from the requirement that we have instances in the training dataset where all the evidence events hold.",
            "zh": "å½“æˆ‘ä»¬æœ€åˆå°è¯•è®¡ç®—æ­¤æŸ¥è¯¢çš„æ¦‚ç‡æ—¶ï¼Œå‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³è¦æ±‚æˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å…·æœ‰æ‰€æœ‰è¯æ®äº‹ä»¶éƒ½æˆç«‹çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then present the naive Bayes model, the standard approach to using probability-based approaches to machine learning.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†æœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œè¿™æ˜¯ä½¿ç”¨åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ æ–¹æ³•çš„æ ‡å‡†æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the updated errors, a new set of weights is calculated, marked in Table 7.8[348] as New Weights (after Iteration 2).",
            "zh": "æ ¹æ®æ›´æ–°çš„è¯¯å·®ï¼Œè®¡ç®—ä¸€ç»„æ–°çš„æƒé‡ï¼Œåœ¨è¡¨7.8[348]ä¸­æ ‡è®°ä¸ºæ–°æƒé‡ï¼ˆè¿­ä»£2ä¹‹åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are three target levels, so three one-versus-all models are built.",
            "zh": "æœ‰ä¸‰ä¸ªç›®æ ‡çº§åˆ«ï¼Œå› æ­¤æ„å»ºäº†ä¸‰ä¸ªä¸€å¯¹ä¸€çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Maria noticed that her baby could occupy one of three statesâ€”HAPPY, CRYING, or SLEEPINGâ€”and moved quite freely between them.",
            "zh": "ç›ä¸½äºšæ³¨æ„åˆ°å¥¹çš„å­©å­å¯ä»¥å æ®ä¸‰ç§çŠ¶æ€ä¹‹ä¸€â€”â€”å¿«ä¹ã€å“­æ³£æˆ–ç¡è§‰â€”â€”å¹¶åœ¨å®ƒä»¬ä¹‹é—´è‡ªç”±ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of the P20 and P45 features from the EEG dataset. Instances representing positive images are shown as crosses, and those representing negative images as triangles.",
            "zh": "EEG æ•°æ®é›†ä¸­ P20 å’Œ P45 ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚è¡¨ç¤ºæ­£å›¾åƒçš„å®ä¾‹æ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œè¡¨ç¤ºè´Ÿå›¾åƒçš„å®ä¾‹æ˜¾ç¤ºä¸ºä¸‰è§’å½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the college athlete dataset are both continuous, which means that the feature space representing this data is technically known as a Euclidean coordinate space, and we can compute the distance between instances in it using Euclidean distance. For example, the Euclidean distance between instances d12 (SPEED = 5.00, AGILITY = 2.50) and d5 (SPEED = 2.75, AGILITY = 7.50) from Table 5.2[183] is",
            "zh": "å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾éƒ½æ˜¯è¿ç»­çš„ï¼Œè¿™æ„å‘³ç€è¡¨ç¤ºæ­¤æ•°æ®çš„ç‰¹å¾ç©ºé—´åœ¨æŠ€æœ¯ä¸Šç§°ä¸ºæ¬§å‡ é‡Œå¾—åæ ‡ç©ºé—´ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»è®¡ç®—å…¶ä¸­å®ä¾‹ä¹‹é—´çš„è·ç¦»ã€‚ä¾‹å¦‚ï¼Œè¡¨ 5.2[183] ä¸­çš„å®ä¾‹ d12 ï¼ˆSPEED = 5.00ï¼Œ AGILITY = 2.50ï¼‰ å’Œ d5 ï¼ˆSPEED = 2.75ï¼Œ AGILITY = 7.50ï¼‰ ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»ä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 12.7",
            "zh": "å›¾ 12.7"
        }
    },
    {
        "translation": {
            "en": "The next section describes how we can train networks with multiple layers of neurons using the backpropagation algorithm and explains how the vanishing gradient problem can negatively affect the training of deep networks.",
            "zh": "ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•è®­ç»ƒå…·æœ‰å¤šå±‚ç¥ç»å…ƒçš„ç½‘ç»œï¼Œå¹¶è§£é‡Šæ¶ˆå¤±æ¢¯åº¦é—®é¢˜å¦‚ä½•å¯¹æ·±åº¦ç½‘ç»œçš„è®­ç»ƒäº§ç”Ÿè´Ÿé¢å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use exactly this idea to define a loss function that can be used to train a neural network",
            "zh": "æˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæƒ³æ³•æ¥å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41[514] presents a worked example of the forward propagation of activations through an LSTM unit.",
            "zh": "å›¾ 8.41[514] å±•ç¤ºäº†é€šè¿‡ LSTM å•å…ƒå‰å‘ä¼ æ’­æ¿€æ´»çš„å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unsupervised learning is a huge topic in its own right, and so the goal of this chapter is to give a flavor of the most important approaches involved.",
            "zh": "æ— ç›‘ç£å­¦ä¹ æœ¬èº«å°±æ˜¯ä¸€ä¸ªå·¨å¤§çš„è¯é¢˜ï¼Œå› æ­¤æœ¬ç« çš„ç›®æ ‡æ˜¯ä»‹ç»æ‰€æ¶‰åŠçš„æœ€é‡è¦çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "where E is the expectation. This value function returns the expected cumulative reward that an agent will earn if it follows policy Ï€ starting from state st.",
            "zh": "å…¶ä¸­ E æ˜¯æœŸæœ›å€¼ã€‚æ­¤å€¼å‡½æ•°è¿”å›ä»£ç†åœ¨éµå¾ªä»çŠ¶æ€ st å¼€å§‹çš„ç­–ç•¥Ï€æ—¶å°†è·å¾—çš„é¢„æœŸç´¯ç§¯å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Business Understanding and Data Understanding are tightly coupled, and projects typically spend some time moving back and forth between these phases.",
            "zh": "ä¾‹å¦‚ï¼Œä¸šåŠ¡ç†è§£å’Œæ•°æ®ç†è§£æ˜¯ç´§å¯†è€¦åˆçš„ï¼Œé¡¹ç›®é€šå¸¸ä¼šèŠ±è´¹ä¸€äº›æ—¶é—´åœ¨è¿™äº›é˜¶æ®µä¹‹é—´æ¥å›ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2â€…â€…â€…A dataset from a loan application fraud detection domain.",
            "zh": "6.2 æ¥è‡ªè´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹åŸŸçš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "As shown in Figure 3.2(e)[60], exponential distributions have a long tail, and so very high values are not uncommon.",
            "zh": "å¦‚å›¾3.2ï¼ˆeï¼‰[60]æ‰€ç¤ºï¼ŒæŒ‡æ•°åˆ†å¸ƒå…·æœ‰é•¿å°¾ï¼Œå› æ­¤éå¸¸é«˜çš„å€¼å¹¶ä¸å°‘è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cumulative gain for each decile of the email classification dataset is shown in Table 9.16[568].",
            "zh": "ç”µå­é‚®ä»¶åˆ†ç±»æ•°æ®é›†æ¯ä¸ªååˆ†ä½æ•°çš„ç´¯ç§¯å¢ç›Šå¦‚è¡¨9.16æ‰€ç¤º[568]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, if we examine the partitioning of the dataset based on the CONTAINS IMAGES feature, shown in Figure 4.7(c)[128], it looks like this feature is not very discriminatory for spam and ham at all.",
            "zh": "æœ€åï¼Œå¦‚æœæˆ‘ä»¬æ ¹æ®å›¾ 4.7ï¼ˆcï¼‰[128] æ‰€ç¤ºçš„ CONTAINS IMAGES ç‰¹å¾æ£€æŸ¥æ•°æ®é›†çš„åˆ†åŒºï¼Œçœ‹èµ·æ¥è¿™ä¸ªåŠŸèƒ½å¯¹åƒåœ¾é‚®ä»¶å’Œç«è…¿çš„æ­§è§†æ€§å¹¶ä¸å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The Voronoi tessellation of the feature space for the dataset in Table 5.2[183], with the position of the query represented by the ? marker; and (b) the decision boundary created by aggregating the neighboring Voronoi regions that belong to the same target level.",
            "zh": "ï¼ˆaï¼‰ è¡¨5.2[183]ä¸­æ•°æ®é›†ç‰¹å¾ç©ºé—´çš„Voronoiç»†åˆ†ï¼ŒæŸ¥è¯¢çš„ä½ç½®ç”±ï¼Ÿæ ‡è®°;ï¼ˆbï¼‰é€šè¿‡æ±‡æ€»å±äºåŒä¸€ç›®æ ‡çº§åˆ«çš„é‚»è¿‘Voronoiåœ°åŒºè€Œåˆ›å»ºçš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 12.3(a)[697] shows a slightly higher propensity of people in rural areas to churn.",
            "zh": "ä¾‹å¦‚ï¼Œå›¾12.3ï¼ˆaï¼‰[697]æ˜¾ç¤ºå†œæ‘åœ°åŒºäººä»¬çš„æµå¤±å€¾å‘ç•¥é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. As Figure 8.13[410] illustrates, logistic(0) = 0.5",
            "zh": "8. å¦‚å›¾ 8.13[410] æ‰€ç¤ºï¼Œlogisticï¼ˆ0ï¼‰ = 0.5"
        }
    },
    {
        "translation": {
            "en": "spending time cleaning the data;",
            "zh": "èŠ±æ—¶é—´æ¸…ç†æ•°æ®;"
        }
    },
    {
        "translation": {
            "en": "As we will see, a fundamental component of creating probabilistic prediction models is deciding on the conditional independence assumptions we wish to make and the resulting factorization of the domain.",
            "zh": "æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œåˆ›å»ºæ¦‚ç‡é¢„æµ‹æ¨¡å‹çš„ä¸€ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†æ˜¯å†³å®šæˆ‘ä»¬å¸Œæœ›åšå‡ºçš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ä»¥åŠç”±æ­¤äº§ç”Ÿçš„åŸŸå› å¼åˆ†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn extracted two key measurements by comparing these manual classifications to the classifications made by the model she had built.",
            "zh": "Jocelyn é€šè¿‡å°†è¿™äº›æ‰‹åŠ¨åˆ†ç±»ä¸å¥¹æ„å»ºçš„æ¨¡å‹æ‰€åšçš„åˆ†ç±»è¿›è¡Œæ¯”è¾ƒï¼Œæå–äº†ä¸¤ä¸ªå…³é”®æµ‹é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. There are several different ways to explain the k-means clustering algorithm. For example, as k-means is actually a special case of the expectation maximization algorithm (Moon, 1996), it is often described in a probabilisitic context more similar to typical descriptions of that algorithm. To align with Chapter 5[181] we present a similarity-based description of the algorithm.",
            "zh": "1. æœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥è§£é‡Š k-means èšç±»ç®—æ³•ã€‚ä¾‹å¦‚ï¼Œç”±äº k-means å®é™…ä¸Šæ˜¯æœŸæœ›æœ€å¤§åŒ–ç®—æ³•çš„ä¸€ä¸ªç‰¹ä¾‹ ï¼ˆMoonï¼Œ 1996ï¼‰ï¼Œå› æ­¤å®ƒé€šå¸¸åœ¨æ›´ç±»ä¼¼äºè¯¥ç®—æ³•çš„å…¸å‹æè¿°çš„æ¦‚ç‡ä¸Šä¸‹æ–‡ä¸­æè¿°ã€‚ä¸ºäº†ä¸ç¬¬5ç« [181]ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºç›¸ä¼¼æ€§çš„ç®—æ³•æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "where x is a numeric value and e is Eulerâ€™s number and is approximately equal to 2.7183.",
            "zh": "å…¶ä¸­ x æ˜¯æ•°å€¼ï¼Œe æ˜¯æ¬§æ‹‰æ•°ï¼Œå¤§çº¦ç­‰äº 2.7183ã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting K-S statistics are 0.940, 0.631, 0.432, and 0.164. These results show that Model 1 is doing a much better job of separating the two target levels than the other models. We can see this in the score histograms and the K-S charts, but it is also nicely captured in the K-S statistics.",
            "zh": "ç”Ÿæˆçš„ K-S ç»Ÿè®¡é‡ä¸º 0.940ã€0.631ã€0.432 å’Œ 0.164ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹ 1 åœ¨åˆ†ç¦»ä¸¤ä¸ªç›®æ ‡æ°´å¹³æ–¹é¢æ¯”å…¶ä»–æ¨¡å‹åšå¾—æ›´å¥½ã€‚æˆ‘ä»¬å¯ä»¥åœ¨åˆ†æ•°ç›´æ–¹å›¾å’Œ K-S å›¾è¡¨ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œä½†åœ¨ K-S ç»Ÿè®¡æ•°æ®ä¸­ä¹Ÿå¾ˆå¥½åœ°æ•æ‰åˆ°äº†è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.1â€…â€…â€…(a) The class conditional densities for two classes (l1,l2) with a single descriptive feature d. (b) The class posterior probabilities plotted for each class for different values of d.",
            "zh": "14.1 ï¼ˆaï¼‰ å…·æœ‰å•ä¸ªæè¿°æ€§ç‰¹å¾ d çš„ä¸¤ä¸ªç±» ï¼ˆl1ï¼Œl2ï¼‰ çš„ç±»æ¡ä»¶å¯†åº¦ã€‚ ï¼ˆbï¼‰ é’ˆå¯¹ä¸åŒçš„ d å€¼ä¸ºæ¯ä¸ªç±»ç»˜åˆ¶çš„ç±»åéªŒæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "convergence, 323",
            "zh": "æ”¶æ•›ï¼Œ323"
        }
    },
    {
        "translation": {
            "en": "Figure 10.8",
            "zh": "å›¾ 10.8"
        }
    },
    {
        "translation": {
            "en": "It is known as a one-hot representation because at most one element in the vector will have the value 1 and all the other elements will be 0, with the value of the feature indicated by whichever element is 1.",
            "zh": "å®ƒè¢«ç§°ä¸ºå•çƒ­è¡¨ç¤ºï¼Œå› ä¸ºå‘é‡ä¸­æœ€å¤šæœ‰ä¸€ä¸ªå…ƒç´ çš„å€¼ä¸º 1ï¼Œè€Œæ‰€æœ‰å…¶ä»–å…ƒç´ çš„å€¼ä¸º 0ï¼Œç‰¹å¾çš„å€¼ç”±å“ªä¸ªå…ƒç´ è¡¨ç¤ºä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some socioeconomic data for a set of countries, and a version of the data after equal-frequency binning has been applied.",
            "zh": "ä¸€ç»„å›½å®¶/åœ°åŒºçš„ä¸€äº›ç¤¾ä¼šç»æµæ•°æ®ï¼Œä»¥åŠåº”ç”¨ç­‰é¢‘åˆå¹¶åçš„æ•°æ®ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Std. Dev.",
            "zh": "æ ‡å‡†å¼€å‘"
        }
    },
    {
        "translation": {
            "en": "During data exploration we donâ€™t need to go any further than simply recognizing that features seem to follow particular distributions, and this can be done from examining the histogram for each feature.",
            "zh": "åœ¨æ•°æ®æ¢ç´¢è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦ç®€å•åœ°è¯†åˆ«ç‰¹å¾ä¼¼ä¹éµå¾ªç‰¹å®šçš„åˆ†å¸ƒï¼Œè¿™å¯ä»¥é€šè¿‡æ£€æŸ¥æ¯ä¸ªç‰¹å¾çš„ç›´æ–¹å›¾æ¥å®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability Distributions",
            "zh": "æ¦‚ç‡åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the boundaries shown in Figure 7.20[358] were trained in isolation, whereas the boundaries shown in Figure 7.21[360] were trained in parallel and so are interconnected.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯å›¾7.20[358]ä¸­æ‰€ç¤ºçš„è¾¹ç•Œæ˜¯å­¤ç«‹è®­ç»ƒçš„ï¼Œè€Œå›¾7.21[360]ä¸­æ˜¾ç¤ºçš„è¾¹ç•Œæ˜¯å¹¶è¡Œè®­ç»ƒçš„ï¼Œå› æ­¤æ˜¯ç›¸äº’è¿æ¥çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.39â€…â€…â€…An illustration of the different iterations of backpropagation during backpropagation through time.",
            "zh": "8.39 åå‘ä¼ æ’­è¿‡ç¨‹ä¸­åå‘ä¼ æ’­çš„ä¸åŒè¿­ä»£çš„ä¾‹è¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This avoids disappointment and difficulties at later stages in a project.",
            "zh": "è¿™æ ·å¯ä»¥é¿å…é¡¹ç›®åæœŸçš„å¤±æœ›å’Œå›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "One reason why this makes sense is that many activation functions have a small output range (e.g., the output of the logistic function has the range [0,1]) and it is appropriate that the range of the target feature matches the output range of the activation function.",
            "zh": "è¿™æœ‰æ„ä¹‰çš„ä¸€ä¸ªåŸå› æ˜¯è®¸å¤šæ¿€æ´»å‡½æ•°çš„è¾“å‡ºèŒƒå›´å¾ˆå°ï¼ˆä¾‹å¦‚ï¼Œé€»è¾‘å‡½æ•°çš„è¾“å‡ºèŒƒå›´ä¸º [0,1]ï¼‰ï¼Œå¹¶ä¸”ç›®æ ‡ç‰¹å¾çš„èŒƒå›´ä¸æ¿€æ´»å‡½æ•°çš„è¾“å‡ºèŒƒå›´åŒ¹é…æ˜¯åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, HANDSETPRICE can take only a small number of valuesâ€”e.g., 59.99, 129.99, 499.99, and so on.",
            "zh": "ä¾‹å¦‚ï¼ŒHANDSETPRICE åªèƒ½é‡‡ç”¨å°‘é‡å€¼ï¼Œä¾‹å¦‚ 59.99ã€129.99ã€499.99 ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this test fails, the algorithm ascends the tree to the parent of the current node and prunes the subtree containing the region on the other side of the hyperplane without testing the instances in that region (Line 11).",
            "zh": "å¦‚æœæ­¤æµ‹è¯•å¤±è´¥ï¼Œåˆ™ç®—æ³•ä¼šå°†æ ‘æå‡åˆ°å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼Œå¹¶ä¿®å‰ªåŒ…å«è¶…å¹³é¢å¦ä¸€ä¾§åŒºåŸŸçš„å­æ ‘ï¼Œè€Œä¸æµ‹è¯•è¯¥åŒºåŸŸä¸­çš„å®ä¾‹ï¼ˆç¬¬ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "external criteria, 611",
            "zh": "å¤–éƒ¨æ ‡å‡†ï¼Œ611"
        }
    },
    {
        "translation": {
            "en": "2.5â€ƒSummary",
            "zh": "2.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Figure 11.1",
            "zh": "å›¾ 11.1"
        }
    },
    {
        "translation": {
            "en": "collection limitation principle, 41",
            "zh": "æ”¶é›†é™åˆ¶åŸåˆ™ï¼Œ41"
        }
    },
    {
        "translation": {
            "en": "The dimensions of the weight matrices are determined by the size of the hidden state.",
            "zh": "æƒé‡çŸ©é˜µçš„ç»´åº¦ç”±éšè—çŠ¶æ€çš„å¤§å°å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "differentiation, 370, 765",
            "zh": "å¾®åˆ†ï¼Œ 370ï¼Œ 765"
        }
    },
    {
        "translation": {
            "en": "exponential distribution, 60, 72, 270, 274",
            "zh": "æŒ‡æ•°åˆ†å¸ƒï¼Œ60ã€72ã€270ã€274"
        }
    },
    {
        "translation": {
            "en": "target policy, 657, 664, 680",
            "zh": "ç›®æ ‡ç­–ç•¥ï¼Œ657ã€664ã€680"
        }
    },
    {
        "translation": {
            "en": "Therefore, the profit arising from correctly predicting the good level for a potential borrower is $140.",
            "zh": "å› æ­¤ï¼Œæ­£ç¡®é¢„æµ‹æ½œåœ¨å€Ÿæ¬¾äººçš„è‰¯å¥½æ°´å¹³æ‰€äº§ç”Ÿçš„åˆ©æ¶¦ä¸º 140 ç¾å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(i) A plot of the blobs, circles, and half-moons datasets and the clusterings achieved by the k-means clustering and agglomerative hierarchical clustering algorithms (where k is set to 3, 2, and 2, respectively).",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆiï¼‰ æ–‘ç‚¹ã€åœ†åœˆå’ŒåŠæœˆå½¢æ•°æ®é›†çš„å›¾ï¼Œä»¥åŠé€šè¿‡ k å‡å€¼èšç±»å’Œé›†èšåˆ†å±‚èšç±»ç®—æ³•å®ç°çš„èšç±»ï¼ˆå…¶ä¸­ k åˆ†åˆ«è®¾ç½®ä¸º 3ã€2 å’Œ 2ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The neurons in this network use a simple threshold activation function, but the intuition holds for logistic functions and the rectifier function because these functions also divide the input space of a neuron into two half-spaces: one in which the neuron activates and one in which it doesnâ€™t activate.",
            "zh": "è¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨ç®€å•çš„é˜ˆå€¼æ¿€æ´»å‡½æ•°ï¼Œä½†ç›´è§‰é€‚ç”¨äºé€»è¾‘å‡½æ•°å’Œæ•´æµå™¨å‡½æ•°ï¼Œå› ä¸ºè¿™äº›å‡½æ•°è¿˜å°†ç¥ç»å…ƒçš„è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸ºä¸¤ä¸ªåŠç©ºé—´ï¼šä¸€ä¸ªç¥ç»å…ƒæ¿€æ´»ï¼Œå¦ä¸€ä¸ªä¸æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adding 4 possible actions (left, right, up, and none) to this would give an action-value table with 67,228 entries.",
            "zh": "å°† 4 ä¸ªå¯èƒ½çš„æ“ä½œï¼ˆå·¦ã€å³ã€å‘ä¸Šå’Œæ— ï¼‰æ·»åŠ åˆ°å…¶ä¸­å°†å¾—åˆ°ä¸€ä¸ªåŒ…å« 67,228 ä¸ªæ¡ç›®çš„æ“ä½œå€¼è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a business context where people are using models to inform decision making, being able to understand how the model works gives people more confidence in the model and, hence, in the insight that it provides.",
            "zh": "åœ¨äººä»¬ä½¿ç”¨æ¨¡å‹ä¸ºå†³ç­–æä¾›ä¿¡æ¯çš„å•†ä¸šç¯å¢ƒä¸­ï¼Œèƒ½å¤Ÿç†è§£æ¨¡å‹çš„å·¥ä½œåŸç†ä¼šè®©äººä»¬å¯¹æ¨¡å‹æ›´æœ‰ä¿¡å¿ƒï¼Œä»è€Œå¯¹å®ƒæä¾›çš„æ´å¯ŸåŠ›æ›´æœ‰ä¿¡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Although it is less important for simple linear regression models, for logistic regression models we recommend that descriptive feature values always be normalized.",
            "zh": "å°½ç®¡å¯¹äºç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹æ¥è¯´ï¼Œå®ƒä¸å¤ªé‡è¦ï¼Œä½†å¯¹äºé€»è¾‘å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å»ºè®®å§‹ç»ˆå¯¹æè¿°æ€§ç‰¹å¾å€¼è¿›è¡Œå½’ä¸€åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.2.1â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "2.2.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "weighted sum, 524",
            "zh": "åŠ æƒæ€»å’Œï¼Œ524"
        }
    },
    {
        "translation": {
            "en": "This has led to the field receiving significant attention from the media (both positive and negative) and a greater interest than ever before from people who want to become machine learning practitioners.",
            "zh": "è¿™å¯¼è‡´è¯¥é¢†åŸŸå—åˆ°åª’ä½“çš„æå¤§å…³æ³¨ï¼ˆæ— è®ºæ˜¯æ­£é¢çš„è¿˜æ˜¯è´Ÿé¢çš„ï¼‰ï¼Œä»¥åŠæƒ³è¦æˆä¸ºæœºå™¨å­¦ä¹ ä»ä¸šè€…çš„äººä»¬æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´æ„Ÿå…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, for the vegetation dataset, the decision tree that will be generated using information gain based on the Gini index will be identical to the one generated using information gain based on entropy (see Figure 4.11[141]).",
            "zh": "äº‹å®ä¸Šï¼Œå¯¹äºæ¤è¢«æ•°æ®é›†ï¼Œä½¿ç”¨åŸºäºåŸºå°¼æŒ‡æ•°çš„ä¿¡æ¯å¢ç›Šç”Ÿæˆçš„å†³ç­–æ ‘å°†ä¸ä½¿ç”¨åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šç”Ÿæˆçš„å†³ç­–æ ‘ç›¸åŒï¼ˆè§å›¾4.11[141]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(d) Initial centroids chosen using the k-means++ approach (all with k = 3) for the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ ä½¿ç”¨k-means++æ–¹æ³•ï¼ˆå‡ä¸ºk = 3ï¼‰ä¸ºè¡¨10.1[604]ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†é€‰æ‹©çš„åˆå§‹è´¨å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This reflects the fact that a support vector machine uses the support vectors to define the separating hyperplane and hence to make the actual model predictions.",
            "zh": "è¿™åæ˜ äº†è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³æ”¯æŒå‘é‡æœºä½¿ç”¨æ”¯æŒå‘é‡æ¥å®šä¹‰åˆ†ç¦»çš„è¶…å¹³é¢ï¼Œä»è€Œè¿›è¡Œå®é™…çš„æ¨¡å‹é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The gray column in the matrix Z(1) contains the weighted sums for the neurons 3, 4, and 5 for this input vector; e.g., for Neuron 3 the weighted sum for d2 is z3 = âˆ’0.0042.",
            "zh": "çŸ©é˜µ Zï¼ˆ1ï¼‰ ä¸­çš„ç°è‰²åˆ—åŒ…å«è¯¥è¾“å…¥å‘é‡çš„ç¥ç»å…ƒ 3ã€4 å’Œ 5 çš„åŠ æƒå’Œ;ä¾‹å¦‚ï¼Œå¯¹äºç¥ç»å…ƒ 3ï¼Œd2 çš„åŠ æƒå’Œæ˜¯ z3 = âˆ’0.0042ã€‚"
        }
    },
    {
        "translation": {
            "en": "where var(t, d=l) is the variance of the target feature in the partition of the dataset containing the instances where d = l, |d=l| is the size of this partition and || is the size of the dataset.",
            "zh": "å…¶ä¸­ varï¼ˆtï¼Œ d=lï¼‰ æ˜¯æ•°æ®é›†åˆ†åŒºä¸­ç›®æ ‡ç‰¹å¾çš„æ–¹å·®ï¼Œå…¶ä¸­åŒ…å« d = lï¼Œ |d=l|æ˜¯æ­¤åˆ†åŒºçš„å¤§å°ï¼Œ||æ˜¯æ•°æ®é›†çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A data quality report for the motor insurance claims fraud detection ABT displayed in Table 3.2[56].",
            "zh": "è¡¨3.2[56]ä¸­æ˜¾ç¤ºçš„æ±½è½¦ä¿é™©ç†èµ”æ¬ºè¯ˆæ£€æµ‹ABTçš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Error-based models would be preferred if the target feature is also continuous.",
            "zh": "å¦‚æœç›®æ ‡ç‰¹å¾ä¹Ÿæ˜¯è¿ç»­çš„ï¼Œåˆ™é¦–é€‰åŸºäºé”™è¯¯çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The debate regarding the advantages and disadvantages of generative and discriminative models can be extended beyond model accuracy to include their ability to handle missing data, unlabeled data, and feature preprocessing, among other topics.",
            "zh": "å…³äºç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹çš„ä¼˜ç¼ºç‚¹çš„äº‰è®ºå¯ä»¥æ‰©å±•åˆ°æ¨¡å‹å‡†ç¡®æ€§ä¹‹å¤–ï¼ŒåŒ…æ‹¬å®ƒä»¬å¤„ç†ç¼ºå¤±æ•°æ®ã€æœªæ ‡è®°æ•°æ®å’Œç‰¹å¾é¢„å¤„ç†çš„èƒ½åŠ›ç­‰ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "What we have presented here is a very short introduction to some of the most basic operations.",
            "zh": "æˆ‘ä»¬åœ¨è¿™é‡Œä»‹ç»çš„æ˜¯å¯¹ä¸€äº›æœ€åŸºæœ¬æ“ä½œçš„éå¸¸ç®€çŸ­çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "So by giving all the instances in the dataset a weighted vote, we have at least reduced the impact of the noisy instance.",
            "zh": "å› æ­¤ï¼Œé€šè¿‡å¯¹æ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹è¿›è¡ŒåŠ æƒæŠ•ç¥¨ï¼Œæˆ‘ä»¬è‡³å°‘å‡å°‘äº†å˜ˆæ‚å®ä¾‹çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some domains co-absence is important. For example, in a medical domain when judging the similarity between two patients, it may be as important to capture the fact that neither patient had a particular symptom as it is to capture the symptoms that the patients have in common. The Sokal-Michener similarity index takes this into account and is defined as the ratio between the total number of co-presences and co-absences and the total number of binary features considered:",
            "zh": "åœ¨æŸäº›é¢†åŸŸï¼Œå…±åŒç¼ºå¸­å¾ˆé‡è¦ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦é¢†åŸŸï¼Œåœ¨åˆ¤æ–­ä¸¤åæ‚£è€…ä¹‹é—´çš„ç›¸ä¼¼æ€§æ—¶ï¼Œæ•æ‰ä¸¤ä¸ªæ‚£è€…éƒ½æ²¡æœ‰ç‰¹å®šç—‡çŠ¶çš„äº‹å®å¯èƒ½ä¸æ•æ‰æ‚£è€…å…±åŒçš„ç—‡çŠ¶ä¸€æ ·é‡è¦ã€‚Sokal-Michener ç›¸ä¼¼æ€§æŒ‡æ•°è€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ï¼Œå¹¶è¢«å®šä¹‰ä¸ºå…±å­˜å’Œå…±ç¼ºæ€»æ•°ä¸æ‰€è€ƒè™‘çš„äºŒå…ƒç‰¹å¾æ€»æ•°ä¹‹é—´çš„æ¯”ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "If there is an even number of values in the sample, then the median is obtained by calculating the arithmetic mean of the middle two values.",
            "zh": "å¦‚æœæ ·æœ¬ä¸­çš„å€¼ä¸ºå¶æ•°ï¼Œåˆ™é€šè¿‡è®¡ç®—ä¸­é—´ä¸¤ä¸ªå€¼çš„ç®—æœ¯å¹³å‡å€¼æ¥è·å¾—ä¸­ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another, less well-known, distance metric is the Manhattan distance.2 The Manhattan distance between two instances a and b in a feature space with m dimensions is defined as",
            "zh": "å¦ä¸€ä¸ªé²œä¸ºäººçŸ¥çš„è·ç¦»åº¦é‡æ˜¯æ›¼å“ˆé¡¿è·ç¦»ã€‚2 åœ¨å…·æœ‰ m ç»´çš„ç‰¹å¾ç©ºé—´ä¸­ï¼Œä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦»å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Changes in Usage: Any changes in the frequency, recency, or monetary value of a customerâ€™s or userâ€™s interactions with an organization (for example, has a cable TV subscriber changed packages in recent months?).",
            "zh": "ä½¿ç”¨æƒ…å†µçš„å˜åŒ–ï¼šå®¢æˆ·æˆ–ç”¨æˆ·ä¸ç»„ç»‡äº’åŠ¨çš„é¢‘ç‡ã€æ–°è¿‘åº¦æˆ–è´§å¸ä»·å€¼çš„ä»»ä½•å˜åŒ–ï¼ˆä¾‹å¦‚ï¼Œæœ‰çº¿ç”µè§†ç”¨æˆ·æœ€è¿‘å‡ ä¸ªæœˆæ˜¯å¦æ›´æ”¹äº†å¥—é¤ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "(e) Assuming that a greedy action selection policy is used again and that Q-learning is still being used with Î± = 0.2 and Î³ = 0.9, select the next action that the agent will perform, simulate this action, and update the entry in the action-value table for the action. (Note: If cards need to be dealt to the player or dealer, continue to use cards from the list given at the beginning of this question.)",
            "zh": "ï¼ˆeï¼‰ å‡è®¾å†æ¬¡ä½¿ç”¨è´ªå©ªæ“ä½œé€‰æ‹©ç­–ç•¥ï¼Œå¹¶ä¸” Q-learning ä»åœ¨ä½¿ç”¨ Î± = 0.2 ä¸” Î³ = 0.9ï¼Œåˆ™é€‰æ‹©ä»£ç†å°†æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªæ“ä½œï¼Œæ¨¡æ‹Ÿæ­¤æ“ä½œï¼Œå¹¶æ›´æ–°æ“ä½œå€¼è¡¨ä¸­çš„æ¡ç›®ã€‚ ï¼ˆæ³¨æ„ï¼šå¦‚æœéœ€è¦å‘ç‰Œç»™ç©å®¶æˆ–åº„å®¶ï¼Œ ç»§ç»­ä½¿ç”¨æœ¬é—®é¢˜å¼€å¤´ç»™å‡ºçš„åˆ—è¡¨ä¸­çš„å¡ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instance d1 has a target level of no, so the nearest neighbor model now predicts a target level of no for the query, meaning that the marketing department wonâ€™t include the customer in their list of direct marketing prospects.",
            "zh": "å®ä¾‹ d1 çš„ç›®æ ‡çº§åˆ«ä¸º noï¼Œå› æ­¤æœ€è¿‘é‚»æ¨¡å‹ç°åœ¨é¢„æµ‹æŸ¥è¯¢çš„ç›®æ ‡çº§åˆ«ä¸º noï¼Œè¿™æ„å‘³ç€è¥é”€éƒ¨é—¨ä¸ä¼šå°†å®¢æˆ·åŒ…å«åœ¨å…¶ç›´æ¥è¥é”€æ½œåœ¨å®¢æˆ·åˆ—è¡¨ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "For two events, X and Y, that are conditionally independent given knowledge of a third event, here Z, we can say that",
            "zh": "å¯¹äºä¸¤ä¸ªäº‹ä»¶ï¼ŒX å’Œ Yï¼Œå®ƒä»¬åœ¨ç»™å®šç¬¬ä¸‰ä¸ªäº‹ä»¶çš„çŸ¥è¯†çš„æƒ…å†µä¸‹æ˜¯æœ‰æ¡ä»¶ç‹¬ç«‹çš„ï¼Œè¿™é‡Œæ˜¯ Zï¼Œæˆ‘ä»¬å¯ä»¥è¯´"
        }
    },
    {
        "translation": {
            "en": "â€”Alfred Korzybski, Science and Sanity, p. 58",
            "zh": "â€”â€”é˜¿å°”å¼—é›·å¾·Â·ç§‘å…¹å¸ƒæ–¯åŸºï¼Œã€Šç§‘å­¦ä¸ç†æ™ºã€‹ï¼Œç¬¬58é¡µ"
        }
    },
    {
        "translation": {
            "en": "Once the forward pass is complete, we calculate an error term for each of the outputs of the network.",
            "zh": "å‰å‘ä¼ é€’å®Œæˆåï¼Œæˆ‘ä»¬è®¡ç®—ç½‘ç»œæ¯ä¸ªè¾“å‡ºçš„è¯¯å·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Outliers",
            "zh": "ï¼ˆcï¼‰ å¼‚å¸¸å€¼"
        }
    },
    {
        "translation": {
            "en": "continuous data, 34",
            "zh": "è¿ç»­æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "1,500,500",
            "zh": "1,500,500"
        }
    },
    {
        "translation": {
            "en": "summing out, 247, 761â€“763",
            "zh": "æ€»ç»“ï¼Œ247,761-763"
        }
    },
    {
        "translation": {
            "en": "A final hidden layer flattened the outputs of the previous convolutional layer and contained 512 fully connected units with rectified linear activations.",
            "zh": "æœ€åä¸€ä¸ªéšè—å±‚ä½¿å‰ä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡ºå˜å¹³ï¼Œå¹¶åŒ…å« 512 ä¸ªå…·æœ‰æ•´æµçº¿æ€§æ¿€æ´»çš„å…¨è¿æ¥å•å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.4",
            "zh": "å›¾ 9.4"
        }
    },
    {
        "translation": {
            "en": "Investigation of this claim with the business revealed that this is in fact a valid outlier and represents an unusually large claim for a very serious injury.",
            "zh": "å¯¹ä¼ä¸šæå‡ºçš„ç´¢èµ”è¿›è¡Œè°ƒæŸ¥åå‘ç°ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å¼‚å¸¸å€¼ï¼Œä»£è¡¨äº†å¯¹éå¸¸ä¸¥é‡ä¼¤å®³çš„å¼‚å¸¸å¤§é¢ç´¢èµ”ã€‚"
        }
    },
    {
        "translation": {
            "en": "30. See Section 4.2.3[127].",
            "zh": "30. å‚è§ç¬¬ 4.2.3 èŠ‚[127]ã€‚"
        }
    },
    {
        "translation": {
            "en": "In designing state representations the principle of parsimony applies: we should strive for the simplest representation that gives sufficient flexibility to model the important aspects of an environment and task.",
            "zh": "åœ¨è®¾è®¡çŠ¶æ€è¡¨ç¤ºæ—¶ï¼Œé€‚ç”¨ç®€çº¦åŸåˆ™ï¼šæˆ‘ä»¬åº”è¯¥åŠªåŠ›å®ç°æœ€ç®€å•çš„è¡¨ç¤ºï¼Œä»¥æä¾›è¶³å¤Ÿçš„çµæ´»æ€§æ¥å¯¹ç¯å¢ƒå’Œä»»åŠ¡çš„é‡è¦æ–¹é¢è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "capacity for model retraining, 739",
            "zh": "æ¨¡å‹å†è®­ç»ƒèƒ½åŠ›ï¼Œ739"
        }
    },
    {
        "translation": {
            "en": "The revenue commissioner would like to solve this problem by targeting audits at companies who are likely to be in breach of tax regulations, rather than selecting companies for audit at random.",
            "zh": "ç¨åŠ¡å±€å±€é•¿å¸Œæœ›é€šè¿‡é’ˆå¯¹å¯èƒ½è¿åç¨æ”¶æ³•è§„çš„å…¬å¸è¿›è¡Œå®¡è®¡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè€Œä¸æ˜¯éšæœºé€‰æ‹©å…¬å¸è¿›è¡Œå®¡è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.5[546] illustrates how the available data is split during the leave-one-out cross validation process.",
            "zh": "å›¾ 9.5[546] è¯´æ˜äº†åœ¨â€œç•™ä¸€â€äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­å¦‚ä½•æ‹†åˆ†å¯ç”¨æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.8",
            "zh": "è¡¨ 9.8"
        }
    },
    {
        "translation": {
            "en": "As a comparator, the filters used in these two equations are the same as those used in Equation (8.90)[486] and Equation (8.91)[486 the difference now is that the generated feature maps are larger, and indeed some of the new cells have positive values.",
            "zh": "ä½œä¸ºæ¯”è¾ƒå™¨ï¼Œè¿™ä¸¤ä¸ªæ–¹ç¨‹ä¸­ä½¿ç”¨çš„æ»¤æ³¢å™¨ä¸ç­‰å¼ï¼ˆ8.90ï¼‰[486]å’Œç­‰å¼ï¼ˆ8.91ï¼‰[486]ä¸­ä½¿ç”¨çš„æ»¤æ³¢å™¨ç›¸åŒï¼Œç°åœ¨çš„åŒºåˆ«åœ¨äºç”Ÿæˆçš„ç‰¹å¾å›¾æ›´å¤§ï¼Œå¹¶ä¸”ç¡®å®ä¸€äº›æ–°å•å…ƒæ ¼å…·æœ‰æ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although it might look like the decision boundary for the single target level shown by the solid line does not discriminate between the instances with the single target level and those with the other target levels, when used in conjunction with the other two decision boundaries, it does.",
            "zh": "å°½ç®¡çœ‹èµ·æ¥å®çº¿æ˜¾ç¤ºçš„å•ä¸ªç›®æ ‡çº§åˆ«çš„å†³ç­–è¾¹ç•Œä¸ä¼šåŒºåˆ†å…·æœ‰å•ä¸ªç›®æ ‡çº§åˆ«çš„å®ä¾‹å’Œå…·æœ‰å…¶ä»–ç›®æ ‡çº§åˆ«çš„å®ä¾‹ï¼Œä½†å½“ä¸å…¶ä»–ä¸¤ä¸ªå†³ç­–è¾¹ç•Œç»“åˆä½¿ç”¨æ—¶ï¼Œå®ƒç¡®å®ä¼šåŒºåˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The covariance and correlation matrices for the HEIGHT, WEIGHT and AGE features are",
            "zh": "HEIGHTã€WEIGHT å’Œ AGE ç‰¹å¾çš„åæ–¹å·®å’Œç›¸å…³çŸ©é˜µä¸º"
        }
    },
    {
        "translation": {
            "en": "Given a full joint probability distribution, we can compute the probability of any event in a domain by summing over the cells in the distribution where that event is true.",
            "zh": "ç»™å®šä¸€ä¸ªå®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹åˆ†å¸ƒä¸­è¯¥äº‹ä»¶ä¸ºçœŸçš„å•å…ƒæ ¼æ±‚å’Œæ¥è®¡ç®—åŸŸä¸­ä»»ä½•äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Modeling, 17, 19, 20, 87, 697, 719, 730",
            "zh": "å»ºæ¨¡ï¼Œ 17ï¼Œ 19ï¼Œ 20ï¼Œ 87ï¼Œ 697ï¼Œ 719ï¼Œ 730"
        }
    },
    {
        "translation": {
            "en": "During the forward pass for each input and hidden layer in the network a vector DropMask of 0 or 1 values is sampled from a Bernoulli distribution with probability Ï that a sampled value will be 1.",
            "zh": "åœ¨ç½‘ç»œä¸­æ¯ä¸ªè¾“å…¥å±‚å’Œéšè—å±‚çš„å‰å‘ä¼ é€’æœŸé—´ï¼Œä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªå€¼ä¸º 0 æˆ– 1 çš„å‘é‡ DropMaskï¼Œé‡‡æ ·å€¼çš„æ¦‚ç‡ Ï ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cristianini, Nello, and John Shawe-Taylor. 2000. An introduction to support vector machines and other kernel-based learning methods. Cambridge University Press.",
            "zh": "å…‹é‡Œæ–¯è’‚äºšå°¼å°¼ã€å†…æ´›å’Œçº¦ç¿°Â·æ²™å¨-æ³°å‹’ã€‚2000. ä»‹ç»æ”¯æŒå‘é‡æœºå’Œå…¶ä»–åŸºäºæ ¸çš„å­¦ä¹ æ–¹æ³•ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we identify data quality issues due to invalid data, we should take immediate action to correct them, regenerate the ABT, and re-create the data quality report.",
            "zh": "å½“æˆ‘ä»¬å‘ç°ç”±äºæ— æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥ç«‹å³é‡‡å–æªæ–½è¿›è¡Œçº æ­£ï¼Œé‡æ–°ç”Ÿæˆ ABTï¼Œå¹¶é‡æ–°åˆ›å»ºæ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.8",
            "zh": "å›¾ 8.8"
        }
    },
    {
        "translation": {
            "en": "We need to be careful when sampling, however, to ensure that the resulting datasets are still representative of the original data and that no unintended bias is introduced during this process.",
            "zh": "ç„¶è€Œï¼Œåœ¨é‡‡æ ·æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å°å¿ƒï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æ•°æ®é›†ä»ç„¶ä»£è¡¨åŸå§‹æ•°æ®ï¼Œå¹¶ä¸”åœ¨æ­¤è¿‡ç¨‹ä¸­ä¸ä¼šå¼•å…¥æ„å¤–çš„åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can solve both these problems by using a more sophisticated threshold function that is continuous, and therefore differentiable, and that allows for the subtlety desired: the logistic function.13",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸€ä¸ªæ›´å¤æ‚çš„é˜ˆå€¼å‡½æ•°æ¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œè¯¥é˜ˆå€¼å‡½æ•°æ˜¯è¿ç»­çš„ï¼Œå› æ­¤æ˜¯å¯å¾®çš„ï¼Œå¹¶ä¸”å…è®¸æ‰€éœ€çš„å¾®å¦™ä¹‹å¤„ï¼šé€»è¾‘å‡½æ•°13ã€‚"
        }
    },
    {
        "translation": {
            "en": "Starting on the left of the figure, the column of 7 three-channel (RGB) pixels is fed into the first convolutional layer.",
            "zh": "ä»å›¾çš„å·¦ä¾§å¼€å§‹ï¼Œå°† 7 ä¸ªä¸‰é€šé“ ï¼ˆRGBï¼‰ åƒç´ åˆ—è¾“å…¥åˆ°ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. It is more common to split an ABT in the opposite proportions (70% for the training set and 30% for the test set). In this case, however, because the ABT was so large it was more useful to have a very large test sample, as 200,000 instances should be more than enough for the training set.",
            "zh": "14. æ›´å¸¸è§çš„æ˜¯ä»¥ç›¸åçš„æ¯”ä¾‹æ‹†åˆ† ABTï¼ˆè®­ç»ƒé›†ä¸º 70%ï¼Œæµ‹è¯•é›†ä¸º 30%ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äº ABT éå¸¸å¤§ï¼Œå› æ­¤æ‹¥æœ‰éå¸¸å¤§çš„æµ‹è¯•æ ·æœ¬æ›´æœ‰ç”¨ï¼Œå› ä¸º 200,000 ä¸ªå®ä¾‹å¯¹äºè®­ç»ƒé›†æ¥è¯´åº”è¯¥ç»°ç»°æœ‰ä½™ã€‚"
        }
    },
    {
        "translation": {
            "en": "MOTORVALUE: The value of the car on the motor policy",
            "zh": "MOTORVALUEï¼šæ±½è½¦åœ¨æ±½è½¦ä¿å•ä¸Šçš„ä»·å€¼"
        }
    },
    {
        "translation": {
            "en": "As a result, the information gain for a particular descriptive feature may be different at different nodes in the tree because it will be computed on different subsets of the full training dataset.",
            "zh": "å› æ­¤ï¼Œç‰¹å®šæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šåœ¨æ ‘ä¸­çš„ä¸åŒèŠ‚ç‚¹ä¸Šå¯èƒ½ä¸åŒï¼Œå› ä¸ºå®ƒå°†åœ¨å®Œæ•´è®­ç»ƒæ•°æ®é›†çš„ä¸åŒå­é›†ä¸Šè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The internal layers in the network, which are neither input nor output layers, are called hidden layers.",
            "zh": "ç½‘ç»œä¸­çš„å†…éƒ¨å±‚æ—¢ä¸æ˜¯è¾“å…¥å±‚ä¹Ÿä¸æ˜¯è¾“å‡ºå±‚ï¼Œç§°ä¸ºéšè—å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because the k-NN makes the mistake of misclassifying a bad borrower as good more often than the decision tree model, and this is the more costly mistake.",
            "zh": "è¿™æ˜¯å› ä¸º k-NN æ¯”å†³ç­–æ ‘æ¨¡å‹æ›´é¢‘ç¹åœ°é”™è¯¯åœ°å°†ä¸è‰¯å€Ÿæ¬¾äººå½’ç±»ä¸ºå¥½å€Ÿæ¬¾äººï¼Œè¿™æ˜¯ä»£ä»·æ›´é«˜çš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This distinction between fat and light tailed distributions is important because it highlights that when we use a normal distribution, we are implicitly assuming that the likelihood of values that differ from the mean of the distribution drops quite dramatically as we move away from the mean.",
            "zh": "è„‚è‚ªåˆ†å¸ƒå’Œè½»å°¾åˆ†å¸ƒä¹‹é—´çš„è¿™ç§åŒºåˆ«å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå¼ºè°ƒäº†å½“æˆ‘ä»¬ä½¿ç”¨æ­£æ€åˆ†å¸ƒæ—¶ï¼Œæˆ‘ä»¬éšå«åœ°å‡è®¾ï¼Œå½“æˆ‘ä»¬è¿œç¦»å‡å€¼æ—¶ï¼Œä¸åˆ†å¸ƒå‡å€¼ä¸åŒçš„å¯èƒ½æ€§ä¼šæ€¥å‰§ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the full dataset has been split into four partitions (labeled 6, 7, 8, and 9 in Table 4.4[137]) and that the feature ELEVATION is no longer listed in these partitions because it has already been used to split the data.",
            "zh": "è¯·æ³¨æ„ï¼Œå®Œæ•´æ•°æ®é›†å·²æ‹†åˆ†ä¸ºå››ä¸ªåˆ†åŒºï¼ˆåœ¨è¡¨ 4.4[137] ä¸­æ ‡è®°ä¸º 6ã€7ã€8 å’Œ 9ï¼‰ï¼Œå¹¶ä¸”è¿™äº›åˆ†åŒºä¸­ä¸å†åˆ—å‡ºç‰¹å¾ ELEVATIONï¼Œå› ä¸ºå®ƒå·²è¢«ç”¨äºæ‹†åˆ†æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This increases the size of the weight space through which we need to search when training the model.",
            "zh": "è¿™å¢åŠ äº†æˆ‘ä»¬åœ¨è®­ç»ƒæ¨¡å‹æ—¶éœ€è¦æœç´¢çš„æƒé‡ç©ºé—´çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Due to space limitations, this dataset covers only a sample of the risk factors for stroke.",
            "zh": "ç”±äºç¯‡å¹…æ‰€é™ï¼Œè¯¥æ•°æ®é›†ä»…æ¶µç›–ä¸­é£å±é™©å› ç´ çš„æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is clear in the visualization of the action-value table after 35 episodes of Q-learning have elapsed that is shown in Figure 11.5(b)[663].",
            "zh": "è¿™åœ¨ç»è¿‡35é›†Qå­¦ä¹ åçš„åŠ¨ä½œå€¼è¡¨çš„å¯è§†åŒ–ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œå¦‚å›¾11.5ï¼ˆbï¼‰[663]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The individual silhouette widths for the instances in a dataset can also be used to produce a useful visual tool for inspecting a clustering.",
            "zh": "æ•°æ®é›†ä¸­å®ä¾‹çš„å„ä¸ªä¾§é¢å½±åƒå®½åº¦ä¹Ÿå¯ç”¨äºç”Ÿæˆç”¨äºæ£€æŸ¥èšç±»çš„æœ‰ç”¨å¯è§†åŒ–å·¥å…·ã€‚"
        }
    },
    {
        "translation": {
            "en": "15. See Chapter 8[381] for a discussion of mini-batch gradient descent.",
            "zh": "15. å‚è§ç¬¬8ç« [381]ï¼Œäº†è§£å°æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "4.1â€ƒBig Idea",
            "zh": "4.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "Performance then became stable with a return of about 40 after the agent learned a useful path through the environment.",
            "zh": "ç„¶åï¼Œåœ¨ä»£ç†å­¦ä¹ äº†ç¯å¢ƒä¸­çš„æœ‰ç”¨è·¯å¾„åï¼Œæ€§èƒ½å˜å¾—ç¨³å®šï¼Œè¿”å›ç‡çº¦ä¸º 40ã€‚"
        }
    },
    {
        "translation": {
            "en": "Currently geologists at the company identify potential drilling sites by manually examining information from a variety of different sources. These include ordinance survey maps, aerial photographs, characteristics of rock and soil samples taken from potential sites, and measurements from sensitive gravitational and seismic instruments.",
            "zh": "ç›®å‰ï¼Œè¯¥å…¬å¸çš„åœ°è´¨å­¦å®¶é€šè¿‡æ‰‹åŠ¨æ£€æŸ¥æ¥è‡ªå„ç§ä¸åŒæ¥æºçš„ä¿¡æ¯æ¥è¯†åˆ«æ½œåœ¨çš„é’»æ¢åœ°ç‚¹ã€‚è¿™äº›åŒ…æ‹¬æ³•ä»¤æµ‹é‡åœ°å›¾ã€èˆªç©ºç…§ç‰‡ã€ä»æ½œåœ¨åœ°ç‚¹é‡‡é›†çš„å²©çŸ³å’ŒåœŸå£¤æ ·æœ¬çš„ç‰¹å¾ï¼Œä»¥åŠæ•æ„Ÿçš„é‡åŠ›å’Œåœ°éœ‡ä»ªå™¨çš„æµ‹é‡ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Silver, Nate. 2012. The signal and the noise: Why so many predictions fail â€” but some donâ€™t. Penguin Press.",
            "zh": "é“¶ç‰Œï¼Œå†…ç‰¹ã€‚2012. ä¿¡å·ä¸å™ªéŸ³ï¼šä¸ºä»€ä¹ˆè¿™ä¹ˆå¤šé¢„æµ‹å¤±è´¥â€”â€”ä½†æœ‰äº›å´æ²¡æœ‰ã€‚ä¼é¹…å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "SCORE",
            "zh": "å¾—åˆ†"
        }
    },
    {
        "translation": {
            "en": "We noted in this section that a heuristic that is used to help avoid saturating the rectifier function is to initialize the bias weights in the network to 0.1.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­æŒ‡å‡ºï¼Œç”¨äºå¸®åŠ©é¿å…æ•´æµå™¨åŠŸèƒ½é¥±å’Œçš„å¯å‘å¼æ–¹æ³•æ˜¯å°†ç½‘ç»œä¸­çš„åç½®æƒé‡åˆå§‹åŒ–ä¸º 0.1ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Gibbs sampling algorithm initializes a Bayesian network by clamping the values of the evidence nodes and randomly assigning values to the non-evidence nodes.",
            "zh": "Gibbs æŠ½æ ·ç®—æ³•é€šè¿‡é’³ä½è¯æ®èŠ‚ç‚¹çš„å€¼å¹¶å°†å€¼éšæœºåˆ†é…ç»™éè¯æ®èŠ‚ç‚¹æ¥åˆå§‹åŒ–è´å¶æ–¯ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "The most common approach to handling categorical features in linear regression models is to use a transformation that converts a single categorical descriptive feature into a number of continuous descriptive feature values that can encode the levels of the categorical feature.",
            "zh": "å¤„ç†çº¿æ€§å›å½’æ¨¡å‹ä¸­åˆ†ç±»ç‰¹å¾çš„æœ€å¸¸è§æ–¹æ³•æ˜¯ä½¿ç”¨è½¬æ¢ï¼Œå°†å•ä¸ªåˆ†ç±»æè¿°æ€§ç‰¹å¾è½¬æ¢ä¸ºå¤šä¸ªè¿ç»­æè¿°æ€§ç‰¹å¾å€¼ï¼Œè¿™äº›å€¼å¯ä»¥å¯¹åˆ†ç±»ç‰¹å¾çš„çº§åˆ«è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "This example shows that the algorithm converges to the global minimum more quickly than any of the approaches shown in Figure 7.7[329].",
            "zh": "è¿™ä¸ªä¾‹å­è¡¨æ˜ï¼Œè¯¥ç®—æ³•æ¯”å›¾7.7[329]æ‰€ç¤ºçš„ä»»ä½•æ–¹æ³•æ›´å¿«åœ°æ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to compare distributions, we measure the distribution of model outputs on the test set that was used to originally evaluate a model and then repeat this measurement on new sets of query instances collected during periods after the model has been deployed.",
            "zh": "ä¸ºäº†æ¯”è¾ƒåˆ†å¸ƒï¼Œæˆ‘ä»¬æµ‹é‡æœ€åˆç”¨äºè¯„ä¼°æ¨¡å‹çš„æµ‹è¯•é›†ä¸Šæ¨¡å‹è¾“å‡ºçš„åˆ†å¸ƒï¼Œç„¶ååœ¨æ¨¡å‹éƒ¨ç½²åçš„ä¸€æ®µæ—¶é—´å†…æ”¶é›†çš„æ–°æŸ¥è¯¢å®ä¾‹é›†ä¸Šé‡å¤æ­¤æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "action-value function, 642, 643, 651, 676",
            "zh": "åŠ¨ä½œå€¼å‡½æ•°ï¼Œ 642ï¼Œ 643ï¼Œ 651ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "19. Taleb (2008) discusses the problems that arise when analysts use normal distributions to model social and economic features, where the assumptions regarding light tails donâ€™t hold.",
            "zh": "19. Talebï¼ˆ2008ï¼‰è®¨è®ºäº†å½“åˆ†æå¸ˆä½¿ç”¨æ­£æ€åˆ†å¸ƒå¯¹ç¤¾ä¼šå’Œç»æµç‰¹å¾è¿›è¡Œå»ºæ¨¡æ—¶å‡ºç°çš„é—®é¢˜ï¼Œå…¶ä¸­å…³äºå…‰å°¾çš„å‡è®¾ä¸æˆç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "From a distribution perspective, the main distinction between a normal distribution and a student-t is that a normal distribution has light tails whereas the student-t distribution has fat tails.",
            "zh": "ä»åˆ†å¸ƒçš„è§’åº¦æ¥çœ‹ï¼Œæ­£æ€åˆ†å¸ƒå’Œ student-t ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºæ­£æ€åˆ†å¸ƒå…·æœ‰æµ…å°¾ï¼Œè€Œ student-t åˆ†å¸ƒå…·æœ‰è‚¥å°¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "What about the other features?",
            "zh": "å…¶ä»–åŠŸèƒ½å‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "data quality issues, 53, 63, 94",
            "zh": "æ•°æ®è´¨é‡é—®é¢˜ï¼Œ 53ï¼Œ 63ï¼Œ 94"
        }
    },
    {
        "translation": {
            "en": "Finally, we hope that you find machine learning as fascinating and rewarding a topic as we do, and we wish you the best in your future learning.",
            "zh": "æœ€åï¼Œæˆ‘ä»¬å¸Œæœ›æ‚¨èƒ½åƒæˆ‘ä»¬ä¸€æ ·å‘ç°æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªå¼•äººå…¥èƒœä¸”æœ‰ç›Šçš„ä¸»é¢˜ï¼Œå¹¶ç¥æ‚¨åœ¨æœªæ¥çš„å­¦ä¹ ä¸­ä¸€åˆ‡é¡ºåˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.2.1â€ƒCase Study: Motor Insurance Fraud",
            "zh": "2.2.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Understanding",
            "zh": "ç†è§£"
        }
    },
    {
        "translation": {
            "en": "Equality directly affects both health and education, so there are directed arcs from GINI COEF to both LIFE EXP and SCHOOL YEARS.",
            "zh": "å¹³ç­‰ç›´æ¥å½±å“å¥åº·å’Œæ•™è‚²ï¼Œå› æ­¤ä»åŸºå°¼COEFåˆ°LIFE EXPå’Œå­¦å¹´éƒ½æœ‰å®šå‘çš„å¼§çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "It would be useful for farmers to be able to predict grass growth for different amounts of forecasted rainfall so that they could plan the optimal times to harvest their grass for making hay.",
            "zh": "å¯¹äºå†œæ°‘æ¥è¯´ï¼Œèƒ½å¤Ÿé¢„æµ‹ä¸åŒé¢„æµ‹é™é›¨é‡çš„è‰ç”Ÿé•¿æƒ…å†µå°†æ˜¯æœ‰ç”¨çš„ï¼Œè¿™æ ·ä»–ä»¬å°±å¯ä»¥è®¡åˆ’æ”¶è·è‰ä»¥åˆ¶ä½œå¹²è‰çš„æœ€ä½³æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another relevant textbook by the same author is (Strang, 2019), which specifically focuses on introducing linear algebra from the perspective of understanding deep learning.",
            "zh": "åŒä¸€ä½œè€…çš„å¦ä¸€æœ¬ç›¸å…³æ•™ç§‘ä¹¦æ˜¯ï¼ˆStrangï¼Œ2019ï¼‰ï¼Œè¯¥æ•™ç§‘ä¹¦ç‰¹åˆ«ä¾§é‡äºä»ç†è§£æ·±åº¦å­¦ä¹ çš„è§’åº¦ä»‹ç»çº¿æ€§ä»£æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will introduce two of the more popular: equal-width binning and equal-frequency binning.",
            "zh": "æˆ‘ä»¬å°†ä»‹ç»ä¸¤ç§æ›´æµè¡Œçš„æ–¹æ³•ï¼šç­‰å®½åˆ†æ¡£å’Œç­‰é¢‘åˆ†æ¡£ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4.5â€…â€…â€…Model Ensembles",
            "zh": "4.4.5 æ¨¡å‹é›†åˆ"
        }
    },
    {
        "translation": {
            "en": "â€œInformation is the resolution of uncertainty.â€",
            "zh": "â€œä¿¡æ¯æ˜¯ä¸ç¡®å®šæ€§çš„è§£å†³æ–¹æ¡ˆã€‚â€"
        }
    },
    {
        "translation": {
            "en": "information gain, 117, 120, 129, 130, 133, 135, 172, 174, 227, 614, 717",
            "zh": "ä¿¡æ¯å¢ç›Šï¼Œ 117ï¼Œ 120ï¼Œ 129ï¼Œ 130ï¼Œ 133ï¼Œ 135ï¼Œ 172ï¼Œ 174ï¼Œ 227ï¼Œ 614ï¼Œ 717"
        }
    },
    {
        "translation": {
            "en": "This process of storing activations in the memory buffer at one time-step and reading from the buffer at the next time-step is how the recurrent connections are implemented.",
            "zh": "åœ¨ä¸€ä¸ªæ—¶é—´æ­¥é•¿å°†æ¿€æ´»å­˜å‚¨åœ¨å†…å­˜ç¼“å†²åŒºä¸­ï¼Œå¹¶åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä»ç¼“å†²åŒºè¯»å–ï¼Œè¿™ä¸ªè¿‡ç¨‹æ˜¯å¾ªç¯è¿æ¥çš„å®ç°æ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. We introduce the subscript k on the target t k into this equation to allow for situations in which the network has multiple neurons in the output layer, and the target output then defines a separate target tk for each of these neurons.",
            "zh": "10. æˆ‘ä»¬å°†ç›®æ ‡ t k ä¸Šçš„ä¸‹æ ‡ k å¼•å…¥è¯¥ç­‰å¼ï¼Œä»¥å…è®¸ç½‘ç»œåœ¨è¾“å‡ºå±‚ä¸­æœ‰å¤šä¸ªç¥ç»å…ƒçš„æƒ…å†µï¼Œç„¶åç›®æ ‡è¾“å‡ºä¸ºæ¯ä¸ªç¥ç»å…ƒå®šä¹‰ä¸€ä¸ªå•ç‹¬çš„ç›®æ ‡ tkã€‚"
        }
    },
    {
        "translation": {
            "en": "ANNUAL INCOME, the target feature with 3 levels ( <25K, 25Kâ€“50K, >50K).",
            "zh": "å¹´æ”¶å…¥ï¼Œç›®æ ‡ç‰¹å¾æœ‰ 3 ä¸ªçº§åˆ«ï¼ˆ<25Kã€25Kâ€“50Kã€>50Kï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The REGIONTYPE and OCCUPATION categorical features both suffered from a significant number of missing valuesâ€”74% and 47.8% respectively.",
            "zh": "REGIONTYPE å’Œ OCCUPATION åˆ†ç±»ç‰¹å¾éƒ½å­˜åœ¨å¤§é‡ç¼ºå¤±å€¼ï¼Œåˆ†åˆ«ä¸º 74% å’Œ 47.8%ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Claim prediction] A model could be built to predict the likelihood that an insurance claim is fraudulent.",
            "zh": "[ç´¢èµ”é¢„æµ‹]å¯ä»¥å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ä¿é™©ç´¢èµ”æ¬ºè¯ˆçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Network Links: Links between an item and other related items (for example, links between different customers or different products, or social network links between customers).",
            "zh": "ç½‘ç»œé“¾æ¥ï¼šå•†å“ä¸å…¶ä»–ç›¸å…³å•†å“ä¹‹é—´çš„é“¾æ¥ï¼ˆä¾‹å¦‚ï¼Œä¸åŒå®¢æˆ·æˆ–ä¸åŒäº§å“ä¹‹é—´çš„é“¾æ¥ï¼Œæˆ–å®¢æˆ·ä¹‹é—´çš„ç¤¾äº¤ç½‘ç»œé“¾æ¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The aggregate class accuracy measure can then be calculated from this combined confusion matrix and, in this case, turns out to be 84%.",
            "zh": "ç„¶åï¼Œå¯ä»¥ä»è¿™ä¸ªç»„åˆæ··æ·†çŸ©é˜µä¸­è®¡ç®—å‡ºèšåˆç±»å‡†ç¡®åº¦é‡ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œç»“æœæ˜¯ 84%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature spaces can, however, have many more dimensionsâ€”in document classification tasks, for example, it is not uncommon to have thousands of descriptive features and therefore thousands of dimensions in the associated feature space.",
            "zh": "ä½†æ˜¯ï¼Œè¦ç´ ç©ºé—´å¯ä»¥å…·æœ‰æ›´å¤šç»´åº¦ï¼Œä¾‹å¦‚ï¼Œåœ¨æ–‡æ¡£åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œåœ¨å…³è”çš„ç‰¹å¾ç©ºé—´ä¸­å…·æœ‰æ•°åƒä¸ªæè¿°æ€§è¦ç´ å¹¶å› æ­¤å…·æœ‰æ•°åƒä¸ªç»´åº¦çš„æƒ…å†µå¹¶ä¸å°‘è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.10â€…â€…â€…(a) Overall profit for the k-NN model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(a)[555]; and (b) overall profit for the decision tree model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(b)[555].",
            "zh": "9.10 ï¼ˆaï¼‰ ä½¿ç”¨è¡¨9.8[554]ä¸­çš„åˆ©æ¶¦çŸ©é˜µå’Œè¡¨9.9ï¼ˆaï¼‰[555]ä¸­çš„æ··æ·†çŸ©é˜µè®¡ç®—çš„k-NNæ¨¡å‹çš„æ€»åˆ©æ¶¦;ï¼ˆbï¼‰ä½¿ç”¨è¡¨9.8[554]ä¸­çš„åˆ©æ¶¦çŸ©é˜µå’Œè¡¨9.9ï¼ˆbï¼‰[555]ä¸­çš„æ··æ·†çŸ©é˜µçš„å†³ç­–æ ‘æ¨¡å‹çš„æ€»åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Acknowledgments",
            "zh": "ç¡®è®¤"
        }
    },
    {
        "translation": {
            "en": "As the term similarity-based learning suggests, a key component of this approach to prediction is defining a computational measure of similarity between instances.",
            "zh": "æ­£å¦‚æœ¯è¯­â€œåŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ â€æ‰€æš—ç¤ºçš„é‚£æ ·ï¼Œè¿™ç§é¢„æµ‹æ–¹æ³•çš„ä¸€ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†æ˜¯å®šä¹‰å®ä¾‹ä¹‹é—´ç›¸ä¼¼æ€§çš„è®¡ç®—åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "imbalanced data, 193, 550, 693",
            "zh": "ä¸å¹³è¡¡æ•°æ®ï¼Œ 193ï¼Œ 550ï¼Œ 693"
        }
    },
    {
        "translation": {
            "en": "Although fully automated approaches to answering this question do not exist, analysts can use an approach based on the data exploration tools presented in Chapter 3[53] to understand the results of a clustering.",
            "zh": "å°½ç®¡ä¸å­˜åœ¨å›ç­”è¿™ä¸ªé—®é¢˜çš„å…¨è‡ªåŠ¨æ–¹æ³•ï¼Œä½†åˆ†æå¸ˆå¯ä»¥ä½¿ç”¨åŸºäºç¬¬ 3 ç« [53] ä¸­ä»‹ç»çš„æ•°æ®æ¢ç´¢å·¥å…·çš„æ–¹æ³•æ¥ç†è§£èšç±»çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "2. if ak, is negative, we should increase the weight wi,k. However, in this case âˆ‚â„°/âˆ‚wi,k = Î´i Ã— ak will be negative, because the product involves a positive and a negative term. And, so to increase wi,k, we should again subtract âˆ‚â„°/âˆ‚wi,k from wi,k.",
            "zh": "2. å¦‚æœ AK ä¸ºè´Ÿæ•°ï¼Œåˆ™åº”å¢åŠ æƒé‡ Wiï¼ŒKã€‚ä½†æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œâˆ‚E/âˆ‚wiï¼Œk = Î´i Ã— ak å°†ä¸ºè´Ÿæ•°ï¼Œå› ä¸ºä¹˜ç§¯æ¶‰åŠæ­£é¡¹å’Œè´Ÿé¡¹ã€‚å› æ­¤ï¼Œä¸ºäº†å¢åŠ  wiï¼Œkï¼Œæˆ‘ä»¬åº”è¯¥å†æ¬¡ä» wiï¼Œk ä¸­å‡å» âˆ‚E/âˆ‚wiï¼Œkã€‚"
        }
    },
    {
        "translation": {
            "en": "average linkage, 619, 635",
            "zh": "å¹³å‡è¿æ†ï¼Œ619,635"
        }
    },
    {
        "translation": {
            "en": "In the case of a nearest neighbor algorithm, as the number of instances becomes large, the model will become slower because it has more instances to check when defining the neighborhood.",
            "zh": "å¯¹äºæœ€è¿‘é‚»ç®—æ³•ï¼Œéšç€å®ä¾‹æ•°å˜å¤§ï¼Œæ¨¡å‹å°†å˜æ…¢ï¼Œå› ä¸ºåœ¨å®šä¹‰é‚»åŸŸæ—¶è¦æ£€æŸ¥çš„å®ä¾‹æ›´å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "and denominator as:",
            "zh": "åˆ†æ¯ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "The task in this question is to create a naive Bayes model to monitor a wastewater treatment plant.33 The table below lists a dataset containing details of activities at a wastewater treatment plant for 14 days.",
            "zh": "33 ä¸‹è¡¨åˆ—å‡ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åºŸæ°´å¤„ç†å‚ 14 å¤©çš„æ´»åŠ¨è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance, however, also rescales the differences between feature values (using the inverse covariance matrix) so that all the features have unit variance, and the effects of covariance are removed.",
            "zh": "ä½†æ˜¯ï¼Œé©¬æ°è·ç¦»è¿˜é‡æ–°ç¼©æ”¾äº†ç‰¹å¾å€¼ä¹‹é—´çš„å·®å¼‚ï¼ˆä½¿ç”¨é€†åæ–¹å·®çŸ©é˜µï¼‰ï¼Œä»¥ä¾¿æ‰€æœ‰ç‰¹å¾éƒ½å…·æœ‰å•ä½æ–¹å·®ï¼Œå¹¶ä¸”å»é™¤äº†åæ–¹å·®çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "So the distance between two points in the feature space is a useful measure of the similarity of the descriptive features of the two instances.",
            "zh": "å› æ­¤ï¼Œç‰¹å¾ç©ºé—´ä¸­ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»æ˜¯è¡¡é‡ä¸¤ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾ç›¸ä¼¼æ€§çš„æœ‰ç”¨åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3.4â€…â€…â€…Backpropagation: The Algorithm",
            "zh": "8.3.4 åå‘ä¼ æ’­ï¼šç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "While the first option is often used, Jocelyn was lucky that another data source became available.",
            "zh": "è™½ç„¶ç»å¸¸ä½¿ç”¨ç¬¬ä¸€ä¸ªé€‰é¡¹ï¼Œä½† Jocelyn å¾ˆå¹¸è¿ï¼Œæœ‰å¦ä¸€ä¸ªæ•°æ®æºå¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is clear from these histograms that the distribution of values taken by the ACCOUNT BALANCE feature in the set of instances where FRAUD = true follows an exponential distribution; whereas, the distribution of the values taken by the ACCOUNT BALANCE feature in the set of instances where the FRAUD = false is similar to a normal distribution.",
            "zh": "ä»è¿™äº›ç›´æ–¹å›¾ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œåœ¨ FRAUD = true çš„ä¸€ç»„å®ä¾‹ä¸­ï¼ŒACCOUNT BALANCE ç‰¹å¾æ‰€è·å–çš„å€¼åˆ†å¸ƒéµå¾ªæŒ‡æ•°åˆ†å¸ƒ;è€Œ ACCOUNT BALANCE ç‰¹å¾åœ¨ FRAUD = false çš„ä¸€ç»„å®ä¾‹ä¸­è·å–çš„å€¼åˆ†å¸ƒç±»ä¼¼äºæ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "probability function, 246, 758",
            "zh": "æ¦‚ç‡å‡½æ•°ï¼Œ 246ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "The good news, however, is that the disease is extremely rare, striking only 1 in 10,000 people.",
            "zh": "ç„¶è€Œï¼Œå¥½æ¶ˆæ¯æ˜¯ï¼Œè¿™ç§ç–¾ç—…æä¸ºç½•è§ï¼Œæ¯10,000äººä¸­åªæœ‰1äººæ‚£ç—…ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. This dataset has been artificially generated for this example. Siddiqi (2005) gives an excellent overview of building predictive data analytics models for financial credit scoring.",
            "zh": "2. æ­¤æ•°æ®é›†æ˜¯é’ˆå¯¹æ­¤ç¤ºä¾‹äººå·¥ç”Ÿæˆçš„ã€‚Siddiqiï¼ˆ2005ï¼‰å¯¹æ„å»ºç”¨äºé‡‘èä¿¡ç”¨è¯„åˆ†çš„é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹è¿›è¡Œäº†å¾ˆå¥½çš„æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the stability index for the two new periods and determine whether the model should be retrained at either of these points.",
            "zh": "è®¡ç®—ä¸¤ä¸ªæ–°å‘¨æœŸçš„ç¨³å®šæ€§æŒ‡æ•°ï¼Œå¹¶ç¡®å®šæ˜¯å¦åº”åœ¨è¿™ä¸¤ä¸ªç‚¹ä¸­çš„ä»»ä½•ä¸€ä¸ªç‚¹é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The histogram represents the bins.",
            "zh": "ç›´æ–¹å›¾è¡¨ç¤ºæ¡æŸ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final evaluation that Jocelyn performed was in two parts.",
            "zh": "Jocelyn è¿›è¡Œçš„æœ€ç»ˆè¯„ä¼°åˆ†ä¸ºä¸¤éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "interpolate, 748",
            "zh": "æ’å€¼ï¼Œ748"
        }
    },
    {
        "translation": {
            "en": "As discussed in the introduction, the goal of this chapter is to give a flavor of the most important unsupervised machine learning techniques, and there are many more clustering algorithms not covered here.",
            "zh": "æ­£å¦‚å¼•è¨€ä¸­æ‰€è®¨è®ºçš„ï¼Œæœ¬ç« çš„ç›®æ ‡æ˜¯ä»‹ç»æœ€é‡è¦çš„æ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œè¿™é‡Œè¿˜æœ‰æ›´å¤šçš„èšç±»ç®—æ³•æ²¡æœ‰ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The naive approach to training a neural network using this loss function would be to use the backpropagation of error algorithm with stochastic gradient descent. This would mean that every time the agent took an action, at, to move from st to st+1, accumulating reward rt, a loss would be calculated using Equation (11.27)[670] and the gradient of this loss Equation (11.28)[670] would be backpropagated through the network to update the weights. Algorithm 15[671] outlines this naive approach.",
            "zh": "ä½¿ç”¨æ­¤æŸå¤±å‡½æ•°è®­ç»ƒç¥ç»ç½‘ç»œçš„æœ´ç´ æ–¹æ³•æ˜¯ä½¿ç”¨å…·æœ‰éšæœºæ¢¯åº¦ä¸‹é™çš„è¯¯å·®åå‘ä¼ æ’­ç®—æ³•ã€‚è¿™æ„å‘³ç€ï¼Œæ¯å½“æ™ºèƒ½ä½“é‡‡å–è¡ŒåŠ¨æ—¶ï¼Œä»stç§»åŠ¨åˆ°st+1ï¼Œç´¯ç§¯å¥–åŠ±rtï¼Œå°†ä½¿ç”¨æ–¹ç¨‹ï¼ˆ11.27ï¼‰[670]è®¡ç®—æŸå¤±ï¼Œå¹¶ä¸”è¯¥æŸå¤±æ–¹ç¨‹ï¼ˆ11.28ï¼‰[670]çš„æ¢¯åº¦å°†é€šè¿‡ç½‘ç»œåå‘ä¼ æ’­ä»¥æ›´æ–°æƒé‡ã€‚ç®—æ³•15[671]æ¦‚è¿°äº†è¿™ç§å¹¼ç¨šçš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Anguita, Davide, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones. In Proceedings of the 21st international European symposium on artificial neural networks, computational intelligence, and machine learning (ESANNâ€™13), 437â€“442.",
            "zh": "å®‰å‰å¡”ã€æˆ´ç»´å¾·ã€äºšå†å±±å¾·ç½—Â·å‰å¥¥ã€å¢å¡Â·å¥¥å†…æ‰˜ã€æ³½ç»´å°”Â·å¸•æ‹‰å’Œè±ªå°”èµ«Â·è·¯æ˜“æ–¯Â·é›·è€¶æ–¯-å¥¥å°”è’‚æ–¯ã€‚2013. ä½¿ç”¨æ™ºèƒ½æ‰‹æœºè¯†åˆ«äººç±»æ´»åŠ¨çš„å…¬å…±é¢†åŸŸæ•°æ®é›†.åœ¨ç¬¬ 21 å±Šæ¬§æ´²äººå·¥ç¥ç»ç½‘ç»œã€è®¡ç®—æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ç ”è®¨ä¼š ï¼ˆESANN'13ï¼‰ çš„ä¼šè®®è®°å½•ä¸­ï¼Œç¬¬ 437â€“442 é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset listing features for a number of generators.",
            "zh": "åˆ—å‡ºå¤šä¸ªç”Ÿæˆå™¨çš„ç‰¹å¾çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Plainly, this model is not performing well.",
            "zh": "æ˜¾ç„¶ï¼Œè¿™ç§æ¨¡å¼è¡¨ç°ä¸ä½³ã€‚"
        }
    },
    {
        "translation": {
            "en": "(2016) provides a comprehensive overview of the field.",
            "zh": "ï¼ˆ2016ï¼‰æä¾›äº†è¯¥é¢†åŸŸçš„å…¨é¢æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "RELATIVE HUMIDITY",
            "zh": "ç›¸å¯¹æ¹¿åº¦"
        }
    },
    {
        "translation": {
            "en": "The equation of a line predicts a y value for every x value given the slope and the y-intercept, and we can use this simple model to capture the relationship between two features such as SIZE and RENTAL PRICE.",
            "zh": "ç»™å®šæ–œç‡å’Œ y æˆªè·ï¼Œç›´çº¿æ–¹ç¨‹é¢„æµ‹æ¯ä¸ª x å€¼çš„ y å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªç®€å•çš„æ¨¡å‹æ¥æ•è·ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚ SIZE å’Œ RENTAL PRICEã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wish to calculate the probability of h given f when we donâ€™t care what values V or M take.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬å¸Œæœ›è®¡ç®—ç»™å®š f çš„ h çš„æ¦‚ç‡ï¼Œè€Œæˆ‘ä»¬ä¸åœ¨ä¹ V æˆ– M å–ä»€ä¹ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantages of using basis functions is that they allow models that represent non-linear relationships to be built even though these models themselves remain a linear combination of inputs (e.g., we still use something very similar to Equation (7.48)[367] to predict continuous targets).",
            "zh": "ä½¿ç”¨åŸºå‡½æ•°çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒä»¬å…è®¸æ„å»ºè¡¨ç¤ºéçº¿æ€§å…³ç³»çš„æ¨¡å‹ï¼Œå³ä½¿è¿™äº›æ¨¡å‹æœ¬èº«ä»ç„¶æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼ˆä¾‹å¦‚ï¼Œæˆ‘ä»¬ä»ç„¶ä½¿ç”¨ä¸æ–¹ç¨‹ï¼ˆ7.48ï¼‰[367]éå¸¸ç›¸ä¼¼çš„ä¸œè¥¿æ¥é¢„æµ‹è¿ç»­ç›®æ ‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamentals of unsupervised learning have already largely been covered in previous chapters. The clustering methods discussed in this chapter use the ideas of a feature space and a distance measure discussed in Chapter 5[181], and the feature generation techniques largely build upon the ideas of error-based learning and neural networks discussed in Chapters 7[311] and 8[381].",
            "zh": "æ— ç›‘ç£å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†åœ¨å‰é¢çš„ç« èŠ‚ä¸­å·²ç»åŸºæœ¬ä»‹ç»è¿‡äº†ã€‚æœ¬ç« è®¨è®ºçš„èšç±»æ–¹æ³•ä½¿ç”¨äº†ç¬¬5ç« [181]ä¸­è®¨è®ºçš„ç‰¹å¾ç©ºé—´å’Œè·ç¦»åº¦é‡çš„æ€æƒ³ï¼Œè€Œç‰¹å¾ç”ŸæˆæŠ€æœ¯åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå»ºç«‹åœ¨ç¬¬7ç« [311]å’Œç¬¬8ç« [381]ä¸­è®¨è®ºçš„åŸºäºé”™è¯¯çš„å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„æ€æƒ³ä¹‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, he would like to acknowledge and thank Aphra; this book would not have been started without her inspiration and would not have been completed without her support and patience.",
            "zh": "æœ€åï¼Œä»–è¦æ„Ÿè°¢é˜¿èŠ™æ‹‰;æ²¡æœ‰å¥¹çš„å¯å‘ï¼Œè¿™æœ¬ä¹¦å°±ä¸ä¼šå¼€å§‹ï¼Œæ²¡æœ‰å¥¹çš„æ”¯æŒå’Œè€å¿ƒï¼Œè¿™æœ¬ä¹¦å°±ä¸ä¼šå®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.4[10] illustrates the relationship between combinations of descriptive feature values and prediction models for the retail scenario.",
            "zh": "è¡¨ 1.4[10] è¯´æ˜äº†é›¶å”®åœºæ™¯çš„æè¿°æ€§ç‰¹å¾å€¼ç»„åˆå’Œé¢„æµ‹æ¨¡å‹ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, the result of the calculation matches the probability computed directly from the dataset (see Equation (B.2)[760]).",
            "zh": "åŒæ ·ï¼Œè®¡ç®—ç»“æœä¸ç›´æ¥ä»æ•°æ®é›†è®¡ç®—çš„æ¦‚ç‡ç›¸åŒ¹é…ï¼ˆå‚è§å…¬å¼ï¼ˆB.2ï¼‰[760]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.17â€…â€…â€…Cumulative gain, lift, and cumulative lift charts for four different models for the extended email classification test set.",
            "zh": "9.17 æ‰©å±•ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†çš„å››ç§ä¸åŒæ¨¡å‹çš„ç´¯è®¡å¢ç›Šã€æå‡å’Œç´¯ç§¯æå‡å›¾è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with Î¼=0.0,Ïƒ=0.01.",
            "zh": "å›¾ 8.22[450] ä¸­ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œå½“æ—¶æƒé‡ä½¿ç”¨ Î¼=0.0ï¼ŒÏƒ=0.01 çš„æ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unlike categorical features, continuous features can be used at multiple points along a path in a decision tree, although the threshold applied to the feature at each of these tests will be different.",
            "zh": "ä¸åˆ†ç±»ç‰¹å¾ä¸åŒï¼Œè¿ç»­ç‰¹å¾å¯ä»¥åœ¨å†³ç­–æ ‘ä¸­è·¯å¾„ä¸Šçš„å¤šä¸ªç‚¹ä¸Šä½¿ç”¨ï¼Œå°½ç®¡åœ¨æ¯ä¸ªæµ‹è¯•ä¸­åº”ç”¨äºç‰¹å¾çš„é˜ˆå€¼ä¼šæœ‰æ‰€ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "1. we represent the target feature using one-hot encoding;",
            "zh": "1.æˆ‘ä»¬ç”¨one-hotç¼–ç æ¥è¡¨ç¤ºç›®æ ‡ç‰¹å¾;"
        }
    },
    {
        "translation": {
            "en": "Other strides are possible, and it is possible to use different horizontal and vertical strides.",
            "zh": "å…¶ä»–æ­¥å¹…æ˜¯å¯èƒ½çš„ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ°´å¹³å’Œå‚ç›´æ­¥å¹…ã€‚"
        }
    },
    {
        "translation": {
            "en": "joint probability, 246, 251, 759",
            "zh": "è”åˆæ¦‚ç‡ï¼Œ246,251,759"
        }
    },
    {
        "translation": {
            "en": "Focusing on the cumulative gain charts, we can see that for Model 1, 80% of the spam messages are identified in the top 40% of the model predictions.",
            "zh": "å…³æ³¨ç´¯ç§¯å¢ç›Šå›¾è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºæ¨¡å‹ 1,80% çš„åƒåœ¾é‚®ä»¶åœ¨æ¨¡å‹é¢„æµ‹çš„å‰ 40% ä¸­è¢«è¯†åˆ«å‡ºæ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6",
            "zh": "å›¾ 2.6"
        }
    },
    {
        "translation": {
            "en": "In these cases the probability calculated is known as a joint probability.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè®¡ç®—å‡ºçš„æ¦‚ç‡ç§°ä¸ºè”åˆæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Case Study: Customer Churn",
            "zh": "æ¡ˆä¾‹ç ”ç©¶ï¼šå®¢æˆ·æµå¤±"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 10.12(b)[621].",
            "zh": "å¦‚å›¾10.12ï¼ˆbï¼‰[621]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Each normal that is merged is known as a component of the mixture.",
            "zh": "åˆå¹¶çš„æ¯ä¸ªæ³•çº¿éƒ½ç§°ä¸ºæ··åˆç‰©çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4.2â€…â€…â€…Deep Q Networks",
            "zh": "11.4.2 Deep Q ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "12.4â€…â€…â€…An unpruned decision tree built for the AT churn prediction problem (shown only to indicate its size and complexity). The excessive complexity and depth of the tree are evidence that overfitting has probably occurred.",
            "zh": "12.4 ä¸º AT æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„æœªä¿®å‰ªå†³ç­–æ ‘ï¼ˆä»…æ˜¾ç¤ºå…¶å¤§å°å’Œå¤æ‚æ€§ï¼‰ã€‚æ ‘çš„è¿‡åº¦å¤æ‚æ€§å’Œæ·±åº¦æ˜¯å¯èƒ½å‘ç”Ÿè¿‡æ‹Ÿåˆçš„è¯æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, some groups of neurons reacted to the same visual feature, but each neuron in the group reacted when the feature occurred at different locations; for example, one neuron would react to the feature if it occurred in the bottom-right of the screen whereas a different neuron would react if the feature occurred in the top-left of the screen.",
            "zh": "æ­¤å¤–ï¼Œä¸€äº›ç¥ç»å…ƒç»„å¯¹ç›¸åŒçš„è§†è§‰ç‰¹å¾æœ‰ååº”ï¼Œä½†è¯¥ç»„ä¸­çš„æ¯ä¸ªç¥ç»å…ƒåœ¨ç‰¹å¾å‘ç”Ÿåœ¨ä¸åŒä½ç½®æ—¶éƒ½ä¼šåšå‡ºååº”;ä¾‹å¦‚ï¼Œå¦‚æœç‰¹å¾å‘ç”Ÿåœ¨å±å¹•çš„å³ä¸‹è§’ï¼Œåˆ™ä¸€ä¸ªç¥ç»å…ƒä¼šå¯¹è¯¥ç‰¹å¾åšå‡ºååº”ï¼Œè€Œå¦‚æœè¯¥ç‰¹å¾å‘ç”Ÿåœ¨å±å¹•çš„å·¦ä¸Šè§’ï¼Œåˆ™å¦ä¸€ä¸ªç¥ç»å…ƒä¼šåšå‡ºååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "All the descriptive features are Boolean, taking two levels: true or false.",
            "zh": "æ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½æ˜¯å¸ƒå°”å€¼ï¼Œåˆ†ä¸ºä¸¤ä¸ªçº§åˆ«ï¼štrue æˆ– falseã€‚"
        }
    },
    {
        "translation": {
            "en": "B.4â€…â€…â€…Summary",
            "zh": "B.4 æ€»ç»“"
        }
    },
    {
        "translation": {
            "en": "We then conclude the extensions and variations of deep learning by introducing two of the most popular network architectures used in deep learning: convolutional neural networks (Section 8.4.5[477]) and recurrent neural networks (Section 8.4.6[499]).",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ä»‹ç»æ·±åº¦å­¦ä¹ ä¸­ä½¿ç”¨çš„ä¸¤ç§æœ€æµè¡Œçš„ç½‘ç»œæ¶æ„æ¥æ€»ç»“æ·±åº¦å­¦ä¹ çš„æ‰©å±•å’Œå˜åŒ–ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆç¬¬ 8.4.5 èŠ‚[477]ï¼‰å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆç¬¬ 8.4.6 èŠ‚[499]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the breast cancer prediction dataset from Question 11 (after some data quality issues present in the dataset have been corrected).",
            "zh": "ä»¥ä¸‹æ•°æ®å¯è§†åŒ–åŸºäºé—®é¢˜ 11 ä¸­çš„ä¹³è…ºç™Œé¢„æµ‹æ•°æ®é›†ï¼ˆåœ¨æ•°æ®é›†ä¸­å­˜åœ¨çš„ä¸€äº›æ•°æ®è´¨é‡é—®é¢˜å·²å¾—åˆ°çº æ­£åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These error gradients are often denoted using the Î´ symbol with a subscript indicating the relevant neuron.",
            "zh": "è¿™äº›è¯¯å·®æ¢¯åº¦é€šå¸¸ä½¿ç”¨Î´ç¬¦å·è¡¨ç¤ºï¼Œä¸‹æ ‡è¡¨ç¤ºç›¸å…³ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Linear models work very well when the underlying relationships in the data are linear.",
            "zh": "å½“æ•°æ®ä¸­çš„åŸºç¡€å…³ç³»æ˜¯çº¿æ€§çš„æ—¶ï¼Œçº¿æ€§æ¨¡å‹å¯ä»¥å¾ˆå¥½åœ°å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "We recommend Fawcett (2006) as an excellent introduction and overview to ROC analysis that covers the topic of imbalance in the test set.",
            "zh": "æˆ‘ä»¬æ¨èFawcettï¼ˆ2006ï¼‰ä½œä¸ºROCåˆ†æçš„ä¸€ä¸ªå¾ˆå¥½çš„ä»‹ç»å’Œæ¦‚è¿°ï¼Œæ¶µç›–äº†æµ‹è¯•é›†ä¸­çš„ä¸å¹³è¡¡ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Generative",
            "zh": "ç”Ÿæˆ"
        }
    },
    {
        "translation": {
            "en": "5.6â€…â€…â€…The dataset from Table 5.5[204] with the Euclidean distance between each instance and the query SALARY = 56,000, AGE = 35 when we use both the SALARY and AGE features, just the SALARY feature, and just the AGE feature.",
            "zh": "5.6 è¡¨ 5.5[204] ä¸­çš„æ•°æ®é›†ï¼Œæ¯ä¸ªå®ä¾‹ä¸æŸ¥è¯¢ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦» SALARY = 56,000ï¼ŒAGE = 35ï¼Œå½“æˆ‘ä»¬åŒæ—¶ä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾æ—¶ï¼Œåªä½¿ç”¨ SALARY ç‰¹å¾ï¼Œå¹¶ä¸”åªä½¿ç”¨ AGE ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning is defined as an automated process that extracts patterns from data. To build the models used in predictive data analytics applications, we use supervised machine learning. Supervised machine learning1 techniques automatically learn a model of the relationship between a set of descriptive features and a target feature based on a set of historical examples, or instances. We can then use this model to make predictions for new instances. These two separate steps are shown in Figure 1.2[5].",
            "zh": "æœºå™¨å­¦ä¹ è¢«å®šä¹‰ä¸ºä»æ•°æ®ä¸­æå–æ¨¡å¼çš„è‡ªåŠ¨åŒ–è¿‡ç¨‹ã€‚ä¸ºäº†æ„å»ºé¢„æµ‹æ•°æ®åˆ†æåº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç›‘ç£æœºå™¨å­¦ä¹ ã€‚ç›‘ç£å¼æœºå™¨å­¦ä¹ 1 æŠ€æœ¯åŸºäºä¸€ç»„å†å²ç¤ºä¾‹æˆ–å®ä¾‹è‡ªåŠ¨å­¦ä¹ ä¸€ç»„æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„æ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ­¤æ¨¡å‹å¯¹æ–°å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚è¿™ä¸¤ä¸ªå•ç‹¬çš„æ­¥éª¤å¦‚å›¾1.2æ‰€ç¤º[5]ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.2â€…â€…â€…Fundamentals",
            "zh": "10.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the current weights in a multivariate linear regression model are w[0] = âˆ’59.50, w[1] = âˆ’0.15, and w[2] = 0.60, make a prediction for each training instance using this model.",
            "zh": "ï¼ˆaï¼‰ å‡è®¾å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ä¸­çš„å½“å‰æƒé‡ä¸º w[0] = âˆ’59.50ã€w[1] = âˆ’0.15 å’Œ w[2] = 0.60ï¼Œä½¿ç”¨è¯¥æ¨¡å‹å¯¹æ¯ä¸ªè®­ç»ƒå®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these equations we distinguish between these two paths of data processing and the weight matrices using the â€  and â€¡.",
            "zh": "åœ¨è¿™äº›æ–¹ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ â€  å’Œ â€¡ åŒºåˆ†äº†è¿™ä¸¤ç§æ•°æ®å¤„ç†è·¯å¾„å’Œæƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "31. Adaboost.R2 (Drucker, 1997) is a nice early example of a boosting algorithm designed to work with continuous targets.",
            "zh": "31. Adaboost.R2 ï¼ˆDruckerï¼Œ 1997ï¼‰ æ˜¯è®¾è®¡ç”¨äºè¿ç»­ç›®æ ‡çš„æå‡ç®—æ³•çš„ä¸€ä¸ªå¾ˆå¥½çš„æ—©æœŸç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we describe are how to handle categorical descriptive features, the use of logistic regression to make predictions for categorical target features, fine-tuning regression models, techniques for building non-linear and multinomial models, and support vector machines, which take a slightly different approach to using error to build prediction models.",
            "zh": "æˆ‘ä»¬æè¿°çš„è¿™ç§æ ‡å‡†æ–¹æ³•çš„æ‰©å±•å’Œå˜ä½“æ˜¯å¦‚ä½•å¤„ç†åˆ†ç±»æè¿°æ€§ç‰¹å¾ï¼Œä½¿ç”¨é€»è¾‘å›å½’å¯¹åˆ†ç±»ç›®æ ‡ç‰¹å¾è¿›è¡Œé¢„æµ‹ï¼Œå¾®è°ƒå›å½’æ¨¡å‹ï¼Œæ„å»ºéçº¿æ€§å’Œå¤šé¡¹å¼æ¨¡å‹çš„æŠ€æœ¯ï¼Œä»¥åŠæ”¯æŒå‘é‡æœºï¼Œå®ƒä»¬é‡‡ç”¨ç•¥æœ‰ä¸åŒçš„æ–¹æ³•æ¥ä½¿ç”¨è¯¯å·®æ¥æ„å»ºé¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout these technical chapters, the link to the broader predictive analytics context is maintained through detailed and complete real-world examples, along with references to the datasets and/or papers on which the examples are based.",
            "zh": "åœ¨è¿™äº›æŠ€æœ¯ç« èŠ‚ä¸­ï¼Œé€šè¿‡è¯¦ç»†è€Œå®Œæ•´çš„çœŸå®ç¤ºä¾‹ä»¥åŠå¯¹ç¤ºä¾‹æ‰€åŸºäºçš„æ•°æ®é›†å’Œ/æˆ–è®ºæ–‡çš„å¼•ç”¨ï¼Œä¿æŒäº†ä¸æ›´å¹¿æ³›çš„é¢„æµ‹åˆ†æä¸Šä¸‹æ–‡çš„é“¾æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Woolery, L., J. Grzymala-Busse, S. Summers, and A. Budihardjo. 1991. The use of machine learning program LERS-LB 2.5 in knowledge acquisition for expert system development in nursing. Computers in Nursing 9: 227â€“234.",
            "zh": "Wooleryï¼Œ L.ã€J. Grzymala-Busseã€S. Summers å’Œ A. Budihardjoã€‚1991. æœºå™¨å­¦ä¹ ç¨‹åº LERS-LB 2.5 åœ¨çŸ¥è¯†è·å–ä¸­çš„åº”ç”¨ï¼Œç”¨äºæŠ¤ç†ä¸“å®¶ç³»ç»Ÿå¼€å‘ã€‚æŠ¤ç†è®¡ç®—æœº 9ï¼š227-234ã€‚"
        }
    },
    {
        "translation": {
            "en": "The outcome of an attempt to catch a wave is a judgment on how well the surfer is doing, so an attempt constitutes an error function: lying too far back on the board leads to a medium error, lying too far forward on the board leads to a more dramatic error, while successfully catching a wave means really no error at all.",
            "zh": "å°è¯•æ•æ‰æ³¢æµªçš„ç»“æœæ˜¯å¯¹å†²æµªè€…è¡¨ç°çš„åˆ¤æ–­ï¼Œå› æ­¤å°è¯•æ„æˆè¯¯å·®å‡½æ•°ï¼šåœ¨å†²æµªæ¿ä¸Šèººå¾—å¤ªé åä¼šå¯¼è‡´ä¸­ç­‰è¯¯å·®ï¼Œåœ¨å†²æµªæ¿ä¸Šèººå¾—å¤ªé å‰ä¼šå¯¼è‡´æ›´ä¸¥é‡çš„é”™è¯¯ï¼Œè€ŒæˆåŠŸæ•æ‰æ³¢æµªæ„å‘³ç€å®é™…ä¸Šæ ¹æœ¬æ²¡æœ‰é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Forward probability reasons from causes to effects: if we know that a particular causal event has happened, then we increase the probability associated with the known effects that it causes.",
            "zh": "ä»åŸå› åˆ°ç»“æœçš„æ­£å‘æ¦‚ç‡åŸå› ï¼šå¦‚æœæˆ‘ä»¬çŸ¥é“ä¸€ä¸ªç‰¹å®šçš„å› æœäº‹ä»¶å·²ç»å‘ç”Ÿï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±ä¼šå¢åŠ ä¸å®ƒå¼•èµ·çš„å·²çŸ¥ç»“æœç›¸å…³çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We do this by defining an error function to measure the error between the predictions a model makes on the basis of the descriptive features for each instance in the training data and the actual target values for each instance in the training data.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªè¯¯å·®å‡½æ•°æ¥è¡¡é‡æ¨¡å‹æ ¹æ®è®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾åšå‡ºçš„é¢„æµ‹ä¸è®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªå®ä¾‹çš„å®é™…ç›®æ ‡å€¼ä¹‹é—´çš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "If, however, you were to randomly select an element from the set in Figure 4.5(f)[124], you would be very uncertain about any prediction as there are 12 possible outcomes, each of which is equally likely.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæ‚¨ä»å›¾ 4.5ï¼ˆfï¼‰[124] ä¸­çš„é›†åˆä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå…ƒç´ ï¼Œæ‚¨å°†éå¸¸ä¸ç¡®å®šä»»ä½•é¢„æµ‹ï¼Œå› ä¸ºæœ‰ 12 ç§å¯èƒ½çš„ç»“æœï¼Œæ¯ç§ç»“æœçš„å¯èƒ½æ€§éƒ½ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The next section explains how use of the logistic function allows us to build logistic regression models that predict categorical target features.",
            "zh": "ä¸‹ä¸€èŠ‚å°†è§£é‡Šå¦‚ä½•ä½¿ç”¨ logistic å‡½æ•°æ¥æ„å»ºé¢„æµ‹åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Using the k-d tree that you created in the first part of this question, find the nearest neighbor to the following query: SIZE = 1,000, RENT = 2,200.",
            "zh": "ï¼ˆbï¼‰ ä½¿ç”¨æ‚¨åœ¨æœ¬é—®é¢˜ç¬¬ä¸€éƒ¨åˆ†ä¸­åˆ›å»ºçš„ k-d æ ‘ï¼Œæ‰¾åˆ°ä¸ä»¥ä¸‹æŸ¥è¯¢æœ€è¿‘çš„ç›¸é‚»é¡¹ï¼šSIZE = 1,000ï¼ŒRENT = 2,200ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data quality plan with potential handling strategies for the motor insurance fraud prediction ABT.",
            "zh": "å…·æœ‰æ½œåœ¨å¤„ç†ç­–ç•¥çš„æ•°æ®è´¨é‡è®¡åˆ’ï¼Œç”¨äºæ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "Although it is evident from the confusion matrix that the model could distinguish between the edge-on spiral galaxies and the other two types, it could not accurately distinguish between the clockwise and anti-clockwise spiral galaxies.",
            "zh": "è™½ç„¶ä»æ··æ·†çŸ©é˜µä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œè¯¥æ¨¡å‹å¯ä»¥åŒºåˆ†è¾¹ç¼˜èºæ—‹æ˜Ÿç³»å’Œå…¶ä»–ä¸¤ç§ç±»å‹ï¼Œä½†å®ƒæ— æ³•å‡†ç¡®åŒºåˆ†é¡ºæ—¶é’ˆå’Œé€†æ—¶é’ˆèºæ—‹æ˜Ÿç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.1â€…â€…â€…Big Idea",
            "zh": "6.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "In the first example, Figure 3.8(a)[73], a bar plot of the CAREER STAGE feature is shown above a 100% stacked bar plot showing how the levels of the SHOE SPONSOR feature are distributed in instances having each level of CAREER STAGE.",
            "zh": "åœ¨ç¬¬ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œå›¾ 3.8ï¼ˆaï¼‰[73]ï¼ŒCAREER STAGE ç‰¹å¾çš„æ¡å½¢å›¾æ˜¾ç¤ºåœ¨ 100% å †å æ¡å½¢å›¾ä¸Šæ–¹ï¼Œæ˜¾ç¤ºäº† SHOE SPONSOR ç‰¹å¾çš„çº§åˆ«åœ¨å…·æœ‰æ¯ä¸ª CAREER STAGE çº§åˆ«çš„å®ä¾‹ä¸­çš„åˆ†å¸ƒæƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "We already used Equation (6.19)[288] when we were making predictions for a naive Bayes classifier.",
            "zh": "å½“æˆ‘ä»¬å¯¹æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å·²ç»ä½¿ç”¨äº†æ–¹ç¨‹ï¼ˆ6.19ï¼‰[288]ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.5â€…â€…â€…Evaluation",
            "zh": "12.5 è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "8.4.5.4â€ƒPoolingâ€ƒThe precise location of a visual feature in an image may not be relevant for an image-processing task.",
            "zh": "8.4.5.4 æ± åŒ– å›¾åƒä¸­è§†è§‰ç‰¹å¾çš„ç²¾ç¡®ä½ç½®å¯èƒ½ä¸å›¾åƒå¤„ç†ä»»åŠ¡æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, we can read the relevant probability distribution for CPI directly from the CPT for the CPI node.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä» CPI èŠ‚ç‚¹çš„ CPT ä¸­è¯»å– CPI çš„ç›¸å…³æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In some of the literature on neural networks, the term logit is used to refer to the result of a weighted sum calculation in a neuron (i.e., the value we normally denote z).",
            "zh": "åœ¨ä¸€äº›å…³äºç¥ç»ç½‘ç»œçš„æ–‡çŒ®ä¸­ï¼Œæœ¯è¯­ logit ç”¨äºæŒ‡ä»£ç¥ç»å…ƒä¸­åŠ æƒå’Œè®¡ç®—çš„ç»“æœï¼ˆå³æˆ‘ä»¬é€šå¸¸è¡¨ç¤ºçš„å€¼ zï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these cases the insurance company goes through an expensive investigation process but still must make a reduced payment in relation to a claim.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä¿é™©å…¬å¸è¦ç»è¿‡æ˜‚è´µçš„è°ƒæŸ¥è¿‡ç¨‹ï¼Œä½†ä»ç„¶å¿…é¡»å‡å°‘ä¸ç´¢èµ”æœ‰å…³çš„ä»˜æ¬¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each image is labeled with the digit it contains, and the prediction task is to return the correct label for each image.",
            "zh": "æ¯ä¸ªå›¾åƒéƒ½ç”¨å®ƒåŒ…å«çš„æ•°å­—è¿›è¡Œæ ‡è®°ï¼Œé¢„æµ‹ä»»åŠ¡æ˜¯ä¸ºæ¯ä¸ªå›¾åƒè¿”å›æ­£ç¡®çš„æ ‡ç­¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "correlation matrix, 83",
            "zh": "ç›¸å…³çŸ©é˜µï¼Œ83"
        }
    },
    {
        "translation": {
            "en": "8.10â€…â€…â€…The per example error of the ReLU network after the forward pass illustrated in Figure 8.18[440], the per example âˆ‚â„°/âˆ‚a 8, and the sum of squared errors for the ReLU model.",
            "zh": "8.10 å›¾ 8.18[440] æ‰€ç¤ºçš„å‰å‘ä¼ é€’å ReLU ç½‘ç»œçš„æ¯ä¾‹è¯¯å·®ã€æ¯ä¾‹ âˆ‚E/âˆ‚a 8 ä»¥åŠ ReLU æ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.7",
            "zh": "å›¾ 13.7"
        }
    },
    {
        "translation": {
            "en": "3.10â€…â€…â€…Using box plots to visualize the relationships between categorical and continuous features from Table 3.7[73]: (a) and (b) show the relationship between the POSITION feature and the AGE feature; and (c) and (d) show the relationship between the POSITION feature and the HEIGHT feature.",
            "zh": "3.10 ä½¿ç”¨ç®±å½¢å›¾å¯è§†åŒ–è¡¨3.7[73]ä¸­çš„åˆ†ç±»ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼šï¼ˆaï¼‰å’Œï¼ˆbï¼‰æ˜¾ç¤ºPOSITIONç‰¹å¾ä¸AGEç‰¹å¾ä¹‹é—´çš„å…³ç³»;ï¼ˆcï¼‰å’Œï¼ˆdï¼‰æ˜¾ç¤ºäº†POSITIONç‰¹å¾å’ŒHEIGHTç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.7[277] illustrates this approximation.",
            "zh": "å›¾6.7[277]è¯´æ˜äº†è¿™ç§è¿‘ä¼¼å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first rule we will introduce defines conditional probability in terms of joint probability:",
            "zh": "æˆ‘ä»¬å°†ä»‹ç»çš„ç¬¬ä¸€æ¡è§„åˆ™æ ¹æ®è”åˆæ¦‚ç‡å®šä¹‰æ¡ä»¶æ¦‚ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "6.2â€…â€…â€…Fundamentals",
            "zh": "6.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "In order to evaluate which machine learning model to use as the pre-annotator filter, the company created a test set of 10 phrases extracted at random from the set of 50,000 candidates.",
            "zh": "ä¸ºäº†è¯„ä¼°ä½¿ç”¨å“ªç§æœºå™¨å­¦ä¹ æ¨¡å‹ä½œä¸ºé¢„æ³¨é‡Šå™¨è¿‡æ»¤å™¨ï¼Œè¯¥å…¬å¸åˆ›å»ºäº†ä¸€ä¸ªæµ‹è¯•é›†ï¼Œå…¶ä¸­åŒ…å«ä»50,000ä¸ªå€™é€‰è€…ä¸­éšæœºæå–çš„10ä¸ªçŸ­è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comment on the appropriateness of these outputs.",
            "zh": "è¯„è®ºè¿™äº›äº§å‡ºçš„é€‚å½“æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that both Neurons 3 and 4 have an activation of zero for d2.",
            "zh": "è¯·æ³¨æ„ï¼Œç¥ç»å…ƒ 3 å’Œ 4 å¯¹ d2 çš„æ¿€æ´»å‡ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The derivative of the rectifier function is:",
            "zh": "æ•´æµå™¨åŠŸèƒ½çš„å¯¼æ•°ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "It is particularly common to use deciles for this task.",
            "zh": "åœ¨æ­¤ä»»åŠ¡ä¸­ä½¿ç”¨ååˆ†ä½æ•°ç‰¹åˆ«å¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often the ROC curves for multiple predictive models will be plotted on a single ROC plot, allowing easy comparison of their performance.",
            "zh": "é€šå¸¸ï¼Œå¤šä¸ªé¢„æµ‹æ¨¡å‹çš„ ROC æ›²çº¿å°†ç»˜åˆ¶åœ¨å•ä¸ª ROC å›¾ä¸Šï¼Œä»¥ä¾¿è½»æ¾æ¯”è¾ƒå…¶æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if the network shown on the right of Figure 8.37[502] was applied only to a single input, then we would calculate the Î´s for the neurons in the output layer.47 and then backpropagate these Î´s to the hidden layer neurons.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœå›¾8.37[502]å³ä¾§æ˜¾ç¤ºçš„ç½‘ç»œä»…åº”ç”¨äºå•ä¸ªè¾“å…¥ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†è®¡ç®—è¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„Î´s.47ï¼Œç„¶åå°†è¿™äº›Î´åå‘ä¼ æ’­åˆ°éšè—å±‚ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that (1) the SDSS data that Jocelyn downloaded was already in a single table; (2) the data was already at the right prediction subject level (one row per galaxy); and (3) many of the columns in this dataset would most likely be used directly as features in the ABT that she was building, Jocelyn decided to produce a data quality report on this dataset.",
            "zh": "é‰´äº ï¼ˆ1ï¼‰ Jocelyn ä¸‹è½½çš„ SDSS æ•°æ®å·²ç»åœ¨å•ä¸ªè¡¨ä¸­;ï¼ˆ2ï¼‰æ•°æ®å·²ç»å¤„äºæ­£ç¡®çš„é¢„æµ‹ä¸»é¢˜æ°´å¹³ï¼ˆæ¯ä¸ªæ˜Ÿç³»ä¸€è¡Œï¼‰;ï¼ˆ3ï¼‰ è¯¥æ•°æ®é›†ä¸­çš„è®¸å¤šåˆ—å¾ˆå¯èƒ½ç›´æ¥ç”¨ä½œå¥¹æ­£åœ¨æ„å»ºçš„ ABT ä¸­çš„ç‰¹å¾ï¼ŒJocelyn å†³å®šç”Ÿæˆæœ‰å…³æ­¤æ•°æ®é›†çš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the query instances shown in the following table (question marks refer to missing values).",
            "zh": "ä½¿ç”¨æ­¤æ¨¡å‹å¯¹ä¸‹è¡¨ä¸­æ˜¾ç¤ºçš„æ¯ä¸ªæŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼ˆé—®å·æ˜¯æŒ‡ç¼ºå¤±å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.4.2â€ƒLogistic regressionâ€ƒTo build a logistic regression model, we threshold the output of the basic linear regression model using the logistic function. So, instead of the regression function simply being the dot product of the weights and the descriptive features (as given in Equation (7.9)[320]), the dot product of weights and descriptive feature values is passed through the logistic function",
            "zh": "7.4.4.2 é€»è¾‘å›å½’ ä¸ºäº†æ„å»ºé€»è¾‘å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨é€»è¾‘å‡½æ•°å¯¹åŸºæœ¬çº¿æ€§å›å½’æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œé˜ˆå€¼ã€‚å› æ­¤ï¼Œå›å½’å‡½æ•°ä¸æ˜¯ç®€å•åœ°æ˜¯æƒé‡å’Œæè¿°æ€§ç‰¹å¾çš„ç‚¹ç§¯ï¼ˆå¦‚å…¬å¼ï¼ˆ7.9ï¼‰[320]æ‰€ç¤ºï¼‰ï¼Œè€Œæ˜¯é€šè¿‡é€»è¾‘å‡½æ•°ä¼ é€’æƒé‡å’Œæè¿°æ€§ç‰¹å¾å€¼çš„ç‚¹ç§¯"
        }
    },
    {
        "translation": {
            "en": "For every step that the agent is firing one of its thrusters it receives a reward of âˆ’ 0.3.",
            "zh": "å¯¹äºæ™ºèƒ½ä½“å‘å°„å…¶æ¨è¿›å™¨çš„æ¯ä¸€æ­¥ï¼Œå®ƒéƒ½ä¼šè·å¾— âˆ’ 0.3 çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.12â€…â€…â€…A summary of the tasks in the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process.",
            "zh": "2.12 CRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£ã€æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µçš„ä»»åŠ¡æ‘˜è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because the instances in the validation set are not used during training, the error rate on the validation set provides a good estimate of the generalization capability of a decision tree.",
            "zh": "ç”±äºéªŒè¯é›†ä¸­çš„å®ä¾‹åœ¨è®­ç»ƒæœŸé—´æœªä½¿ç”¨ï¼Œå› æ­¤éªŒè¯é›†ä¸Šçš„é”™è¯¯ç‡å¯ä»¥å¾ˆå¥½åœ°ä¼°è®¡å†³ç­–æ ‘çš„æ³›åŒ–èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, as we move from one neuron to the next vertically, the receptive fields also move by one row in the input space.",
            "zh": "åŒæ ·ï¼Œå½“æˆ‘ä»¬ä»ä¸€ä¸ªç¥ç»å…ƒå‚ç›´ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªç¥ç»å…ƒæ—¶ï¼Œæ„Ÿå—é‡ä¹Ÿä¼šåœ¨è¾“å…¥ç©ºé—´ä¸­ç§»åŠ¨ä¸€è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Uppercase letters denote generic events where an unspecified feature (or set of features) is assigned a value (or set of values). Typically, we use letters from the end of the alphabetâ€”e.g., X, Y, Zâ€”for this purpose.",
            "zh": "å¤§å†™å­—æ¯è¡¨ç¤ºä¸ºæœªæŒ‡å®šè¦ç´ ï¼ˆæˆ–è¦ç´ é›†ï¼‰åˆ†é…ä¸€ä¸ªå€¼ï¼ˆæˆ–ä¸€ç»„å€¼ï¼‰çš„é€šç”¨äº‹ä»¶ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬ä½¿ç”¨å­—æ¯è¡¨æœ«å°¾çš„å­—æ¯ï¼ˆä¾‹å¦‚ Xã€Yã€Zï¼‰æ¥å®ç°æ­¤ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the arithmetic mean and median are two of the most commonly known such measures, there are more, including the harmonic mean.",
            "zh": "è™½ç„¶ç®—æœ¯å¹³å‡å€¼å’Œä¸­ä½æ•°æ˜¯ä¸¤ä¸ªæœ€å¸¸è§çš„æ­¤ç±»åº¦é‡ï¼Œä½†è¿˜æœ‰æ›´å¤šï¼ŒåŒ…æ‹¬è°æ³¢å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, in any neuron where the input to the rectifier function is greater than zero (z > 0) then the neuron will activate during the forward pass and the partial derivative of the activation function will be 1 during the backward pass.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œåœ¨ä»»ä½•æ•´æµå™¨å‡½æ•°çš„è¾“å…¥å¤§äºé›¶ï¼ˆz > 0ï¼‰çš„ç¥ç»å…ƒä¸­ï¼Œç¥ç»å…ƒå°†åœ¨æ­£å‘ä¼ é€’æœŸé—´æ¿€æ´»ï¼Œè€Œæ¿€æ´»å‡½æ•°çš„åå¯¼æ•°åœ¨å‘åä¼ é€’æœŸé—´å°†ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.4â€ƒA Worked Example",
            "zh": "7.3.4 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "We then do the forward and backward pass of the backpropagation and the weight update as usual for that example; the distinction is just that these processes will be run on the smaller network that remains after the selected neurons were dropped.",
            "zh": "ç„¶åï¼Œå¯¹äºè¯¥ç¤ºä¾‹ï¼Œæˆ‘ä»¬åƒå¾€å¸¸ä¸€æ ·è¿›è¡Œåå‘ä¼ æ’­çš„å‰å‘å’Œå‘åä¼ é€’ä»¥åŠæƒé‡æ›´æ–°;åŒºåˆ«ä»…åœ¨äºè¿™äº›è¿›ç¨‹å°†åœ¨é€‰å®šçš„ç¥ç»å…ƒè¢«ä¸¢å¼ƒåå‰©ä½™çš„è¾ƒå°ç½‘ç»œä¸Šè¿è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Fry, Ben. 2007. Visualizing data: Exploring and explaining data with the processing environment. Oâ€™Reilly Media.",
            "zh": "å¼—è±ï¼Œæœ¬ã€‚2007. å¯è§†åŒ–æ•°æ®ï¼šåœ¨å¤„ç†ç¯å¢ƒä¸­æ¢ç´¢å’Œè§£é‡Šæ•°æ®ã€‚O'Reilly åª’ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why, rather than just using the sum of the errors, we use the sum of the squared errors because this means all values will be positive.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸ä»…ä½¿ç”¨è¯¯å·®ä¹‹å’Œï¼Œè¿˜ä½¿ç”¨è¯¯å·®å¹³æ–¹ä¹‹å’Œï¼Œå› ä¸ºè¿™æ„å‘³ç€æ‰€æœ‰å€¼éƒ½æ˜¯æ­£æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "cell, 508",
            "zh": "ç»†èƒï¼Œ 508"
        }
    },
    {
        "translation": {
            "en": "The first consideration is data availability, because we must have data available to implement any feature we would like to use. For example, in an online payments service scenario, we might define a feature that calculates the average of a customerâ€™s account balance over the past six months. Unless the company maintains a historical record of account balances covering the full six-month period, however, it will not be possible to implement this feature.",
            "zh": "é¦–å…ˆè¦è€ƒè™‘çš„æ˜¯æ•°æ®å¯ç”¨æ€§ï¼Œå› ä¸ºæˆ‘ä»¬å¿…é¡»æœ‰å¯ç”¨çš„æ•°æ®æ¥å®ç°æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„ä»»ä½•åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨åœ¨çº¿æ”¯ä»˜æœåŠ¡åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªåŠŸèƒ½æ¥è®¡ç®—å®¢æˆ·è¿‡å»å…­ä¸ªæœˆçš„è´¦æˆ·ä½™é¢çš„å¹³å‡å€¼ã€‚ä½†æ˜¯ï¼Œé™¤éå…¬å¸ä¿ç•™æ¶µç›–æ•´ä¸ªå…­ä¸ªæœˆæœŸé—´çš„è´¦æˆ·ä½™é¢çš„å†å²è®°å½•ï¼Œå¦åˆ™å°†æ— æ³•å®ç°æ­¤åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "By having multiple such groups of neurons, in which each group contained neurons that specialized in identifying a particular visual feature and that as a whole inspected the entire visual field for the target feature, the cat was able to perceive multiple different features occurring at different locations at the same time.",
            "zh": "é€šè¿‡æ‹¥æœ‰å¤šä¸ªè¿™æ ·çš„ç¥ç»å…ƒç»„ï¼Œå…¶ä¸­æ¯ç»„éƒ½åŒ…å«ä¸“é—¨è¯†åˆ«ç‰¹å®šè§†è§‰ç‰¹å¾çš„ç¥ç»å…ƒï¼Œå¹¶ä¸”ä½œä¸ºä¸€ä¸ªæ•´ä½“æ£€æŸ¥ç›®æ ‡ç‰¹å¾çš„æ•´ä¸ªè§†é‡ï¼ŒçŒ«èƒ½å¤Ÿæ„ŸçŸ¥åŒæ—¶å‘ç”Ÿåœ¨ä¸åŒä½ç½®çš„å¤šä¸ªä¸åŒç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Perhaps the most important thing to remember in relation to correlation is that correlation does not necessarily imply causation.",
            "zh": "ä¹Ÿè®¸è¦è®°ä½çš„æœ€é‡è¦çš„äº‹æƒ…æ˜¯ï¼Œç›¸å…³æ€§å¹¶ä¸ä¸€å®šæ„å‘³ç€å› æœå…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the notation Ï†sm to denote the softmax activation function, Ï†sm(l) denotes applying the softmax function to the vector of logits l, and Ï†sm(li) refers to the calculation of the softmax value for the ith logit, that is, the output activation of the i neuron in the layer.",
            "zh": "ä½¿ç”¨ç¬¦å· Ï†sm è¡¨ç¤º softmax æ¿€æ´»å‡½æ•°ï¼ŒÏ†smï¼ˆlï¼‰ è¡¨ç¤ºå°† softmax å‡½æ•°åº”ç”¨äº logits l çš„å‘é‡ï¼ŒÏ†smï¼ˆliï¼‰ è¡¨ç¤ºè®¡ç®—ç¬¬ i ä¸ª logit çš„ softmax å€¼ï¼Œå³å±‚ä¸­ i ç¥ç»å…ƒçš„è¾“å‡ºæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, if on alternate evenings Conor swapped between choosing his favorite menu item and choosing a menu item at random (Îµ = 0.5), by the end of the two weeks he will have enjoyed a whole selection of meals from the hotel restaurantâ€™s dishes of chicken, beef, pork, mushrooms, and salmon.17",
            "zh": "å› æ­¤ï¼Œå¦‚æœåœ¨éš”å¤©æ™šä¸Šï¼Œåº·çº³åœ¨é€‰æ‹©ä»–æœ€å–œæ¬¢çš„èœå•é¡¹å’Œéšæœºé€‰æ‹©èœå•é¡¹ä¹‹é—´åˆ‡æ¢ï¼ˆÎµ = 0.5ï¼‰ï¼Œåˆ°ä¸¤å‘¨ç»“æŸæ—¶ï¼Œä»–å°†äº«å—åˆ°é…’åº—é¤å…çš„é¸¡è‚‰ã€ç‰›è‚‰ã€çŒªè‚‰ã€è˜‘è‡å’Œé²‘é±¼ç­‰å„ç§èœè‚´17ã€‚"
        }
    },
    {
        "translation": {
            "en": "where (d1,t1)â€¦(dn,tn) are n training instances, and di[j] is the jth descriptive feature of training instance (di,ti). The direction of the gradient calculated using this equation is toward the highest values on the error surface. The error delta function from Line 4[326] of Algorithm 4[326] should return a small step toward a lower value on the error surface. Therefore, we move in the opposite direction of the calculated gradient, and the error delta function can be written",
            "zh": "å…¶ä¸­ ï¼ˆd1ï¼Œt1ï¼‰...ï¼ˆdnï¼Œtnï¼‰ æ˜¯ n ä¸ªè®­ç»ƒå®ä¾‹ï¼Œdi[j] æ˜¯è®­ç»ƒå®ä¾‹ ï¼ˆdiï¼Œtiï¼‰ çš„ç¬¬ j ä¸ªæè¿°æ€§ç‰¹å¾ã€‚ä½¿ç”¨æ­¤æ–¹ç¨‹è®¡ç®—çš„æ¢¯åº¦æ–¹å‘æœå‘è¯¯å·®æ›²é¢ä¸Šçš„æœ€é«˜å€¼ã€‚ç®—æ³• 4[326] çš„ç¬¬ 4 è¡Œ [326] ä¸­çš„è¯¯å·®å¢é‡å‡½æ•°åº”è¿”å›ä¸€å°æ­¥ï¼Œæœç€è¯¯å·®é¢ä¸Šçš„è¾ƒä½å€¼è¿ˆè¿›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ²¿è®¡ç®—æ¢¯åº¦çš„ç›¸åæ–¹å‘ç§»åŠ¨ï¼Œå¯ä»¥å†™å‡ºè¯¯å·®å¢é‡å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "The ROC index can take values in the range [0,1] (although values less than 0.5 are unlikely and indicative of a target labeling error), and larger values indicate better model performance.",
            "zh": "ROC æŒ‡æ•°å¯ä»¥å– [0,1] èŒƒå›´å†…çš„å€¼ï¼ˆå°½ç®¡å°äº 0.5 çš„å€¼ä¸å¤ªå¯èƒ½ï¼Œå¹¶ä¸”æŒ‡ç¤ºç›®æ ‡æ ‡è®°é”™è¯¯ï¼‰ï¼Œè¾ƒå¤§çš„å€¼è¡¨ç¤ºæ›´å¥½çš„æ¨¡å‹æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the nearest neighbor algorithm stores the entire training dataset in memory has a negative effect on the time complexity of the algorithm.",
            "zh": "æœ€è¿‘é‚»ç®—æ³•å°†æ•´ä¸ªè®­ç»ƒæ•°æ®é›†å­˜å‚¨åœ¨å†…å­˜ä¸­è¿™ä¸€äº‹å®å¯¹ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦æœ‰è´Ÿé¢å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1â€…â€…â€…A dataset showing the positions and monthly training expenses of a school basketball team.",
            "zh": "A.1 æ˜¾ç¤ºå­¦æ ¡ç¯®çƒé˜Ÿçš„ä½ç½®å’Œæ¯æœˆè®­ç»ƒè´¹ç”¨çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 8.40[509] the cell is depicted by the line extending from ctâˆ’1 to ct across the top of the diagram.",
            "zh": "åœ¨å›¾8.40[509]ä¸­ï¼Œå•å…ƒæ ¼ç”±ä»ctâˆ’1å»¶ä¼¸åˆ°ctçš„çº¿ç©¿è¿‡å›¾çš„é¡¶éƒ¨è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table shows a small dataset used for human activity recognition from a wearable accelerometer sensor.16 Each instance describes the average acceleration in the X, Y, and Z directions within a short time window.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†ç”¨äºä»å¯ç©¿æˆ´åŠ é€Ÿåº¦è®¡ä¼ æ„Ÿå™¨è¯†åˆ«äººä½“æ´»åŠ¨çš„å°å‹æ•°æ®é›†ã€‚16 æ¯ä¸ªå®ä¾‹éƒ½æè¿°äº†çŸ­æ—¶é—´çª—å£å†… Xã€Y å’Œ Z æ–¹å‘çš„å¹³å‡åŠ é€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "1st New",
            "zh": "1st æ–°å“"
        }
    },
    {
        "translation": {
            "en": "Locating 25,630.3 on the horizontal axis shows that this upper threshold would cause a relatively large number of values to be changed.",
            "zh": "åœ¨æ°´å¹³è½´ä¸Šå®šä½ 25,630.3 è¡¨æ˜æ­¤ä¸Šé™é˜ˆå€¼å°†å¯¼è‡´ç›¸å¯¹è¾ƒå¤šçš„å€¼å‘ç”Ÿæ›´æ”¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This new node indexes d15.",
            "zh": "è¿™ä¸ªæ–°èŠ‚ç‚¹ç´¢å¼• d15ã€‚"
        }
    },
    {
        "translation": {
            "en": "stacked bar plot, 77",
            "zh": "å †å æ¡å½¢å›¾ï¼Œ77"
        }
    },
    {
        "translation": {
            "en": "Poll results from the run-up to the 2012 U.S. presidential election.",
            "zh": "2012å¹´ç¾å›½æ€»ç»Ÿå¤§é€‰å‰çš„æ°‘æ„è°ƒæŸ¥ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, as the number of features in the domain grows, the difference between the number of probabilities required for a factorized representation and the number of probabilities in the full joint probability distribution gets larger.",
            "zh": "å…¶æ¬¡ï¼Œéšç€åŸŸä¸­ç‰¹å¾æ•°é‡çš„å¢åŠ ï¼Œåˆ†è§£è¡¨ç¤ºæ‰€éœ€çš„æ¦‚ç‡æ•°ä¸å®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­çš„æ¦‚ç‡æ•°ä¹‹é—´çš„å·®å¼‚ä¼šå˜å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the assumed conditional independence between the features permits us to factorize the distribution and in doing so reduces the number of probabilities we need to calculate and store from the data.",
            "zh": "å› æ­¤ï¼Œç‰¹å¾ä¹‹é—´çš„å‡è®¾æ¡ä»¶ç‹¬ç«‹æ€§å…è®¸æˆ‘ä»¬å¯¹åˆ†å¸ƒè¿›è¡Œå› å¼åˆ†è§£ï¼Œä»è€Œå‡å°‘äº†æˆ‘ä»¬éœ€è¦ä»æ•°æ®ä¸­è®¡ç®—å’Œå­˜å‚¨çš„æ¦‚ç‡æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6.4â€ƒComparative experiments using a control groupâ€ƒAt the beginning of this chapter, we emphasized that it is important that the evaluation of prediction models not just focus on predictive power but also take into account the suitability of the model for the task to which it will be deployed.",
            "zh": "9.4.6.4 ä½¿ç”¨å¯¹ç…§ç»„çš„æ¯”è¾ƒå®éªŒ åœ¨æœ¬ç« å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬å¼ºè°ƒï¼Œé‡è¦çš„æ˜¯ï¼Œé¢„æµ‹æ¨¡å‹çš„è¯„ä¼°ä¸ä»…è¦å…³æ³¨é¢„æµ‹èƒ½åŠ›ï¼Œè¿˜è¦è€ƒè™‘æ¨¡å‹å¯¹å°†è¦éƒ¨ç½²çš„ä»»åŠ¡çš„é€‚ç”¨æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.40â€…â€…â€…A schematic of the internal structure of a long short-term memory unit.",
            "zh": "8.40 é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„å†…éƒ¨ç»“æ„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The categorical target feature, in particular, makes decision trees a suitable choice for this modeling task.",
            "zh": "ç‰¹åˆ«æ˜¯åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼Œä½¿å†³ç­–æ ‘æˆä¸ºæ­¤å»ºæ¨¡ä»»åŠ¡çš„åˆé€‚é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Astronomy has gone through a revolution in recent years as the reducing costs of digital imaging has made it possible to collect orders of magnitude more data than ever before.",
            "zh": "è¿‘å¹´æ¥ï¼Œå¤©æ–‡å­¦ç»å†äº†ä¸€åœºé©å‘½ï¼Œå› ä¸ºæ•°å­—æˆåƒæˆæœ¬çš„é™ä½ä½¿å¾—æ”¶é›†çš„æ•°æ®æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "6.12â€…â€…â€…Partitioning the dataset based on the value of the target feature and fitting the parameters of a statistical distribution to model the ACCOUNT BALANCE feature in each partition.",
            "zh": "6.12 æ ¹æ®ç›®æ ‡ç‰¹å¾çš„å€¼å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºï¼Œå¹¶æ‹Ÿåˆç»Ÿè®¡åˆ†å¸ƒçš„å‚æ•°ï¼Œä»¥å¯¹æ¯ä¸ªåˆ†åŒºä¸­çš„ ACCOUNT BALANCE ç‰¹å¾è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "R2, 578, 586",
            "zh": "R2ã€578ã€586"
        }
    },
    {
        "translation": {
            "en": "If, however, a graph is composed of a number of clusters connected via bottleneck nodes, this would typically indicate a longer mixing time.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœä¸€ä¸ªå›¾ç”±è®¸å¤šé€šè¿‡ç“¶é¢ˆèŠ‚ç‚¹è¿æ¥çš„é›†ç¾¤ç»„æˆï¼Œè¿™é€šå¸¸è¡¨æ˜æ··åˆæ—¶é—´æ›´é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, using this regime also allowed us to highlight some of the problems that arise when weights are set naively, such as the problem of vanishing gradients, and dead neurons.",
            "zh": "ç„¶è€Œï¼Œä½¿ç”¨è¿™ç§æœºåˆ¶ä¹Ÿä½¿æˆ‘ä»¬èƒ½å¤Ÿçªå‡ºä¸€äº›åœ¨å¤©çœŸåœ°è®¾ç½®æƒé‡æ—¶å‡ºç°çš„é—®é¢˜ï¼Œä¾‹å¦‚æ¢¯åº¦æ¶ˆå¤±å’Œç¥ç»å…ƒæ­»äº¡çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, Jocelyn had put the SDSS data through a preprocessing step, standardizing all descriptive features.",
            "zh": "é¦–å…ˆï¼ŒJocelyn å¯¹ SDSS æ•°æ®è¿›è¡Œäº†é¢„å¤„ç†ï¼Œå°†æ‰€æœ‰æè¿°æ€§ç‰¹å¾æ ‡å‡†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "bag-of-words, 223, 236",
            "zh": "è¯è¢‹ï¼Œ223,236"
        }
    },
    {
        "translation": {
            "en": "The final ABT contained 10,000 instances equally split between customers who churned and customers who did not churn.",
            "zh": "æœ€ç»ˆçš„ ABT åŒ…å« 10,000 ä¸ªå®ä¾‹ï¼Œåœ¨æµå¤±çš„å®¢æˆ·å’Œæœªæµå¤±çš„å®¢æˆ·ä¹‹é—´å¹³å‡åˆ†é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4.4â€…â€…â€…Tree Pruning",
            "zh": "4.4.4 æ ‘æœ¨ä¿®å‰ª"
        }
    },
    {
        "translation": {
            "en": "In that section we also explained that most practitioners use rules of thumb and trial and error to set the learning rate.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¿˜è§£é‡Šäº†å¤§å¤šæ•°ä»ä¸šè€…ä½¿ç”¨ç»éªŒæ³•åˆ™å’Œåå¤è¯•éªŒæ¥è®¾å®šå­¦ä¹ ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the goal in the insurance claim fraud scenario we have been considering is to make predictions about whether an insurance claim will turn out to be fraudulent after investigation based on the details of the claim itself and the details of the claimantâ€™s behavior in the time preceding the claim.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨è€ƒè™‘çš„ä¿é™©ç´¢èµ”æ¬ºè¯ˆåœºæ™¯ä¸­çš„ç›®æ ‡æ˜¯æ ¹æ®ç´¢èµ”æœ¬èº«çš„ç»†èŠ‚å’Œç´¢èµ”äººåœ¨ç´¢èµ”å‰ä¸€æ®µæ—¶é—´çš„è¡Œä¸ºç»†èŠ‚ï¼Œé¢„æµ‹ä¿é™©ç´¢èµ”åœ¨è°ƒæŸ¥åæ˜¯å¦ä¼šè¢«è¯æ˜æ˜¯æ¬ºè¯ˆæ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "di[j] denotes the value of the jth descriptive feature of the ith instance in a dataset.",
            "zh": "di[j] è¡¨ç¤ºæ•°æ®é›†ä¸­ç¬¬ i ä¸ªå®ä¾‹çš„ç¬¬ j ä¸ªæè¿°æ€§ç‰¹å¾çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example the actual population of interest was the voting population of the United States, which was approximately 240,926,957 people.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ„Ÿå…´è¶£çš„å®é™…äººå£æ˜¯ç¾å›½çš„æŠ•ç¥¨äººå£ï¼Œçº¦ä¸º 240,926,957 äººã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of soft tissue injury claims the claimant has made in the past and the ratio between the number of soft tissue injury claims and other claims made by the claimant are both included as descriptive features in the ABT.",
            "zh": "ç´¢èµ”äººè¿‡å»æå‡ºçš„è½¯ç»„ç»‡æŸä¼¤ç´¢èµ”æ•°é‡ä»¥åŠè½¯ç»„ç»‡æŸä¼¤ç´¢èµ”æ•°é‡ä¸ç´¢èµ”äººæå‡ºçš„å…¶ä»–ç´¢èµ”æ•°é‡ä¹‹é—´çš„æ¯”ç‡å‡ä½œä¸ºæè¿°æ€§ç‰¹å¾åˆ—å…¥ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "A scalar is a single number.",
            "zh": "æ ‡é‡æ˜¯ä¸€ä¸ªæ•°å­—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The parameter Î» is learned in tandem with the weights of the network. Similar to the weights of the network, the Î» parameter is initialized to a value and is then iteratively updated as training progresses. In their experiments He et al. (2015) initialized the Î» parameters in their networks to 0.25. Also similar to the weights in a network, the updating of a Î» is proportional to the error gradient of the network with respect to changes in that parameter",
            "zh": "å‚æ•° Î» ä¸ç½‘ç»œçš„æƒé‡ä¸€èµ·å­¦ä¹ ã€‚ä¸ç½‘ç»œçš„æƒé‡ç±»ä¼¼ï¼ŒÎ» å‚æ•°è¢«åˆå§‹åŒ–ä¸ºä¸€ä¸ªå€¼ï¼Œç„¶åéšç€è®­ç»ƒçš„è¿›è¡Œè¿›è¡Œè¿­ä»£æ›´æ–°ã€‚åœ¨ä»–ä»¬çš„å®éªŒä¸­ï¼ŒHeç­‰äººï¼ˆ2015ï¼‰å°†ç½‘ç»œä¸­çš„Î»å‚æ•°åˆå§‹åŒ–ä¸º0.25ã€‚ä¸ç½‘ç»œä¸­çš„æƒé‡ç±»ä¼¼ï¼ŒÎ» çš„æ›´æ–°ä¸ç½‘ç»œç›¸å¯¹äºè¯¥å‚æ•°å˜åŒ–çš„è¯¯å·®æ¢¯åº¦æˆæ­£æ¯”"
        }
    },
    {
        "translation": {
            "en": "The matrix labeled Input Layer contains the inputs for the examples, augmented with the bias inputs for each neuron.",
            "zh": "æ ‡è®°ä¸ºè¾“å…¥å±‚çš„çŸ©é˜µåŒ…å«ç¤ºä¾‹çš„è¾“å…¥ï¼Œå¹¶ç”¨æ¯ä¸ªç¥ç»å…ƒçš„åå·®è¾“å…¥è¿›è¡Œå¢å¼ºã€‚"
        }
    },
    {
        "translation": {
            "en": "8. Francis Anscombe was a famous statistician who published his quartet in 1973 (Anscombe, 1973).",
            "zh": "8. å¼—æœ—è¥¿æ–¯Â·å®‰æ–¯ç§‘å§†ï¼ˆFrancis Anscombeï¼‰æ˜¯ä¸€ä½è‘—åçš„ç»Ÿè®¡å­¦å®¶ï¼Œä»–äº1973å¹´å‡ºç‰ˆäº†ä»–çš„å››é‡å¥ï¼ˆAnscombeï¼Œ1973ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.6[393] illustrates how the same sequence of operations shown in Figure 8.5[392] to process one example can be used to enable the same network to process four examples in parallel.",
            "zh": "å›¾ 8.6[393] è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨å›¾ 8.5[392] ä¸­æ‰€ç¤ºçš„ç›¸åŒæ“ä½œåºåˆ—æ¥å¤„ç†ä¸€ä¸ªç¤ºä¾‹ï¼Œä»¥ä½¿åŒä¸€ç½‘ç»œèƒ½å¤Ÿå¹¶è¡Œå¤„ç†å››ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, as networks become deeper they can become more difficult to train.",
            "zh": "ç„¶è€Œï¼Œéšç€ç½‘ç»œå˜å¾—è¶Šæ¥è¶Šæ·±ï¼Œå®ƒä»¬å¯èƒ½ä¼šå˜å¾—æ›´åŠ éš¾ä»¥è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The drawback of batch gradient descent is that the entire dataset must be processed between each weight update.",
            "zh": "æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„ç¼ºç‚¹æ˜¯å¿…é¡»åœ¨æ¯æ¬¡æƒé‡æ›´æ–°ä¹‹é—´å¤„ç†æ•´ä¸ªæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Error-based learning (Chapter 7[311])",
            "zh": "åŸºäºé”™è¯¯çš„å­¦ä¹ ï¼ˆç¬¬7ç« [311]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Edwin was broadly in agreement with the set of domain concepts that Jocelyn had developed and was very positive about the use of Galaxy Zoo classifications as a source for generating the target feature.",
            "zh": "Edwin å¤§ä½“ä¸ŠåŒæ„ Jocelyn å¼€å‘çš„ä¸€ç»„é¢†åŸŸæ¦‚å¿µï¼Œå¹¶ä¸”éå¸¸ç§¯æåœ°ä½¿ç”¨ Galaxy Zoo åˆ†ç±»ä½œä¸ºç”Ÿæˆç›®æ ‡ç‰¹å¾çš„æ¥æºã€‚"
        }
    },
    {
        "translation": {
            "en": "deep Q network, 637, 664, 671, 673, 676",
            "zh": "æ·±Qç½‘ç»œï¼Œ 637ï¼Œ 664ï¼Œ 671ï¼Œ 673ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "10.6â€…â€…â€…(a) Intra-cluster distance; (b) inter-cluster distance; (c) a good clustering; and (d) a bad clustering.",
            "zh": "10.6 ï¼ˆaï¼‰ é›†ç¾¤å†…è·ç¦»;ï¼ˆbï¼‰ é›†ç¾¤é—´è·ç¦»;ï¼ˆcï¼‰ è‰¯å¥½çš„èšç±»;ï¼ˆdï¼‰èšç±»ä¸è‰¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The particular choices of filter size, stride length, and padding is task dependent.",
            "zh": "æ»¤é•œå¤§å°ã€æ­¥å¹…å’Œå¡«å……çš„ç‰¹å®šé€‰æ‹©å–å†³äºä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure, the activation flow through the gates is ordered vertically: the top row of the figure illustrates the flow through the forget gate; the next two rows illustrate the flow through the two paths of the input gate; and the bottom two rows illustrate the flow through the two paths of the output gate.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œé€šè¿‡é—¸é—¨çš„æ¿€æ´»æµæ˜¯å‚ç›´æ’åºçš„ï¼šå›¾çš„é¡¶è¡Œè¯´æ˜äº†é€šè¿‡é—å¿˜é—¸é—¨çš„æµ;æ¥ä¸‹æ¥çš„ä¸¤è¡Œè¯´æ˜äº†é€šè¿‡è¾“å…¥é—¨çš„ä¸¤æ¡è·¯å¾„çš„æµé‡;åº•éƒ¨ä¸¤è¡Œè¡¨ç¤ºé€šè¿‡è¾“å‡ºé—¨çš„ä¸¤æ¡è·¯å¾„çš„æµé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The age of the customerâ€™s current handset",
            "zh": "å®¢æˆ·å½“å‰æ‰‹æœºçš„ä½¿ç”¨å¹´é™"
        }
    },
    {
        "translation": {
            "en": "Is it better for a genuine email to be marked as spam and deleted, or for a spam email to end up in our in-box?",
            "zh": "æ˜¯å°†çœŸæ­£çš„ç”µå­é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶å¹¶åˆ é™¤ï¼Œè¿˜æ˜¯å°†åƒåœ¾é‚®ä»¶æœ€ç»ˆå‘é€åˆ°æˆ‘ä»¬çš„æ”¶ä»¶ç®±æ›´å¥½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "multivariable, 319",
            "zh": "å¤šå˜é‡ï¼Œ319"
        }
    },
    {
        "translation": {
            "en": "With that caveat regarding bias terms stated, we return to the question of why non-linear activation functions are necessary in a neural network. It turns out that understanding that a neural network can be implemented as a sequence of matrix multiplications with the non-linearity of the activation functions introduced between the matrix multiplications can help answer this question.",
            "zh": "åœ¨å¯¹åå·®é¡¹æå‡ºè­¦å‘Šä¹‹åï¼Œæˆ‘ä»¬å›åˆ°ä¸ºä»€ä¹ˆéçº¿æ€§æ¿€æ´»å‡½æ•°åœ¨ç¥ç»ç½‘ç»œä¸­æ˜¯å¿…è¦çš„é—®é¢˜ã€‚äº‹å®è¯æ˜ï¼Œç†è§£ç¥ç»ç½‘ç»œå¯ä»¥å®ç°ä¸ºçŸ©é˜µä¹˜æ³•åºåˆ—ï¼ŒçŸ©é˜µä¹˜æ³•ä¹‹é—´å¼•å…¥çš„æ¿€æ´»å‡½æ•°çš„éçº¿æ€§å¯ä»¥å¸®åŠ©å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Assign each instance to its nearest cluster to generate the clustering at the first iteration of k-means on the basis of the initial cluster centroids.",
            "zh": "ï¼ˆaï¼‰ å°†æ¯ä¸ªå®ä¾‹åˆ†é…åˆ°å…¶æœ€è¿‘çš„èšç±»ï¼Œä»¥åœ¨åŸºäºåˆå§‹èšç±»è´¨å¿ƒçš„ k å‡å€¼çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ç”Ÿæˆèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Linear algebra is an important topic in machine learning.",
            "zh": "çº¿æ€§ä»£æ•°æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªé‡è¦ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are not massively different from the values calculated using root mean squared error.",
            "zh": "è¿™äº›å€¼ä¸ä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®è®¡ç®—çš„å€¼æ²¡æœ‰å¤ªå¤§å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weights used by this ReLU are shown on the edges feeding into the unit.",
            "zh": "è¯¥ ReLU ä½¿ç”¨çš„ç ç æ˜¾ç¤ºåœ¨é€å…¥è£…ç½®çš„è¾¹ç¼˜ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "We can, however, use the values in the profit matrix to calculate the overall profit associated with the predictions made by these two models.",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ©æ¶¦çŸ©é˜µä¸­çš„å€¼æ¥è®¡ç®—ä¸è¿™ä¸¤ä¸ªæ¨¡å‹æ‰€åšçš„é¢„æµ‹ç›¸å…³çš„æ€»åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "To make this decision, we partition the training data based on the target feature and generate histograms of the values of the descriptive feature for each of the splits.",
            "zh": "ä¸ºäº†åšå‡ºè¿™ä¸ªå†³å®šï¼Œæˆ‘ä»¬æ ¹æ®ç›®æ ‡ç‰¹å¾å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ†åŒºï¼Œå¹¶ä¸ºæ¯ä¸ªæ‹†åˆ†ç”Ÿæˆæè¿°æ€§ç‰¹å¾å€¼çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "MontÃºfar, Guido. 2014. Universal approximation depth and errors of narrow belief networks with discrete units. Neural Computation 26 (7): 1386â€“1407.",
            "zh": "è’™å›¾æ³•å°”ï¼Œåœ­å¤šã€‚2014. å…·æœ‰ç¦»æ•£å•å…ƒçš„ç‹­ä¹‰ä¿¡å¿µç½‘ç»œçš„æ™®éè¿‘ä¼¼æ·±åº¦å’Œè¯¯å·®.ç¥ç»è®¡ç®— 26 ï¼ˆ7ï¼‰ï¼š1386â€“1407ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Claim Details domain concept, for example, highlights the importance of the details of the claim itself in distinguishing between fraudulent and genuine claims.",
            "zh": "ä¾‹å¦‚ï¼Œâ€œæƒåˆ©è¦æ±‚è¯¦ç»†ä¿¡æ¯â€åŸŸæ¦‚å¿µå¼ºè°ƒäº†æƒåˆ©è¦æ±‚æœ¬èº«çš„è¯¦ç»†ä¿¡æ¯åœ¨åŒºåˆ†æ¬ºè¯ˆæ€§æƒåˆ©è¦æ±‚å’ŒçœŸå®æƒåˆ©è¦æ±‚æ–¹é¢çš„é‡è¦æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The initial cluster centroids for the two clusters 1 and 2 are c1 = âˆ’0.235,0.253,0.438 and c2 = 0.232,0.325,âˆ’0.159.",
            "zh": "ä¸¤ä¸ªèšç±» 1 å’Œ 2 çš„åˆå§‹èšç±»è´¨å¿ƒä¸º c1 = âˆ’0.235,0.253,0.438 å’Œ c2 = 0.232,0.325ï¼Œâˆ’0.159ã€‚"
        }
    },
    {
        "translation": {
            "en": "After dividing the dataset into groups, the number of instances in the largest group becomes the over-sampling target size.",
            "zh": "å°†æ•°æ®é›†åˆ’åˆ†ä¸ºç»„åï¼Œæœ€å¤§ç»„ä¸­çš„å®ä¾‹æ•°æˆä¸ºè¿‡é‡‡æ ·ç›®æ ‡å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_G_R",
            "zh": "PETROMAGDIFF_G_R"
        }
    },
    {
        "translation": {
            "en": "whiskers, 755",
            "zh": "æ™¶é¡»ï¼Œ755"
        }
    },
    {
        "translation": {
            "en": "Table 9.20",
            "zh": "è¡¨ 9.20"
        }
    },
    {
        "translation": {
            "en": "Once the number of bins, b, has been chosen, the equal-width binning algorithm splits the range of the feature values into b bins each of size . For example, if the values for a feature fell between zero and 100 and we wished to have 10 bins, then bin 1 would cover the interval12 [0,10), bin 2 would cover the interval [10,20), and so on, up to bin 10, which would cover the interval [90,100]. Consequently, an instance with a feature value of 18 would be placed into bin 2.",
            "zh": "é€‰æ‹©ç®±æ•° b åï¼Œç­‰å®½åˆ†ç®±ç®—æ³•å°†ç‰¹å¾å€¼çš„èŒƒå›´æ‹†åˆ†ä¸º b ç®±ï¼Œæ¯ä¸ªç®±çš„å¤§å°ä¸º ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªç‰¹å¾çš„å€¼ä»‹äº 0 å’Œ 100 ä¹‹é—´ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›æœ‰ 10 ä¸ªç®±ï¼Œåˆ™ç®± 1 å°†è¦†ç›–åŒºé—´ 12 [0,10]ï¼Œç®± 2 å°†è¦†ç›–åŒºé—´ [10,20]ï¼Œä¾æ­¤ç±»æ¨ï¼Œç›´åˆ°ç®± 10ï¼Œå®ƒå°†è¦†ç›–åŒºé—´ [90,100]ã€‚å› æ­¤ï¼Œç‰¹å¾å€¼ä¸º 18 çš„å®ä¾‹å°†è¢«æ”¾å…¥ bin 2 ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Categorical Targets In the context of handling categorical target features (see Section 8.4.3[463]) using a softmax function, we use the following symbols:",
            "zh": "åˆ†ç±»ç›®æ ‡ åœ¨ä½¿ç”¨ softmax å‡½æ•°å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆå‚è§ Section 8.4.3[463]ï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ç¬¦å·ï¼š"
        }
    },
    {
        "translation": {
            "en": "The distances calculated using only the SALARY feature are almost exactly the same as the distances calculated using both the SALARY and AGE features.",
            "zh": "ä»…ä½¿ç”¨ SALARY ç‰¹å¾è®¡ç®—çš„è·ç¦»ä¸ä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾è®¡ç®—çš„è·ç¦»å‡ ä¹å®Œå…¨ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.6â€…â€…â€…Feature Selection",
            "zh": "5.4.6 åŠŸèƒ½é€‰æ‹©"
        }
    },
    {
        "translation": {
            "en": "6.4.4.2â€ƒUsing a Bayesian network to make predictionsâ€ƒOnce a network has been created, it is relatively straightforward to use to make a prediction. We simply compute the probability distribution for the target feature conditioned on the state of the descriptive features in the query and return the target feature level with the maximum a posteriori probability:",
            "zh": "6.4.4.2 ä½¿ç”¨è´å¶æ–¯ç½‘ç»œè¿›è¡Œé¢„æµ‹ ä¸€æ—¦åˆ›å»ºäº†ç½‘ç»œï¼Œå°±å¯ä»¥ç›¸å¯¹ç®€å•åœ°ä½¿ç”¨å®ƒè¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬åªéœ€æ ¹æ®æŸ¥è¯¢ä¸­æè¿°æ€§ç‰¹å¾çš„çŠ¶æ€è®¡ç®—ç›®æ ‡ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶è¿”å›å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç›®æ ‡ç‰¹å¾çº§åˆ«ï¼š"
        }
    },
    {
        "translation": {
            "en": "cubic clustering criterion, 609",
            "zh": "ä¸‰æ¬¡èšç±»å‡†åˆ™ï¼Œ609"
        }
    },
    {
        "translation": {
            "en": "The bulk of this chapter discusses these different approaches and the kinds of modeling tasks that they best suit.",
            "zh": "æœ¬ç« çš„å¤§éƒ¨åˆ†å†…å®¹å°†è®¨è®ºè¿™äº›ä¸åŒçš„æ–¹æ³•ä»¥åŠå®ƒä»¬æœ€é€‚åˆçš„å»ºæ¨¡ä»»åŠ¡ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The two plots on the right show the distributions for those players with and without a shoe sponsor.",
            "zh": "å³è¾¹çš„ä¸¤å¼ å›¾æ˜¾ç¤ºäº†æœ‰å’Œæ²¡æœ‰çƒé‹èµåŠ©å•†çš„çƒå‘˜çš„åˆ†å¸ƒæƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "We will not discuss these topics here.",
            "zh": "æˆ‘ä»¬ä¸ä¼šåœ¨è¿™é‡Œè®¨è®ºè¿™äº›è¯é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Using equal-frequency binning, transform the AGE feature into a categorical feature with three levels: young, middle-aged, mature.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨ç­‰é¢‘åˆ†ç®±ï¼Œå°† AGE ç‰¹å¾è½¬æ¢ä¸ºå…·æœ‰ä¸‰ä¸ªçº§åˆ«çš„åˆ†ç±»ç‰¹å¾ï¼šå¹´è½»ã€ä¸­å¹´ã€æˆç†Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "The player has just three controls: thrusters that turn the spacecraft left and right, and one that pushes it up.",
            "zh": "ç©å®¶åªæœ‰ä¸‰ä¸ªæ§åˆ¶ï¼šå·¦å³è½¬åŠ¨èˆªå¤©å™¨çš„æ¨è¿›å™¨ï¼Œä»¥åŠä¸€ä¸ªæ¨åŠ¨å®ƒå‘ä¸Šçš„æ¨è¿›å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instance d6 has a target value of yes, and this is why the model will return a positive prediction for the query.",
            "zh": "å®ä¾‹ d6 çš„ç›®æ ‡å€¼ä¸º yesï¼Œè¿™å°±æ˜¯æ¨¡å‹å°†è¿”å›æŸ¥è¯¢çš„æ­£é¢„æµ‹çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "When time is a factor in a scenario, the descriptive features and the target feature will not necessarily both be time dependent. In some cases only the descriptive features have a time component to them, and the target feature is time independent. Conversely, the target feature may have a time component and the descriptive features may not.",
            "zh": "å½“æ—¶é—´æ˜¯åœºæ™¯ä¸­çš„ä¸€ä¸ªå› ç´ æ—¶ï¼Œæè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¸ä¸€å®šéƒ½ä¸æ—¶é—´ç›¸å…³ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œåªæœ‰æè¿°æ€§ç‰¹å¾å…·æœ‰æ—¶é—´åˆ†é‡ï¼Œè€Œç›®æ ‡ç‰¹å¾ä¸æ—¶é—´æ— å…³ã€‚ç›¸åï¼Œç›®æ ‡ç‰¹å¾å¯èƒ½å…·æœ‰æ—¶é—´åˆ†é‡ï¼Œè€Œæè¿°æ€§ç‰¹å¾å¯èƒ½æ²¡æœ‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, we use the 6-by-6 matrix grayscale encoding of a 4, shown in Equation (8.84)[478] as the input pattern for our examples",
            "zh": "å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¼ï¼ˆ8.84ï¼‰[478]ä¸­æ‰€ç¤ºçš„4çš„6Ã—6çŸ©é˜µç°åº¦ç¼–ç ä½œä¸ºç¤ºä¾‹çš„è¾“å…¥æ¨¡å¼"
        }
    },
    {
        "translation": {
            "en": "The action-value target network is frozen and not updated at each iteration of the algorithm.",
            "zh": "åŠ¨ä½œå€¼ç›®æ ‡ç½‘ç»œè¢«å†»ç»“ï¼Œå¹¶ä¸”åœ¨ç®—æ³•çš„æ¯æ¬¡è¿­ä»£æ—¶éƒ½ä¸ä¼šæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, when we are dealing with large datasets, it is likely that there is noise3 in the data, and prediction models that are consistent with noisy data make incorrect predictions.",
            "zh": "é¦–å…ˆï¼Œå½“æˆ‘ä»¬å¤„ç†å¤§å‹æ•°æ®é›†æ—¶ï¼Œæ•°æ®ä¸­å¾ˆå¯èƒ½å­˜åœ¨å™ªå£°3ï¼Œä¸å™ªå£°æ•°æ®ä¸€è‡´çš„é¢„æµ‹æ¨¡å‹ä¼šåšå‡ºé”™è¯¯çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This figure was inspired by Figure 4.2 in (Reed and Marks, 1999) and Figure 3.10 in (Marsland, 2011).",
            "zh": "è¿™ä¸ªæ•°å­—çš„çµæ„Ÿæ¥è‡ªå›¾4.2ï¼ˆReedå’ŒMarksï¼Œ1999ï¼‰å’Œå›¾3.10ï¼ˆMarslandï¼Œ2011ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we dropped the d[0] dummy feature and then multiplied each of the real descriptive features by a weight and summed the results, we would be applying a linear function to the inputs.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å»æ‰ d[0] è™šæ‹Ÿç‰¹å¾ï¼Œç„¶åå°†æ¯ä¸ªçœŸå®çš„æè¿°æ€§ç‰¹å¾ä¹˜ä»¥ä¸€ä¸ªæƒé‡å¹¶å°†ç»“æœç›¸åŠ ï¼Œæˆ‘ä»¬å°†å¯¹è¾“å…¥åº”ç”¨çº¿æ€§å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that a nearest neighbor model may not be appropriate in domains where speed of prediction is of the essence.",
            "zh": "è¿™æ„å‘³ç€æœ€è¿‘é‚»æ¨¡å‹å¯èƒ½ä¸é€‚åˆé¢„æµ‹é€Ÿåº¦è‡³å…³é‡è¦çš„é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23",
            "zh": "å›¾ 7.23"
        }
    },
    {
        "translation": {
            "en": "This introduction is focused primarily on supporting your understanding of the content in this book, in particular the chapter on deep learning, rather than on providing a comprehensive introduction to linear algebra.",
            "zh": "æœ¬ä»‹ç»ä¸»è¦ä¾§é‡äºæ”¯æŒæ‚¨ç†è§£æœ¬ä¹¦çš„å†…å®¹ï¼Œç‰¹åˆ«æ˜¯å…³äºæ·±åº¦å­¦ä¹ çš„ç« èŠ‚ï¼Œè€Œä¸æ˜¯æä¾›çº¿æ€§ä»£æ•°çš„å…¨é¢ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The ROC index is insensitive to changes in class distribution within the test set. This means that if the proportion of positive to negative instances changes in a test set, the ROC index will remain the same if the performance of the models on each class is constant. Consequently, the ROC index is robust to class imbalance or skew in the test set. Why do you think this is the case?26",
            "zh": "ï¼ˆcï¼‰ ROCæŒ‡æ•°å¯¹æµ‹è¯•é›†ä¸­ç±»åˆ«åˆ†å¸ƒçš„å˜åŒ–ä¸æ•æ„Ÿã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæµ‹è¯•é›†ä¸­æ­£å®ä¾‹ä¸è´Ÿå®ä¾‹çš„æ¯”ä¾‹å‘ç”Ÿå˜åŒ–ï¼Œåˆ™å¦‚æœæ¨¡å‹åœ¨æ¯ä¸ªç±»ä¸Šçš„æ€§èƒ½ä¿æŒä¸å˜ï¼Œåˆ™ ROC æŒ‡æ•°å°†ä¿æŒä¸å˜ã€‚å› æ­¤ï¼ŒROC æŒ‡æ•°å¯¹æµ‹è¯•é›†ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡æˆ–åæ–œå…·æœ‰é²æ£’æ€§ã€‚ä½ è®¤ä¸ºä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ26"
        }
    },
    {
        "translation": {
            "en": "The statistics outlined in the previous section work well to describe continuous features, but they do not work for categorical features.",
            "zh": "ä¸Šä¸€èŠ‚ä¸­æ¦‚è¿°çš„ç»Ÿè®¡é‡é€‚ç”¨äºæè¿°è¿ç»­è¦ç´ ï¼Œä½†ä¸é€‚ç”¨äºåˆ†ç±»è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this situation, the observation period for all the prediction subjects, in this case, customers, might be defined as the six months prior to the launch of the new product, and the outcome period might cover the three months after the launch.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰é¢„æµ‹å¯¹è±¡ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºå®¢æˆ·ï¼‰çš„è§‚å¯ŸæœŸå¯èƒ½å®šä¹‰ä¸ºæ–°äº§å“å‘å¸ƒå‰çš„å…­ä¸ªæœˆï¼Œç»“æœæœŸå¯èƒ½æ¶µç›–å‘å¸ƒåçš„ä¸‰ä¸ªæœˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Designing solutions based on unsupervised machine learning techniques can be more creative than designing solutions based on supervised learning because the solutions tend not to follow quite so obvious a pattern.",
            "zh": "åŸºäºæ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯è®¾è®¡è§£å†³æ–¹æ¡ˆå¯èƒ½æ¯”åŸºäºç›‘ç£å­¦ä¹ è®¾è®¡è§£å†³æ–¹æ¡ˆæ›´å…·åˆ›é€ æ€§ï¼Œå› ä¸ºè§£å†³æ–¹æ¡ˆå¾€å¾€ä¸éµå¾ªå¦‚æ­¤æ˜æ˜¾çš„æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Grace explained to Ross that incomes were actually recorded in bands rather than as exact values, so this was really a categorical feature.",
            "zh": "æ ¼è•¾ä¸å‘ç½—æ–¯è§£é‡Šè¯´ï¼Œæ”¶å…¥å®é™…ä¸Šæ˜¯ä»¥æ³¢æ®µè®°å½•çš„ï¼Œè€Œä¸æ˜¯ä½œä¸ºç²¾ç¡®å€¼è®°å½•çš„ï¼Œæ‰€ä»¥è¿™ç¡®å®æ˜¯ä¸€ä¸ªåˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When padding is applied it is generally added to all edges as equally as is possible.",
            "zh": "åº”ç”¨å¡«å……æ—¶ï¼Œé€šå¸¸ä¼šå°½å¯èƒ½å¹³å‡åœ°å°†å…¶æ·»åŠ åˆ°æ‰€æœ‰è¾¹ç¼˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.3â€…â€…â€…Summary statistics for the three clusters found in the mobile phone customer dataset in Table 10.1[604] using k-means clustering (k = 3). Note, that the % missing and cardinality columns usually used are omitted here for legibility as these data quality issues will not arise in this simple example. They could be included when this approach is used on real datasets.",
            "zh": "10.3 ä½¿ç”¨k-meansèšç±»ï¼ˆk = 3ï¼‰å¯¹è¡¨10.1[604]ä¸­çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­å‘ç°çš„ä¸‰ä¸ªèšç±»è¿›è¡Œæ±‡æ€»ç»Ÿè®¡ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†ä¾¿äºé˜…è¯»ï¼Œæ­¤å¤„çœç•¥äº†é€šå¸¸ä½¿ç”¨çš„ç¼ºå¤±ç™¾åˆ†æ¯”å’ŒåŸºæ•°åˆ—ï¼Œå› ä¸ºåœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ä¸ä¼šå‡ºç°è¿™äº›æ•°æ®è´¨é‡é—®é¢˜ã€‚å½“è¿™ç§æ–¹æ³•ç”¨äºå®é™…æ•°æ®é›†æ—¶ï¼Œå¯ä»¥åŒ…æ‹¬å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The three weight matrices are",
            "zh": "è¿™ä¸‰ä¸ªæƒé‡çŸ©é˜µæ˜¯"
        }
    },
    {
        "translation": {
            "en": "We have seen that switching a network from a logistic activation function to a rectified linear activation function can speed up training; however, a less obvious effect of this switch is that it also tends to make the representations learned by a network sparse.",
            "zh": "æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼Œå°†ç½‘ç»œä»é€»è¾‘æ¿€æ´»å‡½æ•°åˆ‡æ¢åˆ°æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°å¯ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦;ç„¶è€Œï¼Œè¿™ç§åˆ‡æ¢çš„ä¸€ä¸ªä¸å¤ªæ˜æ˜¾çš„æ•ˆæœæ˜¯ï¼Œå®ƒè¿˜å€¾å‘äºä½¿ç½‘ç»œå­¦ä¹ çš„è¡¨ç¤ºå˜å¾—ç¨€ç–ã€‚"
        }
    },
    {
        "translation": {
            "en": "To ground our discussion of PDFs, and to illustrate how they can be used in making naive Bayes prediction models, we will extend our loan application fraud detection scenario to have two extra continuous features: ACCOUNT BALANCE, which specifies the amount of money in the account of the loan applicant at the time of the application; and LOAN AMOUNT, which specifies the amount of the loan being applied for.",
            "zh": "ä¸ºäº†å¥ å®šæˆ‘ä»¬å¯¹ PDF çš„è®¨è®ºçš„åŸºç¡€ï¼Œå¹¶è¯´æ˜å¦‚ä½•ä½¿ç”¨å®ƒä»¬æ¥åˆ¶ä½œæœ´ç´ çš„è´å¶æ–¯é¢„æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬å°†æ‰©å±•æˆ‘ä»¬çš„è´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹åœºæ™¯ï¼Œä»¥å…·æœ‰ä¸¤ä¸ªé¢å¤–çš„è¿ç»­åŠŸèƒ½ï¼šè´¦æˆ·ä½™é¢ï¼ŒæŒ‡å®šç”³è¯·æ—¶è´·æ¬¾ç”³è¯·äººè´¦æˆ·ä¸­çš„é‡‘é¢;å’Œ LOAN AMOUNTï¼ŒæŒ‡å®šæ‰€ç”³è¯·çš„è´·æ¬¾é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.16[568] shows the lift for each decile for the predictions shown in Table 9.11[557] for the email classification problem.",
            "zh": "è¡¨ 9.16[568] æ˜¾ç¤ºäº†è¡¨ 9.11[557] ä¸­é’ˆå¯¹ç”µå­é‚®ä»¶åˆ†ç±»é—®é¢˜çš„é¢„æµ‹ï¼Œæ¯ä¸ªååˆ†ä½æ•°çš„æå‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values and target feature values for the support vectors in these cases are (âˆ’0.225, 0.217, + 1), (âˆ’0.066, âˆ’0.069,âˆ’1), and (âˆ’0.273, âˆ’0.080, âˆ’1).",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæ”¯æŒå‘é‡çš„æè¿°æ€§ç‰¹å¾å€¼å’Œç›®æ ‡ç‰¹å¾å€¼ä¸º ï¼ˆâˆ’0.225ï¼Œ 0.217ï¼Œ + 1ï¼‰ã€ï¼ˆâˆ’0.066ï¼Œ âˆ’0.069ï¼Œâˆ’1ï¼‰ å’Œ ï¼ˆâˆ’0.273ï¼Œ âˆ’0.080ï¼Œ âˆ’1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This has the impact of first greatly reducing the dimensionality of the input data, before reproducing the inputs from this lower-dimensional representation.",
            "zh": "è¿™é¦–å…ˆä¼šå¤§å¤§é™ä½è¾“å…¥æ•°æ®çš„ç»´æ•°ï¼Œç„¶åå†ä»è¿™ç§ä½ç»´è¡¨ç¤ºæ³•é‡ç°è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "calculus, 765",
            "zh": "å¾®ç§¯åˆ†ï¼Œ765"
        }
    },
    {
        "translation": {
            "en": "4.9â€…â€…â€…Dataset for predicting the vegetation in an area sorted by the continuous ELEVATION feature.",
            "zh": "4.9 ç”¨äºé¢„æµ‹æŒ‰è¿ç»­é«˜ç¨‹è¦ç´ æ’åºçš„åŒºåŸŸå†…æ¤è¢«çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLASS: The clinicianâ€™s assessment of the biopsy sample as either benign or malignant.",
            "zh": "CLASSï¼šä¸´åºŠåŒ»ç”Ÿå¯¹æ´»æ£€æ ·æœ¬çš„è¯„ä¼°æ˜¯è‰¯æ€§è¿˜æ˜¯æ¶æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The silhouette is a well-known and widely used performance measure that assesses how well a clustering meets these criteria.5 Calculating the silhouette for a clustering involves a reasonable amount of computation. Algorithm 11[610] outlines the steps involved. To calculate the silhouette for a clustering, ğ’, over a dataset, ğ’Ÿ, we calculate a silhouette width for each instance, di, in ğ’Ÿ and average these over all instances in the dataset.",
            "zh": "è½®å»“ç¼©å°æ˜¯ä¸€ç§å¹¿ä¸ºäººçŸ¥ä¸”å¹¿æ³›ä½¿ç”¨çš„æ€§èƒ½åº¦é‡ï¼Œç”¨äºè¯„ä¼°èšç±»æ»¡è¶³è¿™äº›æ¡ä»¶çš„ç¨‹åº¦ã€‚5 è®¡ç®—èšç±»çš„è½®å»“éœ€è¦è¿›è¡Œåˆç†çš„è®¡ç®—ã€‚ç®—æ³•11[610]æ¦‚è¿°äº†æ‰€æ¶‰åŠçš„æ­¥éª¤ã€‚ä¸ºäº†è®¡ç®—èšç±» C åœ¨æ•°æ®é›† D ä¸Šçš„è½®å»“ï¼Œæˆ‘ä»¬è®¡ç®—æ¯ä¸ªå®ä¾‹çš„è½®å»“å®½åº¦ diï¼Œä»¥ D ä¸ºå•ä½ï¼Œå¹¶å°†è¿™äº›å®½åº¦å¹³å‡åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because these differences are squared in the Euclidean distance calculation, the larger maximum single difference between d12 and d17 results in a larger overall distance being calculated for this pair of instances.",
            "zh": "ç”±äºè¿™äº›å·®å€¼åœ¨æ¬§å‡ é‡Œå¾—è·ç¦»è®¡ç®—ä¸­æ˜¯å¹³æ–¹çš„ï¼Œå› æ­¤ d12 å’Œ d17 ä¹‹é—´çš„æœ€å¤§å•å·®å€¼è¶Šå¤§ï¼Œå°±ä¼šä¸ºè¿™å¯¹å®ä¾‹è®¡ç®—å‡ºæ›´å¤§çš„æ€»è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection is a commonly used implementation of the greedy local search approach to feature selection.",
            "zh": "å‰å‘é¡ºåºé€‰æ‹©æ˜¯è´ªå©ªå±€éƒ¨æœç´¢æ–¹æ³•çš„ç‰¹å¾é€‰æ‹©çš„å¸¸ç”¨å®ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "where .",
            "zh": "å“ªé‡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Propensity Modeling: Most business decision making would be much easier if we could predict the likelihood, or propensity, of individual customers to take particular actions.",
            "zh": "å€¾å‘å»ºæ¨¡ï¼šå¦‚æœæˆ‘ä»¬èƒ½å¤Ÿé¢„æµ‹å•ä¸ªå®¢æˆ·é‡‡å–ç‰¹å®šè¡ŒåŠ¨çš„å¯èƒ½æ€§æˆ–å€¾å‘ï¼Œé‚£ä¹ˆå¤§å¤šæ•°ä¸šåŠ¡å†³ç­–å°±ä¼šå®¹æ˜“å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Table 10.4[616] lists the features in the mobile phone customer dataset in order of importance in defining membership of each of the three clusters found.",
            "zh": "æœ€åï¼Œè¡¨10.4[616]åˆ—å‡ºäº†ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­çš„ç‰¹å¾ï¼ŒæŒ‰é‡è¦æ€§æ’åºï¼Œä»¥å®šä¹‰æ‰€å‘ç°çš„ä¸‰ä¸ªé›†ç¾¤ä¸­æ¯ä¸ªé›†ç¾¤çš„æˆå‘˜èµ„æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the gap between the 3rd quartile and the maximum value is noticeably larger than the gap between the median and the 3rd quartile, this suggests that the maximum value is unusual and is likely to be an outlier.",
            "zh": "å¦‚æœç¬¬ 3 ä¸ªå››åˆ†ä½æ•°å’Œæœ€å¤§å€¼ä¹‹é—´çš„å·®è·æ˜æ˜¾å¤§äºä¸­ä½æ•°å’Œç¬¬ 3 ä¸ªå››åˆ†ä½æ•°ä¹‹é—´çš„å·®è·ï¼Œåˆ™è¡¨æ˜æœ€å¤§å€¼ä¸å¯»å¸¸ï¼Œå¾ˆå¯èƒ½æ˜¯å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Silhouette plots show a useful overview of a clustering, including the size of each cluster and an indication of how well each instance belongs to its cluster, which can be an easy way to identify outliers in clusterings.",
            "zh": "è½®å»“å›¾æ˜¾ç¤ºäº†èšç±»çš„æœ‰ç”¨æ¦‚è¿°ï¼ŒåŒ…æ‹¬æ¯ä¸ªèšç±»çš„å¤§å°ä»¥åŠæ¯ä¸ªå®ä¾‹ä¸å…¶èšç±»çš„å½’å±ç¨‹åº¦çš„æŒ‡ç¤ºï¼Œè¿™æ˜¯è¯†åˆ«èšç±»ä¸­å¼‚å¸¸å€¼çš„ä¸€ç§ç®€å•æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sudden braking at the end of the journey results in large negative values that slowly taper off to match the speed profile in Figure C.1(a)[765].",
            "zh": "æ—…ç¨‹ç»“æŸæ—¶çš„çªç„¶åˆ¶åŠ¨ä¼šå¯¼è‡´è¾ƒå¤§çš„è´Ÿå€¼ï¼Œè¿™äº›è´Ÿå€¼ä¼šæ…¢æ…¢é€æ¸å˜ç»†ï¼Œä»¥åŒ¹é…å›¾C.1ï¼ˆaï¼‰[765]ä¸­çš„é€Ÿåº¦æ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for the purposes of updating the weights on the connections into a hidden layer neuron, this distinction is irrelevant and the same Î´ is used to update all the weights on the connections into a neuron.",
            "zh": "ç„¶è€Œï¼Œä¸ºäº†å°†è¿æ¥ä¸Šçš„æƒé‡æ›´æ–°ä¸ºéšè—å±‚ç¥ç»å…ƒï¼Œè¿™ç§åŒºåˆ«æ˜¯æ— å…³ç´§è¦çš„ï¼Œå¹¶ä¸”ä½¿ç”¨ç›¸åŒçš„Î´å°†è¿æ¥ä¸Šçš„æ‰€æœ‰æƒé‡æ›´æ–°ä¸ºç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "By optimizing her decisions to maximize these immediate rewards, Sarah learned how to complete the overall task successfully.",
            "zh": "é€šè¿‡ä¼˜åŒ–å¥¹çš„å†³ç­–ä»¥æœ€å¤§åŒ–è¿™äº›å³æ—¶å¥–åŠ±ï¼ŒSarah å­¦ä¼šäº†å¦‚ä½•æˆåŠŸå®Œæˆæ•´ä¸ªä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that a very low learning rate is required in order to ensure that the changes made to the weights at each iteration of the learning process are small enough for the algorithm to work effectively.",
            "zh": "è¿™æ„å‘³ç€éœ€è¦éå¸¸ä½çš„å­¦ä¹ ç‡ï¼Œä»¥ç¡®ä¿åœ¨å­¦ä¹ è¿‡ç¨‹çš„æ¯æ¬¡è¿­ä»£ä¸­å¯¹æƒé‡æ‰€åšçš„æ›´æ”¹è¶³å¤Ÿå°ï¼Œä»¥ä½¿ç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆå·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (7.46)[366] requires a dot product calculation between the result of applying the basis functions to the query instance and to each of the support vectors.",
            "zh": "ç­‰å¼ï¼ˆ7.46ï¼‰[366]è¦æ±‚åœ¨å°†åŸºå‡½æ•°åº”ç”¨äºæŸ¥è¯¢å®ä¾‹å’Œæ¯ä¸ªæ”¯æŒå‘é‡çš„ç»“æœä¹‹é—´è¿›è¡Œç‚¹ç§¯è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Updating weights after each training example is known as on-line, sequential, or stochastic gradient descent.",
            "zh": "åœ¨æ¯ä¸ªè®­ç»ƒç¤ºä¾‹ä¹‹åæ›´æ–°æƒé‡ç§°ä¸ºåœ¨çº¿ã€é¡ºåºæˆ–éšæœºæ¢¯åº¦ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distinction between easy learners and lazy learners is based on when the algorithm abstracts from the data.",
            "zh": "è½»æ¾å­¦ä¹ è€…å’Œæ‡’æƒ°å­¦ä¹ è€…ä¹‹é—´çš„åŒºåˆ«å–å†³äºç®—æ³•ä½•æ—¶ä»æ•°æ®ä¸­æŠ½è±¡å‡ºæ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we get to a point where we have already split on all the features, we go back to the start of the feature list.",
            "zh": "å¦‚æœæˆ‘ä»¬å·²ç»æ‹†åˆ†äº†æ‰€æœ‰åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†å›åˆ°åŠŸèƒ½åˆ—è¡¨çš„å¼€å¤´ã€‚"
        }
    },
    {
        "translation": {
            "en": "37. We can also use one-hot encodings to represent categorical descriptive features (see Section 7.4.3[336]).",
            "zh": "37. æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å•çƒ­ç¼–ç æ¥è¡¨ç¤ºåˆ†ç±»æè¿°æ€§ç‰¹å¾ï¼ˆå‚è§ç¬¬ 7.4.3 èŠ‚[336]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if a chess-playing agent never took good early moves, the agent would never have a chance to learn how to behave in potentially game-winning situations.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªä¸‹æ£‹çš„ä»£ç†äººä»æ¥æ²¡æœ‰é‡‡å–è‰¯å¥½çš„æ—©æœŸè¡ŒåŠ¨ï¼Œé‚£ä¹ˆè¿™ä¸ªä»£ç†äººå°†æ°¸è¿œæ²¡æœ‰æœºä¼šå­¦ä¹ å¦‚ä½•åœ¨å¯èƒ½èµ¢å¾—æ¯”èµ›çš„æƒ…å†µä¸‹è¡¨ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. All average class accuracies used in this section use a harmonic mean.",
            "zh": "7. æœ¬èŠ‚ä¸­ä½¿ç”¨çš„æ‰€æœ‰å¹³å‡ç­‰çº§ç²¾åº¦å‡ä½¿ç”¨è°æ³¢å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.9",
            "zh": "å›¾ 7.9"
        }
    },
    {
        "translation": {
            "en": "Consequently, the sum of all the cells in a joint probability distribution must be 1.0.",
            "zh": "å› æ­¤ï¼Œè”åˆæ¦‚ç‡åˆ†å¸ƒä¸­æ‰€æœ‰åƒå…ƒçš„æ€»å’Œå¿…é¡»ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "gradient descent, 168, 272, 274, 275, 319, 321, 368, 403, 541, 655",
            "zh": "æ¢¯åº¦ä¸‹é™ï¼Œ 168ï¼Œ 272ï¼Œ 274ï¼Œ 275ï¼Œ 319ï¼Œ 321ï¼Œ 368ï¼Œ 403ï¼Œ 541ï¼Œ 655"
        }
    },
    {
        "translation": {
            "en": "24. Section 3.5.2[81] describes the calculation of covariance matrices. The inverse covariance matrix was calculated using the solve function from the R programming language.",
            "zh": "24. ç¬¬3.5.2èŠ‚[81]æè¿°äº†åæ–¹å·®çŸ©é˜µçš„è®¡ç®—ã€‚é€†åæ–¹å·®çŸ©é˜µæ˜¯ä½¿ç”¨ R ç¼–ç¨‹è¯­è¨€çš„æ±‚è§£å‡½æ•°è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, it is a good idea to run the network for a number of iterations before the generated states are recorded as samples.",
            "zh": "å› æ­¤ï¼Œåœ¨å°†ç”Ÿæˆçš„çŠ¶æ€è®°å½•ä¸ºæ ·æœ¬ä¹‹å‰ï¼Œæœ€å¥½å…ˆè¿è¡Œç½‘ç»œè¿›è¡Œå¤šæ¬¡è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, in the Îµ0 bootstrap, k is set to values greater than or equal to 200, much larger values than when k-fold cross validation is used.",
            "zh": "é€šå¸¸ï¼Œåœ¨ Îµ0 å¼•å¯¼ç¨‹åºä¸­ï¼Œk è®¾ç½®ä¸ºå¤§äºæˆ–ç­‰äº 200 çš„å€¼ï¼Œæ¯”ä½¿ç”¨ k æŠ˜å äº¤å‰éªŒè¯æ—¶çš„å€¼å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "The full set of descriptive features Ross developed, along with a short description of each, is shown in Table 12.1[692].",
            "zh": "Ross å¼€å‘çš„å…¨å¥—æè¿°æ€§ç‰¹å¾ä»¥åŠæ¯ä¸ªç‰¹å¾çš„ç®€çŸ­æè¿°å¦‚è¡¨ 12.1[692] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we can use feature selection29 to help reduce the number of descriptive features in a dataset to just the subset that is most useful. Before we begin our discussion of approaches to feature selection, it is useful to distinguish between different types of descriptive features.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ feature selection29 æ¥å¸®åŠ©å°†æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾çš„æ•°é‡å‡å°‘åˆ°æœ€æœ‰ç”¨çš„å­é›†ã€‚åœ¨æˆ‘ä»¬å¼€å§‹è®¨è®ºç‰¹å¾é€‰æ‹©çš„æ–¹æ³•ä¹‹å‰ï¼ŒåŒºåˆ†ä¸åŒç±»å‹çš„æè¿°æ€§ç‰¹å¾æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. âˆ‚â„°t/âˆ‚ot: the rate of change of the error of the network at time-step t with respect to changes in the activation vector ot that was propagated to the output layer during the forward pass;",
            "zh": "1. âˆ‚Et/âˆ‚otï¼šç½‘ç»œåœ¨æ—¶é—´æ­¥é•¿tå¤„çš„è¯¯å·®ç›¸å¯¹äºåœ¨å‰å‘ä¼ é€’æœŸé—´ä¼ æ’­åˆ°è¾“å‡ºå±‚çš„æ¿€æ´»å‘é‡otçš„å˜åŒ–ç‡;"
        }
    },
    {
        "translation": {
            "en": "DBScan, 630",
            "zh": "DBSæ‰«æï¼Œ630"
        }
    },
    {
        "translation": {
            "en": "where each Yi is one of a set of events Y1 to Yk that cover all the possible outcomes in a domain and have no overlap between them.",
            "zh": "å…¶ä¸­ï¼Œæ¯ä¸ª Yi éƒ½æ˜¯ Y1 åˆ° Yk çš„ä¸€ç»„äº‹ä»¶ä¹‹ä¸€ï¼Œè¿™äº›äº‹ä»¶æ¶µç›–äº†åŸŸä¸­æ‰€æœ‰å¯èƒ½çš„ç»“æœï¼Œå¹¶ä¸”å®ƒä»¬ä¹‹é—´æ²¡æœ‰é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two issues arise when using hold-out sampling.",
            "zh": "ä½¿ç”¨ä¿æŒé‡‡æ ·æ—¶ä¼šå‡ºç°ä¸¤ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Then we introduce a well-known extension to backpropagation training known as dropout, which can help stop a network from overfitting.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥çš„åå‘ä¼ æ’­è®­ç»ƒæ‰©å±•ï¼Œç§°ä¸º dropoutï¼Œå®ƒå¯ä»¥å¸®åŠ©é˜»æ­¢ç½‘ç»œè¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "8.11â€…â€…â€…The calculation of the z values and activations of each neuron during the forward pass of the backpropagation algorithm.",
            "zh": "8.11 åå‘ä¼ æ’­ç®—æ³•å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­æ¯ä¸ªç¥ç»å…ƒçš„zå€¼å’Œæ¿€æ´»çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.70",
            "zh": "0.70"
        }
    },
    {
        "translation": {
            "en": "Figure 8.17",
            "zh": "å›¾ 8.17"
        }
    },
    {
        "translation": {
            "en": "gradient, 321, 368",
            "zh": "æ¢¯åº¦ï¼Œ 321ï¼Œ 368"
        }
    },
    {
        "translation": {
            "en": "Our first task is to sort the dataset based on the ELEVATION feature.",
            "zh": "æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯æ ¹æ® ELEVATION ç‰¹å¾å¯¹æ•°æ®é›†è¿›è¡Œæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "The dotted diagonal line on the cumulative gain chart shows the performance we would expect from random guessing, and the closer the cumulative gain line is to the top left-hand corner of the chart, the better the model is performing.",
            "zh": "ç´¯ç§¯å¢ç›Šå›¾ä¸Šçš„è™šçº¿å¯¹è§’çº¿æ˜¾ç¤ºäº†æˆ‘ä»¬ä»éšæœºçŒœæµ‹ä¸­é¢„æœŸçš„æ€§èƒ½ï¼Œç´¯ç§¯å¢ç›Šçº¿è¶Šé è¿‘å›¾è¡¨çš„å·¦ä¸Šè§’ï¼Œæ¨¡å‹çš„è¡¨ç°å°±è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "AHC has an advantage over k-means that it does not require k to be set before the algorithm starts.",
            "zh": "AHC ä¸ k å‡å€¼ç›¸æ¯”å…·æœ‰ä¼˜åŠ¿ï¼Œå³å®ƒä¸éœ€è¦åœ¨ç®—æ³•å¼€å§‹ä¹‹å‰è®¾ç½® kã€‚"
        }
    },
    {
        "translation": {
            "en": "Activations",
            "zh": "æ¿€æ´»"
        }
    },
    {
        "translation": {
            "en": "As mentioned in the chapter, ReLUs (or variants) are now the default activation function to use, although if a network architecture specifies a particular activation function, then follow the specification (e.g., LSTMs specify the use of sigmoid and tanh activations).",
            "zh": "å¦‚æœ¬ç« æ‰€è¿°ï¼ŒReLUï¼ˆæˆ–å˜ä½“ï¼‰ç°åœ¨æ˜¯é»˜è®¤ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œä½†å¦‚æœç½‘ç»œæ¶æ„æŒ‡å®šäº†ç‰¹å®šçš„æ¿€æ´»å‡½æ•°ï¼Œåˆ™éµå¾ªè§„èŒƒï¼ˆä¾‹å¦‚ï¼ŒLSTM æŒ‡å®šä½¿ç”¨ sigmoid å’Œ tanh æ¿€æ´»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.30â€…â€…â€…Samples of the handwritten digit images from the MNIST dataset.",
            "zh": "8.30 æ¥è‡ªMNISTæ•°æ®é›†çš„æ‰‹å†™æ•°å­—å›¾åƒæ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The set of weight parameters for the mixture must sum to 1.",
            "zh": "æ··åˆç‰©çš„é‡é‡å‚æ•°é›†æ€»å’Œå¿…é¡»ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) There are a lot of zero entries in the spam bag-of-words dataset. This is indicative of sparse data and is typical for text analytics. Cosine similarity is often a good choice when dealing with sparse non-binary data. What target level would a 3-NN model using cosine similarity return for the query?",
            "zh": "ï¼ˆeï¼‰ åƒåœ¾é‚®ä»¶è¯è¢‹æ•°æ®é›†ä¸­æœ‰å¾ˆå¤šé›¶æ¡ç›®ã€‚è¿™è¡¨ç¤ºæ•°æ®ç¨€ç–ï¼Œæ˜¯æ–‡æœ¬åˆ†æçš„å…¸å‹ç‰¹å¾ã€‚åœ¨å¤„ç†ç¨€ç–çš„éäºŒè¿›åˆ¶æ•°æ®æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼æ€§é€šå¸¸æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦çš„ 3-NN æ¨¡å‹ä¼šä¸ºæŸ¥è¯¢è¿”å›ä»€ä¹ˆç›®æ ‡çº§åˆ«ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "10.17â€…â€…â€…The process of using an unsupervised auto-encoder network to generate a feature representation used to train a supervised model.",
            "zh": "10.17 ä½¿ç”¨æ— ç›‘ç£è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œç”Ÿæˆç”¨äºè®­ç»ƒç›‘ç£æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "population parameters, 751",
            "zh": "ç§ç¾¤å‚æ•°ï¼Œ751"
        }
    },
    {
        "translation": {
            "en": "(a) Design a state representation for the car agent in this scenario. How many states will exist in the representation?",
            "zh": "ï¼ˆaï¼‰ åœ¨æ­¤æ–¹æ¡ˆä¸­ä¸ºæ±½è½¦ä»£ç†è®¾è®¡çŠ¶æ€è¡¨ç¤ºã€‚è¡¨ç¤ºå½¢å¼ä¸­å°†å­˜åœ¨å¤šå°‘ä¸ªå·ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "5.12â€…â€…â€…(a) The feature space defined by the SALARY and AGE features in Table 5.5[204]; and (b) the normalized SALARY and AGE feature space based on the normalized data in Table 5.7[208].",
            "zh": "5.12 ï¼ˆaï¼‰ è¡¨5.5[204]ä¸­SALARY å’Œ AGE ç‰¹å¾å®šä¹‰çš„ç‰¹å¾ç©ºé—´;ï¼ˆbï¼‰åŸºäºè¡¨5.7[208]ä¸­å½’ä¸€åŒ–æ•°æ®çš„å½’ä¸€åŒ–SALAWå’ŒAGEç‰¹å¾ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. In this simplified version of Blackjack, the complication of the player having to choose a wager for each hand is ignored.",
            "zh": "10. åœ¨è¿™ä¸ªç®€åŒ–ç‰ˆçš„äºŒåä¸€ç‚¹ä¸­ï¼Œç©å®¶å¿…é¡»ä¸ºæ¯æ‰‹ç‰Œé€‰æ‹©èµŒæ³¨çš„å¤æ‚æ€§è¢«å¿½ç•¥äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "hits, 538",
            "zh": "ç‚¹å‡»æ•°ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "A little investigation revealed that this minimum value arises from d3 in Table 3.2[56].",
            "zh": "ç¨åŠ è°ƒæŸ¥åå‘ç°ï¼Œè¯¥æœ€å°å€¼æ¥è‡ªè¡¨3.2ä¸­çš„d3[56]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Properly constructed Bayesian networks are relatively powerful models that can capture the interactions between descriptive features in determining a prediction.",
            "zh": "æ­£ç¡®æ„å»ºçš„è´å¶æ–¯ç½‘ç»œæ˜¯ç›¸å¯¹å¼ºå¤§çš„æ¨¡å‹ï¼Œå¯ä»¥åœ¨ç¡®å®šé¢„æµ‹æ—¶æ•è·æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Stratified sampling is a sampling method that ensures that the relative frequencies of the levels of a specific stratification feature are maintained in the sampled dataset.",
            "zh": "åˆ†å±‚æŠ½æ ·æ˜¯ä¸€ç§æŠ½æ ·æ–¹æ³•ï¼Œå¯ç¡®ä¿åœ¨æŠ½æ ·æ•°æ®é›†ä¸­ä¿æŒç‰¹å®šåˆ†å±‚è¦ç´ æ°´å¹³çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "An event is then an experiment whose outcome fixes the values of the random variables.",
            "zh": "ç„¶åï¼Œäº‹ä»¶æ˜¯ä¸€ä¸ªå®éªŒï¼Œå…¶ç»“æœå›ºå®šéšæœºå˜é‡çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. We return to this discussion in Section 12.5[698] and Section 13.4.1[719].",
            "zh": "5. æˆ‘ä»¬å›åˆ°ç¬¬ 12.5 èŠ‚[698] å’Œç¬¬ 13.4.1 èŠ‚[719] ä¸­çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The formal definition of Bayesâ€™ Theorem is",
            "zh": "è´å¶æ–¯å®šç†çš„æ­£å¼å®šä¹‰æ˜¯"
        }
    },
    {
        "translation": {
            "en": "One of the key skills the novice surfer has to learn is how to successfully catch a wave.",
            "zh": "æ–°æ‰‹å†²æµªè€…å¿…é¡»å­¦ä¹ çš„å…³é”®æŠ€èƒ½ä¹‹ä¸€æ˜¯å¦‚ä½•æˆåŠŸæ•æ‰æµ·æµªã€‚"
        }
    },
    {
        "translation": {
            "en": "If the index is a whole number, we take the value at that position in the ordered list of values as the ith percentile.",
            "zh": "å¦‚æœç´¢å¼•æ˜¯æ•´æ•°ï¼Œåˆ™æˆ‘ä»¬å°†æœ‰åºåˆ—å€¼åˆ—è¡¨ä¸­è¯¥ä½ç½®çš„å€¼ä½œä¸ºç¬¬ i ä¸ªç™¾åˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "distance measure, 599, 601, 618",
            "zh": "è·ç¦»æµ‹é‡ï¼Œ 599ï¼Œ 601ï¼Œ 618"
        }
    },
    {
        "translation": {
            "en": "The calculations in Table 4.5[138] show that STREAM has a higher information gain than SLOPE and so is the best feature with which to split 7.",
            "zh": "è¡¨4.5[138]ä¸­çš„è®¡ç®—è¡¨æ˜ï¼ŒSTREAMçš„ä¿¡æ¯å¢ç›Šé«˜äºSLOPEï¼Œå› æ­¤æ˜¯åˆ†å‰²7çš„æœ€ä½³ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The third way in which a data quality issue can arise due to an irregular cardinality is if a categorical feature has a much higher cardinality than we would expect given the definition of the feature.",
            "zh": "ç”±äºä¸è§„åˆ™åŸºæ•°è€Œå¯¼è‡´æ•°æ®è´¨é‡é—®é¢˜çš„ç¬¬ä¸‰ç§æ–¹å¼æ˜¯ï¼Œå¦‚æœåˆ†ç±»ç‰¹å¾çš„åŸºæ•°æ¯”æˆ‘ä»¬ç»™å®šçš„ç‰¹å¾å®šä¹‰é¢„æœŸçš„è¦é«˜å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The final k-d tree generated for the dataset in Table 5.4[191]; and (b) the partitioning of the feature space defined by this k-d tree.",
            "zh": "ï¼ˆaï¼‰ ä¸ºè¡¨5.4[191]ä¸­çš„æ•°æ®é›†ç”Ÿæˆçš„æœ€ç»ˆk-dæ ‘;ï¼ˆbï¼‰ç”±è¯¥k-dæ ‘å®šä¹‰çš„ç‰¹å¾ç©ºé—´çš„åˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "Network Error",
            "zh": "ç½‘ç»œé”™è¯¯"
        }
    },
    {
        "translation": {
            "en": "The table below lists the bag-of-words representation for the following five emails and a target feature, SPAM, whether they are spam emails or genuine emails:",
            "zh": "ä¸‹è¡¨åˆ—å‡ºäº†ä»¥ä¸‹äº”å°ç”µå­é‚®ä»¶å’Œç›®æ ‡åŠŸèƒ½â€œåƒåœ¾é‚®ä»¶â€çš„è¯è¢‹è¡¨ç¤ºå½¢å¼ï¼Œæ— è®ºå®ƒä»¬æ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯æ­£ç‰ˆç”µå­é‚®ä»¶ï¼š"
        }
    },
    {
        "translation": {
            "en": "Cumulatively, however, these differences will lead to quite different behavior.",
            "zh": "ç„¶è€Œï¼Œç´¯ç§¯èµ·æ¥ï¼Œè¿™äº›å·®å¼‚å°†å¯¼è‡´å®Œå…¨ä¸åŒçš„è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "electroencephalography pattern recognition, 353",
            "zh": "è„‘ç”µå›¾æ¨¡å¼è¯†åˆ«ï¼Œ353"
        }
    },
    {
        "translation": {
            "en": "normal distribution, 59, 61, 71, 78, 269, 270, 557",
            "zh": "æ­£æ€åˆ†å¸ƒï¼Œ 59ï¼Œ 61ï¼Œ 71ï¼Œ 78ï¼Œ 269ï¼Œ 270ï¼Œ 557"
        }
    },
    {
        "translation": {
            "en": "8.4.5.1â€ƒLocal receptive fields and filtersâ€ƒThe concept of local receptive field comes from research on visual perception in cats.",
            "zh": "8.4.5.1 å±€éƒ¨æ„Ÿå—é‡å’Œæ»¤æ³¢å™¨ å±€éƒ¨æ„Ÿå—é‡çš„æ¦‚å¿µæ¥è‡ªå¯¹çŒ«è§†è§‰çŸ¥è§‰çš„ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "39. This example is inspired by the research reported in Palaniappan and Awang (2008).",
            "zh": "39. è¿™ä¸ªä¾‹å­çš„çµæ„Ÿæ¥è‡ªPalaniappanå’ŒAwangï¼ˆ2008å¹´ï¼‰æŠ¥å‘Šçš„ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Is it a man?",
            "zh": "1.æ˜¯ç”·äººå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Although this is not unheard of (particularly in cases like the SDSS project in which data is generated in a fully automated process), it is very unusual.",
            "zh": "è™½ç„¶è¿™å¹¶éé—»æ‰€æœªé—»ï¼ˆç‰¹åˆ«æ˜¯åœ¨åƒSDSSé¡¹ç›®è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œæ•°æ®æ˜¯åœ¨å®Œå…¨è‡ªåŠ¨åŒ–çš„è¿‡ç¨‹ä¸­ç”Ÿæˆçš„ï¼‰ï¼Œä½†è¿™æ˜¯éå¸¸ä¸å¯»å¸¸çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "parsimony, 646",
            "zh": "åå•¬ï¼Œ646"
        }
    },
    {
        "translation": {
            "en": "The height of each bar indicates the frequency of the associated level (readers will most likely already be familiar with the bar plot).",
            "zh": "æ¯ä¸ªæŸ±çš„é«˜åº¦è¡¨ç¤ºç›¸å…³æ°´å¹³çš„é¢‘ç‡ï¼ˆè¯»è€…å¾ˆå¯èƒ½å·²ç»ç†Ÿæ‚‰æŸ±å½¢å›¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we have discretized the data using binning, we need to record the raw continuous feature thresholds between the bins.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬ä½¿ç”¨åˆ†ç®±å¯¹æ•°æ®è¿›è¡Œç¦»æ•£åŒ–ï¼Œæˆ‘ä»¬å°±éœ€è¦è®°å½•åˆ†ç®±ä¹‹é—´çš„åŸå§‹è¿ç»­ç‰¹å¾é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, to train the network we must backpropagate this loss through the network.",
            "zh": "ä½†æ˜¯ï¼Œè¦è®­ç»ƒç½‘ç»œï¼Œæˆ‘ä»¬å¿…é¡»é€šè¿‡ç½‘ç»œåå‘ä¼ æ’­è¿™ç§æŸå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2.3â€…â€…â€…Information Gain",
            "zh": "4.2.3 ä¿¡æ¯å¢ç›Š"
        }
    },
    {
        "translation": {
            "en": "Note that neurons are often referred to as units, and they are distinguished by the type of activation function they use.",
            "zh": "è¯·æ³¨æ„ï¼Œç¥ç»å…ƒé€šå¸¸è¢«ç§°ä¸ºå•ä½ï¼Œå®ƒä»¬é€šè¿‡å®ƒä»¬ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ç±»å‹æ¥åŒºåˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This tree is shown in Figure 12.4[698], and the lack of pruning is obvious in its complexity.",
            "zh": "è¿™æ£µæ ‘å¦‚å›¾ 12.4[698] æ‰€ç¤ºï¼Œå…¶å¤æ‚æ€§æ˜æ˜¾ç¼ºä¹ä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "backpropagation of error, 387, 403, 404, 624, 731",
            "zh": "è¯¯å·®åå‘ä¼ æ’­ï¼Œ 387ï¼Œ 403ï¼Œ 404ï¼Œ 624ï¼Œ 731"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed for the revenue commission, outline the type of data that would be required.",
            "zh": "ï¼ˆbï¼‰ å¯¹äºæ‚¨ä¸ºæ”¶å…¥å§”å‘˜ä¼šæå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°æ‰€éœ€çš„æ•°æ®ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The ensemble contains 21 independent models, all of which have an error rate of 0.49.",
            "zh": "ï¼ˆcï¼‰ è¯¥é›†åˆåŒ…å«21ä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹çš„é”™è¯¯ç‡ä¸º0.49ã€‚"
        }
    },
    {
        "translation": {
            "en": "As is the case in most predictive data analytics projects, AT did not approach Ross with a well-specified predictive analytics solution.",
            "zh": "ä¸å¤§å¤šæ•°é¢„æµ‹æ€§æ•°æ®åˆ†æé¡¹ç›®ä¸€æ ·ï¼ŒATæ²¡æœ‰å‘Rossæä¾›æ˜ç¡®çš„é¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Although internal measures such as the silhouette and external measures calculated against a proxy ground truth are useful in measuring how well a clustering matches an ideal expectation, they do not tell analysts anything about what has been found in the clustering, or whether or not the clustering will be useful for a particular task.",
            "zh": "å°½ç®¡å†…éƒ¨åº¦é‡ï¼ˆå¦‚è½®å»“ï¼‰å’Œæ ¹æ®ä»£ç†å®å†µè®¡ç®—çš„å¤–éƒ¨åº¦é‡å¯¹äºè¡¡é‡èšç±»ä¸ç†æƒ³æœŸæœ›çš„åŒ¹é…ç¨‹åº¦å¾ˆæœ‰ç”¨ï¼Œä½†å®ƒä»¬ä¸ä¼šå‘Šè¯‰åˆ†æäººå‘˜ä»»ä½•å…³äºèšç±»ä¸­å‘ç°çš„å†…å®¹ï¼Œæˆ–è€…èšç±»æ˜¯å¦å¯¹ç‰¹å®šä»»åŠ¡æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the domain is not complex, or if the available data is small, or if the available hardware is not powerful enough for deep learning, then it is likely that you will have more success by exploring whether an alternative machine learning model can be used to develop a viable solution for the task.",
            "zh": "å¦‚æœåŸŸä¸å¤æ‚ï¼Œæˆ–è€…å¯ç”¨æ•°æ®å¾ˆå°ï¼Œæˆ–è€…å¯ç”¨çš„ç¡¬ä»¶ä¸å¤Ÿå¼ºå¤§ï¼Œæ— æ³•è¿›è¡Œæ·±åº¦å­¦ä¹ ï¼Œé‚£ä¹ˆé€šè¿‡æ¢ç´¢æ˜¯å¦å¯ä»¥ä½¿ç”¨æ›¿ä»£æœºå™¨å­¦ä¹ æ¨¡å‹æ¥ä¸ºä»»åŠ¡å¼€å‘å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œæ‚¨å¯èƒ½ä¼šå–å¾—æ›´å¤§çš„æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision Trees",
            "zh": "å†³ç­–æ ‘"
        }
    },
    {
        "translation": {
            "en": "Table B.2",
            "zh": "è¡¨B.2"
        }
    },
    {
        "translation": {
            "en": "1. Other types of machine learning include unsupervised learning, semi-supervised learning, and reinforcement learning. In this book, however, we focus mainly on supervised machine learning and in most of the book use the terms supervised machine learning and machine learning interchangeably. Chapters 10[597] and 11[637] provide overviews of unsupervised learning and reinforcement learning, respectively.",
            "zh": "1. å…¶ä»–ç±»å‹çš„æœºå™¨å­¦ä¹ åŒ…æ‹¬æ— ç›‘ç£å­¦ä¹ ã€åŠç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚ç„¶è€Œï¼Œåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨ç›‘ç£æœºå™¨å­¦ä¹ ï¼Œå¹¶ä¸”åœ¨æœ¬ä¹¦çš„å¤§éƒ¨åˆ†å†…å®¹ä¸­ï¼Œç›‘ç£æœºå™¨å­¦ä¹ å’Œæœºå™¨å­¦ä¹ è¿™ä¸¤ä¸ªæœ¯è¯­å¯ä»¥äº’æ¢ä½¿ç”¨ã€‚ç¬¬10ç« [597]å’Œç¬¬11ç« [637]åˆ†åˆ«æ¦‚è¿°äº†æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first goal is to fully understand the characteristics of the data in the ABT.",
            "zh": "ç¬¬ä¸€ä¸ªç›®æ ‡æ˜¯å……åˆ†äº†è§£ ABT ä¸­æ•°æ®çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM, 16",
            "zh": "CRISP-DMï¼Œ16"
        }
    },
    {
        "translation": {
            "en": "6.4â€ƒExtensions and Variations",
            "zh": "6.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Recall from Chapter 7[311] that w[0] is the equivalent of the y-intercept in the equation of the line from high school geometry (see (7.2.1)[313]), and d[0] is a dummy descriptive feature used for notational convenience and is always equal to 1 (see (7.9)[320]).",
            "zh": "å›æƒ³ä¸€ä¸‹ç¬¬7ç« [311]ï¼Œw[0]ç­‰ä»·äºé«˜ä¸­å‡ ä½•ä¸­ç›´çº¿æ–¹ç¨‹ä¸­çš„yæˆªè·ï¼ˆå‚è§ï¼ˆ7.2.1ï¼‰[313]ï¼‰ï¼Œè€Œd[0]æ˜¯ä¸€ä¸ªç”¨äºç¬¦å·æ–¹ä¾¿çš„è™šæ‹Ÿæè¿°ç‰¹å¾ï¼Œå¹¶ä¸”å§‹ç»ˆç­‰äº1ï¼ˆå‚è§ï¼ˆ7.9ï¼‰[320]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We divide by nâˆ’ 1 so that the sample variance is an unbiased estimate of the population variance.",
            "zh": "æˆ‘ä»¬é™¤ä»¥ nâˆ’ 1ï¼Œä½¿æ ·æœ¬æ–¹å·®æ˜¯æ€»ä½“æ–¹å·®çš„æ— åä¼°è®¡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The techniques described in Section 10.4.2[607] for evaluating clusterings can be used here to set the best value for k.",
            "zh": "ç¬¬ 10.4.2 èŠ‚[607] ä¸­æè¿°çš„ç”¨äºè¯„ä¼°èšç±»çš„æŠ€æœ¯å¯ç”¨äºè®¾ç½® k çš„æœ€ä½³å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) Generate a cumulative gain chart for each model.",
            "zh": "ï¼ˆdï¼‰ ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆç´¯ç§¯å¢ç›Šå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each of these layers we calculate the error gradient with respect to the layerâ€™s input (hxt) by multiplying the Î´ values for the neurons in the layer by the weights the neuron uses.",
            "zh": "å¯¹äºè¿™äº›å±‚ä¸­çš„æ¯ä¸€ä¸ªï¼Œæˆ‘ä»¬é€šè¿‡å°†å±‚ä¸­ç¥ç»å…ƒçš„Î´å€¼ä¹˜ä»¥ç¥ç»å…ƒä½¿ç”¨çš„æƒé‡æ¥è®¡ç®—ç›¸å¯¹äºå±‚è¾“å…¥ ï¼ˆhxtï¼‰ çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.6â€…â€…â€…Illustration of how a mixture of Gaussians model is composed of a number of normal distributions. The curve plotted using a solid line is the mixture of Gaussians density curve, created using an appropriately weighted summation of the three normal curves, plotted using dashed and dotted lines.",
            "zh": "6.6 è¯´æ˜é«˜æ–¯æ¨¡å‹çš„æ··åˆå¦‚ä½•ç”±è®¸å¤šæ­£æ€åˆ†å¸ƒç»„æˆã€‚ä½¿ç”¨å®çº¿ç»˜åˆ¶çš„æ›²çº¿æ˜¯é«˜æ–¯å¯†åº¦æ›²çº¿çš„æ··åˆï¼Œä½¿ç”¨ä½¿ç”¨è™šçº¿å’Œè™šçº¿ç»˜åˆ¶çš„ä¸‰æ¡æ­£æ€æ›²çº¿çš„é€‚å½“åŠ æƒæ±‚å’Œåˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.7[612] shows the silhouette plot for the clustering of the mobile phone customer dataset.",
            "zh": "å›¾10.7[612]æ˜¾ç¤ºäº†ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†èšç±»çš„è½®å»“å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons are ReLUs, that the input to the network is Neuron 1 = 0.2, and that the desired output for this input is 0.7:",
            "zh": "ï¼ˆbï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒæ˜¯ ReLUï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.2ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æœŸæœ›è¾“å‡ºæ˜¯ 0.7ï¼š"
        }
    },
    {
        "translation": {
            "en": "SOCIOECONOMIC BAND B",
            "zh": "ç¤¾ä¼šç»æµç­‰çº§ B"
        }
    },
    {
        "translation": {
            "en": "The structure of the dataset required for this task would contain one row per galaxy, and each row would include a set of descriptive features describing the characteristics of that galaxy object and a target feature indicating the morphological category of the galaxy object.",
            "zh": "è¿™é¡¹ä»»åŠ¡æ‰€éœ€çš„æ•°æ®é›†ç»“æ„å°†åŒ…å«æ¯ä¸ªæ˜Ÿç³»ä¸€è¡Œï¼Œæ¯è¡Œå°†åŒ…æ‹¬ä¸€ç»„æè¿°è¯¥æ˜Ÿç³»å¤©ä½“ç‰¹å¾çš„æè¿°æ€§ç‰¹å¾å’Œä¸€ä¸ªæŒ‡ç¤ºæ˜Ÿç³»å¤©ä½“å½¢æ€ç±»åˆ«çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is primarily this path of error gradients flow (rather than the backpropagated hidden state âˆ‚â„°t/âˆ‚htâˆ’1 gradients) that enable LSTMs to learn long-distance dependencies",
            "zh": "ä¸»è¦æ˜¯è¿™ç§è¯¯å·®æ¢¯åº¦æµè·¯å¾„ï¼ˆè€Œä¸æ˜¯åå‘ä¼ æ’­çš„éšè—çŠ¶æ€âˆ‚Et/âˆ‚htâˆ’1æ¢¯åº¦ï¼‰ä½¿LSTMèƒ½å¤Ÿå­¦ä¹ é•¿è·ç¦»ä¾èµ–å…³ç³»"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons are ReLUs, that the input to the network is Neuron 1 = 0.5 and that the desired output for this input is 0.9",
            "zh": "ï¼ˆbï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒæ˜¯ ReLUï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.5ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æœŸæœ›è¾“å‡ºæ˜¯ 0.9"
        }
    },
    {
        "translation": {
            "en": "where f is a feature and levels(f) is the set of levels in the domain of the feature. This means that we have a total probability mass of 1.0 that is shared out between the different assignments of a level to a feature based on their relative frequency. Smoothing involves taking some of the probability mass from the assignments with probability greater than average and spreading it across the probabilities that are below average, or even equal to zero.",
            "zh": "å…¶ä¸­ f æ˜¯ç‰¹å¾ï¼Œlevelsï¼ˆfï¼‰ æ˜¯ç‰¹å¾åŸŸä¸­çš„ä¸€ç»„çº§åˆ«ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬æœ‰ä¸€ä¸ªæ€»æ¦‚ç‡è´¨é‡ 1.0ï¼Œè¯¥æ¦‚ç‡è´¨é‡æ ¹æ®å®ƒä»¬çš„ç›¸å¯¹é¢‘ç‡åœ¨çº§åˆ«å¯¹ç‰¹å¾çš„ä¸åŒåˆ†é…ä¹‹é—´å…±äº«ã€‚å¹³æ»‘æ¶‰åŠä»æ¦‚ç‡å¤§äºå¹³å‡å€¼çš„èµ‹å€¼ä¸­è·å–ä¸€äº›æ¦‚ç‡è´¨é‡ï¼Œå¹¶å°†å…¶åˆ†å¸ƒåœ¨ä½äºå¹³å‡å€¼ç”šè‡³ç­‰äºé›¶çš„æ¦‚ç‡ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.5â€…â€…â€…(a)â€“(c) The evolution of the entries in the action-value table over episodes of Q-learning off-policy temporal-difference learning across the grid world. (d) The cumulative reward earned from each episode. (e) An illustration of the target policy learned by the agent after 350 episodes. (f) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "11.5 ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ è¡ŒåŠ¨-ä»·å€¼è¡¨ä¸­æ¡ç›®åœ¨æ•´ä¸ªç½‘æ ¼ä¸–ç•Œçš„ Q-learning æ”¿ç­–å¤–æ—¶é—´å·®å¼‚å­¦ä¹ äº‹ä»¶ä¸­çš„æ¼”å˜ã€‚ï¼ˆdï¼‰ æ¯é›†çš„ç´¯ç§¯å¥–åŠ±ã€‚ï¼ˆeï¼‰ ä»£ç†äººåœ¨350é›†åäº†è§£åˆ°çš„ç›®æ ‡æ”¿ç­–çš„è¯´æ˜ã€‚ï¼ˆfï¼‰ å½“è´ªå©ªåœ°éµå¾ªç›®æ ‡ç­–ç•¥æ—¶ï¼Œä»£ç†ä»å¼€å§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Claim Types subconcept of the Claim History is also time dependent.",
            "zh": "â€œå£°æ˜å†å²è®°å½•â€çš„â€œå£°æ˜ç±»å‹â€å­æ¦‚å¿µä¹Ÿä¸æ—¶é—´æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "A pseudocode description of the deep Q network algorithm is given in Algorithm 16[673].",
            "zh": "ç®—æ³•16[673]ç»™å‡ºäº†æ·±åº¦Qç½‘ç»œç®—æ³•çš„ä¼ªä»£ç æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "independent features, 83",
            "zh": "ç‹¬ç«‹åŠŸèƒ½ï¼Œ 83"
        }
    },
    {
        "translation": {
            "en": "PREDICTIVE DATA ANALYTICS",
            "zh": "é¢„æµ‹æ€§æ•°æ®åˆ†æ"
        }
    },
    {
        "translation": {
            "en": "Control Group",
            "zh": "æ§åˆ¶ç»„"
        }
    },
    {
        "translation": {
            "en": "An action-value table for an agent trained to play the card game TwentyTwos (the simplified version of Blackjack described in Section 11.2.3[643]).",
            "zh": "ä¸€ä¸ªåŠ¨ä½œå€¼è¡¨ï¼Œä¾›å—è¿‡è®­ç»ƒçš„ä»£ç†ç©çº¸ç‰Œæ¸¸æˆ TwentyTwosï¼ˆç¬¬ 11.2.3 èŠ‚ä¸­æè¿°çš„ Blackjack çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰[643]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.32",
            "zh": "å›¾ 8.32"
        }
    },
    {
        "translation": {
            "en": "In both these cases we should subtract âˆ‚â„°/âˆ‚wi,k from wi,k. The same conclusion can be reached via similar reasoning for the case ai < ti. Hence we update the weights as follows:",
            "zh": "åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½åº”è¯¥ä» wiï¼Œk ä¸­å‡å» âˆ‚E/âˆ‚wiï¼Œkã€‚é€šè¿‡å¯¹æ¡ˆä¾‹çš„ç±»ä¼¼æ¨ç†ï¼Œå¯ä»¥å¾—å‡ºç›¸åŒçš„ç»“è®º ai < ti.å› æ­¤ï¼Œæˆ‘ä»¬æ›´æ–°æƒé‡å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The fact that a weight matrix may be involved multiple times in the generation of an output means that backpropagating the error for an output can result in multiple error gradients being calculated for a weight: one error gradient for each time the weight was involved in generating the output.",
            "zh": "æƒé‡çŸ©é˜µåœ¨è¾“å‡ºç”Ÿæˆè¿‡ç¨‹ä¸­å¯èƒ½æ¶‰åŠå¤šä¸ªï¼Œè¿™æ„å‘³ç€åå‘ä¼ æ’­è¾“å‡ºçš„è¯¯å·®å¯èƒ½ä¼šå¯¼è‡´ä¸ºä¸€ä¸ªæƒé‡è®¡ç®—å¤šä¸ªè¯¯å·®æ¢¯åº¦ï¼šæ¯æ¬¡ç”Ÿæˆè¾“å‡ºæ—¶æ¶‰åŠæƒé‡æ—¶ï¼Œéƒ½ä¼šè®¡ç®—ä¸€ä¸ªè¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example d15 and d8 are separated by a distance of just 0.06 and are combined together into the cluster 10.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œd15 å’Œ d8 ç›¸è·ä»… 0.06ï¼Œå¹¶ç»„åˆæˆç°‡ 10ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 10.3(e)[602] and 10.3(f)[602] show the remaining steps of the k-means clustering process.",
            "zh": "å›¾10.3ï¼ˆeï¼‰[602]å’Œå›¾10.3ï¼ˆfï¼‰[602]æ˜¾ç¤ºäº†k-meansèšç±»è¿‡ç¨‹çš„å…¶ä½™æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. P(q[1],â€¦,q[m]), the joint probability of the descriptive features of a query instance taking a specific set of values",
            "zh": "2. Pï¼ˆq[1],...,q[m]ï¼‰ï¼ŒæŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾çš„è”åˆæ¦‚ç‡ï¼Œé‡‡ç”¨ä¸€ç»„ç‰¹å®šçš„å€¼"
        }
    },
    {
        "translation": {
            "en": "6.14â€…â€…â€…The probabilities, from Table 6.13[281], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, and AB = 759.07, and the calculation of the scores for each candidate prediction.",
            "zh": "6.14 ä»è¡¨6.13[281]å¯ä»¥çœ‹å‡ºï¼Œæœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹å¯¹CH = paidã€GC = guarantorã€ACC = freeå’ŒAB = 759.07çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„æ¦‚ç‡ï¼Œä»¥åŠè®¡ç®—æ¯ä¸ªå€™é€‰é¢„æµ‹çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, following the Îµ-greedy policy a random number is generated, 0.073, which this time is below Îµ, and so a random action from those available from state 0-2 is selected.",
            "zh": "åŒæ ·ï¼ŒæŒ‰ç…§Îµè´ªå©ªç­–ç•¥ï¼Œå°†ç”Ÿæˆä¸€ä¸ªéšæœºæ•° 0.073ï¼Œè¿™æ¬¡è¯¥éšæœºæ•°ä½äº Îµï¼Œå› æ­¤ä»çŠ¶æ€ 0-2 ä¸­å¯ç”¨çš„éšæœºæ“ä½œä¸­é€‰æ‹©ä¸€ä¸ªéšæœºæ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "10â€…â€…â€…Beyond Prediction: Unsupervised Learning",
            "zh": "10 è¶…è¶Šé¢„æµ‹ï¼šæ— ç›‘ç£å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "The next stage is to backpropagate the Î´s for the neurons in the network.",
            "zh": "ä¸‹ä¸€é˜¶æ®µæ˜¯åå‘ä¼ æ’­ç½‘ç»œä¸­ç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table shows the information gain calculated when each descriptive feature is used to predict the membership of a single cluster versus the rest of the population.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†å½“ä½¿ç”¨æ¯ä¸ªæè¿°æ€§ç‰¹å¾æ¥é¢„æµ‹å•ä¸ªèšç±»ä¸å…¶ä½™èšç±»çš„æˆå‘˜æ—¶è®¡ç®—çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "5â€…â€…â€…Similarity-Based Learning",
            "zh": "5 åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "5.2.1â€…â€…â€…Feature Space",
            "zh": "5.2.1 åŠŸèƒ½ç©ºé—´"
        }
    },
    {
        "translation": {
            "en": "To fit the normal distribution to the set of instances where FRAUD = false, we compute the sample mean and sample standard deviation for the ACCOUNT BALANCE feature for this set of instances and set the parameters of the normal distribution to these values.",
            "zh": "ä¸ºäº†å°†æ­£æ€åˆ†å¸ƒæ‹Ÿåˆåˆ° FRAUD = false çš„å®ä¾‹é›†ï¼Œæˆ‘ä»¬è®¡ç®—äº†è¿™ç»„å®ä¾‹çš„ ACCOUNT BALANCE ç‰¹å¾çš„æ ·æœ¬å‡å€¼å’Œæ ·æœ¬æ ‡å‡†å·®ï¼Œå¹¶å°†æ­£æ€åˆ†å¸ƒçš„å‚æ•°è®¾ç½®ä¸ºè¿™äº›å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each known animal, you count how many features it has in common with the unknown animal.",
            "zh": "å¯¹äºæ¯ç§å·²çŸ¥åŠ¨ç‰©ï¼Œæ‚¨å¯ä»¥è®¡ç®—å®ƒä¸æœªçŸ¥åŠ¨ç‰©æœ‰å¤šå°‘å…±åŒç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "augment data, 599, 629",
            "zh": "å¢å¼ºæ•°æ®ï¼Œ599,629"
        }
    },
    {
        "translation": {
            "en": "credit scoring, 538, 553, 563",
            "zh": "ä¿¡ç”¨è¯„åˆ†ï¼Œ538ã€553ã€563"
        }
    },
    {
        "translation": {
            "en": "or slightly more succinctly:",
            "zh": "æˆ–è€…æ›´ç®€æ´ä¸€ç‚¹ï¼š"
        }
    },
    {
        "translation": {
            "en": "5.4.2â€ƒEfficient Memory Search",
            "zh": "5.4.2 é«˜æ•ˆå†…å­˜æœç´¢"
        }
    },
    {
        "translation": {
            "en": "As a result, the model is unable to return a prediction for this query.",
            "zh": "å› æ­¤ï¼Œæ¨¡å‹æ— æ³•è¿”å›æ­¤æŸ¥è¯¢çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset is composed of n instances, (d1, t1) to (dn, tn), where d is a set of m descriptive features, and t is a target feature.",
            "zh": "æ•°æ®é›†ç”± n ä¸ªå®ä¾‹ ï¼ˆd1ï¼Œ t1ï¼‰ åˆ° ï¼ˆdnï¼Œ tnï¼‰ ç»„æˆï¼Œå…¶ä¸­ d æ˜¯ä¸€ç»„ m æè¿°æ€§ç‰¹å¾ï¼Œt æ˜¯ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the term âˆ‚â„°/âˆ‚ak connects the activation of the neuron ak to the output error of the network â„°.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯æœ¯è¯­ âˆ‚E/âˆ‚ak å°†ç¥ç»å…ƒ ak çš„æ¿€æ´»ä¸ç½‘ç»œ E çš„è¾“å‡ºé”™è¯¯è”ç³»èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "If you lie too far toward the back of the board, the board will sink and create so much drag that even big waves will pass by, leaving you behind.",
            "zh": "å¦‚æœä½ ç¦»å†²æµªæ¿çš„åé¢å¤ªè¿œï¼Œå†²æµªæ¿ä¼šä¸‹æ²‰å¹¶äº§ç”Ÿå¾ˆå¤§çš„é˜»åŠ›ï¼Œå³ä½¿æ˜¯å¤§æµªä¹Ÿä¼šç»è¿‡ï¼ŒæŠŠä½ ç”©åœ¨åé¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The big idea in deep learning is to develop computational models that are inspired by the structure and operations of the human brain.",
            "zh": "æ·±åº¦å­¦ä¹ çš„ä¸»è¦ç†å¿µæ˜¯å¼€å‘å—äººè„‘ç»“æ„å’Œæ“ä½œå¯å‘çš„è®¡ç®—æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, a feature is included that expresses the variety of different claim types made by the claimant in the past.",
            "zh": "æœ€åï¼Œè¿˜åŒ…æ‹¬ä¸€ä¸ªåŠŸèƒ½ï¼Œè¡¨ç¤ºç´¢èµ”äººè¿‡å»æå‡ºçš„å„ç§ä¸åŒç´¢èµ”ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVFLUX_U/G/R/I/Z",
            "zh": "DEVFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The next step in the algorithm is to calculate the average distance from d1 to each member of the other two clusters, ğ’2 and ğ’3â€”the inter-cluster distances. The distances from d1 to the members of ğ’2 are",
            "zh": "è¯¥ç®—æ³•çš„ä¸‹ä¸€æ­¥æ˜¯è®¡ç®—ä» d1 åˆ°å…¶ä»–ä¸¤ä¸ªèšç±» C2 å’Œ C3 çš„æ¯ä¸ªæˆå‘˜çš„å¹³å‡è·ç¦»ï¼Œå³èšç±»é—´è·ç¦»ã€‚ä» d1 åˆ° C2 æˆå‘˜çš„è·ç¦»ä¸º"
        }
    },
    {
        "translation": {
            "en": "All the examples that we have looked at so far have been regression problems. To create a neural network that can predict a multi-level categorical feature, we make three adjustments:",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çœ‹åˆ°çš„æ‰€æœ‰ç¤ºä¾‹éƒ½æ˜¯å›å½’é—®é¢˜ã€‚ä¸ºäº†åˆ›å»ºä¸€ä¸ªå¯ä»¥é¢„æµ‹å¤šçº§åˆ†ç±»ç‰¹å¾çš„ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸‰ä¸ªè°ƒæ•´ï¼š"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, co-absences arenâ€™t that meaningful.",
            "zh": "ç„¶è€Œï¼Œæœ‰æ—¶ï¼Œå…±åŒç¼ºå¸­å¹¶æ²¡æœ‰é‚£ä¹ˆæœ‰æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.2",
            "zh": "å›¾ 4.2"
        }
    },
    {
        "translation": {
            "en": "Looking at the decision trees in Figures 4.4(a)[122] and 4.4(b)[122], we notice that the tree in Figure 4.4(a)[122] performs tests on two features in order to make a prediction, whereas the decision tree in Figure 4.4(b)[122] needs to test only the value of one feature.",
            "zh": "æŸ¥çœ‹å›¾4.4ï¼ˆaï¼‰[122]å’Œå›¾4.4ï¼ˆbï¼‰[122]ä¸­çš„å†³ç­–æ ‘ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°å›¾4.4ï¼ˆaï¼‰[122]ä¸­çš„å†³ç­–æ ‘å¯¹ä¸¤ä¸ªç‰¹å¾è¿›è¡Œæµ‹è¯•ä»¥åšå‡ºé¢„æµ‹ï¼Œè€Œå›¾4.4ï¼ˆbï¼‰[122]ä¸­çš„å†³ç­–æ ‘åªéœ€è¦æµ‹è¯•ä¸€ä¸ªç‰¹å¾çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the remainder of this section, we examine this in some detail.",
            "zh": "åœ¨æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å¯¹æ­¤è¿›è¡Œä¸€äº›è¯¦ç»†çš„ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Following this action it was updated as follows:",
            "zh": "åœ¨æ­¤æ“ä½œä¹‹åï¼Œå®ƒå·²æ›´æ–°å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "11.1â€ƒBig Idea",
            "zh": "11.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "For example, the density histograms in Figure 9.10[558] show the distributions of prediction scores for the spam and ham target levels based on the data in Table 9.11[557].",
            "zh": "ä¾‹å¦‚ï¼Œå›¾ 9.10[558] ä¸­çš„å¯†åº¦ç›´æ–¹å›¾æ˜¾ç¤ºäº†åŸºäºè¡¨ 9.11[557] ä¸­çš„æ•°æ®çš„åƒåœ¾é‚®ä»¶å’Œç«è…¿ç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 7.3.3[328] we illustrated the impact of a learning rate parameter on the gradient descent algorithm.",
            "zh": "åœ¨ç¬¬ 7.3.3 èŠ‚[328]ä¸­ï¼Œæˆ‘ä»¬è¯´æ˜äº†å­¦ä¹ ç‡å‚æ•°å¯¹æ¢¯åº¦ä¸‹é™ç®—æ³•çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "confusion matrix, 537, 553, 572, 591",
            "zh": "æ··æ·†çŸ©é˜µï¼Œ 537ï¼Œ 553ï¼Œ 572ï¼Œ 591"
        }
    },
    {
        "translation": {
            "en": "Reagen, Brandon, Robert Adolf, Paul Whatmough, Gu-Yeon Wei, and David Brooks. 2017. Deep learning for computer architects. Morgan and Claypool.",
            "zh": "é‡Œæ ¹ã€å¸ƒå…°ç™»ã€ç½—ä¼¯ç‰¹Â·é˜¿é“å¤«ã€ä¿ç½—Â·æ²ƒç‰¹è«ã€é­è°·å¦å’Œå¤§å«Â·å¸ƒé²å…‹æ–¯ã€‚2017. é¢å‘è®¡ç®—æœºæ¶æ„å¸ˆçš„æ·±åº¦å­¦ä¹ .æ‘©æ ¹å’Œå…‹è±æ™®å°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.2",
            "zh": "å›¾ 6.2"
        }
    },
    {
        "translation": {
            "en": "Anything that the analyst can imagine can be implemented.",
            "zh": "åˆ†æå¸ˆå¯ä»¥æƒ³è±¡åˆ°çš„ä»»ä½•äº‹æƒ…éƒ½å¯ä»¥å®æ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Samples of the handwritten digit images from the MNIST dataset. Image attribution: Josef Steppan, used here under the Creative Commons Attribution-Share Alike 4.0 International license https://creativecommons.org/licenses/by-sa/4.0) and was sourced via Wikimedia Commons https://commons.wikimedia.org/wiki/File:MnistExamples.png.",
            "zh": "æ¥è‡ªMNISTæ•°æ®é›†çš„æ‰‹å†™æ•°å­—å›¾åƒæ ·æœ¬ã€‚å›¾ç‰‡å½’å±ï¼šçº¦ç‘Ÿå¤«Â·æ–¯è’‚èŠ¬æ½˜ï¼ˆJosef Steppanï¼‰ï¼Œæ­¤å¤„æ ¹æ®çŸ¥è¯†å…±äº«ç½²å-ç›¸åŒæ–¹å¼å…±äº«4.0å›½é™…è®¸å¯ https://creativecommons.org/licenses/by-sa/4.0ï¼‰ä½¿ç”¨ï¼Œæ¥æºäºç»´åŸºå…±äº«èµ„æº https://commons.wikimedia.org/wiki/File:MnistExamples.pngã€‚"
        }
    },
    {
        "translation": {
            "en": "If we treat the evidence events as conditionally independent given the target feature, however, then we can factorize the evidence into its component events and calculate probabilities for each of these events separately.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çš„æƒ…å†µä¸‹å°†è¯æ®äº‹ä»¶è§†ä¸ºæ¡ä»¶ç‹¬ç«‹çš„äº‹ä»¶ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†è¯æ®åˆ†è§£ä¸ºå…¶ç»„ä»¶äº‹ä»¶ï¼Œå¹¶åˆ†åˆ«è®¡ç®—æ¯ä¸ªäº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "where W are the network weights; and ti, the target feature value, is defined as the actual return earned from taking an action. We can calculate a gradient of this function",
            "zh": "å…¶ä¸­ W æ˜¯ç½‘ç»œæƒé‡;è€Œ Tiï¼Œå³ç›®æ ‡ç‰¹å¾å€¼ï¼Œå®šä¹‰ä¸ºé€šè¿‡é‡‡å–è¡ŒåŠ¨è·å¾—çš„å®é™…å›æŠ¥ã€‚æˆ‘ä»¬å¯ä»¥è®¡ç®—è¿™ä¸ªå‡½æ•°çš„æ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic is calculated by determining the maximum difference between the cumulative probability distributions for the positive and negative target levels. This can be given formally as",
            "zh": "K-S ç»Ÿè®¡é‡æ˜¯é€šè¿‡ç¡®å®šæ­£ç›®æ ‡æ°´å¹³å’Œè´Ÿç›®æ ‡æ°´å¹³çš„ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„æœ€å¤§å·®å€¼æ¥è®¡ç®—çš„ã€‚è¿™å¯ä»¥æ­£å¼ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10",
            "zh": "å›¾ 5.10"
        }
    },
    {
        "translation": {
            "en": "DEVFLUXIVAR_U/G/R/I/Z",
            "zh": "DEVFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This can help indicate which descriptive features might be useful for predicting a target feature and help find pairs of descriptive features that are closely related.",
            "zh": "è¿™æœ‰åŠ©äºæŒ‡ç¤ºå“ªäº›æè¿°æ€§ç‰¹å¾å¯èƒ½æœ‰åŠ©äºé¢„æµ‹ç›®æ ‡ç‰¹å¾ï¼Œå¹¶å¸®åŠ©æ‰¾åˆ°å¯†åˆ‡ç›¸å…³çš„æè¿°æ€§ç‰¹å¾å¯¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.44",
            "zh": "0.44"
        }
    },
    {
        "translation": {
            "en": "Before presenting the formal version of this, it is worth stating the intuition.",
            "zh": "åœ¨ä»‹ç»æ­£å¼ç‰ˆæœ¬ä¹‹å‰ï¼Œå€¼å¾—è¯´æ˜ä¸€ä¸‹ç›´è§‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cohenâ€™s kappa, 726",
            "zh": "ç§‘æ©çš„æ²³ç«¥ï¼Œ726"
        }
    },
    {
        "translation": {
            "en": "Having used the measures of central tendency to describe where our data is centered, we will now turn our attention to the variation in our data.",
            "zh": "åœ¨ä½¿ç”¨é›†ä¸­è¶‹åŠ¿çš„åº¦é‡æ¥æè¿°æˆ‘ä»¬çš„æ•°æ®ä¸­å¿ƒä½ç½®ä¹‹åï¼Œæˆ‘ä»¬ç°åœ¨å°†æ³¨æ„åŠ›è½¬å‘æ•°æ®çš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, Chapter 5 (Similarity-Based Learning) and/or 6 (Probability-Based Learning) could be used instead.",
            "zh": "ä½†æ˜¯ï¼Œå¯ä»¥ä½¿ç”¨ç¬¬ 5 ç« ï¼ˆåŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ ï¼‰å’Œ/æˆ–ç¬¬ 6 ç« ï¼ˆåŸºäºæ¦‚ç‡çš„å­¦ä¹ ï¼‰æ¥ä»£æ›¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Much of the focus of machine learning is on developing the single most accurate prediction model possible for a given task. The techniques we introduce in this section take a slightly different approach. Rather than creating a single model, they generate a set of models and then make predictions by aggregating the outputs of these models. A prediction model that is composed of a set of models is called a model ensemble.",
            "zh": "æœºå™¨å­¦ä¹ çš„å¤§éƒ¨åˆ†é‡ç‚¹æ˜¯ä¸ºç»™å®šä»»åŠ¡å¼€å‘æœ€å‡†ç¡®çš„é¢„æµ‹æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­ä»‹ç»çš„æŠ€æœ¯é‡‡ç”¨çš„æ–¹æ³•ç•¥æœ‰ä¸åŒã€‚ä»–ä»¬ä¸æ˜¯åˆ›å»ºå•ä¸ªæ¨¡å‹ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ç»„æ¨¡å‹ï¼Œç„¶åé€šè¿‡èšåˆè¿™äº›æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹ã€‚ç”±ä¸€ç»„æ¨¡å‹ç»„æˆçš„é¢„æµ‹æ¨¡å‹ç§°ä¸ºæ¨¡å‹é›†æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "On Line 8[420] the bias inputs vector and the matrix of activations from the previous layer Alâˆ’1 are vertically concatenated so that the bias inputs are now stored in the first row of Alâˆ’1; we use the notation [v;A] to represent the vertical concatenation of the vector/matrix v and A.",
            "zh": "åœ¨ç¬¬ 8 è¡Œ[420]ä¸Šï¼Œåç½®è¾“å…¥çŸ¢é‡å’Œæ¥è‡ªå‰ä¸€å±‚ Alâˆ’1 çš„æ¿€æ´»çŸ©é˜µå‚ç›´è¿æ¥ï¼Œå› æ­¤åç½®è¾“å…¥ç°åœ¨å­˜å‚¨åœ¨ Alâˆ’1 çš„ç¬¬ä¸€è¡Œä¸­;æˆ‘ä»¬ä½¿ç”¨ç¬¦å· [v;A] æ¥è¡¨ç¤ºå‘é‡/çŸ©é˜µ v å’Œ A çš„å‚ç›´è¿æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.1â€…â€…â€…Matching animals you remember to the features of the unknown animal described by the sailor.",
            "zh": "5.1 å°†ä½ è®°å¾—çš„åŠ¨ç‰©ä¸æ°´æ‰‹æè¿°çš„æœªçŸ¥åŠ¨ç‰©çš„ç‰¹å¾ç›¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "A partial derivative (denoted by the symbol âˆ‚) of a function of more than one variable is its derivative with respect to one of those variables with the other variables held constant.",
            "zh": "ä¸€ä¸ªä»¥ä¸Šå˜é‡çš„å‡½æ•°çš„åå¯¼æ•°ï¼ˆç”¨ç¬¦å· âˆ‚ è¡¨ç¤ºï¼‰æ˜¯å…¶ç›¸å¯¹äºå…¶ä¸­ä¸€ä¸ªå˜é‡çš„å¯¼æ•°ï¼Œè€Œå…¶ä»–å˜é‡ä¿æŒä¸å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dunn, Joseph C. 1974. Well-separated clusters and optimal fuzzy partitions. Journal of Cybernetics 4 (1): 95â€“104.",
            "zh": "é‚“æ©ï¼Œçº¦ç‘Ÿå¤« C. 1974 å¹´ã€‚åˆ†ç¦»è‰¯å¥½çš„èšç±»å’Œæœ€ä½³çš„æ¨¡ç³Šåˆ†åŒºã€‚æ§åˆ¶è®ºæ‚å¿—4ï¼ˆ1ï¼‰ï¼š95-104ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first iteration of training is done on the first mini-batch in the sequence, the second iteration on the second mini-batch, and so on until the epoch is completed.",
            "zh": "è®­ç»ƒçš„ç¬¬ä¸€æ¬¡è¿­ä»£åœ¨åºåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªå°æ‰¹é‡ä¸Šå®Œæˆï¼Œç¬¬äºŒæ¬¡è¿­ä»£åœ¨ç¬¬äºŒä¸ªå°æ‰¹é‡ä¸Šå®Œæˆï¼Œä¾æ­¤ç±»æ¨ï¼Œç›´åˆ°çºªå…ƒå®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the best policy for Conor to take for learning is to balance exploration and exploitation.",
            "zh": "ç›¸åï¼Œåº·çº³å­¦ä¹ çš„æœ€ä½³ç­–ç•¥æ˜¯å¹³è¡¡æ¢ç´¢å’Œå¼€å‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, both the trees are attempting to generalize beyond the dataset.",
            "zh": "å› æ­¤ï¼Œè¿™ä¸¤æ£µæ ‘éƒ½è¯•å›¾åœ¨æ•°æ®é›†ä¹‹å¤–è¿›è¡Œæ³›åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The training phase needed to build a nearest neighbor model is very simple and just involves storing all the training instances in memory.",
            "zh": "æ„å»ºæœ€è¿‘é‚»æ¨¡å‹æ‰€éœ€çš„è®­ç»ƒé˜¶æ®µéå¸¸ç®€å•ï¼Œåªéœ€å°†æ‰€æœ‰è®­ç»ƒå®ä¾‹å­˜å‚¨åœ¨å†…å­˜ä¸­å³å¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "inverse covariance matrix, 219, 242",
            "zh": "é€†åæ–¹å·®çŸ©é˜µï¼Œ 219ï¼Œ 242"
        }
    },
    {
        "translation": {
            "en": "In this clustering d1 is a member of ğ’1. The first step is calculating the silhouette value for d1 is to calculate a(i), the average distance between d1 and the other members of cluster ğ’1. The distance from d1 to each other member of ğ’1 is",
            "zh": "åœ¨æ­¤èšç±»ä¸­ï¼Œd1 æ˜¯ C1 çš„æˆå‘˜ã€‚ç¬¬ä¸€æ­¥æ˜¯è®¡ç®— d1 çš„è½®å»“å€¼ï¼Œå³è®¡ç®— aï¼ˆiï¼‰ï¼Œå³ d1 ä¸èšç±» C1 çš„å…¶ä»–æˆå‘˜ä¹‹é—´çš„å¹³å‡è·ç¦»ã€‚ä» d1 åˆ° C1 çš„æ¯ä¸ªå…¶ä»–æˆå‘˜çš„è·ç¦»ä¸º"
        }
    },
    {
        "translation": {
            "en": "Note that all the neurons in this network are ReLU, so each of these activations was calculated in each neuron by passing the result of the weighted sum calculation through a rectified linear activation function (similar to the calculation listed in Equation (8.102)[494]).",
            "zh": "è¯·æ³¨æ„ï¼Œè¯¥ç½‘ç»œä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½æ˜¯ ReLUï¼Œå› æ­¤æ¯ä¸ªç¥ç»å…ƒä¸­çš„æ¯ä¸€ä¸ªæ¿€æ´»éƒ½æ˜¯é€šè¿‡é€šè¿‡ä¿®æ­£çº¿æ€§æ¿€æ´»å‡½æ•°ä¼ é€’åŠ æƒå’Œè®¡ç®—ç»“æœæ¥è®¡ç®—çš„ï¼ˆç±»ä¼¼äºå…¬å¼ ï¼ˆ8.102ï¼‰[494] ä¸­åˆ—å‡ºçš„è®¡ç®—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can demonstrate how this retrieval algorithm works by showing how the algorithm finds the nearest neighbor for a query instance with SPEED = 6.00 and AGILITY = 3.50.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡å±•ç¤ºç®—æ³•å¦‚ä½•ä¸º SPEED = 6.00 å’Œ AGILITY = 3.50 çš„æŸ¥è¯¢å®ä¾‹æŸ¥æ‰¾æœ€è¿‘é‚»æ¥æ¼”ç¤ºæ­¤æ£€ç´¢ç®—æ³•çš„å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important that analytics professionals have a basic grasp of the work their scientific partners are undertaking so that they can converse fluently with them.",
            "zh": "é‡è¦çš„æ˜¯ï¼Œåˆ†æä¸“ä¸šäººå‘˜å¿…é¡»å¯¹ä»–ä»¬çš„ç§‘å­¦åˆä½œä¼™ä¼´æ­£åœ¨å¼€å±•çš„å·¥ä½œæœ‰ä¸€ä¸ªåŸºæœ¬çš„äº†è§£ï¼Œä»¥ä¾¿ä»–ä»¬èƒ½å¤Ÿä¸ä»–ä»¬æµåˆ©åœ°äº¤è°ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "All instances are normalized so as to lie on a hypersphere of radius 1.0 with its center at the origin of the feature space.",
            "zh": "æ‰€æœ‰å®ä¾‹éƒ½ç»è¿‡å½’ä¸€åŒ–ï¼Œä»¥ä¾¿ä½äºåŠå¾„ä¸º 1.0 çš„è¶…çƒä½“ä¸Šï¼Œå…¶ä¸­å¿ƒä½äºç‰¹å¾ç©ºé—´çš„åŸç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a simple random sample, each item in the population is equally likely to make it into the sample.",
            "zh": "åœ¨ç®€å•çš„éšæœºæ ·æœ¬ä¸­ï¼Œæ€»ä½“ä¸­çš„æ¯ä¸ªé¡¹ç›®è¿›å…¥æ ·æœ¬çš„å¯èƒ½æ€§éƒ½ç›¸ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two different networks are used in the training process: an action-value behavior network that is used to predict the values of actions for making decisions and an action-value target network that is used to predict the value of taking subsequent actions in subsequent states when generating target feature values.",
            "zh": "è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†ä¸¤ç§ä¸åŒçš„ç½‘ç»œï¼šä¸€ç§æ˜¯ç”¨äºé¢„æµ‹ç”¨äºåšå‡ºå†³ç­–çš„åŠ¨ä½œå€¼çš„åŠ¨ä½œ-ä»·å€¼è¡Œä¸ºç½‘ç»œï¼Œå¦ä¸€ç§æ˜¯ç”¨äºé¢„æµ‹ç”Ÿæˆç›®æ ‡ç‰¹å¾å€¼æ—¶åœ¨åç»­çŠ¶æ€ä¸‹é‡‡å–åç»­åŠ¨ä½œçš„ä»·å€¼çš„åŠ¨ä½œ-ä»·å€¼ç›®æ ‡ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "We write the model trained at the first iteration of gradient boosting",
            "zh": "æˆ‘ä»¬ç¼–å†™äº†åœ¨æ¢¯åº¦æå‡çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­è®­ç»ƒçš„æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Samet, Hanan. 1990. The design and analysis of spatial data structures, Vol. 199. Addison-Wesley.",
            "zh": "è¨æ¢…ç‰¹ï¼Œå“ˆå—ã€‚1990. ç©ºé—´æ•°æ®ç»“æ„çš„è®¾è®¡ä¸åˆ†æï¼Œ Vol. 199.è‰¾è¿ªç”Ÿ-å«æ–¯ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This gives a series of discrete steps that make up an episode",
            "zh": "è¿™ç»™å‡ºäº†æ„æˆå‰§é›†çš„ä¸€ç³»åˆ—ç¦»æ•£æ­¥éª¤"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the grass growth dataset from Table 7.9[351].",
            "zh": "è¡¨7.9[351]ä¸­è‰ç”Ÿé•¿æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem here is that our dataset is not large enough to be truly representative of the meningitis diagnosis scenario, and our model is overfitting to the training data.",
            "zh": "è¿™é‡Œçš„é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†ä¸å¤Ÿå¤§ï¼Œæ— æ³•çœŸæ­£ä»£è¡¨è„‘è†œç‚è¯Šæ–­åœºæ™¯ï¼Œè€Œä¸”æˆ‘ä»¬çš„æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10(a)[340] shows a scatter plot of this dataset in which we can see that there is a good separation between the two types of generator.",
            "zh": "å›¾7.10ï¼ˆaï¼‰[340]æ˜¾ç¤ºäº†è¯¥æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œä»ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ç§ç±»å‹çš„ç”Ÿæˆå™¨ä¹‹é—´å­˜åœ¨è‰¯å¥½çš„åˆ†ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "You ask him to describe the animal to you, and he explains that he didnâ€™t see it very well because, as he approached it, the animal growled at him, so he didnâ€™t approach too closely.",
            "zh": "ä½ è®©ä»–å‘ä½ æè¿°è¿™åªåŠ¨ç‰©ï¼Œä»–è§£é‡Šè¯´ä»–çœ‹å¾—ä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œå› ä¸ºå½“ä»–æ¥è¿‘å®ƒæ—¶ï¼ŒåŠ¨ç‰©å¯¹ä»–å’†å“®ï¼Œæ‰€ä»¥ä»–æ²¡æœ‰é è¿‘å¤ªè¿‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.2(a)[644] shows these states and how an individual can move between them.7",
            "zh": "å›¾11.2ï¼ˆaï¼‰[644]æ˜¾ç¤ºäº†è¿™äº›çŠ¶æ€ä»¥åŠä¸ªä½“å¦‚ä½•åœ¨å®ƒä»¬ä¹‹é—´ç§»åŠ¨7ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What target level will a naive Bayes model predict for the following query document: â€œchristmas family funâ€?",
            "zh": "ï¼ˆbï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹ä»¥ä¸‹æŸ¥è¯¢æ–‡æ¡£çš„ç›®æ ‡æ°´å¹³ï¼šâ€œåœ£è¯å®¶åº­ä¹è¶£â€ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Mnih, Volodymyr, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.",
            "zh": "Mnihã€Volodymyrã€Koray Kavukcuogluã€David Silverã€Alex Gravesã€Ioannis Antonoglouã€Daan Wierstra å’Œ Martin Riedmillerã€‚2013. ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ç©é›…è¾¾åˆ©.arXiv é¢„å°æœ¬ arXivï¼š1312.5602ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, the variance of the z values across the neurons in HL1 is var(Z(HL1)) = 2 Ã— 0.04 = 0.08 (i.e., Ïƒ â‰ˆ 0.283), and this is then scaled by 100 Ã— 0.04 = 4 at each of the other hidden layers in the network.",
            "zh": "å› æ­¤ï¼ŒHL1 ä¸­ç¥ç»å…ƒçš„ z å€¼æ–¹å·®ä¸º varï¼ˆZï¼ˆHL1ï¼‰ï¼‰ = 2 Ã— 0.04 = 0.08ï¼ˆå³ Ïƒ â‰ˆ 0.283ï¼‰ï¼Œç„¶ååœ¨ç½‘ç»œä¸­æ¯ä¸ªå…¶ä»–éšè—å±‚å¤„å°†å…¶æŒ‰ 100 Ã— 0.04 = 4 è¿›è¡Œç¼©æ”¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "disease diagnosis, 538",
            "zh": "ç–¾ç—…è¯Šæ–­ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "3.177",
            "zh": "3.177"
        }
    },
    {
        "translation": {
            "en": "Sarah had a task that she wanted to get better at, and so she practiced it many times.",
            "zh": "èæ‹‰æœ‰ä¸€é¡¹å¥¹æƒ³åšå¾—æ›´å¥½çš„ä»»åŠ¡ï¼Œæ‰€ä»¥å¥¹ç»ƒä¹ äº†å¾ˆå¤šæ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The technical term to describe a dataset in which most of the features have zero values is sparse data.",
            "zh": "ç”¨äºæè¿°å¤§å¤šæ•°è¦ç´ å€¼ä¸ºé›¶çš„æ•°æ®é›†çš„æŠ€æœ¯æœ¯è¯­æ˜¯ç¨€ç–æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The parameters required for the normal, exponential, and mixture of Gaussians PDFs are shown in Table 6.10[271].",
            "zh": "é«˜æ–¯PDFçš„æ­£æ€ã€æŒ‡æ•°å’Œæ··åˆæ‰€éœ€çš„å‚æ•°å¦‚è¡¨6.10æ‰€ç¤º[271]ã€‚"
        }
    },
    {
        "translation": {
            "en": "As time went by, Sarah found herself feeling this excitement more and more often as she became better and better at quickly assessing her situation when the blindfold was cleared and making better decisions about which direction to step in.",
            "zh": "éšç€æ—¶é—´çš„æµé€ï¼Œèæ‹‰å‘ç°è‡ªå·±è¶Šæ¥è¶Šé¢‘ç¹åœ°æ„Ÿå—åˆ°è¿™ç§å…´å¥‹ï¼Œå› ä¸ºå¥¹è¶Šæ¥è¶Šå–„äºåœ¨çœ¼ç½©è¢«æ¸…é™¤æ—¶å¿«é€Ÿè¯„ä¼°è‡ªå·±çš„å¤„å¢ƒï¼Œå¹¶æ›´å¥½åœ°å†³å®šå‘å“ªä¸ªæ–¹å‘è¿ˆè¿›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many modern convolutional networks use a max function that simply returns the maximum value in the region of the feature map covered by the local receptive field.",
            "zh": "è®¸å¤šç°ä»£å·ç§¯ç½‘ç»œéƒ½ä½¿ç”¨ max å‡½æ•°ï¼Œè¯¥å‡½æ•°ä»…è¿”å›å±€éƒ¨æ„Ÿå—é‡æ‰€è¦†ç›–çš„ç‰¹å¾å›¾åŒºåŸŸä¸­çš„æœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.6â€…â€…â€…Further Reading",
            "zh": "7.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "Concept drift is a phenomenon that occurs when the relationship between the target feature and the descriptive features changes over time.",
            "zh": "æ¦‚å¿µæ¼‚ç§»æ˜¯å½“ç›®æ ‡ç‰¹å¾å’Œæè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å…³ç³»éšæ—¶é—´å˜åŒ–æ—¶å‘ç”Ÿçš„ç°è±¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recalling that the error surface is defined by the error function, L2 (given in Equation (7.10)[320]), the gradient at any point on this error surface is given by the value of the partial derivative of the error function with respect to a particular weight at that point.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œè¯¯å·®é¢ç”±è¯¯å·®å‡½æ•° L2 å®šä¹‰ï¼ˆåœ¨ç­‰å¼ ï¼ˆ7.10ï¼‰[320] ä¸­ç»™å‡ºï¼‰ï¼Œè¯¥è¯¯å·®æ›²é¢ä¸Šä»»ä½•ç‚¹çš„æ¢¯åº¦ç”±è¯¯å·®å‡½æ•°ç›¸å¯¹äºè¯¥ç‚¹ç‰¹å®šæƒé‡çš„åå¯¼æ•°å€¼ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROFLUXIVAR_U/G/R/I/Z",
            "zh": "PETROFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "conditional probability, 245, 246, 251, 757, 759, 759, 762",
            "zh": "æ¡ä»¶æ¦‚ç‡ï¼Œ 245ï¼Œ 246ï¼Œ 251ï¼Œ 757ï¼Œ 759ï¼Œ 759ï¼Œ 762"
        }
    },
    {
        "translation": {
            "en": "Each cluster centroid is then updated by calculating the mean value of each descriptive feature for all instances that are a member of the cluster. For example, there are nine members of ğ’1: {d1,d2,d3,d6,d8,d11,d13,d20,d24}. So, c1 is updated to",
            "zh": "ç„¶åï¼Œé€šè¿‡è®¡ç®—ä½œä¸ºèšç±»æˆå‘˜çš„æ‰€æœ‰å®ä¾‹çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„å¹³å‡å€¼æ¥æ›´æ–°æ¯ä¸ªèšç±»è´¨å¿ƒã€‚ä¾‹å¦‚ï¼ŒC1 æœ‰ 9 ä¸ªæˆå‘˜ï¼š{d1ï¼Œd2ï¼Œd3ï¼Œd6ï¼Œd8ï¼Œd11ï¼Œd13ï¼Œd20ï¼Œd24}ã€‚å› æ­¤ï¼Œc1 æ›´æ–°ä¸º"
        }
    },
    {
        "translation": {
            "en": "The easiest way to handle outliers is to use a clamp transformation. This clamps all values above an upper threshold and below a lower threshold to these threshold values, thus removing the offending outliers:",
            "zh": "å¤„ç†å¼‚å¸¸å€¼çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨é’³ä½å˜æ¢ã€‚è¿™ä¼šå°†é«˜äºä¸Šé™é˜ˆå€¼å’Œä½äºé˜ˆå€¼ä¸‹é™çš„æ‰€æœ‰å€¼é™åˆ¶åœ¨è¿™äº›é˜ˆå€¼ä¸Šï¼Œä»è€Œåˆ é™¤æœ‰é—®é¢˜çš„å¼‚å¸¸å€¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "Jocelyn performed the same baseline test on the three model types using this new dataset.",
            "zh": "Jocelyn ä½¿ç”¨è¿™ä¸ªæ–°æ•°æ®é›†å¯¹ä¸‰ç§æ¨¡å‹ç±»å‹æ‰§è¡Œäº†ç›¸åŒçš„åŸºçº¿æµ‹è¯•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subspace sampling further encourages the diversity of the trees within the ensemble and has the advantage of reducing the training time for each tree.",
            "zh": "å­ç©ºé—´é‡‡æ ·è¿›ä¸€æ­¥é¼“åŠ±äº†é›†åˆä¸­æ ‘çš„å¤šæ ·æ€§ï¼Œå¹¶å…·æœ‰å‡å°‘æ¯æ£µæ ‘çš„è®­ç»ƒæ—¶é—´çš„ä¼˜ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Later in this section we return to the question of how to counteract this property of weighted sum calculations.",
            "zh": "åœ¨æœ¬èŠ‚çš„åé¢ï¼Œæˆ‘ä»¬å°†å›åˆ°å¦‚ä½•æŠµæ¶ˆåŠ æƒå’Œè®¡ç®—çš„è¿™ä¸€ç‰¹æ€§çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "What makes predictive data analytics difficult, but also fascinating, is figuring out how to answer all the questions that surround the modeling phase of a project.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æä¹‹æ‰€ä»¥å›°éš¾ï¼Œä½†åˆä»¤äººç€è¿·çš„æ˜¯å¼„æ¸…æ¥šå¦‚ä½•å›ç­”å›´ç»•é¡¹ç›®å»ºæ¨¡é˜¶æ®µçš„æ‰€æœ‰é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "ä½¿ç”¨è£…è¢‹å’Œå­ç©ºé—´é‡‡æ ·åˆ›å»ºæ¨¡å‹é›†åˆçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "decision tree, 117, 121, 121, 169, 541, 554, 556, 732, 733, 735, 736",
            "zh": "å†³ç­–æ ‘ï¼Œ 117ï¼Œ 121ï¼Œ 121ï¼Œ 169ï¼Œ 541ï¼Œ 554ï¼Œ 556ï¼Œ 732ï¼Œ 733ï¼Œ 735ï¼Œ 736"
        }
    },
    {
        "translation": {
            "en": "10.7â€…â€…â€…The silhouette plot for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3).",
            "zh": "10.7 ä½¿ç”¨kå‡å€¼ç®—æ³•ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†æœ€ç»ˆèšç±»çš„è½®å»“å›¾ï¼ˆè¡¨10.1[604]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapter 10 is a new chapter covering the most important ideas and techniques in unsupervised learning. This chapter is one-half of a new part of the book, Beyond Prediction, that expands beyond the focus of the first edition on supervised learning to allow broader coverage of machine learning.",
            "zh": "ç¬¬10ç« æ˜¯ä¸€ä¸ªæ–°çš„ç« èŠ‚ï¼Œæ¶µç›–äº†æ— ç›‘ç£å­¦ä¹ ä¸­æœ€é‡è¦çš„æ€æƒ³å’ŒæŠ€æœ¯ã€‚æœ¬ç« æ˜¯æœ¬ä¹¦æ–°éƒ¨åˆ†â€œè¶…è¶Šé¢„æµ‹â€çš„ä¸€åŠï¼Œè¯¥éƒ¨åˆ†è¶…å‡ºäº†ç¬¬ä¸€ç‰ˆå¯¹ç›‘ç£å­¦ä¹ çš„å…³æ³¨èŒƒå›´ï¼Œä»è€Œæ‰©å¤§äº†æœºå™¨å­¦ä¹ çš„è¦†ç›–èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Lowercase letters represent a single feature (e.g., f, a, b, c â€¦).",
            "zh": "å°å†™å­—æ¯è¡¨ç¤ºå•ä¸ªç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œfã€aã€bã€c ç­‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Features recording salaries often follow a right skewed distribution, as most people are paid salaries near a well-defined central tendency, but there are usually a small number of people who are paid very large salaries.",
            "zh": "è®°å½•å·¥èµ„çš„ç‰¹å¾é€šå¸¸éµå¾ªå³åæ€åˆ†å¸ƒï¼Œå› ä¸ºå¤§å¤šæ•°äººçš„å·¥èµ„æ¥è¿‘æ˜ç¡®å®šä¹‰çš„ä¸­å¿ƒè¶‹åŠ¿ï¼Œä½†é€šå¸¸æœ‰å°‘æ•°äººçš„å·¥èµ„éå¸¸é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "target network freezing, 672",
            "zh": "ç›®æ ‡ç½‘ç»œå†»ç»“ï¼Œ672"
        }
    },
    {
        "translation": {
            "en": "Freund, Yoav, and Robert E. Schapire. 1995. A desicion-theoretic generalization of on-line learning and an application to boosting. In Computational Learning Theory, 23â€“37. Springer.",
            "zh": "Freundã€Yoav å’Œ Robert E. Schapireã€‚1995. åœ¨çº¿å­¦ä¹ çš„å†³ç­–ç†è®ºæ¨å¹¿åŠå…¶åœ¨æå‡ä¸­çš„åº”ç”¨.åœ¨è®¡ç®—å­¦ä¹ ç†è®ºä¸­ï¼Œ23-37ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Stepping through the processing of the network in Figure 8.5[392], the sequence of calculations necessary to generate the activations for the neurons in the hidden layer is illustrated in the top row of the figure.",
            "zh": "é€šè¿‡å›¾8.5[392]ä¸­ç½‘ç»œçš„å¤„ç†ï¼Œå›¾çš„é¡¶è¡Œæ˜¾ç¤ºäº†ä¸ºéšè—å±‚ä¸­çš„ç¥ç»å…ƒç”Ÿæˆæ¿€æ´»æ‰€éœ€çš„è®¡ç®—é¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "We also mentioned that this global minimum can be found at the point at which the partial derivatives of the error surface, with respect to the weights, are equal to zero.",
            "zh": "æˆ‘ä»¬è¿˜æåˆ°ï¼Œè¿™ä¸ªå…¨å±€æœ€å°å€¼å¯ä»¥åœ¨è¯¯å·®é¢çš„åå¯¼æ•°ç›¸å¯¹äºæƒé‡ç­‰äºé›¶çš„ç‚¹ä¸Šæ‰¾åˆ°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will use Russia as our query country for this question. The table below lists the descriptive features for Russia.",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨ä¿„ç½—æ–¯ä½œä¸ºè¿™ä¸ªé—®é¢˜çš„æŸ¥è¯¢å›½å®¶ã€‚ä¸‹è¡¨åˆ—å‡ºäº†ä¿„ç½—æ–¯çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The CPTs are shown in Figure 6.13[296].",
            "zh": "CPTå¦‚å›¾6.13æ‰€ç¤º[296]ã€‚"
        }
    },
    {
        "translation": {
            "en": "We also introduced the ID3 algorithm as a standard algorithm for inducing decision trees from a dataset.",
            "zh": "æˆ‘ä»¬è¿˜å¼•å…¥äº† ID3 ç®—æ³•ä½œä¸ºä»æ•°æ®é›†ä¸­è¯±å¯¼å†³ç­–æ ‘çš„æ ‡å‡†ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the correspondence between graphical and matrix representations of a neural network. This figure is inspired by Figure 3.9 of Kelleher (2019).",
            "zh": "ç¥ç»ç½‘ç»œçš„å›¾å½¢è¡¨ç¤ºå’ŒçŸ©é˜µè¡¨ç¤ºä¹‹é—´çš„å¯¹åº”å…³ç³»çš„å›¾ç¤ºã€‚è¯¥å›¾çš„çµæ„Ÿæ¥è‡ªKelleherï¼ˆ2019ï¼‰çš„å›¾3.9ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sloan Digital Sky Survey, 703",
            "zh": "ä»•é¾™æ•°å­—å·¡å¤©ï¼Œ703"
        }
    },
    {
        "translation": {
            "en": "Title: Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies / John D. Kelleher, Brian Mac Namee and Aoife Dâ€™Arcy.",
            "zh": "é¢˜ç›®ï¼šé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ åŸºç¡€ï¼šç®—æ³•ã€å·¥ä½œç¤ºä¾‹å’Œæ¡ˆä¾‹ç ”ç©¶ / John D. Kelleherã€Brian Mac Namee å’Œ Aoife D'Arcyã€‚"
        }
    },
    {
        "translation": {
            "en": "For ease of reading, the instances have been ordered in descending order of the score the model assigned to each instance.",
            "zh": "ä¸ºäº†ä¾¿äºé˜…è¯»ï¼Œå®ä¾‹å·²æŒ‰æ¨¡å‹åˆ†é…ç»™æ¯ä¸ªå®ä¾‹çš„åˆ†æ•°çš„é™åºæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "The player wins if their total is less than or equal to 22 and is greater than the dealerâ€™s total, or if the dealer goes bust.",
            "zh": "å¦‚æœç©å®¶çš„æ€»å’Œå°äºæˆ–ç­‰äº 22 ä¸”å¤§äºåº„å®¶çš„æ€»æ•°ï¼Œæˆ–è€…åº„å®¶ç ´äº§ï¼Œåˆ™ç©å®¶è·èƒœã€‚"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm builds the tree in a recursive, depth-first manner, beginning at the root node and working down to the leaf nodes.",
            "zh": "ID3 ç®—æ³•ä»¥é€’å½’ã€æ·±åº¦ä¼˜å…ˆçš„æ–¹å¼æ„å»ºæ ‘ï¼Œä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œä¸€ç›´åˆ°å¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) The following table shows handwritten examples of the digits 7 and 8 and their corresponding histogram values.",
            "zh": "ï¼ˆeï¼‰ ä¸‹è¡¨æ˜¾ç¤ºäº†æ•°å­— 7 å’Œ 8 çš„æ‰‹å†™ç¤ºä¾‹åŠå…¶ç›¸åº”çš„ç›´æ–¹å›¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In an experiment performed to capture this data, participants were shown a series of different images, and their neural responses were measured using electroencephalography (EEG).",
            "zh": "åœ¨ä¸ºæ•è·è¿™äº›æ•°æ®è€Œè¿›è¡Œçš„å®éªŒä¸­ï¼Œå‘å‚ä¸è€…å±•ç¤ºäº†ä¸€ç³»åˆ—ä¸åŒçš„å›¾åƒï¼Œå¹¶ä½¿ç”¨è„‘ç”µå›¾ï¼ˆEEGï¼‰æµ‹é‡äº†ä»–ä»¬çš„ç¥ç»ååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal of any feature selection approach is to identify the smallest subset of descriptive features that maintains overall model performance. Ideally, a feature selection approach will return the subset of features that includes the predictive and interacting features while excluding the irrelevant and redundant features.",
            "zh": "ä»»ä½•ç‰¹å¾é€‰æ‹©æ–¹æ³•çš„ç›®æ ‡éƒ½æ˜¯ç¡®å®šæè¿°æ€§ç‰¹å¾çš„æœ€å°å­é›†ï¼Œä»¥ä¿æŒæ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œç‰¹å¾é€‰æ‹©æ–¹æ³•å°†è¿”å›åŒ…å«é¢„æµ‹ç‰¹å¾å’Œäº¤äº’ç‰¹å¾çš„ç‰¹å¾å­é›†ï¼ŒåŒæ—¶æ’é™¤ä¸ç›¸å…³å’Œå†—ä½™ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Grayscale images are stored as a matrix of pixel values in the range [0,1] where 0 represents a black pixel and 1 represents a white one.",
            "zh": "ç°åº¦å›¾åƒå­˜å‚¨ä¸º [0,1] èŒƒå›´å†…çš„åƒç´ å€¼çŸ©é˜µï¼Œå…¶ä¸­ 0 è¡¨ç¤ºé»‘è‰²åƒç´ ï¼Œ1 è¡¨ç¤ºç™½è‰²åƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This choice is made by computing the information gain of the descriptive features in the training dataset.",
            "zh": "è¿™ç§é€‰æ‹©æ˜¯é€šè¿‡è®¡ç®—è®­ç»ƒæ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¥åšå‡ºçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.1â€…â€…The sample space for the domain of two dice.",
            "zh": "B.1 ä¸¤ä¸ªéª°å­åŸŸçš„æ ·æœ¬ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental information processing pattern within the forget gate can be characterized as passing the concatenated hxt vector through a layer of sigmoid neurons in order to generate a vector mask, and then using an elementwise product of this mask with the cell state to update (or filter) the cellâ€™s activations. This information processing pattern of creating a vector mask and then using it in an elementwise product to update another activation vector is present in both of the other gates in an LSTM.",
            "zh": "é—å¿˜é—¨å†…çš„åŸºæœ¬ä¿¡æ¯å¤„ç†æ¨¡å¼å¯ä»¥è¡¨å¾ä¸ºå°†ä¸²è”çš„ hxt å‘é‡é€šè¿‡ä¹™çŠ¶ç»“è‚ ç¥ç»å…ƒå±‚ä»¥ç”Ÿæˆå‘é‡æ©ç ï¼Œç„¶åä½¿ç”¨è¯¥æ©ç çš„å…ƒç´ ä¹˜ç§¯ä¸ç»†èƒçŠ¶æ€æ¥æ›´æ–°ï¼ˆæˆ–è¿‡æ»¤ï¼‰ç»†èƒçš„æ¿€æ´»ã€‚è¿™ç§åˆ›å»ºå‘é‡æ©ç ï¼Œç„¶ååœ¨é€å…ƒä¹˜ç§¯ä¸­ä½¿ç”¨å®ƒæ¥æ›´æ–°å¦ä¸€ä¸ªæ¿€æ´»å‘é‡çš„ä¿¡æ¯å¤„ç†æ¨¡å¼å­˜åœ¨äº LSTM çš„å…¶ä»–ä¸¤ä¸ªé—¨ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case the maximum values for TOTAL CLAIMED and NUM.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼ŒTOTAL CLAIM å’Œ NUM."
        }
    },
    {
        "translation": {
            "en": "One way to think about this process is that we change the dataset from two dimensions to a higher-dimensional space.",
            "zh": "è€ƒè™‘æ­¤è¿‡ç¨‹çš„ä¸€ç§æ–¹æ³•æ˜¯å°†æ•°æ®é›†ä»äºŒç»´ç©ºé—´æ›´æ”¹ä¸ºæ›´é«˜ç»´ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "index, 211, 212",
            "zh": "ç´¢å¼•ï¼Œ 211ï¼Œ 212"
        }
    },
    {
        "translation": {
            "en": "The decision tree resulting from splitting the data in Table 4.11[152] using the feature SEASON.",
            "zh": "ä½¿ç”¨ç‰¹å¾ SEASON æ‹†åˆ†è¡¨ 4.11[152] ä¸­çš„æ•°æ®ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplicity of the derivative of the logistic function is one of the reasons why the logistic function was such a popular activation function in neural networks: using logistic activation functions made it relatively easy to implement the backpropagation algorithm.",
            "zh": "é€»è¾‘å‡½æ•°å¯¼æ•°çš„ç®€å•æ€§æ˜¯é€»è¾‘å‡½æ•°åœ¨ç¥ç»ç½‘ç»œä¸­å¦‚æ­¤æµè¡Œçš„æ¿€æ´»å‡½æ•°çš„åŸå› ä¹‹ä¸€ï¼šä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ä½¿å¾—å®ç°åå‘ä¼ æ’­ç®—æ³•å˜å¾—ç›¸å¯¹å®¹æ˜“ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the time Jocelyn arrived, the SDSS pipeline included rule-based systems that could classify night sky objects into broad categoriesâ€”for example, stars and galaxies.",
            "zh": "åœ¨Jocelynåˆ°è¾¾æ—¶ï¼ŒSDSSç®¡é“åŒ…æ‹¬åŸºäºè§„åˆ™çš„ç³»ç»Ÿï¼Œå¯ä»¥å°†å¤œç©ºç‰©ä½“åˆ†ç±»ä¸ºå¤§ç±»ï¼Œä¾‹å¦‚æ’æ˜Ÿå’Œæ˜Ÿç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) What value will the Bayesian network predict for ALARM, given that there is a storm but we donâ€™t know if a burglar has broken in or where the cat is?",
            "zh": "ï¼ˆdï¼‰ è´å¶æ–¯ç½‘ç»œå¯¹ ALARM çš„é¢„æµ‹å€¼æ˜¯å¤šå°‘ï¼Œå‡è®¾æœ‰æš´é£é›¨ï¼Œä½†æˆ‘ä»¬ä¸çŸ¥é“çªƒè´¼æ˜¯å¦é—¯å…¥æˆ–çŒ«åœ¨å“ªé‡Œï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "0.84",
            "zh": "0.84"
        }
    },
    {
        "translation": {
            "en": "This makes sense because their activation will not have been used to generate the output of the model and so will not have contributed to the error of the model.",
            "zh": "è¿™æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå®ƒä»¬çš„æ¿€æ´»ä¸ä¼šç”¨äºç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºï¼Œå› æ­¤ä¸ä¼šå¯¼è‡´æ¨¡å‹çš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Functionally, an individual neuron can be understood as a simple signal processing system.",
            "zh": "ä»åŠŸèƒ½ä¸Šè®²ï¼Œå•ä¸ªç¥ç»å…ƒå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªç®€å•çš„ä¿¡å·å¤„ç†ç³»ç»Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "In a predictive analytics task, we will often be interested in calculating the probability of more than one event.",
            "zh": "åœ¨é¢„æµ‹åˆ†æä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¯¹è®¡ç®—å¤šä¸ªäº‹ä»¶çš„æ¦‚ç‡æ„Ÿå…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the diagrams in Figure 4.4[122], ellipses represent root or interior nodes, and rectangles represent leaf nodes. The labels of the ellipses indicate which descriptive feature is tested at that node. The labels on each branch indicate one of the possible feature levels that the descriptive feature at the node above can take. The labels on the rectangular leaf nodes indicate the target level that should be predicted when the tests on the interior nodes create a path that terminates at that leaf node.",
            "zh": "åœ¨å›¾4.4[122]çš„å›¾ä¸­ï¼Œæ¤­åœ†è¡¨ç¤ºæ ¹èŠ‚ç‚¹æˆ–å†…éƒ¨èŠ‚ç‚¹ï¼ŒçŸ©å½¢è¡¨ç¤ºå¶èŠ‚ç‚¹ã€‚æ¤­åœ†çš„æ ‡ç­¾æŒ‡ç¤ºåœ¨è¯¥èŠ‚ç‚¹ä¸Šæµ‹è¯•å“ªä¸ªæè¿°æ€§ç‰¹å¾ã€‚æ¯ä¸ªåˆ†æ”¯ä¸Šçš„æ ‡ç­¾æŒ‡ç¤ºä¸Šè¿°èŠ‚ç‚¹ä¸Šçš„æè¿°æ€§ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å¯èƒ½ç‰¹å¾çº§åˆ«ä¹‹ä¸€ã€‚çŸ©å½¢å¶èŠ‚ç‚¹ä¸Šçš„æ ‡ç­¾æŒ‡ç¤ºåœ¨å†…éƒ¨èŠ‚ç‚¹ä¸Šçš„æµ‹è¯•åˆ›å»ºç»ˆæ­¢äºè¯¥å¶èŠ‚ç‚¹çš„è·¯å¾„æ—¶åº”é¢„æµ‹çš„ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling is sometimes extended to include a third sample, the validation set.",
            "zh": "ä¿æŒæŠ½æ ·æœ‰æ—¶ä¼šæ‰©å±•åˆ°åŒ…æ‹¬ç¬¬ä¸‰ä¸ªæ ·æœ¬ï¼Œå³éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D. 2019. Deep learning. Essential Knowledge Series. MIT Press.",
            "zh": "å‡¯è±èµ«ï¼Œçº¦ç¿° D. 2019 å¹´ã€‚æ·±åº¦å­¦ä¹ ã€‚åŸºæœ¬çŸ¥è¯†ç³»åˆ—ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the general idea of a convergence criterion is that as the training progresses, the error of the network should generally decrease.",
            "zh": "ç„¶è€Œï¼Œæ”¶æ•›å‡†åˆ™çš„ä¸€èˆ¬æ€æƒ³æ˜¯ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œç½‘ç»œçš„è¯¯å·®é€šå¸¸åº”è¯¥ä¼šå‡å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the output for Neuron 5 for the input vector: Neuron 1 = 0.9, Neuron 2 = 0.5.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—è¾“å…¥å‘é‡çš„ç¥ç»å…ƒ 5 çš„è¾“å‡ºï¼šç¥ç»å…ƒ 1 = 0.9ï¼Œç¥ç»å…ƒ 2 = 0.5ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. A nice example of building machine learning models for drug dosage prediction can be found in Mac Namee et al. (2002).",
            "zh": "21. Mac Namee et al. ï¼ˆ2002ï¼‰ æ˜¯æ„å»ºç”¨äºè¯ç‰©å‰‚é‡é¢„æµ‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the student-t distribution, the degrees of freedom is always set to the sample size (number of rows in the dataset) minus one.",
            "zh": "å¯¹äº student-t åˆ†å¸ƒï¼Œè‡ªç”±åº¦å§‹ç»ˆè®¾ç½®ä¸ºæ ·æœ¬æ•°é‡ï¼ˆæ•°æ®é›†ä¸­çš„è¡Œæ•°ï¼‰å‡å» 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.6â€…â€…â€…Histograms of a selection of features from the SDSS dataset.",
            "zh": "13.6 SDSS æ•°æ®é›†ä¸­æ‰€é€‰è¦ç´ çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another way to understand how dropout helps is to notice that the training data looks different at every epoch because each time an example is presented to a network a different set of input neurons is set to 0.",
            "zh": "ç†è§£è¾å­¦å¦‚ä½•å¸®åŠ©çš„å¦ä¸€ç§æ–¹æ³•æ˜¯æ³¨æ„åˆ°è®­ç»ƒæ•°æ®åœ¨æ¯ä¸ªæ—¶æœŸçœ‹èµ·æ¥éƒ½ä¸åŒï¼Œå› ä¸ºæ¯æ¬¡å‘ç½‘ç»œå‘ˆç°ç¤ºä¾‹æ—¶ï¼Œéƒ½ä¼šå°†ä¸€ç»„ä¸åŒçš„è¾“å…¥ç¥ç»å…ƒè®¾ç½®ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the equations for the input gate, we use the symbols â€  and â€¡ to distinguish the different paths of information processing in the output gate.",
            "zh": "ä¸è¾“å…¥é—¨çš„æ–¹ç¨‹ç±»ä¼¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¦å· â€  å’Œ â€¡ æ¥åŒºåˆ†è¾“å‡ºé—¨ä¸­ä¿¡æ¯å¤„ç†çš„ä¸åŒè·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main structural difference is that the network in Figure 8.36[498] does not include a softmax output layer.",
            "zh": "ä¸»è¦çš„ç»“æ„åŒºåˆ«åœ¨äºå›¾8.36[498]ä¸­çš„ç½‘ç»œä¸åŒ…æ‹¬softmaxè¾“å‡ºå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "25. A formal test for statistical significance could easily be used to reinforce this conclusion.",
            "zh": "25. å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§çš„æ­£å¼æ£€éªŒæ¥åŠ å¼ºè¿™ä¸€ç»“è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "6.11â€…â€…â€…The dataset from the loan application fraud detection domain (from Table 6.2[263]) with two continuous descriptive features added: ACCOUNT BALANCE and LOAN AMOUNT.",
            "zh": "6.11 æ¥è‡ªè´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹åŸŸçš„æ•°æ®é›†ï¼ˆæ¥è‡ªè¡¨6.2[263]ï¼‰ï¼Œå¢åŠ äº†ä¸¤ä¸ªè¿ç»­çš„æè¿°æ€§ç‰¹å¾ï¼šè´¦æˆ·ä½™é¢å’Œè´·æ¬¾é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the simple accuracy and average class accuracy (using an arithmetic mean) for each model.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„ç®€å•å‡†ç¡®ç‡å’Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼ˆä½¿ç”¨ç®—æœ¯å¹³å‡å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a consequence, the weights on a dropped neuron wonâ€™t receive any weight updates for that example.",
            "zh": "å› æ­¤ï¼Œå¯¹äºè¯¥ç¤ºä¾‹ï¼Œä¸¢å¼ƒç¥ç»å…ƒä¸Šçš„æƒé‡ä¸ä¼šæ”¶åˆ°ä»»ä½•æƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Appendix C[765] we provide an introduction to differentiation that covers all the techniques required to understand how the gradient descent algorithm works.",
            "zh": "åœ¨é™„å½•C[765]ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¾®åˆ†ï¼Œæ¶µç›–äº†ç†è§£æ¢¯åº¦ä¸‹é™ç®—æ³•å·¥ä½œåŸç†æ‰€éœ€çš„æ‰€æœ‰æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVMAGERR_U/G/R/I/Z",
            "zh": "DEVMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This single value, however, may not capture all the relevant information.",
            "zh": "ä½†æ˜¯ï¼Œæ­¤å•ä¸ªå€¼å¯èƒ½æ— æ³•æ•è·æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset contains measurements of the revolutions per minute (RPM) that power station generators are running at, the amount of vibration in the generators (VIBRATION), and an indicator to show whether the generators proved to be working or faulty the day after these measurements were taken.",
            "zh": "è¯¥æ•°æ®é›†åŒ…å«ç”µç«™å‘ç”µæœºè¿è¡Œçš„æ¯åˆ†é’Ÿè½¬æ•° ï¼ˆRPMï¼‰ çš„æµ‹é‡å€¼ã€å‘ç”µæœºä¸­çš„æŒ¯åŠ¨é‡ ï¼ˆVIBRATIONï¼‰ ä»¥åŠä¸€ä¸ªæŒ‡ç¤ºå™¨ï¼Œç”¨äºæ˜¾ç¤ºå‘ç”µæœºåœ¨è¿›è¡Œè¿™äº›æµ‹é‡åçš„ç¬¬äºŒå¤©æ˜¯å¦è¢«è¯æ˜æ˜¯å·¥ä½œè¿˜æ˜¯æ•…éšœã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.8945",
            "zh": "-0.8945"
        }
    },
    {
        "translation": {
            "en": "This threshold can be changed, however, which leads to different predictions and a different confusion matrix.",
            "zh": "ä½†æ˜¯ï¼Œæ­¤é˜ˆå€¼å¯ä»¥æ›´æ”¹ï¼Œè¿™ä¼šå¯¼è‡´ä¸åŒçš„é¢„æµ‹å’Œä¸åŒçš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The target hypersphere after instance d21 has been stored as best, and best-distance has been updated; and (b) the extent of the search process: white nodes were checked by the search process, and the node with the bold outline indexed instance d21, which was returned as the nearest neighbor to the query. Grayed-out branches indicate the portions of the k-d tree pruned from the search.",
            "zh": "ï¼ˆaï¼‰ å®ä¾‹d21ä¹‹åçš„ç›®æ ‡è¶…çƒä½“å·²å­˜å‚¨ä¸ºæœ€ä½³ï¼Œæœ€ä½³è·ç¦»å·²æ›´æ–°;ï¼ˆbï¼‰ æœç´¢è¿‡ç¨‹çš„èŒƒå›´ï¼šæœç´¢è¿‡ç¨‹æ£€æŸ¥äº†ç™½è‰²èŠ‚ç‚¹ï¼Œå…·æœ‰ç²—ä½“è½®å»“çš„èŠ‚ç‚¹ç´¢å¼•äº†å®ä¾‹ d21ï¼Œè¯¥å®ä¾‹ä½œä¸ºæŸ¥è¯¢çš„æœ€è¿‘é‚»å±…è¿”å›ã€‚ç°è‰²çš„æ ‘æè¡¨ç¤ºä»æœç´¢ä¸­ä¿®å‰ªçš„ k-d æ ‘éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The key point to remember here is that if a sample of data is not representative of a population, then inferences based on that sample will not generalize to the larger population.",
            "zh": "è¿™é‡Œè¦è®°ä½çš„å…³é”®ç‚¹æ˜¯ï¼Œå¦‚æœæ•°æ®æ ·æœ¬ä¸èƒ½ä»£è¡¨æ€»ä½“ï¼Œé‚£ä¹ˆåŸºäºè¯¥æ ·æœ¬çš„æ¨è®ºå°†ä¸ä¼šæ¨å¹¿åˆ°æ›´å¤§çš„æ€»ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, eating cake almost always seems like a good idea in the moment, but in terms of long-term health is probably not always a strong choice.",
            "zh": "ä¾‹å¦‚ï¼Œåƒè›‹ç³•åœ¨å½“ä¸‹ä¼¼ä¹æ€»æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œä½†å°±é•¿æœŸå¥åº·è€Œè¨€ï¼Œå¯èƒ½å¹¶ä¸æ€»æ˜¯ä¸€ä¸ªå¼ºæœ‰åŠ›çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "other features, 36",
            "zh": "å…¶ä»–åŠŸèƒ½ï¼Œ 36"
        }
    },
    {
        "translation": {
            "en": "Padding may be applied to retain dimensionality, and in some cases the non-linearity activation or sub-sampling may be dropped in some convolutional layers.",
            "zh": "å¯ä»¥åº”ç”¨å¡«å……æ¥ä¿æŒç»´æ•°ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œåœ¨æŸäº›å·ç§¯å±‚ä¸­å¯èƒ½ä¼šä¸¢å¼ƒéçº¿æ€§æ¿€æ´»æˆ–å­é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the downside to not normalizing the target feature in a regression problem is that if the target feature has a large range, then during training the error of the network on an example can be very large, resulting in very large error gradients, which in turn can result in large weight updates and an unstable learning process (similar to the instability that can arise with large inputs, but in this case the instability arises from large errors).",
            "zh": "ç„¶è€Œï¼Œåœ¨å›å½’é—®é¢˜ä¸­ä¸è§„èŒƒåŒ–ç›®æ ‡ç‰¹å¾çš„ç¼ºç‚¹æ˜¯ï¼Œå¦‚æœç›®æ ‡ç‰¹å¾çš„èŒƒå›´å¾ˆå¤§ï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç¤ºä¾‹ä¸Šçš„ç½‘ç»œè¯¯å·®å¯èƒ½éå¸¸å¤§ï¼Œä»è€Œå¯¼è‡´éå¸¸å¤§çš„è¯¯å·®æ¢¯åº¦ï¼Œè¿™åè¿‡æ¥åˆä¼šå¯¼è‡´å¤§é‡çš„æƒé‡æ›´æ–°å’Œä¸ç¨³å®šçš„å­¦ä¹ è¿‡ç¨‹ï¼ˆç±»ä¼¼äºå¤§è¾“å…¥å¯èƒ½äº§ç”Ÿçš„ä¸ç¨³å®šæ€§ï¼Œ ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸ç¨³å®šæ€§æ˜¯ç”±å¤§é”™è¯¯å¼•èµ·çš„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "CRM, 572",
            "zh": "å®¢æˆ·å…³ç³»ç®¡ç†ï¼Œ572"
        }
    },
    {
        "translation": {
            "en": "Figure 3.10(a)[80] shows a box plot for AGE across the full dataset, while Figure 3.10(b)[80] shows individual box plots for AGE for each level of the POSITION feature.",
            "zh": "å›¾ 3.10ï¼ˆaï¼‰[80] æ˜¾ç¤ºäº†æ•´ä¸ªæ•°æ®é›†ä¸­ AGE çš„ç®±å½¢å›¾ï¼Œè€Œå›¾ 3.10ï¼ˆbï¼‰[80] æ˜¾ç¤ºäº† POSITION ç‰¹å¾æ¯ä¸ªçº§åˆ«çš„ AGE çš„å•ç‹¬ç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "hypersphere, 201, 217",
            "zh": "è¶…çƒä½“ï¼Œ 201ï¼Œ 217"
        }
    },
    {
        "translation": {
            "en": "The problem with this is that we are essentially wasting bins because some of the bins end up representing a very small number of instances (the height of the bars in the diagram shows the number of instances in each bin).",
            "zh": "è¿™æ ·åšçš„é—®é¢˜åœ¨äºï¼Œæˆ‘ä»¬æœ¬è´¨ä¸Šæ˜¯åœ¨æµªè´¹åƒåœ¾ç®±ï¼Œå› ä¸ºä¸€äº›åƒåœ¾ç®±æœ€ç»ˆä»£è¡¨äº†éå¸¸å°‘é‡çš„å®ä¾‹ï¼ˆå›¾ä¸­æ¡å½¢çš„é«˜åº¦æ˜¾ç¤ºäº†æ¯ä¸ªåƒåœ¾æ¡¶ä¸­çš„å®ä¾‹æ•°é‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sample",
            "zh": "æ ·æœ¬"
        }
    },
    {
        "translation": {
            "en": "The k-means algorithm is a well-known example of this kind of algorithm and is used as the default clustering implementation in many machine learning packages and tools.",
            "zh": "k å‡å€¼ç®—æ³•æ˜¯æ­¤ç±»ç®—æ³•çš„ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥çš„ä¾‹å­ï¼Œåœ¨è®¸å¤šæœºå™¨å­¦ä¹ åŒ…å’Œå·¥å…·ä¸­ç”¨ä½œé»˜è®¤èšç±»å®ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11(b)[203] illustrates the parts of the k-d tree that were checked or pruned during the search process.",
            "zh": "å›¾5.11ï¼ˆbï¼‰[203]è¯´æ˜äº†åœ¨æœç´¢è¿‡ç¨‹ä¸­æ£€æŸ¥æˆ–ä¿®å‰ªçš„k-dæ ‘éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Events Involving Binary Features",
            "zh": "æ¶‰åŠäºŒè¿›åˆ¶ç‰¹å¾çš„äº‹ä»¶"
        }
    },
    {
        "translation": {
            "en": "Each of these instances is described in terms of three binary descriptive features (GOOD BEHAVIOR, AGE < 30, DRUG DEPENDENT) and a binary target feature (RECIDIVIST).",
            "zh": "è¿™äº›å®ä¾‹ä¸­çš„æ¯ä¸€ä¸ªéƒ½æ ¹æ®ä¸‰ä¸ªäºŒå…ƒæè¿°ç‰¹å¾ï¼ˆè‰¯å¥½è¡Œä¸ºã€å¹´é¾„ < 30ã€è¯ç‰©ä¾èµ–ï¼‰å’Œä¸€ä¸ªäºŒå…ƒç›®æ ‡ç‰¹å¾ï¼ˆç´¯çŠ¯ï¼‰è¿›è¡Œæè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The minus sign at the beginning of the equation is simply added to convert the negative numbers returned by the log function to positive ones (as described above).",
            "zh": "åªéœ€æ·»åŠ ç­‰å¼å¼€å¤´çš„å‡å·å³å¯å°†å¯¹æ•°å‡½æ•°è¿”å›çš„è´Ÿæ•°è½¬æ¢ä¸ºæ­£æ•°ï¼ˆå¦‚ä¸Šæ‰€è¿°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to use the clamp transformation to change the values of these outliers to something closer to the central tendency of the features.",
            "zh": "Jocelyn å†³å®šä½¿ç”¨é’³ä½å˜æ¢å°†è¿™äº›å¼‚å¸¸å€¼çš„å€¼æ›´æ”¹ä¸ºæ›´æ¥è¿‘ç‰¹å¾ä¸­å¿ƒè¶‹åŠ¿çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.3â€ƒContinuous Features: Binning",
            "zh": "6.4.3 è¿ç»­åŠŸèƒ½ï¼šåˆ†ç®±"
        }
    },
    {
        "translation": {
            "en": "The boundary between imaginary and valid pixels is highlighted by a thickly outlined rectangle enclosing the valid pixels.",
            "zh": "è™šåƒç´ å’Œæœ‰æ•ˆåƒç´ ä¹‹é—´çš„è¾¹ç•Œç”±åŒ…å›´æœ‰æ•ˆåƒç´ çš„ç²—è½®å»“çŸ©å½¢çªå‡ºæ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "CALLMINUTESCHANGEPCT: Derived from the raw call data, this feature captured the amount by which the number of minutes a customer used had changed that month compared to the previous month.",
            "zh": "CALLMINUTESCHANGEPCTï¼šæ­¤åŠŸèƒ½æºè‡ªåŸå§‹å‘¼å«æ•°æ®ï¼Œå¯æ•è·å®¢æˆ·å½“æœˆä½¿ç”¨çš„åˆ†é’Ÿæ•°ä¸ä¸Šä¸ªæœˆç›¸æ¯”çš„å˜åŒ–é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This derivation was based on the chain rule and is the product of the rate of change of the error of the model with respect to its outputâ€”the term (tâˆ’ ğ•„w(d))â€”and the rate of change of the output of the linear regression model with respect to a change in the weight j, the term âˆ’d[j].",
            "zh": "è¯¥æ¨å¯¼åŸºäºé“¾å¼æ³•åˆ™ï¼Œæ˜¯æ¨¡å‹ç›¸å¯¹äºå…¶è¾“å‡ºçš„è¯¯å·®å˜åŒ–ç‡ï¼ˆé¡¹ ï¼ˆtâˆ’ Mwï¼ˆdï¼‰ï¼‰ï¼‰å’Œçº¿æ€§å›å½’æ¨¡å‹è¾“å‡ºç›¸å¯¹äºæƒé‡ j å˜åŒ–çš„å˜åŒ–ç‡ï¼ˆé¡¹ âˆ’d[j]ï¼‰çš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "An individual can belong to only one of these states at a time and moves between them according to a Markov process.",
            "zh": "ä¸€ä¸ªäººä¸€æ¬¡åªèƒ½å±äºè¿™äº›çŠ¶æ€ä¸­çš„ä¸€ç§ï¼Œå¹¶æ ¹æ®é©¬å°”å¯å¤«è¿‡ç¨‹åœ¨å®ƒä»¬ä¹‹é—´ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4â€…â€…â€…Weights and standard errors for each feature in the office rentals model.",
            "zh": "7.4 åŠå…¬å®¤ç§Ÿèµæ¨¡å‹ä¸­æ¯ä¸ªç‰¹å¾çš„æƒé‡å’Œæ ‡å‡†è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Following the flow of d2 through all three layers of the network, the prediction output by the model for this example is 0.4718 (see Cell 2, the gray cell, in the Activations Output Layer matrix).",
            "zh": "åœ¨ d2 æµç»ç½‘ç»œçš„æ‰€æœ‰ä¸‰å±‚ä¹‹åï¼Œæ­¤ç¤ºä¾‹çš„æ¨¡å‹çš„é¢„æµ‹è¾“å‡ºä¸º 0.4718ï¼ˆè¯·å‚é˜…æ¿€æ´»è¾“å‡ºå±‚çŸ©é˜µä¸­çš„å•å…ƒæ ¼ 2ï¼Œç°è‰²å•å…ƒæ ¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2â€…â€…â€…Calculating the sum of squared errors for the candidate model (with w [0] = 6.47 and w [1]= 0.62) to make predictions for the office rentals dataset.",
            "zh": "7.2 è®¡ç®—å€™é€‰æ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼ˆw [0] = 6.47ï¼Œw [1]= 0.62ï¼‰ï¼Œä»¥å¯¹åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The multiplication operation calculates the weighted sum for the output neuron z(2), and this is passed through the neuronâ€™s activation function Ï† to generate the output of the network.",
            "zh": "ä¹˜æ³•è¿ç®—è®¡ç®—è¾“å‡ºç¥ç»å…ƒ zï¼ˆ2ï¼‰ çš„åŠ æƒå’Œï¼Œå¹¶é€šè¿‡ç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°Ï†ç”Ÿæˆç½‘ç»œçš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Adam, 523",
            "zh": "äºšå½“ï¼Œ523"
        }
    },
    {
        "translation": {
            "en": "This pattern was investigated with the business to understand whether this was an issue due to valid or invalid data.",
            "zh": "ä¸ä¸šåŠ¡éƒ¨é—¨ä¸€èµ·è°ƒæŸ¥äº†æ­¤æ¨¡å¼ï¼Œä»¥äº†è§£è¿™æ˜¯ç”±äºæœ‰æ•ˆæ•°æ®è¿˜æ˜¯æ— æ•ˆæ•°æ®é€ æˆçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.14(b)[218] highlights the normalization of descriptive feature values that takes place as part of calculating cosine similarity.",
            "zh": "å›¾5.14ï¼ˆbï¼‰[218]çªå‡ºæ˜¾ç¤ºäº†æè¿°æ€§ç‰¹å¾å€¼çš„å½’ä¸€åŒ–ï¼Œè¿™æ˜¯è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mixture of Gaussians distributions are used to represent data that is composed of multiple subpopulations.",
            "zh": "é«˜æ–¯åˆ†å¸ƒçš„æ··åˆç”¨äºè¡¨ç¤ºç”±å¤šä¸ªå­ç¾¤ä½“ç»„æˆçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.76)[469] is taken from Equation (8.72)[467 the step to Equation (8.77)[469] uses Equation (8.74)[468 the rewrite in Equation (8.78)[469] uses Equation (8.75)[468 and finally Equation (8.79)[469] is the simplification we get when the terms cancel out after the product.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.76ï¼‰[469]å–è‡ªæ–¹ç¨‹ï¼ˆ8.72ï¼‰[467]ï¼Œæ–¹ç¨‹ï¼ˆ8.77ï¼‰[469]çš„æ­¥éª¤ä½¿ç”¨æ–¹ç¨‹ï¼ˆ8.74ï¼‰[468]ï¼Œæ–¹ç¨‹ï¼ˆ8.78ï¼‰[469]ä¸­çš„é‡å†™ä½¿ç”¨æ–¹ç¨‹ï¼ˆ8.75ï¼‰[468]ï¼Œæœ€åæ–¹ç¨‹ï¼ˆ8.79ï¼‰[469]æ˜¯å½“é¡¹åœ¨ä¹˜ç§¯åæŠµæ¶ˆæ—¶æˆ‘ä»¬å¾—åˆ°çš„ç®€åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Maintaining long histories of actions, rewards, and observations (which are possibly only very slightly different from one iteration to the next) is not a very efficient way to reason about the world, particularly as episodes might cover hundreds or thousands of time-steps.",
            "zh": "ä¿æŒè¡ŒåŠ¨ã€å¥–åŠ±å’Œè§‚å¯Ÿçš„é•¿å†å²ï¼ˆåœ¨ä¸€æ¬¡è¿­ä»£åˆ°ä¸‹ä¸€æ¬¡è¿­ä»£ä¹‹é—´å¯èƒ½åªæœ‰å¾ˆå°çš„å·®å¼‚ï¼‰å¹¶ä¸æ˜¯æ¨ç†ä¸–ç•Œçš„éå¸¸æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å½“å‰§é›†å¯èƒ½æ¶µç›–æ•°ç™¾æˆ–æ•°åƒä¸ªæ—¶é—´æ­¥é•¿æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because AT was already using a process in which its retention team generated call lists based on collected data, deployment of the new decision tree model was reasonably straightforward.",
            "zh": "ç”±äº AT å·²ç»åœ¨ä½¿ç”¨å…¶ä¿ç•™å›¢é˜Ÿæ ¹æ®æ”¶é›†çš„æ•°æ®ç”Ÿæˆå‘¼å«åˆ—è¡¨çš„æµç¨‹ï¼Œå› æ­¤éƒ¨ç½²æ–°çš„å†³ç­–æ ‘æ¨¡å‹ç›¸å½“ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "full joint probability distribution, 284, 302, 761",
            "zh": "å…¨è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œ284,302,761"
        }
    },
    {
        "translation": {
            "en": "We can show that both of the networks in Figure 6.12[291] represent the same joint probability by using each of them to calculate the probability of an arbitrarily chosen joint event from the domain. We should get the same probability for the joint event from both of the networks. For this example, we will calculate the probability of the event Â¬a, b, c. Using the Bayesian network in Figure 6.12(a)[291], we would carry out the calculation as follows:",
            "zh": "æˆ‘ä»¬å¯ä»¥è¯æ˜ï¼Œå›¾ 6.12[291] ä¸­çš„ä¸¤ä¸ªç½‘ç»œéƒ½è¡¨ç¤ºç›¸åŒçš„è”åˆæ¦‚ç‡ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨å®ƒä»¬ä¸­çš„æ¯ä¸€ä¸ªæ¥è®¡ç®—ä»åŸŸä¸­ä»»æ„é€‰æ‹©çš„è”åˆäº‹ä»¶çš„æ¦‚ç‡ã€‚æˆ‘ä»¬åº”è¯¥ä»ä¸¤ä¸ªç½‘ç»œè·å¾—ç›¸åŒçš„è”åˆäº‹ä»¶æ¦‚ç‡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†è®¡ç®—äº‹ä»¶ Â¬aã€bã€c çš„æ¦‚ç‡ã€‚ä½¿ç”¨å›¾6.12ï¼ˆaï¼‰[291]ä¸­çš„è´å¶æ–¯ç½‘ç»œï¼Œæˆ‘ä»¬å°†è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "Using the Î´ values you have calculated, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., âˆ‚â„°/âˆ‚w5,4, âˆ‚â„°/âˆ‚w5,3,âˆ‚â„°/âˆ‚w5,0,âˆ‚â„°/âˆ‚w4,2,âˆ‚â„°/âˆ‚w4,0,âˆ‚â„°/âˆ‚w3,2,âˆ‚â„°/âˆ‚w3,0,âˆ‚â„°/âˆ‚w2,1,âˆ‚â„°/âˆ‚w2,0).",
            "zh": "ä½¿ç”¨æ‚¨è®¡ç®—çš„Î´å€¼ï¼Œè®¡ç®—ç½‘ç»œè¯¯å·®å¯¹ç½‘ç»œæ¯ä¸ªæƒé‡å˜åŒ–çš„æ•æ„Ÿåº¦ï¼ˆå³ âˆ‚E/âˆ‚w5,4ã€âˆ‚E/âˆ‚w5ã€3ã€âˆ‚E/âˆ‚w5,0ã€âˆ‚E/âˆ‚w4,2ï¼Œâˆ‚E/âˆ‚w4,0ï¼Œâˆ‚E/âˆ‚w3,2ï¼Œâˆ‚E/âˆ‚w3,0ï¼Œâˆ‚E/âˆ‚w2,1ï¼Œâˆ‚E/âˆ‚w2,0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the normal distribution, the Î» parameter for the exponential distribution can be easily calculated by using the value of 1 divided by the mean of the data.",
            "zh": "ä¸æ­£æ€åˆ†å¸ƒç±»ä¼¼ï¼ŒæŒ‡æ•°åˆ†å¸ƒçš„ Î» å‚æ•°å¯ä»¥é€šè¿‡ä½¿ç”¨ 1 é™¤ä»¥æ•°æ®å¹³å‡å€¼æ¥è½»æ¾è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(c)[329] shows the impact of a large learning rate.",
            "zh": "å›¾7.7ï¼ˆcï¼‰[329]æ˜¾ç¤ºäº†é«˜å­¦ä¹ ç‡çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term channel is used to describe the number of matrices used to encode the information in an image.",
            "zh": "æœ¯è¯­é€šé“ç”¨äºæè¿°ç”¨äºå¯¹å›¾åƒä¸­çš„ä¿¡æ¯è¿›è¡Œç¼–ç çš„çŸ©é˜µæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5[392] highlights how bias terms are introduced into the activation vectors in such a way that they are aligned with the bias term weights during the matrix multiplication.",
            "zh": "å›¾ 8.5[392] çªå‡ºæ˜¾ç¤ºäº†å¦‚ä½•åœ¨çŸ©é˜µä¹˜æ³•è¿‡ç¨‹ä¸­å°†åç½®é¡¹å¼•å…¥æ¿€æ´»å‘é‡ï¼Œä½¿å…¶ä¸åç½®é¡¹æƒé‡å¯¹é½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.8",
            "zh": "å›¾ 13.8"
        }
    },
    {
        "translation": {
            "en": "to estimate how the model will perform when deployed",
            "zh": "ä¼°è®¡æ¨¡å‹åœ¨éƒ¨ç½²æ—¶çš„æ€§èƒ½"
        }
    },
    {
        "translation": {
            "en": "sampling variance, 153",
            "zh": "æŠ½æ ·æ–¹å·®ï¼Œ153"
        }
    },
    {
        "translation": {
            "en": "B.3â€…â€…â€…Some Useful Probability Rules",
            "zh": "B.3 ä¸€äº›æœ‰ç”¨çš„æ¦‚ç‡è§„åˆ™"
        }
    },
    {
        "translation": {
            "en": "Once the set of models has been created, the ensemble makes predictions using a weighted aggregate of the predictions made by the individual models.",
            "zh": "åˆ›å»ºæ¨¡å‹é›†åï¼Œé›†æˆå°†ä½¿ç”¨å„ä¸ªæ¨¡å‹æ‰€åšçš„é¢„æµ‹çš„åŠ æƒèšåˆè¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2",
            "zh": "å›¾ 7.2"
        }
    },
    {
        "translation": {
            "en": "Similarly, the gradients for the inputs to the elementwise product in the forget gate are calculated",
            "zh": "ç±»ä¼¼åœ°ï¼Œè®¡ç®—é—å¿˜é—¨ä¸­é€å…ƒä¹˜ç§¯è¾“å…¥çš„æ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "The original gradient boosting paper by Friedman (2001) gives a detailed explanation on the fundamentals of gradient boosting.",
            "zh": "Friedmanï¼ˆ2001ï¼‰çš„åŸå§‹æ¢¯åº¦æå‡è®ºæ–‡å¯¹æ¢¯åº¦æå‡çš„åŸºæœ¬åŸç†è¿›è¡Œäº†è¯¦ç»†çš„è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4â€ƒExtensions and Variations",
            "zh": "5.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Notice that one of the partitions created by splitting 8 on the basis of SLOPE is empty: 18.",
            "zh": "è¯·æ³¨æ„ï¼Œé€šè¿‡åœ¨ SLOPE çš„åŸºç¡€ä¸Šæ‹†åˆ† 8 åˆ›å»ºçš„åˆ†åŒºä¹‹ä¸€æ˜¯ç©ºçš„ï¼š18ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, machine learning is an ill-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available.",
            "zh": "å› æ­¤ï¼Œæœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªç—…æ€çš„é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ªæ— æ³•ä»…ä½¿ç”¨å¯ç”¨ä¿¡æ¯ç¡®å®šå”¯ä¸€è§£å†³æ–¹æ¡ˆçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "To fully capture the game dynamics we could represent TwentyTwos using the 190 different hand states plus five more terminal states representing the outcomes of going bust, losing, tying, winning, and winning with a TwentyTwo.",
            "zh": "ä¸ºäº†å……åˆ†æ•æ‰æ¸¸æˆåŠ¨æ€ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ 190 ç§ä¸åŒçš„æ‰‹ç‰ŒçŠ¶æ€åŠ ä¸Šå¦å¤– 5 ç§æœ€ç»ˆçŠ¶æ€æ¥è¡¨ç¤º TwentyTwoï¼Œè¿™äº›çŠ¶æ€ä»£è¡¨äº† TwentyTwo ç ´äº§ã€è¾“å®¶ã€å¹³å±€ã€èµ¢ç‰Œå’Œè·èƒœçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.21",
            "zh": "å›¾ 8.21"
        }
    },
    {
        "translation": {
            "en": "This is also an attractive characteristic of this function.",
            "zh": "è¿™ä¹Ÿæ˜¯æ­¤åŠŸèƒ½çš„ä¸€ä¸ªå¸å¼•äººçš„ç‰¹ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The correlations between the HEIGHT and WEIGHT and AGE features can be calculated, using the covariances and standard deviations from Table 3.8[82], as follows:",
            "zh": "ä½¿ç”¨è¡¨3.8[82]ä¸­çš„åæ–¹å·®å’Œæ ‡å‡†å·®ï¼Œå¯ä»¥è®¡ç®—èº«é«˜ã€ä½“é‡å’Œå¹´é¾„ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, the probability of the joint event2 DICE1 = , DICE2 = would be calculated as",
            "zh": "ä¾‹å¦‚ï¼Œè”åˆäº‹ä»¶ 2 DICE1 = ï¼Œ DICE2 = çš„æ¦‚ç‡è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "There is always a trade-off in setting the value of k. If we set k too low, we run the risk of the algorithm being sensitive to noise in the data and overfitting.",
            "zh": "åœ¨è®¾ç½® k çš„å€¼æ—¶æ€»æ˜¯éœ€è¦æƒè¡¡å–èˆã€‚å¦‚æœæˆ‘ä»¬å°† k è®¾ç½®å¾—å¤ªä½ï¼Œæˆ‘ä»¬å°±ä¼šé¢ä¸´ç®—æ³•å¯¹æ•°æ®ä¸­çš„å™ªå£°æ•æ„Ÿå’Œè¿‡åº¦æ‹Ÿåˆçš„é£é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "An edge-on disk is a spiral galaxy viewed from the edge, which makes the direction of the spiral arms unclear.",
            "zh": "è¾¹ç¼˜åœ†ç›˜æ˜¯ä»è¾¹ç¼˜è§‚å¯Ÿçš„èºæ—‹æ˜Ÿç³»ï¼Œè¿™ä½¿å¾—æ—‹è‡‚çš„æ–¹å‘ä¸æ¸…æ™°ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.48",
            "zh": "0.48"
        }
    },
    {
        "translation": {
            "en": "Lintott, C., K. Schawinski, S. Bamford, A. Slosar, K. Land, D. Thomas, E. Edmondson, K. Masters, R. C. Nichol, M. J. Raddick, A. Szalay, D. Andreescu, P. Murray, and J. Vandenberg. 2011. Galaxy Zoo 1: Data release of morphological classifications for nearly 900 000 galaxies. Monthly Notices of the Royal Astronomical Society 410: 166â€“178. doi:10.1111/j.1365-2966.2010.17432.x.",
            "zh": "Lintottï¼Œ C.ï¼Œ K. Schawinskiï¼Œ S. Bamfordï¼Œ A. Slosarï¼Œ K. Landï¼Œ D. Thomasï¼Œ E. Edmondsonï¼Œ K. Mastersï¼Œ RC Nicholï¼Œ MJ Raddickï¼Œ A. Szalayï¼Œ D. Andreescuï¼Œ P. Murrayï¼Œ and J. Vandenberg.2011. é“¶æ²³åŠ¨ç‰©å›­1å·ï¼šè¿‘90ä¸‡ä¸ªæ˜Ÿç³»å½¢æ€åˆ†ç±»æ•°æ®å‘å¸ƒã€‚çš‡å®¶å¤©æ–‡å­¦ä¼šæœˆåˆŠ 410ï¼š166-178ã€‚doiï¼š10.1111/j.1365-2966.2010.17432.x."
        }
    },
    {
        "translation": {
            "en": "The 6 neurons in the top layer share the weights in Filter 1, and the 6 neurons in the bottom layer share the weights in Filter 2.",
            "zh": "é¡¶å±‚çš„ 6 ä¸ªç¥ç»å…ƒå…±äº«è¿‡æ»¤å™¨ 1 ä¸­çš„æƒé‡ï¼Œåº•å±‚çš„ 6 ä¸ªç¥ç»å…ƒå…±äº«è¿‡æ»¤å™¨ 2 ä¸­çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The product EDâŠº is however defined because DâŠº is a 3 Ã— 2 matrix and the number of columns is E (3) equals the number of rows in DâŠº (3).",
            "zh": "ç„¶è€Œï¼Œä¹˜ç§¯ EDâŠº çš„å®šä¹‰æ˜¯å› ä¸º DâŠº æ˜¯ä¸€ä¸ª 3 Ã— 2 çŸ©é˜µï¼Œåˆ—æ•°ä¸º E ï¼ˆ3ï¼‰ ç­‰äº DâŠº ï¼ˆ3ï¼‰ ä¸­çš„è¡Œæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we shift the focus to unsupervised machine learning methods.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹è½¬ç§»åˆ°æ— ç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The vanishing gradient problem is a direct consequence of the fact that the backpropagation algorithm is based on the chain rule.",
            "zh": "æ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ˜¯åå‘ä¼ æ’­ç®—æ³•åŸºäºé“¾å¼æ³•åˆ™è¿™ä¸€äº‹å®çš„ç›´æ¥ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Measures of flux and magnitude are made in each of the five photometric bands used by the SDSS imaging system.",
            "zh": "åœ¨SDSSæˆåƒç³»ç»Ÿä½¿ç”¨çš„äº”ä¸ªå…‰åº¦æ³¢æ®µä¸­ï¼Œæ¯ä¸ªæ³¢æ®µéƒ½æµ‹é‡äº†é€šé‡å’Œé‡çº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Claude Shannon is considered to be the father of information theory.",
            "zh": "å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰è¢«è®¤ä¸ºæ˜¯ä¿¡æ¯è®ºä¹‹çˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ordinal: Values that allow ordering but do not permit arithmetic (e.g., size measured as small, medium, or large)",
            "zh": "åºå·ï¼šå…è®¸æ’åºä½†ä¸å…è®¸ç®—æœ¯çš„å€¼ï¼ˆä¾‹å¦‚ï¼Œæµ‹é‡ä¸ºå°ã€ä¸­æˆ–å¤§çš„å¤§å°ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Chapter 13 of Hastie et al. (2009) gives an introduction to the statistical theory underpinning nearest neighbor models. The measure used to judge similarity is a key element in a nearest neighbor model. In this chapter, we have described a number of different distance metrics and similarity indexes. Cunningham (2009) provides a broader introduction to the range of metrics and indexes that are available.",
            "zh": "Hastie et al. ï¼ˆ2009ï¼‰çš„ç¬¬13ç« ä»‹ç»äº†æ”¯æ’‘æœ€è¿‘é‚»æ¨¡å‹çš„ç»Ÿè®¡ç†è®ºã€‚ç”¨äºåˆ¤æ–­ç›¸ä¼¼æ€§çš„åº¦é‡æ˜¯æœ€è¿‘é‚»æ¨¡å‹ä¸­çš„å…³é”®è¦ç´ ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†è®¸å¤šä¸åŒçš„è·ç¦»åº¦é‡å’Œç›¸ä¼¼æ€§æŒ‡æ•°ã€‚Cunninghamï¼ˆ2009ï¼‰å¯¹å¯ç”¨çš„æŒ‡æ ‡å’ŒæŒ‡æ•°èŒƒå›´è¿›è¡Œäº†æ›´å¹¿æ³›çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the hierarchical grouping of the instances in the mobile phone customer dataset from Table 10.1[604] found by the AHC algorithm (using Euclidean distance and single linkage). (b) The clustering returned when the tree is cut at k = 3. (c) The clustering returned when the tree is cut at k = 6.",
            "zh": "ï¼ˆaï¼‰ AHCç®—æ³•ï¼ˆä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»å’Œå•é“¾æ¥ï¼‰æ‰¾åˆ°çš„è¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­å®ä¾‹çš„åˆ†å±‚å›¾ã€‚ï¼ˆbï¼‰ å½“æ ‘æœ¨åœ¨k = 3æ—¶è¢«ç ä¼æ—¶è¿”å›çš„èšç±»ã€‚ï¼ˆcï¼‰ åœ¨k = 6æ—¶ç ä¼æ ‘æœ¨æ—¶è¿”å›çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability functions are the basic building blocks of probability theory, and they are very easy to create from a dataset.",
            "zh": "æ¦‚ç‡å‡½æ•°æ˜¯æ¦‚ç‡è®ºçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œå®ƒä»¬å¾ˆå®¹æ˜“ä»æ•°æ®é›†ä¸­åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The final two extensions and variations sections introduce well-known neural network architectures, including convolutional neural networks and recurrent neural networks.",
            "zh": "æœ€åä¸¤ä¸ªæ‰©å±•å’Œå˜ä½“éƒ¨åˆ†ä»‹ç»äº†ä¼—æ‰€å‘¨çŸ¥çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬å·ç§¯ç¥ç»ç½‘ç»œå’Œé€’å½’ç¥ç»ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "FP, 537",
            "zh": "FPï¼Œ537"
        }
    },
    {
        "translation": {
            "en": "One disadvantage of using basis functions, however, is that the analyst has to design the basis function set that will be used.",
            "zh": "ä½†æ˜¯ï¼Œä½¿ç”¨åŸºå‡½æ•°çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼Œåˆ†æäººå‘˜å¿…é¡»è®¾è®¡å°†è¦ä½¿ç”¨çš„åŸºå‡½æ•°é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "To make Bayesian predictions, we generate the probability of the event that a target feature, t, takes a specific level, l, given the assignment of values to a set of descriptive features, q, from a query instance. We can restate Bayesâ€™ Theorem using this terminology and generalize the definition of Bayesâ€™ Theorem so that it can take into account more than one piece of evidence (each descriptive feature value is a separate piece of evidence). The Generalized Bayesâ€™ Theorem is defined as",
            "zh": "ä¸ºäº†è¿›è¡Œè´å¶æ–¯é¢„æµ‹ï¼Œæˆ‘ä»¬ç”Ÿæˆç›®æ ‡ç‰¹å¾ t å…·æœ‰ç‰¹å®šæ°´å¹³ l çš„äº‹ä»¶çš„æ¦‚ç‡ï¼Œç»™å®šä»æŸ¥è¯¢å®ä¾‹ä¸­ä¸ºä¸€ç»„æè¿°æ€§ç‰¹å¾ q èµ‹å€¼ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªæœ¯è¯­é‡è¿°è´å¶æ–¯å®šç†ï¼Œå¹¶æ¨å¹¿è´å¶æ–¯å®šç†çš„å®šä¹‰ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è€ƒè™‘å¤šä¸ªè¯æ®ï¼ˆæ¯ä¸ªæè¿°æ€§ç‰¹å¾å€¼éƒ½æ˜¯ä¸€ä¸ªå•ç‹¬çš„è¯æ®ï¼‰ã€‚å¹¿ä¹‰è´å¶æ–¯å®šç†å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "TD-Gammon, 677",
            "zh": "TD-é‡‘é—¨ï¼Œ 677"
        }
    },
    {
        "translation": {
            "en": "The eleven states are shown as the nodes in the graph with transitions based on different actions represented by the edges (transitions for Twist actions are shown as solid lines and transitions for Stick actions are shown as dashed lines).",
            "zh": "è¿™ 11 ä¸ªçŠ¶æ€åœ¨å›¾ä¸­æ˜¾ç¤ºä¸ºèŠ‚ç‚¹ï¼Œå…¶è¿‡æ¸¡åŸºäºè¾¹è¡¨ç¤ºçš„ä¸åŒåŠ¨ä½œï¼ˆTwist åŠ¨ä½œçš„è¿‡æ¸¡æ˜¾ç¤ºä¸ºå®çº¿ï¼Œæ‘‡æ†åŠ¨ä½œçš„è¿‡æ¸¡æ˜¾ç¤ºä¸ºè™šçº¿ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m + 1 descriptive features (including the dummy d[0] feature), d[0],d[1],â€¦,d[m w is a vector of m + 1 weights (including the bias term) w[0],w[1] , â€¦,w[m and Ï† represents the activation function (threshold, tanh, logistic, or rectifier, etc.)",
            "zh": "å…¶ä¸­ d æ˜¯ m + 1 æè¿°æ€§ç‰¹å¾ï¼ˆåŒ…æ‹¬è™šæ‹Ÿ d[0] ç‰¹å¾ï¼‰çš„å‘é‡ï¼Œd[0]ï¼Œd[1],...,d[m w æ˜¯ m + 1 æƒé‡ï¼ˆåŒ…æ‹¬åç½®é¡¹ï¼‰w[0]ï¼Œw[1] ï¼Œ ...ï¼Œw[m çš„å‘é‡ï¼ŒÏ† è¡¨ç¤ºæ¿€æ´»å‡½æ•°ï¼ˆé˜ˆå€¼ã€tanhã€é€»è¾‘æˆ–æ•´æµå™¨ç­‰ï¼‰"
        }
    },
    {
        "translation": {
            "en": "In this chapter we introduce probability-based approaches to machine learning.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, for every floor we go up in an office building, we can expect the rental price to decrease by 0.1781 Euro per month.",
            "zh": "åŒæ ·ï¼Œå¯¹äºæˆ‘ä»¬åœ¨åŠå…¬æ¥¼ä¸­æ¯ä¸Šå‡ä¸€å±‚ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸç§Ÿé‡‘ä»·æ ¼æ¯æœˆå°†ä¸‹é™ 0.1781 æ¬§å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, if the relationship between the number of inputs to a weighted sum and the variance of the weights is incorrect, then the result of a weighted sum can have either a larger variance than the variance of its inputs or a smaller variance than the variance of its inputs.",
            "zh": "å› æ­¤ï¼Œå¦‚æœåŠ æƒå’Œçš„è¾“å…¥æ•°ä¸æƒé‡æ–¹å·®ä¹‹é—´çš„å…³ç³»ä¸æ­£ç¡®ï¼Œåˆ™åŠ æƒå’Œçš„ç»“æœçš„æ–¹å·®å¯èƒ½å¤§äºå…¶è¾“å…¥çš„æ–¹å·®ï¼Œæˆ–è€…æ–¹å·®å°äºå…¶è¾“å…¥çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Input images were scaled to 84Ã—84 and the network contained hidden convolutional layers with 32, 64 and 64 units.30 Filter sizes were 8 Ã— 8 (stride 4), 4 Ã— 4 (stride 3), and 3 Ã— 3 (stride 1).",
            "zh": "è¾“å…¥å›¾åƒè¢«ç¼©æ”¾åˆ°84Ã—84ï¼Œç½‘ç»œåŒ…å«32ã€64å’Œ64ä¸ªå•å…ƒçš„éšè—å·ç§¯å±‚.30æ»¤æ³¢å™¨å¤§å°ä¸º8Ã—8ï¼ˆæ­¥å¹…4ï¼‰ã€4Ã—4ï¼ˆæ­¥å¹…3ï¼‰å’Œ3Ã—3ï¼ˆæ­¥å¹…1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We return to the topic of weight initialization strategies in Section 8.4.2[447].",
            "zh": "æˆ‘ä»¬å›åˆ°ç¬¬8.4.2èŠ‚[447]ä¸­çš„æƒé‡åˆå§‹åŒ–ç­–ç•¥ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "A preference bias guides the learning algorithm to prefer certain models over others.",
            "zh": "åå¥½åå·®ä¼šå¼•å¯¼å­¦ä¹ ç®—æ³•ä¼˜å…ˆé€‰æ‹©æŸäº›æ¨¡å‹è€Œä¸æ˜¯å…¶ä»–æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the customer group dataset from Table 7.11[359]. Squares represent instances with the single target level, triangles the business level, and crosses the family level. The bottom-right panel illustrates the overall decision boundaries between the three target levels.",
            "zh": "è¡¨7.11[359]ä¸­å®¢æˆ·ç»„æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚æ­£æ–¹å½¢è¡¨ç¤ºå…·æœ‰å•ä¸ªç›®æ ‡çº§åˆ«çš„å®ä¾‹ï¼Œä¸‰è§’å½¢è¡¨ç¤ºä¸šåŠ¡çº§åˆ«ï¼Œå¹¶è·¨ç³»åˆ—çº§åˆ«ã€‚å³ä¸‹è§’çš„é¢æ¿è¯´æ˜äº†ä¸‰ä¸ªç›®æ ‡çº§åˆ«ä¹‹é—´çš„æ€»ä½“å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "We use a bold capital W to indicate a weight matrix, and we use a superscript in brackets to indicate the layer of the network the matrix is associated with.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç²—ä½“å¤§å†™å­—æ¯ W æ¥è¡¨ç¤ºæƒé‡çŸ©é˜µï¼Œå¹¶ä½¿ç”¨æ‹¬å·ä¸­çš„ä¸Šæ ‡æ¥è¡¨ç¤ºä¸çŸ©é˜µå…³è”çš„ç½‘ç»œå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. When defining intervals, a square bracket, [ or ], indicates that the boundary value is included in the interval, and a parenthesis, ( or ), indicates that it is excluded from the interval.",
            "zh": "7. å®šä¹‰åŒºé—´æ—¶ï¼Œæ–¹æ‹¬å· [ æˆ– ]ï¼Œ è¡¨ç¤ºè¾¹ç•Œå€¼åŒ…å«åœ¨åŒºé—´ä¸­ï¼Œæ‹¬å· ï¼ˆ æˆ– ï¼‰ è¡¨ç¤ºå®ƒè¢«æ’é™¤åœ¨åŒºé—´ä¹‹å¤–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Now that we know that the row and column vector both contain the difference between the feature values of the two instances, it should be clear that, similar to Euclidean distance, the Mahalanobis distance squares the differences of the features.",
            "zh": "ç°åœ¨æˆ‘ä»¬çŸ¥é“è¡Œå‘é‡å’Œåˆ—å‘é‡éƒ½åŒ…å«ä¸¤ä¸ªå®ä¾‹çš„ç‰¹å¾å€¼ä¹‹é—´çš„å·®å€¼ï¼Œåº”è¯¥å¾ˆæ¸…æ¥šï¼Œä¸æ¬§å‡ é‡Œå¾—è·ç¦»ç±»ä¼¼ï¼Œé©¬æ°è·ç¦»å¯¹ç‰¹å¾çš„å·®å€¼è¿›è¡Œå¹³æ–¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The formal measure we use to do this is Shannonâ€™s entropy model.",
            "zh": "æˆ‘ä»¬ç”¨æ¥åšåˆ°è¿™ä¸€ç‚¹çš„å½¢å¼åº¦é‡æ˜¯é¦™å†œçš„ç†µæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason why we need two different derivatives for the softmax function to handle these two cases is that when we are taking the derivative with respect to changes in the logit for the neuron whose activation is (i.e.",
            "zh": "æˆ‘ä»¬ä¹‹æ‰€ä»¥éœ€è¦ä¸¤ä¸ªä¸åŒçš„å¯¼æ•°æ¥å¤„ç† softmax å‡½æ•°æ¥å¤„ç†è¿™ä¸¤ç§æƒ…å†µï¼Œæ˜¯å› ä¸ºå½“æˆ‘ä»¬å–å¯¼æ•°æ—¶ï¼Œå¯¹äºæ¿€æ´»ä¸º ï¼ˆå³"
        }
    },
    {
        "translation": {
            "en": "From a probability point of view, each feature in a dataset is a random variable, and the sample space for the domain associated with a prediction problem is the set of all possible combinations of assignments of values to features.",
            "zh": "ä»æ¦‚ç‡çš„è§’åº¦æ¥çœ‹ï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸ªç‰¹å¾éƒ½æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼Œä¸é¢„æµ‹é—®é¢˜å…³è”çš„åŸŸçš„æ ·æœ¬ç©ºé—´æ˜¯ç‰¹å¾å€¼åˆ†é…çš„æ‰€æœ‰å¯èƒ½ç»„åˆçš„é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The completed transition matrix for the Stick action, ğ’«Stick, is",
            "zh": "æ‘‡æ†åŠ¨ä½œ PStick çš„å®Œæ•´è¿‡æ¸¡çŸ©é˜µä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 2.9",
            "zh": "å›¾ 2.9"
        }
    },
    {
        "translation": {
            "en": "Consequently, decision trees naturally lend themselves to being trained using information-based metrics.",
            "zh": "å› æ­¤ï¼Œå†³ç­–æ ‘è‡ªç„¶é€‚åˆä½¿ç”¨åŸºäºä¿¡æ¯çš„æŒ‡æ ‡è¿›è¡Œè®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Alternatively, we can use the Theorem of Total Probability to calculate P(Y):",
            "zh": "æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ€»æ¦‚ç‡å®šç†æ¥è®¡ç®— Pï¼ˆYï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "A range of techniques can also be used to make a decision tree more robust to noise in the data.",
            "zh": "è¿˜å¯ä»¥ä½¿ç”¨ä¸€ç³»åˆ—æŠ€æœ¯æ¥ä½¿å†³ç­–æ ‘å¯¹æ•°æ®ä¸­çš„å™ªå£°æ›´å…·é²æ£’æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "LOC: The customerâ€™s location (rural or urban)",
            "zh": "LOCï¼šå®¢æˆ·çš„ä½ç½®ï¼ˆå†œæ‘æˆ–åŸå¸‚ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Choosing a high value for Î³ gives almost equal importance to all rewards. For example, with Î³ = 0.9",
            "zh": "ä¸ºÎ³é€‰æ‹©é«˜ä»·å€¼å¯¹æ‰€æœ‰å¥–åŠ±å‡ ä¹åŒç­‰é‡è¦ã€‚ä¾‹å¦‚ï¼ŒÎ³ = 0.9"
        }
    },
    {
        "translation": {
            "en": "Analysts will often input a suggested starting point for this search based on their own analysis of the data in order to guide the process.",
            "zh": "åˆ†æå¸ˆé€šå¸¸ä¼šæ ¹æ®è‡ªå·±å¯¹æ•°æ®çš„åˆ†æï¼Œä¸ºè¿™æ¬¡æœç´¢è¾“å…¥ä¸€ä¸ªå»ºè®®çš„èµ·ç‚¹ï¼Œä»¥æŒ‡å¯¼è¯¥è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data, filter weights, and scale of the network shown in Figure 8.36[498] have been simplified for the purposes of illustration.",
            "zh": "å›¾ 8.36[498] ä¸­æ‰€ç¤ºçš„ç½‘ç»œæ•°æ®ã€æ»¤æ³¢å™¨æƒé‡å’Œæ¯”ä¾‹å·²ç®€åŒ–ï¼Œä»¥ä¾¿äºè¯´æ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case the initial model predicts a likelihood that an instance belongs to each of the possible target levels, and subsequent models predict corrections to these likelihoods.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆå§‹æ¨¡å‹é¢„æµ‹å®ä¾‹å±äºæ¯ä¸ªå¯èƒ½çš„ç›®æ ‡çº§åˆ«çš„å¯èƒ½æ€§ï¼Œåç»­æ¨¡å‹é¢„æµ‹å¯¹è¿™äº›å¯èƒ½æ€§çš„ä¿®æ­£ã€‚"
        }
    },
    {
        "translation": {
            "en": "unbiased estimate, 752",
            "zh": "æ— åä¼°è®¡ï¼Œ752"
        }
    },
    {
        "translation": {
            "en": "We will use the dataset2 in Table 6.1[246] to illustrate how the terminology of probability is mapped into the language of machine learning for predictive data analytics. The target being predicted in this dataset is whether a patient is suffering from MENINGITIS, and the descriptive features are common symptoms associated with this disease (HEADACHE, FEVER, and VOMITING).",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨è¡¨ 6.1[246] ä¸­çš„ dataset2 æ¥è¯´æ˜å¦‚ä½•å°†æ¦‚ç‡æœ¯è¯­æ˜ å°„åˆ°ç”¨äºé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ è¯­è¨€ä¸­ã€‚è¯¥æ•°æ®é›†ä¸­é¢„æµ‹çš„ç›®æ ‡æ˜¯æ‚£è€…æ˜¯å¦æ‚£æœ‰è„‘è†œç‚ï¼Œæè¿°æ€§ç‰¹å¾æ˜¯ä¸è¯¥ç–¾ç—…ç›¸å…³çš„å¸¸è§ç—‡çŠ¶ï¼ˆå¤´ç—›ã€å‘çƒ§å’Œå‘•åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that each time we observe a decrease in the best validation error, we reset the patience count to zero.",
            "zh": "è¯·æ³¨æ„ï¼Œæ¯æ¬¡æˆ‘ä»¬è§‚å¯Ÿåˆ°æœ€ä½³éªŒè¯é”™è¯¯å‡å°‘æ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†è€å¿ƒè®¡æ•°é‡ç½®ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comparing Figure 5.5(b)[192] with Figure 5.4(b)[190], we can see that the main difference is that the decision boundary in the bottom-right region of the feature space has moved to the left.",
            "zh": "å°†å›¾5.5ï¼ˆbï¼‰[192]ä¸å›¾5.4ï¼ˆbï¼‰[190]è¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥çœ‹å‡ºä¸»è¦åŒºåˆ«åœ¨äºç‰¹å¾ç©ºé—´å³ä¸‹è§’åŒºåŸŸçš„å†³ç­–è¾¹ç•Œå‘å·¦ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the data in Tables 6.11[278] and 6.15[283].",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.11[278]å’Œè¡¨6.15[283]ä¸­çš„æ•°æ®è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The second course (â€œM.L.",
            "zh": "ç¬¬äºŒé“èœï¼ˆâ€œM.L."
        }
    },
    {
        "translation": {
            "en": "A dataset that represents the characters in the Guess Who game.",
            "zh": "è¡¨ç¤º Guess Who æ¸¸æˆä¸­è§’è‰²çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "So the probability of DICE1 = given that DICE2 = would be written as",
            "zh": "å› æ­¤ï¼ŒDICE1 = çš„æ¦‚ç‡ç»™å®š DICE2 = å°†å†™ä¸º"
        }
    },
    {
        "translation": {
            "en": "-0.19558",
            "zh": "-0.19558"
        }
    },
    {
        "translation": {
            "en": "We use the term rem(d, ) to denote this quantity and define it formally",
            "zh": "æˆ‘ä»¬ä½¿ç”¨æœ¯è¯­ remï¼ˆdï¼Œ ï¼‰ æ¥è¡¨ç¤ºè¿™ä¸ªé‡å¹¶æ­£å¼å®šä¹‰å®ƒ"
        }
    },
    {
        "translation": {
            "en": "Toward the end of the chapter, we introduce some more advanced data exploration techniques that, although not part of the standard data quality report, can be useful at this stage of an analytics project and present some data preparation techniques that can be applied to the data in an ABT prior to modeling.",
            "zh": "åœ¨æœ¬ç« çš„æœ€åï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›æ›´é«˜çº§çš„æ•°æ®æ¢ç´¢æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯è™½ç„¶ä¸æ˜¯æ ‡å‡†æ•°æ®è´¨é‡æŠ¥å‘Šçš„ä¸€éƒ¨åˆ†ï¼Œä½†åœ¨åˆ†æé¡¹ç›®çš„è¿™ä¸ªé˜¶æ®µå¾ˆæœ‰ç”¨ï¼Œå¹¶ä»‹ç»äº†ä¸€äº›æ•°æ®å‡†å¤‡æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯å¯ä»¥åœ¨å»ºæ¨¡ä¹‹å‰åº”ç”¨äº ABT ä¸­çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "To enable the naive Bayes model to handle the ACCOUNT BALANCE feature, we have to extend the set of probabilities used by the model to represent the domain to include the probabilities for this feature.",
            "zh": "ä¸ºäº†ä½¿æœ´ç´ è´å¶æ–¯æ¨¡å‹èƒ½å¤Ÿå¤„ç† ACCOUNT BALANCE ç‰¹å¾ï¼Œæˆ‘ä»¬å¿…é¡»æ‰©å±•æ¨¡å‹ç”¨äºè¡¨ç¤ºåŸŸçš„æ¦‚ç‡é›†ï¼Œä»¥åŒ…å«æ­¤ç‰¹å¾çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "38. This census dataset is based on the Census Income Dataset (Kohavi, 1996), which is available from the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Census+Income/.",
            "zh": "38. è¯¥äººå£æ™®æŸ¥æ•°æ®é›†ä»¥äººå£æ™®æŸ¥æ”¶å…¥æ•°æ®é›†ï¼ˆKohaviï¼Œ1996å¹´ï¼‰ä¸ºåŸºç¡€ï¼Œè¯¥æ•°æ®é›†å¯ä» archive.ics.uci.edu/ml/datasets/Census+Income/ çš„UCIæœºå™¨å­¦ä¹ èµ„æ–™åº“ï¼ˆBacheå’ŒLichmanï¼Œ2013å¹´ï¼‰è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Starting on the right, we calculate âˆ‚â„°/âˆ‚ot per Equation (8.118)[516] and then backpropagate this through the output gate elementwise product to calculate âˆ‚â„°/âˆ‚oâ€¡ (Equation (8.119)[516]) and âˆ‚â„°/âˆ‚oâ€¡ (Equation (8.120)[516]).",
            "zh": "ä»å³è¾¹å¼€å§‹ï¼Œæˆ‘ä»¬æ ¹æ®æ–¹ç¨‹ ï¼ˆ8.118ï¼‰[516] è®¡ç®— âˆ‚E/âˆ‚otï¼Œç„¶åé€šè¿‡è¾“å‡ºé—¨é€å…ƒä¹˜ç§¯åå‘ä¼ æ’­ä»¥è®¡ç®— âˆ‚E/âˆ‚oâ€¡ï¼ˆæ–¹ç¨‹ ï¼ˆ8.119ï¼‰[516]ï¼‰å’Œ âˆ‚E/âˆ‚oâ€¡ï¼ˆæ–¹ç¨‹ ï¼ˆ8.120ï¼‰[516]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.66",
            "zh": "0.66"
        }
    },
    {
        "translation": {
            "en": "We reiterate the factors required to represent the full joint distribution for the meningitis diagnosis scenario when we assume that the descriptive features are conditionally independent given the target, this time including the actual probabilities calculated from the dataset:",
            "zh": "å½“æˆ‘ä»¬å‡è®¾æè¿°æ€§ç‰¹å¾åœ¨ç»™å®šç›®æ ‡çš„æƒ…å†µä¸‹æ˜¯æœ‰æ¡ä»¶ç‹¬ç«‹çš„æ—¶ï¼Œæˆ‘ä»¬é‡ç”³äº†è¡¨ç¤ºè„‘è†œç‚è¯Šæ–­åœºæ™¯çš„å®Œæ•´å…³èŠ‚åˆ†å¸ƒæ‰€éœ€çš„å› ç´ ï¼Œè¿™æ¬¡åŒ…æ‹¬ä»æ•°æ®é›†è®¡ç®—çš„å®é™…æ¦‚ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "3.2.2â€ƒCase Study: Motor Insurance Fraud",
            "zh": "3.2.2 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "With regard to the network training, take care with the weight initialization process, and it is generally a good idea to include dropout.",
            "zh": "å…³äºç½‘ç»œè®­ç»ƒï¼Œæ³¨æ„æƒé‡åˆå§‹åŒ–è¿‡ç¨‹ï¼Œé€šå¸¸æœ€å¥½åŒ…æ‹¬ dropoutã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that if we represent a set of input vectors as a matrix of inputs, we can get the network to process all the inputs in parallel.",
            "zh": "è¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬å°†ä¸€ç»„è¾“å…¥å‘é‡è¡¨ç¤ºä¸ºè¾“å…¥çŸ©é˜µï¼Œæˆ‘ä»¬å¯ä»¥è®©ç½‘ç»œå¹¶è¡Œå¤„ç†æ‰€æœ‰è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.5â€ƒSummary",
            "zh": "8.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Figure 9.6",
            "zh": "å›¾ 9.6"
        }
    },
    {
        "translation": {
            "en": "The final domain concept diagram is shown in Figure 13.4[712].",
            "zh": "æœ€ç»ˆçš„é¢†åŸŸæ¦‚å¿µå›¾å¦‚å›¾13.4[712]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "To combat overfitting, we allow algorithms to train models beyond this point but save the model generated at each iteration.",
            "zh": "ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬å…è®¸ç®—æ³•è®­ç»ƒè¶…è¿‡è¿™ä¸€ç‚¹çš„æ¨¡å‹ï¼Œä½†ä¿å­˜æ¯æ¬¡è¿­ä»£æ—¶ç”Ÿæˆçš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.1â€…â€…â€…Business Understanding",
            "zh": "12.1 ä¸šåŠ¡ç†è§£"
        }
    },
    {
        "translation": {
            "en": "The management of a large hospital group are concerned about the readmission rate for patients who are hospitalized with problems relating to diabetes.",
            "zh": "ä¸€å®¶å¤§å‹åŒ»é™¢é›†å›¢çš„ç®¡ç†å±‚æ‹…å¿ƒå› ç³–å°¿ç—…ç›¸å…³é—®é¢˜ä½é™¢çš„æ‚£è€…çš„å†å…¥é™¢ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.3",
            "zh": "å›¾ 13.3"
        }
    },
    {
        "translation": {
            "en": "Working from the right of the equation, first we calculate âˆ‚â„°/âˆ‚ak by subtracting ak from tk and multiplying the result by âˆ’ 1.",
            "zh": "ä»ç­‰å¼çš„å³è¾¹å¼€å§‹ï¼Œé¦–å…ˆæˆ‘ä»¬é€šè¿‡ä» tk ä¸­å‡å» ak å¹¶å°†ç»“æœä¹˜ä»¥ âˆ’ 1 æ¥è®¡ç®— âˆ‚E/âˆ‚akã€‚"
        }
    },
    {
        "translation": {
            "en": "The different question sequences that can follow in a game of Guess Who beginning with the question Does the person wear glasses?",
            "zh": "çŒœçŒœè°æ¸¸æˆä¸­å¯ä»¥éµå¾ªçš„ä¸åŒé—®é¢˜åºåˆ—ï¼Œä»é—®é¢˜å¼€å§‹ï¼šè¿™ä¸ªäººæˆ´çœ¼é•œå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "8.18â€…â€…â€…The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390] when all the neurons are ReLUs.",
            "zh": "8.18 å½“æ‰€æœ‰ç¥ç»å…ƒéƒ½æ˜¯ReLUæ—¶ï¼Œè¡¨8.3[423]ä¸­åˆ—å‡ºçš„ç¤ºä¾‹é€šè¿‡å›¾8.4[390]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms address this issue by encoding an inductive biasâ€”or set of assumptionsâ€”that guide the algorithm to prefer certain models over others.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡ç¼–ç å½’çº³åå·®ï¼ˆæˆ–ä¸€ç»„å‡è®¾ï¼‰æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™äº›åå·®æˆ–å‡è®¾å¼•å¯¼ç®—æ³•ä¼˜å…ˆé€‰æ‹©æŸäº›æ¨¡å‹è€Œä¸æ˜¯å…¶ä»–æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we work through an example to illustrate how the ID3 is used to induce a decision tree.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨ ID3 æ¥è¯±å¯¼å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, a discriminative model works by",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œåˆ¤åˆ«æ¨¡å‹çš„å·¥ä½œåŸç†æ˜¯"
        }
    },
    {
        "translation": {
            "en": "where is the normalized feature value, ai is the original value, Ä is the mean for feature a, and sd(a) is the standard deviation for a. Standardizing feature values in this ways squashes the values of the feature so that the feature values have a mean of 0 and a standard deviation of 1.",
            "zh": "å…¶ä¸­ æ˜¯å½’ä¸€åŒ–ç‰¹å¾å€¼ï¼Œai æ˜¯åŸå§‹å€¼ï¼ŒÄ æ˜¯ç‰¹å¾ A çš„å¹³å‡å€¼ï¼Œsdï¼ˆaï¼‰ æ˜¯ a çš„æ ‡å‡†å·®ã€‚ä»¥è¿™ç§æ–¹å¼æ ‡å‡†åŒ–ç‰¹å¾å€¼ä¼šå‹ç¼©ç‰¹å¾å€¼ï¼Œä½¿ç‰¹å¾å€¼çš„å¹³å‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.3â€ƒPopulations and Samples",
            "zh": "A.3 ç§ç¾¤å’Œæ ·æœ¬"
        }
    },
    {
        "translation": {
            "en": "If H is the size of the hidden state, and the input x has a dimension of n (in this example n = 1), then the dimensions of the weight matrices in the forget gate and input gate (W(f), W(iâ€ ), and W(iâ€¡)) and the sigmoid layer in the output gate (W(oâ€ )), including bias terms is: H Ã— (1 + n + H).",
            "zh": "å¦‚æœ H æ˜¯éšè—çŠ¶æ€çš„å¤§å°ï¼Œå¹¶ä¸”è¾“å…¥ x çš„ç»´æ•°ä¸º nï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º n = 1ï¼‰ï¼Œåˆ™é—å¿˜é—¨å’Œè¾“å…¥é—¨ ï¼ˆWï¼ˆfï¼‰ã€Wï¼ˆiâ€ ï¼‰ å’Œ Wï¼ˆiâ€¡ï¼‰ï¼‰ ä¸­çš„æƒé‡çŸ©é˜µå’Œè¾“å‡ºé—¨ ï¼ˆWï¼ˆoâ€ ï¼‰ï¼‰ ä¸­çš„ s å½¢ç»“è‚ å±‚ï¼ˆåŒ…æ‹¬åç½®é¡¹ï¼‰çš„ç»´æ•°ä¸ºï¼š H Ã— ï¼ˆ1 + n + Hï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given the sensitivity of the algorithm to the value of k, how should we set this parameter?",
            "zh": "é‰´äºç®—æ³•å¯¹ k å€¼çš„æ•æ„Ÿæ€§ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•è®¾ç½®è¿™ä¸ªå‚æ•°ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Burges (1998) is still a good, freely available tutorial on support vector machines. For more details, Cristianini and Shawe-Taylor (2000) is a well-respected textbook on the topic and covers the extensions mentioned in Section 7.4.7[361], while Vapnik (2000) gives a good overview of the theoretical underpinnings of support vector machines.",
            "zh": "Burges ï¼ˆ1998ï¼‰ ä»ç„¶æ˜¯ä¸€ä¸ªå…³äºæ”¯æŒå‘é‡æœºçš„å¾ˆå¥½çš„ã€å…è´¹æä¾›çš„æ•™ç¨‹ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼ŒCristianini å’Œ Shawe-Taylor ï¼ˆ2000ï¼‰ æ˜¯ä¸€æœ¬å…³äºè¯¥ä¸»é¢˜çš„å¤‡å—æ¨å´‡çš„æ•™ç§‘ä¹¦ï¼Œæ¶µç›–äº†ç¬¬ 7.4.7 èŠ‚ä¸­æåˆ°çš„æ‰©å±•[361]ï¼Œè€Œ Vapnik ï¼ˆ2000ï¼‰ å¾ˆå¥½åœ°æ¦‚è¿°äº†æ”¯æŒå‘é‡æœºçš„ç†è®ºåŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "where âˆ‘i P(Xi) should be interpreted as summing over the set of events that are a complete assignment to the features in X. The reason that the division functions as a normalization mechanism is that the prior probability of the evidence, P(Y), is not conditional on Xi, and as a result, it is constant for all Xi.",
            "zh": "å…¶ä¸­ âˆ‘i Pï¼ˆä¹ ï¼‰ åº”è§£é‡Šä¸ºå¯¹ X ä¸­ç‰¹å¾çš„å®Œæ•´èµ‹å€¼çš„äº‹ä»¶é›†æ±‚å’Œã€‚åˆ’åˆ†ä½œä¸ºå½’ä¸€åŒ–æœºåˆ¶çš„åŸå› æ˜¯è¯æ®çš„å…ˆéªŒæ¦‚ç‡ Pï¼ˆYï¼‰ ä¸ä»¥ ä¹  ä¸ºæ¡ä»¶ï¼Œå› æ­¤ï¼Œå®ƒå¯¹æ‰€æœ‰ ä¹  éƒ½æ˜¯æ’å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Richter, Michael M., and Rosina O. Weber. 2013. Case-based reasoning: A textbook. Springer.",
            "zh": "Richterã€Michael M. å’Œ Rosina O. Weberã€‚2013. åŸºäºæ¡ˆä¾‹çš„æ¨ç†ï¼šä¸€æœ¬æ•™ç§‘ä¹¦.æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can illustrate how machine learning is an ill-posed problem using an example in which the analytics team at a supermarket chain wants to be able to classify customer households into the demographic groups single, couple, or family, solely on the basis of their shopping habits.4 The dataset given in Table 1.3[9] contains descriptive features describing the shopping habits of five customers.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜æœºå™¨å­¦ä¹ å¦‚ä½•æˆä¸ºä¸€ä¸ªç—…æ€çš„é—®é¢˜ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä¸€å®¶è¿é”è¶…å¸‚çš„åˆ†æå›¢é˜Ÿå¸Œæœ›èƒ½å¤Ÿä»…æ ¹æ®ä»–ä»¬çš„è´­ç‰©ä¹ æƒ¯å°†å®¢æˆ·å®¶åº­åˆ†ç±»ä¸ºå•èº«ã€å¤«å¦»æˆ–å®¶åº­çš„äººå£ç»Ÿè®¡ç¾¤ä½“.4 è¡¨ 1.3[9] ä¸­ç»™å‡ºçš„æ•°æ®é›†åŒ…å«æè¿°äº”ä¸ªå®¢æˆ·è´­ç‰©ä¹ æƒ¯çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for the analytics solutions proposed for the motor insurance fraud scenario, the prediction subject of the claim prediction and payment prediction models would be an insurance claim; for the member prediction model, the prediction subject would be a member; and for the application prediction model, it would be an application.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºé’ˆå¯¹æ±½è½¦ä¿é™©æ¬ºè¯ˆåœºæ™¯æå‡ºçš„åˆ†æè§£å†³æ–¹æ¡ˆï¼Œç´¢èµ”é¢„æµ‹å’Œä»˜æ¬¾é¢„æµ‹æ¨¡å‹çš„é¢„æµ‹ä¸»ä½“å°†æ˜¯ä¿é™©ç´¢èµ”;å¯¹äºæˆå‘˜é¢„æµ‹æ¨¡å‹ï¼Œé¢„æµ‹ä¸»ä½“ä¸ºæˆå‘˜;å¯¹äºåº”ç”¨ç¨‹åºé¢„æµ‹æ¨¡å‹ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªåº”ç”¨ç¨‹åºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.14[464] illustrates the calculation of the softmax function for a vector of three logits (i.e., three z values),",
            "zh": "è¡¨ 8.14[464] è¯´æ˜äº† softmax å‡½æ•°å¯¹ä¸‰ä¸ª logits å‘é‡ï¼ˆå³ä¸‰ä¸ª z å€¼ï¼‰çš„è®¡ç®—ï¼Œ"
        }
    },
    {
        "translation": {
            "en": "sampling bias, 12",
            "zh": "é‡‡æ ·åå·®ï¼Œ12"
        }
    },
    {
        "translation": {
            "en": "12. See Chapter 8[381] for descriptions of these different activation functions.",
            "zh": "12. æœ‰å…³è¿™äº›ä¸åŒæ¿€æ´»å‡½æ•°çš„æè¿°ï¼Œè¯·å‚é˜…ç¬¬ 8 ç« [381]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Discuss the strength of the relationships shown in each visualization.",
            "zh": "è®¨è®ºæ¯ä¸ªå¯è§†åŒ–ä¸­æ˜¾ç¤ºçš„å…³ç³»çš„å¼ºåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The conditional independence assumption means that naive Bayes models use very few parameters to represent a domain.",
            "zh": "æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾æ„å‘³ç€æœ´ç´ è´å¶æ–¯æ¨¡å‹ä½¿ç”¨å¾ˆå°‘çš„å‚æ•°æ¥è¡¨ç¤ºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Last, a conditional probability refers to the probability of one feature taking a specific value given that we already know the value of a different feature, for example, P(MENINGITIS = true | HEADACHE = true) = 0.2857.",
            "zh": "æœ€åï¼Œæ¡ä»¶æ¦‚ç‡æ˜¯æŒ‡ä¸€ä¸ªç‰¹å¾å–ç‰¹å®šå€¼çš„æ¦‚ç‡ï¼Œå‡è®¾æˆ‘ä»¬å·²ç»çŸ¥é“å¦ä¸€ä¸ªç‰¹å¾çš„å€¼ï¼Œä¾‹å¦‚ï¼ŒPï¼ˆMENINGITIS = true |å¤´ç—› = çœŸï¼‰ = 0.2857ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision tree that would be generated for the vegetation classification dataset listed in Table 4.9[147] using information gain.",
            "zh": "ä½¿ç”¨ä¿¡æ¯å¢ç›Šä¸ºè¡¨4.9[147]ä¸­åˆ—å‡ºçš„æ¤è¢«åˆ†ç±»æ•°æ®é›†ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we noted in our discussion regarding handling time, the motor insurance claim prediction scenario is a good example of a situation in which the observation period and outcome period are measured over different dates for each insurance claim (the prediction subject for this case study).",
            "zh": "æ­£å¦‚æˆ‘ä»¬åœ¨å…³äºå¤„ç†æ—¶é—´çš„è®¨è®ºä¸­æ‰€æŒ‡å‡ºçš„ï¼Œæ±½è½¦ä¿é™©ç´¢èµ”é¢„æµ‹åœºæ™¯æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œå…¶ä¸­è§‚å¯ŸæœŸå’Œç»“æœæœŸæ˜¯åœ¨æ¯ä¸ªä¿é™©ç´¢èµ”çš„ä¸åŒæ—¥æœŸï¼ˆæœ¬æ¡ˆä¾‹ç ”ç©¶çš„é¢„æµ‹ä¸»é¢˜ï¼‰ä¸Šæµ‹é‡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, for the purpose of simplifying the discussion and examples in this section, we drop the bias term in this figure and throughout most of this section.",
            "zh": "æ­¤å¤–ï¼Œä¸ºäº†ç®€åŒ–æœ¬èŠ‚ä¸­çš„è®¨è®ºå’Œç¤ºä¾‹ï¼Œæˆ‘ä»¬åˆ é™¤äº†æœ¬å›¾å’Œæœ¬èŠ‚å¤§éƒ¨åˆ†å†…å®¹ä¸­çš„åå·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this easily in Figure 5.10(b)[201], as d15 is well outside the target hypersphere.",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å›¾5.10ï¼ˆbï¼‰[201]ä¸­å¾ˆå®¹æ˜“çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸ºd15è¿œè¿œè¶…å‡ºç›®æ ‡è¶…çƒä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that it is the policy, Ï€, that determines which action an agent will take in a given state, it is reasonable to assume that if an agent follows different policies, then the agent can expect to earn different levels of returnâ€”some higher and some lower.",
            "zh": "é‰´äºæ”¿ç­–Ï€å†³å®šäº†ä»£ç†äººåœ¨ç»™å®šçŠ¶æ€ä¸‹å°†é‡‡å–çš„è¡ŒåŠ¨ï¼Œå› æ­¤å¯ä»¥åˆç†åœ°å‡è®¾ï¼Œå¦‚æœä»£ç†äººéµå¾ªä¸åŒçš„æ”¿ç­–ï¼Œé‚£ä¹ˆä»£ç†äººå¯ä»¥æœŸæœ›è·å¾—ä¸åŒæ°´å¹³çš„å›æŠ¥â€”â€”æœ‰äº›æ›´é«˜ï¼Œæœ‰äº›æ›´ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, the decision boundary is much smoother than the decision boundaries of the other models we have looked at in this section.",
            "zh": "æ­¤å¤–ï¼Œå†³ç­–è¾¹ç•Œæ¯”æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­æŸ¥çœ‹çš„å…¶ä»–æ¨¡å‹çš„å†³ç­–è¾¹ç•Œè¦å¹³æ»‘å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.5.2â€ƒDomain independent measures of errorâ€ƒThe fact that root mean squared error and mean absolute error are in the same units as the target feature itself can be attractive, as it gives a very intuitive measure of how well a model is performingâ€”for example, a model is typically 1.38mg out in its dosage predictions.",
            "zh": "9.4.5.2 ä¸åŸŸæ— å…³çš„è¯¯å·®åº¦é‡ å‡æ–¹æ ¹è¯¯å·®å’Œå¹³å‡ç»å¯¹è¯¯å·®ä¸ç›®æ ‡ç‰¹å¾æœ¬èº«çš„å•ä½ç›¸åŒè¿™ä¸€äº‹å®å¯èƒ½å¾ˆæœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒå¯ä»¥éå¸¸ç›´è§‚åœ°è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œä¾‹å¦‚ï¼Œæ¨¡å‹çš„å‰‚é‡é¢„æµ‹é€šå¸¸ä¸º 1.38mgã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, to align with this general terminology, for this discussion we switch from discussing z values for a neuron to discussing the logit of the neuron.",
            "zh": "å› æ­¤ï¼Œä¸ºäº†ä¸è¿™ä¸ªé€šç”¨æœ¯è¯­ä¿æŒä¸€è‡´ï¼Œåœ¨æœ¬æ¬¡è®¨è®ºä¸­ï¼Œæˆ‘ä»¬ä»è®¨è®ºç¥ç»å…ƒçš„ z å€¼åˆ‡æ¢åˆ°è®¨è®ºç¥ç»å…ƒçš„ logitã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, beyond highlighting that the Jaccard index is useful for sparse binary data, we cannot give a hard and fast rule for how to choose between these indexes.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œé™¤äº†å¼ºè°ƒ Jaccard ç´¢å¼•å¯¹ç¨€ç–äºŒè¿›åˆ¶æ•°æ®æœ‰ç”¨ä¹‹å¤–ï¼Œæˆ‘ä»¬æ— æ³•ç»™å‡ºå¦‚ä½•åœ¨è¿™äº›ç´¢å¼•ä¹‹é—´è¿›è¡Œé€‰æ‹©çš„ç¡¬æ€§è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.5â€…â€…â€…Summary",
            "zh": "8.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "As the decision boundary is a linear separator, it can be defined using the equation of the line (remember Equation (7.2.1)[313]).",
            "zh": "ç”±äºå†³ç­–è¾¹ç•Œæ˜¯çº¿æ€§åˆ†éš”ç¬¦ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ç›´çº¿æ–¹ç¨‹æ¥å®šä¹‰ï¼ˆè®°ä½æ–¹ç¨‹ï¼ˆ7.2.1ï¼‰[313]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.11[278], extended to include the conditional probabilities for the new ACCOUNT BALANCE feature, which are defined in terms of PDFs.",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨ 6.11[278] ä¸­çš„æ•°æ®é›†è®¡ç®—å¾—å‡ºï¼Œæ‰©å±•ä¸ºåŒ…æ‹¬æ–°çš„ ACCOUNT BALANCE ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ï¼Œè¿™äº›æ¦‚ç‡æ˜¯æ ¹æ® PDF å®šä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The behavior policy used was Îµ greedy, but linear annealing was also used.",
            "zh": "ä½¿ç”¨çš„è¡Œä¸ºç­–ç•¥Îµè´ªå©ªï¼Œä½†ä¹Ÿä½¿ç”¨äº†çº¿æ€§é€€ç«ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dot product of two high-dimensional vectors is a computationally expensive operation, but a clever trickâ€”the kernel trickâ€”is used to avoid it.",
            "zh": "ä¸¤ä¸ªé«˜ç»´å‘é‡çš„ç‚¹ç§¯æ˜¯ä¸€é¡¹è®¡ç®—æˆæœ¬é«˜æ˜‚çš„æ“ä½œï¼Œä½†ä½¿ç”¨äº†ä¸€ä¸ªèªæ˜çš„æŠ€å·§â€”â€”æ ¸æŠ€å·§â€”â€”æ¥é¿å…å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "negative",
            "zh": "é˜´æ€§"
        }
    },
    {
        "translation": {
            "en": "So to obtain independent sample states, we often sub-sample from the sequence (sub-sampling in this way is also known as thinning).",
            "zh": "å› æ­¤ï¼Œä¸ºäº†è·å¾—ç‹¬ç«‹çš„é‡‡æ ·çŠ¶æ€ï¼Œæˆ‘ä»¬ç»å¸¸ä»åºåˆ—ä¸­è¿›è¡Œå­é‡‡æ ·ï¼ˆè¿™ç§æ–¹å¼çš„å­é‡‡æ ·ä¹Ÿç§°ä¸ºç¨€é‡Šï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The depth of a neural network is equal to the number of hidden layers plus the output layer.",
            "zh": "ç¥ç»ç½‘ç»œçš„æ·±åº¦ç­‰äºéšè—å±‚æ•°åŠ ä¸Šè¾“å‡ºå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "A matrix is a 2-dimensional (n Ã— m) array of numbers.",
            "zh": "çŸ©é˜µæ˜¯äºŒç»´ ï¼ˆn Ã— mï¼‰ æ•°å­—æ•°ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Several different linkage methods for AHC exist in the literature; some of the most common are",
            "zh": "æ–‡çŒ®ä¸­å­˜åœ¨å‡ ç§ä¸åŒçš„AHCè¿æ¥æ–¹æ³•;ä¸€äº›æœ€å¸¸è§çš„æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Using the distance weighted k nearest neighbor approach, the prediction returned for a given query is the target level with the highest score when we sum the weights of the votes of the instances in the neighborhood of k nearest neighbors for each target level. The weighted k nearest neighbor model is defined as",
            "zh": "ä½¿ç”¨è·ç¦»åŠ æƒ k æœ€è¿‘é‚»æ–¹æ³•ï¼Œå½“æˆ‘ä»¬å°†æ¯ä¸ªç›®æ ‡æ°´å¹³çš„ k ä¸ªæœ€è¿‘é‚»é‚»åŸŸä¸­çš„å®ä¾‹çš„æŠ•ç¥¨æƒé‡ç›¸åŠ æ—¶ï¼Œä¸ºç»™å®šæŸ¥è¯¢è¿”å›çš„é¢„æµ‹æ˜¯å¾—åˆ†æœ€é«˜çš„ç›®æ ‡çº§åˆ«ã€‚åŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Jaynes, Edwin T. 2003. Probability theory: The logic of science. Cambridge University Press.",
            "zh": "æ°æ©æ–¯ï¼ŒåŸƒå¾·æ¸© T. 2003 å¹´ã€‚æ¦‚ç‡è®ºï¼šç§‘å­¦çš„é€»è¾‘ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "APERFLUX7_U/G/R/I/Z",
            "zh": "APERFLUX7_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Because this is the initial descent down the tree, best is automatically set to d12, and best-distance is set to the distance between instance d12 and the query, which is 1.4142 (we use Euclidean distance throughout this example).",
            "zh": "å› ä¸ºè¿™æ˜¯æ ‘çš„åˆå§‹ä¸‹é™ï¼Œæ‰€ä»¥ best ä¼šè‡ªåŠ¨è®¾ç½®ä¸º d12ï¼Œbest-distance è®¾ç½®ä¸ºå®ä¾‹ d12 å’ŒæŸ¥è¯¢ä¹‹é—´çš„è·ç¦»ï¼Œå³ 1.4142ï¼ˆæˆ‘ä»¬åœ¨æ­¤ç¤ºä¾‹ä¸­ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For Model 2, we need to look almost as far as the top 50% of predictions to find the same percentage of spam messages.",
            "zh": "å¯¹äºæ¨¡å‹ 2ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥çœ‹å‡ ä¹ä¸å‰ 50% çš„é¢„æµ‹ä¸€æ ·è¿œï¼Œæ‰èƒ½æ‰¾åˆ°ç›¸åŒç™¾åˆ†æ¯”çš„åƒåœ¾é‚®ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This structure directly reflects the assumption, made by naive Bayes models, of the conditional independence between descriptive features given knowledge of the target feature and is why the conditional probabilities of the descriptive features in a naive Bayes model are conditioned only on the target feature.",
            "zh": "è¿™ç§ç»“æ„ç›´æ¥åæ˜ äº†æœ´ç´ è´å¶æ–¯æ¨¡å‹åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çŸ¥è¯†çš„æƒ…å†µä¸‹æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§çš„å‡è®¾ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ´ç´ è´å¶æ–¯æ¨¡å‹ä¸­æè¿°æ€§ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ä»…ä»¥ç›®æ ‡ç‰¹å¾ä¸ºæ¡ä»¶çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.13â€…â€…â€…A Bayesian network that encodes the causal relationships between the features in the corruption domain. The CPT entries have been calculated using the binned data from Table 6.18[295].",
            "zh": "6.13 è´å¶æ–¯ç½‘ç»œï¼Œç”¨äºç¼–ç æŸååŸŸä¸­ç‰¹å¾ä¹‹é—´çš„å› æœå…³ç³»ã€‚CPTæ¡ç›®æ˜¯ä½¿ç”¨è¡¨6.18[295]ä¸­çš„åˆ†ç®±æ•°æ®è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "where n is the number of instances in the training dataset. A standard error calculation is then done for a descriptive feature as follows:",
            "zh": "å…¶ä¸­ n æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹æ•°ã€‚ç„¶åå¯¹æè¿°æ€§ç‰¹å¾è¿›è¡Œæ ‡å‡†è¯¯å·®è®¡ç®—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Most of the deep network models described in Chapter 8[381] are also discriminative models, although the auto-encoder network described in Chapter 10[597] is a nice example of a generative neural network.",
            "zh": "å°½ç®¡ç¬¬10ç« [597]ä¸­æè¿°çš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œæ˜¯ç”Ÿæˆç¥ç»ç½‘ç»œçš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œä½†ç¬¬8ç« [381]ä¸­æè¿°çš„å¤§å¤šæ•°æ·±åº¦ç½‘ç»œæ¨¡å‹ä¹Ÿæ˜¯åˆ¤åˆ«æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Returning to the motor insurance fraud detection case study, below we evaluate the feasibility of each proposed analytics solution in terms of data and business capacity requirements.",
            "zh": "å›åˆ°æ±½è½¦ä¿é™©æ¬ºè¯ˆæ£€æµ‹æ¡ˆä¾‹ç ”ç©¶ï¼Œä¸‹é¢æˆ‘ä»¬ä»æ•°æ®å’Œä¸šåŠ¡å®¹é‡è¦æ±‚çš„è§’åº¦è¯„ä¼°æ¯ä¸ªæ‹Ÿè®®çš„åˆ†æè§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is repeated until all the instances in a partition have the same target level, at which point a leaf node is created and labeled with that level.",
            "zh": "é‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°åˆ†åŒºä¸­çš„æ‰€æœ‰å®ä¾‹éƒ½å…·æœ‰ç›¸åŒçš„ç›®æ ‡çº§åˆ«ï¼Œæ­¤æ—¶å°†åˆ›å»ºä¸€ä¸ªå¶èŠ‚ç‚¹å¹¶ä½¿ç”¨è¯¥çº§åˆ«è¿›è¡Œæ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.12â€…â€…â€…The partitioning of the dataset in Table 4.11[152] based on SEASON and WORK DAY features and the computation of the weighted variance for each partitioning.",
            "zh": "4.12 è¡¨4.11[152]ä¸­åŸºäºSEASONå’ŒWORK DAYç‰¹å¾çš„æ•°æ®é›†åˆ†åŒºï¼Œä»¥åŠæ¯ä¸ªåˆ†åŒºçš„åŠ æƒæ–¹å·®è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.8",
            "zh": "è¡¨ 7.8"
        }
    },
    {
        "translation": {
            "en": "cross-sell model, 572",
            "zh": "äº¤å‰é”€å”®æ¨¡å‹ï¼Œ572"
        }
    },
    {
        "translation": {
            "en": "Using a hold-out test set avoids this problem, because none of the instances in the test set will have been used in the training process.",
            "zh": "ä½¿ç”¨ä¿ç•™æµ‹è¯•é›†å¯ä»¥é¿å…æ­¤é—®é¢˜ï¼Œå› ä¸ºæµ‹è¯•é›†ä¸­çš„ä»»ä½•å®ä¾‹éƒ½ä¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, to connect the activation of a hidden neuron ak to the network error â„°, we have to create a chain of connection via the activations of the downstream neurons.",
            "zh": "å› æ­¤ï¼Œä¸ºäº†å°†éšè—ç¥ç»å…ƒ ak çš„æ¿€æ´»ä¸ç½‘ç»œé”™è¯¯ E è”ç³»èµ·æ¥ï¼Œæˆ‘ä»¬å¿…é¡»é€šè¿‡æ¿€æ´»ä¸‹æ¸¸ç¥ç»å…ƒæ¥åˆ›å»ºè¿æ¥é“¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important that the details of any data preparation techniques we perform on the data in the ABT be saved (usually in the data quality plan) so that we can also apply the same techniques to newly arising data.",
            "zh": "é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¯¹ ABT ä¸­çš„æ•°æ®æ‰§è¡Œçš„ä»»ä½•æ•°æ®å‡†å¤‡æŠ€æœ¯çš„è¯¦ç»†ä¿¡æ¯éƒ½åº”ä¿å­˜ï¼ˆé€šå¸¸åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­ï¼‰ï¼Œä»¥ä¾¿æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ç›¸åŒçš„æŠ€æœ¯åº”ç”¨äºæ–°å‡ºç°çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using basis functions is a simple and effective way in which to capture non-linear relationships within a linear regression model.",
            "zh": "ä½¿ç”¨åŸºå‡½æ•°æ˜¯æ•è·çº¿æ€§å›å½’æ¨¡å‹ä¸­éçº¿æ€§å…³ç³»çš„ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "We donâ€™t know exactly what state an agent will arrive in after taking action at from state st, but from the transition matrix, at, we do know the probability of each possible transition between states, .",
            "zh": "æˆ‘ä»¬ä¸çŸ¥é“ä»£ç†åœ¨ä»çŠ¶æ€ st é‡‡å–è¡ŒåŠ¨åå°†åˆ°è¾¾ä»€ä¹ˆçŠ¶æ€ï¼Œä½†ä»è½¬æ¢çŸ©é˜µ at ä¸­ï¼Œæˆ‘ä»¬ç¡®å®çŸ¥é“çŠ¶æ€ä¹‹é—´æ¯ä¸ªå¯èƒ½çš„è½¬æ¢çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 8.32[481] shows a second neuron with a different local receptive field, and Equation (8.87)[482] shows the calculation of the activation of this neuron if it uses the same set of weights.",
            "zh": "ä¾‹å¦‚ï¼Œå›¾8.32[481]æ˜¾ç¤ºäº†å…·æœ‰ä¸åŒå±€éƒ¨æ„Ÿå—é‡çš„ç¬¬äºŒä¸ªç¥ç»å…ƒï¼Œè€Œæ–¹ç¨‹ï¼ˆ8.87ï¼‰[482]æ˜¾ç¤ºäº†å¦‚æœè¯¥ç¥ç»å…ƒä½¿ç”¨ç›¸åŒçš„æƒé‡é›†ï¼Œåˆ™è¯¥ç¥ç»å…ƒçš„æ¿€æ´»è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comparing Table 8.8[433] with Table 8.4[426], we see that the model made a slightly different prediction for each example; the prediction for d2 is now 0.4741 whereas the original prediction was 0.4718.",
            "zh": "å°†è¡¨8.8[433]ä¸è¡¨8.4[426]è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹å¯¹æ¯ä¸ªç¤ºä¾‹çš„é¢„æµ‹ç•¥æœ‰ä¸åŒ;D2çš„é¢„æµ‹ç°åœ¨æ˜¯0.4741ï¼Œè€Œæœ€åˆçš„é¢„æµ‹æ˜¯0.4718ã€‚"
        }
    },
    {
        "translation": {
            "en": "The last two layers of the network are typical of the types of layers that are used near the output of a convolutional network when it is used for image classification.",
            "zh": "ç½‘ç»œçš„æœ€åä¸¤å±‚æ˜¯å·ç§¯ç½‘ç»œç”¨äºå›¾åƒåˆ†ç±»æ—¶åœ¨è¾“å‡ºé™„è¿‘ä½¿ç”¨çš„å…¸å‹å±‚ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Alongside these descriptive features is a target feature, GRP, that describes the demographic group for each customer (single, couple, or family).",
            "zh": "é™¤äº†è¿™äº›æè¿°æ€§åŠŸèƒ½ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªç›®æ ‡åŠŸèƒ½ GRPï¼Œç”¨äºæè¿°æ¯ä¸ªå®¢æˆ·ï¼ˆå•èº«ã€å¤«å¦»æˆ–å®¶åº­ï¼‰çš„äººå£ç»Ÿè®¡ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Siddiqi, Naeem. 2005. Credit risk scorecards: Developing and implementing intelligent credit scoring. Wiley.",
            "zh": "è¥¿è¿ªå¥‡ï¼Œçº³ä¼Šå§†ã€‚2005. ä¿¡ç”¨é£é™©è®°åˆ†å¡ï¼šå¼€å‘å’Œå®æ–½æ™ºèƒ½ä¿¡ç”¨è¯„åˆ†ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy scores achieved by the models were 54.663%, 62.137%, and 58.107% by the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "kæœ€è¿‘é‚»æ¨¡å‹ã€é€»è¾‘å›å½’æ¨¡å‹å’Œæ”¯æŒå‘é‡æœºæ¨¡å‹çš„å¹³å‡ç±»å‡†ç¡®ç‡å¾—åˆ†åˆ†åˆ«ä¸º54.663%ã€62.137%å’Œ58.107%ã€‚"
        }
    },
    {
        "translation": {
            "en": "The overall accuracy of this model is somewhat comparable with the overall accuracy of the 3-level model.",
            "zh": "è¯¥æ¨¡å‹çš„æ•´ä½“ç²¾åº¦ä¸ä¸‰ç”µå¹³æ¨¡å‹çš„æ•´ä½“ç²¾åº¦ç›¸å½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "data manipulation tools, 42",
            "zh": "æ•°æ®æ“ä½œå·¥å…·ï¼Œ42"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE features was found to be valid, because these are categorical features and can only take values in a small range, as people tend not to make very many claims.",
            "zh": "SOFT TISSUE ç‰¹å¾è¢«å‘ç°æ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºè¿™äº›æ˜¯åˆ†ç±»ç‰¹å¾ï¼Œå¹¶ä¸”åªèƒ½åœ¨å¾ˆå°çš„èŒƒå›´å†…å–å€¼ï¼Œå› ä¸ºäººä»¬å¾€å¾€ä¸ä¼šæå‡ºå¾ˆå¤šä¸»å¼ ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the difficulties with learning a network structure is that we can always improve the likelihood of the data given a network by simply adding new links into the network.",
            "zh": "å­¦ä¹ ç½‘ç»œç»“æ„çš„å›°éš¾ä¹‹ä¸€æ˜¯ï¼Œæˆ‘ä»¬æ€»æ˜¯å¯ä»¥é€šè¿‡ç®€å•åœ°åœ¨ç½‘ç»œä¸­æ·»åŠ æ–°é“¾æ¥æ¥æé«˜ç»™å®šç½‘ç»œæ•°æ®çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4.2â€ƒDeep Q Networks",
            "zh": "11.4.2 Deep Q ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "The reason for its fame is that its victory in the ImageNet LargeScale Visual Recognition Challenges (ILSVRC) in 2012 was a watershed moment for deep learning that reinvigorated a lot of interest in the field of neural networks.",
            "zh": "å®ƒä¹‹æ‰€ä»¥æˆåï¼Œæ˜¯å› ä¸ºå®ƒåœ¨ 2012 å¹´çš„ ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ› ï¼ˆILSVRCï¼‰ ä¸­çš„èƒœåˆ©æ˜¯æ·±åº¦å­¦ä¹ çš„åˆ†æ°´å²­ï¼Œé‡æ–°æ¿€å‘äº†äººä»¬å¯¹ç¥ç»ç½‘ç»œé¢†åŸŸçš„æµ“åšå…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "The curved shape of the harmonic mean surface shows that the harmonic mean emphasizes the contribution of smaller values more than the arithmetic meanâ€”note how the sides of the surface are pulled down to the base of the graph by the harmonic mean.",
            "zh": "è°æ³¢å¹³å‡æ›²é¢çš„å¼¯æ›²å½¢çŠ¶è¡¨æ˜ï¼Œè°æ³¢å‡å€¼æ¯”ç®—æœ¯å‡å€¼æ›´å¼ºè°ƒè¾ƒå°å€¼çš„è´¡çŒ® - è¯·æ³¨æ„ï¼Œè°æ³¢å‡å€¼å¦‚ä½•å°†æ›²é¢çš„ä¾§é¢æ‹‰åˆ°å›¾å½¢çš„åº•éƒ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recognizing that a feature follows an exponential distribution is another clear warning sign that outliers are likely.",
            "zh": "è¯†åˆ«ç‰¹å¾éµå¾ªæŒ‡æ•°åˆ†å¸ƒæ˜¯å¦ä¸€ä¸ªæ˜ç¡®çš„è­¦å‘Šä¿¡å·ï¼Œè¡¨æ˜å¯èƒ½å­˜åœ¨å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.3668",
            "zh": "0.3668"
        }
    },
    {
        "translation": {
            "en": "These initial baseline results were promising; however, one key issue did emerge.",
            "zh": "è¿™äº›åˆæ­¥åŸºçº¿ç»“æœæ˜¯æœ‰å¸Œæœ›çš„;ç„¶è€Œï¼Œä¸€ä¸ªå…³é”®é—®é¢˜ç¡®å®å‡ºç°äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that the MNIST handwriting recognition case study we are using in this section involves grayscale images.",
            "zh": "åŸå› æ˜¯æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­ä½¿ç”¨çš„ MNIST æ‰‹å†™è¯†åˆ«æ¡ˆä¾‹ç ”ç©¶æ¶‰åŠç°åº¦å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning, and its Q-learning (off-policy) and SARSA (on-policy) variants, are standard approaches to reinforcement learning and have been used effectively in a variety of environments.",
            "zh": "æ—¶é—´å·®åˆ†å­¦ä¹ åŠå…¶ Q å­¦ä¹ ï¼ˆç­–ç•¥å¤–ï¼‰å’Œ SARSAï¼ˆç­–ç•¥å†…ï¼‰å˜ä½“æ˜¯å¼ºåŒ–å­¦ä¹ çš„æ ‡å‡†æ–¹æ³•ï¼Œå¹¶å·²åœ¨å„ç§ç¯å¢ƒä¸­æœ‰æ•ˆä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the errors show that, in general, predictions made by the candidate model are too high, then w[j] should be decreased if di[j] is positive and increased if di[j] is negative.",
            "zh": "å¦‚æœè¯¯å·®è¡¨æ˜ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œå€™é€‰æ¨¡å‹çš„é¢„æµ‹å€¼å¤ªé«˜ï¼Œé‚£ä¹ˆå¦‚æœ di[j] ä¸ºæ­£ï¼Œåˆ™ w[j] åº”å‡å°ï¼Œå¦‚æœ di[j] ä¸ºè´Ÿï¼Œåˆ™åº”å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "P_ACW",
            "zh": "P_ACW"
        }
    },
    {
        "translation": {
            "en": "A portion of the action-value table for the grid world example after 350 episodes of Q-learning have elapsed.",
            "zh": "åœ¨ 350 é›† Q å­¦ä¹ ä¹‹åï¼Œç½‘æ ¼ä¸–ç•Œç¤ºä¾‹çš„æ“ä½œå€¼è¡¨çš„ä¸€éƒ¨åˆ†å·²ç»è¿‡å»ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.9â€…â€…â€…(a) A Bayesian network for a domain consisting of two binary features. The structure of the network states that the value of feature A directly influences the value of feature B. (b) A Bayesian network consisting of four binary features with a path containing three generations of nodes: D, C, and B.",
            "zh": "6.9 ï¼ˆaï¼‰ ç”±ä¸¤ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ç»„æˆçš„åŸŸçš„è´å¶æ–¯ç½‘ç»œã€‚ï¼ˆbï¼‰ è´å¶æ–¯ç½‘ç»œï¼Œç”±å››ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ç»„æˆï¼Œå…¶è·¯å¾„åŒ…å«ä¸‰ä»£èŠ‚ç‚¹ï¼šDã€C å’Œ Bã€‚"
        }
    },
    {
        "translation": {
            "en": "The columns labeled i(d) give the predictions made by the model trained at iteration i for each instance in the training dataset.",
            "zh": "æ ‡è®°ä¸º iï¼ˆdï¼‰ çš„åˆ—ç»™å‡ºäº†åœ¨è¿­ä»£ i ä¸­è®­ç»ƒçš„æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹æ‰€åšçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2â€ƒFundamentals",
            "zh": "4.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "No model will ever be perfect, so some fraction of the predictions made by every model will be incorrect.",
            "zh": "æ²¡æœ‰ä¸€ä¸ªæ¨¡å‹æ˜¯å®Œç¾çš„ï¼Œå› æ­¤æ¯ä¸ªæ¨¡å‹æ‰€åšçš„é¢„æµ‹ä¸­éƒ½æœ‰ä¸€éƒ¨åˆ†æ˜¯ä¸æ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with all tree representations, a decision tree consists of a root node (or starting node), interior nodes, and leaf nodes (or terminating nodes) that are connected by branches.",
            "zh": "ä¸æ‰€æœ‰æ ‘è¡¨ç¤ºä¸€æ ·ï¼Œå†³ç­–æ ‘ç”±æ ¹èŠ‚ç‚¹ï¼ˆæˆ–èµ·å§‹èŠ‚ç‚¹ï¼‰ã€å†…éƒ¨èŠ‚ç‚¹å’Œå¶èŠ‚ç‚¹ï¼ˆæˆ–ç»ˆæ­¢èŠ‚ç‚¹ï¼‰ç»„æˆï¼Œè¿™äº›èŠ‚ç‚¹ç”±åˆ†æ”¯è¿æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate L2 we use our candidate model w to make a prediction for each member of the training dataset, , and then calculate the error (or residual) between these predictions and the actual target feature values in the training set.",
            "zh": "ä¸ºäº†è®¡ç®— L2ï¼Œæˆ‘ä»¬ä½¿ç”¨å€™é€‰æ¨¡å‹ w å¯¹è®­ç»ƒæ•°æ®é›†çš„æ¯ä¸ªæˆå‘˜è¿›è¡Œé¢„æµ‹ï¼Œç„¶åè®¡ç®—è¿™äº›é¢„æµ‹ä¸è®­ç»ƒé›†ä¸­çš„å®é™…ç›®æ ‡ç‰¹å¾å€¼ä¹‹é—´çš„è¯¯å·®ï¼ˆæˆ–æ®‹å·®ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use the notation l to denote a vector of logits for a layer of neurons, and li to indicate the logit for the ith neuron in the layer.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç¬¦å· l è¡¨ç¤ºä¸€å±‚ç¥ç»å…ƒçš„ logits å‘é‡ï¼Œå¹¶ä½¿ç”¨ li è¡¨ç¤ºè¯¥å±‚ä¸­ç¬¬ i ä¸ªç¥ç»å…ƒçš„ logitã€‚"
        }
    },
    {
        "translation": {
            "en": "Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research 15 (1): 1929â€“1958.",
            "zh": "æ–¯é‡Œç“¦æ–¯å¡”ç“¦ã€å°¼è’‚ä»€ã€æ°å¼—é‡ŒÂ·è¾›é¡¿ã€äºšå†å…‹æ–¯Â·å…‹é‡Œçƒ­å¤«æ–¯åŸºã€ä¼Šåˆ©äºšÂ·è‹èŒ¨å…‹å¼—å’Œé²æ–¯å…°Â·è¨æ‹‰èƒ¡è¿ªè¯ºå¤«ã€‚2014. Dropoutï¼šä¸€ç§é˜²æ­¢ç¥ç»ç½‘ç»œè¿‡æ‹Ÿåˆçš„ç®€å•æ–¹æ³•ã€‚æœºå™¨å­¦ä¹ ç ”ç©¶æ‚å¿— 15 ï¼ˆ1ï¼‰ï¼š 1929â€“1958."
        }
    },
    {
        "translation": {
            "en": "Lift can take values in the range [0,âˆ], and higher values indicate that a model is performing well at a particular decile.",
            "zh": "æå‡å¯ä»¥å– [0ï¼Œâˆ] èŒƒå›´å†…çš„å€¼ï¼Œè¾ƒé«˜çš„å€¼è¡¨ç¤ºæ¨¡å‹åœ¨ç‰¹å®šååˆ†ä½æ•°ä¸Šè¡¨ç°è‰¯å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "A probability function is a function that takes an event (an assignment of values to features) as a parameter and returns the likelihood of that event.",
            "zh": "æ¦‚ç‡å‡½æ•°æ˜¯å°†äº‹ä»¶ï¼ˆä¸ºè¦ç´ èµ‹å€¼ï¼‰ä½œä¸ºå‚æ•°å¹¶è¿”å›è¯¥äº‹ä»¶çš„å¯èƒ½æ€§çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this appendix we present the basic differentiation techniques that are required to understand how linear regression can be used to build predictive analytics models. In particular we explain what a derivative is, how to calculate derivatives for continuous functions, the chain rule for differentiation, and what a partial derivative is.",
            "zh": "åœ¨æœ¬é™„å½•ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»äº†è§£å¦‚ä½•ä½¿ç”¨çº¿æ€§å›å½’æ„å»ºé¢„æµ‹åˆ†ææ¨¡å‹æ‰€éœ€çš„åŸºæœ¬å¾®åˆ†æŠ€æœ¯ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è§£é‡Šäº†ä»€ä¹ˆæ˜¯å¯¼æ•°ï¼Œå¦‚ä½•è®¡ç®—è¿ç»­å‡½æ•°çš„å¯¼æ•°ï¼Œå¾®åˆ†çš„é“¾å¼æ³•åˆ™ä»¥åŠä»€ä¹ˆæ˜¯åå¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.1â€…â€…â€…Multivariable Linear Regression",
            "zh": "7.3.1 å¤šå˜é‡çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "Given that the preceding analysis in Section 8.2.4[394] showed that a network with multiple layers of linear neurons is equivalent to a single-layer network of linear functions, a natural question is, why is adding extra layers to a network (even with non-linearities) a useful thing to do?",
            "zh": "é‰´äºå‰é¢åœ¨ç¬¬8.2.4èŠ‚[394]ä¸­çš„åˆ†æè¡¨æ˜ï¼Œå…·æœ‰å¤šå±‚çº¿æ€§ç¥ç»å…ƒçš„ç½‘ç»œç­‰åŒäºçº¿æ€§å‡½æ•°çš„å•å±‚ç½‘ç»œï¼Œä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼Œä¸ºä»€ä¹ˆå‘ç½‘ç»œæ·»åŠ é¢å¤–çš„å±‚ï¼ˆå³ä½¿å…·æœ‰éçº¿æ€§ï¼‰æ˜¯ä¸€ä»¶æœ‰ç”¨çš„äº‹æƒ…ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "As a result, the CPT representation is sufficient to handle both categorical and (binned) continuous features.",
            "zh": "å› æ­¤ï¼ŒCPT è¡¨ç¤ºè¶³ä»¥å¤„ç†åˆ†ç±»ç‰¹å¾å’Œï¼ˆåˆ†ç®±ï¼‰è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 12.2",
            "zh": "è¡¨ 12.2"
        }
    },
    {
        "translation": {
            "en": "channel, 492",
            "zh": "é¢‘é“ï¼Œ492"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, adding nodes in this way results in the tree becoming unbalanced, which can have a detrimental effect on the efficiency of the tree.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œä»¥è¿™ç§æ–¹å¼æ·»åŠ èŠ‚ç‚¹ä¼šå¯¼è‡´æ ‘å˜å¾—ä¸å¹³è¡¡ï¼Œè¿™å¯èƒ½ä¼šå¯¹æ ‘çš„æ•ˆç‡äº§ç”Ÿä¸åˆ©å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the inverse covariance matrix used in the calculations is based on the covariance matrix24 calculated directly from the dataset:",
            "zh": "å…¶ä¸­ï¼Œè®¡ç®—ä¸­ä½¿ç”¨çš„é€†åæ–¹å·®çŸ©é˜µåŸºäºç›´æ¥ä»æ•°æ®é›†è®¡ç®—çš„åæ–¹å·®çŸ©é˜µ24ï¼š"
        }
    },
    {
        "translation": {
            "en": "With the target feature suitably defined, Rossâ€™s next task was to determine the domain concepts that would underpin the design of the ABT.",
            "zh": "åœ¨æ­£ç¡®å®šä¹‰äº†ç›®æ ‡åŠŸèƒ½åï¼ŒRoss çš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯ç¡®å®šæ”¯æ’‘ ABT è®¾è®¡çš„é¢†åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "Burglary is also rare, and if it is a stormy night, burglars are likely to stay at home (burglars donâ€™t like going out in storms).",
            "zh": "å…¥å®¤ç›—çªƒä¹Ÿå¾ˆå°‘è§ï¼Œå¦‚æœæ˜¯æš´é£é›¨çš„å¤œæ™šï¼Œçªƒè´¼å¾ˆå¯èƒ½ä¼šå‘†åœ¨å®¶é‡Œï¼ˆçªƒè´¼ä¸å–œæ¬¢åœ¨æš´é£é›¨ä¸­å¤–å‡ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. In interval notation, a square bracket, [ or ], indicates that the boundary value is included in the interval, and a parenthesis, ( or ), indicates that it is excluded from the interval.",
            "zh": "12. åœ¨åŒºé—´è¡¨ç¤ºæ³•ä¸­ï¼Œæ–¹æ‹¬å· [ æˆ– ]ï¼Œ è¡¨ç¤ºè¾¹ç•Œå€¼åŒ…å«åœ¨åŒºé—´ä¸­ï¼Œæ‹¬å· ï¼ˆ æˆ– ï¼‰ è¡¨ç¤ºå®ƒè¢«æ’é™¤åœ¨åŒºé—´ä¹‹å¤–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The bad news is that the patient has tested positive for a serious disease and that the test the doctor used is 99% accurate (i.e., the probability of testing positive when a patient has the disease is 0.99, as is the probability of testing negative when a patient does not have the disease).",
            "zh": "åæ¶ˆæ¯æ˜¯ï¼Œæ‚£è€…å¯¹ä¸¥é‡ç–¾ç—…çš„æ£€æµ‹å‘ˆé˜³æ€§ï¼Œè€ŒåŒ»ç”Ÿä½¿ç”¨çš„æ£€æµ‹å‡†ç¡®ç‡ä¸º 99%ï¼ˆå³ï¼Œå½“æ‚£è€…æ‚£æœ‰ç–¾ç—…æ—¶æ£€æµ‹å‘ˆé˜³æ€§çš„æ¦‚ç‡ä¸º 0.99ï¼Œå½“æ‚£è€…æ²¡æœ‰ç–¾ç—…æ—¶æ£€æµ‹å‘ˆé˜´æ€§çš„æ¦‚ç‡ä¹Ÿæ˜¯å¦‚æ­¤ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each non-leaf node (root and interior) in the tree specifies a test to be carried out on a descriptive feature.",
            "zh": "æ ‘ä¸­çš„æ¯ä¸ªéå¶èŠ‚ç‚¹ï¼ˆæ ¹èŠ‚ç‚¹å’Œå†…éƒ¨èŠ‚ç‚¹ï¼‰éƒ½æŒ‡å®šè¦å¯¹æè¿°æ€§ç‰¹å¾æ‰§è¡Œçš„æµ‹è¯•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mr. Murphy walked to the kitchen to have a look and agreed with his son that he too had done a great job of organizing the letters.",
            "zh": "å¢¨è²å…ˆç”Ÿèµ°åˆ°å¨æˆ¿çœ‹äº†çœ‹ï¼Œå¹¶åŒæ„å„¿å­çš„æ„è§ï¼Œè¯´ä»–åœ¨æ•´ç†ä¿¡ä»¶æ–¹é¢ä¹Ÿåšå¾—å¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13[410] illustrates this relationship between the slope of the graph of a function and its derivative.",
            "zh": "å›¾8.13[410]è¯´æ˜äº†å‡½æ•°å›¾çš„æ–œç‡ä¸å…¶å¯¼æ•°ä¹‹é—´çš„è¿™ç§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The AHC algorithm begins by considering each instance in a dataset to be the only member of a cluster, which gives n initial clusters, ğ’1 to ğ’n. The two clusters that are nearest are then merged (or agglomerated) to form a new cluster. This process repeats over and over until a single cluster containing all instances in the dataset is formed. Figure 10.10[617] shows how AHC can be used for find the intuitive clusterings in the half-moons and circles datasets as well as the blobs dataset.",
            "zh": "AHC ç®—æ³•é¦–å…ˆå°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹è§†ä¸ºé›†ç¾¤çš„å”¯ä¸€æˆå‘˜ï¼Œè¿™ç»™å‡ºäº† n ä¸ªåˆå§‹é›†ç¾¤ï¼Œä» C1 åˆ° Cnã€‚ç„¶åï¼Œå°†æœ€è¿‘çš„ä¸¤ä¸ªé›†ç¾¤åˆå¹¶ï¼ˆæˆ–èšé›†ï¼‰ä»¥å½¢æˆä¸€ä¸ªæ–°é›†ç¾¤ã€‚æ­¤è¿‡ç¨‹ä¸€éåˆä¸€éåœ°é‡å¤ï¼Œç›´åˆ°å½¢æˆåŒ…å«æ•°æ®é›†ä¸­æ‰€æœ‰å®ä¾‹çš„å•ä¸ªé›†ç¾¤ã€‚å›¾ 10.10[617] æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨ AHC åœ¨åŠæœˆå’Œåœ†æ•°æ®é›†ä»¥åŠ blobs æ•°æ®é›†ä¸­æŸ¥æ‰¾ç›´è§‚çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.1â€…â€…â€…Big Idea",
            "zh": "8.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "An illustration of how different small networks are generated for different training examples by applying dropout to the original large network. The gray nodes mark the neurons that have been dropped from the network for the training example.",
            "zh": "é€šè¿‡å¯¹åŸå§‹å¤§å‹ç½‘ç»œåº”ç”¨dropoutï¼Œå¦‚ä½•ä¸ºä¸åŒçš„è®­ç»ƒç¤ºä¾‹ç”Ÿæˆä¸åŒçš„å°å‹ç½‘ç»œçš„è¯´æ˜ã€‚ç°è‰²èŠ‚ç‚¹æ ‡è®°äº†å·²ä»ç½‘ç»œä¸­åˆ é™¤çš„ç¥ç»å…ƒï¼Œä»¥ç”¨äºè®­ç»ƒç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this stage, these reconstructed images are already beginning to resemble the originals on which they are based.",
            "zh": "åœ¨è¿™ä¸ªé˜¶æ®µï¼Œè¿™äº›é‡å»ºçš„å›¾åƒå·²ç»å¼€å§‹ç±»ä¼¼äºå®ƒä»¬æ‰€åŸºäºçš„åŸå§‹å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "ti refers to the value of the target feature of the ith instance in a dataset",
            "zh": "Ti æ˜¯æŒ‡æ•°æ®é›†ä¸­ç¬¬ i ä¸ªå®ä¾‹çš„ç›®æ ‡ç‰¹å¾çš„å€¼"
        }
    },
    {
        "translation": {
            "en": "23. See Equation (8.4)[386] and Figure 8.2[387].",
            "zh": "23. å‚è§å…¬å¼ï¼ˆ8.4ï¼‰[386]å’Œå›¾8.2[387]ã€‚"
        }
    },
    {
        "translation": {
            "en": "The classification accuracies achieved during the cross validation experiment were 82.912%, 86.041%, and 85.942% by the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "åœ¨äº¤å‰éªŒè¯å®éªŒä¸­ï¼Œkæœ€è¿‘é‚»æ¨¡å‹ã€é€»è¾‘å›å½’å’Œæ”¯æŒå‘é‡æœºæ¨¡å‹çš„åˆ†ç±»ç²¾åº¦åˆ†åˆ«ä¸º82.912%ã€86.041%å’Œ85.942%ã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantage of this is that learning can happen quickly as updates are made after each action the agent takes.",
            "zh": "è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå­¦ä¹ å¯ä»¥å¿«é€Ÿè¿›è¡Œï¼Œå› ä¸ºåœ¨ä»£ç†é‡‡å–çš„æ¯ä¸ªæ“ä½œä¹‹åéƒ½ä¼šè¿›è¡Œæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm and other algorithms like it impose an expected global structure onto the clustering processâ€”essentially, the k-means algorithm searches for tightly packed spherical clusters.",
            "zh": "k å‡å€¼èšç±»ç®—æ³•å’Œå…¶ä»–ç±»ä¼¼ç®—æ³•å°†é¢„æœŸçš„å…¨å±€ç»“æ„å¼ºåŠ ç»™èšç±»è¿‡ç¨‹ï¼Œä»æœ¬è´¨ä¸Šè®²ï¼Œk å‡å€¼ç®—æ³•æœç´¢ç´§å¯†å †ç§¯çš„çƒå½¢èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The word batch is used because only one adjustment is made to each weight at each iteration of the algorithm based on summing the squared error made by the candidate model for each instance in the training dataset.7 Batch gradient descent is a straightforward, accurate, and reasonably efficient approach to training multivariable linear regression models and is used widely in practice.",
            "zh": "ä¹‹æ‰€ä»¥ä½¿ç”¨â€œæ‰¹å¤„ç†â€ä¸€è¯ï¼Œæ˜¯å› ä¸ºåœ¨ç®—æ³•çš„æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæ ¹æ®è®­ç»ƒæ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹çš„å€™é€‰æ¨¡å‹æ‰€çŠ¯è¯¯å·®çš„å¹³æ–¹ç›¸åŠ ï¼Œåªå¯¹æ¯ä¸ªæƒé‡è¿›è¡Œä¸€æ¬¡è°ƒæ•´.7 æ‰¹å¤„ç†æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ç®€å•ã€å‡†ç¡®ä¸”ç›¸å½“æœ‰æ•ˆçš„è®­ç»ƒå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„æ–¹æ³•ï¼Œåœ¨å®è·µä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Equation (6.1)[247] listed the joint probability distribution for the four binary features in the meningitis diagnosis dataset in Table 6.1[246].",
            "zh": "ä¾‹å¦‚ï¼Œæ–¹ç¨‹ï¼ˆ6.1ï¼‰[247]åœ¨è¡¨6.1[246]ä¸­åˆ—å‡ºäº†è„‘è†œç‚è¯Šæ–­æ•°æ®é›†ä¸­å››ä¸ªäºŒå…ƒç‰¹å¾çš„è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The Manhattan distance, or taxi-cab distance, is so called because it is the distance that a taxi driver would have to cover if going from one point to another on a road system that is laid out in blocks, like the Manhattan road system.",
            "zh": "2. æ›¼å“ˆé¡¿è·ç¦»ï¼Œæˆ–å‡ºç§Ÿè½¦è·ç¦»ï¼Œä¹‹æ‰€ä»¥å¦‚æ­¤ç§°å‘¼ï¼Œæ˜¯å› ä¸ºå®ƒæ˜¯å‡ºç§Ÿè½¦å¸æœºåœ¨åˆ†å—å¸ƒå±€çš„é“è·¯ç³»ç»Ÿï¼ˆå¦‚æ›¼å“ˆé¡¿é“è·¯ç³»ç»Ÿï¼‰ä¸Šä»ä¸€ä¸ªç‚¹åˆ°å¦ä¸€ä¸ªç‚¹æ—¶å¿…é¡»è¦†ç›–çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Returning to 1798 and HMS Calcutta, the next day you accompany your men on the expedition up the river, and you encounter the strange animal the sailor had described to you. This time when you see the animal yourself, you realize that it definitely isnâ€™t a duck! It turns out that you and your men are the first Europeans to encounter a platypus.33",
            "zh": "å›åˆ° 1798 å¹´å’Œ HMS åŠ å°”å„ç­”ï¼Œç¬¬äºŒå¤©ä½ é™ªä½ çš„æ‰‹ä¸‹æ²¿æ²³æ¢é™©ï¼Œä½ é‡åˆ°äº†æ°´æ‰‹å‘ä½ æè¿°çš„å¥‡æ€ªåŠ¨ç‰©ã€‚è¿™ä¸€æ¬¡ï¼Œå½“ä½ äº²çœ¼çœ‹åˆ°è¿™åªåŠ¨ç‰©æ—¶ï¼Œä½ æ„è¯†åˆ°å®ƒç»å¯¹ä¸æ˜¯é¸­å­ï¼äº‹å®è¯æ˜ï¼Œä½ å’Œä½ çš„æ‰‹ä¸‹æ˜¯ç¬¬ä¸€æ‰¹é‡åˆ°é¸­å˜´å…½çš„æ¬§æ´²äºº33ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.2â€ƒFundamentals of Reinforcement Learning",
            "zh": "11.2.2 å¼ºåŒ–å­¦ä¹ åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "430.37",
            "zh": "430.37"
        }
    },
    {
        "translation": {
            "en": "Machine learning is a huge topic, however, and one book can only be so long.",
            "zh": "ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªå·¨å¤§çš„è¯é¢˜ï¼Œä¸€æœ¬ä¹¦åªèƒ½è¿™ä¹ˆé•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The typical value of a loan is $1,000, and the interest rate charged is 14%.",
            "zh": "è´·æ¬¾çš„å…¸å‹ä»·å€¼ä¸º 1,000 ç¾å…ƒï¼Œæ”¶å–çš„åˆ©ç‡ä¸º 14%ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this is done correctly, then the total probability mass for the set will remain equal to 1.0, but the spread of probabilities across the set will be smoother (hence the name smoothing).",
            "zh": "å¦‚æœæ“ä½œæ­£ç¡®ï¼Œåˆ™é›†åˆçš„æ€»æ¦‚ç‡è´¨é‡å°†ä¿æŒç­‰äº 1.0ï¼Œä½†æ•´ä¸ªé›†åˆä¸­çš„æ¦‚ç‡åˆ†å¸ƒå°†æ›´å¹³æ»‘ï¼ˆå› æ­¤ç§°ä¸ºå¹³æ»‘ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The easiest way to solve this problem is to employ a k nearest neighbor model, which uses a function of the target feature values of the k closest instances to a query.",
            "zh": "è§£å†³æ­¤é—®é¢˜çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ k æœ€è¿‘é‚»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æŸ¥è¯¢æœ€æ¥è¿‘çš„ k ä¸ªå®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "P_EL",
            "zh": "P_EL"
        }
    },
    {
        "translation": {
            "en": "Like stratified sampling, under-sampling begins by dividing a dataset into groups, where each group contains only instances that have a particular level for the feature to be under-sampled.",
            "zh": "ä¸åˆ†å±‚æŠ½æ ·ä¸€æ ·ï¼Œæ¬ é‡‡æ ·é¦–å…ˆå°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªç»„ï¼Œå…¶ä¸­æ¯ä¸ªç»„ä»…åŒ…å«å…·æœ‰è¦æ¬ é‡‡æ ·çš„ç‰¹å¾çš„ç‰¹å®šçº§åˆ«çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is not always correct to treat all outcomes equally.",
            "zh": "å¹³ç­‰å¯¹å¾…æ‰€æœ‰ç»“æœå¹¶ä¸æ€»æ˜¯æ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why the variance of z rapidly decreases for each layer as we move forward through the network as shown in Figure 8.23(b)[453].",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“æˆ‘ä»¬åœ¨ç½‘ç»œä¸­å‰è¿›æ—¶ï¼Œæ¯ä¸€å±‚çš„ z æ–¹å·®ä¼šè¿…é€Ÿå‡å°ï¼Œå¦‚å›¾ 8.23ï¼ˆbï¼‰[453] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The second convolutional layer uses two filters (Filters 3 and 4) and so contains two layers of neurons that share weights.",
            "zh": "ç¬¬äºŒä¸ªå·ç§¯å±‚ä½¿ç”¨ä¸¤ä¸ªæ»¤æ³¢å™¨ï¼ˆæ»¤æ³¢å™¨ 3 å’Œ 4ï¼‰ï¼Œå› æ­¤åŒ…å«ä¸¤å±‚å…±äº«æƒé‡çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "They achieve this goal by removing the repeated multiplication by the Whh matrix during backpropagation.",
            "zh": "ä»–ä»¬é€šè¿‡æ¶ˆé™¤åå‘ä¼ æ’­æœŸé—´ Whh çŸ©é˜µçš„é‡å¤ä¹˜æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, for any domain of reasonable complexity, it is not tractable to define the full joint probability distribution, and therefore probability-based prediction models build more compact representations of full joint probability distributions instead.",
            "zh": "å› æ­¤ï¼Œå¯¹äºä»»ä½•å…·æœ‰åˆç†å¤æ‚åº¦çš„é¢†åŸŸï¼Œå®šä¹‰å®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒéƒ½æ˜¯ä¸å®¹æ˜“å¤„ç†çš„ï¼Œå› æ­¤åŸºäºæ¦‚ç‡çš„é¢„æµ‹æ¨¡å‹ä¼šæ„å»ºæ›´ç´§å‡‘çš„å…¨è”åˆæ¦‚ç‡åˆ†å¸ƒè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplest way to prune a decision tree is to introduce early stopping criteria (similar to the early stopping criterion discussed in the preceding section) into the tree induction algorithm.",
            "zh": "ä¿®å‰ªå†³ç­–æ ‘çš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨æ ‘è¯±å¯¼ç®—æ³•ä¸­å¼•å…¥æ—©æœŸåœæ­¢æ ‡å‡†ï¼ˆç±»ä¼¼äºä¸Šä¸€èŠ‚ä¸­è®¨è®ºçš„æ—©æœŸåœæ­¢æ ‡å‡†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Monte Carlo methods, 298, 677",
            "zh": "è’™ç‰¹å¡ç½—æ–¹æ³•ï¼Œ298,677"
        }
    },
    {
        "translation": {
            "en": "8.3.2â€…â€…â€…Backpropagation: Backpropagating the Error Gradients",
            "zh": "8.3.2 åå‘ä¼ æ’­ï¼šåå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "Patients are not aware which group they have been assigned to during the trial (hence the need for the placebo).",
            "zh": "æ‚£è€…ä¸çŸ¥é“ä»–ä»¬åœ¨è¯•éªŒæœŸé—´è¢«åˆ†é…åˆ°å“ªä¸€ç»„ï¼ˆå› æ­¤éœ€è¦å®‰æ…°å‰‚ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We calculate the numerator in this term as follows:",
            "zh": "æˆ‘ä»¬è®¡ç®—è¯¥é¡¹ä¸­çš„åˆ†å­å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 7.20",
            "zh": "å›¾ 7.20"
        }
    },
    {
        "translation": {
            "en": "This could be expressed in a single descriptive feature counting the number of claims that the claimant has made in the past.",
            "zh": "è¿™å¯ä»¥ç”¨ä¸€ä¸ªå•ä¸€çš„æè¿°æ€§ç‰¹å¾æ¥è¡¨ç¤ºï¼Œå³è®¡ç®—ç´¢èµ”äººè¿‡å»æå‡ºçš„ç´¢èµ”æ•°ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This information can be useful in informing the development of more powerful models later in a project.",
            "zh": "è¿™äº›ä¿¡æ¯å¯ç”¨äºä¸ºé¡¹ç›®åæœŸæ›´å¼ºå¤§çš„æ¨¡å‹çš„å¼€å‘æä¾›ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examination of the histograms in Figures 3.1(c)[58] and 3.1(h)[58] show that the CLAIM AMOUNT and AMOUNT RECEIVED features have a number of large values (evidenced by the small bars to the right-hand side of these histograms) and that d302 is not unique.",
            "zh": "å¯¹å›¾3.1ï¼ˆcï¼‰[58]å’Œå›¾3.1ï¼ˆhï¼‰[58]ä¸­çš„ç›´æ–¹å›¾çš„æ£€æŸ¥è¡¨æ˜ï¼ŒCLAIM AMOUNTå’ŒAMOUNT RECEIVEDç‰¹å¾å…·æœ‰è®¸å¤šå¤§å€¼ï¼ˆç”±è¿™äº›ç›´æ–¹å›¾å³ä¾§çš„å°æ¡è¯æ˜ï¼‰ï¼Œå¹¶ä¸”d302ä¸æ˜¯å”¯ä¸€çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "These thresholded units are also known as perceptron networks (Rosenblatt, 1958); we introduce this terminology here because it is useful in the following discussion.",
            "zh": "è¿™äº›é˜ˆå€¼å•å…ƒä¹Ÿç§°ä¸ºæ„ŸçŸ¥å™¨ç½‘ç»œï¼ˆRosenblattï¼Œ1958ï¼‰;æˆ‘ä»¬åœ¨è¿™é‡Œä»‹ç»è¿™ä¸ªæœ¯è¯­ï¼Œå› ä¸ºå®ƒåœ¨ä¸‹é¢çš„è®¨è®ºä¸­å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "If a model has a relatively large weight on one input feature, then the output of the model can be very sensitive to small changes in the value of the feature and hence the outputs of the model can be very different for similar input vectors.",
            "zh": "å¦‚æœæ¨¡å‹åœ¨ä¸€ä¸ªè¾“å…¥ç‰¹å¾ä¸Šå…·æœ‰ç›¸å¯¹è¾ƒå¤§çš„æƒé‡ï¼Œåˆ™æ¨¡å‹çš„è¾“å‡ºå¯èƒ½å¯¹ç‰¹å¾å€¼çš„å¾®å°å˜åŒ–éå¸¸æ•æ„Ÿï¼Œå› æ­¤å¯¹äºç›¸ä¼¼çš„è¾“å…¥å‘é‡ï¼Œæ¨¡å‹çš„è¾“å‡ºå¯èƒ½ä¼šæœ‰å¾ˆå¤§ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6â€…â€…â€…A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "3.6 è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾æ•£ç‚¹å›¾çš„æ•£ç‚¹å›¾çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Including this dummy feature makes the d and w vectors have the same length, and this allows us to write the equation as the dot product of the two vectors (i.e., w Â·d).",
            "zh": "åŒ…æ‹¬è¿™ä¸ªè™šæ‹Ÿç‰¹å¾ä½¿ d å’Œ w å‘é‡å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†æ–¹ç¨‹å†™æˆä¸¤ä¸ªå‘é‡ï¼ˆå³ w Â·dï¼‰çš„ç‚¹ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason that only the states immediately surrounding those that led to large positive or negative rewards reflect these rewards is that Q-learning, and temporal-difference learning in general, uses bootstrapping and updates Q values immediately after actions rather than waiting until the end of an episode.",
            "zh": "åªæœ‰é‚£äº›å¯¼è‡´å¤§é‡ç§¯ææˆ–æ¶ˆæå¥–åŠ±çš„çŠ¶æ€æ‰èƒ½åæ˜ è¿™äº›å¥–åŠ±çš„åŸå› æ˜¯ï¼ŒQå­¦ä¹ å’Œä¸€èˆ¬çš„æ—¶é—´å·®åˆ†å­¦ä¹ ä½¿ç”¨å¼•å¯¼å¹¶åœ¨è¡ŒåŠ¨åç«‹å³æ›´æ–°Qå€¼ï¼Œè€Œä¸æ˜¯ç­‰åˆ°ä¸€é›†ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "depth of a neural network, 389",
            "zh": "ç¥ç»ç½‘ç»œçš„æ·±åº¦ï¼Œ389"
        }
    },
    {
        "translation": {
            "en": "where d[j] is some descriptive feature and d[j] is the mean value of that descriptive feature in the training set.",
            "zh": "å…¶ä¸­ d[j] æ˜¯ä¸€äº›æè¿°æ€§ç‰¹å¾ï¼Œd[j] æ˜¯è¯¥æè¿°æ€§ç‰¹å¾åœ¨è®­ç»ƒé›†ä¸­çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.4â€…â€…â€…Early Stopping and Dropout: Preventing Overfitting",
            "zh": "8.4.4 æå‰åœæ­¢å’Œé€€å‡ºï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ"
        }
    },
    {
        "translation": {
            "en": "This means that neurons with saturated activation functions can get stuck: their weights never change substantially during training because the incremental updates are either 0 or are tiny.",
            "zh": "è¿™æ„å‘³ç€å…·æœ‰é¥±å’Œæ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒå¯èƒ½ä¼šè¢«å¡ä½ï¼šå®ƒä»¬çš„æƒé‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ°¸è¿œä¸ä¼šå‘ç”Ÿå®è´¨æ€§å˜åŒ–ï¼Œå› ä¸ºå¢é‡æ›´æ–°è¦ä¹ˆä¸º 0ï¼Œè¦ä¹ˆå¾ˆå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although for some simple problems, like those presented in our office rentals dataset, it is possible to try out every reasonable combination of weights and through this brute-force search find the best combination, for most real-world problems this is not feasibleâ€”the computation required would take far too long.",
            "zh": "è™½ç„¶å¯¹äºä¸€äº›ç®€å•çš„é—®é¢˜ï¼Œæ¯”å¦‚æˆ‘ä»¬çš„åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†ä¸­å‡ºç°çš„é—®é¢˜ï¼Œå¯ä»¥å°è¯•æ¯ä¸€ä¸ªåˆç†çš„æƒé‡ç»„åˆï¼Œå¹¶é€šè¿‡è¿™ç§è›®åŠ›æœç´¢æ‰¾åˆ°æœ€ä½³ç»„åˆï¼Œä½†å¯¹äºå¤§å¤šæ•°ç°å®ä¸–ç•Œçš„é—®é¢˜æ¥è¯´ï¼Œè¿™æ˜¯ä¸å¯è¡Œçš„â€”â€”æ‰€éœ€çš„è®¡ç®—å°†èŠ±è´¹å¤ªé•¿æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.6â€…â€…â€…An illustration of how a batch of examples can be processed in parallel using matrix operations.",
            "zh": "8.6 è¯´æ˜å¦‚ä½•ä½¿ç”¨çŸ©é˜µè¿ç®—å¹¶è¡Œå¤„ç†ä¸€æ‰¹ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "expected reward, 651",
            "zh": "é¢„æœŸå¥–åŠ±ï¼Œ651"
        }
    },
    {
        "translation": {
            "en": "9.17â€…â€…â€…The structure of a confusion matrix for a multinomial prediction problem with l target levels.",
            "zh": "9.17 å…·æœ‰ l ä¸ªç›®æ ‡æ°´å¹³çš„å¤šé¡¹å¼é¢„æµ‹é—®é¢˜çš„æ··æ·†çŸ©é˜µç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 6.4(a)[273] follows a light tail distributionâ€”the bars at the extreme left and right of the distribution have zero height.",
            "zh": "å›¾6.4ï¼ˆaï¼‰[273]ä¸­çš„æ•°æ®é›†éµå¾ªå…‰å°¾åˆ†å¸ƒï¼Œå³åˆ†å¸ƒæœ€å·¦è¾¹å’Œæœ€å³è¾¹çš„æ¡å½¢é«˜åº¦ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.17â€…â€…â€…A selection of the models developed during the gradient descent process for the grass growth dataset from Table 7.9[351].",
            "zh": "7.17 è¡¨7.9[351]ä¸­è‰ç”Ÿé•¿æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "In both cases, the target feature level was set to the galaxy category that received the majority of the votes.",
            "zh": "åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œç›®æ ‡ç‰¹å¾çº§åˆ«éƒ½è¢«è®¾ç½®ä¸ºè·å¾—å¤§å¤šæ•°é€‰ç¥¨çš„æ˜Ÿç³»ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature, RECIDIVIST, has a true value if the prisoner was arrested within two years of being released; otherwise it has a value of false.",
            "zh": "å¦‚æœå›šçŠ¯åœ¨è·é‡Šåä¸¤å¹´å†…è¢«æ•ï¼Œåˆ™ç›®æ ‡ç‰¹å¾â€œç´¯çŠ¯â€å…·æœ‰çœŸæ­£çš„ä»·å€¼;å¦åˆ™ï¼Œå®ƒçš„å€¼ä¸º falseã€‚"
        }
    },
    {
        "translation": {
            "en": "parent node, 286",
            "zh": "çˆ¶èŠ‚ç‚¹ï¼Œ286"
        }
    },
    {
        "translation": {
            "en": "One way of judging similarity is to focus solely on co-presence. For example, in an online retail setting, co-presence could capture what two users jointly viewed, liked, or bought. The Russel-Rao similarity index focuses on this and is measured in terms of the ratio between the number of co-presences and the total number of binary features considered:",
            "zh": "åˆ¤æ–­ç›¸ä¼¼æ€§çš„ä¸€ç§æ–¹æ³•æ˜¯åªå…³æ³¨å…±åŒå­˜åœ¨ã€‚ä¾‹å¦‚ï¼Œåœ¨åœ¨çº¿é›¶å”®ç¯å¢ƒä¸­ï¼Œå…±åŒå­˜åœ¨å¯ä»¥æ•è·ä¸¤ä¸ªç”¨æˆ·å…±åŒæŸ¥çœ‹ã€å–œæ¬¢æˆ–è´­ä¹°çš„å†…å®¹ã€‚Russel-Raoç›¸ä¼¼æ€§æŒ‡æ•°å…³æ³¨è¿™ä¸€ç‚¹ï¼Œå¹¶æ ¹æ®å…±å­˜æ•°é‡ä¸æ‰€è€ƒè™‘çš„äºŒå…ƒç‰¹å¾æ€»æ•°ä¹‹é—´çš„æ¯”ç‡æ¥è¡¡é‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "The algorithm assumes a dataset is available; it also requires that values for the learning rate Î± and the batch size B hyper-parameters have been selected.",
            "zh": "è¯¥ç®—æ³•å‡å®šæ•°æ®é›†å¯ç”¨;å®ƒè¿˜è¦æ±‚å·²é€‰æ‹©å­¦ä¹ ç‡Î±å’Œæ‰¹é‡å¤§å° B è¶…å‚æ•°çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case you can only assume that the queen is equally likely to be in any of the three possible positions: left, center, or right.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åªèƒ½å‡è®¾å¥³ç‹åŒæ ·å¯èƒ½å¤„äºä¸‰ä¸ªå¯èƒ½ä½ç½®ä¸­çš„ä»»ä½•ä¸€ä¸ªï¼šå·¦ã€ä¸­æˆ–å³ã€‚"
        }
    },
    {
        "translation": {
            "en": "To train a support vector machine, we need to find values for each of the components in Equation (7.41)[363] (the support vectors, w 0, and the Î± parameters) that define the optimal decision boundary between the target levels.",
            "zh": "ä¸ºäº†è®­ç»ƒæ”¯æŒå‘é‡æœºï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ–¹ç¨‹ï¼ˆ7.41ï¼‰[363]ä¸­æ¯ä¸ªåˆ†é‡çš„å€¼ï¼ˆæ”¯æŒå‘é‡ã€w 0 å’Œ Î± å‚æ•°ï¼‰ï¼Œè¿™äº›åˆ†é‡å®šä¹‰äº†ç›®æ ‡æ°´å¹³ä¹‹é—´çš„æœ€ä½³å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "We explore the most important of these modifications in the following sections.",
            "zh": "æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹å„èŠ‚ä¸­æ¢è®¨è¿™äº›ä¿®æ”¹ä¸­æœ€é‡è¦çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, the Î´ term for a neuron is the partial derivative of the error of the network with respect to the weighted sum (z) of the neuron. The Î´s for all neurons in a network (irrespective of whether they are in the output layer or a hidden layer) are calculated as the product of two terms:",
            "zh": "æ¢å¥è¯è¯´ï¼Œç¥ç»å…ƒÎ´é¡¹æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒåŠ æƒå’Œ ï¼ˆzï¼‰ çš„åå¯¼æ•°ã€‚ç½‘ç»œä¸­æ‰€æœ‰ç¥ç»å…ƒï¼ˆæ— è®ºå®ƒä»¬ä½äºè¾“å‡ºå±‚è¿˜æ˜¯éšè—å±‚ï¼‰çš„ Î´ è®¡ç®—ä¸ºä¸¤é¡¹çš„ä¹˜ç§¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "Algorithm 8[507] provides a pseudocode definition of the backpropagation through time algorithm for a single sequence of input-output pairs of length n.",
            "zh": "ç®—æ³•8[507]ä¸ºé•¿åº¦ä¸ºnçš„å•ä¸ªè¾“å…¥è¾“å‡ºå¯¹åºåˆ—æä¾›äº†åå‘ä¼ æ’­æ—¶é—´ç®—æ³•çš„ä¼ªä»£ç å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "When a relationship exists between the two features, the box plots should show differing central tendencies and variations.",
            "zh": "å½“ä¸¤ä¸ªç‰¹å¾ä¹‹é—´å­˜åœ¨å…³ç³»æ—¶ï¼Œç®±å½¢å›¾åº”æ˜¾ç¤ºä¸åŒçš„ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "More generally, we can mathematically define the weighted sum calculation",
            "zh": "æ›´ä¸€èˆ¬åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ•°å­¦æ–¹å¼å®šä¹‰åŠ æƒå’Œè®¡ç®—"
        }
    },
    {
        "translation": {
            "en": "Another commonly used approach to setting the upper and lower thresholds is to use the mean value of a feature plus or minus 2 times the standard deviation.6 Again this works well, but it does assume that the underlying data follows a normal distribution.",
            "zh": "è®¾ç½®ä¸Šé™å’Œä¸‹é™é˜ˆå€¼çš„å¦ä¸€ç§å¸¸ç”¨æ–¹æ³•æ˜¯ä½¿ç”¨ç‰¹å¾çš„å¹³å‡å€¼æ­£è´Ÿæ ‡å‡†å·®çš„ 2 å€ã€‚6 åŒæ ·ï¼Œè¿™å¾ˆæœ‰æ•ˆï¼Œä½†å®ƒç¡®å®å‡è®¾åŸºç¡€æ•°æ®éµå¾ªæ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why these networks are useful for processing sequential data that exhibit long-distance dependencies.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™äº›ç½‘ç»œå¯¹äºå¤„ç†è¡¨ç°å‡ºé•¿è·ç¦»ä¾èµ–å…³ç³»çš„é¡ºåºæ•°æ®å¾ˆæœ‰ç”¨çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of expected return for actions at+1 and beyond refers to the policy, Ï€, that is used to select the action that will be taken in each state (as did all other calculations of expected return). We can define the policy as a function that returns a probability distribution over the set of possible actions that can be taken from a state, as described in Equation (11.5)[641]. Using this definition we can rewrite Equation (11.19)[652]",
            "zh": "+1 åŠä»¥ä¸Šæ“ä½œçš„é¢„æœŸå›æŠ¥è®¡ç®—æ˜¯æŒ‡ç”¨äºé€‰æ‹©åœ¨æ¯ä¸ªçŠ¶æ€ä¸‹å°†é‡‡å–çš„è¡ŒåŠ¨çš„ç­–ç•¥ Ï€ï¼ˆä¸é¢„æœŸå›æŠ¥çš„æ‰€æœ‰å…¶ä»–è®¡ç®—ä¸€æ ·ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥å°†ç­–ç•¥å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°è¿”å›å¯ä»¥ä»çŠ¶æ€ä¸­é‡‡å–çš„ä¸€ç»„å¯èƒ½æ“ä½œçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¦‚å…¬å¼ ï¼ˆ11.5ï¼‰[641] ä¸­æ‰€è¿°ã€‚ä½¿ç”¨è¿™ä¸ªå®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥é‡å†™ç­‰å¼ï¼ˆ11.19ï¼‰[652]"
        }
    },
    {
        "translation": {
            "en": "weight sharing, 483",
            "zh": "é‡é‡åˆ†æ‘Šï¼Œ 483"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: The challenge in this case would be to integrate the automated application assessment process into whatever application approval process currently exists within the company.",
            "zh": "å®¹é‡è¦æ±‚ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŒ‘æˆ˜åœ¨äºå°†è‡ªåŠ¨åŒ–åº”ç”¨ç¨‹åºè¯„ä¼°æµç¨‹é›†æˆåˆ°å…¬å¸å†…éƒ¨å½“å‰å­˜åœ¨çš„ä»»ä½•åº”ç”¨ç¨‹åºå®¡æ‰¹æµç¨‹ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A good measure of distance between two instances with categorical features is the overlap metric (also known as the hamming distance), which simply counts the number of descriptive features that have different values. Using this measure of distance, compute the distances between the mystery animal and each of the animals in the animal dataset.",
            "zh": "ï¼ˆaï¼‰ é‡å åº¦é‡ï¼ˆä¹Ÿç§°ä¸ºæ±‰æ˜è·ç¦»ï¼‰æ˜¯è¡¡é‡ä¸¤ä¸ªå…·æœ‰åˆ†ç±»ç‰¹å¾çš„å®ä¾‹ä¹‹é—´è·ç¦»çš„ä¸€ä¸ªå¾ˆå¥½çš„åº¦é‡æ ‡å‡†ï¼Œå®ƒç®€å•åœ°è®¡ç®—å…·æœ‰ä¸åŒå€¼çš„æè¿°æ€§ç‰¹å¾çš„æ•°é‡ã€‚ä½¿ç”¨æ­¤è·ç¦»åº¦é‡ï¼Œè®¡ç®—ç¥ç§˜åŠ¨ç‰©ä¸åŠ¨ç‰©æ•°æ®é›†ä¸­æ¯åªåŠ¨ç‰©ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "invalid outliers, 65, 68, 715",
            "zh": "æ— æ•ˆå¼‚å¸¸å€¼ã€65ã€68ã€715"
        }
    },
    {
        "translation": {
            "en": "(2009) and Smyth and Keane (1995).",
            "zh": "ï¼ˆ2009ï¼‰å’Œå²å¯†æ–¯å’ŒåŸºæ©ï¼ˆ1995ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The occurrence of tachycardia can have serious implications including increased risk of stroke or sudden cardiac arrest.",
            "zh": "å¿ƒåŠ¨è¿‡é€Ÿçš„å‘ç”Ÿå¯èƒ½ä¼šäº§ç”Ÿä¸¥é‡çš„å½±å“ï¼ŒåŒ…æ‹¬å¢åŠ ä¸­é£æˆ–å¿ƒè„éª¤åœçš„é£é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "29. Monte Carlo methods are named after the Mediterranean principality that is famous for its casino.",
            "zh": "29. è’™ç‰¹å¡æ´›æ–¹æ³•ä»¥ä»¥å…¶èµŒåœºè€Œé—»åçš„åœ°ä¸­æµ·å…¬å›½å‘½åã€‚"
        }
    },
    {
        "translation": {
            "en": "We begin by illustrating the key differences between supervised and unsupervised machine learning before describing clustering, one of the main applications of unsupervised learning; and the standard approach for clustering, the k-means clustering algorithm.",
            "zh": "æˆ‘ä»¬é¦–å…ˆè¯´æ˜ç›‘ç£æœºå™¨å­¦ä¹ å’Œæ— ç›‘ç£æœºå™¨å­¦ä¹ ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ï¼Œç„¶åæè¿°èšç±»ï¼Œè¿™æ˜¯æ— ç›‘ç£å­¦ä¹ çš„ä¸»è¦åº”ç”¨ä¹‹ä¸€;ä»¥åŠèšç±»çš„æ ‡å‡†æ–¹æ³•ï¼Œå³ k-means èšç±»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of using a logistic regression model is that along with classifications, it also produces probabilities.",
            "zh": "ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯ï¼Œé™¤äº†åˆ†ç±»ä¹‹å¤–ï¼Œå®ƒè¿˜ä¼šäº§ç”Ÿæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.2â€…â€…The members of the school basketball team from Figure A.1[746] with one very tall ringer added: (a) the dashed gray line shows the mean of the playersâ€™ heights; and (b) the dashed gray line shows the median of the playersâ€™ heights, with the players ordered by height.",
            "zh": "A.2 å›¾A.1[746]ä¸­å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ï¼ŒåŠ ä¸Šä¸€ä¸ªéå¸¸é«˜çš„é“ƒå£°ï¼šï¼ˆaï¼‰ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„å¹³å‡å€¼;ï¼ˆbï¼‰ç°è‰²è™šçº¿æ˜¾ç¤ºçƒå‘˜èº«é«˜çš„ä¸­ä½æ•°ï¼Œçƒå‘˜æŒ‰èº«é«˜æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "In all cases the extreme values were determined to be valid outliers.",
            "zh": "åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæå€¼éƒ½è¢«ç¡®å®šä¸ºæœ‰æ•ˆçš„å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.13â€…â€…â€…The vegetation classification decision tree after the dataset has been split using ELEVATION > 4,175.",
            "zh": "4.13 ä½¿ç”¨ELEVATION > 4,175åˆ†å‰²æ•°æ®é›†åçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Which of these two models do you think will generalize better to instances not contained in the dataset?",
            "zh": "ï¼ˆaï¼‰ æ‚¨è®¤ä¸ºè¿™ä¸¤ç§æ¨¡å‹ä¸­çš„å“ªä¸€ç§å¯ä»¥æ›´å¥½åœ°æ¨å¹¿åˆ°æ•°æ®é›†ä¸­æœªåŒ…å«çš„å®ä¾‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Because the descriptive feature ACCOUNT BALANCE is continuous, there is an infinite number of values in the featureâ€™s domain.",
            "zh": "ç”±äºæè¿°æ€§è¦ç´  ACCOUNT BALANCE æ˜¯è¿ç»­çš„ï¼Œå› æ­¤è¦ç´ åŸŸä¸­å­˜åœ¨æ— é™æ•°é‡çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "BLANDCHROMATIN",
            "zh": "å¸ƒå…°å¾·æŸ“è‰²è´¨"
        }
    },
    {
        "translation": {
            "en": "(c) What value will the Bayesian network predict for ALARM, given that there is both a burglar and a cat in the house but there is no storm?",
            "zh": "ï¼ˆcï¼‰ è´å¶æ–¯ç½‘ç»œå¯¹ ALARM çš„é¢„æµ‹å€¼æ˜¯å¤šå°‘ï¼Œå› ä¸ºæˆ¿å­é‡Œæ—¢æœ‰çªƒè´¼åˆæœ‰çŒ«ï¼Œä½†æ²¡æœ‰æš´é£é›¨ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "There is a range of simple pre-pruning strategies.",
            "zh": "æœ‰ä¸€ç³»åˆ—ç®€å•çš„é¢„ä¿®å‰ªç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "A model is generative if it can be used to generate data that will have the same characteristics as the dataset from which the model was produced.",
            "zh": "å¦‚æœæ¨¡å‹å¯ç”¨äºç”Ÿæˆä¸ç”Ÿæˆæ¨¡å‹çš„æ•°æ®é›†å…·æœ‰ç›¸åŒç‰¹å¾çš„æ•°æ®ï¼Œåˆ™è¯¥æ¨¡å‹æ˜¯ç”Ÿæˆæ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gibbs sampling is one of the best-known MCMC algorithms and is particularly suitable when we wish to generate probabilities that are conditioned on some evidence, so this is the algorithm we discuss in this section.",
            "zh": "å‰å¸ƒæ–¯é‡‡æ ·æ˜¯æœ€è‘—åçš„ MCMC ç®—æ³•ä¹‹ä¸€ï¼Œç‰¹åˆ«é€‚ç”¨äºæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆä»¥æŸäº›è¯æ®ä¸ºæ¡ä»¶çš„æ¦‚ç‡ï¼Œå› æ­¤è¿™å°±æ˜¯æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­è®¨è®ºçš„ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in this section, we focus on showing how a sequence of linear layers can be replaced by a single linear function (as distinct from an affine transformation).",
            "zh": "ç„¶è€Œï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹å±•ç¤ºå¦‚ä½•ç”¨å•ä¸ªçº¿æ€§å‡½æ•°ï¼ˆä¸ä»¿å°„å˜æ¢ä¸åŒï¼‰æ›¿æ¢çº¿æ€§å±‚åºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this is the case, these missing values are due to invalid data, so the data integration errors can be corrected, and the ABT can be regenerated to populate the missing values.",
            "zh": "å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œè¿™äº›ç¼ºå¤±å€¼æ˜¯ç”±äºæ— æ•ˆæ•°æ®é€ æˆçš„ï¼Œå› æ­¤å¯ä»¥æ›´æ­£æ•°æ®é›†æˆé”™è¯¯ï¼Œå¹¶ä¸”å¯ä»¥é‡æ–°ç”Ÿæˆ ABT ä»¥å¡«å……ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Descriptive Statistics and Data Visualization for Machine Learning",
            "zh": "æœºå™¨å­¦ä¹ çš„æè¿°æ€§ç»Ÿè®¡å’Œæ•°æ®å¯è§†åŒ–"
        }
    },
    {
        "translation": {
            "en": "Figure 4.9[139] depicts the state of the decision tree after the 7 partition has been split.",
            "zh": "å›¾ 4.9[139] æè¿°äº† 7 åˆ†åŒºæ‹†åˆ†åçš„å†³ç­–æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "situational fluency, 24, 48, 686, 706",
            "zh": "æƒ…å¢ƒæµç•…åº¦ï¼Œ24,48,686,706"
        }
    },
    {
        "translation": {
            "en": "In a second experiment, the refractive effect of passing N rays through a prism (something that does not happen to X-rays) is demonstrated.",
            "zh": "åœ¨ç¬¬äºŒä¸ªå®éªŒä¸­ï¼Œæ¼”ç¤ºäº†é€šè¿‡æ£±é•œçš„ N å°„çº¿çš„æŠ˜å°„æ•ˆåº”ï¼ˆX å°„çº¿ä¸ä¼šå‘ç”Ÿï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "When this occurs, the model needs to be changed in some way to adapt to the new scenario.",
            "zh": "å‘ç”Ÿè¿™ç§æƒ…å†µæ—¶ï¼Œéœ€è¦ä»¥æŸç§æ–¹å¼æ›´æ”¹æ¨¡å‹ä»¥é€‚åº”æ–°åœºæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The image-based measures of overall galaxy shape are extracted from the images using morphological and moment image processing operations.",
            "zh": "ä½¿ç”¨å½¢æ€å­¦å’ŒçŸ©å›¾åƒå¤„ç†æ“ä½œä»å›¾åƒä¸­æå–åŸºäºå›¾åƒçš„æ•´ä½“æ˜Ÿç³»å½¢çŠ¶æµ‹é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first two extensions and variations sections explain why the backpropagation algorithm can struggle with unstable gradients when training a deep network and how a number of important hyper-parameter decisions, such as the choice of the network weight initialization process, and activation functions, can help with the challenge of unstable gradients.",
            "zh": "å‰ä¸¤ä¸ªæ‰©å±•å’Œå˜ä½“éƒ¨åˆ†è§£é‡Šäº†ä¸ºä»€ä¹ˆåå‘ä¼ æ’­ç®—æ³•åœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œæ—¶ä¼šé‡åˆ°ä¸ç¨³å®šçš„æ¢¯åº¦é—®é¢˜ï¼Œä»¥åŠä¸€äº›é‡è¦çš„è¶…å‚æ•°å†³ç­–ï¼ˆä¾‹å¦‚ç½‘ç»œæƒé‡åˆå§‹åŒ–è¿‡ç¨‹çš„é€‰æ‹©å’Œæ¿€æ´»å‡½æ•°ï¼‰å¦‚ä½•å¸®åŠ©åº”å¯¹ä¸ç¨³å®šæ¢¯åº¦çš„æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gradient descent works in exactly the same way.",
            "zh": "æ¢¯åº¦ä¸‹é™çš„å·¥ä½œæ–¹å¼å®Œå…¨ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "instance, 5, 28",
            "zh": "å®ä¾‹ï¼Œ 5ï¼Œ 28"
        }
    },
    {
        "translation": {
            "en": "A simple dataset for a MENINGITIS diagnosis with descriptive features that describe the presence or absence of three common symptoms of the disease: HEADACHE, FEVER, and VOMITING.",
            "zh": "ç”¨äºè„‘è†œç‚è¯Šæ–­çš„ç®€å•æ•°æ®é›†ï¼Œå…·æœ‰æè¿°æ€§ç‰¹å¾ï¼Œæè¿°æ˜¯å¦å­˜åœ¨è¯¥ç–¾ç—…çš„ä¸‰ç§å¸¸è§ç—‡çŠ¶ï¼šå¤´ç—›ã€å‘çƒ§å’Œå‘•åã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.86)[481] lists the calculation of the activation for this neuron for this set of inputs.",
            "zh": "ç­‰å¼ï¼ˆ8.86ï¼‰[481]åˆ—å‡ºäº†è¿™ç»„è¾“å…¥ä¸­è¯¥ç¥ç»å…ƒæ¿€æ´»çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is often useful to talk about the probabilities for all the possible assignments to a feature.",
            "zh": "è®¨è®ºå¯¹ä¸€ä¸ªç‰¹å¾çš„æ‰€æœ‰å¯èƒ½èµ‹å€¼çš„æ¦‚ç‡é€šå¸¸å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This structure is typically captured in new generated features that can be appended to the original dataset and so augment or enrich it.",
            "zh": "æ­¤ç»“æ„é€šå¸¸æ•è·åœ¨æ–°ç”Ÿæˆçš„ç‰¹å¾ä¸­ï¼Œè¿™äº›ç‰¹å¾å¯ä»¥é™„åŠ åˆ°åŸå§‹æ•°æ®é›†ä¸­ï¼Œä»è€Œå¢å¼ºæˆ–ä¸°å¯Œå®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "feature space, 181, 183, 184, 231, 599",
            "zh": "åŠŸèƒ½ç©ºé—´ï¼Œ 181ï¼Œ 183ï¼Œ 184ï¼Œ 231ï¼Œ 599"
        }
    },
    {
        "translation": {
            "en": "Deep learning has grown out of research on neural networks.",
            "zh": "æ·±åº¦å­¦ä¹ æ˜¯ä»å¯¹ç¥ç»ç½‘ç»œçš„ç ”ç©¶å‘å±•è€Œæ¥çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "When these cases occur, the algorithm will create a leaf node that returns the mean value of the target feature in a data partition, rather than the majority level.",
            "zh": "å½“è¿™äº›æƒ…å†µå‘ç”Ÿæ—¶ï¼Œè¯¥ç®—æ³•å°†åˆ›å»ºä¸€ä¸ªå¶èŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹è¿”å›æ•°æ®åˆ†åŒºä¸­ç›®æ ‡ç‰¹å¾çš„å¹³å‡å€¼ï¼Œè€Œä¸æ˜¯å¤šæ•°çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a more in-depth treatment of regression models and their underpinnings in statistics, Chapter 14 of Rice (2006) offers a nice treatment of the topic, and Kutner et al. (2004) provides massive detail. Ayres (2008) gives a lighter discussion of the many different ways in which regression models are applied in practice.",
            "zh": "ä¸ºäº†æ›´æ·±å…¥åœ°ç ”ç©¶å›å½’æ¨¡å‹åŠå…¶åœ¨ç»Ÿè®¡å­¦ä¸­çš„åŸºç¡€ï¼ŒRice ï¼ˆ2006ï¼‰ çš„ç¬¬ 14 ç« æä¾›äº†å¯¹è¯¥ä¸»é¢˜çš„è‰¯å¥½å¤„ç†ï¼ŒKutner et al. ï¼ˆ2004ï¼‰ æä¾›äº†å¤§é‡ç»†èŠ‚ã€‚Ayresï¼ˆ2008ï¼‰å¯¹å›å½’æ¨¡å‹åœ¨å®è·µä¸­åº”ç”¨çš„è®¸å¤šä¸åŒæ–¹å¼è¿›è¡Œäº†è¾ƒè½»æ¾çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapter 11, in the second half of the new Beyond Prediction part of the book, describes reinforcement learning from the fundamental ideas that underpin it to the use of deep neural networks in modern reinforcement learning systems.",
            "zh": "ç¬¬11ç« æ˜¯æœ¬ä¹¦æ–°çš„â€œè¶…è¶Šé¢„æµ‹â€éƒ¨åˆ†çš„ååŠéƒ¨åˆ†ï¼Œæè¿°äº†å¼ºåŒ–å­¦ä¹ ï¼Œä»æ”¯æ’‘å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ€æƒ³åˆ°æ·±åº¦ç¥ç»ç½‘ç»œåœ¨ç°ä»£å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿä¸­çš„ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "These locations can be thought of as sensing neurons that permit the network to sense the external inputs.",
            "zh": "è¿™äº›ä½ç½®å¯ä»¥è¢«è®¤ä¸ºæ˜¯å…è®¸ç½‘ç»œæ„ŸçŸ¥å¤–éƒ¨è¾“å…¥çš„æ„ŸçŸ¥ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This value was calculated by multiplying the prediction error for d1 (226.74) by the SIZE value for this instance (500).",
            "zh": "è¯¥å€¼çš„è®¡ç®—æ–¹æ³•æ˜¯å°† d1 çš„é¢„æµ‹è¯¯å·® ï¼ˆ226.74ï¼‰ ä¹˜ä»¥æ­¤å®ä¾‹çš„ SIZE å€¼ ï¼ˆ500ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.2â€ƒFundamentals",
            "zh": "5.2 åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "One advantage of AHC is that the number of clusters to be found, k, is not a required input for the algorithm.",
            "zh": "AHC çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯è¦æ‰¾åˆ°çš„èšç±»æ•° k ä¸æ˜¯ç®—æ³•çš„å¿…éœ€è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Out of the different approaches we have considered, the information-based and probability-based approaches are least well suited in this case.",
            "zh": "åœ¨æˆ‘ä»¬è€ƒè™‘è¿‡çš„ä¸åŒæ–¹æ³•ä¸­ï¼ŒåŸºäºä¿¡æ¯å’ŒåŸºäºæ¦‚ç‡çš„æ–¹æ³•æœ€ä¸é€‚åˆè¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "17.667",
            "zh": "17.667"
        }
    },
    {
        "translation": {
            "en": "Figure 3.6[75] shows an example scatter plot matrix for the continuous features from the professional basketball team dataset in Table 3.7[73]: HEIGHT, WEIGHT, AGE, and SPONSORSHIP EARNINGS.",
            "zh": "å›¾3.6[75]æ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾çš„æ•£ç‚¹å›¾çŸ©é˜µç¤ºä¾‹ï¼šèº«é«˜ã€ä½“é‡ã€å¹´é¾„å’ŒèµåŠ©æ”¶å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Custom metrics aside, the standard distance metrics and similarity indexes weight all features equally.",
            "zh": "æ’‡å¼€è‡ªå®šä¹‰æŒ‡æ ‡ä¸è°ˆï¼Œæ ‡å‡†è·ç¦»æŒ‡æ ‡å’Œç›¸ä¼¼æ€§æŒ‡æ•°å¯¹æ‰€æœ‰è¦ç´ çš„æƒé‡ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics is the art of building and using models that make predictions based on patterns extracted from historical data. Applications of predictive data analytics include",
            "zh": "é¢„æµ‹æ•°æ®åˆ†ææ˜¯æ„å»ºå’Œä½¿ç”¨æ¨¡å‹çš„è‰ºæœ¯ï¼Œè¿™äº›æ¨¡å‹æ ¹æ®ä»å†å²æ•°æ®ä¸­æå–çš„æ¨¡å¼è¿›è¡Œé¢„æµ‹ã€‚é¢„æµ‹æ•°æ®åˆ†æçš„åº”ç”¨åŒ…æ‹¬"
        }
    },
    {
        "translation": {
            "en": "The weighted variance is computed by summing the variance of the target feature within each partition created by splitting a dataset on a descriptive feature multiplied by the fraction of the dataset in each partition.",
            "zh": "åŠ æƒæ–¹å·®çš„è®¡ç®—æ–¹æ³•æ˜¯å°†æ¯ä¸ªåˆ†åŒºä¸­ç›®æ ‡è¦ç´ çš„æ–¹å·®ç›¸åŠ ï¼Œæ–¹æ³•æ˜¯å°†æè¿°æ€§è¦ç´ ä¸Šçš„æ•°æ®é›†æ‹†åˆ†ä¹˜ä»¥æ¯ä¸ªåˆ†åŒºä¸­æ•°æ®é›†çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we need to calculate 2 + (2 Ã— 4) + (2 Ã— 3) + (2 Ã— 3) = 22 probabilities.",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦è®¡ç®— 2 + ï¼ˆ2 Ã— 4ï¼‰ + ï¼ˆ2 Ã— 3ï¼‰ + ï¼ˆ2 Ã— 3ï¼‰ = 22 ä¸ªæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Prediction score distributions for two different prediction models. The distributions in (a) are much better separated than those in (b).",
            "zh": "ä¸¤ç§ä¸åŒé¢„æµ‹æ¨¡å‹çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒã€‚ï¼ˆaï¼‰ä¸­çš„åˆ†å¸ƒæ¯”ï¼ˆbï¼‰ä¸­çš„åˆ†å¸ƒåˆ†ç¦»å¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent has no map of the environment and begins with knowledge only of the actions that can be takenâ€”left, right, up, or downâ€”and its current state.",
            "zh": "æ™ºèƒ½ä½“æ²¡æœ‰ç¯å¢ƒåœ°å›¾ï¼Œä¸€å¼€å§‹åªçŸ¥é“å¯ä»¥é‡‡å–çš„è¡ŒåŠ¨ï¼ˆå·¦ã€å³ã€ä¸Šæˆ–ä¸‹ï¼‰åŠå…¶å½“å‰çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then rewrite Equation (8.28)[415] as Equation (8.30)[416] to use this new term",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬å°†ç­‰å¼ï¼ˆ8.28ï¼‰[415]æ”¹å†™ä¸ºç­‰å¼ï¼ˆ8.30ï¼‰[416]ä»¥ä½¿ç”¨è¿™ä¸ªæ–°æœ¯è¯­"
        }
    },
    {
        "translation": {
            "en": "The differences between SARSA and Q-learning can be illustrated by examining the behavior of a SARSA agent in the same grid world environment used in Section 11.3.1[659] (we assume the same sequence of random numbers are generated for easy comparison).",
            "zh": "SARSA å’Œ Q å­¦ä¹ ä¹‹é—´çš„å·®å¼‚å¯ä»¥é€šè¿‡æ£€æŸ¥ SARSA ä»£ç†åœ¨ç¬¬ 11.3.1 èŠ‚[659] ä¸­ä½¿ç”¨çš„ç›¸åŒç½‘æ ¼ä¸–ç•Œç¯å¢ƒä¸­çš„è¡Œä¸ºæ¥è¯´æ˜ï¼ˆæˆ‘ä»¬å‡è®¾ç”Ÿæˆç›¸åŒçš„éšæœºæ•°åºåˆ—ä»¥ä¾¿äºæ¯”è¾ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most naturally suited learning approaches in these scenarios are probably those that are best suited for the majority feature type.",
            "zh": "åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæœ€è‡ªç„¶çš„å­¦ä¹ æ–¹æ³•å¯èƒ½æ˜¯é‚£äº›æœ€é€‚åˆå¤§å¤šæ•°ç‰¹å¾ç±»å‹çš„å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.4â€ƒCase Study: Motor Insurance Fraud",
            "zh": "3.3.4 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Larger values of k mean that more smoothing occursâ€”that is, more probability mass is taken from the larger probabilities and given to the small probabilities.",
            "zh": "k å€¼è¶Šå¤§ï¼Œæ„å‘³ç€å¹³æ»‘å‘ç”Ÿè¶Šå¤šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä»è¾ƒå¤§çš„æ¦‚ç‡ä¸­è·å–æ›´å¤šçš„æ¦‚ç‡è´¨é‡ï¼Œå¹¶èµ‹äºˆè¾ƒå°çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure the arrows carry activations in the direction the arrow is pointing, the weight label on each arrow represents the weight that will be applied to the descriptive feature carried along the arrow, the âˆ‘ symbol represents the weighted sum of the inputs, and the Ï† symbol represents the threshold function being applied to the result of the weighted sum to convert it into an activation.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œç®­å¤´æ²¿ç®­å¤´æŒ‡å‘çš„æ–¹å‘è¿›è¡Œæ¿€æ´»ï¼Œæ¯ä¸ªç®­å¤´ä¸Šçš„æƒé‡æ ‡ç­¾è¡¨ç¤ºå°†åº”ç”¨äºæ²¿ç®­å¤´æºå¸¦çš„æè¿°æ€§ç‰¹å¾çš„æƒé‡ï¼Œâˆ‘ç¬¦å·è¡¨ç¤ºè¾“å…¥çš„åŠ æƒæ€»å’Œï¼ŒÏ†ç¬¦å·è¡¨ç¤ºåº”ç”¨äºåŠ æƒæ€»å’Œç»“æœä»¥å°†å…¶è½¬æ¢ä¸ºæ¿€æ´»çš„é˜ˆå€¼å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "So the rest of the search process will involve a descent down to the node, indexing d18 and a direct ascent to the root node where the search process will then terminate and return d21 as the nearest neighbor (we will skip the details of these steps).",
            "zh": "å› æ­¤ï¼Œæœç´¢è¿‡ç¨‹çš„å…¶ä½™éƒ¨åˆ†å°†æ¶‰åŠä¸‹é™åˆ°èŠ‚ç‚¹ï¼Œç´¢å¼• d18 å¹¶ç›´æ¥ä¸Šå‡åˆ°æ ¹èŠ‚ç‚¹ï¼Œç„¶åæœç´¢è¿‡ç¨‹å°†ç»ˆæ­¢å¹¶è¿”å› d21 ä½œä¸ºæœ€è¿‘çš„é‚»å±…ï¼ˆæˆ‘ä»¬å°†è·³è¿‡è¿™äº›æ­¥éª¤çš„ç»†èŠ‚ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.1â€…â€…â€…Artificial Neurons",
            "zh": "8.2.1 äººå·¥ç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "SHOP VALUE",
            "zh": "åº—é¢ä»·å€¼"
        }
    },
    {
        "translation": {
            "en": "Two key innovations that helped with the unstable gradient problem were the adoption of the rectified linear activation function and the development of new techniques for weight initialization.",
            "zh": "æœ‰åŠ©äºè§£å†³ä¸ç¨³å®šæ¢¯åº¦é—®é¢˜çš„ä¸¤é¡¹å…³é”®åˆ›æ–°æ˜¯é‡‡ç”¨æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°å’Œå¼€å‘ç”¨äºæƒé‡åˆå§‹åŒ–çš„æ–°æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dashed line in Figure 9.3[542] shows the performance of the model being trained on a validation dataset.",
            "zh": "å›¾ 9.3[542] ä¸­çš„è™šçº¿æ˜¾ç¤ºäº†åœ¨éªŒè¯æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the initial design for the features in an ABT has been completed, we can begin to implement the technical processes that are needed to extract, create, and aggregate the features into an ABT.",
            "zh": "å®Œæˆ ABT ä¸­ç‰¹å¾çš„åˆå§‹è®¾è®¡åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹å®æ–½æå–ã€åˆ›å»ºå’Œèšåˆåˆ° ABT ä¸­æ‰€éœ€çš„æŠ€æœ¯æµç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. The axes in Figure 8.8[398] are slightly offset for ease of reading.",
            "zh": "4. å›¾8.8[398]ä¸­çš„è½´ç•¥æœ‰åç§»ï¼Œä»¥ä¾¿äºé˜…è¯»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this way the cluster centroids are moved to be representative of the members of that cluster.",
            "zh": "è¿™æ ·ï¼Œèšç±»è´¨å¿ƒè¢«ç§»åŠ¨ä»¥ä»£è¡¨è¯¥èšç±»çš„æˆå‘˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can rearrange Equation (5.13)[216] to calculate the cosine of the inner angle between two vectors as the normalized dot product",
            "zh": "æˆ‘ä»¬å¯ä»¥é‡æ–°æ’åˆ—æ–¹ç¨‹ï¼ˆ5.13ï¼‰[216]ï¼Œä»¥è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´å†…è§’çš„ä½™å¼¦ä½œä¸ºå½’ä¸€åŒ–ç‚¹ç§¯"
        }
    },
    {
        "translation": {
            "en": "A matrix of activations for a layer of neurons processing a batch of examples is denoted by A(k) where k identifies the layer.",
            "zh": "å¤„ç†ä¸€æ‰¹æ ·æœ¬çš„ç¥ç»å…ƒå±‚çš„æ¿€æ´»çŸ©é˜µç”¨ Aï¼ˆkï¼‰ è¡¨ç¤ºï¼Œå…¶ä¸­ k æ ‡è¯†è¯¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although we consider these memory locations as (sensing) neurons within the network, the inputs presented to the network are not transformed by these sensing neurons.",
            "zh": "å°½ç®¡æˆ‘ä»¬å°†è¿™äº›è®°å¿†ä½ç½®è§†ä¸ºç½‘ç»œä¸­çš„ï¼ˆæ„ŸçŸ¥ï¼‰ç¥ç»å…ƒï¼Œä½†å‘ˆç°ç»™ç½‘ç»œçš„è¾“å…¥ä¸ä¼šè¢«è¿™äº›æ„ŸçŸ¥ç¥ç»å…ƒè½¬æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of layers required for a network to be considered deep is an open question; however, Cybenko (1988) proved that a network with three layers of (processing) neurons (i.e., two hidden layers and an output layer) can approximate any function to arbitrary accuracy.",
            "zh": "å°†ç½‘ç»œè§†ä¸ºæ·±åº¦æ‰€éœ€çš„å±‚æ•°æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜;ç„¶è€Œï¼ŒCybenkoï¼ˆ1988ï¼‰è¯æ˜ï¼Œå…·æœ‰ä¸‰å±‚ï¼ˆå¤„ç†ï¼‰ç¥ç»å…ƒï¼ˆå³ä¸¤ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼‰çš„ç½‘ç»œå¯ä»¥ä»¥ä»»æ„ç²¾åº¦è¿‘ä¼¼ä»»ä½•å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important when choosing the periods for out-of-time sampling that the time spans are large enough to take into account any cyclical behavioral patterns or that other approaches are used to account for these.",
            "zh": "åœ¨é€‰æ‹©æ—¶é—´å¤–æŠ½æ ·çš„æ—¶é—´æ®µæ—¶ï¼Œé‡è¦çš„æ˜¯æ—¶é—´è·¨åº¦è¶³å¤Ÿå¤§ï¼Œå¯ä»¥è€ƒè™‘ä»»ä½•å‘¨æœŸæ€§è¡Œä¸ºæ¨¡å¼ï¼Œæˆ–è€…ä½¿ç”¨å…¶ä»–æ–¹æ³•æ¥è§£é‡Šè¿™äº›è¡Œä¸ºæ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12(a)[562] shows a complete ROC curve for the email predictions in Table 9.13[560].",
            "zh": "å›¾9.12ï¼ˆaï¼‰[562]æ˜¾ç¤ºäº†è¡¨9.13[560]ä¸­ç”µå­é‚®ä»¶é¢„æµ‹çš„å®Œæ•´ROCæ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The company estimates that it has an annotation budget that will cover the human annotation of 20,000 phrases (i.e., 40% of the set of candidate phrases).",
            "zh": "è¯¥å…¬å¸ä¼°è®¡ï¼Œå®ƒçš„æ³¨é‡Šé¢„ç®—å°†æ¶µç›– 20,000 ä¸ªçŸ­è¯­çš„äººå·¥æ³¨é‡Šï¼ˆå³å€™é€‰çŸ­è¯­é›†çš„ 40%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each row represents an iteration of the process, in which the black rectangles indicate the data used for testing while the white spaces indicate the data used for training.",
            "zh": "æ¯ä¸€è¡Œè¡¨ç¤ºè¿‡ç¨‹çš„è¿­ä»£ï¼Œå…¶ä¸­é»‘è‰²çŸ©å½¢è¡¨ç¤ºç”¨äºæµ‹è¯•çš„æ•°æ®ï¼Œè€Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºç”¨äºè®­ç»ƒçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1.1â€ƒHold-out samplingâ€ƒIn Section 9.3[535] we used a hold-out test set to evaluate the performance of a model.",
            "zh": "9.4.1.1 ä¿æŒæŠ½æ · åœ¨ç¬¬ 9.3[535] èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¿æŒæµ‹è¯•é›†æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, a domain concept, Fraud Outcome, is included to cover the target feature.",
            "zh": "æœ€åï¼ŒåŒ…æ‹¬ä¸€ä¸ªé¢†åŸŸæ¦‚å¿µï¼Œå³æ¬ºè¯ˆç»“æœï¼Œä»¥æ¶µç›–ç›®æ ‡åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "nodes: each feature in a domain is represented by a single node in the graph.",
            "zh": "èŠ‚ç‚¹ï¼šåŸŸä¸­çš„æ¯ä¸ªè¦ç´ éƒ½ç”±å›¾å½¢ä¸­çš„å•ä¸ªèŠ‚ç‚¹è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "All the neurons in this network use the following threshold activation function:",
            "zh": "è¯¥ç½‘ç»œä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½ä½¿ç”¨ä»¥ä¸‹é˜ˆå€¼æ¿€æ´»å‡½æ•°ï¼š"
        }
    },
    {
        "translation": {
            "en": "12.4â€…â€…â€…Modeling",
            "zh": "12.4 å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "This figure shows the weights on each connection and for each neuron shows the weighted sum z calculated by that neuron (the number on the left of the neuron) and the activation a for the neuron (the number on the right of the neuron).",
            "zh": "è¯¥å›¾æ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ï¼Œå¹¶ä¸”å¯¹äºæ¯ä¸ªç¥ç»å…ƒæ˜¾ç¤ºäº†ç”±è¯¥ç¥ç»å…ƒï¼ˆç¥ç»å…ƒå·¦ä¾§çš„æ•°å­—ï¼‰è®¡ç®—çš„åŠ æƒæ€»å’Œzå’Œç¥ç»å…ƒçš„æ¿€æ´»aï¼ˆç¥ç»å…ƒå³ä¾§çš„æ•°å­—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "supervised learning, 5, 21, 597, 598, 674",
            "zh": "ç›‘ç£å­¦ä¹ ï¼Œ 5ï¼Œ 21ï¼Œ 597ï¼Œ 598ï¼Œ 674"
        }
    },
    {
        "translation": {
            "en": "exploding gradients, 448, 452, 507",
            "zh": "çˆ†ç‚¸æ¢¯åº¦ï¼Œ448ã€452ã€507"
        }
    },
    {
        "translation": {
            "en": "precision, 548, 549, 572",
            "zh": "ç²¾åº¦ï¼Œ 548ï¼Œ 549ï¼Œ 572"
        }
    },
    {
        "translation": {
            "en": "Ross also needed to define the lengths of the observation period and the outcome period for the model.",
            "zh": "Ross è¿˜éœ€è¦å®šä¹‰æ¨¡å‹çš„è§‚å¯ŸæœŸé•¿åº¦å’Œç»“æœæœŸã€‚"
        }
    },
    {
        "translation": {
            "en": "where T is a set of thresholds, |T| is the number of thresholds tested, and TPR(T[i]) and FPR(T[i]) are the true positive and false positive rates at threshold i respectively.",
            "zh": "å…¶ä¸­ T æ˜¯ä¸€ç»„é˜ˆå€¼ï¼Œ|T|æ˜¯æµ‹è¯•çš„é˜ˆå€¼æ•°ï¼ŒTPRï¼ˆT[i]ï¼‰ å’Œ FPRï¼ˆT[i]ï¼‰ åˆ†åˆ«æ˜¯é˜ˆå€¼ i å¤„çš„çœŸé˜³æ€§ç‡å’Œå‡é˜³æ€§ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remember that during the prediction stage, the nearest neighbor algorithm iterates across all the instances in the training dataset and computes the distance between each instance and the query.",
            "zh": "è¯·è®°ä½ï¼Œåœ¨é¢„æµ‹é˜¶æ®µï¼Œæœ€è¿‘é‚»ç®—æ³•ä¼šéå†è®­ç»ƒæ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå®ä¾‹ä¸æŸ¥è¯¢ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.6â€ƒDeployment",
            "zh": "12.6 éƒ¨ç½²"
        }
    },
    {
        "translation": {
            "en": "3.4.1â€ƒHandling Missing Values",
            "zh": "3.4.1 å¤„ç†ç¼ºå¤±å€¼"
        }
    },
    {
        "translation": {
            "en": "Table 9.22",
            "zh": "è¡¨ 9.22"
        }
    },
    {
        "translation": {
            "en": "Usage: The frequency and recency with which customers or users have interacted with an organization. The monetary value of a customerâ€™s interactions with a service. The mix of products or services offered by the organization that a customer or user has used.",
            "zh": "ä½¿ç”¨æƒ…å†µï¼šå®¢æˆ·æˆ–ç”¨æˆ·ä¸ç»„ç»‡äº¤äº’çš„é¢‘ç‡å’Œæ–°è¿‘åº¦ã€‚å®¢æˆ·ä¸æœåŠ¡äº¤äº’çš„è´§å¸ä»·å€¼ã€‚å®¢æˆ·æˆ–ç”¨æˆ·ä½¿ç”¨çš„ç»„ç»‡æä¾›çš„äº§å“æˆ–æœåŠ¡çš„ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason selecting which type of model to use should be informed by the specific priorities of a project and the types of the descriptive and target features in the data.",
            "zh": "å› æ­¤ï¼Œé€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ç±»å‹æ—¶ï¼Œåº”æ ¹æ®é¡¹ç›®çš„ç‰¹å®šä¼˜å…ˆçº§ä»¥åŠæ•°æ®ä¸­æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾çš„ç±»å‹æ¥å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "We use the symbol Ï† to generically represent activation functions. In some cases we use a subscript to indicate the use of a particular activation function. For example, Ï†SM indicates the use of a softmax function activation function, whereas Ï†ReLU indicates the use of a rectified linear activation function.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç¬¦å· Ï† æ¥é€šç”¨åœ°è¡¨ç¤ºæ¿€æ´»å‡½æ•°ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‹æ ‡æ¥æŒ‡ç¤ºä½¿ç”¨ç‰¹å®šçš„æ¿€æ´»å‡½æ•°ã€‚ä¾‹å¦‚ï¼ŒÏ†SM è¡¨ç¤ºä½¿ç”¨ softmax å‡½æ•°æ¿€æ´»å‡½æ•°ï¼Œè€Œ Ï†ReLU è¡¨ç¤ºä½¿ç”¨ä¿®æ­£çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each group containing more instances than the smallest one is then randomly sampled by the appropriate percentage to create a subset that is the under-sampling target size.",
            "zh": "ç„¶åï¼Œæ¯ä¸ªåŒ…å«æ¯”æœ€å°å®ä¾‹å¤šçš„ç»„æŒ‰é€‚å½“çš„ç™¾åˆ†æ¯”éšæœºæŠ½æ ·ï¼Œä»¥åˆ›å»ºä¸€ä¸ªå­é›†ï¼Œè¯¥å­é›†æ˜¯æ¬ é‡‡æ ·çš„ç›®æ ‡å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "These measures capture how well objects match template shapesâ€”although none is accurate enough to actually perform the galaxy morphology prediction itself.",
            "zh": "è¿™äº›æµ‹é‡æ•è·äº†ç‰©ä½“ä¸æ¨¡æ¿å½¢çŠ¶çš„åŒ¹é…ç¨‹åº¦ï¼Œå°½ç®¡æ²¡æœ‰ä¸€ä¸ªè¶³å¤Ÿå‡†ç¡®ï¼Œæ— æ³•å®é™…æ‰§è¡Œæ˜Ÿç³»å½¢æ€é¢„æµ‹æœ¬èº«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.14",
            "zh": "å›¾ 10.14"
        }
    },
    {
        "translation": {
            "en": "A.2â€…â€…â€…Descriptive Statistics for Categorical Features",
            "zh": "A.2 åˆ†ç±»ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡"
        }
    },
    {
        "translation": {
            "en": "are continuous functions with a single variable x. Graphs of these functions are shown in Figure C.2[767]. Each graph also shows the derivative of the function. We will return to these shortly.",
            "zh": "æ˜¯å…·æœ‰å•ä¸ªå˜é‡ x çš„è¿ç»­å‡½æ•°ã€‚è¿™äº›å‡½æ•°çš„å›¾å½¢å¦‚å›¾C.2[767]æ‰€ç¤ºã€‚æ¯ä¸ªå›¾å½¢è¿˜æ˜¾ç¤ºäº†å‡½æ•°çš„å¯¼æ•°ã€‚æˆ‘ä»¬ç¨åå°†å›åˆ°è¿™äº›é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with the analysis of the scaling of the variances for z in the forward pass, the scaling of the variance of the Î´ values as they are backpropagated through each layer k is a function of number of inputs to each neuron in the layer (here nout(k)) multiplied by the variance of the weights for that layer var(W(k)).",
            "zh": "ä¸å‰å‘ä¼ é€’ä¸­ z æ–¹å·®çš„ç¼©æ”¾åˆ†æä¸€æ ·ï¼ŒÎ´å€¼åœ¨æ¯å±‚ k ä¸­åå‘ä¼ æ’­æ—¶æ–¹å·®çš„ç¼©æ”¾æ˜¯è¯¥å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥æ•°ï¼ˆæ­¤å¤„ä¸º noutï¼ˆkï¼‰ï¼‰ä¹˜ä»¥è¯¥å±‚çš„æƒé‡æ–¹å·® varï¼ˆWï¼ˆkï¼‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "predictive data analytics, 3, 3, 21",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æï¼Œ 3ï¼Œ 3ï¼Œ 21"
        }
    },
    {
        "translation": {
            "en": "LIFE EXP., the mean life expectancy at birth",
            "zh": "LIFE EXP.ï¼Œå‡ºç”Ÿæ—¶çš„å¹³å‡é¢„æœŸå¯¿å‘½"
        }
    },
    {
        "translation": {
            "en": "where the training set is composed of n training instances; each training instance is composed of descriptive features d and a target feature t; ğ•„w(di) is the prediction made by a candidate model ğ•„w for a training instance with descriptive features di; and the candidate model ğ•„w is defined by the weight vector w. For our simple scenario in which each instance is described with a single descriptive feature, Equation (7.4)[316] expands to",
            "zh": "å…¶ä¸­è®­ç»ƒé›†ç”± n ä¸ªè®­ç»ƒå®ä¾‹ç»„æˆ;æ¯ä¸ªè®­ç»ƒå®ä¾‹ç”±æè¿°æ€§ç‰¹å¾ D å’Œç›®æ ‡ç‰¹å¾ T ç»„æˆ;Mwï¼ˆdiï¼‰ æ˜¯å€™é€‰æ¨¡å‹ Mw å¯¹å…·æœ‰æè¿°æ€§ç‰¹å¾ di çš„è®­ç»ƒå®ä¾‹æ‰€åšçš„é¢„æµ‹;å€™é€‰æ¨¡å‹ Mw ç”±æƒé‡å‘é‡ w å®šä¹‰ã€‚å¯¹äºæ¯ä¸ªå®ä¾‹éƒ½ç”¨å•ä¸ªæè¿°æ€§ç‰¹å¾æè¿°çš„ç®€å•åœºæ™¯ï¼Œç­‰å¼ ï¼ˆ7.4ï¼‰[316] æ‰©å±•ä¸º"
        }
    },
    {
        "translation": {
            "en": "Linear annealing allows the value for Îµ used in Îµ greedy policy to change over time.",
            "zh": "çº¿æ€§é€€ç«å…è®¸è´ªå©ªç­–ç•¥ä¸­ä½¿ç”¨Îµ Îµå€¼éšæ—¶é—´å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.19â€…â€…â€…An illustration of the forward propagation of d2 through the ReLU network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "8.19 d2 é€šè¿‡ ReLU ç½‘ç»œå‘å‰ä¼ æ’­çš„å›¾ç¤ºï¼Œæ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ï¼Œä»¥åŠç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒæ€»å’Œ z å’Œæ¿€æ´»å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term sample refers to the subset of the population that is selected for analysis.",
            "zh": "æœ¯è¯­â€œæ ·æœ¬â€æ˜¯æŒ‡é€‰æ‹©è¿›è¡Œåˆ†æçš„æ€»ä½“å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.18(b)[226] we have added a second descriptive feature, Y, and assigned each of the instances in the dataset a random Y value in the range [0.0,3.0].",
            "zh": "åœ¨å›¾ 5.18ï¼ˆbï¼‰[226] ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ç¬¬äºŒä¸ªæè¿°æ€§ç‰¹å¾ Yï¼Œå¹¶ä¸ºæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹åˆ†é…äº†ä¸€ä¸ª [0.0,3.0] èŒƒå›´å†…çš„éšæœº Y å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.4",
            "zh": "è¡¨ 1.4"
        }
    },
    {
        "translation": {
            "en": "To best handle image inputs a convolutional neural network29 was used.",
            "zh": "ä¸ºäº†æœ€å¥½åœ°å¤„ç†å›¾åƒè¾“å…¥ï¼Œä½¿ç”¨äº†å·ç§¯ç¥ç»ç½‘ç»œ29ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the version of the support vector machine prediction model that uses a kernel function (see Equation 7.47) with the polynomial kernel function, calculate the output of the model for a query instance with DOSE1 = 0.22 and DOSE2 = 0.16.",
            "zh": "ä½¿ç”¨ä½¿ç”¨æ ¸å‡½æ•°ï¼ˆå‚è§å…¬å¼ 7.47ï¼‰å’Œå¤šé¡¹å¼æ ¸å‡½æ•°çš„æ”¯æŒå‘é‡æœºé¢„æµ‹æ¨¡å‹ç‰ˆæœ¬ï¼Œè®¡ç®— DOSE1 = 0.22 å’Œ DOSE2 = 0.16 çš„æŸ¥è¯¢å®ä¾‹çš„æ¨¡å‹è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Kollar and Friedman (2009) is a comprehensive text on the theory and methods of graphical models and is a good reference text for postgraduate students who are doing research using graphical models.",
            "zh": "Kollar and Friedman ï¼ˆ2009ï¼‰ æ˜¯ä¸€æœ¬å…³äºå›¾å½¢æ¨¡å‹ç†è®ºå’Œæ–¹æ³•çš„ç»¼åˆæ€§æ–‡æœ¬ï¼Œå¯¹äºä½¿ç”¨å›¾å½¢æ¨¡å‹è¿›è¡Œç ”ç©¶çš„ç ”ç©¶ç”Ÿæ¥è¯´æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å‚è€ƒæ–‡æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "To measure error rate, we set aside some of the training data as a validation dataset22 that is not used during tree induction.",
            "zh": "ä¸ºäº†æµ‹é‡é”™è¯¯ç‡ï¼Œæˆ‘ä»¬å°†ä¸€äº›è®­ç»ƒæ•°æ®ç•™ä½œéªŒè¯æ•°æ®é›†22ï¼Œåœ¨æ ‘å½’çº³æœŸé—´ä¸ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prediction subject is a component, and the descriptive features are a set of characteristics of the component that can be gathered on the production line.",
            "zh": "é¢„æµ‹ä¸»ä½“æ˜¯ä¸€ä¸ªç»„ä»¶ï¼Œæè¿°æ€§ç‰¹å¾æ˜¯å¯ä»¥åœ¨ç”Ÿäº§çº¿ä¸Šæ”¶é›†çš„ç»„ä»¶çš„ä¸€ç»„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Careful readers will have noticed that in the equation for variance given in Equation (A.3)[747], we divided the sum of the differences between the values of the feature a and Ä not by n, the number of values for a in the ABT, but by n âˆ’ 1.",
            "zh": "ç»†å¿ƒçš„è¯»è€…ä¼šæ³¨æ„åˆ°ï¼Œåœ¨æ–¹ç¨‹ï¼ˆA.3ï¼‰[747]ä¸­ç»™å‡ºçš„æ–¹å·®æ–¹ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ç‰¹å¾aå’ŒÄçš„å€¼ä¹‹é—´çš„å·®å€¼ä¹‹å’Œé™¤ä»¥nï¼Œå³ABTä¸­açš„å€¼æ•°ï¼Œè€Œæ˜¯é™¤ä»¥n âˆ’ 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "sparse, 443",
            "zh": "ç¨€ç–ï¼Œ443"
        }
    },
    {
        "translation": {
            "en": "The curve defined by a normal probability distribution is symmetric around a single peak value.",
            "zh": "ç”±æ­£æ€æ¦‚ç‡åˆ†å¸ƒå®šä¹‰çš„æ›²çº¿å›´ç»•å•ä¸ªå³°å€¼å¯¹ç§°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bootstrapping uses the existing estimates of expected returns in the action-value table to make action-value table updates rather than waiting for an episode to finish to discover what the actual return is.",
            "zh": "Bootstrapping ä½¿ç”¨æ“ä½œå€¼è¡¨ä¸­é¢„æœŸå›æŠ¥çš„ç°æœ‰ä¼°è®¡å€¼æ¥æ›´æ–°æ“ä½œå€¼è¡¨ï¼Œè€Œä¸æ˜¯ç­‰å¾…å‰§é›†ç»“æŸæ¥å‘ç°å®é™…å›æŠ¥æ˜¯å¤šå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "least squares optimization, 318",
            "zh": "æœ€å°äºŒä¹˜ä¼˜åŒ–ï¼Œ318"
        }
    },
    {
        "translation": {
            "en": "This gives the new set of weights shown as New Weights (after Iteration 1).",
            "zh": "è¿™å°†ç»™å‡ºæ˜¾ç¤ºä¸ºâ€œæ–°æƒé‡â€ï¼ˆåœ¨è¿­ä»£ 1 ä¹‹åï¼‰çš„æ–°æƒé‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "so there are four weightsâ€”w[0], w[1], w[2], and w[3]â€”for which optimal values must be found. For this example, letâ€™s assume that the learning rate, Î±, is 0.00000002 and the initial weights are chosen from a uniform random distribution in the range [âˆ’0.2, 0.2] to be w[0] = âˆ’0.146, w[1] = 0.185, w[2] = âˆ’0.044, and w[3] = 0.119. Table 7.3[331] details the important values from the first two iterations of the gradient descent algorithm when applied to this data.9",
            "zh": "å› æ­¤ï¼Œæœ‰å››ä¸ªæƒé‡ - W[0]ã€W[1]ã€W[2] å’Œ W[3]â€”â€”å¿…é¡»æ‰¾åˆ°æœ€ä½³å€¼ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œå‡è®¾å­¦ä¹ ç‡ Î± ä¸º 0.000000002ï¼Œåˆå§‹æƒé‡ä» [âˆ’0.2ï¼Œ 0.2] èŒƒå›´å†…çš„å‡åŒ€éšæœºåˆ†å¸ƒä¸­é€‰æ‹©ä¸º w[0] = âˆ’0.146ã€w[1] = 0.185ã€w[2] = âˆ’0.044 å’Œ w[3] = 0.119ã€‚è¡¨ 7.3[331] è¯¦ç»†ä»‹ç»äº†æ¢¯åº¦ä¸‹é™ç®—æ³•å‰ä¸¤æ¬¡è¿­ä»£ä¸­åº”ç”¨äºæ­¤æ•°æ®æ—¶çš„é‡è¦å€¼9ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.3â€ƒHandling Categorical Descriptive Features",
            "zh": "7.4.3 å¤„ç†åˆ†ç±»æè¿°æ€§ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "Sarah spent days training to get better at this challenge.",
            "zh": "èæ‹‰èŠ±äº†å‡ å¤©æ—¶é—´è®­ç»ƒï¼Œä»¥æ›´å¥½åœ°åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In practice, the simplest way to calculate a K-S statistic for the predictions made by a model for a test dataset is to first tabulate the positive and negative cumulative probabilities for the scores predicted for each instance in the test dataset, in ascending order by prediction score.",
            "zh": "åœ¨å®è·µä¸­ï¼Œè®¡ç®—æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®é›†æ‰€åšçš„é¢„æµ‹çš„ K-S ç»Ÿè®¡é‡çš„æœ€ç®€å•æ–¹æ³•æ˜¯é¦–å…ˆå°†æµ‹è¯•æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹é¢„æµ‹çš„åˆ†æ•°çš„æ­£è´Ÿç´¯ç§¯æ¦‚ç‡åˆ¶æˆè¡¨æ ¼ï¼ŒæŒ‰é¢„æµ‹åˆ†æ•°å‡åºæ’åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "To build shallow trees, we need to put the descriptive features that best discriminate between instances that have different target feature values toward the top of the tree.",
            "zh": "ä¸ºäº†æ„å»ºæµ…å±‚æ ‘ï¼Œæˆ‘ä»¬éœ€è¦å°†æœ€èƒ½åŒºåˆ†å…·æœ‰ä¸åŒç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹çš„æè¿°æ€§ç‰¹å¾æ”¾åœ¨æ ‘çš„é¡¶éƒ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Initially, though, we will focus on a simplified version of this task in which just SIZE is used to predict RENTAL PRICE.",
            "zh": "ä¸è¿‡ï¼Œæœ€åˆï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºæ­¤ä»»åŠ¡çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­ä»…ä½¿ç”¨ SIZE æ¥é¢„æµ‹ RENTAL PRICEã€‚"
        }
    },
    {
        "translation": {
            "en": "The correlation between two features, a and b, can be calculated as",
            "zh": "ä¸¤ä¸ªç‰¹å¾ a å’Œ b ä¹‹é—´çš„ç›¸å…³æ€§å¯ä»¥è®¡ç®—ä¸º"
        }
    },
    {
        "translation": {
            "en": "and for MENINGITIS = false",
            "zh": "è„‘è†œç‚ = å‡"
        }
    },
    {
        "translation": {
            "en": "This layer of neurons is the same width as the LSTM cell, and so there is one activation in the output of the sigmoid layer for each activation in the cell state.",
            "zh": "è¯¥ç¥ç»å…ƒå±‚çš„å®½åº¦ä¸LSTMç»†èƒç›¸åŒï¼Œå› æ­¤åœ¨ç»†èƒçŠ¶æ€ä¸‹ï¼Œå¯¹äºæ¯æ¬¡æ¿€æ´»ï¼Œåœ¨ä¹™çŠ¶ç»“è‚ å±‚çš„è¾“å‡ºä¸­éƒ½æœ‰ä¸€æ¬¡æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Normalizing the data is an important thing to do for almost all machine learning algorithms, not just nearest neighbor.",
            "zh": "å¯¹äºå‡ ä¹æ‰€æœ‰æœºå™¨å­¦ä¹ ç®—æ³•æ¥è¯´ï¼Œè§„èŒƒåŒ–æ•°æ®æ˜¯ä¸€ä»¶é‡è¦çš„äº‹æƒ…ï¼Œè€Œä¸ä»…ä»…æ˜¯æœ€è¿‘é‚»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "K-S statistic, 563",
            "zh": "K-S ç»Ÿè®¡ï¼Œ563"
        }
    },
    {
        "translation": {
            "en": "3. Obviously, churn events will happen on different dates for different customers; therefore, to build the ABT, the observation and outcome periods for different customers would have to be aligned. This situation is an example of the propensity model scenario illustrated in Figure 2.6[39] in Section 2.4.3[36].",
            "zh": "3. æ˜¾ç„¶ï¼Œä¸åŒå®¢æˆ·çš„æµå¤±äº‹ä»¶ä¼šåœ¨ä¸åŒçš„æ—¥æœŸå‘ç”Ÿ;å› æ­¤ï¼Œè¦æ„å»º ABTï¼Œå¿…é¡»å¯¹ä¸åŒå®¢æˆ·çš„è§‚å¯ŸæœŸå’Œç»“æœæœŸä¿æŒä¸€è‡´ã€‚è¿™ç§æƒ…å†µæ˜¯ç¬¬ 2.4.3 èŠ‚[36] çš„å›¾ 2.6[39] ä¸­æ‰€ç¤ºçš„å€¾å‘æ¨¡å‹åœºæ™¯çš„ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first question addresses data availability.",
            "zh": "ç¬¬ä¸€ä¸ªé—®é¢˜æ¶‰åŠæ•°æ®å¯ç”¨æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "(short)â€ course so that students gain a deeper and broader understanding of machine learning, and it includes the second case study.",
            "zh": "ï¼ˆshortï¼‰â€œè¯¾ç¨‹ï¼Œä»¥ä¾¿å­¦ç”Ÿå¯¹æœºå™¨å­¦ä¹ æœ‰æ›´æ·±å…¥ã€æ›´å¹¿æ³›çš„äº†è§£ï¼Œå…¶ä¸­åŒ…æ‹¬ç¬¬äºŒä¸ªæ¡ˆä¾‹ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the approaches to machine learning that we have presented in this book induces distinct types of prediction models with different strengths and weaknesses.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ä»‹ç»çš„æ¯ç§æœºå™¨å­¦ä¹ æ–¹æ³•éƒ½ä¼šè¯±å¯¼å‡ºå…·æœ‰ä¸åŒä¼˜åŠ¿å’ŒåŠ£åŠ¿çš„ä¸åŒç±»å‹çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extended version of the college athletes dataset.",
            "zh": "å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The inductive bias encoded in this algorithm includes a preference bias to prefer models that minimize the sum of squared errors function and a restriction bias introduced by the facts that we consider only linear combinations of descriptive features and that we take a single path through the error gradient from a random starting point.",
            "zh": "è¯¥ç®—æ³•ä¸­ç¼–ç çš„å½’çº³åå·®åŒ…æ‹¬åå¥½åå·®æœ€å°åŒ–å¹³æ–¹è¯¯å·®å‡½æ•°ä¹‹å’Œçš„æ¨¡å‹ï¼Œä»¥åŠç”±æˆ‘ä»¬ä»…è€ƒè™‘æè¿°æ€§ç‰¹å¾çš„çº¿æ€§ç»„åˆçš„äº‹å®å¼•å…¥çš„é™åˆ¶åå·®ï¼Œä»¥åŠæˆ‘ä»¬ä»éšæœºèµ·ç‚¹é€šè¿‡è¯¯å·®æ¢¯åº¦çš„å•ä¸€è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10[340] illustrates a linearly separable dataset; in that case the two classes of inputs were good generators and faulty generators.",
            "zh": "å›¾ 7.10[340] å±•ç¤ºäº†ä¸€ä¸ªçº¿æ€§å¯åˆ†ç¦»çš„æ•°æ®é›†;åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸¤ç±»è¾“å…¥æ˜¯è‰¯å¥½çš„å‘ç”µæœºå’Œæ•…éšœå‘ç”µæœºã€‚"
        }
    },
    {
        "translation": {
            "en": "The name convolutional neural network comes from the fact that it is possible to implement the processing of an image by a set of neurons that share a filter with a single neuron that applies the filter to each region of the image in sequence and stores the result for each region.",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œçš„åç§°æ¥æºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å¯ä»¥é€šè¿‡ä¸€ç»„ç¥ç»å…ƒæ¥å®ç°å›¾åƒçš„å¤„ç†ï¼Œè¿™äº›ç¥ç»å…ƒä¸å•ä¸ªç¥ç»å…ƒå…±äº«ä¸€ä¸ªè¿‡æ»¤å™¨ï¼Œè¯¥ç¥ç»å…ƒæŒ‰é¡ºåºå°†è¿‡æ»¤å™¨åº”ç”¨äºå›¾åƒçš„æ¯ä¸ªåŒºåŸŸå¹¶å­˜å‚¨æ¯ä¸ªåŒºåŸŸçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.5â€…â€…â€…Agglomerative Hierarchical Clustering",
            "zh": "10.4.5 é›†èšåˆ†å±‚èšç±»"
        }
    },
    {
        "translation": {
            "en": "4.4â€…â€…â€…Extensions and Variations",
            "zh": "4.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "There are three types of vegetation that should be recognized by this model.",
            "zh": "æ­¤æ¨¡å‹åº”è¯†åˆ«ä¸‰ç§ç±»å‹çš„æ¤è¢«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Extreme cases of exploding gradients can result in numerical overflow generating NaN (not-a-number) gradients.",
            "zh": "æ¢¯åº¦çˆ†ç‚¸çš„æç«¯æƒ…å†µå¯èƒ½å¯¼è‡´æ•°å€¼æº¢å‡ºï¼Œç”Ÿæˆ NaNï¼ˆéæ•°å­—ï¼‰æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, unsupervised learning is a fascinating research area, and it is probably fair to say that it has many more significant open research challenges than supervised learning.",
            "zh": "æœ€åï¼Œæ— ç›‘ç£å­¦ä¹ æ˜¯ä¸€ä¸ªå¼•äººå…¥èƒœçš„ç ”ç©¶é¢†åŸŸï¼Œå¯ä»¥å…¬å¹³åœ°è¯´ï¼Œå®ƒæ¯”ç›‘ç£å­¦ä¹ é¢ä¸´æ›´é‡è¦çš„å¼€æ”¾ç ”ç©¶æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The relationship between rainfall and grass growth in the grass growth dataset can be accurately represented as a second order polynomial through the following model:",
            "zh": "è‰ç”Ÿé•¿æ•°æ®é›†ä¸­é™é›¨é‡ä¸è‰ç”Ÿé•¿ä¹‹é—´çš„å…³ç³»å¯ä»¥é€šè¿‡ä»¥ä¸‹æ¨¡å‹å‡†ç¡®åœ°è¡¨ç¤ºä¸ºäºŒé˜¶å¤šé¡¹å¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "Kutner, Michael, Christopher Nachtsheim, John Neter, and William Li. 2004. Applied linear statistical models. McGraw-Hill.",
            "zh": "Kutnerã€Michaelã€Christopher Nachtsheimã€John Neter å’Œ William Li. 2004 å¹´ã€‚åº”ç”¨çº¿æ€§ç»Ÿè®¡æ¨¡å‹ã€‚éº¦æ ¼åŠ³-å¸Œå°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "true positive, 537",
            "zh": "çœŸé˜³æ€§ï¼Œ 537"
        }
    },
    {
        "translation": {
            "en": "26. The implementation of Lunar Lander used in this example comes from the Gym toolkit developed by OpenAI (Brockman et al., 2016). This is a fantastic resource for experimenting with reinforcement learning agents.",
            "zh": "26. æœ¬ä¾‹ä¸­ä½¿ç”¨çš„ Lunar Lander çš„å®ç°æ¥è‡ª OpenAI å¼€å‘çš„ Gym å·¥å…·åŒ…ï¼ˆBrockman ç­‰äººï¼Œ2016 å¹´ï¼‰ã€‚è¿™æ˜¯è¯•éªŒå¼ºåŒ–å­¦ä¹ ä»£ç†çš„ç»ä½³èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4â€…â€…â€…Extensions and Variations",
            "zh": "6.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "The ratio between peak and off-peak calls made by the customer this month",
            "zh": "æœ¬æœˆå®¢æˆ·æ‹¨æ‰“çš„é«˜å³°å’Œéé«˜å³°å‘¼å«ä¹‹é—´çš„æ¯”ç‡"
        }
    },
    {
        "translation": {
            "en": "the probability of a patient having a headache and meningitis is",
            "zh": "æ‚£è€…å¤´ç—›å’Œè„‘è†œç‚çš„æ¦‚ç‡æ˜¯"
        }
    },
    {
        "translation": {
            "en": "component, 274",
            "zh": "ç»„ä»¶ï¼Œ274"
        }
    },
    {
        "translation": {
            "en": "During the process of determining which analytics solution was most suitable for the current situation at AT, Ross had already begun to understand the data resources available.",
            "zh": "åœ¨ç¡®å®šå“ªç§åˆ†æè§£å†³æ–¹æ¡ˆæœ€é€‚åˆ AT å½“å‰æƒ…å†µçš„è¿‡ç¨‹ä¸­ï¼ŒRoss å·²ç»å¼€å§‹äº†è§£å¯ç”¨çš„æ•°æ®èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.4â€ƒThe Bellman Equations",
            "zh": "11.2.4 è´å°”æ›¼æ–¹ç¨‹"
        }
    },
    {
        "translation": {
            "en": "domain subconcept, 32",
            "zh": "é¢†åŸŸå­æ¦‚å¿µï¼Œ32"
        }
    },
    {
        "translation": {
            "en": "12.3â€…â€…â€…The confusion matrix from the test of the AT churn prediction stratified hold-out test set using the pruned decision tree in Figure 12.5[699].",
            "zh": "12.3 ä½¿ç”¨å›¾12.5[699]ä¸­ä¿®å‰ªåçš„å†³ç­–æ ‘ï¼Œæ¥è‡ªATæµå¤±é¢„æµ‹åˆ†å±‚ä¿æŒæµ‹è¯•é›†çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce Claude Shannonâ€™s approach to measuring information,1 in particular his model of entropy and how it is used in the information gain measure to capture the informativeness of a descriptive feature. Before this we introduce decision trees, the actual prediction models that we are trying to build.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰æµ‹é‡ä¿¡æ¯çš„æ–¹æ³•ï¼Œ1ç‰¹åˆ«æ˜¯ä»–çš„ç†µæ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•åœ¨ä¿¡æ¯å¢ç›Šæµ‹é‡ä¸­ä½¿ç”¨å®ƒæ¥æ•è·æè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯æ€§ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬ä»‹ç»å†³ç­–æ ‘ï¼Œå³æˆ‘ä»¬å°è¯•æ„å»ºçš„å®é™…é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that there are 190 different combinations of the values of the hands held by the player and the dealer.",
            "zh": "è¿™æ„å‘³ç€ç©å®¶å’Œåº„å®¶æ‰€æŒæ‰‹ç‰Œçš„å€¼æœ‰ 190 ç§ä¸åŒçš„ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "8.41â€…â€…â€…The flow of activations through a long short-term memory unit during forward propagation when ctâˆ’1 = [0.3, 0.6], ht = [0.1, 0.8], and xt = [0.9].",
            "zh": "8.41 å½“ctâˆ’1 = [0.3ï¼Œ 0.6]ï¼Œ ht = [0.1ï¼Œ 0.8]ï¼Œ and xt = [0.9]æ—¶ï¼Œæ­£å‘ä¼ æ’­æœŸé—´é€šè¿‡é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„æ¿€æ´»æµã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.4",
            "zh": "å›¾ 2.4"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11(b)[290] illustrates the network structure of the naive Bayes model for predicting a fraudulent loan application that was built in Section 6.3.1[262].",
            "zh": "å›¾6.11ï¼ˆbï¼‰[290]è¯´æ˜äº†ç¬¬6.3.1èŠ‚[262]ä¸­æ„å»ºçš„ç”¨äºé¢„æµ‹æ¬ºè¯ˆæ€§è´·æ¬¾ç”³è¯·çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„ç½‘ç»œç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The top row of images in Figure 14.2[737] illustrates how the three artificial datasets were created.",
            "zh": "å›¾14.2[737]ä¸­çš„æœ€ä¸Šé¢ä¸€è¡Œå›¾åƒè¯´æ˜äº†ä¸‰ä¸ªäººå·¥æ•°æ®é›†çš„åˆ›å»ºæ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "population mean, 61",
            "zh": "äººå£å¹³å‡æ•°ï¼Œ61"
        }
    },
    {
        "translation": {
            "en": "The player then repeatedly chooses to either be dealt another card, Twist, or to stop on their current total, Stick.8 When the player is finished, the dealer turns over their second card and must continue to deal themselves cards until they reach a total value of 17 or more, or go bust by exceeding a value of 22.",
            "zh": "ç„¶åï¼Œç©å®¶åå¤é€‰æ‹©å‘å¦ä¸€å¼ ç‰Œï¼ŒTwistï¼Œæˆ–è€…åœæ­¢ä»–ä»¬å½“å‰çš„æ€»æ•°ï¼ŒStick.8 å½“ç©å®¶å®Œæˆæ—¶ï¼Œåº„å®¶äº¤å‡ºä»–ä»¬çš„ç¬¬äºŒå¼ ç‰Œï¼Œå¿…é¡»ç»§ç»­å‘ç‰Œï¼Œç›´åˆ°ä»–ä»¬è¾¾åˆ° 17 æˆ–æ›´å¤šçš„æ€»ä»·å€¼ï¼Œæˆ–è€…è¶…è¿‡ä»·å€¼ 22 è€Œç ´äº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. The table below shows the predictions made for a categorical target feature by a model for a test dataset. Based on this test set, calculate the evaluation measures listed below.",
            "zh": "1. ä¸‹è¡¨æ˜¾ç¤ºäº†æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®é›†çš„åˆ†ç±»ç›®æ ‡ç‰¹å¾æ‰€åšçš„é¢„æµ‹ã€‚æ ¹æ®æ­¤æµ‹è¯•é›†ï¼Œè®¡ç®—ä¸‹é¢åˆ—å‡ºçš„è¯„ä¼°åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.17[222] shows a contour plot of these Mahalanobis distances.",
            "zh": "å›¾5.17[222]æ˜¾ç¤ºäº†è¿™äº›é©¬æ°è·ç¦»çš„ç­‰å€¼çº¿å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a Markov process diagram to capture the behavior of a small baby as described.",
            "zh": "ï¼ˆbï¼‰ ç»˜åˆ¶é©¬å°”å¯å¤«è¿‡ç¨‹å›¾ä»¥æ•æ‰æ‰€æè¿°çš„å°å©´å„¿çš„è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "13.2â€ƒData Understanding",
            "zh": "13.2 æ•°æ®ç†è§£"
        }
    },
    {
        "translation": {
            "en": "Percentiles are another useful measure of the variation of the values for a feature.",
            "zh": "ç™¾åˆ†ä½æ•°æ˜¯è¡¡é‡è¦ç´ å€¼å˜åŒ–çš„å¦ä¸€ä¸ªæœ‰ç”¨åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, not only is a different randomly selected set of neurons dropped for each training example, but a different set of neurons is randomly selected for each presentation of a training example.",
            "zh": "äº‹å®ä¸Šï¼Œä¸ä»…æ¯ä¸ªè®­ç»ƒç¤ºä¾‹éƒ½ä¼šä¸¢å¼ƒä¸€ç»„ä¸åŒçš„éšæœºé€‰æ‹©çš„ç¥ç»å…ƒï¼Œè€Œä¸”æ¯ä¸ªè®­ç»ƒç¤ºä¾‹çš„å‘ˆç°éƒ½ä¼šéšæœºé€‰æ‹©ä¸€ç»„ä¸åŒçš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Î´k would denote the error gradient for neuron k. It is these Î´ error gradients that are calculated and backpropagated during the backward pass of the backpropagation algorithm.",
            "zh": "ä¾‹å¦‚ï¼ŒÎ´k è¡¨ç¤ºç¥ç»å…ƒ k çš„è¯¯å·®æ¢¯åº¦ã€‚æ­£æ˜¯è¿™äº›Î´è¯¯å·®æ¢¯åº¦åœ¨åå‘ä¼ æ’­ç®—æ³•çš„å‘åä¼ é€’è¿‡ç¨‹ä¸­è¢«è®¡ç®—å’Œåå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Transitions related to a Twist action are shown as solid lines, and transitions related to a Stick action are shown with dashed lines.",
            "zh": "ä¸ Twist æ“ä½œç›¸å…³çš„è¿‡æ¸¡æ˜¾ç¤ºä¸ºå®çº¿ï¼Œä¸æ‘‡æ†æ“ä½œç›¸å…³çš„è¿‡æ¸¡ä»¥è™šçº¿æ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The impact this has on designing features for inclusion in an ABT is that the use of some features in analytics solutions that leads to some people being given preferential treatment is in breach of anti-discrimination law. For example, credit scoring models such as the one discussed in Section 1.2[5] cannot use race as a descriptive feature because this would discriminate against people on this basis.",
            "zh": "è¿™å¯¹è®¾è®¡åŒ…å«åœ¨ ABT ä¸­çš„åŠŸèƒ½çš„å½±å“æ˜¯ï¼Œåœ¨åˆ†æè§£å†³æ–¹æ¡ˆä¸­ä½¿ç”¨æŸäº›åŠŸèƒ½å¯¼è‡´æŸäº›äººè·å¾—ä¼˜æƒ å¾…é‡è¿åäº†åæ­§è§†æ³•ã€‚ä¾‹å¦‚ï¼Œä¿¡ç”¨è¯„åˆ†æ¨¡å‹ï¼ˆå¦‚ç¬¬1.2èŠ‚[5]ä¸­è®¨è®ºçš„æ¨¡å‹ä¸èƒ½ä½¿ç”¨ç§æ—ä½œä¸ºæè¿°æ€§ç‰¹å¾ï¼Œå› ä¸ºè¿™ä¼šåœ¨æ­¤åŸºç¡€ä¸Šæ­§è§†äººä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the categorical feature GENDER and the target feature PREFCHANNEL.",
            "zh": "ï¼ˆbï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†åˆ†ç±»ç‰¹å¾ GENDER å’Œç›®æ ‡ç‰¹å¾ PREFCHANNEL ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the example function f(x,y) = x2 âˆ’ y2 + 2x + 4y âˆ’ xy + 2, we get two partial derivatives:",
            "zh": "å¯¹äºç¤ºä¾‹å‡½æ•° fï¼ˆxï¼Œyï¼‰ = x2 âˆ’ y2 + 2x + 4y âˆ’ xy + 2ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸¤ä¸ªåå¯¼æ•°ï¼š"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors",
            "zh": "è¯¯å·®çš„å¹³æ–¹å’Œ"
        }
    },
    {
        "translation": {
            "en": "The most popular method for implementing dropout is known as inverted dropout.38 When we use inverted dropout we drop a neuron by multiplying the activation of the neuron during the forward pass by zero.",
            "zh": "å®ç° dropout çš„æœ€æµè¡Œæ–¹æ³•ç§°ä¸ºå€’ç½®è¾å­¦.38 å½“æˆ‘ä»¬ä½¿ç”¨å€’ç½®è¾å­¦æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡å°†ç¥ç»å…ƒåœ¨å‰å‘ä¼ é€’æœŸé—´çš„æ¿€æ´»ä¹˜ä»¥é›¶æ¥ä¸¢å¼ƒç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Another benefit of using the logistic function is that logistic regression model outputs can be interpreted as probabilities of the occurrence of a target level.",
            "zh": "ä½¿ç”¨é€»è¾‘å‡½æ•°çš„å¦ä¸€ä¸ªå¥½å¤„æ˜¯ï¼Œé€»è¾‘å›å½’æ¨¡å‹çš„è¾“å‡ºå¯ä»¥è§£é‡Šä¸ºç›®æ ‡æ°´å¹³å‡ºç°çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A Bayesian network for a domain consisting of two binary features. The structure of the network states that the value of feature A directly influences the value of feature B. (b) A Bayesian network consisting of four binary features with a path containing three generations of nodes: D, C, and B.",
            "zh": "ï¼ˆaï¼‰ ç”±ä¸¤ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ç»„æˆçš„åŸŸçš„è´å¶æ–¯ç½‘ç»œã€‚ï¼ˆbï¼‰ è´å¶æ–¯ç½‘ç»œï¼Œç”±å››ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ç»„æˆï¼Œå…¶è·¯å¾„åŒ…å«ä¸‰ä»£èŠ‚ç‚¹ï¼šDã€C å’Œ Bã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 12.4",
            "zh": "å›¾ 12.4"
        }
    },
    {
        "translation": {
            "en": "A pruned and stunted decision tree built for the Acme Telephonica churn prediction problem.",
            "zh": "ä¸º Acme Telephonica æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„ä¿®å‰ªå’Œå‘è‚²ä¸è‰¯çš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Based on the average class accuracy measures, which model appears to perform best at this task?",
            "zh": "ï¼ˆcï¼‰ æ ¹æ®å¹³å‡ç±»åˆ«å‡†ç¡®æ€§æµ‹é‡ï¼Œå“ªä¸ªæ¨¡å‹ä¼¼ä¹åœ¨è¿™é¡¹ä»»åŠ¡ä¸­è¡¨ç°æœ€å¥½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "2.1.1â€ƒCase Study: Motor Insurance Fraud",
            "zh": "2.1.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "7.7â€…â€…â€…Exercises",
            "zh": "7.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Heating load is the amount of heat energy required to keep a building at a specified temperature, usually 65Â° Fahrenheit during the winter regardless of outside temperature.",
            "zh": "ä¾›æš–è´Ÿè·æ˜¯å°†å»ºç­‘ç‰©ä¿æŒåœ¨æŒ‡å®šæ¸©åº¦æ‰€éœ€çš„çƒ­èƒ½é‡ï¼Œæ— è®ºå¤–éƒ¨æ¸©åº¦å¦‚ä½•ï¼Œå†¬å­£é€šå¸¸ä¸º 65Â° åæ°åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the expected volumes of images that would be produced by the SDSS pipeline, Jocelyn and Edwin agreed that the model developed should be capable of performing approximately 1,000 classifications per second on a dedicated server of modest specification.",
            "zh": "æ ¹æ® SDSS ç®¡é“å°†äº§ç”Ÿçš„é¢„æœŸå›¾åƒé‡ï¼ŒJocelyn å’Œ Edwin ä¸€è‡´è®¤ä¸ºï¼Œå¼€å‘çš„æ¨¡å‹åº”è¯¥èƒ½å¤Ÿåœ¨ä¸­ç­‰è§„æ ¼çš„ä¸“ç”¨æœåŠ¡å™¨ä¸Šæ¯ç§’æ‰§è¡Œå¤§çº¦ 1,000 æ¬¡åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.32",
            "zh": "0.32"
        }
    },
    {
        "translation": {
            "en": "The revised predictions are also used in making predictions for query instances. The predicted level for a query, q, is the level associated with the one-versus-all model that outputs the highest result after normalization. We can write this",
            "zh": "ä¿®è®¢åçš„é¢„æµ‹è¿˜ç”¨äºå¯¹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚æŸ¥è¯¢çš„é¢„æµ‹çº§åˆ« q æ˜¯ä¸è§„èŒƒåŒ–åè¾“å‡ºæœ€é«˜ç»“æœçš„ä¸€å¯¹å¤šæ¨¡å‹å…³è”çš„çº§åˆ«ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·å†™"
        }
    },
    {
        "translation": {
            "en": "The stride parameter specifies the distance between the center of the local receptive field of one neuron and the center of the local receptive fields of its horizontal or vertical neighbor in the set of neurons sharing the filter.",
            "zh": "æ­¥å¹…å‚æ•°æŒ‡å®šä¸€ä¸ªç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ä¸­å¿ƒä¸å…±äº«æ»¤æ³¢å™¨çš„ä¸€ç»„ç¥ç»å…ƒä¸­å…¶æ°´å¹³æˆ–å‚ç›´é‚»å±…çš„å±€éƒ¨æ„Ÿå—é‡ä¸­å¿ƒä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, this set has zero entropy.",
            "zh": "æ‰€ä»¥ï¼Œè¿™ä¸ªé›†åˆçš„ç†µä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the two features being visualized have a strong relationship, then the bar plots for each level of the second feature will look noticeably different from one another and from the overall bar plot for the first feature.",
            "zh": "å¦‚æœè¦å¯è§†åŒ–çš„ä¸¤ä¸ªè¦ç´ å…·æœ‰å¾ˆå¼ºçš„å…³ç³»ï¼Œåˆ™ç¬¬äºŒä¸ªè¦ç´ çš„æ¯ä¸ªçº§åˆ«çš„æ¡å½¢å›¾çœ‹èµ·æ¥å½¼æ­¤æ˜æ˜¾ä¸åŒï¼Œå¹¶ä¸”ä¸ç¬¬ä¸€ä¸ªè¦ç´ çš„æ•´ä½“æ¡å½¢å›¾æ˜æ˜¾ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Description: Second edition. | Cambridge, Massachusetts: The MIT Press, 2020. | Includes bibliographical references and index.",
            "zh": "æè¿°ï¼šç¬¬äºŒç‰ˆã€‚|é©¬è¨è¯¸å¡å·å‰‘æ¡¥ï¼šéº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ï¼Œ2020 å¹´ã€‚|åŒ…æ‹¬å‚è€ƒä¹¦ç›®å’Œç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Daelemans and van den Bosch (2005) discuss why nearest neighbor models are so suitable for text analytics.",
            "zh": "Daelemans å’Œ van den Bosch ï¼ˆ2005ï¼‰ è®¨è®ºäº†ä¸ºä»€ä¹ˆæœ€è¿‘é‚»æ¨¡å‹å¦‚æ­¤é€‚ç”¨äºæ–‡æœ¬åˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "0.3057",
            "zh": "0.3057"
        }
    },
    {
        "translation": {
            "en": "The impact of this larger standard deviation on the weights in the network is evident if we compare Figure 8.23(a)[453] with Figure 8.24(a)[454]: although the distribution of weights within each layer looks similar in the two figures, the scales on the weights axes show that the weights plotted in Figure 8.24(a)[454] have a larger variance from the median 0, indicating that the weights tend to be larger.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†å›¾8.23ï¼ˆaï¼‰[453]ä¸å›¾8.24ï¼ˆaï¼‰[454]è¿›è¡Œæ¯”è¾ƒï¼Œè¿™ç§è¾ƒå¤§çš„æ ‡å‡†å·®å¯¹ç½‘ç»œä¸­æƒé‡çš„å½±å“æ˜¯æ˜¾è€Œæ˜“è§çš„ï¼šå°½ç®¡åœ¨ä¸¤ä¸ªå›¾ä¸­ï¼Œæ¯å±‚å†…çš„æƒé‡åˆ†å¸ƒçœ‹èµ·æ¥ç›¸ä¼¼ï¼Œä½†æƒé‡è½´ä¸Šçš„åˆ»åº¦æ˜¾ç¤ºï¼Œå›¾8.24ï¼ˆaï¼‰[454]ä¸­ç»˜åˆ¶çš„æƒé‡ä¸ä¸­ä½æ•°0çš„æ–¹å·®æ›´å¤§ï¼Œ è¡¨ç¤ºæƒé‡å¾€å¾€æ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Payment prediction] Data Requirements: This solution would require the full details of policies and claims as well as data on the original amount specified in a claim and the amount ultimately paid out. Capacity Requirements: Again, this solution assumes that the company has the potential to run this model in a timely fashion whenever new claims rise and also has the capacity to make offers to claimants. This assumes the existence of a customer contact center or something similar.",
            "zh": "[ä»˜æ¬¾é¢„æµ‹]æ•°æ®è¦æ±‚ï¼šæ­¤è§£å†³æ–¹æ¡ˆå°†éœ€è¦ä¿å•å’Œç´¢èµ”çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯ï¼Œä»¥åŠç´¢èµ”ä¸­æŒ‡å®šçš„åŸå§‹é‡‘é¢å’Œæœ€ç»ˆæ”¯ä»˜çš„é‡‘é¢çš„æ•°æ®ã€‚å®¹é‡è¦æ±‚ï¼šåŒæ ·ï¼Œæ­¤è§£å†³æ–¹æ¡ˆå‡è®¾å…¬å¸æœ‰å¯èƒ½åœ¨æ–°ç´¢èµ”å‡ºç°æ—¶åŠæ—¶è¿è¡Œæ­¤æ¨¡å‹ï¼Œå¹¶ä¸”è¿˜æœ‰èƒ½åŠ›å‘ç´¢èµ”äººæå‡ºæŠ¥ä»·ã€‚è¿™å‡å®šå­˜åœ¨å®¢æˆ·è”ç»œä¸­å¿ƒæˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is more convenient for us to convert the output of the log function to positive numbers by multiplying them by âˆ’ 1.",
            "zh": "é€šè¿‡å°†å¯¹æ•°å‡½æ•°çš„è¾“å‡ºä¹˜ä»¥ âˆ’ 1ï¼Œå°†å¯¹æ•°è½¬æ¢ä¸ºæ­£æ•°å¯¹æˆ‘ä»¬æ¥è¯´æ›´æ–¹ä¾¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.2â€ƒDifferent Types of Features",
            "zh": "2.4.2 ä¸åŒç±»å‹çš„åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "5. Fat finger is a phrase often used in financial trading to refer to mistakes that arise when a trader enters extra zeros by mistake and buys or sells much more of a stock than intended.",
            "zh": "5. èƒ–æ‰‹æŒ‡æ˜¯é‡‘èäº¤æ˜“ä¸­ç»å¸¸ä½¿ç”¨çš„ä¸€ä¸ªçŸ­è¯­ï¼ŒæŒ‡çš„æ˜¯å½“äº¤æ˜“è€…é”™è¯¯åœ°è¾“å…¥é¢å¤–çš„é›¶å¹¶ä¹°å…¥æˆ–å–å‡ºæ¯”é¢„æœŸå¤šå¾—å¤šçš„è‚¡ç¥¨æ—¶å‡ºç°çš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. Instances should be added to the training dataset only if we have determined after making the prediction that the prediction was, in fact, correct. In this example, we assume that at the draft, the query player was drafted.",
            "zh": "5. åªæœ‰å½“æˆ‘ä»¬åœ¨åšå‡ºé¢„æµ‹åç¡®å®šé¢„æµ‹å®é™…ä¸Šæ˜¯æ­£ç¡®çš„æ—¶ï¼Œæ‰åº”å°†å®ä¾‹æ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ä¸­ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾åœ¨è‰ç¨¿æ—¶ï¼ŒæŸ¥è¯¢æ’­æ”¾å™¨æ˜¯è‰ç¨¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider Neuron 4 in our example network.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘æˆ‘ä»¬ç¤ºä¾‹ç½‘ç»œä¸­çš„ç¥ç»å…ƒ 4ã€‚"
        }
    },
    {
        "translation": {
            "en": "From these domain concepts, Ross worked on deriving a set of descriptive features.",
            "zh": "ä»è¿™äº›é¢†åŸŸæ¦‚å¿µä¸­ï¼ŒRoss è‡´åŠ›äºæ¨å¯¼å‡ºä¸€ç»„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An alternative to entirely deleting features that suffer from large numbers of missing values is to derive a missing indicator feature from them.",
            "zh": "å®Œå…¨åˆ é™¤å­˜åœ¨å¤§é‡ç¼ºå¤±å€¼çš„ç‰¹å¾çš„æ›¿ä»£æ–¹æ³•æ˜¯ä»ä¸­æ´¾ç”Ÿç¼ºå¤±æŒ‡æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4091",
            "zh": "3.4091"
        }
    },
    {
        "translation": {
            "en": "This was reasonably straightforward as AT management had stated that their goal was to reduce their customer churn rates.",
            "zh": "è¿™ç›¸å½“ç®€å•ï¼Œå› ä¸º AT ç®¡ç†å±‚æ›¾è¡¨ç¤ºä»–ä»¬çš„ç›®æ ‡æ˜¯é™ä½å®¢æˆ·æµå¤±ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The spiral category further divided into clockwise spiral and anti-clockwise spiral subcategories.",
            "zh": "èºæ—‹ç±»åˆ«è¿›ä¸€æ­¥åˆ†ä¸ºé¡ºæ—¶é’ˆèºæ—‹å’Œé€†æ—¶é’ˆèºæ—‹å­ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "28. Schapire (1999) gives a readable introduction to boosting by one of the originators of the technique.",
            "zh": "28. Schapire ï¼ˆ1999ï¼‰ å¯¹è¯¥æŠ€æœ¯çš„åˆ›å§‹äººä¹‹ä¸€çš„æå‡è¿›è¡Œäº†å¯è¯»çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A joint probability distribution is a probability distribution over more than one feature assignment and is written as a multidimensional matrix in which each cell lists the probability of a particular combination of feature values being assigned.",
            "zh": "è”åˆæ¦‚ç‡åˆ†å¸ƒæ˜¯å¤šä¸ªç‰¹å¾åˆ†é…çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå†™æˆä¸€ä¸ªå¤šç»´çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸ªå•å…ƒæ ¼åˆ—å‡ºäº†åˆ†é…ç‰¹å¾å€¼çš„ç‰¹å®šç»„åˆçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "13. This approach is related to binning, as described in Section 3.6.2[89]. Simply binning continuous features to convert them into categorical features is another valid approach to handling continuous features in decision trees.",
            "zh": "13. è¿™ç§æ–¹æ³•ä¸åˆ†ç®±æœ‰å…³ï¼Œå¦‚ç¬¬ 3.6.2 èŠ‚æ‰€è¿°[89]ã€‚ç®€å•åœ°å°†è¿ç»­ç‰¹å¾è£…ç®±ä»¥å°†å®ƒä»¬è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾æ˜¯å¤„ç†å†³ç­–æ ‘ä¸­è¿ç»­ç‰¹å¾çš„å¦ä¸€ç§æœ‰æ•ˆæ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.11[278] lists this extended dataset.",
            "zh": "è¡¨6.11[278]åˆ—å‡ºäº†è¿™ä¸ªæ‰©å±•æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.2",
            "zh": "è¡¨ 8.2"
        }
    },
    {
        "translation": {
            "en": "12â€…â€…â€…Case Study: Customer Churn",
            "zh": "12 æ¡ˆä¾‹ç ”ç©¶ï¼šå®¢æˆ·æµå¤±"
        }
    },
    {
        "translation": {
            "en": "Outliers are values that lie far away from the central tendency of a feature.",
            "zh": "å¼‚å¸¸å€¼æ˜¯è¿œç¦»ç‰¹å¾ä¸­å¿ƒè¶‹åŠ¿çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For clarity of explanation, however, we have ignored these in this discussion of the fundamentals required to understand the approaches to reinforcement learning that are discussed in this chapter.",
            "zh": "ç„¶è€Œï¼Œä¸ºäº†æ¸…æ¥šè§£é‡Šï¼Œæˆ‘ä»¬åœ¨è®¨è®ºç†è§£æœ¬ç« è®¨è®ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ‰€éœ€çš„åŸºç¡€çŸ¥è¯†æ—¶å¿½ç•¥äº†è¿™äº›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Designing ABTs that properly represent the characteristics of a prediction subject is a key skill for analytics practitioners.",
            "zh": "è®¾è®¡æ­£ç¡®è¡¨ç¤ºé¢„æµ‹ä¸»ä½“ç‰¹å¾çš„ ABT æ˜¯åˆ†æä»ä¸šè€…çš„ä¸€é¡¹å…³é”®æŠ€èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn suggested that she would first work on the coarse classification of galaxies into elliptical and spiral categories, and then, depending on how this model performed, look at classifying spirals into the more fine-grained categories.",
            "zh": "Jocelynå»ºè®®å¥¹é¦–å…ˆå°†æ˜Ÿç³»ç²—ç•¥åœ°åˆ†ç±»ä¸ºæ¤­åœ†æ˜Ÿç³»å’Œèºæ—‹æ˜Ÿç³»ï¼Œç„¶åæ ¹æ®è¯¥æ¨¡å‹çš„è¡¨ç°ï¼Œå°†æ˜Ÿç³»åˆ†ç±»ä¸ºæ›´ç»†ç²’åº¦çš„ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The ensemble contains 11 independent models, all of which have an error rate of 0.2.",
            "zh": "ï¼ˆaï¼‰ è¯¥é›†åˆåŒ…å«11ä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹çš„é”™è¯¯ç‡ä¸º0.2ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these stacked feature map inputs, each channel then encodes the information from a particular filter spectrum (for example, the information from the horizontal edge detector filter spectrum) instead of encoding the information in a particular color spectrum (Charniak, 2019).",
            "zh": "åœ¨è¿™äº›å †å çš„ç‰¹å¾å›¾è¾“å…¥ä¸­ï¼Œæ¯ä¸ªé€šé“ç„¶åå¯¹æ¥è‡ªç‰¹å®šæ»¤æ³¢å™¨å…‰è°±çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ªæ°´å¹³è¾¹ç¼˜æ£€æµ‹å™¨æ»¤æ³¢å™¨å…‰è°±çš„ä¿¡æ¯ï¼‰è¿›è¡Œç¼–ç ï¼Œè€Œä¸æ˜¯å¯¹ç‰¹å®šè‰²è°±ä¸­çš„ä¿¡æ¯è¿›è¡Œç¼–ç ï¼ˆCharniakï¼Œ2019ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A derived feature containing the ratio between the claim amount and the total value of the premiums paid to date on the policy is included.",
            "zh": "åŒ…æ‹¬ä¸€ä¸ªæ´¾ç”Ÿç‰¹å¾ï¼Œå…¶ä¸­åŒ…å«ç´¢èµ”é‡‘é¢ä¸ä¿å•è¿„ä»Šä¸ºæ­¢å·²æ”¯ä»˜çš„ä¿è´¹æ€»ä»·å€¼ä¹‹é—´çš„æ¯”ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "false positive rate, 548",
            "zh": "è¯¯æŠ¥ç‡ï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "This is the partial derivative of the error surface with respect to a particular weight w[j] and indicates the gradient of the error surface. Using this formulation for the gradient, we can write the weight update rule for logistic regression as",
            "zh": "è¿™æ˜¯è¯¯å·®æ›²é¢ç›¸å¯¹äºç‰¹å®šæƒé‡ w[j] çš„åå¯¼æ•°ï¼Œè¡¨ç¤ºè¯¯å·®æ›²é¢çš„æ¢¯åº¦ã€‚ä½¿ç”¨è¿™ä¸ªæ¢¯åº¦å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å°†é€»è¾‘å›å½’çš„æƒé‡æ›´æ–°è§„åˆ™å†™ä¸º"
        }
    },
    {
        "translation": {
            "en": "0.62",
            "zh": "0.62"
        }
    },
    {
        "translation": {
            "en": "There are two important observations regarding the division in Bayesâ€™ Theorem by the denominator P(Y). The first is that this division functions as a normalization mechanism ensuring that",
            "zh": "å…³äºè´å¶æ–¯å®šç†ä¸­åˆ†æ¯ Pï¼ˆYï¼‰ çš„é™¤æ³•æœ‰ä¸¤ä¸ªé‡è¦çš„è§‚å¯Ÿç»“æœã€‚é¦–å…ˆï¼Œè¿™ç§åˆ’åˆ†ä½œä¸ºä¸€ç§è§„èŒƒåŒ–æœºåˆ¶ï¼Œç¡®ä¿"
        }
    },
    {
        "translation": {
            "en": "Chapter 3[53]",
            "zh": "ç¬¬3ç« [53]"
        }
    },
    {
        "translation": {
            "en": "4.2.2â€…â€…â€…Shannonâ€™s Entropy Model",
            "zh": "4.2.2 é¦™å†œç†µæ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "0.120800",
            "zh": "0.120800"
        }
    },
    {
        "translation": {
            "en": "BLANDCHROMATIN: A measure of the texture of cell nuclei (1 to 10).",
            "zh": "BLANDCHROMATINï¼šç»†èƒæ ¸è´¨åœ°çš„é‡åº¦ï¼ˆ1 åˆ° 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The actual process for determining domain concepts is essentially one of knowledge elicitationâ€”attempting to extract from domain experts the knowledge about the scenario we are trying to model. Often, this process will take place across multiple meetings, involving the analytics and domain experts, where the set of relevant domain concepts for the analytics solution are developed and refined.",
            "zh": "ç¡®å®šé¢†åŸŸæ¦‚å¿µçš„å®é™…è¿‡ç¨‹æœ¬è´¨ä¸Šæ˜¯çŸ¥è¯†è·å–çš„è¿‡ç¨‹ä¹‹ä¸€ï¼Œå³è¯•å›¾ä»é¢†åŸŸä¸“å®¶é‚£é‡Œæå–æœ‰å…³æˆ‘ä»¬è¯•å›¾å»ºæ¨¡çš„åœºæ™¯çš„çŸ¥è¯†ã€‚é€šå¸¸ï¼Œæ­¤è¿‡ç¨‹å°†åœ¨å¤šä¸ªä¼šè®®ä¸­è¿›è¡Œï¼Œæ¶‰åŠåˆ†æå’Œé¢†åŸŸä¸“å®¶ï¼Œåœ¨è¿™äº›ä¼šè®®ä¸­ï¼Œåˆ†æè§£å†³æ–¹æ¡ˆçš„ç›¸å…³é¢†åŸŸæ¦‚å¿µé›†è¢«å¼€å‘å’Œå®Œå–„ã€‚"
        }
    },
    {
        "translation": {
            "en": "It turns out that these slightly larger weight values can dramatically affect the internal dynamics of the network during training.",
            "zh": "äº‹å®è¯æ˜ï¼Œè¿™äº›ç¨å¤§çš„æƒé‡å€¼å¯ä»¥æå¤§åœ°å½±å“è®­ç»ƒæœŸé—´ç½‘ç»œçš„å†…éƒ¨åŠ¨æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "weight update rule, 327, 403",
            "zh": "é‡é‡æ›´æ–°è§„åˆ™ï¼Œ327,403"
        }
    },
    {
        "translation": {
            "en": "The prediction model that we would build using this data would be deployed to predict whether newly arising claims are likely to be fraudulent.",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›æ•°æ®æ„å»ºçš„é¢„æµ‹æ¨¡å‹å°†ç”¨äºé¢„æµ‹æ–°å‡ºç°çš„ç´¢èµ”æ˜¯å¦å¯èƒ½æ˜¯æ¬ºè¯ˆæ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The maximum entropy for sets with three elements is 1.58 and occurs when there are equal numbers of each type in the set, as is the case shown in Figure 4.5(e)[124].",
            "zh": "å…·æœ‰ä¸‰ä¸ªå…ƒç´ çš„é›†åˆçš„æœ€å¤§ç†µä¸º1.58ï¼Œå½“é›†åˆä¸­æ¯ç§ç±»å‹çš„æ•°é‡ç›¸ç­‰æ—¶ï¼Œå°±ä¼šå‘ç”Ÿï¼Œå¦‚å›¾4.5ï¼ˆeï¼‰æ‰€ç¤º[124]ã€‚"
        }
    },
    {
        "translation": {
            "en": "For support vector machines, we first set the negative target feature level to âˆ’ 1 and the positive target feature level to + 1. We then build a support vector machine prediction model so that instances with the negative target level result in the model outputting â‰¤âˆ’1 and instances with the positive target level result in the model outputting â‰¥ +1. The space between the outputs of âˆ’ 1 and + 1 allows for the margin.",
            "zh": "å¯¹äºæ”¯æŒå‘é‡æœºï¼Œæˆ‘ä»¬é¦–å…ˆå°†è´Ÿç›®æ ‡ç‰¹å¾çº§åˆ«è®¾ç½®ä¸º âˆ’ 1ï¼Œå°†æ­£ç›®æ ‡ç‰¹å¾çº§åˆ«è®¾ç½®ä¸º + 1ã€‚ç„¶åï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ”¯æŒå‘é‡æœºé¢„æµ‹æ¨¡å‹ï¼Œä»¥ä¾¿å…·æœ‰è´Ÿç›®æ ‡æ°´å¹³çš„å®ä¾‹å¯¼è‡´æ¨¡å‹è¾“å‡º â‰¤âˆ’1ï¼Œå…·æœ‰æ­£ç›®æ ‡æ°´å¹³çš„å®ä¾‹å¯¼è‡´æ¨¡å‹è¾“å‡ºâ‰¥ +1ã€‚âˆ’ 1 å’Œ + 1 è¾“å‡ºä¹‹é—´çš„ç©ºé—´å…è®¸è£•é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.9(a)[287] illustrates a simple Bayesian network. This network describes a domain consisting of two features A and B. The directed link from A to B indicates that the value of A directly influences the value of B. In probability terms, the directed edge from A to B in Figure 6.9(a)[287] states that",
            "zh": "å›¾6.9ï¼ˆaï¼‰[287]è¯´æ˜äº†ä¸€ä¸ªç®€å•çš„è´å¶æ–¯ç½‘ç»œã€‚è¯¥ç½‘ç»œæè¿°äº†ç”±ä¸¤ä¸ªç‰¹å¾ A å’Œ B ç»„æˆçš„åŸŸã€‚ä» A åˆ° B çš„å®šå‘é“¾æ¥è¡¨æ˜ A çš„å€¼ç›´æ¥å½±å“ B çš„å€¼ã€‚ä»æ¦‚ç‡çš„è§’åº¦æ¥çœ‹ï¼Œå›¾6.9ï¼ˆaï¼‰[287]ä¸­ä»Aåˆ°Bçš„æœ‰å‘è¾¹è¡¨ç¤º"
        }
    },
    {
        "translation": {
            "en": "To further support his model, Ross organized a control group test (see Section 9.4.6[578]) in which for two months, the AT customer base was randomly divided into two groups, and call lists for the retention team were selected from the first group using the old approach based on calls to customer care, and for the second group using the new decision tree model.",
            "zh": "ä¸ºäº†è¿›ä¸€æ­¥æ”¯æŒä»–çš„æ¨¡å‹ï¼ŒRoss ç»„ç»‡äº†ä¸€ä¸ªå¯¹ç…§ç»„æµ‹è¯•ï¼ˆå‚è§ç¬¬ 9.4.6 èŠ‚ [578]ï¼‰ï¼Œåœ¨ä¸¤ä¸ªæœˆçš„æ—¶é—´é‡Œï¼ŒAT å®¢æˆ·ç¾¤è¢«éšæœºåˆ†ä¸ºä¸¤ç»„ï¼Œä¿ç•™å›¢é˜Ÿçš„å‘¼å«åˆ—è¡¨ä½¿ç”¨åŸºäºå®¢æˆ·æœåŠ¡å‘¼å«çš„æ—§æ–¹æ³•ä»ç¬¬ä¸€ç»„ä¸­é€‰æ‹©ï¼Œç¬¬äºŒç»„ä½¿ç”¨æ–°çš„å†³ç­–æ ‘æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout the discussion in the previous sections about central tendency and variation, we consistently used the word sample to refer to the set of values in an ABT for a particular feature.",
            "zh": "åœ¨å‰å‡ èŠ‚ä¸­å…³äºé›†ä¸­è¶‹åŠ¿å’Œå˜åŒ–çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´ä½¿ç”¨â€œæ ·æœ¬â€ä¸€è¯æ¥æŒ‡ä»£ ABT ä¸­ç‰¹å®šç‰¹å¾çš„å€¼é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.3â€…â€…â€…Features from the ABT for the SDSS galaxy classification problem.",
            "zh": "13.3 ABTä¸­å…³äºSDSSæ˜Ÿç³»åˆ†ç±»é—®é¢˜çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To show how boosting works in practice, we use a modified version of the bike rentals dataset used in Section 4.4.3[149].",
            "zh": "ä¸ºäº†å±•ç¤ºæå‡åœ¨å®è·µä¸­çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç¬¬ 4.4.3 èŠ‚[149] ä¸­ä½¿ç”¨çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†çš„ä¿®æ”¹ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that we are dealing with vectors of gradients, and so for each layer we will do an elementwise product with a vector of activation function derivatives; also, the derivatives of the activation functions are dependent on whether the neurons in the layer are using a sigmoid or tanh function.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬æ­£åœ¨å¤„ç†æ¢¯åº¦å‘é‡ï¼Œå› æ­¤å¯¹äºæ¯ä¸€å±‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¿€æ´»å‡½æ•°å¯¼æ•°çš„å‘é‡è¿›è¡Œé€å…ƒç´ ä¹˜ç§¯;æ­¤å¤–ï¼Œæ¿€æ´»å‡½æ•°çš„å¯¼æ•°å–å†³äºè¯¥å±‚ä¸­çš„ç¥ç»å…ƒæ˜¯ä½¿ç”¨ S å½¢ç»“è‚ è¿˜æ˜¯ tanh å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second term in the product, âˆ‚a i/âˆ‚Î»i, is the gradient of the activation function with respect to changes in Î»i.",
            "zh": "ä¹˜ç§¯ä¸­çš„ç¬¬äºŒé¡¹ âˆ‚a i/âˆ‚Î»i æ˜¯æ¿€æ´»å‡½æ•°ç›¸å¯¹äº Î»i å˜åŒ–çš„æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation 8.52[449] shows the last line from Equation 8.41[436] and is annotated to explain how extreme weights can make gradients unstable.",
            "zh": "ç­‰å¼ 8.52[449] æ˜¾ç¤ºäº†ç­‰å¼ 8.41[436] çš„æœ€åä¸€è¡Œï¼Œå¹¶è¿›è¡Œäº†æ³¨é‡Šä»¥è§£é‡Šæç«¯æƒé‡å¦‚ä½•ä½¿æ¢¯åº¦ä¸ç¨³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Different models offer different levels of explanation capacity and therefore different levels of interpretability.",
            "zh": "ä¸åŒçš„æ¨¡å‹æä¾›ä¸åŒç¨‹åº¦çš„è§£é‡Šèƒ½åŠ›ï¼Œå› æ­¤æä¾›ä¸åŒç¨‹åº¦çš„å¯è§£é‡Šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapter 8 is a new chapter on deep learning that covers the fundamentals of artificial neural networks as well as the most important network architectures used in modern machine learning applications for images, language, and more. This brings the book right up to date with the most recent developments in machine learning.",
            "zh": "ç¬¬ 8 ç« æ˜¯å…³äºæ·±åº¦å­¦ä¹ çš„æ–°ç« èŠ‚ï¼Œæ¶µç›–äº†äººå·¥ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†ä»¥åŠç°ä»£æœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„æœ€é‡è¦çš„ç½‘ç»œæ¶æ„ï¼Œç”¨äºå›¾åƒã€è¯­è¨€ç­‰ã€‚è¿™ä½¿æœ¬ä¹¦ä¸æœºå™¨å­¦ä¹ çš„æœ€æ–°å‘å±•ä¿æŒåŒæ­¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "We now have the two terms we need to calculate Î´8, and Equation 8.32[427] steps through the calculation of Î´8 for d2.",
            "zh": "æˆ‘ä»¬ç°åœ¨æœ‰äº†è®¡ç®— Î´8 æ‰€éœ€çš„ä¸¤ä¸ªé¡¹ï¼Œæ–¹ç¨‹ 8.32[427] é€æ­¥è®¡ç®—äº† d2 çš„ Î´8ã€‚"
        }
    },
    {
        "translation": {
            "en": "19. For example, there might be errors in the target feature or descriptive feature values of one or more of the training instances.",
            "zh": "19. ä¾‹å¦‚ï¼Œä¸€ä¸ªæˆ–å¤šä¸ªè®­ç»ƒå®ä¾‹çš„ç›®æ ‡ç‰¹å¾æˆ–æè¿°æ€§ç‰¹å¾å€¼å¯èƒ½å­˜åœ¨é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once again he went to the kitchen to inspect and agreed that Amalia had also done a great job of organizing the letters.",
            "zh": "ä»–åˆä¸€æ¬¡å»å¨æˆ¿æ£€æŸ¥ï¼Œå¹¶åŒæ„é˜¿ç›åˆ©äºšåœ¨æ•´ç†ä¿¡ä»¶æ–¹é¢ä¹Ÿåšå¾—å¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each element in a vector is identified by a single index. For example:",
            "zh": "å‘é‡ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½ç”±å•ä¸ªç´¢å¼•æ ‡è¯†ã€‚ä¾‹å¦‚ï¼š"
        }
    },
    {
        "translation": {
            "en": "(a) A 3D plot of an error surface and (b) a birdâ€™s-eye view contour plot of the same error surface. The lines indicate the path that the gradient descent algorithm would take across this error surface from four different starting positions to the global minimumâ€”marked as the white dot in the center.",
            "zh": "ï¼ˆaï¼‰ è¯¯å·®é¢çš„ 3D å›¾å’Œ ï¼ˆbï¼‰ åŒä¸€è¯¯å·®é¢çš„é¸Ÿç°ç­‰å€¼çº¿å›¾ã€‚è¿™äº›çº¿è¡¨ç¤ºæ¢¯åº¦ä¸‹é™ç®—æ³•ä»å››ä¸ªä¸åŒçš„èµ·å§‹ä½ç½®åˆ°å…¨å±€æœ€å°å€¼ï¼ˆæ ‡è®°ä¸ºä¸­å¿ƒçš„ç™½ç‚¹ï¼‰ç©¿è¿‡æ­¤è¯¯å·®è¡¨é¢çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 3.6.1[87] we discussed variance and introduced a number of normalization techniques that normalize the variances in a set of features.",
            "zh": "åœ¨ç¬¬ 3.6.1 èŠ‚[87]ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†æ–¹å·®ï¼Œå¹¶ä»‹ç»äº†ä¸€äº›å½’ä¸€åŒ–æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯å¯ä»¥å½’ä¸€åŒ–ä¸€ç»„ç‰¹å¾ä¸­çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, it is because deep learning models are inspired by the human brain that they are known as artificial neural networks: they are designed (at least at a very abstract level) to mirror the structure of the brain, and the adoption of a learning mechanism based on adjusting the connections between neurons can be understood as mimicking Hebbâ€™s theory of how the brain learns.",
            "zh": "ç„¶è€Œï¼Œæ­£æ˜¯å› ä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹å—åˆ°äººè„‘çš„å¯å‘ï¼Œå®ƒä»¬æ‰è¢«ç§°ä¸ºäººå·¥ç¥ç»ç½‘ç»œï¼šå®ƒä»¬è¢«è®¾è®¡ï¼ˆè‡³å°‘åœ¨éå¸¸æŠ½è±¡çš„å±‚é¢ä¸Šï¼‰æ¥åæ˜ å¤§è„‘çš„ç»“æ„ï¼Œå¹¶ä¸”é‡‡ç”¨åŸºäºè°ƒæ•´ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„å­¦ä¹ æœºåˆ¶å¯ä»¥ç†è§£ä¸ºæ¨¡ä»¿Hebbçš„å¤§è„‘å¦‚ä½•å­¦ä¹ çš„ç†è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Illustration of the robustness of the student-t distribution to outliers: (a) a density histogram of a unimodal dataset overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data; and (b) a density histogram of the same dataset with outliers added, overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data. (This figure is inspired by Figure 2.16 in Bishop (2006).)",
            "zh": "å­¦ç”Ÿ t åˆ†å¸ƒå¯¹å¼‚å¸¸å€¼çš„é²æ£’æ€§è¯´æ˜ï¼šï¼ˆaï¼‰ å•å³°æ•°æ®é›†çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œå åŠ äº†å·²æ‹Ÿåˆåˆ°æ•°æ®çš„æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ t åˆ†å¸ƒçš„å¯†åº¦æ›²çº¿;ï¼ˆbï¼‰æ·»åŠ äº†å¼‚å¸¸å€¼çš„åŒä¸€æ•°æ®é›†çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œä¸å·²æ‹Ÿåˆåˆ°æ•°æ®çš„æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ-tåˆ†å¸ƒçš„å¯†åº¦æ›²çº¿å åŠ ã€‚ï¼ˆè¿™ä¸ªæ•°å­—çš„çµæ„Ÿæ¥è‡ªBishop ï¼ˆ2006ï¼‰ä¸­çš„å›¾2.16ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examining the INCOME row in the data quality report also shows a large difference between the mean and median values, which is unusual.",
            "zh": "æ£€æŸ¥æ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„ INCOME è¡Œè¿˜æ˜¾ç¤ºå¹³å‡å€¼å’Œä¸­ä½æ•°ä¹‹é—´å­˜åœ¨å¾ˆå¤§å·®å¼‚ï¼Œè¿™æ˜¯ä¸å¯»å¸¸çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. When using the reciprocal of the squared distance as a weighting function, we need to be careful to avoid division by zero in the case in which the query is exactly the same as its nearest neighbor. Typically this problem case is handled by assigning the query the target level of the training instance d that it exactly matches.",
            "zh": "6. å½“ä½¿ç”¨å¹³æ–¹è·ç¦»çš„å€’æ•°ä½œä¸ºåŠ æƒå‡½æ•°æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ³¨æ„é¿å…åœ¨æŸ¥è¯¢ä¸å…¶æœ€è¿‘é‚»å®Œå…¨ç›¸åŒçš„æƒ…å†µä¸‹é™¤ä»¥é›¶ã€‚é€šå¸¸ï¼Œæ­¤é—®é¢˜æ¡ˆä¾‹æ˜¯é€šè¿‡ä¸ºæŸ¥è¯¢åˆ†é…å®Œå…¨åŒ¹é…çš„è®­ç»ƒå®ä¾‹ d çš„ç›®æ ‡çº§åˆ«æ¥å¤„ç†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the images in the top row shows a feature space defined by two continuous descriptive features, F1 and F2, partitioned into good and bad regions by three different, artificially created decision boundaries.3 In the subsequent images, we show the decision boundaries that are learned by four different machine learning algorithms based on training datasets generated according to the decision boundaries shown in the top row.",
            "zh": "é¡¶è¡Œä¸­çš„æ¯å¼ å›¾åƒéƒ½æ˜¾ç¤ºäº†ä¸€ä¸ªç”±ä¸¤ä¸ªè¿ç»­æè¿°æ€§ç‰¹å¾ F1 å’Œ F2 å®šä¹‰çš„ç‰¹å¾ç©ºé—´ï¼Œç”±ä¸‰ä¸ªä¸åŒçš„ã€äººå·¥åˆ›å»ºçš„å†³ç­–è¾¹ç•Œåˆ’åˆ†ä¸ºå¥½åŒºåŸŸå’ŒååŒºåŸŸ.3 åœ¨éšåçš„å›¾åƒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç”±å››ç§ä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•æ ¹æ®æ ¹æ®é¡¶è¡Œæ‰€ç¤ºçš„å†³ç­–è¾¹ç•Œç”Ÿæˆçš„è®­ç»ƒæ•°æ®é›†å­¦ä¹ çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "3.11â€…â€…â€…A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73] with correlation coefficients included.",
            "zh": "3.11 ä¸€ä¸ªæ•£ç‚¹å›¾çŸ©é˜µï¼Œæ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼ŒåŒ…æ‹¬ç›¸å…³ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.6â€…â€…â€…A dataset listing features for a number of generators.",
            "zh": "7.6 åˆ—å‡ºè®¸å¤šç”Ÿæˆå™¨ç‰¹å¾çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.19",
            "zh": "è¡¨ 9.19"
        }
    },
    {
        "translation": {
            "en": "Mac Namee (2009) provides an overview of the dominant approaches in using intelligent agent systems in games and entertainment applications.",
            "zh": "Mac Nameeï¼ˆ2009ï¼‰æ¦‚è¿°äº†åœ¨æ¸¸æˆå’Œå¨±ä¹åº”ç”¨ä¸­ä½¿ç”¨æ™ºèƒ½ä»£ç†ç³»ç»Ÿçš„ä¸»è¦æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "OCCUPATION",
            "zh": "èŒä¸š"
        }
    },
    {
        "translation": {
            "en": "A.4â€…â€…The members of the rival school basketball team from Figure A.3[747] ordered by height.",
            "zh": "A.4 å›¾A.3[747]ä¸­å¯¹æ‰‹å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜æŒ‰èº«é«˜æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "density histogram, 753",
            "zh": "å¯†åº¦ç›´æ–¹å›¾ï¼Œ753"
        }
    },
    {
        "translation": {
            "en": "11.2.3â€ƒMarkov Decision Processes",
            "zh": "11.2.3 é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹"
        }
    },
    {
        "translation": {
            "en": "We are delighted to take this opportunity to acknowledge these contributions to the book.",
            "zh": "æˆ‘ä»¬å¾ˆé«˜å…´å€Ÿæ­¤æœºä¼šæ„Ÿè°¢è¿™äº›å¯¹æœ¬ä¹¦çš„è´¡çŒ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, we should use ELEVATION â‰¥ 4,175 as the test at the root node of the tree, as shown in Figure 4.13[149].",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨ ELEVATION â‰¥ 4,175 ä½œä¸ºæ ‘æ ¹èŠ‚ç‚¹çš„æµ‹è¯•ï¼Œå¦‚å›¾ 4.13[149] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "12.2â€…â€…â€…A data quality report for the Acme Telephonica ABT.",
            "zh": "12.2 Acme Telephonica ABTçš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Traditionally, the most frequent heuristic used to initialize the weights of a neural network was randomly sampling values from a normal or uniform distribution with a mean of 0.",
            "zh": "ä¼ ç»Ÿä¸Šï¼Œç”¨äºåˆå§‹åŒ–ç¥ç»ç½‘ç»œæƒé‡çš„æœ€å¸¸è§å¯å‘å¼æ–¹æ³•æ˜¯ä»å‡å€¼ä¸º 0 çš„æ­£æ€åˆ†å¸ƒæˆ–å‡åŒ€åˆ†å¸ƒä¸­éšæœºæŠ½æ ·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first part of this chapter we present an approach to developing analytics solutions that address specific business problems.",
            "zh": "åœ¨æœ¬ç« çš„ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€ç§å¼€å‘è§£å†³ç‰¹å®šä¸šåŠ¡é—®é¢˜çš„åˆ†æè§£å†³æ–¹æ¡ˆçš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "stratified sampling, 93, 710",
            "zh": "åˆ†å±‚æŠ½æ ·ï¼Œ 93ï¼Œ 710"
        }
    },
    {
        "translation": {
            "en": "The model shown in Equation (7.2)[313] is defined by the weights w[0] = 6.47 and w[1] = 0.62.",
            "zh": "å…¬å¼ï¼ˆ7.2ï¼‰[313]ä¸­æ‰€ç¤ºçš„æ¨¡å‹ç”±æƒé‡w[0] = 6.47å’Œw[1] = 0.62å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dynamics of an environment in which an agent transitions between states, a Markov process, can be captured in a transition matrix",
            "zh": "æ™ºèƒ½ä½“åœ¨çŠ¶æ€ä¹‹é—´è½¬æ¢çš„ç¯å¢ƒï¼ˆé©¬å°”å¯å¤«è¿‡ç¨‹ï¼‰çš„åŠ¨æ€å¯ä»¥åœ¨è½¬æ¢çŸ©é˜µä¸­æ•è·"
        }
    },
    {
        "translation": {
            "en": "neural network, 369, 381, 383, 599, 624, 629, 669, 735",
            "zh": "ç¥ç»ç½‘ç»œï¼Œ 369ï¼Œ 381ï¼Œ 383ï¼Œ 599ï¼Œ 624ï¼Œ 629ï¼Œ 669ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "Often states and actions are explicitly named, in which case we use the following formatting: STATE and action.",
            "zh": "é€šå¸¸ï¼ŒçŠ¶æ€å’Œæ“ä½œæ˜¯æ˜¾å¼å‘½åçš„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼šSTATE å’Œ actionã€‚"
        }
    },
    {
        "translation": {
            "en": "Post-pruning is an alternative approach to tree pruning in which the tree induction algorithm is allowed to grow a tree to completion, and then each branch on the tree is examined in turn.",
            "zh": "ä¿®å‰ªåæ˜¯æ ‘æœ¨ä¿®å‰ªçš„å¦ä¸€ç§æ–¹æ³•ï¼Œå…¶ä¸­å…è®¸æ ‘æœ¨è¯±å¯¼ç®—æ³•å°†ä¸€æ£µæ ‘ç”Ÿé•¿åˆ°å®Œæˆï¼Œç„¶åä¾æ¬¡æ£€æŸ¥æ ‘ä¸Šçš„æ¯ä¸ªåˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7",
            "zh": "å›¾ 5.7"
        }
    },
    {
        "translation": {
            "en": "Doctors could use the outputs of such a system to help them make better dosing decisions.21 The mean squared error for the multivariable linear regression model is 1.905 and for the k-NN model is 4.394.",
            "zh": "21 å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„å‡æ–¹è¯¯å·®ä¸º 1.905ï¼Œk-NN æ¨¡å‹çš„å‡æ–¹è¯¯å·®ä¸º 4.394ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the confusion matrices shown in Tables 9.5[551] and 9.6[551] show the performance of two different models on a test dataset that relates to a prediction problem in which we would like to predict whether a customer will churn or not.",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨ 9.5[551] å’Œ 9.6[551] ä¸­æ‰€ç¤ºçš„æ··æ·†çŸ©é˜µæ˜¾ç¤ºäº†ä¸¤ä¸ªä¸åŒæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œè¿™äº›æ¨¡å‹ä¸é¢„æµ‹é—®é¢˜æœ‰å…³ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¯¥é—®é¢˜ä¸­é¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šæµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "The time horizon for which data is available. It is important that the data available covers the period required for the analytics solution. For example, in an online gaming scenario, it might be possible to find out every customerâ€™s account balance today but utterly impossible to find out what their balance was last month, or even yesterday.",
            "zh": "æ•°æ®å¯ç”¨çš„æ—¶é—´èŒƒå›´ã€‚é‡è¦çš„æ˜¯ï¼Œå¯ç”¨æ•°æ®å¿…é¡»æ¶µç›–åˆ†æè§£å†³æ–¹æ¡ˆæ‰€éœ€çš„æ—¶é—´æ®µã€‚ä¾‹å¦‚ï¼Œåœ¨åœ¨çº¿æ¸¸æˆåœºæ™¯ä¸­ï¼Œä»Šå¤©å¯èƒ½å¯ä»¥æ‰¾åˆ°æ¯ä¸ªå®¢æˆ·çš„è´¦æˆ·ä½™é¢ï¼Œä½†å®Œå…¨ä¸å¯èƒ½æ‰¾å‡ºä»–ä»¬ä¸Šä¸ªæœˆç”šè‡³æ˜¨å¤©çš„ä½™é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.09",
            "zh": "3.09"
        }
    },
    {
        "translation": {
            "en": "Figure 2.9[43] shows these descriptive features in a portion of the domain concept diagram.",
            "zh": "å›¾ 2.9[43] åœ¨é¢†åŸŸæ¦‚å¿µå›¾çš„ä¸€éƒ¨åˆ†ä¸­æ˜¾ç¤ºäº†è¿™äº›æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The churn model replaced the random selection of customers by assigning every customer in the companyâ€™s customer base a churn risk score and selecting the 1,000 customers with the highest churn risk scores to receive a call from the customer contact center.",
            "zh": "å®¢æˆ·æµå¤±æ¨¡å‹å–ä»£äº†éšæœºé€‰æ‹©å®¢æˆ·ï¼Œæ–¹æ³•æ˜¯ä¸ºå…¬å¸å®¢æˆ·ç¾¤ä¸­çš„æ¯ä¸ªå®¢æˆ·åˆ†é…ä¸€ä¸ªå®¢æˆ·æµå¤±é£é™©è¯„åˆ†ï¼Œå¹¶é€‰æ‹©æµå¤±é£é™©è¯„åˆ†æœ€é«˜çš„ 1,000 åå®¢æˆ·æ¥æ¥å¬æ¥è‡ªå®¢æˆ·è”ç»œä¸­å¿ƒçš„ç”µè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Grace had played a significant role in developing the process that had made information about customer support contacts available to the customer retention team.",
            "zh": "Grace åœ¨å¼€å‘æµç¨‹æ–¹é¢å‘æŒ¥äº†é‡è¦ä½œç”¨ï¼Œè¯¥æµç¨‹å‘å®¢æˆ·ä¿ç•™å›¢é˜Ÿæä¾›æœ‰å…³å®¢æˆ·æ”¯æŒè”ç³»äººçš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, there are now as many neurons in the grid as there are valid pixels in the image.",
            "zh": "äº‹å®ä¸Šï¼Œç°åœ¨ç½‘æ ¼ä¸­çš„ç¥ç»å…ƒæ•°é‡ä¸å›¾åƒä¸­çš„æœ‰æ•ˆåƒç´ æ•°é‡ä¸€æ ·å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "centroid linkage: the distance between the centroids of two clusters is used as the overall distance between the clusters.",
            "zh": "è´¨å¿ƒè”åŠ¨ï¼šä¸¤ä¸ªç°‡çš„è´¨å¿ƒä¹‹é—´çš„è·ç¦»ä½œä¸ºç°‡ä¹‹é—´çš„æ€»è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 12.1",
            "zh": "å›¾ 12.1"
        }
    },
    {
        "translation": {
            "en": "8.2.4â€…â€…â€…Why Are Non-Linear Activation Functions Necessary?",
            "zh": "8.2.4 ä¸ºä»€ä¹ˆéœ€è¦éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "So, when you consider both the likelihood of an answer and how an answer splits up the domain of solutions, it becomes clear that an answer to Question 2 leaves you with more work to do to solve the game than an answer to Question 1.",
            "zh": "å› æ­¤ï¼Œå½“ä½ åŒæ—¶è€ƒè™‘ç­”æ¡ˆçš„å¯èƒ½æ€§ä»¥åŠç­”æ¡ˆå¦‚ä½•åˆ’åˆ†è§£å†³æ–¹æ¡ˆé¢†åŸŸæ—¶ï¼Œå¾ˆæ˜æ˜¾ï¼Œé—®é¢˜ 2 çš„ç­”æ¡ˆæ¯”é—®é¢˜ 1 çš„ç­”æ¡ˆè®©ä½ æœ‰æ›´å¤šçš„å·¥ä½œè¦åšæ¥è§£å†³æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "We backpropagate through the other elementwise products that occur in the forward pass within the LSTM using a similar strategy: in order to calculate the backpropagated error gradient for one input to a product, we multiply the error gradient for the result of the product by the other input to the product.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç±»ä¼¼çš„ç­–ç•¥åœ¨ LSTM ä¸­å‰å‘ä¼ é€’ä¸­å‡ºç°çš„å…¶ä»–é€å‘ä¹˜ç§¯è¿›è¡Œåå‘ä¼ æ’­ï¼šä¸ºäº†è®¡ç®—ä¹˜ç§¯çš„ä¸€ä¸ªè¾“å…¥çš„åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦ï¼Œæˆ‘ä»¬å°†ä¹˜ç§¯ç»“æœçš„è¯¯å·®æ¢¯åº¦ä¹˜ä»¥ä¹˜ç§¯çš„å¦ä¸€ä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes it is useful to talk about the probabilities for all the possible assignments to a feature.",
            "zh": "æœ‰æ—¶ï¼Œè®¨è®ºå¯¹ä¸€ä¸ªç‰¹å¾çš„æ‰€æœ‰å¯èƒ½èµ‹å€¼çš„æ¦‚ç‡æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each instance in a dataset is represented by a point on the plot determined by the values for that instance of the two features being plotted.",
            "zh": "æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½ç”±ç»˜å›¾ä¸Šçš„ä¸€ä¸ªç‚¹è¡¨ç¤ºï¼Œè¯¥ç‚¹ç”±æ­£åœ¨ç»˜åˆ¶çš„ä¸¤ä¸ªè¦ç´ çš„è¯¥å®ä¾‹çš„å€¼ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The most important tool used during data exploration is the data quality report.",
            "zh": "æ•°æ®æµè§ˆè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æœ€é‡è¦çš„å·¥å…·æ˜¯æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The conditional probability for an event given that we know another event is true is calculated by dividing the number of rows in the dataset where both events are true by the number of rows in the dataset where just the given event is true. For example, the conditional probability for the event DICE1 = given that DICE2 = would be calculated as",
            "zh": "å‡è®¾æˆ‘ä»¬çŸ¥é“å¦ä¸€ä¸ªäº‹ä»¶ä¸ºçœŸï¼Œåˆ™äº‹ä»¶çš„æ¡ä»¶æ¦‚ç‡æ˜¯é€šè¿‡å°†æ•°æ®é›†ä¸­ä¸¤ä¸ªäº‹ä»¶éƒ½ä¸ºçœŸçš„è¡Œæ•°é™¤ä»¥æ•°æ®é›†ä¸­ä»…ç»™å®šäº‹ä»¶ä¸ºçœŸçš„è¡Œæ•°æ¥è®¡ç®—çš„ã€‚ä¾‹å¦‚ï¼Œäº‹ä»¶ DICE1 = çš„æ¡ä»¶æ¦‚ç‡ DICE2 = çš„è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "32. These errors are often known as the model residuals.",
            "zh": "32. è¿™äº›è¯¯å·®é€šå¸¸ç§°ä¸ºæ¨¡å‹æ®‹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Table 10.1[604] the columns labeled Cluster Distances Iter.",
            "zh": "åœ¨è¡¨ 10.1[604] ä¸­ï¼Œæ ‡è®°ä¸º Cluster Distances Iter çš„åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "crowdsourcing, 708",
            "zh": "ä¼—åŒ…ï¼Œ708"
        }
    },
    {
        "translation": {
            "en": "The first step in creating an interior node is to decide which descriptive feature should be tested at this node (Line 8 of Algorithm 1[134]).",
            "zh": "åˆ›å»ºå†…éƒ¨èŠ‚ç‚¹çš„ç¬¬ä¸€æ­¥æ˜¯å†³å®šåº”åœ¨æ­¤èŠ‚ç‚¹ä¸Šæµ‹è¯•å“ªä¸ªæè¿°æ€§ç‰¹å¾ï¼ˆç®—æ³• 1 çš„ç¬¬ 8 è¡Œ[134]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second requirement is that the Markov chain used to generate the samples must be ergodic.",
            "zh": "ç¬¬äºŒä¸ªè¦æ±‚æ˜¯ç”¨äºç”Ÿæˆæ ·å“çš„é©¬å°”å¯å¤«é“¾å¿…é¡»æ˜¯éå†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A common business model for online services is to allow users a free trial period after which time they have to sign up to a paid account to continue using the service.",
            "zh": "åœ¨çº¿æœåŠ¡çš„ä¸€ç§å¸¸è§å•†ä¸šæ¨¡å¼æ˜¯å…è®¸ç”¨æˆ·å…è´¹è¯•ç”¨æœŸï¼Œä¹‹åä»–ä»¬å¿…é¡»æ³¨å†Œä»˜è´¹å¸æˆ·æ‰èƒ½ç»§ç»­ä½¿ç”¨è¯¥æœåŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM remains an appropriate process to follow, the approach to designing data representations based on domain concepts is still very useful, and the project flow presented in Section 2.5[44] is still appropriate.",
            "zh": "CRISP-DMä»ç„¶æ˜¯ä¸€ä¸ªåˆé€‚çš„è¿‡ç¨‹ï¼ŒåŸºäºé¢†åŸŸæ¦‚å¿µè®¾è®¡æ•°æ®è¡¨ç¤ºçš„æ–¹æ³•ä»ç„¶éå¸¸æœ‰ç”¨ï¼Œç¬¬2.5èŠ‚[44]ä¸­ä»‹ç»çš„é¡¹ç›®æµç¨‹ä»ç„¶é€‚ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of an imbalanced dataset, in which the different levels of the target featureâ€”in this case, churners and non-churnersâ€”are not equally represented in the data.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªä¸å¹³è¡¡æ•°æ®é›†çš„ç¤ºä¾‹ï¼Œå…¶ä¸­ç›®æ ‡è¦ç´ çš„ä¸åŒçº§åˆ«ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæµå¤±è€…å’Œéæµå¤±è€…ï¼‰åœ¨æ•°æ®ä¸­çš„è¡¨ç¤ºæ–¹å¼ä¸ç›¸ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "normalization constant, 251",
            "zh": "å½’ä¸€åŒ–å¸¸æ•°ï¼Œ251"
        }
    },
    {
        "translation": {
            "en": "We can measure the performance of a decision tree by presenting the instances in the validation to the decision tree and comparing the predictions made for these instances with the actual target feature values in the dataset.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†éªŒè¯ä¸­çš„å®ä¾‹å‘ˆç°ç»™å†³ç­–æ ‘å¹¶å°†å¯¹è¿™äº›å®ä¾‹æ‰€åšçš„é¢„æµ‹ä¸æ•°æ®é›†ä¸­çš„å®é™…ç›®æ ‡ç‰¹å¾å€¼è¿›è¡Œæ¯”è¾ƒæ¥è¡¡é‡å†³ç­–æ ‘çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that during the backward pass, error gradients will be multiplied by the Whh matrix multiple timesâ€”once for each time-step through which we backpropagate.",
            "zh": "åŸå› æ˜¯åœ¨å‘åä¼ é€’è¿‡ç¨‹ä¸­ï¼Œè¯¯å·®æ¢¯åº¦å°†å¤šæ¬¡ä¹˜ä»¥ Whh çŸ©é˜µâ€”â€”å¯¹äºæˆ‘ä»¬åå‘ä¼ æ’­çš„æ¯ä¸ªæ—¶é—´æ­¥é•¿ï¼Œä¸€æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4â€ƒExtensions and Variations",
            "zh": "11.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "In this instance, both possible predictions have a score of zero!",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸¤ç§å¯èƒ½çš„é¢„æµ‹çš„åˆ†æ•°å‡ä¸ºé›¶ï¼"
        }
    },
    {
        "translation": {
            "en": "So, here we define the minimum number of hidden layers necessary for a network to be considered deep as two; under this definition the network in shown Figure 8.4[390] would be described as a deep network.",
            "zh": "å› æ­¤ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç½‘ç»œè§†ä¸ºæ·±åº¦æ‰€éœ€çš„æœ€å°éšè—å±‚æ•°å®šä¹‰ä¸ºä¸¤ä¸ª;æ ¹æ®è¯¥å®šä¹‰ï¼Œå›¾8.4[390]ä¸­çš„ç½‘ç»œå°†è¢«æè¿°ä¸ºæ·±åº¦ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "balanced sample, 693",
            "zh": "å¹³è¡¡æ ·å“ï¼Œ693"
        }
    },
    {
        "translation": {
            "en": "Table 8.11",
            "zh": "è¡¨ 8.11"
        }
    },
    {
        "translation": {
            "en": "We have in fact already come across the weighted sum calculation in Chapter 7[311] when we defined the multivariate linear regression model (see Equation (7.9)[320]).",
            "zh": "äº‹å®ä¸Šï¼Œå½“æˆ‘ä»¬å®šä¹‰å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å·²ç»åœ¨ç¬¬ 7 ç« [311]ä¸­é‡åˆ°äº†åŠ æƒå’Œè®¡ç®—ï¼ˆå‚è§æ–¹ç¨‹ ï¼ˆ7.9ï¼‰[320]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "expectation, 652",
            "zh": "æœŸæœ›ï¼Œ652"
        }
    },
    {
        "translation": {
            "en": "An ABT for a predictive analytics solution contains a set of instances that are represented by a set of descriptive features and a target feature.",
            "zh": "é¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„ ABT åŒ…å«ä¸€ç»„å®ä¾‹ï¼Œè¿™äº›å®ä¾‹ç”±ä¸€ç»„æè¿°æ€§ç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡ç‰¹å¾è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating covariance.",
            "zh": "è®¡ç®—åæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vertical gaps between cluster linkages indicate the distance between the two clusters that have been merged.",
            "zh": "é›†ç¾¤é“¾æ¥ä¹‹é—´çš„å‚ç›´é—´éš™è¡¨ç¤ºå·²åˆå¹¶çš„ä¸¤ä¸ªé›†ç¾¤ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.8â€ƒFurther Reading",
            "zh": "3.8 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "Example bar plots for the POSITION feature in Table A.1[750]: (a) frequency bar plot, (b) density bar plot, and (c) order density bar plot.",
            "zh": "è¡¨A.1[750]ä¸­POSITIONç‰¹å¾çš„ç¤ºä¾‹æ¡å½¢å›¾ï¼šï¼ˆaï¼‰é¢‘ç‡æ¡å½¢å›¾ï¼Œï¼ˆbï¼‰å¯†åº¦æ¡å½¢å›¾å’Œï¼ˆcï¼‰é˜¶å¯†åº¦æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the ABT has to be created by combining a range of operational data sources together.",
            "zh": "ç›¸åï¼ŒABT å¿…é¡»é€šè¿‡å°†ä¸€ç³»åˆ—æ“ä½œæ•°æ®æºç»„åˆåœ¨ä¸€èµ·æ¥åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "5.1â€…â€…â€…Big Idea",
            "zh": "5.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "The average monthly bill amount",
            "zh": "å¹³å‡æ¯æœˆè´¦å•é‡‘é¢"
        }
    },
    {
        "translation": {
            "en": "In this instance, the error rate for the root node of this subtree (the STABLE-TEMP node) is 2, whereas the error rate of the leaf nodes of the tree is 0 + 0 = 0.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼Œæ­¤å­æ ‘çš„æ ¹èŠ‚ç‚¹ï¼ˆSTABLE-TEMP èŠ‚ç‚¹ï¼‰çš„é”™è¯¯ç‡ä¸º 2ï¼Œè€Œæ ‘çš„å¶èŠ‚ç‚¹çš„é”™è¯¯ç‡ä¸º 0 + 0 = 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we changed the threshold used to generate the predictions shown in Table 9.11[557] from 0.5 to 0.75, the predictions for instances d17, d8, and d6 would change from spam to ham, resulting in their outcomes changing to TN, FN, and FN respectively.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°†ç”¨äºç”Ÿæˆè¡¨ 9.11[557] ä¸­æ‰€ç¤ºé¢„æµ‹çš„é˜ˆå€¼ä» 0.5 æ›´æ”¹ä¸º 0.75ï¼Œåˆ™å®ä¾‹ d17ã€d8 å’Œ d6 çš„é¢„æµ‹å°†ä» spam æ›´æ”¹ä¸º hamï¼Œä»è€Œå¯¼è‡´å…¶ç»“æœåˆ†åˆ«æ›´æ”¹ä¸º TNã€FN å’Œ FNã€‚"
        }
    },
    {
        "translation": {
            "en": "To see the use of a profit matrix in action, consider a prediction problem in which a payday loan company has built a credit scoring model to predict the likelihood that a borrower will default on a loan.",
            "zh": "è¦äº†è§£åˆ©æ¶¦çŸ©é˜µçš„å®é™…ä½¿ç”¨ï¼Œè¯·è€ƒè™‘ä¸€ä¸ªé¢„æµ‹é—®é¢˜ï¼Œå…¶ä¸­å‘è–ªæ—¥è´·æ¬¾å…¬å¸å»ºç«‹äº†ä¸€ä¸ªä¿¡ç”¨è¯„åˆ†æ¨¡å‹æ¥é¢„æµ‹å€Ÿæ¬¾äººæ‹–æ¬ è´·æ¬¾çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity allows us to do this.",
            "zh": "ä½™å¼¦ç›¸ä¼¼æ€§å…è®¸æˆ‘ä»¬è¿™æ ·åšã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(c) Small multiple box plots (split by the target feature) of some of the features from the SDSS ABT.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ SDSS ABTä¸­æŸäº›ç‰¹å¾çš„å°å‹å¤šç®±å½¢å›¾ï¼ˆæŒ‰ç›®æ ‡ç‰¹å¾åˆ’åˆ†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bernstein, Peter L. 1996. Against the gods: The remarkable story of risk. Wiley.",
            "zh": "ä¼¯æ©æ–¯å¦ï¼Œå½¼å¾— L. 1996 å¹´ã€‚ä¸ä¼—ç¥å¯¹æŠ—ï¼šå…³äºé£é™©çš„éå‡¡æ•…äº‹ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Missing values",
            "zh": "ï¼ˆaï¼‰ ç¼ºå¤±å€¼"
        }
    },
    {
        "translation": {
            "en": "8.4â€ƒExtensions and Variations",
            "zh": "8.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "The predictions shown in Table 9.11[557] and in the confusion matrix in Table 9.3[539] are based on a prediction score threshold of 0.5.",
            "zh": "è¡¨9.11[557]å’Œè¡¨9.3[539]ä¸­çš„æ··æ·†çŸ©é˜µä¸­æ˜¾ç¤ºçš„é¢„æµ‹åŸºäº0.5çš„é¢„æµ‹åˆ†æ•°é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "ROC index, 558",
            "zh": "ä¸­åæ°‘å›½æŒ‡æ•°ï¼Œ558"
        }
    },
    {
        "translation": {
            "en": "This is happening because the salary values are much larger than the age values.",
            "zh": "å‘ç”Ÿè¿™ç§æƒ…å†µæ˜¯å› ä¸ºå·¥èµ„å€¼è¿œå¤§äºå¹´é¾„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, for prediction problems like those posed by the office rentals dataset, the associated error surfaces have two properties that help us find the optimal combination of weights: they are convex, and they have a global minimum.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œå¯¹äºåƒåŠå…¬å®¤ç§Ÿèµæ•°æ®é›†è¿™æ ·çš„é¢„æµ‹é—®é¢˜ï¼Œç›¸å…³çš„è¯¯å·®æ›²é¢æœ‰ä¸¤ä¸ªå±æ€§å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ‰¾åˆ°æƒé‡çš„æœ€ä½³ç»„åˆï¼šå®ƒä»¬æ˜¯å‡¸çš„ï¼Œå¹¶ä¸”å®ƒä»¬å…·æœ‰å…¨å±€æœ€å°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) Assuming that Q-learning is being used with Î± = 0.2 and Î³ = 0.9, update the entry in the action-value table for the action simulated in Part (c).",
            "zh": "ï¼ˆdï¼‰ å‡è®¾ Q å­¦ä¹ åœ¨ Î± = 0.2 å’Œ Î³ = 0.9 çš„æƒ…å†µä¸‹ä½¿ç”¨ï¼Œåˆ™æ›´æ–° ï¼ˆcï¼‰ éƒ¨åˆ†ä¸­æ¨¡æ‹Ÿçš„åŠ¨ä½œå€¼è¡¨ä¸­çš„æ¡ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "cardinality, 54, 54, 693",
            "zh": "åŸºæ•°ï¼Œ54,54,693"
        }
    },
    {
        "translation": {
            "en": "mode, 54, 69, 746, 749",
            "zh": "æ¨¡å¼ï¼Œ54ã€69ã€746ã€749"
        }
    },
    {
        "translation": {
            "en": "2.3â€…â€…â€…Designing the Analytics Base Table",
            "zh": "2.3 è®¾è®¡åˆ†æåŸºè¡¨"
        }
    },
    {
        "translation": {
            "en": "There is one case in which we might deal directly with missing values that arise from valid data during data exploration. If the proportion of missing values for a feature is very high, a good rule of thumb is anything in excess of 60%, then the amount of information stored in the feature is so low that it is probably a good idea to simply remove that feature from the ABT.",
            "zh": "åœ¨ä¸€ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å¤„ç†åœ¨æ•°æ®æ¢ç´¢è¿‡ç¨‹ä¸­ç”±æœ‰æ•ˆæ•°æ®äº§ç”Ÿçš„ç¼ºå¤±å€¼ã€‚å¦‚æœæŸä¸ªç‰¹å¾çš„ç¼ºå¤±å€¼æ¯”ä¾‹éå¸¸é«˜ï¼Œä¸€ä¸ªå¥½çš„ç»éªŒæ³•åˆ™æ˜¯è¶…è¿‡ 60%ï¼Œé‚£ä¹ˆå­˜å‚¨åœ¨ç‰¹å¾ä¸­çš„ä¿¡æ¯é‡éå¸¸ä½ï¼Œå› æ­¤ä» ABT ä¸­åˆ é™¤è¯¥ç‰¹å¾å¯èƒ½æ˜¯ä¸ªå¥½ä¸»æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Measuring the difference in descriptive feature distributions can be useful, however, in understanding what has changed to make a model go stale.",
            "zh": "ç„¶è€Œï¼Œæµ‹é‡æè¿°æ€§ç‰¹å¾åˆ†å¸ƒçš„å·®å¼‚å¯¹äºç†è§£å“ªäº›å˜åŒ–ä½¿æ¨¡å‹è¿‡æ—¶å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) What is the entropy in bits of the letters in this set?",
            "zh": "ï¼ˆç”²ï¼‰è¿™ç»„å­—æ¯çš„ç†µæ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Q-learning, 637, 657, 657, 676, 680, 741",
            "zh": "Q-learningï¼Œ 637ï¼Œ 657ï¼Œ 657ï¼Œ 676ï¼Œ 680ï¼Œ 741"
        }
    },
    {
        "translation": {
            "en": "This variation in the data stops the model from memorizing the training data and forces it to learn patterns that generalize over sets of features rather than relying on a particular feature (or small subset of features).",
            "zh": "æ•°æ®ä¸­çš„è¿™ç§å˜åŒ–ä¼šé˜»æ­¢æ¨¡å‹è®°ä½è®­ç»ƒæ•°æ®ï¼Œå¹¶è¿«ä½¿å®ƒå­¦ä¹ åœ¨ç‰¹å¾é›†ä¸Šæ³›åŒ–çš„æ¨¡å¼ï¼Œè€Œä¸æ˜¯ä¾èµ–äºç‰¹å®šç‰¹å¾ï¼ˆæˆ–ç‰¹å¾çš„ä¸€å°éƒ¨åˆ†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "That said, sampling bias is a difficult problem to tackle.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼ŒæŠ½æ ·åå·®æ˜¯ä¸€ä¸ªéš¾ä»¥è§£å†³çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for many of the other statistical distributions, for example, the mixture of Gaussians distribution, we cannot define an equation over the data that estimates the parameters appropriately.",
            "zh": "ä½†æ˜¯ï¼Œå¯¹äºè®¸å¤šå…¶ä»–ç»Ÿè®¡åˆ†å¸ƒï¼Œä¾‹å¦‚é«˜æ–¯åˆ†å¸ƒçš„æ··åˆï¼Œæˆ‘ä»¬æ— æ³•åœ¨æ•°æ®ä¸Šå®šä¹‰ä¸€ä¸ªæ–¹ç¨‹æ¥é€‚å½“ä¼°è®¡å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "dataset, 5, 758",
            "zh": "æ•°æ®é›†ï¼Œ 5ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "0.65",
            "zh": "0.65"
        }
    },
    {
        "translation": {
            "en": "CNN, 477",
            "zh": "ç¾å›½æœ‰çº¿ç”µè§†æ–°é—»ç½‘ï¼Œ477"
        }
    },
    {
        "translation": {
            "en": "5.7â€…â€…â€…Epilogue",
            "zh": "5.7 ç»“è¯­"
        }
    },
    {
        "translation": {
            "en": "Figure 10.3(b)[602] shows the initial randomly selected cluster centroids overlaid onto the dataset, where c1 = âˆ’1.1048,âˆ’0.1324, c2 = âˆ’0.8431,âˆ’1.2239, and c3 = âˆ’1.2744,0.2187.",
            "zh": "å›¾10.3ï¼ˆbï¼‰[602]æ˜¾ç¤ºäº†å åŠ åœ¨æ•°æ®é›†ä¸Šçš„åˆå§‹éšæœºé€‰æ‹©çš„èšç±»è´¨å¿ƒï¼Œå…¶ä¸­c1 = âˆ’1.1048ï¼Œâˆ’0.1324ï¼Œc2 = âˆ’0.8431ï¼Œâˆ’1.2239ï¼Œc3 = âˆ’1.2744,0.2187ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ted quickly made two observations.",
            "zh": "æ³°å¾·å¾ˆå¿«æå‡ºäº†ä¸¤ä¸ªæ„è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, a feature characterized by a multimodal distribution has two or more very commonly occurring ranges of values that are clearly separated.",
            "zh": "æœ€åï¼Œä»¥å¤šå³°åˆ†å¸ƒä¸ºç‰¹å¾çš„ç‰¹å¾å…·æœ‰ä¸¤ä¸ªæˆ–å¤šä¸ªéå¸¸å¸¸è§çš„å€¼èŒƒå›´ï¼Œè¿™äº›å€¼èŒƒå›´æ˜¯æ˜ç¡®åˆ†å¼€çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.18",
            "zh": "å›¾ 7.18"
        }
    },
    {
        "translation": {
            "en": "This is why the XOR function is not linearly separable.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ XOR å‡½æ•°ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The range of the basketball player heights in Figure A.1[746] is 163 âˆ’ 140 = 23 and for those in Figure A.3[747] is 192 âˆ’ 102 = 90. These measures match what we intuitively see in these figuresâ€”the heights of the second team vary much more than those of the first team. The main advantage of using the range is the ease with which it is calculated. The major disadvantage of the range, however, is that it is highly sensitive to outliers.",
            "zh": "å›¾A.1[746]ä¸­ç¯®çƒè¿åŠ¨å‘˜çš„èº«é«˜èŒƒå›´ä¸º163 âˆ’ 140 = 23ï¼Œå›¾A.3[747]ä¸­çš„ç¯®çƒè¿åŠ¨å‘˜èº«é«˜èŒƒå›´ä¸º192 âˆ’ 102 = 90ã€‚è¿™äº›è¡¡é‡æ ‡å‡†ä¸æˆ‘ä»¬åœ¨è¿™äº›æ•°å­—ä¸­ç›´è§‚åœ°çœ‹åˆ°çš„ç›¸ç¬¦â€”â€”äºŒé˜Ÿçš„èº«é«˜å˜åŒ–æ¯”ä¸€é˜Ÿçš„é«˜è¦å¤§å¾—å¤šã€‚ä½¿ç”¨èŒƒå›´çš„ä¸»è¦ä¼˜ç‚¹æ˜¯æ˜“äºè®¡ç®—ã€‚ç„¶è€Œï¼Œè¯¥èŒƒå›´çš„ä¸»è¦ç¼ºç‚¹æ˜¯å®ƒå¯¹å¼‚å¸¸å€¼é«˜åº¦æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.9",
            "zh": "è¡¨ 3.9"
        }
    },
    {
        "translation": {
            "en": "8.4â€…â€…â€…The per example error after the forward pass illustrated in Figure 8.14[425], the per example âˆ‚â„°/âˆ‚a 8, and the sum of squared errors for the model over the dataset of four examples.",
            "zh": "8.4 å›¾ 8.14[425] æ‰€ç¤ºçš„å‰å‘ä¼ é€’åçš„æ¯ä¾‹è¯¯å·®ã€æ¯ä¾‹ âˆ‚E/âˆ‚a 8 ä»¥åŠæ¨¡å‹åœ¨å››ä¸ªç¤ºä¾‹æ•°æ®é›†ä¸Šçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This table is ordered so that the weights for inputs to Neuron 8 are at the top, and then as we move down the table, we move back through the network.",
            "zh": "è¿™ä¸ªè¡¨æ˜¯æœ‰åºçš„ï¼Œè¿™æ ·Neuron 8çš„è¾“å…¥æƒé‡å°±æ”¾åœ¨äº†é¡¶éƒ¨ï¼Œç„¶åå½“æˆ‘ä»¬åœ¨è¡¨æ ¼ä¸­å‘ä¸‹ç§»åŠ¨æ—¶ï¼Œæˆ‘ä»¬åˆé€šè¿‡ç½‘ç»œå‘åç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the player enters one of the terminal states (BUST, LOSE, TIE, WIN, or TWENTYTWO) the game is over and there are no more actions to take.",
            "zh": "ä¸€æ—¦ç©å®¶è¿›å…¥æœ€ç»ˆçŠ¶æ€ä¹‹ä¸€ï¼ˆBUSTã€LOSEã€TIEã€WIN æˆ– TWENTYTWOï¼‰ï¼Œæ¸¸æˆå°±ç»“æŸäº†ï¼Œæ²¡æœ‰æ›´å¤šçš„è¡ŒåŠ¨å¯åšã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.5â€ƒModeling Non-Linear Relationships",
            "zh": "7.4.5 éçº¿æ€§å…³ç³»å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "(a) The following table presents the scoring by two models of the test set of candidate idioms. Which model would be chosen to filter candidate idioms if the decision were taken on the basis of the F1 score for each model, assuming both models use a threshold of > 0.5 for classifying a candidate as an idiom.",
            "zh": "ï¼ˆaï¼‰ ä¸‹è¡¨åˆ—å‡ºäº†ä¸¤ç§æ¨¡å‹å¯¹å€™é€‰ä¹ è¯­æµ‹è¯•é›†çš„è¯„åˆ†æƒ…å†µã€‚å‡è®¾ä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨>é˜ˆå€¼ 0.5 å°†å€™é€‰ä¹ è¯­åˆ†ç±»ä¸ºä¹ è¯­ï¼Œåˆ™å¦‚æœæ ¹æ®æ¯ä¸ªæ¨¡å‹çš„ F1 åˆ†æ•°åšå‡ºå†³å®šï¼Œåˆ™é€‰æ‹©å“ªä¸ªæ¨¡å‹æ¥è¿‡æ»¤å€™é€‰ä¹ è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "When using small multiples, it is important that all the small charts are kept consistent because this ensures that only genuine differences within the data are highlighted, rather than differences that arise from formatting.",
            "zh": "ä½¿ç”¨å°å€æ•°æ—¶ï¼Œæ‰€æœ‰å°å›¾è¡¨ä¿æŒä¸€è‡´éå¸¸é‡è¦ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ç¡®ä¿ä»…çªå‡ºæ˜¾ç¤ºæ•°æ®ä¸­çš„çœŸæ­£å·®å¼‚ï¼Œè€Œä¸æ˜¯å› æ ¼å¼è®¾ç½®è€Œäº§ç”Ÿçš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "By doing this, the Bayesian prediction model is able to calculate reasonable probabilities for queries with combinations of evidence that do not occur in the dataset.",
            "zh": "é€šè¿‡è¿™æ ·åšï¼Œè´å¶æ–¯é¢„æµ‹æ¨¡å‹èƒ½å¤Ÿè®¡ç®—å‡ºå…·æœ‰æ•°æ®é›†ä¸­æœªå‡ºç°çš„è¯æ®ç»„åˆçš„æŸ¥è¯¢çš„åˆç†æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. Covariance between features means that knowing the value of one feature tells us something about the value of the other feature. See Section 3.5.2[219] for more information.",
            "zh": "21. ç‰¹å¾ä¹‹é—´çš„åæ–¹å·®æ„å‘³ç€çŸ¥é“ä¸€ä¸ªç‰¹å¾çš„ä»·å€¼å¯ä»¥å‘Šè¯‰æˆ‘ä»¬æœ‰å…³å¦ä¸€ä¸ªç‰¹å¾çš„ä»·å€¼çš„ä¸€äº›ä¿¡æ¯ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ç¬¬ 3.5.2[219] èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, it may be that the network outputs only a single value once it has processed the whole sequence; this scenario might hold if we were training a network to process a sentence and then return a label describing the sentimentâ€”positive or negativeâ€”expressed in the sentence.",
            "zh": "ä¾‹å¦‚ï¼Œç½‘ç»œåœ¨å¤„ç†å®Œæ•´ä¸ªåºåˆ—åå¯èƒ½åªè¾“å‡ºä¸€ä¸ªå€¼;å¦‚æœæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç½‘ç»œæ¥å¤„ç†ä¸€ä¸ªå¥å­ï¼Œç„¶åè¿”å›ä¸€ä¸ªæ ‡ç­¾æ¥æè¿°å¥å­ä¸­è¡¨è¾¾çš„æƒ…ç»ªï¼ˆç§¯ææˆ–æ¶ˆæï¼‰ï¼Œè¿™ç§æƒ…å†µå¯èƒ½ä¼šæˆç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Backward Pass The error of the network is calculated by comparing the output generated by the forward pass with the target output specified in the dataset.",
            "zh": "åå‘ä¼ é€’ é€šè¿‡å°†å‰å‘ä¼ é€’ç”Ÿæˆçš„è¾“å‡ºä¸æ•°æ®é›†ä¸­æŒ‡å®šçš„ç›®æ ‡è¾“å‡ºè¿›è¡Œæ¯”è¾ƒæ¥è®¡ç®—ç½‘ç»œçš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "NUMRETENTIONOFFERS",
            "zh": "NUMRETENTIONä¼˜æƒ "
        }
    },
    {
        "translation": {
            "en": "This model is",
            "zh": "è¿™ä¸ªæ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "40. The data in this table has been artificially generated for this question, but is inspired by the results from the Framingham Heart Study: www.framinghamheartstudy.org.",
            "zh": "40. æœ¬è¡¨ä¸­çš„æ•°æ®æ˜¯é’ˆå¯¹è¿™ä¸ªé—®é¢˜äººä¸ºç”Ÿæˆçš„ï¼Œä½†å—åˆ°å¼—é›·æ˜æ±‰å¿ƒè„ç ”ç©¶ç»“æœçš„å¯å‘ï¼šwww.framinghamheartstudy.orgã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate how adjusting the variance of the sample distribution used to initialize the weights of a network affects the dynamics of the network during training, we will scale up our example network so that the effects become apparent.",
            "zh": "ä¸ºäº†è¯´æ˜è°ƒæ•´ç”¨äºåˆå§‹åŒ–ç½‘ç»œæƒé‡çš„æ ·æœ¬åˆ†å¸ƒçš„æ–¹å·®å¦‚ä½•å½±å“è®­ç»ƒæœŸé—´ç½‘ç»œçš„åŠ¨æ€ï¼Œæˆ‘ä»¬å°†æ‰©å±•ç¤ºä¾‹ç½‘ç»œï¼Œä»¥ä¾¿æ•ˆæœå˜å¾—æ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 5[420] brings together the different topics covered in the preceding sections.",
            "zh": "ç®—æ³• 5[420] æ±‡é›†äº†å‰é¢å„èŠ‚ä¸­æ¶µç›–çš„ä¸åŒä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Looking up the results on the other modules of the student whose script hasnâ€™t been corrected, the lecturer finds that the student got the following marks: MODULE 1=60, and MODULE 2=85. Assuming that the k-nearest neighbor model uses k=1 and Euclidean distance as its similarity metric, what GRADE would the model assign the student?",
            "zh": "ï¼ˆaï¼‰ æŸ¥æ‰¾è„šæœ¬æœªè¢«çº æ­£çš„å­¦ç”Ÿçš„å…¶ä»–æ¨¡å—çš„ç»“æœï¼Œè®²å¸ˆå‘ç°è¯¥å­¦ç”Ÿè·å¾—äº†ä»¥ä¸‹åˆ†æ•°ï¼šæ¨¡å— 1=60ï¼Œæ¨¡å— 2=85ã€‚å‡è®¾ k æœ€è¿‘é‚»æ¨¡å‹ä½¿ç”¨ k=1 å’Œæ¬§å‡ é‡Œå¾—è·ç¦»ä½œä¸ºå…¶ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼Œè¯¥æ¨¡å‹ä¼šç»™å­¦ç”Ÿåˆ†é…ä»€ä¹ˆ GRADEï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "So which approach should we use?",
            "zh": "é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªç§æ–¹æ³•å‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "33. The story recounted here of the discovery of the platypus is loosely based on real events. See Eco (1999) for a more faithful account of what happened and for a discussion of the implications of this discovery for classification systems in general. The platypus is not the only animal from Australia whose discovery by Europeans has relevance to predictive machine learning. See Taleb (2008) regarding the discovery of black swans and its relevance to predictive models.",
            "zh": "33. è¿™é‡Œè®²è¿°çš„é¸­å˜´å…½å‘ç°çš„æ•…äº‹å¤§è‡´æ˜¯æ ¹æ®çœŸå®äº‹ä»¶æ”¹ç¼–çš„ã€‚å‚è§Eco ï¼ˆ1999ï¼‰å¯¹æ‰€å‘ç”Ÿäº‹ä»¶çš„æ›´å¿ å®çš„æè¿°ï¼Œå¹¶è®¨è®ºäº†è¿™ä¸€å‘ç°å¯¹ä¸€èˆ¬åˆ†ç±»ç³»ç»Ÿçš„å½±å“ã€‚é¸­å˜´å…½å¹¶ä¸æ˜¯å”¯ä¸€ä¸€ç§æ¥è‡ªæ¾³å¤§åˆ©äºšçš„åŠ¨ç‰©ï¼Œæ¬§æ´²äººçš„å‘ç°ä¸é¢„æµ‹æœºå™¨å­¦ä¹ æœ‰å…³ã€‚å‚è§Taleb ï¼ˆ2008ï¼‰å…³äºé»‘å¤©é¹…çš„å‘ç°åŠå…¶ä¸é¢„æµ‹æ¨¡å‹çš„ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.74572",
            "zh": "0.74572"
        }
    },
    {
        "translation": {
            "en": "Unless a project is focused on clearly stated goals, it is unlikely to be successful.",
            "zh": "é™¤éä¸€ä¸ªé¡¹ç›®ä¸“æ³¨äºæ˜ç¡®è§„å®šçš„ç›®æ ‡ï¼Œå¦åˆ™å®ƒä¸å¤ªå¯èƒ½æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Dealer High (DH): 8 âˆ’ 11",
            "zh": "ç»é”€å•†æœ€é«˜ä»· ï¼ˆDHï¼‰ï¼š 8 âˆ’ 11"
        }
    },
    {
        "translation": {
            "en": "There are a couple of interesting things that are evident, however.",
            "zh": "ç„¶è€Œï¼Œæœ‰å‡ ä»¶æœ‰è¶£çš„äº‹æƒ…æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. See Kelleher (2019) for a history of the development of neural network models and the emergence of deep learning.",
            "zh": "2. å‚è§ Kelleher ï¼ˆ2019ï¼‰ äº†è§£ç¥ç»ç½‘ç»œæ¨¡å‹çš„å‘å±•å’Œæ·±åº¦å­¦ä¹ çš„å‡ºç°çš„å†å²ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. What is supervised machine learning?",
            "zh": "2. ä»€ä¹ˆæ˜¯ç›‘ç£æœºå™¨å­¦ä¹ ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Example of using small multiple histograms to visualize the relationship between a categorical feature and a continuous feature. All examples use data from the professional basketball team dataset in Table 3.7[73]: (a) a histogram of the AGE feature; (b) a histogram of the HEIGHT feature; (c) histograms of the AGE feature for instances displaying each level of the POSITION feature; and (d) histograms of the HEIGHT feature for instances displaying each level of the POSITION feature.",
            "zh": "ä½¿ç”¨å°å‹å¤šé‡ç›´æ–¹å›¾å¯è§†åŒ–åˆ†ç±»è¦ç´ å’Œè¿ç»­è¦ç´ ä¹‹é—´å…³ç³»çš„ç¤ºä¾‹ã€‚æ‰€æœ‰ç¤ºä¾‹å‡ä½¿ç”¨è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†çš„æ•°æ®ï¼šï¼ˆaï¼‰AGEç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆbï¼‰ é«˜åº¦ç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆcï¼‰ æ˜¾ç¤º POSITION ç‰¹å¾æ¯ä¸ªçº§åˆ«çš„å®ä¾‹çš„ AGE ç‰¹å¾ç›´æ–¹å›¾;ä»¥åŠ ï¼ˆdï¼‰ æ˜¾ç¤º POSITION ç‰¹å¾æ¯ä¸ªçº§åˆ«çš„å®ä¾‹çš„ HEIGHT ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, we can counteract this scaling by the number of inputs by setting var(W) = 1/nin; that is, by setting the variance of the distribution that the weights for a neuron are sampled from to 1/nin.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½® varï¼ˆWï¼‰ = 1/nin æ¥æŠµæ¶ˆè¾“å…¥æ•°é‡æ¥æŠµæ¶ˆè¿™ç§ç¼©æ”¾;ä¹Ÿå°±æ˜¯è¯´ï¼Œé€šè¿‡å°†ç¥ç»å…ƒæƒé‡é‡‡æ ·çš„åˆ†å¸ƒæ–¹å·®è®¾ç½®ä¸º 1/ninã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.7",
            "zh": "è¡¨ 9.7"
        }
    },
    {
        "translation": {
            "en": "Another approach to avoiding dead ReLUs is to modify the rectified linear function so that it does not saturate for z < 0.",
            "zh": "é¿å…æ­» ReLU çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä¿®æ”¹æ•´æµåçš„çº¿æ€§å‡½æ•°ï¼Œä½¿å…¶åœ¨ z < 0 æ—¶ä¸ä¼šé¥±å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because if a parent node is unknown, then to compute the distribution for the node, we must sum out this parent.",
            "zh": "è¿™æ˜¯å› ä¸ºå¦‚æœçˆ¶èŠ‚ç‚¹æ˜¯æœªçŸ¥çš„ï¼Œé‚£ä¹ˆè¦è®¡ç®—è¯¥èŠ‚ç‚¹çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¿…é¡»å¯¹è¿™ä¸ªçˆ¶èŠ‚ç‚¹æ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A number of values are missing from these workings (indicated by ??). Calculate the missing values. The distances between each instance in the dataset from Question 1 (using Euclidean distance) are shown in the following distance matrix, and will be useful for this exercise.",
            "zh": "ï¼ˆaï¼‰ è¿™äº›å·¥ä½œæ–¹å¼ä¸­ç¼ºå°‘ä¸€äº›å€¼ï¼ˆç”¨ï¼Ÿï¼Ÿï¼‰è¡¨ç¤ºã€‚è®¡ç®—ç¼ºå¤±å€¼ã€‚é—®é¢˜ 1 ä¸­æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼ˆä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰æ˜¾ç¤ºåœ¨ä»¥ä¸‹è·ç¦»çŸ©é˜µä¸­ï¼Œå¯¹æœ¬ç»ƒä¹ å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is clear from this figure that the weighted sum of the three normals does an excellent job of modeling the multimodal density distribution.",
            "zh": "ä»è¿™å¼ å›¾ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œä¸‰ä¸ªæ­£æ€çš„åŠ æƒå’Œåœ¨æ¨¡æ‹Ÿå¤šæ¨¡æ€å¯†åº¦åˆ†å¸ƒæ–¹é¢åšå¾—éå¸¸å‡ºè‰²ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Note that subtraction is viewed as addition of negative numbers, and division is seen as multiplication by reciprocals, so both are also allowed.",
            "zh": "1. è¯·æ³¨æ„ï¼Œå‡æ³•è¢«è§†ä¸ºè´Ÿæ•°çš„åŠ æ³•ï¼Œé™¤æ³•è¢«è§†ä¸ºå€’æ•°çš„ä¹˜æ³•ï¼Œå› æ­¤ä¸¤è€…éƒ½æ˜¯å…è®¸çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. Hence the name Iterative Dichotomizer.",
            "zh": "9. å› æ­¤å¾—åè¿­ä»£äºŒåˆ†æ³•å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simple nature of this first trained model is evident from the predictions made by Î”1 shown in Table 4.15[166].",
            "zh": "ä»è¡¨4.15[166]æ‰€ç¤ºçš„Î”1çš„é¢„æµ‹ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºç¬¬ä¸€ä¸ªè®­ç»ƒæ¨¡å‹çš„ç®€å•æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "FIBER2MAG_U/G/R/I/Z",
            "zh": "FIBER2MAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The consequence of this is that each instance from the original dataset can appear more than once in the sampled dataset.14 After having created the larger samples from each group, we combine these to form the overall over-sampled dataset.",
            "zh": "è¿™æ ·åšçš„ç»“æœæ˜¯ï¼ŒåŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½å¯ä»¥åœ¨é‡‡æ ·æ•°æ®é›†ä¸­å‡ºç°ä¸æ­¢ä¸€æ¬¡ã€‚14 åœ¨ä»æ¯ä¸ªç»„åˆ›å»ºè¾ƒå¤§çš„æ ·æœ¬åï¼Œæˆ‘ä»¬å°†è¿™äº›æ ·æœ¬ç»„åˆåœ¨ä¸€èµ·ä»¥å½¢æˆæ•´ä¸ªè¿‡é‡‡æ ·æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The evaluation of machine learning models is a live research issue, and a large body of material addresses all the questions that have been discussed in this chapter.",
            "zh": "æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¯„ä¼°æ˜¯ä¸€ä¸ªå®æ—¶ç ”ç©¶é—®é¢˜ï¼Œå¤§é‡ææ–™è§£å†³äº†æœ¬ç« ä¸­è®¨è®ºçš„æ‰€æœ‰é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.4â€…â€…â€…Legal Issues",
            "zh": "2.4.4 æ³•å¾‹é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "Figure A.5",
            "zh": "å›¾ A.5"
        }
    },
    {
        "translation": {
            "en": "similarity measure, 181",
            "zh": "ç›¸ä¼¼åº¦æµ‹é‡ï¼Œ181"
        }
    },
    {
        "translation": {
            "en": "So, for example, each row in Table 6.1[246] represents an experiment, and the assignment of the descriptive features to the values shown in each row can be referred to as a distinct event.",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œè¡¨ 6.1[246] ä¸­çš„æ¯ä¸€è¡Œéƒ½ä»£è¡¨ä¸€ä¸ªå®éªŒï¼Œå¹¶ä¸”å°†æè¿°æ€§ç‰¹å¾åˆ†é…ç»™æ¯è¡Œä¸­æ˜¾ç¤ºçš„å€¼å¯ä»¥ç§°ä¸ºä¸€ä¸ªä¸åŒçš„äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes Conor would be very happy with his choices (his reward would be high), but sometimes he would be disappointed (his reward would be low).",
            "zh": "æœ‰æ—¶åº·çº³ä¼šå¯¹ä»–çš„é€‰æ‹©æ„Ÿåˆ°éå¸¸æ»¡æ„ï¼ˆä»–çš„å›æŠ¥ä¼šå¾ˆé«˜ï¼‰ï¼Œä½†æœ‰æ—¶ä»–ä¼šæ„Ÿåˆ°å¤±æœ›ï¼ˆä»–çš„å›æŠ¥ä¼šå¾ˆä½ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adaboost.R2, 161",
            "zh": "Adaboost.R2,161"
        }
    },
    {
        "translation": {
            "en": "In a grid world scenario an agent must learn to navigate an environment from a start position to a goal position, often avoiding obstacles along the way.",
            "zh": "åœ¨ç½‘æ ¼ä¸–ç•Œåœºæ™¯ä¸­ï¼Œæ™ºèƒ½ä½“å¿…é¡»å­¦ä¼šå°†ç¯å¢ƒä»èµ·å§‹ä½ç½®å¯¼èˆªåˆ°ç›®æ ‡ä½ç½®ï¼Œå¹¶ç»å¸¸é¿å¼€æ²¿é€”çš„éšœç¢ç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "information theory, 117, 126",
            "zh": "ä¿¡æ¯è®ºï¼Œ 117ï¼Œ 126"
        }
    },
    {
        "translation": {
            "en": "stride, 486",
            "zh": "æ­¥å¹…ï¼Œ486"
        }
    },
    {
        "translation": {
            "en": "Creating models that can identify queries as being sufficiently different from what was in a training dataset so as to be considered a new type of entity is a difficult research problem. Some of the areas of research relevant to this problem include outlier detection and one-class classification.",
            "zh": "åˆ›å»ºèƒ½å¤Ÿè¯†åˆ«æŸ¥è¯¢ä¸è®­ç»ƒæ•°æ®é›†ä¸­çš„å†…å®¹æœ‰è¶³å¤Ÿå·®å¼‚çš„æ¨¡å‹ï¼Œä»è€Œè¢«è§†ä¸ºä¸€ç§æ–°å‹å®ä½“æ˜¯ä¸€ä¸ªå›°éš¾çš„ç ”ç©¶é—®é¢˜ã€‚ä¸æ­¤é—®é¢˜ç›¸å…³çš„ä¸€äº›ç ”ç©¶é¢†åŸŸåŒ…æ‹¬å¼‚å¸¸å€¼æ£€æµ‹å’Œä¸€ç±»åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather, it is because of the way that the answer to each question splits the character cards into different sets based on the value of the descriptive feature the question is asked about (MAN, LONG HAIR or GLASSES) and the likelihood of each possible answer to the question.",
            "zh": "ç›¸åï¼Œè¿™æ˜¯å› ä¸ºæ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆæ ¹æ®é—®é¢˜æ‰€æå‡ºçš„æè¿°æ€§ç‰¹å¾ï¼ˆç”·äººã€é•¿å‘æˆ–çœ¼é•œï¼‰çš„å€¼ä»¥åŠæ¯ä¸ªå¯èƒ½ç­”æ¡ˆçš„å¯èƒ½æ€§å°†è§’è‰²å¡åˆ†æˆä¸åŒçš„é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "batch normalization, 523",
            "zh": "æ‰¹é‡å½’ä¸€åŒ–ï¼Œ523"
        }
    },
    {
        "translation": {
            "en": "This is quite a dramatic increase; however, it gets even more dramatic when we increase from two to three descriptive features.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„å¢é•¿;ç„¶è€Œï¼Œå½“æˆ‘ä»¬ä»ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾å¢åŠ åˆ°ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾æ—¶ï¼Œå®ƒå˜å¾—æ›´åŠ æˆå‰§åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Detailed descriptions of the story of Professor Blondlot and N rays are available in Klotz (1980) and Ashmore (1993).",
            "zh": "1. Klotz ï¼ˆ1980ï¼‰ å’Œ Ashmore ï¼ˆ1993ï¼‰ å¯¹ Blondlot æ•™æˆå’Œ N å°„çº¿çš„æ•…äº‹è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The gray columns in each of the activation and z matrices trace the processing of the second example through the sequence of operations.",
            "zh": "æ¯ä¸ªæ¿€æ´»çŸ©é˜µå’Œ z çŸ©é˜µä¸­çš„ç°è‰²åˆ—é€šè¿‡æ“ä½œåºåˆ—è·Ÿè¸ªç¬¬äºŒä¸ªç¤ºä¾‹çš„å¤„ç†è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the model visualizations black circles show the training dataset, gray squares show the predictions made for the instances in the training dataset by the current model, and the dotted line shows the predictions that would be made by the current model for the full range of input temperatures.",
            "zh": "åœ¨æ¨¡å‹å¯è§†åŒ–ä¸­ï¼Œé»‘è‰²åœ†åœˆè¡¨ç¤ºè®­ç»ƒæ•°æ®é›†ï¼Œç°è‰²æ–¹å—è¡¨ç¤ºå½“å‰æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹æ‰€åšçš„é¢„æµ‹ï¼Œè™šçº¿è¡¨ç¤ºå½“å‰æ¨¡å‹å°†å¯¹æ•´ä¸ªè¾“å…¥æ¸©åº¦èŒƒå›´è¿›è¡Œçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prediction score distributions shown in Figure 9.9(a)[557] are much better separated than those in Figure 9.9(b)[557].",
            "zh": "å›¾9.9ï¼ˆaï¼‰[557]æ‰€ç¤ºçš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒæ¯”å›¾9.9ï¼ˆbï¼‰[557]ä¸­çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒè¦å¥½å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "These kinds of publications are an invaluable resource for an analytics professional trying to come to grips with a new topic.",
            "zh": "å¯¹äºè¯•å›¾æŒæ¡æ–°ä¸»é¢˜çš„åˆ†æä¸“ä¸šäººå‘˜æ¥è¯´ï¼Œè¿™äº›ç±»å‹çš„å‡ºç‰ˆç‰©æ˜¯å®è´µçš„èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "The second target feature allowed three levels for spiral galaxies: spiral_cw (P_CW majority), spiral_acw (P_ACW majority), and spiral_edge (P_EDGE majority).",
            "zh": "ç¬¬äºŒä¸ªç›®æ ‡ç‰¹å¾å…è®¸èºæ—‹æ˜Ÿç³»åˆ†ä¸ºä¸‰ä¸ªå±‚æ¬¡ï¼šspiral_cwï¼ˆP_CWå¤šæ•°ï¼‰ã€spiral_acwï¼ˆP_ACWå¤šæ•°ï¼‰å’Œspiral_edgeï¼ˆP_EDGEå¤šæ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.39",
            "zh": "-0.39"
        }
    },
    {
        "translation": {
            "en": "There are two important things to remember in designing these base cases.",
            "zh": "åœ¨è®¾è®¡è¿™äº›åŸºæœ¬æƒ…å†µæ—¶ï¼Œéœ€è¦è®°ä½ä¸¤ä»¶é‡è¦çš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate the probability of an event, we have simply counted how often the event occurred and divided this number by how often the event could have occurred. A continuous feature can have an infinite number of values in its domain, so any particular value will occur a negligible amount of the time. In fact, the relative frequency of any particular value for a continuous feature will be indistinguishable from zero given a large dataset.",
            "zh": "ä¸ºäº†è®¡ç®—äº‹ä»¶çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬åªéœ€è®¡ç®—äº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡ï¼Œç„¶åå°†è¯¥æ•°å­—é™¤ä»¥äº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡ã€‚è¿ç»­è¦ç´ åœ¨å…¶åŸŸä¸­å¯ä»¥æœ‰æ— é™æ•°é‡çš„å€¼ï¼Œå› æ­¤ä»»ä½•ç‰¹å®šå€¼çš„å‡ºç°æ—¶é—´å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚äº‹å®ä¸Šï¼Œåœ¨ç»™å®šå¤§å‹æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œè¿ç»­ç‰¹å¾çš„ä»»ä½•ç‰¹å®šå€¼çš„ç›¸å¯¹é¢‘ç‡éƒ½æ— æ³•ä¸é›¶åŒºåˆ†å¼€æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bagging/Boosting",
            "zh": "è£…è¢‹/æå‡"
        }
    },
    {
        "translation": {
            "en": "data, 3",
            "zh": "æ•°æ®ï¼Œ 3"
        }
    },
    {
        "translation": {
            "en": "A multi-layer feedforward neural network that uses only linear neurons (i.e., neurons that do not include a non-linear activation function) is equivalent to a single-layer network with linear neurons; in other words, it can represent only a linear mapping on the inputs.",
            "zh": "ä»…ä½¿ç”¨çº¿æ€§ç¥ç»å…ƒï¼ˆå³ä¸åŒ…å«éçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒï¼‰çš„å¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œç­‰æ•ˆäºå…·æœ‰çº¿æ€§ç¥ç»å…ƒçš„å•å±‚ç½‘ç»œ;æ¢å¥è¯è¯´ï¼Œå®ƒåªèƒ½è¡¨ç¤ºè¾“å…¥ä¸Šçš„çº¿æ€§æ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "John D. Kelleher, Brian Mac Namee, and Aoife Dâ€™Arcy",
            "zh": "John D. Kelleherã€Brian Mac Namee å’Œ Aoife D'Arcy"
        }
    },
    {
        "translation": {
            "en": "This example demonstrates that, using the DQN algorithm, it is possible to train agents to perform very sophisticated tasks using modern deep neural networks combined with very basic state representationsâ€”in this case just screenshots from the game.",
            "zh": "æ­¤ç¤ºä¾‹æ¼”ç¤ºäº†ä½¿ç”¨ DQN ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨ç°ä»£æ·±åº¦ç¥ç»ç½‘ç»œç»“åˆéå¸¸åŸºæœ¬çš„çŠ¶æ€è¡¨ç¤ºæ¥è®­ç»ƒä»£ç†æ‰§è¡Œéå¸¸å¤æ‚çš„ä»»åŠ¡ï¼Œåœ¨æœ¬ä¾‹ä¸­åªæ˜¯æ¸¸æˆçš„å±å¹•æˆªå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, we cover a second use case of unsupervised learning, to generate representations that will be used in other machine learning approaches rather than as an end result in their own right.",
            "zh": "æœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†æ— ç›‘ç£å­¦ä¹ çš„ç¬¬äºŒä¸ªç”¨ä¾‹ï¼Œä»¥ç”Ÿæˆå°†ç”¨äºå…¶ä»–æœºå™¨å­¦ä¹ æ–¹æ³•çš„è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä½œä¸ºæœ€ç»ˆç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the if statement on Line 8 fails, and the search moves to the parent of the current node (Line 11).",
            "zh": "è¿™æ„å‘³ç€ç¬¬ 8 è¡Œçš„ if è¯­å¥å¤±è´¥ï¼Œæœç´¢å°†ç§»åŠ¨åˆ°å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼ˆç¬¬ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Perhaps one of the other items on the menu is even better than chicken, but following a greedy policy will never allow Conor the opportunity to learn this.",
            "zh": "ä¹Ÿè®¸èœå•ä¸Šçš„å…¶ä»–é¡¹ç›®ä¹‹ä¸€ç”šè‡³æ¯”é¸¡è‚‰æ›´å¥½ï¼Œä½†éµå¾ªè´ªå©ªçš„æ”¿ç­–æ°¸è¿œä¸ä¼šè®©åº·çº³æœ‰æœºä¼šå­¦ä¹ è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this dataset, generate the following binned versions of the IQ feature:",
            "zh": "ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œç”Ÿæˆä»¥ä¸‹ IQ ç‰¹å¾çš„åˆ†ç®±ç‰ˆæœ¬ï¼š"
        }
    },
    {
        "translation": {
            "en": "Â© 2020 Massachusetts Institute of Technology",
            "zh": "Â© 2020 éº»çœç†å·¥å­¦é™¢"
        }
    },
    {
        "translation": {
            "en": "chain rule (probability), 245, 251, 257, 291, 757, 763, 768",
            "zh": "é“¾å¼æ³•åˆ™ï¼ˆæ¦‚ç‡ï¼‰ï¼Œ245ã€251ã€257ã€291ã€757ã€763ã€768"
        }
    },
    {
        "translation": {
            "en": "Figure 7.9[336] shows an example of this in which learning rate decay is used with Î±0 = 0.25 and c = 100.",
            "zh": "å›¾ 7.9[336] æ˜¾ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼Œå…¶ä¸­å­¦ä¹ ç‡è¡°å‡ç”¨äº Î±0 = 0.25 å’Œ c = 100ã€‚"
        }
    },
    {
        "translation": {
            "en": "The heavier the weight of the line used to plot the hyperplane, the earlier in the tree the split occurred.",
            "zh": "ç”¨äºç»˜åˆ¶è¶…å¹³é¢çš„çº¿çš„æƒé‡è¶Šé‡ï¼Œæ ‘ä¸­åˆ†è£‚å‘ç”Ÿå¾—è¶Šæ—©ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we cannot train error-based models with data that contains missing values, and data that contains outliers significantly damages the performance of similarity-based models.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ— æ³•ä½¿ç”¨åŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®è®­ç»ƒåŸºäºé”™è¯¯çš„æ¨¡å‹ï¼Œè€ŒåŒ…å«å¼‚å¸¸å€¼çš„æ•°æ®ä¼šä¸¥é‡æŸå®³åŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this point the design of the ABT had fallen into place. For the most part, Jocelyn would use descriptive features directly from the raw SDSS data. These would be augmented with a small number of derived features that the literature review undertaken with Edwin had identified. Jocelyn was now ready to move into the Data Preparation phase, during which she would populate the ABT, analyze its contents in detail, and perform any transformations that were required to handle data quality issues.",
            "zh": "è‡³æ­¤ï¼ŒABTçš„è®¾è®¡å·²ç»åˆ°ä½ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒJocelyn ä¼šç›´æ¥ä½¿ç”¨åŸå§‹ SDSS æ•°æ®ä¸­çš„æè¿°æ€§ç‰¹å¾ã€‚è¿™äº›å°†é€šè¿‡ä¸Edwinä¸€èµ·è¿›è¡Œçš„æ–‡çŒ®ç»¼è¿°æ‰€ç¡®å®šçš„å°‘é‡è¡ç”Ÿç‰¹å¾æ¥å¢å¼ºã€‚Jocelyn ç°åœ¨å·²å‡†å¤‡å¥½è¿›å…¥æ•°æ®å‡†å¤‡é˜¶æ®µï¼Œåœ¨æ­¤æœŸé—´ï¼Œå¥¹å°†å¡«å…… ABTï¼Œè¯¦ç»†åˆ†æå…¶å†…å®¹ï¼Œå¹¶æ‰§è¡Œå¤„ç†æ•°æ®è´¨é‡é—®é¢˜æ‰€éœ€çš„ä»»ä½•è½¬æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "These models are used to inform resource management and conservation activities,10 such as managing the distribution of animal species and vegetation across geographic regions.",
            "zh": "è¿™äº›æ¨¡å‹ç”¨äºä¸ºèµ„æºç®¡ç†å’Œä¿æŠ¤æ´»åŠ¨æä¾›ä¿¡æ¯ï¼Œ10 ä¾‹å¦‚ç®¡ç†åŠ¨ç‰©ç‰©ç§å’Œæ¤è¢«åœ¨åœ°ç†åŒºåŸŸçš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "deep learning, xvi, 19, 381, 396, 599, 624, 629, 637, 676, 773",
            "zh": "æ·±åº¦å­¦ä¹ ï¼Œ xviï¼Œ 19ï¼Œ 381ï¼Œ 396ï¼Œ 599ï¼Œ 624ï¼Œ 629ï¼Œ 637ï¼Œ 676ï¼Œ 773"
        }
    },
    {
        "translation": {
            "en": "While there are no hard and fast rules about what constitutes an acceptable value for the ROC index, and this is really an application-specific decision, a good rule of thumb is that a value above 0.7 indicates a strong model, while a value below 0.6 indicates a weak model.",
            "zh": "è™½ç„¶å¯¹äºROCæŒ‡æ•°çš„å¯æ¥å—å€¼æ²¡æœ‰ç¡¬æ€§è§„å®šï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªç‰¹å®šäºåº”ç”¨çš„å†³å®šï¼Œä½†ä¸€ä¸ªå¥½çš„ç»éªŒæ³•åˆ™æ˜¯ï¼Œé«˜äº0.7çš„å€¼è¡¨ç¤ºå¼ºæ¨¡å‹ï¼Œè€Œä½äº0.6çš„å€¼è¡¨ç¤ºå¼±æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, the Data Preparation and Modeling phases are closely linked, and analytics projects often spend some time alternating between these two phases.",
            "zh": "åŒæ ·ï¼Œæ•°æ®å‡†å¤‡å’Œå»ºæ¨¡é˜¶æ®µå¯†åˆ‡ç›¸å…³ï¼Œåˆ†æé¡¹ç›®é€šå¸¸ä¼šåœ¨è¿™ä¸¤ä¸ªé˜¶æ®µä¹‹é—´äº¤æ›¿èŠ±è´¹ä¸€äº›æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, parametric models make stronger assumptions about the underlying distributions of the data in a domain.",
            "zh": "é€šå¸¸ï¼Œå‚æ•°åŒ–æ¨¡å‹å¯¹åŸŸä¸­æ•°æ®çš„åŸºæœ¬åˆ†å¸ƒåšå‡ºæ›´å¼ºçš„å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neural network models are particularly useful for representation learning, and this is a large part of the promise of deep learning, as discussed in Chapter 8[381].",
            "zh": "ç¥ç»ç½‘ç»œæ¨¡å‹å¯¹äºè¡¨å¾å­¦ä¹ ç‰¹åˆ«æœ‰ç”¨ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ çš„å¾ˆå¤§ä¸€éƒ¨åˆ†ï¼Œå¦‚ç¬¬8ç« [381]æ‰€è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this dataset are defined as follows:",
            "zh": "æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "If the event of the target feature t taking the level l causes the assignment of values to the descriptive features, q[1],â€¦,q[m], then the events of each descriptive feature taking a value are conditionally independent of each other given the value of the target feature. This means that the chain rule definition can be simplified as follows:",
            "zh": "å¦‚æœç›®æ ‡ç‰¹å¾ t çš„äº‹ä»¶è¾¾åˆ° l çº§åˆ«ï¼Œå¯¼è‡´å°†å€¼åˆ†é…ç»™æè¿°æ€§ç‰¹å¾ q[1],...,q[m]ï¼Œåˆ™åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çš„å€¼çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ªè·å–å€¼çš„æè¿°æ€§ç‰¹å¾çš„äº‹ä»¶åœ¨æ¡ä»¶ä¸Šå½¼æ­¤ç‹¬ç«‹ã€‚è¿™æ„å‘³ç€é“¾å¼è§„åˆ™çš„å®šä¹‰å¯ä»¥ç®€åŒ–å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "0.40",
            "zh": "0.40"
        }
    },
    {
        "translation": {
            "en": "âˆ’ 13.92",
            "zh": "âˆ’ 13.92"
        }
    },
    {
        "translation": {
            "en": "The Îµ-greedy policy is often used together with Q-learning for choosing actions that balance exploration and exploitation and will be used in this section.19",
            "zh": "Îµè´ªå©ªç­–ç•¥é€šå¸¸ä¸ Q-learning ä¸€èµ·ä½¿ç”¨ï¼Œç”¨äºé€‰æ‹©å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨çš„è¡ŒåŠ¨ï¼Œæœ¬èŠ‚å°†ä½¿ç”¨19ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.10[355] shows a dataset, the EEG dataset, based on a neurological experiment designed to capture how neural responses change when experiment participants view positive images (e.g., a picture of a smiling baby) and negative images (e.g., a picture of rotting food).",
            "zh": "è¡¨7.10[355]æ˜¾ç¤ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå³è„‘ç”µå›¾æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŸºäºç¥ç»å­¦å®éªŒï¼Œæ—¨åœ¨æ•æ‰å®éªŒå‚ä¸è€…çœ‹åˆ°æ­£é¢å›¾åƒï¼ˆä¾‹å¦‚ï¼Œå¾®ç¬‘çš„å©´å„¿çš„ç…§ç‰‡ï¼‰å’Œè´Ÿé¢å›¾åƒï¼ˆä¾‹å¦‚ï¼Œè…çƒ‚é£Ÿç‰©çš„å›¾ç‰‡ï¼‰æ—¶ç¥ç»ååº”çš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The link between temporal-difference learning and gradient descent was already made in Section 11.2.5[654].",
            "zh": "æ—¶é—´å·®åˆ†å­¦ä¹ å’Œæ¢¯åº¦ä¸‹é™ä¹‹é—´çš„è”ç³»å·²ç»åœ¨ç¬¬ 11.2.5 èŠ‚ä¸­å»ºç«‹[654]ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability-based learning, 19, 243",
            "zh": "åŸºäºæ¦‚ç‡çš„å­¦ä¹ ï¼Œ 19ï¼Œ 243"
        }
    },
    {
        "translation": {
            "en": "where the values used are again extracted from Table 3.3[57]. Examining the histogram in Figure 3.1(h)[58] is again a good indication of the impact of using this transformation. This impact can be reduced by changing the multiplier used to calculate the thresholds from 2 to a larger value.",
            "zh": "å…¶ä¸­ä½¿ç”¨çš„å€¼å†æ¬¡ä»è¡¨3.3[57]ä¸­æå–ã€‚æ£€æŸ¥å›¾3.1ï¼ˆhï¼‰[58]ä¸­çš„ç›´æ–¹å›¾å†æ¬¡å¾ˆå¥½åœ°è¡¨æ˜äº†ä½¿ç”¨è¿™ç§å˜æ¢çš„å½±å“ã€‚é€šè¿‡å°†ç”¨äºè®¡ç®—é˜ˆå€¼çš„ä¹˜æ•°ä» 2 æ›´æ”¹ä¸ºæ›´å¤§çš„å€¼ï¼Œå¯ä»¥å‡å°‘è¿™ç§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the two squares on the left of the figure represent the two memory locations through which inputs are presented to this network.",
            "zh": "é¦–å…ˆï¼Œå›¾å·¦ä¾§çš„ä¸¤ä¸ªæ–¹å—è¡¨ç¤ºè¾“å…¥å‘ˆç°ç»™è¯¥ç½‘ç»œçš„ä¸¤ä¸ªå†…å­˜ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "dosage prediction, 3",
            "zh": "å‰‚é‡é¢„æµ‹ï¼Œ3"
        }
    },
    {
        "translation": {
            "en": "the probability that an event has happened given a set of evidence for it is equal to the probability of the evidence being caused by the event multiplied by the probability of the event itself",
            "zh": "ç»™å®šä¸€ç»„è¯æ®ï¼Œäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ç­‰äºè¯æ®ç”±äº‹ä»¶å¼•èµ·çš„æ¦‚ç‡ä¹˜ä»¥äº‹ä»¶æœ¬èº«çš„æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "The division of data during the leave-one-out cross validation process. Black rectangles indicate instances in the test set, and white spaces indicate training data.",
            "zh": "åœ¨â€œç•™ä¸€â€äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•é›†ä¸­çš„å®ä¾‹ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor model uses both the SALARY and AGE features when it calculates distances to find the nearest neighbor to the query.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹åœ¨è®¡ç®—è·ç¦»ä»¥æŸ¥æ‰¾æŸ¥è¯¢çš„æœ€è¿‘é‚»æ—¶åŒæ—¶ä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a box plot the vertical axis shows the range of values that a feature can take.",
            "zh": "åœ¨ç®±å½¢å›¾ä¸­ï¼Œçºµè½´æ˜¾ç¤ºè¦ç´ å¯ä»¥é‡‡ç”¨çš„å€¼èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Original",
            "zh": "æºè¯­è¨€"
        }
    },
    {
        "translation": {
            "en": "3.4â€…â€…â€…Handling Data Quality Issues",
            "zh": "3.4 å¤„ç†æ•°æ®è´¨é‡é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "(a) The area under a density curve between the limits and ; (b) the approximation of this area computed by PDF(x)Ã—Îµ; and (c) the error in the approximation is equal to the difference between area A, the area under the curve omitted from the approximation, and area B, the area above the curve erroneously included in the approximation. Both of these areas will get smaller as the width of the interval gets smaller, resulting in a smaller error in the approximation.",
            "zh": "ï¼ˆaï¼‰ è¾¹ç•Œå’Œ ä¹‹é—´çš„å¯†åº¦æ›²çº¿ä¸‹çš„é¢ç§¯;ï¼ˆbï¼‰ ç”±PDFï¼ˆxï¼‰Ã—Îµè®¡ç®—çš„é¢ç§¯çš„è¿‘ä¼¼å€¼;ï¼ˆcï¼‰è¿‘ä¼¼è¯¯å·®ç­‰äºé¢ç§¯Aï¼ˆä»è¿‘ä¼¼ä¸­çœç•¥çš„æ›²çº¿ä¸‹é¢ç§¯ï¼‰å’Œé¢ç§¯Bï¼ˆæ›²çº¿ä¸Šæ–¹çš„é¢ç§¯é”™è¯¯åœ°åŒ…å«åœ¨è¿‘ä¼¼å€¼ä¸­ï¼‰ä¹‹é—´çš„å·®å€¼ã€‚éšç€é—´éš”å®½åº¦å˜å°ï¼Œè¿™ä¸¤ä¸ªåŒºåŸŸéƒ½ä¼šå˜å°ï¼Œä»è€Œå¯¼è‡´è¿‘ä¼¼è¯¯å·®å˜å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example, before the training process begins, both descriptive features are normalized to the range [âˆ’1, 1].",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹å¼€å§‹ä¹‹å‰ï¼Œä¸¤ä¸ªæè¿°æ€§ç‰¹å¾éƒ½å½’ä¸€åŒ–ä¸ºèŒƒå›´ [âˆ’1ï¼Œ 1]ã€‚"
        }
    },
    {
        "translation": {
            "en": "1â€…â€…â€…Machine Learning for Predictive Data Analytics",
            "zh": "1 ç”¨äºé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Equation (8.71)[467] specifies that the cross-entropy loss for the network is dependent solely on the negative natural log of the probability of the correct prediction, per Equation (8.67)[466].",
            "zh": "æ–¹ç¨‹ï¼ˆ8.71ï¼‰[467]æŒ‡å‡ºï¼Œæ ¹æ®æ–¹ç¨‹ï¼ˆ8.67ï¼‰[466]ï¼Œç½‘ç»œçš„äº¤å‰ç†µæŸå¤±ä»…å–å†³äºæ­£ç¡®é¢„æµ‹æ¦‚ç‡çš„è´Ÿè‡ªç„¶å¯¹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "noise, 7, 66, 69, 191",
            "zh": "å™ªéŸ³ï¼Œ 7ï¼Œ 66ï¼Œ 69ï¼Œ 191"
        }
    },
    {
        "translation": {
            "en": "Once domain concepts have been agreed on, the next task is to design and implement concrete features based on these concepts.",
            "zh": "ä¸€æ—¦é¢†åŸŸæ¦‚å¿µè¾¾æˆä¸€è‡´ï¼Œä¸‹ä¸€ä¸ªä»»åŠ¡å°±æ˜¯åŸºäºè¿™äº›æ¦‚å¿µè®¾è®¡å’Œå®ç°å…·ä½“åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that predictive data analytics models built using machine learning techniques are tools that we can use to help make better decisions within an organization and are not an end in themselves.",
            "zh": "é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ æŠ€æœ¯æ„å»ºçš„é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹æ˜¯æˆ‘ä»¬å¯ä»¥ç”¨æ¥å¸®åŠ©åœ¨ç»„ç»‡å†…åšå‡ºæ›´å¥½å†³ç­–çš„å·¥å…·ï¼Œå…¶æœ¬èº«å¹¶ä¸æ˜¯ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The business problem and goals should always be expressed in business terms and not yet be concerned with the actual analytics work at this stage.",
            "zh": "ä¸šåŠ¡é—®é¢˜å’Œç›®æ ‡åº”å§‹ç»ˆä»¥ä¸šåŠ¡æœ¯è¯­è¡¨è¾¾ï¼Œè€Œåœ¨æ­¤é˜¶æ®µè¿˜ä¸å…³å¿ƒå®é™…çš„åˆ†æå·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "This line is known as a decision boundary.",
            "zh": "è¿™æ¡çº¿ç§°ä¸ºå†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider the number of features we can derive from the monthly payment a customer makes on an electricity bill.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘æˆ‘ä»¬å¯ä»¥ä»å®¢æˆ·æ¯æœˆæ”¯ä»˜çš„ç”µè´¹ä¸­è·å¾—çš„åŠŸèƒ½æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the ROC index for this model using the trapezoidal method and the following set of thresholds: 1.0, 0.5, and 0.0.",
            "zh": "ä½¿ç”¨æ¢¯å½¢æ–¹æ³•å’Œä»¥ä¸‹ä¸€ç»„é˜ˆå€¼è®¡ç®—æ­¤æ¨¡å‹çš„ ROC æŒ‡æ•°ï¼š1.0ã€0.5 å’Œ 0.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, decision trees and linear regression models are very easily interpreted, while support vector machines, ensembles, and deep neural networks are almost entirely uninterpretable (because of this, they are often referred to as a black box).",
            "zh": "ä¾‹å¦‚ï¼Œå†³ç­–æ ‘å’Œçº¿æ€§å›å½’æ¨¡å‹å¾ˆå®¹æ˜“è§£é‡Šï¼Œè€Œæ”¯æŒå‘é‡æœºã€é›†æˆå’Œæ·±åº¦ç¥ç»ç½‘ç»œå‡ ä¹å®Œå…¨æ— æ³•è§£é‡Šï¼ˆå› æ­¤ï¼Œå®ƒä»¬é€šå¸¸è¢«ç§°ä¸ºé»‘åŒ£å­ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Before training data becomes available.",
            "zh": "ï¼ˆaï¼‰ åœ¨è®­ç»ƒæ•°æ®å¯ç”¨ä¹‹å‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if D is a 2 Ã— 3 matrix (i.e., a matrix with 2 rows and 3 columns) and E is a 3 Ã— 3 matrix, then the product of these two matrices DE is defined, because the number of columns in D (3) equals the number of rows in E (3).",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœ D æ˜¯ 2 Ã— 3 çŸ©é˜µï¼ˆå³å…·æœ‰ 2 è¡Œå’Œ 3 åˆ—çš„çŸ©é˜µï¼‰ï¼Œè€Œ E æ˜¯ 3 Ã— 3 çŸ©é˜µï¼Œåˆ™å®šä¹‰è¿™ä¸¤ä¸ªçŸ©é˜µ DE çš„ä¹˜ç§¯ï¼Œå› ä¸º D ï¼ˆ3ï¼‰ ä¸­çš„åˆ—æ•°ç­‰äº E ï¼ˆ3ï¼‰ ä¸­çš„è¡Œæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, no learning is taking place because the set of consistent models tells us nothing about the underlying relationship between the descriptive and target features beyond what a simple look-up of the training dataset would provide.",
            "zh": "å› æ­¤ï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•å­¦ä¹ ï¼Œå› ä¸ºé™¤äº†å¯¹è®­ç»ƒæ•°æ®é›†çš„ç®€å•æŸ¥æ‰¾ä¹‹å¤–ï¼Œä¸€ç»„ä¸€è‡´çš„æ¨¡å‹æ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„åŸºæœ¬å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is true no matter how large the sample is.",
            "zh": "æ— è®ºæ ·æœ¬æœ‰å¤šå¤§ï¼Œéƒ½æ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Scrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. Mclust 5: Clustering, classification and density estimation using gaussian finite mixture models. The R Journal 8 (1): 289.",
            "zh": "æ–¯å…‹é²å¡ã€å¢å¡ã€è¿ˆå…‹å°”Â·ç¦æ™®ã€T. Brendan Murphy å’Œ Adrian E. Rafteryã€‚2016. Mclust 5ï¼šä½¿ç”¨é«˜æ–¯æœ‰é™æ··åˆæ¨¡å‹è¿›è¡Œèšç±»ã€åˆ†ç±»å’Œå¯†åº¦ä¼°è®¡ã€‚Ræ‚å¿—8ï¼ˆ1ï¼‰ï¼š289ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.3825",
            "zh": "-0.3825"
        }
    },
    {
        "translation": {
            "en": "However, the network now has five fully connected hidden layers with 100 neurons in each layer.",
            "zh": "ç„¶è€Œï¼Œè¯¥ç½‘ç»œç°åœ¨æœ‰äº”ä¸ªå®Œå…¨è¿æ¥çš„éšè—å±‚ï¼Œæ¯å±‚æœ‰ 100 ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "ground truth, 607",
            "zh": "åœ°é¢å®å†µï¼Œ607"
        }
    },
    {
        "translation": {
            "en": "Figure 6.4[273] illustrates the distinction between fat and light tail distributions using histograms of two datasets.",
            "zh": "å›¾6.4[273]ä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†çš„ç›´æ–¹å›¾è¯´æ˜äº†è„‚è‚ªå’Œè½»å°¾åˆ†å¸ƒä¹‹é—´çš„åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayes, Thomas, and Richard Price. 1763. An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, FRS communicated by Mr. Price, in a letter to John Canton, AMFRS. Philosophical Transactions (1683-1775).",
            "zh": "è´å¶æ–¯ã€æ‰˜é©¬æ–¯å’Œç†æŸ¥å¾·Â·æ™®è±æ–¯ã€‚1763. ä¸€ç¯‡å…³äºè§£å†³æœºä¼šå­¦è¯´ä¸­é—®é¢˜çš„æ–‡ç« ã€‚ç”±å·²æ•…çš„è´å¶æ–¯ç‰§å¸ˆå…ˆç”Ÿï¼ŒFRSç”±Priceå…ˆç”Ÿåœ¨ç»™AMFRSçš„John Cantonçš„ä¸€å°ä¿¡ä¸­ä¼ è¾¾ã€‚å“²å­¦æ±‡åˆŠï¼ˆ1683-1775ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having continuous features in an ABT that cover very different ranges can cause difficulty for some machine learning algorithms.",
            "zh": "åœ¨ ABT ä¸­å…·æœ‰æ¶µç›–éå¸¸ä¸åŒèŒƒå›´çš„è¿ç»­ç‰¹å¾å¯èƒ½ä¼šç»™æŸäº›æœºå™¨å­¦ä¹ ç®—æ³•å¸¦æ¥å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "valid pixels, 487",
            "zh": "æœ‰æ•ˆåƒç´ ï¼Œ487"
        }
    },
    {
        "translation": {
            "en": "This offers huge potential for new science based on this massive data collection effort.",
            "zh": "è¿™ä¸ºåŸºäºè¿™ç§å¤§è§„æ¨¡æ•°æ®æ”¶é›†å·¥ä½œçš„æ–°ç§‘å­¦æä¾›äº†å·¨å¤§çš„æ½œåŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before we examine the mathematical definition of entropy, we first provide an intuitive explanation of what it means.",
            "zh": "åœ¨æˆ‘ä»¬ç ”ç©¶ç†µçš„æ•°å­¦å®šä¹‰ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆè¦ç›´è§‚åœ°è§£é‡Šå®ƒçš„å«ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predicting churn is a form of propensity modeling,2 where the event of interest in this case is a customer making the decision to churn.",
            "zh": "é¢„æµ‹æµå¤±æ˜¯å€¾å‘å»ºæ¨¡çš„ä¸€ç§å½¢å¼ï¼Œ2åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ„Ÿå…´è¶£çš„äº‹ä»¶æ˜¯å®¢æˆ·åšå‡ºæµå¤±çš„å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "4.6â€…â€…â€…Further Reading",
            "zh": "4.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "Target network freezing is used to address this.",
            "zh": "ç›®æ ‡ç½‘ç»œå†»ç»“ç”¨äºè§£å†³æ­¤é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often we condition the probability of an agent transitioning from one state, s1, to another, s2, on the agent taking a specific action, a. We write this",
            "zh": "é€šå¸¸ï¼Œæˆ‘ä»¬ä»¥æ™ºèƒ½ä½“é‡‡å–ç‰¹å®šæ“ä½œ a æ¥å†³å®šæ™ºèƒ½ä½“ä»ä¸€ç§çŠ¶æ€ s1 è¿‡æ¸¡åˆ°å¦ä¸€ç§çŠ¶æ€ s2 çš„æ¦‚ç‡ã€‚æˆ‘ä»¬å†™è¿™ä¸ª"
        }
    },
    {
        "translation": {
            "en": "The four examples in Table 8.1[422] are only a sample from a larger dataset;18 however, for this example, for ease of illustration we treat these four examples as if they were our full dataset.",
            "zh": "è¡¨8.1[422]ä¸­çš„å››ä¸ªç¤ºä¾‹åªæ˜¯æ¥è‡ªè¾ƒå¤§æ•°æ®é›†çš„æ ·æœ¬;18 ç„¶è€Œï¼Œå¯¹äºè¿™ä¸ªä¾‹å­ï¼Œä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œæˆ‘ä»¬å°†è¿™å››ä¸ªä¾‹å­è§†ä¸ºæˆ‘ä»¬çš„å®Œæ•´æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.3(a)[62] illustrates how the location of the peak moves as the value for Î¼ changes, and Figure 3.3(b)[62] illustrates how the shape of the curve changes as we vary the value for Ïƒ.",
            "zh": "å›¾3.3ï¼ˆaï¼‰[62]è¯´æ˜äº†å³°çš„ä½ç½®å¦‚ä½•éšç€Î¼å€¼çš„å˜åŒ–è€Œç§»åŠ¨ï¼Œå›¾3.3ï¼ˆbï¼‰[62]è¯´æ˜äº†æ›²çº¿çš„å½¢çŠ¶å¦‚ä½•éšç€Ïƒå€¼çš„å˜åŒ–è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.14[150] shows the decision tree that is ultimately generated from this process.",
            "zh": "å›¾ 4.14[150] æ˜¾ç¤ºäº†æœ€ç»ˆä»è¯¥è¿‡ç¨‹ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first term in this product, âˆ‚â„°/âˆ‚ai, is the rate of change of the error of the network with respect to changes in the activation function and is calculated as it would be for the weights in the network; for neurons in the output layer, it is calculated using Equation 8.20[411], and for neurons in the hidden layer, it is calculated as the weighted sum of the Î´s backpropagated to the neuron, per Equation 8.22[412].",
            "zh": "æœ¬äº§å“ä¸­çš„ç¬¬ä¸€ä¸ªé¡¹ âˆ‚E/âˆ‚ai æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºæ¿€æ´»å‡½æ•°å˜åŒ–çš„å˜åŒ–ç‡ï¼Œå…¶è®¡ç®—æ–¹å¼ä¸ç½‘ç»œä¸­çš„æƒé‡ç›¸åŒ;å¯¹äºè¾“å‡ºå±‚ä¸­çš„ç¥ç»å…ƒï¼Œä½¿ç”¨å…¬å¼ 8.20[411] è®¡ç®—ï¼Œå¯¹äºéšè—å±‚ä¸­çš„ç¥ç»å…ƒï¼Œæ ¹æ®å…¬å¼ 8.22[412]ï¼Œå°†å…¶è®¡ç®—ä¸ºåå‘ä¼ æ’­åˆ°ç¥ç»å…ƒçš„ Î´ çš„åŠ æƒå’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6(a)[39] shows an example in which, rather than being defined by a fixed date, the observation period and outcome period are defined relative to an event that occurs at different dates for each prediction subject.",
            "zh": "å›¾2.6ï¼ˆaï¼‰[39]æ˜¾ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼Œå…¶ä¸­è§‚å¯ŸæœŸå’Œç»“æœæœŸä¸æ˜¯ç”±å›ºå®šæ—¥æœŸå®šä¹‰çš„ï¼Œè€Œæ˜¯ç›¸å¯¹äºæ¯ä¸ªé¢„æµ‹å¯¹è±¡åœ¨ä¸åŒæ—¥æœŸå‘ç”Ÿçš„äº‹ä»¶å®šä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The per example error after the forward pass illustrated in Figure 8.14[425], the per example âˆ‚â„°/âˆ‚a 8, and the sum of squared errors for the model over the dataset of four examples.",
            "zh": "å›¾ 8.14[425] æ‰€ç¤ºçš„å‰å‘ä¼ é€’ä¹‹åçš„æ¯ä¾‹è¯¯å·®ã€æ¯ä¾‹ âˆ‚E/âˆ‚a 8 ä»¥åŠæ¨¡å‹åœ¨å››ä¸ªç¤ºä¾‹æ•°æ®é›†ä¸Šçš„å¹³æ–¹è¯¯å·®æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.16[627] shows a more detailed view of the reconstructions of the first example from Figure 10.15(a)[626], an image of the digit 2. Reconstructed images and the underlying pixel values from before, during, and after training are shown, as well as the corresponding reconstruction errors. It is clear from both the quality of the image shown and the reconstruction errors that the quality of the reconstruction improves as training progresses.",
            "zh": "å›¾10.16[627]æ˜¾ç¤ºäº†å›¾10.15ï¼ˆaï¼‰[626]ä¸­ç¬¬ä¸€ä¸ªç¤ºä¾‹é‡å»ºçš„æ›´è¯¦ç»†è§†å›¾ï¼Œè¿™æ˜¯æ•°å­—2çš„å›¾åƒã€‚æ˜¾ç¤ºäº†è®­ç»ƒå‰ã€è®­ç»ƒä¸­å’Œè®­ç»ƒåçš„é‡å»ºå›¾åƒå’ŒåŸºç¡€åƒç´ å€¼ï¼Œä»¥åŠç›¸åº”çš„é‡å»ºè¯¯å·®ã€‚ä»æ˜¾ç¤ºçš„å›¾åƒè´¨é‡å’Œé‡å»ºé”™è¯¯ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œé‡å»ºçš„è´¨é‡ä¼šæé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "For these reasons, analysts often must rely more heavily on domain experts in projects using unsupervised learning than in performing supervised machine learning tasks.",
            "zh": "ç”±äºè¿™äº›åŸå› ï¼Œåˆ†æå¸ˆåœ¨ä½¿ç”¨æ— ç›‘ç£å­¦ä¹ çš„é¡¹ç›®ä¸­é€šå¸¸å¿…é¡»æ›´å¤šåœ°ä¾èµ–é¢†åŸŸä¸“å®¶ï¼Œè€Œä¸æ˜¯æ‰§è¡Œç›‘ç£æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can also calculate the expected value from the starting point of an agentâ€™s taking a specific action, at, in a given state, st. This is known as an action-value function and returns the cumulative reward that an agent can expect to earn if it takes an action at in state st and then continues to select actions using policy, Ï€, all the way to the end of an episode. We can write this5",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥ä»æ™ºèƒ½ä½“é‡‡å–ç‰¹å®šæ“ä½œçš„èµ·ç‚¹å¼€å§‹è®¡ç®—æœŸæœ›å€¼ï¼Œåœ¨ç»™å®šçŠ¶æ€ä¸‹ï¼Œstã€‚è¿™ç§°ä¸ºæ“ä½œå€¼å‡½æ•°ï¼Œå¹¶è¿”å›ä»£ç†åœ¨çŠ¶æ€ st æ—¶æ‰§è¡Œæ“ä½œï¼Œç„¶åç»§ç»­ä½¿ç”¨ç­–ç•¥ ï¼ˆÏ€ï¼‰ é€‰æ‹©æ“ä½œï¼Œä¸€ç›´åˆ°å‰§é›†ç»“æŸæ—¶å¯ä»¥é¢„æœŸè·å¾—çš„ç´¯ç§¯å¥–åŠ±ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·å†™5"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, in this case we cannot just use the gradient descent algorithm.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸èƒ½åªä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Next, an elementwise product of the vector of activations in the cell state ctâˆ’1 with the vector of activations from the sigmoid layer is performed.",
            "zh": "æ¥ä¸‹æ¥ï¼Œæ‰§è¡Œç»†èƒçŠ¶æ€ ct-1 ä¸­æ¿€æ´»å‘é‡ä¸æ¥è‡ª S å½¢ç»“è‚ å±‚çš„æ¿€æ´»å‘é‡çš„å…ƒç´ ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "true",
            "zh": "çœŸ"
        }
    },
    {
        "translation": {
            "en": "Skewed distributions are often said to have long tails toward these very high or very low values.",
            "zh": "é€šå¸¸è¯´åæ€åˆ†å¸ƒåœ¨è¿™äº›éå¸¸é«˜æˆ–éå¸¸ä½çš„å€¼ä¸Šæœ‰é•¿å°¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is obvious from Figure 5.11(a)[203] that the search process will not find any instances closer to the query than d21, nor are there any other hyperplanes that intersect with the target hypersphere.",
            "zh": "ä»å›¾5.11ï¼ˆaï¼‰[203]ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œæœç´¢è¿‡ç¨‹ä¸ä¼šæ‰¾åˆ°æ¯”d21æ›´æ¥è¿‘æŸ¥è¯¢çš„ä»»ä½•å®ä¾‹ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•å…¶ä»–ä¸ç›®æ ‡è¶…çƒä½“ç›¸äº¤çš„è¶…å¹³é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "one-versus-all model, 357, 357, 358, 367, 369",
            "zh": "ä¸€å¯¹å¤šå‹å·ï¼Œ357ã€357ã€358ã€367ã€369"
        }
    },
    {
        "translation": {
            "en": "In some extreme cases we may have to abandon a domain concept completely if the data required to express it isnâ€™t available.",
            "zh": "åœ¨æŸäº›æç«¯æƒ…å†µä¸‹ï¼Œå¦‚æœè¡¨è¾¾åŸŸæ¦‚å¿µæ‰€éœ€çš„æ•°æ®ä¸å¯ç”¨ï¼Œæˆ‘ä»¬å¯èƒ½ä¸å¾—ä¸å®Œå…¨æ”¾å¼ƒå®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE feature are missing, so removal would be extreme in this case.",
            "zh": "ç¼ºå°‘è½¯ç»„ç»‡åŠŸèƒ½ï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç§»é™¤å°†æ˜¯æç«¯çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the CONTAINS IMAGES feature has an information gain score of 0 bits.",
            "zh": "æœ€åï¼ŒCONTAINS IMAGES åŠŸèƒ½çš„ä¿¡æ¯å¢ç›Šåˆ†æ•°ä¸º 0 ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two points worth highlighting:",
            "zh": "æœ‰ä¸¤ç‚¹å€¼å¾—å¼ºè°ƒï¼š"
        }
    },
    {
        "translation": {
            "en": "In these situations we should use a metric that ignores co-absences.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å¿½ç•¥å…±åŒç¼ºå¸­çš„æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "To find the optimal decision boundary for a logistic regression problem, we use the gradient descent algorithm (Algorithm 4[326]) to minimize the sum of squared errors based on the training dataset. Figure 7.13[344] shows a series of the candidate models that were explored on the way to finding this boundary. The final panel in Figure 7.13[344] shows how the sum of squared errors changed during the training process.",
            "zh": "ä¸ºäº†æ‰¾åˆ°é€»è¾‘å›å½’é—®é¢˜çš„æœ€ä½³å†³ç­–è¾¹ç•Œï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆç®—æ³• 4[326]ï¼‰æ¥æœ€å°åŒ–åŸºäºè®­ç»ƒæ•°æ®é›†çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚å›¾7.13[344]æ˜¾ç¤ºäº†åœ¨å¯»æ‰¾è¯¥è¾¹ç•Œçš„è¿‡ç¨‹ä¸­æ¢ç´¢çš„ä¸€ç³»åˆ—å€™é€‰æ¨¡å‹ã€‚å›¾ 7.13[344] ä¸­çš„æœ€åä¸€ä¸ªé¢æ¿æ˜¾ç¤ºäº†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¹³æ–¹è¯¯å·®çš„æ€»å’Œæ˜¯å¦‚ä½•å˜åŒ–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.7â€ƒExercises",
            "zh": "10.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Table 8.12",
            "zh": "è¡¨ 8.12"
        }
    },
    {
        "translation": {
            "en": "This configuration means that variance of z values across the neurons in layer HL1 is",
            "zh": "è¿™ç§é…ç½®æ„å‘³ç€ HL1 å±‚ä¸­ç¥ç»å…ƒä¹‹é—´çš„ z å€¼æ–¹å·®ä¸º"
        }
    },
    {
        "translation": {
            "en": "5.4.3â€…â€…â€…Data Normalization",
            "zh": "5.4.3 æ•°æ®è§„èŒƒåŒ–"
        }
    },
    {
        "translation": {
            "en": "In general, however, we are more interested in creating prediction models that generalize well to new data rather than that are strictly consistent with training data, so it is common to sacrifice consistency for generalization capacity.",
            "zh": "ç„¶è€Œï¼Œæ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬æ›´æ„Ÿå…´è¶£çš„æ˜¯åˆ›å»ºèƒ½å¤Ÿå¾ˆå¥½åœ°æ³›åŒ–åˆ°æ–°æ•°æ®çš„é¢„æµ‹æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä¸è®­ç»ƒæ•°æ®ä¸¥æ ¼ä¸€è‡´çš„é¢„æµ‹æ¨¡å‹ï¼Œå› æ­¤ä¸ºäº†æ³›åŒ–èƒ½åŠ›è€Œç‰ºç‰²ä¸€è‡´æ€§æ˜¯å¾ˆå¸¸è§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once Ross had reviewed the full data quality report in detail, he made the following decisions regarding the problematic features he had identified.",
            "zh": "ä¸€æ—¦ Ross è¯¦ç»†å®¡æŸ¥äº†å®Œæ•´çš„æ•°æ®è´¨é‡æŠ¥å‘Šï¼Œä»–å°±ä»–å‘ç°çš„é—®é¢˜ç‰¹å¾åšå‡ºäº†ä»¥ä¸‹å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The typical situation where conditional independence holds between events is when the events share the same cause.",
            "zh": "äº‹ä»¶ä¹‹é—´æœ‰æ¡ä»¶ç‹¬ç«‹æ€§çš„å…¸å‹æƒ…å†µæ˜¯äº‹ä»¶å…·æœ‰ç›¸åŒçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "prediction subject, 23, 29, 689, 707",
            "zh": "é¢„æµ‹å¯¹è±¡ï¼Œ 23ï¼Œ 29ï¼Œ 689ï¼Œ 707"
        }
    },
    {
        "translation": {
            "en": "(a) Overall profit for the k-NN model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(a)[555]; and (b) overall profit for the decision tree model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(b)[555].",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨è¡¨9.8[554]ä¸­çš„åˆ©æ¶¦çŸ©é˜µå’Œè¡¨9.9ï¼ˆaï¼‰[555]ä¸­çš„æ··æ·†çŸ©é˜µçš„k-NNæ¨¡å‹çš„æ€»åˆ©æ¶¦;ï¼ˆbï¼‰ä½¿ç”¨è¡¨9.8[554]ä¸­çš„åˆ©æ¶¦çŸ©é˜µå’Œè¡¨9.9ï¼ˆbï¼‰[555]ä¸­çš„æ··æ·†çŸ©é˜µçš„å†³ç­–æ ‘æ¨¡å‹çš„æ€»åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.22[584] shows the number of customers who churned from each of these two groups during the 12 weeks of the trial, and the associated means and standard deviations.",
            "zh": "è¡¨ 9.22[584] æ˜¾ç¤ºäº†åœ¨è¯•éªŒçš„ 12 å‘¨å†…ä»è¿™ä¸¤ç»„ä¸­æ¯ç»„æµå¤±çš„å®¢æˆ·æ•°é‡ï¼Œä»¥åŠç›¸å…³çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure, the input to the network is a 6-by-6 matrix of grayscale values to represent a 6-by-6 image41 of a 4; the 4 is shown in the matrix by 255 values.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ä¸€ä¸ª 6Ã—6 çš„ç°åº¦å€¼çŸ©é˜µï¼Œç”¨äºè¡¨ç¤º 4 çš„ 6Ã—6 å›¾åƒ41;4 åœ¨çŸ©é˜µä¸­ç”¨ 255 ä¸ªå€¼è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The average distance between d1 and the other members of ğ’1, the average intra-cluster distance, is the average of these values, which is equal to 0.401, the a(i) value for d1 given in Table 10.2[611].",
            "zh": "d1 å’Œ C1 çš„å…¶ä»–æˆå‘˜ä¹‹é—´çš„å¹³å‡è·ç¦»ï¼Œå³å¹³å‡ç°‡å†…è·ç¦»ï¼Œæ˜¯è¿™äº›å€¼çš„å¹³å‡å€¼ï¼Œç­‰äº 0.401ï¼Œå³è¡¨ 10.2[611] ä¸­ç»™å‡ºçš„ d1 çš„ aï¼ˆiï¼‰ å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Surprisingly, however, as the number of descriptive features in a dataset increases, there often comes a point at which continuing to add new features to the dataset results in a decrease in the predictive power of the induced models.",
            "zh": "ç„¶è€Œï¼Œä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œéšç€æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾æ•°é‡çš„å¢åŠ ï¼Œé€šå¸¸ä¼šå‡ºç°ä¸€ä¸ªç‚¹ï¼Œå³ç»§ç»­å‘æ•°æ®é›†æ·»åŠ æ–°ç‰¹å¾ä¼šå¯¼è‡´è¯±å¯¼æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that, initially, the performance of the model on the validation set falls almost in line with the performance of the model on the training dataset (we usually expect the model to perform slightly better on the training set).",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæœ€åˆï¼Œæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½å‡ ä¹ä¸æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¸€è‡´ï¼ˆæˆ‘ä»¬é€šå¸¸æœŸæœ›æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°ç•¥å¥½ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.12",
            "zh": "å›¾ 6.12"
        }
    },
    {
        "translation": {
            "en": "The office rentals dataset from Table 7.1[313] adjusted to handle the categorical ENERGY RATING descriptive feature in linear regression models.",
            "zh": "è¡¨7.1[313]ä¸­çš„åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥å¤„ç†çº¿æ€§å›å½’æ¨¡å‹ä¸­çš„åˆ†ç±»ENERGY RATINGæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a non-parametric model the number of parameters used by the model increases as the number of instances increases.",
            "zh": "åœ¨éå‚æ•°æ¨¡å‹ä¸­ï¼Œæ¨¡å‹ä½¿ç”¨çš„å‚æ•°æ•°éšç€å®ä¾‹æ•°çš„å¢åŠ è€Œå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are 6 neurons in each of these layers because we are assuming a step size of 1, and so it requires six neurons to convolve one of these filters over the 7-by-1-by-3 input.",
            "zh": "æ¯å±‚éƒ½æœ‰ 6 ä¸ªç¥ç»å…ƒï¼Œå› ä¸ºæˆ‘ä»¬å‡è®¾æ­¥é•¿ä¸º 1ï¼Œå› æ­¤éœ€è¦ 6 ä¸ªç¥ç»å…ƒåœ¨ 7Ã—1Ã—3 è¾“å…¥ä¸Šå·ç§¯å…¶ä¸­ä¸€ä¸ªæ»¤æ³¢å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.13",
            "zh": "å›¾ 4.13"
        }
    },
    {
        "translation": {
            "en": "12. Similar to a hyperplane, a hypersphere is a generalization of the geometric concept of a sphere across multiple dimensions. Hence, in a 2D space the term hypersphere denotes a circle, in 3D it denotes a sphere, and so on.",
            "zh": "12. ä¸è¶…å¹³é¢ç±»ä¼¼ï¼Œè¶…çƒä½“æ˜¯çƒä½“å‡ ä½•æ¦‚å¿µåœ¨å¤šä¸ªç»´åº¦ä¸Šçš„æ¨å¹¿ã€‚å› æ­¤ï¼Œåœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œæœ¯è¯­è¶…çƒä½“è¡¨ç¤ºä¸€ä¸ªåœ†ï¼Œåœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œå®ƒè¡¨ç¤ºä¸€ä¸ªçƒä½“ï¼Œä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "AGE: The patientâ€™s age",
            "zh": "å¹´é¾„ï¼šæ‚£è€…çš„å¹´é¾„"
        }
    },
    {
        "translation": {
            "en": "For transitions based on the Stick action a large number of games of TwentyTwos have been simulated and transition probabilities have been calculated based on this simulation.11",
            "zh": "å¯¹äºåŸºäºæ‘‡æ†åŠ¨ä½œçš„è¿‡æ¸¡ï¼Œå·²ç»æ¨¡æ‹Ÿäº†å¤§é‡çš„ TwentyTwo æ¸¸æˆï¼Œå¹¶åŸºäºæ­¤æ¨¡æ‹Ÿè®¡ç®—äº†è¿‡æ¸¡æ¦‚ç‡11ã€‚"
        }
    },
    {
        "translation": {
            "en": "The argument for using a wrapper approach is that to get the best predictive accuracy, the inductive bias of the particular machine learning algorithm that will be used should be taken into consideration during feature selection.",
            "zh": "ä½¿ç”¨åŒ…è£…æ–¹æ³•çš„è®ºç‚¹æ˜¯ï¼Œä¸ºäº†è·å¾—æœ€ä½³çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œåœ¨ç‰¹å¾é€‰æ‹©è¿‡ç¨‹ä¸­åº”è€ƒè™‘å°†ä½¿ç”¨çš„ç‰¹å®šæœºå™¨å­¦ä¹ ç®—æ³•çš„å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The neurons in these max pooling layers have non-overlapping local receptive fields, and each local receptive field covers two cells in a feature map.",
            "zh": "è¿™äº›æœ€å¤§æ± åŒ–å±‚ä¸­çš„ç¥ç»å…ƒå…·æœ‰ä¸é‡å çš„å±€éƒ¨æ„Ÿå—é‡ï¼Œå¹¶ä¸”æ¯ä¸ªå±€éƒ¨æ„Ÿå—é‡è¦†ç›–ç‰¹å¾å›¾ä¸­çš„ä¸¤ä¸ªç»†èƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The defining characteristic of a feedforward network is that there are no loops or cycles in the network connections that would allow the output of a neuron to flow back into the neuron as an input (even indirectly).",
            "zh": "å‰é¦ˆç½‘ç»œçš„å®šä¹‰ç‰¹å¾æ˜¯ï¼Œç½‘ç»œè¿æ¥ä¸­æ²¡æœ‰å…è®¸ç¥ç»å…ƒè¾“å‡ºä½œä¸ºè¾“å…¥ï¼ˆç”šè‡³é—´æ¥ï¼‰æµå›ç¥ç»å…ƒçš„å¾ªç¯æˆ–å¾ªç¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are a lot of potential answers to this question, and that is why there are a lot of different machine learning algorithms.",
            "zh": "è¿™ä¸ªé—®é¢˜æœ‰å¾ˆå¤šå¯èƒ½çš„ç­”æ¡ˆï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰å¾ˆå¤šä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "From this CPT we can see that when SCHOOL YEARS = high, and LIFE EXP = high, then the most likely level is CPI = high.",
            "zh": "ä»è¿™ä¸ª CPT ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“ SCHOOL YEARS = é«˜ï¼Œè€Œ LIFE EXP = é«˜æ—¶ï¼Œé‚£ä¹ˆæœ€æœ‰å¯èƒ½çš„æ°´å¹³æ˜¯ CPI = é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The output gate uses a three-step process:",
            "zh": "è¾“å‡ºé—¨é‡‡ç”¨ä¸‰æ­¥å·¥è‰ºï¼š"
        }
    },
    {
        "translation": {
            "en": "2. we change the output layer of the network to be a softmax layer; and",
            "zh": "2. æˆ‘ä»¬å°†ç½‘ç»œçš„è¾“å‡ºå±‚æ›´æ”¹ä¸º softmax å±‚;å’Œ"
        }
    },
    {
        "translation": {
            "en": "The intelligent agent view of artificial intelligence overlaps to a large extent with machine learning but is a vibrant field in its own right.",
            "zh": "äººå·¥æ™ºèƒ½çš„æ™ºèƒ½ä»£ç†è§‚ç‚¹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¸æœºå™¨å­¦ä¹ é‡å ï¼Œä½†å…¶æœ¬èº«å°±æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›çš„é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross first assessed the level of missing values within the data.",
            "zh": "Ross é¦–å…ˆè¯„ä¼°äº†æ•°æ®ä¸­çš„ç¼ºå¤±å€¼æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "center",
            "zh": "ä¸­å¿ƒ"
        }
    },
    {
        "translation": {
            "en": "Figure 9.18(d)[582] shows how the stability index could be tracked for the bacterial species identification problem every month for a period of 12 months after model deployment.",
            "zh": "å›¾9.18ï¼ˆdï¼‰[582]æ˜¾ç¤ºäº†åœ¨æ¨¡å‹éƒ¨ç½²åçš„12ä¸ªæœˆå†…ï¼Œå¦‚ä½•æ¯æœˆè·Ÿè¸ªç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜çš„ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "ensemble, 117",
            "zh": "åˆå¥ï¼Œ 117"
        }
    },
    {
        "translation": {
            "en": "Levitt, Steven D., and Stephen J. Dubner. 2005. Freakonomics: A rogue economist explores the hidden side of everything. Penguin.",
            "zh": "è±ç»´ç‰¹ã€å²è’‚æ–‡ D. å’Œæ–¯è’‚èŠ¬ J. æœå¸ƒçº³ã€‚2005. æ€ªèƒç»æµå­¦ï¼šä¸€ä¸ªæµæ°“ç»æµå­¦å®¶æ¢ç´¢ä¸€åˆ‡éšè—çš„ä¸€é¢ã€‚ä¼é¹…ã€‚"
        }
    },
    {
        "translation": {
            "en": "For more detail on unsupervised machine learning algorithms (Friedman et al., 2001) has a fairly comprehensive unsupervised learning section that gives a broader sweep of approaches than those covered in this chapter.",
            "zh": "æœ‰å…³æ— ç›‘ç£æœºå™¨å­¦ä¹ ç®—æ³•çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼ˆFriedman et al.ï¼Œ 2001ï¼‰ï¼Œæœ‰ä¸€ä¸ªç›¸å½“å…¨é¢çš„æ— ç›‘ç£å­¦ä¹ éƒ¨åˆ†ï¼Œå®ƒæä¾›äº†æ¯”æœ¬ç« æ¶µç›–çš„æ–¹æ³•æ›´å¹¿æ³›çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "During the backward pass, once we have calculated the Î´s for the neurons in a layer, we multiply each neuronâ€™s Î´ by the corresponding element the DropMask vector that was created for that layer during the forward pass (Line 7[476]).",
            "zh": "åœ¨å‘åä¼ é€’è¿‡ç¨‹ä¸­ï¼Œä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†ä¸€å±‚ä¸­ç¥ç»å…ƒçš„ Î´ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªç¥ç»å…ƒçš„Î´ä¹˜ä»¥ç›¸åº”çš„å…ƒç´ ï¼Œå³åœ¨å‰å‘ä¼ é€’æœŸé—´ä¸ºè¯¥å±‚åˆ›å»ºçš„ DropMask å‘é‡ï¼ˆç¬¬ 7 è¡Œ[476]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.2â€…â€…â€…Irregular Cardinality",
            "zh": "3.3.2 ä¸è§„åˆ™åŸºæ•°"
        }
    },
    {
        "translation": {
            "en": "selection bias, 12",
            "zh": "é€‰æ‹©åå·®ï¼Œ12"
        }
    },
    {
        "translation": {
            "en": "Ideally, the topology of a network should reflect the causal relationships between the entities in a domain.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œç½‘ç»œçš„æ‹“æ‰‘åº”åæ˜ åŸŸä¸­å®ä½“ä¹‹é—´çš„å› æœå…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because both the parent nodes for CPI are known (SCHOOL YEARS and LIFE EXP), the probability distribution for CPI is independent of the GINI COEF feature.",
            "zh": "ç”±äº CPI çš„ä¸¤ä¸ªçˆ¶èŠ‚ç‚¹ï¼ˆSCHOOL YEARS å’Œ LIFE EXPï¼‰éƒ½æ˜¯å·²çŸ¥çš„ï¼Œå› æ­¤ CPI çš„æ¦‚ç‡åˆ†å¸ƒä¸ GINI COEF ç‰¹å¾æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gradient descent starts by selecting a random point within the weight space (i.e., each weight in the multivariable linear regression equation is assigned a random value within some sensible range) and calculating the sum of squared errors associated with this point based on predictions made for each instance in the training set using the randomly selected weights (as shown in Section 7.2.2[315]).",
            "zh": "æ¢¯åº¦ä¸‹é™é¦–å…ˆåœ¨æƒé‡ç©ºé—´ä¸­é€‰æ‹©ä¸€ä¸ªéšæœºç‚¹ï¼ˆå³ï¼Œå¤šå˜é‡çº¿æ€§å›å½’æ–¹ç¨‹ä¸­çš„æ¯ä¸ªæƒé‡åœ¨æŸä¸ªåˆç†èŒƒå›´å†…åˆ†é…ä¸€ä¸ªéšæœºå€¼ï¼‰ï¼Œå¹¶æ ¹æ®ä½¿ç”¨éšæœºé€‰æ‹©çš„æƒé‡å¯¹è®­ç»ƒé›†ä¸­æ¯ä¸ªå®ä¾‹æ‰€åšçš„é¢„æµ‹è®¡ç®—ä¸è¯¥ç‚¹ç›¸å…³çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼ˆå¦‚ç¬¬ 7.2.2 èŠ‚[315]æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the answers to the following questions, assume that after the initial cards have been dealt to the player and the dealer, the following cards are coming up next in the deck: 10 â™¥, 2 â™£, 7 â™£, K â™¥, 9 â™¦.",
            "zh": "åœ¨ä»¥ä¸‹é—®é¢˜çš„ç­”æ¡ˆä¸­ï¼Œå‡è®¾åœ¨å°†åˆå§‹ç‰Œå‘ç»™ç©å®¶å’Œåº„å®¶åï¼Œä»¥ä¸‹ç‰Œå°†å‡ºç°åœ¨ç‰Œç»„ä¸­ï¼š10 â™¥ã€2 â™£ã€7 â™£ã€K â™¥ã€9 â™¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Normalization techniques can be used to change a continuous feature to fall within a specified range while maintaining the relative differences between the values for the feature.",
            "zh": "å½’ä¸€åŒ–æŠ€æœ¯å¯ç”¨äºå°†è¿ç»­è¦ç´ æ›´æ”¹ä¸ºè½åœ¨æŒ‡å®šèŒƒå›´å†…ï¼ŒåŒæ—¶ä¿æŒè¦ç´ å€¼ä¹‹é—´çš„ç›¸å¯¹å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian information criterion, 292",
            "zh": "è´å¶æ–¯ä¿¡æ¯å‡†åˆ™ï¼Œ292"
        }
    },
    {
        "translation": {
            "en": "identity criterion, 184, 211",
            "zh": "èº«ä»½æ ‡å‡†ï¼Œ184,211"
        }
    },
    {
        "translation": {
            "en": "The template structure of these computational models was first defined by McCulloch and Pitts (1943).",
            "zh": "è¿™äº›è®¡ç®—æ¨¡å‹çš„æ¨¡æ¿ç»“æ„é¦–å…ˆç”± McCulloch å’Œ Pitts ï¼ˆ1943ï¼‰ å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 1996. Bagging predictors. Machine Learning 24 (2): 123â€“140.",
            "zh": "å¸ƒè±æ›¼ï¼Œç‹®å­åº§ã€‚1996. è£…è¢‹é¢„æµ‹å› å­ã€‚æœºå™¨å­¦ä¹  24 ï¼ˆ2ï¼‰ï¼š123â€“140ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.6[206] lists these distances when we include both the SALARY and AGE features, only the SALARY features, and only the AGE feature in the distance calculation.",
            "zh": "è¡¨ 5.6[206] åˆ—å‡ºäº†å½“æˆ‘ä»¬åœ¨è·ç¦»è®¡ç®—ä¸­åŒæ—¶åŒ…æ‹¬ SALARY å’Œ AGE ç‰¹å¾ã€ä»…åŒ…æ‹¬ SALARY ç‰¹å¾å’Œ AGE ç‰¹å¾æ—¶çš„è¿™äº›è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability density function, 61, 246, 269, 758",
            "zh": "æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œ 61ï¼Œ 246ï¼Œ 269ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "A good approach is to use box plots to initially determine which pairs of features might have a strong relationship and then further investigate these pairs using small multiple histograms.",
            "zh": "ä¸€ä¸ªå¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ç®±å½¢å›¾æ¥åˆæ­¥ç¡®å®šå“ªäº›ç‰¹å¾å¯¹å¯èƒ½å…·æœ‰å¾ˆå¼ºçš„å…³ç³»ï¼Œç„¶åä½¿ç”¨å°çš„å¤šé‡ç›´æ–¹å›¾è¿›ä¸€æ­¥ç ”ç©¶è¿™äº›ç‰¹å¾å¯¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Vâ€…â€…â€…APPENDICES",
            "zh": "äº” é™„å½•"
        }
    },
    {
        "translation": {
            "en": "Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. 2018. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science 362 (6419): 1140â€“1144. doi:10.1126/science.aar6404.",
            "zh": "è¥¿å°”å¼—ã€å¤§å«ã€æ‰˜é©¬æ–¯Â·ä¼‘ä¼¯ç‰¹ã€æœ±åˆ©å®‰Â·æ–½é‡Œç‰¹ç»´ç‘Ÿã€æ‰¬å°¼æ–¯Â·å®‰ä¸œè¯ºæ ¼é²ã€é©¬ä¿®Â·èµ–ã€äºšç‘ŸÂ·ç›–å…¹ã€é©¬å…‹Â·å…°å…‹æ‰˜ã€æ´›æœ—Â·è¥¿å¼—å°”ã€è¾¾å±±Â·åº“é©¬å…°ã€ç´¢å°”Â·æ ¼é›·ä½©å°”ã€è’‚è«è¥¿Â·åˆ©åˆ©å…‹æ‹‰æ™®ã€å‡¯ä¼¦Â·è¥¿è’™å°¼æ‰¬å’Œå¾·ç±³æ–¯Â·å“ˆè¨æ¯”æ–¯ã€‚2018. æŒæ¡å›½é™…è±¡æ£‹ã€å°†æ£‹å’Œè‡ªå­¦çš„é€šç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•.ç§‘å­¦362ï¼ˆ6419ï¼‰ï¼š1140-1144ã€‚doiï¼š10.1126/science.aar6404."
        }
    },
    {
        "translation": {
            "en": "It is possible, however, to successfully use measures of similarity in similarity-based models that do not satisfy all four of these criteria.",
            "zh": "ç„¶è€Œï¼Œåœ¨åŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹ä¸­ï¼Œæœ‰å¯èƒ½æˆåŠŸåœ°ä½¿ç”¨ç›¸ä¼¼æ€§åº¦é‡ï¼Œè€Œè¿™äº›æ¨¡å‹å¹¶ä¸æ»¡è¶³æ‰€æœ‰è¿™å››ä¸ªæ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, if there is an interaction effect between two or more descriptive features, a decision tree can model this.",
            "zh": "å› æ­¤ï¼Œå¦‚æœä¸¤ä¸ªæˆ–å¤šä¸ªæè¿°æ€§ç‰¹å¾ä¹‹é—´å­˜åœ¨äº¤äº’æ•ˆåº”ï¼Œåˆ™å†³ç­–æ ‘å¯ä»¥å¯¹æ­¤è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This insight into the likely future behavior of a customer can help a marketing department decide which customers coming close to the end of their trial period the department should contact to promote the benefits of signup to the paid service.",
            "zh": "è¿™ç§å¯¹å®¢æˆ·æœªæ¥å¯èƒ½è¡Œä¸ºçš„æ´å¯Ÿå¯ä»¥å¸®åŠ©è¥é”€éƒ¨é—¨å†³å®šå“ªäº›å®¢æˆ·å³å°†ç»“æŸè¯•ç”¨æœŸï¼Œè¯¥éƒ¨é—¨åº”è¯¥è”ç³»å“ªäº›å®¢æˆ·ï¼Œä»¥ä¿ƒè¿›æ³¨å†Œä»˜è´¹æœåŠ¡çš„å¥½å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.6[608] illustrates these two types of distances along with examples of a good and a bad clusteringâ€”according to this definition.",
            "zh": "å›¾ 10.6[608] æ ¹æ®æ­¤å®šä¹‰ï¼Œè¯´æ˜äº†è¿™ä¸¤ç§ç±»å‹çš„è·ç¦»ä»¥åŠè‰¯å¥½å’Œä¸è‰¯èšç±»çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Trask, Andrew. 2019. Grokking deep learning. Manning.",
            "zh": "ç‰¹æ‹‰æ–¯å…‹ï¼Œå®‰å¾·é²ã€‚2019. Grokking æ·±åº¦å­¦ä¹ .æ›¼å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, there is rapid progress within the field, with new techniques and network architectures being published every month.",
            "zh": "å› æ­¤ï¼Œè¯¥é¢†åŸŸå–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œæ¯ä¸ªæœˆéƒ½ä¼šå‘å¸ƒæ–°æŠ€æœ¯å’Œç½‘ç»œæ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.21[581] shows an example of how the stability index could be calculated for two different sets of query instances collected at two different times after model deployment based on the bacterial species identification problem given in Table 9.18[573].",
            "zh": "è¡¨9.21[581]æ˜¾ç¤ºäº†å¦‚ä½•æ ¹æ®è¡¨9.18[573]ä¸­ç»™å‡ºçš„ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜ï¼Œè®¡ç®—æ¨¡å‹éƒ¨ç½²ååœ¨ä¸¤ä¸ªä¸åŒæ—¶é—´æ”¶é›†çš„ä¸¤ç»„ä¸åŒæŸ¥è¯¢å®ä¾‹çš„ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The transition matrix is also shown.",
            "zh": "è¿˜æ˜¾ç¤ºäº†è¿‡æ¸¡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the training set to train a model and the test set to evaluate it, a performance measure (or measures) is calculated for this iteration.",
            "zh": "ä½¿ç”¨è®­ç»ƒé›†æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨æµ‹è¯•é›†æ¥è¯„ä¼°æ¨¡å‹ï¼Œä¸ºæ­¤è¿­ä»£è®¡ç®—ä¸€ä¸ªæˆ–å¤šä¸ªæ€§èƒ½åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAGERR_U/G/R/I/Z",
            "zh": "PETROMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "state, 640, 643, 676",
            "zh": "å·ï¼Œ 640ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "A joint probability distribution is a multidimensional matrix where each cell in the matrix lists the probability for one of the events in the sample space defined by the combination of feature values.",
            "zh": "è”åˆæ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸€ä¸ªå¤šç»´çŸ©é˜µï¼Œå…¶ä¸­çŸ©é˜µä¸­çš„æ¯ä¸ªå•å…ƒæ ¼éƒ½åˆ—å‡ºäº†ç”±ç‰¹å¾å€¼ç»„åˆå®šä¹‰çš„æ ·æœ¬ç©ºé—´ä¸­æŸä¸ªäº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.3â€…â€…â€…Markov Decision Processes",
            "zh": "11.2.3 é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹"
        }
    },
    {
        "translation": {
            "en": "The final one-versus-all decision boundaries shown in the bottom-middle panel of Figure 7.21[360] do not look like the individual one-versus-all decision boundaries shown in Figure 7.20[358].",
            "zh": "å›¾7.21[360]åº•éƒ¨é¢æ¿ä¸­æ˜¾ç¤ºçš„æœ€ç»ˆä¸€å¯¹å…¨å†³ç­–è¾¹ç•Œçœ‹èµ·æ¥ä¸å›¾7.20[358]ä¸­æ˜¾ç¤ºçš„å•ä¸ªä¸€å¯¹å…¨å†³ç­–è¾¹ç•Œä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "With the exception of the definition of the target feature, data that will be used to define a feature must be available before the event around which we are trying to make predictions occurs.",
            "zh": "é™¤äº†ç›®æ ‡ç‰¹å¾çš„å®šä¹‰ä¹‹å¤–ï¼Œå°†ç”¨äºå®šä¹‰ç‰¹å¾çš„æ•°æ®å¿…é¡»åœ¨æˆ‘ä»¬è¯•å›¾è¿›è¡Œé¢„æµ‹çš„äº‹ä»¶å‘ç”Ÿä¹‹å‰å¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many instances the SDSS dataset contained the same measurement for a night sky object measured separately for each of the five photometric bands covered by the SDSS telescope.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼ŒSDSSæ•°æ®é›†åŒ…å«å¯¹å¤œç©ºå¤©ä½“çš„ç›¸åŒæµ‹é‡å€¼ï¼Œåˆ†åˆ«æµ‹é‡SDSSæœ›è¿œé•œè¦†ç›–çš„äº”ä¸ªå…‰åº¦æ³¢æ®µä¸­çš„æ¯ä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "Factorizing the domain representation reduces the number of interactions between the features and reduces the number of model parameters.",
            "zh": "åˆ†è§£åŸŸè¡¨ç¤ºå¯å‡å°‘ç‰¹å¾ä¹‹é—´çš„äº¤äº’æ¬¡æ•°å¹¶å‡å°‘æ¨¡å‹å‚æ•°çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that a dataset in which the majority of descriptive features have zero as the value is known as sparse data.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œå¤§å¤šæ•°æè¿°æ€§ç‰¹å¾çš„å€¼ä¸ºé›¶çš„æ•°æ®é›†ç§°ä¸ºç¨€ç–æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "RISK",
            "zh": "é£é™©"
        }
    },
    {
        "translation": {
            "en": "Lines 1â€“6 of Algorithm 1[134] control when a new leaf node is created in the tree.",
            "zh": "ç®—æ³• 1[134] çš„ç¬¬ 1-6 è¡Œæ§åˆ¶ä½•æ—¶åœ¨æ ‘ä¸­åˆ›å»ºæ–°çš„å¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.2â€ƒContinuous Features: Probability Density Functions",
            "zh": "6.4.2 è¿ç»­ç‰¹å¾ï¼šæ¦‚ç‡å¯†åº¦å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "GALAXY_CLASS_3",
            "zh": "GALAXY_CLASS_3"
        }
    },
    {
        "translation": {
            "en": "outcome, 757, 758",
            "zh": "æˆæœï¼Œ 757ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "8.2â€…â€…â€…Plots for activation functions that have been popular in the history of neural networks.",
            "zh": "8.2 ç¥ç»ç½‘ç»œå†å²ä¸Šæµè¡Œçš„æ¿€æ´»å‡½æ•°å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "With this model selected as the best performing approach, Jocelyn was ready to perform the final evaluation experiment.",
            "zh": "å°†è¯¥æ¨¡å‹é€‰ä¸ºæœ€ä½³æ€§èƒ½æ–¹æ³•åï¼ŒJocelyn å·²å‡†å¤‡å¥½è¿›è¡Œæœ€ç»ˆè¯„ä¼°å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.5â€…â€…â€…Modeling Non-Linear Relationships",
            "zh": "7.4.5 éçº¿æ€§å…³ç³»å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "restriction bias, 11, 357",
            "zh": "é™åˆ¶åå·®ï¼Œ 11ï¼Œ 357"
        }
    },
    {
        "translation": {
            "en": "5.2.1â€ƒFeature Space",
            "zh": "5.2.1 åŠŸèƒ½ç©ºé—´"
        }
    },
    {
        "translation": {
            "en": "Histograms show more detail than box plots, so small multiple histograms offer a more detailed view of the relationship between two features.",
            "zh": "ç›´æ–¹å›¾æ¯”ç®±å½¢å›¾æ˜¾ç¤ºæ›´å¤šç»†èŠ‚ï¼Œå› æ­¤è¾ƒå°çš„å¤šä¸ªç›´æ–¹å›¾å¯ä»¥æ›´è¯¦ç»†åœ°æŸ¥çœ‹ä¸¤ä¸ªè¦ç´ ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter1 we introduce deep learning, an approach to machine learning that is inspired by how the brain is structured and operates.",
            "zh": "åœ¨æœ¬ç« 1ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ·±åº¦å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå…¶çµæ„Ÿæ¥è‡ªå¤§è„‘çš„ç»“æ„å’Œè¿ä½œæ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "è¡¨8.3[423]ä¸­åˆ—å‡ºçš„ç¤ºä¾‹é€šè¿‡å›¾8.4[390]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, although this feature doesnâ€™t perfectly discriminate between spam and ham, it does give us some information that we might be able to use in conjunction with other features to help decide whether a new email is spam or ham.",
            "zh": "å› æ­¤ï¼Œå°½ç®¡æ­¤åŠŸèƒ½ä¸èƒ½å®Œå…¨åŒºåˆ†åƒåœ¾é‚®ä»¶å’Œç«è…¿ï¼Œä½†å®ƒç¡®å®ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›ä¿¡æ¯ä¸å…¶ä»–åŠŸèƒ½ç»“åˆä½¿ç”¨ï¼Œä»¥å¸®åŠ©ç¡®å®šæ–°ç”µå­é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯ç«è…¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "For categorical prediction problems, use average class accuracy based on a harmonic mean.",
            "zh": "å¯¹äºåˆ†ç±»é¢„æµ‹é—®é¢˜ï¼Œè¯·ä½¿ç”¨åŸºäºè°æ³¢å‡å€¼çš„å¹³å‡ç±»å‡†ç¡®ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.2â€ƒGetting to Know the Data",
            "zh": "3.2 äº†è§£æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(b)[329] shows that a well-chosen learning rate strikes a good balance, converging quickly but also ensuring that the global minimum is reached.",
            "zh": "å›¾7.7ï¼ˆbï¼‰[329]æ˜¾ç¤ºï¼Œç²¾å¿ƒé€‰æ‹©çš„å­¦ä¹ ç‡å¯ä»¥è¾¾åˆ°è‰¯å¥½çš„å¹³è¡¡ï¼Œå¿«é€Ÿæ”¶æ•›ï¼Œä½†ä¹Ÿèƒ½ç¡®ä¿è¾¾åˆ°å…¨çƒæœ€ä½é™åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once this tipping point in dataset size has been surpassed, a discriminative model will outperform a generative model.",
            "zh": "ä¸€æ—¦è¶…è¿‡æ•°æ®é›†å¤§å°çš„è¿™ä¸ªä¸´ç•Œç‚¹ï¼Œåˆ¤åˆ«æ¨¡å‹çš„æ€§èƒ½å°†ä¼˜äºç”Ÿæˆæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Precision tells us how confident we can be that an instance predicted to have the positive target level actually has the positive target level.",
            "zh": "ç²¾åº¦å‘Šè¯‰æˆ‘ä»¬ï¼Œé¢„æµ‹å…·æœ‰æ­£ç›®æ ‡æ°´å¹³çš„å®ä¾‹å®é™…ä¸Šå…·æœ‰æ­£ç›®æ ‡æ°´å¹³ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰å¤šå¤§çš„ä¿¡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "3. In the extreme case with p = âˆ, the Minkowski metric simply returns the maximum difference between any of the features. This is known as the Chebyshev distance but is also sometimes called the chessboard distance because it is the number of moves a king must make in chess to go from one square on the board to any other.",
            "zh": "3. åœ¨ p = âˆ çš„æç«¯æƒ…å†µä¸‹ï¼ŒMinkowski åº¦é‡ä»…è¿”å›ä»»ä½•ç‰¹å¾ä¹‹é—´çš„æœ€å¤§å·®å€¼ã€‚è¿™è¢«ç§°ä¸ºåˆ‡æ¯”é›ªå¤«è·ç¦»ï¼Œä½†æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºæ£‹ç›˜è·ç¦»ï¼Œå› ä¸ºå®ƒæ˜¯å›½ç‹åœ¨å›½é™…è±¡æ£‹ä¸­ä»æ£‹ç›˜ä¸Šçš„ä¸€ä¸ªæ–¹æ ¼åˆ°å¦ä¸€ä¸ªæ–¹æ ¼å¿…é¡»èµ°çš„æ­¥æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It also, however, illustrates an issue with using variance.",
            "zh": "ä½†æ˜¯ï¼Œå®ƒä¹Ÿè¯´æ˜äº†ä½¿ç”¨æ–¹å·®çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter, affine and linear functions are so closely associated that we often use the term linear to refer to affine operations.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œä»¿å°„å‡½æ•°å’Œçº¿æ€§å‡½æ•°å¯†åˆ‡ç›¸å…³ï¼Œä»¥è‡³äºæˆ‘ä»¬ç»å¸¸ä½¿ç”¨æœ¯è¯­çº¿æ€§æ¥æŒ‡ä»£ä»¿å°„æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "where d is a set of m descriptive features, w is a set of b weights, and Ï•0 to Ï•b are a series of b basis functions that each transform the input vector d in a different way. It is worth noting that there is no reason that b must equal m, and usually b is quite a bit larger than mâ€”that is, there are usually more basis functions than there are descriptive features.",
            "zh": "å…¶ä¸­ d æ˜¯ä¸€ç»„ m æè¿°æ€§ç‰¹å¾ï¼Œw æ˜¯ä¸€ç»„ b æƒé‡ï¼ŒÏ†0 åˆ° Ï†b æ˜¯ä¸€ç³»åˆ— b åŸºå‡½æ•°ï¼Œæ¯ä¸ªå‡½æ•°ä»¥ä¸åŒçš„æ–¹å¼è½¬æ¢è¾“å…¥å‘é‡ dã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ²¡æœ‰ç†ç”± b å¿…é¡»ç­‰äº mï¼Œè€Œä¸”é€šå¸¸ b æ¯” m å¤§å¾—å¤šâ€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼ŒåŸºå‡½æ•°é€šå¸¸å¤šäºæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The deep Q network algorithm can be used with any state representation that can be input into a neural network, and can use different neural network architectures.",
            "zh": "æ·±åº¦ Q ç½‘ç»œç®—æ³•å¯ä»¥ä¸ä»»ä½•å¯ä»¥è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­çš„çŠ¶æ€è¡¨ç¤ºä¸€èµ·ä½¿ç”¨ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ä¸åŒçš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. These charts are often referred to as Pareto charts, especially when they also include a line indicating the cumulative total frequency or density.",
            "zh": "6. è¿™äº›å›¾è¡¨é€šå¸¸è¢«ç§°ä¸ºå¸•ç´¯æ‰˜å›¾ï¼Œç‰¹åˆ«æ˜¯å½“å®ƒä»¬è¿˜åŒ…æ‹¬ä¸€æ¡è¡¨ç¤ºç´¯ç§¯æ€»é¢‘ç‡æˆ–å¯†åº¦çš„çº¿æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.6â€…â€…â€…Multinomial Logistic Regression",
            "zh": "7.4.6 å¤šé¡¹å¼é€»è¾‘å›å½’"
        }
    },
    {
        "translation": {
            "en": "So, even when we take the evidence into account, the posterior probability of having meningitis remains low.",
            "zh": "å› æ­¤ï¼Œå³ä½¿æˆ‘ä»¬è€ƒè™‘åˆ°è¯æ®ï¼Œæ‚£è„‘è†œç‚çš„åéªŒæ¦‚ç‡ä»ç„¶å¾ˆä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the history of artificial neural networks can be traced back to the 1940s, the term deep learning came to prominence only in the mid-2000s.2 The term deep learning emphasizes that modern networks are deeper (in terms of number of layers) than previous networks.",
            "zh": "å°½ç®¡äººå·¥ç¥ç»ç½‘ç»œçš„å†å²å¯ä»¥è¿½æº¯åˆ° 1940 å¹´ä»£ï¼Œä½†æ·±åº¦å­¦ä¹ ä¸€è¯ç›´åˆ° 2000 å¹´ä»£ä¸­æœŸæ‰å¼€å§‹å´­éœ²å¤´è§’.2 æ·±åº¦å­¦ä¹ ä¸€è¯å¼ºè°ƒç°ä»£ç½‘ç»œï¼ˆå°±å±‚æ•°è€Œè¨€ï¼‰æ¯”ä»¥å‰çš„ç½‘ç»œæ›´æ·±ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.2â€ƒWeight Initialization and Unstable Gradients",
            "zh": "8.4.2 æƒé‡åˆå§‹åŒ–å’Œä¸ç¨³å®šæ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "The book is detailed, rigorous, and easy to read.",
            "zh": "è¿™æœ¬ä¹¦è¯¦ç»†ã€ä¸¥è°¨ã€æ˜“äºé˜…è¯»ã€‚"
        }
    },
    {
        "translation": {
            "en": "separating hyperplane, 362",
            "zh": "åˆ†ç¦»è¶…å¹³é¢ï¼Œ362"
        }
    },
    {
        "translation": {
            "en": "Table 7.2",
            "zh": "è¡¨ 7.2"
        }
    },
    {
        "translation": {
            "en": "Indexes",
            "zh": "æŒ‡æ ‡"
        }
    },
    {
        "translation": {
            "en": "subset generation, 228",
            "zh": "å­é›†ç”Ÿæˆï¼Œ228"
        }
    },
    {
        "translation": {
            "en": "The value of w0 is âˆ’ 0.1838, and the values of the Î± parameters are 23.056, 6.998, 16.058).",
            "zh": "w0 çš„å€¼ä¸º âˆ’ 0.1838ï¼ŒÎ±å‚æ•°çš„å€¼ä¸º 23.056ã€6.998ã€16.058ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to evaluate the effect this model was having on the companyâ€™s churn problem, they performed a comparative experiment.",
            "zh": "ä¸ºäº†è¯„ä¼°è¯¥æ¨¡å‹å¯¹å…¬å¸æµå¤±é—®é¢˜çš„å½±å“ï¼Œä»–ä»¬è¿›è¡Œäº†ä¸€é¡¹æ¯”è¾ƒå®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network can have any structure, but a layer-based organization of neurons is common.",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œå¯ä»¥å…·æœ‰ä»»ä½•ç»“æ„ï¼Œä½†åŸºäºå±‚çš„ç¥ç»å…ƒç»„ç»‡å¾ˆå¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The covariance matrix, usually denoted as âˆ‘, between a set of continuous features, {a,b,â€¦,z}, is given as",
            "zh": "ä¸€ç»„è¿ç»­ç‰¹å¾ {aï¼Œb,...,z} ä¹‹é—´çš„åæ–¹å·®çŸ©é˜µï¼ˆé€šå¸¸è¡¨ç¤ºä¸º âˆ‘ï¼‰è¡¨ç¤ºä¸º"
        }
    },
    {
        "translation": {
            "en": "Equation (8.27)[414] defined how the rate of change of the error of a network with respect to a weight in the network âˆ‚â„°/âˆ‚wi,k can be calculated using the chain rule.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.27ï¼‰[414]å®šä¹‰äº†å¦‚ä½•ä½¿ç”¨é“¾å¼æ³•åˆ™è®¡ç®—ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç½‘ç»œæƒé‡çš„å˜åŒ–ç‡âˆ‚E/âˆ‚wiï¼Œkã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we must backpropagate the error at time t to all the parameters that contributed to the error.",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»å°†æ—¶é—´ t çš„è¯¯å·®åå‘ä¼ æ’­åˆ°å¯¼è‡´è¯¯å·®çš„æ‰€æœ‰å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19(f)[356] shows a 3D plot of the final decision surface.",
            "zh": "å›¾7.19ï¼ˆfï¼‰[356]æ˜¾ç¤ºäº†æœ€ç»ˆå†³ç­–é¢çš„3Då›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of prediction models built for continuous targets, there are fewer options to choose from.",
            "zh": "åœ¨è¯„ä¼°ä¸ºè¿ç»­ç›®æ ‡æ„å»ºçš„é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½æ—¶ï¼Œå¯ä¾›é€‰æ‹©çš„é€‰é¡¹è¾ƒå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is the organizational problem being addressed? In what ways could a prediction model address the organizational problem? Do we have situational fluency? What is the capacity of the organization to utilize the output of a prediction model? What data is available?",
            "zh": "æ­£åœ¨è§£å†³çš„ç»„ç»‡é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿé¢„æµ‹æ¨¡å‹å¯ä»¥é€šè¿‡å“ªäº›æ–¹å¼è§£å†³ç»„ç»‡é—®é¢˜ï¼Ÿæˆ‘ä»¬æœ‰æƒ…å¢ƒæµç•…æ€§å—ï¼Ÿç»„ç»‡åˆ©ç”¨é¢„æµ‹æ¨¡å‹è¾“å‡ºçš„èƒ½åŠ›å¦‚ä½•ï¼Ÿæœ‰å“ªäº›æ•°æ®å¯ç”¨ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "k Nearest Neighbor",
            "zh": "k æœ€è¿‘é‚»"
        }
    },
    {
        "translation": {
            "en": "ğ•„w refers to a model ğ•„ parameterized by a parameter vector w.",
            "zh": "Mw æ˜¯æŒ‡ç”±å‚æ•°å‘é‡ w å‚æ•°åŒ–çš„æ¨¡å‹ Mã€‚"
        }
    },
    {
        "translation": {
            "en": "A frequency table for the POSITION feature from the school basketball team dataset in Table A.1[750].",
            "zh": "è¡¨A.1[750]ä¸­å­¦æ ¡ç¯®çƒé˜Ÿæ•°æ®é›†ä¸­POSITIONç‰¹å¾çš„é¢‘ç‡è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the developers of a smartphone app might decide that by turning on location tracking, they could gather data that would be extremely useful in predicting future usage of the app.",
            "zh": "ä¾‹å¦‚ï¼Œæ™ºèƒ½æ‰‹æœºåº”ç”¨ç¨‹åºçš„å¼€å‘äººå‘˜å¯èƒ½ä¼šå†³å®šï¼Œé€šè¿‡æ‰“å¼€ä½ç½®è·Ÿè¸ªï¼Œä»–ä»¬å¯ä»¥æ”¶é›†æ•°æ®ï¼Œè¿™äº›æ•°æ®å¯¹äºé¢„æµ‹åº”ç”¨ç¨‹åºçš„æœªæ¥ä½¿ç”¨æƒ…å†µéå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the partial derivative of a weighted sum function with respect to a weight simplifies to the derivative of the product of the weight by its input that is equal to the input the weight is applied to",
            "zh": "è¿™æ„å‘³ç€åŠ æƒå’Œå‡½æ•°ç›¸å¯¹äºæƒé‡çš„åå¯¼æ•°ç®€åŒ–ä¸ºæƒé‡ä¹˜ç§¯çš„å¯¼æ•°ï¼Œå…¶è¾“å…¥ç­‰äºæ–½åŠ æƒé‡çš„è¾“å…¥"
        }
    },
    {
        "translation": {
            "en": "If the LSTM used only sigmoid units, then the activations in the cell would monotonically increase across time and this would have the unwanted consequence of the cell state tending to saturate with maximum activations as the sequence of time-steps increases, irrespective of the inputs.",
            "zh": "å¦‚æœLSTMä»…ä½¿ç”¨ä¹™çŠ¶ç»“è‚ å•ä½ï¼Œåˆ™ç»†èƒä¸­çš„æ¿€æ´»å°†éšæ—¶é—´å•è°ƒå¢åŠ ï¼Œè¿™å°†äº§ç”Ÿä¸è‰¯åæœï¼Œå³éšç€æ—¶é—´æ­¥é•¿åºåˆ—çš„å¢åŠ ï¼Œç»†èƒçŠ¶æ€è¶‹äºé¥±å’Œï¼Œå…·æœ‰æœ€å¤§çš„æ¿€æ´»ï¼Œè€Œä¸è¾“å…¥æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Demographics: Demographic features of users or customers such as age, gender, occupation, and address.",
            "zh": "äººå£ç»Ÿè®¡ï¼šç”¨æˆ·æˆ–å®¢æˆ·çš„äººå£ç»Ÿè®¡ç‰¹å¾ï¼Œä¾‹å¦‚å¹´é¾„ã€æ€§åˆ«ã€èŒä¸šå’Œåœ°å€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kaufman, Leonard, and Peter J. Rousseeuw. 1990. Finding groups in data: An introduction to cluster analysis. Wiley.",
            "zh": "è€ƒå¤«æ›¼ã€ä¼¦çº³å¾·å’Œå½¼å¾— J. Rousseeuwã€‚1990. åœ¨æ•°æ®ä¸­æŸ¥æ‰¾ç»„ï¼šèšç±»åˆ†æç®€ä»‹ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The probability mass is simply the probability of an event.",
            "zh": "æ¦‚ç‡è´¨é‡åªæ˜¯äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each Î´ expresses the rate of change (or sensitivity) of the error of the network with respect to changes in the weighted sum calculation of a specific neuron.",
            "zh": "æ¯ä¸ªÎ´è¡¨ç¤ºç½‘ç»œè¯¯å·®çš„å˜åŒ–ç‡ï¼ˆæˆ–çµæ•åº¦ï¼‰ä¸ç‰¹å®šç¥ç»å…ƒçš„åŠ æƒå’Œè®¡ç®—çš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "11. This artificially generated example dataset is inspired by the research reported in Franklin et al. (2000).",
            "zh": "11. è¿™ä¸ªäººå·¥ç”Ÿæˆçš„ç¤ºä¾‹æ•°æ®é›†çš„çµæ„Ÿæ¥è‡ªFranklinç­‰äººï¼ˆ2000å¹´ï¼‰æŠ¥å‘Šçš„ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.5â€…â€…â€…(a)â€“(d) Initial centroids chosen using the k-means++ approach (all with k = 3) for the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "10.5 ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ ä½¿ç”¨è¡¨ 10.1[604] ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ k-means++ æ–¹æ³•é€‰æ‹©çš„åˆå§‹è´¨å¿ƒï¼ˆå‡ä¸º k = 3ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Section 7.6[370] recommends further reading on this topic.",
            "zh": "ç¬¬7.6èŠ‚[370]å»ºè®®è¿›ä¸€æ­¥é˜…è¯»æ­¤ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In spite of the modelâ€™s difficulty distinguishing between the clockwise and anti-clockwise spiral galaxies, Jocelyn did perform an evaluation of the two-stage model.",
            "zh": "å°½ç®¡è¯¥æ¨¡å‹éš¾ä»¥åŒºåˆ†é¡ºæ—¶é’ˆå’Œé€†æ—¶é’ˆèºæ—‹æ˜Ÿç³»ï¼Œä½†Jocelynç¡®å®å¯¹ä¸¤é˜¶æ®µæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Range normalization has the drawback that it is quite sensitive to the presence of outliers in a dataset. Another way to normalize data is to standardize it into standard scores.10 A standard score measures how many standard deviations a feature value is from the mean for that feature. To calculate a standard score, we compute the mean and standard deviation for the feature and normalize the feature values using the following equation:",
            "zh": "èŒƒå›´å½’ä¸€åŒ–çš„ç¼ºç‚¹æ˜¯å®ƒå¯¹æ•°æ®é›†ä¸­å¼‚å¸¸å€¼çš„å­˜åœ¨éå¸¸æ•æ„Ÿã€‚è§„èŒƒåŒ–æ•°æ®çš„å¦ä¸€ç§æ–¹æ³•æ˜¯å°†å…¶æ ‡å‡†åŒ–ä¸ºæ ‡å‡†åˆ†æ•°ã€‚10 æ ‡å‡†åˆ†æ•°è¡¡é‡ç‰¹å¾å€¼ä¸è¯¥ç‰¹å¾çš„å¹³å‡å€¼æœ‰å¤šå°‘ä¸ªæ ‡å‡†å·®ã€‚ä¸ºäº†è®¡ç®—æ ‡å‡†åˆ†æ•°ï¼Œæˆ‘ä»¬è®¡ç®—ç‰¹å¾çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¹¶ä½¿ç”¨ä»¥ä¸‹å…¬å¼å¯¹ç‰¹å¾å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼š"
        }
    },
    {
        "translation": {
            "en": "11.10â€…â€…â€…(a) Frames from an episode early in the training process in which the agent performs poorly. (b) Frames from an episode near the end of the learning process where the agent is starting to be very effective. (c) Changing episode returns during DQN training. The gray line shows a 50-episode moving average to better highlight the trend.",
            "zh": "11.10 ï¼ˆaï¼‰ åœ¨è®­ç»ƒè¿‡ç¨‹æ—©æœŸï¼Œæ™ºèƒ½ä½“è¡¨ç°ä¸ä½³çš„æƒ…èŠ‚ã€‚ï¼ˆbï¼‰ åœ¨å­¦ä¹ è¿‡ç¨‹æ¥è¿‘å°¾å£°æ—¶ï¼Œæ™ºèƒ½ä½“å¼€å§‹å˜å¾—éå¸¸æœ‰æ•ˆçš„ä¸€é›†çš„å¸§ã€‚ï¼ˆcï¼‰ åœ¨ DQN è®­ç»ƒæœŸé—´æ›´æ”¹å‰§é›†è¿”å›ã€‚ç°çº¿æ˜¾ç¤º 50 é›†çš„ç§»åŠ¨å¹³å‡çº¿ï¼Œä»¥æ›´å¥½åœ°çªå‡ºè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Things become a little more complex when a recurrent network is applied to a sequence of inputs.",
            "zh": "å½“å°†å¾ªç¯ç½‘ç»œåº”ç”¨äºä¸€ç³»åˆ—è¾“å…¥æ—¶ï¼Œäº‹æƒ…ä¼šå˜å¾—æ›´åŠ å¤æ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tempel, E., E. Saar, L. J. LiivamÃ¤gi, A. Tamm, J. Einasto, M. Einasto, and V. MÃ¼ller. 2011. Galaxy morphology, luminosity, and environment in the SDSS DR7. A&A 529: 53. doi:10.1051/0004-6361/201016196.",
            "zh": "Tempelï¼Œ E.ï¼Œ E. Saarï¼Œ L. J. LiivamÃ¤giï¼Œ A. Tammï¼Œ J. Einastoï¼Œ M. Einastoï¼Œ å’Œ V. MÃ¼ller.2011. SDSS DR7 ä¸­çš„æ˜Ÿç³»å½¢æ€ã€å…‰åº¦å’Œç¯å¢ƒ.A&A 529ï¼š53ã€‚doiï¼š10.1051/0004-6361/201016196."
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the tachycardia prediction dataset from Question 9 (after the instances with missing TACHYCARDIA values have been removed and all outliers have been handled).",
            "zh": "ä»¥ä¸‹æ•°æ®å¯è§†åŒ–åŸºäºé—®é¢˜ 9 ä¸­çš„å¿ƒåŠ¨è¿‡é€Ÿé¢„æµ‹æ•°æ®é›†ï¼ˆåœ¨åˆ é™¤ç¼ºå°‘å¿ƒåŠ¨è¿‡é€Ÿå€¼çš„å®ä¾‹å¹¶å¤„ç†æ‰€æœ‰å¼‚å¸¸å€¼ä¹‹åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.8[198] illustrates the creation of the first two nodes of a k-d tree for the college athlete dataset in Table 5.4[191].",
            "zh": "å›¾5.8[198]è¯´æ˜äº†è¡¨5.4[191]ä¸­å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†çš„k-dæ ‘çš„å‰ä¸¤ä¸ªèŠ‚ç‚¹çš„åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The set of nodes in a graph that make a node independent of the rest of the graph are known as the Markov blanket of a node.",
            "zh": "å›¾ä¸­ä½¿èŠ‚ç‚¹ç‹¬ç«‹äºå›¾çš„å…¶ä½™éƒ¨åˆ†çš„èŠ‚ç‚¹é›†ç§°ä¸ºèŠ‚ç‚¹çš„é©¬å°”å¯å¤«æ¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The last point worth mentioning is that this chapter relates to deployment.",
            "zh": "æœ€åä¸€ç‚¹å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæœ¬ç« ä¸éƒ¨ç½²æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "This calculation reduces to multiplying the Î´ for the neuron that uses the weight in its weighted sum by the activation that the weight was applied to in the weighted sum.",
            "zh": "æ­¤è®¡ç®—ç®€åŒ–ä¸ºå°†ä½¿ç”¨åŠ æƒå’Œä¸­çš„æƒé‡çš„ç¥ç»å…ƒçš„Î´ä¹˜ä»¥åŠ æƒå’Œä¸­åº”ç”¨æƒé‡çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Named Features",
            "zh": "å‘½ååŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "The next section discusses this interaction in more detail and introduces some popular weight initialization schemes for deep networks.",
            "zh": "ä¸‹ä¸€èŠ‚å°†æ›´è¯¦ç»†åœ°è®¨è®ºè¿™ç§äº¤äº’ï¼Œå¹¶ä»‹ç»ä¸€äº›æµè¡Œçš„æ·±åº¦ç½‘ç»œæƒé‡åˆå§‹åŒ–æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The price of the customerâ€™s current handset",
            "zh": "å®¢æˆ·å½“å‰æ‰‹æœºçš„ä»·æ ¼"
        }
    },
    {
        "translation": {
            "en": "Using variance as our measure of impurity, the impurity at a node can be calculated",
            "zh": "ä½¿ç”¨æ–¹å·®ä½œä¸ºæ‚è´¨çš„åº¦é‡ï¼Œå¯ä»¥è®¡ç®—èŠ‚ç‚¹å¤„çš„æ‚è´¨"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the ABT developed for the Acme Telephonica churn prediction task.",
            "zh": "ABT ä¸­çš„æè¿°æ€§åŠŸèƒ½æ˜¯ä¸º Acme Telephonica æµå¤±é¢„æµ‹ä»»åŠ¡å¼€å‘çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "They also need to reflect on the processes they use to preprocess and manage the data, and whether any of these processes introduce bias into the sample.9 So, in summary, although inductive bias is necessary for machine learning, and in a sense, a key goal of a data analyst is to find the correct inductive bias, sample bias is something that a data analyst should proactively work hard to remove from the data used in any data analytics project.",
            "zh": "ä»–ä»¬è¿˜éœ€è¦åæ€ä»–ä»¬ç”¨äºé¢„å¤„ç†å’Œç®¡ç†æ•°æ®çš„è¿‡ç¨‹ï¼Œä»¥åŠè¿™äº›è¿‡ç¨‹ä¸­çš„ä»»ä½•ä¸€ä¸ªæ˜¯å¦ä¼šåœ¨æ ·æœ¬ä¸­å¼•å…¥åå·®.9 å› æ­¤ï¼Œæ€»è€Œè¨€ä¹‹ï¼Œå°½ç®¡å½’çº³åå·®å¯¹äºæœºå™¨å­¦ä¹ æ˜¯å¿…è¦çš„ï¼Œä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œæ•°æ®åˆ†æå¸ˆçš„ä¸€ä¸ªå…³é”®ç›®æ ‡æ˜¯æ‰¾åˆ°æ­£ç¡®çš„å½’çº³åå·®ï¼Œ æ ·æœ¬åå·®æ˜¯æ•°æ®åˆ†æå¸ˆåº”è¯¥ä¸»åŠ¨åŠªåŠ›ä»ä»»ä½•æ•°æ®åˆ†æé¡¹ç›®ä¸­ä½¿ç”¨çš„æ•°æ®ä¸­å»é™¤çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "This would allow him to sample every item and update his knowledge about what he likes and what he doesnâ€™t like.",
            "zh": "è¿™å°†ä½¿ä»–èƒ½å¤Ÿå¯¹æ¯ä»¶ç‰©å“è¿›è¡Œé‡‡æ ·ï¼Œå¹¶æ›´æ–°ä»–å¯¹å–œæ¬¢ä»€ä¹ˆå’Œä¸å–œæ¬¢ä»€ä¹ˆçš„çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.1.1â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "2.1.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "A similar rule is used for instances with the ENERGY RATING feature levels of B and C.",
            "zh": "ç±»ä¼¼çš„è§„åˆ™ç”¨äº ENERGY RATING ç‰¹å¾çº§åˆ«ä¸º B å’Œ C çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "As before, for a naive Bayes model, we calculate the prior probability distribution for the target feature and the posterior distribution for each descriptive feature conditioned on the target feature.",
            "zh": "å¦‚å‰æ‰€è¿°ï¼Œå¯¹äºæœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬è®¡ç®—ç›®æ ‡ç‰¹å¾çš„å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒå’Œä»¥ç›®æ ‡ç‰¹å¾ä¸ºæ¡ä»¶çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„åéªŒåˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Our new network is designed to work with our scenario of predicting the electrical output of a combined cycle power plant: the network has two neurons in the input layer for the inputs AMBIENT TEMPERATURE and the RELATIVE HUMIDITY, and one neuron in the output layer for the target ELECTRICAL OUTPUT.",
            "zh": "æˆ‘ä»¬çš„æ–°ç½‘ç»œæ—¨åœ¨ä¸é¢„æµ‹è”åˆå¾ªç¯å‘ç”µå‚çš„ç”µåŠ›è¾“å‡ºçš„åœºæ™¯é…åˆä½¿ç”¨ï¼šè¯¥ç½‘ç»œåœ¨è¾“å…¥å±‚ä¸­æœ‰ä¸¤ä¸ªç¥ç»å…ƒç”¨äºè¾“å…¥ç¯å¢ƒæ¸©åº¦å’Œç›¸å¯¹æ¹¿åº¦ï¼Œåœ¨è¾“å‡ºå±‚ä¸­æœ‰ä¸€ä¸ªç¥ç»å…ƒç”¨äºç›®æ ‡ç”µè¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Although this simple model goes some way toward capturing the general trend of the relationship between AGE and INCOME, it does not manage to capture any of the subtlety of the relationship.",
            "zh": "å°½ç®¡è¿™ä¸ªç®€å•çš„æ¨¡å‹åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥æ•æ‰åˆ°å¹´é¾„å’Œæ”¶å…¥ä¹‹é—´å…³ç³»çš„æ€»ä½“è¶‹åŠ¿ï¼Œä½†å®ƒå¹¶æ²¡æœ‰è®¾æ³•æ•æ‰åˆ°è¿™ç§å…³ç³»çš„ä»»ä½•å¾®å¦™ä¹‹å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The earlier in the network a weight occurs, the more terms there are in the product.",
            "zh": "æƒé‡åœ¨ç½‘ç»œä¸­å‡ºç°å¾—è¶Šæ—©ï¼Œä¹˜ç§¯ä¸­çš„é¡¹å°±è¶Šå¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "where G(st,at) is the actual return received from the point of taking action at to the end of the episode. By repeatedly applying this update rule, the values in the action-value table slowly converge to good estimates of their true values.15",
            "zh": "å…¶ä¸­ Gï¼ˆstï¼Œatï¼‰ æ˜¯ä»åœ¨å‰§é›†ç»“æŸæ—¶é‡‡å–è¡ŒåŠ¨åˆ°ç»“æŸæ—¶æ”¶åˆ°çš„å®é™…å›æŠ¥ã€‚é€šè¿‡åå¤åº”ç”¨æ­¤æ›´æ–°è§„åˆ™ï¼Œæ“ä½œå€¼è¡¨ä¸­çš„å€¼ä¼šæ…¢æ…¢æ”¶æ•›åˆ°å¯¹å…¶çœŸå®å€¼çš„è‰¯å¥½ä¼°è®¡å€¼15ã€‚"
        }
    },
    {
        "translation": {
            "en": "The black circles show the training dataset, the gray squares show the predictions made for the instances in the training dataset by the ensemble model, and the dotted line shows the predictions that would be made by the ensemble model for the full range of input temperatures.",
            "zh": "é»‘è‰²åœ†åœˆè¡¨ç¤ºè®­ç»ƒæ•°æ®é›†ï¼Œç°è‰²æ–¹å—è¡¨ç¤ºé›†æˆæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹æ‰€åšçš„é¢„æµ‹ï¼Œè™šçº¿è¡¨ç¤ºé›†æˆæ¨¡å‹å°†å¯¹æ•´ä¸ªè¾“å…¥æ¸©åº¦èŒƒå›´åšå‡ºçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This might seem a little surprising given that the patient is suffering from a headache and is vomiting, two key symptoms of meningitis.",
            "zh": "è¿™ä¼¼ä¹æœ‰ç‚¹ä»¤äººæƒŠè®¶ï¼Œå› ä¸ºæ‚£è€…æ‚£æœ‰å¤´ç—›å’Œå‘•åï¼Œè¿™æ˜¯è„‘è†œç‚çš„ä¸¤ä¸ªä¸»è¦ç—‡çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This ensures that the output of all models sums to 1.",
            "zh": "è¿™ç¡®ä¿äº†æ‰€æœ‰æ¨¡å‹çš„è¾“å‡ºæ€»å’Œä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main observation that Jocelyn made from these is that galaxies in the dataset were not evenly distributed across the different morphology types.",
            "zh": "Jocelynä»ä¸­å¾—å‡ºçš„ä¸»è¦è§‚å¯Ÿç»“æœæ˜¯ï¼Œæ•°æ®é›†ä¸­çš„æ˜Ÿç³»åœ¨ä¸åŒçš„å½¢æ€ç±»å‹ä¸­åˆ†å¸ƒä¸å‡åŒ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œEssentially, all models are wrong, but some are useful.â€",
            "zh": "â€œä»æœ¬è´¨ä¸Šè®²ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ˜¯é”™è¯¯çš„ï¼Œä½†æœ‰äº›æ¨¡å‹æ˜¯æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4â€…â€…â€…Extensions and Variations",
            "zh": "9.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "12.6â€…â€…â€…(a) Cumulative gain, (b) lift, and (c) cumulative lift charts for the predictions made on the large test data sample.",
            "zh": "12.6 ï¼ˆaï¼‰ å¯¹å¤§å‹æµ‹è¯•æ•°æ®æ ·æœ¬è¿›è¡Œé¢„æµ‹çš„ç´¯ç§¯å¢ç›Šã€ï¼ˆbï¼‰ æå‡å’Œ ï¼ˆcï¼‰ ç´¯ç§¯æå‡å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 6.2.3[256], however, we showed how conditional independence between features allows us to factorize the joint distribution, and this helps with the curse of dimensionality problem by reducing the number of probabilities we are required to calculate from the data as well as the number of conditioning constraints on these probabilities.",
            "zh": "ç„¶è€Œï¼Œåœ¨ç¬¬ 6.2.3 èŠ‚[256]ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§å¦‚ä½•å…è®¸æˆ‘ä»¬å¯¹è”åˆåˆ†å¸ƒè¿›è¡Œå› å¼åˆ†è§£ï¼Œè¿™æœ‰åŠ©äºè§£å†³ç»´æ•°é—®é¢˜çš„è¯…å’’ï¼Œå‡å°‘æˆ‘ä»¬éœ€è¦ä»æ•°æ®ä¸­è®¡ç®—çš„æ¦‚ç‡æ•°é‡ä»¥åŠè¿™äº›æ¦‚ç‡çš„æ¡ä»¶çº¦æŸçš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conor does, however, recognize the Irish word for chicken, sicÃ­n, on the hotel restaurant menu, and he does like chicken.",
            "zh": "ç„¶è€Œï¼Œåº·çº³ç¡®å®åœ¨é…’åº—é¤å…çš„èœå•ä¸Šè®¤å‡ºäº†çˆ±å°”å…°è¯­ä¸­çš„é¸¡è‚‰å•è¯sicÃ­nï¼Œè€Œä¸”ä»–ç¡®å®å–œæ¬¢é¸¡è‚‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "positive",
            "zh": "é˜³æ€§"
        }
    },
    {
        "translation": {
            "en": "FRAUD FLAG was changed to be a categorical feature.",
            "zh": "FRAUD FLAG å·²æ›´æ”¹ä¸ºåˆ†ç±»åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.3â€…â€…â€…A Markov decision process representation for TwentyTwos, a simplified version of the card game Blackjack.",
            "zh": "11.3 TwentyTwosçš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹è¡¨ç¤ºï¼ŒTwentyTwosæ˜¯çº¸ç‰Œæ¸¸æˆBlackjackçš„ç®€åŒ–ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "outcome period, 37, 689",
            "zh": "æˆæœæœŸï¼Œ 37ï¼Œ 689"
        }
    },
    {
        "translation": {
            "en": "To illustrate how information gain is calculated and to check how well it models our intuitions described at the beginning of this section, we compute the information gain for each descriptive feature in the spam dataset. The first step is to compute the entropy for the whole dataset using Equation (4.2)[129]",
            "zh": "ä¸ºäº†è¯´æ˜å¦‚ä½•è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œå¹¶æ£€æŸ¥å®ƒå¦‚ä½•æ¨¡æ‹Ÿæœ¬èŠ‚å¼€å¤´æè¿°çš„ç›´è§‰ï¼Œæˆ‘ä»¬è®¡ç®—åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚ç¬¬ä¸€æ­¥æ˜¯ä½¿ç”¨å…¬å¼ï¼ˆ4.2ï¼‰è®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„ç†µ[129]"
        }
    },
    {
        "translation": {
            "en": "Agents need to make sequences of good decisions in order to get the opportunity to explore deeper into action sequences and so need to exploit before exploring in some episodes.",
            "zh": "ç‰¹å·¥éœ€è¦åšå‡ºä¸€ç³»åˆ—æ­£ç¡®çš„å†³å®šï¼Œä»¥ä¾¿æœ‰æœºä¼šæ›´æ·±å…¥åœ°æ¢ç´¢åŠ¨ä½œåºåˆ—ï¼Œå› æ­¤åœ¨æŸäº›æƒ…èŠ‚ä¸­éœ€è¦åœ¨æ¢ç´¢ä¹‹å‰è¿›è¡Œåˆ©ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Admittedly, this drop in error is tiny, but it is a reduction in error, and this reduction was achieved by updating randomly initialized weights once.",
            "zh": "è¯šç„¶ï¼Œè¿™ç§è¯¯å·®ä¸‹é™å¾ˆå°ï¼Œä½†å®ƒæ˜¯è¯¯å·®çš„å‡å°‘ï¼Œè€Œè¿™ç§å‡å°‘æ˜¯é€šè¿‡æ›´æ–°ä¸€æ¬¡éšæœºåˆå§‹åŒ–çš„æƒé‡æ¥å®ç°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This system will examine new claims as they arise and flag for further investigation those that look like they might be fraud risks.",
            "zh": "è¯¥ç³»ç»Ÿå°†åœ¨å‡ºç°æ–°ç´¢èµ”æ—¶å¯¹å…¶è¿›è¡Œæ£€æŸ¥ï¼Œå¹¶æ ‡è®°é‚£äº›çœ‹èµ·æ¥å¯èƒ½å­˜åœ¨æ¬ºè¯ˆé£é™©çš„ç´¢èµ”ä»¥ä¾›è¿›ä¸€æ­¥è°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "second",
            "zh": "ç¬¬äºŒ"
        }
    },
    {
        "translation": {
            "en": "The standard technique for applying dropout to a recurrent neural network during training is known as variational RNN (Goldberg, 2017).",
            "zh": "åœ¨è®­ç»ƒæœŸé—´å°†è¾å­¦åº”ç”¨äºé€’å½’ç¥ç»ç½‘ç»œçš„æ ‡å‡†æŠ€æœ¯ç§°ä¸ºå˜åˆ†RNNï¼ˆGoldbergï¼Œ2017ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "factors, 258",
            "zh": "å› å­ï¼Œ 258"
        }
    },
    {
        "translation": {
            "en": "The activations in the cell can take values in the range [âˆ’1,+1].",
            "zh": "ç»†èƒä¸­çš„æ¿€æ´»å¯ä»¥å– [âˆ’1ï¼Œ+1] èŒƒå›´å†…çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2.2â€ƒPrecision, recall, and F1 measureâ€ƒPrecision, recall, and the F1 measure are another frequently used set of performance measures that can be calculated directly from the confusion matrix. Precision and recall are defined as follows:",
            "zh": "9.4.2.2 ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åº¦é‡ ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åº¦é‡æ˜¯å¦ä¸€ç»„å¸¸ç”¨çš„æ€§èƒ½åº¦é‡ï¼Œå¯ä»¥ç›´æ¥ä»æ··æ·†çŸ©é˜µä¸­è®¡ç®—å‡ºæ¥ã€‚ç²¾ç¡®åº¦å’Œå¬å›ç‡å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The reason is that the network uses the same weights to process Input 1 as it does to process Input 3.",
            "zh": "åŸå› æ˜¯ç½‘ç»œä½¿ç”¨ç›¸åŒçš„æƒé‡æ¥å¤„ç†è¾“å…¥ 1 å’Œå¤„ç†è¾“å…¥ 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two cases that we need to handle with this derivative (1) when lk is the logit for the neuron whose activation is the probability of the correct category (i.e., k = â‹†), and (2) when lk is the logit for a neuron whose activation is the probability for one of the incorrect categories (i.e., k â‰  â‹†).",
            "zh": "æˆ‘ä»¬éœ€è¦ç”¨è¿™ä¸ªå¯¼æ•°å¤„ç†ä¸¤ç§æƒ…å†µï¼šï¼ˆ1ï¼‰å½“ lk æ˜¯ç¥ç»å…ƒçš„ logit æ—¶ï¼Œå…¶æ¿€æ´»æ˜¯æ­£ç¡®ç±»åˆ«çš„æ¦‚ç‡ï¼ˆå³ k = â‹†ï¼‰ï¼Œä»¥åŠ ï¼ˆ2ï¼‰ å½“ lk æ˜¯ç¥ç»å…ƒçš„ logit æ—¶ï¼Œå…¶æ¿€æ´»æ˜¯å…¶ä¸­ä¸€ä¸ªé”™è¯¯ç±»åˆ«çš„æ¦‚ç‡ï¼ˆå³ k â‰  â‹†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "agglomerative hierarchical clustering, 618, 618, 629, 635",
            "zh": "é›†èšåˆ†å±‚èšç±»ï¼Œ 618ï¼Œ 618ï¼Œ 629ï¼Œ 635"
        }
    },
    {
        "translation": {
            "en": "9.11â€…â€…â€…A sample test set with model predictions and scores.",
            "zh": "9.11 å…·æœ‰æ¨¡å‹é¢„æµ‹å’Œåˆ†æ•°çš„æ ·æœ¬æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In calculus, when we take the partial derivative of a function with respect to a particular input, all the terms in the function that are not involved in the input disappear, because they are constants when the input changes.",
            "zh": "åœ¨å¾®ç§¯åˆ†ä¸­ï¼Œå½“æˆ‘ä»¬å¯¹ç‰¹å®šè¾“å…¥å–å‡½æ•°çš„åå¯¼æ•°æ—¶ï¼Œå‡½æ•°ä¸­æ‰€æœ‰ä¸æ¶‰åŠè¾“å…¥çš„é¡¹éƒ½æ¶ˆå¤±äº†ï¼Œå› ä¸ºå®ƒä»¬åœ¨è¾“å…¥å‘ç”Ÿå˜åŒ–æ—¶æ˜¯å¸¸æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The benefit of this is that the z values for the neurons in the next layer will be of a similar magnitude during training, when we are using dropout, as they will be during testing/inference (when we do not use dropout).",
            "zh": "è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨dropoutæ—¶ï¼Œä¸‹ä¸€å±‚ä¸­ç¥ç»å…ƒçš„zå€¼åœ¨è®­ç»ƒæœŸé—´å°†å…·æœ‰ç›¸ä¼¼çš„é‡çº§ï¼Œå°±åƒåœ¨æµ‹è¯•/æ¨ç†æœŸé—´ï¼ˆå½“æˆ‘ä»¬ä¸ä½¿ç”¨dropoutæ—¶ï¼‰ä¸€æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if we are trying to build a predictive model that automatically assigns a target level to a query instance, then we need to decide how the model will make a prediction based on the computed probabilities.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•æ„å»ºä¸€ä¸ªè‡ªåŠ¨å°†ç›®æ ‡çº§åˆ«åˆ†é…ç»™æŸ¥è¯¢å®ä¾‹çš„é¢„æµ‹æ¨¡å‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦å†³å®šæ¨¡å‹å°†å¦‚ä½•æ ¹æ®è®¡ç®—çš„æ¦‚ç‡è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.1â€…â€…â€…Big Idea",
            "zh": "11.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "It is clear that the different outcomes have different profit and loss associated with them.",
            "zh": "å¾ˆæ˜æ˜¾ï¼Œä¸åŒçš„ç»“æœå…·æœ‰ä¸åŒçš„æŸç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "A quick comment on our notation.",
            "zh": "å¯¹æˆ‘ä»¬çš„ç¬¦å·è¿›è¡Œå¿«é€Ÿè¯„è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Charniak, Eugene. 2019. Introduction to deep learning. MIT Press.",
            "zh": "æŸ¥å°¼äºšå…‹ï¼Œå°¤é‡‘ã€‚2019. æ·±åº¦å­¦ä¹ ç®€ä»‹.éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This results in a query with AGE = 0.0667 and RATING = 1.00.",
            "zh": "è¿™å°†å¯¼è‡´ AGE = 0.0667 å’Œ RATING = 1.00 çš„æŸ¥è¯¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "post-pruning, 155, 698",
            "zh": "ä¿®å‰ªåï¼Œ 155ï¼Œ 698"
        }
    },
    {
        "translation": {
            "en": "LIFEEXPECTANCY: The average life expectancy (in years)",
            "zh": "é¢„æœŸå¯¿å‘½ï¼šå¹³å‡é¢„æœŸå¯¿å‘½ï¼ˆä»¥å¹´ä¸ºå•ä½ï¼‰"
        }
    },
    {
        "translation": {
            "en": "4.4.5.2â€ƒBoostingâ€ƒWhen we use boosting,28 each new model added to an ensemble is biased to pay more attention to instances that previous models misclassified.",
            "zh": "4.4.5.2 æå‡ å½“æˆ‘ä»¬ä½¿ç”¨æå‡æ—¶ï¼Œ28 æ·»åŠ åˆ°é›†æˆä¸­çš„æ¯ä¸ªæ–°æ¨¡å‹éƒ½ä¼šåå‘äºæ›´å¤šåœ°å…³æ³¨å…ˆå‰æ¨¡å‹é”™è¯¯åˆ†ç±»çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that when an instance is randomly selected from the original dataset, it is replaced into the dataset so that it might be selected again.",
            "zh": "è¿™æ„å‘³ç€ï¼Œå½“ä»åŸå§‹æ•°æ®é›†ä¸­éšæœºé€‰æ‹©å®ä¾‹æ—¶ï¼Œè¯¥å®ä¾‹å°†è¢«æ›¿æ¢åˆ°æ•°æ®é›†ä¸­ï¼Œä»¥ä¾¿å¯ä»¥å†æ¬¡é€‰æ‹©è¯¥å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix calculates the frequencies of each possible outcome of the predictions made by a model for a test dataset in order to show, in detail, how the model is performing.",
            "zh": "æ··æ·†çŸ©é˜µè®¡ç®—æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®é›†æ‰€åšçš„é¢„æµ‹çš„æ¯ä¸ªå¯èƒ½ç»“æœçš„é¢‘ç‡ï¼Œä»¥ä¾¿è¯¦ç»†æ˜¾ç¤ºæ¨¡å‹çš„æ‰§è¡Œæƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "This type of histogram is often referred to as a frequency histogram.",
            "zh": "è¿™ç§ç±»å‹çš„ç›´æ–¹å›¾é€šå¸¸ç§°ä¸ºé¢‘ç‡ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov chart, 563",
            "zh": "Kolmogorov-Smirnov å›¾è¡¨ï¼Œ563"
        }
    },
    {
        "translation": {
            "en": "If she takes a small step in the direction in which the ground slopes most steeply downward (the direction of the gradient of the mountain), she will be headed toward the bottom of the mountain.",
            "zh": "å¦‚æœå¥¹å‘åœ°é¢æœ€é™¡å³­çš„æ–¹å‘ï¼ˆå±±å¡çš„æ–¹å‘ï¼‰è¿ˆå‡ºä¸€å°æ­¥ï¼Œå¥¹å°±ä¼šæœç€å±±åº•å‰è¿›ã€‚"
        }
    },
    {
        "translation": {
            "en": "taxi-cab distance, 185",
            "zh": "å‡ºç§Ÿè½¦è·ç¦»ï¼Œ185"
        }
    },
    {
        "translation": {
            "en": "We can, in fact, use the gradient descent algorithm to train a single-layer network (or perceptron), such as the one shown in Figure 8.7[397].",
            "zh": "äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥è®­ç»ƒå•å±‚ç½‘ç»œï¼ˆæˆ–æ„ŸçŸ¥å™¨ï¼‰ï¼Œå¦‚å›¾8.7[397]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "This is simply 1 divided by the modelâ€™s predicted probability for the correct category.",
            "zh": "è¿™åªæ˜¯ 1 é™¤ä»¥æ¨¡å‹å¯¹æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.14â€…â€…â€…The calculation of the softmax activation function Ï•sm over a vector of three logits l.",
            "zh": "8.14 softmaxæ¿€æ´»å‡½æ•°Ï†småœ¨3logits lçš„å‘é‡ä¸Šçš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extent of the rectangular box in the middle of the plot is determined by the 3rd quartile at the top and the 1st quartile at the bottom.",
            "zh": "å›¾ä¸­é—´çŸ©å½¢æ¡†çš„èŒƒå›´ç”±é¡¶éƒ¨çš„ç¬¬ 3 ä¸ªå››åˆ†ä½æ•°å’Œåº•éƒ¨çš„ç¬¬ 1 ä¸ªå››åˆ†ä½æ•°ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Biases are introduced when, due to the sampling process, the distributions of features in the sampled dataset are very different from the distributions of features in the original dataset.",
            "zh": "å½“ç”±äºé‡‡æ ·è¿‡ç¨‹çš„åŸå› ï¼Œé‡‡æ ·æ•°æ®é›†ä¸­çš„ç‰¹å¾åˆ†å¸ƒä¸åŸå§‹æ•°æ®é›†ä¸­çš„ç‰¹å¾åˆ†å¸ƒæœ‰å¾ˆå¤§ä¸åŒæ—¶ï¼Œå°±ä¼šå¼•å…¥åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) At the fourth iteration of AHC, the first hierarchical cluster combination is created when a single instance, d11 is combined with the cluster 10 to create a new cluster, 13.",
            "zh": "ï¼ˆdï¼‰ åœ¨AHCçš„ç¬¬å››æ¬¡è¿­ä»£ä¸­ï¼Œå½“å•ä¸ªå®ä¾‹d11ä¸ç°‡10åˆå¹¶ä»¥åˆ›å»ºæ–°ç°‡13æ—¶ï¼Œå°†åˆ›å»ºç¬¬ä¸€ä¸ªåˆ†å±‚ç°‡ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "AHC begins by considering each instance in the dataset as a simple cluster containing just one instance.",
            "zh": "AHC é¦–å…ˆå°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹è§†ä¸ºä»…åŒ…å«ä¸€ä¸ªå®ä¾‹çš„ç®€å•é›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, we can calculate the rate of change of the error of the network â„° with respect to the changes in the activation ak by taking the product: wi,k Ã— Î´i.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å–ä¹˜ç§¯ wiï¼Œk Ã— Î´i æ¥è®¡ç®—ç½‘ç»œ E çš„è¯¯å·®ç›¸å¯¹äºæ¿€æ´» ak å˜åŒ–çš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarity-based prediction models attempt to mimic a very human way of reasoning by basing predictions for a target feature value on the most similar instances in memory.",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„é¢„æµ‹æ¨¡å‹è¯•å›¾é€šè¿‡åŸºäºå†…å­˜ä¸­æœ€ç›¸ä¼¼çš„å®ä¾‹æ¥æ¨¡æ‹Ÿå¯¹ç›®æ ‡ç‰¹å¾å€¼çš„é¢„æµ‹ï¼Œä»è€Œæ¨¡ä»¿ä¸€ç§éå¸¸äººæ€§çš„æ¨ç†æ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, any instances with a missing value for the target feature should always be removed from an ABT.",
            "zh": "äº‹å®ä¸Šï¼Œåº”å§‹ç»ˆä» ABT ä¸­åˆ é™¤ä»»ä½•ç¼ºå°‘ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "That means that three out of every four times you ask Question 2, the answer will be no, and you will still have to distinguish between the three remaining characters.",
            "zh": "è¿™æ„å‘³ç€ä½ æ¯é—®å››æ¬¡é—®é¢˜ 2 ä¸­å°±æœ‰ä¸‰æ¬¡ï¼Œç­”æ¡ˆæ˜¯å¦å®šçš„ï¼Œä½ ä»ç„¶éœ€è¦åŒºåˆ†å‰©ä¸‹çš„ä¸‰ä¸ªå­—ç¬¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, we present machine learning within the context of predictive data analytics, an important industry application of machine learning.",
            "zh": "å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹æ•°æ®åˆ†æçš„èƒŒæ™¯ä¸‹ä»‹ç»äº†æœºå™¨å­¦ä¹ ï¼Œè¿™æ˜¯æœºå™¨å­¦ä¹ çš„é‡è¦è¡Œä¸šåº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the values of a descriptive feature are normally distributed, then standardizing the feature is appropriate; however, this is relatively rare, and the default is to use range normalization into either [âˆ’1,+1] or [0,1] for preprocessing.",
            "zh": "å¦‚æœæè¿°æ€§ç‰¹å¾çš„å€¼å‘ˆæ­£æ€åˆ†å¸ƒï¼Œåˆ™æ ‡å‡†åŒ–ç‰¹å¾æ˜¯åˆé€‚çš„;ä½†æ˜¯ï¼Œè¿™ç§æƒ…å†µç›¸å¯¹ç½•è§ï¼Œé»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–ä¸º [âˆ’1ï¼Œ+1] æˆ– [0,1] è¿›è¡Œé¢„å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The shaded cells in Image (a) below show the region that these sensors cover.",
            "zh": "ä¸‹å›¾ï¼ˆaï¼‰ä¸­çš„é˜´å½±å•å…ƒæ ¼æ˜¾ç¤ºäº†è¿™äº›ä¼ æ„Ÿå™¨è¦†ç›–çš„åŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Data Exploration",
            "zh": "æ•°æ®æ¢ç´¢"
        }
    },
    {
        "translation": {
            "en": "In other words, in a feedforward network the activations in the network always flow forward through the sequence of layers.",
            "zh": "æ¢å¥è¯è¯´ï¼Œåœ¨å‰é¦ˆç½‘ç»œä¸­ï¼Œç½‘ç»œä¸­çš„æ¿€æ´»æ€»æ˜¯é€šè¿‡å±‚åºåˆ—å‘å‰æµåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelynâ€™s options at this stage were (1) to embark on a large-scale manual data labeling project for which she would hire experts to manually label a suitably large set of historical night sky object observations, or (2) to find some other data source that she could add to the SDSS data to use as a target feature.",
            "zh": "Jocelyn åœ¨è¿™ä¸ªé˜¶æ®µçš„é€‰æ‹©æ˜¯ ï¼ˆ1ï¼‰ å¼€å§‹ä¸€ä¸ªå¤§è§„æ¨¡çš„æ‰‹åŠ¨æ•°æ®æ ‡è®°é¡¹ç›®ï¼Œä¸ºæ­¤å¥¹å°†è˜è¯·ä¸“å®¶æ‰‹åŠ¨æ ‡è®°ä¸€ç»„é€‚å½“å¤§çš„å†å²å¤œç©ºå¤©ä½“è§‚æµ‹ï¼Œæˆ–è€… ï¼ˆ2ï¼‰ æ‰¾åˆ°ä¸€äº›å…¶ä»–æ•°æ®æºï¼Œå¥¹å¯ä»¥å°†å…¶æ·»åŠ åˆ° SDSS æ•°æ®ä¸­ä»¥ç”¨ä½œç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms learn prediction models by inducing a generalized model of the relationship between a set of descriptive features and a target feature from a set of specific training instances.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡ä»ä¸€ç»„ç‰¹å®šè®­ç»ƒå®ä¾‹ä¸­è¯±å¯¼å‡ºä¸€ç»„æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„å¹¿ä¹‰æ¨¡å‹æ¥å­¦ä¹ é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Readers who are not already familiar with standard measures of central tendency (mean, mode, and median), standard measures of variation (standard deviation and percentiles), and standard data visualization plots (bar plots, histograms, and box plots) should read Appendix A[745] for the necessary introduction.",
            "zh": "å¦‚æœè¯»è€…è¿˜ä¸ç†Ÿæ‚‰é›†ä¸­è¶‹åŠ¿çš„æ ‡å‡†åº¦é‡ï¼ˆå‡å€¼ã€ä¼—æ•°å’Œä¸­ä½æ•°ï¼‰ã€æ ‡å‡†å˜å¼‚åº¦é‡ï¼ˆæ ‡å‡†å·®å’Œç™¾åˆ†ä½æ•°ï¼‰å’Œæ ‡å‡†æ•°æ®å¯è§†åŒ–å›¾ï¼ˆæ¡å½¢å›¾ã€ç›´æ–¹å›¾å’Œç®±å½¢å›¾ï¼‰ï¼Œåˆ™åº”é˜…è¯»é™„å½• A[745] ä»¥è·å–å¿…è¦çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (7.14)[324] calculates the gradient based only on a single training instance. To take into account multiple training instances, we calculate the sum of the squared errors for each training instance (as we did in all our previous examples). So, Equation (7.14)[324] becomes",
            "zh": "æ–¹ç¨‹ï¼ˆ7.14ï¼‰[324]ä»…åŸºäºå•ä¸ªè®­ç»ƒå®ä¾‹è®¡ç®—æ¢¯åº¦ã€‚ä¸ºäº†è€ƒè™‘å¤šä¸ªè®­ç»ƒå®ä¾‹ï¼Œæˆ‘ä»¬è®¡ç®—æ¯ä¸ªè®­ç»ƒå®ä¾‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼ˆå°±åƒæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ‰€æœ‰ç¤ºä¾‹ä¸­æ‰€åšçš„é‚£æ ·ï¼‰ã€‚å› æ­¤ï¼Œæ–¹ç¨‹ï¼ˆ7.14ï¼‰[324]å˜ä¸º"
        }
    },
    {
        "translation": {
            "en": "Due to the fact that the differences are squared, variances are not in the same units as the original values, so they are not especially informativeâ€”telling someone that the variance of the heights on one team is 63.125 and on another is 1,011.411 doesnâ€™t give them any particularly useful information other than the fact that the variance of one team is bigger than that of the other.",
            "zh": "ç”±äºå·®å€¼æ˜¯å¹³æ–¹çš„ï¼Œå› æ­¤æ–¹å·®ä¸åŸå§‹å€¼çš„å•ä½ä¸åŒï¼Œå› æ­¤å®ƒä»¬ä¸æ˜¯ç‰¹åˆ«æœ‰ç”¨çš„ä¿¡æ¯â€”â€”å‘Šè¯‰æŸäººä¸€ä¸ªå›¢é˜Ÿçš„é«˜åº¦æ–¹å·®æ˜¯ 63.125ï¼Œå¦ä¸€ä¸ªå›¢é˜Ÿçš„é«˜åº¦æ–¹å·®æ˜¯ 1,011.411 é™¤äº†ä¸€ä¸ªå›¢é˜Ÿçš„æ–¹å·®å¤§äºå¦ä¸€ä¸ªå›¢é˜Ÿçš„æ–¹å·®è¿™ä¸€äº‹å®ä¹‹å¤–ï¼Œå¹¶æ²¡æœ‰ç»™ä»–ä»¬ä»»ä½•ç‰¹åˆ«æœ‰ç”¨çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "An indication of the performance of the model is also evident from this orderingâ€”the Target column shows that the instances that actually should get predictions of the ham level generally have lower scores, and those that should get predictions of the spam level generally have higher scores.",
            "zh": "ä»æ­¤æ’åºä¸­ä¹Ÿå¯ä»¥æ˜æ˜¾çœ‹å‡ºæ¨¡å‹çš„æ€§èƒ½ - â€œç›®æ ‡â€åˆ—æ˜¾ç¤ºï¼Œå®é™…åº”è·å¾— ham çº§åˆ«é¢„æµ‹çš„å®ä¾‹é€šå¸¸å…·æœ‰è¾ƒä½çš„åˆ†æ•°ï¼Œè€Œé‚£äº›åº”è¯¥è·å¾—åƒåœ¾é‚®ä»¶çº§åˆ«é¢„æµ‹çš„å®ä¾‹é€šå¸¸å…·æœ‰è¾ƒé«˜çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the ReLU network changed during training when Î± = 0.2.",
            "zh": "è¯¥å›¾æ˜¾ç¤ºäº†å½“ Î± = 0.2 æ—¶ï¼ŒReLU ç½‘ç»œçš„å¹³æ–¹è¯¯å·®æ€»å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, we begin the worked example by explaining why normalization is important for neural networks and normalizing the data in Table 8.1[422].",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡è§£é‡Šä¸ºä»€ä¹ˆå½’ä¸€åŒ–å¯¹ç¥ç»ç½‘ç»œå¾ˆé‡è¦ï¼Œå¹¶åœ¨è¡¨ 8.1[422] ä¸­å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–æ¥å¼€å§‹å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.13",
            "zh": "å›¾ 5.13"
        }
    },
    {
        "translation": {
            "en": "Given that there are multiple Bayesian networks for any domain, an obvious question to ask is, what is the best topological structure to give the algorithm as input?",
            "zh": "é‰´äºä»»ä½•åŸŸéƒ½æœ‰å¤šä¸ªè´å¶æ–¯ç½‘ç»œï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜æ˜¯ï¼Œå°†ç®—æ³•ä½œä¸ºè¾“å…¥çš„æœ€ä½³æ‹“æ‰‘ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "At some point in this process, however, overfitting will begin to occur, and the ability of the model to generalize well to new query instances will diminish.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­çš„æŸä¸ªæ—¶åˆ»ï¼Œå°†å¼€å§‹å‘ç”Ÿè¿‡åº¦æ‹Ÿåˆï¼Œå¹¶ä¸”æ¨¡å‹å¾ˆå¥½åœ°æ³›åŒ–åˆ°æ–°æŸ¥è¯¢å®ä¾‹çš„èƒ½åŠ›å°†å‡å¼±ã€‚"
        }
    },
    {
        "translation": {
            "en": "As well as visually inspecting scatter plots, we can calculate formal measures of the relationship between two continuous features using covariance and correlation. For two features, a and b, in a dataset of n instances, the sample covariance between a and b is",
            "zh": "é™¤äº†ç›®è§†æ£€æŸ¥æ•£ç‚¹å›¾å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨åæ–¹å·®å’Œç›¸å…³æ€§è®¡ç®—ä¸¤ä¸ªè¿ç»­ç‰¹å¾ä¹‹é—´å…³ç³»çš„å½¢å¼åº¦é‡ã€‚å¯¹äºåŒ…å« n ä¸ªå®ä¾‹çš„æ•°æ®é›†ä¸­çš„ä¸¤ä¸ªç‰¹å¾ a å’Œ bï¼Œa å’Œ b ä¹‹é—´çš„æ ·æœ¬åæ–¹å·®ä¸º"
        }
    },
    {
        "translation": {
            "en": "[Payment prediction] Many fraudulent insurance claims simply over-exaggerate the amount that should actually be paid out.",
            "zh": "[ä»˜æ¬¾é¢„æµ‹]è®¸å¤šæ¬ºè¯ˆæ€§ä¿é™©ç´¢èµ”åªæ˜¯å¤¸å¤§äº†å®é™…åº”è¯¥æ”¯ä»˜çš„é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are lots of options for the state representation that can be used to model an agent playing the game TwentyTwos.",
            "zh": "çŠ¶æ€è¡¨ç¤ºæœ‰å¾ˆå¤šé€‰é¡¹å¯ç”¨äºå¯¹ç©æ¸¸æˆ TwentyTwo çš„ä»£ç†è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As the name constrained quadratic optimization problem suggests, this type of problem is defined in terms of (1) a set of constraints and (2) an optimization criterion.",
            "zh": "é¡¾åæ€ä¹‰ï¼Œçº¦æŸäºŒæ¬¡ä¼˜åŒ–é—®é¢˜ï¼Œè¿™ç±»é—®é¢˜çš„å®šä¹‰æ˜¯ï¼šï¼ˆ1ï¼‰ä¸€ç»„çº¦æŸæ¡ä»¶å’Œï¼ˆ2ï¼‰ä¸€ä¸ªä¼˜åŒ–å‡†åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dataset for predicting the vegetation in an area sorted by the continuous ELEVATION feature.",
            "zh": "ç”¨äºé¢„æµ‹æŒ‰è¿ç»­é«˜ç¨‹è¦ç´ æ’åºçš„åŒºåŸŸå†…æ¤è¢«çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "binning, 89, 102, 146, 280",
            "zh": "åˆ†æ¡£ã€89ã€102ã€146ã€280"
        }
    },
    {
        "translation": {
            "en": "For a query instance with SPEND = 25.67 and FREQ = 6.12, which are normalized to SPEND = âˆ’0.7279 and FREQ = 0.4789, the predictions of the individual models would be",
            "zh": "å¯¹äº SPEND = 25.67 å’Œ FREQ = 6.12 çš„æŸ¥è¯¢å®ä¾‹ï¼Œå®ƒä»¬è¢«å½’ä¸€åŒ–ä¸º SPEND = âˆ’0.7279 å’Œ FREQ = 0.4789ï¼Œå„ä¸ªæ¨¡å‹çš„é¢„æµ‹å°†æ˜¯"
        }
    },
    {
        "translation": {
            "en": "6.8â€…â€…â€…The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.2[263].",
            "zh": "6.8 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.2[263]ä¸­çš„æ•°æ®é›†è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "7.10â€…â€…â€…(a) A scatter plot of the RPM and VIBRATION descriptive features from the generators dataset shown in Table 7.6[339], where good generators are shown as crosses, and faulty generators are shown as triangles; and (b) as decision boundary separating good generators (crosses) from faulty generators (triangles).",
            "zh": "7.10 ï¼ˆaï¼‰ è¡¨7.6[339]æ‰€ç¤ºçš„å‘ç”µæœºæ•°æ®é›†ä¸­çš„RPMå’ŒVIBRATIONæè¿°æ€§ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼Œå…¶ä¸­å¥½çš„å‘ç”µæœºæ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œæ•…éšœå‘ç”µæœºæ˜¾ç¤ºä¸ºä¸‰è§’å½¢;ï¼ˆbï¼‰ä½œä¸ºå°†è‰¯å¥½å‘ç”µæœºï¼ˆåå­—æ¶ï¼‰ä¸æ•…éšœå‘ç”µæœºï¼ˆä¸‰è§’å½¢ï¼‰åˆ†å¼€çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "At the beginning, a large value 0.9 is used and this slowly moves down toward a small value 0.05.",
            "zh": "ä¸€å¼€å§‹ï¼Œä½¿ç”¨å¤§å€¼ 0.9ï¼Œç„¶åæ…¢æ…¢å‘ä¸‹ç§»åŠ¨åˆ°å°å€¼ 0.05ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sampling density is the average density of training instances across the feature space.",
            "zh": "é‡‡æ ·å¯†åº¦æ˜¯æ•´ä¸ªç‰¹å¾ç©ºé—´ä¸­è®­ç»ƒå®ä¾‹çš„å¹³å‡å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Randomly dropping neurons from a network during training may seem like a surprising way to improve the performance of the model.",
            "zh": "åœ¨è®­ç»ƒæœŸé—´ä»ç½‘ç»œä¸­éšæœºä¸¢å¼ƒç¥ç»å…ƒä¼¼ä¹æ˜¯æé«˜æ¨¡å‹æ€§èƒ½çš„ä¸€ç§ä»¤äººæƒŠè®¶çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A further advantage that results from this simplicity is the compactness of the naive Bayes model with which a very large dataset can be represented.",
            "zh": "è¿™ç§ç®€å•æ€§å¸¦æ¥çš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„ç´§å‡‘æ€§ï¼Œå¯ä»¥è¡¨ç¤ºéå¸¸å¤§çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tedâ€™s second observation was that, although there was a huge amount of data available on past observations of night sky objects, only a tiny fraction of these contained manual labels indicating the morphological category to which they belonged.",
            "zh": "æ³°å¾·çš„ç¬¬äºŒä¸ªè§‚å¯Ÿç»“æœæ˜¯ï¼Œå°½ç®¡è¿‡å»å¯¹å¤œç©ºå¤©ä½“çš„è§‚æµ‹æœ‰å¤§é‡æ•°æ®å¯ç”¨ï¼Œä½†å…¶ä¸­åªæœ‰ä¸€å°éƒ¨åˆ†åŒ…å«æ‰‹åŠ¨æ ‡ç­¾ï¼Œè¡¨æ˜å®ƒä»¬æ‰€å±çš„å½¢æ€ç±»åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesâ€™ Theorem relates these two views of probability by using the notion of a prior probability.",
            "zh": "è´å¶æ–¯å®šç†é€šè¿‡ä½¿ç”¨å…ˆéªŒæ¦‚ç‡çš„æ¦‚å¿µå°†è¿™ä¸¤ç§æ¦‚ç‡è§‚ç‚¹è”ç³»èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The original feature values shown in Table 6.18[295] are continuous, so we use the standard approach of converting them to categorical features using equal-frequency binning, with two bins for each feature: low and high. The columns labeled Binned Feature Values in Table 6.18[295] show the data after it has been binned.",
            "zh": "è¡¨6.18[295]ä¸­æ˜¾ç¤ºçš„åŸå§‹ç‰¹å¾å€¼æ˜¯è¿ç»­çš„ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨æ ‡å‡†æ–¹æ³•ï¼Œä½¿ç”¨ç­‰é¢‘åˆ†ç®±å°†å®ƒä»¬è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾æœ‰ä¸¤ä¸ªæ¡æŸ±ï¼šä½å’Œé«˜ã€‚è¡¨ 6.18[295] ä¸­æ ‡æœ‰â€œåˆ†ç®±è¦ç´ å€¼â€çš„åˆ—æ˜¾ç¤ºæ•°æ®åˆ†ç®±åçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the circles in the network represents a processing neuron that transforms its input using the previously described two-step process of a weighted sum followed by an activation function.",
            "zh": "ç½‘ç»œä¸­çš„æ¯ä¸ªåœ†åœˆéƒ½ä»£è¡¨ä¸€ä¸ªå¤„ç†ç¥ç»å…ƒï¼Œè¯¥ç¥ç»å…ƒä½¿ç”¨å‰é¢æè¿°çš„ä¸¤æ­¥è¿‡ç¨‹ï¼ˆåŠ æƒå’Œåè·Ÿæ¿€æ´»å‡½æ•°ï¼‰æ¥è½¬æ¢å…¶è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.558",
            "zh": "0.558"
        }
    },
    {
        "translation": {
            "en": "13.5â€…â€…â€…Evaluation",
            "zh": "13.5 è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "This observation is important because it highlights that machine learning has the same properties as inductive learning.",
            "zh": "è¿™ä¸€è§‚å¯Ÿç»“æœå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå¼ºè°ƒäº†æœºå™¨å­¦ä¹ å…·æœ‰ä¸å½’çº³å­¦ä¹ ç›¸åŒçš„å±æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other two functions are known as polynomial functions as they include addition, multiplication, and raising to exponents.",
            "zh": "å¦å¤–ä¸¤ä¸ªå‡½æ•°ç§°ä¸ºå¤šé¡¹å¼å‡½æ•°ï¼Œå› ä¸ºå®ƒä»¬åŒ…æ‹¬åŠ æ³•ã€ä¹˜æ³•å’Œæå‡åˆ°æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A selection of images from the handwritten digits dataset; (b) image reconstructions generated by the auto-encoder network before training; (c) image reconstructions generated by the auto-encoder network after minimal training (10 epochs); and (d) image reconstructions generated by the auto-encoder network after complete training (1,000 epochs).",
            "zh": "ï¼ˆaï¼‰ ä»æ‰‹å†™æ•°å­—æ•°æ®é›†ä¸­é€‰å‡ºçš„å›¾åƒ;ï¼ˆbï¼‰è‡ªç¼–ç å™¨ç½‘ç»œåœ¨è®­ç»ƒå‰ç”Ÿæˆçš„å›¾åƒé‡å»º;ï¼ˆcï¼‰ è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œåœ¨æœ€å°è®­ç»ƒï¼ˆ10 ä¸ªå‘¨æœŸï¼‰åç”Ÿæˆçš„å›¾åƒé‡å»º;ï¼ˆdï¼‰è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œåœ¨å®Œæˆè®­ç»ƒåç”Ÿæˆçš„å›¾åƒé‡å»ºï¼ˆ1,000ä¸ªå‘¨æœŸï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each feature, we should examine the central tendency and variation to understand the types of values that each feature can take.",
            "zh": "å¯¹äºæ¯ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬åº”è¯¥æ£€æŸ¥ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–ï¼Œä»¥äº†è§£æ¯ä¸ªç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å€¼ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.1â€ƒThe Data Quality Report",
            "zh": "3.1 æ•°æ®è´¨é‡æŠ¥å‘Š"
        }
    },
    {
        "translation": {
            "en": "There is no closed form solution to calculate the parameters to fit a mixture of Gaussians distribution to a set of feature values, as there is for the exponential and normal distributions.",
            "zh": "æ²¡æœ‰é—­å¼è§£æ¥è®¡ç®—å‚æ•°ä»¥å°†é«˜æ–¯åˆ†å¸ƒçš„æ··åˆæ‹Ÿåˆåˆ°ä¸€ç»„ç‰¹å¾å€¼ï¼Œå°±åƒæŒ‡æ•°åˆ†å¸ƒå’Œæ­£æ€åˆ†å¸ƒä¸€æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "R2 coefficient values fall in the range [0,1) and larger values indicate better model performance. A useful interpretation of the R2 coefficient is as the amount of variation in the target feature that is explained by the descriptive features in the model.",
            "zh": "R2 ç³»æ•°å€¼åœ¨ [0,1] èŒƒå›´å†…ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚R2 ç³»æ•°çš„ä¸€ä¸ªæœ‰ç”¨è§£é‡Šæ˜¯ç›®æ ‡ç‰¹å¾çš„å˜å¼‚é‡ï¼Œç”±æ¨¡å‹ä¸­çš„æè¿°æ€§ç‰¹å¾è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "There are 10 values that the dealerâ€™s visible card can represent: 2 to 11.",
            "zh": "åº„å®¶çš„å¯è§å¡ç‰‡å¯ä»¥è¡¨ç¤º 10 ä¸ªå€¼ï¼š2 åˆ° 11ã€‚"
        }
    },
    {
        "translation": {
            "en": "We explain the early stopping algorithm in Section 8.4.4[472].",
            "zh": "æˆ‘ä»¬åœ¨ Section 8.4.4[472] ä¸­è§£é‡Šäº†æ—©æœŸåœæ­¢ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two goals in data exploration.",
            "zh": "æ•°æ®æ¢ç´¢æœ‰ä¸¤ä¸ªç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.16â€…â€…â€…(a) A scatter plot of the RAIN and GROWTH feature from the grass growth dataset; and (b) the same plot with a simple linear regression model trained to capture the relationship between the grass growth and rainfall.",
            "zh": "7.16 ï¼ˆaï¼‰ è‰ç”Ÿé•¿æ•°æ®é›†ä¸­é›¨æ°´å’Œç”Ÿé•¿ç‰¹å¾çš„æ•£ç‚¹å›¾;ï¼ˆbï¼‰ä½¿ç”¨ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹è®­ç»ƒç›¸åŒçš„å›¾ï¼Œä»¥æ•æ‰è‰ç”Ÿé•¿å’Œé™é›¨ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This problem is illustrated very clearly in the famous example of Anscombeâ€™s quartet,8 shown in Figure 3.12[86]. This is a series of four pairs of features that all have the same correlation value of 0.816, even though they exhibit very different relationships.",
            "zh": "è¿™ä¸ªé—®é¢˜åœ¨è‘—åçš„Anscombeå››é‡å¥8ä¸­å¾—åˆ°äº†éå¸¸æ¸…æ™°çš„è¯´æ˜ï¼Œå¦‚å›¾3.12æ‰€ç¤º[86]ã€‚è¿™æ˜¯ä¸€ç³»åˆ—å››å¯¹ç‰¹å¾ï¼Œå®ƒä»¬éƒ½å…·æœ‰ç›¸åŒçš„ç›¸å…³å€¼ 0.816ï¼Œå°½ç®¡å®ƒä»¬è¡¨ç°å‡ºéå¸¸ä¸åŒçš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The large gap between the two apparent clusters in this dataset results in a large variance, which indicates that we are probably underfitting with this grouping.",
            "zh": "è¯¥æ•°æ®é›†ä¸­ä¸¤ä¸ªæ˜æ˜¾èšç±»ä¹‹é—´çš„å·¨å¤§å·®è·å¯¼è‡´äº†å¾ˆå¤§çš„æ–¹å·®ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬å¯èƒ½ä¸è¿™ç§åˆ†ç»„æ‹Ÿåˆä¸è¶³ã€‚"
        }
    },
    {
        "translation": {
            "en": "A single-layer network.",
            "zh": "å•å±‚ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "gates, 508",
            "zh": "ç›–èŒ¨ï¼Œ508"
        }
    },
    {
        "translation": {
            "en": "Figure C.1(b)[765] shows a profile of the acceleration during this journey.",
            "zh": "å›¾C.1ï¼ˆbï¼‰[765]æ˜¾ç¤ºäº†è¿™ä¸€è¿‡ç¨‹ä¸­çš„åŠ é€Ÿåº¦æ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we describe the most popular performance measures used for continuous targets.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”¨äºè¿ç»­ç›®æ ‡çš„æœ€å¸¸ç”¨çš„ç»©æ•ˆåº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The multiplication of w[4] Ã— ENERGY RATING causes a problem here. Energy rating is a categorical feature, so multiplying the values of this feature by a numeric weight is simply not sensible. The basic structure of the multivariable linear regression model allows for only continuous descriptive features. Obviously, though, in real-world datasets, we often encounter categorical descriptive features, so for the linear regression approach to be really useful, we need a way to handle these.",
            "zh": "w[4] Ã— ENERGY RATING çš„ä¹˜æ³•åœ¨è¿™é‡Œä¼šå¯¼è‡´ä¸€ä¸ªé—®é¢˜ã€‚èƒ½é‡é¢å®šå€¼æ˜¯ä¸€ä¸ªåˆ†ç±»ç‰¹å¾ï¼Œå› æ­¤å°†è¯¥ç‰¹å¾çš„å€¼ä¹˜ä»¥æ•°å­—æƒé‡æ˜¯ä¸æ˜æ™ºçš„ã€‚å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„åŸºæœ¬ç»“æ„åªå…è®¸è¿ç»­çš„æè¿°æ€§ç‰¹å¾ã€‚ç„¶è€Œï¼Œæ˜¾ç„¶ï¼Œåœ¨ç°å®ä¸–ç•Œçš„æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šé‡åˆ°åˆ†ç±»æè¿°æ€§ç‰¹å¾ï¼Œå› æ­¤ï¼Œè¦ä½¿çº¿æ€§å›å½’æ–¹æ³•çœŸæ­£æœ‰ç”¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥å¤„ç†è¿™äº›ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In dealing with an elementwise vector product, this is applied to each of the separate products in turn.",
            "zh": "åœ¨å¤„ç†é€å…ƒç´ å‘é‡ä¹˜ç§¯æ—¶ï¼Œè¿™ä¾æ¬¡åº”ç”¨äºæ¯ä¸ªå•ç‹¬çš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, unless a model uses a very small number of descriptive features (generally fewer than 10), we do not recommend this approach.",
            "zh": "å› æ­¤ï¼Œé™¤éæ¨¡å‹ä½¿ç”¨æå°‘é‡çš„æè¿°æ€§ç‰¹å¾ï¼ˆé€šå¸¸å°‘äº 10 ä¸ªï¼‰ï¼Œå¦åˆ™æˆ‘ä»¬ä¸å»ºè®®ä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This illustrates that a decision boundary is a global representation of the predictions made by the local models associated with each instance in the training set.",
            "zh": "è¿™è¯´æ˜å†³ç­–è¾¹ç•Œæ˜¯ä¸è®­ç»ƒé›†ä¸­æ¯ä¸ªå®ä¾‹å…³è”çš„å±€éƒ¨æ¨¡å‹æ‰€åšçš„é¢„æµ‹çš„å…¨å±€è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "1.00",
            "zh": "1.00"
        }
    },
    {
        "translation": {
            "en": "All the different model selection criteria consist of a set of assumptions about the characteristics of the model that we would like the algorithm to induce.",
            "zh": "æ‰€æœ‰ä¸åŒçš„æ¨¡å‹é€‰æ‹©æ ‡å‡†éƒ½ç”±ä¸€ç»„å…³äºæ¨¡å‹ç‰¹å¾çš„å‡è®¾ç»„æˆï¼Œæˆ‘ä»¬å¸Œæœ›ç®—æ³•èƒ½å¤Ÿè¯±å¯¼å‡ºè¿™äº›å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.1â€…â€…â€…The Data Quality Report",
            "zh": "3.1 æ•°æ®è´¨é‡æŠ¥å‘Š"
        }
    },
    {
        "translation": {
            "en": "The data quality issues we identify from a data quality report will be of two types: data quality issues due to invalid data and data quality issues due to valid data.",
            "zh": "æˆ‘ä»¬ä»æ•°æ®è´¨é‡æŠ¥å‘Šä¸­è¯†åˆ«çš„æ•°æ®è´¨é‡é—®é¢˜åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼šæ— æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜å’Œæœ‰æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we sum across the posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false, we will get a value of 1.0 (see Table 6.6[267]).",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨ FRAUD = false çš„æ¡ä»¶ä¸‹å¯¹ GUARANTOR/COAPPLICANT ç‰¹å¾çš„åéªŒæ¦‚ç‡åˆ†å¸ƒæ±‚å’Œï¼Œæˆ‘ä»¬å°†å¾—åˆ° 1.0 çš„å€¼ï¼ˆå‚è§è¡¨ 6.6[267]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, distance computations are sensitive to the value ranges of the features in the dataset.",
            "zh": "æ€»ä¹‹ï¼Œè·ç¦»è®¡ç®—å¯¹æ•°æ®é›†ä¸­è¦ç´ çš„å€¼èŒƒå›´å¾ˆæ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "This is calculated by summing over all the instances in the training set the prediction error multiplied by the value of the relevant feature for that instance (see Equation (7.16)[327]).",
            "zh": "è¿™æ˜¯é€šè¿‡å°†è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰å®ä¾‹çš„é¢„æµ‹è¯¯å·®ä¹˜ä»¥è¯¥å®ä¾‹çš„ç›¸å…³ç‰¹å¾å€¼ç›¸åŠ æ¥è®¡ç®—çš„ï¼ˆå‚è§å…¬å¼ ï¼ˆ7.16ï¼‰[327]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, it is important to remember that neurons in a convolutional network do have bias terms and that they are learned in the same way, as they are feedforward networks.",
            "zh": "ç„¶è€Œï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå·ç§¯ç½‘ç»œä¸­çš„ç¥ç»å…ƒç¡®å®æœ‰åå·®é¡¹ï¼Œå¹¶ä¸”å®ƒä»¬çš„å­¦ä¹ æ–¹å¼ä¸å‰é¦ˆç½‘ç»œç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2â€…â€…â€…Choosing a Machine Learning Approach",
            "zh": "14.2 é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•"
        }
    },
    {
        "translation": {
            "en": "Once the required probabilities are calculated, our naive Bayes model is ready to make predictions for queries.",
            "zh": "ä¸€æ—¦è®¡ç®—å‡ºæ‰€éœ€çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹å°±å¯ä»¥å¯¹æŸ¥è¯¢è¿›è¡Œé¢„æµ‹äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) At the beginning of the first episode the player is dealt (2 â™¥,K â™£), the dealer is dealt (A â™¦,3 â™¦), and the dealerâ€™s visible card is the A â™¦. Given these cards, what state is the TwentyTwos playing agent in?",
            "zh": "ï¼ˆaï¼‰åœ¨ç¬¬ä¸€é›†å¼€å§‹æ—¶ï¼Œç©å®¶è¢«å‘ç‰Œï¼ˆ2ï¼ŒKï¼‰ï¼Œåº„å®¶è¢«å‘ç‰Œï¼ˆAï¼Œ3 â™¦ â™¦ï¼‰ï¼Œåº„å®¶çš„å¯è§ç‰Œæ˜¯A â™¦ã€‚ â™¥ â™£æœ‰äº†è¿™äº›ç‰Œï¼ŒäºŒåäºŒé˜Ÿçš„ç‰¹å·¥å¤„äºä»€ä¹ˆçŠ¶æ€ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Table 5.4[191] lists the updated dataset when the example query instance with its prediction of yes is included.5 Figure 5.5(a)[192] illustrates the Voronoi tessellation of the feature space that results from this update, and Figure 5.5(b)[192] presents the updated decision boundary.",
            "zh": "è¡¨ 5.4[191] åˆ—å‡ºäº†åŒ…å«é¢„æµ‹ä¸º yes çš„ç¤ºä¾‹æŸ¥è¯¢å®ä¾‹æ—¶æ›´æ–°çš„æ•°æ®é›†ã€‚5 å›¾ 5.5ï¼ˆaï¼‰[192] è¯´æ˜äº†æ­¤æ›´æ–°å¯¼è‡´çš„ç‰¹å¾ç©ºé—´çš„ Voronoi ç»†åˆ†ï¼Œå›¾ 5.5ï¼ˆbï¼‰[192] æ˜¾ç¤ºäº†æ›´æ–°åçš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "25.56%",
            "zh": "25.56%"
        }
    },
    {
        "translation": {
            "en": "5.2â€…â€…â€…The SPEED and AGILITY ratings for 20 college athletes and whether they were drafted by a professional team.",
            "zh": "5.2 20 åå¤§å­¦è¿åŠ¨å‘˜çš„é€Ÿåº¦å’Œæ•æ·æ€§è¯„çº§ï¼Œä»¥åŠä»–ä»¬æ˜¯å¦ç”±ä¸“ä¸šå›¢é˜Ÿé€‰æ‹”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dimensions of the matrix are dependent on the number of features and the number of values in the domains of the features.",
            "zh": "çŸ©é˜µçš„ç»´åº¦å–å†³äºç‰¹å¾çš„æ•°é‡å’Œç‰¹å¾åŸŸä¸­çš„å€¼çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is at this point that the distinction between raw and derived features becomes apparent.",
            "zh": "æ­£æ˜¯åœ¨è¿™ä¸€ç‚¹ä¸Šï¼ŒåŸå§‹ç‰¹å¾å’Œæ´¾ç”Ÿç‰¹å¾ä¹‹é—´çš„åŒºåˆ«å˜å¾—æ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability distribution, 59, 94, 247, 752, 761",
            "zh": "æ¦‚ç‡åˆ†å¸ƒï¼Œ 59ï¼Œ 94ï¼Œ 247ï¼Œ 752ï¼Œ 761"
        }
    },
    {
        "translation": {
            "en": "The main conclusions from this, and other similar studies, is that no machine learning approach is universally best, and experimentation with different approaches is the best way to ensure that an accurate model is built.",
            "zh": "ä»è¿™é¡¹ç ”ç©¶å’Œå…¶ä»–ç±»ä¼¼ç ”ç©¶ä¸­å¾—å‡ºçš„ä¸»è¦ç»“è®ºæ˜¯ï¼Œæ²¡æœ‰ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•æ™®éæ˜¯æœ€å¥½çš„ï¼Œä½¿ç”¨ä¸åŒçš„æ–¹æ³•è¿›è¡Œå®éªŒæ˜¯ç¡®ä¿æ„å»ºå‡†ç¡®æ¨¡å‹çš„æœ€ä½³æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of the softmax activation function Ï†sm over a vector of three logits l.",
            "zh": "softmax æ¿€æ´»å‡½æ•° Ï†sm åœ¨ 3 logits l çš„å‘é‡ä¸Šçš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we do this when sampling the weights for each of the layers in the network, then the variance of the z values across all the layers will be stable.",
            "zh": "å¦‚æœæˆ‘ä»¬åœ¨å¯¹ç½‘ç»œä¸­æ¯ä¸ªå±‚çš„æƒé‡è¿›è¡Œé‡‡æ ·æ—¶è¿™æ ·åšï¼Œé‚£ä¹ˆæ‰€æœ‰å±‚çš„ z å€¼çš„æ–¹å·®å°†æ˜¯ç¨³å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In 2010 AT hired Ross, a predictive data analytics specialist, to take a new approach to reducing customer churn. This case study describes the work carried out by Ross when he took AT through the CRISP-DM process1 in order to develop a predictive data analytics solution to this business problem. The remainder of this chapter will discuss how each phase of the CRISP-DM process was addressed in this project.",
            "zh": "2010 å¹´ï¼ŒAT è˜è¯·äº†é¢„æµ‹æ•°æ®åˆ†æä¸“å®¶ Ross æ¥é‡‡ç”¨ä¸€ç§æ–°æ–¹æ³•æ¥å‡å°‘å®¢æˆ·æµå¤±ã€‚æœ¬æ¡ˆä¾‹ç ”ç©¶æè¿°äº† Ross åœ¨ä½¿ç”¨ CRISP-DM æµç¨‹ 1 æ—¶æ‰€åšçš„å·¥ä½œï¼Œä»¥ä¾¿ä¸ºè¯¥ä¸šåŠ¡é—®é¢˜å¼€å‘é¢„æµ‹æ€§æ•°æ®åˆ†æè§£å†³æ–¹æ¡ˆã€‚æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å°†è®¨è®ºå¦‚ä½•åœ¨è¯¥é¡¹ç›®ä¸­è§£å†³ CRISP-DM è¿‡ç¨‹çš„æ¯ä¸ªé˜¶æ®µã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, there are possibly legal restrictions associated with making this kind of contact.",
            "zh": "æœ€åï¼Œè¿›è¡Œè¿™ç§æ¥è§¦å¯èƒ½å­˜åœ¨æ³•å¾‹é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, here we assume that the weight matrices do not include bias terms.",
            "zh": "å› æ­¤ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾æƒé‡çŸ©é˜µä¸åŒ…æ‹¬åå·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is also important that densities are shown rather than frequencies, as the overall bar plots on the left of each visualization cover much more of the dataset than the other two plots, so frequency-based plots would look very uneven.",
            "zh": "æ˜¾ç¤ºå¯†åº¦è€Œä¸æ˜¯é¢‘ç‡ä¹Ÿå¾ˆé‡è¦ï¼Œå› ä¸ºæ¯ä¸ªå¯è§†åŒ–å·¦ä¾§çš„æ•´ä½“æ¡å½¢å›¾æ¯”å…¶ä»–ä¸¤ä¸ªå›¾è¦†ç›–äº†æ›´å¤šçš„æ•°æ®é›†ï¼Œå› æ­¤åŸºäºé¢‘ç‡çš„å›¾çœ‹èµ·æ¥éå¸¸ä¸å‡åŒ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, the elements along the main diagonal list the covariance between a feature and itself, in other words, the variance of the feature.",
            "zh": "å› æ­¤ï¼Œæ²¿ä¸»å¯¹è§’çº¿çš„å…ƒç´ åˆ—å‡ºäº†ç‰¹å¾ä¸è‡ªèº«ä¹‹é—´çš„åæ–¹å·®ï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯ç‰¹å¾çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.16",
            "zh": "å›¾ 5.16"
        }
    },
    {
        "translation": {
            "en": "Figure 8.14",
            "zh": "å›¾ 8.14"
        }
    },
    {
        "translation": {
            "en": "2. Is the approach suitable for the type of prediction we want to make and the types of descriptive features we are using?",
            "zh": "2. è¯¥æ–¹æ³•æ˜¯å¦é€‚åˆæˆ‘ä»¬æƒ³è¦è¿›è¡Œçš„é¢„æµ‹ç±»å‹å’Œæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾ç±»å‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Table 6.16",
            "zh": "è¡¨ 6.16"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11(a)[561] shows the changing values for TPR and TNR for the prediction scores shown in Table 9.13[560] as the threshold is varied from 0 to 1.13 This graph shows that changing the value of the threshold results in a trade-off between accuracy for predictions of positive target levels and accuracy for predictions of negative target levels. Capturing this trade-off is the basis of the ROC curve.",
            "zh": "å›¾ 9.11ï¼ˆaï¼‰[561] æ˜¾ç¤ºäº†è¡¨ 9.13[560] ä¸­æ‰€ç¤ºé¢„æµ‹åˆ†æ•°çš„ TPR å’Œ TNR å€¼çš„å˜åŒ–å€¼ï¼Œå› ä¸ºé˜ˆå€¼ä» 0 åˆ° 1.13 å˜åŒ–ã€‚æ•æ‰è¿™ç§æƒè¡¡æ˜¯ ROC æ›²çº¿çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "false alarms, 538",
            "zh": "è¯¯æŠ¥ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "This w[0] term is often referred to as the bias parameter because in the absence of any other input, the output of the weighted sum is biased to be the value of w[0].",
            "zh": "è¿™ä¸ª w[0] é¡¹é€šå¸¸è¢«ç§°ä¸ºåç½®å‚æ•°ï¼Œå› ä¸ºåœ¨æ²¡æœ‰ä»»ä½•å…¶ä»–è¾“å…¥çš„æƒ…å†µä¸‹ï¼ŒåŠ æƒå’Œçš„è¾“å‡ºåç½®ä¸º w[0] çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "100.16%",
            "zh": "100.16%"
        }
    },
    {
        "translation": {
            "en": "This ensures that no error gradients flow back through the neurons that were dropped for this example.",
            "zh": "è¿™ç¡®ä¿äº†æ²¡æœ‰è¯¯å·®æ¢¯åº¦å›æµå›æœ¬ç¤ºä¾‹ä¸­ä¸¢å¼ƒçš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4â€…â€…â€…The revised domain concepts diagram for the galaxy classification task.",
            "zh": "13.4 ä¿®è®¢åçš„æ˜Ÿç³»åˆ†ç±»ä»»åŠ¡é¢†åŸŸæ¦‚å¿µå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Clinicians often use BMI as a combined measure of an individualâ€™s WEIGHT and HEIGHT. BMI is defined as an individualâ€™s weight in kilograms divided by their height in meters-squared. Assuming that the profiles of the five individuals in the system were updated so that the features WEIGHT and HEIGHT were replaced by a single feature BMI and also that the doctor entered the patientâ€™s BMI into the system, what prediction would the system return for this patient?",
            "zh": "ï¼ˆbï¼‰ ä¸´åºŠåŒ»ç”Ÿç»å¸¸ä½¿ç”¨ BMI ä½œä¸ºä¸ªäººä½“é‡å’Œèº«é«˜çš„ç»¼åˆè¡¡é‡æ ‡å‡†ã€‚BMI å®šä¹‰ä¸ºä¸ªäººçš„ä½“é‡ï¼ˆå…¬æ–¤ï¼‰é™¤ä»¥èº«é«˜ï¼ˆç±³ï¼‰çš„å¹³æ–¹ã€‚å‡è®¾ç³»ç»Ÿä¸­äº”ä¸ªäººçš„ä¸ªäººèµ„æ–™è¢«æ›´æ–°ï¼Œä»¥ä¾¿å°†ç‰¹å¾ WEIGHT å’Œ HEIGHT æ›¿æ¢ä¸ºå•ä¸ªç‰¹å¾ BMIï¼Œå¹¶ä¸”åŒ»ç”Ÿå°†æ‚£è€…çš„ BMI è¾“å…¥ç³»ç»Ÿï¼Œç³»ç»Ÿä¼šä¸ºè¯¥æ‚£è€…è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "slope of a line, 313, 766",
            "zh": "ç›´çº¿çš„æ–œç‡ï¼Œ313,766"
        }
    },
    {
        "translation": {
            "en": "Correctly predicting the bad level for a potential borrower results in no profit as no money is loaned.11 Incorrectly predicting the good level for a potential borrower who goes on to default on the loan, however, results in a loan not being repaid.",
            "zh": "11 ç„¶è€Œï¼Œé”™è¯¯åœ°é¢„æµ‹æ½œåœ¨å€Ÿæ¬¾äººçš„ä¸è‰¯æ°´å¹³ä¼šå¯¼è‡´æ²¡æœ‰åˆ©æ¶¦ï¼Œå› ä¸ºæ²¡æœ‰é’±è¢«å€Ÿå‡º.11 ç„¶è€Œï¼Œé”™è¯¯åœ°é¢„æµ‹äº†ç»§ç»­æ‹–æ¬ è´·æ¬¾çš„æ½œåœ¨å€Ÿæ¬¾äººçš„è‰¯å¥½æ°´å¹³ï¼Œä¼šå¯¼è‡´è´·æ¬¾æ— æ³•å¿è¿˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The same can actually be done for models that predict binary categorical targets by dividing the prediction scores into deciles.",
            "zh": "å¯¹äºé€šè¿‡å°†é¢„æµ‹åˆ†æ•°åˆ’åˆ†ä¸ºååˆ†ä½æ•°æ¥é¢„æµ‹äºŒå…ƒåˆ†ç±»ç›®æ ‡çš„æ¨¡å‹ï¼Œå®é™…ä¸Šä¹Ÿå¯ä»¥è¿™æ ·åšã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the selection of a machine learning approach also depends on the aspects of an application scenario described above (speed, capacity for retraining, interpretability), and often, these factors are a bigger driver for the selection of a machine learning approach than prediction accuracy.",
            "zh": "æ­¤å¤–ï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„é€‰æ‹©è¿˜å–å†³äºä¸Šè¿°åº”ç”¨åœºæ™¯çš„å„ä¸ªæ–¹é¢ï¼ˆé€Ÿåº¦ã€å†è®­ç»ƒèƒ½åŠ›ã€å¯è§£é‡Šæ€§ï¼‰ï¼Œé€šå¸¸ï¼Œè¿™äº›å› ç´ æ˜¯é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•çš„æ›´å¤§é©±åŠ¨å› ç´ ï¼Œè€Œä¸æ˜¯é¢„æµ‹å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "binary data, 34",
            "zh": "äºŒè¿›åˆ¶æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "7.10â€…â€…â€…A dataset showing participantsâ€™ responses to viewing positive and negative images measured on the EEG P20 and P45 potentials.",
            "zh": "7.10 ä¸€ä¸ªæ•°æ®é›†ï¼Œæ˜¾ç¤ºå‚ä¸è€…å¯¹è§‚çœ‹åœ¨ EEG P20 å’Œ P45 ç”µä½ä¸Šæµ‹é‡çš„æ­£é¢å’Œè´Ÿé¢å›¾åƒçš„ååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "In forward sequential selection, the search starts in a state with no features (shown on the left of Figure 5.19[228]).",
            "zh": "åœ¨å‰å‘é¡ºåºé€‰æ‹©ä¸­ï¼Œæœç´¢ä»¥æ²¡æœ‰ç‰¹å¾çš„çŠ¶æ€å¼€å§‹ï¼ˆå¦‚å›¾ 5.19[228] å·¦ä¾§æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if a prediction model is being used as a diagnostic tool in a medical scenario, it is not sufficient for the system to simply return a diagnosis.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœé¢„æµ‹æ¨¡å‹åœ¨åŒ»ç–—åœºæ™¯ä¸­ç”¨ä½œè¯Šæ–­å·¥å…·ï¼Œåˆ™ç³»ç»Ÿä»…è¿”å›è¯Šæ–­æ˜¯ä¸å¤Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Then in Section 8.4.3[463] we explain how to adapt the design of a neural network to classification problems by using a softmax output layer and the cross-entropy loss function.",
            "zh": "ç„¶åï¼Œåœ¨ç¬¬ 8.4.3 èŠ‚[463]ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šäº†å¦‚ä½•é€šè¿‡ä½¿ç”¨ softmax è¾“å‡ºå±‚å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è°ƒæ•´ç¥ç»ç½‘ç»œçš„è®¾è®¡ä»¥é€‚åº”åˆ†ç±»é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "discontinuous function, 341",
            "zh": "ä¸è¿ç»­å‡½æ•°ï¼Œ341"
        }
    },
    {
        "translation": {
            "en": "Multiplying the difference in feature values by the inverse covariance matrix has two effects.",
            "zh": "å°†ç‰¹å¾å€¼çš„å·®å€¼ä¹˜ä»¥é€†åæ–¹å·®çŸ©é˜µæœ‰ä¸¤ä¸ªæ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "matrix product, 385",
            "zh": "çŸ©é˜µä¹˜ç§¯ï¼Œ385"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(b) Visualizations of the distributions of the descriptive features in the mobile phone customer dataset in Table 10.1[604] across the complete dataset, and divided by the clustering found using k-means clustering (k = 3).",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆbï¼‰ è¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­çš„åˆ†å¸ƒå¯è§†åŒ–ï¼Œå¹¶é™¤ä»¥ä½¿ç”¨k-meansèšç±»ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6.1â€…â€…â€…Normalization",
            "zh": "3.6.1 å½’ä¸€åŒ–"
        }
    },
    {
        "translation": {
            "en": "A PDF is an abstraction over a density histogram and, as such, defines a density curve.",
            "zh": "PDF æ˜¯å¯¹å¯†åº¦ç›´æ–¹å›¾çš„æŠ½è±¡ï¼Œå› æ­¤å®šä¹‰äº†å¯†åº¦æ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Only 3 of these scenarios, however, will lead to the agent staying in the PM-DH state.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›åœºæ™¯ä¸­åªæœ‰ 3 ç§ä¼šå¯¼è‡´ä»£ç†ä¿æŒ PM-DH çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 7.10(b)[340] the decision boundary is defined as",
            "zh": "åœ¨å›¾7.10ï¼ˆbï¼‰[340]ä¸­ï¼Œå†³ç­–è¾¹ç•Œå®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Using a horizontal and vertical stride of 1 means that there is a relatively large overlap in the receptive fields between a neuron and its neighbors.",
            "zh": "ä½¿ç”¨æ°´å¹³å’Œå‚ç›´æ­¥å¹… 1 æ„å‘³ç€ç¥ç»å…ƒä¸å…¶é‚»å±…ä¹‹é—´çš„æ„Ÿå—é‡å­˜åœ¨ç›¸å¯¹è¾ƒå¤§çš„é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "Near-sighted parents are more likely to have near-sighted children, and it is this that accounts for the correlation between night-light use and near-sightedness in children, rather than any causal link.",
            "zh": "è¿‘è§†çš„çˆ¶æ¯æ›´æœ‰å¯èƒ½ç”Ÿå‡ºè¿‘è§†çš„å­©å­ï¼Œæ­£æ˜¯è¿™ä¸€ç‚¹è§£é‡Šäº†å„¿ç«¥ä½¿ç”¨å¤œç¯ä¸è¿‘è§†ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œè€Œä¸æ˜¯ä»»ä½•å› æœå…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The table below gives details of symptoms that patients presented and whether they were suffering from meningitis.",
            "zh": "2. ä¸‹è¡¨è¯¦ç»†ä»‹ç»äº†æ‚£è€…å‡ºç°çš„ç—‡çŠ¶ä»¥åŠä»–ä»¬æ˜¯å¦æ‚£æœ‰è„‘è†œç‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.10[212] shows the calculation of the numerator and denominator of Equation (5.8)[210] for our whiskey bottle example, using the normalized dataset with k set to 20 (the full size of the dataset). The final prediction for the price of the bottle of whiskey we plan to sell is",
            "zh": "è¡¨5.10[212]æ˜¾ç¤ºäº†æˆ‘ä»¬çš„å¨å£«å¿Œé…’ç“¶ç¤ºä¾‹çš„ç­‰å¼ï¼ˆ5.8ï¼‰[210]çš„åˆ†å­å’Œåˆ†æ¯çš„è®¡ç®—ï¼Œä½¿ç”¨kè®¾ç½®ä¸º20ï¼ˆæ•°æ®é›†çš„å…¨å¤§å°ï¼‰çš„å½’ä¸€åŒ–æ•°æ®é›†ã€‚æˆ‘ä»¬è®¡åˆ’å‡ºå”®çš„ä¸€ç“¶å¨å£«å¿Œä»·æ ¼çš„æœ€ç»ˆé¢„æµ‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Figure 8.9",
            "zh": "å›¾ 8.9"
        }
    },
    {
        "translation": {
            "en": "Figure 9.3",
            "zh": "å›¾ 9.3"
        }
    },
    {
        "translation": {
            "en": "For more information on stroke and risk factors related to stroke, please see the National Heart, Lung, and Blood Institute on Stroke: https://www.nhlbi.nih.gov/health-topics/stroke.",
            "zh": "æœ‰å…³å’ä¸­å’Œå’ä¸­ç›¸å…³å±é™©å› ç´ çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ç¾å›½å›½å®¶å¿ƒè‚ºè¡€æ¶²ç ”ç©¶æ‰€å’ä¸­ï¼šhttps://www.nhlbi.nih.gov/health-topics/strokeã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) The charity for which the model is being built typically has only enough money to send a mailshot to the top 20% of its contact list. Based on the cumulative gain chart generated in the previous part, would you recommend that Model 1 or Model 2 would perform best for the charity?",
            "zh": "ï¼ˆeï¼‰ ä¸ºä¹‹æ„å»ºæ¨¡å‹çš„æ…ˆå–„æœºæ„é€šå¸¸åªæœ‰è¶³å¤Ÿçš„èµ„é‡‘å‘å…¶è”ç³»äººåˆ—è¡¨ä¸­çš„å‰ 20% å‘é€é‚®ä»¶ã€‚æ ¹æ®ä¸Šä¸€éƒ¨åˆ†ç”Ÿæˆçš„ç´¯ç§¯æ”¶ç›Šå›¾è¡¨ï¼Œæ‚¨è®¤ä¸ºæ¨¡å‹ 1 æˆ–æ¨¡å‹ 2 å¯¹æ…ˆå–„æœºæ„æ¥è¯´è¡¨ç°æœ€å¥½å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "6.3â€…â€…â€…Standard Approach: The Naive Bayes Model",
            "zh": "6.3 æ ‡å‡†æ–¹æ³•ï¼šæœ´ç´ è´å¶æ–¯æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Most of the advice given in the previous sections on choosing machine learning approaches and completing successful projects, also equally applies to these machine learning approaches, and a good grounding in predictive modeling makes adding these approaches to your toolkit relatively straight-forward.",
            "zh": "å‰é¢å‡ èŠ‚ä¸­ç»™å‡ºçš„å…³äºé€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•å’Œå®ŒæˆæˆåŠŸé¡¹ç›®çš„å¤§å¤šæ•°å»ºè®®ä¹ŸåŒæ ·é€‚ç”¨äºè¿™äº›æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¹¶ä¸”é¢„æµ‹å»ºæ¨¡çš„è‰¯å¥½åŸºç¡€ä½¿å¾—å°†è¿™äº›æ–¹æ³•æ·»åŠ åˆ°æ‚¨çš„å·¥å…·åŒ…ä¸­å˜å¾—ç›¸å¯¹ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sampling techniques can be used to reduce the size of a large ABT to make exploratory analysis easier, to change the distributions of target features in an ABT, and to generate different portions of an ABT to use for training and evaluating a model.",
            "zh": "é‡‡æ ·æŠ€æœ¯å¯ç”¨äºå‡å°å¤§å‹ ABT çš„å¤§å°ï¼Œä»¥ä¾¿æ›´è½»æ¾åœ°è¿›è¡Œæ¢ç´¢æ€§åˆ†æï¼Œæ›´æ”¹ ABT ä¸­ç›®æ ‡ç‰¹å¾çš„åˆ†å¸ƒï¼Œå¹¶ç”Ÿæˆ ABT çš„ä¸åŒéƒ¨åˆ†ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.12[280] shows how these values are calculated, and the dashed lines in Figure 6.8[279] plot the density curves that result from this process.",
            "zh": "è¡¨6.12[280]æ˜¾ç¤ºäº†è¿™äº›å€¼çš„è®¡ç®—æ–¹æ³•ï¼Œå›¾6.8[279]ä¸­çš„è™šçº¿ç»˜åˆ¶äº†è¿™ä¸€è¿‡ç¨‹äº§ç”Ÿçš„å¯†åº¦æ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use a lowercase z to represent the result of the weighted sum of the inputs in a neuron.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨å°å†™çš„ z æ¥è¡¨ç¤ºç¥ç»å…ƒä¸­è¾“å…¥çš„åŠ æƒå’Œçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (11.18)[652] still includes the expected return that arises from taking all of the actions after at essentially as it was stated before in Equation (11.17)[651].",
            "zh": "ç­‰å¼ï¼ˆ11.18ï¼‰[652]ä»ç„¶åŒ…æ‹¬åœ¨ç­‰å¼ï¼ˆ11.17ï¼‰[651]ä¸­é™ˆè¿°çš„åœ¨atä¹‹åé‡‡å–æ‰€æœ‰è¡ŒåŠ¨æ‰€äº§ç”Ÿçš„é¢„æœŸå›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "A hidden feature is a feature whose value is not specified as part of the evidence.",
            "zh": "éšè—ç‰¹å¾æ˜¯æŒ‡å…¶å€¼æœªæŒ‡å®šä¸ºè¯æ®çš„ä¸€éƒ¨åˆ†çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a mobile telecoms scenario, we could represent customers with just two descriptive features: the average number of SMS messages a customer sends per month, and the average number of VOICE calls a customer makes per month.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨ç§»åŠ¨ç”µä¿¡åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä»…ä½¿ç”¨ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾æ¥è¡¨ç¤ºå®¢æˆ·ï¼šå®¢æˆ·æ¯æœˆå‘é€çš„å¹³å‡çŸ­ä¿¡æ•°ï¼Œä»¥åŠå®¢æˆ·æ¯æœˆæ‹¨æ‰“ VOICE çš„å¹³å‡æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The mathematical foundation of these approaches can be described using five simple (but important) equations: Claude Shannonâ€™s model of entropy (Equation (14.1)[731]), Euclidean distance (Equation (14.2)[731]), Bayesâ€™ Theorem (Equation (14.3)[731]), the sum of squared errors (Equation (14.4)[731]), and the application of the chain rule to backpropagate error gradients in a neural network (Equation (14.5)[731]).",
            "zh": "è¿™äº›æ–¹æ³•çš„æ•°å­¦åŸºç¡€å¯ä»¥ç”¨äº”ä¸ªç®€å•ï¼ˆä½†å¾ˆé‡è¦ï¼‰çš„æ–¹ç¨‹æ¥æè¿°ï¼šå…‹åŠ³å¾·Â·é¦™å†œçš„ç†µæ¨¡å‹ï¼ˆæ–¹ç¨‹ï¼ˆ14.1ï¼‰[731]ï¼‰ã€æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆæ–¹ç¨‹ï¼ˆ14.2ï¼‰[731]ï¼‰ã€è´å¶æ–¯å®šç†ï¼ˆæ–¹ç¨‹ï¼ˆ14.3ï¼‰[731]ï¼‰ã€è¯¯å·®çš„å¹³æ–¹å’Œï¼ˆæ–¹ç¨‹ï¼ˆ14.4ï¼‰[731]ï¼‰ï¼Œä»¥åŠé“¾å¼æ³•åˆ™åœ¨ç¥ç»ç½‘ç»œä¸­åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦çš„åº”ç”¨ï¼ˆæ–¹ç¨‹ï¼ˆ14.5ï¼‰[731]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "INTRODUCTION TO MACHINE LEARNING AND DATA ANALYTICS",
            "zh": "æœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æç®€ä»‹"
        }
    },
    {
        "translation": {
            "en": "Unique SDSS object identifier",
            "zh": "å”¯ä¸€ SDSS å¯¹è±¡æ ‡è¯†ç¬¦"
        }
    },
    {
        "translation": {
            "en": "The partitioning of the dataset in Table 4.11[152] based on SEASON and WORK DAY features and the computation of the weighted variance for each partitioning.",
            "zh": "è¡¨4.11[152]ä¸­åŸºäºSEASONå’ŒWORK DAYç‰¹å¾å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºï¼Œå¹¶è®¡ç®—æ¯ä¸ªåˆ†åŒºçš„åŠ æƒæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "; CLAIM TO PREMIUM PAID RATIO: CLAIM TO PREM.",
            "zh": ";ç†èµ”ä¸å·²ä»˜ä¿è´¹æ¯”ç‡ï¼šç†èµ”è‡³é¢„ä»˜æ¬¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Sherlock Holmes",
            "zh": "â€”â€”å¤æ´›å…‹Â·ç¦å°”æ‘©æ–¯"
        }
    },
    {
        "translation": {
            "en": "In the email classification example, the percentage of positive (spam) instances in the full test dataset is .",
            "zh": "åœ¨ç”µå­é‚®ä»¶åˆ†ç±»ç¤ºä¾‹ä¸­ï¼Œå®Œæ•´æµ‹è¯•æ•°æ®é›†ä¸­é˜³æ€§ï¼ˆåƒåœ¾é‚®ä»¶ï¼‰å®ä¾‹çš„ç™¾åˆ†æ¯”ä¸º ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a patience parameter allows the validation error to fluctuate a bit during training while still allow training to progress; it is only when we have observed a clear trend over multiple iterations of a relatively high validation error that we stop training.",
            "zh": "ä½¿ç”¨è€å¿ƒå‚æ•°å…è®¸éªŒè¯é”™è¯¯åœ¨è®­ç»ƒæœŸé—´ç•¥æœ‰æ³¢åŠ¨ï¼ŒåŒæ—¶ä»å…è®¸è®­ç»ƒè¿›è¡Œ;åªæœ‰å½“æˆ‘ä»¬åœ¨å¤šæ¬¡è¿­ä»£ä¸­è§‚å¯Ÿåˆ°ç›¸å¯¹è¾ƒé«˜çš„éªŒè¯è¯¯å·®çš„æ˜æ˜¾è¶‹åŠ¿æ—¶ï¼Œæˆ‘ä»¬æ‰ä¼šåœæ­¢è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This leads to the same conclusion with regard to model ranking as the root mean squared error measures: namely, that the regression model has better performance on this task than the nearest neighbor model.",
            "zh": "è¿™å¯¼è‡´äº†ä¸å‡æ–¹æ ¹è¯¯å·®åº¦é‡ç›¸åŒçš„æ¨¡å‹æ’åºç»“è®ºï¼šå³å›å½’æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸Šæ¯”æœ€è¿‘é‚»æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "We subsequently explain what is causing both these vanishing and exploding z values.",
            "zh": "éšåï¼Œæˆ‘ä»¬å°†è§£é‡Šå¯¼è‡´è¿™äº›æ¶ˆå¤±å’Œçˆ†ç‚¸çš„ z å€¼çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "On completion of each action the agent receives an immediate scalar reward indicating whether the outcome of the action was positive or negative, and to what degree.",
            "zh": "åœ¨å®Œæˆæ¯ä¸ªæ“ä½œåï¼Œæ™ºèƒ½ä½“ä¼šç«‹å³æ”¶åˆ°æ ‡é‡å¥–åŠ±ï¼ŒæŒ‡ç¤ºæ“ä½œçš„ç»“æœæ˜¯ç§¯æçš„è¿˜æ˜¯æ¶ˆæçš„ï¼Œä»¥åŠç¨‹åº¦å¦‚ä½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "transpose, 772",
            "zh": "è½¬ç½®ï¼Œ772"
        }
    },
    {
        "translation": {
            "en": "The backpropagation algorithm begins by initializing the weights of the network.",
            "zh": "åå‘ä¼ æ’­ç®—æ³•é¦–å…ˆåˆå§‹åŒ–ç½‘ç»œçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This trend has continued and recent, high-profile successes include Deep Q Learning for Atari video games (Mnih et al., 2013), AlphaGo for Go (Silver et al., 2017), AlphaZero for chess (Silver et al., 2018), and the OpenAI Five player for DOTA 2 (McCandlish et al., 2018).",
            "zh": "è¿™ç§è¶‹åŠ¿ä»åœ¨ç»§ç»­ï¼Œæœ€è¿‘å¤‡å—ç©ç›®çš„æˆåŠŸåŒ…æ‹¬ç”¨äº Atari è§†é¢‘æ¸¸æˆçš„ Deep Q Learningï¼ˆMnih ç­‰äººï¼Œ2013 å¹´ï¼‰ã€ç”¨äºå›´æ£‹çš„ AlphaGoï¼ˆSilver ç­‰äººï¼Œ2017 å¹´ï¼‰ã€ç”¨äºå›½é™…è±¡æ£‹çš„ AlphaZeroï¼ˆSilver ç­‰äººï¼Œ2018 å¹´ï¼‰å’Œ DOTA 2 çš„ OpenAI Five ç©å®¶ï¼ˆMcCandlish ç­‰äººï¼Œ2018 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.34",
            "zh": "å›¾ 8.34"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values of all instances above the decision boundary will result in a negative value when plugged into the decision boundary equation, whereas the descriptive features of all instances below the decision boundary will result in a positive value.",
            "zh": "å½“ä»£å…¥å†³ç­–è¾¹ç•Œæ–¹ç¨‹æ—¶ï¼Œå†³ç­–è¾¹ç•Œä»¥ä¸Šæ‰€æœ‰å®ä¾‹çš„æè¿°æ€§ç‰¹å¾å€¼å°†äº§ç”Ÿè´Ÿå€¼ï¼Œè€Œå†³ç­–è¾¹ç•Œä»¥ä¸‹æ‰€æœ‰å®ä¾‹çš„æè¿°æ€§ç‰¹å¾å°†äº§ç”Ÿæ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "A number of other features exhibited a similar pattern.",
            "zh": "è®¸å¤šå…¶ä»–ç‰¹å¾ä¹Ÿè¡¨ç°å‡ºç±»ä¼¼çš„æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "LSTM, 508",
            "zh": "LSTMï¼Œ508"
        }
    },
    {
        "translation": {
            "en": "7.5â€…â€…â€…(a) A 3D surface plot and (b) a birdâ€™s-eye view contour plot of the error surface for the office rentals dataset showing the path that the gradient descent algorithm takes toward the best-fit model.",
            "zh": "7.5 ï¼ˆaï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†è¯¯å·®é¢çš„ 3D æ›²é¢å›¾å’Œ ï¼ˆbï¼‰ é¸Ÿç°ç­‰å€¼çº¿å›¾ï¼Œæ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™ç®—æ³•èµ°å‘æœ€ä½³æ‹Ÿåˆæ¨¡å‹çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "What this means is that for any given input vector, only a subset of the neurons in the network will activate (i.e., ai > 0).",
            "zh": "è¿™æ„å‘³ç€ï¼Œå¯¹äºä»»ä½•ç»™å®šçš„è¾“å…¥å‘é‡ï¼Œç½‘ç»œä¸­åªæœ‰ä¸€éƒ¨åˆ†ç¥ç»å…ƒä¼šæ¿€æ´»ï¼ˆå³ ai > 0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Normalization also has a part to play here.",
            "zh": "å½’ä¸€åŒ–åœ¨è¿™é‡Œä¹Ÿå‘æŒ¥äº†ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order from top to bottom, we show decision trees (without pruning), nearest neighbor models (with k = 3 and using majority voting), naive Bayes models (using normal distributions to represent the two continuous feature values), and logistic regression models (using a simple linear model).",
            "zh": "ä»ä¸Šåˆ°ä¸‹ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å†³ç­–æ ‘ï¼ˆä¸ä¿®å‰ªï¼‰ã€æœ€è¿‘é‚»æ¨¡å‹ï¼ˆk = 3 å¹¶ä½¿ç”¨å¤šæ•°æŠ•ç¥¨ï¼‰ã€æœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼ˆä½¿ç”¨æ­£æ€åˆ†å¸ƒæ¥è¡¨ç¤ºä¸¤ä¸ªè¿ç»­ç‰¹å¾å€¼ï¼‰å’Œé€»è¾‘å›å½’æ¨¡å‹ï¼ˆä½¿ç”¨ç®€å•çš„çº¿æ€§æ¨¡å‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the big idea here is to figure out which features are the most informative ones to ask questions about by considering the effects of the different answers to the questions, in terms of how the domain is split up after the answer is received and the likelihood of each of the answers.",
            "zh": "å› æ­¤ï¼Œè¿™é‡Œçš„å¤§æƒ³æ³•æ˜¯é€šè¿‡è€ƒè™‘é—®é¢˜çš„ä¸åŒç­”æ¡ˆçš„å½±å“ï¼Œåœ¨æ”¶åˆ°ç­”æ¡ˆåå¦‚ä½•åˆ’åˆ†åŸŸä»¥åŠæ¯ä¸ªç­”æ¡ˆçš„å¯èƒ½æ€§æ–¹é¢ï¼Œæ‰¾å‡ºå“ªäº›åŠŸèƒ½æ˜¯æœ€æœ‰ç”¨çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. Sometimes target levels in categorical prediction problems are referred to as classes, which is where this name comes from.",
            "zh": "7. æœ‰æ—¶åˆ†ç±»é¢„æµ‹é—®é¢˜ä¸­çš„ç›®æ ‡æ°´å¹³è¢«ç§°ä¸ºç±»ï¼Œè¿™å°±æ˜¯è¿™ä¸ªåå­—çš„ç”±æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Implementing the target feature for an ABT can demand significant effort.",
            "zh": "å®ç° ABT çš„ç›®æ ‡åŠŸèƒ½å¯èƒ½éœ€è¦ä»˜å‡ºå·¨å¤§çš„åŠªåŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "So if model performance is more important than computational considerations, backward sequential selection may be the better option; otherwise use forward sequential selection.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæ¨¡å‹æ€§èƒ½æ¯”è®¡ç®—è€ƒè™‘æ›´é‡è¦ï¼Œé‚£ä¹ˆå‘åé¡ºåºé€‰æ‹©å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©;å¦åˆ™ï¼Œè¯·ä½¿ç”¨å‰å‘é¡ºåºé€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.19â€…â€…â€…A confusion matrix for a model trained on the bacterial species identification problem.",
            "zh": "9.19 é’ˆå¯¹ç»†èŒç§ç±»è¯†åˆ«é—®é¢˜è®­ç»ƒçš„æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "For many functions the requirement of sufficient neurons turns out to be exponential with respect to the dimensions of the network inputs.",
            "zh": "å¯¹äºè®¸å¤šåŠŸèƒ½ï¼Œç›¸å¯¹äºç½‘ç»œè¾“å…¥çš„ç»´åº¦ï¼Œå¯¹è¶³å¤Ÿç¥ç»å…ƒçš„éœ€æ±‚å‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "wrapper-based feature selection, 228, 541, 722",
            "zh": "åŸºäºåŒ…è£…å™¨çš„åŠŸèƒ½é€‰æ‹©ï¼Œ228ã€541ã€722"
        }
    },
    {
        "translation": {
            "en": "We believe that this book will provide you with an understanding of the broader context and core techniques of machine learning that will enable you to have a successful career in predictive data analytics.",
            "zh": "æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ¬ä¹¦å°†ä½¿æ‚¨äº†è§£æœºå™¨å­¦ä¹ çš„æ›´å¹¿æ³›èƒŒæ™¯å’Œæ ¸å¿ƒæŠ€æœ¯ï¼Œè¿™å°†ä½¿æ‚¨åœ¨é¢„æµ‹æ•°æ®åˆ†æé¢†åŸŸå–å¾—æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "This process, working backward from the output to the input layer, constructs for each neuron in the network a chain of connections linking the weighted sum of the neuron to the error of the network.",
            "zh": "è¿™ä¸ªè¿‡ç¨‹ä»è¾“å‡ºå±‚åˆ°è¾“å…¥å±‚å‘åå·¥ä½œï¼Œä¸ºç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒæ„å»ºäº†ä¸€æ¡è¿æ¥é“¾ï¼Œå°†ç¥ç»å…ƒçš„åŠ æƒå’Œä¸ç½‘ç»œçš„è¯¯å·®è”ç³»èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the next section, we introduce the standard algorithm for growing decision trees in this way.",
            "zh": "åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä»¥è¿™ç§æ–¹å¼ç§æ¤å†³ç­–æ ‘çš„æ ‡å‡†ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The mistake is to confuse the probability of a prediction given the evidence with the probability of the evidence given the prediction and is another example of the paradox of the false positive.10",
            "zh": "é”™è¯¯åœ¨äºæ··æ·†äº†ç»™å®šè¯æ®çš„é¢„æµ‹æ¦‚ç‡å’Œç»™å®šé¢„æµ‹çš„è¯æ®çš„æ¦‚ç‡ï¼Œè¿™æ˜¯è¯¯æŠ¥æ‚–è®ºçš„å¦ä¸€ä¸ªä¾‹å­10ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œfree money for free gambling funâ€",
            "zh": "â€œå…è´¹èµšé’±ï¼Œäº«å—å…è´¹èµŒåšçš„ä¹è¶£â€"
        }
    },
    {
        "translation": {
            "en": "Identifiers: LCCN 2020002998 | ISBN 9780262044691 (hardcover)",
            "zh": "æ ‡è¯†ç¬¦ï¼šLCCN 2020002998 |ISBN 9780262044691 ï¼ˆç²¾è£…ï¼‰"
        }
    },
    {
        "translation": {
            "en": "27. The similarity of this update rule to the standard weight update rule is apparent if we compare this equation with Equation 8.28[415].",
            "zh": "27. å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªç­‰å¼ä¸ç­‰å¼8.28[415]è¿›è¡Œæ¯”è¾ƒï¼Œè¿™ä¸ªæ›´æ–°è§„åˆ™ä¸æ ‡å‡†ç ç æ›´æ–°è§„åˆ™çš„ç›¸ä¼¼æ€§æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The downside to this approach is that it introduces a number of extra weights for which optimal values must be foundâ€”in this simple example for only four descriptive features, we need seven weights.",
            "zh": "è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å®ƒå¼•å…¥äº†è®¸å¤šé¢å¤–çš„æƒé‡ï¼Œå¿…é¡»æ‰¾åˆ°æœ€ä½³å€¼ - åœ¨è¿™ä¸ªåªæœ‰å››ä¸ªæè¿°æ€§ç‰¹å¾çš„ç®€å•ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸ƒä¸ªæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "LSTMs have a complex internal structure containing multiple layers of neurons, and they can be considered networks in their own right. However, they can also be used as the building block of a recurrent neural network. This is achieved by replacing the hidden layer in a recurrent neural network with an LSTM unit. LSTMs have proven very successful at processing language; for example, they are currently the standard network used for speech recognition on mobile phones.",
            "zh": "LSTM å…·æœ‰å¤æ‚çš„å†…éƒ¨ç»“æ„ï¼ŒåŒ…å«å¤šå±‚ç¥ç»å…ƒï¼Œå®ƒä»¬æœ¬èº«å¯ä»¥è¢«è§†ä¸ºç½‘ç»œã€‚ä½†æ˜¯ï¼Œå®ƒä»¬ä¹Ÿå¯ä»¥ç”¨ä½œå¾ªç¯ç¥ç»ç½‘ç»œçš„æ„å»ºå—ã€‚è¿™æ˜¯é€šè¿‡ç”¨ LSTM å•å…ƒæ›¿æ¢é€’å½’ç¥ç»ç½‘ç»œä¸­çš„éšè—å±‚æ¥å®ç°çš„ã€‚äº‹å®è¯æ˜ï¼ŒLSTM åœ¨å¤„ç†è¯­è¨€æ–¹é¢éå¸¸æˆåŠŸ;ä¾‹å¦‚ï¼Œå®ƒä»¬ç›®å‰æ˜¯ç”¨äºæ‰‹æœºè¯­éŸ³è¯†åˆ«çš„æ ‡å‡†ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "We then use an appropriate measure to calculate the difference between the distributions collected after deployment and the original distribution.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨é€‚å½“çš„åº¦é‡æ¥è®¡ç®—éƒ¨ç½²åæ”¶é›†çš„åˆ†å¸ƒä¸åŸå§‹åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "How to Use This Book",
            "zh": "å¦‚ä½•ä½¿ç”¨æœ¬ä¹¦"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19[356] shows a series of the models built during the gradient descent process.",
            "zh": "å›¾7.19[356]æ˜¾ç¤ºäº†åœ¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­æ„å»ºçš„ä¸€ç³»åˆ—æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "fully connected network, 389",
            "zh": "å…¨è¿æ¥ç½‘ç»œï¼Œ389"
        }
    },
    {
        "translation": {
            "en": "This was the challenge that the SDSS had hired Jocelyn to address.",
            "zh": "è¿™æ˜¯ SDSS è˜è¯· Jocelyn æ¥åº”å¯¹çš„æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, some situations where decision tree models are not the best option. Although decision trees can handle both categorical and continuous features, they tend to become quite large when dealing with continuous descriptive features. This can result in trees becoming difficult to interpret. Consequently, in dealing with purely continuous data, other prediction models may be more appropriate, for example, the error-based models discussed in Chapter 7[311].",
            "zh": "ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå†³ç­–æ ‘æ¨¡å‹ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚å°½ç®¡å†³ç­–æ ‘å¯ä»¥å¤„ç†åˆ†ç±»ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ï¼Œä½†åœ¨å¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾æ—¶ï¼Œå®ƒä»¬å¾€å¾€ä¼šå˜å¾—ç›¸å½“å¤§ã€‚è¿™å¯èƒ½å¯¼è‡´æ ‘æœ¨å˜å¾—éš¾ä»¥è§£é‡Šã€‚å› æ­¤ï¼Œåœ¨å¤„ç†çº¯è¿ç»­æ•°æ®æ—¶ï¼Œå…¶ä»–é¢„æµ‹æ¨¡å‹å¯èƒ½æ›´åˆé€‚ï¼Œä¾‹å¦‚ç¬¬7ç« [311]ä¸­è®¨è®ºçš„åŸºäºè¯¯å·®çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This section describes two of the most common such techniques: binning and normalization.",
            "zh": "æœ¬èŠ‚ä»‹ç»ä¸¤ç§æœ€å¸¸è§çš„æ­¤ç±»æŠ€æœ¯ï¼šåˆ†ç®±å’Œå½’ä¸€åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the score predicted by the model for each instance in the test set, the distance between the positive and negative cumulative probabilities at that score can then be calculated.",
            "zh": "å¯¹äºæ¨¡å‹é¢„æµ‹çš„æµ‹è¯•é›†ä¸­æ¯ä¸ªå®ä¾‹çš„åˆ†æ•°ï¼Œå¯ä»¥è®¡ç®—è¯¥åˆ†æ•°å¤„çš„æ­£è´Ÿç´¯ç§¯æ¦‚ç‡ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.5â€…â€…â€…Convolutional Neural Networks",
            "zh": "8.4.5 å·ç§¯ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "A probability density function (PDF) represents the probability distribution of a continuous feature using a mathematical function, and there are a large number of standard, well-defined probability distributionsâ€”such as the normal distributionâ€”that we can use to model the probability of a continuous feature taking different values in its range.",
            "zh": "æ¦‚ç‡å¯†åº¦å‡½æ•° ï¼ˆPDFï¼‰ ä½¿ç”¨æ•°å­¦å‡½æ•°è¡¨ç¤ºè¿ç»­ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶ä¸”æœ‰å¤§é‡æ ‡å‡†ã€å®šä¹‰æ˜ç¡®çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆä¾‹å¦‚æ­£æ€åˆ†å¸ƒï¼‰ï¼Œå¯ç”¨äºå¯¹è¿ç»­ç‰¹å¾åœ¨å…¶èŒƒå›´å†…å–ä¸åŒå€¼çš„æ¦‚ç‡è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Target",
            "zh": "ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "; CLAIM AMOUNT: CLAIM AMT.",
            "zh": ";ç´¢èµ”é‡‘é¢ï¼šç´¢èµ”AMTã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5(a)[273] shows a histogram of a dataset that has been overlaid with the curves of a normal and a student-t distribution that have been fitted to the data.",
            "zh": "å›¾ 6.5ï¼ˆaï¼‰[273] æ˜¾ç¤ºäº†æ•°æ®é›†çš„ç›´æ–¹å›¾ï¼Œè¯¥ç›´æ–¹å›¾å·²å åŠ åˆ°æ•°æ®çš„æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ t åˆ†å¸ƒæ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distance between instance d15 and the query instance is 3.0208, which is not less than the current value of best-distance, so the if statement on Line 5 will fail.",
            "zh": "å®ä¾‹ d15 ä¸æŸ¥è¯¢å®ä¾‹ä¹‹é—´çš„è·ç¦»ä¸º 3.0208ï¼Œä¸å°äºå½“å‰ best-distance å€¼ï¼Œå› æ­¤ç¬¬ 5 è¡Œçš„ if è¯­å¥å°†å¤±è´¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "1,050",
            "zh": "1,050"
        }
    },
    {
        "translation": {
            "en": "When using out-of-time sampling, we should be careful to ensure that the times from which the training and test sets are taken do not introduce a bias into the evaluation process, because the two different time samples are not really representative.",
            "zh": "åœ¨ä½¿ç”¨æ—¶é—´å¤–æŠ½æ ·æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°å¿ƒç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„è·å–æ—¶é—´ä¸ä¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­å¼•å…¥åå·®ï¼Œå› ä¸ºä¸¤ä¸ªä¸åŒçš„æ—¶é—´æ ·æœ¬å¹¶ä¸çœŸæ­£å…·æœ‰ä»£è¡¨æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vector of activations that the unit would propagate forward as the cell state for the next time (ct) step is shown on the top right of the figure, and the vector of activations ot that the unit would propagate both to the output layer for this time-step and on to the next time-step as the hidden state is shown in the bottom-right of the figure.",
            "zh": "è¯¥å•å…ƒå°†ä½œä¸ºä¸‹ä¸€æ¬¡ ï¼ˆctï¼‰ æ­¥é•¿çš„å•å…ƒçŠ¶æ€å‘å‰ä¼ æ’­çš„æ¿€æ´»å‘é‡æ˜¾ç¤ºåœ¨å›¾çš„å³ä¸Šè§’ï¼Œè€Œè¯¥å•å…ƒå°†åœ¨æ­¤æ—¶é—´æ­¥é•¿å’Œä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼ˆéšè—çŠ¶æ€ï¼‰ä¸­ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„æ¿€æ´»å‘é‡æ˜¾ç¤ºåœ¨å›¾çš„å³ä¸‹è§’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Any of the distance measures discussed in this book (as well as many others not discussed in this book) can be used for this.",
            "zh": "æœ¬ä¹¦ä¸­è®¨è®ºçš„ä»»ä½•è·ç¦»æµ‹é‡ï¼ˆä»¥åŠæœ¬ä¹¦ä¸­æœªè®¨è®ºçš„è®¸å¤šå…¶ä»–æµ‹é‡æ–¹æ³•ï¼‰éƒ½å¯ä»¥ç”¨äºæ­¤ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.4.3â€ƒMaking predictions with missing descriptive feature valuesâ€ƒOne real advantage of Bayesian networks over the other predictive model types that we discuss in this book is they a provide an elegant solution to making predictions for a target feature when one or more of the descriptive feature values in a query instance are missing.27 For example, we may wish to predict the CPI for a country with the following profile:",
            "zh": "6.4.4.3 ä½¿ç”¨ç¼ºå¤±çš„æè¿°æ€§ç‰¹å¾å€¼è¿›è¡Œé¢„æµ‹ ä¸æœ¬ä¹¦ä¸­è®¨è®ºçš„å…¶ä»–é¢„æµ‹æ¨¡å‹ç±»å‹ç›¸æ¯”ï¼Œè´å¶æ–¯ç½‘ç»œçš„ä¸€ä¸ªçœŸæ­£çš„ä¼˜åŠ¿æ˜¯ï¼Œå½“æŸ¥è¯¢å®ä¾‹ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªæè¿°æ€§ç‰¹å¾å€¼ç¼ºå¤±æ—¶ï¼Œå®ƒä»¬ä¸ºå¯¹ç›®æ ‡ç‰¹å¾è¿›è¡Œé¢„æµ‹æä¾›äº†ä¸€ç§ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆ27ã€‚ æˆ‘ä»¬ä¸å¦¨é¢„æµ‹ä¸€ä¸ªå›½å®¶/åœ°åŒºçš„ CPIï¼š"
        }
    },
    {
        "translation": {
            "en": "evolutionary reinforcement learning, 641",
            "zh": "è¿›åŒ–å¼ºåŒ–å­¦ä¹ ï¼Œ641"
        }
    },
    {
        "translation": {
            "en": "9.16â€…â€…â€…The (a) lift and (b) cumulative lift at each decile for the email predictions given in Table 9.11[557].",
            "zh": "9.16 è¡¨9.11[557]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶é¢„æµ‹çš„ï¼ˆaï¼‰æå‡å’Œï¼ˆbï¼‰æ¯ä¸ªååˆ†ä½æ•°çš„ç´¯ç§¯æå‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this point all the remaining partitions are pure with respect to the target feature. Consequently, the algorithm converts each partition into a leaf node and returns the final decision tree. Figure 4.11[141] shows this decision tree. If the prediction strategy encoded in this tree is applied to the original dataset in Table 4.3[136], it will correctly classify all the instances in the dataset. In machine learning terms, the induced model is consistent with the training data.",
            "zh": "æ­¤æ—¶ï¼Œæ‰€æœ‰å‰©ä½™çš„åˆ†åŒºç›¸å¯¹äºç›®æ ‡ç‰¹å¾éƒ½æ˜¯çº¯çš„ã€‚å› æ­¤ï¼Œè¯¥ç®—æ³•å°†æ¯ä¸ªåˆ†åŒºè½¬æ¢ä¸ºä¸€ä¸ªå¶èŠ‚ç‚¹ï¼Œå¹¶è¿”å›æœ€ç»ˆçš„å†³ç­–æ ‘ã€‚å›¾4.11[141]æ˜¾ç¤ºäº†è¿™ä¸ªå†³ç­–æ ‘ã€‚å¦‚æœå°†æ­¤æ ‘ä¸­ç¼–ç çš„é¢„æµ‹ç­–ç•¥åº”ç”¨äºè¡¨4.3[136]ä¸­çš„åŸå§‹æ•°æ®é›†ï¼Œå®ƒå°†æ­£ç¡®åˆ†ç±»æ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹ã€‚åœ¨æœºå™¨å­¦ä¹ æ–¹é¢ï¼Œè¯±å¯¼æ¨¡å‹ä¸è®­ç»ƒæ•°æ®ä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "paradox of the false positive, 254",
            "zh": "è¯¯æŠ¥æ‚–è®ºï¼Œ254"
        }
    },
    {
        "translation": {
            "en": "5.2â€…â€…â€…(a) A generalized illustration of the Manhattan and Euclidean distances between two points; and (b) a plot of the Manhattan and Euclidean distances between instances d12 and d5, and between d12 and d17 from Table 5.2[183].",
            "zh": "5.2 ï¼ˆaï¼‰ ä¸¤ç‚¹ä¹‹é—´æ›¼å“ˆé¡¿è·ç¦»å’Œæ¬§å‡ é‡Œå¾—è·ç¦»çš„å¹¿ä¹‰å›¾ç¤º;ï¼ˆbï¼‰è¡¨5.2[183]ä¸­å®ä¾‹d12å’Œd5ä¹‹é—´ä»¥åŠd12å’Œd17ä¹‹é—´çš„æ›¼å“ˆé¡¿å’Œæ¬§å‡ é‡Œå¾—è·ç¦»å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive models are based on the assumption that the patterns learned in the training data will be relevant to unseen instances that are presented to the model in the future.",
            "zh": "é¢„æµ‹æ¨¡å‹åŸºäºè¿™æ ·çš„å‡è®¾ï¼Œå³åœ¨è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ çš„æ¨¡å¼å°†ä¸å°†æ¥å‘ˆç°ç»™æ¨¡å‹çš„çœ‹ä¸è§çš„å®ä¾‹ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2.3â€…â€…â€…Conditional Independence and Factorization",
            "zh": "6.2.3 æ¡ä»¶ç‹¬ç«‹æ€§å’Œå› å¼åˆ†è§£"
        }
    },
    {
        "translation": {
            "en": "For ease of explanation, we will assume that each of these three neurons uses a threshold activation function.",
            "zh": "ä¸ºäº†ä¾¿äºè§£é‡Šï¼Œæˆ‘ä»¬å°†å‡è®¾è¿™ä¸‰ä¸ªç¥ç»å…ƒä¸­çš„æ¯ä¸€ä¸ªéƒ½ä½¿ç”¨é˜ˆå€¼æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SDSS pipeline takes the data captured by the SDSS instruments and processes it, before storing the results of this processing in a centrally accessible database.",
            "zh": "SDSS ç®¡é“è·å– SDSS ä»ªå™¨æ•è·çš„æ•°æ®å¹¶å¯¹å…¶è¿›è¡Œå¤„ç†ï¼Œç„¶åå°†æ­¤å¤„ç†çš„ç»“æœå­˜å‚¨åœ¨å¯é›†ä¸­è®¿é—®çš„æ•°æ®åº“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, the predictive analytics models that we can build do not do any of these things.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºçš„é¢„æµ‹åˆ†ææ¨¡å‹æ— æ³•æ‰§è¡Œä»»ä½•è¿™äº›äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "(See Section 3.5.2[81] for further discussion.)",
            "zh": "ï¼ˆæœ‰å…³è¿›ä¸€æ­¥è®¨è®ºï¼Œè¯·å‚è§ç¬¬ 3.5.2 èŠ‚[81]ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3â€…â€…â€…A schematic of an artificial neuron.",
            "zh": "8.3 äººå·¥ç¥ç»å…ƒç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Three of theseâ€”2, 4, and 5â€”are shown in Table 1.4[10].",
            "zh": "å…¶ä¸­ä¸‰ä¸ªï¼ˆ2ã€4 å’Œ 5ï¼‰å¦‚è¡¨ 1.4[10] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The âˆ‚a/âˆ‚z for each neuron for Example 2 rounded to four decimal places.",
            "zh": "ç¤ºä¾‹ 2 ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚z å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is important because one of the key advantages of a nearest neighbor approach is that it can be updated with new instances as more labeled data arrive.",
            "zh": "è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºæœ€è¿‘é‚»æ–¹æ³•çš„ä¸»è¦ä¼˜ç‚¹ä¹‹ä¸€æ˜¯ï¼Œéšç€æ›´å¤šæ ‡è®°æ•°æ®çš„åˆ°æ¥ï¼Œå®ƒå¯ä»¥ä½¿ç”¨æ–°å®ä¾‹è¿›è¡Œæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "When two or more neurons share a filter, then each weight in the filter is used multiple times during the forward pass of the training algorithm to process a given input (once by each neuron that uses the filter).",
            "zh": "å½“ä¸¤ä¸ªæˆ–å¤šä¸ªç¥ç»å…ƒå…±äº«ä¸€ä¸ªè¿‡æ»¤å™¨æ—¶ï¼Œè¿‡æ»¤å™¨ä¸­çš„æ¯ä¸ªæƒé‡åœ¨è®­ç»ƒç®—æ³•çš„å‰å‘ä¼ é€’æœŸé—´è¢«å¤šæ¬¡ä½¿ç”¨ï¼Œä»¥å¤„ç†ç»™å®šçš„è¾“å…¥ï¼ˆæ¯ä¸ªä½¿ç”¨è¿‡æ»¤å™¨çš„ç¥ç»å…ƒä¸€æ¬¡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the selection of the best feature on which to split a dataset is based on the purity, or homogeneity, of the resulting partitions in the datasets.",
            "zh": "å› æ­¤ï¼Œé€‰æ‹©ç”¨äºæ‹†åˆ†æ•°æ®é›†çš„æœ€ä½³ç‰¹å¾æ˜¯åŸºäºæ•°æ®é›†ä¸­ç»“æœåˆ†åŒºçš„çº¯åº¦æˆ–åŒè´¨æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Whether the customerâ€™s current handset is a smartphone",
            "zh": "å®¢æˆ·å½“å‰çš„æ‰‹æœºæ˜¯å¦ä¸ºæ™ºèƒ½æ‰‹æœº"
        }
    },
    {
        "translation": {
            "en": "The architecture of the network consists of ReLUs that share a filter (Neurons 1,2,3,4), followed by a sub-sampling layer containing two max pooling units (Neurons 5,6), and then a fully connected layer containing a single ReLU (Neuron 7).",
            "zh": "è¯¥ç½‘ç»œçš„æ¶æ„ç”±å…±äº«ä¸€ä¸ªè¿‡æ»¤å™¨çš„ ReLU ï¼ˆç¥ç»å…ƒ 1,2,3,4ï¼‰ ç»„æˆï¼Œç„¶åæ˜¯åŒ…å«ä¸¤ä¸ªæœ€å¤§æ± åŒ–å•å…ƒçš„å­é‡‡æ ·å±‚ï¼ˆç¥ç»å…ƒ 5,6ï¼‰ï¼Œç„¶åæ˜¯åŒ…å«å•ä¸ª ReLU çš„å…¨è¿æ¥å±‚ï¼ˆç¥ç»å…ƒ 7ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gradient-descent-like algorithms for training neural networks assume training instances are independent from each other.",
            "zh": "ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œçš„ç±»ä¼¼æ¢¯åº¦ä¸‹é™çš„ç®—æ³•å‡å®šè®­ç»ƒå®ä¾‹å½¼æ­¤ç‹¬ç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use machine learning to train these models.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For now we continue with using two-dimensional filters, but we return to this topic in Section 8.4.5.5[492].",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨äºŒç»´è¿‡æ»¤å™¨ï¼Œä½†æˆ‘ä»¬åœ¨ç¬¬ 8.4.5.5 èŠ‚[492]ä¸­å›åˆ°äº†è¿™ä¸ªä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Based on the AUC values for Model 1 and Model 2, calculate the Gini coefficient for each model.",
            "zh": "ï¼ˆcï¼‰ æ ¹æ®æ¨¡å‹1å’Œæ¨¡å‹2çš„AUCå€¼ï¼Œè®¡ç®—æ¯ä¸ªæ¨¡å‹çš„åŸºå°¼ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo labels were available for approximately 600,000 SDSS galaxies, which Jocelyn felt would be more than enough to use to train and test a galaxy morphology classification model.",
            "zh": "é“¶æ²³åŠ¨ç‰©å›­çš„æ ‡ç­¾å¯ç”¨äºå¤§çº¦600,000ä¸ªSDSSæ˜Ÿç³»ï¼ŒJocelynè®¤ä¸ºè¿™äº›æ ‡ç­¾è¶³ä»¥ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ˜Ÿç³»å½¢æ€åˆ†ç±»æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation 8.58[456] states that the variance of z is equal to the variance of the inputs (var(d)) scaled by nin var(W).",
            "zh": "å…¬å¼ 8.58[456] æŒ‡å‡ºï¼Œz çš„æ–¹å·®ç­‰äºè¾“å…¥çš„æ–¹å·® ï¼ˆvarï¼ˆdï¼‰ï¼‰ ç”¨ nin varï¼ˆWï¼‰ ç¼©æ”¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "semi-supervised learning, 5, 742",
            "zh": "åŠç›‘ç£å­¦ä¹ ï¼Œ5,742"
        }
    },
    {
        "translation": {
            "en": "It is important that after the feature selection process is complete, a separate test set still exists that can be used to evaluate the expected performance of the model on future unseen data after deployment.",
            "zh": "é‡è¦çš„æ˜¯ï¼Œåœ¨åŠŸèƒ½é€‰æ‹©è¿‡ç¨‹å®Œæˆåï¼Œä»ç„¶å­˜åœ¨ä¸€ä¸ªå•ç‹¬çš„æµ‹è¯•é›†ï¼Œå¯ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨éƒ¨ç½²åå¯¹æœªæ¥çœ‹ä¸è§çš„æ•°æ®çš„é¢„æœŸæ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that they can learn to behave effectively in an environment with only minimal knowledge of that environmentâ€”the states that can be occupied and the actions that the agent can take are all that the agent needs to know.",
            "zh": "è¿™æ„å‘³ç€ä»–ä»¬å¯ä»¥å­¦ä¼šåœ¨ä¸€ä¸ªç¯å¢ƒä¸­æœ‰æ•ˆåœ°è¡¨ç°ï¼Œè€Œå¯¹è¯¥ç¯å¢ƒåªæœ‰æœ€å°‘çš„äº†è§£â€”â€”å¯ä»¥å æ®çš„çŠ¶æ€å’Œä»£ç†å¯ä»¥é‡‡å–çš„è¡ŒåŠ¨æ˜¯ä»£ç†éœ€è¦çŸ¥é“çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we switch a network from ReLUs to Leaky ReLUs, we sacrifice the potential benefits in terms of energy efficiency of sparse representations for a gradient that may potentially be more robust during training.",
            "zh": "å½“æˆ‘ä»¬å°†ç½‘ç»œä» ReLU åˆ‡æ¢åˆ° Leaky ReLU æ—¶ï¼Œæˆ‘ä»¬ç‰ºç‰²äº†ç¨€ç–è¡¨ç¤ºåœ¨èƒ½é‡æ•ˆç‡æ–¹é¢çš„æ½œåœ¨å¥½å¤„ï¼Œä»¥è·å¾—åœ¨è®­ç»ƒæœŸé—´å¯èƒ½æ›´å¥å£®çš„æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "SVM, 361",
            "zh": "æ”¯æŒå‘é‡æœºï¼Œ361"
        }
    },
    {
        "translation": {
            "en": "Representation learning essentially tries to automatically extract new descriptive features from a dataset.",
            "zh": "è¡¨å¾å­¦ä¹ æœ¬è´¨ä¸Šæ˜¯å°è¯•ä»æ•°æ®é›†ä¸­è‡ªåŠ¨æå–æ–°çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. Because Euclidean distance between any two points is symmetrical (dist(a,b) = dist(b,a)), we show only half of the distance matrix.",
            "zh": "9. å› ä¸ºä»»ä½•ä¸¤ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯å¯¹ç§°çš„ï¼ˆdistï¼ˆaï¼Œbï¼‰ = distï¼ˆbï¼Œaï¼‰ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬åªæ˜¾ç¤ºè·ç¦»çŸ©é˜µçš„ä¸€åŠã€‚"
        }
    },
    {
        "translation": {
            "en": "As part of a natural language processing project, a company is creating a dictionary of idiomatic phrases.27 The company has used an automatic process to extract a set of 50,000 candidate idioms from a large corpus and now are planning to use a machine learning model to filter this set of candidates before presenting them to a human annotator who decides whether a candidate phrase should be added to the dictionary or not.",
            "zh": "ä½œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œä¸€å®¶å…¬å¸æ­£åœ¨åˆ›å»ºä¸€æœ¬æƒ¯ç”¨çŸ­è¯­è¯å…¸.27 è¯¥å…¬å¸ä½¿ç”¨è‡ªåŠ¨è¿‡ç¨‹ä»å¤§å‹è¯­æ–™åº“ä¸­æå–ä¸€ç»„ 50,000 ä¸ªå€™é€‰ä¹ è¯­ï¼Œç°åœ¨æ­£è®¡åˆ’ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹æ¥è¿‡æ»¤è¿™ç»„å€™é€‰ä¹ è¯­ï¼Œç„¶åå†å°†å®ƒä»¬å‘ˆç°ç»™äººå·¥æ³¨é‡Šè€…ï¼Œç”±äººå·¥æ³¨é‡Šè€…å†³å®šæ˜¯å¦åº”å°†å€™é€‰çŸ­è¯­æ·»åŠ åˆ°è¯å…¸ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the CRISP-DM process improves the likelihood that predictive data analytics projects will be successful, and we recommend its use.",
            "zh": "ä½¿ç”¨ CRISP-DM æµç¨‹å¯ä»¥æé«˜é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®æˆåŠŸçš„å¯èƒ½æ€§ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This chapter moved away from the supervised machine learning techniques for training predictive models discussed in the rest of the book to focus on unsupervised machine learning.",
            "zh": "æœ¬ç« æ‘’å¼ƒäº†æœ¬ä¹¦å…¶ä½™éƒ¨åˆ†è®¨è®ºçš„ç”¨äºè®­ç»ƒé¢„æµ‹æ¨¡å‹çš„ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œè½¬è€Œå…³æ³¨æ— ç›‘ç£æœºå™¨å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.2â€…â€…â€…Evaluating Clustering",
            "zh": "10.4.2 è¯„ä¼°èšç±»"
        }
    },
    {
        "translation": {
            "en": "13.11â€…â€…â€…The confusion matrix for the final logistic regression model on the large hold-out test set (classification accuracy: 87.979%, average class accuracy: 67.305%).",
            "zh": "13.11 å¤§å‹ä¿æŒæµ‹è¯•é›†ä¸Šæœ€ç»ˆé€»è¾‘å›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š87.979%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š67.305%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "action-value target network, 672",
            "zh": "åŠ¨ä½œå€¼ç›®æ ‡ç½‘ç»œï¼Œ672"
        }
    },
    {
        "translation": {
            "en": "The data listed in this table is real.",
            "zh": "æ­¤è¡¨ä¸­åˆ—å‡ºçš„æ•°æ®æ˜¯çœŸå®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward and backward pass is then carried out on each subsequence in turn: in the forward pass the network is unrolled over a subsequence, and in the backward pass the error gradients are backpropagated only through this truncated unrolled network.",
            "zh": "ç„¶åä¾æ¬¡å¯¹æ¯ä¸ªå­åºåˆ—è¿›è¡Œæ­£å‘å’Œå‘åä¼ é€’ï¼šåœ¨å‰å‘ä¼ é€’ä¸­ï¼Œç½‘ç»œåœ¨å­åºåˆ—ä¸Šå±•å¼€ï¼Œè€Œåœ¨å‘åä¼ é€’ä¸­ï¼Œè¯¯å·®æ¢¯åº¦ä»…é€šè¿‡è¿™ä¸ªæˆªæ–­çš„å±•å¼€ç½‘ç»œè¿›è¡Œåå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.5â€…â€…â€…Summary",
            "zh": "4.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "3.6.3â€…â€…â€…Sampling",
            "zh": "3.6.3 æŠ½æ ·"
        }
    },
    {
        "translation": {
            "en": "Although in a neural network it is relatively straightforward to calculate the gradient of the error for neurons in the output layer by directly comparing the activations of these neurons with the expected outputs, it is not possible to directly compare the activation of a hidden neuron with the expected activation for that neuron, and so we cannot directly calculate an error gradient for hidden neurons.",
            "zh": "è™½ç„¶åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œé€šè¿‡ç›´æ¥æ¯”è¾ƒè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„æ¿€æ´»æ¥è®¡ç®—è¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ç›¸å¯¹ç®€å•ï¼Œä½†ä¸å¯èƒ½ç›´æ¥å°†éšè—ç¥ç»å…ƒçš„æ¿€æ´»ä¸è¯¥ç¥ç»å…ƒçš„é¢„æœŸæ¿€æ´»è¿›è¡Œæ¯”è¾ƒï¼Œå› æ­¤æˆ‘ä»¬ä¸èƒ½ç›´æ¥è®¡ç®—éšè—ç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "(Model Selection)",
            "zh": "ï¼ˆå‹å·é€‰æ‹©ï¼‰"
        }
    },
    {
        "translation": {
            "en": "4.4.5.1â€ƒBaggingâ€ƒWhen we use bagging (or bootstrap aggregating), each model in the ensemble is trained on a random sample25 of the dataset where, importantly, each random sample is the same size as the dataset, and sampling with replacement is used.",
            "zh": "4.4.5.1 è£…è¢‹ å½“æˆ‘ä»¬ä½¿ç”¨è£…è¢‹ï¼ˆæˆ–å¼•å¯¼èšåˆï¼‰æ—¶ï¼Œé›†åˆä¸­çš„æ¯ä¸ªæ¨¡å‹éƒ½æ˜¯åœ¨æ•°æ®é›†çš„éšæœºæ ·æœ¬25ä¸Šè®­ç»ƒçš„ï¼Œå…¶ä¸­é‡è¦çš„æ˜¯ï¼Œæ¯ä¸ªéšæœºæ ·æœ¬çš„å¤§å°ä¸æ•°æ®é›†ç›¸åŒï¼Œå¹¶ä¸”ä½¿ç”¨å¸¦æ›¿æ¢çš„é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This efficiency gain, however, is at the cost of the likely exclusion of interacting features.",
            "zh": "ç„¶è€Œï¼Œè¿™ç§æ•ˆç‡çš„æé«˜æ˜¯ä»¥å¯èƒ½æ’é™¤äº¤äº’åŠŸèƒ½ä¸ºä»£ä»·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.7â€ƒExercises",
            "zh": "6.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "The patience parameter is a predefined threshold (i.e., it is a hyper-parameter) that specifies the number of times in a row we will permit the error on the validation set to be higher than the lowest recorded so far before we stop training.",
            "zh": "è€å¿ƒå‚æ•°æ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„é˜ˆå€¼ï¼ˆå³ï¼Œå®ƒæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼‰ï¼Œå®ƒæŒ‡å®šåœ¨åœæ­¢è®­ç»ƒä¹‹å‰ï¼Œæˆ‘ä»¬å°†å…è®¸éªŒè¯é›†ä¸Šçš„è¯¯å·®é«˜äºè¿„ä»Šä¸ºæ­¢è®°å½•çš„æœ€ä½å€¼çš„è¿ç»­æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.3",
            "zh": "è¡¨ 3.3"
        }
    },
    {
        "translation": {
            "en": "Line 4[326] of Algorithm 4[326] can therefore be rewritten as what is known as the weight update rule for multivariable linear regression with gradient descent",
            "zh": "å› æ­¤ï¼Œç®—æ³• 4[326] çš„ç¬¬ 4 è¡Œ [326] å¯ä»¥æ”¹å†™ä¸ºå…·æœ‰æ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’çš„æƒé‡æ›´æ–°è§„åˆ™"
        }
    },
    {
        "translation": {
            "en": "Decision trees are induced by recursively partitioning the feature space into regions belonging to the different classes, and consequently they define a decision boundary by aggregating the neighboring regions belonging to the same class.",
            "zh": "å†³ç­–æ ‘æ˜¯é€šè¿‡é€’å½’åœ°å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºå±äºä¸åŒç±»çš„åŒºåŸŸæ¥è¯±å¯¼çš„ï¼Œå› æ­¤å®ƒä»¬é€šè¿‡èšåˆå±äºåŒä¸€ç±»çš„ç›¸é‚»åŒºåŸŸæ¥å®šä¹‰å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "RENT",
            "zh": "ç§Ÿé‡‘"
        }
    },
    {
        "translation": {
            "en": "Table 8.13[464] lists the power plant dataset after the target feature ELECTRICAL OUTPUT has been converted to a three-level categorical feature, by applying binning to the range-normalized values (low â‰¤ 0.33, medium â‰¤ 0.66, high > 0.66), and then encoded using one-hot encoding.",
            "zh": "è¡¨ 8.13[464] åˆ—å‡ºäº†å°†ç›®æ ‡ç‰¹å¾ ELECTRICAL OUTPUT è½¬æ¢ä¸ºä¸‰çº§åˆ†ç±»ç‰¹å¾åçš„å‘ç”µå‚æ•°æ®é›†ï¼Œæ–¹æ³•æ˜¯å¯¹èŒƒå›´å½’ä¸€åŒ–å€¼ï¼ˆä½â‰¤ 0.33ã€ä¸­â‰¤ 0.66ã€é«˜> 0.66ï¼‰è¿›è¡Œåˆ†ç®±ï¼Œç„¶åä½¿ç”¨å•çƒ­ç¼–ç è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prediction problem in this case is to determine the dosage of a blood-thinning drug (in milligrams) that should be given to a patient in order to achieve a particular level of blood-thinning.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢„æµ‹é—®é¢˜æ˜¯ç¡®å®šåº”ç»™äºˆæ‚£è€…çš„è¡€æ¶²ç¨€é‡Šè¯ç‰©çš„å‰‚é‡ï¼ˆä»¥æ¯«å…‹ä¸ºå•ä½ï¼‰ï¼Œä»¥è¾¾åˆ°ç‰¹å®šçš„è¡€æ¶²ç¨€é‡Šæ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "19. The length of a vector, |a|, is computed as the square root of the sum of the elements of the vector squared: .",
            "zh": "19. å‘é‡çš„é•¿åº¦ |a|ï¼Œè®¡ç®—ä¸ºå‘é‡å…ƒç´ ä¹‹å’Œçš„å¹³æ–¹æ ¹ï¼š ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.4",
            "zh": "å›¾ 7.4"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a bar plot for the POLICY feature.",
            "zh": "ï¼ˆbï¼‰ ç»˜åˆ¶ POLICY ç‰¹å¾çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. See Guisan and Zimmermann (2000) and Franklin (2009) for an introduction to uses of predictive analytics in ecological modeling.",
            "zh": "10. å‚è§ Guisan and Zimmermann ï¼ˆ2000ï¼‰ å’Œ Franklin ï¼ˆ2009ï¼‰ å…³äºé¢„æµ‹åˆ†æåœ¨ç”Ÿæ€å»ºæ¨¡ä¸­çš„åº”ç”¨çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Doing this without the permission of the users of the app, however, would be in breach of this principle.",
            "zh": "ä½†æ˜¯ï¼Œæœªç»åº”ç”¨ç¨‹åºç”¨æˆ·è®¸å¯è€Œè¿™æ ·åšå°†è¿åæ­¤åŸåˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.2",
            "zh": "å›¾ 9.2"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the algorithm occurs in the for loop Lines 6[420] to 11[420].",
            "zh": "ç®—æ³•çš„å‰å‘ä¼ é€’å‘ç”Ÿåœ¨ for å¾ªç¯è¡Œ 6[420] åˆ° 11[420] ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "stationarity assumption, 234",
            "zh": "å¹³ç¨³æ€§å‡è®¾ï¼Œ234"
        }
    },
    {
        "translation": {
            "en": "Figure 10.4[606] illustrates this, showing other clusterings that are possible given different random initial cluster centroids for the mobile phone customer dataset presented in Table 10.1[604].",
            "zh": "å›¾10.4[606]è¯´æ˜äº†è¿™ä¸€ç‚¹ï¼Œæ˜¾ç¤ºäº†è¡¨10.1[604]ä¸­æ˜¾ç¤ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ä¸åŒéšæœºåˆå§‹èšç±»è´¨å¿ƒä¸‹å¯èƒ½çš„å…¶ä»–èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Naturally occurring phenomenaâ€”for example, the heights or weights of a randomly selected group of men or womenâ€”tend to follow a normal distribution.",
            "zh": "è‡ªç„¶å‘ç”Ÿçš„ç°è±¡ï¼ˆä¾‹å¦‚ï¼Œéšæœºé€‰æ‹©çš„ä¸€ç»„ç”·æ€§æˆ–å¥³æ€§çš„èº«é«˜æˆ–ä½“é‡ï¼‰å¾€å¾€éµå¾ªæ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.3â€…â€…â€…Choosing the Number of Clusters",
            "zh": "10.4.3 é€‰æ‹©é›†ç¾¤æ•°é‡"
        }
    },
    {
        "translation": {
            "en": "then",
            "zh": "ç„¶å"
        }
    },
    {
        "translation": {
            "en": "Vanishing gradients are a serious challenge for training deep networks because the Î´s are the learning signal that tells each neuron how it should update its weights in order to improve the networkâ€™s performance on an example.",
            "zh": "æ¢¯åº¦æ¶ˆå¤±å¯¹äºè®­ç»ƒæ·±åº¦ç½‘ç»œæ¥è¯´æ˜¯ä¸€ä¸ªä¸¥å³»çš„æŒ‘æˆ˜ï¼Œå› ä¸ºÎ´æ˜¯å­¦ä¹ ä¿¡å·ï¼Œå®ƒå‘Šè¯‰æ¯ä¸ªç¥ç»å…ƒåº”è¯¥å¦‚ä½•æ›´æ–°å…¶æƒé‡ï¼Œä»¥æé«˜ç½‘ç»œçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because all the features in this example are binary, we need to store only the probabilities for the events where the features are true under the different combinations of values for the conditioning cases, as the probabilities for the complementary events can be computed by subtracting the stored probabilities from 1.0.",
            "zh": "ç”±äºæ­¤ç¤ºä¾‹ä¸­çš„æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦åœ¨æ¡ä»¶æƒ…å†µçš„ä¸åŒå€¼ç»„åˆä¸‹å­˜å‚¨ç‰¹å¾ä¸ºçœŸçš„äº‹ä»¶çš„æ¦‚ç‡ï¼Œå› ä¸ºäº’è¡¥äº‹ä»¶çš„æ¦‚ç‡å¯ä»¥é€šè¿‡ä» 1.0 ä¸­å‡å»å­˜å‚¨çš„æ¦‚ç‡æ¥è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the same way we calculated cumulative gain, we can calculate lift cumulatively. The cumulative lift at decile dec is defined as",
            "zh": "ä»¥è®¡ç®—ç´¯ç§¯æ”¶ç›Šçš„æ–¹å¼ç›¸åŒï¼Œæˆ‘ä»¬å¯ä»¥ç´¯ç§¯è®¡ç®—æå‡ã€‚ååˆ†ä½æ•° dec çš„ç´¯ç§¯æå‡å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "5.4â€…â€…â€…Extensions and Variations",
            "zh": "5.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "This point is at the global minimum of the error surface, and the coordinates of this point define the weights for the prediction model with the lowest sum of squared errors on the dataset.",
            "zh": "è¯¥ç‚¹ä½äºè¯¯å·®é¢çš„å…¨å±€æœ€å°å€¼å¤„ï¼Œè¯¥ç‚¹çš„åæ ‡å®šä¹‰äº†æ•°æ®é›†ä¸Šè¯¯å·®å¹³æ–¹å’Œæœ€ä½çš„é¢„æµ‹æ¨¡å‹çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, using a k-d tree is not always appropriate; k-d trees are reasonably efficient when there are a lot more instances than there are features.",
            "zh": "ä½†æ˜¯ï¼Œä½¿ç”¨ k-d æ ‘å¹¶ä¸æ€»æ˜¯åˆé€‚çš„;å½“å®ä¾‹æ•°é‡è¿œè¿œå¤šäºç‰¹å¾æ—¶ï¼ŒK-D æ ‘æ˜¯ç›¸å½“æœ‰æ•ˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Player Medium (PM): 15 âˆ’ 18",
            "zh": "ç©å®¶ä¸­ç­‰å€¼ ï¼ˆPMï¼‰ï¼š 15 âˆ’ 18"
        }
    },
    {
        "translation": {
            "en": "The game is tied if the dealer and the player have the same total, less than or equal to 22.",
            "zh": "å¦‚æœåº„å®¶å’Œç©å®¶çš„æ€»æ•°ç›¸åŒï¼Œå°äºæˆ–ç­‰äº 22ï¼Œåˆ™æ¸¸æˆæ‰“æˆå¹³æ‰‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It should be corrected through a mapping to a standard set of levels, and the ABT should be regenerated.",
            "zh": "å®ƒåº”è¯¥é€šè¿‡æ˜ å°„åˆ°ä¸€ç»„æ ‡å‡†çº§åˆ«æ¥æ ¡æ­£ï¼Œå¹¶ä¸”åº”è¯¥é‡æ–°ç”Ÿæˆ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "Both scores are set to zero because one of the conditional probabilities used to calculate them is zero.",
            "zh": "è¿™ä¸¤ä¸ªåˆ†æ•°éƒ½è®¾ç½®ä¸ºé›¶ï¼Œå› ä¸ºç”¨äºè®¡ç®—å®ƒä»¬çš„æ¡ä»¶æ¦‚ç‡ä¹‹ä¸€ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Applying a max function to a local receptive field is often referred to as max pooling.",
            "zh": "å°† max å‡½æ•°åº”ç”¨äºå±€éƒ¨æ„Ÿå—é‡é€šå¸¸ç§°ä¸º max æ± åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. Note that we have shortened feature names in these calculations to save space.",
            "zh": "7. è¯·æ³¨æ„ï¼Œä¸ºäº†èŠ‚çœç©ºé—´ï¼Œæˆ‘ä»¬åœ¨è¿™äº›è®¡ç®—ä¸­ç¼©çŸ­äº†ç‰¹å¾åç§°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Information Gain",
            "zh": "ä¿¡æ¯å¢ç›Š"
        }
    },
    {
        "translation": {
            "en": "Figure 10.10[617] illustrates this using three well-known simple two-dimensional artificial datasets: blobs, circles, and half-moons.",
            "zh": "å›¾10.10[617]ä½¿ç”¨ä¸‰ä¸ªè‘—åçš„ç®€å•äºŒç»´äººå·¥æ•°æ®é›†æ¥è¯´æ˜è¿™ä¸€ç‚¹ï¼šæ–‘ç‚¹ã€åœ†åœˆå’ŒåŠæœˆå½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bentley, Jon Louis. 1975. Multidimensional binary search trees used for associative searching. Communications of the ACM 18 (9): 509â€“517. doi:10.1145/361002.361007.",
            "zh": "å®¾åˆ©ï¼Œä¹”æ©Â·è·¯æ˜“æ–¯ã€‚1975. ç”¨äºå…³è”æœç´¢çš„å¤šç»´äºŒå‰æœç´¢æ ‘.ACM é€šè®¯ 18 ï¼ˆ9ï¼‰ï¼š509â€“517ã€‚doiï¼š10.1145/361002.361007."
        }
    },
    {
        "translation": {
            "en": "The strengths of these models, however, are that they are easy to interpret, they can handle different types of descriptive features, they are relatively robust to noise (when k is set appropriately), and they may be more robust to concept drift than models induced by eager learning algorithms.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„ä¼˜åŠ¿åœ¨äºå®ƒä»¬æ˜“äºè§£é‡Šï¼Œå®ƒä»¬å¯ä»¥å¤„ç†ä¸åŒç±»å‹çš„æè¿°æ€§ç‰¹å¾ï¼Œå®ƒä»¬å¯¹å™ªå£°ç›¸å¯¹é²æ£’ï¼ˆå½“ k è®¾ç½®å¾—å½“æ—¶ï¼‰ï¼Œå¹¶ä¸”å®ƒä»¬å¯èƒ½æ¯”æ¸´æœ›å­¦ä¹ ç®—æ³•è¯±å¯¼çš„æ¨¡å‹å¯¹æ¦‚å¿µæ¼‚ç§»æ›´é²æ£’ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEIGHT",
            "zh": "é«˜åº¦"
        }
    },
    {
        "translation": {
            "en": "By contrast, a naive Bayes model uses a very compact representation of a domain.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹ä½¿ç”¨éå¸¸ç´§å‡‘çš„åŸŸè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "So far in this chapter we have been initializing the bias terms and weights in our worked examples by sampling from a uniform distribution with a range of [âˆ’0.5,+0.5].",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»èŒƒå›´ä¸º [âˆ’0.5ï¼Œ+0.5] çš„å‡åŒ€åˆ†å¸ƒä¸­æŠ½æ ·æ¥åˆå§‹åŒ–å·¥ä½œç¤ºä¾‹ä¸­çš„åå·®é¡¹å’Œæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "That a recurrent network contains cycles means that the output from a neuron at one time point may be fed back into the same neuron at another time point.",
            "zh": "å¾ªç¯ç½‘ç»œåŒ…å«å‘¨æœŸæ„å‘³ç€ä¸€ä¸ªæ—¶é—´ç‚¹çš„ç¥ç»å…ƒè¾“å‡ºå¯èƒ½ä¼šåœ¨å¦ä¸€ä¸ªæ—¶é—´ç‚¹åé¦ˆåˆ°åŒä¸€ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "So, relying solely on a stability index can lead to models being rebuilt when it is not required.",
            "zh": "å› æ­¤ï¼Œä»…ä¾èµ–ç¨³å®šæ€§æŒ‡æ•°å¯èƒ½ä¼šå¯¼è‡´åœ¨ä¸éœ€è¦æ—¶é‡å»ºæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "But ğ•„w(d) = logistic(w Â·d), so",
            "zh": "ä½†æ˜¯ Mwï¼ˆdï¼‰ = logisticï¼ˆw Â·dï¼‰ï¼Œæ‰€ä»¥"
        }
    },
    {
        "translation": {
            "en": "A dataset listing salary and age information for customers and whether they purchased a product.",
            "zh": "åˆ—å‡ºå®¢æˆ·çš„å·¥èµ„å’Œå¹´é¾„ä¿¡æ¯ä»¥åŠä»–ä»¬æ˜¯å¦è´­ä¹°äº†äº§å“çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The only factor left unspecified was what the magnitude of that reduction was expected to be.",
            "zh": "å”¯ä¸€æ²¡æœ‰å…·ä½“è¯´æ˜çš„å› ç´ æ˜¯é¢„è®¡å‡å°‘çš„å¹…åº¦æ˜¯å¤šå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”John Maynard Keynes",
            "zh": "â€”â€”çº¦ç¿°Â·æ¢…çº³å¾·Â·å‡¯æ©æ–¯"
        }
    },
    {
        "translation": {
            "en": "Also, in general, it is not a good idea to select just one machine learning approach at the beginning of a project and to exclusively use that.",
            "zh": "æ­¤å¤–ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œåœ¨é¡¹ç›®å¼€å§‹æ—¶åªé€‰æ‹©ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•å¹¶ä¸“é—¨ä½¿ç”¨å®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a learning rate34 parameter, Î±, can be added to Equation (4.17)[164] to cause predictions of later errors to have less impact on the overall model than earlier ones, which makes models more robust to outliers.35",
            "zh": "ä¾‹å¦‚ï¼Œå¯ä»¥å°†å­¦ä¹ ç‡34å‚æ•°Î±æ·»åŠ åˆ°æ–¹ç¨‹ï¼ˆ4.17ï¼‰[164]ä¸­ï¼Œä»¥ä½¿å¯¹åæœŸè¯¯å·®çš„é¢„æµ‹å¯¹æ•´ä¸ªæ¨¡å‹çš„å½±å“å°äºæ—©æœŸè¯¯å·®ï¼Œè¿™ä½¿å¾—æ¨¡å‹å¯¹å¼‚å¸¸å€¼æ›´å…·é²æ£’æ€§35ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both of these decompositions are valid, and both define different Bayesian networks for the domain. Figure 6.12(a)[291] illustrates the Bayesian network representing the decomposition defined in Equation (6.20)[291], and Figure 6.12(b)[291] illustrates the Bayesian network representing the decompositions defined in Equation (6.21)[291].",
            "zh": "è¿™ä¸¤ç§åˆ†è§£éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”éƒ½ä¸ºåŸŸå®šä¹‰äº†ä¸åŒçš„è´å¶æ–¯ç½‘ç»œã€‚å›¾6.12ï¼ˆaï¼‰[291]ç¤ºå‡ºäº†è¡¨ç¤ºç­‰å¼ï¼ˆ6.20ï¼‰[291]ä¸­å®šä¹‰çš„åˆ†è§£çš„è´å¶æ–¯ç½‘ç»œï¼Œå›¾6.12ï¼ˆbï¼‰[291]ç¤ºå‡ºäº†è¡¨ç¤ºç­‰å¼ï¼ˆ6.21ï¼‰[291]ä¸­å®šä¹‰çš„åˆ†è§£çš„è´å¶æ–¯ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "To restate Equation (11.17)[651] using the components of an MDP we must explicitly represent the uncertainty associated with state transitions.",
            "zh": "ä¸ºäº†ä½¿ç”¨MDPçš„ç»„ä»¶é‡è¿°æ–¹ç¨‹ï¼ˆ11.17ï¼‰[651]ï¼Œæˆ‘ä»¬å¿…é¡»æ˜ç¡®è¡¨ç¤ºä¸çŠ¶æ€è½¬æ¢ç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "naive neural Q-learning, 671",
            "zh": "æœ´ç´ çš„ç¥ç»Qå­¦ä¹ ï¼Œ671"
        }
    },
    {
        "translation": {
            "en": "To understand why Equation (8.67)[466] is an appropriate measure to use as the loss function for categorical training, we should first remember that the loss function is the function that we wish to minimize during training, and so we wish the loss function to return a large value when there is a large difference between the true and predicted probability distributions, and a small value when t and are similar or identical.",
            "zh": "ä¸ºäº†ç†è§£ä¸ºä»€ä¹ˆæ–¹ç¨‹ï¼ˆ8.67ï¼‰[466]æ˜¯ç”¨ä½œåˆ†ç±»è®­ç»ƒæŸå¤±å‡½æ•°çš„åˆé€‚åº¦é‡ï¼Œæˆ‘ä»¬é¦–å…ˆåº”è¯¥è®°ä½ï¼ŒæŸå¤±å‡½æ•°æ˜¯æˆ‘ä»¬å¸Œæœ›åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ€å°åŒ–çš„å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›æŸå¤±å‡½æ•°åœ¨çœŸå®å’Œé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®å¼‚æ—¶è¿”å›ä¸€ä¸ªå¤§å€¼ï¼Œ å½“ t å’Œ ç›¸ä¼¼æˆ–ç›¸åŒæ—¶ï¼Œå€¼å¾ˆå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.20[576] shows the expected target values for a test set, the predictions made by two different models (a multivariable linear regression model and a k-NN model), and the resulting errors based on these predictions (the additional error measures will be explained shortly).",
            "zh": "è¡¨9.20[576]æ˜¾ç¤ºäº†æµ‹è¯•é›†çš„é¢„æœŸç›®æ ‡å€¼ã€ä¸¤ä¸ªä¸åŒæ¨¡å‹ï¼ˆå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹å’Œk-NNæ¨¡å‹ï¼‰çš„é¢„æµ‹ï¼Œä»¥åŠåŸºäºè¿™äº›é¢„æµ‹å¾—å‡ºçš„è¯¯å·®ï¼ˆå…¶ä»–è¯¯å·®åº¦é‡å°†åœ¨ç¨åè§£é‡Šï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the relative likelihoods for each target level have been calculated, we simply return the maximum a posteriori (MAP) prediction.",
            "zh": "ä¸€æ—¦è®¡ç®—äº†æ¯ä¸ªç›®æ ‡æ°´å¹³çš„ç›¸å¯¹ä¼¼ç„¶ï¼Œæˆ‘ä»¬åªéœ€è¿”å›æœ€å¤§åéªŒ ï¼ˆMAPï¼‰ é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Evaluation",
            "zh": "è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "Table 9.7[553]shows the structure of a profit matrix, which is the same as the structure of a confusion matrix.",
            "zh": "è¡¨9.7[553]æ˜¾ç¤ºäº†åˆ©æ¶¦çŸ©é˜µçš„ç»“æ„ï¼Œè¯¥ç»“æ„ä¸æ··æ·†çŸ©é˜µçš„ç»“æ„ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "However, as the size of the dataset grows, particularly if the decision boundary between the classes is very complex, it may make more sense to allow the data to inform the predictions more directly.",
            "zh": "ä½†æ˜¯ï¼Œéšç€æ•°æ®é›†å¤§å°çš„å¢é•¿ï¼Œç‰¹åˆ«æ˜¯å¦‚æœç±»ä¹‹é—´çš„å†³ç­–è¾¹ç•Œéå¸¸å¤æ‚ï¼Œåˆ™å…è®¸æ•°æ®æ›´ç›´æ¥åœ°ä¸ºé¢„æµ‹æä¾›ä¿¡æ¯å¯èƒ½æ›´æœ‰æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm can, however, be extended to handle continuous descriptive features and continuous target features.",
            "zh": "ä½†æ˜¯ï¼Œè¯¥ç®—æ³•å¯ä»¥æ‰©å±•ä¸ºå¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾å’Œè¿ç»­ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "We noted previously that we can often increase the learning rate Î± when using batch gradient descent.",
            "zh": "æˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡ï¼Œä½¿ç”¨æ‰¹é‡æ¢¯åº¦ä¸‹é™æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¯ä»¥æé«˜å­¦ä¹ ç‡Î±ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.3â€…â€…â€…Outliers",
            "zh": "3.3.3 å¼‚å¸¸å€¼"
        }
    },
    {
        "translation": {
            "en": "Chapter",
            "zh": "ç« "
        }
    },
    {
        "translation": {
            "en": "Finally, decision trees are relatively easy to interpret, which means that the structure of the model can give some insight into customer behavior.",
            "zh": "æœ€åï¼Œå†³ç­–æ ‘ç›¸å¯¹å®¹æ˜“è§£é‡Šï¼Œè¿™æ„å‘³ç€æ¨¡å‹çš„ç»“æ„å¯ä»¥å¯¹å®¢æˆ·è¡Œä¸ºæä¾›ä¸€äº›è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.15â€…â€…â€…(a) A selection of images from the handwritten digits dataset; (b)â€“(d) image reconstructions generated by the auto-encoder network after 0, 10, and 1,000 training epochs.",
            "zh": "10.15 ï¼ˆaï¼‰ ä»æ‰‹å†™æ•°å­—æ•°æ®é›†ä¸­é€‰å‡ºçš„å›¾åƒ;ï¼ˆbï¼‰â€“ï¼ˆdï¼‰ è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œåœ¨ 0ã€10 å’Œ 1,000 ä¸ªè®­ç»ƒå‘¨æœŸåç”Ÿæˆçš„å›¾åƒé‡å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In all three figures, B and C are equidistant from A based on Euclidean distance.",
            "zh": "åœ¨æ‰€æœ‰ä¸‰ä¸ªå›¾å½¢ä¸­ï¼ŒåŸºäºæ¬§å‡ é‡Œå¾—è·ç¦»ï¼ŒB å’Œ C ä¸ A ç­‰è·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Now, when updating the value for Q(0-3,left), the Q value for this action, down, from the next state is used rather than the Q value for the best possible action, left, that was used in Q-learning.",
            "zh": "ç°åœ¨ï¼Œåœ¨æ›´æ–° Qï¼ˆ0-3ï¼Œleftï¼‰ çš„å€¼æ—¶ï¼Œå°†ä½¿ç”¨æ­¤æ“ä½œçš„ Q å€¼ï¼ˆä»ä¸‹ä¸€ä¸ªçŠ¶æ€å‘ä¸‹ï¼‰ï¼Œè€Œä¸æ˜¯åœ¨ Q å­¦ä¹ ä¸­ä½¿ç”¨çš„æœ€ä½³å¯èƒ½æ“ä½œï¼ˆå·¦ï¼‰çš„ Q å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use an error function to measure how well a set of weights fits the relationship in the training data.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨è¯¯å·®å‡½æ•°æ¥è¡¡é‡ä¸€ç»„æƒé‡ä¸è®­ç»ƒæ•°æ®ä¸­å…³ç³»çš„æ‹Ÿåˆç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The model evaluations based on misclassification rate described in the previous section are the first step in evaluating the performance of the prediction model created.",
            "zh": "åŸºäºä¸Šä¸€èŠ‚æ‰€è¿°çš„é”™è¯¯åˆ†ç±»ç‡çš„æ¨¡å‹è¯„ä¼°æ˜¯è¯„ä¼°æ‰€åˆ›å»ºçš„é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„ç¬¬ä¸€æ­¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 14.1",
            "zh": "è¡¨ 14.1"
        }
    },
    {
        "translation": {
            "en": "MARGINALADHESION: A measure of how much cells in the biopsy stick together (1 to 10).",
            "zh": "è¾¹ç¼˜ç²˜é™„ï¼šæµ‹é‡æ´»æ£€ä¸­æœ‰å¤šå°‘ç»†èƒç²˜åœ¨ä¸€èµ·ï¼ˆ1 åˆ° 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, non-normalized descriptive features can result in unstable or slow learning and a more unstable model in relation to generalization.",
            "zh": "æ€»ä¹‹ï¼Œéè§„èŒƒåŒ–çš„æè¿°æ€§ç‰¹å¾ä¼šå¯¼è‡´å­¦ä¹ ä¸ç¨³å®šæˆ–ç¼“æ…¢ï¼Œå¹¶ä¸”ä¸æ³›åŒ–ç›¸å…³çš„æ¨¡å‹æ›´ä¸ç¨³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The Jaccard similarity index is often used in these contexts.",
            "zh": "Jaccard ç›¸ä¼¼æ€§ç´¢å¼•é€šå¸¸ç”¨äºè¿™äº›ä¸Šä¸‹æ–‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, although its derivative is simple, that it has a max value of 0.25 contributes to the vanishing gradient problem in neural networks.",
            "zh": "ç„¶è€Œï¼Œå°½ç®¡å®ƒçš„å¯¼æ•°å¾ˆç®€å•ï¼Œä½†å®ƒçš„æœ€å¤§å€¼ä¸º 0.25 å¯¼è‡´äº†ç¥ç»ç½‘ç»œä¸­æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Overall there is a general trend that deeper networks have better performance than shallower networks, and that deeper networks are often more efficient in terms of the number of neurons they require.",
            "zh": "æ€»ä½“è€Œè¨€ï¼Œæœ‰ä¸€ä¸ªæ™®éçš„è¶‹åŠ¿ï¼Œå³æ›´æ·±çš„ç½‘ç»œæ¯”è¾ƒæµ…çš„ç½‘ç»œå…·æœ‰æ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”æ›´æ·±çš„ç½‘ç»œåœ¨æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡æ–¹é¢é€šå¸¸æ›´æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Choosing a good filter size for a given dataset often involves a trial-and-error process of experimenting with different options.",
            "zh": "ä¸ºç»™å®šæ•°æ®é›†é€‰æ‹©ä¸€ä¸ªå¥½çš„è¿‡æ»¤å™¨å¤§å°é€šå¸¸æ¶‰åŠè¯•éªŒä¸åŒé€‰é¡¹çš„è¯•é”™è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ROC index or area under the curve (AUC) measures the area underneath an ROC curve.",
            "zh": "ROC æŒ‡æ•°æˆ–æ›²çº¿ä¸‹é¢ç§¯ ï¼ˆAUCï¼‰ è¡¡é‡ ROC æ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "A model able to distinguish between instances that are very close to the boundary and those that are farther away would be preferable.",
            "zh": "ä¸€ä¸ªèƒ½å¤ŸåŒºåˆ†éå¸¸æ¥è¿‘è¾¹ç•Œçš„å®ä¾‹å’Œé‚£äº›è·ç¦»è¾ƒè¿œçš„å®ä¾‹çš„æ¨¡å‹ä¼šæ›´å¯å–ã€‚"
        }
    },
    {
        "translation": {
            "en": "This exponential growth rate is partially due to the fact that a full joint probability distribution ignores the structural relationships between features, such as direct influence and conditional independence relationships.",
            "zh": "è¿™ç§æŒ‡æ•°å¢é•¿ç‡éƒ¨åˆ†æ˜¯ç”±äºå®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒå¿½ç•¥äº†ç‰¹å¾ä¹‹é—´çš„ç»“æ„å…³ç³»ï¼Œä¾‹å¦‚ç›´æ¥å½±å“å’Œæ¡ä»¶ç‹¬ç«‹å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5(b)[38] illustrates how the observation and outcome period for multiple customers are measured over the same period.",
            "zh": "å›¾2.5ï¼ˆbï¼‰[38]è¯´æ˜äº†å¦‚ä½•åœ¨åŒä¸€æ—¶æœŸå†…æµ‹é‡å¤šä¸ªå®¢æˆ·çš„è§‚å¯ŸæœŸå’Œç»“æœæœŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Despite the lack of any instances that perfectly match the evidence, the fact that we were still able to calculate a score for each target level and make a prediction for the query highlights how the conditional independence assumption between the evidence given the target level both increases the coverage of the model and allows the model to generalize beyond the data used to induce it.",
            "zh": "å°½ç®¡ç¼ºä¹ä»»ä½•ä¸è¯æ®å®Œå…¨åŒ¹é…çš„å®ä¾‹ï¼Œä½†æˆ‘ä»¬ä»ç„¶èƒ½å¤Ÿè®¡ç®—æ¯ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°å¹¶å¯¹æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œè¿™ä¸€äº‹å®çªå‡ºäº†ç»™å®šç›®æ ‡æ°´å¹³çš„è¯æ®ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾å¦‚ä½•å¢åŠ æ¨¡å‹çš„è¦†ç›–èŒƒå›´ï¼Œå¹¶å…è®¸æ¨¡å‹åœ¨ç”¨äºè¯±å¯¼å®ƒçš„æ•°æ®ä¹‹å¤–è¿›è¡Œæ¨å¹¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some cases a lack of appropriate data will simply rule out proposed analytics solutions to a business problem.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œç¼ºä¹é€‚å½“çš„æ•°æ®åªä¼šæ’é™¤é’ˆå¯¹ä¸šåŠ¡é—®é¢˜çš„æ‹Ÿè®®åˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Specifically, if the value of one feature directly influences, or causes, the value taken by another feature, then this should be reflected in the structure of the graph by having a link from the cause feature to the effect feature.",
            "zh": "å…·ä½“è€Œè¨€ï¼Œå¦‚æœä¸€ä¸ªç‰¹å¾çš„å€¼ç›´æ¥å½±å“æˆ–å¯¼è‡´å¦ä¸€ä¸ªç‰¹å¾æ‰€è·å–çš„å€¼ï¼Œåˆ™åº”é€šè¿‡ä»åŸå› ç‰¹å¾åˆ°ç»“æœç‰¹å¾çš„é“¾æ¥æ¥åæ˜ åœ¨å›¾å½¢ç»“æ„ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "This involves an analysis of the needs of the business, the data we have available for use, and the capacity of the business to use analytics.",
            "zh": "è¿™æ¶‰åŠå¯¹ä¸šåŠ¡éœ€æ±‚ã€æˆ‘ä»¬å¯ä¾›ä½¿ç”¨çš„æ•°æ®ä»¥åŠä¸šåŠ¡ä½¿ç”¨åˆ†æçš„èƒ½åŠ›çš„åˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) On the basis of the clustering calculated in Part (a), calculate a set of new cluster centroids.",
            "zh": "ï¼ˆbï¼‰ æ ¹æ®ï¼ˆaï¼‰éƒ¨åˆ†è®¡ç®—çš„èšç±»ï¼Œè®¡ç®—ä¸€ç»„æ–°çš„èšç±»è´¨å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "If, on the other hand, the target feature is categorical, then information-based and probability-based approaches are likely to work very well.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œå¦‚æœç›®æ ‡ç‰¹å¾æ˜¯åˆ†ç±»çš„ï¼Œé‚£ä¹ˆåŸºäºä¿¡æ¯å’ŒåŸºäºæ¦‚ç‡çš„æ–¹æ³•å¯èƒ½ä¼šéå¸¸æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "linkage method, 618",
            "zh": "è”åŠ¨æ–¹å¼ï¼Œ618"
        }
    },
    {
        "translation": {
            "en": "There is a simple, well-known mathematical model that can capture the relationship between two continuous features like those in our dataset. Many readers will remember from high school geometry that the equation of a line can be written",
            "zh": "æœ‰ä¸€ä¸ªç®€å•ã€ä¼—æ‰€å‘¨çŸ¥çš„æ•°å­¦æ¨¡å‹å¯ä»¥æ•è·ä¸¤ä¸ªè¿ç»­ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼Œå°±åƒæˆ‘ä»¬æ•°æ®é›†ä¸­çš„ç‰¹å¾ä¸€æ ·ã€‚è®¸å¤šè¯»è€…ä¼šè®°å¾—é«˜ä¸­å‡ ä½•å­¦ä¸­å¯ä»¥å†™å‡ºä¸€æ¡çº¿çš„æ–¹ç¨‹"
        }
    },
    {
        "translation": {
            "en": "Modeling points in time for a scenario with no real observation period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "å¯¹æ²¡æœ‰å®é™…è§‚æµ‹æœŸçš„åœºæ™¯çš„æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªå®¢æˆ·ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "variable elimination, 298",
            "zh": "å˜é‡æ¶ˆé™¤ï¼Œ298"
        }
    },
    {
        "translation": {
            "en": "8.4.6.1â€ƒSimple recurrent neural networksâ€ƒA simple recurrent neural network architecture is a feedforward architecture with one hidden layer that has been extended with a memory buffer that is used to store the activations from the hidden layer for one time-step.",
            "zh": "8.4.6.1 ç®€å•çš„é€’å½’ç¥ç»ç½‘ç»œ ç®€å•çš„é€’å½’ç¥ç»ç½‘ç»œæ¶æ„æ˜¯ä¸€ç§å‰é¦ˆæ¶æ„ï¼Œå…·æœ‰ä¸€ä¸ªéšè—å±‚ï¼Œè¯¥éšè—å±‚å·²ä½¿ç”¨å†…å­˜ç¼“å†²åŒºè¿›è¡Œæ‰©å±•ï¼Œè¯¥å†…å­˜ç¼“å†²åŒºç”¨äºå­˜å‚¨éšè—å±‚çš„æ¿€æ´»ä¸€ä¸ªæ—¶é—´æ­¥é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 6.2[245] we described how a full joint probability distribution could be used to compute the probability for any event in a domain.",
            "zh": "åœ¨ç¬¬ 6.2 èŠ‚[245]ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•ä½¿ç”¨å®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒæ¥è®¡ç®—åŸŸä¸­ä»»ä½•äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Then working backward in a layer-by-layer manner, the Î´ for the hidden neurons are calculated using Equation (8.23)[412].",
            "zh": "ç„¶åä»¥é€å±‚æ–¹å¼å‘åå·¥ä½œï¼Œä½¿ç”¨å…¬å¼ï¼ˆ8.23ï¼‰[412]è®¡ç®—éšè—ç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "This would, however, ignore the fact that sometimes reward is delayed and that taking an action that gives a low immediate reward can be a good idea if it leads the agent to a state that could give it large positive rewards later on.",
            "zh": "ç„¶è€Œï¼Œè¿™å°†å¿½ç•¥è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³æœ‰æ—¶å¥–åŠ±æ˜¯å»¶è¿Ÿçš„ï¼Œå¦‚æœå®ƒå¯¼è‡´ä»£ç†è¿›å…¥ä¸€ä¸ªå¯ä»¥åœ¨ä»¥åç»™å®ƒå¸¦æ¥å¤§é‡ç§¯æå¥–åŠ±çš„çŠ¶æ€ï¼Œé‚£ä¹ˆé‡‡å–ä¸€ä¸ªç«‹å³å¥–åŠ±è¾ƒä½çš„è¡ŒåŠ¨å¯èƒ½æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for elliptical galaxy category",
            "zh": "æ¤­åœ†æ˜Ÿç³»ç±»åˆ«çš„å¾—ç¥¨åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "Histograms of a selection of features from the SDSS dataset.",
            "zh": "SDSS æ•°æ®é›†ä¸­æ‰€é€‰è¦ç´ çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This empty partition will result in a leaf node that returns a prediction of the majority target level in 8, chapparal.",
            "zh": "è¿™ä¸ªç©ºåˆ†åŒºå°†äº§ç”Ÿä¸€ä¸ªå¶èŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹è¿”å›å¯¹ 8 chapparal ä¸­å¤šæ•°ç›®æ ‡æ°´å¹³çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.5",
            "zh": "è¡¨ 10.5"
        }
    },
    {
        "translation": {
            "en": "where q and d are two instances, |q| is the total number of features in the dataset, and CP(q,d) measures the total number of co-presences between q and d. Using Russel-Rao, q has a higher similarity to d1 than to d2:",
            "zh": "å…¶ä¸­ q å’Œ d æ˜¯ä¸¤ä¸ªå®ä¾‹ï¼Œ|q|æ˜¯æ•°æ®é›†ä¸­çš„ç‰¹å¾æ€»æ•°ï¼ŒCPï¼ˆqï¼Œdï¼‰ æµ‹é‡ q å’Œ d ä¹‹é—´çš„å…±å­˜æ€»æ•°ã€‚ ä½¿ç”¨ Russel-Raoï¼Œq ä¸ d1 çš„ç›¸ä¼¼åº¦é«˜äºä¸ d2 çš„ç›¸ä¼¼åº¦ï¼š"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset.",
            "zh": "ï¼ˆaï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†ä¸­ SIZE å’Œ RENTAL PRICE ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3â€ƒStandard Approach: Multivariable Linear Regression with Gradient Descent",
            "zh": "7.3 æ ‡å‡†æ–¹æ³•ï¼šæ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "Derived descriptive features do not exist in any raw data source, so they must be constructed from data in one or more raw data sources.",
            "zh": "æ´¾ç”Ÿçš„æè¿°æ€§ç‰¹å¾åœ¨ä»»ä½•åŸå§‹æ•°æ®æºä¸­éƒ½ä¸å­˜åœ¨ï¼Œå› æ­¤å¿…é¡»æ ¹æ®ä¸€ä¸ªæˆ–å¤šä¸ªåŸå§‹æ•°æ®æºä¸­çš„æ•°æ®æ„é€ å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, as the number of basis functions grows beyond the number of descriptive features, the complexity of our models increases, so the gradient descent process must search through a more complex weight space.",
            "zh": "å…¶æ¬¡ï¼Œéšç€åŸºå‡½æ•°çš„æ•°é‡è¶…è¿‡æè¿°æ€§ç‰¹å¾çš„æ•°é‡ï¼Œæˆ‘ä»¬æ¨¡å‹çš„å¤æ‚æ€§å¢åŠ ï¼Œå› æ­¤æ¢¯åº¦ä¸‹é™è¿‡ç¨‹å¿…é¡»æœç´¢æ›´å¤æ‚çš„æƒé‡ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of the softmax activations for each of the neurons in the output layer for each example in the mini-batch, and the calculation of the Î´ for each neuron in the output layer for each example in the mini-batch.",
            "zh": "è®¡ç®—å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ softmax æ¿€æ´»æ¬¡æ•°ï¼Œä»¥åŠè®¡ç®—å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.5[204] lists a sample from this dataset.",
            "zh": "è¡¨5.5[204]åˆ—å‡ºäº†è¯¥æ•°æ®é›†ä¸­çš„ä¸€ä¸ªæ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main challenge was a return to the Data Preparation phase to make the routines used to extract the data for the ABT robust and reliable enough to be used to generate new query instances every month.",
            "zh": "ä¸»è¦æŒ‘æˆ˜æ˜¯è¿”å›æ•°æ®å‡†å¤‡é˜¶æ®µï¼Œä½¿ç”¨äºæå– ABT æ•°æ®çš„ä¾‹ç¨‹è¶³å¤Ÿå¼ºå¤§å’Œå¯é ï¼Œä»¥ä¾¿æ¯æœˆç”Ÿæˆæ–°çš„æŸ¥è¯¢å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Which of the two descriptive features should we use as the testing criterion at the root node of a decision tree to predict studentsâ€™ scores?",
            "zh": "æˆ‘ä»¬åº”è¯¥ä½¿ç”¨ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ä¸­çš„å“ªä¸€ä¸ªä½œä¸ºå†³ç­–æ ‘æ ¹èŠ‚ç‚¹çš„æµ‹è¯•æ ‡å‡†æ¥é¢„æµ‹å­¦ç”Ÿçš„åˆ†æ•°ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The node is not NULL, so the while loop on Line 4 succeeds.",
            "zh": "èŠ‚ç‚¹ä¸ä¸º NULLï¼Œå› æ­¤ç¬¬ 4 è¡Œä¸Šçš„ while å¾ªç¯æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "4.1â€…â€…â€…Cards showing character faces and names for the Guess Who game.",
            "zh": "4.1 æ˜¾ç¤ºçŒœçŒœè°æ¸¸æˆè§’è‰²é¢å­”å’Œåå­—çš„å¡ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.9â€ƒExercises",
            "zh": "3.9 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Fortunately, there is an easy calculation that can be made from the ROC curve that achieves this.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œå¯ä»¥ä» ROC æ›²çº¿è¿›è¡Œç®€å•çš„è®¡ç®—æ¥å®ç°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "One common approach to evaluating clustering is to use an internal criterion to evaluate how well the clustering found by an algorithm matches some idealized notion of what a good clustering would look like.",
            "zh": "è¯„ä¼°èšç±»çš„ä¸€ç§å¸¸ç”¨æ–¹æ³•æ˜¯ä½¿ç”¨å†…éƒ¨æ ‡å‡†æ¥è¯„ä¼°ç®—æ³•å‘ç°çš„èšç±»ä¸è‰¯å¥½èšç±»çš„ç†æƒ³åŒ–æ¦‚å¿µçš„åŒ¹é…ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are four descriptive features and one target feature in this dataset, as follows:",
            "zh": "è¯¥æ•°æ®é›†ä¸­æœ‰å››ä¸ªæè¿°æ€§ç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡ç‰¹å¾ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 6.8[279] shows the histograms of the values of the ACCOUNT BALANCE feature partitioned on the two levels of the FRAUD target feature.",
            "zh": "å›¾ 6.8[279] æ˜¾ç¤ºäº†åœ¨ FRAUD ç›®æ ‡ç‰¹å¾çš„ä¸¤ä¸ªçº§åˆ«ä¸Šåˆ’åˆ†çš„ ACCOUNT BALANCE ç‰¹å¾å€¼çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.1",
            "zh": "å›¾ 8.1"
        }
    },
    {
        "translation": {
            "en": "Furthermore, large weight updates can result in instability in model training.",
            "zh": "æ­¤å¤–ï¼Œè¾ƒå¤§çš„æƒé‡æ›´æ–°ä¼šå¯¼è‡´æ¨¡å‹è®­ç»ƒçš„ä¸ç¨³å®šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Sam Walton",
            "zh": "â€”â€”å±±å§†Â·æ²ƒå°”é¡¿"
        }
    },
    {
        "translation": {
            "en": "4.4.1â€ƒAlternative Feature Selection and Impurity Metrics",
            "zh": "4.4.1 æ›¿ä»£ç‰¹å¾é€‰æ‹©å’Œæ‚è´¨æŒ‡æ ‡"
        }
    },
    {
        "translation": {
            "en": "A.4â€ƒData Visualization",
            "zh": "A.4 æ•°æ®å¯è§†åŒ–"
        }
    },
    {
        "translation": {
            "en": "This transformation from a joint probability conditioned on a single event into a product of conditional probabilities with just one event being conditioned in each term may not appear to achieve much. We will see shortly, however, that this transformation is incredibly useful.",
            "zh": "è¿™ç§ä»ä»¥å•ä¸ªäº‹ä»¶ä¸ºæ¡ä»¶çš„è”åˆæ¦‚ç‡åˆ°æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ï¼ˆæ¯ä¸ªé¡¹ä¸­åªæœ‰ä¸€ä¸ªäº‹ä»¶è¢«æ¡ä»¶æ¡ä»¶ï¼‰çš„è½¬å˜ä¼¼ä¹å¹¶æ²¡æœ‰å–å¾—å¤šå¤§æˆå°±ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°ï¼Œè¿™ç§è½¬å˜æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case the median value of 0.0 (shown in Table 3.3(a)[57]) is the most appropriate value to use to replace the missing values; because this feature only actually takes discrete values, the mean value of 0.2 never naturally occurs in the dataset.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸­å€¼ 0.0ï¼ˆå¦‚è¡¨ 3.3ï¼ˆaï¼‰[57] æ‰€ç¤ºï¼‰æ˜¯ç”¨äºæ›¿æ¢ç¼ºå¤±å€¼çš„æœ€åˆé€‚å€¼;ç”±äºæ­¤ç‰¹å¾å®é™…ä¸Šä»…é‡‡ç”¨ç¦»æ•£å€¼ï¼Œå› æ­¤ 0.2 çš„å¹³å‡å€¼æ°¸è¿œä¸ä¼šè‡ªç„¶åœ°å‡ºç°åœ¨æ•°æ®é›†ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.3â€…â€…â€…Standard Approach: Q-Learning, Off-Policy Temporal-Difference Learning",
            "zh": "11.3 æ ‡å‡†æ–¹æ³•ï¼šQ-å­¦ä¹ ã€éæ”¿ç­–æ—¶é—´å·®å¼‚å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "In many cases, however, it does not make sense to consider one target level as being more important.",
            "zh": "ç„¶è€Œï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå°†ä¸€ä¸ªç›®æ ‡çº§åˆ«è§†ä¸ºæ›´é‡è¦æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.11",
            "zh": "å›¾ 7.11"
        }
    },
    {
        "translation": {
            "en": "Each neuron in a sub-sampling layer has a local receptive field in a feature map generated by the previous layer, which will have convolved a filter over the input to that layer.",
            "zh": "å­é‡‡æ ·å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒåœ¨å‰ä¸€å±‚ç”Ÿæˆçš„ç‰¹å¾å›¾ä¸­éƒ½æœ‰ä¸€ä¸ªå±€éƒ¨æ„Ÿå—é‡ï¼Œè¯¥ç‰¹å¾å›¾å°†åœ¨è¯¥å±‚çš„è¾“å…¥ä¸Šå·ç§¯ä¸€ä¸ªæ»¤æ³¢å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.19",
            "zh": "å›¾ 5.19"
        }
    },
    {
        "translation": {
            "en": "Exponential or skewed distributions in histograms are also good indicators of the presence of outliers.",
            "zh": "ç›´æ–¹å›¾ä¸­çš„æŒ‡æ•°åˆ†å¸ƒæˆ–åæ€åˆ†å¸ƒä¹Ÿæ˜¯å¼‚å¸¸å€¼å­˜åœ¨çš„è‰¯å¥½æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "ordinal data, 34",
            "zh": "åºæ•°æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "The sum of all the cells in a joint probability distribution must be 1.0.",
            "zh": "è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­æ‰€æœ‰å•å…ƒæ ¼çš„æ€»å’Œå¿…é¡»ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "As learning continues, however, values start to propagate across the states in the environment on subsequent episodes.",
            "zh": "ç„¶è€Œï¼Œéšç€å­¦ä¹ çš„ç»§ç»­ï¼Œä»·å€¼è§‚åœ¨éšåçš„æƒ…èŠ‚ä¸­å¼€å§‹åœ¨ç¯å¢ƒä¸­çš„å„ä¸ªå·ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) P(HEADACHE = true,VOMITING = false)",
            "zh": "ï¼ˆcï¼‰ Pï¼ˆå¤´ç—› = çœŸï¼Œå‘•å = å‡ï¼‰"
        }
    },
    {
        "translation": {
            "en": "-1.0836",
            "zh": "-1.0836"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39[506] also shows how often each weight matrix was used in the generation of each output.",
            "zh": "å›¾8.39[506]è¿˜æ˜¾ç¤ºäº†åœ¨ç”Ÿæˆæ¯ä¸ªè¾“å‡ºæ—¶ä½¿ç”¨æ¯ä¸ªæƒé‡çŸ©é˜µçš„é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mitchell, Tom M., Svetlana V. Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L. Malave, Robert A. Mason, and Marcel A. Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science 320 (5880): 1191â€“1195. doi:10.1126/science.1152876.",
            "zh": "Mitchellã€Tom M.ã€Svetlana V. Shinkarevaã€Andrew Carlsonã€Kai-Min Changã€Vicente L. Malaveã€Robert A. Mason å’Œ Marcel A. Justã€‚2008. é¢„æµ‹ä¸åè¯å«ä¹‰ç›¸å…³çš„äººè„‘æ´»åŠ¨.ç§‘å­¦320ï¼ˆ5880ï¼‰ï¼š1191-1195ã€‚doiï¼š10.1126/science.1152876."
        }
    },
    {
        "translation": {
            "en": "The second thing that the examples listed have in common is that a model is trained to make predictions based on a set of historical examples.",
            "zh": "åˆ—å‡ºçš„ç¤ºä¾‹çš„ç¬¬äºŒä¸ªå…±åŒç‚¹æ˜¯ï¼Œæ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥æ ¹æ®ä¸€ç»„å†å²ç¤ºä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ranking the models by profit, we are able to take this into account, which is impossible using classification accuracy or average class accuracy.",
            "zh": "æŒ‰åˆ©æ¶¦å¯¹æ¨¡å‹è¿›è¡Œæ’åï¼Œæˆ‘ä»¬èƒ½å¤Ÿè€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè¿™ä½¿ç”¨åˆ†ç±»ç²¾åº¦æˆ–å¹³å‡ç±»ç²¾åº¦æ˜¯ä¸å¯èƒ½çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A line along the diagonal of ROC space from (0,0) to (1,0), shown as a dotted line in Figure 9.12(a)[562], is a reference line representing the expected performance of a model that makes random predictions.",
            "zh": "ä»ï¼ˆ0,0ï¼‰åˆ°ï¼ˆ1,0ï¼‰æ²¿ROCç©ºé—´å¯¹è§’çº¿çš„ä¸€æ¡çº¿ï¼Œåœ¨å›¾9.12ï¼ˆaï¼‰[562]ä¸­æ˜¾ç¤ºä¸ºè™šçº¿ï¼Œæ˜¯è¡¨ç¤ºè¿›è¡Œéšæœºé¢„æµ‹çš„æ¨¡å‹çš„é¢„æœŸæ€§èƒ½çš„å‚è€ƒçº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Parents(xi) describes the set of nodes in the graph that directly link into node xi. Using this equation, we can compute any joint event in the domain represented by the Bayesian network. For example, using the slightly more complex Bayesian network in Figure 6.9(b)[287], we can calculate the probability of the joint event P(a,Â¬b,Â¬c,d) as",
            "zh": "å…¶ä¸­ Parentsï¼ˆä¹ ï¼‰ æè¿°å›¾ä¸­ç›´æ¥é“¾æ¥åˆ°èŠ‚ç‚¹ ä¹  çš„èŠ‚ç‚¹é›†ã€‚ä½¿ç”¨è¿™ä¸ªæ–¹ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è´å¶æ–¯ç½‘ç»œè¡¨ç¤ºçš„åŸŸä¸­çš„ä»»ä½•è”åˆäº‹ä»¶ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨å›¾6.9ï¼ˆbï¼‰[287]ä¸­ç¨å¾®å¤æ‚çš„è´å¶æ–¯ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è”åˆäº‹ä»¶Pï¼ˆaï¼ŒÂ¬bï¼ŒÂ¬cï¼Œdï¼‰çš„æ¦‚ç‡ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "34. This is a naive assumption because we are making it to simplify the discussion irrespective of whether or not it is true.",
            "zh": "34. è¿™æ˜¯ä¸€ä¸ªå¹¼ç¨šçš„å‡è®¾ï¼Œå› ä¸ºæˆ‘ä»¬è¿™æ ·åšæ˜¯ä¸ºäº†ç®€åŒ–è®¨è®ºï¼Œè€Œä¸ç®¡å®ƒæ˜¯å¦å±å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. Learning a general rule from a finite set of examples is called inductive learning. This is why machine learning is sometimes described as inductive learning, and the set of assumptions used by the machine algorithm that biases it toward selecting a single model is called the inductive bias of the algorithm.",
            "zh": "6. ä»ä¸€ç»„æœ‰é™çš„ä¾‹å­ä¸­å­¦ä¹ ä¸€èˆ¬è§„åˆ™ç§°ä¸ºå½’çº³å­¦ä¹ ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœºå™¨å­¦ä¹ æœ‰æ—¶è¢«æè¿°ä¸ºå½’çº³å­¦ä¹ ï¼Œè€Œæœºå™¨ç®—æ³•ä½¿ç”¨çš„åå‘äºé€‰æ‹©å•ä¸ªæ¨¡å‹çš„ä¸€ç»„å‡è®¾ç§°ä¸ºç®—æ³•çš„å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "That the neurons in this network use a linear activation function means that var(Z(HL1)) is also the variance of the activations propagated forward to the next hidden layer, and so it is also the variance of the inputs to the next layer: var(Z(HL1)) = var(A(HL1)) = var(d(HL2)).",
            "zh": "è¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°æ„å‘³ç€ varï¼ˆZï¼ˆHL1ï¼‰ï¼‰ ä¹Ÿæ˜¯å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªéšè—å±‚çš„æ¿€æ´»çš„æ–¹å·®ï¼Œå› æ­¤å®ƒä¹Ÿæ˜¯ä¸‹ä¸€å±‚è¾“å…¥çš„æ–¹å·®ï¼švarï¼ˆZï¼ˆHL1ï¼‰ï¼‰ = varï¼ˆAï¼ˆHL1ï¼‰ï¼‰ = varï¼ˆdï¼ˆHL2ï¼‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. Figure 5.12(a)[205] further misleads us because when we draw scatter plots, we scale the values to make the plot fit into a square-shaped image. If we were to plot the axis for the SALARY feature to the same scale as the AGE feature in Figure 5.12(a)[205], it would stretch over almost 400 pages.",
            "zh": "14. å›¾5.12ï¼ˆaï¼‰[205]è¿›ä¸€æ­¥è¯¯å¯¼äº†æˆ‘ä»¬ï¼Œå› ä¸ºå½“æˆ‘ä»¬ç»˜åˆ¶æ•£ç‚¹å›¾æ—¶ï¼Œæˆ‘ä»¬ä¼šç¼©æ”¾è¿™äº›å€¼ä»¥ä½¿å›¾é€‚åˆæ­£æ–¹å½¢å›¾åƒã€‚å¦‚æœæˆ‘ä»¬å°† SALARY ç‰¹å¾çš„è½´ç»˜åˆ¶åˆ°ä¸å›¾ 5.12ï¼ˆaï¼‰[205] ä¸­çš„ AGE ç‰¹å¾ç›¸åŒçš„æ¯”ä¾‹ï¼Œå®ƒå°†å»¶ä¼¸è¿‘ 400 é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "Another well-known variant of the ID3 algorithm is the CART algorithm.",
            "zh": "ID3 ç®—æ³•çš„å¦ä¸€ä¸ªè‘—åå˜ä½“æ˜¯ CART ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "âˆ‚â„°/âˆ‚w4,0, âˆ‚â„°/âˆ‚w3,2, âˆ‚â„°/âˆ‚w3,1, âˆ‚â„°/âˆ‚w3,0).",
            "zh": "âˆ‚E/âˆ‚w4,0ã€âˆ‚E/âˆ‚w3,2ã€âˆ‚E/âˆ‚w3,1ã€âˆ‚E/âˆ‚w3,0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The end result of clustering is a single new generated feature that indicates the cluster that an instance belongs to, and the generation of this new feature is typically the end goal of the clustering task.",
            "zh": "èšç±»çš„æœ€ç»ˆç»“æœæ˜¯å•ä¸ªæ–°ç”Ÿæˆçš„ç‰¹å¾ï¼Œè¯¥ç‰¹å¾æŒ‡ç¤ºå®ä¾‹æ‰€å±çš„èšç±»ï¼Œç”Ÿæˆæ­¤æ–°ç‰¹å¾é€šå¸¸æ˜¯èšç±»ä»»åŠ¡çš„æœ€ç»ˆç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "TD(0), 655",
            "zh": "TDï¼ˆ0ï¼‰ï¼Œ 655"
        }
    },
    {
        "translation": {
            "en": "There were two fundamental problems with how Literary Digest collected its sample, and the result of both was that the sample used for prediction (the survey responses) was not representative of the overall population.",
            "zh": "ã€Šæ–‡å­¦æ–‡æ‘˜ã€‹æ”¶é›†æ ·æœ¬çš„æ–¹å¼å­˜åœ¨ä¸¤ä¸ªåŸºæœ¬é—®é¢˜ï¼Œä¸¤è€…çš„ç»“æœæ˜¯ç”¨äºé¢„æµ‹çš„æ ·æœ¬ï¼ˆè°ƒæŸ¥å›å¤ï¼‰ä¸èƒ½ä»£è¡¨æ€»ä½“äººå£ã€‚"
        }
    },
    {
        "translation": {
            "en": "For categorical features, we use a specific typography to indicate the levels in the domain of the feature when referring to a feature by name in the text (e.g., center, aa, and soft tissue).",
            "zh": "å¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œå½“åœ¨æ–‡æœ¬ä¸­æŒ‰åç§°å¼•ç”¨ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹å®šçš„æ’ç‰ˆæ¥æŒ‡ç¤ºç‰¹å¾åŸŸä¸­çš„çº§åˆ«ï¼ˆä¾‹å¦‚ï¼Œä¸­å¿ƒã€aa å’Œè½¯ç»„ç»‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "19.31",
            "zh": "19.31"
        }
    },
    {
        "translation": {
            "en": "More recently, Leshno et al.",
            "zh": "æœ€è¿‘ï¼ŒLeshno ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "The player and dealer are initially each dealt two cards.",
            "zh": "ç©å®¶å’Œåº„å®¶æœ€åˆå„å‘ä¸¤å¼ ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This backward pass gives the network its name: backpropagation.",
            "zh": "è¿™ç§å‘åä¼ é€’ä½¿ç½‘ç»œå¾—åï¼šåå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "natural language processing, 234",
            "zh": "è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œ234"
        }
    },
    {
        "translation": {
            "en": "inter-cluster distance, 608",
            "zh": "é›†ç¾¤é—´è·ç¦»ï¼Œ608"
        }
    },
    {
        "translation": {
            "en": "Hand, David J., and Christoforos Anagnostopoulos. 2013. When is the area under the receiver operating characteristic curve an appropriate measure of classifier performance? Pattern Recognition Letters 34 (5): 492â€“495.",
            "zh": "Handã€David J. å’Œ Christoforos Anagnostopoulosã€‚2013. ä½•æ—¶ï¼Œå—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹çš„é¢ç§¯æ˜¯åˆ†çº§å™¨æ€§èƒ½çš„é€‚å½“è¡¡é‡æ ‡å‡†ï¼Ÿæ¨¡å¼è¯†åˆ«å¿«æŠ¥34ï¼ˆ5ï¼‰ï¼š492â€“495ã€‚"
        }
    },
    {
        "translation": {
            "en": "backpropagation through time, 502, 518",
            "zh": "éšæ—¶é—´åå‘ä¼ æ’­ï¼Œ502,518"
        }
    },
    {
        "translation": {
            "en": "8.12â€…â€…â€…The ReLU networkâ€™s per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "8.12 ReLU ç½‘ç»œæ¯ä¸ªç¤ºä¾‹çš„é¢„æµ‹ã€è¯¯å·®å’Œè®­ç»ƒåçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œæ”¶æ•›åˆ° SSE < 0.0001ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activations for the other three neurons using this filter would be calculated in a similar way, resulting in the following feature map being generated by this 2-by-2 layer of neurons:",
            "zh": "ä½¿ç”¨æ­¤è¿‡æ»¤å™¨çš„å…¶ä»–ä¸‰ä¸ªç¥ç»å…ƒçš„æ¿€æ´»å°†ä»¥ç±»ä¼¼çš„æ–¹å¼è®¡ç®—ï¼Œä»è€Œç”±æ­¤ 2Ã—2 ç¥ç»å…ƒå±‚ç”Ÿæˆä»¥ä¸‹ç‰¹å¾å›¾ï¼š"
        }
    },
    {
        "translation": {
            "en": "perceptron, 396",
            "zh": "æ„ŸçŸ¥å™¨ï¼Œ396"
        }
    },
    {
        "translation": {
            "en": "The outliers shown in box plots also help to make this comparison.",
            "zh": "ç®±å½¢å›¾ä¸­æ˜¾ç¤ºçš„å¼‚å¸¸å€¼ä¹Ÿæœ‰åŠ©äºè¿›è¡Œæ­¤æ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "8.22â€…â€…â€…The architecture of the neural network used in the weight initialization experiments. Note that the neurons in this network use a linear activation function: ai = zi.",
            "zh": "8.22 æƒé‡åˆå§‹åŒ–å®éªŒä¸­ä½¿ç”¨çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚è¯·æ³¨æ„ï¼Œè¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼šai = ziã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if the neurons in the early layers of the network take a long time to train, then the neurons in the later layers cannot efficiently build upon the outputs of these early neurons.",
            "zh": "ç„¶è€Œï¼Œå¦‚æœç½‘ç»œæ—©æœŸå±‚çš„ç¥ç»å…ƒéœ€è¦å¾ˆé•¿æ—¶é—´æ¥è®­ç»ƒï¼Œé‚£ä¹ˆåæœŸå±‚çš„ç¥ç»å…ƒå°±æ— æ³•æœ‰æ•ˆåœ°å»ºç«‹åœ¨è¿™äº›æ—©æœŸç¥ç»å…ƒçš„è¾“å‡ºä¹‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "simple multivariable linear regression, 367",
            "zh": "ç®€å•å¤šå˜é‡çº¿æ€§å›å½’ï¼Œ367"
        }
    },
    {
        "translation": {
            "en": "Using basis functions is an interesting way to change the inductive bias, in particular the restriction bias, encoded in the gradient descent algorithm for learning regression models.",
            "zh": "ä½¿ç”¨åŸºå‡½æ•°æ˜¯æ”¹å˜å½’çº³åå·®çš„ä¸€ç§æœ‰è¶£æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é™åˆ¶åå·®ï¼Œç¼–ç åœ¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­ï¼Œç”¨äºå­¦ä¹ å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most popular strategy to define a convergence criterion to stop training a neural network is early stopping.",
            "zh": "å®šä¹‰æ”¶æ•›æ ‡å‡†ä»¥åœæ­¢è®­ç»ƒç¥ç»ç½‘ç»œçš„æœ€æµè¡Œç­–ç•¥æ˜¯æ—©æœŸåœæ­¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "From each smaller group, we then create a sample containing that number of instances.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬ä»æ¯ä¸ªè¾ƒå°çš„ç»„ä¸­åˆ›å»ºä¸€ä¸ªåŒ…å«è¯¥æ•°é‡å®ä¾‹çš„æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false.",
            "zh": "GUARANTOR/COAPPLICANT ç‰¹å¾åœ¨ FRAUD = false æ¡ä»¶ä¸‹çš„åéªŒæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "box plot, 54, 451, 745, 752, 755",
            "zh": "ç®±å½¢åœ°å—ï¼Œ 54ï¼Œ 451ï¼Œ 745ï¼Œ 752ï¼Œ 755"
        }
    },
    {
        "translation": {
            "en": "Loan default prediction is an example where the definition of the target feature has a time element but the descriptive features are time independent.",
            "zh": "è´·æ¬¾è¿çº¦é¢„æµ‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå…¶ä¸­ç›®æ ‡ç‰¹å¾çš„å®šä¹‰å…·æœ‰æ—¶é—´å…ƒç´ ï¼Œä½†æè¿°æ€§ç‰¹å¾ä¸æ—¶é—´æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.1â€ƒConverting Business Problems into Analytics Solutions",
            "zh": "2.1 å°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆ"
        }
    },
    {
        "translation": {
            "en": "ME1_U/G/R/I/Z",
            "zh": "ME1_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "the bias imposed on a generative model can become larger than the error of the trained model.",
            "zh": "æ–½åŠ åœ¨ç”Ÿæˆæ¨¡å‹ä¸Šçš„åå·®å¯èƒ½å¤§äºè®­ç»ƒæ¨¡å‹çš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The histograms for each continuous feature included in a data quality report are a very easy way for us to understand how the values for a feature are distributed across the range they can take.2 When we generate histograms of features, there are a number of common, well-understood shapes that we should look out for.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­åŒ…å«çš„æ¯ä¸ªè¿ç»­ç‰¹å¾çš„ç›´æ–¹å›¾æ˜¯ä¸€ç§éå¸¸ç®€å•çš„æ–¹æ³•ï¼Œå¯ä»¥è®©æˆ‘ä»¬äº†è§£ç‰¹å¾çš„å€¼å¦‚ä½•åœ¨å®ƒä»¬å¯ä»¥é‡‡ç”¨çš„èŒƒå›´å†…åˆ†å¸ƒã€‚2 å½“æˆ‘ä»¬ç”Ÿæˆç‰¹å¾çš„ç›´æ–¹å›¾æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥æ³¨æ„è®¸å¤šå¸¸è§çš„ã€æ˜“äºç†è§£çš„å½¢çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finding a good equilibrium for a given prediction task involves experimenting with different architectures to see which performs best.",
            "zh": "ä¸ºç»™å®šçš„é¢„æµ‹ä»»åŠ¡æ‰¾åˆ°è‰¯å¥½çš„å¹³è¡¡éœ€è¦å°è¯•ä¸åŒçš„æ¶æ„ï¼Œçœ‹çœ‹å“ªç§æ¶æ„è¡¨ç°æœ€å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the performance changes significantly, this is a strong indication that concept drift has occurred and that the model has gone stale.",
            "zh": "å¦‚æœæ€§èƒ½å‘ç”Ÿé‡å¤§å˜åŒ–ï¼Œåˆ™å¼ºçƒˆè¡¨æ˜å‘ç”Ÿäº†æ¦‚å¿µæ¼‚ç§»ï¼Œå¹¶ä¸”æ¨¡å‹å·²ç»è¿‡æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2.1â€ƒBayesâ€™ Theorem",
            "zh": "6.2.1 è´å¶æ–¯å®šç†"
        }
    },
    {
        "translation": {
            "en": "Glorot, Xavier, and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (AISTATS), 249â€“256. JMLR.",
            "zh": "æ ¼æ´›ç½—ç‰¹ã€æ³½ç»´å°”å’Œçº¦ä¹¦äºšÂ·æœ¬å‰å¥¥ã€‚2010. äº†è§£è®­ç»ƒæ·±åº¦å‰é¦ˆç¥ç»ç½‘ç»œçš„éš¾åº¦.ç¬¬åä¸‰å±Šäººå·¥æ™ºèƒ½ä¸ç»Ÿè®¡å›½é™…ä¼šè®®ï¼ˆAISTATSï¼‰è®ºæ–‡é›†ï¼Œç¬¬249-256é¡µã€‚JMLRã€‚"
        }
    },
    {
        "translation": {
            "en": "In a full network training scenario there would be many such weight updates as the training progressed through multiple epochs and, for each epoch, multiple mini-batches; the reduction of the network error would accumulate over these weight updates.",
            "zh": "åœ¨å®Œæ•´çš„ç½‘ç»œè®­ç»ƒåœºæ™¯ä¸­ï¼Œéšç€è®­ç»ƒç»è¿‡å¤šä¸ªå‘¨æœŸçš„è¿›å±•ï¼Œå¹¶ä¸”å¯¹äºæ¯ä¸ªå‘¨æœŸï¼Œä¼šæœ‰å¤šä¸ªå°æ‰¹é‡çš„æƒé‡æ›´æ–°;ç½‘ç»œè¯¯å·®çš„å‡å°‘å°†ç´¯ç§¯åœ¨è¿™äº›æƒé‡æ›´æ–°ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, m will denote the event MENINGITIS = true and Â¬m will denote MENINGITIS = false.",
            "zh": "å› æ­¤ï¼Œm è¡¨ç¤ºäº‹ä»¶ MENINGITIS = trueï¼ŒÂ¬m è¡¨ç¤º MENINGITIS = falseã€‚"
        }
    },
    {
        "translation": {
            "en": "As we see when we discuss the vanishing gradient problem, adding depth to a network can slow down the rate at which a network learns.",
            "zh": "æ­£å¦‚æˆ‘ä»¬åœ¨è®¨è®ºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ—¶æ‰€çœ‹åˆ°çš„ï¼Œå¢åŠ ç½‘ç»œçš„æ·±åº¦ä¼šå‡æ…¢ç½‘ç»œçš„å­¦ä¹ é€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´ for a neuron in the last hidden layer is calculated by summing the portions of the Î´s backpropagated to it from all the neurons in the output layer that it connects to.",
            "zh": "æœ€åä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„Î´æ˜¯é€šè¿‡å°†å®ƒæ‰€è¿æ¥çš„è¾“å‡ºå±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒåå‘ä¼ æ’­åˆ°å®ƒçš„ Î´ éƒ¨åˆ†ç›¸åŠ æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "To investigate this idea, she generated SPLOM charts for different photometric band versions of a selection of columns from the dataset (see Figure 13.5[714]), and these showed significant relationships, which confirmed her suspicion.",
            "zh": "ä¸ºäº†ç ”ç©¶è¿™ä¸ªæƒ³æ³•ï¼Œå¥¹ä¸ºæ•°æ®é›†ä¸­é€‰æ‹©çš„åˆ—çš„ä¸åŒå…‰åº¦æ³¢æ®µç‰ˆæœ¬ç”Ÿæˆäº†SPLOMå›¾è¡¨ï¼ˆè§å›¾13.5[714]ï¼‰ï¼Œè¿™äº›å›¾è¡¨æ˜¾ç¤ºå‡ºæ˜¾ç€çš„å…³ç³»ï¼Œè¿™è¯å®äº†å¥¹çš„æ€€ç–‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "This new node indexes d21, which is not NULL, so the while loop on Line 4 succeeds.",
            "zh": "è¿™ä¸ªæ–°èŠ‚ç‚¹ç´¢å¼• d21ï¼Œå®ƒä¸æ˜¯ NULLï¼Œå› æ­¤ç¬¬ 4 è¡Œä¸Šçš„ while å¾ªç¯æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "7. We have already discussed the derivative of the logistic function in Chapter 7[311] (see Equation (7.28)[345]); we rewrite it here using z in place of x for convenience.",
            "zh": "7. æˆ‘ä»¬å·²ç»åœ¨ç¬¬7ç« [311]ä¸­è®¨è®ºäº†é€»è¾‘å‡½æ•°çš„å¯¼æ•°ï¼ˆè§æ–¹ç¨‹ï¼ˆ7.28ï¼‰[345]ï¼‰;ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç”¨ z ä»£æ›¿ x é‡å†™å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that we have been focusing on processing a grayscale image that is a two-dimensional input.",
            "zh": "åŸå› æ˜¯æˆ‘ä»¬ä¸€ç›´ä¸“æ³¨äºå¤„ç†ä½œä¸ºäºŒç»´è¾“å…¥çš„ç°åº¦å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, Î”wi,k is the error gradient for weight wi,k for one epoch.",
            "zh": "å› æ­¤ï¼ŒÎ”wiï¼Œk æ˜¯ä¸€ä¸ªçºªå…ƒçš„æƒé‡ wiï¼Œk çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2(a)[316] shows a scatter plot of the SIZE and RENTAL PRICE descriptive features from the office rentals dataset and a number of different simple linear regression models that might be used to capture this relationship.",
            "zh": "å›¾7.2ï¼ˆaï¼‰[316]æ˜¾ç¤ºäº†æ¥è‡ªåŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„SIZEå’ŒRENTAL PRICEæè¿°æ€§ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼Œä»¥åŠå¯ç”¨äºæ•è·è¿™ç§å…³ç³»çš„è®¸å¤šä¸åŒçš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPMAGERR_U/G/R/I/Z",
            "zh": "EXPMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "dendrogram, 622",
            "zh": "æ ‘çŠ¶å›¾ï¼Œ622"
        }
    },
    {
        "translation": {
            "en": "8. Advanced features of Blackjack, like doubling down, insurance, and splitting pairs, are not allowed in our TwentyTwos game.",
            "zh": "8. äºŒåä¸€ç‚¹çš„é«˜çº§åŠŸèƒ½ï¼Œå¦‚åŠ å€ã€ä¿é™©å’Œæ‹†åˆ†å¯¹å­ï¼Œåœ¨æˆ‘ä»¬çš„ TwentyTwos æ¸¸æˆä¸­æ˜¯ä¸å…è®¸çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.14",
            "zh": "å›¾ 5.14"
        }
    },
    {
        "translation": {
            "en": "The effect of these negative weights is apparent in the Z(1) matrix in forward pass of the mini-batch through the ReLU network in Figure 8.18[440]: for all four examples of the mini-batch z 4 < 0, and hence a4 = 0.",
            "zh": "è¿™äº›è´Ÿæƒé‡çš„å½±å“åœ¨å›¾ 8.18[440] ä¸­å°æ‰¹é‡é€šè¿‡ ReLU ç½‘ç»œçš„å‰å‘ä¼ é€’çš„ Zï¼ˆ1ï¼‰ çŸ©é˜µä¸­å¾ˆæ˜æ˜¾ï¼šå¯¹äºå°æ‰¹é‡çš„æ‰€æœ‰å››ä¸ªç¤ºä¾‹ï¼Œz 4 < 0ï¼Œå› æ­¤ a4 = 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "32. A violin plot is a box plot that has been augmented to show the probability density of a data at different values in the range. The use of violin plots to illustrate the variance across layers within a network was inspired by a blog post by Daniel Godoy (see https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404).",
            "zh": "32. å°æç´å›¾æ˜¯ä¸€ç§ç®±å½¢å›¾ï¼Œç»è¿‡æ‰©å……ä»¥æ˜¾ç¤ºèŒƒå›´å†…ä¸åŒå€¼çš„æ•°æ®çš„æ¦‚ç‡å¯†åº¦ã€‚ä½¿ç”¨å°æç´å›¾æ¥è¯´æ˜ç½‘ç»œå†…å„å±‚ä¹‹é—´çš„å·®å¼‚çš„çµæ„Ÿæ¥è‡ªä¸¹å°¼å°”Â·æˆˆå¤šä¼Šï¼ˆDaniel Godoyï¼‰çš„ä¸€ç¯‡åšå®¢æ–‡ç« ï¼ˆè§ https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "return, 640",
            "zh": "å›ç¨‹ï¼Œ 640"
        }
    },
    {
        "translation": {
            "en": "Second, Figure 8.24(d)[454] shows that the network now has an exploding gradient dynamic during backpropagation, with the variance of Î´ values rapidly increasing as they are backpropagated through the network.",
            "zh": "å…¶æ¬¡ï¼Œå›¾8.24ï¼ˆdï¼‰[454]æ˜¾ç¤ºï¼Œç½‘ç»œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å…·æœ‰çˆ†ç‚¸æ€§çš„æ¢¯åº¦åŠ¨æ€ï¼ŒÎ´å€¼çš„æ–¹å·®éšç€å®ƒä»¬é€šè¿‡ç½‘ç»œçš„åå‘ä¼ æ’­è€Œè¿…é€Ÿå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38[504] provides a graphical representation of a recurrent neural network unrolled through three time-steps.48 The subscripts on the x, h, and y layer labels indicate that these layers have a different state at each time-step.",
            "zh": "å›¾ 8.38[504] æä¾›äº†é€šè¿‡ä¸‰ä¸ªæ—¶é—´æ­¥é•¿å±•å¼€çš„å¾ªç¯ç¥ç»ç½‘ç»œçš„å›¾å½¢è¡¨ç¤º.48 xã€h å’Œ y å±‚æ ‡ç­¾ä¸Šçš„ä¸‹æ ‡è¡¨ç¤ºè¿™äº›å±‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿å…·æœ‰ä¸åŒçš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.3â€ƒHandling Categorical Target Features: Softmax Output Layers and Cross-Entropy Loss Functions",
            "zh": "8.4.3 å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼šSoftmax è¾“å‡ºå±‚å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "Once the Î´s for the output neurons have been calculated, the backpropagation of the Î´s through the network and the updating of the weights progresses as in the previous examples. For example, to update weight w9,6 we would first calculate Î”w9,6 using Equation (8.29)[416]. Equation (8.82)[472] shows this calculation with the per example Î´s for neuron 9 taken from Table 8.15[471], and the activations for Neuron 6 are from Figure 8.28[470]",
            "zh": "ä¸€æ—¦è®¡ç®—å‡ºè¾“å‡ºç¥ç»å…ƒçš„ Î´ï¼ŒÎ´ åœ¨ç½‘ç»œä¸­çš„åå‘ä¼ æ’­å’Œæƒé‡çš„æ›´æ–°å°±ä¼šåƒå‰é¢çš„ä¾‹å­ä¸€æ ·è¿›è¡Œã€‚ä¾‹å¦‚ï¼Œä¸ºäº†æ›´æ–°æƒé‡w9,6ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨å…¬å¼ï¼ˆ8.29ï¼‰[416]è®¡ç®—Î”w9,6ã€‚æ–¹ç¨‹ï¼ˆ8.82ï¼‰[472]æ˜¾ç¤ºäº†è¯¥è®¡ç®—ï¼Œæ¯ä¸ªç¤ºä¾‹ä¸­ç¥ç»å…ƒ9çš„Î´så–è‡ªè¡¨8.15[471]ï¼Œç¥ç»å…ƒ6çš„æ¿€æ´»æ¥è‡ªå›¾8.28[470]"
        }
    },
    {
        "translation": {
            "en": "Second, the magnitudes of the weights show how much the value of the target feature changes for a unit change in the value of a particular descriptive feature.",
            "zh": "å…¶æ¬¡ï¼Œæƒé‡çš„å¤§å°æ˜¾ç¤ºç›®æ ‡ç‰¹å¾çš„å€¼éšç€ç‰¹å®šæè¿°æ€§ç‰¹å¾å€¼çš„å•ä½å˜åŒ–è€Œå˜åŒ–çš„ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is a simple one-level decision tree composed of a root note that performs one split on the basis of TEMPERATURE (because TEMPERATURE is a continuous target, the process for training regression trees described in Section 4.4.3[149] is used).",
            "zh": "è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å•çº§å†³ç­–æ ‘ï¼Œç”±ä¸€ä¸ªæ ¹æ³¨é‡Šç»„æˆï¼Œè¯¥æ ¹æ³¨é‡ŠåŸºäº TEMPERATURE æ‰§è¡Œä¸€æ¬¡æ‹†åˆ†ï¼ˆå› ä¸º TEMPERATURE æ˜¯ä¸€ä¸ªè¿ç»­ç›®æ ‡ï¼Œæ‰€ä»¥ä½¿ç”¨äº†ç¬¬ 4.4.3 èŠ‚[149]ä¸­æè¿°çš„è®­ç»ƒå›å½’æ ‘çš„è¿‡ç¨‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The architecture of the neural network used in the weight initialization experiments. Note that the neurons in this network use a linear activation function: ai = zi.",
            "zh": "æƒé‡åˆå§‹åŒ–å®éªŒä¸­ä½¿ç”¨çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚è¯·æ³¨æ„ï¼Œè¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼šai = ziã€‚"
        }
    },
    {
        "translation": {
            "en": "The font sizes of the correlation coefficients are scaled according to the absolute value of the strength of the correlation to draw attention to those pairs of features with the strongest relationships.",
            "zh": "ç›¸å…³ç³»æ•°çš„å­—ä½“å¤§å°æ ¹æ®ç›¸å…³æ€§å¼ºåº¦çš„ç»å¯¹å€¼è¿›è¡Œç¼©æ”¾ï¼Œä»¥å¼•èµ·äººä»¬å¯¹å…³ç³»æœ€å¼ºçš„ç‰¹å¾å¯¹çš„æ³¨æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "TPProfit represents the profit arising from a correct positive prediction, FNProfit is the profit arising from an incorrect negative prediction, and so on (note that profit can refer to a positive or a negative value).",
            "zh": "TPProfit è¡¨ç¤ºæ­£ç¡®çš„æ­£é¢„æµ‹äº§ç”Ÿçš„åˆ©æ¶¦ï¼ŒFNProfit è¡¨ç¤ºä¸æ­£ç¡®çš„è´Ÿé¢„æµ‹äº§ç”Ÿçš„åˆ©æ¶¦ï¼Œä¾æ­¤ç±»æ¨ï¼ˆè¯·æ³¨æ„ï¼Œåˆ©æ¶¦å¯ä»¥æŒ‡æ­£å€¼æˆ–è´Ÿå€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given the dataset in Table B.2[760], the probability of a patient having a headache is",
            "zh": "ç»™å®šè¡¨B.2[760]ä¸­çš„æ•°æ®é›†ï¼Œæ‚£è€…å¤´ç—›çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "The target feature, STATUS, reports the current situation at the plant: ok, everything is working correctly; settler, there is a problem with the plant settler equipment; or solids, there is a problem with the amount of solids going through the plant.",
            "zh": "ç›®æ ‡åŠŸèƒ½ STATUS æŠ¥å‘Šå·¥å‚çš„å½“å‰æƒ…å†µï¼šæ­£å¸¸ï¼Œä¸€åˆ‡æ­£å¸¸;å®šå±…è€…ï¼Œæ¤ç‰©å®šå±…è€…è®¾å¤‡æœ‰é—®é¢˜;æˆ–å›ºä½“ï¼Œé€šè¿‡å·¥å‚çš„å›ºä½“é‡å­˜åœ¨é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.4â€…â€…â€…Inductive Bias Versus Sample Bias",
            "zh": "1.4 ç”µæ„Ÿåå·®ä¸æ ·æœ¬åå·®"
        }
    },
    {
        "translation": {
            "en": "This is something we need to control for when we are creating a model, as otherwise we are allowing an unwanted bias to affect the learning process.",
            "zh": "è¿™æ˜¯æˆ‘ä»¬åœ¨åˆ›å»ºæ¨¡å‹æ—¶éœ€è¦æ§åˆ¶çš„äº‹æƒ…ï¼Œå¦åˆ™æˆ‘ä»¬å°±ä¼šå…è®¸ä¸å¿…è¦çš„åè§å½±å“å­¦ä¹ è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is evidence of just how well the model is performing.",
            "zh": "è¿™è¯æ˜äº†è¯¥æ¨¡å‹çš„æ€§èƒ½æœ‰å¤šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is striking, however, that the Euclidean distance between d12 and d17 is 8.25, which is greater than the Euclidean distance between d12 and d5, which is just 5.48.",
            "zh": "ç„¶è€Œï¼Œä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œd12 å’Œ d17 ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»ä¸º 8.25ï¼Œå¤§äº d12 å’Œ d5 ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œåè€…ä»…ä¸º 5.48ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although it is possible to calculate this point directly for some simpler problems, this approach is not computationally feasible for most interesting predictive analytics problems.",
            "zh": "å°½ç®¡å¯¹äºä¸€äº›è¾ƒç®€å•çš„é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥è®¡ç®—è¿™ä¸€ç‚¹ï¼Œä½†å¯¹äºå¤§å¤šæ•°æœ‰è¶£çš„é¢„æµ‹åˆ†æé—®é¢˜ï¼Œè¿™ç§æ–¹æ³•åœ¨è®¡ç®—ä¸Šæ˜¯ä¸å¯è¡Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "t-test, 333",
            "zh": "t æ£€éªŒï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "(a) What target level would a nearest neighbor model using Euclidean distance return for the following email: â€œmachine learning for freeâ€?",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„æœ€è¿‘é‚»æ¨¡å‹ä¼šä¸ºä»¥ä¸‹ç”µå­é‚®ä»¶è¿”å›ä»€ä¹ˆç›®æ ‡æ°´å¹³ï¼šâ€œå…è´¹æœºå™¨å­¦ä¹ â€ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "8.5â€…â€…â€…An illustration of the correspondence between graphical and matrix representations of a neural network.",
            "zh": "8.5 ç¥ç»ç½‘ç»œçš„å›¾å½¢å’ŒçŸ©é˜µè¡¨ç¤ºä¹‹é—´çš„å¯¹åº”å…³ç³»çš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.5â€…â€…â€…Performance Measures: Continuous Targets",
            "zh": "9.4.5 ç»©æ•ˆè¡¡é‡ï¼šæŒç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "(c) If average linkage were used with AHC instead of single linkage, which agglomerations would be made in the first three iterations of the algorithm?",
            "zh": "ï¼ˆcï¼‰ å¦‚æœå°†å¹³å‡é“¾æ¥ä¸AHCä¸€èµ·ä½¿ç”¨ï¼Œè€Œä¸æ˜¯å•æ¬¡é“¾æ¥ï¼Œåˆ™åœ¨ç®—æ³•çš„å‰ä¸‰æ¬¡è¿­ä»£ä¸­å°†è¿›è¡Œå“ªäº›é›†èšï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The dataset has three binary descriptive features: SUSPICIOUS WORDS is true if an email contains one or more words that are typically found in spam email (e.g., casino, viagra, bank, or account); UNKNOWN SENDER is true if the email is from an address that is not listed in the contacts of the person who received the email; and CONTAINS IMAGES is true if the email contains one or more images.",
            "zh": "è¯¥æ•°æ®é›†å…·æœ‰ä¸‰ä¸ªäºŒè¿›åˆ¶æè¿°æ€§ç‰¹å¾ï¼šå¦‚æœç”µå­é‚®ä»¶åŒ…å«åƒåœ¾é‚®ä»¶ä¸­å¸¸è§çš„ä¸€ä¸ªæˆ–å¤šä¸ªå•è¯ï¼ˆä¾‹å¦‚ï¼ŒèµŒåœºã€ä¼Ÿå“¥ã€é“¶è¡Œæˆ–è´¦æˆ·ï¼‰ï¼Œåˆ™ SUSPICIOUS WORDS ä¸ºçœŸ;å¦‚æœç”µå­é‚®ä»¶æ¥è‡ªæœªåœ¨æ¥æ”¶ç”µå­é‚®ä»¶çš„äººçš„è”ç³»äººä¸­åˆ—å‡ºçš„åœ°å€ï¼Œåˆ™ UNKNOWN SENDER ä¸º true;å¦‚æœç”µå­é‚®ä»¶åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå›¾åƒï¼Œåˆ™ CONTAINS IMAGES ä¸º trueã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms automate the process of learning a model that captures the relationship between the descriptive features and the target feature in a dataset. For simple datasets like the one presented in Table 1.1[6], we may be able to manually create a prediction model; in an example of this scale, machine learning has little to offer us.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•å¯è‡ªåŠ¨æ‰§è¡Œå­¦ä¹ æ¨¡å‹çš„è¿‡ç¨‹ï¼Œè¯¥æ¨¡å‹æ•è·æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚å¯¹äºè¡¨1.1[6]ä¸­æ‰€ç¤ºçš„ç®€å•æ•°æ®é›†ï¼Œæˆ‘ä»¬ä¹Ÿè®¸å¯ä»¥æ‰‹åŠ¨åˆ›å»ºé¢„æµ‹æ¨¡å‹;åœ¨è¿™ç§è§„æ¨¡çš„ä¾‹å­ä¸­ï¼Œæœºå™¨å­¦ä¹ å‡ ä¹æ²¡æœ‰ä¸ºæˆ‘ä»¬æä¾›ä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The outputs of the second model for the same test dataset are shown in the table below.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†åŒä¸€æµ‹è¯•æ•°æ®é›†çš„ç¬¬äºŒä¸ªæ¨¡å‹çš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "under-sampled training set, 720",
            "zh": "æ¬ é‡‡æ ·è®­ç»ƒé›†ï¼Œ720"
        }
    },
    {
        "translation": {
            "en": "The top layer of neurons share the weights in Filter 3, and the bottom layer share the weights in Filter 4.",
            "zh": "é¡¶å±‚ç¥ç»å…ƒå…±äº«è¿‡æ»¤å™¨ 3 ä¸­çš„æƒé‡ï¼Œåº•å±‚å…±äº«è¿‡æ»¤å™¨ 4 ä¸­çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS both come from d460 in Table 3.2[56].",
            "zh": "CLAIMSå‡æ¥è‡ªè¡¨3.2ä¸­çš„d460[56]ã€‚"
        }
    },
    {
        "translation": {
            "en": "One way to understand why depth is important to the representational capacity of a neural network is to consider what types of functions a network that has only a single layer of processing neurons, such as the one shown in Figure 8.7[397], is capable of representing.",
            "zh": "ç†è§£ä¸ºä»€ä¹ˆæ·±åº¦å¯¹ç¥ç»ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›å¾ˆé‡è¦çš„ä¸€ç§æ–¹æ³•æ˜¯è€ƒè™‘åªæœ‰ä¸€å±‚å¤„ç†ç¥ç»å…ƒçš„ç½‘ç»œèƒ½å¤Ÿè¡¨ç¤ºå“ªäº›ç±»å‹çš„åŠŸèƒ½ï¼Œä¾‹å¦‚å›¾ 8.7[397] æ‰€ç¤ºçš„ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "The cluster centroids are then updated to the average value of the descriptive features of the members of a cluster.",
            "zh": "ç„¶åï¼Œå°†èšç±»è´¨å¿ƒæ›´æ–°ä¸ºèšç±»æˆå‘˜çš„æè¿°æ€§ç‰¹å¾çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Preface",
            "zh": "å‰è¨€"
        }
    },
    {
        "translation": {
            "en": "3.6â€…â€…â€…The data quality plan with potential handling strategies for the motor insurance fraud prediction ABT.",
            "zh": "3.6 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹ABTçš„æ•°æ®è´¨é‡è®¡åˆ’ï¼Œä»¥åŠæ½œåœ¨çš„å¤„ç†ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can be an attractive alternative to the manual work of designing features that we described in Chapter 2[23].",
            "zh": "å¯¹äºæˆ‘ä»¬åœ¨ç¬¬ 2 ç« [23]ä¸­æè¿°çš„æ‰‹åŠ¨è®¾è®¡åŠŸèƒ½çš„å·¥ä½œï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset lists six instances in which prisoners were granted parole.",
            "zh": "è¯¥æ•°æ®é›†åˆ—å‡ºäº†å›šçŠ¯è·å¾—å‡é‡Šçš„å…­ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In 1949 Donald O. Hebb proposed a theory that attempted to explain how general human behavior emerged from the physiology of the brain.",
            "zh": "1949å¹´ï¼Œå”çº³å¾·Â·èµ«å¸ƒï¼ˆDonald O. Hebbï¼‰æå‡ºäº†ä¸€ä¸ªç†è®ºï¼Œè¯•å›¾è§£é‡Šä¸€èˆ¬äººç±»è¡Œä¸ºæ˜¯å¦‚ä½•ä»å¤§è„‘çš„ç”Ÿç†å­¦ä¸­äº§ç”Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.11",
            "zh": "å›¾ 3.11"
        }
    },
    {
        "translation": {
            "en": "Figure 8.24",
            "zh": "å›¾ 8.24"
        }
    },
    {
        "translation": {
            "en": "Table 13.8",
            "zh": "è¡¨ 13.8"
        }
    },
    {
        "translation": {
            "en": "(f) 12th percentile",
            "zh": "ï¼ˆfï¼‰ ç¬¬12ä¸ªç™¾åˆ†ä½"
        }
    },
    {
        "translation": {
            "en": "absolute rarity, 720",
            "zh": "ç»å¯¹ç¨€æœ‰ï¼Œ720"
        }
    },
    {
        "translation": {
            "en": "For the examples in this section, we introduce a new dataset. Table 3.7[73] shows the details of 30 players on a professional basketball team. The dataset includes the HEIGHT, WEIGHT, and AGE of each player; the POSITION that the player normally plays (guard, center, or forward); the CAREER STAGE of the player (rookie, mid-career, or veteran); the average weekly SPONSORSHIP EARNINGS of each player; and whether the player has a SHOE SPONSOR (yes or no).",
            "zh": "å¯¹äºæœ¬èŠ‚ä¸­çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€ä¸ªæ–°çš„æ•°æ®é›†ã€‚è¡¨3.7[73]æ˜¾ç¤ºäº†ä¸€æ”¯èŒä¸šç¯®çƒé˜Ÿä¸­30åçƒå‘˜çš„è¯¦ç»†ä¿¡æ¯ã€‚æ•°æ®é›†åŒ…æ‹¬æ¯ä¸ªçƒå‘˜çš„èº«é«˜ã€ä½“é‡å’Œå¹´é¾„;çƒå‘˜é€šå¸¸è¸¢çš„ä½ç½®ï¼ˆåå«ã€ä¸­é”‹æˆ–å‰é”‹ï¼‰;çƒå‘˜çš„èŒä¸šç”Ÿæ¶¯é˜¶æ®µï¼ˆæ–°ç§€ã€èŒä¸šç”Ÿæ¶¯ä¸­æœŸæˆ–è€å°†ï¼‰;æ¯ä¸ªçƒå‘˜çš„å¹³å‡æ¯å‘¨èµåŠ©æ”¶å…¥;ä»¥åŠçƒå‘˜æ˜¯å¦æœ‰é‹å­èµåŠ©å•†ï¼ˆæ˜¯æˆ–å¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first two items in this list focus on measuring and comparing the performance of a group of models to determine which model best performs the prediction task that the models have been built to address.",
            "zh": "æ­¤åˆ—è¡¨ä¸­çš„å‰ä¸¤é¡¹ä¾§é‡äºæµ‹é‡å’Œæ¯”è¾ƒä¸€ç»„æ¨¡å‹çš„æ€§èƒ½ï¼Œä»¥ç¡®å®šå“ªä¸ªæ¨¡å‹æœ€èƒ½æ‰§è¡Œæ¨¡å‹æ„å»ºè¦è§£å†³çš„é¢„æµ‹ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Until recently, one of the most popular functions used in artificial neurons was the logistic function introduced in Chapter 7 (see Equation (7.25)[342] and Figure 7.12[343]).",
            "zh": "ç›´åˆ°æœ€è¿‘ï¼Œäººå·¥ç¥ç»å…ƒä¸­ä½¿ç”¨çš„æœ€æµè¡Œçš„åŠŸèƒ½ä¹‹ä¸€æ˜¯ç¬¬7ç« ä¸­ä»‹ç»çš„é€»è¾‘å‡½æ•°ï¼ˆå‚è§å…¬å¼ï¼ˆ7.25ï¼‰[342]å’Œå›¾7.12[343]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also suggested that a third other category be included to take into account the fact that all the sky objects labeled as galaxies in the previous step in the SDSS may not actually be galaxies.",
            "zh": "Jocelynè¿˜å»ºè®®åŒ…æ‹¬ç¬¬ä¸‰ä¸ªå…¶ä»–ç±»åˆ«ï¼Œä»¥è€ƒè™‘åˆ°åœ¨SDSSçš„ä¸Šä¸€æ­¥ä¸­æ ‡è®°ä¸ºæ˜Ÿç³»çš„æ‰€æœ‰å¤©ç©ºç‰©ä½“å®é™…ä¸Šå¯èƒ½ä¸æ˜¯æ˜Ÿç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "chessboard distance, 186",
            "zh": "æ£‹ç›˜è·ç¦»ï¼Œ186"
        }
    },
    {
        "translation": {
            "en": "A scatter plot is based on two axes: the horizontal axis represents one feature, and the vertical axis represents a second.",
            "zh": "æ•£ç‚¹å›¾åŸºäºä¸¤ä¸ªè½´ï¼šæ°´å¹³è½´è¡¨ç¤ºä¸€ä¸ªè¦ç´ ï¼Œå‚ç›´è½´è¡¨ç¤ºç¬¬äºŒä¸ªè¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we used a horizontal and vertical stride of 3 in Figure 8.33[484], then there would be no overlap between the receptive fields of different neurons, and this would also reduce the number of neurons required to cover the input.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨å›¾8.33[484]ä¸­ä½¿ç”¨3çš„æ°´å¹³å’Œå‚ç›´æ­¥å¹…ï¼Œé‚£ä¹ˆä¸åŒç¥ç»å…ƒçš„æ„Ÿå—é‡ä¹‹é—´å°±ä¸ä¼šæœ‰é‡å ï¼Œè¿™ä¹Ÿå°†å‡å°‘è¦†ç›–è¾“å…¥æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 12.2[695] presents the histograms for these features.",
            "zh": "å›¾12.2[695]æ˜¾ç¤ºäº†è¿™äº›ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.2â€…â€…â€…The structure of a confusion matrix.",
            "zh": "9.2 æ··æ·†çŸ©é˜µçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.7(a)[128], we can see that splitting the dataset based on the SUSPICIOUS WORDS feature provides a lot of information about whether an email is spam or ham.",
            "zh": "åœ¨å›¾4.7ï¼ˆaï¼‰[128]ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒåŸºäºå¯ç–‘è¯ç‰¹å¾æ‹†åˆ†æ•°æ®é›†å¯ä»¥æä¾›å¤§é‡æœ‰å…³ç”µå­é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯ç«è…¿çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The diagnoses made by predictive analytics models usually become an input into the professionalâ€™s existing diagnosis process.",
            "zh": "é¢„æµ‹åˆ†ææ¨¡å‹åšå‡ºçš„è¯Šæ–­é€šå¸¸æˆä¸ºä¸“ä¸šäººå‘˜ç°æœ‰è¯Šæ–­è¿‡ç¨‹çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of the nearest neighbor approach to prediction is that it is relatively straightforward to update the model when new labeled instances become availableâ€”we simply add them to the training dataset.",
            "zh": "æœ€è¿‘é‚»é¢„æµ‹æ–¹æ³•çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯ï¼Œå½“æ–°çš„æ ‡è®°å®ä¾‹å¯ç”¨æ—¶ï¼Œæ›´æ–°æ¨¡å‹ç›¸å¯¹ç®€å• - æˆ‘ä»¬åªéœ€å°†å®ƒä»¬æ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ä¸­å³å¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we use dropout, each time we load a training example we choose a random set of neurons from the input and hidden layers and drop (or delete) them from the network for that training instance.",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨ dropout æ—¶ï¼Œæ¯æ¬¡åŠ è½½è®­ç»ƒç¤ºä¾‹æ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šä»è¾“å…¥å±‚å’Œéšè—å±‚ä¸­éšæœºé€‰æ‹©ä¸€ç»„ç¥ç»å…ƒï¼Œå¹¶å°†å®ƒä»¬ä»è¯¥è®­ç»ƒå®ä¾‹çš„ç½‘ç»œä¸­åˆ é™¤ï¼ˆæˆ–åˆ é™¤ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the lift at decile dec is the ratio between the percentage of positive instances in that decile and the percentage of positive instances overall in the population:",
            "zh": "å› æ­¤ï¼Œååˆ†ä½æ•° dec çš„æå‡æ˜¯è¯¥ååˆ†ä½æ•°ä¸­é˜³æ€§å®ä¾‹çš„ç™¾åˆ†æ¯”ä¸æ€»ä½“ä¸­é˜³æ€§å®ä¾‹çš„ç™¾åˆ†æ¯”ä¹‹é—´çš„æ¯”ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "Second, riparian vegetation occurs near streams and is characterized by trees and shrubs.",
            "zh": "å…¶æ¬¡ï¼Œæ²³å²¸æ¤è¢«å‡ºç°åœ¨æºªæµé™„è¿‘ï¼Œä»¥æ ‘æœ¨å’ŒçŒæœ¨ä¸ºç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "alert",
            "zh": "è­¦æŠ¥"
        }
    },
    {
        "translation": {
            "en": "The results of each of the max pooling layers are then stacked together to create a multi-channel input for the second layer.",
            "zh": "ç„¶åï¼Œå°†æ¯ä¸ªæœ€å¤§æ± åŒ–å±‚çš„ç»“æœå †å åœ¨ä¸€èµ·ï¼Œä¸ºç¬¬äºŒå±‚åˆ›å»ºå¤šé€šé“è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.1â€…â€…â€…A dataset that includes office rental prices and a number of descriptive features for 10 Dublin city-center offices.",
            "zh": "7.1 ä¸€ä¸ªæ•°æ®é›†ï¼ŒåŒ…æ‹¬éƒ½æŸæ—å¸‚ä¸­å¿ƒ 10 ä¸ªåŠå…¬å®¤çš„åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼å’Œä¸€äº›æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence, we can expect our 730-square-foot office to rent for about 460 Euro per month. This kind of model is known as a simple linear regression model. This approach to modeling the relationships between features is extremely common in both machine learning and statistics.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸæˆ‘ä»¬ 730 å¹³æ–¹è‹±å°ºçš„åŠå…¬å®¤æ¯æœˆç§Ÿé‡‘çº¦ä¸º 460 æ¬§å…ƒã€‚è¿™ç§æ¨¡å‹ç§°ä¸ºç®€å•çº¿æ€§å›å½’æ¨¡å‹ã€‚è¿™ç§å¯¹ç‰¹å¾ä¹‹é—´å…³ç³»è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ å’Œç»Ÿè®¡å­¦ä¸­éƒ½éå¸¸å¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are three categorical descriptive features in this dataset.",
            "zh": "æ­¤æ•°æ®é›†ä¸­æœ‰ä¸‰ä¸ªåˆ†ç±»æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A schematic of an artificial neuron.",
            "zh": "äººå·¥ç¥ç»å…ƒçš„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When checking this against Figure 8.23(b)[453], note that a variance of Ïƒ2 = 0.0002 is equivalent to a standard deviation of Ïƒ â‰ˆ 0.014.",
            "zh": "å½“ä¸å›¾ 8.23ï¼ˆbï¼‰[453] è¿›è¡Œæ ¸å¯¹æ—¶ï¼Œè¯·æ³¨æ„ Ïƒ2 = 0.0002 çš„æ–¹å·®ç›¸å½“äº Ïƒ â‰ˆ 0.014 çš„æ ‡å‡†å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the purposes of illustration, imagine that we are using this filter to process the following 3-by-3 RGB image (the pixel values here are not real; they have been selected to ease the calculations in the example):",
            "zh": "ä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œå‡è®¾æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨æ­¤è¿‡æ»¤å™¨æ¥å¤„ç†ä»¥ä¸‹ 3Ã—3 RGB å›¾åƒï¼ˆæ­¤å¤„çš„åƒç´ å€¼ä¸æ˜¯çœŸå®çš„;é€‰æ‹©å®ƒä»¬æ˜¯ä¸ºäº†ç®€åŒ–ç¤ºä¾‹ä¸­çš„è®¡ç®—ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "2.1â€…â€…â€…The different data sources typically combined to create an analytics base table.",
            "zh": "2.1 ä¸åŒçš„æ•°æ®æºé€šå¸¸ç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºåˆ†æåŸºè¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.3[32] shows some domain concepts that are likely to be useful in this case.",
            "zh": "å›¾2.3[32]æ˜¾ç¤ºäº†ä¸€äº›åœ¨è¿™ç§æƒ…å†µä¸‹å¯èƒ½æœ‰ç”¨çš„é¢†åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "Mingers, John. 1989. An empirical comparison of selection measures for decision-tree induction. Machine Learning 3 (4): 319â€“342.",
            "zh": "æ˜æ ¼æ–¯ï¼Œçº¦ç¿°ã€‚1989. å†³ç­–æ ‘å½’çº³é€‰æ‹©æªæ–½çš„å®è¯æ¯”è¾ƒ.æœºå™¨å­¦ä¹  3 ï¼ˆ4ï¼‰ï¼š319â€“342ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if all the descriptive features are conditionally independent given the target feature, we can factorize the joint distribution and represent it using just 19 probabilities (one for the prior of the target and two conditional probabilities for each descriptive feature).",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœç»™å®šç›®æ ‡ç‰¹å¾ï¼Œæ‰€æœ‰æè¿°æ€§ç‰¹å¾åœ¨æ¡ä»¶ä¸Šéƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†è§£è”åˆåˆ†å¸ƒå¹¶ä»…ä½¿ç”¨ 19 ä¸ªæ¦‚ç‡ï¼ˆä¸€ä¸ªç”¨äºç›®æ ‡çš„å…ˆéªŒï¼Œä¸¤ä¸ªæ¡ä»¶æ¦‚ç‡ç”¨äºæ¯ä¸ªæè¿°æ€§ç‰¹å¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, we also recommend Goldberg (2017) for an accessible introduction to the use of deep learning for natural language processing and Reagen et al.",
            "zh": "æœ€åï¼Œæˆ‘ä»¬è¿˜æ¨èGoldbergï¼ˆ2017ï¼‰å¯¹ä½¿ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†å’ŒReagenç­‰äººçš„é€šä¿—æ˜“æ‡‚çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to begin her data exploration work by focusing on the target feature. The structure of the data available from the Galaxy Zoo project is shown in Table 13.1[709]. The category of each galaxy is voted on by multiple Galaxy Zoo participants, and the data includes the fraction of these votes for each of the categories.",
            "zh": "Jocelyn å†³å®šé€šè¿‡ä¸“æ³¨äºç›®æ ‡ç‰¹å¾æ¥å¼€å§‹å¥¹çš„æ•°æ®æ¢ç´¢å·¥ä½œã€‚Galaxy Zooé¡¹ç›®æä¾›çš„æ•°æ®ç»“æ„å¦‚è¡¨13.1[709]æ‰€ç¤ºã€‚æ¯ä¸ªæ˜Ÿç³»çš„ç±»åˆ«ç”±å¤šä¸ªé“¶æ²³åŠ¨ç‰©å›­å‚ä¸è€…æŠ•ç¥¨é€‰å‡ºï¼Œæ•°æ®åŒ…æ‹¬æ¯ä¸ªç±»åˆ«çš„è¿™äº›æŠ•ç¥¨çš„æ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mingers, John. 1987. Expert systems - rule induction with statistical data. Journal of the Operational Research Society 38: 39â€“47.",
            "zh": "æ˜æ ¼æ–¯ï¼Œçº¦ç¿°ã€‚1987. ä¸“å®¶ç³»ç»Ÿ - ç»Ÿè®¡æ•°æ®çš„è§„åˆ™å½’çº³ã€‚è¿ç­¹å­¦å­¦ä¼šæ‚å¿—38ï¼š39-47ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even more dramatically, he reports that he actually interfered with the second experiment by removing the prism from the apparatus during the demonstration (because the experiment was completed in darkness, Wood was able to do this without anybody noticing), which made no difference to the results that you measured and reported, so it completely undermines them.",
            "zh": "æ›´æˆå‰§æ€§çš„æ˜¯ï¼Œä»–æŠ¥å‘Šè¯´ï¼Œä»–å®é™…ä¸Šå¹²æ‰°äº†ç¬¬äºŒä¸ªå®éªŒï¼Œåœ¨æ¼”ç¤ºè¿‡ç¨‹ä¸­ä»è®¾å¤‡ä¸Šå–ä¸‹äº†æ£±é•œï¼ˆå› ä¸ºå®éªŒæ˜¯åœ¨é»‘æš—ä¸­å®Œæˆçš„ï¼Œä¼å¾·èƒ½å¤Ÿåœ¨æ²¡æœ‰äººæ³¨æ„åˆ°çš„æƒ…å†µä¸‹åšåˆ°è¿™ä¸€ç‚¹ï¼‰ï¼Œè¿™å¯¹ä½ æµ‹é‡å’ŒæŠ¥å‘Šçš„ç»“æœæ²¡æœ‰å½±å“ï¼Œæ‰€ä»¥å®ƒå®Œå…¨ç ´åäº†å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the next action that the agent will take is selected using a greedy action selection policy, what action will the agent choose to take (Stick or Twist)?",
            "zh": "ï¼ˆbï¼‰ å‡è®¾ä½¿ç”¨è´ªå©ªè¡ŒåŠ¨é€‰æ‹©ç­–ç•¥é€‰æ‹©ä»£ç†å°†é‡‡å–çš„ä¸‹ä¸€ä¸ªè¡ŒåŠ¨ï¼Œä»£ç†å°†é€‰æ‹©é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼ˆåšæŒæˆ–æ‰­æ›²ï¼‰ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Valid outliers are correct values that are simply very different from the rest of the values for a feature, for example, a billionaire who has a massive salary compared to everyone else in a sample.",
            "zh": "æœ‰æ•ˆå¼‚å¸¸å€¼æ˜¯ä¸è¦ç´ çš„å…¶ä½™å€¼æœ‰å¾ˆå¤§å·®å¼‚çš„æ­£ç¡®å€¼ï¼Œä¾‹å¦‚ï¼Œä¸æ ·æœ¬ä¸­çš„å…¶ä»–äººç›¸æ¯”ï¼Œä¸€ä½äº¿ä¸‡å¯Œç¿çš„è–ªæ°´å¾ˆé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "A key step, then, in any data analytics project is to understand the business problem that the organization wants to solve and, based on this, to determine the kind of insight that a predictive analytics model can provide to help the organization address this problem. This defines the analytics solution that the analytics practitioner will set out to build using machine learning. Defining the analytics solution is the most important task in the Business Understanding phase of the CRISP-DM process.",
            "zh": "å› æ­¤ï¼Œåœ¨ä»»ä½•æ•°æ®åˆ†æé¡¹ç›®ä¸­ï¼Œä¸€ä¸ªå…³é”®æ­¥éª¤æ˜¯äº†è§£ç»„ç»‡æƒ³è¦è§£å†³çš„ä¸šåŠ¡é—®é¢˜ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šç¡®å®šé¢„æµ‹åˆ†ææ¨¡å‹å¯ä»¥æä¾›çš„æ´å¯ŸåŠ›ç±»å‹ï¼Œä»¥å¸®åŠ©ç»„ç»‡è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿™å®šä¹‰äº†åˆ†æä»ä¸šè€…å°†ç€æ‰‹ä½¿ç”¨æœºå™¨å­¦ä¹ æ„å»ºçš„åˆ†æè§£å†³æ–¹æ¡ˆã€‚å®šä¹‰åˆ†æè§£å†³æ–¹æ¡ˆæ˜¯ CRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£é˜¶æ®µæœ€é‡è¦çš„ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neapolitan (2004) is a good textbook on Bayesian networks.",
            "zh": "é‚£ä¸å‹’æ–¯ï¼ˆ2004ï¼‰æ˜¯ä¸€æœ¬å…³äºè´å¶æ–¯ç½‘ç»œçš„å¥½æ•™ç§‘ä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "As previously, the bias term is simply an extra weight that is multiplied by the dummy input value 1, and the result of this product is included in the weighted sum of the neuron.",
            "zh": "å¦‚å‰æ‰€è¿°ï¼Œåå·®é¡¹åªæ˜¯ä¸€ä¸ªé¢å¤–çš„æƒé‡ä¹˜ä»¥è™šæ‹Ÿè¾“å…¥å€¼ 1ï¼Œå¹¶ä¸”è¯¥ä¹˜ç§¯çš„ç»“æœåŒ…å«åœ¨ç¥ç»å…ƒçš„åŠ æƒå’Œä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Taleb, Nassim Nicholas. 2008. The black swan: The impact of the highly improbable. Penguin.",
            "zh": "å¡”å‹’å¸ƒï¼Œçº³è¥¿å§†Â·å°¼å¤æ‹‰æ–¯ã€‚2008. é»‘å¤©é¹…ï¼šæä¸å¯èƒ½çš„å½±å“ã€‚ä¼é¹…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weight can then be updated using the batch weight update rule (see Equation (8.30)[416]), where we assume a learning rate of Î± = 0.01, as shown in Equation (8.83)[472]",
            "zh": "ç„¶åå¯ä»¥ä½¿ç”¨æ‰¹é‡æƒé‡æ›´æ–°è§„åˆ™æ›´æ–°æƒé‡ï¼ˆå‚è§ç­‰å¼ï¼ˆ8.30ï¼‰[416]ï¼‰ï¼Œå…¶ä¸­æˆ‘ä»¬å‡è®¾å­¦ä¹ ç‡ä¸ºÎ± = 0.01ï¼Œå¦‚ç­‰å¼ï¼ˆ8.83ï¼‰[472]æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "We write t to indicate the one-hot encoding vector of a categorical target.",
            "zh": "æˆ‘ä»¬å†™ t æ¥è¡¨ç¤ºåˆ†ç±»ç›®æ ‡çš„å•çƒ­ç¼–ç å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for each of these 8 possible combinations of descriptive feature values, there are 3 possible target feature values, so this means that there are 38 = 6,561 possible prediction models that could be used.",
            "zh": "ä½†æ˜¯ï¼Œå¯¹äºè¿™ 8 ç§æè¿°æ€§ç‰¹å¾å€¼çš„å¯èƒ½ç»„åˆä¸­çš„æ¯ä¸€ç§ï¼Œéƒ½æœ‰ 3 ä¸ªå¯èƒ½çš„ç›®æ ‡ç‰¹å¾å€¼ï¼Œå› æ­¤è¿™æ„å‘³ç€å¯ä»¥ä½¿ç”¨ 38 = 6,561 ä¸ªå¯èƒ½çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For HL2 we know that and var(W(HL2)) = 0.0001, and so we can now calculate the variance of z across the neurons in layer HL2 as follows:",
            "zh": "å¯¹äº HL2ï¼Œæˆ‘ä»¬çŸ¥é“ å’Œ varï¼ˆWï¼ˆHL2ï¼‰ï¼‰ = 0.0001ï¼Œå› æ­¤æˆ‘ä»¬ç°åœ¨å¯ä»¥è®¡ç®— HL2 å±‚ä¸­ç¥ç»å…ƒçš„ z æ–¹å·®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 8.3",
            "zh": "å›¾ 8.3"
        }
    },
    {
        "translation": {
            "en": "Instances",
            "zh": "å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that naive Bayes models can be trained using a relatively small dataset: with so few parameters and so few conditions on each parameterâ€”only the state of the target featureâ€”it is possible to make reasonable estimates for the parameters using a small dataset.",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªç»“æœæ˜¯ï¼Œæœ´ç´ çš„è´å¶æ–¯æ¨¡å‹å¯ä»¥ä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼šç”±äºå‚æ•°å¦‚æ­¤ä¹‹å°‘ï¼Œæ¯ä¸ªå‚æ•°çš„æ¡ä»¶ä¹Ÿå¦‚æ­¤ä¹‹å°‘ï¼ˆåªæœ‰ç›®æ ‡ç‰¹å¾çš„çŠ¶æ€ï¼‰ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†å¯¹å‚æ•°è¿›è¡Œåˆç†çš„ä¼°è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "âˆ‚a/âˆ‚z",
            "zh": "âˆ‚a/âˆ‚z"
        }
    },
    {
        "translation": {
            "en": "Figure 5.17",
            "zh": "å›¾ 5.17"
        }
    },
    {
        "translation": {
            "en": "23. We provide references in Section 7.6[370].",
            "zh": "23. æˆ‘ä»¬åœ¨ç¬¬7.6èŠ‚[370]ä¸­æä¾›äº†å‚è€ƒèµ„æ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.3 presents a graphical representation of this same function.",
            "zh": "å›¾ 8.3 æ˜¾ç¤ºäº†åŒä¸€å‡½æ•°çš„å›¾å½¢è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "1. if ak, the activation from neuron k that the weight wi,k was applied to, is positive, we should decrease the weight wi,k. In this case âˆ‚â„°/âˆ‚wi,k = Î´i Ã— ak will be positive, because both terms in the product are positive, and so to decrease the weight wi,k we should subtract âˆ‚â„°/âˆ‚wi,k from wi,k.",
            "zh": "1. å¦‚æœ AKï¼Œå³æ–½åŠ æƒé‡ Wiï¼ŒK çš„ç¥ç»å…ƒ K çš„æ¿€æ´»æ˜¯æ­£çš„ï¼Œæˆ‘ä»¬åº”è¯¥é™ä½æƒé‡ Wiï¼ŒKã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œâˆ‚E/âˆ‚wiï¼Œk = Î´i Ã— ak å°†ä¸ºæ­£ï¼Œå› ä¸ºä¹˜ç§¯ä¸­çš„ä¸¤ä¸ªé¡¹éƒ½æ˜¯æ­£çš„ï¼Œå› æ­¤ä¸ºäº†é™ä½æƒé‡ wiï¼Œkï¼Œæˆ‘ä»¬åº”è¯¥ä» wiï¼Œk ä¸­å‡å» âˆ‚E/âˆ‚wiï¼Œkã€‚"
        }
    },
    {
        "translation": {
            "en": "AVGRECURRINGCHARGE",
            "zh": "AVGRECURRINGè´¹ç”¨"
        }
    },
    {
        "translation": {
            "en": "The values chosen for the learning rate and initial weights can have a significant impact on how the gradient descent algorithm proceeds. Unfortunately, there are no theoretical results that help in choosing the optimal values for these parameters. Instead, these algorithm parameters must be chosen using rules of thumb gathered through experience.",
            "zh": "ä¸ºå­¦ä¹ ç‡å’Œåˆå§‹æƒé‡é€‰æ‹©çš„å€¼å¯èƒ½ä¼šå¯¹æ¢¯åº¦ä¸‹é™ç®—æ³•çš„è¿›è¡Œæ–¹å¼äº§ç”Ÿé‡å¤§å½±å“ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæ²¡æœ‰ç†è®ºç»“æœæœ‰åŠ©äºé€‰æ‹©è¿™äº›å‚æ•°çš„æœ€ä½³å€¼ã€‚ç›¸åï¼Œè¿™äº›ç®—æ³•å‚æ•°å¿…é¡»ä½¿ç”¨é€šè¿‡ç»éªŒæ”¶é›†çš„ç»éªŒæ³•åˆ™æ¥é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subsequently in this chapter we introduce network architectures that are not feedforward and also architectures that are not fully connected.",
            "zh": "åœ¨æœ¬ç« çš„åç»­ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»éå‰é¦ˆç½‘ç»œæ¶æ„ä»¥åŠæœªå®Œå…¨è¿æ¥çš„æ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "weak learners, 165",
            "zh": "å¼±å­¦ä¹ è€…ï¼Œ165"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions.",
            "zh": "å…·æœ‰æ¨¡å‹é¢„æµ‹çš„ç¤ºä¾‹æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having covered how we backpropagate through branches, elementwise products, and elementwise additions in the forward pass, we are now able to backpropagate the error gradients through the LSTM.",
            "zh": "åœ¨ä»‹ç»äº†å¦‚ä½•åœ¨å‰å‘ä¼ é€’ä¸­é€šè¿‡åˆ†æ”¯ã€é€å…ƒä¹˜ç§¯å’Œé€å…ƒåŠ æ³•è¿›è¡Œåå‘ä¼ æ’­ä¹‹åï¼Œæˆ‘ä»¬ç°åœ¨èƒ½å¤Ÿé€šè¿‡ LSTM åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The query instance value for CONTAINS IMAGES is true so the process descends the left branch from the root node, labeled true, to an interior node that tests the SUSPICIOUS WORDS feature.",
            "zh": "CONTAINS IMAGES çš„æŸ¥è¯¢å®ä¾‹å€¼ä¸º trueï¼Œå› æ­¤è¯¥è¿›ç¨‹å°†å·¦ä¾§åˆ†æ”¯ä»æ ‡è®°ä¸º true çš„æ ¹èŠ‚ç‚¹ä¸‹é™åˆ°æµ‹è¯• SUSPICIOUS WORDS åŠŸèƒ½çš„å†…éƒ¨èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The error delta function invoked on Line 4[326] of Algorithm 4[326] performs this calculation to determine the delta value by which each weight should be adjusted.",
            "zh": "åœ¨ç®—æ³• 4[326] çš„ç¬¬ 4 è¡Œ [326] ä¸Šè°ƒç”¨çš„è¯¯å·® delta å‡½æ•°æ‰§è¡Œæ­¤è®¡ç®—ä»¥ç¡®å®šåº”è°ƒæ•´æ¯ä¸ªæƒé‡çš„ delta å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the leaf nodes specifies a predicted level of the target feature.",
            "zh": "æ¯ä¸ªå¶èŠ‚ç‚¹æŒ‡å®šç›®æ ‡è¦ç´ çš„é¢„æµ‹çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall is equivalent to true positive rate (TPR) (compare Equations (9.4)[548] and (9.9)[549]).",
            "zh": "å¬å›ç‡ç­‰åŒäºçœŸé˜³æ€§ç‡ï¼ˆTPRï¼‰ï¼ˆæ¯”è¾ƒå…¬å¼ï¼ˆ9.4ï¼‰[548]å’Œï¼ˆ9.9ï¼‰[549]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gaussian distribution, 61",
            "zh": "é«˜æ–¯åˆ†å¸ƒï¼Œ61"
        }
    },
    {
        "translation": {
            "en": "He dismisses the experimental setup for the experiments you demonstrated as entirely inappropriate.",
            "zh": "ä»–é©³å›äº†ä½ æ¼”ç¤ºçš„å®éªŒçš„å®éªŒè®¾ç½®ï¼Œè®¤ä¸ºè¿™æ˜¯å®Œå…¨ä¸åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that SLOPE is the only descriptive feature that is listed in 10 and 11.",
            "zh": "è¯·æ³¨æ„ï¼ŒSLOPE æ˜¯ 10 å’Œ 11 ä¸­åˆ—å‡ºçš„å”¯ä¸€æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6.3â€ƒMonitoring descriptive feature distribution changesâ€ƒIn the same way we can compare the distributions of model outputs between the time that the model was built and after deployment, we can also make the same type of comparison for the distributions of the descriptive features used by the model. We can use any appropriate measure that captures the difference between two different distributions for this, including the stability index, the Ï‡2 statistic, and the K-S statistic.",
            "zh": "9.4.6.3 ç›‘æµ‹æè¿°æ€§ç‰¹å¾åˆ†å¸ƒå˜åŒ– åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥æ¯”è¾ƒæ¨¡å‹ç”Ÿæˆå’Œéƒ¨ç½²åæ¨¡å‹è¾“å‡ºçš„åˆ†å¸ƒï¼Œä¹Ÿå¯ä»¥å¯¹æ¨¡å‹ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾çš„åˆ†å¸ƒè¿›è¡Œç›¸åŒç±»å‹çš„æ¯”è¾ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•é€‚å½“çš„åº¦é‡æ¥æ•è·ä¸¤ä¸ªä¸åŒåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼ŒåŒ…æ‹¬ç¨³å®šæ€§æŒ‡æ•°ã€Ï‡2 ç»Ÿè®¡é‡å’Œ K-S ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we compare, the three images, 14 bins seems to best model the data.",
            "zh": "å½“æˆ‘ä»¬æ¯”è¾ƒè¿™ä¸‰å¼ å›¾åƒæ—¶ï¼Œ14 ä¸ªç®±ä¼¼ä¹å¯ä»¥æœ€å¥½åœ°å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The choice is really a matter of convenience.",
            "zh": "é€‰æ‹©ç¡®å®æ˜¯ä¸€ä¸ªæ–¹ä¾¿çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3â€ƒStandard Approach: Backpropagation and Gradient Descent",
            "zh": "8.3 æ ‡å‡†æ–¹æ³•ï¼šåå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™"
        }
    },
    {
        "translation": {
            "en": "Figure 8.34[488] illustrates what happens if we pad the boundary of an image with imaginary pixels.",
            "zh": "å›¾8.34[488]è¯´æ˜äº†å¦‚æœæˆ‘ä»¬ç”¨å‡æƒ³åƒç´ å¡«å……å›¾åƒçš„è¾¹ç•Œä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Both the resulting sets contain a balanced mixture of spam and ham instances.",
            "zh": "ç”Ÿæˆçš„ä¸¤ä¸ªé›†åˆéƒ½åŒ…å«åƒåœ¾é‚®ä»¶å’Œç«è…¿å®ä¾‹çš„å¹³è¡¡ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "After removing a large number of the columns from the raw SDSS dataset, introducing a number of derived features, and generating two target features, Jocelyn generated an ABT containing 327 descriptive features and two target features. Table 13.3[715] lists these features (features that occur over all five photometric bands are listed as NAME_U/G/R/I/Z to save space).13",
            "zh": "ä»åŸå§‹ SDSS æ•°æ®é›†ä¸­åˆ é™¤å¤§é‡åˆ—ï¼Œå¼•å…¥å¤§é‡æ´¾ç”Ÿç‰¹å¾å¹¶ç”Ÿæˆä¸¤ä¸ªç›®æ ‡ç‰¹å¾åï¼ŒJocelyn ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å« 327 ä¸ªæè¿°æ€§ç‰¹å¾å’Œä¸¤ä¸ªç›®æ ‡ç‰¹å¾çš„ ABTã€‚è¡¨13.3[715]åˆ—å‡ºäº†è¿™äº›ç‰¹å¾ï¼ˆä¸ºäº†èŠ‚çœç©ºé—´ï¼Œåœ¨æ‰€æœ‰äº”ä¸ªå…‰åº¦æ³¢æ®µä¸Šå‡ºç°çš„ç‰¹å¾è¢«åˆ—ä¸ºNAME_U/G/R/I/Zï¼‰13ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, the details of each claim, the related policy, and the related claimant would need to be available.",
            "zh": "åŒæ ·ï¼Œéœ€è¦æä¾›æ¯é¡¹ç´¢èµ”ã€ç›¸å…³ä¿å•å’Œç›¸å…³ç´¢èµ”äººçš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Faced with the backs of three cards (as shown in Figure 6.1(b)[244]), the player then has to guess where the queen has landed.",
            "zh": "é¢å¯¹ä¸‰å¼ ç‰Œçš„èƒŒé¢ï¼ˆå¦‚å›¾6.1ï¼ˆbï¼‰[244]æ‰€ç¤ºï¼‰ï¼Œç©å®¶å¿…é¡»çŒœæµ‹å¥³ç‹é™è½åœ¨å“ªé‡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "A.3â€…â€…â€…Poll results from the run-up to the 2012 U.S. presidential election.",
            "zh": "A.3 2012å¹´ç¾å›½æ€»ç»Ÿå¤§é€‰å‰çš„æ°‘æ„è°ƒæŸ¥ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(c)[663] visualizes the action-value table after 350 episodes have elapsed.",
            "zh": "å›¾ 11.5ï¼ˆcï¼‰[663] æ˜¾ç¤ºäº† 350 é›†åçš„åŠ¨ä½œå€¼è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEALTHUSD: Health spending per person converted into US dollars",
            "zh": "HEALTHUSDï¼šäººå‡åŒ»ç–—æ”¯å‡ºæ¢ç®—æˆç¾å…ƒ"
        }
    },
    {
        "translation": {
            "en": "For example, the decision tree learning algorithms we looked at in the last chapter worked by selecting subsets of features from which to build predictive trees and so naturally reduce dimensionality.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€ç« ä¸­ç ”ç©¶çš„å†³ç­–æ ‘å­¦ä¹ ç®—æ³•é€šè¿‡é€‰æ‹©ç‰¹å¾å­é›†æ¥æ„å»ºé¢„æµ‹æ ‘ï¼Œä»è€Œè‡ªç„¶åœ°é™ä½ç»´åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the other hand, misclassifying a customer who really was a churn risk probably has a much larger cost associated with it because that customer will be lost when a small bonus may have enticed the customer to stay.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œé”™è¯¯åœ°å°†çœŸæ­£å­˜åœ¨æµå¤±é£é™©çš„å®¢æˆ·åˆ†ç±»å¯èƒ½ä¼šäº§ç”Ÿæ›´å¤§çš„æˆæœ¬ï¼Œå› ä¸ºå½“å°é¢å¥–é‡‘å¯èƒ½è¯±ä½¿å®¢æˆ·ç•™ä¸‹æ¥æ—¶ï¼Œè¯¥å®¢æˆ·å°±ä¼šæµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "This gives a large set of low-information descriptive features.",
            "zh": "è¿™æä¾›äº†å¤§é‡ä½ä¿¡æ¯æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.8â€…â€…(a) The structure of a box plot; and (b) a box plot for the TRAINING EXPENSES feature from the basketball team dataset in Table A.1[750].",
            "zh": "A.8 ï¼ˆaï¼‰ ç®±å½¢å›¾çš„ç»“æ„;ï¼ˆbï¼‰è¡¨A.1[750]ä¸­ç¯®çƒé˜Ÿæ•°æ®é›†çš„è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„ç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, we use the matrix representation of a network as a compact representation of neural networks in the worked examples.",
            "zh": "æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ç½‘ç»œçš„çŸ©é˜µè¡¨ç¤ºä½œä¸ºå·¥ä½œç¤ºä¾‹ä¸­ç¥ç»ç½‘ç»œçš„ç´§å‡‘è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "tolerance, 323",
            "zh": "å…¬å·®ï¼Œ 323"
        }
    },
    {
        "translation": {
            "en": "It is not easy to apply the measures based on prediction scores to multinomial problems. Although there are some examples of doing it, there is no broad consensus in the community on how it should best be done in all cases, so we do not discuss it further in this book.",
            "zh": "å°†åŸºäºé¢„æµ‹åˆ†æ•°çš„åº¦é‡åº”ç”¨äºå¤šé¡¹å¼é—®é¢˜å¹¶ä¸å®¹æ˜“ã€‚å°½ç®¡æœ‰ä¸€äº›è¿™æ ·åšçš„ä¾‹å­ï¼Œä½†ç¤¾åŒºä¸­å¹¶æ²¡æœ‰å°±å¦‚ä½•åœ¨æ‰€æœ‰æƒ…å†µä¸‹æœ€å¥½åœ°åšåˆ°è¿™ä¸€ç‚¹è¾¾æˆå¹¿æ³›çš„å…±è¯†ï¼Œå› æ­¤æˆ‘ä»¬ä¸ä¼šåœ¨æœ¬ä¹¦ä¸­è¿›ä¸€æ­¥è®¨è®ºå®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This book had a major impact and is attributed with killing interest in neural networks for nearly a decade.",
            "zh": "è¿™æœ¬ä¹¦äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œå¹¶è¢«è®¤ä¸ºæ‰¼æ€äº†è¿‘åå¹´æ¥å¯¹ç¥ç»ç½‘ç»œçš„å…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two neurons in each of these layers because we are assuming a step size of 1, and so it requires two neurons to convolve a 2-by-1-by-2 filter over the 3-by-2-by-2 input.",
            "zh": "æ¯ä¸€å±‚éƒ½æœ‰ä¸¤ä¸ªç¥ç»å…ƒï¼Œå› ä¸ºæˆ‘ä»¬å‡è®¾æ­¥é•¿ä¸º 1ï¼Œå› æ­¤éœ€è¦ä¸¤ä¸ªç¥ç»å…ƒåœ¨ 3Ã—2Ã—2 è¾“å…¥ä¸Šå·ç§¯ 2Ã—1Ã—2 æ»¤æ³¢å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of these predictions, Îµ is calculated as 0.200, the sum of the weights of the two instances misclassified by the model (d9 and d10). The weights of all correctly classified instances are then updated using Equation (4.13)[161]. For example, the weight for d1 is updated",
            "zh": "æ ¹æ®è¿™äº›é¢„æµ‹ï¼ŒÎµè®¡ç®—ä¸º 0.200ï¼Œå³æ¨¡å‹é”™è¯¯åˆ†ç±»çš„ä¸¤ä¸ªå®ä¾‹çš„æƒé‡ä¹‹å’Œï¼ˆd9 å’Œ d10ï¼‰ã€‚ç„¶åä½¿ç”¨å…¬å¼ï¼ˆ4.13ï¼‰[161]æ›´æ–°æ‰€æœ‰æ­£ç¡®åˆ†ç±»çš„å®ä¾‹çš„æƒé‡ã€‚ä¾‹å¦‚ï¼Œd1 çš„æƒé‡å·²æ›´æ–°"
        }
    },
    {
        "translation": {
            "en": "variation, 54, 745, 746",
            "zh": "å˜ä½“ï¼Œ 54ï¼Œ 745ï¼Œ 746"
        }
    },
    {
        "translation": {
            "en": "Figure 4.17[154] illustrates the final decision tree that will be generated for this dataset. This tree will predict the mean target feature value of the leaf node indicated by the descriptive features of a query instance. For example, given a query instance with SEASON = summer and WORK DAY = true, this decision tree will predict that there will be 6,000 bike rentals on that day.",
            "zh": "å›¾ 4.17[154] è¯´æ˜äº†å°†ä¸ºè¯¥æ•°æ®é›†ç”Ÿæˆçš„æœ€ç»ˆå†³ç­–æ ‘ã€‚æ­¤æ ‘å°†é¢„æµ‹ç”±æŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾æŒ‡ç¤ºçš„å¶èŠ‚ç‚¹çš„å¹³å‡ç›®æ ‡ç‰¹å¾å€¼ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ª SEASON = summer ä¸” WORK DAY = true çš„æŸ¥è¯¢å®ä¾‹ï¼Œæ­¤å†³ç­–æ ‘å°†é¢„æµ‹å½“å¤©å°†æœ‰ 6,000 è¾†è‡ªè¡Œè½¦ç§Ÿèµã€‚"
        }
    },
    {
        "translation": {
            "en": "HANDSETAGE",
            "zh": "æ‰‹æœº"
        }
    },
    {
        "translation": {
            "en": "burn-in time, 300",
            "zh": "è€åŒ–æ—¶é—´ï¼Œ300"
        }
    },
    {
        "translation": {
            "en": "At each node encountered in the search, the algorithm does three things.",
            "zh": "åœ¨æœç´¢ä¸­é‡åˆ°çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šï¼Œè¯¥ç®—æ³•ä¼šæ‰§è¡Œä¸‰ä»¶äº‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, although there is still a differential between some of the valid pixels in terms of the number of neurons that take them as input, this differential has been decreased; each of the valid corner pixels is now present in four receptive fields, as opposed to one as previously, whereas the count of receptive fields covering a pixel in the center of the image is not affected by the padding.",
            "zh": "æ­¤å¤–ï¼Œå°½ç®¡åœ¨å°†å®ƒä»¬ä½œä¸ºè¾“å…¥çš„ç¥ç»å…ƒæ•°é‡æ–¹é¢ï¼Œä¸€äº›æœ‰æ•ˆåƒç´ ä¹‹é—´ä»ç„¶å­˜åœ¨å·®å¼‚ï¼Œä½†è¿™ç§å·®å¼‚å·²ç»å‡å°‘;æ¯ä¸ªæœ‰æ•ˆçš„è§’åƒç´ ç°åœ¨éƒ½å­˜åœ¨äºå››ä¸ªæ„Ÿå—é‡ä¸­ï¼Œè€Œä¸æ˜¯åƒä»¥å‰é‚£æ ·å­˜åœ¨ä¸€ä¸ªæ„Ÿå—é‡ï¼Œè€Œè¦†ç›–å›¾åƒä¸­å¿ƒåƒç´ çš„æ„Ÿå—é‡è®¡æ•°ä¸å—å¡«å……çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is an ongoing argument regarding whether descriptive features should be normalized before being used in linear regression models.",
            "zh": "å…³äºæè¿°æ€§ç‰¹å¾åœ¨ç”¨äºçº¿æ€§å›å½’æ¨¡å‹ä¹‹å‰æ˜¯å¦åº”è¯¥å½’ä¸€åŒ–ï¼Œä¸€ç›´å­˜åœ¨äº‰è®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.1â€ƒInterpreting Multivariable Linear Regression Models",
            "zh": "7.4.1 è§£é‡Šå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "This can limit the amount of data that an organization collects and, sometimes, restricts implementing features to capture certain domain concepts because consent has not been granted to collect the required data.",
            "zh": "è¿™å¯èƒ½ä¼šé™åˆ¶ç»„ç»‡æ”¶é›†çš„æ•°æ®é‡ï¼Œæœ‰æ—¶è¿˜ä¼šé™åˆ¶å®ç°åŠŸèƒ½ä»¥æ•è·æŸäº›é¢†åŸŸæ¦‚å¿µï¼Œå› ä¸ºå°šæœªæˆäºˆæ”¶é›†æ‰€éœ€æ•°æ®çš„åŒæ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.7[432] illustrates this calculation for weight w7,5, and Equation 8.39[432] shows how the Î”w 7,5 is used as part of Equation 8.30[416] to update the weight after the batch of four examples has been processed; again, in this weight update we assume that Î± = 0.2.",
            "zh": "è¡¨ 8.7[432] è¯´æ˜äº†é‡é‡ w7,5 çš„è®¡ç®—ï¼Œç­‰å¼ 8.39[432] æ˜¾ç¤ºäº†å¦‚ä½•åœ¨å¤„ç†å®Œæ‰¹æ¬¡å››ä¸ªç¤ºä¾‹åå°† Î”w 7,5 ç”¨ä½œç­‰å¼ 8.30[416] çš„ä¸€éƒ¨åˆ†æ¥æ›´æ–°é‡é‡;åŒæ ·ï¼Œåœ¨æ­¤æƒé‡æ›´æ–°ä¸­ï¼Œæˆ‘ä»¬å‡è®¾ Î± = 0.2ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that would be needed in order to utilize the analytics-based insight that your solution would provide.",
            "zh": "ï¼ˆcï¼‰ å¯¹äºæ‚¨æå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°åˆ©ç”¨æ‚¨çš„è§£å†³æ–¹æ¡ˆå°†æä¾›çš„åŸºäºåˆ†æçš„è§è§£æ‰€éœ€çš„å®¹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a more broad discussion, Isaac Asimovâ€™s I, Robot (Asimov, 1950), in which the Three Laws of Robotics first appear, is a fun exploration of the challenges of defining reward and utility functions. Similarly, Bostromâ€™s paperclip maximizer thought experiment (Bostrom, 2003) is an interesting exploration of the potential negative consequences of a highly functional intelligent agent pursuing cumulative reward.",
            "zh": "å¯¹äºæ›´å¹¿æ³›çš„è®¨è®ºï¼Œè‰¾è¨å…‹Â·é˜¿è¥¿è«å¤«ï¼ˆIsaac Asimovï¼‰çš„ã€Šæˆ‘ï¼Œæœºå™¨äººã€‹ï¼ˆé˜¿è¥¿è«å¤«ï¼Œ1950å¹´ï¼‰é¦–æ¬¡å‡ºç°äº†æœºå™¨äººä¸‰å®šå¾‹ï¼Œè¿™æ˜¯å¯¹å®šä¹‰å¥–åŠ±å’Œæ•ˆç”¨å‡½æ•°çš„æŒ‘æˆ˜çš„æœ‰è¶£æ¢ç´¢ã€‚åŒæ ·ï¼ŒBostromçš„å›å½¢é’ˆæœ€å¤§åŒ–å™¨æ€æƒ³å®éªŒï¼ˆBostromï¼Œ2003ï¼‰æ˜¯å¯¹è¿½æ±‚ç´¯ç§¯å¥–åŠ±çš„é«˜åŠŸèƒ½æ™ºèƒ½ä»£ç†çš„æ½œåœ¨è´Ÿé¢åæœçš„æœ‰è¶£æ¢ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "where IG(d, ğ’Ÿ) is the information gain of the feature d for the dataset ğ’Ÿ (computed using Equation (4.4)[130] from Section 4.2.3[127]), and the divisor is the entropy of the dataset ğ’Ÿ with respect to the feature d (note that levels(d) is the set of levels that the feature d can take). This divisor biases information gain ratio away from features that take on a large number of values and as such counteracts the bias in information gain toward these features.",
            "zh": "å…¶ä¸­ IGï¼ˆdï¼Œ Dï¼‰ æ˜¯æ•°æ®é›† D çš„ç‰¹å¾ d çš„ä¿¡æ¯å¢ç›Šï¼ˆä½¿ç”¨ç¬¬ 4.2.3 èŠ‚[127] ä¸­çš„å…¬å¼ ï¼ˆ4.4ï¼‰[130] è®¡ç®—ï¼‰ï¼Œé™¤æ•°æ˜¯æ•°æ®é›† D ç›¸å¯¹äºç‰¹å¾ d çš„ç†µï¼ˆè¯·æ³¨æ„ï¼Œlevelsï¼ˆdï¼‰ æ˜¯ç‰¹å¾ d å¯ä»¥é‡‡ç”¨çš„æ°´å¹³é›†ï¼‰ã€‚è¯¥é™¤æ•°ä½¿ä¿¡æ¯å¢ç›Šæ¯”åç¦»å…·æœ‰å¤§é‡å€¼çš„ç‰¹å¾ï¼Œä»è€ŒæŠµæ¶ˆäº†ä¿¡æ¯å¢ç›Šå¯¹è¿™äº›ç‰¹å¾çš„åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "step-wise sequential search, 722, 723",
            "zh": "é€æ­¥é¡ºåºæœç´¢ï¼Œ722,723"
        }
    },
    {
        "translation": {
            "en": "Vertically aligning the columns in the input matrix with the columns in the output matrix shows that the network correctly maps all four inputs combinations to XOR outputs: < 0,0 > â†’ 0, < 0,1 > â†’ 1, < 1,0 > â†’ 1, and < 1,1 > â†’ 0.",
            "zh": "å°†è¾“å…¥çŸ©é˜µä¸­çš„åˆ—ä¸è¾“å‡ºçŸ©é˜µä¸­çš„åˆ—å‚ç›´å¯¹é½è¡¨æ˜ï¼Œç½‘ç»œæ­£ç¡®åœ°å°†æ‰€æœ‰å››ä¸ªè¾“å…¥ç»„åˆæ˜ å°„åˆ° XOR è¾“å‡ºï¼š< 0,0 > â†’ 0ã€< 0,1 > â†’ 1ã€< 1,0 > â†’ 1 å’Œ < 1,1 > â†’ 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the cumulative gain of each of the models for the 4th decile.",
            "zh": "è®¡ç®—ç¬¬ 4 ä¸ªååˆ†ä½æ•°çš„æ¯ä¸ªæ¨¡å‹çš„ç´¯ç§¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "1. An online movie streaming company has a business problem of growing customer churnâ€”subscription customers canceling their subscriptions to join a competitor. Create a list of ways in which predictive data analytics could be used to help address this business problem. For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original business problem.",
            "zh": "1. ä¸€å®¶åœ¨çº¿ç”µå½±æµåª’ä½“å…¬å¸é¢ä¸´ç€å®¢æˆ·æµå¤±ç‡ä¸æ–­å¢é•¿çš„ä¸šåŠ¡é—®é¢˜â€”â€”è®¢é˜…å®¢æˆ·å–æ¶ˆè®¢é˜…ä»¥åŠ å…¥ç«äº‰å¯¹æ‰‹ã€‚åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—å‡ºå¯ä»¥ä½¿ç”¨é¢„æµ‹æ•°æ®åˆ†ææ¥å¸®åŠ©è§£å†³æ­¤ä¸šåŠ¡é—®é¢˜çš„æ–¹æ³•ã€‚å¯¹äºæ¯ä¸ªå»ºè®®çš„æ–¹æ³•ï¼Œæè¿°å°†è¦æ„å»ºçš„é¢„æµ‹æ¨¡å‹ã€ä¸šåŠ¡éƒ¨é—¨å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹ï¼Œä»¥åŠä½¿ç”¨è¯¥æ¨¡å‹å°†å¦‚ä½•å¸®åŠ©è§£å†³åŸå§‹ä¸šåŠ¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of this feedback, Sarah learned what constituted a good decision and and became better and better at assessing her situation and choosing which direction to step in next and how far.",
            "zh": "æ ¹æ®è¿™äº›åé¦ˆï¼Œèæ‹‰äº†è§£äº†ä»€ä¹ˆæ˜¯æ­£ç¡®çš„å†³å®šï¼Œå¹¶ä¸”è¶Šæ¥è¶Šå–„äºè¯„ä¼°è‡ªå·±çš„å¤„å¢ƒï¼Œå¹¶é€‰æ‹©ä¸‹ä¸€æ­¥è¦èµ°å“ªä¸ªæ–¹å‘ä»¥åŠèµ°å¤šè¿œã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall tells us how confident we can be that all the instances with the positive target level have been found by the model.",
            "zh": "å¬å›å‘Šè¯‰æˆ‘ä»¬ï¼Œæ¨¡å‹å·²ç»æ‰¾åˆ°äº†æ‰€æœ‰å…·æœ‰æ­£ç›®æ ‡æ°´å¹³çš„å®ä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰å¤šå¤§çš„ä¿¡å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "learning rate, 168, 323, 332, 379, 422, 654",
            "zh": "å­¦ä¹ ç‡ï¼Œ 168ï¼Œ 323ï¼Œ 332ï¼Œ 379ï¼Œ 422ï¼Œ 654"
        }
    },
    {
        "translation": {
            "en": "partially observable environments, 640",
            "zh": "éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒï¼Œ640"
        }
    },
    {
        "translation": {
            "en": "The inclusion of the weight w[0] means that there is one more weight term than there are real descriptive features.",
            "zh": "åŒ…å«æƒé‡ w[0] æ„å‘³ç€æƒé‡é¡¹æ¯”å®é™…æè¿°æ€§ç‰¹å¾å¤šä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "rank and prune, 227, 614",
            "zh": "ç­‰çº§å’Œä¿®å‰ªï¼Œ227,614"
        }
    },
    {
        "translation": {
            "en": "where the parameter p is typically set to a positive value and defines the behavior of the distance metric. Different distance metrics result from adjusting the value of p. For example, the Minkowski distance with p = 1 is the Manhattan distance, and with p = 2 is the Euclidean distance. Continuing in this manner, we can define an infinite number of distance metrics.",
            "zh": "å…¶ä¸­ï¼Œå‚æ•° p é€šå¸¸è®¾ç½®ä¸ºæ­£å€¼ï¼Œå¹¶å®šä¹‰è·ç¦»æŒ‡æ ‡çš„è¡Œä¸ºã€‚è°ƒæ•´ p çš„å€¼ä¼šäº§ç”Ÿä¸åŒçš„è·ç¦»åº¦é‡ã€‚ä¾‹å¦‚ï¼Œp = 1 çš„é—µå¯å¤«æ–¯åŸºè·ç¦»æ˜¯æ›¼å“ˆé¡¿è·ç¦»ï¼Œp = 2 çš„é—µå¯å¤«æ–¯åŸºè·ç¦»æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚ä»¥è¿™ç§æ–¹å¼ç»§ç»­ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰æ— é™æ•°é‡çš„è·ç¦»åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, these models are very sensitive to noise in the target feature.",
            "zh": "å› æ­¤ï¼Œè¿™äº›æ¨¡å‹å¯¹ç›®æ ‡ç‰¹å¾ä¸­çš„å™ªå£°éå¸¸æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, manually setting upper and lower thresholds based on domain knowledge is most appropriate in this case.",
            "zh": "å› æ­¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ ¹æ®é¢†åŸŸçŸ¥è¯†æ‰‹åŠ¨è®¾ç½®ä¸Šé™å’Œä¸‹é™æ˜¯æœ€åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address the problem that the oil exploration company is facing. For each proposed approach, describe the predictive model that will be built, how the model will be used by the company, and how using the model will help address the original problem.",
            "zh": "ï¼ˆaï¼‰ æå‡ºä¸¤ç§æ–¹æ³•ï¼Œåˆ©ç”¨é¢„æµ‹æ€§æ•°æ®åˆ†ææ¥å¸®åŠ©è§£å†³çŸ³æ²¹å‹˜æ¢å…¬å¸é¢ä¸´çš„é—®é¢˜ã€‚å¯¹äºæ¯ä¸ªå»ºè®®çš„æ–¹æ³•ï¼Œæè¿°å°†è¦æ„å»ºçš„é¢„æµ‹æ¨¡å‹ã€å…¬å¸å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹ï¼Œä»¥åŠä½¿ç”¨è¯¥æ¨¡å‹å°†å¦‚ä½•å¸®åŠ©è§£å†³åŸå§‹é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.207122",
            "zh": "0.207122"
        }
    },
    {
        "translation": {
            "en": "We discuss sampling methods in more detail in Section 3.6.3[91].",
            "zh": "æˆ‘ä»¬å°†åœ¨ç¬¬3.6.3èŠ‚[91]ä¸­æ›´è¯¦ç»†åœ°è®¨è®ºé‡‡æ ·æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "No individual feature stood out as having a very strong relationship, but the evidence of connections between the descriptive features and the target feature could be seen.",
            "zh": "æ²¡æœ‰ä¸€ä¸ªå•ç‹¬çš„ç‰¹å¾å…·æœ‰éå¸¸å¼ºçš„å…³ç³»ï¼Œä½†å¯ä»¥çœ‹åˆ°æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´è”ç³»çš„è¯æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "bootstrapping, 546, 655, 662, 676",
            "zh": "å¼•å¯¼ï¼Œ 546ï¼Œ 655ï¼Œ 662ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "where for a given state the model outputs the value of the action-value function for every action that could be taken in that state. To simplify notation we refer to action-value functions implemented as predictive models as Qğ•„. Figure 11.8[669] illustrates this framing of the action-value function learning problem.",
            "zh": "å…¶ä¸­ï¼Œå¯¹äºç»™å®šçŠ¶æ€ï¼Œæ¨¡å‹è¾“å‡ºåœ¨è¯¥çŠ¶æ€ä¸‹å¯ä»¥æ‰§è¡Œçš„æ¯ä¸ªæ“ä½œçš„ action-value å‡½æ•°çš„å€¼ã€‚ä¸ºäº†ç®€åŒ–ç¬¦å·ï¼Œæˆ‘ä»¬å°†ä½œä¸ºé¢„æµ‹æ¨¡å‹å®ç°çš„åŠ¨ä½œå€¼å‡½æ•°ç§°ä¸º QMã€‚å›¾11.8[669]è¯´æ˜äº†åŠ¨ä½œ-ä»·å€¼å‡½æ•°å­¦ä¹ é—®é¢˜çš„æ¡†æ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The CART algorithm uses the Gini index (introduced in Section 4.4.1[142]) instead of information gain to select features to add to the tree.",
            "zh": "CARTç®—æ³•ä½¿ç”¨åŸºå°¼æŒ‡æ•°ï¼ˆåœ¨ç¬¬4.4.1èŠ‚[142]ä¸­ä»‹ç»ï¼‰è€Œä¸æ˜¯ä¿¡æ¯å¢ç›Šæ¥é€‰æ‹©è¦æ·»åŠ åˆ°æ ‘ä¸­çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks provide a more flexible representation for encoding the conditional independence assumptions between the features in a domain.",
            "zh": "è´å¶æ–¯ç½‘ç»œä¸ºç¼–ç åŸŸä¸­ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾æä¾›äº†æ›´çµæ´»çš„è¡¨ç¤ºå½¢å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the judgment of similarity between current trial user and the other users in the dataset changed dramatically depending on which similarity index was employed illustrates the importance of choosing the correct index for the task.",
            "zh": "å½“å‰è¯•éªŒç”¨æˆ·ä¸æ•°æ®é›†ä¸­å…¶ä»–ç”¨æˆ·ä¹‹é—´çš„ç›¸ä¼¼æ€§åˆ¤æ–­æ ¹æ®æ‰€é‡‡ç”¨çš„ç›¸ä¼¼æ€§æŒ‡æ•°è€Œå‘ç”Ÿå·¨å¤§å˜åŒ–ï¼Œè¿™ä¸€äº‹å®è¯´æ˜äº†ä¸ºä»»åŠ¡é€‰æ‹©æ­£ç¡®æŒ‡æ•°çš„é‡è¦æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the ROC curve gives us an immediate visual indication of the strength of a modelâ€”the closer the curve is to the top left, the more predictive the model.",
            "zh": "å› æ­¤ï¼ŒROC æ›²çº¿ä¸ºæˆ‘ä»¬æä¾›äº†æ¨¡å‹å¼ºåº¦çš„ç›´æ¥è§†è§‰æŒ‡ç¤ºâ€”â€”æ›²çº¿è¶Šé è¿‘å·¦ä¸Šè§’ï¼Œæ¨¡å‹çš„é¢„æµ‹æ€§å°±è¶Šå¼ºã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the discounted return at time t = 0 on the basis of this sequence of rewards using a discount rate of 0.22.",
            "zh": "ï¼ˆbï¼‰ ä½¿ç”¨è´´ç°ç‡ä¸º 0.22 çš„è´´ç°ç‡ï¼Œæ ¹æ®è¿™ä¸€ç³»åˆ—å¥–åŠ±è®¡ç®—æ—¶é—´ t = 0 æ—¶çš„è´´ç°å›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "That cumulative gain chart allows us to understand how many of the positive instances in a complete test set we can expect to have identified at each decile of the dataset.",
            "zh": "è¯¥ç´¯ç§¯å¢ç›Šå›¾ä½¿æˆ‘ä»¬èƒ½å¤Ÿäº†è§£åœ¨æ•°æ®é›†çš„æ¯ä¸ªååˆ†ä½æ•°å¯ä»¥è¯†åˆ«å‡ºå®Œæ•´æµ‹è¯•é›†ä¸­æœ‰å¤šå°‘ä¸ªé˜³æ€§å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main difference in processing examples in parallel is that instead of augmenting the input and activation matrices with a single dummy feature value, they are now augmented with a row of dummy features values, one per example.",
            "zh": "å¹¶è¡Œå¤„ç†ç¤ºä¾‹çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œç°åœ¨ä¸æ˜¯ç”¨å•ä¸ªè™šæ‹Ÿç‰¹å¾å€¼æ¥æ‰©å……è¾“å…¥å’Œæ¿€æ´»çŸ©é˜µï¼Œè€Œæ˜¯ç”¨ä¸€è¡Œè™šæ‹Ÿç‰¹å¾å€¼æ¥æ‰©å……å®ƒä»¬ï¼Œæ¯ä¸ªç¤ºä¾‹ä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "A model is trained using the training set, and the relevant performance measures on the test set are recorded.",
            "zh": "ä½¿ç”¨è®­ç»ƒé›†è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è®°å½•æµ‹è¯•é›†ä¸Šçš„ç›¸å…³æ€§èƒ½åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dynamic of a ReLU being in a state where it is inactive for all (or nearly all) inputs and consequently it never updated and so never becomes active is known as the dying ReLU problem.",
            "zh": "ReLU å¤„äºå¯¹æ‰€æœ‰ï¼ˆæˆ–å‡ ä¹æ‰€æœ‰ï¼‰è¾“å…¥éƒ½å¤„äºéæ´»åŠ¨çŠ¶æ€çš„è¿™ç§åŠ¨æ€ï¼Œå› æ­¤å®ƒæ°¸è¿œä¸ä¼šæ›´æ–°ï¼Œå› æ­¤æ°¸è¿œä¸ä¼šå˜å¾—æ´»è·ƒï¼Œè¿™è¢«ç§°ä¸ºå‚æ­»çš„ ReLU é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15[151] illustrates the type of partitioning we are trying to achieve when we use a variance measure to select the features to split on in a decision tree.",
            "zh": "å›¾ 4.15[151] è¯´æ˜äº†å½“æˆ‘ä»¬ä½¿ç”¨æ–¹å·®åº¦é‡æ¥é€‰æ‹©è¦åœ¨å†³ç­–æ ‘ä¸­æ‹†åˆ†çš„ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬è¯•å›¾å®ç°çš„åˆ†åŒºç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In practice, unfortunately, this doesnâ€™t work, for a number of reasons.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œåœ¨å®è·µä¸­ï¼Œç”±äºå¤šç§åŸå› ï¼Œè¿™ä¸èµ·ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.5795",
            "zh": "-0.5795"
        }
    },
    {
        "translation": {
            "en": "Logistic regression models, for example, are very fast at making predictions as all that is involved is calculating the regression equation and performing a thresholding operation.",
            "zh": "ä¾‹å¦‚ï¼Œé€»è¾‘å›å½’æ¨¡å‹åœ¨è¿›è¡Œé¢„æµ‹æ—¶éå¸¸å¿«ï¼Œå› ä¸ºæ‰€æ¶‰åŠçš„åªæ˜¯è®¡ç®—å›å½’æ–¹ç¨‹å¹¶æ‰§è¡Œé˜ˆå€¼è¿ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are strong relationships between these measures, for example: FNR = 1 âˆ’ TPR, and FPR = 1 âˆ’ TNR.",
            "zh": "è¿™äº›æªæ–½ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„å…³ç³»ï¼Œä¾‹å¦‚ï¼šFNR = 1 âˆ’ TPR å’Œ FPR = 1 âˆ’ TNRã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1.2â€ƒVariation",
            "zh": "A.1.2 å˜åŒ–"
        }
    },
    {
        "translation": {
            "en": "The model is designed to award a grade to a student on the basis of how similar they are to other students in the module in terms of their grades on other modules.",
            "zh": "è¯¥æ¨¡å‹æ—¨åœ¨æ ¹æ®å­¦ç”Ÿåœ¨å…¶ä»–æ¨¡å—ä¸­çš„æˆç»©ä¸æ¨¡å—ä¸­å…¶ä»–å­¦ç”Ÿçš„ç›¸ä¼¼ç¨‹åº¦æ¥æˆäºˆå­¦ç”Ÿæˆç»©ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this approach were to be used for the CLAIM AMOUNT feature from the motor claims insurance fraud detection scenario, then the upper and lower thresholds would be defined as follows:",
            "zh": "å¦‚æœæ­¤æ–¹æ³•ç”¨äºæ±½è½¦ç´¢èµ”ä¿é™©æ¬ºè¯ˆæ£€æµ‹æ–¹æ¡ˆä¸­çš„ CLAIM AMOUNT åŠŸèƒ½ï¼Œåˆ™ä¸Šé™å’Œä¸‹é™å°†å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "conditional probability table, 286",
            "zh": "æ¡ä»¶æ¦‚ç‡è¡¨ï¼Œ286"
        }
    },
    {
        "translation": {
            "en": "1. Parts of this chapter assume a familiarity with calculus, in particular the concepts of a partial derivative and the chain rule; see Appendix C[765] for an introduction to these concepts. This chapter also draws on a number of concepts introduced in Chapter 7[311], including the gradient descent algorithm, and logistic regression models.",
            "zh": "1. æœ¬ç« çš„éƒ¨åˆ†å†…å®¹å‡å®šæ‚¨ç†Ÿæ‚‰å¾®ç§¯åˆ†ï¼Œç‰¹åˆ«æ˜¯åå¯¼æ•°å’Œé“¾å¼æ³•åˆ™çš„æ¦‚å¿µ;æœ‰å…³è¿™äº›æ¦‚å¿µçš„ä»‹ç»ï¼Œè¯·å‚é˜…é™„å½•C[765]ã€‚æœ¬ç« è¿˜å€Ÿé‰´äº†ç¬¬7ç« [311]ä¸­ä»‹ç»çš„ä¸€äº›æ¦‚å¿µï¼ŒåŒ…æ‹¬æ¢¯åº¦ä¸‹é™ç®—æ³•å’Œé€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Well-designed application-based, or point-and-click, tools make it very quick and easy to develop and evaluate models and to perform associated data manipulation tasks.",
            "zh": "ç²¾å¿ƒè®¾è®¡çš„åŸºäºåº”ç”¨ç¨‹åºæˆ–ç‚¹å‡»å¼å·¥å…·ä½¿å¼€å‘å’Œè¯„ä¼°æ¨¡å‹ä»¥åŠæ‰§è¡Œç›¸å…³æ•°æ®æ“ä½œä»»åŠ¡å˜å¾—éå¸¸å¿«é€Ÿå’Œå®¹æ˜“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Full independence between events is quite rare.",
            "zh": "äº‹ä»¶ä¹‹é—´çš„å®Œå…¨ç‹¬ç«‹æ€§æ˜¯ç›¸å½“ç½•è§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "risk assessment, 3",
            "zh": "é£é™©è¯„ä¼°ï¼Œ3"
        }
    },
    {
        "translation": {
            "en": "13.1â€…â€…â€…Examples of the different galaxy morphology categories into which SDSS scientists categorize galaxy objects.",
            "zh": "13.1 SDSSç§‘å­¦å®¶å°†æ˜Ÿç³»å¤©ä½“åˆ†ç±»ä¸ºä¸åŒæ˜Ÿç³»å½¢æ€ç±»åˆ«çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is evident in Figure 11.6[667], which shows a visualization of the final action-value table learned by an agent training using SARSA for the grid world.",
            "zh": "è¿™åœ¨å›¾ 11.6[667] ä¸­å¾ˆæ˜æ˜¾ï¼Œå®ƒæ˜¾ç¤ºäº†ä½¿ç”¨ SARSA åœ¨ç½‘æ ¼ä¸–ç•Œä¸­è®­ç»ƒçš„æ™ºèƒ½ä½“æ‰€å­¦ä¹ çš„æœ€ç»ˆè¡ŒåŠ¨å€¼è¡¨çš„å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "feature map, 485",
            "zh": "ç‰¹å¾åœ°å›¾ï¼Œ485"
        }
    },
    {
        "translation": {
            "en": "This issue should be noted in the data quality plan.",
            "zh": "æ­¤é—®é¢˜åº”åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­æ³¨æ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "This distinction is not absolute, but it generally describes whether the size of the domain representation used to define a model is solely determined by the number of features in the domain or is affected by the number of instances in the dataset.",
            "zh": "è¿™ç§åŒºåˆ«ä¸æ˜¯ç»å¯¹çš„ï¼Œä½†å®ƒé€šå¸¸æè¿°äº†ç”¨äºå®šä¹‰æ¨¡å‹çš„åŸŸè¡¨ç¤ºçš„å¤§å°æ˜¯ä»…ç”±åŸŸä¸­çš„è¦ç´ æ•°å†³å®šçš„ï¼Œè¿˜æ˜¯å—æ•°æ®é›†ä¸­çš„å®ä¾‹æ•°çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the actual result was a massive win for Roosevelt, with 62% of the votes.",
            "zh": "ç„¶è€Œï¼Œå®é™…ç»“æœæ˜¯ç½—æ–¯ç¦ä»¥62%çš„é€‰ç¥¨å¤§è·å…¨èƒœã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The height of employees in a trucking company.",
            "zh": "ï¼ˆaï¼‰ å¡è½¦è¿è¾“å…¬å¸é›‡å‘˜çš„èº«é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Returning to our example, the regression equation for this RENTAL PRICE model would change to",
            "zh": "å›åˆ°æˆ‘ä»¬çš„ç¤ºä¾‹ï¼Œè¿™ä¸ª RENTAL PRICE æ¨¡å‹çš„å›å½’æ–¹ç¨‹å°†å˜ä¸º"
        }
    },
    {
        "translation": {
            "en": "To perform this ranking, we need to reduce the information contained in the confusion matrix to a single measure, for example, misclassification rate.",
            "zh": "ä¸ºäº†æ‰§è¡Œæ­¤æ’åï¼Œæˆ‘ä»¬éœ€è¦å°†æ··æ·†çŸ©é˜µä¸­åŒ…å«çš„ä¿¡æ¯ç®€åŒ–ä¸ºå•ä¸ªåº¦é‡ï¼Œä¾‹å¦‚é”™è¯¯åˆ†ç±»ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unless, however, this second use was stated at the time of collection, this use would be in breach of this principle.",
            "zh": "ä½†æ˜¯ï¼Œé™¤éåœ¨æ”¶é›†æ—¶è¯´æ˜ç¬¬äºŒæ¬¡ä½¿ç”¨ï¼Œå¦åˆ™è¿™ç§ä½¿ç”¨å°†è¿åè¿™ä¸€åŸåˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "When this happens, it indicates that all the chains are sampling from the same distribution and, hence, that it is likely that they have all forgotten their starting states.",
            "zh": "å½“è¿™ç§æƒ…å†µå‘ç”Ÿæ—¶ï¼Œå®ƒè¡¨æ˜æ‰€æœ‰é“¾éƒ½ä»åŒä¸€åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå› æ­¤ï¼Œå®ƒä»¬å¾ˆå¯èƒ½éƒ½å¿˜è®°äº†å®ƒä»¬çš„èµ·å§‹çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "covariance, 81, 218",
            "zh": "åæ–¹å·®ï¼Œ 81ï¼Œ 218"
        }
    },
    {
        "translation": {
            "en": "The cells above and below the diagonal show scatter plots of the features in the row and column that meet at that cell.",
            "zh": "å¯¹è§’çº¿ä¸Šæ–¹å’Œä¸‹æ–¹çš„åƒå…ƒæ˜¾ç¤ºè¡Œå’Œåˆ—ä¸­åœ¨è¯¥åƒå…ƒå¤„ç›¸äº¤çš„è¦ç´ çš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Computing a conditional probability for a node becomes more complex if the value of one or more of the parent nodes is unknown.",
            "zh": "å¦‚æœä¸€ä¸ªæˆ–å¤šä¸ªçˆ¶èŠ‚ç‚¹çš„å€¼æœªçŸ¥ï¼Œåˆ™è®¡ç®—èŠ‚ç‚¹çš„æ¡ä»¶æ¦‚ç‡ä¼šå˜å¾—æ›´åŠ å¤æ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason that partitioning the dataset into single instances is indicative of overfitting is that if there is any noise in the training data (something that is likely in real applications), then the leaf nodes generated due to noisy instances will result in unreliable predictions for queries.",
            "zh": "å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå•ä¸ªå®ä¾‹è¡¨ç¤ºè¿‡åº¦æ‹Ÿåˆçš„åŸå› æ˜¯ï¼Œå¦‚æœè®­ç»ƒæ•°æ®ä¸­å­˜åœ¨ä»»ä½•å™ªå£°ï¼ˆåœ¨å®é™…åº”ç”¨ç¨‹åºä¸­å¯èƒ½å­˜åœ¨ï¼‰ï¼Œåˆ™ç”±äºå™ªå£°å®ä¾‹è€Œç”Ÿæˆçš„å¶èŠ‚ç‚¹å°†å¯¼è‡´æŸ¥è¯¢é¢„æµ‹ä¸å¯é ã€‚"
        }
    },
    {
        "translation": {
            "en": "convolutional neural network, 434, 477, 485, 673, 674",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œï¼Œ 434ï¼Œ 477ï¼Œ 485ï¼Œ 673ï¼Œ 674"
        }
    },
    {
        "translation": {
            "en": "classes, 551",
            "zh": "ç±»ï¼Œ551"
        }
    },
    {
        "translation": {
            "en": "2. âˆ‚ai/âˆ‚zi is always â‰¥ 0 for a logistic function.",
            "zh": "2. âˆ‚ai/âˆ‚zi å¯¹äºé€»è¾‘å‡½æ•°å§‹ç»ˆâ‰¥ 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices and class accuracy measures arising from each fold are shown in Table 9.4[544].",
            "zh": "æ¯ä¸ªæŠ˜å äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå’Œç±»ç²¾åº¦æµ‹é‡å¦‚è¡¨9.4[544]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "8.17â€…â€…â€…A plot showing how the sum of squared errors of the network changed during training.",
            "zh": "8.17 æ˜¾ç¤ºç½‘ç»œè¯¯å·®å¹³æ–¹å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–çš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "coordinate system, 183",
            "zh": "åæ ‡ç³»ï¼Œ183"
        }
    },
    {
        "translation": {
            "en": "At any point in time, t, the agent observes the current state of its environment, ot; considers these observations to select an action, at; and takes this action, receiving immediate feedback, rt, from the environment about whether this was a good or bad action to take.",
            "zh": "åœ¨ä»»ä½•æ—¶é—´ç‚¹ tï¼Œä»£ç†è§‚å¯Ÿå…¶ç¯å¢ƒçš„å½“å‰çŠ¶æ€ï¼Œot;è€ƒè™‘è¿™äº›è§‚å¯Ÿç»“æœä»¥é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œï¼Œåœ¨;å¹¶é‡‡å–æ­¤æ“ä½œï¼Œä»ç¯å¢ƒä¸­æ¥æ”¶å³æ—¶åé¦ˆ RTï¼Œäº†è§£è¿™æ˜¯è¦é‡‡å–çš„æ“ä½œæ˜¯å¥½æ˜¯åã€‚"
        }
    },
    {
        "translation": {
            "en": "This makes bar plots comparable across datasets or samples of different sizes and is referred to as a probability distribution, because the densities actually tell us the probability that we would pick each level if we were to select one instance at random from the dataset.",
            "zh": "è¿™ä½¿å¾—æ¡å½¢å›¾åœ¨ä¸åŒå¤§å°çš„æ•°æ®é›†æˆ–æ ·æœ¬ä¹‹é—´å…·æœ‰å¯æ¯”æ€§ï¼Œå¹¶ä¸”è¢«ç§°ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œå› ä¸ºå¯†åº¦å®é™…ä¸Šå‘Šè¯‰æˆ‘ä»¬ï¼Œå¦‚æœæˆ‘ä»¬ä»æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå®ä¾‹ï¼Œæˆ‘ä»¬å°†é€‰æ‹©æ¯ä¸ªæ°´å¹³çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.1[182] illustrates this process by listing some of the animals you have encountered before and how they compare with the growling, web-footed, duck-billed animal that the sailor described.",
            "zh": "è¡¨5.1[182]é€šè¿‡åˆ—å‡ºä½ ä»¥å‰é‡åˆ°çš„ä¸€äº›åŠ¨ç‰©ï¼Œä»¥åŠå®ƒä»¬ä¸æ°´æ‰‹æè¿°çš„å’†å“®ã€è¹¼è¶³ã€é¸­å˜´åŠ¨ç‰©çš„æ¯”è¾ƒï¼Œæ¥è¯´æ˜è¿™ä¸ªè¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Computational considerations aside, Euclidean distance is often used as the default.",
            "zh": "æ’‡å¼€è®¡ç®—è€ƒè™‘ä¸è°ˆï¼Œæ¬§å‡ é‡Œå¾—è·ç¦»é€šå¸¸è¢«ç”¨ä½œé»˜è®¤å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "17. The concept of a convergence criterion is also used in the gradient decent algorithm discussed in Chapter 7[311]; see Algorithm 4[326].",
            "zh": "17. æ”¶æ•›å‡†åˆ™çš„æ¦‚å¿µä¹Ÿç”¨äºç¬¬7ç« [311]è®¨è®ºçš„æ¢¯åº¦ä½“é¢ç®—æ³•;å‚è§ç®—æ³•4[326]ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.2â€ƒData Understanding",
            "zh": "12.2 æ•°æ®ç†è§£"
        }
    },
    {
        "translation": {
            "en": "Linear Regression",
            "zh": "çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "0.36",
            "zh": "0.36"
        }
    },
    {
        "translation": {
            "en": "These two classes are linearly separable because as Figure 7.10[340](b) shows, it is possible to draw a single straight line that separates one class from the other.",
            "zh": "è¿™ä¸¤ä¸ªç±»æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ï¼Œå› ä¸ºå¦‚å›¾ 7.10[340]ï¼ˆbï¼‰ æ‰€ç¤ºï¼Œå¯ä»¥ç»˜åˆ¶ä¸€æ¡ç›´çº¿å°†ä¸€ä¸ªç±»ä¸å¦ä¸€ä¸ªç±»åˆ†å¼€ã€‚"
        }
    },
    {
        "translation": {
            "en": "This extra depth enables the networks to learn more complex input-output mappings.",
            "zh": "è¿™ç§é¢å¤–çš„æ·±åº¦ä½¿ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ æ›´å¤æ‚çš„è¾“å…¥-è¾“å‡ºæ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.14â€…â€…â€…(a)â€“(c) Equal-frequency binning of normally distributed data with different numbers of bins; and (d)â€“(f) the same data binned into the same number of bins using equal-width binning. The dashed lines illustrate the distribution of the original continuous feature values, and the gray boxes represent the bins.",
            "zh": "3.14 ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ å…·æœ‰ä¸åŒç®±æ•°çš„æ­£æ€åˆ†å¸ƒæ•°æ®çš„ç­‰é¢‘åˆ†ç®±;ï¼ˆdï¼‰â€“ï¼ˆfï¼‰ä½¿ç”¨ç­‰å®½åˆ†ç®±å°†ç›¸åŒçš„æ•°æ®åˆ†ç®±åˆ°ç›¸åŒæ•°é‡çš„åˆ†ç®±ä¸­ã€‚è™šçº¿è¡¨ç¤ºåŸå§‹è¿ç»­è¦ç´ å€¼çš„åˆ†å¸ƒï¼Œç°è‰²æ¡†è¡¨ç¤ºæ¡æŸ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, if you ask Question 2 first, the average number of questions you have to ask per game is",
            "zh": "å› æ­¤ï¼Œå¦‚æœæ‚¨å…ˆé—®é—®é¢˜ 2ï¼Œåˆ™æ¯åœºæ¯”èµ›å¿…é¡»é—®çš„å¹³å‡é—®é¢˜æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "The completed transition matrix for the Twist action, ğ’«Twist, is",
            "zh": "Twist åŠ¨ä½œ PTwist çš„å®Œæ•´è¿‡æ¸¡çŸ©é˜µä¸º"
        }
    },
    {
        "translation": {
            "en": "Each loop of the repeat loop from Line 3[420] to Line 33[420] involves an epoch of training (i.e., a full traversal of the training data completed via a single pass through all the mini-batches).",
            "zh": "ä»ç¬¬ 3 è¡Œ [420] åˆ°ç¬¬ 33 è¡Œ [420] çš„é‡å¤å¾ªç¯çš„æ¯ä¸ªå¾ªç¯éƒ½æ¶‰åŠä¸€ä¸ªè®­ç»ƒå‘¨æœŸï¼ˆå³ï¼Œé€šè¿‡æ‰€æœ‰å°æ‰¹é‡çš„å•æ¬¡éå†å®Œæˆçš„è®­ç»ƒæ•°æ®çš„å®Œæ•´éå†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where t is a target feature with a set of levels, levels(t), and q is a query instance with a set of descriptive features, q[1],â€¦,q[m].",
            "zh": "å…¶ä¸­ t æ˜¯å…·æœ‰ä¸€ç»„çº§åˆ«çš„ç›®æ ‡ç‰¹å¾ levelsï¼ˆtï¼‰ï¼Œq æ˜¯å…·æœ‰ä¸€ç»„æè¿°æ€§ç‰¹å¾çš„æŸ¥è¯¢å®ä¾‹ï¼Œq[1],...,q[m]ã€‚"
        }
    },
    {
        "translation": {
            "en": "hold-out test set, 533, 535, 540, 579, 719",
            "zh": "ä¿æŒæµ‹è¯•ä»ªï¼Œ533ã€535ã€540ã€579ã€719"
        }
    },
    {
        "translation": {
            "en": "9.1â€…â€…â€…Big Idea",
            "zh": "9.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "For example, in a banking scenario, we might include a ratio between a loan applicantâ€™s salary and the amount for which they are requesting a loan rather than including these two values themselves.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨é“¶è¡Œä¸šåŠ¡åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šåŒ…æ‹¬è´·æ¬¾ç”³è¯·äººçš„å·¥èµ„ä¸ä»–ä»¬ç”³è¯·è´·æ¬¾çš„é‡‘é¢ä¹‹é—´çš„æ¯”ç‡ï¼Œè€Œä¸æ˜¯åŒ…æ‹¬è¿™ä¸¤ä¸ªå€¼æœ¬èº«ã€‚"
        }
    },
    {
        "translation": {
            "en": "This arises from the fact that the tests carried out at each node in the tree are performed in the context of the results of the tests on the other descriptive features that were tested at the preceding nodes on the path from the root.",
            "zh": "è¿™æ˜¯å› ä¸ºåœ¨æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ‰§è¡Œçš„æµ‹è¯•æ˜¯åœ¨å¯¹å…¶ä»–æè¿°æ€§ç‰¹å¾çš„æµ‹è¯•ç»“æœçš„ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œçš„ï¼Œè¿™äº›æè¿°æ€§ç‰¹å¾åœ¨æ ¹è·¯å¾„ä¸Šçš„å…ˆå‰èŠ‚ç‚¹ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In our example, CORE-TEMP describes the core temperature of the patient (which can be low or high), and STABLE-TEMP describes whether the patientâ€™s current temperature is stable (true or false).",
            "zh": "åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼ŒCORE-TEMP æè¿°æ‚£è€…çš„æ ¸å¿ƒæ¸©åº¦ï¼ˆå¯ä½æˆ–é«˜ï¼‰ï¼ŒSTABLE-TEMP æè¿°æ‚£è€…å½“å‰æ¸©åº¦æ˜¯å¦ç¨³å®šï¼ˆçœŸæˆ–å‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Widdows (2004) provides a very readable and interesting introduction to geometry and linguistic meaning; see, in particular, Chapter 4 for an excellent introduction to similarity and distance.",
            "zh": "Widdowsï¼ˆ2004ï¼‰å¯¹å‡ ä½•å­¦å’Œè¯­è¨€æ„ä¹‰è¿›è¡Œäº†éå¸¸å¯è¯»å’Œæœ‰è¶£çš„ä»‹ç»;ç‰¹åˆ«æ˜¯ï¼Œå‚è§ç¬¬ 4 ç« ï¼Œäº†è§£ç›¸ä¼¼æ€§å’Œè·ç¦»çš„ç²¾å½©ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "-3.82398",
            "zh": "-3.82398"
        }
    },
    {
        "translation": {
            "en": "The basis of data exploration is statistics. Montgomery and Runger (2010) is an excellent applied introductory text in statistics and covers, in more detail, all the basic measures used in this chapter. It also covers advanced topics, such as the Ï‡2 test and ANOVA test mentioned in the notes for Section 3.5.2[81]. Rice (2006) provides a goodâ€”if more theoreticalâ€”treatment of statistics.",
            "zh": "æ•°æ®æ¢ç´¢çš„åŸºç¡€æ˜¯ç»Ÿè®¡ã€‚Montgomery and Runger ï¼ˆ2010ï¼‰æ˜¯ä¸€æœ¬ä¼˜ç§€çš„ç»Ÿè®¡å­¦åº”ç”¨ä»‹ç»æ€§è‘—ä½œï¼Œæ›´è¯¦ç»†åœ°æ¶µç›–äº†æœ¬ç« ä¸­ä½¿ç”¨çš„æ‰€æœ‰åŸºæœ¬æªæ–½ã€‚å®ƒè¿˜æ¶µç›–äº†é«˜çº§ä¸»é¢˜ï¼Œä¾‹å¦‚ç¬¬ 3.5.2 èŠ‚æ³¨é‡Šä¸­æåˆ°çš„ Ï‡2 æ£€éªŒå’Œæ–¹å·®åˆ†ææ£€éªŒ[81]ã€‚Riceï¼ˆ2006ï¼‰å¯¹ç»Ÿè®¡å­¦è¿›è¡Œäº†å¾ˆå¥½çš„ç†è®ºåŒ–å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "where t1â€¦tn is a set of n expected target values, and ğ•„(d1)â€¦ğ•„(dn) is a set of n predictions for a set of test instances, d1â€¦dn. We modify this very slightly to give us the mean squared error performance measure, which captures the average difference between the expected target values in the test set and the values predicted by the model. The mean squared error (MSE) performance measure is defined as",
            "zh": "å…¶ä¸­ t1...tn æ˜¯ n ä¸ªé¢„æœŸç›®æ ‡å€¼çš„é›†åˆï¼ŒMï¼ˆd1ï¼‰...Mï¼ˆdnï¼‰ æ˜¯ä¸€ç»„æµ‹è¯•å®ä¾‹çš„ n ä¸ªé¢„æµ‹ï¼Œd1...DNä¸­ã€‚æˆ‘ä»¬å¯¹æ­¤è¿›è¡Œäº†éå¸¸è½»å¾®çš„ä¿®æ”¹ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†å‡æ–¹è¯¯å·®æ€§èƒ½åº¦é‡ï¼Œè¯¥åº¦é‡æ•è·äº†æµ‹è¯•é›†ä¸­çš„é¢„æœŸç›®æ ‡å€¼ä¸æ¨¡å‹é¢„æµ‹çš„å€¼ä¹‹é—´çš„å¹³å‡å·®å¼‚ã€‚å‡æ–¹è¯¯å·® ï¼ˆMSEï¼‰ æ€§èƒ½åº¦é‡å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "While this random action selection policy is good for learning, pursuing it into the second week of Conorâ€™s stay would seem like a bad idea.",
            "zh": "è™½ç„¶è¿™ç§éšæœºè¡ŒåŠ¨é€‰æ‹©ç­–ç•¥æœ‰åˆ©äºå­¦ä¹ ï¼Œä½†å°†å…¶å»¶ç»­åˆ°åº·çº³é€—ç•™çš„ç¬¬äºŒå‘¨ä¼¼ä¹æ˜¯ä¸€ä¸ªåä¸»æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "One feature of equal-width binning is that it can result in a very uneven distribution of instances across the bins, with some bins containing a large number of instances and other bins being nearly empty.",
            "zh": "ç­‰å®½åˆ†ç®±çš„ä¸€ä¸ªç‰¹ç‚¹æ˜¯ï¼Œå®ƒå¯èƒ½å¯¼è‡´å®ä¾‹åœ¨ç®±ä¸­çš„åˆ†å¸ƒéå¸¸ä¸å‡åŒ€ï¼Œä¸€äº›ç®±åŒ…å«å¤§é‡å®ä¾‹ï¼Œè€Œå…¶ä»–ç®±å‡ ä¹æ˜¯ç©ºçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The aggregate confusion matrix, generated by summing together the corresponding cells in the individual confusion matrices for each fold, is shown at the bottom of Table 9.4[544].",
            "zh": "é€šè¿‡å°†æ¯ä¸ªæŠ˜å çš„å„ä¸ªæ··æ·†çŸ©é˜µä¸­çš„ç›¸åº”å•å…ƒæ ¼ç›¸åŠ è€Œç”Ÿæˆçš„èšåˆæ··æ·†çŸ©é˜µæ˜¾ç¤ºåœ¨è¡¨9.4[544]çš„åº•éƒ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Clamp transformation (manual: 0, 80,000)",
            "zh": "å¤¹å…·è½¬æ¢ï¼ˆæ‰‹åŠ¨ï¼š0,80,000ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The left action is the most attractive in this instance on the basis of its Q value.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå·¦è¾¹çš„åŠ¨ä½œæœ€æœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒçš„ Q å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that both these neurons happen to have large negative weights on at least one of their inputs.",
            "zh": "åŸå› æ˜¯è¿™ä¸¤ä¸ªç¥ç»å…ƒç¢°å·§åœ¨å®ƒä»¬çš„è‡³å°‘ä¸€ä¸ªè¾“å…¥ä¸Šæœ‰å¾ˆå¤§çš„è´Ÿæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the error of the network for this example using the new weights, compared with using the original weights.",
            "zh": "ä¸ä½¿ç”¨åŸå§‹æƒé‡ç›¸æ¯”ï¼Œä½¿ç”¨æ–°æƒé‡è®¡ç®—æ­¤ç¤ºä¾‹ä¸­ç½‘ç»œè¯¯å·®çš„å‡å°‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.31[480] illustrates the concept of a local receptive field in a neural network.",
            "zh": "å›¾8.31[480]è¯´æ˜äº†ç¥ç»ç½‘ç»œä¸­å±€éƒ¨æ„Ÿå—é‡çš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "This ensures that there are H neurons in the layers in these gates.",
            "zh": "è¿™ç¡®ä¿äº†è¿™äº›é—¨çš„å±‚ä¸­æœ‰ H ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The design of the ID3 algorithm is based on the assumption that a correct decision tree for a domain will classify instances from that domain in the same proportion as the target level occurs in the domain.",
            "zh": "ID3 ç®—æ³•çš„è®¾è®¡åŸºäºä»¥ä¸‹å‡è®¾ï¼šåŸŸçš„æ­£ç¡®å†³ç­–æ ‘å°†æŒ‰ç…§åŸŸä¸­ç›®æ ‡çº§åˆ«å‡ºç°çš„ç›¸åŒæ¯”ä¾‹å¯¹æ¥è‡ªè¯¥åŸŸçš„å®ä¾‹è¿›è¡Œåˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the call minutes used by the customer has changed from last month to this month",
            "zh": "å®¢æˆ·ä½¿ç”¨çš„é€šè¯åˆ†é’Ÿæ•°ä»ä¸Šä¸ªæœˆåˆ°æœ¬æœˆçš„å˜åŒ–ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "Consequently, in this schematic we have abstracted away from some of the details of a network architecture: for example, the layers of neurons are represented by rectangles with rounded corners; and the (multiple) connections between neurons in different layers are represented by single arrows labeled with the name of the weight matrix for the weights on those connections.",
            "zh": "å› æ­¤ï¼Œåœ¨è¿™ä¸ªç¤ºæ„å›¾ä¸­ï¼Œæˆ‘ä»¬æŠ½è±¡å‡ºç½‘ç»œæ¶æ„çš„ä¸€äº›ç»†èŠ‚ï¼šä¾‹å¦‚ï¼Œç¥ç»å…ƒå±‚ç”±åœ†è§’çš„çŸ©å½¢è¡¨ç¤º;ä¸åŒå±‚ä¸­ç¥ç»å…ƒä¹‹é—´çš„ï¼ˆå¤šä¸ªï¼‰è¿æ¥ç”±å•ä¸ªç®­å¤´è¡¨ç¤ºï¼Œç®­å¤´æ ‡æœ‰è¿™äº›è¿æ¥ä¸Šæƒé‡çŸ©é˜µçš„åç§°ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.6â€ƒThe Predictive Data Analytics Project Lifecycle: CRISP-DM",
            "zh": "1.6 é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ç”Ÿå‘½å‘¨æœŸï¼šCRISP-DM"
        }
    },
    {
        "translation": {
            "en": "Just like the proverbial cat, there is more than one way to skin a probability problem!",
            "zh": "å°±åƒä¼—æ‰€å‘¨çŸ¥çš„çŒ«ä¸€æ ·ï¼Œæ¦‚ç‡é—®é¢˜çš„æ–¹æ³•ä¸æ­¢ä¸€ç§ï¼"
        }
    },
    {
        "translation": {
            "en": "In order to calculate and backpropagate the Î´s for d2 through the network, we need the âˆ‚a/âˆ‚z for each neuron in the network for this example, Table 8.11[442] lists these values; because all the neurons use a rectified linear activation function, the âˆ‚a/âˆ‚z are either 0 or 1 (as per derivative of the rectified linear function given in Equation 8.43[437]).",
            "zh": "ä¸ºäº†é€šè¿‡ç½‘ç»œè®¡ç®—å’Œåå‘ä¼ æ’­ d2 çš„ Î´sï¼Œæˆ‘ä»¬éœ€è¦ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚zï¼Œè¡¨ 8.11[442] åˆ—å‡ºäº†è¿™äº›å€¼;å› ä¸ºæ‰€æœ‰çš„ç¥ç»å…ƒéƒ½ä½¿ç”¨æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæ‰€ä»¥âˆ‚a/âˆ‚zè¦ä¹ˆæ˜¯0ï¼Œè¦ä¹ˆæ˜¯1ï¼ˆæ ¹æ®ç­‰å¼8.43[437]ä¸­ç»™å‡ºçš„æ•´æµçº¿æ€§å‡½æ•°çš„å¯¼æ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, when a loan is repaid in full, the profit made by the company is usually $140.",
            "zh": "å› æ­¤ï¼Œå½“è´·æ¬¾å…¨é¢å¿è¿˜æ—¶ï¼Œå…¬å¸çš„åˆ©æ¶¦é€šå¸¸ä¸º 140 ç¾å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "However, these approaches are more complex, take a longer time to train, and are harder to interpret than the simpler approaches that we have presented.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ¯”æˆ‘ä»¬ä»‹ç»çš„æ›´ç®€å•çš„æ–¹æ³•æ›´å¤æ‚ï¼Œéœ€è¦æ›´é•¿çš„æ—¶é—´æ¥è®­ç»ƒï¼Œå¹¶ä¸”æ›´éš¾è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_U_G",
            "zh": "DEREDDIFF_U_G"
        }
    },
    {
        "translation": {
            "en": "The relationship between probability-based and information-based learning is simply that the amount of information provided by an observationâ€”such as a descriptive feature taking a particular valueâ€”is reflected in the difference between the prior and posterior probabilities caused by the observation.",
            "zh": "åŸºäºæ¦‚ç‡çš„å­¦ä¹ å’ŒåŸºäºä¿¡æ¯çš„å­¦ä¹ ä¹‹é—´çš„å…³ç³»å¾ˆç®€å•ï¼Œå³è§‚å¯Ÿæä¾›çš„ä¿¡æ¯é‡ï¼ˆä¾‹å¦‚é‡‡ç”¨ç‰¹å®šå€¼çš„æè¿°æ€§ç‰¹å¾ï¼‰åæ˜ åœ¨è§‚å¯Ÿå¼•èµ·çš„å…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡ä¹‹é—´çš„å·®å¼‚ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The gradient descent algorithm for training multivariable regression models is formally presented in Algorithm 4[326].",
            "zh": "ç”¨äºè®­ç»ƒå¤šå˜é‡å›å½’æ¨¡å‹çš„æ¢¯åº¦ä¸‹é™ç®—æ³•åœ¨ç®—æ³•4[326]ä¸­æ­£å¼æå‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "For clarity there are some extra notational conventions used in Chapter 11[637] on reinforcement learning (this chapter also heavily uses the notation from the probability chapter).",
            "zh": "ä¸ºäº†æ¸…æ¥šèµ·è§ï¼Œåœ¨ç¬¬11ç« [637]ä¸­ï¼Œå…³äºå¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨äº†ä¸€äº›é¢å¤–çš„ç¬¦å·çº¦å®šï¼ˆæœ¬ç« ä¹Ÿå¤§é‡ä½¿ç”¨äº†æ¦‚ç‡ä¸€ç« ä¸­çš„ç¬¦å·ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.4",
            "zh": "è¡¨ 6.4"
        }
    },
    {
        "translation": {
            "en": "We start off by playing a game.",
            "zh": "æˆ‘ä»¬ä»ç©æ¸¸æˆå¼€å§‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "One thing to note is that many of the rules and techniques we presented were different ways of achieving the same thingâ€”for example, we can calculate P(h) by simple counting, by summing out from a full joint probability distribution, or by using the Theorem of Total Probability.",
            "zh": "éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œæˆ‘ä»¬æå‡ºçš„è®¸å¤šè§„åˆ™å’ŒæŠ€æœ¯éƒ½æ˜¯å®ç°åŒä¸€ç›®æ ‡çš„ä¸åŒæ–¹æ³•â€”â€”ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•çš„è®¡æ•°ã€ä»å®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­æ±‚å’Œæˆ–ä½¿ç”¨æ€»æ¦‚ç‡å®šç†æ¥è®¡ç®— Pï¼ˆhï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "dot product, 216, 320, 342, 385, 773",
            "zh": "ç‚¹ç§¯ï¼Œ 216ï¼Œ 320ï¼Œ 342ï¼Œ 385ï¼Œ 773"
        }
    },
    {
        "translation": {
            "en": "Descriptive statistics provides us with a range of tools that we can use to formally measure variation and so distinguish between the sets of heights in the two basketball teams.",
            "zh": "æè¿°æ€§ç»Ÿè®¡ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç³»åˆ—å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™äº›å·¥å…·æ¥æ­£å¼æµ‹é‡å˜åŒ–ï¼Œä»è€ŒåŒºåˆ†ä¸¤æ”¯ç¯®çƒé˜Ÿçš„èº«é«˜é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "integration, 276",
            "zh": "é›†æˆï¼Œ276"
        }
    },
    {
        "translation": {
            "en": "6. The full text of the EU Treaty of Amsterdam is available at www.europa.eu/eu-law/decision-making/treaties/pdf/treaty_of_amsterdam/treaty_of_amsterdam_en.pdf.",
            "zh": "6. ã€Šæ¬§ç›Ÿé˜¿å§†æ–¯ç‰¹ä¸¹æ¡çº¦ã€‹å…¨æ–‡è§ www.europa.eu/eu-law/decision-making/treaties/pdf/treaty_of_amsterdam/treaty_of_amsterdam_en.pdfã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS and AMOUNT RECEIVED all seem to have unusually high maximum values, especially when compared to their median and 3rd quartile values.",
            "zh": "CLAIMS å’Œ AMOUNT RECEIVED ä¼¼ä¹éƒ½å…·æœ‰å¼‚å¸¸é«˜çš„æœ€å¤§å€¼ï¼Œå°¤å…¶æ˜¯ä¸å®ƒä»¬çš„ä¸­ä½æ•°å’Œç¬¬ 3 ä¸ªå››åˆ†ä½æ•°å€¼ç›¸æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. Most consumer digital cameras capture full-color images by capturing separate images on red, green, and blue imaging sensors and combining these. The colors red, green, and blue are known as photometric bands. The photometric bands captured by the SDSS imaging camera are the same as these bands; they are just defined on different parts of the spectrum.",
            "zh": "7. å¤§å¤šæ•°æ¶ˆè´¹ç±»æ•°ç ç›¸æœºé€šè¿‡åœ¨çº¢è‰²ã€ç»¿è‰²å’Œè“è‰²æˆåƒä¼ æ„Ÿå™¨ä¸Šæ•è·å•ç‹¬çš„å›¾åƒå¹¶å°†å®ƒä»¬ç»„åˆåœ¨ä¸€èµ·æ¥æ•è·å…¨å½©è‰²å›¾åƒã€‚çº¢è‰²ã€ç»¿è‰²å’Œè“è‰²è¢«ç§°ä¸ºå…‰åº¦æ³¢æ®µã€‚SDSSæˆåƒç›¸æœºæ•è·çš„å…‰åº¦æ³¢æ®µä¸è¿™äº›æ³¢æ®µç›¸åŒ;å®ƒä»¬åªæ˜¯åœ¨é¢‘è°±çš„ä¸åŒéƒ¨åˆ†å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.9",
            "zh": "è¡¨ 9.9"
        }
    },
    {
        "translation": {
            "en": "Target level imbalance typically arises through either absolute rarity or relative rarity of the minority target levels.",
            "zh": "ç›®æ ‡æ°´å¹³çš„ä¸å¹³è¡¡é€šå¸¸æ˜¯ç”±äºå°‘æ•°ç›®æ ‡æ°´å¹³çš„ç»å¯¹ç¨€æœ‰æ€§æˆ–ç›¸å¯¹ç¨€æœ‰æ€§è€Œäº§ç”Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.3073",
            "zh": "0.3073"
        }
    },
    {
        "translation": {
            "en": "Although the performance of the two-stage model was better than the performance of the simpler 5-level model, it still did a very poor job of distinguishing between the different spiral galaxy types.",
            "zh": "å°½ç®¡ä¸¤çº§æ¨¡å‹çš„æ€§èƒ½ä¼˜äºç®€å•çš„äº”çº§æ¨¡å‹ï¼Œä½†å®ƒåœ¨åŒºåˆ†ä¸åŒçš„èºæ—‹æ˜Ÿç³»ç±»å‹æ–¹é¢ä»ç„¶åšå¾—å¾ˆå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This set of domain concepts was felt to be extensive enough to cover all the characteristics that were likely to contribute to a customerâ€™s likelihood to churn and is shown in Figure 12.1[690].",
            "zh": "è¿™ç»„é¢†åŸŸæ¦‚å¿µè¢«è®¤ä¸ºè¶³å¤Ÿå¹¿æ³›ï¼Œè¶³ä»¥æ¶µç›–å¯èƒ½å¯¼è‡´å®¢æˆ·æµå¤±çš„æ‰€æœ‰ç‰¹å¾ï¼Œå¦‚å›¾ 12.1[690] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.14",
            "zh": "å›¾ 4.14"
        }
    },
    {
        "translation": {
            "en": "However, it also tells us that the scaling of the variance of z is dependent on the product nin var(W).",
            "zh": "ç„¶è€Œï¼Œå®ƒä¹Ÿå‘Šè¯‰æˆ‘ä»¬ï¼Œz æ–¹å·®çš„ç¼©æ”¾å–å†³äºä¹˜ç§¯ nin varï¼ˆWï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Lehmann et al. (2003) discusses building prediction models to perform this task.",
            "zh": "4. Lehmann et al. ï¼ˆ2003ï¼‰ è®¨è®ºäº†å»ºç«‹é¢„æµ‹æ¨¡å‹æ¥æ‰§è¡Œè¿™é¡¹ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(c) Equal-frequency binning of normally distributed data with different numbers of bins; and (d)â€“(f) the same data binned into the same number of bins using equal-width binning. The dashed lines illustrate the distribution of the original continuous feature values, and the gray boxes represent the bins.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ å…·æœ‰ä¸åŒç®±æ•°çš„æ­£æ€åˆ†å¸ƒæ•°æ®çš„ç­‰é¢‘åˆ†ç®±;ï¼ˆdï¼‰â€“ï¼ˆfï¼‰ä½¿ç”¨ç­‰å®½åˆ†ç®±å°†ç›¸åŒçš„æ•°æ®åˆ†ç®±åˆ°ç›¸åŒæ•°é‡çš„åˆ†ç®±ä¸­ã€‚è™šçº¿è¡¨ç¤ºåŸå§‹è¿ç»­è¦ç´ å€¼çš„åˆ†å¸ƒï¼Œç°è‰²æ¡†è¡¨ç¤ºæ¡æŸ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Up to this point we have outlined descriptive statistics that we can use to describe the values in a sample.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»æ¦‚è¿°äº†å¯ç”¨äºæè¿°æ ·æœ¬ä¸­å€¼çš„æè¿°æ€§ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "WEIGHT: The patientâ€™s weight",
            "zh": "ä½“é‡ï¼šæ‚£è€…çš„ä½“é‡"
        }
    },
    {
        "translation": {
            "en": "An understanding of these five equations is a strong basis for understanding the mathematical fundamentals of many areas of scientific modeling. Adding an understanding of how these five equations are used in the machine learning algorithms we have described (ID3, k nearest neighbor, multivariable linear regression with gradient descent, naive Bayes, and the backpropagation of error algorithm) is a strong foundation on which to build a career in predictive data analytics.",
            "zh": "å¯¹è¿™äº”ä¸ªæ–¹ç¨‹çš„ç†è§£æ˜¯ç†è§£ç§‘å­¦å»ºæ¨¡è®¸å¤šé¢†åŸŸçš„æ•°å­¦åŸºç¡€çš„åšå®åŸºç¡€ã€‚äº†è§£è¿™äº”ä¸ªæ–¹ç¨‹åœ¨æˆ‘ä»¬æè¿°çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¸­çš„ä½¿ç”¨æ–¹å¼ï¼ˆID3ã€k æœ€è¿‘é‚»ã€æ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’ã€æœ´ç´ è´å¶æ–¯å’Œè¯¯å·®ç®—æ³•çš„åå‘ä¼ æ’­ï¼‰æ˜¯å»ºç«‹é¢„æµ‹æ•°æ®åˆ†æèŒä¸šç”Ÿæ¶¯çš„åšå®åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROR50_U/G/R/I/Z",
            "zh": "PETROR50_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This allows us an important reformulation of the chain rule for situations in which conditional independence applies. Recall that the chain rule for calculating the probability that a set of descriptive features, q[1],â€¦,q[m], takes a specific set of values when a target feature, t, takes a specific level, l, is",
            "zh": "è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹é€‚ç”¨æ¡ä»¶ç‹¬ç«‹æ€§çš„æƒ…å†µçš„è¿é”è§„åˆ™è¿›è¡Œé‡è¦çš„é‡æ–°è¡¨è¿°ã€‚å›æƒ³ä¸€ä¸‹ï¼Œå½“ç›®æ ‡ç‰¹å¾ t é‡‡ç”¨ç‰¹å®šæ°´å¹³ l æ—¶ï¼Œç”¨äºè®¡ç®—ä¸€ç»„æè¿°æ€§ç‰¹å¾ q[1],...,q[m] é‡‡ç”¨ç‰¹å®šå€¼çš„æ¦‚ç‡çš„é“¾å¼æ³•åˆ™"
        }
    },
    {
        "translation": {
            "en": "For all the remaining hidden layers in this network nin = 100, and so this process of scaling the variance of z by 100 Ã— 0.0001 = 0.01 will continue through each of the subsequent hidden layers in this network.",
            "zh": "å¯¹äºæ­¤ç½‘ç»œä¸­æ‰€æœ‰å‰©ä½™çš„éšè—å±‚ï¼Œnin = 100ï¼Œå› æ­¤å°† z çš„æ–¹å·®ç¼©æ”¾ 100 Ã— 0.0001 = 0.01 çš„è¿‡ç¨‹å°†ç»§ç»­é€šè¿‡è¯¥ç½‘ç»œä¸­çš„æ¯ä¸ªåç»­éšè—å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "As this example shows, if a neuron k uses the logistic function as its activation function, then we can calculate the term âˆ‚ak/âˆ‚zk by simply inputting the weighted sum for the neuron zk into Equation (8.15)[408].",
            "zh": "å¦‚è¿™ä¸ªä¾‹å­æ‰€ç¤ºï¼Œå¦‚æœç¥ç»å…ƒ k ä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºå…¶æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°å°†ç¥ç»å…ƒ zk çš„åŠ æƒå’Œè¾“å…¥æ–¹ç¨‹ ï¼ˆ8.15ï¼‰[408] æ¥è®¡ç®—é¡¹ âˆ‚ak/âˆ‚zkã€‚"
        }
    },
    {
        "translation": {
            "en": "7. The full discussion of these principles is available at www.oecd.org/sti/ieconomy/privacy.htm.",
            "zh": "7. æœ‰å…³è¿™äº›åŸåˆ™çš„å®Œæ•´è®¨è®ºï¼Œè¯·è§ www.oecd.org/sti/ieconomy/privacy.htmã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.1",
            "zh": "å›¾ A.1"
        }
    },
    {
        "translation": {
            "en": "0.157248",
            "zh": "0.157248"
        }
    },
    {
        "translation": {
            "en": "Figure 7.5",
            "zh": "å›¾ 7.5"
        }
    },
    {
        "translation": {
            "en": "The most common issues in this regard are missing values and outliers, which are both examples of noise in the data.",
            "zh": "è¿™æ–¹é¢æœ€å¸¸è§çš„é—®é¢˜æ˜¯ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œå®ƒä»¬éƒ½æ˜¯æ•°æ®ä¸­å™ªå£°çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Batch gradient descent14 involves calculating the error gradients for each weight for all the examples in a dataset and summing the gradients for each weight, and only then updating the weights using the summed error gradients calculated over the entire dataset.",
            "zh": "æ‰¹é‡æ¢¯åº¦ä¸‹é™14 æ¶‰åŠè®¡ç®—æ•°æ®é›†ä¸­æ‰€æœ‰ç¤ºä¾‹çš„æ¯ä¸ªæƒé‡çš„è¯¯å·®æ¢¯åº¦ï¼Œå¹¶å°†æ¯ä¸ªæƒé‡çš„æ¢¯åº¦æ±‚å’Œï¼Œç„¶åæ‰ä½¿ç”¨åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—çš„è¯¯å·®æ¢¯åº¦æ±‚å’Œæ¥æ›´æ–°æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the input gate has two paths of processing means that it uses two separate weight matrices to process the input, one on each processing path.",
            "zh": "è¾“å…¥é—¨æœ‰ä¸¤æ¡å¤„ç†è·¯å¾„ï¼Œè¿™æ„å‘³ç€å®ƒä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„æƒé‡çŸ©é˜µæ¥å¤„ç†è¾“å…¥ï¼Œæ¯ä¸ªå¤„ç†è·¯å¾„ä¸Šä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "8.26â€…â€…â€…The internal dynamics of the network in Figure 8.22[450], using ReLUs, during the first training iteration when the weights were initialized using He initialization.",
            "zh": "8.26 å›¾ 8.22[450] ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œä½¿ç”¨ ReLU åœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨ He åˆå§‹åŒ–è¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The set of random variables in a domain maps to the set of features in a dataset (both descriptive and target). DICE1 and DICE2 are the equivalent of random variables.",
            "zh": "åŸŸä¸­çš„éšæœºå˜é‡é›†æ˜ å°„åˆ°æ•°æ®é›†ä¸­çš„è¦ç´ é›†ï¼ˆæè¿°æ€§å’Œç›®æ ‡æ€§ï¼‰ã€‚DICE1 å’Œ DICE2 ç­‰ä»·äºéšæœºå˜é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "kernel function, 366, 373",
            "zh": "å†…æ ¸å‡½æ•°ï¼Œ366,373"
        }
    },
    {
        "translation": {
            "en": "8.5â€…â€…â€…The âˆ‚a/âˆ‚z for each neuron for Example 2 rounded to four decimal places.",
            "zh": "8.5 ä¾‹ 2 ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚z å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second equation defines how we compute the entropy remaining after we partition the dataset using a particular descriptive feature d. When we partition the dataset using the descriptive feature d, we create a number of partitions (or sets) d=l1â€¦d=lk, where l1â€¦lk are the k levels that feature d can take.",
            "zh": "ç¬¬äºŒä¸ªæ–¹ç¨‹å®šä¹‰äº†æˆ‘ä»¬å¦‚ä½•è®¡ç®—ä½¿ç”¨ç‰¹å®šæè¿°æ€§ç‰¹å¾ d å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºåçš„å‰©ä½™ç†µã€‚å½“æˆ‘ä»¬ä½¿ç”¨æè¿°æ€§ç‰¹å¾ d å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºæ—¶ï¼Œæˆ‘ä»¬ä¼šåˆ›å»ºè®¸å¤šåˆ†åŒºï¼ˆæˆ–é›†åˆï¼‰d=l1...d=lkï¼Œå…¶ä¸­ l1...LK æ˜¯åŠŸèƒ½ D å¯ä»¥é‡‡ç”¨çš„ K çº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.9[270] illustrates how a naive Bayes model would calculate the scores for each candidate target level for this query using the smoothed probabilities from Table 6.8[269]. Using our smoothed probabilities, we are able to calculate a score for both target levels: 0.0036 for true and 0.0043 for false. The target level false has the highest score (if only marginally) and is the MAP prediction for this query. Therefore, our naive Bayes model will predict that this loan application is not fraudulent.",
            "zh": "è¡¨6.9[270]è¯´æ˜äº†æœ´ç´ è´å¶æ–¯æ¨¡å‹å¦‚ä½•ä½¿ç”¨è¡¨6.8[269]ä¸­çš„å¹³æ»‘æ¦‚ç‡è®¡ç®—æ­¤æŸ¥è¯¢çš„æ¯ä¸ªå€™é€‰ç›®æ ‡æ°´å¹³çš„åˆ†æ•°ã€‚ä½¿ç”¨æˆ‘ä»¬çš„å¹³æ»‘æ¦‚ç‡ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè®¡ç®—å‡ºä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°ï¼š0.0036 è¡¨ç¤ºçœŸå€¼ï¼Œ0.0043 è¡¨ç¤ºå‡å€¼ã€‚ç›®æ ‡çº§åˆ« false çš„å¾—åˆ†æœ€é«˜ï¼ˆå¦‚æœåªæ˜¯ç•¥å¾®ï¼‰ï¼Œå¹¶ä¸”æ˜¯æ­¤æŸ¥è¯¢çš„ MAP é¢„æµ‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹è¯¥è´·æ¬¾ç”³è¯·ä¸æ˜¯æ¬ºè¯ˆæ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "information-based learning, 19, 117",
            "zh": "åŸºäºä¿¡æ¯çš„å­¦ä¹ ï¼Œ 19ï¼Œ 117"
        }
    },
    {
        "translation": {
            "en": "Such a network configuration is likely to result in the network overfitting the training data (i.e., memorizing all the training examples, including the noise, rather than learning the general patterns in the data).",
            "zh": "è¿™æ ·çš„ç½‘ç»œé…ç½®å¯èƒ½ä¼šå¯¼è‡´ç½‘ç»œè¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼ˆå³ï¼Œè®°ä½æ‰€æœ‰è®­ç»ƒç¤ºä¾‹ï¼ŒåŒ…æ‹¬å™ªå£°ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ•°æ®ä¸­çš„ä¸€èˆ¬æ¨¡å¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although we canâ€™t easily draw feature spaces beyond three dimensions, the ideas underpinning them remain the same.",
            "zh": "å°½ç®¡æˆ‘ä»¬ä¸èƒ½è½»æ˜“åœ°ç»˜åˆ¶ä¸‰ç»´ä»¥å¤–çš„ç‰¹å¾ç©ºé—´ï¼Œä½†æ”¯æ’‘å®ƒä»¬çš„æƒ³æ³•ä¿æŒä¸å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A 3D surface plot and (b) a birdâ€™s-eye view contour plot of the error surface for the office rentals dataset showing the path that the gradient descent algorithm takes toward the best-fit model.",
            "zh": "ï¼ˆaï¼‰ åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„ 3D è¡¨é¢å›¾å’Œ ï¼ˆbï¼‰ è¯¯å·®è¡¨é¢çš„é¸Ÿç°è§†å›¾ç­‰å€¼çº¿å›¾ï¼Œæ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™ç®—æ³•é€šå¾€æœ€ä½³æ‹Ÿåˆæ¨¡å‹çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instances d1 and d9 are duplicated in this sample, and instances d3 and d10 are not included at all.",
            "zh": "æ­¤ç¤ºä¾‹ä¸­é‡å¤äº†å®ä¾‹ d1 å’Œ d9ï¼Œå®Œå…¨ä¸åŒ…æ‹¬å®ä¾‹ d3 å’Œ d10ã€‚"
        }
    },
    {
        "translation": {
            "en": "inverted dropout, 474, 475, 530",
            "zh": "å€’ç½®å‹å·®ï¼Œ474ã€475ã€530"
        }
    },
    {
        "translation": {
            "en": "There are no labels, so this data is being clustered in an attempt to recognize different activity from this simple data stream.",
            "zh": "æ²¡æœ‰æ ‡ç­¾ï¼Œå› æ­¤æ­£åœ¨å¯¹è¿™äº›æ•°æ®è¿›è¡Œèšç±»ï¼Œä»¥å°è¯•ä»è¿™ä¸ªç®€å•çš„æ•°æ®æµä¸­è¯†åˆ«ä¸åŒçš„æ´»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The class conditional densities for two classes (l1,l2) with a single descriptive feature d. The height of each curve reflects the density of the instances from that class for that value of d. (b) The class posterior probabilities plotted for each class for different values of d. Notice that the class posterior probability P(t = l1|d) is not affected by the multimodal structure of the corresponding class conditional density P(d|t = l1).",
            "zh": "ï¼ˆaï¼‰ å…·æœ‰å•ä¸ªæè¿°æ€§ç‰¹å¾ d çš„ä¸¤ä¸ªç±» ï¼ˆl1ï¼Œl2ï¼‰ çš„ç±»æ¡ä»¶å¯†åº¦ã€‚æ¯æ¡æ›²çº¿çš„é«˜åº¦åæ˜ äº†è¯¥ç±»ä¸­è¯¥ d å€¼çš„å®ä¾‹çš„å¯†åº¦ã€‚ ï¼ˆbï¼‰ é’ˆå¯¹ä¸åŒçš„ d å€¼ä¸ºæ¯ä¸ªç±»ç»˜åˆ¶çš„ç±»åéªŒæ¦‚ç‡ã€‚è¯·æ³¨æ„ï¼Œç±»åéªŒæ¦‚ç‡ Pï¼ˆt = l1|dï¼‰ ä¸å—ç›¸åº”ç±»æ¡ä»¶å¯†åº¦ Pï¼ˆd|t = l1ï¼‰ çš„å¤šæ¨¡æ€ç»“æ„çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Other approaches to efficient memory access have been developed, for example, locality sensitivity hashing, R-Trees, B-Trees, M-Trees, and VoRTrees, among others.",
            "zh": "å·²ç»å¼€å‘äº†å…¶ä»–é«˜æ•ˆå†…å­˜è®¿é—®çš„æ–¹æ³•ï¼Œä¾‹å¦‚å±€éƒ¨æ•æ„Ÿåº¦å“ˆå¸Œã€R æ ‘ã€B æ ‘ã€M æ ‘å’Œ VoRTrees ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The samples have then been manually categorized by clinicians as either benign or malignant.19 The descriptive features in this dataset are defined as follows:",
            "zh": "ç„¶åï¼Œä¸´åºŠåŒ»ç”Ÿæ‰‹åŠ¨å°†æ ·æœ¬åˆ†ç±»ä¸ºè‰¯æ€§æˆ–æ¶æ€§.19 è¯¥æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Business Understanding, 16, 19, 24, 28, 46, 685, 704, 730",
            "zh": "å•†ä¸šç†è§£ï¼Œ 16ï¼Œ 19ï¼Œ 24ï¼Œ 28ï¼Œ 46ï¼Œ 685ï¼Œ 704ï¼Œ 730"
        }
    },
    {
        "translation": {
            "en": "Table 8.14",
            "zh": "è¡¨ 8.14"
        }
    },
    {
        "translation": {
            "en": "kernel trick, 366, 373",
            "zh": "å†…æ ¸æŠ€å·§ï¼Œ366,373"
        }
    },
    {
        "translation": {
            "en": "The reason is that to ensure that the weight updates for all the weights on the network are on a similar scale.",
            "zh": "åŸå› æ˜¯è¦ç¡®ä¿ç½‘ç»œä¸Šæ‰€æœ‰æƒé‡çš„æƒé‡æ›´æ–°éƒ½å¤„äºç›¸ä¼¼çš„æ¯”ä¾‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This vanishing z values dynamic is a result of the fact that the z values are calculated using a weighted sum, and in this network configuration the relationship between the number of inputs to each weighted sum and the variances of the weights is such that the variance of the z values is scaled down at each layer in the network.",
            "zh": "è¿™ç§ z å€¼çš„åŠ¨æ€æ¶ˆå¤±æ˜¯ç”±äº z å€¼æ˜¯ä½¿ç”¨åŠ æƒå’Œè®¡ç®—çš„ï¼Œå¹¶ä¸”åœ¨æ­¤ç½‘ç»œé…ç½®ä¸­ï¼Œæ¯ä¸ªåŠ æƒå’Œçš„è¾“å…¥æ•°ä¸æƒé‡æ–¹å·®ä¹‹é—´çš„å…³ç³»ä½¿å¾— z å€¼çš„æ–¹å·®åœ¨ç½‘ç»œä¸­çš„æ¯ä¸€å±‚éƒ½æŒ‰æ¯”ä¾‹ç¼©å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.13â€…â€…â€…An example validation set for the post-operative patient routing task.",
            "zh": "4.13 æœ¯åæ‚£è€…è·¯ç”±ä»»åŠ¡çš„ç¤ºä¾‹éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "true negative, 537",
            "zh": "çœŸé˜´æ€§ï¼Œ537"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, Brian. 2009. Agent based modeling in computer graphics and games. In Encyclopedia of complexity andsystems science, ed. R. A. Meyers. Dublin Institute of Technology.",
            "zh": "éº¦å…‹Â·çº³æ¢…ï¼Œå¸ƒè±æ©ã€‚2009. è®¡ç®—æœºå›¾å½¢å­¦å’Œæ¸¸æˆä¸­åŸºäºæ™ºèƒ½ä½“çš„å»ºæ¨¡.åœ¨å¤æ‚æ€§å’Œç³»ç»Ÿç§‘å­¦ç™¾ç§‘å…¨ä¹¦ä¸­ï¼ŒR. A. Meyersç¼–è¾‘ã€‚éƒ½æŸæ—ç†å·¥å­¦é™¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "An event is any subset of an experiment. An event may describe an assignment of values to all the features in the domain (e.g., a full row in the dataset) or an assignment to one or more features in the domain. DICE1 = is an example of an event. DICE1 = , DICE2 = is also an event.",
            "zh": "äº‹ä»¶æ˜¯å®éªŒçš„ä»»ä½•å­é›†ã€‚äº‹ä»¶å¯ä»¥æè¿°å¯¹åŸŸä¸­æ‰€æœ‰è¦ç´ çš„å€¼åˆ†é…ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®é›†ä¸­çš„ä¸€æ•´è¡Œï¼‰æˆ–å¯¹åŸŸä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªè¦ç´ çš„èµ‹å€¼ã€‚DICE1 = æ˜¯äº‹ä»¶çš„ç¤ºä¾‹ã€‚DICE1 = ï¼Œ DICE2 = ä¹Ÿæ˜¯ä¸€ä¸ªäº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The course â€œP.D.A.",
            "zh": "è¯¾ç¨‹â€œP.D.A."
        }
    },
    {
        "translation": {
            "en": "Prediction speed: How quickly can a model make predictions?",
            "zh": "é¢„æµ‹é€Ÿåº¦ï¼šæ¨¡å‹åšå‡ºé¢„æµ‹çš„é€Ÿåº¦æœ‰å¤šå¿«ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Individuals can belong to one of three states: SUSCEPTIBLE, INFECTED, or RECOVERED (these are often referred to as S-I-R models).",
            "zh": "ä¸ªä½“å¯ä»¥å±äºä»¥ä¸‹ä¸‰ç§çŠ¶æ€ä¹‹ä¸€ï¼šæ˜“æ„Ÿã€æ„ŸæŸ“æˆ–åº·å¤ï¼ˆè¿™äº›é€šå¸¸ç§°ä¸º S-I-R æ¨¡å‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The expansion of the sum of squared errors loss function, L2, that we gave in Equation (7.5)[316] changes slightly to reflect the new regression equation",
            "zh": "æˆ‘ä»¬åœ¨æ–¹ç¨‹ï¼ˆ7.5ï¼‰[316]ä¸­ç»™å‡ºçš„å¹³æ–¹è¯¯å·®æŸå¤±å‡½æ•°å’Œçš„å±•å¼€ç•¥æœ‰å˜åŒ–ï¼Œä»¥åæ˜ æ–°çš„å›å½’æ–¹ç¨‹"
        }
    },
    {
        "translation": {
            "en": "This model is said to underfit the data as it is not complex enough to fully capture the relationship between the descriptive feature and the target feature.",
            "zh": "æ®è¯´è¯¥æ¨¡å‹å¯¹æ•°æ®æ‹Ÿåˆä¸è¶³ï¼Œå› ä¸ºå®ƒä¸å¤Ÿå¤æ‚ï¼Œæ— æ³•å®Œå…¨æ•è·æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.16â€…â€…â€…The coordinate systems defined by the Mahalanobis distance using the covariance matrix for the dataset in Figure 5.15(c)[219] using three different origins: (a) (50, 50); (b) (63,71); and (c) (42, 35). The ellipses in each figure plot the 1, 3, and 5 unit distance contours.",
            "zh": "5.16 ä½¿ç”¨å›¾5.15ï¼ˆcï¼‰[219]ä¸­æ•°æ®é›†çš„åæ–¹å·®çŸ©é˜µå®šä¹‰çš„é©¬æ°è·ç¦»çš„åæ ‡ç³»ï¼Œä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„åŸç‚¹ï¼šï¼ˆaï¼‰ï¼ˆ50,50ï¼‰;ï¼ˆbï¼‰ï¼ˆ63,71ï¼‰;ä»¥åŠï¼ˆcï¼‰ï¼ˆ42ã€35ï¼‰ã€‚æ¯ä¸ªå›¾ä¸­çš„æ¤­åœ†ç»˜åˆ¶äº† 1ã€3 å’Œ 5 å•ä½è·ç¦»ç­‰å€¼çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that even though the network is unrolled through three time-steps, it still has only 3 weight matrices (not 9).",
            "zh": "è¿™æ„å‘³ç€å³ä½¿ç½‘ç»œé€šè¿‡ä¸‰ä¸ªæ—¶é—´æ­¥é•¿å±•å¼€ï¼Œå®ƒä»ç„¶åªæœ‰ 3 ä¸ªæƒé‡çŸ©é˜µï¼ˆè€Œä¸æ˜¯ 9 ä¸ªï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data Understanding: Once the manner in which predictive data analytics will be used to address a business problem has been decided, it is important that the data analyst fully understand the different data sources available within an organization and the different kinds of data that are contained in these sources.",
            "zh": "æ•°æ®ç†è§£ï¼šä¸€æ—¦ç¡®å®šäº†ä½¿ç”¨é¢„æµ‹æ•°æ®åˆ†ææ¥è§£å†³ä¸šåŠ¡é—®é¢˜çš„æ–¹å¼ï¼Œæ•°æ®åˆ†æå¸ˆå°±å¿…é¡»å……åˆ†äº†è§£ç»„ç»‡å†…å¯ç”¨çš„ä¸åŒæ•°æ®æºä»¥åŠè¿™äº›æºä¸­åŒ…å«çš„ä¸åŒç±»å‹çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Edwin agreed that it was likely that correlations existed between measurements in the different photometric bands but stressed, however, that differences across these bands would exist and might be quite important in predicting galaxy morphology.",
            "zh": "åŸƒå¾·æ¸©åŒæ„ä¸åŒå…‰åº¦æ³¢æ®µçš„æµ‹é‡ç»“æœä¹‹é—´å¯èƒ½å­˜åœ¨ç›¸å…³æ€§ï¼Œä½†ä»–å¼ºè°ƒï¼Œè¿™äº›æ³¢æ®µä¹‹é—´çš„å·®å¼‚å°†å­˜åœ¨ï¼Œå¹¶ä¸”å¯èƒ½åœ¨é¢„æµ‹æ˜Ÿç³»å½¢æ€æ–¹é¢éå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, we may have to use some proxy features to capture something that is closely related to a domain concept when direct measurement is not possible.",
            "zh": "æ­¤å¤–ï¼Œå½“æ— æ³•ç›´æ¥æµ‹é‡æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¸å¾—ä¸ä½¿ç”¨ä¸€äº›ä»£ç†ç‰¹å¾æ¥æ•è·ä¸é¢†åŸŸæ¦‚å¿µå¯†åˆ‡ç›¸å…³çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The important characteristic of this test set was that it was not used in the process of training the model.",
            "zh": "è¯¥æµ‹è¯•é›†çš„é‡è¦ç‰¹å¾æ˜¯ï¼Œåœ¨è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ä¸­æ²¡æœ‰ä½¿ç”¨å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.3",
            "zh": "è¡¨ 9.3"
        }
    },
    {
        "translation": {
            "en": "-0.189800",
            "zh": "-0.189800"
        }
    },
    {
        "translation": {
            "en": "To illustrate the effect that switching to a rectified linear activation function has on a network, we step through the forward and backward pass of the backpropagation algorithm for d2.",
            "zh": "ä¸ºäº†è¯´æ˜åˆ‡æ¢åˆ°æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°å¯¹ç½‘ç»œçš„å½±å“ï¼Œæˆ‘ä»¬é€æ­¥ä»‹ç»äº† d2 çš„åå‘ä¼ æ’­ç®—æ³•çš„å‰å‘å’Œåå‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.13[90] illustrates the effect of using different numbers of bins.11 In this example, the dashed line represents a multimodal distribution from which a set of continuous feature values has been generated.",
            "zh": "å›¾ 3.13[90] è¯´æ˜äº†ä½¿ç”¨ä¸åŒæ•°é‡çš„æ¡æŸ±çš„æ•ˆæœ.11 åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè™šçº¿è¡¨ç¤ºå¤šæ¨¡æ€åˆ†å¸ƒï¼Œä»ä¸­ç”Ÿæˆäº†ä¸€ç»„è¿ç»­ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these cases the error gradients are able to be backpropagated through the neuron without scaling.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè¯¯å·®æ¢¯åº¦èƒ½å¤Ÿåœ¨ç¥ç»å…ƒä¸­åå‘ä¼ æ’­è€Œä¸ä¼šç¼©æ”¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The function f(x) = 2x + 3 is known as a linear function because the output is a combination of only additions and multiplications1 involving x.",
            "zh": "å‡½æ•° fï¼ˆxï¼‰ = 2x + 3 è¢«ç§°ä¸ºçº¿æ€§å‡½æ•°ï¼Œå› ä¸ºè¾“å‡ºä»…æ˜¯æ¶‰åŠ x çš„åŠ æ³•å’Œä¹˜æ³•1 çš„ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Other algorithms, such as the nearest neighbor algorithm, which use all the descriptive features when making a prediction, are particularly sensitive to the curse.",
            "zh": "å…¶ä»–ç®—æ³•ï¼Œä¾‹å¦‚æœ€è¿‘é‚»ç®—æ³•ï¼Œåœ¨è¿›è¡Œé¢„æµ‹æ—¶ä½¿ç”¨æ‰€æœ‰æè¿°æ€§ç‰¹å¾ï¼Œå¯¹è¯…å’’ç‰¹åˆ«æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, stochastic gradient descent still works because generally descending the error gradient on an individual example will move the weight in a similar direction as descending the gradient over the entire dataset.",
            "zh": "é€šå¸¸ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ä»ç„¶æœ‰æ•ˆï¼Œå› ä¸ºé€šå¸¸å¯¹å•ä¸ªç¤ºä¾‹çš„è¯¯å·®æ¢¯åº¦è¿›è¡Œé™åºä¼šä½¿æƒé‡å‘ä¸åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šé™åºç±»ä¼¼çš„æ–¹å‘ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, the performance measured on this test set should be a good indicator of how well the model will perform on future unseen data for which it will be used to make predictions after deployment.",
            "zh": "å› æ­¤ï¼Œåœ¨æ­¤æµ‹è¯•é›†ä¸Šæµ‹é‡çš„æ€§èƒ½åº”è¯¥æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ ‡ï¼Œè¡¨æ˜æ¨¡å‹åœ¨æœªæ¥çœ‹ä¸è§çš„æ•°æ®ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼Œè¿™äº›æ•°æ®å°†åœ¨éƒ¨ç½²åç”¨äºè¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "During a trial period, half of the patients, the treatment group, are given the new drug, and the other half, the control group, are given a placebo (essentially a fake drug that has no actual medical effect).",
            "zh": "åœ¨è¯•éªŒæœŸé—´ï¼Œä¸€åŠçš„æ‚£è€…ï¼ˆæ²»ç–—ç»„ï¼‰æœç”¨æ–°è¯ï¼Œå¦ä¸€åŠï¼ˆå¯¹ç…§ç»„ï¼‰æœç”¨å®‰æ…°å‰‚ï¼ˆæœ¬è´¨ä¸Šæ˜¯ä¸€ç§æ²¡æœ‰å®é™…åŒ»ç–—æ•ˆæœçš„å‡è¯ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a rough rule of thumb, we should have around 2m instances for m descriptive features.",
            "zh": "ä½œä¸ºä¸€ä¸ªç²—ç•¥çš„ç»éªŒæ³•åˆ™ï¼Œæˆ‘ä»¬åº”è¯¥æœ‰å¤§çº¦ 2m ä¸ªå®ä¾‹æ¥æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "valid data, 63, 94",
            "zh": "æœ‰æ•ˆæ•°æ®ï¼Œ 63ï¼Œ 94"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m descriptive features, d[1]â€¦d[m], and w[0]â€¦w[m] are (m + 1) weights. We can make Equation (7.8)[320] look a little neater by inventing a dummy descriptive feature, d[0], that is always equal to 1. This then gives us",
            "zh": "å…¶ä¸­ d æ˜¯ m æè¿°æ€§ç‰¹å¾çš„å‘é‡ï¼Œd[1]...d[m] å’Œ w[0]...w[m] æ˜¯ ï¼ˆm + 1ï¼‰ æƒé‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘æ˜ä¸€ä¸ªå§‹ç»ˆç­‰äº 1 çš„è™šæ‹Ÿæè¿°ç‰¹å¾ d[0] æ¥ä½¿æ–¹ç¨‹ ï¼ˆ7.8ï¼‰[320] çœ‹èµ·æ¥æ›´æ•´æ´ä¸€äº›ã€‚è¿™ç»™äº†æˆ‘ä»¬"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm for building decision trees and the gradient descent algorithm for building regression models are two examples of this type of approach.",
            "zh": "ç”¨äºæ„å»ºå†³ç­–æ ‘çš„ ID3 ç®—æ³•å’Œç”¨äºæ„å»ºå›å½’æ¨¡å‹çš„æ¢¯åº¦ä¸‹é™ç®—æ³•æ˜¯æ­¤ç±»æ–¹æ³•çš„ä¸¤ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is much simpler to construct a Bayesian network using a hybrid approach, where the topology of the network is given to the learning algorithm, and the learning task involves inducing the CPT entries from the data.",
            "zh": "ä½¿ç”¨æ··åˆæ–¹æ³•æ„å»ºè´å¶æ–¯ç½‘ç»œè¦ç®€å•å¾—å¤šï¼Œå…¶ä¸­ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„è¢«èµ‹äºˆå­¦ä¹ ç®—æ³•ï¼Œå­¦ä¹ ä»»åŠ¡æ¶‰åŠä»æ•°æ®ä¸­è¯±å¯¼å‡º CPT æ¡ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The alarm on your house is designed to be triggered if a burglar breaks into your house, but sometimes it can be set off by your cat coming into the house, and sometimes it might not be triggered even if a burglar breaks in (it could be faulty or the burglar might be very good).",
            "zh": "æ‚¨å®¶çš„è­¦æŠ¥å™¨è®¾è®¡ä¸ºåœ¨çªƒè´¼é—¯å…¥æ‚¨çš„æˆ¿å­æ—¶è§¦å‘ï¼Œä½†æœ‰æ—¶å®ƒå¯ä»¥è¢«æ‚¨çš„çŒ«è¿›å…¥æˆ¿å±‹å¼•å‘ï¼Œæœ‰æ—¶å³ä½¿çªƒè´¼é—¯å…¥ä¹Ÿå¯èƒ½ä¸ä¼šè¢«è§¦å‘ï¼ˆå®ƒå¯èƒ½æœ‰æ•…éšœæˆ–çªƒè´¼å¯èƒ½éå¸¸å¥½ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Q-learning is referred to as off-policy learning, as when the update to the value function is made the behavior policy (for example, Îµ-greedy action selection) to select the action used to calculate the expected future return. Rather, the agent uses a greedy policyâ€”it is assumed that the agent will always take the best possible next action (based on the current action-value table). This leads Q-learning to be optimistic about what will happen in the future.",
            "zh": "Q-learningè¢«ç§°ä¸ºéç­–ç•¥å­¦ä¹ ï¼Œå› ä¸ºå½“å¯¹ä»·å€¼å‡½æ•°è¿›è¡Œæ›´æ–°æ—¶ï¼Œè¡Œä¸ºç­–ç•¥ï¼ˆä¾‹å¦‚ï¼ŒÎµè´ªå©ªè¡Œä¸ºé€‰æ‹©ï¼‰é€‰æ‹©ç”¨äºè®¡ç®—é¢„æœŸæœªæ¥å›æŠ¥çš„è¡ŒåŠ¨ã€‚ç›¸åï¼Œä»£ç†ä½¿ç”¨è´ªå©ªç­–ç•¥ - å‡è®¾ä»£ç†å°†å§‹ç»ˆé‡‡å–æœ€ä½³çš„ä¸‹ä¸€æ­¥æ“ä½œï¼ˆåŸºäºå½“å‰æ“ä½œå€¼è¡¨ï¼‰ã€‚è¿™å¯¼è‡´Q-learningå¯¹æœªæ¥å‘ç”Ÿçš„äº‹æƒ…æŒä¹è§‚æ€åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have also simplified the RGB values to be only 1s or 0s, and similarly we have selected values for the filter weight that, hopefully, make it easier to follow the flow of the data processing (rather than filter values that encode meaningful feature detectors).",
            "zh": "æˆ‘ä»¬è¿˜å°† RGB å€¼ç®€åŒ–ä¸ºä»…ä¸º 1 æˆ– 0ï¼ŒåŒæ ·ï¼Œæˆ‘ä»¬é€‰æ‹©äº†æ»¤æ³¢å™¨æƒé‡å€¼ï¼Œå¸Œæœ›èƒ½å¤Ÿæ›´è½»æ¾åœ°è·Ÿè¸ªæ•°æ®å¤„ç†æµç¨‹ï¼ˆè€Œä¸æ˜¯ç¼–ç æœ‰æ„ä¹‰çš„ç‰¹å¾æ£€æµ‹å™¨çš„æ»¤æ³¢å™¨å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.15[219] illustrates why this is important.",
            "zh": "å›¾5.15[219]è¯´æ˜äº†ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Figure 3.13(c)[90] illustrates what happens when we used 60 bins.",
            "zh": "æœ€åï¼Œå›¾ 3.13ï¼ˆcï¼‰[90] è¯´æ˜äº†å½“æˆ‘ä»¬ä½¿ç”¨ 60 ä¸ªç®±å­æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "It is paramount that, when tasked with creating a predictive model, we fully understand the business problem that this model is being constructed to address and ensure that it does address it.",
            "zh": "è‡³å…³é‡è¦çš„æ˜¯ï¼Œåœ¨åˆ›å»ºé¢„æµ‹æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å®Œå…¨äº†è§£æ„å»ºè¯¥æ¨¡å‹æ‰€è¦è§£å†³çš„ä¸šåŠ¡é—®é¢˜ï¼Œå¹¶ç¡®ä¿å®ƒç¡®å®è§£å†³äº†å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks use a graph-based representation to encode the structural relationships (such as direct influence and conditional independence) between subsets of features in a domain.",
            "zh": "è´å¶æ–¯ç½‘ç»œä½¿ç”¨åŸºäºå›¾çš„è¡¨ç¤ºæ¥ç¼–ç åŸŸä¸­ç‰¹å¾å­é›†ä¹‹é—´çš„ç»“æ„å…³ç³»ï¼ˆä¾‹å¦‚ç›´æ¥å½±å“å’Œæ¡ä»¶ç‹¬ç«‹æ€§ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross learned that AT had reasonably sophisticated transactional systems for recording recent call activity and billing information.",
            "zh": "Ross äº†è§£åˆ°ï¼ŒAT æ‹¥æœ‰ç›¸å½“å¤æ‚çš„äº¤æ˜“ç³»ç»Ÿï¼Œç”¨äºè®°å½•æœ€è¿‘çš„å‘¼å«æ´»åŠ¨å’Œè®¡è´¹ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Models",
            "zh": "æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "The reasonably large dataset that Ross had to begin with, which in turn led to a reasonably large validation partition, meant that reduced error pruning was appropriate in this case.9 Figure 12.5[699] shows the tree resulting from this training iteration.",
            "zh": "Ross å¿…é¡»ä»ç›¸å½“å¤§çš„æ•°æ®é›†å¼€å§‹ï¼Œè¿™åè¿‡æ¥åˆå¯¼è‡´äº†ç›¸å½“å¤§çš„éªŒè¯åˆ†åŒºï¼Œè¿™æ„å‘³ç€åœ¨è¿™ç§æƒ…å†µä¸‹å‡å°‘é”™è¯¯ä¿®å‰ªæ˜¯åˆé€‚çš„.9 å›¾ 12.5[699] æ˜¾ç¤ºäº†æ­¤è®­ç»ƒè¿­ä»£äº§ç”Ÿçš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(a)[453] illustrates the distribution of weight values across each of the five hidden laters immediately after initialization.",
            "zh": "å›¾ 8.23ï¼ˆaï¼‰[453] è¯´æ˜äº†åˆå§‹åŒ–åç«‹å³åœ¨äº”ä¸ªéšè—çš„åé¢æ¯ä¸ªåé¢çš„æƒé‡å€¼çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The differentiation is performed in two steps. First, treating g(x) as a unit, we differentiate f(g(x)) with respect to g(x), and then we differentiate g(x) with respect to x, in both cases using the differentiation rules from the previous section. The derivative of f(g(x)) with respect to x is the product of these two pieces.",
            "zh": "åˆ†ä¸¤æ­¥è¿›è¡ŒåŒºåˆ†ã€‚é¦–å…ˆï¼Œå°† gï¼ˆxï¼‰ è§†ä¸ºä¸€ä¸ªå•ä½ï¼Œæˆ‘ä»¬æ ¹æ® gï¼ˆxï¼‰ å¯¹ fï¼ˆgï¼ˆxï¼‰ï¼‰ è¿›è¡Œå¾®åˆ†ï¼Œç„¶åå¯¹ x å¯¹ gï¼ˆxï¼‰ è¿›è¡Œå¾®åˆ†ï¼Œåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹éƒ½ä½¿ç”¨ä¸Šä¸€èŠ‚çš„å¾®åˆ†è§„åˆ™è¿›è¡Œå¾®åˆ†ã€‚fï¼ˆgï¼ˆxï¼‰ï¼‰ ç›¸å¯¹äº x çš„å¯¼æ•°æ˜¯è¿™ä¸¤éƒ¨åˆ†çš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3â€…â€…â€…(a) A 3D surface plot and (b) a birdâ€™s-eye view contour plot of the error surface generated by plotting the sum of squared errors for the office rentals training set for each possible combination of values for w [0] (from the range [â€“10, 20]) and w [1] (from the range [â€“2,3]).",
            "zh": "7.3 ï¼ˆaï¼‰ 3D æ›²é¢å›¾å’Œ ï¼ˆbï¼‰ è¯¯å·®æ›²é¢çš„é¸Ÿç°å›¾ï¼Œé€šè¿‡ç»˜åˆ¶ w [0]ï¼ˆèŒƒå›´ [â€“10ï¼Œ 20]ï¼‰å’Œ w [1]ï¼ˆèŒƒå›´ [â€“2,3]ï¼‰çš„æ¯ç§å¯èƒ½å€¼ç»„åˆçš„åŠå…¬å®¤ç§Ÿèµè®­ç»ƒé›†çš„å¹³æ–¹è¯¯å·®æ€»å’Œç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "flag features, 35",
            "zh": "æ ‡è®°ç‰¹å¾ï¼Œ 35"
        }
    },
    {
        "translation": {
            "en": "Table 3.4",
            "zh": "è¡¨ 3.4"
        }
    },
    {
        "translation": {
            "en": "The clustering returned by the k-means clustering algorithm, however, can accurately find these intuitive clusterings only for the blobs dataset.",
            "zh": "ä½†æ˜¯ï¼Œk-means èšç±»åˆ†æç®—æ³•è¿”å›çš„èšç±»åªèƒ½ä¸º blob æ•°æ®é›†å‡†ç¡®æ‰¾åˆ°è¿™äº›ç›´è§‚çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, evaluating the feasibility of an analytics solution in terms of its data requirements involves aligning the following issues with the requirements of the analytics solution:",
            "zh": "é€šå¸¸ï¼Œæ ¹æ®æ•°æ®è¦æ±‚è¯„ä¼°åˆ†æè§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§æ¶‰åŠå°†ä»¥ä¸‹é—®é¢˜ä¸åˆ†æè§£å†³æ–¹æ¡ˆçš„è¦æ±‚ä¿æŒä¸€è‡´ï¼š"
        }
    },
    {
        "translation": {
            "en": "This distance is indicated by the vertical dotted line in Figure 9.13[564], from which it is clear that the K-S statistic is the largest distance between the positive and negative cumulative distributions.",
            "zh": "è¯¥è·ç¦»ç”±å›¾ 9.13[564] ä¸­çš„å‚ç›´è™šçº¿è¡¨ç¤ºï¼Œä»ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡º K-S ç»Ÿè®¡é‡æ˜¯æ­£åˆ†å¸ƒå’Œè´Ÿç´¯ç§¯åˆ†å¸ƒä¹‹é—´çš„æœ€å¤§è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Ross learned that the retention team believed that one of the main reasons customers churned was the availability of new, high-end handsets at other networks.",
            "zh": "ä¾‹å¦‚ï¼ŒRoss äº†è§£åˆ°ï¼Œå®¢æˆ·å®¢æˆ·æµå¤±çš„ä¸»è¦åŸå› ä¹‹ä¸€æ˜¯å…¶ä»–ç½‘ç»œä¸Šæœ‰æ–°çš„é«˜ç«¯æ‰‹æœºã€‚"
        }
    },
    {
        "translation": {
            "en": "In a typical scenario with two target levels, a prediction score in the range [0,1] is generated by a model, and a threshold of 0.5 is used to convert this score into a categorical prediction as follows:",
            "zh": "åœ¨å…·æœ‰ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„å…¸å‹åœºæ™¯ä¸­ï¼Œæ¨¡å‹ç”Ÿæˆ [0,1] èŒƒå›´å†…çš„é¢„æµ‹åˆ†æ•°ï¼Œå¹¶ä½¿ç”¨é˜ˆå€¼ 0.5 å°†è¯¥åˆ†æ•°è½¬æ¢ä¸ºåˆ†ç±»é¢„æµ‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "There is, however, a reliable approach that the hiker can take that will guide her to the bottom (assuming, somewhat ideally, that the valley is convex and has a global minimum).",
            "zh": "ç„¶è€Œï¼Œå¾’æ­¥æ—…è¡Œè€…å¯ä»¥é‡‡å–ä¸€ç§å¯é çš„æ–¹æ³•ï¼Œå°†å¥¹å¼•å¯¼åˆ°åº•éƒ¨ï¼ˆå‡è®¾ï¼Œåœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œå±±è°·æ˜¯å‡¸çš„å¹¶ä¸”å…·æœ‰å…¨çƒæœ€å°å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "19. See De Bruyne et al. (2011) for an example of machine learning models being used for this task.",
            "zh": "19. å‚è§De Bruyne et al. ï¼ˆ2011ï¼‰å…³äºç”¨äºæ­¤ä»»åŠ¡çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider an input feature recording salaries in dollars; this feature could have a spread of values in the range of millions or more.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘ä»¥ç¾å…ƒè®°å½•å·¥èµ„çš„è¾“å…¥è¦ç´ ;æ­¤åŠŸèƒ½çš„å€¼åˆ†å¸ƒå¯èƒ½åœ¨æ•°ç™¾ä¸‡æˆ–æ›´å¤šèŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEIGHT: The patientâ€™s height",
            "zh": "èº«é«˜ï¼šæ‚£è€…çš„èº«é«˜"
        }
    },
    {
        "translation": {
            "en": "The algorithm then continues merging clusters until only a single cluster containing all instances remains.",
            "zh": "ç„¶åï¼Œè¯¥ç®—æ³•ç»§ç»­åˆå¹¶é›†ç¾¤ï¼Œç›´åˆ°åªå‰©ä¸‹åŒ…å«æ‰€æœ‰å®ä¾‹çš„å•ä¸ªé›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.9â€…â€…â€…Exercises",
            "zh": "3.9 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Focusing on the top cell of column 7, we see the value 113,370.05.",
            "zh": "èšç„¦äºç¬¬ 7 åˆ—çš„é¡¶éƒ¨å•å…ƒæ ¼ï¼Œæˆ‘ä»¬çœ‹åˆ°å€¼ 113,370.05ã€‚"
        }
    },
    {
        "translation": {
            "en": "Clustering is a technique that partitions the instances in a dataset into groups, or clusters, that are similar to each other.",
            "zh": "èšç±»åˆ†ææ˜¯ä¸€ç§å°†æ•°æ®é›†ä¸­çš„å®ä¾‹åˆ’åˆ†ä¸ºå½¼æ­¤ç›¸ä¼¼çš„ç»„æˆ–èšç±»çš„æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although k can be set to any value, 10-fold cross validation is probably the most common variant used in practice.",
            "zh": "è™½ç„¶ k å¯ä»¥è®¾ç½®ä¸ºä»»ä½•å€¼ï¼Œä½† 10 å€äº¤å‰éªŒè¯å¯èƒ½æ˜¯å®è·µä¸­æœ€å¸¸ç”¨çš„å˜ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first distinction between models that we will discuss is the distinction between parametric and non-parametric models.",
            "zh": "æˆ‘ä»¬å°†è®¨è®ºçš„æ¨¡å‹ä¹‹é—´çš„ç¬¬ä¸€ä¸ªåŒºåˆ«æ˜¯å‚æ•°æ¨¡å‹å’Œéå‚æ•°æ¨¡å‹ä¹‹é—´çš„åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, if ai > ti, we know that we should decrease the output ai. Therefore,",
            "zh": "æ­¤å¤–ï¼Œå¦‚æœ ai > tiï¼Œæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬åº”è¯¥å‡å°‘è¾“å‡º aiã€‚å› æ­¤"
        }
    },
    {
        "translation": {
            "en": "Predictive analytics models can help professionals make better diagnoses by leveraging large collections of historical examples at a scale beyond anything one individual would see over his or her career.",
            "zh": "é¢„æµ‹åˆ†ææ¨¡å‹å¯ä»¥å¸®åŠ©ä¸“ä¸šäººå‘˜é€šè¿‡åˆ©ç”¨å¤§é‡å†å²ç¤ºä¾‹æ¥åšå‡ºæ›´å¥½çš„è¯Šæ–­ï¼Œå…¶è§„æ¨¡è¶…å‡ºäº†ä¸ªäººåœ¨å…¶èŒä¸šç”Ÿæ¶¯ä¸­æ‰€èƒ½çœ‹åˆ°çš„ä»»ä½•ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bins that contain only a few instances may have extremely small or extremely large conditional probabilities (depending on how the instances are divided when conditioned on the target feature), and these extreme conditional probabilities may bias a model based on the parameters of the binning technique (for example, the number of bins we choose to have) rather than on real distributions in the data.",
            "zh": "ä»…åŒ…å«å‡ ä¸ªå®ä¾‹çš„ bin å¯èƒ½å…·æœ‰æå°æˆ–æå¤§çš„æ¡ä»¶æ¦‚ç‡ï¼ˆå–å†³äºå®ä¾‹åœ¨ä»¥ç›®æ ‡ç‰¹å¾ä¸ºæ¡ä»¶æ—¶å¦‚ä½•åˆ’åˆ†ï¼‰ï¼Œå¹¶ä¸”è¿™äº›æç«¯æ¡ä»¶æ¦‚ç‡å¯èƒ½ä¼šæ ¹æ®åˆ†ç®±æŠ€æœ¯çš„å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œæˆ‘ä»¬é€‰æ‹©æ‹¥æœ‰çš„ bins æ•°é‡ï¼‰è€Œä¸æ˜¯æ•°æ®ä¸­çš„å®é™…åˆ†å¸ƒæ¥åå·®æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weights can either be excitatory (having a positive value, which increases the probability of the neuron activating) or inhibitory (having a negative value, which decreases the probability of a neuron firing).",
            "zh": "æƒé‡å¯ä»¥æ˜¯å…´å¥‹æ€§çš„ï¼ˆå…·æœ‰æ­£å€¼ï¼Œè¿™ä¼šå¢åŠ ç¥ç»å…ƒæ¿€æ´»çš„æ¦‚ç‡ï¼‰æˆ–æŠ‘åˆ¶æ€§çš„ï¼ˆå…·æœ‰è´Ÿå€¼ï¼Œè¿™ä¼šé™ä½ç¥ç»å…ƒæ”¾ç”µçš„æ¦‚ç‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4â€…â€…â€…A portion of the action-value table for the grid world example after 350 episodes of Q-learning have elapsed.",
            "zh": "11.4 ç»è¿‡ 350 é›† Q å­¦ä¹ åï¼Œç½‘æ ¼ä¸–ç•Œç¤ºä¾‹çš„åŠ¨ä½œå€¼è¡¨çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This would also require that information about claims become available in a suitably timely manner so that the claims investigation process would not be delayed by the model.",
            "zh": "è¿™è¿˜è¦æ±‚ä»¥é€‚å½“çš„æ–¹å¼åŠæ—¶æä¾›å…³äºç´¢èµ”çš„ä¿¡æ¯ï¼Œä»¥ä¾¿ç´¢èµ”è°ƒæŸ¥è¿‡ç¨‹ä¸ä¼šå› æ¨¡å‹è€Œå»¶è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "All is not lost, however, as the concepts of conditional independence and factorization can help us overcome this flaw of our current approach.",
            "zh": "ç„¶è€Œï¼Œä¸€åˆ‡éƒ½æ²¡æœ‰ä¸¢å¤±ï¼Œå› ä¸ºæ¡ä»¶ç‹¬ç«‹æ€§å’Œå› å¼åˆ†è§£çš„æ¦‚å¿µå¯ä»¥å¸®åŠ©æˆ‘ä»¬å…‹æœå½“å‰æ–¹æ³•çš„è¿™ä¸€ç¼ºé™·ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 5.6(b)[193] illustrates what happens to the decision boundary in our example feature space when k = 5.",
            "zh": "ä¾‹å¦‚ï¼Œå›¾ 5.6ï¼ˆbï¼‰[193] è¯´æ˜äº†å½“ k = 5 æ—¶ï¼Œæˆ‘ä»¬çš„ç¤ºä¾‹ç‰¹å¾ç©ºé—´ä¸­çš„å†³ç­–è¾¹ç•Œä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11(a)[203] illustrates the extent of the revised target hypersphere once these updates have been made.",
            "zh": "å›¾5.11ï¼ˆaï¼‰[203]æ˜¾ç¤ºäº†è¿›è¡Œè¿™äº›æ›´æ–°åä¿®è®¢åçš„ç›®æ ‡è¶…çƒä½“çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. âˆ‚â„°t+1/âˆ‚ht: the rate of change of the error of the network at time-step t+1 with respect to changes in the activation vector ht that was propagated forward to the next time-step during the forward pass; and",
            "zh": "2. âˆ‚Et+1/âˆ‚htï¼šåœ¨æ—¶é—´æ­¥é•¿ t+1 å¤„ï¼Œç½‘ç»œè¯¯å·®ç›¸å¯¹äºåœ¨å‰å‘ä¼ é€’æœŸé—´å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿çš„æ¿€æ´»å‘é‡ ht çš„å˜åŒ–ç‡;å’Œ"
        }
    },
    {
        "translation": {
            "en": "It is extremely important that analytics professionals manage the expectations of their clients during the business understanding process, and agreeing on expected levels of model performance is one of the easiest ways in which to do this.",
            "zh": "åˆ†æä¸“ä¸šäººå‘˜åœ¨ä¸šåŠ¡ç†è§£è¿‡ç¨‹ä¸­ç®¡ç†å®¢æˆ·çš„æœŸæœ›éå¸¸é‡è¦ï¼Œè€Œå°±æ¨¡å‹æ€§èƒ½çš„é¢„æœŸæ°´å¹³è¾¾æˆä¸€è‡´æ˜¯å®ç°è¿™ä¸€ç›®æ ‡çš„æœ€ç®€å•æ–¹æ³•ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first tree that Ross built used an entropy-based information gain as the splitting criterion, limited continuous splits to binary choices, and no pruning.",
            "zh": "Ross æ„å»ºçš„ç¬¬ä¸€æ£µæ ‘ä½¿ç”¨åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šä½œä¸ºæ‹†åˆ†æ ‡å‡†ï¼Œå°†è¿ç»­æ‹†åˆ†ä¸ºäºŒå…ƒé€‰æ‹©ï¼Œå¹¶ä¸”æ²¡æœ‰ä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "Using backpropagation, the error gradient at any point in the network is a product of the gradients up to that point; for convenience, we repeat Equation (8.25)[414] here",
            "zh": "ä½¿ç”¨åå‘ä¼ æ’­ï¼Œç½‘ç»œä¸­ä»»ä½•ä¸€ç‚¹çš„è¯¯å·®æ¢¯åº¦éƒ½æ˜¯è¯¥ç‚¹çš„æ¢¯åº¦çš„ä¹˜ç§¯;ä¸ºæ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé‡å¤ç­‰å¼ï¼ˆ8.25ï¼‰[414]"
        }
    },
    {
        "translation": {
            "en": "13.4â€…â€…â€…A data quality report for a subset of the features in the SDSS ABT.",
            "zh": "13.4 SDSS ABTä¸­è¦ç´ å­é›†çš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "6.3â€ƒStandard Approach: The Naive Bayes Model",
            "zh": "6.3 æ ‡å‡†æ–¹æ³•ï¼šæœ´ç´ è´å¶æ–¯æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Widdows, Dominic. 2004. Geometry and meaning. CSLI Publications.",
            "zh": "å¯¡å¦‡ï¼Œå¤šç±³å°¼å…‹ã€‚2004. å‡ ä½•ä¸æ„ä¹‰.CSLIå‡ºç‰ˆç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The hard decision boundary given in Equation (7.24)[341] is discontinuous, so is not differentiable, which means we cannot calculate the gradient of the error surface using the derivative.",
            "zh": "æ–¹ç¨‹ï¼ˆ7.24ï¼‰[341]ä¸­ç»™å‡ºçš„ç¡¬å†³ç­–è¾¹ç•Œæ˜¯ä¸è¿ç»­çš„ï¼Œå› æ­¤ä¸å¯å¾®åˆ†ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨å¯¼æ•°è®¡ç®—è¯¯å·®é¢çš„æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1.5â€ƒOut-of-time samplingâ€ƒThe sampling methods discussed in the previous section all rely on random sampling from a large dataset in order to create test sets.",
            "zh": "9.4.1.5 è¶…æ—¶æŠ½æ · ä¸Šä¸€èŠ‚ä¸­è®¨è®ºçš„æŠ½æ ·æ–¹æ³•éƒ½ä¾èµ–äºä»å¤§å‹æ•°æ®é›†ä¸­éšæœºæŠ½æ ·æ¥åˆ›å»ºæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "How the notation used in the book relates to the elements of a dataset.",
            "zh": "æœ¬ä¹¦ä¸­ä½¿ç”¨çš„ç¬¦å·ä¸æ•°æ®é›†å…ƒç´ çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects use machine learning algorithms to induce prediction models from historical data.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•ä»å†å²æ•°æ®ä¸­å¼•å…¥é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kate explained that at the end of every month, a call list was generated, capturing the customers who had made more than three calls to the AT customer support service in the previous two months.",
            "zh": "Kateè§£é‡Šè¯´ï¼Œæ¯ä¸ªæœˆåº•éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå‘¼å«åˆ—è¡¨ï¼Œæ•è·åœ¨è¿‡å»ä¸¤ä¸ªæœˆä¸­å‘ATå®¢æˆ·æ”¯æŒæœåŠ¡æ‹¨æ‰“è¿‡ä¸‰æ¬¡ä»¥ä¸Šç”µè¯çš„å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in a simple recurrent network we distinguish the weight matrices on the basis of whether the matrix is on the connections between the input and the hidden layer, the hidden layer and the output, or the activation memory buffer and the hidden layer.",
            "zh": "ç„¶è€Œï¼Œåœ¨ä¸€ä¸ªç®€å•çš„å¾ªç¯ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬æ ¹æ®çŸ©é˜µæ˜¯åœ¨è¾“å…¥å’Œéšè—å±‚ã€éšè—å±‚å’Œè¾“å‡ºä¹‹é—´çš„è¿æ¥ä¸Šï¼Œè¿˜æ˜¯åœ¨æ¿€æ´»å­˜å‚¨å™¨ç¼“å†²åŒºå’Œéšè—å±‚ä¸Šçš„è¿æ¥æ¥åŒºåˆ†æƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "PSFFLUX_U/G/R/I/Z",
            "zh": "PSFFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "With these baseline performance measures established, Jocelyn turned her attention to feature selection in an effort to improve on these performance scores.",
            "zh": "å»ºç«‹è¿™äº›åŸºçº¿æ€§èƒ½åº¦é‡åï¼ŒJocelyn å°†æ³¨æ„åŠ›è½¬å‘åŠŸèƒ½é€‰æ‹©ï¼Œä»¥åŠªåŠ›æé«˜è¿™äº›æ€§èƒ½åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Incorrectly predicting the bad level for a potential borrower who would have repaid the loan in full will result in a negative profit (or loss) of âˆ’ $140, as the company has forgone potential interest payments.",
            "zh": "é”™è¯¯åœ°é¢„æµ‹äº†æœ¬æ¥å¯ä»¥å…¨é¢å¿è¿˜è´·æ¬¾çš„æ½œåœ¨å€Ÿæ¬¾äººçš„ä¸è‰¯æ°´å¹³å°†å¯¼è‡´ -140 ç¾å…ƒçš„è´Ÿåˆ©æ¶¦ï¼ˆæˆ–æŸå¤±ï¼‰ï¼Œå› ä¸ºå…¬å¸å·²ç»æ”¾å¼ƒäº†æ½œåœ¨çš„åˆ©æ¯æ”¯ä»˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given these good results Ross decided that it was appropriate to present the model to other parts of the business.",
            "zh": "é‰´äºè¿™äº›è‰¯å¥½çš„ç»“æœï¼ŒRoss å†³å®šå°†è¯¥æ¨¡å‹å±•ç¤ºç»™ä¸šåŠ¡çš„å…¶ä»–éƒ¨é—¨æ˜¯åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, developing algorithms to learn the structure of Bayesian networks is an ongoing research challenge.24",
            "zh": "å› æ­¤ï¼Œå¼€å‘ç®—æ³•æ¥å­¦ä¹ è´å¶æ–¯ç½‘ç»œçš„ç»“æ„æ˜¯ä¸€é¡¹æŒç»­çš„ç ”ç©¶æŒ‘æˆ˜24ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Using the Jaccard similarity index (reproduced here from Section 5.4.5[211])",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨ Jaccard ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆæ­¤å¤„è½¬è½½è‡ªç¬¬ 5.4.5 èŠ‚ [211]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10",
            "zh": "å›¾ 7.10"
        }
    },
    {
        "translation": {
            "en": "Because correlation is normalized, it is dimensionless and, consequently, does not suffer from the interpretability difficulties associated with covariance.",
            "zh": "ç”±äºç›¸å…³æ€§æ˜¯å½’ä¸€åŒ–çš„ï¼Œå› æ­¤å®ƒæ˜¯æ— é‡çº²çš„ï¼Œå› æ­¤ä¸ä¼šå—åˆ°ä¸åæ–¹å·®ç›¸å…³çš„å¯è§£é‡Šæ€§å›°éš¾çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplest form of sampling is top sampling, which simply selects the top s% of instances from a dataset to create a sample. Top sampling runs a serious risk of introducing bias, however, as the sample will be affected by any ordering of the original dataset. For this reason, we recommend that top sampling be avoided.",
            "zh": "æœ€ç®€å•çš„æŠ½æ ·å½¢å¼æ˜¯é¡¶éƒ¨æŠ½æ ·ï¼Œå®ƒåªæ˜¯ä»æ•°æ®é›†ä¸­é€‰æ‹©å‰ s% çš„å®ä¾‹æ¥åˆ›å»ºæ ·æœ¬ã€‚ç„¶è€Œï¼Œé¡¶éƒ¨é‡‡æ ·å­˜åœ¨å¼•å…¥åå·®çš„ä¸¥é‡é£é™©ï¼Œå› ä¸ºæ ·æœ¬å°†å—åˆ°åŸå§‹æ•°æ®é›†çš„ä»»ä½•æ’åºçš„å½±å“ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®é¿å…é¡¶éƒ¨é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic structure of the AT business was that customers had a contract for call services that AT provided.",
            "zh": "ATä¸šåŠ¡çš„åŸºæœ¬ç»“æ„æ˜¯å®¢æˆ·ä¸ATæä¾›çš„å‘¼å«æœåŠ¡ç­¾è®¢åˆåŒã€‚"
        }
    },
    {
        "translation": {
            "en": "So far our treatment of probability has assumed that the evidence we have collected affects the probability of the event we are trying to predict.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹æ¦‚ç‡çš„å¤„ç†å‡è®¾æˆ‘ä»¬æ”¶é›†çš„è¯æ®ä¼šå½±å“æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cunningham, Padraig. 2009. A taxonomy of similarity mechanisms for case-based reasoning. IEEE Transactions on Knowledge and Data Engineering 21 (11): 1532â€“1543.",
            "zh": "åå®å®‰ï¼Œå¸•å¾·é›·æ ¼ã€‚2009. åŸºäºæ¡ˆä¾‹çš„æ¨ç†ç›¸ä¼¼æ€§æœºåˆ¶åˆ†ç±»æ³•.IEEEçŸ¥è¯†ä¸æ•°æ®å·¥ç¨‹æ±‡åˆŠ21ï¼ˆ11ï¼‰ï¼š1532â€“1543ã€‚"
        }
    },
    {
        "translation": {
            "en": "41. The data in this table has been artificially generated for this question. The American Cancer Society does, however, provide information on the causes of cancer: www.cancer.org/cancer/cancercauses/.",
            "zh": "41. æœ¬è¡¨ä¸­çš„æ•°æ®æ˜¯é’ˆå¯¹è¿™ä¸ªé—®é¢˜äººä¸ºç”Ÿæˆçš„ã€‚ç„¶è€Œï¼Œç¾å›½ç™Œç—‡åä¼šç¡®å®æä¾›äº†æœ‰å…³ç™Œç—‡åŸå› çš„ä¿¡æ¯ï¼šwww.cancer.org/cancer/cancercauses/ã€‚"
        }
    },
    {
        "translation": {
            "en": "16. The example given here is based on artificial data generated for the purposes of this book. Predicting the prices of assets such as whiskey or wine using machine learning is, however, done in reality. For example, Ashenfelter (2008) deals with predicting wine prices and was covered in Ayres (2008).",
            "zh": "16. è¿™é‡Œç»™å‡ºçš„ä¾‹å­æ˜¯åŸºäºä¸ºæœ¬ä¹¦çš„ç›®çš„è€Œç”Ÿæˆçš„äººå·¥æ•°æ®ã€‚ç„¶è€Œï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹å¨å£«å¿Œæˆ–è‘¡è„é…’ç­‰èµ„äº§çš„ä»·æ ¼æ˜¯åœ¨ç°å®ä¸­å®Œæˆçš„ã€‚ä¾‹å¦‚ï¼ŒAshenfelterï¼ˆ2008ï¼‰æ¶‰åŠé¢„æµ‹è‘¡è„é…’ä»·æ ¼ï¼Œå¹¶åœ¨Ayresï¼ˆ2008ï¼‰ä¸­æœ‰æ‰€ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see bootstrapping quite clearly in the definition of the actual temporal-difference learning update rule",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å®é™…æ—¶å·®å­¦ä¹ æ›´æ–°è§„åˆ™çš„å®šä¹‰ä¸­éå¸¸æ¸…æ¥šåœ°çœ‹åˆ°å¼•å¯¼"
        }
    },
    {
        "translation": {
            "en": "It would also require that any changes to a policy are recorded and available historically.",
            "zh": "å®ƒè¿˜è¦æ±‚å¯¹æ”¿ç­–çš„ä»»ä½•æ›´æ”¹éƒ½è®°å½•åœ¨å†å²è®°å½•ä¸­å¹¶æä¾›ã€‚"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE features, and its low cardinality arises from their low cardinality.",
            "zh": "SOFT TISSUE ç‰¹å¾ï¼Œå…¶ä½åŸºæ•°æºäºå®ƒä»¬çš„ä½åŸºæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having normalized the dataset, we first need to normalize the descriptive feature values of this query instance using the same normalization process.",
            "zh": "å¯¹æ•°æ®é›†è¿›è¡Œè§„èŒƒåŒ–åï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ä½¿ç”¨ç›¸åŒçš„è§„èŒƒåŒ–è¿‡ç¨‹è§„èŒƒåŒ–æ­¤æŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information gain for a feature based on the Gini index can be calculated in the same way that it is using entropy: calculate the Gini index for the full dataset and then subtract the sum of the weighted Gini index scores for the partitions created by splitting with the feature.",
            "zh": "åŸºäºåŸºå°¼æŒ‡æ•°çš„ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šå¯ä»¥é‡‡ç”¨ä¸ä½¿ç”¨ç†µç›¸åŒçš„æ–¹å¼è®¡ç®—ï¼šè®¡ç®—å®Œæ•´æ•°æ®é›†çš„åŸºå°¼æŒ‡æ•°ï¼Œç„¶åå‡å»é€šè¿‡ä¸ç‰¹å¾æ‹†åˆ†åˆ›å»ºçš„åˆ†åŒºçš„åŠ æƒåŸºå°¼æŒ‡æ•°åˆ†æ•°çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in Chapter 7[311] we introduce a machine learning algorithm called multivariable linear regression with gradient descent, which implements the restriction bias of considering only prediction models that produce predictions on the basis of a linear combination of the descriptive feature values and applies a preference bias over the order of the linear models it considers in terms of a gradient descent approach through a weight space.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨ç¬¬ 7 ç« [311]ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ç§°ä¸ºæ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•å®ç°äº†ä»…è€ƒè™‘åŸºäºæè¿°æ€§ç‰¹å¾å€¼çš„çº¿æ€§ç»„åˆç”Ÿæˆé¢„æµ‹çš„é¢„æµ‹æ¨¡å‹çš„é™åˆ¶åå·®ï¼Œå¹¶åœ¨é€šè¿‡æƒé‡ç©ºé—´çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•è€ƒè™‘çš„çº¿æ€§æ¨¡å‹çš„é¡ºåºä¸Šåº”ç”¨åå¥½åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The probability that the feature f is equal to the value v is written P(f = v).",
            "zh": "ç‰¹å¾ f ç­‰äºå€¼ v çš„æ¦‚ç‡å†™ä¸º Pï¼ˆf = vï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) In general, which is preferable when you are playing Scrabble: a set of letters with high entropy or a set of letters with low entropy?",
            "zh": "ï¼ˆdï¼‰ ä¸€èˆ¬æ¥è¯´ï¼Œå½“ä½ ç©æ‹¼å­—æ¸¸æˆæ—¶ï¼Œå“ªä¸ªæ›´å¯å–ï¼šä¸€ç»„é«˜ç†µçš„å­—æ¯è¿˜æ˜¯ä¸€ç»„ä½ç†µçš„å­—æ¯ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "However, it is quite possible to use one-dimensional filters or filters with three or more dimensions.",
            "zh": "ä½†æ˜¯ï¼Œå¾ˆæœ‰å¯èƒ½ä½¿ç”¨ä¸€ç»´æ»¤é•œæˆ–å…·æœ‰ä¸‰ç»´æˆ–æ›´å¤šç»´åº¦çš„æ»¤é•œã€‚"
        }
    },
    {
        "translation": {
            "en": "The combination of features listed in this query does not occur in the dataset.",
            "zh": "æ­¤æŸ¥è¯¢ä¸­åˆ—å‡ºçš„è¦ç´ ç»„åˆä¸ä¼šå‡ºç°åœ¨æ•°æ®é›†ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(a)[626] shows a selection of these digits.",
            "zh": "å›¾10.15ï¼ˆaï¼‰[626]æ˜¾ç¤ºäº†è¿™äº›æ•°å­—çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.1",
            "zh": "å›¾ 1.1"
        }
    },
    {
        "translation": {
            "en": "The â€œP.D.A.",
            "zh": "â€œP.D.A."
        }
    },
    {
        "translation": {
            "en": "Shannonâ€™s model of entropy is a weighted sum of the logs of the probabilities of each possible outcome when we make a random selection from a set. The weights used in the sum are the probabilities of the outcomes themselves, so that outcomes with high probabilities contribute more to the overall entropy of a set than outcomes with low probabilities. Shannonâ€™s model of entropy is defined as",
            "zh": "Shannon çš„ç†µæ¨¡å‹æ˜¯å½“æˆ‘ä»¬ä»é›†åˆä¸­éšæœºé€‰æ‹©æ—¶ï¼Œæ¯ä¸ªå¯èƒ½ç»“æœçš„æ¦‚ç‡å¯¹æ•°çš„åŠ æƒå’Œã€‚æ€»å’Œä¸­ä½¿ç”¨çš„æƒé‡æ˜¯ç»“æœæœ¬èº«çš„æ¦‚ç‡ï¼Œå› æ­¤é«˜æ¦‚ç‡çš„ç»“æœæ¯”ä½æ¦‚ç‡çš„ç»“æœå¯¹é›†åˆçš„æ•´ä½“ç†µçš„è´¡çŒ®æ›´å¤§ã€‚é¦™å†œçš„ç†µæ¨¡å‹å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes classifier is a Bayesian network with a specific topological structure.",
            "zh": "æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯å…·æœ‰ç‰¹å®šæ‹“æ‰‘ç»“æ„çš„è´å¶æ–¯ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Asimov, Isaac. 1950. I, robot. Gnome Press.",
            "zh": "é˜¿è¥¿è«å¤«ï¼Œè‰¾è¨å…‹ã€‚1950. æˆ‘ï¼Œæœºå™¨äººã€‚ä¾å„’å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. See Section 3.1[54].",
            "zh": "7. å‚è§ç¬¬ 3.1 èŠ‚[54]ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.12(a)[205] the SALARY axis ranged from 45,000 to 75,000, and the AGE axis ranged from 25 to 60.",
            "zh": "åœ¨å›¾5.12ï¼ˆaï¼‰[205]ä¸­ï¼Œå·¥èµ„è½´èŒƒå›´ä¸º45,000è‡³75,000ï¼Œå¹´é¾„è½´èŒƒå›´ä¸º25è‡³60ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SDSS project captures two distinct kinds of dataâ€”images of night-sky objects and spectrographs of night sky objectsâ€”using two distinct types of instrument, an imaging camera and a spectrograph.",
            "zh": "SDSSé¡¹ç›®ä½¿ç”¨ä¸¤ç§ä¸åŒç±»å‹çš„ä»ªå™¨ï¼ˆæˆåƒç›¸æœºå’Œå…‰è°±ä»ªï¼‰æ•è·ä¸¤ç§ä¸åŒç±»å‹çš„æ•°æ® - å¤œç©ºå¤©ä½“çš„å›¾åƒå’Œå¤œç©ºå¤©ä½“çš„å…‰è°±ä»ªã€‚"
        }
    },
    {
        "translation": {
            "en": "0.1253",
            "zh": "0.1253"
        }
    },
    {
        "translation": {
            "en": "This câ€¡ value is very close to the original ctâˆ’1, which shows that the forget gate has largely retained the value in the cell state (or in other words, the cell state has largely remembered this value).",
            "zh": "è¯¥ câ€¡ å€¼éå¸¸æ¥è¿‘åŸå§‹ ctâˆ’1ï¼Œè¿™è¡¨æ˜é—å¿˜é—¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¿ç•™äº†å•å…ƒçŠ¶æ€ä¸­çš„å€¼ï¼ˆæˆ–è€…æ¢å¥è¯è¯´ï¼Œå•å…ƒçŠ¶æ€åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè®°ä½äº†è¯¥å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this example we set k = 3.",
            "zh": "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è®¾ç½® k = 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Surfaces generated by calculating (a) the arithmetic mean and (b) the harmonic mean of all combinations of features A and B that range from 0 to 100.",
            "zh": "é€šè¿‡è®¡ç®— ï¼ˆaï¼‰ ç®—æœ¯å¹³å‡å€¼å’Œ ï¼ˆbï¼‰ èŒƒå›´ä¸º 0 åˆ° 100 çš„æ‰€æœ‰è¦ç´  A å’Œ B ç»„åˆçš„è°æ³¢å¹³å‡å€¼ç”Ÿæˆçš„æ›²é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "In representation learning the goal of unsupervised machine learning is to create a new way to represent the instances in a dataset, usually with the expectation that this new representation will be more useful for a later, usually supervised, machine learning process. The origins of deep learning discussed in Chapter 8[381] lie in this application of unsupervised machine learning.",
            "zh": "åœ¨è¡¨ç¤ºå­¦ä¹ ä¸­ï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ç§æ–°çš„æ–¹æ³•æ¥è¡¨ç¤ºæ•°æ®é›†ä¸­çš„å®ä¾‹ï¼Œé€šå¸¸æœŸæœ›è¿™ç§æ–°è¡¨ç¤ºå¯¹äºä»¥åçš„ï¼ˆé€šå¸¸æ˜¯ç›‘ç£çš„ï¼‰æœºå™¨å­¦ä¹ è¿‡ç¨‹æ›´æœ‰ç”¨ã€‚ç¬¬8ç« [381]ä¸­è®¨è®ºçš„æ·±åº¦å­¦ä¹ çš„èµ·æºåœ¨äºæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "ME2_U/G/R/I/Z",
            "zh": "ME2_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The s% of the instances in each stratum are then randomly selected, and these selections are combined to give an overall sample of s% of the original dataset.",
            "zh": "ç„¶åéšæœºé€‰æ‹©æ¯ä¸ªå±‚ä¸­å®ä¾‹çš„ s%ï¼Œå¹¶å°†è¿™äº›é€‰æ‹©ç»„åˆåœ¨ä¸€èµ·ï¼Œä»¥æä¾›åŸå§‹æ•°æ®é›†çš„ s% çš„æ€»æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why, as Figure 8.11[406] highlights, the weighted sum for each neuron is stored in the forward pass of the algorithm: it is used to calculate the âˆ‚ak/âˆ‚zk term during the backpropagation process.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆï¼Œå¦‚å›¾8.11[406]æ‰€ç¤ºï¼Œæ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒå’Œå­˜å‚¨åœ¨ç®—æ³•çš„å‰å‘ä¼ é€’ä¸­ï¼šå®ƒç”¨äºåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è®¡ç®—âˆ‚ak/âˆ‚zké¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "He decided to keep the REGIONTYPE feature, however, because it appeared to have some relationship with the target.",
            "zh": "ä½†æ˜¯ï¼Œä»–å†³å®šä¿ç•™ REGIONTYPE åŠŸèƒ½ï¼Œå› ä¸ºå®ƒä¼¼ä¹ä¸ç›®æ ‡æœ‰æŸç§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we compare the Î´ for Neuron 8 (the output neuron) with the Î´s for the neurons in the first hidden layer (Neurons 3, 4, and 5), it becomes clear that the Î´ values become smaller as they are propagated back from the output layer to the earlier layers in the network: Î´8 = 0.0851, whereas Î´3 = âˆ’0.0006, Î´4 = âˆ’0.0003, and Î´5 = 0.0003 are all smaller in magnitude.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†ç¥ç»å…ƒ 8ï¼ˆè¾“å‡ºç¥ç»å…ƒï¼‰çš„Î´ä¸ç¬¬ä¸€ä¸ªéšè—å±‚ï¼ˆç¥ç»å…ƒ 3ã€4 å’Œ 5ï¼‰ä¸­ç¥ç»å…ƒçš„ Î´ è¿›è¡Œæ¯”è¾ƒï¼Œå¾ˆæ˜æ˜¾ï¼Œå½“å®ƒä»¬ä»è¾“å‡ºå±‚ä¼ æ’­å›ç½‘ç»œä¸­çš„æ—©æœŸå±‚æ—¶ï¼ŒÎ´å€¼ä¼šå˜å°ï¼šÎ´8 = 0.0851ï¼Œè€Œ Î´3 = âˆ’0.0006ï¼Œ Î´4 = âˆ’0.0003 å’Œ Î´5 = 0.0003 çš„é‡çº§éƒ½è¾ƒå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, this terminology is often used in the explanation of softmax functions; therefore, in the section on handling categorical features, we switch from our normal z notation, and instead follow this logit nomenclature, using the notation l to denote a vector of logits for a layer of neurons, and li to indicate the logit for the ith neuron in the layer.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œè¿™ä¸ªæœ¯è¯­ç»å¸¸ç”¨äºè§£é‡Šsoftmaxå‡½æ•°;å› æ­¤ï¼Œåœ¨å¤„ç†åˆ†ç±»ç‰¹å¾çš„ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»æ­£å¸¸çš„ Z è¡¨ç¤ºæ³•åˆ‡æ¢ï¼Œè€Œæ˜¯éµå¾ªè¿™ä¸ª Logit å‘½åæ³•ï¼Œä½¿ç”¨ç¬¦å· l è¡¨ç¤ºç¥ç»å…ƒå±‚çš„ logits å‘é‡ï¼Œå¹¶ä½¿ç”¨ li è¡¨ç¤ºè¯¥å±‚ä¸­ç¬¬ i ä¸ªç¥ç»å…ƒçš„ logitã€‚"
        }
    },
    {
        "translation": {
            "en": "In this equation the subscript j indexes over the examples in the dataset and subscripts i and k index over neurons in the network.",
            "zh": "åœ¨è¿™ä¸ªç­‰å¼ä¸­ï¼Œä¸‹æ ‡ j ç´¢å¼•æ•°æ®é›†ä¸­çš„ç¤ºä¾‹ï¼Œä¸‹æ ‡ i å’Œ k ç´¢å¼•ç½‘ç»œä¸­çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.1",
            "zh": "å›¾ 5.1"
        }
    },
    {
        "translation": {
            "en": "10.6â€ƒFurther Reading",
            "zh": "10.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "A feature space plot of the college athlete data in Table 5.2[183].",
            "zh": "è¡¨5.2[183]ä¸­å¤§å­¦è¿åŠ¨å‘˜æ•°æ®çš„ç‰¹å¾ç©ºé—´å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapter 2[23]",
            "zh": "ç¬¬2ç« [23]"
        }
    },
    {
        "translation": {
            "en": "Generalized Bayesâ€™ Theorem, 251",
            "zh": "å¹¿ä¹‰è´å¶æ–¯å®šç†ï¼Œ251"
        }
    },
    {
        "translation": {
            "en": "2. a dot product between the input vector for this time-step xt and the weight matrix for the weights on the connections between the input layer and the hidden layer Whx;",
            "zh": "2. è¯¥æ—¶é—´æ­¥é•¿ xt çš„è¾“å…¥å‘é‡ä¸è¾“å…¥å±‚å’Œéšè—å±‚ Whx ä¹‹é—´è¿æ¥çš„æƒé‡çš„æƒé‡çŸ©é˜µä¹‹é—´çš„ç‚¹ç§¯;"
        }
    },
    {
        "translation": {
            "en": "location-scale family of distributions, 271",
            "zh": "ä½ç½®å°ºåº¦åˆ†å¸ƒç³»åˆ—ï¼Œ271"
        }
    },
    {
        "translation": {
            "en": "For example, in English, the subject and verb of a sentence should agree.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨è‹±è¯­ä¸­ï¼Œå¥å­çš„ä¸»è¯­å’ŒåŠ¨è¯åº”è¯¥ä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Informally explain what an algorithm has been designed to do before presenting the technical formal description of how it does it. Providing this informal introduction to each topic gives students a solid basis from which to attack the more technical material. Our experience with teaching this material to mixed audiences of undergraduates, postgraduates, and professionals has shown that these informal introductions enable students to easily access the topic.",
            "zh": "2. åœ¨ä»‹ç»ç®—æ³•å¦‚ä½•å®ç°çš„æŠ€æœ¯æ­£å¼æè¿°ä¹‹å‰ï¼Œéæ­£å¼åœ°è§£é‡Šç®—æ³•çš„è®¾è®¡ç›®çš„ã€‚ä¸ºæ¯ä¸ªä¸»é¢˜æä¾›è¿™ç§éæ­£å¼çš„ä»‹ç»ï¼Œä¸ºå­¦ç”Ÿæä¾›äº†ä¸€ä¸ªåšå®çš„åŸºç¡€ï¼Œä»ä¸­æ”»å‡»æ›´å…·æŠ€æœ¯æ€§çš„ææ–™ã€‚æˆ‘ä»¬å‘æœ¬ç§‘ç”Ÿã€ç ”ç©¶ç”Ÿå’Œä¸“ä¸šäººå£«çš„æ··åˆå—ä¼—æ•™æˆè¿™äº›ææ–™çš„ç»éªŒè¡¨æ˜ï¼Œè¿™äº›éæ­£å¼çš„ä»‹ç»ä½¿å­¦ç”Ÿèƒ½å¤Ÿè½»æ¾è®¿é—®è¯¥ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we are representing the target feature in a dataset using a one-hot encoding, then for each instance in the dataset there is a one-hot vector encoding the level of the target for that instance.",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨å•çƒ­ç¼–ç è¡¨ç¤ºæ•°æ®é›†ä¸­çš„ç›®æ ‡ç‰¹å¾æ—¶ï¼Œå¯¹äºæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹ï¼Œéƒ½æœ‰ä¸€ä¸ªå•çƒ­å‘é‡å¯¹è¯¥å®ä¾‹çš„ç›®æ ‡çº§åˆ«è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.15[283] shows the discretization of the LOAN AMOUNT feature into four equal-frequency bins.",
            "zh": "è¡¨ 6.15[283] æ˜¾ç¤ºäº† LOAN AMOUNT ç‰¹å¾ç¦»æ•£åŒ–ä¸ºå››ä¸ªç­‰é¢‘ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearly 2.4 million people responded to the survey, and on the basis of this sample, Literary Digest very publicly and confidently predicted that Alfred Landon would win by a landslide.",
            "zh": "è¿‘ 240 ä¸‡äººå¯¹è°ƒæŸ¥åšå‡ºäº†å›åº”ï¼Œæ ¹æ®è¿™ä¸ªæ ·æœ¬ï¼Œã€Šæ–‡å­¦æ–‡æ‘˜ã€‹éå¸¸å…¬å¼€å’Œè‡ªä¿¡åœ°é¢„æµ‹é˜¿å°”å¼—é›·å¾·Â·å…°ç™»å°†ä»¥å‹å€’æ€§ä¼˜åŠ¿è·èƒœã€‚"
        }
    },
    {
        "translation": {
            "en": "Player High (PH): 19 âˆ’ 22",
            "zh": "çƒå‘˜æœ€é«˜å€¼ ï¼ˆPHï¼‰ï¼š 19 âˆ’ 22"
        }
    },
    {
        "translation": {
            "en": "In this scenario, feedback on the performance of the model implicitly arises within a reasonably short amount of time after predictions are madeâ€”churn predictions can be easily compared to actual customer behavior (taking into account interventions made by the business).",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨åšå‡ºé¢„æµ‹åï¼Œåœ¨ç›¸å½“çŸ­çš„æ—¶é—´å†…éšå¼åœ°å‡ºç°å¯¹æ¨¡å‹æ€§èƒ½çš„åé¦ˆ - æµå¤±é¢„æµ‹å¯ä»¥å¾ˆå®¹æ˜“åœ°ä¸å®é™…å®¢æˆ·è¡Œä¸ºè¿›è¡Œæ¯”è¾ƒï¼ˆè€ƒè™‘åˆ°ä¸šåŠ¡éƒ¨é—¨çš„å¹²é¢„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "squared error, 378",
            "zh": "å¹³æ–¹è¯¯å·®ï¼Œ378"
        }
    },
    {
        "translation": {
            "en": "The convolutional neural networks discussed in Section 8.4.5[477] are ideally suited to processing data that have a fixed-size grid-like structure and where the basic features have a local extent, such as images.",
            "zh": "ç¬¬8.4.5èŠ‚[477]ä¸­è®¨è®ºçš„å·ç§¯ç¥ç»ç½‘ç»œéå¸¸é€‚åˆå¤„ç†å…·æœ‰å›ºå®šå¤§å°çš„ç½‘æ ¼çŠ¶ç»“æ„ä¸”åŸºæœ¬ç‰¹å¾å…·æœ‰å±€éƒ¨èŒƒå›´çš„æ•°æ®ï¼Œä¾‹å¦‚å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23[364] shows two different decision boundaries that satisfy these constraints.",
            "zh": "å›¾ 7.23[364] æ˜¾ç¤ºäº†æ»¡è¶³è¿™äº›çº¦æŸçš„ä¸¤ä¸ªä¸åŒçš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "D.2â€…â€…â€…Transpose",
            "zh": "D.2 è½¬ç½®"
        }
    },
    {
        "translation": {
            "en": "The fact that a neural network can represent a function does not guarantee that we will be able to train it to learn the function: the training algorithm may not be able to find the correct set of weights, or it may choose weights that overfit the data (i.e., choose the wrong function) (Goodfellow et al., 2016).",
            "zh": "ç¥ç»ç½‘ç»œå¯ä»¥è¡¨ç¤ºä¸€ä¸ªå‡½æ•°è¿™ä¸€äº‹å®å¹¶ä¸èƒ½ä¿è¯æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒå®ƒæ¥å­¦ä¹ è¯¥å‡½æ•°ï¼šè®­ç»ƒç®—æ³•å¯èƒ½æ— æ³•æ‰¾åˆ°æ­£ç¡®çš„æƒé‡é›†ï¼Œæˆ–è€…å®ƒå¯èƒ½ä¼šé€‰æ‹©è¿‡åº¦æ‹Ÿåˆæ•°æ®çš„æƒé‡ï¼ˆå³é€‰æ‹©é”™è¯¯çš„å‡½æ•°ï¼‰ï¼ˆGoodfellowç­‰äººï¼Œ 2016)."
        }
    },
    {
        "translation": {
            "en": "Hornik, Kur, Maxwell Stinchcombe, and Halber White. 1989. Multilayer feedforward networks are universal approximators. Neural Networks 2: 359â€“366.",
            "zh": "éœå°¼å…‹ã€åº“å°”ã€éº¦å…‹æ–¯éŸ¦Â·æ–¯å»·å¥‡ç§‘å§†å’Œå“ˆå°”ä¼¯Â·æ€€ç‰¹ã€‚1989. å¤šå±‚å‰é¦ˆç½‘ç»œæ˜¯é€šç”¨é€¼è¿‘å™¨ã€‚ç¥ç»ç½‘ç»œ 2ï¼š359â€“366ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„(q) is the prediction returned by the model ğ•„ using a MAP prediction mechanism for a query, q, composed of q[1],â€¦,q[m] descriptive features; levels(t) is the set of levels the target feature can take; and arg maxlâˆˆlevels(t) specifies that we return the level, l, that has the maximum value computed using the function on the right of the arg max term.",
            "zh": "å…¶ä¸­ Mï¼ˆqï¼‰ æ˜¯æ¨¡å‹ M ä½¿ç”¨ MAP é¢„æµ‹æœºåˆ¶å¯¹ç”± q[1],...,q[m] æè¿°æ€§ç‰¹å¾ç»„æˆçš„æŸ¥è¯¢ q è¿”å›çš„é¢„æµ‹;levelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡è¦ç´ å¯ä»¥é‡‡ç”¨çš„ä¸€ç»„çº§åˆ«;arg maxlâˆˆlevelsï¼ˆtï¼‰ æŒ‡å®šæˆ‘ä»¬è¿”å›çº§åˆ« lï¼Œè¯¥çº§åˆ«å…·æœ‰ä½¿ç”¨ arg max é¡¹å³ä¾§çš„å‡½æ•°è®¡ç®—çš„æœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Shannonâ€™s model of information is designed to reflect this intuition, and the entropy value for this set is 0.00 bits.",
            "zh": "Shannon çš„ä¿¡æ¯æ¨¡å‹æ—¨åœ¨åæ˜ è¿™ç§ç›´è§‰ï¼Œè¯¥é›†åˆçš„ç†µå€¼ä¸º 0.00 ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because the chain rule specifies the product of a sequence of probabilities, if any of the probabilities in the sequence is zero, then the overall probability will be zero.",
            "zh": "ç”±äºé“¾å¼æ³•åˆ™æŒ‡å®šäº†æ¦‚ç‡åºåˆ—çš„ä¹˜ç§¯ï¼Œå› æ­¤å¦‚æœåºåˆ—ä¸­çš„ä»»ä½•æ¦‚ç‡ä¸ºé›¶ï¼Œåˆ™æ€»æ¦‚ç‡å°†ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.6â€…â€…â€…Observation and outcome periods defined by an event rather than by a fixed point in time (each line represents a prediction subject, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.6 ç”±äº‹ä»¶è€Œä¸æ˜¯å›ºå®šæ—¶é—´ç‚¹å®šä¹‰çš„è§‚å¯Ÿå’Œç»“æœå‘¨æœŸï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ä¸»é¢˜ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "where is the normalized feature value, ai is the original value, min(a) is the minimum value of feature a, max(a) is the maximum value of feature a, and low and high are the minimum and maximum values of the desired range. Typical ranges used for normalizing feature values are [0,1] and [âˆ’1,1]. Table 3.9[88] shows the effect of applying range normalization to a small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the dataset in Table 3.7[73].",
            "zh": "å…¶ä¸­ï¼Œä¸ºå½’ä¸€åŒ–ç‰¹å¾å€¼ï¼Œaiä¸ºåŸå§‹å€¼ï¼Œminï¼ˆaï¼‰ä¸ºç‰¹å¾Açš„æœ€å°å€¼ï¼Œmaxï¼ˆaï¼‰ä¸ºç‰¹å¾Açš„æœ€å¤§å€¼ï¼Œlowå’Œhighä¸ºæ‰€éœ€èŒƒå›´çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚ç”¨äºå½’ä¸€åŒ–ç‰¹å¾å€¼çš„å…¸å‹èŒƒå›´æ˜¯ [0,1] å’Œ [âˆ’1,1]ã€‚è¡¨3.9[88]æ˜¾ç¤ºäº†å¯¹è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­HEIGHTå’ŒSPONSORSHIP EARNSç‰¹å¾çš„å°æ ·æœ¬åº”ç”¨èŒƒå›´å½’ä¸€åŒ–çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "From inspecting Figure 5.12(a)[205], it would appear as if instance d1â€”which has a target level noâ€”is the closest neighbor to the query.",
            "zh": "é€šè¿‡æ£€æŸ¥å›¾ 5.12ï¼ˆaï¼‰[205]ï¼Œå®ä¾‹ d1ï¼ˆç›®æ ‡çº§åˆ«ä¸º noï¼‰ä¼¼ä¹æ˜¯ä¸æŸ¥è¯¢æœ€æ¥è¿‘çš„é‚»å±…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bellman optimality equation, 653",
            "zh": "è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹ï¼Œ653"
        }
    },
    {
        "translation": {
            "en": "The main difference is in the Q value update step, where the next action to be taken, at+1, from the new state, st+1, is chosen using the behavior policy (Line 14[666]) and then used in updating the value of Q(st,at) (Line 14[666]).",
            "zh": "ä¸»è¦åŒºåˆ«åœ¨äº Q å€¼æ›´æ–°æ­¥éª¤ï¼Œå…¶ä¸­ä½¿ç”¨è¡Œä¸ºç­–ç•¥ï¼ˆç¬¬ 14 è¡Œ[666]ï¼‰é€‰æ‹©ä»æ–°çŠ¶æ€ st+1 è¦æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªæ“ä½œ at+1ï¼Œç„¶åç”¨äºæ›´æ–° Qï¼ˆstï¼Œatï¼‰ çš„å€¼ï¼ˆç¬¬ 14 è¡Œ[666]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If all the descriptive features in a dataset are continuous, then a similarity-based approach is a natural fit, especially when there is also a categorical target feature.",
            "zh": "å¦‚æœæ•°æ®é›†ä¸­çš„æ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½æ˜¯è¿ç»­çš„ï¼Œåˆ™åŸºäºç›¸ä¼¼æ€§çš„æ–¹æ³•å¾ˆè‡ªç„¶åœ°é€‚åˆï¼Œå°¤å…¶æ˜¯å½“è¿˜å­˜åœ¨åˆ†ç±»ç›®æ ‡ç‰¹å¾æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the network in Figure 8.38[504] we would calculate three errors: one for y1, one for y2, and one for y3.",
            "zh": "å¯¹äºå›¾ 8.38[504] ä¸­çš„ç½‘ç»œï¼Œæˆ‘ä»¬å°†è®¡ç®—ä¸‰ä¸ªè¯¯å·®ï¼šä¸€ä¸ªç”¨äº y1ï¼Œä¸€ä¸ªç”¨äº y2ï¼Œä¸€ä¸ªç”¨äº y3ã€‚"
        }
    },
    {
        "translation": {
            "en": "upsell model, 213, 572",
            "zh": "è¿½åŠ é”€å”®æ¨¡å‹ï¼Œ213,572"
        }
    },
    {
        "translation": {
            "en": "The fact that our single-layer network in Figure 8.7[397] contains three independent neurons means that the network has the potential to represent three separate linear decision boundaries. However, none of the neurons in the output layer are capable of representing a non-linear decision boundary on the inputs, and therefore the network as a whole cannot represent a non-linear function.",
            "zh": "å›¾8.7[397]ä¸­çš„å•å±‚ç½‘ç»œåŒ…å«ä¸‰ä¸ªç‹¬ç«‹çš„ç¥ç»å…ƒï¼Œè¿™æ„å‘³ç€è¯¥ç½‘ç»œæœ‰å¯èƒ½è¡¨ç¤ºä¸‰ä¸ªç‹¬ç«‹çš„çº¿æ€§å†³ç­–è¾¹ç•Œã€‚ç„¶è€Œï¼Œè¾“å‡ºå±‚ä¸­æ²¡æœ‰ä¸€ä¸ªç¥ç»å…ƒèƒ½å¤Ÿè¡¨ç¤ºè¾“å…¥ä¸Šçš„éçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œå› æ­¤æ•´ä¸ªç½‘ç»œä¸èƒ½è¡¨ç¤ºéçº¿æ€§å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.3â€…â€…â€…Continuous Features: Binning",
            "zh": "6.4.3 è¿ç»­åŠŸèƒ½ï¼šåˆ†ç®±"
        }
    },
    {
        "translation": {
            "en": "The second useful thing that can be done is to prepare a series of data visualizations that examine the distribution of each feature for the members of each cluster found.",
            "zh": "å¯ä»¥åšçš„ç¬¬äºŒä»¶æœ‰ç”¨çš„äº‹æƒ…æ˜¯å‡†å¤‡ä¸€ç³»åˆ—æ•°æ®å¯è§†åŒ–ï¼Œä»¥æ£€æŸ¥æ‰¾åˆ°çš„æ¯ä¸ªèšç±»æˆå‘˜çš„æ¯ä¸ªç‰¹å¾çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œThere is only one boss. The customer. And he can fire everybody in the company from the chairman on down, simply by spending his money somewhere else.â€",
            "zh": "â€œåªæœ‰ä¸€ä¸ªè€æ¿ã€‚å®¢æˆ·ã€‚ä»–å¯ä»¥è§£é›‡å…¬å¸é‡Œçš„æ¯ä¸€ä¸ªäººï¼Œä»è‘£äº‹é•¿åˆ°ä¸‹å±‚ï¼Œåªè¦æŠŠé’±èŠ±åœ¨å…¶ä»–åœ°æ–¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The k-means algorithm is still stochastic in the manner in which initial cluster centroids are selected, and it does not completely remove the possibility of a poor starting point that leads to a sub-optimal clustering.",
            "zh": "k-means ç®—æ³•åœ¨é€‰æ‹©åˆå§‹èšç±»è´¨å¿ƒçš„æ–¹å¼ä¸Šä»ç„¶æ˜¯éšæœºçš„ï¼Œå¹¶ä¸”å®ƒå¹¶æ²¡æœ‰å®Œå…¨æ¶ˆé™¤å¯¼è‡´æ¬¡ä¼˜èšç±»çš„ä¸è‰¯èµ·ç‚¹çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.1",
            "zh": "è¡¨ 6.1"
        }
    },
    {
        "translation": {
            "en": "correlation, 81, 82, 94, 103, 223",
            "zh": "ç›¸å…³æ€§ï¼Œ 81ï¼Œ 82ï¼Œ 94ï¼Œ 103ï¼Œ 223"
        }
    },
    {
        "translation": {
            "en": "Andoni and Indyk (2006) provide a survey of these hash-based approaches.",
            "zh": "Andoniå’ŒIndykï¼ˆ2006ï¼‰å¯¹è¿™äº›åŸºäºå“ˆå¸Œçš„æ–¹æ³•è¿›è¡Œäº†è°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the Î´s for all the neurons in the last hidden layer is calculated, the process is repeated in order to calculate Î´s for the neurons in the preceding hidden layer.",
            "zh": "ä¸€æ—¦è®¡ç®—å‡ºæœ€åä¸€ä¸ªéšè—å±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒçš„ Î´sï¼Œå°±ä¼šé‡å¤è¯¥è¿‡ç¨‹ä»¥è®¡ç®—å‰ä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„ Î´sã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2.1â€…â€…â€…Bayesâ€™ Theorem",
            "zh": "6.2.1 è´å¶æ–¯å®šç†"
        }
    },
    {
        "translation": {
            "en": "This is why in recent years most researchers have switched to using the rectifier function (or variants) as the default activation function.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿‘å¹´æ¥å¤§å¤šæ•°ç ”ç©¶äººå‘˜éƒ½è½¬è€Œä½¿ç”¨æ•´æµå™¨åŠŸèƒ½ï¼ˆæˆ–å˜ä½“ï¼‰ä½œä¸ºé»˜è®¤æ¿€æ´»åŠŸèƒ½çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "When different performance measures are used, the aggregates can be calculated in the same way.",
            "zh": "å½“ä½¿ç”¨ä¸åŒçš„æ€§èƒ½åº¦é‡æ—¶ï¼Œå¯ä»¥ä»¥ç›¸åŒçš„æ–¹å¼è®¡ç®—èšåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This model could be run whenever new claims arise, and the policyholder could be offered the amount predicted by the model as settlement as an alternative to going through a claims investigation process.",
            "zh": "æ¯å½“å‡ºç°æ–°çš„ç´¢èµ”æ—¶ï¼Œéƒ½å¯ä»¥è¿è¡Œè¯¥æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥å‘æŠ•ä¿äººæä¾›æ¨¡å‹é¢„æµ‹çš„é‡‘é¢ä½œä¸ºç»“ç®—ï¼Œä½œä¸ºé€šè¿‡ç´¢èµ”è°ƒæŸ¥è¿‡ç¨‹çš„æ›¿ä»£æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that because of the way that the sigmoid activation function operates, large positive values in the Zt(f) vector (i.e., + 6) are mapped to values close to 1 in ft: 0.002472623, whereas large negative values in Zt(f) (such as âˆ’ 6) are mapped to values near 0; and Zt(f) values near 0 are mapped to values around 0.5.",
            "zh": "è¯·æ³¨æ„ï¼Œç”±äº S å½¢æ¿€æ´»å‡½æ•°çš„è¿ä½œæ–¹å¼ï¼ŒZtï¼ˆfï¼‰ å‘é‡ä¸­çš„å¤§æ­£å€¼ï¼ˆå³ + 6ï¼‰æ˜ å°„åˆ°æ¥è¿‘ ft çš„ 1 å€¼ï¼š0.002472623ï¼Œè€Œ Ztï¼ˆfï¼‰ ä¸­çš„å¤§è´Ÿå€¼ï¼ˆä¾‹å¦‚ âˆ’ 6ï¼‰æ˜ å°„åˆ°æ¥è¿‘ 0 çš„å€¼;æ¥è¿‘ 0 çš„ Ztï¼ˆfï¼‰ å€¼æ˜ å°„åˆ° 0.5 é™„è¿‘çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sample descriptive feature data illustrating numeric, binary, ordinal, interval, categorical, and textual types.",
            "zh": "ç¤ºä¾‹æè¿°æ€§ç‰¹å¾æ•°æ®ï¼Œè¯´æ˜æ•°å€¼ã€äºŒè¿›åˆ¶ã€åºæ•°ã€åŒºé—´ã€åˆ†ç±»å’Œæ–‡æœ¬ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "CMODELMAGERR_U/G/R/I/Z",
            "zh": "CMODELMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "From these calculations we can see that SLOPE has the highest information gain ratio score, even though ELEVATION has the highest information gain. The implication is that if we built a decision tree for the dataset in Table 4.3[136] using information gain ratio, then SLOPE (rather than ELEVATION) would be the feature chosen for the root of the tree. Figure 4.12[144] illustrates the tree that would be generated for this dataset using information gain ratio.",
            "zh": "ä»è¿™äº›è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° SLOPE å…·æœ‰æœ€é«˜çš„ä¿¡æ¯å¢ç›Šæ¯”å¾—åˆ†ï¼Œå³ä½¿ ELEVATION å…·æœ‰æœ€é«˜çš„ä¿¡æ¯å¢ç›Šã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”ä¸ºè¡¨4.3[136]ä¸­çš„æ•°æ®é›†æ„å»ºå†³ç­–æ ‘ï¼Œé‚£ä¹ˆSLOPEï¼ˆè€Œä¸æ˜¯ELEVATIONï¼‰å°†æ˜¯ä¸ºæ ‘æ ¹é€‰æ‹©çš„ç‰¹å¾ã€‚å›¾4.12[144]è¯´æ˜äº†ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”ä¸ºè¯¥æ•°æ®é›†ç”Ÿæˆçš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each partition, d=li, contains the instances in that have a value of level li for the d feature.",
            "zh": "æ¯ä¸ªåˆ†åŒº d=li éƒ½åŒ…å«å…¶ä¸­çš„å®ä¾‹ï¼Œå…¶ä¸­ d ç‰¹å¾çš„å€¼ä¸º li çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "A root node is then added to the tree and labeled with the selected test feature.",
            "zh": "ç„¶åï¼Œå°†æ ¹èŠ‚ç‚¹æ·»åŠ åˆ°æ ‘ä¸­ï¼Œå¹¶ä½¿ç”¨æ‰€é€‰æµ‹è¯•ç‰¹å¾è¿›è¡Œæ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we can generate good predictions for queries by interpolating from nearby instances with known target values.",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»å…·æœ‰å·²çŸ¥ç›®æ ‡å€¼çš„é™„è¿‘å®ä¾‹è¿›è¡Œæ’å€¼æ¥ç”Ÿæˆè‰¯å¥½çš„æŸ¥è¯¢é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, estimating how long the burn-in should be is difficult.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œä¼°è®¡è€åŒ–åº”è¯¥æŒç»­å¤šé•¿æ—¶é—´æ˜¯å¾ˆå›°éš¾çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, bias terms are initialized to 0.",
            "zh": "é€šå¸¸ï¼Œåç½®é¡¹åˆå§‹åŒ–ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. we change the error (or loss) function we use for training to be the cross-entropy function.",
            "zh": "3. æˆ‘ä»¬å°†ç”¨äºè®­ç»ƒçš„è¯¯å·®ï¼ˆæˆ–æŸå¤±ï¼‰å‡½æ•°æ›´æ”¹ä¸ºäº¤å‰ç†µå‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "insights, 3",
            "zh": "è§è§£ï¼Œ3"
        }
    },
    {
        "translation": {
            "en": "8.4â€…â€…â€…A schematic of a feedforward artificial neural network.",
            "zh": "8.4 å‰é¦ˆäººå·¥ç¥ç»ç½‘ç»œç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "NUM. SOFT TISSUE",
            "zh": "è½¯ç»„ç»‡æ•°é‡"
        }
    },
    {
        "translation": {
            "en": "36. Xavier initialization is named after the first author (Xavier Glorot) of the paper that introduced this layer-wise approach to weight initialization, Glorot and Bengio (2010). However, in some places the authorâ€™s second name is used instead of his first name to describe the same initialization algorithm, so that it is sometimes called Glorot initialization.",
            "zh": "36. Xavier åˆå§‹åŒ–ä»¥ä»‹ç»è¿™ç§é€å±‚æƒé‡åˆå§‹åŒ–æ–¹æ³•çš„è®ºæ–‡çš„ç¬¬ä¸€ä½œè€… ï¼ˆXavier Glorotï¼‰ çš„åå­—å‘½åï¼ŒGlorot å’Œ Bengio ï¼ˆ2010ï¼‰ã€‚ä½†æ˜¯ï¼Œåœ¨æŸäº›åœ°æ–¹ï¼Œä½¿ç”¨ä½œè€…çš„ç¬¬äºŒä¸ªåå­—è€Œä¸æ˜¯ä»–çš„åå­—æ¥æè¿°ç›¸åŒçš„åˆå§‹åŒ–ç®—æ³•ï¼Œå› æ­¤æœ‰æ—¶ç§°ä¸º Glorot åˆå§‹åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, Rossâ€™s first goal was to convert this business problem into a concrete analytics solution.",
            "zh": "å› æ­¤ï¼ŒRoss çš„é¦–è¦ç›®æ ‡æ˜¯å°†è¿™ä¸ªä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºå…·ä½“çš„åˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "parametric model, 732",
            "zh": "å‚æ•°æ¨¡å‹ï¼Œ732"
        }
    },
    {
        "translation": {
            "en": "14.1â€ƒDifferent Perspectives on Prediction Models",
            "zh": "14.1 é¢„æµ‹æ¨¡å‹çš„ä¸åŒè§†è§’"
        }
    },
    {
        "translation": {
            "en": "The taxonomy we have used to distinguish between different machine learning algorithms is based on human approaches to learning that the algorithms can be said to emulate. This is not the only set of distinctions that can be made between the algorithms and the resulting models. It is useful to understand some of the other commonly used distinctions, because this understanding can provide insight into which learning algorithm and related model is most appropriate for a given scenario.",
            "zh": "æˆ‘ä»¬ç”¨æ¥åŒºåˆ†ä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•çš„åˆ†ç±»æ³•æ˜¯åŸºäºäººç±»çš„å­¦ä¹ æ–¹æ³•ï¼Œè¿™äº›ç®—æ³•å¯ä»¥è¯´æ˜¯æ¨¡ä»¿çš„ã€‚è¿™å¹¶ä¸æ˜¯ç®—æ³•å’Œç»“æœæ¨¡å‹ä¹‹é—´å”¯ä¸€å¯ä»¥åŒºåˆ†çš„ä¸€ç»„ã€‚äº†è§£å…¶ä»–ä¸€äº›å¸¸ç”¨çš„åŒºåˆ«æ˜¯å¾ˆæœ‰ç”¨çš„ï¼Œå› ä¸ºè¿™ç§ç†è§£å¯ä»¥æ·±å…¥äº†è§£å“ªç§å­¦ä¹ ç®—æ³•å’Œç›¸å…³æ¨¡å‹æœ€é€‚åˆç»™å®šåœºæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Beyond Prediction: Reinforcement Learning",
            "zh": "è¶…è¶Šé¢„æµ‹ï¼šå¼ºåŒ–å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "An easy way to understand the entropy of a set is to think in terms of the uncertainty associated with guessing the result if you were to make a random selection from the set.",
            "zh": "ç†è§£é›†åˆç†µçš„ä¸€ä¸ªç®€å•æ–¹æ³•æ˜¯ï¼Œå¦‚æœæ‚¨è¦ä»é›†åˆä¸­éšæœºé€‰æ‹©ï¼Œåˆ™è€ƒè™‘ä¸çŒœæµ‹ç»“æœç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„k(q) is the prediction returned by the model using parameter value k for the query q, i iterates over the k nearest neighbors to q in the dataset, and ti is the value of the target feature for instance i.",
            "zh": "å…¶ä¸­ Mkï¼ˆqï¼‰ æ˜¯æ¨¡å‹ä½¿ç”¨å‚æ•°å€¼ k è¿”å›çš„æŸ¥è¯¢ q çš„é¢„æµ‹ï¼Œi éå†æ•°æ®é›†ä¸­ q çš„ k ä¸ªæœ€è¿‘é‚»ï¼Œti æ˜¯å®ä¾‹ i çš„ç›®æ ‡ç‰¹å¾çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The shape of the derivative in Figure C.2(c)[767] can be understood similarly.",
            "zh": "å›¾C.2ï¼ˆcï¼‰[767]ä¸­å¯¼æ•°çš„å½¢çŠ¶å¯ä»¥ç±»ä¼¼åœ°ç†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can demonstrate the product rule by recalculating the probability P(m,h) using previously computed probabilities:",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å…ˆå‰è®¡ç®—çš„æ¦‚ç‡é‡æ–°è®¡ç®—æ¦‚ç‡ Pï¼ˆmï¼Œhï¼‰ æ¥è¯æ˜ä¹˜ç§¯è§„åˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 10.9",
            "zh": "å›¾ 10.9"
        }
    },
    {
        "translation": {
            "en": "An illustration of how the representational capacity of a network increases as more layers are added to the network.",
            "zh": "è¯´æ˜ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›å¦‚ä½•éšç€å‘ç½‘ç»œæ·»åŠ æ›´å¤šå±‚è€Œå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, for example, for our ENERGY RATING feature, instead of adding three new features (ENERGY RATING A, ENERGY RATING B, and ENERGY RATING C), we could just add ENERGY RATING A and ENERGY RATING B and assume that whenever they both have a value of 0, ENERGY RATING C is implicitly set.",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œå¯¹äºæˆ‘ä»¬çš„ ENERGY RATING åŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ  ENERGY RATING A å’Œ ENERGY RATING Bï¼Œå¹¶å‡è®¾åªè¦å®ƒä»¬çš„å€¼éƒ½ä¸º 0ï¼Œåˆ™ä¸æ·»åŠ ä¸‰ä¸ªæ–°åŠŸèƒ½ï¼ˆENERGY RATING Aã€ENERGY RATING B å’Œ ENERGY RATING Cï¼‰ï¼Œå¹¶å‡è®¾åªè¦å®ƒä»¬çš„å€¼éƒ½ä¸º 0ï¼Œå°±ä¼šéšå¼è®¾ç½® ENERGY RATING Cã€‚"
        }
    },
    {
        "translation": {
            "en": "There are very few missing values for this feature (2%), so replacing them with an imputed value should not excessively affect the variance of the feature.",
            "zh": "æ­¤ç‰¹å¾çš„ç¼ºå¤±å€¼å¾ˆå°‘ ï¼ˆ2%ï¼‰ï¼Œå› æ­¤å°†å…¶æ›¿æ¢ä¸ºæ’è¡¥å€¼ä¸åº”è¿‡åº¦å½±å“ç‰¹å¾çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "These two paths of processing are then merged using an elementwise product operation between the tanh activations and the sigmoid activations (i.e., the vector mask).",
            "zh": "ç„¶åï¼Œä½¿ç”¨tanhæ¿€æ´»å’Œsigmoidæ¿€æ´»ï¼ˆå³å‘é‡æ©ç ï¼‰ä¹‹é—´çš„å…ƒç´ ä¹˜ç§¯æ“ä½œåˆå¹¶è¿™ä¸¤ç§å¤„ç†è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the k-d trees described in Section 5.4.2[196] require that the measure of similarity used be a metric (in particular that the measure conform to the triangular inequality constraint).",
            "zh": "ä¾‹å¦‚ï¼Œç¬¬ 5.4.2 èŠ‚[196] ä¸­æè¿°çš„ k-d æ ‘è¦æ±‚ä½¿ç”¨çš„ç›¸ä¼¼åº¦é‡æ˜¯åº¦é‡ï¼ˆç‰¹åˆ«æ˜¯åº¦é‡ç¬¦åˆä¸‰è§’ä¸ç­‰å¼çº¦æŸï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "29. Normally in machine learning, we do not test a model using the same dataset that we use to train it. Boosting, however, is an exception to this rule.",
            "zh": "29. é€šå¸¸ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šä½¿ç”¨ç”¨äºè®­ç»ƒæ¨¡å‹çš„ç›¸åŒæ•°æ®é›†æ¥æµ‹è¯•æ¨¡å‹ã€‚ç„¶è€Œï¼Œæå‡æ˜¯è¿™æ¡è§„åˆ™çš„ä¾‹å¤–ã€‚"
        }
    },
    {
        "translation": {
            "en": "A support vector machine model is defined as",
            "zh": "æ”¯æŒå‘é‡æœºæ¨¡å‹å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "CHROMATIN",
            "zh": "æŸ“è‰²è´¨"
        }
    },
    {
        "translation": {
            "en": "The scatter plot matrices (SPLOMs) described in Section 3.5.1[72] are really a visualization of the correlation matrix.",
            "zh": "ç¬¬3.5.1èŠ‚[72]ä¸­æè¿°çš„æ•£ç‚¹å›¾çŸ©é˜µï¼ˆSPLOMï¼‰å®é™…ä¸Šæ˜¯ç›¸å…³çŸ©é˜µçš„å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Diagnosis: Doctors, engineers, and scientists regularly make diagnoses as part of their work.",
            "zh": "è¯Šæ–­ï¼šåŒ»ç”Ÿã€å·¥ç¨‹å¸ˆå’Œç§‘å­¦å®¶å®šæœŸè¿›è¡Œè¯Šæ–­ï¼Œä½œä¸ºä»–ä»¬å·¥ä½œçš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many cases organizations begin analytics projects because they have a clear issue that they want to address.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œç»„ç»‡å¼€å§‹åˆ†æé¡¹ç›®æ˜¯å› ä¸ºä»–ä»¬æƒ³è¦è§£å†³ä¸€ä¸ªæ˜ç¡®çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is exactly the behavior we desire from a loss function: small values for correct predictions and large values for incorrect predictions.",
            "zh": "è¿™æ­£æ˜¯æˆ‘ä»¬æœŸæœ›ä»æŸå¤±å‡½æ•°ä¸­è·å¾—çš„è¡Œä¸ºï¼šæ­£ç¡®é¢„æµ‹çš„å°å€¼å’Œé”™è¯¯é¢„æµ‹çš„å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1987. Simplifying decision trees. International Journal of Man-Machine Studies 27 (3): 221â€“234.",
            "zh": "æ˜†å…°ï¼ŒJ.ç½—æ–¯ã€‚1987. ç®€åŒ–å†³ç­–æ ‘ã€‚å›½é™…äººæœºç ”ç©¶æ‚å¿— 27 ï¼ˆ3ï¼‰ï¼š 221â€“234."
        }
    },
    {
        "translation": {
            "en": "where is the dataset that has reached the node; n is the number of instances in ; is the mean of the target feature for the dataset ; and ti iterates across the target value of each instance in .",
            "zh": "å…¶ä¸­ æ˜¯å·²åˆ°è¾¾èŠ‚ç‚¹çš„æ•°æ®é›†;n æ˜¯ ä¸­çš„å®ä¾‹æ•°;æ˜¯æ•°æ®é›†ç›®æ ‡ç‰¹å¾çš„å¹³å‡å€¼;å’Œ ti éå† ä¸­æ¯ä¸ªå®ä¾‹çš„ç›®æ ‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "We also assume that all the neurons use a logistic activation function.",
            "zh": "æˆ‘ä»¬è¿˜å‡è®¾æ‰€æœ‰ç¥ç»å…ƒéƒ½ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using these results, we can compute the information gain ratio for each descriptive feature by dividing the featureâ€™s information gain by the entropy for that feature",
            "zh": "åˆ©ç”¨è¿™äº›ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šé™¤ä»¥è¯¥ç‰¹å¾çš„ç†µæ¥è®¡ç®—æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¯”"
        }
    },
    {
        "translation": {
            "en": "(left) The XOR function implemented as a two-layer neural network. (right) The network processing the four possible input combinations, one combination plus bias input per column: [bias, FALSE,FALSE] â†’ [1,0,0]; [bias, FALSE,TRUE] â†’ [1,0,1]; [bias, TRUE,FALSE] â†’ [1,1,0]; [bias, TRUE,TRUE] â†’ [1,1,1].",
            "zh": "ï¼ˆå·¦ï¼‰XOR å‡½æ•°ä½œä¸ºä¸¤å±‚ç¥ç»ç½‘ç»œå®ç°ã€‚ï¼ˆå³ï¼‰å¤„ç†å››ç§å¯èƒ½çš„è¾“å…¥ç»„åˆçš„ç½‘ç»œï¼Œæ¯åˆ—ä¸€ä¸ªç»„åˆåŠ ä¸Šåç½®è¾“å…¥ï¼š[biasï¼Œ FALSEï¼ŒFALSE] â†’ [1,0,0];[biasï¼Œ FALSEï¼ŒTRUE] â†’ [1,0,1];[åå·®ï¼ŒçœŸï¼Œå‡] â†’ [1,1,0];[biasï¼Œ TRUEï¼ŒTRUE] â†’ [1,1,1]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Regardless of the dataset used, the k-means clustering algorithm will always find the number of clusters requested from it regardless of whether these define meaningful structure within the dataset.",
            "zh": "æ— è®ºä½¿ç”¨ä½•ç§æ•°æ®é›†ï¼Œk-means èšç±»ç®—æ³•å°†å§‹ç»ˆæ‰¾åˆ°ä»ä¸­è¯·æ±‚çš„èšç±»æ•°é‡ï¼Œæ— è®ºè¿™äº›èšç±»æ˜¯å¦åœ¨æ•°æ®é›†ä¸­å®šä¹‰æœ‰æ„ä¹‰çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The networkâ€™s weight matrices are initialized in Line 2[420].",
            "zh": "ç½‘ç»œçš„æƒé‡çŸ©é˜µåœ¨ç¬¬ 2 è¡Œ [420] ä¸­åˆå§‹åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we have decided which analytics solution we are going to develop in response to a business problem, we need to begin to design the data structures that will be used to build, evaluate, and ultimately deploy the model. This work sits primarily in the Data Understanding phase of the CRISP-DM process (see Figure 1.4[16]) but also overlaps with the Business Understanding and Data Preparation phases (remember that the CRISP-DM process is not strictly linear).",
            "zh": "ä¸€æ—¦æˆ‘ä»¬å†³å®šäº†è¦å¼€å‘å“ªç§åˆ†æè§£å†³æ–¹æ¡ˆæ¥å“åº”ä¸šåŠ¡é—®é¢˜ï¼Œæˆ‘ä»¬å°±éœ€è¦å¼€å§‹è®¾è®¡æ•°æ®ç»“æ„ï¼Œè¿™äº›ç»“æ„å°†ç”¨äºæ„å»ºã€è¯„ä¼°å’Œæœ€ç»ˆéƒ¨ç½²æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œä¸»è¦ä½äº CRISP-DM æµç¨‹çš„æ•°æ®ç†è§£é˜¶æ®µï¼ˆå‚è§å›¾ 1.4[16]ï¼‰ï¼Œä½†ä¹Ÿä¸ä¸šåŠ¡ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µé‡å ï¼ˆè¯·è®°ä½ï¼ŒCRISP-DM æµç¨‹ä¸æ˜¯ä¸¥æ ¼çº¿æ€§çš„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Batista, Gustavo E. A. P. A., and Maria Carolina Monard. 2003. An analysis of four missing data treatment methods for supervised learning. Applied Artificial Intelligence 17 (5-6): 519â€“533.",
            "zh": "å·´è’‚æ–¯å¡”ã€å¤æ–¯å¡”æ²ƒ E. A. P. A. å’Œç›ä¸½äºšÂ·å¡ç½—è±çº³Â·è«çº³å¾·ã€‚2003. ç›‘ç£å­¦ä¹ çš„å››ç§ç¼ºå¤±æ•°æ®å¤„ç†æ–¹æ³•çš„åˆ†æ.åº”ç”¨äººå·¥æ™ºèƒ½17ï¼ˆ5-6ï¼‰ï¼š519-533ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on previous projects he had worked on, the current approach to customer retention that AT was taking, and ATâ€™s historical data, Ross agreed with AT management that a target reduction from the current high of approximately 10% to approximately 7.5% was realistic and probably achievable.",
            "zh": "æ ¹æ®ä»–ä¹‹å‰å‚ä¸çš„é¡¹ç›®ã€ATç›®å‰é‡‡å–çš„å®¢æˆ·ä¿ç•™æ–¹æ³•ä»¥åŠATçš„å†å²æ•°æ®ï¼ŒRossåŒæ„ATç®¡ç†å±‚çš„è§‚ç‚¹ï¼Œå³å°†ç›®æ ‡ä»ç›®å‰çš„çº¦10%çš„é«˜ç‚¹é™ä½åˆ°çº¦7.5%æ˜¯ç°å®çš„ï¼Œå¹¶ä¸”å¯èƒ½æ˜¯å¯ä»¥å®ç°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that we want to use shallow decision trees, is there a way in which we can automatically create them from data? One of the best known decision tree induction algorithms is the Iterative Dichotomizer 3 (ID3) algorithm.8 This algorithm attempts to create the shallowest decision tree that is consistent with the data given.",
            "zh": "å‡è®¾æˆ‘ä»¬æƒ³ä½¿ç”¨æµ…å±‚å†³ç­–æ ‘ï¼Œæœ‰æ²¡æœ‰åŠæ³•ä»æ•°æ®ä¸­è‡ªåŠ¨åˆ›å»ºå®ƒä»¬ï¼Ÿæœ€è‘—åçš„å†³ç­–æ ‘å½’çº³ç®—æ³•ä¹‹ä¸€æ˜¯è¿­ä»£äºŒåˆ†æ³•å™¨ 3 ï¼ˆID3ï¼‰ ç®—æ³•.8 è¯¥ç®—æ³•è¯•å›¾åˆ›å»ºä¸ç»™å®šæ•°æ®ä¸€è‡´çš„æœ€æµ…å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "SMARTPHONE: This feature indicated whether the customerâ€™s current handset was a smartphone, which was derived from the customerâ€™s most recent handset entry.",
            "zh": "æ™ºèƒ½æ‰‹æœºï¼šæ­¤åŠŸèƒ½æŒ‡ç¤ºå®¢æˆ·å½“å‰çš„æ‰‹æœºæ˜¯å¦ä¸ºæ™ºèƒ½æ‰‹æœºï¼Œè¯¥æ™ºèƒ½æ‰‹æœºæºè‡ªå®¢æˆ·æœ€è¿‘çš„æ‰‹æœºæ¡ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we replace A(1) in Equation (8.8)[395] with the right-hand side of Equation (8.7)[395] we get",
            "zh": "å¦‚æœæˆ‘ä»¬ç”¨ç­‰å¼ï¼ˆ8.7ï¼‰[395]çš„å³è¾¹æ›¿æ¢æ–¹ç¨‹ï¼ˆ8.8ï¼‰[395]ä¸­çš„Aï¼ˆ1ï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "The risks associated with setting k to a high value are particularly acute when we are dealing with an imbalanced dataset.",
            "zh": "å½“æˆ‘ä»¬å¤„ç†ä¸å¹³è¡¡çš„æ•°æ®é›†æ—¶ï¼Œå°† k è®¾ç½®ä¸ºé«˜å€¼çš„ç›¸å…³é£é™©å°¤ä¸ºä¸¥é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "LogitBoost, 171",
            "zh": "LogitBoostï¼Œ171"
        }
    },
    {
        "translation": {
            "en": "The raw data did not contain a single column that could be used as a target feature, so Jocelyn had to design one from the data sources that were present.",
            "zh": "åŸå§‹æ•°æ®ä¸åŒ…å«å¯ç”¨ä½œç›®æ ‡è¦ç´ çš„å•ä¸ªåˆ—ï¼Œå› æ­¤ Jocelyn å¿…é¡»æ ¹æ®å­˜åœ¨çš„æ•°æ®æºè®¾è®¡ä¸€ä¸ªåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many of the predictive models that we build are propensity models, which predict the likelihood (or propensity) of a future outcome based on a set of descriptive features describing the past.",
            "zh": "æˆ‘ä»¬æ„å»ºçš„è®¸å¤šé¢„æµ‹æ¨¡å‹éƒ½æ˜¯å€¾å‘æ¨¡å‹ï¼Œå®ƒæ ¹æ®ä¸€ç»„æè¿°è¿‡å»çš„æè¿°æ€§ç‰¹å¾æ¥é¢„æµ‹æœªæ¥ç»“æœçš„å¯èƒ½æ€§ï¼ˆæˆ–å€¾å‘ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "folds, 543",
            "zh": "è¤¶çš±ï¼Œ543"
        }
    },
    {
        "translation": {
            "en": "An illustration of the DQN algorithm including experience replay and target network freezing.",
            "zh": "DQN ç®—æ³•çš„å›¾ç¤ºï¼ŒåŒ…æ‹¬ä½“éªŒå›æ”¾å’Œç›®æ ‡ç½‘ç»œå†»ç»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means the overall prediction for the query instance is single, as this gets the highest normalized score.",
            "zh": "è¿™æ„å‘³ç€æŸ¥è¯¢å®ä¾‹çš„æ€»ä½“é¢„æµ‹æ˜¯å•ä¸€çš„ï¼Œå› ä¸ºè¿™ä¼šè·å¾—æœ€é«˜çš„è§„èŒƒåŒ–åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "binomial distribution, 178",
            "zh": "äºŒé¡¹åˆ†å¸ƒï¼Œ178"
        }
    },
    {
        "translation": {
            "en": "Figure 8.11[406] illustrates the forward pass in a little more detail.",
            "zh": "å›¾ 8.11[406] æ›´è¯¦ç»†åœ°è¯´æ˜äº†å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is generally used when networks use logistic or tanh activation functions.",
            "zh": "å®ƒé€šå¸¸ç”¨äºç½‘ç»œä½¿ç”¨ logistic æˆ– tanh æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, the values of the commonly used P20 and P45 potentials were measured while a participant viewed each image.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œåœ¨å‚ä¸è€…æŸ¥çœ‹æ¯å¼ å›¾åƒæ—¶æµ‹é‡å¸¸ç”¨çš„ P20 å’Œ P45 ç”µä½å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Processing these inputs, the hidden neurons generate activations that are then propagated forward to the output layer and also written to the activation memory buffer (overwriting whatever information was in the memory buffer).",
            "zh": "å¤„ç†è¿™äº›è¾“å…¥æ—¶ï¼Œéšè—çš„ç¥ç»å…ƒäº§ç”Ÿæ¿€æ´»ï¼Œç„¶åå‘å‰ä¼ æ’­åˆ°è¾“å‡ºå±‚ï¼Œå¹¶å†™å…¥æ¿€æ´»å†…å­˜ç¼“å†²åŒºï¼ˆè¦†ç›–å†…å­˜ç¼“å†²åŒºä¸­çš„ä»»ä½•ä¿¡æ¯ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dietterich (2000) give an excellent explanation of the motivations behind using ensembles, and Kuncheva (2004) and Zhou (2012) both provide good overviews of ensemble learning methods.",
            "zh": "Dietterichï¼ˆ2000ï¼‰å¾ˆå¥½åœ°è§£é‡Šäº†ä½¿ç”¨é›†æˆèƒŒåçš„åŠ¨æœºï¼ŒKunchevaï¼ˆ2004ï¼‰å’Œå‘¨ï¼ˆ2012ï¼‰éƒ½å¯¹é›†æˆå­¦ä¹ æ–¹æ³•è¿›è¡Œäº†å¾ˆå¥½çš„æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal of the agent is to complete the task as successfully as possible.",
            "zh": "ä»£ç†çš„ç›®æ ‡æ˜¯å°½å¯èƒ½æˆåŠŸåœ°å®Œæˆä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "One final thing worth noting is that temporal-difference learning is model-free.",
            "zh": "æœ€åä¸€ä»¶å€¼å¾—æ³¨æ„çš„äº‹æƒ…æ˜¯ï¼Œæ—¶é—´å·®åˆ†å­¦ä¹ æ˜¯æ— æ¨¡å‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Now, imagine that we have picked one of these cards and you have to guess which one by asking questions. Which of the following questions would you ask first?",
            "zh": "ç°åœ¨ï¼Œæƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬é€‰æ‹©äº†å…¶ä¸­ä¸€å¼ å¡ç‰‡ï¼Œæ‚¨å¿…é¡»é€šè¿‡æé—®æ¥çŒœæµ‹æ˜¯å“ªä¸€å¼ ã€‚æ‚¨é¦–å…ˆä¼šé—®ä»¥ä¸‹å“ªä¸ªé—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "â€”Nick Hornby, High Fidelity",
            "zh": "â€”Nick Hornbyï¼ŒHigh Fidelity"
        }
    },
    {
        "translation": {
            "en": "-0.6653",
            "zh": "-0.6653"
        }
    },
    {
        "translation": {
            "en": "subjective estimate, 757",
            "zh": "ä¸»è§‚ä¼°è®¡ï¼Œ757"
        }
    },
    {
        "translation": {
            "en": "A game of find the lady: (a) the cards used; (b) the cards dealt facedown on a table; (c) the initial likelihoods of the queen ending up in each position; and (d) a revised set of likelihoods for the position of the queen based on evidence collected.",
            "zh": "å¯»æ‰¾å¥³å£«çš„æ¸¸æˆï¼šï¼ˆaï¼‰ä½¿ç”¨çš„ç‰Œ;ï¼ˆbï¼‰ åœ¨æ¡Œå­ä¸Šå‘ç‰Œé¢æœä¸‹;ï¼ˆcï¼‰ å¥³ç‹æœ€ç»ˆæ‹…ä»»æ¯ä¸ªèŒä½çš„æœ€åˆå¯èƒ½æ€§;ï¼ˆdï¼‰æ ¹æ®æ”¶é›†åˆ°çš„è¯æ®ï¼Œå¯¹å¥³ç‹èŒä½çš„ä¸€ç³»åˆ—å¯èƒ½æ€§è¿›è¡Œäº†ä¿®è®¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that nearest neighbor models use the full set of descriptive features when making a prediction makes them particularly sensitive to the occurrence of missing descriptive feature values.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹åœ¨è¿›è¡Œé¢„æµ‹æ—¶ä½¿ç”¨å®Œæ•´çš„æè¿°æ€§ç‰¹å¾é›†ï¼Œè¿™ä¸€äº‹å®ä½¿å®ƒä»¬å¯¹ç¼ºå°‘æè¿°æ€§ç‰¹å¾å€¼çš„å‘ç”Ÿç‰¹åˆ«æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Models trained using error-based approaches can become overly complicated when the number of levels of the target feature goes above two, although deep neural network models handle these scenarios easily.",
            "zh": "å½“ç›®æ ‡ç‰¹å¾çš„çº§åˆ«æ•°è¶…è¿‡ä¸¤ä¸ªæ—¶ï¼Œä½¿ç”¨åŸºäºé”™è¯¯çš„æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹å¯èƒ½ä¼šå˜å¾—è¿‡äºå¤æ‚ï¼Œå°½ç®¡æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹å¯ä»¥è½»æ¾å¤„ç†è¿™äº›åœºæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even if significant computational resources were to be deployed for such a problem, it may not be possible for a k nearest neighbor model to perform fast enough to meet this requirement.",
            "zh": "å³ä½¿è¦ä¸ºæ­¤ç±»é—®é¢˜éƒ¨ç½²å¤§é‡è®¡ç®—èµ„æºï¼Œkä¸ªæœ€è¿‘é‚»æ¨¡å‹çš„æ‰§è¡Œé€Ÿåº¦ä¹Ÿå¯èƒ½ä¸è¶³ä»¥æ»¡è¶³æ­¤è¦æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.1â€…â€…â€…A credit scoring dataset.",
            "zh": "1.1 ä¿¡ç”¨è¯„åˆ†æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "As mentioned before this game has four actions available to the agent: None, Up, Left, and Right.",
            "zh": "å¦‚å‰æ‰€è¿°ï¼Œè¯¥æ¸¸æˆæœ‰å››ä¸ªæ“ä½œå¯ä¾›ä»£ç†ä½¿ç”¨ï¼šæ— ã€å‘ä¸Šã€å‘å·¦å’Œå‘å³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Where a named feature is binary, we use the lowercase initial letter of the name of the feature to denote the event where the feature is true and the lowercase initial letter preceded by the Â¬ symbol to denote the event where it is false. So, m will represent the event MENINGITIS = true, and Â¬m will denote MENINGITIS = false.",
            "zh": "å¦‚æœå‘½åç‰¹å¾æ˜¯äºŒè¿›åˆ¶çš„ï¼Œåˆ™æˆ‘ä»¬ä½¿ç”¨ç‰¹å¾åç§°çš„å°å†™é¦–å­—æ¯æ¥è¡¨ç¤ºç‰¹å¾ä¸ºçœŸçš„äº‹ä»¶ï¼Œå¹¶ä½¿ç”¨å‰é¢çš„å°å†™é¦–å­—æ¯ Â¬ ç¬¦å·æ¥è¡¨ç¤ºä¸ºå‡çš„äº‹ä»¶ã€‚å› æ­¤ï¼Œm è¡¨ç¤ºäº‹ä»¶ MENINGITIS = trueï¼ŒÂ¬m è¡¨ç¤º MENINGITIS = falseã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) What target level would a k-NN model with k = 3 and using Manhattan distance return for the same query?",
            "zh": "ï¼ˆdï¼‰ å¯¹äºåŒä¸€æŸ¥è¯¢ï¼Œk = 3 å¹¶ä½¿ç”¨æ›¼å“ˆé¡¿è·ç¦»çš„ k-NN æ¨¡å‹å°†è¿”å›ä»€ä¹ˆç›®æ ‡æ°´å¹³ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The model output is less than âˆ’ 1, so this query is predicted to be a faulty generator. For the second query instance, the model output is calculated similarly and is 1.592. This is greater than + 1, so this instance is predicted to be a good generator.",
            "zh": "æ¨¡å‹è¾“å‡ºå°äº âˆ’ 1ï¼Œå› æ­¤æ­¤æŸ¥è¯¢è¢«é¢„æµ‹ä¸ºæœ‰æ•…éšœçš„ç”Ÿæˆå™¨ã€‚å¯¹äºç¬¬äºŒä¸ªæŸ¥è¯¢å®ä¾‹ï¼Œæ¨¡å‹è¾“å‡ºçš„è®¡ç®—æ–¹å¼ç±»ä¼¼ï¼Œä¸º 1.592ã€‚è¿™å¤§äº + 1ï¼Œå› æ­¤é¢„è®¡æ­¤å®ä¾‹å°†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç”Ÿæˆå™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the ID3 algorithm the base cases are the situations in which we stop splitting the dataset and construct a leaf node with an associated target level.",
            "zh": "åœ¨ ID3 ç®—æ³•ä¸­ï¼ŒåŸºæœ¬æƒ…å†µæ˜¯æˆ‘ä»¬åœæ­¢æ‹†åˆ†æ•°æ®é›†å¹¶æ„é€ å…·æœ‰å…³è”ç›®æ ‡çº§åˆ«çš„å¶èŠ‚ç‚¹çš„æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "This suggests the need for a more sophisticated measure of the value of taking an action in a given state and leads to the final fundamental component of a reinforcement learning agent: a value function.",
            "zh": "è¿™è¡¨æ˜éœ€è¦å¯¹åœ¨ç»™å®šçŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„ä»·å€¼è¿›è¡Œæ›´å¤æ‚çš„åº¦é‡ï¼Œå¹¶å¯¼è‡´å¼ºåŒ–å­¦ä¹ ä»£ç†çš„æœ€åä¸€ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼šä»·å€¼å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Their inspiration for this work was linking the fact that propositional logic using a Boolean representation (TRUE/FALSE or 1/0) and neurons in the brain are somewhat similar, insofar as they have an all-or-none character (i.e., they act as a switch that responds to a set of inputs by outputting either a high activation or no activation).",
            "zh": "ä»–ä»¬è¿™é¡¹å·¥ä½œçš„çµæ„Ÿæ¥è‡ªäºå°†ä½¿ç”¨å¸ƒå°”è¡¨ç¤ºï¼ˆTRUE/FALSE æˆ– 1/0ï¼‰çš„å‘½é¢˜é€»è¾‘ä¸å¤§è„‘ä¸­çš„ç¥ç»å…ƒæœ‰äº›ç›¸ä¼¼çš„äº‹å®è”ç³»èµ·æ¥ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å…¨æœ‰æˆ–å…¨æ— çš„ç‰¹å¾ï¼ˆå³ï¼Œå®ƒä»¬å……å½“å¼€å…³ï¼Œé€šè¿‡è¾“å‡ºé«˜æ¿€æ´»æˆ–ä¸æ¿€æ´»æ¥å“åº”ä¸€ç»„è¾“å…¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The P(Y) terms on the left-hand side of this equation, however, cancel each other out to give us Bayesâ€™ Theorem",
            "zh": "ç„¶è€Œï¼Œè¿™ä¸ªæ–¹ç¨‹å·¦ä¾§çš„ Pï¼ˆYï¼‰ é¡¹ç›¸äº’æŠµæ¶ˆï¼Œä¸ºæˆ‘ä»¬æä¾›äº†è´å¶æ–¯å®šç†"
        }
    },
    {
        "translation": {
            "en": "Also, as the differences between the values of the descriptive features of two instances grows, so too does the distance between the points in the feature space that represent these instances.",
            "zh": "æ­¤å¤–ï¼Œéšç€ä¸¤ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾å€¼ä¹‹é—´çš„å·®å¼‚å¢å¤§ï¼Œç‰¹å¾ç©ºé—´ä¸­è¡¨ç¤ºè¿™äº›å®ä¾‹çš„ç‚¹ä¹‹é—´çš„è·ç¦»ä¹Ÿä¼šå¢å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is the goal behind the process of converting business problems into analytics solutions as part of the Business Understanding phase of the CRISP-DM process.",
            "zh": "è¿™æ˜¯å°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆçš„è¿‡ç¨‹èƒŒåçš„ç›®æ ‡ï¼Œä½œä¸º CRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£é˜¶æ®µçš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.6â€ƒFurther Reading",
            "zh": "4.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "The âˆ‚a/âˆ‚z for each neuron for d2 rounded to four decimal places.",
            "zh": "d2 ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚z å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "In its call records, AT did not include information about which network calls are made to, and with the free movement of numbers among operators, numbers themselves were no longer a reliable indicator of network.",
            "zh": "åœ¨å…¶é€šè¯è®°å½•ä¸­ï¼ŒATæ²¡æœ‰åŒ…æ‹¬æœ‰å…³å‘å“ªäº›ç½‘ç»œå‘¼å«è¿›è¡Œçš„ä¿¡æ¯ï¼Œå¹¶ä¸”éšç€å·ç åœ¨è¿è¥å•†ä¹‹é—´çš„è‡ªç”±ç§»åŠ¨ï¼Œå·ç æœ¬èº«ä¸å†æ˜¯ç½‘ç»œçš„å¯é æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "So far we have focused on calculating the probability of an individual event.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè®¡ç®—å•ä¸ªäº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The larger the value of Ïƒ, the lower the maximum height of the curve and the shallower the slope.",
            "zh": "Ïƒå€¼è¶Šå¤§ï¼Œæ›²çº¿çš„æœ€å¤§é«˜åº¦è¶Šä½ï¼Œæ–œç‡è¶Šæµ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "A better way to determine the importance of each descriptive feature in the model is to perform a statistical significance test.",
            "zh": "ç¡®å®šæ¨¡å‹ä¸­æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„é‡è¦æ€§çš„æ›´å¥½æ–¹æ³•æ˜¯æ‰§è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "ROC curve, 558",
            "zh": "ROCæ›²çº¿ï¼Œ558"
        }
    },
    {
        "translation": {
            "en": "Consequently, these theorems are not relevant to the practical task of training a network to learn a function because the inclusion of these complex functions within the neurons of the network shifts the learning burden from approximating the target function to finding these complex internal functions (Reed and Marks, 1999).",
            "zh": "å› æ­¤ï¼Œè¿™äº›å®šç†ä¸è®­ç»ƒç½‘ç»œå­¦ä¹ å‡½æ•°çš„å®é™…ä»»åŠ¡æ— å…³ï¼Œå› ä¸ºå°†è¿™äº›å¤æ‚å‡½æ•°åŒ…å«åœ¨ç½‘ç»œçš„ç¥ç»å…ƒä¸­ä¼šå°†å­¦ä¹ è´Ÿæ‹…ä»è¿‘ä¼¼ç›®æ ‡å‡½æ•°è½¬ç§»åˆ°æ‰¾åˆ°è¿™äº›å¤æ‚çš„å†…éƒ¨å‡½æ•°ï¼ˆReed and Marksï¼Œ 1999ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The purpose of this book is to give readers a solid grounding in the theoretical underpinnings of the most commonly used machine learning techniques and a clear view of the ways machine learning techniques are used in practice in predictive data analytics projects. With this in mind, readers can view the book as four parts that are mapped to the phases of the CRISP-DM process.",
            "zh": "æœ¬ä¹¦çš„ç›®çš„æ˜¯ä¸ºè¯»è€…æä¾›æœ€å¸¸ç”¨çš„æœºå™¨å­¦ä¹ æŠ€æœ¯çš„ç†è®ºåŸºç¡€çš„åšå®åŸºç¡€ï¼Œå¹¶æ¸…æ¥šåœ°äº†è§£æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä¸­çš„å®è·µä½¿ç”¨æ–¹å¼ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè¯»è€…å¯ä»¥å°†æœ¬ä¹¦è§†ä¸ºæ˜ å°„åˆ° CRISP-DM è¿‡ç¨‹å„ä¸ªé˜¶æ®µçš„å››ä¸ªéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some days Conor should order the item he knows he likes best, and some days he should choose something new.",
            "zh": "æœ‰äº›æ—¥å­ï¼Œåº·çº³åº”è¯¥è®¢è´­ä»–çŸ¥é“è‡ªå·±æœ€å–œæ¬¢çš„å•†å“ï¼Œæœ‰äº›æ—¥å­ä»–åº”è¯¥é€‰æ‹©æ–°çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4â€…â€…â€…Two decision trees, (a) and (b), that are consistent with the instances in the spam dataset; and (c) the path taken through the tree shown in (a) to make a prediction for the query instance SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, and CONTAINS IMAGES = true.",
            "zh": "4.4 ä¸¤ä¸ªå†³ç­–æ ‘ï¼Œï¼ˆaï¼‰å’Œï¼ˆbï¼‰ï¼Œä¸åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„å®ä¾‹ä¸€è‡´;ä»¥åŠ ï¼ˆcï¼‰ é€šè¿‡ ï¼ˆaï¼‰ æ‰€ç¤ºçš„æ ‘å¯¹æŸ¥è¯¢å®ä¾‹ SUSPICIOUS WORDS = trueã€UNKNOWN SENDER = true å’Œ CONTAINS IMAGES = true è¿›è¡Œé¢„æµ‹çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "comparative experiments, 583",
            "zh": "æ¯”è¾ƒå®éªŒï¼Œ583"
        }
    },
    {
        "translation": {
            "en": "Model",
            "zh": "å‹"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a Markov process diagram to capture the behavior of the taxi driver as described.",
            "zh": "ï¼ˆbï¼‰ ç»˜åˆ¶é©¬å°”å¯å¤«è¿‡ç¨‹å›¾ï¼Œä»¥æ•æ‰å‡ºç§Ÿè½¦å¸æœºçš„è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) In building a decision tree, the easiest way to handle a continuous feature is to define a threshold around which splits will be made. What would be the optimal threshold to split the continuous AGE feature (use information gain based on entropy as the feature selection measure)?",
            "zh": "ï¼ˆcï¼‰ åœ¨æ„å»ºå†³ç­–æ ‘æ—¶ï¼Œå¤„ç†è¿ç»­ç‰¹å¾çš„æœ€ç®€å•æ–¹æ³•æ˜¯å®šä¹‰ä¸€ä¸ªé˜ˆå€¼ï¼Œå›´ç»•è¯¥é˜ˆå€¼è¿›è¡Œæ‹†åˆ†ã€‚æ‹†åˆ†è¿ç»­AGEç‰¹å¾çš„æœ€ä½³é˜ˆå€¼æ˜¯å¤šå°‘ï¼ˆä½¿ç”¨åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šä½œä¸ºç‰¹å¾é€‰æ‹©åº¦é‡ï¼‰ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "In fact, partitioning the data by this feature creates two pure sets: one containing only instances with the target level spam and the other set containing only instances with the target level ham.",
            "zh": "äº‹å®ä¸Šï¼ŒæŒ‰æ­¤åŠŸèƒ½å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºä¼šåˆ›å»ºä¸¤ä¸ªçº¯é›†ï¼šä¸€ä¸ªä»…åŒ…å«å…·æœ‰ç›®æ ‡çº§åˆ«åƒåœ¾é‚®ä»¶çš„å®ä¾‹ï¼Œå¦ä¸€ä¸ªä»…åŒ…å«å…·æœ‰ç›®æ ‡çº§åˆ« ham çš„å®ä¾‹çš„é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "A single majority classification was calculated from the five manual classifications for each galaxy.",
            "zh": "æ ¹æ®æ¯ä¸ªæ˜Ÿç³»çš„äº”ä¸ªæ‰‹åŠ¨åˆ†ç±»è®¡ç®—å‡ºä¸€ä¸ªå•ä¸€å¤šæ•°åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.2.1â€…â€…â€…The Normal Distribution",
            "zh": "3.2.1 æ­£æ€åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "Table 10.2[611] shows an example of calculating the silhouette for the final clustering of the mobile phone customer dataset found using the k-means algorithm (with k = 3) (Table 10.1[604]). The cluster to which each instance has been assigned, the nearest other cluster to each instance, the values of a(i) and b(i), and the final silhouette value, s(i), are all shown. We discuss in detail the calculation of the silhouette width for the first instance in the dataset, d1.",
            "zh": "è¡¨10.2[611]æ˜¾ç¤ºäº†ä½¿ç”¨k-meansç®—æ³•ï¼ˆk = 3ï¼‰è®¡ç®—ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†æœ€ç»ˆèšç±»çš„è½®å»“çš„ç¤ºä¾‹ï¼ˆè¡¨10.1[604]ï¼‰ã€‚å°†æ˜¾ç¤ºæ¯ä¸ªå®ä¾‹åˆ†é…åˆ°çš„èšç±»ã€ç¦»æ¯ä¸ªå®ä¾‹æœ€è¿‘çš„å…¶ä»–èšç±»ã€aï¼ˆiï¼‰ å’Œ bï¼ˆiï¼‰ çš„å€¼ä»¥åŠæœ€ç»ˆçš„å‰ªå½±æ•ˆæœå€¼ sï¼ˆiï¼‰ã€‚æˆ‘ä»¬è¯¦ç»†è®¨è®ºäº†æ•°æ®é›†ä¸­ç¬¬ä¸€ä¸ªå®ä¾‹ d1 çš„è½®å»“å®½åº¦çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.5.5â€ƒHandling color images and multiple filtersâ€ƒAll the example filters that we previously presented were two-dimensional.",
            "zh": "8.4.5.5 å¤„ç†å½©è‰²å›¾åƒå’Œå¤šä¸ªæ»¤é•œ æˆ‘ä»¬ä¹‹å‰ä»‹ç»çš„æ‰€æœ‰ç¤ºä¾‹æ»¤é•œéƒ½æ˜¯äºŒç»´çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Definitions of some standard probability distributions.",
            "zh": "ä¸€äº›æ ‡å‡†æ¦‚ç‡åˆ†å¸ƒçš„å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.4106",
            "zh": "0.4106"
        }
    },
    {
        "translation": {
            "en": "Since all three plots show very similar distributions, we can conclude that no real relationship exists between these two features and that players of any career stage are equally likely to have a shoe sponsor or not.",
            "zh": "ç”±äºè¿™ä¸‰ä¸ªå›¾éƒ½æ˜¾ç¤ºå‡ºéå¸¸ç›¸ä¼¼çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œè¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´ä¸å­˜åœ¨çœŸæ­£çš„å…³ç³»ï¼Œå¹¶ä¸”ä»»ä½•èŒä¸šé˜¶æ®µçš„çƒå‘˜éƒ½æœ‰åŒæ ·çš„å¯èƒ½æ€§æœ‰é‹èµåŠ©å•†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 1993. Classification and regression trees. CRC Press.",
            "zh": "å¸ƒè±æ›¼ï¼Œç‹®å­åº§ã€‚1993. åˆ†ç±»å’Œå›å½’æ ‘.CRCå‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is similar to the way we calculate the error gradients with respect to the weights of a neuron, the difference here being that we want the error gradient with respect to the input hxt, and so in this case we multiply the Î´ by the weights rather than the inputs.",
            "zh": "è¿™ç±»ä¼¼äºæˆ‘ä»¬è®¡ç®—ç›¸å¯¹äºç¥ç»å…ƒæƒé‡çš„è¯¯å·®æ¢¯åº¦çš„æ–¹å¼ï¼Œè¿™é‡Œçš„åŒºåˆ«åœ¨äºæˆ‘ä»¬æƒ³è¦ç›¸å¯¹äºè¾“å…¥ hxt çš„è¯¯å·®æ¢¯åº¦ï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†Î´ä¹˜ä»¥æƒé‡è€Œä¸æ˜¯è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. For example, some of the feature values will be mislabeled.",
            "zh": "3. ä¾‹å¦‚ï¼ŒæŸäº›ç‰¹å¾å€¼å°†è¢«é”™è¯¯æ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.1[537] shows the expected targets for a small sample test set and a set of predictions made by a model trained for this prediction problem (the FP and FN comments in the Outcome column will be explained shortly).",
            "zh": "è¡¨ 9.1[537] æ˜¾ç¤ºäº†å°å‹æ ·æœ¬æµ‹è¯•é›†çš„é¢„æœŸç›®æ ‡ï¼Œä»¥åŠé’ˆå¯¹æ­¤é¢„æµ‹é—®é¢˜è®­ç»ƒçš„æ¨¡å‹æ‰€åšçš„ä¸€ç»„é¢„æµ‹ï¼ˆâ€œç»“æœâ€åˆ—ä¸­çš„ FP å’Œ FN æ³¨é‡Šå°†å¾ˆå¿«è§£é‡Šï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The standardization parameters (the mean and standard deviation of each feature) needed to be included in the pipeline so that the same preprocessing step could be applied to newly arriving instances before presenting them to the models.",
            "zh": "æ ‡å‡†åŒ–å‚æ•°ï¼ˆæ¯ä¸ªç‰¹å¾çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼‰éœ€è¦åŒ…å«åœ¨ç®¡é“ä¸­ï¼Œä»¥ä¾¿åœ¨å°†æ–°åˆ°è¾¾çš„å®ä¾‹å‘ˆç°ç»™æ¨¡å‹ä¹‹å‰ï¼Œå¯ä»¥å°†ç›¸åŒçš„é¢„å¤„ç†æ­¥éª¤åº”ç”¨äºè¿™äº›å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rewriting logistic(w Â·d) as ğ•„w(d) for readability, we get",
            "zh": "ä¸ºäº†æé«˜å¯è¯»æ€§ï¼Œå°† logisticï¼ˆw Â·dï¼‰ é‡å†™ä¸º Mwï¼ˆdï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "The simplest approach to handling missing values is to simply drop from an ABT any features that have them.",
            "zh": "å¤„ç†ç¼ºå¤±å€¼çš„æœ€ç®€å•æ–¹æ³•æ˜¯ç®€å•åœ°ä» ABT ä¸­åˆ é™¤å…·æœ‰ç¼ºå¤±å€¼çš„ä»»ä½•ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If, however, you wish to get a broader understanding of calculus, we recommend Stewart (2012) as an excellent textbook on all aspects of calculus.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæ‚¨å¸Œæœ›æ›´å¹¿æ³›åœ°äº†è§£å¾®ç§¯åˆ†ï¼Œæˆ‘ä»¬æ¨èStewartï¼ˆ2012ï¼‰ä½œä¸ºä¸€æœ¬å…³äºå¾®ç§¯åˆ†å„ä¸ªæ–¹é¢çš„ä¼˜ç§€æ•™ç§‘ä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sequence of observations, actions and rewards that precede any time-step, t, is referred to as a history, Ht. The job of the agent in the environment is to make decisions at each time-step, t, about what action to take next on the basis of its current observations of the environment, ot, and the history, Ht.",
            "zh": "ä»»ä½•æ—¶é—´æ­¥é•¿ t ä¹‹å‰çš„è§‚å¯Ÿã€æ“ä½œå’Œå¥–åŠ±åºåˆ—ç§°ä¸ºå†å²è®°å½• Htã€‚æ™ºèƒ½ä½“åœ¨ç¯å¢ƒä¸­çš„å·¥ä½œæ˜¯åœ¨æ¯ä¸ªæ—¶é—´æ­¥ t æ ¹æ®å…¶å½“å‰å¯¹ç¯å¢ƒçš„è§‚å¯Ÿ ot å’Œå†å² Ht æ¥å†³å®šä¸‹ä¸€æ­¥è¦é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "(2001), Bishop (2006), and Murphy (2012) for broad coverage of machine learning algorithms, including more in-depth coverage of unsupervised and reinforcement learning approaches than included in this book.",
            "zh": "ï¼ˆ2001ï¼‰ã€Bishop ï¼ˆ2006ï¼‰ å’Œ Murphy ï¼ˆ2012ï¼‰ å¯¹æœºå™¨å­¦ä¹ ç®—æ³•çš„å¹¿æ³›è¦†ç›–ï¼ŒåŒ…æ‹¬å¯¹æ— ç›‘ç£å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„æ›´æ·±å…¥çš„è¦†ç›–ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3â€ƒIdentifying Data Quality Issues",
            "zh": "3.3 è¯†åˆ«æ•°æ®è´¨é‡é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "In fact, searching for predictive models that are consistent with the dataset is equivalent to just memorizing the dataset.",
            "zh": "äº‹å®ä¸Šï¼Œæœç´¢ä¸æ•°æ®é›†ä¸€è‡´çš„é¢„æµ‹æ¨¡å‹ç­‰åŒäºä»…ä»…è®°ä½æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.1â€ƒBig Idea",
            "zh": "7.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "The regression equation for a multivariable linear regression model for the full dataset shown in Table 7.1[313] would look like",
            "zh": "è¡¨7.1[313]æ‰€ç¤ºçš„å®Œæ•´æ•°æ®é›†çš„å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„å›å½’æ–¹ç¨‹å¦‚ä¸‹æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "13.4.3â€…â€…â€…The 5-Level Model",
            "zh": "13.4.3 äº”çº§æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "This equation is equivalent to Equation (6.19)[288]. The fact that the probability P(t) is an unconditional probability simply reflects the structure of the naive Bayesâ€™ network where the target feature has no parent nodes (see Figure 6.11(a)[290]).",
            "zh": "è¯¥ç­‰ä»·äºç­‰å¼ï¼ˆ6.19ï¼‰[288]ã€‚æ¦‚ç‡ Pï¼ˆtï¼‰ æ˜¯æ— æ¡ä»¶æ¦‚ç‡è¿™ä¸€äº‹å®ä»…åæ˜ äº†æœ´ç´ è´å¶æ–¯ç½‘ç»œçš„ç»“æ„ï¼Œå…¶ä¸­ç›®æ ‡ç‰¹å¾æ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼ˆå‚è§å›¾ 6.11ï¼ˆaï¼‰[290]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The table below lists a set of instances from the house alarm domain. Using the data in this table, create the conditional probability tables (CPTs) for the network you created in Part (a) of this question.",
            "zh": "ï¼ˆbï¼‰ ä¸‹è¡¨åˆ—å‡ºäº†æˆ¿å±‹æŠ¥è­¦åŸŸä¸­çš„ä¸€ç»„å®ä¾‹ã€‚ä½¿ç”¨æ­¤è¡¨ä¸­çš„æ•°æ®ï¼Œä¸ºæ‚¨åœ¨æœ¬é—®é¢˜ ï¼ˆaï¼‰ éƒ¨åˆ†ä¸­åˆ›å»ºçš„ç½‘ç»œåˆ›å»ºæ¡ä»¶æ¦‚ç‡è¡¨ ï¼ˆCPTï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating exact probabilities for each of the possible target levels is often very useful to a human decision maker, for example, a doctor.",
            "zh": "è®¡ç®—æ¯ä¸ªå¯èƒ½çš„ç›®æ ‡æ°´å¹³çš„ç²¾ç¡®æ¦‚ç‡é€šå¸¸å¯¹äººç±»å†³ç­–è€…ï¼ˆä¾‹å¦‚åŒ»ç”Ÿï¼‰éå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.10",
            "zh": "è¡¨ 13.10"
        }
    },
    {
        "translation": {
            "en": "This works out really well when the set containing the single element contains the solution.",
            "zh": "å½“åŒ…å«å•ä¸ªå…ƒç´ çš„é›†åˆåŒ…å«æº¶æ¶²æ—¶ï¼Œè¿™éå¸¸æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "linear separator, 339",
            "zh": "çº¿æ€§åˆ†ç¦»å™¨ï¼Œ339"
        }
    },
    {
        "translation": {
            "en": "In this example we use Euclidean distance as the distance measure.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ä½œä¸ºè·ç¦»åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another problem with this model is that the model always makes completely confident predictions of 0 or 1.",
            "zh": "è¯¥æ¨¡å‹çš„å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œè¯¥æ¨¡å‹å§‹ç»ˆå¯¹ 0 æˆ– 1 åšå‡ºå®Œå…¨è‡ªä¿¡çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.3",
            "zh": "å›¾ 3.3"
        }
    },
    {
        "translation": {
            "en": "This is important because it allows multiple splits within a range of a continuous feature to be considered on a path.",
            "zh": "è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå…è®¸åœ¨è·¯å¾„ä¸Šè€ƒè™‘è¿ç»­ç‰¹å¾èŒƒå›´å†…çš„å¤šä¸ªæ‹†åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The average class accuracy (harmonic mean)",
            "zh": "ï¼ˆbï¼‰ å¹³å‡ç­‰çº§ç²¾åº¦ï¼ˆè°æ³¢å¹³å‡å€¼ï¼‰"
        }
    },
    {
        "translation": {
            "en": "8.2.2â€…â€…â€…Artificial Neural Networks",
            "zh": "8.2.2 äººå·¥ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "In this example the Îµ-greedy policy with Îµ = 0.1 is used throughout, and the hyper-parameters Î± and Î³ are set to Î± = 0.2 and Î³ = 0.9.23",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œå§‹ç»ˆä½¿ç”¨ Îµ = 0.1 çš„è´ªå©ªÎµç­–ç•¥ï¼Œå¹¶å°†è¶…å‚æ•° Î± å’Œ Î³ è®¾ç½®ä¸º Î± = 0.2 å’Œ Î³ = 0.9.23"
        }
    },
    {
        "translation": {
            "en": "The optimal values for the weights are the values that define the model with the minimum prediction error.",
            "zh": "æƒé‡çš„æœ€ä¼˜å€¼æ˜¯å®šä¹‰å…·æœ‰æœ€å°é¢„æµ‹è¯¯å·®çš„æ¨¡å‹çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.5â€…â€…â€…Illustration of the robustness of the student-t distribution to outliers: (a) a density histogram of a unimodal dataset overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data; and (b) a density histogram of the same dataset with outliers added, overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data.",
            "zh": "6.5 å­¦ç”Ÿ-tåˆ†å¸ƒå¯¹å¼‚å¸¸å€¼çš„é²æ£’æ€§è¯´æ˜ï¼šï¼ˆaï¼‰å•å³°æ•°æ®é›†çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œä¸Šé¢è¦†ç›–ç€å·²æ‹Ÿåˆåˆ°æ•°æ®çš„æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ-tåˆ†å¸ƒçš„å¯†åº¦æ›²çº¿;ï¼ˆbï¼‰æ·»åŠ äº†å¼‚å¸¸å€¼çš„åŒä¸€æ•°æ®é›†çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œä¸å·²æ‹Ÿåˆåˆ°æ•°æ®çš„æ­£æ€åˆ†å¸ƒå’Œå­¦ç”Ÿ-tåˆ†å¸ƒçš„å¯†åº¦æ›²çº¿å åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the next chapter, we describe the process we should follow to evaluate the quality of the data in the ABT and the actions we can take if the quality isnâ€™t good enough.",
            "zh": "åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»è¯„ä¼° ABT ä¸­æ•°æ®è´¨é‡æ—¶åº”éµå¾ªçš„æµç¨‹ï¼Œä»¥åŠå¦‚æœè´¨é‡ä¸å¤Ÿå¥½ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–çš„æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The motivation for using a row vector to hold one copy of the feature differences and a column vector to hold the second copy of the features differences is to facilitate matrix multiplication.",
            "zh": "ä½¿ç”¨è¡Œå‘é‡æ¥ä¿å­˜ç‰¹å¾å·®å¼‚çš„ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶ä½¿ç”¨åˆ—å‘é‡æ¥ä¿å­˜ç‰¹å¾å·®å¼‚çš„ç¬¬äºŒä¸ªå‰¯æœ¬çš„åŠ¨æœºæ˜¯ä¸ºäº†ä¿ƒè¿›çŸ©é˜µä¹˜æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In such a network, immediately after initialization, approximately half the hidden neurons in the network will have activations equal to zero; in a sense, in a network with a sparse representation, each input vector flows through a subset of active pathways in the network (Glorot et al., 2011).",
            "zh": "åœ¨è¿™æ ·çš„ç½‘ç»œä¸­ï¼Œåˆå§‹åŒ–åï¼Œç½‘ç»œä¸­å¤§çº¦ä¸€åŠçš„éšè—ç¥ç»å…ƒçš„æ¿€æ´»æ¬¡æ•°å°†ç­‰äºé›¶;ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œåœ¨å…·æœ‰ç¨€ç–è¡¨ç¤ºçš„ç½‘ç»œä¸­ï¼Œæ¯ä¸ªè¾“å…¥å‘é‡éƒ½æµç»ç½‘ç»œä¸­æ´»åŠ¨è·¯å¾„çš„å­é›†ï¼ˆGlorotç­‰äººï¼Œ2011ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A data quality issue arises when the cardinality for a feature does not match what we expect, a mismatch called an irregular cardinality.",
            "zh": "å½“è¦ç´ çš„åŸºæ•°ä¸æˆ‘ä»¬é¢„æœŸçš„ä¸åŒ¹é…æ—¶ï¼Œå°±ä¼šå‡ºç°æ•°æ®è´¨é‡é—®é¢˜ï¼Œè¿™ç§ä¸åŒ¹é…ç§°ä¸ºä¸è§„åˆ™åŸºæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the AGE, GENDER, CREDITRATING, and OCCUPATION columns from the customer demographics data warehouse could be directly included as descriptive features in the ABT to capture the CUSTOMER DEMOGRAPHICS domain concept.",
            "zh": "ä¾‹å¦‚ï¼Œå®¢æˆ·äººå£ç»Ÿè®¡æ•°æ®ä»“åº“ä¸­çš„ AGEã€GENDERã€CREDITRATING å’Œ OCCUPATION åˆ—å¯ä»¥ä½œä¸ºæè¿°æ€§ç‰¹å¾ç›´æ¥åŒ…å«åœ¨ ABT ä¸­ï¼Œä»¥æ•è· CUSTOMER DEMOGRAPHICS åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates that the SUSPICIOUS WORDS feature is a good feature to test if we are trying to decide whether a new emailâ€”not listed in the training datasetâ€”is spam or not.",
            "zh": "è¿™è¡¨æ˜ SUSPICIOUS WORDS åŠŸèƒ½æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åŠŸèƒ½ï¼Œå¯ä»¥æµ‹è¯•æˆ‘ä»¬æ˜¯å¦è¯•å›¾ç¡®å®šæ–°ç”µå­é‚®ä»¶ï¼ˆæœªåœ¨è®­ç»ƒæ•°æ®é›†ä¸­åˆ—å‡ºï¼‰æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Equation (8.121)[517] we calculate a vector containing Î´ values for the neurons in the output gate tanh layer by backpropagating the error gradients âˆ‚â„°/âˆ‚oâ€¡ back through that tanh activation function. Then in Equation (8.122)[517] we merge the two sets of gradients that arise from the fork in the forward propagation of ct to both the next time-step (as the cell state) and the output layer for this time-step.",
            "zh": "åœ¨æ–¹ç¨‹ï¼ˆ8.121ï¼‰[517]ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°†è¯¯å·®æ¢¯åº¦âˆ‚E/âˆ‚oâ€¡åå‘ä¼ æ’­å›è¯¥tanhæ¿€æ´»å‡½æ•°ï¼Œè®¡ç®—å‡ºè¾“å‡ºé—¨tanhå±‚ä¸­ç¥ç»å…ƒå€¼çš„Î´å‘é‡ã€‚ç„¶åï¼Œåœ¨ç­‰å¼ï¼ˆ8.122ï¼‰[517]ä¸­ï¼Œæˆ‘ä»¬åˆå¹¶äº†ä»ctå‰å‘ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼ˆä½œä¸ºå•å…ƒçŠ¶æ€ï¼‰å’Œè¯¥æ—¶é—´æ­¥é•¿çš„è¾“å‡ºå±‚çš„åˆ†å‰äº§ç”Ÿçš„ä¸¤ç»„æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The area under an ROC curve is calculated as the integral of the curve.",
            "zh": "ROC æ›²çº¿ä¸‹çš„é¢ç§¯è®¡ç®—ä¸ºæ›²çº¿çš„ç§¯åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4â€…â€…â€…The performance measures from the five individual evaluation experiments and an overall aggregate from the 5-fold cross validation performed on the chest X-ray classification dataset.",
            "zh": "9.4 æ¥è‡ªäº”ä¸ªå•ç‹¬è¯„ä¼°å®éªŒçš„æ€§èƒ½æµ‹é‡å’Œå¯¹èƒ¸éƒ¨ X å°„çº¿åˆ†ç±»æ•°æ®é›†è¿›è¡Œçš„ 5 å€äº¤å‰éªŒè¯çš„æ€»ä½“æ±‡æ€»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, in training an image processing model we typically want the model to generalize over the precise locations of features in training images so that it can still use these features when they occur in offset configurations in new images.",
            "zh": "äº‹å®ä¸Šï¼Œåœ¨è®­ç»ƒå›¾åƒå¤„ç†æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›æ¨¡å‹å¯¹è®­ç»ƒå›¾åƒä¸­ç‰¹å¾çš„ç²¾ç¡®ä½ç½®è¿›è¡Œæ³›åŒ–ï¼Œä»¥ä¾¿åœ¨æ–°å›¾åƒä¸­ä»¥åç§»é…ç½®å‡ºç°è¿™äº›ç‰¹å¾æ—¶ï¼Œå®ƒä»ç„¶å¯ä»¥ä½¿ç”¨è¿™äº›ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal of the network schematic on the left of Figure 8.37[502] is to provide a high-level overview of the template structure of a simple recurrent neural network.",
            "zh": "å›¾8.37[502]å·¦ä¾§çš„ç½‘ç»œåŸç†å›¾çš„ç›®çš„æ˜¯æä¾›ç®€å•å¾ªç¯ç¥ç»ç½‘ç»œçš„æ¨¡æ¿ç»“æ„çš„é«˜çº§æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We always expect the ROC curve for a trained model to be above this random reference line.15 In fact, as the strength of a predictive model increases, the ROC curve moves farther away from the random line toward the top left-hand corner of ROC spaceâ€”toward a TPR of 1.0 and an FPR of 0.0.",
            "zh": "15 äº‹å®ä¸Šï¼Œéšç€é¢„æµ‹æ¨¡å‹å¼ºåº¦çš„å¢åŠ ï¼ŒROC æ›²çº¿ä¼šä»éšæœºçº¿å‘ ROC ç©ºé—´çš„å·¦ä¸Šè§’ç§»åŠ¨ï¼ŒTPR ä¸º 1.0ï¼ŒFPR ä¸º 0.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating the stability index for the bacterial species identification problem given new test data for two periods after model deployment.",
            "zh": "è®¡ç®—æ¨¡å‹éƒ¨ç½²åä¸¤ä¸ªæ—¶æœŸçš„æ–°æµ‹è¯•æ•°æ®ä¸‹ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜çš„ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "These networks have been shown to be especially effective, particularly when states are stored in very low-level representations, such as the arrangement of pieces on a game board or a screenshot of a game.",
            "zh": "è¿™äº›ç½‘ç»œå·²è¢«è¯æ˜ç‰¹åˆ«æœ‰æ•ˆï¼Œç‰¹åˆ«æ˜¯å½“çŠ¶æ€ä»¥éå¸¸ä½çº§çš„è¡¨ç¤ºå½¢å¼å­˜å‚¨æ—¶ï¼Œä¾‹å¦‚æ¸¸æˆæ¿ä¸Šçš„æ£‹å­æ’åˆ—æˆ–æ¸¸æˆçš„å±å¹•æˆªå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This time, however, as the dealer drops the cards onto the table, a sudden gust of wind turns over the card on the right to reveal that it is the ace of spades (shown in Figure 6.2(a)[245]).",
            "zh": "ç„¶è€Œï¼Œè¿™ä¸€æ¬¡ï¼Œå½“åº„å®¶å°†ç‰Œæ‰”åˆ°æ¡Œå­ä¸Šæ—¶ï¼Œä¸€é˜µçªå¦‚å…¶æ¥çš„é£å¹ç¿»äº†å³è¾¹çš„ç‰Œï¼Œæ˜¾ç¤ºå®ƒæ˜¯é»‘æ¡ƒAï¼ˆå¦‚å›¾6.2ï¼ˆaï¼‰[245]æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.1â€…â€…â€…Vanishing Gradients and ReLUs",
            "zh": "8.4.1 æ¶ˆå¤±æ¢¯åº¦å’Œ ReLU"
        }
    },
    {
        "translation": {
            "en": "Throughout the course of a predictive data analytics project, we are forced to use our intuition and experience, and experimentation, to steer the project toward the best solution.",
            "zh": "åœ¨é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®çš„æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è¢«è¿«åˆ©ç”¨æˆ‘ä»¬çš„ç›´è§‰ã€ç»éªŒå’Œå®éªŒæ¥å¼•å¯¼é¡¹ç›®èµ°å‘æœ€ä½³è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Table A.4(a)[755] shows the density and probability calculations for the TRAINING EXPENSES feature when we use ten 200-unit intervals, and Table A.4(b)[755] shows the same calculations when we use four 500-unit intervals.7 Recall that we compute the density for each interval by dividing the number of observations in the interval by the width of the interval multiplied by the total number of observations.",
            "zh": "è¡¨ A.4ï¼ˆaï¼‰[755] æ˜¾ç¤ºäº†å½“æˆ‘ä»¬ä½¿ç”¨ 10 ä¸ª 200 ä¸ªå•ä½çš„åŒºé—´æ—¶ï¼Œè®­ç»ƒè´¹ç”¨ç‰¹å¾çš„å¯†åº¦å’Œæ¦‚ç‡è®¡ç®—ï¼Œè¡¨ A.4ï¼ˆbï¼‰[755] æ˜¾ç¤ºäº†å½“æˆ‘ä»¬ä½¿ç”¨ 4 ä¸ª 500 ä¸ªå•ä½çš„åŒºé—´æ—¶çš„ç›¸åŒè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is one of the key benefits of using logistic regression.",
            "zh": "è¿™æ˜¯ä½¿ç”¨é€»è¾‘å›å½’çš„ä¸»è¦å¥½å¤„ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "silhouette method, 612",
            "zh": "å‰ªå½±æ³•ï¼Œ612"
        }
    },
    {
        "translation": {
            "en": "In this example, the hidden state has a size of 2; however, typically the size of the hidden state is much larger.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œéšè—çŠ¶æ€çš„å¤§å°ä¸º 2;ä½†æ˜¯ï¼Œé€šå¸¸éšè—çŠ¶æ€çš„å¤§å°è¦å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Schematic of the simple recurrent neural architecture.",
            "zh": "ç®€å•é€’å½’ç¥ç»æ¶æ„çš„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The different weight initialization regimes that have been developed vary, depending on whether they take both nin and nout into account and the activation functions with which they work best.",
            "zh": "å·²ç»å¼€å‘çš„ä¸åŒæƒé‡åˆå§‹åŒ–æœºåˆ¶å„ä¸ç›¸åŒï¼Œè¿™å–å†³äºå®ƒä»¬æ˜¯å¦åŒæ—¶è€ƒè™‘äº† nin å’Œ noutï¼Œä»¥åŠå®ƒä»¬æœ€é€‚åˆçš„æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.3.1â€ƒA Worked Example",
            "zh": "10.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "For the simple version of the office rentals example that uses only the SIZE descriptive feature, described in Section 7.2.1[312], it is easy to visualize how the gradient descent algorithm would move iteratively toward a model that best fits the training data, making small adjustments each timeâ€”with each adjustment reducing the error of the model, just as our surfer from Section 7.1[311] did.",
            "zh": "å¯¹äºä»…ä½¿ç”¨ SIZE æè¿°æ€§ç‰¹å¾çš„åŠå…¬å®¤ç§Ÿèµç¤ºä¾‹çš„ç®€å•ç‰ˆæœ¬ï¼Œå¦‚ç¬¬ 7.2.1 èŠ‚[312]æ‰€è¿°ï¼Œå¾ˆå®¹æ˜“å¯è§†åŒ–æ¢¯åº¦ä¸‹é™ç®—æ³•å¦‚ä½•è¿­ä»£åœ°å‘æœ€é€‚åˆè®­ç»ƒæ•°æ®çš„æ¨¡å‹ç§»åŠ¨ï¼Œæ¯æ¬¡éƒ½è¿›è¡Œå°çš„è°ƒæ•´â€”â€”æ¯æ¬¡è°ƒæ•´éƒ½ä¼šå‡å°‘æ¨¡å‹çš„è¯¯å·®ï¼Œ å°±åƒæˆ‘ä»¬ç¬¬ 7.1 èŠ‚[311] ä¸­çš„å†²æµªè€…ä¸€æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that each fold of the test set contains only one instance, and the training set contains the remainder of the data.",
            "zh": "è¿™æ„å‘³ç€æµ‹è¯•é›†çš„æ¯ä¸ªæŠ˜å åªåŒ…å«ä¸€ä¸ªå®ä¾‹ï¼Œè€Œè®­ç»ƒé›†åŒ…å«å‰©ä½™çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider that the mean value of the distribution shown in Figure 3.2(f)[60] is likely to sit right in the valley between the two peaks, even though very few instances actually have this value.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾å›¾3.2ï¼ˆfï¼‰[60]æ‰€ç¤ºçš„åˆ†å¸ƒå¹³å‡å€¼å¯èƒ½æ­£å¥½ä½äºä¸¤ä¸ªå³°å€¼ä¹‹é—´çš„è°·å€¼ä¸­ï¼Œå°½ç®¡å®é™…ä¸Šå¾ˆå°‘æœ‰å®ä¾‹å…·æœ‰æ­¤å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. They make a prediction by aggregating the predictions of the different models in the ensemble. For categorical target features, this can be done using different types of voting mechanisms; and for continuous target features, this can be done using a measure of the central tendency of the different model predictions, such as the mean or the median.",
            "zh": "2. ä»–ä»¬é€šè¿‡èšåˆé›†æˆä¸­ä¸åŒæ¨¡å‹çš„é¢„æµ‹æ¥åšå‡ºé¢„æµ‹ã€‚å¯¹äºåˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒç±»å‹çš„æŠ•ç¥¨æœºåˆ¶æ¥å®Œæˆ;å¯¹äºè¿ç»­ç›®æ ‡ç‰¹å¾ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒæ¨¡å‹é¢„æµ‹ï¼ˆä¾‹å¦‚å‡å€¼æˆ–ä¸­ä½æ•°ï¼‰çš„ä¸­å¿ƒè¶‹åŠ¿åº¦é‡æ¥å®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "All the performance measures described in the previous section assumed that the prediction problem being evaluated had only two target levels. Many of the prediction problems for which we build models are multinomial, that is, there are multiple target levels. When we deal with multinomial prediction problems, we need a different set of performance measures. This section describes the most common of these. We begin by discussing how the confusion matrix can be extended to handle multiple target levels.",
            "zh": "ä¸Šä¸€èŠ‚ä¸­æè¿°çš„æ‰€æœ‰æ€§èƒ½åº¦é‡éƒ½å‡å®šæ­£åœ¨è¯„ä¼°çš„é¢„æµ‹é—®é¢˜åªæœ‰ä¸¤ä¸ªç›®æ ‡æ°´å¹³ã€‚æˆ‘ä»¬æ„å»ºæ¨¡å‹çš„è®¸å¤šé¢„æµ‹é—®é¢˜éƒ½æ˜¯å¤šé¡¹å¼çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰å¤šä¸ªç›®æ ‡æ°´å¹³ã€‚å½“æˆ‘ä»¬å¤„ç†å¤šé¡¹å¼é¢„æµ‹é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç»„ä¸åŒçš„æ€§èƒ½åº¦é‡ã€‚æœ¬èŠ‚ä»‹ç»å…¶ä¸­æœ€å¸¸è§çš„æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆè®¨è®ºå¦‚ä½•æ‰©å±•æ··æ·†çŸ©é˜µä»¥å¤„ç†å¤šä¸ªç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 8.4.4[472] we introduced dropout as one of the standard methods used to stop a deep learning network from overfitting.",
            "zh": "åœ¨ç¬¬ 8.4.4 èŠ‚[472]ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº† dropout ä½œä¸ºç”¨äºé˜»æ­¢æ·±åº¦å­¦ä¹ ç½‘ç»œè¿‡æ‹Ÿåˆçš„æ ‡å‡†æ–¹æ³•ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "random action selection policy, 656",
            "zh": "éšæœºæ“ä½œé€‰æ‹©ç­–ç•¥ï¼Œ656"
        }
    },
    {
        "translation": {
            "en": "Then during training after each iteration (or number of iterations), the current model is run on the validation set and its error is recorded.",
            "zh": "ç„¶åï¼Œåœ¨æ¯æ¬¡è¿­ä»£ï¼ˆæˆ–è¿­ä»£æ¬¡æ•°ï¼‰åçš„è®­ç»ƒæœŸé—´ï¼Œåœ¨éªŒè¯é›†ä¸Šè¿è¡Œå½“å‰æ¨¡å‹å¹¶è®°å½•å…¶é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hart, P. 1968. The condensed nearest neighbor rule. IEEE Transactions on Information Theory 14 (3): 515â€“516.",
            "zh": "å“ˆç‰¹ï¼Œç¬¬ 1968 é¡µã€‚æµ“ç¼©çš„æœ€è¿‘é‚»è§„åˆ™ã€‚IEEEä¿¡æ¯ç†è®ºæ±‡åˆŠ14ï¼ˆ3ï¼‰ï¼š515â€“516ã€‚"
        }
    },
    {
        "translation": {
            "en": "gradient boosting, xvi, 159, 164",
            "zh": "æ¢¯åº¦æå‡ï¼Œ xviï¼Œ 159ï¼Œ 164"
        }
    },
    {
        "translation": {
            "en": "If we update all the weights in the network using the process illustrated in Equation 8.39[432] for weight w 7,5 and then run the same examples through a forward pass of the network, we reduce the error of the model by a small amount; Table 8.8[433] lists the per example error and sum of squared errors for the four examples after all the weights have been updated.",
            "zh": "å¦‚æœæˆ‘ä»¬ä½¿ç”¨å…¬å¼ 8.39[432] ä¸­æ‰€ç¤ºçš„æƒé‡ w 7,5 çš„è¿‡ç¨‹æ›´æ–°ç½‘ç»œä¸­çš„æ‰€æœ‰æƒé‡ï¼Œç„¶åé€šè¿‡ç½‘ç»œçš„å‰å‘ä¼ é€’è¿è¡Œç›¸åŒçš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†æ¨¡å‹çš„è¯¯å·®å‡å°‘å°‘é‡;è¡¨ 8.8[433] åˆ—å‡ºäº†æ‰€æœ‰æƒé‡æ›´æ–°åæ¯ä¸ªç¤ºä¾‹çš„è¯¯å·®å’Œå››ä¸ªç¤ºä¾‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the weight matrix for the single layer network that would implement the equivalent mapping that this two-layer network implements.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—å•å±‚ç½‘ç»œçš„æƒé‡çŸ©é˜µï¼Œè¯¥çŸ©é˜µå°†å®ç°è¯¥åŒå±‚ç½‘ç»œå®ç°çš„ç­‰æ•ˆæ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.16",
            "zh": "å›¾ 7.16"
        }
    },
    {
        "translation": {
            "en": "If this assumption does not hold, then standardization may introduce some distortions.",
            "zh": "å¦‚æœè¿™ä¸ªå‡è®¾ä¸æˆç«‹ï¼Œé‚£ä¹ˆæ ‡å‡†åŒ–å¯èƒ½ä¼šå¼•å…¥ä¸€äº›æ‰­æ›²ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision boundary is the boundary between regions of the feature space in which different target levels will be predicted.",
            "zh": "å†³ç­–è¾¹ç•Œæ˜¯ç‰¹å¾ç©ºé—´åŒºåŸŸä¹‹é—´çš„è¾¹ç•Œï¼Œå…¶ä¸­å°†é¢„æµ‹ä¸åŒçš„ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first category of proofs that assume the use of complex functions within the neurons is based on the foundational mathematical theorems from Kolmogorov (1963) and Spercher (1965).",
            "zh": "ç¬¬ä¸€ç±»å‡è®¾åœ¨ç¥ç»å…ƒå†…ä½¿ç”¨å¤æ‚å‡½æ•°çš„è¯æ˜æ˜¯åŸºäºKolmogorovï¼ˆ1963ï¼‰å’ŒSpercherï¼ˆ1965ï¼‰çš„åŸºç¡€æ•°å­¦å®šç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "D.1â€…â€…â€…Basic Types",
            "zh": "D.1 åŸºæœ¬ç±»å‹"
        }
    },
    {
        "translation": {
            "en": "As such, Bayesian network models are an intermediary between full joint distributions and naive Bayes models and offer a useful compromise between model compactness and predictive accuracy.",
            "zh": "å› æ­¤ï¼Œè´å¶æ–¯ç½‘ç»œæ¨¡å‹æ˜¯å…¨è”åˆåˆ†å¸ƒå’Œæœ´ç´ è´å¶æ–¯æ¨¡å‹ä¹‹é—´çš„ä¸­ä»‹ï¼Œå¹¶åœ¨æ¨¡å‹ç´§å‡‘æ€§å’Œé¢„æµ‹å‡†ç¡®æ€§ä¹‹é—´æä¾›äº†æœ‰ç”¨çš„æŠ˜è¡·æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4â€ƒHandling Data Quality Issues",
            "zh": "3.4 å¤„ç†æ•°æ®è´¨é‡é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values for these query instances are q1 = âˆ’0.314, âˆ’0.251 and q2 = âˆ’0.117, 0.31.",
            "zh": "è¿™äº›æŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾å€¼ä¸º q1 = âˆ’0.314ã€âˆ’0.251 å’Œ q2 = âˆ’0.117ã€0.31ã€‚"
        }
    },
    {
        "translation": {
            "en": "When learning rate decay is used, there is much less thrashing back and forth across the error surface than when the large static learning rate is used.",
            "zh": "å½“ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡æ—¶ï¼Œä¸ä½¿ç”¨å¤§å‹é™æ€å­¦ä¹ ç‡æ—¶ç›¸æ¯”ï¼Œåœ¨é”™è¯¯è¡¨é¢ä¸Šæ¥å›æ™ƒåŠ¨è¦å°‘å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "One advantage of this was notational convenience; we were able to simplify Equation (8.2)[385].",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯ç¬¦å·çš„ä¾¿åˆ©æ€§;æˆ‘ä»¬èƒ½å¤Ÿç®€åŒ–æ–¹ç¨‹ï¼ˆ8.2ï¼‰[385]ã€‚"
        }
    },
    {
        "translation": {
            "en": "The predictions for this very simple ensemble model are given in Table 4.15[166] and visualized in Figure 4.22(c)[167], from which the characteristic step pattern of a decision tree is very obvious.",
            "zh": "è¡¨4.15[166]ç»™å‡ºäº†è¿™ä¸ªéå¸¸ç®€å•çš„é›†æˆæ¨¡å‹çš„é¢„æµ‹ï¼Œå¹¶åœ¨å›¾4.22ï¼ˆcï¼‰[167]ä¸­å¯è§†åŒ–ï¼Œä»ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºå†³ç­–æ ‘çš„ç‰¹å¾æ­¥è¿›æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy measure shown in Equation (9.11)[551] uses an arithmetic mean and so can be more fully labeled averageclassaccuracyAM.",
            "zh": "å…¬å¼ï¼ˆ9.11ï¼‰[551]ä¸­æ‰€ç¤ºçš„å¹³å‡ç±»å‡†ç¡®åº¦åº¦é‡ä½¿ç”¨ç®—æœ¯å¹³å‡å€¼ï¼Œå› æ­¤å¯ä»¥æ›´å®Œæ•´åœ°æ ‡è®°ä¸ºaverageclassaccuracyAMã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41",
            "zh": "å›¾ 8.41"
        }
    },
    {
        "translation": {
            "en": "The topology of the network can provide some insight into this problem.",
            "zh": "ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„å¯ä»¥æä¾›å¯¹æ­¤é—®é¢˜çš„ä¸€äº›è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, organizations begin analytics projects simply because somebody in the organization feels that this is an important new technique that they should be using.",
            "zh": "ç„¶è€Œï¼Œæœ‰æ—¶ç»„ç»‡å¼€å§‹åˆ†æé¡¹ç›®ä»…ä»…æ˜¯å› ä¸ºç»„ç»‡ä¸­çš„æŸä¸ªäººè®¤ä¸ºè¿™æ˜¯ä»–ä»¬åº”è¯¥ä½¿ç”¨çš„é‡è¦æ–°æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMANTS, NUM.",
            "zh": "ç´¢èµ”äººï¼Œç¼–å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.0599",
            "zh": "0.0599"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7(a)[194] illustrates the decision boundary when k = 15.",
            "zh": "å›¾5.7ï¼ˆaï¼‰[194]è¯´æ˜äº†k = 15æ—¶çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "lift, 567, 569, 700",
            "zh": "å‡é™æœºï¼Œ 567ï¼Œ 569ï¼Œ 700"
        }
    },
    {
        "translation": {
            "en": "0.0095",
            "zh": "0.0095"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming conditional independence between features given the target feature value, calculate the probability (rounded to four places of decimal) of each outcome (PURCHASED=true, and PURCHASED=false) for the following book:",
            "zh": "ï¼ˆbï¼‰ å‡è®¾ç»™å®šç›®æ ‡ç‰¹å¾å€¼çš„ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œè®¡ç®—ä»¥ä¸‹ä¹¦ç±çš„æ¯ä¸ªç»“æœï¼ˆPURCHASED=true å’Œ PURCHASED=falseï¼‰çš„æ¦‚ç‡ï¼ˆå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "columns in the data quality report highlight the percentage of missing values for each feature (both continuous and categorical) in an ABT, and so it is very easy to identify which features suffer from this issue.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„åˆ—çªå‡ºæ˜¾ç¤ºäº† ABT ä¸­æ¯ä¸ªç‰¹å¾ï¼ˆè¿ç»­å’Œåˆ†ç±»ï¼‰çš„ç¼ºå¤±å€¼çš„ç™¾åˆ†æ¯”ï¼Œå› æ­¤å¾ˆå®¹æ˜“è¯†åˆ«å“ªäº›ç‰¹å¾å­˜åœ¨æ­¤é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Any objects classified as belonging to the spiral target level were then presented to a model trained to distinguish between the three different spiral types.",
            "zh": "ç„¶åï¼Œå°†ä»»ä½•è¢«å½’ç±»ä¸ºå±äºèºæ—‹ç›®æ ‡çº§åˆ«çš„ç‰©ä½“å‘ˆç°ç»™ç»è¿‡è®­ç»ƒä»¥åŒºåˆ†ä¸‰ç§ä¸åŒèºæ—‹ç±»å‹çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature is the Corruption Perception Index (CPI). The CPI measures the perceived levels of corruption in the public sector of countries and ranges from 0 (highly corrupt) to 100 (very clean).34",
            "zh": "ç›®æ ‡ç‰¹å¾æ˜¯æ¸…å»‰æŒ‡æ•° ï¼ˆCPIï¼‰ã€‚æ¶ˆè´¹ç‰©ä»·æŒ‡æ•°è¡¡é‡çš„æ˜¯å„å›½å…¬å…±éƒ¨é—¨çš„è…è´¥ç¨‹åº¦ï¼ŒèŒƒå›´ä»0ï¼ˆé«˜åº¦è…è´¥ï¼‰åˆ°100ï¼ˆéå¸¸å¹²å‡€ï¼‰34ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the Î´ values for each of the processing neurons in the network (i.e., Î´6, Î´5, Î´4, Î´3).",
            "zh": "è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªå¤„ç†ç¥ç»å…ƒï¼ˆå³ Î´6ã€Î´5ã€Î´4ã€Î´3ï¼‰çš„Î´å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.1â€…â€…â€…The alignment between the phases of CRISP-DM, key questions for analytics projects, and the chapters and sections of this book.",
            "zh": "14.1 CRISP-DMçš„å„ä¸ªé˜¶æ®µã€åˆ†æé¡¹ç›®çš„å…³é”®é—®é¢˜ä»¥åŠæœ¬ä¹¦çš„ç« èŠ‚å’Œéƒ¨åˆ†ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the vector of error gradients with respect to hxt has been calculated for each of the layers, âˆ‚â„°/âˆ‚hx is calculated using an elementwise sum of these vectors of gradients",
            "zh": "ä¸€æ—¦è®¡ç®—äº†æ¯ä¸ªå±‚çš„è¯¯å·®æ¢¯åº¦å‘é‡ï¼Œå°±ä¼šä½¿ç”¨è¿™äº›æ¢¯åº¦å‘é‡çš„å…ƒç´ å’Œæ¥è®¡ç®— âˆ‚E/âˆ‚hx"
        }
    },
    {
        "translation": {
            "en": "environment, 643, 676",
            "zh": "ç¯å¢ƒï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Figure 6.10[288] illustrates the Markov blanket of a node.",
            "zh": "å›¾6.10[288]è¯´æ˜äº†èŠ‚ç‚¹çš„é©¬å°”å¯å¤«æ¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.2â€…â€…â€…What Is Machine Learning?",
            "zh": "1.2 ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "If the agent is in the PM-DH state, they must have a total value in their hand of either 15, 16, 17, or 18.",
            "zh": "å¦‚æœä»£ç†å¤„äº PM-DH çŠ¶æ€ï¼Œåˆ™ä»–ä»¬æ‰‹ä¸­çš„æ€»å€¼å¿…é¡»ä¸º 15ã€16ã€17 æˆ– 18ã€‚"
        }
    },
    {
        "translation": {
            "en": "data quality plan, 64, 94",
            "zh": "æ•°æ®è´¨é‡è®¡åˆ’ï¼Œ64,94"
        }
    },
    {
        "translation": {
            "en": "Agents trained using SARSA tend to learn more conservative strategies than agents trained using Q-learning.",
            "zh": "ä½¿ç”¨ SARSA è®­ç»ƒçš„æ™ºèƒ½ä½“å¾€å¾€æ¯”ä½¿ç”¨ Q-learning è®­ç»ƒçš„æ™ºèƒ½ä½“å­¦ä¹ æ›´ä¿å®ˆçš„ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is often referred to as a small multiples visualization.",
            "zh": "è¿™é€šå¸¸ç§°ä¸ºå°å€æ•°å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the context of a softmax layer, the non-normalized z values are often referred to as logits.",
            "zh": "åœ¨ softmax å±‚çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œéè§„èŒƒåŒ–çš„ z å€¼é€šå¸¸ç§°ä¸º logitsã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see from these examples that calculating derivatives of simple functions is a matter of, fairly mechanically, applying these four simple rules. Calculating the derivatives of the other two functions are left as exercises for the reader. Some of the functions that we will encounter later on in this chapter will be a little more complex, and we need two more differentiation rules to handle these.",
            "zh": "ä»è¿™äº›ä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œè®¡ç®—ç®€å•å‡½æ•°çš„å¯¼æ•°æ˜¯ç›¸å½“æœºæ¢°åœ°åº”ç”¨è¿™å››ä¸ªç®€å•è§„åˆ™çš„é—®é¢˜ã€‚è®¡ç®—å…¶ä»–ä¸¤ä¸ªå‡½æ•°çš„å¯¼æ•°ç•™ç»™è¯»è€…ä½œä¸ºç»ƒä¹ ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« åé¢é‡åˆ°çš„ä¸€äº›å‡½æ•°ä¼šç¨å¾®å¤æ‚ä¸€äº›ï¼Œæˆ‘ä»¬éœ€è¦æ›´å¤šçš„å¾®åˆ†è§„åˆ™æ¥å¤„ç†è¿™äº›è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "off-policy reinforcement learning, 659, 676",
            "zh": "éæ”¿ç­–å¼ºåŒ–å­¦ä¹ ï¼Œ659,676"
        }
    },
    {
        "translation": {
            "en": "mean squared error loss, 625",
            "zh": "å‡æ–¹è¯¯å·®æŸè€—ï¼Œ625"
        }
    },
    {
        "translation": {
            "en": "14.4â€…â€…â€…Your Next Steps",
            "zh": "14.4 æ‚¨çš„ä¸‹ä¸€æ­¥"
        }
    },
    {
        "translation": {
            "en": "The story of Professor Blondlot and N rays is true,1 and it is one of the most famous examples in all of science of how badly designed experiments can lead to completely inappropriate conclusions.",
            "zh": "å¸ƒéš†å¾·æ´›ç‰¹æ•™æˆå’Œ N å°„çº¿çš„æ•…äº‹æ˜¯çœŸå®çš„ï¼Œ1 å®ƒæ˜¯æ‰€æœ‰ç§‘å­¦ä¸­æœ€è‘—åçš„ä¾‹å­ä¹‹ä¸€ï¼Œè¯´æ˜è®¾è®¡ç³Ÿç³•çš„å®éªŒä¼šå¯¼è‡´å®Œå…¨ä¸æ°å½“çš„ç»“è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Banerji, Manda, Ofer Lahav, Chris J. Lintott, Filipe B. Abdalla, Kevin Schawinski, Steven P. Bamford, Dan Andreescu, Phil Murray, M. Jordan Raddick, Anze Slosar, Alex Szalay, Daniel Thomas, and Jan Vandenberg. 2010. Galaxy zoo: Reproducing galaxy morphologies via machine learning. Monthly Notices of the Royal Astronomical Society 406 (1): 342â€“353.",
            "zh": "ç­çº³å‰ã€æ›¼è¾¾ã€å¥¥å¼—Â·æ‹‰å“ˆå¤«ã€å…‹é‡Œæ–¯Â·æ—æ‰˜ç‰¹ã€è²åˆ©æ™®Â·é˜¿åœæœæ‹‰ã€å‡¯æ–‡Â·æ²™æ¸©æ–¯åŸºã€å²è’‚æ–‡Â·ç­ç¦å¾·ã€ä¸¹Â·å®‰å¾·è±æ–¯åº“ã€è²å°”Â·é»˜é‡Œã€MÂ·ä¹”ä¸¹Â·æ‹‰è¿ªå…‹ã€å®‰æ³½Â·æ–¯æ´›è¨å°”ã€äºšå†å…‹æ–¯Â·è¨è±ã€ä¸¹å°¼å°”Â·æ‰˜é©¬æ–¯å’Œæ‰¬Â·èŒƒç™»å ¡ã€‚2010. æ˜Ÿç³»åŠ¨ç‰©å›­ï¼šé€šè¿‡æœºå™¨å­¦ä¹ å†ç°æ˜Ÿç³»å½¢æ€ã€‚çš‡å®¶å¤©æ–‡å­¦ä¼šæœˆåˆŠ 406 ï¼ˆ1ï¼‰ï¼š342â€“353ã€‚"
        }
    },
    {
        "translation": {
            "en": "We concluded by explaining model ensembles.",
            "zh": "æœ€åï¼Œæˆ‘ä»¬è§£é‡Šäº†æ¨¡å‹é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Krizhevsky, A., I. Sutskever, and G. E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 1097â€“1105.",
            "zh": "Krizhevskyï¼Œ A.ã€I. Sutskever å’Œ GE Hintonã€‚2012. åŸºäºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„ Imagenet åˆ†ç±».åœ¨ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•ä¸­ï¼Œ1097-1105ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example, the cell state propagated forward from the previous time-step is ctâˆ’1 = [0.3,0.6 the hidden state propagated forward from the previous time-step is ht = [0.1,0.8 and the input at the xt = [0.9].",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä»å‰ä¸€ä¸ªæ—¶é—´æ­¥é•¿å‘å‰ä¼ æ’­çš„å•å…ƒçŠ¶æ€ä¸º ctâˆ’1 = [0.3,0.6ï¼Œä»å‰ä¸€ä¸ªæ—¶é—´æ­¥å‘å‰ä¼ æ’­çš„éšè—çŠ¶æ€ä¸º ht = [0.1,0.8ï¼Œxt = [0.9] å¤„çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, in complex domains, discriminative models are likely to be more accurate.",
            "zh": "å› æ­¤ï¼Œåœ¨å¤æ‚é¢†åŸŸä¸­ï¼Œåˆ¤åˆ«æ¨¡å‹å¯èƒ½æ›´å‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, under this factorization, we need to calculate only seven probabilities directly from the data: P(m), P(h | m), P(h | Â¬m), P(f | m), P(f | Â¬m), P(v | m), and P(v | Â¬m).",
            "zh": "å› æ­¤ï¼Œåœ¨è¿™ç§å› å¼åˆ†è§£ä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦ç›´æ¥ä»æ•°æ®ä¸­è®¡ç®—ä¸ƒä¸ªæ¦‚ç‡ï¼šPï¼ˆmï¼‰ã€Pï¼ˆh | mï¼‰ã€Pï¼ˆh | Â¬mï¼‰ã€Pï¼ˆf | mï¼‰ã€Pï¼ˆf | mï¼‰ã€Pï¼ˆv | mï¼‰ å’Œ Pï¼ˆv | Â¬mï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although any model can be used at the model training steps in gradient boosting, it is most common to use very shallow decision trees, or decision stumpsâ€”often just one level deep. This is using the same approach taken in random forests, which aims to combine a large number of weak learners into an overall strong learner.",
            "zh": "å°½ç®¡ä»»ä½•æ¨¡å‹éƒ½å¯ä»¥åœ¨æ¢¯åº¦æå‡çš„æ¨¡å‹è®­ç»ƒæ­¥éª¤ä¸­ä½¿ç”¨ï¼Œä½†æœ€å¸¸è§çš„æ˜¯ä½¿ç”¨éå¸¸æµ…çš„å†³ç­–æ ‘æˆ–å†³ç­–æ ‘æ¡©ï¼Œé€šå¸¸åªæœ‰ä¸€å±‚æ·±åº¦ã€‚è¿™ä½¿ç”¨äº†ä¸éšæœºæ£®æ—ç›¸åŒçš„æ–¹æ³•ï¼Œæ—¨åœ¨å°†å¤§é‡å¼±å­¦ä¹ è€…ç»„åˆæˆä¸€ä¸ªæ•´ä½“å¼ºå­¦ä¹ è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "A one-hot encoding is a vector-based representation of a categorial feature value.37 A one-hot vector has one element per level of the categorical feature.",
            "zh": "å•çƒ­ç¼–ç æ˜¯åˆ†ç±»ç‰¹å¾å€¼çš„åŸºäºå‘é‡çš„è¡¨ç¤ºã€‚37 å•çƒ­å‘é‡åœ¨åˆ†ç±»ç‰¹å¾çš„æ¯ä¸ªçº§åˆ«éƒ½æœ‰ä¸€ä¸ªå…ƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "A vector is an array of numbers, organized in a specific order. A vector can be either a column vector or a row vector. For example, a is a column vector, and b is a row vector.",
            "zh": "å‘é‡æ˜¯æŒ‰ç‰¹å®šé¡ºåºç»„ç»‡çš„æ•°å­—æ•°ç»„ã€‚å‘é‡å¯ä»¥æ˜¯åˆ—å‘é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯è¡Œå‘é‡ã€‚ä¾‹å¦‚ï¼Œa æ˜¯åˆ—å‘é‡ï¼Œb æ˜¯è¡Œå‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The hospital will use this model to make predictions for each patient when they visit the clinic and offer increased monitoring for those deemed to be at risk.",
            "zh": "åŒ»é™¢å°†ä½¿ç”¨è¯¥æ¨¡å‹å¯¹æ¯ä½æ‚£è€…å°±è¯Šæ—¶è¿›è¡Œé¢„æµ‹ï¼Œå¹¶åŠ å¼ºå¯¹è¢«è®¤ä¸ºæœ‰é£é™©çš„æ‚£è€…çš„ç›‘æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks are a network architecture that have been very successful at image processing tasks.",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§åœ¨å›¾åƒå¤„ç†ä»»åŠ¡ä¸­éå¸¸æˆåŠŸçš„ç½‘ç»œæ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.4.3â€ƒA worked example of multivariable logistic regressionâ€ƒOne of the advantages of using a logistic regression model is that it works well for datasets in which the instances with target features set to different levels overlap with each other in the feature space.",
            "zh": "7.4.4.3 å¤šå˜é‡é€»è¾‘å›å½’çš„æœ‰æ•ˆç¤ºä¾‹ ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯ï¼Œå®ƒé€‚ç”¨äºç›®æ ‡ç‰¹å¾è®¾ç½®ä¸ºä¸åŒçº§åˆ«çš„å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­ç›¸äº’é‡å çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "categorical cross entropy, 378",
            "zh": "åˆ†ç±»äº¤å‰ç†µï¼Œ378"
        }
    },
    {
        "translation": {
            "en": "It was understood by the AT retention team that customers often made a decision to churn if their bill increased significantly due to changing call patterns, or when they began to make large numbers of calls to new friends or colleagues on other networks.",
            "zh": "æ® AT ä¿ç•™å›¢é˜Ÿäº†è§£ï¼Œå¦‚æœå®¢æˆ·çš„è´¦å•å› é€šè¯æ¨¡å¼çš„æ”¹å˜è€Œå¤§å¹…å¢åŠ ï¼Œæˆ–è€…å½“ä»–ä»¬å¼€å§‹å‘å…¶ä»–ç½‘ç»œä¸Šçš„æ–°æœ‹å‹æˆ–åŒäº‹æ‹¨æ‰“å¤§é‡ç”µè¯æ—¶ï¼Œä»–ä»¬é€šå¸¸ä¼šåšå‡ºæµå¤±çš„å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "For ease of presentation we have reduced the input image to be a single column of 7 color pixels.",
            "zh": "ä¸ºäº†ä¾¿äºæ¼”ç¤ºï¼Œæˆ‘ä»¬å·²å°†è¾“å…¥å›¾åƒç®€åŒ–ä¸ºä¸€åˆ— 7 ä¸ªé¢œè‰²åƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "sampling with replacement, 159",
            "zh": "å–æ ·ä¸æ›´æ¢ï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "We noted at the start of this section that in order to train a deep network, it is important to keep the internal behavior of the network (i.e., the variance of the z values, activations, and Î´s) similar across all the layers during training, because doing so allows us to add more layers to the network while avoiding saturated units (by avoiding extreme z values) and exploding or vanishing Î´s.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬èŠ‚å¼€å¤´æŒ‡å‡ºï¼Œä¸ºäº†è®­ç»ƒæ·±åº¦ç½‘ç»œï¼Œåœ¨è®­ç»ƒæœŸé—´ä¿æŒç½‘ç»œå†…éƒ¨è¡Œä¸ºï¼ˆå³ z å€¼ã€æ¿€æ´»å’Œ Î´ çš„æ–¹å·®ï¼‰åœ¨æ‰€æœ‰å±‚ä¸­ç›¸ä¼¼æ˜¯å¾ˆé‡è¦çš„ï¼Œå› ä¸ºè¿™æ ·åšå¯ä»¥è®©æˆ‘ä»¬å‘ç½‘ç»œæ·»åŠ æ›´å¤šå±‚ï¼ŒåŒæ—¶é¿å…é¥±å’Œå•ä½ï¼ˆé€šè¿‡é¿å…æç«¯ z å€¼ï¼‰å’Œçˆ†ç‚¸æˆ–æ¶ˆå¤± Î´sã€‚"
        }
    },
    {
        "translation": {
            "en": "However, a popular combination is to use a stride length of 1 and to pad the image with imaginary pixels (Charniak, 2019, p. 56).",
            "zh": "ç„¶è€Œï¼Œä¸€ç§æµè¡Œçš„ç»„åˆæ˜¯ä½¿ç”¨ 1 çš„æ­¥å¹…å¹¶ç”¨å‡æƒ³åƒç´ å¡«å……å›¾åƒï¼ˆCharniakï¼Œ2019 å¹´ï¼Œç¬¬ 56 é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Like simpler boosting algorithms, gradient boosting iteratively trains prediction models trying to make later models specialize in areas that earlier models struggled with.",
            "zh": "ä¸æ›´ç®€å•çš„æå‡ç®—æ³•ä¸€æ ·ï¼Œæ¢¯åº¦æå‡ä»¥è¿­ä»£æ–¹å¼è®­ç»ƒé¢„æµ‹æ¨¡å‹ï¼Œè¯•å›¾ä½¿åæ¥çš„æ¨¡å‹ä¸“æ³¨äºæ—©æœŸæ¨¡å‹éš¾ä»¥è§£å†³çš„é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, at least two reasons why simply searching for consistent models is not sufficient for learning useful prediction models.",
            "zh": "ç„¶è€Œï¼Œè‡³å°‘æœ‰ä¸¤ä¸ªåŸå› å¯ä»¥è§£é‡Šä¸ºä»€ä¹ˆä»…ä»…æœç´¢ä¸€è‡´çš„æ¨¡å‹ä¸è¶³ä»¥å­¦ä¹ æœ‰ç”¨çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "unimodal distribution, 59, 272",
            "zh": "å•å³°åˆ†å¸ƒï¼Œ 59ï¼Œ 272"
        }
    },
    {
        "translation": {
            "en": "enrich data, 599, 629",
            "zh": "ä¸°å¯Œæ•°æ®ï¼Œ599,629"
        }
    },
    {
        "translation": {
            "en": "In this edition we have sought to expand the topics covered in the first edition to bring them up to date with modern developments, while at the same time staying true to the approach used in the first edition of covering the core concepts in the field in depth with fully worked examples.",
            "zh": "åœ¨æœ¬ç‰ˆä¸­ï¼Œæˆ‘ä»¬è¯•å›¾æ‰©å±•ç¬¬ä¸€ç‰ˆä¸­æ¶µç›–çš„ä¸»é¢˜ï¼Œä»¥ä½¿å…¶ä¸ç°ä»£å‘å±•ä¿æŒåŒæ­¥ï¼ŒåŒæ—¶å¿ å®äºç¬¬ä¸€ç‰ˆä¸­ä½¿ç”¨çš„æ–¹æ³•ï¼Œå³é€šè¿‡å……åˆ†çš„å®ä¾‹æ·±å…¥æ¶µç›–è¯¥é¢†åŸŸçš„æ ¸å¿ƒæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "A learning rate is used to control the size of the changes that are made to the action-value estimates at each iteration.",
            "zh": "å­¦ä¹ ç‡ç”¨äºæ§åˆ¶æ¯æ¬¡è¿­ä»£æ—¶å¯¹æ“ä½œå€¼ä¼°è®¡å€¼æ‰€åšçš„æ›´æ”¹çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, it checks that the node is not NULL.",
            "zh": "é¦–å…ˆï¼Œå®ƒæ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦ä¸º NULLã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.3 and Neuron 2 = 0.6, and that the desired output for this input is Neuron 5 = 0.7 and Neuron 6 = 0.4:",
            "zh": "ï¼ˆaï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.3 å’Œç¥ç»å…ƒ 2 = 0.6ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æœŸæœ›è¾“å‡ºæ˜¯ç¥ç»å…ƒ 5 = 0.7 å’Œç¥ç»å…ƒ 6 = 0.4ï¼š"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from the test of the AT churn prediction non-stratified hold-out test set.",
            "zh": "æ¥è‡ª AT æµå¤±é¢„æµ‹éåˆ†å±‚ä¿æŒæµ‹è¯•é›†çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "OBJID",
            "zh": "OBJIDçš„"
        }
    },
    {
        "translation": {
            "en": "NUMRETENTIONCALLS",
            "zh": "NUMRETENTIONCALLS"
        }
    },
    {
        "translation": {
            "en": "Technically, a filter can be defined as a heuristic rule that assesses the predictiveness of a feature using only the intrinsic properties of the data, independently of the learning algorithm that will use the features to induce the model.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œè¿‡æ»¤å™¨å¯ä»¥å®šä¹‰ä¸ºä¸€ç§å¯å‘å¼è§„åˆ™ï¼Œè¯¥è§„åˆ™ä»…ä½¿ç”¨æ•°æ®çš„å†…åœ¨å±æ€§æ¥è¯„ä¼°ç‰¹å¾çš„é¢„æµ‹æ€§ï¼Œè€Œä¸å°†ä½¿ç”¨ç‰¹å¾æ¥è¯±å¯¼æ¨¡å‹çš„å­¦ä¹ ç®—æ³•æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conversely, if the feature we are dealing with is a continuous feature, the probability function is known as a probability density function.",
            "zh": "ç›¸åï¼Œå¦‚æœæˆ‘ä»¬å¤„ç†çš„ç‰¹å¾æ˜¯è¿ç»­ç‰¹å¾ï¼Œåˆ™æ¦‚ç‡å‡½æ•°ç§°ä¸ºæ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œA map is not the territory it represents, but, if correct, it has a similar structure to the territory, which accounts for its usefulness.â€",
            "zh": "â€œåœ°å›¾ä¸æ˜¯å®ƒæ‰€ä»£è¡¨çš„é¢†åœŸï¼Œä½†æ˜¯ï¼Œå¦‚æœæ­£ç¡®çš„è¯ï¼Œå®ƒä¸é¢†åœŸå…·æœ‰ç›¸ä¼¼çš„ç»“æ„ï¼Œè¿™è§£é‡Šäº†å®ƒçš„æœ‰ç”¨æ€§ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "A key step in any predictive analytics project is deciding which type of predictive analytics model to use.",
            "zh": "ä»»ä½•é¢„æµ‹åˆ†æé¡¹ç›®çš„ä¸€ä¸ªå…³é”®æ­¥éª¤æ˜¯ç¡®å®šè¦ä½¿ç”¨çš„é¢„æµ‹åˆ†ææ¨¡å‹ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The silhouette width for an individual instance is essentially a localized ratio of inter-cluster and intra-cluster distances capturing how well the instance di has been clustered.",
            "zh": "å•ä¸ªå®ä¾‹çš„è½®å»“å®½åº¦å®è´¨ä¸Šæ˜¯é›†ç¾¤é—´å’Œé›†ç¾¤å†…è·ç¦»çš„å±€éƒ¨æ¯”ç‡ï¼Œç”¨äºæ•è·å®ä¾‹ di çš„èšç±»ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "labeled dataset, 9",
            "zh": "æ ‡è®°æ•°æ®é›†ï¼Œ9"
        }
    },
    {
        "translation": {
            "en": "The logistic regression approach (and the SVM approach) discussed in this chapter is at a disadvantage to those discussed in the previous chapters in that in its basic form, it can only handle categorical target features with two levels.",
            "zh": "æœ¬ç« è®¨è®ºçš„é€»è¾‘å›å½’æ–¹æ³•ï¼ˆå’Œ SVM æ–¹æ³•ï¼‰ä¸å‰å‡ ç« è®¨è®ºçš„æ–¹æ³•ç›¸æ¯”å¤„äºåŠ£åŠ¿ï¼Œå› ä¸ºå®ƒçš„åŸºæœ¬å½¢å¼åªèƒ½å¤„ç†å…·æœ‰ä¸¤ä¸ªçº§åˆ«çš„åˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Andoni, Alexandr, and Piotr Indyk. 2006. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In Proceedings of the 47th annual IEEE symposium on foundations of computer science (FOCSâ€™06), 459â€“468. IEEE.",
            "zh": "Andoniã€Alexandr å’Œ Piotr Indykã€‚2006. é«˜ç»´è¿‘ä¼¼æœ€è¿‘é‚»çš„è¿‘ä¼¼å“ˆå¸Œç®—æ³•.åœ¨ç¬¬ 47 å±Šå¹´åº¦ IEEE è®¡ç®—æœºç§‘å­¦åŸºç¡€ç ”è®¨ä¼š ï¼ˆFOCS'06ï¼‰ çš„è®ºæ–‡é›†ä¸­ï¼Œç¬¬ 459â€“468 é¡µã€‚IEEEçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we might want to know the probability of the target feature taking a particular value and one of the descriptive features taking a particular value at the same time.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³çŸ¥é“ç›®æ ‡ç‰¹å¾é‡‡ç”¨ç‰¹å®šå€¼å’Œæè¿°æ€§ç‰¹å¾ä¹‹ä¸€åŒæ—¶é‡‡ç”¨ç‰¹å®šå€¼çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.10",
            "zh": "å›¾ 6.10"
        }
    },
    {
        "translation": {
            "en": "In Chapter 1[3] of this book we described supervised machine learning techniques as automatically learning a model of the relationship between a set of descriptive features and a target feature on the basis of a set of historical instances.",
            "zh": "åœ¨æœ¬ä¹¦çš„ç¬¬ 1 ç« [3]ä¸­ï¼Œæˆ‘ä»¬å°†ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯æè¿°ä¸ºåŸºäºä¸€ç»„å†å²å®ä¾‹è‡ªåŠ¨å­¦ä¹ ä¸€ç»„æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "From top to bottom, the models use 0.4, 0.5, 0.62, 0.7, and 0.8, respectively, for w[1].",
            "zh": "ä»ä¸Šåˆ°ä¸‹ï¼Œæ¨¡å‹åˆ†åˆ«ä½¿ç”¨ 0.4ã€0.5ã€0.62ã€0.7 å’Œ 0.8 è¡¨ç¤º w[1]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adding depth to a filter not only enables a convolutional neural network to process color images that contain multiple channels; it also enables a convolutional network to have a sequence of multi-filter convolutional layers.",
            "zh": "ä¸ºæ»¤æ³¢å™¨æ·»åŠ æ·±åº¦ä¸ä»…ä½¿å·ç§¯ç¥ç»ç½‘ç»œèƒ½å¤Ÿå¤„ç†åŒ…å«å¤šä¸ªé€šé“çš„å½©è‰²å›¾åƒ;å®ƒè¿˜ä½¿å·ç§¯ç½‘ç»œå…·æœ‰ä¸€ç³»åˆ—å¤šæ»¤æ³¢å™¨å·ç§¯å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œfree machine learningâ€",
            "zh": "â€œå…è´¹æœºå™¨å­¦ä¹ â€"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks achieve translation equivariant feature detection through weight sharing.",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œé€šè¿‡æƒé‡å…±äº«å®ç°å¹³ç§»ç­‰å˜ç‰¹å¾æ£€æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The derivative of a saturated activation function is 0 (or near 0).",
            "zh": "é¥±å’Œæ¿€æ´»å‡½æ•°çš„å¯¼æ•°ä¸º 0ï¼ˆæˆ–æ¥è¿‘ 0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean tends toward the smaller values in a list of numbers and so can be less sensitive to large outliers than the arithmetic mean, which tends toward higher values.",
            "zh": "è°æ³¢å¹³å‡å€¼è¶‹å‘äºæ•°å­—åˆ—è¡¨ä¸­çš„è¾ƒå°å€¼ï¼Œå› æ­¤å¯¹å¤§å¼‚å¸¸å€¼çš„æ•æ„Ÿåº¦ä½äºç®—æœ¯å¹³å‡å€¼ï¼Œè€Œç®—æœ¯å¹³å‡å€¼è¶‹å‘äºè¾ƒé«˜çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. Target level imbalance affects misclassification rate in the same way, and average misclassification rate can also be calculated to combat this problem.",
            "zh": "8.ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡ä»¥åŒæ ·çš„æ–¹å¼å½±å“è¯¯åˆ†ç±»ç‡ï¼Œå¹³å‡è¯¯åˆ†ç±»ç‡ä¹Ÿå¯ä»¥è®¡ç®—å‡ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.3â€…â€…â€…Handling Time",
            "zh": "2.4.3 å¤„ç†æ—¶é—´"
        }
    },
    {
        "translation": {
            "en": "To complete the network, we need to add the CPTs.",
            "zh": "ä¸ºäº†å®Œæˆç½‘ç»œï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ  CPTã€‚"
        }
    },
    {
        "translation": {
            "en": "An analysis of historical data suggests that the rate of readmission within 30 days of being discharged for patients who were hospitalized for complications relating to diabetes is approximately 20%, compared to an overall average for all patients of approximately 11%.",
            "zh": "å¯¹å†å²æ•°æ®çš„åˆ†æè¡¨æ˜ï¼Œå› ç³–å°¿ç—…ç›¸å…³å¹¶å‘ç—‡ä½é™¢çš„æ‚£è€…åœ¨å‡ºé™¢å 30 å¤©å†…çš„å†å…¥é™¢ç‡çº¦ä¸º 20%ï¼Œè€Œæ‰€æœ‰æ‚£è€…çš„æ€»ä½“å¹³å‡æ°´å¹³çº¦ä¸º 11%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Despite this simplifying assumption, however, the naive Bayes approach has been found to be surprisingly accurate across a large range of domains.",
            "zh": "ç„¶è€Œï¼Œå°½ç®¡æœ‰è¿™ç§ç®€åŒ–çš„å‡è®¾ï¼Œä½†äººä»¬å‘ç°æœ´ç´ çš„è´å¶æ–¯æ–¹æ³•åœ¨å¹¿æ³›çš„é¢†åŸŸä¸­å‡ºå¥‡åœ°å‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Given the state representation that you have defined in Part (a) and the actions available to the agent, how many entries would the action-value function table for a tabular reinforcement learning agent trained for this task have?",
            "zh": "ï¼ˆbï¼‰ é‰´äºæ‚¨åœ¨ ï¼ˆaï¼‰ éƒ¨åˆ†ä¸­å®šä¹‰çš„çŠ¶æ€è¡¨ç¤ºä»¥åŠä»£ç†å¯ç”¨çš„æ“ä½œï¼Œä¸ºæ­¤ä»»åŠ¡è®­ç»ƒçš„è¡¨æ ¼å¼ºåŒ–å­¦ä¹ ä»£ç†çš„åŠ¨ä½œå€¼å‡½æ•°è¡¨å°†æœ‰å¤šå°‘ä¸ªæ¡ç›®ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "A key part of doing this is being able to decide which tests should be included in the sequence and in what order.",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªå…³é”®éƒ¨åˆ†æ˜¯èƒ½å¤Ÿå†³å®šå“ªäº›æµ‹è¯•åº”è¯¥åŒ…å«åœ¨åºåˆ—ä¸­ä»¥åŠä»¥ä»€ä¹ˆé¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "k-d tree, 181, 196, 212, 232, 241",
            "zh": "K-Dæ ‘ï¼Œ 181ï¼Œ 196ï¼Œ 212ï¼Œ 232ï¼Œ 241"
        }
    },
    {
        "translation": {
            "en": "There are two ways that this can speed up neural network training and data processing:",
            "zh": "æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åŠ å¿«ç¥ç»ç½‘ç»œè®­ç»ƒå’Œæ•°æ®å¤„ç†é€Ÿåº¦ï¼š"
        }
    },
    {
        "translation": {
            "en": "Multiplying the weight matrix by the augmented input vector generates the vector of weighted sums for the hidden layer neurons, z(1).",
            "zh": "å°†æƒé‡çŸ©é˜µä¹˜ä»¥å¢å¼ºçš„è¾“å…¥å‘é‡ï¼Œç”Ÿæˆéšè—å±‚ç¥ç»å…ƒçš„åŠ æƒå’Œå‘é‡ zï¼ˆ1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "backward sequential selection, 229",
            "zh": "å‘åé¡ºåºé€‰æ‹©ï¼Œ229"
        }
    },
    {
        "translation": {
            "en": "10.8â€…â€…â€…(a)â€“(f) Different clusterings found for the mobile phone customer dataset in Table 10.1[604] for values of k in (2, 9). (g) shows the silhouette for each clustering.",
            "zh": "10.8 ï¼ˆaï¼‰â€“ï¼ˆfï¼‰ è¡¨10.1[604]ä¸­ï¼ˆ2,9ï¼‰ä¸­kå€¼çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†å‘ç°ä¸åŒçš„èšç±»ã€‚ï¼ˆgï¼‰ æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„è½®å»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "We describe a range of different sampling techniques that can be used to do this.",
            "zh": "æˆ‘ä»¬æè¿°äº†ä¸€ç³»åˆ—å¯ç”¨äºæ‰§è¡Œæ­¤æ“ä½œçš„ä¸åŒé‡‡æ ·æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.140)[521] expands out the full set of operations and terms that are used in the calculation of âˆ‚â„°t/âˆ‚ctâˆ’1.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.140ï¼‰[521]æ‰©å±•äº†ç”¨äºè®¡ç®—âˆ‚Et/âˆ‚ctâˆ’1çš„å…¨å¥—è¿ç®—å’Œé¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This introduces something of an explosion in the number of weights required for a model, as we have an individual set of weights for every target feature level.",
            "zh": "è¿™å¼•å…¥äº†æ¨¡å‹æ‰€éœ€çš„æƒé‡æ•°é‡çš„çˆ†ç‚¸å¼å¢é•¿ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ºæ¯ä¸ªç›®æ ‡ç‰¹å¾çº§åˆ«éƒ½æœ‰ä¸€ç»„å•ç‹¬çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The system will be integrated into the factoryâ€™s production line and determine whether components are of an acceptable quality standard based on a set of test results.",
            "zh": "è¯¥ç³»ç»Ÿå°†è¢«é›†æˆåˆ°å·¥å‚çš„ç”Ÿäº§çº¿ä¸­ï¼Œå¹¶æ ¹æ®ä¸€ç»„æµ‹è¯•ç»“æœç¡®å®šç»„ä»¶æ˜¯å¦ç¬¦åˆå¯æ¥å—çš„è´¨é‡æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning is a simple, iterative, tabular approach to learning the action-value function, QÏ€(st,at), that is quite effective.",
            "zh": "æ—¶é—´å·®åˆ†å­¦ä¹ æ˜¯ä¸€ç§ç®€å•çš„ã€è¿­ä»£çš„ã€è¡¨æ ¼åŒ–çš„æ–¹æ³•æ¥å­¦ä¹ åŠ¨ä½œ-ä»·å€¼å‡½æ•° QÏ€ï¼ˆstï¼Œatï¼‰ï¼Œéå¸¸æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.20",
            "zh": "å›¾ 8.20"
        }
    },
    {
        "translation": {
            "en": "recall, 548, 549, 551, 572",
            "zh": "å¬å›ï¼Œ 548ï¼Œ 549ï¼Œ 551ï¼Œ 572"
        }
    },
    {
        "translation": {
            "en": "On the other hand, some of the machine learning techniques that we discuss in upcoming chapters perform poorly in the presence of outliers.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­è®¨è®ºçš„ä¸€äº›æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨å­˜åœ¨å¼‚å¸¸å€¼çš„æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature AGE and the target feature, CLASS.",
            "zh": "ï¼ˆaï¼‰ ä¸‹é¢çš„å¯è§†åŒ–å›¾è¯´æ˜äº†è¿ç»­ç‰¹å¾ AGE ä¸ç›®æ ‡ç‰¹å¾ CLASS ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a large negative z value ( â‰ˆ z < âˆ’2) or a large positive z value ( â‰ˆ z > +2) will cause the logistic function to saturate, and a large negative z < 0 will cause the rectified linear function to saturate.",
            "zh": "ä¾‹å¦‚ï¼Œè¾ƒå¤§çš„è´Ÿ z å€¼ ï¼ˆ â‰ˆ z < âˆ’2ï¼‰ æˆ–è¾ƒå¤§çš„æ­£ z å€¼ ï¼ˆ â‰ˆ z > +2ï¼‰ å°†å¯¼è‡´é€»è¾‘å‡½æ•°é¥±å’Œï¼Œè€Œè¾ƒå¤§çš„è´Ÿ z < 0 å°†å¯¼è‡´æ•´æµåçš„çº¿æ€§å‡½æ•°é¥±å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This sampling of the feature set is known as subspace sampling.",
            "zh": "ç‰¹å¾é›†çš„è¿™ç§é‡‡æ ·ç§°ä¸ºå­ç©ºé—´é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is done as follows:",
            "zh": "å…·ä½“æ“ä½œå¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Continuous",
            "zh": "è¿ç»­çš„"
        }
    },
    {
        "translation": {
            "en": "Histograms of the EXPRAD_R feature split by target feature level.",
            "zh": "æŒ‰ç›®æ ‡ç‰¹å¾çº§åˆ«åˆ’åˆ†çš„EXPRAD_Rç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data quality report gives an in-depth picture of the data in an ABT, and we should study it in detail in order to get to know the data that we will work with.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šæä¾›äº† ABT ä¸­æ•°æ®çš„æ·±å…¥å›¾ç‰‡ï¼Œæˆ‘ä»¬åº”è¯¥è¯¦ç»†ç ”ç©¶å®ƒï¼Œä»¥ä¾¿äº†è§£æˆ‘ä»¬å°†è¦å¤„ç†çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2â€…â€…â€…(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset. A collection of possible simple linear regression models capturing the relationship between these two features are also shown. (b) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset showing a candidate prediction model and the resulting errors.",
            "zh": "7.2 ï¼ˆaï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†ä¸­ SIZE å’Œ RENTAL PRICE ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚è¿˜æ˜¾ç¤ºäº†ä¸€ç»„å¯èƒ½çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œç”¨äºæ•è·è¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚ï¼ˆbï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†ä¸­ SIZE å’Œ RENTAL PRICE ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼Œæ˜¾ç¤ºå€™é€‰é¢„æµ‹æ¨¡å‹å’Œç”±æ­¤äº§ç”Ÿçš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that within this set, P(GC = none | Â¬fr) is quite large, and at the other extreme, P(GC = guarantor | Â¬fr) = is equal to zero.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨æ­¤é›†åˆä¸­ï¼ŒPï¼ˆGC = none | Â¬frï¼‰ éå¸¸å¤§ï¼Œè€Œåœ¨å¦ä¸€ä¸ªæç«¯ï¼ŒPï¼ˆGC = æ‹…ä¿äºº | Â¬frï¼‰ = ç­‰äºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2â€ƒPerformance Measures: Categorical Targets",
            "zh": "9.4.2 ç»©æ•ˆè¡¡é‡ï¼šåˆ†ç±»ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "In the next section we discuss the standard approach to clustering, the k-means clustering algorithm.",
            "zh": "åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºèšç±»çš„æ ‡å‡†æ–¹æ³•ï¼Œå³ k-means èšç±»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, if we wish to calculate the error gradient of a network with multiple outputs over multiple examples, we simply sum the error gradients for each output over the examples.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è®¡ç®—å¤šä¸ªç¤ºä¾‹ä¸Šå…·æœ‰å¤šä¸ªè¾“å‡ºçš„ç½‘ç»œçš„è¯¯å·®æ¢¯åº¦ï¼Œæˆ‘ä»¬åªéœ€å°†æ¯ä¸ªè¾“å‡ºçš„è¯¯å·®æ¢¯åº¦ç›¸åŠ å³å¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that the expected return is the cumulative reward that the agent expects to receive if it takes action at in state st and then follows the policy Ï€ all the way to the end of the episode.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œé¢„æœŸå›æŠ¥æ˜¯ä»£ç†åœ¨çŠ¶æ€ st é‡‡å–è¡ŒåŠ¨ï¼Œç„¶åä¸€ç›´éµå¾ªç­–ç•¥Ï€ç›´åˆ°å‰§é›†ç»“æŸæ—¶æœŸæœ›è·å¾—çš„ç´¯ç§¯å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a set of confusion matrices gives a detailed description of how a set of models trained on a categorical prediction problem performed and can be used for a detailed comparison of performances.",
            "zh": "ä¾‹å¦‚ï¼Œä¸€ç»„æ··æ·†çŸ©é˜µè¯¦ç»†æè¿°äº†ä¸€ç»„åœ¨åˆ†ç±»é¢„æµ‹é—®é¢˜ä¸Šè®­ç»ƒçš„æ¨¡å‹çš„æ‰§è¡Œæ–¹å¼ï¼Œå¹¶å¯ç”¨äºè¯¦ç»†çš„æ€§èƒ½æ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The plot on the left of Figure 8.8[398] shows the input space for the AND with the convention that FALSE has been mapped to 0 and TRUE has been mapped to 1.4 In the plot each of the four possible input combinations is labeled as either triggering a TRUE response (shown in the figure by a clear dot) or FALSE (shown in the figure by a black dot).",
            "zh": "å›¾ 8.8[398] å·¦ä¾§çš„å›¾æ˜¾ç¤ºäº† AND çš„è¾“å…¥ç©ºé—´ï¼Œå…¶çº¦å®šæ˜¯ FALSE å·²æ˜ å°„åˆ° 0ï¼ŒTRUE å·²æ˜ å°„åˆ° 1.4 åœ¨å›¾ä¸­ï¼Œå››ç§å¯èƒ½çš„è¾“å…¥ç»„åˆä¸­çš„æ¯ä¸€ç§éƒ½è¢«æ ‡è®°ä¸ºè§¦å‘ TRUE å“åº”ï¼ˆåœ¨å›¾ä¸­ç”¨æ˜ç‚¹æ˜¾ç¤ºï¼‰æˆ– FALSEï¼ˆåœ¨å›¾ä¸­ç”¨é»‘ç‚¹æ˜¾ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.16",
            "zh": "è¡¨ 9.16"
        }
    },
    {
        "translation": {
            "en": "The granularity of the data that the business has available. In a bricks-and-mortar retail scenario, data on sales might only be stored as a total number of sales per product type per day, rather than as individual items sold to individual customers.",
            "zh": "ä¸šåŠ¡å¯ç”¨æ•°æ®çš„ç²’åº¦ã€‚åœ¨å®ä½“é›¶å”®æ–¹æ¡ˆä¸­ï¼Œé”€å”®æ•°æ®å¯èƒ½ä»…å­˜å‚¨ä¸ºæ¯ç§äº§å“ç±»å‹æ¯å¤©çš„é”€å”®æ€»æ•°ï¼Œè€Œä¸æ˜¯ä½œä¸ºé”€å”®ç»™å•ä¸ªå®¢æˆ·çš„å•ä¸ªå•†å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "These first two questions are not always easy to answer.",
            "zh": "å‰ä¸¤ä¸ªé—®é¢˜å¹¶ä¸æ€»æ˜¯å®¹æ˜“å›ç­”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subscripts are used to index into a list of instances.",
            "zh": "ä¸‹æ ‡ç”¨äºç´¢å¼•åˆ°å®ä¾‹åˆ—è¡¨ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset of instances from the sample space in Figure B.1[757].",
            "zh": "å›¾B.1[757]ä¸­æ ·æœ¬ç©ºé—´ä¸­çš„å®ä¾‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. This is a simple manufactured example for this book, but this type of model is often used in epidemiology Hunter et al. (2018).",
            "zh": "7. è¿™æ˜¯æœ¬ä¹¦çš„ä¸€ä¸ªç®€å•åˆ¶é€ ç¤ºä¾‹ï¼Œä½†è¿™ç§ç±»å‹çš„æ¨¡å‹ç»å¸¸ç”¨äºæµè¡Œç—…å­¦ Hunter ç­‰äººï¼ˆ2018 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_U_G",
            "zh": "PETROMAGDIFF_U_G"
        }
    },
    {
        "translation": {
            "en": "If index is not a whole number, then we interpolate the value for the ith percentile as",
            "zh": "å¦‚æœ index ä¸æ˜¯æ•´æ•°ï¼Œåˆ™æˆ‘ä»¬å°†ç¬¬ i ä¸ªç™¾åˆ†ä½æ•°çš„å€¼ä»£å€¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "The book is intended for use in machine learning, data mining, data analytics, or artificial intelligence modules of undergraduate and postgraduate computer science, natural and social science, engineering, and business courses.",
            "zh": "æœ¬ä¹¦æ—¨åœ¨ç”¨äºæœ¬ç§‘å’Œç ”ç©¶ç”Ÿè®¡ç®—æœºç§‘å­¦ã€è‡ªç„¶å’Œç¤¾ä¼šç§‘å­¦ã€å·¥ç¨‹å’Œå•†ä¸šè¯¾ç¨‹çš„æœºå™¨å­¦ä¹ ã€æ•°æ®æŒ–æ˜ã€æ•°æ®åˆ†ææˆ–äººå·¥æ™ºèƒ½æ¨¡å—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imagine that we attempt to learn a prediction model for this retail scenario by searching for a model that is consistent with the dataset.",
            "zh": "æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬å°è¯•é€šè¿‡æœç´¢ä¸æ•°æ®é›†ä¸€è‡´çš„æ¨¡å‹æ¥å­¦ä¹ æ­¤é›¶å”®åœºæ™¯çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "invariant distribution, 299",
            "zh": "ä¸å˜åˆ†å¸ƒï¼Œ299"
        }
    },
    {
        "translation": {
            "en": "In this figure, SPEED has been plotted on the horizontal axis, and AGILITY has been plotted on the vertical axis.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼ŒSPEEDç»˜åˆ¶åœ¨æ¨ªè½´ä¸Šï¼ŒAGILITYç»˜åˆ¶åœ¨çºµè½´ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4â€…â€…â€…Modeling",
            "zh": "13.4 å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "We believe that this book will give you the knowledge and skills that you will need to explore these topics yourself.",
            "zh": "æˆ‘ä»¬ç›¸ä¿¡è¿™æœ¬ä¹¦å°†ä¸ºæ‚¨æä¾›è‡ªå·±æ¢ç´¢è¿™äº›ä¸»é¢˜æ‰€éœ€çš„çŸ¥è¯†å’ŒæŠ€èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œIt is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.â€",
            "zh": "â€œåœ¨æ‹¥æœ‰æ•°æ®ä¹‹å‰å°±è¿›è¡Œç†è®ºåŒ–æ˜¯ä¸€ä¸ªå¤§é”™è¯¯ã€‚ä¸çŸ¥ä¸è§‰ä¸­ï¼Œäººä»¬å¼€å§‹æ­ªæ›²äº‹å®ä»¥é€‚åº”ç†è®ºï¼Œè€Œä¸æ˜¯ç†è®ºä»¥é€‚åº”äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.19",
            "zh": "è¡¨ 6.19"
        }
    },
    {
        "translation": {
            "en": "Once the individual models in an ensemble have been induced, the ensemble makes predictions by returning the majority vote or the median, depending on the type of prediction required.",
            "zh": "ä¸€æ—¦é›†æˆä¸­çš„å•ä¸ªæ¨¡å‹è¢«è¯±å¯¼å‡ºæ¥ï¼Œé›†æˆå°±ä¼šé€šè¿‡è¿”å›å¤šæ•°æŠ•ç¥¨æˆ–ä¸­ä½æ•°æ¥è¿›è¡Œé¢„æµ‹ï¼Œå…·ä½“å–å†³äºæ‰€éœ€çš„é¢„æµ‹ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the output of the model (using the updated weights calculated in the previous part) for these two instances.",
            "zh": "è®¡ç®—è¿™ä¸¤ä¸ªå®ä¾‹çš„æ¨¡å‹è¾“å‡ºï¼ˆä½¿ç”¨ä¸Šä¸€éƒ¨åˆ†ä¸­è®¡ç®—çš„æ›´æ–°æƒé‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, it will implement a function, and once the network has been initialized we can now train the network to implement a useful function by iteratively presenting examples to the network and using the error of the network on the examples to update the weights so that the network converges on a set of weights that implement a useful function relative to the patterns in the training data.",
            "zh": "ä½†æ˜¯ï¼Œå®ƒå°†å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œä¸€æ—¦ç½‘ç»œè¢«åˆå§‹åŒ–ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥é€šè¿‡è¿­ä»£åœ°å‘ç½‘ç»œæä¾›ç¤ºä¾‹å¹¶ä½¿ç”¨ç¤ºä¾‹ä¸Šçš„ç½‘ç»œè¯¯å·®æ¥æ›´æ–°æƒé‡æ¥è®­ç»ƒç½‘ç»œæ¥å®ç°ä¸€ä¸ªæœ‰ç”¨çš„å‡½æ•°ï¼Œä»¥ä¾¿ç½‘ç»œæ”¶æ•›åˆ°ä¸€ç»„æƒé‡ä¸Šï¼Œè¿™äº›æƒé‡å®ç°äº†ä¸€ä¸ªç›¸å¯¹äºè®­ç»ƒæ•°æ®ä¸­çš„æ¨¡å¼çš„æœ‰ç”¨å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The only way that this can happen is if there is at least one instance on the other side of the hyperplane boundary that bisects the node that is closer to the query than the current best-distance.",
            "zh": "å‘ç”Ÿè¿™ç§æƒ…å†µçš„å”¯ä¸€æ–¹æ³•æ˜¯ï¼Œå¦‚æœè¶…å¹³é¢è¾¹ç•Œçš„å¦ä¸€ä¾§è‡³å°‘æœ‰ä¸€ä¸ªå®ä¾‹å°†æ¯”å½“å‰æœ€ä½³è·ç¦»æ›´æ¥è¿‘æŸ¥è¯¢çš„èŠ‚ç‚¹ä¸€åˆ†ä¸ºäºŒã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Explain the most important and popular algorithms clearly, rather than overview the full breadth of machine learning. As teachers we believe that giving students a deep knowledge of the core concepts underpinning a field provides them with a solid basis from which they can explore the field themselves. This sharper focus allows us to spend more time introducing, explaining, illustrating, and contextualizing the algorithms that are fundamental to the field and their uses.",
            "zh": "1. æ¸…æ¥šåœ°è§£é‡Šæœ€é‡è¦å’Œæœ€æµè¡Œçš„ç®—æ³•ï¼Œè€Œä¸æ˜¯æ¦‚è¿°æœºå™¨å­¦ä¹ çš„å…¨éƒ¨å¹¿åº¦ã€‚ä½œä¸ºæ•™å¸ˆï¼Œæˆ‘ä»¬ç›¸ä¿¡ï¼Œè®©å­¦ç”Ÿæ·±å…¥äº†è§£æ”¯æ’‘ä¸€ä¸ªé¢†åŸŸçš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¸ºä»–ä»¬æä¾›äº†åšå®çš„åŸºç¡€ï¼Œè®©ä»–ä»¬å¯ä»¥ä»ä¸­è‡ªå·±æ¢ç´¢è¯¥é¢†åŸŸã€‚è¿™ç§æ›´æ•é”çš„å…³æ³¨ä½¿æˆ‘ä»¬èƒ½å¤ŸèŠ±æ›´å¤šçš„æ—¶é—´æ¥ä»‹ç»ã€è§£é‡Šã€è¯´æ˜å’ŒèƒŒæ™¯åŒ–å¯¹è¯¥é¢†åŸŸåŠå…¶ç”¨é€”è‡³å…³é‡è¦çš„ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.5â€ƒSummary",
            "zh": "4.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Both equal-width and equal-frequency binning require that we manually specify how many bins we would like to use. Deciding on the number of bins can be difficult. The general trade-off is this:",
            "zh": "ç­‰å®½å’Œç­‰é¢‘åˆ†ç®±éƒ½è¦æ±‚æˆ‘ä»¬æ‰‹åŠ¨æŒ‡å®šè¦ä½¿ç”¨çš„ç®±æ•°ã€‚ç¡®å®šåƒåœ¾ç®±çš„æ•°é‡å¯èƒ½å¾ˆå›°éš¾ã€‚ä¸€èˆ¬çš„æƒè¡¡æ˜¯è¿™æ ·çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "These predictions would be normalized as follows:",
            "zh": "è¿™äº›é¢„æµ‹å°†æŒ‰å¦‚ä¸‹æ–¹å¼è§„èŒƒåŒ–ï¼š"
        }
    },
    {
        "translation": {
            "en": "Michie, D. 1963. Experiments on the mechanisation of game learning. Computer Journal 1: 232â€“263.",
            "zh": "ç±³å¥‡ï¼ŒD. 1963 å¹´ã€‚æ¸¸æˆå­¦ä¹ æœºæ¢°åŒ–çš„å®éªŒã€‚è®¡ç®—æœºæ‚å¿— 1ï¼š232-263ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.1â€…â€…â€…Suggested course syllabi.",
            "zh": "0.1 å»ºè®®çš„è¯¾ç¨‹å¤§çº²ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two kinds of outliers that might occur in an ABT: invalid outliers and valid outliers.",
            "zh": "ABT ä¸­å¯èƒ½å‡ºç°ä¸¤ç§å¼‚å¸¸å€¼ï¼šæ— æ•ˆå¼‚å¸¸å€¼å’Œæœ‰æ•ˆå¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.2",
            "zh": "è¡¨ 1.2"
        }
    },
    {
        "translation": {
            "en": "The bar plots shown in the data quality report are also very useful here.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­æ˜¾ç¤ºçš„æ¡å½¢å›¾åœ¨è¿™é‡Œä¹Ÿéå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Usually the player bets money on their ability to do this, and the dealer uses a little manual trickery to misdirect the player toward the wrong card.",
            "zh": "é€šå¸¸ï¼Œç©å®¶å°†é’±æŠ¼åœ¨ä»–ä»¬è¿™æ ·åšçš„èƒ½åŠ›ä¸Šï¼Œè€Œåº„å®¶ä½¿ç”¨ä¸€äº›æ‰‹åŠ¨æŠ€å·§å°†ç©å®¶è¯¯å¯¼åˆ°é”™è¯¯çš„ç‰Œä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The dotted line indicates a stability index value of 0.1, above which a model should be closely monitored, and the dashed line indicates a stability index of 0.25, above which corrective action is recommended.",
            "zh": "è™šçº¿è¡¨ç¤ºç¨³å®šæ€§æŒ‡æ•°å€¼ä¸º 0.1ï¼Œé«˜äºè¯¥å€¼æ—¶åº”å¯†åˆ‡ç›‘æ§æ¨¡å‹ï¼Œè™šçº¿è¡¨ç¤ºç¨³å®šæ€§æŒ‡æ•°ä¸º 0.25ï¼Œé«˜äºè¯¥å€¼å»ºè®®é‡‡å–çº æ­£æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ReLU networkâ€™s per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "ReLU ç½‘ç»œçš„æ¯ä¸ªç¤ºä¾‹é¢„æµ‹ã€è¯¯å·®å’Œè®­ç»ƒåçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œå·²æ”¶æ•›åˆ° SSE < 0.0001ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second way that a naive weight initialization can lead to instability during training is that very small or large weights can result in unstable gradients.",
            "zh": "æœ´ç´ æƒé‡åˆå§‹åŒ–å¯èƒ½å¯¼è‡´è®­ç»ƒæœŸé—´ä¸ç¨³å®šçš„ç¬¬äºŒç§æ–¹å¼æ˜¯ï¼Œéå¸¸å°æˆ–å¾ˆå¤§çš„æƒé‡éƒ½ä¼šå¯¼è‡´æ¢¯åº¦ä¸ç¨³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Although reinforcement learning can be used for many different tasks, its most common application is in learning to control the behaviors of autonomous systemsâ€”for example, training robots to perform tasks, or automated players to play gamesâ€”and this is the application that this chapter focuses on.",
            "zh": "å°½ç®¡å¼ºåŒ–å­¦ä¹ å¯ä»¥ç”¨äºè®¸å¤šä¸åŒçš„ä»»åŠ¡ï¼Œä½†å…¶æœ€å¸¸è§çš„åº”ç”¨æ˜¯å­¦ä¹ æ§åˆ¶è‡ªä¸»ç³»ç»Ÿçš„è¡Œä¸ºï¼Œä¾‹å¦‚ï¼Œè®­ç»ƒæœºå™¨äººæ‰§è¡Œä»»åŠ¡ï¼Œæˆ–è®­ç»ƒè‡ªåŠ¨ç©å®¶ç©æ¸¸æˆï¼Œè¿™æ˜¯æœ¬ç« é‡ç‚¹ä»‹ç»çš„åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A full joint probability distribution encodes the probabilities for all joint events in the domain.",
            "zh": "å®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå¯¹åŸŸä¸­æ‰€æœ‰è”åˆäº‹ä»¶çš„æ¦‚ç‡è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.13â€…â€…â€…The effect of using different numbers of bins when using binning to convert a continuous feature into a categorical feature.",
            "zh": "3.13 ä½¿ç”¨åˆ†ç®±å°†è¿ç»­ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾æ—¶ä½¿ç”¨ä¸åŒæ•°é‡çš„æ¡æŸ±çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.1",
            "zh": "å›¾ 2.1"
        }
    },
    {
        "translation": {
            "en": "The basic principle informing how weights in a neural network should be adjusted is that a weight should be updated in proportion to the sensitivity of the network error to changes in the weight.",
            "zh": "å‘ŠçŸ¥å¦‚ä½•è°ƒæ•´ç¥ç»ç½‘ç»œä¸­çš„æƒé‡çš„åŸºæœ¬åŸåˆ™æ˜¯ï¼Œæƒé‡åº”æ ¹æ®ç½‘ç»œè¯¯å·®å¯¹æƒé‡å˜åŒ–çš„æ•æ„Ÿæ€§æˆæ¯”ä¾‹åœ°æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that although a convolutional layer that runs multiple filters in parallel over its input will generate multiple feature maps, the next convolutional layer can treat these multiple feature maps as if they were a single multi-channel input.",
            "zh": "åŸå› æ˜¯ï¼Œå°½ç®¡åœ¨å…¶è¾“å…¥ä¸Šå¹¶è¡Œè¿è¡Œå¤šä¸ªæ»¤æ³¢å™¨çš„å·ç§¯å±‚å°†ç”Ÿæˆå¤šä¸ªç‰¹å¾å›¾ï¼Œä½†ä¸‹ä¸€ä¸ªå·ç§¯å±‚å¯ä»¥å°†è¿™äº›å¤šä¸ªç‰¹å¾å›¾è§†ä¸ºå•ä¸ªå¤šé€šé“è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPFLUX_U/G/R/I/Z",
            "zh": "EXPFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It does, however, need to be updated occasionally because otherwise the estimated values used in the loss function will be inaccurate.",
            "zh": "ä½†æ˜¯ï¼Œå®ƒç¡®å®éœ€è¦å¶å°”æ›´æ–°ï¼Œå¦åˆ™æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨çš„ä¼°è®¡å€¼å°†ä¸å‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ratios: Ratios are continuous features that capture the relationship between two or more raw data values.",
            "zh": "æ¯”ç‡ï¼šæ¯”ç‡æ˜¯æ•è·ä¸¤ä¸ªæˆ–å¤šä¸ªåŸå§‹æ•°æ®å€¼ä¹‹é—´å…³ç³»çš„è¿ç»­è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a sense, the unrolled recurrent neural network is similar to a convolutional neural network in that weights are shared between different neurons: the neurons in the hidden layer at time t = 1 use exactly the same weights as the neurons in the hidden layer at time t = 2 and t = 3, and so on.",
            "zh": "ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œå±•å¼€çš„å¾ªç¯ç¥ç»ç½‘ç»œç±»ä¼¼äºå·ç§¯ç¥ç»ç½‘ç»œï¼Œå› ä¸ºæƒé‡åœ¨ä¸åŒçš„ç¥ç»å…ƒä¹‹é—´å…±äº«ï¼šåœ¨æ—¶é—´ t = 1 æ—¶éšè—å±‚ä¸­çš„ç¥ç»å…ƒä½¿ç”¨ä¸åœ¨æ—¶é—´ t = 2 å’Œ t = 3 æ—¶éšè—å±‚ä¸­çš„ç¥ç»å…ƒå®Œå…¨ç›¸åŒçš„æƒé‡ï¼Œä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.3â€…â€…â€…Standard Approach: The ID3 Algorithm",
            "zh": "4.3 æ ‡å‡†æ–¹æ³•ï¼šID3 ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "Calculate the output generated by the network in response to this input.",
            "zh": "è®¡ç®—ç½‘ç»œå“åº”æ­¤è¾“å…¥ç”Ÿæˆçš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The starting position is shown marked with an S and the goal position is marked with a G. The cells marked with an f represent fiery ground that will damage the agent if it is crossed.",
            "zh": "èµ·å§‹ä½ç½®æ ‡æœ‰ Sï¼Œç›®æ ‡ä½ç½®æ ‡æœ‰ Gã€‚æ ‡æœ‰ f çš„å•å…ƒæ ¼ä»£è¡¨ç‚½çƒ­çš„åœ°é¢ï¼Œå¦‚æœç©¿è¿‡å®ƒä¼šæŸåä»£ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In consultation with the members of the AT executive team and the retention team, Ross agreed that his goal would be to create a churn prediction system that would achieve a prediction accuracy in excess of 75%.",
            "zh": "åœ¨ä¸ AT æ‰§è¡Œå›¢é˜Ÿå’Œä¿ç•™å›¢é˜Ÿæˆå‘˜åå•†åï¼ŒRoss ä¸€è‡´è®¤ä¸ºä»–çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªå®¢æˆ·æµå¤±é¢„æµ‹ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿçš„é¢„æµ‹å‡†ç¡®ç‡å°†è¶…è¿‡ 75%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Contrast this with a feature that measures age in years; this feature is likely to have a spread of values with a maximum of just over 100.",
            "zh": "ä¸æ­¤å½¢æˆé²œæ˜å¯¹æ¯”çš„æ˜¯ä»¥å¹´ä¸ºå•ä½æµ‹é‡å¹´é¾„çš„åŠŸèƒ½;æ­¤åŠŸèƒ½å¯èƒ½å…·æœ‰æœ€å¤§å€¼ç•¥é«˜äº 100 çš„å€¼åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "If we are defining the probability function for a categorical feature, then the function is known as a probability mass function because it can be understood as returning a discrete probability mass for each level in the domain of the feature.",
            "zh": "å¦‚æœæˆ‘ä»¬è¦ä¸ºåˆ†ç±»ç‰¹å¾å®šä¹‰æ¦‚ç‡å‡½æ•°ï¼Œåˆ™è¯¥å‡½æ•°ç§°ä¸ºæ¦‚ç‡è´¨é‡å‡½æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥ç†è§£ä¸ºè¿”å›ç‰¹å¾åŸŸä¸­æ¯ä¸ªæ°´å¹³çš„ç¦»æ•£æ¦‚ç‡è´¨é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.1â€…â€…â€…A dataset of mobile phone customers described by their average monthly data (DATA USAGE) and call (CALL VOLUME) usage. Details of the first two iterations of the k-means clustering algorithm are also shown. The clustering in the second iteration is actually the final clustering in this simple example.",
            "zh": "10.1 ç§»åŠ¨ç”µè¯å®¢æˆ·çš„æ•°æ®é›†ï¼Œç”±å…¶å¹³å‡æ¯æœˆæ•°æ®ï¼ˆDATA USAGEï¼‰å’Œé€šè¯é‡ï¼ˆCALL VOLUMEï¼‰ä½¿ç”¨æƒ…å†µæè¿°ã€‚è¿˜æ˜¾ç¤ºäº† k-means èšç±»ç®—æ³•çš„å‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œç¬¬äºŒæ¬¡è¿­ä»£ä¸­çš„èšç±»å®é™…ä¸Šæ˜¯æœ€ç»ˆèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.14â€…â€…â€…The architecture of an auto-encoder network made up of an encoder and a decoder connected by a bottleneck layer.",
            "zh": "10.14 ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆçš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œçš„æ¶æ„ï¼Œé€šè¿‡ç“¶é¢ˆå±‚è¿æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Differentiation Techniques for Machine Learning",
            "zh": "æœºå™¨å­¦ä¹ çš„å·®å¼‚åŒ–æŠ€æœ¯"
        }
    },
    {
        "translation": {
            "en": "classification accuracy, 539, 545, 550",
            "zh": "åˆ†ç±»ç²¾åº¦ï¼Œ539ã€545ã€550"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that in reality, the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process are performed iteratively rather than linearly.",
            "zh": "é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œåœ¨ç°å®ä¸­ï¼ŒCRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£ã€æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µæ˜¯è¿­ä»£æ‰§è¡Œçš„ï¼Œè€Œä¸æ˜¯çº¿æ€§æ‰§è¡Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "17. The term arising from Ï•7 is commonly referred to as an interaction term because it allows two descriptive features to interact in the model.",
            "zh": "17. ç”±Ï†7äº§ç”Ÿçš„é¡¹é€šå¸¸è¢«ç§°ä¸ºäº¤äº’é¡¹ï¼Œå› ä¸ºå®ƒå…è®¸ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾åœ¨æ¨¡å‹ä¸­ç›¸äº’ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice how the model gets closer and closer to a model that accurately captures the relationship between SIZE and RENTAL PRICE.",
            "zh": "è¯·æ³¨æ„ï¼Œè¯¥æ¨¡å‹å¦‚ä½•è¶Šæ¥è¶Šæ¥è¿‘å‡†ç¡®æ•è· SIZE å’Œ RENTAL PRICE ä¹‹é—´å…³ç³»çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the histograms in Figure 3.9[79], this visualization shows a slight indication that centers tend to be older than forwards and guards, but the three box plots overlap significantly, suggesting that this relationship is not very strong.",
            "zh": "ä¸å›¾3.9[79]ä¸­çš„ç›´æ–¹å›¾ç±»ä¼¼ï¼Œè¯¥å¯è§†åŒ–æ˜¾ç¤ºäº†ä¸€ä¸ªè½»å¾®çš„è¿¹è±¡ï¼Œå³ä¸­é”‹å¾€å¾€æ¯”å‰é”‹å’Œåå«æ›´è€ï¼Œä½†ä¸‰ä¸ªç®±å½¢å›¾æ˜æ˜¾é‡å ï¼Œè¡¨æ˜è¿™ç§å…³ç³»ä¸æ˜¯å¾ˆå¼ºã€‚"
        }
    },
    {
        "translation": {
            "en": "calculate the overall output of the ensemble for each instance in the test dataset.",
            "zh": "è®¡ç®—æµ‹è¯•æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹çš„é›†æˆæ€»è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "vanishing gradients, 387, 403, 435, 451, 507",
            "zh": "æ¶ˆå¤±æ¢¯åº¦ï¼Œ387ã€403ã€435ã€451ã€507"
        }
    },
    {
        "translation": {
            "en": "mode imputation, 374",
            "zh": "æ¨¡æ€æ’è¡¥ï¼Œ374"
        }
    },
    {
        "translation": {
            "en": "The entropy remaining after we have tested d is a weighted sum of the entropy, still with respect to the target feature, of each partition.",
            "zh": "æˆ‘ä»¬æµ‹è¯• d åå‰©ä½™çš„ç†µæ˜¯æ¯ä¸ªåˆ†åŒºçš„ç†µçš„åŠ æƒå’Œï¼Œä»ç„¶ç›¸å¯¹äºç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross hoped that this would make his task a little easier because Grace was the main gatekeeper to all the data resources at AT, and having her support for the project would be important.",
            "zh": "Ross å¸Œæœ›è¿™ä¼šè®©ä»–çš„ä»»åŠ¡å˜å¾—æ›´å®¹æ˜“ä¸€äº›ï¼Œå› ä¸º Grace æ˜¯ AT æ‰€æœ‰æ•°æ®èµ„æºçš„ä¸»è¦çœ‹é—¨äººï¼Œè·å¾—å¥¹å¯¹é¡¹ç›®çš„æ”¯æŒéå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. This explanation is inspired by the discussion in Reagen et al. (2017, p. 14).",
            "zh": "3. è¿™ç§è§£é‡Šçš„çµæ„Ÿæ¥è‡ª Reagen ç­‰äººï¼ˆ2017 å¹´ï¼Œç¬¬ 14 é¡µï¼‰ä¸­çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "This can be seen in the increasing sums of squared errors in Figure 7.9(b)[336].",
            "zh": "è¿™å¯ä»¥ä»å›¾7.9ï¼ˆbï¼‰[336]ä¸­å¹³æ–¹è¯¯å·®å’Œçš„å¢åŠ ä¸­çœ‹å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia when the descriptive features have been normalized using range normalization?",
            "zh": "å½“ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–å¯¹æè¿°æ€§ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–æ—¶ï¼Œä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„ 3 æœ€è¿‘é‚»é¢„æµ‹æ¨¡å‹å¯¹ä¿„ç½—æ–¯çš„ CPI è¿”å›çš„å€¼æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This is done by creating one new binary descriptive feature for every level of the categorical feature.",
            "zh": "è¿™æ˜¯é€šè¿‡ä¸ºåˆ†ç±»ç‰¹å¾çš„æ¯ä¸ªçº§åˆ«åˆ›å»ºä¸€ä¸ªæ–°çš„äºŒè¿›åˆ¶æè¿°æ€§ç‰¹å¾æ¥å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "When an axon of a cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that Aâ€™s efficiency, as one of the cells firing B, is increased. (Hebb, 1949, p. 62)",
            "zh": "å½“ç»†èƒ A çš„è½´çªè¶³å¤Ÿæ¥è¿‘ä»¥æ¿€å‘ç»†èƒ B å¹¶åå¤æˆ–æŒç»­åœ°å‚ä¸å‘å°„å®ƒæ—¶ï¼Œä¸€ä¸ªæˆ–ä¸¤ä¸ªç»†èƒä¸­ä¼šå‘ç”Ÿä¸€äº›ç”Ÿé•¿è¿‡ç¨‹æˆ–ä»£è°¢å˜åŒ–ï¼Œä½¿å¾— A çš„æ•ˆç‡ï¼Œä½œä¸ºå‘å°„ B çš„ç»†èƒä¹‹ä¸€ï¼Œä¼šå¢åŠ ã€‚ï¼ˆHebbï¼Œ1949 å¹´ï¼Œç¬¬ 62 é¡µï¼‰"
        }
    },
    {
        "translation": {
            "en": "Generative/",
            "zh": "ç”Ÿæˆ/"
        }
    },
    {
        "translation": {
            "en": "We use the network architecture illustrated in Figure 8.4[390] as the structure for the model we train.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨å›¾ 8.4[390] æ‰€ç¤ºçš„ç½‘ç»œæ¶æ„ä½œä¸ºæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.1â€ƒBig Idea",
            "zh": "5.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "When we talk about categorical features, we refer to the set of possible values that a categorical feature can take as the levels of the feature or the domain of the feature.",
            "zh": "å½“æˆ‘ä»¬è°ˆè®ºåˆ†ç±»ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬æŒ‡çš„æ˜¯åˆ†ç±»ç‰¹å¾å¯ä»¥ä½œä¸ºç‰¹å¾çš„çº§åˆ«æˆ–ç‰¹å¾åŸŸçš„å¯èƒ½å€¼é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For categorical target features, the ensemble returns the majority target level using a weighted vote.",
            "zh": "å¯¹äºåˆ†ç±»ç›®æ ‡è¦ç´ ï¼Œé›†æˆä½¿ç”¨åŠ æƒæŠ•ç¥¨è¿”å›å¤šæ•°ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "We indicate the identity of the neuron in which the calculation occurred using a subscript.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ä¸‹æ ‡æŒ‡ç¤ºå‘ç”Ÿè®¡ç®—çš„ç¥ç»å…ƒçš„èº«ä»½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.12",
            "zh": "å›¾ 8.12"
        }
    },
    {
        "translation": {
            "en": "population, 750",
            "zh": "äººå£ï¼Œ 750"
        }
    },
    {
        "translation": {
            "en": "valid outliers, 65, 68, 715",
            "zh": "æœ‰æ•ˆå¼‚å¸¸å€¼ã€65ã€68ã€715"
        }
    },
    {
        "translation": {
            "en": "nearest neighbor, 303, 732, 736",
            "zh": "æœ€è¿‘é‚»ï¼Œ 303ï¼Œ 732ï¼Œ 736"
        }
    },
    {
        "translation": {
            "en": "3. Machine learning is often referred to as an ill-posed problem. What does this mean?",
            "zh": "3. æœºå™¨å­¦ä¹ é€šå¸¸è¢«ç§°ä¸ºä¸€ä¸ªç—…æ€çš„é—®é¢˜ã€‚è¿™æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "5.3â€…â€…â€…Standard Approach: The Nearest Neighbor Algorithm",
            "zh": "5.3 æ ‡å‡†æ–¹æ³•ï¼šæœ€è¿‘é‚»ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "We will see in the next section how the best-fit set of weights for this equation are found, but for now we will set w[0] = âˆ’0.1513, w[1] = 0.6270, w[2] = âˆ’0.1781, and w[3] = 0.0714. This means that the model is rewritten",
            "zh": "æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­çœ‹åˆ°å¦‚ä½•æ‰¾åˆ°è¯¥æ–¹ç¨‹çš„æœ€ä½³æ‹Ÿåˆæƒé‡é›†ï¼Œä½†ç°åœ¨æˆ‘ä»¬å°†è®¾ç½® w[0] = âˆ’0.1513ã€w[1] = 0.6270ã€w[2] = âˆ’0.1781 å’Œ w[3] = 0.0714ã€‚è¿™æ„å‘³ç€æ¨¡å‹è¢«é‡å†™"
        }
    },
    {
        "translation": {
            "en": "6.13â€…â€…â€…The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.11[278], extended to include the conditional probabilities for the new ACCOUNT BALANCE feature, which are defined in terms of PDFs.",
            "zh": "6.13 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.11[278]ä¸­çš„æ•°æ®é›†è®¡ç®—å¾—å‡ºï¼Œæ‰©å±•ä¸ºåŒ…æ‹¬æ–°çš„è´¦æˆ·ä½™é¢ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ï¼Œè¿™äº›æ¦‚ç‡æ˜¯ç”¨PDFå®šä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distances (Dist.) between the query instance with SPEED = 6.75 and AGILITY = 3.00 and each instance in Table 5.2[183].",
            "zh": "SPEED = 6.75 ä¸” AGILITY = 3.00 çš„æŸ¥è¯¢å®ä¾‹ä¸è¡¨ 5.2[183] ä¸­æ¯ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦» ï¼ˆDist.ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This section describes some of the most important of these measures.",
            "zh": "æœ¬èŠ‚ä»‹ç»å…¶ä¸­ä¸€äº›æœ€é‡è¦çš„æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS; DIVERSITY OF CLAIM TYPES: CLAIM DIV.",
            "zh": "ç´¢èµ”;ç´¢èµ”ç±»å‹çš„å¤šæ ·æ€§ï¼šç´¢èµ”ç§‘"
        }
    },
    {
        "translation": {
            "en": "In a reinforcement learning scenario an agent inhabiting an environment attempts to achieve a goal by taking a sequence of actions to move it between states.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ åœºæ™¯ä¸­ï¼Œå±…ä½åœ¨ç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“è¯•å›¾é€šè¿‡é‡‡å–ä¸€ç³»åˆ—æ“ä½œåœ¨çŠ¶æ€ä¹‹é—´ç§»åŠ¨ç›®æ ‡æ¥å®ç°ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ELECTRICAL OUTPUT feature is the target feature for this example.",
            "zh": "ELECTRICAL OUTPUT ç‰¹å¾æ˜¯æ­¤ç¤ºä¾‹çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2â€ƒChoosing a Machine Learning Approach",
            "zh": "14.2 é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•"
        }
    },
    {
        "translation": {
            "en": "In one of these experiments, the brightening of a small spark that occurs when an object that supposedly emits N rays is brought close to it is measured.",
            "zh": "åœ¨å…¶ä¸­ä¸€ä¸ªå®éªŒä¸­ï¼Œæµ‹é‡äº†å½“ä¸€ä¸ªæ®ç§°å‘å°„Nå°„çº¿çš„ç‰©ä½“é è¿‘å®ƒæ—¶å‘ç”Ÿçš„å°ç«èŠ±çš„å¢äº®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the outcome period was defined as three months.3",
            "zh": "å› æ­¤ï¼Œç»“æœæœŸè¢«å®šä¹‰ä¸ºä¸‰ä¸ªæœˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The conclusion is that in order to create networks that can represent complex non-linear functions, it is not enough to add layers; we must also include non-linearities between these layers.",
            "zh": "ç»“è®ºæ˜¯ï¼Œä¸ºäº†åˆ›å»ºå¯ä»¥è¡¨ç¤ºå¤æ‚éçº¿æ€§å‡½æ•°çš„ç½‘ç»œï¼Œä»…ä»…æ·»åŠ å±‚æ˜¯ä¸å¤Ÿçš„;æˆ‘ä»¬è¿˜å¿…é¡»åŒ…æ‹¬è¿™äº›å±‚ä¹‹é—´çš„éçº¿æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "If a neural network (see Chapter 8[381]) is used for this task (and that is what we will use in the approach described in this section), we can output the value of all actions in a given state at the same time across the output layer of a network. So, the problem is reframed",
            "zh": "å¦‚æœç¥ç»ç½‘ç»œï¼ˆå‚è§ç¬¬ 8 ç«  [381]ï¼‰ç”¨äºæ­¤ä»»åŠ¡ï¼ˆæˆ‘ä»¬å°†åœ¨æœ¬èŠ‚æè¿°çš„æ–¹æ³•ä¸­ä½¿ç”¨ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ç½‘ç»œçš„è¾“å‡ºå±‚ä¸­åŒæ—¶è¾“å‡ºç»™å®šçŠ¶æ€ä¸‹æ‰€æœ‰æ“ä½œçš„å€¼ã€‚å› æ­¤ï¼Œé—®é¢˜è¢«é‡æ–°å®šä¹‰"
        }
    },
    {
        "translation": {
            "en": "9â€…â€…â€…Evaluation",
            "zh": "9 è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "exploring the data to understand it correctly;",
            "zh": "æ¢ç´¢æ•°æ®ä»¥æ­£ç¡®ç†è§£æ•°æ®;"
        }
    },
    {
        "translation": {
            "en": "The value returned by a probability function for an event is simply the relative frequency of that event in the dataset.",
            "zh": "äº‹ä»¶çš„æ¦‚ç‡å‡½æ•°è¿”å›çš„å€¼åªæ˜¯è¯¥äº‹ä»¶åœ¨æ•°æ®é›†ä¸­çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "With this in mind, it is instructive to refer to Figure 8.13[410], which plots the logistic function and the derivative of the logistic function.",
            "zh": "è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œå‚è€ƒå›¾ 8.13[410] å¾ˆæœ‰å¯å‘æ€§ï¼Œå®ƒç»˜åˆ¶äº†é€»è¾‘å‡½æ•°å’Œé€»è¾‘å‡½æ•°çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.1(a)[55] shows the structure of the table in a data quality report that describes continuous features.",
            "zh": "è¡¨ 3.1ï¼ˆaï¼‰[55] æ˜¾ç¤ºäº†æè¿°è¿ç»­ç‰¹å¾çš„æ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„è¡¨çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The PRICE achieved at auction by the each bottle is also included.",
            "zh": "æ¯ç“¶é…’åœ¨æ‹å–ä¼šä¸Šè¾¾åˆ°çš„ä»·æ ¼ä¹ŸåŒ…æ‹¬åœ¨å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to do this, a generative model must learn, or encode, the distribution of the data belonging to each class.",
            "zh": "ä¸ºæ­¤ï¼Œç”Ÿæˆæ¨¡å‹å¿…é¡»å­¦ä¹ æˆ–ç¼–ç å±äºæ¯ä¸ªç±»çš„æ•°æ®çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "model-based reinforcement learning, 643",
            "zh": "åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼Œ643"
        }
    },
    {
        "translation": {
            "en": "1.4â€…â€…â€…Potential prediction models (a) before and (b) after training data becomes available.",
            "zh": "1.4 æ½œåœ¨çš„é¢„æµ‹æ¨¡å‹ï¼ˆaï¼‰åœ¨è®­ç»ƒæ•°æ®å¯ç”¨ä¹‹å‰å’Œï¼ˆbï¼‰ä¹‹åã€‚"
        }
    },
    {
        "translation": {
            "en": "8.1â€…â€…â€…Hourly samples of ambient factors and full load electrical power output of a combined cycle power plant.",
            "zh": "8.1 è”åˆå¾ªç¯ç”µå‚ç¯å¢ƒå› ç´ å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„æ¯å°æ—¶æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sampling bias is closely related to the problem of selection bias, and the terms are often treated as synonyms.",
            "zh": "æŠ½æ ·åå·®ä¸é€‰æ‹©åå·®é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œè¿™äº›æœ¯è¯­é€šå¸¸è¢«è§†ä¸ºåŒä¹‰è¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imagine a very simple two layer network (one hidden layer and an output layer) with linear neurons (neurons that donâ€™t include an activation function, so that the output activation is just the weighted sum of the inputs).3 The calculation of the activations for the neurons in the first layer can be expressed as follows:",
            "zh": "æƒ³è±¡ä¸€ä¸ªéå¸¸ç®€å•çš„ä¸¤å±‚ç½‘ç»œï¼ˆä¸€ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼‰ï¼Œå…¶ä¸­æœ‰çº¿æ€§ç¥ç»å…ƒï¼ˆä¸åŒ…æ‹¬æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒï¼Œå› æ­¤è¾“å‡ºæ¿€æ´»åªæ˜¯è¾“å…¥çš„åŠ æƒå’Œï¼‰.3 ç¬¬ä¸€å±‚ä¸­ç¥ç»å…ƒæ¿€æ´»çš„è®¡ç®—å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Varying the value Î» changes the rate at which the density drops off.",
            "zh": "æ”¹å˜å€¼ Î» ä¼šæ”¹å˜å¯†åº¦ä¸‹é™çš„é€Ÿç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The similarity between the current trial user, q, and the two users in the dataset, d1 and d2, in terms of co-presence (CP), co-absence (CA), presence-absence (PA), and absence-presence (AP).",
            "zh": "å½“å‰è¯•éªŒç”¨æˆ· q ä¸æ•°æ®é›†ä¸­çš„ä¸¤ä¸ªç”¨æˆ· d1 å’Œ d2 åœ¨å…±å­˜ ï¼ˆCPï¼‰ã€å…±ç¼º ï¼ˆCAï¼‰ã€ç¼ºå‹¤ ï¼ˆPAï¼‰ å’Œç¼ºå‹¤ ï¼ˆAPï¼‰ æ–¹é¢çš„ç›¸ä¼¼æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.6.3â€ƒLong short-term memory networksâ€ƒRecurrent neural networks are particularly susceptible to the exploding gradients and vanishing gradients problems we discussed in Section 8.4.1[434] and Section 8.4.2[447].",
            "zh": "8.4.6.3 é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ é€’å½’ç¥ç»ç½‘ç»œç‰¹åˆ«å®¹æ˜“å—åˆ°æˆ‘ä»¬åœ¨ 8.4.1[434] å’Œ 8.4.2[447] ä¸­è®¨è®ºçš„æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the error gradients in the backward pass can propagate along the paths of active neurons in the network, and because âˆ‚ak/âˆ‚zk = 1 along these paths, the gradients can flow back through a deeper network (Glorot et al., 2011).",
            "zh": "å› æ­¤ï¼Œå‘åä¼ é€’ä¸­çš„è¯¯å·®æ¢¯åº¦å¯ä»¥æ²¿ç€ç½‘ç»œä¸­æ´»è·ƒç¥ç»å…ƒçš„è·¯å¾„ä¼ æ’­ï¼Œå¹¶ä¸”ç”±äºâˆ‚ak / âˆ‚zk = 1æ²¿ç€è¿™äº›è·¯å¾„ï¼Œæ¢¯åº¦å¯ä»¥é€šè¿‡æ›´æ·±çš„ç½‘ç»œæµå›ï¼ˆGlorotç­‰äººï¼Œ2011ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Maas, Andrew L., Awni Y. Hannun, and Andrew Y. Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In Proceedings of thirtieth international conference on machine learning (ICML 13), Vol. 30. JMLR.",
            "zh": "Maasã€Andrew L.ã€Awni Y. Hannun å’Œ Andrew Y. Ng. 2013ã€‚æ•´æµå™¨éçº¿æ€§æ”¹å–„äº†ç¥ç»ç½‘ç»œå£°å­¦æ¨¡å‹ã€‚ç¬¬30å±Šæœºå™¨å­¦ä¹ å›½é™…ä¼šè®®ï¼ˆICML 13ï¼‰è®ºæ–‡é›†ï¼Œç¬¬30å·ã€‚JMLRã€‚"
        }
    },
    {
        "translation": {
            "en": "MCMC, 298",
            "zh": "MCMCï¼Œ298"
        }
    },
    {
        "translation": {
            "en": "The same is true for large range variations across the descriptive features in a dataset and normalization techniques (like those described in Section 3.6.1[87]) should almost always be applied when nearest neighbor models are used.",
            "zh": "å¯¹äºæ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å¤§èŒƒå›´å˜åŒ–ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå½“ä½¿ç”¨æœ€è¿‘é‚»æ¨¡å‹æ—¶ï¼Œå½’ä¸€åŒ–æŠ€æœ¯ï¼ˆå¦‚ç¬¬ 3.6.1 èŠ‚ [87] ä¸­æè¿°çš„æŠ€æœ¯ï¼‰å‡ ä¹æ€»æ˜¯åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following short summary of the important things she learned illustrates the level of situational fluency required for this kind of scenario.",
            "zh": "ä»¥ä¸‹æ˜¯å¥¹æ‰€å­¦åˆ°çš„é‡è¦å†…å®¹çš„ç®€çŸ­æ€»ç»“ï¼Œè¯´æ˜äº†è¿™ç§åœºæ™¯æ‰€éœ€çš„æƒ…å¢ƒæµç•…ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œFail to prepare, prepare to fail.â€",
            "zh": "â€œæ²¡æœ‰å‡†å¤‡ï¼Œå‡†å¤‡å¤±è´¥ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "9.4.4â€…â€…â€…Performance Measures: Multinomial Targets",
            "zh": "9.4.4 ç»©æ•ˆè¡¡é‡ï¼šå¤šé¡¹å¼ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "Notice that the sum of the probabilities (the bar areas in the histograms) in both of these tables is 1.0, which is what we would expect with a probability distributionâ€”all probability distributions sum to 1.0.",
            "zh": "è¯·æ³¨æ„ï¼Œè¿™ä¸¤ä¸ªè¡¨ä¸­çš„æ¦‚ç‡ï¼ˆç›´æ–¹å›¾ä¸­çš„æ¡å½¢åŒºåŸŸï¼‰ä¹‹å’Œå‡ä¸º 1.0ï¼Œè¿™æ˜¯æˆ‘ä»¬å¯¹æ¦‚ç‡åˆ†å¸ƒçš„é¢„æœŸ - æ‰€æœ‰æ¦‚ç‡åˆ†å¸ƒçš„æ€»å’Œå‡ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data Preparation, 17, 19, 28, 46, 53, 87, 94, 95, 535, 691, 713, 730",
            "zh": "æ•°æ®å‡†å¤‡ï¼Œ 17ï¼Œ 19ï¼Œ 28ï¼Œ 46ï¼Œ 53ï¼Œ 87ï¼Œ 94ï¼Œ 95ï¼Œ 535ï¼Œ 691ï¼Œ 713ï¼Œ 730"
        }
    },
    {
        "translation": {
            "en": "A range of other approaches we do not cover in this book can be used to do other in-depth analysis of regression models.",
            "zh": "æœ¬ä¹¦ä¸­æ²¡æœ‰ä»‹ç»çš„ä¸€ç³»åˆ—å…¶ä»–æ–¹æ³•å¯ç”¨äºå¯¹å›å½’æ¨¡å‹è¿›è¡Œå…¶ä»–æ·±å…¥åˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "That there are no weights on these connections is indicated in Figure 8.37[502] by a dashed arrow that represents these connections.",
            "zh": "å›¾ 8.37[502] ä¸­ç”¨è™šçº¿ç®­å¤´è¡¨ç¤ºè¿™äº›è¿æ¥ä¸Šæ²¡æœ‰æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In preparing to create predictive models, it is always a good idea to investigate the relationships between pairs of features.",
            "zh": "åœ¨å‡†å¤‡åˆ›å»ºé¢„æµ‹æ¨¡å‹æ—¶ï¼Œç ”ç©¶ç‰¹å¾å¯¹ä¹‹é—´çš„å…³ç³»å§‹ç»ˆæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "analytics base table, 17, 23, 28, 28, 45, 49, 50, 52, 53, 94, 97, 600, 625, 688",
            "zh": "åˆ†æåŸºè¡¨ã€17ã€23ã€28ã€28ã€45ã€49ã€50ã€52ã€53ã€94ã€97ã€600ã€625ã€688"
        }
    },
    {
        "translation": {
            "en": "24. See Kollar and Friedman (2009) for a discussion of algorithms that seek to address this research challenge.",
            "zh": "24. å‚è§Kollar and Friedman ï¼ˆ2009ï¼‰å…³äºæ—¨åœ¨è§£å†³è¿™ä¸€ç ”ç©¶æŒ‘æˆ˜çš„ç®—æ³•çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2[60] shows a selection of histogram shapes that exhibit characteristics commonly seen when analyzing features and that are indicative of standard, well-known probability distributions.",
            "zh": "å›¾ 3.2[60] æ˜¾ç¤ºäº†ä¸€ç³»åˆ—ç›´æ–¹å›¾å½¢çŠ¶ï¼Œè¿™äº›ç›´æ–¹å›¾å½¢çŠ¶å…·æœ‰åˆ†æç‰¹å¾æ—¶å¸¸è§çš„ç‰¹å¾ï¼Œå¹¶æŒ‡ç¤ºæ ‡å‡†çš„ã€ä¼—æ‰€å‘¨çŸ¥çš„æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "ii. Mode % and 2nd mode %",
            "zh": "ii. æ¨¡å¼ % å’Œç¬¬äºŒæ¨¡å¼ %"
        }
    },
    {
        "translation": {
            "en": "Aggregates: These are aggregate measures defined over a group or period and are usually defined as the count, sum, average, minimum, or maximum of the values within a group. For example, the total number of insurance claims that a member of an insurance company has made over his or her lifetime might be a useful derived feature. Similarly, the average amount of money spent by a customer at an online retailer over periods of one, three, and six months might make an interesting set of derived features.",
            "zh": "èšåˆï¼šè¿™äº›æ˜¯åœ¨ä¸€ä¸ªç»„æˆ–æœŸé—´å†…å®šä¹‰çš„èšåˆåº¦é‡ï¼Œé€šå¸¸å®šä¹‰ä¸ºç»„å†…å€¼çš„è®¡æ•°ã€æ€»å’Œã€å¹³å‡å€¼ã€æœ€å°å€¼æˆ–æœ€å¤§å€¼ã€‚ä¾‹å¦‚ï¼Œä¿é™©å…¬å¸æˆå‘˜åœ¨å…¶ä¸€ç”Ÿä¸­æå‡ºçš„ä¿é™©ç´¢èµ”æ€»æ•°å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ´¾ç”Ÿç‰¹å¾ã€‚åŒæ ·ï¼Œå®¢æˆ·åœ¨ä¸€ã€ä¸‰å’Œå…­ä¸ªæœˆå†…åœ¨åœ¨çº¿é›¶å”®å•†å¤„èŠ±è´¹çš„å¹³å‡é‡‘é¢å¯èƒ½ä¼šäº§ç”Ÿä¸€ç»„æœ‰è¶£çš„æ´¾ç”Ÿç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "æ¯ä¸ªç¤ºä¾‹çš„é¢„æµ‹ã€è¯¯å·®å’Œè®­ç»ƒåçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œå·²æ”¶æ•›åˆ° SSE < 0.0001ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tsoumakas, Grigorios, Min-Ling Zhang, and Zhi-Hua Zhou. 2012. Introduction to the special issue on learning from multi-label data. Machine Learning 88 (1-2): 1â€“4.",
            "zh": "Tsoumakasã€Grigoriosã€Min-Ling Zhang å’Œ Zhi-å å‘¨ã€‚2012. å…³äºä»å¤šæ ‡ç­¾æ•°æ®ä¸­å­¦ä¹ çš„ç‰¹åˆŠä»‹ç».æœºå™¨å­¦ä¹  88 ï¼ˆ1-2ï¼‰ï¼š1-4ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another approach to evaluating clustering is to use external criteria in which some measure from outside the clustering is used as a proxy ground truth.",
            "zh": "è¯„ä¼°èšç±»çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å¤–éƒ¨æ ‡å‡†ï¼Œå…¶ä¸­æ¥è‡ªèšç±»å¤–éƒ¨çš„æŸäº›åº¦é‡ç”¨ä½œä»£ç†äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4[16] shows six key phases of the predictive data analytics project lifecycle that are defined by the CRISP-DM:",
            "zh": "å›¾ 1.4[16] æ˜¾ç¤ºäº† CRISP-DM å®šä¹‰çš„é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ç”Ÿå‘½å‘¨æœŸçš„å…­ä¸ªå…³é”®é˜¶æ®µï¼š"
        }
    },
    {
        "translation": {
            "en": "The second term we need in order to calculate Î´8 is the rate of change of the activation function with respect to the changes in the weighted sum z: âˆ‚a/âˆ‚z.",
            "zh": "ä¸ºäº†è®¡ç®— Î´8ï¼Œæˆ‘ä»¬éœ€è¦çš„ç¬¬äºŒä¸ªé¡¹æ˜¯æ¿€æ´»å‡½æ•°ç›¸å¯¹äºåŠ æƒæ€»å’Œ z çš„å˜åŒ–ç‡ï¼šâˆ‚a/âˆ‚zã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.7â€…â€…â€…Support Vector Machines",
            "zh": "7.4.7 æ”¯æŒå‘é‡æœº"
        }
    },
    {
        "translation": {
            "en": "A point that we didnâ€™t discuss in this chapter is that it is possible to create custom measures for datasets with both continuous and categorical descriptive features by combining measures.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬ç« ä¸­æ²¡æœ‰è®¨è®ºçš„ä¸€ç‚¹æ˜¯ï¼Œé€šè¿‡ç»„åˆåº¦é‡ï¼Œå¯ä»¥ä¸ºå…·æœ‰è¿ç»­å’Œåˆ†ç±»æè¿°æ€§ç‰¹å¾çš„æ•°æ®é›†åˆ›å»ºè‡ªå®šä¹‰åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some predictive analytics scenarios, the dataset we have is so large that we do not use all the data available to us in an ABT and instead sample a smaller percentage from the larger dataset.",
            "zh": "åœ¨æŸäº›é¢„æµ‹åˆ†æåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é›†éå¸¸å¤§ï¼Œä»¥è‡³äºæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ ABT ä¸­å¯ç”¨çš„æ‰€æœ‰æ•°æ®ï¼Œè€Œæ˜¯ä»è¾ƒå¤§çš„æ•°æ®é›†ä¸­æŠ½å–è¾ƒå°ç™¾åˆ†æ¯”çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Converting business problems into solutions based on unsupervised machine learning also relies mainly on the techniques discussed in the context of supervised learning in Chapter 2[23].",
            "zh": "å°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåŸºäºæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆä¹Ÿä¸»è¦ä¾èµ–äºç¬¬2ç« [23]ä¸­ç›‘ç£å­¦ä¹ èƒŒæ™¯ä¸‹è®¨è®ºçš„æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "LSTMs were specifically designed to be able to model long-distance dependencies in a sequence.",
            "zh": "LSTM ç»è¿‡ä¸“é—¨è®¾è®¡ï¼Œèƒ½å¤Ÿå¯¹åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Out-of-time sampling is essentially a form of hold-out sampling in which the sampling is done in a targeted rather than a random fashion.",
            "zh": "è¶…æ—¶æŠ½æ ·æœ¬è´¨ä¸Šæ˜¯ä¸€ç§ä¿ç•™æŠ½æ ·å½¢å¼ï¼Œå…¶ä¸­æŠ½æ ·æ˜¯ä»¥æœ‰é’ˆå¯¹æ€§çš„æ–¹å¼è€Œä¸æ˜¯éšæœºæ–¹å¼è¿›è¡Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, to illustrate the DQN algorithm we will examine at a higher level how an automated player of the Lunar Lander game can be trained.",
            "zh": "ç›¸åï¼Œä¸ºäº†è¯´æ˜DQNç®—æ³•ï¼Œæˆ‘ä»¬å°†åœ¨æ›´é«˜å±‚æ¬¡ä¸Šç ”ç©¶å¦‚ä½•è®­ç»ƒæœˆçƒç€é™†å™¨æ¸¸æˆçš„è‡ªåŠ¨ç©å®¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Glorot initialization, 458",
            "zh": "Glorot åˆå§‹åŒ–ï¼Œ458"
        }
    },
    {
        "translation": {
            "en": "Frequently, features will have very strong non-linear relationships that correlation does not respond to.",
            "zh": "é€šå¸¸ï¼Œç‰¹å¾å°†å…·æœ‰éå¸¸å¼ºçš„éçº¿æ€§å…³ç³»ï¼Œç›¸å…³æ€§ä¸ä¼šå“åº”è¿™äº›å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the most informative feature, d[best], has been chosen, the algorithm adds a new node, labeled with the feature d[best], to the tree (Line 9).",
            "zh": "ä¸€æ—¦é€‰æ‹©äº†ä¿¡æ¯é‡æœ€å¤§çš„ç‰¹å¾ d[best]ï¼Œç®—æ³•å°±ä¼šåœ¨æ ‘ä¸­æ·»åŠ ä¸€ä¸ªæ ‡æœ‰ç‰¹å¾ d[best] çš„æ–°èŠ‚ç‚¹ï¼ˆç¬¬ 9 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that there is an entry for each action-state combination and that the terminal states always have a value of 0.000 for every action.",
            "zh": "è¯·æ³¨æ„ï¼Œæ¯ä¸ªæ“ä½œçŠ¶æ€ç»„åˆéƒ½æœ‰ä¸€ä¸ªæ¡ç›®ï¼Œå¹¶ä¸”æ¯ä¸ªæ“ä½œçš„ç»ˆç«¯çŠ¶æ€çš„å€¼å§‹ç»ˆä¸º 0.000ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.7â€ƒExercises",
            "zh": "7.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "8.3.4â€ƒBackpropagation: The Algorithm",
            "zh": "8.3.4 åå‘ä¼ æ’­ï¼šç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "LIKED: Did the user Like the website on Facebook?",
            "zh": "å–œæ¬¢ï¼šç”¨æˆ·å–œæ¬¢Facebookä¸Šçš„ç½‘ç«™å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "For example, after starting with the feature subset including no features, the process will move to the most desirable of the feature subsets containing just one feature.",
            "zh": "ä¾‹å¦‚ï¼Œä»ä¸åŒ…å«ç‰¹å¾çš„ç‰¹å¾å­é›†å¼€å§‹åï¼Œè¯¥è¿‡ç¨‹å°†ç§»åŠ¨åˆ°ä»…åŒ…å«ä¸€ä¸ªç‰¹å¾çš„æœ€ç†æƒ³çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A stationary distribution is a distribution that doesnâ€™t change.",
            "zh": "ç¨³æ€åˆ†å¸ƒæ˜¯ä¸å˜çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.6",
            "zh": "å›¾ 10.6"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows a visualization of an MDP for TwentyTwos using this representation where the circles represent the 11 states.",
            "zh": "å›¾ 11.3[648] æ˜¾ç¤ºäº†ä½¿ç”¨æ­¤è¡¨ç¤ºçš„ TwentyTwo çš„ MDP çš„å¯è§†åŒ–ï¼Œå…¶ä¸­åœ†åœˆè¡¨ç¤º 11 ä¸ªçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "This involved working with the AT IT department to develop deployment-ready extract-transform-load (ETL) routines.",
            "zh": "è¿™æ¶‰åŠä¸ AT IT éƒ¨é—¨åˆä½œå¼€å‘éƒ¨ç½²å°±ç»ªçš„æå–-è½¬æ¢-åŠ è½½ ï¼ˆETLï¼‰ ä¾‹ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10 illustrates how using just three layers and threshold activation functions, a network is able to represent a function that maps to a convex region.",
            "zh": "å›¾ 8.10 è¯´æ˜äº†ä»…ä½¿ç”¨ä¸‰å±‚å’Œé˜ˆå€¼æ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œå¦‚ä½•èƒ½å¤Ÿè¡¨ç¤ºæ˜ å°„åˆ°å‡¸åŒºåŸŸçš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks have three distinctive characteristics:",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œå…·æœ‰ä¸‰ä¸ªæ˜¾è‘—ç‰¹å¾ï¼š"
        }
    },
    {
        "translation": {
            "en": "Table 13.4",
            "zh": "è¡¨ 13.4"
        }
    },
    {
        "translation": {
            "en": "In order to find this single best model, a machine learning algorithm must use some criteria for choosing among the candidate models it considers during its search.",
            "zh": "ä¸ºäº†æ‰¾åˆ°è¿™ä¸ªå•ä¸€çš„æœ€ä½³æ¨¡å‹ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•å¿…é¡»ä½¿ç”¨ä¸€äº›æ ‡å‡†æ¥é€‰æ‹©å®ƒåœ¨æœç´¢è¿‡ç¨‹ä¸­è€ƒè™‘çš„å€™é€‰æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature combinations are listed on the left-hand side of the table, and the set of potential models for this domain are shown as 1 to 6,561 on the right-hand side of the table.",
            "zh": "æè¿°æ€§ç‰¹å¾ç»„åˆåˆ—åœ¨è¡¨æ ¼çš„å·¦ä¾§ï¼Œè¯¥åŸŸçš„æ½œåœ¨æ¨¡å‹é›†åœ¨è¡¨æ ¼çš„å³ä¾§æ˜¾ç¤ºä¸º 1 åˆ° 6,561ã€‚"
        }
    },
    {
        "translation": {
            "en": "28. The discussion relating to the features of real data that help with the induction of models in high-dimensional spaces is based on Bishop (2006), pp. 33â€“38.",
            "zh": "28. å…³äºæœ‰åŠ©äºåœ¨é«˜ç»´ç©ºé—´ä¸­å½’çº³æ¨¡å‹çš„çœŸå®æ•°æ®ç‰¹å¾çš„è®¨è®ºåŸºäºBishopï¼ˆ2006ï¼‰ï¼Œç¬¬33-38é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "16. See Goodfellow et al. (2016, p. 272) and references therein for further discussion on the trade-offs in batch size.",
            "zh": "16. å‚è§ Goodfellow ç­‰äººï¼ˆ2016 å¹´ï¼Œç¬¬ 272 é¡µï¼‰åŠå…¶å‚è€ƒæ–‡çŒ®ï¼Œä»¥è¿›ä¸€æ­¥è®¨è®ºæ‰¹é‡å¤§å°çš„æƒè¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Discriminative",
            "zh": "åˆ¤åˆ«"
        }
    },
    {
        "translation": {
            "en": "Agents, States, and Actions",
            "zh": "ä»£ç†ã€çŠ¶æ€å’Œæ“ä½œ"
        }
    },
    {
        "translation": {
            "en": "To collect instances of customers who had not churned, Ross randomly sampled customers who did not match the churn definition but who also could be deemed active customers.",
            "zh": "ä¸ºäº†æ”¶é›†æœªæµå¤±çš„å®¢æˆ·å®ä¾‹ï¼ŒRoss éšæœºæŠ½å–äº†ä¸ç¬¦åˆæµå¤±å®šä¹‰ä½†ä¹Ÿå¯ä»¥è¢«è§†ä¸ºæ´»è·ƒå®¢æˆ·çš„å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "16. The features selected were AE_I, APERFLUX7IVAR_G, APERFLUX7IVAR_I, APERFLUX7_U, DERED_U, DEVAB_R, DEVRADERR_Z, DEVRAD_U, DEREDDIFF_G_R, EXPRAD_G, EXPRAD_R, FIBER2FLUXIVAR_Z, FIBER2MAGERR_G, FIBERFLUXIVAR_R, FRACDEV_Z, LNLDEV_G, LNLDEV_R, LNLDEV_U, LNLDEV_Z, MCR4_Z, PETROFLUXIVAR_G, PETROFLUXIVAR_I, PETROR50ERR_R, PETROR50_G, PETROR90_G, PETRORATIO_R, PSFFLUXIVAR_I, PSFMAGERR_R, PSFMAG_R, SKYIVAR_U, and SKYIVAR_Z.",
            "zh": "16. é€‰å®šçš„ç‰¹å¾æ˜¯AE_Iã€APERFLUX7IVAR_Gã€APERFLUX7IVAR_Iã€APERFLUX7_Uã€DERED_Uã€DEVAB_Rã€DEVRADERR_Zã€DEVRAD_Uã€DEREDDIFF_G_Rã€EXPRAD_Gã€EXPRAD_Rã€FIBER2FLUXIVAR_Zã€FIBER2MAGERR_Gã€FIBERFLUXIVAR_Rã€FRACDEV_Zã€LNLDEV_Gã€LNLDEV_Rã€LNLDEV_Uã€LNLDEV_Zã€MCR4_Zã€PETROFLUXIVAR_Gã€PETROFLUXIVAR_Iã€PETROR50ERR_Rã€PETROR50_Gã€PETROR90_Gã€ PETRORATIO_Rã€PSFFLUXIVAR_Iã€PSFMAGERR_Rã€PSFMAG_Rã€SKYIVAR_U å’Œ SKYIVAR_Zã€‚"
        }
    },
    {
        "translation": {
            "en": "For continuous targets there is no such thing as a pure split, so we will need to change the final base case.",
            "zh": "å¯¹äºè¿ç»­ç›®æ ‡ï¼Œæ²¡æœ‰çº¯ç²¹çš„æ‹†åˆ†ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ›´æ”¹æœ€ç»ˆçš„åŸºæœ¬æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, it is possible to represent the XOR function using a very simple two-layer network.",
            "zh": "äº‹å®ä¸Šï¼Œå¯ä»¥ä½¿ç”¨éå¸¸ç®€å•çš„ä¸¤å±‚ç½‘ç»œæ¥è¡¨ç¤º XOR å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 12.3",
            "zh": "è¡¨ 12.3"
        }
    },
    {
        "translation": {
            "en": "8.4.1â€ƒVanishing Gradients and ReLUs",
            "zh": "8.4.1 æ¶ˆå¤±æ¢¯åº¦å’Œ ReLU"
        }
    },
    {
        "translation": {
            "en": "Mean",
            "zh": "æ„å‘³ ç€"
        }
    },
    {
        "translation": {
            "en": "All the performance measures that we have discussed so far focus on prediction problems with categorical targets.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºçš„æ‰€æœ‰ç»©æ•ˆæŒ‡æ ‡éƒ½é›†ä¸­åœ¨åˆ†ç±»ç›®æ ‡çš„é¢„æµ‹é—®é¢˜ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6.3â€ƒSampling",
            "zh": "3.6.3 æŠ½æ ·"
        }
    },
    {
        "translation": {
            "en": "propensity modeling, 4, 36, 689",
            "zh": "å€¾å‘å»ºæ¨¡ï¼Œ 4ï¼Œ 36ï¼Œ 689"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy on the non-stratified hold-out test set was 79.284%. Ross also generated cumulative gain, lift, and cumulative lift charts for the dataset.10 These are shown in Figure 12.6[700]. The cumulative gain chart in particular shows that if AT were to call just 40% of their customer base, they would identify approximately 80% of the customers who are likely to churn, which is strong evidence that the model is doing a good job of distinguishing between different customer types.",
            "zh": "éåˆ†å±‚ä¿æŒæµ‹è¯•é›†çš„å¹³å‡ç±»å‡†ç¡®ç‡ä¸º 79.284%ã€‚Ross è¿˜ä¸ºæ•°æ®é›†ç”Ÿæˆäº†ç´¯ç§¯å¢ç›Šã€æå‡å’Œç´¯ç§¯æå‡å›¾è¡¨10ï¼Œå¦‚å›¾ 12.6[700] æ‰€ç¤ºã€‚ç‰¹åˆ«æ˜¯ç´¯ç§¯æ”¶ç›Šå›¾è¡¨æ˜¾ç¤ºï¼Œå¦‚æœ AT åªæ‰“ç”µè¯ç»™ 40% çš„å®¢æˆ·ç¾¤ï¼Œä»–ä»¬å°†è¯†åˆ«å¤§çº¦ 80% å¯èƒ½æµå¤±çš„å®¢æˆ·ï¼Œè¿™æœ‰åŠ›åœ°è¯æ˜äº†è¯¥æ¨¡å‹åœ¨åŒºåˆ†ä¸åŒå®¢æˆ·ç±»å‹æ–¹é¢åšå¾—å¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4.1â€ƒBaseline Models",
            "zh": "13.4.1 åŸºçº¿æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "The bag-of-words representation is covered more in Question 2[236] at the end of this chapter.",
            "zh": "æœ¬ç« æœ«å°¾çš„é—®é¢˜2[236]ä¸­è¯¦ç»†ä»‹ç»äº†è¯è¢‹è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.70)[467] restates this definition in terms of the error of the network as calculated using the cross-entropy loss function and also taking the partial derivative with respect to a change in the logit for neuron k in the output layer.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.70ï¼‰[467]æ ¹æ®ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®¡ç®—çš„ç½‘ç»œè¯¯å·®ï¼Œå¹¶é‡‡ç”¨åå¯¼æ•°æ¥è§£é‡Šè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒkçš„logitå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the performance of the model on the non-churn level overwhelms the performance on the churn level in the accuracy calculation and illustrates how classification accuracy can be a misleading measure of model performance.",
            "zh": "è¿™æ„å‘³ç€ï¼Œåœ¨å‡†ç¡®æ€§è®¡ç®—ä¸­ï¼Œæ¨¡å‹åœ¨éæµå¤±çº§åˆ«çš„æ€§èƒ½ä¼šå‹å€’æµå¤±ç‡çº§åˆ«çš„æ€§èƒ½ï¼Œå¹¶è¯´æ˜åˆ†ç±»å‡†ç¡®æ€§å¦‚ä½•æˆä¸ºæ¨¡å‹æ€§èƒ½çš„è¯¯å¯¼æ€§åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can easily be done by calculating the information gain7 for each descriptive feature as a predictor of binary flags indicating membership of each cluster and ranking features according to these information gain values.8",
            "zh": "è¿™å¯ä»¥é€šè¿‡è®¡ç®—æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Š7ä½œä¸ºäºŒè¿›åˆ¶æ ‡å¿—çš„é¢„æµ‹å› å­æ¥è½»æ¾å®Œæˆï¼Œè¯¥äºŒè¿›åˆ¶æ ‡å¿—æŒ‡ç¤ºæ¯ä¸ªèšç±»çš„æˆå‘˜èµ„æ ¼ï¼Œå¹¶æ ¹æ®è¿™äº›ä¿¡æ¯å¢ç›Šå€¼å¯¹ç‰¹å¾è¿›è¡Œæ’å8ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS RATIO; NUMBER OF SOFT TISSUE CLAIMS: NUM.",
            "zh": "ç´¢èµ”æ¯”ç‡;è½¯ç»„ç»‡ç´¢èµ”æ•°é‡ï¼šæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cooper, Gregory F., and Edward Herskovits. 1992. A Bayesian method for the induction of probabilistic networks from data. Machine Learning 9 (4): 309â€“347.",
            "zh": "åº“ç€ã€æ ¼é›·æˆˆé‡Œ F. å’Œçˆ±å¾·åÂ·èµ«æ–¯ç§‘ç»´èŒ¨ã€‚1992. ä¸€ç§ä»æ•°æ®ä¸­å½’çº³æ¦‚ç‡ç½‘ç»œçš„è´å¶æ–¯æ–¹æ³•.æœºå™¨å­¦ä¹  9 ï¼ˆ4ï¼‰ï¼š309â€“347ã€‚"
        }
    },
    {
        "translation": {
            "en": "To perform stratified sampling, the instances in a dataset are first divided into groups (or strata), where each group contains only instances that have a particular level for the stratification feature.",
            "zh": "è¦æ‰§è¡Œåˆ†å±‚é‡‡æ ·ï¼Œé¦–å…ˆå°†æ•°æ®é›†ä¸­çš„å®ä¾‹åˆ’åˆ†ä¸ºç»„ï¼ˆæˆ–å±‚ï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªç»„ä»…åŒ…å«å…·æœ‰ç‰¹å®šåˆ†å±‚ç‰¹å¾çº§åˆ«çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "interior nodes, 121",
            "zh": "å†…éƒ¨èŠ‚ç‚¹ï¼Œ121"
        }
    },
    {
        "translation": {
            "en": "Features such as the number of times a person has made an insurance claim or the number of times a person has been married tend to follow an exponential distribution.",
            "zh": "è¯¸å¦‚ä¸€ä¸ªäººæå‡ºä¿é™©ç´¢èµ”çš„æ¬¡æ•°æˆ–ä¸€ä¸ªäººç»“å©šçš„æ¬¡æ•°ç­‰ç‰¹å¾å¾€å¾€éµå¾ªæŒ‡æ•°åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The impact of the clamp transformation can be reduced by changing the multiplier used to calculate the thresholds from 1.5 to a larger value.",
            "zh": "é€šè¿‡å°†ç”¨äºè®¡ç®—é˜ˆå€¼çš„ä¹˜æ•°ä» 1.5 æ›´æ”¹ä¸ºæ›´å¤§çš„å€¼ï¼Œå¯ä»¥å‡å°‘é’³ä½å˜æ¢çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Error-Based Learning",
            "zh": "åŸºäºé”™è¯¯çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "After discussing some extensions and variations of this approach, the chapter focuses on how deep learning techniques have been recently integrated into reinforcement learning to impressive effect.",
            "zh": "åœ¨è®¨è®ºäº†è¿™ç§æ–¹æ³•çš„ä¸€äº›æ‰©å±•å’Œå˜åŒ–ä¹‹åï¼Œæœ¬ç« é‡ç‚¹ä»‹ç»äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯æœ€è¿‘å¦‚ä½•è¢«æ•´åˆåˆ°å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå¹¶å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.9",
            "zh": "è¡¨ 5.9"
        }
    },
    {
        "translation": {
            "en": "The standard value of 1.5 times the inter-quartile range was changed to 2.5 to slightly reduce the impact of this operation.",
            "zh": "å°†å››åˆ†ä½è· 1.5 å€çš„æ ‡å‡†å€¼æ›´æ”¹ä¸º 2.5ï¼Œä»¥ç•¥å¾®é™ä½æ­¤æ“ä½œçš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hastie, T., R. Tibshirani, and J. Friedman. 2009. The elements of statistical learning. Springer.",
            "zh": "Hastieï¼Œ T.ã€R. Tibshirani å’Œ J. Friedmanã€‚2009. ç»Ÿè®¡å­¦ä¹ çš„è¦ç´ .æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "skew, 59",
            "zh": "æ­ªæ–œï¼Œ59"
        }
    },
    {
        "translation": {
            "en": "Equations (8.69)[467] to (8.72)[467] step through the definition of the Î´k for a neuron in a softmax output layer when a cross-entropy loss function is used.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.69ï¼‰[467]è‡³ï¼ˆ8.72ï¼‰[467]é€æ­¥ä»‹ç»äº†ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ—¶softmaxè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„Î´kçš„å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Statistics that describe the population are referred to as population parameters.",
            "zh": "æè¿°æ€»ä½“çš„ç»Ÿè®¡æ•°æ®ç§°ä¸ºæ€»ä½“å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4.3â€ƒBox Plots",
            "zh": "A.4.3 ç®±å½¢å›¾"
        }
    },
    {
        "translation": {
            "en": "Furthermore, decision tree algorithms are capable of handling both categorical and continuous descriptive features as well as handling missing values and outliers without any need to transform the data.",
            "zh": "æ­¤å¤–ï¼Œå†³ç­–æ ‘ç®—æ³•èƒ½å¤Ÿå¤„ç†åˆ†ç±»å’Œè¿ç»­æè¿°æ€§ç‰¹å¾ï¼Œä»¥åŠå¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œè€Œæ— éœ€è½¬æ¢æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. the two vectors of activations generated by Steps 1 and 2 are merged using an elementwise product, and the result of this operation is the vector of activations that is propagated to the output layer.",
            "zh": "3. ä½¿ç”¨é€å…ƒä¹˜ç§¯åˆå¹¶æ­¥éª¤ 1 å’Œ 2 ç”Ÿæˆçš„ä¸¤ä¸ªæ¿€æ´»å‘é‡ï¼Œæ­¤æ“ä½œçš„ç»“æœæ˜¯ä¼ æ’­åˆ°è¾“å‡ºå±‚çš„æ¿€æ´»å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Most weight initialization processes are based on heuristics that try to ensure that the weights are neither too big nor too small.",
            "zh": "å¤§å¤šæ•°æƒé‡åˆå§‹åŒ–è¿‡ç¨‹éƒ½åŸºäºå¯å‘å¼æ–¹æ³•ï¼Œè¯•å›¾ç¡®ä¿æƒé‡æ—¢ä¸å¤ªå¤§ä¹Ÿä¸å¤ªå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating probabilities in this way is known as summing out.",
            "zh": "ä»¥è¿™ç§æ–¹å¼è®¡ç®—æ¦‚ç‡ç§°ä¸ºæ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapters 4[117], 5[181], 6[243], 7[311] and 8[381]",
            "zh": "ç¬¬4ç« [117]ã€ç¬¬5ç« [181]ã€ç¬¬6ç« [243]ã€ç¬¬7ç« [311]å’Œç¬¬8ç« [381]"
        }
    },
    {
        "translation": {
            "en": "The term representation learning is sometimes used to describe what the neurons in the hidden layers of a network are doing; in a sense, each subsequent layer in the network projects the inputs it receives into a new representation, and the output layer of the network then learns a mapping from a learned representation to the final output.",
            "zh": "æœ¯è¯­è¡¨å¾å­¦ä¹ æœ‰æ—¶ç”¨äºæè¿°ç½‘ç»œéšè—å±‚ä¸­çš„ç¥ç»å…ƒåœ¨åšä»€ä¹ˆ;ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œç½‘ç»œä¸­çš„æ¯ä¸€å±‚åç»­å±‚éƒ½å°†å…¶æ¥æ”¶åˆ°çš„è¾“å…¥æŠ•å°„åˆ°æ–°çš„è¡¨ç¤ºä¸­ï¼Œç„¶åç½‘ç»œçš„è¾“å‡ºå±‚å­¦ä¹ ä»å­¦ä¹ åˆ°çš„è¡¨ç¤ºåˆ°æœ€ç»ˆè¾“å‡ºçš„æ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of using a sampling method to evaluate the performance of a model, as we take distinct, random, non-overlapping samples from a larger dataset and use these for training and testing a prediction model.",
            "zh": "è¿™æ˜¯ä½¿ç”¨æŠ½æ ·æ–¹æ³•è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œå› ä¸ºæˆ‘ä»¬ä»æ›´å¤§çš„æ•°æ®é›†ä¸­è·å–ä¸åŒçš„ã€éšæœºçš„ã€ä¸é‡å çš„æ ·æœ¬ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ ·æœ¬æ¥è®­ç»ƒå’Œæµ‹è¯•é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see how the cumulative likelihood of finding a ham (or negative) instance increases much more quickly than that of finding a spam (or positive) instance.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸æŸ¥æ‰¾åƒåœ¾é‚®ä»¶ï¼ˆæˆ–æ­£é¢ï¼‰å®ä¾‹ç›¸æ¯”ï¼Œæ‰¾åˆ°ç«è…¿ï¼ˆæˆ–è´Ÿé¢ï¼‰å®ä¾‹çš„ç´¯ç§¯å¯èƒ½æ€§å¢åŠ å¾—æ›´å¿«ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2â€…â€…â€…Performance Measures: Categorical Targets",
            "zh": "9.4.2 ç»©æ•ˆè¡¡é‡ï¼šåˆ†ç±»ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "Each weight is iteratively adjusted by a small amount based on the error in the predictions made by the current candidate model so as to generate subsequently more and more accurate candidate models.",
            "zh": "æ ¹æ®å½“å‰å€™é€‰æ¨¡å‹çš„é¢„æµ‹è¯¯å·®ï¼Œå¯¹æ¯ä¸ªæƒé‡è¿›è¡Œå°‘é‡è¿­ä»£è°ƒæ•´ï¼Œä»¥ä¾¿ç”Ÿæˆè¶Šæ¥è¶Šå‡†ç¡®çš„å€™é€‰æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the threshold between bin1 and bin2 will be the midpoint between the LOAN AMOUNT values for d12 (9,850) and d4 (10,000) which is 9,925.",
            "zh": "å› æ­¤ï¼Œbin1 å’Œ bin2 ä¹‹é—´çš„é˜ˆå€¼å°†æ˜¯ d12 ï¼ˆ9,850ï¼‰ å’Œ d4 ï¼ˆ10,000ï¼‰ çš„ LOAN AMOUNT å€¼ä¹‹é—´çš„ä¸­ç‚¹ï¼Œå³ 9,925ã€‚"
        }
    },
    {
        "translation": {
            "en": "To Grandad Dâ€™Arcy, for the inspiration.",
            "zh": "ç»™è¾¾è¥¿çˆ·çˆ·ï¼Œçµæ„Ÿæ¥æºã€‚"
        }
    },
    {
        "translation": {
            "en": "The instances in a training dataset that fall along the margin extents, and therefore the margins, are known as the support vectors. These are the most important instances in the dataset because they define the decision boundary. There will always be at least one support vector for each level of the target feature, but there is no limit to how many support vectors there can be in total.",
            "zh": "è®­ç»ƒæ•°æ®é›†ä¸­æ²¿è¾¹è·èŒƒå›´ï¼ˆå› æ­¤ä¹Ÿä½äºè¾¹è·ï¼‰çš„å®ä¾‹ç§°ä¸ºæ”¯æŒå‘é‡ã€‚è¿™äº›æ˜¯æ•°æ®é›†ä¸­æœ€é‡è¦çš„å®ä¾‹ï¼Œå› ä¸ºå®ƒä»¬å®šä¹‰äº†å†³ç­–è¾¹ç•Œã€‚å¯¹äºç›®æ ‡è¦ç´ çš„æ¯ä¸ªçº§åˆ«ï¼Œå§‹ç»ˆè‡³å°‘æœ‰ä¸€ä¸ªæ”¯æŒå‘é‡ï¼Œä½†æ€»å…±å¯ä»¥æœ‰å¤šå°‘ä¸ªæ”¯æŒå‘é‡æ²¡æœ‰é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "silhouette width, 609",
            "zh": "è½®å»“å®½åº¦ï¼Œ609"
        }
    },
    {
        "translation": {
            "en": "13.1â€…â€…â€…Business Understanding",
            "zh": "13.1 ä¸šåŠ¡ç†è§£"
        }
    },
    {
        "translation": {
            "en": "The customerâ€™s income level",
            "zh": "å®¢æˆ·çš„æ”¶å…¥æ°´å¹³"
        }
    },
    {
        "translation": {
            "en": "Peak time was 08:00 to 18:00 from Monday to Friday, and calls made during peak time were more expensive than calls made during off-peak times.",
            "zh": "å‘¨ä¸€è‡³å‘¨äº”çš„é«˜å³°æ—¶é—´ä¸º08ï¼š00è‡³18ï¼š00ï¼Œé«˜å³°æ—¶æ®µçš„ç”µè¯æ¯”éé«˜å³°æ—¶æ®µçš„ç”µè¯æ›´è´µã€‚"
        }
    },
    {
        "translation": {
            "en": "We use bold notation P() to distinguish a probability distribution from a probability mass function P().",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç²—ä½“ç¬¦å· Pï¼ˆï¼‰ æ¥åŒºåˆ†æ¦‚ç‡åˆ†å¸ƒå’Œæ¦‚ç‡è´¨é‡å‡½æ•° Pï¼ˆï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that neurons that use a rectified linear activation function are known as ReLUs (short for rectified linear units).",
            "zh": "è¯·æ³¨æ„ï¼Œä½¿ç”¨æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒç§°ä¸º ReLUï¼ˆæ•´æµçº¿æ€§å•å…ƒçš„ç¼©å†™ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "With respect to the general ability of bagging and boosting ensembles to make accurate predictions, the results reported in Caruana et al.",
            "zh": "å…³äºè£…è¢‹å’Œå¢å¼ºé›†åˆåšå‡ºå‡†ç¡®é¢„æµ‹çš„ä¸€èˆ¬èƒ½åŠ›ï¼ŒCaruana ç­‰äººæŠ¥å‘Šçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) The actual 2011 CPI for Russia was 2.4488. Which of the predictions made was the most accurate? Why do you think this was?",
            "zh": "ï¼ˆeï¼‰ ä¿„ç½—æ–¯2011å¹´å®é™…æ¶ˆè´¹ç‰©ä»·æŒ‡æ•°ä¸º2.4488ã€‚å“ªä¸ªé¢„æµ‹æœ€å‡†ç¡®ï¼Ÿä½ è®¤ä¸ºè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "If, however, we need to calculate the posterior probability distribution over X given Y, that is P(X | Y), then we will be actually calculating each of the P(Y | Xi)P(Xi) values in Equation (6.5)[250] as part of this calculation, and it is more efficient to use Equation (6.7)[250].",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦è®¡ç®—ç»™å®š Y çš„ X ä¸Šçš„åéªŒæ¦‚ç‡åˆ†å¸ƒï¼Œåˆ™ä¸º Pï¼ˆX |Yï¼‰ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†å®é™…è®¡ç®—æ¯ä¸ª Pï¼ˆY |å…¬å¼ï¼ˆ6.5ï¼‰[250]ä¸­çš„ä¹ Pï¼ˆä¹ ï¼‰å€¼ä½œä¸ºæ­¤è®¡ç®—çš„ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨å…¬å¼ï¼ˆ6.7ï¼‰[250]æ›´æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "These methods have been in existence since at least the early 1990s but have seen a resurgence of interest in the 2010s with the emergence of deep learning.",
            "zh": "è¿™äº›æ–¹æ³•è‡³å°‘ä» 1990 å¹´ä»£åˆå°±å·²ç»å­˜åœ¨ï¼Œä½†éšç€æ·±åº¦å­¦ä¹ çš„å‡ºç°ï¼Œåœ¨ 2010 å¹´ä»£é‡æ–°å¼•èµ·äº†äººä»¬çš„å…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Discuss this data quality report in terms of the following:",
            "zh": "ä»ä»¥ä¸‹æ–¹é¢è®¨è®ºæ­¤æ•°æ®è´¨é‡æŠ¥å‘Šï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18(c)[226] illustrates the distribution of the original 29 instances when we move to a three-dimensional feature space (each instance has been given a random value in the range [0.0,3.0] for the Z feature).",
            "zh": "å›¾ 5.18ï¼ˆcï¼‰[226] è¯´æ˜äº†å½“æˆ‘ä»¬ç§»åŠ¨åˆ°ä¸‰ç»´ç‰¹å¾ç©ºé—´æ—¶åŸå§‹ 29 ä¸ªå®ä¾‹çš„åˆ†å¸ƒï¼ˆæ¯ä¸ªå®ä¾‹éƒ½è¢«èµ‹äºˆäº† Z ç‰¹å¾èŒƒå›´å†… [0.0,3.0] çš„éšæœºå€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "action-value table, 654",
            "zh": "åŠ¨ä½œå€¼è¡¨ï¼Œ654"
        }
    },
    {
        "translation": {
            "en": "thinning, 299",
            "zh": "å˜è–„ï¼Œ299"
        }
    },
    {
        "translation": {
            "en": "The target feature",
            "zh": "ç›®æ ‡åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "If we needed to do it, the most sensible approach to handling the missing values in the NUM.",
            "zh": "å¦‚æœæˆ‘ä»¬éœ€è¦è¿™æ ·åšï¼Œå¤„ç† NUM ä¸­ç¼ºå¤±å€¼çš„æœ€æ˜æ™ºçš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, this heuristic is not guaranteed to avoid dead ReLUs: returning to the forward propagation of d2 through the ReLU network (see Figure 8.19[441]), in this network Neuron 3 already has a bias of w3,0 = 0.1, but this positive bias is dominated by the large negative weight w3,1 = âˆ’0.20.",
            "zh": "ç„¶è€Œï¼Œè¿™ç§å¯å‘å¼æ–¹æ³•å¹¶ä¸èƒ½ä¿è¯é¿å…æ­» ReLUï¼šé€šè¿‡ ReLU ç½‘ç»œè¿”å› d2 çš„å‰å‘ä¼ æ’­ï¼ˆå‚è§å›¾ 8.19[441]ï¼‰ï¼Œåœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œç¥ç»å…ƒ 3 å·²ç»å…·æœ‰ w3,0 = 0.1 çš„åå·®ï¼Œä½†è¿™ç§æ­£åå·®ç”±å¤§è´Ÿæƒé‡ w3,1 = âˆ’0.20 ä¸»å¯¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This first candidate model is not particularly accurate with an initial sum of squared errors of 12.2369.",
            "zh": "ç¬¬ä¸€ä¸ªå€™é€‰æ¨¡å‹ä¸æ˜¯ç‰¹åˆ«å‡†ç¡®ï¼Œåˆå§‹å¹³æ–¹è¯¯å·®ä¹‹å’Œä¸º 12.2369ã€‚"
        }
    },
    {
        "translation": {
            "en": "test set, 535, 541",
            "zh": "æµ‹è¯•é›†ï¼Œ 535ï¼Œ 541"
        }
    },
    {
        "translation": {
            "en": "The fundamental concepts required to build a system on the basis of this idea are feature spaces and measures of similarity, and these are covered in the fundamentals section of this chapter.",
            "zh": "åŸºäºè¿™ä¸ªæƒ³æ³•æ„å»ºç³»ç»Ÿæ‰€éœ€çš„åŸºæœ¬æ¦‚å¿µæ˜¯ç‰¹å¾ç©ºé—´å’Œç›¸ä¼¼åº¦é‡ï¼Œè¿™äº›åœ¨æœ¬ç« çš„åŸºç¡€éƒ¨åˆ†ä¸­éƒ½æœ‰ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This algorithm is built on two fundamental concepts: (1) a feature space, and (2) measures of similarity between instances within the feature space.",
            "zh": "è¯¥ç®—æ³•å»ºç«‹åœ¨ä¸¤ä¸ªåŸºæœ¬æ¦‚å¿µä¹‹ä¸Šï¼šï¼ˆ1ï¼‰ ç‰¹å¾ç©ºé—´ï¼Œä»¥åŠ ï¼ˆ2ï¼‰ ç‰¹å¾ç©ºé—´å†…å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼åº¦åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will find this useful when we are trying to decide whether to search both branches of a node when we are looking for the nearest neighbor or whether we can prune one of them.",
            "zh": "å½“æˆ‘ä»¬è¯•å›¾å†³å®šæ˜¯å¦åœ¨å¯»æ‰¾æœ€è¿‘çš„é‚»å±…æ—¶æœç´¢èŠ‚ç‚¹çš„ä¸¤ä¸ªåˆ†æ”¯ï¼Œæˆ–è€…æˆ‘ä»¬æ˜¯å¦å¯ä»¥ä¿®å‰ªå…¶ä¸­ä¸€ä¸ªåˆ†æ”¯æ—¶ï¼Œæˆ‘ä»¬ä¼šå‘ç°è¿™å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then present the standard approach to building error-based predictive models: multivariable linear regression with gradient descent.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†æ„å»ºåŸºäºè¯¯å·®çš„é¢„æµ‹æ¨¡å‹çš„æ ‡å‡†æ–¹æ³•ï¼šæ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic approach to learning the structure of a Bayesian network is to use a local search algorithm that moves through the space of possible networks and parameters, and searches for the network topology and CPT parameters that best fit with the data.",
            "zh": "å­¦ä¹ è´å¶æ–¯ç½‘ç»œç»“æ„çš„åŸºæœ¬æ–¹æ³•æ˜¯ä½¿ç”¨æœ¬åœ°æœç´¢ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨å¯èƒ½çš„ç½‘ç»œå’Œå‚æ•°çš„ç©ºé—´ä¸­ç§»åŠ¨ï¼Œå¹¶æœç´¢ä¸æ•°æ®æœ€åŒ¹é…çš„ç½‘ç»œæ‹“æ‰‘å’Œ CPT å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.3.1â€ƒA Worked Example",
            "zh": "11.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "Examining the actual raw data in Table 3.2[56] shows that these zeros always co-occur with missing values in the MARITAL STATUS feature.",
            "zh": "æ£€æŸ¥è¡¨3.2[56]ä¸­çš„å®é™…åŸå§‹æ•°æ®è¡¨æ˜ï¼Œè¿™äº›é›¶æ€»æ˜¯ä¸å©šå§»çŠ¶å†µç‰¹å¾ä¸­çš„ç¼ºå¤±å€¼åŒæ—¶å‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that for ease of presentation the network schematics in this figure have been rotated so that the forward flow of information through each network is from the input layer at the bottom to the output layer at the top.",
            "zh": "è¯·æ³¨æ„ï¼Œä¸ºäº†ä¾¿äºæ¼”ç¤ºï¼Œæ­¤å›¾ä¸­çš„ç½‘ç»œåŸç†å›¾å·²æ—‹è½¬ï¼Œä»¥ä¾¿é€šè¿‡æ¯ä¸ªç½‘ç»œçš„ä¿¡æ¯æµä»åº•éƒ¨çš„è¾“å…¥å±‚åˆ°é¡¶éƒ¨çš„è¾“å‡ºå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "using the 6th and 7th values in the list, 165 and 188. We have actually already come across a percentile in the measures of central tendency. The median is the 50th percentile.",
            "zh": "ä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ 6 ä¸ªå’Œç¬¬ 7 ä¸ªå€¼ 165 å’Œ 188ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å·²ç»åœ¨é›†ä¸­è¶‹åŠ¿çš„è¡¡é‡æ ‡å‡†ä¸­é‡åˆ°äº†ä¸€ä¸ªç™¾åˆ†ä½æ•°ã€‚ä¸­ä½æ•°æ˜¯ç¬¬ 50 ä¸ªç™¾åˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table contains an extract from this ABTâ€”the full ABT contains 2,440 instances.",
            "zh": "ä¸‹è¡¨åŒ…å«æ­¤ ABT çš„æ‘˜å½• - å®Œæ•´çš„ ABT åŒ…å« 2,440 ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adding depth to a filter does not involve a major change in the way a neuron applies a filter to its local receptive field.",
            "zh": "å‘è¿‡æ»¤å™¨æ·»åŠ æ·±åº¦å¹¶ä¸æ¶‰åŠç¥ç»å…ƒå°†è¿‡æ»¤å™¨åº”ç”¨äºå…¶å±€éƒ¨æ„Ÿå—é‡çš„æ–¹å¼çš„é‡å¤§å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dosage Prediction: Doctors and scientists frequently decide how much of a medicine or other chemical to include in a treatment. Predictive analytics models can be used to assist this decision making by predicting optimal dosages based on data about past dosages and associated outcomes.",
            "zh": "å‰‚é‡é¢„æµ‹ï¼šåŒ»ç”Ÿå’Œç§‘å­¦å®¶ç»å¸¸å†³å®šåœ¨æ²»ç–—ä¸­åŠ å…¥å¤šå°‘è¯ç‰©æˆ–å…¶ä»–åŒ–å­¦ç‰©è´¨ã€‚é¢„æµ‹åˆ†ææ¨¡å‹å¯ç”¨äºæ ¹æ®è¿‡å»å‰‚é‡å’Œç›¸å…³ç»“æœçš„æ•°æ®é¢„æµ‹æœ€ä½³å‰‚é‡ï¼Œä»è€ŒååŠ©åšå‡ºæ­¤å†³ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The biggest challenge in creating a Bayesian prediction model is overcoming the exponential growth in the number of probabilities (model parameters) that are required as the dimensionality of the feature space increases.",
            "zh": "åˆ›å»ºè´å¶æ–¯é¢„æµ‹æ¨¡å‹çš„æœ€å¤§æŒ‘æˆ˜æ˜¯å…‹æœéšç€ç‰¹å¾ç©ºé—´ç»´æ•°çš„å¢åŠ è€Œæ‰€éœ€çš„æ¦‚ç‡ï¼ˆæ¨¡å‹å‚æ•°ï¼‰æ•°é‡çš„æŒ‡æ•°å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, with just 20 descriptive features, there are 220 = 1,048,576 possible feature subsets.",
            "zh": "ä¾‹å¦‚ï¼Œåªæœ‰ 20 ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œå°±æœ‰ 220 = 1,048,576 ä¸ªå¯èƒ½çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, a common practice when training a recurrent neural network to process a long sequence is to break the sequence up into subsequences.",
            "zh": "å› æ­¤ï¼Œåœ¨è®­ç»ƒé€’å½’ç¥ç»ç½‘ç»œå¤„ç†é•¿åºåˆ—æ—¶ï¼Œä¸€ç§å¸¸è§çš„åšæ³•æ˜¯å°†åºåˆ—åˆ†è§£ä¸ºå­åºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Building a churn prediction model was also attractive to the AT executive team, as they hoped that as well as being useful in reducing churn rates, it would help to explain the main drivers behind customer churn. A better understanding of the main drivers of customer churn would be useful to many other parts of the AT business.",
            "zh": "æ„å»ºå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹å¯¹ AT æ‰§è¡Œå›¢é˜Ÿä¹Ÿå¾ˆæœ‰å¸å¼•åŠ›ï¼Œå› ä¸ºä»–ä»¬å¸Œæœ›å®ƒä¸ä»…æœ‰åŠ©äºé™ä½å®¢æˆ·æµå¤±ç‡ï¼Œè¿˜æœ‰åŠ©äºè§£é‡Šå®¢æˆ·æµå¤±èƒŒåçš„ä¸»è¦é©±åŠ¨å› ç´ ã€‚æ›´å¥½åœ°äº†è§£å®¢æˆ·æµå¤±çš„ä¸»è¦é©±åŠ¨å› ç´ å°†å¯¹ATä¸šåŠ¡çš„è®¸å¤šå…¶ä»–éƒ¨åˆ†æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The third way in which naive weights initialization can cause unstable gradients arises from the fact that the variance of the output of a weighted sum is a function of three factors: the number of inputs to the weighted sum, the variance of the inputs, and the variance of the weights.",
            "zh": "æœ´ç´ æƒé‡åˆå§‹åŒ–å¯èƒ½å¯¼è‡´ä¸ç¨³å®šæ¢¯åº¦çš„ç¬¬ä¸‰ç§æ–¹å¼æºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³åŠ æƒå’Œçš„è¾“å‡ºæ–¹å·®æ˜¯ä¸‰ä¸ªå› ç´ çš„å‡½æ•°ï¼šåŠ æƒå’Œçš„è¾“å…¥æ•°ã€è¾“å…¥çš„æ–¹å·®å’Œæƒé‡çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, given the set of values for a continuous feature, we fit a mixture of Gaussians distribution to this data by searching for the number of components and set of parameters for each component that best matches the data.",
            "zh": "ç›¸åï¼Œç»™å®šè¿ç»­ç‰¹å¾çš„ä¸€ç»„å€¼ï¼Œæˆ‘ä»¬é€šè¿‡æœç´¢ä¸æ•°æ®æœ€åŒ¹é…çš„æ¯ä¸ªåˆ†é‡çš„åˆ†é‡æ•°å’Œå‚æ•°é›†ï¼Œå°†é«˜æ–¯åˆ†å¸ƒçš„æ··åˆæ‹Ÿåˆåˆ°è¯¥æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can be problematic because modern datasets can be very largeâ€”it is quite possible to have datasets containing millions or even billions of examples.",
            "zh": "è¿™å¯èƒ½æ˜¯æœ‰é—®é¢˜çš„ï¼Œå› ä¸ºç°ä»£æ•°æ®é›†å¯èƒ½éå¸¸å¤§â€”â€”å¾ˆå¯èƒ½æ‹¥æœ‰åŒ…å«æ•°ç™¾ä¸‡ç”šè‡³æ•°åäº¿ä¸ªç¤ºä¾‹çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2.1â€ƒMatching Machine Learning Approaches to Projects",
            "zh": "14.2.1 å°†æœºå™¨å­¦ä¹ æ–¹æ³•ä¸é¡¹ç›®ç›¸åŒ¹é…"
        }
    },
    {
        "translation": {
            "en": "In general, the histogram heights follow the dashed line, so the resulting bins can be considered a reasonable representation of the continuous feature.",
            "zh": "é€šå¸¸ï¼Œç›´æ–¹å›¾é«˜åº¦éµå¾ªè™šçº¿ï¼Œå› æ­¤ç”Ÿæˆçš„æ¡æŸ±å¯ä»¥è¢«è§†ä¸ºè¿ç»­è¦ç´ çš„åˆç†è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "4.16â€…â€…â€…The decision tree resulting from splitting the data in Table 4.11[152] using the feature SEASON.",
            "zh": "4.16 ä½¿ç”¨ç‰¹å¾ SEASON æ‹†åˆ†è¡¨ 4.11[152] ä¸­çš„æ•°æ®ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other change we need to make to Algorithm 1[134] to handle continuous targets relates to the base cases that cause the algorithm to stop processing data partitions and to create a leaf node.",
            "zh": "æˆ‘ä»¬éœ€è¦å¯¹ç®—æ³• 1[134] è¿›è¡Œçš„å¦ä¸€ä¸ªæ›´æ”¹æ˜¯å¤„ç†è¿ç»­ç›®æ ‡ï¼Œè¿™ä¸å¯¼è‡´ç®—æ³•åœæ­¢å¤„ç†æ•°æ®åˆ†åŒºå¹¶åˆ›å»ºå¶èŠ‚ç‚¹çš„åŸºæœ¬æƒ…å†µæœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.63",
            "zh": "0.63"
        }
    },
    {
        "translation": {
            "en": "99.97",
            "zh": "99.97"
        }
    },
    {
        "translation": {
            "en": "Certain approaches, however, are a more natural fit for some kinds of data than others, so we can make some recommendations.",
            "zh": "ä½†æ˜¯ï¼ŒæŸäº›æ–¹æ³•æ¯”å…¶ä»–æ–¹æ³•æ›´é€‚åˆæŸäº›ç±»å‹çš„æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æå‡ºä¸€äº›å»ºè®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The upper and lower thresholds can be set manually based on domain knowledge or can be calculated from data. One common way to calculate clamp thresholds is to set the lower threshold to the 1st quartile value minus 1.5 times the inter-quartile range and the upper threshold to the 3rd quartile plus 1.5 times the inter-quartile range. This works effectively and takes into account the fact that the variation in a dataset can be different on either side of a central tendency.",
            "zh": "ä¸Šé™å’Œä¸‹é™é˜ˆå€¼å¯ä»¥æ ¹æ®é¢†åŸŸçŸ¥è¯†æ‰‹åŠ¨è®¾ç½®ï¼Œä¹Ÿå¯ä»¥æ ¹æ®æ•°æ®è®¡ç®—ã€‚è®¡ç®—é’³ä½é˜ˆå€¼çš„ä¸€ç§å¸¸ç”¨æ–¹æ³•æ˜¯å°†ä¸‹é™é˜ˆå€¼è®¾ç½®ä¸ºç¬¬ 1 ä¸ªå››åˆ†ä½æ•°å€¼å‡å»å››åˆ†ä½æ•°é—´èŒƒå›´çš„ 1.5 å€ï¼Œå°†ä¸Šé™é˜ˆå€¼è®¾ç½®ä¸ºç¬¬ 3 ä¸ªå››åˆ†ä½æ•°åŠ ä¸Šå››åˆ†ä½æ•°é—´èŒƒå›´çš„ 1.5 å€ã€‚è¿™å¾ˆæœ‰æ•ˆï¼Œå¹¶è€ƒè™‘åˆ°æ•°æ®é›†ä¸­çš„å˜åŒ–åœ¨ä¸­å¿ƒè¶‹åŠ¿çš„ä»»ä½•ä¸€ä¾§éƒ½å¯èƒ½ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "NEWFREQUENTNUMBERS: Derived from analysis of the actual numbers dialed in the raw call data, this feature attempted to capture how many new numbers a customer has begun calling frequently that month. A frequent number was defined as a number that constituted more than 15% of a customerâ€™s total calls.",
            "zh": "NEWFREQUENTNUMBERSï¼šæ ¹æ®å¯¹åŸå§‹å‘¼å«æ•°æ®ä¸­å®é™…æ‹¨æ‰“çš„å·ç çš„åˆ†æï¼Œæ­¤åŠŸèƒ½è¯•å›¾æ•è·å®¢æˆ·å½“æœˆå¼€å§‹é¢‘ç¹å‘¼å«çš„æ–°å·ç æ•°é‡ã€‚é¢‘ç¹å·ç è¢«å®šä¹‰ä¸ºå å®¢æˆ·æ€»å‘¼å«é‡ 15% ä»¥ä¸Šçš„å·ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "Precision, recall, and the F1 measure work best in prediction problems with binary target features and place an emphasis on capturing the performance of a prediction model on the positive, or most important, level.",
            "zh": "ç²¾åº¦ã€å¬å›ç‡å’Œ F1 åº¦é‡åœ¨å…·æœ‰äºŒå…ƒç›®æ ‡ç‰¹å¾çš„é¢„æµ‹é—®é¢˜ä¸­æ•ˆæœæœ€å¥½ï¼Œå¹¶å¼ºè°ƒåœ¨æ­£æˆ–æœ€é‡è¦çš„æ°´å¹³ä¸Šæ•è·é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the terms in the equation have the same meaning as before, and abs refers to the absolute value. Mean absolute error values fall in the range [0,âˆ], and smaller values indicate better model performance.",
            "zh": "å…¶ä¸­ç­‰å¼ä¸­çš„é¡¹å…·æœ‰ä¸å‰é¢ç›¸åŒçš„å«ä¹‰ï¼Œå¹¶ä¸” abs è¡¨ç¤ºç»å¯¹å€¼ã€‚å¹³å‡ç»å¯¹è¯¯å·®å€¼åœ¨ [0ï¼Œâˆ] èŒƒå›´å†…ï¼Œå€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 10[607] shows a pseudocode description of the k-means algorithm.",
            "zh": "ç®—æ³•10[607]æ˜¾ç¤ºäº†k-meansç®—æ³•çš„ä¼ªä»£ç æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Edwin also agreed that Ted was correct about the unavailability of spectrograph data for most objects, so this was also removed.",
            "zh": "åŸƒå¾·æ¸©ä¹ŸåŒæ„æ³°å¾·å…³äºå¤§å¤šæ•°ç‰©ä½“çš„å…‰è°±ä»ªæ•°æ®ä¸å¯ç”¨æ˜¯æ­£ç¡®çš„ï¼Œæ‰€ä»¥è¿™ä¹Ÿè¢«åˆ é™¤äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if the age of a customer was used as a descriptive feature in a financial credit scoring model, it is more difficult to talk about changes in normalized age on a scale from 0 to 1 than it is to discuss original age values on their natural scale, about 18 to 80.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœå®¢æˆ·çš„å¹´é¾„è¢«ç”¨ä½œé‡‘èä¿¡ç”¨è¯„åˆ†æ¨¡å‹ä¸­çš„æè¿°æ€§ç‰¹å¾ï¼Œé‚£ä¹ˆåœ¨ä» 0 åˆ° 1 çš„èŒƒå›´å†…è°ˆè®ºæ ‡å‡†åŒ–å¹´é¾„çš„å˜åŒ–æ¯”åœ¨è‡ªç„¶é‡è¡¨ï¼ˆå¤§çº¦ 18 åˆ° 80 å²ï¼‰ä¸Šè®¨è®ºåŸå§‹å¹´é¾„å€¼æ›´å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "19. See Section 7.4.2[334].",
            "zh": "19. å‚è§ç¬¬ 7.4.2 èŠ‚[334]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some argue that reinforcement learning is closer to supervised learning because the reward signal is a form of supervision.",
            "zh": "ä¸€äº›äººè®¤ä¸ºå¼ºåŒ–å­¦ä¹ æ›´æ¥è¿‘äºç›‘ç£å­¦ä¹ ï¼Œå› ä¸ºå¥–åŠ±ä¿¡å·æ˜¯ä¸€ç§ç›‘ç£å½¢å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.1â€ƒWhat Is Predictive Data Analytics?",
            "zh": "1.1 ä»€ä¹ˆæ˜¯é¢„æµ‹æ•°æ®åˆ†æï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "If all the neurons in a network use a logistic activation function or another activation function whose derivative has a small range less than 1, then the error gradient will get smaller and smaller as it is backpropagated through the networks layers, and the scaling down of the gradient is particularly severe for neurons whose z value is in the saturated region of the activation function.",
            "zh": "å¦‚æœç½‘ç»œä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°æˆ–å…¶ä»–æ¿€æ´»å‡½æ•°ï¼Œå…¶å¯¼æ•°èŒƒå›´å°äº 1ï¼Œåˆ™è¯¯å·®æ¢¯åº¦åœ¨ç½‘ç»œå±‚ä¸­åå‘ä¼ æ’­æ—¶ä¼šè¶Šæ¥è¶Šå°ï¼Œå¹¶ä¸”æ¢¯åº¦çš„ç¼©å°å¯¹äºzå€¼åœ¨æ¿€æ´»å‡½æ•°é¥±å’ŒåŒºåŸŸçš„ç¥ç»å…ƒå°¤å…¶ä¸¥é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The single classification accuracy performance measure hides this poor performance on the minority target levels.",
            "zh": "å•ä¸€çš„åˆ†ç±»å‡†ç¡®æ€§ç»©æ•ˆè¡¡é‡æ ‡å‡†æ©ç›–äº†å°‘æ•°ç›®æ ‡æ°´å¹³ä¸Šçš„è¿™ç§ç³Ÿç³•è¡¨ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A network can represent a function if a set of weights exist for that network for which the network implements the function.",
            "zh": "å¦‚æœç½‘ç»œä¸ºå…¶å®ç°å‡½æ•°çš„ç½‘ç»œå­˜åœ¨ä¸€ç»„æƒé‡ï¼Œåˆ™ç½‘ç»œå¯ä»¥è¡¨ç¤ºè¯¥å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) After three iterations of the AHC algorithm, three pairs of instances have been combined into clusters, 10, 11, and 12.",
            "zh": "ï¼ˆcï¼‰ ç»è¿‡ AHC ç®—æ³•çš„ä¸‰æ¬¡è¿­ä»£ï¼Œä¸‰å¯¹å®ä¾‹è¢«ç»„åˆæˆé›†ç¾¤ 10ã€11 å’Œ 12ã€‚"
        }
    },
    {
        "translation": {
            "en": "conditionally independent, 285, 288",
            "zh": "æœ‰æ¡ä»¶ç‹¬ç«‹ï¼Œ285,288"
        }
    },
    {
        "translation": {
            "en": "Returning to the backward pass of the backpropagation algorithm, Figure 8.12[407] shows that the backward pass begins by calculating the Î´ for each of the neurons in the output layer of the network.",
            "zh": "å›åˆ°åå‘ä¼ æ’­ç®—æ³•çš„å‘åä¼ é€’ï¼Œå›¾8.12[407]æ˜¾ç¤ºï¼Œå‘åä¼ é€’ä»è®¡ç®—ç½‘ç»œè¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´å¼€å§‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first partâ€”Chapters 2[23] and 3[53]â€”covers the Business Understanding, Data Understanding, and Data Preparation phases of the process. In this part we discuss how a business problem is converted into a data analytics solution, how data can be prepared for this task, and the data exploration tasks that should be performed during these phases.",
            "zh": "ç¬¬ä¸€éƒ¨åˆ†ï¼ˆç¬¬ 2 ç« [23] å’Œ 3 ç« [53]ï¼‰æ¶µç›–äº†æµç¨‹çš„ä¸šåŠ¡ç†è§£ã€æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•å°†ä¸šåŠ¡é—®é¢˜è½¬æ¢ä¸ºæ•°æ®åˆ†æè§£å†³æ–¹æ¡ˆï¼Œå¦‚ä½•ä¸ºæ­¤ä»»åŠ¡å‡†å¤‡æ•°æ®ï¼Œä»¥åŠåœ¨è¿™äº›é˜¶æ®µåº”æ‰§è¡Œçš„æ•°æ®æ¢ç´¢ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, it is not possible in a single chapter to cover all possible deep learning topics.",
            "zh": "å› æ­¤ï¼Œä¸å¯èƒ½åœ¨ä¸€ç« ä¸­æ¶µç›–æ‰€æœ‰å¯èƒ½çš„æ·±åº¦å­¦ä¹ ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature is binary and labels components as good or bad.",
            "zh": "ç›®æ ‡åŠŸèƒ½æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå¹¶å°†ç»„ä»¶æ ‡è®°ä¸ºå¥½æˆ–åã€‚"
        }
    },
    {
        "translation": {
            "en": "target feature, 5, 19, 28, 598",
            "zh": "ç›®æ ‡ç‰¹å¾ï¼Œ 5ï¼Œ 19ï¼Œ 28ï¼Œ 598"
        }
    },
    {
        "translation": {
            "en": "The roots of probability are in gambling, where, understandably, gamblers wanted to be able to predict future events based on their likelihood.",
            "zh": "æ¦‚ç‡çš„æ ¹æºåœ¨äºèµŒåšï¼Œå¯ä»¥ç†è§£çš„æ˜¯ï¼ŒèµŒå¾’å¸Œæœ›èƒ½å¤Ÿæ ¹æ®ä»–ä»¬çš„å¯èƒ½æ€§é¢„æµ‹æœªæ¥äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is also illustrated in Figure 11.9[672].",
            "zh": "å›¾11.9[672]ä¹Ÿè¯´æ˜äº†è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We recommend using early stopping as the default strategy to control when to stop training a neural network.",
            "zh": "æˆ‘ä»¬å»ºè®®ä½¿ç”¨æå‰åœæ­¢ä½œä¸ºé»˜è®¤ç­–ç•¥æ¥æ§åˆ¶ä½•æ—¶åœæ­¢è®­ç»ƒç¥ç»ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "k nearest neighbor, 181, 192, 231, 536, 554, 575, 719, 731, 733, 735",
            "zh": "k æœ€è¿‘é‚»ï¼Œ 181ï¼Œ 192ï¼Œ 231ï¼Œ 536ï¼Œ 554ï¼Œ 575ï¼Œ 719ï¼Œ 731ï¼Œ 733ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "The exponential distribution is often used to model waiting times (for example, how long it will take for a call to be answered at a help desk, how long you will have to wait for a bus, or how long before a piece of hardware fails), where the parameter Î» is equal to 1 divided by the average time it takes for the event.",
            "zh": "æŒ‡æ•°åˆ†å¸ƒé€šå¸¸ç”¨äºå¯¹ç­‰å¾…æ—¶é—´è¿›è¡Œå»ºæ¨¡ï¼ˆä¾‹å¦‚ï¼Œåœ¨æœåŠ¡å°æ¥å¬ç”µè¯éœ€è¦å¤šé•¿æ—¶é—´ï¼Œæ‚¨å¿…é¡»ç­‰å¾…å…¬äº¤è½¦å¤šé•¿æ—¶é—´ï¼Œæˆ–è€…ç¡¬ä»¶æ•…éšœä¹‹å‰éœ€è¦å¤šé•¿æ—¶é—´ï¼‰ï¼Œå…¶ä¸­å‚æ•° Î» ç­‰äº 1 é™¤ä»¥äº‹ä»¶æ‰€éœ€çš„å¹³å‡æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "For datasets that only sparsely populate the feature space, however, weighted k nearest neighbor models usually make more accurate predictions, as they take into account the fact that some of the nearest neighbors can actually be quite far away.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºä»…ç¨€ç–å¡«å……ç‰¹å¾ç©ºé—´çš„æ•°æ®é›†ï¼ŒåŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹é€šå¸¸ä¼šåšå‡ºæ›´å‡†ç¡®çš„é¢„æµ‹ï¼Œå› ä¸ºå®ƒä»¬è€ƒè™‘åˆ°ä¸€äº›æœ€è¿‘é‚»å®é™…ä¸Šå¯èƒ½éå¸¸è¿œçš„äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two useful performance measures in this regard are gain and lift (we will see that the related performance measures of cumulative gain and cumulative lift are also useful).",
            "zh": "åœ¨è¿™æ–¹é¢ï¼Œä¸¤ä¸ªæœ‰ç”¨çš„ç»©æ•ˆæŒ‡æ ‡æ˜¯å¢ç›Šå’Œæå‡ï¼ˆæˆ‘ä»¬å°†çœ‹åˆ°ç´¯ç§¯å¢ç›Šå’Œç´¯ç§¯æå‡çš„ç›¸å…³ç»©æ•ˆæŒ‡æ ‡ä¹Ÿå¾ˆæœ‰ç”¨ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most straightforward way to make a model abstract away from the precise location of visual features is to sub-sample the feature maps.",
            "zh": "ä½¿æ¨¡å‹æŠ½è±¡å‡ºè§†è§‰ç‰¹å¾çš„ç²¾ç¡®ä½ç½®çš„æœ€ç›´æ¥æ–¹æ³•æ˜¯å¯¹ç‰¹å¾å›¾è¿›è¡Œå­é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "These corrections are combined with the 0 predictions to give the ensemble predictions after the first iteration, 1.",
            "zh": "è¿™äº›ä¿®æ­£ä¸ 0 ä¸ªé¢„æµ‹ç›¸ç»“åˆï¼Œä»¥åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ 1 ä¹‹åç»™å‡ºé›†æˆé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental idea underpinning reinforcement learning is that the only goal of an intelligent agent is to maximize cumulative reward across an episode.3 The cumulative reward earned across an episode is referred to as the return from the episode and can be defined as",
            "zh": "æ”¯æ’‘å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œæ™ºèƒ½ä»£ç†çš„å”¯ä¸€ç›®æ ‡æ˜¯åœ¨ä¸€é›†ä¸­æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±.3 åœ¨ä¸€é›†ä¸­è·å¾—çš„ç´¯ç§¯å¥–åŠ±ç§°ä¸ºä»ä¸€é›†ä¸­è·å¾—çš„å›æŠ¥ï¼Œå¯ä»¥å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "If a three-layer network can represent any function with arbitrary accuracy, is it helpful to go deeper, or is it better to make the layers wider?",
            "zh": "å¦‚æœä¸€ä¸ªä¸‰å±‚ç½‘ç»œå¯ä»¥ä»¥ä»»æ„ç²¾åº¦è¡¨ç¤ºä»»ä½•å‡½æ•°ï¼Œé‚£ä¹ˆæ›´æ·±ä¸€ç‚¹æ˜¯æœ‰å¸®åŠ©çš„ï¼Œè¿˜æ˜¯è®©å±‚æ›´å®½æ›´å¥½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The fact that the ReLU activation function for Neuron 4 is saturated for all four examples means that Neuron 4 is essentially dead during the forward pass of the algorithm (it does not activate for any example) and this reduces the representational capacity of the network.",
            "zh": "Neuron 4 çš„ ReLU æ¿€æ´»å‡½æ•°åœ¨æ‰€æœ‰å››ä¸ªç¤ºä¾‹ä¸­éƒ½é¥±å’Œï¼Œè¿™æ„å‘³ç€ Neuron 4 åœ¨ç®—æ³•çš„å‰å‘ä¼ é€’æœŸé—´åŸºæœ¬ä¸Šæ˜¯æ­»çš„ï¼ˆå®ƒä¸ä¼šæ¿€æ´»ä»»ä½•ç¤ºä¾‹ï¼‰ï¼Œè¿™é™ä½äº†ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the terms âˆ‚â„°/âˆ‚f (Equation (8.126)[518]), âˆ‚â„°/âˆ‚iâ€  (Equation (8.124)[518]), âˆ‚â„°/âˆ‚iâ€¡ (Equation (8.123)[518]), and âˆ‚â„°/âˆ‚oâ€  (Equation (8.120)[516]) describes a vector of error gradients with respect to the output activations of the neurons in one of the sigmoid and tanh layers in the LSTM.",
            "zh": "æ¯ä¸ªé¡¹ âˆ‚E/âˆ‚f ï¼ˆç­‰å¼ ï¼ˆ8.126ï¼‰[518]ï¼‰ã€âˆ‚E/âˆ‚iâ€  ï¼ˆç­‰å¼ ï¼ˆ8.124ï¼‰[518]ï¼‰ã€âˆ‚E/âˆ‚iâ€¡ ï¼ˆç­‰å¼ ï¼ˆ8.123ï¼‰[518]ï¼‰ å’Œ âˆ‚E/âˆ‚oâ€  ï¼ˆç­‰å¼ ï¼ˆ8.120ï¼‰[516]ï¼‰ æè¿°äº†ä¸ LSTM ä¸­ sigmoid å’Œ tanh å±‚ä¹‹ä¸€çš„ç¥ç»å…ƒè¾“å‡ºæ¿€æ´»ç›¸å…³çš„è¯¯å·®æ¢¯åº¦å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The majority of this book is focused on building predictive models. Machine learning, however, can be used for many other tasks. In Chapters 10[597] and 11[637] we described two of the major uses of machine learning that go beyond prediction: unsupervised learning and reinforcement learning.",
            "zh": "æœ¬ä¹¦çš„å¤§éƒ¨åˆ†å†…å®¹éƒ½é›†ä¸­åœ¨æ„å»ºé¢„æµ‹æ¨¡å‹ä¸Šã€‚ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ å¯ä»¥ç”¨äºè®¸å¤šå…¶ä»–ä»»åŠ¡ã€‚åœ¨ç¬¬ 10 ç« [597] å’Œ 11 ç« [637]ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªä¸»è¦ç”¨é€”ï¼Œå®ƒä»¬è¶…è¶Šäº†é¢„æµ‹ï¼šæ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "A Markov decision process representation for TwentyTwos, a simplified version of the card game Blackjack.",
            "zh": "TwentyTwosçš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹è¡¨ç¤ºï¼ŒTwentyTwosæ˜¯çº¸ç‰Œæ¸¸æˆBlackjackçš„ç®€åŒ–ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, we should experiment with different metrics to find which one results in the best models for each dataset.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥å°è¯•ä¸åŒçš„æŒ‡æ ‡ï¼Œä»¥æ‰¾åˆ°å“ªä¸ªæŒ‡æ ‡å¯ä»¥äº§ç”Ÿæ¯ä¸ªæ•°æ®é›†çš„æœ€ä½³æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why they are represented by squares to visually distinguish them from the other neurons in the network that do transform their inputs.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä»¬ç”¨æ­£æ–¹å½¢è¡¨ç¤ºï¼Œä»¥ä¾¿åœ¨è§†è§‰ä¸Šå°†å®ƒä»¬ä¸ç½‘ç»œä¸­è½¬æ¢å…¶è¾“å…¥çš„å…¶ä»–ç¥ç»å…ƒåŒºåˆ†å¼€æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The caution comes from the fact that measures of central tendency and variation tend to break down for multimodal data.",
            "zh": "è¿™ç§è°¨æ…æ¥è‡ªäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å¤šæ¨¡æ€æ•°æ®çš„é›†ä¸­è¶‹åŠ¿å’Œå˜åŒ–çš„åº¦é‡å¾€å¾€ä¼šå´©æºƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.1",
            "zh": "è¡¨ 1.1"
        }
    },
    {
        "translation": {
            "en": "The outputs of this model for the training dataset instances are shown in Table 4.15[166] and Figure 4.22(d)[167].",
            "zh": "è¯¥æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†å®ä¾‹çš„è¾“å‡ºå¦‚è¡¨4.15[166]å’Œå›¾4.22ï¼ˆdï¼‰[167]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A greedy local search process moves across a feature subset space like this search in order to find the best feature subset.",
            "zh": "è´ªå©ªçš„æœ¬åœ°æœç´¢è¿‡ç¨‹åœ¨ç‰¹å¾å­é›†ç©ºé—´ä¸­ç§»åŠ¨ï¼Œä¾‹å¦‚æ­¤æœç´¢ï¼Œä»¥æ‰¾åˆ°æœ€ä½³ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.4",
            "zh": "å›¾ 4.4"
        }
    },
    {
        "translation": {
            "en": "Sometimes this is not possible, even after using a kernel function to move the data to a higher-dimensional feature space.",
            "zh": "æœ‰æ—¶è¿™æ˜¯ä¸å¯èƒ½çš„ï¼Œå³ä½¿åœ¨ä½¿ç”¨å†…æ ¸å‡½æ•°å°†æ•°æ®ç§»åŠ¨åˆ°æ›´é«˜ç»´çš„ç‰¹å¾ç©ºé—´ä¹‹åä¹Ÿæ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "distance matrix, 620, 621",
            "zh": "è·ç¦»çŸ©é˜µï¼Œ 620ï¼Œ 621"
        }
    },
    {
        "translation": {
            "en": "Deep learning is a relatively new term that describes research on modern artificial neural networks.",
            "zh": "æ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒæ–°çš„æœ¯è¯­ï¼Œç”¨äºæè¿°å¯¹ç°ä»£äººå·¥ç¥ç»ç½‘ç»œçš„ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "We begin this section by introducing the basic building block of all deep learning models, the artificial neuron (see Section 8.2.1[384]); we then describe how the artificial neurons can be connected together to create an artificial neural network (see Section 8.2.2[388]).",
            "zh": "åœ¨æœ¬èŠ‚çš„å¼€å¤´ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ‰€æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹çš„åŸºæœ¬æ„å»ºå—ï¼Œå³äººå·¥ç¥ç»å…ƒï¼ˆå‚è§ç¬¬ 8.2.1 èŠ‚[384]ï¼‰;ç„¶åï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•å°†äººå·¥ç¥ç»å…ƒè¿æ¥åœ¨ä¸€èµ·ä»¥åˆ›å»ºäººå·¥ç¥ç»ç½‘ç»œï¼ˆå‚è§ç¬¬ 8.2.2 èŠ‚[388]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features used are the overall surface area of the building, the height of the building, the area of the buildingâ€™s roof, and the percentage of wall area in the building that is glazed.",
            "zh": "ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾æ˜¯å»ºç­‘ç‰©çš„æ•´ä½“è¡¨é¢ç§¯ã€å»ºç­‘ç‰©çš„é«˜åº¦ã€å»ºç­‘ç‰©å±‹é¡¶çš„é¢ç§¯ä»¥åŠå»ºç­‘ç‰©ä¸­ç»ç’ƒå¢™é¢ç§¯çš„ç™¾åˆ†æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the second stage of the McCulloch and Pitts model, the result of the weighted sum calculation, z, is then converted into a high or a low activation by comparing the value of z with a manually preset threshold; if z is greater than or equal to the threshold, the artificial neuron outputs a 1 (high activation), and otherwise it outputs a 0 (low activation).",
            "zh": "åœ¨ McCulloch å’Œ Pitts æ¨¡å‹çš„ç¬¬äºŒé˜¶æ®µï¼Œé€šè¿‡å°† z çš„å€¼ä¸æ‰‹åŠ¨é¢„è®¾é˜ˆå€¼è¿›è¡Œæ¯”è¾ƒï¼Œå°†åŠ æƒå’Œè®¡ç®—ç»“æœ z è½¬æ¢ä¸ºé«˜æ¿€æ´»æˆ–ä½æ¿€æ´»;å¦‚æœ z å¤§äºæˆ–ç­‰äºé˜ˆå€¼ï¼Œåˆ™äººå·¥ç¥ç»å…ƒè¾“å‡º 1ï¼ˆé«˜æ¿€æ´»ï¼‰ï¼Œå¦åˆ™è¾“å‡º 0ï¼ˆä½æ¿€æ´»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The successors of the current best feature subset generated in backward sequential selection are the set of feature subsets that can be generated from the current best subset by removing just a single extra feature.",
            "zh": "åœ¨å‘åé¡ºåºé€‰æ‹©ä¸­ç”Ÿæˆçš„å½“å‰æœ€ä½³ç‰¹å¾å­é›†çš„åç»§è€…æ˜¯ä¸€ç»„ç‰¹å¾å­é›†ï¼Œåªéœ€åˆ é™¤ä¸€ä¸ªé¢å¤–çš„ç‰¹å¾å³å¯ä»å½“å‰æœ€ä½³å­é›†ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this simplification, the Bayesian MAP prediction model can be restated as",
            "zh": "ä½¿ç”¨è¿™ç§ç®€åŒ–ï¼Œè´å¶æ–¯ MAP é¢„æµ‹æ¨¡å‹å¯ä»¥é‡è¿°ä¸º"
        }
    },
    {
        "translation": {
            "en": "Table 8.6[431] lists the calculations of âˆ‚â„°/âˆ‚w i,k for each weight in the network for d2.",
            "zh": "è¡¨ 8.6[431] åˆ—å‡ºäº† d2 ç½‘ç»œä¸­æ¯ä¸ªæƒé‡çš„ âˆ‚E/âˆ‚w iï¼Œk è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This illustrates how sensitive the training of a deep neural network can be to a range of hyper-parameters, such as the learning rate and activation function.",
            "zh": "è¿™è¯´æ˜äº†æ·±åº¦ç¥ç»ç½‘ç»œçš„è®­ç»ƒå¯¹ä¸€ç³»åˆ—è¶…å‚æ•°ï¼ˆä¾‹å¦‚å­¦ä¹ é€Ÿç‡å’Œæ¿€æ´»å‡½æ•°ï¼‰çš„æ•æ„Ÿæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "equation of a line, 313, 385",
            "zh": "ç›´çº¿æ–¹ç¨‹ï¼Œ313,385"
        }
    },
    {
        "translation": {
            "en": "This trade-off between the number of descriptive features and the density of the instances in the feature space is known as the curse of dimensionality.",
            "zh": "æè¿°æ€§ç‰¹å¾çš„æ•°é‡ä¸ç‰¹å¾ç©ºé—´ä¸­å®ä¾‹çš„å¯†åº¦ä¹‹é—´çš„è¿™ç§æƒè¡¡ç§°ä¸ºç»´åº¦è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chebyshev distance, 186",
            "zh": "åˆ‡æ¯”é›ªå¤«è·ç¦»ï¼Œ186"
        }
    },
    {
        "translation": {
            "en": "However, the action-value function given in Equation (11.9)[643] can be expressed in terms of the components of an MDP to do just this.",
            "zh": "ç„¶è€Œï¼Œç­‰å¼ï¼ˆ11.9ï¼‰[643]ä¸­ç»™å‡ºçš„åŠ¨ä½œ-å€¼å‡½æ•°å¯ä»¥ç”¨MDPçš„åˆ†é‡æ¥è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "NEWSLETTER: Did the user sign up for the weekly newsletter?",
            "zh": "æ—¶äº‹é€šè®¯ï¼šç”¨æˆ·æ˜¯å¦æ³¨å†Œäº†æ¯å‘¨æ—¶äº‹é€šè®¯ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This is one reason that other approaches are often favored over logistic regression for predicting categorical targets with many levels.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå…¶ä»–æ–¹æ³•åœ¨é¢„æµ‹å…·æœ‰å¤šä¸ªå±‚æ¬¡çš„åˆ†ç±»ç›®æ ‡æ—¶é€šå¸¸æ¯”é€»è¾‘å›å½’æ›´å—é’ççš„åŸå› ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these contexts both the doctor and the patient would want the system to provide some explanation of how it arrives at the predictions it makes.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼ŒåŒ»ç”Ÿå’Œæ‚£è€…éƒ½å¸Œæœ›ç³»ç»Ÿæä¾›ä¸€äº›è§£é‡Šï¼Œè¯´æ˜å®ƒæ˜¯å¦‚ä½•å¾—å‡ºé¢„æµ‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE, % SOFT TISSUE, and FRAUD FLAG all have cardinality less than 10, which is unusual in a dataset of 500 instances.",
            "zh": "SOFT TISSUEã€% SOFT TISSUE å’Œ FRAUD FLAG çš„åŸºæ•°éƒ½å°äº 10ï¼Œè¿™åœ¨åŒ…å« 500 ä¸ªå®ä¾‹çš„æ•°æ®é›†ä¸­æ˜¯ä¸å¯»å¸¸çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the drug dosage predictions given in Table 9.20[576], the mean absolute error is 0.975 for the regression model and 1.750 for the nearest neighbor model.",
            "zh": "å¯¹äºè¡¨9.20[576]ä¸­ç»™å‡ºçš„è¯ç‰©å‰‚é‡é¢„æµ‹ï¼Œå›å½’æ¨¡å‹çš„å¹³å‡ç»å¯¹è¯¯å·®ä¸º0.975ï¼Œæœ€è¿‘é‚»æ¨¡å‹çš„å¹³å‡ç»å¯¹è¯¯å·®ä¸º1.750ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the distribution used to generate the samples for a Monte Carlo method is a Markov chain, then the specific algorithms we use to implement this approach come from a family known as Markov chain Monte Carlo (MCMC) algorithms.",
            "zh": "å¦‚æœç”¨äºç”Ÿæˆè’™ç‰¹å¡æ´›æ–¹æ³•æ ·æœ¬çš„åˆ†å¸ƒæ˜¯é©¬å°”å¯å¤«é“¾ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç”¨äºå®ç°æ­¤æ–¹æ³•çš„ç‰¹å®šç®—æ³•æ¥è‡ªç§°ä¸ºé©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´› ï¼ˆMCMCï¼‰ ç®—æ³•çš„å®¶æ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The different question sequences that can follow in a game of Guess Who beginning with the question Is it a man?",
            "zh": "çŒœçŒœè°æ¸¸æˆä¸­å¯ä»¥éµå¾ªçš„ä¸åŒé—®é¢˜åºåˆ—ï¼Œä»é—®é¢˜å¼€å§‹ï¼šæ˜¯ç”·äººå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The big idea to take from this example to predictive data analytics projects is that when we evaluate predictive models, we must ensure that the evaluation experiments are designed so that they give an accurate estimate of how the models will perform when deployed. The most important part of the design of an evaluation experiment for a predictive model is ensuring that the data used to evaluate the model is not the same as the data used to train the model.",
            "zh": "ä»è¿™ä¸ªä¾‹å­ä¸­å¯ä»¥å€Ÿé‰´åˆ°é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®çš„ä¸»è¦æƒ³æ³•æ˜¯ï¼Œå½“æˆ‘ä»¬è¯„ä¼°é¢„æµ‹æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿è¯„ä¼°å®éªŒçš„è®¾è®¡èƒ½å¤Ÿå‡†ç¡®ä¼°è®¡æ¨¡å‹åœ¨éƒ¨ç½²æ—¶çš„è¡¨ç°ã€‚é¢„æµ‹æ¨¡å‹è¯„ä¼°å®éªŒè®¾è®¡ä¸­æœ€é‡è¦çš„éƒ¨åˆ†æ˜¯ç¡®ä¿ç”¨äºè¯„ä¼°æ¨¡å‹çš„æ•°æ®ä¸ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•°æ®ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "2.6â€…â€…â€…Further Reading",
            "zh": "2.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "tanh, 387, 461",
            "zh": "è°­ï¼Œ 387ï¼Œ 461"
        }
    },
    {
        "translation": {
            "en": "MITOSES",
            "zh": "æœ‰ä¸åˆ†è£‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„w1 to ğ•„wr are r different one-versus-all logistic regression models, and w1 to wr are r different sets of weights. To combine the outputs of these different models, we normalize their results as follows:",
            "zh": "å…¶ä¸­ Mw1 åˆ° Mwr æ˜¯ r ä¸ªä¸åŒçš„ä¸€å¯¹å¤šé€»è¾‘å›å½’æ¨¡å‹ï¼Œw1 åˆ° wr æ˜¯ r ä¸ªä¸åŒçš„æƒé‡é›†ã€‚ä¸ºäº†ç»“åˆè¿™äº›ä¸åŒæ¨¡å‹çš„è¾“å‡ºï¼Œæˆ‘ä»¬å°†å…¶ç»“æœå½’ä¸€åŒ–å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 8.4",
            "zh": "å›¾ 8.4"
        }
    },
    {
        "translation": {
            "en": "Instead of explicitly handling problems like noise within the data in an ABT, some data preparation techniques change the way data is represented just to make it more compatible with certain machine learning algorithms.",
            "zh": "ä¸€äº›æ•°æ®å‡†å¤‡æŠ€æœ¯ä¸æ˜¯åœ¨ ABT ä¸­æ˜¾å¼å¤„ç†æ•°æ®ä¸­çš„å™ªå£°ç­‰é—®é¢˜ï¼Œè€Œæ˜¯æ”¹å˜æ•°æ®çš„è¡¨ç¤ºæ–¹å¼ï¼Œä½¿å…¶ä¸æŸäº›æœºå™¨å­¦ä¹ ç®—æ³•æ›´å…¼å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even these algorithms, however, do eventually succumb to the curse as the dimensionality grows.",
            "zh": "ç„¶è€Œï¼Œå³ä½¿æ˜¯è¿™äº›ç®—æ³•ï¼Œéšç€ç»´åº¦çš„å¢é•¿ï¼Œæœ€ç»ˆä¹Ÿä¼šå±ˆæœäºè¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, an exponential increase is required in the size of the dataset as each new descriptive feature is added to ensure that for any conditional probability, there are enough instances in the training dataset matching the conditions so that the resulting probability is reasonable.",
            "zh": "å› æ­¤ï¼Œå½“æ·»åŠ æ¯ä¸ªæ–°çš„æè¿°æ€§ç‰¹å¾æ—¶ï¼Œæ•°æ®é›†çš„å¤§å°éœ€è¦å‘ˆæŒ‡æ•°å¢é•¿ï¼Œä»¥ç¡®ä¿å¯¹äºä»»ä½•æ¡ä»¶æ¦‚ç‡ï¼Œè®­ç»ƒæ•°æ®é›†ä¸­æœ‰è¶³å¤Ÿçš„å®ä¾‹ä¸æ¡ä»¶åŒ¹é…ï¼Œä»¥ä¾¿ç»“æœæ¦‚ç‡æ˜¯åˆç†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„(q) is the prediction made by the model for the query q, levels(t) is the set of levels in the domain of the target feature t, and Gibbs(t = l,q) returns the probability for the event t = l given the evidence specified in the query q using Gibbs sampling.",
            "zh": "å…¶ä¸­ Mï¼ˆqï¼‰ æ˜¯æ¨¡å‹å¯¹æŸ¥è¯¢ q æ‰€åšçš„é¢„æµ‹ï¼Œlevelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡ç‰¹å¾ t åŸŸä¸­çš„æ°´å¹³é›†ï¼ŒGibbsï¼ˆt = lï¼Œqï¼‰ è¿”å›äº‹ä»¶ t = l çš„æ¦‚ç‡ï¼Œç»™å®šæŸ¥è¯¢ q ä¸­ä½¿ç”¨ Gibbs é‡‡æ ·æŒ‡å®šçš„è¯æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The maturity of regression-based approaches means that they are easily accepted in other disciplines (e.g., biological, physical, and social sciences) and that there is a range of techniques that allow a degree of analysis of regression models beyond what is possible for other approaches.",
            "zh": "åŸºäºå›å½’çš„æ–¹æ³•çš„æˆç†Ÿæ„å‘³ç€å®ƒä»¬å¾ˆå®¹æ˜“è¢«å…¶ä»–å­¦ç§‘ï¼ˆä¾‹å¦‚ï¼Œç”Ÿç‰©ã€ç‰©ç†å’Œç¤¾ä¼šç§‘å­¦ï¼‰æ‰€æ¥å—ï¼Œå¹¶ä¸”æœ‰ä¸€ç³»åˆ—æŠ€æœ¯å¯ä»¥å¯¹å›å½’æ¨¡å‹è¿›è¡Œä¸€å®šç¨‹åº¦çš„åˆ†æï¼Œè¿™è¶…å‡ºäº†å…¶ä»–æ–¹æ³•æ‰€èƒ½è¾¾åˆ°çš„æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.38â€…â€…â€…A simple RNN model unrolled through time (in this instance, three time-steps).",
            "zh": "8.38 ä¸€ä¸ªç®€å•çš„RNNæ¨¡å‹åœ¨æ—¶é—´ä¸Šå±•å¼€ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºä¸‰ä¸ªæ—¶é—´æ­¥é•¿ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure we have set k = 3, and this modification has resulted in the no region in the top right corner of the feature space disappearing.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº† k = 3ï¼Œæ­¤ä¿®æ”¹å¯¼è‡´ç‰¹å¾ç©ºé—´å³ä¸Šè§’çš„ no åŒºåŸŸæ¶ˆå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Application prediction] A model could be built to predict, at the point of application, the likelihood that a policy someone has applied for will ultimately result in a fraudulent claim. The company could run this model every time a new application is made and reject those applications that are predicted likely to result in a fraudulent claim. The company would therefore reduce the number of fraudulent claims and reduce the amount of money they would lose to these claims.",
            "zh": "[åº”ç”¨é¢„æµ‹]å¯ä»¥å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ï¼Œåœ¨ç”³è¯·æ—¶ï¼ŒæŸäººç”³è¯·çš„ä¿å•æœ€ç»ˆå¯¼è‡´æ¬ºè¯ˆæ€§ç´¢èµ”çš„å¯èƒ½æ€§ã€‚è¯¥å…¬å¸å¯ä»¥åœ¨æ¯æ¬¡æå‡ºæ–°ç”³è¯·æ—¶è¿è¡Œæ­¤æ¨¡å‹ï¼Œå¹¶æ‹’ç»é‚£äº›é¢„è®¡å¯èƒ½å¯¼è‡´æ¬ºè¯ˆæ€§ç´¢èµ”çš„ç”³è¯·ã€‚å› æ­¤ï¼Œè¯¥å…¬å¸å°†å‡å°‘æ¬ºè¯ˆæ€§ç´¢èµ”çš„æ•°é‡ï¼Œå¹¶å‡å°‘ä»–ä»¬å› è¿™äº›ç´¢èµ”è€ŒæŸå¤±çš„é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The INCOME feature stood out as unusual with only 10 distinct values (the histogram for this feature confirmed this; see Figure 12.2(a)[695]).",
            "zh": "INCOME ç‰¹å¾éå¸¸ä¸å¯»å¸¸ï¼Œåªæœ‰ 10 ä¸ªä¸åŒçš„å€¼ï¼ˆè¯¥ç‰¹å¾çš„ç›´æ–¹å›¾è¯å®äº†è¿™ä¸€ç‚¹;å‚è§å›¾ 12.2ï¼ˆaï¼‰[695]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(short) (deep)â€) is designed to be a one-semester machine learning course with a focus on giving students a deep understanding of two approaches to machine learning, along with an understanding of the correct methodology to use when evaluating a machine learning model.",
            "zh": "ï¼ˆçŸ­ï¼‰ï¼ˆdeepï¼‰â€œï¼‰ è¢«è®¾è®¡ä¸ºä¸€é—¨ä¸ºæœŸä¸€å­¦æœŸçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œé‡ç‚¹æ˜¯è®©å­¦ç”Ÿæ·±å…¥äº†è§£æœºå™¨å­¦ä¹ çš„ä¸¤ç§æ–¹æ³•ï¼Œä»¥åŠäº†è§£åœ¨è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ä½¿ç”¨çš„æ­£ç¡®æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is a particularly pertinent question, considering that the adoption of the term deep learning in the mid-2000s to describe modern neural networks was to emphasize that these modern networks are deeper than most of the networks that were developed between the 1940s and the early 2000s.",
            "zh": "è€ƒè™‘åˆ°åœ¨ 2000 å¹´ä»£ä¸­æœŸé‡‡ç”¨æ·±åº¦å­¦ä¹ ä¸€è¯æ¥æè¿°ç°ä»£ç¥ç»ç½‘ç»œæ˜¯ä¸ºäº†å¼ºè°ƒè¿™äº›ç°ä»£ç½‘ç»œæ¯” 1940 å¹´ä»£å’Œ 2000 å¹´ä»£åˆä¹‹é—´å¼€å‘çš„å¤§å¤šæ•°ç½‘ç»œæ›´æ·±å…¥ï¼Œè¿™æ˜¯ä¸€ä¸ªç‰¹åˆ«ç›¸å…³çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Deployment: Machine learning models are built to serve a purpose within an organization, and the last phase of CRISP-DM covers all the work that must be done to successfully integrate a machine learning model into the processes within an organization.",
            "zh": "éƒ¨ç½²ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹æ˜¯ä¸ºäº†åœ¨ç»„ç»‡å†…æœåŠ¡äºæŸä¸ªç›®çš„è€Œæ„å»ºçš„ï¼ŒCRISP-DM çš„æœ€åé˜¶æ®µæ¶µç›–äº†å°†æœºå™¨å­¦ä¹ æ¨¡å‹æˆåŠŸé›†æˆåˆ°ç»„ç»‡å†…æµç¨‹ä¸­å¿…é¡»å®Œæˆçš„æ‰€æœ‰å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "The test statistic we calculate is called the t-statistic.",
            "zh": "æˆ‘ä»¬è®¡ç®—çš„æ£€éªŒç»Ÿè®¡é‡ç§°ä¸º t ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A wide range of standard kernel functions can be used with support vector machines. Some popular options are",
            "zh": "å„ç§æ ‡å‡†å†…æ ¸å‡½æ•°å¯ç”¨äºæ”¯æŒå‘é‡æœºã€‚ä¸€äº›æµè¡Œçš„é€‰é¡¹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "multinomial logistic regression, 357, 376",
            "zh": "å¤šé¡¹å¼é€»è¾‘å›å½’ï¼Œ 357ï¼Œ 376"
        }
    },
    {
        "translation": {
            "en": "A.4.2â€ƒHistograms",
            "zh": "A.4.2 ç›´æ–¹å›¾"
        }
    },
    {
        "translation": {
            "en": "The other cells in these columns are populated with similar calculations.",
            "zh": "è¿™äº›åˆ—ä¸­çš„å…¶ä»–å•å…ƒæ ¼å¡«å……äº†ç±»ä¼¼çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.4",
            "zh": "å›¾ A.4"
        }
    },
    {
        "translation": {
            "en": "Examining the arrows in the network shows that the input to the processing neurons can be any of the following: an external input presented to the network via the sensing neurons, the output activation of another processing neuron in the network, or a dummy input that is always set to 1 (the input from a black circle).",
            "zh": "æ£€æŸ¥ç½‘ç»œä¸­çš„ç®­å¤´è¡¨æ˜ï¼Œå¤„ç†ç¥ç»å…ƒçš„è¾“å…¥å¯ä»¥æ˜¯ä»¥ä¸‹ä»»ä½•ä¸€ç§ï¼šé€šè¿‡æ„ŸçŸ¥ç¥ç»å…ƒå‘ˆç°ç»™ç½‘ç»œçš„å¤–éƒ¨è¾“å…¥ï¼Œç½‘ç»œä¸­å¦ä¸€ä¸ªå¤„ç†ç¥ç»å…ƒçš„è¾“å‡ºæ¿€æ´»ï¼Œæˆ–å§‹ç»ˆè®¾ç½®ä¸º 1 çš„è™šæ‹Ÿè¾“å…¥ï¼ˆæ¥è‡ªé»‘è‰²åœ†åœˆçš„è¾“å…¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These smoother curves are more representative of the kind of ROC curves we typically encounter in practice.",
            "zh": "è¿™äº›æ›´å¹³æ»‘çš„æ›²çº¿æ›´èƒ½ä»£è¡¨æˆ‘ä»¬åœ¨å®è·µä¸­é€šå¸¸é‡åˆ°çš„ ROC æ›²çº¿ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "32. Obviously we must verify that the prediction made was correct before adding a new instance to the dataset.",
            "zh": "32. æ˜¾ç„¶ï¼Œåœ¨å‘æ•°æ®é›†æ·»åŠ æ–°å®ä¾‹ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»éªŒè¯æ‰€åšçš„é¢„æµ‹æ˜¯å¦æ­£ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability mass function, 246, 758",
            "zh": "æ¦‚ç‡è´¨é‡å‡½æ•°ï¼Œ 246ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "So, for example, the new value of w[0] is calculated as the old value plus the learning rate times the sum of the errorDelta(,w[0]) contributions to give âˆ’ 2.9465 + 0.02 Ã— 2.7031 = âˆ’2.8924.",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œw[0] çš„æ–°å€¼è®¡ç®—ä¸ºæ—§å€¼åŠ ä¸Šå­¦ä¹ ç‡ä¹˜ä»¥ errorDeltaï¼ˆï¼Œw[0]ï¼‰ è´¡çŒ®ä¹‹å’Œï¼Œå¾—å‡º âˆ’ 2.9465 + 0.02 Ã— 2.7031 = âˆ’2.8924ã€‚"
        }
    },
    {
        "translation": {
            "en": "The remaining entropy for the UNKNOWN SENDER feature is",
            "zh": "UNKNOWN SENDER ç‰¹å¾çš„å‰©ä½™ç†µä¸º"
        }
    },
    {
        "translation": {
            "en": "6.18â€…â€…â€…Some socioeconomic data for a set of countries, and a version of the data after equal-frequency binning has been applied.",
            "zh": "6.18 ä¸€ç»„å›½å®¶çš„ä¸€äº›ç¤¾ä¼šç»æµæ•°æ®ï¼Œä»¥åŠåº”ç”¨äº†ç­‰é¢‘åˆ†æ¡£åçš„æ•°æ®ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. There are approaches to formally measuring the relationship between a pair of categorical features (for example, the Ï‡2 test) and for measuring the relationship between a categorical feature and a continuous feature (for example, the ANOVA test). We do not cover these in this book, however, and readers are directed to the further reading section at the end of this chapter for information on these approaches.",
            "zh": "9. æœ‰ä¸€äº›æ–¹æ³•å¯ä»¥æ­£å¼æµ‹é‡ä¸€å¯¹åˆ†ç±»ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼ˆä¾‹å¦‚ï¼ŒÏ‡2æ£€éªŒï¼‰å’Œæµ‹é‡åˆ†ç±»ç‰¹å¾ä¸è¿ç»­ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼ˆä¾‹å¦‚ï¼Œæ–¹å·®åˆ†ææ£€éªŒï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­æ²¡æœ‰æ¶‰åŠè¿™äº›ï¼Œè¯»è€…å¯ä»¥åˆ°æœ¬ç« æœ«å°¾çš„è¿›ä¸€æ­¥é˜…è¯»éƒ¨åˆ†ï¼Œä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "When var(W) = 1/nin then nin var(W) = 1 and the variance of z for the neuron is solely dependent on the variance of the inputs, which if standardized will have a variance of 1.",
            "zh": "å½“ varï¼ˆWï¼‰ = 1/nin æ—¶ï¼Œåˆ™ nin varï¼ˆWï¼‰ = 1ï¼Œç¥ç»å…ƒçš„ z æ–¹å·®å®Œå…¨å–å†³äºè¾“å…¥çš„æ–¹å·®ï¼Œå¦‚æœæ ‡å‡†åŒ–ï¼Œåˆ™æ–¹å·®ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conor knows the expected reward for ordering chicken is high compared with the expected reward for ordering the other unknown items (which he assumes to be low), and so this policy will return a consistently high reward.",
            "zh": "Conor çŸ¥é“ï¼Œä¸è®¢è´­å…¶ä»–æœªçŸ¥ç‰©å“çš„é¢„æœŸå¥–åŠ±ç›¸æ¯”ï¼Œè®¢è´­é¸¡è‚‰çš„é¢„æœŸå¥–åŠ±å¾ˆé«˜ï¼ˆä»–è®¤ä¸ºå¥–åŠ±å¾ˆä½ï¼‰ï¼Œå› æ­¤æ­¤ç­–ç•¥å°†è¿”å›å§‹ç»ˆå¦‚ä¸€çš„é«˜å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.3",
            "zh": "è¡¨ 7.3"
        }
    },
    {
        "translation": {
            "en": "auto-encoder, 624, 624, 629, 733",
            "zh": "è‡ªåŠ¨ç¼–ç å™¨ï¼Œ 624ï¼Œ 624ï¼Œ 629ï¼Œ 733"
        }
    },
    {
        "translation": {
            "en": "Vectors are often treated as special cases of matrices. For example, a column vector can be thought of as a matrix with just one column, and a row vector can be thought of as a matrix with a single row.",
            "zh": "å‘é‡é€šå¸¸è¢«è§†ä¸ºçŸ©é˜µçš„ç‰¹ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†åˆ—å‘é‡è§†ä¸ºåªæœ‰ä¸€åˆ—çš„çŸ©é˜µï¼Œè€Œè¡Œå‘é‡å¯ä»¥å°†å…¶è§†ä¸ºå…·æœ‰å•è¡Œçš„çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, imagine our data followed a normal distribution: then the bins covering the intervals of the feature range at the tails of the normal distribution will have very few instances, and the bins covering the intervals of the feature range near the mean will contain a lot of instances.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„æ•°æ®éµå¾ªæ­£æ€åˆ†å¸ƒï¼šé‚£ä¹ˆåœ¨æ­£æ€åˆ†å¸ƒçš„å°¾éƒ¨è¦†ç›–ç‰¹å¾èŒƒå›´é—´éš”çš„æ¡æŸ±å°†å…·æœ‰å¾ˆå°‘çš„å®ä¾‹ï¼Œè€Œè¦†ç›–æ¥è¿‘å‡å€¼çš„ç‰¹å¾èŒƒå›´åŒºé—´çš„æ¡æŸ±å°†åŒ…å«å¤§é‡å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The defining characteristic of a recurrent neural network is that it contains feedback connections, and so, unlike a feedforward network, which is a directed acyclic graph, a recurrent neural network is a directed cyclic graph.",
            "zh": "é€’å½’ç¥ç»ç½‘ç»œçš„å®šä¹‰ç‰¹å¾æ˜¯å®ƒåŒ…å«åé¦ˆè¿æ¥ï¼Œå› æ­¤ï¼Œä¸å‰é¦ˆç½‘ç»œä¸åŒï¼Œå‰é¦ˆç½‘ç»œæ˜¯æœ‰å‘æ— ç¯å›¾ï¼Œé€’å½’ç¥ç»ç½‘ç»œæ˜¯æœ‰å‘å¾ªç¯å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A simple bicycle demand predictions dataset and the workings of the first three iterations of training an ensemble model using boosting to predict RENTALS given TEMP.",
            "zh": "ä¸€ä¸ªç®€å•çš„è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®é›†å’Œè®­ç»ƒé›†æˆæ¨¡å‹çš„å‰ä¸‰ä¸ªè¿­ä»£çš„å·¥ä½œåŸç†ï¼Œä½¿ç”¨æå‡æ¥é¢„æµ‹ç»™å®šæ¸©åº¦çš„ç§Ÿèµã€‚"
        }
    },
    {
        "translation": {
            "en": "We can say more formally that acceleration is, in fact, the derivative of speed with respect to time.",
            "zh": "æˆ‘ä»¬å¯ä»¥æ›´æ­£å¼åœ°è¯´ï¼ŒåŠ é€Ÿåº¦å®é™…ä¸Šæ˜¯é€Ÿåº¦ç›¸å¯¹äºæ—¶é—´çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that on the left-hand side of the graph (for large negative values of x), the rate of change has a high negative value, while on the right-hand side of the graph (for large positive values of x), the rate of change has a large positive value.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å›¾å½¢çš„å·¦ä¾§ï¼ˆå¯¹äº x çš„å¤§è´Ÿå€¼ï¼‰ï¼Œå˜åŒ–ç‡å…·æœ‰å¾ˆé«˜çš„è´Ÿå€¼ï¼Œè€Œåœ¨å›¾å½¢çš„å³ä¾§ï¼ˆå¯¹äº x çš„å¤§æ­£å€¼ï¼‰ï¼Œå˜åŒ–ç‡å…·æœ‰è¾ƒå¤§çš„æ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The learning in Q-learning takes place when an entry in the action-value table is updated after an action has taken place using Equation (13)[658] at Line 13.20 The intuition behind this update is that the value of taking a specific action in a specific state, Q(st,at), should increase if that action leads to an immediate positive reward and/or it takes the agent to a state from which the agent can expect to receive a positive future return.",
            "zh": "Q-learningä¸­çš„å­¦ä¹ å‘ç”Ÿåœ¨æ“ä½œå‘ç”Ÿåï¼Œä½¿ç”¨å…¬å¼ï¼ˆ13ï¼‰[658]åœ¨ç¬¬13.20è¡Œæ›´æ–°åŠ¨ä½œå€¼è¡¨ä¸­çš„æ¡ç›®æ—¶ï¼Œæ­¤æ›´æ–°èƒŒåçš„ç›´è§‰æ˜¯ï¼Œå¦‚æœè¯¥åŠ¨ä½œå¯¼è‡´ç«‹å³çš„æ­£å¥–åŠ±å’Œ/æˆ–å°†æ™ºèƒ½ä½“å¸¦åˆ°æ™ºèƒ½ä½“å¯ä»¥é¢„æœŸçš„çŠ¶æ€ï¼Œåˆ™åœ¨ç‰¹å®šçŠ¶æ€ä¸‹é‡‡å–ç‰¹å®šæ“ä½œçš„ä»·å€¼Qï¼ˆstï¼Œatï¼‰åº”è¯¥å¢åŠ ä»¥è·å¾—ç§¯æçš„æœªæ¥å›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, controlling the size of weight updates in order to stabilize convergence during training is one of the reasons why the learning rate hyper-parameter Î± is included in the weight update rules.19 In addition, having a large variance on the weight updates applied to input connections can result in the networkâ€™s having relatively large weights for some features.",
            "zh": "äº‹å®ä¸Šï¼Œæ§åˆ¶æƒé‡æ›´æ–°çš„å¤§å°ä»¥åœ¨è®­ç»ƒæœŸé—´ç¨³å®šæ”¶æ•›æ˜¯å°†å­¦ä¹ ç‡è¶…å‚æ•°Î±åŒ…å«åœ¨æƒé‡æ›´æ–°è§„åˆ™ä¸­çš„åŸå› ä¹‹ä¸€ã€‚19 æ­¤å¤–ï¼Œåº”ç”¨äºè¾“å…¥è¿æ¥çš„æƒé‡æ›´æ–°å­˜åœ¨è¾ƒå¤§å·®å¼‚å¯èƒ½å¯¼è‡´ç½‘ç»œå¯¹æŸäº›ç‰¹å¾å…·æœ‰ç›¸å¯¹è¾ƒå¤§çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the softmax function returns a normalized set of positive values across the layer allows us to interpret the activation of each neuron in the layer as a probability.",
            "zh": "softmax å‡½æ•°åœ¨æ•´ä¸ªå±‚ä¸­è¿”å›ä¸€ç»„å½’ä¸€åŒ–çš„æ­£å€¼ï¼Œè¿™ä¸€äº‹å®å…è®¸æˆ‘ä»¬å°†å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»è§£é‡Šä¸ºæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.7â€…â€…â€…Partition sets (Part.), entropy, Gini index, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "4.7 è¡¨4.3[136]ä¸­æ•°æ®é›†çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€åŸºå°¼æŒ‡æ•°ã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For instance, the rectangle on the very left represents the feature subset that includes no features at all, and the rectangle at the top of the second column from the left represents the feature subset including just the feature X.",
            "zh": "ä¾‹å¦‚ï¼Œæœ€å·¦è¾¹çš„çŸ©å½¢è¡¨ç¤ºå®Œå…¨ä¸åŒ…å«è¦ç´ çš„ç‰¹å¾å­é›†ï¼Œå·¦èµ·ç¬¬äºŒåˆ—é¡¶éƒ¨çš„çŸ©å½¢è¡¨ç¤ºä»…åŒ…å«è¦ç´  X çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "prediction speed, 738",
            "zh": "é¢„æµ‹é€Ÿåº¦ï¼Œ738"
        }
    },
    {
        "translation": {
            "en": "In the second part of this chapter we move our attention to the data structures that are required to build predictive analytics models, and in particular the analytics base table (ABT).",
            "zh": "åœ¨æœ¬ç« çš„ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ³¨æ„åŠ›è½¬ç§»åˆ°æ„å»ºé¢„æµ‹åˆ†ææ¨¡å‹æ‰€éœ€çš„æ•°æ®ç»“æ„ä¸Šï¼Œç‰¹åˆ«æ˜¯åˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "diagnosis, 4",
            "zh": "è¯Šæ–­ï¼Œ 4"
        }
    },
    {
        "translation": {
            "en": "Although it is useful to visually compare the performance of different models using an ROC curve, it is often preferable to have a single numeric performance measure with which models can be assessed.",
            "zh": "å°½ç®¡ä½¿ç”¨ ROC æ›²çº¿ç›´è§‚åœ°æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†é€šå¸¸æœ€å¥½ä½¿ç”¨å•ä¸€çš„æ•°å€¼æ€§èƒ½åº¦é‡æ¥è¯„ä¼°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general we use the sample statistics, which we have already calculated, as estimates for the population parameters.",
            "zh": "é€šå¸¸ï¼Œæˆ‘ä»¬ä½¿ç”¨å·²ç»è®¡ç®—è¿‡çš„æ ·æœ¬ç»Ÿè®¡é‡ä½œä¸ºæ€»ä½“å‚æ•°çš„ä¼°è®¡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.10",
            "zh": "è¡¨ 8.10"
        }
    },
    {
        "translation": {
            "en": "This ensures that the output vector from this layer oâ€¡t is the same size as H and so is the correct dimensions for the elementwise product with the oâ€ t vector, and also that the vector resulting from this operation will have a size of H. This is important because it ensures that htâˆ’1 and ht are the same size.",
            "zh": "è¿™ç¡®ä¿äº†è¯¥å±‚ oâ€¡t çš„è¾“å‡ºå‘é‡ä¸ H çš„å¤§å°ç›¸åŒï¼Œå› æ­¤å…·æœ‰ oâ€ t å‘é‡çš„é€å…ƒä¹˜ç§¯çš„å°ºå¯¸ä¹Ÿç›¸åŒï¼Œå¹¶ä¸”æ­¤æ“ä½œäº§ç”Ÿçš„å‘é‡çš„å¤§å°ä¸º Hã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒç¡®ä¿ htâˆ’1 å’Œ ht çš„å¤§å°ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "While the overall classification accuracy for this set of predictions is 80%,20 the individual recall scores for each target level show that the performance of the model is not the same for all four levels: the accuracy on the ficulneus and fructosus levels is quite high (85.714% and 90.909% respectively), while for the durionis and pseudoficulneus levels, the accuracy is considerably lower (71.429% and 60.000%).",
            "zh": "è™½ç„¶è¿™ç»„é¢„æµ‹çš„æ€»ä½“åˆ†ç±»å‡†ç¡®ç‡ä¸º 80%ï¼Œ20 ä½†æ¯ä¸ªç›®æ ‡æ°´å¹³çš„å•ç‹¬å¬å›åˆ†æ•°è¡¨æ˜ï¼Œæ¨¡å‹åœ¨æ‰€æœ‰å››ä¸ªæ°´å¹³ä¸Šçš„æ€§èƒ½å¹¶ä¸ç›¸åŒï¼šficulneus å’Œ fructosus æ°´å¹³çš„å‡†ç¡®ç‡ç›¸å½“é«˜ï¼ˆåˆ†åˆ«ä¸º 85.714% å’Œ 90.909%ï¼‰ï¼Œè€Œå¯¹äº durionis å’Œ pseudoficulneus æ°´å¹³ï¼Œ å‡†ç¡®ç‡è¦ä½å¾—å¤šï¼ˆ71.429% å’Œ 60.000%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The definition of best is important here.",
            "zh": "åœ¨è¿™é‡Œï¼Œæœ€å¥½çš„å®šä¹‰å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) On the basis of this behavior sequence, calculate a transition matrix that gives the probability of moving between all the four states.",
            "zh": "ï¼ˆaï¼‰ åœ¨æ­¤è¡Œä¸ºåºåˆ—çš„åŸºç¡€ä¸Šï¼Œè®¡ç®—ä¸€ä¸ªè½¬ç§»çŸ©é˜µï¼Œè¯¥çŸ©é˜µç»™å‡ºåœ¨æ‰€æœ‰å››ç§çŠ¶æ€ä¹‹é—´ç§»åŠ¨çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The density calculation for the TRAINING EXPENSES feature from Table A.1[750] using (a) ten 200-unit intervals and (b) four 500-unit intervals.",
            "zh": "ä½¿ç”¨ ï¼ˆaï¼‰ 10 ä¸ª 200 å•ä½çš„é—´éš”å’Œ ï¼ˆbï¼‰ 4 ä¸ª 500 å•ä½çš„é—´éš”è®¡ç®—è¡¨ A.1[750] ä¸­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„å¯†åº¦è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.1",
            "zh": "è¡¨ 10.1"
        }
    },
    {
        "translation": {
            "en": "2. A convicted criminal who reoffends after release is known as a recidivist. The following table lists a dataset that describes prisoners released on parole and whether they reoffended within two years of release.37",
            "zh": "2. è¢«å®šç½ªçš„ç½ªçŠ¯åœ¨é‡Šæ”¾åå†æ¬¡çŠ¯ç½ªï¼Œç§°ä¸ºç´¯çŠ¯ã€‚ä¸‹è¡¨åˆ—å‡ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æè¿°äº†å‡é‡Šçš„å›šçŠ¯ä»¥åŠä»–ä»¬åœ¨é‡Šæ”¾åä¸¤å¹´å†…æ˜¯å¦å†æ¬¡çŠ¯ç½ª37ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the decision boundaries learned by each algorithm are characteristic of that algorithm.",
            "zh": "é¦–å…ˆï¼Œæ¯ä¸ªç®—æ³•å­¦ä¹ çš„å†³ç­–è¾¹ç•Œæ˜¯è¯¥ç®—æ³•çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imputation replaces missing feature values with a plausible estimated value based on the feature values that are present. The most common approach to imputation is to replace missing values for a feature with a measure of the central tendency of that feature. For continuous features, the mean or median is most commonly used, and for categorical features, the mode is most commonly used.",
            "zh": "æ’è¡¥å°†ç¼ºå¤±çš„ç‰¹å¾å€¼æ›¿æ¢ä¸ºåŸºäºå­˜åœ¨çš„ç‰¹å¾å€¼çš„åˆç†ä¼°è®¡å€¼ã€‚æœ€å¸¸è§çš„æ’è¡¥æ–¹æ³•æ˜¯å°†ç‰¹å¾çš„ç¼ºå¤±å€¼æ›¿æ¢ä¸ºç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿çš„åº¦é‡ã€‚å¯¹äºè¿ç»­ç‰¹å¾ï¼Œæœ€å¸¸ä½¿ç”¨å‡å€¼æˆ–ä¸­ä½æ•°ï¼Œå¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œæœ€å¸¸ä½¿ç”¨ä¼—æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important, however, to know if a measure is a metric or an index, as there are some similarity-based techniques that strictly require measures of similarity to be metrics.",
            "zh": "ä½†æ˜¯ï¼Œé‡è¦çš„æ˜¯è¦çŸ¥é“åº¦é‡å€¼æ˜¯åº¦é‡å€¼è¿˜æ˜¯ç´¢å¼•ï¼Œå› ä¸ºæœ‰ä¸€äº›åŸºäºç›¸ä¼¼æ€§çš„æŠ€æœ¯ä¸¥æ ¼è¦æ±‚ç›¸ä¼¼åº¦é‡å€¼æ˜¯åº¦é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, instances 1 and 2 are the only instances at this stage that are given predictions of the faulty target level, level 1 (note that their prediction values are the only ones greater than 0.5).",
            "zh": "äº‹å®ä¸Šï¼Œå®ä¾‹ 1 å’Œ 2 æ˜¯æ­¤é˜¶æ®µå”¯ä¸€ç»™å‡ºé”™è¯¯ç›®æ ‡æ°´å¹³ï¼ˆçº§åˆ« 1ï¼‰é¢„æµ‹çš„å®ä¾‹ï¼ˆè¯·æ³¨æ„ï¼Œå®ƒä»¬çš„é¢„æµ‹å€¼æ˜¯å”¯ä¸€å¤§äº 0.5 çš„é¢„æµ‹å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the variance of the z values across for the neurons in the first hidden layer in the first iteration of training.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¸­ç¬¬ä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„ z å€¼çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4.3â€ƒThe 5-Level Model",
            "zh": "13.4.3 äº”çº§æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Lewis, Michael. 2004. Moneyball: The art of winning an unfair game. Norton.",
            "zh": "åˆ˜æ˜“æ–¯ï¼Œè¿ˆå…‹å°”ã€‚2004. ç‚¹çƒæˆé‡‘ï¼šèµ¢å¾—ä¸å…¬å¹³æ¸¸æˆçš„è‰ºæœ¯ã€‚è¯ºé¡¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the gradient descent algorithm uses the error gradient of a model (neuron or regression model) to update the weights on the inputs into the model.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯æ¢¯åº¦ä¸‹é™ç®—æ³•ä½¿ç”¨æ¨¡å‹ï¼ˆç¥ç»å…ƒæˆ–å›å½’æ¨¡å‹ï¼‰çš„è¯¯å·®æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹è¾“å…¥çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.2[56] shows a portion of the ABT that has been developed for the motor insurance claims fraud detection solution based on the design described in Section 2.4.6[42].1 The data quality report for this ABT is shown across Table 3.3[57] (tabular reports for continuous and categorical features) and Figure 3.1[58] (data visualizations for each feature in the dataset).",
            "zh": "è¡¨ 3.2[56] æ˜¾ç¤ºäº†åŸºäºç¬¬ 2.4.6 èŠ‚[42]1 ä¸­æè¿°çš„è®¾è®¡ä¸ºæ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹è§£å†³æ–¹æ¡ˆå¼€å‘çš„ ABT çš„ä¸€éƒ¨åˆ†ã€‚è¡¨ 3.3[57]ï¼ˆè¿ç»­å’Œåˆ†ç±»ç‰¹å¾çš„è¡¨æ ¼æŠ¥å‘Šï¼‰å’Œå›¾ 3.1[58]ï¼ˆæ•°æ®é›†ä¸­æ¯ä¸ªç‰¹å¾çš„æ•°æ®å¯è§†åŒ–ï¼‰æ˜¾ç¤ºäº†æ­¤ ABT çš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Rob: Nopeâ€¦",
            "zh": "Robï¼š ä¸..."
        }
    },
    {
        "translation": {
            "en": "The only difference to keep in mind is that when we use distances, smaller values mean that instances are closer together in a feature space, whereas when we use similarities, larger values indicate this.",
            "zh": "å”¯ä¸€è¦è®°ä½çš„åŒºåˆ«æ˜¯ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨è·ç¦»æ—¶ï¼Œè¾ƒå°çš„å€¼æ„å‘³ç€å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­é å¾—æ›´è¿‘ï¼Œè€Œå½“æˆ‘ä»¬ä½¿ç”¨ç›¸ä¼¼æ€§æ—¶ï¼Œè¾ƒå¤§çš„å€¼è¡¨ç¤ºè¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "An example of a very simple prediction model for this domain is",
            "zh": "è¿™ä¸ªé¢†åŸŸçš„ä¸€ä¸ªéå¸¸ç®€å•çš„é¢„æµ‹æ¨¡å‹çš„ä¾‹å­æ˜¯"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the confidence factor, Î±, associated with ğ•„4.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—ä¸M4ç›¸å…³çš„ç½®ä¿¡å› å­Î±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 0.1",
            "zh": "å›¾ 0.1"
        }
    },
    {
        "translation": {
            "en": "Imagine that you are at a county fair and a stall owner is offering all comers a game of find the lady.",
            "zh": "æƒ³è±¡ä¸€ä¸‹ï¼Œä½ åœ¨ä¸€ä¸ªå¿é›†å¸‚ä¸Šï¼Œä¸€ä¸ªæ‘Šä¸»æ­£åœ¨ä¸ºæ‰€æœ‰æ¥è€…æä¾›å¯»æ‰¾å¥³å£«çš„æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "As each generated state is a modified version of the preceding state, it is clear that successive states will be correlated with each other.",
            "zh": "ç”±äºæ¯ä¸ªç”Ÿæˆçš„çŠ¶æ€éƒ½æ˜¯å‰ä¸€ä¸ªçŠ¶æ€çš„ä¿®æ”¹ç‰ˆæœ¬ï¼Œå› æ­¤å¾ˆæ˜æ˜¾ï¼Œè¿ç»­çš„çŠ¶æ€å°†ç›¸äº’å…³è”ã€‚"
        }
    },
    {
        "translation": {
            "en": "24. Question 4 in the Exercises at the end of this chapter explores the kernel trick in more detail, and worked examples are provided in the solution.",
            "zh": "24. æœ¬ç« æœ«å°¾çš„ç»ƒä¹ ä¸­çš„é—®é¢˜ 4 æ›´è¯¦ç»†åœ°æ¢è®¨äº†å†…æ ¸æŠ€å·§ï¼Œå¹¶åœ¨è§£å†³æ–¹æ¡ˆä¸­æä¾›äº†å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In total, AlexNet had 60 million weights and 650,000 neurons.",
            "zh": "AlexNetæ€»å…±æœ‰6000ä¸‡ä¸ªæƒé‡å’Œ65ä¸‡ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "So, frequently, at the start of training the dataset is shuffled and then split into a sequence of mini-batches.",
            "zh": "å› æ­¤ï¼Œé€šå¸¸ï¼Œåœ¨è®­ç»ƒå¼€å§‹æ—¶ï¼Œæ•°æ®é›†ä¼šè¢«æ´—ç‰Œï¼Œç„¶åæ‹†åˆ†ä¸ºä¸€ç³»åˆ—å°æ‰¹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "prediction model, 3, 19",
            "zh": "é¢„æµ‹æ¨¡å‹ï¼Œ 3ï¼Œ 19"
        }
    },
    {
        "translation": {
            "en": "For this reason we use the term sampling bias here; however, for the purposes of this book, the distinction is not particularly important and in general we use the terms as synonyms.",
            "zh": "å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨æœ¯è¯­æŠ½æ ·åå·®;ç„¶è€Œï¼Œå°±æœ¬ä¹¦è€Œè¨€ï¼Œè¿™ç§åŒºåˆ«å¹¶ä¸æ˜¯ç‰¹åˆ«é‡è¦ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›æœ¯è¯­ä½œä¸ºåŒä¹‰è¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the characteristics of spam emails change both cyclically through the year (typical spam emails at Christmastime are different from typical spam at other times of the year) and also longitudinally (spam in 2014 is very different from spam in 1994).",
            "zh": "ä¾‹å¦‚ï¼Œåƒåœ¾é‚®ä»¶çš„ç‰¹å¾åœ¨ä¸€å¹´ä¸­å¾ªç¯å˜åŒ–ï¼ˆåœ£è¯èŠ‚æœŸé—´çš„å…¸å‹åƒåœ¾é‚®ä»¶ä¸ä¸€å¹´ä¸­å…¶ä»–æ—¶é—´çš„å…¸å‹åƒåœ¾é‚®ä»¶ä¸åŒï¼‰å’Œçºµå‘å˜åŒ–ï¼ˆ2014 å¹´çš„åƒåœ¾é‚®ä»¶ä¸ 1994 å¹´çš„åƒåœ¾é‚®ä»¶æœ‰å¾ˆå¤§ä¸åŒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov test, 272",
            "zh": "Kolmogorov-Smirnov æµ‹è¯•ï¼Œ272"
        }
    },
    {
        "translation": {
            "en": "13.6â€…â€…â€…The confusion matrices showing the performance of models on the under-sampled training set.",
            "zh": "13.6 æ˜¾ç¤ºæ¨¡å‹åœ¨æ¬ é‡‡æ ·è®­ç»ƒé›†ä¸Šçš„æ€§èƒ½çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we do not need to add complex non-linearities between the layers; introducing simple non-linearities, such as the logistic or rectifier functions, between each layer is sufficient to enable neural networks to represent arbitrarily complex functions, as long as the network contains enough layers; in other words, as long as the networks are deep enough.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦åœ¨å±‚ä¹‹é—´æ·»åŠ å¤æ‚çš„éçº¿æ€§;åœ¨æ¯ä¸€å±‚ä¹‹é—´å¼•å…¥ç®€å•çš„éçº¿æ€§ï¼Œä¾‹å¦‚é€»è¾‘å‡½æ•°æˆ–æ•´æµå‡½æ•°ï¼Œè¶³ä»¥ä½¿ç¥ç»ç½‘ç»œè¡¨ç¤ºä»»æ„å¤æ‚çš„å‡½æ•°ï¼Œåªè¦ç½‘ç»œåŒ…å«è¶³å¤Ÿçš„å±‚;æ¢å¥è¯è¯´ï¼Œåªè¦ç½‘ç»œè¶³å¤Ÿæ·±ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can then place each instance within the feature space based on the values of its descriptive features.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æ¯ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾çš„å€¼å°†æ¯ä¸ªå®ä¾‹æ”¾ç½®åœ¨ç‰¹å¾ç©ºé—´ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. This is an example of how machine learning is an ill-posed problem, as discussed in Section 1.3[7].",
            "zh": "12. è¿™æ˜¯æœºå™¨å­¦ä¹ å¦‚ä½•æˆä¸ºä¸€ä¸ªä¸æ°å½“çš„é—®é¢˜çš„ä¸€ä¸ªä¾‹å­ï¼Œå¦‚ç¬¬ 1.3 èŠ‚[7]æ‰€è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) For this task, discuss the suitability of the decision tree, k nearest neighbor, naive Bayes, and logistic regression models. Which one do you think would be most appropriate?",
            "zh": "ï¼ˆbï¼‰ å¯¹äºæ­¤ä»»åŠ¡ï¼Œè®¨è®ºå†³ç­–æ ‘ã€k æœ€è¿‘é‚»ã€æœ´ç´ è´å¶æ–¯å’Œé€»è¾‘å›å½’æ¨¡å‹çš„é€‚ç”¨æ€§ã€‚ä½ è®¤ä¸ºå“ªä¸€ä¸ªæœ€åˆé€‚ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The first way that a naive weight initialization can result in instability during training is that the weights on the connections into a neuron are too large.",
            "zh": "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ´ç´ çš„æƒé‡åˆå§‹åŒ–å¯èƒ½å¯¼è‡´ä¸ç¨³å®šçš„ç¬¬ä¸€ç§æ–¹å¼æ˜¯ç¥ç»å…ƒè¿æ¥ä¸Šçš„æƒé‡å¤ªå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22(a)[361] shows a scatter plot of a reduced version of the generators dataset (shown in Table 7.6[339]) with a decision boundary drawn across it.",
            "zh": "å›¾7.22ï¼ˆaï¼‰[361]æ˜¾ç¤ºäº†ç”Ÿæˆå™¨æ•°æ®é›†çš„ç®€åŒ–ç‰ˆæœ¬çš„æ•£ç‚¹å›¾ï¼ˆå¦‚è¡¨7.6[339]æ‰€ç¤ºï¼‰ï¼Œå¹¶åœ¨å…¶ä¸Šç»˜åˆ¶äº†å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Weights",
            "zh": "æƒé‡"
        }
    },
    {
        "translation": {
            "en": "In a dendrogram each instance in a dataset is represented by its ID label at the bottom of the figure,10 and the horizontal linkages indicate where clusters have been created.",
            "zh": "åœ¨æ ‘çŠ¶å›¾ä¸­ï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½ç”±å›¾åº•éƒ¨çš„ ID æ ‡ç­¾è¡¨ç¤ºï¼Œ10 æ°´å¹³é“¾æ¥æŒ‡ç¤ºé›†ç¾¤çš„åˆ›å»ºä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because the values of this equation are so well behaved, we can use it to predict a categorical target feature. Reverting to our previous notation, we have",
            "zh": "ç”±äºæ­¤æ–¹ç¨‹çš„å€¼è¡¨ç°è‰¯å¥½ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥é¢„æµ‹åˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚å›åˆ°æˆ‘ä»¬ä¹‹å‰çš„ç¬¦å·ï¼Œæˆ‘ä»¬æœ‰"
        }
    },
    {
        "translation": {
            "en": "Reduced error pruning (Quinlan, 1987) is a popular version of post-pruning based on error rates.",
            "zh": "å‡å°‘é”™è¯¯ä¿®å‰ªï¼ˆQuinlanï¼Œ1987ï¼‰æ˜¯åŸºäºé”™è¯¯ç‡çš„åä¿®å‰ªçš„æµè¡Œç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.10",
            "zh": "å›¾ 11.10"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, PREFCHANNEL.",
            "zh": "æ¯ä¸ªå¯è§†åŒ–éƒ½è¯´æ˜äº†æè¿°æ€§è¦ç´ ä¸ç›®æ ‡è¦ç´  PREFCHANNEL ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even in decision trees, the prediction is based on the majority target level at a leaf node, and the proportion of this level gives us a prediction score.",
            "zh": "å³ä½¿åœ¨å†³ç­–æ ‘ä¸­ï¼Œé¢„æµ‹ä¹Ÿæ˜¯åŸºäºå¶èŠ‚ç‚¹ä¸Šçš„å¤šæ•°ç›®æ ‡æ°´å¹³ï¼Œå¹¶ä¸”è¯¥æ°´å¹³çš„æ¯”ä¾‹ä¸ºæˆ‘ä»¬æä¾›äº†é¢„æµ‹åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "An episode involves an attempt to land the spaceship from a position at the top of the screen and ends when either the spaceship successfully touches down gently on the landing pad or crashes.",
            "zh": "ä¸€é›†æ¶‰åŠå°è¯•ä»å±å¹•é¡¶éƒ¨çš„ä½ç½®é™è½å®‡å®™é£èˆ¹ï¼Œå¹¶åœ¨å®‡å®™é£èˆ¹æˆåŠŸè½»è½»é™è½åœ¨ç€é™†å«ä¸Šæˆ–å æ¯æ—¶ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "ELECTRICAL OUTPUT",
            "zh": "ç”µæ°”è¾“å‡º"
        }
    },
    {
        "translation": {
            "en": "These calculations tell us that it is twice as probable that the patient does not have meningitis as it is that the patient does.",
            "zh": "è¿™äº›è®¡ç®—å‘Šè¯‰æˆ‘ä»¬ï¼Œæ‚£è€…æ²¡æœ‰è„‘è†œç‚çš„å¯èƒ½æ€§æ˜¯æ‚£è€…çš„ä¸¤å€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we look at how auto-encoder models, a particular type of neural network, can be used to learn a new feature representation that can be a useful step as part of a larger machine learning process.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹ï¼ˆä¸€ç§ç‰¹å®šç±»å‹çš„ç¥ç»ç½‘ç»œï¼‰æ¥å­¦ä¹ æ–°çš„ç‰¹å¾è¡¨ç¤ºï¼Œä½œä¸ºæ›´å¤§çš„æœºå™¨å­¦ä¹ è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.4â€…â€…â€…Handling Categorical Target Features: Logistic Regression",
            "zh": "7.4.4 å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼šé€»è¾‘å›å½’"
        }
    },
    {
        "translation": {
            "en": "C4.5, 169",
            "zh": "C4.5ï¼Œ 169"
        }
    },
    {
        "translation": {
            "en": "GRADE",
            "zh": "å¹´çº§"
        }
    },
    {
        "translation": {
            "en": "We have marked the unit hypercube covering the interval 0 to 1 in this figure.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œæˆ‘ä»¬æ ‡è®°äº†è¦†ç›–åŒºé—´ 0 åˆ° 1 çš„å•ä½è¶…ç«‹æ–¹ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The intuition behind support vector machines is that this second decision boundary should distinguish between the two target levels much more reliably than the first.",
            "zh": "æ”¯æŒå‘é‡æœºèƒŒåçš„ç›´è§‰æ˜¯ï¼Œç¬¬äºŒä¸ªå†³ç­–è¾¹ç•Œåº”è¯¥æ¯”ç¬¬ä¸€ä¸ªæ›´å¯é åœ°åŒºåˆ†ä¸¤ä¸ªç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "11. See Chapter 8[381].",
            "zh": "[11]è§ç¬¬8ç« [381]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov assumption, 644",
            "zh": "é©¬å°”å¯å¤«å‡è®¾ï¼Œ644"
        }
    },
    {
        "translation": {
            "en": "Then the z value for the neuron will be large, which can result in the activation function for the neuron becoming saturated.",
            "zh": "ç„¶åç¥ç»å…ƒçš„ z å€¼ä¼šå¾ˆå¤§ï¼Œè¿™å¯èƒ½å¯¼è‡´ç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°å˜å¾—é¥±å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4.3â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "3.4.3 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Hebb, Donald O. 1949. The organization of behavior; A neuropsychological theory. Wiley.",
            "zh": "èµ«å¸ƒï¼Œå”çº³å¾· O. 1949 å¹´ã€‚è¡Œä¸ºçš„ç»„ç»‡;ä¸€ç§ç¥ç»å¿ƒç†å­¦ç†è®ºã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "24. The natural logarithm of a value a, loge(a), is the logarithm of a to the base e, where e is Eulerâ€™s number, equal to approximately 2.718.",
            "zh": "24. å€¼ a çš„è‡ªç„¶å¯¹æ•° logeï¼ˆaï¼‰ æ˜¯ a åˆ°åº•æ•° e çš„å¯¹æ•°ï¼Œå…¶ä¸­ e æ˜¯æ¬§æ‹‰æ•°ï¼Œå¤§çº¦ç­‰äº 2.718ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is equivalent to the total entropy for the entire dataset.",
            "zh": "è¿™ç›¸å½“äºæ•´ä¸ªæ•°æ®é›†çš„æ€»ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Performing evaluation experiments using different model types is really the only way to determine which variant will work best for a specific problem.",
            "zh": "ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ç±»å‹æ‰§è¡Œè¯„ä¼°å®éªŒå®é™…ä¸Šæ˜¯ç¡®å®šå“ªç§å˜ä½“æœ€é€‚åˆç‰¹å®šé—®é¢˜çš„å”¯ä¸€æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "universal approximation theorem, 400",
            "zh": "é€šç”¨è¿‘ä¼¼å®šç†ï¼Œ400"
        }
    },
    {
        "translation": {
            "en": "Another advantage of AHC is that it is deterministic, and doesnâ€™t suffer from the impact of different seeds as k-means or k-means++ does. This means that it will give exactly the same result every time it is run on the same dataset and that the issues around finding seeds discussed in Section 10.4.1[605] do not arise. These two advantages are present in most hierarchical clustering algorithms.",
            "zh": "AHC çš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯å®ƒæ˜¯ç¡®å®šæ€§çš„ï¼Œå¹¶ä¸”ä¸ä¼šåƒ k-means æˆ– k-means++ é‚£æ ·å—åˆ°ä¸åŒç§å­çš„å½±å“ã€‚è¿™æ„å‘³ç€æ¯æ¬¡åœ¨ç›¸åŒçš„æ•°æ®é›†ä¸Šè¿è¡Œæ—¶ï¼Œå®ƒéƒ½ä¼šç»™å‡ºå®Œå…¨ç›¸åŒçš„ç»“æœï¼Œå¹¶ä¸”ä¸ä¼šå‡ºç°ç¬¬ 10.4.1 èŠ‚[605] ä¸­è®¨è®ºçš„æŸ¥æ‰¾ç§å­çš„é—®é¢˜ã€‚è¿™ä¸¤ä¸ªä¼˜ç‚¹å­˜åœ¨äºå¤§å¤šæ•°åˆ†å±‚èšç±»ç®—æ³•ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A continuous function in two variables, x and y; (b) the partial derivative of this function with respect to x; and (c) the partial derivative of this function with respect to y.",
            "zh": "ï¼ˆaï¼‰ xå’Œyä¸¤ä¸ªå˜é‡çš„è¿ç»­å‡½æ•°;ï¼ˆbï¼‰ è¯¥å‡½æ•°ç›¸å¯¹äº x çš„åå¯¼æ•°;ï¼ˆcï¼‰è¯¥å‡½æ•°ç›¸å¯¹äº y çš„åå¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "bar plot, 54, 745, 752",
            "zh": "æ¡å½¢å›¾ï¼Œ 54ï¼Œ 745ï¼Œ 752"
        }
    },
    {
        "translation": {
            "en": "4. The following is a description of the causal relationship between storms, the behavior of burglars and cats, and house alarms:",
            "zh": "4.ä»¥ä¸‹æ˜¯å¯¹æš´é£é›¨ã€çªƒè´¼å’ŒçŒ«çš„è¡Œä¸ºä»¥åŠæˆ¿å±‹è­¦æŠ¥ä¹‹é—´çš„å› æœå…³ç³»çš„æè¿°ï¼š"
        }
    },
    {
        "translation": {
            "en": "Hence, the size of the domain representation used by a support vector machine may change as instances are added to the dataset.",
            "zh": "å› æ­¤ï¼Œæ”¯æŒå‘é‡æœºä½¿ç”¨çš„åŸŸè¡¨ç¤ºçš„å¤§å°å¯èƒ½ä¼šéšç€å®ä¾‹æ·»åŠ åˆ°æ•°æ®é›†è€Œæ”¹å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.9[672] illustrates this process.",
            "zh": "å›¾11.9[672]è¯´æ˜äº†è¿™ä¸€è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "45) for a discussion on how to train a probability-based prediction model in situations where one of the target levels is rare.",
            "zh": "45ï¼‰ è®¨è®ºå¦‚ä½•åœ¨ç›®æ ‡æ°´å¹³ä¹‹ä¸€å¾ˆå°‘çš„æƒ…å†µä¸‹è®­ç»ƒåŸºäºæ¦‚ç‡çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The depth of a filter must match the depth of the input.",
            "zh": "ç­›é€‰å™¨çš„æ·±åº¦å¿…é¡»ä¸è¾“å…¥çš„æ·±åº¦åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, given a sufficiently large sample, we use the sample variance, var(a), as a point estimate of Ïƒ2.",
            "zh": "é€šå¸¸ï¼Œç»™å®šè¶³å¤Ÿå¤§çš„æ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ·æœ¬æ–¹å·® varï¼ˆaï¼‰ ä½œä¸º Ïƒ2 çš„ç‚¹ä¼°è®¡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we describe are the use of smoothing to combat overfitting, the modifications required to the standard naive Bayes model to allow it to handle continuous features, and Bayesian network models that give us more control than a naive Bayes model over the assumptions that are encoded in a model.",
            "zh": "æˆ‘ä»¬æè¿°çš„è¿™ç§æ ‡å‡†æ–¹æ³•çš„æ‰©å±•å’Œå˜åŒ–æ˜¯ä½¿ç”¨å¹³æ»‘æ¥å¯¹æŠ—è¿‡æ‹Ÿåˆï¼Œå¯¹æ ‡å‡†æœ´ç´ è´å¶æ–¯æ¨¡å‹è¿›è¡Œå¿…è¦çš„ä¿®æ”¹ä»¥ä½¿å…¶èƒ½å¤Ÿå¤„ç†è¿ç»­ç‰¹å¾ï¼Œä»¥åŠè´å¶æ–¯ç½‘ç»œæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ä¸ºæˆ‘ä»¬æä¾›äº†æ¯”æœ´ç´ è´å¶æ–¯æ¨¡å‹æ›´å¤šçš„æ§åˆ¶æƒï¼Œå¯ä»¥æ§åˆ¶æ¨¡å‹ä¸­ç¼–ç çš„å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A silhouette plot shows the silhouette width for each instance in the dataset grouped by the clusters to which they belong.",
            "zh": "è½®å»“å›¾æ˜¾ç¤ºæ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹çš„è½®å»“å®½åº¦ï¼Œè¿™äº›å®ä¾‹æŒ‰å…¶æ‰€å±çš„èšç±»åˆ†ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, Jocelyn chose to use a step-wise sequential search for feature selection for each of the three model types.",
            "zh": "å‡ºäºè¿™ä¸ªåŸå› ï¼ŒJocelyn é€‰æ‹©å¯¹ä¸‰ç§æ¨¡å‹ç±»å‹ä¸­çš„æ¯ä¸€ç§éƒ½ä½¿ç”¨é€æ­¥é¡ºåºæœç´¢æ¥é€‰æ‹©ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, the partial derivative with respect to w[4] is",
            "zh": "ç±»ä¼¼åœ°ï¼Œå…³äº w[4] çš„åå¯¼æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "Voronoi tessellation, 189, 231",
            "zh": "Voronoi é•¶åµŒï¼Œ 189ï¼Œ 231"
        }
    },
    {
        "translation": {
            "en": "If we have developed a predictive model that is used in a particular business process, we can run that business process in parallel both with the predictive model, the treatment group, and without the predictive model, the control group, in order to evaluate how much the use of the predictive model has improved the business process.",
            "zh": "å¦‚æœæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç”¨äºç‰¹å®šä¸šåŠ¡æµç¨‹çš„é¢„æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä¸é¢„æµ‹æ¨¡å‹ï¼ˆå¤„ç†ç»„ï¼‰å’Œæ²¡æœ‰é¢„æµ‹æ¨¡å‹ï¼ˆå¯¹ç…§ç»„ï¼‰å¹¶è¡Œè¿è¡Œè¯¥ä¸šåŠ¡æµç¨‹ï¼Œä»¥è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„ä½¿ç”¨åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ”¹å–„äº†ä¸šåŠ¡æµç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) An illustration of the final ensemble model trained using the boosting algorithm.",
            "zh": "ï¼ˆbï¼‰ ä½¿ç”¨æå‡ç®—æ³•è®­ç»ƒçš„æœ€ç»ˆé›†æˆæ¨¡å‹çš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.6",
            "zh": "å›¾ 7.6"
        }
    },
    {
        "translation": {
            "en": "Therefore, the inclusion of the translation by the bias term allows the weighted sum to define a linear function on its inputs that does not pass through the origin.",
            "zh": "å› æ­¤ï¼Œé€šè¿‡åç½®é¡¹åŒ…å«å¹³ç§»ï¼ŒåŠ æƒå’Œå¯ä»¥åœ¨å…¶è¾“å…¥ä¸Šå®šä¹‰ä¸€ä¸ªä¸é€šè¿‡åŸç‚¹çš„çº¿æ€§å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comparing Figure 6.5(a)[273] and Figure 6.5(b)[273], we can see clearly that the introduction of outliers has a much larger effect on the normal distribution than it does on the student-t distribution.",
            "zh": "æ¯”è¾ƒå›¾6.5ï¼ˆaï¼‰[273]å’Œå›¾6.5ï¼ˆbï¼‰[273]ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œå¼•å…¥å¼‚å¸¸å€¼å¯¹æ­£æ€åˆ†å¸ƒçš„å½±å“æ¯”å¯¹å­¦ç”Ÿtåˆ†å¸ƒçš„å½±å“è¦å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "which has a sum of squared errors of 1.8804. Obviously, because there are instances with different levels for the target feature overlapping in the feature space, it is not possible in this case to build a model that perfectly separates the good and faulty machines. The model trained, however, strikes a good balance between mistaking good machines for faulty ones and vice versa.",
            "zh": "å…¶å¹³æ–¹è¯¯å·®ä¹‹å’Œä¸º 1.8804ã€‚æ˜¾ç„¶ï¼Œç”±äºåœ¨ç‰¹å¾ç©ºé—´ä¸­å­˜åœ¨å…·æœ‰ä¸åŒçº§åˆ«çš„ç›®æ ‡ç‰¹å¾é‡å çš„å®ä¾‹ï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸å¯èƒ½æ„å»ºä¸€ä¸ªå®Œç¾åŒºåˆ†è‰¯å¥½å’Œæ•…éšœæœºå™¨çš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œç»è¿‡è®­ç»ƒçš„æ¨¡å‹åœ¨å°†å¥½æœºå™¨è¯¯è®¤ä¸ºæœ‰ç¼ºé™·çš„æœºå™¨ä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ï¼Œåä¹‹äº¦ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "One complaint that is often leveled against mean squared error is that, although it can be used to effectively rank models, the actual mean squared error values themselves are not especially meaningful in relation to the scenario that a model is being used for.",
            "zh": "ç»å¸¸é’ˆå¯¹å‡æ–¹è¯¯å·®çš„ä¸€ä¸ªæŠ±æ€¨æ˜¯ï¼Œå°½ç®¡å®ƒå¯ç”¨äºæœ‰æ•ˆåœ°å¯¹æ¨¡å‹è¿›è¡Œæ’åï¼Œä½†å®é™…çš„å‡æ–¹è¯¯å·®å€¼æœ¬èº«å¯¹äºæ¨¡å‹æ‰€ç”¨äºçš„åœºæ™¯å¹¶ä¸æ˜¯ç‰¹åˆ«æœ‰æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can consider the scout to be an intelligent agent (or simply agent) attempting to complete a task within an environment.",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†ä¾¦å¯Ÿå‘˜è§†ä¸ºè¯•å›¾åœ¨ç¯å¢ƒä¸­å®Œæˆä»»åŠ¡çš„æ™ºèƒ½ä»£ç†ï¼ˆæˆ–ç®€ç§°ä»£ç†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just like our imagined mountain climber, the algorithm can use only very localized information.",
            "zh": "å°±åƒæˆ‘ä»¬æƒ³è±¡ä¸­çš„ç™»å±±è€…ä¸€æ ·ï¼Œè¯¥ç®—æ³•åªèƒ½ä½¿ç”¨éå¸¸æœ¬åœ°åŒ–çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the temporal-difference learning approach, which is the basis for the standard approach to reinforcement learning that will be discussed in the following chapter, is explained.",
            "zh": "æœ€åï¼Œè§£é‡Šäº†æ—¶é—´å·®åˆ†å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜¯ä¸‹ä¸€ç« å°†è®¨è®ºçš„æ ‡å‡†å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.2(a)[186] illustrates the difference between the Manhattan and Euclidean distances between two points in a two-dimensional feature space. If we compare Equation (5.1)[185] and Equation (5.2)[185], we can see that both distance metrics are essentially functions of the differences between the values of the features. Indeed, the Euclidean and Manhattan distances are special cases of the Minkowski distance, which defines a family of distance metrics based on differences between features.",
            "zh": "å›¾5.2ï¼ˆaï¼‰[186]è¯´æ˜äº†äºŒç»´ç‰¹å¾ç©ºé—´ä¸­ä¸¤ç‚¹ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦»å’Œæ¬§å‡ é‡Œå¾—è·ç¦»ä¹‹é—´çš„å·®å¼‚ã€‚å¦‚æœæˆ‘ä»¬æ¯”è¾ƒç­‰å¼ï¼ˆ5.1ï¼‰[185]å’Œç­‰å¼ï¼ˆ5.2ï¼‰[185]ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸¤ä¸ªè·ç¦»åº¦é‡æœ¬è´¨ä¸Šéƒ½æ˜¯ç‰¹å¾å€¼ä¹‹é—´å·®å¼‚çš„å‡½æ•°ã€‚äº‹å®ä¸Šï¼Œæ¬§å‡ é‡Œå¾—è·ç¦»å’Œæ›¼å“ˆé¡¿è·ç¦»æ˜¯é—µå¯å¤«æ–¯åŸºè·ç¦»çš„ç‰¹ä¾‹ï¼Œé—µå¯å¤«æ–¯åŸºè·ç¦»æ ¹æ®è¦ç´ ä¹‹é—´çš„å·®å¼‚å®šä¹‰äº†ä¸€ç³»åˆ—è·ç¦»åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that when we perform data preparations (such as those in Section 3.6[87] or those described in Section 3.4[69]), we are changing the data that we will use to subsequently train predictive models.",
            "zh": "é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå½“æˆ‘ä»¬æ‰§è¡Œæ•°æ®å‡†å¤‡æ—¶ï¼ˆä¾‹å¦‚ç¬¬ 3.6 èŠ‚[87] æˆ–ç¬¬ 3.4 èŠ‚[69]ä¸­æè¿°çš„æ•°æ®ï¼‰ï¼Œæˆ‘ä»¬æ­£åœ¨æ›´æ”¹å°†ç”¨äºåç»­è®­ç»ƒé¢„æµ‹æ¨¡å‹çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this number changed significantly from what was seen in the data used to build the model, the model would be deemed stale, and retraining would be required.",
            "zh": "å¦‚æœæ­¤æ•°å­—ä¸ç”¨äºæ„å»ºæ¨¡å‹çš„æ•°æ®ä¸­æ˜¾ç¤ºçš„æ•°å­—å‘ç”Ÿæ˜¾è‘—å˜åŒ–ï¼Œåˆ™è¯¥æ¨¡å‹å°†è¢«è§†ä¸ºè¿‡æ—¶ï¼Œéœ€è¦é‡æ–°è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "10.9â€…â€…â€…(a)â€“(b) Visualizations of the distributions of the descriptive features in the mobile phone customer dataset in Table 10.1[604] across the complete dataset, and divided by the clustering found using k-means clustering (k = 3).",
            "zh": "10.9 ï¼ˆaï¼‰â€“ï¼ˆbï¼‰ è¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾åˆ†å¸ƒåœ¨æ•´ä¸ªæ•°æ®é›†ä¸­çš„å¯è§†åŒ–ï¼Œå¹¶é™¤ä»¥ä½¿ç”¨k-meansèšç±»ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The validation set is used when data outside the training set is required in order to tune particular aspects of a model.",
            "zh": "å½“éœ€è¦è®­ç»ƒé›†ä¹‹å¤–çš„æ•°æ®æ¥ä¼˜åŒ–æ¨¡å‹çš„ç‰¹å®šæ–¹é¢æ—¶ï¼Œä½¿ç”¨éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) What target level will the naive Bayes model predict for the following query:",
            "zh": "ï¼ˆaï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹ä»¥ä¸‹æŸ¥è¯¢çš„ç›®æ ‡æ°´å¹³ï¼š"
        }
    },
    {
        "translation": {
            "en": "mapping features, 36, 65",
            "zh": "æ˜ å°„è¦ç´ ï¼Œ 36ï¼Œ 65"
        }
    },
    {
        "translation": {
            "en": "The optimal threshold is found by computing the information gain for each of the target level transition boundaries and selecting the boundary with the highest information gain as the threshold.",
            "zh": "é€šè¿‡è®¡ç®—æ¯ä¸ªç›®æ ‡ç”µå¹³è½¬æ¢è¾¹ç•Œçš„ä¿¡æ¯å¢ç›Šå¹¶é€‰æ‹©å…·æœ‰æœ€é«˜ä¿¡æ¯å¢ç›Šçš„è¾¹ç•Œä½œä¸ºé˜ˆå€¼ï¼Œå¯ä»¥æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "At first, this choice of question might seem ineffective.",
            "zh": "èµ·åˆï¼Œè¿™ç§é—®é¢˜é€‰æ‹©ä¼¼ä¹æ˜¯æ— æ•ˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "These measures, however, are intrinsically tied to the threshold used to convert prediction scores into target levels.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›åº¦é‡ä¸ç”¨äºå°†é¢„æµ‹åˆ†æ•°è½¬æ¢ä¸ºç›®æ ‡æ°´å¹³çš„é˜ˆå€¼æœ‰ç€å†…åœ¨çš„è”ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.5â€ƒSummary",
            "zh": "10.5 æ€»ç»“"
        }
    },
    {
        "translation": {
            "en": "Lintott, C. J., K. Schawinski, A. Slosar, K. Land, S. Bamford, D. Thomas, M. J. Raddick, R. C. Nichol, A. Szalay, D. Andreescu, P. Murray, and J. Vandenberg. 2008. Galaxy Zoo: Morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey. Monthly Notices of the Royal Astronomical Society 389: 1179â€“1189. doi:10.1111/j.1365-2966.2008.13689.x.",
            "zh": "æ—æ‰˜ç‰¹ã€CJã€K. Schawinskiã€A. Slosarã€K. Landã€S. Bamfordã€D. Thomasã€MJ Raddickã€RC Nicholã€A. Szalayã€D. Andreescuã€P. Murray å’Œ J. Vandenbergã€‚2008. é“¶æ²³åŠ¨ç‰©å›­ï¼šæ–¯éš†æ•°å­—å·¡å¤©å¯¹æ˜Ÿç³»çš„ç›®è§†æ£€æŸ¥å¾—å‡ºçš„å½¢æ€å­¦ã€‚çš‡å®¶å¤©æ–‡å­¦ä¼šæœˆåˆŠ 389ï¼š1179â€“1189ã€‚doiï¼š10.1111/j.1365-2966.2008.13689.x."
        }
    },
    {
        "translation": {
            "en": "4.14â€…â€…â€…The decision tree that would be generated for the vegetation classification dataset listed in Table 4.9[147] using information gain.",
            "zh": "4.14 ä½¿ç”¨ä¿¡æ¯å¢ç›Šä¸ºè¡¨4.9[147]ä¸­åˆ—å‡ºçš„æ¤è¢«åˆ†ç±»æ•°æ®é›†ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Create a k-d tree for this dataset. Assume the following order over the features: RENT then SIZE.",
            "zh": "ï¼ˆaï¼‰ ä¸ºæ­¤æ•°æ®é›†åˆ›å»º k-d æ ‘ã€‚å‡è®¾è¦ç´ çš„é¡ºåºå¦‚ä¸‹ï¼šRENT å’Œ SIZEã€‚"
        }
    },
    {
        "translation": {
            "en": "As TD(0) updates an entry in the action-value table every time an action has been taken, it has the advantage that an agent can start to learn very quickly; however, this approach can take a long time to converge toward the optimal values in the action-value table.16",
            "zh": "ç”±äº TDï¼ˆ0ï¼‰ åœ¨æ¯æ¬¡æ‰§è¡Œæ“ä½œæ—¶éƒ½ä¼šæ›´æ–°æ“ä½œå€¼è¡¨ä¸­çš„æ¡ç›®ï¼Œå› æ­¤å®ƒçš„ä¼˜ç‚¹æ˜¯ä»£ç†å¯ä»¥éå¸¸å¿«é€Ÿåœ°å¼€å§‹å­¦ä¹ ;ä½†æ˜¯ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½æ”¶æ•›åˆ°æ“ä½œå€¼è¡¨ä¸­çš„æœ€ä½³å€¼16ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.1â€…â€…â€…A high-level schematic of the structure of a neuron.",
            "zh": "8.1 ç¥ç»å…ƒç»“æ„çš„é«˜çº§ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "where var(W(k)) is the variance of all the weights in layer k; nin(k) is the number of neurons that feed inputs to layer k; and nout(k) is the number of neurons that neurons in layer k connect forward to (in a fully connected feedforward network nin(k) is equal to the number of neurons in layer k âˆ’ 1 and nout(k) is the number of neurons in layer k + 1). Often in practice, however, a simpler variant of Xavier initialization is used that just considers nin(k)",
            "zh": "å…¶ä¸­ varï¼ˆWï¼ˆkï¼‰ï¼‰ æ˜¯å±‚ k ä¸­æ‰€æœ‰æƒé‡çš„æ–¹å·®;ninï¼ˆkï¼‰ æ˜¯å°†è¾“å…¥é¦ˆé€åˆ°ç¬¬ k å±‚çš„ç¥ç»å…ƒæ•°é‡;noutï¼ˆkï¼‰ æ˜¯ k å±‚ç¥ç»å…ƒå‘å‰è¿æ¥çš„ç¥ç»å…ƒæ•°ï¼ˆåœ¨å…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œä¸­ï¼Œninï¼ˆkï¼‰ ç­‰äº k å±‚ âˆ’ 1 ä¸­çš„ç¥ç»å…ƒæ•°ï¼Œnoutï¼ˆkï¼‰ æ˜¯ k å±‚ + 1 ä¸­çš„ç¥ç»å…ƒæ•°ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œé€šå¸¸ä½¿ç”¨æ›´ç®€å•çš„ Xavier åˆå§‹åŒ–å˜ä½“ï¼Œåªè€ƒè™‘ ninï¼ˆkï¼‰"
        }
    },
    {
        "translation": {
            "en": "The Minkowski distance between two instances a and b in a feature space with m descriptive features is defined as",
            "zh": "åœ¨å…·æœ‰ m ä¸ªæè¿°æ€§ç‰¹å¾çš„ç‰¹å¾ç©ºé—´ä¸­ï¼Œä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„é—µå¯å¤«æ–¯åŸºè·ç¦»å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "This uncertainty is one of the key things that the MDP formulation allows us to model.",
            "zh": "è¿™ç§ä¸ç¡®å®šæ€§æ˜¯ MDP å…¬å¼å…è®¸æˆ‘ä»¬å»ºæ¨¡çš„å…³é”®å› ç´ ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason why Equation 8.104[501] has a more complicated form then previously is that the neuron has two sets of inputs (from the input layer and the activation buffer), and so it has two separate weight matrices; also, to be as transparent as possible, we have explicitly represented the bias terms for the weights in a separate vector w0.",
            "zh": "æ–¹ç¨‹ 8.104[501] çš„å½¢å¼æ¯”ä»¥å‰æ›´å¤æ‚çš„åŸå› æ˜¯ç¥ç»å…ƒæœ‰ä¸¤ç»„è¾“å…¥ï¼ˆæ¥è‡ªè¾“å…¥å±‚å’Œæ¿€æ´»ç¼“å†²åŒºï¼‰ï¼Œå› æ­¤å®ƒæœ‰ä¸¤ä¸ªç‹¬ç«‹çš„æƒé‡çŸ©é˜µ;æ­¤å¤–ï¼Œä¸ºäº†å°½å¯èƒ½é€æ˜ï¼Œæˆ‘ä»¬åœ¨å•ç‹¬çš„å‘é‡ W0 ä¸­æ˜ç¡®è¡¨ç¤ºäº†æƒé‡çš„åå·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This does assume that the width of the layers is sufficient to permit the network to represent the function; however, for a given function the number of neurons required in each of the hidden layers is not known, in general.",
            "zh": "è¿™ç¡®å®å‡è®¾å±‚çš„å®½åº¦è¶³ä»¥å…è®¸ç½‘ç»œè¡¨ç¤ºå‡½æ•°;ç„¶è€Œï¼Œå¯¹äºç»™å®šçš„å‡½æ•°ï¼Œé€šå¸¸æ¯ä¸ªéšè—å±‚ä¸­æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡æ˜¯æœªçŸ¥çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.7â€…â€…â€…The Lunar Lander environment. The aim of the game is to control the spaceship starting from the top of the world and attempting to land on the landing pad.",
            "zh": "11.7 æœˆçƒç€é™†å™¨ç¯å¢ƒã€‚æ¸¸æˆçš„ç›®çš„æ˜¯æ§åˆ¶å®‡å®™é£èˆ¹ä»ä¸–ç•Œä¹‹å·…å¼€å§‹ï¼Œè¯•å›¾é™è½åœ¨ç€é™†å°ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4.2â€…â€…â€…Handling Continuous Descriptive Features",
            "zh": "4.4.2 å¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "frequency histogram, 752",
            "zh": "é¢‘ç‡ç›´æ–¹å›¾ï¼Œ752"
        }
    },
    {
        "translation": {
            "en": "Switching the focus to the calculation of Î´s for hidden neurons, the calculation of âˆ‚â„°/âˆ‚ak for a hidden neuron k requires that the Î´s for all downstream neurons be calculated first (i.e., all the neurons that the activation ak is directly propagated to during the forward pass).",
            "zh": "å°†ç„¦ç‚¹åˆ‡æ¢åˆ°éšè—ç¥ç»å…ƒçš„ Î´s è®¡ç®—ï¼Œéšè—ç¥ç»å…ƒ k çš„ âˆ‚E/âˆ‚ak è®¡ç®—éœ€è¦é¦–å…ˆè®¡ç®—æ‰€æœ‰ä¸‹æ¸¸ç¥ç»å…ƒçš„ Î´sï¼ˆå³æ¿€æ´» ak åœ¨å‰å‘ä¼ é€’æœŸé—´ç›´æ¥ä¼ æ’­åˆ°çš„æ‰€æœ‰ç¥ç»å…ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIM AMOUNT, TOTAL CLAIMED, NUM.",
            "zh": "ç´¢èµ”é‡‘é¢ï¼Œç´¢èµ”æ€»é¢ï¼Œç¼–å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of customers who left the mobile phone network operator each week during the comparative experiment from both the control group (random selection) and the treatment group (model selection).",
            "zh": "åœ¨å¯¹ç…§ç»„ï¼ˆéšæœºé€‰æ‹©ï¼‰å’Œæ²»ç–—ç»„ï¼ˆæ¨¡å‹é€‰æ‹©ï¼‰çš„æ¯”è¾ƒå®éªŒæœŸé—´æ¯å‘¨ç¦»å¼€ç§»åŠ¨ç”µè¯ç½‘ç»œè¿è¥å•†çš„å®¢æˆ·æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "to determine which of the models that we have built for a particular task is most suited to that task",
            "zh": "ç¡®å®šæˆ‘ä»¬ä¸ºç‰¹å®šä»»åŠ¡æ„å»ºçš„å“ªäº›æ¨¡å‹æœ€é€‚åˆè¯¥ä»»åŠ¡"
        }
    },
    {
        "translation": {
            "en": "It is important to recognize that using an inductive bias is a necessary prerequisite for learning to occur; without inductive bias, a machine learning algorithm cannot learn anything beyond what is in the data.",
            "zh": "é‡è¦çš„æ˜¯è¦è®¤è¯†åˆ°ï¼Œä½¿ç”¨å½’çº³åå·®æ˜¯å­¦ä¹ å‘ç”Ÿçš„å¿…è¦å…ˆå†³æ¡ä»¶;å¦‚æœæ²¡æœ‰å½’çº³åå·®ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•å°±æ— æ³•å­¦ä¹ æ•°æ®ä¹‹å¤–çš„ä»»ä½•å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A multivariate logistic regression model has been built to predict the propensity of shoppers to perform a repeat purchase of a free gift that they are given.",
            "zh": "å·²ç»å»ºç«‹äº†ä¸€ä¸ªå¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹æ¥é¢„æµ‹è´­ç‰©è€…é‡å¤è´­ä¹°å…è´¹ç¤¼ç‰©çš„å€¾å‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that each row in the CPT tables sum to 1.",
            "zh": "è¯·æ³¨æ„ï¼ŒCPT è¡¨ä¸­çš„æ¯ä¸€è¡Œæ€»å’Œä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "A portion of the action-value table for the grid world example at its first initialization.",
            "zh": "é¦–æ¬¡åˆå§‹åŒ–æ—¶ç½‘æ ¼ä¸–ç•Œç¤ºä¾‹çš„æ“ä½œå€¼è¡¨çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, Ross needed to understand the current analytics capability of the company and its readiness to take action in response to the insights that an analytics solution would provide.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼ŒRoss éœ€è¦äº†è§£å…¬å¸å½“å‰çš„åˆ†æèƒ½åŠ›ï¼Œä»¥åŠå®ƒæ˜¯å¦å‡†å¤‡å¥½é‡‡å–è¡ŒåŠ¨ä»¥å“åº”åˆ†æè§£å†³æ–¹æ¡ˆå°†æä¾›çš„è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to explain how matrix multiplications are used in a neural network, we need to introduce some notation and then define the order of the matrices in the multiplication.",
            "zh": "ä¸ºäº†è§£é‡ŠçŸ©é˜µä¹˜æ³•åœ¨ç¥ç»ç½‘ç»œä¸­çš„ä½¿ç”¨æ–¹å¼ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥ä¸€äº›ç¬¦å·ï¼Œç„¶åå®šä¹‰ä¹˜æ³•ä¸­çŸ©é˜µçš„é¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout the discussion of the data quality report and how we use it, we return to the motor insurance fraud case study from Chapter 2[23].",
            "zh": "åœ¨å¯¹æ•°æ®è´¨é‡æŠ¥å‘Šä»¥åŠæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨å®ƒçš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬å›åˆ°äº†ç¬¬ 2 ç« [23] çš„æ±½è½¦ä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. This is a slight departure from Equation (11.9)[643] as it sums to infinity rather than to the end of an episode. This, however, makes no difference in the discussion that follows but is the normal formulation of the Bellman Equations.",
            "zh": "12. è¿™ä¸ç­‰å¼ï¼ˆ11.9ï¼‰[643]ç•¥æœ‰ä¸åŒï¼Œå› ä¸ºå®ƒçš„æ€»å’Œæ˜¯æ— ç©·å¤§ï¼Œè€Œä¸æ˜¯ä¸€é›†çš„æœ«å°¾ã€‚ç„¶è€Œï¼Œè¿™åœ¨éšåçš„è®¨è®ºä¸­æ²¡æœ‰åŒºåˆ«ï¼Œä½†è¿™æ˜¯è´å°”æ›¼æ–¹ç¨‹çš„æ­£å¸¸å…¬å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neural network texts that we would recommend include Bishop (1996) and Reed and Marks (1999).",
            "zh": "æˆ‘ä»¬æ¨èçš„ç¥ç»ç½‘ç»œæ–‡æœ¬åŒ…æ‹¬Bishopï¼ˆ1996ï¼‰å’ŒReed and Marksï¼ˆ1999ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, the algorithm checks if the instance indexed by the node is closer to the query than the instance at the current best node.",
            "zh": "å…¶æ¬¡ï¼Œè¯¥ç®—æ³•æ£€æŸ¥èŠ‚ç‚¹ç´¢å¼•çš„å®ä¾‹æ˜¯å¦æ¯”å½“å‰æœ€ä½³èŠ‚ç‚¹çš„å®ä¾‹æ›´æ¥è¿‘æŸ¥è¯¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. See Section 3.1[54].",
            "zh": "6. å‚è§ç¬¬ 3.1 èŠ‚[54]ã€‚"
        }
    },
    {
        "translation": {
            "en": "68.50",
            "zh": "68.50"
        }
    },
    {
        "translation": {
            "en": "In an example like the car journey just described, where we have a set of discrete measurements, calculating the derivative is simply a matter of determining the difference between subsequent pairs of measurements.",
            "zh": "åœ¨åƒåˆšæ‰æè¿°çš„æ±½è½¦æ—…ç¨‹è¿™æ ·çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ç»„ç¦»æ•£çš„æµ‹é‡å€¼ï¼Œè®¡ç®—å¯¼æ•°åªæ˜¯ç¡®å®šåç»­æµ‹é‡å¯¹ä¹‹é—´çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.2â€…â€…â€…Calculating the silhouette for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3). The overall silhouette index value is 0.66.",
            "zh": "10.2 è®¡ç®—ä½¿ç”¨ k å‡å€¼ç®—æ³•ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†æœ€ç»ˆèšç±»çš„è½®å»“ï¼ˆè¡¨ 10.1[604]ï¼‰ã€‚æ•´ä½“è½®å»“æŒ‡æ•°å€¼ä¸º 0.66ã€‚"
        }
    },
    {
        "translation": {
            "en": "Intercept (w[0])",
            "zh": "æ‹¦æˆª ï¼ˆw[0]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The remainder of this section focuses on the error delta function, which calculates the delta value that determines the direction (either positive or negative) and the magnitude of the adjustments made to each weight.",
            "zh": "æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†é‡ç‚¹ä»‹ç»è¯¯å·®å¢é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°è®¡ç®—ç¡®å®šæ–¹å‘ï¼ˆæ­£æˆ–è´Ÿï¼‰çš„å¢é‡å€¼ä»¥åŠå¯¹æ¯ä¸ªæƒé‡æ‰€åšçš„è°ƒæ•´å¹…åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "ABT, 17",
            "zh": "ABTï¼Œ17"
        }
    },
    {
        "translation": {
            "en": "OECD. 2013. The OECD privacy framework. Organisation for Economic Co-operation and Development.",
            "zh": "ç»åˆç»„ç»‡ã€‚2013. ç»åˆç»„ç»‡éšç§æ¡†æ¶ã€‚ç»æµåˆä½œä¸å‘å±•ç»„ç»‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What would be the reduction in entropy (i.e., the information gain) in bits if we split these letters into two sets, one containing the vowels and the other containing the consonants?",
            "zh": "ï¼ˆä¹™ï¼‰å¦‚æœæˆ‘ä»¬æŠŠè¿™äº›å­—æ¯åˆ†æˆä¸¤ç»„ï¼Œä¸€ç»„åŒ…å«å…ƒéŸ³ï¼Œå¦ä¸€ç»„åŒ…å«è¾…éŸ³ï¼Œç†µï¼ˆå³ä¿¡æ¯å¢ç›Šï¼‰ä¼šå‡å°‘å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The Gini coefficient can take values in the range [0,1], and higher values indicate better model performance. The Gini coefficient for the model shown in Figure 9.12(a)[562] is 0.596, and the Gini coefficients for the four models shown in Figure 9.12(a)[562] are 0.992, 0.774, 0.527, and 0.190. The Gini coefficient is very commonly used in financial modeling scenarios such as credit scoring.",
            "zh": "åŸºå°¼ç³»æ•°å¯ä»¥å– [0,1] èŒƒå›´å†…çš„å€¼ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚å›¾9.12ï¼ˆaï¼‰[562]æ‰€ç¤ºæ¨¡å‹çš„åŸºå°¼ç³»æ•°ä¸º0.596ï¼Œå›¾9.12ï¼ˆaï¼‰[562]æ‰€ç¤ºçš„å››ä¸ªæ¨¡å‹çš„åŸºå°¼ç³»æ•°åˆ†åˆ«ä¸º0.992ã€0.774ã€0.527å’Œ0.190ã€‚åŸºå°¼ç³»æ•°éå¸¸å¸¸ç”¨äºä¿¡ç”¨è¯„åˆ†ç­‰é‡‘èå»ºæ¨¡åœºæ™¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "An extension of the standard support vector machine approach that allows a soft margin, however, caters for this and allows overlap between instances with target features of the two different levels.",
            "zh": "ç„¶è€Œï¼Œæ ‡å‡†æ”¯æŒå‘é‡æœºæ–¹æ³•çš„æ‰©å±•å…è®¸è½¯è£•é‡ï¼Œå¯ä»¥æ»¡è¶³è¿™ä¸€ç‚¹ï¼Œå¹¶å…è®¸å…·æœ‰ä¸¤ä¸ªä¸åŒçº§åˆ«ç›®æ ‡ç‰¹å¾çš„å®ä¾‹ä¹‹é—´é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "The units in all hidden layers use a rectified linear activation function.",
            "zh": "æ‰€æœ‰éšè—å±‚ä¸­çš„å•å…ƒéƒ½ä½¿ç”¨æ ¡æ­£çš„çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "An algorithm to learn decision trees for a continuous target can use the first two base cases.",
            "zh": "å­¦ä¹ è¿ç»­ç›®æ ‡å†³ç­–æ ‘çš„ç®—æ³•å¯ä»¥ä½¿ç”¨å‰ä¸¤ä¸ªåŸºæœ¬æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.6",
            "zh": "è¡¨ 3.6"
        }
    },
    {
        "translation": {
            "en": "The figure also illustrates the local receptive field of the first neuron in the grid; note that this receptive field includes imaginary pixels.",
            "zh": "è¯¥å›¾è¿˜è¯´æ˜äº†ç½‘æ ¼ä¸­ç¬¬ä¸€ä¸ªç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡;è¯·æ³¨æ„ï¼Œæ­¤æ„Ÿå—é‡åŒ…æ‹¬è™šåƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the decision to use deep learning has been made, the next decision is to choose the network architecture to use.",
            "zh": "ä¸€æ—¦å†³å®šä½¿ç”¨æ·±åº¦å­¦ä¹ ï¼Œä¸‹ä¸€ä¸ªå†³å®šå°±æ˜¯é€‰æ‹©è¦ä½¿ç”¨çš„ç½‘ç»œæ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the distribution of model outputs changes dramatically, for example, if a model that previously made positive predictions 80% of the time is suddenly making positive predictions only 20% of the time, then we can assume that there is a strong possibility that concept drift has occurred and that the model has gone stale.",
            "zh": "å¦‚æœæ¨¡å‹è¾“å‡ºçš„åˆ†å¸ƒå‘ç”Ÿäº†å·¨å¤§å˜åŒ–ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªæ¨¡å‹ä¹‹å‰åœ¨ 80% çš„æ—¶é—´é‡Œåšå‡ºäº†ç§¯æçš„é¢„æµ‹ï¼Œè€Œç°åœ¨åªæœ‰ 20% çš„æ—¶é—´åšå‡ºäº†ç§¯æçš„é¢„æµ‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å‡è®¾å¾ˆæœ‰å¯èƒ½å‘ç”Ÿäº†æ¦‚å¿µæ¼‚ç§»ï¼Œå¹¶ä¸”æ¨¡å‹å·²ç»è¿‡æ—¶äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "histogram, 54, 745, 752, 752",
            "zh": "ç›´æ–¹å›¾ï¼Œ 54ï¼Œ 745ï¼Œ 752ï¼Œ 752"
        }
    },
    {
        "translation": {
            "en": "Obviously, the competitor would not give the retailer this information, and so the analytics team at the retailer sought to find some proxy feature that would give them much the same information.",
            "zh": "æ˜¾ç„¶ï¼Œç«äº‰å¯¹æ‰‹ä¸ä¼šå‘é›¶å”®å•†æä¾›è¿™äº›ä¿¡æ¯ï¼Œå› æ­¤é›¶å”®å•†çš„åˆ†æå›¢é˜Ÿè¯•å›¾æ‰¾åˆ°ä¸€äº›ä»£ç†åŠŸèƒ½ï¼Œä¸ºä»–ä»¬æä¾›å¤§è‡´ç›¸åŒçš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activation vector created by this division a(l)â€²â€² is the activation vector propagated forward to the next layer.",
            "zh": "ç”±æ­¤åˆ’åˆ† aï¼ˆlï¼‰â€²â€² åˆ›å»ºçš„æ¿€æ´»å‘é‡æ˜¯å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€å±‚çš„æ¿€æ´»å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "38. This explanation of inverted dropout is inspired by a description given in Andrew Ngâ€™s Coursera course; the video is available at https://www.youtube.com/watch?v=D8PJAL-MZv8&feature=youtu.be.",
            "zh": "38. è¿™ç§å¯¹å€’ç½®è¾å­¦çš„è§£é‡Šçš„çµæ„Ÿæ¥è‡ªå´æ©è¾¾çš„ Coursera è¯¾ç¨‹ä¸­çš„æè¿°;è¯¥è§†é¢‘å¯åœ¨ https://www.youtube.com/watch?v=D8PJAL-MZv8&feature=youtu.be ä¸Šè§‚çœ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Vectors of Features",
            "zh": "ç‰¹å¾å‘é‡"
        }
    },
    {
        "translation": {
            "en": "John",
            "zh": "John"
        }
    },
    {
        "translation": {
            "en": "The overall measure of similarity could then be based on a weighted combination of the two.",
            "zh": "ç„¶åï¼Œç›¸ä¼¼æ€§çš„æ€»ä½“è¡¡é‡æ ‡å‡†å¯ä»¥åŸºäºä¸¤è€…çš„åŠ æƒç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Does a machine learning approach match the requirements of the project?",
            "zh": "1. æœºå™¨å­¦ä¹ æ–¹æ³•æ˜¯å¦ç¬¦åˆé¡¹ç›®çš„è¦æ±‚ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The units in the output layer use a sigmoid activation function.",
            "zh": "è¾“å‡ºå±‚ä¸­çš„å•ä½ä½¿ç”¨ S å½¢æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification decision tree after the dataset has been split using ELEVATION â‰¥ 4,175.",
            "zh": "ä½¿ç”¨ ELEVATION â‰¥ 4,175 åˆ†å‰²æ•°æ®é›†åçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sarahâ€™s training for the stepping-stone challenge has many of the characteristics of a reinforcement learning problem.",
            "zh": "Sarah çš„å«è„šçŸ³æŒ‘æˆ˜è®­ç»ƒå…·æœ‰å¼ºåŒ–å­¦ä¹ é—®é¢˜çš„è®¸å¤šç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values for d1 are SMS = 97 and VOICE = 21, and for d2 are SMS = 181 and VOICE = 184.",
            "zh": "d1 çš„æè¿°æ€§ç‰¹å¾å€¼ä¸º SMS = 97 å’Œ VOICE = 21ï¼Œd2 çš„æè¿°æ€§ç‰¹å¾å€¼ä¸º SMS = 181 å’Œ VOICE = 184ã€‚"
        }
    },
    {
        "translation": {
            "en": "This introduces the second art of reinforcement learning: the design of effective reward functions.",
            "zh": "è¿™å¼•å…¥äº†å¼ºåŒ–å­¦ä¹ çš„ç¬¬äºŒç§è‰ºæœ¯ï¼šæœ‰æ•ˆå¥–åŠ±å‡½æ•°çš„è®¾è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Segata, N., E. Blanzieri, S. J. Delany, and Padraig Cunningham. 2009. Noise reduction for instance-based learning with a local maximal margin approach. Journal of Intelligent Information Systems 35: 301â€“331.",
            "zh": "Segataï¼Œ N.ã€E. Blanzieriã€SJ Delany å’Œ Padraig Cunninghamã€‚2009. åŸºäºå®ä¾‹çš„å­¦ä¹ çš„é™å™ªä¸å±€éƒ¨æœ€å¤§è¾¹è·æ–¹æ³•.æ™ºèƒ½ä¿¡æ¯ç³»ç»Ÿæ‚å¿— 35ï¼š301â€“331ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) On the basis of the silhouette, would you choose 2 or 3 for the value of k for this dataset?",
            "zh": "ï¼ˆcï¼‰ æ ¹æ®è½®å»“ï¼Œæ‚¨ä¼šé€‰æ‹© 2 è¿˜æ˜¯ 3 ä½œä¸ºè¯¥æ•°æ®é›†çš„ k å€¼ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Also, all our filter examples so far have been two-dimensional filters.",
            "zh": "æ­¤å¤–ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ‰€æœ‰çš„è¿‡æ»¤å™¨ç¤ºä¾‹éƒ½æ˜¯äºŒç»´è¿‡æ»¤å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "silhouette plot, 610",
            "zh": "å‰ªå½±å›¾ï¼Œ610"
        }
    },
    {
        "translation": {
            "en": "The plot of activation values directly mirrors the plot of the z values because the neurons are using a linear activation function.",
            "zh": "æ¿€æ´»å€¼çš„å›¾ç›´æ¥åæ˜ äº† z å€¼çš„å›¾ï¼Œå› ä¸ºç¥ç»å…ƒä½¿ç”¨çš„æ˜¯çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, given a dataset representing a domain with two target levels C1 and C2, an arbitrary instance from the domain should be classified as being associated with target level C1 with the probability and to target level C2 with the probability , where |C1| and |C2| refer to the number of instances in associated with C1 and C2, respectively.",
            "zh": "å› æ­¤ï¼Œç»™å®šä¸€ä¸ªæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†è¡¨ç¤ºå…·æœ‰ä¸¤ä¸ªç›®æ ‡çº§åˆ« C1 å’Œ C2 çš„åŸŸï¼ŒåŸŸä¸­çš„ä»»æ„å®ä¾‹åº”åˆ†ç±»ä¸ºä¸ç›®æ ‡çº§åˆ« C1 ç›¸å…³è”ï¼Œæ¦‚ç‡ä¸ç›®æ ‡çº§åˆ« C2 ç›¸å…³è”ï¼Œå…¶ä¸­ |C1|ä»¥åŠ |C2|åˆ†åˆ«æŒ‡ä¸ C1 å’Œ C2 å…³è”çš„å®ä¾‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the continuous HEIGHT feature and the target feature TACHYCARDIA.",
            "zh": "ï¼ˆbï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†è¿ç»­ HEIGHT ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾å¿ƒåŠ¨è¿‡é€Ÿä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "SMARTPHONE",
            "zh": "æ™ºèƒ½æ‰‹æœº"
        }
    },
    {
        "translation": {
            "en": "Goodfellow et al.",
            "zh": "Goodfellowç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov, Andrei Nikolaevich. 1963. On the representation of continuous functions of several variables by superpositions of continuous functions of one variable and addition. American Mathematical Society Translations.",
            "zh": "ç§‘å°”è«æˆˆç½—å¤«ï¼Œå®‰å¾·çƒˆÂ·å°¼å¤æ‹‰è€¶ç»´å¥‡ã€‚1963. å…³äºé€šè¿‡ä¸€ä¸ªå˜é‡çš„è¿ç»­å‡½æ•°çš„å åŠ å’ŒåŠ æ³•æ¥è¡¨ç¤ºå¤šä¸ªå˜é‡çš„è¿ç»­å‡½æ•°.ç¾å›½æ•°å­¦å­¦ä¼šç¿»è¯‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dashed circle centered on the query location has a radius equal to the best-distance.",
            "zh": "ä»¥æŸ¥è¯¢ä½ç½®ä¸ºä¸­å¿ƒçš„è™šçº¿åœ†çš„åŠå¾„ç­‰äºæœ€ä½³è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dashed lines plot the axes of the coordinate system, and the ellipses plot the 1, 3, and 5 unit distance contours.",
            "zh": "è™šçº¿ç»˜åˆ¶åæ ‡ç³»çš„è½´ï¼Œæ¤­åœ†ç»˜åˆ¶ 1ã€3 å’Œ 5 å•ä½è·ç¦»ç­‰å€¼çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "That said, there are some other features of this plot that are encouraging.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªæƒ…èŠ‚è¿˜æœ‰ä¸€äº›å…¶ä»–ç‰¹ç‚¹æ˜¯ä»¤äººé¼“èˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "These three functions have the same structure; they all take two inputs that can be either TRUE or FALSE, and they return either TRUE or FALSE.",
            "zh": "è¿™ä¸‰ä¸ªå‡½æ•°å…·æœ‰ç›¸åŒçš„ç»“æ„;å®ƒä»¬éƒ½æ¥å—ä¸¤ä¸ªå¯ä»¥æ˜¯ TRUE æˆ– FALSE çš„è¾“å…¥ï¼Œå¹¶è¿”å› TRUE æˆ– FALSEã€‚"
        }
    },
    {
        "translation": {
            "en": "State can be represented as a stack of the last 4 frames in the game.",
            "zh": "çŠ¶æ€å¯ä»¥è¡¨ç¤ºä¸ºæ¸¸æˆä¸­æœ€å 4 å¸§çš„å †æ ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.4",
            "zh": "è¡¨ 4.4"
        }
    },
    {
        "translation": {
            "en": "This characteristic is useful in the generation of performance measures like the F1 measure, as we typically prefer measures to highlight shortcomings in our models rather than hide them.",
            "zh": "æ­¤ç‰¹æ€§åœ¨ç”Ÿæˆæ€§èƒ½åº¦é‡ï¼ˆå¦‚ F1 åº¦é‡ï¼‰æ—¶å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸æ›´å–œæ¬¢çªå‡ºæ¨¡å‹ä¸­çš„ç¼ºç‚¹è€Œä¸æ˜¯éšè—å®ƒä»¬çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that in both figures, the normal distribution plotted with the continuous black line has mean Î¼ = 0 and standard deviation Ïƒ = 1.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨è¿™ä¸¤ä¸ªå›¾ä¸­ï¼Œç”¨è¿ç»­é»‘çº¿ç»˜åˆ¶çš„æ­£æ€åˆ†å¸ƒå‡å€¼ Î¼ = 0ï¼Œæ ‡å‡†å·® Ïƒ = 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data with which to implement features based on these domain concepts would likely come from the raw camera imaging and spectrograph images themselves, or from the results of the SDSS processing pipeline.",
            "zh": "åŸºäºè¿™äº›é¢†åŸŸæ¦‚å¿µå®ç°åŠŸèƒ½çš„æ•°æ®å¯èƒ½æ¥è‡ªåŸå§‹ç›¸æœºæˆåƒå’Œå…‰è°±ä»ªå›¾åƒæœ¬èº«ï¼Œæˆ–è€…æ¥è‡ª SDSS å¤„ç†ç®¡é“çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "1.1â€…â€…â€…Predictive data analytics moving from data to insight to decision.",
            "zh": "1.1 é¢„æµ‹æ€§æ•°æ®åˆ†æä»æ•°æ®åˆ°æ´å¯Ÿå†åˆ°å†³ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "An alternative approach to using small multiples to visualize the relationship between a categorical feature and a continuous feature is to use a collection of box plots.",
            "zh": "ä½¿ç”¨å°å€æ•°å¯è§†åŒ–åˆ†ç±»è¦ç´ å’Œè¿ç»­è¦ç´ ä¹‹é—´å…³ç³»çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ç®±å½¢å›¾é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 11.2",
            "zh": "è¡¨ 11.2"
        }
    },
    {
        "translation": {
            "en": "model-free reinforcement learning, 657, 676",
            "zh": "æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼Œ 657ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Figure 8.28[470] illustrates the forward pass for this mini-batch through this network.",
            "zh": "å›¾ 8.28[470] è¯´æ˜äº†è¯¥å°æ‰¹æ¬¡é€šè¿‡è¯¥ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental element in an LSTM network is the cell.",
            "zh": "LSTM ç½‘ç»œä¸­çš„åŸºæœ¬å…ƒç´ æ˜¯å°åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "A.7â€…â€…(a) and (b) frequency histograms and (c) and (d) density histograms for the continuous TRAINING EXPENSES feature from Table A.1[750], illustrating how using intervals overcomes the problem seen in Figure A.6[753] and the effect of varying interval sizes.",
            "zh": "è¡¨A.1[750]ä¸­è¿ç»­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„A.7ï¼ˆaï¼‰å’Œï¼ˆbï¼‰é¢‘ç‡ç›´æ–¹å›¾ä»¥åŠï¼ˆcï¼‰å’Œï¼ˆdï¼‰å¯†åº¦ç›´æ–¹å›¾ï¼Œè¯´æ˜äº†ä½¿ç”¨é—´éš”å¦‚ä½•å…‹æœå›¾A.6[753]ä¸­çš„é—®é¢˜ä»¥åŠä¸åŒé—´éš”å¤§å°çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This step defines the set of prediction models the machine learning algorithm will search.",
            "zh": "æ­¤æ­¥éª¤å®šä¹‰æœºå™¨å­¦ä¹ ç®—æ³•å°†æœç´¢çš„é¢„æµ‹æ¨¡å‹é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "26. By unbounded, we mean that, unlike the logistic function where the maximum value it will return is 1, the rectifier linear function may return any value up to + âˆ.",
            "zh": "26. æˆ‘ä»¬æ‰€è¯´çš„æ— ç•Œï¼Œæ˜¯æŒ‡ï¼Œä¸é€»è¾‘å‡½æ•°ä¸åŒï¼Œé€»è¾‘å‡½æ•°å°†è¿”å›çš„æœ€å¤§å€¼ä¸º 1ï¼Œæ•´æµå™¨çº¿æ€§å‡½æ•°å¯ä»¥è¿”å›é«˜è¾¾ + âˆ çš„ä»»ä½•å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, color images typically encode three types of information for each pixelâ€”the red, green and blue information, with other colors generated via the combination of these three primary colors.",
            "zh": "ä½†æ˜¯ï¼Œå½©è‰²å›¾åƒé€šå¸¸å¯¹æ¯ä¸ªåƒç´ çš„ä¸‰ç§ç±»å‹çš„ä¿¡æ¯è¿›è¡Œç¼–ç  - çº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ä¿¡æ¯ï¼Œå…¶ä»–é¢œè‰²é€šè¿‡è¿™ä¸‰ç§åŸè‰²çš„ç»„åˆç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The final model is then a model that makes a basic prediction and adds a number of improvements to this prediction. We can see this if we consider the model trained after four iterations of gradient boosting33",
            "zh": "ç„¶åï¼Œæœ€ç»ˆæ¨¡å‹æ˜¯ä¸€ä¸ªè¿›è¡ŒåŸºæœ¬é¢„æµ‹çš„æ¨¡å‹ï¼Œå¹¶å¯¹è¯¥é¢„æµ‹è¿›è¡Œäº†è®¸å¤šæ”¹è¿›ã€‚å¦‚æœæˆ‘ä»¬è€ƒè™‘åœ¨æ¢¯åº¦æå‡çš„å››æ¬¡è¿­ä»£åè®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸€ç‚¹33"
        }
    },
    {
        "translation": {
            "en": "The reason we perform this division by Ï is to scale up the non-zero activations in the new activation vector so that the weighted sum calculations in the next layer are of a similar magnitude to what they would have been if none of the activations had been set to 0.",
            "zh": "æˆ‘ä»¬æŒ‰ Ï è¿›è¡Œé™¤æ³•çš„åŸå› æ˜¯ä¸ºäº†æ”¾å¤§æ–°æ¿€æ´»å‘é‡ä¸­çš„éé›¶æ¿€æ´»ï¼Œä»¥ä¾¿ä¸‹ä¸€å±‚ä¸­çš„åŠ æƒå’Œè®¡ç®—ä¸æ²¡æœ‰æ¿€æ´»è®¾ç½®ä¸º 0 æ—¶çš„å¤§å°ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rossâ€™s previous discussions with Grace, the AT CTO, had established that the data required to build a churn prediction model were likely to be available and reasonably easily accessible.",
            "zh": "Ross ä¹‹å‰ä¸ AT é¦–å¸­æŠ€æœ¯å®˜ Grace çš„è®¨è®ºå·²ç»ç¡®å®šï¼Œæ„å»ºå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ•°æ®å¾ˆå¯èƒ½æ˜¯å¯ç”¨çš„ï¼Œå¹¶ä¸”ç›¸å½“å®¹æ˜“è®¿é—®ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. See the discussion in Section 2.1[23] relating to data availability, data connections, data granularity, data volume, and data time horizons.",
            "zh": "2. è¯·å‚é˜…ç¬¬ 2.1 èŠ‚[23]ä¸­æœ‰å…³æ•°æ®å¯ç”¨æ€§ã€æ•°æ®è¿æ¥ã€æ•°æ®ç²’åº¦ã€æ•°æ®é‡å’Œæ•°æ®æ—¶é—´èŒƒå›´çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "2nd New",
            "zh": "ç¬¬ 2 ä¸ªæ–°å“"
        }
    },
    {
        "translation": {
            "en": "noise dampening mechanism, 157",
            "zh": "é™å™ªæœºæ„ï¼Œ157"
        }
    },
    {
        "translation": {
            "en": "Both of these phenomena are a consequence of the fact that we are applying the filter only to valid pixels in the image.",
            "zh": "è¿™ä¸¤ç§ç°è±¡éƒ½æ˜¯ç”±äºæˆ‘ä»¬ä»…å°†æ»¤é•œåº”ç”¨äºå›¾åƒä¸­çš„æœ‰æ•ˆåƒç´ è¿™ä¸€äº‹å®çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Weights are also known as model parameters, and so regression models are often known as parameterized models.",
            "zh": "1. æƒé‡ä¹Ÿç§°ä¸ºæ¨¡å‹å‚æ•°ï¼Œå› æ­¤å›å½’æ¨¡å‹é€šå¸¸ç§°ä¸ºå‚æ•°åŒ–æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sejnowski, Terrence J. 2018. The deep learning revolution. MIT Press.",
            "zh": "Sejnowskiï¼ŒTerrence J. 2018 å¹´ã€‚æ·±åº¦å­¦ä¹ é©å‘½ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If it is, best and best-distance are updated to reflect this (Lines 5, 6, and 7).",
            "zh": "å¦‚æœæ˜¯ï¼Œåˆ™æ›´æ–°æœ€ä½³å’Œæœ€ä½³è·ç¦»ä»¥åæ˜ è¿™ä¸€ç‚¹ï¼ˆç¬¬ 5ã€6 å’Œ 7 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "With regard to defining the outcome period, the company agreed that it would be most useful to make a prediction that a customer was likely to churn three months before the churn event took place, as this gave them time to take retention actions.",
            "zh": "å…³äºå®šä¹‰ç»“æœæœŸï¼Œè¯¥å…¬å¸ä¸€è‡´è®¤ä¸ºï¼Œåœ¨å®¢æˆ·æµå¤±äº‹ä»¶å‘ç”Ÿå‰ä¸‰ä¸ªæœˆé¢„æµ‹å®¢æˆ·å¯èƒ½ä¼šæµå¤±æ˜¯æœ€æœ‰ç”¨çš„ï¼Œå› ä¸ºè¿™ç»™äº†ä»–ä»¬æ—¶é—´é‡‡å–ä¿ç•™æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "These error gradients can then be used by the gradient descent weight update rule to update the weights for each neuron.",
            "zh": "ç„¶åï¼Œæ¢¯åº¦ä¸‹é™æƒé‡æ›´æ–°è§„åˆ™å¯ä»¥ä½¿ç”¨è¿™äº›è¯¯å·®æ¢¯åº¦æ¥æ›´æ–°æ¯ä¸ªç¥ç»å…ƒçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m + 1 descriptive features, d[0]â€¦d[m]; and w[0]â€¦w[m] are (m + 1) weights. However, no matter which way we choose to define the weighted sum, the operation remains the same.",
            "zh": "å…¶ä¸­ d æ˜¯ m + 1 ä¸ªæè¿°æ€§ç‰¹å¾çš„å‘é‡ï¼Œd[0]...d[m];å’Œ w[0]...w[m] æ˜¯ ï¼ˆm + 1ï¼‰ æƒé‡ã€‚ä½†æ˜¯ï¼Œæ— è®ºæˆ‘ä»¬é€‰æ‹©å“ªç§æ–¹å¼å®šä¹‰åŠ æƒå’Œï¼Œæ“ä½œéƒ½ä¿æŒä¸å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the same way we used basis functions with logistic regression models in Section 7.4.5[351], basis functions can be used with support vector machines to handle training data that is not linearly separable. In order to use basis functions, we must update Equation (7.44)[364] to",
            "zh": "å°±åƒæˆ‘ä»¬åœ¨ç¬¬7.4.5èŠ‚[351]ä¸­å°†åŸºå‡½æ•°ä¸é€»è¾‘å›å½’æ¨¡å‹ä¸€èµ·ä½¿ç”¨ä¸€æ ·ï¼ŒåŸºå‡½æ•°å¯ä»¥ä¸æ”¯æŒå‘é‡æœºä¸€èµ·ä½¿ç”¨ï¼Œä»¥å¤„ç†ä¸å¯çº¿æ€§åˆ†ç¦»çš„è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†ä½¿ç”¨åŸºå‡½æ•°ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ–¹ç¨‹ï¼ˆ7.44ï¼‰[364]æ›´æ–°ä¸º"
        }
    },
    {
        "translation": {
            "en": "Logistic Regression",
            "zh": "é€»è¾‘å›å½’"
        }
    },
    {
        "translation": {
            "en": "For continuous target features, the median is preferred to the mean because the mean is more heavily affected by outliers.27",
            "zh": "å¯¹äºè¿ç»­ç›®æ ‡ç‰¹å¾ï¼Œä¸­ä½æ•°ä¼˜äºå‡å€¼ï¼Œå› ä¸ºå‡å€¼å—å¼‚å¸¸å€¼çš„å½±å“æ›´å¤§27ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is not always the case.",
            "zh": "ä½†æƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.13",
            "zh": "è¡¨ 4.13"
        }
    },
    {
        "translation": {
            "en": "Sometimes a blend of Xavier and He initialization is used.",
            "zh": "æœ‰æ—¶ä½¿ç”¨ Xavier å’Œ He åˆå§‹åŒ–çš„æ··åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "To begin the backpropagation process through the convolutional layer, we assume that the Î´s for the neurons D and E have already been calculated. We can now calculate the Î´ for Neuron C",
            "zh": "ä¸ºäº†å¼€å§‹é€šè¿‡å·ç§¯å±‚çš„åå‘ä¼ æ’­è¿‡ç¨‹ï¼Œæˆ‘ä»¬å‡è®¾å·²ç»è®¡ç®—äº†ç¥ç»å…ƒ D å’Œ E çš„ Î´ã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥è®¡ç®—ç¥ç»å…ƒ C çš„Î´"
        }
    },
    {
        "translation": {
            "en": "However, a modified version of this weight initialization heuristic is recommended when the network uses rectified linear units (He et al., 2015).",
            "zh": "ç„¶è€Œï¼Œå½“ç½‘ç»œä½¿ç”¨æ•´æµçº¿æ€§å•å…ƒæ—¶ï¼Œå»ºè®®ä½¿ç”¨è¿™ç§æƒé‡åˆå§‹åŒ–å¯å‘å¼çš„ä¿®æ”¹ç‰ˆæœ¬ï¼ˆHe et al.ï¼Œ 2015ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.42[516] indicates the flow of error gradients back through the elementwise product in the output gate by labeling each path emerging from the operation with its respective error gradient vector: âˆ‚â„°/âˆ‚oâ€¡ and âˆ‚â„°/âˆ‚oâ€¡, respectively.",
            "zh": "å›¾ 8.42[516] é€šè¿‡åˆ†åˆ«ç”¨å…¶å„è‡ªçš„è¯¯å·®æ¢¯åº¦å‘é‡æ ‡è®°æ“ä½œä¸­å‡ºç°çš„æ¯æ¡è·¯å¾„ï¼šâˆ‚E/âˆ‚oâ€¡ å’Œ âˆ‚E/âˆ‚oâ€¡ï¼Œæ¥æŒ‡ç¤ºè¯¯å·®æ¢¯åº¦æµå›è¾“å‡ºé—¨ä¸­çš„é€å…ƒä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Learning requires an opportunity to explore as well as to exploit.",
            "zh": "å­¦ä¹ éœ€è¦ä¸€ä¸ªæ¢ç´¢å’Œåˆ©ç”¨çš„æœºä¼šã€‚"
        }
    },
    {
        "translation": {
            "en": "percentiles, 54, 91, 567, 748",
            "zh": "ç™¾åˆ†ä½æ•°ï¼Œ 54ï¼Œ 91ï¼Œ 567ï¼Œ 748"
        }
    },
    {
        "translation": {
            "en": "A schematic of a feedforward artificial neural network with a three-neuron softmax output layer.",
            "zh": "å…·æœ‰ä¸‰ç¥ç»å…ƒsoftmaxè¾“å‡ºå±‚çš„å‰é¦ˆäººå·¥ç¥ç»ç½‘ç»œç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 9.18(b)[582] and 9.18(c)[582] show the target distributions for the two points in time after deployment for which the stability index is to be calculated.",
            "zh": "å›¾9.18ï¼ˆbï¼‰[582]å’Œå›¾9.18ï¼ˆcï¼‰[582]æ˜¾ç¤ºäº†éƒ¨ç½²åä¸¤ä¸ªæ—¶é—´ç‚¹çš„ç›®æ ‡åˆ†å¸ƒï¼Œè¿™äº›æ—¶é—´ç‚¹å°†è®¡ç®—ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.5.1â€ƒSimilarity indexes for binary descriptive featuresâ€ƒThere are lots of datasets that contain binary descriptive featuresâ€”categorical features that have only two levels.",
            "zh": "5.4.5.1 äºŒå…ƒæè¿°æ€§ç‰¹å¾çš„ç›¸ä¼¼æ€§ç´¢å¼• æœ‰è®¸å¤šæ•°æ®é›†åŒ…å«äºŒå…ƒæè¿°æ€§ç‰¹å¾ï¼Œå³åªæœ‰ä¸¤ä¸ªçº§åˆ«çš„åˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the end of the chapter, unsupervised machine learning for feature generation will be discussed.",
            "zh": "åœ¨æœ¬ç« çš„æœ€åï¼Œå°†è®¨è®ºç”¨äºç‰¹å¾ç”Ÿæˆçš„æ— ç›‘ç£æœºå™¨å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "equivariant, 483",
            "zh": "ç­‰å˜é‡ï¼Œ483"
        }
    },
    {
        "translation": {
            "en": "Jocelyn discussed this issue and the results of these two baseline experiments with Edwin, and both decided that it would be best to pursue the optimal performance measured by overall classification accuracy because, in practice, the important thing for the SDSS system was to classify elliptical and spiral galaxies as accurately as possible.",
            "zh": "Jocelyn ä¸ Edwin è®¨è®ºäº†è¿™ä¸ªé—®é¢˜ä»¥åŠè¿™ä¸¤ä¸ªåŸºçº¿å®éªŒçš„ç»“æœï¼Œä¸¤äººéƒ½è®¤ä¸ºæœ€å¥½è¿½æ±‚é€šè¿‡æ•´ä½“åˆ†ç±»ç²¾åº¦æ¥è¡¡é‡çš„æœ€ä½³æ€§èƒ½ï¼Œå› ä¸ºåœ¨å®è·µä¸­ï¼ŒSDSS ç³»ç»Ÿçš„é‡è¦äº‹æƒ…æ˜¯å°½å¯èƒ½å‡†ç¡®åœ°å¯¹æ¤­åœ†æ˜Ÿç³»å’Œèºæ—‹æ˜Ÿç³»è¿›è¡Œåˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This new discovery caused ripples of great excitement in the international physics community and greatly enhanced the reputations of the lab at Nancy and Professor Blondlot.",
            "zh": "è¿™ä¸€æ–°å‘ç°åœ¨å›½é™…ç‰©ç†å­¦ç•Œå¼•èµ·äº†æå¤§çš„å…´å¥‹ï¼Œå¹¶å¤§å¤§æé«˜äº†å—å¸Œå®éªŒå®¤å’Œå¸ƒéš†å¾·æ´›ç‰¹æ•™æˆçš„å£°èª‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Only when you are positioned at the sweet spot in the middle of the boardâ€”neither too far forward nor too far backâ€”will you be able to use your paddling efforts to successfully catch a wave.",
            "zh": "åªæœ‰å½“ä½ è¢«å®šä½åœ¨å†²æµªæ¿ä¸­é—´çš„æœ€ä½³ä½ç½®æ—¶â€”â€”æ—¢ä¸è¦å¤ªé å‰ï¼Œä¹Ÿä¸è¦å¤ªé åâ€”â€”ä½ æ‰èƒ½åˆ©ç”¨ä½ çš„åˆ’æ¡¨åŠªåŠ›æˆåŠŸåœ°èµ¶ä¸Šä¸€ä¸ªæ³¢æµªã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5[124] shows a collection of sets of playing cards of contrasting entropy.",
            "zh": "å›¾4.5[124]æ˜¾ç¤ºäº†ä¸€ç»„å¯¹æ¯”ç†µçš„æ‰‘å…‹ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For some modeling approaches this is quite easy, while for others it is almost impossible to adapt a model, and the only option is to discard the current model and train a new one using an updated dataset.",
            "zh": "å¯¹äºæŸäº›å»ºæ¨¡æ–¹æ³•æ¥è¯´ï¼Œè¿™å¾ˆå®¹æ˜“ï¼Œè€Œå¯¹äºå…¶ä»–æ–¹æ³•æ¥è¯´ï¼Œå‡ ä¹ä¸å¯èƒ½è°ƒæ•´æ¨¡å‹ï¼Œå”¯ä¸€çš„é€‰æ‹©æ˜¯ä¸¢å¼ƒå½“å‰æ¨¡å‹å¹¶ä½¿ç”¨æ›´æ–°çš„æ•°æ®é›†è®­ç»ƒæ–°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that the intuitive clusters in the other two datasets do not conform to the assumption of spherical clusters that underlies the k-means clustering algorithm.",
            "zh": "åŸå› æ˜¯å…¶ä»–ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„ç›´è§‚èšç±»ä¸ç¬¦åˆçƒå½¢èšç±»çš„å‡è®¾ï¼Œè€Œçƒå½¢èšç±»æ˜¯ k å‡å€¼èšç±»ç®—æ³•çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the if statement on Line 5 succeeds, and best is set to d21, and best-distance is set to 0.9014 (Lines 6 and 7).",
            "zh": "å› æ­¤ï¼Œç¬¬ 5 è¡Œçš„ if è¯­å¥æˆåŠŸï¼Œbest è®¾ç½®ä¸º d21ï¼Œbest distance è®¾ç½®ä¸º 0.9014ï¼ˆç¬¬ 6 è¡Œå’Œç¬¬ 7 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examples of continuous functions (shown as solid lines) and their derivatives (shown as dashed lines).",
            "zh": "è¿ç»­å‡½æ•°ï¼ˆæ˜¾ç¤ºä¸ºå®çº¿ï¼‰åŠå…¶å¯¼æ•°ï¼ˆæ˜¾ç¤ºä¸ºè™šçº¿ï¼‰çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the customers in the treatment group, the company applied the process using the predictive model to determine which customers to contact regarding customer satisfaction.",
            "zh": "å¯¹äºæ²»ç–—ç»„ä¸­çš„å®¢æˆ·ï¼Œè¯¥å…¬å¸ä½¿ç”¨é¢„æµ‹æ¨¡å‹åº”ç”¨è¯¥è¿‡ç¨‹æ¥ç¡®å®šè¦è”ç³»å“ªäº›å®¢æˆ·äº†è§£å®¢æˆ·æ»¡æ„åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are also a number of different ways in which evaluation experiments can be performed, as described in Section 9.4.1[540].",
            "zh": "è¿˜æœ‰è®¸å¤šä¸åŒçš„æ–¹æ³•å¯ä»¥è¿›è¡Œè¯„ä¼°å®éªŒï¼Œå¦‚ç¬¬9.4.1èŠ‚[540]æ‰€è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Categorical: A finite set of values that cannot be ordered and allow no arithmetic (e.g., country, product type)",
            "zh": "åˆ†ç±»ï¼šä¸€ç»„æœ‰é™çš„å€¼ï¼Œä¸èƒ½æ’åºï¼Œä¹Ÿä¸å…è®¸ç®—æœ¯ï¼ˆä¾‹å¦‚ï¼Œå›½å®¶/åœ°åŒºã€äº§å“ç±»å‹ï¼‰"
        }
    },
    {
        "translation": {
            "en": "3.12â€…â€…â€…Anscombeâ€™s quartet. For all four samples, the correlation measure returns the same value (0.816) even though the relationship between the features is very different in each case.",
            "zh": "3.12 å®‰æ–¯ç§‘å§†çš„å››é‡å¥ã€‚å¯¹äºæ‰€æœ‰å››ä¸ªæ ·æœ¬ï¼Œç›¸å…³åº¦é‡è¿”å›ç›¸åŒçš„å€¼ ï¼ˆ0.816ï¼‰ï¼Œå°½ç®¡æ¯ç§æƒ…å†µä¸‹ç‰¹å¾ä¹‹é—´çš„å…³ç³»éƒ½éå¸¸ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "In loan default prediction, the likelihood that an applicant will default on a loan is predicted based on the information the applicant provides on the application form.",
            "zh": "åœ¨è´·æ¬¾è¿çº¦é¢„æµ‹ä¸­ï¼Œç”³è¯·äººæ‹–æ¬ è´·æ¬¾çš„å¯èƒ½æ€§æ˜¯æ ¹æ®ç”³è¯·äººåœ¨ç”³è¯·è¡¨ä¸Šæä¾›çš„ä¿¡æ¯æ¥é¢„æµ‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is somewhat surprising how often a linear multivariable regression model can accurately represent the relationship between descriptive features and a target feature without the use of basis functions. We recommend that simple linear models be evaluated first and basis functions introduced only when the performance of the simpler models is deemed unsatisfactory.",
            "zh": "ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œçº¿æ€§å¤šå˜é‡å›å½’æ¨¡å‹åœ¨ä¸ä½¿ç”¨åŸºå‡½æ•°çš„æƒ…å†µä¸‹å¯ä»¥å‡†ç¡®è¡¨ç¤ºæè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚æˆ‘ä»¬å»ºè®®é¦–å…ˆè¯„ä¼°ç®€å•çš„çº¿æ€§æ¨¡å‹ï¼Œåªæœ‰åœ¨è®¤ä¸ºç®€å•æ¨¡å‹çš„æ€§èƒ½ä¸ä»¤äººæ»¡æ„æ—¶æ‰å¼•å…¥åŸºå‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.32â€…â€…â€…A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a different receptive field from the neuron in Figure 8.31[480].",
            "zh": "8.32 å›¾ 4 çš„ç°åº¦å›¾åƒçš„ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠä¸å›¾ 8.31 [480] ä¸­ç¥ç»å…ƒå…·æœ‰ä¸åŒæ„Ÿå—é‡çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "5.5â€…â€…â€…A dataset listing salary and age information for customers and whether they purchased a product.",
            "zh": "5.5 åˆ—å‡ºå®¢æˆ·å·¥èµ„å’Œå¹´é¾„ä¿¡æ¯ä»¥åŠä»–ä»¬æ˜¯å¦è´­ä¹°äº§å“çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.4â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "3.3.4 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "1. In the notation used in this book, d1 refers to the instance in a dataset with an ID of 1, and so on.",
            "zh": "1. åœ¨æœ¬ä¹¦ä½¿ç”¨çš„ç¬¦å·ä¸­ï¼Œd1 æŒ‡çš„æ˜¯ ID ä¸º 1 çš„æ•°æ®é›†ä¸­çš„å®ä¾‹ï¼Œä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "We also take the opportunity to introduce the use of data normalization and feature selection in the context of similarity-based learning.",
            "zh": "æˆ‘ä»¬è¿˜å€Ÿæ­¤æœºä¼šä»‹ç»äº†åœ¨åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ èƒŒæ™¯ä¸‹ä½¿ç”¨æ•°æ®è§„èŒƒåŒ–å’Œç‰¹å¾é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Non-Parametric",
            "zh": "éå‚æ•°"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "è¡¨4.3[136]ä¸­æ•°æ®é›†çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.14[625] shows the architecture of a typical auto-encoder network.",
            "zh": "å›¾10.14[625]æ˜¾ç¤ºäº†å…¸å‹è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œçš„æ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the abs() function returns the absolute value. For example, the Manhattan distance between instances d12 (SPEED = 5.00, AGILITY = 2.50) and d5 (SPEED = 2.75, AGILITY = 7.50) in Table 5.2[183] is",
            "zh": "å…¶ä¸­ absï¼ˆï¼‰ å‡½æ•°è¿”å›ç»å¯¹å€¼ã€‚ä¾‹å¦‚ï¼Œè¡¨ 5.2[183] ä¸­çš„å®ä¾‹ d12 ï¼ˆSPEED = 5.00ï¼Œ AGILITY = 2.50ï¼‰ å’Œ d5 ï¼ˆSPEED = 2.75ï¼Œ AGILITY = 7.50ï¼‰ ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦»ä¸º"
        }
    },
    {
        "translation": {
            "en": "residual, 315",
            "zh": "æ®‹å·®ï¼Œ315"
        }
    },
    {
        "translation": {
            "en": "The values for the new categorical feature are then created by assigning to instances in the dataset the level of the new feature that corresponds to the range that their value of the continuous feature falls into.",
            "zh": "ç„¶åï¼Œé€šè¿‡å°†æ–°ç‰¹å¾çš„çº§åˆ«åˆ†é…ç»™æ•°æ®é›†ä¸­çš„å®ä¾‹æ¥åˆ›å»ºæ–°åˆ†ç±»ç‰¹å¾çš„å€¼ï¼Œè¯¥çº§åˆ«å¯¹åº”äºå…¶è¿ç»­ç‰¹å¾å€¼æ‰€å±çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 3[200] lists the algorithm we use to retrieve the nearest neighbor for a query.",
            "zh": "ç®—æ³•3[200]åˆ—å‡ºäº†æˆ‘ä»¬ç”¨æ¥æ£€ç´¢æŸ¥è¯¢çš„æœ€è¿‘é‚»çš„ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kelleher (2019) provides an overview of the history of deep learning that highlights the major developments in the field and the trends that are driving its adoption across a broad range of domains, and it discusses likely future developments in the field.",
            "zh": "Kelleherï¼ˆ2019ï¼‰æ¦‚è¿°äº†æ·±åº¦å­¦ä¹ çš„å†å²ï¼Œçªå‡ºäº†è¯¥é¢†åŸŸçš„ä¸»è¦å‘å±•ä»¥åŠæ¨åŠ¨å…¶åœ¨å¹¿æ³›é¢†åŸŸé‡‡ç”¨çš„è¶‹åŠ¿ï¼Œå¹¶è®¨è®ºäº†è¯¥é¢†åŸŸæœªæ¥å¯èƒ½çš„å‘å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "regularization, 477",
            "zh": "æ­£åˆ™åŒ–ï¼Œ 477"
        }
    },
    {
        "translation": {
            "en": "The numbers along the arrows in Figure 11.2[644] show the probabilities of moving between the different sates in this model.",
            "zh": "å›¾11.2[644]ä¸­ç®­å¤´æ²¿çº¿çš„æ•°å­—æ˜¾ç¤ºäº†è¯¥æ¨¡å‹ä¸­ä¸åŒä½ç½®ä¹‹é—´ç§»åŠ¨çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The result of this calculation is âˆ’ 0.6668.",
            "zh": "è®¡ç®—ç»“æœä¸ºâˆ’ 0.6668ã€‚"
        }
    },
    {
        "translation": {
            "en": "Apart from the advantage of descending the true error gradient for the entire dataset, batch gradient descent is also able to take advantage of the fact that a neural network, implemented as a sequence of matrix operations, can process multiple examples in parallel (as illustrated by Figure 8.6[393] and Figure 8.9[399]).",
            "zh": "é™¤äº†å¯¹æ•´ä¸ªæ•°æ®é›†çš„çœŸå®è¯¯å·®æ¢¯åº¦è¿›è¡Œé™åºçš„ä¼˜ç‚¹å¤–ï¼Œæ‰¹é‡æ¢¯åº¦ä¸‹é™è¿˜èƒ½å¤Ÿåˆ©ç”¨ä»¥ä¸‹äº‹å®ï¼šä½œä¸ºçŸ©é˜µæ“ä½œåºåˆ—å®ç°çš„ç¥ç»ç½‘ç»œå¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªç¤ºä¾‹ï¼ˆå¦‚å›¾ 8.6[393] å’Œå›¾ 8.9[399] æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, the prediction task is a binary classification task, and the instances in the test set are labeled as belonging to the positive or negative class.",
            "zh": "åŒæ ·ï¼Œé¢„æµ‹ä»»åŠ¡æ˜¯ä¸€ä¸ªäºŒå…ƒåˆ†ç±»ä»»åŠ¡ï¼Œæµ‹è¯•é›†ä¸­çš„å®ä¾‹è¢«æ ‡è®°ä¸ºå±äºæ­£ç±»æˆ–è´Ÿç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Understanding these two equations, and the core algorithms that they underpin (k-means clustering and Q-learning), is an excellent step toward broadening your knowledge out to the many other uses of machine learning beyond prediction.",
            "zh": "äº†è§£è¿™ä¸¤ä¸ªæ–¹ç¨‹ï¼Œä»¥åŠå®ƒä»¬æ‰€æ”¯æ’‘çš„æ ¸å¿ƒç®—æ³•ï¼ˆk-meansèšç±»å’ŒQ-learningï¼‰ï¼Œæ˜¯å°†ä½ çš„çŸ¥è¯†æ‰©å±•åˆ°æœºå™¨å­¦ä¹ çš„è®¸å¤šå…¶ä»–ç”¨é€”ï¼ˆé™¤äº†é¢„æµ‹ä¹‹å¤–ï¼‰çš„ä¸€ä¸ªå¾ˆå¥½çš„æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.43",
            "zh": "-0.43"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7[128] shows how the instances in the spam dataset are split when we partition it using each of the three descriptive features.",
            "zh": "å›¾ 4.7[128] æ˜¾ç¤ºäº†å½“æˆ‘ä»¬ä½¿ç”¨ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾ä¸­çš„æ¯ä¸€ä¸ªå¯¹åƒåœ¾é‚®ä»¶æ•°æ®é›†è¿›è¡Œåˆ†åŒºæ—¶ï¼Œåƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„å®ä¾‹æ˜¯å¦‚ä½•æ‹†åˆ†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the features are related, however, then the shapes and/or the central tendencies of the histograms will be different.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœç‰¹å¾æ˜¯ç›¸å…³çš„ï¼Œåˆ™ç›´æ–¹å›¾çš„å½¢çŠ¶å’Œ/æˆ–ä¸­å¿ƒè¶‹åŠ¿å°†ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Tukey, John W. 1977. Exploratory data analysis. Addison-Wesley.",
            "zh": "Tukeyï¼ŒJohn W. 1977 å¹´ã€‚æ¢ç´¢æ€§æ•°æ®åˆ†æã€‚è‰¾è¿ªç”Ÿ-å«æ–¯ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The backward pass starts by using the calculation illustrated by Equation (8.21)[411] to calculate a Î´ for each neuron in the output layer.",
            "zh": "å‘åä¼ é€’é¦–å…ˆä½¿ç”¨å…¬å¼ ï¼ˆ8.21ï¼‰[411] æ‰€ç¤ºçš„è®¡ç®—æ¥è®¡ç®—è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The challenge is if two clusters, each containing multiple instances, have been found, how should the distance between them be calculated?",
            "zh": "æŒ‘æˆ˜åœ¨äºï¼Œå¦‚æœæ‰¾åˆ°äº†ä¸¤ä¸ªé›†ç¾¤ï¼Œæ¯ä¸ªé›†ç¾¤éƒ½åŒ…å«å¤šä¸ªå®ä¾‹ï¼Œé‚£ä¹ˆåº”è¯¥å¦‚ä½•è®¡ç®—å®ƒä»¬ä¹‹é—´çš„è·ç¦»ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "CREDITRATING",
            "zh": "ä¿¡ç”¨è¯„çº§"
        }
    },
    {
        "translation": {
            "en": "For example, early moves in a game of chess do not lead to large positive rewards but set the ground for later high-reward moves.",
            "zh": "ä¾‹å¦‚ï¼Œå›½é™…è±¡æ£‹æ¸¸æˆä¸­çš„æ—©æœŸèµ°æ³•ä¸ä¼šå¸¦æ¥å·¨å¤§çš„ç§¯æå¥–åŠ±ï¼Œä½†ä¼šä¸ºä»¥åçš„é«˜å›æŠ¥èµ°æ³•å¥ å®šåŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assume that we are using the dataset in Table 5.2[183] as our labeled training dataset, and we want to make a prediction to tell us whether a query instance with SPEED = 6.75 and AGILITY = 3.00 is likely to be drafted or not. Figure 5.3[188] illustrates the feature space of the training dataset with the query, represented by the ? marker.",
            "zh": "å‡è®¾æˆ‘ä»¬ä½¿ç”¨è¡¨ 5.2[183] ä¸­çš„æ•°æ®é›†ä½œä¸ºæ ‡è®°çš„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶ä¸”æˆ‘ä»¬æƒ³è¦è¿›è¡Œé¢„æµ‹ä»¥å‘Šè¯‰æˆ‘ä»¬æ˜¯å¦å¯èƒ½èµ·è‰ SPEED = 6.75 ä¸” AGILITY = 3.00 çš„æŸ¥è¯¢å®ä¾‹ã€‚ å›¾ 5.3[188] è¯´æ˜äº†å¸¦æœ‰æŸ¥è¯¢çš„è®­ç»ƒæ•°æ®é›†çš„ç‰¹å¾ç©ºé—´ï¼Œ ç”± ï¼Ÿæ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "complete case analysis, 69, 712",
            "zh": "å®Œæ•´æ¡ˆä¾‹åˆ†æï¼Œ69,712"
        }
    },
    {
        "translation": {
            "en": "A.4.1â€…â€…â€…â€…Bar Plots",
            "zh": "A.4.1 æ¡å½¢å›¾"
        }
    },
    {
        "translation": {
            "en": "Assuming that the agent generates the same random number as before (0.634), which is greater than Îµ, greedy action selection will be used and, again, a0 = left will be chosen as it has the highest Q value for the start state, 0-3.",
            "zh": "å‡è®¾ä»£ç†ç”Ÿæˆä¸ä¹‹å‰ç›¸åŒçš„éšæœºæ•° ï¼ˆ0.634ï¼‰ï¼Œè¯¥éšæœºæ•°å¤§äº Îµï¼Œåˆ™å°†ä½¿ç”¨è´ªå©ªæ“ä½œé€‰æ‹©ï¼Œå¹¶ä¸”å†æ¬¡é€‰æ‹© a0 = leftï¼Œå› ä¸ºå®ƒå…·æœ‰åˆå§‹çŠ¶æ€çš„æœ€é«˜ Q å€¼ 0-3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.19[301] lists a some of the samples generated using Gibbs sampling for the Bayesian network in Figure 6.13[296] for the query",
            "zh": "è¡¨6.19[301]åˆ—å‡ºäº†å›¾6.13[296]ä¸­ä½¿ç”¨å‰å¸ƒæ–¯é‡‡æ ·ä¸ºè´å¶æ–¯ç½‘ç»œç”Ÿæˆçš„ä¸€äº›æ ·æœ¬"
        }
    },
    {
        "translation": {
            "en": "The problem with this reasoning, however, is that, on average, the answer to Question 2 will be yes only one out of every four times you play.",
            "zh": "ç„¶è€Œï¼Œè¿™ç§æ¨ç†çš„é—®é¢˜åœ¨äºï¼Œå¹³å‡è€Œè¨€ï¼Œé—®é¢˜ 2 çš„ç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œæ¯ç©å››æ¬¡ä¸­åªæœ‰ä¸€æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset in the college athlete example is imbalancedâ€”there are 13 no instances and only 7 yes instances.",
            "zh": "å¤§å­¦è¿åŠ¨å‘˜ç¤ºä¾‹ä¸­çš„æ•°æ®é›†æ˜¯ä¸å¹³è¡¡çš„â€”â€”æœ‰ 13 ä¸ªæ²¡æœ‰å®ä¾‹ï¼Œåªæœ‰ 7 ä¸ªæ˜¯å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the initial weights predictions are made for all the instances in the training dataset, as shown in the Predictions column (column 3) of Table 7.3[331]. By comparing these predicted values with the actual RENTAL PRICE (column 2), we can compute an error and a squared error term for each training instance, columns 4 and 5 of the table.",
            "zh": "ä½¿ç”¨åˆå§‹æƒé‡å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œå¦‚è¡¨ 7.3[331] çš„â€œé¢„æµ‹â€åˆ—ï¼ˆç¬¬ 3 åˆ—ï¼‰æ‰€ç¤ºã€‚é€šè¿‡å°†è¿™äº›é¢„æµ‹å€¼ä¸å®é™…çš„ RENTAL PRICEï¼ˆç¬¬ 2 åˆ—ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯ä¸ªè®­ç»ƒå®ä¾‹çš„è¯¯å·®å’Œè¯¯å·®é¡¹çš„å¹³æ–¹è¯¯å·®é¡¹ï¼Œå³è¡¨çš„ç¬¬ 4 åˆ—å’Œç¬¬ 5 åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Such a definition, however, has the complication that the same customer could appear in the ABT as both an active and a churn customer, although admittedly the descriptive features for these two instances would be calculated over different periods of time.",
            "zh": "ç„¶è€Œï¼Œè¿™æ ·çš„å®šä¹‰å…·æœ‰å¤æ‚æ€§ï¼Œå³åŒä¸€å®¢æˆ·å¯èƒ½åŒæ—¶ä½œä¸ºæ´»è·ƒå®¢æˆ·å’Œæµå¤±å®¢æˆ·å‡ºç°åœ¨ ABT ä¸­ï¼Œå°½ç®¡ä¸å¯å¦è®¤ï¼Œè¿™ä¸¤ä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾å°†åœ¨ä¸åŒçš„æ—¶é—´æ®µå†…è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another simple approach to handling missing values is complete case analysis, which deletes from an ABT any instances that are missing one or more feature values.",
            "zh": "å¤„ç†ç¼ºå¤±å€¼çš„å¦ä¸€ç§ç®€å•æ–¹æ³•æ˜¯å®Œæ•´æ¡ˆä¾‹åˆ†æï¼Œå®ƒä» ABT ä¸­åˆ é™¤ä»»ä½•ç¼ºå°‘ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾å€¼çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The monitoring system that Ross put in place generated a report at the end of every quarter that evaluated the performance of the model in the previous quarter by comparing how many of the people not contacted by the retention team actually churned.",
            "zh": "Ross å®æ–½çš„ç›‘æ§ç³»ç»Ÿåœ¨æ¯ä¸ªå­£åº¦æœ«éƒ½ä¼šç”Ÿæˆä¸€ä»½æŠ¥å‘Šï¼Œé€šè¿‡æ¯”è¾ƒä¿ç•™å›¢é˜Ÿæœªè”ç³»çš„äººå‘˜ä¸­æœ‰å¤šå°‘äººå®é™…æµå¤±ï¼Œæ¥è¯„ä¼°æ¨¡å‹åœ¨ä¸Šä¸€å­£åº¦çš„ç»©æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a threshold on the error of the model error on the training set as a convergence criterionâ€”as we are doing hereâ€”is very likely to result in the model overfitting the training data.",
            "zh": "ä½¿ç”¨è®­ç»ƒé›†ä¸Šæ¨¡å‹è¯¯å·®çš„é˜ˆå€¼ä½œä¸ºæ”¶æ•›æ ‡å‡†ï¼ˆå°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œæ‰€åšçš„é‚£æ ·ï¼‰ï¼Œå¾ˆå¯èƒ½å¯¼è‡´æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that the standard deviation is measured in the original units of the sample, which makes it much more interpretable than the variance. It is very common to see the mean and standard deviation provided as a full description of a sample.",
            "zh": "è¿™æ„å‘³ç€æ ‡å‡†å·®æ˜¯ä»¥æ ·æœ¬çš„åŸå§‹å•ä½æµ‹é‡çš„ï¼Œè¿™ä½¿å¾—å®ƒæ¯”æ–¹å·®æ›´å®¹æ˜“è§£é‡Šã€‚é€šå¸¸å°†å‡å€¼å’Œæ ‡å‡†å·®è§†ä¸ºæ ·æœ¬çš„å®Œæ•´æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "where index_w is the whole part of index, index_f is the fractional part of index, and aindex_w is the value in the ordered list at position index_w.",
            "zh": "å…¶ä¸­ index_w æ˜¯ç´¢å¼•çš„å…¨éƒ¨éƒ¨åˆ†ï¼Œindex_f æ˜¯ç´¢å¼•çš„å°æ•°éƒ¨åˆ†ï¼Œaindex_w æ˜¯ä½ç½® index_w å¤„çš„æœ‰åºåˆ—è¡¨ä¸­çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Jaccard similarity, the current trial user in the online retail example is judged to be equally similar to instance d1 and d2:",
            "zh": "ä½¿ç”¨ Jaccard ç›¸ä¼¼æ€§ï¼Œåˆ¤æ–­åœ¨çº¿é›¶å”®ç¤ºä¾‹ä¸­çš„å½“å‰è¯•ç”¨ç”¨æˆ·ä¸å®ä¾‹ d1 å’Œ d2 çš„ç›¸ä¼¼åº¦ç›¸åŒï¼š"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated a Î´ for each of the neurons in the sub-sampling layer, we can then backpropagate these Î´s to the layer of neurons that convolve the filter.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†å­é‡‡æ ·å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è¿™äº› Î´ åå‘ä¼ æ’­åˆ°å·ç§¯æ»¤æ³¢å™¨çš„ç¥ç»å…ƒå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is appropriate in many applications.",
            "zh": "è¿™åœ¨è®¸å¤šåº”ç”¨ä¸­éƒ½æ˜¯é€‚ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.24[454] illustrates what happens in the internal dynamics of the network if we increase the standard deviation of the distribution from which we sample, in this instance a normal distribution with Î¼ = 0.0 and Ïƒ = 0.2.",
            "zh": "å›¾ 8.24[454] è¯´æ˜äº†å¦‚æœæˆ‘ä»¬å¢åŠ é‡‡æ ·åˆ†å¸ƒçš„æ ‡å‡†å·®ï¼Œç½‘ç»œå†…éƒ¨åŠ¨åŠ›å­¦ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸º Î¼ = 0.0 ä¸” Ïƒ = 0.2 çš„æ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The time differences arising from these different computational loads can have an influence on model selection.",
            "zh": "è¿™äº›ä¸åŒçš„è®¡ç®—è´Ÿè½½äº§ç”Ÿçš„æ—¶é—´å·®å¯èƒ½ä¼šå¯¹æ¨¡å‹é€‰æ‹©äº§ç”Ÿå½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The optimization criterion used when training a support vector machine allows us to choose between multiple different decision boundaries that satisfy the constraint given in Equation (7.44)[364], such as those shown in Figure 7.23[364]. The optimization criterion used is defined in terms of the perpendicular distance from any instance to the decision boundary and is given by",
            "zh": "è®­ç»ƒæ”¯æŒå‘é‡æœºæ—¶ä½¿ç”¨çš„ä¼˜åŒ–æ ‡å‡†å…è®¸æˆ‘ä»¬åœ¨æ»¡è¶³æ–¹ç¨‹ï¼ˆ7.44ï¼‰[364]ä¸­ç»™å‡ºçš„çº¦æŸçš„å¤šä¸ªä¸åŒå†³ç­–è¾¹ç•Œä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼Œå¦‚å›¾7.23[364]æ‰€ç¤ºã€‚ä½¿ç”¨çš„ä¼˜åŒ–æ ‡å‡†æ˜¯æ ¹æ®ä»ä»»ä½•å®ä¾‹åˆ°å†³ç­–è¾¹ç•Œçš„å‚ç›´è·ç¦»æ¥å®šä¹‰çš„ï¼Œç”±ä¸‹å¼ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "Using the information provided, write a description of what it means for a taxpayer to be a member of each of the clusters.",
            "zh": "ä½¿ç”¨æä¾›çš„ä¿¡æ¯ï¼Œæè¿°çº³ç¨äººæˆä¸ºæ¯ä¸ªé›†ç¾¤æˆå‘˜æ„å‘³ç€ä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.6[753] is a bar plot of the TRAINING EXPENSES feature from Table A.1[750]. The figure illustrates why a bar plot is not an appropriate graphic to use to visualize a continuous feature: as is generally the case with a continuous feature, there are as many distinct values as there are instances in the dataset, and therefore there are as many bars in the histogram as there are instances, each bar having a height of 1.0.",
            "zh": "å›¾A.6[753]æ˜¯è¡¨A.1[750]ä¸­åŸ¹è®­è´¹ç”¨ç‰¹å¾çš„æ¡å½¢å›¾ã€‚è¯¥å›¾è¯´æ˜äº†ä¸ºä»€ä¹ˆæ¡å½¢å›¾ä¸é€‚åˆç”¨äºå¯è§†åŒ–è¿ç»­è¦ç´ çš„å›¾å½¢ï¼šä¸è¿ç»­è¦ç´ çš„ä¸€èˆ¬æƒ…å†µä¸€æ ·ï¼Œæ•°æ®é›†ä¸­çš„å®ä¾‹å…·æœ‰ç›¸åŒçš„ä¸åŒå€¼ï¼Œå› æ­¤ç›´æ–¹å›¾ä¸­çš„æ¡å½¢ä¸å®ä¾‹ä¸€æ ·å¤šï¼Œæ¯ä¸ªæ¡å½¢çš„é«˜åº¦ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, it is unlikely that a change in the distribution of just one descriptive feature in a multi-feature model will have a large impact on model performance.",
            "zh": "æ­¤å¤–ï¼Œåœ¨å¤šç‰¹å¾æ¨¡å‹ä¸­ï¼Œä»…ä¸€ä¸ªæè¿°æ€§ç‰¹å¾çš„åˆ†å¸ƒå˜åŒ–ä¸å¤ªå¯èƒ½å¯¹æ¨¡å‹æ€§èƒ½äº§ç”Ÿé‡å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS PER YEAR; RATIO OF AVERAGE CLAIMS PER YEAR TO NUMBER OF CLAIMS IN LAST 12 MONTHS: AVG.",
            "zh": "æ¯å¹´çš„ç´¢èµ”;æ¯å¹´å¹³å‡ç”³é¢†äººæ•°ä¸è¿‡å»12ä¸ªæœˆç”³é¢†äººæ•°çš„æ¯”ç‡ï¼šå¹³å‡"
        }
    },
    {
        "translation": {
            "en": "11.2â€ƒFundamentals",
            "zh": "11.2 åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "The number of times the customer has been called by the retention team",
            "zh": "ä¿ç•™å›¢é˜Ÿå‘¼å«å®¢æˆ·çš„æ¬¡æ•°"
        }
    },
    {
        "translation": {
            "en": "Table 3.2",
            "zh": "è¡¨ 3.2"
        }
    },
    {
        "translation": {
            "en": "A Bayesian network that encodes the causal relationships between the features in the corruption domain. The CPT entries have been calculated using the binned data from Table 6.18[295].",
            "zh": "ä¸€ä¸ªè´å¶æ–¯ç½‘ç»œï¼Œç”¨äºå¯¹æŸååŸŸä¸­ç‰¹å¾ä¹‹é—´çš„å› æœå…³ç³»è¿›è¡Œç¼–ç ã€‚CPTæ¡ç›®æ˜¯ä½¿ç”¨è¡¨6.18[295]ä¸­çš„åˆ†ç®±æ•°æ®è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The choice of which one to use mostly depends on how much data is available.",
            "zh": "é€‰æ‹©ä½¿ç”¨å“ªä¸€ä¸ªä¸»è¦å–å†³äºå¯ç”¨çš„æ•°æ®é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the cardinality of a continuous feature is significantly less than the number of instances in the dataset, then it should be investigated.",
            "zh": "å¦‚æœè¿ç»­è¦ç´ çš„åŸºæ•°æ˜æ˜¾å°äºæ•°æ®é›†ä¸­çš„å®ä¾‹æ•°ï¼Œåˆ™åº”å¯¹å…¶è¿›è¡Œè°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Î”w7,5=",
            "zh": "Î”w7,5="
        }
    },
    {
        "translation": {
            "en": "4.6â€…â€…â€…Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset ğ’Ÿ8 in Figure 4.9[139].",
            "zh": "4.6 å›¾4.9[139]ä¸­æ•°æ®é›†D8çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate this growth in the number of terms in the chain of products as we move back through a network, imagine a simple feedforward network with just three neurons, i, j, and k, arranged so that i feeds forward into j and j into k",
            "zh": "ä¸ºäº†è¯´æ˜å½“æˆ‘ä»¬é€šè¿‡ç½‘ç»œå‘åç§»åŠ¨æ—¶ï¼Œäº§å“é“¾ä¸­é¡¹æ•°é‡çš„å¢é•¿ï¼Œæƒ³è±¡ä¸€ä¸ªç®€å•çš„å‰é¦ˆç½‘ç»œï¼Œåªæœ‰ä¸‰ä¸ªç¥ç»å…ƒï¼Œiã€j å’Œ kï¼Œæ’åˆ—æˆ i å‰é¦ˆåˆ° J ä¸­ï¼Œj è¿›åˆ° k ä¸­"
        }
    },
    {
        "translation": {
            "en": "multi-armed bandit problem, 656",
            "zh": "å¤šè‡‚åœŸåŒªé—®é¢˜ï¼Œ656"
        }
    },
    {
        "translation": {
            "en": "where âŠ™ is an elementwise vector product, oâ€  was calculated in the forward pass using Equation (8.114)[512 and oâ€¡ was calculated in the forward pass using Equation (8.115)[512].",
            "zh": "å…¶ä¸­ âŠ™ æ˜¯é€å…ƒç´ å‘é‡ç§¯ï¼Œoâ€  åœ¨å‰å‘ä¼ é€’ä¸­ä½¿ç”¨æ–¹ç¨‹ ï¼ˆ8.114ï¼‰[512] è®¡ç®—ï¼Œoâ€¡ åœ¨å‰å‘ä¼ é€’ä¸­ä½¿ç”¨æ–¹ç¨‹ ï¼ˆ8.115ï¼‰[512] è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The arithmetic mean, for example, is very sensitive to very large or very small values in a sample.",
            "zh": "ä¾‹å¦‚ï¼Œç®—æœ¯å¹³å‡å€¼å¯¹æ ·æœ¬ä¸­éå¸¸å¤§æˆ–éå¸¸å°çš„å€¼éå¸¸æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Lowercase boldface letters refer to a vector of features. For example, d denotes a vector of descriptive features for an instance in a dataset, and q denotes a vector of descriptive features in a query.",
            "zh": "å°å†™ç²—ä½“å­—æ¯è¡¨ç¤ºè¦ç´ å‘é‡ã€‚ä¾‹å¦‚ï¼Œd è¡¨ç¤ºæ•°æ®é›†ä¸­å®ä¾‹çš„æè¿°æ€§ç‰¹å¾å‘é‡ï¼Œq è¡¨ç¤ºæŸ¥è¯¢ä¸­çš„æè¿°æ€§ç‰¹å¾å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A particularly useful feature of linear regression models is that the weights used by the model indicate the effect of each descriptive feature on the predictions returned by the model.",
            "zh": "çº¿æ€§å›å½’æ¨¡å‹çš„ä¸€ä¸ªç‰¹åˆ«æœ‰ç”¨çš„åŠŸèƒ½æ˜¯ï¼Œæ¨¡å‹ä½¿ç”¨çš„æƒé‡è¡¨ç¤ºæ¯ä¸ªæè¿°æ€§ç‰¹å¾å¯¹æ¨¡å‹è¿”å›çš„é¢„æµ‹çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 2[188] provides a pseudocode definition of the algorithm for the prediction stage.",
            "zh": "ç®—æ³•2[188]ä¸ºé¢„æµ‹é˜¶æ®µæä¾›äº†ç®—æ³•çš„ä¼ªä»£ç å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the email classification data given in Table 9.1[537], the confusion matrix-based values can be calculated as follows:",
            "zh": "å¯¹äºè¡¨9.1[537]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶åˆ†ç±»æ•°æ®ï¼ŒåŸºäºæ··æ·†çŸ©é˜µçš„å€¼å¯ä»¥è®¡ç®—å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The key step in this iterative weight update process is solving the blame assignment problem. The general structure of the backpropagation algorithm is a two-step process that results in an assignment of blame (or an error gradient) to each of the neurons in the network:",
            "zh": "æ­¤è¿­ä»£æƒé‡æ›´æ–°è¿‡ç¨‹çš„å…³é”®æ­¥éª¤æ˜¯è§£å†³å½’å’åˆ†é…é—®é¢˜ã€‚åå‘ä¼ æ’­ç®—æ³•çš„ä¸€èˆ¬ç»“æ„æ˜¯ä¸€ä¸ªä¸¤æ­¥è¿‡ç¨‹ï¼Œå¯¼è‡´å°†è´£ä»»ï¼ˆæˆ–è¯¯å·®æ¢¯åº¦ï¼‰åˆ†é…ç»™ç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(b)[453] illustrates how the z values vary across the layers of the network during the forward pass of the algorithm.",
            "zh": "å›¾8.23ï¼ˆbï¼‰[453]è¯´æ˜äº†åœ¨ç®—æ³•çš„å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­ï¼Œzå€¼åœ¨ç½‘ç»œå±‚ä¸­æ˜¯å¦‚ä½•å˜åŒ–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. Subsequently, in this chapter we illustrate how this can be done for ReLU, neurons using rectifier activation functions.",
            "zh": "6. éšåï¼Œåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•ä½¿ç”¨æ•´æµå™¨æ¿€æ´»å‡½æ•°çš„ ReLU ç¥ç»å…ƒæ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each level of the categorical feature, a box plot of the corresponding values of the continuous feature is drawn.",
            "zh": "å¯¹äºåˆ†ç±»è¦ç´ çš„æ¯ä¸ªæ°´å¹³ï¼Œç»˜åˆ¶è¿ç»­è¦ç´ ç›¸åº”å€¼çš„ç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we have a third instance with SMS = 194 and VOICE = 42, the cosine similarity between this instance and d1 will be 1.0, because even though the magnitudes of their feature values are different, the relationship between the feature values for both instances is the same: both customers use about four times as many SMS messages as VOICE calls.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ç¬¬ä¸‰ä¸ªå®ä¾‹ï¼Œå…¶ SMS = 194 ä¸” VOICE = 42ï¼Œåˆ™æ­¤å®ä¾‹ä¸ d1 ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦å°†ä¸º 1.0ï¼Œå› ä¸ºå³ä½¿å®ƒä»¬çš„ç‰¹å¾å€¼å¤§å°ä¸åŒï¼Œä¸¤ä¸ªå®ä¾‹çš„ç‰¹å¾å€¼ä¹‹é—´çš„å…³ç³»æ˜¯ç›¸åŒçš„ï¼šä¸¤ä¸ªå®¢æˆ·ä½¿ç”¨çš„ SMS æ¶ˆæ¯æ•°é‡å¤§çº¦æ˜¯ VOICE å‘¼å«çš„å››å€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT Press.",
            "zh": "Goodfellowã€Ianã€Yoshua Bengio å’Œ Aaron Courvilleã€‚2016. æ·±åº¦å­¦ä¹ .éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, if we are working with a large dataset, the time cost in computing the distances between a query and all the training instances and retrieving the k nearest neighbors may be prohibitive.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å¤§å‹æ•°æ®é›†ï¼Œåˆ™è®¡ç®—æŸ¥è¯¢ä¸æ‰€æœ‰è®­ç»ƒå®ä¾‹ä¹‹é—´çš„è·ç¦»ä»¥åŠæ£€ç´¢ k ä¸ªæœ€è¿‘é‚»çš„æ—¶é—´æˆæœ¬å¯èƒ½ä¼šä»¤äººæœ›è€Œå´æ­¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This figure is based on Figure 5.4 of Kelleher (2019), which in turn was inspired by an image by Christopher Olah (available at: http://colah.github.io/posts/2015-08-Understanding-LSTMs/).",
            "zh": "è¯¥å›¾åŸºäºKelleherï¼ˆ2019ï¼‰çš„å›¾5.4ï¼Œè€Œè¯¥å›¾çš„çµæ„Ÿæ¥è‡ªChristopher Olahçš„å›¾åƒï¼ˆå¯åœ¨ http://colah.github.io/posts/2015-08-Understanding-LSTMs/ è·å¾—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. The following image shows an artificial network with two layers of linear neurons (i.e., neurons that have no activation function and whose output is simply the result of the weighted sum of their inputs). Furthermore, these neurons have no bias terms.",
            "zh": "3. ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªå…·æœ‰ä¸¤å±‚çº¿æ€§ç¥ç»å…ƒçš„äººå·¥ç½‘ç»œï¼ˆå³ï¼Œæ²¡æœ‰æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒï¼Œå…¶è¾“å‡ºåªæ˜¯å…¶è¾“å…¥çš„åŠ æƒå’Œçš„ç»“æœï¼‰ã€‚æ­¤å¤–ï¼Œè¿™äº›ç¥ç»å…ƒæ²¡æœ‰åå·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) 100 neurons in the input layer",
            "zh": "ï¼ˆaï¼‰ è¾“å…¥å±‚ä¸­æœ‰ 100 ä¸ªç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "The last data visualization technique we will discuss for visualizing the values of a single feature is the box plot.8 A box plot is a visual representation of the five key descriptive statistics for a continuous feature: minimum, 1st quartile, median, 3rd quartile, and maximum.",
            "zh": "æˆ‘ä»¬å°†è®¨è®ºçš„æœ€åä¸€ä¸ªæ•°æ®å¯è§†åŒ–æŠ€æœ¯æ˜¯ç®±å½¢å›¾ã€‚8 ç®±å½¢å›¾æ˜¯è¿ç»­ç‰¹å¾çš„äº”ä¸ªå…³é”®æè¿°æ€§ç»Ÿè®¡é‡çš„å¯è§†åŒ–è¡¨ç¤ºï¼šæœ€å°å€¼ã€ç¬¬ä¸€å››åˆ†ä½æ•°ã€ä¸­ä½æ•°ã€ç¬¬ä¸‰å››åˆ†ä½æ•°å’Œæœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. See Frank (2000) for a detailed discussion and analysis on the use of statistical tests in decision tree pruning.",
            "zh": "21. å‚è§Frank ï¼ˆ2000ï¼‰å…³äºåœ¨å†³ç­–æ ‘ä¿®å‰ªä¸­ä½¿ç”¨ç»Ÿè®¡æ£€éªŒçš„è¯¦ç»†è®¨è®ºå’Œåˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "If the value of the stability index is less than 0.1, then the distribution of the newly collected test set is broadly similar to the distribution in the original test set.",
            "zh": "å¦‚æœç¨³å®šæ€§æŒ‡æ•°çš„å€¼å°äº 0.1ï¼Œåˆ™æ–°æ”¶é›†çš„æµ‹è¯•é›†çš„åˆ†å¸ƒä¸åŸå§‹æµ‹è¯•é›†ä¸­çš„åˆ†å¸ƒå¤§è‡´ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Induces a model using the weighted dataset and calculates the total error, Îµ, in the set of predictions made by the model for the instances in the training dataset.29 The Îµ value is calculated by summing the weights of the training instances for which the predictions made by the model are incorrect.",
            "zh": "1. ä½¿ç”¨åŠ æƒæ•°æ®é›†è¯±å¯¼æ¨¡å‹ï¼Œå¹¶è®¡ç®—æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹æ‰€åšçš„é¢„æµ‹é›†ä¸­çš„æ€»è¯¯å·® Îµ.29 Îµå€¼æ˜¯é€šè¿‡å°†æ¨¡å‹åšå‡ºçš„é¢„æµ‹ä¸æ­£ç¡®çš„è®­ç»ƒå®ä¾‹çš„æƒé‡ç›¸åŠ æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Choosing between models in this sort of scenario is difficult as it really comes down to balancing the needs of the applicationâ€”when the system makes errors (as it inevitably will from time to time), what error is least bad?",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨æ¨¡å‹ä¹‹é—´è¿›è¡Œé€‰æ‹©æ˜¯å¾ˆå›°éš¾çš„ï¼Œå› ä¸ºå®ƒå®é™…ä¸Šå½’ç»“ä¸ºå¹³è¡¡åº”ç”¨ç¨‹åºçš„éœ€æ±‚â€”â€”å½“ç³»ç»Ÿå‡ºé”™æ—¶ï¼ˆä¸å¯é¿å…åœ°ä¼šä¸æ—¶å‡ºç°é”™è¯¯ï¼‰ï¼Œå“ªä¸ªé”™è¯¯æœ€ä¸ä¸¥é‡ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Assuming a stride length of 1 and no padding on the input, we would require a 2-by-2 layer of neurons to convolve the filter over this image. The top-left neuron in this layer would have a local receptive field covering the 2-by-2 square in the top-left of each of the channels. Equation 8.101[494] lists the values from the image that are inside this neuronâ€™s local receptive field",
            "zh": "å‡è®¾æ­¥å¹…ä¸º 1 å¹¶ä¸”è¾“å…¥ä¸Šæ²¡æœ‰å¡«å……ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª 2Ã—2 çš„ç¥ç»å…ƒå±‚æ¥å·ç§¯æ­¤å›¾åƒä¸Šçš„æ»¤æ³¢å™¨ã€‚è¯¥å±‚ä¸­å·¦ä¸Šè§’çš„ç¥ç»å…ƒå°†æœ‰ä¸€ä¸ªå±€éƒ¨æ„Ÿå—é‡ï¼Œè¦†ç›–æ¯ä¸ªé€šé“å·¦ä¸Šè§’çš„ 2Ã—2 æ­£æ–¹å½¢ã€‚å…¬å¼ 8.101[494] åˆ—å‡ºäº†è¯¥ç¥ç»å…ƒå±€éƒ¨æ„Ÿå—é‡å†…çš„å›¾åƒå€¼"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12(b)[562] shows ROC curves for four models tested on a version of the email classification test set in Table 9.13[560], containing many more instances than the one we have been discussing so far, which is why the curves are so much smoother than the curve shown in Figure 9.12(a)[562].",
            "zh": "å›¾9.12ï¼ˆbï¼‰[562]æ˜¾ç¤ºäº†åœ¨è¡¨9.13[560]ä¸­çš„ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†ç‰ˆæœ¬ä¸Šæµ‹è¯•çš„å››ä¸ªæ¨¡å‹çš„ROCæ›²çº¿ï¼Œå…¶ä¸­åŒ…å«çš„å®ä¾‹æ¯”æˆ‘ä»¬ç›®å‰è®¨è®ºçš„å®ä¾‹å¤šå¾—å¤šï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ›²çº¿æ¯”å›¾9.12ï¼ˆaï¼‰[562]ä¸­æ˜¾ç¤ºçš„æ›²çº¿å¹³æ»‘å¾—å¤šçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "cross-entropy, 434, 463, 465",
            "zh": "äº¤å‰ç†µï¼Œ 434ï¼Œ 463ï¼Œ 465"
        }
    },
    {
        "translation": {
            "en": "We can now define the calculation of the Î´ for a neuron in a softmax output layer using a cross-entropy loss function as follows:",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°å®šä¹‰softmaxè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒÎ´çš„è®¡ç®—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Table 9.8[554] shows the profit matrix for this problem.",
            "zh": "è¡¨ 9.8[554] æ˜¾ç¤ºäº†è¯¥é—®é¢˜çš„åˆ©æ¶¦çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "The best performing model is the logistic regression model.",
            "zh": "æ€§èƒ½æœ€å¥½çš„æ¨¡å‹æ˜¯é€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Specifically, it represents how sensitive the error of the network â„° is to changes in ak.",
            "zh": "å…·ä½“æ¥è¯´ï¼Œå®ƒè¡¨ç¤ºç½‘ç»œ E çš„è¯¯å·®å¯¹ ak å˜åŒ–çš„æ•æ„Ÿç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, this equation computes a distance between two instances a and b, each with m descriptive features.",
            "zh": "é¦–å…ˆï¼Œè¯¥æ–¹ç¨‹è®¡ç®—ä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„è·ç¦»ï¼Œæ¯ä¸ªå®ä¾‹éƒ½æœ‰ m ä¸ªæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the preceding figure, the image on the right shows a simple linear logistic regression model trained to perform this task. This model is",
            "zh": "åœ¨ä¸Šå›¾ä¸­ï¼Œå³å›¾æ˜¾ç¤ºäº†ä¸ºæ‰§è¡Œæ­¤ä»»åŠ¡è€Œè®­ç»ƒçš„ç®€å•çº¿æ€§é€»è¾‘å›å½’æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The first is that if we use a 4-by-4 layer of neurons, to cover a 6-by-6 input matrix, the dimensionality of the resulting feature map is also 4-by-4.",
            "zh": "é¦–å…ˆï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ 4Ã—4 çš„ç¥ç»å…ƒå±‚æ¥è¦†ç›– 6Ã—6 çš„è¾“å…¥çŸ©é˜µï¼Œåˆ™ç”Ÿæˆçš„ç‰¹å¾å›¾çš„ç»´æ•°ä¹Ÿæ˜¯ 4Ã—4ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distance of each instance in the dataset to each of these cluster centroids is then calculated using the distance measure Dist.",
            "zh": "ç„¶åï¼Œä½¿ç”¨è·ç¦»æµ‹é‡ Dist."
        }
    },
    {
        "translation": {
            "en": "In these instances, a margin cannot be defined, as we have done in this example.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæ— æ³•å®šä¹‰è¾¹è·ï¼Œå°±åƒæˆ‘ä»¬åœ¨æ­¤ç¤ºä¾‹ä¸­æ‰€åšçš„é‚£æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_R_I",
            "zh": "DEREDDIFF_R_I"
        }
    },
    {
        "translation": {
            "en": "Obviously, the set of domain concepts that are important change from one analytics solution to another. However, there are a number of general domain concepts that are often useful:",
            "zh": "æ˜¾ç„¶ï¼Œé‡è¦çš„é¢†åŸŸæ¦‚å¿µé›†ä»ä¸€ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆæ›´æ”¹ä¸ºå¦ä¸€ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆã€‚ä½†æ˜¯ï¼Œæœ‰è®¸å¤šé€šç”¨åŸŸæ¦‚å¿µé€šå¸¸å¾ˆæœ‰ç”¨ï¼š"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, Conor doesnâ€™t speak any Irish and the staff in the hotel restaurant donâ€™t speak any English.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œåº·çº³ä¸ä¼šè¯´çˆ±å°”å…°è¯­ï¼Œé…’åº—é¤å…çš„å·¥ä½œäººå‘˜ä¹Ÿä¸ä¼šè¯´è‹±è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table B.1",
            "zh": "è¡¨B.1"
        }
    },
    {
        "translation": {
            "en": "This is because having a headache increases the probability of the patient having meningitis, which in turn increases the probability of the patient having a fever.",
            "zh": "è¿™æ˜¯å› ä¸ºå¤´ç—›ä¼šå¢åŠ æ‚£è€…æ‚£è„‘è†œç‚çš„æ¦‚ç‡ï¼Œä»è€Œå¢åŠ æ‚£è€…å‘çƒ§çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This uneven distribution of instances across bins can have dramatic and unwanted consequences for probability-based models.",
            "zh": "è¿™ç§å®ä¾‹åœ¨ bin ä¸­çš„ä¸å‡åŒ€åˆ†å¸ƒå¯èƒ½ä¼šå¯¹åŸºäºæ¦‚ç‡çš„æ¨¡å‹äº§ç”Ÿä¸¥é‡ä¸”ä¸å¿…è¦çš„åæœã€‚"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1993. C4.5: Programs for machine learning. Morgan Kaufmann.",
            "zh": "æ˜†å…°ï¼ŒJ.ç½—æ–¯ã€‚1993. C4.5ï¼šæœºå™¨å­¦ä¹ ç¨‹åºã€‚æ‘©æ ¹Â·è€ƒå¤«æ›¼ï¼ˆMorgan Kaufmannï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.3.1â€ƒA Worked Example: Predicting Vegetation Distributions",
            "zh": "4.3.1 å·¥ä½œç¤ºä¾‹ï¼šé¢„æµ‹æ¤è¢«åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "The following website:",
            "zh": "ä»¥ä¸‹ç½‘ç«™ï¼š"
        }
    },
    {
        "translation": {
            "en": "The type of region the customer lives in",
            "zh": "å®¢æˆ·å±…ä½çš„åŒºåŸŸç±»å‹"
        }
    },
    {
        "translation": {
            "en": "4.4.3â€ƒPredicting Continuous Targets",
            "zh": "4.4.3 é¢„æµ‹è¿ç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "(b) Measure the performance of this bagged ensemble using misclassification rate (misclassification rate is discussed in detail in Section 9.3[535]; it is simply the percentage of instances in the test dataset that a model has incorrectly classified).",
            "zh": "ï¼ˆbï¼‰ ä½¿ç”¨é”™è¯¯åˆ†ç±»ç‡ï¼ˆé”™è¯¯åˆ†ç±»ç‡åœ¨ç¬¬ 9.3[535] èŠ‚ä¸­è¯¦ç»†è®¨è®º;å®ƒåªæ˜¯æµ‹è¯•æ•°æ®é›†ä¸­æ¨¡å‹é”™è¯¯åˆ†ç±»çš„å®ä¾‹çš„ç™¾åˆ†æ¯”ï¼‰æ¥è¡¡é‡è¿™ä¸ªè¢‹è£…é›†æˆçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.6",
            "zh": "å›¾ 8.6"
        }
    },
    {
        "translation": {
            "en": "Figure 2.3",
            "zh": "å›¾ 2.3"
        }
    },
    {
        "translation": {
            "en": "When Jocelyn first arrived at SDSS, she was pleased to find that the business problem she was being asked to help with was already pretty well defined in predictive analytics terms.",
            "zh": "å½“ Jocelyn ç¬¬ä¸€æ¬¡æ¥åˆ° SDSS æ—¶ï¼Œå¥¹å¾ˆé«˜å…´åœ°å‘ç°ï¼Œå¥¹è¢«è¦æ±‚å¸®åŠ©è§£å†³çš„ä¸šåŠ¡é—®é¢˜å·²ç»åœ¨é¢„æµ‹åˆ†ææœ¯è¯­ä¸­å¾—åˆ°äº†å¾ˆå¥½çš„å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.10â€…â€…â€…A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.10 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æåˆ†æè§£å†³æ–¹æ¡ˆçš„é¢†åŸŸæ¦‚å¿µå’Œç›¸å…³åŠŸèƒ½çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Scatter plots of three bivariate datasets with the same center point A and two queries B and C both equidistant from A; (a) a dataset uniformly spread around the center point; (b) a dataset with negative covariance; and (c) a dataset with positive covariance.",
            "zh": "å…·æœ‰ç›¸åŒä¸­å¿ƒç‚¹ A çš„ä¸‰ä¸ªåŒå˜é‡æ•°æ®é›†å’Œä¸¤ä¸ªæŸ¥è¯¢ B å’Œ C çš„æ•£ç‚¹å›¾ï¼Œå®ƒä»¬éƒ½ä¸ A ç­‰è·;ï¼ˆaï¼‰ å‡åŒ€åˆ†å¸ƒåœ¨ä¸­å¿ƒç‚¹å‘¨å›´çš„æ•°æ®é›†;ï¼ˆbï¼‰ å…·æœ‰è´Ÿåæ–¹å·®çš„æ•°æ®é›†;ï¼ˆcï¼‰å…·æœ‰æ­£åæ–¹å·®çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that instances far away from the current set of centroids are much more likely to be selected than those close to already selected centroids.",
            "zh": "è¿™æ„å‘³ç€è¿œç¦»å½“å‰è´¨å¿ƒé›†çš„å®ä¾‹æ¯”é è¿‘å·²é€‰æ‹©è´¨å¿ƒçš„å®ä¾‹æ›´æœ‰å¯èƒ½è¢«é€‰ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, over 60% of the values for MARITAL STATUS are missing, so this feature should almost certainly be removed from the ABT (we return to this feature shortly).",
            "zh": "äº‹å®ä¸Šï¼Œè¶…è¿‡60%çš„å©šå§»çŠ¶å†µå€¼ç¼ºå¤±ï¼Œå› æ­¤å‡ ä¹å¯ä»¥è‚¯å®šçš„æ˜¯ï¼Œè¿™ä¸ªåŠŸèƒ½åº”è¯¥ä»ABTä¸­åˆ é™¤ï¼ˆæˆ‘ä»¬å¾ˆå¿«å°±ä¼šå›åˆ°è¿™ä¸ªåŠŸèƒ½ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We describe these regions as saturated: in economics when a market becomes saturated with a product, the growth in the consumption of the product flattens out; by analogy, regions of curves that are flat are said to be saturated.",
            "zh": "æˆ‘ä»¬å°†è¿™äº›åŒºåŸŸæè¿°ä¸ºé¥±å’Œï¼šåœ¨ç»æµå­¦ä¸­ï¼Œå½“å¸‚åœºå¯¹äº§å“é¥±å’Œæ—¶ï¼Œäº§å“æ¶ˆè´¹çš„å¢é•¿è¶‹äºå¹³ç¼“;ä»¥æ­¤ç±»æ¨ï¼Œå¹³å¦çš„æ›²çº¿åŒºåŸŸè¢«ç§°ä¸ºé¥±å’Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This scenario is illustrated in Figures 3.14(a)[92] to 3.14(c)[92], which shows a continuous feature following a normal distribution converted into different numbers of bins using equal-width binning.",
            "zh": "å›¾ 3.14ï¼ˆaï¼‰[92] è‡³ 3.14ï¼ˆcï¼‰[92] è¯´æ˜äº†è¿™ç§æƒ…å†µï¼Œå›¾æ˜¾ç¤ºäº†ä½¿ç”¨ç­‰å®½åˆ†ç®±è½¬æ¢ä¸ºä¸åŒæ•°é‡çš„ç®±æ•°çš„æ­£æ€åˆ†å¸ƒåçš„è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) What value will the Bayesian network predict for WINE if:",
            "zh": "ï¼ˆcï¼‰ å¦‚æœå‡ºç°ä»¥ä¸‹æƒ…å†µï¼Œè´å¶æ–¯ç½‘ç»œå°†é¢„æµ‹ WINE çš„å€¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "polynomial functions, 766",
            "zh": "å¤šé¡¹å¼å‡½æ•°ï¼Œ766"
        }
    },
    {
        "translation": {
            "en": "The problem with setting k to a high value arises because the algorithm starts taking into account neighbors that are far away from the query instance in the feature space.",
            "zh": "å°† k è®¾ç½®ä¸ºé«˜å€¼çš„é—®é¢˜å‡ºç°ï¼Œå› ä¸ºç®—æ³•å¼€å§‹è€ƒè™‘è¿œç¦»ç‰¹å¾ç©ºé—´ä¸­æŸ¥è¯¢å®ä¾‹çš„é‚»å±…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data fragmentation is essentially an instance of the curse of dimensionality.",
            "zh": "æ•°æ®ç¢ç‰‡åŒ–æœ¬è´¨ä¸Šæ˜¯ç»´åº¦è¯…å’’çš„ä¸€ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Grid worlds are an excellent environment in which to study reinforcement learning because, as we will see, it is easy to examine how the action-value table evolves over time.",
            "zh": "ç½‘æ ¼ä¸–ç•Œæ˜¯ç ”ç©¶å¼ºåŒ–å­¦ä¹ çš„ç»ä½³ç¯å¢ƒï¼Œå› ä¸ºæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œå¾ˆå®¹æ˜“æ£€æŸ¥åŠ¨ä½œ-ä»·å€¼è¡¨å¦‚ä½•éšæ—¶é—´æ¼”å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the model makes a prediction of ham incorrectly 3 times out of the 9 times that the correct prediction should be spam (33.333% of the time), while it makes a prediction of spam incorrectly just 2 times out the 11 times that the correct prediction should be ham (18.182% of the time).",
            "zh": "ä¾‹å¦‚ï¼Œè¯¥æ¨¡å‹åœ¨æ­£ç¡®é¢„æµ‹åº”è¯¥æ˜¯åƒåœ¾é‚®ä»¶çš„ 9 æ¬¡ä¸­ï¼Œæœ‰ 3 æ¬¡é”™è¯¯åœ°é¢„æµ‹äº†ç«è…¿ï¼ˆ33.333% çš„æ—¶é—´ï¼‰ï¼Œè€Œåœ¨æ­£ç¡®é¢„æµ‹åº”è¯¥æ˜¯ç«è…¿çš„ 11 æ¬¡ä¸­ï¼Œå®ƒåªå¯¹åƒåœ¾é‚®ä»¶è¿›è¡Œäº† 2 æ¬¡é”™è¯¯é¢„æµ‹ï¼ˆ18.182% çš„æ—¶é—´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, many books on neural networks cover the fundamentals of deep learning.",
            "zh": "å› æ­¤ï¼Œè®¸å¤šå…³äºç¥ç»ç½‘ç»œçš„ä¹¦ç±éƒ½æ¶µç›–äº†æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the correlation measure given in Equation (3.4)[82] responds only to linear relationships between features.",
            "zh": "é¦–å…ˆï¼Œç­‰å¼ï¼ˆ3.4ï¼‰[82]ä¸­ç»™å‡ºçš„ç›¸å…³æ€§åº¦é‡ä»…å“åº”ç‰¹å¾ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The population variance of a feature is usually denoted by Ïƒ2.",
            "zh": "ç‰¹å¾çš„æ€»ä½“æ–¹å·®é€šå¸¸ç”¨ Ïƒ2 è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "We can generate the decision boundary by aggregating the neighboring local models (in this case, Voronoi regions) that make the same prediction.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡èšåˆåšå‡ºç›¸åŒé¢„æµ‹çš„ç›¸é‚»å±€éƒ¨æ¨¡å‹ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º Voronoi åŒºåŸŸï¼‰æ¥ç”Ÿæˆå†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm begins by randomly selecting k cluster centroids, c1 to ck, where a cluster centroid is composed of a value for each descriptive feature present in a dataset (these initial cluster centroids are often referred to as seeds).",
            "zh": "è¯¥ç®—æ³•é¦–å…ˆéšæœºé€‰æ‹© k ä¸ªèšç±»è´¨å¿ƒï¼ˆc1 åˆ° ckï¼‰ï¼Œå…¶ä¸­èšç±»è´¨å¿ƒç”±æ•°æ®é›†ä¸­å­˜åœ¨çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„å€¼ç»„æˆï¼ˆè¿™äº›åˆå§‹èšç±»è´¨å¿ƒé€šå¸¸ç§°ä¸ºç§å­ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETRORAD_U/G/R/I/Z",
            "zh": "PETRORAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "If an Îµ-greedy behavior policy (or any other similar behavior policy that encourages exploration) is used, then occasionally random actions rather than the best action will be used in this step.",
            "zh": "å¦‚æœä½¿ç”¨Îµè´ªå©ªè¡Œä¸ºç­–ç•¥ï¼ˆæˆ–ä»»ä½•å…¶ä»–é¼“åŠ±æ¢ç´¢çš„ç±»ä¼¼è¡Œä¸ºç­–ç•¥ï¼‰ï¼Œåˆ™åœ¨æ­¤æ­¥éª¤ä¸­å¶å°”ä¼šä½¿ç”¨éšæœºæ“ä½œè€Œä¸æ˜¯æœ€ä½³æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "d-separation, 289",
            "zh": "D-åˆ†ç¦»ï¼Œ289"
        }
    },
    {
        "translation": {
            "en": "Finally, Equation (8.113)[511] specifies how the cell state, post the forget gate, is updated by the input gate to generate the cell state for this time-step ct.",
            "zh": "æœ€åï¼Œæ–¹ç¨‹ï¼ˆ8.113ï¼‰[511]æŒ‡å®šäº†è¾“å…¥é—¨å¦‚ä½•æ›´æ–°é—å¿˜é—¨åçš„å•å…ƒçŠ¶æ€ï¼Œä»¥ç”Ÿæˆè¯¥æ—¶é—´æ­¥é•¿ctçš„å•å…ƒçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subsequent legislation has added to this list (for example, disability was later added as a further basis for non-discrimination).",
            "zh": "éšåçš„ç«‹æ³•ä¹Ÿå¢åŠ äº†è¿™ä¸€æ¸…å•ï¼ˆä¾‹å¦‚ï¼Œåæ¥åˆå¢åŠ äº†æ®‹ç–¾ä½œä¸ºä¸æ­§è§†çš„è¿›ä¸€æ­¥åŸºç¡€ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then explain some variations on the standard algorithm as well as how clustering can be evaluated and interpreted.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬è§£é‡Šäº†æ ‡å‡†ç®—æ³•çš„ä¸€äº›å˜åŒ–ï¼Œä»¥åŠå¦‚ä½•è¯„ä¼°å’Œè§£é‡Šèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, in the move between Equations (7.13)[324] and (7.14)[324], becomes âˆ’d[j] (remember that in this equation, t is a constant and so becomes zero when differentiated).",
            "zh": "å› æ­¤ï¼Œåœ¨æ–¹ç¨‹ï¼ˆ7.13ï¼‰[324]å’Œï¼ˆ7.14ï¼‰[324]ä¹‹é—´çš„ç§»åŠ¨ä¸­ï¼Œå˜ä¸ºâˆ’d[j]ï¼ˆè¯·è®°ä½ï¼Œåœ¨è¿™ä¸ªæ–¹ç¨‹ä¸­ï¼Œtæ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œå› æ­¤åœ¨å¾®åˆ†æ—¶å˜ä¸ºé›¶ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision tree models have a feature selection mechanism built into the algorithm and so are more robust to this issue.",
            "zh": "å†³ç­–æ ‘æ¨¡å‹åœ¨ç®—æ³•ä¸­å†…ç½®äº†ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œå› æ­¤å¯¹è¿™ä¸ªé—®é¢˜æ›´å¯é ã€‚"
        }
    },
    {
        "translation": {
            "en": "18. Any percentiles (see Section A.1[745]) can be used, but deciles are particularly common.",
            "zh": "18. å¯ä»¥ä½¿ç”¨ä»»ä½•ç™¾åˆ†ä½æ•°ï¼ˆè§ç¬¬A.1[745]èŠ‚ï¼‰ï¼Œä½†ååˆ†ä½æ•°ç‰¹åˆ«å¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both networks return the same probability for the joint event. In fact, these networks will return identical probabilities for all events in this domain.",
            "zh": "ä¸¤ä¸ªç½‘ç»œä¸ºè”åˆäº‹ä»¶è¿”å›ç›¸åŒçš„æ¦‚ç‡ã€‚äº‹å®ä¸Šï¼Œè¿™äº›ç½‘ç»œå°†ä¸ºè¯¥åŸŸä¸­çš„æ‰€æœ‰äº‹ä»¶è¿”å›ç›¸åŒçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tachycardia is a condition that causes the heart to beat faster than normal at rest.",
            "zh": "å¿ƒåŠ¨è¿‡é€Ÿæ˜¯ä¸€ç§å¯¼è‡´å¿ƒè„åœ¨ä¼‘æ¯æ—¶è·³åŠ¨æ¯”æ­£å¸¸äººå¿«çš„ç–¾ç—…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The AGE and RATING feature space for the whiskey dataset. The location of the query instance is indicated by the ? symbol. The circle plotted with a dashed line demarcates the border of the neighborhood around the query when k = 3. The three nearest neighbors to the query are labeled with their ID values.",
            "zh": "å¨å£«å¿Œæ•°æ®é›†çš„ AGE å’Œ RATING ç‰¹å¾ç©ºé—´ã€‚æŸ¥è¯¢å®ä¾‹çš„ä½ç½®ç”± ï¼Ÿè±¡å¾ã€‚å½“ k = 3 æ—¶ï¼Œç”¨è™šçº¿ç»˜åˆ¶çš„åœ†åœˆåˆ’å®šäº†æŸ¥è¯¢å‘¨å›´é‚»åŸŸçš„è¾¹ç•Œã€‚æŸ¥è¯¢çš„ä¸‰ä¸ªæœ€è¿‘é‚»åŸŸæ ‡æœ‰å…¶ ID å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, even a small increase in k can have a significant impact on the decision boundary.",
            "zh": "å› æ­¤ï¼Œå³ä½¿ k çš„å¾®å°å¢åŠ ä¹Ÿä¼šå¯¹å†³ç­–è¾¹ç•Œäº§ç”Ÿé‡å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETRORATIO_R",
            "zh": "PETRORATIO_R"
        }
    },
    {
        "translation": {
            "en": "By looking at these five key families, we cover the most commonly used approaches to inductive machine learning that can be used to build most predictive data analytics solutions. The second part of the book concludes with Chapter 9[533], which describes a range of approaches to evaluating prediction models.",
            "zh": "é€šè¿‡ç ”ç©¶è¿™äº”ä¸ªå…³é”®ç³»åˆ—ï¼Œæˆ‘ä»¬æ¶µç›–äº†æœ€å¸¸ç”¨çš„å½’çº³æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å¯ç”¨äºæ„å»ºå¤§å¤šæ•°é¢„æµ‹æ€§æ•°æ®åˆ†æè§£å†³æ–¹æ¡ˆã€‚æœ¬ä¹¦çš„ç¬¬äºŒéƒ¨åˆ†ä»¥ç¬¬9ç« [533]ç»“æŸï¼Œè¯¥ç« æè¿°äº†è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„ä¸€ç³»åˆ—æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activation memory buffer is not shown in this figure because the feedback loop of storing the hidden state activations from one time-step in the buffer and reading from the buffer at the next time-step is represented by the horizontal arrows between each ht layer.",
            "zh": "æ­¤å›¾ä¸­æœªæ˜¾ç¤ºæ¿€æ´»å†…å­˜ç¼“å†²åŒºï¼Œå› ä¸ºå°†ä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ¿€æ´»å­˜å‚¨åœ¨ç¼“å†²åŒºä¸­å¹¶åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä»ç¼“å†²åŒºè¯»å–çš„åé¦ˆå¾ªç¯ç”±æ¯ä¸ª ht å±‚ä¹‹é—´çš„æ°´å¹³ç®­å¤´è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Irregular cardinality",
            "zh": "ï¼ˆbï¼‰ ä¸è§„åˆ™åŸºæ•°"
        }
    },
    {
        "translation": {
            "en": "The curved arrows in Figure 2.12[47] show the most common iterations in the process.",
            "zh": "å›¾ 2.12[47] ä¸­çš„å¼¯æ›²ç®­å¤´æ˜¾ç¤ºäº†è¯¥è¿‡ç¨‹ä¸­æœ€å¸¸è§çš„è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "33. Because of the way that they make a number of additions to a basic model, gradient boosting models can be considered an instance of a generic family of mathematical models known as additive models.",
            "zh": "33. ç”±äºæ¢¯åº¦æå‡æ¨¡å‹å¯¹åŸºæœ¬æ¨¡å‹è¿›è¡Œäº†å¤§é‡è¡¥å……ï¼Œå› æ­¤å¯ä»¥å°†å…¶è§†ä¸ºç§°ä¸ºåŠ æ³•æ¨¡å‹çš„é€šç”¨æ•°å­¦æ¨¡å‹ç³»åˆ—çš„ä¸€ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cardinality of 2 for the FRAUD FLAG feature highlights the fact that this is not really a continuous feature.",
            "zh": "FRAUD FLAG ç‰¹å¾çš„åŸºæ•°ä¸º 2 çªå‡ºäº†ä¸€ä¸ªäº‹å®ï¼Œå³è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision of which node to move to next is made by checking if any instances indexed by nodes in the subtree on the other branch of the current node could be the nearest neighbor.",
            "zh": "é€šè¿‡æ£€æŸ¥å½“å‰èŠ‚ç‚¹å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„å­æ ‘ä¸­çš„èŠ‚ç‚¹ç´¢å¼•çš„ä»»ä½•å®ä¾‹æ˜¯å¦å¯ä»¥æ˜¯æœ€è¿‘çš„é‚»å±…æ¥å†³å®šä¸‹ä¸€æ­¥ç§»åŠ¨åˆ°å“ªä¸ªèŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "SDSS, 703",
            "zh": "SDSSï¼Œ703"
        }
    },
    {
        "translation": {
            "en": "There are L layers in this network and so there are L weight matrices, where W(i) represents the weight matrix for layer i.",
            "zh": "è¯¥ç½‘ç»œä¸­æœ‰ L å±‚ï¼Œå› æ­¤æœ‰ L ä¸ªæƒé‡çŸ©é˜µï¼Œå…¶ä¸­ Wï¼ˆiï¼‰ è¡¨ç¤ºç¬¬ i å±‚çš„æƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "The main decision to be made in this process is how to select the feature to split on.",
            "zh": "åœ¨æ­¤è¿‡ç¨‹ä¸­è¦åšå‡ºçš„ä¸»è¦å†³ç­–æ˜¯å¦‚ä½•é€‰æ‹©è¦æ‹†åˆ†çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b)â€“(e) Visualizations of the prediction models trained in the early iterations of the gradient boosting process.",
            "zh": "ï¼ˆbï¼‰â€“ï¼ˆeï¼‰ åœ¨æ¢¯åº¦æå‡è¿‡ç¨‹çš„æ—©æœŸè¿­ä»£ä¸­è®­ç»ƒçš„é¢„æµ‹æ¨¡å‹çš„å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "scale parameter, 271",
            "zh": "åˆ»åº¦å‚æ•°ï¼Œ271"
        }
    },
    {
        "translation": {
            "en": "This intuition is mirrored in the derivative of the function with respect to x.",
            "zh": "è¿™ç§ç›´è§‰åæ˜ åœ¨å‡½æ•°ç›¸å¯¹äº x çš„å¯¼æ•°ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Define the topology of a Bayesian network that encodes these causal relationships.",
            "zh": "ï¼ˆaï¼‰ å®šä¹‰ç¼–ç è¿™äº›å› æœå…³ç³»çš„è´å¶æ–¯ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2166",
            "zh": "0.2166"
        }
    },
    {
        "translation": {
            "en": "This leaves us with the tasks of calculating the best threshold on which to split the ELEVATION feature, and calculating the information gain when we partition the dataset with ELEVATION using this optimal threshold.",
            "zh": "è¿™ç»™æˆ‘ä»¬ç•™ä¸‹äº†è®¡ç®—æ‹†åˆ† ELEVATION ç‰¹å¾çš„æœ€ä½³é˜ˆå€¼çš„ä»»åŠ¡ï¼Œä»¥åŠä½¿ç”¨æ­¤æœ€ä½³é˜ˆå€¼ä½¿ç”¨ ELEVATION å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºæ—¶è®¡ç®—ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Cambridge, Massachusetts",
            "zh": "é©¬è¨è¯¸å¡å·å‰‘æ¡¥å¸‚"
        }
    },
    {
        "translation": {
            "en": "where var(ZHL1) denotes the shared scalar variance of all the z values across the neurons in layer HL1; ninHL1 is the number of inputs coming into each neuron in layer HL1; var(W(HL1)) denotes the shared scalar variance of all the weights across the neurons in layer HL1; and var(d(HL1) denotes the shared scalar variance of all the inputs to layer HL1.",
            "zh": "å…¶ä¸­ varï¼ˆZHL1ï¼‰ è¡¨ç¤º HL1 å±‚ç¥ç»å…ƒä¸­æ‰€æœ‰ z å€¼çš„å…±äº«æ ‡é‡æ–¹å·®;ninHL1 æ˜¯è¿›å…¥ HL1 å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥æ•°é‡;varï¼ˆWï¼ˆHL1ï¼‰ï¼‰ è¡¨ç¤º HL1 å±‚ä¸­ç¥ç»å…ƒä¸Šæ‰€æœ‰æƒé‡çš„å…±äº«æ ‡é‡æ–¹å·®;varï¼ˆdï¼ˆHL1ï¼‰ è¡¨ç¤ºå±‚ HL1 çš„æ‰€æœ‰è¾“å…¥çš„å…±äº«æ ‡é‡æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Support vector machines and the other classification models described in Chapter 7[311] are examples of discriminative prediction models.",
            "zh": "æ”¯æŒå‘é‡æœºå’Œç¬¬7ç« [311]ä¸­æè¿°çš„å…¶ä»–åˆ†ç±»æ¨¡å‹æ˜¯åˆ¤åˆ«é¢„æµ‹æ¨¡å‹çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "cost function, 409",
            "zh": "æˆæœ¬å‡½æ•°ï¼Œ409"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) for the candidate ELEVATION thresholds: â‰¥750, â‰¥1,350, â‰¥2,250 and â‰¥4,175.",
            "zh": "å€™é€‰ ELEVATION é˜ˆå€¼çš„åˆ†åŒºé›† ï¼ˆPart.ï¼‰ã€ç†µã€ä½™æ•° ï¼ˆRem.ï¼‰ å’Œä¿¡æ¯å¢ç›Š ï¼ˆInfo. Gainï¼‰ï¼šâ‰¥750ã€â‰¥1,350ã€â‰¥2,250 å’Œ â‰¥4,175ã€‚"
        }
    },
    {
        "translation": {
            "en": "491.35",
            "zh": "491.35"
        }
    },
    {
        "translation": {
            "en": "Examples of the different galaxy morphology categories into which SDSS scientists categorize galaxy objects. Credits for these images belong to the Sloan Digital Sky Survey, www.sdss3.org.",
            "zh": "SDSSç§‘å­¦å®¶å°†æ˜Ÿç³»å¤©ä½“åˆ†ç±»ä¸ºä¸åŒæ˜Ÿç³»å½¢æ€ç±»åˆ«çš„ä¾‹å­ã€‚è¿™äº›å›¾åƒçš„ç‰ˆæƒå½’æ–¯éš†æ•°å­—å·¡å¤© www.sdss3.org æ‰€æœ‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dalgaard, Peter. 2008. Introductory statistics with R. Springer.",
            "zh": "è¾¾å°”åŠ å¾·ï¼Œå½¼å¾—ã€‚2008. R. Springer çš„ä»‹ç»æ€§ç»Ÿè®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "galaxy morphology, 704",
            "zh": "æ˜Ÿç³»å½¢æ€å­¦ï¼Œ704"
        }
    },
    {
        "translation": {
            "en": "The three smaller histograms depart from this distribution and suggest that centers tend to be taller than forwards, who in turn tend to be taller than guards.",
            "zh": "ä¸‰ä¸ªè¾ƒå°çš„ç›´æ–¹å›¾åç¦»äº†è¿™ä¸ªåˆ†å¸ƒï¼Œè¡¨æ˜ä¸­é”‹å¾€å¾€æ¯”å‰é”‹é«˜ï¼Œè€Œå‰é”‹åˆå¾€å¾€æ¯”åå«é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.38",
            "zh": "0.38"
        }
    },
    {
        "translation": {
            "en": "Data visualization is a mix of statistics, graphic design, art, and psychology. Chang (2012) and Fry (2007) both provide great detail on visualization in general and the R language in particular (the visualizations in this book are almost all generated in R). For more conceptual discussions of data visualization, Tufte (2001) and Bertin (2010) are important works in the field.",
            "zh": "æ•°æ®å¯è§†åŒ–æ˜¯ç»Ÿè®¡å­¦ã€å¹³é¢è®¾è®¡ã€è‰ºæœ¯å’Œå¿ƒç†å­¦çš„æ··åˆä½“ã€‚Chang ï¼ˆ2012ï¼‰ å’Œ Fry ï¼ˆ2007ï¼‰ éƒ½æä¾›äº†å…³äºå¯è§†åŒ–çš„ç»†èŠ‚ï¼Œç‰¹åˆ«æ˜¯ R è¯­è¨€ï¼ˆæœ¬ä¹¦ä¸­çš„å¯è§†åŒ–å‡ ä¹éƒ½æ˜¯ç”¨ R è¯­è¨€ç”Ÿæˆçš„ï¼‰ã€‚å¯¹äºæ•°æ®å¯è§†åŒ–çš„æ›´å¤šæ¦‚å¿µæ€§è®¨è®ºï¼ŒTufte ï¼ˆ2001ï¼‰ å’Œ Bertin ï¼ˆ2010ï¼‰ æ˜¯è¯¥é¢†åŸŸçš„é‡è¦è‘—ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "In all these tasks, the absence of a target feature makes determining what descriptive features are likely to be useful in an ABT and evaluating the performance of a proposed solution a little more challenging.",
            "zh": "åœ¨æ‰€æœ‰è¿™äº›ä»»åŠ¡ä¸­ï¼Œç”±äºç¼ºå°‘ç›®æ ‡ç‰¹å¾ï¼Œå› æ­¤ç¡®å®šå“ªäº›æè¿°æ€§ç‰¹å¾å¯èƒ½åœ¨ ABT ä¸­æœ‰ç”¨ï¼Œå¹¶è¯„ä¼°æ‰€å»ºè®®è§£å†³æ–¹æ¡ˆçš„æ€§èƒ½æ›´å…·æŒ‘æˆ˜æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4â€…â€…â€…Extensions and Variations",
            "zh": "8.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "4. Triangular Inequality: metric(a,b) â‰¤ metric(a,c) + metric(b,c)",
            "zh": "4. ä¸‰è§’ä¸ç­‰å¼ï¼šmetricï¼ˆaï¼Œbï¼‰ â‰¤ metricï¼ˆaï¼Œcï¼‰ + metricï¼ˆbï¼Œcï¼‰"
        }
    },
    {
        "translation": {
            "en": "An affine function is composed of a linear function followed by a translation; this simply means that the mapping defined by an affine function from inputs to outputs is linear but the plot of this mapping does not necessarily pass through the origin.",
            "zh": "ä»¿å°„å‡½æ•°ç”±çº¿æ€§å‡½æ•°åè·Ÿå¹³ç§»ç»„æˆ;è¿™ä»…ä»…æ„å‘³ç€ä»¿å°„å‡½æ•°å®šä¹‰çš„ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„æ˜¯çº¿æ€§çš„ï¼Œä½†æ­¤æ˜ å°„çš„ç»˜å›¾ä¸ä¸€å®šé€šè¿‡åŸç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A feature space plot of the data in Table 5.2[183], with the position in the feature space of the query represented by the ? marker.",
            "zh": "è¡¨5.2[183]ä¸­æ•°æ®çš„ç‰¹å¾ç©ºé—´å›¾ï¼ŒæŸ¥è¯¢åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„ä½ç½®ç”¨ ï¼Ÿæ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This first convolutional layer contains two layers of 6 neurons.",
            "zh": "ç¬¬ä¸€å·ç§¯å±‚åŒ…å«ä¸¤å±‚ 6 ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "artificial intelligence, 304, 677",
            "zh": "äººå·¥æ™ºèƒ½ï¼Œ 304ï¼Œ 677"
        }
    },
    {
        "translation": {
            "en": "Imputation techniques tend to give good results and avoid the data loss associated with deleting features or complete case analysis. It is important to note, however, that all imputation techniques suffer from the fact that they change the underlying data in an ABT and can cause the variation within a feature to be underestimated, which can negatively bias the relationships between a descriptive feature and a target feature.",
            "zh": "æ’è¡¥æŠ€æœ¯å¾€å¾€ä¼šç»™å‡ºè‰¯å¥½çš„ç»“æœï¼Œå¹¶é¿å…ä¸åˆ é™¤ç‰¹å¾æˆ–å®Œæ•´çš„æ¡ˆä¾‹åˆ†æç›¸å…³çš„æ•°æ®ä¸¢å¤±ã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰æ’è¡¥æŠ€æœ¯éƒ½å—åˆ°ä»¥ä¸‹äº‹å®çš„å½±å“ï¼šå®ƒä»¬ä¼šæ”¹å˜ ABT ä¸­çš„åŸºç¡€æ•°æ®ï¼Œå¹¶å¯èƒ½å¯¼è‡´ç‰¹å¾å†…çš„å˜åŒ–è¢«ä½ä¼°ï¼Œè¿™å¯èƒ½ä¼šå¯¹æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„å…³ç³»äº§ç”Ÿè´Ÿé¢å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "A series of charts for different model performance on the same large email classification test set used to generate the ROC curves in Figure 9.12(b)[562]. Each column from top to bottom: a histogram of the ham scores predicted by the model, a histogram of the spam scores predicted by the model, and the K-S chart.",
            "zh": "å›¾9.12ï¼ˆbï¼‰ä¸­ç”¨äºç”ŸæˆROCæ›²çº¿çš„åŒä¸€å¤§å‹ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†ä¸Šä¸åŒæ¨¡å‹æ€§èƒ½çš„ä¸€ç³»åˆ—å›¾è¡¨[562]ã€‚æ¯åˆ—ä»ä¸Šåˆ°ä¸‹ï¼šæ¨¡å‹é¢„æµ‹çš„ç«è…¿åˆ†æ•°çš„ç›´æ–¹å›¾ã€æ¨¡å‹é¢„æµ‹çš„åƒåœ¾é‚®ä»¶åˆ†æ•°çš„ç›´æ–¹å›¾ä»¥åŠ K-S æ§åˆ¶å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS and NUM.",
            "zh": "CLAIMS å’Œ NUM."
        }
    },
    {
        "translation": {
            "en": "(a) The feature space defined by the SALARY and AGE features in Table 5.5[204]; and (b) the normalized SALARY and AGE feature space based on the normalized data in Table 5.7[208]. The instances are labeled with their IDs; triangles represent instances with the no target level; and crosses represent instances with the yes target level. The location of the query SALARY = 56,000, AGE = 35 is indicated by the ?.",
            "zh": "ï¼ˆaï¼‰ è¡¨5.5[204]ä¸­SALARY å’Œ AGE ç‰¹å¾å®šä¹‰çš„ç‰¹å¾ç©ºé—´;ï¼ˆbï¼‰åŸºäºè¡¨5.7[208]ä¸­å½’ä¸€åŒ–æ•°æ®çš„å½’ä¸€åŒ–SALAWå’ŒAGEç‰¹å¾ç©ºé—´ã€‚å®ä¾‹æ ‡æœ‰å…¶ ID;ä¸‰è§’å½¢è¡¨ç¤ºå…·æœ‰æ— ç›®æ ‡çº§åˆ«çš„å®ä¾‹;å‰è¡¨ç¤ºå…·æœ‰ yes ç›®æ ‡çº§åˆ«çš„å®ä¾‹ã€‚æŸ¥è¯¢çš„ä½ç½® SALARY = 56,000ï¼Œ AGE = 35 ç”± ï¼Ÿ."
        }
    },
    {
        "translation": {
            "en": "true positive rate, 548, 549, 558",
            "zh": "çœŸé˜³æ€§ç‡ï¼Œ548ã€549ã€558"
        }
    },
    {
        "translation": {
            "en": "If this is the case, then the algorithm has reached the parent node of the root of the tree and should terminate (Line 4) by returning the instance stored in best (Line 12).",
            "zh": "å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œåˆ™ç®—æ³•å·²åˆ°è¾¾æ ‘æ ¹çš„çˆ¶èŠ‚ç‚¹ï¼Œå¹¶ä¸”åº”é€šè¿‡è¿”å›å­˜å‚¨åœ¨ bestï¼ˆç¬¬ 12 è¡Œï¼‰ä¸­çš„å®ä¾‹æ¥ç»ˆæ­¢ï¼ˆç¬¬ 4 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, the offer was a reduced call rate for the next three months, although retention team members had the freedom to make other offers.",
            "zh": "é€šå¸¸ï¼Œè¯¥æè®®æ˜¯åœ¨æ¥ä¸‹æ¥çš„ä¸‰ä¸ªæœˆå†…é™ä½å‘¼å«è´¹ç‡ï¼Œå°½ç®¡ä¿ç•™å›¢é˜Ÿæˆå‘˜å¯ä»¥è‡ªç”±æå‡ºå…¶ä»–æè®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.2â€…â€…â€…The ABT for the motor insurance claims fraud detection solution.",
            "zh": "2.2 ç”¨äºæ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹è§£å†³æ–¹æ¡ˆçš„ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4.2â€ƒFeature Selection",
            "zh": "13.4.2 åŠŸèƒ½é€‰æ‹©"
        }
    },
    {
        "translation": {
            "en": "CMODELMAG_U/G/R/I/Z",
            "zh": "CMODELMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It is usual in k-means clustering for Dist to calculate Euclidean distance.2 As discussed in Section 5.4.3[204] in relation to similarity models for predictive modeling, it is important that all descriptive features are normalized before using k-means clustering so that distance contributions across features are comparable.",
            "zh": "2 æ­£å¦‚ç¬¬ 5.4.3 èŠ‚[204]ä¸­å…³äºé¢„æµ‹å»ºæ¨¡çš„ç›¸ä¼¼æ€§æ¨¡å‹æ‰€è®¨è®ºçš„ï¼Œåœ¨ä½¿ç”¨ k-means èšç±»ä¹‹å‰ï¼Œå¿…é¡»å¯¹æ‰€æœ‰æè¿°æ€§ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œä»¥ä¾¿ç‰¹å¾ä¹‹é—´çš„è·ç¦»è´¡çŒ®å…·æœ‰å¯æ¯”æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "regression task, 149",
            "zh": "å›å½’ä»»åŠ¡ï¼Œ149"
        }
    },
    {
        "translation": {
            "en": "8.35â€…â€…â€…Schematic of the typical sequences of layers found in a convolutional neural network.",
            "zh": "8.35 å·ç§¯ç¥ç»ç½‘ç»œä¸­å…¸å‹å±‚åºåˆ—çš„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this scenario, then will be relatively close to 1 (and the better the modelâ€™s prediction the closer to one will be).",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ™ç›¸å¯¹æ¥è¿‘ 1ï¼ˆæ¨¡å‹çš„é¢„æµ‹è¶Šå¥½ï¼Œå°±è¶Šæ¥è¿‘ 1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These low cardinalities were investigated with the business.",
            "zh": "è¿™äº›ä½åŸºæ•°ä¸ä¼ä¸šä¸€èµ·è¿›è¡Œäº†è°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.23)[412] illustrates how the term âˆ‚â„°/âˆ‚a k is calculated for a hidden neuron and how this term is then used to calculate the Î´ for a hidden neuron by multiplying it by the term âˆ‚ak/âˆ‚zk (which, as previously described, is calculated by plugging the zk into the derivative of the activation function).",
            "zh": "æ–¹ç¨‹ï¼ˆ8.23ï¼‰[412]è¯´æ˜äº†å¦‚ä½•è®¡ç®—éšè—ç¥ç»å…ƒçš„é¡¹âˆ‚E/âˆ‚a kï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨è¯¥é¡¹é€šè¿‡å°†å…¶ä¹˜ä»¥é¡¹âˆ‚ak/âˆ‚zkï¼ˆå¦‚å‰æ‰€è¿°ï¼Œé€šè¿‡å°†zkä»£å…¥æ¿€æ´»å‡½æ•°çš„å¯¼æ•°æ¥è®¡ç®—ï¼‰æ¥è®¡ç®—éšè—ç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "We do not derive the derivatives of the softmax for each of these cases, as that is relatively convoluted, involving in quotient rule from calculus; instead, we simply state them",
            "zh": "å¯¹äºæ¯ç§æƒ…å†µï¼Œæˆ‘ä»¬éƒ½æ²¡æœ‰æ¨å¯¼å‡ºè½¯æœ€å¤§å€¼çš„å¯¼æ•°ï¼Œå› ä¸ºè¿™ç›¸å¯¹å¤æ‚ï¼Œæ¶‰åŠå¾®ç§¯åˆ†çš„å•†è§„åˆ™;ç›¸åï¼Œæˆ‘ä»¬åªæ˜¯ç®€å•åœ°é™ˆè¿°å®ƒä»¬"
        }
    },
    {
        "translation": {
            "en": "complete linkage, 619",
            "zh": "å®Œå…¨è”åŠ¨ï¼Œ619"
        }
    },
    {
        "translation": {
            "en": "The reason why this difference is considered a rate of change is that the larger the difference between ak and tk, the faster the error of the network can be changed by changing the activation. However, the direction of the calculated gradient is toward the highest value on the error surface, and therefore to move down the error surface we should multiply it by âˆ’ 1.11 Hence, using the sum of squared errors error function, the error gradient for a single output neuron k on a single example is",
            "zh": "ä¹‹æ‰€ä»¥å°†è¿™ç§å·®å¼‚è§†ä¸ºå˜åŒ–ç‡ï¼Œæ˜¯å› ä¸º ak å’Œ tk ä¹‹é—´çš„å·®å¼‚è¶Šå¤§ï¼Œé€šè¿‡æ›´æ”¹æ¿€æ´»å¯ä»¥æ›´å¿«åœ°æ”¹å˜ç½‘ç»œçš„è¯¯å·®ã€‚ç„¶è€Œï¼Œè®¡ç®—å‡ºçš„æ¢¯åº¦çš„æ–¹å‘æœå‘è¯¯å·®æ›²é¢ä¸Šçš„æœ€é«˜å€¼ï¼Œå› æ­¤è¦å‘ä¸‹ç§»åŠ¨è¯¯å·®æ›²é¢ï¼Œæˆ‘ä»¬åº”è¯¥å°†å…¶ä¹˜ä»¥ âˆ’ 1.11 å› æ­¤ï¼Œä½¿ç”¨è¯¯å·®è¯¯å·®å‡½æ•°çš„å¹³æ–¹å’Œï¼Œå•ä¸ªç¤ºä¾‹ä¸Šå•ä¸ªè¾“å‡ºç¥ç»å…ƒ k çš„è¯¯å·®æ¢¯åº¦ä¸º"
        }
    },
    {
        "translation": {
            "en": "The Claimant History domain concept that we developed for this scenario indicates the importance of information regarding the previous claims made by the claimant to the task of identifying fraudulent claims.",
            "zh": "æˆ‘ä»¬ä¸ºæ­¤æ–¹æ¡ˆå¼€å‘çš„â€œç´¢èµ”äººå†å²è®°å½•â€åŸŸæ¦‚å¿µè¡¨æ˜ï¼Œæœ‰å…³ç´¢èµ”äººå…ˆå‰æå‡ºçš„ç´¢èµ”çš„ä¿¡æ¯å¯¹äºè¯†åˆ«æ¬ºè¯ˆæ€§ç´¢èµ”çš„ä»»åŠ¡éå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. For further details, see www.ibm.com/software/ie/analytics/spss, www.knime.org, www.rapidminer.com, www.sas.com, and www.cs.waikato.ac.nz/ml/weka.",
            "zh": "14. æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… www.ibm.com/software/ie/analytics/spssã€www.knime.orgã€www.rapidminer.comã€www.sas.com å’Œ www.cs.waikato.ac.nz/ml/wekaã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if we already know that the patient has meningitis, then also knowing that the patient has a headache will not affect the probability of the patient having a fever.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å·²ç»çŸ¥é“æ‚£è€…æ‚£æœ‰è„‘è†œç‚ï¼Œé‚£ä¹ˆä¹ŸçŸ¥é“æ‚£è€…å¤´ç—›ä¸ä¼šå½±å“æ‚£è€…å‘çƒ§çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Q-learning algorithm discussed in Section 11.3[657] is referred to as off-policy as the behavior policy is not used to select the action to be taken in the next state when Q values are updated (a greedy target policy is used instead).",
            "zh": "ç¬¬ 11.3 èŠ‚[657] ä¸­è®¨è®ºçš„ Q å­¦ä¹ ç®—æ³•ç§°ä¸º off-policyï¼Œå› ä¸ºå½“ Q å€¼æ›´æ–°æ—¶ï¼Œè¡Œä¸ºç­–ç•¥ä¸ç”¨äºé€‰æ‹©åœ¨ä¸‹ä¸€ä¸ªçŠ¶æ€ä¸‹è¦æ‰§è¡Œçš„æ“ä½œï¼ˆè€Œæ˜¯ä½¿ç”¨è´ªå©ªç›®æ ‡ç­–ç•¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.12[214] presents a pairwise analysis of similarity between the current trial user, q, and the two customers in the dataset in Table 5.11[213] in terms of",
            "zh": "è¡¨5.12[214]å¯¹å½“å‰è¯•éªŒç”¨æˆ·qä¸è¡¨5.11[213]ä¸­æ•°æ®é›†ä¸­çš„ä¸¤ä¸ªå®¢æˆ·ä¹‹é—´çš„ç›¸ä¼¼æ€§è¿›è¡Œäº†æˆå¯¹åˆ†æï¼ŒåŒ…æ‹¬ï¼š"
        }
    },
    {
        "translation": {
            "en": "Algorithm 6[474] lists the early stopping algorithm.",
            "zh": "ç®—æ³•6[474]åˆ—å‡ºäº†æ—©æœŸåœæ­¢ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "420.26MW",
            "zh": "420.26å…†ç“¦"
        }
    },
    {
        "translation": {
            "en": "2.7â€…â€…â€…Exercises",
            "zh": "2.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "This shows that the clustering with three clusters has the highest silhouette score and could be chosen as the most appropriate clustering given the assumptions that underlie the silhouette.",
            "zh": "è¿™è¡¨æ˜å…·æœ‰ä¸‰ä¸ªèšç±»çš„èšç±»å…·æœ‰æœ€é«˜çš„è½®å»“å¾—åˆ†ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®è½®å»“åŸºç¡€çš„å‡è®¾é€‰æ‹©ä¸ºæœ€åˆé€‚çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "An easy way to address this issue is to perform multiple runs of the k-means clustering algorithm starting from different initial centroids and then aggregate the results.",
            "zh": "è§£å†³æ­¤é—®é¢˜çš„ä¸€ç§ç®€å•æ–¹æ³•æ˜¯ä»ä¸åŒçš„åˆå§‹è´¨å¿ƒå¼€å§‹å¤šæ¬¡è¿è¡Œ k å‡å€¼èšç±»ç®—æ³•ï¼Œç„¶åèšåˆç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "We will look at application-based solutions first.",
            "zh": "æˆ‘ä»¬å°†é¦–å…ˆç ”ç©¶åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The concept of a probability distribution also applies to joint probabilities, which gives us the concept of a joint probability distribution.",
            "zh": "æ¦‚ç‡åˆ†å¸ƒçš„æ¦‚å¿µä¹Ÿé€‚ç”¨äºè”åˆæ¦‚ç‡ï¼Œè¿™ç»™äº†æˆ‘ä»¬è”åˆæ¦‚ç‡åˆ†å¸ƒçš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "IQR, 749",
            "zh": "å››åˆ†çº¿ï¼Œ749"
        }
    },
    {
        "translation": {
            "en": "patience, 473",
            "zh": "è€å¿ƒï¼Œ473"
        }
    },
    {
        "translation": {
            "en": "Second, Jocelyn calculated an inter-annotator agreement statistic for the manual classifications given by the five SDSS scientists.",
            "zh": "å…¶æ¬¡ï¼ŒJocelyn è®¡ç®—äº†äº”ä½ SDSS ç§‘å­¦å®¶ç»™å‡ºçš„æ‰‹åŠ¨åˆ†ç±»çš„æ³¨é‡Šè€…é—´ä¸€è‡´æ€§ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2â€ƒFundamentals",
            "zh": "7.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "Also, there are no gaps between the histogram bars, which indicates that there are no empty bins.",
            "zh": "æ­¤å¤–ï¼Œç›´æ–¹å›¾æ¡ä¹‹é—´æ²¡æœ‰é—´éš™ï¼Œè¿™è¡¨æ˜æ²¡æœ‰ç©ºç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "The old approach of doing all this manually has become obsolete because the volume of data involved is just too large.",
            "zh": "æ‰‹åŠ¨å®Œæˆæ‰€æœ‰è¿™äº›æ“ä½œçš„æ—§æ–¹æ³•å·²ç»è¿‡æ—¶ï¼Œå› ä¸ºæ¶‰åŠçš„æ•°æ®é‡å¤ªå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors error function, L2, is formally defined as",
            "zh": "è¯¯å·®è¯¯å·®å‡½æ•°çš„å¹³æ–¹å’Œè¯¯å·®å‡½æ•° L2 è¢«æ­£å¼å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Note that Ï†sm(li) can be understood as equivalent to Ï†sm(zi) in Equation (8.65)[463 the notational differences arise because we are now specifying the parameter as an index of a logit rather than specifying the z score directly.",
            "zh": "è¯·æ³¨æ„ï¼ŒÏ†smï¼ˆliï¼‰å¯ä»¥ç†è§£ä¸ºç­‰ä»·äºç­‰å¼ï¼ˆ8.65ï¼‰[463ä¸­çš„Ï†smï¼ˆziï¼‰[463ï¼Œä¹‹æ‰€ä»¥å‡ºç°ç¬¦å·å·®å¼‚ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬ç°åœ¨å°†å‚æ•°æŒ‡å®šä¸ºlogitçš„ç´¢å¼•ï¼Œè€Œä¸æ˜¯ç›´æ¥æŒ‡å®šzåˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.4â€ƒWhy Are Non-Linear Activation Functions Necessary?",
            "zh": "8.2.4 ä¸ºä»€ä¹ˆéœ€è¦éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "average class accuracy, 550, 551, 554, 577, 586, 591, 698",
            "zh": "å¹³å‡ç­‰çº§ç²¾åº¦ï¼Œ550ã€551ã€554ã€577ã€586ã€591ã€698"
        }
    },
    {
        "translation": {
            "en": "decoder, 624",
            "zh": "è§£ç å™¨ï¼Œ624"
        }
    },
    {
        "translation": {
            "en": "However, rather than training these models to perform the original prediction taskâ€”to predict the target feature t based on the descriptive features dâ€”these models are trained to predict the errors that the previous model is likely to have made.32 In this way the newly trained models are directly trying to correct, and therefore improve, the predictions made by the models previously added to the ensemble.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¸æ˜¯è®­ç»ƒè¿™äº›æ¨¡å‹æ¥æ‰§è¡ŒåŸå§‹çš„é¢„æµ‹ä»»åŠ¡â€”â€”æ ¹æ®æè¿°æ€§ç‰¹å¾ d é¢„æµ‹ç›®æ ‡ç‰¹å¾ tâ€”â€”è€Œæ˜¯è®­ç»ƒè¿™äº›æ¨¡å‹æ¥é¢„æµ‹å…ˆå‰æ¨¡å‹å¯èƒ½çŠ¯çš„é”™è¯¯.32 ä»¥è¿™ç§æ–¹å¼ï¼Œæ–°è®­ç»ƒçš„æ¨¡å‹ç›´æ¥å°è¯•çº æ­£ï¼Œä»è€Œæ”¹è¿›ï¼Œ å…ˆå‰æ·»åŠ åˆ°é›†åˆä¸­çš„æ¨¡å‹æ‰€åšçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We note these types of data quality issues during exploration for potential handling when we reach the Modeling phase of a project.",
            "zh": "å½“æˆ‘ä»¬åˆ°è¾¾é¡¹ç›®çš„å»ºæ¨¡é˜¶æ®µæ—¶ï¼Œæˆ‘ä»¬ä¼šåœ¨æ¢ç´¢æ½œåœ¨å¤„ç†è¿‡ç¨‹ä¸­æ³¨æ„åˆ°è¿™äº›ç±»å‹çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard reinforcement learning approach, Q-learning, a form of temporal-difference learning, is then described.",
            "zh": "ç„¶åæè¿°äº†æ ‡å‡†çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå³Q-learningï¼Œä¸€ç§æ—¶é—´å·®å¼‚å­¦ä¹ å½¢å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each proposed solution, the following points should be described: (1) the predictive model that will be built; (2) how the predictive model will be used by the business; and (3) how using the predictive model will help address the original business problem.",
            "zh": "å¯¹äºæ¯ä¸ªæå‡ºçš„è§£å†³æ–¹æ¡ˆï¼Œåº”æè¿°ä»¥ä¸‹å‡ ç‚¹ï¼šï¼ˆ1ï¼‰å°†è¦æ„å»ºçš„é¢„æµ‹æ¨¡å‹;ï¼ˆ2ï¼‰ä¼ä¸šå¦‚ä½•ä½¿ç”¨é¢„æµ‹æ¨¡å‹;ï¼ˆ3ï¼‰ä½¿ç”¨é¢„æµ‹æ¨¡å‹å°†å¦‚ä½•å¸®åŠ©è§£å†³åŸå§‹ä¸šåŠ¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "peeking, 536",
            "zh": "å·çœ‹ï¼Œ536"
        }
    },
    {
        "translation": {
            "en": "If we were processing RGB images, then we would use three-dimensional filters: height by width by channel.",
            "zh": "å¦‚æœæˆ‘ä»¬è¦å¤„ç†RGBå›¾åƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†ä½¿ç”¨ä¸‰ç»´æ»¤é•œï¼šé«˜åº¦å’Œå®½åº¦ï¼Œé€šé“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This distance from the decision boundary to the nearest training instance is known as the margin.",
            "zh": "ä»å†³ç­–è¾¹ç•Œåˆ°æœ€è¿‘çš„è®­ç»ƒå®ä¾‹çš„è·ç¦»ç§°ä¸ºè¾¹é™…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.11",
            "zh": "å›¾ 2.11"
        }
    },
    {
        "translation": {
            "en": "11. A hyperplane is a geometric concept that generalizes the idea of a plane into different dimensions. For example, a hyperplane in 2D space is a line and in a 3D space is a plane.",
            "zh": "11. è¶…å¹³é¢æ˜¯ä¸€ä¸ªå‡ ä½•æ¦‚å¿µï¼Œå®ƒå°†å¹³é¢çš„æ¦‚å¿µæ¨å¹¿åˆ°ä¸åŒçš„ç»´åº¦ã€‚ä¾‹å¦‚ï¼Œ2D ç©ºé—´ä¸­çš„è¶…å¹³é¢æ˜¯ä¸€æ¡çº¿ï¼Œè€Œ 3D ç©ºé—´ä¸­çš„è¶…å¹³é¢æ˜¯å¹³é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The rate of change of the network error with respect to changes in a weight is written mathematically as âˆ‚â„°/âˆ‚wi,k for the weight on the connection from neuron k to neuron i. Using the chain rule12 we can rewrite this term as a product of three terms",
            "zh": "ç½‘ç»œè¯¯å·®ç›¸å¯¹äºæƒé‡å˜åŒ–çš„å˜åŒ–ç‡åœ¨æ•°å­¦ä¸Šå†™ä¸º âˆ‚E/âˆ‚wiï¼Œkï¼Œè¡¨ç¤ºä»ç¥ç»å…ƒ k åˆ°ç¥ç»å…ƒ i çš„è¿æ¥ä¸Šçš„æƒé‡ã€‚ä½¿ç”¨é“¾å¼æ³•åˆ™12ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¯¥æœ¯è¯­é‡å†™ä¸ºä¸‰ä¸ªæœ¯è¯­çš„ä¹˜ç§¯"
        }
    },
    {
        "translation": {
            "en": "The algorithm really is very simple, so we can move straight to looking at a worked example of it in action.",
            "zh": "è¯¥ç®—æ³•éå¸¸ç®€å•ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç›´æ¥æŸ¥çœ‹å®ƒçš„å®é™…æ“ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor model is now factoring both SALARY and AGE into the ranking of the instances.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹ç°åœ¨å°† SALARY å’Œ AGE éƒ½è€ƒè™‘åœ¨å®ä¾‹çš„æ’åä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Frequently, when bagging is used with decision trees, the sampling process is extended so that each bootstrap sample uses only a randomly selected subset of the descriptive features in the dataset.",
            "zh": "é€šå¸¸ï¼Œå½“å°†è£…è¢‹ä¸å†³ç­–æ ‘ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œé‡‡æ ·è¿‡ç¨‹ä¼šæ‰©å±•ï¼Œä»¥ä¾¿æ¯ä¸ªå¼•å¯¼æ ·æœ¬ä»…ä½¿ç”¨æ•°æ®é›†ä¸­éšæœºé€‰æ‹©çš„æè¿°æ€§ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "cumulative lift, 567, 570, 700",
            "zh": "ç´¯è®¡æ‰¬ç¨‹ï¼Œ 567ï¼Œ 570ï¼Œ 700"
        }
    },
    {
        "translation": {
            "en": "1. Forward Pass An input pattern is presented to the network, and the activations flow forward through the network until an output is generated.",
            "zh": "1. å‰å‘ä¼ é€’ è¾“å…¥æ¨¡å¼å‘ˆç°ç»™ç½‘ç»œï¼Œæ¿€æ´»åœ¨ç½‘ç»œä¸­å‘å‰æµåŠ¨ï¼Œç›´åˆ°ç”Ÿæˆè¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Cohen, Jacob. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement 20 (1): 34â€“46.",
            "zh": "ç§‘æ©ï¼Œé›…å„å¸ƒã€‚1960. æ ‡ç§°å°ºåº¦çš„ä¸€è‡´æ€§ç³»æ•°ã€‚æ•™è‚²å’Œå¿ƒç†æµ‹é‡20ï¼ˆ1ï¼‰ï¼š34-46ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see in this structure that the target feature, FRAUD, has no parents and is the single parent for all the descriptive feature nodes.",
            "zh": "åœ¨è¿™ä¸ªç»“æ„ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç›®æ ‡ç‰¹å¾ FRAUD æ²¡æœ‰çˆ¶çº§ï¼Œå¹¶ä¸”æ˜¯æ‰€æœ‰æè¿°æ€§ç‰¹å¾èŠ‚ç‚¹çš„å•çˆ¶çº§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.9",
            "zh": "å›¾ 5.9"
        }
    },
    {
        "translation": {
            "en": "You should notice, however, that, in general, the larger the sample, the smaller the margin of error.",
            "zh": "ä½†æ˜¯ï¼Œæ‚¨åº”è¯¥æ³¨æ„åˆ°ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæ ·æœ¬è¶Šå¤§ï¼Œè¯¯å·®èŒƒå›´è¶Šå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is, however, a challenge here, as usually, there are a large number of descriptive features for which measures need to be calculated and tracked.",
            "zh": "ç„¶è€Œï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæŒ‘æˆ˜ï¼Œåƒå¾€å¸¸ä¸€æ ·ï¼Œæœ‰å¤§é‡çš„æè¿°æ€§ç‰¹å¾éœ€è¦è®¡ç®—å’Œè·Ÿè¸ªåº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "To restate Equation (11.9)[643] in terms of the components of an MDP, we modify Equation (11.9)[643] to sum to infinity rather than just the end of an episode,12 and we state the equation a little more succinctly",
            "zh": "ä¸ºäº†æ ¹æ® MDP çš„ç»„æˆéƒ¨åˆ†é‡è¿°ç­‰å¼ ï¼ˆ11.9ï¼‰[643]ï¼Œæˆ‘ä»¬å°†ç­‰å¼ ï¼ˆ11.9ï¼‰[643] ä¿®æ”¹ä¸ºæ±‚å’Œä¸ºæ— ç©·å¤§ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€é›†çš„ç»“å°¾ï¼Œ12 å¹¶ä¸”æˆ‘ä»¬æ›´ç®€æ´åœ°é™ˆè¿°äº†ç­‰å¼"
        }
    },
    {
        "translation": {
            "en": "HEALTHINS: Whether the customer holds a health insurance policy with the company (yes or no)",
            "zh": "HEALTHINSï¼šå®¢æˆ·æ˜¯å¦æŒæœ‰å…¬å¸çš„å¥åº·ä¿é™©å•ï¼ˆæ˜¯æˆ–å¦ï¼‰"
        }
    },
    {
        "translation": {
            "en": "3. The table below shows a sample of a larger dataset containing details of policyholders at an insurance company. The descriptive features included in the table describe each policy holdersâ€™ ID, occupation, gender, age, the value of their car, the type of insurance policy they hold, and their preferred contact channel.",
            "zh": "3. ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†çš„æ ·æœ¬ï¼Œå…¶ä¸­åŒ…å«ä¿é™©å…¬å¸æŠ•ä¿äººçš„è¯¦ç»†ä¿¡æ¯ã€‚è¡¨ä¸­åŒ…å«çš„æè¿°æ€§ç‰¹å¾æè¿°äº†æ¯ä¸ªæŠ•ä¿äººçš„ IDã€èŒä¸šã€æ€§åˆ«ã€å¹´é¾„ã€ä»–ä»¬çš„æ±½è½¦ä»·å€¼ã€ä»–ä»¬æŒæœ‰çš„ä¿é™©å•ç±»å‹ä»¥åŠä»–ä»¬é¦–é€‰çš„è”ç³»æ¸ é“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the model assumes that all the descriptive features are conditionally independent of each other given the value of the target feature.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œæ¨¡å‹å‡è®¾æ‰€æœ‰æè¿°æ€§ç‰¹å¾åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çš„å€¼æ—¶éƒ½æ˜¯æœ‰æ¡ä»¶åœ°ç›¸äº’ç‹¬ç«‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, Jocelyn addressed the target level imbalance problem by using under-sampling to generate a new training dataset in which all three target levels had an equal distribution.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼ŒJocelyn é€šè¿‡ä½¿ç”¨æ¬ é‡‡æ ·æ¥ç”Ÿæˆä¸€ä¸ªæ–°çš„è®­ç»ƒæ•°æ®é›†ï¼Œå…¶ä¸­æ‰€æœ‰ä¸‰ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†å¸ƒç›¸ç­‰ï¼Œä»è€Œè§£å†³äº†ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We might be tempted to think that having multiple models that are consistent with the data is a good thing.",
            "zh": "æˆ‘ä»¬å¯èƒ½ä¼šè®¤ä¸ºæ‹¥æœ‰å¤šä¸ªä¸æ•°æ®ä¸€è‡´çš„æ¨¡å‹æ˜¯ä¸€ä»¶å¥½äº‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "edges: nodes are connected by directed links; the connectivity of the links in a graph encodes the influence and conditional independence relationships between nodes.",
            "zh": "è¾¹ï¼šèŠ‚ç‚¹é€šè¿‡æœ‰å‘é“¾æ¥è¿æ¥;å›¾ä¸­é“¾æ¥çš„è¿é€šæ€§å¯¹èŠ‚ç‚¹ä¹‹é—´çš„å½±å“å’Œæ¡ä»¶ç‹¬ç«‹æ€§å…³ç³»è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "Understanding that we are dealing with shared weights is important because the standard process for updating a shared weight is (a) to calculate the weight update for the weight at each location in the network where it is used; (b) to sum these weight updates together; and (c) finally to update the weight once using this summed weight update.",
            "zh": "äº†è§£æˆ‘ä»¬æ­£åœ¨å¤„ç†å…±äº«æƒé‡å¾ˆé‡è¦ï¼Œå› ä¸ºæ›´æ–°å…±äº«æƒé‡çš„æ ‡å‡†è¿‡ç¨‹æ˜¯ ï¼ˆaï¼‰ è®¡ç®—ç½‘ç»œä¸­ä½¿ç”¨æƒé‡çš„æ¯ä¸ªä½ç½®çš„æƒé‡æ›´æ–°;ï¼ˆbï¼‰ å°†è¿™äº›é‡é‡æ›´æ–°ç›¸åŠ ;ï¼ˆcï¼‰æœ€åä½¿ç”¨æ­¤æ€»é‡æ›´æ–°æ›´æ–°ä¸€æ¬¡æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, the lift at each decile dec is the percentage of spam instances in that decile divided by 0.45.",
            "zh": "å› æ­¤ï¼Œæ¯ä¸ªååˆ†ä½æ•°çš„æå‡æ˜¯è¯¥ååˆ†ä½æ•°ä¸­åƒåœ¾é‚®ä»¶å®ä¾‹çš„ç™¾åˆ†æ¯”é™¤ä»¥ 0.45ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, range normalization using the range [0,1] is applied to instance d1 from Table 5.5[204] as follows:",
            "zh": "ä¾‹å¦‚ï¼Œä½¿ç”¨èŒƒå›´ [0,1] çš„èŒƒå›´å½’ä¸€åŒ–åº”ç”¨äºè¡¨ 5.5[204] ä¸­çš„å®ä¾‹ d1ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(h) Different clusterings (all with k = 3) that can be found for the mobile phone customer dataset given in Table 10.1[604] when different initial cluster centroids are used.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆhï¼‰ å½“ä½¿ç”¨ä¸åŒçš„åˆå§‹èšç±»è´¨å¿ƒæ—¶ï¼Œå¯ä»¥åœ¨è¡¨ 10.1[604] ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­æ‰¾åˆ°ä¸åŒçš„èšç±»ï¼ˆå‡ä¸º k = 3ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "connectionism, 382",
            "zh": "è”ç»“ä¸»ä¹‰ï¼Œ382"
        }
    },
    {
        "translation": {
            "en": "The idea that human mental phenomena emerge through the interconnections between neurons became known as connectionism.",
            "zh": "äººç±»å¿ƒç†ç°è±¡é€šè¿‡ç¥ç»å…ƒä¹‹é—´çš„ç›¸äº’è¿æ¥è€Œå‡ºç°çš„æƒ³æ³•è¢«ç§°ä¸ºè”ç»“ä¸»ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The path through the decision tree for this query instance is shown in Figure 4.4(c)[122].",
            "zh": "å›¾ 4.4ï¼ˆcï¼‰[122] æ˜¾ç¤ºäº†æ­¤æŸ¥è¯¢å®ä¾‹çš„å†³ç­–æ ‘è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "purpose specification principle, 41",
            "zh": "ç›®çš„è§„èŒƒåŸåˆ™ï¼Œ41"
        }
    },
    {
        "translation": {
            "en": "The model predicts a correction value of âˆ’ 460.9 for input temperatures less than or equal to 9.5 degrees, and a correction value of 691.4 for temperatures above this threshold.",
            "zh": "è¯¥æ¨¡å‹é¢„æµ‹ï¼Œå½“è¾“å…¥æ¸©åº¦å°äºæˆ–ç­‰äº 9.5 åº¦æ—¶ï¼Œæ ¡æ­£å€¼ä¸º âˆ’ 460.9ï¼Œå¯¹äºé«˜äºæ­¤é˜ˆå€¼çš„æ¸©åº¦ï¼Œæ ¡æ­£å€¼ä¸º 691.4ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result of these considerations, feature design and implementation is an iterative process in which data exploration informs the design and implementation of features, which in turn inform further data exploration, and so on.",
            "zh": "ç”±äºè¿™äº›è€ƒè™‘å› ç´ ï¼ŒåŠŸèƒ½è®¾è®¡å’Œå®ç°æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ•°æ®æ¢ç´¢ä¸ºåŠŸèƒ½çš„è®¾è®¡å’Œå®ç°æä¾›ä¿¡æ¯ï¼Œè€ŒåŠŸèƒ½å’Œå®ç°åˆä¸ºè¿›ä¸€æ­¥çš„æ•°æ®æ¢ç´¢æä¾›ä¿¡æ¯ï¼Œä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.14â€…â€…â€…The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "8.14 è¡¨8.3[423]æ‰€åˆ—ç¤ºä¾‹é€šè¿‡å›¾8.4[390]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gradient boosting can be said to do this in a more aggressive way than the boosting algorithm described previously.",
            "zh": "å¯ä»¥è¯´æ¢¯åº¦æå‡ä»¥æ¯”å‰é¢æè¿°çš„æå‡ç®—æ³•æ›´æ¿€è¿›çš„æ–¹å¼åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This normal distribution is known as the standard normal distribution.",
            "zh": "è¿™ç§æ­£æ€åˆ†å¸ƒç§°ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The values in this matrix are based on historical data that the company has on loans given out in the past.",
            "zh": "æ­¤çŸ©é˜µä¸­çš„å€¼åŸºäºå…¬å¸è¿‡å»å‘æ”¾çš„è´·æ¬¾çš„å†å²æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision tree model ensembles based on bagging and boosting are also discriminative models.",
            "zh": "åŸºäºbaggingå’Œboostingçš„å†³ç­–æ ‘æ¨¡å‹é›†åˆä¹Ÿæ˜¯åˆ¤åˆ«æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using variance as our measure of impurity, we can select which feature to split on at a node by selecting the feature that minimizes the weighted variance across the resulting partitions.",
            "zh": "ä½¿ç”¨æ–¹å·®ä½œä¸ºæ‚è´¨çš„åº¦é‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰æ‹©æœ€å°åŒ–ç»“æœåˆ†åŒºä¸­åŠ æƒæ–¹å·®çš„ç‰¹å¾æ¥é€‰æ‹©è¦åœ¨èŠ‚ç‚¹ä¸Šæ‹†åˆ†çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Burges, Christopher J. C. 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery 2 (2): 121â€“167.",
            "zh": "ä¼¯å‰æ–¯ï¼Œå…‹é‡Œæ–¯æ‰˜å¼— JC 1998 å¹´ã€‚å…³äºæ¨¡å¼è¯†åˆ«çš„æ”¯æŒå‘é‡æœºçš„æ•™ç¨‹ã€‚æ•°æ®æŒ–æ˜ä¸çŸ¥è¯†å‘ç° 2 ï¼ˆ2ï¼‰ï¼š121â€“167ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, he decided to delete the AGE and OCCUPATION features because of the level of missing values in each of these features.",
            "zh": "é¦–å…ˆï¼Œä»–å†³å®šåˆ é™¤ AGE å’Œ OCCUPATION è¦ç´ ï¼Œå› ä¸ºæ¯ä¸ªè¦ç´ çš„ç¼ºå¤±å€¼çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.4",
            "zh": "è¡¨ 5.4"
        }
    },
    {
        "translation": {
            "en": "The other two partitions created by splitting 8 are pure with respect to the target feature: 17 contains one instance with a conifer target level, and 19 contains two instances that both have a chapparal target level.",
            "zh": "é€šè¿‡æ‹†åˆ† 8 åˆ›å»ºçš„å¦å¤–ä¸¤ä¸ªåˆ†åŒºç›¸å¯¹äºç›®æ ‡ç‰¹å¾æ˜¯çº¯çš„ï¼š17 åŒ…å«ä¸€ä¸ªå…·æœ‰é’ˆå¶æ ‘ç›®æ ‡çº§åˆ«çš„å®ä¾‹ï¼Œ19 åŒ…å«ä¸¤ä¸ªå®ä¾‹ï¼Œè¿™ä¸¤ä¸ªå®ä¾‹éƒ½å…·æœ‰ chapparal ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Probabilities",
            "zh": "æ¦‚ç‡çš„ç¬¦å·çº¦å®š"
        }
    },
    {
        "translation": {
            "en": "Stoughton, Chris, Robert H. Lupton, Mariangela Bernardi, Michael R. Blanton, Scott Burles, Francisco J. Castander, A. J. Connolly, Daniel J. Eisenstein, Joshua A. Frieman, G. S. Hennessy, et al.. 2002. Sloan digital sky survey: Early data release. The Astronomical Journal 123 (1): 485. http://stacks.iop.org/1538-3881/123/i=1/a=485.",
            "zh": "æ–¯æ‰˜é¡¿ã€å…‹é‡Œæ–¯ã€ç½—ä¼¯ç‰¹Â·å¢æ™®é¡¿ã€ç›ä¸½å®‰å‰æ‹‰Â·ä¼¯çº³è¿ªã€è¿ˆå…‹å°”Â·å¸ƒå…°é¡¿ã€æ–¯ç§‘ç‰¹Â·ä¼¯å°”æ–¯ã€å¼—æœ—è¥¿æ–¯ç§‘Â·å¡æ–¯å¦å¾·ã€AJ åº·è¯ºåˆ©ã€ä¸¹å°¼å°”Â·çˆ±æ£®æ–¯å¦ã€çº¦ä¹¦äºšÂ·å¼—é‡Œæ›¼ã€GS è½©å°¼è¯—ç­‰ã€‚2002. æ–¯éš†æ•°å­—å·¡å¤©ï¼šæ—©æœŸæ•°æ®å‘å¸ƒã€‚å¤©æ–‡å­¦æ‚å¿—123ï¼ˆ1ï¼‰ï¼š485ã€‚http://stacks.iop.org/1538-3881/123/i=1/a=485ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if the patience parameter is set to 10 and we test the model on the validation set after every iteration, then we would allow training to continue until we observe 10 successive validation errors higher than the lowest recorded so far at which point our patience would run out and we stop training.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœè€å¿ƒå‚æ•°è®¾ç½®ä¸º 10ï¼Œå¹¶ä¸”æˆ‘ä»¬åœ¨æ¯æ¬¡è¿­ä»£ååœ¨éªŒè¯é›†ä¸Šæµ‹è¯•æ¨¡å‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†å…è®¸è®­ç»ƒç»§ç»­è¿›è¡Œï¼Œç›´åˆ°æˆ‘ä»¬è§‚å¯Ÿåˆ° 10 ä¸ªè¿ç»­çš„éªŒè¯é”™è¯¯é«˜äºè¿„ä»Šä¸ºæ­¢è®°å½•çš„æœ€ä½é”™è¯¯ï¼Œæ­¤æ—¶æˆ‘ä»¬çš„è€å¿ƒå°†è€—å°½å¹¶åœæ­¢è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11",
            "zh": "å›¾ 5.11"
        }
    },
    {
        "translation": {
            "en": "outlier detection, 235",
            "zh": "å¼‚å¸¸å€¼æ£€æµ‹ï¼Œ235"
        }
    },
    {
        "translation": {
            "en": "Every analytics solution will have its own set of data requirements, and it is useful, as early as possible, to determine if the business has sufficient data available to meet these requirements.",
            "zh": "æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆéƒ½æœ‰è‡ªå·±çš„ä¸€ç»„æ•°æ®è¦æ±‚ï¼Œå°½æ—©ç¡®å®šä¼ä¸šæ˜¯å¦æœ‰è¶³å¤Ÿçš„å¯ç”¨æ•°æ®æ¥æ»¡è¶³è¿™äº›è¦æ±‚æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.11â€…â€…â€…The âˆ‚a/âˆ‚z for each neuron for d2 rounded to four decimal places.",
            "zh": "8.11 d2 ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚z å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the Î´ values you calculated above, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., âˆ‚â„°/âˆ‚w6,4, âˆ‚â„°/âˆ‚w6,3, âˆ‚â„°/âˆ‚w6,0, âˆ‚â„°/âˆ‚w5,4, âˆ‚â„°/âˆ‚w5,3, âˆ‚â„°/âˆ‚w5,0, âˆ‚â„°/âˆ‚w4,2, âˆ‚â„°/âˆ‚w4,1,",
            "zh": "ä½¿ç”¨ä¸Šé¢è®¡ç®—çš„Î´å€¼ï¼Œè®¡ç®—ç½‘ç»œè¯¯å·®å¯¹ç½‘ç»œæ¯ä¸ªæƒé‡å˜åŒ–çš„æ•æ„Ÿåº¦ï¼ˆå³ âˆ‚E/âˆ‚w6,4ã€âˆ‚E/âˆ‚w6,3ã€âˆ‚E/âˆ‚w6,0ã€âˆ‚E/âˆ‚w5,4ã€âˆ‚E/âˆ‚w5,3ã€âˆ‚E/âˆ‚w5,0ã€âˆ‚E/âˆ‚w4,2ã€âˆ‚E/âˆ‚w4,1ã€"
        }
    },
    {
        "translation": {
            "en": "4.4.3â€…â€…â€…Predicting Continuous Targets",
            "zh": "4.4.3 é¢„æµ‹è¿ç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "Mahalunkar, Abhijit, and John D Kelleher. 2018. Using regular languages to explore the representational capacity of recurrent neural architectures. In International conference on artificial neural networks, 189â€“198. Springer.",
            "zh": "Mahalunkarã€Abhijit å’Œ John D Kelleherã€‚2018. ä½¿ç”¨å¸¸è§„è¯­è¨€æ¢ç´¢é€’å½’ç¥ç»æ¶æ„çš„è¡¨å¾èƒ½åŠ›.åœ¨äººå·¥ç¥ç»ç½‘ç»œå›½é™…ä¼šè®®ä¸Šï¼Œ189-198ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that a max function allows through only the maximum value from its inputs, and so the non-max values did not affect the output (and hence the error) of the network.",
            "zh": "åŸå› æ˜¯ max å‡½æ•°åªå…è®¸é€šè¿‡å…¶è¾“å…¥çš„æœ€å¤§å€¼ï¼Œå› æ­¤é max å€¼ä¸ä¼šå½±å“ç½‘ç»œçš„è¾“å‡ºï¼ˆå› æ­¤ä¹Ÿä¼šå½±å“è¯¯å·®ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "It should be clear that this is a much simpler tree than the previous one.",
            "zh": "åº”è¯¥æ¸…æ¥šçš„æ˜¯ï¼Œè¿™æ˜¯ä¸€æ£µæ¯”å‰ä¸€æ£µç®€å•å¾—å¤šçš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature selection approaches that search through subsets of features (known as wrapper approaches) are better at removing redundant features than rank and prune approaches because they consider groups of features together.",
            "zh": "æœç´¢ç‰¹å¾å­é›†çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼ˆç§°ä¸ºåŒ…è£…æ–¹æ³•ï¼‰æ¯”æ’åå’Œä¿®å‰ªæ–¹æ³•æ›´èƒ½å»é™¤å†—ä½™ç‰¹å¾ï¼Œå› ä¸ºå®ƒä»¬å°†ç‰¹å¾ç»„æ”¾åœ¨ä¸€èµ·è€ƒè™‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "cumulative gain, 567, 567, 594, 700",
            "zh": "ç´¯è®¡å¢ç›Šï¼Œ 567ï¼Œ 567ï¼Œ 594ï¼Œ 700"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes are particularly useful for formalizing this structure and provide the scaffolding for reasoning about reinforcement learning problems.",
            "zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å¯¹äºå½¢å¼åŒ–è¿™ç§ç»“æ„ç‰¹åˆ«æœ‰ç”¨ï¼Œå¹¶ä¸ºæ¨ç†å¼ºåŒ–å­¦ä¹ é—®é¢˜æä¾›äº†è„šæ‰‹æ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "As is so often the case in predictive analytics, making the right choice requires an understanding of the requirements of the task that we are trying to accomplish and matching these requirements with the features we want to emphasize in our model.",
            "zh": "æ­£å¦‚é¢„æµ‹åˆ†æä¸­ç»å¸¸å‡ºç°çš„æƒ…å†µä¸€æ ·ï¼Œåšå‡ºæ­£ç¡®çš„é€‰æ‹©éœ€è¦äº†è§£æˆ‘ä»¬è¯•å›¾å®Œæˆçš„ä»»åŠ¡çš„è¦æ±‚ï¼Œå¹¶å°†è¿™äº›è¦æ±‚ä¸æˆ‘ä»¬æƒ³è¦åœ¨æ¨¡å‹ä¸­å¼ºè°ƒçš„ç‰¹å¾ç›¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "i. Mode and 2nd mode",
            "zh": "i. æ¨¡å¼å’Œç¬¬äºŒæ¨¡å¼"
        }
    },
    {
        "translation": {
            "en": "dying ReLU, 444",
            "zh": "å‚æ­»çš„ ReLUï¼Œ444"
        }
    },
    {
        "translation": {
            "en": "The table below lists a sample of properties that have recently been sold for rental in the city.",
            "zh": "ä¸‹è¡¨åˆ—å‡ºäº†æœ€è¿‘åœ¨è¯¥å¸‚å‡ºå”®å‡ºç§Ÿçš„æˆ¿äº§ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are also specific measures that are often used for this, for example normalized mutual information (NMI), which is based on information-theoretic ideas including entropy, as discussed in Chapter 4[117 however, these are outside the scope of this chapter.",
            "zh": "æ­¤å¤–ï¼Œè¿˜ç»å¸¸ä½¿ç”¨ä¸€äº›ç‰¹å®šçš„æªæ–½ï¼Œä¾‹å¦‚è§„èŒƒåŒ–äº’ä¿¡æ¯ï¼ˆNMIï¼‰ï¼Œå®ƒåŸºäºåŒ…æ‹¬ç†µåœ¨å†…çš„ä¿¡æ¯ç†è®ºæ€æƒ³ï¼Œå¦‚ç¬¬4ç« æ‰€è¿°[117ï¼Œä½†è¿™äº›éƒ½è¶…å‡ºäº†æœ¬ç« çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Ï•0, Ï•1, and Ï•2 are as described before. This model captures the non-linear relationship in the data very well but was still easy to train using a gradient descent approach. Basis functions can also be used for multivariable simple linear regression models in the same way, the only extra requirement being the definition of more basis functions.",
            "zh": "å…¶ä¸­ Ï†0ã€Ï†1 å’Œ Ï†2 å¦‚å‰æ‰€è¿°ã€‚è¯¥æ¨¡å‹å¾ˆå¥½åœ°æ•è·äº†æ•°æ®ä¸­çš„éçº¿æ€§å…³ç³»ï¼Œä½†ä»ç„¶å¾ˆå®¹æ˜“ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚åŸºå‡½æ•°ä¹Ÿå¯ä»¥ä»¥åŒæ ·çš„æ–¹å¼ç”¨äºå¤šå˜é‡ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œå”¯ä¸€çš„é¢å¤–è¦æ±‚æ˜¯å®šä¹‰æ›´å¤šçš„åŸºå‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just as we saw in Figure 5.3[188], this shows that the nearest neighbor to the query is instance d18, with a distance of 1.2749 and a target level of yes.",
            "zh": "æ­£å¦‚æˆ‘ä»¬åœ¨å›¾ 5.3[188] ä¸­çœ‹åˆ°çš„ï¼Œè¿™è¡¨æ˜ä¸æŸ¥è¯¢æœ€è¿‘çš„é‚»å±…æ˜¯å®ä¾‹ d18ï¼Œè·ç¦»ä¸º 1.2749ï¼Œç›®æ ‡çº§åˆ«ä¸º yesã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, the goal of machine learning is to find the predictive model that generalizes best.",
            "zh": "äº‹å®ä¸Šï¼Œæœºå™¨å­¦ä¹ çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€èƒ½æ¦‚æ‹¬çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.42â€…â€…â€…The flow of error gradients through a long short-term memory unit during backpropagation.",
            "zh": "8.42 åå‘ä¼ æ’­è¿‡ç¨‹ä¸­é€šè¿‡é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„è¯¯å·®æ¢¯åº¦æµåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why during the forward pass we unrolled the network and stored a separate weighted sum z and activation a for each occurrence of a neuron in the unrolled network.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨å‰å‘ä¼ é€’æœŸé—´ï¼Œæˆ‘ä»¬å±•å¼€ç½‘ç»œï¼Œå¹¶ä¸ºå±•å¼€ç½‘ç»œä¸­æ¯ä¸ªå‡ºç°çš„ç¥ç»å…ƒå­˜å‚¨ä¸€ä¸ªå•ç‹¬çš„åŠ æƒæ€»å’Œ z å’Œæ¿€æ´» aã€‚"
        }
    },
    {
        "translation": {
            "en": "forward",
            "zh": "å‘å‰"
        }
    },
    {
        "translation": {
            "en": "The performance recorded in Table 9.1[537] shows that this system is slightly more likely to make the second kind of mistake than the first.",
            "zh": "è¡¨9.1[537]ä¸­è®°å½•çš„æ€§èƒ½è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿæ¯”ç¬¬ä¸€ç§ç³»ç»Ÿæ›´å®¹æ˜“çŠ¯ç¬¬äºŒç§é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "N rays, 533",
            "zh": "Nå°„çº¿ï¼Œ533"
        }
    },
    {
        "translation": {
            "en": "When a distance weighted k nearest neighbor approach is used, the contribution of each neighbor to the prediction is a function of the inverse distance between the neighbor and the query.",
            "zh": "å½“ä½¿ç”¨è·ç¦»åŠ æƒ k æœ€è¿‘é‚»æ–¹æ³•æ—¶ï¼Œæ¯ä¸ªé‚»åŸŸå¯¹é¢„æµ‹çš„è´¡çŒ®æ˜¯é‚»åŸŸä¸æŸ¥è¯¢ä¹‹é—´åè·ç¦»çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVRAD_U/G/R/I/Z",
            "zh": "DEVRAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "1. (a) Three people flip a fair coin. What is the probability that exactly two of them will get heads?",
            "zh": "1.ï¼ˆç”²ï¼‰ä¸‰ä¸ªäººæŠ›ç¡¬å¸ã€‚ä»–ä»¬ä¸­çš„ä¸¤ä¸ªè·å¾—æ­£é¢çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "3.8â€…â€…â€…Examples of using stacked bar plot visualizations to illustrate the relationship between two categorical features: (a) CAREER STAGE and SHOE SPONSOR features; and (b) POSITION and SHOE SPONSOR features, all from Table 3.7[73].",
            "zh": "3.8 ä½¿ç”¨å †ç§¯æ¡å½¢å›¾å¯è§†åŒ–æ¥è¯´æ˜ä¸¤ä¸ªåˆ†ç±»ç‰¹å¾ä¹‹é—´å…³ç³»çš„ç¤ºä¾‹ï¼šï¼ˆaï¼‰ CAREER STAGE å’Œ SHOE SPONSOR ç‰¹å¾;ï¼ˆbï¼‰POSITIONå’ŒSHOE SPONSORç‰¹å¾ï¼Œå‡æ¥è‡ªè¡¨3.7[73]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects are not handed to data analytics practitioners fully formed.",
            "zh": "é¢„æµ‹æ€§æ•°æ®åˆ†æé¡¹ç›®æ²¡æœ‰äº¤ç»™å®Œå…¨å½¢æˆçš„æ•°æ®åˆ†æä»ä¸šè€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross also spoke to the chief technology officer (CTO) at AT, Grace, in order to understand the available data resources.",
            "zh": "Ross è¿˜ä¸ AT çš„é¦–å¸­æŠ€æœ¯å®˜ ï¼ˆCTOï¼‰ Grace è¿›è¡Œäº†äº¤è°ˆï¼Œä»¥äº†è§£å¯ç”¨çš„æ•°æ®èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "Iâ€…â€…â€…â€…INTRODUCTION TO MACHINE LEARNING AND DATA ANALYTICS",
            "zh": "ä¸€ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æç®€ä»‹"
        }
    },
    {
        "translation": {
            "en": "47. The details of how this is done depend on how the output layer is organized. For networks trained using the sum of squared errors loss function, the Î´ for output neurons is calculated using Equation (8.21)[411]; for neurons in a softmax output layer the Î´ is calculated using Equation 8.72[467].",
            "zh": "47. å¦‚ä½•å®Œæˆæ­¤æ“ä½œçš„ç»†èŠ‚å–å†³äºè¾“å‡ºå±‚çš„ç»„ç»‡æ–¹å¼ã€‚å¯¹äºä½¿ç”¨è¯¯å·®æŸå¤±å‡½æ•°å¹³æ–¹å’Œè®­ç»ƒçš„ç½‘ç»œï¼Œè¾“å‡ºç¥ç»å…ƒçš„Î´ä½¿ç”¨å…¬å¼ï¼ˆ8.21ï¼‰[411]è®¡ç®—;å¯¹äºsoftmaxè¾“å‡ºå±‚ä¸­çš„ç¥ç»å…ƒï¼ŒÎ´ä½¿ç”¨å…¬å¼8.72[467]è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Barber, David. 2012. Bayesian reasoning and machine learning. Cambridge University Press.",
            "zh": "ç†å‘å¸ˆï¼Œå¤§å«ã€‚2012. è´å¶æ–¯æ¨ç†ä¸æœºå™¨å­¦ä¹ .å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Following the Îµ-greedy policy, the agent generates a random number (uniformly from [0,1]) of 0.634, which is greater than Îµ, and the agent uses greedy action selection and chooses a0 = left.",
            "zh": "æŒ‰ç…§è´ªå©ªÎµç­–ç•¥ï¼Œä»£ç†ç”Ÿæˆä¸€ä¸ªéšæœºæ•°ï¼ˆä» [0,1] å‡åŒ€åœ°å–è‡ª [0,1]ï¼‰ï¼Œè¯¥éšæœºæ•°å¤§äº Îµï¼Œä»£ç†ä½¿ç”¨è´ªå©ªæ“ä½œé€‰æ‹©å¹¶é€‰æ‹© a0 = leftã€‚"
        }
    },
    {
        "translation": {
            "en": "The agentâ€™s task is to navigate the environment from the start state to the goal state as quickly as possible while avoiding damage from fiery ground.",
            "zh": "æ™ºèƒ½ä½“çš„ä»»åŠ¡æ˜¯å°½å¿«å°†ç¯å¢ƒä»å¼€å§‹çŠ¶æ€å¯¼èˆªåˆ°ç›®æ ‡çŠ¶æ€ï¼ŒåŒæ—¶é¿å…ç«çƒ­åœ°é¢çš„æŸåã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, a range of variations to this standard approach to evaluating prediction model performance, and the remainder of this chapter covers the most important of these.",
            "zh": "ç„¶è€Œï¼Œè¿™ç§è¯„ä¼°é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„æ ‡å‡†æ–¹æ³•å­˜åœ¨ä¸€ç³»åˆ—å˜åŒ–ï¼Œæœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å°†ä»‹ç»å…¶ä¸­æœ€é‡è¦çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The three descriptive features, PRESSURE, TEMPERATURE, and VOLUME measure characteristics of the oil flowing through the valve when it was opened.",
            "zh": "å‹åŠ›ã€æ¸©åº¦å’Œä½“ç§¯è¿™ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾æµ‹é‡é˜€é—¨æ‰“å¼€æ—¶æµç»é˜€é—¨çš„æ²¹çš„ç‰¹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. A standard score is equivalent to a z-score, and standardizing in the way described here is also known as applying a z-transform to the data.",
            "zh": "10. æ ‡å‡†åˆ†æ•°ç­‰åŒäº z åˆ†æ•°ï¼Œä»¥æ­¤å¤„æè¿°çš„æ–¹å¼è¿›è¡Œæ ‡å‡†åŒ–ä¹Ÿç§°ä¸ºå¯¹æ•°æ®åº”ç”¨ z è½¬æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "This will continue almost indefinitely as the model becomes more and more tuned to the instances in the training set.",
            "zh": "éšç€æ¨¡å‹è¶Šæ¥è¶Šé€‚åº”è®­ç»ƒé›†ä¸­çš„å®ä¾‹ï¼Œè¿™ç§æƒ…å†µå‡ ä¹ä¼šæ— é™æœŸåœ°æŒç»­ä¸‹å»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A similar dynamic emerges between weight updates for the bias inputs, which are always equal to 1 (a0 = 1), and weights on inputs with values much larger than 1.",
            "zh": "åç½®è¾“å…¥çš„æƒé‡æ›´æ–°ï¼ˆå§‹ç»ˆç­‰äº 1 ï¼ˆa0 = 1ï¼‰ï¼‰å’Œè¾“å…¥çš„æƒé‡ï¼ˆå€¼è¿œå¤§äº 1ï¼‰ï¼‰ä¹‹é—´ä¹Ÿå‡ºç°äº†ç±»ä¼¼çš„åŠ¨æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having encouraged his two younger children to play outside, Mr. Murphy had just sat down to read the newspaper when his third child Amalia ran in to say that she had fixed the letters on the fridge because they were all out of order.",
            "zh": "å¢¨è²é¼“åŠ±ä»–çš„ä¸¤ä¸ªå¹´å¹¼çš„å­©å­åˆ°å¤–é¢ç©ï¼Œåˆšåä¸‹æ¥çœ‹æŠ¥çº¸ï¼Œä»–çš„ç¬¬ä¸‰ä¸ªå­©å­é˜¿ç›åˆ©äºšè·‘è¿›æ¥è¯´ï¼Œå¥¹å·²ç»æŠŠä¿¡æ”¾åœ¨å†°ç®±ä¸Šäº†ï¼Œå› ä¸ºå®ƒä»¬éƒ½åäº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) In designing a dataset, it is generally a bad idea if all the descriptive features are indicators of the target feature taking a particular value. For example, a potential criticism of the design of the dataset in this question is that all the descriptive features are indicators of the CANCER RISK target feature taking the same level, high. Can you think of any descriptive features that could be added to this dataset that are indicators of the low target level?",
            "zh": "ï¼ˆbï¼‰ åœ¨è®¾è®¡æ•°æ®é›†æ—¶ï¼Œå¦‚æœæ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½æ˜¯ç›®æ ‡ç‰¹å¾å…·æœ‰ç‰¹å®šå€¼çš„æŒ‡æ ‡ï¼Œåˆ™é€šå¸¸æ˜¯ä¸€ä¸ªåä¸»æ„ã€‚ä¾‹å¦‚ï¼Œå¯¹æœ¬é—®é¢˜ä¸­æ•°æ®é›†è®¾è®¡çš„æ½œåœ¨æ‰¹è¯„æ˜¯ï¼Œæ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½æ˜¯ CANCER RISK ç›®æ ‡ç‰¹å¾å¤„äºç›¸åŒæ°´å¹³çš„æŒ‡æ ‡ï¼Œå³é«˜ã€‚æ‚¨èƒ½æƒ³åˆ°ä»»ä½•å¯ä»¥æ·»åŠ åˆ°æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ˜¯ä½ç›®æ ‡æ°´å¹³çš„æŒ‡æ ‡å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Dunn index, 609",
            "zh": "é‚“æ©æŒ‡æ•°ï¼Œ609"
        }
    },
    {
        "translation": {
            "en": "This preference for caution is often the reason for choosing between SARSA and Q-Learning (although this can also be managed through careful design of rewards).",
            "zh": "è¿™ç§è°¨æ…çš„åå¥½é€šå¸¸æ˜¯åœ¨SARSAå’ŒQ-Learningä¹‹é—´åšå‡ºé€‰æ‹©çš„åŸå› ï¼ˆå°½ç®¡è¿™ä¹Ÿå¯ä»¥é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±æ¥ç®¡ç†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Not only is the learning more stable (i.e., smoother) but the training of the network actually converges on the stop criterion of SSE < 0.0001 in fewer epochs, 412 instead of 424.",
            "zh": "ä¸ä»…å­¦ä¹ æ›´ç¨³å®šï¼ˆå³æ›´å¹³æ»‘ï¼‰ï¼Œè€Œä¸”ç½‘ç»œçš„è®­ç»ƒå®é™…ä¸Šæ”¶æ•›äºSSEçš„åœæ­¢æ ‡å‡†ï¼Œ<æ›´å°‘çš„çºªå…ƒï¼Œ412è€Œä¸æ˜¯424ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rosenblatt, Frank. 1958. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review 65 (6): 386â€“408.",
            "zh": "ç½—æ£®å¸ƒæ‹‰ç‰¹ï¼Œå¼—å…°å…‹ã€‚1958. æ„ŸçŸ¥å™¨ï¼šå¤§è„‘ä¸­ä¿¡æ¯å­˜å‚¨å’Œç»„ç»‡çš„æ¦‚ç‡æ¨¡å‹ã€‚å¿ƒç†å­¦è¯„è®º65ï¼ˆ6ï¼‰ï¼š386-408ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.64",
            "zh": "0.64"
        }
    },
    {
        "translation": {
            "en": "Concept drift means that almost all the predictive models that we build will at some point go stale, and the relationships that they have learned between descriptive features and target features will no longer apply.",
            "zh": "æ¦‚å¿µæ¼‚ç§»æ„å‘³ç€æˆ‘ä»¬æ„å»ºçš„å‡ ä¹æ‰€æœ‰é¢„æµ‹æ¨¡å‹éƒ½ä¼šåœ¨æŸä¸ªæ—¶å€™è¿‡æ—¶ï¼Œå¹¶ä¸”å®ƒä»¬åœ¨æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´å­¦åˆ°çš„å…³ç³»å°†ä¸å†é€‚ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before we can start to aggregate the data from these different sources, however, a significant amount of work is required to determine the appropriate design for the ABT.",
            "zh": "ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬å¼€å§‹æ±‡æ€»æ¥è‡ªè¿™äº›ä¸åŒæ¥æºçš„æ•°æ®ä¹‹å‰ï¼Œéœ€è¦å¤§é‡çš„å·¥ä½œæ¥ç¡®å®š ABT çš„é€‚å½“è®¾è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The effect of the rectified linear activation function is evident in Figure 8.26(c)[462], where the activations are all positive.",
            "zh": "åœ¨å›¾8.26ï¼ˆcï¼‰[462]ä¸­ï¼Œæ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°çš„æ•ˆæœå¾ˆæ˜æ˜¾ï¼Œå…¶ä¸­æ¿€æ´»éƒ½æ˜¯æ­£çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.1â€ƒHandling Noisy Data",
            "zh": "5.4.1 å¤„ç†å˜ˆæ‚æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "The version of the gradient boosting algorithm described here searches for an ensemble model that minimizes the mean squared error between the target feature values from the training dataset and the model predictions. We often describe this as minimizing mean squared error (or L2) loss.36 Gradient boosting can be extended to learn to minimize other loss functions, which makes it an extremely effective and flexible approach to predictive modeling.",
            "zh": "æ­¤å¤„æè¿°çš„æ¢¯åº¦æå‡ç®—æ³•ç‰ˆæœ¬æœç´¢ä¸€ä¸ªé›†æˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†è®­ç»ƒæ•°æ®é›†ä¸­çš„ç›®æ ‡ç‰¹å¾å€¼ä¸æ¨¡å‹é¢„æµ‹ä¹‹é—´çš„å‡æ–¹è¯¯å·®é™è‡³æœ€ä½ã€‚æˆ‘ä»¬ç»å¸¸å°†å…¶æè¿°ä¸ºæœ€å°åŒ–å‡æ–¹è¯¯å·®ï¼ˆæˆ–L2ï¼‰æŸå¤±.36æ¢¯åº¦æå‡å¯ä»¥æ‰©å±•ä»¥å­¦ä¹ æœ€å°åŒ–å…¶ä»–æŸå¤±å‡½æ•°ï¼Œè¿™ä½¿å…¶æˆä¸ºä¸€ç§éå¸¸æœ‰æ•ˆå’Œçµæ´»çš„é¢„æµ‹å»ºæ¨¡æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of months the customer has been with AT",
            "zh": "å®¢æˆ·åœ¨ AT å·¥ä½œçš„æœˆæ•°"
        }
    },
    {
        "translation": {
            "en": "11. This is always an interesting category to determine a value for. Some people might argue that some profit arises as no loss was made.",
            "zh": "11. è¿™å§‹ç»ˆæ˜¯ç¡®å®šå…¶å€¼çš„æœ‰è¶£ç±»åˆ«ã€‚æœ‰äº›äººå¯èƒ½ä¼šäº‰è¾©è¯´ï¼Œç”±äºæ²¡æœ‰äºæŸï¼Œå› æ­¤äº§ç”Ÿäº†ä¸€äº›åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first draft of the domain concepts diagram developed by Jocelyn for the galaxy classification task.",
            "zh": "Jocelyn ä¸ºæ˜Ÿç³»åˆ†ç±»ä»»åŠ¡å¼€å‘çš„åŸŸæ¦‚å¿µå›¾çš„åˆç¨¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.7â€ƒExercises",
            "zh": "8.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "For the customers in the control group, the random selection process was used.",
            "zh": "å¯¹äºå¯¹ç…§ç»„ä¸­çš„å®¢æˆ·ï¼Œä½¿ç”¨éšæœºé€‰æ‹©è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "All the descriptive statistics and data visualization techniques that we have used in the previous sections of this chapter have focused on the characteristics of individual features. This section will introduce techniques that enable us to examine relationships between pairs of features.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬ç« å‰å‡ èŠ‚ä¸­ä½¿ç”¨çš„æ‰€æœ‰æè¿°æ€§ç»Ÿè®¡å’Œæ•°æ®å¯è§†åŒ–æŠ€æœ¯éƒ½é›†ä¸­åœ¨å•ä¸ªç‰¹å¾çš„ç‰¹å¾ä¸Šã€‚æœ¬èŠ‚å°†ä»‹ç»ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ£€æŸ¥ç‰¹å¾å¯¹ä¹‹é—´çš„å…³ç³»çš„æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates that the regression model is more accurately predicting the correct drug dosages than the nearest neighbor model.",
            "zh": "è¿™è¡¨æ˜å›å½’æ¨¡å‹æ¯”æœ€è¿‘é‚»æ¨¡å‹æ›´å‡†ç¡®åœ°é¢„æµ‹äº†æ­£ç¡®çš„è¯ç‰©å‰‚é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "When the gradient descent algorithm is used to find optimal weights for linear regression models, the initial weights are chosen randomly from a predefined range that must be specified as an input to the algorithm.",
            "zh": "å½“ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸ºçº¿æ€§å›å½’æ¨¡å‹æŸ¥æ‰¾æœ€ä½³æƒé‡æ—¶ï¼Œå°†ä»é¢„å®šä¹‰èŒƒå›´å†…éšæœºé€‰æ‹©åˆå§‹æƒé‡ï¼Œè¯¥èŒƒå›´å¿…é¡»æŒ‡å®šä¸ºç®—æ³•çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "indicates the predicted probability for the true category (i.e., the category encoded as a 1 in the one-hot encoded vector t). To illustrate this simplification with a case study, we assume that our distribution is over three categories, and the target distribution is encoded as a one-hot vector. Now if the target distribution over a particular instance is t = [0,1,0] (i.e., the second category is the correct category), then the cross-entropy summation in Equation (8.66)[465] expands as follows:",
            "zh": "è¡¨ç¤ºçœŸç±»åˆ«ï¼ˆå³ï¼Œåœ¨å•çƒ­ç¼–ç å‘é‡ t ä¸­ç¼–ç ä¸º 1 çš„ç±»åˆ«ï¼‰çš„é¢„æµ‹æ¦‚ç‡ã€‚ä¸ºäº†é€šè¿‡æ¡ˆä¾‹ç ”ç©¶æ¥è¯´æ˜è¿™ç§ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾æˆ‘ä»¬çš„åˆ†å¸ƒè¶…è¿‡ä¸‰ä¸ªç±»åˆ«ï¼Œå¹¶ä¸”ç›®æ ‡åˆ†å¸ƒè¢«ç¼–ç ä¸ºä¸€ä¸ªçƒ­å‘é‡ã€‚ç°åœ¨ï¼Œå¦‚æœç‰¹å®šå®ä¾‹çš„ç›®æ ‡åˆ†å¸ƒä¸º t = [0,1,0]ï¼ˆå³ï¼Œç¬¬äºŒä¸ªç±»åˆ«æ˜¯æ­£ç¡®çš„ç±»åˆ«ï¼‰ï¼Œåˆ™æ–¹ç¨‹ ï¼ˆ8.66ï¼‰[465] ä¸­çš„äº¤å‰ç†µæ±‚å’Œå±•å¼€å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, consider a feedforward network that has been initialized with weights randomly sampled with uniform probability from a range such as [âˆ’0.5,+0.5].",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªå‰é¦ˆç½‘ç»œï¼Œè¯¥ç½‘ç»œå·²åˆå§‹åŒ–æƒé‡ï¼Œæƒé‡ä» [âˆ’0.5ï¼Œ+0.5] ç­‰èŒƒå›´å†…ä»¥å‡åŒ€çš„æ¦‚ç‡éšæœºé‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the agent chooses the Twist action they will be dealt one of the 13 types of cards in a deck with a value between 2 and 11 (remember that there are four cards in the deck with a value of 10: 10, J, Q, and K).",
            "zh": "å¦‚æœä»£ç†é€‰æ‹© Twist åŠ¨ä½œï¼Œä»–ä»¬å°†è·å¾—ä¸€å‰¯ç‰Œä¸­ 13 ç§ç‰Œä¸­çš„ä¸€ç§ï¼Œå…¶å€¼åœ¨ 2 åˆ° 11 ä¹‹é—´ï¼ˆè¯·è®°ä½ï¼Œç‰Œç»„ä¸­æœ‰å››å¼ ç‰Œçš„å€¼ä¸º 10ï¼š10ã€Jã€Q å’Œ Kï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "silhouette, 609, 610",
            "zh": "å‰ªå½±ï¼Œ 609ï¼Œ 610"
        }
    },
    {
        "translation": {
            "en": "3. Calculates a confidence factor, Î±, for the model such that Î± increases as Îµ decreases. A common way to calculate the confidence factor is",
            "zh": "3. è®¡ç®—æ¨¡å‹çš„ç½®ä¿¡å› å­ Î±ï¼Œä½¿Î±éšç€Îµçš„å‡å°‘è€Œå¢åŠ ã€‚è®¡ç®—ç½®ä¿¡å› å­çš„å¸¸ç”¨æ–¹æ³•æ˜¯"
        }
    },
    {
        "translation": {
            "en": "This mean height is shown by the dashed gray line in Figure A.1[746]. The arithmetic mean is one measure of the central tendency of a sample (for our purposes, a sample is just a set of values for a feature in an ABT). Because it is easy to calculate and easy to interpret, the mean is commonly used as part of the data exploration process as a good estimate of the central tendencies of features in an ABT.",
            "zh": "è¯¥å¹³å‡é«˜åº¦ç”±å›¾A.1[746]ä¸­çš„ç°è‰²è™šçº¿è¡¨ç¤ºã€‚ç®—æœ¯å¹³å‡å€¼æ˜¯æ ·æœ¬é›†ä¸­è¶‹åŠ¿çš„ä¸€ç§åº¦é‡ï¼ˆå°±æˆ‘ä»¬çš„ç›®çš„è€Œè¨€ï¼Œæ ·æœ¬åªæ˜¯ ABT ä¸­ç‰¹å¾çš„ä¸€ç»„å€¼ï¼‰ã€‚ç”±äºå‡å€¼æ˜“äºè®¡ç®—å’Œè§£é‡Šï¼Œå› æ­¤é€šå¸¸ç”¨ä½œæ•°æ®æ¢ç´¢è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œä½œä¸ºå¯¹ ABT ä¸­ç‰¹å¾ä¸­å¿ƒè¶‹åŠ¿çš„è‰¯å¥½ä¼°è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "posterior probability distribution, 250",
            "zh": "åéªŒæ¦‚ç‡åˆ†å¸ƒï¼Œ250"
        }
    },
    {
        "translation": {
            "en": "Deep learning works best in complex domains with lots of features and large datasets.",
            "zh": "æ·±åº¦å­¦ä¹ åœ¨å…·æœ‰å¤§é‡ç‰¹å¾å’Œå¤§å‹æ•°æ®é›†çš„å¤æ‚é¢†åŸŸä¸­æ•ˆæœæœ€ä½³ã€‚"
        }
    },
    {
        "translation": {
            "en": "This may seem like a trivial taskâ€”it is essentially an identity functionâ€”but it is made more interesting by a network architecture that transforms the data through a series of narrower and narrower layers.",
            "zh": "è¿™ä¼¼ä¹æ˜¯ä¸€é¡¹å¾®ä¸è¶³é“çš„ä»»åŠ¡â€”â€”å®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªèº«ä»½å‡½æ•°â€”â€”ä½†å®ƒé€šè¿‡ä¸€ç³»åˆ—è¶Šæ¥è¶Šçª„çš„å±‚è½¬æ¢æ•°æ®çš„ç½‘ç»œæ¶æ„ä½¿å®ƒå˜å¾—æ›´åŠ æœ‰è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Obviously, a network with random weights is unlikely to implement a useful function.",
            "zh": "æ˜¾ç„¶ï¼Œå…·æœ‰éšæœºæƒé‡çš„ç½‘ç»œä¸å¤ªå¯èƒ½å®ç°æœ‰ç”¨çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this in the solid line in Figure 9.3[542].",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å›¾ 9.3[542] çš„å®çº¿ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the terminology of Bayesian networks, node A is a parent node of B, and node B is a child node of A, because there is a direct edge from A into B.",
            "zh": "åœ¨è´å¶æ–¯ç½‘ç»œçš„æœ¯è¯­ä¸­ï¼ŒèŠ‚ç‚¹ A æ˜¯ B çš„çˆ¶èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹ B æ˜¯ A çš„å­èŠ‚ç‚¹ï¼Œå› ä¸ºä» A åˆ° B æœ‰ä¸€æ¡ç›´æ¥è¾¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn stressed that until she had looked at the data and performed experiments, she could not make any predictions as to what classification accuracy would be possible.",
            "zh": "Jocelynå¼ºè°ƒï¼Œåœ¨å¥¹æŸ¥çœ‹æ•°æ®å¹¶è¿›è¡Œå®éªŒä¹‹å‰ï¼Œå¥¹æ— æ³•é¢„æµ‹åˆ†ç±»ç²¾åº¦çš„å¯èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, Figure 8.24(b)[454] shows that now the z values consistently become larger as we move forward through the network; this is a complete reversal of the vanishing z value dynamic shown in Figure 8.23(b)[453].",
            "zh": "é¦–å…ˆï¼Œå›¾ 8.24ï¼ˆbï¼‰[454] æ˜¾ç¤ºï¼Œéšç€æˆ‘ä»¬åœ¨ç½‘ç»œä¸­å‰è¿›ï¼Œç°åœ¨ z å€¼ä¸æ–­å˜å¤§;è¿™æ˜¯å›¾8.23ï¼ˆbï¼‰[453]æ‰€ç¤ºçš„Zå€¼æ¶ˆå¤±åŠ¨æ€çš„å®Œå…¨é€†è½¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.2â€…â€…â€…Portions of the ABT for the motor insurance claims fraud detection problem discussed in Section 2.4.6[42].",
            "zh": "3.2 ABTä¸­å…³äºç¬¬2.4.6èŠ‚[42]ä¸­è®¨è®ºçš„æ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹é—®é¢˜çš„éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "bias, 91, 385, 751",
            "zh": "åç½®ï¼Œ 91ï¼Œ 385ï¼Œ 751"
        }
    },
    {
        "translation": {
            "en": "This figure shows scatter plots for three bivariate datasets that have the same central tendency, marked A and located in the feature space at (50,50), but whose instances are spread out differently across the feature space.",
            "zh": "æ­¤å›¾æ˜¾ç¤ºäº†ä¸‰ä¸ªåŒå˜é‡æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œè¿™äº›æ•°æ®é›†å…·æœ‰ç›¸åŒçš„ä¸­å¿ƒè¶‹åŠ¿ï¼Œæ ‡è®°ä¸º Aï¼Œä½äºç‰¹å¾ç©ºé—´ ï¼ˆ50,50ï¼‰ å¤„ï¼Œä½†å…¶å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†å¸ƒæ–¹å¼ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, suppose our basketball team manages to sign a ringer measuring in at 229cm, as shown in Figure A.2(a)[746].",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„ç¯®çƒé˜Ÿè®¾æ³•ç­¾ä¸‹äº†ä¸€ä¸ª 229 å˜ç±³çš„é“ƒå£°ï¼Œå¦‚å›¾ A.2ï¼ˆaï¼‰[746] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "lazy learner, 232",
            "zh": "æ‡’æƒ°çš„å­¦ä¹ è€…ï¼Œ232"
        }
    },
    {
        "translation": {
            "en": "Again, remember that each node is constructed in a context consisting of a dataset of instances containing a subset of the instances used to construct its parent node and the set of descriptive features that have not been tested on the path between the root node and parent node.",
            "zh": "åŒæ ·ï¼Œè¯·è®°ä½ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯åœ¨ä¸Šä¸‹æ–‡ä¸­æ„å»ºçš„ï¼Œè¯¥ä¸Šä¸‹æ–‡ç”±å®ä¾‹æ•°æ®é›†ç»„æˆï¼Œè¯¥æ•°æ®é›†åŒ…å«ç”¨äºæ„é€ å…¶çˆ¶èŠ‚ç‚¹çš„å®ä¾‹å­é›†ä»¥åŠå°šæœªåœ¨æ ¹èŠ‚ç‚¹å’Œçˆ¶èŠ‚ç‚¹ä¹‹é—´çš„è·¯å¾„ä¸Šæµ‹è¯•çš„æè¿°æ€§ç‰¹å¾é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then present extensions and variations of this approach that describe different performance measures for models predicting categorical, continuous, and multinomial targets; how to design effective evaluation experiments; and how to continually measure the performance of models after deployment.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬ä»‹ç»äº†è¿™ç§æ–¹æ³•çš„æ‰©å±•å’Œå˜ä½“ï¼Œè¿™äº›æ‰©å±•å’Œå˜ä½“æè¿°äº†é¢„æµ‹åˆ†ç±»ã€è¿ç»­å’Œå¤šé¡¹å¼ç›®æ ‡çš„æ¨¡å‹çš„ä¸åŒæ€§èƒ½åº¦é‡;å¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„è¯„ä¼°å®éªŒ;ä»¥åŠå¦‚ä½•åœ¨éƒ¨ç½²åæŒç»­æµ‹é‡æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.139)[520] may appear to undermine this design goal, because the calculation of the backpropagated error gradients in the vector âˆ‚â„°t/âˆ‚htâˆ’1 involves a multiplication by weight matrices.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.139ï¼‰[520]ä¼¼ä¹ç ´åäº†è¿™ä¸€è®¾è®¡ç›®æ ‡ï¼Œå› ä¸ºè®¡ç®—å‘é‡âˆ‚Et/âˆ‚htâˆ’1ä¸­çš„åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦æ¶‰åŠä¹˜ä»¥æƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "9.7â€ƒExercises",
            "zh": "9.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Furthermore, the correlations between instances are broken because mini-batches are randomly selected from the replay memory.",
            "zh": "æ­¤å¤–ï¼Œå®ä¾‹ä¹‹é—´çš„ç›¸å…³æ€§è¢«ç ´åï¼Œå› ä¸ºå°æ‰¹é‡æ˜¯ä»é‡æ”¾å†…å­˜ä¸­éšæœºé€‰æ‹©çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "ID3, 133",
            "zh": "ID3,133"
        }
    },
    {
        "translation": {
            "en": "Hence the name backpropagation through time: as we backpropagate through the previous states of the network, we are in effect going back through time.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¾—åâ€œæ—¶é—´åå‘ä¼ æ’­â€ï¼šå½“æˆ‘ä»¬é€šè¿‡ç½‘ç»œçš„å…ˆå‰çŠ¶æ€è¿›è¡Œåå‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨å›æº¯æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The company can run this model whenever a new loan application is made and only extend credit to those borrowers predicted to belong to the good target level.",
            "zh": "æ¯å½“æå‡ºæ–°çš„è´·æ¬¾ç”³è¯·æ—¶ï¼Œå…¬å¸éƒ½å¯ä»¥è¿è¡Œæ­¤æ¨¡å‹ï¼Œå¹¶ä¸”ä»…å‘é¢„æµ‹å±äºè‰¯å¥½ç›®æ ‡æ°´å¹³çš„å€Ÿæ¬¾äººæä¾›ä¿¡è´·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This differential is largest between the pixels at the corners of the image versus the pixels in the middle of the image; only one of the receptive fields covers the top-left pixel in the image, whereas nine receptive fields cover the pixel at coordinate (3,3).",
            "zh": "å›¾åƒè§’è½çš„åƒç´ ä¸å›¾åƒä¸­é—´çš„åƒç´ ä¹‹é—´çš„å·®å¼‚æœ€å¤§;åªæœ‰ä¸€ä¸ªæ„Ÿå—é‡è¦†ç›–å›¾åƒä¸­å·¦ä¸Šè§’çš„åƒç´ ï¼Œè€Œä¹ä¸ªæ„Ÿå—é‡è¦†ç›–åæ ‡å¤„çš„åƒç´  ï¼ˆ3,3ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4.1â€ƒSARSA, On-Policy Temporal-Difference Learning",
            "zh": "11.4.1 SARSAï¼Œæ”¿ç­–æ—¶é—´å·®å¼‚å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "This is the same process that we use for the forward pass of a standard feedforward network (see Figure 8.11[406]); the slightly complicating factor here is that in an unrolled recurrent network a neuron may occur multiple times (for example, neurons in the hidden layer will occur once for each time-step), and so for each neuron we have a time-stamped sequence of z and a values.",
            "zh": "è¿™ä¸æˆ‘ä»¬ç”¨äºæ ‡å‡†å‰é¦ˆç½‘ç»œçš„å‰å‘ä¼ é€’çš„è¿‡ç¨‹ç›¸åŒï¼ˆå‚è§å›¾ 8.11[406]ï¼‰;è¿™é‡Œç¨å¾®å¤æ‚çš„å› ç´ æ˜¯ï¼Œåœ¨å±•å¼€çš„å¾ªç¯ç½‘ç»œä¸­ï¼Œä¸€ä¸ªç¥ç»å…ƒå¯èƒ½ä¼šå‡ºç°å¤šæ¬¡ï¼ˆä¾‹å¦‚ï¼Œéšè—å±‚ä¸­çš„ç¥ç»å…ƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸­éƒ½ä¼šå‡ºç°ä¸€æ¬¡ï¼‰ï¼Œå› æ­¤å¯¹äºæ¯ä¸ªç¥ç»å…ƒï¼Œæˆ‘ä»¬éƒ½æœ‰ä¸€ä¸ªå¸¦æœ‰æ—¶é—´æˆ³çš„ z å’Œ a å€¼åºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "To summarize, the backward pass of the backpropagation algorithm propagates the Î´ error gradients back through the network.",
            "zh": "æ€»è€Œè¨€ä¹‹ï¼Œåå‘ä¼ æ’­ç®—æ³•çš„å‘åä¼ é€’é€šè¿‡ç½‘ç»œå°†Î´è¯¯å·®æ¢¯åº¦ä¼ æ’­å›å»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ID3 decision tree induction algorithm described in the previous section provides the basic approach to decision tree induction: a top-down, recursive, depth-first partitioning of the dataset beginning at the root node and finishing at the leaf nodes.",
            "zh": "ä¸Šä¸€èŠ‚ä¸­æè¿°çš„ ID3 å†³ç­–æ ‘å½’çº³ç®—æ³•æä¾›äº†å†³ç­–æ ‘å½’çº³çš„åŸºæœ¬æ–¹æ³•ï¼šæ•°æ®é›†çš„è‡ªä¸Šè€Œä¸‹ã€é€’å½’ã€æ·±åº¦ä¼˜å…ˆçš„åˆ†åŒºï¼Œä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œåˆ°å¶èŠ‚ç‚¹ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Esposito, Floriana, Donato Malerba, and Giovanni Semeraro. 1997. A comparative analysis of methods for pruning decision trees. IEEE Transactions on Pattern Analysis and Machine Intelligence 19 (5): 476â€“491.",
            "zh": "åŸƒæ–¯æ³¢è¥¿æ‰˜ã€å¼—æ´›é‡Œäºšçº³ã€å¤šçº³æ‰˜Â·é©¬å‹’å·´å’Œä¹”ç“¦å°¼Â·å¡æ¢…æ‹‰ç½—ã€‚1997. å†³ç­–æ ‘ä¿®å‰ªæ–¹æ³•çš„æ¯”è¾ƒåˆ†æ.IEEEæ¨¡å¼åˆ†æä¸æœºå™¨æ™ºèƒ½æ±‡åˆŠ19ï¼ˆ5ï¼‰ï¼š476â€“491ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.2â€ƒArtificial Neural Networks",
            "zh": "8.2.2 äººå·¥ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "The members of a rival school basketball team. Player heights are listed below each player. The dashed gray line shows the arithmetic mean of the playersâ€™ heights.",
            "zh": "æ•Œå¯¹å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ã€‚æ¯ä¸ªç©å®¶ä¸‹æ–¹åˆ—å‡ºäº†ç©å®¶çš„èº«é«˜ã€‚ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "bits, 126",
            "zh": "ä½ï¼Œ126"
        }
    },
    {
        "translation": {
            "en": "The final probability that we need to calculate, P(q[1],â€¦,q[m] | t = l), can be calculated either directly from a dataset (by calculating the relative frequency of the joint event q[1],â€¦,q[m] within the set of instances where t = l), or alternatively, it can be calculated using the probability chain rule.9 The chain rule states that the probability of a joint event can be rewritten as a product of conditional probabilities. So, we can rewrite P(q[1],â€¦,q[m]) as",
            "zh": "æˆ‘ä»¬éœ€è¦è®¡ç®—çš„æœ€ç»ˆæ¦‚ç‡ Pï¼ˆq[1],...,q[m] | t = lï¼‰ å¯ä»¥ç›´æ¥ä»æ•°æ®é›†ä¸­è®¡ç®—ï¼ˆé€šè¿‡è®¡ç®— t = l çš„å®ä¾‹é›†ä¸­çš„è”åˆäº‹ä»¶ q[1],...,q[m] çš„ç›¸å¯¹é¢‘ç‡ï¼‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ¦‚ç‡é“¾è§„åˆ™è¿›è¡Œè®¡ç®—.9 é“¾å¼è§„åˆ™æŒ‡å‡ºï¼Œè”åˆäº‹ä»¶çš„æ¦‚ç‡å¯ä»¥æ”¹å†™ä¸ºæ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°† Pï¼ˆq[1],...,q[m]ï¼‰ æ”¹å†™ä¸º"
        }
    },
    {
        "translation": {
            "en": "The expectation is that each domain concept, or domain subconcept, will lead to one or more actual descriptive features derived directly from organizational data sources.",
            "zh": "æœŸæœ›æ¯ä¸ªé¢†åŸŸæ¦‚å¿µæˆ–é¢†åŸŸå­æ¦‚å¿µéƒ½ä¼šå¯¼è‡´ä¸€ä¸ªæˆ–å¤šä¸ªç›´æ¥ä»ç»„ç»‡æ•°æ®æºæ´¾ç”Ÿçš„å®é™…æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.7[268] illustrates the steps in smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature when conditioned on FRAUD = false. We can see that after smoothing, the probability mass is more evenly distributed across the events in the set. Crucially, the posterior probability for P(GC = guarantor | Â¬fr) is no longer zero, and as a result, the coverage of the model has been extended to include queries with GUARANTOR/COAPPLICANT values of guarantor.",
            "zh": "è¡¨ 6.7[268] è¯´æ˜äº†åœ¨ä»¥ FRAUD = false ä¸ºæ¡ä»¶æ—¶ï¼Œå¯¹ GUARANTOR/COAPPLICANT ç‰¹å¾çš„åéªŒæ¦‚ç‡è¿›è¡Œå¹³æ»‘å¤„ç†çš„æ­¥éª¤ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å¹³æ»‘ä¹‹åï¼Œæ¦‚ç‡è´¨é‡æ›´å‡åŒ€åœ°åˆ†å¸ƒåœ¨é›†åˆä¸­çš„äº‹ä»¶ä¸­ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼ŒPï¼ˆGC = guarantor | Â¬frï¼‰ çš„åéªŒæ¦‚ç‡ä¸å†ä¸ºé›¶ï¼Œå› æ­¤ï¼Œè¯¥æ¨¡å‹çš„è¦†ç›–èŒƒå›´å·²æ‰©å±•åˆ°åŒ…æ‹¬å…·æœ‰ GUARANTOR/COAPPLICANT å€¼çš„ guarantor çš„æŸ¥è¯¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "AVGOVERBUNDLEMINS",
            "zh": "AVGOVERBUNDLEMINS"
        }
    },
    {
        "translation": {
            "en": "In this dataset there are three categories of risk: low, medium, and high.",
            "zh": "åœ¨æ­¤æ•°æ®é›†ä¸­ï¼Œæœ‰ä¸‰ç±»é£é™©ï¼šä½ã€ä¸­å’Œé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset from a loan application fraud detection domain.",
            "zh": "æ¥è‡ªè´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹åŸŸçš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For r target feature levels, we build r separate logistic regression models ğ•„w1 to ğ•„wr:",
            "zh": "å¯¹äº r ç›®æ ‡ç‰¹å¾çº§åˆ«ï¼Œæˆ‘ä»¬æ„å»ºäº† r ä¸ªå•ç‹¬çš„é€»è¾‘å›å½’æ¨¡å‹ Mw1 åˆ° Mwrï¼š"
        }
    },
    {
        "translation": {
            "en": "There are two main ways that the data quality report can be used to identify outliers within a dataset.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šå¯ç”¨äºè¯†åˆ«æ•°æ®é›†ä¸­çš„å¼‚å¸¸å€¼æœ‰ä¸¤ç§ä¸»è¦æ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The important thing to remember, though, is that the different approaches exist because in different scenarios it will often be easier to apply one approach over the others.",
            "zh": "ä½†æ˜¯ï¼Œè¦è®°ä½çš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œå­˜åœ¨ä¸åŒçš„æ–¹æ³•ï¼Œå› ä¸ºåœ¨ä¸åŒçš„åœºæ™¯ä¸­ï¼Œåº”ç”¨ä¸€ç§æ–¹æ³•é€šå¸¸æ¯”å…¶ä»–æ–¹æ³•æ›´å®¹æ˜“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This kind of insight that we can get from the confusion matrix can help in trying to improve a model, as it can suggest to us where we should focus our work.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä»æ··æ·†çŸ©é˜µä¸­è·å¾—çš„è¿™ç§è§è§£å¯ä»¥å¸®åŠ©å°è¯•æ”¹è¿›æ¨¡å‹ï¼Œå› ä¸ºå®ƒå¯ä»¥å‘æˆ‘ä»¬å»ºè®®æˆ‘ä»¬åº”è¯¥å°†å·¥ä½œé‡ç‚¹æ”¾åœ¨å“ªé‡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.11[619] illustrates these options. In the AHC examples shown in Figure 10.10[617], Euclidean distance and single linkage are used. The choice of linkage method can lead to quite different results when AHC is used. For example, using centroid linkage leads to results very similar to a k-means clustering approach, whereas using single linkage leads to results much more heavily reliant on local distances within a dataset.",
            "zh": "å›¾ 10.11[619] è¯´æ˜äº†è¿™äº›é€‰é¡¹ã€‚åœ¨å›¾10.10[617]æ‰€ç¤ºçš„AHCç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨äº†æ¬§å‡ é‡Œå¾—è·ç¦»å’Œå•è¿æ†ã€‚å½“ä½¿ç”¨AHCæ—¶ï¼Œè”åŠ¨æ–¹æ³•çš„é€‰æ‹©ä¼šå¯¼è‡´å®Œå…¨ä¸åŒçš„ç»“æœã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨è´¨å¿ƒé“¾æ¥ä¼šå¯¼è‡´ç»“æœä¸ k å‡å€¼èšç±»æ–¹æ³•éå¸¸ç›¸ä¼¼ï¼Œè€Œä½¿ç”¨å•é“¾æ¥ä¼šå¯¼è‡´ç»“æœæ›´ä¸¥é‡åœ°ä¾èµ–äºæ•°æ®é›†ä¸­çš„å±€éƒ¨è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we examine Figure 8.39[506] we see that when â„° t=3 is backpropagated through the network, a single error gradient is calculated for each weight in Wyh because this matrix occurs only once in the unrolled network, but three separate error gradients are calculated for each weight in Whh and Whx.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æ£€æŸ¥å›¾ 8.39[506]ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å½“ E t=3 é€šè¿‡ç½‘ç»œåå‘ä¼ æ’­æ—¶ï¼Œæ¯ä¸ªæƒé‡ï¼ˆWyhï¼‰éƒ½ä¼šè®¡ç®—ä¸€ä¸ªè¯¯å·®æ¢¯åº¦ï¼Œå› ä¸ºè¯¥çŸ©é˜µåœ¨å±•å¼€çš„ç½‘ç»œä¸­åªå‡ºç°ä¸€æ¬¡ï¼Œä½†æ¯ä¸ªæƒé‡ï¼ˆä»¥ Whh å’Œ Whx ä¸ºå•ä½ï¼‰è®¡ç®—ä¸‰ä¸ªå•ç‹¬çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will use the dataset presented in Table 6.2[263] to illustrate how to create and use a naive Bayes model for a prediction problem.",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨è¡¨ 6.2[263] ä¸­æä¾›çš„æ•°æ®é›†æ¥è¯´æ˜å¦‚ä½•ä¸ºé¢„æµ‹é—®é¢˜åˆ›å»ºå’Œä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The ensemble contains 11 independent models, all of which have an error rate of 0.49.",
            "zh": "ï¼ˆbï¼‰ è¯¥é›†åˆåŒ…å«11ä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹çš„é”™è¯¯ç‡ä¸º0.49ã€‚"
        }
    },
    {
        "translation": {
            "en": "With the knowledge that the Galaxy Zoo labels would provide her with a target feature, Jocelyn returned to speak with Ted again about getting access to the SDSS data.",
            "zh": "åœ¨çŸ¥é“é“¶æ²³åŠ¨ç‰©å›­æ ‡ç­¾ä¼šä¸ºå¥¹æä¾›ç›®æ ‡åŠŸèƒ½åï¼Œä¹”æ–¯ç³å†æ¬¡ä¸æ³°å¾·è®¨è®ºå¦‚ä½•è®¿é—®SDSSæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important to explore these possibilities and, in conjunction with the business, to agree on the most suitable solution for the business.",
            "zh": "é‡è¦çš„æ˜¯è¦æ¢ç´¢è¿™äº›å¯èƒ½æ€§ï¼Œå¹¶ä¸ä¸šåŠ¡éƒ¨é—¨ä¸€èµ·ï¼Œå°±æœ€é€‚åˆä¸šåŠ¡çš„è§£å†³æ–¹æ¡ˆè¾¾æˆä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "We begin, however, by introducing some of the metrics, other than entropy-based information gain, that can be used to select the next feature to split on as we build the tree.",
            "zh": "ç„¶è€Œï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»äº†ä¸€äº›æŒ‡æ ‡ï¼Œé™¤äº†åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šä¹‹å¤–ï¼Œè¿™äº›æŒ‡æ ‡å¯ç”¨äºåœ¨æ„å»ºæ ‘æ—¶é€‰æ‹©ä¸‹ä¸€ä¸ªè¦æ‹†åˆ†çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that the logistic function is a threshold function that pushes values above zero to 1 and values below zero to 0.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé€»è¾‘å‡½æ•°æ˜¯ä¸€ä¸ªé˜ˆå€¼å‡½æ•°ï¼Œå®ƒå°†é«˜äºé›¶çš„å€¼æ¨é€åˆ° 1ï¼Œå°†ä½äºé›¶çš„å€¼æ¨é€åˆ° 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "The silhouette plot for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3).",
            "zh": "ä½¿ç”¨ k å‡å€¼ç®—æ³•ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†æœ€ç»ˆèšç±»çš„è½®å»“å›¾ï¼ˆè¡¨ 10.1[604]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, in a convolutional neural network, when two neurons share weights, they share all their weights, because they use the same filter.",
            "zh": "æ¢å¥è¯è¯´ï¼Œåœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œå½“ä¸¤ä¸ªç¥ç»å…ƒå…±äº«æƒé‡æ—¶ï¼Œå®ƒä»¬å…±äº«æ‰€æœ‰æƒé‡ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨ç›¸åŒçš„æ»¤æ³¢å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "interaction effect, 169",
            "zh": "äº¤äº’ä½œç”¨ï¼Œ169"
        }
    },
    {
        "translation": {
            "en": "If treated as a continuous feature in a data quality report, this would have a cardinality of 2.",
            "zh": "å¦‚æœåœ¨æ•°æ®è´¨é‡æŠ¥å‘Šä¸­è¢«è§†ä¸ºè¿ç»­ç‰¹å¾ï¼Œåˆ™åŸºæ•°ä¸º 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Variance and standard deviation",
            "zh": "ï¼ˆcï¼‰ æ–¹å·®å’Œæ ‡å‡†å·®"
        }
    },
    {
        "translation": {
            "en": "There are two ways of computing the likelihood of a future event: (1) use the relative frequency of the event in the past, or (2) use a subjective estimate (ideally from an expert!).",
            "zh": "æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥è®¡ç®—æœªæ¥äº‹ä»¶çš„å¯èƒ½æ€§ï¼šï¼ˆ1ï¼‰ä½¿ç”¨è¿‡å»äº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡ï¼Œæˆ–ï¼ˆ2ï¼‰ä½¿ç”¨ä¸»è§‚ä¼°è®¡ï¼ˆæœ€å¥½æ¥è‡ªä¸“å®¶ï¼"
        }
    },
    {
        "translation": {
            "en": "where â€²wk(d) is a revised, normalized prediction for the one-versus-all model for the target level k. The denominator in this equation sums the predictions of each of the one-versus-all models for the r levels of the target feature and acts as a normalization term.",
            "zh": "å…¶ä¸­ â€²wkï¼ˆdï¼‰ æ˜¯é’ˆå¯¹ç›®æ ‡æ°´å¹³ k çš„ä¸€å¯¹å…¨æ¨¡å‹çš„ä¿®è®¢ç‰ˆå½’ä¸€åŒ–é¢„æµ‹ã€‚æ­¤ç­‰å¼ä¸­çš„åˆ†æ¯å°†ç›®æ ‡ç‰¹å¾çš„ r çº§çš„æ¯ä¸ªä¸€å¯¹å¤šæ¨¡å‹çš„é¢„æµ‹æ±‚å’Œï¼Œå¹¶ç”¨ä½œå½’ä¸€åŒ–é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather than defining a curve (as was the case for all the previous examples), this function defines a surface, as shown in Figure C.3(a)[769].",
            "zh": "è¯¥å‡½æ•°ä¸æ˜¯å®šä¹‰æ›²çº¿ï¼ˆå¦‚å‰é¢æ‰€æœ‰ç¤ºä¾‹çš„æƒ…å†µï¼‰ï¼Œè€Œæ˜¯å®šä¹‰æ›²é¢ï¼Œå¦‚å›¾C.3ï¼ˆaï¼‰[769]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The probability distribution for a categorical feature is a vector that lists the probabilities associated with each of the values in the domain of the feature.",
            "zh": "åˆ†ç±»ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸€ä¸ªå‘é‡ï¼Œå®ƒåˆ—å‡ºäº†ä¸ç‰¹å¾åŸŸä¸­æ¯ä¸ªå€¼å…³è”çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.2[541] illustrates how a large ABT can be divided into a training set, a validation set, and a test set.",
            "zh": "å›¾ 9.2[541] è¯´æ˜äº†å¦‚ä½•å°†å¤§å‹ ABT åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, we cannot use the set of consistent models to make predictions for these queries.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬ä¸èƒ½ä½¿ç”¨ä¸€ç»„ä¸€è‡´çš„æ¨¡å‹æ¥å¯¹è¿™äº›æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The generated feature maps have the same 6-by-6 dimensionality as the input image (before padding was applied).",
            "zh": "ç”Ÿæˆçš„ç‰¹å¾å›¾å…·æœ‰ä¸è¾“å…¥å›¾åƒç›¸åŒçš„ 6Ã—6 ç»´åº¦ï¼ˆåœ¨åº”ç”¨å¡«å……ä¹‹å‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Fundamentals section of this chapter introduces the key ideas of a parameterized model, measuring error, and an error surface.",
            "zh": "æœ¬ç« çš„åŸºç¡€çŸ¥è¯†éƒ¨åˆ†ä»‹ç»äº†å‚æ•°åŒ–æ¨¡å‹ã€æµ‹é‡è¯¯å·®å’Œè¯¯å·®æ›²é¢çš„å…³é”®æ€æƒ³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Smoothing takes some of the probability mass from the events with high probability and shares this with the events with low probabilities.",
            "zh": "å¹³æ»‘ä»é«˜æ¦‚ç‡äº‹ä»¶ä¸­è·å–ä¸€äº›æ¦‚ç‡è´¨é‡ï¼Œå¹¶ä¸ä½æ¦‚ç‡äº‹ä»¶å…±äº«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Obviously, pruning will result in the creation of decision trees that are not consistent with the training set used to build them.",
            "zh": "æ˜¾ç„¶ï¼Œä¿®å‰ªå°†å¯¼è‡´å†³ç­–æ ‘çš„åˆ›å»ºä¸ç”¨äºæ„å»ºå®ƒä»¬çš„è®­ç»ƒé›†ä¸ä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each visualization is composed of four plots: one plot of the distribution of the descriptive feature values in the entire dataset, and three plots illustrating the distribution of the descriptive feature values for each level of the target.",
            "zh": "æ¯ä¸ªå¯è§†åŒ–æ•ˆæœéƒ½ç”±å››ä¸ªå›¾ç»„æˆï¼šä¸€ä¸ªå›¾æ˜¯æ•´ä¸ªæ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾å€¼çš„åˆ†å¸ƒå›¾ï¼Œä¸‰ä¸ªå›¾æ˜¯è¯´æ˜æ¯ä¸ªç›®æ ‡çº§åˆ«çš„æè¿°æ€§ç‰¹å¾å€¼çš„åˆ†å¸ƒå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Roy Keane",
            "zh": "â€”â€”ç½—ä¼ŠÂ·åŸºæ©"
        }
    },
    {
        "translation": {
            "en": "Figure 12.5",
            "zh": "å›¾ 12.5"
        }
    },
    {
        "translation": {
            "en": "sensitivity, 548, 559",
            "zh": "çµæ•åº¦ï¼Œ 548ï¼Œ 559"
        }
    },
    {
        "translation": {
            "en": "As with the hidden layer, the first operation is the multiplication of the layerâ€™s weight matrix by the (augmented) vector of activations from the previous layer.",
            "zh": "ä¸éšè—å±‚ä¸€æ ·ï¼Œç¬¬ä¸€ä¸ªæ“ä½œæ˜¯å°†å±‚çš„æƒé‡çŸ©é˜µä¹˜ä»¥æ¥è‡ªå‰ä¸€å±‚çš„ï¼ˆå¢å¼ºï¼‰æ¿€æ´»å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simple linear regression and logistic regression models that we first looked at were only capable of representing linear relationships between descriptive features and a target feature.",
            "zh": "æˆ‘ä»¬é¦–å…ˆç ”ç©¶çš„ç®€å•çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’æ¨¡å‹åªèƒ½è¡¨ç¤ºæè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Anti-discrimination legislation in most jurisdictions prohibits discrimination on the basis of some set of the following grounds: sex, age, race, ethnicity, nationality, sexual orientation, religion, disability, and political opinions.",
            "zh": "å¤§å¤šæ•°å¸æ³•ç®¡è¾–åŒºçš„åæ­§è§†ç«‹æ³•ç¦æ­¢åŸºäºä»¥ä¸‹å‡ æ–¹é¢çš„æ­§è§†ï¼šæ€§åˆ«ã€å¹´é¾„ã€ç§æ—ã€æ°‘æ—ã€å›½ç±ã€æ€§å–å‘ã€å®—æ•™ã€æ®‹ç–¾å’Œæ”¿æ²»è§‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "From Figure 3.9(b)[79] we can see that HEIGHT follows a normal distribution centered around a mean of approximately 194.",
            "zh": "ä»å›¾3.9ï¼ˆbï¼‰[79]ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°HEIGHTéµå¾ªä»¥å¤§çº¦194çš„å¹³å‡å€¼ä¸ºä¸­å¿ƒçš„æ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "We also assume cards are dealt from an infinite deck, which simplifies some of the modeling of the game.9",
            "zh": "æˆ‘ä»¬è¿˜å‡è®¾ç‰Œæ˜¯ä»æ— é™å¥—ç‰Œä¸­å‘ç‰Œçš„ï¼Œè¿™ç®€åŒ–äº†æ¸¸æˆçš„ä¸€äº›å»ºæ¨¡9ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.10â€…â€…â€…(a) The path taken from the root node to a leaf node when we search the tree with a query; and (b) the ? marks the location of the query, and the dashed circle plots the extent of the target.",
            "zh": "5.10 ï¼ˆaï¼‰ å½“æˆ‘ä»¬ä½¿ç”¨æŸ¥è¯¢æœç´¢æ ‘æ—¶ï¼Œä»æ ¹èŠ‚ç‚¹åˆ°å¶èŠ‚ç‚¹çš„è·¯å¾„;åŠ ï¼ˆbï¼‰ ï¼Ÿæ ‡è®°æŸ¥è¯¢çš„ä½ç½®ï¼Œè™šçº¿åœ†åœˆç»˜åˆ¶ç›®æ ‡çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Missing values (2%)",
            "zh": "ç¼ºå¤±å€¼ ï¼ˆ2%ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The compactness of the representation is at the cost of making a naive assumption that may adversely affect the predictive accuracy of the model.",
            "zh": "è¡¨ç¤ºçš„ç´§å‡‘æ€§æ˜¯ä»¥åšå‡ºå¯èƒ½å¯¹æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§äº§ç”Ÿä¸åˆ©å½±å“çš„å¹¼ç¨šå‡è®¾ä¸ºä»£ä»·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The network is trained for 1,000 epochs using mini-batch gradient descent with a batch size of 32.15",
            "zh": "è¯¥ç½‘ç»œä½¿ç”¨æ‰¹é‡å¤§å°ä¸º 32.15 çš„å°å‹æ‰¹é‡æ¢¯åº¦ä¸‹é™è®­ç»ƒäº† 1,000 ä¸ªå‘¨æœŸ"
        }
    },
    {
        "translation": {
            "en": "Features can be of many different types, but it is useful to think of a distinction between raw features that come directly from existing data sources and derived features that are constructed by manipulating values from existing data sources.",
            "zh": "è¦ç´ å¯ä»¥æœ‰è®¸å¤šä¸åŒçš„ç±»å‹ï¼Œä½†è€ƒè™‘åŒºåˆ†ç›´æ¥æ¥è‡ªç°æœ‰æ•°æ®æºçš„åŸå§‹è¦ç´ å’Œé€šè¿‡æ“ä½œç°æœ‰æ•°æ®æºä¸­çš„å€¼è€Œæ„é€ çš„æ´¾ç”Ÿè¦ç´ æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, recall that when gradient descent was discussed, the instances in the training data were shuffled at the beginning of each epoch.",
            "zh": "é¦–å…ˆï¼Œå›æƒ³ä¸€ä¸‹ï¼Œå½“è®¨è®ºæ¢¯åº¦ä¸‹é™æ—¶ï¼Œè®­ç»ƒæ•°æ®ä¸­çš„å®ä¾‹åœ¨æ¯ä¸ªçºªå…ƒå¼€å§‹æ—¶è¢«æ´—ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For clarity in the graph, rewards at non-terminal nodes are left out and rewards are shown just once at each terminal node; the BUST state is shown twice to avoid overlapping transition arrows; and only an illustrative selection of transition probabilities are shown (the full set of transitions probabilities is shown in the transition matrices in Equations (11.15)[650] and (11.14)[650]).",
            "zh": "ä¸ºäº†å›¾ä¸­çš„æ¸…æ™°èµ·è§ï¼Œéç»ˆç«¯èŠ‚ç‚¹çš„å¥–åŠ±è¢«çœç•¥ï¼Œæ¯ä¸ªç»ˆç«¯èŠ‚ç‚¹çš„å¥–åŠ±åªæ˜¾ç¤ºä¸€æ¬¡;BUST çŠ¶æ€æ˜¾ç¤ºä¸¤æ¬¡ï¼Œä»¥é¿å…é‡å è¿‡æ¸¡ç®­å¤´;å¹¶ä¸”ä»…æ˜¾ç¤ºäº†è½¬ç§»æ¦‚ç‡çš„è¯´æ˜æ€§é€‰æ‹©ï¼ˆå®Œæ•´çš„è½¬ç§»æ¦‚ç‡é›†æ˜¾ç¤ºåœ¨æ–¹ç¨‹ï¼ˆ11.15ï¼‰[650]å’Œï¼ˆ11.14ï¼‰[650]çš„è½¬ç§»çŸ©é˜µä¸­ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.9[88] also shows the effect of applying standardization to the HEIGHT and SPONSORSHIP EARNINGS features.",
            "zh": "è¡¨3.9[88]è¿˜æ˜¾ç¤ºäº†å¯¹HEIGHTå’ŒSPONSORSHIP EARNSç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "The criterion of consistency with the training data doesnâ€™t provide any guidance with regard to which of the consistent models to prefer in dealing with queries that are outside the training dataset.",
            "zh": "ä¸è®­ç»ƒæ•°æ®çš„ä¸€è‡´æ€§æ ‡å‡†æ²¡æœ‰æä¾›ä»»ä½•æŒ‡å¯¼ï¼Œè¯´æ˜åœ¨å¤„ç†è®­ç»ƒæ•°æ®é›†ä¹‹å¤–çš„æŸ¥è¯¢æ—¶é¦–é€‰å“ªç§ä¸€è‡´æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s return to the motor insurance fraud detection solution to consider the design and implementation of the features that will populate the ABT.",
            "zh": "è®©æˆ‘ä»¬å›åˆ°æ±½è½¦ä¿é™©æ¬ºè¯ˆæ£€æµ‹è§£å†³æ–¹æ¡ˆï¼Œä»¥è€ƒè™‘å°†å¡«å…… ABT çš„åŠŸèƒ½çš„è®¾è®¡å’Œå®ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision trees look very like the game trees that we developed for the Guess Who game.",
            "zh": "å†³ç­–æ ‘çœ‹èµ·æ¥éå¸¸åƒæˆ‘ä»¬ä¸º Guess Who æ¸¸æˆå¼€å‘çš„æ¸¸æˆæ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "31. See Davies (2005, pp. 693â€“696).",
            "zh": "31. å‚è§Daviesï¼ˆ2005å¹´ï¼Œç¬¬693-696é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(c) Histograms for the features from the AT ABT with irregular cardinality; (d)â€“(g) histograms for the features from the AT ABT that are potentially suffering from outliers.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ å…·æœ‰ä¸è§„åˆ™åŸºæ•°çš„ AT ABT ç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆdï¼‰â€“ï¼ˆgï¼‰ æ¥è‡ª AT ABT çš„å¯èƒ½å—åˆ°å¼‚å¸¸å€¼å½±å“çš„ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.11[152] lists a small dataset from this domain.17",
            "zh": "è¡¨4.11[152]åˆ—å‡ºäº†æ¥è‡ªè¯¥åŸŸçš„ä¸€ä¸ªå°æ•°æ®é›†17ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.75",
            "zh": "0.75"
        }
    },
    {
        "translation": {
            "en": "If none of these cases holds, the algorithm continues to recursively create interior nodes, Lines 7â€“13 of Algorithm 1[134].",
            "zh": "å¦‚æœè¿™äº›æƒ…å†µéƒ½ä¸æˆç«‹ï¼Œåˆ™ç®—æ³•ç»§ç»­é€’å½’åˆ›å»ºå†…éƒ¨èŠ‚ç‚¹ï¼Œå³ç®—æ³• 1 çš„ç¬¬ 7-13 è¡Œ[134]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.9",
            "zh": "å›¾ 9.9"
        }
    },
    {
        "translation": {
            "en": "By contrast, consider the example of calculating the entropy of a set of 52 playing cards if we distinguish between cards on the sole basis of their suit (hearts â™¥, clubs â™£, diamonds â™¦ or, spades â™ ). This time, there are only four possible outcomes when a random card is selected from this set, each with a reasonably large probability of . The entropy associated with this set can be calculated",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬ä»…æ ¹æ®èŠ±è‰²ï¼ˆçº¢å¿ƒâ™¥ã€æ¢…èŠ±â™£ã€æ–¹å—â™¦æˆ–é»‘æ¡ƒâ™ ï¼‰æ¥åŒºåˆ†ç‰Œï¼Œè¯·è€ƒè™‘è®¡ç®—ä¸€ç»„ 52 å¼ æ‰‘å…‹ç‰Œçš„ç†µçš„ä¾‹å­ã€‚è¿™ä¸€æ¬¡ï¼Œå½“ä»è¿™ç»„ç‰Œä¸­éšæœºé€‰æ‹©ä¸€å¼ ç‰Œæ—¶ï¼Œåªæœ‰å››ç§å¯èƒ½çš„ç»“æœï¼Œæ¯ç§ç»“æœçš„æ¦‚ç‡éƒ½ç›¸å½“å¤§ã€‚å¯ä»¥è®¡ç®—ä¸æ­¤é›†åˆç›¸å…³çš„ç†µ"
        }
    },
    {
        "translation": {
            "en": "1 show the distances between each instance and these initial cluster centroids.",
            "zh": "å›¾ 1 æ˜¾ç¤ºäº†æ¯ä¸ªå®ä¾‹ä¸è¿™äº›åˆå§‹èšç±»è´¨å¿ƒä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) Measure the performance of this boosted ensemble using misclassification rate.",
            "zh": "ï¼ˆdï¼‰ ä½¿ç”¨é”™è¯¯åˆ†ç±»ç‡æ¥è¡¡é‡è¿™ç§å¢å¼ºé›†åˆçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This adjustment is repeated over and over until the global minimum on the error surface is reached.",
            "zh": "ä¸€éåˆä¸€éåœ°é‡å¤æ­¤è°ƒæ•´ï¼Œç›´åˆ°è¾¾åˆ°è¯¯å·®æ›²é¢ä¸Šçš„å…¨å±€æœ€å°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.17",
            "zh": "å›¾ 10.17"
        }
    },
    {
        "translation": {
            "en": "The following image labeled (a) shows a simple schematic of a system used to train a self-driving car to drive on a four-lane highway.",
            "zh": "ä¸‹å›¾æ ‡è®°ä¸ºï¼ˆaï¼‰æ˜¾ç¤ºäº†ç”¨äºè®­ç»ƒè‡ªåŠ¨é©¾é©¶æ±½è½¦åœ¨å››è½¦é“é«˜é€Ÿå…¬è·¯ä¸Šè¡Œé©¶çš„ç³»ç»Ÿçš„ç®€å•ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, there is no guaranteed way of finding the optimal number of bins for a set of values for a continuous feature.",
            "zh": "é—æ†¾çš„æ˜¯ï¼Œæ— æ³•ä¿è¯ä¸ºè¿ç»­ç‰¹å¾çš„ä¸€ç»„å€¼æ‰¾åˆ°æœ€ä½³æ¡æŸ±æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Within a few years of the publication of this article, the consensus within the physics research community is that N rays do not exist.",
            "zh": "åœ¨è¿™ç¯‡æ–‡ç« å‘è¡¨åçš„å‡ å¹´å†…ï¼Œç‰©ç†å­¦ç ”ç©¶ç•Œçš„å…±è¯†æ˜¯Nå°„çº¿ä¸å­˜åœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "bootstrap samples, 159",
            "zh": "Bootstrap ç¤ºä¾‹ï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "Table 6.3[264] lists the probabilities we need for our naive Bayes fraud detection model.",
            "zh": "è¡¨ 6.3[264] åˆ—å‡ºäº†æœ´ç´ è´å¶æ–¯æ¬ºè¯ˆæ£€æµ‹æ¨¡å‹æ‰€éœ€çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Transition Probabilities",
            "zh": "è½¬ç§»æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "There are three technical requirements that must hold for distribution of states generated from Gibbs sampling to converge with the distribution that we are sampling fromâ€”in this case, the distribution defined by the Bayesian network.",
            "zh": "å¯¹äºä»å‰å¸ƒæ–¯é‡‡æ ·ç”Ÿæˆçš„çŠ¶æ€åˆ†å¸ƒï¼Œå¿…é¡»æ»¡è¶³ä¸‰ä¸ªæŠ€æœ¯è¦æ±‚ï¼Œä»¥ä¾¿ä¸æˆ‘ä»¬ä»ä¸­é‡‡æ ·çš„åˆ†å¸ƒæ”¶æ•›ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œç”±è´å¶æ–¯ç½‘ç»œå®šä¹‰çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "A Markov decision process (MDP) extends the Markov process by adding decision making and rewards. We extend the formulation of the Markov process to include a finite set of actions that can be taken, A, and add actions from this set to the formulation of transition probabilities",
            "zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ ï¼ˆMDPï¼‰ é€šè¿‡æ·»åŠ å†³ç­–å’Œå¥–åŠ±æ¥æ‰©å±•é©¬å°”å¯å¤«è¿‡ç¨‹ã€‚æˆ‘ä»¬æ‰©å±•äº†é©¬å°”å¯å¤«è¿‡ç¨‹çš„å…¬å¼ï¼Œä»¥åŒ…æ‹¬ä¸€ç»„å¯ä»¥é‡‡å–çš„æœ‰é™åŠ¨ä½œï¼ŒAï¼Œå¹¶å°†è¯¥é›†åˆä¸­çš„åŠ¨ä½œæ·»åŠ åˆ°è½¬ç§»æ¦‚ç‡çš„å…¬å¼ä¸­"
        }
    },
    {
        "translation": {
            "en": "In the context of a predictive analytics scenario, the sample is the set of values that occur in an ABT. The population is the set of all the values that could possibly occur. For example, in an ABT for a motor insurance claims fraud prediction problem, we may include details of 500 claims that have happened in the past. This would be our sample. The population would be all the claims that have ever happened.",
            "zh": "åœ¨é¢„æµ‹åˆ†ææ–¹æ¡ˆçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œç¤ºä¾‹æ˜¯ ABT ä¸­å‡ºç°çš„ä¸€ç»„å€¼ã€‚æ€»ä½“æ˜¯å¯èƒ½å‘ç”Ÿçš„æ‰€æœ‰å€¼çš„é›†åˆã€‚ä¾‹å¦‚ï¼Œåœ¨æ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆé¢„æµ‹é—®é¢˜çš„ ABT ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šåŒ…æ‹¬è¿‡å»å‘ç”Ÿçš„ 500 é¡¹ç´¢èµ”çš„è¯¦ç»†ä¿¡æ¯ã€‚è¿™å°†æ˜¯æˆ‘ä»¬çš„ç¤ºä¾‹ã€‚äººå£å°†æ˜¯æ›¾ç»å‘ç”Ÿè¿‡çš„æ‰€æœ‰ç´¢èµ”ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we are computing a conditional probability, we need to be aware of the state of both the parents of a node and the children of a node and their parents. This is because knowledge of the state of a child node can tell us something about the state of the parent node. For example, returning to our simple Bayesian network in Figure 6.9(a)[287], we can compute P(a | Â¬b) using Bayesâ€™ Theorem as follows:",
            "zh": "å½“æˆ‘ä»¬è®¡ç®—æ¡ä»¶æ¦‚ç‡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹å’ŒèŠ‚ç‚¹çš„å­èŠ‚ç‚¹åŠå…¶çˆ¶èŠ‚ç‚¹çš„çŠ¶æ€ã€‚è¿™æ˜¯å› ä¸ºäº†è§£å­èŠ‚ç‚¹çš„çŠ¶æ€å¯ä»¥å‘Šè¯‰æˆ‘ä»¬æœ‰å…³çˆ¶èŠ‚ç‚¹çŠ¶æ€çš„ä¸€äº›ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå›åˆ°å›¾6.9ï¼ˆaï¼‰[287]ä¸­çš„ç®€å•è´å¶æ–¯ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è´å¶æ–¯å®šç†è®¡ç®—Pï¼ˆa | Â¬bï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "What are the goals that the business wants to achieve?",
            "zh": "ä¼ä¸šæƒ³è¦å®ç°çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "MRRCC_U/G/R/I/Z",
            "zh": "MRRCC_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The measure of brightness used in the SDSS pipeline is referred to as magnitude.",
            "zh": "SDSS ç®¡é“ä¸­ä½¿ç”¨çš„äº®åº¦åº¦é‡ç§°ä¸ºå¹…åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(d)[626] shows the final reconstructions generated by the network after 1,000 epochs of network training.",
            "zh": "å›¾ 10.15ï¼ˆdï¼‰[626] æ˜¾ç¤ºäº†ç½‘ç»œåœ¨ 1,000 ä¸ªç½‘ç»œè®­ç»ƒå‘¨æœŸåç”Ÿæˆçš„æœ€ç»ˆé‡å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "SMOKER, do they smoke",
            "zh": "å¸çƒŸè€…ï¼Œä»–ä»¬æŠ½çƒŸå—"
        }
    },
    {
        "translation": {
            "en": "Tables 9.10(a)[555] and 9.10(b)[555] show this calculation for the k-NN and the decision tree models.",
            "zh": "è¡¨9.10ï¼ˆaï¼‰[555]å’Œè¡¨9.10ï¼ˆbï¼‰[555]æ˜¾ç¤ºäº†k-NNå’Œå†³ç­–æ ‘æ¨¡å‹çš„è®¡ç®—ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "stability index, 580, 590, 591, 727",
            "zh": "ç¨³å®šæ€§æŒ‡æ•°ï¼Œ 580ï¼Œ 590ï¼Œ 591ï¼Œ 727"
        }
    },
    {
        "translation": {
            "en": "The SDSS download that Jocelyn had access to was a big datasetâ€”over 600,000 rows. Although modern predictive analytics and machine learning tools can handle data of this size, a large dataset can be cumbersome when performing data exploration operationsâ€”calculating summary statistics, generating visualizations, and performing correlation tests can just take too long. For this reason, Jocelyn extracted a small sample of 10,000 rows from the full dataset for exploratory analysis using stratified sampling.",
            "zh": "Jocelyn å¯ä»¥è®¿é—®çš„ SDSS ä¸‹è½½æ˜¯ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼Œè¶…è¿‡ 600,000 è¡Œã€‚å°½ç®¡ç°ä»£é¢„æµ‹åˆ†æå’Œæœºå™¨å­¦ä¹ å·¥å…·å¯ä»¥å¤„ç†è¿™ç§å¤§å°çš„æ•°æ®ï¼Œä½†åœ¨æ‰§è¡Œæ•°æ®æ¢ç´¢æ“ä½œæ—¶ï¼Œå¤§å‹æ•°æ®é›†å¯èƒ½ä¼šå¾ˆéº»çƒ¦ - è®¡ç®—æ±‡æ€»ç»Ÿè®¡ã€ç”Ÿæˆå¯è§†åŒ–æ•ˆæœå’Œæ‰§è¡Œç›¸å…³æ€§æµ‹è¯•å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼ŒJocelyn ä»å®Œæ•´æ•°æ®é›†ä¸­æå–äº† 10,000 è¡Œçš„å°æ ·æœ¬ï¼Œä»¥ä½¿ç”¨åˆ†å±‚æŠ½æ ·è¿›è¡Œæ¢ç´¢æ€§åˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "The mapping between the features we have discussed here and the column names in Table 2.2[46] is as follows: NUMBER OF CLAIMANTS: NUM.",
            "zh": "æˆ‘ä»¬åœ¨è¿™é‡Œè®¨è®ºçš„ç‰¹å¾ä¸è¡¨2.2[46]ä¸­çš„åˆ—åä¹‹é—´çš„æ˜ å°„å¦‚ä¸‹ï¼š ç´¢èµ”äººæ•°é‡ï¼šæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "machine learning, 4, 5",
            "zh": "æœºå™¨å­¦ä¹ ï¼Œ 4ï¼Œ 5"
        }
    },
    {
        "translation": {
            "en": "This first path of information processing in the input gate is similar to the process used in the forget gate; however, in this case the generate vector mask is not applied directly to the cell state but rather is used to filter the vector of output activations generated by the second path of processing in the input gate.",
            "zh": "è¾“å…¥é—¨ä¸­ä¿¡æ¯å¤„ç†çš„ç¬¬ä¸€æ¡è·¯å¾„ç±»ä¼¼äºé—å¿˜é—¨ä¸­ä½¿ç”¨çš„è¿‡ç¨‹;ä½†æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”Ÿæˆå‘é‡æ©ç ä¸ä¼šç›´æ¥åº”ç”¨äºå•å…ƒçŠ¶æ€ï¼Œè€Œæ˜¯ç”¨äºè¿‡æ»¤ç”±è¾“å…¥é—¨ä¸­çš„ç¬¬äºŒæ¡å¤„ç†è·¯å¾„ç”Ÿæˆçš„è¾“å‡ºæ¿€æ´»å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "information, 120",
            "zh": "ä¿¡æ¯ï¼Œ120"
        }
    },
    {
        "translation": {
            "en": "The link between machine learning and data analytics runs through every chapter in the book but is especially strong in Part I, which includes Chapters 1 to 3.",
            "zh": "æœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æä¹‹é—´çš„è”ç³»è´¯ç©¿äº†æœ¬ä¹¦çš„æ¯ä¸€ç« ï¼Œä½†åœ¨ç¬¬ä¸€éƒ¨åˆ†ï¼ˆåŒ…æ‹¬ç¬¬ 1 ç« åˆ°ç¬¬ 3 ç« ï¼‰ä¸­å°¤ä¸ºçªå‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The boundary between d4 and d3 is",
            "zh": "d4 å’Œ d3 ä¹‹é—´çš„è¾¹ç•Œæ˜¯"
        }
    },
    {
        "translation": {
            "en": "Note that in this diagram the BUST state has been included twice to make the illustration a little more clear by avoiding too many overlapping arrows.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨æ­¤å›¾ä¸­ï¼ŒBUST çŠ¶æ€å·²åŒ…å«ä¸¤æ¬¡ï¼Œé€šè¿‡é¿å…å¤ªå¤šé‡å ç®­å¤´ä½¿æ’å›¾æ›´åŠ æ¸…æ™°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.6â€…â€…â€…The posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false.",
            "zh": "6.6 FRAUD=falseæ¡ä»¶ä¸‹æ‹…ä¿äºº/å…±åŒç”³è¯·äººç‰¹å¾çš„åéªŒæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "derived features, 34, 41, 45",
            "zh": "æ´¾ç”Ÿç‰¹å¾ï¼Œ 34ï¼Œ 41ï¼Œ 45"
        }
    },
    {
        "translation": {
            "en": "This will repeat for some pre-specified number of episodes after which the expectation is that the agent will have learned to perform the task well.",
            "zh": "è¿™å°†åœ¨ä¸€äº›é¢„å…ˆæŒ‡å®šçš„å‰§é›†ä¸­é‡å¤ï¼Œä¹‹åæœŸæœ›ä»£ç†å·²ç»å­¦ä¼šå¾ˆå¥½åœ°æ‰§è¡Œä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Applying this to the example f(x) = (x2 + 1)2 we get",
            "zh": "å°†å…¶åº”ç”¨äºç¤ºä¾‹ fï¼ˆxï¼‰ = ï¼ˆx2 + 1ï¼‰2 æˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "The ability of deep neural networks to learn and represent complex mappings from inputs to outputs is why these networks have been so successful at so many complex tasks. However, this representational capacity also means that deep networks are likely to suffer from overfitting. Dropout is a very simple and effective method that helps to stop overfitting.",
            "zh": "æ·±åº¦ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å’Œè¡¨ç¤ºä»è¾“å…¥åˆ°è¾“å‡ºçš„å¤æ‚æ˜ å°„ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™äº›ç½‘ç»œåœ¨å¦‚æ­¤å¤šçš„å¤æ‚ä»»åŠ¡ä¸­å¦‚æ­¤æˆåŠŸçš„åŸå› ã€‚ç„¶è€Œï¼Œè¿™ç§è¡¨ç¤ºèƒ½åŠ›ä¹Ÿæ„å‘³ç€æ·±åº¦ç½‘ç»œå¯èƒ½ä¼šé­å—è¿‡æ‹Ÿåˆçš„å½±å“ã€‚Dropout æ˜¯ä¸€ç§éå¸¸ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œæœ‰åŠ©äºé˜»æ­¢è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The narrow middle layer is often referred to as a bottleneck layer.",
            "zh": "ç‹­çª„çš„ä¸­é—´å±‚é€šå¸¸è¢«ç§°ä¸ºç“¶é¢ˆå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "linear kernel, 366",
            "zh": "çº¿æ€§å†…æ ¸ï¼Œ366"
        }
    },
    {
        "translation": {
            "en": "We use rt to refer to feedback, as in reinforcement learning feedback is more commonly referred to as reward (where reward can be either positive or negative).",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ rt æ¥æŒ‡ä»£åé¦ˆï¼Œå› ä¸ºåœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œåé¦ˆé€šå¸¸è¢«ç§°ä¸ºå¥–åŠ±ï¼ˆå¥–åŠ±å¯ä»¥æ˜¯ç§¯æçš„ï¼Œä¹Ÿå¯ä»¥æ˜¯æ¶ˆæçš„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The definition of the mixture of Gaussians distribution in Table 6.10[271] shows how the individual normal distributions in a mixture of Gaussians distribution are combined using a weighted sum.",
            "zh": "è¡¨6.10[271]ä¸­é«˜æ–¯åˆ†å¸ƒæ··åˆçš„å®šä¹‰æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨åŠ æƒå’Œç»„åˆé«˜æ–¯åˆ†å¸ƒæ··åˆä¸­çš„å„ä¸ªæ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE; RATIO OF SOFT TISSUE CLAIMS TO OTHER CLAIMS: % SOFT TISSUE; UNSUCCESSFUL CLAIM MADE: UNSUCC.",
            "zh": "è½¯ç»„ç»‡;è½¯ç»„ç»‡æƒåˆ©è¦æ±‚ä¸å…¶ä»–æƒåˆ©è¦æ±‚çš„æ¯”ç‡ï¼š%è½¯ç»„ç»‡;ç´¢èµ”ä¸æˆåŠŸï¼šUNSUCCã€‚"
        }
    },
    {
        "translation": {
            "en": "Each subsequent layer in the network is able to use the functions learned by the previous layer to construct a more complex function; this process of using the outputs from one or more functions and inputs to another function to create a new function is known as function composition.",
            "zh": "ç½‘ç»œä¸­çš„æ¯ä¸€å±‚éƒ½èƒ½å¤Ÿä½¿ç”¨å‰ä¸€å±‚å­¦ä¹ åˆ°çš„å‡½æ•°æ¥æ„é€ æ›´å¤æ‚çš„å‡½æ•°;ä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå‡½æ•°çš„è¾“å‡ºå’Œå¦ä¸€ä¸ªå‡½æ•°çš„è¾“å…¥æ¥åˆ›å»ºæ–°å‡½æ•°çš„è¿‡ç¨‹ç§°ä¸ºå‡½æ•°ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "data quality report, 53, 54, 94, 98, 105, 110, 614, 693, 710",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šï¼Œ 53ï¼Œ 54ï¼Œ 94ï¼Œ 98ï¼Œ 105ï¼Œ 110ï¼Œ 614ï¼Œ 693ï¼Œ 710"
        }
    },
    {
        "translation": {
            "en": "The result of this product is the Î´k for the neuron.",
            "zh": "è¯¥ä¹˜ç§¯çš„ç»“æœæ˜¯ç¥ç»å…ƒçš„ Î´kã€‚"
        }
    },
    {
        "translation": {
            "en": "When the algorithm exits the for loop on Line 11[420], the mini-batch examples will have been propagated through all L layers of the network, and A(L) will store the activations for all the neurons in the output layer for all the examples in the mini-batch; as per Figure 8.6[393] the activations are arranged so that the output layer activations for each example will be stored as a column in A(L).",
            "zh": "å½“ç®—æ³•åœ¨ç¬¬ 11 è¡Œé€€å‡º for å¾ªç¯æ—¶[420]ï¼Œå°æ‰¹é‡ç¤ºä¾‹å°†é€šè¿‡ç½‘ç»œçš„æ‰€æœ‰ L å±‚ä¼ æ’­ï¼Œå¹¶ä¸” Aï¼ˆLï¼‰ å°†å­˜å‚¨å°æ‰¹é‡ä¸­æ‰€æœ‰ç¤ºä¾‹çš„è¾“å‡ºå±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒçš„æ¿€æ´»;æ ¹æ®å›¾ 8.6[393]ï¼Œæ¿€æ´»çš„æ’åˆ—æ–¹å¼ä½¿å¾—æ¯ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚æ¿€æ´»å°†å­˜å‚¨ä¸º Aï¼ˆLï¼‰ ä¸­çš„ä¸€åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision boundary using majority vote of the nearest 3 and 5 instances.",
            "zh": "ä½¿ç”¨æœ€æ¥è¿‘çš„ 3 ä¸ªå’Œ 5 ä¸ªå®ä¾‹çš„å¤šæ•°ç¥¨çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "0.71",
            "zh": "0.71"
        }
    },
    {
        "translation": {
            "en": "18. This is related to the idea of concept drift discussed in Section 9.4.6[578].",
            "zh": "18. è¿™ä¸ç¬¬9.4.6èŠ‚[578]ä¸­è®¨è®ºçš„æ¦‚å¿µæ¼‚ç§»çš„æ¦‚å¿µæœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "where levels(f) returns the set of levels in the domain of the feature f.",
            "zh": "å…¶ä¸­ levelsï¼ˆfï¼‰ è¿”å›ç‰¹å¾ f åŸŸä¸­çš„çº§åˆ«é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "TACHYCARDIA: Is the patient at high risk of suffering from tachycardia in the next month?",
            "zh": "å¿ƒåŠ¨è¿‡é€Ÿï¼šæ‚£è€…åœ¨ä¸‹ä¸ªæœˆæ‚£å¿ƒåŠ¨è¿‡é€Ÿçš„é£é™©æ˜¯å¦å¾ˆé«˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Once the data has been prepared, there are two stages to building the Bayesian network. First, we define the topology of the network. Second, we create the network CPTs. The topology of the network will be a causal graph that models this domain. In order to build this, we must have a theory of the causal relationships between the features in the domain. A potential causal theory between the features in this dataset is that",
            "zh": "å‡†å¤‡å¥½æ•°æ®åï¼Œæ„å»ºè´å¶æ–¯ç½‘ç»œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åˆ›å»ºç½‘ç»œ CPTã€‚ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„å°†æ˜¯æ¨¡æ‹Ÿæ­¤åŸŸçš„å› æœå›¾ã€‚ä¸ºäº†å»ºç«‹è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ä¸ªå…³äºåŸŸä¸­ç‰¹å¾ä¹‹é—´å› æœå…³ç³»çš„ç†è®ºã€‚è¯¥æ•°æ®é›†ä¸­ç‰¹å¾ä¹‹é—´çš„æ½œåœ¨å› æœç†è®ºæ˜¯"
        }
    },
    {
        "translation": {
            "en": "So the effect of multiplying feature values by an inverse covariance matrix is to rescale the variances of all features to 1 and to set the covariance between all feature pairs to 0.",
            "zh": "å› æ­¤ï¼Œå°†ç‰¹å¾å€¼ä¹˜ä»¥é€†åæ–¹å·®çŸ©é˜µçš„æ•ˆæœæ˜¯å°†æ‰€æœ‰ç‰¹å¾çš„æ–¹å·®é‡æ–°ç¼©æ”¾ä¸º 1ï¼Œå¹¶å°†æ‰€æœ‰ç‰¹å¾å¯¹ä¹‹é—´çš„åæ–¹å·®è®¾ç½®ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "MODELFLUXIVAR_U/G/R/I/Z",
            "zh": "MODELFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The company would like to evaluate how well the model is helping to address the churn problem.",
            "zh": "è¯¥å…¬å¸å¸Œæœ›è¯„ä¼°è¯¥æ¨¡å‹åœ¨å¸®åŠ©è§£å†³å®¢æˆ·æµå¤±é—®é¢˜æ–¹é¢çš„æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrices are shown in Table 13.6[721].",
            "zh": "ç”±æ­¤äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.6[721]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In email classification, identifying spam emails is the most important issue, so the spam level is referred to as the positive level.",
            "zh": "åœ¨ç”µå­é‚®ä»¶åˆ†ç±»ä¸­ï¼Œè¯†åˆ«åƒåœ¾é‚®ä»¶æ˜¯æœ€é‡è¦çš„é—®é¢˜ï¼Œå› æ­¤åƒåœ¾é‚®ä»¶çº§åˆ«ç§°ä¸ºæ­£é¢çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "29. Note that using linear activation functions in this way means that the network as a whole implements a linear function. However, in this instance, this simplification is appropriate because the purpose of this network architecture design is to illustrate the effect of different weight initialization regimes rather than to be accurate on the task.",
            "zh": "29. è¯·æ³¨æ„ï¼Œä»¥è¿™ç§æ–¹å¼ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°æ„å‘³ç€æ•´ä¸ªç½‘ç»œå®ç°äº†çº¿æ€§å‡½æ•°ã€‚ä½†æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™ç§ç®€åŒ–æ˜¯é€‚å½“çš„ï¼Œå› ä¸ºæ­¤ç½‘ç»œæ¶æ„è®¾è®¡çš„ç›®çš„æ˜¯è¯´æ˜ä¸åŒæƒé‡åˆå§‹åŒ–æœºåˆ¶çš„å½±å“ï¼Œè€Œä¸æ˜¯åœ¨ä»»åŠ¡ä¸Šå‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to using small multiples for categorical features, if the features are unrelated (or independent), then the histograms for each level should be very similar.",
            "zh": "ä¸å¯¹åˆ†ç±»è¦ç´ ä½¿ç”¨å°å€æ•°ç±»ä¼¼ï¼Œå¦‚æœè¦ç´ ä¸ç›¸å…³ï¼ˆæˆ–ç‹¬ç«‹ï¼‰ï¼Œåˆ™æ¯ä¸ªçº§åˆ«çš„ç›´æ–¹å›¾åº”éå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "MODULE 1",
            "zh": "æ¨¡å— 1"
        }
    },
    {
        "translation": {
            "en": "gain, 567, 569",
            "zh": "å¢ç›Šï¼Œ 567ï¼Œ 569"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy was 78.278%, which was similar to the accuracies measured on the overall test set.",
            "zh": "å¹³å‡ç±»å‡†ç¡®ç‡ä¸º78.278%ï¼Œä¸æ•´ä¸ªæµ‹è¯•é›†æµ‹é‡çš„å‡†ç¡®åº¦ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "OpenAI Gym, 668",
            "zh": "OpenAI å¥èº«æˆ¿ï¼Œ668"
        }
    },
    {
        "translation": {
            "en": "For example, if the target feature originally had the range [min,max] and range normalization has been applied to map this to the range of [0,1], then the activation of a logistic unit in the output layer of the network ai can be mapped to the corresponding value in the original range of the target feature by max Ã— ai.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœç›®æ ‡è¦ç´ åŸæ¥å…·æœ‰ [minï¼Œmax] çš„èŒƒå›´ï¼Œå¹¶ä¸”å·²åº”ç”¨èŒƒå›´å½’ä¸€åŒ–å°†å…¶æ˜ å°„åˆ° [0,1] çš„èŒƒå›´ï¼Œåˆ™å¯ä»¥é€šè¿‡ max Ã— ai å°†ç½‘ç»œ ai è¾“å‡ºå±‚ä¸­é€»è¾‘å•å…ƒçš„æ¿€æ´»æ˜ å°„åˆ°ç›®æ ‡è¦ç´ åŸå§‹èŒƒå›´å†…çš„ç›¸åº”å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are using the term valid here to distinguish the pixels that occur in the image from imaginary (or padding) pixels that we might invent around the border of an image.",
            "zh": "æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨æœ‰æ•ˆçš„æœ¯è¯­æ¥åŒºåˆ†å›¾åƒä¸­å‡ºç°çš„åƒç´ å’Œæˆ‘ä»¬å¯èƒ½åœ¨å›¾åƒè¾¹ç•Œå‘¨å›´å‘æ˜çš„è™šæ„ï¼ˆæˆ–å¡«å……ï¼‰åƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset contains 60,000 training and 10,000 test images of handwritten digits from approximately 250 writers.",
            "zh": "è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªå¤§çº¦ 250 åä½œå®¶çš„ 60,000 å¼ è®­ç»ƒå›¾åƒå’Œ 10,000 å¼ æ‰‹å†™æ•°å­—æµ‹è¯•å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, this rewriting shows that the output of this two-layer network with linear neurons is equivalent to a single-layer network with linear neurons.",
            "zh": "å› æ­¤ï¼Œè¿™ç§é‡å†™è¡¨æ˜ï¼Œè¿™ä¸ªå…·æœ‰çº¿æ€§ç¥ç»å…ƒçš„ä¸¤å±‚ç½‘ç»œçš„è¾“å‡ºç­‰ä»·äºå…·æœ‰çº¿æ€§ç¥ç»å…ƒçš„å•å±‚ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Open Questions",
            "zh": "å¼€æ”¾æ€§é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "We can see from Table 7.4[333] that only the SIZE descriptive feature has a significant impact on the model.",
            "zh": "ä»è¡¨7.4[333]ä¸­å¯ä»¥çœ‹å‡ºï¼Œåªæœ‰SIZEæè¿°æ€§ç‰¹å¾å¯¹æ¨¡å‹æœ‰æ˜¾è‘—å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "In our example, convergence occurred after 100 iterations, and the final values for the weights were w[0] = âˆ’0.1513, w[1] = 0.6270, w[2] = âˆ’0.1781, and w[3] = 0.0714.",
            "zh": "åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæ”¶æ•›å‘ç”Ÿåœ¨ 100 æ¬¡è¿­ä»£åï¼Œæƒé‡çš„æœ€ç»ˆå€¼ä¸º w[0] = âˆ’0.1513ã€w[1] = 0.6270ã€w[2] = âˆ’0.1781 å’Œ w[3] = 0.0714ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can calculate performance measures for a deployed model and compare these to the performance achieved in evaluations before the model was deployed.",
            "zh": "æˆ‘ä»¬å¯ä»¥è®¡ç®—å·²éƒ¨ç½²æ¨¡å‹çš„æ€§èƒ½åº¦é‡ï¼Œå¹¶å°†å…¶ä¸éƒ¨ç½²æ¨¡å‹ä¹‹å‰åœ¨è¯„ä¼°ä¸­å®ç°çš„æ€§èƒ½è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This domain concept is inherently related to the notion of an observation period, and as we will see, the descriptive features derived from the domain subconcepts under Claimant History are time dependent.",
            "zh": "è¿™ä¸ªé¢†åŸŸæ¦‚å¿µä¸è§‚å¯ŸæœŸçš„æ¦‚å¿µæœ‰ç€å†…åœ¨çš„è”ç³»ï¼Œæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œä»ç´¢èµ”äººå†å²ä¸‹çš„é¢†åŸŸå­æ¦‚å¿µæ´¾ç”Ÿçš„æè¿°æ€§ç‰¹å¾æ˜¯ä¸æ—¶é—´ç›¸å…³çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many of the continuous features in the dataset also have very low cardinality values.",
            "zh": "æ•°æ®é›†ä¸­çš„è®¸å¤šè¿ç»­è¦ç´ ä¹Ÿå…·æœ‰éå¸¸ä½çš„åŸºæ•°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy, however, to extend the ID3 algorithm to handle continuous descriptive features and continuous target features.",
            "zh": "ä½†æ˜¯ï¼Œæ‰©å±• ID3 ç®—æ³•ä»¥å¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾å’Œè¿ç»­ç›®æ ‡ç‰¹å¾ç›¸å¯¹å®¹æ˜“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix is a very useful analysis tool to capture what has happened in an evaluation test in a little more detail and is the basis for calculating many other performance measures.",
            "zh": "æ··æ·†çŸ©é˜µæ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åˆ†æå·¥å…·ï¼Œå¯ä»¥æ›´è¯¦ç»†åœ°æ•è·è¯„ä¼°æµ‹è¯•ä¸­å‘ç”Ÿçš„æƒ…å†µï¼Œå¹¶ä¸”æ˜¯è®¡ç®—è®¸å¤šå…¶ä»–æ€§èƒ½åº¦é‡çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Together the strong performance by the model on the large test dataset and the confidence built through the manual annotation exercise meant that Edwin and his colleagues were happy to integrate the 3-level model into the SDSS processing pipeline.",
            "zh": "è¯¥æ¨¡å‹åœ¨å¤§å‹æµ‹è¯•æ•°æ®é›†ä¸Šçš„å¼ºå¤§æ€§èƒ½ä»¥åŠé€šè¿‡æ‰‹åŠ¨æ³¨é‡Šç»ƒä¹ å»ºç«‹çš„ä¿¡å¿ƒæ„å‘³ç€ Edwin å’Œä»–çš„åŒäº‹ä»¬å¾ˆé«˜å…´å°† 3 çº§æ¨¡å‹é›†æˆåˆ° SDSS å¤„ç†ç®¡é“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, i is used to index instances in a dataset, and j is used to index features in a vector.",
            "zh": "é€šå¸¸ï¼Œi ç”¨äºç´¢å¼•æ•°æ®é›†ä¸­çš„å®ä¾‹ï¼Œj ç”¨äºç´¢å¼•å‘é‡ä¸­çš„è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The choice of the range from which these initial weights are selected affects how quickly the gradient descent algorithm will converge to a solution.",
            "zh": "é€‰æ‹©è¿™äº›åˆå§‹æƒé‡çš„èŒƒå›´ä¼šå½±å“æ¢¯åº¦ä¸‹é™ç®—æ³•æ”¶æ•›åˆ°è§£å†³æ–¹æ¡ˆçš„é€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Details of the first two iterations when the gradient descent algorithm is used to train a logistic regression model for the extended generators dataset given in Table 7.7[347].",
            "zh": "è¡¨7.7[347]ä¸­ç»™å‡ºçš„æ¢¯åº¦ä¸‹é™ç®—æ³•ç”¨äºè®­ç»ƒæ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„é€»è¾‘å›å½’æ¨¡å‹æ—¶ï¼Œå‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Manhattan distances between both pairs of instances are the same: 7.25.",
            "zh": "ä¸¤å¯¹å®ä¾‹ä¹‹é—´çš„æ›¼å“ˆé¡¿è·ç¦»ç›¸åŒï¼š7.25ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neural networks with a single hidden layer have been proven to be capable of universal approximation of (bounded) continuous functions as long as either (1) complex functions are integrated into the structure of the neurons, or (2) the hidden layer of the network is sufficiently (potentially exponentially) wide.",
            "zh": "å…·æœ‰å•ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œå·²è¢«è¯æ˜èƒ½å¤Ÿæ™®éè¿‘ä¼¼ï¼ˆæœ‰ç•Œï¼‰è¿ç»­å‡½æ•°ï¼Œåªè¦ ï¼ˆ1ï¼‰ å¤æ‚å‡½æ•°é›†æˆåˆ°ç¥ç»å…ƒç»“æ„ä¸­ï¼Œæˆ– ï¼ˆ2ï¼‰ ç½‘ç»œçš„éšè—å±‚è¶³å¤Ÿï¼ˆå¯èƒ½å‘ˆæŒ‡æ•°ï¼‰å®½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, assume both models use a threshold of > 0.5 for the idiom class.",
            "zh": "åŒæ ·ï¼Œå‡è®¾ä¸¤ä¸ªæ¨¡å‹éƒ½å¯¹ä¹ è¯­ç±»ä½¿ç”¨é˜ˆå€¼ > 0.5ã€‚"
        }
    },
    {
        "translation": {
            "en": "These new generated features can then replace the original descriptive features in an ABT for later tasks in a pipeline, for example, training a supervised machine learning model.",
            "zh": "ç„¶åï¼Œè¿™äº›æ–°ç”Ÿæˆçš„ç‰¹å¾å¯ä»¥æ›¿æ¢ ABT ä¸­çš„åŸå§‹æè¿°æ€§ç‰¹å¾ï¼Œç”¨äºç®¡é“ä¸­çš„åç»­ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œè®­ç»ƒç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(2008) report empirical evaluations of the accuracy of a range of model types across a range of domains.",
            "zh": "ï¼ˆ2008ï¼‰æŠ¥å‘Šäº†å¯¹ä¸€ç³»åˆ—æ¨¡å‹ç±»å‹åœ¨ä¸€ç³»åˆ—é¢†åŸŸçš„å‡†ç¡®æ€§çš„å®è¯è¯„ä¼°ã€‚"
        }
    },
    {
        "translation": {
            "en": "AMBIENT TEMPERATURE",
            "zh": "ç¯å¢ƒæ¸©åº¦"
        }
    },
    {
        "translation": {
            "en": "Figure 7.8[335] shows the journey across the error surface and related plot of the sums of squared errors for the office rentals problemâ€”using just the SIZE descriptive featureâ€”when error decay is used with Î±0 = 0.18 and c = 10 (this is a pretty simple problem, so smaller values for these parameters are suitable).",
            "zh": "å›¾ 7.8[335] æ˜¾ç¤ºäº†å½“è¯¯å·®è¡°å‡ä¸ Î±0 = 0.18 å’Œ c = 10 ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œä»…ä½¿ç”¨ SIZE æè¿°æ€§ç‰¹å¾æ—¶ï¼ŒåŠå…¬å®¤ç§Ÿèµé—®é¢˜çš„è¯¯å·®é¢å’Œå¹³æ–¹æ€»å’Œçš„ç›¸å…³å›¾ï¼ˆè¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„é—®é¢˜ï¼Œå› æ­¤è¿™äº›å‚æ•°çš„è¾ƒå°å€¼æ˜¯åˆé€‚çš„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rice, John A. 2006. Mathematical statistics and data analysis. Cengage Learning.",
            "zh": "èµ–æ–¯ï¼Œçº¦ç¿° A. 2006 å¹´ã€‚æ•°ç†ç»Ÿè®¡å’Œæ•°æ®åˆ†æã€‚åœ£æ™ºå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "INFANT MORT., the number of infant deaths per 1,000 births",
            "zh": "INFANT MORT.ï¼Œæ¯1000åæ–°ç”Ÿå„¿çš„å©´å„¿æ­»äº¡äººæ•°"
        }
    },
    {
        "translation": {
            "en": "Figure 4.18[156] illustrates a decision tree that has been trained for this post-operative patient routing task.",
            "zh": "å›¾ 4.18[156] è¯´æ˜äº†å·²é’ˆå¯¹æ­¤æœ¯åæ‚£è€…è·¯ç”±ä»»åŠ¡è®­ç»ƒçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The query instance value for this feature is true, and so on the basis of the result of the test at this node, the process descends the left branch, labeled true, to a leaf node labeled spam.",
            "zh": "æ­¤åŠŸèƒ½çš„æŸ¥è¯¢å®ä¾‹å€¼ä¸º trueï¼Œå› æ­¤ï¼Œæ ¹æ®æ­¤èŠ‚ç‚¹ä¸Šçš„æµ‹è¯•ç»“æœï¼Œè¯¥è¿›ç¨‹å°†æ ‡è®°ä¸º true çš„å·¦ä¾§åˆ†æ”¯ä¸‹é™åˆ°æ ‡è®°ä¸º spam çš„å¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simple multivariable linear regression (Section 7.3[319]) model (for convenience, repeated here as Equation (7.48)[367]) makes a prediction for a continuous target feature based on a weighted sum of the values of a set of descriptive features.",
            "zh": "ç®€å•çš„å¤šå˜é‡çº¿æ€§å›å½’ï¼ˆç¬¬ 7.3 èŠ‚[319]ï¼‰æ¨¡å‹ï¼ˆä¸ºæ–¹ä¾¿èµ·è§ï¼Œæ­¤å¤„é‡å¤ä¸ºæ–¹ç¨‹ ï¼ˆ7.48ï¼‰[367]ï¼‰åŸºäºä¸€ç»„æè¿°æ€§ç‰¹å¾å€¼çš„åŠ æƒå’Œå¯¹è¿ç»­ç›®æ ‡ç‰¹å¾è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset contained 600,000 rows and 547 columns,9 with one row for each galaxy observation, containing identifiers, position information, and measures describing the characteristics of the galaxy.",
            "zh": "è¯¥æ•°æ®é›†åŒ…å« 600,000 è¡Œå’Œ 547 åˆ—ï¼Œ9 æ¯ä¸ªæ˜Ÿç³»è§‚æµ‹ä¸€è¡Œï¼ŒåŒ…å«æ ‡è¯†ç¬¦ã€ä½ç½®ä¿¡æ¯å’Œæè¿°æ˜Ÿç³»ç‰¹å¾çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, in domains where the causal relationships between features are known, Bayesian networks have the advantage of providing a natural framework for integrating expert human knowledge with data-driven induction.",
            "zh": "æ­¤å¤–ï¼Œåœ¨å·²çŸ¥ç‰¹å¾ä¹‹é—´å› æœå…³ç³»çš„é¢†åŸŸä¸­ï¼Œè´å¶æ–¯ç½‘ç»œçš„ä¼˜åŠ¿åœ¨äºæä¾›äº†ä¸€ä¸ªè‡ªç„¶çš„æ¡†æ¶ï¼Œç”¨äºå°†ä¸“å®¶äººç±»çŸ¥è¯†ä¸æ•°æ®é©±åŠ¨çš„å½’çº³ç›¸ç»“åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "An average class accuracy performance measure, however, brings this issue to the fore.",
            "zh": "ç„¶è€Œï¼Œå¹³å‡ç±»å‡†ç¡®æ€§æ€§èƒ½æµ‹é‡ä½¿è¿™ä¸ªé—®é¢˜å‡¸æ˜¾å‡ºæ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This neuron receives nin inputs d1,â€¦,dnin (note that for this discussion we ignore the bias input and weight, and we drop the layer (k) superscript when we are discussing a single neuron).",
            "zh": "è¯¥ç¥ç»å…ƒæ¥æ”¶ nin è¾“å…¥ d1,...,dninï¼ˆè¯·æ³¨æ„ï¼Œåœ¨æœ¬æ¬¡è®¨è®ºä¸­ï¼Œæˆ‘ä»¬å¿½ç•¥äº†åå·®è¾“å…¥å’Œæƒé‡ï¼Œå¹¶ä¸”åœ¨è®¨è®ºå•ä¸ªç¥ç»å…ƒæ—¶ä¼šåˆ é™¤å±‚ ï¼ˆkï¼‰ ä¸Šæ ‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The solid vertical line in (b) plots the decision boundary for d that gives the minimum misclassification rate assuming uniform prior for the two target levels (i.e., P(t = l1) = P(t = l2)).",
            "zh": "ï¼ˆbï¼‰ä¸­çš„å‚ç›´å®çº¿ç»˜åˆ¶äº†dçš„å†³ç­–è¾¹ç•Œï¼Œè¯¥è¾¹ç•Œç»™å‡ºäº†æœ€å°è¯¯åˆ†ç±»ç‡ï¼Œå‡è®¾ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„å…ˆéªŒä¸€è‡´ï¼ˆå³Pï¼ˆt = l1ï¼‰ = Pï¼ˆt = l2ï¼‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is evident that the instances are getting farther and farther away from each other, and the feature space is becoming very sparsely populated, with relatively large areas where there are no or very few instances.",
            "zh": "å¾ˆæ˜æ˜¾ï¼Œå®ä¾‹ä¹‹é—´çš„è·ç¦»è¶Šæ¥è¶Šè¿œï¼Œè¦ç´ ç©ºé—´çš„äººå£å˜å¾—éå¸¸ç¨€å°‘ï¼Œæ²¡æœ‰å®ä¾‹æˆ–å®ä¾‹å¾ˆå°‘çš„åŒºåŸŸç›¸å¯¹è¾ƒå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "An unusually large or small value like this is referred to as an outlier, and the arithmetic mean is very sensitive to the presence of outliers.",
            "zh": "åƒè¿™æ ·çš„å¼‚å¸¸å¤§æˆ–å°çš„å€¼ç§°ä¸ºå¼‚å¸¸å€¼ï¼Œç®—æœ¯å¹³å‡å€¼å¯¹å¼‚å¸¸å€¼çš„å­˜åœ¨éå¸¸æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "P_EDGE",
            "zh": "P_EDGE"
        }
    },
    {
        "translation": {
            "en": "An extended version of the generators dataset from Table 7.6[339].",
            "zh": "è¡¨7.6[339]ä¸­ç”Ÿæˆå™¨æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "child node, 286",
            "zh": "å­èŠ‚ç‚¹ï¼Œ286"
        }
    },
    {
        "translation": {
            "en": "SCHOOL YEARS, the mean number years spent in school by adult females",
            "zh": "å­¦é¾„ï¼Œæˆå¹´å¥³æ€§åœ¨æ ¡çš„å¹³å‡å¹´é™"
        }
    },
    {
        "translation": {
            "en": "Although in some applications the target feature is a raw value copied directly from an existing data source, in many others it must be derived.",
            "zh": "å°½ç®¡åœ¨æŸäº›åº”ç”¨ç¨‹åºä¸­ï¼Œç›®æ ‡ç‰¹å¾æ˜¯ç›´æ¥ä»ç°æœ‰æ•°æ®æºå¤åˆ¶çš„åŸå§‹å€¼ï¼Œä½†åœ¨è®¸å¤šå…¶ä»–åº”ç”¨ç¨‹åºä¸­ï¼Œå®ƒå¿…é¡»æ´¾ç”Ÿå‡ºæ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many argue that performing this type of transformation may remove the most interesting and, from a predictive modeling point of view, informative instances from a dataset.",
            "zh": "è®¸å¤šäººè®¤ä¸ºï¼Œæ‰§è¡Œè¿™ç§ç±»å‹çš„è½¬æ¢å¯èƒ½ä¼šä»æ•°æ®é›†ä¸­åˆ é™¤æœ€æœ‰è¶£çš„ï¼Œå¹¶ä¸”ä»é¢„æµ‹å»ºæ¨¡çš„è§’åº¦æ¥çœ‹ï¼Œä¿¡æ¯é‡æœ€å¤§çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout our worked example using the college athlete dataset, the top-right corner of the feature space contained a no region (see Figure 5.4[190]).",
            "zh": "åœ¨æˆ‘ä»¬ä½¿ç”¨å¤§å­¦è¿åŠ¨å‘˜æ•°æ®é›†çš„å·¥ä½œç¤ºä¾‹ä¸­ï¼Œç‰¹å¾ç©ºé—´çš„å³ä¸Šè§’åŒ…å«ä¸€ä¸ª no åŒºåŸŸï¼ˆå‚è§å›¾ 5.4[190]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Capacity for retraining: In Section 9.4.6[578] we discussed approaches that can be used to monitor the performance of a model so as to flag the occurrence of concept drift and indicate if a model has gone stale.",
            "zh": "å†è®­ç»ƒèƒ½åŠ›ï¼šåœ¨ç¬¬ 9.4.6[578] èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¯ç”¨äºç›‘æ§æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ï¼Œä»¥ä¾¿æ ‡è®°æ¦‚å¿µæ¼‚ç§»çš„å‘ç”Ÿå¹¶æŒ‡ç¤ºæ¨¡å‹æ˜¯å¦è¿‡æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "These customers were deemed to be at risk of churning in the coming month, so the customer retention team set about contacting them with a special offer.",
            "zh": "è¿™äº›å®¢æˆ·è¢«è®¤ä¸ºåœ¨ä¸‹ä¸ªæœˆæœ‰æµå¤±çš„é£é™©ï¼Œå› æ­¤å®¢æˆ·ä¿ç•™å›¢é˜Ÿå¼€å§‹ä¸ä»–ä»¬è”ç³»ï¼Œæä¾›ç‰¹åˆ«ä¼˜æƒ ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. The primary papers introducing k-d trees are Bentley (1975) and Friedman et al. (1977). Also note that the k here has no relationship with the k used in k nearest neighbor. It simply specifies the number of levels in the depth of the tree, which is arbitrary and typically determined by the algorithm that constructs the tree.",
            "zh": "8. ä»‹ç»k-dæ ‘çš„ä¸»è¦è®ºæ–‡æ˜¯Bentleyï¼ˆ1975ï¼‰å’ŒFriedmanç­‰äººï¼ˆ1977ï¼‰ã€‚å¦è¯·æ³¨æ„ï¼Œæ­¤å¤„çš„ k ä¸ k æœ€è¿‘é‚»ä¸­ä½¿ç”¨çš„ k æ²¡æœ‰å…³ç³»ã€‚å®ƒåªæ˜¯æŒ‡å®šæ ‘æ·±åº¦ä¸­çš„çº§åˆ«æ•°ï¼Œè¿™æ˜¯ä»»æ„çš„ï¼Œé€šå¸¸ç”±æ„é€ æ ‘çš„ç®—æ³•ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The first thing to consider in regard to data is whether the target feature is continuous or categorical.",
            "zh": "å…³äºæ•°æ®ï¼Œé¦–å…ˆè¦è€ƒè™‘çš„æ˜¯ç›®æ ‡ç‰¹å¾æ˜¯è¿ç»­çš„è¿˜æ˜¯åˆ†ç±»çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, the algorithm tends toward the majority target level in the dataset.",
            "zh": "å› æ­¤ï¼Œè¯¥ç®—æ³•å€¾å‘äºæ•°æ®é›†ä¸­çš„å¤šæ•°ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.106)[509] defines the calculation of the forget mask for time-step t, and Equation (8.107)[509] defines the filtering of the cell state by the forget mask.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.106ï¼‰[509]å®šä¹‰äº†æ—¶é—´æ­¥é•¿tçš„é—å¿˜æ©ç çš„è®¡ç®—ï¼Œç­‰å¼ï¼ˆ8.107ï¼‰[509]å®šä¹‰äº†é—å¿˜æ©ç å¯¹å•å…ƒçŠ¶æ€çš„æ»¤æ³¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.04",
            "zh": "0.04"
        }
    },
    {
        "translation": {
            "en": "Figure 3.1",
            "zh": "å›¾ 3.1"
        }
    },
    {
        "translation": {
            "en": "SPLOM, 74",
            "zh": "æ–¯æ™®æ´›å§†ï¼Œ74"
        }
    },
    {
        "translation": {
            "en": "20.500",
            "zh": "20.500"
        }
    },
    {
        "translation": {
            "en": "Brockman, Greg, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. arXiv:1606.01540.",
            "zh": "å¸ƒç½—å…‹æ›¼ã€æ ¼é›·æ ¼ã€å¼ è–‡çªã€è·¯å¾·ç»´å¸ŒÂ·ä½©ç‰¹æ£®ã€ä¹”çº³æ–¯Â·æ–½è€å¾·ã€çº¦ç¿°Â·èˆ’å°”æ›¼ã€å”æ°å’Œæ²ƒä¼Šåˆ‡èµ«Â·æ‰ä¼¦å·´ã€‚2016. OpenAI å¥èº«æˆ¿ã€‚arXivï¼š1606.01540ã€‚"
        }
    },
    {
        "translation": {
            "en": "It might, at first, seem like all is lost and that it will be impossible for the hiker to find her way down to the bottom of the valley.",
            "zh": "ä¹ä¸€çœ‹ï¼Œä¼¼ä¹ä¸€åˆ‡éƒ½å¤±å»äº†ï¼Œå¾’æ­¥æ—…è¡Œè€…ä¸å¯èƒ½æ‰¾åˆ°é€šå¾€è°·åº•çš„è·¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The consultant generated the following data quality report from the ABT (visualizations of binary features have been omitted for space saving).",
            "zh": "é¡¾é—®ä» ABT ç”Ÿæˆäº†ä»¥ä¸‹æ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆä¸ºäº†èŠ‚çœç©ºé—´ï¼Œçœç•¥äº†äºŒè¿›åˆ¶ç‰¹å¾çš„å¯è§†åŒ–ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. the rate of change of the activation of the neuron with respect to changes in the weighted sum calculated at the neuron: âˆ‚ak/âˆ‚zk.",
            "zh": "2. ç¥ç»å…ƒæ¿€æ´»ç›¸å¯¹äºåœ¨ç¥ç»å…ƒå¤„è®¡ç®—çš„åŠ æƒå’Œå˜åŒ–çš„å˜åŒ–ç‡ï¼šâˆ‚ak/âˆ‚zkã€‚"
        }
    },
    {
        "translation": {
            "en": "Conversely, in batch gradient descent, assuming we process all the training examples in parallel, we complete a single epoch in each iteration of the algorithm and so there is a single weight update per epoch.",
            "zh": "ç›¸åï¼Œåœ¨æ‰¹é‡æ¢¯åº¦ä¸‹é™ä¸­ï¼Œå‡è®¾æˆ‘ä»¬å¹¶è¡Œå¤„ç†æ‰€æœ‰è®­ç»ƒç¤ºä¾‹ï¼Œæˆ‘ä»¬åœ¨ç®—æ³•çš„æ¯æ¬¡è¿­ä»£ä¸­å®Œæˆä¸€ä¸ª epochï¼Œå› æ­¤æ¯ä¸ª epoch éƒ½æœ‰ä¸€ä¸ªæƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A fork in computational flow during forward propagation results in the same activation vector flowing in two directions, with each path generating error gradients that must be merged in the backpropagation stage.",
            "zh": "åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æµçš„åˆ†å‰ä¼šå¯¼è‡´ç›¸åŒçš„æ¿€æ´»å‘é‡åœ¨ä¸¤ä¸ªæ–¹å‘ä¸ŠæµåŠ¨ï¼Œæ¯æ¡è·¯å¾„éƒ½ä¼šäº§ç”Ÿå¿…é¡»åœ¨åå‘ä¼ æ’­é˜¶æ®µåˆå¹¶çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2000. Additive logistic regression: A statistical view of boosting. The Annals of Statistics 28 (2): 337â€“407.",
            "zh": "å¼—é‡Œå¾·æ›¼ã€æ°ç½—å§†ã€ç‰¹é›·å¼—Â·å“ˆæ–¯è’‚å’Œç½—ä¼¯ç‰¹Â·è’‚å¸ƒå¸Œæ‹‰å°¼ã€‚2000. åŠ æ€§é€»è¾‘å›å½’ï¼šæå‡çš„ç»Ÿè®¡è§‚ç‚¹.ç»Ÿè®¡å¹´é‰´28ï¼ˆ2ï¼‰ï¼š337-407ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.6â€…â€…â€…Deployment",
            "zh": "13.6 éƒ¨ç½²"
        }
    },
    {
        "translation": {
            "en": "Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. 2011. Deep sparse rectifier neural networks. In Proceedings of the fourteenth international conference on artificial intelligence and statistics (AISTATS), 315â€“323. JMLR.",
            "zh": "æ ¼æ´›ç½—ç‰¹ã€æ³½ç»´å°”ã€å®‰æ‰˜ä¸‡Â·åšå°”å¾·æ–¯å’Œçº¦ä¹¦äºšÂ·æœ¬å‰å¥¥ã€‚2011. æ·±åº¦ç¨€ç–æ•´æµå™¨ç¥ç»ç½‘ç»œ.ç¬¬åå››å±Šäººå·¥æ™ºèƒ½ä¸ç»Ÿè®¡å›½é™…ä¼šè®®ï¼ˆAISTATSï¼‰è®ºæ–‡é›†ï¼Œç¬¬315-323é¡µã€‚JMLRã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure C.2(d)[767] shows this example function and its derivative calculated using the chain rule.",
            "zh": "å›¾C.2ï¼ˆdï¼‰[767]æ˜¾ç¤ºäº†ä½¿ç”¨é“¾å¼æ³•åˆ™è®¡ç®—çš„ç¤ºä¾‹å‡½æ•°åŠå…¶å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.6",
            "zh": "è¡¨ 8.6"
        }
    },
    {
        "translation": {
            "en": "The data quality report is the most important tool of the data exploration process.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šæ˜¯æ•°æ®æ¢ç´¢è¿‡ç¨‹ä¸­æœ€é‡è¦çš„å·¥å…·ã€‚"
        }
    },
    {
        "translation": {
            "en": "It would most likely be possible to create a model that could distinguish between the clockwise and anti-clockwise spiral galaxies, but this would probably require the calculation of new features based on the application of image processing techniques to the raw galaxy images.",
            "zh": "æœ€æœ‰å¯èƒ½åˆ›å»ºä¸€ä¸ªå¯ä»¥åŒºåˆ†é¡ºæ—¶é’ˆå’Œé€†æ—¶é’ˆèºæ—‹æ˜Ÿç³»çš„æ¨¡å‹ï¼Œä½†è¿™å¯èƒ½éœ€è¦æ ¹æ®å›¾åƒå¤„ç†æŠ€æœ¯å¯¹åŸå§‹æ˜Ÿç³»å›¾åƒçš„åº”ç”¨æ¥è®¡ç®—æ–°ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Different margins that satisfy the constraint in Equation (7.44)[364], the instances that define the margin are highlighted in each case; (b) shows the maximum margin and also shows two query instances represented as black dots.",
            "zh": "æ»¡è¶³ç­‰å¼ï¼ˆ7.44ï¼‰[364]ä¸­çº¦æŸæ¡ä»¶çš„ä¸åŒè¾¹è·ï¼Œå®šä¹‰è¾¹è·çš„å®ä¾‹åœ¨æ¯ç§æƒ…å†µä¸‹éƒ½çªå‡ºæ˜¾ç¤º;ï¼ˆbï¼‰ æ˜¾ç¤ºæœ€å¤§è¾¹è·ï¼Œå¹¶æ˜¾ç¤ºä¸¤ä¸ªè¡¨ç¤ºä¸ºé»‘ç‚¹çš„æŸ¥è¯¢å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Schwartz, Paul M. 2010. Data protection law and the ethical use of analytics, Technical report, The Centre for Information Policy Leadership (at Hunton & Williams LLP).",
            "zh": "æ–½ç“¦èŒ¨ï¼Œä¿ç½— M. 2010 å¹´ã€‚æ•°æ®ä¿æŠ¤æ³•å’Œåˆ†æçš„é“å¾·ä½¿ç”¨ï¼ŒæŠ€æœ¯æŠ¥å‘Šï¼Œä¿¡æ¯æ”¿ç­–é¢†å¯¼ä¸­å¿ƒï¼ˆHunton & Williams LLPï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "D.4â€ƒSummary",
            "zh": "D.4 æ¦‚è¿°"
        }
    },
    {
        "translation": {
            "en": "reinforcement learning, xvi, 5, 20, 637, 638, 674, 740",
            "zh": "å¼ºåŒ–å­¦ä¹ ï¼Œ xviï¼Œ 5ï¼Œ 20ï¼Œ 637ï¼Œ 638ï¼Œ 674ï¼Œ 740"
        }
    },
    {
        "translation": {
            "en": "Similarly, if the gap between the 1st quartile and the minimum value is noticeably larger than the gap between the median and the 1st quartile, this suggests that the minimum value is unusual and is likely to be an outlier.",
            "zh": "åŒæ ·ï¼Œå¦‚æœç¬¬ 1 ä¸ªå››åˆ†ä½æ•°å’Œæœ€å°å€¼ä¹‹é—´çš„å·®è·æ˜æ˜¾å¤§äºä¸­ä½æ•°å’Œç¬¬ 1 ä¸ªå››åˆ†ä½æ•°ä¹‹é—´çš„å·®è·ï¼Œåˆ™è¡¨æ˜æœ€å°å€¼æ˜¯ä¸å¯»å¸¸çš„ï¼Œå¹¶ä¸”å¯èƒ½æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Model ensembles are among the most powerful machine learning algorithms; Caruana and Niculescu-Mizil (2006) report a large-scale comparison between seven different types of prediction model in which bagged and boosted tree ensembles are reported as among the best-performing.",
            "zh": "æ¨¡å‹é›†æˆæ˜¯æœ€å¼ºå¤§çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¹‹ä¸€;Caruanaå’ŒNiculescu-Mizilï¼ˆ2006ï¼‰æŠ¥å‘Šäº†ä¸ƒç§ä¸åŒç±»å‹çš„é¢„æµ‹æ¨¡å‹ä¹‹é—´çš„å¤§è§„æ¨¡æ¯”è¾ƒï¼Œå…¶ä¸­è¢‹è£…å’Œæå‡çš„æ ‘æœ¨é›†åˆè¢«æŠ¥å‘Šä¸ºè¡¨ç°æœ€å¥½çš„æ¨¡å‹ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Where appropriate, conditional independence not only simplifies the calculations but also enables us to compactly represent the full joint probability distribution for a domain. Rather than calculating and storing the probabilities of all the joint events in a domain, we can break up the distribution into data structures called factors, which define distributions over subsets of features. We can then compute any of the probabilities in the joint probability distribution using the product of these factors.",
            "zh": "åœ¨é€‚å½“çš„æƒ…å†µä¸‹ï¼Œæ¡ä»¶ç‹¬ç«‹æ€§ä¸ä»…ç®€åŒ–äº†è®¡ç®—ï¼Œè€Œä¸”ä½¿æˆ‘ä»¬èƒ½å¤Ÿç´§å‡‘åœ°è¡¨ç¤ºåŸŸçš„å®Œæ•´è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥å°†åˆ†å¸ƒåˆ†è§£ä¸ºç§°ä¸ºå› å­çš„æ•°æ®ç»“æ„ï¼Œè€Œä¸æ˜¯è®¡ç®—å’Œå­˜å‚¨åŸŸä¸­æ‰€æœ‰è”åˆäº‹ä»¶çš„æ¦‚ç‡ï¼Œè¿™äº›æ•°æ®ç»“æ„å®šä¹‰ç‰¹å¾å­é›†çš„åˆ†å¸ƒã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›å› å­çš„ä¹˜ç§¯è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­çš„ä»»ä½•æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will see as we proceed through this book that the selection of a machine learning algorithm is not the only way that we can bias the predictive data analytics process.",
            "zh": "åœ¨ç»§ç»­é˜…è¯»æœ¬ä¹¦çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ï¼Œé€‰æ‹©æœºå™¨å­¦ä¹ ç®—æ³•å¹¶ä¸æ˜¯æˆ‘ä»¬åå‘é¢„æµ‹æ•°æ®åˆ†æè¿‡ç¨‹çš„å”¯ä¸€æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "32. See Mitchell (1997, pp. 164â€“167).",
            "zh": "32. å‚è§Mitchellï¼ˆ1997å¹´ï¼Œç¬¬164-167é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Classifying galaxies according to galaxy morphology is standard practice in astronomy,3 and morphological categories have been shown to be strongly correlated with other important galaxy features.",
            "zh": "æ ¹æ®æ˜Ÿç³»å½¢æ€å¯¹æ˜Ÿç³»è¿›è¡Œåˆ†ç±»æ˜¯å¤©æ–‡å­¦çš„æ ‡å‡†åšæ³•ï¼Œ3 å½¢æ€å­¦ç±»åˆ«å·²è¢«è¯æ˜ä¸å…¶ä»–é‡è¦çš„æ˜Ÿç³»ç‰¹å¾å¯†åˆ‡ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we could have used four 500-unit intervals to generate the histogram insteadâ€”see Figure A.7(b)[754], based on frequencies from Table A.4(b)[755]â€”or, indeed, any other set of intervals.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å››ä¸ª 500 å•ä½çš„åŒºé—´æ¥ç”Ÿæˆç›´æ–¹å›¾â€”â€”å‚è§å›¾ A.7ï¼ˆbï¼‰[754]ï¼ŒåŸºäºè¡¨ A.4ï¼ˆbï¼‰[755] ä¸­çš„é¢‘ç‡â€”â€”æˆ–è€…ï¼Œå®é™…ä¸Šï¼Œä»»ä½•å…¶ä»–åŒºé—´é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) A simple approach to adapting a logistic regression model to learn this type of decision boundary is to introduce a set of basis functions that will allow a non-linear decision boundary to be learned. In this case, a set of basis functions that generate a cubic decision boundary will work well. An appropriate set of basis functions is as follows:",
            "zh": "ï¼ˆbï¼‰ è°ƒæ•´é€»è¾‘å›å½’æ¨¡å‹ä»¥å­¦ä¹ è¿™ç§å†³ç­–è¾¹ç•Œçš„ä¸€ç§ç®€å•æ–¹æ³•æ˜¯å¼•å…¥ä¸€ç»„åŸºç¡€å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å°†å…è®¸å­¦ä¹ éçº¿æ€§å†³ç­–è¾¹ç•Œã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸€ç»„ç”Ÿæˆä¸‰æ¬¡å†³ç­–è¾¹ç•Œçš„åŸºå‡½æ•°å°†å¾ˆå¥½åœ°å·¥ä½œã€‚ä¸€ç»„é€‚å½“çš„åŸºå‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 8.31",
            "zh": "å›¾ 8.31"
        }
    },
    {
        "translation": {
            "en": "If the p-value is less than the required significance level, typically 0.05, we reject the null hypothesis and say that the descriptive feature has a significant impact on the model; otherwise we say that it does not.",
            "zh": "å¦‚æœ p å€¼å°äºæ‰€éœ€çš„æ˜¾è‘—æ€§æ°´å¹³ï¼ˆé€šå¸¸ä¸º 0.05ï¼‰ï¼Œåˆ™æˆ‘ä»¬æ‹’ç»åŸå‡è®¾ï¼Œå¹¶è¯´æè¿°æ€§ç‰¹å¾å¯¹æ¨¡å‹æœ‰æ˜¾è‘—å½±å“;å¦åˆ™æˆ‘ä»¬è¯´å®ƒæ²¡æœ‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "27. This question is inspired by the work reported in KlubiÄka et al. (2018).",
            "zh": "27. è¿™ä¸ªé—®é¢˜çš„çµæ„Ÿæ¥è‡ªKlubiÄkaç­‰äººï¼ˆ2018å¹´ï¼‰æŠ¥å‘Šçš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "3. The example given here is based on artificial data generated for the purposes of this book. Performing customer segmentation in this way, however, is very common (see, for example, Berry and Linoff (2004)).",
            "zh": "3. è¿™é‡Œç»™å‡ºçš„ä¾‹å­æ˜¯åŸºäºä¸ºæœ¬ä¹¦çš„ç›®çš„è€Œç”Ÿæˆçš„äººå·¥æ•°æ®ã€‚ç„¶è€Œï¼Œä»¥è¿™ç§æ–¹å¼è¿›è¡Œå®¢æˆ·ç»†åˆ†æ˜¯å¾ˆå¸¸è§çš„ï¼ˆä¾‹å¦‚ï¼Œå‚è§Berry and Linoff ï¼ˆ2004ï¼‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "OCCUPATION (transport = works in the transportation industry; professional = doctor, lawyer, or similar; agriculture = works in the agricultural industry; armed forces = is a member of the armed forces); and",
            "zh": "èŒä¸šï¼ˆè¿è¾“=è¿è¾“ä¸šå·¥ä½œ;ä¸“ä¸š=åŒ»ç”Ÿã€å¾‹å¸ˆæˆ–ç±»ä¼¼è¡Œä¸š;å†œä¸š=å†œä¸šå·¥ä½œ;æ­¦è£…éƒ¨é˜Ÿ=æ˜¯æ­¦è£…éƒ¨é˜Ÿæˆå‘˜ï¼‰;å’Œ"
        }
    },
    {
        "translation": {
            "en": "This is the standard calculation we would use to calculate the Î´ for any hidden neuron, see Equation (8.23)[412], with the slight simplification that, as mentioned previously, the gradient of the activation function âˆ‚ac/âˆ‚zC = 1. We calculate the Î´s for the other neurons in the sub-sampling layer in a similar fashion.",
            "zh": "è¿™æ˜¯æˆ‘ä»¬ç”¨æ¥è®¡ç®—ä»»ä½•éšè—ç¥ç»å…ƒÎ´çš„æ ‡å‡†è®¡ç®—ï¼Œå‚è§æ–¹ç¨‹ï¼ˆ8.23ï¼‰[412]ï¼Œå¦‚å‰æ‰€è¿°ï¼Œç¨å¾®ç®€åŒ–ä¸ºæ¿€æ´»å‡½æ•°çš„æ¢¯åº¦âˆ‚ac/âˆ‚zC = 1ã€‚æˆ‘ä»¬ä»¥ç±»ä¼¼çš„æ–¹å¼è®¡ç®—å­é‡‡æ ·å±‚ä¸­å…¶ä»–ç¥ç»å…ƒçš„Î´sã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The precision, recall, and F1 measure",
            "zh": "ï¼ˆcï¼‰ ç²¾åº¦ã€å¬å›ç‡å’Œ F1 æµ‹é‡å€¼"
        }
    },
    {
        "translation": {
            "en": "K-S chart, 563",
            "zh": "K-S å›¾è¡¨ï¼Œ563"
        }
    },
    {
        "translation": {
            "en": "4. The following diagram shows a decision tree for the task of predicting heart disease.39 The descriptive features in this domain describe whether the patient suffers from chest pain (CHEST PAIN) and the blood pressure of the patient (BLOOD PRESSURE). The binary target feature is HEART DISEASE. The table beside the diagram lists a pruning set from this domain.",
            "zh": "4. ä¸‹å›¾æ˜¾ç¤ºäº†é¢„æµ‹å¿ƒè„ç—…ä»»åŠ¡çš„å†³ç­–æ ‘.39 è¯¥é¢†åŸŸçš„æè¿°æ€§ç‰¹å¾æè¿°äº†æ‚£è€…æ˜¯å¦æ‚£æœ‰èƒ¸ç—› ï¼ˆCHEST PAINï¼‰ å’Œæ‚£è€…çš„è¡€å‹ ï¼ˆBLOOD PRESSUREï¼‰ã€‚äºŒå…ƒç›®æ ‡ç‰¹å¾æ˜¯ HEART DISEASEã€‚å›¾æ—è¾¹çš„è¡¨æ ¼åˆ—å‡ºäº†æ­¤åŸŸä¸­çš„ä¿®å‰ªé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning as a single-step process.",
            "zh": "æ— ç›‘ç£æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªå•æ­¥è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.2â€…â€…â€…Hold-out sampling can divide the full data into training, validation, and test sets.",
            "zh": "9.2 ä¿æŒæŠ½æ ·å¯ä»¥å°†å®Œæ•´æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "After watching the dealer play 30 games with other players, you notice that he has a tendency to drop the queen in the position on the right (19 times) more than the left (3 times) or center (8 times). Based on this, you update your beliefs about where the queen is likely to land based on the evidence that you have collected. This is shown in Figure 6.1(d)[244], where the bars have been redistributed to illustrate the revised likelihoods.",
            "zh": "åœ¨è§‚çœ‹åº„å®¶ä¸å…¶ä»–ç©å®¶ç© 30 åœºæ¯”èµ›åï¼Œæ‚¨æ³¨æ„åˆ°ä»–å€¾å‘äºå°†çš‡åæ”¾åœ¨å³ä¾§ä½ç½®ï¼ˆ19 æ¬¡ï¼‰è€Œä¸æ˜¯å·¦ä¾§ï¼ˆ3 æ¬¡ï¼‰æˆ–ä¸­é—´ï¼ˆ8 æ¬¡ï¼‰ã€‚åŸºäºæ­¤ï¼Œä½ æ ¹æ®ä½ æ”¶é›†çš„è¯æ®æ›´æ–°äº†ä½ å¯¹å¥³ç‹å¯èƒ½é™è½åœ°ç‚¹çš„ä¿¡å¿µã€‚å¦‚å›¾6.1ï¼ˆdï¼‰[244]æ‰€ç¤ºï¼Œå…¶ä¸­æ¡å½¢å›¾å·²é‡æ–°åˆ†å¸ƒï¼Œä»¥è¯´æ˜ä¿®è®¢åçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Samet (1990) gives an introduction to r-trees and other related approaches.",
            "zh": "Sametï¼ˆ1990ï¼‰ä»‹ç»äº†ræ ‘å’Œå…¶ä»–ç›¸å…³æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.13(b)[90] there are 14 bins.",
            "zh": "åœ¨å›¾3.13ï¼ˆbï¼‰[90]ä¸­ï¼Œæœ‰14ä¸ªç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "From this plot we can get a concise, but detailed, description of the feature and notice the inclusion of an outlier value.",
            "zh": "ä»æ­¤å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªç®€æ´ä½†è¯¦ç»†çš„ç‰¹å¾æè¿°ï¼Œå¹¶æ³¨æ„åˆ°åŒ…å«ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Hand and Anagnostopoulos (2013) discusses issues with the use of the ROC index.",
            "zh": "ä¾‹å¦‚ï¼ŒHand and Anagnostopoulos ï¼ˆ2013ï¼‰ è®¨è®ºäº†ä½¿ç”¨ ROC æŒ‡æ•°çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In upcoming chapters we use normalization to prepare data for use with machine learning algorithms that require descriptive features to be in particular ranges. As is so often the case in data analytics, there is no hard and fast rule that says which is the best normalization technique, and this decision is generally made based on experimentation.",
            "zh": "åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å½’ä¸€åŒ–æ¥å‡†å¤‡æ•°æ®ï¼Œä»¥ä¾¿ä¸æœºå™¨å­¦ä¹ ç®—æ³•ä¸€èµ·ä½¿ç”¨ï¼Œè¿™äº›ç®—æ³•è¦æ±‚æè¿°æ€§ç‰¹å¾åœ¨ç‰¹å®šèŒƒå›´å†…ã€‚æ­£å¦‚æ•°æ®åˆ†æä¸­ç»å¸¸å‡ºç°çš„æƒ…å†µä¸€æ ·ï¼Œæ²¡æœ‰ç¡¬æ€§è§„å®šå“ªç§æ˜¯æœ€å¥½çš„å½’ä¸€åŒ–æŠ€æœ¯ï¼Œå¹¶ä¸”é€šå¸¸æ ¹æ®å®éªŒåšå‡ºæ­¤å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.4â€ƒBayesian Networks",
            "zh": "6.4.4 è´å¶æ–¯ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "18. The featuresselected were AE_I, APERFLUX7IVAR_R, CMODELFLUXIVAR_U, DEVABERR_G, DEVABERR_Z, DEVAB_G, DEVAB_I, DEVFLUXIVAR_U, DEVMAGERR_U, DEVRAD_G, DEVRAD_U, DEREDDIFF_U_G, EXPABERR_U, EXPAB_G, EXPMAG_Z, EXPRADERR_U, FIBER2FLUXIVAR_R, FIBER2MAG_I, FIBERFLUXIVAR_G, FIBERFLUX_G, FIBERFLUX_R, FIBERFLUX_Z, LNLDEV_R, MCR4_Z, ME1E1ERR_Z, ME1_U, MODELMAGDIFF_R_I, PETROMAGDIFF_R_I, PETROR90_R, PSFMAG_U, SKYIVAR_U, and U_R.",
            "zh": "18. é€‰æ‹©çš„ç‰¹å¾æ˜¯AE_Iã€APERFLUX7IVAR_Rã€CMODELFLUXIVAR_Uã€DEVABERR_Gã€DEVABERR_Zã€DEVAB_Gã€DEVAB_Iã€DEVFLUXIVAR_Uã€DEVMAGERR_Uã€DEVRAD_Gã€DEVRAD_Uã€DEREDDIFF_U_Gã€EXPABERR_Uã€EXPAB_Gã€EXPMAG_Zã€EXPRADERR_Uã€FIBER2FLUXIVAR_Rã€FIBER2MAG_Iã€FIBERFLUXIVAR_Gã€FIBERFLUX_Gã€FIBERFLUX_Rã€FIBERFLUX_Zã€LNLDEV_Rã€MCR4_Zã€ME1E1ERR_Zã€ME1_Uã€ MODELMAGDIFF_R_Iã€PETROMAGDIFF_R_Iã€PETROR90_Rã€PSFMAG_Uã€SKYIVAR_Uå’ŒU_Rã€‚"
        }
    },
    {
        "translation": {
            "en": "16. It is also common to use a minimum partition variance as an early stopping criterion. If the variance in the partition being processed is below a set threshold, then the algorithm will not partition the data and will instead create a leaf node.",
            "zh": "16. ä½¿ç”¨æœ€å°åˆ†åŒºæ–¹å·®ä½œä¸ºæ—©æœŸåœæ­¢æ ‡å‡†ä¹Ÿå¾ˆå¸¸è§ã€‚å¦‚æœæ­£åœ¨å¤„ç†çš„åˆ†åŒºä¸­çš„æ–¹å·®ä½äºè®¾å®šçš„é˜ˆå€¼ï¼Œåˆ™ç®—æ³•ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œåˆ†åŒºï¼Œè€Œæ˜¯åˆ›å»ºå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tijms, Henk. 2012. Understanding probability. Cambridge University Press.",
            "zh": "è’‚å§†æ–¯ï¼Œäº¨å…‹ã€‚2012. ç†è§£æ¦‚ç‡.å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "batches, 391, 417",
            "zh": "æ‰¹æ¬¡ï¼Œ391,417"
        }
    },
    {
        "translation": {
            "en": "These tell us the most common levels within these features and will identify if any levels dominate the dataset (these levels will have a very high mode %).",
            "zh": "è¿™äº›å‘Šè¯‰æˆ‘ä»¬è¿™äº›ç‰¹å¾ä¸­æœ€å¸¸è§çš„çº§åˆ«ï¼Œå¹¶å°†ç¡®å®šæ˜¯å¦æœ‰ä»»ä½•çº§åˆ«åœ¨æ•°æ®é›†ä¸­å ä¸»å¯¼åœ°ä½ï¼ˆè¿™äº›çº§åˆ«å°†å…·æœ‰éå¸¸é«˜çš„æ¨¡å¼%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the early part of this chapter, we focus on categorical features, but we return to continuous features in Section 6.4[265].",
            "zh": "åœ¨æœ¬ç« çš„å¼€å¤´éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¸“æ³¨äºåˆ†ç±»ç‰¹å¾ï¼Œä½†æˆ‘ä»¬å›åˆ°äº†ç¬¬ 6.4 èŠ‚ä¸­çš„è¿ç»­ç‰¹å¾[265]ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the biggest challenges in training a deep neural network is to ensure that the flow of error gradients back through the layers of a network is stable during training.",
            "zh": "è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„æœ€å¤§æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ç¡®ä¿åœ¨è®­ç»ƒæœŸé—´ï¼Œé€šè¿‡ç½‘ç»œå±‚çš„è¯¯å·®æ¢¯åº¦æµæ˜¯ç¨³å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the error value at this point in the weight space can be calculated, we know little else about the relative position of this point on the error surface.",
            "zh": "è™½ç„¶å¯ä»¥è®¡ç®—å‡ºæƒé‡ç©ºé—´ä¸­è¯¥ç‚¹çš„è¯¯å·®å€¼ï¼Œä½†æˆ‘ä»¬å¯¹è¿™ä¸ªç‚¹åœ¨è¯¯å·®æ›²é¢ä¸Šçš„ç›¸å¯¹ä½ç½®çŸ¥ä¹‹ç”šå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "maximum likelihood, 301",
            "zh": "æœ€å¤§ä¼¼ç„¶ï¼Œ301"
        }
    },
    {
        "translation": {
            "en": "2.3.1â€ƒCase Study: Motor Insurance Fraud",
            "zh": "2.3.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Another way to make models robust to outliers is to train the models to predict only the sign of the errors of the previous predictions rather than the magnitudes of the errors; this is a frequently used adjustment.",
            "zh": "ä½¿æ¨¡å‹å¯¹å¼‚å¸¸å€¼å…·æœ‰é²æ£’æ€§çš„å¦ä¸€ç§æ–¹æ³•æ˜¯è®­ç»ƒæ¨¡å‹ä»…é¢„æµ‹å…ˆå‰é¢„æµ‹çš„è¯¯å·®ç¬¦å·ï¼Œè€Œä¸æ˜¯è¯¯å·®çš„å¤§å°;è¿™æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„è°ƒæ•´ã€‚"
        }
    },
    {
        "translation": {
            "en": "They generally work very well on data that has a grid-like structure and in which the low-level features in the data have a local extent.",
            "zh": "å®ƒä»¬é€šå¸¸é€‚ç”¨äºå…·æœ‰ç½‘æ ¼çŠ¶ç»“æ„çš„æ•°æ®ï¼Œå¹¶ä¸”æ•°æ®ä¸­çš„ä½çº§è¦ç´ å…·æœ‰å±€éƒ¨èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this case would be the level of blood-thinning desired, demographic details for the patient, and the results of various medical tests performed on the patient.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæè¿°æ€§ç‰¹å¾æ˜¯æ‰€éœ€çš„è¡€æ¶²ç¨€é‡Šæ°´å¹³ã€æ‚£è€…çš„äººå£ç»Ÿè®¡å­¦è¯¦ç»†ä¿¡æ¯ä»¥åŠå¯¹æ‚£è€…è¿›è¡Œçš„å„ç§åŒ»å­¦æ£€æŸ¥çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "loss given default, 554",
            "zh": "è¿çº¦æŸå¤±ï¼Œ554"
        }
    },
    {
        "translation": {
            "en": "30.59",
            "zh": "30.59"
        }
    },
    {
        "translation": {
            "en": "Next we calculate âˆ‚â„°/âˆ‚ct.",
            "zh": "æ¥ä¸‹æ¥æˆ‘ä»¬è®¡ç®— âˆ‚E/âˆ‚ctã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that di doesnâ€™t really belong to the cluster in which it has been placed.",
            "zh": "è¿™æ„å‘³ç€ di å®é™…ä¸Šå¹¶ä¸å±äºæ”¾ç½®å®ƒçš„é›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Overall the Euclidean distance weights features with larger differences in values more than features with smaller differences in values.",
            "zh": "æ€»ä½“è€Œè¨€ï¼Œæ¬§å‡ é‡Œå¾—è·ç¦»å¯¹å€¼å·®å¼‚è¾ƒå¤§çš„ç‰¹å¾è¿›è¡ŒåŠ æƒï¼Œå¯¹å€¼å·®å¼‚è¾ƒå¤§çš„ç‰¹å¾è¿›è¡ŒåŠ æƒã€‚"
        }
    },
    {
        "translation": {
            "en": "AGE: The age of the person screened.",
            "zh": "å¹´é¾„ï¼šè¢«ç­›æŸ¥è€…çš„å¹´é¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Part V of the book contains appendices covering background material required to support the content of the other chapters of the book. This includes descriptive statistics and data visualization (Appendix A), probability (Appendix B), differentiation (Appendix C), and linear algebra (Appendix D).",
            "zh": "æœ¬ä¹¦çš„ç¬¬äº”éƒ¨åˆ†åŒ…å«é™„å½•ï¼Œæ¶µç›–äº†æ”¯æŒæœ¬ä¹¦å…¶ä»–ç« èŠ‚å†…å®¹æ‰€éœ€çš„èƒŒæ™¯ææ–™ã€‚è¿™åŒ…æ‹¬æè¿°æ€§ç»Ÿè®¡å’Œæ•°æ®å¯è§†åŒ–ï¼ˆé™„å½• Aï¼‰ã€æ¦‚ç‡ï¼ˆé™„å½• Bï¼‰ã€å¾®åˆ†ï¼ˆé™„å½• Cï¼‰å’Œçº¿æ€§ä»£æ•°ï¼ˆé™„å½• Dï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.5012",
            "zh": "0.5012"
        }
    },
    {
        "translation": {
            "en": "All the values of acceleration have been calculated in this way.",
            "zh": "æ‰€æœ‰åŠ é€Ÿåº¦å€¼éƒ½æ˜¯ä»¥è¿™ç§æ–¹å¼è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "data exploration, 34, 53, 94",
            "zh": "æ•°æ®æ¢ç´¢ï¼Œ 34ï¼Œ 53ï¼Œ 94"
        }
    },
    {
        "translation": {
            "en": "The final example of a data quality issue due to an irregular cardinality is when a categorical feature simply has a very high number of levelsâ€”anything over 50 is worth investigation.",
            "zh": "ç”±äºä¸è§„åˆ™åŸºæ•°å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜çš„æœ€åä¸€ä¸ªä¾‹å­æ˜¯ï¼Œå½“åˆ†ç±»ç‰¹å¾å…·æœ‰éå¸¸é«˜çš„çº§åˆ«æ•°æ—¶ï¼Œä»»ä½•è¶…è¿‡ 50 çš„çº§åˆ«éƒ½å€¼å¾—è°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sutton, Richard S., and Andrew G. Barto. 1998. Reinforcement learning: An introduction. MIT Press.",
            "zh": "è¨é¡¿ã€ç†æŸ¥å¾· S. å’Œå®‰å¾·é² G. å·´æ‰˜ã€‚1998. å¼ºåŒ–å­¦ä¹ ï¼šç®€ä»‹.éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This section covers a selection of the most important performance measures. We also describe different experimental designs for evaluating prediction models and ways to monitor model performance after a model has been deployed.",
            "zh": "æœ¬èŠ‚ä»‹ç»ä¸€äº›æœ€é‡è¦çš„ç»©æ•ˆæŒ‡æ ‡ã€‚æˆ‘ä»¬è¿˜æè¿°äº†ç”¨äºè¯„ä¼°é¢„æµ‹æ¨¡å‹çš„ä¸åŒå®éªŒè®¾è®¡ï¼Œä»¥åŠåœ¨éƒ¨ç½²æ¨¡å‹åç›‘æ§æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.7â€…â€…â€…The details of a professional basketball team.",
            "zh": "3.7 èŒä¸šç¯®çƒé˜Ÿçš„ç»†èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Stewart, James. 2012. Calculus, 7th ed. Cengage Learning.",
            "zh": "æ–¯å›¾å°”ç‰¹ï¼Œè©¹å§†æ–¯ã€‚2012. å¾®ç§¯åˆ†ï¼Œç¬¬ 7 ç‰ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "We refer to measures of similarity of this type as indexes.",
            "zh": "æˆ‘ä»¬å°†è¿™ç§ç±»å‹çš„ç›¸ä¼¼åº¦é‡ç§°ä¸ºç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelynâ€™s first step in fully understanding the data available to her was to define the prediction subject.",
            "zh": "Jocelyn å……åˆ†äº†è§£å¥¹å¯ç”¨çš„æ•°æ®çš„ç¬¬ä¸€æ­¥æ˜¯å®šä¹‰é¢„æµ‹ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.3)[386] defines how the McCulloch and Pitts neuron, or perceptron network, maps an input vector to an output activation.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.3ï¼‰[386]å®šä¹‰äº†McCullochå’ŒPittsç¥ç»å…ƒæˆ–æ„ŸçŸ¥å™¨ç½‘ç»œå¦‚ä½•å°†è¾“å…¥å‘é‡æ˜ å°„åˆ°è¾“å‡ºæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are no fixed recommendations for how large the different datasets should be when hold-out sampling is used, although training:validation:test splits of 50:20:30 or 40:20:40 are common.",
            "zh": "å¯¹äºä½¿ç”¨ä¿æŒæŠ½æ ·æ—¶ä¸åŒæ•°æ®é›†çš„å¤§å°ï¼Œæ²¡æœ‰å›ºå®šçš„å»ºè®®ï¼Œå°½ç®¡ 50ï¼š20ï¼š30 æˆ– 40ï¼š20ï¼š40 çš„ trainingï¼švalidationï¼štest æ‹†åˆ†å¾ˆå¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "This meant that the data available at the SDSS did not contain a suitable target feature that Jocelyn could use to train prediction models.",
            "zh": "è¿™æ„å‘³ç€ SDSS ä¸Šå¯ç”¨çš„æ•°æ®ä¸åŒ…å« Jocelyn å¯ç”¨äºè®­ç»ƒé¢„æµ‹æ¨¡å‹çš„åˆé€‚ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, knowing that there is an eye in the top-left region of an image is useful for face recognition, but the extra precision of knowing that it is centered at pixel (998,742) may not be useful.",
            "zh": "ä¾‹å¦‚ï¼ŒçŸ¥é“å›¾åƒçš„å·¦ä¸Šè§’åŒºåŸŸæœ‰ä¸€åªçœ¼ç›å¯¹äºé¢éƒ¨è¯†åˆ«å¾ˆæœ‰ç”¨ï¼Œä½†çŸ¥é“å®ƒä»¥åƒç´  ï¼ˆ998,742ï¼‰ ä¸ºä¸­å¿ƒçš„é¢å¤–ç²¾åº¦å¯èƒ½æ²¡æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The LOAN AMOUNT continuous feature discretized into four equal-frequency bins.",
            "zh": "LOAN AMOUNT è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºå››ä¸ªç­‰é¢‘ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "18. This guided search process is similar to the gradient descent search we use to fit our regression models in Chapter 7[311]. Many data analytics packages and programming APIs provide functions that implement methods to fit a distribution to a dataset.",
            "zh": "18. è¿™ç§å¼•å¯¼å¼æœç´¢è¿‡ç¨‹ç±»ä¼¼äºæˆ‘ä»¬åœ¨ç¬¬ 7 ç« [311] ä¸­ç”¨äºæ‹Ÿåˆå›å½’æ¨¡å‹çš„æ¢¯åº¦ä¸‹é™æœç´¢ã€‚è®¸å¤šæ•°æ®åˆ†æåŒ…å’Œç¼–ç¨‹ API éƒ½æä¾›å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å®ç°å°†åˆ†å¸ƒæ‹Ÿåˆåˆ°æ•°æ®é›†çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) There is a cost associated with each item presented to the human annotator, and the company wants to maximize the number of items that end up in the dictionary.",
            "zh": "ï¼ˆbï¼‰ å‘ˆç°ç»™äººå·¥æ³¨é‡Šå‘˜çš„æ¯ä¸ªé¡¹ç›®éƒ½æœ‰ç›¸å…³çš„æˆæœ¬ï¼Œå…¬å¸å¸Œæœ›æœ€å¤§é™åº¦åœ°å¢åŠ æœ€ç»ˆå‡ºç°åœ¨å­—å…¸ä¸­çš„é¡¹ç›®æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.20â€…â€…â€…The expected target values for a test set, the predictions made by a model, and the resulting errors based on these predictions for a blood-thinning drug dosage prediction problem.",
            "zh": "9.20 æµ‹è¯•é›†çš„é¢„æœŸç›®æ ‡å€¼ã€æ¨¡å‹çš„é¢„æµ‹ä»¥åŠåŸºäºè¿™äº›é¢„æµ‹å¾—å‡ºçš„è¡€æ¶²ç¨€é‡Šè¯ç‰©å‰‚é‡é¢„æµ‹é—®é¢˜çš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is in contrast to Q-learning, which always assumes the action with the highest expected return will be chosen when computing the update.",
            "zh": "è¿™ä¸Q-learningå½¢æˆé²œæ˜å¯¹æ¯”ï¼ŒQ-learningåœ¨è®¡ç®—æ›´æ–°æ—¶æ€»æ˜¯å‡è®¾å°†é€‰æ‹©å…·æœ‰æœ€é«˜é¢„æœŸå›æŠ¥çš„æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "As such, the prediction for the query instance should be yes.",
            "zh": "å› æ­¤ï¼ŒæŸ¥è¯¢å®ä¾‹çš„é¢„æµ‹åº”ä¸º yesã€‚"
        }
    },
    {
        "translation": {
            "en": "11.4.1â€…â€…â€…SARSA, On-Policy Temporal-Difference Learning",
            "zh": "11.4.1 SARSAï¼Œæ”¿ç­–æ—¶é—´å·®å¼‚å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "EXPRAD_U/G/R/I/Z",
            "zh": "EXPRAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The number of retention offers the customer has accepted",
            "zh": "å®¢æˆ·å·²æ¥å—çš„ä¿ç•™äº§å“/æœåŠ¡æ•°"
        }
    },
    {
        "translation": {
            "en": "Also, Neuron B is a ReLU and so âˆ‚aB/âˆ‚zB = 1 because aB > 0",
            "zh": "æ­¤å¤–ï¼Œç¥ç»å…ƒ B æ˜¯ ReLUï¼Œå› æ­¤ âˆ‚aB/âˆ‚zB = 1ï¼Œå› ä¸º aB > 0"
        }
    },
    {
        "translation": {
            "en": "data-driven decisions, 19",
            "zh": "æ•°æ®é©±åŠ¨å‹å†³ç­–ï¼Œ19"
        }
    },
    {
        "translation": {
            "en": "The distance between each of these single-instance clusters is then calculated (in this example Euclidean distance is used).",
            "zh": "ç„¶åè®¡ç®—æ¯ä¸ªå•å®ä¾‹é›†ç¾¤ä¹‹é—´çš„è·ç¦»ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "marginalization, 761",
            "zh": "è¾¹ç¼˜åŒ–ï¼Œ761"
        }
    },
    {
        "translation": {
            "en": "At their first attempt, new surfers will typically position themselves either too far forward or too far backward on their board when they attempt to catch their first wave, resulting in a bad outcome.",
            "zh": "åœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶ï¼Œæ–°å†²æµªè€…åœ¨å°è¯•æ•æ‰ç¬¬ä¸€æ³¢å†²æµªæ—¶ï¼Œé€šå¸¸ä¼šå°†è‡ªå·±çš„ä½ç½®æ”¾åœ¨æ¿ä¸Šå¤ªé å‰æˆ–å¤ªé åï¼Œä»è€Œå¯¼è‡´ç³Ÿç³•çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "The dashed lines on either side of the decision boundary show the extent of the margin, and we refer to these as the margin extents.",
            "zh": "å†³ç­–è¾¹ç•Œä¸¤ä¾§çš„è™šçº¿è¡¨ç¤ºè¾¹è·èŒƒå›´ï¼Œæˆ‘ä»¬å°†è¿™äº›è™šçº¿ç§°ä¸ºè¾¹è·èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "False Negative (FN): an instance in the test set that had a positive target feature value but that was predicted to have a negative target feature value",
            "zh": "å‡é˜´æ€§ ï¼ˆFNï¼‰ï¼šæµ‹è¯•é›†ä¸­å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼ä½†é¢„æµ‹å…·æœ‰è´Ÿç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "Consequently, the performance of the model on the test set is a better measure of how the model is likely to perform when actually deployed and shows how well the model can generalize beyond the instances used to train it.",
            "zh": "å› æ­¤ï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½å¯ä»¥æ›´å¥½åœ°è¡¡é‡æ¨¡å‹åœ¨å®é™…éƒ¨ç½²æ—¶å¯èƒ½æ‰§è¡Œçš„æ€§èƒ½ï¼Œå¹¶æ˜¾ç¤ºæ¨¡å‹åœ¨ç”¨äºè®­ç»ƒå®ƒçš„å®ä¾‹ä¹‹å¤–çš„æ³›åŒ–ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This deviation from the norm was investigated with the business, and it turned out that although these figures were correct, this policy was actually a company policy rather than an individual policy, which was included in the ABT by mistake.",
            "zh": "ä¸ä¼ä¸šä¸€èµ·è°ƒæŸ¥äº†è¿™ç§åç¦»è§„èŒƒçš„æƒ…å†µï¼Œç»“æœå‘ç°ï¼Œå°½ç®¡è¿™äº›æ•°å­—æ˜¯æ­£ç¡®çš„ï¼Œä½†è¯¥æ”¿ç­–å®é™…ä¸Šæ˜¯å…¬å¸æ”¿ç­–è€Œä¸æ˜¯ä¸ªäººæ”¿ç­–ï¼Œé”™è¯¯åœ°åŒ…å«åœ¨ ABT ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final vegetation classification decision tree.",
            "zh": "æœ€ç»ˆçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "CART, 169",
            "zh": "æ‰‹æ¨è½¦ï¼Œ 169"
        }
    },
    {
        "translation": {
            "en": "8.3â€…â€…â€…Standard Approach: Backpropagation and Gradient Descent",
            "zh": "8.3 æ ‡å‡†æ–¹æ³•ï¼šåå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™"
        }
    },
    {
        "translation": {
            "en": "AHC, 618",
            "zh": "AHCï¼Œ618"
        }
    },
    {
        "translation": {
            "en": "NEURON",
            "zh": "ç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "Reward is often delayed, and the real value of an action is not reflected immediately but rather by the fact that an action takes us toward a later state that will ultimately allow an agent to earn a reward.",
            "zh": "å¥–åŠ±ç»å¸¸è¢«å»¶è¿Ÿï¼Œä¸€ä¸ªè¡ŒåŠ¨çš„çœŸæ­£ä»·å€¼ä¸ä¼šç«‹å³åæ˜ å‡ºæ¥ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªè¡ŒåŠ¨å°†æˆ‘ä»¬å¸¦å…¥ä¸€ä¸ªæœ€ç»ˆå…è®¸ä»£ç†äººè·å¾—å¥–åŠ±çš„åæœŸçŠ¶æ€è¿™ä¸€äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other unsupervised machine learning use case covered in this chapter was representation learning.",
            "zh": "æœ¬ç« ä»‹ç»çš„å¦ä¸€ä¸ªæ— ç›‘ç£æœºå™¨å­¦ä¹ ç”¨ä¾‹æ˜¯è¡¨ç¤ºå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate a series of similarity indexes for binary descriptive features, we will use an example of predicting upsell in an online service.",
            "zh": "ä¸ºäº†è¯´æ˜äºŒè¿›åˆ¶æè¿°æ€§ç‰¹å¾çš„ä¸€ç³»åˆ—ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé¢„æµ‹åœ¨çº¿æœåŠ¡ä¸­çš„è¿½åŠ é”€å”®çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the training sample covered a period in the summer and the testing sample covered a period in the winter, the results of any evaluation would not provide a reliable measure of how likely the model might actually perform when deployed.",
            "zh": "å¦‚æœè®­ç»ƒæ ·æœ¬è¦†ç›–äº†å¤å­£çš„ä¸€æ®µæ—¶é—´ï¼Œè€Œæµ‹è¯•æ ·æœ¬è¦†ç›–äº†å†¬å­£çš„ä¸€æ®µæ—¶é—´ï¼Œåˆ™ä»»ä½•è¯„ä¼°çš„ç»“æœéƒ½æ— æ³•å¯é åœ°è¡¡é‡æ¨¡å‹åœ¨éƒ¨ç½²æ—¶å®é™…æ‰§è¡Œçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Today some deep networks have tens or even hundreds of layers.",
            "zh": "ä»Šå¤©ï¼Œä¸€äº›æ·±åº¦ç½‘ç»œæœ‰å‡ åå±‚ç”šè‡³å‡ ç™¾å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is similar to the way we summed the weight updates for a weight during batch training (see Equation (8.30)[416]); the difference here is that for each training example we sum over the weight updates for each neuron that uses the weight (as opposed to weight updates for different training examples).",
            "zh": "è¿™ç±»ä¼¼äºæˆ‘ä»¬åœ¨æ‰¹é‡è®­ç»ƒæœŸé—´å¯¹æƒé‡æ›´æ–°è¿›è¡Œæƒé‡æ›´æ–°æ±‚å’Œçš„æ–¹å¼ï¼ˆå‚è§å…¬å¼ï¼ˆ8.30ï¼‰[416]ï¼‰;è¿™é‡Œçš„åŒºåˆ«åœ¨äºï¼Œå¯¹äºæ¯ä¸ªè®­ç»ƒç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æƒé‡çš„æ¯ä¸ªç¥ç»å…ƒçš„æƒé‡æ›´æ–°ç›¸åŠ ï¼ˆè€Œä¸æ˜¯ä¸åŒè®­ç»ƒç¤ºä¾‹çš„æƒé‡æ›´æ–°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, though, a range of ways in which models can be incorrect, and different analytics projects will emphasize some over others.",
            "zh": "ä½†æ˜¯ï¼Œæ¨¡å‹å¯èƒ½ä»¥å¤šç§æ–¹å¼ä¸æ­£ç¡®ï¼Œä¸åŒçš„åˆ†æé¡¹ç›®ä¼šå¼ºè°ƒæŸäº›æ–¹æ³•è€Œä¸æ˜¯å…¶ä»–æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.12",
            "zh": "è¡¨ 6.12"
        }
    },
    {
        "translation": {
            "en": "The second term in the product in Equation (8.72)[467] is the rate of change of the predicted probability for the true category with respect to the logit for one of the neurons in the softmax layer.",
            "zh": "ç­‰å¼ï¼ˆ8.72ï¼‰[467]ä¸­ä¹˜ç§¯ä¸­çš„ç¬¬äºŒé¡¹æ˜¯çœŸå®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ç›¸å¯¹äºsoftmaxå±‚ä¸­ä¸€ä¸ªç¥ç»å…ƒçš„logitçš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example we assume that the hidden neurons and the output layer are ReLUs.",
            "zh": "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å‡è®¾éšè—çš„ç¥ç»å…ƒå’Œè¾“å‡ºå±‚æ˜¯ReLUã€‚"
        }
    },
    {
        "translation": {
            "en": "Histograms of two unimodal datasets: (a) the distribution has light tails; and (b) the distribution has fat tails.",
            "zh": "ä¸¤ä¸ªå•å³°æ•°æ®é›†çš„ç›´æ–¹å›¾ï¼šï¼ˆaï¼‰åˆ†å¸ƒæœ‰å…‰å°¾;ï¼ˆbï¼‰åˆ†å¸ƒæœ‰è‚¥å°¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Simulate taking the action that the agent selected in Part (b) and determine the state that the agent will move to following this action and the reward that they will receive. (Note: If cards need to be dealt to the player or dealer, use cards from the list given at the beginning of this question.)",
            "zh": "ï¼ˆcï¼‰ æ¨¡æ‹Ÿé‡‡å–ä»£ç†äººåœ¨ï¼ˆbï¼‰éƒ¨åˆ†ä¸­é€‰æ‹©çš„è¡ŒåŠ¨ï¼Œå¹¶ç¡®å®šä»£ç†äººåœ¨é‡‡å–è¯¥è¡ŒåŠ¨åå°†è¿›å…¥çš„çŠ¶æ€ä»¥åŠä»–ä»¬å°†è·å¾—çš„å¥–åŠ±ã€‚ï¼ˆæ³¨æ„ï¼šå¦‚æœéœ€è¦å‘ç‰Œç»™ç©å®¶æˆ–åº„å®¶ï¼Œè¯·ä½¿ç”¨æœ¬é—®é¢˜å¼€å¤´ç»™å‡ºçš„åˆ—è¡¨ä¸­çš„ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The first column of each weight matrix (filled in black) contains the bias term weights for each neuron in the layer.",
            "zh": "æ¯ä¸ªæƒé‡çŸ©é˜µçš„ç¬¬ä¸€åˆ—ï¼ˆä»¥é»‘è‰²å¡«å……ï¼‰åŒ…å«å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„åå·®é¡¹æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.1â€…â€…â€…The structures of the tables included in a data quality report to describe (a) continuous features and (b) categorical features.",
            "zh": "3.1 æ•°æ®è´¨é‡æŠ¥å‘Šä¸­æè¿°ï¼ˆaï¼‰è¿ç»­ç‰¹å¾å’Œï¼ˆbï¼‰åˆ†ç±»ç‰¹å¾çš„è¡¨æ ¼ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The measures of predictiveness are called filters because they are used to filter apparently irrelevant features before learning occurs.",
            "zh": "é¢„æµ‹æ€§çš„åº¦é‡è¢«ç§°ä¸ºè¿‡æ»¤å™¨ï¼Œå› ä¸ºå®ƒä»¬ç”¨äºåœ¨å­¦ä¹ å‘ç”Ÿä¹‹å‰è¿‡æ»¤æ˜æ˜¾ä¸ç›¸å…³çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "From a computational perspective, the Manhattan distance has a slight advantage over the Euclidean distanceâ€”the computation of the squaring and the square root is savedâ€”and computational considerations can become important when dealing with very large datasets.",
            "zh": "ä»è®¡ç®—çš„è§’åº¦æ¥çœ‹ï¼Œæ›¼å“ˆé¡¿è·ç¦»æ¯”æ¬§å‡ é‡Œå¾—è·ç¦»ç•¥æœ‰ä¼˜åŠ¿ï¼ˆèŠ‚çœäº†å¹³æ–¹å’Œå¹³æ–¹æ ¹çš„è®¡ç®—ï¼‰ï¼Œåœ¨å¤„ç†éå¸¸å¤§çš„æ•°æ®é›†æ—¶ï¼Œè®¡ç®—è€ƒè™‘å› ç´ å¯èƒ½å˜å¾—å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian Network",
            "zh": "è´å¶æ–¯ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "There are three hyper-parameters that affect the number of neurons required to cover the entirety of an input and hence the dimensionality of the resulting feature map; these are filter dimensions, the stride, and the padding.",
            "zh": "æœ‰ä¸‰ä¸ªè¶…å‚æ•°ä¼šå½±å“è¦†ç›–æ•´ä¸ªè¾“å…¥æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡ï¼Œä»è€Œå½±å“ç”Ÿæˆçš„ç‰¹å¾å›¾çš„ç»´æ•°;è¿™äº›æ˜¯è¿‡æ»¤å™¨å°ºå¯¸ã€æ­¥å¹…å’Œå¡«å……ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. Revenue commissioners around the world use predictive data analytics techniques to keep their processes as efficient as possible. Cleary and Tax (2011) is a good example.",
            "zh": "10. ä¸–ç•Œå„åœ°çš„ç¨åŠ¡ä¸“å‘˜ä½¿ç”¨é¢„æµ‹æ•°æ®åˆ†ææŠ€æœ¯æ¥ä¿æŒå…¶æµç¨‹å°½å¯èƒ½é«˜æ•ˆã€‚Cleary and Taxï¼ˆ2011ï¼‰å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, CLASS and is composed of three plots: a plot of the distribution of the descriptive feature values in the full dataset, and plots showing the distribution of the descriptive feature values for each level of the target.",
            "zh": "æ¯ä¸ªå¯è§†åŒ–éƒ½è¯´æ˜äº†æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ CLASS ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ç”±ä¸‰ä¸ªå›¾ç»„æˆï¼šå®Œæ•´æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾å€¼çš„åˆ†å¸ƒå›¾ï¼Œä»¥åŠæ˜¾ç¤ºç›®æ ‡æ¯ä¸ªçº§åˆ«çš„æè¿°æ€§ç‰¹å¾å€¼åˆ†å¸ƒçš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The animals that may be found in these forests include bears, deer, and cougars.",
            "zh": "åœ¨è¿™äº›æ£®æ—ä¸­å¯èƒ½å‘ç°çš„åŠ¨ç‰©åŒ…æ‹¬ç†Šã€é¹¿å’Œç¾æ´²ç‹®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This chapter discusses reinforcement learning, an approach to machine learning that is sufficiently different from supervised and unsupervised machine learning to be often considered the third leg of the machine learning stool.",
            "zh": "æœ¬ç« è®¨è®ºå¼ºåŒ–å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå®ƒä¸æœ‰ç›‘ç£å’Œæ— ç›‘ç£çš„æœºå™¨å­¦ä¹ æœ‰å¾ˆå¤§ä¸åŒï¼Œé€šå¸¸è¢«è®¤ä¸ºæ˜¯æœºå™¨å­¦ä¹ å‡³å­çš„ç¬¬ä¸‰æ¡è…¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "This results in the majority of feature values being in a range of [âˆ’1,1].",
            "zh": "è¿™å¯¼è‡´å¤§å¤šæ•°ç‰¹å¾å€¼åœ¨ [âˆ’1,1] çš„èŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "These synapses allow electrical signals to pass from the axon of one neuron to a dendrite of another.",
            "zh": "è¿™äº›çªè§¦å…è®¸ç”µä¿¡å·ä»ä¸€ä¸ªç¥ç»å…ƒçš„è½´çªä¼ é€’åˆ°å¦ä¸€ä¸ªç¥ç»å…ƒçš„æ ‘çªã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross sampled data from the period 2008 to 2013.",
            "zh": "Ross å¯¹ 2008 å¹´è‡³ 2013 å¹´æœŸé—´çš„æ•°æ®è¿›è¡Œäº†æŠ½æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, machine learning works by searching through a set of potential models to find the prediction model that best generalizes beyond the dataset. Machine learning algorithms use two sources of information to guide this search, the training dataset and the inductive bias assumed by the algorithm.",
            "zh": "æ€»ä¹‹ï¼Œæœºå™¨å­¦ä¹ çš„å·¥ä½œåŸç†æ˜¯æœç´¢ä¸€ç»„æ½œåœ¨æ¨¡å‹ï¼Œä»¥æ‰¾åˆ°æœ€èƒ½åœ¨æ•°æ®é›†ä¹‹å¤–æ³›åŒ–çš„é¢„æµ‹æ¨¡å‹ã€‚æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ä¸¤ä¸ªä¿¡æ¯æºæ¥æŒ‡å¯¼è¿™ç§æœç´¢ï¼Œå³è®­ç»ƒæ•°æ®é›†å’Œç®—æ³•å‡è®¾çš„å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.73",
            "zh": "0.73"
        }
    },
    {
        "translation": {
            "en": "Laplace smoothing, 267, 308",
            "zh": "æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Œ267,308"
        }
    },
    {
        "translation": {
            "en": "8.2.5â€ƒWhy Is Network Depth Important?",
            "zh": "8.2.5 ä¸ºä»€ä¹ˆç½‘ç»œæ·±åº¦å¾ˆé‡è¦ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Once we have discretized the continuous features and calculated the thresholds for binning query features, we are ready to create our predictive model.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬å¯¹è¿ç»­ç‰¹å¾è¿›è¡Œäº†ç¦»æ•£åŒ–å¹¶è®¡ç®—äº†åˆ†ç®±æŸ¥è¯¢ç‰¹å¾çš„é˜ˆå€¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ›å»ºé¢„æµ‹æ¨¡å‹äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Encoding the red, green, and blue (RGB) information is normally done using a separate two-dimensional matrix for each color, with the dimensions of each of these two-dimensional matrices equal to the pixel resolution of the image.",
            "zh": "å¯¹çº¢è‰²ã€ç»¿è‰²å’Œè“è‰² ï¼ˆRGBï¼‰ ä¿¡æ¯è¿›è¡Œç¼–ç é€šå¸¸ä½¿ç”¨æ¯ç§é¢œè‰²çš„å•ç‹¬äºŒç»´çŸ©é˜µæ¥å®Œæˆï¼Œæ¯ä¸ªäºŒç»´çŸ©é˜µçš„å°ºå¯¸ç­‰äºå›¾åƒçš„åƒç´ åˆ†è¾¨ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset from Table 5.5[204] with the Euclidean distance between each instance and the query SALARY = 56,000, AGE = 35 when we use both the SALARY and AGE features, just the SALARY feature, and just the AGE feature.",
            "zh": "è¡¨ 5.5[204] ä¸­çš„æ•°æ®é›†ï¼Œæ¯ä¸ªå®ä¾‹ä¹‹é—´çš„æ¬§æ°è·ç¦»ä¸æŸ¥è¯¢ SALARY = 56,000ï¼ŒAGE = 35ï¼Œå½“æˆ‘ä»¬åŒæ—¶ä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾æ—¶ï¼Œä»…ä½¿ç”¨ SALARY ç‰¹å¾ï¼Œå¹¶ä¸”ä»…ä½¿ç”¨ AGE ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "28. These images are based on the dataset from the UCI Machine Learning repository Dua and Graff (2017) and originally described by Alimoglu and Alpaydin (1996).",
            "zh": "28. è¿™äº›å›¾åƒåŸºäº UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ Dua å’Œ Graff ï¼ˆ2017ï¼‰ çš„æ•°æ®é›†ï¼Œæœ€åˆç”± Alimoglu å’Œ Alpaydin ï¼ˆ1996ï¼‰ æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these scenarios we need to process millions of examples and to calculate and accumulate millions of error gradients for each weight update.",
            "zh": "åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†æ•°ç™¾ä¸‡ä¸ªç¤ºä¾‹ï¼Œå¹¶ä¸ºæ¯æ¬¡æƒé‡æ›´æ–°è®¡ç®—å’Œç´¯ç§¯æ•°ç™¾ä¸‡ä¸ªè¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "A simple RNN model unrolled through time (in this instance, three time-steps).",
            "zh": "ä¸€ä¸ªç®€å•çš„ RNN æ¨¡å‹éšæ—¶é—´å±•å¼€ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºä¸‰ä¸ªæ—¶é—´æ­¥é•¿ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The rotation and scaling of the axes are the result of the multiplication by the inverse covariance matrix of the dataset (âˆ‘âˆ’1).",
            "zh": "è½´çš„æ—‹è½¬å’Œç¼©æ”¾æ˜¯ä¹˜ä»¥æ•°æ®é›†çš„é€†åæ–¹å·®çŸ©é˜µ ï¼ˆâˆ‘âˆ’1ï¼‰ çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Often missing values arise from errors in data integration or in the process of generating values for derived fields.",
            "zh": "ä¸¢å¤±å€¼é€šå¸¸æ˜¯ç”±äºæ•°æ®é›†æˆæˆ–ä¸ºæ´¾ç”Ÿå­—æ®µç”Ÿæˆå€¼è¿‡ç¨‹ä¸­çš„é”™è¯¯å¼•èµ·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the more unusual challenges involved in earning this badge is to learn to cross a stream using a set of stepping-stones while wearing an electronic blindfold.",
            "zh": "è·å¾—æ­¤å¾½ç« æ‰€æ¶‰åŠçš„æ›´ä¸å¯»å¸¸çš„æŒ‘æˆ˜ä¹‹ä¸€æ˜¯åœ¨æˆ´ç€ç”µå­çœ¼ç½©çš„æƒ…å†µä¸‹å­¦ä¹ ä½¿ç”¨ä¸€ç»„å«è„šçŸ³ç©¿è¶Šæºªæµã€‚"
        }
    },
    {
        "translation": {
            "en": "If we do not do this, then as we continue to increase the dimensionality of the feature space, the instances will continue to spread out until we reach a point in a high-dimensional feature space where most of the feature space is empty.",
            "zh": "å¦‚æœæˆ‘ä»¬ä¸è¿™æ ·åšï¼Œé‚£ä¹ˆéšç€æˆ‘ä»¬ç»§ç»­å¢åŠ ç‰¹å¾ç©ºé—´çš„ç»´æ•°ï¼Œå®ä¾‹å°†ç»§ç»­æ‰©æ•£ï¼Œç›´åˆ°æˆ‘ä»¬åˆ°è¾¾é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­å¤§éƒ¨åˆ†ç‰¹å¾ç©ºé—´ä¸ºç©ºçš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We now understand the theory of how to calculate a simple unconditional probability, a joint probability, and a conditional probability using a dataset. Now is a good point to ground this knowledge in a more interesting example focused on predictive data analytics. We will use the dataset in Table B.2[760] for this.3 The target being predicted in this dataset is whether or not a patient is suffering from meningitis, and the descriptive features are common symptoms associated with meningitis.",
            "zh": "æˆ‘ä»¬ç°åœ¨äº†è§£äº†å¦‚ä½•ä½¿ç”¨æ•°æ®é›†è®¡ç®—ç®€å•æ— æ¡ä»¶æ¦‚ç‡ã€è”åˆæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡çš„ç†è®ºã€‚ç°åœ¨æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç‚¹ï¼Œå°†è¿™äº›çŸ¥è¯†å»ºç«‹åœ¨ä¸€ä¸ªæ›´æœ‰è¶£çš„ä¾‹å­ä¸­ï¼Œé‡ç‚¹æ˜¯é¢„æµ‹æ•°æ®åˆ†æã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¡¨B.2[760]ä¸­çš„æ•°æ®é›†.3è¯¥æ•°æ®é›†ä¸­é¢„æµ‹çš„ç›®æ ‡æ˜¯æ‚£è€…æ˜¯å¦æ‚£æœ‰è„‘è†œç‚ï¼Œæè¿°æ€§ç‰¹å¾æ˜¯ä¸è„‘è†œç‚ç›¸å…³çš„å¸¸è§ç—‡çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, Figure 10.13(a)[623] returns to the full mobile phone customer dataset from Table 10.1[604] and shows the dendrogram capturing the result of running the AHC algorithm on this dataset.",
            "zh": "ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œå›¾10.13ï¼ˆaï¼‰[623]ä»è¡¨10.1[604]è¿”å›åˆ°å®Œæ•´çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ï¼Œå¹¶æ˜¾ç¤ºäº†æ•è·åœ¨è¯¥æ•°æ®é›†ä¸Šè¿è¡ŒAHCç®—æ³•ç»“æœçš„æ ‘çŠ¶å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset is listed in Table 4.8[147].",
            "zh": "è¯¥æ•°æ®é›†åˆ—äºè¡¨4.8[147]ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a real-time credit card fraud prediction system, it may be required that a model perform thousands of predictions per second.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å®æ—¶ä¿¡ç”¨å¡æ¬ºè¯ˆé¢„æµ‹ç³»ç»Ÿä¸­ï¼Œå¯èƒ½éœ€è¦æ¨¡å‹æ¯ç§’æ‰§è¡Œæ•°åƒæ¬¡é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning a value function returns the cumulative reward that an agent can expect to earn if it starts from a particular state, st, and follows a specific policy, Ï€ all the way to the end of an episode. We can write this",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå€¼å‡½æ•°è¿”å›æ™ºèƒ½ä½“ä»ç‰¹å®šçŠ¶æ€ st å¼€å§‹å¹¶éµå¾ªç‰¹å®šç­–ç•¥ï¼ˆÏ€ä¸€ç›´åˆ°å‰§é›†ç»“æŸï¼‰å¯ä»¥æœŸæœ›è·å¾—çš„ç´¯ç§¯å¥–åŠ±ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·å†™"
        }
    },
    {
        "translation": {
            "en": "In the next section we combine the ideas of temporal-difference learning and a specific behavior policy to define the standard approach to reinforcement learning: Q-learning.",
            "zh": "åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ—¶é—´å·®å¼‚å­¦ä¹ çš„æ€æƒ³ä¸ç‰¹å®šçš„è¡Œä¸ºç­–ç•¥ç›¸ç»“åˆï¼Œä»¥å®šä¹‰å¼ºåŒ–å­¦ä¹ çš„æ ‡å‡†æ–¹æ³•ï¼šQ-learningã€‚"
        }
    },
    {
        "translation": {
            "en": "single",
            "zh": "å•"
        }
    },
    {
        "translation": {
            "en": "social science, 293",
            "zh": "ç¤¾ä¼šç§‘å­¦ï¼Œ 293"
        }
    },
    {
        "translation": {
            "en": "Being a large retailer, they had considerable resources at their disposal, one of which was the ability to regularly take high-resolution satellite photos.",
            "zh": "ä½œä¸ºä¸€å®¶å¤§å‹é›¶å”®å•†ï¼Œä»–ä»¬æ‹¥æœ‰å¤§é‡èµ„æºå¯ä¾›ä½¿ç”¨ï¼Œå…¶ä¸­ä¹‹ä¸€å°±æ˜¯èƒ½å¤Ÿå®šæœŸæ‹æ‘„é«˜åˆ†è¾¨ç‡å«æ˜Ÿç…§ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. An analytics consultant at an insurance company has built an ABT that will be used to train a model to predict the best communications channel to use to contact a potential customer with an offer of a new insurance product.15 The following table contains an extract from this ABTâ€”the full ABT contains 5,200 instances.",
            "zh": "3. ä¸€å®¶ä¿é™©å…¬å¸çš„åˆ†æé¡¾é—®æ„å»ºäº†ä¸€ä¸ª ABTï¼Œè¯¥æ¨¡å‹å°†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä»¥é¢„æµ‹ç”¨äºè”ç³»æ½œåœ¨å®¢æˆ·å¹¶æä¾›æ–°ä¿é™©äº§å“çš„æœ€ä½³æ²Ÿé€šæ¸ é“ã€‚15 ä¸‹è¡¨åŒ…å«æ­¤ ABT çš„æ‘˜å½• - å®Œæ•´çš„ ABT åŒ…å« 5,200 ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The choice of the correct performance measure for a particular problem depends on a combination of the nature of the prediction problem (e.g., continuous versus categorical), the characteristics of the dataset (e.g., balanced versus imbalanced), and the needs of the application (e.g., medical diagnosis versus marketing response prediction).",
            "zh": "ä¸ºç‰¹å®šé—®é¢˜é€‰æ‹©æ­£ç¡®çš„æ€§èƒ½åº¦é‡å–å†³äºé¢„æµ‹é—®é¢˜çš„æ€§è´¨ï¼ˆä¾‹å¦‚ï¼Œè¿ç»­ä¸åˆ†ç±»ï¼‰ã€æ•°æ®é›†çš„ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œå¹³è¡¡ä¸ä¸å¹³è¡¡ï¼‰ä»¥åŠåº”ç”¨ç¨‹åºçš„éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼ŒåŒ»å­¦è¯Šæ–­ä¸è¥é”€å“åº”é¢„æµ‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A probability function, P(), returns the probability of an event.",
            "zh": "æ¦‚ç‡å‡½æ•° Pï¼ˆï¼‰ è¿”å›äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.12",
            "zh": "å›¾ 3.12"
        }
    },
    {
        "translation": {
            "en": "Both Filters 1 and 2 have a dimensionality of 2-by-1-by-3.",
            "zh": "è¿‡æ»¤å™¨ 1 å’Œ 2 çš„ç»´åº¦å‡ä¸º 2Ã—1Ã—3ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we compare the visualization of lift for these predictions shown in Figure 9.16(a)[570] to the gain chart for the same set of predictions in Figure 9.15(a)[569], we can see that the shapes are the same.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†å›¾9.16ï¼ˆaï¼‰[570]ä¸­æ‰€ç¤ºçš„è¿™äº›é¢„æµ‹çš„å‡åŠ›å¯è§†åŒ–ä¸å›¾9.15ï¼ˆaï¼‰[569]ä¸­åŒä¸€ç»„é¢„æµ‹çš„å¢ç›Šå›¾è¡¨è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å½¢çŠ¶æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the end of this process, a Î´ has been calculated for every neuron in the network.",
            "zh": "åœ¨æ­¤è¿‡ç¨‹ç»“æŸæ—¶ï¼Œå·²ç»ä¸ºç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒè®¡ç®—äº†Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model first used a 3-level logistic regression model to distinguish between the elliptical, spiral, and other target levels.",
            "zh": "è¯¥æ¨¡å‹é¦–å…ˆä½¿ç”¨ 3 çº§é€»è¾‘å›å½’æ¨¡å‹æ¥åŒºåˆ†æ¤­åœ†ã€èºæ—‹å’Œå…¶ä»–ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (11.22)[655] states that the action-value table is updated using the actual return received by an agent across a full episode, whereas we also said that this update takes place after every action.",
            "zh": "ç­‰å¼ï¼ˆ11.22ï¼‰[655]æŒ‡å‡ºï¼Œæ“ä½œå€¼è¡¨æ˜¯ä½¿ç”¨ä»£ç†åœ¨æ•´ä¸ªå‰§é›†ä¸­æ”¶åˆ°çš„å®é™…å›æŠ¥æ¥æ›´æ–°çš„ï¼Œè€Œæˆ‘ä»¬è¿˜è¯´ï¼Œæ­¤æ›´æ–°å‘ç”Ÿåœ¨æ¯ä¸ªæ“ä½œä¹‹åã€‚"
        }
    },
    {
        "translation": {
            "en": "linear activations, 674",
            "zh": "çº¿æ€§æ¿€æ´»ï¼Œ674"
        }
    },
    {
        "translation": {
            "en": "Davenport, Thomas H. 2006. Competing on analytics. Harvard Business Review 84 (1): 98â€“107. http://hbr.harvardbusiness.org/2006/01/competing-on-analytics/ar/1.",
            "zh": "è¾¾æ–‡æ³¢ç‰¹ï¼Œæ‰˜é©¬æ–¯ H. 2006 å¹´ã€‚åœ¨åˆ†ææ–¹é¢å±•å¼€ç«äº‰ã€‚å“ˆä½›å•†ä¸šè¯„è®º84ï¼ˆ1ï¼‰ï¼š98-107ã€‚http://hbr.harvardbusiness.org/2006/01/competing-on-analytics/ar/1ã€‚"
        }
    },
    {
        "translation": {
            "en": "The matrix on the right of Equation (8.95)[491] represents an extension to the architecture that we have discussed.",
            "zh": "ç­‰å¼ï¼ˆ8.95ï¼‰[491]å³è¾¹çš„çŸ©é˜µä»£è¡¨äº†æˆ‘ä»¬è®¨è®ºçš„æ¶æ„çš„æ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using predictive analytics, however, the results of small-scale surveys can be used to create predictive models that can be applied across large regions.",
            "zh": "ä½†æ˜¯ï¼Œä½¿ç”¨é¢„æµ‹åˆ†æï¼Œå°è§„æ¨¡è°ƒæŸ¥çš„ç»“æœå¯ç”¨äºåˆ›å»ºå¯åº”ç”¨äºå¤§å‹åŒºåŸŸçš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.7â€…â€…â€…Histograms of the EXPRAD_R feature split by target feature level.",
            "zh": "13.7 æŒ‰ç›®æ ‡ç‰¹å¾çº§åˆ«åˆ’åˆ†çš„EXPRAD_Rç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When the algorithm is searching for the nearest neighbor using Euclidean distance, it is partitioning the feature space into what is known as a Voronoi tessellation,4 and it is trying to decide which Voronoi region the query belongs to.",
            "zh": "å½“ç®—æ³•ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»æœç´¢æœ€è¿‘é‚»æ—¶ï¼Œå®ƒä¼šå°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºæ‰€è°“çš„ Voronoi æ›²é¢ç»†åˆ†ï¼Œ4 å¹¶å°è¯•ç¡®å®šæŸ¥è¯¢å±äºå“ªä¸ª Voronoi åŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) What prediction will the decision tree generated in Part (a) of this question return for the following query?",
            "zh": "ï¼ˆcï¼‰ æœ¬é—®é¢˜ï¼ˆaï¼‰éƒ¨åˆ†ç”Ÿæˆçš„å†³ç­–æ ‘å¯¹ä»¥ä¸‹æŸ¥è¯¢å°†è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "FIBER2MAGERR_U/G/R/I/Z",
            "zh": "FIBER2MAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Gapminder, 237",
            "zh": "Gapminderï¼Œ237"
        }
    },
    {
        "translation": {
            "en": "In some applications there is a natural structure in the data that we can take advantage of to form test sets.",
            "zh": "åœ¨æŸäº›åº”ç”¨ç¨‹åºä¸­ï¼Œæ•°æ®ä¸­æœ‰ä¸€ä¸ªè‡ªç„¶ç»“æ„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å®ƒæ¥å½¢æˆæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this situation the node becomes dependent on the ancestors of its unknown parent.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹å°†ä¾èµ–äºå…¶æœªçŸ¥çˆ¶èŠ‚ç‚¹çš„ç¥–å…ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, it would seem reasonable to argue that the behavior of an octopus in a swimming tank should not affect the outcome of a soccer match.12 If knowledge of one event has no effect on the probability of another event, and vice versa, then the two events are said to be independent of each other.",
            "zh": "ä¾‹å¦‚ï¼Œè®¤ä¸ºç« é±¼åœ¨æ°´ç®±ä¸­çš„è¡Œä¸ºä¸åº”å½±å“è¶³çƒæ¯”èµ›çš„ç»“æœä¼¼ä¹æ˜¯åˆç†çš„.12å¦‚æœå¯¹ä¸€ä¸ªäº‹ä»¶çš„äº†è§£å¯¹å¦ä¸€ä¸ªäº‹ä»¶çš„æ¦‚ç‡æ²¡æœ‰å½±å“ï¼Œåä¹‹äº¦ç„¶ï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªäº‹ä»¶è¢«è®¤ä¸ºæ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rectified linear activation functions were used in all hidden layer units.",
            "zh": "æ‰€æœ‰éšè—å±‚å•å…ƒéƒ½ä½¿ç”¨äº†æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4â€…â€…â€…Designing and Implementing Features",
            "zh": "2.4 è®¾è®¡å’Œå®ç°åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "ANOVA test, 86, 95",
            "zh": "æ–¹å·®åˆ†ææ£€éªŒï¼Œ86,95"
        }
    },
    {
        "translation": {
            "en": "The data quality plan for the motor insurance fraud prediction ABT.",
            "zh": "æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹ABTçš„æ•°æ®è´¨é‡è®¡åˆ’ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, P(FEVER = true) returns the probability of the FEVER feature taking the value true.",
            "zh": "ä¾‹å¦‚ï¼ŒPï¼ˆFEVER = trueï¼‰ è¿”å› FEVER ç‰¹å¾å–å€¼ true çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Analytics practitioners must, however, possess what is referred to as situational fluency.",
            "zh": "ç„¶è€Œï¼Œåˆ†æä»ä¸šè€…å¿…é¡»å…·å¤‡æ‰€è°“çš„æƒ…å¢ƒæµç•…æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The neuron in the figure takes 9 inputs, arranged in a two-dimensional 3-by-3 grid, mirroring the two-dimensional nature of the image.",
            "zh": "å›¾ä¸­çš„ç¥ç»å…ƒæ¥å— 9 ä¸ªè¾“å…¥ï¼Œæ’åˆ—æˆäºŒç»´ 3Ã—3 ç½‘æ ¼ï¼Œåæ˜ äº†å›¾åƒçš„äºŒç»´æ€§è´¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.0481",
            "zh": "0.0481"
        }
    },
    {
        "translation": {
            "en": "800,000",
            "zh": "800,000"
        }
    },
    {
        "translation": {
            "en": "LNLSTAR_U/G/R/I/Z",
            "zh": "LNLSTAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "AE_I",
            "zh": "AE_I"
        }
    },
    {
        "translation": {
            "en": "The complexity of the calculations can be reduced by being careful with the positioning of features with respect to summations and by using dynamic programming techniques to avoid repeated computations.",
            "zh": "é€šè¿‡ä»”ç»†å®šä½ç›¸å¯¹äºæ±‚å’Œçš„ç‰¹å¾ï¼Œä»¥åŠä½¿ç”¨åŠ¨æ€è§„åˆ’æŠ€æœ¯æ¥é¿å…é‡å¤è®¡ç®—ï¼Œå¯ä»¥é™ä½è®¡ç®—çš„å¤æ‚æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Understanding, at least in principle, whether a particular network architecture is capable of representing a function, or not, is very important, because the fundamental task in predictive modeling is to learn functions from data, and if the network cannot represent a function, then it cannot learn it, no matter how much data we provide to the training algorithm.",
            "zh": "è‡³å°‘åœ¨åŸåˆ™ä¸Šï¼Œäº†è§£ç‰¹å®šçš„ç½‘ç»œæ¶æ„æ˜¯å¦èƒ½å¤Ÿè¡¨ç¤ºå‡½æ•°éå¸¸é‡è¦ï¼Œå› ä¸ºé¢„æµ‹å»ºæ¨¡çš„åŸºæœ¬ä»»åŠ¡æ˜¯ä»æ•°æ®ä¸­å­¦ä¹ å‡½æ•°ï¼Œå¦‚æœç½‘ç»œä¸èƒ½è¡¨ç¤ºå‡½æ•°ï¼Œé‚£ä¹ˆå®ƒå°±æ— æ³•å­¦ä¹ å®ƒï¼Œæ— è®ºæˆ‘ä»¬å‘è®­ç»ƒç®—æ³•æä¾›å¤šå°‘æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of these measures is suitable for different types of data, and matching the appropriate measure to the data is an important step in inducing an accurate similarity-based prediction model.",
            "zh": "è¿™äº›åº¦é‡ä¸­çš„æ¯ä¸€ä¸ªéƒ½é€‚ç”¨äºä¸åŒç±»å‹çš„æ•°æ®ï¼Œå°†é€‚å½“çš„åº¦é‡ä¸æ•°æ®ç›¸åŒ¹é…æ˜¯è¯±å¯¼åŸºäºç›¸ä¼¼æ€§çš„å‡†ç¡®é¢„æµ‹æ¨¡å‹çš„é‡è¦æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Choosing to Twist in any of the non-terminal states will take the agent to the same non-terminal state, another non-terminal state representing a higher player hand value, orâ€”if they are unluckyâ€”the BUST state.",
            "zh": "é€‰æ‹©åœ¨ä»»ä½•éç»ˆç«¯çŠ¶æ€ä¸‹è¿›è¡Œ Twist éƒ½ä¼šå°†ä»£ç†å¸¦åˆ°ç›¸åŒçš„éç»ˆç«¯çŠ¶æ€ï¼Œå¦ä¸€ä¸ªéç»ˆç«¯çŠ¶æ€ä»£è¡¨æ›´é«˜çš„ç©å®¶æ‰‹ç‰Œå€¼ï¼Œæˆ–è€…â€”â€”å¦‚æœä»–ä»¬è¿æ°”ä¸å¥½â€”â€”BUST çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2â€…â€…â€…An action-value table for an agent trained to play the card game TwentyTwos (the simplified version of Blackjack described in Section 11.2.3[643]).",
            "zh": "11.2 ä¸€ä¸ªåŠ¨ä½œå€¼è¡¨ï¼Œä¾›ä¸€ä¸ªå—è¿‡è®­ç»ƒç©çº¸ç‰Œæ¸¸æˆTwentyTwosï¼ˆç¬¬11.2.3[643]èŠ‚ä¸­æè¿°çš„äºŒåä¸€ç‚¹çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰çš„ä»£ç†ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The % SOFT TISSUE feature is a ratio of the NUM.",
            "zh": "% SOFT TISSUE ç‰¹å¾æ˜¯ NUM çš„æ¯”ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "k-NN, 181",
            "zh": "k-NNï¼Œ181"
        }
    },
    {
        "translation": {
            "en": "There are two advantages to using a causal graph: (1) people find it relatively easy to think in terms of causal relationships, and as a result, networks that encode these relationships are relatively easy to understand; (2) often networks that reflect the causal structure of a domain are more compact in terms of the number of links between nodes and hence are more compact with respect to the number of CPT entries.",
            "zh": "ä½¿ç”¨å› æœå›¾æœ‰ä¸¤ä¸ªä¼˜ç‚¹ï¼šï¼ˆ1ï¼‰äººä»¬å‘ç°ä»å› æœå…³ç³»çš„è§’åº¦æ€è€ƒç›¸å¯¹å®¹æ˜“ï¼Œå› æ­¤ï¼Œç¼–ç è¿™äº›å…³ç³»çš„ç½‘ç»œç›¸å¯¹å®¹æ˜“ç†è§£;ï¼ˆ2ï¼‰é€šå¸¸ï¼Œåæ˜ åŸŸå› æœç»“æ„çš„ç½‘ç»œåœ¨èŠ‚ç‚¹ä¹‹é—´çš„é“¾æ¥æ•°é‡æ–¹é¢æ›´ç´§å‡‘ï¼Œå› æ­¤åœ¨CPTæ¡ç›®æ•°é‡æ–¹é¢æ›´ç´§å‡‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "support vectors, 362",
            "zh": "æ”¯æŒå‘é‡ï¼Œ362"
        }
    },
    {
        "translation": {
            "en": "The simple prediction model using only the loan-salary ratio feature is no longer consistent with the dataset. It turns out, however, that there is at least one prediction model that is consistent with the dataset; it is just a little harder to find than the previous one:",
            "zh": "ä»…ä½¿ç”¨è´·æ¬¾-å·¥èµ„æ¯”ç‰¹å¾çš„ç®€å•é¢„æµ‹æ¨¡å‹ä¸å†ä¸æ•°æ®é›†ä¸€è‡´ã€‚ç„¶è€Œï¼Œäº‹å®è¯æ˜ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ä¸æ•°æ®é›†ä¸€è‡´;å®ƒåªæ˜¯æ¯”å‰ä¸€ä¸ªæ›´éš¾æ‰¾åˆ°ï¼š"
        }
    },
    {
        "translation": {
            "en": "Contents",
            "zh": "å†…å®¹"
        }
    },
    {
        "translation": {
            "en": "5.6â€ƒFurther Reading",
            "zh": "5.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "You are currently preparing for a visit by the American physicist Professor Robert W. Wood to whom Professor Blondlot has agreed to demonstrate the experiments that show the effects of N rays.",
            "zh": "æ‚¨ç›®å‰æ­£åœ¨å‡†å¤‡ç¾å›½ç‰©ç†å­¦å®¶ç½—ä¼¯ç‰¹Â·ä¼å¾·ï¼ˆRobert W. Woodï¼‰æ•™æˆçš„è®¿é—®ï¼Œå¸ƒéš†å¾·æ´›ç‰¹æ•™æˆå·²åŒæ„å‘ä»–æ¼”ç¤ºæ˜¾ç¤ºNå°„çº¿æ•ˆåº”çš„å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "2,700",
            "zh": "2,700"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification decision tree generated using information gain ratio.",
            "zh": "ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”ç”Ÿæˆçš„æ¤è¢«åˆ†ç±»å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The menu is quite simple, displaying only five words: sicÃ­n, mairteoil, muiceoil, muisiriÃºn, and bradÃ¡n.",
            "zh": "èœå•éå¸¸ç®€å•ï¼Œåªæ˜¾ç¤ºäº”ä¸ªè¯ï¼šsicÃ­nã€mairteoilã€muiceoilã€muisiriÃºn å’Œ bradÃ¡nã€‚"
        }
    },
    {
        "translation": {
            "en": "4.7â€…â€…â€…How the instances in the spam dataset split when we partition using each of the different descriptive features from the spam dataset in Table 4.2[121].",
            "zh": "4.7 å½“æˆ‘ä»¬ä½¿ç”¨è¡¨ 4.2[121] ä¸­åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„æ¯ä¸ªä¸åŒæè¿°æ€§ç‰¹å¾è¿›è¡Œåˆ†åŒºæ—¶ï¼Œåƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„å®ä¾‹æ˜¯å¦‚ä½•åˆ†è£‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.6â€…â€…â€…The division of data during the É›0 bootstrap process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "9.6 É›0 å¼•å¯¼è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•æ•°æ®ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In hindsight, the general criticisms of neural networks made by Minsky and Papert have not stood the test of time; however, their criticism of the representational capacity of single-layer networks is valid.",
            "zh": "äº‹åçœ‹æ¥ï¼ŒMinsky å’Œ Papert å¯¹ç¥ç»ç½‘ç»œçš„æ™®éæ‰¹è¯„å¹¶æ²¡æœ‰ç»å—ä½æ—¶é—´çš„è€ƒéªŒ;ç„¶è€Œï¼Œä»–ä»¬å¯¹å•å±‚ç½‘ç»œè¡¨ç¤ºèƒ½åŠ›çš„æ‰¹è¯„æ˜¯æœ‰é“ç†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.5â€…â€…â€…The confusion matrices for the baseline models.",
            "zh": "13.5 åŸºçº¿æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset had not been used in the training process, so the performance of the model on this dataset should give a fair indication of how well the model would perform when deployed on real, unseen data.",
            "zh": "è¯¥æ•°æ®é›†æœªåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨ï¼Œå› æ­¤æ¨¡å‹åœ¨æ­¤æ•°æ®é›†ä¸Šçš„æ€§èƒ½åº”å…¬å¹³åœ°è¡¨æ˜è¯¥æ¨¡å‹åœ¨éƒ¨ç½²åœ¨çœŸå®ã€çœ‹ä¸è§çš„æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) If xt = [1,0.5] and htâˆ’1 = [0.05,0.2,0.15], calculate the value of yt.",
            "zh": "ï¼ˆaï¼‰ å¦‚æœ xt = [1,0.5] å’Œ htâˆ’1 = [0.05,0.2,0.15]ï¼Œåˆ™è®¡ç®— yt çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Summing out is sometimes referred to as marginalization because statisticians used to carry out these calculations in the margins of the probability tables they were working with!",
            "zh": "4. æ±‚å’Œæœ‰æ—¶è¢«ç§°ä¸ºè¾¹ç¼˜åŒ–ï¼Œå› ä¸ºç»Ÿè®¡å­¦å®¶è¿‡å»å¸¸å¸¸åœ¨ä»–ä»¬æ­£åœ¨ä½¿ç”¨çš„æ¦‚ç‡è¡¨çš„è¾¹ç¼˜è¿›è¡Œè¿™äº›è®¡ç®—ï¼"
        }
    },
    {
        "translation": {
            "en": "In an error-based model, learning equates to finding the optimal values for these weights.",
            "zh": "åœ¨åŸºäºè¯¯å·®çš„æ¨¡å‹ä¸­ï¼Œå­¦ä¹ ç­‰åŒäºæ‰¾åˆ°è¿™äº›æƒé‡çš„æœ€ä½³å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gaeltacht, 655",
            "zh": "ç›–å°”å¡”èµ«ç‰¹ï¼Œ655"
        }
    },
    {
        "translation": {
            "en": "However, the posterior probabilities are not as extreme as those calculated when we did not assume conditional independence.",
            "zh": "ç„¶è€Œï¼ŒåéªŒæ¦‚ç‡å¹¶ä¸åƒæˆ‘ä»¬æ²¡æœ‰å‡è®¾æ¡ä»¶ç‹¬ç«‹æ€§æ—¶è®¡ç®—çš„æ¦‚ç‡é‚£ä¹ˆæç«¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The key objects in the companyâ€™s data model and the data available regarding them. For example, in a bricks-and-mortar retail scenario, the key objects are likely to be customers, products, sales, suppliers, stores, and staff. In an insurance scenario, the key objects are likely to be policyholders, policies, claims, policy applications, investigations, brokers, members, investigators, and payments.",
            "zh": "å…¬å¸æ•°æ®æ¨¡å‹ä¸­çš„å…³é”®å¯¹è±¡ä»¥åŠæœ‰å…³å®ƒä»¬çš„å¯ç”¨æ•°æ®ã€‚ä¾‹å¦‚ï¼Œåœ¨å®ä½“é›¶å”®åœºæ™¯ä¸­ï¼Œå…³é”®å¯¹è±¡å¯èƒ½æ˜¯å®¢æˆ·ã€äº§å“ã€é”€å”®ã€ä¾›åº”å•†ã€å•†åº—å’Œå‘˜å·¥ã€‚åœ¨ä¿é™©åœºæ™¯ä¸­ï¼Œå…³é”®å¯¹è±¡å¯èƒ½æ˜¯æŠ•ä¿äººã€ä¿å•ã€ç´¢èµ”ã€ä¿å•ç”³è¯·ã€è°ƒæŸ¥ã€ç»çºªäººã€æˆå‘˜ã€è°ƒæŸ¥å‘˜å’Œä»˜æ¬¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.1â€…â€…â€…Smoothing",
            "zh": "6.4.1 å¹³æ»‘"
        }
    },
    {
        "translation": {
            "en": "Online Resources",
            "zh": "åœ¨çº¿èµ„æº"
        }
    },
    {
        "translation": {
            "en": "2.3â€…â€…â€…Example domain concepts for a motor insurance fraud prediction analytics solution.",
            "zh": "2.3 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„ç¤ºä¾‹åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "We can make predictions using Gibbs sampling in the same way that we made predictions using exact probabilistic inference by predicting the target level with the maximum a posteriori probability:",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Gibbs æŠ½æ ·è¿›è¡Œé¢„æµ‹ï¼Œå°±åƒæˆ‘ä»¬ä½¿ç”¨ç²¾ç¡®æ¦‚ç‡æ¨ç†è¿›è¡Œé¢„æµ‹ä¸€æ ·ï¼Œé€šè¿‡ä»¥æœ€å¤§åéªŒæ¦‚ç‡é¢„æµ‹ç›®æ ‡æ°´å¹³ï¼š"
        }
    },
    {
        "translation": {
            "en": "Equation (8.112)[511] defines how these the two paths of processing are merged using an elementwise product, denoted by the âŠ™ term.",
            "zh": "ç­‰å¼ï¼ˆ8.112ï¼‰[511]å®šä¹‰äº†å¦‚ä½•ä½¿ç”¨é€å…ƒä¹˜ç§¯ï¼ˆç”¨âŠ™é¡¹è¡¨ç¤ºï¼‰åˆå¹¶è¿™ä¸¤ç§å¤„ç†è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. See Appendix C[765].",
            "zh": "[12]è§é™„å½•C[765]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Marsland, Stephen. 2011. Machine learning: An algorithmic perspective. CRC Press.",
            "zh": "é©¬æ–¯å…°ï¼Œæ–¯è’‚èŠ¬ã€‚2011. æœºå™¨å­¦ä¹ ï¼šç®—æ³•è§†è§’ã€‚CRCå‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An error function captures the error between the predictions made by a model and the actual values in a training dataset.2 There are many different kinds of error functions, but for measuring the fit of simple linear regression models, the most commonly used is the sum of squared errors error function, or L2.",
            "zh": "è¯¯å·®å‡½æ•°æ•è·æ¨¡å‹åšå‡ºçš„é¢„æµ‹ä¸è®­ç»ƒæ•°æ®é›†ä¸­å®é™…å€¼ä¹‹é—´çš„è¯¯å·®.2 æœ‰è®¸å¤šä¸åŒç±»å‹çš„è¯¯å·®å‡½æ•°ï¼Œä½†å¯¹äºæµ‹é‡ç®€å•çº¿æ€§å›å½’æ¨¡å‹çš„æ‹Ÿåˆåº¦ï¼Œæœ€å¸¸ç”¨çš„æ˜¯è¯¯å·®è¯¯å·®æ€»å’Œè¯¯å·®å‡½æ•°ï¼Œæˆ– L2ã€‚"
        }
    },
    {
        "translation": {
            "en": "The graph of the logistic function is relatively flat for large (positive or negative) values.",
            "zh": "å¯¹äºå¤§ï¼ˆæ­£æˆ–è´Ÿï¼‰å€¼ï¼Œé€»è¾‘å‡½æ•°çš„å›¾å½¢ç›¸å¯¹å¹³å¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. A binary tree is simply a tree in which every node in the tree has at most two branches.",
            "zh": "9. äºŒå‰æ ‘åªæ˜¯ä¸€æ£µæ ‘ï¼Œå…¶ä¸­æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹æœ€å¤šæœ‰ä¸¤ä¸ªåˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The bias terms are the weights on the dummy inputs.",
            "zh": "åç½®é¡¹æ˜¯è™šæ‹Ÿè¾“å…¥çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gain is a measure of how many of the positive instances in the overall test set are found in a particular decile. To find this, we count the number of positive instances (based on the known target values) found in each decile and divide these by the total number of positive instances in the test set. So, the gain in a given decile is calculated as",
            "zh": "å¢ç›Šæ˜¯è¡¡é‡åœ¨ç‰¹å®šååˆ†ä½æ•°ä¸­å‘ç°æ•´ä¸ªæµ‹è¯•é›†ä¸­æœ‰å¤šå°‘é˜³æ€§å®ä¾‹çš„åº¦é‡ã€‚ä¸ºäº†æ‰¾åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬è®¡ç®—åœ¨æ¯ä¸ªååˆ†ä½æ•°ä¸­æ‰¾åˆ°çš„é˜³æ€§å®ä¾‹æ•°ï¼ˆåŸºäºå·²çŸ¥ç›®æ ‡å€¼ï¼‰ï¼Œå¹¶å°†å…¶é™¤ä»¥æµ‹è¯•é›†ä¸­é˜³æ€§å®ä¾‹çš„æ€»æ•°ã€‚å› æ­¤ï¼Œç»™å®šååˆ†ä½æ•°çš„å¢ç›Šè®¡ç®—ä¸º"
        }
    },
    {
        "translation": {
            "en": "The player is allowed to see one of the two cards dealt to the dealer, but the dealerâ€™s other card remains hidden until the player is finished taking their actions.",
            "zh": "ç©å®¶å¯ä»¥çœ‹åˆ°å‘ç»™åº„å®¶çš„ä¸¤å¼ ç‰Œä¸­çš„ä¸€å¼ ï¼Œä½†åº„å®¶çš„å¦ä¸€å¼ ç‰Œä¿æŒéšè—çŠ¶æ€ï¼Œç›´åˆ°ç©å®¶å®Œæˆä»–ä»¬çš„è¡ŒåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next iteration of the algorithm is interesting because the smallest distance found in the distance matrix is a distance of 0.16 between cluster 10 and instance d11.",
            "zh": "è¯¥ç®—æ³•çš„ä¸‹ä¸€æ¬¡è¿­ä»£å¾ˆæœ‰è¶£ï¼Œå› ä¸ºåœ¨è·ç¦»çŸ©é˜µä¸­æ‰¾åˆ°çš„æœ€å°è·ç¦»æ˜¯èšç±» 10 å’Œå®ä¾‹ d11 ä¹‹é—´çš„è·ç¦» 0.16ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. The probability chain rule is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "9. æ¦‚ç‡é“¾è§„åˆ™åœ¨é™„å½•B[757]ç¬¬B.3[762]èŠ‚æœ‰è¯¦ç»†è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The first time that Sarah took a step that reached a stepping-stone, however, she felt a huge rush of excitement.",
            "zh": "ç„¶è€Œï¼Œå½“èæ‹‰ç¬¬ä¸€æ¬¡è¿ˆå‡ºè¸è„šçŸ³çš„ä¸€æ­¥æ—¶ï¼Œå¥¹æ„Ÿåˆ°äº†å·¨å¤§çš„å…´å¥‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because a machine learning algorithm encodes an inductive bias, it can induce models that generalize beyond the instances in a training dataset.",
            "zh": "ç”±äºæœºå™¨å­¦ä¹ ç®—æ³•å¯¹å½’çº³åå·®è¿›è¡Œç¼–ç ï¼Œå› æ­¤å®ƒå¯ä»¥è¯±å¯¼è¶…å‡ºè®­ç»ƒæ•°æ®é›†ä¸­å®ä¾‹èŒƒå›´çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Siegel, Eric. 2013. Predictive analytics: The power to predict who will click, buy, lie, or die, 1st ed. Wiley.",
            "zh": "è¥¿æ ¼å°”ï¼ŒåŸƒé‡Œå…‹ã€‚2013. é¢„æµ‹åˆ†æï¼šé¢„æµ‹è°ä¼šç‚¹å‡»ã€è´­ä¹°ã€æ’’è°æˆ–æ­»äº¡çš„åŠ›é‡ï¼Œç¬¬ 1 ç‰ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In choosing a sample, it is important that it be representative of the population.",
            "zh": "åœ¨é€‰æ‹©æ ·æœ¬æ—¶ï¼Œé‡è¦çš„æ˜¯å®ƒè¦ä»£è¡¨æ€»ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "SIZE",
            "zh": "å¤§å°"
        }
    },
    {
        "translation": {
            "en": "Figure 4.3",
            "zh": "å›¾ 4.3"
        }
    },
    {
        "translation": {
            "en": "Similarly, the difference between the mean and median values for the LNLSTAR_R feature suggested that the distribution of this feature was heavily skewed and also suggested the presence of outliers.",
            "zh": "åŒæ ·ï¼ŒLNLSTAR_Rç‰¹å¾çš„å¹³å‡å€¼å’Œä¸­ä½æ•°å€¼ä¹‹é—´çš„å·®å¼‚è¡¨æ˜è¯¥ç‰¹å¾çš„åˆ†å¸ƒä¸¥é‡åæ–œï¼Œå¹¶ä¸”è¿˜è¡¨æ˜å­˜åœ¨å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.4",
            "zh": "å›¾ 6.4"
        }
    },
    {
        "translation": {
            "en": "P_CW",
            "zh": "P_CW"
        }
    },
    {
        "translation": {
            "en": "Knime, RapidMiner, and Weka are interesting because they are all open-source, freely available solutions that readers can begin to use without any financial investment.",
            "zh": "Knimeã€RapidMiner å’Œ Weka å¾ˆæœ‰è¶£ï¼Œå› ä¸ºå®ƒä»¬éƒ½æ˜¯å¼€æºçš„ã€å…è´¹æä¾›çš„è§£å†³æ–¹æ¡ˆï¼Œè¯»è€…æ— éœ€ä»»ä½•è´¢åŠ¡æŠ•èµ„å³å¯å¼€å§‹ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.15â€…â€…â€…The test set with model predictions and scores from Table 9.11[557] extended to include deciles.",
            "zh": "9.15 åŒ…å«è¡¨9.11[557]çš„æ¨¡å‹é¢„æµ‹å’Œåˆ†æ•°çš„æµ‹è¯•é›†æ‰©å±•è‡³åŒ…æ‹¬ååˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(2006) and Hinton (2005)) was the starting point for the wave of renewed interest in neural network models that began in the early 2000s and became known as deep learning.",
            "zh": "ï¼ˆ2006ï¼‰å’ŒHintonï¼ˆ2005ï¼‰ï¼‰æ˜¯2000å¹´ä»£åˆå¼€å§‹çš„å¯¹ç¥ç»ç½‘ç»œæ¨¡å‹é‡æ–°äº§ç”Ÿå…´è¶£çš„èµ·ç‚¹ï¼Œåæ¥è¢«ç§°ä¸ºæ·±åº¦å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "To understand how Shannonâ€™s entropy model works, consider the example of a set of 52 different playing cards. The probability of randomly selecting any specific card i from this set, P(card = i), is quite low, just . The entropy of the set of 52 playing cards is calculated",
            "zh": "è¦ç†è§£é¦™å†œçš„ç†µæ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè¯·è€ƒè™‘ä¸€ç»„ 52 å¼ ä¸åŒæ‰‘å…‹ç‰Œçš„ä¾‹å­ã€‚ä»è¿™ç»„ Pï¼ˆcard = iï¼‰ ä¸­éšæœºé€‰æ‹©ä»»ä½•ç‰¹å®šç‰Œ i çš„æ¦‚ç‡éå¸¸ä½ï¼Œåªæ˜¯ .è®¡ç®—ä¸€ç»„ 52 å¼ æ‰‘å…‹ç‰Œçš„ç†µ"
        }
    },
    {
        "translation": {
            "en": "An information gain score for a feature that matches the entropy for the entire dataset indicates that the feature is perfectly discriminatory with respect to the target feature values.",
            "zh": "ä¸æ•´ä¸ªæ•°æ®é›†çš„ç†µåŒ¹é…çš„ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šåˆ†æ•°è¡¨ç¤ºè¯¥ç‰¹å¾ç›¸å¯¹äºç›®æ ‡ç‰¹å¾å€¼å…·æœ‰å®Œå…¨çš„åˆ¤åˆ«åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "We only need to calculate the relative likelihood of a continuous feature taking a value given different levels of a target feature.",
            "zh": "æˆ‘ä»¬åªéœ€è¦è®¡ç®—è¿ç»­ç‰¹å¾åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çš„ä¸åŒçº§åˆ«æ—¶å–å€¼çš„ç›¸å¯¹ä¼¼ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence it is worth emphasizing that we are using this convergence criterion only for ease of explanation, and in general we recommend that you use early stopping when you are training a neural network.",
            "zh": "å› æ­¤ï¼Œå€¼å¾—å¼ºè°ƒçš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ”¶æ•›æ ‡å‡†åªæ˜¯ä¸ºäº†ä¾¿äºè§£é‡Šï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬å»ºè®®ä½ åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ä½¿ç”¨æå‰åœæ­¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset; and (b) the scatter plot from (a) with a linear model relating RENTAL PRICE to SIZE overlaid.",
            "zh": "ï¼ˆaï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†ä¸­â€œå¤§å°â€å’Œâ€œç§Ÿé‡‘ä»·æ ¼â€ç‰¹å¾çš„æ•£ç‚¹å›¾;ï¼ˆbï¼‰æ¥è‡ªï¼ˆaï¼‰çš„æ•£ç‚¹å›¾ï¼Œå…¶ä¸­å åŠ äº†ä¸RENTAL PRICEå’ŒSIZEç›¸å…³çš„çº¿æ€§æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.1[705] shows illustrations of these different galaxy types.",
            "zh": "å›¾13.1[705]æ˜¾ç¤ºäº†è¿™äº›ä¸åŒæ˜Ÿç³»ç±»å‹çš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Post-pruning relies on a criterion that can distinguish between subtrees that model relevant aspects of the data and subtrees that model irrelevant random patterns in the data.",
            "zh": "ä¿®å‰ªåä¾èµ–äºä¸€ä¸ªæ ‡å‡†ï¼Œè¯¥æ ‡å‡†å¯ä»¥åŒºåˆ†å¯¹æ•°æ®ç›¸å…³æ–¹é¢è¿›è¡Œå»ºæ¨¡çš„å­æ ‘å’Œå¯¹æ•°æ®ä¸­ä¸ç›¸å…³çš„éšæœºæ¨¡å¼è¿›è¡Œå»ºæ¨¡çš„å­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.7(a)[754] shows the frequency histogram for the TRAINING EXPENSES feature when we define ten 200-unit intervals spanning the range that this feature can take (the frequencies come from Table A.4(a)[755]).",
            "zh": "å›¾ A.7ï¼ˆaï¼‰[754] æ˜¾ç¤ºäº†å½“æˆ‘ä»¬å®šä¹‰è·¨è¶Šè¯¥ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„èŒƒå›´çš„ 10 ä¸ª 200 å•ä½é—´éš”æ—¶ï¼ŒTRAINING EXPENSES ç‰¹å¾çš„é¢‘ç‡ç›´æ–¹å›¾ï¼ˆé¢‘ç‡æ¥è‡ªè¡¨ A.4ï¼ˆaï¼‰[755]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once this happens, the target probability can be computed by calculating the relative frequency of the event within the selected subset of generated states.",
            "zh": "ä¸€æ—¦å‘ç”Ÿè¿™ç§æƒ…å†µï¼Œå°±å¯ä»¥é€šè¿‡è®¡ç®—æ‰€é€‰ç”ŸæˆçŠ¶æ€å­é›†ä¸­äº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡æ¥è®¡ç®—ç›®æ ‡æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "boosting, 159, 159, 171, 178, 179, 733, 735",
            "zh": "æå‡ï¼Œ 159ï¼Œ 159ï¼Œ 171ï¼Œ 178ï¼Œ 179ï¼Œ 733ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "Hence Î´i,j is the Î´ value for neuron i for example j.",
            "zh": "å› æ­¤ï¼ŒÎ´iï¼Œj æ˜¯ç¥ç»å…ƒ i çš„Î´å€¼ï¼Œä¾‹å¦‚ jã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, during backpropagation no error gradients flow back through the dropped neurons; their Î´s are set to 0.",
            "zh": "æ­¤å¤–ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæ²¡æœ‰è¯¯å·®æ¢¯åº¦æµå›æ‰è½çš„ç¥ç»å…ƒ;å®ƒä»¬çš„ Î´ è®¾ç½®ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, care must be taken to ensure that the objective function used by the search process avoids overfitting the data by simply creating a very highly connected graph.",
            "zh": "å› æ­¤ï¼Œå¿…é¡»æ³¨æ„ç¡®ä¿æœç´¢è¿‡ç¨‹ä½¿ç”¨çš„ç›®æ ‡å‡½æ•°é€šè¿‡ç®€å•åœ°åˆ›å»ºä¸€ä¸ªé«˜åº¦è¿æ¥çš„å›¾æ¥é¿å…æ•°æ®è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "One way of counterbalancing this tendency is to use a distance weighted k nearest neighbor approach.",
            "zh": "å¹³è¡¡è¿™ç§è¶‹åŠ¿çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è·ç¦»åŠ æƒ k æœ€è¿‘é‚»æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Other: There are no restrictions to the ways in which we can combine data to make derived features.",
            "zh": "å…¶ä»–ï¼šæˆ‘ä»¬ç»„åˆæ•°æ®ä»¥ç”Ÿæˆæ´¾ç”Ÿç‰¹å¾çš„æ–¹å¼æ²¡æœ‰é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(a)[74] shows an example scatter plot for the HEIGHT and WEIGHT features from the dataset in Table 3.7[73].",
            "zh": "å›¾3.5ï¼ˆaï¼‰[74]æ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­HEIGHTå’ŒWEIGHTç‰¹å¾çš„æ•£ç‚¹å›¾ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Transitions into the BUST or LOSE states return a reward of âˆ’ 1, transitions into the TIE state earn a reward of 0, transitions into the WIN state return a reward of + 1, and transitions into the TWENTYTWO state return a reward of + 2.",
            "zh": "è¿‡æ¸¡åˆ° BUST æˆ– LOSE çŠ¶æ€è¿”å› âˆ’ 1 çš„å¥–åŠ±ï¼Œè¿‡æ¸¡åˆ° TIE çŠ¶æ€è·å¾— 0 çš„å¥–åŠ±ï¼Œè¿‡æ¸¡åˆ° WIN çŠ¶æ€è¿”å› + 1 çš„å¥–åŠ±ï¼Œè¿‡æ¸¡åˆ° TWENTYTWO çŠ¶æ€è¿”å› + 2 çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "It quickly became apparent that the key data resources within AT that would be important for this project were",
            "zh": "å¾ˆæ˜æ˜¾ï¼ŒATä¸­å¯¹è¿™ä¸ªé¡¹ç›®å¾ˆé‡è¦çš„å…³é”®æ•°æ®èµ„æºæ˜¯"
        }
    },
    {
        "translation": {
            "en": "So, âˆ‘iP(Xi) should be interpreted as summing over all the possible combinations of value assignments to the features in X.",
            "zh": "å› æ­¤ï¼Œâˆ‘iPï¼ˆä¹ ï¼‰ åº”è¯¥è¢«è§£é‡Šä¸º X ä¸­ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½çš„å€¼èµ‹å€¼ç»„åˆçš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem with this, however, is that generating full joint probability distributions suffers from the curse of dimensionality, and as a result, this approach is not tractable for domains involving more than a few features.",
            "zh": "ç„¶è€Œï¼Œè¿™æ ·åšçš„é—®é¢˜åœ¨äºï¼Œç”Ÿæˆå®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒä¼šå—åˆ°ç»´æ•°çš„è¯…å’’ï¼Œå› æ­¤ï¼Œè¿™ç§æ–¹æ³•å¯¹äºæ¶‰åŠå¤šä¸ªç‰¹å¾çš„åŸŸæ¥è¯´æ˜¯ä¸å¯è¡Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following is a query instance for the fraud detection domain:",
            "zh": "ä»¥ä¸‹æ˜¯æ¬ºè¯ˆæ£€æµ‹åŸŸçš„æŸ¥è¯¢å®ä¾‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Through the 1950s and 1960s there was a lot of interest in neural networks.",
            "zh": "åœ¨ 1950 å¹´ä»£å’Œ 1960 å¹´ä»£ï¼Œäººä»¬å¯¹ç¥ç»ç½‘ç»œäº§ç”Ÿäº†æµ“åšçš„å…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "After remaining in the RECOVERED state for some time, P(R R) = 0.20, most people will soon transition back to the SUSCEPTIBLE state, P(R S) = 0.75, but a small part of the population will instead relapse and return to the INFECTED state, P(R I) = 0.05.",
            "zh": "åœ¨ä¿æŒæ¢å¤çŠ¶æ€ä¸€æ®µæ—¶é—´åï¼ŒPï¼ˆR Rï¼‰ = 0.20ï¼Œå¤§å¤šæ•°äººå°†å¾ˆå¿«è¿‡æ¸¡åˆ°æ˜“æ„ŸçŠ¶æ€ï¼ŒPï¼ˆR Sï¼‰ = 0.75ï¼Œä½†ä¸€å°éƒ¨åˆ†äººä¼šå¤å‘å¹¶å›åˆ°æ„ŸæŸ“çŠ¶æ€ï¼ŒPï¼ˆR Iï¼‰ = 0.05ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, TACHYCARDIA and is composed of three plots: a plot of the distribution of the descriptive feature values in the full dataset, and plots showing the distribution of the descriptive feature values for each level of the target.",
            "zh": "æ¯ä¸ªå¯è§†åŒ–éƒ½è¯´æ˜äº†æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ï¼ˆå¿ƒåŠ¨è¿‡é€Ÿï¼‰ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ç”±ä¸‰ä¸ªå›¾ç»„æˆï¼šå®Œæ•´æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾å€¼çš„åˆ†å¸ƒå›¾ï¼Œä»¥åŠæ˜¾ç¤ºç›®æ ‡æ¯ä¸ªçº§åˆ«çš„æè¿°æ€§ç‰¹å¾å€¼åˆ†å¸ƒçš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "We know from this result that the probability for CPI = low must be 0.8. So, the network will predict CPI = low as the MAP target value for the query. This tells us that an unequal society that has a good education system but for which we have no evidence about the health system is still likely to suffer from corruption.",
            "zh": "æˆ‘ä»¬ä»è¿™ä¸ªç»“æœä¸­çŸ¥é“ï¼ŒCPI = ä½çš„æ¦‚ç‡å¿…é¡»ä¸º 0.8ã€‚å› æ­¤ï¼Œç½‘ç»œå°†é¢„æµ‹ CPI = low ä½œä¸ºæŸ¥è¯¢çš„ MAP ç›®æ ‡å€¼ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬ï¼Œä¸€ä¸ªä¸å¹³ç­‰çš„ç¤¾ä¼šï¼Œå¦‚æœæœ‰ä¸€ä¸ªè‰¯å¥½çš„æ•™è‚²ç³»ç»Ÿï¼Œä½†æˆ‘ä»¬æ²¡æœ‰å…³äºå«ç”Ÿç³»ç»Ÿçš„è¯æ®ï¼Œä»ç„¶æœ‰å¯èƒ½é­å—è…è´¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This new type of radiation was named the N ray (after the University of Nancy), and experiments were designed to demonstrate its existence.",
            "zh": "è¿™ç§æ–°å‹è¾å°„è¢«å‘½åä¸ºNå°„çº¿ï¼ˆä»¥å—é”¡å¤§å­¦çš„åå­—å‘½åï¼‰ï¼Œå¹¶è®¾è®¡äº†å®éªŒæ¥è¯æ˜å®ƒçš„å­˜åœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, neurons A and B are both in the receptive field of Neuron C, but neither A nor B feeds forward into any of the other neurons in the sub-sampling layer.",
            "zh": "ä¾‹å¦‚ï¼Œç¥ç»å…ƒ A å’Œ B éƒ½ä½äºç¥ç»å…ƒ C çš„æ„Ÿå—é‡ä¸­ï¼Œä½† A å’Œ B éƒ½æ²¡æœ‰è½¬å‘åˆ°å­é‡‡æ ·å±‚ä¸­çš„ä»»ä½•å…¶ä»–ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a simple random sample is the most straightforward way of avoiding biased samples.",
            "zh": "ä½¿ç”¨ç®€å•çš„éšæœºæ ·æœ¬æ˜¯é¿å…æœ‰åå·®æ ·æœ¬çš„æœ€ç›´æ¥æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "intelligent agent, 638, 639, 643, 676, 677",
            "zh": "æ™ºèƒ½ä»£ç†ï¼Œ 638ï¼Œ 639ï¼Œ 643ï¼Œ 676ï¼Œ 677"
        }
    },
    {
        "translation": {
            "en": "root node, 121",
            "zh": "æ ¹èŠ‚ç‚¹ï¼Œ121"
        }
    },
    {
        "translation": {
            "en": "The distributions of the outputs of a model",
            "zh": "æ¨¡å‹è¾“å‡ºçš„åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "3. âˆ‚â„°t+1/âˆ‚ct: the rate of change of the error of the network at time-step t+1 with respect to changes in the cell state ct that was propagated forward to the next time-step during the forward pass.",
            "zh": "3. âˆ‚Et+1/âˆ‚ctï¼šç½‘ç»œåœ¨æ—¶é—´æ­¥é•¿ t+1 å¤„çš„è¯¯å·®ç›¸å¯¹äºåœ¨å‰å‘ä¼ é€’æœŸé—´å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„å•å…ƒçŠ¶æ€ ct å˜åŒ–çš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using linear units in the output layer means that the output of the network can have the same range as the non-normalized target feature.",
            "zh": "åœ¨è¾“å‡ºå›¾å±‚ä¸­ä½¿ç”¨çº¿æ€§å•ä½æ„å‘³ç€ç½‘ç»œçš„è¾“å‡ºå¯ä»¥ä¸éå½’ä¸€åŒ–ç›®æ ‡è¦ç´ å…·æœ‰ç›¸åŒçš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "These cumulative probability distributions can be plotted on a Kolmogorov-Smirnov chart (K-S chart).",
            "zh": "è¿™äº›ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒå¯ä»¥ç»˜åˆ¶åœ¨ Kolmogorov-Smirnov æ§åˆ¶å›¾ï¼ˆK-S æ§åˆ¶å›¾ï¼‰ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.5â€ƒTemporal-Difference Learning",
            "zh": "11.2.5 æ—¶å·®å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Doing this requires us to store the parameters of the model each time we observe a drop in the validation error.",
            "zh": "è¿™æ ·åšéœ€è¦æˆ‘ä»¬åœ¨æ¯æ¬¡è§‚å¯Ÿåˆ°éªŒè¯è¯¯å·®ä¸‹é™æ—¶å­˜å‚¨æ¨¡å‹çš„å‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5(a)[38] shows these two different periods, assuming that the customerâ€™s shopping behavior was measured from August 2012 through January 2013, and that whether they bought the product of interest was observed from February 2013 through April 2013.",
            "zh": "å›¾2.5ï¼ˆaï¼‰[38]æ˜¾ç¤ºäº†è¿™ä¸¤ä¸ªä¸åŒçš„æ—¶æœŸï¼Œå‡è®¾å®¢æˆ·çš„è´­ç‰©è¡Œä¸ºæ˜¯ä»2012å¹´8æœˆåˆ°2013å¹´1æœˆæµ‹é‡çš„ï¼Œè€Œä»–ä»¬æ˜¯å¦è´­ä¹°äº†æ„Ÿå…´è¶£çš„äº§å“æ˜¯ä»2013å¹´2æœˆåˆ°2013å¹´4æœˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In the context of model ensembles, this means that each model should make predictions independently of the other models in the ensemble.",
            "zh": "åœ¨æ¨¡å‹é›†æˆçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªæ¨¡å‹éƒ½åº”ç‹¬ç«‹äºé›†æˆä¸­çš„å…¶ä»–æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, data analysts need to think about the sources of the data they are using and understand how the data was collected and whether the collection processes introduced a bias relative to the population.",
            "zh": "å› æ­¤ï¼Œæ•°æ®åˆ†æå¸ˆéœ€è¦è€ƒè™‘ä»–ä»¬æ­£åœ¨ä½¿ç”¨çš„æ•°æ®æ¥æºï¼Œå¹¶äº†è§£æ•°æ®æ˜¯å¦‚ä½•æ”¶é›†çš„ï¼Œä»¥åŠæ”¶é›†è¿‡ç¨‹æ˜¯å¦å¼•å…¥äº†ç›¸å¯¹äºæ€»ä½“çš„åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.22",
            "zh": "å›¾ 8.22"
        }
    },
    {
        "translation": {
            "en": "5.8â€…â€…â€…Exercises",
            "zh": "5.8 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "In this instance, the human expert specifies that topology of the network, and the learning algorithm induces the CPT entries for nodes in the topology in the same way that we computed the conditional probabilities for the naive Bayes model.25",
            "zh": "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œäººç±»ä¸“å®¶æŒ‡å®šäº†ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ï¼Œå­¦ä¹ ç®—æ³•ä»¥æˆ‘ä»¬è®¡ç®—æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ¡ä»¶æ¦‚ç‡çš„æ–¹å¼è¯±å¯¼æ‹“æ‰‘ä¸­èŠ‚ç‚¹çš„ CPT æ¡ç›®25ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.8â€…â€…â€…The confusion matrix for the 5-level logistic regression model (classification accuracy: 77.528%, average class accuracy: 43.018%).",
            "zh": "13.8 äº”çº§logisticå›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š77.528%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š43.018%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The expectation maximization algorithm sits behind all of these and more than warrants careful study (Moon, 1996).",
            "zh": "æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ä½äºæ‰€æœ‰è¿™äº›ç®—æ³•çš„èƒŒåï¼Œå€¼å¾—ä»”ç»†ç ”ç©¶ï¼ˆMoonï¼Œ1996ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "22. Note that TwentyTwos is a much easier game to win than Blackjack, in which it is well known that the house always wins!",
            "zh": "22. è¯·æ³¨æ„ï¼ŒTwentyTwos æ˜¯ä¸€æ¬¾æ¯”äºŒåä¸€ç‚¹æ›´å®¹æ˜“è·èƒœçš„æ¸¸æˆï¼Œä¼—æ‰€å‘¨çŸ¥ï¼Œåœ¨äºŒåä¸€ç‚¹ä¸­ï¼Œæˆ¿å­æ€»æ˜¯èµ¢ï¼"
        }
    },
    {
        "translation": {
            "en": "Examples were labeled as donâ€™t know when a Galaxy Zoo participant could not place the object in question into one of the other categories.",
            "zh": "ç¤ºä¾‹è¢«æ ‡è®°ä¸ºä¸çŸ¥é“é“¶æ²³åŠ¨ç‰©å›­å‚ä¸è€…ä½•æ—¶æ— æ³•å°†æœ‰é—®é¢˜çš„ç‰©ä½“æ”¾å…¥å…¶ä»–ç±»åˆ«ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "FIBERFLUXIVAR_U/G/R/I/Z",
            "zh": "FIBERFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "To successfully model the relationship between grass growth and rainfall, we need to introduce non-linear elements.",
            "zh": "ä¸ºäº†æˆåŠŸåœ°æ¨¡æ‹Ÿè‰ç”Ÿé•¿å’Œé™é›¨ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥éçº¿æ€§å•å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The position of your body on the board is key to doing this successfully.",
            "zh": "ä½ çš„èº«ä½“åœ¨æ£‹ç›˜ä¸Šçš„ä½ç½®æ˜¯æˆåŠŸåšåˆ°è¿™ä¸€ç‚¹çš„å…³é”®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this network the neurons are organized into a sequence of layers.",
            "zh": "åœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œç¥ç»å…ƒè¢«ç»„ç»‡æˆä¸€ç³»åˆ—å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The values for these cluster centroids can be selected randomly following uniform distributions bounded by the minimum and maximum values of each feature.",
            "zh": "è¿™äº›èšç±»è´¨å¿ƒçš„å€¼å¯ä»¥æŒ‰ç…§å‡åŒ€åˆ†å¸ƒéšæœºé€‰æ‹©ï¼Œè¿™äº›åˆ†å¸ƒç”±æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2492",
            "zh": "0.2492"
        }
    },
    {
        "translation": {
            "en": "To calculate gain and lift, we first rank the predictions made for a test set in descending order by prediction score and then divide them into deciles.18 A decile is a group containing 10% of a dataset. Table 9.15[568] shows the data from Table 9.11[557] divided into deciles. There are 20 instances, so each decile contains just 2 instances. The first decile contains instances 9 and 4, the second decile contains instances 18 and 20, and so on.",
            "zh": "ä¸ºäº†è®¡ç®—å¢ç›Šå’Œæå‡ï¼Œæˆ‘ä»¬é¦–å…ˆæŒ‰é¢„æµ‹åˆ†æ•°æŒ‰é™åºå¯¹æµ‹è¯•é›†æ‰€åšçš„é¢„æµ‹è¿›è¡Œæ’åï¼Œç„¶åå°†å®ƒä»¬åˆ’åˆ†ä¸ºååˆ†ä½æ•°.18 ååˆ†ä½æ•°æ˜¯åŒ…å«æ•°æ®é›† 10% çš„ç»„ã€‚è¡¨9.15[568]æ˜¾ç¤ºäº†è¡¨9.11[557]ä¸­çš„æ•°æ®ï¼Œè¿™äº›æ•°æ®è¢«åˆ’åˆ†ä¸ºååˆ†ä½æ•°ã€‚æœ‰ 20 ä¸ªå®ä¾‹ï¼Œå› æ­¤æ¯ä¸ªååˆ†ä½æ•°ä»…åŒ…å« 2 ä¸ªå®ä¾‹ã€‚ç¬¬ä¸€ä¸ªååˆ†ä½æ•°åŒ…å«å®ä¾‹ 9 å’Œ 4ï¼Œç¬¬äºŒä¸ªååˆ†ä½æ•°åŒ…å«å®ä¾‹ 18 å’Œ 20ï¼Œä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce some of the fundamental operations in linear algebra. In particular, we introduce the vector and matrix operations that we use in the book.",
            "zh": "åœ¨æœ¬é™„å½•ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†çº¿æ€§ä»£æ•°ä¸­çš„ä¸€äº›åŸºæœ¬è¿ç®—ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ä»‹ç»äº†æˆ‘ä»¬åœ¨ä¹¦ä¸­ä½¿ç”¨çš„å‘é‡å’ŒçŸ©é˜µè¿ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This analysis shows that adding layers to a network without including a non-linear activation function between the layers appears to add complexity to the network, but in reality the network remains equivalent to a single-layer linear network.",
            "zh": "è¯¥åˆ†æè¡¨æ˜ï¼Œåœ¨ç½‘ç»œä¸­æ·»åŠ å±‚è€Œä¸åœ¨å±‚ä¹‹é—´åŒ…å«éçº¿æ€§æ¿€æ´»å‡½æ•°ä¼¼ä¹å¢åŠ äº†ç½‘ç»œçš„å¤æ‚æ€§ï¼Œä½†å®é™…ä¸Šç½‘ç»œä»ç„¶ç­‰åŒäºå•å±‚çº¿æ€§ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we are dealing with binary features, it may be more appropriate to use the Russel-Rao, Sokal-Michener, or Jaccard similarity metric.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¤„ç†çš„æ˜¯äºŒè¿›åˆ¶ç‰¹å¾ï¼Œé‚£ä¹ˆä½¿ç”¨ Russel-Raoã€Sokal-Michener æˆ– Jaccard ç›¸ä¼¼åº¦é‡å¯èƒ½æ›´åˆé€‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This approach, however, can result in significant amounts of data loss and can introduce a bias into the dataset if the distribution of missing values in the dataset is not completely random.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæ•°æ®é›†ä¸­ç¼ºå¤±å€¼çš„åˆ†å¸ƒä¸æ˜¯å®Œå…¨éšæœºçš„ï¼Œåˆ™è¿™ç§æ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´å¤§é‡æ•°æ®ä¸¢å¤±ï¼Œå¹¶ä¸”å¯èƒ½ä¼šåœ¨æ•°æ®é›†ä¸­å¼•å…¥åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This shows how the misclassification rate made by a model on a set of training instances changes as the training process continues.",
            "zh": "è¿™æ˜¾ç¤ºäº†æ¨¡å‹åœ¨ä¸€ç»„è®­ç»ƒå®ä¾‹ä¸Šçš„é”™è¯¯åˆ†ç±»ç‡å¦‚ä½•éšç€è®­ç»ƒè¿‡ç¨‹çš„ç»§ç»­è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Different heuristics are often used for the bias terms and the weights.",
            "zh": "åå·®é¡¹å’Œæƒé‡é€šå¸¸ä½¿ç”¨ä¸åŒçš„å¯å‘å¼æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A decision tree is then trained using the sample, and it is used to make predictions for each instance in the complete training set.",
            "zh": "ç„¶åä½¿ç”¨æ ·æœ¬è®­ç»ƒå†³ç­–æ ‘ï¼Œå¹¶ä½¿ç”¨å®ƒå¯¹å®Œæ•´è®­ç»ƒé›†ä¸­çš„æ¯ä¸ªå®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Zadnik, Karla, Lisa A. Jones, Brett C. Irvin, Robert N. Kleinstein, Ruth E. Manny, Julie A. Shin, and Donald O. Mutti. 2000. Vision: Myopia and ambient night-time lighting. Nature 404 (6774): 143â€“144. http://dx.doi.org/10.1038/35004661.",
            "zh": "Zadnikã€Karlaã€Lisa A. Jonesã€Brett C. Irvinã€Robert N. Kleinsteinã€Ruth E. Mannyã€Julie A. Shin å’Œ Donald O. Muttiã€‚2000. è§†è§‰ï¼šè¿‘è§†å’Œå¤œé—´ç¯å¢ƒç…§æ˜ã€‚è‡ªç„¶404ï¼ˆ6774ï¼‰ï¼š143-144ã€‚http://dx.doi.org/10.1038/35004661ã€‚"
        }
    },
    {
        "translation": {
            "en": "locality sensitive hashing, 233",
            "zh": "å±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼Œ233"
        }
    },
    {
        "translation": {
            "en": "7. Stochastic gradient descent is a slightly different approach, in which an adjustment to each weight is made on the basis of the error in the prediction made by the candidate model for each training instance individually. This means that many more adjustments are made to the weights. We do not discuss stochastic gradient descent in any detail in this book, although the modifications that need to be made to the gradient descent algorithm for stochastic gradient descent are fairly simple.",
            "zh": "7. éšæœºæ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ç•¥æœ‰ä¸åŒçš„æ–¹æ³•ï¼Œå…¶ä¸­æ ¹æ®å€™é€‰æ¨¡å‹å¯¹æ¯ä¸ªè®­ç»ƒå®ä¾‹çš„é¢„æµ‹è¯¯å·®å¯¹æ¯ä¸ªæƒé‡è¿›è¡Œè°ƒæ•´ã€‚è¿™æ„å‘³ç€å¯¹æƒé‡è¿›è¡Œäº†æ›´å¤šçš„è°ƒæ•´ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰è¯¦ç»†è®¨è®ºéšæœºæ¢¯åº¦ä¸‹é™ï¼Œå°½ç®¡éœ€è¦å¯¹éšæœºæ¢¯åº¦ä¸‹é™çš„æ¢¯åº¦ä¸‹é™ç®—æ³•è¿›è¡Œä¿®æ”¹ç›¸å½“ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hand, David, 586",
            "zh": "æ‰‹ï¼Œå¤§å«ï¼Œ586"
        }
    },
    {
        "translation": {
            "en": "The most common way to tackle this issue is to perform evaluation experiments to investigate the performance of models with different values for k and to select the one that performs best.",
            "zh": "è§£å†³æ­¤é—®é¢˜çš„æœ€å¸¸è§æ–¹æ³•æ˜¯æ‰§è¡Œè¯„ä¼°å®éªŒï¼Œä»¥è°ƒæŸ¥å…·æœ‰ä¸åŒ k å€¼çš„æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶é€‰æ‹©æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The issue with redundant and irrelevant features is inherent in any large dataset, and the feature selection techniques described in this chapter are generally applicable when any type of machine learning algorithm is being used.",
            "zh": "å†—ä½™å’Œä¸ç›¸å…³çš„ç‰¹å¾é—®é¢˜æ˜¯ä»»ä½•å¤§å‹æ•°æ®é›†æ‰€å›ºæœ‰çš„ï¼Œæœ¬ç« ä¸­æè¿°çš„ç‰¹å¾é€‰æ‹©æŠ€æœ¯é€šå¸¸é€‚ç”¨äºä½¿ç”¨ä»»ä½•ç±»å‹çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, calculating a direction of descent by taking an average over a set of noisy examples can make the descent of the error surface smoother, which often means that we can use a larger learning rate Î± with batch gradient descent (i.e., we can take larger steps between weight updates because we are more confident of the direction we are moving).",
            "zh": "æ­¤å¤–ï¼Œé€šè¿‡å¯¹ä¸€ç»„å˜ˆæ‚çš„ç¤ºä¾‹å–å¹³å‡å€¼æ¥è®¡ç®—ä¸‹é™æ–¹å‘å¯ä»¥ä½¿è¯¯å·®æ›²é¢çš„ä¸‹é™æ›´å¹³æ»‘ï¼Œè¿™é€šå¸¸æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡Î±æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆå³ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æƒé‡æ›´æ–°ä¹‹é—´é‡‡å–æ›´å¤§çš„æ­¥éª¤ï¼Œå› ä¸ºæˆ‘ä»¬å¯¹ç§»åŠ¨çš„æ–¹å‘æ›´æœ‰ä¿¡å¿ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 12.6",
            "zh": "å›¾ 12.6"
        }
    },
    {
        "translation": {
            "en": "An agent behaving in an environment and the observation, reward, action cycle. The transition from observations of the environment to a state is shown by the state generation function, Ï•.",
            "zh": "æ™ºèƒ½ä½“åœ¨ç¯å¢ƒä¸­çš„è¡Œä¸ºä»¥åŠè§‚å¯Ÿã€å¥–åŠ±ã€è¡ŒåŠ¨å¾ªç¯ã€‚ä»ç¯å¢ƒè§‚å¯Ÿåˆ°çŠ¶æ€çš„è½¬å˜ç”±çŠ¶æ€ç”Ÿæˆå‡½æ•° Ï† è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.5",
            "zh": "è¡¨ 3.5"
        }
    },
    {
        "translation": {
            "en": "13.1.1â€…â€…â€…Situational Fluency",
            "zh": "13.1.1 æƒ…å¢ƒæµç•…æ€§"
        }
    },
    {
        "translation": {
            "en": "Calculate the missing point in the ROC curves for Model 1 and Model 2. To generate the point for Model 1, use a threshold value of 0.51. To generate the point for Model 2, use a threshold value of 0.43.",
            "zh": "è®¡ç®—æ¨¡å‹ 1 å’Œæ¨¡å‹ 2 çš„ ROC æ›²çº¿ä¸­çš„ç¼ºå¤±ç‚¹ã€‚è¦ç”Ÿæˆæ¨¡å‹ 1 çš„ç‚¹ï¼Œè¯·ä½¿ç”¨é˜ˆå€¼ 0.51ã€‚è¦ç”Ÿæˆæ¨¡å‹ 2 çš„ç‚¹ï¼Œè¯·ä½¿ç”¨é˜ˆå€¼ 0.43ã€‚"
        }
    },
    {
        "translation": {
            "en": "In statistics the degrees of freedom of a distribution is the number of variables in the calculation of the statistic that are free to vary.",
            "zh": "åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œåˆ†å¸ƒçš„è‡ªç”±åº¦æ˜¯ç»Ÿè®¡é‡è®¡ç®—ä¸­å¯ä»¥è‡ªç”±å˜åŒ–çš„å˜é‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.18[440] shows the forward propagation of the examples in Table 8.3[423] through the same network that we used in the worked example, with the single difference that all the neurons in the network are now ReLUs.24 Table 8.10[441] lists the per example error of this ReLU network resulting from the forward pass in Figure 8.18[440]. This table also lists the sum of squared errors for the ReLU model.25",
            "zh": "å›¾8.18[440]æ˜¾ç¤ºäº†è¡¨8.3[423]ä¸­ç¤ºä¾‹é€šè¿‡æˆ‘ä»¬åœ¨å·¥ä½œç¤ºä¾‹ä¸­ä½¿ç”¨çš„ç›¸åŒç½‘ç»œçš„å‰å‘ä¼ æ’­ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯ç½‘ç»œä¸­çš„æ‰€æœ‰ç¥ç»å…ƒç°åœ¨éƒ½æ˜¯ReLU.24è¡¨8.10[441]åˆ—å‡ºäº†å›¾8.18[440]ä¸­å‰å‘ä¼ é€’å¯¼è‡´çš„ReLUç½‘ç»œçš„æ¯ä¸ªç¤ºä¾‹é”™è¯¯ã€‚æ­¤è¡¨è¿˜åˆ—å‡ºäº† ReLU æ¨¡å‹çš„å¹³æ–¹è¯¯å·®æ€»å’Œ25ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see the assumptions encoded in each algorithm reflected in the distinctive characteristics of the decision boundaries that they learn for categorical prediction tasks.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªç®—æ³•ä¸­ç¼–ç çš„å‡è®¾åæ˜ åœ¨å®ƒä»¬ä¸ºåˆ†ç±»é¢„æµ‹ä»»åŠ¡å­¦ä¹ çš„å†³ç­–è¾¹ç•Œçš„æ˜¾ç€ç‰¹å¾ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy to understand the sequences of tests a decision tree carried out in order to make a prediction.",
            "zh": "ç†è§£å†³ç­–æ ‘ä¸ºäº†åšå‡ºé¢„æµ‹è€Œæ‰§è¡Œçš„æµ‹è¯•åºåˆ—ç›¸å¯¹å®¹æ˜“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Parametric",
            "zh": "å‚æ•°"
        }
    },
    {
        "translation": {
            "en": "To help with this, we would recommend Hastie et al.",
            "zh": "ä¸ºäº†å¸®åŠ©è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨è Hastie ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, many domains in which the data has a sequential varying-length structure and in which interactions between data points may span long distances in the sequence.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨è®¸å¤šåŸŸä¸­ï¼Œæ•°æ®å…·æœ‰é¡ºåºå¯å˜é•¿åº¦ç»“æ„ï¼Œå¹¶ä¸”æ•°æ®ç‚¹ä¹‹é—´çš„äº¤äº’å¯èƒ½è·¨è¶Šåºåˆ—ä¸­çš„é•¿è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence dropout can be understood as a regularization technique that improves the stability of the resulting model.",
            "zh": "å› æ­¤ï¼Œdropout å¯ä»¥ç†è§£ä¸ºä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¯ä»¥æé«˜ç»“æœæ¨¡å‹çš„ç¨³å®šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The values in Table 11.2[654] actually show the entries in the action-value table learned for TwentyTwos after 100,000 episodes of Q-learning.21 Examining the actions with the maximum expected return in each state shows that the target policy learned is overwhelmingly to Stick, with Twist being the best action only in the PL-DL, PL-DH, and PM-DH states.",
            "zh": "è¡¨ 11.2[654] ä¸­çš„å€¼å®é™…ä¸Šæ˜¾ç¤ºäº† 100,000 é›† Q-learning åä¸º TwentyTwos å­¦ä¹ çš„åŠ¨ä½œå€¼è¡¨ä¸­çš„æ¡ç›®ã€‚21 æ£€æŸ¥æ¯ä¸ªçŠ¶æ€ä¸­å…·æœ‰æœ€å¤§é¢„æœŸå›æŠ¥çš„åŠ¨ä½œè¡¨æ˜ï¼Œå­¦ä¹ çš„ç›®æ ‡ç­–ç•¥ç»å¤§å¤šæ•°æ˜¯åšæŒï¼Œè€Œ Twist ä»…åœ¨ PL-DLã€PL-DH å’Œ PM-DH çŠ¶æ€ä¸­æ˜¯æœ€ä½³åŠ¨ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Îµ0 bootstrap, 546",
            "zh": "Îµ0 è‡ªä¸¾ï¼Œ546"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we want to compute the probability of P(h) in the domain specified by the joint probability distribution P(H,F,V,M).",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬è¦è®¡ç®—ç”±è”åˆæ¦‚ç‡åˆ†å¸ƒ Pï¼ˆHï¼ŒFï¼ŒVï¼ŒMï¼‰ æŒ‡å®šçš„åŸŸä¸­ Pï¼ˆhï¼‰ çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we provide a short overview of the technical notation used throughout this book.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç®€è¦æ¦‚è¿°æœ¬ä¹¦ä¸­ä½¿ç”¨çš„æŠ€æœ¯ç¬¦å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table A.2",
            "zh": "è¡¨ A.2"
        }
    },
    {
        "translation": {
            "en": "data fragmentation, 255, 262",
            "zh": "æ•°æ®ç¢ç‰‡ï¼Œ 255ï¼Œ 262"
        }
    },
    {
        "translation": {
            "en": "If a model were performing no better than random guessing, we would expect that within each decile, the percentage of positive instances should be the same as the percentage of positive instances overall in the complete dataset.",
            "zh": "å¦‚æœä¸€ä¸ªæ¨¡å‹çš„è¡¨ç°å¹¶ä¸æ¯”éšæœºçŒœæµ‹å¥½ï¼Œæˆ‘ä»¬é¢„è®¡åœ¨æ¯ä¸ªååˆ†ä½æ•°å†…ï¼Œé˜³æ€§å®ä¾‹çš„ç™¾åˆ†æ¯”åº”è¯¥ä¸æ•´ä¸ªæ•°æ®é›†ä¸­æ€»ä½“é˜³æ€§å®ä¾‹çš„ç™¾åˆ†æ¯”ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout this book we discuss the use of machine learning algorithms to train prediction models based on datasets. The following list explains the notation used to refer to different elements in a dataset. Figure 0.1[xxiii] illustrates the key notation using a simple sample dataset.",
            "zh": "åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•æ¥è®­ç»ƒåŸºäºæ•°æ®é›†çš„é¢„æµ‹æ¨¡å‹ã€‚ä»¥ä¸‹åˆ—è¡¨è¯´æ˜äº†ç”¨äºå¼•ç”¨æ•°æ®é›†ä¸­ä¸åŒå…ƒç´ çš„è¡¨ç¤ºæ³•ã€‚å›¾ 0.1[xxiii] ä½¿ç”¨ç®€å•çš„ç¤ºä¾‹æ•°æ®é›†è¯´æ˜äº†é”®è¡¨ç¤ºæ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important that for each feature in the ABT, we understand characteristics such as the types of values a feature can take, the ranges into which the values in a feature fall, and how the values in a dataset for a feature are distributed across the range that they can take.",
            "zh": "å¯¹äº ABT ä¸­çš„æ¯ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬å¿…é¡»äº†è§£ç‰¹å¾ï¼Œä¾‹å¦‚ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å€¼ç±»å‹ã€ç‰¹å¾ä¸­çš„å€¼æ‰€å±èŒƒå›´ä»¥åŠç‰¹å¾æ•°æ®é›†ä¸­çš„å€¼å¦‚ä½•åœ¨å®ƒä»¬å¯ä»¥é‡‡ç”¨çš„èŒƒå›´å†…åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9(a)[79] shows a histogram of the AGE feature from the dataset in Table 3.7[73].",
            "zh": "å›¾3.9ï¼ˆaï¼‰[79]æ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­AGEç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.0542",
            "zh": "0.0542"
        }
    },
    {
        "translation": {
            "en": "1. The table below lists a dataset that was used to create a nearest neighbor model that predicts whether it will be a good day to go surfing.",
            "zh": "1. ä¸‹è¡¨åˆ—å‡ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”¨äºåˆ›å»ºæœ€è¿‘é‚»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é¢„æµ‹ä»Šå¤©æ˜¯å¦æ˜¯å†²æµªçš„å¥½æ—¥å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal of k-means clustering is to take a dataset, , consisting of n instances, d1 to dn, where di is a set of m descriptive features, and divide this dataset into k disjoint clusters, 1 to k. The number of clusters to be found, k, is an input to the algorithm and each instance can belong to only one cluster.",
            "zh": "k-means èšç±»çš„ç›®æ ‡æ˜¯è·å–ä¸€ä¸ªæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”± n ä¸ªå®ä¾‹ï¼ˆd1 åˆ° dnï¼‰ç»„æˆï¼Œå…¶ä¸­ di æ˜¯ä¸€ç»„ m æè¿°æ€§ç‰¹å¾ï¼Œå¹¶å°†è¯¥æ•°æ®é›†åˆ’åˆ†ä¸º k ä¸ªä¸ç›¸äº¤èšç±»ï¼ˆ1 åˆ° kï¼‰ã€‚è¦æ‰¾åˆ°çš„èšç±»æ•° k æ˜¯ç®—æ³•çš„è¾“å…¥ï¼Œæ¯ä¸ªå®ä¾‹åªèƒ½å±äºä¸€ä¸ªèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the probability distribution for the binary feature MENINGITIS from Table 6.1[246] is P(MENINGITIS) = 0.3,0.7 (by convention we give the true probability first).",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨ 6.1[246] ä¸­äºŒå…ƒç‰¹å¾è„‘è†œç‚çš„æ¦‚ç‡åˆ†å¸ƒä¸º Pï¼ˆMENINGITISï¼‰ = 0.3,0.7ï¼ˆæŒ‰ç…§æƒ¯ä¾‹ï¼Œæˆ‘ä»¬é¦–å…ˆç»™å‡ºçœŸå®æ¦‚ç‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This last issue is interesting because sometimes particular performance measures become especially popular in certain industries, and in many cases, this dictates the choice of performance measure.",
            "zh": "æœ€åä¸€ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€ï¼Œå› ä¸ºæœ‰æ—¶ç‰¹å®šçš„ç»©æ•ˆè¡¡é‡æ ‡å‡†åœ¨æŸäº›è¡Œä¸šä¸­å˜å¾—ç‰¹åˆ«æµè¡Œï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™å†³å®šäº†ç»©æ•ˆè¡¡é‡æ ‡å‡†çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.2â€…â€…â€…A simple dataset for MENINGITIS with three common symptoms of the disease listed as descriptive features: HEADACHE, FEVER, and VOMITING.",
            "zh": "B.2 è„‘è†œç‚çš„ç®€å•æ•°æ®é›†ï¼Œè¯¥ç–¾ç—…çš„ä¸‰ç§å¸¸è§ç—‡çŠ¶è¢«åˆ—ä¸ºæè¿°æ€§ç‰¹å¾ï¼šå¤´ç—›ã€å‘çƒ§å’Œå‘•åã€‚"
        }
    },
    {
        "translation": {
            "en": "We have used the convention of a gray background to track the flow of the second example (d2) through the network: the input vector for d2 is < bias = 1, AMBIENT TEMPERATURE = 0.84, RELATIVE HUMIDITY = 0.58 >.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç°è‰²èƒŒæ™¯çš„çº¦å®šæ¥è·Ÿè¸ªç¬¬äºŒä¸ªç¤ºä¾‹ ï¼ˆd2ï¼‰ é€šè¿‡ç½‘ç»œçš„æµé‡ï¼šd2 çš„è¾“å…¥å‘é‡<åç½® = 1ï¼Œç¯å¢ƒæ¸©åº¦ = 0.84ï¼Œç›¸å¯¹æ¹¿åº¦ = 0.58 >ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. The table is too wide to fit on a page, so it has been split into three sections.",
            "zh": "8. è¡¨æ ¼å¤ªå®½ï¼Œæ— æ³•æ”¾åœ¨é¡µé¢ä¸Šï¼Œå› æ­¤å°†å…¶åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is known as discounted return.",
            "zh": "è¿™è¢«ç§°ä¸ºæŠ˜æ‰£é€€è´§ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4.2â€…â€…â€…Continuous Features: Probability Density Functions",
            "zh": "6.4.2 è¿ç»­ç‰¹å¾ï¼šæ¦‚ç‡å¯†åº¦å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "A new set of errors are then calculated by comparing the 1 predictions to the target feature values.",
            "zh": "ç„¶åï¼Œé€šè¿‡å°† 1 ä¸ªé¢„æµ‹å€¼ä¸ç›®æ ‡è¦ç´ å€¼è¿›è¡Œæ¯”è¾ƒæ¥è®¡ç®—ä¸€ç»„æ–°çš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this, the algorithm needs to decide which of the remaining descriptive features has the highest information gain for each partition.",
            "zh": "ä¸ºæ­¤ï¼Œç®—æ³•éœ€è¦ç¡®å®šæ¯ä¸ªåˆ†åŒºçš„å…¶ä½™æè¿°æ€§ç‰¹å¾ä¸­å“ªä¸ªå…·æœ‰æœ€é«˜çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "One descriptive feature is included for each word in a predefined dictionary.",
            "zh": "é¢„å®šä¹‰è¯å…¸ä¸­çš„æ¯ä¸ªå•è¯éƒ½åŒ…å«ä¸€ä¸ªæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having both of these numbers is useful as it allows us to think about tuning the model toward one kind of error or the other.",
            "zh": "æ‹¥æœ‰è¿™ä¸¤ä¸ªæ•°å­—å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬è€ƒè™‘å°†æ¨¡å‹è°ƒæ•´ä¸ºä¸€ç§æˆ–å¦ä¸€ç§é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarity-based learning (Chapter 5[181])",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ ï¼ˆç¬¬5ç« [181]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the probabilities required by a naive Bayes model to represent this domain.",
            "zh": "ï¼ˆcï¼‰ è®¡ç®—æœ´ç´ è´å¶æ–¯æ¨¡å‹è¡¨ç¤ºè¯¥åŸŸæ‰€éœ€çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "random sampling with replacement, 93",
            "zh": "éšæœºæŠ½æ ·æ›¿æ¢ï¼Œ93"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor prediction algorithm creates a set of local models, or neighborhoods, across the feature space where each model is defined by a subset of the training dataset (in this case, one instance).",
            "zh": "æœ€è¿‘é‚»é¢„æµ‹ç®—æ³•åœ¨ç‰¹å¾ç©ºé—´ä¸­åˆ›å»ºä¸€ç»„å±€éƒ¨æ¨¡å‹æˆ–é‚»åŸŸï¼Œå…¶ä¸­æ¯ä¸ªæ¨¡å‹ç”±è®­ç»ƒæ•°æ®é›†çš„å­é›†ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºä¸€ä¸ªå®ä¾‹ï¼‰å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the two-dimensional feature space in Figure 5.18(d)[226], we have maintained the sampling density (the density of the marked unit hypercube is ) at the expense of a very large increase in the number of instancesâ€”there are 29 Ã— 29 = 841 instances plotted in this figure.",
            "zh": "åœ¨å›¾5.18ï¼ˆdï¼‰[226]çš„äºŒç»´ç‰¹å¾ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬ä¿æŒäº†é‡‡æ ·å¯†åº¦ï¼ˆæ ‡è®°å•ä½è¶…ç«‹æ–¹ä½“çš„å¯†åº¦æ˜¯ï¼‰ï¼Œä½†ä»£ä»·æ˜¯å®ä¾‹æ•°é‡çš„å¤§å¹…å¢åŠ â€”â€”è¯¥å›¾ä¸­ç»˜åˆ¶äº† 29 ä¸ªå®ä¾‹Ã— 29 = 841 ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the Claim Frequency domain subconcept under the Claimant History concept should capture the fact that the number of claims a claimant has made in the past has an impact on the likelihood of a new claim being fraudulent.",
            "zh": "ä¾‹å¦‚ï¼Œâ€œç´¢èµ”äººå†å²è®°å½•â€æ¦‚å¿µä¸‹çš„â€œç´¢èµ”é¢‘åŸŸå­æ¦‚å¿µåº”æ¶µç›–ç´¢èµ”äººè¿‡å»æå‡ºçš„ç´¢èµ”æ•°é‡å¯¹æ–°ç´¢èµ”å…·æœ‰æ¬ºè¯ˆæ€§çš„å¯èƒ½æ€§æœ‰å½±å“çš„äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "To change the ID3 algorithm in Algorithm 1[134] to select features to split on based on variance, we replace Line 1 with Equation 4.11[150].",
            "zh": "ä¸ºäº†æ”¹å˜ç®—æ³•1[134]ä¸­çš„ID3ç®—æ³•ï¼Œä»¥é€‰æ‹©è¦æ ¹æ®æ–¹å·®è¿›è¡Œæ‹†åˆ†çš„ç‰¹å¾ï¼Œæˆ‘ä»¬å°†çº¿1æ›¿æ¢ä¸ºå…¬å¼4.11[150]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Part II[117] of the book includes Chapters 4 to 9 and covers the main supervised machine learning material.",
            "zh": "æœ¬ä¹¦çš„ç¬¬äºŒéƒ¨åˆ†[117]åŒ…æ‹¬ç¬¬4ç« è‡³ç¬¬9ç« ï¼Œæ¶µç›–äº†ä¸»è¦çš„ç›‘ç£æœºå™¨å­¦ä¹ ææ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use this data to train and evaluate a machine learning model that will then be deployed for use on newly arising data.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨è¿™äº›æ•°æ®æ¥è®­ç»ƒå’Œè¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç„¶åéƒ¨ç½²è¯¥æ¨¡å‹ä»¥ç”¨äºæ–°å‡ºç°çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another advantage of binning, especially equal-frequency binning, is that it goes some way toward handling outliers.",
            "zh": "åƒç´ åˆå¹¶ï¼ˆå°¤å…¶æ˜¯ç­‰é¢‘åƒç´ åˆå¹¶ï¼‰çš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯ï¼Œå®ƒåœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥å¤„ç†å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2(b)[316] shows the office rentals dataset and the candidate model with w[0] = 6.47 and w[1] = 0.62 and also includes error bars to highlight the differences between the predictions made by the model and the actual RENTAL PRICE values in the training data.",
            "zh": "å›¾ 7.2ï¼ˆbï¼‰[316] æ˜¾ç¤ºäº† w[0] = 6.47 å’Œ w[1] = 0.62 çš„åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†å’Œå€™é€‰æ¨¡å‹ï¼Œè¿˜åŒ…æ‹¬è¯¯å·®çº¿ï¼Œä»¥çªå‡ºæ¨¡å‹æ‰€åšçš„é¢„æµ‹ä¸è®­ç»ƒæ•°æ®ä¸­çš„å®é™… RENTAL PRICE å€¼ä¹‹é—´çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "How do we relate these values to the actual underlying population?",
            "zh": "æˆ‘ä»¬å¦‚ä½•å°†è¿™äº›å€¼ä¸å®é™…çš„æ½œåœ¨äººå£è”ç³»èµ·æ¥ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Cross-referencing Figure 8.14[425], these z and a values are found in the corresponding gray boxes in that figure.",
            "zh": "äº¤å‰å¼•ç”¨å›¾8.14[425]ï¼Œè¿™äº›zå€¼å’Œaå€¼ä½äºè¯¥å›¾ä¸­ç›¸åº”çš„ç°è‰²æ¡†ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example single linkage is used and so the distance between two clusters is calculated as the minimum distance between their member instances.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨å•é“¾æ¥ï¼Œå› æ­¤ä¸¤ä¸ªé›†ç¾¤ä¹‹é—´çš„è·ç¦»è®¡ç®—ä¸ºå…¶æˆå‘˜å®ä¾‹ä¹‹é—´çš„æœ€å°è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mahalanobis distance, 217, 223, 231, 242",
            "zh": "é©¬å“ˆæ‹‰è¯ºæ¯”æ–¯è·ç¦»ï¼Œ 217ï¼Œ 223ï¼Œ 231ï¼Œ 242"
        }
    },
    {
        "translation": {
            "en": "Table 8.15",
            "zh": "è¡¨ 8.15"
        }
    },
    {
        "translation": {
            "en": "The Corruption Perception Index is for 2011 and was retrieved from Transparency International (www.transparency.org).",
            "zh": "æ¸…å»‰æŒ‡æ•°æ˜¯2011å¹´çš„ï¼Œå–è‡ªé€æ˜å›½é™…ï¼ˆwww.transparency.orgï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "34. Learning rates are discussed in much more detail in Chapter 7[311].",
            "zh": "34. å­¦ä¹ ç‡åœ¨ç¬¬7ç« [311]ä¸­æœ‰æ›´è¯¦ç»†çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "1. An agent in an environment completes an episode and receives the following rewards:",
            "zh": "1. ç¯å¢ƒä¸­çš„ä»£ç†å®Œæˆä¸€é›†å¹¶è·å¾—ä»¥ä¸‹å¥–åŠ±ï¼š"
        }
    },
    {
        "translation": {
            "en": "The first step in building a gradient boosting model for this problem is to train the initial model, 0.",
            "zh": "ä¸ºè¿™ä¸ªé—®é¢˜æ„å»ºæ¢¯åº¦æå‡æ¨¡å‹çš„ç¬¬ä¸€æ­¥æ˜¯è®­ç»ƒåˆå§‹æ¨¡å‹ 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "The matrix on the left of Equation (8.95)[491] represents the 6-by-6 layer of neurons that share the filter listed in Equation (8.94)[490].",
            "zh": "ç­‰å¼ï¼ˆ8.95ï¼‰[491]å·¦ä¾§çš„çŸ©é˜µè¡¨ç¤ºå…±äº«ç­‰å¼ï¼ˆ8.94ï¼‰[490]ä¸­åˆ—å‡ºçš„æ»¤æ³¢å™¨çš„6Ã—6ç¥ç»å…ƒå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forget gate removes information from the cell, the input gate adds information to the cell, and the output gate decides which information should be output by the network at the current time-step.",
            "zh": "é—å¿˜é—¨ä»å°åŒºä¸­åˆ é™¤ä¿¡æ¯ï¼Œè¾“å…¥é—¨å‘å°åŒºæ·»åŠ ä¿¡æ¯ï¼Œè¾“å‡ºé—¨å†³å®šç½‘ç»œåœ¨å½“å‰æ—¶é—´æ­¥é•¿åº”è¾“å‡ºå“ªäº›ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "These Î´ values are the error gradients that are backpropagated during the backward pass of the backpropagation algorithm.",
            "zh": "è¿™äº›Î´å€¼æ˜¯åœ¨åå‘ä¼ æ’­ç®—æ³•å‘åä¼ é€’æœŸé—´åå‘ä¼ æ’­çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tables 9.9(a)[555] and 9.9(b)[555] show confusion matrices for two different prediction models, a k-NN model and a decision tree model, trained for the payday loans credit scoring problem. The average class accuracy (using a harmonic mean) for the k-NN model is 83.824% and for the decision tree model is 80.761%, which suggests that the k-NN model is quite a bit better than the decision tree.",
            "zh": "è¡¨9.9ï¼ˆaï¼‰[555]å’Œè¡¨9.9ï¼ˆbï¼‰[555]æ˜¾ç¤ºäº†ä¸¤ç§ä¸åŒé¢„æµ‹æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼Œå³k-NNæ¨¡å‹å’Œå†³ç­–æ ‘æ¨¡å‹ï¼Œé’ˆå¯¹å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜è¿›è¡Œäº†è®­ç»ƒã€‚k-NNæ¨¡å‹çš„å¹³å‡ç±»å‡†ç¡®ç‡ï¼ˆä½¿ç”¨è°æ³¢å¹³å‡å€¼ï¼‰ä¸º83.824%ï¼Œå†³ç­–æ ‘æ¨¡å‹çš„å¹³å‡ç±»å‡†ç¡®ç‡ä¸º80.761%ï¼Œè¿™è¡¨æ˜k-NNæ¨¡å‹æ¯”å†³ç­–æ ‘å¥½å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "The implication of this is that once we have calculated the Î´ for a neuron, all we need to do to calculate the sensitivity of the network error with respect to a weight on a connection coming into the neuron is to multiply the neuronâ€™s Î´ by the activation that was propagated forward on that connection. Equation (8.27)[414] shows how the chain rule product is eventually simplified to the simple product of a Î´ by an activation",
            "zh": "è¿™æ„å‘³ç€ï¼Œä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†ç¥ç»å…ƒçš„Î´ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯è®¡ç®—ç½‘ç»œè¯¯å·®ç›¸å¯¹äºè¿›å…¥ç¥ç»å…ƒçš„è¿æ¥ä¸Šçš„æƒé‡çš„æ•æ„Ÿæ€§ï¼Œå°±æ˜¯å°†ç¥ç»å…ƒçš„Î´ä¹˜ä»¥åœ¨è¯¥è¿æ¥ä¸Šå‘å‰ä¼ æ’­çš„æ¿€æ´»ã€‚æ–¹ç¨‹ï¼ˆ8.27ï¼‰[414]æ˜¾ç¤ºäº†é“¾å¼æ³•åˆ™ä¹˜ç§¯å¦‚ä½•é€šè¿‡æ¿€æ´»æœ€ç»ˆç®€åŒ–ä¸ºÎ´çš„ç®€å•ä¹˜ç§¯"
        }
    },
    {
        "translation": {
            "en": "The Organisation for Economic Co-operation and Development (OECD, 2013) defines a set of eight general principles of data protection legislation.7 For the design of analytics base tables, three are especially relevant: the collection limitation principle, the purpose specification principle, and the use limitation principle.",
            "zh": "ç»æµåˆä½œä¸å‘å±•ç»„ç»‡ï¼ˆOECDï¼Œ2013ï¼‰å®šä¹‰äº†ä¸€å¥—å…«é¡¹æ•°æ®ä¿æŠ¤ç«‹æ³•çš„ä¸€èˆ¬åŸåˆ™.7å¯¹äºåˆ†æåŸºè¡¨çš„è®¾è®¡ï¼Œæœ‰ä¸‰é¡¹ç‰¹åˆ«ç›¸å…³ï¼šæ”¶é›†é™åˆ¶åŸåˆ™ã€ç›®çš„è§„èŒƒåŸåˆ™å’Œä½¿ç”¨é™åˆ¶åŸåˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second example, Figure 3.8(b)[79], shows the POSITION and SHOE SPONSOR features.",
            "zh": "ç¬¬äºŒä¸ªç¤ºä¾‹ï¼Œå›¾ 3.8ï¼ˆbï¼‰[79]ï¼Œæ˜¾ç¤ºäº† POSITION å’Œ SHOE SPONSOR åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, in fraud detection, the fraud events would most likely be the positive level; in credit scoring, the default events would most likely be the positive level; and in disease diagnosis, a confirmation that a patient has the disease would most likely be the positive level.",
            "zh": "åŒæ ·ï¼Œåœ¨æ¬ºè¯ˆæ£€æµ‹ä¸­ï¼Œæ¬ºè¯ˆäº‹ä»¶å¾ˆå¯èƒ½æ˜¯æ­£å€¼;åœ¨ä¿¡ç”¨è¯„åˆ†ä¸­ï¼Œè¿çº¦äº‹ä»¶å¾ˆå¯èƒ½æ˜¯æ­£å€¼;åœ¨ç–¾ç—…è¯Šæ–­ä¸­ï¼Œç¡®è®¤æ‚£è€…æ‚£æœ‰è¯¥ç–¾ç—…å¾ˆå¯èƒ½æ˜¯é˜³æ€§æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the drawbacks of using this method to detect that a model has gone stale is that estimating how large this change needs to be in order to signal that the model has gone stale is entirely domain dependent.23",
            "zh": "ä½¿ç”¨æ­¤æ–¹æ³•æ£€æµ‹æ¨¡å‹æ˜¯å¦è¿‡æ—¶çš„ç¼ºç‚¹ä¹‹ä¸€æ˜¯ï¼Œä¼°è®¡æ­¤æ›´æ”¹éœ€è¦å¤šå¤§æ‰èƒ½å‘å‡ºæ¨¡å‹å·²è¿‡æ—¶çš„ä¿¡å·ï¼Œè¿™å®Œå…¨å–å†³äºé¢†åŸŸ23ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) A standardization of the data",
            "zh": "ï¼ˆcï¼‰ æ•°æ®æ ‡å‡†åŒ–"
        }
    },
    {
        "translation": {
            "en": "(a) A stacked bar plot for the REGIONTYPE feature; and (b) histograms for the AVGOVERBUNDLEMINS feature by target feature value.",
            "zh": "ï¼ˆaï¼‰ REGIONTYPE ç‰¹å¾çš„å †ç§¯æ¡å½¢å›¾;ä»¥åŠ ï¼ˆbï¼‰ æŒ‰ç›®æ ‡ç‰¹å¾å€¼åˆ’åˆ†çš„ AVGOVERBUNDLEMINS ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A single screenshot of a game does not contain sufficient information about the state of an environment and an agent for the environment to be considered fully observable, and so the Markov assumption does not hold.",
            "zh": "æ¸¸æˆçš„å•ä¸ªå±å¹•æˆªå›¾ä¸åŒ…å«æœ‰å…³ç¯å¢ƒçŠ¶æ€å’Œç¯å¢ƒä»£ç†çš„è¶³å¤Ÿä¿¡æ¯ï¼Œå› æ­¤é©¬å°”å¯å¤«å‡è®¾ä¸æˆç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. This practice was first systematically applied by Edwin Hubble in 1936 (Hubble, 1936).",
            "zh": "3. åŸƒå¾·æ¸©Â·å“ˆå‹ƒï¼ˆEdwin Hubbleï¼‰äº1936å¹´é¦–æ¬¡ç³»ç»Ÿåœ°åº”ç”¨äº†è¿™ç§åšæ³•ï¼ˆå“ˆå‹ƒï¼Œ1936å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often when an ABT is generated, some instances will be missing values for one or more features.",
            "zh": "é€šå¸¸ï¼Œåœ¨ç”Ÿæˆ ABT æ—¶ï¼ŒæŸäº›å®ä¾‹å°†ç¼ºå°‘ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an instance of a constrained quadratic optimization problem, and there are well-known approaches to solving this type of problem.",
            "zh": "è¿™æ˜¯çº¦æŸäºŒæ¬¡ä¼˜åŒ–é—®é¢˜çš„ä¸€ä¸ªå®ä¾‹ï¼Œå¹¶ä¸”æœ‰ä¼—æ‰€å‘¨çŸ¥çš„æ–¹æ³•å¯ä»¥è§£å†³æ­¤ç±»é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can cause the network training process to become unstable as small change in the outputs of the action-value network can lead to sudden changes in the policy as a different action is suddenly favored in a type of state.",
            "zh": "è¿™å¯èƒ½ä¼šå¯¼è‡´ç½‘ç»œè®­ç»ƒè¿‡ç¨‹å˜å¾—ä¸ç¨³å®šï¼Œå› ä¸ºåŠ¨ä½œå€¼ç½‘ç»œè¾“å‡ºçš„å¾®å°å˜åŒ–å¯èƒ½ä¼šå¯¼è‡´ç­–ç•¥çš„çªç„¶å˜åŒ–ï¼Œå› ä¸ºåœ¨ä¸€ç§çŠ¶æ€ä¸‹çªç„¶åçˆ±ä¸åŒçš„åŠ¨ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "When undertaking this process, it is important to take into account the availability of data and the capacity of a business to take advantage of insights arising from analytics models, as otherwise it is possible to construct an apparently accurate prediction model that is in fact useless.",
            "zh": "åœ¨è¿›è¡Œæ­¤è¿‡ç¨‹æ—¶ï¼Œé‡è¦çš„æ˜¯è¦è€ƒè™‘æ•°æ®çš„å¯ç”¨æ€§å’Œä¼ä¸šåˆ©ç”¨åˆ†ææ¨¡å‹äº§ç”Ÿçš„è§è§£çš„èƒ½åŠ›ï¼Œå¦åˆ™å°±æœ‰å¯èƒ½æ„å»ºä¸€ä¸ªçœ‹ä¼¼å‡†ç¡®çš„é¢„æµ‹æ¨¡å‹ï¼Œä½†å®é™…ä¸Šæ¯«æ— ç”¨å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "ROC space, 559",
            "zh": "ä¸­åæ°‘å›½ç©ºé—´ï¼Œ559"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12(a)[205] presents a plot of the feature space defined by the SALARY and AGE features, containing the dataset in Table 5.5[204].",
            "zh": "å›¾5.12ï¼ˆaï¼‰[205]æ˜¾ç¤ºäº†ç”±PAYRYå’ŒAGEç‰¹å¾å®šä¹‰çš„ç‰¹å¾ç©ºé—´å›¾ï¼Œå…¶ä¸­åŒ…å«è¡¨5.5[204]ä¸­çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For any business problem, there are a number of different analytics solutions that we could build to address it.",
            "zh": "å¯¹äºä»»ä½•ä¸šåŠ¡é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºè®¸å¤šä¸åŒçš„åˆ†æè§£å†³æ–¹æ¡ˆæ¥è§£å†³å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This issue often arises because multiple levels are used to represent the same thingâ€”for example, in a feature storing gender, we might find levels of male, female, m, f, M, and F, which all represent male and female in slightly different ways.",
            "zh": "ä¹‹æ‰€ä»¥å‡ºç°æ­¤é—®é¢˜ï¼Œé€šå¸¸æ˜¯å› ä¸ºä½¿ç”¨å¤šä¸ªçº§åˆ«æ¥è¡¨ç¤ºåŒä¸€äº‹ç‰© - ä¾‹å¦‚ï¼Œåœ¨å­˜å‚¨æ€§åˆ«çš„ç‰¹å¾ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå‘ç° maleã€femaleã€mã€fã€M å’Œ F çš„çº§åˆ«ï¼Œå®ƒä»¬éƒ½ä»¥ç•¥å¾®ä¸åŒçš„æ–¹å¼è¡¨ç¤ºç”·æ€§å’Œå¥³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.5â€ƒSummary",
            "zh": "7.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "This dataset contains just nine instances (the instance labels have been kept consistent so that this example can be compared with previous ones) and is shown in Figure 10.12(a)[621].",
            "zh": "è¯¥æ•°æ®é›†ä»…åŒ…å« 9 ä¸ªå®ä¾‹ï¼ˆå®ä¾‹æ ‡ç­¾ä¿æŒä¸€è‡´ï¼Œä»¥ä¾¿æ­¤ç¤ºä¾‹å¯ä»¥ä¸ä»¥å‰çš„ç¤ºä¾‹è¿›è¡Œæ¯”è¾ƒï¼‰ï¼Œå¦‚å›¾ 10.12ï¼ˆaï¼‰[621] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Concretely, this means that in each weight update, the weights in the earlier layers in the network are updated by smaller amounts than the neurons in the later layers.",
            "zh": "å…·ä½“æ¥è¯´ï¼Œè¿™æ„å‘³ç€åœ¨æ¯æ¬¡æƒé‡æ›´æ–°ä¸­ï¼Œç½‘ç»œä¸­æ—©æœŸå±‚çš„æƒé‡æ›´æ–°é‡å°äºåå±‚ç¥ç»å…ƒçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This may not be a good thing if this instance is due to noise in the data, and this demonstrates that there is no silver bullet solution to handling noise in datasets.",
            "zh": "å¦‚æœæ­¤å®ä¾‹æ˜¯ç”±äºæ•°æ®ä¸­çš„å™ªå£°å¼•èµ·çš„ï¼Œè¿™å¯èƒ½ä¸æ˜¯ä¸€ä»¶å¥½äº‹ï¼Œè¿™è¡¨æ˜å¤„ç†æ•°æ®é›†ä¸­çš„å™ªå£°æ²¡æœ‰çµä¸¹å¦™è¯è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "cumulative reward, 640, 643, 676",
            "zh": "ç´¯è®¡å¥–åŠ±ï¼Œ 640ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "It is usually home to small animals, including raccoons, frogs, and toads.",
            "zh": "å®ƒé€šå¸¸æ˜¯å°åŠ¨ç‰©çš„å®¶å›­ï¼ŒåŒ…æ‹¬æµ£ç†Šã€é’è›™å’ŒèŸ¾èœã€‚"
        }
    },
    {
        "translation": {
            "en": "In the case of Claimant History, the domain subconcept of Claim Types explicitly recognizes the importance of designing descriptive features to capture the different types of claims the claimant has been involved in in the past, and the Claim Frequency domain subconcept identifies the need to have descriptive features relating to the frequency with which the claimant has been involved in claims.",
            "zh": "å°±ç´¢èµ”äººå†å²è€Œè¨€ï¼Œç´¢èµ”ç±»å‹çš„é¢†åŸŸå­æ¦‚å¿µæ˜ç¡®è®¤è¯†åˆ°è®¾è®¡æè¿°æ€§ç‰¹å¾ä»¥æ•æ‰ç´¢èµ”äººè¿‡å»å‚ä¸çš„ä¸åŒç±»å‹çš„ç´¢èµ”çš„é‡è¦æ€§ï¼Œè€Œç´¢èµ”é¢‘åŸŸå­æ¦‚å¿µåˆ™ç¡®å®šéœ€è¦å…·æœ‰ä¸ç´¢èµ”äººå‚ä¸ç´¢èµ”çš„é¢‘ç‡ç›¸å…³çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dendrites of one neuron connect to the axons of other neurons via connections known as synapses.",
            "zh": "ä¸€ä¸ªç¥ç»å…ƒçš„æ ‘çªé€šè¿‡ç§°ä¸ºçªè§¦çš„è¿æ¥è¿æ¥åˆ°å…¶ä»–ç¥ç»å…ƒçš„è½´çªã€‚"
        }
    },
    {
        "translation": {
            "en": "sampling method, 541, 546",
            "zh": "æŠ½æ ·æ³•ï¼Œ541,546"
        }
    },
    {
        "translation": {
            "en": "The C4.5 algorithm is a well-known variant of the ID3 algorithm that uses these extensions to handle continuous and categorical descriptive features and missing features.",
            "zh": "C4.5 ç®—æ³•æ˜¯ ID3 ç®—æ³•çš„ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥çš„å˜ä½“ï¼Œå®ƒä½¿ç”¨è¿™äº›æ‰©å±•æ¥å¤„ç†è¿ç»­å’Œåˆ†ç±»çš„æè¿°æ€§ç‰¹å¾å’Œç¼ºå¤±çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This section introduces the fundamentals of reinforcement learning.",
            "zh": "æœ¬èŠ‚ä»‹ç»å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent earns a reward of + 100 for landing successfully and a reward of âˆ’ 100 for crashing.",
            "zh": "ç‰¹å·¥æˆåŠŸç€é™†å¯è·å¾— + 100 çš„å¥–åŠ±ï¼Œå æ¯å¯è·å¾— âˆ’ 100 çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "This epilogue illustrates two important, and related, aspects of supervised machine learning.",
            "zh": "æœ¬ç»“è¯­è¯´æ˜äº†ç›‘ç£æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªé‡è¦ä¸”ç›¸å…³çš„æ–¹é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. The following table shows the IQs for a group of people who applied to take part in a television general-knowledge quiz.",
            "zh": "6. ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸€ç»„ç”³è¯·å‚åŠ ç”µè§†å¸¸è¯†æµ‹éªŒçš„äººçš„æ™ºå•†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This calculation shows that if a neuron uses the set of weights in Equation (8.85)[480], then the activation of the neuron is solely dependent on the values along the middle row of inputs.",
            "zh": "è¯¥è®¡ç®—è¡¨æ˜ï¼Œå¦‚æœç¥ç»å…ƒä½¿ç”¨æ–¹ç¨‹ï¼ˆ8.85ï¼‰[480]ä¸­çš„æƒé‡é›†ï¼Œåˆ™ç¥ç»å…ƒçš„æ¿€æ´»å®Œå…¨å–å†³äºæ²¿ä¸­é—´è¾“å…¥è¡Œçš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2â€…â€…â€…A simple Markov process to model the evolution of an infectious disease in individuals during an epidemic using the SUSCEPTIBLE-INFECTED-RECOVERED (S-I-R) model.",
            "zh": "11.2 ä¸€ä¸ªç®€å•çš„é©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œä½¿ç”¨æ˜“æ„Ÿ-æ„ŸæŸ“-åº·å¤ ï¼ˆS-I-Rï¼‰ æ¨¡å‹å¯¹æµè¡Œç—…æœŸé—´ä¸ªä½“ä¼ æŸ“ç—…çš„æ¼”å˜è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in 1936 it was not necessarily obvious that using telephone directories to create an initial list of names would skew the resulting sample toward a particular group in the population (in this instance, Republicans).",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨ 1936 å¹´ï¼Œä½¿ç”¨ç”µè¯ç°¿åˆ›å»ºåˆå§‹å§“ååˆ—è¡¨ä¼šä½¿ç»“æœæ ·æœ¬åå‘äººå£ä¸­çš„ç‰¹å®šç¾¤ä½“ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºå…±å’Œå…šäººï¼‰å¹¶ä¸ä¸€å®šå¾ˆæ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the SALARY feature dominates the computation of the Euclidean distance whether we include the AGE feature or not.",
            "zh": "å› æ­¤ï¼Œæ— è®ºæˆ‘ä»¬æ˜¯å¦åŒ…æ‹¬ AGE ç‰¹å¾ï¼ŒSALARY ç‰¹å¾éƒ½ä¸»å¯¼ç€æ¬§å‡ é‡Œå¾—è·ç¦»çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second kind of mistake that makes people incorrectly infer causation between two features is ignoring a third important, but hidden, feature.",
            "zh": "ä½¿äººä»¬é”™è¯¯åœ°æ¨æ–­ä¸¤ä¸ªç‰¹å¾ä¹‹é—´å› æœå…³ç³»çš„ç¬¬äºŒç§é”™è¯¯æ˜¯å¿½ç•¥äº†ç¬¬ä¸‰ä¸ªé‡è¦ä½†éšè—çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates that the UNKNOWN SENDER feature is not as good at discriminating between spam and ham emails as the SUSPICIOUS WORDS feature.",
            "zh": "è¿™è¡¨æ˜ UNKNOWN SENDER åŠŸèƒ½åœ¨åŒºåˆ†åƒåœ¾é‚®ä»¶å’Œä¸šä½™ç”µå­é‚®ä»¶æ–¹é¢ä¸å¦‚ SUSPICIOUS WORDS åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Doing this does necessitate that in order to retrieve the predicted value of the target in the original range of the target feature, the output from the network must be mapped back to the original scale for the target feature, but generally, this is not a difficult thing to do.",
            "zh": "è¿™æ ·åšç¡®å®éœ€è¦ï¼Œä¸ºäº†åœ¨ç›®æ ‡è¦ç´ çš„åŸå§‹èŒƒå›´å†…æ£€ç´¢ç›®æ ‡çš„é¢„æµ‹å€¼ï¼Œå¿…é¡»å°†ç½‘ç»œçš„è¾“å‡ºæ˜ å°„å›ç›®æ ‡è¦ç´ çš„åŸå§‹æ¯”ä¾‹ï¼Œä½†ä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸æ˜¯ä¸€ä»¶éš¾äº‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have a test set containing instances for which we know the correct target values, and we have a set of predictions made by a model.",
            "zh": "æˆ‘ä»¬æœ‰ä¸€ä¸ªæµ‹è¯•é›†ï¼Œå…¶ä¸­åŒ…å«æˆ‘ä»¬çŸ¥é“æ­£ç¡®ç›®æ ‡å€¼çš„å®ä¾‹ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰ä¸€ç»„ç”±æ¨¡å‹åšå‡ºçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "cut a hierarchical agglomeration, 622",
            "zh": "åˆ‡å‰²ä¸€ä¸ªç­‰çº§é›†èšï¼Œ622"
        }
    },
    {
        "translation": {
            "en": "Each time a prediction is made, the query instance can be added into the dataset and used in subsequent predictions.32 In this way, a nearest neighbor model can be easily updated, which makes it relatively robust to concept drift (we will return to concept drift in Section 9.4.6[578]).",
            "zh": "æ¯æ¬¡è¿›è¡Œé¢„æµ‹æ—¶ï¼Œéƒ½å¯ä»¥å°†æŸ¥è¯¢å®ä¾‹æ·»åŠ åˆ°æ•°æ®é›†ä¸­ï¼Œå¹¶åœ¨åç»­é¢„æµ‹ä¸­ä½¿ç”¨.32 é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæœ€è¿‘é‚»æ¨¡å‹å¯ä»¥å¾ˆå®¹æ˜“åœ°æ›´æ–°ï¼Œè¿™ä½¿å¾—å®ƒå¯¹æ¦‚å¿µæ¼‚ç§»ç›¸å¯¹é²æ£’ï¼ˆæˆ‘ä»¬å°†åœ¨ç¬¬ 9.4.6 èŠ‚ä¸­è¿”å›æ¦‚å¿µæ¼‚ç§»[578]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2.2â€ƒMatching Machine Learning Approaches to Data",
            "zh": "14.2.2 å°†æœºå™¨å­¦ä¹ æ–¹æ³•ä¸æ•°æ®ç›¸åŒ¹é…"
        }
    },
    {
        "translation": {
            "en": "4.18â€…â€…â€…The decision tree for the post-operative patient routing task.",
            "zh": "4.18 æœ¯åæ‚£è€…è·¯ç”±ä»»åŠ¡çš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "subset selection, 228",
            "zh": "å­é›†é€‰æ‹©ï¼Œ228"
        }
    },
    {
        "translation": {
            "en": "The minimum and maximum values for the AMBIENT TEMPERATURE, RELATIVE HUMIDITY, and ELECTRICAL OUTPUT features in the power plant dataset.",
            "zh": "ç”µå‚æ•°æ®é›†ä¸­ AMBIENT TEMPERATUREã€RELATIVE HUMIDITY å’Œ ELECTRICAL OUTPUT è¦ç´ çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are now ready to use Bayesâ€™ Theorem to generate predictions based on a dataset. The next section will examine how this is done.",
            "zh": "æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨è´å¶æ–¯å®šç†æ¥ç”ŸæˆåŸºäºæ•°æ®é›†çš„é¢„æµ‹ã€‚ä¸‹ä¸€èŠ‚å°†ç ”ç©¶å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The network architecture shown in Figure 8.4[390] is an example of a feedforward network.",
            "zh": "å›¾ 8.4[390] æ‰€ç¤ºçš„ç½‘ç»œæ¶æ„æ˜¯å‰é¦ˆç½‘ç»œçš„ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imputation, however, should not be used for features that have very large numbers of missing values because imputing a very large number of missing values will change the central tendency of a feature too much. We would be reluctant to use imputation on features missing in excess of 30% of their values and would strongly recommend against the use of imputation on features missing in excess of 50% of their values.",
            "zh": "ä½†æ˜¯ï¼Œä¸åº”å°†æ’è¡¥ç”¨äºå…·æœ‰å¤§é‡ç¼ºå¤±å€¼çš„ç‰¹å¾ï¼Œå› ä¸ºæ’è¡¥å¤§é‡ç¼ºå¤±å€¼ä¼šè¿‡å¤šåœ°æ”¹å˜ç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿ã€‚æˆ‘ä»¬ä¸æ„¿æ„å¯¹ç¼ºå¤±è¶…è¿‡å…¶å€¼ 30% çš„è¦ç´ ä½¿ç”¨æ’è¡¥ï¼Œå¹¶å¼ºçƒˆå»ºè®®ä¸è¦å¯¹ç¼ºå¤±è¶…è¿‡å…¶å€¼ 50% çš„è¦ç´ ä½¿ç”¨æ’è¡¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Root mean squared error values are in the same units as the target value and so allow us to say something more meaningful about what the error for predictions made by the model will be.",
            "zh": "å‡æ–¹æ ¹è¯¯å·®å€¼ä¸ç›®æ ‡å€¼çš„å•ä½ç›¸åŒï¼Œå› æ­¤å…è®¸æˆ‘ä»¬è¯´æ˜æ¨¡å‹æ‰€åšçš„é¢„æµ‹è¯¯å·®å°†æ˜¯å¤šå°‘æ›´æœ‰æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "thank you for your love, support, and patience.",
            "zh": "æ„Ÿè°¢æ‚¨çš„çˆ±ã€æ”¯æŒå’Œè€å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "BLAND",
            "zh": "ä¹å‘³"
        }
    },
    {
        "translation": {
            "en": "If we were able to merge the bins in the regions where there are very few instances, then the resulting spare bins could be used to represent the differences between instances in the regions where lots of instances are clustered together.",
            "zh": "å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿåˆå¹¶å®ä¾‹å¾ˆå°‘çš„åŒºåŸŸä¸­çš„ binï¼Œé‚£ä¹ˆç”Ÿæˆçš„å¤‡ç”¨ bin å¯ç”¨äºè¡¨ç¤ºå¤§é‡å®ä¾‹èšé›†åœ¨ä¸€èµ·çš„åŒºåŸŸä¸­å®ä¾‹ä¹‹é—´çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.2",
            "zh": "è¡¨ 5.2"
        }
    },
    {
        "translation": {
            "en": "Due to its expanded size, this edition of the book has been organized into five parts: Part I: Introduction to Machine Learning and Data Analytics; Part II: Predictive Data Analytics; Part III: Beyond Prediction; Part IV: Case Studies and Conclusions; and Part V: Appendices.",
            "zh": "ç”±äºç¯‡å¹…è¾ƒå¤§ï¼Œæœ¬ç‰ˆæœ¬ä¹¦åˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼šç¬¬ä¸€éƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æç®€ä»‹;ç¬¬äºŒéƒ¨åˆ†ï¼šé¢„æµ‹æ€§æ•°æ®åˆ†æ;ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¶…è¶Šé¢„æµ‹;ç¬¬å››éƒ¨åˆ†ï¼šæ¡ˆä¾‹ç ”ç©¶å’Œç»“è®º;ç¬¬äº”éƒ¨åˆ†ï¼šé™„å½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent then continues to move across the environment making sequential updates to the action-value table until eventually it reaches the goal state after making 150 moves and accumulating a total reward of âˆ’ 891.",
            "zh": "ç„¶åï¼Œæ™ºèƒ½ä½“ç»§ç»­åœ¨ç¯å¢ƒä¸­ç§»åŠ¨ï¼Œå¯¹æ“ä½œå€¼è¡¨è¿›è¡Œé¡ºåºæ›´æ–°ï¼Œç›´åˆ°åœ¨ç§»åŠ¨ 150 æ¬¡å¹¶ç´¯ç§¯æ€»å¥–åŠ± âˆ’ 891 åæœ€ç»ˆè¾¾åˆ°ç›®æ ‡çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "We would also like to thank the staff at MIT Press, particularly Marie Lufkin Lee and our editors Melanie Mallon (1st Edition), as well as Theresa Carcaldi of Westchester Publishing Services (2nd Edition).",
            "zh": "æˆ‘ä»¬è¿˜è¦æ„Ÿè°¢éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾çš„å·¥ä½œäººå‘˜ï¼Œç‰¹åˆ«æ˜¯ Marie Lufkin Lee å’Œæˆ‘ä»¬çš„ç¼–è¾‘ Melanie Mallonï¼ˆç¬¬ 1 ç‰ˆï¼‰ï¼Œä»¥åŠ Westchester Publishing Servicesï¼ˆç¬¬ 2 ç‰ˆï¼‰çš„ Theresa Carcaldiã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard deviation, sd, of a sample is calculated by taking the square root of the variance of the sample:",
            "zh": "æ ·æœ¬çš„æ ‡å‡†å·® sd æ˜¯é€šè¿‡å–æ ·æœ¬æ–¹å·®çš„å¹³æ–¹æ ¹æ¥è®¡ç®—çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "Notice that the vertical axes in these histograms are labeled density, rather than frequency.",
            "zh": "è¯·æ³¨æ„ï¼Œè¿™äº›ç›´æ–¹å›¾ä¸­çš„å‚ç›´è½´æ ‡è®°ä¸ºå¯†åº¦ï¼Œè€Œä¸æ˜¯é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6(a)[39] shows an illustration of this kind of data, while Figure 2.6(b)[39] shows how this is aligned so that descriptive and target features can be extracted to build an ABT.",
            "zh": "å›¾ 2.6ï¼ˆaï¼‰[39] æ˜¾ç¤ºäº†æ­¤ç±»æ•°æ®çš„æ’å›¾ï¼Œè€Œå›¾ 2.6ï¼ˆbï¼‰[39] æ˜¾ç¤ºäº†å¦‚ä½•å¯¹é½ï¼Œä»¥ä¾¿å¯ä»¥æå–æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾ä»¥æ„å»º ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "This would mean that the confusion matrix would change to that shown in Table 9.12(a)[559] and, in turn, that the TPR and TNR measures would change to 0.5 and 0.833 respectively.",
            "zh": "è¿™æ„å‘³ç€æ··æ·†çŸ©é˜µå°†æ›´æ”¹ä¸ºè¡¨9.12ï¼ˆaï¼‰[559]æ‰€ç¤ºçš„çŸ©é˜µï¼Œåè¿‡æ¥ï¼ŒTPRå’ŒTNRæµ‹é‡å€¼å°†åˆ†åˆ«æ›´æ”¹ä¸º0.5å’Œ0.833ã€‚"
        }
    },
    {
        "translation": {
            "en": "Minsky, Marvin, and Seymour Papert. 1969. Perceptrons. MIT Press.",
            "zh": "æ˜æ–¯åŸºã€é©¬æ–‡å’Œè¥¿æ‘©Â·å¸•ç€ç‰¹ã€‚1969. æ„ŸçŸ¥å™¨ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "long tails, 59",
            "zh": "é•¿å°¾å·´ï¼Œ59"
        }
    },
    {
        "translation": {
            "en": "A consequence of this, and a somewhat less obvious requirement of similarity-based learning, is that if we are going to compute distances between instances, we need to have a concept of space in the representation of the domain used by our model.",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªç»“æœï¼Œä»¥åŠåŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ çš„ä¸€ä¸ªä¸å¤ªæ˜æ˜¾çš„è¦æ±‚æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬è¦è®¡ç®—å®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ¨¡å‹ä½¿ç”¨çš„åŸŸçš„è¡¨ç¤ºä¸­æœ‰ä¸€ä¸ªç©ºé—´æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "The first three types are self-explanatory and match directly with the categories of interest to the SDSS project.",
            "zh": "å‰ä¸‰ç§ç±»å‹æ˜¯ä¸è¨€è‡ªæ˜çš„ï¼Œä¸SDSSé¡¹ç›®æ„Ÿå…´è¶£çš„ç±»åˆ«ç›´æ¥åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will explain why the logistic function became so popular as an activation function when we introduce the backpropagation algorithm (see Section 8.3[403]), and why the rectified linear function replaced it when we explain the vanishing gradient problem (see Section 8.4.1[434]).",
            "zh": "å½“æˆ‘ä»¬å¼•å…¥åå‘ä¼ æ’­ç®—æ³•æ—¶ï¼Œæˆ‘ä»¬å°†è§£é‡Šä¸ºä»€ä¹ˆé€»è¾‘å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°å¦‚æ­¤å—æ¬¢è¿ï¼ˆå‚è§ç¬¬ 8.3 èŠ‚[403]ï¼‰ï¼Œä»¥åŠä¸ºä»€ä¹ˆå½“æˆ‘ä»¬è§£é‡Šæ¶ˆå¤±æ¢¯åº¦é—®é¢˜æ—¶ï¼Œæ•´æµçº¿æ€§å‡½æ•°å–ä»£äº†å®ƒï¼ˆå‚è§ç¬¬ 8.4.1 èŠ‚[434]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A general principle that we can derive from this is that neurons with saturated activation functions learn slowly (or not at all), and so we should take care when initializing weights to avoid saturating neurons.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä»ä¸­å¾—å‡ºä¸€ä¸ªä¸€èˆ¬åŸåˆ™ï¼Œå³å…·æœ‰é¥±å’Œæ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒå­¦ä¹ ç¼“æ…¢ï¼ˆæˆ–æ ¹æœ¬ä¸å­¦ä¹ ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬åœ¨åˆå§‹åŒ–æƒé‡æ—¶åº”è¯¥å°å¿ƒï¼Œä»¥é¿å…ç¥ç»å…ƒé¥±å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "We use the symbol â„° to denote the error of the network at the output layer.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç¬¦å· E æ¥è¡¨ç¤ºè¾“å‡ºå±‚çš„ç½‘ç»œè¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2.4â€ƒMeasuring profit and lossâ€ƒOne of the problems faced by all the performance measures discussed so far is that they place the same value on all the cells within a confusion matrix.",
            "zh": "9.4.2.4 è¡¡é‡æŸç›Š è¿„ä»Šä¸ºæ­¢è®¨è®ºçš„æ‰€æœ‰ç»©æ•ˆè¡¡é‡æ ‡å‡†é¢ä¸´çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå®ƒä»¬å¯¹æ··æ·†çŸ©é˜µä¸­çš„æ‰€æœ‰å•å…ƒæ ¼éƒ½å…·æœ‰ç›¸åŒçš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are often used in text analytics applications.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹é€šå¸¸ç”¨äºæ–‡æœ¬åˆ†æåº”ç”¨ç¨‹åºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.4[333] repeats the final weights for the office rentals model trained in Section 7.3.4[330].",
            "zh": "è¡¨ 7.4[333] é‡å¤äº†ç¬¬ 7.3.4 èŠ‚[330] ä¸­è®­ç»ƒçš„åŠå…¬å®¤ç§Ÿèµæ¨¡å‹çš„æœ€ç»ˆæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this model, the reward for all transitions to non-terminal states (e.g., PL-DL or PM-DH) is 0; these are not shown in Figure 11.3[648].",
            "zh": "åœ¨è¯¥æ¨¡å‹ä¸­ï¼Œæ‰€æœ‰è·ƒè¿åˆ°éç»ˆæœ«çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼ŒPL-DL æˆ– PM-DHï¼‰çš„å¥–åŠ±ä¸º 0;å›¾11.3[648]ä¸­æœªæ˜¾ç¤ºè¿™äº›å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(f)[60] shows a bimodal distribution with two clear peaksâ€”we can think of this as two normal distributions pushed together.",
            "zh": "å›¾3.2ï¼ˆfï¼‰[60]æ˜¾ç¤ºäº†å…·æœ‰ä¸¤ä¸ªæ¸…æ™°å³°çš„åŒå³°åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è§†ä¸ºä¸¤ä¸ªæ­£æ€åˆ†å¸ƒæ¨åœ¨ä¸€èµ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Why is this?",
            "zh": "ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "validation dataset, 155, 473, 541, 541, 719",
            "zh": "éªŒè¯æ•°æ®é›†ï¼Œ155ã€473ã€541ã€541ã€719"
        }
    },
    {
        "translation": {
            "en": "As we discussed previously, a network may have multiple convolutional layers in sequence because the outputs from a sub-sampling layer may be passed as an input to another filter convolution, and so this sequence of operations may be repeated multiple times.",
            "zh": "æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è®¨è®ºçš„ï¼Œä¸€ä¸ªç½‘ç»œå¯èƒ½æœ‰å¤šä¸ªå·ç§¯å±‚ï¼Œå› ä¸ºå­é‡‡æ ·å±‚çš„è¾“å‡ºå¯ä»¥ä½œä¸ºè¾“å…¥ä¼ é€’åˆ°å¦ä¸€ä¸ªæ»¤æ³¢å™¨å·ç§¯ï¼Œå› æ­¤è¿™ä¸ªæ“ä½œåºåˆ—å¯ä»¥é‡å¤å¤šæ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The business advised that for both features, a lower threshold of 0 and an upper threshold of 80,000 would make sense.",
            "zh": "è¯¥ä¸šåŠ¡å»ºè®®ï¼Œå¯¹äºè¿™ä¸¤ä¸ªåŠŸèƒ½ï¼Œé˜ˆå€¼ä¸º 0 çš„ä¸‹é™å’Œ 80,000 çš„ä¸Šé™æ˜¯æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "expectation maximization algorithm, 600, 629",
            "zh": "æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ï¼Œ 600ï¼Œ 629"
        }
    },
    {
        "translation": {
            "en": "17. The student-t distribution can be defined in a number of ways. For example, it can be defined so that it takes only one parameter, degrees of freedom. In this text we use the extended location-scale definition.",
            "zh": "17. å­¦ç”Ÿ-t åˆ†å¸ƒå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®šä¹‰ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å®šä¹‰å®ƒï¼Œä»¥ä¾¿å®ƒåªæ¥å—ä¸€ä¸ªå‚æ•°ï¼Œå³è‡ªç”±åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰©å±•çš„ä½ç½®å°ºåº¦å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Essentially, in this network, because of the use of linear activations, the variance of z for layer k in the network is the variance of z in the preceding layer, var(z(kâˆ’1)), scaled by nin(k) Ã— var(W(k)).",
            "zh": "ä»æœ¬è´¨ä¸Šè®²ï¼Œåœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œç”±äºä½¿ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œç½‘ç»œä¸­ç¬¬ k å±‚çš„ z æ–¹å·®æ˜¯å‰ä¸€å±‚ varï¼ˆzï¼ˆkâˆ’1ï¼‰ï¼‰ ä¸­ z çš„æ–¹å·®ï¼Œç”± ninï¼ˆkï¼‰ Ã— varï¼ˆWï¼ˆkï¼‰ï¼‰ ç¼©æ”¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.5â€ƒSummary",
            "zh": "9.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Calculating probabilities in this way is known as summing out or marginalization.4",
            "zh": "ä»¥è¿™ç§æ–¹å¼è®¡ç®—æ¦‚ç‡è¢«ç§°ä¸ºæ€»ç»“æˆ–è¾¹ç¼˜åŒ–4ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hecht-Nielsen, Robert. 1987. Kolmogorovâ€™s mapping neural network existence theorem. In Proceedings of the IEEE first international conference on neural networks, Vol. 3, 11â€“13.",
            "zh": "èµ«å…‹ç‰¹-å°¼å°”æ£®ï¼Œç½—ä¼¯ç‰¹ã€‚1987. Kolmogorov æ˜ å°„ç¥ç»ç½‘ç»œå­˜åœ¨å®šç†.IEEEç¬¬ä¸€å±Šç¥ç»ç½‘ç»œå›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œç¬¬3å·ï¼Œç¬¬11-13é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the gradient descent algorithm will converge to the global minimum eventually, it takes a very long time as tiny changes are made to the weights at each iteration of the algorithm.",
            "zh": "å°½ç®¡æ¢¯åº¦ä¸‹é™ç®—æ³•æœ€ç»ˆä¼šæ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼ï¼Œä½†è¿™éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œå› ä¸ºåœ¨ç®—æ³•çš„æ¯æ¬¡è¿­ä»£ä¸­éƒ½ä¼šå¯¹æƒé‡è¿›è¡Œå¾®å°çš„æ›´æ”¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate the backpropagation process through a convolutional layer, we need to shift our focus from the flow of data through the layer to the neural architecture of the layer.",
            "zh": "ä¸ºäº†è¯´æ˜é€šè¿‡å·ç§¯å±‚çš„åå‘ä¼ æ’­è¿‡ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦å°†æ³¨æ„åŠ›ä»é€šè¿‡å±‚çš„æ•°æ®æµè½¬ç§»åˆ°å±‚çš„ç¥ç»æ¶æ„ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The explanation of the backpropagation algorithm presented in this chapter is based on Chapter 6 of Kelleher (2019).",
            "zh": "æœ¬ç« ä¸­ä»‹ç»çš„åå‘ä¼ æ’­ç®—æ³•çš„è§£é‡ŠåŸºäºKelleher ï¼ˆ2019ï¼‰çš„ç¬¬6ç« ã€‚"
        }
    },
    {
        "translation": {
            "en": "What tells us that these weights suitably capture the relationship within the training dataset?",
            "zh": "ä»€ä¹ˆå‘Šè¯‰æˆ‘ä»¬è¿™äº›æƒé‡å¯ä»¥é€‚å½“åœ°æ•è·è®­ç»ƒæ•°æ®é›†ä¸­çš„å…³ç³»ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "After the training process has completed, we find the point at which performance on the validation set began to disimprove and revert back to the model trained at that point.",
            "zh": "è®­ç»ƒè¿‡ç¨‹å®Œæˆåï¼Œæˆ‘ä»¬ä¼šå‘ç°éªŒè¯é›†ä¸Šçš„æ€§èƒ½å¼€å§‹ä¸‹é™å¹¶æ¢å¤åˆ°å½“æ—¶è®­ç»ƒçš„æ¨¡å‹çš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "forward reasoning, 248",
            "zh": "æ­£å‘æ¨ç†ï¼Œ248"
        }
    },
    {
        "translation": {
            "en": "The offending large maximums for CLAIM AMOUNT and AMOUNT RECEIVED both come from d302 in Table 3.2[56].",
            "zh": "CLAIM AMOUNT å’Œ AMOUNT RECEIVED çš„è¿è§„æœ€å¤§å€¼å‡æ¥è‡ªè¡¨ 3.2 ä¸­çš„ d302[56]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Aâ€…â€…â€…Descriptive Statistics and Data Visualization for Machine Learning",
            "zh": "æœºå™¨å­¦ä¹ çš„æè¿°æ€§ç»Ÿè®¡å’Œæ•°æ®å¯è§†åŒ–"
        }
    },
    {
        "translation": {
            "en": "The classification accuracy was 87.979% (with an average class accuracy of 67.305%), which was similar to performance on the training data and well above the target that Jocelyn and Edwin had agreed on at the beginning of the project.",
            "zh": "åˆ†ç±»å‡†ç¡®ç‡ä¸º 87.979%ï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡ä¸º 67.305%ï¼‰ï¼Œè¿™ä¸è®­ç»ƒæ•°æ®çš„è¡¨ç°ç›¸ä¼¼ï¼Œè¿œé«˜äº Jocelyn å’Œ Edwin åœ¨é¡¹ç›®å¼€å§‹æ—¶å•†å®šçš„ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the ground truth labels previously given, calculate the categorical cross entropy for the query set. Compare these values to the squared error loss values for each instance.",
            "zh": "ä½¿ç”¨å‰é¢ç»™å‡ºçš„åŸºæœ¬çœŸå€¼æ ‡ç­¾ï¼Œè®¡ç®—æŸ¥è¯¢é›†çš„åˆ†ç±»äº¤å‰ç†µã€‚å°†è¿™äº›å€¼ä¸æ¯ä¸ªå®ä¾‹çš„å¹³æ–¹è¯¯å·®æŸå¤±å€¼è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.3",
            "zh": "å›¾ 6.3"
        }
    },
    {
        "translation": {
            "en": "These changes in the rankings of the instances is a direct result of normalizing the features and reflects the fact that the distance calculations are no longer dominated by the SALARY feature.",
            "zh": "å®ä¾‹æ’åçš„è¿™äº›å˜åŒ–æ˜¯è§„èŒƒåŒ–ç‰¹å¾çš„ç›´æ¥ç»“æœï¼Œåæ˜ äº†è·ç¦»è®¡ç®—ä¸å†ç”± SALARY ç‰¹å¾ä¸»å¯¼çš„äº‹å®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This adjustment should ensure that the change in the weight leads to a move downward on the error surface.",
            "zh": "è¿™ç§è°ƒæ•´åº”ç¡®ä¿æƒé‡çš„å˜åŒ–å¯¼è‡´è¯¯å·®æ›²é¢ä¸Šçš„å‘ä¸‹ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "unconditional probability, 759",
            "zh": "æ— æ¡ä»¶æ¦‚ç‡ï¼Œ759"
        }
    },
    {
        "translation": {
            "en": "For example, the first value in ctâˆ’1 is 1, and this is multiplied by an ft value near 1 resulting in a câ€¡ value of 0.997527377.",
            "zh": "ä¾‹å¦‚ï¼Œctâˆ’1 ä¸­çš„ç¬¬ä¸€ä¸ªå€¼æ˜¯ 1ï¼Œç„¶åä¹˜ä»¥ 1 é™„è¿‘çš„ ft å€¼ï¼Œå¾—å‡º câ€¡ å€¼ 0.997527377ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.1830",
            "zh": "0.1830"
        }
    },
    {
        "translation": {
            "en": "This can be useful if the reason that specific values for a feature are missing might have some relationship to the target featureâ€”for example, if a feature that has missing values represented sensitive personal data, peopleâ€™s readiness to provide this data (or not) might tell us something about them.",
            "zh": "å¦‚æœç¼ºå°‘è¦ç´ çš„ç‰¹å®šå€¼çš„åŸå› å¯èƒ½ä¸ç›®æ ‡è¦ç´ æœ‰æŸç§å…³ç³»ï¼Œåˆ™æ­¤æ–¹æ³•éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚ï¼Œå¦‚æœç¼ºå°‘å€¼çš„è¦ç´ è¡¨ç¤ºæ•æ„Ÿçš„ä¸ªäººæ•°æ®ï¼Œåˆ™äººä»¬æ˜¯å¦æ„¿æ„æä¾›æ­¤æ•°æ®å¯èƒ½ä¼šå‘Šè¯‰æˆ‘ä»¬æœ‰å…³å®ƒä»¬çš„ä¸€äº›ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Compute the distribution for C given D: P(c | d) = 0.2, P(Â¬c | d) = 0.8",
            "zh": "1. è®¡ç®—ç»™å®š D çš„ C åˆ†å¸ƒï¼šPï¼ˆc | dï¼‰ = 0.2ï¼ŒPï¼ˆÂ¬c | dï¼‰ = 0.8"
        }
    },
    {
        "translation": {
            "en": "The natural consequence of this is that using a softmax layer, each neuron is trained to predict the probability of one of the levels of the categorical target feature.",
            "zh": "è¿™æ ·åšçš„è‡ªç„¶ç»“æœæ˜¯ï¼Œä½¿ç”¨ softmax å±‚ï¼Œæ¯ä¸ªç¥ç»å…ƒéƒ½è¢«è®­ç»ƒæ¥é¢„æµ‹åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„ä¸€ä¸ªæ°´å¹³çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2.1â€ƒDecision Trees",
            "zh": "4.2.1 å†³ç­–æ ‘"
        }
    },
    {
        "translation": {
            "en": "The non-linear decision boundary that is just about perceivable in Figure 7.18[355] can be represented using a third-order polynomial in the two descriptive features, P20 and P45. The simple regression model we trained previously cannot cope with a non-linear decision boundary like the one seen in Figure 7.18[355]. We can, however, rewrite the logistic regression equation from Equation (7.26)[342] to use basis functions as follows:",
            "zh": "å›¾7.18[355]ä¸­å‡ ä¹å¯ä»¥æ„ŸçŸ¥çš„éçº¿æ€§å†³ç­–è¾¹ç•Œå¯ä»¥ä½¿ç”¨ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾P20å’ŒP45ä¸­çš„ä¸‰é˜¶å¤šé¡¹å¼è¡¨ç¤ºã€‚æˆ‘ä»¬ä¹‹å‰è®­ç»ƒçš„ç®€å•å›å½’æ¨¡å‹æ— æ³•å¤„ç†å›¾ 7.18[355] æ‰€ç¤ºçš„éçº¿æ€§å†³ç­–è¾¹ç•Œã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é‡å†™ç­‰å¼ï¼ˆ7.26ï¼‰[342]ä¸­çš„é€»è¾‘å›å½’æ–¹ç¨‹ï¼Œä»¥ä½¿ç”¨åŸºå‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "AlphaZero, 677",
            "zh": "é˜¿å°”æ³•é›¶ï¼Œ677"
        }
    },
    {
        "translation": {
            "en": "Then, for each level of the second feature, we draw a bar plot of the first feature using only the instances in the dataset for which the second feature has that level.",
            "zh": "ç„¶åï¼Œå¯¹äºç¬¬äºŒä¸ªç‰¹å¾çš„æ¯ä¸ªçº§åˆ«ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨æ•°æ®é›†ä¸­ç¬¬äºŒä¸ªç‰¹å¾å…·æœ‰è¯¥çº§åˆ«çš„å®ä¾‹ç»˜åˆ¶ç¬¬ä¸€ä¸ªç‰¹å¾çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature selection is an important process in any machine learning project and should generally be applied no matter what type of models are being developed.",
            "zh": "ç‰¹å¾é€‰æ‹©æ˜¯ä»»ä½•æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­çš„ä¸€ä¸ªé‡è¦è¿‡ç¨‹ï¼Œæ— è®ºæ­£åœ¨å¼€å‘å“ªç§ç±»å‹çš„æ¨¡å‹ï¼Œé€šå¸¸éƒ½åº”è¯¥åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "These examples also highlight that covariance is one way of measuring the spread of a dataset.",
            "zh": "è¿™äº›ç¤ºä¾‹è¿˜å¼ºè°ƒäº†åæ–¹å·®æ˜¯è¡¡é‡æ•°æ®é›†åˆ†å¸ƒçš„ä¸€ç§æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A full joint probability distribution is simply a joint probability distribution over all the features in a domain.",
            "zh": "å®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒåªæ˜¯åŸŸä¸­æ‰€æœ‰ç‰¹å¾çš„è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "By the time her test came around, Sarah had become an expert at the river-crossing challenge. No matter how awkwardly the scout leaders laid out the stepping-stones, she could quickly assess the situation each time the blindfold was cleared and choose the right direction to step in. She completed the challenge in record time and was awarded the pioneering badge.",
            "zh": "å½“å¥¹çš„æµ‹è¯•åˆ°æ¥æ—¶ï¼Œèæ‹‰å·²ç»æˆä¸ºè¿‡æ²³æŒ‘æˆ˜çš„ä¸“å®¶ã€‚æ— è®ºä¾¦å¯Ÿé˜Ÿé•¿å¸ƒç½®çš„å«è„šçŸ³å¤šä¹ˆç¬¨æ‹™ï¼Œå¥¹éƒ½èƒ½åœ¨æ¯æ¬¡è’™çœ¼è¢«æ¸…é™¤æ—¶è¿…é€Ÿè¯„ä¼°æƒ…å†µï¼Œå¹¶é€‰æ‹©æ­£ç¡®çš„æ–¹å‘ä»‹å…¥ã€‚å¥¹ä»¥åˆ›çºªå½•çš„æ—¶é—´å®Œæˆäº†æŒ‘æˆ˜ï¼Œå¹¶è¢«æˆäºˆå¼€æ‹“è€…å¾½ç« ã€‚"
        }
    },
    {
        "translation": {
            "en": "The flow of error gradients through a long short-term memory unit during backpropagation.",
            "zh": "åå‘ä¼ æ’­æœŸé—´é€šè¿‡é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„è¯¯å·®æ¢¯åº¦æµã€‚"
        }
    },
    {
        "translation": {
            "en": "The members of a school basketball team. The height of each player is listed below the player. The dashed gray line shows the arithmetic mean of the playersâ€™ heights.",
            "zh": "å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ã€‚æ¯ä¸ªç©å®¶çš„èº«é«˜éƒ½åˆ—åœ¨ç©å®¶ä¸‹æ–¹ã€‚ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "24. See Esposito et al. (1997) and Mingers (1989) for overviews and empirical comparisons of a range of decision tree pruning methods based on error rate.",
            "zh": "24. å‚è§Espositoç­‰äººï¼ˆ1997å¹´ï¼‰å’ŒMingersï¼ˆ1989å¹´ï¼‰å¯¹ä¸€ç³»åˆ—åŸºäºé”™è¯¯ç‡çš„å†³ç­–æ ‘ä¿®å‰ªæ–¹æ³•çš„æ¦‚è¿°å’Œå®è¯æ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "14. This dataset is from the UCI Machine Learning repository Dua and Graff (2017) and was originally described by Alimoglu and Alpaydin (1996).",
            "zh": "14. è¯¥æ•°æ®é›†æ¥è‡ª UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ Dua å’Œ Graff ï¼ˆ2017ï¼‰ï¼Œæœ€åˆç”± Alimoglu å’Œ Alpaydin ï¼ˆ1996ï¼‰ æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "What we need to do at this point is to develop a formal model that captures the intuitions about the informativeness of these features. Unsurprisingly, we do this using Shannonâ€™s entropy model. The measure of informativeness that we use is known as information gain, which is a measure of the reduction in the overall entropy of a set of instances that is achieved by testing on a descriptive feature. Computing information gain is a three-step process:",
            "zh": "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬éœ€è¦åšçš„æ˜¯å¼€å‘ä¸€ä¸ªæ­£å¼çš„æ¨¡å‹æ¥æ•æ‰å…³äºè¿™äº›ç‰¹å¾çš„ä¿¡æ¯æ€§çš„ç›´è§‰ã€‚ä¸å‡ºæ‰€æ–™ï¼Œæˆ‘ä»¬ä½¿ç”¨ Shannon çš„ç†µæ¨¡å‹æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬ä½¿ç”¨çš„ä¿¡æ¯é‡åº¦é‡ç§°ä¸ºä¿¡æ¯å¢ç›Šï¼Œå®ƒæ˜¯é€šè¿‡æµ‹è¯•æè¿°æ€§ç‰¹å¾æ¥å®ç°çš„ä¸€ç»„å®ä¾‹çš„æ•´ä½“ç†µå‡å°‘çš„åº¦é‡ã€‚è®¡ç®—ä¿¡æ¯å¢ç›Šæ˜¯ä¸€ä¸ªä¸‰æ­¥è¿‡ç¨‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Consequently, backpropagating the error gradient through the neuron that uses a logistic activation function involves multiplying the error term by a value â‰¤ 0.25 and that is â‰ˆ 0 for z values in the saturated regions of the logistic function.",
            "zh": "å› æ­¤ï¼Œåœ¨ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒä¸­åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦æ¶‰åŠå°†è¯¯å·®é¡¹ä¹˜ä»¥ 0.25 â‰¤å€¼ï¼Œå¯¹äºé€»è¾‘å‡½æ•°é¥±å’ŒåŒºåŸŸçš„ z å€¼ï¼Œè¯¥å€¼â‰ˆ 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: This solution first assumes that it is possible to run a process every quarter that performs an analysis of the behavior of each customer.",
            "zh": "å®¹é‡è¦æ±‚ï¼šæ­¤è§£å†³æ–¹æ¡ˆé¦–å…ˆå‡å®šå¯ä»¥æ¯å­£åº¦è¿è¡Œä¸€ä¸ªæµç¨‹ï¼Œè¯¥æµç¨‹å¯¹æ¯ä¸ªå®¢æˆ·çš„è¡Œä¸ºè¿›è¡Œåˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places.",
            "zh": "è”åˆå¾ªç¯ç”µå‚çš„ç¯å¢ƒå› å­å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„èŒƒå›´å½’ä¸€åŒ–å°æ—¶æ ·æœ¬ï¼Œå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The boundary between d3 and d7 is",
            "zh": "d3 å’Œ d7 ä¹‹é—´çš„è¾¹ç•Œæ˜¯"
        }
    },
    {
        "translation": {
            "en": "This exploding z value dynamic is a problem because if we wish to avoid saturated activation functions, we need to stop the z values in neurons taking an extreme value (where the concept of extreme is dependent on the activation function).",
            "zh": "è¿™ç§çˆ†ç‚¸æ€§çš„ z å€¼åŠ¨æ€æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬æƒ³é¿å…é¥±å’Œæ¿€æ´»å‡½æ•°ï¼Œæˆ‘ä»¬éœ€è¦åœæ­¢ç¥ç»å…ƒä¸­çš„ z å€¼å–æå€¼ï¼ˆå…¶ä¸­æå€¼çš„æ¦‚å¿µå–å†³äºæ¿€æ´»å‡½æ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, the ability to select the appropriate machine learning algorithm (and hence inductive bias) to use for a given predictive task is one of the core skills that a data analyst must develop.",
            "zh": "äº‹å®ä¸Šï¼Œé€‰æ‹©é€‚å½“çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆä»¥åŠå½’çº³åå·®ï¼‰æ¥ç”¨äºç»™å®šé¢„æµ‹ä»»åŠ¡çš„èƒ½åŠ›æ˜¯æ•°æ®åˆ†æå¸ˆå¿…é¡»åŸ¹å…»çš„æ ¸å¿ƒæŠ€èƒ½ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset relates to a fraud detection scenario in which we would like to build a model that predicts whether loan applications are fraudulent or genuine.",
            "zh": "è¯¥æ•°æ®é›†ä¸æ¬ºè¯ˆæ£€æµ‹åœºæ™¯ç›¸å…³ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¯¥åœºæ™¯ä¸­æ„å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è´·æ¬¾ç”³è¯·æ˜¯æ¬ºè¯ˆæ€§è¿˜æ˜¯çœŸå®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. A Voronoi tessellation is a way of decomposing a space into regions in which each region belongs to an instance and contains all the points in the space whose distance to that instance is less than the distance to any other instance.",
            "zh": "4. Voronoi æ›²é¢ç»†åˆ†æ˜¯ä¸€ç§å°†ç©ºé—´åˆ†è§£ä¸ºåŒºåŸŸçš„æ–¹æ³•ï¼Œå…¶ä¸­æ¯ä¸ªåŒºåŸŸéƒ½å±äºä¸€ä¸ªå®ä¾‹ï¼Œå¹¶åŒ…å«ç©ºé—´ä¸­ä¸è¯¥å®ä¾‹çš„è·ç¦»å°äºä¸ä»»ä½•å…¶ä»–å®ä¾‹çš„è·ç¦»çš„æ‰€æœ‰ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, the forget gate has largely erased the original cell value from the cell state (i.e., the cell state has now forgotten the original value).",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé—å¿˜é—¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»å•å…ƒçŠ¶æ€ä¸­åˆ é™¤äº†åŸå§‹å•å…ƒå€¼ï¼ˆå³ï¼Œå•å…ƒçŠ¶æ€ç°åœ¨å·²ç»å¿˜è®°äº†åŸå§‹å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "branches, 121",
            "zh": "åˆ†æ”¯ï¼Œ 121"
        }
    },
    {
        "translation": {
            "en": "low risk",
            "zh": "ä½é£é™©"
        }
    },
    {
        "translation": {
            "en": "convergence criterion, 418",
            "zh": "æ”¶æ•›å‡†åˆ™ï¼Œ418"
        }
    },
    {
        "translation": {
            "en": "Overfitting happens for a number of reasons, including sampling variance18 and noise in the training set.19 The problem of overfitting can affect any machine learning algorithm; however, the fact that decision tree induction algorithms work by recursively splitting the training data means that they have a natural tendency to segregate noisy instances and to create leaf nodes around these instances.",
            "zh": "è¿‡æ‹Ÿåˆçš„å‘ç”Ÿæœ‰å¤šç§åŸå› ï¼ŒåŒ…æ‹¬é‡‡æ ·æ–¹å·®18å’Œè®­ç»ƒé›†ä¸­çš„å™ªå£°19ï¼Œè¿‡æ‹Ÿåˆé—®é¢˜ä¼šå½±å“ä»»ä½•æœºå™¨å­¦ä¹ ç®—æ³•;ç„¶è€Œï¼Œå†³ç­–æ ‘å½’çº³ç®—æ³•é€šè¿‡é€’å½’æ‹†åˆ†è®­ç»ƒæ•°æ®æ¥å·¥ä½œï¼Œè¿™æ„å‘³ç€å®ƒä»¬æœ‰ä¸€ç§è‡ªç„¶çš„å€¾å‘ï¼Œå³éš”ç¦»å˜ˆæ‚çš„å®ä¾‹ï¼Œå¹¶åœ¨è¿™äº›å®ä¾‹å‘¨å›´åˆ›å»ºå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "batch learning, 417",
            "zh": "æ‰¹é‡å­¦ä¹ ï¼Œ417"
        }
    },
    {
        "translation": {
            "en": "Equation (8.28)[415] illustrates how a weight in a network is updated after a single training example has been processed.",
            "zh": "ç­‰å¼ï¼ˆ8.28ï¼‰[415]è¯´æ˜äº†åœ¨å¤„ç†å•ä¸ªè®­ç»ƒç¤ºä¾‹åå¦‚ä½•æ›´æ–°ç½‘ç»œä¸­çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.94",
            "zh": "0.94"
        }
    },
    {
        "translation": {
            "en": "where Î± is a learning rate.",
            "zh": "å…¶ä¸­Î±æ˜¯å­¦ä¹ ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A recurrent neural network works in discrete time.",
            "zh": "é€’å½’ç¥ç»ç½‘ç»œåœ¨ç¦»æ•£æ—¶é—´å†…å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "data availability, 33",
            "zh": "æ•°æ®å¯ç”¨æ€§ï¼Œ 33"
        }
    },
    {
        "translation": {
            "en": "A prediction model that makes the correct predictions for these queries captures the underlying relationship between the descriptive and target features and is said to generalize well.",
            "zh": "å¯¹è¿™äº›æŸ¥è¯¢è¿›è¡Œæ­£ç¡®é¢„æµ‹çš„é¢„æµ‹æ¨¡å‹å¯ä»¥æ•è·æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„åŸºæœ¬å…³ç³»ï¼Œå¹¶ä¸”å¯ä»¥è¯´å¯ä»¥å¾ˆå¥½åœ°æ³›åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can be done by preparing a data quality report6 for each cluster that describes the instances that belong to that cluster.",
            "zh": "ä¸ºæ­¤ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªé›†ç¾¤å‡†å¤‡ä¸€ä»½æ•°æ®è´¨é‡æŠ¥å‘Š6ï¼Œè¯¥æŠ¥å‘Šæè¿°äº†å±äºè¯¥é›†ç¾¤çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "SARSA, 664, 664, 666, 676",
            "zh": "SARSAï¼Œ 664ï¼Œ 664ï¼Œ 666ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "At the time not every household in U.S. had telephones, and of those that did, a disproportionate number (relative to the total voting population of the U.S.) were Republican voters.",
            "zh": "å½“æ—¶ï¼Œå¹¶éç¾å›½æ¯ä¸ªå®¶åº­éƒ½æœ‰ç”µè¯ï¼Œåœ¨é‚£äº›æœ‰ç”µè¯çš„å®¶åº­ä¸­ï¼Œå…±å’Œå…šé€‰æ°‘çš„æ•°é‡ï¼ˆç›¸å¯¹äºç¾å›½çš„æ€»æŠ•ç¥¨äººå£ï¼‰ä¸æˆæ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, using hold-out sampling requires that we have enough data available to make suitably large training, test, and if required, validation sets.",
            "zh": "é¦–å…ˆï¼Œä½¿ç”¨ä¿æŒæŠ½æ ·éœ€è¦æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„å¯ç”¨æ•°æ®æ¥åˆ¶ä½œé€‚å½“å¤§çš„è®­ç»ƒã€æµ‹è¯•ä»¥åŠéœ€è¦çš„éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customer demographic records from the AT data warehouse",
            "zh": "æ¥è‡ª AT æ•°æ®ä»“åº“çš„å®¢æˆ·äººå£ç»Ÿè®¡è®°å½•"
        }
    },
    {
        "translation": {
            "en": "11.7â€…â€…â€…Exercises",
            "zh": "11.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "greedy local search problem, 228",
            "zh": "è´ªå©ªçš„æœ¬åœ°æœç´¢é—®é¢˜ï¼Œ228"
        }
    },
    {
        "translation": {
            "en": "This is calculated by plugging the z for the neuron into the derivative of the activation function.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†ç¥ç»å…ƒçš„ z ä»£å…¥æ¿€æ´»å‡½æ•°çš„å¯¼æ•°æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(f) Different clusterings found for the mobile phone customer dataset in Table 10.1[604] for values of k in (2,9). (g) shows the silhouette for each clustering.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆfï¼‰ è¡¨ 10.1[604] ä¸­ k å€¼çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†å‘ç°ä¸åŒçš„èšç±»ã€‚ï¼ˆgï¼‰ æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„è½®å»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "that converts the result of the weighted sum to the output activation.",
            "zh": "è¿™ä¼šå°†åŠ æƒæ€»å’Œçš„ç»“æœè½¬æ¢ä¸ºè¾“å‡ºæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second part of each chapter explains different ways that the standard algorithm can be extended and well-known variations on the algorithm.",
            "zh": "æ¯ç« çš„ç¬¬äºŒéƒ¨åˆ†è§£é‡Šäº†æ ‡å‡†ç®—æ³•å¯ä»¥æ‰©å±•çš„ä¸åŒæ–¹å¼ä»¥åŠç®—æ³•çš„ä¼—æ‰€å‘¨çŸ¥çš„å˜ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table contains an extract from this ABTâ€”the full ABT contains 680 instances.",
            "zh": "ä¸‹è¡¨åŒ…å«æ­¤ ABT çš„æ‘˜å½• - å®Œæ•´çš„ ABT åŒ…å« 680 ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2",
            "zh": "å›¾ 8.2"
        }
    },
    {
        "translation": {
            "en": "Once the target feature has been normalized, then during training the error of the network on an example can be calculated by directly comparing the output of the network with the normalized target feature value.",
            "zh": "ä¸€æ—¦ç›®æ ‡ç‰¹å¾è¢«å½’ä¸€åŒ–ï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒæœŸé—´ï¼Œå¯ä»¥é€šè¿‡ç›´æ¥å°†ç½‘ç»œçš„è¾“å‡ºä¸å½’ä¸€åŒ–çš„ç›®æ ‡ç‰¹å¾å€¼è¿›è¡Œæ¯”è¾ƒæ¥è®¡ç®—ç¤ºä¾‹ä¸Šçš„ç½‘ç»œè¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "25. See Section 3.6.3[91].",
            "zh": "25. å‚è§ç¬¬ 3.6.3 èŠ‚[91]ã€‚"
        }
    },
    {
        "translation": {
            "en": "The instances have moved away from each other, and the sampling density has decreased.",
            "zh": "å®ä¾‹å½¼æ­¤è¿œç¦»ï¼Œé‡‡æ ·å¯†åº¦é™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.1",
            "zh": "å›¾ 6.1"
        }
    },
    {
        "translation": {
            "en": "5.20â€…â€…â€…The process of model induction with feature selection.",
            "zh": "5.20 ç‰¹å¾é€‰æ‹©çš„æ¨¡å‹å½’çº³è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "imputation, 69, 296",
            "zh": "æ’è¡¥ï¼Œ 69ï¼Œ 296"
        }
    },
    {
        "translation": {
            "en": "Keri, Jonah. 2007. Baseball between the numbers: Why everything you know about the game is wrong. Basic Books.",
            "zh": "å‡¯ä¸½ï¼Œçº¦æ‹¿ã€‚2007. æ•°å­—ä¹‹é—´çš„æ£’çƒï¼šä¸ºä»€ä¹ˆä½ å¯¹æ¯”èµ›çš„äº†è§£éƒ½æ˜¯é”™è¯¯çš„ã€‚åŸºæœ¬ä¹¦ç±ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.3â€…â€…â€…Handling Categorical Target Features: Softmax Output Layers and Cross-Entropy Loss Functions",
            "zh": "8.4.3 å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼šSoftmax è¾“å‡ºå±‚å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "The main advantage of this initialization regime is its simplicity.",
            "zh": "è¿™ç§åˆå§‹åŒ–åˆ¶åº¦çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å…¶ç®€å•æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 14.2[735] summarizes the different perspectives on the model types that we have presented in this book.",
            "zh": "è¡¨14.2[735]æ€»ç»“äº†æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­æå‡ºçš„å…³äºæ¨¡å‹ç±»å‹çš„ä¸åŒè§‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation 8.44[442] lists the calculations of the Î´s for d2 for all the neurons in the ReLU network.",
            "zh": "å…¬å¼ 8.44[442] åˆ—å‡ºäº† ReLU ç½‘ç»œä¸­æ‰€æœ‰ç¥ç»å…ƒçš„ d2 çš„ Î´s è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The layer of tanh units is as wide as the cell state and so there is one tanh activation per activation in the cell state.",
            "zh": "tanh å•å…ƒçš„å±‚ä¸ç»†èƒçŠ¶æ€ä¸€æ ·å®½ï¼Œå› æ­¤åœ¨ç»†èƒçŠ¶æ€ä¸­æ¯æ¬¡æ¿€æ´»éƒ½æœ‰ä¸€ä¸ª tanh æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "To understand how to calculate the value of the partial derivative of the error function with respect to a particular weight, let us imagine for a moment that our training dataset, ğ’Ÿ, contains just one training instance: (d,t), where d is a set of descriptive features and t is a target feature. The gradient of the error surface is given as the partial derivative of L2 with respect to each weight, w[j]",
            "zh": "ä¸ºäº†ç†è§£å¦‚ä½•è®¡ç®—è¯¯å·®å‡½æ•°ç›¸å¯¹äºç‰¹å®šæƒé‡çš„åå¯¼æ•°å€¼ï¼Œè®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›† D åªåŒ…å«ä¸€ä¸ªè®­ç»ƒå®ä¾‹ï¼šï¼ˆdï¼Œtï¼‰ï¼Œå…¶ä¸­ d æ˜¯ä¸€ç»„æè¿°æ€§ç‰¹å¾ï¼Œt æ˜¯ç›®æ ‡ç‰¹å¾ã€‚è¯¯å·®é¢çš„æ¢¯åº¦æ˜¯ L2 ç›¸å¯¹äºæ¯ä¸ªæƒé‡ w[j] çš„åå¯¼æ•°"
        }
    },
    {
        "translation": {
            "en": "We then present the ID3 algorithm, the standard algorithm used to induce a decision tree from a dataset.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº† ID3 ç®—æ³•ï¼Œè¿™æ˜¯ç”¨äºä»æ•°æ®é›†ä¸­è¯±å¯¼å‡ºå†³ç­–æ ‘çš„æ ‡å‡†ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Events Involving Non-Binary Features",
            "zh": "æ¶‰åŠéäºŒè¿›åˆ¶ç‰¹å¾çš„äº‹ä»¶"
        }
    },
    {
        "translation": {
            "en": "We can use percentiles to describe another measure of variation known as the inter-quartile range (IQR). The inter-quartile range is calculated as the difference between the 25th percentile and the 75th percentile. These percentiles are also known as the lower quartile (or 1st quartile) and the upper quartile (or 3rd quartile), hence the name inter-quartile range. For the heights of the first basketball team, the inter-quartile range is 151 âˆ’ 140 = 11, while for the second team, it is 165 âˆ’ 123 = 42.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç™¾åˆ†ä½æ•°æ¥æè¿°å¦ä¸€ç§ç§°ä¸ºå››åˆ†ä½è· ï¼ˆIQRï¼‰ çš„å˜å¼‚åº¦é‡ã€‚å››åˆ†ä½æ•°é—´èŒƒå›´è®¡ç®—ä¸ºç¬¬ 25 ä¸ªç™¾åˆ†ä½æ•°å’Œç¬¬ 75 ä¸ªç™¾åˆ†ä½æ•°ä¹‹é—´çš„å·®å€¼ã€‚è¿™äº›ç™¾åˆ†ä½æ•°ä¹Ÿç§°ä¸ºä¸‹å››åˆ†ä½æ•°ï¼ˆæˆ–ç¬¬ä¸€å››åˆ†ä½æ•°ï¼‰å’Œä¸Šå››åˆ†ä½æ•°ï¼ˆæˆ–ç¬¬ä¸‰å››åˆ†ä½æ•°ï¼‰ï¼Œå› æ­¤ç§°ä¸ºå››åˆ†ä½æ•°é—´èŒƒå›´ã€‚å¯¹äºç¬¬ä¸€æ”¯ç¯®çƒé˜Ÿçš„èº«é«˜ï¼Œå››åˆ†ä½æ•°èŒƒå›´ä¸º 151 âˆ’ 140 = 11ï¼Œè€Œå¯¹äºç¬¬äºŒæ”¯çƒé˜Ÿï¼Œåˆ™ä¸º 165 âˆ’ 123 = 42ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first operation in this sequence is the multiplication of the matrix containing the weights on the connections into the neurons in the hidden layer by the outputs of the input layer.",
            "zh": "æ­¤åºåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªæ“ä½œæ˜¯å°†åŒ…å«ä¸éšè—å±‚ä¸­ç¥ç»å…ƒçš„è¿æ¥çš„æƒé‡çš„çŸ©é˜µä¹˜ä»¥è¾“å…¥å±‚çš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "While it is interesting to see how derivatives can be calculated for discrete examples, it is much more common that we need to calculate the derivative of a continuous function. A continuous function, f(x), generates an output for every value of a variable x based on some expression involving x. For example:",
            "zh": "è™½ç„¶äº†è§£å¦‚ä½•è®¡ç®—ç¦»æ•£ç¤ºä¾‹çš„å¯¼æ•°å¾ˆæœ‰è¶£ï¼Œä½†æ›´å¸¸è§çš„æ˜¯æˆ‘ä»¬éœ€è¦è®¡ç®—è¿ç»­å‡½æ•°çš„å¯¼æ•°ã€‚è¿ç»­å‡½æ•° fï¼ˆxï¼‰ æ ¹æ®æ¶‰åŠ x çš„æŸä¸ªè¡¨è¾¾å¼ä¸ºå˜é‡ x çš„æ¯ä¸ªå€¼ç”Ÿæˆè¾“å‡ºã€‚ä¾‹å¦‚ï¼š"
        }
    },
    {
        "translation": {
            "en": "7â€…â€…â€…Error-Based Learning",
            "zh": "7 åŸºäºé”™è¯¯çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Schapire, Robert E. 1999. A brief introduction to boosting. In Proceedings of the sixteenth international joint conference on artificial intelligence (IJCAI-99), Vol. 2, 1401â€“1406.",
            "zh": "Schapireï¼Œ Robert E. 1999 å¹´ã€‚æå‡çš„ç®€è¦ä»‹ç»ã€‚ç¬¬åå…­å±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®ï¼ˆIJCAI-99ï¼‰è®ºæ–‡é›†ï¼Œç¬¬2å·ï¼Œç¬¬1401-1406é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.5â€ƒPerformance Measures: Continuous Targets",
            "zh": "9.4.5 ç»©æ•ˆè¡¡é‡ï¼šæŒç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "The way to solve the problem of zero probabilities is to think in terms of how the probability of a continuous feature taking a value is distributed across the range of values that a continuous feature can take.",
            "zh": "è§£å†³é›¶æ¦‚ç‡é—®é¢˜çš„æ–¹æ³•æ˜¯è€ƒè™‘è¿ç»­ç‰¹å¾å–å€¼çš„æ¦‚ç‡å¦‚ä½•åˆ†å¸ƒåœ¨è¿ç»­ç‰¹å¾å¯ä»¥å–çš„å€¼èŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.1â€…â€…â€…Derivatives of Continuous Functions",
            "zh": "C.1 è¿ç»­å‡½æ•°çš„å¯¼æ•°"
        }
    },
    {
        "translation": {
            "en": "absence-presence (AP), how often a false value occurred in the query data q when a true value occurred in the data for the comparison user (d1 or d2) for the same feature",
            "zh": "ä¸å­˜åœ¨ ï¼ˆAPï¼‰ï¼Œå½“åŒä¸€åŠŸèƒ½çš„æ¯”è¾ƒç”¨æˆ·ï¼ˆd1 æˆ– d2ï¼‰çš„æ•°æ®ä¸­å‡ºç°çœŸå€¼æ—¶ï¼ŒæŸ¥è¯¢æ•°æ® q ä¸­å‡ºç°å‡å€¼çš„é¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "The lines in this figure indicate the hyperplanes partitioning the feature space that were created by the splits encoded in the non-leaf nodes in the tree.",
            "zh": "æ­¤å›¾ä¸­çš„çº¿è¡¨ç¤ºåˆ†åŒºç‰¹å¾ç©ºé—´çš„è¶…å¹³é¢ï¼Œè¿™äº›è¶…å¹³é¢æ˜¯ç”±æ ‘ä¸­çš„éå¶èŠ‚ç‚¹ä¸­ç¼–ç çš„æ‹†åˆ†åˆ›å»ºçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, when we wish to increase the representational power of a network, there is often a trade-off between making a network deeper and making the layers wider.",
            "zh": "å› æ­¤ï¼Œå½“æˆ‘ä»¬å¸Œæœ›å¢åŠ ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›æ—¶ï¼Œé€šå¸¸ä¼šåœ¨ä½¿ç½‘ç»œæ›´æ·±å’Œæ›´å®½ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "underfitting, 14, 193",
            "zh": "æ¬ æ‹Ÿåˆï¼Œ 14ï¼Œ 193"
        }
    },
    {
        "translation": {
            "en": "2,000,000",
            "zh": "2,000,000"
        }
    },
    {
        "translation": {
            "en": "Invalid outliers are values that have been included in a sample through error and are often referred to as noise in the data.",
            "zh": "æ— æ•ˆå¼‚å¸¸å€¼æ˜¯é€šè¿‡è¯¯å·®åŒ…å«åœ¨æ ·æœ¬ä¸­çš„å€¼ï¼Œé€šå¸¸ç§°ä¸ºæ•°æ®ä¸­çš„å™ªå£°ã€‚"
        }
    },
    {
        "translation": {
            "en": "One thing that is immediately apparent in Table 5.8[209] is that the AGE and RATING features have different ranges. We should normalize these features before we build a model. Table 5.9[210] lists the whiskey dataset after the descriptive features have been normalized, using range normalization to the range [0,1].",
            "zh": "åœ¨è¡¨5.8[209]ä¸­æ˜¾è€Œæ˜“è§çš„ä¸€ä»¶äº‹æ˜¯ï¼ŒAGEå’ŒRATINGç‰¹å¾å…·æœ‰ä¸åŒçš„èŒƒå›´ã€‚åœ¨æ„å»ºæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œè§„èŒƒåŒ–ã€‚è¡¨5.9[210]åˆ—å‡ºäº†æè¿°æ€§ç‰¹å¾å½’ä¸€åŒ–åçš„å¨å£«å¿Œæ•°æ®é›†ï¼Œä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–åˆ°èŒƒå›´[0,1]ã€‚"
        }
    },
    {
        "translation": {
            "en": "AVGRECEIVEDMINS",
            "zh": "AVGRECEIVEDMINS"
        }
    },
    {
        "translation": {
            "en": "1.5â€…â€…â€…The age-income dataset.",
            "zh": "1.5 å¹´é¾„-æ”¶å…¥æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) As part of the study, researchers have decided to create a predictive model to screen participants based on their risk of heart disease. You have been asked to implement this screening model using a random forest. The three tables below list three bootstrap samples that have been generated from the above dataset. Using these bootstrap samples, create the decision trees that will be in the random forest model (use entropy-based information gain as the feature selection criterion).",
            "zh": "ï¼ˆaï¼‰ä½œä¸ºç ”ç©¶çš„ä¸€éƒ¨åˆ†ï¼Œç ”ç©¶äººå‘˜å†³å®šåˆ›å»ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œæ ¹æ®å‚ä¸è€…æ‚£å¿ƒè„ç—…çš„é£é™©è¿›è¡Œç­›æŸ¥ã€‚æˆ‘ä»¬è¦æ±‚æ‚¨ä½¿ç”¨éšæœºæ£®æ—å®ç°æ­¤ç­›é€‰æ¨¡å‹ã€‚ä¸‹é¢çš„ä¸‰ä¸ªè¡¨åˆ—å‡ºäº†ä»ä¸Šè¿°æ•°æ®é›†ç”Ÿæˆçš„ä¸‰ä¸ªå¼•å¯¼æ ·æœ¬ã€‚ä½¿ç”¨è¿™äº› bootstrap æ ·æœ¬ï¼Œåˆ›å»ºå°†ä½äºéšæœºæ£®æ—æ¨¡å‹ä¸­çš„å†³ç­–æ ‘ï¼ˆä½¿ç”¨åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šä½œä¸ºç‰¹å¾é€‰æ‹©æ ‡å‡†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, although in principle a recurrent neural network has the ability to propagate information across the spans of long-distance dependencies in input sequences, the vanishing and exploding gradient problems limit the ability of these networks to learn these dependencies.",
            "zh": "å› æ­¤ï¼Œå°½ç®¡åŸåˆ™ä¸Šé€’å½’ç¥ç»ç½‘ç»œå…·æœ‰åœ¨è¾“å…¥åºåˆ—ä¸­é•¿è·ç¦»ä¾èµ–å…³ç³»çš„è·¨åº¦ä¸­ä¼ æ’­ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä½†æ¶ˆå¤±å’Œçˆ†ç‚¸æ¢¯åº¦é—®é¢˜é™åˆ¶äº†è¿™äº›ç½‘ç»œå­¦ä¹ è¿™äº›ä¾èµ–å…³ç³»çš„èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "One problem that we need to solve in order to use the model defined in Equation (7.24)[341] is how to determine the values for the weights, w, that will minimize the error function for our hypothesis w(d).",
            "zh": "ä¸ºäº†ä½¿ç”¨æ–¹ç¨‹ï¼ˆ7.24ï¼‰[341]ä¸­å®šä¹‰çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦è§£å†³çš„ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚ä½•ç¡®å®šæƒé‡wçš„å€¼ï¼Œè¿™å°†ä½¿æˆ‘ä»¬çš„å‡è®¾wï¼ˆdï¼‰çš„è¯¯å·®å‡½æ•°æœ€å°åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically mini-batches are all of the same size.",
            "zh": "é€šå¸¸ï¼Œå°æ‰¹é‡çš„å¤§å°éƒ½ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "0.047",
            "zh": "0.047"
        }
    },
    {
        "translation": {
            "en": "Lift tells us how much higher the actual percentage of positive instances in a decile dec is than the rate expected.",
            "zh": "Lift å‘Šè¯‰æˆ‘ä»¬ååˆ†ä½æ•° dec ä¸­é˜³æ€§å®ä¾‹çš„å®é™…ç™¾åˆ†æ¯”æ¯”é¢„æœŸæ¯”ç‡é«˜å¤šå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.11",
            "zh": "è¡¨ 7.11"
        }
    },
    {
        "translation": {
            "en": "Generally, finding a good combination of values for the batch size and learning rate hyper-parameters involves trial-and-error experimentation.",
            "zh": "é€šå¸¸ï¼Œè¦æ‰¾åˆ°æ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡è¶…å‚æ•°å€¼çš„è‰¯å¥½ç»„åˆï¼Œéœ€è¦è¿›è¡Œè¯•é”™è¯•éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The âˆ‚â„°/âˆ‚wi,k calculations for d2 for every weight in the network. We use the neuron index 0 to denote the bias input for each neuron.",
            "zh": "âˆ‚E/âˆ‚wiï¼Œk è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªæƒé‡çš„ d2ã€‚æˆ‘ä»¬ä½¿ç”¨ç¥ç»å…ƒç´¢å¼• 0 æ¥è¡¨ç¤ºæ¯ä¸ªç¥ç»å…ƒçš„åå·®è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "In contrast with this, unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset.",
            "zh": "ä¸æ­¤ç›¸åï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨æ²¡æœ‰ç›®æ ‡ç‰¹å¾çš„æƒ…å†µä¸‹ä½¿ç”¨ï¼Œå¹¶å¯¹æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¸­çš„åº•å±‚ç»“æ„è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature",
            "zh": "ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "There are a number of different ways to find this point. In this chapter we describe a guided search approach known as the gradient descent algorithm. This is one of the most important algorithms in machine learning and, as we discuss in other chapters, can be used for many different purposes. The next section describes how gradient descent can be used to find the optimal weights for linear regression models that handle multiple descriptive features: multivariable linear regression models.",
            "zh": "æœ‰è®¸å¤šä¸åŒçš„æ–¹æ³•å¯ä»¥æ‰¾åˆ°è¿™ä¸€ç‚¹ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€ç§ç§°ä¸ºæ¢¯åº¦ä¸‹é™ç®—æ³•çš„å¼•å¯¼å¼æœç´¢æ–¹æ³•ã€‚è¿™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€é‡è¦çš„ç®—æ³•ä¹‹ä¸€ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨å…¶ä»–ç« èŠ‚ä¸­è®¨è®ºçš„é‚£æ ·ï¼Œå¯ä»¥ç”¨äºè®¸å¤šä¸åŒçš„ç›®çš„ã€‚ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥æŸ¥æ‰¾å¤„ç†å¤šä¸ªæè¿°æ€§ç‰¹å¾çš„çº¿æ€§å›å½’æ¨¡å‹çš„æœ€ä½³æƒé‡ï¼šå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are no weights on the connections between the output of the hidden layer and the memory buffer.",
            "zh": "éšè—å±‚çš„è¾“å‡ºå’Œå†…å­˜ç¼“å†²åŒºä¹‹é—´çš„è¿æ¥æ²¡æœ‰æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12(b)[205] shows a plot of the feature space after the features have been normalized.",
            "zh": "å›¾5.12ï¼ˆbï¼‰[205]æ˜¾ç¤ºäº†ç‰¹å¾å½’ä¸€åŒ–åçš„ç‰¹å¾ç©ºé—´å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two values in the domain of the MENINGITIS feature, true and false, so we have to do this calculation once for each. Considering first the calculation for m, we need the following probabilities, which can be computed directly from Table 6.1[246]",
            "zh": "è„‘è†œç‚ç‰¹å¾çš„åŸŸä¸­æœ‰ä¸¤ä¸ªå€¼ï¼Œtrue å’Œ falseï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»å¯¹æ¯ä¸ªå€¼è¿›è¡Œä¸€æ¬¡è®¡ç®—ã€‚é¦–å…ˆè€ƒè™‘ m çš„è®¡ç®—ï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹æ¦‚ç‡ï¼Œè¿™äº›æ¦‚ç‡å¯ä»¥ç›´æ¥ä»è¡¨ 6.1[246] ä¸­è®¡ç®—å‡ºæ¥"
        }
    },
    {
        "translation": {
            "en": "There are many genuine examples of features that will have such high cardinality, but some of the machine learning algorithms that we will look at will struggle to effectively use features with such high cardinality.",
            "zh": "æœ‰è®¸å¤šå…·æœ‰å¦‚æ­¤é«˜åŸºæ•°çš„ç‰¹å¾çš„çœŸå®ç¤ºä¾‹ï¼Œä½†æ˜¯æˆ‘ä»¬å°†è¦ç ”ç©¶çš„ä¸€äº›æœºå™¨å­¦ä¹ ç®—æ³•å°†éš¾ä»¥æœ‰æ•ˆåœ°ä½¿ç”¨å…·æœ‰å¦‚æ­¤é«˜åŸºæ•°çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Based on this data, calculate the following summary statistics for the POLICY feature:",
            "zh": "ï¼ˆaï¼‰ æ ¹æ®æ­¤æ•°æ®ï¼Œè®¡ç®— POLICY ç‰¹å¾çš„ä»¥ä¸‹æ±‡æ€»ç»Ÿè®¡é‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "Lifecycle Phase: The position of a customer or user in their lifecycle (for example, is a customer a new customer, a loyal customer, or a lapsing customer?).",
            "zh": "ç”Ÿå‘½å‘¨æœŸé˜¶æ®µï¼šå®¢æˆ·æˆ–ç”¨æˆ·åœ¨å…¶ç”Ÿå‘½å‘¨æœŸä¸­çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œå®¢æˆ·æ˜¯æ–°å®¢æˆ·ã€å¿ è¯šå®¢æˆ·è¿˜æ˜¯å³å°†ç¦»èŒçš„å®¢æˆ·ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Another important property of inductive learning is that learning cannot occur unless the learning process is biased in some way. This means that we need to tell the learning process what types of patterns to look for in the data. This bias is referred to as inductive bias. The inductive bias of a learning algorithm comprises the set of assumptions that define the search space the algorithm explores, and the search process it uses.",
            "zh": "å½’çº³å­¦ä¹ çš„å¦ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯ï¼Œé™¤éå­¦ä¹ è¿‡ç¨‹åœ¨æŸç§ç¨‹åº¦ä¸Šæœ‰åè§ï¼Œå¦åˆ™å­¦ä¹ ä¸ä¼šå‘ç”Ÿã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦å‘Šè¯‰å­¦ä¹ è¿‡ç¨‹åœ¨æ•°æ®ä¸­å¯»æ‰¾å“ªäº›ç±»å‹çš„æ¨¡å¼ã€‚è¿™ç§åå·®è¢«ç§°ä¸ºå½’çº³åå·®ã€‚å­¦ä¹ ç®—æ³•çš„å½’çº³åå·®åŒ…æ‹¬ä¸€ç»„å‡è®¾ï¼Œè¿™äº›å‡è®¾å®šä¹‰äº†ç®—æ³•æ¢ç´¢çš„æœç´¢ç©ºé—´åŠå…¶ä½¿ç”¨çš„æœç´¢è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.9",
            "zh": "è¡¨ 8.9"
        }
    },
    {
        "translation": {
            "en": "For example, some are percentages, others are measured in years, and others are measured in counts per 1,000.",
            "zh": "ä¾‹å¦‚ï¼Œæœ‰äº›æ˜¯ç™¾åˆ†æ¯”ï¼Œæœ‰äº›æ˜¯ä»¥å¹´ä¸ºå•ä½ï¼Œæœ‰äº›æ˜¯ä»¥æ¯ 1,000 äººçš„è®¡æ•°æ¥è¡¡é‡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We started this section with the idea that if we could construct a sequence of tests that splits the training data into pure sets with respect to the target feature values, then we could do prediction by applying the same sequence of tests to the prediction queries and labeling them with the target feature of the set in which they end up.",
            "zh": "æˆ‘ä»¬ä»æœ¬èŠ‚å¼€å§‹çš„æƒ³æ³•æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¯ä»¥æ„é€ ä¸€ä¸ªæµ‹è¯•åºåˆ—ï¼Œå°†è®­ç»ƒæ•°æ®æ‹†åˆ†ä¸ºç›¸å¯¹äºç›®æ ‡ç‰¹å¾å€¼çš„çº¯é›†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†ç›¸åŒçš„æµ‹è¯•åºåˆ—åº”ç”¨äºé¢„æµ‹æŸ¥è¯¢å¹¶ç”¨å®ƒä»¬æœ€ç»ˆæ‰€åœ¨çš„é›†åˆçš„ç›®æ ‡ç‰¹å¾æ ‡è®°å®ƒä»¬æ¥è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "20. Critical value pruning (Mingers, 1987) is a well-known version of this pruning technique.",
            "zh": "20. ä¸´ç•Œå€¼ä¿®å‰ªï¼ˆMingersï¼Œ1987ï¼‰æ˜¯è¿™ç§ä¿®å‰ªæŠ€æœ¯çš„ä¸€ä¸ªè‘—åç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that in order to keep the number of decimal points required to represent the calculations through this forward pass manageable for presentation purposes, the outputs of the logistic functions for each layer have been rounded to four decimal places, and these rounded activations were the activations used in the subsequent calculations.",
            "zh": "è¯·æ³¨æ„ï¼Œä¸ºäº†ä¿æŒé€šè¿‡æ­¤å‰å‘ä¼ é€’è¡¨ç¤ºè®¡ç®—æ‰€éœ€çš„å°æ•°ç‚¹æ•°æ˜“äºç®¡ç†ï¼Œä»¥ä¾¿äºæ¼”ç¤ºç›®çš„ï¼Œæ¯å±‚çš„é€»è¾‘å‡½æ•°è¾“å‡ºå·²å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼Œè¿™äº›å››èˆäº”å…¥çš„æ¿€æ´»æ˜¯åç»­è®¡ç®—ä¸­ä½¿ç”¨çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Are there data quality issues? How will we handle missing values? How will we normalize our features? What features will we include?",
            "zh": "æ˜¯å¦å­˜åœ¨æ•°æ®è´¨é‡é—®é¢˜ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•è§„èŒƒåŒ–æˆ‘ä»¬çš„åŠŸèƒ½ï¼Ÿæˆ‘ä»¬å°†åŒ…æ‹¬å“ªäº›åŠŸèƒ½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 4.20[160] illustrates the process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "å›¾4.20[160]è¯´æ˜äº†ä½¿ç”¨è£…è¢‹å’Œå­ç©ºé—´é‡‡æ ·åˆ›å»ºæ¨¡å‹é›†æˆçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the next section we introduce the naive Bayes model, a probability-based machine learning algorithm that asserts a global conditional independence between the descriptive features given the target. As a result of this conditional independence assumption, naive Bayes models are very compact and relatively robust to overfitting the data, making them one of the most popular predictive modeling approaches.",
            "zh": "åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå®ƒæ–­è¨€ç»™å®šç›®æ ‡çš„æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å…¨å±€æ¡ä»¶ç‹¬ç«‹æ€§ã€‚ç”±äºè¿™ç§æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹éå¸¸ç´§å‡‘ï¼Œå¹¶ä¸”å¯¹æ•°æ®è¿‡æ‹Ÿåˆç›¸å¯¹é²æ£’ï¼Œä½¿å…¶æˆä¸ºæœ€æµè¡Œçš„é¢„æµ‹å»ºæ¨¡æ–¹æ³•ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. weight sharing; and",
            "zh": "2.é‡é‡åˆ†æ‹…;å’Œ"
        }
    },
    {
        "translation": {
            "en": "(a) State whether each descriptive feature contains numeric, interval, ordinal, categorical, binary, or textual data.",
            "zh": "ï¼ˆaï¼‰ è¯´æ˜æ¯ä¸ªæè¿°æ€§ç‰¹å¾æ˜¯å¦åŒ…å«æ•°å­—ã€åŒºé—´ã€åºæ•°ã€åˆ†ç±»ã€äºŒè¿›åˆ¶æˆ–æ–‡æœ¬æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21(b)[163] shows an illustration of the final ensemble model trained using five iterations of the boosting algorithm. Even this simple example can nicely illustrate the power of boosting as, although all the individual decision trees in the ensemble are limited to a single split at the root node of the tree, the ensemble is able to learn a more sophisticated prediction model that none of the individual models within it are capable of representing.",
            "zh": "å›¾ 4.21ï¼ˆbï¼‰[163] æ˜¾ç¤ºäº†ä½¿ç”¨æå‡ç®—æ³•çš„äº”æ¬¡è¿­ä»£è®­ç»ƒçš„æœ€ç»ˆé›†æˆæ¨¡å‹çš„å›¾ç¤ºã€‚å³ä½¿æ˜¯è¿™ä¸ªç®€å•çš„ä¾‹å­ä¹Ÿå¯ä»¥å¾ˆå¥½åœ°è¯´æ˜æå‡çš„åŠ›é‡ï¼Œå› ä¸ºå°½ç®¡é›†æˆä¸­çš„æ‰€æœ‰å•ä¸ªå†³ç­–æ ‘éƒ½ä»…é™äºæ ‘æ ¹èŠ‚ç‚¹å¤„çš„å•ä¸ªåˆ†è£‚ï¼Œä½†é›†æˆèƒ½å¤Ÿå­¦ä¹ ä¸€ä¸ªæ›´å¤æ‚çš„é¢„æµ‹æ¨¡å‹ï¼Œå…¶ä¸­çš„å•ä¸ªæ¨¡å‹éƒ½æ— æ³•è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the Î´ values for each of the neurons in the network (i.e., Î´3, Î´2).",
            "zh": "è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´å€¼ï¼ˆå³Î´3ï¼ŒÎ´2ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The argument stems from a disagreement about when a discrete moment of time endsâ€”after the action completes or after the reward is received?",
            "zh": "äº‰è®ºæºäºå¯¹ç¦»æ•£æ—¶åˆ»ä½•æ—¶ç»“æŸçš„åˆ†æ­§â€”â€”åœ¨è¡ŒåŠ¨å®Œæˆä¹‹åè¿˜æ˜¯åœ¨æ”¶åˆ°å¥–åŠ±ä¹‹åï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Table 9.18",
            "zh": "è¡¨ 9.18"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2[387] makes it apparent that a common characteristic of all of these activation functions is that they are not linear functions.",
            "zh": "å›¾8.2[387]æ¸…æ¥šåœ°è¡¨æ˜ï¼Œæ‰€æœ‰è¿™äº›æ¿€æ´»å‡½æ•°çš„ä¸€ä¸ªå…±åŒç‰¹å¾æ˜¯å®ƒä»¬ä¸æ˜¯çº¿æ€§å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "dropout, 434, 472, 473, 507",
            "zh": "è¾å­¦ï¼Œ 434ï¼Œ 472ï¼Œ 473ï¼Œ 507"
        }
    },
    {
        "translation": {
            "en": "representational capacity, 396",
            "zh": "ä»£è¡¨èƒ½åŠ›ï¼Œ396"
        }
    },
    {
        "translation": {
            "en": "A more complex credit scoring dataset.",
            "zh": "æ›´å¤æ‚çš„ä¿¡ç”¨è¯„åˆ†æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.4549",
            "zh": "-0.4549"
        }
    },
    {
        "translation": {
            "en": "For each iteration of the boosting process the columns labeled Dist.",
            "zh": "å¯¹äºæå‡è¿‡ç¨‹çš„æ¯æ¬¡è¿­ä»£ï¼Œæ ‡è®°ä¸º Dist."
        }
    },
    {
        "translation": {
            "en": "PRICE",
            "zh": "ä»·æ ¼"
        }
    },
    {
        "translation": {
            "en": "Square brackets [] are used to index into a vector of features (e.g., d[j] denotes the value of the jth feature in the vector d).",
            "zh": "æ–¹æ‹¬å· [] ç”¨äºç´¢å¼•ç‰¹å¾å‘é‡ï¼ˆä¾‹å¦‚ï¼Œd[j] è¡¨ç¤ºå‘é‡ d ä¸­ç¬¬ j ä¸ªç‰¹å¾çš„å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "At a glance, the confusion matrix can show us that a model is performing well if the numbers on its diagonal, representing the true positives and true negatives, are high. Looking at the other cells within the confusion matrix can show us what kind of mistakes the model is making. Table 9.3[539] shows the confusion matrix for the set of predictions shown in Table 9.1[537] (in this case, we refer to the spam target level as the positive level and ham as the negative level).3",
            "zh": "ä¸€ç›®äº†ç„¶ï¼Œæ··æ·†çŸ©é˜µå¯ä»¥å‘æˆ‘ä»¬æ˜¾ç¤ºï¼Œå¦‚æœæ¨¡å‹å¯¹è§’çº¿ä¸Šçš„æ•°å­—ï¼ˆä»£è¡¨çœŸæ­£æ•°å’ŒçœŸè´Ÿæ•°ï¼‰å¾ˆé«˜ï¼Œåˆ™æ¨¡å‹è¡¨ç°è‰¯å¥½ã€‚æŸ¥çœ‹æ··æ·†çŸ©é˜µä¸­çš„å…¶ä»–å•å…ƒæ ¼å¯ä»¥å‘æˆ‘ä»¬å±•ç¤ºæ¨¡å‹çŠ¯äº†ä»€ä¹ˆæ ·çš„é”™è¯¯ã€‚è¡¨ 9.3[539] æ˜¾ç¤ºäº†è¡¨ 9.1[537] ä¸­æ‰€ç¤ºçš„ä¸€ç»„é¢„æµ‹çš„æ··æ·†çŸ©é˜µï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åƒåœ¾é‚®ä»¶ç›®æ ‡çº§åˆ«ç§°ä¸ºæ­£çº§åˆ«ï¼Œå°† ham ç§°ä¸ºè´Ÿçº§åˆ«ï¼‰3ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Whx containing the weights for the connections between the input layer (x) and the hidden layer (h);",
            "zh": "1. Whx åŒ…å«è¾“å…¥å±‚ ï¼ˆxï¼‰ å’Œéšè—å±‚ ï¼ˆhï¼‰ ä¹‹é—´è¿æ¥çš„æƒé‡;"
        }
    },
    {
        "translation": {
            "en": "11.3â€…â€…â€…A portion of the action-value table for the grid world example at its first initialization.",
            "zh": "11.3 ç½‘æ ¼ä¸–ç•Œç¤ºä¾‹é¦–æ¬¡åˆå§‹åŒ–æ—¶æ“ä½œå€¼è¡¨çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "More specifically, a Bayesian network can be viewed as defining a Markov chain.",
            "zh": "æ›´å…·ä½“åœ°è¯´ï¼Œè´å¶æ–¯ç½‘ç»œå¯ä»¥è¢«è§†ä¸ºå®šä¹‰é©¬å°”å¯å¤«é“¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.8[348] shows just the first two iterations of the gradient descent process for this model.",
            "zh": "è¡¨7.8[348]ä»…æ˜¾ç¤ºäº†è¯¥æ¨¡å‹æ¢¯åº¦ä¸‹é™è¿‡ç¨‹çš„å‰ä¸¤æ¬¡è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.5â€…â€…â€…Summary",
            "zh": "9.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "A.2â€…â€…â€…A frequency table for the POSITION feature from the school basketball team dataset in Table A.1[750].",
            "zh": "A.2 è¡¨A.1[750]ä¸­å­¦æ ¡ç¯®çƒé˜Ÿæ•°æ®é›†ä¸­POSITIONç‰¹å¾çš„é¢‘ç‡è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "During the European Soccer Championships in 2008 and the 2010 Soccer World Cup, an octopus in Germany, called Paul, was attributed with achieving an 85% success rate at predicting the results of the matches involving Germany.",
            "zh": "åœ¨ 2008 å¹´çš„æ¬§æ´²è¶³çƒé”¦æ ‡èµ›å’Œ 2010 å¹´è¶³çƒä¸–ç•Œæ¯æœŸé—´ï¼Œå¾·å›½çš„ä¸€åªåå«ä¿ç½—çš„ç« é±¼è¢«è®¤ä¸ºåœ¨é¢„æµ‹æ¶‰åŠå¾·å›½çš„æ¯”èµ›ç»“æœæ–¹é¢å–å¾—äº† 85% çš„æˆåŠŸç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is not a coincidence.",
            "zh": "è¿™å¹¶éå·§åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of Î± = 0.1, calculate the updated values for each of the weights in the network (w6,4,w6,3,w6,0,w5,4, w5,3, w5,0, w4,2,w4,1,w4,0, w3,2, w3,1, w3,0,) after the processing of this single training example.",
            "zh": "å‡è®¾å­¦ä¹ ç‡ä¸º Î± = 0.1ï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªæƒé‡ï¼ˆw6,4ï¼Œw6,3ï¼Œw6,0ï¼Œw5,4ã€w5,3ã€w5,0ã€w4,2ã€w4,1ã€w4,0ã€w3,2ã€w3,1ã€w3,0ï¼Œï¼‰çš„æ›´æ–°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The middle column in this weight matrix represents the weights on the connections from Neuron 1 to each of the neurons in hidden layer 1: Neurons 3, 4 and 5, respectively.",
            "zh": "æ­¤æƒé‡çŸ©é˜µä¸­çš„ä¸­é—´åˆ—åˆ†åˆ«è¡¨ç¤ºä»ç¥ç»å…ƒ 1 åˆ°éšè—å±‚ 1 ä¸­æ¯ä¸ªç¥ç»å…ƒçš„è¿æ¥ä¸Šçš„æƒé‡ï¼šç¥ç»å…ƒ 3ã€4 å’Œ 5ã€‚"
        }
    },
    {
        "translation": {
            "en": "de-noising auto-encoders, 630",
            "zh": "é™å™ªè‡ªåŠ¨ç¼–ç å™¨ï¼Œ630"
        }
    },
    {
        "translation": {
            "en": "Implementing a derived feature, however, requires data from multiple sources to be combined into a set of single feature values.",
            "zh": "ä½†æ˜¯ï¼Œå®ç°æ´¾ç”Ÿç‰¹å¾éœ€è¦å°†æ¥è‡ªå¤šä¸ªæºçš„æ•°æ®ç»„åˆæˆä¸€ç»„å•ä¸ªç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the sampling density is too low, then large regions of the feature space do not contain any training instances, and it doesnâ€™t make sense to associate such a region with any cluster of training instances or to look for training instances that are nearby.",
            "zh": "å¦‚æœé‡‡æ ·å¯†åº¦å¤ªä½ï¼Œåˆ™ç‰¹å¾ç©ºé—´çš„å¤§åŒºåŸŸä¸åŒ…å«ä»»ä½•è®­ç»ƒå®ä¾‹ï¼Œå¹¶ä¸”å°†æ­¤ç±»åŒºåŸŸä¸ä»»ä½•è®­ç»ƒå®ä¾‹èšç±»ç›¸å…³è”æˆ–æŸ¥æ‰¾é™„è¿‘çš„è®­ç»ƒå®ä¾‹æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another potential issue with decision trees is that they are eager learners. As such, they are not suitable for modeling concepts that change over time, because they will need to be retrained. In these scenarios, the similarity-based prediction models that are the topic of Chapter 5[181] perform better, as these models can be incrementally retrained.",
            "zh": "å†³ç­–æ ‘çš„å¦ä¸€ä¸ªæ½œåœ¨é—®é¢˜æ˜¯å®ƒä»¬æ˜¯æ¸´æœ›å­¦ä¹ çš„äººã€‚å› æ­¤ï¼Œå®ƒä»¬ä¸é€‚åˆå¯¹éšæ—¶é—´å˜åŒ–çš„æ¦‚å¿µè¿›è¡Œå»ºæ¨¡ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦é‡æ–°è®­ç»ƒã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œç¬¬ 5 ç« [181] ä¸»é¢˜çš„åŸºäºç›¸ä¼¼æ€§çš„é¢„æµ‹æ¨¡å‹è¡¨ç°æ›´å¥½ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹å¯ä»¥å¢é‡é‡æ–°è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Using dropout during the training of a recurrent neural network can be problematic because dropping different neurons from the network at different time-steps across a sequence can stop the network from propagating important information forward through the sequence.",
            "zh": "åœ¨å¾ªç¯ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨dropoutå¯èƒ½ä¼šæœ‰é—®é¢˜ï¼Œå› ä¸ºåœ¨åºåˆ—çš„ä¸åŒæ—¶é—´æ­¥é•¿ä»ç½‘ç»œä¸­åˆ é™¤ä¸åŒçš„ç¥ç»å…ƒå¯èƒ½ä¼šé˜»æ­¢ç½‘ç»œé€šè¿‡åºåˆ—å‘å‰ä¼ æ’­é‡è¦ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, when we are dealing with a financial feature, we might use intervals that represent cents, while if we were dealing with temperature, we might define the interval to be 1 degree.",
            "zh": "ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å¤„ç†è´¢åŠ¡ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨è¡¨ç¤ºç¾åˆ†çš„åŒºé—´ï¼Œè€Œå¦‚æœæˆ‘ä»¬å¤„ç†æ¸©åº¦ï¼Œæˆ‘ä»¬å¯ä»¥å°†åŒºé—´å®šä¹‰ä¸º 1 åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "BEYOND PREDICTION",
            "zh": "è¶…è¶Šé¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "We refer to this as getting to know the data.",
            "zh": "æˆ‘ä»¬å°†å…¶ç§°ä¸ºäº†è§£æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Not long afterward the three Murphy children came to their father together to ask how it was that he had told each of them that they had done a great job of arranging the letters when they had all done something different.",
            "zh": "ä¸ä¹…ä¹‹åï¼Œå¢¨è²çš„ä¸‰ä¸ªå­©å­ä¸€èµ·æ¥æ‰¾ä»–ä»¬çš„çˆ¶äº²ï¼Œé—®ä»–ä¸ºä»€ä¹ˆå‘Šè¯‰ä»–ä»¬æ¯ä¸ªäººï¼Œå½“ä»–ä»¬éƒ½åšäº†ä¸€äº›ä¸åŒçš„äº‹æƒ…æ—¶ï¼Œä»–ä»¬åœ¨æ•´ç†ä¿¡ä»¶æ–¹é¢åšå¾—å¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "ä¸€ä¸ªæ•£ç‚¹å›¾çŸ©é˜µï¼Œæ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was based on the assumption that such a call made to customers considering switching to a different network would encourage them to stay with their current network.",
            "zh": "è¿™æ˜¯åŸºäºè¿™æ ·çš„å‡è®¾ï¼Œå³å‘è€ƒè™‘åˆ‡æ¢åˆ°å…¶ä»–ç½‘ç»œçš„å®¢æˆ·æ‹¨æ‰“æ­¤ç±»ç”µè¯ä¼šé¼“åŠ±ä»–ä»¬ç»§ç»­ä½¿ç”¨å½“å‰ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the pruning set, apply reduced error pruning to the decision tree. Assume that the algorithm is applied in a bottom-up, left-to-right fashion. For each iteration of the algorithm, indicate the subtrees considered as pruning candidates, explain why the algorithm chooses to prune or leave these subtrees in the tree, and illustrate the tree that results from each iteration.",
            "zh": "ä½¿ç”¨ä¿®å‰ªé›†ï¼Œå°†å‡å°‘è¯¯å·®çš„ä¿®å‰ªåº”ç”¨äºå†³ç­–æ ‘ã€‚å‡è®¾è¯¥ç®—æ³•ä»¥è‡ªä¸‹è€Œä¸Šã€ä»å·¦åˆ°å³çš„æ–¹å¼åº”ç”¨ã€‚å¯¹äºç®—æ³•çš„æ¯æ¬¡è¿­ä»£ï¼Œè¯·æŒ‡å‡ºè¢«è§†ä¸ºä¿®å‰ªå€™é€‰é¡¹çš„å­æ ‘ï¼Œè§£é‡Šç®—æ³•é€‰æ‹©ä¿®å‰ªæˆ–å°†è¿™äº›å­æ ‘ä¿ç•™åœ¨æ ‘ä¸­çš„åŸå› ï¼Œå¹¶è¯´æ˜æ¯æ¬¡è¿­ä»£äº§ç”Ÿçš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the scatter plot, DOSE1 is shown on the horizontal axis, DOSE2 is shown on the vertical axis, and the shapes of the points represent the target levelâ€”crosses represent dangerous interactions and triangles represent safe interactions.",
            "zh": "åœ¨æ•£ç‚¹å›¾ä¸­ï¼ŒDOSE1 æ˜¾ç¤ºåœ¨æ¨ªè½´ä¸Šï¼ŒDOSE2 æ˜¾ç¤ºåœ¨çºµè½´ä¸Šï¼Œç‚¹çš„å½¢çŠ¶è¡¨ç¤ºç›®æ ‡æ°´å¹³ï¼Œåå­—è¡¨ç¤ºå±é™©ç›¸äº’ä½œç”¨ï¼Œä¸‰è§’å½¢è¡¨ç¤ºå®‰å…¨ç›¸äº’ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can analyze why this happens if we examine the Euclidean distance computations between the query and the instances in the dataset.",
            "zh": "å¦‚æœæˆ‘ä»¬æ£€æŸ¥æŸ¥è¯¢å’Œæ•°æ®é›†ä¸­å®ä¾‹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»è®¡ç®—ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†æä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Hospital management would like to explore the use of predictive analytics to address this issue.12 They would like to reduce the readmittance rate of diabetes patients, while at the same time not keeping patients in the hospital longer than they need to be.",
            "zh": "12 ä»–ä»¬å¸Œæœ›é™ä½ç³–å°¿ç—…æ‚£è€…çš„å†å…¥é™¢ç‡ï¼ŒåŒæ—¶ä¸è¦è®©æ‚£è€…ä½é™¢æ—¶é—´è¶…è¿‡ä»–ä»¬éœ€è¦çš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.6â€…â€…â€…(a) A graph illustrating how the value of a binary log (the log to the base 2) of a probability changes across the range of probability values; and (b) the impact of multiplying these values by â€“ 1.",
            "zh": "4.6 ï¼ˆaï¼‰ è¯´æ˜æ¦‚ç‡çš„äºŒè¿›åˆ¶å¯¹æ•°ï¼ˆä»¥ 2 ä¸ºåŸºæ•°çš„å¯¹æ•°ï¼‰çš„å€¼åœ¨æ¦‚ç‡å€¼èŒƒå›´å†…å¦‚ä½•å˜åŒ–çš„å›¾è¡¨;ä»¥åŠ ï¼ˆbï¼‰ å°†è¿™äº›å€¼ä¹˜ä»¥ â€“ 1 çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 2.1",
            "zh": "è¡¨ 2.1"
        }
    },
    {
        "translation": {
            "en": "As in the previous analysis, in this network the instability in gradient propagation (in this instance exploding gradients) is not due to a scaling of the gradients by the derivative of the activation function; the linear activation function used by the neurons in this network has a derivative of 1, and so the gradients are not changed by this derivative during backpropagation.",
            "zh": "ä¸å‰é¢çš„åˆ†æä¸€æ ·ï¼Œåœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œæ¢¯åº¦ä¼ æ’­çš„ä¸ç¨³å®šæ€§ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºçˆ†ç‚¸æ¢¯åº¦ï¼‰ä¸æ˜¯ç”±äºæ¿€æ´»å‡½æ•°å¯¼æ•°å¯¹æ¢¯åº¦çš„ç¼©æ”¾;è¯¥ç½‘ç»œä¸­ç¥ç»å…ƒä½¿ç”¨çš„çº¿æ€§æ¿€æ´»å‡½æ•°çš„å¯¼æ•°ä¸º 1ï¼Œå› æ­¤åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¢¯åº¦ä¸ä¼šå› è¯¥å¯¼æ•°è€Œæ”¹å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The plot on the right of Figure 8.8[398] shows the input space for the XOR and labels the input combinations as resulting in TRUE responses or FALSE responses.",
            "zh": "å›¾8.8[398]å³ä¾§çš„å›¾æ˜¾ç¤ºäº†XORçš„è¾“å…¥ç©ºé—´ï¼Œå¹¶å°†è¾“å…¥ç»„åˆæ ‡è®°ä¸ºäº§ç”ŸTRUEå“åº”æˆ–FALSEå“åº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because a probability distribution must sum to 1, an increase in one probability results in a decrease in one or more of the other probabilities in the distribution.",
            "zh": "ç”±äºæ¦‚ç‡åˆ†å¸ƒçš„æ€»å’Œå¿…é¡»ä¸º 1ï¼Œå› æ­¤ä¸€ä¸ªæ¦‚ç‡çš„å¢åŠ ä¼šå¯¼è‡´åˆ†å¸ƒä¸­ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–æ¦‚ç‡çš„å‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "When an audit reveals that a company is complying with all tax requirements, there is a sense that the time spent performing the audit was wasted, and more important, that another business who is not tax compliant has been spared an investigation.",
            "zh": "å½“å®¡è®¡æ˜¾ç¤ºä¸€å®¶å…¬å¸éµå®ˆæ‰€æœ‰ç¨åŠ¡è¦æ±‚æ—¶ï¼Œå°±ä¼šæœ‰ä¸€ç§æ„Ÿè§‰ï¼Œå³æ‰§è¡Œå®¡è®¡æ‰€èŠ±è´¹çš„æ—¶é—´è¢«æµªè´¹äº†ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå¦ä¸€å®¶ä¸éµå®ˆç¨åŠ¡è§„å®šçš„ä¼ä¸šå¹¸å…äºéš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6â€…â€…â€…Data Preparation",
            "zh": "3.6 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices from the evaluation of these models are shown in Table 13.5[720].",
            "zh": "è¿™äº›æ¨¡å‹è¯„ä¼°çš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.5[720]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Once identified, these features should be recoded as categorical features.",
            "zh": "ä¸€æ—¦è¯†åˆ«ï¼Œè¿™äº›ç‰¹å¾åº”é‡æ–°ç¼–ç ä¸ºåˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11",
            "zh": "å›¾ 6.11"
        }
    },
    {
        "translation": {
            "en": "The propagation of activations along the cell is controlled by three gates: the forget gate, the input gate, and the output gate.",
            "zh": "æ¿€æ´»æ²¿ç»†èƒçš„ä¼ æ’­ç”±ä¸‰ä¸ªé—¨æ§åˆ¶ï¼šé—å¿˜é—¨ã€è¾“å…¥é—¨å’Œè¾“å‡ºé—¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Îµ-greedy action selection policy is a simple action selection policy that balances exploration and exploitation.",
            "zh": "Îµè´ªå©ªè¡ŒåŠ¨é€‰æ‹©ç­–ç•¥æ˜¯ä¸€ç§å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨çš„ç®€å•è¡ŒåŠ¨é€‰æ‹©ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "For simplicity in later calculations, we can combine the two constraints in Equations (7.42)[363] and (7.43)[363] into a single constraint (remember that ti is always equal to either âˆ’ 1 or + 1)",
            "zh": "ä¸ºäº†åœ¨ä»¥åçš„è®¡ç®—ä¸­ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ–¹ç¨‹ï¼ˆ7.42ï¼‰[363]å’Œï¼ˆ7.43ï¼‰[363]ä¸­çš„ä¸¤ä¸ªçº¦æŸç»„åˆæˆä¸€ä¸ªçº¦æŸï¼ˆè¯·è®°ä½ï¼Œtiæ€»æ˜¯ç­‰äºâˆ’1æˆ–+ 1ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The moral here is that the curse of dimensionality is a problem for all inductive learning approaches, and given that acquiring new labeled instances is typically not an option, the best way to avoid it is to restrict the number of descriptive features in a dataset to the smallest set possible, while still providing the learning algorithm with enough information about the instances to be able to build a useful model.",
            "zh": "è¿™é‡Œçš„å¯“æ„æ˜¯ï¼Œç»´åº¦çš„è¯…å’’æ˜¯æ‰€æœ‰å½’çº³å­¦ä¹ æ–¹æ³•çš„é—®é¢˜ï¼Œé‰´äºè·å–æ–°çš„æ ‡è®°å®ä¾‹é€šå¸¸ä¸æ˜¯ä¸€ç§é€‰æ‹©ï¼Œé¿å…å®ƒçš„æœ€ä½³æ–¹æ³•æ˜¯å°†æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾çš„æ•°é‡é™åˆ¶ä¸ºå°½å¯èƒ½å°çš„é›†åˆï¼ŒåŒæ—¶ä»ç„¶ä¸ºå­¦ä¹ ç®—æ³•æä¾›æœ‰å…³å®ä¾‹çš„è¶³å¤Ÿä¿¡æ¯ï¼Œä»¥ä¾¿èƒ½å¤Ÿæ„å»ºæœ‰ç”¨çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the two-part structure of the McCulloch and Pitts model of the neuron is the blueprint for the neurons used in modern neural networks.",
            "zh": "ç„¶è€Œï¼Œç¥ç»å…ƒçš„ McCulloch å’Œ Pitts æ¨¡å‹çš„ä¸¤éƒ¨åˆ†ç»“æ„æ˜¯ç°ä»£ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨çš„ç¥ç»å…ƒçš„è“å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "TÃ¼fekci, Pinar. 2014. Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods. International Journal of Electrical Power & Energy Systems 60: 126â€“140.",
            "zh": "å›¾è´¹å…‹å¥‡ï¼Œçš®çº³å°”ã€‚2014. ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•é¢„æµ‹åŸºæœ¬è´Ÿè·è¿è¡Œçš„è”åˆå¾ªç¯ç”µå‚çš„æ»¡è½½ç”µåŠ›è¾“å‡º.å›½é™…ç”µåŠ›ä¸èƒ½æºç³»ç»Ÿæ‚å¿—60ï¼š126-140ã€‚"
        }
    },
    {
        "translation": {
            "en": "When he considered cardinality, Ross noticed that a number of the continuous features had very low cardinalityâ€”for example, INCOME, AGE, NUMHANDSETS, HANDSETPRICE, and NUMRETENTIONCALLS.",
            "zh": "åœ¨è€ƒè™‘åŸºæ•°æ—¶ï¼ŒRoss æ³¨æ„åˆ°è®¸å¤šè¿ç»­ç‰¹å¾çš„åŸºæ•°éå¸¸ä½ï¼Œä¾‹å¦‚ï¼ŒINCOMEã€AGEã€NUMHANDETSã€HANDSETPRICE å’Œ NUMRETENTIONCALLSã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.13",
            "zh": "è¡¨ 8.13"
        }
    },
    {
        "translation": {
            "en": "The decision trees described in Chapter 4[117] are an example of this type of abstraction.",
            "zh": "ç¬¬4ç« [117]ä¸­æè¿°çš„å†³ç­–æ ‘å°±æ˜¯è¿™ç§æŠ½è±¡çš„ä¸€ä¸ªä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´s for the downstream neurons are the links in this chain, and therefore we must calculate these downstream Î´s prior to calculating âˆ‚â„°/âˆ‚ak.",
            "zh": "ä¸‹æ¸¸ç¥ç»å…ƒçš„ Î´ æ˜¯è¿™æ¡é“¾ä¸­çš„ç¯èŠ‚ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»åœ¨è®¡ç®— âˆ‚E/âˆ‚ak ä¹‹å‰è®¡ç®—è¿™äº›ä¸‹æ¸¸ Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that unlike the layers, the weight matrices do not have a time subscript on them.",
            "zh": "è¯·æ³¨æ„ï¼Œä¸å›¾å±‚ä¸åŒï¼Œæƒé‡çŸ©é˜µä¸Šæ²¡æœ‰æ—¶é—´ä¸‹æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Modern organizations collect massive amounts of data. To be of value to an organization, this data must be analyzed to extract insights that can be used to make better decisions. The progression from data to insights to decisions is illustrated in Figure 1.1[4]. Extracting insights from data is the job of data analytics. This book focuses on predictive data analytics, which is an important subfield of data analytics.",
            "zh": "ç°ä»£ç»„ç»‡æ”¶é›†å¤§é‡æ•°æ®ã€‚ä¸ºäº†å¯¹ç»„ç»‡æœ‰ä»·å€¼ï¼Œå¿…é¡»åˆ†æè¿™äº›æ•°æ®ä»¥æå–å¯ç”¨äºåšå‡ºæ›´å¥½å†³ç­–çš„è§è§£ã€‚å›¾1.1[4]è¯´æ˜äº†ä»æ•°æ®åˆ°æ´å¯Ÿå†åˆ°å†³ç­–çš„è¿‡ç¨‹ã€‚ä»æ•°æ®ä¸­æå–è§è§£æ˜¯æ•°æ®åˆ†æçš„å·¥ä½œã€‚æœ¬ä¹¦é‡ç‚¹ä»‹ç»é¢„æµ‹æ•°æ®åˆ†æï¼Œè¿™æ˜¯æ•°æ®åˆ†æçš„ä¸€ä¸ªé‡è¦å­é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "cluster centroids, 600",
            "zh": "ç°‡è´¨å¿ƒï¼Œ600"
        }
    },
    {
        "translation": {
            "en": "data protection legislation, 40",
            "zh": "æ•°æ®ä¿æŠ¤ç«‹æ³•ï¼Œ40"
        }
    },
    {
        "translation": {
            "en": "9.4.4â€ƒPerformance Measures: Multinomial Targets",
            "zh": "9.4.4 ç»©æ•ˆè¡¡é‡ï¼šå¤šé¡¹å¼ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "The forget gate works by passing hxt through a layer of neurons that use sigmoid activation functions.",
            "zh": "é—å¿˜é—¨çš„å·¥ä½œåŸç†æ˜¯å°† hxt ä¼ é€’åˆ°ä½¿ç”¨ S å½¢æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first evaluation experiment, the data in the 1st fold is used as the test set, and the data in the remaining k âˆ’ 1 folds is used as the training set.",
            "zh": "åœ¨ç¬¬ä¸€ä¸ªè¯„ä¼°å®éªŒä¸­ï¼Œç¬¬ 1 ä¸ªæŠ˜å ä¸­çš„æ•°æ®ç”¨ä½œæµ‹è¯•é›†ï¼Œå…¶ä½™ k âˆ’ 1 ä¸ªæŠ˜å ä¸­çš„æ•°æ®ç”¨ä½œè®­ç»ƒé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "GALAXY_CLASS_5",
            "zh": "GALAXY_CLASS_5"
        }
    },
    {
        "translation": {
            "en": "So, in some cases prediction has a temporal aspect but not in all.",
            "zh": "å› æ­¤ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé¢„æµ‹å…·æœ‰æ—¶é—´æ–¹é¢ï¼Œä½†ä¸æ˜¯å…¨éƒ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was this focus on encoding that motivated his approach to measuring information.",
            "zh": "æ­£æ˜¯è¿™ç§å¯¹ç¼–ç çš„å…³æ³¨æ¿€å‘äº†ä»–æµ‹é‡ä¿¡æ¯çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This includes all financial details of the companyâ€™s operations during the year and is the basis of calculating the tax liability of a company.",
            "zh": "è¿™åŒ…æ‹¬å…¬å¸å½“å¹´è¿è¥çš„æ‰€æœ‰è´¢åŠ¡ç»†èŠ‚ï¼Œæ˜¯è®¡ç®—å…¬å¸çº³ç¨ä¹‰åŠ¡çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this phenomenon is that, fundamentally, the predictive power of an induced model is based on one of the following:",
            "zh": "é€ æˆè¿™ç§ç°è±¡çš„åŸå› æ˜¯ï¼Œä»æ ¹æœ¬ä¸Šè¯´ï¼Œè¯±å¯¼æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›åŸºäºä»¥ä¸‹å› ç´ ä¹‹ä¸€ï¼š"
        }
    },
    {
        "translation": {
            "en": "PETROR50ERR_U/G/R/I/Z",
            "zh": "PETROR50ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "61,000",
            "zh": "61,000"
        }
    },
    {
        "translation": {
            "en": "Once this ratio drops, the efficiency of the k-d tree diminishes.",
            "zh": "ä¸€æ—¦è¿™ä¸ªæ¯”ç‡ä¸‹é™ï¼Œk-dæ ‘çš„æ•ˆç‡å°±ä¼šé™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Error functions are commonly referred to as loss functions because they represent what we lose by reducing the training set to a simple model.",
            "zh": "2. è¯¯å·®å‡½æ•°é€šå¸¸è¢«ç§°ä¸ºæŸå¤±å‡½æ•°ï¼Œå› ä¸ºå®ƒä»¬ä»£è¡¨äº†æˆ‘ä»¬é€šè¿‡å°†è®­ç»ƒé›†ç®€åŒ–ä¸ºç®€å•æ¨¡å‹è€Œå¤±å»çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data",
            "zh": "æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "Some of the other machine learning topics that you might like to explore include semi-supervised learning (Chapelle et al., 2009), multi-label classification (Tsoumakas et al., 2012), and graphical models (Kollar and Friedman, 2009).",
            "zh": "æ‚¨å¯èƒ½æƒ³è¦æ¢ç´¢çš„å…¶ä»–ä¸€äº›æœºå™¨å­¦ä¹ ä¸»é¢˜åŒ…æ‹¬åŠç›‘ç£å­¦ä¹ ï¼ˆChapelle et al.ï¼Œ 2009ï¼‰ã€å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆTsoumakas et al.ï¼Œ 2012ï¼‰å’Œå›¾å½¢æ¨¡å‹ï¼ˆKollar and Friedmanï¼Œ2009ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "mean, 54, 69, 745, 746",
            "zh": "å¹³å‡å€¼ï¼Œ 54ï¼Œ 69ï¼Œ 745ï¼Œ 746"
        }
    },
    {
        "translation": {
            "en": "For example, we might use a greedy action selection policy that says the agent should always take the action that will give it this highest immediate reward.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è´ªå©ªçš„è¡ŒåŠ¨é€‰æ‹©ç­–ç•¥ï¼Œè¯¥ç­–ç•¥è§„å®šä»£ç†åº”å§‹ç»ˆé‡‡å–èƒ½å¤Ÿä¸ºå…¶æä¾›æœ€é«˜å³æ—¶å¥–åŠ±çš„è¡ŒåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.2â€…â€…â€…Fundamentals",
            "zh": "9.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "This involved working very closely with Grace to understand what data was available, the formats that the data was kept in, and where the data resided.",
            "zh": "è¿™æ¶‰åŠä¸ Grace å¯†åˆ‡åˆä½œï¼Œä»¥äº†è§£å“ªäº›æ•°æ®å¯ç”¨ã€æ•°æ®çš„ä¿å­˜æ ¼å¼ä»¥åŠæ•°æ®é©»ç•™çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a softmax output layer there is a single neuron for each level of the target feature. For example, if the prediction task is to predict the level of a categorical feature that can take three levels (e.g., low, medium, high), then the output layer of the network would have three neurons. The activation function used by the neurons in a softmax layer is the softmax function; for an output layer with m neurons, the softmax activation function is defined as follows:",
            "zh": "åœ¨ softmax è¾“å‡ºå±‚ä¸­ï¼Œç›®æ ‡è¦ç´ çš„æ¯ä¸ªçº§åˆ«éƒ½æœ‰ä¸€ä¸ªç¥ç»å…ƒã€‚ä¾‹å¦‚ï¼Œå¦‚æœé¢„æµ‹ä»»åŠ¡æ˜¯é¢„æµ‹å¯ä»¥é‡‡å–ä¸‰ä¸ªçº§åˆ«ï¼ˆä¾‹å¦‚ï¼Œä½ã€ä¸­ã€é«˜ï¼‰çš„åˆ†ç±»ç‰¹å¾çš„çº§åˆ«ï¼Œé‚£ä¹ˆç½‘ç»œçš„è¾“å‡ºå±‚å°†æœ‰ä¸‰ä¸ªç¥ç»å…ƒã€‚softmaxå±‚ä¸­ç¥ç»å…ƒä½¿ç”¨çš„æ¿€æ´»å‡½æ•°æ˜¯softmaxå‡½æ•°;å¯¹äºå…·æœ‰ m ä¸ªç¥ç»å…ƒçš„è¾“å‡ºå±‚ï¼Œsoftmax æ¿€æ´»å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Overall, although naive Bayes models may not be as powerful as some other prediction models, they often provide reasonable accuracy results, for prediction tasks with categorical targets, while being robust to the curse of dimensionality and also being easy to train. As a result, a naive Bayes model is often a good prediction model to use to define a baseline accuracy score or when working with limited data.",
            "zh": "æ€»ä½“è€Œè¨€ï¼Œå°½ç®¡æœ´ç´ è´å¶æ–¯æ¨¡å‹å¯èƒ½ä¸å¦‚å…¶ä»–ä¸€äº›é¢„æµ‹æ¨¡å‹å¼ºå¤§ï¼Œä½†å®ƒä»¬é€šå¸¸ä¸ºå…·æœ‰åˆ†ç±»ç›®æ ‡çš„é¢„æµ‹ä»»åŠ¡æä¾›åˆç†çš„å‡†ç¡®æ€§ç»“æœï¼ŒåŒæ—¶å¯¹ç»´æ•°çš„è¯…å’’å…·æœ‰é²æ£’æ€§ï¼Œå¹¶ä¸”æ˜“äºè®­ç»ƒã€‚å› æ­¤ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹é€šå¸¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é¢„æµ‹æ¨¡å‹ï¼Œå¯ç”¨äºå®šä¹‰åŸºçº¿å‡†ç¡®æ€§åˆ†æ•°æˆ–å¤„ç†æœ‰é™æ•°æ®æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.11[85] the cells above the diagonal show the correlation coefficients for each pair of features.",
            "zh": "åœ¨å›¾3.11[85]ä¸­ï¼Œå¯¹è§’çº¿ä¸Šæ–¹çš„å•å…ƒæ ¼æ˜¾ç¤ºäº†æ¯å¯¹ç‰¹å¾çš„ç›¸å…³ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "40. NIST is the acronym for the institute that collected the data, the National Institute for Standards and Technology, and M indicates that the original data has been modified to make it easier to use for machine learning. The MNIST dataset is available at http://yann.lecun.com/exdb/mnist/.",
            "zh": "40. NISTæ˜¯æ”¶é›†æ•°æ®çš„æœºæ„ç¾å›½å›½å®¶æ ‡å‡†ä¸æŠ€æœ¯ç ”ç©¶æ‰€çš„é¦–å­—æ¯ç¼©å†™ï¼ŒMè¡¨ç¤ºåŸå§‹æ•°æ®å·²è¢«ä¿®æ”¹ï¼Œä½¿å…¶æ›´æ˜“äºç”¨äºæœºå™¨å­¦ä¹ ã€‚MNISTæ•°æ®é›†å¯åœ¨ http://yann.lecun.com/exdb/mnist/ ä¸Šè·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the sample of the population surveyed was skewed toward Republican voters, and so the predictions based on these surveys were also skewed.",
            "zh": "å› æ­¤ï¼Œæ¥å—è°ƒæŸ¥çš„äººå£æ ·æœ¬åå‘äºå…±å’Œå…šé€‰æ°‘ï¼Œå› æ­¤åŸºäºè¿™äº›è°ƒæŸ¥çš„é¢„æµ‹ä¹Ÿå­˜åœ¨åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This McCulloch and Pitts model had a two-part structure.",
            "zh": "è¿™ä¸ª McCulloch å’Œ Pitts æ¨¡å‹å…·æœ‰ä¸¤éƒ¨åˆ†ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. Box plots are one of the collection of visual data exploration techniques first presented in Tukeyâ€™s influential 1977 book Exploratory Data Analysis (Tukey, 1977).",
            "zh": "8. ç®±å½¢å›¾æ˜¯ Tukey 1977 å¹´å‡ºç‰ˆçš„æœ‰å½±å“åŠ›çš„è‘—ä½œã€Šæ¢ç´¢æ€§æ•°æ®åˆ†æã€‹ï¼ˆTukeyï¼Œ1977 å¹´ï¼‰ä¸­é¦–æ¬¡æå‡ºçš„è§†è§‰æ•°æ®æ¢ç´¢æŠ€æœ¯é›†åˆä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conversely, however, as the amount of training data increases.",
            "zh": "ç„¶è€Œï¼Œç›¸åï¼Œéšç€è®­ç»ƒæ•°æ®é‡çš„å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. We can do this either by consulting a probability table or by using integration to calculate the area under the curve within the bounds of the interval. There are many excellent statistical textbooks that explain how to do both of these, for example, Montgomery and Runger (2010).",
            "zh": "21. æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥é˜…æ¦‚ç‡è¡¨æˆ–ä½¿ç”¨ç§¯åˆ†æ¥è®¡ç®—åŒºé—´èŒƒå›´å†…çš„æ›²çº¿ä¸‹é¢ç§¯æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æœ‰è®¸å¤šä¼˜ç§€çš„ç»Ÿè®¡æ•™ç§‘ä¹¦è§£é‡Šäº†å¦‚ä½•åšåˆ°è¿™ä¸¤ç‚¹ï¼Œä¾‹å¦‚Montgomeryå’ŒRungerï¼ˆ2010ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first convolutional layer uses a max pooling layer to sub-sample each of the feature maps.",
            "zh": "ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä½¿ç”¨æœ€å¤§æ± åŒ–å±‚å¯¹æ¯ä¸ªç‰¹å¾å›¾è¿›è¡Œå­é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is clear that the variance of the distribution of z values dramatically reduces as we move forward through the network, and this reduction in the variance together with the fact that the median of the z values is 0 across all the layers indicates that the z values are consistently getting smaller.",
            "zh": "å¾ˆæ˜æ˜¾ï¼Œå½“æˆ‘ä»¬åœ¨ç½‘ç»œä¸­å‰è¿›æ—¶ï¼Œz å€¼åˆ†å¸ƒçš„æ–¹å·®ä¼šæ€¥å‰§å‡å°ï¼Œå¹¶ä¸”æ–¹å·®çš„è¿™ç§å‡å°ä»¥åŠæ‰€æœ‰å±‚ä¸­ z å€¼çš„ä¸­ä½æ•°ä¸º 0 è¿™ä¸€äº‹å®è¡¨æ˜ z å€¼ä¸€ç›´åœ¨å˜å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This course gives students an introduction to predictive data analytics, a solid understanding of how machine learning solutions should be designed to meet a business need, insight into how prediction models work and should be evaluated, and one of the case studies.",
            "zh": "æœ¬è¯¾ç¨‹å‘å­¦ç”Ÿä»‹ç»äº†é¢„æµ‹æ•°æ®åˆ†æï¼Œæ·±å…¥äº†è§£äº†æœºå™¨å­¦ä¹ è§£å†³æ–¹æ¡ˆåº”å¦‚ä½•è®¾è®¡ä»¥æ»¡è¶³ä¸šåŠ¡éœ€æ±‚ï¼Œæ·±å…¥äº†è§£é¢„æµ‹æ¨¡å‹çš„å·¥ä½œåŸç†å’Œè¯„ä¼°æ–¹å¼ï¼Œä»¥åŠå…¶ä¸­ä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wanted to use the Bayesian network in Figure 6.13[296] to predict the CPI for a country with the following profile:",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æƒ³ä½¿ç”¨å›¾ 6.13[296] ä¸­çš„è´å¶æ–¯ç½‘ç»œæ¥é¢„æµ‹å…·æœ‰ä»¥ä¸‹é…ç½®æ–‡ä»¶çš„å›½å®¶çš„ CPIï¼š"
        }
    },
    {
        "translation": {
            "en": "Using this dataset, calculate the following probabilities:",
            "zh": "ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œè®¡ç®—ä»¥ä¸‹æ¦‚ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 9.16",
            "zh": "å›¾ 9.16"
        }
    },
    {
        "translation": {
            "en": "The data from the Galaxy Zoo project was publicly available and therefore easily accessible to Jocelyn.",
            "zh": "é“¶æ²³åŠ¨ç‰©å›­é¡¹ç›®çš„æ•°æ®æ˜¯å…¬å¼€çš„ï¼Œå› æ­¤Jocelynå¾ˆå®¹æ˜“è®¿é—®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Backpropagation works by using the chain rule to assign blame to each of the modelâ€™s parameters (weights) in proportion to the sensitivity of the networkâ€™s error to changes in those weights.",
            "zh": "åå‘ä¼ æ’­çš„å·¥ä½œåŸç†æ˜¯ä½¿ç”¨é“¾å¼æ³•åˆ™å°†è´£ä»»åˆ†é…ç»™æ¨¡å‹çš„æ¯ä¸ªå‚æ•°ï¼ˆæƒé‡ï¼‰ï¼Œè¯¥å‚æ•°ï¼ˆæƒé‡ï¼‰ä¸ç½‘ç»œè¯¯å·®å¯¹è¿™äº›æƒé‡å˜åŒ–çš„æ•æ„Ÿæ€§æˆæ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 3.14(d)[92] to 3.14(f)[92] show the same normally distributed continuous feature mentioned previously binned into different numbers of bins using equal-frequency binning.13",
            "zh": "å›¾3.14ï¼ˆdï¼‰[92]è‡³3.14ï¼ˆfï¼‰[92]æ˜¾ç¤ºäº†å‰é¢æåˆ°çš„ç›¸åŒçš„æ­£æ€åˆ†å¸ƒè¿ç»­ç‰¹å¾ï¼Œä½¿ç”¨ç­‰é¢‘åˆ†æ¡£åˆ°ä¸åŒæ•°é‡çš„åˆ†æ¡£ä¸­13ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21",
            "zh": "å›¾ 4.21"
        }
    },
    {
        "translation": {
            "en": "If the distributions of prediction scores from predictive models perfectly followed a normal distribution, similar to those in Figure 9.9[557], calculating the degree of separation between distributions would be very simple and only involve a simple comparison of means and standard deviations.",
            "zh": "å¦‚æœé¢„æµ‹æ¨¡å‹çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒå®Œå…¨éµå¾ªæ­£æ€åˆ†å¸ƒï¼Œç±»ä¼¼äºå›¾9.9[557]ä¸­çš„åˆ†å¸ƒï¼Œåˆ™è®¡ç®—åˆ†å¸ƒä¹‹é—´çš„åˆ†ç¦»ç¨‹åº¦å°†éå¸¸ç®€å•ï¼Œå¹¶ä¸”ä»…æ¶‰åŠå‡å€¼å’Œæ ‡å‡†å·®çš„ç®€å•æ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Prediction score distributions for the (a) spam and (b) ham target levels based on the data in Table 9.11[557].",
            "zh": "ï¼ˆaï¼‰åƒåœ¾é‚®ä»¶å’Œï¼ˆbï¼‰ç«è…¿ç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒåŸºäºè¡¨9.11[557]ä¸­çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "where m is the slope of the line, and b is known as the y-intercept of the line (i.e., the position at which the line meets the vertical axis when the value of x is set to zero).",
            "zh": "å…¶ä¸­ m æ˜¯ç›´çº¿çš„æ–œç‡ï¼Œb ç§°ä¸ºç›´çº¿çš„ y æˆªè·ï¼ˆå³ï¼Œå½“ x å€¼è®¾ç½®ä¸ºé›¶æ—¶ç›´çº¿ä¸å‚ç›´è½´ç›¸äº¤çš„ä½ç½®ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this model, we can, for example, predict the expected rental price of a 690-square-foot office on the 11th floor of a building with a broadband rate of 50 Mb per second",
            "zh": "ä¾‹å¦‚ï¼Œä½¿ç”¨è¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æµ‹ä½äºå»ºç­‘ç‰© 11 æ¥¼çš„ 690 å¹³æ–¹è‹±å°ºåŠå…¬å®¤çš„é¢„æœŸç§Ÿé‡‘ä»·æ ¼ï¼Œå®½å¸¦é€Ÿç‡ä¸ºæ¯ç§’ 50 Mb"
        }
    },
    {
        "translation": {
            "en": "The threshold boundaries for the four bins used to discretize the LOAN AMOUNT feature are",
            "zh": "ç”¨äºç¦»æ•£åŒ– LOAN AMOUNT ç‰¹å¾çš„å››ä¸ªç®±çš„é˜ˆå€¼è¾¹ç•Œä¸º"
        }
    },
    {
        "translation": {
            "en": "For this introduction, we focus on categorical features and probability mass functions.",
            "zh": "åœ¨æœ¬ä»‹ç»ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹ä»‹ç»åˆ†ç±»ç‰¹å¾å’Œæ¦‚ç‡è´¨é‡å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection terminates when no accessible feature subset is better than the current subset.",
            "zh": "å½“æ²¡æœ‰å¯è®¿é—®çš„ç‰¹å¾å­é›†ä¼˜äºå½“å‰å­é›†æ—¶ï¼Œå‰å‘é¡ºåºé€‰æ‹©ç»ˆæ­¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "After covering the standard algorithm, we then look at extensions and variations that allow us to handle noisy data (the k nearest neighbor, or k-NN, algorithm), to make predictions more efficiently (k-d trees), to predict continuous targets, and to handle different kinds of descriptive features with varying measures of similarity.",
            "zh": "åœ¨ä»‹ç»äº†æ ‡å‡†ç®—æ³•ä¹‹åï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ‰©å±•å’Œå˜ä½“ï¼Œè¿™äº›æ‰©å±•å’Œå˜ä½“å…è®¸æˆ‘ä»¬å¤„ç†å™ªå£°æ•°æ®ï¼ˆk æœ€è¿‘é‚»æˆ– k-NN ç®—æ³•ï¼‰ã€æ›´æœ‰æ•ˆåœ°è¿›è¡Œé¢„æµ‹ï¼ˆk-d æ ‘ï¼‰ã€é¢„æµ‹è¿ç»­ç›®æ ‡ä»¥åŠå¤„ç†å…·æœ‰ä¸åŒç›¸ä¼¼åº¦é‡çš„ä¸åŒç±»å‹çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of possible levels that a descriptive feature can take determines the number of downward branches from a non-leaf node.",
            "zh": "æè¿°æ€§ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å¯èƒ½çº§åˆ«æ•°å†³å®šäº†ä»éå¶èŠ‚ç‚¹å‘ä¸‹åˆ†æ”¯çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The deep Q network (DQN) algorithm addresses these issues using two key ideas: experience replay and network freezing.",
            "zh": "æ·±åº¦ Q ç½‘ç»œ ï¼ˆDQNï¼‰ ç®—æ³•ä½¿ç”¨ä¸¤ä¸ªå…³é”®æ€æƒ³æ¥è§£å†³è¿™äº›é—®é¢˜ï¼šä½“éªŒå›æ”¾å’Œç½‘ç»œå†»ç»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.3",
            "zh": "è¡¨ 5.3"
        }
    },
    {
        "translation": {
            "en": "Figure 4.11",
            "zh": "å›¾ 4.11"
        }
    },
    {
        "translation": {
            "en": "Shannon, Claude, 731",
            "zh": "é¦™å†œï¼Œå…‹åŠ³å¾·ï¼Œ731"
        }
    },
    {
        "translation": {
            "en": "OpenAI, 668",
            "zh": "OpenAIï¼Œ668"
        }
    },
    {
        "translation": {
            "en": "Figure 10.10",
            "zh": "å›¾ 10.10"
        }
    },
    {
        "translation": {
            "en": "11. Gross et al. (2006) describes a real-world example of this kind of application of predictive analytics.",
            "zh": "11. Gross et al. ï¼ˆ2006ï¼‰ æè¿°äº†è¿™ç§é¢„æµ‹åˆ†æåº”ç”¨çš„çœŸå®ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(f) Calculate information gain using the Gini index for the EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "ï¼ˆfï¼‰ ä½¿ç”¨åŸºå°¼æŒ‡æ•°è®¡ç®—æ•™è‚²ã€å©šå§»çŠ¶å†µå’ŒèŒä¸šç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, during a manual data entry process, a fat fingered5 analyst may have entered 100,000 instead of 1,000.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨æ‰‹åŠ¨æ•°æ®è¾“å…¥è¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªèƒ–æ‰‹æŒ‡5åˆ†æå¸ˆå¯èƒ½è¾“å…¥äº† 100,000 è€Œä¸æ˜¯ 1,000ã€‚"
        }
    },
    {
        "translation": {
            "en": "Binning involves converting a continuous feature into a categorical feature.",
            "zh": "åˆ†ç®±æ¶‰åŠå°†è¿ç»­ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use the separation of the prediction score distributions to construct performance measures for categorical prediction models.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„æµ‹åˆ†æ•°åˆ†å¸ƒçš„åˆ†ç¦»æ¥æ„å»ºåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The â€  symbol marks the path of processing that generates the vector mask that controls which activations in the cell state are updated (see Equation (8.110)[511]).",
            "zh": "â€ ç¬¦å·æ ‡è®°äº†ç”ŸæˆçŸ¢é‡æ©ç çš„å¤„ç†è·¯å¾„ï¼Œè¯¥çŸ¢é‡æ©ç æ§åˆ¶ç»†èƒçŠ¶æ€ä¸­çš„å“ªäº›æ¿€æ´»è¢«æ›´æ–°ï¼ˆå‚è§å…¬å¼ï¼ˆ8.110ï¼‰[511]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weight matrix is organized so that each row contains the weights for a single neuron.",
            "zh": "æƒé‡çŸ©é˜µçš„ç»„ç»‡æ–¹å¼æ˜¯ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«å•ä¸ªç¥ç»å…ƒçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "After the player chooses to Stick, the dealer will reveal their hidden card and keep dealing more cards until they reach a total greater than or equal to 17.",
            "zh": "åœ¨ç©å®¶é€‰æ‹©åšæŒåï¼Œåº„å®¶å°†å±•ç¤ºä»–ä»¬çš„éšè—ç‰Œå¹¶ç»§ç»­å‘æ›´å¤šçš„ç‰Œï¼Œç›´åˆ°ä»–ä»¬è¾¾åˆ°å¤§äºæˆ–ç­‰äº 17 çš„æ€»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then select the statistical distribution that is most similar in shape to each of the resulting histograms.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬é€‰æ‹©å½¢çŠ¶ä¸æ¯ä¸ªç»“æœç›´æ–¹å›¾æœ€ç›¸ä¼¼çš„ç»Ÿè®¡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.3",
            "zh": "å›¾ A.3"
        }
    },
    {
        "translation": {
            "en": "PROFILE: Did the user complete the profile form when registering for the free trial?",
            "zh": "ä¸ªäººèµ„æ–™ï¼šç”¨æˆ·åœ¨æ³¨å†Œå…è´¹è¯•ç”¨æ—¶æ˜¯å¦å¡«å†™äº†ä¸ªäººèµ„æ–™è¡¨å•ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 3.8",
            "zh": "å›¾ 3.8"
        }
    },
    {
        "translation": {
            "en": "Based on this error another new set of weights is calculated using the error deltas shown.",
            "zh": "åŸºäºæ­¤è¯¯å·®ï¼Œä½¿ç”¨æ‰€ç¤ºçš„è¯¯å·®å¢é‡è®¡ç®—å¦ä¸€ç»„æ–°çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Focusing on the softmax activations for the output layer for all four examples, all three neurons output similar values; this is not surprising given that this is a randomly initialized network.",
            "zh": "å…³æ³¨æ‰€æœ‰å››ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚çš„ softmax æ¿€æ´»ï¼Œæ‰€æœ‰ä¸‰ä¸ªç¥ç»å…ƒè¾“å‡ºçš„å€¼éƒ½ç›¸ä¼¼;è¿™å¹¶ä¸å¥‡æ€ªï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12",
            "zh": "å›¾ 9.12"
        }
    },
    {
        "translation": {
            "en": "Actions are then selected randomly following this distribution.",
            "zh": "ç„¶åï¼Œæ ¹æ®æ­¤åˆ†å¸ƒéšæœºé€‰æ‹©æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5",
            "zh": "å›¾ 4.5"
        }
    },
    {
        "translation": {
            "en": "The rows in the table are labeled Target-positive and Target-negative and represent the target feature values that were expected.",
            "zh": "è¡¨ä¸­çš„è¡Œæ ‡æœ‰â€œç›®æ ‡é˜³æ€§â€å’Œâ€œç›®æ ‡é˜´æ€§â€ï¼Œè¡¨ç¤ºé¢„æœŸçš„ç›®æ ‡è¦ç´ å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, as we build the rest of the tree, we may reuse the ELEVATION feature.",
            "zh": "å› æ­¤ï¼Œå½“æˆ‘ä»¬æ„å»ºæ ‘çš„å…¶ä½™éƒ¨åˆ†æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é‡ç”¨ ELEVATION ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two kinds of mistakes that an inappropriate inductive bias can lead to: underfitting and overfitting. Underfitting occurs when the prediction model selected by the algorithm is too simplistic to represent the underlying relationship in the dataset between the descriptive features and the target feature. Overfitting, by contrast, occurs when the prediction model selected by the algorithm is so complex that the model fits the dataset too closely and becomes sensitive to noise in the data.",
            "zh": "ä¸é€‚å½“çš„å½’çº³åå·®ä¼šå¯¼è‡´ä¸¤ç§é”™è¯¯ï¼šæ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆã€‚å½“ç®—æ³•é€‰æ‹©çš„é¢„æµ‹æ¨¡å‹è¿‡äºç®€å•ï¼Œæ— æ³•è¡¨ç¤ºæ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„åŸºæœ¬å…³ç³»æ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ¬ æ‹Ÿåˆã€‚ç›¸åï¼Œå½“ç®—æ³•é€‰æ‹©çš„é¢„æµ‹æ¨¡å‹éå¸¸å¤æ‚ï¼Œä»¥è‡³äºæ¨¡å‹ä¸æ•°æ®é›†æ‹Ÿåˆå¾—å¤ªç´§å¯†å¹¶ä¸”å¯¹æ•°æ®ä¸­çš„å™ªå£°å˜å¾—æ•æ„Ÿæ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿‡æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "17. If we extended this example so that the restaurant was slightly hip and prepared different dishes based on the main ingredient chosen every night, some that Conor likes more than others (for example, chicken satay one night and chicken pie the next), this would become an example of a multi-armed bandit problem. Multi-armed bandit problems are a common framework for solving optimization problems where choices have uncertain outcomes and can be viewed as a very simple form of reinforcement learning.",
            "zh": "17. å¦‚æœæˆ‘ä»¬æ‰©å±•è¿™ä¸ªä¾‹å­ï¼Œè®©é¤å…ç¨å¾®æ—¶é«¦ä¸€ç‚¹ï¼Œæ ¹æ®æ¯æ™šé€‰æ‹©çš„ä¸»è¦é£Ÿæå‡†å¤‡ä¸åŒçš„èœè‚´ï¼Œå…¶ä¸­ä¸€äº›æ˜¯åº·çº³æ¯”å…¶ä»–é£Ÿææ›´å–œæ¬¢çš„ï¼ˆä¾‹å¦‚ï¼Œå‰ä¸€å¤©æ™šä¸Šçš„é¸¡è‚‰æ²™çˆ¹å’Œç¬¬äºŒå¤©çš„é¸¡è‚‰é¦…é¥¼ï¼‰ï¼Œè¿™å°†æˆä¸ºå¤šè‡‚å¼ºç›—é—®é¢˜çš„ä¸€ä¸ªä¾‹å­ã€‚å¤šè‡‚å¼ºç›—é—®é¢˜æ˜¯è§£å†³ä¼˜åŒ–é—®é¢˜çš„å¸¸è§æ¡†æ¶ï¼Œå…¶ä¸­é€‰æ‹©å…·æœ‰ä¸ç¡®å®šçš„ç»“æœï¼Œå¯ä»¥è¢«è§†ä¸ºä¸€ç§éå¸¸ç®€å•çš„å¼ºåŒ–å­¦ä¹ å½¢å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons in this network use a ReLU activation function, what would be the output of Neuron 5 if the network received the input vector: Neuron 1 = 0.7 and Neuron 2 = 0.3?",
            "zh": "ï¼ˆbï¼‰ å‡è®¾è¯¥ç½‘ç»œä¸­çš„å¤„ç†ç¥ç»å…ƒä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœç½‘ç»œæ¥æ”¶åˆ°è¾“å…¥å‘é‡ï¼šç¥ç»å…ƒ 1 = 0.7 å’Œç¥ç»å…ƒ 2 = 0.3ï¼Œç¥ç»å…ƒ 5 çš„è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "(a) Use this model to make predictions for each of the following query instances.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨æ­¤æ¨¡å‹å¯¹ä»¥ä¸‹æ¯ä¸ªæŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.9[399] illustrates such a network: the left uses a directed graph representation to show the topology of the network, and the weights on the connections; the right uses the matrix representation of the network to illustrate it processing the four possible input combinations to the XOR function in parallel.",
            "zh": "å›¾8.9[399]è¯´æ˜äº†è¿™æ ·ä¸€ä¸ªç½‘ç»œï¼šå·¦è¾¹ä½¿ç”¨æœ‰å‘å›¾è¡¨ç¤ºæ¥æ˜¾ç¤ºç½‘ç»œçš„æ‹“æ‰‘ç»“æ„å’Œè¿æ¥ä¸Šçš„æƒé‡;å³å›¾ä½¿ç”¨ç½‘ç»œçš„çŸ©é˜µè¡¨ç¤ºæ¥è¯´æ˜å®ƒå¹¶è¡Œå¤„ç† XOR å‡½æ•°çš„å››ç§å¯èƒ½çš„è¾“å…¥ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "86.34",
            "zh": "86.34"
        }
    },
    {
        "translation": {
            "en": "This circle covers the area in the feature space that we know must contain all the instances that are closer to the query than best.",
            "zh": "è¿™ä¸ªåœ†åœˆè¦†ç›–äº†ç‰¹å¾ç©ºé—´ä¸­çš„åŒºåŸŸï¼Œæˆ‘ä»¬çŸ¥é“è¯¥åŒºåŸŸå¿…é¡»åŒ…å«æ¯”æœ€ä½³å®ä¾‹æ›´æ¥è¿‘æŸ¥è¯¢çš„æ‰€æœ‰å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks whose topological structure correctly reflects the causal relationships between the features in a dataset are called causal graphs.",
            "zh": "è´å¶æ–¯ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„æ­£ç¡®åœ°åæ˜ äº†æ•°æ®é›†ä¸­ç‰¹å¾ä¹‹é—´çš„å› æœå…³ç³»ï¼Œç§°ä¸ºå› æœå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The same weights are used during the forward and backward passes of a single iteration of backpropagation.",
            "zh": "åœ¨åå‘ä¼ æ’­çš„å•æ¬¡è¿­ä»£çš„æ­£å‘å’Œå‘åä¼ é€’æœŸé—´ä½¿ç”¨ç›¸åŒçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "To understand underfitting and overfitting, consider the task of inducing a model to predict a personâ€™s INCOME (the target feature) based on AGE (a single descriptive feature). Table 1.5[14] lists a simple dataset that gives ages and salaries for five people. A visualization11 of this dataset is shown in Figure 1.3(a)[15].",
            "zh": "è¦ç†è§£æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆï¼Œè¯·è€ƒè™‘è¯±å¯¼æ¨¡å‹çš„ä»»åŠ¡ï¼Œä»¥æ ¹æ® AGEï¼ˆå•ä¸ªæè¿°æ€§ç‰¹å¾ï¼‰é¢„æµ‹ä¸€ä¸ªäººçš„æ”¶å…¥ï¼ˆç›®æ ‡ç‰¹å¾ï¼‰ã€‚è¡¨1.5[14]åˆ—å‡ºäº†ä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼Œå…¶ä¸­ç»™å‡ºäº†äº”ä¸ªäººçš„å¹´é¾„å’Œå·¥èµ„ã€‚è¯¥æ•°æ®é›†çš„å¯è§†åŒ–11å¦‚å›¾1.3ï¼ˆaï¼‰[15]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Another interesting point of comparison between these two trees is that even though they are both consistent with the dataset given in Table 4.3[136], they do not always return the same prediction.",
            "zh": "è¿™ä¸¤ä¸ªæ ‘ä¹‹é—´å¦ä¸€ä¸ªæœ‰è¶£çš„æ¯”è¾ƒç‚¹æ˜¯ï¼Œå³ä½¿å®ƒä»¬éƒ½ä¸è¡¨4.3[136]ä¸­ç»™å‡ºçš„æ•°æ®é›†ä¸€è‡´ï¼Œä½†å®ƒä»¬å¹¶ä¸æ€»æ˜¯è¿”å›ç›¸åŒçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Of those, f(x) = x2 is an example of a second order polynomial function, also known as a quadratic function, as its highest exponent is 2, and f(x) = 3x3 + 2x2 âˆ’ x âˆ’ 2 is a third order polynomial function, also known as a cubic function, as its highest exponent is 3.",
            "zh": "å…¶ä¸­ï¼Œfï¼ˆxï¼‰ = x2 æ˜¯äºŒé˜¶å¤šé¡¹å¼å‡½æ•°çš„ä¸€ä¸ªä¾‹å­ï¼Œä¹Ÿç§°ä¸ºäºŒæ¬¡å‡½æ•°ï¼Œå› ä¸ºå®ƒçš„æœ€é«˜æŒ‡æ•°æ˜¯ 2ï¼Œè€Œ fï¼ˆxï¼‰ = 3x3 + 2x2 âˆ’ x âˆ’ 2 æ˜¯ä¸‰é˜¶å¤šé¡¹å¼å‡½æ•°ï¼Œä¹Ÿç§°ä¸ºä¸‰æ¬¡å‡½æ•°ï¼Œå› ä¸ºå®ƒçš„æœ€é«˜æŒ‡æ•°æ˜¯ 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.8â€…â€…â€…Modeling points in time for a scenario with no real observation period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.8 å¯¹æ²¡æœ‰å®é™…è§‚æµ‹æœŸçš„åœºæ™¯çš„æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªå®¢æˆ·ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the predictions of these models, perform the following tasks to compare their performance.",
            "zh": "æ ¹æ®è¿™äº›æ¨¡å‹çš„é¢„æµ‹ï¼Œæ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ä»¥æ¯”è¾ƒå…¶æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The minimum values of âˆ’ 9,999 for the SKYIVAR_U/G/R/I/Z columns (and some others not shown in Table 13.2[711]), which were so different from the means for those columns, suggested that maybe there were missing values after all.10 There were also a number of columns, such as ROWC_U/G/R/I/Z, that had cardinality of 1 (and standard deviations of zero) indicating that every row had the same.",
            "zh": "SKYIVAR_U/G/R/I/Z åˆ—ï¼ˆä»¥åŠè¡¨ 13.2[711] ä¸­æœªæ˜¾ç¤ºçš„å…¶ä»–ä¸€äº›åˆ—ï¼‰çš„æœ€å°å€¼ä¸º âˆ’ 9,999ï¼Œè¿™ä¸è¿™äº›åˆ—çš„å¹³å‡å€¼å¤§ä¸ç›¸åŒï¼Œè¿™è¡¨æ˜å¯èƒ½æ¯•ç«Ÿå­˜åœ¨ç¼ºå¤±å€¼ROWC_Uã€‚ åŸºæ•°ä¸º 1ï¼ˆæ ‡å‡†å·®ä¸ºé›¶ï¼‰ï¼Œè¡¨ç¤ºæ¯è¡Œéƒ½ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "This combination of multiple examples processed in parallel and a larger learning rate can result in much faster training times using batch gradient descent.",
            "zh": "è¿™ç§å¹¶è¡Œå¤„ç†çš„å¤šä¸ªç¤ºä¾‹å’Œæ›´å¤§çš„å­¦ä¹ ç‡çš„ç»„åˆå¯ä»¥å¯¼è‡´ä½¿ç”¨æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„è®­ç»ƒæ—¶é—´æ›´å¿«ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was not reasonable, nor necessary, to expect that Jocelyn would become fully familiar with the intricacies of the SDSS and the astronomy that it performs.",
            "zh": "æœŸæœ›Jocelynå®Œå…¨ç†Ÿæ‚‰SDSSçš„å¤æ‚æ€§åŠå…¶æ‰€æ‰§è¡Œçš„å¤©æ–‡å­¦æ˜¯ä¸åˆç†çš„ï¼Œä¹Ÿæ²¡æœ‰å¿…è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weights in this weighted sum are the probabilities of the state transitions13",
            "zh": "æ­¤åŠ æƒå’Œä¸­çš„æƒé‡æ˜¯çŠ¶æ€è½¬æ¢çš„æ¦‚ç‡13"
        }
    },
    {
        "translation": {
            "en": "This type of instability can be indicative that the learning rate Î± is too high.",
            "zh": "è¿™ç§ç±»å‹çš„ä¸ç¨³å®šæ€§å¯èƒ½è¡¨æ˜Î±å­¦ä¹ ç‡å¤ªé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, several features of real data can help us to induce reasonable models in high-dimensional feature spaces.28 First, although real data does spread out, it doesnâ€™t spread out quite as randomly and quickly as we have illustrated here.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼ŒçœŸå®æ•°æ®çš„å‡ ä¸ªç‰¹å¾å¯ä»¥å¸®åŠ©æˆ‘ä»¬åœ¨é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­è¯±å¯¼å‡ºåˆç†çš„æ¨¡å‹.28é¦–å…ˆï¼Œå°½ç®¡çœŸå®æ•°æ®ç¡®å®ä¼šåˆ†æ•£å¼€æ¥ï¼Œä½†å®ƒå¹¶ä¸åƒæˆ‘ä»¬åœ¨è¿™é‡Œè¯´æ˜çš„é‚£æ ·éšæœºå’Œå¿«é€Ÿåœ°æ•£å¼€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision surface resulting from Equation (7.27)[342] is shown in Figure 7.12(b)[343].",
            "zh": "ç”±æ–¹ç¨‹ï¼ˆ7.27ï¼‰[342]å¾—å‡ºçš„å†³ç­–é¢å¦‚å›¾7.12ï¼ˆbï¼‰[343]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Information gain for each descriptive feature as a predictor of membership of each cluster based on the clustering of the mobile phone customer dataset in Table 10.1[604] found using k-means clustering (k = 3).",
            "zh": "æ ¹æ®è¡¨10.1[604]ä¸­ä½¿ç”¨kå‡å€¼èšç±»ï¼ˆk = 3ï¼‰å‘ç°çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„èšç±»ï¼Œæ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šä½œä¸ºæ¯ä¸ªèšç±»æˆå‘˜çš„é¢„æµ‹å› å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The business agreed that a customer who had been inactive for one month (i.e., had not made any calls or paid a bill) or who had explicitly canceled or not renewed a contract would be considered to have churned.",
            "zh": "è¯¥ä¼ä¸šåŒæ„ï¼Œä¸€ä¸ªæœˆä¸æ´»è·ƒçš„å®¢æˆ·ï¼ˆå³æ²¡æœ‰æ‹¨æ‰“ä»»ä½•ç”µè¯æˆ–æ”¯ä»˜è´¦å•ï¼‰æˆ–æ˜ç¡®å–æ¶ˆæˆ–æœªç»­ç­¾åˆåŒçš„å®¢æˆ·å°†è¢«è§†ä¸ºå·²æµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hebbâ€™s theory that learning occurs through changes in the connections between neurons and that behavior emerges through the flow of information across these connections has been very influential both in neuroscience and, as we will discuss, in deep learning.",
            "zh": "Hebb çš„ç†è®ºè®¤ä¸ºï¼Œå­¦ä¹ æ˜¯é€šè¿‡ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„å˜åŒ–å‘ç”Ÿçš„ï¼Œè€Œè¡Œä¸ºæ˜¯é€šè¿‡è¿™äº›è¿æ¥ä¸­çš„ä¿¡æ¯æµå‡ºç°çš„ï¼Œè¿™åœ¨ç¥ç»ç§‘å­¦ä¸­éƒ½éå¸¸æœ‰å½±å“åŠ›ï¼Œæ­£å¦‚æˆ‘ä»¬å°†è¦è®¨è®ºçš„é‚£æ ·ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ä¹Ÿéå¸¸æœ‰å½±å“åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, zi is the result of the weighted sum calculation carried out in neuron i.",
            "zh": "ä¾‹å¦‚ï¼Œzi æ˜¯åœ¨ç¥ç»å…ƒ i ä¸­æ‰§è¡Œçš„åŠ æƒå’Œè®¡ç®—çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "1. This example dataset is inspired by the use of analytics in professional and college sports, often referred to as sabremetrics. Two accessible introductions to this field are Lewis (2004) and Keri (2007).",
            "zh": "1. æ­¤ç¤ºä¾‹æ•°æ®é›†çš„çµæ„Ÿæ¥è‡ªåœ¨èŒä¸šå’Œå¤§å­¦ä½“è‚²è¿åŠ¨ä¸­ä½¿ç”¨åˆ†æï¼Œé€šå¸¸ç§°ä¸º sabremetricsã€‚Lewis ï¼ˆ2004ï¼‰ å’Œ Keri ï¼ˆ2007ï¼‰ å¯¹è¿™ä¸€é¢†åŸŸçš„ä¸¤ä¸ªæ— éšœç¢ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A covariance matrix contains a row and column for each feature, and each element of the matrix lists the covariance between the corresponding pairs of features.",
            "zh": "åæ–¹å·®çŸ©é˜µåŒ…å«æ¯ä¸ªç‰¹å¾çš„è¡Œå’Œåˆ—ï¼ŒçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ éƒ½åˆ—å‡ºäº†ç›¸åº”ç‰¹å¾å¯¹ä¹‹é—´çš„åæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5",
            "zh": "å›¾ 3.5"
        }
    },
    {
        "translation": {
            "en": "Cards showing character faces and names for the Guess Who game.",
            "zh": "æ˜¾ç¤ºâ€œçŒœçŒœè°â€æ¸¸æˆçš„è§’è‰²é¢å­”å’Œåå­—çš„å¡ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see in Figure 5.10(b)[201] that this circle intersects with the triangle marking the location of d12, which is currently stored in best (i.e., it is our current best guess for the nearest neighbor).",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å›¾5.10ï¼ˆbï¼‰[201]ä¸­çœ‹åˆ°ï¼Œè¿™ä¸ªåœ†ä¸æ ‡è®°d12ä½ç½®çš„ä¸‰è§’å½¢ç›¸äº¤ï¼Œd12ç›®å‰å­˜å‚¨åœ¨æœ€ä½³ä½ç½®ï¼ˆå³ï¼Œè¿™æ˜¯æˆ‘ä»¬ç›®å‰å¯¹æœ€è¿‘é‚»å±…çš„æœ€ä½³çŒœæµ‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Pearl, Judea. 2000. Causality: Models, reasoning and inference, Vol. 29. Cambridge University Press.",
            "zh": "çç ï¼ŒçŠ¹å¤ªã€‚2000. å› æœå…³ç³»ï¼šæ¨¡å‹ã€æ¨ç†å’Œæ¨ç†ï¼Œç¬¬ 29 å·ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.1â€ƒDerivatives of Continuous Functions",
            "zh": "C.1 è¿ç»­å‡½æ•°çš„å¯¼æ•°"
        }
    },
    {
        "translation": {
            "en": "39. This operation is sometimes called the Hadamard product (see Appendix D[771]).",
            "zh": "39. è¿™ç§æ“ä½œæœ‰æ—¶è¢«ç§°ä¸ºHadamardç§¯ï¼ˆè§é™„å½•D[771]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Here we can see that the decision boundary may have been pushed too far back into the yes region (one of the crosses is now on the wrong side of the decision boundary).",
            "zh": "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å†³ç­–è¾¹ç•Œå¯èƒ½è¢«æ¨å¾—å¤ªè¿œäº†ï¼Œå›åˆ°äº†â€œæ˜¯â€åŒºåŸŸï¼ˆå…¶ä¸­ä¸€ä¸ªäº¤å‰ç°åœ¨ä½äºå†³ç­–è¾¹ç•Œçš„é”™è¯¯ä¸€ä¾§ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weighting is determined by the size of each partitionâ€”so a large partition should contribute more to the overall remaining entropy than a smaller partition.",
            "zh": "æƒé‡ç”±æ¯ä¸ªåˆ†åŒºçš„å¤§å°å†³å®šï¼Œå› æ­¤å¤§åˆ†åŒºå¯¹æ•´ä½“å‰©ä½™ç†µçš„è´¡çŒ®åº”è¯¥æ¯”è¾ƒå°çš„åˆ†åŒºæ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic ranges from 0 to 1, and higher values indicate better model performance, reflecting the fact that there is a clear distinction between the distributions of the scores predicted by the model for the negative and the positive instances.",
            "zh": "K-S ç»Ÿè®¡é‡èŒƒå›´ä» 0 åˆ° 1ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ï¼Œè¿™åæ˜ äº†æ¨¡å‹é¢„æµ‹çš„è´Ÿå®ä¾‹å’Œæ­£å®ä¾‹çš„åˆ†æ•°åˆ†å¸ƒä¹‹é—´å­˜åœ¨æ˜æ˜¾åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.6[547] illustrates how the data is divided during the Îµ0 bootstrap process.",
            "zh": "å›¾ 9.6[547] è¯´æ˜äº†åœ¨ Îµ0 å¼•å¯¼è¿‡ç¨‹ä¸­å¦‚ä½•åˆ’åˆ†æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two popular variants of ReLU that adopt this strategy are the Leaky ReLU (Maas et al., 2013) and the Parametric ReLU (He et al., 2015).",
            "zh": "é‡‡ç”¨è¿™ç§ç­–ç•¥çš„ä¸¤ç§æµè¡Œçš„ ReLU å˜ä½“æ˜¯ Leaky ReLU ï¼ˆMaas et al.ï¼Œ 2013ï¼‰ å’Œ Parametric ReLU ï¼ˆHe et al.ï¼Œ 2015ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.1â€…â€…â€…Different Types of Data",
            "zh": "2.4.1 ä¸åŒç±»å‹çš„æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "For example, a minimum age value of âˆ’ 12 would jump out as an error.",
            "zh": "ä¾‹å¦‚ï¼Œæœ€å°å¹´é¾„å€¼ âˆ’ 12 å°†ä½œä¸ºé”™è¯¯è·³å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the layers of neurons are here represented by rectangles with rounded corners with the labels on the rectangles indicating whether the rectangle represents the input layer xt, the hidden layer ht, the output layer yt, or the hidden layer from the previous time-step htâˆ’1; and the (multiple) connections between neurons in different layers are here represented by a single arrow labeled with the name of the weight matrix for the weights on those connections.",
            "zh": "ä¾‹å¦‚ï¼Œç¥ç»å…ƒå±‚åœ¨è¿™é‡Œç”±åœ†è§’çŸ©å½¢è¡¨ç¤ºï¼ŒçŸ©å½¢ä¸Šçš„æ ‡ç­¾æŒ‡ç¤ºçŸ©å½¢æ˜¯ä»£è¡¨è¾“å…¥å±‚ xtã€éšè—å±‚ htã€è¾“å‡ºå±‚ ytï¼Œè¿˜æ˜¯æ¥è‡ªå‰ä¸€ä¸ªæ—¶é—´æ­¥é•¿ htâˆ’1 çš„éšè—å±‚;ä¸åŒå±‚ä¸­ç¥ç»å…ƒä¹‹é—´çš„ï¼ˆå¤šä¸ªï¼‰è¿æ¥åœ¨è¿™é‡Œç”±ä¸€ä¸ªç®­å¤´è¡¨ç¤ºï¼Œç®­å¤´æ ‡æœ‰è¿™äº›è¿æ¥ä¸Šçš„æƒé‡çŸ©é˜µçš„åç§°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for the set of predictions shown in Table 9.1[537].",
            "zh": "è¡¨9.1[537]æ‰€ç¤ºçš„ä¸€ç»„é¢„æµ‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure C.1(a)[765] shows a profile of the speed during this journey measured at different points in time.",
            "zh": "å›¾C.1ï¼ˆaï¼‰[765]æ˜¾ç¤ºäº†åœ¨ä¸åŒæ—¶é—´ç‚¹æµ‹é‡çš„è¿™æ®µæ—…ç¨‹ä¸­çš„é€Ÿåº¦æ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, for those interested in experimenting with different evaluation measures, the ROCR package (Sing et al., 2005) for the R programming language includes a wide range of measures.",
            "zh": "æœ€åï¼Œå¯¹äºé‚£äº›æœ‰å…´è¶£å°è¯•ä¸åŒè¯„ä¼°æªæ–½çš„äººæ¥è¯´ï¼ŒR ç¼–ç¨‹è¯­è¨€çš„ ROCR åŒ…ï¼ˆSing et al.ï¼Œ 2005ï¼‰åŒ…æ‹¬å¹¿æ³›çš„æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are a number of fundamental mathematical types that are the building blocks of linear algebra. These include",
            "zh": "æœ‰è®¸å¤šåŸºæœ¬çš„æ•°å­¦ç±»å‹æ˜¯çº¿æ€§ä»£æ•°çš„ç»„æˆéƒ¨åˆ†ã€‚è¿™äº›åŒ…æ‹¬"
        }
    },
    {
        "translation": {
            "en": "business",
            "zh": "å•†"
        }
    },
    {
        "translation": {
            "en": "BILLAMOUNTCHANGEPCT",
            "zh": "è´¦å•é‡‘é¢æ›´æ”¹PCT"
        }
    },
    {
        "translation": {
            "en": "13. The staircase nature of this graph arises from the fact that there are ranges for the threshold in which no instances occur (for example, from 0.348 to 0.657), during which the TPR and TNR values do not change. Larger test sets cause these curves to smoothen significantly.",
            "zh": "13. è¯¥å›¾çš„é˜¶æ¢¯æ€§è´¨æºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³é˜ˆå€¼å­˜åœ¨ä¸å‘ç”Ÿä»»ä½•å®ä¾‹çš„èŒƒå›´ï¼ˆä¾‹å¦‚ï¼Œä» 0.348 åˆ° 0.657ï¼‰ï¼Œåœ¨æ­¤æœŸé—´ TPR å’Œ TNR å€¼ä¸ä¼šæ”¹å˜ã€‚è¾ƒå¤§çš„æµ‹è¯•é›†ä¼šå¯¼è‡´è¿™äº›æ›²çº¿æ˜¾è‘—å¹³æ»‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.2",
            "zh": "è¡¨ 9.2"
        }
    },
    {
        "translation": {
            "en": "When we have a small dataset (introducing the possibility of a lucky split), measuring aggregate performance using a set of models gives a better estimate of post-deployment performance than measuring performance using a single model.",
            "zh": "å½“æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾ƒå°çš„æ•°æ®é›†æ—¶ï¼ˆå¼•å…¥äº†å¹¸è¿æ‹†åˆ†çš„å¯èƒ½æ€§ï¼‰ï¼Œä½¿ç”¨ä¸€ç»„æ¨¡å‹æ¥è¡¡é‡æ€»ä½“æ€§èƒ½æ¯”ä½¿ç”¨å•ä¸ªæ¨¡å‹æ¥è¡¡é‡æ€§èƒ½å¯ä»¥æ›´å¥½åœ°ä¼°è®¡éƒ¨ç½²åçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) The salaries of car insurance policyholders.",
            "zh": "ï¼ˆeï¼‰ æ±½è½¦ä¿é™©æŠ•ä¿äººçš„è–ªé‡‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.6â€…â€…â€…(a) A visualization of the final action-value table for an agent trained using SARSA on-policy temporal-difference learning across the grid world after 350 episodes. (b) The cumulative reward earned from each episode. (c) An illustration of the target policy learned by the agent after 350 episodes. (d) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "11.6 ï¼ˆaï¼‰ åœ¨ 350 é›†åï¼Œåœ¨æ•´ä¸ªç½‘æ ¼ä¸–ç•Œä¸­ä½¿ç”¨ SARSA æ”¿ç­–æ—¶é—´å·®å¼‚å­¦ä¹ è®­ç»ƒçš„æ™ºèƒ½ä½“çš„æœ€ç»ˆè¡ŒåŠ¨å€¼è¡¨çš„å¯è§†åŒ–ã€‚ï¼ˆbï¼‰ æ¯é›†æ‰€è·å¾—çš„ç´¯ç§¯å¥–åŠ±ã€‚ï¼ˆcï¼‰ ä»£ç†äººåœ¨350é›†åäº†è§£åˆ°çš„ç›®æ ‡æ”¿ç­–çš„è¯´æ˜ã€‚ï¼ˆdï¼‰ å½“è´ªå©ªåœ°éµå¾ªç›®æ ‡ç­–ç•¥æ—¶ï¼Œä»£ç†ä»å¼€å§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The Voronoi tessellation of the feature space when the dataset has been updated to include the query instance; and (b) the updated decision boundary reflecting the addition of the query instance in the training set.",
            "zh": "ï¼ˆaï¼‰ å½“æ•°æ®é›†æ›´æ–°ä¸ºåŒ…å«æŸ¥è¯¢å®ä¾‹æ—¶ï¼Œç‰¹å¾ç©ºé—´çš„ Voronoi æ›²é¢ç»†åˆ†;ï¼ˆbï¼‰ æ›´æ–°çš„å†³ç­–è¾¹ç•Œï¼Œåæ˜ äº†åœ¨è®­ç»ƒé›†ä¸­æ·»åŠ æŸ¥è¯¢å®ä¾‹çš„æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "This section assumes a basic understanding of probability theory, including the basics of calculating probabilities based on relative frequencies, calculating conditional probabilities, the probability product rule, the probability chain rule, and the Theorem of Total Probability.",
            "zh": "æœ¬èŠ‚å‡è®¾å¯¹æ¦‚ç‡è®ºæœ‰åŸºæœ¬çš„äº†è§£ï¼ŒåŒ…æ‹¬åŸºäºç›¸å¯¹é¢‘ç‡è®¡ç®—æ¦‚ç‡ã€è®¡ç®—æ¡ä»¶æ¦‚ç‡ã€æ¦‚ç‡ä¹˜ç§¯è§„åˆ™ã€æ¦‚ç‡é“¾è§„åˆ™å’Œæ€»æ¦‚ç‡å®šç†çš„åŸºç¡€çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes this expected global structure does not match actual patterns within a dataset that we might want to take advantage of.",
            "zh": "æœ‰æ—¶ï¼Œè¿™ç§é¢„æœŸçš„å…¨å±€ç»“æ„ä¸æˆ‘ä»¬å¯èƒ½æƒ³è¦åˆ©ç”¨çš„æ•°æ®é›†ä¸­çš„å®é™…æ¨¡å¼ä¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "68âˆ’95âˆ’99.7 rule, 62, 71",
            "zh": "68âˆ’95âˆ’99.7 è§„åˆ™ã€62ã€71"
        }
    },
    {
        "translation": {
            "en": "Consequently, there is a diminishing return on the improvement of the network relative to the time spent on training.",
            "zh": "å› æ­¤ï¼Œç›¸å¯¹äºèŠ±åœ¨åŸ¹è®­ä¸Šçš„æ—¶é—´ï¼Œç½‘ç»œæ”¹è¿›çš„å›æŠ¥æ˜¯é€’å‡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "cumulative gain chart, 569, 570, 592",
            "zh": "ç´¯è®¡å¢ç›Šå›¾ï¼Œ569ã€570ã€592"
        }
    },
    {
        "translation": {
            "en": "The average monthly recurring charge paid by the customer",
            "zh": "å®¢æˆ·æ¯æœˆæ”¯ä»˜çš„å¹³å‡ç»å¸¸æ€§è´¹ç”¨"
        }
    },
    {
        "translation": {
            "en": "(2008) indicate that boosted decision tree ensembles were the best-performing model of those tested for datasets containing up to 4,000 descriptive features.",
            "zh": "ï¼ˆ2008ï¼‰æŒ‡å‡ºï¼Œåœ¨åŒ…å«å¤šè¾¾4,000ä¸ªæè¿°æ€§ç‰¹å¾çš„æ•°æ®é›†ä¸­ï¼Œå¢å¼ºå†³ç­–æ ‘é›†æˆæ˜¯æ€§èƒ½æœ€å¥½çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It may, for example, be a state that has a very low probability in the distribution.",
            "zh": "ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½æ˜¯åˆ†å¸ƒä¸­æ¦‚ç‡éå¸¸ä½çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use an example to illustrate how a prediction is made using a multinomial regression model.",
            "zh": "æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨å¤šé¡¹å¼å›å½’æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cars occupy an area covered by two cells (one above the other as shown in Image (a)).",
            "zh": "æ±½è½¦å æ®ç”±ä¸¤ä¸ªå•å…ƒæ ¼è¦†ç›–çš„åŒºåŸŸï¼ˆä¸€ä¸ªåœ¨å¦ä¸€ä¸ªå•å…ƒæ ¼ä¹‹ä¸Šï¼Œå¦‚å›¾ï¼ˆaï¼‰æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.5â€ƒEvaluation",
            "zh": "13.5 è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "Consequently, Ross needed to agree with the business (in particular the customer retention team) on a definition of churn.",
            "zh": "å› æ­¤ï¼ŒRoss éœ€è¦ä¸ä¸šåŠ¡éƒ¨é—¨ï¼ˆå°¤å…¶æ˜¯å®¢æˆ·ä¿ç•™å›¢é˜Ÿï¼‰å°±å®¢æˆ·æµå¤±çš„å®šä¹‰è¾¾æˆä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "DIABETES",
            "zh": "ç³–å°¿ç—…"
        }
    },
    {
        "translation": {
            "en": "2. To try to better understand the slightly baffling behavior of her new baby, Mariaâ€”a scientifically minded new motherâ€”monitored her baby girl over the course of a day recording her activity at 20 minute intervals. The activity stream looked like this (with time flowing down through the columns):",
            "zh": "2. ä¸ºäº†æ›´å¥½åœ°ç†è§£å¥¹æ–°ç”Ÿå©´å„¿ç•¥å¾®è«åå…¶å¦™çš„è¡Œä¸ºï¼Œç›ä¸½äºšâ€”â€”ä¸€ä½å…·æœ‰ç§‘å­¦å¤´è„‘çš„æ–°å¦ˆå¦ˆâ€”â€”åœ¨ä¸€å¤©çš„æ—¶é—´é‡Œç›‘æµ‹å¥¹çš„å¥³å©´ï¼Œæ¯éš” 20 åˆ†é’Ÿè®°å½•ä¸€æ¬¡å¥¹çš„æ´»åŠ¨ã€‚æ´»åŠ¨æµå¦‚ä¸‹æ‰€ç¤ºï¼ˆæ—¶é—´æµè¿‡åˆ—ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "4. Likely voters are the subset of registered voters who have been identified as most likely to actually vote in an election.",
            "zh": "4. å¯èƒ½é€‰æ°‘æ˜¯è¢«ç¡®å®šä¸ºæœ€æœ‰å¯èƒ½åœ¨é€‰ä¸¾ä¸­å®é™…æŠ•ç¥¨çš„ç™»è®°é€‰æ°‘çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "sum of squared errors, 315, 367, 409, 411, 424, 426, 433, 441, 575, 578, 731",
            "zh": "è¯¯å·®çš„å¹³æ–¹å’Œï¼Œ315ã€367ã€409ã€411ã€424ã€426ã€433ã€441ã€575ã€578ã€731"
        }
    },
    {
        "translation": {
            "en": "At first she was terrible at it, and almost every step she took led to the disappointing sensation of wet feet.",
            "zh": "èµ·åˆï¼Œå¥¹å¯¹æ­¤å¾ˆç³Ÿç³•ï¼Œå‡ ä¹æ¯èµ°ä¸€æ­¥éƒ½ä¼šå¯¼è‡´ä»¤äººå¤±æœ›çš„æ¹¿è„šæ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "If we have knowledge of these parent and children nodes, however, then the node is conditionally independent of the rest of the nodes in the graph.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬äº†è§£è¿™äº›çˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹ï¼Œåˆ™è¯¥èŠ‚ç‚¹åœ¨æ¡ä»¶ä¸Šç‹¬ç«‹äºå›¾ä¸­çš„å…¶ä½™èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we describe the techniques used to address these issues as well as the use of ensemble methods that allow us to combine the predictions made by multiple models.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”¨äºè§£å†³è¿™äº›é—®é¢˜çš„æŠ€æœ¯ï¼Œä»¥åŠé›†æˆæ–¹æ³•çš„ä½¿ç”¨ï¼Œè¿™äº›æ–¹æ³•å…è®¸æˆ‘ä»¬ç»„åˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "PREFCHANNEL: The customerâ€™s preferred contact channel (email, phone, or sms)",
            "zh": "PREFCHANNELï¼šå®¢æˆ·çš„é¦–é€‰è”ç³»æ¸ é“ï¼ˆç”µå­é‚®ä»¶ã€ç”µè¯æˆ–çŸ­ä¿¡ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Figure 8.21[444] plots the SSE of the ReLU network across the training epochs when we use a smaller learning rate, in this case Î± = 0.1.",
            "zh": "å›¾ 8.21[444] ç»˜åˆ¶äº†å½“æˆ‘ä»¬ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º Î± = 0.1ï¼‰æ—¶ï¼ŒReLU ç½‘ç»œåœ¨æ•´ä¸ªè®­ç»ƒæ—¶æœŸçš„ SSEã€‚"
        }
    },
    {
        "translation": {
            "en": "Long short-term memory (LSTM) networks are specifically designed to improve the ability of a recurrent network to model dependencies over long distances in a sequence (Hochreiter and Schmidhuber, 1997).",
            "zh": "é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œä¸“é—¨è®¾è®¡ç”¨äºæé«˜å¾ªç¯ç½‘ç»œåœ¨åºåˆ—ä¸­é•¿è·ç¦»å»ºæ¨¡ä¾èµ–æ€§çš„èƒ½åŠ›ï¼ˆHochreiterå’ŒSchmidhuberï¼Œ1997ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "All the performance measures described in Chapter 9[533] for supervised learning relied on the existence of ground truth labels to which the predictions made by a model can be compared to measure its performance.",
            "zh": "ç¬¬9ç« [533]ä¸­æè¿°çš„ç›‘ç£å­¦ä¹ çš„æ‰€æœ‰æ€§èƒ½æµ‹é‡éƒ½ä¾èµ–äºåŸºæœ¬å®å†µæ ‡ç­¾çš„å­˜åœ¨ï¼Œæ¨¡å‹æ‰€åšçš„é¢„æµ‹å¯ä»¥ä¸è¿™äº›æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒä»¥è¡¡é‡å…¶æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. Using binary logs, the maximum entropy for a set with two types of elements is 1.00 bit, but the entropy for a set with more than two types of elements may be greater than 1.00 bit. The choice of base used in Shannonâ€™s model, in the context in which it is used in this chapter, is arbitrary. The choice of base 2 is due partly to a conventional computer science background and partly to its allowing us to use the bits unit of information.",
            "zh": "5. ä½¿ç”¨äºŒè¿›åˆ¶å¯¹æ•°ï¼Œå…·æœ‰ä¸¤ç§ç±»å‹å…ƒç´ çš„é›†åˆçš„æœ€å¤§ç†µä¸º 1.00 ä½ï¼Œä½†å…·æœ‰ä¸¤ç§ä»¥ä¸Šå…ƒç´ çš„é›†åˆçš„æœ€å¤§ç†µå¯èƒ½å¤§äº 1.00 ä½ã€‚åœ¨æœ¬ç« ä½¿ç”¨çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œé¦™å†œæ¨¡å‹ä¸­ä½¿ç”¨çš„åŸºæ•°çš„é€‰æ‹©æ˜¯ä»»æ„çš„ã€‚é€‰æ‹©ä»¥ 2 ä¸ºåŸºæ•°çš„éƒ¨åˆ†åŸå› æ˜¯ä¼ ç»Ÿçš„è®¡ç®—æœºç§‘å­¦èƒŒæ™¯ï¼Œéƒ¨åˆ†åŸå› æ˜¯å®ƒå…è®¸æˆ‘ä»¬ä½¿ç”¨ä¿¡æ¯çš„æ¯”ç‰¹å•ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Scarne, John. 1986. Scarneâ€™s new complete guide to gambling. Simon & Schuster.",
            "zh": "æ–¯å¡æ©ï¼Œçº¦ç¿°ã€‚1986. æ–¯å¡æ©çš„æ–°èµŒåšå®Œæ•´æŒ‡å—ã€‚è¥¿è’™å’Œèˆ’æ–¯ç‰¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "FAMILY, did any of their parents or siblings suffer from heart disease",
            "zh": "å®¶åº­ï¼Œä»–ä»¬çš„çˆ¶æ¯æˆ–å…„å¼Ÿå§å¦¹æ˜¯å¦æ‚£æœ‰å¿ƒè„ç—…"
        }
    },
    {
        "translation": {
            "en": "The fact that the same weights are applied on the feedback loop within a recurrent network means that these networks are very susceptible to unstable gradients, as the repeated multiplication by the same weight of the gradient as it is propagated back through the unrolled network can cause the gradient to explode or vanish.",
            "zh": "åœ¨å¾ªç¯ç½‘ç»œä¸­çš„åé¦ˆå›è·¯ä¸Šæ–½åŠ ç›¸åŒçš„æƒé‡è¿™ä¸€äº‹å®æ„å‘³ç€è¿™äº›ç½‘ç»œéå¸¸å®¹æ˜“å—åˆ°ä¸ç¨³å®šæ¢¯åº¦çš„å½±å“ï¼Œå› ä¸ºåœ¨æ¢¯åº¦é€šè¿‡å±•å¼€ç½‘ç»œä¼ æ’­å›æ¥æ—¶ï¼Œé‡å¤ä¹˜ä»¥ç›¸åŒæƒé‡çš„æ¢¯åº¦ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "As the figure shows, it is possible to draw a straight line between these two classes of inputs.",
            "zh": "å¦‚å›¾æ‰€ç¤ºï¼Œå¯ä»¥åœ¨è¿™ä¸¤ç±»è¾“å…¥ä¹‹é—´ç”»ä¸€æ¡ç›´çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Most people would ask Question 1 first.",
            "zh": "å¤§å¤šæ•°äººä¼šå…ˆé—®é—®é¢˜ 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "logistic unit, 386",
            "zh": "åå‹¤å•ä½ï¼Œ386"
        }
    },
    {
        "translation": {
            "en": "The other main advantage of using a programming language is that, in most cases, the newest advanced analytics techniques become available in programming languages long before they are implemented in application-based solutions.",
            "zh": "ä½¿ç”¨ç¼–ç¨‹è¯­è¨€çš„å¦ä¸€ä¸ªä¸»è¦ä¼˜ç‚¹æ˜¯ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæœ€æ–°çš„é«˜çº§åˆ†ææŠ€æœ¯æ—©åœ¨åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆä¸­å®ç°ä¹‹å‰ï¼Œå°±å·²ç»åœ¨ç¼–ç¨‹è¯­è¨€ä¸­å¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Stormy nights are rare.",
            "zh": "æš´é£é›¨çš„å¤œæ™šå¾ˆå°‘è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "A data quality report, however, can also be used to explore any dataset and is commonly used to understand the data in the raw data sources that are used to populate an ABT.",
            "zh": "ä½†æ˜¯ï¼Œæ•°æ®è´¨é‡æŠ¥å‘Šä¹Ÿå¯ç”¨äºæµè§ˆä»»ä½•æ•°æ®é›†ï¼Œå¹¶ä¸”é€šå¸¸ç”¨äºäº†è§£ç”¨äºå¡«å…… ABT çš„åŸå§‹æ•°æ®æºä¸­çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "So what is the actual probability that the patient has the disease?",
            "zh": "é‚£ä¹ˆæ‚£è€…æ‚£ä¸Šè¿™ç§ç–¾ç—…çš„å®é™…æ¦‚ç‡æ˜¯å¤šå°‘å‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The issue was that some levels had multiple representationsâ€”for example, for the REGIONTYPE feature, towns were represented as town and as t. Ross easily corrected this issue by mapping the levels of the feature to one consistent labeling scheme.",
            "zh": "é—®é¢˜åœ¨äºæŸäº›çº§åˆ«å…·æœ‰å¤šä¸ªè¡¨ç¤ºå½¢å¼ï¼Œä¾‹å¦‚ï¼Œå¯¹äº REGIONTYPE ç‰¹å¾ï¼ŒåŸé•‡è¡¨ç¤ºä¸ºåŸé•‡å’Œ tã€‚Ross é€šè¿‡å°†ç‰¹å¾çº§åˆ«æ˜ å°„åˆ°ä¸€ä¸ªä¸€è‡´çš„æ ‡è®°æ–¹æ¡ˆï¼Œè½»æ¾çº æ­£äº†è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, automated approaches to answering this question donâ€™t really exist, and it falls on analysts to understand what a clustering result tells them about a dataset.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œå›ç­”è¿™ä¸ªé—®é¢˜çš„è‡ªåŠ¨åŒ–æ–¹æ³•å¹¶ä¸å­˜åœ¨ï¼Œåˆ†æå¸ˆéœ€è¦äº†è§£èšç±»ç»“æœå¯¹æ•°æ®é›†çš„äº†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.1â€…â€…â€…A dataset that represents the characters in the Guess Who game.",
            "zh": "4.1 è¡¨ç¤ºçŒœçŒœè°æ¸¸æˆä¸­è§’è‰²çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œDick: I guess it looks as if youâ€™re reorganizing your records. What is this though? Chronological?",
            "zh": "â€œè¿ªå…‹ï¼šæˆ‘çŒœä½ å¥½åƒåœ¨é‡æ–°æ•´ç†ä½ çš„è®°å½•ã€‚è¿™æ˜¯ä»€ä¹ˆå‘¢ï¼ŸæŒ‰æ—¶é—´å…ˆåï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "To calculate the ith percentile of the n values of a feature a, we first order the values in ascending order and then multiply n by to determine the index.",
            "zh": "ä¸ºäº†è®¡ç®—ç‰¹å¾ a çš„ n ä¸ªå€¼çš„ç¬¬ i ä¸ªç™¾åˆ†ä½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆæŒ‰å‡åºå¯¹å€¼è¿›è¡Œæ’åºï¼Œç„¶åå°† n ä¹˜ä»¥ä»¥ç¡®å®šæŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that we can use a sequence of matrix operations to implement how a neural network processes a single example can be generalized to processing a number of examples in parallel.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ç³»åˆ—çŸ©é˜µè¿ç®—æ¥å®ç°ç¥ç»ç½‘ç»œå¦‚ä½•å¤„ç†å•ä¸ªç¤ºä¾‹ï¼Œè¿™ä¸€äº‹å®å¯ä»¥æ¨å¹¿åˆ°å¹¶è¡Œå¤„ç†å¤šä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The three closest neighbors to the query are instances d12, d16 and d3.",
            "zh": "æŸ¥è¯¢çš„ä¸‰ä¸ªæœ€è¿‘é‚»å±…æ˜¯å®ä¾‹ d12ã€d16 å’Œ d3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.12",
            "zh": "å›¾ 2.12"
        }
    },
    {
        "translation": {
            "en": "Howard, R. 1960. Dynamic programming and Markov processes. MIT Press.",
            "zh": "éœåå¾·ï¼ŒR. 1960 å¹´ã€‚åŠ¨æ€è§„åˆ’å’Œé©¬å°”å¯å¤«è¿‡ç¨‹ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If a predictive model is to be useful, it must be able to make predictions for queries that are not present in the data.",
            "zh": "å¦‚æœé¢„æµ‹æ¨¡å‹è¦æœ‰ç”¨ï¼Œå®ƒå¿…é¡»èƒ½å¤Ÿå¯¹æ•°æ®ä¸­ä¸å­˜åœ¨çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rewards can also often be somewhat contradictory, and an action that gives an immediate positive reward may turn out to be a bad one in the longer term.",
            "zh": "å¥–åŠ±ä¹Ÿå¸¸å¸¸æœ‰äº›çŸ›ç›¾ï¼Œä»é•¿è¿œæ¥çœ‹ï¼Œç«‹å³ç»™äºˆç§¯æå¥–åŠ±çš„è¡ŒåŠ¨å¯èƒ½ä¼šå˜æˆä¸€ä¸ªç³Ÿç³•çš„è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "13.3â€ƒData Preparation",
            "zh": "13.3 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "The remaining rewards are based on the winnings earned within the game.",
            "zh": "å…¶ä½™å¥–åŠ±åŸºäºåœ¨æ¸¸æˆä¸­è·å¾—çš„å¥–é‡‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Wood, Robert W. 1904. The n-rays. Nature 70: 530â€“531.",
            "zh": "ä¼å¾·ï¼Œç½—ä¼¯ç‰¹ W. 1904 å¹´ã€‚nå°„çº¿ã€‚è‡ªç„¶70ï¼š530-531ã€‚"
        }
    },
    {
        "translation": {
            "en": "third order polynomial function, 766",
            "zh": "ä¸‰é˜¶å¤šé¡¹å¼å‡½æ•°ï¼Œ766"
        }
    },
    {
        "translation": {
            "en": "A linear relationship implies that the target is calculated from the descriptive features using only the addition of the descriptive feature values multiplied by weight values.",
            "zh": "çº¿æ€§å…³ç³»æ„å‘³ç€ä»…ä½¿ç”¨æè¿°æ€§ç‰¹å¾å€¼ä¹˜ä»¥æƒé‡å€¼ç›¸åŠ ï¼Œå³å¯æ ¹æ®æè¿°æ€§ç‰¹å¾è®¡ç®—ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The input gate uses separate paths of information processing to make each of these decisions and then merges the results of these decisions using an elementwise product.",
            "zh": "è¾“å…¥é—¨ä½¿ç”¨å•ç‹¬çš„ä¿¡æ¯å¤„ç†è·¯å¾„æ¥åšå‡ºè¿™äº›å†³ç­–ä¸­çš„æ¯ä¸€ä¸ªï¼Œç„¶åä½¿ç”¨é€å…ƒä¹˜ç§¯åˆå¹¶è¿™äº›å†³ç­–çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "co-presence (CP), how often a true value occurred for the same feature in both the query data q and the data for the comparison user (d1 or d2)",
            "zh": "å…±å­˜ ï¼ˆCPï¼‰ï¼ŒåŒä¸€è¦ç´ åœ¨æŸ¥è¯¢æ•°æ® q å’Œæ¯”è¾ƒç”¨æˆ·ï¼ˆd1 æˆ– d2ï¼‰çš„æ•°æ®ä¸­å‡ºç°çœŸå€¼çš„é¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "Figure 5.8",
            "zh": "å›¾ 5.8"
        }
    },
    {
        "translation": {
            "en": "bagging, 159, 159, 171, 179, 733, 735",
            "zh": "è£…è¢‹ï¼Œ 159ï¼Œ 159ï¼Œ 171ï¼Œ 179ï¼Œ 733ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "The sample space for the domain of two dice.",
            "zh": "ä¸¤ä¸ªéª°å­çš„åŸŸçš„æ ·æœ¬ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The pattern 99,999 also suggests that this is most likely a data entry error or a system default remaining in the ABT.",
            "zh": "æ¨¡å¼ 99,999 è¿˜è¡¨æ˜ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯æ•°æ®è¾“å…¥é”™è¯¯æˆ– ABT ä¸­æ®‹ç•™çš„ç³»ç»Ÿé»˜è®¤å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian score, 293",
            "zh": "è´å¶æ–¯è¯„åˆ†ï¼Œ293"
        }
    },
    {
        "translation": {
            "en": "However, he did notice that the animal had webbed feet and a duck-billed snout.",
            "zh": "ç„¶è€Œï¼Œä»–ç¡®å®æ³¨æ„åˆ°è¿™åªåŠ¨ç‰©æœ‰è¹¼çš„è„šå’Œé¸­å˜´çš„é¼»å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.6353",
            "zh": "0.6353"
        }
    },
    {
        "translation": {
            "en": "Elman, Jeffrey L. 1990. Finding structure in time. Cognitive Science 14 (2): 179â€“211.",
            "zh": "åŸƒå°”æ›¼ï¼Œæ°å¼—é‡Œ L. 1990 å¹´ã€‚åŠæ—¶æ‰¾åˆ°ç»“æ„ã€‚è®¤çŸ¥ç§‘å­¦14ï¼ˆ2ï¼‰ï¼š179-211ã€‚"
        }
    },
    {
        "translation": {
            "en": "We do not correct data quality issues due to valid data unless the predictive models we will use the data in the ABT to train require that particular data quality issues be corrected.",
            "zh": "æˆ‘ä»¬ä¸ä¼šçº æ­£ç”±äºæœ‰æ•ˆæ•°æ®è€Œå¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜ï¼Œé™¤éæˆ‘ä»¬å°†ä½¿ç”¨ ABT ä¸­çš„æ•°æ®è¿›è¡Œè®­ç»ƒçš„é¢„æµ‹æ¨¡å‹éœ€è¦çº æ­£ç‰¹å®šçš„æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "To achieve this a reward structure has been designed.",
            "zh": "ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè®¾è®¡äº†ä¸€ç§å¥–åŠ±ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Friedman, Jerome H. 2001. Greedy function approximation: A gradient boosting machine. Annals of Statistics 21 (5): 1189â€“1232.",
            "zh": "å¼—é‡Œå¾·æ›¼ï¼Œæ°ç½—å§† H. 2001 å¹´ã€‚è´ªå©ªå‡½æ•°è¿‘ä¼¼ï¼šæ¢¯åº¦æå‡æœºã€‚ç»Ÿè®¡å¹´é‰´21ï¼ˆ5ï¼‰ï¼š1189-1232ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.1828",
            "zh": "0.1828"
        }
    },
    {
        "translation": {
            "en": "Table 14.2",
            "zh": "è¡¨ 14.2"
        }
    },
    {
        "translation": {
            "en": "Table 4.5",
            "zh": "è¡¨ 4.5"
        }
    },
    {
        "translation": {
            "en": "The simple version of gradient boosting described here can be extended in many ways.",
            "zh": "æ­¤å¤„æè¿°çš„æ¢¯åº¦æå‡çš„ç®€å•ç‰ˆæœ¬å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è¿›è¡Œæ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This illustrates how two different models that are both consistent with a dataset can make different generalizations.12 So, which feature selection metric should be used, information gain or information gain ratio?",
            "zh": "è¿™è¯´æ˜äº†ä¸¤ä¸ªä¸æ•°æ®é›†ä¸€è‡´çš„ä¸åŒæ¨¡å‹å¦‚ä½•è¿›è¡Œä¸åŒçš„æ³›åŒ–.12é‚£ä¹ˆï¼Œåº”è¯¥ä½¿ç”¨å“ªç§ç‰¹å¾é€‰æ‹©æŒ‡æ ‡ï¼Œä¿¡æ¯å¢ç›Šè¿˜æ˜¯ä¿¡æ¯å¢ç›Šæ¯”ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the final logistic regression model on the large hold-out test set (classification accuracy: 87.979%, average class accuracy: 67.305%).",
            "zh": "å¤§å‹ä¿æŒæ£€éªŒé›†ä¸Šæœ€ç»ˆé€»è¾‘å›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š87.979%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š67.305%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "PSFMAG_U/G/R/I/Z",
            "zh": "PSFMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "false",
            "zh": "å‡"
        }
    },
    {
        "translation": {
            "en": "The definition would be used to identify churn events in ATâ€™s historical data and, consequently, was fundamental to building the ABT for the project.",
            "zh": "è¯¥å®šä¹‰å°†ç”¨äºè¯†åˆ« AT å†å²æ•°æ®ä¸­çš„æµå¤±äº‹ä»¶ï¼Œå› æ­¤å¯¹äºä¸ºé¡¹ç›®æ„å»º ABT è‡³å…³é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The design of model evaluation experiments is an example of the application of techniques from the larger discipline of experimental design, which is used extensively in the manufacturing industry amongst others. Montgomery (2012) is an excellent reference for this topic and well worth reading.",
            "zh": "æ¨¡å‹è¯„ä¼°å®éªŒçš„è®¾è®¡æ˜¯åº”ç”¨å®éªŒè®¾è®¡è¿™ä¸€æ›´å¤§å­¦ç§‘çš„æŠ€æœ¯çš„ä¸€ä¸ªä¾‹å­ï¼Œè¯¥å­¦ç§‘åœ¨åˆ¶é€ ä¸šç­‰é¢†åŸŸè¢«å¹¿æ³›ä½¿ç”¨ã€‚Montgomeryï¼ˆ2012ï¼‰æ˜¯è¯¥ä¸»é¢˜çš„æå¥½å‚è€ƒï¼Œéå¸¸å€¼å¾—ä¸€è¯»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the weight matrices do not change shape, nor does the sequence of operations, and the activation functions Ï† are still applied elementwise to all the elements in z matrices.",
            "zh": "è¯·æ³¨æ„ï¼Œæƒé‡çŸ©é˜µä¸ä¼šæ”¹å˜å½¢çŠ¶ï¼Œæ“ä½œé¡ºåºä¹Ÿä¸ä¼šæ”¹å˜ï¼Œå¹¶ä¸”æ¿€æ´»å‡½æ•°Ï†ä»æŒ‰å…ƒç´ åº”ç”¨äº z çŸ©é˜µä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are typically used in situations where a Minkowski distance is not appropriate.",
            "zh": "è¿™äº›é€šå¸¸ç”¨äºé—µå¯å¤«æ–¯åŸºè·ç¦»ä¸åˆé€‚çš„æƒ…å†µä¸‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Like every telecommunications company, AT struggles with customer churnâ€”customers leaving AT for other mobile phone operators.",
            "zh": "ä¸æ¯å®¶ç”µä¿¡å…¬å¸ä¸€æ ·ï¼ŒATä¹Ÿåœ¨åŠªåŠ›åº”å¯¹å®¢æˆ·æµå¤±é—®é¢˜ï¼Œå³å®¢æˆ·å°†ATç•™ç»™å…¶ä»–ç§»åŠ¨ç”µè¯è¿è¥å•†ã€‚"
        }
    },
    {
        "translation": {
            "en": "To facilitate its use in these different contexts, the book has been designed to be modularâ€”with very few dependencies between chapters.",
            "zh": "ä¸ºäº†ä¾¿äºåœ¨è¿™äº›ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨ï¼Œæœ¬ä¹¦è¢«è®¾è®¡ä¸ºæ¨¡å—åŒ–çš„ï¼Œç« èŠ‚ä¹‹é—´çš„ä¾èµ–å…³ç³»éå¸¸å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the company approached him with a business problemâ€”reducing customer churn.",
            "zh": "ç›¸åï¼Œè¯¥å…¬å¸å‘ä»–æå‡ºäº†ä¸€ä¸ªä¸šåŠ¡é—®é¢˜â€”â€”å‡å°‘å®¢æˆ·æµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "While complex scientific scenarios can make this process more difficult than is the case for more typical business applications, there is also the advantage that scientific projects typically produce publications clearly explaining their work.",
            "zh": "è™½ç„¶å¤æ‚çš„ç§‘å­¦åœºæ™¯å¯èƒ½ä¼šä½¿è¿™ä¸ªè¿‡ç¨‹æ¯”æ›´å…¸å‹çš„ä¸šåŠ¡åº”ç”¨ç¨‹åºæ›´åŠ å›°éš¾ï¼Œä½†è¿˜æœ‰ä¸€ä¸ªä¼˜åŠ¿ï¼Œå³ç§‘å­¦é¡¹ç›®é€šå¸¸ä¼šäº§ç”Ÿæ¸…æ¥šåœ°è§£é‡Šå…¶å·¥ä½œçš„å‡ºç‰ˆç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.1â€ƒIntelligent Agents",
            "zh": "11.2.1 æ™ºèƒ½ä»£ç†"
        }
    },
    {
        "translation": {
            "en": "After approximately 150 epochs the rate of decrease of the sum of squared errors increases, but training also becomes a bit unstable with the sum of squared errors of the network sometimes increasing and decreasing dramatically.",
            "zh": "å¤§çº¦150ä¸ªå‘¨æœŸåï¼Œå¹³æ–¹è¯¯å·®å’Œçš„å‡å°‘ç‡å¢åŠ ï¼Œä½†è®­ç»ƒä¹Ÿå˜å¾—æœ‰ç‚¹ä¸ç¨³å®šï¼Œç½‘ç»œçš„å¹³æ–¹è¯¯å·®æ€»å’Œæœ‰æ—¶ä¼šæ€¥å‰§å¢åŠ å’Œå‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "This observation is the basis for a number of weight initialization regimes that adjust the variance of the distribution used to sample the weights for a neuron based on its connections to other neurons in the network.",
            "zh": "è¿™ä¸€è§‚å¯Ÿç»“æœæ˜¯è®¸å¤šæƒé‡åˆå§‹åŒ–æ–¹æ¡ˆçš„åŸºç¡€ï¼Œè¿™äº›æ–¹æ¡ˆæ ¹æ®ç¥ç»å…ƒä¸ç½‘ç»œä¸­å…¶ä»–ç¥ç»å…ƒçš„è¿æ¥æ¥è°ƒæ•´ç”¨äºå¯¹ç¥ç»å…ƒçš„æƒé‡è¿›è¡Œé‡‡æ ·çš„åˆ†å¸ƒæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Corruption Perception Index, 237, 294",
            "zh": "æ¸…å»‰æŒ‡æ•°ï¼Œ 237ï¼Œ 294"
        }
    },
    {
        "translation": {
            "en": "DropMask, 530",
            "zh": "æ»´é¢è†œï¼Œ530"
        }
    },
    {
        "translation": {
            "en": "F1 score, 549",
            "zh": "F1å¾—åˆ†ï¼Œ549"
        }
    },
    {
        "translation": {
            "en": "This is an example of using a state generation function as discussed in Section 11.2[638].",
            "zh": "è¿™æ˜¯ä½¿ç”¨çŠ¶æ€ç”Ÿæˆå‡½æ•°çš„ç¤ºä¾‹ï¼Œå¦‚ç¬¬ 11.2 èŠ‚[638]æ‰€è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having a dominant target level, like the elliptical target level in this example, means that models trained on this data can overcompensate for the majority target level and ignore the minority ones.",
            "zh": "å…·æœ‰ä¸»å¯¼ç›®æ ‡æ°´å¹³ï¼ˆå¦‚æœ¬ä¾‹ä¸­çš„æ¤­åœ†ç›®æ ‡æ°´å¹³ï¼‰æ„å‘³ç€åœ¨æ­¤æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å¯ä»¥è¿‡åº¦è¡¥å¿å¤šæ•°ç›®æ ‡æ°´å¹³å¹¶å¿½ç•¥å°‘æ•°ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "top sampling, 92",
            "zh": "é¡¶éƒ¨é‡‡æ ·ï¼Œ92"
        }
    },
    {
        "translation": {
            "en": "Equal-frequency binning does this.",
            "zh": "ç­‰é¢‘åˆå¹¶å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a general rule of thumb, only features that are missing in excess of 60% of their values should be considered for complete removal, and more subtle handling techniques should be used for features missing less data.",
            "zh": "ä½œä¸ºä¸€èˆ¬ç»éªŒæ³•åˆ™ï¼Œåªæœ‰ç¼ºå¤±è¶…è¿‡å…¶å€¼ 60% çš„ç‰¹å¾æ‰åº”è€ƒè™‘å®Œå…¨åˆ é™¤ï¼Œå¹¶ä¸”å¯¹äºç¼ºå°‘è¾ƒå°‘æ•°æ®çš„ç‰¹å¾ï¼Œåº”ä½¿ç”¨æ›´ç²¾ç»†çš„å¤„ç†æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.5â€ƒSummary",
            "zh": "11.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "The following table also shows the distance to these three cluster centers for each instance in the dataset.",
            "zh": "ä¸‹è¡¨è¿˜æ˜¾ç¤ºäº†æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹åˆ°è¿™ä¸‰ä¸ªèšç±»ä¸­å¿ƒçš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The table below shows the predictions made for a continuous target feature by two different prediction models for a test dataset.",
            "zh": "2. ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸¤ç§ä¸åŒçš„é¢„æµ‹æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®é›†çš„è¿ç»­ç›®æ ‡ç‰¹å¾æ‰€åšçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Either way, this instance is likely to be an example of noise in the dataset.",
            "zh": "æ— è®ºå“ªç§æ–¹å¼ï¼Œæ­¤å®ä¾‹éƒ½å¯èƒ½æ˜¯æ•°æ®é›†ä¸­å™ªå£°çš„ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the decision boundaries associated with decision trees have a characteristic stepped appearance because of the way feature values are split in a decision tree, while the decision boundaries associated with k-NN models are noticeably jagged because of their local focus.",
            "zh": "ä¾‹å¦‚ï¼Œç”±äºç‰¹å¾å€¼åœ¨å†³ç­–æ ‘ä¸­çš„åˆ†å‰²æ–¹å¼ï¼Œä¸å†³ç­–æ ‘å…³è”çš„å†³ç­–è¾¹ç•Œå…·æœ‰ç‰¹å¾é˜¶æ¢¯å¤–è§‚ï¼Œè€Œä¸ k-NN æ¨¡å‹å…³è”çš„å†³ç­–è¾¹ç•Œç”±äºå…¶å±€éƒ¨ç„¦ç‚¹è€Œæ˜æ˜¾å‘ˆé”¯é½¿çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "If you donâ€™t understand any of these concepts, see Appendix C[765] for the necessary introduction.",
            "zh": "å¦‚æœæ‚¨ä¸ç†è§£è¿™äº›æ¦‚å¿µä¸­çš„ä»»ä½•ä¸€ä¸ªï¼Œè¯·å‚é˜…é™„å½• C[765] ä»¥è·å–å¿…è¦çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Schapire (1990) desscribed some of the early work on weak learners and computational learning theory.",
            "zh": "Schapireï¼ˆ1990ï¼‰æè¿°äº†ä¸€äº›å…³äºå¼±å­¦ä¹ è€…å’Œè®¡ç®—å­¦ä¹ ç†è®ºçš„æ—©æœŸå·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "5.14â€…â€…â€…(a) The Î¸ represents the inner angle between the vector emanating from the origin to instance d1 and the vector emanating from the origin to instance d2; and (b) shows d1 and d2 normalized to the unit circle.",
            "zh": "5.14 ï¼ˆaï¼‰ Î¸è¡¨ç¤ºä»åŸç‚¹åˆ°å®ä¾‹d1çš„å‘é‡ä¸ä»åŸç‚¹åˆ°å®ä¾‹d2çš„å‘é‡ä¹‹é—´çš„å†…è§’;ï¼ˆbï¼‰ æ˜¾ç¤ºå½’ä¸€åŒ–ä¸ºå•ä½åœ†çš„ d1 å’Œ d2ã€‚"
        }
    },
    {
        "translation": {
            "en": "Since agents using SARSA use a policy with some exploration in their action-value table update equation, they will often base their estimation of expected return on next actions with quite poor return.",
            "zh": "ç”±äºä½¿ç”¨ SARSA çš„ä»£ç†åœ¨å…¶è¡ŒåŠ¨-ä»·å€¼è¡¨æ›´æ–°æ–¹ç¨‹ä¸­ä½¿ç”¨äº†ä¸€äº›æ¢ç´¢çš„ç­–ç•¥ï¼Œå› æ­¤ä»–ä»¬é€šå¸¸ä¼šæ ¹æ®å›æŠ¥ç›¸å½“ä½çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ¥ä¼°è®¡é¢„æœŸå›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Aoife",
            "zh": "å¥¥ä¼Šå¤«"
        }
    },
    {
        "translation": {
            "en": "where hxt is the concatenation of htâˆ’1 and xt; and W(f) is the forget gate matrix of weights. For example, imagine an LSTM unit with the inputs and W(f) matrix (the zeros are the bias terms) as listed in Equation (8.108)[510]",
            "zh": "å…¶ä¸­ hxt æ˜¯ htâˆ’1 å’Œ xt çš„ä¸²è”;Wï¼ˆfï¼‰ æ˜¯æƒé‡çš„é—å¿˜é—¨çŸ©é˜µã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä¸€ä¸ªLSTMå•å…ƒå…·æœ‰è¾“å…¥å’ŒWï¼ˆfï¼‰çŸ©é˜µï¼ˆé›¶ç‚¹æ˜¯åç½®é¡¹ï¼‰ï¼Œå¦‚å…¬å¼ï¼ˆ8.108ï¼‰[510]æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "Some of the bins are very tall and other bins are empty, as indicated by the gaps between the bars.",
            "zh": "ä¸€äº›åƒåœ¾ç®±éå¸¸é«˜ï¼Œè€Œå…¶ä»–åƒåœ¾ç®±æ˜¯ç©ºçš„ï¼Œå¦‚æ æ†ä¹‹é—´çš„é—´éš™æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A high-level schematic of the structure of a neuron. This figure illustrates three interconnected neurons; the middle neuron is highlighted in black, and the major structural components of this neuron are labeled cell body, dendrites, and axon. Also marked are the synapses connecting the axon of one neuron and the dendrite of another, which allow signals to pass between the neurons.",
            "zh": "ç¥ç»å…ƒç»“æ„çš„é«˜çº§ç¤ºæ„å›¾ã€‚è¯¥å›¾è¯´æ˜äº†ä¸‰ä¸ªç›¸äº’è¿æ¥çš„ç¥ç»å…ƒ;ä¸­é—´ç¥ç»å…ƒä»¥é»‘è‰²çªå‡ºæ˜¾ç¤ºï¼Œè¯¥ç¥ç»å…ƒçš„ä¸»è¦ç»“æ„æˆåˆ†è¢«æ ‡è®°ä¸ºç»†èƒä½“ã€æ ‘çªå’Œè½´çªã€‚è¿˜æ ‡è®°äº†è¿æ¥ä¸€ä¸ªç¥ç»å…ƒçš„è½´çªå’Œå¦ä¸€ä¸ªç¥ç»å…ƒçš„æ ‘çªçš„çªè§¦ï¼Œå®ƒä»¬å…è®¸ä¿¡å·åœ¨ç¥ç»å…ƒä¹‹é—´ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. What is predictive data analytics?",
            "zh": "1. ä»€ä¹ˆæ˜¯é¢„æµ‹æ€§æ•°æ®åˆ†æï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "HEALTHDEPSKIDS: How many dependent children are included on the health insurance policy",
            "zh": "HEALTHDEPSKIDSï¼šå¥åº·ä¿é™©å•ä¸­åŒ…æ‹¬å¤šå°‘å—æŠšå…»å­å¥³"
        }
    },
    {
        "translation": {
            "en": "We can, if we wish, sum out more than one feature. For example, we could compute P(h) by summing out all the other features in the dataset:",
            "zh": "å¦‚æœæˆ‘ä»¬æ„¿æ„ï¼Œæˆ‘ä»¬å¯ä»¥æ€»ç»“å‡ºå¤šä¸ªåŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹æ•°æ®é›†ä¸­çš„æ‰€æœ‰å…¶ä»–ç‰¹å¾æ±‚å’Œæ¥è®¡ç®— Pï¼ˆhï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "23. Systems like the Western Electric rules (Montgomery, 2004), used widely in process engineering to detect out-of-control processes, can be useful in this regard.",
            "zh": "23. è¥¿éƒ¨ç”µæ°”è§„åˆ™ï¼ˆMontgomeryï¼Œ2004å¹´ï¼‰ç­‰ç³»ç»Ÿåœ¨è¿‡ç¨‹å·¥ç¨‹ä¸­è¢«å¹¿æ³›ç”¨äºæ£€æµ‹å¤±æ§çš„è¿‡ç¨‹ï¼Œåœ¨è¿™æ–¹é¢æ˜¯æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "local models, 189",
            "zh": "æœ¬åœ°æ¨¡å‹ï¼Œ189"
        }
    },
    {
        "translation": {
            "en": "DQN, 664",
            "zh": "DQNï¼Œ664"
        }
    },
    {
        "translation": {
            "en": "unit hypercube, 224",
            "zh": "å•ä½è¶…ç«‹æ–¹ä½“ï¼Œ224"
        }
    },
    {
        "translation": {
            "en": "If features have missing values, we must first determine why the values are missing.",
            "zh": "å¦‚æœè¦ç´ ç¼ºå°‘å€¼ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆç¡®å®šç¼ºå°‘å€¼çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, no matter how long we train the network, Neuron 4 will remain in this dead state.",
            "zh": "å› æ­¤ï¼Œæ— è®ºæˆ‘ä»¬è®­ç»ƒç½‘ç»œå¤šé•¿æ—¶é—´ï¼ŒNeuron 4 éƒ½å°†ä¿æŒè¿™ç§æ­»çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The only knowledge an agent using temporal-difference learning requires is a list of states that exist in the environment, a way to recognize what state it is in, and a list of the actions that it is possible for the agent to take.",
            "zh": "ä½¿ç”¨æ—¶å·®å­¦ä¹ çš„æ™ºèƒ½ä½“éœ€è¦çš„å”¯ä¸€çŸ¥è¯†æ˜¯ç¯å¢ƒä¸­å­˜åœ¨çš„çŠ¶æ€åˆ—è¡¨ã€è¯†åˆ«å…¶å¤„äºä½•ç§çŠ¶æ€çš„æ–¹æ³•ä»¥åŠæ™ºèƒ½ä½“å¯èƒ½é‡‡å–çš„æ“ä½œåˆ—è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "directed cyclic graph, 499",
            "zh": "æœ‰å‘å¾ªç¯å›¾ï¼Œ499"
        }
    },
    {
        "translation": {
            "en": "A dataset that includes office rental prices and a number of descriptive features for 10 Dublin city-center offices.",
            "zh": "ä¸€ä¸ªæ•°æ®é›†ï¼ŒåŒ…æ‹¬éƒ½æŸæ—å¸‚ä¸­å¿ƒ 10 ä¸ªåŠå…¬å®¤çš„åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼å’Œä¸€äº›æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Models that either underfit or overfit do not generalize well and so will not be able to make good predictions for query instances beyond the content of the training dataset.",
            "zh": "æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆçš„æ¨¡å‹ä¸èƒ½å¾ˆå¥½åœ°æ³›åŒ–ï¼Œå› æ­¤æ— æ³•å¯¹è®­ç»ƒæ•°æ®é›†å†…å®¹ä¹‹å¤–çš„æŸ¥è¯¢å®ä¾‹åšå‡ºè‰¯å¥½çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.2â€…â€…â€…Gradient Descent",
            "zh": "7.3.2 æ¢¯åº¦ä¸‹é™"
        }
    },
    {
        "translation": {
            "en": "The problem is caused by features having different variance.",
            "zh": "è¯¥é—®é¢˜æ˜¯ç”±å…·æœ‰ä¸åŒæ–¹å·®çš„ç‰¹å¾å¼•èµ·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are also sensitive to the presence of redundant and irrelevant descriptive features in training data.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®ä¸­æ˜¯å¦å­˜åœ¨å†—ä½™å’Œä¸ç›¸å…³çš„æè¿°æ€§ç‰¹å¾ä¹Ÿå¾ˆæ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "We completed the data quality plan by including these potential handling strategies. The final data quality plan is shown in Table 3.6[72]. Together with the data quality report, these are the outputs of the data exploration work for the motor insurance fraud detection project.",
            "zh": "æˆ‘ä»¬é€šè¿‡åŒ…æ‹¬è¿™äº›æ½œåœ¨çš„å¤„ç†ç­–ç•¥æ¥å®Œæˆæ•°æ®è´¨é‡è®¡åˆ’ã€‚æœ€ç»ˆçš„æ•°æ®è´¨é‡è®¡åˆ’å¦‚è¡¨3.6æ‰€ç¤º[72]ã€‚ä¸æ•°æ®è´¨é‡æŠ¥å‘Šä¸€èµ·ï¼Œè¿™äº›æ˜¯æ±½è½¦ä¿é™©æ¬ºè¯ˆæ£€æµ‹é¡¹ç›®æ•°æ®æ¢ç´¢å·¥ä½œçš„æˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "For our example we apply range normalization to both the descriptive features and the target feature. Note that for range normalization of the features we need the minimum and maximum values for each feature. Table 8.2[423] lists these values for the original complete dataset20 (as distinct from our sample of four examples). Table 8.3[423] lists the examples after the features have been range-normalized into the range [0,1].",
            "zh": "åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†èŒƒå›´å½’ä¸€åŒ–åº”ç”¨äºæè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ã€‚è¯·æ³¨æ„ï¼Œå¯¹äºè¦ç´ çš„èŒƒå›´å½’ä¸€åŒ–ï¼Œæˆ‘ä»¬éœ€è¦æ¯ä¸ªè¦ç´ çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚è¡¨ 8.2[423] åˆ—å‡ºäº†åŸå§‹å®Œæ•´æ•°æ®é›† 20 çš„è¿™äº›å€¼ï¼ˆä¸æˆ‘ä»¬çš„å››ä¸ªç¤ºä¾‹æ ·æœ¬ä¸åŒï¼‰ã€‚è¡¨ 8.3[423] åˆ—å‡ºäº†å°†ç‰¹å¾å½’ä¸€åŒ–ä¸ºèŒƒå›´ [0,1] åçš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "guard",
            "zh": "è­¦å«"
        }
    },
    {
        "translation": {
            "en": "(a) The company has decided to use a similarity-based model to implement the recommender system. Which of the following three similarity indexes do you think the system should be based on?",
            "zh": "ï¼ˆaï¼‰ å…¬å¸å†³å®šä½¿ç”¨åŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹æ¥å®æ–½æ¨èç³»ç»Ÿã€‚æ‚¨è®¤ä¸ºç³»ç»Ÿåº”è¯¥åŸºäºä»¥ä¸‹ä¸‰ä¸ªç›¸ä¼¼æ€§æŒ‡æ•°ä¸­çš„å“ªä¸€ä¸ªï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "cumulative lift curve, 570",
            "zh": "ç´¯ç§¯æå‡æ›²çº¿ï¼Œ570"
        }
    },
    {
        "translation": {
            "en": "random sampling without replacement, 94",
            "zh": "æ— æ›¿æ¢çš„éšæœºæŠ½æ ·ï¼Œ94"
        }
    },
    {
        "translation": {
            "en": "The number of instances in the training set and the number of weights for which we need to find values simply make the problem too large.",
            "zh": "è®­ç»ƒé›†ä¸­çš„å®ä¾‹æ•°å’Œæˆ‘ä»¬éœ€è¦æŸ¥æ‰¾å€¼çš„æƒé‡æ•°åªä¼šä½¿é—®é¢˜å˜å¾—å¤ªå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Careful examination of the workings of the different classification models that we have discussed in Chapters 4[117] to 7[311] shows that none of them simply produces a target feature level as its output.",
            "zh": "ä»”ç»†ç ”ç©¶æˆ‘ä»¬åœ¨ç¬¬ 4 ç« [117] è‡³ 7[311] ä¸­è®¨è®ºçš„ä¸åŒåˆ†ç±»æ¨¡å‹çš„å·¥ä½œåŸç†è¡¨æ˜ï¼Œå®ƒä»¬éƒ½æ²¡æœ‰ç®€å•åœ°äº§ç”Ÿç›®æ ‡ç‰¹å¾çº§åˆ«ä½œä¸ºå…¶è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the first row in Z(1) contains the weighted sum for Neuron 3 (i.e., z3) for d1, d2, d3, and d4, respectively.",
            "zh": "ä¾‹å¦‚ï¼ŒZï¼ˆ1ï¼‰ ä¸­çš„ç¬¬ä¸€è¡Œåˆ†åˆ«åŒ…å«ç¥ç»å…ƒ 3ï¼ˆå³ z3ï¼‰å¯¹ d1ã€d2ã€d3 å’Œ d4 çš„åŠ æƒå’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The set of domain concepts for the Acme Telephonica customer churn prediction problem.",
            "zh": "Acme Telephonica å®¢æˆ·æµå¤±é¢„æµ‹é—®é¢˜çš„åŸŸæ¦‚å¿µé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Multiplying any matrix by the identity matrix leaves the original matrix unchangedâ€”this is the equivalent of multiplying by 1 for real numbers.",
            "zh": "å°†ä»»ä½•çŸ©é˜µä¹˜ä»¥å•ä½çŸ©é˜µä¼šä½¿åŸå§‹çŸ©é˜µä¿æŒä¸å˜ï¼Œè¿™ç›¸å½“äºå°†å®æ•°ä¹˜ä»¥ 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.7(c)[754] illustrates the density histogram of the TRAINING EXPENSES feature using ten 200-unit intervals, and Figure A.7(d)[754] illustrates the density histogram using four 500-unit intervals.",
            "zh": "å›¾ A.7ï¼ˆcï¼‰[754] ä½¿ç”¨åä¸ª 200 å•ä½é—´éš”è¯´æ˜äº†è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œå›¾ A.7ï¼ˆdï¼‰[754] è¯´æ˜äº†ä½¿ç”¨å››ä¸ª 500 å•ä½é—´éš”çš„å¯†åº¦ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "More formally, for a network with three nodes x1,x2,x3, using a predefined node selection order of x1,x2,x3,x1,â€¦ and assuming that at iteration Ï„ each node has the values , the next four states generated will be",
            "zh": "æ›´æ­£å¼åœ°è¯´ï¼Œå¯¹äºå…·æœ‰ä¸‰ä¸ªèŠ‚ç‚¹ x1ï¼Œx2ï¼Œx3 çš„ç½‘ç»œï¼Œä½¿ç”¨é¢„å®šä¹‰çš„èŠ‚ç‚¹é€‰æ‹©é¡ºåº x1ï¼Œx2ï¼Œx3ï¼Œx1,...å‡è®¾åœ¨è¿­ä»£ Ï„ æ—¶æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ çš„å€¼ï¼Œæ¥ä¸‹æ¥ç”Ÿæˆçš„å››ä¸ªçŠ¶æ€å°†æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Although the ABT is the key structure that we use in developing machine learning models, data in organizations is rarely kept in neat tables ready to be used to build predictive models. Instead, we need to construct the ABT from the raw data sources that are available in an organization. These may be very diverse in nature. Figure 2.1[29] illustrates some of the different data sources that are typically combined to create an ABT.",
            "zh": "å°½ç®¡ ABT æ˜¯æˆ‘ä»¬ç”¨äºå¼€å‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„å…³é”®ç»“æ„ï¼Œä½†ç»„ç»‡ä¸­çš„æ•°æ®å¾ˆå°‘ä¿å­˜åœ¨æ•´æ´çš„è¡¨æ ¼ä¸­ï¼Œä»¥ä¾¿ç”¨äºæ„å»ºé¢„æµ‹æ¨¡å‹ã€‚ç›¸åï¼Œæˆ‘ä»¬éœ€è¦ä»ç»„ç»‡ä¸­å¯ç”¨çš„åŸå§‹æ•°æ®æºæ„å»º ABTã€‚è¿™äº›åœ¨æ€§è´¨ä¸Šå¯èƒ½éå¸¸å¤šæ ·åŒ–ã€‚å›¾ 2.1[29] è¯´æ˜äº†é€šå¸¸ç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»º ABT çš„ä¸€äº›ä¸åŒæ•°æ®æºã€‚"
        }
    },
    {
        "translation": {
            "en": "McGrayne (2011) is an accessible book on the development and history of Bayesâ€™ Theorem. All data analysts should have at least one good textbook on statistics and probability. We would recommend either Montgomery and Runger (2010) or Tijms (2012) (or both). Jaynes (2003) deals with the use of probability theory in science and is a suitable text for postgraduate students.",
            "zh": "McGrayne ï¼ˆ2011ï¼‰ æ˜¯ä¸€æœ¬å…³äºè´å¶æ–¯å®šç†å‘å±•å’Œå†å²çš„é€šä¿—æ˜“æ‡‚çš„ä¹¦ã€‚æ‰€æœ‰æ•°æ®åˆ†æå¸ˆéƒ½åº”è¯¥è‡³å°‘æœ‰ä¸€æœ¬å…³äºç»Ÿè®¡å’Œæ¦‚ç‡çš„å¥½æ•™ç§‘ä¹¦ã€‚æˆ‘ä»¬æ¨èMontgomeryå’ŒRungerï¼ˆ2010ï¼‰æˆ–Tijmsï¼ˆ2012ï¼‰ï¼ˆæˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹ï¼‰ã€‚Jaynesï¼ˆ2003ï¼‰æ¶‰åŠæ¦‚ç‡è®ºåœ¨ç§‘å­¦ä¸­çš„åº”ç”¨ï¼Œæ˜¯ä¸€æœ¬é€‚åˆç ”ç©¶ç”Ÿçš„æ•™æã€‚"
        }
    },
    {
        "translation": {
            "en": "total sum of squares, 578",
            "zh": "å¹³æ–¹æ€»å’Œï¼Œ578"
        }
    },
    {
        "translation": {
            "en": "4.4.5.3â€ƒGradient boostingâ€ƒGradient boosting is a more recently developed, and very effective, algorithm for training ensemble models using boosting.",
            "zh": "4.4.5.3 æ¢¯åº¦æå‡ æ¢¯åº¦æå‡æ˜¯æœ€è¿‘å¼€å‘çš„ä¸€ç§éå¸¸æœ‰æ•ˆçš„ç®—æ³•ï¼Œç”¨äºä½¿ç”¨æå‡æ¥è®­ç»ƒé›†æˆæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.4[390] illustrates the structure of a basic artificial neural network.",
            "zh": "å›¾8.4[390]è¯´æ˜äº†åŸºæœ¬äººå·¥ç¥ç»ç½‘ç»œçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Struggling to entertain his daughter one afternoon, Mr. Murphy asked little Abigail to tidy them up.",
            "zh": "ä¸€å¤©ä¸‹åˆï¼Œå¢¨è²å…ˆç”ŸåŠªåŠ›æ‹›å¾…å¥³å„¿ï¼Œè®©å°é˜¿æ¯”ç›–å°”æ”¶æ‹¾ä»–ä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "reward hypothesis, 640",
            "zh": "å¥–åŠ±å‡è¯´ï¼Œ640"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(b)[151] depicts one of the extremes for grouping these instances, in which we treat them all as belonging to one partition.",
            "zh": "å›¾ 4.15ï¼ˆbï¼‰[151] æè¿°äº†å¯¹è¿™äº›å®ä¾‹è¿›è¡Œåˆ†ç»„çš„æç«¯æƒ…å†µä¹‹ä¸€ï¼Œå…¶ä¸­æˆ‘ä»¬å°†å®ƒä»¬å…¨éƒ¨è§†ä¸ºå±äºä¸€ä¸ªåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "495.76MW",
            "zh": "495.76å…†ç“¦"
        }
    },
    {
        "translation": {
            "en": "7.7â€…â€…â€…Plots of the journeys made across the error surface for the simple office rentals prediction problem for different learning rates: (a) a very small learning rate (0.002); (b) a medium learning rate (0.08); and (c) a very large learning rate (0.18). The changing sum of squared errors are also shown.",
            "zh": "7.7 ä¸åŒå­¦ä¹ ç‡çš„ç®€å•åŠå…¬å®¤ç§Ÿèµé¢„æµ‹é—®é¢˜åœ¨è¯¯å·®é¢ä¸Šçš„æ—…ç¨‹å›¾ï¼šï¼ˆaï¼‰å­¦ä¹ ç‡éå¸¸å°ï¼ˆ0.002ï¼‰;ï¼ˆbï¼‰ä¸­ç­‰å­¦ä¹ ç‡ï¼ˆ0.08ï¼‰;ï¼ˆcï¼‰éå¸¸é«˜çš„å­¦ä¹ ç‡ï¼ˆ0.18ï¼‰ã€‚è¿˜æ˜¾ç¤ºäº†å¹³æ–¹è¯¯å·®çš„å˜åŒ–å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "37. This example of predicting recidivism is based on a real application of machine learning: parole boards do rely on machine learning prediction models to help them when they are making their decisions. See Berk and Bleich (2013) for a recent comparison of different machine learning models used for this task. Datasets dealing with prisoner recidivism are available online, for example, catalog.data.gov/dataset/prisoner-recidivism/. The dataset presented here is not based on real data.",
            "zh": "37. è¿™ä¸ªé¢„æµ‹ç´¯çŠ¯çš„ä¾‹å­æ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„å®é™…åº”ç”¨ï¼šå‡é‡Šå§”å‘˜ä¼šç¡®å®ä¾é æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹æ¥å¸®åŠ©ä»–ä»¬åšå‡ºå†³å®šã€‚å‚è§Berk and Bleich ï¼ˆ2013ï¼‰ æœ€è¿‘å¯¹ç”¨äºæ­¤ä»»åŠ¡çš„ä¸åŒæœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¯”è¾ƒã€‚ä¾‹å¦‚ï¼Œcatalog.data.gov/dataset/prisoner-recidivism/ å¯ä»¥åœ¨çº¿è·å¾—æœ‰å…³å›šçŠ¯ç´¯çŠ¯çš„æ•°æ®é›†ã€‚è¿™é‡Œä»‹ç»çš„æ•°æ®é›†ä¸æ˜¯åŸºäºçœŸå®æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.5",
            "zh": "è¡¨ 9.5"
        }
    },
    {
        "translation": {
            "en": "(2008) suggest that a potential explanation for this pattern of results is that boosted ensembles are prone to overfitting, and in domains with large numbers of features, overfitting becomes a serious problem.",
            "zh": "ï¼ˆ2008ï¼‰è®¤ä¸ºï¼Œå¯¹è¿™ç§ç»“æœæ¨¡å¼çš„ä¸€ä¸ªæ½œåœ¨è§£é‡Šæ˜¯ï¼Œå¢å¼ºé›†æˆå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆï¼Œè€Œåœ¨å…·æœ‰å¤§é‡ç‰¹å¾çš„é¢†åŸŸä¸­ï¼Œè¿‡æ‹Ÿåˆæˆä¸ºä¸€ä¸ªä¸¥é‡çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "policy, 641, 643, 676",
            "zh": "æ”¿ç­–ï¼Œ 641ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset. Usually this is done either to divide a dataset into clusters of similar examples, or to generate new features that can be appended to a dataset.",
            "zh": "åœ¨æ²¡æœ‰ç›®æ ‡ç‰¹å¾çš„æƒ…å†µä¸‹ä½¿ç”¨æ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¹¶å¯¹æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾ä¸­çš„åº•å±‚ç»“æ„è¿›è¡Œå»ºæ¨¡ã€‚é€šå¸¸ï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå…·æœ‰ç›¸ä¼¼ç¤ºä¾‹çš„èšç±»ï¼Œæˆ–è€…ç”Ÿæˆå¯è¿½åŠ åˆ°æ•°æ®é›†çš„æ–°ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Confusion matrices for the set of predictions shown in Table 9.11[557] using (a) a prediction score threshold of 0.75 and (b) a prediction score threshold of 0.25.",
            "zh": "è¡¨ 9.11[557] æ‰€ç¤ºçš„ä¸€ç»„é¢„æµ‹çš„æ··æ·†çŸ©é˜µï¼Œä½¿ç”¨ ï¼ˆaï¼‰ é¢„æµ‹åˆ†æ•°é˜ˆå€¼ä¸º 0.75 å’Œ ï¼ˆbï¼‰ é¢„æµ‹åˆ†æ•°é˜ˆå€¼ä¸º 0.25ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another approach used to determine the appropriate burn-in time is to start several Markov chains with different initial states and wait until all the chains are generating states with similar distribution characteristics (mean state, mode state, etc.).",
            "zh": "ç”¨äºç¡®å®šé€‚å½“è€åŒ–æ—¶é—´çš„å¦ä¸€ç§æ–¹æ³•æ˜¯å¯åŠ¨å‡ ä¸ªå…·æœ‰ä¸åŒåˆå§‹çŠ¶æ€çš„é©¬å°”å¯å¤«é“¾ï¼Œå¹¶ç­‰å¾…æ‰€æœ‰é“¾ç”Ÿæˆå…·æœ‰ç›¸ä¼¼åˆ†å¸ƒç‰¹å¾ï¼ˆå¹³å‡çŠ¶æ€ã€æ¨¡å¼çŠ¶æ€ç­‰ï¼‰çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "where w[j] is the weight associated with descriptive feature d[j].",
            "zh": "å…¶ä¸­w[j]æ˜¯ä¸æè¿°æ€§ç‰¹å¾d[j]ç›¸å…³çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.2[711] shows an extract from this data quality report.",
            "zh": "è¡¨13.2[711]æ˜¾ç¤ºäº†æ­¤æ•°æ®è´¨é‡æŠ¥å‘Šçš„æ‘˜å½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This assumption allows a naive Bayes model to radically reduce the number of probabilities it requires, resulting in a very compact, highly factored representation of a domain.",
            "zh": "è¿™ä¸ªå‡è®¾å…è®¸æœ´ç´ è´å¶æ–¯æ¨¡å‹ä»æ ¹æœ¬ä¸Šå‡å°‘å®ƒæ‰€éœ€çš„æ¦‚ç‡æ•°ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªéå¸¸ç´§å‡‘ã€é«˜åº¦åˆ†è§£çš„åŸŸè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.3",
            "zh": "å›¾ 7.3"
        }
    },
    {
        "translation": {
            "en": "-0.2843",
            "zh": "-0.2843"
        }
    },
    {
        "translation": {
            "en": "Artificial neural networks are some of the most powerful machine learning models, able to learn complex non-linear mappings from inputs to outputs.",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œæ˜¯ä¸€äº›æœ€å¼ºå¤§çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿå­¦ä¹ ä»è¾“å…¥åˆ°è¾“å‡ºçš„å¤æ‚éçº¿æ€§æ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm then iteratively generates samples by changing the value of one of the non-evidence nodes.",
            "zh": "ç„¶åï¼Œè¯¥ç®—æ³•é€šè¿‡æ›´æ”¹å…¶ä¸­ä¸€ä¸ªéè¯æ®èŠ‚ç‚¹çš„å€¼æ¥è¿­ä»£ç”Ÿæˆæ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just as we might be more excited about receiving a gift of $100 today than a promise to receive a gift of $100 in a yearâ€™s time, it is reasonable when calculating expected return to pay more attention to the immediate reward we expect to receive from taking the next action than to the rewards that we expect to receive in 10 or even 100 actionsâ€™ time.",
            "zh": "æ­£å¦‚æˆ‘ä»¬ä»Šå¤©æ”¶åˆ° 100 ç¾å…ƒçš„ç¤¼ç‰©å¯èƒ½æ¯”æ‰¿è¯ºåœ¨ä¸€å¹´å†…æ”¶åˆ° 100 ç¾å…ƒçš„ç¤¼ç‰©æ›´å…´å¥‹ä¸€æ ·ï¼Œåœ¨è®¡ç®—é¢„æœŸå›æŠ¥æ—¶ï¼Œæˆ‘ä»¬æ›´å…³æ³¨æˆ‘ä»¬æœŸæœ›ä»é‡‡å–ä¸‹ä¸€ä¸ªè¡ŒåŠ¨ä¸­è·å¾—çš„å³æ—¶å¥–åŠ±ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬æœŸæœ›åœ¨ 10 æ¬¡ç”šè‡³ 100 æ¬¡è¡ŒåŠ¨åæ”¶åˆ°çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, the version of the classic Lunar Lander video game shown in Figure 11.7[669].26 In this game the player must land the spacecraft on the Moonâ€™s surface without damaging it.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘å›¾11.7[669]æ‰€ç¤ºçš„ç»å…¸æœˆçƒç€é™†å™¨è§†é¢‘æ¸¸æˆçš„ç‰ˆæœ¬.26åœ¨è¿™ä¸ªæ¸¸æˆä¸­ï¼Œç©å®¶å¿…é¡»åœ¨ä¸æŸåæœˆçƒè¡¨é¢çš„æƒ…å†µä¸‹å°†èˆªå¤©å™¨é™è½åœ¨æœˆçƒè¡¨é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Either way, it is joined to the current node with a branch labeled with the appropriate level of the selected feature.",
            "zh": "æ— è®ºé‡‡ç”¨å“ªç§æ–¹å¼ï¼Œå®ƒéƒ½ä¼šé€šè¿‡æ ‡æœ‰æ‰€é€‰è¦ç´ ç›¸åº”çº§åˆ«çš„åˆ†æ”¯è¿æ¥åˆ°å½“å‰èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Î± is the learning rate hyper-parameter and has the same function as the learning rate in gradient descent.13 This equation states that the updated weight after processing a training example is equal to the weight used to process the training example minus Î± times the sensitivity of the error of the network with respect to changes in the weight.",
            "zh": "å…¶ä¸­ Î± æ˜¯å­¦ä¹ ç‡è¶…å‚æ•°ï¼Œä¸æ¢¯åº¦ä¸‹é™ä¸­çš„å­¦ä¹ ç‡å…·æœ‰ç›¸åŒçš„å‡½æ•°.13 è¯¥ç­‰å¼æŒ‡å‡ºï¼Œå¤„ç†è®­ç»ƒç¤ºä¾‹åçš„æ›´æ–°æƒé‡ç­‰äºç”¨äºå¤„ç†è®­ç»ƒç¤ºä¾‹çš„æƒé‡å‡å»ç½‘ç»œè¯¯å·®å¯¹æƒé‡å˜åŒ–çš„æ•æ„Ÿåº¦çš„ Î± å€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, in a reinforcement learning scenario, an agent inhabiting an environment attempts to achieve a goal by taking a sequence of actions to move it between states.",
            "zh": "æ€»ä¹‹ï¼Œåœ¨å¼ºåŒ–å­¦ä¹ åœºæ™¯ä¸­ï¼Œå±…ä½åœ¨ç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“è¯•å›¾é€šè¿‡é‡‡å–ä¸€ç³»åˆ—æ“ä½œåœ¨çŠ¶æ€ä¹‹é—´ç§»åŠ¨ç›®æ ‡æ¥å®ç°ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The x-y plane is known as a weight space, and the surface is known as an error surface.",
            "zh": "x-y å¹³é¢ç§°ä¸ºæƒé‡ç©ºé—´ï¼Œæ›²é¢ç§°ä¸ºè¯¯å·®æ›²é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "To train a recurrent neural network using backpropagation through time, we first do a forward pass by presenting each input in the sequence in turn and unrolling the network through time (as shown in Figure 8.38[504]).",
            "zh": "ä¸ºäº†ä½¿ç”¨éšæ—¶é—´åå‘ä¼ æ’­æ¥è®­ç»ƒé€’å½’ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¾æ¬¡å‘ˆç°åºåˆ—ä¸­çš„æ¯ä¸ªè¾“å…¥å¹¶éšæ—¶é—´å±•å¼€ç½‘ç»œæ¥è¿›è¡Œå‰å‘ä¼ é€’ï¼ˆå¦‚å›¾ 8.38[504] æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "NUMHANDSETS: This was a count of how many different handsets the customer had had in the past three years. This was derived from a count of all the handset entries for a particular customer.",
            "zh": "NUMHANDSETSï¼šè¿™æ˜¯å¯¹å®¢æˆ·åœ¨è¿‡å»ä¸‰å¹´ä¸­æ‹¥æœ‰çš„ä¸åŒæ‰‹æœºæ•°é‡çš„ç»Ÿè®¡ã€‚è¿™æ˜¯ä»ç‰¹å®šå®¢æˆ·çš„æ‰€æœ‰æ‰‹æœºæ¡ç›®çš„è®¡æ•°ä¸­å¾—å‡ºçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We return to the discussion of weights in the next section, Section 8.4.2[447 our focus in this section is on the effect of repeatedly multiplying the error gradient by the derivative of an activation function",
            "zh": "æˆ‘ä»¬å›åˆ°ä¸‹ä¸€èŠ‚ä¸­å¯¹æƒé‡çš„è®¨è®ºï¼Œç¬¬ 8.4.2 èŠ‚[447 æœ¬èŠ‚çš„é‡ç‚¹æ˜¯å°†è¯¯å·®æ¢¯åº¦é‡å¤ä¹˜ä»¥æ¿€æ´»å‡½æ•°çš„å¯¼æ•°çš„æ•ˆæœ"
        }
    },
    {
        "translation": {
            "en": "The experiments designed to show the existence of N rays simply relied too much on subjective measurements (the changes in the brightness of the spark was measured by simple human observation) and did not account for all the reasons other than the presence of N rays that could have created the phenomena observed.",
            "zh": "æ—¨åœ¨è¯æ˜Nå°„çº¿å­˜åœ¨çš„å®éªŒè¿‡äºä¾èµ–ä¸»è§‚æµ‹é‡ï¼ˆç«èŠ±äº®åº¦çš„å˜åŒ–æ˜¯é€šè¿‡ç®€å•çš„äººç±»è§‚å¯Ÿæ¥æµ‹é‡çš„ï¼‰ï¼Œå¹¶ä¸”æ²¡æœ‰è§£é‡Šé™¤Nå°„çº¿çš„å­˜åœ¨ä¹‹å¤–çš„æ‰€æœ‰åŸå› ï¼Œè¿™äº›åŸå› å¯èƒ½äº§ç”Ÿè§‚å¯Ÿåˆ°çš„ç°è±¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”George E. P. Box",
            "zh": "â€”â€”ä¹”æ²»Â·åšå…‹æ–¯ï¼ˆGeorge E. P. Boxï¼‰"
        }
    },
    {
        "translation": {
            "en": "3.3.4.1â€ƒMissing valuesâ€ƒThe % Miss.",
            "zh": "3.3.4.1 ç¼ºå¤±å€¼ æœªå‘½ä¸­ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "For example, if we had used root mean squared error on a hold-out test set to evaluate the performance of a model before deployment, we could collect all the query instances presented to the model for a period after deployment and, once their true target feature values became available, calculate the root mean squared error on this new set of query instances.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨éƒ¨ç½²ä¹‹å‰å¯¹ä¿æŒæµ‹è¯•é›†ä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œåˆ™æˆ‘ä»¬å¯ä»¥åœ¨éƒ¨ç½²åçš„ä¸€æ®µæ—¶é—´å†…æ”¶é›†æä¾›ç»™æ¨¡å‹çš„æ‰€æœ‰æŸ¥è¯¢å®ä¾‹ï¼Œå¹¶åœ¨å…¶çœŸæ­£çš„ç›®æ ‡ç‰¹å¾å€¼å¯ç”¨åï¼Œè®¡ç®—è¿™ç»„æ–°æŸ¥è¯¢å®ä¾‹çš„å‡æ–¹æ ¹è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "saturated, 437, 447",
            "zh": "é¥±å’Œï¼Œ 437ï¼Œ 447"
        }
    },
    {
        "translation": {
            "en": "Xavier initialization has empirically been shown to often lead to faster training and is one of the most popular weight initialization approaches in deep learning.",
            "zh": "ç»éªŒè¡¨æ˜ï¼ŒXavier åˆå§‹åŒ–é€šå¸¸å¯ä»¥æ›´å¿«åœ°è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”æ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€æµè¡Œçš„æƒé‡åˆå§‹åŒ–æ–¹æ³•ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "degrees of freedom, 272",
            "zh": "è‡ªç”±åº¦ï¼Œ272"
        }
    },
    {
        "translation": {
            "en": "If the prior and posterior probabilities are very different, then the information content in the observation was high.",
            "zh": "å¦‚æœå…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡å·®å¼‚å¾ˆå¤§ï¼Œåˆ™è§‚å¯Ÿä¸­çš„ä¿¡æ¯å«é‡å¾ˆé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.5â€ƒSummary",
            "zh": "6.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "This ability led to a resurgence of interest in reinforcement learning in the 2010s after somewhat of a quiet period.",
            "zh": "è¿™ç§èƒ½åŠ›å¯¼è‡´åœ¨ç»å†äº†ä¸€æ®µå¹³é™æœŸåï¼Œ2010 å¹´ä»£å¯¹å¼ºåŒ–å­¦ä¹ çš„å…´è¶£é‡æ–°æŠ¬å¤´ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, we will empirically show how different variations of weight initialization can interact with this property of weighted sum calculations in order to introduce different types instability into the internal training dynamics within a network.",
            "zh": "é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®è¯åœ°å±•ç¤ºæƒé‡åˆå§‹åŒ–çš„ä¸åŒå˜åŒ–å¦‚ä½•ä¸åŠ æƒå’Œè®¡ç®—çš„è¿™ç§å±æ€§ç›¸äº’ä½œç”¨ï¼Œä»¥ä¾¿å°†ä¸åŒç±»å‹çš„ä¸ç¨³å®šæ€§å¼•å…¥ç½‘ç»œå†…çš„å†…éƒ¨è®­ç»ƒåŠ¨æ€ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate how a K-S statistic and K-S chart can give insight into model performance, Figure 9.14[566] shows a series of charts for the four different prediction models trained on the email classification task and evaluated on a large test set. The charts are a histogram of the spam scores predicted by the model, a histogram of the ham scores predicted by the model, and the resulting K-S chart with the K-S statistic highlighted.",
            "zh": "ä¸ºäº†è¯´æ˜ K-S ç»Ÿè®¡é‡å’Œ K-S æ§åˆ¶å›¾å¦‚ä½•æ·±å…¥äº†è§£æ¨¡å‹æ€§èƒ½ï¼Œå›¾ 9.14[566] æ˜¾ç¤ºäº†åœ¨ç”µå­é‚®ä»¶åˆ†ç±»ä»»åŠ¡ä¸Šè®­ç»ƒå¹¶åœ¨å¤§å‹æµ‹è¯•é›†ä¸Šè¯„ä¼°çš„å››ç§ä¸åŒé¢„æµ‹æ¨¡å‹çš„ä¸€ç³»åˆ—å›¾è¡¨ã€‚è¿™äº›å›¾è¡¨æ˜¯æ¨¡å‹é¢„æµ‹çš„åƒåœ¾é‚®ä»¶åˆ†æ•°çš„ç›´æ–¹å›¾ã€æ¨¡å‹é¢„æµ‹çš„ç«è…¿åˆ†æ•°çš„ç›´æ–¹å›¾ï¼Œä»¥åŠçªå‡ºæ˜¾ç¤º K-S ç»Ÿè®¡é‡çš„ç»“æœ K-S å›¾è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "MARITAL STATUS (never married, married, divorced);",
            "zh": "å©šå§»çŠ¶å†µï¼ˆæœªå©šã€å·²å©šã€ç¦»å©šï¼‰;"
        }
    },
    {
        "translation": {
            "en": "These weights are used as a distribution over which the dataset is sampled to create a replicated training set, in which the number of times an instance is replicated is proportional to its weight.",
            "zh": "è¿™äº›æƒé‡ç”¨ä½œå¯¹æ•°æ®é›†è¿›è¡Œé‡‡æ ·ä»¥åˆ›å»ºå¤åˆ¶è®­ç»ƒé›†çš„åˆ†å¸ƒï¼Œå…¶ä¸­å¤åˆ¶å®ä¾‹çš„æ¬¡æ•°ä¸å…¶æƒé‡æˆæ­£æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most common error function used for error-based models is the sum of squared errors.",
            "zh": "ç”¨äºåŸºäºè¯¯å·®çš„æ¨¡å‹çš„æœ€å¸¸è§è¯¯å·®å‡½æ•°æ˜¯è¯¯å·®çš„å¹³æ–¹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (Î±0 = 0.25, c = 100); (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡æ—¶ï¼ŒåŠå…¬å®¤ç§Ÿé‡‘é¢„æµ‹é—®é¢˜çš„è¯¯å·®é¢è¡Œç¨‹ ï¼ˆÎ±0 = 0.25ï¼Œ c = 100ï¼‰;ï¼ˆbï¼‰ æ­¤æ—…ç¨‹ä¸­è¯¯å·®å¹³æ–¹å’Œçš„å˜åŒ–å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 5.15(b)[219], however, demonstrates a strong negative covariance21 between the features.",
            "zh": "ç„¶è€Œï¼Œå›¾5.15ï¼ˆbï¼‰[219]ä¸­çš„æ•°æ®é›†æ˜¾ç¤ºäº†ç‰¹å¾ä¹‹é—´çš„å¼ºè´Ÿåæ–¹å·®21ã€‚"
        }
    },
    {
        "translation": {
            "en": "The former criterion is very domain specific, and so it is not discussed further here.",
            "zh": "å‰ä¸€ä¸ªæ ‡å‡†æ˜¯éå¸¸ç‰¹å®šäºé¢†åŸŸçš„ï¼Œå› æ­¤è¿™é‡Œä¸å†è¿›ä¸€æ­¥è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the professional basketball team dataset in Table 3.7[73], showing the result of range normalization and standardization.",
            "zh": "è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†çš„HEIGHTå’ŒSPONSORSHIP EARNSç‰¹å¾çš„ä¸€å°éƒ¨åˆ†æ ·æœ¬ï¼Œæ˜¾ç¤ºäº†èŒƒå›´æ ‡å‡†åŒ–å’Œæ ‡å‡†åŒ–çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "This is partly because errors in the calculation of the posterior probabilities for the different target levels do not necessarily result in prediction errors.",
            "zh": "è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å› ä¸ºä¸åŒç›®æ ‡æ°´å¹³çš„åéªŒæ¦‚ç‡è®¡ç®—è¯¯å·®ä¸ä¸€å®šä¼šå¯¼è‡´é¢„æµ‹è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "sample, 541, 745, 750, 751",
            "zh": "æ ·å“ï¼Œ 541ï¼Œ 745ï¼Œ 750ï¼Œ 751"
        }
    },
    {
        "translation": {
            "en": "So, in an m-dimensional feature space, the cosine similarity between two instances a and b is defined as",
            "zh": "å› æ­¤ï¼Œåœ¨ m ç»´ç‰¹å¾ç©ºé—´ä¸­ï¼Œä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: Given that the insurance company already has a claims investigation team, the main requirements would be that a mechanism could be put in place to inform claims investigators that some claims were prioritized above others.",
            "zh": "èƒ½åŠ›è¦æ±‚ï¼šé‰´äºä¿é™©å…¬å¸å·²ç»æœ‰ä¸€ä¸ªç´¢èµ”è°ƒæŸ¥å°ç»„ï¼Œä¸»è¦è¦æ±‚æ˜¯å¯ä»¥å»ºç«‹ä¸€ç§æœºåˆ¶ï¼Œå‘ŠçŸ¥ç´¢èµ”è°ƒæŸ¥å‘˜æŸäº›ç´¢èµ”ä¼˜å…ˆäºå…¶ä»–ç´¢èµ”ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are other statistics that we can use to measure central tendency that are not as sensitive to outliers.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…¶ä»–ç»Ÿè®¡æ•°æ®æ¥è¡¡é‡å¯¹å¼‚å¸¸å€¼ä¸é‚£ä¹ˆæ•æ„Ÿçš„ä¸­å¿ƒè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "We find these Goldilocks models by using machine learning algorithms with appropriate inductive biases.",
            "zh": "æˆ‘ä»¬é€šè¿‡ä½¿ç”¨å…·æœ‰é€‚å½“å½’çº³åå·®çš„æœºå™¨å­¦ä¹ ç®—æ³•æ¥æ‰¾åˆ°è¿™äº›é‡‘å‘å§‘å¨˜æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The flow of activations through a long short-term memory unit during forward propagation when ctâˆ’1 = [0.3,0.6], ht = [0.1,0.8], and xt = [0.9].",
            "zh": "å½“ ctâˆ’1 = [0.3,0.6]ã€ht = [0.1,0.8] å’Œ xt = [0.9] æ—¶ï¼Œåœ¨æ­£å‘ä¼ æ’­è¿‡ç¨‹ä¸­é€šè¿‡é•¿çŸ­æœŸè®°å¿†å•å…ƒçš„æ¿€æ´»æµã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, it can be shown that, under some assumptions, any learning algorithm that minimizes the squared error of the model over the data will output a maximum likelihood prediction.32 The relevance of this finding is that it provides a probabilistic justification for the approach to learning we present in Chapter 7[311].",
            "zh": "æœ€åï¼Œå¯ä»¥è¯æ˜ï¼Œåœ¨æŸäº›å‡è®¾ä¸‹ï¼Œä»»ä½•æœ€å°åŒ–æ¨¡å‹å¯¹æ•°æ®çš„å¹³æ–¹è¯¯å·®çš„å­¦ä¹ ç®—æ³•éƒ½å°†è¾“å‡ºæœ€å¤§ä¼¼ç„¶é¢„æµ‹.32è¿™ä¸€å‘ç°çš„ç›¸å…³æ€§åœ¨äºï¼Œå®ƒä¸ºæˆ‘ä»¬åœ¨ç¬¬7ç« [311]ä¸­ä»‹ç»çš„å­¦ä¹ æ–¹æ³•æä¾›äº†æ¦‚ç‡è®ºçš„åˆç†æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.2â€ƒSetting the Learning Rate Using Weight Decay",
            "zh": "7.4.2 ä½¿ç”¨æƒé‡è¡°å‡è®¾ç½®å­¦ä¹ ç‡"
        }
    },
    {
        "translation": {
            "en": "3.4.1â€…â€…â€…Handling Missing Values",
            "zh": "3.4.1 å¤„ç†ç¼ºå¤±å€¼"
        }
    },
    {
        "translation": {
            "en": "Instead, the exploding exploding gradients exhibited in Figure 8.24(d)[454] is caused by a similar process to the vanishing z values plotted in Figure 8.23(b)[453] and the exploding z values plotted in Figure 8.24(b)[454 the connection between these three processes is that they all involve a weighted sum.",
            "zh": "ç›¸åï¼Œå›¾8.24ï¼ˆdï¼‰[454]ä¸­æ˜¾ç¤ºçš„çˆ†ç‚¸çˆ†ç‚¸æ¢¯åº¦æ˜¯ç”±ä¸å›¾8.23ï¼ˆbï¼‰[453]ä¸­ç»˜åˆ¶çš„æ¶ˆå¤±zå€¼å’Œå›¾8.24ï¼ˆbï¼‰[454ä¸­ç»˜åˆ¶çš„çˆ†ç‚¸zå€¼ç›¸ä¼¼çš„è¿‡ç¨‹å¼•èµ·çš„ï¼Œè¿™ä¸‰ä¸ªè¿‡ç¨‹ä¹‹é—´çš„è”ç³»æ˜¯å®ƒä»¬éƒ½æ¶‰åŠåŠ æƒå’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "A commonly used alternative to representing a continuous feature using a probability density function is to convert the feature into a categorical feature using binning.",
            "zh": "ä½¿ç”¨æ¦‚ç‡å¯†åº¦å‡½æ•°è¡¨ç¤ºè¿ç»­ç‰¹å¾çš„å¸¸ç”¨æ–¹æ³•æ˜¯ä½¿ç”¨åˆ†ç®±å°†ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, conifer refers to forested areas that contain a variety of tree species (including pine, cedar, and fir trees), with a mixture of shrubs on the forest floor.",
            "zh": "æœ€åï¼Œé’ˆå¶æ ‘æ˜¯æŒ‡åŒ…å«å„ç§æ ‘ç§ï¼ˆåŒ…æ‹¬æ¾æ ‘ã€é›ªæ¾å’Œå†·æ‰ï¼‰çš„æ£®æ—åœ°åŒºï¼Œæ£®æ—åœ°é¢ä¸Šæ··åˆäº†çŒæœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have already calculated the conditional probability of the event m given h directly from the dataset in Table B.2[760] as P(m | h) = 0.2857 (see Equation (B.3)[761]). We will now recalculate this probability using our rule-based definition of conditional probability. From our previous calculations, we already know that P(h) = 0.7 (see Equation (B.1)[760]) and P(m,h) = 0.2 (see Equation (B.2)[760]). So our calculation for P(m | h) is",
            "zh": "æˆ‘ä»¬å·²ç»ç›´æ¥ä»è¡¨B.2[760]ä¸­çš„æ•°æ®é›†ä¸­è®¡ç®—äº†äº‹ä»¶mç»™å®šhçš„æ¡ä»¶æ¦‚ç‡ä¸ºPï¼ˆm | hï¼‰ = 0.2857ï¼ˆå‚è§æ–¹ç¨‹ï¼ˆB.3ï¼‰[761]ï¼‰ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸºäºè§„åˆ™çš„æ¡ä»¶æ¦‚ç‡å®šä¹‰é‡æ–°è®¡ç®—æ­¤æ¦‚ç‡ã€‚ä»æˆ‘ä»¬ä¹‹å‰çš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“ Pï¼ˆhï¼‰ = 0.7ï¼ˆå‚è§æ–¹ç¨‹ ï¼ˆB.1ï¼‰[760]ï¼‰å’Œ Pï¼ˆmï¼Œhï¼‰ = 0.2ï¼ˆå‚è§æ–¹ç¨‹ ï¼ˆB.2ï¼‰[760]ï¼‰ã€‚æ‰€ä»¥æˆ‘ä»¬å¯¹ Pï¼ˆm | hï¼‰ çš„è®¡ç®—æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The scores are 0.0139 for a prediction of true and 0.0245 for a prediction of false.",
            "zh": "é¢„æµ‹ä¸ºçœŸæ—¶å¾—åˆ†ä¸º 0.0139ï¼Œé¢„æµ‹ä¸ºå‡æ—¶å¾—åˆ†ä¸º 0.0245ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because the information we get from knowing that the patient has a headache is already contained within the information that the patient has meningitis.",
            "zh": "è¿™æ˜¯å› ä¸ºæˆ‘ä»¬ä»çŸ¥é“æ‚£è€…å¤´ç—›ä¸­è·å¾—çš„ä¿¡æ¯å·²ç»åŒ…å«åœ¨æ‚£è€…æ‚£æœ‰è„‘è†œç‚çš„ä¿¡æ¯ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset has been used to build a decision tree to predict which customers will respond to future special offers. The decision tree, created using the ID3 algorithm, is the following:",
            "zh": "è¯¥æ•°æ®é›†å·²ç”¨äºæ„å»ºå†³ç­–æ ‘ï¼Œä»¥é¢„æµ‹å“ªäº›å®¢æˆ·å°†å“åº”æœªæ¥çš„ç‰¹åˆ«ä¼˜æƒ ã€‚ä½¿ç”¨ ID3 ç®—æ³•åˆ›å»ºçš„å†³ç­–æ ‘å¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "The third segment lists the per neuron and per example softmax activations; these values are calculated by dividing the eli value in the corresponding cell in the second segment by the sum for that column âˆ‘ieli.",
            "zh": "ç¬¬ä¸‰éƒ¨åˆ†åˆ—å‡ºäº†æ¯ä¸ªç¥ç»å…ƒå’Œæ¯ä¸ªç¤ºä¾‹çš„ softmax æ¿€æ´»;è¿™äº›å€¼çš„è®¡ç®—æ–¹æ³•æ˜¯å°†ç¬¬äºŒæ®µä¸­ç›¸åº”å•å…ƒæ ¼ä¸­çš„ ELI å€¼é™¤ä»¥è¯¥åˆ—çš„æ€»å’Œ âˆ‘ieliã€‚"
        }
    },
    {
        "translation": {
            "en": "This model tells us that for every increase of a square foot in SIZE, RENTAL PRICE increases by 0.62 Euro. We can also use this model to determine the expected rental price of the 730-square-foot office mentioned previously by simply plugging this value for SIZE into the model",
            "zh": "è¯¥æ¨¡å‹å‘Šè¯‰æˆ‘ä»¬ï¼Œé¢ç§¯æ¯å¢åŠ ä¸€å¹³æ–¹è‹±å°ºï¼Œç§Ÿé‡‘ä»·æ ¼å°±ä¼šå¢åŠ  0.62 æ¬§å…ƒã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ­¤æ¨¡å‹æ¥ç¡®å®šå‰é¢æåˆ°çš„ 730 å¹³æ–¹è‹±å°ºåŠå…¬å®¤çš„é¢„æœŸç§Ÿé‡‘ä»·æ ¼ï¼Œåªéœ€å°† SIZE çš„è¿™ä¸ªå€¼ä»£å…¥æ¨¡å‹å³å¯"
        }
    },
    {
        "translation": {
            "en": "(a) and (b) frequency histograms and (c) and (d) density histograms for the continuous TRAINING EXPENSES feature from Table A.1[750], illustrating how using intervals overcomes the problem seen in Figure A.6[753] and the effect of varying interval sizes.",
            "zh": "è¡¨A.1[750]ä¸­è¿ç»­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„ï¼ˆaï¼‰å’Œï¼ˆbï¼‰é¢‘ç‡ç›´æ–¹å›¾ä»¥åŠï¼ˆcï¼‰å’Œï¼ˆdï¼‰å¯†åº¦ç›´æ–¹å›¾ï¼Œè¯´æ˜äº†ä½¿ç”¨é—´éš”å¦‚ä½•å…‹æœå›¾A.6[753]ä¸­çš„é—®é¢˜ä»¥åŠä¸åŒé—´éš”å¤§å°çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was encouraging that in many cases distinct distributions for each galaxy type were apparent in the histograms.",
            "zh": "ä»¤äººé¼“èˆçš„æ˜¯ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ¯ç§æ˜Ÿç³»ç±»å‹çš„ä¸åŒåˆ†å¸ƒåœ¨ç›´æ–¹å›¾ä¸­éƒ½å¾ˆæ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature in this domain, DECISION, records the decision of whether the patient is sent to the icu or to a general ward (gen) for recovery.",
            "zh": "æ­¤åŸŸä¸­çš„ç›®æ ‡åŠŸèƒ½ DECISION è®°å½•äº†æ‚£è€…æ˜¯è¢«é€å¾€ ICU è¿˜æ˜¯æ™®é€šç—…æˆ¿ ï¼ˆgenï¼‰ è¿›è¡Œåº·å¤çš„å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The large values of the RENTAL PRICE feature, [320,620], cause the squared errors and, in turn, the error delta values to become very large.",
            "zh": "RENTAL PRICE ç‰¹å¾ [320,620] çš„å¤§å€¼ä¼šå¯¼è‡´å¹³æ–¹è¯¯å·®ï¼Œè¿›è€Œå¯¼è‡´è¯¯å·®å¢é‡å€¼å˜å¾—éå¸¸å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.7[208] also repeats the calculations from Table 5.6[206] using the normalized dataset and the normalized query instance.",
            "zh": "è¡¨ 5.7[208] è¿˜ä½¿ç”¨è§„èŒƒåŒ–æ•°æ®é›†å’Œè§„èŒƒåŒ–æŸ¥è¯¢å®ä¾‹é‡å¤äº†è¡¨ 5.6[206] ä¸­çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first part, she performed a performance test of the final model selectedâ€”the 3-level logistic regression model using the selected feature subsetâ€”on the large test dataset mentioned at the beginning of Section 13.4[719].",
            "zh": "åœ¨ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œå¥¹å¯¹ç¬¬ 13.4 èŠ‚å¼€å¤´æåˆ°çš„å¤§å‹æµ‹è¯•æ•°æ®é›†æ‰§è¡Œäº†æœ€ç»ˆé€‰æ‹©çš„æ¨¡å‹ï¼ˆä½¿ç”¨æ‰€é€‰ç‰¹å¾å­é›†çš„ 3 çº§é€»è¾‘å›å½’æ¨¡å‹ï¼‰çš„æ€§èƒ½æµ‹è¯•[719]ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that these models are part of an ensemble training using bagging, calculate the overall output of the ensemble for each instance in the test dataset.",
            "zh": "ï¼ˆaï¼‰ å‡è®¾è¿™äº›æ¨¡å‹æ˜¯ä½¿ç”¨è¢‹è£…çš„é›†æˆè®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼Œè®¡ç®—æµ‹è¯•æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹çš„é›†æˆçš„æ€»è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Each customerâ€™s average weekly spending with the chain, SPEND, and average number of visits per week to the chain, FREQ, are included along with the TYPE of customer: single, business, or family.",
            "zh": "æ¯ä¸ªå®¢æˆ·åœ¨è¿é”åº—çš„å¹³å‡æ¯å‘¨æ”¯å‡ºã€æ”¯å‡ºå’Œæ¯å‘¨å¯¹è¿é”åº—çš„å¹³å‡è®¿é—®æ¬¡æ•° FREQ ä¸å®¢æˆ·ç±»å‹ä¸€èµ·åŒ…æ‹¬åœ¨å†…ï¼šå•èº«ã€ä¼ä¸šæˆ–å®¶åº­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The errorDelta(,w[j]) for each weight is then the summation of the relevant column, for example, errorDelta(,w[0]) = 3,185.61 and errorDelta(,w[1]) = 2,412,073.90.",
            "zh": "æ¯ä¸ªæƒé‡çš„ errorDeltaï¼ˆï¼Œw[j]ï¼‰ æ˜¯ç›¸å…³åˆ—çš„æ€»å’Œï¼Œä¾‹å¦‚ï¼ŒerrorDeltaï¼ˆï¼Œw[0]ï¼‰ = 3,185.61 å’Œ errorDeltaï¼ˆï¼Œw[1]ï¼‰ = 2,412,073.90ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.3â€ƒHow Does Machine Learning Work?",
            "zh": "1.3 æœºå™¨å­¦ä¹ æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Case Study: Galaxy Classification",
            "zh": "æ¡ˆä¾‹ç ”ç©¶ï¼šæ˜Ÿç³»åˆ†ç±»"
        }
    },
    {
        "translation": {
            "en": "The companyâ€™s entire customer base was divided randomly into two groups, the treatment group and the control groupâ€”and each group contained approximately 400,000 customers.",
            "zh": "è¯¥å…¬å¸çš„æ•´ä¸ªå®¢æˆ·ç¾¤è¢«éšæœºåˆ†ä¸ºä¸¤ç»„ï¼Œæ²»ç–—ç»„å’Œå¯¹ç…§ç»„ï¼Œæ¯ç»„åŒ…å«å¤§çº¦ 400,000 åå®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes prediction model returns the MAP prediction, so our naive Bayes model would make a prediction of false and so classify this loan application query as not fraudulent.",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹è¿”å› MAP é¢„æµ‹ï¼Œå› æ­¤æˆ‘ä»¬çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†åšå‡ºé”™è¯¯çš„é¢„æµ‹ï¼Œä»è€Œå°†æ­¤è´·æ¬¾ç”³è¯·æŸ¥è¯¢å½’ç±»ä¸ºéæ¬ºè¯ˆæ€§æŸ¥è¯¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can illustrate how the AHC algorithm works using a reduced version of the mobile phone customer dataset from Table 10.1[604].",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¡¨ 10.1[604] ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ç®€åŒ–ç‰ˆæœ¬æ¥è¯´æ˜ AHC ç®—æ³•çš„å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This illustrates how the class posterior probabilities can be simpler than the class conditional densities.",
            "zh": "è¿™è¯´æ˜äº†ç±»åéªŒæ¦‚ç‡å¦‚ä½•æ¯”ç±»æ¡ä»¶å¯†åº¦æ›´ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem is even more serious than this, however, as in practice, it is almost never possible to collect a dataset that is big enough to sufficiently cover all the possible combinations of descriptive feature values that can occur in a dataset so as to avoid this.",
            "zh": "ç„¶è€Œï¼Œé—®é¢˜æ¯”è¿™æ›´ä¸¥é‡ï¼Œå› ä¸ºåœ¨å®è·µä¸­ï¼Œå‡ ä¹ä¸å¯èƒ½æ”¶é›†åˆ°è¶³å¤Ÿå¤§çš„æ•°æ®é›†ï¼Œä»¥å……åˆ†æ¶µç›–æ•°æ®é›†ä¸­å¯èƒ½å‡ºç°çš„æ‰€æœ‰æè¿°æ€§ç‰¹å¾å€¼ç»„åˆï¼Œä»¥é¿å…è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "The main additions in the second edition are the following:",
            "zh": "ç¬¬äºŒç‰ˆçš„ä¸»è¦æ–°å¢å†…å®¹å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The retention team could focus their retention efforts on these customers.",
            "zh": "ä¿ç•™å›¢é˜Ÿå¯ä»¥å°†ä¿ç•™å·¥ä½œé‡ç‚¹æ”¾åœ¨è¿™äº›å®¢æˆ·ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This is in contrast to application-based solutions, in which the analyst can really achieve only what the tool developers had in mind when they designed the tool.",
            "zh": "è¿™ä¸åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆå½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåœ¨åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆä¸­ï¼Œåˆ†æå¸ˆåªèƒ½çœŸæ­£å®ç°å·¥å…·å¼€å‘äººå‘˜åœ¨è®¾è®¡å·¥å…·æ—¶æ‰€è€ƒè™‘çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The presence of large numbers of outliers can also be seen.",
            "zh": "è¿˜å¯ä»¥çœ‹åˆ°å¤§é‡å¼‚å¸¸å€¼çš„å­˜åœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In selecting the appropriate model type to use, all these aspects, along with the structure of the data, should be taken into account.",
            "zh": "åœ¨é€‰æ‹©è¦ä½¿ç”¨çš„é€‚å½“æ¨¡å‹ç±»å‹æ—¶ï¼Œåº”è€ƒè™‘æ‰€æœ‰è¿™äº›æ–¹é¢ä»¥åŠæ•°æ®çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "false negative, 537, 556",
            "zh": "å‡é˜´æ€§ï¼Œ 537ï¼Œ 556"
        }
    },
    {
        "translation": {
            "en": "metric, 184, 211",
            "zh": "å…¬åˆ¶ï¼Œ 184ï¼Œ 211"
        }
    },
    {
        "translation": {
            "en": "overfitting, 14, 153, 157, 193, 256, 265, 432, 434, 472, 541",
            "zh": "è¿‡æ‹Ÿåˆï¼Œ 14ï¼Œ 153ï¼Œ 157ï¼Œ 193ï¼Œ 256ï¼Œ 265ï¼Œ 432ï¼Œ 434ï¼Œ 472ï¼Œ 541"
        }
    },
    {
        "translation": {
            "en": "As such, support vector machines are often a good choice in complex domains with lots of data.",
            "zh": "å› æ­¤ï¼Œåœ¨å…·æœ‰å¤§é‡æ•°æ®çš„å¤æ‚é¢†åŸŸä¸­ï¼Œæ”¯æŒå‘é‡æœºé€šå¸¸æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "AGE: The customerâ€™s age",
            "zh": "å¹´é¾„ï¼šå®¢æˆ·çš„å¹´é¾„"
        }
    },
    {
        "translation": {
            "en": "HEALTHDEPSADULTS: How many dependent adults are included on the health insurance policy",
            "zh": "HEALTHDEPSADULTSï¼šå¥åº·ä¿é™©å•ä¸­åŒ…æ‹¬å¤šå°‘å—æŠšå…»æˆå¹´äºº"
        }
    },
    {
        "translation": {
            "en": "4.3â€…â€…â€…The different question sequences that can follow in a game of Guess Who beginning with the question Is it a man?",
            "zh": "4.3 çŒœçŒœè°æ¸¸æˆä¸­å¯ä»¥éµå¾ªçš„ä¸åŒé—®é¢˜åºåˆ—ï¼Œä»é—®é¢˜å¼€å§‹ æ˜¯ç”·äººå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "0.2351",
            "zh": "0.2351"
        }
    },
    {
        "translation": {
            "en": "In Section 3.4[69] we introduced a number of techniques for handling missing values, and particular care should be taken to handle missing values if a nearest neighbor model is being used.",
            "zh": "åœ¨ç¬¬ 3.4 èŠ‚[69]ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€äº›å¤„ç†ç¼ºå¤±å€¼çš„æŠ€æœ¯ï¼Œå¦‚æœä½¿ç”¨æœ€è¿‘é‚»æ¨¡å‹ï¼Œåˆ™åº”ç‰¹åˆ«æ³¨æ„å¤„ç†ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "A shorter time later than Mr. Murphy would have liked, Abigail skipped back in to her father to say that she was finished.",
            "zh": "æ¯”å¢¨è²å…ˆç”Ÿå¸Œæœ›çš„è¦æ™šäº†ä¸€å°æ®µæ—¶é—´ï¼Œé˜¿æ¯”ç›–å°”è·³å›å¥¹çˆ¶äº²é‚£é‡Œï¼Œè¯´å¥¹å®Œè›‹äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can write this action-value table update rule",
            "zh": "æˆ‘ä»¬å¯ä»¥ç¼–å†™è¿™ä¸ªæ“ä½œå€¼è¡¨æ›´æ–°è§„åˆ™"
        }
    },
    {
        "translation": {
            "en": "Transparency International, 237",
            "zh": "é€æ˜å›½é™…ï¼Œ237"
        }
    },
    {
        "translation": {
            "en": "An important decision to be made in designing any recursive process is what the base cases that stop the recursion will be.",
            "zh": "åœ¨è®¾è®¡ä»»ä½•é€’å½’è¿‡ç¨‹æ—¶ï¼Œè¦åšå‡ºçš„ä¸€ä¸ªé‡è¦å†³å®šæ˜¯åœæ­¢é€’å½’çš„åŸºæœ¬æƒ…å†µæ˜¯ä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "leaf nodes, 121",
            "zh": "å¶èŠ‚ç‚¹ï¼Œ121"
        }
    },
    {
        "translation": {
            "en": "Cleary, Duncan, and Revenue Irish Tax. 2011. Predictive analytics in the public sector: Using data mining to assist better target selection for audit. In The proceedings of the 11th European conference on egovernment: Faculty of administration, University of Ljubljana, Ljubljana, Slovenia, 16â€“17 June 2011, 168. Academic Conferences Limited.",
            "zh": "Clearyã€Duncan å’Œçˆ±å°”å…°ç¨åŠ¡å±€ã€‚2011. å…¬å…±éƒ¨é—¨çš„é¢„æµ‹åˆ†æï¼šä½¿ç”¨æ•°æ®æŒ–æ˜æ¥å¸®åŠ©æ›´å¥½åœ°é€‰æ‹©å®¡è®¡ç›®æ ‡ã€‚ç¬¬11å±Šæ¬§æ´²ç”µå­æ”¿åŠ¡ä¼šè®®è®ºæ–‡é›†ï¼šå¢å¸ƒå°”é›…é‚£å¤§å­¦è¡Œæ”¿å­¦é™¢ï¼Œæ–¯æ´›æ–‡å°¼äºšå¢å¸ƒå°”é›…é‚£ï¼Œ2011å¹´6æœˆ16-17æ—¥ï¼Œç¬¬168é¡µã€‚å­¦æœ¯ä¼šè®®æœ‰é™å…¬å¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "binary tree, 196",
            "zh": "äºŒå‰æ ‘ï¼Œ196"
        }
    },
    {
        "translation": {
            "en": "Extracting the action with the highest Q value in each state from the action-value table gives the greedy target policy that the agent, now trained to complete the task, would use after deployment.",
            "zh": "ä» action-value è¡¨ä¸­æå–æ¯ä¸ªçŠ¶æ€ä¸­ Q å€¼æœ€é«˜çš„æ“ä½œï¼Œå¯æä¾›ä»£ç†ï¼ˆç°å·²è®­ç»ƒå®Œæˆä»»åŠ¡ï¼‰åœ¨éƒ¨ç½²åå°†ä½¿ç”¨çš„è´ªå©ªç›®æ ‡ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a more general textbook on natural language processing, we recommend Jurafsky and Martin (2008).",
            "zh": "å¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†çš„æ›´é€šç”¨çš„æ•™ç§‘ä¹¦ï¼Œæˆ‘ä»¬æ¨èJurafsky and Martin ï¼ˆ2008ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "His next task was to add much more depth to this understanding, following the process described in Section 2.3[28].",
            "zh": "ä»–çš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯æŒ‰ç…§ç¬¬2.3èŠ‚[28]ä¸­æè¿°çš„è¿‡ç¨‹ï¼Œä¸ºè¿™ç§ç†è§£å¢åŠ æ›´å¤šçš„æ·±åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "26. A hypercube is a generalization of the geometric concept of a cube across multiple dimensions. Hence in a two-dimensional space, the term hypercube denotes a square; in three-dimensional space, it denotes a cube; and so on. A unit hypercube is a hypercube in which the length of every side is 1 unit.",
            "zh": "26. è¶…ç«‹æ–¹ä½“æ˜¯ç«‹æ–¹ä½“å‡ ä½•æ¦‚å¿µåœ¨å¤šä¸ªç»´åº¦ä¸Šçš„æ¦‚æ‹¬ã€‚å› æ­¤ï¼Œåœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œæœ¯è¯­è¶…ç«‹æ–¹ä½“è¡¨ç¤ºæ­£æ–¹å½¢;åœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œå®ƒè¡¨ç¤ºä¸€ä¸ªç«‹æ–¹ä½“;ç­‰ç­‰ã€‚å•ä½è¶…ç«‹æ–¹ä½“æ˜¯æ¯è¾¹é•¿åº¦ä¸º 1 ä¸ªå•ä½çš„è¶…ç«‹æ–¹ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "misclassification rate, 179, 533, 536, 539, 540, 549, 551",
            "zh": "è¯¯åˆ†ç±»ç‡ï¼Œ179ã€533ã€536ã€539ã€540ã€549ã€551"
        }
    },
    {
        "translation": {
            "en": "Tufte, Edward R. 2001. The visual display of quantitative information. Graphics Press.",
            "zh": "å¡”å¤«ç‰¹ï¼Œçˆ±å¾·å R. 2001 å¹´ã€‚å®šé‡ä¿¡æ¯çš„å¯è§†åŒ–æ˜¾ç¤ºã€‚å›¾å½¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the most informative features occupy berths toward the top of a tree means that stunted trees usually capture the most important information.",
            "zh": "äº‹å®ä¸Šï¼Œä¿¡æ¯é‡æœ€å¤§çš„ç‰¹å¾å æ®äº†æ ‘é¡¶çš„æ³Šä½ï¼Œè¿™æ„å‘³ç€å‘è‚²ä¸è‰¯çš„æ ‘æœ¨é€šå¸¸ä¼šæ•è·æœ€é‡è¦çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Chapter 14[729] provides some overarching perspectives on machine learning for predictive data analytics and summarizes some of the key differences between the different approaches covered in this book.",
            "zh": "æœ€åï¼Œç¬¬14ç« [729]æä¾›äº†ä¸€äº›å…³äºæœºå™¨å­¦ä¹ ç”¨äºé¢„æµ‹æ•°æ®åˆ†æçš„æ€»ä½“è§‚ç‚¹ï¼Œå¹¶æ€»ç»“äº†æœ¬ä¹¦ä¸­æ¶µç›–çš„ä¸åŒæ–¹æ³•ä¹‹é—´çš„ä¸€äº›å…³é”®åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2115",
            "zh": "0.2115"
        }
    },
    {
        "translation": {
            "en": "This summation gives us the Î”wi,k term in Equation (8.30)[416].",
            "zh": "è¿™ä¸ªæ±‚å’Œç»™å‡ºäº†æ–¹ç¨‹ï¼ˆ8.30ï¼‰[416]ä¸­çš„Î”wiï¼Œké¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The columns identified as being most predictive of galaxy morphology were EXPRAD_G (0.3908), EXPRAD_R (0.3649), DEVRAD_G (0.3607), EXPRAD_I (0.3509), DEVRAD_R (0.3467), EXPRAD_Z (0.3457), and MRRCC_G (0.3365).",
            "zh": "è¢«ç¡®å®šä¸ºæœ€èƒ½é¢„æµ‹æ˜Ÿç³»å½¢æ€çš„åˆ—æ˜¯EXPRAD_Gï¼ˆ0.3908ï¼‰ã€EXPRAD_Rï¼ˆ0.3649ï¼‰ã€DEVRAD_Gï¼ˆ0.3607ï¼‰ã€EXPRAD_Iï¼ˆ0.3509ï¼‰ã€DEVRAD_Rï¼ˆ0.3467ï¼‰ã€EXPRAD_Zï¼ˆ0.3457ï¼‰å’ŒMRRCC_Gï¼ˆ0.3365ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "units, 386",
            "zh": "å•ä½ï¼Œ 386"
        }
    },
    {
        "translation": {
            "en": "A more common phenomenon is that two or more events may be independent if we know that a third event has happened.",
            "zh": "ä¸€ä¸ªæ›´å¸¸è§çš„ç°è±¡æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬çŸ¥é“å‘ç”Ÿäº†ç¬¬ä¸‰ä¸ªäº‹ä»¶ï¼Œé‚£ä¹ˆä¸¤ä¸ªæˆ–å¤šä¸ªäº‹ä»¶å¯èƒ½æ˜¯ç‹¬ç«‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The robustness of the student-t to outliers is another reason to consider using this distribution, as opposed to a normal distribution, to model unimodal data in situations with relatively small or possibly noisy datasets.",
            "zh": "student-t å¯¹å¼‚å¸¸å€¼çš„é²æ£’æ€§æ˜¯è€ƒè™‘ä½¿ç”¨æ­¤åˆ†å¸ƒï¼ˆè€Œä¸æ˜¯æ­£æ€åˆ†å¸ƒï¼‰åœ¨æ•°æ®é›†ç›¸å¯¹è¾ƒå°æˆ–å¯èƒ½å˜ˆæ‚çš„æƒ…å†µä¸‹å¯¹å•å³°æ•°æ®è¿›è¡Œå»ºæ¨¡çš„å¦ä¸€ä¸ªåŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we can expect the predictions made by the regression model to be 1.38mg out on average, whereas those made by the nearest neighbor model will be, on average, 2.096mg out.",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é¢„æœŸå›å½’æ¨¡å‹åšå‡ºçš„é¢„æµ‹å¹³å‡ä¸º 1.38 æ¯«å…‹ï¼Œè€Œæœ€è¿‘é‚»æ¨¡å‹åšå‡ºçš„é¢„æµ‹å¹³å‡ä¸º 2.096 æ¯«å…‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "All the other input values are ignored because they are given a weight of 0.",
            "zh": "æ‰€æœ‰å…¶ä»–è¾“å…¥å€¼éƒ½å°†è¢«å¿½ç•¥ï¼Œå› ä¸ºå®ƒä»¬çš„æƒé‡ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both these new partitions are pure sets with respect to the target feature (indeed, they contain only one instance each), and consequently these sets do not need to be split any further and can be converted into leaf nodes.",
            "zh": "è¿™ä¸¤ä¸ªæ–°åˆ†åŒºéƒ½æ˜¯ç›¸å¯¹äºç›®æ ‡åŠŸèƒ½çš„çº¯é›†ï¼ˆå®é™…ä¸Šï¼Œå®ƒä»¬æ¯ä¸ªåªåŒ…å«ä¸€ä¸ªå®ä¾‹ï¼‰ï¼Œå› æ­¤è¿™äº›é›†ä¸éœ€è¦è¿›ä¸€æ­¥æ‹†åˆ†ï¼Œå¯ä»¥è½¬æ¢ä¸ºå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This time we will predict the expected rental demand on the basis of a single descriptive feature, the forecasted temperature for a day.",
            "zh": "è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å°†æ ¹æ®ä¸€ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œå³ä¸€å¤©çš„é¢„æµ‹æ¸©åº¦æ¥é¢„æµ‹é¢„æœŸçš„ç§Ÿèµéœ€æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.1â€…â€…â€…A dataset of instances from the sample space in Figure B.1[757].",
            "zh": "B.1 å›¾B.1[757]ä¸­æ ·æœ¬ç©ºé—´ä¸­çš„å®ä¾‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this scenario it is interesting to take a perspective on the similarity between customers that focuses on the mix of these two types of services they use, rather than the volumes of the services they use.",
            "zh": "åœ¨æ­¤æ–¹æ¡ˆä¸­ï¼Œæœ‰è¶£çš„æ˜¯ï¼Œä»å®¢æˆ·ä¹‹é—´çš„ç›¸ä¼¼æ€§çš„è§’åº¦æ¥çœ‹ï¼Œé‡ç‚¹å…³æ³¨ä»–ä»¬ä½¿ç”¨çš„è¿™ä¸¤ç§ç±»å‹çš„æœåŠ¡çš„ç»„åˆï¼Œè€Œä¸æ˜¯ä»–ä»¬ä½¿ç”¨çš„æœåŠ¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are now ready to process a query that has the continuous LOAN AMOUNT feature as part of the evidence:",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬å·²å‡†å¤‡å¥½å¤„ç†ä¸€ä¸ªæŸ¥è¯¢ï¼Œè¯¥æŸ¥è¯¢å…·æœ‰è¿ç»­è´·æ¬¾é‡‘é¢ç‰¹å¾ä½œä¸ºè¯æ®çš„ä¸€éƒ¨åˆ†ï¼š"
        }
    },
    {
        "translation": {
            "en": "tired",
            "zh": "ç´¯"
        }
    },
    {
        "translation": {
            "en": "thinking hard about the best ways to represent features;",
            "zh": "è®¤çœŸæ€è€ƒè¡¨ç¤ºç‰¹å¾çš„æœ€ä½³æ–¹å¼;"
        }
    },
    {
        "translation": {
            "en": "Table 6.6",
            "zh": "è¡¨ 6.6"
        }
    },
    {
        "translation": {
            "en": "Although this example is small, the same approach can be used effectively for large multivariate datasets, with the only difference being a need to examine summary statistics and visualizations for many more features.",
            "zh": "å°½ç®¡æ­¤ç¤ºä¾‹å¾ˆå°ï¼Œä½†ç›¸åŒçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ç”¨äºå¤§å‹å¤šå˜é‡æ•°æ®é›†ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯éœ€è¦æ£€æŸ¥æ›´å¤šç‰¹å¾çš„æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Policies rely on being able to assess the expected return of taking an action in a particular state, and an action-value function is used to calculate this.",
            "zh": "ç­–ç•¥ä¾èµ–äºèƒ½å¤Ÿè¯„ä¼°åœ¨ç‰¹å®šçŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥ï¼Œå¹¶ä½¿ç”¨æ“ä½œå€¼å‡½æ•°æ¥è®¡ç®—æ­¤å›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.1â€…â€…â€…Interpreting Multivariable Linear Regression Models",
            "zh": "7.4.1 è§£é‡Šå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Over the last four chapters, we have discussed a range of approaches to building machine learning models that make various kinds of predictions. The question that we must answer in the Evaluation phase of the CRISP-DM process (recall Section 1.6[15]) is Can the model generated do the job that it has been built for? The purpose of evaluation is threefold:",
            "zh": "åœ¨è¿‡å»çš„å››ç« ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¸€ç³»åˆ—æ–¹æ³•ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥è¿›è¡Œå„ç§é¢„æµ‹ã€‚åœ¨CRISP-DMè¿‡ç¨‹çš„è¯„ä¼°é˜¶æ®µï¼ˆå›æƒ³ä¸€ä¸‹ç¬¬1.6èŠ‚[15]ï¼‰ï¼Œæˆ‘ä»¬å¿…é¡»å›ç­”çš„é—®é¢˜æ˜¯ï¼šç”Ÿæˆçš„æ¨¡å‹èƒ½å¦å®Œæˆå…¶æ„å»ºçš„å·¥ä½œï¼Ÿè¯„ä¼°çš„ç›®çš„æœ‰ä¸‰ä¸ªï¼š"
        }
    },
    {
        "translation": {
            "en": "scatter plot, 73, 183",
            "zh": "æ•£ç‚¹å›¾ï¼Œ73,183"
        }
    },
    {
        "translation": {
            "en": "To calculate these thresholds, we take the midpoint in the feature range between the instance with the highest feature value in one bin and the feature with the lowest feature value in the next bin.",
            "zh": "ä¸ºäº†è®¡ç®—è¿™äº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å–ä¸€ä¸ª bin ä¸­ç‰¹å¾å€¼æœ€é«˜çš„å®ä¾‹å’Œä¸‹ä¸€ä¸ª bin ä¸­ç‰¹å¾å€¼æœ€ä½çš„ç‰¹å¾ä¹‹é—´çš„ç‰¹å¾èŒƒå›´çš„ä¸­ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The following image shows an artificial neural network with two sensing neurons (Neurons 1 and 2) and 3 processing neurons (Neurons 3, 4, and 5)",
            "zh": "2. ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªäººå·¥ç¥ç»ç½‘ç»œï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªä¼ æ„Ÿç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 1 å’Œ 2ï¼‰å’Œ 3 ä¸ªå¤„ç†ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 3ã€4 å’Œ 5ï¼‰"
        }
    },
    {
        "translation": {
            "en": "We also need to calculate the likelihood of the descriptive feature values of the query given that the target is true. We could calculate this directly from the dataset, but in this example, we will illustrate the chain rule approach just described. Using the chain rule approach, we compute the overall likelihood of the descriptive feature values given a target value of true as the product of a set of conditional probabilities that are themselves calculated from the dataset",
            "zh": "æˆ‘ä»¬è¿˜éœ€è¦è®¡ç®—æŸ¥è¯¢çš„æè¿°æ€§ç‰¹å¾å€¼çš„å¯èƒ½æ€§ï¼Œå‰ææ˜¯ç›®æ ‡ä¸ºçœŸã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥ä»æ•°æ®é›†ä¸­è®¡ç®—å‡ºæ¥ï¼Œä½†åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜åˆšæ‰æè¿°çš„é“¾å¼è§„åˆ™æ–¹æ³•ã€‚ä½¿ç”¨é“¾å¼è§„åˆ™æ–¹æ³•ï¼Œæˆ‘ä»¬è®¡ç®—ç»™å®šç›®æ ‡å€¼ä¸ºtrueçš„æè¿°æ€§ç‰¹å¾å€¼çš„æ€»ä½“å¯èƒ½æ€§ï¼Œä½œä¸ºä¸€ç»„æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ï¼Œè¿™äº›æ¡ä»¶æ¦‚ç‡æœ¬èº«æ˜¯ä»æ•°æ®é›†è®¡ç®—å¾—å‡ºçš„"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7(b)[128] shows how the UNKNOWN SENDER feature partitions the dataset.",
            "zh": "å›¾ 4.7ï¼ˆbï¼‰[128] æ˜¾ç¤ºäº† UNKNOWN SENDER ç‰¹å¾å¦‚ä½•å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "INFANTMORTALITY: The infant mortality rate (per 1,000 live births)",
            "zh": "å©´å„¿æ­»äº¡ç‡ï¼šå©´å„¿æ­»äº¡ç‡ï¼ˆæ¯1000åæ´»äº§å©´å„¿ï¼‰"
        }
    },
    {
        "translation": {
            "en": "The a(i), b(i), and s(i) values in Table 10.2[611] are calculated similarly for each other instance, and the overall silhouette for the clustering is the average of these values, in this case, 0.656. This suggests a reasonably good clustering.",
            "zh": "è¡¨ 10.2[611] ä¸­çš„ aï¼ˆiï¼‰ã€bï¼ˆiï¼‰ å’Œ sï¼ˆiï¼‰ å€¼çš„è®¡ç®—æ–¹å¼ç±»ä¼¼ï¼Œèšç±»çš„æ€»ä½“è½®å»“æ˜¯è¿™äº›å€¼çš„å¹³å‡å€¼ï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸º 0.656ã€‚è¿™è¡¨æ˜äº†ä¸€ä¸ªç›¸å½“å¥½çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Pearson correlation, 82, 223",
            "zh": "çš®å°”é€Šç›¸å…³æ€§ï¼Œ82,223"
        }
    },
    {
        "translation": {
            "en": "8. See Section 4.4.4[153].",
            "zh": "8. å‚è§ç¬¬ 4.4.4 èŠ‚[153]ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the rate of error reduction after each weight update will also decrease.",
            "zh": "ä½†æ˜¯ï¼Œæ¯æ¬¡æƒé‡æ›´æ–°åçš„é”™è¯¯å‡å°‘ç‡ä¹Ÿä¼šé™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "In two out of these three rows (d8 and d10), h is the case, so the conditional probability P(h | m) = 0.6666.",
            "zh": "åœ¨è¿™ä¸‰è¡Œä¸­çš„ä¸¤è¡Œï¼ˆd8 å’Œ d10ï¼‰ä¸­ï¼Œh æ˜¯è¿™ç§æƒ…å†µï¼Œå› æ­¤æ¡ä»¶æ¦‚ç‡ Pï¼ˆh | mï¼‰ = 0.6666ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) What will be the value of ct if",
            "zh": "ï¼ˆcï¼‰ å¦‚æœ ct çš„å€¼æ˜¯å¤šå°‘"
        }
    },
    {
        "translation": {
            "en": "AGE, a continuous feature listing the age of the individual;",
            "zh": "å¹´é¾„ï¼Œåˆ—å‡ºä¸ªäººå¹´é¾„çš„è¿ç»­ç‰¹å¾;"
        }
    },
    {
        "translation": {
            "en": "In this book we have presented some of the most commonly used prediction models and the machine learning algorithms used to build them.",
            "zh": "åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€äº›æœ€å¸¸ç”¨çš„é¢„æµ‹æ¨¡å‹ä»¥åŠç”¨äºæ„å»ºå®ƒä»¬çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.1 presents a schematic of the structure of a neuron that illustrates how the neuronâ€™s cell body, dendrites, and axon are interconnected and how one neuron connects to other neurons in the brain.",
            "zh": "å›¾ 8.1 æ˜¾ç¤ºäº†ç¥ç»å…ƒç»“æ„çš„ç¤ºæ„å›¾ï¼Œè¯´æ˜äº†ç¥ç»å…ƒçš„ç»†èƒä½“ã€æ ‘çªå’Œè½´çªå¦‚ä½•ç›¸äº’è¿æ¥ï¼Œä»¥åŠä¸€ä¸ªç¥ç»å…ƒå¦‚ä½•è¿æ¥åˆ°å¤§è„‘ä¸­çš„å…¶ä»–ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The second is the linkage method, â„’, that will be used to allow distances between whole clusters rather than just single instances to be compared.",
            "zh": "ç¬¬äºŒç§æ˜¯é“¾æ¥æ–¹æ³• Lï¼Œå®ƒå°†ç”¨äºæ¯”è¾ƒæ•´ä¸ªé›†ç¾¤ä¹‹é—´çš„è·ç¦»ï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This results in four candidate thresholds: â‰¥750, â‰¥1,350, â‰¥2,250, and â‰¥4,175.",
            "zh": "è¿™ä¼šäº§ç”Ÿå››ä¸ªå€™é€‰é˜ˆå€¼ï¼šâ‰¥750ã€â‰¥1,350ã€â‰¥2,250 å’Œ â‰¥4,175ã€‚"
        }
    },
    {
        "translation": {
            "en": "Leaky ReLUs always activate to some extent for every input; however, given that for z â‰¤ 0 the derivative of the rectifierleaky function is very small (0.01), a leaky ReLU with large negative weight will still learn very slowly.",
            "zh": "å¯¹äºæ¯ä¸ªè¾“å…¥ï¼Œæ³„æ¼çš„ ReLU æ€»æ˜¯åœ¨æŸç§ç¨‹åº¦ä¸Šæ¿€æ´»;ç„¶è€Œï¼Œé‰´äº z â‰¤ 0 æ•´æµå™¨æ³„æ¼å‡½æ•°çš„å¯¼æ•°éå¸¸å° ï¼ˆ0.01ï¼‰ï¼Œå…·æœ‰å¤§è´Ÿæƒé‡çš„æ³„æ¼ ReLU ä»ç„¶ä¼šå­¦ä¹ å¾—å¾ˆæ…¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Human Activity Recognition Using Smartphones Dataset, 636",
            "zh": "ä½¿ç”¨æ™ºèƒ½æ‰‹æœºçš„äººç±»æ´»åŠ¨è¯†åˆ«æ•°æ®é›†ï¼Œ636"
        }
    },
    {
        "translation": {
            "en": "stochastic gradient descent, 327, 415",
            "zh": "éšæœºæ¢¯åº¦ä¸‹é™ï¼Œ 327ï¼Œ 415"
        }
    },
    {
        "translation": {
            "en": "TP, 537",
            "zh": "TPï¼Œ 537"
        }
    },
    {
        "translation": {
            "en": "This means that each of the neurons in the output layer is equivalent to the McCulloch and Pitts neuron described in Section 8.2.1[384].",
            "zh": "è¿™æ„å‘³ç€è¾“å‡ºå±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ç­‰åŒäºç¬¬ 8.2.1 èŠ‚ä¸­æè¿°çš„ McCulloch å’Œ Pitts ç¥ç»å…ƒ[384]ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Yet another colleague has suggested that the ID feature would be a very effective at the root node of the tree. Would you agree with this suggestion?",
            "zh": "ï¼ˆbï¼‰ å¦ä¸€ä½åŒäº‹å»ºè®®ï¼ŒIDåŠŸèƒ½åœ¨æ ‘çš„æ ¹èŠ‚ç‚¹ä¸Šå°†éå¸¸æœ‰æ•ˆã€‚ä½ åŒæ„è¿™ä¸ªå»ºè®®å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "To plot an ROC curve, we create a chart with true positive rate on the vertical access and false positive rate (or 1 âˆ’ true negative rate) on the horizontal axis.14 The values for these measures, when any threshold value is used on a collection of score predictions, gives a point on this plot, or a point in receiver operating characteristic space (ROC space).",
            "zh": "ä¸ºäº†ç»˜åˆ¶ ROC æ›²çº¿ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå›¾è¡¨ï¼Œåœ¨å‚ç›´è®¿é—®ä¸Šå…·æœ‰çœŸé˜³æ€§ç‡ï¼Œåœ¨æ°´å¹³è½´ä¸Šå…·æœ‰å‡é˜³æ€§ç‡ï¼ˆæˆ– 1 âˆ’ çœŸé˜´æ€§ç‡ï¼‰.14 å½“ä»»ä½•é˜ˆå€¼ç”¨äºåˆ†æ•°é¢„æµ‹çš„é›†åˆæ—¶ï¼Œè¿™äº›åº¦é‡çš„å€¼åœ¨æ­¤å›¾ä¸Šç»™å‡ºäº†ä¸€ä¸ªç‚¹ï¼Œæˆ–åœ¨æ¥æ”¶å™¨å·¥ä½œç‰¹å¾ç©ºé—´ï¼ˆROC ç©ºé—´ï¼‰ä¸­ç»™å‡ºäº†ä¸€ä¸ªç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "margin extents, 361, 364",
            "zh": "è¾¹è·èŒƒå›´ï¼Œ 361ï¼Œ 364"
        }
    },
    {
        "translation": {
            "en": "We say that the naive Bayes model is naive because the assumption of conditional independence between the features in the evidence given the target level is a simplifying assumption that is made whether or not it is incorrect.",
            "zh": "æˆ‘ä»¬è¯´æœ´ç´ è´å¶æ–¯æ¨¡å‹æ˜¯æœ´ç´ çš„ï¼Œå› ä¸ºç»™å®šç›®æ ‡æ°´å¹³çš„è¯æ®ä¸­ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾æ˜¯ä¸€ä¸ªç®€åŒ–çš„å‡è®¾ï¼Œæ— è®ºå®ƒæ˜¯å¦ä¸æ­£ç¡®ï¼Œéƒ½ä¼šåšå‡ºè¿™ç§å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given these two pieces of information, we can compute the relative likelihood of a particular instance having a particular target level as",
            "zh": "ç»™å®šè¿™ä¸¤æ¡ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºç‰¹å®šå®ä¾‹å…·æœ‰ç‰¹å®šç›®æ ‡æ°´å¹³çš„ç›¸å¯¹å¯èƒ½æ€§ä¸º"
        }
    },
    {
        "translation": {
            "en": "Jaccard similarity measure, 635",
            "zh": "Jaccardç›¸ä¼¼åº¦é‡ï¼Œ635"
        }
    },
    {
        "translation": {
            "en": "bootstrap aggregating, 159",
            "zh": "å¼•å¯¼èšåˆï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "Technically, the derivative of the rectifier function is undefined when zk = 0, so strictly, the rectifier function is not an appropriate choice for gradient descent and backpropagation, which assume differentiable functions. However, a common practice in neural networks is to choose a derivative value for zk = 0 of zero, and we have integrated this convention into the definition of Equation (8.43)[437]. This convention has been found generally to work well.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œå½“ zk = 0 æ—¶ï¼Œæ•´æµå™¨å‡½æ•°çš„å¯¼æ•°æ˜¯æœªå®šä¹‰çš„ï¼Œå› æ­¤ä¸¥æ ¼æ¥è¯´ï¼Œæ•´æµå™¨å‡½æ•°ä¸æ˜¯æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­çš„åˆé€‚é€‰æ‹©ï¼Œæ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­å‡è®¾å¯å¾®å‡½æ•°ã€‚ç„¶è€Œï¼Œç¥ç»ç½‘ç»œä¸­çš„ä¸€ç§å¸¸è§åšæ³•æ˜¯ä¸º zk = 0 çš„é›¶é€‰æ‹©ä¸€ä¸ªå¯¼æ•°å€¼ï¼Œæˆ‘ä»¬å·²å°†æ­¤çº¦å®šé›†æˆåˆ°æ–¹ç¨‹ ï¼ˆ8.43ï¼‰[437] çš„å®šä¹‰ä¸­ã€‚äººä»¬æ™®éè®¤ä¸ºï¼Œè¿™ä¸€æƒ¯ä¾‹è¿ä½œè‰¯å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subjects: LCSH: Machine learning. | Data mining. | Prediction theory.",
            "zh": "ä¸»é¢˜ï¼šLCSHï¼šæœºå™¨å­¦ä¹ ã€‚|æ•°æ®æŒ–æ˜ã€‚|é¢„æµ‹ç†è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Moreover, reinforcement learning agents can often find exceptional solutions to problems that a human operator would not be aware of.",
            "zh": "æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ ä»£ç†é€šå¸¸å¯ä»¥ä¸ºäººç±»æ“ä½œå‘˜æ— æ³•æ„è¯†åˆ°çš„é—®é¢˜æ‰¾åˆ°ç‰¹æ®Šçš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This covers a deep theoretical framing of the reinforcement learning problem, as well as a collection of approaches including dynamic programming, Monte Carlo methods, temporal-difference learning, and other extensions.",
            "zh": "è¿™æ¶µç›–äº†å¼ºåŒ–å­¦ä¹ é—®é¢˜çš„æ·±å…¥ç†è®ºæ¡†æ¶ï¼Œä»¥åŠä¸€ç³»åˆ—æ–¹æ³•ï¼ŒåŒ…æ‹¬åŠ¨æ€è§„åˆ’ã€è’™ç‰¹å¡ç½—æ–¹æ³•ã€æ—¶å·®å­¦ä¹ å’Œå…¶ä»–æ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the entropy for this dataset.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—è¯¥æ•°æ®é›†çš„ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Bertsekas, Dimitri. 2017. Dynamic programming and optimal control. Athena Scientific.",
            "zh": "è´å°”å¡å¡æ–¯ï¼Œè¿ªç±³ç‰¹é‡Œã€‚2017. åŠ¨æ€è§„åˆ’ä¸ä¼˜åŒ–æ§åˆ¶.é›…å…¸å¨œç§‘å­¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "F measure, 549",
            "zh": "F æµ‹é‡ï¼Œ549"
        }
    },
    {
        "translation": {
            "en": "Given that the vanishing gradients exhibited in Figure 8.23(d)[453] are partly caused by the repeated multiplication by small weights, we can try to avoid this problem by making the network weights larger.",
            "zh": "é‰´äºå›¾8.23ï¼ˆdï¼‰[453]ä¸­æ˜¾ç¤ºçš„æ¢¯åº¦æ¶ˆå¤±éƒ¨åˆ†æ˜¯ç”±å°æƒé‡çš„é‡å¤ä¹˜æ³•å¼•èµ·çš„ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•é€šè¿‡ä½¿ç½‘ç»œæƒé‡æ›´å¤§æ¥é¿å…è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Flags: Flags are binary features that indicate the presence or absence of some characteristic within a dataset. For example, a flag indicating whether or not a bank account has ever been overdrawn might be a useful descriptive feature.",
            "zh": "æ ‡å¿—ï¼šæ ‡å¿—æ˜¯äºŒè¿›åˆ¶ç‰¹å¾ï¼Œç”¨äºæŒ‡ç¤ºæ•°æ®é›†ä¸­æ˜¯å¦å­˜åœ¨æŸäº›ç‰¹å¾ã€‚ä¾‹å¦‚ï¼ŒæŒ‡ç¤ºé“¶è¡Œè´¦æˆ·æ˜¯å¦æ›¾ç»é€æ”¯çš„æ ‡å¿—å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æè¿°æ€§åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each of the data quality issues found, we include the feature it was found in and the details of the data quality issue.",
            "zh": "å¯¹äºå‘ç°çš„æ¯ä¸ªæ•°æ®è´¨é‡é—®é¢˜ï¼Œæˆ‘ä»¬éƒ½ä¼šåŒ…æ‹¬å‘ç°å®ƒçš„åŠŸèƒ½ä»¥åŠæ•°æ®è´¨é‡é—®é¢˜çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward computational flow through the LSTM input gates include an elementwise addition of two activation vectors.",
            "zh": "é€šè¿‡ LSTM è¾“å…¥é—¨çš„å‰å‘è®¡ç®—æµç¨‹åŒ…æ‹¬ä¸¤ä¸ªæ¿€æ´»å‘é‡çš„å…ƒç´ ç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a domain with one target feature and nine descriptive features, all of which are binary, the full joint probability distribution will contain 210 = 1,024 probabilities.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å…·æœ‰ä¸€ä¸ªç›®æ ‡ç‰¹å¾å’Œä¹ä¸ªæè¿°æ€§ç‰¹å¾ï¼ˆæ‰€æœ‰ç‰¹å¾éƒ½æ˜¯äºŒè¿›åˆ¶çš„ï¼‰çš„åŸŸä¸­ï¼Œå®Œæ•´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå°†åŒ…å« 210 = 1,024 ä¸ªæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "document classification, 4, 223",
            "zh": "æ–‡ä»¶åˆ†ç±»ï¼Œ 4ï¼Œ 223"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11(b)[561] shows three such points in ROC space and associated confusion matrices for the email classification dataset for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "å›¾ 9.11ï¼ˆbï¼‰[561] æ˜¾ç¤ºäº† ROC ç©ºé—´ä¸­çš„ä¸‰ä¸ªæ­¤ç±»ç‚¹ä»¥åŠé˜ˆå€¼ä¸º 0.25ã€0.5 å’Œ 0.75 çš„ç”µå­é‚®ä»¶åˆ†ç±»æ•°æ®é›†çš„ç›¸å…³æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.7[347] shows an extended version of the generators dataset given in Table 7.6[339], including extra instances that make the separation between good generators and faulty generators less clear cut.",
            "zh": "è¡¨ 7.7[347] æ˜¾ç¤ºäº†è¡¨ 7.6[339] ä¸­ç»™å‡ºçš„å‘ç”µæœºæ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ï¼ŒåŒ…æ‹¬ä½¿è‰¯å¥½å‘ç”µæœºå’Œæ•…éšœå‘ç”µæœºä¹‹é—´åŒºåˆ†ä¸å¤ªæ¸…æ™°çš„é¢å¤–å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This case study2 describes the work undertaken when, in 2011, the SDSS hired Jocelyn, an analytics professional, to build a galaxy morphology classification model to include in their data processing pipeline. The remainder of this chapter describes the work undertaken by Jocelyn on this project within each phase of the CRISP-DM process.",
            "zh": "æœ¬æ¡ˆä¾‹ç ”ç©¶2æè¿°äº†2011å¹´SDSSè˜è¯·åˆ†æä¸“å®¶Jocelynæ„å»ºæ˜Ÿç³»å½¢æ€åˆ†ç±»æ¨¡å‹ä»¥çº³å…¥å…¶æ•°æ®å¤„ç†ç®¡é“æ—¶æ‰€åšçš„å·¥ä½œã€‚æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†æè¿°äº† Jocelyn åœ¨ CRISP-DM æµç¨‹çš„æ¯ä¸ªé˜¶æ®µå¯¹è¯¥é¡¹ç›®æ‰€åšçš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Remember, we refer to each value that a particular categorical feature can take as the levels of the categorical feature.",
            "zh": "2. è¯·è®°ä½ï¼Œæˆ‘ä»¬å°†ç‰¹å®šåˆ†ç±»ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„æ¯ä¸ªå€¼ç§°ä¸ºåˆ†ç±»ç‰¹å¾çš„çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "(f) The final ensemble model trained after 20 iterations of gradient boosting.",
            "zh": "ï¼ˆfï¼‰ ç»è¿‡ 20 æ¬¡æ¢¯åº¦æå‡è¿­ä»£åè®­ç»ƒçš„æœ€ç»ˆé›†æˆæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.15",
            "zh": "è¡¨ 4.15"
        }
    },
    {
        "translation": {
            "en": "There is some argument in the reinforcement learning literature about whether the reward that follows an action, at, taken in a state, st, should be referred to as rt or rt+1.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ æ–‡çŒ®ä¸­ï¼Œå…³äºåœ¨çŠ¶æ€ st ä¸­é‡‡å–çš„åŠ¨ä½œä¹‹åçš„å¥–åŠ±æ˜¯å¦åº”è¯¥ç§°ä¸º rt æˆ– rt+1ï¼Œå­˜åœ¨ä¸€äº›äº‰è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of âˆ‚â„°/âˆ‚ak for output neurons is dependent on the error function9 that is used during training. We have already introduced the sum of squared errors, or L2, error function (see Equation 7.4[316]), repeated here for convenience",
            "zh": "è¾“å‡ºç¥ç»å…ƒçš„ âˆ‚E/âˆ‚ak è®¡ç®—å–å†³äºè®­ç»ƒæœŸé—´ä½¿ç”¨çš„è¯¯å·®å‡½æ•°9ã€‚æˆ‘ä»¬å·²ç»ä»‹ç»äº†è¯¯å·®çš„å¹³æ–¹å’Œï¼Œæˆ–L2ï¼Œè¯¯å·®å‡½æ•°ï¼ˆå‚è§å…¬å¼7.4[316]ï¼‰ï¼Œä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œè¿™é‡Œé‡å¤äº†ä¸€é"
        }
    },
    {
        "translation": {
            "en": "text analytics, 262",
            "zh": "æ–‡æœ¬åˆ†æï¼Œ262"
        }
    },
    {
        "translation": {
            "en": "The fact that we have emphasized feature selection in this chapter does not mean that it is not important to predictive analytics in general.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬ç« ä¸­å¼ºè°ƒç‰¹å¾é€‰æ‹©è¿™ä¸€äº‹å®å¹¶ä¸æ„å‘³ç€å®ƒå¯¹ä¸€èˆ¬çš„é¢„æµ‹åˆ†æä¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case good is the positive level and set to + 1, and faulty is the negative level and set to âˆ’ 1.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼Œgood æ˜¯æ­£ç”µå¹³ï¼Œè®¾ç½®ä¸º + 1ï¼Œfaulty æ˜¯è´Ÿç”µå¹³ï¼Œè®¾ç½®ä¸º âˆ’ 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the time Literary Digest was a well-known magazine that had accurately predicted the outcomes of previous presidential elections.",
            "zh": "å½“æ—¶ï¼Œã€Šæ–‡å­¦æ–‡æ‘˜ã€‹æ˜¯ä¸€æœ¬è‘—åçš„æ‚å¿—ï¼Œå®ƒå‡†ç¡®åœ°é¢„æµ‹äº†å†å±Šæ€»ç»Ÿé€‰ä¸¾çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390] when all the neurons are ReLUs.",
            "zh": "å½“æ‰€æœ‰ç¥ç»å…ƒéƒ½æ˜¯ ReLU æ—¶ï¼Œè¡¨ 8.3[423] ä¸­åˆ—å‡ºçš„ç¤ºä¾‹é€šè¿‡å›¾ 8.4[390] ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once a company has been registered, it must provide a tax return at the end of every financial year.",
            "zh": "å…¬å¸æ³¨å†Œåï¼Œå¿…é¡»åœ¨æ¯ä¸ªè´¢æ”¿å¹´åº¦ç»“æŸæ—¶æä¾›çº³ç¨ç”³æŠ¥è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A burn-in of 30 iterations was used, and the samples were thinned by sub-sampling every 7th iteration.",
            "zh": "ä½¿ç”¨äº† 30 æ¬¡è¿­ä»£çš„è€åŒ–ï¼Œå¹¶ä¸”æ¯ 7 æ¬¡è¿­ä»£é€šè¿‡å­é‡‡æ ·æ¥ç¨€é‡Šæ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The middle plot shows a similar plot for the OR function, and again it is possible to draw a single straight line to separate the two classes of inputs.",
            "zh": "ä¸­é—´çš„å›¾æ˜¾ç¤ºäº†ORå‡½æ•°çš„ç±»ä¼¼å›¾ï¼ŒåŒæ ·å¯ä»¥ç”»ä¸€æ¡ç›´çº¿æ¥åˆ†éš”ä¸¤ç±»è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "This assignment of blame back to the neurons connecting into a neuron is dependent on the weight on the connection between the neurons and also on the activation of the hidden neuron during the forward pass.",
            "zh": "è¿™ç§å°†è´£ä»»å½’å’äºè¿æ¥åˆ°ç¥ç»å…ƒçš„ç¥ç»å…ƒçš„åˆ†é…å–å†³äºç¥ç»å…ƒä¹‹é—´è¿æ¥çš„æƒé‡ï¼Œä¹Ÿå–å†³äºå‰å‘ä¼ é€’è¿‡ç¨‹ä¸­éšè—ç¥ç»å…ƒçš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "where cov(a,b) is the covariance between features a and b and sd(a) and sd(b) are the standard deviations of a and b respectively.",
            "zh": "å…¶ä¸­ Covï¼ˆaï¼Œbï¼‰ æ˜¯ç‰¹å¾ A å’Œ B ä¹‹é—´çš„åæ–¹å·®ï¼ŒSDï¼ˆAï¼‰ å’Œ SDï¼ˆBï¼‰ åˆ†åˆ«æ˜¯ A å’Œ B çš„æ ‡å‡†å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weights in this network have been initialized so that all the bias terms are equal to + 1.0 and the other weights are listed in the weight matrices shown in Figure 8.28[470].",
            "zh": "è¯¥ç½‘ç»œä¸­çš„æƒé‡å·²ç»åˆå§‹åŒ–ï¼Œå› æ­¤æ‰€æœ‰åå·®é¡¹éƒ½ç­‰äº + 1.0ï¼Œå…¶ä»–æƒé‡åˆ—åœ¨å›¾ 8.28[470] æ‰€ç¤ºçš„æƒé‡çŸ©é˜µä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is, however, a simple approach to learning weights that we can take based on the facts that, even though they are hard to visualize, the error surfaces that correspond to these high-dimensional weight spaces still have the convex shape seen in Figure 7.3[318] (albeit in multiple dimensions), and that a single global minimum exists. This approach uses a guided search from a random starting position and is known as gradient descent.",
            "zh": "ç„¶è€Œï¼Œæœ‰ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥å­¦ä¹ æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºä»¥ä¸‹äº‹å®ï¼šå³ä½¿å®ƒä»¬å¾ˆéš¾å¯è§†åŒ–ï¼Œä¸è¿™äº›é«˜ç»´æƒé‡ç©ºé—´ç›¸å¯¹åº”çš„è¯¯å·®æ›²é¢ä»ç„¶å…·æœ‰å›¾7.3[318]æ‰€ç¤ºçš„å‡¸å½¢ï¼ˆå°½ç®¡æ˜¯å¤šç»´çš„ï¼‰ï¼Œå¹¶ä¸”å­˜åœ¨å•ä¸ªå…¨å±€æœ€å°å€¼ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨ä»éšæœºèµ·å§‹ä½ç½®çš„å¼•å¯¼å¼æœç´¢ï¼Œç§°ä¸ºæ¢¯åº¦ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The differences in central tendency and variation between levels can, however, be easier to see in box plots.",
            "zh": "ç„¶è€Œï¼Œåœ¨ç®±å½¢å›¾ä¸­æ›´å®¹æ˜“çœ‹åˆ°ä¸­å¿ƒè¶‹åŠ¿å’Œæ°´å¹³ä¹‹é—´å˜åŒ–çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adding this padding to the image increases the number of neurons required to cover the image, assuming that the filter size and horizontal and vertical strides are maintained.",
            "zh": "åœ¨å›¾åƒä¸­æ·»åŠ æ­¤å¡«å……ä¼šå¢åŠ è¦†ç›–å›¾åƒæ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡ï¼Œå‰ææ˜¯ä¿æŒæ»¤é•œå¤§å°ä»¥åŠæ°´å¹³å’Œå‚ç›´æ­¥å¹…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Technically, this property is described as the model being equivariant to the translation of features.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œæ­¤å±æ€§è¢«æè¿°ä¸ºæ¨¡å‹ä¸ç‰¹å¾çš„å¹³ç§»ç­‰å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The (a) gain and (b) cumulative gain at each decile for the email predictions given in Table 9.11[557].",
            "zh": "è¡¨9.11[557]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶é¢„æµ‹åœ¨æ¯ä¸ªååˆ†ä½æ•°å¤„çš„ï¼ˆaï¼‰å¢ç›Šå’Œï¼ˆbï¼‰ç´¯ç§¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "true negative rate, 548, 558",
            "zh": "çœŸé˜´æ€§ç‡ï¼Œ548,558"
        }
    },
    {
        "translation": {
            "en": "6.2â€ƒFundamentals",
            "zh": "6.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "Similar to k-fold cross validation, the Îµ0 bootstrap iteratively performs multiple evaluation experiments using sightly different training and test sets each time to evaluate the expected performance of a model.",
            "zh": "ä¸ k å€äº¤å‰éªŒè¯ç±»ä¼¼ï¼ŒÎµ0 å¼•å¯¼ç¨‹åºæ¯æ¬¡éƒ½ä½¿ç”¨æˆªç„¶ä¸åŒçš„è®­ç»ƒå’Œæµ‹è¯•é›†è¿­ä»£æ‰§è¡Œå¤šä¸ªè¯„ä¼°å®éªŒï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„é¢„æœŸæ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on Table B.1[758], the probability of the event DICE1 = is1",
            "zh": "æ ¹æ®è¡¨ B.1[758]ï¼Œäº‹ä»¶ DICE1 = çš„æ¦‚ç‡ä¸º 1"
        }
    },
    {
        "translation": {
            "en": "For example, we can use information gain30 as a filter in a rank and prune approach.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ’åå’Œä¿®å‰ªæ–¹æ³•ä¸­ä½¿ç”¨ä¿¡æ¯å¢ç›Š30ä½œä¸ºè¿‡æ»¤å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning models are being used for a more diverse range of applications than ever before, and new developments in machine learning methods are opening up even more opportunities.",
            "zh": "æœºå™¨å­¦ä¹ æ¨¡å‹è¢«ç”¨äºæ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´å¤šæ ·åŒ–çš„åº”ç”¨ï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„æ–°å‘å±•æ­£åœ¨å¼€è¾Ÿæ›´å¤šçš„æœºä¼šã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure each rectangle represents a state in the search space that is a particular feature subset.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œæ¯ä¸ªçŸ©å½¢è¡¨ç¤ºæœç´¢ç©ºé—´ä¸­çš„ä¸€ä¸ªçŠ¶æ€ï¼Œè¯¥çŠ¶æ€æ˜¯ç‰¹å®šåŠŸèƒ½å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder can be trained to learn a more compact representation of these images.",
            "zh": "å¯ä»¥è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨æ¥å­¦ä¹ è¿™äº›å›¾åƒçš„æ›´ç´§å‡‘çš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "AUC, 561",
            "zh": "AUCï¼Œ561"
        }
    },
    {
        "translation": {
            "en": "Part III covers fundamental techniques in machine learning beyond the supervised machine learning approaches described in Part II. Chapter 10 describes unsupervised machine learning, and Chapter 11 describes reinforcement learning. These chapters follow the same two-part structure as the chapters in Part II.",
            "zh": "ç¬¬ä¸‰éƒ¨åˆ†æ¶µç›–äº†æœºå™¨å­¦ä¹ çš„åŸºæœ¬æŠ€æœ¯ï¼Œè¶…å‡ºäº†ç¬¬äºŒéƒ¨åˆ†ä¸­æè¿°çš„ç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚ç¬¬ 10 ç« ä»‹ç»äº†æ— ç›‘ç£æœºå™¨å­¦ä¹ ï¼Œç¬¬ 11 ç« ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ ã€‚è¿™äº›ç« èŠ‚éµå¾ªä¸ç¬¬äºŒéƒ¨åˆ†ç« èŠ‚ç›¸åŒçš„ä¸¤éƒ¨åˆ†ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "where Ï€(st+1,at+1) returns the likelihood of taking action at+1 from state st+1 under policy Ï€, and QÏ€(st+1,at+1) is a recursive call to the action-value function itself.",
            "zh": "å…¶ä¸­ Ï€ï¼ˆst+1ï¼Œat+1ï¼‰ è¿”å›ç­–ç•¥ Ï€ ä¸‹çŠ¶æ€ st+1 åœ¨ at+1 ä¸Šé‡‡å–è¡ŒåŠ¨çš„å¯èƒ½æ€§ï¼ŒQÏ€ï¼ˆst+1ï¼Œat+1ï¼‰ æ˜¯å¯¹åŠ¨ä½œå€¼å‡½æ•°æœ¬èº«çš„é€’å½’è°ƒç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "27. The data in this question has been artificially created but is inspired by the famous Wisconsin breast cancer dataset first described in Mangasarian and Wolberg (1990) and is available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "27. æœ¬é—®é¢˜ä¸­çš„æ•°æ®æ˜¯äººå·¥åˆ›å»ºçš„ï¼Œä½†çµæ„Ÿæ¥è‡ªè‘—åçš„å¨æ–¯åº·æ˜Ÿå·ä¹³è…ºç™Œæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é¦–æ¬¡åœ¨ Mangasarian å’Œ Wolberg ï¼ˆ1990ï¼‰ ä¸­æè¿°ï¼Œå¯ä» UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBache å’Œ Lichmanï¼Œ2013 å¹´ï¼‰è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "stunted trees, 701",
            "zh": "å‘è‚²ä¸è‰¯çš„æ ‘æœ¨ï¼Œ701"
        }
    },
    {
        "translation": {
            "en": "At this point the retrieval process will have executed Lines 1â€“7 of the algorithm.",
            "zh": "æ­¤æ—¶ï¼Œæ£€ç´¢è¿‡ç¨‹å°†æ‰§è¡Œç®—æ³•çš„ç¬¬ 1-7 è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "PEAKRATIOCHANGEPCT",
            "zh": "å³°å€¼æ¯”ç‡å˜åŒ–PCT"
        }
    },
    {
        "translation": {
            "en": "Returning to our loan application fraud detection example, we will show how binning can be used to include the LOAN AMOUNT feature (see Table 6.11[278]) in a naive Bayes prediction model for this scenario.",
            "zh": "å›åˆ°æˆ‘ä»¬çš„è´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨åˆ†ç®±æ¥åŒ…å«æ­¤åœºæ™¯çš„æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹ä¸­çš„ LOAN AMOUNT ç‰¹å¾ï¼ˆå‚è§è¡¨ 6.11[278]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this approach were to be used for the AMOUNT RECEIVED feature from the motor claims insurance fraud detection scenario, then the upper and lower thresholds would be defined as follows:",
            "zh": "å¦‚æœå°†æ­¤æ–¹æ³•ç”¨äºæ±½è½¦ç´¢èµ”ä¿é™©æ¬ºè¯ˆæ£€æµ‹æ–¹æ¡ˆä¸­çš„â€œæ”¶åˆ°é‡‘é¢â€ç‰¹å¾ï¼Œåˆ™ä¸Šé™å’Œä¸‹é™é˜ˆå€¼å°†å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "3.5.1.1â€ƒVisualizing pairs of continuous featuresâ€ƒThe scatter plot is one of the most important tools in data visualization.",
            "zh": "3.5.1.1 è¿ç»­ç‰¹å¾å¯¹çš„å¯è§†åŒ– æ•£ç‚¹å›¾æ˜¯æ•°æ®å¯è§†åŒ–ä¸­æœ€é‡è¦çš„å·¥å…·ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "To summarize, although the inclusion of a non-linear activation function within neurons in a network enables the network to represent non-linear mappings from inputs to outputs, the selection of which non-linear function we use can have a significant effect on the training speed of a deep network.",
            "zh": "æ€»è€Œè¨€ä¹‹ï¼Œå°½ç®¡åœ¨ç½‘ç»œä¸­çš„ç¥ç»å…ƒä¸­åŒ…å«éçº¿æ€§æ¿€æ´»å‡½æ•°ä½¿ç½‘ç»œèƒ½å¤Ÿè¡¨ç¤ºä»è¾“å…¥åˆ°è¾“å‡ºçš„éçº¿æ€§æ˜ å°„ï¼Œä½†æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨å“ªç§éçº¿æ€§å‡½æ•°ä¼šå¯¹æ·±åº¦ç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦äº§ç”Ÿé‡å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The task of the output gate is to decide which parts of the ct should be passed to the output layer of the network and on to the next time-step as the propagated hidden state.",
            "zh": "è¾“å‡ºé—¨çš„ä»»åŠ¡æ˜¯å†³å®š ct çš„å“ªäº›éƒ¨åˆ†åº”è¯¥ä¼ é€’åˆ°ç½‘ç»œçš„è¾“å‡ºå±‚ï¼Œå¹¶ä½œä¸ºä¼ æ’­çš„éšè—çŠ¶æ€ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "machine learning algorithm, 6, 19",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œ 6ï¼Œ 19"
        }
    },
    {
        "translation": {
            "en": "inductive bias, 11, 11, 19, 22, 123, 141, 328, 357, 362, 729, 736",
            "zh": "ç”µæ„Ÿåç½®ï¼Œ 11ï¼Œ 11ï¼Œ 19ï¼Œ 22ï¼Œ 123ï¼Œ 141ï¼Œ 328ï¼Œ 357ï¼Œ 362ï¼Œ 729ï¼Œ 736"
        }
    },
    {
        "translation": {
            "en": "iteration, 416",
            "zh": "è¿­ä»£ï¼Œ416"
        }
    },
    {
        "translation": {
            "en": "Each row in a dataset represents an experiment, which associates a target feature value with a set of descriptive feature values, and the assignment of a set of descriptive features with values is an event.",
            "zh": "æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œéƒ½è¡¨ç¤ºä¸€ä¸ªå®éªŒï¼Œè¯¥å®éªŒå°†ç›®æ ‡è¦ç´ å€¼ä¸ä¸€ç»„æè¿°æ€§è¦ç´ å€¼ç›¸å…³è”ï¼Œå¹¶ä¸”å°†ä¸€ç»„æè¿°æ€§è¦ç´ ä¸å€¼çš„èµ‹å€¼æ˜¯ä¸€ä¸ªäº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.5",
            "zh": "è¡¨ 1.5"
        }
    },
    {
        "translation": {
            "en": "The reason why keeping the behavior of a network across its layers similar is useful in creating deep networks is that it allows us to add more layers to the network.",
            "zh": "åœ¨åˆ›å»ºæ·±åº¦ç½‘ç»œæ—¶ï¼Œä¿æŒç½‘ç»œå„å±‚è¡Œä¸ºç›¸ä¼¼çš„åŸå› æ˜¯ï¼Œå®ƒå…è®¸æˆ‘ä»¬å‘ç½‘ç»œæ·»åŠ æ›´å¤šå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each link in this chain of products is the rate of change of the output of a function (loss function, activation function, or weighted sum function) with respect to one of its inputs. Working from a network weight wi,k forward toward the network error, we have",
            "zh": "è¯¥ä¹˜ç§¯é“¾ä¸­çš„æ¯ä¸ªç¯èŠ‚éƒ½æ˜¯å‡½æ•°è¾“å‡ºï¼ˆæŸå¤±å‡½æ•°ã€æ¿€æ´»å‡½æ•°æˆ–åŠ æƒå’Œå‡½æ•°ï¼‰ç›¸å¯¹äºå…¶è¾“å…¥ä¹‹ä¸€çš„å˜åŒ–ç‡ã€‚ä»ç½‘ç»œæƒé‡ wiï¼Œk å‘å‰å‘ç½‘ç»œé”™è¯¯å·¥ä½œï¼Œæˆ‘ä»¬æœ‰"
        }
    },
    {
        "translation": {
            "en": "The zig-zagging line in Figure 7.24(a)[368] shows an example journey across an error surface, and Figure 7.24(b)[368] shows the reduction in the sum of squared errors as the search for the optimal weights progresses down the error surface.",
            "zh": "å›¾7.24ï¼ˆaï¼‰[368]ä¸­çš„é”¯é½¿å½¢çº¿æ˜¾ç¤ºäº†ç©¿è¶Šè¯¯å·®è¡¨é¢çš„ç¤ºä¾‹æ—…ç¨‹ï¼Œå›¾7.24ï¼ˆbï¼‰[368]æ˜¾ç¤ºäº†éšç€è¯¯å·®è¡¨é¢å¯¹æœ€ä½³æƒé‡çš„æœç´¢ï¼Œå¹³æ–¹è¯¯å·®æ€»å’Œçš„å‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1.1â€ƒCentral Tendency",
            "zh": "A.1.1 é›†ä¸­è¶‹åŠ¿"
        }
    },
    {
        "translation": {
            "en": "This figure contains 16 subfigures, with each subfigure containing a matrix of input data (on the left) representing the input image and a grid of 16 circles (on the right) in which each circle represents a neuron.",
            "zh": "è¯¥å›¾åŒ…å« 16 ä¸ªå­å›¾ï¼Œæ¯ä¸ªå­å›¾åŒ…å«ä¸€ä¸ªè¾“å…¥æ•°æ®çŸ©é˜µï¼ˆå·¦ä¾§ï¼‰ä»£è¡¨è¾“å…¥å›¾åƒå’Œä¸€ä¸ªç”± 16 ä¸ªåœ†åœˆï¼ˆå³ä¾§ï¼‰ç»„æˆçš„ç½‘æ ¼ï¼Œå…¶ä¸­æ¯ä¸ªåœ†åœˆä»£è¡¨ä¸€ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.12",
            "zh": "å›¾ 7.12"
        }
    },
    {
        "translation": {
            "en": "8.2.5â€…â€…â€…Why Is Network Depth Important?",
            "zh": "8.2.5 ä¸ºä»€ä¹ˆç½‘ç»œæ·±åº¦å¾ˆé‡è¦ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 13.6[717] shows histograms for these features.",
            "zh": "å›¾13.6[717]æ˜¾ç¤ºäº†è¿™äº›ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Caruana, Rich, and Alexandru Niculescu-Mizil. 2006. An empirical comparison of supervised learning algorithms. In Proceedings of the 23rd international conference on machine learning, 161â€“168. ACM.",
            "zh": "å¡é²é˜¿çº³ã€é‡Œå¥‡å’Œäºšå†å±±å¾·é²Â·å°¼å¤åˆ—æ–¯åº“-ç±³é½å°”ã€‚2006. ç›‘ç£å­¦ä¹ ç®—æ³•çš„å®è¯æ¯”è¾ƒ.åœ¨ç¬¬ 23 å±Šæœºå™¨å­¦ä¹ å›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œ161â€“168ã€‚ACMã€‚"
        }
    },
    {
        "translation": {
            "en": "The leaky rectified linear function has a small (predefined) non-zero gradient when z < 0. Maas et al. (2013) set the non-zero gradient for z < 0 to 0.01, giving the following definition of this function:",
            "zh": "å½“ z < 0 æ—¶ï¼Œæ³„æ¼æ•´æµçº¿æ€§å‡½æ•°å…·æœ‰å°çš„ï¼ˆé¢„å®šä¹‰çš„ï¼‰éé›¶æ¢¯åº¦ã€‚Maasç­‰äººï¼ˆ2013ï¼‰å°†zçš„éé›¶æ¢¯åº¦è®¾ç½®ä¸º0<0åˆ°0.01ï¼Œç»™å‡ºäº†è¯¥å‡½æ•°çš„ä»¥ä¸‹å®šä¹‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "To make these judgments it is necessary to have a normalized, domain independent measure of model performance.",
            "zh": "ä¸ºäº†åšå‡ºè¿™äº›åˆ¤æ–­ï¼Œæœ‰å¿…è¦å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œæ ‡å‡†åŒ–çš„ã€ä¸é¢†åŸŸæ— å…³çš„æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "where w[j] is a single weight from the set of weights w. Applying the chain rule to this, we get",
            "zh": "å…¶ä¸­ w[j] æ˜¯æƒé‡ w é›†åˆä¸­çš„å•ä¸ªæƒé‡ã€‚å°†é“¾å¼æ³•åˆ™åº”ç”¨äºæ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "In churn analysis, and in any sort of propensity modeling, change is usually a key driver of customer behavior.",
            "zh": "åœ¨å®¢æˆ·æµå¤±åˆ†æå’Œä»»ä½•ç±»å‹çš„å€¾å‘å»ºæ¨¡ä¸­ï¼Œå˜åŒ–é€šå¸¸æ˜¯å®¢æˆ·è¡Œä¸ºçš„å…³é”®é©±åŠ¨å› ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that the training set will remain relatively stable, this time issue can be offset by investing in some one-off computation to create an index of the instances that enables efficient retrieval of the nearest neighbors without doing an exhaustive search of the entire dataset.",
            "zh": "å‡è®¾è®­ç»ƒé›†å°†ä¿æŒç›¸å¯¹ç¨³å®šï¼Œåˆ™å¯ä»¥é€šè¿‡æŠ•èµ„ä¸€äº›ä¸€æ¬¡æ€§è®¡ç®—æ¥åˆ›å»ºå®ä¾‹ç´¢å¼•æ¥æŠµæ¶ˆæ­¤æ—¶é—´é—®é¢˜ï¼Œä»è€Œå¯ä»¥æœ‰æ•ˆåœ°æ£€ç´¢æœ€è¿‘é‚»ï¼Œè€Œæ— éœ€å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œè¯¦å°½çš„æœç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "In cases with very small datasets (approximately fewer than 300 instances), bootstrapping approaches are preferred over cross validation approaches.",
            "zh": "å¯¹äºæ•°æ®é›†éå¸¸å°ï¼ˆå¤§çº¦å°‘äº 300 ä¸ªå®ä¾‹ï¼‰çš„æƒ…å†µï¼Œå¼•å¯¼æ–¹æ³•ä¼˜äºäº¤å‰éªŒè¯æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.13â€…â€…â€…A selection of the logistic regression models developed during the gradient descent process for the machinery dataset from Table 7.6[339]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.13 è¡¨7.6[339]ä¸­æœºæ¢°æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„é€»è¾‘å›å½’æ¨¡å‹çš„é€‰æ‹©ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The Theorem of Total Probability is a formal specification of the summing out process we introduced earlier in Section B.2[761].",
            "zh": "æ€»æ¦‚ç‡å®šç†æ˜¯æˆ‘ä»¬å‰é¢åœ¨B.2èŠ‚[761]ä¸­ä»‹ç»çš„æ±‚å’Œè¿‡ç¨‹çš„æ­£å¼è§„èŒƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For the purposes of the case study, we assume that after the feasibility review, it was decided to proceed with the claim prediction solution, in which a model will be built that can predict the likelihood that an insurance claim is fraudulent.",
            "zh": "å‡ºäºæ¡ˆä¾‹ç ”ç©¶çš„ç›®çš„ï¼Œæˆ‘ä»¬å‡è®¾åœ¨å¯è¡Œæ€§å®¡æŸ¥ä¹‹åï¼Œå†³å®šç»§ç»­è¿›è¡Œç´¢èµ”é¢„æµ‹è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­å°†å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ä¿é™©ç´¢èµ”æ¬ºè¯ˆçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for a query with CH = paid, GC = none, and ACC = rent, and the calculation of the scores for each target level.",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹å¯¹ CH = paidã€GC = none å’Œ ACC = rent çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ï¼Œä»¥åŠæ¯ä¸ªç›®æ ‡çº§åˆ«çš„åˆ†æ•°è®¡ç®—æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, typically the local receptive fields of neurons in a sub-sampling layer do not overlap (in contrast with the overlapping receptive fields used when we arrange neurons to convolve a filter).",
            "zh": "ç„¶è€Œï¼Œé€šå¸¸å­é‡‡æ ·å±‚ä¸­ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ä¸ä¼šé‡å ï¼ˆä¸æˆ‘ä»¬å®‰æ’ç¥ç»å…ƒå·ç§¯æ»¤æ³¢å™¨æ—¶ä½¿ç”¨çš„é‡å æ„Ÿå—é‡ç›¸åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, we donâ€™t necessarily have to normalize the scores for each target levelâ€”something we would have to do if we wanted the actual probabilities.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬ä¸å¿…å¯¹æ¯ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°è¿›è¡Œæ ‡å‡†åŒ–â€”â€”å¦‚æœæˆ‘ä»¬æƒ³è¦å®é™…æ¦‚ç‡ï¼Œæˆ‘ä»¬å°±å¿…é¡»è¿™æ ·åšã€‚"
        }
    },
    {
        "translation": {
            "en": "9.6â€ƒFurther Reading",
            "zh": "9.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "The auto-encoders presented in this chapter are fairly simple, and more sophisticated approaches have emerged, for example, convolutional auto-encoders, de-noising auto-encoders, and variational auto-encoders. Guo et al. (2016) provide a readable, coherent overview of these different types.",
            "zh": "æœ¬ç« ä»‹ç»çš„è‡ªåŠ¨ç¼–ç å™¨ç›¸å½“ç®€å•ï¼Œå¹¶ä¸”å‡ºç°äº†æ›´å¤æ‚çš„æ–¹æ³•ï¼Œä¾‹å¦‚å·ç§¯è‡ªåŠ¨ç¼–ç å™¨ã€å»å™ªè‡ªåŠ¨ç¼–ç å™¨å’Œå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ã€‚Guo et al. ï¼ˆ2016ï¼‰ å¯¹è¿™äº›ä¸åŒç±»å‹çš„è¿›è¡Œäº†å¯è¯»ã€è¿è´¯çš„æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "35. The variance of the product of two independent random variables X and Y is given by var(X Ã— Y) = [E(X)]2var(Y ) + [E(Y )]2var(X) + var(X)var(Y ).",
            "zh": "35. ä¸¤ä¸ªè‡ªéšæœºå˜é‡ X å’Œ Y çš„ä¹˜ç§¯æ–¹å·®ç”± varï¼ˆX Ã— Yï¼‰ = [Eï¼ˆXï¼‰]2varï¼ˆY ï¼‰ + [Eï¼ˆY ï¼‰]2varï¼ˆXï¼‰ + varï¼ˆXï¼‰varï¼ˆYï¼‰ ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "basis functions, 351, 365, 368",
            "zh": "åŸºå‡½æ•°ï¼Œ 351ï¼Œ 365ï¼Œ 368"
        }
    },
    {
        "translation": {
            "en": "When this happens, most of the queries will be in locations where none of the training instances are nearby, and as a result, the predictive power of the models based on these training instances will begin to decrease.",
            "zh": "å‘ç”Ÿè¿™ç§æƒ…å†µæ—¶ï¼Œå¤§å¤šæ•°æŸ¥è¯¢å°†ä½äºé™„è¿‘æ²¡æœ‰è®­ç»ƒå®ä¾‹çš„ä½ç½®ï¼Œå› æ­¤ï¼ŒåŸºäºè¿™äº›è®­ç»ƒå®ä¾‹çš„æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›å°†å¼€å§‹ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next section discusses recommended readings for more information on the regression approaches discussed in this chapter and on some of the more recent developments in error-based learning.",
            "zh": "ä¸‹ä¸€èŠ‚å°†è®¨è®ºæ¨èçš„é˜…è¯»ææ–™ï¼Œä»¥è·å–æœ‰å…³æœ¬ç« ä¸­è®¨è®ºçš„å›å½’æ–¹æ³•ä»¥åŠåŸºäºé”™è¯¯å­¦ä¹ çš„ä¸€äº›æœ€æ–°å‘å±•çš„æ›´å¤šä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Leave-one-out cross validation is useful when the amount of data available is too small to allow big enough training sets in a k-fold cross validation.",
            "zh": "å½“å¯ç”¨æ•°æ®é‡å¤ªå°è€Œæ— æ³•åœ¨ k å€äº¤å‰éªŒè¯ä¸­å…è®¸è¶³å¤Ÿå¤§çš„è®­ç»ƒé›†æ—¶ï¼Œç•™ä¸€äº¤å‰éªŒè¯éå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A merger is a sky object in which multiple galaxies appear grouped together.",
            "zh": "åˆå¹¶æ˜¯ä¸€ä¸ªå¤©ä½“ï¼Œå…¶ä¸­å¤šä¸ªæ˜Ÿç³»ç»„åˆåœ¨ä¸€èµ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the performance of the logistic regression model on the 3-level classification problem, Jocelyn trained a logistic regression classifier on the 5-level dataset and evaluated it using a 10-fold cross validation.",
            "zh": "åŸºäºé€»è¾‘å›å½’æ¨¡å‹åœ¨ 3 çº§åˆ†ç±»é—®é¢˜ä¸Šçš„è¡¨ç°ï¼ŒJocelyn åœ¨ 5 çº§æ•°æ®é›†ä¸Šè®­ç»ƒäº†é€»è¾‘å›å½’åˆ†ç±»å™¨ï¼Œå¹¶ä½¿ç”¨ 10 å€äº¤å‰éªŒè¯å¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a feature following an exponential distribution, as shown in Figure 3.2(e)[60], the likelihood of low values occurring is very high but diminishes rapidly for higher values.",
            "zh": "åœ¨æŒ‡æ•°åˆ†å¸ƒåçš„ç‰¹å¾ä¸­ï¼Œå¦‚å›¾3.2ï¼ˆeï¼‰[60]æ‰€ç¤ºï¼Œå‡ºç°ä½å€¼çš„å¯èƒ½æ€§éå¸¸é«˜ï¼Œä½†å¯¹äºè¾ƒé«˜å€¼ï¼Œåˆ™ä¼šè¿…é€Ÿé™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of these sets contains the solution, which leaves you with just one more question to ask to finish the game.",
            "zh": "å…¶ä¸­ä¸€ç»„åŒ…å«è§£å†³æ–¹æ¡ˆï¼Œè®©æ‚¨åªéœ€å†é—®ä¸€ä¸ªé—®é¢˜å³å¯å®Œæˆæ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The derivative of this activation function with respect to z is always 1: each unit change in the value of zi results in a unit change in the value of ai.",
            "zh": "æ­¤æ¿€æ´»å‡½æ•°ç›¸å¯¹äº z çš„å¯¼æ•°å§‹ç»ˆä¸º 1ï¼šzi å€¼çš„æ¯ä¸ªå•ä½å˜åŒ–éƒ½ä¼šå¯¼è‡´ ai å€¼çš„å•ä½å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "interaction term, 355",
            "zh": "äº¤äº’é¡¹ï¼Œ355"
        }
    },
    {
        "translation": {
            "en": "There are two key main use cases for unsupervised learning: clustering and representation learning.",
            "zh": "æ— ç›‘ç£å­¦ä¹ æœ‰ä¸¤ä¸ªå…³é”®çš„ä¸»è¦ç”¨ä¾‹ï¼šèšç±»å’Œè¡¨ç¤ºå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "STUDIED",
            "zh": "ç ”ç©¶"
        }
    },
    {
        "translation": {
            "en": "We now understand the two fundamental components of similarity-based learning: a feature space representation of the instances in a dataset and a measure of similarity between instances.",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬äº†è§£äº†åŸºäºç›¸ä¼¼æ€§å­¦ä¹ çš„ä¸¤ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼šæ•°æ®é›†ä¸­å®ä¾‹çš„ç‰¹å¾ç©ºé—´è¡¨ç¤ºå’Œå®ä¾‹ä¹‹é—´ç›¸ä¼¼æ€§çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "All entries in the action-value table are first initialized to random values (or sometimes zeros).",
            "zh": "action-value è¡¨ä¸­çš„æ‰€æœ‰æ¡ç›®é¦–å…ˆåˆå§‹åŒ–ä¸ºéšæœºå€¼ï¼ˆæœ‰æ—¶ä¸ºé›¶ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts at the position marked 1 on the error surface, and learning steps actually cause it to move farther and farther up the error surface.",
            "zh": "è¯¥ç®—æ³•ä»è¯¯å·®é¢ä¸Šæ ‡è®°ä¸º 1 çš„ä½ç½®å¼€å§‹ï¼Œå­¦ä¹ æ­¥éª¤å®é™…ä¸Šä¼šå¯¼è‡´å®ƒåœ¨è¯¯å·®é¢ä¸Šè¶Šèµ°è¶Šè¿œã€‚"
        }
    },
    {
        "translation": {
            "en": "Hebb also postulated a mechanism for how lasting memories are learned in the brain on the basis of a process of changes to the connections between neurons:",
            "zh": "Hebbè¿˜å‡è®¾äº†ä¸€ç§æœºåˆ¶ï¼Œå³åœ¨ç¥ç»å…ƒä¹‹é—´è¿æ¥å‘ç”Ÿå˜åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œå¤§è„‘ä¸­å¦‚ä½•å­¦ä¹ æŒä¹…çš„è®°å¿†ï¼š"
        }
    },
    {
        "translation": {
            "en": "We can see here that the large positive Q values from actions taken in states near the goal state have started to propagate through the environment, although there are not yet large positive values near the start state.",
            "zh": "æˆ‘ä»¬åœ¨è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼Œåœ¨æ¥è¿‘ç›®æ ‡çŠ¶æ€çš„çŠ¶æ€ä¸‹æ‰€é‡‡å–çš„è¡ŒåŠ¨çš„å¤§æ­£ Q å€¼å·²ç»å¼€å§‹åœ¨ç¯å¢ƒä¸­ä¼ æ’­ï¼Œå°½ç®¡åœ¨å¼€å§‹çŠ¶æ€é™„è¿‘è¿˜æ²¡æœ‰å¤§çš„æ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each attempt at the task is referred to as an episode.",
            "zh": "å¯¹ä»»åŠ¡çš„æ¯æ¬¡å°è¯•éƒ½ç§°ä¸ºä¸€ä¸ªæƒ…èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "observation period, 37, 689",
            "zh": "è§‚å¯ŸæœŸï¼Œ 37ï¼Œ 689"
        }
    },
    {
        "translation": {
            "en": "Finding features that exhibit a normal distribution is a good thing, as many of the modeling techniques we discuss in later chapters work particularly well with normally distributed data.",
            "zh": "æ‰¾åˆ°è¡¨ç°å‡ºæ­£æ€åˆ†å¸ƒçš„ç‰¹å¾æ˜¯ä¸€ä»¶å¥½äº‹ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åé¢çš„ç« èŠ‚ä¸­è®¨è®ºçš„è®¸å¤šå»ºæ¨¡æŠ€æœ¯éƒ½ç‰¹åˆ«é€‚ç”¨äºæ­£æ€åˆ†å¸ƒçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "stale model, 578, 580, 583, 702",
            "zh": "é™ˆæ—§å‹å·ï¼Œ578ã€580ã€583ã€702"
        }
    },
    {
        "translation": {
            "en": "Once a signal has identified that concept drift has occurred and that a model has indeed gone stale, corrective action is required. The nature of this corrective action depends on the application and the type of model being used. In most cases, however, corrective action involves gathering a new labeled dataset and restarting the model building process using this new dataset.",
            "zh": "ä¸€æ—¦ä¿¡å·ç¡®å®šå‘ç”Ÿäº†æ¦‚å¿µæ¼‚ç§»ï¼Œå¹¶ä¸”æ¨¡å‹ç¡®å®å·²ç»è¿‡æ—¶ï¼Œå°±éœ€è¦é‡‡å–çº æ­£æªæ–½ã€‚æ­¤çº æ­£æªæ–½çš„æ€§è´¨å–å†³äºåº”ç”¨ç¨‹åºå’Œæ‰€ä½¿ç”¨çš„æ¨¡å‹ç±»å‹ã€‚ä½†æ˜¯ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œçº æ­£æªæ–½åŒ…æ‹¬æ”¶é›†æ–°çš„æ ‡è®°æ•°æ®é›†å¹¶ä½¿ç”¨æ­¤æ–°æ•°æ®é›†é‡æ–°å¯åŠ¨æ¨¡å‹æ„å»ºè¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of how a batch of examples can be processed in parallel using matrix operations.",
            "zh": "å¦‚ä½•ä½¿ç”¨çŸ©é˜µè¿ç®—å¹¶è¡Œå¤„ç†ä¸€æ‰¹ç¤ºä¾‹çš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In all cases performance of the models improved with feature selection.",
            "zh": "åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„æ€§èƒ½éƒ½é€šè¿‡ç‰¹å¾é€‰æ‹©è€Œå¾—åˆ°æ”¹å–„ã€‚"
        }
    },
    {
        "translation": {
            "en": "heterogeneity, 126",
            "zh": "å¼‚è´¨æ€§ï¼Œ126"
        }
    },
    {
        "translation": {
            "en": "The major difference between Figure 5.12(a)[205] and Figure 5.12(b)[205] is that the axes are scaled differently.",
            "zh": "å›¾5.12ï¼ˆaï¼‰[205]å’Œå›¾5.12ï¼ˆbï¼‰[205]ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºè½´çš„ç¼©æ”¾æ–¹å¼ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Early stopping is designed to avoid a model overfitting the training data.",
            "zh": "æå‰åœæ­¢æ—¨åœ¨é¿å…æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why for datasets such as the one depicted in Figure 5.15(a)[219], where there is no covariance between the features, the Mahalanobis distance is simply the Euclidean distance.23",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¯¹äºå›¾5.15ï¼ˆaï¼‰[219]ä¸­æè¿°çš„æ•°æ®é›†ï¼Œç‰¹å¾ä¹‹é—´æ²¡æœ‰åæ–¹å·®ï¼Œé©¬æ°è·ç¦»åªæ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»23ã€‚"
        }
    },
    {
        "translation": {
            "en": "filters, 227, 482",
            "zh": "è¿‡æ»¤å™¨ï¼Œ 227ï¼Œ 482"
        }
    },
    {
        "translation": {
            "en": "If we examine the graph of the binary logarithm (a logarithm to the base 2) of probabilities ranging from 0 to 1, shown in Figure 4.6(a)[125], we see that the logarithm function returns large negative numbers for low probabilities and small negative numbers for high probabilities.",
            "zh": "å¦‚æœæˆ‘ä»¬æ£€æŸ¥æ¦‚ç‡èŒƒå›´ä¸º 0 åˆ° 1 çš„äºŒè¿›åˆ¶å¯¹æ•°ï¼ˆä»¥ 2 ä¸ºåº•çš„å¯¹æ•°ï¼‰çš„å›¾å½¢ï¼Œå¦‚å›¾ 4.6ï¼ˆaï¼‰[125] æ‰€ç¤ºï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å¯¹æ•°å‡½æ•°ä¸ºä½æ¦‚ç‡è¿”å›å¤§è´Ÿæ•°ï¼Œé«˜æ¦‚ç‡è¿”å›å°è´Ÿæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The result of this pruning is visible on the left branch of the tree shown in Figure 4.19(b)[158].",
            "zh": "è¿™ç§ä¿®å‰ªçš„ç»“æœåœ¨å›¾4.19ï¼ˆbï¼‰[158]æ‰€ç¤ºçš„æ ‘çš„å·¦ä¾§åˆ†æ”¯ä¸Šå¯è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that although this decision surface is more complex than the ones we have seen before (e.g., Figure 7.12[343]), the logistic shape is still maintained.",
            "zh": "è¯·æ³¨æ„ï¼Œå°½ç®¡è¿™ä¸ªå†³ç­–é¢æ¯”æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„å†³ç­–é¢æ›´å¤æ‚ï¼ˆä¾‹å¦‚ï¼Œå›¾7.12[343]ï¼‰ï¼Œä½†é€»è¾‘å½¢çŠ¶ä»ç„¶ä¿æŒä¸å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the error for this example using the new weights for the network, compared with using the original weights.",
            "zh": "ä¸ä½¿ç”¨åŸå§‹æƒé‡ç›¸æ¯”ï¼Œä½¿ç”¨ç½‘ç»œçš„æ–°æƒé‡è®¡ç®—æ­¤ç¤ºä¾‹çš„è¯¯å·®å‡å°‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This understanding would form the basis of Rossâ€™s work on designing the domain concepts and descriptive features that would make up the analytics base table (ABT), which would drive the creation of the predictive model.",
            "zh": "è¿™ç§ç†è§£å°†æ„æˆ Ross è®¾è®¡æ„æˆåˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ çš„é¢†åŸŸæ¦‚å¿µå’Œæè¿°æ€§ç‰¹å¾çš„å·¥ä½œåŸºç¡€ï¼Œè¿™å°†æ¨åŠ¨é¢„æµ‹æ¨¡å‹çš„åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Fawcett, Tom. 2006. An introduction to ROC analysis. Pattern Recognition Letters 27 (8): 861â€“874.",
            "zh": "ç¦å¡ç‰¹ï¼Œæ±¤å§†ã€‚2006. ROCåˆ†æç®€ä»‹.æ¨¡å¼è¯†åˆ«å¿«æŠ¥27ï¼ˆ8ï¼‰ï¼š861â€“874ã€‚"
        }
    },
    {
        "translation": {
            "en": "SPEND",
            "zh": "èŠ±è´¹"
        }
    },
    {
        "translation": {
            "en": "Similarly, the weights of all incorrectly classified instances are updated using Equation (4.12)[161]. For example, the weight for d9 is updated",
            "zh": "åŒæ ·ï¼Œæ‰€æœ‰é”™è¯¯åˆ†ç±»çš„å®ä¾‹çš„æƒé‡éƒ½ä½¿ç”¨å…¬å¼ï¼ˆ4.12ï¼‰[161]è¿›è¡Œæ›´æ–°ã€‚ä¾‹å¦‚ï¼Œd9 çš„æƒé‡å·²æ›´æ–°"
        }
    },
    {
        "translation": {
            "en": "9.4.1.3â€ƒLeave-one-out cross validationâ€ƒLeave-one-out cross validation, also known as jackknifing, is an extreme form of k-fold cross validation in which the number of folds is the same as the number of training instances.",
            "zh": "9.4.1.3 ç•™ä¸€äº¤å‰éªŒè¯ ç•™ä¸€äº¤å‰éªŒè¯ï¼Œä¹Ÿç§°ä¸º jackknifingï¼Œæ˜¯ k æŠ˜å äº¤å‰éªŒè¯çš„ä¸€ç§æç«¯å½¢å¼ï¼Œå…¶ä¸­æŠ˜å æ•°ä¸è®­ç»ƒå®ä¾‹æ•°ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The starting point for our explanation of the relationship between weighted sum calculations and vanishing and exploding z and Î´ values is the BienaymÃ© formula from statistics, which states that the variance of the sum of uncorrelated random variables is the sum of their variance",
            "zh": "æˆ‘ä»¬è§£é‡ŠåŠ æƒå’Œè®¡ç®—ä¸æ¶ˆå¤±å’Œçˆ†ç‚¸ z å’Œ Î´ å€¼ä¹‹é—´å…³ç³»çš„èµ·ç‚¹æ˜¯ç»Ÿè®¡å­¦ä¸­çš„ BienaymÃ© å…¬å¼ï¼Œè¯¥å…¬å¼æŒ‡å‡ºä¸ç›¸å…³éšæœºå˜é‡ä¹‹å’Œçš„æ–¹å·®æ˜¯å®ƒä»¬çš„æ–¹å·®ä¹‹å’Œ"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s look at an example of how we can now use Bayesâ€™ Theorem to make predictions based on the meningitis diagnosis dataset in Table 6.1[246] for a query instance with HEADACHE = true, FEVER = false, and VOMITING = true. Returning to the shortened notation that we used previously, a predicted diagnosis for this query instance can be given using Bayesâ€™ Theorem as",
            "zh": "è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯´æ˜æˆ‘ä»¬ç°åœ¨å¦‚ä½•ä½¿ç”¨è´å¶æ–¯å®šç†æ ¹æ®è¡¨ 6.1[246] ä¸­çš„è„‘è†œç‚è¯Šæ–­æ•°æ®é›†å¯¹ HEADACHE = trueã€FEVER = false å’Œ VOMITING = true çš„æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚å›åˆ°æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„ç¼©çŸ­ç¬¦å·ï¼Œå¯ä»¥ä½¿ç”¨è´å¶æ–¯å®šç†ç»™å‡ºæ­¤æŸ¥è¯¢å®ä¾‹çš„é¢„æµ‹è¯Šæ–­ï¼Œå› ä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(a)[663] shows a representation of the action-value table after this first episode.",
            "zh": "å›¾11.5ï¼ˆaï¼‰[663]æ˜¾ç¤ºäº†ç¬¬ä¸€é›†ä¹‹åçš„åŠ¨ä½œå€¼è¡¨çš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first stage of the McCulloch and Pitts model, each input is multiplied by a weight, and the results of these multiplications are then added together.",
            "zh": "åœ¨ McCulloch å’Œ Pitts æ¨¡å‹çš„ç¬¬ä¸€é˜¶æ®µï¼Œå°†æ¯ä¸ªè¾“å…¥ä¹˜ä»¥ä¸€ä¸ªæƒé‡ï¼Œç„¶åå°†è¿™äº›ä¹˜æ³•çš„ç»“æœç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "17. The Gini coefficient should not be confused with the Gini index described in Section 4.4.1[142]. Their only connection is that they are both named after the Italian statistician Corrado Gini.",
            "zh": "17. åŸºå°¼ç³»æ•°ä¸åº”ä¸ç¬¬4.4.1èŠ‚[142]ä¸­æè¿°çš„åŸºå°¼ç³»æ•°ç›¸æ··æ·†ã€‚å®ƒä»¬å”¯ä¸€çš„è”ç³»æ˜¯å®ƒä»¬éƒ½æ˜¯ä»¥æ„å¤§åˆ©ç»Ÿè®¡å­¦å®¶ç§‘æ‹‰å¤šÂ·åŸºå°¼ï¼ˆCorrado Giniï¼‰çš„åå­—å‘½åçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6.2â€…â€…â€…Binning",
            "zh": "3.6.2 åƒç´ åˆå¹¶"
        }
    },
    {
        "translation": {
            "en": "An extreme case of this problem happens when k nearest neighbor models are used.",
            "zh": "å½“ä½¿ç”¨ k ä¸ªæœ€è¿‘é‚»æ¨¡å‹æ—¶ï¼Œä¼šå‘ç”Ÿæ­¤é—®é¢˜çš„æç«¯æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Brian",
            "zh": "å¸ƒè±æ©"
        }
    },
    {
        "translation": {
            "en": "Sampling bias arises when the sample of data used within a data-driven process is collected in such a way that the sample is not representative of the population the sample is used to represent.",
            "zh": "å½“åœ¨æ•°æ®é©±åŠ¨è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®æ ·æœ¬çš„æ”¶é›†æ–¹å¼ä½¿å¾—æ ·æœ¬ä¸èƒ½ä»£è¡¨æ ·æœ¬æ‰€ä»£è¡¨çš„æ€»ä½“æ—¶ï¼Œå°±ä¼šå‡ºç°æŠ½æ ·åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.1â€…â€…â€…Choosing Initial Cluster Centroids",
            "zh": "10.4.1 é€‰æ‹©åˆå§‹èšç±»è´¨å¿ƒ"
        }
    },
    {
        "translation": {
            "en": "Figure 7.17",
            "zh": "å›¾ 7.17"
        }
    },
    {
        "translation": {
            "en": "That said, some models are more susceptible to the curse of dimensionality than others.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰äº›æ¨¡å‹æ¯”å…¶ä»–æ¨¡å‹æ›´å®¹æ˜“å—åˆ°ç»´åº¦çš„è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "data mining, 16",
            "zh": "æ•°æ®æŒ–æ˜ï¼Œ 16"
        }
    },
    {
        "translation": {
            "en": "9.3â€…â€…â€…Standard Approach: Misclassification Rate on a Hold-Out Test Set",
            "zh": "9.3 æ ‡å‡†æ–¹æ³•ï¼šä¿æŒæµ‹è¯•é›†çš„é”™è¯¯åˆ†ç±»ç‡"
        }
    },
    {
        "translation": {
            "en": "history, 639",
            "zh": "å†å²ï¼Œ639"
        }
    },
    {
        "translation": {
            "en": "Table 4.3",
            "zh": "è¡¨ 4.3"
        }
    },
    {
        "translation": {
            "en": "One problem with updating the weights of a network after each example is that the error gradient calculated on a single example sampled from the training set is likely to be a noisy approximation of the true gradient over the entire dataset; in other words, the error gradient calculated on a single example may not point in the same direction as the steepest gradient when we average the gradients over the entire dataset.",
            "zh": "åœ¨æ¯ä¸ªç¤ºä¾‹ä¹‹åæ›´æ–°ç½‘ç»œæƒé‡çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä»è®­ç»ƒé›†é‡‡æ ·çš„å•ä¸ªç¤ºä¾‹ä¸Šè®¡ç®—çš„è¯¯å·®æ¢¯åº¦å¯èƒ½æ˜¯æ•´ä¸ªæ•°æ®é›†ä¸ŠçœŸå®æ¢¯åº¦çš„å™ªå£°è¿‘ä¼¼å€¼;æ¢è¨€ä¹‹ï¼Œå½“æˆ‘ä»¬å¯¹æ•´ä¸ªæ•°æ®é›†çš„æ¢¯åº¦è¿›è¡Œå¹³å‡æ—¶ï¼Œåœ¨å•ä¸ªç¤ºä¾‹ä¸Šè®¡ç®—çš„è¯¯å·®æ¢¯åº¦å¯èƒ½ä¸æœ€é™¡å³­çš„æ¢¯åº¦æŒ‡å‘çš„æ–¹å‘ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "As noted, the activation vector ht of the hidden layer for input t is propagated forward to the output layer, and also to the memory buffer where it is stored for one time-step. Equation (8.105)[501] specifies how the output activations yt for input t are then generated: a weighted sum is calculated via a dot product operation between the weight matrix Wyh and the activations vector from the hidden layer ht, and this is passed through a non-linear activation function Ï†.",
            "zh": "å¦‚å‰æ‰€è¿°ï¼Œè¾“å…¥ t çš„éšè—å±‚çš„æ¿€æ´»å‘é‡ ht å‘å‰ä¼ æ’­åˆ°è¾“å‡ºå±‚ï¼Œå¹¶ä¼ æ’­åˆ°å­˜å‚¨ä¸€ä¸ªæ—¶é—´æ­¥é•¿çš„å†…å­˜ç¼“å†²åŒºã€‚æ–¹ç¨‹ï¼ˆ8.105ï¼‰[501]æŒ‡å®šäº†å¦‚ä½•ç”Ÿæˆè¾“å…¥tçš„è¾“å‡ºæ¿€æ´»ytï¼šé€šè¿‡æƒé‡çŸ©é˜µWyhå’Œéšè—å±‚htçš„æ¿€æ´»å‘é‡ä¹‹é—´çš„ç‚¹ç§¯è¿ç®—è®¡ç®—åŠ æƒå’Œï¼Œå¹¶é€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°Ï†ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The chapter finishes by describing the deep Q network algorithm.",
            "zh": "æœ¬ç« æœ€åä»‹ç»äº†æ·±åº¦ Q ç½‘ç»œç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are many different types of neurons in the brain; however, in general, neurons have a simple three-part structure consisting of (1) a cell body; (2) a set of relatively short fibers connected to the cell body, called dendrites; and (3) a single long fiber connected to the cell body, called an axon.",
            "zh": "å¤§è„‘ä¸­æœ‰è®¸å¤šä¸åŒç±»å‹çš„ç¥ç»å…ƒ;ç„¶è€Œï¼Œä¸€èˆ¬æ¥è¯´ï¼Œç¥ç»å…ƒå…·æœ‰ç®€å•çš„ä¸‰éƒ¨åˆ†ç»“æ„ï¼ŒåŒ…æ‹¬ ï¼ˆ1ï¼‰ ç»†èƒä½“;ï¼ˆ2ï¼‰ä¸€ç»„è¿æ¥åˆ°ç»†èƒä½“çš„ç›¸å¯¹è¾ƒçŸ­çš„çº¤ç»´ï¼Œç§°ä¸ºæ ‘çª;ï¼ˆ3ï¼‰è¿æ¥åˆ°ç»†èƒä½“çš„å•æ ¹é•¿çº¤ç»´ï¼Œç§°ä¸ºè½´çªã€‚"
        }
    },
    {
        "translation": {
            "en": "5.8â€…â€…â€…A dataset of whiskeys listing the age (in years), the rating (between 1 and 5, with 5 being the best), and the bottle price of each whiskey.",
            "zh": "5.8 å¨å£«å¿Œæ•°æ®é›†ï¼Œåˆ—å‡ºæ¯ç§å¨å£«å¿Œçš„å¹´é¾„ï¼ˆä»¥å¹´ä¸ºå•ä½ï¼‰ã€è¯„çº§ï¼ˆåœ¨ 1 åˆ° 5 ä¹‹é—´ï¼Œ5 ä¸ºæœ€ä½³ï¼‰å’Œç“¶ä»·ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two defining characteristics of ensemble models:",
            "zh": "é›†æˆæ¨¡å‹æœ‰ä¸¤ä¸ªå®šä¹‰ç‰¹å¾ï¼š"
        }
    },
    {
        "translation": {
            "en": "This rise in relative frequency illustrates that, as the number of samples generated increases, the resulting distribution approaches the actual distribution.",
            "zh": "è¿™ç§ç›¸å¯¹é¢‘ç‡çš„å¢åŠ è¡¨æ˜ï¼Œéšç€ç”Ÿæˆçš„æ ·æœ¬æ•°é‡çš„å¢åŠ ï¼Œå¾—åˆ°çš„åˆ†å¸ƒæ¥è¿‘å®é™…åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35",
            "zh": "å›¾ 8.35"
        }
    },
    {
        "translation": {
            "en": "Figure 2.7",
            "zh": "å›¾ 2.7"
        }
    },
    {
        "translation": {
            "en": "AVGROAMCALLS",
            "zh": "AVGROAMCALLS"
        }
    },
    {
        "translation": {
            "en": "13. See Section 9.4.5[574].",
            "zh": "13. å‚è§ç¬¬ 9.4.5 èŠ‚[574]ã€‚"
        }
    },
    {
        "translation": {
            "en": "To help illustrate this, imagine Conor has gone to a small Gaeltacht town in Ireland on a two-week business trip.",
            "zh": "ä¸ºäº†å¸®åŠ©è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæƒ³è±¡ä¸€ä¸‹åº·çº³å»çˆ±å°”å…°çš„ä¸€ä¸ªç›–å°”å¡”èµ«ç‰¹å°é•‡è¿›è¡Œäº†ä¸ºæœŸä¸¤å‘¨çš„å•†åŠ¡æ—…è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "33. The dataset in this question is inspired by the Waste Water Treatment Dataset that is available from the UCI Machine Learning repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/machine-learning-databases/water-treatment. The creators of this dataset reported their work in Bejar et al. (1991).",
            "zh": "33. æœ¬é—®é¢˜ä¸­çš„æ•°æ®é›†çš„çµæ„Ÿæ¥è‡ª archive.ics.uci.edu/ml/machine-learning-databases/water-treatment çš„UCIæœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBacheå’ŒLichmanï¼Œ2013å¹´ï¼‰æä¾›çš„åºŸæ°´å¤„ç†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†çš„åˆ›å»ºè€…åœ¨Bejarç­‰äººï¼ˆ1991ï¼‰ä¸­æŠ¥å‘Šäº†ä»–ä»¬çš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "This rule highlights that in data that follows a normal distribution, there is a very low probability of observations occurring that differ from the mean by more than two standard deviations.",
            "zh": "æ­¤è§„åˆ™å¼ºè°ƒï¼Œåœ¨éµå¾ªæ­£æ€åˆ†å¸ƒçš„æ•°æ®ä¸­ï¼Œå‘ç”Ÿä¸å‡å€¼ç›¸å·®è¶…è¿‡ä¸¤ä¸ªæ ‡å‡†å·®çš„è§‚æµ‹å€¼çš„æ¦‚ç‡éå¸¸ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The default distance metric used in nearest neighbor models is Euclidean distance.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹ä¸­ä½¿ç”¨çš„é»˜è®¤è·ç¦»åº¦é‡æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "27. This should not be confused with the concept of sparse data that was introduced earlier.",
            "zh": "27. è¿™ä¸åº”ä¸å‰é¢ä»‹ç»çš„ç¨€ç–æ•°æ®æ¦‚å¿µç›¸æ··æ·†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Demsar, Janez. 2006. Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research 7: 1â€“30.",
            "zh": "å¾·å§†è¨å°”ï¼Œè´¾å†…æ–¯ã€‚2006. åˆ†ç±»å™¨åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç»Ÿè®¡æ¯”è¾ƒ.æœºå™¨å­¦ä¹ ç ”ç©¶æ‚å¿— 7ï¼š1-30ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use the chain rule for conditional probabilities by just adding the conditioning term to each term in the expression, so",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ¡ä»¶é¡¹æ·»åŠ åˆ°è¡¨è¾¾å¼ä¸­çš„æ¯ä¸ªé¡¹æ¥ä½¿ç”¨æ¡ä»¶æ¦‚ç‡é“¾å¼æ³•åˆ™ï¼Œå› æ­¤"
        }
    },
    {
        "translation": {
            "en": "This is because the rectified linear function has a zero output value for half its domain (i.e., for all z â‰¤ 0).",
            "zh": "è¿™æ˜¯å› ä¸ºæ•´æµçº¿æ€§å‡½æ•°åœ¨å…¶ä¸€åŠåŸŸï¼ˆå³æ‰€æœ‰ z â‰¤ 0ï¼‰çš„è¾“å‡ºå€¼ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.11â€…â€…â€…A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.11 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„é¢†åŸŸæ¦‚å¿µå’Œç›¸å…³åŠŸèƒ½çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that this action is different from the action used in the update equation previously (left).",
            "zh": "è¯·æ³¨æ„ï¼Œæ­¤æ“ä½œä¸ä¹‹å‰æ›´æ–°å…¬å¼ä¸­ä½¿ç”¨çš„æ“ä½œï¼ˆå·¦ï¼‰ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The main disadvantage of normalization is that the interpretative analysis discussed in Section 7.4.4[338] becomes more difficult as the descriptive feature values used in the model do not relate to the actual feature values in the data.",
            "zh": "å½’ä¸€åŒ–çš„ä¸»è¦ç¼ºç‚¹æ˜¯ï¼Œç”±äºæ¨¡å‹ä¸­ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾å€¼ä¸æ•°æ®ä¸­çš„å®é™…ç‰¹å¾å€¼æ— å…³ï¼Œå› æ­¤ç¬¬ 7.4.4 èŠ‚[338] ä¸­è®¨è®ºçš„è§£é‡Šæ€§åˆ†æå˜å¾—æ›´åŠ å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1.1â€…â€…â€…â€…Central Tendency",
            "zh": "A.1.1 é›†ä¸­è¶‹åŠ¿"
        }
    },
    {
        "translation": {
            "en": "Once Edwin had approved the models that Jocelyn had built, Jocelyn met again with Ted to begin the process of integrating the models into the SDSS processing pipeline.",
            "zh": "Edwin æ‰¹å‡†äº† Jocelyn æ„å»ºçš„æ¨¡å‹åï¼ŒJocelyn å†æ¬¡ä¸ Ted ä¼šé¢ï¼Œå¼€å§‹å°†æ¨¡å‹é›†æˆåˆ° SDSS å¤„ç†ç®¡é“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance uses covariance to scale distances so that distances along a direction where the dataset is very spread out are scaled down, and distances along directions where the dataset is tightly packed are scaled up. For example, in Figure 5.15(b)[219] the Mahalanobis distance between B and A will be less than the Mahalanobis distance between C and A, whereas in Figure 5.15(c)[219] the opposite will be true. The Mahalanobis distance is defined as",
            "zh": "é©¬æ°è·ç¦»ä½¿ç”¨åæ–¹å·®æ¥ç¼©æ”¾è·ç¦»ï¼Œä»¥ä¾¿æ²¿æ•°æ®é›†éå¸¸åˆ†æ•£çš„æ–¹å‘çš„è·ç¦»æŒ‰æ¯”ä¾‹ç¼©å°ï¼Œæ²¿æ•°æ®é›†ç´§å¯†å †ç§¯çš„æ–¹å‘çš„è·ç¦»æŒ‰æ¯”ä¾‹æ”¾å¤§ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾5.15ï¼ˆbï¼‰[219]ä¸­ï¼ŒBå’ŒAä¹‹é—´çš„é©¬æ°è·ç¦»å°†å°äºCå’ŒAä¹‹é—´çš„é©¬æ°è·ç¦»ï¼Œè€Œåœ¨å›¾5.15ï¼ˆcï¼‰[219]ä¸­ï¼Œæƒ…å†µæ­£å¥½ç›¸åã€‚é©¬æ°è·ç¦»å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Because they explicitly model the distribution of the data for each class k nearest neighbor models are also generative models.",
            "zh": "å› ä¸ºå®ƒä»¬æ˜¾å¼åœ°å¯¹æ¯ä¸ªç±»çš„æ•°æ®åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œæ‰€ä»¥ k æœ€è¿‘é‚»æ¨¡å‹ä¹Ÿæ˜¯ç”Ÿæˆæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for clockwise spiral galaxy category",
            "zh": "é¡ºæ—¶é’ˆèºæ—‹æ˜Ÿç³»ç±»åˆ«çš„å¾—ç¥¨åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of these two features is shown in Figure 7.16(a)[352], from which the strong non-linear relationship between rainfall and grass growth is clearly apparentâ€”grass does not grow well when there is very little rain or too much rain, but hits a sweet spot at rainfall of about 2.5mm per day.",
            "zh": "è¿™ä¸¤ä¸ªç‰¹å¾çš„æ•£ç‚¹å›¾å¦‚å›¾7.16ï¼ˆaï¼‰[352]æ‰€ç¤ºï¼Œä»ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºé™é›¨é‡ä¸è‰ç”Ÿé•¿ä¹‹é—´çš„å¼ºéçº¿æ€§å…³ç³»â€”â€”å½“é›¨æ°´å¾ˆå°‘æˆ–é›¨æ°´è¿‡å¤šæ—¶ï¼Œè‰ç”Ÿé•¿ä¸å¥½ï¼Œä½†åœ¨æ¯å¤©é™é›¨é‡çº¦2.5æ¯«ç±³æ—¶è¾¾åˆ°æœ€ä½³çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a linear relationship between two features, as one feature increases or decreases, the other feature increases or decreases by a corresponding amount.",
            "zh": "åœ¨ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„çº¿æ€§å…³ç³»ä¸­ï¼Œå½“ä¸€ä¸ªç‰¹å¾å¢åŠ æˆ–å‡å°‘æ—¶ï¼Œå¦ä¸€ä¸ªç‰¹å¾ä¼šç›¸åº”å¢åŠ æˆ–å‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Fundamentals section of this chapter introduces the standard artificial neural network architecture: a feedforward neural network. We then present the backpropagation algorithm, the standard algorithm used to train neural networks, and illustrate how the algorithm functions with a worked example.",
            "zh": "æœ¬ç« çš„åŸºç¡€éƒ¨åˆ†ä»‹ç»äº†æ ‡å‡†çš„äººå·¥ç¥ç»ç½‘ç»œæ¶æ„ï¼šå‰é¦ˆç¥ç»ç½‘ç»œã€‚ç„¶åï¼Œæˆ‘ä»¬ä»‹ç»äº†åå‘ä¼ æ’­ç®—æ³•ï¼Œè¿™æ˜¯ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œçš„æ ‡å‡†ç®—æ³•ï¼Œå¹¶ç”¨ä¸€ä¸ªå·¥ä½œç¤ºä¾‹è¯´æ˜äº†è¯¥ç®—æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this, we compute the required conditional probabilities from the binned data in Table 6.18[295].",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä»è¡¨6.18[295]ä¸­çš„åˆ†ç®±æ•°æ®ä¸­è®¡ç®—æ‰€éœ€çš„æ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information about the scenario gives us the probability of having the disease as P(d) = 0.0001 and the probability of not having the disease as P(Â¬d) = 0.9999. The accuracy of the test is captured as P(t | d) = 0.99 and P(t | Â¬d) = 0.01. The overall probability of the test returning a positive value, P(t), is not given in the description above, but it can be easily calculated using the Theorem of Total Probability5 as",
            "zh": "æœ‰å…³è¯¥åœºæ™¯çš„ä¿¡æ¯ä¸ºæˆ‘ä»¬æä¾›äº† Pï¼ˆdï¼‰ = 0.0001 çš„ç–¾ç—…æ¦‚ç‡å’Œ Pï¼ˆÂ¬dï¼‰ = 0.9999 çš„ä¸ç–¾ç—…æ¦‚ç‡ã€‚æµ‹è¯•çš„ç²¾åº¦ä¸º Pï¼ˆt | dï¼‰ = 0.99 å’Œ Pï¼ˆt | Â¬dï¼‰ = 0.01ã€‚ä¸Šé¢çš„æè¿°ä¸­æ²¡æœ‰ç»™å‡ºæ£€éªŒè¿”å›æ­£å€¼ Pï¼ˆtï¼‰ çš„æ€»æ¦‚ç‡ï¼Œä½†å¯ä»¥ä½¿ç”¨æ€»æ¦‚ç‡å®šç† 5 è½»æ¾è®¡ç®—ä¸º"
        }
    },
    {
        "translation": {
            "en": "Equation (7.12)[324] is calculated from Equation (7.11)[324] by applying the differentiation chain rule.6 To understand the move from Equation (7.13)[324] to Equation (7.14)[324], imagine a problem with four descriptive features d[1]â€¦d[4]. Remembering that we always include the dummy feature d[0] with a value of 1, the dot product w Â·d becomes",
            "zh": "æ–¹ç¨‹ï¼ˆ7.12ï¼‰[324]æ˜¯æ ¹æ®æ–¹ç¨‹ï¼ˆ7.11ï¼‰[324]é€šè¿‡åº”ç”¨å¾®åˆ†é“¾æ³•åˆ™è®¡ç®—çš„.6è¦ç†è§£ä»æ–¹ç¨‹ï¼ˆ7.13ï¼‰[324]åˆ°æ–¹ç¨‹ï¼ˆ7.14ï¼‰[324]çš„ç§»åŠ¨ï¼Œæƒ³è±¡ä¸€ä¸ªå…·æœ‰å››ä¸ªæè¿°æ€§ç‰¹å¾d[1]çš„é—®é¢˜......d[4]ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬å§‹ç»ˆåŒ…å«å€¼ä¸º 1 çš„è™šæ‹Ÿç‰¹å¾ d[0]ï¼Œç‚¹ç§¯ w Â·d å˜ä¸º"
        }
    },
    {
        "translation": {
            "en": "Finally, the k sets of performance measures are aggregated to give one overall set of performance measures.",
            "zh": "æœ€åï¼Œå°† k ç»„ç»©æ•ˆåº¦é‡æ±‡æ€»åœ¨ä¸€èµ·ï¼Œç»™å‡ºä¸€ç»„æ•´ä½“ç»©æ•ˆåº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather than use individual pixel values, which can lead to very high-dimensional feature vectors, a simpler way to represent images for use with regression models is to calculate a histogram for each image and use this as the feature vector instead. In this case the histograms simply count the frequency of occurrence of each possible gray level in each image. The table that follows shows the histograms for a small dataset of 16 images split between examples of digits 0 and 1.",
            "zh": "è¡¨ç¤ºå›¾åƒä»¥ç”¨äºå›å½’æ¨¡å‹çš„ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•æ˜¯è®¡ç®—æ¯ä¸ªå›¾åƒçš„ç›´æ–¹å›¾ï¼Œå¹¶å°†å…¶ç”¨ä½œç‰¹å¾å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å•ä¸ªåƒç´ å€¼ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´éå¸¸é«˜ç»´çš„ç‰¹å¾å‘é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç›´æ–¹å›¾åªæ˜¯è®¡ç®—æ¯ä¸ªå›¾åƒä¸­æ¯ä¸ªå¯èƒ½çš„ç°åº¦çº§åˆ«çš„å‡ºç°é¢‘ç‡ã€‚ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸€ä¸ªåŒ…å« 16 ä¸ªå›¾åƒçš„å°å‹æ•°æ®é›†çš„ç›´æ–¹å›¾ï¼Œè¿™äº›å›¾åƒåˆ†ä¸ºæ•°å­— 0 å’Œ 1 çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPRADERR_U/G/R/I/Z",
            "zh": "EXPRADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 5.16[221] illustrates how the Mahalanobis distance defines this coordinate system, which is translated, rotated, and scaled with respect to the standard coordinates of a feature space.",
            "zh": "å›¾ 5.16[221] è¯´æ˜äº†é©¬æ°è·ç¦»å¦‚ä½•å®šä¹‰æ­¤åæ ‡ç³»ï¼Œè¯¥åæ ‡ç³»ç›¸å¯¹äºè¦ç´ ç©ºé—´çš„æ ‡å‡†åæ ‡è¿›è¡Œå¹³ç§»ã€æ—‹è½¬å’Œç¼©æ”¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "personal data, 40",
            "zh": "ä¸ªäººèµ„æ–™ï¼Œ 40"
        }
    },
    {
        "translation": {
            "en": "(d) Are there likely to be any legal issues associated with the domain concepts you have included?",
            "zh": "ï¼ˆdï¼‰ ä½ æ‰€åŒ…å«çš„é¢†åŸŸæ¦‚å¿µæ˜¯å¦å¯èƒ½å­˜åœ¨ä»»ä½•æ³•å¾‹é—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "SARSA24 is the most well-known on-policy temporal-difference learning algorithm, and is described in Algorithm 14[666].",
            "zh": "SARSA24æ˜¯æœ€å¹¿ä¸ºäººçŸ¥çš„ç­–ç•¥æ—¶å·®å­¦ä¹ ç®—æ³•ï¼Œåœ¨ç®—æ³•14[666]ä¸­è¿›è¡Œäº†æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we use a weighted dataset in which each instance has an associated weight wi â‰¥ 0, initially set to where n is the number of instances in the dataset.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåŠ æƒæ•°æ®é›†ï¼Œå…¶ä¸­æ¯ä¸ªå®ä¾‹éƒ½æœ‰ä¸€ä¸ªå…³è”çš„æƒé‡ wi â‰¥ 0ï¼Œæœ€åˆè®¾ç½®ä¸ºå…¶ä¸­ n æ˜¯æ•°æ®é›†ä¸­çš„å®ä¾‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "L2 loss, 168",
            "zh": "L2 æŸå¤±ï¼Œ168"
        }
    },
    {
        "translation": {
            "en": "(b) An equal-frequency binning using 5 bins",
            "zh": "ï¼ˆbï¼‰ ä½¿ç”¨ 5 ä¸ªåˆ†æ¡£çš„ç­‰é¢‘åˆ†æ¡£"
        }
    },
    {
        "translation": {
            "en": "3.1.1â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "3.1.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo, 708",
            "zh": "é“¶æ²³åŠ¨ç‰©å›­ï¼Œ708"
        }
    },
    {
        "translation": {
            "en": "The purpose specification principle states that data subjects should be informed of the purpose for which data will be used at the time of its collection.",
            "zh": "ç›®çš„æŒ‡æ˜åŸåˆ™è§„å®šï¼Œåœ¨æ”¶é›†æ•°æ®æ—¶ï¼Œåº”å‘ŠçŸ¥æ•°æ®ä¸»ä½“ä½¿ç”¨æ•°æ®çš„ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the goal of finding the best decision boundary is the same for algorithms that build support vector machines as it is for logistic regression models, the inductive bias encoded in the algorithms to select this boundary is different, which leads to different decision boundaries being found.",
            "zh": "å°½ç®¡å¯¹äºæ„å»ºæ”¯æŒå‘é‡æœºçš„ç®—æ³•æ¥è¯´ï¼Œæ‰¾åˆ°æœ€ä½³å†³ç­–è¾¹ç•Œçš„ç›®æ ‡ä¸é€»è¾‘å›å½’æ¨¡å‹çš„ç›®æ ‡ç›¸åŒï¼Œä½†ç®—æ³•ä¸­ç¼–ç çš„ç”¨äºé€‰æ‹©æ­¤è¾¹ç•Œçš„å½’çº³åå·®æ˜¯ä¸åŒçš„ï¼Œè¿™å¯¼è‡´æ‰¾åˆ°ä¸åŒçš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "We use the convention of a bold capital letter to denote a matrix and a superscript in parentheses to list the relevant layer.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç²—ä½“å¤§å†™å­—æ¯è¡¨ç¤ºçŸ©é˜µçš„æƒ¯ä¾‹ï¼Œå¹¶ä½¿ç”¨æ‹¬å·ä¸­çš„ä¸Šæ ‡æ¥åˆ—å‡ºç›¸å…³å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we noted when we dropped the denominator of Bayesâ€™ Theorem from the MAP prediction model (Equation (6.11)[254]), for a categorical prediction task, we are primarily interested in the relative size of the posterior probabilities for the different target levels rather than the exact probabilities.",
            "zh": "æ­£å¦‚æˆ‘ä»¬ä»MAPé¢„æµ‹æ¨¡å‹ä¸­åˆ é™¤è´å¶æ–¯å®šç†çš„åˆ†æ¯æ—¶æ‰€æŒ‡å‡ºçš„ï¼ˆæ–¹ç¨‹ï¼ˆ6.11ï¼‰[254]ï¼‰ï¼Œå¯¹äºåˆ†ç±»é¢„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸»è¦æ„Ÿå…´è¶£çš„æ˜¯ä¸åŒç›®æ ‡æ°´å¹³çš„åéªŒæ¦‚ç‡çš„ç›¸å¯¹å¤§å°ï¼Œè€Œä¸æ˜¯ç¡®åˆ‡çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that we typically need to move beyond the performance measures described in Chapter 9[533].",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬é€šå¸¸éœ€è¦è¶…è¶Šç¬¬ 9 ç« [533] ä¸­æè¿°çš„æ€§èƒ½åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bishop, C. M. 2006. Pattern recognition and machine learning. Springer.",
            "zh": "ä¸»æ•™ï¼ŒCM 2006ã€‚æ¨¡å¼è¯†åˆ«å’Œæœºå™¨å­¦ä¹ ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ideally, we would like to use the network whose structure most accurately reflects the causal relationships in the domain.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨å…¶ç»“æ„æœ€å‡†ç¡®åœ°åæ˜ åŸŸä¸­å› æœå…³ç³»çš„ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the joint receptive fields of the neurons in each set cover the entire input means that if the relevant visual feature (where relevance is defined by the filter used by a set of neurons) occurs anywhere in the input, then at least one of the neurons in the set will have a high activation.",
            "zh": "äº‹å®ä¸Šï¼Œæ¯ä¸ªé›†åˆä¸­ç¥ç»å…ƒçš„è”åˆæ„Ÿå—é‡è¦†ç›–äº†æ•´ä¸ªè¾“å…¥ï¼Œè¿™æ„å‘³ç€å¦‚æœç›¸å…³çš„è§†è§‰ç‰¹å¾ï¼ˆç›¸å…³æ€§ç”±ä¸€ç»„ç¥ç»å…ƒä½¿ç”¨çš„è¿‡æ»¤å™¨å®šä¹‰ï¼‰å‘ç”Ÿåœ¨è¾“å…¥çš„ä»»ä½•ä½ç½®ï¼Œé‚£ä¹ˆé›†åˆä¸­è‡³å°‘æœ‰ä¸€ä¸ªç¥ç»å…ƒå°†å…·æœ‰é«˜åº¦æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the tree branching and the depth of the tree are related to the complexity of the dataset it is trained on.",
            "zh": "ç›¸åï¼Œæ ‘çš„åˆ†æ”¯å’Œæ ‘çš„æ·±åº¦ä¸è®­ç»ƒå®ƒçš„æ•°æ®é›†çš„å¤æ‚æ€§æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Applying these rules to the first of our previous examples, f(x) = 2x + 3 (Figure C.2(a)[767]), we first apply Rule 3 to split this function into two parts, 2x and 3, and then apply differentiation rules to each. By Rule 2 we can differentiate 2x to 2 (remember that x is really x1). The 3 is a constant, so by Rule 1 differentiates to zero. The derivative of the function, then, is .",
            "zh": "å°†è¿™äº›è§„åˆ™åº”ç”¨äºæˆ‘ä»¬å‰é¢çš„ç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼Œfï¼ˆxï¼‰ = 2x + 3ï¼ˆå›¾C.2ï¼ˆaï¼‰[767]ï¼‰ï¼Œæˆ‘ä»¬é¦–å…ˆåº”ç”¨è§„åˆ™3å°†è¯¥å‡½æ•°æ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œ2xå’Œ3ï¼Œç„¶åå¯¹æ¯ä¸ªéƒ¨åˆ†åº”ç”¨å¾®åˆ†è§„åˆ™ã€‚æ ¹æ®è§„åˆ™ 2ï¼Œæˆ‘ä»¬å¯ä»¥å°† 2x åŒºåˆ†ä¸º 2ï¼ˆè¯·è®°ä½ï¼Œx å®é™…ä¸Šæ˜¯ x1ï¼‰ã€‚3 æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œå› æ­¤æ ¹æ®è§„åˆ™ 1 åˆ†åŒ–ä¸ºé›¶ã€‚å› æ­¤ï¼Œè¯¥å‡½æ•°çš„å¯¼æ•°ä¸º ã€‚"
        }
    },
    {
        "translation": {
            "en": "The likelihood of overfitting increases as a tree gets deeper because the resulting predictions are based on smaller and smaller subsets as the dataset is partitioned after each feature test in the path.",
            "zh": "éšç€æ ‘çš„æ·±å…¥ï¼Œè¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§ä¹Ÿä¼šå¢åŠ ï¼Œå› ä¸ºç”Ÿæˆçš„é¢„æµ‹åŸºäºè¶Šæ¥è¶Šå°çš„å­é›†ï¼Œå› ä¸ºæ•°æ®é›†åœ¨è·¯å¾„ä¸­çš„æ¯ä¸ªç‰¹å¾æµ‹è¯•åéƒ½ä¼šè¿›è¡Œåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "1. See Section 1.6[15].",
            "zh": "1. å‚è§ç¬¬ 1.6 èŠ‚[15]ã€‚"
        }
    },
    {
        "translation": {
            "en": "To fit an exponential distribution to a continuous feature, we set Î» equal to 1 divided by the mean of the feature.",
            "zh": "ä¸ºäº†å°†æŒ‡æ•°åˆ†å¸ƒæ‹Ÿåˆåˆ°è¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬å°† Î» è®¾ç½®ä¸ºç­‰äº 1 é™¤ä»¥ç‰¹å¾çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This backward process builds these chains in an efficient manner because the linking of a new neuron to the chain can be done by extending the chains created for the neurons downstream of it.",
            "zh": "è¿™ç§å‘åè¿‡ç¨‹ä»¥æœ‰æ•ˆçš„æ–¹å¼æ„å»ºè¿™äº›é“¾ï¼Œå› ä¸ºå¯ä»¥é€šè¿‡æ‰©å±•ä¸ºå…¶ä¸‹æ¸¸ç¥ç»å…ƒåˆ›å»ºçš„é“¾æ¥å®Œæˆæ–°ç¥ç»å…ƒä¸é“¾çš„é“¾æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The full text of the Civil Rights Act of 1964 is available at www.gpo.gov/fdsys/granule/STATUTE-78/STATUTE-78-Pg241/content-detail.html.",
            "zh": "5. 1964å¹´ã€Šæ°‘æƒæ³•æ¡ˆã€‹å…¨æ–‡è§ www.gpo.gov/fdsys/granule/STATUTE-78/STATUTE-78-Pg241/content-detail.htmlã€‚"
        }
    },
    {
        "translation": {
            "en": "This is not uncommon in this kind of scenario, in which the classifications have a certain amount of fuzziness around their boundariesâ€”e.g., the exact line between an elliptical and a spiral galaxy can be hard to defineâ€”and led to very interesting discussions for the scientists!",
            "zh": "è¿™ç§æƒ…å†µå¹¶ä¸å°‘è§ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ†ç±»åœ¨å…¶è¾¹ç•Œå‘¨å›´æœ‰ä¸€å®šçš„æ¨¡ç³Šæ€§ - ä¾‹å¦‚ï¼Œæ¤­åœ†æ˜Ÿç³»å’Œèºæ—‹æ˜Ÿç³»ä¹‹é—´çš„ç¡®åˆ‡çº¿å¯èƒ½å¾ˆéš¾å®šä¹‰ - å¹¶å¼•å‘äº†ç§‘å­¦å®¶éå¸¸æœ‰è¶£çš„è®¨è®ºï¼"
        }
    },
    {
        "translation": {
            "en": "null hypothesis, 333",
            "zh": "åŸå‡è®¾ï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "Three of these, broken limb, soft tissue, and back, are quite frequent in the ABT, while serious is quite rare.",
            "zh": "å…¶ä¸­ä¸‰ç§ï¼Œè‚¢ä½“éª¨æŠ˜ã€è½¯ç»„ç»‡éª¨æŠ˜å’ŒèƒŒéƒ¨éª¨æŠ˜ï¼Œåœ¨ ABT ä¸­å¾ˆå¸¸è§ï¼Œè€Œä¸¥é‡åˆ™éå¸¸ç½•è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.3.1â€…â€…â€…A Worked Example",
            "zh": "6.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "-0.113108",
            "zh": "-0.113108"
        }
    },
    {
        "translation": {
            "en": "Casscells, Ward, Arno Schoenberger, and Thomas B. Graboys. 1978. Interpretation by physicians of clinical laboratory results. New England Journal of Medicine 299 (18): 999â€“1001.",
            "zh": "Casscellsã€Wardã€Arno Schoenberger å’Œ Thomas B. Graboysã€‚1978. åŒ»ç”Ÿå¯¹ä¸´åºŠå®éªŒå®¤ç»“æœçš„è§£é‡Šã€‚æ–°è‹±æ ¼å…°åŒ»å­¦æ‚å¿—299ï¼ˆ18ï¼‰ï¼š999-1001ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this context, instance B is much more likely to be a member of the dataset than instance C. Figure 5.15(c)[219] shows a dataset with a strong positive covariance, and for this dataset, instance C is much more likely to be a member than instance B.",
            "zh": "å›¾5.15ï¼ˆcï¼‰[219]æ˜¾ç¤ºäº†ä¸€ä¸ªå…·æœ‰å¼ºæ­£åæ–¹å·®çš„æ•°æ®é›†ï¼Œå¯¹äºè¿™ä¸ªæ•°æ®é›†ï¼Œå®ä¾‹Cæ¯”å®ä¾‹Bæ›´æœ‰å¯èƒ½æˆä¸ºæˆå‘˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that each element in z(2) is the result of multiplying each element in a row in W(2) by the corresponding element in the column vector a(1) and summing the results.",
            "zh": "è¿™æ„å‘³ç€ zï¼ˆ2ï¼‰ ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å°† Wï¼ˆ2ï¼‰ ä¸­ä¸€è¡Œä¸­çš„æ¯ä¸ªå…ƒç´ ä¹˜ä»¥åˆ—å‘é‡ aï¼ˆ1ï¼‰ ä¸­çš„ç›¸åº”å…ƒç´ å¹¶å°†ç»“æœç›¸åŠ çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) Calculate a new set of weights for this model using a learning rate of 0.01.",
            "zh": "ï¼ˆdï¼‰ ä½¿ç”¨0.01çš„å­¦ä¹ ç‡è®¡ç®—è¯¥æ¨¡å‹çš„ä¸€ç»„æ–°æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Monte Carlo methods work well in conjunction with Bayesian networks because a Bayesian network models the probability distribution over the features.",
            "zh": "è’™ç‰¹å¡ç½—æ–¹æ³•ä¸è´å¶æ–¯ç½‘ç»œé…åˆä½¿ç”¨æ•ˆæœå¾ˆå¥½ï¼Œå› ä¸ºè´å¶æ–¯ç½‘ç»œå¯¹ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.235460",
            "zh": "0.235460"
        }
    },
    {
        "translation": {
            "en": "Predictions for the other target level are actually being performed this time, whereas in the previous example, this target level was essentially being ignored.",
            "zh": "è¿™æ¬¡å®é™…ä¸Šæ˜¯å¯¹å¦ä¸€ä¸ªç›®æ ‡æ°´å¹³çš„é¢„æµ‹ï¼Œè€Œåœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œè¿™ä¸ªç›®æ ‡æ°´å¹³åŸºæœ¬ä¸Šè¢«å¿½ç•¥äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This policyholder seems to have made many more claims than anyone else, and the total amount claimed reflects this.",
            "zh": "è¿™ä½æŠ•ä¿äººæå‡ºçš„ç´¢èµ”ä¼¼ä¹æ¯”å…¶ä»–ä»»ä½•äººéƒ½å¤šï¼Œç´¢èµ”æ€»é¢åæ˜ äº†è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "statistical inference, 751",
            "zh": "ç»Ÿè®¡æ¨æ–­ï¼Œ751"
        }
    },
    {
        "translation": {
            "en": "Frequently, the term activation function is used as a general term to refer to whatever function is employed in the second stage of an artificial neuron, because the function maps the weighted sum value, z, into the output value, or activation, of the neuron.",
            "zh": "é€šå¸¸ï¼Œæœ¯è¯­æ¿€æ´»å‡½æ•°è¢«ç”¨ä½œé€šç”¨æœ¯è¯­æ¥æŒ‡ä»£äººå·¥ç¥ç»å…ƒç¬¬äºŒé˜¶æ®µä½¿ç”¨çš„ä»»ä½•åŠŸèƒ½ï¼Œå› ä¸ºè¯¥å‡½æ•°å°†åŠ æƒå’Œå€¼ z æ˜ å°„åˆ°ç¥ç»å…ƒçš„è¾“å‡ºå€¼æˆ–æ¿€æ´»å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.4.2â€ƒIrregular cardinalityâ€ƒReading down the Card.",
            "zh": "3.3.4.2 ä¸è§„åˆ™åŸºæ•° è¯»å¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see from Iteration 2 in the bottom half of Table 7.3[331] that the new set of predictions made using the updated set of weights calculated in iteration 1 result in a lower sum of squared errors, 443,361.52.",
            "zh": "ä»è¡¨7.3[331]ä¸‹åŠéƒ¨åˆ†çš„è¿­ä»£2ä¸­å¯ä»¥çœ‹å‡ºï¼Œä½¿ç”¨è¿­ä»£1ä¸­è®¡ç®—çš„æ›´æ–°æƒé‡é›†è¿›è¡Œçš„æ–°é¢„æµ‹é›†å¯¼è‡´çš„å¹³æ–¹è¯¯å·®æ€»å’Œè¾ƒä½ï¼Œä¸º443,361.52ã€‚"
        }
    },
    {
        "translation": {
            "en": "This input matrix is organized so that each column contains the feature vector for a single example.",
            "zh": "æ­¤è¾“å…¥çŸ©é˜µçš„ç»„ç»‡æ–¹å¼æ˜¯ï¼Œæ¯åˆ—éƒ½åŒ…å«å•ä¸ªç¤ºä¾‹çš„ç‰¹å¾å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "where w is the vector w[0], w[1 the parameters w[0] and w[1] are referred to as weights;1 d is an instance defined by a single descriptive feature d[1 and w(d) is the prediction output by the model for the instance d. The key to using simple linear regression models is determining the optimal values for the weights in the model.",
            "zh": "å…¶ä¸­ w æ˜¯å‘é‡ w[0]ï¼Œw[1 å‚æ•° w[0] å’Œ w[1] ç§°ä¸ºæƒé‡;1 d æ˜¯ç”±å•ä¸ªæè¿°æ€§ç‰¹å¾ d[1] å®šä¹‰çš„å®ä¾‹ï¼Œwï¼ˆdï¼‰ æ˜¯æ¨¡å‹å¯¹å®ä¾‹ d çš„é¢„æµ‹è¾“å‡ºã€‚ä½¿ç”¨ç®€å•çº¿æ€§å›å½’æ¨¡å‹çš„å…³é”®æ˜¯ç¡®å®šæ¨¡å‹ä¸­æƒé‡çš„æœ€ä½³å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "43. In some texts, such as Goodfellow et al. (2016), the application of the activation function is treated as a separate step after the feature map has been generated by the application of the filter. Here we include the application function as part of the generation of the feature map.",
            "zh": "43. åœ¨ä¸€äº›æ–‡æœ¬ä¸­ï¼Œä¾‹å¦‚Goodfellowç­‰äººï¼ˆ2016å¹´ï¼‰ï¼Œåœ¨åº”ç”¨è¿‡æ»¤å™¨ç”Ÿæˆç‰¹å¾å›¾åï¼Œæ¿€æ´»å‡½æ•°çš„åº”ç”¨è¢«è§†ä¸ºä¸€ä¸ªå•ç‹¬çš„æ­¥éª¤ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åº”ç”¨ç¨‹åºåŠŸèƒ½ä½œä¸ºåŠŸèƒ½å›¾ç”Ÿæˆçš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We need to define three equations to formally specify information gain (one for each step). The first equation calculates the entropy for a dataset with respect to a target feature6",
            "zh": "æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸‰ä¸ªæ–¹ç¨‹æ¥æ­£å¼æŒ‡å®šä¿¡æ¯å¢ç›Šï¼ˆæ¯ä¸ªæ­¥éª¤ä¸€ä¸ªï¼‰ã€‚ç¬¬ä¸€ä¸ªæ–¹ç¨‹è®¡ç®—æ•°æ®é›†ç›¸å¯¹äºç›®æ ‡ç‰¹å¾çš„ç†µ6"
        }
    },
    {
        "translation": {
            "en": "Figure 11.4",
            "zh": "å›¾ 11.4"
        }
    },
    {
        "translation": {
            "en": "2. The overall performance of a model can be captured in a single performance measure, for example, misclassification rate.",
            "zh": "2. æ¨¡å‹çš„æ•´ä½“æ€§èƒ½å¯ä»¥åœ¨å•ä¸ªæ€§èƒ½åº¦é‡ä¸­æ•è·ï¼Œä¾‹å¦‚é”™è¯¯åˆ†ç±»ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "data preprocessing, 421",
            "zh": "æ•°æ®é¢„å¤„ç†ï¼Œ421"
        }
    },
    {
        "translation": {
            "en": "For example, a feature representing customer ages might cover the range [16,96], whereas a feature representing customer salaries might cover the range [10,000, 100,000].",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨ç¤ºå®¢æˆ·å¹´é¾„çš„ç‰¹å¾å¯èƒ½æ¶µç›–èŒƒå›´ [16,96]ï¼Œè€Œè¡¨ç¤ºå®¢æˆ·å·¥èµ„çš„ç‰¹å¾å¯èƒ½æ¶µç›–èŒƒå›´ [10,000ï¼Œ 100,000]ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. We discuss probability distributions in more depth in Chapter 6[243].",
            "zh": "3. æˆ‘ä»¬åœ¨ç¬¬6ç« [243]ä¸­æ›´æ·±å…¥åœ°è®¨è®ºäº†æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Pre-pruning approaches are computationally efficient and can work well for small datasets. By stopping the partitioning of the data early, however, induction algorithms that use pre-pruning can fail to create the most effective trees because they miss interactions between features that emerge within subtrees that are not obvious when the parent nodes are being considered. Pre-pruning can mean that these useful subtrees are never created.",
            "zh": "é¢„ä¿®å‰ªæ–¹æ³•åœ¨è®¡ç®—ä¸Šæ˜¯æœ‰æ•ˆçš„ï¼Œå¯ä»¥å¾ˆå¥½åœ°ç”¨äºå°å‹æ•°æ®é›†ã€‚ä½†æ˜¯ï¼Œé€šè¿‡æå‰åœæ­¢æ•°æ®åˆ†åŒºï¼Œä½¿ç”¨é¢„ä¿®å‰ªçš„å½’çº³ç®—æ³•å¯èƒ½æ— æ³•åˆ›å»ºæœ€æœ‰æ•ˆçš„æ ‘ï¼Œå› ä¸ºå®ƒä»¬ä¼šé”™è¿‡å­æ ‘ä¸­å‡ºç°çš„ç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œè€Œè¿™äº›ç‰¹å¾åœ¨è€ƒè™‘çˆ¶èŠ‚ç‚¹æ—¶å¹¶ä¸æ˜æ˜¾ã€‚é¢„ä¿®å‰ªå¯èƒ½æ„å‘³ç€æ°¸è¿œä¸ä¼šåˆ›å»ºè¿™äº›æœ‰ç”¨çš„å­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "These two feature maps are then stacked together and fed forward as input to the second convolutional layer.",
            "zh": "ç„¶åå°†è¿™ä¸¤ä¸ªç‰¹å¾å›¾å †å åœ¨ä¸€èµ·ï¼Œå¹¶ä½œä¸ºè¾“å…¥è½¬å‘åˆ°ç¬¬äºŒä¸ªå·ç§¯å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this way the most common clustering is chosen as the final result.",
            "zh": "è¿™æ ·ï¼Œå°†é€‰æ‹©æœ€å¸¸è§çš„èšç±»ä½œä¸ºæœ€ç»ˆç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Risk Assessment: Risk is one of the key influencers in almost every decision an organization makes. Predictive analytics models can be used to predict the risk associated with decisions such as issuing a loan or underwriting an insurance policy. These models are trained using historical data from which they extract the key indicators of risk. The output from risk prediction models can be used by organizations to make better risk judgments.",
            "zh": "é£é™©è¯„ä¼°ï¼šé£é™©æ˜¯ç»„ç»‡åšå‡ºçš„å‡ ä¹æ¯ä¸ªå†³ç­–çš„å…³é”®å½±å“å› ç´ ä¹‹ä¸€ã€‚é¢„æµ‹åˆ†ææ¨¡å‹å¯ç”¨äºé¢„æµ‹ä¸å†³ç­–ç›¸å…³çš„é£é™©ï¼Œä¾‹å¦‚å‘æ”¾è´·æ¬¾æˆ–æ‰¿ä¿ä¿é™©å•ã€‚è¿™äº›æ¨¡å‹ä½¿ç”¨å†å²æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»ä¸­æå–å…³é”®é£é™©æŒ‡æ ‡ã€‚ç»„ç»‡å¯ä»¥ä½¿ç”¨é£é™©é¢„æµ‹æ¨¡å‹çš„è¾“å‡ºæ¥åšå‡ºæ›´å¥½çš„é£é™©åˆ¤æ–­ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in domains where we have good prior knowledge of the independence relationships between features, we can encode this prior structural information into a generative model.",
            "zh": "ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬å¯¹ç‰¹å¾ä¹‹é—´çš„ç‹¬ç«‹å…³ç³»æœ‰å¾ˆå¥½çš„å…ˆéªŒçŸ¥è¯†çš„é¢†åŸŸä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›å…ˆéªŒç»“æ„ä¿¡æ¯ç¼–ç åˆ°ç”Ÿæˆæ¨¡å‹ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the notation meanings are the same as for Equation (9.11)[551]. The average class accuracyHM for the model performances shown in Tables 9.5[551] and 9.6[551] are",
            "zh": "å…¶ä¸­ç¬¦å·å«ä¹‰ä¸ç­‰å¼ï¼ˆ9.11ï¼‰[551]ç›¸åŒã€‚è¡¨9.5[551]å’Œè¡¨9.6[551]æ‰€ç¤ºæ¨¡å‹æ€§èƒ½çš„å¹³å‡ç­‰çº§ç²¾åº¦HMä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 2.12[47] shows how the major tasks described in this chapter align with these phases.",
            "zh": "å›¾2.12[47]æ˜¾ç¤ºäº†æœ¬ç« ä¸­æè¿°çš„ä¸»è¦ä»»åŠ¡å¦‚ä½•ä¸è¿™äº›é˜¶æ®µä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "This choice of these initial seeds, unfortunately, can have a big impact on the performance of the algorithm.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œè¿™äº›åˆå§‹ç§å­çš„é€‰æ‹©å¯èƒ½ä¼šå¯¹ç®—æ³•çš„æ€§èƒ½äº§ç”Ÿé‡å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imputation (median: 0.0)",
            "zh": "æ’è¡¥ï¼ˆä¸­ä½æ•°ï¼š0.0ï¼‰"
        }
    },
    {
        "translation": {
            "en": "In these images the training data instances are shown as symbols on the feature space (triangles for good and crosses for bad), the decision boundaries learned by each algorithm are represented by thick black lines, and the underlying actual decision boundaries are shown by the background shading.",
            "zh": "åœ¨è¿™äº›å›¾åƒä¸­ï¼Œè®­ç»ƒæ•°æ®å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸Šæ˜¾ç¤ºä¸ºç¬¦å·ï¼ˆä¸‰è§’å½¢è¡¨ç¤ºå¥½ï¼Œåå­—è¡¨ç¤ºåï¼‰ï¼Œæ¯ä¸ªç®—æ³•å­¦ä¹ çš„å†³ç­–è¾¹ç•Œç”¨ç²—é»‘çº¿è¡¨ç¤ºï¼Œåº•å±‚çš„å®é™…å†³ç­–è¾¹ç•Œç”±èƒŒæ™¯é˜´å½±æ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A prediction model that works in this way is making a maximum a posteriori (MAP) prediction.11 We can formally define a Bayesian MAP prediction model as",
            "zh": "ä»¥è¿™ç§æ–¹å¼å·¥ä½œçš„é¢„æµ‹æ¨¡å‹æ­£åœ¨è¿›è¡Œæœ€å¤§åéªŒ ï¼ˆMAPï¼‰ é¢„æµ‹.11 æˆ‘ä»¬å¯ä»¥å°†è´å¶æ–¯ MAP é¢„æµ‹æ¨¡å‹æ­£å¼å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "EXPFLUXIVAR_U/G/R/I/Z",
            "zh": "EXPFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It is in small differences like this that we see the impact of working on samples rather than populations.",
            "zh": "æ­£æ˜¯åœ¨è¿™æ ·çš„å¾®å°å·®å¼‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¯¹æ ·æœ¬è€Œä¸æ˜¯æ€»ä½“çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Numeric: True numeric values that allow arithmetic operations (e.g., price, age)",
            "zh": "æ•°å€¼ï¼šå…è®¸ç®—æœ¯è¿ç®—çš„çœŸå®æ•°å€¼ï¼ˆä¾‹å¦‚ï¼Œä»·æ ¼ã€å¹´é¾„ï¼‰"
        }
    },
    {
        "translation": {
            "en": "artificial neural network, 369",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œï¼Œ369"
        }
    },
    {
        "translation": {
            "en": "We begin by explaining the concept of an intelligent agent and then describe the fundamental building blocks of reinforcement learning.",
            "zh": "æˆ‘ä»¬é¦–å…ˆè§£é‡Šæ™ºèƒ½ä»£ç†çš„æ¦‚å¿µï¼Œç„¶åæè¿°å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ„å»ºå—ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.3â€…â€…â€…A confusion matrix for the set of predictions shown in Table 9.1[537].",
            "zh": "9.3 è¡¨9.1[537]æ‰€ç¤ºçš„ä¸€ç»„é¢„æµ‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "hidden layers, 389",
            "zh": "éšè—å±‚ï¼Œ 389"
        }
    },
    {
        "translation": {
            "en": "Document Classification: Predictive data analytics can be used to automatically classify documents into different categories. Examples include email spam filtering, news sentiment analysis, customer complaint redirection, and medical decision making. In fact, the definition of a document can be expanded to include images, sounds, and videos, all of which can be classified using predictive data analytics models.",
            "zh": "æ–‡æ¡£åˆ†ç±»ï¼šé¢„æµ‹æ•°æ®åˆ†æå¯ç”¨äºè‡ªåŠ¨å°†æ–‡æ¡£åˆ†ç±»ä¸ºä¸åŒçš„ç±»åˆ«ã€‚ç¤ºä¾‹åŒ…æ‹¬åƒåœ¾é‚®ä»¶è¿‡æ»¤ã€æ–°é—»æƒ…ç»ªåˆ†æã€å®¢æˆ·æŠ•è¯‰é‡å®šå‘å’ŒåŒ»ç–—å†³ç­–ã€‚äº‹å®ä¸Šï¼Œæ–‡æ¡£çš„å®šä¹‰å¯ä»¥æ‰©å±•åˆ°åŒ…æ‹¬å›¾åƒã€å£°éŸ³å’Œè§†é¢‘ï¼Œæ‰€æœ‰è¿™äº›éƒ½å¯ä»¥ä½¿ç”¨é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹è¿›è¡Œåˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "These values are marked in Figure C.1[765].",
            "zh": "è¿™äº›å€¼æ ‡è®°åœ¨å›¾C.1[765]ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Next-best-offer models provide an example scenario where the descriptive features are time dependent but the target feature is not.",
            "zh": "æ¬¡ä¼˜äº§å“/æœåŠ¡æ¨¡å‹æä¾›äº†ä¸€ä¸ªç¤ºä¾‹æ–¹æ¡ˆï¼Œå…¶ä¸­æè¿°æ€§è¦ç´ ä¸æ—¶é—´ç›¸å…³ï¼Œä½†ç›®æ ‡è¦ç´ ä¸æ—¶é—´æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4â€…â€…â€…(a) A 3D plot of an error surface and (b) a birdâ€™s-eye view contour plot of the same error surface. The lines indicate the path that the gradient descent algorithm would take across this error surface from four different starting positions to the global minimumâ€”marked as the white dot in the center.",
            "zh": "7.4 ï¼ˆaï¼‰ è¯¯å·®é¢çš„ 3D å›¾å’Œ ï¼ˆbï¼‰ åŒä¸€è¯¯å·®é¢çš„é¸Ÿç°ç­‰å€¼çº¿å›¾ã€‚è¿™äº›çº¿è¡¨ç¤ºæ¢¯åº¦ä¸‹é™ç®—æ³•ä»å››ä¸ªä¸åŒçš„èµ·å§‹ä½ç½®åˆ°å…¨å±€æœ€å°å€¼ï¼ˆæ ‡è®°ä¸ºä¸­å¿ƒçš„ç™½ç‚¹ï¼‰ç©¿è¿‡æ­¤è¯¯å·®è¡¨é¢çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "7,000",
            "zh": "7,000"
        }
    },
    {
        "translation": {
            "en": "Note that even though the shape of the curve in Figure 7.7(e)[329] is similar to the shape in Figure 7.7(d)[329], it takes far fewer iterations to reach the global minimum.",
            "zh": "è¯·æ³¨æ„ï¼Œå°½ç®¡å›¾7.7ï¼ˆeï¼‰[329]ä¸­çš„æ›²çº¿å½¢çŠ¶ä¸å›¾7.7ï¼ˆdï¼‰[329]ä¸­çš„å½¢çŠ¶ç›¸ä¼¼ï¼Œä½†è¾¾åˆ°å…¨å±€æœ€å°å€¼æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°è¦å°‘å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "8.27â€…â€…â€…A schematic of a feedforward artificial neural network with a three-neuron softmax output layer.",
            "zh": "8.27 å…·æœ‰ä¸‰ç¥ç»å…ƒsoftmaxè¾“å‡ºå±‚çš„å‰é¦ˆäººå·¥ç¥ç»ç½‘ç»œç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Individual Features in a Particular Instance",
            "zh": "ç‰¹å®šå®ä¾‹ä¸­çš„å•ä¸ªåŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "Decision trees take this approach.",
            "zh": "å†³ç­–æ ‘é‡‡ç”¨è¿™ç§æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this instance, the weights for the different matrices in the LSTM unit are randomly sampled from a normal distribution Î¼ = 0,Ïƒ = 0.1, and the bias terms have been initialized to 0.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼ŒLSTM å•å…ƒä¸­ä¸åŒçŸ©é˜µçš„æƒé‡ä»æ­£æ€åˆ†å¸ƒ Î¼ = 0ï¼ŒÏƒ = 0.1 ä¸­éšæœºé‡‡æ ·ï¼Œå¹¶ä¸”åå·®é¡¹å·²åˆå§‹åŒ–ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, Figure 12.3(b)[697] shows that customers who churned tended to make more calls outside their bundle than those who did not.",
            "zh": "åŒæ ·ï¼Œå›¾12.3ï¼ˆbï¼‰[697]æ˜¾ç¤ºï¼Œæµå¤±çš„å®¢æˆ·å¾€å¾€æ¯”æ²¡æœ‰æµå¤±çš„å®¢æˆ·åœ¨æ†ç»‘åŒ…ä¹‹å¤–æ‹¨æ‰“æ›´å¤šçš„ç”µè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.7â€ƒExercises",
            "zh": "4.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "Each row represents a fold in the process, in which the black rectangles indicate the data used for testing while the white spaces indicate the data used for training.",
            "zh": "æ¯ä¸€è¡Œè¡¨ç¤ºæµç¨‹ä¸­çš„ä¸€ä¸ªæŠ˜å ï¼Œå…¶ä¸­é»‘è‰²çŸ©å½¢è¡¨ç¤ºç”¨äºæµ‹è¯•çš„æ•°æ®ï¼Œè€Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºç”¨äºè®­ç»ƒçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The CNN architecture was originally applied to handwritten digit recognition, and much of the early work on CNNs was based on the MNIST (pronounced em-nist) dataset40 (Le Cun et al., 1998).",
            "zh": "CNNæ¶æ„æœ€åˆåº”ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ï¼ŒCNNçš„å¤§éƒ¨åˆ†æ—©æœŸå·¥ä½œéƒ½æ˜¯åŸºäºMNISTï¼ˆå‘éŸ³ä¸ºem-nistï¼‰æ•°æ®é›†40ï¼ˆLe Cun et al.ï¼Œ 1998ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in this example we use batch gradient descent training, and so for each weight update we must first calculate a table equivalent to Table 8.6[431] for each example.",
            "zh": "ç„¶è€Œï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰¹é‡æ¢¯åº¦ä¸‹é™è®­ç»ƒï¼Œå› æ­¤å¯¹äºæ¯ä¸ªæƒé‡æ›´æ–°ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—ä¸€ä¸ªç›¸å½“äºæ¯ä¸ªç¤ºä¾‹çš„è¡¨8.6[431]çš„è¡¨æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just about any state representation we could design that would accurately capture the dynamics of this game would result in an action-value table with thousands or hundreds of thousands of entries.",
            "zh": "æˆ‘ä»¬å¯ä»¥è®¾è®¡çš„ä»»ä½•èƒ½å¤Ÿå‡†ç¡®æ•æ‰è¿™ä¸ªæ¸¸æˆåŠ¨æ€çš„çŠ¶æ€è¡¨ç¤ºï¼Œéƒ½ä¼šäº§ç”Ÿä¸€ä¸ªåŒ…å«æ•°åƒæˆ–æ•°åä¸‡ä¸ªæ¡ç›®çš„åŠ¨ä½œå€¼è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Individual Features",
            "zh": "ä¸ªæ€§åŒ–åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "Assuming that the variance of the Î´s for the output layer is equal to 1:",
            "zh": "å‡è®¾è¾“å‡ºå±‚çš„ Î´s æ–¹å·®ç­‰äº 1ï¼š"
        }
    },
    {
        "translation": {
            "en": "A simple Markov process to model the evolution of an infectious disease in individuals during an epidemic using the SUSCEPTIBLE-INFECTED-RECOVERED (S-I-R) model.",
            "zh": "ä¸€ä¸ªç®€å•çš„é©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œä½¿ç”¨æ˜“æ„Ÿ-æ„ŸæŸ“-åº·å¤ ï¼ˆS-I-Rï¼‰ æ¨¡å‹å¯¹æµè¡Œç—…æœŸé—´ä¸ªä½“ä¼ æŸ“ç—…çš„æ¼”å˜è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use bold notation P() to distinguish between a probability distribution and a probability function P().",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç²—ä½“ç¬¦å· Pï¼ˆï¼‰ æ¥åŒºåˆ†æ¦‚ç‡åˆ†å¸ƒå’Œæ¦‚ç‡å‡½æ•° Pï¼ˆï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "batch gradient descent, 327, 416, 417",
            "zh": "æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œ327ã€416ã€417"
        }
    },
    {
        "translation": {
            "en": "For example, if a feature can take three levels (e.g., low, medium, high), then the vector would have three elements.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªç‰¹å¾å¯ä»¥é‡‡ç”¨ä¸‰ä¸ªçº§åˆ«ï¼ˆä¾‹å¦‚ï¼Œä½ã€ä¸­ã€é«˜ï¼‰ï¼Œåˆ™å‘é‡å°†å…·æœ‰ä¸‰ä¸ªå…ƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "error-based learning, 19, 311, 599",
            "zh": "åŸºäºé”™è¯¯çš„å­¦ä¹ ï¼Œ19,311,599"
        }
    },
    {
        "translation": {
            "en": "On the other hand, if a(i) is much larger than b(i), then di is closer on average to members of another cluster than it is on average to the members of its own cluster, and s(i) will be close to âˆ’ 1.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œå¦‚æœ aï¼ˆiï¼‰ æ¯” bï¼ˆiï¼‰ å¤§å¾—å¤šï¼Œåˆ™ di å¹³å‡æ›´æ¥è¿‘å¦ä¸€ä¸ªèšç±»çš„æˆå‘˜ï¼Œè€Œä¸æ˜¯å¹³å‡æ¥è¿‘å…¶è‡ªèº«èšç±»çš„æˆå‘˜ï¼Œå¹¶ä¸” sï¼ˆiï¼‰ å°†æ¥è¿‘ âˆ’ 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Since 2012, however, several larger convolutional networks have been developed, and new and larger models continue to be announced.",
            "zh": "ç„¶è€Œï¼Œè‡ª 2012 å¹´ä»¥æ¥ï¼Œå·²ç»å¼€å‘äº†å‡ ä¸ªæ›´å¤§çš„å·ç§¯ç½‘ç»œï¼Œå¹¶ä¸”ä¸æ–­å®£å¸ƒæ–°çš„å’Œæ›´å¤§çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Applying the chain rule again to the partial derivative part of this equation, and remembering that , we get",
            "zh": "å†æ¬¡å°†é“¾å¼æ³•åˆ™åº”ç”¨äºè¯¥æ–¹ç¨‹çš„åå¯¼æ•°éƒ¨åˆ†ï¼Œå¹¶è®°ä½è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "7.11â€…â€…â€…(a) A surface showing the value of Equation (7.23)[339] for all values of RPM and VIBRATION, with the decision boundary given in Equation (7.23)[339] highlighted; and (b) the same surface linearly thresholded at zero to operate as a predictor.",
            "zh": "7.11 ï¼ˆaï¼‰ æ˜¾ç¤ºæ‰€æœ‰RPMå’ŒVIBRATIONå€¼çš„å…¬å¼ï¼ˆ7.23ï¼‰[339]çš„è¡¨é¢ï¼Œå¹¶çªå‡ºæ˜¾ç¤ºå…¬å¼ï¼ˆ7.23ï¼‰[339]ä¸­ç»™å‡ºçš„å†³å®šè¾¹ç•Œ;ï¼ˆbï¼‰åŒä¸€æ›²é¢çº¿æ€§é˜ˆå€¼ä¸ºé›¶ï¼Œå¯ä½œä¸ºé¢„æµ‹å˜é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Euclidean distance, 185, 200, 231, 237, 577, 601, 602, 620, 631, 632, 636, 731",
            "zh": "æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œ 185ï¼Œ 200ï¼Œ 231ï¼Œ 237ï¼Œ 577ï¼Œ 601ï¼Œ 602ï¼Œ 620ï¼Œ 631ï¼Œ 632ï¼Œ 636ï¼Œ 731"
        }
    },
    {
        "translation": {
            "en": "Very large or very small values simply end up in the highest or lowest bin.",
            "zh": "éå¸¸å¤§æˆ–éå¸¸å°çš„å€¼æœ€ç»ˆéƒ½ä¼šè¿›å…¥æœ€é«˜æˆ–æœ€ä½çš„ç®±ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "This generative versus discriminative distinction is more than just a labeling exercise. Generative and discriminative models learn different concepts. In probabilistic terms, using d to represent the vector of descriptive feature values and tl to represent a target level, a generative model works by",
            "zh": "è¿™ç§ç”Ÿæˆæ€§ä¸æ­§è§†æ€§çš„åŒºåˆ«ä¸ä»…ä»…æ˜¯ä¸€ç§æ ‡ç­¾ç»ƒä¹ ã€‚ç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹å­¦ä¹ ä¸åŒçš„æ¦‚å¿µã€‚åœ¨æ¦‚ç‡æœ¯è¯­ä¸­ï¼Œä½¿ç”¨ d è¡¨ç¤ºæè¿°æ€§ç‰¹å¾å€¼çš„å‘é‡ï¼Œä½¿ç”¨ tl è¡¨ç¤ºç›®æ ‡æ°´å¹³ï¼Œç”Ÿæˆæ¨¡å‹çš„å·¥ä½œåŸç†æ˜¯"
        }
    },
    {
        "translation": {
            "en": "This stability in the internal dynamics of the network, particularly with respect to the gradients, is likely to result in the network learning much faster than networks affected by vanishing or exploding gradients, and it is a result of careful weight initialization.",
            "zh": "ç½‘ç»œå†…éƒ¨åŠ¨æ€çš„è¿™ç§ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯å…³äºæ¢¯åº¦çš„ç¨³å®šæ€§ï¼Œå¯èƒ½å¯¼è‡´ç½‘ç»œå­¦ä¹ é€Ÿåº¦æ¯”å—æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸å½±å“çš„ç½‘ç»œå¿«å¾—å¤šï¼Œè¿™æ˜¯ä»”ç»†çš„æƒé‡åˆå§‹åŒ–çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic data requirements for predictive models are surprisingly simple.",
            "zh": "é¢„æµ‹æ¨¡å‹çš„åŸºæœ¬æ•°æ®è¦æ±‚éå¸¸ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this approach an agent is deployed into the world and acts sequentially, observing the state of the world and taking actions that move it to new states and generate reward.",
            "zh": "åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ™ºèƒ½ä½“è¢«éƒ¨ç½²åˆ°ä¸–ç•Œä¸­å¹¶æŒ‰é¡ºåºè¡ŒåŠ¨ï¼Œè§‚å¯Ÿä¸–ç•Œçš„çŠ¶æ€å¹¶é‡‡å–è¡ŒåŠ¨å°†å…¶ç§»åŠ¨åˆ°æ–°çš„çŠ¶æ€å¹¶äº§ç”Ÿå¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a model that is sensitive to the relative size of the feature values, a feature that was measured in millimeters would have a larger effect on the resulting model predictions than a feature that was measured in meters.14 Clearly we need to address this issue.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å¯¹ç‰¹å¾å€¼çš„ç›¸å¯¹å¤§å°æ•æ„Ÿçš„æ¨¡å‹ä¸­ï¼Œä»¥æ¯«ç±³ä¸ºå•ä½æµ‹é‡çš„ç‰¹å¾æ¯”ä»¥ç±³ä¸ºå•ä½çš„ç‰¹å¾å¯¹æœ€ç»ˆæ¨¡å‹é¢„æµ‹çš„å½±å“æ›´å¤§ã€‚14 æ˜¾ç„¶ï¼Œæˆ‘ä»¬éœ€è¦è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Cumulative gain, (b) lift, and (c) cumulative lift charts for the predictions made on the large test data sample.",
            "zh": "ï¼ˆaï¼‰ å¯¹å¤§å‹æµ‹è¯•æ•°æ®æ ·æœ¬è¿›è¡Œé¢„æµ‹çš„ç´¯ç§¯å¢ç›Šã€ï¼ˆbï¼‰ æå‡å’Œ ï¼ˆcï¼‰ ç´¯ç§¯æå‡å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.11",
            "zh": "è¡¨ 13.11"
        }
    },
    {
        "translation": {
            "en": "4. Sometimes, the variance of a feature, Ïƒ2, rather than its standard deviation, Ïƒ, is listed as the parameter for the normal distribution. In this text we always use the standard deviation Ïƒ.",
            "zh": "4. æœ‰æ—¶ï¼Œç‰¹å¾çš„æ–¹å·® Ïƒ2 è€Œä¸æ˜¯å…¶æ ‡å‡†å·® Ïƒ è¢«åˆ—ä¸ºæ­£æ€åˆ†å¸ƒçš„å‚æ•°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å§‹ç»ˆä½¿ç”¨æ ‡å‡†å·®Ïƒã€‚"
        }
    },
    {
        "translation": {
            "en": "He et al.",
            "zh": "ä»–ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is illustrated in Figure 10.12(e)[621].",
            "zh": "è¯¥è¿‡ç¨‹å¦‚å›¾10.12ï¼ˆeï¼‰[621]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Fundamentally, the nearest neighbor algorithm is a set of local models, each defined using a single instance.",
            "zh": "ä»æ ¹æœ¬ä¸Šè¯´ï¼Œæœ€è¿‘é‚»ç®—æ³•æ˜¯ä¸€ç»„å±€éƒ¨æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨å•ä¸ªå®ä¾‹å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision trees are also discriminative models.",
            "zh": "å†³ç­–æ ‘ä¹Ÿæ˜¯åˆ¤åˆ«æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Real predictive data analytics projects use datasets that are much more complex than those shown in Figure 14.2[737].",
            "zh": "çœŸæ­£çš„é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä½¿ç”¨çš„æ•°æ®é›†æ¯”å›¾14.2[737]æ‰€ç¤ºçš„æ•°æ®é›†å¤æ‚å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the objective functions used by these algorithms are often based on the minimum description length principle, which asserts that the solution with the fewest parameters (shortest description) is the best one.",
            "zh": "å› æ­¤ï¼Œè¿™äº›ç®—æ³•ä½¿ç”¨çš„ç›®æ ‡å‡½æ•°é€šå¸¸åŸºäºæœ€å°æè¿°é•¿åº¦åŸåˆ™ï¼Œè¯¥åŸåˆ™æ–­è¨€å‚æ•°æœ€å°‘ï¼ˆæœ€çŸ­æè¿°ï¼‰çš„è§£å†³æ–¹æ¡ˆæ˜¯æœ€ä½³è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "A.5 Example bar plots for the POSITION feature in Table A.1[750]: (a) frequency bar plot, (b) density bar plot, and (c) order density bar plot.",
            "zh": "A.5 è¡¨A.1[750]ä¸­POSITIONç‰¹å¾çš„ç¤ºä¾‹æ¡å½¢å›¾ï¼šï¼ˆaï¼‰é¢‘ç‡æ¡å½¢å›¾ï¼Œï¼ˆbï¼‰å¯†åº¦æ¡å½¢å›¾å’Œï¼ˆcï¼‰é˜¶å¯†åº¦æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.14",
            "zh": "å›¾ 3.14"
        }
    },
    {
        "translation": {
            "en": "A plot of the logistic function for values of x in the range [âˆ’10, 10] is shown in Figure 7.12(a)[343].",
            "zh": "å›¾7.12ï¼ˆaï¼‰[343]æ˜¾ç¤ºäº†[âˆ’10,10]èŒƒå›´å†…xå€¼çš„é€»è¾‘å‡½æ•°å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The average number of roaming calls made by the customer each month",
            "zh": "å®¢æˆ·æ¯æœˆæ‹¨æ‰“çš„å¹³å‡æ¼«æ¸¸ç”µè¯æ•°"
        }
    },
    {
        "translation": {
            "en": "2. The set of features left to test is empty. This means that we have already tested every feature on the path between the root node and the current node. We have no more features we can use to distinguish between the instances, so we return a single leaf node tree with the majority target level of the dataset as its target level (Algorithm 1[134] Lines 3â€“4).",
            "zh": "2. å‰©ä¸‹çš„è¦æµ‹è¯•çš„ç‰¹å¾é›†æ˜¯ç©ºçš„ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å·²ç»æµ‹è¯•äº†æ ¹èŠ‚ç‚¹å’Œå½“å‰èŠ‚ç‚¹ä¹‹é—´è·¯å¾„ä¸Šçš„æ¯ä¸ªç‰¹å¾ã€‚æˆ‘ä»¬æ²¡æœ‰æ›´å¤šçš„ç‰¹å¾å¯ä»¥ç”¨æ¥åŒºåˆ†å®ä¾‹ï¼Œå› æ­¤æˆ‘ä»¬è¿”å›ä¸€ä¸ªå•å¶èŠ‚ç‚¹æ ‘ï¼Œå…¶ä¸­æ•°æ®é›†çš„å¤§å¤šæ•°ç›®æ ‡çº§åˆ«ä½œä¸ºå…¶ç›®æ ‡çº§åˆ«ï¼ˆç®—æ³• 1[134] ç¬¬ 3-4 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently we require only a two-dimensional filter because all pixel information for an image can be represented in a two-dimensional matrix indexing over the height and width of the grayscale image.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸€ä¸ªäºŒç»´æ»¤æ³¢å™¨ï¼Œå› ä¸ºå›¾åƒçš„æ‰€æœ‰åƒç´ ä¿¡æ¯éƒ½å¯ä»¥åœ¨äºŒç»´çŸ©é˜µä¸­è¡¨ç¤ºï¼Œå¹¶åœ¨ç°åº¦å›¾åƒçš„é«˜åº¦å’Œå®½åº¦ä¸Šè¿›è¡Œç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Different machine learning algorithms encode different inductive biases.",
            "zh": "ä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•ç¼–ç ä¸åŒçš„å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "A small sample of the generators dataset with two features, RPM and VIBRATION, and two target levels, good (shown as crosses) and faulty (shown as triangles): (a) a decision boundary with a very small margin; and (b) a decision boundary with a much larger margin. In both cases, the instances along the margins are highlighted.",
            "zh": "ç”Ÿæˆå™¨æ•°æ®é›†çš„ä¸€ä¸ªå°æ ·æœ¬ï¼Œå…·æœ‰ä¸¤ä¸ªç‰¹å¾ï¼ŒRPM å’Œ VIBRATIONï¼Œä»¥åŠä¸¤ä¸ªç›®æ ‡æ°´å¹³ï¼Œè‰¯å¥½ï¼ˆæ˜¾ç¤ºä¸ºåå­—ï¼‰å’Œé”™è¯¯ï¼ˆæ˜¾ç¤ºä¸ºä¸‰è§’å½¢ï¼‰ï¼šï¼ˆaï¼‰ è¾¹é™…éå¸¸å°çš„å†³ç­–è¾¹ç•Œ;ï¼ˆbï¼‰å…·æœ‰æ›´å¤§ä½™åœ°çš„å†³ç­–è¾¹ç•Œã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œè¾¹è·ä¸Šçš„å®ä¾‹éƒ½ä¼šçªå‡ºæ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Near the end of this chapter we covered support vector machines (SVM).",
            "zh": "åœ¨æœ¬ç« æ¥è¿‘å°¾å£°æ—¶ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ”¯æŒå‘é‡æœº ï¼ˆSVMï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Vertical bars | | refer to counts of occurrences (e.g., |a = l| represents the number of times that a = l occurs in a dataset).",
            "zh": "ç«–æ† | |è¯·å‚é˜…å‡ºç°æ¬¡æ•°ï¼ˆä¾‹å¦‚ï¼Œ|a = l| è¡¨ç¤ºæ•°æ®é›†ä¸­ a = l å‡ºç°çš„æ¬¡æ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix.",
            "zh": "æ··æ·†çŸ©é˜µçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4(a)[190] illustrates the Voronoi tessellation of the feature space using the training instances from Table 5.2[183] and shows the position of our sample query instance within this decomposition.",
            "zh": "å›¾5.4ï¼ˆaï¼‰[190]ä½¿ç”¨è¡¨5.2[183]ä¸­çš„è®­ç»ƒå®ä¾‹è¯´æ˜äº†ç‰¹å¾ç©ºé—´çš„Voronoiç»†åˆ†ï¼Œå¹¶æ˜¾ç¤ºäº†ç¤ºä¾‹æŸ¥è¯¢å®ä¾‹åœ¨æ­¤åˆ†è§£ä¸­çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "single linkage, 619, 620, 635",
            "zh": "å•è¿æ†ï¼Œ619ã€620ã€635"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across an error surface; and (b) the changing sums of squared errors during this journey.",
            "zh": "ï¼ˆaï¼‰ ç©¿è¶Šè¯¯å·®é¢çš„æ—…ç¨‹;ï¼ˆbï¼‰åœ¨æ­¤è¿‡ç¨‹ä¸­å¹³æ–¹è¯¯å·®å’Œçš„å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The car can move at three speeds: stationary, slow, and fast.",
            "zh": "æ±½è½¦å¯ä»¥ä»¥ä¸‰ç§é€Ÿåº¦ç§»åŠ¨ï¼šé™æ­¢ã€æ…¢é€Ÿå’Œå¿«é€Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the top row of the matrix shown in Figure 8.4[390] labeled Hidden layer 1 Weight Matrix contains the weights on the connections coming into Neuron 3 in Figure 8.4[390 hence this row has the label 3.",
            "zh": "ä¾‹å¦‚ï¼Œå›¾ 8.4[390] ä¸­æ‰€ç¤ºçš„çŸ©é˜µçš„é¡¶è¡Œæ ‡è®°ä¸ºéšè—å±‚ 1 æƒé‡çŸ©é˜µï¼Œå…¶ä¸­åŒ…å«å›¾ 8.4[390] ä¸­è¿›å…¥ç¥ç»å…ƒ 3 çš„è¿æ¥ä¸Šçš„æƒé‡ï¼Œå› æ­¤è¯¥è¡Œå…·æœ‰æ ‡ç­¾ 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Any information reduction process will result in some information loss, and a single measure of model performance will be designed to emphasize some aspects of model performance and de-emphasize, or lose, others.",
            "zh": "ä»»ä½•ä¿¡æ¯ç¼©å‡è¿‡ç¨‹éƒ½ä¼šå¯¼è‡´ä¸€äº›ä¿¡æ¯ä¸¢å¤±ï¼Œå¹¶ä¸”æ¨¡å‹æ€§èƒ½çš„å•ä¸€åº¦é‡å°†è¢«è®¾è®¡ä¸ºå¼ºè°ƒæ¨¡å‹æ€§èƒ½çš„æŸäº›æ–¹é¢ï¼Œè€Œä¸å¼ºè°ƒæˆ–ä¸¢å¤±å…¶ä»–æ–¹é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.2[119] illustrates the possible question sequences that can follow in a game beginning with Question 2.",
            "zh": "å›¾ 4.2[119] è¯´æ˜äº†ä»é—®é¢˜ 2 å¼€å§‹çš„æ¸¸æˆä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜åºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "SCHOOL YEARS refers to the mean number of years spent in school for adult females.",
            "zh": "å­¦é¾„æ˜¯æŒ‡æˆå¹´å¥³æ€§åœ¨æ ¡çš„å¹³å‡å¹´é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "violin plot, 451",
            "zh": "å°æç´æƒ…èŠ‚ï¼Œ451"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to build a second set of models in which she would address the target level imbalance issue.",
            "zh": "Jocelyn å†³å®šå»ºç«‹ç¬¬äºŒç»„æ¨¡å‹ï¼Œä»¥è§£å†³ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The age-income dataset.",
            "zh": "å¹´é¾„-æ”¶å…¥æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second issue affecting the feasibility of an analytics solution is the ability of the business to utilize the insight that the solution provides. If a business is required to drastically revise all their processes to take advantage of the insights that can be garnered from a predictive model, the business may not be ready to do this no matter how good the model is. In many cases the best predictive analytics solutions are those that fit easily into an existing business process.",
            "zh": "å½±å“åˆ†æè§£å†³æ–¹æ¡ˆå¯è¡Œæ€§çš„ç¬¬äºŒä¸ªé—®é¢˜æ˜¯ä¼ä¸šåˆ©ç”¨è§£å†³æ–¹æ¡ˆæä¾›çš„æ´å¯ŸåŠ›çš„èƒ½åŠ›ã€‚å¦‚æœä¼ä¸šéœ€è¦å¤§å¹…ä¿®æ”¹å…¶æ‰€æœ‰æµç¨‹ä»¥åˆ©ç”¨å¯ä»¥ä»é¢„æµ‹æ¨¡å‹ä¸­è·å¾—çš„è§è§£ï¼Œé‚£ä¹ˆæ— è®ºæ¨¡å‹æœ‰å¤šå¥½ï¼Œä¼ä¸šéƒ½å¯èƒ½è¿˜æ²¡æœ‰å‡†å¤‡å¥½è¿™æ ·åšã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæœ€å¥½çš„é¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆæ˜¯é‚£äº›å®¹æ˜“é€‚åº”ç°æœ‰ä¸šåŠ¡æµç¨‹çš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The average number of customer calls dropped each month",
            "zh": "æ¯ä¸ªæœˆçš„å¹³å‡å®¢æˆ·ç”µè¯æ•°é‡ä¸‹é™"
        }
    },
    {
        "translation": {
            "en": "Chapter 6 of Mitchell (1997) provides an excellent overview of Bayesian learning. Barber (2012) is a more recent machine learning textbook that adopts a Bayesian approach to learning and inference.",
            "zh": "Mitchellï¼ˆ1997ï¼‰çš„ç¬¬6ç« å¯¹è´å¶æ–¯å­¦ä¹ è¿›è¡Œäº†å¾ˆå¥½çš„æ¦‚è¿°ã€‚Barber ï¼ˆ2012ï¼‰ æ˜¯ä¸€æœ¬è¾ƒæ–°çš„æœºå™¨å­¦ä¹ æ•™ç§‘ä¹¦ï¼Œé‡‡ç”¨è´å¶æ–¯æ–¹æ³•æ¥å­¦ä¹ å’Œæ¨ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "BLOOD",
            "zh": "è¡€"
        }
    },
    {
        "translation": {
            "en": "to the much simpler",
            "zh": "åˆ°æ›´ç®€å•"
        }
    },
    {
        "translation": {
            "en": "Treatment Group",
            "zh": "æ²»ç–—ç»„"
        }
    },
    {
        "translation": {
            "en": "12.5â€…â€…â€…A pruned decision tree built for the AT churn prediction problem. Gray leaf nodes indicate a churn prediction, and clear leaf nodes indicate a non-churn prediction. For space reasons, we show only the features tested at the top-level nodes.",
            "zh": "12.5 é’ˆå¯¹ AT æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„ä¿®å‰ªå†³ç­–æ ‘ã€‚ç°å¶èŠ‚ç‚¹è¡¨ç¤ºæµå¤±é¢„æµ‹ï¼Œæ¸…é™¤å¶èŠ‚ç‚¹è¡¨ç¤ºéæµå¤±é¢„æµ‹ã€‚ç”±äºç¯‡å¹…åŸå› ï¼Œæˆ‘ä»¬åªæ˜¾ç¤ºåœ¨é¡¶çº§èŠ‚ç‚¹ä¸Šæµ‹è¯•çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "type II errors, 538",
            "zh": "ç±»å‹ II é”™è¯¯ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "We can say that this model is consistent with the dataset because there are no instances in the dataset for which the model does not make a correct prediction. When new mortgage applications are made, we can use this model to predict whether the applicant will repay the mortgage or default on it and make lending decisions on the basis of this prediction.",
            "zh": "æˆ‘ä»¬å¯ä»¥è¯´è¿™ä¸ªæ¨¡å‹ä¸æ•°æ®é›†æ˜¯ä¸€è‡´çš„ï¼Œå› ä¸ºæ•°æ®é›†ä¸­æ²¡æœ‰æ¨¡å‹æ²¡æœ‰åšå‡ºæ­£ç¡®é¢„æµ‹çš„å®ä¾‹ã€‚å½“æå‡ºæ–°çš„æŠµæŠ¼è´·æ¬¾ç”³è¯·æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥é¢„æµ‹ç”³è¯·äººæ˜¯å¿è¿˜æŠµæŠ¼è´·æ¬¾è¿˜æ˜¯è¿çº¦ï¼Œå¹¶æ ¹æ®è¿™ä¸ªé¢„æµ‹åšå‡ºè´·æ¬¾å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.2(b)[746] shows the extended basketball team ordered from smallest to tallest, with the height of the each player listed below the player. The median value of this set is 150 and is shown as the dashed gray line in Figure A.2(b)[746]. In this case the median better captures the central tendency of the set of values.",
            "zh": "å›¾A.2ï¼ˆbï¼‰[746]æ˜¾ç¤ºäº†ä»å°åˆ°é«˜çš„æ‰©å±•ç¯®çƒé˜Ÿï¼Œæ¯ä¸ªçƒå‘˜çš„èº«é«˜åˆ—åœ¨çƒå‘˜çš„ä¸‹æ–¹ã€‚è¯¥é›†åˆçš„ä¸­å€¼ä¸º150ï¼Œåœ¨å›¾A.2ï¼ˆbï¼‰[746]ä¸­æ˜¾ç¤ºä¸ºç°è‰²è™šçº¿ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸­ä½æ•°æ›´å¥½åœ°æ•æ‰äº†å€¼é›†çš„ä¸­å¿ƒè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2â€…â€…â€…Fundamentals",
            "zh": "8.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "If, however, a neuron used a different activation function, then we would use the derivative of that function when we are calculating âˆ‚ak/âˆ‚zk; however, we would do so in the same way, by plugging the zk value into the derivative.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœç¥ç»å…ƒä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆæˆ‘ä»¬åœ¨è®¡ç®— âˆ‚ak/âˆ‚zk;ä½†æ˜¯ï¼Œæˆ‘ä»¬å°†ä»¥ç›¸åŒçš„æ–¹å¼æ‰§è¡Œæ­¤æ“ä½œï¼Œæ–¹æ³•æ˜¯å°† ZK å€¼ä»£å…¥å¯¼æ•°ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The bar plot on the left shows the distribution of the different levels of the CAREER STAGE feature across the entire dataset.",
            "zh": "å·¦ä¾§çš„æ¡å½¢å›¾æ˜¾ç¤ºäº† CAREER STAGE ç‰¹å¾ä¸åŒçº§åˆ«çš„åˆ†å¸ƒåœ¨æ•´ä¸ªæ•°æ®é›†ä¸­çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "A value near 1 indicates that the corresponding element of the cell state should be updated, and a value near 0 indicates that the corresponding element of the cell state should be preserved as is.",
            "zh": "æ¥è¿‘ 1 çš„å€¼è¡¨ç¤ºåº”æ›´æ–°å•å…ƒæ ¼çŠ¶æ€çš„ç›¸åº”å…ƒç´ ï¼Œæ¥è¿‘ 0 çš„å€¼è¡¨ç¤ºå•å…ƒæ ¼çŠ¶æ€çš„ç›¸åº”å…ƒç´ åº”æŒ‰åŸæ ·ä¿ç•™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.13",
            "zh": "å›¾ 9.13"
        }
    },
    {
        "translation": {
            "en": "where Î³ is a discount rate and is a value in [0,1]. This implements an exponential discounting so that future expected rewards have less and less impact on the value calculated for an action. Choosing a low value for Î³ makes the action-value function focus heavily on the most immediate rewards. For example, with Î³ = 0.1",
            "zh": "å…¶ä¸­ Î³ æ˜¯è´´ç°ç‡ï¼Œæ˜¯ [0,1] ä¸­çš„å€¼ã€‚è¿™å®ç°äº†æŒ‡æ•°æŠ˜æ‰£ï¼Œå› æ­¤æœªæ¥çš„é¢„æœŸå¥–åŠ±å¯¹ä¸ºæ“ä½œè®¡ç®—çš„ä»·å€¼çš„å½±å“è¶Šæ¥è¶Šå°ã€‚ä¸ºÎ³é€‰æ‹©ä½å€¼ä¼šä½¿è¡ŒåŠ¨ä»·å€¼å‡½æ•°ä¸»è¦å…³æ³¨æœ€ç›´æ¥çš„å¥–åŠ±ã€‚ä¾‹å¦‚ï¼ŒÎ³ = 0.1"
        }
    },
    {
        "translation": {
            "en": "interval data, 34",
            "zh": "åŒºé—´æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "One of the most common uses of a validation set is to avoid overfitting when using machine learning algorithms that iteratively build more and more complex models.",
            "zh": "éªŒè¯é›†æœ€å¸¸è§çš„ç”¨é€”ä¹‹ä¸€æ˜¯åœ¨ä½¿ç”¨ä»¥è¿­ä»£æ–¹å¼æ„å»ºè¶Šæ¥è¶Šå¤æ‚çš„æ¨¡å‹çš„æœºå™¨å­¦ä¹ ç®—æ³•æ—¶é¿å…è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculations for the weighted k nearest neighbor prediction.",
            "zh": "åŠ æƒ k æœ€è¿‘é‚»é¢„æµ‹çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two levels in the target feature domain, four levels in the CREDIT HISTORY domain, three in the GUARANTOR/COAPPLICANT domain, and three in the ACCOMMODATION domain.",
            "zh": "ç›®æ ‡ç‰¹å¾åŸŸä¸­æœ‰ä¸¤ä¸ªçº§åˆ«ï¼Œä¿¡ç”¨è®°å½•åŸŸä¸­æœ‰å››ä¸ªçº§åˆ«ï¼Œæ‹…ä¿äºº/å…±åŒç”³è¯·äººåŸŸä¸­æœ‰ä¸‰ä¸ªçº§åˆ«ï¼ŒACCOMMODATIONåŸŸä¸­æœ‰ä¸‰ä¸ªçº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "As long as both the treatment group and the control group are representative of the overall population, at the end of the trial period, the doctors running the trial can be confident that any improvement they see in the patients in the treatment group that they do not see in the control group is due to the new medicine.",
            "zh": "åªè¦æ²»ç–—ç»„å’Œå¯¹ç…§ç»„éƒ½ä»£è¡¨äº†æ•´ä¸ªäººç¾¤ï¼Œåœ¨è¯•éªŒæœŸç»“æŸæ—¶ï¼Œè¿›è¡Œè¯•éªŒçš„åŒ»ç”Ÿå¯ä»¥ç¡®ä¿¡ï¼Œä»–ä»¬åœ¨æ²»ç–—ç»„æ‚£è€…èº«ä¸Šçœ‹åˆ°çš„ä»»ä½•æ”¹å–„ï¼Œä»–ä»¬åœ¨å¯¹ç…§ç»„ä¸­æ²¡æœ‰çœ‹åˆ°ï¼Œéƒ½æ˜¯ç”±äºæ–°è¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Compute the entropy of the original dataset with respect to the target feature. This gives us a measure of how much information is required to organize the dataset into pure sets.",
            "zh": "1. è®¡ç®—åŸå§‹æ•°æ®é›†ç›¸å¯¹äºç›®æ ‡ç‰¹å¾çš„ç†µã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å°†æ•°æ®é›†ç»„ç»‡æˆçº¯é›†æ‰€éœ€çš„ä¿¡æ¯é‡åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "graphical models, 304, 742",
            "zh": "å›¾å½¢æ¨¡å‹ï¼Œ304,742"
        }
    },
    {
        "translation": {
            "en": "guided search, 274, 319, 321",
            "zh": "å¼•å¯¼å¼æœç´¢ï¼Œ 274ï¼Œ 319ï¼Œ 321"
        }
    },
    {
        "translation": {
            "en": "For example, recall Neuron 4 in the ReLU network in Section 8.4.1[434 this neuron was inactive for all the input examples and so the weights of the neuron would never be updated, and it was therefore stuck in this dead state.",
            "zh": "ä¾‹å¦‚ï¼Œå›æƒ³ä¸€ä¸‹ç¬¬ 8.4.1 èŠ‚ä¸­ ReLU ç½‘ç»œä¸­çš„ç¥ç»å…ƒ 4[434 è¯¥ç¥ç»å…ƒåœ¨æ‰€æœ‰è¾“å…¥ç¤ºä¾‹ä¸­éƒ½å¤„äºéæ´»åŠ¨çŠ¶æ€ï¼Œå› æ­¤ç¥ç»å…ƒçš„æƒé‡æ°¸è¿œä¸ä¼šæ›´æ–°ï¼Œå› æ­¤å®ƒå¤„äºè¿™ç§æ­»çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The point on the error surface at which the partial derivatives with respect to w[0] and w[1] are equal to 0 is simply the point at the very bottom of the bowl defined by the error surfaceâ€”there is no slope at the bottom of the bowl.",
            "zh": "è¯¯å·®æ›²é¢ä¸Šç›¸å¯¹äº w[0] å’Œ w[1] çš„åå¯¼æ•°ç­‰äº 0 çš„ç‚¹å°±æ˜¯ç”±è¯¯å·®æ›²é¢å®šä¹‰çš„ç¢—æœ€åº•éƒ¨çš„ç‚¹ï¼Œå³ç¢—åº•éƒ¨æ²¡æœ‰æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.3â€…â€…â€…Data Preparation",
            "zh": "13.3 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "The next section describes one of the most important of these, temporal-difference learning.",
            "zh": "ä¸‹ä¸€èŠ‚å°†ä»‹ç»å…¶ä¸­æœ€é‡è¦çš„ä¸€ç§ï¼Œå³æ—¶é—´å·®åˆ†å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model will be used to target the marketing campaign only to those customers who are most likely to purchase the pension product.",
            "zh": "è¯¥æ¨¡å‹å°†ç”¨äºä»…é’ˆå¯¹æœ€æœ‰å¯èƒ½è´­ä¹°å…»è€é‡‘äº§å“çš„å®¢æˆ·è¿›è¡Œè¥é”€æ´»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23[453] illustrates the internal dynamics of the network shown in Figure 8.22[450] during the first iteration of training if we initialize the weights of the network by sampling from a normal distribution with Î¼ = 0.0 and Ïƒ = 0.01 and pass our 100 examples through the network as a single mini-batch.",
            "zh": "å›¾ 8.23[453] è¯´æ˜äº†å›¾ 8.22[450] æ‰€ç¤ºçš„ç½‘ç»œå†…éƒ¨åŠ¨åŠ›å­¦ï¼Œå¦‚æœæˆ‘ä»¬é€šè¿‡ä» Î¼ = 0.0 å’Œ Ïƒ = 0.01 çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·æ¥åˆå§‹åŒ–ç½‘ç»œçš„æƒé‡ï¼Œå¹¶å°†æˆ‘ä»¬çš„ 100 ä¸ªç¤ºä¾‹ä½œä¸ºå•ä¸ªå°æ‰¹é‡é€šè¿‡ç½‘ç»œä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.29â€…â€…â€…An illustration of how different small networks are generated for different training examples by applying dropout to the original large network.",
            "zh": "8.29 ä¸¾ä¾‹è¯´æ˜å¦‚ä½•é€šè¿‡å¯¹åŸæ¥çš„å¤§å‹ç½‘ç»œåº”ç”¨dropoutï¼Œä¸ºä¸åŒçš„è®­ç»ƒå®ä¾‹ç”Ÿæˆä¸åŒçš„å°å‹ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "We can capture the full dynamics of the TwentyTwos MDP in a pair of transition matrices, one for each possible action. For the Twist action the structure of the state transition matrix, ğ’«Twist, is",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨ä¸€å¯¹è¿‡æ¸¡çŸ©é˜µä¸­æ•è· TwentyTwos MDP çš„å®Œæ•´åŠ¨æ€ï¼Œæ¯ä¸ªå¯èƒ½çš„åŠ¨ä½œä¸€ä¸ªã€‚å¯¹äº Twist åŠ¨ä½œï¼ŒçŠ¶æ€è½¬æ¢çŸ©é˜µ PTwist çš„ç»“æ„ä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 7.21[360] shows the training sequence for a multinomial logistic regression model trained using this data (after the data had been range normalized to [âˆ’1, 1]).",
            "zh": "å›¾ 7.21[360] æ˜¾ç¤ºäº†ä½¿ç”¨æ­¤æ•°æ®è®­ç»ƒçš„å¤šé¡¹å¼é€»è¾‘å›å½’æ¨¡å‹çš„è®­ç»ƒåºåˆ—ï¼ˆåœ¨æ•°æ®èŒƒå›´å½’ä¸€åŒ–ä¸º [âˆ’1ï¼Œ 1] ä¹‹åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice as well that the distribution of the z and Î´ values is relatively stable across the layers (see Figure 8.26(b)[462] and Figure 8.26(d)[462]).",
            "zh": "è¿˜è¦æ³¨æ„çš„æ˜¯ï¼Œzå’ŒÎ´å€¼åœ¨å„å±‚ä¸­çš„åˆ†å¸ƒç›¸å¯¹ç¨³å®šï¼ˆå‚è§å›¾8.26ï¼ˆbï¼‰[462]å’Œå›¾8.26ï¼ˆdï¼‰[462]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, we simply need to define two PDFs for the new feature with each PDF conditioned on a different level of the target feature: P(AB = x | fr) = PDF1(AB = x | fr) and P(AB = x | Â¬fr) = PDF2(AB = x | Â¬fr).",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸ºæ–°åŠŸèƒ½å®šä¹‰ä¸¤ä¸ª PDFï¼Œæ¯ä¸ª PDF éƒ½ä»¥ç›®æ ‡åŠŸèƒ½çš„ä¸åŒçº§åˆ«ä¸ºæ¡ä»¶ï¼šPï¼ˆAB = x | frï¼‰ = PDF1ï¼ˆAB = x | frï¼‰ å’Œ Pï¼ˆAB = x | Â¬frï¼‰ = PDF2ï¼ˆAB = x | Â¬frï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this discussion it may be useful to quickly refer to Figure (4.6)[125] to see a plot of how the negative log of a probability changes as the probability changes (Figure (4.6)[125] shows this plot for binary logs, but the general shape of the plot is similar for natural logs).",
            "zh": "å¯¹äºè¿™ä¸ªè®¨è®ºï¼Œå¿«é€Ÿå‚è€ƒå›¾ï¼ˆ4.6ï¼‰[125]ï¼ŒæŸ¥çœ‹æ¦‚ç‡çš„è´Ÿå¯¹æ•°å¦‚ä½•éšæ¦‚ç‡å˜åŒ–çš„å›¾ï¼ˆå›¾ï¼ˆ4.6ï¼‰[125]æ˜¾ç¤ºäº†äºŒè¿›åˆ¶å¯¹æ•°çš„å›¾ï¼Œä½†å›¾çš„ä¸€èˆ¬å½¢çŠ¶ä¸è‡ªç„¶å¯¹æ•°ç›¸ä¼¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 2.3[32] the domain concepts Claimant History and Claimant Links have both been broken down into a number of domain subconcepts.",
            "zh": "åœ¨å›¾2.3[32]ä¸­ï¼ŒåŸŸåæ¦‚å¿µâ€œç´¢èµ”äººå†å²â€å’Œâ€œåŸŸåé“¾æ¥â€éƒ½è¢«åˆ†è§£ä¸ºè®¸å¤šåŸŸåå­æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "More recently, hash-based indexes, such as locality sensitive hashing, have been developed.",
            "zh": "æœ€è¿‘ï¼ŒåŸºäºå“ˆå¸Œçš„ç´¢å¼•ï¼ˆä¾‹å¦‚ä½ç½®æ•æ„Ÿå“ˆå¸Œï¼‰å·²ç»å¼€å‘å‡ºæ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also shown are the resulting TPR, TNR, FPR, and FNR values, as well as the misclassification rate for each threshold.",
            "zh": "æ­¤å¤–ï¼Œè¿˜æ˜¾ç¤ºäº†ç”Ÿæˆçš„ TPRã€TNRã€FPR å’Œ FNR å€¼ï¼Œä»¥åŠæ¯ä¸ªé˜ˆå€¼çš„é”™è¯¯åˆ†ç±»ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This index ignores co-absences and is defined as the ratio between the number of co-presences and the total number of features, excluding those that record a co-absence between a pair of instances:18",
            "zh": "æ­¤ç´¢å¼•å¿½ç•¥å…±ç¼ºï¼Œå®šä¹‰ä¸ºå…±å­˜æ•°é‡ä¸è¦ç´ æ€»æ•°ä¹‹é—´çš„æ¯”ç‡ï¼Œä¸åŒ…æ‹¬è®°å½•ä¸€å¯¹å®ä¾‹ä¹‹é—´å…±ç¼ºçš„ç‰¹å¾ï¼š18"
        }
    },
    {
        "translation": {
            "en": "The Lunar Lander environment. The aim of the game is to control the spaceship starting from the top of the world and attempting to land on the landing pad.",
            "zh": "æœˆçƒç€é™†å™¨ç¯å¢ƒã€‚æ¸¸æˆçš„ç›®çš„æ˜¯æ§åˆ¶å®‡å®™é£èˆ¹ä»ä¸–ç•Œä¹‹å·…å¼€å§‹ï¼Œè¯•å›¾é™è½åœ¨ç€é™†å°ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Even worse, because there are no rows in the dataset where f, h, and m are true, there are no rows in the dataset where the conditions for the third term P(Â¬v | f,h,m) hold, so this probability is actually undefined, as calculating it involves a division by zero.",
            "zh": "æ›´ç³Ÿç³•çš„æ˜¯ï¼Œç”±äºæ•°æ®é›†ä¸­æ²¡æœ‰ fã€h å’Œ m ä¸ºçœŸçš„è¡Œï¼Œæ•°æ®é›†ä¸­æ²¡æœ‰ç¬¬ä¸‰é¡¹ Pï¼ˆÂ¬v | fï¼Œhï¼Œmï¼‰ æ¡ä»¶æˆç«‹çš„è¡Œï¼Œå› æ­¤è¯¥æ¦‚ç‡å®é™…ä¸Šæ˜¯æœªå®šä¹‰çš„ï¼Œå› ä¸ºè®¡ç®—å®ƒæ¶‰åŠé™¤ä»¥é›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the other hand, a model built to predict which customers would be most likely to respond to an online ad only needs to do a slightly better than random job of selecting those customers that will actually respond in order to make a profit for the company.",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œä¸€ä¸ªæ¨¡å‹æ˜¯ä¸ºäº†é¢„æµ‹å“ªäº›å®¢æˆ·æœ€æœ‰å¯èƒ½å¯¹åœ¨çº¿å¹¿å‘Šåšå‡ºååº”ï¼Œåªéœ€è¦æ¯”éšæœºé€‰æ‹©é‚£äº›å®é™…å“åº”çš„å®¢æˆ·ç¨å¾®å¥½ä¸€ç‚¹ï¼Œä»¥ä¾¿ä¸ºå…¬å¸åˆ›é€ åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remember that d[0] is a dummy descriptive feature, added to match w[0], with a value of 1 for all training instances.",
            "zh": "è¯·è®°ä½ï¼Œd[0] æ˜¯ä¸€ä¸ªè™šæ‹Ÿæè¿°æ€§ç‰¹å¾ï¼Œæ·»åŠ ä»¥åŒ¹é… w[0]ï¼Œæ‰€æœ‰è®­ç»ƒå®ä¾‹çš„å€¼å‡ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "The two-stage model achieved a classification accuracy of 79.410%.",
            "zh": "ä¸¤é˜¶æ®µæ¨¡å‹çš„åˆ†ç±»å‡†ç¡®ç‡ä¸º79.410%ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Wyh containing the weights for the connections between the hidden layer (h) and the output layer (y); and",
            "zh": "2. Wyh åŒ…å«éšè—å±‚ ï¼ˆhï¼‰ å’Œè¾“å‡ºå±‚ ï¼ˆyï¼‰ ä¹‹é—´è¿æ¥çš„æƒé‡;å’Œ"
        }
    },
    {
        "translation": {
            "en": "Minkowski distance, 185, 186",
            "zh": "é—µå¯å¤«æ–¯åŸºè·ç¦»ï¼Œ185,186"
        }
    },
    {
        "translation": {
            "en": "In this example the test dataset is quite imbalanced, containing 90 instances with the non-churn level and just 10 instances with the churn level.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæµ‹è¯•æ•°æ®é›†éå¸¸ä¸å¹³è¡¡ï¼ŒåŒ…å« 90 ä¸ªå…·æœ‰éæµå¤±çº§åˆ«çš„å®ä¾‹ï¼Œè€Œåªæœ‰ 10 ä¸ªå…·æœ‰æµå¤±çº§åˆ«çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on historical examples, the expected loss in this case, referred to as the loss given default, is $700 (most borrowers will repay some of their loan before defaulting).",
            "zh": "æ ¹æ®å†å²ç¤ºä¾‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢„æœŸæŸå¤±ï¼ˆç§°ä¸ºè¿çº¦æŸå¤±ï¼‰ä¸º 700 ç¾å…ƒï¼ˆå¤§å¤šæ•°å€Ÿæ¬¾äººä¼šåœ¨è¿çº¦å‰å¿è¿˜éƒ¨åˆ†è´·æ¬¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that when the car is driving at a constant speed, on the minor road or the highway, acceleration is zero as the speed is not changing.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“æ±½è½¦ä»¥æ’å®šé€Ÿåº¦è¡Œé©¶æ—¶ï¼Œåœ¨å°è·¯æˆ–é«˜é€Ÿå…¬è·¯ä¸Šï¼Œç”±äºé€Ÿåº¦ä¸å˜ï¼ŒåŠ é€Ÿåº¦ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "34. The data listed in this table is real and is for 2010/11 (or the most recent year prior to 2010/11 when the data was available). The data for the descriptive features in this table was amalgamated from a number of surveys retrieved from Gapminder (www.gapminder.org). The Corruption Perception Index is generated annually by Transparency International (www.transparency.org).",
            "zh": "34. æœ¬è¡¨æ‰€åˆ—æ•°æ®ä¸ºå®æ•°ï¼Œä¸º2010/11å¹´åº¦ï¼ˆæˆ–2010/11å¹´åº¦ä¹‹å‰æœ‰æ•°æ®çš„æœ€è¿‘ä¸€å¹´ï¼‰ã€‚è¯¥è¡¨ä¸­æè¿°æ€§ç‰¹å¾çš„æ•°æ®æ˜¯ä»Gapminderï¼ˆwww.gapminder.orgï¼‰æ£€ç´¢åˆ°çš„ä¸€äº›è°ƒæŸ¥ä¸­åˆå¹¶çš„ã€‚æ¸…å»‰æŒ‡æ•°ç”±é€æ˜å›½é™…ï¼ˆwww.transparency.orgï¼‰æ¯å¹´å‘å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Deep neural networks can contain millions of neurons.",
            "zh": "æ·±åº¦ç¥ç»ç½‘ç»œå¯ä»¥åŒ…å«æ•°ç™¾ä¸‡ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This graph shows that the agentâ€™s performance initially declined, and it started to perform quite badly, until after about 40 episodes its performance began to improve.",
            "zh": "è¿™å¼ å›¾æ˜¾ç¤ºï¼Œç‰¹å·¥çš„è¡¨ç°æœ€åˆæœ‰æ‰€ä¸‹é™ï¼Œå¹¶ä¸”å¼€å§‹è¡¨ç°å¾—å¾ˆå·®ï¼Œç›´åˆ°å¤§çº¦ 40 é›†åï¼Œå®ƒçš„è¡¨ç°å¼€å§‹æ”¹å–„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, and based on discussions with the AT team, Ross included the BILL CHANGE and SOCIAL NETWORK CHANGE domain concepts.",
            "zh": "å‡ºäºè¿™ä¸ªåŸå› ï¼Œåœ¨ä¸ATå›¢é˜Ÿçš„è®¨è®ºä¸­ï¼ŒRossåŠ å…¥äº†BILL CHANGEå’ŒSOCIAL NETWORK CHANGEé¢†åŸŸçš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "This ensures that the dummy descriptive feature (row 0) will be multiplied by the bias terms weights (column 0) in the multiplication operation.",
            "zh": "è¿™å¯ç¡®ä¿åœ¨ä¹˜æ³•è¿ç®—ä¸­å°†è™šæ‹Ÿæè¿°ç‰¹å¾ï¼ˆç¬¬ 0 è¡Œï¼‰ä¹˜ä»¥åå·®é¡¹æƒé‡ï¼ˆç¬¬ 0 åˆ—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder model can be trained like any other feedforward neural network using the backpropagation of error algorithm.11 The only difference is that rather than having a separate target feature vector against which loss is measured, the loss functions used to train these measure the ability of the network to reproduce the inputs for particular instances at its output layer.",
            "zh": "è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹å¯ä»¥åƒä»»ä½•å…¶ä»–å‰é¦ˆç¥ç»ç½‘ç»œä¸€æ ·ä½¿ç”¨è¯¯å·®åå‘ä¼ æ’­ç®—æ³•è¿›è¡Œè®­ç»ƒ.11 å”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œç”¨äºè®­ç»ƒè¿™äº›ç‰¹å¾çš„æŸå¤±å‡½æ•°æµ‹é‡ç½‘ç»œåœ¨å…¶è¾“å‡ºå±‚é‡ç°ç‰¹å®šå®ä¾‹è¾“å…¥çš„èƒ½åŠ›ï¼Œè€Œä¸æ˜¯å…·æœ‰ç”¨äºæµ‹é‡æŸå¤±çš„å•ç‹¬ç›®æ ‡ç‰¹å¾å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the tree uses a mixture of continuous and categorical features and that the ELEVATION feature is used twice with different thresholds in each case.",
            "zh": "è¯·æ³¨æ„ï¼Œè¯¥æ ‘æ··åˆä½¿ç”¨è¿ç»­è¦ç´ å’Œåˆ†ç±»è¦ç´ ï¼Œå¹¶ä¸” ELEVATION è¦ç´ åœ¨æ¯ç§æƒ…å†µä¸‹éƒ½ä½¿ç”¨ä¸¤æ¬¡ï¼Œé˜ˆå€¼ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The first is that the distribution we are sampling from must be a stationary distribution (also known as an invariant distribution).",
            "zh": "é¦–å…ˆï¼Œæˆ‘ä»¬ä»ä¸­é‡‡æ ·çš„åˆ†å¸ƒå¿…é¡»æ˜¯å¹³ç¨³åˆ†å¸ƒï¼ˆä¹Ÿç§°ä¸ºä¸å˜åˆ†å¸ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "logistic function, 342, 386, 461",
            "zh": "é€»è¾‘åŠŸèƒ½ï¼Œ342,386,461"
        }
    },
    {
        "translation": {
            "en": "The continuing process that finds the final model is illustrated in Figure 7.15[350], which shows a selection of the candidate models generated on the way to generating the final model, and the bottom-right panel shows how the sum of squared errors changed during the process.",
            "zh": "å›¾ 7.15[350] è¯´æ˜äº†æ‰¾åˆ°æœ€ç»ˆæ¨¡å‹çš„è¿ç»­è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æ˜¾ç¤ºäº†åœ¨ç”Ÿæˆæœ€ç»ˆæ¨¡å‹çš„è¿‡ç¨‹ä¸­ç”Ÿæˆçš„å€™é€‰æ¨¡å‹çš„é€‰æ‹©ï¼Œå³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†åœ¨æ­¤è¿‡ç¨‹ä¸­å¹³æ–¹è¯¯å·®çš„æ€»å’Œå¦‚ä½•å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "In modern reinforcement learning, however, iterative approaches that calculate approximate solutions are typically used.",
            "zh": "ç„¶è€Œï¼Œåœ¨ç°ä»£å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œé€šå¸¸ä½¿ç”¨è®¡ç®—è¿‘ä¼¼è§£çš„è¿­ä»£æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "An examination of the histogram for the INCOME feature (shown in Figure 3.1(a)[58]) and the actual data for this feature in Table 3.2[56] reveals an interesting pattern.",
            "zh": "å¯¹INCOMEç‰¹å¾çš„ç›´æ–¹å›¾ï¼ˆå¦‚å›¾3.1ï¼ˆaï¼‰[58]æ‰€ç¤ºï¼‰å’Œè¡¨3.2[56]ä¸­è¯¥ç‰¹å¾çš„å®é™…æ•°æ®çš„æ£€æŸ¥æ­ç¤ºäº†ä¸€ä¸ªæœ‰è¶£çš„æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "463.00",
            "zh": "463.00"
        }
    },
    {
        "translation": {
            "en": "Figure 7.15",
            "zh": "å›¾ 7.15"
        }
    },
    {
        "translation": {
            "en": "Wooldridge, Michael. 2009. An introduction to multiagent systems. Wiley.",
            "zh": "ä¼å°”å¾·é‡Œå¥‡ï¼Œè¿ˆå…‹å°”ã€‚2009. å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®€ä»‹.å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these cases, unless the dimensionality is maintained by using imaginary pixels, then the dimensionality of the input to each layer reduces for each subsequent layer.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œé™¤éé€šè¿‡ä½¿ç”¨è™šæ„åƒç´ æ¥ä¿æŒç»´æ•°ï¼Œå¦åˆ™æ¯ä¸ªå±‚çš„è¾“å…¥ç»´æ•°éƒ½ä¼šåœ¨æ¯ä¸ªåç»­å±‚ä¸­å‡å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ROC index can be interpreted probabilistically as the probability that a model will assign a higher rank to a randomly selected positive instance than to a randomly selected negative instance.16 The Gini coefficient17 is another commonly used performance measure that is just a linear rescaling of the ROC index:",
            "zh": "ROC æŒ‡æ•°å¯ä»¥æ¦‚ç‡åœ°è§£é‡Šä¸ºæ¨¡å‹ä¸ºéšæœºé€‰æ‹©çš„æ­£å®ä¾‹åˆ†é…æ¯”éšæœºé€‰æ‹©çš„è´Ÿå®ä¾‹æ›´é«˜çš„æ’åçš„æ¦‚ç‡.16 åŸºå°¼ç³»æ•° 17 æ˜¯å¦ä¸€ç§å¸¸ç”¨çš„ç»©æ•ˆè¡¡é‡æ ‡å‡†ï¼Œå®ƒåªæ˜¯ ROC æŒ‡æ•°çš„çº¿æ€§é‡æ–°è°ƒæ•´ï¼š"
        }
    },
    {
        "translation": {
            "en": "Another useful property of ez is that e0 is 1; as a result, even in the unlikely event that all the zs are 0, we avoid the problem of a division by 0, and each neuron will have an activation of 1/m.",
            "zh": "ez çš„å¦ä¸€ä¸ªæœ‰ç”¨å±æ€§æ˜¯ e0 æ˜¯ 1;å› æ­¤ï¼Œå³ä½¿åœ¨æ‰€æœ‰ z éƒ½ä¸º 0 çš„ä¸å¤ªå¯èƒ½çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿé¿å…äº†é™¤ä»¥ 0 çš„é—®é¢˜ï¼Œå¹¶ä¸”æ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»åº¦ä¸º 1/mã€‚"
        }
    },
    {
        "translation": {
            "en": "For this model, just 31 out of the total 327 features were selected.16 This was not surprising given the large amount of redundancy within the feature set.",
            "zh": "å¯¹äºæ­¤æ¨¡å‹ï¼Œæ€»å…± 327 ä¸ªåŠŸèƒ½ä¸­åªæœ‰ 31 ä¸ªè¢«é€‰ä¸­ã€‚16 è€ƒè™‘åˆ°åŠŸèƒ½é›†ä¸­çš„å¤§é‡å†—ä½™ï¼Œè¿™å¹¶ä¸å¥‡æ€ªã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic normalization technique we introduced was range normalization,15 and we can apply it to the pension plan prediction dataset to normalize the variance in the SALARY and AGE features.",
            "zh": "æˆ‘ä»¬å¼•å…¥çš„åŸºæœ¬å½’ä¸€åŒ–æŠ€æœ¯æ˜¯èŒƒå›´å½’ä¸€åŒ–ï¼Œ15 æˆ‘ä»¬å¯ä»¥å°†å…¶åº”ç”¨äºå…»è€é‡‘è®¡åˆ’é¢„æµ‹æ•°æ®é›†ï¼Œä»¥å½’ä¸€åŒ– SALARY å’Œ AGE ç‰¹å¾ä¸­çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) How many possible models exist for the scenario described by the features in this dataset?",
            "zh": "ï¼ˆaï¼‰ å¯¹äºæœ¬æ•°æ®é›†ä¸­çš„ç‰¹å¾æ‰€æè¿°çš„æƒ…æ™¯ï¼Œæœ‰å¤šå°‘ç§å¯èƒ½çš„æ¨¡å‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "For example, consider a mobile phone network operator that has built a churn prediction model to help address a problem with customers leaving to join other networks.",
            "zh": "ä¾‹å¦‚ï¼Œå‡è®¾ç§»åŠ¨ç”µè¯ç½‘ç»œè¿è¥å•†å·²ç»æ„å»ºäº†ä¸€ä¸ªå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹ï¼Œä»¥å¸®åŠ©è§£å†³å®¢æˆ·ç¦»å¼€åŠ å…¥å…¶ä»–ç½‘ç»œçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In machine learning terms, each row in the dataset is referred to as a training instance, and the overall dataset is referred to as a training dataset.",
            "zh": "åœ¨æœºå™¨å­¦ä¹ æœ¯è¯­ä¸­ï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œéƒ½ç§°ä¸ºè®­ç»ƒå®ä¾‹ï¼Œæ•´ä¸ªæ•°æ®é›†ç§°ä¸ºè®­ç»ƒæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.28",
            "zh": "0.28"
        }
    },
    {
        "translation": {
            "en": "A simple heuristic that is sometimes used to try to avoid dead ReLUs is to initialize all the bias weights of a network to small positive values, such as 0.1, because this increases the likelihood that most of the neurons will initially be active for most of the training examples and so these neurons can learn from these examples (Goodfellow et al., 2016, p. 187).",
            "zh": "æœ‰æ—¶ç”¨äºå°è¯•é¿å…æ­» ReLU çš„ç®€å•å¯å‘å¼æ–¹æ³•æ˜¯å°†ç½‘ç»œçš„æ‰€æœ‰åå·®æƒé‡åˆå§‹åŒ–ä¸ºå°çš„æ­£å€¼ï¼Œä¾‹å¦‚ 0.1ï¼Œå› ä¸ºè¿™å¢åŠ äº†å¤§å¤šæ•°ç¥ç»å…ƒæœ€åˆåœ¨å¤§å¤šæ•°è®­ç»ƒç¤ºä¾‹ä¸­å¤„äºæ´»åŠ¨çŠ¶æ€çš„å¯èƒ½æ€§ï¼Œå› æ­¤è¿™äº›ç¥ç»å…ƒå¯ä»¥ä»è¿™äº›ç¤ºä¾‹ä¸­å­¦ä¹ ï¼ˆGoodfellow ç­‰äººï¼Œ 2016 å¹´ï¼Œç¬¬ 187 é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 6.4(b)[273] has a fat tail distributionâ€”the bars on the extreme left and right of the distribution are still above zero, if only just.",
            "zh": "å›¾6.4ï¼ˆbï¼‰[273]ä¸­çš„æ•°æ®é›†å…·æœ‰è‚¥å°¾åˆ†å¸ƒï¼Œå³åˆ†å¸ƒæœ€å·¦è¾¹å’Œæœ€å³è¾¹çš„æ¡å½¢ä»ç„¶é«˜äºé›¶ï¼Œå³ä½¿åªæ˜¯é›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "A simple retail dataset.",
            "zh": "ä¸€ä¸ªç®€å•çš„é›¶å”®æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The XGBoost (Chen and Guestrin, 2016) gradient boosting implementation played a significant role in popularizing the approach and is a good example of how the basic algorithm can be optimized for performance.",
            "zh": "XGBoost ï¼ˆChen and Guestrinï¼Œ 2016ï¼‰ æ¢¯åº¦æå‡å®ç°åœ¨æ™®åŠè¯¥æ–¹æ³•æ–¹é¢å‘æŒ¥äº†é‡è¦ä½œç”¨ï¼Œå¹¶ä¸”æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œè¯´æ˜å¦‚ä½•ä¼˜åŒ–åŸºæœ¬ç®—æ³•ä»¥æé«˜æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "For all models w[0] is set to 6.47.",
            "zh": "å¯¹äºæ‰€æœ‰å‹å·ï¼Œw[0] è®¾ç½®ä¸º 6.47ã€‚"
        }
    },
    {
        "translation": {
            "en": "The backpropagation of the Î´ values during the backward pass of the backpropagation algorithm. This figure is based on Figure 6.6 of Kelleher (2019).",
            "zh": "åå‘ä¼ æ’­ç®—æ³•å‘åä¼ é€’æœŸé—´Î´å€¼çš„åå‘ä¼ æ’­ã€‚è¯¥æ•°å­—åŸºäºKelleherï¼ˆ2019ï¼‰çš„å›¾6.6ã€‚"
        }
    },
    {
        "translation": {
            "en": "experimental design, 586",
            "zh": "å®éªŒè®¾è®¡ï¼Œ586"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10",
            "zh": "å›¾ 8.10"
        }
    },
    {
        "translation": {
            "en": "He would have no opportunity to exploit the knowledge he established in the first week about the rewards associated with ordering different items.",
            "zh": "ä»–å°†æ²¡æœ‰æœºä¼šåˆ©ç”¨ä»–åœ¨ç¬¬ä¸€å‘¨å»ºç«‹çš„å…³äºè®¢è´­ä¸åŒç‰©å“çš„å¥–åŠ±çš„çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A joint probability refers to the probability of an assignment of specific values to multiple different features, for example, P(MENINGITIS = true,HEADACHE = true) = 0.2.",
            "zh": "è”åˆæ¦‚ç‡æ˜¯æŒ‡å°†ç‰¹å®šå€¼åˆ†é…ç»™å¤šä¸ªä¸åŒç‰¹å¾çš„æ¦‚ç‡ï¼Œä¾‹å¦‚ï¼ŒPï¼ˆMENINGITIS = trueï¼ŒHEADACHE = trueï¼‰ = 0.2ã€‚"
        }
    },
    {
        "translation": {
            "en": "give the number of times a training instance was included in the training set sampled using the sampling distribution.",
            "zh": "ç»™å‡ºä½¿ç”¨æŠ½æ ·åˆ†å¸ƒé‡‡æ ·çš„è®­ç»ƒé›†ä¸­åŒ…å«è®­ç»ƒå®ä¾‹çš„æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This reduction of a network to a single weight matrix by using a matrix product can be done no matter how many layers there are in a network, so long as none of the network layers includes non-linear activation functions.",
            "zh": "æ— è®ºç½‘ç»œä¸­æœ‰å¤šå°‘å±‚ï¼Œåªè¦ç½‘ç»œå±‚ä¸­æ²¡æœ‰ä¸€ä¸ªåŒ…å«éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå°±å¯ä»¥é€šè¿‡ä½¿ç”¨çŸ©é˜µä¹˜ç§¯å°†ç½‘ç»œç®€åŒ–ä¸ºå•ä¸ªæƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "With this extended network architecture, the question arises of how we will initialize the weights.",
            "zh": "æœ‰äº†è¿™ç§æ‰©å±•çš„ç½‘ç»œæ¶æ„ï¼Œé—®é¢˜å°±å‡ºç°äº†ï¼Œæˆ‘ä»¬å°†å¦‚ä½•åˆå§‹åŒ–æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tabulating the workings required to generate a K-S statistic.",
            "zh": "å°†ç”Ÿæˆ K-S ç»Ÿè®¡é‡æ‰€éœ€çš„å·¥ä½œåˆ¶æˆè¡¨æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.5â€ƒEvaluation",
            "zh": "12.5 è¯„ä¼°"
        }
    },
    {
        "translation": {
            "en": "0.13",
            "zh": "0.13"
        }
    },
    {
        "translation": {
            "en": "5.8â€ƒExercises",
            "zh": "5.8 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "In other words, the updates applied to a weight are a function of the Î´ for the neuron that uses the weight in its weighted sum.",
            "zh": "æ¢å¥è¯è¯´ï¼Œåº”ç”¨äºæƒé‡çš„æ›´æ–°æ˜¯ç¥ç»å…ƒçš„Î´å‡½æ•°ï¼Œè¯¥ç¥ç»å…ƒåœ¨å…¶åŠ æƒæ€»å’Œä¸­ä½¿ç”¨æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "summary statistics, 96",
            "zh": "æ±‡æ€»ç»Ÿè®¡ï¼Œ96"
        }
    },
    {
        "translation": {
            "en": "The final prediction is then made by taking the feature level whose neuron predicts the highest probability.",
            "zh": "ç„¶åé€šè¿‡è·å–å…¶ç¥ç»å…ƒé¢„æµ‹æœ€é«˜æ¦‚ç‡çš„ç‰¹å¾çº§åˆ«æ¥åšå‡ºæœ€ç»ˆé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The net result is that the vanishing gradient problem can cause deep networks to take a very long time to train.",
            "zh": "æœ€ç»ˆç»“æœæ˜¯ï¼Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜å¯èƒ½å¯¼è‡´æ·±åº¦ç½‘ç»œéœ€è¦å¾ˆé•¿æ—¶é—´æ¥è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Note that in a density histogram, the height of each bar represents the likelihood that a value in the range defining that bar will occur in a data sample (see Section A.4.2[752]).",
            "zh": "2. è¯·æ³¨æ„ï¼Œåœ¨å¯†åº¦ç›´æ–¹å›¾ä¸­ï¼Œæ¯ä¸ªæŸ±çš„é«˜åº¦è¡¨ç¤ºå®šä¹‰è¯¥æŸ±çš„èŒƒå›´å†…çš„å€¼å‡ºç°åœ¨æ•°æ®æ ·æœ¬ä¸­çš„å¯èƒ½æ€§ï¼ˆå‚è§ç¬¬ A.4.2[752] èŠ‚ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesâ€™ Theorem defines the conditional probability of an event, X, given some evidence, Y, in terms of the product of the inverse conditional probability, P(Y | X), and the prior probability of the event P(X).",
            "zh": "è´å¶æ–¯å®šç†æ ¹æ®é€†æ¡ä»¶æ¦‚ç‡ Pï¼ˆY |Xï¼‰å’Œäº‹ä»¶Pï¼ˆXï¼‰çš„å…ˆéªŒæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information theory basis for this function can be seen in the similarity between Equation (8.66)[465] and the equation for Shannonâ€™s entropy, Equation (4.1)[125].",
            "zh": "è¯¥å‡½æ•°çš„ä¿¡æ¯è®ºåŸºç¡€å¯ä»¥ä»æ–¹ç¨‹ï¼ˆ8.66ï¼‰[465]å’Œé¦™å†œç†µæ–¹ç¨‹ï¼ˆ4.1ï¼‰[125]ä¹‹é—´çš„ç›¸ä¼¼æ€§ä¸­çœ‹å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s now make a prediction using this model for a two-year-old bottle of whiskey that received a magazine rating of 5.",
            "zh": "ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ¨¡å‹å¯¹ä¸€ç“¶ä¸¤å¹´å‰çš„å¨å£«å¿Œè¿›è¡Œé¢„æµ‹ï¼Œè¯¥å¨å£«å¿Œçš„æ‚å¿—è¯„åˆ†ä¸º 5ã€‚"
        }
    },
    {
        "translation": {
            "en": "An unpruned decision tree built for the AT churn prediction problem (shown only to indicate its size and complexity). The excessive complexity and depth of the tree are evidence that overfitting has probably occurred.",
            "zh": "ä¸º AT æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„æœªä¿®å‰ªå†³ç­–æ ‘ï¼ˆæ˜¾ç¤ºä»…ç”¨äºæŒ‡ç¤ºå…¶å¤§å°å’Œå¤æ‚æ€§ï¼‰ã€‚æ ‘çš„è¿‡åº¦å¤æ‚æ€§å’Œæ·±åº¦æ˜¯å¯èƒ½å‘ç”Ÿè¿‡æ‹Ÿåˆçš„è¯æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information gain model we have developed allows us to decide which test we should add to the sequence next because it enables us to select the best feature to use on a given dataset.",
            "zh": "æˆ‘ä»¬å¼€å‘çš„ä¿¡æ¯å¢ç›Šæ¨¡å‹å…è®¸æˆ‘ä»¬å†³å®šæ¥ä¸‹æ¥åº”è¯¥å°†å“ªä¸ªæµ‹è¯•æ·»åŠ åˆ°åºåˆ—ä¸­ï¼Œå› ä¸ºå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿé€‰æ‹©è¦åœ¨ç»™å®šæ•°æ®é›†ä¸Šä½¿ç”¨çš„æœ€ä½³ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Frequencies and proportions are typically presented in a frequency table, which shows the frequency and proportion of each level for a particular featureâ€”usually sorted by descending frequency.",
            "zh": "é¢‘ç‡å’Œæ¯”ä¾‹é€šå¸¸æ˜¾ç¤ºåœ¨é¢‘ç‡è¡¨ä¸­ï¼Œè¯¥è¡¨æ˜¾ç¤ºç‰¹å®šç‰¹å¾çš„æ¯ä¸ªç”µå¹³çš„é¢‘ç‡å’Œæ¯”ä¾‹ï¼Œé€šå¸¸æŒ‰é™åºæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "This is the opposite of the prediction made using the original dataset.",
            "zh": "è¿™ä¸ä½¿ç”¨åŸå§‹æ•°æ®é›†åšå‡ºçš„é¢„æµ‹ç›¸åã€‚"
        }
    },
    {
        "translation": {
            "en": "The learning challenges raised by the second point in the preceding list highlight the main motivation for using networks with more than one hidden layer.",
            "zh": "å‰é¢åˆ—è¡¨ä¸­çš„ç¬¬äºŒç‚¹æå‡ºçš„å­¦ä¹ æŒ‘æˆ˜çªå‡ºäº†ä½¿ç”¨å…·æœ‰å¤šä¸ªéšè—å±‚çš„ç½‘ç»œçš„ä¸»è¦åŠ¨æœºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.7",
            "zh": "å›¾ A.7"
        }
    },
    {
        "translation": {
            "en": "Ashenfelter, Orley. 2008. Predicting the quality and prices of bordeaux wine. The Economic Journal 118 (529): 174â€“184. doi:10.1111/j.1468-0297.2008.02148.x.",
            "zh": "é˜¿ç”³è´¹å°”ç‰¹ï¼Œå¥¥åˆ©ã€‚2008. é¢„æµ‹æ³¢å°”å¤šè‘¡è„é…’çš„è´¨é‡å’Œä»·æ ¼ã€‚ç»æµæ‚å¿—118ï¼ˆ529ï¼‰ï¼š174-184ã€‚doiï¼š10.1111/j.1468-0297.2008.02148.x."
        }
    },
    {
        "translation": {
            "en": "This is shown in Figure 11.5(e)[663].",
            "zh": "å¦‚å›¾11.5ï¼ˆeï¼‰[663]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Essentially, the dendrites are the neuronâ€™s input channels, and the axon is the output channel.",
            "zh": "ä»æœ¬è´¨ä¸Šè®²ï¼Œæ ‘çªæ˜¯ç¥ç»å…ƒçš„è¾“å…¥é€šé“ï¼Œè½´çªæ˜¯è¾“å‡ºé€šé“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.8",
            "zh": "å›¾ 6.8"
        }
    },
    {
        "translation": {
            "en": "The agent performs this action (Line 13[658]), moving to the left, and records the next state, s1 = 0-2, and the reward received, r0 = âˆ’1.",
            "zh": "ä»£ç†æ‰§è¡Œæ­¤æ“ä½œï¼ˆç¬¬ 13 è¡Œ [658]ï¼‰ï¼Œå‘å·¦ç§»åŠ¨ï¼Œå¹¶è®°å½•ä¸‹ä¸€ä¸ªçŠ¶æ€ s1 = 0-2 å’Œæ”¶åˆ°çš„å¥–åŠ± r0 = âˆ’1ã€‚"
        }
    },
    {
        "translation": {
            "en": "18. Multinomial logistic regression models are often known as maximum entropy, conditional maximum entropy, or MaxEnt models.",
            "zh": "18. å¤šé¡¹å¼é€»è¾‘å›å½’æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºæœ€å¤§ç†µã€æ¡ä»¶æœ€å¤§ç†µæˆ– MaxEnt æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "weighted k nearest neighbor, 194, 209, 237, 238",
            "zh": "åŠ æƒ k æœ€è¿‘é‚»ï¼Œ 194ï¼Œ 209ï¼Œ 237ï¼Œ 238"
        }
    },
    {
        "translation": {
            "en": "Long Hair",
            "zh": "é•·é«®"
        }
    },
    {
        "translation": {
            "en": "If a model could be trained to classify brain activity as being associated with positive images or negative images, doctors could use this model to help in assessing the brain function of people who have suffered severe brain injuries and are non-communicative.16 Figure 7.18[355] shows a scatter plot of this dataset, from which it is clear that the decision boundary between the two different types of images is not linearâ€”that is, the two types of images are not linearly separable.",
            "zh": "å¦‚æœå¯ä»¥è®­ç»ƒä¸€ä¸ªæ¨¡å‹å°†å¤§è„‘æ´»åŠ¨åˆ†ç±»ä¸ºä¸æ­£é¢å›¾åƒæˆ–è´Ÿé¢å›¾åƒç›¸å…³ï¼ŒåŒ»ç”Ÿå¯ä»¥ä½¿ç”¨è¯¥æ¨¡å‹æ¥å¸®åŠ©è¯„ä¼°é­å—ä¸¥é‡è„‘æŸä¼¤ä¸”æ— æ³•äº¤æµçš„äººçš„å¤§è„‘åŠŸèƒ½.16å›¾7.18[355]æ˜¾ç¤ºäº†è¯¥æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œä»ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œä¸¤ç§ä¸åŒç±»å‹çš„å›¾åƒä¹‹é—´çš„å†³ç­–è¾¹ç•Œä¸æ˜¯çº¿æ€§çš„ï¼Œå³ è¿™ä¸¤ç§ç±»å‹çš„å›¾åƒä¸æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "exploitation, 655, 656",
            "zh": "å‰¥å‰Šï¼Œ 655ï¼Œ 656"
        }
    },
    {
        "translation": {
            "en": "Consequently, understanding and exploring the data sources related to each domain concept that are available within an organization is a fundamental component of feature design.",
            "zh": "å› æ­¤ï¼Œäº†è§£å’Œæ¢ç´¢ä¸ç»„ç»‡å†…å¯ç”¨çš„æ¯ä¸ªé¢†åŸŸæ¦‚å¿µç›¸å…³çš„æ•°æ®æºæ˜¯åŠŸèƒ½è®¾è®¡çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on this data, calculate the following summary statistics for the AGE feature:",
            "zh": "æ ¹æ®æ­¤æ•°æ®ï¼Œè®¡ç®— AGE è¦ç´ çš„ä»¥ä¸‹æ±‡æ€»ç»Ÿè®¡é‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "For propensity modeling, there are two key periods: the observation period, over which descriptive features are calculated, and the outcome period, over which the target feature is calculated.3",
            "zh": "å¯¹äºå€¾å‘å»ºæ¨¡ï¼Œæœ‰ä¸¤ä¸ªå…³é”®æ—¶æœŸï¼šè§‚å¯ŸæœŸï¼ˆè®¡ç®—æè¿°æ€§ç‰¹å¾ï¼‰å’Œç»“æœæœŸï¼ˆè®¡ç®—ç›®æ ‡ç‰¹å¾ï¼‰3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also made the decision to normalize all the descriptive features into standard scores.The differences in the ranges of values of the set of descriptive features in the ABT was huge.",
            "zh": "Jocelyn è¿˜å†³å®šå°†æ‰€æœ‰æè¿°æ€§ç‰¹å¾è§„èŒƒåŒ–ä¸ºæ ‡å‡†åˆ†æ•°ã€‚ABTä¸­æè¿°æ€§ç‰¹å¾é›†çš„å€¼èŒƒå›´å·®å¼‚å¾ˆå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. A test statistic is computed.",
            "zh": "1. è®¡ç®—æ£€éªŒç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, these proofs fail if the neurons are restricted to using smooth functions.",
            "zh": "äº‹å®ä¸Šï¼Œå¦‚æœç¥ç»å…ƒè¢«é™åˆ¶ä¸ºä½¿ç”¨å¹³æ»‘å‡½æ•°ï¼Œè¿™äº›è¯æ˜å°±ä¼šå¤±è´¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn showed these charts to Edwin.",
            "zh": "ä¹”æ–¯æ—æŠŠè¿™äº›å›¾è¡¨æ‹¿ç»™åŸƒå¾·æ¸©çœ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The arithmetic mean for the full group is now 158.222cm and, as shown by the dashed gray line in Figure A.2(a)[746], no longer really represents the central tendency of the group.",
            "zh": "æ•´ä¸ªç»„çš„ç®—æœ¯å¹³å‡å€¼ç°åœ¨æ˜¯158.222å˜ç±³ï¼Œå¦‚å›¾A.2ï¼ˆaï¼‰[746]ä¸­çš„ç°è‰²è™šçº¿æ‰€ç¤ºï¼Œä¸å†çœŸæ­£ä»£è¡¨è¯¥ç»„çš„ä¸­å¿ƒè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "dynamic programming, 653, 677",
            "zh": "åŠ¨æ€è§„åˆ’ï¼Œ 653ï¼Œ 677"
        }
    },
    {
        "translation": {
            "en": "5.2â€…â€…â€…Fundamentals",
            "zh": "5.2 åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "So if we add a lot of new instances, we may find that the tree has become too unbalanced and that we will need to construct a new tree from scratch using the extended dataset to restore the efficiency of the retrieval process.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æ·»åŠ å¤§é‡æ–°å®ä¾‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå‘ç°æ ‘å˜å¾—å¤ªä¸å¹³è¡¡ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ‰©å±•æ•°æ®é›†ä»å¤´å¼€å§‹æ„å»ºæ–°æ ‘ï¼Œä»¥æ¢å¤æ£€ç´¢è¿‡ç¨‹çš„æ•ˆç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Comparing each term in ctâˆ’1 with the corresponding term in câ€¡ illustrates how the elementwise product of ft updates the cell state.",
            "zh": "å°† ctâˆ’1 ä¸­çš„æ¯ä¸ªé¡¹ä¸ câ€¡ ä¸­çš„ç›¸åº”é¡¹è¿›è¡Œæ¯”è¾ƒï¼Œè¯´æ˜äº† ft çš„é€å…ƒç´ ä¹˜ç§¯å¦‚ä½•æ›´æ–°ç»†èƒçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "To actually calculate the derivative, referred to as , of a simple continuous function, f(x), we use a small number of differentiation rules:",
            "zh": "ä¸ºäº†å®é™…è®¡ç®—ç®€å•è¿ç»­å‡½æ•° fï¼ˆxï¼‰ çš„å¯¼æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨å°‘é‡å¾®åˆ†è§„åˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "Crawford, Kate. 2017. The trouble with bias. Conference on Neural Information Processing Systems, invited speaker.",
            "zh": "å…‹åŠ³ç¦å¾·ï¼Œå‡¯ç‰¹ã€‚2017. åè§çš„éº»çƒ¦ã€‚ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿä¼šè®®ï¼Œç‰¹é‚€æ¼”è®²äººã€‚"
        }
    },
    {
        "translation": {
            "en": "The architecture of the auto-encoder used in this example is shown in Figure 10.14[625].",
            "zh": "æœ¬ä¾‹ä¸­ä½¿ç”¨çš„è‡ªåŠ¨ç¼–ç å™¨çš„æ¶æ„å¦‚å›¾10.14[625]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "2.5â€…â€…â€…Summary",
            "zh": "2.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Notice that the model sometimes overestimates the office rental price, and sometimes underestimates the office rental price.",
            "zh": "è¯·æ³¨æ„ï¼Œè¯¥æ¨¡å‹æœ‰æ—¶ä¼šé«˜ä¼°åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ï¼Œæœ‰æ—¶ä¼šä½ä¼°åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesâ€™ Theorem, 243, 245, 248, 731",
            "zh": "è´å¶æ–¯å®šç†ï¼Œ 243ï¼Œ 245ï¼Œ 248ï¼Œ 731"
        }
    },
    {
        "translation": {
            "en": "Each histogram includes only those instances in the dataset that have the associated level of the categorical feature.",
            "zh": "æ¯ä¸ªç›´æ–¹å›¾ä»…åŒ…æ‹¬æ•°æ®é›†ä¸­å…·æœ‰åˆ†ç±»è¦ç´ å…³è”çº§åˆ«çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Invalid outliers can arise for all sorts of different reasons.",
            "zh": "æ— æ•ˆçš„å¼‚å¸¸å€¼å¯èƒ½ç”±äºå„ç§ä¸åŒçš„åŸå› è€Œå‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vector of gradients âˆ‚â„°/âˆ‚hx includes error gradients for each element of htâˆ’1 and xt. This is because htâˆ’1 and xt were concatenated together in the forward pass. Hence the vector of gradients âˆ‚â„°t/âˆ‚htâˆ’1 is extracted from âˆ‚â„°/âˆ‚hx by splitting the vector at the index that joined htâˆ’1 and xt when they were concatenated.",
            "zh": "æ¢¯åº¦å‘é‡ âˆ‚E/âˆ‚hx åŒ…æ‹¬ htâˆ’1 å’Œ xt çš„æ¯ä¸ªå…ƒç´ çš„è¯¯å·®æ¢¯åº¦ã€‚è¿™æ˜¯å› ä¸º htâˆ’1 å’Œ xt åœ¨å‰å‘ä¼ é€’ä¸­è¿æ¥åœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œæ¢¯åº¦ âˆ‚Et/âˆ‚htâˆ’1 çš„å‘é‡æ˜¯ä» âˆ‚E/âˆ‚hx ä¸­æå–çš„ï¼Œæ–¹æ³•æ˜¯åœ¨è¿æ¥ htâˆ’1 å’Œ xt çš„ç´¢å¼•å¤„æ‹†åˆ†å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "From the rankings we can see that the nearest neighbor to the query is instance d6 (indicated by its rank of 1).",
            "zh": "ä»æ’åä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸æŸ¥è¯¢æœ€è¿‘çš„é‚»å±…æ˜¯å®ä¾‹ d6ï¼ˆç”±å…¶æ’å 1 è¡¨ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.10",
            "zh": "è¡¨ 5.10"
        }
    },
    {
        "translation": {
            "en": "(a) Based on these predictions, calculate the evaluation measures listed below for each model.",
            "zh": "ï¼ˆaï¼‰ æ ¹æ®è¿™äº›é¢„æµ‹ï¼Œè®¡ç®—ä¸‹åˆ—å„æ¨¡å‹çš„è¯„ä»·æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Just by visually inspecting Figure 5.3[188], we can see that the nearest neighbor to the query instance has a target level of yes, so this is the prediction that the model should return.",
            "zh": "åªéœ€ç›®è§†æ£€æŸ¥å›¾ 5.3[188]ï¼Œæˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°æŸ¥è¯¢å®ä¾‹çš„æœ€è¿‘é‚»åŸŸçš„ç›®æ ‡çº§åˆ«ä¸º yesï¼Œå› æ­¤è¿™æ˜¯æ¨¡å‹åº”è¿”å›çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This normalization is what makes cosine similarity so useful in scenarios in which we are interested in the relative spread of values across a set of descriptive features rather than the magnitudes of the values themselves.",
            "zh": "è¿™ç§å½’ä¸€åŒ–ä½¿ä½™å¼¦ç›¸ä¼¼æ€§åœ¨æˆ‘ä»¬æ„Ÿå…´è¶£çš„åœºæ™¯ä¸­å¦‚æ­¤æœ‰ç”¨ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯å€¼åœ¨ä¸€ç»„æè¿°æ€§ç‰¹å¾ä¸Šçš„ç›¸å¯¹åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å€¼æœ¬èº«çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1â€…â€…â€…Descriptive Statistics for Continuous Features",
            "zh": "A.1 è¿ç»­ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡"
        }
    },
    {
        "translation": {
            "en": "We can illustrate this using the simplified version of the RENTAL PRICE prediction problem based only on office size (SIZE).",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»…åŸºäºåŠå…¬å®¤å¤§å° ï¼ˆSIZEï¼‰ çš„ RENTAL PRICE é¢„æµ‹é—®é¢˜çš„ç®€åŒ–ç‰ˆæœ¬æ¥è¯´æ˜è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this simple example the decision tree is limited to a single root node with one split based on a value of TEMP (in this case the tree predicts Low rental demand for temperatures less than or equal to 8.5 degrees and High rental demand for all other temperatures).",
            "zh": "åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œå†³ç­–æ ‘ä»…é™äºå•ä¸ªæ ¹èŠ‚ç‚¹ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªåŸºäº TEMP å€¼çš„æ‹†åˆ†ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œè¯¥æ ‘é¢„æµ‹æ¸©åº¦å°äºæˆ–ç­‰äº 8.5 åº¦çš„ä½ç§Ÿèµéœ€æ±‚å’Œæ‰€æœ‰å…¶ä»–æ¸©åº¦çš„é«˜ç§Ÿèµéœ€æ±‚ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The outputs of the bottleneck layer in the network can be used as a new representation of the original input features.",
            "zh": "ç½‘ç»œä¸­ç“¶é¢ˆå±‚çš„è¾“å‡ºå¯ä»¥ç”¨ä½œåŸå§‹è¾“å…¥ç‰¹å¾çš„æ–°è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A popular metric used by these algorithms is the Bayesian information criterion (BIC):",
            "zh": "è¿™äº›ç®—æ³•ä½¿ç”¨çš„å¸¸ç”¨æŒ‡æ ‡æ˜¯è´å¶æ–¯ä¿¡æ¯å‡†åˆ™ ï¼ˆBICï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "3.6â€ƒData Preparation",
            "zh": "3.6 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "The first decision that must be made in choosing a machine learning platform is whether to use an application-based solution or to use a programming language.",
            "zh": "åœ¨é€‰æ‹©æœºå™¨å­¦ä¹ å¹³å°æ—¶ï¼Œå¿…é¡»åšå‡ºçš„ç¬¬ä¸€ä¸ªå†³å®šæ˜¯ä½¿ç”¨åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆè¿˜æ˜¯ä½¿ç”¨ç¼–ç¨‹è¯­è¨€ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is also commonly known as a conditional probability, because the probability calculated is valid conditional on the given events (or evidence).When we want to express this type of probability, formally we use a vertical bar, |, to separate the events we want the probability for (listed on the left-hand side of the bar) from the events that we know have already happened.",
            "zh": "å®ƒé€šå¸¸ä¹Ÿç§°ä¸ºæ¡ä»¶æ¦‚ç‡ï¼Œå› ä¸ºè®¡ç®—å‡ºçš„æ¦‚ç‡åœ¨ç»™å®šäº‹ä»¶ï¼ˆæˆ–è¯æ®ï¼‰çš„æ¡ä»¶ä¸‹æ˜¯æœ‰æ•ˆçš„ã€‚å½“æˆ‘ä»¬æƒ³è¦è¡¨è¾¾è¿™ç§ç±»å‹çš„æ¦‚ç‡æ—¶ï¼Œæˆ‘ä»¬æ­£å¼ä½¿ç”¨å‚ç›´æ¡|æ¥å°†æˆ‘ä»¬æƒ³è¦æ¦‚ç‡çš„äº‹ä»¶ï¼ˆåˆ—åœ¨æ¡çš„å·¦ä¾§ï¼‰ä¸æˆ‘ä»¬çŸ¥é“å·²ç»å‘ç”Ÿçš„äº‹ä»¶åˆ†å¼€ã€‚"
        }
    },
    {
        "translation": {
            "en": "2,200",
            "zh": "2,200"
        }
    },
    {
        "translation": {
            "en": "The car has sensors on the front, the rear, and the sides that indicate the presence of other cars or lane barriers in the area immediately surrounding the car.",
            "zh": "æ±½è½¦çš„å‰éƒ¨ã€åéƒ¨å’Œä¾§é¢éƒ½æœ‰ä¼ æ„Ÿå™¨ï¼Œå¯æŒ‡ç¤ºæ±½è½¦å‘¨å›´åŒºåŸŸæ˜¯å¦å­˜åœ¨å…¶ä»–æ±½è½¦æˆ–è½¦é“éšœç¢ç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.1175",
            "zh": "-0.1175"
        }
    },
    {
        "translation": {
            "en": "The same error gradient vector flows back along both paths that feed into the elementwise summation in the forward path.",
            "zh": "ç›¸åŒçš„è¯¯å·®æ¢¯åº¦å‘é‡æ²¿ç€ä¸¤æ¡è·¯å¾„å›æµï¼Œè¿™äº›è·¯å¾„é¦ˆé€åˆ°æ­£å‘è·¯å¾„ä¸­çš„å…ƒç´ æ±‚å’Œä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "It then splits the dataset that was considered at this node, , into partitions, 1,â€¦,k, according to the levels that d[best] can take, {l1,â€¦,lk} (Line 10).",
            "zh": "ç„¶åï¼Œæ ¹æ® d[best] å¯ä»¥é‡‡ç”¨çš„çº§åˆ«ï¼Œå°†åœ¨æ­¤èŠ‚ç‚¹ ä¸Šè€ƒè™‘çš„æ•°æ®é›†æ‹†åˆ†ä¸º 1,...,k åˆ†åŒº {l1,...,lk}ï¼ˆç¬¬ 10 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. The following image illustrates the topology of a simple feedforward neural network that has a single sensing neuron (Neuron 1), a single hidden processing neuron (Neuron 2), and a single processing output neuron (Neuron 3).",
            "zh": "4. ä¸‹å›¾è¯´æ˜äº†å…·æœ‰å•ä¸ªæ„ŸçŸ¥ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 1ï¼‰ã€å•ä¸ªéšè—å¤„ç†ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 2ï¼‰å’Œå•ä¸ªå¤„ç†è¾“å‡ºç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 3ï¼‰çš„ç®€å•å‰é¦ˆç¥ç»ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. The following table lists a dataset from the credit scoring domain that we discussed in the chapter. Underneath the table we list two prediction models consistent with this dataset, Model 1 and Model 2.",
            "zh": "4. ä¸‹è¡¨åˆ—å‡ºäº†æˆ‘ä»¬åœ¨æœ¬ç« ä¸­è®¨è®ºçš„ä¿¡ç”¨è¯„åˆ†åŸŸä¸­çš„æ•°æ®é›†ã€‚åœ¨è¡¨æ ¼ä¸‹æ–¹ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†ä¸æ­¤æ•°æ®é›†ä¸€è‡´çš„ä¸¤ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œå³æ¨¡å‹ 1 å’Œæ¨¡å‹ 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, we draw a simple bar plot showing the densities of the different levels of the first feature.",
            "zh": "é¦–å…ˆï¼Œæˆ‘ä»¬ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„æ¡å½¢å›¾ï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰¹å¾çš„ä¸åŒçº§åˆ«çš„å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, an answer to Question 2 splits the game domain into one set containing one element, Brian, and another set containing three elements: John, Aphra, and Aoife.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œé—®é¢˜ 2 çš„ç­”æ¡ˆå°†æ¸¸æˆåŸŸæ‹†åˆ†ä¸ºä¸€ä¸ªåŒ…å«ä¸€ä¸ªå…ƒç´  Brian çš„é›†åˆå’Œå¦ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªå…ƒç´ çš„é›†åˆï¼šJohnã€Aphra å’Œ Aoifeã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address this problem for the hospital group. For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original problem.",
            "zh": "ï¼ˆaï¼‰ æå‡ºä¸¤ç§æ–¹æ³•ï¼Œåˆ©ç”¨é¢„æµ‹æ€§æ•°æ®åˆ†ææ¥å¸®åŠ©åŒ»é™¢é›†å›¢è§£å†³è¿™ä¸€é—®é¢˜ã€‚å¯¹äºæ¯ä¸ªå»ºè®®çš„æ–¹æ³•ï¼Œæè¿°å°†è¦æ„å»ºçš„é¢„æµ‹æ¨¡å‹ã€ä¸šåŠ¡éƒ¨é—¨å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹ï¼Œä»¥åŠä½¿ç”¨è¯¥æ¨¡å‹å°†å¦‚ä½•å¸®åŠ©è§£å†³åŸå§‹é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11(a)[290] illustrates the network structure of a naive Bayes classifier and how it encodes the conditional independence between the descriptive features given assumed knowledge of the target.",
            "zh": "å›¾6.11ï¼ˆaï¼‰[290]è¯´æ˜äº†æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„ç½‘ç»œç»“æ„ï¼Œä»¥åŠå®ƒå¦‚ä½•å¯¹ç»™å®šç›®æ ‡çŸ¥è¯†çš„æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§è¿›è¡Œç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. the probability of an instance having a particular set of descriptive feature values given that it has a particular target level P(d | t)",
            "zh": "1. ç»™å®šå®ä¾‹å…·æœ‰ç‰¹å®šç›®æ ‡çº§åˆ« Pï¼ˆd | tï¼‰ çš„å®ä¾‹å…·æœ‰ä¸€ç»„ç‰¹å®šæè¿°æ€§ç‰¹å¾å€¼çš„æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "We do not want our model to bias toward a particular feature simply because the values of that feature happen to be large relative to the other features in the dataset.",
            "zh": "æˆ‘ä»¬ä¸å¸Œæœ›æˆ‘ä»¬çš„æ¨¡å‹ä»…ä»…å› ä¸ºè¯¥ç‰¹å¾çš„å€¼ç›¸å¯¹äºæ•°æ®é›†ä¸­çš„å…¶ä»–ç‰¹å¾è€Œè¨€æ°å¥½å¾ˆå¤§è€Œåå‘äºç‰¹å®šç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross spent a significant amount of time meeting with Kate, the leader of the customer retention team, in order to understand how they worked.",
            "zh": "Ross èŠ±äº†å¤§é‡æ—¶é—´ä¸å®¢æˆ·ä¿ç•™å›¢é˜Ÿçš„è´Ÿè´£äºº Kate ä¼šé¢ï¼Œä»¥äº†è§£ä»–ä»¬çš„å·¥ä½œæ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Drucker, Harris. 1997. Improving regressors using boosting techniques. In International conference on machine learning ICML, Vol. 97, 107â€“115.",
            "zh": "å¾·é²å…‹ï¼Œå“ˆé‡Œæ–¯ã€‚1997. ä½¿ç”¨æå‡æŠ€æœ¯æ”¹è¿›å›å½’å™¨.åœ¨æœºå™¨å­¦ä¹ å›½é™…ä¼šè®®ä¸Šï¼ŒICMLï¼Œç¬¬97å·ï¼Œ107-115ã€‚"
        }
    },
    {
        "translation": {
            "en": "The universal approximation theorem (Hornik et al., 1989; Cybenko, 1989) proved that neural networks with a single hidden layer of neurons using smooth functions (such as sigmoids or logistic functions) can approximate any bounded continuous function, provided there are sufficient neurons in the hidden layer of the network.",
            "zh": "æ™®éè¿‘ä¼¼å®šç†ï¼ˆHornik et al.ï¼Œ 1989;Cybenkoï¼Œ1989ï¼‰è¯æ˜ï¼Œå…·æœ‰å•ä¸ªéšè—ç¥ç»å…ƒå±‚çš„ç¥ç»ç½‘ç»œä½¿ç”¨å…‰æ»‘å‡½æ•°ï¼ˆä¾‹å¦‚sigmoidsæˆ–é€»è¾‘å‡½æ•°ï¼‰å¯ä»¥è¿‘ä¼¼ä»»ä½•æœ‰ç•Œè¿ç»­å‡½æ•°ï¼Œå‰ææ˜¯ç½‘ç»œçš„éšè—å±‚ä¸­æœ‰è¶³å¤Ÿçš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The distributions of the descriptive features in query instances presented to the model",
            "zh": "å‘ˆç°ç»™æ¨¡å‹çš„æŸ¥è¯¢å®ä¾‹ä¸­æè¿°æ€§ç‰¹å¾çš„åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network consists of a network of interconnected artificial neurons.",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œç”±ç›¸äº’è¿æ¥çš„äººå·¥ç¥ç»å…ƒç½‘ç»œç»„æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "multi-layer perceptron, 673",
            "zh": "å¤šå±‚æ„ŸçŸ¥å™¨ï¼Œ673"
        }
    },
    {
        "translation": {
            "en": "To select the best feature to use at the root of the tree, we need to calculate the information gain for each feature.",
            "zh": "ä¸ºäº†é€‰æ‹©åœ¨æ ‘çš„æ ¹éƒ¨ä½¿ç”¨çš„æœ€ä½³ç‰¹å¾ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "A simple dataset for MENINGITIS with three common symptoms of the disease listed as descriptive features: HEADACHE, FEVER, and VOMITING.",
            "zh": "è„‘è†œç‚çš„ç®€å•æ•°æ®é›†ï¼Œè¯¥ç–¾ç—…çš„ä¸‰ç§å¸¸è§ç—‡çŠ¶è¢«åˆ—ä¸ºæè¿°æ€§ç‰¹å¾ï¼šå¤´ç—›ã€å‘çƒ§å’Œå‘•åã€‚"
        }
    },
    {
        "translation": {
            "en": "random variable, 246, 652, 757, 758",
            "zh": "éšæœºå˜é‡ï¼Œ 246ï¼Œ 652ï¼Œ 757ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "Here, each pair of weights w[0] and w[1] defines a point on the x-y plane, and the sum of squared errors for the model using these weights determines the height of the error surface above the x-y plane for that pair of weights.",
            "zh": "åœ¨è¿™é‡Œï¼Œæ¯å¯¹æƒé‡ w[0] å’Œ w[1] å®šä¹‰ x-y å¹³é¢ä¸Šçš„ä¸€ä¸ªç‚¹ï¼Œä½¿ç”¨è¿™äº›æƒé‡çš„æ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œå†³å®šäº†è¯¥å¯¹æƒé‡åœ¨ x-y å¹³é¢ä¸Šæ–¹çš„è¯¯å·®æ›²é¢çš„é«˜åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, these diagnoses are based on their extensive training, expertise, and experience.",
            "zh": "é€šå¸¸ï¼Œè¿™äº›è¯Šæ–­åŸºäºä»–ä»¬å¹¿æ³›çš„åŸ¹è®­ã€ä¸“ä¸šçŸ¥è¯†å’Œç»éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "For a prediction problem with a binary target feature (where, by convention, we refer to the two levels as positive and negative), there are just four outcomes when the model makes a prediction:",
            "zh": "å¯¹äºå…·æœ‰äºŒå…ƒç›®æ ‡ç‰¹å¾çš„é¢„æµ‹é—®é¢˜ï¼ˆæŒ‰ç…§æƒ¯ä¾‹ï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªçº§åˆ«ç§°ä¸ºæ­£å€¼å’Œè´Ÿå€¼ï¼‰ï¼Œæ¨¡å‹è¿›è¡Œé¢„æµ‹æ—¶åªæœ‰å››ä¸ªç»“æœï¼š"
        }
    },
    {
        "translation": {
            "en": "The rationale is that if the network error is not sensitive to changes in a weight (i.e., the error does not change when the weight changes), then the error is independent of the weight, or to put it another way, the weight did not contribute to the error.",
            "zh": "å…¶åŸºæœ¬åŸç†æ˜¯ï¼Œå¦‚æœç½‘ç»œè¯¯å·®å¯¹æƒé‡çš„å˜åŒ–ä¸æ•æ„Ÿï¼ˆå³ï¼Œå½“æƒé‡å˜åŒ–æ—¶ï¼Œè¯¯å·®ä¸ä¼šæ”¹å˜ï¼‰ï¼Œåˆ™è¯¯å·®ä¸æƒé‡æ— å…³ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œæƒé‡å¯¹è¯¯å·®æ²¡æœ‰è´¡çŒ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, there is no special symbol used to denote a matrix product. Instead, we write the matrix product by writing the names of the two matrices side by side. For example, DE is the way we write the product for two matrices D and E, although sometimes a dot may be inserted between the two matrices (a Â· is frequently used to highlight that one or both of the matrices is a vector):",
            "zh": "é€šå¸¸ï¼Œæ²¡æœ‰ç”¨äºè¡¨ç¤ºçŸ©é˜µä¹˜ç§¯çš„ç‰¹æ®Šç¬¦å·ã€‚å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡å¹¶æ’å†™ä¸¤ä¸ªçŸ©é˜µçš„åç§°æ¥ç¼–å†™çŸ©é˜µäº§å“ã€‚ä¾‹å¦‚ï¼ŒDE æ˜¯æˆ‘ä»¬ä¸ºä¸¤ä¸ªçŸ©é˜µ D å’Œ E ç¼–å†™ä¹˜ç§¯çš„æ–¹å¼ï¼Œå°½ç®¡æœ‰æ—¶å¯èƒ½ä¼šåœ¨ä¸¤ä¸ªçŸ©é˜µä¹‹é—´æ’å…¥ä¸€ä¸ªç‚¹ï¼ˆa Â· ç»å¸¸ç”¨äºçªå‡ºæ˜¾ç¤ºä¸€ä¸ªæˆ–ä¸¤ä¸ªçŸ©é˜µæ˜¯å‘é‡ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "PRESSURE",
            "zh": "å‹åŠ›"
        }
    },
    {
        "translation": {
            "en": "The models that analytics practitioners build simply make predictions based on patterns extracted from historical datasets.",
            "zh": "åˆ†æä»ä¸šè€…æ„å»ºçš„æ¨¡å‹åªæ˜¯æ ¹æ®ä»å†å²æ•°æ®é›†ä¸­æå–çš„æ¨¡å¼è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first course listed (column â€œM.L.",
            "zh": "åˆ—å‡ºçš„ç¬¬ä¸€é—¨è¯¾ç¨‹ï¼ˆâ€œM.L."
        }
    },
    {
        "translation": {
            "en": "To illustrate how the Theorem of Total Probability can be used to calculate probabilities, we will compute P(h) by summing out M (note: earlier, in Equation (B.1)[760], we computed P(h) = 0.7):",
            "zh": "ä¸ºäº†è¯´æ˜å¦‚ä½•ä½¿ç”¨æ€»æ¦‚ç‡å®šç†æ¥è®¡ç®—æ¦‚ç‡ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ±‚å’ŒMæ¥è®¡ç®—Pï¼ˆhï¼‰ï¼ˆæ³¨æ„ï¼šåœ¨å‰é¢çš„æ–¹ç¨‹ï¼ˆB.1ï¼‰[760]ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—äº†Pï¼ˆhï¼‰= 0.7ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "Goldilocks model, 14",
            "zh": "é‡‘å‘å§‘å¨˜æ¨¡å‹ï¼Œ14"
        }
    },
    {
        "translation": {
            "en": "(d) 1st quartile (25th percentile) and 3rd quartile (75th percentile)",
            "zh": "ï¼ˆdï¼‰ ç¬¬1ä¸ªå››åˆ†ä½æ•°ï¼ˆç¬¬25ä¸ªç™¾åˆ†ä½æ•°ï¼‰å’Œç¬¬3ä¸ªå››åˆ†ä½æ•°ï¼ˆç¬¬75ä¸ªç™¾åˆ†ä½æ•°ï¼‰"
        }
    },
    {
        "translation": {
            "en": "There are many more scenarios, however, in which the correct target feature values either never become available or do not become available early enough to be useful for ongoing model validation.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨æ›´å¤šæƒ…å†µä¸‹ï¼Œæ­£ç¡®çš„ç›®æ ‡ç‰¹å¾å€¼è¦ä¹ˆæ°¸è¿œä¸ä¼šå¯ç”¨ï¼Œè¦ä¹ˆæ— æ³•è¶³å¤Ÿæ—©åœ°ç”¨äºæ­£åœ¨è¿›è¡Œçš„æ¨¡å‹éªŒè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Having a global minimum means that on an error surface, there is a unique set of optimal weights with the lowest sum of squared errors.",
            "zh": "å…·æœ‰å…¨å±€æœ€å°å€¼æ„å‘³ç€åœ¨è¯¯å·®æ›²é¢ä¸Šï¼Œå­˜åœ¨ä¸€ç»„å”¯ä¸€çš„æœ€ä½³æƒé‡ï¼Œå…¶å¹³æ–¹è¯¯å·®ä¹‹å’Œæœ€å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some cases we may not have data for all the features; and in these instances, the standard approach to learning the CPT entries is to use a gradient descent approach (similar to the one we introduce in Chapter 7[311]), where the objective function of the local search algorithm is simply how well the product of the induced conditional probabilities match the relative frequency of each joint event in the data.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½æ²¡æœ‰æ‰€æœ‰åŠŸèƒ½çš„æ•°æ®;åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå­¦ä¹  CPT æ¡ç›®çš„æ ‡å‡†æ–¹æ³•æ˜¯ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•ï¼ˆç±»ä¼¼äºæˆ‘ä»¬åœ¨ç¬¬ 7 ç« [311]ä¸­ä»‹ç»çš„æ–¹æ³•ï¼‰ï¼Œå…¶ä¸­å±€éƒ¨æœç´¢ç®—æ³•çš„ç›®æ ‡å‡½æ•°åªæ˜¯è¯±å¯¼æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ä¸æ•°æ®ä¸­æ¯ä¸ªè”åˆäº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡çš„åŒ¹é…ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often, however, we want to know the probability of an event in the context where one or more other events are known to have happened.",
            "zh": "ç„¶è€Œï¼Œé€šå¸¸ï¼Œæˆ‘ä»¬æƒ³çŸ¥é“åœ¨å·²çŸ¥ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–äº‹ä»¶å‘ç”Ÿçš„ä¸Šä¸‹æ–‡ä¸­äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "13. Recall that each non-leaf node in the tree indexes an instance in the dataset and also defines a hyperplane that partitions the feature space. For example, the horizontal and vertical lines in Figure 5.9(b)[199] plot the hyperplanes defined by the non-leaf nodes of the k-d tree shown in Figure 5.9(a)[199].",
            "zh": "13. å›æƒ³ä¸€ä¸‹ï¼Œæ ‘ä¸­çš„æ¯ä¸ªéå¶èŠ‚ç‚¹éƒ½ä¸ºæ•°æ®é›†ä¸­çš„ä¸€ä¸ªå®ä¾‹ç¼–åˆ¶ç´¢å¼•ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªç”¨äºåˆ’åˆ†ç‰¹å¾ç©ºé—´çš„è¶…å¹³é¢ã€‚ä¾‹å¦‚ï¼Œå›¾5.9ï¼ˆbï¼‰[199]ä¸­çš„æ°´å¹³çº¿å’Œå‚ç›´çº¿ç»˜åˆ¶äº†ç”±å›¾5.9ï¼ˆaï¼‰[199]æ‰€ç¤ºçš„k-dæ ‘çš„éå¶èŠ‚ç‚¹å®šä¹‰çš„è¶…å¹³é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning models can be built to help predict optimal dosages of drugs so as to achieve a medical practitionerâ€™s goals.26 In the following figure, the image on the left shows a scatter plot of a dataset used to train a model to distinguish between dosages of two drugs that cause a dangerous interaction and those that cause a safe interaction.",
            "zh": "26 åœ¨ä¸‹å›¾ä¸­ï¼Œå·¦å›¾æ˜¾ç¤ºäº†æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œè¯¥æ•°æ®é›†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä»¥åŒºåˆ†å¯¼è‡´å±é™©ç›¸äº’ä½œç”¨çš„ä¸¤ç§è¯ç‰©çš„å‰‚é‡å’Œå¼•èµ·å®‰å…¨ç›¸äº’ä½œç”¨çš„è¯ç‰©å‰‚é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once this hierarchical tree structure has been found, it can be cut to any level to give a clustering with that many clusters.",
            "zh": "ä¸€æ—¦æ‰¾åˆ°è¿™ä¸ªåˆ†å±‚æ ‘ç»“æ„ï¼Œå°±å¯ä»¥å°†å…¶åˆ‡å‰²åˆ°ä»»ä½•çº§åˆ«ï¼Œä»¥æä¾›å…·æœ‰è¯¥å¤šèšç±»çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.3â€…â€…â€…Standard Approach: The k-Means Clustering Algorithm",
            "zh": "10.3 æ ‡å‡†æ–¹æ³•ï¼šk-Means èšç±»ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "Figure C.1",
            "zh": "å›¾ C.1"
        }
    },
    {
        "translation": {
            "en": "As a result, when we define the activation function for a PReLU, we introduce a subscript on the terms to identify the neuron and the corresponding gradient being used.",
            "zh": "å› æ­¤ï¼Œå½“æˆ‘ä»¬å®šä¹‰ PReLU çš„æ¿€æ´»å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬åœ¨é¡¹ä¸Šå¼•å…¥äº†ä¸€ä¸ªä¸‹æ ‡æ¥è¯†åˆ«ç¥ç»å…ƒå’Œæ­£åœ¨ä½¿ç”¨çš„ç›¸åº”æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the activation ak may be propagated to many downstream neurons, and therefore to calculate the total sensitivity of the network error â„° to changes in ak, we must sum this product for all n neurons that ak is directly propagated to",
            "zh": "ç„¶è€Œï¼Œæ¿€æ´» ak å¯ä»¥ä¼ æ’­åˆ°è®¸å¤šä¸‹æ¸¸ç¥ç»å…ƒï¼Œå› æ­¤è¦è®¡ç®—ç½‘ç»œè¯¯å·® E å¯¹ ak å˜åŒ–çš„æ€»æ•æ„Ÿæ€§ï¼Œæˆ‘ä»¬å¿…é¡»å°† ak ç›´æ¥ä¼ æ’­åˆ°çš„æ‰€æœ‰ n ä¸ªç¥ç»å…ƒçš„ä¹˜ç§¯æ±‚å’Œ"
        }
    },
    {
        "translation": {
            "en": "The F1 measure can assume values in the range (0,1], and higher values indicate better performance.",
            "zh": "F1 åº¦é‡å€¼å¯ä»¥å‡å®šå€¼åœ¨ ï¼ˆ0,1ï¼‰ èŒƒå›´å†…ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºæ€§èƒ½è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.10",
            "zh": "å›¾ 9.10"
        }
    },
    {
        "translation": {
            "en": "5.4.3â€ƒData Normalization",
            "zh": "5.4.3 æ•°æ®è§„èŒƒåŒ–"
        }
    },
    {
        "translation": {
            "en": "Player Low (PL): 4 âˆ’ 14",
            "zh": "ä½çƒå‘˜ ï¼ˆPLï¼‰ï¼š 4 âˆ’ 14"
        }
    },
    {
        "translation": {
            "en": "To ensure that the resulting decision tree classifies in the correct proportions, the decision tree is constructed by repeatedly partitioning9 the training dataset until every instance in a partition maps to the same target level.",
            "zh": "ä¸ºç¡®ä¿ç”Ÿæˆçš„å†³ç­–æ ‘ä»¥æ­£ç¡®çš„æ¯”ä¾‹è¿›è¡Œåˆ†ç±»ï¼Œå†³ç­–æ ‘æ˜¯é€šè¿‡å¯¹è®­ç»ƒæ•°æ®é›†è¿›è¡Œé‡å¤åˆ†åŒº9æ¥æ„å»ºçš„ï¼Œç›´åˆ°åˆ†åŒºä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½æ˜ å°„åˆ°ç›¸åŒçš„ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.15",
            "zh": "è¡¨ 6.15"
        }
    },
    {
        "translation": {
            "en": "lift chart, 570",
            "zh": "å‡é™å›¾ï¼Œ570"
        }
    },
    {
        "translation": {
            "en": "There are two key use cases for unsupervised learning: clustering and representation learning.",
            "zh": "æ— ç›‘ç£å­¦ä¹ æœ‰ä¸¤ä¸ªå…³é”®ç”¨ä¾‹ï¼šèšç±»å’Œè¡¨ç¤ºå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "When this approach is used, we show a bar plot of the first feature above a bar plot that shows the relative distribution of the levels of the second feature within each level of the first.",
            "zh": "å½“ä½¿ç”¨è¿™ç§æ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬åœ¨æ¡å½¢å›¾ä¸Šæ–¹æ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰¹å¾çš„æ¡å½¢å›¾ï¼Œè¯¥æ¡å½¢å›¾æ˜¾ç¤ºäº†ç¬¬ä¸€ä¸ªç‰¹å¾çš„æ¯ä¸ªæ°´å¹³å†…ç¬¬äºŒä¸ªç‰¹å¾çš„ç›¸å¯¹åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal in temporal-difference learning is to find the true values for each entry in this table, and this is achieved by deploying the agent into the environment and updating the values in the table on the basis of the performance of the agent.",
            "zh": "æ—¶å·®å­¦ä¹ çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æ­¤è¡¨ä¸­æ¯ä¸ªæ¡ç›®çš„çœŸå®å€¼ï¼Œè¿™æ˜¯é€šè¿‡å°†ä»£ç†éƒ¨ç½²åˆ°ç¯å¢ƒä¸­å¹¶æ ¹æ®ä»£ç†çš„æ€§èƒ½æ›´æ–°è¡¨ä¸­çš„å€¼æ¥å®ç°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 5.18(b)[226] and 5.18(c)[226] illustrate what happens if we increase the number of descriptive features in a dataset but do not increase the number of instances.",
            "zh": "å›¾ 5.18ï¼ˆbï¼‰[226] å’Œ 5.18ï¼ˆcï¼‰[226] è¯´æ˜äº†å¦‚æœæˆ‘ä»¬å¢åŠ æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾çš„æ•°é‡ä½†ä¸å¢åŠ å®ä¾‹çš„æ•°é‡ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Select which probability distribution we believe will best model the distribution of the values of the feature. The simplest and most direct way to choose a distribution for a feature is to create a density histogram of the featureâ€™s values and compare the shape of this histogram to the shapes of the standard distributions. We should choose whichever standard distribution best matches the shape of the histogram to model the feature.",
            "zh": "1. é€‰æ‹©æˆ‘ä»¬è®¤ä¸ºæœ€èƒ½å¯¹ç‰¹å¾å€¼åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡çš„æ¦‚ç‡åˆ†å¸ƒã€‚ä¸ºè¦ç´ é€‰æ‹©åˆ†å¸ƒçš„æœ€ç®€å•ã€æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯åˆ›å»ºè¦ç´ å€¼çš„å¯†åº¦ç›´æ–¹å›¾ï¼Œå¹¶å°†è¯¥ç›´æ–¹å›¾çš„å½¢çŠ¶ä¸æ ‡å‡†åˆ†å¸ƒçš„å½¢çŠ¶è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬åº”è¯¥é€‰æ‹©ä¸ç›´æ–¹å›¾å½¢çŠ¶æœ€åŒ¹é…çš„æ ‡å‡†åˆ†å¸ƒæ¥å¯¹ç‰¹å¾è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Han, Jiawei, Jian Pei, and Micheline Kamber. 2011. Data mining: concepts and techniques. Elsevier.",
            "zh": "Hanã€Jiaweiã€Jian Pei å’Œ Micheline Kamberã€‚2011. æ•°æ®æŒ–æ˜ï¼šæ¦‚å¿µå’ŒæŠ€æœ¯.çˆ±æ€å”¯å°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.5â€…â€…â€…Other Measures of Similarity",
            "zh": "5.4.5 å…¶ä»–ç›¸ä¼¼åº¦è¡¡é‡æ ‡å‡†"
        }
    },
    {
        "translation": {
            "en": "Inductive bias is not the only type of bias that affects machine learning. An in-depth review of the range of biases that affect machine learning and the social harms that they can cause are beyond the scope of this book.7 However, we highlight sampling bias8 as a particular form of bias that a data analyst should be aware of and should proactively guard against in any data analytics project.",
            "zh": "å½’çº³åå·®å¹¶ä¸æ˜¯å½±å“æœºå™¨å­¦ä¹ çš„å”¯ä¸€åå·®ç±»å‹ã€‚å¯¹å½±å“æœºå™¨å­¦ä¹ çš„åè§èŒƒå›´åŠå…¶å¯èƒ½é€ æˆçš„ç¤¾ä¼šå±å®³çš„æ·±å…¥å®¡æŸ¥è¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒå›´.7 ç„¶è€Œï¼Œæˆ‘ä»¬å¼ºè°ƒæŠ½æ ·åè§8æ˜¯ä¸€ç§ç‰¹æ®Šå½¢å¼çš„åè§ï¼Œæ•°æ®åˆ†æå¸ˆåº”è¯¥æ„è¯†åˆ°ï¼Œå¹¶ä¸”åº”è¯¥åœ¨ä»»ä½•æ•°æ®åˆ†æé¡¹ç›®ä¸­ä¸»åŠ¨é˜²èŒƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.8",
            "zh": "è¡¨ 6.8"
        }
    },
    {
        "translation": {
            "en": "(b) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset showing a candidate prediction model (with w[0] = 6.47 and w[1] = 0.62) and the resulting errors.",
            "zh": "ï¼ˆbï¼‰ æ¥è‡ªåŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„ SIZE å’Œ RENTAL PRICE ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼Œæ˜¾ç¤ºäº†å€™é€‰é¢„æµ‹æ¨¡å‹ï¼ˆw[0] = 6.47 å’Œ w[1] = 0.62ï¼‰å’Œç”±æ­¤äº§ç”Ÿçš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gal, Yarin, and Zoubin Ghahramani. 2016. A theoretically grounded application of dropout in recurrent neural networks. In Advances in neural information processing systems 29: Annual conference on neural information processing systems 2016, December 5â€“10, 2016, Barcelona, Spain, 1019â€“1027.",
            "zh": "Galã€Yarin å’Œ Zoubin Ghahramaniã€‚2016. è¾å­¦åœ¨é€’å½’ç¥ç»ç½‘ç»œä¸­çš„ç†è®ºåº”ç”¨.ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±• 29ï¼š2016 å¹´ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¹´ä¼šï¼Œ2016 å¹´ 12 æœˆ 5 æ—¥è‡³ 10 æ—¥ï¼Œè¥¿ç­ç‰™å·´å¡ç½—é‚£ï¼Œ1019â€“1027ã€‚"
        }
    },
    {
        "translation": {
            "en": "TOTALINCOME: The taxpayerâ€™s total income for the current tax year.",
            "zh": "æ€»æ”¶å…¥ï¼šçº³ç¨äººåœ¨å½“å‰çº³ç¨å¹´åº¦çš„æ€»æ”¶å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the correlation between the LIFEEXPECTANCY and INFANTMORTALITY features.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—é¢„æœŸå¯¿å‘½å’Œå©´å„¿æ­»äº¡ç‡ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 11.3",
            "zh": "è¡¨ 11.3"
        }
    },
    {
        "translation": {
            "en": "Maintaining the dimensionality between input and output becomes important in convolutional neural networks when we use multiple layers of neurons, the output for one layer being interpreted as the image input to the next layer.",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨å¤šå±‚ç¥ç»å…ƒæ—¶ï¼Œä¿æŒè¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„ç»´åº¦åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­å˜å¾—å¾ˆé‡è¦ï¼Œä¸€å±‚çš„è¾“å‡ºè¢«è§£é‡Šä¸ºä¸‹ä¸€å±‚çš„å›¾åƒè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "A feature will be tested only once on any path in the tree, but it may occur several times in the tree on different paths.",
            "zh": "ä¸€ä¸ªè¦ç´ åªä¼šåœ¨æ ‘ä¸­çš„ä»»ä½•è·¯å¾„ä¸Šæµ‹è¯•ä¸€æ¬¡ï¼Œä½†å®ƒå¯èƒ½ä¼šåœ¨æ ‘ä¸­çš„ä¸åŒè·¯å¾„ä¸Šå‡ºç°å‡ æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Armed with the unsuccessful outcome of their first attempt, surfers usually overcompensate on the second attempt, resulting in the opposite problem.",
            "zh": "ç”±äºç¬¬ä¸€æ¬¡å°è¯•çš„ç»“æœä¸æˆåŠŸï¼Œå†²æµªè€…é€šå¸¸ä¼šåœ¨ç¬¬äºŒæ¬¡å°è¯•æ—¶è¿‡åº¦è¡¥å¿ï¼Œä»è€Œå¯¼è‡´ç›¸åçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The maximum entropy for a set with two types of elements is 1.00 bit, which occurs when there are equal numbers of each type in the set.",
            "zh": "å…·æœ‰ä¸¤ç§ç±»å‹å…ƒç´ çš„é›†åˆçš„æœ€å¤§ç†µä¸º 1.00 ä½ï¼Œå½“é›†åˆä¸­æ¯ç§ç±»å‹çš„å…ƒç´ æ•°é‡ç›¸ç­‰æ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "margin, 361",
            "zh": "ä¿è¯é‡‘ï¼Œ361"
        }
    },
    {
        "translation": {
            "en": "Surprisingly, given the naivete and strength of the assumption it depends upon, naive Bayes models often perform well.",
            "zh": "ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè€ƒè™‘åˆ°å®ƒæ‰€ä¾èµ–çš„å‡è®¾çš„å¹¼ç¨šæ€§å’Œå¼ºåº¦ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹é€šå¸¸è¡¨ç°è‰¯å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.6â€ƒSequential Models: Recurrent Neural Networks and Long Short-Term Memory Networks",
            "zh": "8.4.6 é¡ºåºæ¨¡å‹ï¼šé€’å½’ç¥ç»ç½‘ç»œå’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9(c)[79] shows small multiple histograms for values of AGE broken down by the different levels of the POSITION feature.",
            "zh": "å›¾3.9ï¼ˆcï¼‰[79]æ˜¾ç¤ºäº†æŒ‰ä½ç½®ç‰¹å¾çš„ä¸åŒçº§åˆ«ç»†åˆ†çš„AGEå€¼çš„å°å€æ•°ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, there are more weight parameters on the model than there are dimensions in the input space.",
            "zh": "æ¢è¨€ä¹‹ï¼Œæ¨¡å‹ä¸Šçš„æƒé‡å‚æ•°å¤šäºè¾“å…¥ç©ºé—´ä¸­çš„ç»´åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a given prediction task, all that is required to train a naive Bayes model is to calculate the priors for each target level and the conditional probability for each feature given each target level.",
            "zh": "å¯¹äºç»™å®šçš„é¢„æµ‹ä»»åŠ¡ï¼Œè®­ç»ƒæœ´ç´ è´å¶æ–¯æ¨¡å‹æ‰€éœ€çš„åªæ˜¯è®¡ç®—æ¯ä¸ªç›®æ ‡æ°´å¹³çš„å…ˆéªŒå’Œç»™å®šæ¯ä¸ªç›®æ ‡æ°´å¹³çš„æ¯ä¸ªç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "generalization, 11, 14, 536",
            "zh": "æ¦‚æ‹¬ï¼Œ 11ï¼Œ 14ï¼Œ 536"
        }
    },
    {
        "translation": {
            "en": "A greedy policy exploits current knowledge of the rewards that actions are expected to return.",
            "zh": "è´ªå©ªçš„æ”¿ç­–åˆ©ç”¨äº†å½“å‰å¯¹è¡ŒåŠ¨é¢„æœŸå›æŠ¥çš„å›æŠ¥çš„äº†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remember that the neurons in this network all use a linear activation function that has a derivative value of 1.",
            "zh": "è¯·è®°ä½ï¼Œè¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒéƒ½ä½¿ç”¨å¯¼æ•°å€¼ä¸º 1 çš„çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The net effect of this is that the distribution of real data tends to have a lower effective dimensionality than the dimensionality of the feature space.",
            "zh": "è¿™æ ·åšçš„æœ€ç»ˆç»“æœæ˜¯ï¼Œå®é™…æ•°æ®çš„åˆ†å¸ƒå¾€å¾€å…·æœ‰ä½äºç‰¹å¾ç©ºé—´ç»´æ•°çš„æœ‰æ•ˆç»´æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is, however, a simple way to find the optimal threshold, which avoids testing an infinite number of possible thresholds.",
            "zh": "ä½†æ˜¯ï¼Œæœ‰ä¸€ç§ç®€å•çš„æ–¹æ³•å¯ä»¥æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ï¼Œä»è€Œé¿å…æµ‹è¯•æ— é™æ•°é‡çš„å¯èƒ½é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the practical details of building a data quality report, Svolba (2012, 2007) are very good, even if the SAS language is not being used. Similarly, Dalgaard (2008) is very good even if the R language is not being used. As an example of a detailed investigation into the impact of applying data preparation techniques, Batista and Monard (2003) is interesting.",
            "zh": "å¯¹äºæ„å»ºæ•°æ®è´¨é‡æŠ¥å‘Šçš„å®é™…ç»†èŠ‚ï¼ŒSvolbaï¼ˆ2012,2007ï¼‰éå¸¸å¥½ï¼Œå³ä½¿æ²¡æœ‰ä½¿ç”¨SASè¯­è¨€ã€‚åŒæ ·ï¼ŒDalgaard ï¼ˆ2008ï¼‰å³ä½¿æ²¡æœ‰ä½¿ç”¨Rè¯­è¨€ä¹Ÿéå¸¸å¥½ã€‚ä½œä¸ºå¯¹åº”ç”¨æ•°æ®å‡†å¤‡æŠ€æœ¯çš„å½±å“è¿›è¡Œè¯¦ç»†è°ƒæŸ¥çš„ä¸€ä¸ªä¾‹å­ï¼ŒBatista å’Œ Monard ï¼ˆ2003ï¼‰ å¾ˆæœ‰è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, a number of methods designed to more carefully select the initial centroids.",
            "zh": "ç„¶è€Œï¼Œæœ‰è®¸å¤šæ–¹æ³•å¯ä»¥æ›´ä»”ç»†åœ°é€‰æ‹©åˆå§‹è´¨å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if a new customer starts shopping at the supermarket and buys baby food, alcohol, and organic vegetables, our set of consistent models will contradict each other with respect to the prediction that should be returned for this customer; for example, 2 will return GRP = single, 4 will return GRP = family, and 5 will return GRP = couple.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªæ–°å®¢æˆ·å¼€å§‹åœ¨è¶…å¸‚è´­ç‰©å¹¶è´­ä¹°å©´å„¿é£Ÿå“ã€é…’ç²¾å’Œæœ‰æœºè”¬èœï¼Œæˆ‘ä»¬çš„ä¸€ç»„ä¸€è‡´æ¨¡å‹å°†åœ¨åº”è¯¥ä¸ºè¯¥å®¢æˆ·è¿”å›çš„é¢„æµ‹æ–¹é¢ç›¸äº’çŸ›ç›¾;ä¾‹å¦‚ï¼Œ2 å°†è¿”å› GRP = å•ï¼Œ4 å°†è¿”å› GRP = å®¶åº­ï¼Œ5 å°†è¿”å› GRP = coupleã€‚"
        }
    },
    {
        "translation": {
            "en": "binary logarithm, 124",
            "zh": "äºŒè¿›åˆ¶å¯¹æ•°ï¼Œ124"
        }
    },
    {
        "translation": {
            "en": "Correlation values fall into the range [âˆ’1, 1], where values close to âˆ’ 1 indicate a very strong negative correlation (or covariance), values close to 1 indicate a very strong positive correlation, and values around 0 indicate no correlation.",
            "zh": "ç›¸å…³å€¼è½åœ¨ [âˆ’1ï¼Œ 1] èŒƒå›´å†…ï¼Œå…¶ä¸­æ¥è¿‘ âˆ’ 1 çš„å€¼è¡¨ç¤ºéå¸¸å¼ºçš„è´Ÿç›¸å…³ï¼ˆæˆ–åæ–¹å·®ï¼‰ï¼Œæ¥è¿‘ 1 çš„å€¼è¡¨ç¤ºéå¸¸å¼ºçš„æ­£ç›¸å…³ï¼Œè€Œ 0 é™„è¿‘çš„å€¼è¡¨ç¤ºæ²¡æœ‰ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes this means that data collected by an organization cannot be included in an ABT because this would be incompatible with the original use for which the data was collected.",
            "zh": "æœ‰æ—¶ï¼Œè¿™æ„å‘³ç€ç»„ç»‡æ”¶é›†çš„æ•°æ®ä¸èƒ½åŒ…å«åœ¨ ABT ä¸­ï¼Œå› ä¸ºè¿™ä¸æ”¶é›†æ•°æ®çš„åŸå§‹ç”¨é€”ä¸å…¼å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculate the Î´ values for each of the processing neurons in the network (i.e., Î´5, Î´4, Î´3, Î´2).",
            "zh": "è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªå¤„ç†ç¥ç»å…ƒçš„Î´å€¼ï¼ˆå³ Î´5ã€Î´4ã€Î´3ã€Î´2ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, a nice feature of the Gini index is that Gini index scores are always between 0 and 1, and in some contexts this may make it easier to compare Gini indexes across features.",
            "zh": "äº‹å®ä¸Šï¼ŒåŸºå°¼æŒ‡æ•°çš„ä¸€ä¸ªå¾ˆå¥½çš„ç‰¹ç‚¹æ˜¯åŸºå°¼æŒ‡æ•°å¾—åˆ†æ€»æ˜¯åœ¨0åˆ°1ä¹‹é—´ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™å¯èƒ½æ›´å®¹æ˜“æ¯”è¾ƒä¸åŒç‰¹å¾çš„åŸºå°¼æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A full dataset can be passed through the encoder network, and the outputs of the bottleneck layer can be saved as new generated features.",
            "zh": "å®Œæ•´çš„æ•°æ®é›†å¯ä»¥é€šè¿‡ç¼–ç å™¨ç½‘ç»œä¼ é€’ï¼Œç“¶é¢ˆå±‚çš„è¾“å‡ºå¯ä»¥ä¿å­˜ä¸ºæ–°ç”Ÿæˆçš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two questions to consider:",
            "zh": "æœ‰ä¸¤ä¸ªé—®é¢˜éœ€è¦è€ƒè™‘ï¼š"
        }
    },
    {
        "translation": {
            "en": "This is a binary feature that flags whether the value was present or missing in the original feature.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ï¼Œç”¨äºæ ‡è®°åŸå§‹ç‰¹å¾ä¸­æ˜¯å¦å­˜åœ¨è¯¥å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm returns the instance stored in the best variable as the nearest neighbor.",
            "zh": "è¯¥ç®—æ³•å°†å­˜å‚¨åœ¨æœ€ä½³å˜é‡ä¸­çš„å®ä¾‹ä½œä¸ºæœ€è¿‘é‚»è¿”å›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Berry and Linoff (2004) provide a good specialized treatment of clustering algorithms for customer segmentation applications. Han et al. (2011) is also very good on describing unsupervised machine learning techniques with customer applications in mind.",
            "zh": "Berry å’Œ Linoff ï¼ˆ2004ï¼‰ ä¸ºå®¢æˆ·ç»†åˆ†åº”ç”¨ç¨‹åºæä¾›äº†å¾ˆå¥½çš„èšç±»ç®—æ³•ä¸“ä¸šåŒ–å¤„ç†ã€‚Han et al. ï¼ˆ2011ï¼‰ ä¹Ÿéå¸¸æ“…é•¿æè¿°æ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¹¶è€ƒè™‘åˆ°å®¢æˆ·åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, we collapse this information into a single representation, referred to as a state.",
            "zh": "å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œæˆ‘ä»¬å°†è¿™äº›ä¿¡æ¯æŠ˜å æˆä¸€ä¸ªå•ä¸€çš„è¡¨ç¤ºå½¢å¼ï¼Œç§°ä¸ºçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the start of the second epoch, the sequence of mini-batches is shuffled and the training iterations are carried out on this new sequence of mini-batches.",
            "zh": "åœ¨ç¬¬äºŒä¸ªçºªå…ƒå¼€å§‹æ—¶ï¼Œå¯¹å°æ‰¹é‡çš„åºåˆ—è¿›è¡Œæ´—ç‰Œï¼Œå¹¶å¯¹è¿™ä¸ªæ–°çš„å°æ‰¹é‡åºåˆ—è¿›è¡Œè®­ç»ƒè¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "When presented in class, the material in Chapters 1, 2, 12, 13, and 14 typically takes two to three lecture hours per chapter to cover; and the material in Chapters 3, 4, 5, 6, 7, 8, 9, 10, and 11 normally takes four to six lecture hours per chapter to cover.",
            "zh": "åœ¨è¯¾å ‚ä¸Šå±•ç¤ºæ—¶ï¼Œç¬¬ 1ã€2ã€12ã€13 å’Œ 14 ç« ä¸­çš„ææ–™é€šå¸¸æ¯ç« éœ€è¦ä¸¤åˆ°ä¸‰ä¸ªè¯¾æ—¶æ‰èƒ½æ¶µç›–;ç¬¬ 3ã€4ã€5ã€6ã€7ã€8ã€9ã€10 å’Œ 11 ç« ä¸­çš„ææ–™é€šå¸¸æ¯ç« éœ€è¦å››åˆ°å…­ä¸ªè¯¾æ—¶æ‰èƒ½æ¶µç›–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each column in this matrix contains the descriptive features for one of the examples in Table 8.3[423].",
            "zh": "æ­¤çŸ©é˜µä¸­çš„æ¯ä¸€åˆ—éƒ½åŒ…å«è¡¨ 8.3[423] ä¸­å…¶ä¸­ä¸€ä¸ªç¤ºä¾‹çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gauss-Jordan elimination, 220",
            "zh": "é«˜æ–¯-ä¹”ä¸¹æ·˜æ±°èµ›ï¼Œ220"
        }
    },
    {
        "translation": {
            "en": "Finally, nearest neighbor models are the basis of case-based reasoning (CBR), which is an umbrella term for applications based on similarity-based machine learning.",
            "zh": "æœ€åï¼Œæœ€è¿‘é‚»æ¨¡å‹æ˜¯åŸºäºæ¡ˆä¾‹çš„æ¨ç† ï¼ˆCBRï¼‰ çš„åŸºç¡€ï¼ŒCBR æ˜¯åŸºäºç›¸ä¼¼æ€§çš„æœºå™¨å­¦ä¹ çš„åº”ç”¨ç¨‹åºçš„æ€»ç§°ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, we recommend that if a model has been flagged as having gone stale using either performance measure monitoring or output distribution monitoring, then the distributions of the descriptive features at the time that the model was built and the distributions of the features at the time that the model went stale should be compared in an effort to understand what has changed.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®ï¼Œå¦‚æœä½¿ç”¨æ€§èƒ½åº¦é‡ç›‘è§†æˆ–è¾“å‡ºåˆ†å¸ƒç›‘è§†å°†æ¨¡å‹æ ‡è®°ä¸ºå·²è¿‡æ—¶ï¼Œåˆ™åº”æ¯”è¾ƒæ¨¡å‹æ„å»ºæ—¶æè¿°æ€§ç‰¹å¾çš„åˆ†å¸ƒå’Œæ¨¡å‹è¿‡æ—¶æ—¶ç‰¹å¾çš„åˆ†å¸ƒï¼Œä»¥äº†è§£å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the size of a no region in the top right of the feature space is smaller than the corresponding region for the nearest neighbor model with k = 1 (see Figure 5.4(b)[190]).",
            "zh": "ä¾‹å¦‚ï¼Œç‰¹å¾ç©ºé—´å³ä¸Šè§’çš„æ— åŒºåŸŸçš„å¤§å°å°äº k = 1 çš„æœ€è¿‘é‚»æ¨¡å‹çš„ç›¸åº”åŒºåŸŸï¼ˆå‚è§å›¾ 5.4ï¼ˆbï¼‰[190]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The effect of using a Mahalanobis versus Euclidean distance. A marks the central tendency of the dataset in Figure 5.15(c)[219]. The ellipses plot the Mahalanobis distance contours from A that B and C lie on. In Euclidean terms, B and C are equidistant from A; however, using the Mahalanobis distance, C is much closer to A than B.",
            "zh": "ä½¿ç”¨é©¬æ°è·ç¦»ä¸æ¬§å‡ é‡Œå¾—è·ç¦»çš„æ•ˆæœã€‚Aåœ¨å›¾5.15ï¼ˆcï¼‰ä¸­æ ‡è®°äº†æ•°æ®é›†çš„ä¸­å¿ƒè¶‹åŠ¿[219]ã€‚æ¤­åœ†ç»˜åˆ¶äº† B å’Œ C æ‰€åœ¨çš„ A çš„é©¬æ°è·ç¦»ç­‰å€¼çº¿ã€‚åœ¨æ¬§å‡ é‡Œå¾—æœ¯è¯­ä¸­ï¼ŒB å’Œ C ä¸ A ç­‰è·;ç„¶è€Œï¼Œä½¿ç”¨é©¬æ°è·ç¦»ï¼ŒC æ¯” B æ›´æ¥è¿‘ Aã€‚"
        }
    },
    {
        "translation": {
            "en": "We previously mentioned that the ID3 algorithm constructs the decision tree by recursively partitioning the dataset.",
            "zh": "æˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡ï¼ŒID3 ç®—æ³•é€šè¿‡é€’å½’åˆ†åŒºæ•°æ®é›†æ¥æ„å»ºå†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to calculate this test statistic, we first have to calculate the standard error for the overall model and the standard error for the descriptive feature we are investigating the importance of.",
            "zh": "ä¸ºäº†è®¡ç®—è¿™ä¸ªæ£€éªŒç»Ÿè®¡é‡ï¼Œæˆ‘ä»¬é¦–å…ˆå¿…é¡»è®¡ç®—æ•´ä¸ªæ¨¡å‹çš„æ ‡å‡†è¯¯å·®å’Œæˆ‘ä»¬æ­£åœ¨ç ”ç©¶çš„æè¿°æ€§ç‰¹å¾çš„æ ‡å‡†è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ashmore, Malcolm. 1993. The theatre of the blind: Starring a promethean prankster, a phoney phenomenon, a prism, a pocket, and a piece of wood. Social Studies of Science 23 (1): 67â€“106.",
            "zh": "é˜¿ä»€è«å°”ï¼Œé©¬å°”ç§‘å§†ã€‚1993. ç›²äººå‰§é™¢ï¼šä¸»æ¼”ä¸€ä¸ªæ™®ç½—ç±³ä¿®æ–¯å¼çš„æ¶ä½œå‰§è€…ã€ä¸€ä¸ªè™šå‡ç°è±¡ã€ä¸€ä¸ªæ£±é•œã€ä¸€ä¸ªå£è¢‹å’Œä¸€å—æœ¨å¤´ã€‚ç§‘å­¦ç¤¾ä¼šç ”ç©¶23ï¼ˆ1ï¼‰ï¼š67-106ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address this business problem.10 For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original business problem.",
            "zh": "10 å¯¹äºæ¯ä¸€ç§æè®®çš„æ–¹æ³•ï¼Œè¯·æè¿°å°†è¦å»ºç«‹çš„é¢„æµ‹æ¨¡å‹ã€ä¸šåŠ¡éƒ¨é—¨å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹ä»¥åŠä½¿ç”¨è¯¥æ¨¡å‹å°†å¦‚ä½•å¸®åŠ©è§£å†³åŸå§‹ä¸šåŠ¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is also important to remember that the purpose of an analytics project is to solve a real-world problem and to keep focus on this rather than being distracted by the, admittedly sometimes fascinating, technical challenges of model building.",
            "zh": "åŒæ ·é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œåˆ†æé¡¹ç›®çš„ç›®çš„æ˜¯è§£å†³ç°å®ä¸–ç•Œçš„é—®é¢˜ï¼Œå¹¶ä¸“æ³¨äºæ­¤ï¼Œè€Œä¸æ˜¯è¢«æ¨¡å‹æ„å»ºçš„ä¸å¯å¦è®¤çš„æœ‰æ—¶ä»¤äººç€è¿·çš„æŠ€æœ¯æŒ‘æˆ˜åˆ†æ•£æ³¨æ„åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table shows a small dataset in which each instance describes measurements taken using three sensors when a valve in an oil well was opened.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸€ä¸ªå°å‹æ•°æ®é›†ï¼Œå…¶ä¸­æ¯ä¸ªå®ä¾‹éƒ½æè¿°äº†å½“æ²¹äº•ä¸­çš„é˜€é—¨æ‰“å¼€æ—¶ä½¿ç”¨ä¸‰ä¸ªä¼ æ„Ÿå™¨è¿›è¡Œçš„æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "bins, 89",
            "zh": "åƒåœ¾ç®±ï¼Œ89"
        }
    },
    {
        "translation": {
            "en": "Building predictive data analytics solutions for the kinds of applications described in Section 1.1[3] involves a lot more than just choosing the right machine learning algorithm.",
            "zh": "ä¸ºç¬¬1.1èŠ‚[3]ä¸­æè¿°çš„å„ç±»åº”ç”¨æ„å»ºé¢„æµ‹æ€§æ•°æ®åˆ†æè§£å†³æ–¹æ¡ˆæ¶‰åŠçš„ä¸ä»…ä»…æ˜¯é€‰æ‹©æ­£ç¡®çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distributions of the levels of SHOE SPONSOR are almost the same for each level of CAREER STAGE, and therefore we can conclude that there is no relationship between these two features.",
            "zh": "SHOE SPONSORçš„ç­‰çº§åˆ†å¸ƒåœ¨CAREER STAGEçš„æ¯ä¸ªçº§åˆ«å‡ ä¹ç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œè¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´æ²¡æœ‰å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In gradient boosting later models are trained to directly correct errors made by earlier models, rather than the more subtle approach of simply changing weights in a sampling distribution to encourage this.",
            "zh": "åœ¨æ¢¯åº¦æå‡ä¸­ï¼Œåæ¥çš„æ¨¡å‹è¢«è®­ç»ƒä¸ºç›´æ¥çº æ­£æ—©æœŸæ¨¡å‹æ‰€çŠ¯çš„é”™è¯¯ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æ”¹å˜é‡‡æ ·åˆ†å¸ƒä¸­çš„æƒé‡æ¥é¼“åŠ±è¿™ä¸€ç‚¹çš„æ›´å¾®å¦™çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The height and slope of the curve is dependent on the parameter Ïƒ (pronounced sigma), which denotes the population standard deviation.",
            "zh": "æ›²çº¿çš„é«˜åº¦å’Œæ–œç‡å–å†³äºå‚æ•° Ïƒï¼ˆå‘éŸ³ä¸º sigmaï¼‰ï¼Œå®ƒè¡¨ç¤ºæ€»ä½“æ ‡å‡†å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4â€…â€…â€…(a) The Voronoi tessellation of the feature space for the dataset in Table 5.2[183], with the position of the query represented by the? marker; and (b) the decision boundary created by aggregating the neighboring Voronoi regions that belong to the same target level.",
            "zh": "5.4 ï¼ˆaï¼‰ è¡¨ 5.2[183] ä¸­æ•°æ®é›†ç‰¹å¾ç©ºé—´çš„ Voronoi æ›²é¢ç»†åˆ†ï¼ŒæŸ¥è¯¢çš„ä½ç½®ç”¨ ï¼Ÿæ ‡è®°;ï¼ˆbï¼‰é€šè¿‡æ±‡æ€»å±äºåŒä¸€ç›®æ ‡çº§åˆ«çš„é‚»è¿‘Voronoiåœ°åŒºè€Œåˆ›å»ºçš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The matrix representation of a neural network is also useful in terms of understanding why we need to include a non-linear function as part of the information processing within each of the neurons in a network (see Section 8.2.4[394]) and why the depth of a network (i.e., the number of layers) is important (see Section 8.2.5[395]).",
            "zh": "ç¥ç»ç½‘ç»œçš„çŸ©é˜µè¡¨ç¤ºä¹Ÿæœ‰åŠ©äºç†è§£ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å°†éçº¿æ€§å‡½æ•°ä½œä¸ºç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒå†…ä¿¡æ¯å¤„ç†çš„ä¸€éƒ¨åˆ†ï¼ˆå‚è§ç¬¬ 8.2.4 èŠ‚[394]ï¼‰ï¼Œä»¥åŠä¸ºä»€ä¹ˆç½‘ç»œçš„æ·±åº¦ï¼ˆå³å±‚æ•°ï¼‰å¾ˆé‡è¦ï¼ˆå‚è§ç¬¬ 8.2.5 èŠ‚[395]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information gained by splitting ğ’Ÿ7 for using STREAM and SLOPE is then computed as presented in Table 4.5[138].",
            "zh": "ç„¶åè®¡ç®—é€šè¿‡æ‹†åˆ† D7 ä½¿ç”¨ STREAM å’Œ SLOPE è·å¾—çš„ä¿¡æ¯ï¼Œå¦‚è¡¨ 4.5 æ‰€ç¤º[138]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.8[82] shows the workings for the calculation of the covariance between the HEIGHT feature and the WEIGHT and AGE features from the dataset in Table 3.7[73]. The table shows how the portion of Equation (3.3)[81] is calculated for each instance in the dataset for the two covariance calculations. Given this table we can calculate the covariances as follows:",
            "zh": "è¡¨3.8[82]æ˜¾ç¤ºäº†ä»è¡¨3.7[73]çš„æ•°æ®é›†ä¸­è®¡ç®—HEIGHTç‰¹å¾ä¸WEIGHTå’ŒAGEç‰¹å¾ä¹‹é—´çš„åæ–¹å·®çš„å·¥ä½œåŸç†ã€‚ä¸‹è¡¨æ˜¾ç¤ºäº†å¦‚ä½•ä¸ºæ•°æ®é›†ä¸­çš„ä¸¤ä¸ªåæ–¹å·®è®¡ç®—è®¡ç®—æ–¹ç¨‹ ï¼ˆ3.3ï¼‰[81] ä¸­çš„éƒ¨åˆ†ã€‚ç»™å®šæ­¤è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—åæ–¹å·®ï¼š"
        }
    },
    {
        "translation": {
            "en": "It is apparent from this figure that it is not possible to separate the inputs that generate TRUE from those that generate FALSE with a single straight line.",
            "zh": "ä»è¿™å¼ å›¾ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œä¸å¯èƒ½ç”¨ä¸€æ¡ç›´çº¿å°†ç”Ÿæˆ TRUE çš„è¾“å…¥ä¸ç”Ÿæˆ FALSE çš„è¾“å…¥åˆ†å¼€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.7[146] shows the calculation of the information gain using the Gini index for the descriptive features in the vegetation classification dataset.",
            "zh": "è¡¨4.7[146]æ˜¾ç¤ºäº†ä½¿ç”¨åŸºå°¼æŒ‡æ•°è®¡ç®—æ¤è¢«åˆ†ç±»æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Basis functions can also be used to train logistic regression models for categorical prediction problems that involve non-linear relationships.",
            "zh": "åŸºå‡½æ•°è¿˜å¯ç”¨äºè®­ç»ƒæ¶‰åŠéçº¿æ€§å…³ç³»çš„åˆ†ç±»é¢„æµ‹é—®é¢˜çš„é€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "De Bruyne, Katrien, Bram Slabbinck, Willem Waegeman, Paul Vauterin, Bernard De Baets, and Peter Vandamme. 2011. Bacterial species identification from maldi-tof mass spectra through data analysis and machine learning. Systematic and Applied Microbiology 34 (1): 20â€“29.",
            "zh": "å¾·å¸ƒåŠ³å†…ã€å¡ç‰¹é‡Œå®‰ã€å¸ƒæ‹‰å§†Â·æ–¯æ‹‰å®¾å…‹ã€å¨å»‰Â·éŸ¦æ ¼æ›¼ã€ä¿ç½—Â·æ²ƒç‰¹æ—ã€ä¼¯çº³å¾·Â·å¾·è´èŒ¨å’Œå½¼å¾—Â·èŒƒè¾¾å§†ã€‚2011. é€šè¿‡æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ ä»maldi-tofè´¨è°±é‰´å®šç»†èŒç§ç±».ç³»ç»Ÿä¸åº”ç”¨å¾®ç”Ÿç‰©å­¦34ï¼ˆ1ï¼‰ï¼š20-29ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.7â€…â€…â€…A pruned and stunted decision tree built for the Acme Telephonica churn prediction problem.",
            "zh": "12.7 ä¸º Acme Telephonica æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„ä¿®å‰ªå’Œå‘è‚²ä¸è‰¯çš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The observation period that the descriptive features will be based on is the customerâ€™s entire behavior up to the point at which they make this contact.",
            "zh": "æè¿°æ€§ç‰¹å¾æ‰€åŸºäºçš„è§‚å¯ŸæœŸæ˜¯å®¢æˆ·åœ¨è¿›è¡Œæ­¤è”ç³»ä¹‹å‰çš„æ•´ä¸ªè¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.4.1â€ƒPredicting categorical targets using linear regressionâ€ƒTable 7.6[339] shows a sample dataset with a categorical target feature.",
            "zh": "7.4.4.1 ä½¿ç”¨çº¿æ€§å›å½’é¢„æµ‹åˆ†ç±»ç›®æ ‡ è¡¨ 7.6[339] æ˜¾ç¤ºäº†å…·æœ‰åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„æ ·æœ¬æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second Edition",
            "zh": "å†ç‰ˆ"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the interval size, we need to calculate the area under the density curve for that interval.21",
            "zh": "ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†åŒºé—´å¤§å°ï¼Œæˆ‘ä»¬å°±éœ€è¦è®¡ç®—è¯¥åŒºé—´çš„å¯†åº¦æ›²çº¿ä¸‹çš„é¢ç§¯21ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each row in an ABT is composed of a set of descriptive features and a target feature. The actual features themselves can be based on any of the data sources within an organization, and defining them can appear to be a mammoth task at first. This task can be made easier by making a hierarchical distinction between the actual features contained in an ABT and a set of domain concepts upon which features are basedâ€”see Figure 2.2[30].",
            "zh": "ABT ä¸­çš„æ¯ä¸€è¡Œéƒ½ç”±ä¸€ç»„æè¿°æ€§ç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡ç‰¹å¾ç»„æˆã€‚å®é™…åŠŸèƒ½æœ¬èº«å¯ä»¥åŸºäºç»„ç»‡å†…çš„ä»»ä½•æ•°æ®æºï¼Œå®šä¹‰å®ƒä»¬èµ·åˆä¼¼ä¹æ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚é€šè¿‡å¯¹ ABT ä¸­åŒ…å«çš„å®é™…ç‰¹å¾å’Œç‰¹å¾æ‰€åŸºäºçš„ä¸€ç»„é¢†åŸŸæ¦‚å¿µè¿›è¡Œåˆ†å±‚åŒºåˆ†ï¼Œå¯ä»¥ç®€åŒ–æ­¤ä»»åŠ¡â€”â€”å‚è§å›¾ 2.2[30]ã€‚"
        }
    },
    {
        "translation": {
            "en": "If more than one instance in a dataset has the median value for a feature we are splitting on, then we select one of these instances to represent the median and place the other instances with the median value in the set containing the instances whose values are greater than the median.",
            "zh": "å¦‚æœæ•°æ®é›†ä¸­æœ‰å¤šä¸ªå®ä¾‹å…·æœ‰æˆ‘ä»¬æ­£åœ¨æ‹†åˆ†çš„ç‰¹å¾çš„ä¸­å€¼ï¼Œåˆ™æˆ‘ä»¬é€‰æ‹©å…¶ä¸­ä¸€ä¸ªå®ä¾‹æ¥è¡¨ç¤ºä¸­ä½æ•°ï¼Œå¹¶å°†ä¸­ä½æ•°å€¼çš„å…¶ä»–å®ä¾‹æ”¾åœ¨åŒ…å«å…¶å€¼å¤§äºä¸­ä½æ•°çš„å®ä¾‹çš„é›†åˆä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is based on an expectation that fraudulent claims may be made early in the lifetime of a policy before too much has been spent on premiums.",
            "zh": "è¿™æ˜¯åŸºäºä¸€ç§é¢„æœŸï¼Œå³åœ¨ä¿å•å¯¿å‘½çš„æ—©æœŸï¼Œåœ¨ä¿è´¹ä¸ŠèŠ±è´¹è¿‡å¤šä¹‹å‰ï¼Œå¯èƒ½ä¼šæå‡ºæ¬ºè¯ˆæ€§ç´¢èµ”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The softmax activation function normalizes the z scores for a layer of neurons so that the sum of the activations of the neurons is 1.",
            "zh": "softmax æ¿€æ´»å‡½æ•°å¯¹ä¸€å±‚ç¥ç»å…ƒçš„ z åˆ†æ•°è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿ç¥ç»å…ƒçš„æ¿€æ´»æ€»å’Œä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "The logit for an output neuron k, lk, can only indirectly affect the loss in terms of how it changes the predicted probability for the true category: .",
            "zh": "è¾“å‡ºç¥ç»å…ƒ kï¼Œ lk çš„ logit åªèƒ½é—´æ¥å½±å“æŸå¤±ï¼Œå³å®ƒå¦‚ä½•æ”¹å˜çœŸå®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ï¼šã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the version of the support vector machine prediction model that uses basis functions (see Equation 7.46) with the basis functions given in Part (a), calculate the output of the model for a query instance with DOSE1 = 0.90 and DOSE2 = âˆ’0.90.",
            "zh": "ä½¿ç”¨ä½¿ç”¨åŸºå‡½æ•°ï¼ˆå‚è§å…¬å¼ 7.46ï¼‰çš„æ”¯æŒå‘é‡æœºé¢„æµ‹æ¨¡å‹ç‰ˆæœ¬å’Œç¬¬ ï¼ˆaï¼‰ éƒ¨åˆ†ç»™å‡ºçš„åŸºå‡½æ•°ï¼Œè®¡ç®— DOSE1 = 0.90 å’Œ DOSE2 = âˆ’0.90 çš„æŸ¥è¯¢å®ä¾‹çš„æ¨¡å‹è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "It is often (but not always) the case that using a deeper network can drastically reduce the number of neurons required to enable the network to represent a target function.",
            "zh": "é€šå¸¸ï¼ˆä½†å¹¶éæ€»æ˜¯å¦‚æ­¤ï¼‰æƒ…å†µæ˜¯ï¼Œä½¿ç”¨æ›´æ·±çš„ç½‘ç»œå¯ä»¥å¤§å¤§å‡å°‘ä½¿ç½‘ç»œèƒ½å¤Ÿè¡¨ç¤ºç›®æ ‡å‡½æ•°æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final model can accurately distinguish between the two different types of image based on the measured P20 and P45 activity.",
            "zh": "æœ€ç»ˆæ¨¡å‹å¯ä»¥æ ¹æ®æµ‹å¾—çš„P20å’ŒP45æ´»æ€§å‡†ç¡®åŒºåˆ†ä¸¤ç§ä¸åŒç±»å‹çš„å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example the observation period and outcome period are both defined relative to the date of the claim event, which will happen on different dates for different claims.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè§‚å¯ŸæœŸå’Œç»“æœæœŸéƒ½æ˜¯ç›¸å¯¹äºç´¢èµ”äº‹ä»¶çš„æ—¥æœŸå®šä¹‰çš„ï¼Œå¯¹äºä¸åŒçš„ç´¢èµ”ï¼Œè¿™å°†åœ¨ä¸åŒçš„æ—¥æœŸå‘ç”Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Data Understanding, 17, 19, 28, 46, 53, 94, 688, 707, 730",
            "zh": "æ•°æ®ç†è§£ï¼Œ 17ï¼Œ 19ï¼Œ 28ï¼Œ 46ï¼Œ 53ï¼Œ 94ï¼Œ 688ï¼Œ 707ï¼Œ 730"
        }
    },
    {
        "translation": {
            "en": "where Î· is as defined in Equation (6.5)[250].",
            "zh": "å…¶ä¸­Î·å¦‚ç­‰å¼ï¼ˆ6.5ï¼‰[250]æ‰€å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each calculation applies Equation (6.16)[261] and can be understood as a product of the four factors that the naive Bayes model represents: P(FR), P(CH | FR), P(GC | FR), and P(ACC | FR).",
            "zh": "æ¯ä¸ªè®¡ç®—éƒ½åº”ç”¨æ–¹ç¨‹ï¼ˆ6.16ï¼‰[261]ï¼Œå¯ä»¥ç†è§£ä¸ºæœ´ç´ è´å¶æ–¯æ¨¡å‹æ‰€è¡¨ç¤ºçš„å››ä¸ªå› ç´ çš„ä¹˜ç§¯ï¼šPï¼ˆFRï¼‰ï¼ŒPï¼ˆCH |FRï¼‰ã€Pï¼ˆGC |FRï¼‰ å’Œ Pï¼ˆACC |FRï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The three scatter plots in this image are of the dataset in Figure 5.15(c)[219].",
            "zh": "è¯¥å›¾åƒä¸­çš„ä¸‰ä¸ªæ•£ç‚¹å›¾æ˜¯å›¾5.15ï¼ˆcï¼‰[219]ä¸­çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "AHC is, however, much more computationally expensive than k-means, which can be a barrier to using it on very large datasets.",
            "zh": "ç„¶è€Œï¼ŒAHC çš„è®¡ç®—æˆæœ¬æ¯” k å‡å€¼é«˜å¾—å¤šï¼Œè¿™å¯èƒ½æ˜¯åœ¨éå¸¸å¤§çš„æ•°æ®é›†ä¸Šä½¿ç”¨å®ƒçš„éšœç¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Demsar (2006) gives another excellent overview of comparing multiple modeling types and has been the basis for much discussion in the machine learning community.",
            "zh": "Demsar ï¼ˆ2006ï¼‰ å¯¹æ¯”è¾ƒå¤šç§å»ºæ¨¡ç±»å‹è¿›è¡Œäº†å¦ä¸€ä¸ªå‡ºè‰²çš„æ¦‚è¿°ï¼Œå¹¶ä¸”ä¸€ç›´æ˜¯æœºå™¨å­¦ä¹ ç¤¾åŒºä¸­è®¸å¤šè®¨è®ºçš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The emergence of knowledge about how to traverse the environment is also reflected in the fact that the cumulative reward earned by the agent at episode 35 is âˆ’ 115 based on a journey taking 50 actions.",
            "zh": "å…³äºå¦‚ä½•ç©¿è¶Šç¯å¢ƒçš„çŸ¥è¯†çš„å‡ºç°ä¹Ÿåæ˜ åœ¨ä»¥ä¸‹äº‹å®ä¸­ï¼šç‰¹å·¥åœ¨ç¬¬ 35 é›†è·å¾—çš„ç´¯ç§¯å¥–åŠ±æ˜¯ -115ï¼ŒåŸºäºé‡‡å– 50 æ¬¡è¡ŒåŠ¨çš„æ—…ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.1[422] lists the hourly averages for the AMBIENT TEMPERATURE and the RELATIVE HUMIDITY when a power plant is working at full load and the net hourly ELECTRICAL OUTPUT for the plant under these conditions.",
            "zh": "è¡¨8.1[422]åˆ—å‡ºäº†ç”µå‚æ»¡è´Ÿè·å·¥ä½œæ—¶ç¯å¢ƒæ¸©åº¦å’Œç›¸å¯¹æ¹¿åº¦çš„æ¯å°æ—¶å¹³å‡å€¼ï¼Œä»¥åŠç”µå‚åœ¨è¿™äº›æ¡ä»¶ä¸‹çš„æ¯å°æ—¶å‡€ç”µåŠ›è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Not feeling quite brave enough to play a game, you decide to instead study the dealer playing games with other people.",
            "zh": "ä½ è§‰å¾—è‡ªå·±ä¸å¤Ÿå‹‡æ•¢å»ç©æ¸¸æˆï¼Œäºæ˜¯å†³å®šè½¬è€Œç ”ç©¶åº„å®¶å’Œå…¶ä»–äººä¸€èµ·ç©æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, given that the weights are real numbers, there are infinitely many combinations of weights, and we are using only integer values in the examples for the sake of clarity in presentation.",
            "zh": "äº‹å®ä¸Šï¼Œé‰´äºæƒé‡æ˜¯å®æ•°ï¼Œæƒé‡çš„ç»„åˆæœ‰æ— é™å¤šï¼Œä¸ºäº†è¡¨ç¤ºæ¸…æ¥šèµ·è§ï¼Œæˆ‘ä»¬åœ¨ç¤ºä¾‹ä¸­åªä½¿ç”¨æ•´æ•°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that both Neurons 3 and 4 had an activation of 0 in response to d2 resulted in both of these neurons having a Î´ = 0.",
            "zh": "ç¥ç»å…ƒ 3 å’Œ 4 å¯¹ d2 çš„æ¿€æ´»å‡ä¸º 0ï¼Œè¿™ä¸€äº‹å®å¯¼è‡´è¿™ä¸¤ä¸ªç¥ç»å…ƒçš„Î´ = 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "student-t distribution, 271, 272",
            "zh": "å­¦ç”Ÿ-T åˆ†å¸ƒï¼Œ271ã€272"
        }
    },
    {
        "translation": {
            "en": "The â€œM.L.",
            "zh": "â€œM.L."
        }
    },
    {
        "translation": {
            "en": "The state at time-step t, st, should contain all the important information about the environment at that time-step, any important information about what has been happening in the environment at preceding time-steps, and any important information about the internal composition of the agent.",
            "zh": "æ—¶é—´æ­¥é•¿ tï¼Œ st çš„çŠ¶æ€åº”åŒ…å«æœ‰å…³è¯¥æ—¶é—´æ­¥ç¯å¢ƒçš„æ‰€æœ‰é‡è¦ä¿¡æ¯ã€æœ‰å…³å‰ä¸€ä¸ªæ—¶é—´æ­¥ç¯å¢ƒä¸­å‘ç”Ÿçš„æƒ…å†µçš„ä»»ä½•é‡è¦ä¿¡æ¯ï¼Œä»¥åŠæœ‰å…³ä»£ç†å†…éƒ¨ç»„æˆçš„ä»»ä½•é‡è¦ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2",
            "zh": "å›¾ 3.2"
        }
    },
    {
        "translation": {
            "en": "reduced error pruning, 155, 174, 698",
            "zh": "å‡å°‘é”™è¯¯ä¿®å‰ªï¼Œ155,174,698"
        }
    },
    {
        "translation": {
            "en": "Remember that the sum of all the elements in a probability distribution must be 1.0.",
            "zh": "è¯·è®°ä½ï¼Œæ¦‚ç‡åˆ†å¸ƒä¸­æ‰€æœ‰å…ƒç´ çš„æ€»å’Œå¿…é¡»ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following data quality report has been generated from the ABT.",
            "zh": "ä»¥ä¸‹æ•°æ®è´¨é‡æŠ¥å‘Šå·²ä» ABT ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2473",
            "zh": "0.2473"
        }
    },
    {
        "translation": {
            "en": "These algorithms determine which descriptive features provide the most information about a target feature and make predictions by sequentially testing the features in order of their informativeness.",
            "zh": "è¿™äº›ç®—æ³•ç¡®å®šå“ªäº›æè¿°æ€§ç‰¹å¾æä¾›æœ‰å…³ç›®æ ‡ç‰¹å¾çš„æœ€å¤šä¿¡æ¯ï¼Œå¹¶é€šè¿‡æŒ‰ä¿¡æ¯é¡ºåºæµ‹è¯•ç‰¹å¾è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second approach to identifying outliers is to compare the gaps between the median, minimum, maximum, 1st quartile, and 3rd quartile values.",
            "zh": "è¯†åˆ«å¼‚å¸¸å€¼çš„ç¬¬äºŒç§æ–¹æ³•æ˜¯æ¯”è¾ƒä¸­ä½æ•°ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€ç¬¬ä¸€å››åˆ†ä½æ•°å’Œç¬¬ä¸‰å››åˆ†ä½æ•°å€¼ä¹‹é—´çš„å·®è·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each neuron in this layer has a local receptive field of dimensions 2-by-2, and there is no overlap between the receptive fields of the neurons in this layer.",
            "zh": "è¯¥å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰ä¸€ä¸ªç»´åº¦ä¸º 2Ã—2 çš„å±€éƒ¨æ„Ÿå—é‡ï¼Œå¹¶ä¸”è¯¥å±‚ä¸­ç¥ç»å…ƒçš„æ„Ÿå—é‡ä¹‹é—´æ²¡æœ‰é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.6â€…â€…â€…The Predictive Data Analytics Project Lifecycle: CRISP-DM",
            "zh": "1.6 é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ç”Ÿå‘½å‘¨æœŸï¼šCRISP-DM"
        }
    },
    {
        "translation": {
            "en": "Figure 5.6(a)[193] demonstrates how this approach can regularize the decision boundary for the dataset in Table 5.4[191].",
            "zh": "å›¾5.6ï¼ˆaï¼‰[193]æ¼”ç¤ºäº†è¿™ç§æ–¹æ³•å¦‚ä½•è§„èŒƒè¡¨5.4[191]ä¸­æ•°æ®é›†çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The last four columns on the right of the table list for each instance the product of the prediction error and the feature value.",
            "zh": "è¡¨æ ¼å³ä¾§çš„æœ€åå››åˆ—åˆ—å‡ºäº†æ¯ä¸ªå®ä¾‹çš„é¢„æµ‹è¯¯å·®å’Œç‰¹å¾å€¼çš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is known as conditional independence.",
            "zh": "è¿™ç§°ä¸ºæœ‰æ¡ä»¶ç‹¬ç«‹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem is, however, that although these models agree on which predictions should be made for the instances in the training dataset, they disagree with regard to which predictions should be returned for instances that are not in the training dataset.",
            "zh": "ç„¶è€Œï¼Œé—®é¢˜åœ¨äºï¼Œå°½ç®¡è¿™äº›æ¨¡å‹åŒæ„åº”è¯¥å¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹è¿›è¡Œå“ªäº›é¢„æµ‹ï¼Œä½†å®ƒä»¬ä¸åŒæ„åº”è¯¥ä¸ºä¸åœ¨è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹è¿”å›å“ªäº›é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the probability of the event a and Â¬b is",
            "zh": "ä¾‹å¦‚ï¼Œäº‹ä»¶ a å’Œ Â¬b çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "(a) Would the similarity-based, information-based, or probability-based predictive modeling approaches already covered in this book be likely to do a better job of learning this model than the simple linear regression model?",
            "zh": "ï¼ˆaï¼‰ æœ¬ä¹¦ä¸­å·²ç»ä»‹ç»çš„åŸºäºç›¸ä¼¼æ€§ã€åŸºäºä¿¡æ¯æˆ–åŸºäºæ¦‚ç‡çš„é¢„æµ‹å»ºæ¨¡æ–¹æ³•æ˜¯å¦å¯èƒ½æ¯”ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ è¯¥æ¨¡å‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The way that a convolutional neural network uses weight sharing to achieve translation equivariant feature detection is by organizing the local receptive fields of a set of neurons that share a filter (and hence share their weights) so that (1) each neuronâ€™s receptive field covers a slightly different region of the visual field compared with the other neurons in the set; and (2) together the receptive fields of the neurons in the set cover the entire visual field.",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œä½¿ç”¨æƒé‡å…±äº«æ¥å®ç°å¹³ç§»ç­‰å˜ç‰¹å¾æ£€æµ‹çš„æ–¹å¼æ˜¯é€šè¿‡ç»„ç»‡ä¸€ç»„å…±äº«è¿‡æ»¤å™¨ï¼ˆå› æ­¤å…±äº«å…¶æƒé‡ï¼‰çš„ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ï¼Œä»¥ä¾¿ ï¼ˆ1ï¼‰ ä¸é›†åˆä¸­çš„å…¶ä»–ç¥ç»å…ƒç›¸æ¯”ï¼Œæ¯ä¸ªç¥ç»å…ƒçš„æ„Ÿå—é‡è¦†ç›–çš„è§†é‡åŒºåŸŸç•¥æœ‰ä¸åŒ;ï¼ˆ2ï¼‰é›†åˆä¸­ç¥ç»å…ƒçš„æ„Ÿå—é‡ä¸€èµ·è¦†ç›–äº†æ•´ä¸ªè§†é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Convolutional layer 2 includes Filters 3 and 4, and it does not include a sub-sampling layer.45 Filters 3 and 4 will both have a depth of 2 because the input to the second convolutional layer is the two stacked features maps generated by Convolutional layer 1.",
            "zh": "å·ç§¯å±‚ 2 åŒ…æ‹¬æ»¤æ³¢å™¨ 3 å’Œ 4ï¼Œå®ƒä¸åŒ…æ‹¬å­é‡‡æ ·å±‚ã€‚45 æ»¤æ³¢å™¨ 3 å’Œ 4 çš„æ·±åº¦å‡ä¸º 2ï¼Œå› ä¸ºç¬¬äºŒä¸ªå·ç§¯å±‚çš„è¾“å…¥æ˜¯ç”±å·ç§¯å±‚ 1 ç”Ÿæˆçš„ä¸¤ä¸ªå †å ç‰¹å¾å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is one of the Bellman Equations,14 which are the foundation stones of reinforcement learning.",
            "zh": "è¿™æ˜¯è´å°”æ›¼æ–¹ç¨‹14ä¹‹ä¸€ï¼Œå®ƒæ˜¯å¼ºåŒ–å­¦ä¹ çš„åŸºçŸ³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Histograms for six different sets of data, each of which exhibit well-known, common characteristics.",
            "zh": "å…­ç»„ä¸åŒæ•°æ®é›†çš„ç›´æ–¹å›¾ï¼Œæ¯ç»„æ•°æ®éƒ½å…·æœ‰ä¼—æ‰€å‘¨çŸ¥çš„å…±åŒç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that the vanishing gradient problem arises from repeatedly multiplying the error gradients by the derivative of the activation functions, one way to address the vanishing gradient problem is to use a different activation function. At the start of the chapter we introduced the rectified linear function:23",
            "zh": "é‰´äºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ˜¯ç”±äºè¯¯å·®æ¢¯åº¦åå¤ä¹˜ä»¥æ¿€æ´»å‡½æ•°çš„å¯¼æ•°è€Œäº§ç”Ÿçš„ï¼Œå› æ­¤è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°ã€‚åœ¨æœ¬ç« çš„å¼€å¤´ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ•´æµçº¿æ€§å‡½æ•°ï¼š23"
        }
    },
    {
        "translation": {
            "en": "statistical significance, 585",
            "zh": "ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œ585"
        }
    },
    {
        "translation": {
            "en": "Figure 2.2",
            "zh": "å›¾ 2.2"
        }
    },
    {
        "translation": {
            "en": "This is slightly more of a concern to machine learning researchers who are interested in comparing the overall power of different machine learning algorithms.",
            "zh": "å¯¹äºæœ‰å…´è¶£æ¯”è¾ƒä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•çš„æ•´ä½“èƒ½åŠ›çš„æœºå™¨å­¦ä¹ ç ”ç©¶äººå‘˜æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªç¨å¾®å…³å¿ƒçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, .",
            "zh": "æ‰€ä»¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.15[427] illustrates the forward pass of d2 through the network.",
            "zh": "å›¾ 8.15[427] è¯´æ˜äº† d2 é€šè¿‡ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can do this by adapting the ID3 algorithm to use a measure of variance15 rather than a measure of entropy in selecting the best feature.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´ ID3 ç®—æ³•ï¼Œä½¿å…¶åœ¨é€‰æ‹©æœ€ä½³ç‰¹å¾æ—¶ä½¿ç”¨æ–¹å·®åº¦é‡15ï¼Œè€Œä¸æ˜¯ç†µåº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the errors show that, in general, predictions made by the candidate model are too low, then w[j] should be increased if di[j] is positive and decreased if di[j] is negative.",
            "zh": "å¦‚æœè¯¯å·®è¡¨æ˜ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œå€™é€‰æ¨¡å‹çš„é¢„æµ‹å€¼å¤ªä½ï¼Œé‚£ä¹ˆå¦‚æœ di[j] ä¸ºæ­£ï¼Œåˆ™ w[j] åº”å¢åŠ ï¼Œå¦‚æœ di[j] ä¸ºè´Ÿï¼Œåˆ™ w[j] åº”å‡å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "mean squared error, 575",
            "zh": "å‡æ–¹è¯¯å·®ï¼Œ575"
        }
    },
    {
        "translation": {
            "en": "6.2.2â€ƒBayesian Prediction",
            "zh": "6.2.2 è´å¶æ–¯é¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "In this example each instance has been put into an individual partition, and although these partitions each have a variance of zero, this is indicative of overfitting the data.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ¯ä¸ªå®ä¾‹éƒ½å·²æ”¾å…¥å•ç‹¬çš„åˆ†åŒºä¸­ï¼Œå°½ç®¡æ¯ä¸ªåˆ†åŒºçš„æ–¹å·®å‡ä¸ºé›¶ï¼Œä½†è¿™è¡¨ç¤ºæ•°æ®è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "These Î´s were calculated by backpropagating the error on Example 2.",
            "zh": "è¿™äº›Î´æ˜¯é€šè¿‡åå‘ä¼ æ’­ç¤ºä¾‹2ä¸Šçš„è¯¯å·®æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, this is not the case, as the distribution of prediction scores for a model can follow any distribution.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œäº‹å®å¹¶éå¦‚æ­¤ï¼Œå› ä¸ºæ¨¡å‹çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒå¯ä»¥éµå¾ªä»»ä½•åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we describe how to evaluate machine learning models built for predictive data analytics tasks.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•è¯„ä¼°ä¸ºé¢„æµ‹æ•°æ®åˆ†æä»»åŠ¡æ„å»ºçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the SDSS dataset, many of the features are represented multiple times for each of the five different photometric bands, and this made Jocelyn suspect that many of these features might be redundant and so ripe for removal from the dataset.",
            "zh": "åœ¨ SDSS æ•°æ®é›†ä¸­ï¼Œäº”ä¸ªä¸åŒå…‰åº¦æ³¢æ®µä¸­çš„æ¯ä¸€ä¸ªéƒ½å¤šæ¬¡è¡¨ç¤ºäº†è®¸å¤šç‰¹å¾ï¼Œè¿™è®© Jocelyn æ€€ç–‘å…¶ä¸­è®¸å¤šç‰¹å¾å¯èƒ½æ˜¯å¤šä½™çš„ï¼Œå› æ­¤å¯ä»¥ä»æ•°æ®é›†ä¸­åˆ é™¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "For this reason, we recommend the use of equal-frequency binning to convert continuous features to categorical ones for probability-based models.",
            "zh": "å› æ­¤ï¼Œå¯¹äºåŸºäºæ¦‚ç‡çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ç­‰é¢‘åˆ†ç®±å°†è¿ç»­ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An email spam prediction dataset.",
            "zh": "åƒåœ¾é‚®ä»¶é¢„æµ‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "distributions, 102",
            "zh": "åˆ†å¸ƒï¼Œ102"
        }
    },
    {
        "translation": {
            "en": "Care must be taken, however, when selecting the parameter k, particularly when working with imbalanced datasets.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨é€‰æ‹©å‚æ•° k æ—¶å¿…é¡»å°å¿ƒï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨ä¸å¹³è¡¡æ•°æ®é›†æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, as is so often the case in machine learning, this is not the end of the generative versus discriminative debate.",
            "zh": "ç„¶è€Œï¼Œæ­£å¦‚æœºå™¨å­¦ä¹ ä¸­ç»å¸¸å‡ºç°çš„æƒ…å†µä¸€æ ·ï¼Œè¿™å¹¶ä¸æ˜¯ç”Ÿæˆæ€§ä¸æ­§è§†æ€§è¾©è®ºçš„ç»“æŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7(b)[76] shows another example, for the POSITION and SHOE SPONSOR features from the same dataset. In this case, the three plots are very different, so we can conclude that there is a relationship between these two features. It seems that players who play in the guard position are much more likely to have a shoe sponsor than forwards or centers.",
            "zh": "å›¾ 3.7ï¼ˆbï¼‰[76] æ˜¾ç¤ºäº†æ¥è‡ªåŒä¸€æ•°æ®é›†çš„ POSITION å’Œ SHOE SPONSOR è¦ç´ çš„å¦ä¸€ä¸ªç¤ºä¾‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™ä¸‰ä¸ªå›¾éå¸¸ä¸åŒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œè¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´å­˜åœ¨å…³ç³»ã€‚ä¼¼ä¹åœ¨åå«ä½ç½®ä¸Šè¸¢çƒçš„çƒå‘˜æ¯”å‰é”‹æˆ–ä¸­é”‹æ›´æœ‰å¯èƒ½æ‹¥æœ‰é‹å­èµåŠ©å•†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Four continuous features stood out as possibly suffering from the presence of outliers: HANDSETPRICE, with a minimum value of 0, which seemed unusual; AVGMINS, with a maximum of 6,336.25, which was very different from the mean and the 3rd quartile values for that feature; AVGRECEIVEDMINS, with a maximum of 2,006.29, which was also very different from the mean and the 3rd quartile values for that feature; and AVGOVERBUNDLEMINS, with minimum, 1st quartile, and median values of 0 compared to a mean of 40.",
            "zh": "å››ä¸ªè¿ç»­çš„ç‰¹å¾å¯èƒ½å—åˆ°å¼‚å¸¸å€¼çš„å½±å“ï¼šHANDSETPRICEï¼Œæœ€å°å€¼ä¸º 0ï¼Œè¿™ä¼¼ä¹ä¸å¯»å¸¸;AVGMINSï¼Œæœ€å¤§å€¼ä¸º 6,336.25ï¼Œä¸è¯¥ç‰¹å¾çš„å¹³å‡å€¼å’Œç¬¬ 3 ä¸ªå››åˆ†ä½æ•°å€¼ç›¸å·®å¾ˆå¤§;AVGRECEIVEDMINSï¼Œæœ€å¤§å€¼ä¸º 2,006.29ï¼Œä¹Ÿä¸è¯¥ç‰¹å¾çš„å¹³å‡å€¼å’Œç¬¬ 3 ä¸ªå››åˆ†ä½æ•°å€¼æœ‰å¾ˆå¤§å·®å¼‚;å’Œ AVGOVERBUNDLEMINSï¼Œæœ€å°å€¼ã€ç¬¬ä¸€å››åˆ†ä½æ•°å’Œä¸­ä½æ•°å€¼ä¸º 0ï¼Œè€Œå¹³å‡å€¼ä¸º 40ã€‚"
        }
    },
    {
        "translation": {
            "en": "More likely, the easy availability of data for some solutions might favor them over others.",
            "zh": "æ›´æœ‰å¯èƒ½çš„æ˜¯ï¼ŒæŸäº›è§£å†³æ–¹æ¡ˆçš„æ•°æ®æ˜“äºè·å¾—å¯èƒ½æ¯”å…¶ä»–è§£å†³æ–¹æ¡ˆæ›´æœ‰åˆ©äºå®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is useful for exploring the relationships between groups of featuresâ€”for example, all the continuous features in an ABT.",
            "zh": "è¿™å¯¹äºæ¢ç´¢ç‰¹å¾ç»„ä¹‹é—´çš„å…³ç³»éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚ï¼ŒABT ä¸­çš„æ‰€æœ‰è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Paulâ€™s impressive accuracy should not be taken to suggest that octopus behavior affects soccer matches but rather that independent events may be correlated, at least for an interval of time, without the events actually being dependent.",
            "zh": "ä¿ç½—ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§ä¸åº”è¯¥è¢«ç†è§£ä¸ºç« é±¼çš„è¡Œä¸ºä¼šå½±å“è¶³çƒæ¯”èµ›ï¼Œè€Œæ˜¯è®¤ä¸ºç‹¬ç«‹çš„äº‹ä»¶å¯èƒ½æ˜¯ç›¸å…³çš„ï¼Œè‡³å°‘åœ¨ä¸€æ®µæ—¶é—´å†…æ˜¯è¿™æ ·ï¼Œè€Œè¿™äº›äº‹ä»¶å®é™…ä¸Šå¹¶ä¸å…·æœ‰ä¾èµ–æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hadamard product, xxvii, 475, 773",
            "zh": "Hadamard äº§å“ï¼Œxxviiï¼Œ475,773"
        }
    },
    {
        "translation": {
            "en": "clusters, 599",
            "zh": "é›†ç¾¤ï¼Œ599"
        }
    },
    {
        "translation": {
            "en": "The distance between the query instance and d21 is 0.9014, which is less than the value stored in best-distance (we can see this in Figure 5.10(b)[201], as d21 is inside the target hypersphere).",
            "zh": "æŸ¥è¯¢å®ä¾‹å’Œ d21 ä¹‹é—´çš„è·ç¦»ä¸º 0.9014ï¼Œå°äºå­˜å‚¨åœ¨ best-distance ä¸­çš„å€¼ï¼ˆæˆ‘ä»¬å¯ä»¥åœ¨å›¾ 5.10ï¼ˆbï¼‰[201] ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸º d21 ä½äºç›®æ ‡è¶…çƒä½“å†…ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first is to examine the minimum and maximum values for each feature and use domain knowledge to determine whether these are plausible values.",
            "zh": "é¦–å…ˆæ˜¯æ£€æŸ¥æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œå¹¶ä½¿ç”¨é¢†åŸŸçŸ¥è¯†æ¥ç¡®å®šè¿™äº›å€¼æ˜¯å¦åˆç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A Bayesian network representation of the conditional independence asserted by a naive Bayes model between the descriptive features given knowledge of the target feature; and (b) a Bayesian network representation of the conditional independence assumption for the naive Bayes model in the fraud example.",
            "zh": "ï¼ˆaï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çŸ¥è¯†çš„æè¿°æ€§ç‰¹å¾ä¹‹é—´æ–­è¨€çš„æ¡ä»¶ç‹¬ç«‹æ€§çš„è´å¶æ–¯ç½‘ç»œè¡¨ç¤º;ï¼ˆbï¼‰æ¬ºè¯ˆç¤ºä¾‹ä¸­æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾çš„è´å¶æ–¯ç½‘ç»œè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.14",
            "zh": "å›¾ 7.14"
        }
    },
    {
        "translation": {
            "en": "âˆ’0.00176664",
            "zh": "âˆ’0.00176664"
        }
    },
    {
        "translation": {
            "en": "An example of a commonly used sampling method that attempts to address these two issues is k-fold cross validation.",
            "zh": "å°è¯•è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜çš„å¸¸ç”¨æŠ½æ ·æ–¹æ³•çš„ä¸€ä¸ªä¾‹å­æ˜¯ k å€äº¤å‰éªŒè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. Remember that a harmonic mean is used in the F 1 measure given in Equation (9.10)[550].",
            "zh": "10. è¯·è®°ä½ï¼Œåœ¨ç­‰å¼ï¼ˆ9.10ï¼‰[550]ä¸­ç»™å‡ºçš„F 1åº¦é‡ä¸­ä½¿ç”¨äº†è°ƒå’Œå¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each image is grayscale and can be represented as a grid of 28 by 28 integers in the range [0,255] where a 0 value indicates a white pixel, a value of 255 indicates a black pixel, and numbers between 0 and 255 indicate shades of gray.",
            "zh": "æ¯ä¸ªå›¾åƒéƒ½æ˜¯ç°åº¦çš„ï¼Œå¯ä»¥è¡¨ç¤ºä¸º [0,255] èŒƒå›´å†…çš„ 28 x 28 æ•´æ•°ç½‘æ ¼ï¼Œå…¶ä¸­ 0 å€¼è¡¨ç¤ºç™½è‰²åƒç´ ï¼Œå€¼ 255 è¡¨ç¤ºé»‘è‰²åƒç´ ï¼Œ0 åˆ° 255 ä¹‹é—´çš„æ•°å­—è¡¨ç¤ºç°è‰²é˜´å½±ã€‚"
        }
    },
    {
        "translation": {
            "en": "What types of models will we use? How will we set the parameters of the machine learning algorithms? Have underfitting or overfitting occurred?",
            "zh": "æˆ‘ä»¬å°†ä½¿ç”¨å“ªäº›ç±»å‹çš„æ¨¡å‹ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•è®¾ç½®æœºå™¨å­¦ä¹ ç®—æ³•çš„å‚æ•°ï¼Ÿæ˜¯å¦å‘ç”Ÿè¿‡æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "15. The data used in this question have been artificially generated for this book. Channel propensity modeling is used widely in industry; for example, see Hirschowitz (2001).",
            "zh": "15. æœ¬é—®é¢˜ä¸­ä½¿ç”¨çš„æ•°æ®æ˜¯ä¸ºæœ¬ä¹¦äººå·¥ç”Ÿæˆçš„ã€‚ä¿¡é“å€¾å‘å»ºæ¨¡åœ¨å·¥ä¸šä¸­è¢«å¹¿æ³›ä½¿ç”¨;ä¾‹å¦‚ï¼Œè¯·å‚é˜…Hirschowitz ï¼ˆ2001ï¼‰ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Guess Who is a two-player game in which one player chooses a card with a picture of a character on it from a deck, and the other player tries to guess which character is on the card by asking a series of questions to which the answer can be only yes or no.",
            "zh": "çŒœçŒœæ˜¯è°æ˜¯ä¸€æ¬¾åŒäººæ¸¸æˆï¼Œå…¶ä¸­ä¸€åç©å®¶ä»ä¸€å‰¯ç‰Œä¸­é€‰æ‹©ä¸€å¼ å¸¦æœ‰è§’è‰²å›¾ç‰‡çš„å¡ç‰‡ï¼Œå¦ä¸€åç©å®¶è¯•å›¾é€šè¿‡æå‡ºä¸€ç³»åˆ—é—®é¢˜æ¥çŒœæµ‹å¡ç‰‡ä¸Šçš„å“ªä¸ªè§’è‰²ï¼Œç­”æ¡ˆåªèƒ½æ˜¯æˆ–å¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are many scenarios in which this is the case.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½æ˜¯è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "minimum description length principle, 292",
            "zh": "æœ€å°æè¿°é•¿åº¦åŸåˆ™ï¼Œ292"
        }
    },
    {
        "translation": {
            "en": "10.3.1â€…â€…â€…A Worked Example",
            "zh": "10.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "â€œStudy the past if you would define the future.â€",
            "zh": "â€œå¦‚æœä½ è¦å®šä¹‰æœªæ¥ï¼Œå°±è¦ç ”ç©¶è¿‡å»ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "Two decision trees, (a) and (b), that are consistent with the instances in the spam dataset; and (c) the path taken through the tree shown in (a) to make a prediction for the query instance SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, and CONTAINS IMAGES = true.",
            "zh": "ä¸¤ä¸ªå†³ç­–æ ‘ ï¼ˆaï¼‰ å’Œ ï¼ˆbï¼‰ï¼Œä¸åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„å®ä¾‹ä¸€è‡´;ä»¥åŠ ï¼ˆcï¼‰ é€šè¿‡ ï¼ˆaï¼‰ æ‰€ç¤ºçš„æ ‘å¯¹æŸ¥è¯¢å®ä¾‹ SUSPICIOUS WORDS = trueã€UNKNOWN SENDER = true å’Œ CONTAINS IMAGES = true è¿›è¡Œé¢„æµ‹çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia?",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„ä¸‰æœ€è¿‘é‚»é¢„æµ‹æ¨¡å‹å¯¹ä¿„ç½—æ–¯ CPI çš„è¿”å›å€¼æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The galaxy types that Galaxy Zoo citizen scientists could choose from were elliptical, clockwise spiral, anti-clockwise spiral, edge-on disk, merger, and donâ€™t know.",
            "zh": "é“¶æ²³åŠ¨ç‰©å›­å…¬æ°‘ç§‘å­¦å®¶å¯ä»¥é€‰æ‹©çš„æ˜Ÿç³»ç±»å‹æ˜¯æ¤­åœ†å½¢ã€é¡ºæ—¶é’ˆèºæ—‹ã€é€†æ—¶é’ˆèºæ—‹ã€è¾¹ç¼˜åœ†ç›˜ã€åˆå¹¶å’Œä¸çŸ¥é“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the fact that deep learning models are combined by connecting artificial neurons together means that we can tailor the structure of a network toward the characteristics of the data on which we are planning to run the network.",
            "zh": "æœ€åï¼Œé€šè¿‡å°†äººå·¥ç¥ç»å…ƒè¿æ¥åœ¨ä¸€èµ·æ¥ç»„åˆæ·±åº¦å­¦ä¹ æ¨¡å‹è¿™ä¸€äº‹å®æ„å‘³ç€æˆ‘ä»¬å¯ä»¥æ ¹æ®æˆ‘ä»¬è®¡åˆ’è¿è¡Œç½‘ç»œçš„æ•°æ®ç‰¹å¾æ¥å®šåˆ¶ç½‘ç»œçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this, the R2 coefficient for the regression model can be calculated as 0.889 and for the nearest neighbor model as 0.776.",
            "zh": "ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œå›å½’æ¨¡å‹çš„ R2 ç³»æ•°å¯ä»¥è®¡ç®—ä¸º 0.889ï¼Œæœ€è¿‘é‚»æ¨¡å‹çš„ R2 ç³»æ•°å¯ä»¥è®¡ç®—ä¸º 0.776ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, each of the neurons in the first layer connects only to a single neuron in the sub-sampling layer.",
            "zh": "å› æ­¤ï¼Œç¬¬ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä»…è¿æ¥åˆ°å­é‡‡æ ·å±‚ä¸­çš„å•ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This is achieved by replacing the input vector containing a single example with an input matrix containing multiple examples.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†åŒ…å«å•ä¸ªç¤ºä¾‹çš„è¾“å…¥å‘é‡æ›¿æ¢ä¸ºåŒ…å«å¤šä¸ªç¤ºä¾‹çš„è¾“å…¥çŸ©é˜µæ¥å®ç°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is one of the reasons why creating a data quality report7 and spending time on cleaning the dataset is such an important part of any machine learning project.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåˆ›å»ºæ•°æ®è´¨é‡æŠ¥å‘Š7 å¹¶èŠ±æ—¶é—´æ¸…ç†æ•°æ®é›†æ˜¯ä»»ä½•æœºå™¨å­¦ä¹ é¡¹ç›®å¦‚æ­¤é‡è¦çš„ä¸€éƒ¨åˆ†çš„åŸå› ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.2",
            "zh": "å›¾ 1.2"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this dataset are SIZE (the property size in square feet) and RENT (the estimated monthly rental value of the property in dollars).",
            "zh": "æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾æ˜¯ SIZEï¼ˆä»¥å¹³æ–¹è‹±å°ºä¸ºå•ä½çš„æˆ¿äº§é¢ç§¯ï¼‰å’Œ RENTï¼ˆä»¥ç¾å…ƒä¸ºå•ä½çš„æˆ¿äº§çš„ä¼°è®¡æœˆç§Ÿé‡‘ä»·å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the channel prediction dataset given in Question 3.",
            "zh": "ä»¥ä¸‹æ•°æ®å¯è§†åŒ–åŸºäºé—®é¢˜ 3 ä¸­ç»™å‡ºçš„ä¿¡é“é¢„æµ‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "WEIGHT",
            "zh": "é‡é‡"
        }
    },
    {
        "translation": {
            "en": "Hecht-Nielsen (1987) showed how these proofs could be applied to neural networks.",
            "zh": "Hecht-Nielsenï¼ˆ1987ï¼‰å±•ç¤ºäº†å¦‚ä½•å°†è¿™äº›è¯æ˜åº”ç”¨äºç¥ç»ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "B.3â€ƒSome Useful Probability Rules",
            "zh": "B.3 ä¸€äº›æœ‰ç”¨çš„æ¦‚ç‡è§„åˆ™"
        }
    },
    {
        "translation": {
            "en": "This scenario is illustrated in Figure 2.8[40].",
            "zh": "å›¾2.8[40]è¯´æ˜äº†è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "After deployment it can often make sense to restrict an agent to greedy action selection and allow no further exploration.",
            "zh": "éƒ¨ç½²åï¼Œé€šå¸¸å°†ä»£ç†é™åˆ¶ä¸ºè´ªå©ªçš„æ“ä½œé€‰æ‹©ï¼Œå¹¶ä¸”ä¸å…è®¸è¿›ä¸€æ­¥æ¢ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "specificity, 548, 559",
            "zh": "ç‰¹å¼‚æ€§ï¼Œ548,559"
        }
    },
    {
        "translation": {
            "en": "The prediction model shown in Figure 1.3(d)[15], however, is a Goldilocks model: it is just right, striking a good balance between underfitting and overfitting.",
            "zh": "ç„¶è€Œï¼Œå›¾1.3ï¼ˆdï¼‰[15]æ‰€ç¤ºçš„é¢„æµ‹æ¨¡å‹æ˜¯ä¸€ä¸ªé‡‘å‘å§‘å¨˜æ¨¡å‹ï¼šå®ƒæ°åˆ°å¥½å¤„ï¼Œåœ¨æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Efficiently indexing and accessing memory is an important consideration in scaling nearest neighbor models to large datasets.",
            "zh": "æœ‰æ•ˆåœ°ç´¢å¼•å’Œè®¿é—®å†…å­˜æ˜¯å°†æœ€è¿‘é‚»æ¨¡å‹æ‰©å±•åˆ°å¤§å‹æ•°æ®é›†çš„é‡è¦è€ƒè™‘å› ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tsanas, Athanasios, and Angeliki Xifara. 2012. Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. Energy and Buildings 49: 560â€“567.",
            "zh": "Tsanasã€Athanasios å’Œ Angeliki Xifaraã€‚2012. ä½¿ç”¨ç»Ÿè®¡æœºå™¨å­¦ä¹ å·¥å…·å¯¹ä½å®…å»ºç­‘èƒ½æºæ€§èƒ½è¿›è¡Œå‡†ç¡®å®šé‡ä¼°è®¡.èƒ½æºä¸å»ºç­‘49ï¼š560-567ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of working in scientific scenarios is that there is a body of literature that discusses how other scientists have addressed similar problems.",
            "zh": "åœ¨ç§‘å­¦åœºæ™¯ä¸­å·¥ä½œçš„å¥½å¤„ä¹‹ä¸€æ˜¯ï¼Œæœ‰å¤§é‡æ–‡çŒ®è®¨è®ºäº†å…¶ä»–ç§‘å­¦å®¶å¦‚ä½•è§£å†³ç±»ä¼¼é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.8â€ƒThe Road Ahead",
            "zh": "1.8 å‰æ–¹çš„é“è·¯"
        }
    },
    {
        "translation": {
            "en": "It is important to remember, though, that no matter how well it is done, binning always discards information from the dataset because it abstracts from a continuous representation to a coarser categorical resolution.",
            "zh": "ä½†æ˜¯ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œæ— è®ºå®ƒåšå¾—å¤šä¹ˆå¥½ï¼Œåˆ†ç®±æ€»æ˜¯ä¼šä¸¢å¼ƒæ•°æ®é›†ä¸­çš„ä¿¡æ¯ï¼Œå› ä¸ºå®ƒä»è¿ç»­è¡¨ç¤ºæŠ½è±¡åˆ°æ›´ç²—ç•¥çš„åˆ†ç±»åˆ†è¾¨ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we set the number of bins to a very low numberâ€”for example, two or three binsâ€”(in other words, we abstract to a very low level of resolution), we may lose a lot of information with respect to the distribution of values in the original continuous feature. Using a small number of bins, however, has the advantage of having a large number of instances in each bin.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†æ¡æŸ±çš„æ•°é‡è®¾ç½®ä¸ºä¸€ä¸ªéå¸¸ä½çš„æ•°å­—ï¼ˆä¾‹å¦‚ï¼Œä¸¤ä¸ªæˆ–ä¸‰ä¸ªæ¡æŸ±ï¼‰ï¼Œï¼ˆæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æŠ½è±¡åˆ°ä¸€ä¸ªéå¸¸ä½çš„åˆ†è¾¨ç‡çº§åˆ«ï¼‰ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä¸¢å¤±å¾ˆå¤šå…³äºåŸå§‹è¿ç»­ç‰¹å¾ä¸­å€¼åˆ†å¸ƒçš„ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œä½¿ç”¨å°‘é‡ bin çš„ä¼˜ç‚¹æ˜¯æ¯ä¸ª bin ä¸­éƒ½æœ‰å¤§é‡å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A doctor has carried out a regular checkup on a patient and measured the patientâ€™s WEIGHT to be 65 kilograms and their HEIGHT to be 1.7 meters. The doctor inputs these details into a k-NN classifier to check whether the patient is at risk of DIABETES. Assuming that k = 1, and that the model uses Euclidean distance as its similarity metric, will the model return true or false for this patient?",
            "zh": "ï¼ˆaï¼‰ åŒ»ç”Ÿå¯¹ç—…äººè¿›è¡Œå®šæœŸæ£€æŸ¥ï¼Œæµ‹é‡ç—…äººçš„ä½“é‡ä¸º65å…¬æ–¤ï¼Œèº«é«˜ä¸º1.7ç±³ã€‚åŒ»ç”Ÿå°†è¿™äº›è¯¦ç»†ä¿¡æ¯è¾“å…¥åˆ° k-NN åˆ†ç±»å™¨ä¸­ï¼Œä»¥æ£€æŸ¥æ‚£è€…æ˜¯å¦æœ‰æ‚£ç³–å°¿ç—…çš„é£é™©ã€‚å‡è®¾ k = 1ï¼Œå¹¶ä¸”æ¨¡å‹ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ä½œä¸ºå…¶ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼Œåˆ™è¯¥æ¨¡å‹ä¼šè¿”å›è¯¥æ‚£è€…çš„çœŸå€¼è¿˜æ˜¯å‡å€¼ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "As a result, the area of each bar (the bar height times the bar width) gives the probability for the feature taking a value in the interval represented by that bar.",
            "zh": "å› æ­¤ï¼Œæ¯ä¸ªæ¡å½¢çš„é¢ç§¯ï¼ˆæ¡å½¢é«˜åº¦ä¹˜ä»¥æ¡å½¢å®½åº¦ï¼‰ç»™å‡ºäº†è¦ç´ åœ¨è¯¥æ¡å½¢æ‰€è¡¨ç¤ºçš„åŒºé—´å†…å–ä¸€ä¸ªå€¼çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The error rate measures the number of predictions made by the tree that are incorrect.",
            "zh": "é”™è¯¯ç‡è¡¡é‡æ ‘åšå‡ºçš„ä¸æ­£ç¡®é¢„æµ‹çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given these terms we calculate the update for the weights in W(f) using the sequence of calculations listed in Equations (8.132)[519] to (8.138)[520]",
            "zh": "ç»™å®šè¿™äº›é¡¹ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–¹ç¨‹ï¼ˆ8.132ï¼‰[519]è‡³ï¼ˆ8.138ï¼‰[520]ä¸­åˆ—å‡ºçš„è®¡ç®—é¡ºåºæ¥è®¡ç®—Wï¼ˆfï¼‰ä¸­æƒé‡çš„æ›´æ–°"
        }
    },
    {
        "translation": {
            "en": "FIBERFLUX_U/G/R/I/Z",
            "zh": "FIBERFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "When an Îµ-greedy policy is used, an agent chooses the best action most of the time, but occasionallyâ€”with a probability of Îµâ€”selects a random action uniformly from those available.",
            "zh": "å½“ä½¿ç”¨Îµè´ªå©ªç­–ç•¥æ—¶ï¼Œä»£ç†å¤§å¤šæ•°æ—¶å€™ä¼šé€‰æ‹©æœ€ä½³æ“ä½œï¼Œä½†å¶å°”ï¼ˆæ¦‚ç‡ä¸º Îµï¼‰ä¼šä»å¯ç”¨æ“ä½œä¸­ç»Ÿä¸€é€‰æ‹©éšæœºæ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.13(a)[90] there are three bins that are each quite wide, and the histogram heights donâ€™t really follow the dashed line.",
            "zh": "åœ¨å›¾ 3.13ï¼ˆaï¼‰[90] ä¸­ï¼Œæœ‰ä¸‰ä¸ªæ¡æŸ±ï¼Œæ¯ä¸ªæ¡æŸ±éƒ½å¾ˆå®½ï¼Œç›´æ–¹å›¾é«˜åº¦å¹¶ä¸çœŸæ­£éµå¾ªè™šçº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, letâ€™s step through how the algorithm makes this prediction.",
            "zh": "ä½†æ˜¯ï¼Œè®©æˆ‘ä»¬é€æ­¥äº†è§£ç®—æ³•å¦‚ä½•è¿›è¡Œæ­¤é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A Markov process, a more basic framework than an MDP that does not include decision making, can be used to model a discrete random process that transitions through a finite set of states, S. For example, we could use a Markov process to model how infection progresses in an individual when a disease epidemic breaks out.",
            "zh": "é©¬å°”å¯å¤«è¿‡ç¨‹æ˜¯ä¸€ä¸ªæ¯”ä¸åŒ…æ‹¬å†³ç­–çš„ MDP æ›´åŸºæœ¬çš„æ¡†æ¶ï¼Œå¯ç”¨äºæ¨¡æ‹Ÿé€šè¿‡ä¸€ç»„æœ‰é™çŠ¶æ€ S è½¬æ¢çš„ç¦»æ•£éšæœºè¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é©¬å°”å¯å¤«è¿‡ç¨‹æ¥æ¨¡æ‹Ÿç–¾ç—…æµè¡Œçˆ†å‘æ—¶ä¸ªä½“çš„æ„ŸæŸ“è¿›å±•æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "This chapter begins by describing the structure of a data quality report and explaining how it is used to get to know the data in an ABT and to identify data quality issues.",
            "zh": "æœ¬ç« é¦–å…ˆæè¿°äº†æ•°æ®è´¨é‡æŠ¥å‘Šçš„ç»“æ„ï¼Œå¹¶è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨å®ƒæ¥äº†è§£ ABT ä¸­çš„æ•°æ®å¹¶è¯†åˆ«æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "This suggests that when the model makes mistakes, it more commonly incorrectly predicts the spam level than the ham level.",
            "zh": "è¿™è¡¨æ˜ï¼Œå½“æ¨¡å‹çŠ¯é”™è¯¯æ—¶ï¼Œå®ƒæ›´å¸¸è§åœ°é”™è¯¯åœ°é¢„æµ‹åƒåœ¾é‚®ä»¶çº§åˆ«ï¼Œè€Œä¸æ˜¯ä¸šä½™æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, Gini index, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "è¡¨4.3[136]ä¸­æ•°æ®é›†çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€åŸºå°¼æŒ‡æ•°ã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although, data protection legislation changes significantly across different jurisdictions, there are some common tenets on which there is broad agreement.",
            "zh": "å°½ç®¡ä¸åŒå¸æ³•ç®¡è¾–åŒºçš„æ•°æ®ä¿æŠ¤ç«‹æ³•æœ‰å¾ˆå¤§å˜åŒ–ï¼Œä½†æœ‰ä¸€äº›å…±åŒçš„åŸåˆ™å¾—åˆ°äº†å¹¿æ³›çš„è®¤åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "One consequence of abstracting away from the training data is that models induced using an eager learning algorithm are typically faster at making predictions than models based on a lazy learner.",
            "zh": "ä»è®­ç»ƒæ•°æ®ä¸­æŠ½è±¡å‡ºæ¥çš„ä¸€ä¸ªåæœæ˜¯ï¼Œä½¿ç”¨æ¸´æœ›å­¦ä¹ ç®—æ³•è¯±å¯¼çš„æ¨¡å‹é€šå¸¸æ¯”åŸºäºæ‡’æƒ°å­¦ä¹ è€…çš„æ¨¡å‹æ›´å¿«åœ°è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov processes are built on the Markov assumption that the probability of transitioning to a particular state at the next time-step relies only on the current state, and does not require any knowledge of the history of states that came before that, or",
            "zh": "é©¬å°”å¯å¤«è¿‡ç¨‹å»ºç«‹åœ¨é©¬å°”å¯å¤«å‡è®¾ä¹‹ä¸Šï¼Œå³åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥è¿‡æ¸¡åˆ°ç‰¹å®šçŠ¶æ€çš„æ¦‚ç‡ä»…å–å†³äºå½“å‰çŠ¶æ€ï¼Œå¹¶ä¸”ä¸éœ€è¦ä»»ä½•å…³äºä¹‹å‰çŠ¶æ€å†å²çš„çŸ¥è¯†ï¼Œæˆ–è€…"
        }
    },
    {
        "translation": {
            "en": "When we use a hold-out test set, we take one sample from the overall dataset to use to train a model and another separate sample to test the model.",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨ä¿ç•™æµ‹è¯•é›†æ—¶ï¼Œæˆ‘ä»¬ä»æ•´ä¸ªæ•°æ®é›†ä¸­è·å–ä¸€ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä»å¦ä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ä¸­è·å–æ¨¡å‹æ¥æµ‹è¯•æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "As well as showing that it is hard to make money in the payday loans business, this reverses the ordering implied using the average class accuracy.",
            "zh": "é™¤äº†è¡¨æ˜åœ¨å‘è–ªæ—¥è´·æ¬¾ä¸šåŠ¡ä¸­å¾ˆéš¾èµšé’±å¤–ï¼Œè¿™è¿˜é¢ å€’äº†ä½¿ç”¨å¹³å‡ç±»å‡†ç¡®æ€§éšå«çš„æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "This example also illustrates a problem with using covariance.",
            "zh": "æ­¤ç¤ºä¾‹è¿˜è¯´æ˜äº†ä½¿ç”¨åæ–¹å·®çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final component of the MDP shown in Figure 11.3[648] is the reward associated with each transition to a new state based on taking a particular action.",
            "zh": "å›¾ 11.3[648] æ‰€ç¤ºçš„ MDP çš„æœ€åä¸€ä¸ªç»„æˆéƒ¨åˆ†æ˜¯åŸºäºé‡‡å–ç‰¹å®šè¡ŒåŠ¨çš„æ¯æ¬¡è¿‡æ¸¡åˆ°æ–°çŠ¶æ€çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "weighted dataset, 160",
            "zh": "åŠ æƒæ•°æ®é›†ï¼Œ160"
        }
    },
    {
        "translation": {
            "en": "-0.71",
            "zh": "-0.71"
        }
    },
    {
        "translation": {
            "en": "The weight matrix for the tanh layer in the output gate (W(oâ€¡), including bias terms, has dimensions H Ã— (1 + H).",
            "zh": "è¾“å‡ºæ …æ ï¼ˆWï¼ˆoâ€¡ï¼‰ ä¸­ tanh å±‚çš„æƒé‡çŸ©é˜µï¼ˆåŒ…æ‹¬åç½®é¡¹ï¼‰çš„å°ºå¯¸ä¸º H Ã— ï¼ˆ1 + Hï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can formally define a feature space as an abstract m-dimensional space that is created by making each descriptive feature in a dataset an axis of an m-dimensional coordinate system and mapping each instance in the dataset to a point in this coordinate system based on the values of its descriptive features.",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†ç‰¹å¾ç©ºé—´æ­£å¼å®šä¹‰ä¸ºä¸€ä¸ªæŠ½è±¡çš„ m ç»´ç©ºé—´ï¼Œè¯¥ç©ºé—´æ˜¯é€šè¿‡ä½¿æ•°æ®é›†ä¸­çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾æˆä¸º m ç»´åæ ‡ç³»çš„è½´ï¼Œå¹¶æ ¹æ®å…¶æè¿°æ€§ç‰¹å¾çš„å€¼å°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹æ˜ å°„åˆ°è¯¥åæ ‡ç³»ä¸­çš„æŸä¸ªç‚¹æ¥åˆ›å»ºçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If too many neurons in a network are dead, then the network will not converge during training.",
            "zh": "å¦‚æœç½‘ç»œä¸­æœ‰å¤ªå¤šçš„ç¥ç»å…ƒæ­»äº¡ï¼Œé‚£ä¹ˆç½‘ç»œåœ¨è®­ç»ƒæœŸé—´å°±ä¸ä¼šæ”¶æ•›ã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPMAG_U/G/R/I/Z",
            "zh": "EXPMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The simplest version of this would be a numeric state vector input into a multi-layer perceptron feedforward network.",
            "zh": "æœ€ç®€å•çš„ç‰ˆæœ¬æ˜¯å°†æ•°å­—çŠ¶æ€å‘é‡è¾“å…¥åˆ°å¤šå±‚æ„ŸçŸ¥å™¨å‰é¦ˆç½‘ç»œä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(d)[453] clearly illustrates vanishing gradients across layers in the network; that the Î´ values are tending toward 0 is indicated by the fact that the median of the Î´ values across the layers is 0 but the variance of Î´ values rapidly shrinks as we move backward from the last hidden layer (HL5) to the first layer (HL1).",
            "zh": "å›¾8.23ï¼ˆdï¼‰[453]æ¸…æ¥šåœ°è¯´æ˜äº†ç½‘ç»œä¸­å„å±‚çš„æ¢¯åº¦æ¶ˆå¤±;Î´å€¼è¶‹å‘äº 0 çš„äº‹å®è¡¨æ˜ï¼Œå„å±‚çš„ Î´ å€¼çš„ä¸­ä½æ•°ä¸º 0ï¼Œä½†å½“æˆ‘ä»¬ä»æœ€åä¸€ä¸ªéšè—å±‚ ï¼ˆHL5ï¼‰ å‘åç§»åŠ¨åˆ°ç¬¬ä¸€å±‚ ï¼ˆHL1ï¼‰ æ—¶ï¼ŒÎ´å€¼çš„æ–¹å·®ä¼šè¿…é€Ÿç¼©å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "unstable gradients, 449",
            "zh": "ä¸ç¨³å®šæ¢¯åº¦ï¼Œ449"
        }
    },
    {
        "translation": {
            "en": "The algorithm finds the division of instances into clusters by minimizing",
            "zh": "è¯¥ç®—æ³•é€šè¿‡æœ€å°åŒ–æ¥æ‰¾åˆ°å°†å®ä¾‹åˆ’åˆ†ä¸ºé›†ç¾¤çš„æ–¹æ³•"
        }
    },
    {
        "translation": {
            "en": "8.4.5â€ƒConvolutional Neural Networks",
            "zh": "8.4.5 å·ç§¯ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "1.2â€…â€…â€…The two steps in supervised machine learning: (a) learning and (b) predicting.",
            "zh": "1.2 ç›‘ç£æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªæ­¥éª¤ï¼šï¼ˆaï¼‰å­¦ä¹ å’Œï¼ˆbï¼‰é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "TwentyTwos is a game played between a single player and a dealer.",
            "zh": "TwentyTwosæ˜¯å•äººç©å®¶å’Œåº„å®¶ä¹‹é—´çš„æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "5. Be confident that enough good-quality data exists to continue with a project.",
            "zh": "5. ç¡®ä¿¡å­˜åœ¨è¶³å¤Ÿå¤šçš„é«˜è´¨é‡æ•°æ®æ¥ç»§ç»­é¡¹ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent chooses the next action to take, however, using its policy (Line 13[658]), in this case Îµ-greedy with Îµ = 0.1.",
            "zh": "ä½†æ˜¯ï¼Œä»£ç†ä½¿ç”¨å…¶ç­–ç•¥ï¼ˆç¬¬ 13 è¡Œ[658]ï¼‰é€‰æ‹©è¦æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªæ“ä½œï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸º Îµ = 0.1 çš„è´ªå©ªÎµã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the probability distribution for the binary feature MENINGITIS from Table B.2[760], with a probability of 0.3 of being true and using the convention of the first element in the vector being the probability for a true value, would be written as P(M) = 0.3,0.7.",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨B.2[760]ä¸­äºŒå…ƒç‰¹å¾è„‘è†œç‚çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…¶ä¸ºçœŸçš„æ¦‚ç‡ä¸º0.3ï¼Œå¹¶ä¸”ä½¿ç”¨å‘é‡ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ çš„çº¦å®šä¸ºçœŸå€¼çš„æ¦‚ç‡ï¼Œå°†å†™ä¸ºPï¼ˆMï¼‰ = 0.3,0.7ã€‚"
        }
    },
    {
        "translation": {
            "en": "All three gates in an LSTM involve an elementwise product of two activation vectors (see Equations (8.107)[509], (8.112)[511], and (8.116)[512]).",
            "zh": "LSTMä¸­çš„æ‰€æœ‰ä¸‰ä¸ªé—¨éƒ½æ¶‰åŠä¸¤ä¸ªæ¿€æ´»å‘é‡çš„å…ƒç´ ä¹˜ç§¯ï¼ˆå‚è§æ–¹ç¨‹ï¼ˆ8.107ï¼‰[509]ï¼Œï¼ˆ8.112ï¼‰[511]å’Œï¼ˆ8.116ï¼‰[512]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov decision process, 638, 643, 645",
            "zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œ638,643,645"
        }
    },
    {
        "translation": {
            "en": "At this point the information in the query is used to define a neighborhood in the feature space, and a prediction is made based on the instances in this neighborhood.",
            "zh": "æ­¤æ—¶ï¼ŒæŸ¥è¯¢ä¸­çš„ä¿¡æ¯ç”¨äºå®šä¹‰è¦ç´ ç©ºé—´ä¸­çš„é‚»åŸŸï¼Œå¹¶æ ¹æ®è¯¥é‚»åŸŸä¸­çš„å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Email classification is a good application scenario in which the different information provided by precision and recall is useful.",
            "zh": "ç”µå­é‚®ä»¶åˆ†ç±»æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åº”ç”¨åœºæ™¯ï¼Œå…¶ä¸­ç²¾åº¦å’Œå¬å›ç‡æä¾›çš„ä¸åŒä¿¡æ¯å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The electrical power output from a combined cycle power plant is influenced by a number of ambient parameters, such as temperature and humidity; being able to accurately predict the output of the power plant working a full load with respect to these parameters can significantly reduce the cost of energy production (TÃ¼fekci, 2014).",
            "zh": "è”åˆå¾ªç¯å‘ç”µå‚çš„ç”µåŠ›è¾“å‡ºå—è®¸å¤šç¯å¢ƒå‚æ•°çš„å½±å“ï¼Œä¾‹å¦‚æ¸©åº¦å’Œæ¹¿åº¦;èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å‘ç”µå‚æ ¹æ®è¿™äº›å‚æ•°æ»¡è´Ÿè·å·¥ä½œçš„è¾“å‡ºå¯ä»¥æ˜¾ç€é™ä½èƒ½æºç”Ÿäº§æˆæœ¬ï¼ˆTÃ¼fekciï¼Œ2014ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a model trained on the bacterial species identification problem.",
            "zh": "é’ˆå¯¹ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜è®­ç»ƒçš„æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "One problem with sparse data is that with so few non-zero values, the variation between two instances may be dominated by noise.",
            "zh": "ç¨€ç–æ•°æ®çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œç”±äºéé›¶å€¼å¾ˆå°‘ï¼Œä¸¤ä¸ªå®ä¾‹ä¹‹é—´çš„å˜åŒ–å¯èƒ½ä»¥å™ªå£°ä¸ºä¸»ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we perform the same calculation for the other candidate models shown in Figure 7.2(a)[316], we find that with w[1] set to 0.4, 0.5, 0.7, and 0.8, the sums of squared errors are 136,218, 42,712, 20,092, and 90,978 respectively. The fact that the sums of squared errors for these models are larger than for the model with w[1] set to 0.62 demonstrates that our previous visual intuition that this model most accurately fits the training data was correct.",
            "zh": "å¦‚æœæˆ‘ä»¬å¯¹å›¾7.2ï¼ˆaï¼‰[316]ä¸­æ‰€ç¤ºçš„å…¶ä»–å€™é€‰æ¨¡å‹æ‰§è¡Œç›¸åŒçš„è®¡ç®—ï¼Œæˆ‘ä»¬å‘ç°ï¼Œå½“w[1]è®¾ç½®ä¸º0.4ã€0.5ã€0.7å’Œ0.8æ—¶ï¼Œå¹³æ–¹è¯¯å·®ä¹‹å’Œåˆ†åˆ«ä¸º136,218ã€42,712ã€20,092å’Œ90,978ã€‚è¿™äº›æ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œå¤§äºè®¾ç½®ä¸º 0.62 çš„æ¨¡å‹çš„å¹³æ–¹è¯¯å·®æ€»å’Œè¿™ä¸€äº‹å®è¡¨æ˜ï¼Œæˆ‘ä»¬ä¹‹å‰çš„è§†è§‰ç›´è§‰è®¤ä¸ºè¯¥æ¨¡å‹æœ€å‡†ç¡®åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®æ˜¯æ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, each neuron in the network learns a separate gradient for its activation function for the region z â‰¤ 0.",
            "zh": "æ¢å¥è¯è¯´ï¼Œç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸ºå…¶åŒºåŸŸ z â‰¤ 0 çš„æ¿€æ´»å‡½æ•°å­¦ä¹ ä¸€ä¸ªå•ç‹¬çš„æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Identifying pairs of closely related descriptive features is one way to reduce the size of an ABT because if the relationship between two descriptive features is strong enough, we may not need to include both.",
            "zh": "è¯†åˆ«å¯†åˆ‡ç›¸å…³çš„æè¿°æ€§ç‰¹å¾å¯¹æ˜¯å‡å° ABT å¤§å°çš„ä¸€ç§æ–¹æ³•ï¼Œå› ä¸ºå¦‚æœä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å…³ç³»è¶³å¤Ÿå¼ºï¼Œæˆ‘ä»¬å¯èƒ½ä¸éœ€è¦åŒæ—¶åŒ…å«ä¸¤è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first thing to understand is that there is not one best approach that always outperforms the others.",
            "zh": "é¦–å…ˆè¦äº†è§£çš„æ˜¯ï¼Œæ²¡æœ‰ä¸€ç§æœ€ä½³æ–¹æ³•æ€»æ˜¯ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.6",
            "zh": "è¡¨ 5.6"
        }
    },
    {
        "translation": {
            "en": "These two approaches ran in parallel for 12 weeks, and at the end of this period, the company measured the number of customers within each group who had left the company to join another network.",
            "zh": "è¿™ä¸¤ç§æ–¹æ³•å¹¶è¡Œè¿è¡Œäº† 12 å‘¨ï¼Œåœ¨è¿™æ®µæ—¶é—´ç»“æŸæ—¶ï¼Œè¯¥å…¬å¸æµ‹é‡äº†æ¯ä¸ªç»„ä¸­ç¦»å¼€å…¬å¸åŠ å…¥å¦ä¸€ä¸ªç½‘ç»œçš„å®¢æˆ·æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental idea underpinning early stopping is that we can identify the point during an iterative training algorithm (such as backpropagation) when a model begins to overfit the training data as being the point when the error of the model on a validation dataset begins to increase.",
            "zh": "æ”¯æŒæ—©æœŸåœæ­¢çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿­ä»£è®­ç»ƒç®—æ³•ï¼ˆä¾‹å¦‚åå‘ä¼ æ’­ï¼‰æœŸé—´ç¡®å®šæ¨¡å‹å¼€å§‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®çš„ç‚¹ï¼Œå³æ¨¡å‹åœ¨éªŒè¯æ•°æ®é›†ä¸Šçš„è¯¯å·®å¼€å§‹å¢åŠ çš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.1â€ƒVisualizing Relationships between Features",
            "zh": "3.5.1 å¯è§†åŒ–è¦ç´ ä¹‹é—´çš„å…³ç³»"
        }
    },
    {
        "translation": {
            "en": "(a) What target level will a naive Bayes model predict for the following query document: â€œmachine learning is funâ€?",
            "zh": "ï¼ˆaï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹ä»¥ä¸‹æŸ¥è¯¢æ–‡æ¡£çš„ç›®æ ‡æ°´å¹³ï¼šâ€œæœºå™¨å­¦ä¹ å¾ˆæœ‰è¶£â€ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Although from an analytics perspective, there is really little difference, using the correct terminology makes it much easier for business partners to engage with the analytics project.",
            "zh": "å°½ç®¡ä»åˆ†æçš„è§’åº¦æ¥çœ‹ï¼Œå®é™…ä¸Šå‡ ä¹æ²¡æœ‰åŒºåˆ«ï¼Œä½†ä½¿ç”¨æ­£ç¡®çš„æœ¯è¯­å¯ä»¥ä½¿ä¸šåŠ¡åˆä½œä¼™ä¼´æ›´å®¹æ˜“å‚ä¸åˆ†æé¡¹ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4.3â€ƒCase Study: Motor Insurance Fraud",
            "zh": "3.4.3 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "We would like to measure how accurately the predicted values match the correct target values.",
            "zh": "æˆ‘ä»¬æƒ³è¡¡é‡é¢„æµ‹å€¼ä¸æ­£ç¡®ç›®æ ‡å€¼åŒ¹é…çš„å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "weights, 314",
            "zh": "é‡é‡ï¼Œ314"
        }
    },
    {
        "translation": {
            "en": "In variational RNN, the dropout mask is selected once per sequence (rather than at each input), and so the same neurons are dropped across all time-steps in the sequence; for more details see Gal and Ghahramani (2016).",
            "zh": "åœ¨å˜åˆ†RNNä¸­ï¼Œæ¯ä¸ªåºåˆ—ï¼ˆè€Œä¸æ˜¯åœ¨æ¯ä¸ªè¾“å…¥ä¸­ï¼‰é€‰æ‹©ä¸€æ¬¡ç¼ºå¤±æ©ç ï¼Œå› æ­¤åœ¨åºåˆ—ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥é•¿ä¸­éƒ½ä¸¢å¼ƒç›¸åŒçš„ç¥ç»å…ƒ;æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…Gal and Ghahramani ï¼ˆ2016ï¼‰ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each image contains a single digit that has been size-normalized and centered.",
            "zh": "æ¯ä¸ªå›¾åƒéƒ½åŒ…å«ä¸€ä¸ªå·²æ ‡å‡†åŒ–å¤§å°å¹¶å±…ä¸­çš„å•ä¸ªæ•°å­—ã€‚"
        }
    },
    {
        "translation": {
            "en": "These techniques are generally applicable to all machine learning algorithms but are especially important when similarity-based approaches are used.",
            "zh": "è¿™äº›æŠ€æœ¯é€šå¸¸é€‚ç”¨äºæ‰€æœ‰æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä½†åœ¨ä½¿ç”¨åŸºäºç›¸ä¼¼æ€§çš„æ–¹æ³•æ—¶å°¤ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "What retention offer would a particular customer best respond to? A system could be built to predict which offer, from a set of possible retention offers, a particular customer would be most likely respond to when contacted by the AT retention team. This could help the retention team convince more customers to stay with AT.",
            "zh": "ç‰¹å®šå®¢æˆ·æœ€èƒ½å“åº”å“ªäº›ä¿ç•™ä¼˜æƒ ï¼Ÿå¯ä»¥æ„å»ºä¸€ä¸ªç³»ç»Ÿæ¥é¢„æµ‹ï¼Œå½“ AT ä¿ç•™å›¢é˜Ÿè”ç³»æ—¶ï¼Œç‰¹å®šå®¢æˆ·æœ€æœ‰å¯èƒ½ä»ä¸€ç»„å¯èƒ½çš„ä¿ç•™äº§å“/æœåŠ¡ä¸­å“åº”å“ªäº›äº§å“/æœåŠ¡ã€‚è¿™å¯ä»¥å¸®åŠ©ç•™å­˜å›¢é˜Ÿè¯´æœæ›´å¤šå®¢æˆ·ç•™åœ¨ ATã€‚"
        }
    },
    {
        "translation": {
            "en": "In the basic form of k-means clustering, the initial cluster centroids, or seeds, are chosen at random uniformly within the feature space.",
            "zh": "åœ¨ k å‡å€¼èšç±»çš„åŸºæœ¬å½¢å¼ä¸­ï¼Œåˆå§‹èšç±»è´¨å¿ƒæˆ–ç§å­åœ¨ç‰¹å¾ç©ºé—´å†…è¢«éšæœºå‡åŒ€é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "variance, 149, 206, 220, 747, 747, 748, 752",
            "zh": "æ–¹å·®ï¼Œ 149ï¼Œ 206ï¼Œ 220ï¼Œ 747ï¼Œ 747ï¼Œ 748ï¼Œ 752"
        }
    },
    {
        "translation": {
            "en": "Figures 3.2(c)[60] and 3.2(d)[60] show unimodal histograms that exhibit skew.",
            "zh": "å›¾3.2ï¼ˆcï¼‰[60]å’Œå›¾3.2ï¼ˆdï¼‰[60]æ˜¾ç¤ºäº†è¡¨ç°å‡ºåæ–œçš„å•å³°ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each claim the observation and output periods are defined relative to the specific date of that claim.",
            "zh": "å¯¹äºæ¯ä¸€é¡¹ç´¢èµ”ï¼Œè§‚å¯ŸæœŸå’Œè¾“å‡ºæœŸæ˜¯ç›¸å¯¹äºè¯¥ç´¢èµ”çš„å…·ä½“æ—¥æœŸç¡®å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What items will the system recommend to the following customer? Assume that the recommender system uses the similarity index you chose in the first part of this question and is trained on the sample dataset listed above. Also assume that the system generates recommendations for query customers by finding the customer most similar to them in the dataset and then recommending the items that this similar customer has bought but that the query customer has not bought.",
            "zh": "ï¼ˆbï¼‰ ç³»ç»Ÿå°†å‘ä»¥ä¸‹å®¢æˆ·æ¨èå“ªäº›é¡¹ç›®ï¼Ÿå‡è®¾æ¨èç³»ç»Ÿä½¿ç”¨æ‚¨åœ¨æœ¬é—®é¢˜ç¬¬ä¸€éƒ¨åˆ†ä¸­é€‰æ‹©çš„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œå¹¶åœ¨ä¸Šé¢åˆ—å‡ºçš„ç¤ºä¾‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œå‡è®¾ç³»ç»Ÿé€šè¿‡åœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾ä¸ä»–ä»¬æœ€ç›¸ä¼¼çš„å®¢æˆ·ï¼Œç„¶åæ¨èè¯¥ç±»ä¼¼å®¢æˆ·å·²è´­ä¹°ä½†æŸ¥è¯¢å®¢æˆ·å°šæœªè´­ä¹°çš„ç‰©æ–™ï¼Œä¸ºæŸ¥è¯¢å®¢æˆ·ç”Ÿæˆå»ºè®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The effects that can occur when different drugs are taken together can be difficult for doctors to predict.",
            "zh": "å½“ä¸åŒçš„è¯ç‰©ä¸€èµ·æœç”¨æ—¶å¯èƒ½å‘ç”Ÿçš„å½±å“å¯¹äºåŒ»ç”Ÿæ¥è¯´å¯èƒ½å¾ˆéš¾é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "All the imaginary pixels have been given a value of 000.",
            "zh": "æ‰€æœ‰è™šåƒç´ çš„å€¼å‡ä¸º 000ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental question that analysts must answer is how do the members of a particular cluster differ from the overall populationâ€”what makes the members of this cluster special?",
            "zh": "åˆ†æå¸ˆå¿…é¡»å›ç­”çš„åŸºæœ¬é—®é¢˜æ˜¯ï¼Œç‰¹å®šèšç±»çš„æˆå‘˜ä¸æ€»ä½“ç¾¤ä½“æœ‰ä½•ä¸åŒâ€”â€”æ˜¯ä»€ä¹ˆè®©è¿™ä¸ªèšç±»çš„æˆå‘˜ä¸ä¼—ä¸åŒï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The second category of proofs assumes the use of smooth functions within neurons.",
            "zh": "ç¬¬äºŒç±»è¯æ˜å‡è®¾åœ¨ç¥ç»å…ƒå†…ä½¿ç”¨å¹³æ»‘å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2â€…â€…â€…An illustration of the decision boundaries learned by different machine learning algorithms for three artificial datasets.",
            "zh": "14.2 ä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•å¯¹ä¸‰ä¸ªäººå·¥æ•°æ®é›†å­¦ä¹ çš„å†³ç­–è¾¹ç•Œçš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.7",
            "zh": "å›¾ 6.7"
        }
    },
    {
        "translation": {
            "en": "FRACDEV_U/G/R/I/Z",
            "zh": "FRACDEV_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Instead, she needed enough information to understand the key pieces of equipment involved, the important aspects of the night sky objects that she would be classifying, and the key terminology involved.",
            "zh": "ç›¸åï¼Œå¥¹éœ€è¦è¶³å¤Ÿçš„ä¿¡æ¯æ¥äº†è§£æ‰€æ¶‰åŠçš„å…³é”®è®¾å¤‡ã€å¥¹å°†è¦åˆ†ç±»çš„å¤œç©ºå¤©ä½“çš„é‡è¦æ–¹é¢ä»¥åŠæ‰€æ¶‰åŠçš„å…³é”®æœ¯è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The descriptive features in this dataset are of different types.",
            "zh": "ï¼ˆcï¼‰ æœ¬æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾å±äºä¸åŒç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning is based on calculating the error between a predicted value for the expected return from taking an action in a given state and the actual return that is earned when the agent takes that action (Equation (11.23)[655]).",
            "zh": "æ—¶é—´å·®åˆ†å­¦ä¹ åŸºäºè®¡ç®—åœ¨ç»™å®šçŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥çš„é¢„æµ‹å€¼ä¸æ™ºèƒ½ä½“é‡‡å–è¯¥è¡ŒåŠ¨æ—¶è·å¾—çš„å®é™…å›æŠ¥ä¹‹é—´çš„è¯¯å·®ï¼ˆç­‰å¼ï¼ˆ11.23ï¼‰[655]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some of these probabilities are highlighted along the edges in Figure 11.3[648].",
            "zh": "å…¶ä¸­ä¸€äº›æ¦‚ç‡åœ¨å›¾11.3[648]çš„è¾¹ç¼˜çªå‡ºæ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of a reduced version of the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "ï¼ˆaï¼‰ è¡¨10.1[604]ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ç®€åŒ–ç‰ˆæœ¬å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An example validation set for the post-operative patient routing task.",
            "zh": "æœ¯åæ‚£è€…è·¯ç”±ä»»åŠ¡çš„ç¤ºä¾‹éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In more realistic scenarios, however, there are usually many more descriptive features, which means many more possible combinations.",
            "zh": "ç„¶è€Œï¼Œåœ¨æ›´ç°å®çš„åœºæ™¯ä¸­ï¼Œé€šå¸¸æœ‰æ›´å¤šçš„æè¿°æ€§ç‰¹å¾ï¼Œè¿™æ„å‘³ç€æ›´å¤šå¯èƒ½çš„ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Euclidean norm, 364",
            "zh": "æ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼Œ364"
        }
    },
    {
        "translation": {
            "en": "Once we have used the backpropagation algorithm to solve the blame assignment problem for all the neurons in the network, we can then use the weight update rule from the gradient descent algorithm to update the weights for each of the neurons in the network.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•è§£å†³äº†ç½‘ç»œä¸­æ‰€æœ‰ç¥ç»å…ƒçš„å½’å’åˆ†é…é—®é¢˜ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­çš„æƒé‡æ›´æ–°è§„åˆ™æ¥æ›´æ–°ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "44. As noted previously, in some texts, such as Goodfellow et al. (2016), the application of the activation function is treated as a separate step after the feature map has been generated by the application of the filter. In these scenarios, the raw scalar value would be stored in the feature map.",
            "zh": "44. å¦‚å‰æ‰€è¿°ï¼Œåœ¨ä¸€äº›æ–‡æœ¬ä¸­ï¼Œä¾‹å¦‚Goodfellowç­‰äººï¼ˆ2016å¹´ï¼‰ï¼Œåœ¨åº”ç”¨è¿‡æ»¤å™¨ç”Ÿæˆç‰¹å¾å›¾ä¹‹åï¼Œæ¿€æ´»å‡½æ•°çš„åº”ç”¨è¢«è§†ä¸ºä¸€ä¸ªå•ç‹¬çš„æ­¥éª¤ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼ŒåŸå§‹æ ‡é‡å€¼å°†å­˜å‚¨åœ¨ç‰¹å¾å›¾ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the discounted return at time t = 0 on the basis of this sequence of rewards using a discounting factor of 0.72.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨è´´ç°ç³»æ•° 0.72 æ ¹æ®è¿™ä¸€å¥–åŠ±åºåˆ—è®¡ç®—æ—¶é—´ t = 0 æ—¶çš„è´´ç°å›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Approaches taking this approach include policy gradient and evolutionary reinforcement learning approaches.",
            "zh": "4. é‡‡ç”¨è¿™ç§æ–¹æ³•çš„æ–¹æ³•åŒ…æ‹¬æ”¿ç­–æ¢¯åº¦å’Œè¿›åŒ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "ecological modeling, 135",
            "zh": "ç”Ÿæ€å»ºæ¨¡ï¼Œ135"
        }
    },
    {
        "translation": {
            "en": "IIâ€…â€…â€…PREDICTIVE DATA ANALYTICS",
            "zh": "II é¢„æµ‹æ€§æ•°æ®åˆ†æ"
        }
    },
    {
        "translation": {
            "en": "conditional maximum entropy model, 357",
            "zh": "æ¡ä»¶æœ€å¤§ç†µæ¨¡å‹ï¼Œ357"
        }
    },
    {
        "translation": {
            "en": "C.2â€…â€…Examples of continuous functions (shown as solid lines) and their derivatives (shown as dashed lines).",
            "zh": "C.2 è¿ç»­å‡½æ•°ï¼ˆä»¥å®çº¿è¡¨ç¤ºï¼‰åŠå…¶å¯¼æ•°ï¼ˆä»¥è™šçº¿è¡¨ç¤ºï¼‰çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2.3â€ƒInformation Gain",
            "zh": "4.2.3 ä¿¡æ¯å¢ç›Š"
        }
    },
    {
        "translation": {
            "en": "where the values used are extracted from Table 3.3[57].",
            "zh": "å…¶ä¸­ä½¿ç”¨çš„å€¼æ˜¯ä»è¡¨3.3[57]ä¸­æå–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Lagrange multipliers, 363",
            "zh": "æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°ï¼Œ363"
        }
    },
    {
        "translation": {
            "en": "In many cases, this limits the creation of an accurate prediction model.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™é™åˆ¶äº†å‡†ç¡®é¢„æµ‹æ¨¡å‹çš„åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "proxy features, 33, 36",
            "zh": "ä»£ç†åŠŸèƒ½ï¼Œ 33ï¼Œ 36"
        }
    },
    {
        "translation": {
            "en": "Just because the values of two features are correlated does not mean that an actual causal relationship exists between the two.",
            "zh": "ä»…ä»…å› ä¸ºä¸¤ä¸ªç‰¹å¾çš„å€¼æ˜¯ç›¸å…³çš„ï¼Œå¹¶ä¸æ„å‘³ç€ä¸¤è€…ä¹‹é—´å­˜åœ¨å®é™…çš„å› æœå…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "To address partition ğ’Ÿ7, first the algorithm computes the entropy of ğ’Ÿ7",
            "zh": "ä¸ºäº†è§£å†³åˆ†åŒº D7ï¼Œè¯¥ç®—æ³•é¦–å…ˆè®¡ç®— D7 çš„ç†µ"
        }
    },
    {
        "translation": {
            "en": "A standard data preprocessing practice for neural networks is to normalize the descriptive features.",
            "zh": "ç¥ç»ç½‘ç»œçš„æ ‡å‡†æ•°æ®é¢„å¤„ç†å®è·µæ˜¯å¯¹æè¿°æ€§ç‰¹å¾è¿›è¡Œè§„èŒƒåŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. Cumulative gain, lift, and cumulative lift are introduced in Section 9.4.3.3[565].",
            "zh": "10. ç´¯ç§¯å¢ç›Šã€å‡åŠ›å’Œç´¯ç§¯å‡åŠ›åœ¨ç¬¬ 9.4.3.3 èŠ‚[565] ä¸­ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "customer segmentation, 599",
            "zh": "å®¢æˆ·ç»†åˆ†ï¼Œ599"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for anti-clockwise spiral galaxy category",
            "zh": "é€†æ—¶é’ˆèºæ—‹æ˜Ÿç³»ç±»åˆ«çš„å¾—ç¥¨åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "8. This is much like the rank and prune approach to feature selection described in Section 5.4.6[223].",
            "zh": "8. è¿™å¾ˆåƒç¬¬ 5.4.6 èŠ‚[223] ä¸­æè¿°çš„ç‰¹å¾é€‰æ‹©çš„ç­‰çº§å’Œä¿®å‰ªæ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In much of this chapter we discuss matrix representations and calculations, so it is worth noting here that a linear function can always be represented by a single matrix multiplication and that an affine transformation in m dimensions can always be represented as a linear function in m + 1 dimensions (as we have done here) and consequently as a single matrix multiplication in m + 1 dimensions.",
            "zh": "åœ¨æœ¬ç« çš„å¤§éƒ¨åˆ†å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºçŸ©é˜µè¡¨ç¤ºå’Œè®¡ç®—ï¼Œå› æ­¤è¿™é‡Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œçº¿æ€§å‡½æ•°æ€»æ˜¯å¯ä»¥ç”¨å•ä¸ªçŸ©é˜µä¹˜æ³•æ¥è¡¨ç¤ºï¼Œå¹¶ä¸” m ç»´ä¸­çš„ä»¿å°„å˜æ¢æ€»æ˜¯å¯ä»¥è¡¨ç¤ºä¸º m + 1 ç»´çš„çº¿æ€§å‡½æ•°ï¼ˆæ­£å¦‚æˆ‘ä»¬åœ¨è¿™é‡Œæ‰€åšçš„é‚£æ ·ï¼‰ï¼Œå› æ­¤å¯ä»¥è¡¨ç¤ºä¸º m + 1 ç»´çš„å•ä¸ªçŸ©é˜µä¹˜æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What value would a weighted k-NN prediction model return for the CPI of Russia? Use k = 16 (i.e., the full dataset) and a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query.",
            "zh": "ï¼ˆbï¼‰ åŠ æƒk-NNé¢„æµ‹æ¨¡å‹å¯¹ä¿„ç½—æ–¯æ¶ˆè´¹ç‰©ä»·æŒ‡æ•°çš„å›æŠ¥æ˜¯å¤šå°‘ï¼Ÿä½¿ç”¨ k = 16ï¼ˆå³å®Œæ•´æ•°æ®é›†ï¼‰å’Œé‚»åŸŸå’ŒæŸ¥è¯¢ä¹‹é—´æ¬§å‡ é‡Œå¾—è·ç¦»å¹³æ–¹çš„å€’æ•°çš„åŠ æƒæ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 3.6.2[89] we explained two of the best known binning techniques, equal-width binning and equal-frequency binning, and discussed some of the general advantages and disadvantages of each technique.",
            "zh": "åœ¨ç¬¬ 3.6.2 èŠ‚[89]ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šäº†ä¸¤ç§æœ€è‘—åçš„åˆ†æ¡£æŠ€æœ¯ï¼Œç­‰å®½åˆ†æ¡£å’Œç­‰é¢‘åˆ†æ¡£ï¼Œå¹¶è®¨è®ºäº†æ¯ç§æŠ€æœ¯çš„ä¸€äº›ä¸€èˆ¬ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is achieved by multiplying the values in the confusion matrix by the corresponding values in the profit matrix and summing the results.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†æ··æ·†çŸ©é˜µä¸­çš„å€¼ä¹˜ä»¥åˆ©æ¶¦çŸ©é˜µä¸­çš„ç›¸åº”å€¼å¹¶å°†ç»“æœç›¸åŠ æ¥å®ç°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Not surprisingly, neurons that use the leaky rectified linear function as their activation function are known as Leaky ReLUs.",
            "zh": "æ¯«ä¸å¥‡æ€ªï¼Œä½¿ç”¨æ³„æ¼æ•´æµçº¿æ€§å‡½æ•°ä½œä¸ºå…¶æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒè¢«ç§°ä¸ºæ³„æ¼ ReLUã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarity-based approaches are particularly sensitive to the curse of dimensionality and can struggle to perform well for a dataset with large numbers of descriptive features.",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„æ–¹æ³•å¯¹ç»´åº¦çš„è¯…å’’ç‰¹åˆ«æ•æ„Ÿï¼Œå¹¶ä¸”å¯¹äºå…·æœ‰å¤§é‡æè¿°æ€§ç‰¹å¾çš„æ•°æ®é›†å¯èƒ½éš¾ä»¥è¡¨ç°è‰¯å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the dataset in Table 7.9[351] is based on an agricultural scenario and shows rainfall (in mm per day), RAIN, and resulting grass growth (in kilograms per acre per day), GROWTH, measured on a number of Irish farms during July 2012.",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨7.9[351]ä¸­çš„æ•°æ®é›†åŸºäºå†œä¸šæƒ…æ™¯ï¼Œæ˜¾ç¤ºäº†2012å¹´7æœˆåœ¨ä¸€äº›çˆ±å°”å…°å†œåœºæµ‹é‡çš„é™é›¨é‡ï¼ˆä»¥æ¯«ç±³/å¤©ä¸ºå•ä½ï¼‰ã€é™é›¨é‡å’Œç”±æ­¤äº§ç”Ÿçš„è‰ç”Ÿé•¿ï¼ˆä»¥åƒå…‹/è‹±äº©/å¤©ä¸ºå•ä½ï¼‰ã€ç”Ÿé•¿é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we have a categorical target feature, we may want to ensure that the sample has exactly the same distribution of the different levels of the target feature as the original dataset.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªåˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ç¡®ä¿æ ·æœ¬å…·æœ‰ä¸åŸå§‹æ•°æ®é›†å®Œå…¨ç›¸åŒçš„ç›®æ ‡ç‰¹å¾ä¸åŒçº§åˆ«çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In essence, most of statistics, and in turn, analytics, is about describing and understanding variation.",
            "zh": "ä»æœ¬è´¨ä¸Šè®²ï¼Œå¤§å¤šæ•°ç»Ÿè®¡å­¦ï¼Œä»¥åŠåˆ†æï¼Œéƒ½æ˜¯å…³äºæè¿°å’Œç†è§£å˜åŒ–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIM AMOUNT",
            "zh": "ç´¢èµ”é‡‘é¢"
        }
    },
    {
        "translation": {
            "en": "5. In fact, this is the error surface that results from the office rentals dataset when the descriptive features in the dataset are normalized to the range [âˆ’1, 1] using range normalization before being used. We discuss normalization subsequently in the chapter.",
            "zh": "5. å®é™…ä¸Šï¼Œè¿™æ˜¯å½“æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾åœ¨ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–ä¹‹å‰ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–åˆ°èŒƒå›´ [âˆ’1ï¼Œ 1] æ—¶äº§ç”Ÿçš„è¯¯å·®é¢ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„åé¢è®¨è®ºå½’ä¸€åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.30[478] shows some examples of the images from the dataset.",
            "zh": "å›¾ 8.30[478] æ˜¾ç¤ºäº†æ•°æ®é›†ä¸­å›¾åƒçš„ä¸€äº›ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the purposes of this explanation we assume that the weights are initialized to random values close to zero (e.g., by sampling from a normal distribution with mean Î¼ = 0.0 and Ïƒ = 0.1).",
            "zh": "å‡ºäºæœ¬è§£é‡Šçš„ç›®çš„ï¼Œæˆ‘ä»¬å‡è®¾æƒé‡åˆå§‹åŒ–ä¸ºæ¥è¿‘é›¶çš„éšæœºå€¼ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡ä»å‡å€¼ Î¼ = 0.0 ä¸” Ïƒ = 0.1 çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The leaky ReLU and parametric ReLU were developed to address this potential problem.",
            "zh": "æ³„æ¼ ReLU å’Œå‚æ•°åŒ– ReLU å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªæ½œåœ¨é—®é¢˜è€Œå¼€å‘çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The question sets at the end of each chapter have been revised and expandedâ€”this includes over 50 new questions.",
            "zh": "æ¯ç« æœ«å°¾çš„é¢˜é›†éƒ½ç»è¿‡äº†ä¿®è®¢å’Œæ‰©å±•ï¼Œå…¶ä¸­åŒ…æ‹¬ 50 å¤šä¸ªæ–°é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "He also applied the planned mapping of the REGIONTYPE values to a consistent labeling scheme: {s|suburb} suburb; {t|town} town; {missing|absent} missing.",
            "zh": "ä»–è¿˜å°† REGIONTYPE å€¼çš„è®¡åˆ’æ˜ å°„åº”ç”¨äºä¸€è‡´çš„æ ‡æ³¨æ–¹æ¡ˆï¼š{s|suburb} suburb;{t|town} é•‡;{missing|absent} ç¼ºå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "To perform an audit, a tax inspector visits a company and spends a number of days scrutinizing the companyâ€™s accounts.",
            "zh": "ä¸ºäº†è¿›è¡Œå®¡è®¡ï¼Œç¨åŠ¡æ£€æŸ¥å‘˜ä¼šè®¿é—®ä¸€å®¶å…¬å¸å¹¶èŠ±è´¹å‡ å¤©æ—¶é—´ä»”ç»†æ£€æŸ¥å…¬å¸çš„è´¦ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "J48, 169",
            "zh": "J48ã€169å‹"
        }
    },
    {
        "translation": {
            "en": "During learning, after completing an episode the agent will return to the initial state and start again.",
            "zh": "åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œå®Œæˆä¸€é›†åï¼Œæ™ºèƒ½ä½“å°†è¿”å›åˆå§‹çŠ¶æ€å¹¶é‡æ–°å¼€å§‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. This is not to be confused with the probability chain rule discussed in Section B.3[762]. These are two completely different operations.",
            "zh": "2. è¿™ä¸åº”ä¸B.3[762]èŠ‚ä¸­è®¨è®ºçš„æ¦‚ç‡é“¾è§„åˆ™ç›¸æ··æ·†ã€‚è¿™æ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "This differential in the weight updates is apparent in Table 8.6[431], which is arranged so that âˆ‚â„°/âˆ‚wi,k terms for the weights on inputs to output layer (Neuron 8) are at the top of the table, and then as we move down the table, we move back through the network.",
            "zh": "æƒé‡æ›´æ–°çš„è¿™ç§å·®å¼‚åœ¨è¡¨ 8.6[431] ä¸­å¾ˆæ˜æ˜¾ï¼Œè¡¨çš„æ’åˆ—æ–¹å¼æ˜¯ï¼Œè¾“å…¥åˆ°è¾“å‡ºå±‚ ï¼ˆNeuron 8ï¼‰ çš„æƒé‡çš„ âˆ‚E/âˆ‚wiï¼Œk é¡¹ä½äºè¡¨çš„é¡¶éƒ¨ï¼Œç„¶åå½“æˆ‘ä»¬å‘ä¸‹ç§»åŠ¨è¡¨æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡ç½‘ç»œå‘åç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model is being used by the marketing department to determine who should be given the free gift.",
            "zh": "è¥é”€éƒ¨é—¨æ­£åœ¨ä½¿ç”¨æ­¤æ¨¡å‹æ¥ç¡®å®šè°åº”è¯¥è·å¾—å…è´¹ç¤¼ç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictions are made for a query instance using the target level of the training instance defining the neighborhood in the feature space that contains the query.",
            "zh": "ä½¿ç”¨è®­ç»ƒå®ä¾‹çš„ç›®æ ‡çº§åˆ«å¯¹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œè¯¥ç›®æ ‡çº§åˆ«åœ¨åŒ…å«æŸ¥è¯¢çš„ç‰¹å¾ç©ºé—´ä¸­å®šä¹‰é‚»åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Clearly, the probability of a patient who has a headache and a fever having meningitis should be greater than zero.",
            "zh": "æ˜¾ç„¶ï¼Œå¤´ç—›å’Œå‘çƒ§çš„æ‚£è€…æ‚£è„‘è†œç‚çš„æ¦‚ç‡åº”è¯¥å¤§äºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.064314",
            "zh": "0.064314"
        }
    },
    {
        "translation": {
            "en": "We often reduce this categorization to just two data types: continuous (encompassing the numeric and interval types), and categorical (encompassing the categorical, ordinal, binary, and textual types).",
            "zh": "æˆ‘ä»¬é€šå¸¸å°†æ­¤åˆ†ç±»ç®€åŒ–ä¸ºä¸¤ç§æ•°æ®ç±»å‹ï¼šè¿ç»­ï¼ˆåŒ…æ‹¬æ•°å€¼å’ŒåŒºé—´ç±»å‹ï¼‰å’Œåˆ†ç±»ï¼ˆåŒ…æ‹¬åˆ†ç±»ã€åºæ•°ã€äºŒè¿›åˆ¶å’Œæ–‡æœ¬ç±»å‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most direct way of mitigating against the impact of noise in the dataset on a nearest neighbor algorithm is to dilute the dependency of the algorithm on individual (possibly noisy) instances.",
            "zh": "å‡è½»æ•°æ®é›†ä¸­çš„å™ªå£°å¯¹æœ€è¿‘é‚»ç®—æ³•çš„å½±å“çš„æœ€ç›´æ¥æ–¹æ³•æ˜¯ç¨€é‡Šç®—æ³•å¯¹å•ä¸ªï¼ˆå¯èƒ½æ˜¯å™ªå£°ï¼‰å®ä¾‹çš„ä¾èµ–æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are merged into a new cluster, 13, as shown in Figure 10.12(d)[621].",
            "zh": "å®ƒä»¬è¢«åˆå¹¶åˆ°ä¸€ä¸ªæ–°çš„é›†ç¾¤13ä¸­ï¼Œå¦‚å›¾10.12ï¼ˆdï¼‰[621]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Proportion",
            "zh": "æ¯”ä¾‹"
        }
    },
    {
        "translation": {
            "en": "Figure 4.12",
            "zh": "å›¾ 4.12"
        }
    },
    {
        "translation": {
            "en": "In this case, however, the number of inputs to the weighted sum calculation within a neuron during the backpropagation process is the number of neurons that the neuron propagated its activation to during the forward pass (see Equation 8.22[412]).",
            "zh": "ç„¶è€Œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œç¥ç»å…ƒå†…åŠ æƒå’Œè®¡ç®—çš„è¾“å…¥æ•°æ˜¯ç¥ç»å…ƒåœ¨å‰å‘ä¼ é€’æœŸé—´å°†å…¶æ¿€æ´»ä¼ æ’­åˆ°çš„ç¥ç»å…ƒæ•°ï¼ˆå‚è§ç­‰å¼ 8.22[412]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2017. Mastering the game of go without human knowledge. Nature 550 (7676): 354.",
            "zh": "è¥¿å°”å¼—ã€å¤§å«ã€é»„é›…ã€å…‹é‡Œæ–¯Â·éº¦è¿ªé€Šã€äºšç‘ŸÂ·ç›–å…¹ã€æ´›æœ—Â·è¥¿å¼—å°”ã€ä¹”æ²»Â·èŒƒç™»å¾·é‡Œä»€ã€æœ±åˆ©å®‰Â·æ–½é‡Œç‰¹ç»´ç‘Ÿã€æ‰¬å°¼æ–¯Â·å®‰ä¸œè¯ºæ ¼é²ã€éŸ¦è¾¾ç»´äºšæ–¯Â·æ½˜å†…å°”èˆå°”ç“¦å§†ã€é©¬å…‹Â·å…°å…‹æ‰˜ã€æ¡‘å¾·Â·è¿ªå‹’æ›¼ã€å¤šç±³å°¼å…‹Â·æ ¼é›·ã€çº¦ç¿°Â·çº³å§†ã€çº³å°”Â·å¡å°”å¥‡å¸ƒä¼¦çº³ã€ä¼Šåˆ©äºšÂ·è¨èŒ¨å…‹å¼—ã€è’‚è«è¥¿Â·åˆ©åˆ©å…‹æ‹‰æ™®ã€ç›å¾·ç³Â·åˆ©å¥‡ã€ç§‘é›·Â·å¡æ­¦å…‹åº“æ ¼é²ã€ç´¢å°”Â·æ ¼é›·ä½©å°”å’Œå¾·ç±³æ–¯Â·å“ˆè¨æ¯”æ–¯ã€‚2017. åœ¨äººç±»ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹æŒæ¡å›´æ£‹æ¸¸æˆã€‚è‡ªç„¶550ï¼ˆ7676ï¼‰ï¼š354ã€‚"
        }
    },
    {
        "translation": {
            "en": "single linkage: the distance between the most similar instances in two clusters is used as the overall distance between the clusters;",
            "zh": "å•è”åŠ¨ï¼šä»¥ä¸¤ä¸ªé›†ç¾¤ä¸­æœ€ç›¸ä¼¼çš„å®ä¾‹ä¹‹é—´çš„è·ç¦»ä½œä¸ºé›†ç¾¤ä¹‹é—´çš„æ€»è·ç¦»;"
        }
    },
    {
        "translation": {
            "en": "3. The dataset is empty. This can occur when, for a particular partition of the dataset, there are no instances that have a particular feature value. In this case we return a single leaf node tree with the majority target level of the dataset at the parent node that made the recursive call (Algorithm 1[134] Lines 5â€“6).",
            "zh": "3. æ•°æ®é›†ä¸ºç©ºã€‚å½“æ•°æ®é›†çš„ç‰¹å®šåˆ†åŒºæ²¡æœ‰å…·æœ‰ç‰¹å®šç‰¹å¾å€¼çš„å®ä¾‹æ—¶ï¼Œå¯èƒ½ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªå•å¶èŠ‚ç‚¹æ ‘ï¼Œå…¶æ•°æ®é›†çš„å¤§å¤šæ•°ç›®æ ‡çº§åˆ«ä½äºè¿›è¡Œé€’å½’è°ƒç”¨çš„çˆ¶èŠ‚ç‚¹ï¼ˆç®—æ³• 1[134]ï¼Œç¬¬ 5-6 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "constrained quadratic optimization problem, 363",
            "zh": "çº¦æŸäºŒæ¬¡ä¼˜åŒ–é—®é¢˜ï¼Œ 363"
        }
    },
    {
        "translation": {
            "en": "Table 12.1",
            "zh": "è¡¨ 12.1"
        }
    },
    {
        "translation": {
            "en": "In writing this book our target was to deliver an accessible, introductory text on the fundamentals of machine learning and the ways that machine learning is used in practice to solve predictive data analytics problems in business, science, and other organizational contexts. As such, the book goes beyond the standard topics covered in machine learning books and also covers the lifecycle of a predictive analytics project, data preparation, feature design, and model deployment.",
            "zh": "åœ¨æ’°å†™æœ¬ä¹¦æ—¶ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æä¾›ä¸€ä»½æ˜“äºç†è§£çš„ä»‹ç»æ€§æ–‡æœ¬ï¼Œä»‹ç»æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åŠæœºå™¨å­¦ä¹ åœ¨å®è·µä¸­ç”¨äºè§£å†³å•†ä¸šã€ç§‘å­¦å’Œå…¶ä»–ç»„ç»‡ç¯å¢ƒä¸­çš„é¢„æµ‹æ€§æ•°æ®åˆ†æé—®é¢˜çš„æ–¹å¼ã€‚å› æ­¤ï¼Œæœ¬ä¹¦è¶…è¶Šäº†æœºå™¨å­¦ä¹ ä¹¦ç±ä¸­æ¶µç›–çš„æ ‡å‡†ä¸»é¢˜ï¼Œè¿˜æ¶µç›–äº†é¢„æµ‹åˆ†æé¡¹ç›®çš„ç”Ÿå‘½å‘¨æœŸã€æ•°æ®å‡†å¤‡ã€åŠŸèƒ½è®¾è®¡å’Œæ¨¡å‹éƒ¨ç½²ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ideas of reinforcement learning and Markov decision processes stem from early work by Howard (1960) and Bellman (1957a,b). One fascinating early example is by Michie (1961, 1963) who built an automated tic-tac-toe player based on ideas of reinforcement learning. Due to a lack of access to computing resources, however, this was built using over two hundred matchboxes filled with colored marbles rather than in software!",
            "zh": "å¼ºåŒ–å­¦ä¹ å’Œé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„æ€æƒ³æºäºHowardï¼ˆ1960ï¼‰å’ŒBellmanï¼ˆ1957aï¼Œbï¼‰çš„æ—©æœŸå·¥ä½œã€‚Michieï¼ˆ1961,1963ï¼‰å°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ—©æœŸä¾‹å­ï¼Œä»–åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ€æƒ³æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–äº•å­—æ¸¸æˆæœºã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¯¹è®¡ç®—èµ„æºçš„è®¿é—®ï¼Œè¿™æ˜¯ä½¿ç”¨ä¸¤ç™¾å¤šä¸ªè£…æ»¡å½©è‰²å¼¹ç çš„ç«æŸ´ç›’è€Œä¸æ˜¯è½¯ä»¶æ„å»ºçš„ï¼"
        }
    },
    {
        "translation": {
            "en": "one-row-per-subject, 29",
            "zh": "æ¯ä¸ªä¸»é¢˜ä¸€è¡Œï¼Œ29"
        }
    },
    {
        "translation": {
            "en": "confounding feature, 85",
            "zh": "æ··æ‚ç‰¹å¾ï¼Œ85"
        }
    },
    {
        "translation": {
            "en": "This is useful because often in real-life applications it can be difficult to capture these values.",
            "zh": "è¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºåœ¨å®é™…åº”ç”¨ä¸­é€šå¸¸å¾ˆéš¾æ•è·è¿™äº›å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(short)â€ plan is also an ideal course plan for a short (one-week) professional training course.",
            "zh": "ï¼ˆshortï¼‰â€œè®¡åˆ’ä¹Ÿæ˜¯çŸ­æœŸï¼ˆä¸€å‘¨ï¼‰ä¸“ä¸šåŸ¹è®­è¯¾ç¨‹çš„ç†æƒ³è¯¾ç¨‹è®¡åˆ’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of the SDSS and Galaxy Zoo combined dataset.",
            "zh": "SDSSå’ŒGalaxy Zooç»„åˆæ•°æ®é›†çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The value of taking the action in the state should decrease if the reward and/or future return are negative.",
            "zh": "å¦‚æœå¥–åŠ±å’Œ/æˆ–æœªæ¥å›æŠ¥ä¸ºè´Ÿæ•°ï¼Œåˆ™åœ¨çŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„ä»·å€¼åº”è¯¥é™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The strong black line across the middle of the rectangle shows the median.",
            "zh": "æ¨ªè·¨çŸ©å½¢ä¸­é—´çš„å¼ºé»‘çº¿è¡¨ç¤ºä¸­ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.109128",
            "zh": "0.109128"
        }
    },
    {
        "translation": {
            "en": "where is a dataset with a target feature t; levels(t) is the set of levels in the domain of the target feature; and P(t = l) is the probability of an instance of having the target level l. The Gini index can be understood as calculating how often the target levels of instances in a dataset would be misclassified if predictions were made on the sole basis of the distribution of the target levels in the dataset.",
            "zh": "å…¶ä¸­ æ˜¯å…·æœ‰ç›®æ ‡ç‰¹å¾ t çš„æ•°æ®é›†;levelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡è¦ç´ åŸŸä¸­çš„ä¸€ç»„çº§åˆ«;Pï¼ˆt = lï¼‰ æ˜¯å…·æœ‰ç›®æ ‡æ°´å¹³ l çš„å®ä¾‹çš„æ¦‚ç‡ã€‚åŸºå°¼ç³»æ•°å¯ä»¥ç†è§£ä¸ºè®¡ç®—å¦‚æœä»…æ ¹æ®æ•°æ®é›†ä¸­ç›®æ ‡æ°´å¹³çš„åˆ†å¸ƒè¿›è¡Œé¢„æµ‹ï¼Œåˆ™æ•°æ®é›†ä¸­å®ä¾‹çš„ç›®æ ‡æ°´å¹³è¢«é”™è¯¯åˆ†ç±»çš„é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "that tells the agent which action, at, to take when in a given state, st. We can also define a policy in probabilistic terms",
            "zh": "è¿™å‘Šè¯‰ä»£ç†åœ¨ç»™å®šçŠ¶æ€ä¸‹é‡‡å–å“ªä¸ªæ“ä½œï¼ŒSTã€‚æˆ‘ä»¬è¿˜å¯ä»¥ç”¨æ¦‚ç‡æœ¯è¯­æ¥å®šä¹‰ç­–ç•¥"
        }
    },
    {
        "translation": {
            "en": "Portions of the ABT for the motor insurance claims fraud detection problem discussed in Section 2.4.6[42].",
            "zh": "ABTä¸­å…³äºæ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹é—®é¢˜çš„éƒ¨åˆ†å†…å®¹ï¼Œåœ¨ç¬¬2.4.6èŠ‚[42]ä¸­è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "cosine similarity, 216, 223, 231, 237",
            "zh": "ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œ 216ï¼Œ 223ï¼Œ 231ï¼Œ 237"
        }
    },
    {
        "translation": {
            "en": "Manhattan distance, 185, 185, 231, 237, 577",
            "zh": "æ›¼å“ˆé¡¿è·ç¦»ï¼Œ 185ï¼Œ 185ï¼Œ 231ï¼Œ 237ï¼Œ 577"
        }
    },
    {
        "translation": {
            "en": "8.6â€ƒFurther Reading",
            "zh": "8.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "D.4â€…â€…â€…Summary",
            "zh": "D.4 æ¦‚è¿°"
        }
    },
    {
        "translation": {
            "en": "We can calculate the Gini index for the dataset in Table 4.3[136]",
            "zh": "æˆ‘ä»¬å¯ä»¥è®¡ç®—è¡¨4.3[136]ä¸­æ•°æ®é›†çš„åŸºå°¼ç³»æ•°"
        }
    },
    {
        "translation": {
            "en": "9.12â€…â€…â€…Confusion matrices for the set of predictions shown in Table 9.11[557] using (a) a prediction score threshold of 0.75 and (b) a prediction score threshold of 0.25.",
            "zh": "9.12 è¡¨9.11[557]æ‰€ç¤ºçš„ä¸€ç»„é¢„æµ‹çš„æ··æ·†çŸ©é˜µï¼Œä½¿ç”¨ï¼ˆaï¼‰é¢„æµ‹å¾—åˆ†é˜ˆå€¼ä¸º0.75ï¼Œï¼ˆbï¼‰é¢„æµ‹å¾—åˆ†é˜ˆå€¼ä¸º0.25ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can get an insight into how we should use this term to update weights by considering the case of a weight wi,k between an output neuron i that uses a logistic activation function and a hidden neuron k. If the output of the neuron i is too high (ai > ti), then Î´i will be positive because it will be the product of two positive terms:",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡è€ƒè™‘ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°çš„è¾“å‡ºç¥ç»å…ƒ i å’Œéšè—ç¥ç»å…ƒ k ä¹‹é—´çš„æƒé‡ wiï¼Œk çš„æƒ…å†µæ¥æ·±å…¥äº†è§£æˆ‘ä»¬åº”è¯¥å¦‚ä½•ä½¿ç”¨è¿™ä¸ªæœ¯è¯­æ¥æ›´æ–°æƒé‡ã€‚å¦‚æœç¥ç»å…ƒ i çš„è¾“å‡ºå¤ªé«˜ ï¼ˆai > tiï¼‰ï¼Œé‚£ä¹ˆ Î´i å°†æ˜¯æ­£çš„ï¼Œå› ä¸ºå®ƒå°†æ˜¯ä¸¤ä¸ªæ­£é¡¹çš„ä¹˜ç§¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, we noted previously that in a fully connected feedforward network, if we set var(W(k)) = 1/nin(k), then the variance of the z values in layer k is dependent solely on the variance of the inputs to that layer; and if the inputs are standardized, then the variance of the z values will not be scaled for that layer.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¹‹å‰æåˆ°ï¼Œåœ¨å…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œä¸­ï¼Œå¦‚æœæˆ‘ä»¬è®¾ç½® varï¼ˆWï¼ˆkï¼‰ï¼‰ = 1/ninï¼ˆkï¼‰ï¼Œåˆ™ç¬¬ k å±‚ä¸­ z å€¼çš„æ–¹å·®ä»…å–å†³äºè¯¥å±‚è¾“å…¥çš„æ–¹å·®;å¦‚æœè¾“å…¥æ˜¯æ ‡å‡†åŒ–çš„ï¼Œåˆ™ä¸ä¼šç¼©æ”¾è¯¥å±‚çš„ z å€¼æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.9",
            "zh": "è¡¨ 6.9"
        }
    },
    {
        "translation": {
            "en": "Neural networks",
            "zh": "ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "The variant of the decision tree algorithm that should be used for a particular problem depends on the nature of the problem and the dataset being used.",
            "zh": "åº”ç”¨äºç‰¹å®šé—®é¢˜çš„å†³ç­–æ ‘ç®—æ³•çš„å˜ä½“å–å†³äºé—®é¢˜çš„æ€§è´¨å’Œæ‰€ä½¿ç”¨çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is no outcome period, as the target feature is determined by whether the company is able to entice the customer to reconsider and, if so, the incentive that was required to do this.",
            "zh": "æ²¡æœ‰ç»“æœæœŸï¼Œå› ä¸ºç›®æ ‡åŠŸèƒ½å–å†³äºå…¬å¸æ˜¯å¦èƒ½å¤Ÿå¸å¼•å®¢æˆ·é‡æ–°è€ƒè™‘ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å–å†³äºè¿™æ ·åšæ‰€éœ€çš„æ¿€åŠ±æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The function f(x) = (x2 + 1)2 (shown in Figure C.2(d)[767]) cannot be differentiated using the rules just described because it is a composite functionâ€”it is a function of a function. We can rewrite f(x) as f(x) = (g(x))2 where g(x) = x2 + 1. The differentiation chain rule allows us to differentiate functions of this kind.2 The chain rule is",
            "zh": "å‡½æ•° fï¼ˆxï¼‰ = ï¼ˆx2 + 1ï¼‰2ï¼ˆå¦‚å›¾ C.2ï¼ˆdï¼‰[767] æ‰€ç¤ºï¼‰ä¸èƒ½ç”¨åˆšæ‰æè¿°çš„è§„åˆ™æ¥åŒºåˆ†ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¤åˆå‡½æ•°â€”â€”å®ƒæ˜¯å‡½æ•°çš„å‡½æ•°ã€‚æˆ‘ä»¬å¯ä»¥å°† fï¼ˆxï¼‰ æ”¹å†™ä¸º fï¼ˆxï¼‰ = ï¼ˆgï¼ˆxï¼‰ï¼‰2ï¼Œå…¶ä¸­ gï¼ˆxï¼‰ = x2 + 1ã€‚å¾®åˆ†é“¾æ³•åˆ™å…è®¸æˆ‘ä»¬åŒºåˆ†è¿™ç§å‡½æ•°.2 é“¾æ³•åˆ™æ˜¯"
        }
    },
    {
        "translation": {
            "en": "20. Available from the UCI repository at https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant.",
            "zh": "20. å¯ä» UCI å­˜å‚¨åº“ https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A generalized illustration of the Manhattan and Euclidean distances between two points; and (b) a plot of the Manhattan and Euclidean distances between instances d12 and d5, and between d12 and d17 from Table 5.2[183].",
            "zh": "ï¼ˆaï¼‰ ä¸¤ç‚¹ä¹‹é—´æ›¼å“ˆé¡¿è·ç¦»å’Œæ¬§å‡ é‡Œå¾—è·ç¦»çš„æ¦‚æ‹¬å›¾ç¤º;ï¼ˆbï¼‰è¡¨5.2[183]ä¸­å®ä¾‹d12å’Œd5ä¹‹é—´ä»¥åŠd12å’Œd17ä¹‹é—´çš„æ›¼å“ˆé¡¿å’Œæ¬§å‡ é‡Œå¾—è·ç¦»å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Continuous features will usually have a cardinality value close to the number of instances in the dataset.",
            "zh": "è¿ç»­è¦ç´ çš„åŸºæ•°å€¼é€šå¸¸æ¥è¿‘æ•°æ®é›†ä¸­çš„å®ä¾‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.11",
            "zh": "1.11"
        }
    },
    {
        "translation": {
            "en": "An alternative strategy for using neural networks for regression is to use linear units in the output layer (i.e., units that do not use an activation function and simply output the weighted sum z as their activation).",
            "zh": "ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå›å½’çš„å¦ä¸€ç§ç­–ç•¥æ˜¯åœ¨è¾“å‡ºå±‚ä¸­ä½¿ç”¨çº¿æ€§å•å…ƒï¼ˆå³ï¼Œä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°å¹¶ç®€å•åœ°è¾“å‡ºåŠ æƒæ€»å’Œ z ä½œä¸ºå…¶æ¿€æ´»çš„å•å…ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A multivariate logistic regression model has been built to diagnose breast cancer in patients on the basis of features extracted from tissue samples extracted by biopsy.27 The model uses three descriptive featuresâ€”MITOSES, a measure of how fast cells are growing; CLUMPTHICKNESS, a measure of the amount of layering in cells; and BLANDCHROMATIN, a measure of the texture of cell nucleiâ€”and predicts the status of a biopsy as either benign or malignant.",
            "zh": "å·²ç»å»ºç«‹äº†ä¸€ä¸ªå¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹ï¼Œæ ¹æ®ä»æ´»æ£€æå–çš„ç»„ç»‡æ ·æœ¬ä¸­æå–çš„ç‰¹å¾æ¥è¯Šæ–­æ‚£è€…çš„ä¹³è…ºç™Œ.27 è¯¥æ¨¡å‹ä½¿ç”¨ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾â€”â€”æœ‰ä¸åˆ†è£‚ï¼Œè¡¡é‡ç»†èƒç”Ÿé•¿é€Ÿåº¦çš„æŒ‡æ ‡;CLUMPTHICKNESSï¼Œç»†èƒä¸­åˆ†å±‚é‡çš„é‡åº¦;å’ŒBLANDCHROMATINï¼Œä¸€ç§è¡¡é‡ç»†èƒæ ¸è´¨åœ°çš„æŒ‡æ ‡ï¼Œå¹¶é¢„æµ‹æ´»æ£€çš„çŠ¶æ€æ˜¯è‰¯æ€§è¿˜æ˜¯æ¶æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The density of a unit hypercube is equal to",
            "zh": "å•ä½è¶…ç«‹æ–¹ä½“çš„å¯†åº¦ç­‰äº"
        }
    },
    {
        "translation": {
            "en": "location parameter, 271",
            "zh": "ä½ç½®å‚æ•°ï¼Œ271"
        }
    },
    {
        "translation": {
            "en": "We use the convention that the first element in a probability distribution vector is the probability for a true value. For example, the probability distribution for a binary feature, A, with a probability of 0.4 of being true would be written P(A) = < 0.4, 0.6 >.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨æ¦‚ç‡åˆ†å¸ƒå‘é‡ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯çœŸå€¼çš„æ¦‚ç‡çš„çº¦å®šã€‚ä¾‹å¦‚ï¼ŒäºŒå…ƒç‰¹å¾ A çš„æ¦‚ç‡åˆ†å¸ƒä¸º 0.4 ä¸ºçœŸï¼Œå†™æˆ Pï¼ˆAï¼‰ = < 0.4ï¼Œ 0.6 >ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4.2â€ƒHandling Continuous Descriptive Features",
            "zh": "4.4.2 å¤„ç†è¿ç»­æè¿°æ€§ç‰¹å¾"
        }
    },
    {
        "translation": {
            "en": "However, in order to use batch gradient descent, we must update Equation (8.28)[415] to accommodate updating a weight using the sum of the error gradients.",
            "zh": "ä½†æ˜¯ï¼Œä¸ºäº†ä½¿ç”¨æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œæˆ‘ä»¬å¿…é¡»æ›´æ–°æ–¹ç¨‹ï¼ˆ8.28ï¼‰[415]ï¼Œä»¥é€‚åº”ä½¿ç”¨è¯¯å·®æ¢¯åº¦ä¹‹å’Œæ›´æ–°æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The raw imaging data captured from the SDSS telescopes is passed through a processing pipeline that identifies individual night sky objects and extracts a number of properties for each object.",
            "zh": "ä»SDSSæœ›è¿œé•œæ•è·çš„åŸå§‹æˆåƒæ•°æ®é€šè¿‡å¤„ç†ç®¡é“ä¼ é€’ï¼Œè¯¥å¤„ç†ç®¡é“å¯è¯†åˆ«å•ä¸ªå¤œç©ºç‰©ä½“å¹¶æå–æ¯ä¸ªç‰©ä½“çš„è®¸å¤šå±æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.17",
            "zh": "è¡¨ 6.17"
        }
    },
    {
        "translation": {
            "en": "The most basic of these measures are true positive rate (TPR), true negative rate (TNR), false negative rate (FNR), and false positive rate (FPR), which convert the raw numbers from the confusion matrix into percentages.5 These measures are defined as follows:",
            "zh": "è¿™äº›æªæ–½ä¸­æœ€åŸºæœ¬çš„æ˜¯çœŸé˜³æ€§ç‡ ï¼ˆTPRï¼‰ã€çœŸé˜´æ€§ç‡ ï¼ˆTNRï¼‰ã€å‡é˜´æ€§ç‡ ï¼ˆFNRï¼‰ å’Œå‡é˜³æ€§ç‡ ï¼ˆFPRï¼‰ï¼Œå®ƒä»¬å°†æ··æ·†çŸ©é˜µä¸­çš„åŸå§‹æ•°å­—è½¬æ¢ä¸ºç™¾åˆ†æ¯”ã€‚5 è¿™äº›æªæ–½å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The manner in which these data resources should be combined must be designed and implemented by the analytics practitioner in collaboration with domain experts.",
            "zh": "è¿™äº›æ•°æ®èµ„æºçš„ç»„åˆæ–¹å¼å¿…é¡»ç”±åˆ†æä»ä¸šè€…ä¸é¢†åŸŸä¸“å®¶åˆä½œè®¾è®¡å’Œå®æ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm then keeps iteratively applying the weight update rule until it converges on a stable set of weights beyond which little improvement in model accuracy is possible.",
            "zh": "ç„¶åï¼Œè¯¥ç®—æ³•ä¸æ–­è¿­ä»£åº”ç”¨æƒé‡æ›´æ–°è§„åˆ™ï¼Œç›´åˆ°å®ƒæ”¶æ•›åˆ°ä¸€ç»„ç¨³å®šçš„æƒé‡ä¸Šï¼Œè¶…è¿‡è¯¥æƒé‡åï¼Œæ¨¡å‹ç²¾åº¦çš„æ”¹è¿›å‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case we would calculate an error (or loss) only at the output at the end of the sequence.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªä¼šåœ¨åºåˆ—æœ«å°¾çš„è¾“å‡ºå¤„è®¡ç®—è¯¯å·®ï¼ˆæˆ–æŸå¤±ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "25. This action selection is required here to seed the first iteration of the loop beginning on Line 14[666].",
            "zh": "25. è¿™é‡Œéœ€è¦è¿™ä¸ªåŠ¨ä½œé€‰æ‹©æ¥ä¸ºä»ç¬¬ 14 è¡Œå¼€å§‹çš„å¾ªç¯çš„ç¬¬ä¸€æ¬¡è¿­ä»£è®¾å®šç§å­[666]ã€‚"
        }
    },
    {
        "translation": {
            "en": "where x is any value, and Î¼ and Ïƒ are parameters that define the shape of the distribution. Given a probability density function, we can plot the density curve associated with a distribution, which gives us a different way to visualize standard distributions like the normal. Figure 3.3[62] shows the density curves for a number of different normal distributions. The higher the curve for a particular value on the horizontal axis, the more likely that value is.",
            "zh": "å…¶ä¸­ x æ˜¯ä»»ä½•å€¼ï¼ŒÎ¼ å’Œ Ïƒ æ˜¯å®šä¹‰åˆ†å¸ƒå½¢çŠ¶çš„å‚æ•°ã€‚ç»™å®šä¸€ä¸ªæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ä¸åˆ†å¸ƒç›¸å…³çš„å¯†åº¦æ›²çº¿ï¼Œè¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§ä¸åŒçš„æ–¹æ³•æ¥å¯è§†åŒ–æ ‡å‡†åˆ†å¸ƒï¼Œå¦‚æ­£æ€åˆ†å¸ƒã€‚å›¾3.3[62]æ˜¾ç¤ºäº†è®¸å¤šä¸åŒæ­£æ€åˆ†å¸ƒçš„å¯†åº¦æ›²çº¿ã€‚æ°´å¹³è½´ä¸Šç‰¹å®šå€¼çš„æ›²çº¿è¶Šé«˜ï¼Œè¯¥å€¼çš„å¯èƒ½æ€§å°±è¶Šå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the error on the validation starts to increase, then we should stop training.",
            "zh": "å¦‚æœéªŒè¯é”™è¯¯å¼€å§‹å¢åŠ ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥åœæ­¢è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed, outline the type of data that would be required.",
            "zh": "ï¼ˆbï¼‰ å¯¹äºæ‚¨æå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°æ‰€éœ€çš„æ•°æ®ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "feedforward network, 389",
            "zh": "å‰é¦ˆç½‘ç»œï¼Œ389"
        }
    },
    {
        "translation": {
            "en": "Box plots are also better suited when the categorical feature has many levelsâ€”beyond four levels, small multiple histograms tend to be difficult to interpret.",
            "zh": "å½“åˆ†ç±»ç‰¹å¾å…·æœ‰å¤šä¸ªçº§åˆ«æ—¶ï¼Œç®±å½¢å›¾ä¹Ÿæ›´é€‚åˆ - è¶…è¿‡å››ä¸ªçº§åˆ«ï¼Œè¾ƒå°çš„å¤šä¸ªç›´æ–¹å›¾å¾€å¾€éš¾ä»¥è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Svolba, Gerhard. 2012. Data quality for analytics using SAS. SAS Institute.",
            "zh": "æ–¯æ²ƒå°”å·´ï¼Œæ ¼å“ˆå¾·ã€‚2012. ä½¿ç”¨ SAS è¿›è¡Œåˆ†æçš„æ•°æ®è´¨é‡ã€‚SASç ”ç©¶æ‰€ã€‚"
        }
    },
    {
        "translation": {
            "en": "A duck-billed platypus. This platypus image was created by Jan Gillbank, English for the Australian Curriculum website (www.e4ac.edu.au). Used under Creative Commons Attribution 3.0 license.",
            "zh": "é¸­å˜´å…½ã€‚è¿™å¼ é¸­å˜´å…½å›¾ç‰‡ç”±Jan Gillbankä¸ºæ¾³å¤§åˆ©äºšè¯¾ç¨‹ç½‘ç«™ï¼ˆwww.e4ac.edu.auï¼‰åˆ›å»ºã€‚åœ¨çŸ¥è¯†å…±äº«ç½²å 3.0 è®¸å¯ä¸‹ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, CPI = high is the MAP CPI value for this query, and this is the prediction the model will return.",
            "zh": "å› æ­¤ï¼ŒCPI = high æ˜¯æ­¤æŸ¥è¯¢çš„ MAP CPI å€¼ï¼Œè¿™æ˜¯æ¨¡å‹å°†è¿”å›çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Considering that all the immediate neighbors of this instance are associated with the yes target level, it is likely that either this instance has been incorrectly labeled and should have a target feature value of yes, or one of the descriptive features for this instance has an incorrect value and hence it is in the wrong location in the feature space.",
            "zh": "è€ƒè™‘åˆ°æ­¤å®ä¾‹çš„æ‰€æœ‰ç›´æ¥é‚»å±…éƒ½ä¸ yes ç›®æ ‡çº§åˆ«ç›¸å…³è”ï¼Œå¾ˆå¯èƒ½æ˜¯æ­¤å®ä¾‹è¢«é”™è¯¯æ ‡è®°ï¼Œç›®æ ‡è¦ç´ å€¼åº”ä¸º yesï¼Œæˆ–è€…æ­¤å®ä¾‹çš„æŸä¸ªæè¿°æ€§è¦ç´ çš„å€¼ä¸æ­£ç¡®ï¼Œå› æ­¤å®ƒåœ¨è¦ç´ ç©ºé—´ä¸­çš„ä½ç½®é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Correlation is a good measure of the relationship between two continuous features, but it is not by any means perfect.",
            "zh": "ç›¸å…³æ€§æ˜¯ä¸¤ä¸ªè¿ç»­ç‰¹å¾ä¹‹é—´å…³ç³»çš„ä¸€ä¸ªå¾ˆå¥½çš„åº¦é‡ï¼Œä½†å®ƒç»ä¸æ˜¯å®Œç¾çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for churn models, customers will either churn or not churn; for credit scoring models, customers will either repay their loans or not; and for models predicting athlete performance, athletes will either match expectations or not.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºæµå¤±æ¨¡å‹ï¼Œå®¢æˆ·è¦ä¹ˆæµå¤±ï¼Œè¦ä¹ˆä¸æµå¤±;å¯¹äºä¿¡ç”¨è¯„åˆ†æ¨¡å‹ï¼Œå®¢æˆ·è¦ä¹ˆå¿è¿˜è´·æ¬¾ï¼Œè¦ä¹ˆä¸å¿è¿˜è´·æ¬¾;å¯¹äºé¢„æµ‹è¿åŠ¨å‘˜è¡¨ç°çš„æ¨¡å‹ï¼Œè¿åŠ¨å‘˜è¦ä¹ˆç¬¦åˆé¢„æœŸï¼Œè¦ä¹ˆä¸ç¬¦åˆé¢„æœŸã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, it is the introduction of a non-linearity into the input to output mapping defined by a neuron that enables an artificial neural network to learn complex non-linear mappings; indeed, it is this ability to learn these complex non-linear mappings that makes artificial neural networks such powerful models, in terms of their ability to be accurate on complex tasks.",
            "zh": "äº‹å®ä¸Šï¼Œæ­£æ˜¯åœ¨ç¥ç»å…ƒå®šä¹‰çš„è¾“å…¥åˆ°è¾“å‡ºæ˜ å°„ä¸­å¼•å…¥äº†éçº¿æ€§ï¼Œä½¿äººå·¥ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„éçº¿æ€§æ˜ å°„;äº‹å®ä¸Šï¼Œæ­£æ˜¯è¿™ç§å­¦ä¹ è¿™äº›å¤æ‚çš„éçº¿æ€§æ˜ å°„çš„èƒ½åŠ›ä½¿äººå·¥ç¥ç»ç½‘ç»œæˆä¸ºå¦‚æ­¤å¼ºå¤§çš„æ¨¡å‹ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿåœ¨å¤æ‚çš„ä»»åŠ¡ä¸Šä¿æŒå‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the posterior probability of LOAN AMOUNT = bin3 conditioned on FRAUD = true will be 0.0 and LOAN AMOUNT = bin3 conditioned FRAUD = false will be 1.0.",
            "zh": "å› æ­¤ï¼Œä»¥ FRAUD = true ä¸ºæ¡ä»¶çš„ LOAN AMOUNT = bin3 çš„åéªŒæ¦‚ç‡ä¸º 0.0ï¼Œä»¥ FRAUD = false ä¸ºæ¡ä»¶çš„ LOAN AMOUNT = bin3 çš„åéªŒæ¦‚ç‡ä¸º 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.3",
            "zh": "å›¾ 1.3"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors for the final model was 2,913.5.10",
            "zh": "æœ€ç»ˆæ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œä¸º 2,913.5.10"
        }
    },
    {
        "translation": {
            "en": "The fact that we can implement the calculation of the weighted sums for an entire layer of neurons as one matrix multiplication operation can be generalized to implementing an entire network as a sequence of matrix multiplications (one per layer of the network).",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†æ•´ä¸ªç¥ç»å…ƒå±‚çš„åŠ æƒå’Œè®¡ç®—å®ç°ä¸ºä¸€ä¸ªçŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œè¿™ä¸€äº‹å®å¯ä»¥æ¨å¹¿åˆ°å°†æ•´ä¸ªç½‘ç»œå®ç°ä¸ºçŸ©é˜µä¹˜æ³•åºåˆ—ï¼ˆæ¯å±‚ç½‘ç»œä¸€ä¸ªï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) 5 hidden layers with 2,000 neurons in each layer",
            "zh": "ï¼ˆbï¼‰ 5 ä¸ªéšè—å±‚ï¼Œæ¯å±‚æœ‰ 2,000 ä¸ªç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35[497] also shows that there may be multiple filters applied in parallel in a convolutional layer.",
            "zh": "å›¾8.35[497]è¿˜æ˜¾ç¤ºï¼Œåœ¨ä¸€ä¸ªå·ç§¯å±‚ä¸­å¯èƒ½æœ‰å¤šä¸ªæ»¤æ³¢å™¨å¹¶è¡Œåº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6â€ƒEvaluating Models after Deployment",
            "zh": "9.4.6 éƒ¨ç½²åè¯„ä¼°æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "This distinction between what generative and discriminative models try to learn is important because the class conditional densities, P(d|tl), can be very complex compared to the class posteriors, P(tl|d) (see Figure 14.1[734]). Consequently, generative models try to learn more complex solutions to the prediction problem than discriminative models.",
            "zh": "ç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹è¯•å›¾å­¦ä¹ çš„å†…å®¹ä¹‹é—´çš„è¿™ç§åŒºåˆ«å¾ˆé‡è¦ï¼Œå› ä¸ºä¸ç±»åéªŒ Pï¼ˆtl|dï¼‰ ç›¸æ¯”ï¼Œç±»æ¡ä»¶å¯†åº¦ Pï¼ˆd|tlï¼‰ å¯èƒ½éå¸¸å¤æ‚ï¼ˆå‚è§å›¾ 14.1[734]ï¼‰ã€‚å› æ­¤ï¼Œä¸åˆ¤åˆ«æ¨¡å‹ç›¸æ¯”ï¼Œç”Ÿæˆæ¨¡å‹è¯•å›¾å­¦ä¹ æ›´å¤æ‚çš„é¢„æµ‹é—®é¢˜è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard approach for handling continuous features in a Bayesian network is to use binning.",
            "zh": "åœ¨è´å¶æ–¯ç½‘ç»œä¸­å¤„ç†è¿ç»­ç‰¹å¾çš„æ ‡å‡†æ–¹æ³•æ˜¯ä½¿ç”¨åˆ†ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "The complementary problems of exploding and vanishing gradients can be understood as examples of the more general challenge of unstable gradients",
            "zh": "æ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤±çš„äº’è¡¥é—®é¢˜å¯ä»¥ç†è§£ä¸ºä¸ç¨³å®šæ¢¯åº¦çš„æ›´æ™®éæŒ‘æˆ˜çš„ä¾‹å­"
        }
    },
    {
        "translation": {
            "en": "Figure 4.6",
            "zh": "å›¾ 4.6"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s return to the original question depicted in Figure 5.15[219]: Are B and C likely to be from the same population from which the dataset has been sampled? Focusing on Figure 5.15(c)[219], for this dataset it appears reasonable to conclude that instance C is a member of the dataset but that B is probably not. To confirm this intuition we can calculate the Mahalanobis distance between A and B and A and C using Equation (5.16)[219] as",
            "zh": "è®©æˆ‘ä»¬å›åˆ°å›¾ 5.15[219] ä¸­æè¿°çš„åŸå§‹é—®é¢˜ï¼šB å’Œ C æ˜¯å¦å¯èƒ½æ¥è‡ªä»ä¸­æŠ½å–æ•°æ®é›†çš„åŒä¸€æ€»ä½“ï¼Ÿä»å›¾5.15ï¼ˆcï¼‰[219]æ¥çœ‹ï¼Œå¯¹äºè¿™ä¸ªæ•°æ®é›†ï¼Œä¼¼ä¹å¯ä»¥åˆç†åœ°å¾—å‡ºç»“è®ºï¼Œå®ä¾‹Cæ˜¯æ•°æ®é›†çš„æˆå‘˜ï¼Œä½†Bå¯èƒ½ä¸æ˜¯ã€‚ä¸ºäº†è¯å®è¿™ä¸€ç›´è§‰ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…¬å¼ï¼ˆ5.16ï¼‰[219]è®¡ç®—Aå’ŒBä»¥åŠAå’ŒCä¹‹é—´çš„é©¬æ°è·ç¦»ï¼Œå¦‚ä¸‹æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "Parametric/",
            "zh": "å‚æ•°/"
        }
    },
    {
        "translation": {
            "en": "Rob: Noâ€¦",
            "zh": "Robï¼š ä¸..."
        }
    },
    {
        "translation": {
            "en": "3.3.2â€ƒIrregular Cardinality",
            "zh": "3.3.2 ä¸è§„åˆ™åŸºæ•°"
        }
    },
    {
        "translation": {
            "en": "non-linear relationship, 368",
            "zh": "éçº¿æ€§å…³ç³»ï¼Œ368"
        }
    },
    {
        "translation": {
            "en": "6.3â€…â€…â€…Plots of some well-known probability distributions.",
            "zh": "6.3 ä¸€äº›ä¼—æ‰€å‘¨çŸ¥çš„æ¦‚ç‡åˆ†å¸ƒå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Example domain concepts for a motor insurance fraud prediction analytics solution.",
            "zh": "æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„ç¤ºä¾‹åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "The motivation behind using ensemble methods is that a committee of experts working together on a problem are more likely to solve it successfully than a single expert working alone.",
            "zh": "ä½¿ç”¨é›†æˆæ–¹æ³•çš„åŠ¨æœºæ˜¯ï¼Œä¸å•ä¸ªä¸“å®¶å•ç‹¬åˆä½œç›¸æ¯”ï¼Œå…±åŒè§£å†³é—®é¢˜çš„ä¸“å®¶å§”å‘˜ä¼šæ›´æœ‰å¯èƒ½æˆåŠŸè§£å†³é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We recommend the use of criteria that compare the error rate in the predictions made by a decision tree when a given subtree is included and when it is pruned.",
            "zh": "æˆ‘ä»¬å»ºè®®ä½¿ç”¨æ ‡å‡†æ¥æ¯”è¾ƒå†³ç­–æ ‘åœ¨åŒ…å«ç»™å®šå­æ ‘å’Œä¿®å‰ªå­æ ‘æ—¶æ‰€åšçš„é¢„æµ‹ä¸­çš„é”™è¯¯ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.6â€…â€…â€…A confusion matrix for a naive Bayes model trained on a churn prediction problem.",
            "zh": "9.6 åœ¨æµå¤±é¢„æµ‹é—®é¢˜ä¸Šè®­ç»ƒçš„æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.7",
            "zh": "å›¾ 9.7"
        }
    },
    {
        "translation": {
            "en": "2. Compute P(b | a,C) by summing out C: P(b | a,C) = âˆ‘i P(b | a,Ci)",
            "zh": "2. é€šè¿‡æ±‚å’Œ C è®¡ç®— Pï¼ˆb | aï¼ŒCï¼‰ = âˆ‘i Pï¼ˆb | aï¼ŒCiï¼‰"
        }
    },
    {
        "translation": {
            "en": "The primary reason was that it had such a simple derivative.",
            "zh": "ä¸»è¦åŸå› æ˜¯å®ƒæœ‰å¦‚æ­¤ç®€å•çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.14",
            "zh": "å›¾ 9.14"
        }
    },
    {
        "translation": {
            "en": "The final element of the equation is a column vector that is created in the same way as the row vector at the beginning of the equationâ€”by subtracting each feature value from b from the corresponding feature value from a.",
            "zh": "ç­‰å¼çš„æœ€åä¸€ä¸ªå…ƒç´ æ˜¯åˆ—å‘é‡ï¼Œå…¶åˆ›å»ºæ–¹å¼ä¸ç­‰å¼å¼€å¤´çš„è¡Œå‘é‡ç›¸åŒï¼Œå³ä» a çš„ç›¸åº”ç‰¹å¾å€¼ä¸­å‡å» b ä¸­çš„æ¯ä¸ªç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "2â€…â€…â€…Data to Insights to Decisions",
            "zh": "2 ä»æ•°æ®åˆ°æ´å¯Ÿå†åˆ°å†³ç­–"
        }
    },
    {
        "translation": {
            "en": "This involves floating on your surfboard until a wave approaches and then paddling furiously to gain enough momentum for the wave to pick up both you and your board.",
            "zh": "è¿™åŒ…æ‹¬æ¼‚æµ®åœ¨å†²æµªæ¿ä¸Šï¼Œç›´åˆ°æµ·æµªæ¥è¿‘ï¼Œç„¶åç–¯ç‹‚åœ°åˆ’æ¡¨ä»¥è·å¾—è¶³å¤Ÿçš„åŠ¨åŠ›ï¼Œè®©æµ·æµªå°†ä½ å’Œä½ çš„å†²æµªæ¿éƒ½å·èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.5â€…â€…â€…The division of data during the leave-one-out cross validation process. Black rectangles indicate instances in the test set, and white spaces indicate training data.",
            "zh": "9.5 åœ¨â€œç•™ä¸€â€äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•é›†ä¸­çš„å®ä¾‹ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consider the following business problem: in spite of having a fraud investigation team that investigates up to 30% of all claims made, a motor insurance company is still losing too much money due to fraudulent claims. The following predictive analytics solutions could be proposed to help address this business problem:",
            "zh": "è€ƒè™‘ä»¥ä¸‹ä¸šåŠ¡é—®é¢˜ï¼šå°½ç®¡æœ‰ä¸€ä¸ªæ¬ºè¯ˆè°ƒæŸ¥å°ç»„ï¼Œå¯ä»¥è°ƒæŸ¥é«˜è¾¾ 30% çš„ç´¢èµ”ï¼Œä½†æ±½è½¦ä¿é™©å…¬å¸ä»ç„¶å› æ¬ºè¯ˆæ€§ç´¢èµ”è€ŒæŸå¤±äº†å¤ªå¤šé’±ã€‚å¯ä»¥æå‡ºä»¥ä¸‹é¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆæ¥å¸®åŠ©è§£å†³æ­¤ä¸šåŠ¡é—®é¢˜ï¼š"
        }
    },
    {
        "translation": {
            "en": "column of the data quality report in Table 3.3[57] shows that MARITAL STATUS and NUM.",
            "zh": "è¡¨3.3[57]ä¸­æ•°æ®è´¨é‡æŠ¥å‘Šçš„åˆ—æ˜¾ç¤ºï¼Œå©šå§»çŠ¶å†µå’ŒNUM."
        }
    },
    {
        "translation": {
            "en": "composite function, 768",
            "zh": "å¤åˆå‡½æ•°ï¼Œ768"
        }
    },
    {
        "translation": {
            "en": "This is different from the normalization we have looked at elsewhere in this chapter as it takes place within an instance rather than across all the values of a feature.",
            "zh": "è¿™ä¸æˆ‘ä»¬åœ¨æœ¬ç« å…¶ä»–åœ°æ–¹çœ‹åˆ°çš„è§„èŒƒåŒ–ä¸åŒï¼Œå› ä¸ºå®ƒå‘ç”Ÿåœ¨ä¸€ä¸ªå®ä¾‹ä¸­ï¼Œè€Œä¸æ˜¯åœ¨ä¸€ä¸ªç‰¹å¾çš„æ‰€æœ‰å€¼ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "IVâ€…â€…â€…CASE STUDIES AND CONCLUSIONS",
            "zh": "å››ã€æ¡ˆä¾‹ç ”ç©¶å’Œç»“è®º"
        }
    },
    {
        "translation": {
            "en": "column of the data quality report, we can see that the cardinality of the INSURANCE TYPE feature is 1, an obvious data problem that needs investigation.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šçš„åˆ—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° INSURANCE TYPE ç‰¹å¾çš„åŸºæ•°ä¸º 1ï¼Œè¿™æ˜¯ä¸€ä¸ªæ˜æ˜¾çš„æ•°æ®é—®é¢˜ï¼Œéœ€è¦è°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, adding depth to filters not only enables convolutional neural networks to process multi-dimensional input; it also enables the networks to apply multiple filters in parallel to the same input and for later layers in the network to integrate information from across these layers.",
            "zh": "å› æ­¤ï¼Œå¢åŠ æ»¤æ³¢å™¨çš„æ·±åº¦ä¸ä»…ä½¿å·ç§¯ç¥ç»ç½‘ç»œèƒ½å¤Ÿå¤„ç†å¤šç»´è¾“å…¥;å®ƒè¿˜ä½¿ç½‘ç»œèƒ½å¤Ÿå°†å¤šä¸ªæ»¤æ³¢å™¨å¹¶è¡Œåº”ç”¨äºåŒä¸€è¾“å…¥ï¼Œå¹¶ä½¿ç½‘ç»œä¸­çš„åç»­å±‚èƒ½å¤Ÿé›†æˆæ¥è‡ªè¿™äº›å±‚çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes in an organization, certain values will only have been collected after a certain date, and the data used to generate an ABT might cover time both before and after this date.",
            "zh": "æœ‰æ—¶ï¼Œåœ¨ç»„ç»‡ä¸­ï¼ŒæŸäº›å€¼ä»…åœ¨ç‰¹å®šæ—¥æœŸä¹‹åæ”¶é›†ï¼Œå¹¶ä¸”ç”¨äºç”Ÿæˆ ABT çš„æ•°æ®å¯èƒ½æ¶µç›–æ­¤æ—¥æœŸä¹‹å‰å’Œä¹‹åçš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "SDSS scientists, however, were struggling to build rule-based systems that could accurately perform more fine-grained classifications.",
            "zh": "ç„¶è€Œï¼ŒSDSSçš„ç§‘å­¦å®¶ä»¬æ­£åœ¨åŠªåŠ›æ„å»ºåŸºäºè§„åˆ™çš„ç³»ç»Ÿï¼Œä»¥å‡†ç¡®æ‰§è¡Œæ›´ç»†ç²’åº¦çš„åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.21",
            "zh": "å›¾ 5.21"
        }
    },
    {
        "translation": {
            "en": "The division of data during the Îµ0 bootstrap process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "Îµ0 å¼•å¯¼è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•æ•°æ®ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The histogram heights fit the contour line to an extent, but there is a greater variance in the heights across the bins in this image.",
            "zh": "ç›´æ–¹å›¾é«˜åº¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¬¦åˆç­‰å€¼çº¿ï¼Œä½†åœ¨æ­¤å›¾åƒä¸­ï¼Œæ¡æŸ±ä¹‹é—´çš„é«˜åº¦å·®å¼‚æ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Wolpert David, H. 1996. The lack of a priori distinctions between learning algorithms. Neural Computation 8 (7): 1341â€“1390.",
            "zh": "æ²ƒå°”ç€ç‰¹Â·å¤§å«ï¼ŒH. 1996 å¹´ã€‚å­¦ä¹ ç®—æ³•ä¹‹é—´ç¼ºä¹å…ˆéªŒçš„åŒºåˆ«ã€‚ç¥ç»è®¡ç®— 8 ï¼ˆ7ï¼‰ï¼š1341â€“1390ã€‚"
        }
    },
    {
        "translation": {
            "en": "Next, âˆ‚â„°/âˆ‚ak is multiplied by âˆ‚ak/âˆ‚zk (which is calculated as previously described, by inputting the zk for the neuron into the derivative of its activation function).",
            "zh": "æ¥ä¸‹æ¥ï¼Œâˆ‚E/âˆ‚ak ä¹˜ä»¥ âˆ‚ak/âˆ‚zkï¼ˆå¦‚å‰æ‰€è¿°è®¡ç®—ï¼Œé€šè¿‡å°†ç¥ç»å…ƒçš„ zk è¾“å…¥åˆ°å…¶æ¿€æ´»å‡½æ•°çš„å¯¼æ•°ä¸­ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. The slightly strange name receiver operating characteristic comes from the fact that this approach was first used for tuning radar signals in World War II.",
            "zh": "12. æœ‰ç‚¹å¥‡æ€ªçš„åç§°æ¥æ”¶æœºå·¥ä½œç‰¹æ€§æ¥è‡ªè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³è¿™ç§æ–¹æ³•åœ¨ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜ä¸­é¦–æ¬¡ç”¨äºè°ƒè°é›·è¾¾ä¿¡å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This example is based on ecological modeling, an area of scientific research that applies statistical and analytical techniques to model ecological processes.",
            "zh": "è¿™ä¸ªä¾‹å­åŸºäºç”Ÿæ€å»ºæ¨¡ï¼Œç”Ÿæ€å»ºæ¨¡æ˜¯ä¸€ä¸ªåº”ç”¨ç»Ÿè®¡å’Œåˆ†ææŠ€æœ¯æ¥æ¨¡æ‹Ÿç”Ÿæ€è¿‡ç¨‹çš„ç§‘å­¦ç ”ç©¶é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The backpropagation of the Î´s and the summation of the error gradients across the examples in the mini-batch are done in the for loop from Line 15[420] to Line 27[420].",
            "zh": "åœ¨å°æ‰¹é‡ä¸­ï¼ŒÎ´ çš„åå‘ä¼ æ’­å’Œè¯¯å·®æ¢¯åº¦çš„æ€»å’Œæ˜¯åœ¨ä»ç¬¬ 15 è¡Œ [420] åˆ°ç¬¬ 27 è¡Œ [420] çš„ for å¾ªç¯ä¸­å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remember, an analytics project is often iterative, with different stages of the project feeding back into later cycles.",
            "zh": "è¯·è®°ä½ï¼Œåˆ†æé¡¹ç›®é€šå¸¸æ˜¯è¿­ä»£çš„ï¼Œé¡¹ç›®çš„ä¸åŒé˜¶æ®µä¼šåé¦ˆåˆ°ä»¥åçš„å‘¨æœŸä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.2â€…â€…â€…Measuring Covariance and Correlation",
            "zh": "3.5.2 æµ‹é‡åæ–¹å·®å’Œç›¸å…³æ€§"
        }
    },
    {
        "translation": {
            "en": "The path that the agent would take from the start state to the goal state following this policy is shown in Figure 11.5(f)[663].",
            "zh": "æŒ‰ç…§æ­¤ç­–ç•¥ï¼Œä»£ç†ä»å¼€å§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„å¦‚å›¾ 11.5ï¼ˆfï¼‰[663] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that there are 52 different scenarios that could occur if a player is in the PM-DH state and chooses the Twist action (the player is dealt one of 13 possible cards when their hand has one of 4 possible values, so 4 Ã— 13 = 52).",
            "zh": "è¿™æ„å‘³ç€ï¼Œå¦‚æœç©å®¶å¤„äº PM-DH çŠ¶æ€å¹¶é€‰æ‹© Twist åŠ¨ä½œï¼Œåˆ™å¯èƒ½ä¼šå‘ç”Ÿ 52 ç§ä¸åŒçš„æƒ…å†µï¼ˆå½“ç©å®¶çš„æ‰‹ç‰Œå…·æœ‰ 4 ä¸ªå¯èƒ½çš„å€¼ä¹‹ä¸€æ—¶ï¼Œç©å®¶å°†è·å¾— 13 å¼ å¯èƒ½çš„ç‰Œä¸­çš„ä¸€å¼ ï¼Œå› æ­¤ 4 Ã— 13 = 52ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another simple variant of the basic bar plot orders the bars in descending order.6 Typically we use bar plots to discover the most frequent levels for a feature, and this ordering makes this more apparent. Figure A.5[753] shows example bar plots of all three types for the POSITION feature from the dataset in Table A.1[750]. We can see that guard is the most frequent level.",
            "zh": "åŸºæœ¬æ¡å½¢å›¾çš„å¦ä¸€ä¸ªç®€å•å˜ä½“æ˜¯æŒ‰é™åºå¯¹æ¡å½¢è¿›è¡Œæ’åº.6 é€šå¸¸ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¡å½¢å›¾æ¥å‘ç°ç‰¹å¾çš„æœ€å¸¸è§çº§åˆ«ï¼Œè¿™ç§æ’åºä½¿è¿™ä¸€ç‚¹æ›´åŠ æ˜æ˜¾ã€‚å›¾A.5[753]æ˜¾ç¤ºäº†è¡¨A.1[750]ä¸­æ•°æ®é›†ä¸­æ‰€æœ‰ä¸‰ç§ç±»å‹çš„POSITIONç‰¹å¾çš„æ¡å½¢å›¾ç¤ºä¾‹ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå®ˆå«æ˜¯æœ€å¸¸è§çš„çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.3â€…â€…â€…Using a validation set to avoid overfitting in iterative machine learning algorithms.",
            "zh": "9.3 ä½¿ç”¨éªŒè¯é›†æ¥é¿å…è¿­ä»£æœºå™¨å­¦ä¹ ç®—æ³•ä¸­çš„è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "So, which model is making the better prediction?",
            "zh": "é‚£ä¹ˆï¼Œå“ªç§æ¨¡å‹çš„é¢„æµ‹æ›´å¥½å‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "where count(f = l | t) is how often the event f = l occurs in the subset of rows in the dataset where the target level is t, count(f | t) is how often the feature, f, took any level in the subset of rows in the dataset where the target level is t, |Domain(f)| is the number of levels in the domain of the feature, and k is a predetermined parameter.",
            "zh": "å…¶ä¸­ countï¼ˆf = l | tï¼‰ æ˜¯äº‹ä»¶ f = l åœ¨ç›®æ ‡çº§åˆ«ä¸º t çš„æ•°æ®é›†ä¸­è¡Œå­é›†ä¸­å‘ç”Ÿçš„é¢‘ç‡ï¼Œcountï¼ˆf | tï¼‰ æ˜¯ç‰¹å¾ f åœ¨ç›®æ ‡çº§åˆ«ä¸º t çš„æ•°æ®é›†ä¸­è¡Œå­é›†ä¸­è·å–ä»»ä½•çº§åˆ«çš„é¢‘ç‡ï¼Œ |åŸŸåï¼ˆfï¼‰|æ˜¯ç‰¹å¾åŸŸä¸­çš„çº§åˆ«æ•°ï¼Œk æ˜¯é¢„å®šå‚æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETRORADERR_U/G/R/I/Z",
            "zh": "PETRORADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Applications of unsupervised learning are widespread, including customer segmentations (Berry and Linoff, 2004), anomaly detection (Chandola et al., 2009), and analyzing peopleâ€™s movement patterns (Li et al., 2015).",
            "zh": "æ— ç›‘ç£å­¦ä¹ çš„åº”ç”¨å¾ˆæ™®éï¼ŒåŒ…æ‹¬å®¢æˆ·ç»†åˆ†ï¼ˆBerry and Linoffï¼Œ2004ï¼‰ï¼Œå¼‚å¸¸æ£€æµ‹ï¼ˆChandola et al.ï¼Œ2009ï¼‰å’Œåˆ†æäººä»¬çš„è¿åŠ¨æ¨¡å¼ï¼ˆLi et al.ï¼Œ2015ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. All values in Table 7.3[331], and similar subsequent tables, are reported at a precision of two places of decimal. Because of this, some error values and squared error values may appear inconsistent. This, however, is only due to rounding differences.",
            "zh": "9. è¡¨7.3[331]ä¸­çš„æ‰€æœ‰å€¼ä»¥åŠç±»ä¼¼çš„åç»­è¡¨æ ¼å‡ä»¥å°æ•°ç‚¹åä¸¤ä½çš„ç²¾åº¦æŠ¥å‘Šã€‚å› æ­¤ï¼ŒæŸäº›è¯¯å·®å€¼å’Œå¹³æ–¹è¯¯å·®å€¼å¯èƒ½çœ‹èµ·æ¥ä¸ä¸€è‡´ã€‚ç„¶è€Œï¼Œè¿™åªæ˜¯ç”±äºå››èˆäº”å…¥çš„å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.53",
            "zh": "0.53"
        }
    },
    {
        "translation": {
            "en": "-0.9394",
            "zh": "-0.9394"
        }
    },
    {
        "translation": {
            "en": "Although this sounds like a lot of probabilities considering the size of the example dataset, it is worth noting that these 22 probabilities would suffice no matter how many new instances are added to the dataset, be it hundreds of thousands, or even millions.",
            "zh": "å°½ç®¡è€ƒè™‘åˆ°ç¤ºä¾‹æ•°æ®é›†çš„å¤§å°ï¼Œè¿™å¬èµ·æ¥åƒæ˜¯å¾ˆå¤šæ¦‚ç‡ï¼Œä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ— è®ºå‘æ•°æ®é›†ä¸­æ·»åŠ å¤šå°‘æ–°å®ä¾‹ï¼Œæ— è®ºæ˜¯æ•°åä¸‡è¿˜æ˜¯æ•°ç™¾ä¸‡ï¼Œè¿™ 22 ä¸ªæ¦‚ç‡éƒ½è¶³å¤Ÿäº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "After going along to admire her work, Mr. Murphy congratulated his daughter on organizing the letters so well.",
            "zh": "åœ¨æ¬£èµäº†å¥¹çš„ä½œå“ä¹‹åï¼Œå¢¨è²å…ˆç”Ÿç¥è´ºä»–çš„å¥³å„¿æŠŠä¿¡ä»¶æ•´ç†å¾—å¦‚æ­¤å‡ºè‰²ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarity-Based Learning",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "logit, xxvii, 464",
            "zh": "logitï¼ŒäºŒåä¸ƒï¼Œ464"
        }
    },
    {
        "translation": {
            "en": "Implementing features is often a process of approximation through which we attempt to express as much of each domain concept as possible from the data sources that are available to us.",
            "zh": "å®ç°åŠŸèƒ½é€šå¸¸æ˜¯ä¸€ä¸ªè¿‘ä¼¼è¿‡ç¨‹ï¼Œé€šè¿‡è¯¥è¿‡ç¨‹ï¼Œæˆ‘ä»¬è¯•å›¾ä»å¯ç”¨çš„æ•°æ®æºä¸­å°½å¯èƒ½å¤šåœ°è¡¨è¾¾æ¯ä¸ªé¢†åŸŸçš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "The LOAN AMOUNT value for this query (8,000) is below the threshold for bin1. Consequently, the query LOAN AMOUNT feature will be treated as being equal to bin1 during prediction. Table 6.17[285] lists the calculations of the naive Bayes scores for the candidate predictions for this query: 0.000000462 for true and 0.000000633 for false. The target level false has the highest score and will be the prediction made by the model.",
            "zh": "æ­¤æŸ¥è¯¢çš„ LOAN AMOUNT å€¼ ï¼ˆ8,000ï¼‰ ä½äº bin1 çš„é˜ˆå€¼ã€‚å› æ­¤ï¼Œåœ¨é¢„æµ‹æœŸé—´ï¼ŒæŸ¥è¯¢ LOAN AMOUNT ç‰¹å¾å°†è¢«è§†ä¸ºç­‰äº bin1ã€‚è¡¨ 6.17[285] åˆ—å‡ºäº†æ­¤æŸ¥è¯¢çš„å€™é€‰é¢„æµ‹çš„æœ´ç´ è´å¶æ–¯åˆ†æ•°çš„è®¡ç®—ï¼š0.000000462 è¡¨ç¤º trueï¼Œ0.000000633 è¡¨ç¤º falseã€‚ç›®æ ‡çº§åˆ« false çš„å¾—åˆ†æœ€é«˜ï¼Œå¹¶ä¸”æ˜¯æ¨¡å‹åšå‡ºçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the third term in ctâˆ’1 is multiplied by an ft of 0.5, which results in the value of 0.5 in câ€¡.",
            "zh": "æœ€åï¼Œå°† ctâˆ’1 ä¸­çš„ç¬¬ä¸‰é¡¹ä¹˜ä»¥ 0.5 çš„ ftï¼Œå¾—å‡º câ€¡ ä¸­çš„å€¼ä¸º 0.5ã€‚"
        }
    },
    {
        "translation": {
            "en": "The initial cluster centroids for the three clusters 1, 2, and 3 are c1 = âˆ’0.929,âˆ’1.040,âˆ’0.831, c2 = âˆ’0.329,âˆ’1.099,0.377, and c3 = âˆ’0.672,âˆ’0.505, 0.110.",
            "zh": "ä¸‰ä¸ªèšç±» 1ã€2 å’Œ 3 çš„åˆå§‹èšç±»è´¨å¿ƒä¸º c1 = âˆ’0.929ã€âˆ’1.040ã€âˆ’0.831ã€c2 = âˆ’0.329ã€âˆ’1.099ã€0.377 å’Œ c3 = âˆ’0.672ã€âˆ’0.505ã€0.110ã€‚"
        }
    },
    {
        "translation": {
            "en": "A stability index value greater than 0.25 suggests that a significant change has occurred and corrective action is required.",
            "zh": "ç¨³å®šæ€§æŒ‡æ•°å€¼å¤§äº 0.25 è¡¨ç¤ºå‘ç”Ÿäº†é‡å¤§å˜åŒ–ï¼Œéœ€è¦é‡‡å–çº æ­£æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn read a number of publications by the SDSS team6 before spending several sessions with Edwin discussing the work that he and his colleagues did.",
            "zh": "Jocelyn é˜…è¯»äº† SDSS å›¢é˜Ÿçš„ä¸€äº›å‡ºç‰ˆç‰©6ï¼Œç„¶åä¸ Edwin è®¨è®ºäº†ä»–å’Œä»–çš„åŒäº‹æ‰€åšçš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "CLAIMS, and NUM.",
            "zh": "CLAIMS å’Œ NUM."
        }
    },
    {
        "translation": {
            "en": "1.3â€…â€…â€…How Does Machine Learning Work?",
            "zh": "1.3 æœºå™¨å­¦ä¹ æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "In Figure 6.6(b)[275] we can see the three normal distributions used to model the multimodal distribution in Figure 6.6(a)[275].",
            "zh": "åœ¨å›¾6.6ï¼ˆbï¼‰[275]ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å›¾6.6ï¼ˆaï¼‰[275]ä¸­ç”¨äºæ¨¡æ‹Ÿå¤šå³°åˆ†å¸ƒçš„ä¸‰ä¸ªæ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Deployment, 17, 20, 702, 727, 730",
            "zh": "éƒ¨ç½²ã€17ã€20ã€702ã€727ã€730"
        }
    },
    {
        "translation": {
            "en": "To calculate the expected return of taking action at from state st we can calculate a weighted sum across the expected returns that the agent could receive in every state, st+1, that the agent could reach after taking action at in state st.",
            "zh": "ä¸ºäº†è®¡ç®—ä»çŠ¶æ€ st é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä»£ç†åœ¨æ¯ä¸ªçŠ¶æ€ st+1 ä¸­å¯ä»¥è·å¾—çš„é¢„æœŸå›æŠ¥çš„åŠ æƒæ€»å’Œï¼Œä»£ç†åœ¨çŠ¶æ€ st é‡‡å–è¡ŒåŠ¨åå¯ä»¥è¾¾åˆ°è¯¥çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The replay memory is given a maximum size, N (usually greater than 10,000), and when it reaches this the oldest instances are dropped as new ones are added.",
            "zh": "é‡æ”¾å†…å­˜çš„æœ€å¤§å¤§å°ä¸º Nï¼ˆé€šå¸¸å¤§äº 10,000ï¼‰ï¼Œå½“å®ƒè¾¾åˆ°æ­¤å¤§å°æ—¶ï¼Œæœ€æ—§çš„å®ä¾‹å°†åœ¨æ·»åŠ æ–°å®ä¾‹æ—¶è¢«ä¸¢å¼ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The following images show histograms of the values of the four descriptive features both for the full dataset and when divided into the three clusters found.",
            "zh": "ä¸‹å›¾æ˜¾ç¤ºäº†å››ä¸ªæè¿°æ€§è¦ç´ å€¼çš„ç›´æ–¹å›¾ï¼ŒåŒ…æ‹¬æ•´ä¸ªæ•°æ®é›†å’Œåˆ’åˆ†ä¸ºä¸‰ä¸ªèšç±»æ—¶çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, the model shown in Figure 1.3(c)[15], although consistent with the training instances, seems much more complicated than necessary.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œå›¾1.3ï¼ˆcï¼‰[15]æ‰€ç¤ºçš„æ¨¡å‹è™½ç„¶ä¸è®­ç»ƒå®ä¾‹ä¸€è‡´ï¼Œä½†ä¼¼ä¹æ¯”å¿…è¦çš„è¦å¤æ‚å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Plots of some well-known probability distributions.",
            "zh": "ä¸€äº›ä¼—æ‰€å‘¨çŸ¥çš„æ¦‚ç‡åˆ†å¸ƒå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Support vector machines have become a very popular approach to building predictive models in recent times. They can be quickly trained, are not overly susceptible to overfitting, and work well for high-dimensional data. In contrast to logistic regression models, however, they are not very interpretable, and, especially when kernel functions are used, it is very difficult to understand why a particular prediction has been made.",
            "zh": "æœ€è¿‘ï¼Œæ”¯æŒå‘é‡æœºå·²æˆä¸ºæ„å»ºé¢„æµ‹æ¨¡å‹çš„ä¸€ç§éå¸¸æµè¡Œçš„æ–¹æ³•ã€‚å®ƒä»¬å¯ä»¥å¿«é€Ÿè®­ç»ƒï¼Œä¸å¤ªå®¹æ˜“å—åˆ°è¿‡åº¦æ‹Ÿåˆçš„å½±å“ï¼Œå¹¶ä¸”é€‚ç”¨äºé«˜ç»´æ•°æ®ã€‚ç„¶è€Œï¼Œä¸é€»è¾‘å›å½’æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒä»¬çš„å¯è§£é‡Šæ€§ä¸å¼ºï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨æ ¸å‡½æ•°æ—¶ï¼Œå¾ˆéš¾ç†è§£ä¸ºä»€ä¹ˆè¦åšå‡ºç‰¹å®šçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, the underlying data will exhibit non-linear relationships that we would like to capture in a model.",
            "zh": "ä½†æ˜¯ï¼Œæœ‰æ—¶åŸºç¡€æ•°æ®ä¼šè¡¨ç°å‡ºæˆ‘ä»¬å¸Œæœ›åœ¨æ¨¡å‹ä¸­æ•è·çš„éçº¿æ€§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "embedding, 624, 626",
            "zh": "åµŒå…¥ï¼Œ 624ï¼Œ 626"
        }
    },
    {
        "translation": {
            "en": "In the standard version of the algorithm, the data structure used to store training data is a simple list.",
            "zh": "åœ¨æ ‡å‡†ç‰ˆæœ¬çš„ç®—æ³•ä¸­ï¼Œç”¨äºå­˜å‚¨è®­ç»ƒæ•°æ®çš„æ•°æ®ç»“æ„æ˜¯ä¸€ä¸ªç®€å•çš„åˆ—è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "31. We discuss the design of evaluation experiments in detail in Chapter 9[533].",
            "zh": "31. æˆ‘ä»¬åœ¨ç¬¬9ç« [533]ä¸­è¯¦ç»†è®¨è®ºäº†è¯„ä¼°å®éªŒçš„è®¾è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "blame assignment, 404, 405, 413",
            "zh": "è´£å¤‡åˆ†é…ï¼Œ404,405,413"
        }
    },
    {
        "translation": {
            "en": "Jocelyn implemented these derived features for inclusion in the final ABT.",
            "zh": "Jocelyn å®ç°äº†è¿™äº›æ´¾ç”ŸåŠŸèƒ½ï¼Œä»¥åŒ…å«åœ¨æœ€ç»ˆçš„ ABT ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Framing the action-value function as a prediction problem.",
            "zh": "å°†åŠ¨ä½œå€¼å‡½æ•°æ„å»ºä¸ºé¢„æµ‹é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The area under the ROC curve (AUC) for Model 1 is 0.955 and for Model 2 is 0.851. Which model is performing best?",
            "zh": "ï¼ˆbï¼‰ æ¨¡å‹1çš„ROCæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰ä¸º0.955ï¼Œæ¨¡å‹2ä¸º0.851ã€‚å“ªç§å‹å·æ€§èƒ½æœ€å¥½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "In this section we describe approaches to visualizing the relationships between pairs of continuous features, pairs of categorical features, and pairs including one categorical and one continuous feature.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¯è§†åŒ–è¿ç»­ç‰¹å¾å¯¹ã€åˆ†ç±»ç‰¹å¾å¯¹ä»¥åŠåŒ…å«ä¸€ä¸ªåˆ†ç±»ç‰¹å¾å’Œä¸€ä¸ªè¿ç»­ç‰¹å¾çš„å¯¹ä¹‹é—´çš„å…³ç³»çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Email spam filtering models often use a bag-of-words representation for emails.",
            "zh": "åƒåœ¾é‚®ä»¶ç­›é€‰æ¨¡å‹é€šå¸¸å¯¹ç”µå­é‚®ä»¶ä½¿ç”¨è¯è¢‹è¡¨ç¤ºå½¢å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are other framings of the reinforcement learning problem under which different framings are used and extra components are addedâ€”for example, policy-based reinforcement learning and model-based reinforcement learning.",
            "zh": "å¼ºåŒ–å­¦ä¹ é—®é¢˜è¿˜æœ‰å…¶ä»–æ¡†æ¶ï¼Œåœ¨è¿™äº›æ¡†æ¶ä¸‹ï¼Œä½¿ç”¨ä¸åŒçš„æ¡†æ¶å¹¶æ·»åŠ é¢å¤–çš„ç»„ä»¶ï¼Œä¾‹å¦‚ï¼ŒåŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ å’ŒåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.20",
            "zh": "å›¾ 5.20"
        }
    },
    {
        "translation": {
            "en": "sabremetrics, 183",
            "zh": "sabremetricsï¼Œ183"
        }
    },
    {
        "translation": {
            "en": "This analysis explains the vanishing z values plotted in Figure 8.23(b)[453].",
            "zh": "è¯¥åˆ†æè§£é‡Šäº†å›¾8.23ï¼ˆbï¼‰[453]ä¸­ç»˜åˆ¶çš„æ¶ˆå¤±çš„zå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5[392] illustrates how a neural network can be defined as a sequence of matrix multiplication operations, with an elementwise application of an activation function to the results of each multiplication.",
            "zh": "å›¾ 8.5[392] è¯´æ˜äº†å¦‚ä½•å°†ç¥ç»ç½‘ç»œå®šä¹‰ä¸ºçŸ©é˜µä¹˜æ³•è¿ç®—åºåˆ—ï¼Œå¹¶å°†æ¿€æ´»å‡½æ•°åº”ç”¨äºæ¯ä¸ªä¹˜æ³•çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Neither forward nor backward sequential selection consider the effect of adding or removing combinations of features, and as a result, they arenâ€™t guaranteed to find the absolute optimal subset of features.",
            "zh": "å‰å‘å’Œåå‘é¡ºåºé€‰æ‹©éƒ½ä¸ä¼šè€ƒè™‘æ·»åŠ æˆ–åˆ é™¤ç‰¹å¾ç»„åˆçš„å½±å“ï¼Œå› æ­¤ï¼Œå®ƒä»¬ä¸èƒ½ä¿è¯æ‰¾åˆ°ç»å¯¹æœ€ä¼˜çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is clear that the clusterings shown in Figures 10.4(d)[606], 10.4(f)[606], and 10.4(h)[606] are quite different from the clustering found previously (shown in Figure 10.3(f)[602]) and are sub-optimal compared with the result we would intuitively expect from looking at the visualization of this dataset.",
            "zh": "å¾ˆæ˜æ˜¾ï¼Œå›¾10.4ï¼ˆdï¼‰[606]ã€10.4ï¼ˆfï¼‰[606]å’Œ10.4ï¼ˆhï¼‰[606]ä¸­æ˜¾ç¤ºçš„èšç±»ä¸ä¹‹å‰å‘ç°çš„èšç±»æœ‰å¾ˆå¤§ä¸åŒï¼ˆå¦‚å›¾10.3ï¼ˆfï¼‰[602]æ‰€ç¤ºï¼‰ï¼Œå¹¶ä¸”ä¸æˆ‘ä»¬ç›´è§‚åœ°æœŸæœ›çš„ç»“æœç›¸æ¯”ï¼Œè¿™äº›èšç±»æ˜¯æ¬¡ä¼˜çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.12",
            "zh": "è¡¨ 9.12"
        }
    },
    {
        "translation": {
            "en": "To use Mahalanobis distance in a nearest neighbor model, we simply use the model in exactly the same way as described previously but substitute Mahalanobis distance for Euclidean distance.",
            "zh": "ä¸ºäº†åœ¨æœ€è¿‘é‚»æ¨¡å‹ä¸­ä½¿ç”¨é©¬æ°è·ç¦»ï¼Œæˆ‘ä»¬åªéœ€ä»¥ä¸å‰é¢æè¿°å®Œå…¨ç›¸åŒçš„æ–¹å¼ä½¿ç”¨è¯¥æ¨¡å‹ï¼Œä½†ç”¨é©¬æ°è·ç¦»ä»£æ›¿æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next term in the equation, âˆ‘âˆ’1, represents the inverse covariance matrix22 computed across all instances in the dataset.",
            "zh": "ç­‰å¼ä¸­çš„ä¸‹ä¸€é¡¹ âˆ‘âˆ’1 è¡¨ç¤ºåœ¨æ•°æ®é›†ä¸­æ‰€æœ‰å®ä¾‹ä¸­è®¡ç®—çš„é€†åæ–¹å·®çŸ©é˜µ 22ã€‚"
        }
    },
    {
        "translation": {
            "en": "nearest neighbor algorithm, 181, 187, 231",
            "zh": "æœ€è¿‘é‚»ç®—æ³•ï¼Œ 181ï¼Œ 187ï¼Œ 231"
        }
    },
    {
        "translation": {
            "en": "The model is using only the SALARY feature and is ignoring the AGE feature when it makes predictions.",
            "zh": "è¯¥æ¨¡å‹ä»…ä½¿ç”¨ SALARY ç‰¹å¾ï¼Œåœ¨è¿›è¡Œé¢„æµ‹æ—¶å¿½ç•¥ AGE ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "CLUMP",
            "zh": "ä¸›"
        }
    },
    {
        "translation": {
            "en": "A common mistake made by many data analysts is to automatically default to modeling unimodally distributed data with a normal distribution.19 There are statistical tests (such as the Kolmogorov-Smirnov test) that can be used to check whether or not a feature is normally distributed, and in cases where the feature is not normally distributed, another unimodal distribution, such as the student-t distribution, may be a better fit.",
            "zh": "è®¸å¤šæ•°æ®åˆ†æå¸ˆå¸¸çŠ¯çš„ä¸€ä¸ªé”™è¯¯æ˜¯è‡ªåŠ¨é»˜è®¤ä¸ºä½¿ç”¨æ­£æ€åˆ†å¸ƒå¯¹å•å³°åˆ†å¸ƒæ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚19 æœ‰ä¸€äº›ç»Ÿè®¡æ£€éªŒï¼ˆå¦‚ Kolmogorov-Smirnov æ£€éªŒï¼‰å¯ç”¨äºæ£€æŸ¥ç‰¹å¾æ˜¯å¦å‘ˆæ­£æ€åˆ†å¸ƒï¼Œå¦‚æœç‰¹å¾ä¸æ˜¯æ­£æ€åˆ†å¸ƒï¼Œåˆ™ä½¿ç”¨å¦ä¸€ç§å•å³°åˆ†å¸ƒï¼Œ æ¯”å¦‚ student-t åˆ†å¸ƒï¼Œå¯èƒ½æ›´é€‚åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "False Positive (FP): an instance in the test set that had a negative target feature value but that was predicted to have a positive target feature value",
            "zh": "è¯¯æŠ¥ ï¼ˆFPï¼‰ï¼šæµ‹è¯•é›†ä¸­å…·æœ‰è´Ÿç›®æ ‡ç‰¹å¾å€¼ä½†é¢„æµ‹å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "Similarity-based approaches to machine learning come from the idea that the best way to make predictions is to simply look at what has worked well in the past and predict the same thing again.",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„æœºå™¨å­¦ä¹ æ–¹æ³•æ¥è‡ªè¿™æ ·ä¸€ç§æƒ³æ³•ï¼Œå³è¿›è¡Œé¢„æµ‹çš„æœ€ä½³æ–¹æ³•æ˜¯ç®€å•åœ°æŸ¥çœ‹è¿‡å»è¡Œä¹‹æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç„¶åå†æ¬¡é¢„æµ‹åŒæ ·çš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates that Model 1 distinguishes between the target levels most effectively.",
            "zh": "è¿™è¡¨æ˜æ¨¡å‹ 1 æœ€æœ‰æ•ˆåœ°åŒºåˆ†äº†ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "distance weighted k nearest neighbor, 194",
            "zh": "è·ç¦»åŠ æƒ k æœ€è¿‘é‚»ï¼Œ194"
        }
    },
    {
        "translation": {
            "en": "C.3â€…â€…(a) A continuous function in two variables, x and y; (b) the partial derivative of this function with respect to x; and (c) the partial derivative of this function with respect to y.",
            "zh": "C.3 ï¼ˆaï¼‰ xå’Œyä¸¤ä¸ªå˜é‡çš„è¿ç»­å‡½æ•°;ï¼ˆbï¼‰ è¯¥å‡½æ•°ç›¸å¯¹äº x çš„åå¯¼æ•°;ï¼ˆcï¼‰è¯¥å‡½æ•°ç›¸å¯¹äº y çš„åå¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The plot of the derivative of the logistic function in Figure 8.13[410] illustrates that as the value of z approaches 0 (from either side), the slope of the logistic graph increases until it reaches its maximum value at z = 0.0; consequently, we can calculate the maximum value of the derivative of the logistic function using Equation (8.15)[408] by setting z = 0.08",
            "zh": "å›¾ 8.13[410] ä¸­çš„é€»è¾‘å‡½æ•°å¯¼æ•°å›¾è¡¨æ˜ï¼Œå½“ z çš„å€¼æ¥è¿‘ 0ï¼ˆä»ä»»ä¸€ä¾§ï¼‰æ—¶ï¼Œé€»è¾‘å›¾çš„æ–œç‡å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ° z = 0.0 æ—¶çš„æœ€å¤§å€¼;å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ–¹ç¨‹ ï¼ˆ8.15ï¼‰[408] é€šè¿‡è®¾ç½® z = 0.08 æ¥è®¡ç®—é€»è¾‘å‡½æ•°å¯¼æ•°çš„æœ€å¤§å€¼"
        }
    },
    {
        "translation": {
            "en": "Using Equation (7.5)[316], we can formally define this point on the error surface as the point at which",
            "zh": "ä½¿ç”¨æ–¹ç¨‹ï¼ˆ7.5ï¼‰[316]ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¯¯å·®æ›²é¢ä¸Šçš„è¿™ä¸ªç‚¹æ­£å¼å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "We then iteratively make small adjustments to these weights based on the output of the error function, which leads to a journey down the error surface that eventually leads to the optimal set of weights.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®è¯¯å·®å‡½æ•°çš„è¾“å‡ºå¯¹è¿™äº›æƒé‡è¿›è¡Œè¿­ä»£è°ƒæ•´ï¼Œè¿™å¯¼è‡´äº†è¯¯å·®è¡¨é¢çš„å‘ä¸‹ç§»åŠ¨ï¼Œæœ€ç»ˆå¯¼è‡´æœ€ä½³æƒé‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The essence of the unsupervised scenario is that no ground truth existsâ€”we donâ€™t know what it is that we are looking for!",
            "zh": "æ— ç›‘ç£åœºæ™¯çš„æœ¬è´¨æ˜¯ä¸å­˜åœ¨åŸºæœ¬äº‹å®â€”â€”æˆ‘ä»¬ä¸çŸ¥é“æˆ‘ä»¬åœ¨å¯»æ‰¾ä»€ä¹ˆï¼"
        }
    },
    {
        "translation": {
            "en": "8.13â€…â€…â€…Plots of the logistic function and its derivative.",
            "zh": "8.13 é€»è¾‘å‡½æ•°åŠå…¶å¯¼æ•°å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network is built up by connecting lots of simple processing units, and therefore neural networks have a very flexible structure.",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡è¿æ¥è®¸å¤šç®€å•çš„å¤„ç†å•å…ƒæ¥æ„å»ºçš„ï¼Œå› æ­¤ç¥ç»ç½‘ç»œå…·æœ‰éå¸¸çµæ´»çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.6[325] shows a series of snapshots of the candidate models created at steps along this journey toward the best-fit model for this dataset.",
            "zh": "å›¾ 7.6[325] æ˜¾ç¤ºäº†åœ¨ä¸ºè¯¥æ•°æ®é›†æ‰¾åˆ°æœ€ä½³æ‹Ÿåˆæ¨¡å‹çš„è¿‡ç¨‹ä¸­åˆ›å»ºçš„å€™é€‰æ¨¡å‹çš„ä¸€ç³»åˆ—å¿«ç…§ã€‚"
        }
    },
    {
        "translation": {
            "en": "They discovered neurons in the brains of cats that activated only when a visual feature appeared at specific locations in the visual field.",
            "zh": "ä»–ä»¬å‘ç°çŒ«å¤§è„‘ä¸­çš„ç¥ç»å…ƒåªæœ‰åœ¨è§†é‡ä¸­çš„ç‰¹å®šä½ç½®å‡ºç°è§†è§‰ç‰¹å¾æ—¶æ‰ä¼šæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In all cases overall classification accuracy was used as the fitness function that drove the search.",
            "zh": "åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæ€»ä½“åˆ†ç±»å‡†ç¡®æ€§éƒ½è¢«ç”¨ä½œé©±åŠ¨æœç´¢çš„é€‚åº”åº¦å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.10â€…â€…â€…The confusion matrix for the 5-level two-stage model (classification accuracy: 79.410%, average class accuracy: 53.118%).",
            "zh": "13.10 äº”çº§ä¸¤é˜¶æ®µæ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š79.410%ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡ï¼š53.118%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1â€…â€…The members of a school basketball team. The height of each player is listed below the player. The dashed gray line shows the arithmetic mean of the playersâ€™ heights.",
            "zh": "A.1 å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ã€‚æ¯ä¸ªç©å®¶çš„èº«é«˜éƒ½åˆ—åœ¨ç©å®¶ä¸‹æ–¹ã€‚ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12",
            "zh": "å›¾ 5.12"
        }
    },
    {
        "translation": {
            "en": "In both of these diagrams, one path to an answer about the character on a card is 1 question long, one path is 2 questions long, and two paths are 3 questions long.",
            "zh": "åœ¨è¿™ä¸¤ä¸ªå›¾ä¸­ï¼Œå…³äºå¡ç‰‡ä¸Šå­—ç¬¦çš„ç­”æ¡ˆçš„ä¸€æ¡è·¯å¾„é•¿ 1 ä¸ªé—®é¢˜ï¼Œä¸€æ¡è·¯å¾„é•¿ 2 ä¸ªé—®é¢˜ï¼Œä¸¤æ¡è·¯å¾„é•¿ 3 ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. P(q[1],â€¦,q[m] | t = l), the conditional probability of the descriptive features of a query instance taking a specific set of values given that the target feature takes the level l",
            "zh": "3. Pï¼ˆq[1],...,q[m] | t = lï¼‰ï¼ŒæŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾é‡‡ç”¨ä¸€ç»„ç‰¹å®šå€¼çš„æ¡ä»¶æ¦‚ç‡ï¼Œå‡è®¾ç›®æ ‡ç‰¹å¾çš„çº§åˆ«ä¸º l"
        }
    },
    {
        "translation": {
            "en": "Done correctly, tailoring the architecture of a network can help the network to learn a particular task by guiding the network to learn useful functions for the target task.",
            "zh": "å¦‚æœåšå¾—æ­£ç¡®ï¼Œå®šåˆ¶ç½‘ç»œçš„æ¶æ„å¯ä»¥é€šè¿‡å¼•å¯¼ç½‘ç»œå­¦ä¹ ç›®æ ‡ä»»åŠ¡çš„æœ‰ç”¨åŠŸèƒ½æ¥å¸®åŠ©ç½‘ç»œå­¦ä¹ ç‰¹å®šä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "one-class classification, 235",
            "zh": "ä¸€ç±»åˆ†ç±»ï¼Œ235"
        }
    },
    {
        "translation": {
            "en": "If we can find the global minimum of the error surface, we can find the set of weights defining the model that best fits the training dataset.",
            "zh": "å¦‚æœæˆ‘ä»¬èƒ½æ‰¾åˆ°è¯¯å·®é¢çš„å…¨å±€æœ€å°å€¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ‰¾åˆ°å®šä¹‰æœ€é€‚åˆè®­ç»ƒæ•°æ®é›†çš„æ¨¡å‹çš„æƒé‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Theorem of Total Probability, 245, 249â€“251, 757, 763, 764",
            "zh": "æ€»æ¦‚ç‡å®šç†ï¼Œ 245ï¼Œ 249â€“251ï¼Œ 757ï¼Œ 763ï¼Œ 764"
        }
    },
    {
        "translation": {
            "en": "Sometimes a feature is actually continuous but in practice can assume only a small range of valuesâ€”for example, the number of children a person has.",
            "zh": "æœ‰æ—¶ï¼Œä¸€ä¸ªç‰¹å¾å®é™…ä¸Šæ˜¯è¿ç»­çš„ï¼Œä½†å®é™…ä¸Šåªèƒ½å‡è®¾ä¸€ä¸ªå°èŒƒå›´çš„å€¼ï¼Œä¾‹å¦‚ï¼Œä¸€ä¸ªäººçš„å­©å­æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that in Section 5.2.2[184] we defined four criteria that a metric must satisfy: non-negativity, identity, symmetry, and triangular inequality.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œåœ¨ç¬¬ 5.2.2 èŠ‚[184]ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†åº¦é‡å¿…é¡»æ»¡è¶³çš„å››ä¸ªæ ‡å‡†ï¼šéè´Ÿæ€§ã€æ’ç­‰æ€§ã€å¯¹ç§°æ€§å’Œä¸‰è§’ä¸ç­‰å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the logistic function (Equation (7.25)[342]) for the range of values [âˆ’10, 10]; and (b) the logistic decision surface that results from training a model to represent the generators dataset given in Table 7.6[339] (note that the data has been normalized to the range [âˆ’1, 1]).",
            "zh": "ï¼ˆaï¼‰ å€¼èŒƒå›´[âˆ’10,10]çš„é€»è¾‘å‡½æ•°å›¾ï¼ˆç­‰å¼ï¼ˆ7.25ï¼‰[342]ï¼‰;ï¼ˆbï¼‰è®­ç»ƒæ¨¡å‹ä»¥è¡¨ç¤ºè¡¨7.6[339]ä¸­ç»™å‡ºçš„ç”Ÿæˆå™¨æ•°æ®é›†æ‰€å¾—åˆ°çš„é€»è¾‘å†³ç­–é¢ï¼ˆè¯·æ³¨æ„ï¼Œæ•°æ®å·²å½’ä¸€åŒ–ä¸ºèŒƒå›´[âˆ’1,1]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case there is nothing wrong, and the feature should be left alone.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ²¡æœ‰ä»»ä½•é—®é¢˜ï¼Œåº”è¯¥ä¿ç•™è¯¥åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term we want to define is the rate of change of the error of a neuron (a model) with respect to its activation (output): âˆ‚â„°/âˆ‚ak. For this we need only the first term from the product in Equation (8.18)[410]10",
            "zh": "æˆ‘ä»¬è¦å®šä¹‰çš„æœ¯è¯­æ˜¯ç¥ç»å…ƒï¼ˆæ¨¡å‹ï¼‰ç›¸å¯¹äºå…¶æ¿€æ´»ï¼ˆè¾“å‡ºï¼‰çš„è¯¯å·®å˜åŒ–ç‡ï¼šâˆ‚E/âˆ‚akã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦æ–¹ç¨‹ï¼ˆ8.18ï¼‰[410]10ä¸­ä¹˜ç§¯çš„ç¬¬ä¸€é¡¹"
        }
    },
    {
        "translation": {
            "en": "A predictive model can be trained to learn the action-value function",
            "zh": "å¯ä»¥è®­ç»ƒé¢„æµ‹æ¨¡å‹æ¥å­¦ä¹ åŠ¨ä½œ-ä»·å€¼å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the continuous BLANDCHROMATIN feature and the target feature CLASS.",
            "zh": "ï¼ˆbï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†è¿ç»­ BLANDCHROMATIN ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ CLASS ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.5[324] shows the journey across the error surface that is taken by the gradient descent algorithm when training this model.",
            "zh": "å›¾ 7.5[324] æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™ç®—æ³•åœ¨è®­ç»ƒè¯¥æ¨¡å‹æ—¶ç©¿è¶Šè¯¯å·®è¡¨é¢çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A probability distribution is a data structure that describes the probability of each possible value a feature can take.",
            "zh": "æ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸€ç§æ•°æ®ç»“æ„ï¼Œç”¨äºæè¿°è¦ç´ å¯ä»¥é‡‡ç”¨çš„æ¯ä¸ªå¯èƒ½å€¼çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of a confounding feature, a feature that influences two others and so leads to the appearance of a causal relationship.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªæ··æ·†ç‰¹å¾çš„ä¾‹å­ï¼Œè¿™ä¸ªç‰¹å¾ä¼šå½±å“å¦å¤–ä¸¤ä¸ªç‰¹å¾ï¼Œä»è€Œå¯¼è‡´å› æœå…³ç³»çš„å‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another way to address the problem of how to set k is to use a weighted k nearest neighbor approach.",
            "zh": "è§£å†³å¦‚ä½•è®¾ç½® k é—®é¢˜çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨åŠ æƒ k æœ€è¿‘é‚»æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This section describes the most important performance measures for evaluating the performance of models with categorical target features.",
            "zh": "æœ¬èŠ‚ä»‹ç»ç”¨äºè¯„ä¼°å…·æœ‰åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„æ¨¡å‹æ€§èƒ½çš„æœ€é‡è¦æ€§èƒ½åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.3.1â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "2.3.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "4.5â€…â€…â€…The entropy of different sets of playing cards measured in bits.",
            "zh": "4.5 ä»¥æ¯”ç‰¹ä¸ºå•ä½æµ‹é‡çš„ä¸åŒæ‰‘å…‹ç‰Œç»„çš„ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for the same example, the target one-hot encoding for Neuron 10 is 1, and so we use Equation (8.80)[469] to calculate the Î´ for neuron 10 in this example.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºåŒä¸€ä¸ªä¾‹å­ï¼Œç¥ç»å…ƒ 10 çš„ç›®æ ‡å•çƒ­ç¼–ç æ˜¯ 1ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨å…¬å¼ ï¼ˆ8.80ï¼‰[469] æ¥è®¡ç®—æœ¬ä¾‹ä¸­ç¥ç»å…ƒ 10 çš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consider the task of predicting the likelihood that a customer will buy a new product based on past shopping behavior: features describing the past shopping behavior are calculated over the observation period, while the outcome period is the time during which we observe whether the customer bought the product.",
            "zh": "è€ƒè™‘æ ¹æ®è¿‡å»çš„è´­ç‰©è¡Œä¸ºé¢„æµ‹å®¢æˆ·è´­ä¹°æ–°äº§å“çš„å¯èƒ½æ€§çš„ä»»åŠ¡ï¼šæè¿°è¿‡å»è´­ç‰©è¡Œä¸ºçš„ç‰¹å¾æ˜¯åœ¨è§‚å¯ŸæœŸå†…è®¡ç®—çš„ï¼Œè€Œç»“æœæœŸæ˜¯æˆ‘ä»¬è§‚å¯Ÿå®¢æˆ·æ˜¯å¦è´­ä¹°äº§å“çš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "DOSE1",
            "zh": "å‰‚é‡1"
        }
    },
    {
        "translation": {
            "en": "0.4932",
            "zh": "0.4932"
        }
    },
    {
        "translation": {
            "en": "RMSE, 577",
            "zh": "RMSEï¼Œ577"
        }
    },
    {
        "translation": {
            "en": "Using Equation (9.12)[552], we can calculate the average class accuracy for this problem:",
            "zh": "ä½¿ç”¨æ–¹ç¨‹ï¼ˆ9.12ï¼‰[552]ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºè¿™ä¸ªé—®é¢˜çš„å¹³å‡ç±»å‡†ç¡®ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "14.2â€…â€…â€…A taxonomy of models based on the parametric versus non-parametric and generative versus discriminative distinctions.",
            "zh": "14.2 åŸºäºå‚æ•°ä¸éå‚æ•°ä»¥åŠç”Ÿæˆä¸åˆ¤åˆ«åŒºåˆ«çš„æ¨¡å‹åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The revenue commission currently selects companies for audit at random.",
            "zh": "æ”¶å…¥å§”å‘˜ä¼šç›®å‰éšæœºé€‰æ‹©å…¬å¸è¿›è¡Œå®¡è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We define the separating hyperplane in the same way that we did at the beginning of the discussion of logistic regression",
            "zh": "æˆ‘ä»¬å®šä¹‰åˆ†ç¦»è¶…å¹³é¢çš„æ–¹å¼ä¸æˆ‘ä»¬åœ¨è®¨è®ºé€»è¾‘å›å½’å¼€å§‹æ—¶æ‰€åšçš„ç›¸åŒ"
        }
    },
    {
        "translation": {
            "en": "2. The probability of a test-statistic value as big as or greater than the one computed being the result of chance is calculated. This probability is called a p-value.",
            "zh": "2. è®¡ç®—æ£€éªŒç»Ÿè®¡é‡å€¼ç­‰äºæˆ–å¤§äºè®¡ç®—å€¼çš„æ¦‚ç‡æ˜¯å¶ç„¶çš„ç»“æœã€‚è¿™ç§æ¦‚ç‡ç§°ä¸º p å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in financial credit scoring, the Gini coefficient is almost always used to evaluate model performance.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨é‡‘èä¿¡ç”¨è¯„åˆ†ä¸­ï¼ŒåŸºå°¼ç³»æ•°å‡ ä¹æ€»æ˜¯ç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "the more equal a society, the higher the investment that society will make in health and education, and this in turn results in a lower level of corruption",
            "zh": "ä¸€ä¸ªç¤¾ä¼šè¶Šå¹³ç­‰ï¼Œç¤¾ä¼šåœ¨å«ç”Ÿå’Œæ•™è‚²æ–¹é¢çš„æŠ•èµ„å°±è¶Šé«˜ï¼Œè¿™åè¿‡æ¥åˆå¯¼è‡´è…è´¥ç¨‹åº¦é™ä½"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering approach is to be applied to this dataset with k = 3 and using Euclidean distance.",
            "zh": "k-means èšç±»æ–¹æ³•å°†åº”ç”¨äº k = 3 å¹¶ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.1â€…â€…â€…Visualizing Relationships between Features",
            "zh": "3.5.1 å¯è§†åŒ–è¦ç´ ä¹‹é—´çš„å…³ç³»"
        }
    },
    {
        "translation": {
            "en": "We saw some of these techniques in Section 7.4.1[332] when we examined the importance of the different descriptive features in a linear regression model through an analysis of the model weights.",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬ 7.4.1 èŠ‚[332]ä¸­çœ‹åˆ°äº†å…¶ä¸­ä¸€äº›æŠ€æœ¯ï¼Œå½“æ—¶æˆ‘ä»¬é€šè¿‡åˆ†ææ¨¡å‹æƒé‡æ¥æ£€æŸ¥çº¿æ€§å›å½’æ¨¡å‹ä¸­ä¸åŒæè¿°æ€§ç‰¹å¾çš„é‡è¦æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.2",
            "zh": "å›¾ 11.2"
        }
    },
    {
        "translation": {
            "en": "6. See Appendix C[765].",
            "zh": "[6]è§é™„å½•C[765]ã€‚"
        }
    },
    {
        "translation": {
            "en": "black box model, 739",
            "zh": "é»‘åŒ£å­æ¨¡å‹ï¼Œ739"
        }
    },
    {
        "translation": {
            "en": "There is always one dimension for every descriptive feature in a dataset.",
            "zh": "æ•°æ®é›†ä¸­çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾å§‹ç»ˆæœ‰ä¸€ä¸ªç»´åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4â€…â€…â€…Information gain for each descriptive feature as a predictor of membership of each cluster based on the clustering of the mobile phone customer dataset in Table 10.1[604] found using k-means clustering (k = 3).",
            "zh": "10.4 æ ¹æ®è¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„èšç±»ï¼Œä½¿ç”¨kå‡å€¼èšç±»ï¼ˆk = 3ï¼‰æ‰¾åˆ°æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œä½œä¸ºæ¯ä¸ªèšç±»æˆå‘˜çš„é¢„æµ‹å› å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The proportion for each level is calculated by dividing the frequency count for that level by the total sample size.",
            "zh": "æ¯ä¸ªæ°´å¹³çš„æ¯”ä¾‹æ˜¯é€šè¿‡å°†è¯¥æ°´å¹³çš„é¢‘ç‡è®¡æ•°é™¤ä»¥æ€»æ ·æœ¬æ•°é‡æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rossâ€™s next task was to fully assess the current situation within AT.",
            "zh": "ç½—æ–¯çš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯å…¨é¢è¯„ä¼°ATå†…éƒ¨çš„ç°çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the joint probability distribution for the four binary features from Table 6.1[246] (HEADACHE, FEVER, VOMITING, and MENINGITIS) is written3",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨ 6.1[246]ï¼ˆå¤´ç—›ã€å‘çƒ§ã€å‘•åå’Œè„‘è†œç‚ï¼‰ä¸­å››ä¸ªäºŒå…ƒç‰¹å¾çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹3"
        }
    },
    {
        "translation": {
            "en": "Once the âˆ‚ak/âˆ‚zk term has been calculated for a neuron, the other term needed to calculate the Î´ for a neuron k using Equation (8.14)[408] is the rate of change of the error of the network with respect to changes in the activation of the neuron: âˆ‚â„°/âˆ‚ak. As noted previously, the calculation of this term is different for output neurons and hidden neurons.",
            "zh": "ä¸€æ—¦è®¡ç®—äº†ç¥ç»å…ƒçš„ âˆ‚ak/âˆ‚zk é¡¹ï¼Œä½¿ç”¨å…¬å¼ ï¼ˆ8.14ï¼‰[408] è®¡ç®—ç¥ç»å…ƒ k Î´æ‰€éœ€çš„å¦ä¸€ä¸ªé¡¹æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒæ¿€æ´»å˜åŒ–çš„å˜åŒ–ç‡ï¼šâˆ‚E/âˆ‚akã€‚å¦‚å‰æ‰€è¿°ï¼Œå¯¹äºè¾“å‡ºç¥ç»å…ƒå’Œéšè—ç¥ç»å…ƒï¼Œè¯¥é¡¹çš„è®¡ç®—æ˜¯ä¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "OUTCOME",
            "zh": "ç»“æœ"
        }
    },
    {
        "translation": {
            "en": "30. If there are one or more zero entries in the CPTs, then the Markov chain may still be ergodic, but it is non-trivial to prove ergodicity in these cases.",
            "zh": "30. å¦‚æœ CPT ä¸­æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªé›¶æ¡ç›®ï¼Œé‚£ä¹ˆé©¬å°”å¯å¤«é“¾å¯èƒ½ä»ç„¶æ˜¯éå†çš„ï¼Œä½†åœ¨è¿™äº›æƒ…å†µä¸‹è¯æ˜éå†æ€§å¹¶éå¾®ä¸è¶³é“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, Equation (8.117)[512] ensures that the vector of activations that is propagated to the output layer is the same vector that is propagated to the next time-step as the LSTM hidden state.",
            "zh": "æœ€åï¼Œæ–¹ç¨‹ï¼ˆ8.117ï¼‰[512]ç¡®ä¿ä¼ æ’­åˆ°è¾“å‡ºå±‚çš„æ¿€æ´»å‘é‡ä¸ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„å‘é‡ä¸LSTMéšè—çŠ¶æ€ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.5",
            "zh": "å›¾ 13.5"
        }
    },
    {
        "translation": {
            "en": "When agent decisions are allowed, leading to a Markov decision process (MDP), then the dynamics of an environment can be captured in a set of transition matrices, one for each action. For example",
            "zh": "å½“å…è®¸æ™ºèƒ½ä½“å†³ç­–æ—¶ï¼Œå¯¼è‡´é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ ï¼ˆMDPï¼‰ï¼Œåˆ™å¯ä»¥åœ¨ä¸€ç»„è½¬æ¢çŸ©é˜µä¸­æ•è·ç¯å¢ƒçš„åŠ¨æ€ï¼Œæ¯ä¸ªæ“ä½œä¸€ä¸ªã€‚ä¾‹å¦‚"
        }
    },
    {
        "translation": {
            "en": "A specific type of learning, called inductive learning, is used, where learning entails inducing a general rule from a set of specific instances.",
            "zh": "ä½¿ç”¨ä¸€ç§ç§°ä¸ºå½’çº³å­¦ä¹ çš„ç‰¹å®šç±»å‹çš„å­¦ä¹ ï¼Œå…¶ä¸­å­¦ä¹ éœ€è¦ä»ä¸€ç»„ç‰¹å®šå®ä¾‹ä¸­å½’çº³å‡ºä¸€èˆ¬è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information gain measure described in Section 4.2.3[127] uses entropy to judge the impurity of the partitions that result from splitting a dataset using a particular feature.",
            "zh": "ç¬¬4.2.3èŠ‚[127]ä¸­æè¿°çš„ä¿¡æ¯å¢ç›Šåº¦é‡ä½¿ç”¨ç†µæ¥åˆ¤æ–­ä½¿ç”¨ç‰¹å®šç‰¹å¾æ‹†åˆ†æ•°æ®é›†æ‰€å¯¼è‡´çš„åˆ†åŒºçš„æ‚è´¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we want to model the behavior of a die using probability, we would begin by creating a random variable, let us call it X, that has a domain equal to the set of possible outcomes when we roll the die, namely, the set .",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨æ¦‚ç‡å¯¹éª°å­çš„è¡Œä¸ºè¿›è¡Œå»ºæ¨¡ï¼Œæˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ªéšæœºå˜é‡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º Xï¼Œå®ƒæœ‰ä¸€ä¸ªåŸŸç­‰äºæˆ‘ä»¬æ·éª°å­æ—¶å¯èƒ½ç»“æœçš„é›†åˆï¼Œå³é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15(a)[569] graphs the gain for each decile to produce a gain chart. We can see from this chart that the gain is higher for the lower deciles, which contain the instances with the highest scores. This is indicative of the fact that the model is performing reasonably well. Cumulative gain is calculated as the fraction of the total number of positive instances in a test set identified up to a particular decile (i.e., in that decile and all deciles below it):",
            "zh": "å›¾9.15ï¼ˆaï¼‰[569]ç»˜åˆ¶äº†æ¯ä¸ªååˆ†ä½æ•°çš„å¢ç›Šï¼Œä»¥ç”Ÿæˆå¢ç›Šå›¾ã€‚ä»è¿™å¼ å›¾è¡¨ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä½ååˆ†ä½æ•°çš„å¢ç›Šæ›´é«˜ï¼Œå…¶ä¸­åŒ…å«å¾—åˆ†æœ€é«˜çš„å®ä¾‹ã€‚è¿™è¡¨æ˜è¯¥æ¨¡å‹çš„æ€§èƒ½ç›¸å½“ä¸é”™ã€‚ç´¯ç§¯å¢ç›Šè®¡ç®—ä¸ºæµ‹è¯•é›†ä¸­è¯†åˆ«åˆ°ç‰¹å®šååˆ†ä½æ•°ï¼ˆå³åœ¨è¯¥ååˆ†ä½æ•°åŠå…¶ä»¥ä¸‹çš„æ‰€æœ‰ååˆ†ä½æ•°ï¼‰çš„é˜³æ€§å®ä¾‹æ€»æ•°çš„åˆ†æ•°ï¼š"
        }
    },
    {
        "translation": {
            "en": "the rate of change of the error of the network with respect to changes in the activation function (âˆ‚â„°/âˆ‚ai).",
            "zh": "ç½‘ç»œè¯¯å·®ç›¸å¯¹äºæ¿€æ´»å‡½æ•°å˜åŒ–çš„å˜åŒ–ç‡ ï¼ˆâˆ‚E/âˆ‚aiï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The t-statistic for this test is calculated as follows:",
            "zh": "æ­¤æ£€éªŒçš„ t ç»Ÿè®¡é‡è®¡ç®—å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The set of assumptions that defines the model selection criteria of a machine learning algorithm is known as the inductive bias6 of the machine learning algorithm.",
            "zh": "å®šä¹‰æœºå™¨å­¦ä¹ ç®—æ³•æ¨¡å‹é€‰æ‹©æ ‡å‡†çš„ä¸€ç»„å‡è®¾ç§°ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•çš„å½’çº³åå·®6ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both these speedups enable us to remove expensive for loops from the implementation and training of a network: the first removes a for loop over the neurons in a layer, and the second removes a for loop over the examples in a dataset.",
            "zh": "è¿™ä¸¤ç§åŠ é€Ÿéƒ½ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»ç½‘ç»œçš„å®ç°å’Œè®­ç»ƒä¸­æ¶ˆé™¤æ˜‚è´µçš„forå¾ªç¯ï¼šç¬¬ä¸€ä¸ªåˆ é™¤äº†å±‚ä¸­ç¥ç»å…ƒä¸Šçš„forå¾ªç¯ï¼Œç¬¬äºŒä¸ªåˆ é™¤äº†æ•°æ®é›†ä¸­ç¤ºä¾‹ä¸Šçš„forå¾ªç¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "We start by discussing decision trees, the fundamental structure used in information-based machine learning, before presenting the fundamental measures of information content that are used: entropy and information gain.",
            "zh": "æˆ‘ä»¬é¦–å…ˆè®¨è®ºå†³ç­–æ ‘ï¼Œå³åŸºäºä¿¡æ¯çš„æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨çš„åŸºæœ¬ç»“æ„ï¼Œç„¶åä»‹ç»æ‰€ä½¿ç”¨çš„ä¿¡æ¯å†…å®¹çš„åŸºæœ¬åº¦é‡ï¼šç†µå’Œä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This idea of using a validation set to identify when overfitting occurs is illustrated in Figure 9.3[542] in Chapter 9[533] in which we discuss the use of a validation set in the general setting of designing a model evaluation experiment.",
            "zh": "ç¬¬9ç« [533]çš„å›¾9.3[542]è¯´æ˜äº†ä½¿ç”¨éªŒè¯é›†æ¥è¯†åˆ«ä½•æ—¶å‘ç”Ÿè¿‡æ‹Ÿåˆçš„æƒ³æ³•ï¼Œå…¶ä¸­æˆ‘ä»¬è®¨è®ºäº†åœ¨è®¾è®¡æ¨¡å‹è¯„ä¼°å®éªŒçš„ä¸€èˆ¬è®¾ç½®ä¸­ä½¿ç”¨éªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The three different arrangements of the magnetic letters made by the Murphy children on the Murphy family refrigerator.",
            "zh": "å¢¨è²å®¶å†°ç®±ä¸Šå¢¨è²å®¶å†°ç®±ä¸Šä¸‰ç§ä¸åŒçš„ç£æ€§å­—æ¯æ’åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we look at extensions and modifications of the k-means clustering algorithm that answer these questions and address these shortcomings.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ k å‡å€¼èšç±»ç®—æ³•çš„æ‰©å±•å’Œä¿®æ”¹ï¼Œä»¥å›ç­”è¿™äº›é—®é¢˜å¹¶è§£å†³è¿™äº›ç¼ºç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Given this context, calculate the vector of error gradients with respect to the input hxt for the forget gate sigmoid layer.",
            "zh": "ï¼ˆbï¼‰ åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ï¼Œè®¡ç®—ç›¸å¯¹äºå¿˜è®°é—¨ S å½¢ç»“è‚ å±‚çš„è¾“å…¥ hxt çš„è¯¯å·®æ¢¯åº¦å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This experiment showed behavior uncharacteristic of X-rays, which Professor Blondlot interpreted to mean that another, different type of electromagnetic radiation must exist.",
            "zh": "è¯¥å®éªŒæ˜¾ç¤ºå‡ºXå°„çº¿çš„ç‰¹å¾ï¼ŒBlondlotæ•™æˆå°†å…¶è§£é‡Šä¸ºå¿…é¡»å­˜åœ¨å¦ä¸€ç§ä¸åŒç±»å‹çš„ç”µç£è¾å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the spectrograph data collected by the SDSS telescopes was not nearly as extensive as the camera imaging data collectedâ€”while there was imaging data for millions of galaxies, there were spectrograms for only hundreds of thousands.",
            "zh": "é¦–å…ˆï¼ŒSDSSæœ›è¿œé•œæ”¶é›†çš„å…‰è°±ä»ªæ•°æ®å¹¶ä¸åƒæ”¶é›†çš„ç›¸æœºæˆåƒæ•°æ®é‚£ä¹ˆå¹¿æ³› - è™½ç„¶æœ‰æ•°ç™¾ä¸‡ä¸ªæ˜Ÿç³»çš„æˆåƒæ•°æ®ï¼Œä½†åªæœ‰æ•°åä¸‡ä¸ªæ˜Ÿç³»çš„å…‰è°±å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.10â€…â€…â€…Definitions of some standard probability distributions.",
            "zh": "6.10 ä¸€äº›æ ‡å‡†æ¦‚ç‡åˆ†å¸ƒçš„å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A diagram of the CRISP-DM process that shows the six key phases and indicates the important relationships between them. This figure is based on Figure 2 of Wirth and Hipp (2000).",
            "zh": "CRISP-DM è¿‡ç¨‹çš„å›¾è¡¨ï¼Œæ˜¾ç¤ºäº†å…­ä¸ªå…³é”®é˜¶æ®µå¹¶æŒ‡å‡ºå®ƒä»¬ä¹‹é—´çš„é‡è¦å…³ç³»ã€‚è¯¥æ•°å­—åŸºäºWirthå’ŒHippï¼ˆ2000ï¼‰çš„å›¾2ã€‚"
        }
    },
    {
        "translation": {
            "en": "What these examples demonstrate is that when we are trying to decide whether a query belongs to a group, we need to consider not only the central tendency of the group, but also how spread out the members in a group are.",
            "zh": "è¿™äº›ç¤ºä¾‹è¡¨æ˜ï¼Œå½“æˆ‘ä»¬è¯•å›¾ç¡®å®šæŸ¥è¯¢æ˜¯å¦å±äºæŸä¸ªç»„æ—¶ï¼Œæˆ‘ä»¬ä¸ä»…éœ€è¦è€ƒè™‘è¯¥ç»„çš„ä¸­å¿ƒè¶‹åŠ¿ï¼Œè¿˜éœ€è¦è€ƒè™‘ç»„ä¸­æˆå‘˜çš„åˆ†å¸ƒç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) An equal-width binning using 5 bins.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨ 5 ä¸ªç®±çš„ç­‰å®½åˆ†ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn felt that the important domain concepts were likely to be the target (galaxy type), galaxy appearance measures (e.g., color), spectrography information (e.g., red shift), and position information (the position of each object in the night sky was also available from the SDSS pipeline).",
            "zh": "Jocelynè®¤ä¸ºï¼Œé‡è¦çš„é¢†åŸŸæ¦‚å¿µå¯èƒ½æ˜¯ç›®æ ‡ï¼ˆæ˜Ÿç³»ç±»å‹ï¼‰ã€æ˜Ÿç³»å¤–è§‚æµ‹é‡ï¼ˆä¾‹å¦‚ï¼Œé¢œè‰²ï¼‰ã€å…‰è°±ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œçº¢ç§»ï¼‰å’Œä½ç½®ä¿¡æ¯ï¼ˆæ¯ä¸ªç‰©ä½“åœ¨å¤œç©ºä¸­çš„ä½ç½®ä¹Ÿå¯ä»¥ä»SDSSç®¡é“è·å¾—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5â€…â€…â€…Advanced Data Exploration",
            "zh": "3.5 é«˜çº§æ•°æ®æ¢ç´¢"
        }
    },
    {
        "translation": {
            "en": "Figure 4.6(b)[125] shows the impact of this.",
            "zh": "å›¾4.6ï¼ˆbï¼‰[125]æ˜¾ç¤ºäº†è¿™ç§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The two steps in supervised machine learning: (a) learning and (b) predicting.",
            "zh": "ç›‘ç£æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªæ­¥éª¤ï¼šï¼ˆaï¼‰å­¦ä¹ å’Œï¼ˆbï¼‰é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15",
            "zh": "å›¾ 10.15"
        }
    },
    {
        "translation": {
            "en": "and the probability of a patient having meningitis given that we know that the patient has a headache is",
            "zh": "å¦‚æœæˆ‘ä»¬çŸ¥é“æ‚£è€…å¤´ç—›ï¼Œæ‚£è€…æ‚£è„‘è†œç‚çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "Multiplying a number by a number less than 1 makes the number smaller.",
            "zh": "å°†ä¸€ä¸ªæ•°å­—ä¹˜ä»¥å°äº 1 çš„æ•°å­—ä¼šä½¿è¯¥æ•°å­—å˜å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "mini-batch gradient descent, 417, 671",
            "zh": "å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œ417,671"
        }
    },
    {
        "translation": {
            "en": "As part of the process of agreeing on the solution to pursue, the analytics practitioner must agree with the business, as far as possible, on the goals that will define a successful model implementation. These goals could be specified in terms of the required accuracy of the model and/or the impact of the model on the business.",
            "zh": "ä½œä¸ºå°±è¦è¿½æ±‚çš„è§£å†³æ–¹æ¡ˆè¾¾æˆä¸€è‡´çš„è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œåˆ†æä»ä¸šè€…å¿…é¡»å°½å¯èƒ½ä¸ä¸šåŠ¡éƒ¨é—¨å°±å®šä¹‰æˆåŠŸæ¨¡å‹å®æ–½çš„ç›®æ ‡è¾¾æˆä¸€è‡´ã€‚è¿™äº›ç›®æ ‡å¯ä»¥æ ¹æ®æ¨¡å‹æ‰€éœ€çš„å‡†ç¡®æ€§å’Œ/æˆ–æ¨¡å‹å¯¹ä¸šåŠ¡çš„å½±å“æ¥æŒ‡å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The vector of weighted sums for a layer of neurons is denoted by z(k) where k identifies the layer.",
            "zh": "ç¥ç»å…ƒå±‚çš„åŠ æƒå’Œå‘é‡ç”¨ zï¼ˆkï¼‰ è¡¨ç¤ºï¼Œå…¶ä¸­ k è¡¨ç¤ºè¯¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "So if a prediction model is trained to distinguish between lions, frogs, and ducks, the model will classify every query instance as being either a lion, a frog, or a duckâ€”even if the query is actually a platypus.",
            "zh": "å› æ­¤ï¼Œå¦‚æœè®­ç»ƒé¢„æµ‹æ¨¡å‹æ¥åŒºåˆ†ç‹®å­ã€é’è›™å’Œé¸­å­ï¼Œåˆ™è¯¥æ¨¡å‹ä¼šå°†æ¯ä¸ªæŸ¥è¯¢å®ä¾‹åˆ†ç±»ä¸ºç‹®å­ã€é’è›™æˆ–é¸­å­ï¼Œå³ä½¿æŸ¥è¯¢å®é™…ä¸Šæ˜¯é¸­å˜´å…½ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, not all the domain concepts in this scenario are time dependent.",
            "zh": "ä½†æ˜¯ï¼Œå¹¶éæ­¤æ–¹æ¡ˆä¸­çš„æ‰€æœ‰åŸŸæ¦‚å¿µéƒ½ä¸æ—¶é—´ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the combination of the translations that would be applied by including bias terms in each layer can be replaced by applying a single translation (or single bias term) at the end of the processing.",
            "zh": "æ­¤å¤–ï¼Œé€šè¿‡åœ¨æ¯ä¸€å±‚ä¸­åŒ…å«åç½®é¡¹æ¥åº”ç”¨çš„å¹³ç§»ç»„åˆå¯ä»¥é€šè¿‡åœ¨å¤„ç†ç»“æŸæ—¶åº”ç”¨å•ä¸ªå¹³ç§»ï¼ˆæˆ–å•ä¸ªåç½®é¡¹ï¼‰æ¥æ›¿æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "A data quality report for a subset of the features in the SDSS ABT.",
            "zh": "SDSS ABT ä¸­è¦ç´ å­é›†çš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This figure shows the weights on each connection and for each neuron shows the weighted sum z calculated by that neuron (the number on the left of the neuron) and the activation z for the neuron (the number on the right of the neuron).",
            "zh": "è¯¥å›¾æ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥çš„æƒé‡ï¼Œæ¯ä¸ªç¥ç»å…ƒæ˜¾ç¤ºäº†ç”±è¯¥ç¥ç»å…ƒè®¡ç®—çš„åŠ æƒæ€»å’Œzï¼ˆç¥ç»å…ƒå·¦ä¾§çš„æ•°å­—ï¼‰å’Œç¥ç»å…ƒçš„æ¿€æ´»zï¼ˆç¥ç»å…ƒå³ä¾§çš„æ•°å­—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This difference illustrates the effect of the metric used to select which feature to split on during tree construction.",
            "zh": "è¿™ç§å·®å¼‚è¯´æ˜äº†ç”¨äºé€‰æ‹©åœ¨æ ‘æ„é€ æœŸé—´è¦åˆ†å‰²çš„è¦ç´ çš„æŒ‡æ ‡çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Q values of the actions available to the agent from state 0-2 are Q(0-2,up) = 0.223, Q(0-2,down) = 0.582, Q(0-2,left) = 0.672, and Q(0-2,right) = 0.084 (based on Table 11.3[661]).",
            "zh": "ä»çŠ¶æ€ 0-2 ä¸­ï¼Œä»£ç†å¯ç”¨çš„æ“ä½œçš„ Q å€¼ä¸º Qï¼ˆ0-2ï¼Œupï¼‰ = 0.223ã€Qï¼ˆ0-2ï¼Œdownï¼‰ = 0.582ã€Qï¼ˆ0-2ï¼Œleftï¼‰ = 0.672 å’Œ Qï¼ˆ0-2ï¼Œrightï¼‰ = 0.084ï¼ˆåŸºäºè¡¨ 11.3[661]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, we should smooth the resulting probabilities.",
            "zh": "åŒæ ·ï¼Œæˆ‘ä»¬åº”è¯¥å¹³æ»‘å¾—åˆ°çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.23â€…â€…â€…Different margins that satisfy the constraint in Equation (7.44)[364], the instances that define the margin are highlighted in each case; (b) shows the maximum margin and also shows two query instances represented as black dots.",
            "zh": "7.23 æ»¡è¶³ç­‰å¼ï¼ˆ7.44ï¼‰[364]ä¸­çº¦æŸæ¡ä»¶çš„ä¸åŒè¾¹è·ï¼Œå®šä¹‰è¾¹è·çš„å®ä¾‹åœ¨æ¯ç§æƒ…å†µä¸‹éƒ½çªå‡ºæ˜¾ç¤º;ï¼ˆbï¼‰ æ˜¾ç¤ºæœ€å¤§è¾¹è·ï¼Œå¹¶æ˜¾ç¤ºä¸¤ä¸ªè¡¨ç¤ºä¸ºé»‘ç‚¹çš„æŸ¥è¯¢å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most common way to do this is to define an arbitrary order over the descriptive features before we begin building the tree.",
            "zh": "æœ€å¸¸è§çš„æ–¹æ³•æ˜¯åœ¨å¼€å§‹æ„å»ºæ ‘ä¹‹å‰ï¼Œåœ¨æè¿°æ€§ç‰¹å¾ä¸Šå®šä¹‰ä»»æ„é¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that we are training the LSTM network using backpropagation through time, then for each time-step, we calculate the update for each weight by multiplying the Î´ for the neuron that uses the weight by the input value that weight was applied to, and then we sum these weight updates across the time-steps. The weight is then updated using the summed weight update. For example, the update for the weights in W(f) would be calculated as follows:",
            "zh": "å‡è®¾æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨éšæ—¶é—´åå‘ä¼ æ’­æ¥è®­ç»ƒ LSTM ç½‘ç»œï¼Œé‚£ä¹ˆå¯¹äºæ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬é€šè¿‡å°†ä½¿ç”¨æƒé‡çš„ç¥ç»å…ƒçš„Î´ä¹˜ä»¥æ–½åŠ æƒé‡çš„è¾“å…¥å€¼æ¥è®¡ç®—æ¯ä¸ªæƒé‡çš„æ›´æ–°ï¼Œç„¶åæˆ‘ä»¬å°†è¿™äº›æƒé‡æ›´æ–°ç›¸åŠ ã€‚ç„¶åä½¿ç”¨æ€»å’Œçš„æƒé‡æ›´æ–°æ›´æ–°æƒé‡ã€‚ä¾‹å¦‚ï¼ŒWï¼ˆfï¼‰ ä¸­æƒé‡çš„æ›´æ–°å°†æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "To build a predictive model, we need a large dataset of historical examples of the scenario for which we will make predictions.",
            "zh": "ä¸ºäº†æ„å»ºé¢„æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æˆ‘ä»¬å°†è¦è¿›è¡Œé¢„æµ‹çš„åœºæ™¯çš„å†å²ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "1,800",
            "zh": "1,800"
        }
    },
    {
        "translation": {
            "en": "For example, f(x,y) = x2 âˆ’ y2 + 2x + 4y âˆ’ xy + 2 is a function defined in terms of two variables, x and y.",
            "zh": "ä¾‹å¦‚ï¼Œfï¼ˆxï¼Œyï¼‰ = x2 âˆ’ y2 + 2x + 4y âˆ’ xy + 2 æ˜¯æ ¹æ®ä¸¤ä¸ªå˜é‡ x å’Œ y å®šä¹‰çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often this measure of similarity is actually some form of distance measure.",
            "zh": "é€šå¸¸ï¼Œè¿™ç§ç›¸ä¼¼æ€§çš„åº¦é‡å®é™…ä¸Šæ˜¯æŸç§å½¢å¼çš„è·ç¦»åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Multimodal distributions tend to occur when a feature contains a measurement made across a number of distinct groups.",
            "zh": "å½“è¦ç´ åŒ…å«å¯¹å¤šä¸ªä¸åŒç»„è¿›è¡Œçš„æµ‹é‡æ—¶ï¼Œå¾€å¾€ä¼šå‘ç”Ÿå¤šæ¨¡æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The test set with model predictions and scores from Table 9.11[557] extended to include deciles.",
            "zh": "å…·æœ‰è¡¨9.11[557]ä¸­çš„æ¨¡å‹é¢„æµ‹å’Œåˆ†æ•°çš„æµ‹è¯•é›†æ‰©å±•åˆ°åŒ…æ‹¬ååˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Beyond Prediction: Unsupervised Learning",
            "zh": "è¶…è¶Šé¢„æµ‹ï¼šæ— ç›‘ç£å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Interacting: by itself, an interacting descriptive feature is not informative about the value of the target feature. In conjunction with one or more other features, however, it becomes informative.",
            "zh": "äº¤äº’ï¼šäº¤äº’æè¿°æ€§ç‰¹å¾æœ¬èº«å¹¶ä¸èƒ½æä¾›æœ‰å…³ç›®æ ‡ç‰¹å¾å€¼çš„ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œä¸ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–åŠŸèƒ½ç»“åˆä½¿ç”¨æ—¶ï¼Œå®ƒå˜å¾—ä¿¡æ¯ä¸°å¯Œã€‚"
        }
    },
    {
        "translation": {
            "en": "sample mean, 745",
            "zh": "æ ·æœ¬å‡å€¼ï¼Œ745"
        }
    },
    {
        "translation": {
            "en": "12.1â€…â€…â€…The descriptive features in the ABT developed for the Acme Telephonica churn prediction task.",
            "zh": "12.1 ABT ä¸­ä¸º Acme Telephonica æµå¤±é¢„æµ‹ä»»åŠ¡å¼€å‘çš„æè¿°æ€§åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "One way to understand how dropout helps is to recognize that because we use a different network on each training example, we are in effect training an ensemble of a very large number of smaller networks rather than training a single large model, and these smaller networks are less complex and so are less likely to overfit.",
            "zh": "ç†è§£è¾å­¦å¦‚ä½•å¸®åŠ©çš„ä¸€ç§æ–¹æ³•æ˜¯è®¤è¯†åˆ°ï¼Œç”±äºæˆ‘ä»¬åœ¨æ¯ä¸ªè®­ç»ƒç¤ºä¾‹ä¸Šä½¿ç”¨ä¸åŒçš„ç½‘ç»œï¼Œå› æ­¤æˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨è®­ç»ƒå¤§é‡è¾ƒå°ç½‘ç»œçš„é›†åˆï¼Œè€Œä¸æ˜¯è®­ç»ƒå•ä¸ªå¤§å‹æ¨¡å‹ï¼Œå¹¶ä¸”è¿™äº›è¾ƒå°çš„ç½‘ç»œä¸é‚£ä¹ˆå¤æ‚ï¼Œå› æ­¤ä¸å¤ªå¯èƒ½è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "All the simple linear regression and logistic regression models that we have looked at so far model a linear relationship between descriptive features and a target feature.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ç ”ç©¶çš„æ‰€æœ‰ç®€å•çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’æ¨¡å‹éƒ½å¯¹æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„çº¿æ€§å…³ç³»è¿›è¡Œäº†å»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2203",
            "zh": "0.2203"
        }
    },
    {
        "translation": {
            "en": "In teaching a technical topic, it is important to show the application of the concepts discussed to real-life problems.",
            "zh": "åœ¨æ•™æˆæŠ€æœ¯ä¸»é¢˜æ—¶ï¼Œé‡è¦çš„æ˜¯è¦å±•ç¤ºæ‰€è®¨è®ºçš„æ¦‚å¿µåœ¨ç°å®ç”Ÿæ´»ä¸­çš„åº”ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4â€…â€…â€…Extensions and Variations",
            "zh": "7.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Neural networks are a useful modeling approach to use for this prediction problem because, as long as a loss function can be formulated, we can use iterative approaches like the gradient descent algorithm27 to train them.",
            "zh": "ç¥ç»ç½‘ç»œæ˜¯ç”¨äºæ­¤é¢„æµ‹é—®é¢˜çš„æœ‰ç”¨å»ºæ¨¡æ–¹æ³•ï¼Œå› ä¸ºåªè¦å¯ä»¥åˆ¶å®šæŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•27 ç­‰è¿­ä»£æ–¹æ³•æ¥è®­ç»ƒå®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fanaee-T, Hadi, and Goao Gama. 2014. Event labeling combining ensemble detectors and background knowledge. Progress in Artifical Intelligence 2 (2-3): 113â€“127.",
            "zh": "Fanaee-Tã€Hadi å’Œ Goao Gamaã€‚2014. ç»“åˆé›†æˆæ£€æµ‹å™¨å’ŒèƒŒæ™¯çŸ¥è¯†çš„äº‹ä»¶æ ‡è®°.äººå·¥æ™ºèƒ½è¿›å±•2ï¼ˆ2-3ï¼‰ï¼š113-127ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, some of the unsupervised learning approaches described in Chapter 10[597] can be used to address the curse of dimensionality by learning new more compact representations.",
            "zh": "æ­¤å¤–ï¼Œç¬¬10ç« [597]ä¸­æè¿°çš„ä¸€äº›æ— ç›‘ç£å­¦ä¹ æ–¹æ³•å¯ç”¨äºé€šè¿‡å­¦ä¹ æ–°çš„æ›´ç´§å‡‘çš„è¡¨ç¤ºæ¥è§£å†³ç»´åº¦çš„è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "A probability distribution is a data structure that describes the probability of a feature taking a value for all the possible values the feature can take.",
            "zh": "æ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸€ç§æ•°æ®ç»“æ„ï¼Œç”¨äºæè¿°è¦ç´ è·å–è¦ç´ å¯ä»¥è·å–çš„æ‰€æœ‰å¯èƒ½å€¼çš„å€¼çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, for a given example, a different set of neurons is dropped each time it is presented to the network (i.e., for each epoch).",
            "zh": "å› æ­¤ï¼Œå¯¹äºç»™å®šçš„ç¤ºä¾‹ï¼Œæ¯æ¬¡å‘ç½‘ç»œå‘ˆç°æ—¶ï¼ˆå³æ¯ä¸ªæ—¶æœŸï¼‰éƒ½ä¼šä¸¢å¼ƒä¸€ç»„ä¸åŒçš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "and for instances below a separating hyperplane",
            "zh": "ä»¥åŠåˆ†ç¦»è¶…å¹³é¢ä¸‹æ–¹çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "For example, Figure A.4[749] shows the basketball team from Figure A.3[747] ordered by height. To calculate the 25th percentile, we first calculate index as . So, the 25th percentile is the second value in the ordered list, which is 123. To calculate the 80th percentile, we first calculate index as . Because index is not a whole number, we set index_w to the whole part of index, 6, and index_f to the fractional part, 0.4. Then we can calculate the 80th percentile as",
            "zh": "ä¾‹å¦‚ï¼Œå›¾A.4[749]æ˜¾ç¤ºäº†å›¾A.3[747]ä¸­æŒ‰èº«é«˜æ’åºçš„ç¯®çƒé˜Ÿã€‚ä¸ºäº†è®¡ç®—ç¬¬ 25 ä¸ªç™¾åˆ†ä½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æŒ‡æ•°è®¡ç®—ä¸º ã€‚å› æ­¤ï¼Œç¬¬ 25 ä¸ªç™¾åˆ†ä½æ•°æ˜¯æœ‰åºåˆ—è¡¨ä¸­çš„ç¬¬äºŒä¸ªå€¼ï¼Œå³ 123ã€‚ä¸ºäº†è®¡ç®—ç¬¬ 80 ä¸ªç™¾åˆ†ä½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æŒ‡æ•°è®¡ç®—ä¸º ã€‚å› ä¸º index ä¸æ˜¯æ•´æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬å°† index_w è®¾ç½®ä¸ºç´¢å¼• 6 çš„æ•´ä¸ªéƒ¨åˆ†ï¼Œå°† index_f è®¾ç½®ä¸ºå°æ•°éƒ¨åˆ† 0.4ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è®¡ç®—ç¬¬ 80 ä¸ªç™¾åˆ†ä½æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "Obviously, however, using programming languages also has its disadvantages.",
            "zh": "ç„¶è€Œï¼Œæ˜¾ç„¶ï¼Œä½¿ç”¨ç¼–ç¨‹è¯­è¨€ä¹Ÿæœ‰å…¶ç¼ºç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Which of the descriptive features will the ID3 decision tree induction algorithm choose as the feature for the root node of the decision tree?",
            "zh": "ï¼ˆaï¼‰ ID3å†³ç­–æ ‘å½’çº³ç®—æ³•å°†é€‰æ‹©å“ªäº›æè¿°æ€§ç‰¹å¾ä½œä¸ºå†³ç­–æ ‘æ ¹èŠ‚ç‚¹çš„ç‰¹å¾ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18",
            "zh": "å›¾ 5.18"
        }
    },
    {
        "translation": {
            "en": "We use d2 because the processing of this example has been highlighted in Figure 8.14[425], and so it will be easier to identify the relevant zk and ak values for each neuron for this example.",
            "zh": "æˆ‘ä»¬ä¹‹æ‰€ä»¥ä½¿ç”¨ d2ï¼Œæ˜¯å› ä¸ºå›¾ 8.14[425] ä¸­çªå‡ºæ˜¾ç¤ºäº†æ­¤ç¤ºä¾‹çš„å¤„ç†ï¼Œå› æ­¤æ›´å®¹æ˜“è¯†åˆ«æ­¤ç¤ºä¾‹ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ç›¸å…³ zk å’Œ ak å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(1993) extended the universal approximation theorem to include networks with neurons using rectifier activation functions; however, MontÃºfar (2014) has shown that these networks can also require an exponential number of neurons in the hidden layer.",
            "zh": "ï¼ˆ1993ï¼‰æ‰©å±•äº†é€šç”¨è¿‘ä¼¼å®šç†ï¼Œä»¥åŒ…æ‹¬ä½¿ç”¨æ•´æµå™¨æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒç½‘ç»œ;ç„¶è€Œï¼ŒMontÃºfarï¼ˆ2014ï¼‰å·²ç»è¡¨æ˜ï¼Œè¿™äº›ç½‘ç»œåœ¨éšè—å±‚ä¸­ä¹Ÿå¯èƒ½éœ€è¦æŒ‡æ•°æ•°é‡çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "2.0499",
            "zh": "2.0499"
        }
    },
    {
        "translation": {
            "en": "Second, the selection process used to generate the original list of 10 million people was based on telephone directories.",
            "zh": "å…¶æ¬¡ï¼Œç”¨äºç”Ÿæˆ1 000ä¸‡äººåŸå§‹åå•çš„ç”„é€‰è¿‡ç¨‹æ˜¯ä»¥ç”µè¯ç°¿ä¸ºåŸºç¡€çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "optimal control domain, 653",
            "zh": "æœ€ä¼˜æ§åˆ¶åŸŸï¼Œ653"
        }
    },
    {
        "translation": {
            "en": "This results in the model having a higher coverage with respect to the possible queries it can handle.",
            "zh": "è¿™å¯¼è‡´æ¨¡å‹åœ¨å®ƒå¯ä»¥å¤„ç†çš„å¯èƒ½æŸ¥è¯¢æ–¹é¢å…·æœ‰æ›´é«˜çš„è¦†ç›–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(b)[74] shows a scatter plot for the SPONSORSHIP EARNINGS and AGE features from Table 3.7[73].",
            "zh": "å›¾3.5ï¼ˆbï¼‰[74]æ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èµåŠ©æ”¶å…¥å’Œå¹´é¾„ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.2",
            "zh": "å›¾ 13.2"
        }
    },
    {
        "translation": {
            "en": "We can use Bayesâ€™ Theorem to answer both of these questions. To calculate the probability that the patient actually has the disease based on the evidence of the test result, P(d | t), we apply Bayesâ€™ Theorem:",
            "zh": "æˆ‘ä»¬å¯ä»¥ç”¨è´å¶æ–¯å®šç†æ¥å›ç­”è¿™ä¸¤ä¸ªé—®é¢˜ã€‚ä¸ºäº†æ ¹æ®æµ‹è¯•ç»“æœçš„è¯æ®è®¡ç®—æ‚£è€…å®é™…æ‚£æœ‰è¯¥ç–¾ç—…çš„æ¦‚ç‡ï¼ŒPï¼ˆd | tï¼‰ï¼Œæˆ‘ä»¬åº”ç”¨è´å¶æ–¯å®šç†ï¼š"
        }
    },
    {
        "translation": {
            "en": "CLUMPTHICKNESS: A measurae of the amount of layering in cells (1 to 10).",
            "zh": "å›¢å—åšåº¦ï¼šç»†èƒåˆ†å±‚é‡çš„æµ‹é‡å€¼ï¼ˆ1 è‡³ 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The table below lists a set of instances from the house alarm domain. Using the data in this table, create the conditional probability tables (CPTs) for the network you created in the first part of this question, and round the probabilities to two places of decimal.",
            "zh": "ï¼ˆbï¼‰ ä¸‹è¡¨åˆ—å‡ºäº†æˆ¿å±‹æŠ¥è­¦åŸŸä¸­çš„ä¸€ç»„å®ä¾‹ã€‚ä½¿ç”¨æ­¤è¡¨ä¸­çš„æ•°æ®ï¼Œä¸ºæ‚¨åœ¨æœ¬é—®é¢˜ç¬¬ä¸€éƒ¨åˆ†ä¸­åˆ›å»ºçš„ç½‘ç»œåˆ›å»ºæ¡ä»¶æ¦‚ç‡è¡¨ ï¼ˆCPTï¼‰ï¼Œå¹¶å°†æ¦‚ç‡å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.4",
            "zh": "è¡¨ 8.4"
        }
    },
    {
        "translation": {
            "en": "4. the weighted sum calculated in Step (3) is passed through a non-linear activation function Ï†.",
            "zh": "4.åœ¨æ­¥éª¤ï¼ˆ3ï¼‰ä¸­è®¡ç®—çš„åŠ æƒå’Œé€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°Ï†ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "xi refers to the ith instance in a dataset.",
            "zh": "ä¹  æ˜¯æŒ‡æ•°æ®é›†ä¸­çš„ç¬¬ i ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The action with the highest Q value from state 0-2 is therefore left and this is the one used in the update equation.",
            "zh": "å› æ­¤ï¼Œä»çŠ¶æ€ 0-2 ä¸­å…·æœ‰æœ€é«˜ Q å€¼çš„åŠ¨ä½œè¢«ä¿ç•™ä¸‹æ¥ï¼Œè¿™æ˜¯æ›´æ–°æ–¹ç¨‹ä¸­ä½¿ç”¨çš„åŠ¨ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "GPUs, 394",
            "zh": "æ˜¾å¡ï¼Œ394"
        }
    },
    {
        "translation": {
            "en": "(a) P(VOMITING = true)",
            "zh": "ï¼ˆaï¼‰ Pï¼ˆVOMITING = çœŸï¼‰"
        }
    },
    {
        "translation": {
            "en": "This is partly because naive Bayes models are able to make correct predictions even if the probabilities that they calculate are incorrect, so long as the error in the calculated probabilities does not affect the relative rankings of the different target levels.",
            "zh": "è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å› ä¸ºæœ´ç´ è´å¶æ–¯æ¨¡å‹èƒ½å¤Ÿåšå‡ºæ­£ç¡®çš„é¢„æµ‹ï¼Œå³ä½¿å®ƒä»¬è®¡ç®—çš„æ¦‚ç‡ä¸æ­£ç¡®ï¼Œåªè¦è®¡ç®—æ¦‚ç‡ä¸­çš„è¯¯å·®ä¸å½±å“ä¸åŒç›®æ ‡æ°´å¹³çš„ç›¸å¯¹æ’åã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, the inductive bias underpinning similarity-based machine learning algorithms is that things that are similar (i.e., instances that have similar descriptive features) also have the same target feature values.",
            "zh": "æ€»ä¹‹ï¼ŒåŸºäºç›¸ä¼¼æ€§çš„æœºå™¨å­¦ä¹ ç®—æ³•çš„å½’çº³åå·®æ˜¯ç›¸ä¼¼çš„äº‹ç‰©ï¼ˆå³å…·æœ‰ç›¸ä¼¼æè¿°æ€§ç‰¹å¾çš„å®ä¾‹ï¼‰ä¹Ÿå…·æœ‰ç›¸åŒçš„ç›®æ ‡ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The features in an ABT can be of two types: raw features or derived features. Raw features are features that come directly from raw data sources. For example, customer age, customer gender, loan amount, or insurance claim type are all descriptive features that we would most likely be able to transfer directly from a raw data source to an ABT.",
            "zh": "ABT ä¸­çš„ç‰¹å¾å¯ä»¥åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼šåŸå§‹ç‰¹å¾æˆ–æ´¾ç”Ÿç‰¹å¾ã€‚åŸå§‹è¦ç´ æ˜¯ç›´æ¥æ¥è‡ªåŸå§‹æ•°æ®æºçš„è¦ç´ ã€‚ä¾‹å¦‚ï¼Œå®¢æˆ·å¹´é¾„ã€å®¢æˆ·æ€§åˆ«ã€è´·æ¬¾é‡‘é¢æˆ–ä¿é™©ç´¢èµ”ç±»å‹éƒ½æ˜¯æè¿°æ€§ç‰¹å¾ï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½èƒ½å¤Ÿç›´æ¥ä»åŸå§‹æ•°æ®æºä¼ è¾“åˆ° ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "The features place a particular emphasis on claims relating to soft tissue injuries (for example, whiplash) because it is understood within the insurance industry that these are frequently associated with fraudulent claims.",
            "zh": "è¿™äº›ç‰¹ç‚¹ç‰¹åˆ«å¼ºè°ƒä¸è½¯ç»„ç»‡æŸä¼¤ï¼ˆä¾‹å¦‚æŒ¥é­ä¼¤ï¼‰ç›¸å…³çš„ç´¢èµ”ï¼Œå› ä¸ºåœ¨ä¿é™©ä¸šå†…ï¼Œäººä»¬äº†è§£åˆ°è¿™äº›ç´¢èµ”é€šå¸¸ä¸æ¬ºè¯ˆæ€§ç´¢èµ”æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can think of the output of most unsupervised machine learning models as new generated features that can be appended to the original dataset to augment or enrich it.",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†å¤§å¤šæ•°æ— ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºè§†ä¸ºæ–°ç”Ÿæˆçš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯ä»¥é™„åŠ åˆ°åŸå§‹æ•°æ®é›†ä¸­ä»¥å¢å¼ºæˆ–ä¸°å¯Œå®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Brown, Noam, and Tuomas Sandholm. 2017. Libratus: The superhuman AI for no-limit poker. In Proceedings of the twenty-sixth international joint conference on artificial intelligence, IJCAI 2017, Melbourne, Australia, August 19â€“25, 2017, 5226â€“5228. doi:10.24963/ijcai.2017/772.",
            "zh": "å¸ƒæœ—ã€è¯ºå§†å’Œæ‰˜é©¬æ–¯Â·æ¡‘å¾·éœå°”å§†ã€‚2017. Libratusï¼šæ— é™æ‰‘å…‹çš„è¶…äºº AIã€‚2017å¹´8æœˆ19-25æ—¥ï¼Œæ¾³å¤§åˆ©äºšå¢¨å°”æœ¬ï¼ŒIJCAI 2017ï¼Œç¬¬26å±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®è®ºæ–‡é›†ï¼Œç¬¬5226-5228é¡µã€‚doiï¼š10.24963/ijcai.2017/772."
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] illustrates the expansion of the chain of products as the error gradient is propagated back through the network.",
            "zh": "å…¬å¼ 8.41[436] è¯´æ˜äº†å½“è¯¯å·®æ¢¯åº¦é€šè¿‡ç½‘ç»œä¼ æ’­å›æ—¶äº§å“é“¾çš„æ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "batch, 327, 417",
            "zh": "æ‰¹æ¬¡ï¼Œ 327ï¼Œ 417"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 5.15(a)[219] is equally distributed in all directions around A, and as a result, we can say that B and C are equally likely to be from the same population as the dataset.",
            "zh": "å›¾ 5.15ï¼ˆaï¼‰[219] ä¸­çš„æ•°æ®é›†åœ¨ A å‘¨å›´çš„å„ä¸ªæ–¹å‘ä¸Šå‡ç­‰åˆ†å¸ƒï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ B å’Œ C ä¸æ•°æ®é›†æ¥è‡ªåŒä¸€æ€»ä½“çš„å¯èƒ½æ€§ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "[Member prediction] Data Requirements: This solution would not only require that a large collection of claims labeled as either fraudulent or non-fraudulent exist with all relevant details, but also that all claims and policies can be connected to an identifiable member.",
            "zh": "[ä¼šå‘˜é¢„æµ‹]æ•°æ®è¦æ±‚ï¼šæ­¤è§£å†³æ–¹æ¡ˆä¸ä»…è¦æ±‚å­˜åœ¨å¤§é‡æ ‡è®°ä¸ºæ¬ºè¯ˆæ€§æˆ–éæ¬ºè¯ˆæ€§çš„å£°æ˜ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰ç›¸å…³è¯¦ç»†ä¿¡æ¯ï¼Œè€Œä¸”è¿˜è¦æ±‚æ‰€æœ‰å£°æ˜å’Œä¿å•éƒ½å¯ä»¥è¿æ¥åˆ°å¯è¯†åˆ«çš„æˆå‘˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Deep Learning",
            "zh": "æ·±åº¦å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "9.6â€…â€…â€…Further Reading",
            "zh": "9.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "3.3â€…â€…â€…(a) Three normal distributions with different means but identical standard deviations; and (b) three normal distributions with identical means but different standard deviations.",
            "zh": "3.3 ï¼ˆaï¼‰ å‡å€¼ä¸åŒä½†æ ‡å‡†å·®ç›¸åŒçš„ä¸‰ç§æ­£æ€åˆ†å¸ƒ;ï¼ˆbï¼‰å‡å€¼ç›¸åŒä½†æ ‡å‡†å·®ä¸åŒçš„ä¸‰ç§æ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "13.4.2â€…â€…â€…Feature Selection",
            "zh": "13.4.2 åŠŸèƒ½é€‰æ‹©"
        }
    },
    {
        "translation": {
            "en": "19. This is an example of an ensemble model like those described in Section 4.4.5[158].",
            "zh": "19. è¿™æ˜¯ç¬¬4.4.5èŠ‚[158]ä¸­æè¿°çš„é›†æˆæ¨¡å‹çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning an agent inhabiting an environment learns to perform a task by pursuing actions that achieve the highest cumulative reward, where a reward is immediate feedback that follows an action to indicate how successful it was. The main application of reinforcement learning is to learn control strategies, for example, in robotics.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå±…ä½åœ¨ç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“é€šè¿‡è¿½æ±‚è·å¾—æœ€é«˜ç´¯ç§¯å¥–åŠ±çš„è¡ŒåŠ¨æ¥å­¦ä¹ æ‰§è¡Œä»»åŠ¡ï¼Œå…¶ä¸­å¥–åŠ±æ˜¯è¡ŒåŠ¨ä¹‹åçš„å³æ—¶åé¦ˆï¼Œä»¥è¡¨æ˜å®ƒæœ‰å¤šæˆåŠŸã€‚å¼ºåŒ–å­¦ä¹ çš„ä¸»è¦åº”ç”¨æ˜¯å­¦ä¹ æ§åˆ¶ç­–ç•¥ï¼Œä¾‹å¦‚åœ¨æœºå™¨äººæŠ€æœ¯ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "17. This example is inspired by the research reported in Fanaee-T and Gama (2014). The dataset presented here is synthesized for this example; however, a real bike sharing dataset for this task is available through the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset.",
            "zh": "17. è¿™ä¸ªä¾‹å­çš„çµæ„Ÿæ¥è‡ªFanaee-Tå’ŒGamaï¼ˆ2014å¹´ï¼‰æŠ¥å‘Šçš„ç ”ç©¶ã€‚æ­¤å¤„æä¾›çš„æ•°æ®é›†æ˜¯é’ˆå¯¹æ­¤ç¤ºä¾‹åˆæˆçš„;ä½†æ˜¯ï¼Œå¯ä»¥é€šè¿‡ archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset çš„ UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBache å’Œ Lichmanï¼Œ2013 å¹´ï¼‰è·å¾—æ­¤ä»»åŠ¡çš„çœŸå®è‡ªè¡Œè½¦å…±äº«æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.20",
            "zh": "å›¾ 4.20"
        }
    },
    {
        "translation": {
            "en": "Gross, Philip, Albert Boulanger, Marta Arias, David L. Waltz, Philip M. Long, Charles Lawson, Roger Anderson, Matthew Koenig, Mark Mastrocinque, William Fairechio, et al.. 2006. Predicting electricity distribution feeder failures using machine learning susceptibility analysis. In Proceedings of the twenty-first national conference on artificial intelligence (AAAIâ€™06), 1705â€“1711. AAAI Press.",
            "zh": "æ ¼ç½—æ–¯ã€è²åˆ©æ™®ã€é˜¿å°”ä¼¯ç‰¹Â·å¸ƒå…°æ ¼ã€ç›å°”å¡”Â·é˜¿é‡Œäºšæ–¯ã€å¤§å«Â·åå°”å…¹ã€è²åˆ©æ™®Â·æœ—ã€æŸ¥å°”æ–¯Â·åŠ³æ£®ã€ç½—æ°Â·å®‰å¾·æ£®ã€é©¬ä¿®Â·æŸ¯å°¼å¸Œã€é©¬å…‹Â·é©¬æ–¯ç‰¹ç½—è¾›å…‹ã€å¨å»‰Â·è´¹å°”å¥‡å¥¥ç­‰ã€‚2006. ä½¿ç”¨æœºå™¨å­¦ä¹ æ•æ„Ÿæ€§åˆ†æé¢„æµ‹é…ç”µé¦ˆçº¿æ•…éšœ.ç¬¬äºŒåä¸€å±Šå…¨å›½äººå·¥æ™ºèƒ½ä¼šè®® ï¼ˆAAAI'06ï¼‰ ä¼šè®®è®°å½•ï¼Œ1705-1711 å¹´ã€‚AAAIå‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.4",
            "zh": "å›¾ 3.4"
        }
    },
    {
        "translation": {
            "en": "14. This is the same as the batch gradient descent discussed in Chapter 7[311].",
            "zh": "14. è¿™ä¸ç¬¬7ç« [311]ä¸­è®¨è®ºçš„æ‰¹æ¬¡æ¢¯åº¦ä¸‹é™ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision tree for the post-operative patient routing task.",
            "zh": "æœ¯åæ‚£è€…è·¯ç”±ä»»åŠ¡çš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.3â€…â€…â€…Bar plots of the different galaxy types present in the full SDSS dataset for the 3-level and 5-level target features.",
            "zh": "13.3 å®Œæ•´SDSSæ•°æ®é›†ä¸­3çº§å’Œ5çº§ç›®æ ‡ç‰¹å¾ä¸­ä¸åŒæ˜Ÿç³»ç±»å‹çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The statement X is N(Î¼,Ïƒ) is often used as a shorthand for X is a normally distributed feature with mean Î¼ and standard deviation Ïƒ.4 One important characteristic of the normal distribution is often described as the 68âˆ’95âˆ’99.7 rule.",
            "zh": "é™ˆè¿° X æ˜¯ Nï¼ˆÎ¼ï¼ŒÏƒï¼‰ é€šå¸¸ç”¨ä½œ X æ˜¯å…·æœ‰å‡å€¼Î¼å’Œæ ‡å‡†å·®Ïƒçš„æ­£æ€åˆ†å¸ƒç‰¹å¾çš„ç®€å†™.4 æ­£æ€åˆ†å¸ƒçš„ä¸€ä¸ªé‡è¦ç‰¹å¾é€šå¸¸è¢«æè¿°ä¸º 68âˆ’95âˆ’99.7 è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "By offering these customers incentives now to prevent them from churning, AT would ensure that it received the full value from these customers in the future.",
            "zh": "é€šè¿‡ç°åœ¨ä¸ºè¿™äº›å®¢æˆ·æä¾›æ¿€åŠ±æªæ–½ä»¥é˜²æ­¢ä»–ä»¬æµå¤±ï¼ŒATå°†ç¡®ä¿å°†æ¥ä»è¿™äº›å®¢æˆ·é‚£é‡Œè·å¾—å…¨éƒ¨ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, each bootstrap sample will be different, and this means that models trained on different bootstrap samples will also be different.26",
            "zh": "å› æ­¤ï¼Œæ¯ä¸ª bootstrap æ ·æœ¬éƒ½ä¼šä¸åŒï¼Œè¿™æ„å‘³ç€åœ¨ä¸åŒçš„ bootstrap æ ·æœ¬ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¹Ÿä¼šä¸åŒ26ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, based on the confusion matrix in Table 13.5(c)[720], the misclassification rate for the elliptical target level is only 8.756%, while for the spiral target level, it is higher, at 18.693%, and for the other target level, it is a fairly dire 98.230%.",
            "zh": "ä¾‹å¦‚ï¼Œæ ¹æ®è¡¨13.5ï¼ˆcï¼‰[720]ä¸­çš„æ··æ·†çŸ©é˜µï¼Œæ¤­åœ†ç›®æ ‡æ°´å¹³çš„é”™è¯¯åˆ†ç±»ç‡ä»…ä¸º8.756%ï¼Œè€Œèºæ—‹ç›®æ ‡æ°´å¹³çš„é”™è¯¯åˆ†ç±»ç‡æ›´é«˜ï¼Œä¸º18.693%ï¼Œè€Œå¯¹äºå…¶ä»–ç›®æ ‡æ°´å¹³ï¼Œé”™è¯¯åˆ†ç±»ç‡ä¸º98.230%ã€‚"
        }
    },
    {
        "translation": {
            "en": "A much more important advantage, however, is that it can enable significant computational speedups in the training and application of a neural network.",
            "zh": "ç„¶è€Œï¼Œä¸€ä¸ªæ›´é‡è¦çš„ä¼˜åŠ¿æ˜¯ï¼Œå®ƒå¯ä»¥åœ¨ç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œåº”ç”¨ä¸­å®ç°æ˜¾ç€çš„è®¡ç®—åŠ é€Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "In each practice episode, each one of the decisions Sarah made led to immediate feedback: either splashing into the river (negative feedback), landing successfully on the next stepping-stone (positive feedback), turning back on her tracks (very negative feedback), or landing on the far riverbank (very positive feedback).",
            "zh": "åœ¨æ¯ä¸€é›†ç»ƒä¹ ä¸­ï¼Œèæ‹‰åšå‡ºçš„æ¯ä¸€ä¸ªå†³å®šéƒ½ä¼šç«‹å³å¾—åˆ°åé¦ˆï¼šè¦ä¹ˆæº…å…¥æ²³ä¸­ï¼ˆè´Ÿé¢åé¦ˆï¼‰ï¼Œè¦ä¹ˆæˆåŠŸé™è½åœ¨ä¸‹ä¸€ä¸ªå«è„šçŸ³ä¸Šï¼ˆæ­£é¢åé¦ˆï¼‰ï¼Œè¦ä¹ˆå›åˆ°åŸåœ°ï¼ˆéå¸¸è´Ÿé¢çš„åé¦ˆï¼‰ï¼Œè¦ä¹ˆé™è½åœ¨è¿œå¤„çš„æ²³å²¸ä¸Šï¼ˆéå¸¸ç§¯æçš„åé¦ˆï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This parameter is the degrees of freedom of the distribution.",
            "zh": "æ­¤å‚æ•°æ˜¯åˆ†å¸ƒçš„è‡ªç”±åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.17",
            "zh": "å›¾ 9.17"
        }
    },
    {
        "translation": {
            "en": "Calculate the sum of squared errors for this network on this example.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­è®¡ç®—æ­¤ç½‘ç»œçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, most data analytics packages and programming APIs provide functions that implement methods to fit a specified distribution to a given dataset.20",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œå¤§å¤šæ•°æ•°æ®åˆ†æåŒ…å’Œç¼–ç¨‹ API éƒ½æä¾›äº†å®ç°æ–¹æ³•çš„å‡½æ•°ï¼Œä»¥ä¾¿å°†æŒ‡å®šçš„åˆ†å¸ƒæ‹Ÿåˆåˆ°ç»™å®šçš„æ•°æ®é›†20ã€‚"
        }
    },
    {
        "translation": {
            "en": "Modeling: In the Modeling phase of the CRISP-DM process, the machine learning work occurs. Different machine learning algorithms are used to build a range of prediction models from which the best model will be selected for deployment.",
            "zh": "å»ºæ¨¡ï¼šåœ¨ CRISP-DM æµç¨‹çš„å»ºæ¨¡é˜¶æ®µï¼Œå°†è¿›è¡Œæœºå™¨å­¦ä¹ å·¥ä½œã€‚ä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•ç”¨äºæ„å»ºä¸€ç³»åˆ—é¢„æµ‹æ¨¡å‹ï¼Œä»ä¸­é€‰æ‹©æœ€ä½³æ¨¡å‹è¿›è¡Œéƒ¨ç½²ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that there is only a single Î´ per neuron, but typically there are many weights associated with each neuron, and so the Î´ for a neuron will often be used in the calculation of multiple weight error gradients, once for the weight on each connection into the neuron.",
            "zh": "è¯·æ³¨æ„ï¼Œæ¯ä¸ªç¥ç»å…ƒåªæœ‰ä¸€ä¸ªÎ´ï¼Œä½†é€šå¸¸æ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰è®¸å¤šæƒé‡ï¼Œå› æ­¤ç¥ç»å…ƒçš„Î´é€šå¸¸ç”¨äºè®¡ç®—å¤šä¸ªæƒé‡è¯¯å·®æ¢¯åº¦ï¼Œä¸€æ¬¡ç”¨äºä¸ç¥ç»å…ƒçš„æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The input vector has been augmented with the dummy feature d[0] = 1, which is stored in the top row of the vector.",
            "zh": "è¾“å…¥å‘é‡å·²ä½¿ç”¨è™šæ‹Ÿç‰¹å¾ d[0] = 1 è¿›è¡Œæ‰©å……ï¼Œè¯¥ç‰¹å¾å­˜å‚¨åœ¨å‘é‡çš„é¡¶è¡Œä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Those solutions that are deemed feasible should then be presented to the business, and one or more should be selected for implementation.",
            "zh": "ç„¶åï¼Œåº”å°†é‚£äº›è¢«è®¤ä¸ºå¯è¡Œçš„è§£å†³æ–¹æ¡ˆæäº¤ç»™ä¸šåŠ¡éƒ¨é—¨ï¼Œå¹¶åº”é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªè§£å†³æ–¹æ¡ˆè¿›è¡Œå®æ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The stability index can be used for both categorical and continuous targets.",
            "zh": "ç¨³å®šæ€§æŒ‡æ•°å¯ç”¨äºåˆ†ç±»ç›®æ ‡å’Œè¿ç»­ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, when the system makes a mistake, it is desirable that the system can be retrained immediately using the instance that generated the mistake.",
            "zh": "æ­¤å¤–ï¼Œå½“ç³»ç»Ÿå‡ºé”™æ—¶ï¼Œæœ€å¥½èƒ½å¤Ÿç«‹å³ä½¿ç”¨ç”Ÿæˆé”™è¯¯çš„å®ä¾‹å¯¹ç³»ç»Ÿè¿›è¡Œé‡æ–°è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The set of weights used by a neuron determine the type of visual feature to which the neuron activates in response; consequently, these weight matrices are called filters because they filter the input by returning high activations for certain patterns of inputs and low activations for others.",
            "zh": "ç¥ç»å…ƒä½¿ç”¨çš„æƒé‡é›†å†³å®šäº†ç¥ç»å…ƒå“åº”æ¿€æ´»çš„è§†è§‰ç‰¹å¾ç±»å‹;å› æ­¤ï¼Œè¿™äº›æƒé‡çŸ©é˜µè¢«ç§°ä¸ºè¿‡æ»¤å™¨ï¼Œå› ä¸ºå®ƒä»¬é€šè¿‡è¿”å›æŸäº›è¾“å…¥æ¨¡å¼çš„é«˜æ¿€æ´»å’Œå…¶ä»–è¾“å…¥æ¨¡å¼çš„ä½æ¿€æ´»æ¥è¿‡æ»¤è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The adjacent instances in the ordering that have different target feature levels are then selected as possible threshold points.",
            "zh": "ç„¶åï¼Œé€‰æ‹©æ’åºä¸­å…·æœ‰ä¸åŒç›®æ ‡ç‰¹å¾çº§åˆ«çš„ç›¸é‚»å®ä¾‹ä½œä¸ºå¯èƒ½çš„é˜ˆå€¼ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Edwin Powell Hubble",
            "zh": "â€”â€”åŸƒå¾·æ¸©Â·é²å¨å°”Â·å“ˆå‹ƒ"
        }
    },
    {
        "translation": {
            "en": "3.3.4.4â€ƒThe data quality planâ€ƒBased on the analysis described in the preceding sections, the data quality plan shown in Table 3.5[68] was created. This records each of the data quality issues due to valid data that have been identified in the motor insurance fraud ABT. During the Modeling phase of the project, we will use this table as a reminder of data quality issues that could affect model training. At the end of the next section, we complete this table by adding potential handling strategies.",
            "zh": "3.3.4.4 æ•°æ®è´¨é‡è®¡åˆ’ æ ¹æ®å‰å‡ èŠ‚æ‰€è¿°çš„åˆ†æï¼Œåˆ›å»ºäº†è¡¨ 3.5[68] æ‰€ç¤ºçš„æ•°æ®è´¨é‡è®¡åˆ’ã€‚è¿™è®°å½•äº†ç”±äºæ±½è½¦ä¿é™©æ¬ºè¯ˆ ABT ä¸­å·²è¯†åˆ«çš„æœ‰æ•ˆæ•°æ®è€Œå¯¼è‡´çš„æ¯ä¸ªæ•°æ®è´¨é‡é—®é¢˜ã€‚åœ¨é¡¹ç›®çš„å»ºæ¨¡é˜¶æ®µï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ­¤è¡¨æ¥æé†’å¯èƒ½å½±å“æ¨¡å‹è®­ç»ƒçš„æ•°æ®è´¨é‡é—®é¢˜ã€‚åœ¨ä¸‹ä¸€èŠ‚çš„æœ«å°¾ï¼Œæˆ‘ä»¬é€šè¿‡æ·»åŠ å¯èƒ½çš„å¤„ç†ç­–ç•¥æ¥å®Œæˆæ­¤è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For these distributions, the parameters are set using guided search techniques such as gradient descent.",
            "zh": "å¯¹äºè¿™äº›åˆ†å¸ƒï¼Œå‚æ•°æ˜¯ä½¿ç”¨å¼•å¯¼å¼æœç´¢æŠ€æœ¯ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰è®¾ç½®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, supervised machine learning is based on the stationarity assumption, which states that the data doesnâ€™t changeâ€”it remains stationaryâ€”over time.",
            "zh": "é¦–å…ˆï¼Œç›‘ç£æœºå™¨å­¦ä¹ åŸºäºå¹³ç¨³æ€§å‡è®¾ï¼Œè¯¥å‡è®¾æŒ‡å‡ºæ•°æ®ä¸ä¼šéšæ—¶é—´å˜åŒ–è€Œæ”¹å˜â€”â€”å®ƒä¿æŒé™æ­¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Put more formally:",
            "zh": "æ›´æ­£å¼åœ°è¯´ï¼š"
        }
    },
    {
        "translation": {
            "en": "Returning to our example query, in order to calculate P(h,f,Â¬v | m), the chain rule requires us to define three conditional probabilities, P(h | m), P(f | h,m), and P(Â¬v | f,h,m).",
            "zh": "å›åˆ°æˆ‘ä»¬çš„ç¤ºä¾‹æŸ¥è¯¢ï¼Œä¸ºäº†è®¡ç®— Pï¼ˆhï¼Œfï¼ŒÂ¬v | mï¼‰ï¼Œé“¾å¼æ³•åˆ™è¦æ±‚æˆ‘ä»¬å®šä¹‰ä¸‰ä¸ªæ¡ä»¶æ¦‚ç‡ï¼ŒPï¼ˆh | mï¼‰ã€Pï¼ˆf | hï¼Œmï¼‰ å’Œ Pï¼ˆÂ¬v | fï¼Œhï¼Œmï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ideally the histogram heights should follow the dashed line.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œç›´æ–¹å›¾é«˜åº¦åº”éµå¾ªè™šçº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "constraints, 363",
            "zh": "çº¦æŸï¼Œ 363"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (Î±0 = 0.18, c = 10 ); and (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡æ—¶åŠå…¬å®¤ç§Ÿèµé¢„æµ‹é—®é¢˜çš„è¯¯å·®é¢è¡Œç¨‹ ï¼ˆÎ±0 = 0.18ï¼Œ c = 10 ï¼‰;ï¼ˆbï¼‰æ­¤æ—…ç¨‹ä¸­è¯¯å·®å¹³æ–¹å’Œçš„å˜åŒ–å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model could be used to assign every newly arising claim a fraud likelihood, and those that are most likely to be fraudulent could be flagged for investigation by the insurance companyâ€™s claims investigators.",
            "zh": "è¯¥æ¨¡å‹å¯ç”¨äºä¸ºæ¯ä¸ªæ–°å‡ºç°çš„ç´¢èµ”åˆ†é…æ¬ºè¯ˆå¯èƒ½æ€§ï¼Œè€Œé‚£äº›æœ€æœ‰å¯èƒ½æ˜¯æ¬ºè¯ˆçš„ç´¢èµ”å¯ä»¥è¢«ä¿é™©å…¬å¸çš„ç´¢èµ”è°ƒæŸ¥å‘˜æ ‡è®°è¿›è¡Œè°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.4[323] shows an error surface (defined over just two weights so that we can visualize the error surface) and some examples of the path down this surface that the gradient descent algorithm would take from different random starting positions.5",
            "zh": "å›¾ 7.4[323] æ˜¾ç¤ºäº†ä¸€ä¸ªè¯¯å·®é¢ï¼ˆä»…å®šä¹‰ä¸¤ä¸ªæƒé‡ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å¯è§†åŒ–è¯¯å·®é¢ï¼‰ä»¥åŠæ¢¯åº¦ä¸‹é™ç®—æ³•ä»ä¸åŒéšæœºèµ·å§‹ä½ç½®æ²¿è¯¥æ›²é¢å‘ä¸‹çš„è·¯å¾„çš„ä¸€äº›ç¤ºä¾‹5ã€‚"
        }
    },
    {
        "translation": {
            "en": "The exact implementation details of anti-discrimination law change, however, across the countries in the European Union.",
            "zh": "ç„¶è€Œï¼Œåæ­§è§†æ³•çš„ç¡®åˆ‡å®æ–½ç»†èŠ‚åœ¨æ¬§ç›Ÿå„å›½æœ‰æ‰€ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "We have also provided an in-depth introduction to some of the most popular machine learning approaches with examples that illustrate how these algorithms work.",
            "zh": "æˆ‘ä»¬è¿˜æ·±å…¥ä»‹ç»äº†ä¸€äº›æœ€æµè¡Œçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¹¶ä¸¾ä¾‹è¯´æ˜äº†è¿™äº›ç®—æ³•çš„å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œEver tried. Ever failed. No matter. Try again. Fail again. Fail better.â€",
            "zh": "â€œè¯•è¿‡äº†ã€‚æ›¾ç»å¤±è´¥è¿‡ã€‚ä¸ç®¡æ€æ ·ã€‚å†è¯•ä¸€æ¬¡ã€‚å†æ¬¡å¤±è´¥ã€‚å¤±è´¥å¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This repeated multiplication of the error gradient can rapidly scale up the size of the gradient if a weight in Whh is > 1 (causing our weight updates to become too large and our training to become unstable) or cause the gradient to vanish if the weight is very small.",
            "zh": "å¦‚æœä»¥ Wh>h ä¸ºå•ä½çš„æƒé‡ä¸º 1ï¼Œåˆ™è¯¯å·®æ¢¯åº¦çš„é‡å¤ä¹˜æ³•å¯ä»¥è¿…é€Ÿæ‰©å¤§æ¢¯åº¦çš„å¤§å°ï¼ˆå¯¼è‡´æˆ‘ä»¬çš„æƒé‡æ›´æ–°å˜å¾—å¤ªå¤§ï¼Œæˆ‘ä»¬çš„è®­ç»ƒå˜å¾—ä¸ç¨³å®šï¼‰ï¼Œæˆ–è€…å¦‚æœæƒé‡éå¸¸å°ï¼Œåˆ™ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.5â€ƒImplementing Features",
            "zh": "2.4.5 å®ç°åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "We hope that these additions and revisions will make the second edition of the book more useful and relevant than the first. We are indebted to all those peopleâ€”readers, students, instructors, reviewers, colleagues, friends, and familyâ€”who gave us feedback on the first edition, which has helped us massively in designing this new edition.",
            "zh": "æˆ‘ä»¬å¸Œæœ›è¿™äº›è¡¥å……å’Œä¿®è®¢å°†ä½¿æœ¬ä¹¦çš„ç¬¬äºŒç‰ˆæ¯”ç¬¬ä¸€ç‰ˆæ›´æœ‰ç”¨ã€æ›´æœ‰æ„ä¹‰ã€‚æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰è¯»è€…ã€å­¦ç”Ÿã€æ•™å¸ˆã€å®¡ç¨¿äººã€åŒäº‹ã€æœ‹å‹å’Œå®¶äººï¼Œä»–ä»¬ä¸ºæˆ‘ä»¬æä¾›äº†ç¬¬ä¸€ç‰ˆçš„åé¦ˆï¼Œè¿™å¯¹æˆ‘ä»¬è®¾è®¡æ–°ç‰ˆæœ‰å¾ˆå¤§å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "This line illustrates a very simple linear function that maps AGE to INCOME.",
            "zh": "è¿™æ¡çº¿è¯´æ˜äº†ä¸€ä¸ªéå¸¸ç®€å•çš„çº¿æ€§å‡½æ•°ï¼Œå®ƒå°† AGE æ˜ å°„åˆ° INCOMEã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that the agent started with no knowledge of the game and has learned playing strategy through maximization of cumulative reward alone in a simple state space, this is pretty impressive.22",
            "zh": "é‰´äºæ™ºèƒ½ä½“ä¸€å¼€å§‹å¯¹æ¸¸æˆä¸€æ— æ‰€çŸ¥ï¼Œå¹¶ä¸”é€šè¿‡åœ¨ç®€å•çŠ¶æ€ç©ºé—´ä¸­ä»…é€šè¿‡æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±æ¥å­¦ä¹ æ¸¸æˆç­–ç•¥ï¼Œè¿™ä»¤äººå°è±¡æ·±åˆ»22ã€‚"
        }
    },
    {
        "translation": {
            "en": "SEX: The sex of the person screened, either male or female.",
            "zh": "æ€§åˆ«ï¼šè¢«ç­›æŸ¥è€…çš„æ€§åˆ«ï¼Œç”·æ€§æˆ–å¥³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Looking first at Figure C.2(a)[767], the function here is very simple, f(x) = 2x + 3, which results in a straight diagonal line. A straight diagonal line gives us a constant rate of change (in this case an increase of 2 in the value of the function for every change of 1 in x), so the derivative of this function with respect to x is just a constant. This is represented by the horizontal dashed line.",
            "zh": "é¦–å…ˆçœ‹å›¾C.2ï¼ˆaï¼‰[767]ï¼Œè¿™é‡Œçš„å‡½æ•°éå¸¸ç®€å•ï¼Œfï¼ˆxï¼‰ = 2x + 3ï¼Œç»“æœæ˜¯ä¸€æ¡ç›´å¯¹è§’çº¿ã€‚ä¸€æ¡ç›´å¯¹è§’çº¿ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ’å®šçš„å˜åŒ–ç‡ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œx ä¸­æ¯å˜åŒ– 1ï¼Œå‡½æ•°å€¼å°±ä¼šå¢åŠ  2ï¼‰ï¼Œå› æ­¤è¯¥å‡½æ•°ç›¸å¯¹äº x çš„å¯¼æ•°åªæ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚è¿™ç”±æ°´å¹³è™šçº¿è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning, however, is made difficult because there is usually more than one model that is consistent with the training datasetâ€”because of this, machine learning is often described as an ill-posed problem.",
            "zh": "ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ å˜å¾—å›°éš¾ï¼Œå› ä¸ºé€šå¸¸æœ‰å¤šä¸ªæ¨¡å‹ä¸è®­ç»ƒæ•°æ®é›†ä¸€è‡´ï¼Œå› æ­¤ï¼Œæœºå™¨å­¦ä¹ é€šå¸¸è¢«æè¿°ä¸ºä¸€ä¸ªç—…æ€çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ||w|| is known as the Euclidean norm of w and is calculated",
            "zh": "å…¶ä¸­ ||W||è¢«ç§°ä¸º w çš„æ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼Œç»è¿‡è®¡ç®—"
        }
    },
    {
        "translation": {
            "en": "Images (b) and (c) show the car in other positions where other cars and barriers are sensed by the car, but other cars and barriers are out of range of the sensors.",
            "zh": "å›¾åƒ ï¼ˆbï¼‰ å’Œ ï¼ˆcï¼‰ æ˜¾ç¤ºæ±½è½¦å¤„äºå…¶ä»–ä½ç½®ï¼Œæ±½è½¦å¯ä»¥æ„Ÿåº”åˆ°å…¶ä»–æ±½è½¦å’Œéšœç¢ç‰©ï¼Œä½†å…¶ä»–æ±½è½¦å’Œéšœç¢ç‰©è¶…å‡ºäº†ä¼ æ„Ÿå™¨çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, we must use the backpropagation algorithm to calculate the Î´ terms, and once this is done we can calculate the error gradients for each weight.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•æ¥è®¡ç®—Î´é¡¹ï¼Œä¸€æ—¦å®Œæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥è®¡ç®—æ¯ä¸ªæƒé‡çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEALTHTYPE: The type of the health insurance policy (PlanA, PlanB, or PlanC)",
            "zh": "HEALTHTYPEï¼šå¥åº·ä¿é™©å•çš„ç±»å‹ï¼ˆPlanAã€PlanB æˆ– PlanCï¼‰"
        }
    },
    {
        "translation": {
            "en": "4.5â€…â€…â€…Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset ğ’Ÿ7 in Figure 4.8[138].",
            "zh": "4.5 å›¾4.8[138]ä¸­æ•°æ®é›†D7çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature values for the instances in the mini-batch are generated as described in Algorithm 15[671].",
            "zh": "æŒ‰ç…§ç®—æ³• 15[671] ä¸­çš„æè¿°ç”Ÿæˆå°æ‰¹é‡ä¸­å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that we are assuming the neurons in the hidden layers are ReLUs and that the final layer is a softmax layer.",
            "zh": "è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å‡è®¾éšè—å±‚ä¸­çš„ç¥ç»å…ƒæ˜¯ ReLUï¼Œæœ€åä¸€å±‚æ˜¯ softmax å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This network is also a fully connected network because each of the neurons in the network is connected in such a way that it receives inputs from all the neurons in the preceding layer and passes its output activation to all the neurons in the next layer.",
            "zh": "è¿™ä¸ªç½‘ç»œä¹Ÿæ˜¯ä¸€ä¸ªå®Œå…¨è¿æ¥çš„ç½‘ç»œï¼Œå› ä¸ºç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä»¥è¿™æ ·çš„æ–¹å¼è¿æ¥ï¼Œå³å®ƒæ¥æ”¶æ¥è‡ªå‰ä¸€å±‚æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥ï¼Œå¹¶å°†å…¶è¾“å‡ºæ¿€æ´»ä¼ é€’ç»™ä¸‹ä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2.2â€ƒShannonâ€™s Entropy Model",
            "zh": "4.2.2 é¦™å†œç†µæ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Using local receptive fields, neurons can learn to extract low-level features in the input (such as a segment or an oriented edge in an image), and these features can be passed on to neurons in later layers that combine these low-level features into more complex features.",
            "zh": "ä½¿ç”¨å±€éƒ¨æ„Ÿå—é‡ï¼Œç¥ç»å…ƒå¯ä»¥å­¦ä¹ æå–è¾“å…¥ä¸­çš„ä½çº§ç‰¹å¾ï¼ˆä¾‹å¦‚å›¾åƒä¸­çš„çº¿æ®µæˆ–å®šå‘è¾¹ç¼˜ï¼‰ï¼Œå¹¶ä¸”è¿™äº›ç‰¹å¾å¯ä»¥ä¼ é€’ç»™åé¢å±‚çš„ç¥ç»å…ƒï¼Œè¿™äº›ç¥ç»å…ƒå°†è¿™äº›ä½çº§ç‰¹å¾ç»„åˆæˆæ›´å¤æ‚çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dealing with an action-value table of this scale is computationally troublesome, but more important, such a large state space would most likely mean that any training process would inevitably leave much of the action-value table unexplored.",
            "zh": "å¤„ç†è¿™ç§è§„æ¨¡çš„åŠ¨ä½œ-ä»·å€¼è¡¨åœ¨è®¡ç®—ä¸Šæ˜¯å¾ˆéº»çƒ¦çš„ï¼Œä½†æ›´é‡è¦çš„æ˜¯ï¼Œå¦‚æ­¤å¤§çš„çŠ¶æ€ç©ºé—´å¾ˆå¯èƒ½æ„å‘³ç€ä»»ä½•è®­ç»ƒè¿‡ç¨‹éƒ½ä¸å¯é¿å…åœ°ä¼šç•™ä¸‹å¤§éƒ¨åˆ†åŠ¨ä½œ-ä»·å€¼è¡¨çš„æœªè¢«æ¢ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The inverse covariance matrix is the matrix such that when the covariance matrix is multiplied by its inverse, the result is the identity matrix: âˆ‘ Ã— âˆ‘âˆ’1 = .",
            "zh": "é€†åæ–¹å·®çŸ©é˜µæ˜¯è¿™æ ·çš„çŸ©é˜µï¼Œå½“åæ–¹å·®çŸ©é˜µä¹˜ä»¥å…¶é€†çŸ©é˜µæ—¶ï¼Œç»“æœæ˜¯å•ä½çŸ©é˜µï¼šâˆ‘ Ã— âˆ‘âˆ’1 = ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, a simple modification to the Îµ-greedy policy is to reduce Îµ over time so that the amount of exploration that the agent performs reduces over time.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹è´ªå©ªÎµç­–ç•¥çš„ç®€å•ä¿®æ”¹æ˜¯éšç€æ—¶é—´çš„æ¨ç§»å‡å°‘Îµï¼Œä»¥ä¾¿ä»£ç†æ‰§è¡Œçš„æ¢ç´¢é‡éšæ—¶é—´æ¨ç§»è€Œå‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "To use supervised learning for these types of tasks would require an expert controler to operate the system in order to generate a dataset containing examples of correct behavior.",
            "zh": "è¦å°†ç›‘ç£å­¦ä¹ ç”¨äºè¿™äº›ç±»å‹çš„ä»»åŠ¡ï¼Œéœ€è¦ä¸“å®¶æ§åˆ¶è€…æ¥æ“ä½œç³»ç»Ÿï¼Œä»¥ä¾¿ç”ŸæˆåŒ…å«æ­£ç¡®è¡Œä¸ºç¤ºä¾‹çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.3â€ƒBeyond Prediction",
            "zh": "14.3 è¶…è¶Šé¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "14.4â€ƒYour Next Steps",
            "zh": "14.4 æ‚¨çš„ä¸‹ä¸€æ­¥"
        }
    },
    {
        "translation": {
            "en": "Often, in a collaboration between analytics experts and domain experts, we develop a hierarchy of domain concepts that starts from the analytics solution, proceeds through a small number of levels of abstraction to result in concrete descriptive features.",
            "zh": "é€šå¸¸ï¼Œåœ¨åˆ†æä¸“å®¶å’Œé¢†åŸŸä¸“å®¶ä¹‹é—´çš„åˆä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªé¢†åŸŸæ¦‚å¿µçš„å±‚æ¬¡ç»“æ„ï¼Œè¯¥å±‚æ¬¡ç»“æ„ä»åˆ†æè§£å†³æ–¹æ¡ˆå¼€å§‹ï¼Œé€šè¿‡å°‘é‡çš„æŠ½è±¡çº§åˆ«è¿›è¡Œï¼Œä»¥äº§ç”Ÿå…·ä½“çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The identity matrix is a square matrix in which all the elements of the main diagonal are 1, and all other elements are 0.",
            "zh": "å•ä½çŸ©é˜µæ˜¯ä¸€ä¸ªæ­£æ–¹å½¢çŸ©é˜µï¼Œå…¶ä¸­ä¸»å¯¹è§’çº¿çš„æ‰€æœ‰å…ƒç´ å‡ä¸º 1ï¼Œæ‰€æœ‰å…¶ä»–å…ƒç´ å‡ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. Recall that sparse data, discussed in Section 5.4.5[211], refers to datasets where the majority of descriptive features have a value of zero.",
            "zh": "14. å›æƒ³ä¸€ä¸‹ï¼Œç¬¬ 5.4.5 èŠ‚[211] ä¸­è®¨è®ºçš„ç¨€ç–æ•°æ®æ˜¯æŒ‡å¤§å¤šæ•°æè¿°æ€§ç‰¹å¾å€¼ä¸ºé›¶çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bar plots of these three sets of prediction frequencies are shown in the following images.",
            "zh": "è¿™ä¸‰ç»„é¢„æµ‹é¢‘ç‡çš„æ¡å½¢å›¾å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "normalization, 87, 181, 206, 231, 329, 332, 346, 421",
            "zh": "å½’ä¸€åŒ–ï¼Œ 87ï¼Œ 181ï¼Œ 206ï¼Œ 231ï¼Œ 329ï¼Œ 332ï¼Œ 346ï¼Œ 421"
        }
    },
    {
        "translation": {
            "en": "Figure 8.40[509] illustrates the internal structure of an LSTM unit.",
            "zh": "å›¾ 8.40[509] è¯´æ˜äº† LSTM å•å…ƒçš„å†…éƒ¨ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. For each descriptive feature, create the sets that result by partitioning the instances in the dataset using their feature values, and then sum the entropy scores of each of these sets. This gives a measure of the information that remains required to organize the instances into pure sets after we have split them using the descriptive feature.",
            "zh": "2. å¯¹äºæ¯ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œé€šè¿‡ä½¿ç”¨æ•°æ®é›†ä¸­çš„å®ä¾‹çš„ç‰¹å¾å€¼å¯¹å®ä¾‹è¿›è¡Œåˆ†åŒºæ¥åˆ›å»ºç»“æœé›†ï¼Œç„¶åå°†æ¯ä¸ªé›†åˆçš„ç†µåˆ†æ•°ç›¸åŠ ã€‚è¿™ç»™å‡ºäº†åœ¨ä½¿ç”¨æè¿°æ€§ç‰¹å¾å°†å®ä¾‹æ‹†åˆ†ä¸ºçº¯é›†åï¼Œå°†å®ä¾‹ç»„ç»‡æˆçº¯é›†æ‰€éœ€çš„ä¿¡æ¯çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each possible target level.",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹éœ€è¦è¡¨ 6.3[264] ä¸­çš„ç›¸å…³æ¦‚ç‡ï¼Œä»¥ä¾¿å¯¹ CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå¯èƒ½çš„ç›®æ ‡æ°´å¹³çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, this sampling strategy is guaranteed to maintain the relative frequencies of the different levels of the stratification feature.",
            "zh": "å› æ­¤ï¼Œè¿™ç§é‡‡æ ·ç­–ç•¥å¯ä»¥ä¿è¯ä¿æŒä¸åŒå±‚æ¬¡çš„åˆ†å±‚ç‰¹å¾çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The previous process is then repeated, and the distances of each instance in to these updated cluster centroids are given in Table 10.1[604] in the columns labeled Cluster Distances Iter.",
            "zh": "ç„¶åé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œæ¯ä¸ªå®ä¾‹åˆ°è¿™äº›æ›´æ–°çš„èšç±»è´¨å¿ƒçš„è·ç¦»åœ¨è¡¨ 10.1[604] ä¸­æ ‡æœ‰ Cluster Distance Iter çš„åˆ—ä¸­ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Next, it removes the feature d[best] from the set of features considered for testing later on this path in the tree; this enforces the constraint that a feature can be tested only once on any particular path in the tree (Line 11).",
            "zh": "æ¥ä¸‹æ¥ï¼Œå®ƒå°†ç‰¹å¾ d[best] ä»è€ƒè™‘ç¨ååœ¨æ ‘ä¸­çš„æ­¤è·¯å¾„ä¸Šæµ‹è¯•çš„ç‰¹å¾é›†ä¸­åˆ é™¤;è¿™å¼ºåˆ¶æ‰§è¡Œäº†åœ¨æ ‘ä¸­çš„ä»»ä½•ç‰¹å®šè·¯å¾„ä¸Šåªèƒ½æµ‹è¯•ä¸€æ¬¡ç‰¹å¾çš„çº¦æŸï¼ˆç¬¬ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the case of bias terms, this second index is always equal to zero.",
            "zh": "åœ¨åå·®é¡¹çš„æƒ…å†µä¸‹ï¼Œç¬¬äºŒä¸ªç´¢å¼•å§‹ç»ˆç­‰äºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is a subtle difference but can lead to a change in the ordering of models compared to other performance measures.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªå¾®å¦™çš„å·®å¼‚ï¼Œä½†ä¸å…¶ä»–æ€§èƒ½åº¦é‡ç›¸æ¯”ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹é¡ºåºå‘ç”Ÿå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both Edwin and Ted were surprised to see missing values in the data, as it was produced through a fully automated process.",
            "zh": "Edwin å’Œ Ted éƒ½æƒŠè®¶åœ°å‘ç°æ•°æ®ä¸­ç¼ºå°‘å€¼ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡å®Œå…¨è‡ªåŠ¨åŒ–çš„è¿‡ç¨‹ç”Ÿæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "CMODELFLUXIVAR_U/G/R/I/Z",
            "zh": "CMODELFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 10.13",
            "zh": "å›¾ 10.13"
        }
    },
    {
        "translation": {
            "en": "3.2.1â€ƒThe Normal Distribution",
            "zh": "3.2.1 æ­£æ€åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "There are a number of factors to consider in the choice of the batch size, including16 (1) larger batches provide a more accurate estimate of the true gradient for the entire dataset, but (2) hardware constraints may necessitate the use of smaller batches; for example, if all the examples in a mini-batch are to be processed in parallel, then the larger the batch size, the larger is the memory requirement.",
            "zh": "åœ¨é€‰æ‹©æ‰¹é‡å¤§å°æ—¶éœ€è¦è€ƒè™‘è®¸å¤šå› ç´ ï¼ŒåŒ…æ‹¬ 16 ï¼ˆ1ï¼‰ è¾ƒå¤§çš„æ‰¹é‡å¯ä»¥æ›´å‡†ç¡®åœ°ä¼°è®¡æ•´ä¸ªæ•°æ®é›†çš„çœŸå®æ¢¯åº¦ï¼Œä½† ï¼ˆ2ï¼‰ ç¡¬ä»¶é™åˆ¶å¯èƒ½éœ€è¦ä½¿ç”¨è¾ƒå°çš„æ‰¹é‡;ä¾‹å¦‚ï¼Œå¦‚æœè¦å¹¶è¡Œå¤„ç†å°æ‰¹é‡ä¸­çš„æ‰€æœ‰ç¤ºä¾‹ï¼Œåˆ™æ‰¹å¤§å°è¶Šå¤§ï¼Œå†…å­˜è¦æ±‚å°±è¶Šå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is the business problem?",
            "zh": "ä¸šåŠ¡é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "8.8â€…â€…â€…The logical AND and OR functions are linearly separable, but the XOR is not.",
            "zh": "8.8 é€»è¾‘ AND å’Œ OR å‡½æ•°æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ï¼Œä½† XOR ä¸æ˜¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cosine similarity between instances will be in the range [0,1], where 1 indicates maximum similarity and 0 indicates maximum dissimilarity.20 We can calculate the cosine similarity between d1 and d2 from Figure 5.14(a)[218] as",
            "zh": "å®ä¾‹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦å°†åœ¨ [0,1] èŒƒå›´å†…ï¼Œå…¶ä¸­ 1 è¡¨ç¤ºæœ€å¤§ç›¸ä¼¼åº¦ï¼Œ0 è¡¨ç¤ºæœ€å¤§ä¸ç›¸ä¼¼åº¦.20 æˆ‘ä»¬å¯ä»¥ä»å›¾ 5.14ï¼ˆaï¼‰[218] ä¸­è®¡ç®—å‡º d1 å’Œ d2 ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤º"
        }
    },
    {
        "translation": {
            "en": "The standard approach to implementing a similarity-based prediction model is the nearest neighbor algorithm.",
            "zh": "å®ç°åŸºäºç›¸ä¼¼æ€§çš„é¢„æµ‹æ¨¡å‹çš„æ ‡å‡†æ–¹æ³•æ˜¯æœ€è¿‘é‚»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "These weights are necessary because the information read from the memory buffer is processed by the hidden neurons in the same way that each of the inputs is.",
            "zh": "è¿™äº›æƒé‡æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºä»å†…å­˜ç¼“å†²åŒºè¯»å–çš„ä¿¡æ¯ç”±éšè—çš„ç¥ç»å…ƒä»¥ä¸æ¯ä¸ªè¾“å…¥ç›¸åŒçš„æ–¹å¼è¿›è¡Œå¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "These 0 and 1 values tell us which equation to use in order to calculate the corresponding Î´ (below) based on the corresponding softmax activation (above).",
            "zh": "è¿™äº› 0 å’Œ 1 å€¼å‘Šè¯‰æˆ‘ä»¬ä½¿ç”¨å“ªä¸ªæ–¹ç¨‹æ¥è®¡ç®—ç›¸åº”çš„ Î´ï¼ˆä¸‹å›¾ï¼‰ï¼ŒåŸºäºç›¸åº”çš„ softmax æ¿€æ´»ï¼ˆä¸Šå›¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although neither Edwin nor Ted could understand exactly how this had happened, they agreed that something had obviously gone wrong in the processing pipeline in those cases and that the âˆ’ 9,999 values must refer to missing values.11 Complete case analysis was used to entirely remove any rows containing two or more âˆ’ 9,999, or missing, values.",
            "zh": "å°½ç®¡ Edwin å’Œ Ted éƒ½æ— æ³•ç¡®åˆ‡åœ°ç†è§£è¿™æ˜¯å¦‚ä½•å‘ç”Ÿçš„ï¼Œä½†ä»–ä»¬ä¸€è‡´è®¤ä¸ºï¼Œåœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå¤„ç†ç®¡é“ä¸­æ˜¾ç„¶å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼Œå¹¶ä¸” âˆ’ 9,999 å€¼å¿…é¡»å¼•ç”¨ç¼ºå¤±å€¼ã€‚11 å®Œæ•´çš„æ¡ˆä¾‹åˆ†æç”¨äºå®Œå…¨åˆ é™¤ä»»ä½•åŒ…å«ä¸¤ä¸ªæˆ–æ›´å¤šè¡Œ âˆ’ 9,999 æˆ–ç¼ºå¤±çš„è¡Œã€‚ å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "By analyzing the data quality report, we are able to understand the characteristics of the data in the ABT. We will return to the features that seemed to have slightly peculiar distributions.",
            "zh": "é€šè¿‡åˆ†ææ•°æ®è´¨é‡æŠ¥å‘Šï¼Œæˆ‘ä»¬èƒ½å¤Ÿäº†è§£ ABT ä¸­æ•°æ®çš„ç‰¹å¾ã€‚æˆ‘ä»¬å°†å›åˆ°ä¼¼ä¹å…·æœ‰ç•¥å¾®ç‰¹æ®Šåˆ†å¸ƒçš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Anyone who has learned a new sport will have had the sometimes painful experience of taking an error-based approach to learning.",
            "zh": "ä»»ä½•å­¦ä¹ è¿‡ä¸€é¡¹æ–°è¿åŠ¨çš„äººéƒ½ä¼šæœ‰ä¸€æ®µç—›è‹¦çš„ç»å†ï¼Œå³é‡‡ç”¨åŸºäºé”™è¯¯çš„å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examples of the samples generated using Gibbs sampling.",
            "zh": "ä½¿ç”¨ Gibbs é‡‡æ ·ç”Ÿæˆçš„æ ·æœ¬ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "How will we continue to evaluate the model after deployment? How will the model be integrated into the organization?",
            "zh": "éƒ¨ç½²åï¼Œæˆ‘ä»¬å°†å¦‚ä½•ç»§ç»­è¯„ä¼°æ¨¡å‹ï¼Ÿè¯¥æ¨¡å‹å°†å¦‚ä½•é›†æˆåˆ°ç»„ç»‡ä¸­ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "As the learning rate decays, however, the direction of the journey across the error surface moves back downward, and eventually the global minimum is reached.",
            "zh": "ç„¶è€Œï¼Œéšç€å­¦ä¹ ç‡çš„è¡°å‡ï¼Œç©¿è¶Šè¯¯å·®è¡¨é¢çš„è¡Œç¨‹æ–¹å‘ä¼šå‘ä¸‹ç§»åŠ¨ï¼Œæœ€ç»ˆè¾¾åˆ°å…¨å±€æœ€å°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The central tendency of a sample refers to the value that is typical of the sample and therefore can be used to summarize it. Measures of central tendency are an approximation of this notional value. The arithmetic mean (or sample mean or just mean) is the best-known measure of central tendency. The arithmetic mean of a set of n values for a feature a is denoted by the symbol Ä and is calculated as",
            "zh": "æ ·æœ¬çš„ä¸­å¿ƒè¶‹åŠ¿æ˜¯æŒ‡æ ·æœ¬çš„å…¸å‹å€¼ï¼Œå› æ­¤å¯ç”¨äºæ€»ç»“å®ƒã€‚é›†ä¸­è¶‹åŠ¿çš„åº¦é‡æ˜¯è¯¥åä¹‰å€¼çš„è¿‘ä¼¼å€¼ã€‚ç®—æœ¯å¹³å‡å€¼ï¼ˆæˆ–æ ·æœ¬å¹³å‡å€¼æˆ–åªæ˜¯å¹³å‡å€¼ï¼‰æ˜¯é›†ä¸­è¶‹åŠ¿çš„æœ€è‘—åçš„åº¦é‡ã€‚è¦ç´  a çš„ä¸€ç»„ n ä¸ªå€¼çš„ç®—æœ¯å¹³å‡å€¼ç”¨ç¬¦å· Ä è¡¨ç¤ºï¼Œè®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.2(a)[119] we next ask, Is it a man?",
            "zh": "åœ¨å›¾4.2ï¼ˆaï¼‰[119]ä¸­ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥é—®ï¼Œæ˜¯ç”·äººå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 12.3",
            "zh": "å›¾ 12.3"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 5.19[228] illustrates a feature subset space for a dataset with three descriptive features: X, Y, and Z.",
            "zh": "ä¾‹å¦‚ï¼Œå›¾ 5.19[228] è¯´æ˜äº†å…·æœ‰ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾çš„æ•°æ®é›†çš„ç‰¹å¾å­é›†ç©ºé—´ï¼šXã€Y å’Œ Zã€‚"
        }
    },
    {
        "translation": {
            "en": "14.3â€…â€…â€…Beyond Prediction",
            "zh": "14.3 è¶…è¶Šé¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "When a company is formed, it registers with the company registrations office.",
            "zh": "å…¬å¸æˆç«‹åï¼Œåœ¨å…¬å¸æ³¨å†Œå¤„æ³¨å†Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the algorithm can still converge toward an area of the error surface close to the global minimum, there is a strong chance that the global minimum itself will be missed, and the algorithm will simply jump back and forth across it.",
            "zh": "å°½ç®¡ç®—æ³•ä»ç„¶å¯ä»¥æ”¶æ•›åˆ°æ¥è¿‘å…¨å±€æœ€å°å€¼çš„è¯¯å·®é¢åŒºåŸŸï¼Œä½†å¾ˆæœ‰å¯èƒ½ä¼šé”™è¿‡å…¨å±€æœ€å°å€¼æœ¬èº«ï¼Œå¹¶ä¸”ç®—æ³•åªä¼šåœ¨å…¶ä¸Šæ¥å›è·³è½¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.15â€…â€…â€…The (a) gain and (b) cumulative gain at each decile for the email predictions given in Table 9.11[557].",
            "zh": "9.15 è¡¨9.11[557]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶é¢„æµ‹åœ¨æ¯ä¸ªååˆ†ä½æ•°çš„ï¼ˆaï¼‰å¢ç›Šå’Œï¼ˆbï¼‰ç´¯ç§¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Apart from making a model more compact, conditional independence and factorization also increase the coverage of a probability-based prediction model by allowing the model to calculate reasonable probabilities for queries with combinations of evidence that do not occur in the training dataset.",
            "zh": "é™¤äº†ä½¿æ¨¡å‹æ›´ç´§å‡‘ä¹‹å¤–ï¼Œæ¡ä»¶ç‹¬ç«‹æ€§å’Œå› å¼åˆ†è§£è¿˜å…è®¸æ¨¡å‹è®¡ç®—å…·æœ‰è®­ç»ƒæ•°æ®é›†ä¸­æœªå‡ºç°çš„è¯æ®ç»„åˆçš„æŸ¥è¯¢çš„åˆç†æ¦‚ç‡ï¼Œä»è€Œå¢åŠ äº†åŸºäºæ¦‚ç‡çš„é¢„æµ‹æ¨¡å‹çš„è¦†ç›–èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section A.1[745] we talk about how measures of central tendency attempt to capture the average value of a list of numbers.",
            "zh": "åœ¨A.1[745]èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†é›†ä¸­è¶‹åŠ¿çš„åº¦é‡å¦‚ä½•è¯•å›¾æ•è·æ•°å­—åˆ—è¡¨çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Implicitly, however, the algorithm is also creating a global prediction model based on the full dataset.",
            "zh": "ç„¶è€Œï¼Œéšå«åœ°ï¼Œè¯¥ç®—æ³•ä¹Ÿåœ¨åˆ›å»ºä¸€ä¸ªåŸºäºå®Œæ•´æ•°æ®é›†çš„å…¨å±€é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "To my wife and family,",
            "zh": "è‡´æˆ‘çš„å¦»å­å’Œå®¶äººï¼Œ"
        }
    },
    {
        "translation": {
            "en": "In this calculation Shannonâ€™s model multiples the large probability of selecting a specific suit, P(suit = l), by a small negative number, log2(P(suit = l)), to return a relatively small negative number. The relatively small negative numbers associated with each suit are summed to result in a small negative number overall. Again, the sign of this number is inverted to result in a small positive value for the entropy of this much purer set.",
            "zh": "åœ¨æ­¤è®¡ç®—ä¸­ï¼ŒShannon çš„æ¨¡å‹å°†é€‰æ‹©ç‰¹å®šèŠ±è‰²çš„å¤§æ¦‚ç‡ Pï¼ˆsuit = lï¼‰ ä¹˜ä»¥ä¸€ä¸ªå°çš„è´Ÿæ•° log2ï¼ˆPï¼ˆsuit = lï¼‰ï¼‰ï¼Œä»¥è¿”å›ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„è´Ÿæ•°ã€‚ä¸æ¯ç§èŠ±è‰²ç›¸å…³çš„ç›¸å¯¹è¾ƒå°çš„è´Ÿæ•°ç›¸åŠ ï¼Œå¾—å‡ºä¸€ä¸ªè¾ƒå°çš„è´Ÿæ•°ã€‚åŒæ ·ï¼Œè¿™ä¸ªæ•°å­—çš„ç¬¦å·è¢«é¢ å€’ï¼Œä¸ºè¿™ä¸ªæ›´çº¯çš„é›†åˆçš„ç†µäº§ç”Ÿä¸€ä¸ªå°çš„æ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov blanket, 288",
            "zh": "é©¬å°”å¯å¤«æ¯¯å­ï¼Œ288"
        }
    },
    {
        "translation": {
            "en": "52,000",
            "zh": "52,000"
        }
    },
    {
        "translation": {
            "en": "This figure is based on Figure 1.27 from Bishop (2006).",
            "zh": "è¿™ä¸ªæ•°å­—æ˜¯åŸºäºBishopï¼ˆ2006ï¼‰çš„å›¾1.27ã€‚"
        }
    },
    {
        "translation": {
            "en": "These examples show two things.",
            "zh": "è¿™äº›ä¾‹å­è¯´æ˜äº†ä¸¤ä»¶äº‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "variational RNN, 507",
            "zh": "å˜åˆ†RNNï¼Œ507"
        }
    },
    {
        "translation": {
            "en": "Recall that when we did an exact calculation for this query the probability of CPI = high was 0.2.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œå½“æˆ‘ä»¬å¯¹æ­¤æŸ¥è¯¢è¿›è¡Œç²¾ç¡®è®¡ç®—æ—¶ï¼ŒCPI = é«˜çš„æ¦‚ç‡ä¸º 0.2ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a validation set to avoid overfitting in iterative machine learning algorithms.",
            "zh": "ä½¿ç”¨éªŒè¯é›†æ¥é¿å…è¿­ä»£æœºå™¨å­¦ä¹ ç®—æ³•ä¸­çš„è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11",
            "zh": "å›¾ 9.11"
        }
    },
    {
        "translation": {
            "en": "In this use case, unsupervised machine learning is used as one part of a larger machine learning pipeline.",
            "zh": "åœ¨æ­¤ç”¨ä¾‹ä¸­ï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ è¢«ç”¨ä½œæ›´å¤§çš„æœºå™¨å­¦ä¹ ç®¡é“çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of customer care calls made by the customer last month",
            "zh": "å®¢æˆ·ä¸Šä¸ªæœˆæ‹¨æ‰“çš„å®¢æˆ·æœåŠ¡ç”µè¯æ•°é‡"
        }
    },
    {
        "translation": {
            "en": "Learning both the topology of a Bayesian network and the parameters in the CPTs in the network is a difficult computational task.",
            "zh": "å­¦ä¹ è´å¶æ–¯ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„å’Œç½‘ç»œä¸­ CPT ä¸­çš„å‚æ•°æ˜¯ä¸€é¡¹è‰°å·¨çš„è®¡ç®—ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, we choose the set of conditional probabilities that maximize the likelihood of the training data.",
            "zh": "æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬é€‰æ‹©ä½¿è®­ç»ƒæ•°æ®çš„å¯èƒ½æ€§æœ€å¤§åŒ–çš„æ¡ä»¶æ¦‚ç‡é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The mode is simply the most commonly occurring value in a sample (determined by counting the frequency with which each value occurs in the sample).",
            "zh": "è¯¥æ¨¡å¼åªæ˜¯æ ·æœ¬ä¸­æœ€å¸¸å‡ºç°çš„å€¼ï¼ˆé€šè¿‡è®¡ç®—æ ·æœ¬ä¸­æ¯ä¸ªå€¼å‡ºç°çš„é¢‘ç‡æ¥ç¡®å®šï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can apply almost the same approach that we used in the Guess Who game to make this decision.",
            "zh": "æˆ‘ä»¬å¯ä»¥åº”ç”¨ä¸çŒœçŒœè°æ¸¸æˆä¸­å‡ ä¹ç›¸åŒçš„æ–¹æ³•æ¥åšå‡ºè¿™ä¸ªå†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "0.58",
            "zh": "0.58"
        }
    },
    {
        "translation": {
            "en": "When there are many continuous features, probability-based and information-based models can become complicated, but if all the features in a dataset are categorical, then information-based and probability-based models are appropriate.",
            "zh": "å½“å­˜åœ¨è®¸å¤šè¿ç»­ç‰¹å¾æ—¶ï¼ŒåŸºäºæ¦‚ç‡å’ŒåŸºäºä¿¡æ¯çš„æ¨¡å‹å¯èƒ½ä¼šå˜å¾—å¤æ‚ï¼Œä½†å¦‚æœæ•°æ®é›†ä¸­çš„æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯åˆ†ç±»çš„ï¼Œåˆ™åŸºäºä¿¡æ¯å’ŒåŸºäºæ¦‚ç‡çš„æ¨¡å‹æ˜¯åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model is said to overfit the training data.",
            "zh": "æ®è¯´è¯¥æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œäº†è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "In the credit scoring dataset given in Table 1.2[8], for example, a conservative estimate of the number of possible combinations of descriptive features is over 3.6 billion!",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨è¡¨ 1.2[8] ä¸­ç»™å‡ºçš„ä¿¡ç”¨è¯„åˆ†æ•°æ®é›†ä¸­ï¼Œå¯¹æè¿°æ€§ç‰¹å¾çš„å¯èƒ½ç»„åˆæ•°é‡çš„ä¿å®ˆä¼°è®¡è¶…è¿‡ 36 äº¿ï¼"
        }
    },
    {
        "translation": {
            "en": "8.6â€…â€…â€…Further Reading",
            "zh": "8.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "This means that the training process is using its experience of the environment much more efficiently because each step is used in network training multiple times.",
            "zh": "è¿™æ„å‘³ç€è®­ç»ƒè¿‡ç¨‹å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨å…¶ç¯å¢ƒç»éªŒï¼Œå› ä¸ºæ¯ä¸ªæ­¥éª¤éƒ½åœ¨ç½‘ç»œè®­ç»ƒä¸­å¤šæ¬¡ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Smoothing should be used in conjunction with binning to help with these extreme probabilities.",
            "zh": "å¹³æ»‘åº”ä¸åƒç´ åˆå¹¶ç»“åˆä½¿ç”¨ï¼Œä»¥å¸®åŠ©å¤„ç†è¿™äº›æç«¯æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The model, however, will actually return a prediction of yes, indicating that the customer should be contacted.",
            "zh": "ä½†æ˜¯ï¼Œè¯¥æ¨¡å‹å®é™…ä¸Šå°†è¿”å›â€œæ˜¯â€çš„é¢„æµ‹ï¼Œè¡¨ç¤ºåº”è”ç³»å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that the set of training instances reaching a leaf node are indicative of the queries that will be labeled by the node, it makes sense to construct regression trees in a manner that reduces the variance in the target feature values of the set of training instances at each leaf node in the tree.",
            "zh": "å‡è®¾åˆ°è¾¾å¶èŠ‚ç‚¹çš„è®­ç»ƒå®ä¾‹é›†æŒ‡ç¤ºè¯¥èŠ‚ç‚¹å°†æ ‡è®°çš„æŸ¥è¯¢ï¼Œåˆ™ä»¥å‡å°‘æ ‘ä¸­æ¯ä¸ªå¶èŠ‚ç‚¹ä¸Šè®­ç»ƒå®ä¾‹é›†çš„ç›®æ ‡ç‰¹å¾å€¼æ–¹å·®çš„æ–¹å¼æ„é€ å›å½’æ ‘æ˜¯æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "During the forward pass of an LSTM unit, there are three operations on activation vectors that are novel with respect to the other network architectures we have examined: forks in computational flow, elementwise products of vectors, and elementwise addition of vectors. To be able to backpropagate error gradients through an LSTM, we need to understand how the novel operations in the forward pass are handled in the backward pass.",
            "zh": "åœ¨ LSTM å•å…ƒçš„å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­ï¼Œæ¿€æ´»å‘é‡æœ‰ä¸‰ç§æ“ä½œï¼Œè¿™äº›æ“ä½œç›¸å¯¹äºæˆ‘ä»¬ç ”ç©¶è¿‡çš„å…¶ä»–ç½‘ç»œæ¶æ„æ¥è¯´æ˜¯æ–°é¢–çš„ï¼šè®¡ç®—æµä¸­çš„åˆ†å‰ã€å‘é‡çš„é€å…ƒä¹˜ç§¯å’Œå‘é‡çš„é€å…ƒåŠ æ³•ã€‚ä¸ºäº†èƒ½å¤Ÿé€šè¿‡ LSTM åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å¦‚ä½•åœ¨åå‘ä¼ é€’ä¸­å¤„ç†å‰å‘ä¼ é€’ä¸­çš„æ–°æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "In many cases datasets will contain both categorical and continuous descriptive features.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ•°æ®é›†å°†åŒæ—¶åŒ…å«åˆ†ç±»å’Œè¿ç»­æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that in Figure 2.6(b)[39] the month names have been abstracted and are now defined relative to the transition between the observation and outcome periods.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨å›¾2.6ï¼ˆbï¼‰[39]ä¸­ï¼Œæœˆä»½åç§°å·²è¢«æŠ½è±¡åŒ–ï¼Œç°åœ¨ç›¸å¯¹äºè§‚å¯ŸæœŸå’Œç»“æœæœŸä¹‹é—´çš„è¿‡æ¸¡è¿›è¡Œäº†å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "An image of the digit 2 and reconstructions of this image by the auto-encoder after various amounts of network training. The pixel values of the reconstructed images are shown alongside the images, as is the reconstruction error calculated by comparing these to the pixel values of the original image.",
            "zh": "æ•°å­— 2 çš„å›¾åƒä»¥åŠè‡ªåŠ¨ç¼–ç å™¨åœ¨ç»è¿‡ä¸åŒæ•°é‡çš„ç½‘ç»œè®­ç»ƒåå¯¹è¯¥å›¾åƒçš„é‡å»ºã€‚é‡å»ºå›¾åƒçš„åƒç´ å€¼ä¸å›¾åƒä¸€èµ·æ˜¾ç¤ºï¼Œé€šè¿‡å°†è¿™äº›åƒç´ å€¼ä¸åŸå§‹å›¾åƒçš„åƒç´ å€¼è¿›è¡Œæ¯”è¾ƒè®¡ç®—çš„é‡å»ºè¯¯å·®ä¹Ÿæ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Binary: A set of just two values (e.g., gender)",
            "zh": "äºŒè¿›åˆ¶ï¼šä»…åŒ…å«ä¸¤ä¸ªå€¼ï¼ˆä¾‹å¦‚æ€§åˆ«ï¼‰çš„é›†åˆ"
        }
    },
    {
        "translation": {
            "en": "The CPT entries are essentially parameters on the network, and the more parameters a network has, the greater its ability to fit (or overfit) the data.",
            "zh": "CPT æ¡ç›®æœ¬è´¨ä¸Šæ˜¯ç½‘ç»œä¸Šçš„å‚æ•°ï¼Œç½‘ç»œæ‹¥æœ‰çš„å‚æ•°è¶Šå¤šï¼Œå…¶æ‹Ÿåˆï¼ˆæˆ–è¿‡æ‹Ÿåˆï¼‰æ•°æ®çš„èƒ½åŠ›å°±è¶Šå¼ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In a regression problem, in which the target is continuous, normalization is often applied to both the descriptive features and the target feature.",
            "zh": "åœ¨å›å½’é—®é¢˜ä¸­ï¼Œç›®æ ‡ä¸ºè¿ç»­çš„ï¼Œè§„èŒƒåŒ–é€šå¸¸åŒæ—¶åº”ç”¨äºæè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This analysis also explains the exploding z values plotted in Figure 8.24[454].",
            "zh": "è¯¥åˆ†æè¿˜è§£é‡Šäº†å›¾8.24[454]ä¸­ç»˜åˆ¶çš„çˆ†ç‚¸zå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sarah is a young venture scout in training for her pioneering badge.",
            "zh": "èæ‹‰æ˜¯ä¸€åå¹´è½»çš„å†’é™©çƒæ¢ï¼Œæ­£åœ¨ä¸ºå¥¹çš„å¼€æ‹“è€…å¾½ç« è¿›è¡ŒåŸ¹è®­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The table in the data quality report that describes categorical features should include a row for each feature in the ABT that contains the two most frequent levels for the feature (the mode and 2nd mode) and the frequency with which these appear (both as raw frequencies and as a proportion of the total number of instances in the dataset).",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­æè¿°åˆ†ç±»ç‰¹å¾çš„è¡¨åº”åŒ…æ‹¬ ABT ä¸­æ¯ä¸ªç‰¹å¾çš„ä¸€è¡Œï¼Œå…¶ä¸­åŒ…å«ç‰¹å¾çš„ä¸¤ä¸ªæœ€å¸¸è§çº§åˆ«ï¼ˆæ¨¡å¼å’Œç¬¬äºŒæ¨¡å¼ï¼‰ä»¥åŠè¿™äº›çº§åˆ«å‡ºç°çš„é¢‘ç‡ï¼ˆåŸå§‹é¢‘ç‡å’Œæ•°æ®é›†ä¸­å®ä¾‹æ€»æ•°çš„æ¯”ä¾‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.17[434] illustrates how the sum of squared errors of the network changes during the training.",
            "zh": "å›¾ 8.17[434] è¯´æ˜äº†ç½‘ç»œè¯¯å·®çš„å¹³æ–¹å’Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯å¦‚ä½•å˜åŒ–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Naive Bayes",
            "zh": "æœ´ç´ è´å¶æ–¯"
        }
    },
    {
        "translation": {
            "en": "The magnitude of the maximum values for the FIBER2FLUXIVAR_U feature in comparison to the median and 3rd quartile value was unusual and suggested the presence of outliers.",
            "zh": "ä¸ä¸­ä½æ•°å’Œç¬¬ 3 ä¸ªå››åˆ†ä½æ•°ç›¸æ¯”ï¼ŒFIBER2FLUXIVAR_Uç‰¹å¾çš„æœ€å¤§å€¼çš„å¤§å°æ˜¯ä¸å¯»å¸¸çš„ï¼Œè¡¨æ˜å­˜åœ¨å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. learning the class conditional densities (i.e., the distribution of the data for each target level) P(d|tl) and the class priors P(tl);",
            "zh": "1. å­¦ä¹ ç±»æ¡ä»¶å¯†åº¦ï¼ˆå³æ¯ä¸ªç›®æ ‡æ°´å¹³çš„æ•°æ®åˆ†å¸ƒï¼‰Pï¼ˆd|tlï¼‰å’Œç±»å…ˆéªŒPï¼ˆtlï¼‰;"
        }
    },
    {
        "translation": {
            "en": "The variant of backpropagation used to train a recurrent neural network is called backpropagation through time.",
            "zh": "ç”¨äºè®­ç»ƒé€’å½’ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­å˜ä½“ç§°ä¸ºéšæ—¶é—´åå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "For those struggling to choose an appropriate performance measure, in the absence of other information, we recommend:",
            "zh": "å¯¹äºé‚£äº›åœ¨æ²¡æœ‰å…¶ä»–ä¿¡æ¯çš„æƒ…å†µä¸‹éš¾ä»¥é€‰æ‹©é€‚å½“çš„ç»©æ•ˆè¡¡é‡æ ‡å‡†çš„äººï¼Œæˆ‘ä»¬å»ºè®®ï¼š"
        }
    },
    {
        "translation": {
            "en": "Features from the ABT for the SDSS galaxy classification problem.",
            "zh": "æ¥è‡ª ABT çš„ SDSS æ˜Ÿç³»åˆ†ç±»é—®é¢˜çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To test the two-stage classifier, Jocelyn extracted a small ABT containing only spiral galaxies from the original ABT.",
            "zh": "ä¸ºäº†æµ‹è¯•ä¸¤çº§åˆ†ç±»å™¨ï¼ŒJocelyn ä»åŸå§‹ ABT ä¸­æå–äº†ä¸€ä¸ªä»…åŒ…å«èºæ—‹æ˜Ÿç³»çš„å°å‹ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "Given the complexity of exact probabilistic inference for Bayesian networks, a popular alternative is to approximate the probability distribution required for a prediction using Monte Carlo methods.29 Monte Carlo methods generate a large number of sample events and then use the relative frequency of an event in the set of generated samples as the approximation for the probability of that event in the real distribution.",
            "zh": "é‰´äºè´å¶æ–¯ç½‘ç»œç²¾ç¡®æ¦‚ç‡æ¨ç†çš„å¤æ‚æ€§ï¼Œä¸€ç§æµè¡Œçš„æ›¿ä»£æ–¹æ³•æ˜¯ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•è¿‘ä¼¼é¢„æµ‹æ‰€éœ€çš„æ¦‚ç‡åˆ†å¸ƒ.29 è’™ç‰¹å¡æ´›æ–¹æ³•ç”Ÿæˆå¤§é‡æ ·æœ¬äº‹ä»¶ï¼Œç„¶åä½¿ç”¨ç”Ÿæˆçš„æ ·æœ¬é›†ä¸­äº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡ä½œä¸ºè¯¥äº‹ä»¶åœ¨å®é™…åˆ†å¸ƒä¸­çš„æ¦‚ç‡çš„è¿‘ä¼¼å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What prediction will the naive Bayes model return for the following query?",
            "zh": "ï¼ˆbï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹å¯¹ä»¥ä¸‹æŸ¥è¯¢å°†è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Using normalization (see Section 3.6.1[87]) on the features can help avoid these large squared errors, and we do this in most examples from now on.",
            "zh": "å¯¹ç‰¹å¾ä½¿ç”¨å½’ä¸€åŒ–ï¼ˆå‚è§ç¬¬ 3.6.1 èŠ‚ [87]ï¼‰å¯ä»¥å¸®åŠ©é¿å…è¿™äº›å¤§çš„å¹³æ–¹è¯¯å·®ï¼Œä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬åœ¨å¤§å¤šæ•°ç¤ºä¾‹ä¸­éƒ½ä¼šè¿™æ ·åšã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this data, perform the following tasks on the SCORE feature:",
            "zh": "ä½¿ç”¨æ­¤æ•°æ®ï¼Œå¯¹ SCORE åŠŸèƒ½æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š"
        }
    },
    {
        "translation": {
            "en": "rate parameter, 274",
            "zh": "rate å‚æ•°ï¼Œ274"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the bike rental dataset from Table 4.15[166].",
            "zh": "ï¼ˆaï¼‰ è¡¨4.15[166]ä¸­çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A subset of a dataset is denoted by ğ’Ÿ with a subscript to indicate the definition of the subset. For example, ğ’Ÿf=l represents the subset of instances from the dataset ğ’Ÿ where the feature f has the value l.",
            "zh": "æ•°æ®é›†çš„å­é›†ç”¨ D è¡¨ç¤ºï¼Œä¸‹æ ‡è¡¨ç¤ºå­é›†çš„å®šä¹‰ã€‚ä¾‹å¦‚ï¼ŒDf=l è¡¨ç¤ºæ•°æ®é›† D ä¸­å®ä¾‹çš„å­é›†ï¼Œå…¶ä¸­ç‰¹å¾ f çš„å€¼ä¸º lã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason that we sample with replacement is that this will result in duplicates within each of the bootstrap samples, and consequently every bootstrap sample will be missing some of the instances from the dataset.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨æ›¿æ¢è¿›è¡Œé‡‡æ ·çš„åŸå› æ˜¯ï¼Œè¿™å°†å¯¼è‡´æ¯ä¸ªå¼•å¯¼æ ·æœ¬ä¸­å‡ºç°é‡å¤ï¼Œå› æ­¤æ¯ä¸ªå¼•å¯¼æ ·æœ¬éƒ½å°†ç¼ºå°‘æ•°æ®é›†ä¸­çš„ä¸€äº›å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figures 3.10(a)[80] and 3.10(b)[80] we illustrate the multiple box plot approach using the AGE and POSITION features from the dataset in Table 3.7[73].",
            "zh": "åœ¨å›¾3.10ï¼ˆaï¼‰[80]å’Œå›¾3.10ï¼ˆbï¼‰[80]ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­çš„AGEå’ŒPOSITIONç‰¹å¾è¯´æ˜äº†å¤šç®±å›¾æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "These arise when there are no instances in the training data that match a specific combination of target feature and descriptive feature levels.",
            "zh": "å½“è®­ç»ƒæ•°æ®ä¸­æ²¡æœ‰ä¸ç›®æ ‡ç‰¹å¾å’Œæè¿°æ€§ç‰¹å¾çº§åˆ«çš„ç‰¹å®šç»„åˆåŒ¹é…çš„å®ä¾‹æ—¶ï¼Œå°±ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, neurons using this set of weights can be thought of as rudimentary detectors for horizontal edges because they will have maximum activation if there is a horizontal line across the middle row of their inputs.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨è¿™ç»„æƒé‡çš„ç¥ç»å…ƒå¯ä»¥è¢«è®¤ä¸ºæ˜¯æ°´å¹³è¾¹ç¼˜çš„åŸºæœ¬æ£€æµ‹å™¨ï¼Œå› ä¸ºå¦‚æœå®ƒä»¬çš„è¾“å…¥ä¸­é—´æœ‰ä¸€è¡Œæ°´å¹³çº¿ï¼Œå®ƒä»¬å°†å…·æœ‰æœ€å¤§çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Organizations exist to do things like make more money, gain new customers, sell more products, or reduce losses from fraud.",
            "zh": "ç»„ç»‡çš„å­˜åœ¨æ˜¯ä¸ºäº†åšä¸€äº›äº‹æƒ…ï¼Œæ¯”å¦‚èµšæ›´å¤šçš„é’±ã€è·å¾—æ–°å®¢æˆ·ã€é”€å”®æ›´å¤šçš„äº§å“æˆ–å‡å°‘æ¬ºè¯ˆé€ æˆçš„æŸå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "profit matrix, 553, 592",
            "zh": "åˆ©æ¶¦çŸ©é˜µï¼Œ553,592"
        }
    },
    {
        "translation": {
            "en": "4.21â€…â€…â€…(a) A plot of the bike rental dataset from Table 4.14[162]. (b) An illustration of the final ensemble model trained using the boosting algorithm. (c)â€“(e) A representation of the changing weights used to generate sample datasets for the first iterations of the boosting process.",
            "zh": "4.21 ï¼ˆaï¼‰ è¡¨4.14[162]ä¸­çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†å›¾ã€‚ï¼ˆbï¼‰ ä½¿ç”¨æå‡ç®—æ³•è®­ç»ƒçš„æœ€ç»ˆé›†æˆæ¨¡å‹çš„å›¾ç¤ºã€‚ï¼ˆcï¼‰â€“ï¼ˆeï¼‰ ç”¨äºä¸ºæå‡è¿‡ç¨‹çš„ç¬¬ä¸€æ¬¡è¿­ä»£ç”Ÿæˆæ ·æœ¬æ•°æ®é›†çš„å˜åŒ–æƒé‡çš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the analytics solution had been defined, the next step was to agree on the expected performance of the new analytics model.",
            "zh": "å®šä¹‰åˆ†æè§£å†³æ–¹æ¡ˆåï¼Œä¸‹ä¸€æ­¥å°±æ˜¯å°±æ–°åˆ†ææ¨¡å‹çš„é¢„æœŸæ€§èƒ½è¾¾æˆä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, in backpropagating through a max function, the entire error gradient is backpropagated to the neuron that propagated forward the max value, and the other neurons receive an error gradient of zero.",
            "zh": "å› æ­¤ï¼Œåœ¨é€šè¿‡æœ€å¤§å‡½æ•°åå‘ä¼ æ’­æ—¶ï¼Œæ•´ä¸ªè¯¯å·®æ¢¯åº¦è¢«åå‘ä¼ æ’­åˆ°å‘å‰ä¼ æ’­æœ€å¤§å€¼çš„ç¥ç»å…ƒï¼Œè€Œå…¶ä»–ç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov chain, 298",
            "zh": "é©¬å°”å¯å¤«é“¾ï¼Œ298"
        }
    },
    {
        "translation": {
            "en": "20.64",
            "zh": "20.64"
        }
    },
    {
        "translation": {
            "en": "The average number of call minutes used by the customer each month",
            "zh": "å®¢æˆ·æ¯æœˆä½¿ç”¨çš„å¹³å‡é€šè¯åˆ†é’Ÿæ•°"
        }
    },
    {
        "translation": {
            "en": "This section has provided an overview of the aspects of probability that readers need to understand in order to follow the other sections in this book.",
            "zh": "æœ¬èŠ‚æ¦‚è¿°äº†è¯»è€…éœ€è¦äº†è§£çš„æ¦‚ç‡æ–¹é¢ï¼Œä»¥ä¾¿äº†è§£æœ¬ä¹¦çš„å…¶ä»–éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, it is not uncommon to see sizes of 128, 256, 512, and 1,024.",
            "zh": "ä¾‹å¦‚ï¼Œ128ã€256ã€512 å’Œ 1,024 çš„å¤§å°å¹¶ä¸å°‘è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The height of this rectangle, then, also shows the inter-quartile range.",
            "zh": "ç„¶åï¼Œè¿™ä¸ªçŸ©å½¢çš„é«˜åº¦ä¹Ÿæ˜¾ç¤ºäº†å››åˆ†ä½æ•°é—´çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.2â€ƒThe Chain Rule",
            "zh": "C.2 è¿é”æ³•åˆ™"
        }
    },
    {
        "translation": {
            "en": "Table 6.7",
            "zh": "è¡¨ 6.7"
        }
    },
    {
        "translation": {
            "en": "There are, in fact, multiple ways of mathematically defining a weighted sum calculation: we can use the âˆ‘ symbol to reduce the length of the equation, or we can represent it as a dot product or as a matrix product",
            "zh": "äº‹å®ä¸Šï¼Œæœ‰å¤šç§æ–¹æ³•å¯ä»¥åœ¨æ•°å­¦ä¸Šå®šä¹‰åŠ æƒå’Œè®¡ç®—ï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨âˆ‘ç¬¦å·æ¥ç¼©çŸ­æ–¹ç¨‹çš„é•¿åº¦ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥å°†å…¶è¡¨ç¤ºä¸ºç‚¹ç§¯æˆ–çŸ©é˜µç§¯"
        }
    },
    {
        "translation": {
            "en": "negative level, 537",
            "zh": "è´Ÿæ°´å¹³ï¼Œ537"
        }
    },
    {
        "translation": {
            "en": "17. These are covered in Section 9.4.1[540].",
            "zh": "17. è¿™äº›å†…å®¹è¯¦è§ç¬¬9.4.1èŠ‚[540]ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Table A.1[750] lists the position that each player on a school basketball team plays at, and the average training expenses accrued each month by each player on the team. Table A.2[750] shows the frequencies and proportions of the positions that players in the team play at, based on counts of the occurrences of the different levels of the POSITION feature in Table A.1[750]. We can see from this example that the guard level is the most frequent, followed by forward and center.",
            "zh": "ä¾‹å¦‚ï¼Œè¡¨A.1[750]åˆ—å‡ºäº†å­¦æ ¡ç¯®çƒé˜Ÿä¸­æ¯ä¸ªçƒå‘˜æ‰€å¤„çš„ä½ç½®ï¼Œä»¥åŠè¯¥é˜Ÿä¸­æ¯ä¸ªçƒå‘˜æ¯æœˆåº”è®¡çš„å¹³å‡è®­ç»ƒè´¹ç”¨ã€‚è¡¨A.2[750]æ ¹æ®è¡¨A.1[750]ä¸­ä¸åŒçº§åˆ«çš„POSITIONç‰¹å¾çš„å‡ºç°æ¬¡æ•°ï¼Œæ˜¾ç¤ºäº†çƒé˜Ÿä¸­çƒå‘˜æ‰€å¤„ä½ç½®çš„é¢‘ç‡å’Œæ¯”ä¾‹ã€‚ä»è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œåå«çº§åˆ«æ˜¯æœ€å¸¸è§çš„ï¼Œå…¶æ¬¡æ˜¯å‰é”‹å’Œä¸­é”‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Any function can be approximated by combining disconnected regions.",
            "zh": "ä»»ä½•å‡½æ•°éƒ½å¯ä»¥é€šè¿‡ç»„åˆæ–­å¼€çš„åŒºåŸŸæ¥è¿‘ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic curve, 558, 589",
            "zh": "æ¥æ”¶æœºå·¥ä½œç‰¹æ€§æ›²çº¿ï¼Œ558ã€589"
        }
    },
    {
        "translation": {
            "en": "The derivative used to backpropagate Î´s through the rectifierparametric function is then defined as",
            "zh": "ç„¶åï¼Œç”¨äºé€šè¿‡æ•´æµå™¨å‚æ•°å‡½æ•°åå‘ä¼ æ’­ Î´s çš„å¯¼æ•°å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "This equation expands Equation (8.14)[408] using the difference âˆ’ (t k âˆ’ ak) as the value for âˆ‚â„°/âˆ‚ak.",
            "zh": "è¯¥æ–¹ç¨‹æ‰©å±•äº†æ–¹ç¨‹ï¼ˆ8.14ï¼‰[408]ï¼Œä½¿ç”¨å·®å€¼ âˆ’ ï¼ˆt k âˆ’ akï¼‰ ä½œä¸º âˆ‚E/âˆ‚ak çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case we can see that distributions of the levels of the SHOE SPONSOR feature are not the same for each position.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªä½ç½®çš„ SHOE SPONSOR åŠŸèƒ½çº§åˆ«çš„åˆ†å¸ƒå¹¶ä¸ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "HANDSETPRICE",
            "zh": "æ‰‹æœºä»·æ ¼"
        }
    },
    {
        "translation": {
            "en": "7.14â€…â€…â€…A scatter plot of the extended generators dataset given in Table 7.7[347], which results in instances with the different target levels overlapping each other. Instances representing good generators are shown as crosses, and those representing faulty generators as triangles.",
            "zh": "7.14 è¡¨7.7[347]ä¸­ç»™å‡ºçš„æ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œå¯¼è‡´ä¸åŒç›®æ ‡æ°´å¹³ç›¸äº’é‡å çš„å®ä¾‹ã€‚è¡¨ç¤ºè‰¯å¥½ç”Ÿæˆå™¨çš„å®ä¾‹æ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œè¡¨ç¤ºæ•…éšœç”Ÿæˆå™¨çš„å®ä¾‹æ˜¾ç¤ºä¸ºä¸‰è§’å½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the prior and posterior probabilities are similar, then the information content in the observation was low.",
            "zh": "å¦‚æœå…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡ç›¸ä¼¼ï¼Œåˆ™è§‚æµ‹ä¸­çš„ä¿¡æ¯å«é‡è¾ƒä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is a serious problem because the ability of a deep neural network to learn a useful representation of the inputs works by the earlier layers of the network extracting low-level features from the raw data and then the later layers learning to combine these features in useful ways (see Figure 8.10[402] for an illustration of this for a three-layer network).",
            "zh": "è¿™æ˜¯ä¸€ä¸ªä¸¥é‡çš„é—®é¢˜ï¼Œå› ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œå­¦ä¹ è¾“å…¥çš„æœ‰ç”¨è¡¨ç¤ºçš„èƒ½åŠ›ç”±ç½‘ç»œçš„æ—©æœŸå±‚å·¥ä½œï¼Œä»åŸå§‹æ•°æ®ä¸­æå–ä½çº§ç‰¹å¾ï¼Œç„¶ååé¢çš„å±‚å­¦ä¹ ä»¥æœ‰ç”¨çš„æ–¹å¼ç»„åˆè¿™äº›ç‰¹å¾ï¼ˆå‚è§å›¾ 8.10[402] äº†è§£ä¸‰å±‚ç½‘ç»œçš„è¯´æ˜ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conversely, if we increased the dimension of our filter to a 4-by-4 filter, then we could cover the input with a 3-by-3 layer of neurons generating a 3-by-3 feature map.",
            "zh": "ç›¸åï¼Œå¦‚æœæˆ‘ä»¬å°†æ»¤æ³¢å™¨çš„ç»´åº¦å¢åŠ åˆ° 4Ã—4 æ»¤æ³¢å™¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç”¨ 3Ã—3 çš„ç¥ç»å…ƒå±‚è¦†ç›–è¾“å…¥ï¼Œä»è€Œç”Ÿæˆ 3Ã—3 çš„ç‰¹å¾å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customerâ€™s credit rating",
            "zh": "å®¢æˆ·çš„ä¿¡ç”¨è¯„çº§"
        }
    },
    {
        "translation": {
            "en": "The profit matrix for the payday loan credit scoring problem.",
            "zh": "å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜çš„åˆ©æ¶¦çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Generative Adversarial Networks, 523",
            "zh": "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œ523"
        }
    },
    {
        "translation": {
            "en": "natural logarithm, 580",
            "zh": "è‡ªç„¶å¯¹æ•°ï¼Œ580"
        }
    },
    {
        "translation": {
            "en": "The change to the mechanism for selecting the best feature to split on (made on Line 1) and the introduction of an early stopping criterion (which replaces Line 1) are the only modifications we need to make to the ID3 algorithm (Algorithm 1[134]) to allow it to handle continuous target features.",
            "zh": "å¯¹é€‰æ‹©è¦æ‹†åˆ†çš„æœ€ä½³ç‰¹å¾çš„æœºåˆ¶çš„æ›´æ”¹ï¼ˆåœ¨ç¬¬ 1 è¡Œä¸Šè¿›è¡Œï¼‰å’Œå¼•å…¥æå‰åœæ­¢æ ‡å‡†ï¼ˆå–ä»£ç¬¬ 1 è¡Œï¼‰æ˜¯æˆ‘ä»¬éœ€è¦å¯¹ ID3 ç®—æ³•ï¼ˆç®—æ³• 1[134]ï¼‰è¿›è¡Œçš„å”¯ä¸€ä¿®æ”¹ï¼Œä»¥å…è®¸å®ƒå¤„ç†è¿ç»­çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability theory, 243, 757",
            "zh": "æ¦‚ç‡è®ºï¼Œ 243ï¼Œ 757"
        }
    },
    {
        "translation": {
            "en": "Klotz, Irving M. 1980. The n-ray affair. Scientific American 242 (5): 122â€“131.",
            "zh": "å…‹æ´›èŒ¨ï¼Œæ¬§æ–‡ M. 1980 å¹´ã€‚nå°„çº¿äº‹ä»¶ã€‚ç§‘å­¦ç¾å›½äºº242ï¼ˆ5ï¼‰ï¼š122-131ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that ignoring the subscripts, the expression we are summing in Equation (6.4)[250] is identical to the numerator in Bayesâ€™ Theorem. This gives us a way to calculate the posterior probability distribution over the possible assignment of values to the features in event X conditioned on the event Y, that is, P(X | Y), which avoids explicitly calculating P(Y). If we let",
            "zh": "è¯·æ³¨æ„ï¼Œå¿½ç•¥ä¸‹æ ‡ï¼Œæˆ‘ä»¬åœ¨æ–¹ç¨‹ï¼ˆ6.4ï¼‰[250]ä¸­æ±‚å’Œçš„è¡¨è¾¾å¼ä¸è´å¶æ–¯å®šç†ä¸­çš„åˆ†å­ç›¸åŒã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æ–¹æ³•æ¥è®¡ç®—ä»¥äº‹ä»¶ Y ä¸ºæ¡ä»¶çš„äº‹ä»¶ X ä¸­å¯èƒ½å°†å€¼åˆ†é…ç»™ç‰¹å¾çš„åéªŒæ¦‚ç‡åˆ†å¸ƒï¼Œå³ Pï¼ˆX |Yï¼‰ï¼Œé¿å…æ˜¾å¼è®¡ç®— Pï¼ˆYï¼‰ã€‚å¦‚æœæˆ‘ä»¬è®©"
        }
    },
    {
        "translation": {
            "en": "All these chapters follow the same two-part structure:",
            "zh": "æ‰€æœ‰è¿™äº›ç« èŠ‚éƒ½éµå¾ªç›¸åŒçš„ä¸¤éƒ¨åˆ†ç»“æ„ï¼š"
        }
    },
    {
        "translation": {
            "en": "calculate these missing distances in the preceding distance matrix (note that because this is a distance (or dissimilarity) matrix rather than a similarity matrix, the values shown are 1 âˆ’ simJ(q,d)).",
            "zh": "åœ¨å‰é¢çš„è·ç¦»çŸ©é˜µä¸­è®¡ç®—è¿™äº›ç¼ºå¤±çš„è·ç¦»ï¼ˆè¯·æ³¨æ„ï¼Œç”±äºè¿™æ˜¯è·ç¦»ï¼ˆæˆ–ä¸åŒåº¦ï¼‰çŸ©é˜µè€Œä¸æ˜¯ç›¸ä¼¼æ€§çŸ©é˜µï¼Œå› æ­¤æ˜¾ç¤ºçš„å€¼ä¸º 1 âˆ’ simJï¼ˆqï¼Œdï¼‰ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "8. Note that in this example, we have normalized the RENTAL PRICE and SIZE features to the range [âˆ’1, 1], so the error surfaces shown look slightly different from those shown in Figure 7.3[318] and Figure 7.5[329].",
            "zh": "8. è¯·æ³¨æ„ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å·²å°† RENTAL PRICE å’Œ SIZE ç‰¹å¾å½’ä¸€åŒ–ä¸º [âˆ’1ï¼Œ 1] èŒƒå›´ï¼Œå› æ­¤æ˜¾ç¤ºçš„è¯¯å·®æ›²é¢çœ‹èµ·æ¥ä¸å›¾ 7.3[318] å’Œå›¾ 7.5[329] ä¸­æ˜¾ç¤ºçš„è¯¯å·®æ›²é¢ç•¥æœ‰ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "As approaches 1, then the negative log of this probability approaches 0.",
            "zh": "å½“æ¥è¿‘ 1 æ—¶ï¼Œåˆ™è¯¥æ¦‚ç‡çš„è´Ÿå¯¹æ•°æ¥è¿‘ 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the ROC index for this model using the trapezoidal method and the following set of thresholds: 1.0, 0.5, and 0.0.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨æ¢¯å½¢æ–¹æ³•å’Œä»¥ä¸‹ä¸€ç»„é˜ˆå€¼è®¡ç®—è¯¥æ¨¡å‹çš„ ROC æŒ‡æ•°ï¼š1.0ã€0.5 å’Œ 0.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "In early convolution networks, the activation of sub-sampling neurons was often the average of the values in the feature map covered by the local receptive field of the neuron.",
            "zh": "åœ¨æ—©æœŸçš„å·ç§¯ç½‘ç»œä¸­ï¼Œå­é‡‡æ ·ç¥ç»å…ƒçš„æ¿€æ´»é€šå¸¸æ˜¯ç¥ç»å…ƒå±€éƒ¨æ„Ÿå—é‡æ‰€è¦†ç›–çš„ç‰¹å¾å›¾ä¸­å€¼çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this context, the neuron will apply a different 2-by-2 filter to each color channel: one 2-by-2 filter is applied to the red values of the pixels in the receptive field; another 2-by-2 filter is applied to the green values of the pixels in the receptive field; and the third 2-by-2 filter is applied to the blue values of the pixels in the receptive field.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¥ç»å…ƒå°†å¯¹æ¯ä¸ªé¢œè‰²é€šé“åº”ç”¨ä¸åŒçš„ 2Ã—2 æ»¤å…‰ç‰‡ï¼šä¸€ä¸ª 2Ã—2 æ»¤å…‰ç‰‡åº”ç”¨äºæ„Ÿå—é‡ä¸­åƒç´ çš„çº¢è‰²å€¼;å¦ä¸€ä¸ª 2Ã—2 æ»¤å…‰ç‰‡åº”ç”¨äºæ„Ÿå—é‡ä¸­åƒç´ çš„ç»¿è‰²å€¼;ç¬¬ä¸‰ä¸ª 2Ã—2 æ»¤æ³¢å™¨åº”ç”¨äºæ„Ÿå—é‡ä¸­åƒç´ çš„è“è‰²å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(short) (deep)â€ plan is also an ideal course plan for a short (one-week) professional training course.",
            "zh": "ï¼ˆçŸ­ï¼‰ï¼ˆæ·±åº¦ï¼‰â€œè®¡åˆ’ä¹Ÿæ˜¯çŸ­æœŸï¼ˆä¸€å‘¨ï¼‰ä¸“ä¸šåŸ¹è®­è¯¾ç¨‹çš„ç†æƒ³è¯¾ç¨‹è®¡åˆ’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.25",
            "zh": "å›¾ 8.25"
        }
    },
    {
        "translation": {
            "en": "Figure 2.4[35] shows examples of these different data types.",
            "zh": "å›¾ 2.4[35] æ˜¾ç¤ºäº†è¿™äº›ä¸åŒæ•°æ®ç±»å‹çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The stability index is calculated as",
            "zh": "ç¨³å®šæ€§æŒ‡æ•°è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "The columns in the table are labeled Prediction-positive and Prediction-negative and represent the predictions generated by a model, which is either positive or negative.",
            "zh": "è¡¨ä¸­çš„åˆ—æ ‡è®°ä¸ºâ€œé¢„æµ‹æ­£â€å’Œâ€œé¢„æµ‹è´Ÿâ€ï¼Œè¡¨ç¤ºæ¨¡å‹ç”Ÿæˆçš„é¢„æµ‹ï¼Œè¯¥é¢„æµ‹ä¸ºæ­£æˆ–è´Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "3. The p-value is compared to a predefined significance threshold, and if the p-value is less than or equal to the threshold (i.e., the p-value is small), the null hypothesis is rejected. These thresholds are typically the standard statistical thresholds of 5% or 1%.",
            "zh": "3. å°† p å€¼ä¸é¢„å®šä¹‰çš„æ˜¾è‘—æ€§é˜ˆå€¼è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœ p å€¼å°äºæˆ–ç­‰äºé˜ˆå€¼ï¼ˆå³ p å€¼è¾ƒå°ï¼‰ï¼Œåˆ™æ‹’ç»åŸå‡è®¾ã€‚è¿™äº›é˜ˆå€¼é€šå¸¸æ˜¯ 5% æˆ– 1% çš„æ ‡å‡†ç»Ÿè®¡é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.27",
            "zh": "å›¾ 8.27"
        }
    },
    {
        "translation": {
            "en": "AVGDROPPEDCALLS",
            "zh": "AVGDROPPEDå‘¼å«"
        }
    },
    {
        "translation": {
            "en": "We can say that because of the purity of the splits that it makes, the SUSPICIOUS WORDS feature provides more information about the value of the target feature for an instance than the CONTAINS IMAGES feature, and so a tree that tests this descriptive feature at the root node is preferable.",
            "zh": "æˆ‘ä»¬å¯ä»¥è¯´ï¼Œç”±äºå®ƒæ‰€åšçš„æ‹†åˆ†çš„çº¯åº¦ï¼ŒSUSPICIOUS WORDS åŠŸèƒ½æä¾›äº†æ¯” CONTAINS IMAGES åŠŸèƒ½æ›´å¤šå…³äºå®ä¾‹çš„ç›®æ ‡åŠŸèƒ½å€¼çš„ä¿¡æ¯ï¼Œå› æ­¤åœ¨æ ¹èŠ‚ç‚¹æµ‹è¯•æ­¤æè¿°æ€§åŠŸèƒ½çš„æ ‘æ˜¯å¯å–çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The goal is to get across the river in the fewest steps possible without getting wet.",
            "zh": "ç›®æ ‡æ˜¯åœ¨ä¸è¢«æ·‹æ¹¿çš„æƒ…å†µä¸‹ä»¥å°½å¯èƒ½å°‘çš„æ­¥éª¤è¿‡æ²³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Q_U/G/R/I/Z",
            "zh": "Q_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Our goal, however, is still to estimate the performance of a model after deployment.",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬çš„ç›®æ ‡ä»ç„¶æ˜¯åœ¨éƒ¨ç½²åä¼°è®¡æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The pixels from an 8-by-8 pixel image can be flattened into a single vector of 64 values to give an ABT in which each descriptive feature for an instance (an image) represents the grayscale value for a particular pixel in that image.",
            "zh": "8Ã—8 åƒç´ å›¾åƒä¸­çš„åƒç´ å¯ä»¥å±•å¹³ä¸ºåŒ…å« 64 ä¸ªå€¼çš„å•ä¸ªå‘é‡ï¼Œä»¥ç»™å‡ºä¸€ä¸ª ABTï¼Œå…¶ä¸­å®ä¾‹ï¼ˆå›¾åƒï¼‰çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾è¡¨ç¤ºè¯¥å›¾åƒä¸­ç‰¹å®šåƒç´ çš„ç°åº¦å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for d1 the target one-hot encoding for Neuron 8 is 0, and as a result we use Equation (8.81)[469] to calculate the Î´; this entails simply copying the softmax activation.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äº d1ï¼Œç¥ç»å…ƒ 8 çš„ç›®æ ‡å•çƒ­ç¼–ç ä¸º 0ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨æ–¹ç¨‹ ï¼ˆ8.81ï¼‰[469] æ¥è®¡ç®—Î´;è¿™éœ€è¦ç®€å•åœ°å¤åˆ¶ SoftMax æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "These contracts did not have a fixed time and were essentially renewed every month when a customer paid a fixed recurring charge for that month.",
            "zh": "è¿™äº›åˆåŒæ²¡æœ‰å›ºå®šçš„æ—¶é—´ï¼ŒåŸºæœ¬ä¸Šæ¯ä¸ªæœˆéƒ½ä¼šç»­è®¢ï¼Œå½“å®¢æˆ·æ”¯ä»˜å½“æœˆçš„å›ºå®šç»å¸¸æ€§è´¹ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for merger category",
            "zh": "åˆå¹¶ç±»åˆ«çš„ç¥¨æ•°åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "negatively covariant, 74",
            "zh": "è´Ÿåå˜ï¼Œ74"
        }
    },
    {
        "translation": {
            "en": "Implementing a network as a sequence of matrix multiplications (1) speeds up the calculation of a weighted sum across each layer in the network, and (2) enables the network to parallelize the processing of examples.",
            "zh": "å°†ç½‘ç»œå®ç°ä¸ºçŸ©é˜µä¹˜æ³•åºåˆ— ï¼ˆ1ï¼‰ åŠ å¿«äº†ç½‘ç»œä¸­æ¯ä¸€å±‚åŠ æƒå’Œçš„è®¡ç®—é€Ÿåº¦ï¼Œä»¥åŠ ï¼ˆ2ï¼‰ ä½¿ç½‘ç»œèƒ½å¤Ÿå¹¶è¡Œå¤„ç†ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.98)[493] illustrates the structure of such a three-dimensional filter.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.98ï¼‰[493]è¯´æ˜äº†è¿™ç§ä¸‰ç»´æ»¤æ³¢å™¨çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second important principle relates to data protection legislation, and in particular the rules surrounding the use of personal data.",
            "zh": "ç¬¬äºŒé¡¹é‡è¦åŸåˆ™æ¶‰åŠæ•°æ®ä¿æŠ¤ç«‹æ³•ï¼Œç‰¹åˆ«æ˜¯æœ‰å…³ä¸ªäººæ•°æ®ä½¿ç”¨çš„è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the elliptical level was much more heavily represented than the others in both cases.",
            "zh": "ç›¸åï¼Œåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæ¤­åœ†å±‚çš„ä»£è¡¨æ€§éƒ½æ¯”å…¶ä»–æ°´å¹³é«˜å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "SYS. B.P.: The patientâ€™s systolic blood pressure",
            "zh": "ç³»ç»Ÿã€‚B.P.ï¼šæ‚£è€…çš„æ”¶ç¼©å‹"
        }
    },
    {
        "translation": {
            "en": "-0.3459",
            "zh": "-0.3459"
        }
    },
    {
        "translation": {
            "en": "Figure A.8(a)[756] shows the structure of a box plot.",
            "zh": "å›¾A.8ï¼ˆaï¼‰[756]æ˜¾ç¤ºäº†ç®±å½¢å›¾çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.8â€…â€…â€…Details of the first two iterations when the gradient descent algorithm is used to train a logistic regression model for the extended generators dataset given in Table 7.7[347].",
            "zh": "7.8 ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•è®­ç»ƒæ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„é€»è¾‘å›å½’æ¨¡å‹æ—¶å‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚è¡¨ 7.7[347] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "03.21",
            "zh": "03.21"
        }
    },
    {
        "translation": {
            "en": "Boosting works by iteratively creating models and adding them to the ensemble. The iteration stops when a predefined number of models have been added. During each iteration the algorithm does the following:",
            "zh": "Boosting çš„å·¥ä½œåŸç†æ˜¯è¿­ä»£åˆ›å»ºæ¨¡å‹å¹¶å°†å…¶æ·»åŠ åˆ°æ•´ä½“ä¸­ã€‚å½“æ·»åŠ äº†é¢„å®šä¹‰æ•°é‡çš„æ¨¡å‹æ—¶ï¼Œè¿­ä»£å°†åœæ­¢ã€‚åœ¨æ¯æ¬¡è¿­ä»£æœŸé—´ï¼Œç®—æ³•æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š"
        }
    },
    {
        "translation": {
            "en": "For every possible value of the threshold, in the range [0,1], there are corresponding TPR and TNR values.",
            "zh": "å¯¹äºé˜ˆå€¼çš„æ¯ä¸ªå¯èƒ½å€¼ï¼Œåœ¨ [0,1] èŒƒå›´å†…ï¼Œéƒ½æœ‰ç›¸åº”çš„ TPR å’Œ TNR å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.2â€…â€…â€…Fundamentals of Reinforcement Learning",
            "zh": "11.2.2 å¼ºåŒ–å­¦ä¹ åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "-0.4768",
            "zh": "-0.4768"
        }
    },
    {
        "translation": {
            "en": "Hinton, G. E. 2005. What kind of graphical model is the brain? In Proceedings of the 19th international joint conference on artificial intelligence (IJCAI-05). IJCAI.",
            "zh": "Hintonï¼Œ GE 2005 å¹´ã€‚å¤§è„‘æ˜¯ä»€ä¹ˆæ ·çš„å›¾å½¢æ¨¡å‹ï¼Ÿç¬¬19å±Šå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®ï¼ˆIJCAI-05ï¼‰è®ºæ–‡é›†ã€‚IJCAI."
        }
    },
    {
        "translation": {
            "en": "mean imputation, 374",
            "zh": "å¹³å‡æ’è¡¥ï¼Œ374"
        }
    },
    {
        "translation": {
            "en": "For similarity-based learning, the nice thing about the way feature spaces work is that if the values of the descriptive features of two or more instances in the dataset are the same, then these instances will be mapped to the same point in the feature space.",
            "zh": "å¯¹äºåŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ ï¼Œç‰¹å¾ç©ºé—´å·¥ä½œæ–¹å¼çš„å¥½å¤„æ˜¯ï¼Œå¦‚æœæ•°æ®é›†ä¸­ä¸¤ä¸ªæˆ–å¤šä¸ªå®ä¾‹çš„æè¿°æ€§ç‰¹å¾çš„å€¼ç›¸åŒï¼Œåˆ™è¿™äº›å®ä¾‹å°†è¢«æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´ä¸­çš„åŒä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sutton, Richard S., and Andrew G. Barto. 2018. Reinforcement learning: An introduction. MIT Press.",
            "zh": "è¨é¡¿ã€ç†æŸ¥å¾· S. å’Œå®‰å¾·é² G. å·´æ‰˜ã€‚2018. å¼ºåŒ–å­¦ä¹ ï¼šç®€ä»‹.éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "decision stumps, 165",
            "zh": "å†³ç­–æ ‘æ¡©ï¼Œ165"
        }
    },
    {
        "translation": {
            "en": "8.9â€…â€…â€…The per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "8.9 è®­ç»ƒåæ¯ä¸ªç¤ºä¾‹çš„é¢„æµ‹ã€è¯¯å·®å’Œè¯¯å·®å¹³æ–¹å’Œæ”¶æ•›åˆ° SSE < 0.0001ã€‚"
        }
    },
    {
        "translation": {
            "en": "16. See Tijms (2012), or any good probability textbook, for an introduction to the gamma function.",
            "zh": "16. å‚è§ Tijms ï¼ˆ2012ï¼‰ æˆ–ä»»ä½•å¥½çš„æ¦‚ç‡æ•™ç§‘ä¹¦ï¼Œäº†è§£ä¼½é©¬å‡½æ•°çš„ä»‹ç»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, feature selection algorithms often frame feature selection as a greedy local search problem, where each state in the search space specifies a subset of possible features.",
            "zh": "ç›¸åï¼Œç‰¹å¾é€‰æ‹©ç®—æ³•é€šå¸¸å°†ç‰¹å¾é€‰æ‹©è§†ä¸ºè´ªå©ªçš„å±€éƒ¨æœç´¢é—®é¢˜ï¼Œå…¶ä¸­æœç´¢ç©ºé—´ä¸­çš„æ¯ä¸ªçŠ¶æ€éƒ½æŒ‡å®šäº†å¯èƒ½ç‰¹å¾çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "naive Bayes model, 243, 261, 284, 308, 309, 556, 731, 732, 735, 736",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œ 243ï¼Œ 261ï¼Œ 284ï¼Œ 308ï¼Œ 309ï¼Œ 556ï¼Œ 731ï¼Œ 732ï¼Œ 735ï¼Œ 736"
        }
    },
    {
        "translation": {
            "en": "In many environments to which we would like to apply reinforcement learning, it becomes difficult to define a state representation that captures the nuances of the environment and does not lead to so many states as to become impossible to use with the tabular approaches described so far.",
            "zh": "åœ¨æˆ‘ä»¬å¸Œæœ›åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„è®¸å¤šç¯å¢ƒä¸­ï¼Œå¾ˆéš¾å®šä¹‰ä¸€ç§çŠ¶æ€è¡¨ç¤ºï¼Œå®ƒæ•è·äº†ç¯å¢ƒçš„ç»†å¾®å·®åˆ«ï¼Œå¹¶ä¸”ä¸ä¼šå¯¼è‡´å¦‚æ­¤å¤šçš„çŠ¶æ€ï¼Œä»¥è‡³äºæ— æ³•ä¸è¿„ä»Šä¸ºæ­¢æè¿°çš„è¡¨æ ¼æ–¹æ³•ä¸€èµ·ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. A credit card issuer has built two different credit scoring models that predict the propensity of customers to default on their loans. The outputs of the first model for a test dataset are shown in the table below.",
            "zh": "3. ä¸€å®¶ä¿¡ç”¨å¡å‘å¡æœºæ„å»ºç«‹äº†ä¸¤ç§ä¸åŒçš„ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å®¢æˆ·æ‹–æ¬ è´·æ¬¾çš„å€¾å‘ã€‚ä¸‹è¡¨æ˜¾ç¤ºäº†æµ‹è¯•æ•°æ®é›†çš„ç¬¬ä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to build an ABT for such a problem, a historical dataset of application details and subsequent repayment behavior is required (this might stretch back over multiple years depending on the terms of the loans in question).",
            "zh": "ä¸ºäº†é’ˆå¯¹æ­¤ç±»é—®é¢˜æ„å»º ABTï¼Œéœ€è¦åº”ç”¨ç¨‹åºè¯¦ç»†ä¿¡æ¯å’Œåç»­è¿˜æ¬¾è¡Œä¸ºçš„å†å²æ•°æ®é›†ï¼ˆæ ¹æ®ç›¸å…³è´·æ¬¾çš„æ¡æ¬¾ï¼Œè¿™å¯èƒ½ä¼šè¿½æº¯åˆ°å¤šå¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These outliers should be noted in the data quality plan for possible handling later in the project.",
            "zh": "è¿™äº›å¼‚å¸¸å€¼åº”åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­æ³¨æ˜ï¼Œä»¥ä¾¿åœ¨é¡¹ç›®åæœŸè¿›è¡Œå¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The probabilities, from Table 6.13[281], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, and AB = 759.07, and the calculation of the scores for each candidate prediction.",
            "zh": "ä»è¡¨ 6.13[281] ä¸­å¯ä»¥çœ‹å‡ºï¼Œæœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹å¯¹ CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹å’Œ AB = 759.07 çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„æ¦‚ç‡ï¼Œä»¥åŠæ¯ä¸ªå€™é€‰é¢„æµ‹çš„åˆ†æ•°è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.4â€ƒEarly Stopping and Dropout: Preventing Overfitting",
            "zh": "8.4.4 æå‰åœæ­¢å’Œé€€å‡ºï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ"
        }
    },
    {
        "translation": {
            "en": "This is misleading, however.",
            "zh": "ç„¶è€Œï¼Œè¿™æ˜¯è¯¯å¯¼æ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ecological modelers can use information about the type of vegetation that grows in a region as a direct input into their animal species management and conservation programs because areas covered in different types of vegetation support different animal species.",
            "zh": "ç”Ÿæ€å»ºæ¨¡è€…å¯ä»¥ä½¿ç”¨æœ‰å…³æŸä¸ªåœ°åŒºç”Ÿé•¿çš„æ¤è¢«ç±»å‹çš„ä¿¡æ¯ä½œä¸ºå…¶åŠ¨ç‰©ç‰©ç§ç®¡ç†å’Œä¿æŠ¤è®¡åˆ’çš„ç›´æ¥è¾“å…¥ï¼Œå› ä¸ºä¸åŒç±»å‹çš„æ¤è¢«è¦†ç›–çš„åŒºåŸŸæ”¯æŒä¸åŒçš„åŠ¨ç‰©ç‰©ç§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset from the loan application fraud detection domain (from Table 6.2[263]) with two continuous descriptive features added: ACCOUNT BALANCE and LOAN AMOUNT.",
            "zh": "æ¥è‡ªè´·æ¬¾ç”³è¯·æ¬ºè¯ˆæ£€æµ‹åŸŸçš„æ•°æ®é›†ï¼ˆæ¥è‡ªè¡¨ 6.2[263]ï¼‰ï¼Œæ·»åŠ äº†ä¸¤ä¸ªè¿ç»­çš„æè¿°æ€§ç‰¹å¾ï¼šACCOUNT BALANCE å’Œ LOAN AMOUNTã€‚"
        }
    },
    {
        "translation": {
            "en": "Several parallels can be drawn between probability-based learning and the other approaches to machine learning that we present in this book. Intuitively, the prior probability of a nearest neighbor model predicting a particular target level is simply the relative frequency of that target level in the dataset. For this reason, in general it is wrong to artificially balance the dataset used by a nearest neighbor model,31 and doing so biases the target level priors used by the model.",
            "zh": "åŸºäºæ¦‚ç‡çš„å­¦ä¹ å’Œæˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ä»‹ç»çš„å…¶ä»–æœºå™¨å­¦ä¹ æ–¹æ³•ä¹‹é—´å¯ä»¥å¾—å‡ºä¸€äº›ç›¸ä¼¼ä¹‹å¤„ã€‚ç›´è§‚åœ°è¯´ï¼Œæœ€è¿‘é‚»æ¨¡å‹é¢„æµ‹ç‰¹å®šç›®æ ‡æ°´å¹³çš„å…ˆéªŒæ¦‚ç‡åªæ˜¯è¯¥ç›®æ ‡æ°´å¹³åœ¨æ•°æ®é›†ä¸­çš„ç›¸å¯¹é¢‘ç‡ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œäººä¸ºåœ°å¹³è¡¡æœ€è¿‘é‚»æ¨¡å‹ä½¿ç”¨çš„æ•°æ®é›†æ˜¯é”™è¯¯çš„ï¼Œ31 è¿™æ ·åšä¼šåå‘æ¨¡å‹ä½¿ç”¨çš„ç›®æ ‡æ°´å¹³å…ˆéªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.6",
            "zh": "è¡¨ 7.6"
        }
    },
    {
        "translation": {
            "en": "In backpropagating the error â„°t=2 we will calculate a single error gradient for each weight in Wyh and two error gradients for each weight in Whh and Whx; when we backpropagated the error for y1 we calculated one error gradient for each weight in each of the three weight matrices.",
            "zh": "åœ¨åå‘ä¼ æ’­è¯¯å·® Et=2 æ—¶ï¼Œæˆ‘ä»¬å°†è®¡ç®— Wyh ä¸­æ¯ä¸ªæƒé‡çš„å•ä¸ªè¯¯å·®æ¢¯åº¦å’Œ Whh å’Œ Whx ä¸­æ¯ä¸ªæƒé‡çš„ä¸¤ä¸ªè¯¯å·®æ¢¯åº¦;å½“æˆ‘ä»¬åå‘ä¼ æ’­ Y1 çš„è¯¯å·®æ—¶ï¼Œæˆ‘ä»¬è®¡ç®—äº†ä¸‰ä¸ªæƒé‡çŸ©é˜µä¸­æ¯ä¸ªæƒé‡çš„ä¸€ä¸ªè¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.19",
            "zh": "å›¾ 4.19"
        }
    },
    {
        "translation": {
            "en": "multi-feature, 319",
            "zh": "å¤šåŠŸèƒ½ï¼Œ 319"
        }
    },
    {
        "translation": {
            "en": "Figure 5.1[184] is a scatter plot to illustrate the resulting feature space when we do this using the data in Table 5.2[183].",
            "zh": "å›¾5.1[184]æ˜¯ä¸€ä¸ªæ•£ç‚¹å›¾ï¼Œç”¨äºè¯´æ˜å½“æˆ‘ä»¬ä½¿ç”¨è¡¨5.2[183]ä¸­çš„æ•°æ®æ—¶å¾—åˆ°çš„ç‰¹å¾ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In what ways could a predictive analytics model help to address the business problem?",
            "zh": "é¢„æµ‹åˆ†ææ¨¡å‹å¯ä»¥é€šè¿‡å“ªäº›æ–¹å¼å¸®åŠ©è§£å†³ä¸šåŠ¡é—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "4.4.1â€…â€…â€…Alternative Feature Selection and Impurity Metrics",
            "zh": "4.4.1 æ›¿ä»£ç‰¹å¾é€‰æ‹©å’Œæ‚è´¨æŒ‡æ ‡"
        }
    },
    {
        "translation": {
            "en": "mean absolute error, 577, 578",
            "zh": "å¹³å‡ç»å¯¹è¯¯å·®ï¼Œ577,578"
        }
    },
    {
        "translation": {
            "en": "Figure 8.40",
            "zh": "å›¾ 8.40"
        }
    },
    {
        "translation": {
            "en": "Note that we use the notation câ€¡ to represent the vector of activations in the cell state in the interval between the update by the forget gate and the subsequent update by the input gate",
            "zh": "è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¦å· câ€¡ æ¥è¡¨ç¤ºåœ¨å¿˜è®°é—¨æ›´æ–°å’Œè¾“å…¥é—¨åç»­æ›´æ–°ä¹‹é—´çš„é—´éš”å†…ï¼Œå•å…ƒçŠ¶æ€ä¸­çš„æ¿€æ´»å‘é‡"
        }
    },
    {
        "translation": {
            "en": "13.4.1â€…â€…â€…Baseline Models",
            "zh": "13.4.1 åŸºçº¿æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "triangular inequality criterion, 184, 211",
            "zh": "ä¸‰è§’ä¸ç­‰å¼å‡†åˆ™ï¼Œ184,211"
        }
    },
    {
        "translation": {
            "en": "(b) What target level would a k-NN model with k = 3 and using Euclidean distance return for the same query?",
            "zh": "ï¼ˆbï¼‰ å¯¹äºåŒä¸€æŸ¥è¯¢ï¼Œk = 3 å¹¶ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„ k-NN æ¨¡å‹å°†è¿”å›ä»€ä¹ˆç›®æ ‡æ°´å¹³ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm is simple and reasonably effective, but this simple version leaves a number of questions unansweredâ€”can we make the process more efficient, how are clusterings evaluated, how is k chosen, and how are clusters interpreted?â€”and it works only for clusterings of a certain underlying structure.",
            "zh": "k-meansèšç±»ç®—æ³•ç®€å•ä¸”ç›¸å½“æœ‰æ•ˆï¼Œä½†æ˜¯è¿™ä¸ªç®€å•çš„ç‰ˆæœ¬ç•™ä¸‹äº†è®¸å¤šæœªå›ç­”çš„é—®é¢˜â€”â€”æˆ‘ä»¬èƒ½å¦ä½¿è¿™ä¸ªè¿‡ç¨‹æ›´æœ‰æ•ˆç‡ï¼Œå¦‚ä½•è¯„ä¼°èšç±»ï¼Œå¦‚ä½•é€‰æ‹©kï¼Œä»¥åŠå¦‚ä½•è§£é‡Šèšç±»ï¼Ÿâ€”â€”å®ƒåªé€‚ç”¨äºç‰¹å®šåº•å±‚ç»“æ„çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, because the rectifier linear function is unbounded,26 it is often the case that smaller learning rates are necessary in training a ReLU network than in training a network with logistic units.",
            "zh": "äº‹å®ä¸Šï¼Œç”±äºæ•´æµå™¨çº¿æ€§å‡½æ•°æ˜¯æ— ç•Œçš„ï¼Œ26 å› æ­¤ï¼Œåœ¨è®­ç»ƒ ReLU ç½‘ç»œæ—¶ï¼Œé€šå¸¸éœ€è¦æ¯”è®­ç»ƒå…·æœ‰é€»è¾‘å•å…ƒçš„ç½‘ç»œæ›´å°çš„å­¦ä¹ ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The domain concepts were developed through a series of workshops with representatives of various parts of the AT businessâ€”in particular the retention team, but also sales and marketing and billing.",
            "zh": "é¢†åŸŸæ¦‚å¿µæ˜¯é€šè¿‡ä¸€ç³»åˆ—ç ”è®¨ä¼šå¼€å‘çš„ï¼Œè¿™äº›ç ”è®¨ä¼šæ˜¯ä¸ATä¸šåŠ¡å„ä¸ªéƒ¨é—¨çš„ä»£è¡¨è¿›è¡Œçš„ï¼Œç‰¹åˆ«æ˜¯ä¿ç•™å›¢é˜Ÿï¼Œä»¥åŠé”€å”®ã€è¥é”€å’Œè®¡è´¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Real instances tend to cluster.",
            "zh": "çœŸå®å®ä¾‹å€¾å‘äºèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "15. Note that in this example and in the examples that follow, a normalized version of the generators dataset is used (all descriptive features are normalized to the range [âˆ’1, 1] using range normalization), so the weights in Equation (7.27)[342] are different from those in Equation (7.23)[339]. If it were not for normalization, these two sets of weights would be the same.",
            "zh": "15. è¯·æ³¨æ„ï¼Œåœ¨æœ¬ä¾‹å’Œéšåçš„ä¾‹ä¾‹ä¸­ï¼Œä½¿ç”¨äº†ç”Ÿæˆå™¨æ•°æ®é›†çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼ˆæ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–å°†èŒƒå›´ [âˆ’1ï¼Œ 1] å½’ä¸€åŒ–ï¼‰ï¼Œå› æ­¤ç­‰å¼ ï¼ˆ7.27ï¼‰[342] ä¸­çš„æƒé‡ä¸ç­‰å¼ ï¼ˆ7.23ï¼‰[339] ä¸­çš„æƒé‡ä¸åŒã€‚å¦‚æœä¸æ˜¯å½’ä¸€åŒ–ï¼Œè¿™ä¸¤ç»„æƒé‡å°†æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "edges, 286",
            "zh": "è¾¹ç¼˜ï¼Œ 286"
        }
    },
    {
        "translation": {
            "en": "Important application-based solutions for building predictive data analytics models include IBM SPSS, Knime Analytics Platform, RapidMiner Studio, SAS Enterprise Miner, and Weka.14 The tools by IBM and SAS are enterprise-wide solutions that integrate with the other offerings by these companies.",
            "zh": "ç”¨äºæ„å»ºé¢„æµ‹æ€§æ•°æ®åˆ†ææ¨¡å‹çš„é‡è¦åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ IBM SPSSã€Knime Analytics Platformã€RapidMiner Studioã€SAS Enterprise Miner å’Œ Weka.14 IBM å’Œ SAS çš„å·¥å…·æ˜¯ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼Œå¯ä¸è¿™äº›å…¬å¸çš„å…¶ä»–äº§å“é›†æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for the sake of space, here we illustrate the backpropagation process for a single example.",
            "zh": "ä½†æ˜¯ï¼Œä¸ºäº†ç¯‡å¹…æœ‰é™ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¸¾ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜åå‘ä¼ æ’­è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again the relevant performance measures are calculated on the test set and recorded.",
            "zh": "åŒæ ·ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—å¹¶è®°å½•ç›¸å…³çš„æ€§èƒ½æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although there remained some details left to agree on, the fact that the SDSS had defined their problem in terms of analytics meant that Jocelyn very easily completed the important step of converting a business problem into an analytics solution.",
            "zh": "å°½ç®¡è¿˜æœ‰ä¸€äº›ç»†èŠ‚éœ€è¦è¾¾æˆä¸€è‡´ï¼Œä½† SDSS å·²ç»æ ¹æ®åˆ†æå®šä¹‰äº†ä»–ä»¬çš„é—®é¢˜ï¼Œè¿™æ„å‘³ç€ Jocelyn éå¸¸è½»æ¾åœ°å®Œæˆäº†å°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆçš„é‡è¦æ­¥éª¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "1,250",
            "zh": "1,250"
        }
    },
    {
        "translation": {
            "en": "(c) What target level will a naive Bayes model predict for the query document in Part (b) of this question, if Laplace smoothing with k = 10 and a vocabulary size of 6 is used?",
            "zh": "ï¼ˆcï¼‰ å¦‚æœä½¿ç”¨ k = 10 ä¸”è¯æ±‡é‡ä¸º 6 çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹æœ¬é—®é¢˜ ï¼ˆbï¼‰ éƒ¨åˆ†ä¸­çš„æŸ¥è¯¢æ–‡æ¡£çš„ç›®æ ‡æ°´å¹³æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "12.4â€…â€…â€…The confusion matrix from the test of the AT churn prediction non-stratified hold-out test set.",
            "zh": "12.4 æ¥è‡ª AT æµå¤±é¢„æµ‹éåˆ†å±‚ä¿æŒæµ‹è¯•é›†çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two main ways in which causation can be mistakenly assumed.",
            "zh": "æœ‰ä¸¤ç§ä¸»è¦æ–¹å¼å¯ä»¥é”™è¯¯åœ°å‡è®¾å› æœå…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "When the silhouette is used in this approach, it is often referred to as the silhouette method.",
            "zh": "å½“åœ¨è¿™ç§æ–¹æ³•ä¸­ä½¿ç”¨å‰ªå½±æ—¶ï¼Œå®ƒé€šå¸¸è¢«ç§°ä¸ºå‰ªå½±æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with the techniques described in the previous section, sometimes these techniques are performed as part of the Data Preparation phase of CRISP-DM, but sometimes they are performed as part of the Modeling phase.",
            "zh": "ä¸ä¸Šä¸€èŠ‚ä¸­æè¿°çš„æŠ€æœ¯ä¸€æ ·ï¼Œæœ‰æ—¶è¿™äº›æŠ€æœ¯æ˜¯ä½œä¸º CRISP-DM æ•°æ®å‡†å¤‡é˜¶æ®µçš„ä¸€éƒ¨åˆ†æ‰§è¡Œçš„ï¼Œä½†æœ‰æ—¶å®ƒä»¬ä½œä¸ºå»ºæ¨¡é˜¶æ®µçš„ä¸€éƒ¨åˆ†æ‰§è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.9",
            "zh": "å›¾ 4.9"
        }
    },
    {
        "translation": {
            "en": "1. the vector of cell activations ct is passed through a layer of tanh units to create a vector of candidate output activations;",
            "zh": "1. ç»†èƒæ´»åŒ– CT çš„è½½ä½“é€šè¿‡ä¸€å±‚ Tanh å•å…ƒä»¥åˆ›å»ºå€™é€‰è¾“å‡ºæ´»åŒ–çš„è½½ä½“;"
        }
    },
    {
        "translation": {
            "en": "A proportion of of the values in a sample take values equal to or lower than the ith percentile of that sample.",
            "zh": "æ ·æœ¬ä¸­ä¸€å®šæ¯”ä¾‹çš„å€¼å–çš„å€¼ç­‰äºæˆ–å°äºè¯¥æ ·æœ¬çš„ç¬¬ i ä¸ªç™¾åˆ†ä½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.7â€…â€…â€…Exercises",
            "zh": "9.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "The second goal of data exploration is to determine whether or not the data in an ABT suffer from any data quality issues that could adversely affect the models that we build.",
            "zh": "æ•°æ®æ¢ç´¢çš„ç¬¬äºŒä¸ªç›®æ ‡æ˜¯ç¡®å®š ABT ä¸­çš„æ•°æ®æ˜¯å¦å­˜åœ¨ä»»ä½•å¯èƒ½å¯¹æˆ‘ä»¬æ„å»ºçš„æ¨¡å‹äº§ç”Ÿä¸åˆ©å½±å“çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "To see how this revised algorithm can induce a decision tree, we use the example of predicting the number of bike rentals per day for a city bike sharing program based on the SEASON and whether it is a WORK DAY.",
            "zh": "ä¸ºäº†äº†è§£è¿™ç§ä¿®è®¢åçš„ç®—æ³•å¦‚ä½•è¯±å¯¼å†³ç­–æ ‘ï¼Œæˆ‘ä»¬ä»¥é¢„æµ‹åŸå¸‚è‡ªè¡Œè½¦å…±äº«è®¡åˆ’æ¯å¤©çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°é‡ä¸ºä¾‹ï¼Œè¯¥ç¤ºä¾‹åŸºäºå­£èŠ‚ä»¥åŠå®ƒæ˜¯å¦æ˜¯å·¥ä½œæ—¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, we can adjust this by offsetting the values input into the distribution.",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åç§»è¾“å…¥åˆ°åˆ†å¸ƒä¸­çš„å€¼æ¥è°ƒæ•´è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, when dealing with binary features, we need simply state the probability of each feature being true, and the false value is understood as 1 minus this probability.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å¤„ç†äºŒè¿›åˆ¶ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦é™ˆè¿°æ¯ä¸ªç‰¹å¾ä¸ºçœŸçš„æ¦‚ç‡ï¼Œè€Œå‡å€¼è¢«ç†è§£ä¸º 1 å‡å»è¿™ä¸ªæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "CREDIT HISTORY captures the credit history of the applicant, and its levels are none (the applicant has no previous loans), paid (the applicant had loans previously and has paid them off), current (the applicant has existing loans and are current in repayments), and arrears (the applicant has existing loans and are in arrears in repayments).",
            "zh": "ä¿¡ç”¨è®°å½•æ•è·ç”³è¯·äººçš„ä¿¡ç”¨è®°å½•ï¼Œå…¶çº§åˆ«ä¸ºæ— ï¼ˆç”³è¯·äººä»¥å‰æ²¡æœ‰è´·æ¬¾ï¼‰ã€å·²æ”¯ä»˜ï¼ˆç”³è¯·äººä»¥å‰æœ‰è´·æ¬¾å¹¶å·²è¿˜æ¸…ï¼‰ã€å½“å‰ï¼ˆç”³è¯·äººå·²æœ‰è´·æ¬¾ä¸”å½“å‰è¿˜æ¬¾ï¼‰å’Œæ¬ æ¬¾ï¼ˆç”³è¯·äººå·²æœ‰è´·æ¬¾å¹¶æ‹–æ¬ è¿˜æ¬¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "They take a bootstrapping approach where estimates of action-value are iteratively improved on the basis of other estimates of action-value.",
            "zh": "ä»–ä»¬é‡‡ç”¨å¼•å¯¼æ–¹æ³•ï¼Œåœ¨è¡ŒåŠ¨ä»·å€¼çš„å…¶ä»–ä¼°è®¡çš„åŸºç¡€ä¸Šè¿­ä»£æ”¹è¿›è¡ŒåŠ¨ä»·å€¼çš„ä¼°è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each state is connected to all the other states that can be generated by adding or removing a single feature from that state.",
            "zh": "æ¯ä¸ªçŠ¶æ€éƒ½è¿æ¥åˆ°æ‰€æœ‰å…¶ä»–çŠ¶æ€ï¼Œè¿™äº›çŠ¶æ€å¯ä»¥é€šè¿‡åœ¨è¯¥çŠ¶æ€ä¸­æ·»åŠ æˆ–ç§»é™¤å•ä¸ªè¦ç´ æ¥ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Lunar Lander, 668",
            "zh": "æœˆçƒç€é™†å™¨ï¼Œ668"
        }
    },
    {
        "translation": {
            "en": "(d) What is the probability that JIM went shopping given that WINE=true?",
            "zh": "ï¼ˆdï¼‰ åœ¨WINE=trueçš„æƒ…å†µä¸‹ï¼ŒJIMå»è´­ç‰©çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Propensity models inherently have a temporal element, and when this is the case, we must take time into account when designing the ABT.",
            "zh": "å€¾å‘æ¨¡å‹æœ¬èº«å°±å…·æœ‰æ—¶é—´å› ç´ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨è®¾è®¡ ABT æ—¶å¿…é¡»è€ƒè™‘æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, although the likelihood of suffering from a headache and vomiting is quite high when someone has meningitis, the prior probability of having meningitis is quite low.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè™½ç„¶å½“æœ‰äººæ‚£æœ‰è„‘è†œç‚æ—¶ï¼Œå¤´ç—›å’Œå‘•åçš„å¯èƒ½æ€§ç›¸å½“é«˜ï¼Œä½†å…ˆå‰æ‚£è„‘è†œç‚çš„æ¦‚ç‡ç›¸å½“ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Define the topology of a Bayesian network that encodes these causal relationships between the following Boolean variables: JIM (Jim has done the shopping, true or false), MARTHA (Martha has done the shopping, true or false), WINE (wine has been purchased, true or false).",
            "zh": "ï¼ˆaï¼‰ å®šä¹‰è´å¶æ–¯ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ï¼Œè¯¥æ‹“æ‰‘å¯¹ä»¥ä¸‹å¸ƒå°”å˜é‡ä¹‹é—´çš„å› æœå…³ç³»è¿›è¡Œç¼–ç ï¼šJIMï¼ˆJim å·²è´­ç‰©ï¼ŒçœŸæˆ–å‡ï¼‰ã€MARTHAï¼ˆMartha å·²è´­ç‰©ï¼ŒçœŸæˆ–å‡ï¼‰ã€WINEï¼ˆå·²è´­ä¹°è‘¡è„é…’ï¼ŒçœŸæˆ–å‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where |ğ’œ| refers to the size of the test set on which performance measures were originally calculated, |ğ’œt=l| refers to the number of instances in the original test set for which the model made a prediction of level l for target t, |â„¬| and |â„¬t=l| refer to the same measurements on the newly collected dataset, and loge is the natural logarithm.24 In general,",
            "zh": "å…¶ä¸­ |A|æŒ‡æœ€åˆè®¡ç®—æ€§èƒ½åº¦é‡å€¼çš„æµ‹è¯•é›†çš„å¤§å°ï¼Œ|At=l|æŒ‡åŸå§‹æµ‹è¯•é›†ä¸­æ¨¡å‹å¯¹ç›®æ ‡ t è¿›è¡Œ l çº§é¢„æµ‹çš„å®ä¾‹æ•°ï¼Œ|B|å’Œ |Bt=l|å‚è€ƒæ–°æ”¶é›†çš„æ•°æ®é›†ä¸Šçš„ç›¸åŒæµ‹é‡å€¼ï¼Œloge æ˜¯è‡ªç„¶å¯¹æ•°.24 ä¸€èˆ¬æ¥è¯´ï¼Œ"
        }
    },
    {
        "translation": {
            "en": "10.1â€ƒBig Idea",
            "zh": "10.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "To overcome this contradiction temporal-difference learning uses an approach known as bootstrapping.",
            "zh": "ä¸ºäº†å…‹æœè¿™ä¸€çŸ›ç›¾ï¼Œæ—¶é—´å·®åˆ†å­¦ä¹ ä½¿ç”¨äº†ä¸€ç§ç§°ä¸ºè‡ªä¸¾çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2[387] shows plots of some of the activation functions that have been popular in neural networks over the last few decades, including the threshold, logistic, tanh, and rectifier linear functions.",
            "zh": "å›¾8.2[387]æ˜¾ç¤ºäº†è¿‡å»å‡ åå¹´æ¥åœ¨ç¥ç»ç½‘ç»œä¸­æµè¡Œçš„ä¸€äº›æ¿€æ´»å‡½æ•°çš„å›¾ï¼ŒåŒ…æ‹¬é˜ˆå€¼å‡½æ•°ã€é€»è¾‘å‡½æ•°ã€tanhå‡½æ•°å’Œæ•´æµå™¨çº¿æ€§å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if the error is sensitive to changes in the weight, then the error is dependent on the weight and accordingly the current weight is to blame for some portion of the error.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœè¯¯å·®å¯¹æƒé‡çš„å˜åŒ–å¾ˆæ•æ„Ÿï¼Œåˆ™è¯¯å·®å–å†³äºæƒé‡ï¼Œå› æ­¤å½“å‰æƒé‡åº”å½’å’äºè¯¯å·®çš„æŸäº›éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Full details of the SDSS project, which is fascinating, are available at www.sdss.org.",
            "zh": "1. SDSSé¡¹ç›®çš„å…¨éƒ¨ç»†èŠ‚ä»¤äººç€è¿·ï¼Œå¯åœ¨ www.sdss.org ä¸Šæ‰¾åˆ°ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. See Chapter 2[23].",
            "zh": "[5]è§ç¬¬2ç« [23]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hourly samples of ambient factors and full load electrical power output of a combined cycle power plant.",
            "zh": "è”åˆå¾ªç¯ç”µå‚ç¯å¢ƒå› ç´ å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„æ¯å°æ—¶æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data exploration is a key part of both the Data Understanding and Data Preparation phases of CRISP-DM.",
            "zh": "æ•°æ®æ¢ç´¢æ˜¯ CRISP-DM æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µçš„å…³é”®éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.2â€…â€…â€…Data Understanding",
            "zh": "12.2 æ•°æ®ç†è§£"
        }
    },
    {
        "translation": {
            "en": "â€”Claude Elwood Shannon",
            "zh": "â€”â€”å…‹åŠ³å¾·Â·åŸƒå°”ä¼å¾·Â·é¦™å†œ"
        }
    },
    {
        "translation": {
            "en": "A similar analysis also explains the exploding Î´ values plotted in Figure 8.24(d)[454].",
            "zh": "ç±»ä¼¼çš„åˆ†æä¹Ÿè§£é‡Šäº†å›¾8.24ï¼ˆdï¼‰[454]ä¸­ç»˜åˆ¶çš„çˆ†ç‚¸Î´å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Alimoglu, Fevzi, and Ethem Alpaydin. 1996. Methods of combining multiple classifiers based on different representations for pen-based handwritten digit recognition. In Proceedings of the fifth Turkish artificial intelligence and artificial neural networks symposium (TAINNâ€™96).",
            "zh": "Alimogluã€Fevzi å’Œ Ethem Alpaydinã€‚1996. åŸºäºä¸åŒè¡¨ç¤ºçš„å¤šä¸ªåˆ†ç±»å™¨ç»„åˆæ–¹æ³•ï¼Œç”¨äºåŸºäºç¬”çš„æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚åœ¨ç¬¬äº”å±ŠåœŸè€³å…¶äººå·¥æ™ºèƒ½å’Œäººå·¥ç¥ç»ç½‘ç»œç ”è®¨ä¼šï¼ˆTAINN'96ï¼‰çš„è®ºæ–‡é›†ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "When we find data quality issues due to valid data during data exploration, we should note these issues in a data quality plan for potential handling later in the project.",
            "zh": "å½“æˆ‘ä»¬åœ¨æ•°æ®æ¢ç´¢è¿‡ç¨‹ä¸­å‘ç°ç”±äºæœ‰æ•ˆæ•°æ®è€Œå¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­è®°å½•è¿™äº›é—®é¢˜ï¼Œä»¥ä¾¿åœ¨é¡¹ç›®åæœŸè¿›è¡Œå¯èƒ½çš„å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "target hypersphere, 201",
            "zh": "ç›®æ ‡è¶…çƒä½“ï¼Œ201"
        }
    },
    {
        "translation": {
            "en": "Notice that each of the neurons in the output layer (Neurons 3, 4, and 5) are independent of each other; they receive no information from each other.",
            "zh": "è¯·æ³¨æ„ï¼Œè¾“å‡ºå±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 3ã€4 å’Œ 5ï¼‰éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„;ä»–ä»¬ä¹‹é—´æ²¡æœ‰æ”¶åˆ°ä»»ä½•ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "representation learning, 401, 599, 624, 629",
            "zh": "è¡¨ç¤ºå­¦ä¹ ï¼Œ401,599,624,629"
        }
    },
    {
        "translation": {
            "en": "The instances in this table have been sorted by these scores in ascending order; as a result, the thresholding on the scores to generate predictions is very much apparent.",
            "zh": "æ­¤è¡¨ä¸­çš„å®ä¾‹å·²æŒ‰è¿™äº›åˆ†æ•°æŒ‰å‡åºæ’åº;å› æ­¤ï¼Œç”Ÿæˆé¢„æµ‹çš„åˆ†æ•°é˜ˆå€¼éå¸¸æ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The per example error after each weight has been updated once, the per example âˆ‚â„°/âˆ‚a8, and the sum of squared errors for the model.",
            "zh": "æ¯ä¸ªæƒé‡æ›´æ–°ä¸€æ¬¡åçš„æ¯ä¸ªç¤ºä¾‹è¯¯å·®ã€æ¯ä¸ªç¤ºä¾‹ âˆ‚E/âˆ‚a8 å’Œæ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The boundary between d2 and d4 is",
            "zh": "d2 å’Œ d4 ä¹‹é—´çš„è¾¹ç•Œæ˜¯"
        }
    },
    {
        "translation": {
            "en": "The first part of each chapter presents an informal introduction to the material presented in the chapter, followed by a detailed explanation of the fundamental technical concepts required to understand the material. Then it presents a standard machine learning algorithm used in that learning approach, along with a detailed worked example.",
            "zh": "æ¯ç« çš„ç¬¬ä¸€éƒ¨åˆ†å¯¹æœ¬ç« ä¸­ä»‹ç»çš„ææ–™è¿›è¡Œäº†éæ­£å¼çš„ä»‹ç»ï¼Œç„¶åè¯¦ç»†è§£é‡Šäº†ç†è§£ææ–™æ‰€éœ€çš„åŸºæœ¬æŠ€æœ¯æ¦‚å¿µã€‚ç„¶åï¼Œå®ƒä»‹ç»äº†è¯¥å­¦ä¹ æ–¹æ³•ä¸­ä½¿ç”¨çš„æ ‡å‡†æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä»¥åŠè¯¦ç»†çš„å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "non-negativity criterion, 184, 211",
            "zh": "éè´Ÿæ€§æ ‡å‡†ï¼Œ184,211"
        }
    },
    {
        "translation": {
            "en": "None of this, however, yet explains how any actual learning takes place! This explanation appears subsequently, but before discussing reinforcement learning algorithms we will explain Markov decision processes, a useful mathematical framework into which we can place the key components of reinforcement learning to allow learning to take place.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›éƒ½æ²¡æœ‰è§£é‡Šä»»ä½•å®é™…çš„å­¦ä¹ æ˜¯å¦‚ä½•å‘ç”Ÿçš„ï¼è¿™ä¸ªè§£é‡Šéšåå‡ºç°ï¼Œä½†åœ¨è®¨è®ºå¼ºåŒ–å­¦ä¹ ç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬å°†è§£é‡Šé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ•°å­¦æ¡†æ¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†å¼ºåŒ–å­¦ä¹ çš„å…³é”®ç»„ä»¶æ”¾å…¥å…¶ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6â€…â€…â€…Evaluating Models after Deployment",
            "zh": "9.4.6 éƒ¨ç½²åè¯„ä¼°æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "Beyond knowing the correct terminology to use, an analytics practitioner who is situationally fluent will have sufficient knowledge of the quirks of a particular domain to be able to competently build analytics solutions for that domain.",
            "zh": "é™¤äº†çŸ¥é“è¦ä½¿ç”¨çš„æ­£ç¡®æœ¯è¯­ä¹‹å¤–ï¼Œç²¾é€šæƒ…å¢ƒçš„åˆ†æä»ä¸šè€…è¿˜å°†å¯¹ç‰¹å®šé¢†åŸŸçš„æ€ªç™–æœ‰è¶³å¤Ÿçš„äº†è§£ï¼Œä»¥ä¾¿èƒ½å¤Ÿèƒœä»»åœ°ä¸ºè¯¥é¢†åŸŸæ„å»ºåˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s look at Bayesâ€™ Theorem in a little more detail. Bayesâ€™ Theorem is easily derived from the product rule.7 We know from the product rule and the logical symmetry of the and operation8 that",
            "zh": "è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°çœ‹ä¸€ä¸‹è´å¶æ–¯å®šç†ã€‚è´å¶æ–¯å®šç†å¾ˆå®¹æ˜“ä»ä¹˜ç§¯æ³•åˆ™æ¨å¯¼å‡ºæ¥.7 æˆ‘ä»¬ä»ä¹˜ç§¯æ³•åˆ™å’Œ å’Œ è¿ç®—çš„é€»è¾‘å¯¹ç§°æ€§8 ä¸­çŸ¥é“"
        }
    },
    {
        "translation": {
            "en": "The features used at the top levels of both trees, and deemed most informative by the algorithm, were the same: AVGOVERBUNDLEMINS, BILLAMOUNTCHANGEPCT, and HANDSETAGE.",
            "zh": "åœ¨ä¸¤æ£µæ ‘çš„é¡¶å±‚ä½¿ç”¨çš„ç‰¹å¾æ˜¯ç›¸åŒçš„ï¼Œå¹¶ä¸”ç®—æ³•è®¤ä¸ºä¿¡æ¯é‡æœ€å¤§ï¼šAVGOVERBUNDLEMINSã€BILLAMOUNTCHANGEPCT å’Œ HANDSETAGEã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn generated histograms for all these features compared to the target featureâ€”for example, Figure 13.7[718] shows the histograms for the EXPRAD_R feature.",
            "zh": "Jocelyn ä¸ºæ‰€æœ‰è¿™äº›ç‰¹å¾ç”Ÿæˆäº†ä¸ç›®æ ‡ç‰¹å¾ç›¸æ¯”çš„ç›´æ–¹å›¾ï¼Œä¾‹å¦‚ï¼Œå›¾ 13.7[718] æ˜¾ç¤ºäº†EXPRAD_Rç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although this is useful for a range of real-world predictive analytics problems, we are also interested in prediction problems with categorical target features.",
            "zh": "å°½ç®¡è¿™å¯¹äºä¸€ç³»åˆ—å®é™…çš„é¢„æµ‹åˆ†æé—®é¢˜å¾ˆæœ‰ç”¨ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯¹å…·æœ‰åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„é¢„æµ‹é—®é¢˜æ„Ÿå…´è¶£ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.28â€…â€…â€…The forward pass of the mini-batch of examples listed in Table 8.13[464] through the network in Figure 8.27[465].",
            "zh": "8.28 è¡¨8.13[464]ä¸­åˆ—å‡ºçš„å°æ‰¹é‡ç¤ºä¾‹é€šè¿‡å›¾8.27[465]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, in each case a model is used to make a prediction to help a person or organization make a decision.",
            "zh": "é¦–å…ˆï¼Œåœ¨æ¯ç§æƒ…å†µä¸‹ï¼Œéƒ½ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œä»¥å¸®åŠ©ä¸ªäººæˆ–ç»„ç»‡åšå‡ºå†³ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "A generalized way in which to do this is to introduce basis functions that transform the raw inputs to the model into non-linear representations but still keep the model itself linear in terms of the weights.",
            "zh": "å®ç°æ­¤ç›®çš„çš„ä¸€ç§é€šç”¨æ–¹æ³•æ˜¯å¼•å…¥åŸºå‡½æ•°ï¼Œè¿™äº›å‡½æ•°å°†æ¨¡å‹çš„åŸå§‹è¾“å…¥è½¬æ¢ä¸ºéçº¿æ€§è¡¨ç¤ºï¼Œä½†ä»ä¿æŒæ¨¡å‹æœ¬èº«åœ¨æƒé‡æ–¹é¢çš„çº¿æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "output gate, 508, 512",
            "zh": "è¾“å‡ºæ …æï¼Œ508ã€512"
        }
    },
    {
        "translation": {
            "en": "As the number of descriptive features grows, the number of potential conditioning events grows.",
            "zh": "éšç€æè¿°æ€§ç‰¹å¾æ•°é‡çš„å¢åŠ ï¼Œæ½œåœ¨æ¡ä»¶åå°„äº‹ä»¶çš„æ•°é‡ä¹Ÿåœ¨å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This illustrates the big idea behind unsupervised learning.",
            "zh": "è¿™è¯´æ˜äº†æ— ç›‘ç£å­¦ä¹ èƒŒåçš„å¤§æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for every increase of a square foot in office size, we can expect the rental price to go up by 0.6270 Euro per month.",
            "zh": "ä¾‹å¦‚ï¼ŒåŠå…¬å®¤é¢ç§¯æ¯å¢åŠ ä¸€å¹³æ–¹è‹±å°ºï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸç§Ÿé‡‘ä»·æ ¼æ¯æœˆä¸Šæ¶¨ 0.6270 æ¬§å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For continuous features we should first examine the mean and standard deviation of each feature to get a sense of the central tendency and variation of the values within the dataset for the feature.",
            "zh": "å¯¹äºè¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬åº”é¦–å…ˆæ£€æŸ¥æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥äº†è§£ç‰¹å¾æ•°æ®é›†ä¸­å€¼çš„ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.21â€…â€…â€…A plot showing how the sum of squared errors of the ReLU network changed during training when Î± = 0.1.",
            "zh": "8.21 å½“ Î± = 0.1 æ—¶ï¼ŒReLU ç½‘ç»œçš„å¹³æ–¹è¯¯å·®å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–çš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "13. All datasets presented in this chapter have been structured as ABTs.",
            "zh": "13. æœ¬ç« ä»‹ç»çš„æ‰€æœ‰æ•°æ®é›†å‡é‡‡ç”¨ABTç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was confirmed by the business that the zeros in the INCOME feature actually represent missing values and that MARITAL STATUS and INCOME were collected together, leading to their both being missing for the same instances in the ABT.",
            "zh": "è¯¥ä¸šåŠ¡è¯å®ï¼ŒINCOME ç‰¹å¾ä¸­çš„é›¶å®é™…ä¸Šä»£è¡¨ç¼ºå¤±å€¼ï¼Œå¹¶ä¸” MARITAL STATUS å’Œ INCOME æ˜¯ä¸€èµ·æ”¶é›†çš„ï¼Œå¯¼è‡´å®ƒä»¬åœ¨ ABT ä¸­çš„ç›¸åŒå®ä¾‹ä¸­éƒ½ç¼ºå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this notation and taking the second layer of neurons in a network as an example, if we name the matrix containing the weights on the edges into Layer 2 as W(2), the column vector of activations coming from the neurons in Layer 1 as a(1), and the column vector of weighted sums for the neurons in Layer 2 as z(2), then the order of the matrices in the multiplication operation that we use in this explanation is",
            "zh": "ä½¿ç”¨è¿™ç§è¡¨ç¤ºæ³•ï¼Œå¹¶ä»¥ç½‘ç»œä¸­çš„ç¬¬äºŒå±‚ç¥ç»å…ƒä¸ºä¾‹ï¼Œå¦‚æœæˆ‘ä»¬å°†åŒ…å«è¾¹ç¼˜æƒé‡çš„çŸ©é˜µå‘½åä¸º Wï¼ˆ2ï¼‰ï¼Œå°†æ¥è‡ªç¬¬ 1 å±‚ç¥ç»å…ƒçš„æ¿€æ´»çš„åˆ—å‘é‡å‘½åä¸º aï¼ˆ1ï¼‰ï¼Œå°†ç¬¬ 2 å±‚ç¥ç»å…ƒçš„åŠ æƒå’Œçš„åˆ—å‘é‡å‘½åä¸º zï¼ˆ2ï¼‰ï¼Œ é‚£ä¹ˆæˆ‘ä»¬åœ¨è¿™ä¸ªè§£é‡Šä¸­ä½¿ç”¨çš„ä¹˜æ³•è¿ç®—ä¸­çŸ©é˜µçš„é¡ºåºæ˜¯"
        }
    },
    {
        "translation": {
            "en": "What is the predictive analytics target? What descriptive features will we include/exclude? How will we handle missing values? How will we normalize our features? How will we represent continuous features? What types of models will we create? How will we set the parameters of the learning algorithms? What evaluation process will we follow? What performance measures will we use?",
            "zh": "é¢„æµ‹åˆ†æç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å°†åŒ…å«/æ’é™¤å“ªäº›æè¿°æ€§ç‰¹å¾ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•è§„èŒƒåŒ–æˆ‘ä»¬çš„åŠŸèƒ½ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•è¡¨ç¤ºè¿ç»­ç‰¹å¾ï¼Ÿæˆ‘ä»¬å°†åˆ›å»ºå“ªäº›ç±»å‹çš„æ¨¡å‹ï¼Ÿæˆ‘ä»¬å°†å¦‚ä½•è®¾ç½®å­¦ä¹ ç®—æ³•çš„å‚æ•°ï¼Ÿæˆ‘ä»¬å°†éµå¾ªä»€ä¹ˆè¯„ä¼°æµç¨‹ï¼Ÿæˆ‘ä»¬å°†ä½¿ç”¨å“ªäº›ç»©æ•ˆè¡¡é‡æ ‡å‡†ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Another commonly used measure of central tendency is the mode.",
            "zh": "å¦ä¸€ä¸ªå¸¸ç”¨çš„é›†ä¸­è¶‹åŠ¿æµ‹é‡æ˜¯æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this nearest neighbor model, the marketing department wants to decide whether they should contact a customer with the following profile: SALARY = 56,000 and AGE = 35.",
            "zh": "ä½¿ç”¨æ­¤æœ€è¿‘é‚»æ¨¡å‹ï¼Œè¥é”€éƒ¨é—¨å¸Œæœ›å†³å®šæ˜¯å¦åº”è”ç³»å…·æœ‰ä»¥ä¸‹é…ç½®æ–‡ä»¶çš„å®¢æˆ·ï¼šSALARY = 56,000 å’Œ AGE = 35ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Twenty people flip a fair coin. What is the probability that exactly eight of them will get heads?",
            "zh": "ï¼ˆbï¼‰ äºŒåä¸ªäººæ·ä¸€æšå…¬å¹³çš„ç¡¬å¸ã€‚ä»–ä»¬ä¸­çš„å…«ä¸ªäººè·å¾—å¤´éƒ¨çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Activation Functions",
            "zh": "æ¿€æ´»å‡½æ•°"
        }
    },
    {
        "translation": {
            "en": "Later studies (Zadnik et al., 2000; Gwiazda et al., 2000), however, could not replicate this link, and eventually a more plausible explanation for the correlation between night-light use and near-sightedness was uncovered.",
            "zh": "åæ¥çš„ç ”ç©¶ï¼ˆZadnikç­‰äººï¼Œ2000å¹´;ç„¶è€Œï¼ŒGwiazda et al.ï¼Œ 2000ï¼‰æ— æ³•å¤åˆ¶è¿™ç§è”ç³»ï¼Œæœ€ç»ˆå‘ç°äº†å¯¹å¤œç¯ä½¿ç”¨ä¸è¿‘è§†ä¹‹é—´ç›¸å…³æ€§çš„æ›´åˆç†çš„è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "An ABT, however, rarely comes directly from a single source already existing within an organization.",
            "zh": "ç„¶è€Œï¼ŒABT å¾ˆå°‘ç›´æ¥æ¥è‡ªç»„ç»‡å†…å·²ç»å­˜åœ¨çš„å•ä¸€æ¥æºã€‚"
        }
    },
    {
        "translation": {
            "en": "A selection of the logistic regression models developed during the gradient descent process for the machinery dataset from Table 7.6[339]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "è¡¨7.6[339]ä¸­æœºæ¢°æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„é€»è¾‘å›å½’æ¨¡å‹çš„é€‰æ‹©ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions",
            "zh": "ç¬¦å·çº¦å®š"
        }
    },
    {
        "translation": {
            "en": "8.4.5.2â€ƒWeight sharing and translation equivariant feature detectionâ€ƒWhen a neuron applies a filter to its local receptive field, it is a local visual feature detector for which the visual feature is a pattern of input values.",
            "zh": "8.4.5.2 æƒé‡å…±äº«å’Œå¹³ç§»ç­‰å˜ç‰¹å¾æ£€æµ‹ å½“ç¥ç»å…ƒå¯¹å…¶å±€éƒ¨æ„Ÿå—é‡æ–½åŠ æ»¤æ³¢å™¨æ—¶ï¼Œå®ƒæ˜¯ä¸€ä¸ªå±€éƒ¨è§†è§‰ç‰¹å¾æ£€æµ‹å™¨ï¼Œå…¶è§†è§‰ç‰¹å¾æ˜¯è¾“å…¥å€¼çš„æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Is the data required by the solution available, or could it be made available?",
            "zh": "è§£å†³æ–¹æ¡ˆæ‰€éœ€çš„æ•°æ®æ˜¯å¦å¯ç”¨ï¼Œæˆ–è€…æ˜¯å¦å¯ä»¥æä¾›ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The other sets in Figure 4.5[124] have entropy values between these two extremes.",
            "zh": "å›¾4.5[124]ä¸­çš„å…¶ä»–é›†åˆçš„ç†µå€¼ä»‹äºè¿™ä¸¤ä¸ªæç«¯ä¹‹é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many cases, if the environment is fully observable this function is a simple identity function because the observation fully defines the state.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå¦‚æœç¯å¢ƒæ˜¯å®Œå…¨å¯è§‚å¯Ÿçš„ï¼Œåˆ™æ­¤å‡½æ•°æ˜¯ä¸€ä¸ªç®€å•çš„æ ‡è¯†å‡½æ•°ï¼Œå› ä¸ºè§‚å¯Ÿå®Œå…¨å®šä¹‰äº†çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have introduced two ways to represent the probabilities of events in a domain, a full joint probability distribution and a naive Bayes model.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ç§è¡¨ç¤ºåŸŸä¸­äº‹ä»¶æ¦‚ç‡çš„æ–¹æ³•ï¼Œä¸€ç§æ˜¯å®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œå¦ä¸€ç§æ˜¯æœ´ç´ è´å¶æ–¯æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, it looks very similar to a normal distribution, as shown in Figure 6.3(a)[270].",
            "zh": "äº‹å®ä¸Šï¼Œå®ƒçœ‹èµ·æ¥ä¸æ­£æ€åˆ†å¸ƒéå¸¸ç›¸ä¼¼ï¼Œå¦‚å›¾6.3ï¼ˆaï¼‰[270]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "HANDSETAGE: Based on a customerâ€™s latest handset entry, this feature captured the number of days that the customer had had his or her current handset.",
            "zh": "æ‰‹æœºï¼šæ ¹æ®å®¢æˆ·æœ€æ–°çš„æ‰‹æœºæ¡ç›®ï¼Œæ­¤åŠŸèƒ½æ•è·å®¢æˆ·æ‹¥æœ‰å½“å‰æ‰‹æœºçš„å¤©æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The business has decided to use a nearest neighbor model to predict whether a current trial user whose free trial period is about to end is likely to sign up for the paid service. The query instance, q, describing this user is:",
            "zh": "è¯¥ä¼ä¸šå·²å†³å®šä½¿ç”¨æœ€è¿‘é‚»æ¨¡å‹æ¥é¢„æµ‹å…è´¹è¯•ç”¨æœŸå³å°†ç»“æŸçš„å½“å‰è¯•ç”¨ç”¨æˆ·æ˜¯å¦æœ‰å¯èƒ½æ³¨å†Œä»˜è´¹æœåŠ¡ã€‚æè¿°æ­¤ç”¨æˆ·çš„æŸ¥è¯¢å®ä¾‹ q ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "(d) P(VOMITING = false | HEADACHE = true)",
            "zh": "ï¼ˆdï¼‰ Pï¼ˆVOMITING = å‡ |å¤´ç—› = çœŸï¼‰"
        }
    },
    {
        "translation": {
            "en": "In most cases, Ross confirmed with Kate and Grace that these were valid because the range of values that the features could take was naturally low.",
            "zh": "åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒRoss å‘ Kate å’Œ Grace ç¡®è®¤è¿™äº›æ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºè¿™äº›ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å€¼èŒƒå›´è‡ªç„¶å¾ˆä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Trying to compute the probability of P(h,f,Â¬v | m) directly from the data rather than using the chain rule also suffers from the same problem.",
            "zh": "å°è¯•ç›´æ¥ä»æ•°æ®ä¸­è®¡ç®— Pï¼ˆhï¼Œfï¼ŒÂ¬v | mï¼‰ çš„æ¦‚ç‡è€Œä¸æ˜¯ä½¿ç”¨é“¾å¼æ³•åˆ™ä¹Ÿä¼šé‡åˆ°åŒæ ·çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.3â€…â€…â€…The distances (Dist.) between the query instance with SPEED = 6.75 and AGILITY = 3.00 and each instance in Table 5.2[183].",
            "zh": "5.3 SPEED = 6.75 ä¸” AGILITY = 3.00 çš„æŸ¥è¯¢å®ä¾‹ä¸è¡¨ 5.2[183] ä¸­æ¯ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼ˆè·ç¦»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The stepping-stone crossing challenge described in Section 11.1[637] nicely illustrates the intelligent agent approach that underpins reinforcement learning.",
            "zh": "ç¬¬ 11.1 èŠ‚[637]ä¸­æè¿°çš„å«è„šçŸ³äº¤å‰æŒ‘æˆ˜å¾ˆå¥½åœ°è¯´æ˜äº†æ”¯æŒå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä»£ç†æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the terms y2 and 4y are treated as constants as they do not include x, and",
            "zh": "å…¶ä¸­é¡¹ y2 å’Œ 4y è¢«è§†ä¸ºå¸¸é‡ï¼Œå› ä¸ºå®ƒä»¬ä¸åŒ…æ‹¬ xï¼Œå¹¶ä¸”"
        }
    },
    {
        "translation": {
            "en": "To illustrate the use of an auto-encoder network for feature generation, we use a dataset of simple handwritten digits.14 This dataset contains a library of 1,797 small (8 pixels by 8 pixels) grayscale images of handwritten digits (0â€“9).",
            "zh": "ä¸ºäº†è¯´æ˜ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œç”Ÿæˆç‰¹å¾ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªç®€å•çš„æ‰‹å†™æ•°å­—æ•°æ®é›†.14 è¯¥æ•°æ®é›†åŒ…å« 1,797 ä¸ªæ‰‹å†™æ•°å­— ï¼ˆ0â€“9ï¼‰ çš„å°ï¼ˆ8 åƒç´  x 8 åƒç´ ï¼‰ç°åº¦å›¾åƒåº“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling is probably the simplest form of sampling that we can use and is most appropriate when we have very large datasets from which we can take samples.",
            "zh": "ä¿æŒæŠ½æ ·å¯èƒ½æ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„æœ€ç®€å•çš„æŠ½æ ·å½¢å¼ï¼Œå½“æˆ‘ä»¬æœ‰éå¸¸å¤§çš„æ•°æ®é›†å¯ä»¥ä»ä¸­è·å–æ ·æœ¬æ—¶ï¼Œè¿™æ˜¯æœ€åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other problem is that the network being used to generate targets is the actual network being trained.",
            "zh": "å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œç”¨äºç”Ÿæˆç›®æ ‡çš„ç½‘ç»œæ˜¯æ­£åœ¨è®­ç»ƒçš„å®é™…ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "The logical AND and OR functions are linearly separable, but the XOR is not. This figure is Figure 4.2 of Kelleher (2019) and is used here with permission.",
            "zh": "é€»è¾‘ AND å’Œ OR å‡½æ•°æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ï¼Œä½† XOR ä¸æ˜¯ã€‚æ­¤å›¾æ˜¯ Kelleher ï¼ˆ2019ï¼‰ çš„å›¾ 4.2ï¼Œç»è®¸å¯åœ¨æ­¤å¤„ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.004200",
            "zh": "-0.004200"
        }
    },
    {
        "translation": {
            "en": "Consequently, the model will return a price prediction that is the average price of these three neighbors:",
            "zh": "å› æ­¤ï¼Œæ¨¡å‹å°†è¿”å›ä¸€ä¸ªä»·æ ¼é¢„æµ‹ï¼Œå³è¿™ä¸‰ä¸ªé‚»å±…çš„å¹³å‡ä»·æ ¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "This poll put Obama ahead of Romney in the race to the White House.",
            "zh": "è¿™é¡¹æ°‘æ„è°ƒæŸ¥ä½¿å¥¥å·´é©¬åœ¨ç™½å®«ç«é€‰ä¸­é¢†å…ˆäºç½—å§†å°¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Full joint probability distributions, however, grow at an exponential rate as new features or feature levels are added to the domain.",
            "zh": "ä½†æ˜¯ï¼Œéšç€æ–°ç‰¹å¾æˆ–ç‰¹å¾çº§åˆ«æ·»åŠ åˆ°åŸŸä¸­ï¼Œå®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒä¼šä»¥æŒ‡æ•°é€Ÿåº¦å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this naive approach each instance presented to the network would be highly correlated with the previous instance presented (similar states would follow each other on the basis of actions taken) and independence would no longer be the case.",
            "zh": "åœ¨è¿™ç§å¹¼ç¨šçš„æ–¹æ³•ä¸­ï¼Œå‘ˆç°ç»™ç½‘ç»œçš„æ¯ä¸ªå®ä¾‹éƒ½å°†ä¸å‘ˆç°çš„å‰ä¸€ä¸ªå®ä¾‹é«˜åº¦ç›¸å…³ï¼ˆç›¸ä¼¼çš„çŠ¶æ€å°†æ ¹æ®æ‰€é‡‡å–çš„è¡ŒåŠ¨ç›¸äº’è·Ÿéšï¼‰ï¼Œå¹¶ä¸”ç‹¬ç«‹æ€§å°†ä¸å†å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "16. This example is very much simplified for illustration purposes, but very interesting work is done on building prediction models from the output of EEG and fMRI scansâ€”for example, Mitchell et al. (2008).",
            "zh": "16. ä¸ºäº†è¯´æ˜ç›®çš„ï¼Œè¿™ä¸ªä¾‹å­è¢«ç®€åŒ–äº†å¾ˆå¤šï¼Œä½†æ˜¯åœ¨æ ¹æ®è„‘ç”µå›¾å’ŒåŠŸèƒ½ç£å…±æŒ¯æˆåƒæ‰«æçš„è¾“å‡ºå»ºç«‹é¢„æµ‹æ¨¡å‹æ–¹é¢åšäº†éå¸¸æœ‰è¶£çš„å·¥ä½œâ€”â€”ä¾‹å¦‚ï¼ŒMitchellç­‰äººï¼ˆ2008ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "H.R. DIFF.: The difference between the patientâ€™s heart rate at this visit and at their last visit to the clinic",
            "zh": "HR å·®å¼‚ï¼šæ‚£è€…åœ¨è¿™æ¬¡å°±è¯Šæ—¶çš„å¿ƒç‡ä¸ä¸Šæ¬¡å°±è¯Šæ—¶çš„å¿ƒç‡ä¹‹é—´çš„å·®å¼‚"
        }
    },
    {
        "translation": {
            "en": "MCR4_U/G/R/I/Z",
            "zh": "MCR4_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15(b)[569] shows a cumulative gain chart of this data.",
            "zh": "å›¾9.15ï¼ˆbï¼‰[569]æ˜¾ç¤ºäº†è¯¥æ•°æ®çš„ç´¯ç§¯å¢ç›Šå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we use the concept of a probability distribution.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¦‚ç‡åˆ†å¸ƒçš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "12. While the name CRISP-DM refers to data mining (a field that overlaps significantly with predictive data analytics), it is equally applicable to predictive analytics projects.",
            "zh": "12. è™½ç„¶ CRISP-DM è¿™ä¸ªåç§°æŒ‡çš„æ˜¯æ•°æ®æŒ–æ˜ï¼ˆä¸€ä¸ªä¸é¢„æµ‹æ€§æ•°æ®åˆ†ææœ‰å¾ˆå¤§é‡å çš„é¢†åŸŸï¼‰ï¼Œä½†å®ƒåŒæ ·é€‚ç”¨äºé¢„æµ‹æ€§åˆ†æé¡¹ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6.1â€ƒNormalization",
            "zh": "3.6.1 å½’ä¸€åŒ–"
        }
    },
    {
        "translation": {
            "en": "5. The silhouette (Rousseeuw, 1987) is just one example of how clusterings can be evaluated. Others include the cubic clustering criterion (Sarle, 1983) and the Dunn index (Dunn, 1974); however, these are based on very similar ideas to the silhouette.",
            "zh": "5. è½®å»“ï¼ˆRousseeuwï¼Œ1987ï¼‰åªæ˜¯å¦‚ä½•è¯„ä¼°èšç±»çš„ä¸€ä¸ªä¾‹å­ã€‚å…¶ä»–åŒ…æ‹¬ä¸‰æ¬¡èšç±»å‡†åˆ™ï¼ˆSarleï¼Œ1983ï¼‰å’ŒDunnæŒ‡æ•°ï¼ˆDunnï¼Œ1974ï¼‰;ç„¶è€Œï¼Œè¿™äº›éƒ½æ˜¯åŸºäºä¸å‰ªå½±éå¸¸ç›¸ä¼¼çš„æƒ³æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often multiple features are required to fully express a single domain concept.",
            "zh": "é€šå¸¸éœ€è¦å¤šä¸ªç‰¹å¾æ‰èƒ½å®Œå…¨è¡¨è¾¾å•ä¸ªé¢†åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "The predictions made by the decision tree model result in a higher profit than those made by the k-NN model.",
            "zh": "å†³ç­–æ ‘æ¨¡å‹çš„é¢„æµ‹æ¯” k-NN æ¨¡å‹çš„é¢„æµ‹äº§ç”Ÿæ›´é«˜çš„åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "To begin, imagine a car journey where we start out driving on a minor road at about 30mph and then move onto a highway, where we drive at about 80mph before noticing an accident and braking suddenly.",
            "zh": "é¦–å…ˆï¼Œæƒ³è±¡ä¸€ä¸‹æ±½è½¦ä¹‹æ—…ï¼Œæˆ‘ä»¬å¼€å§‹åœ¨ä¸€æ¡å°è·¯ä¸Šä»¥å¤§çº¦ 30 è‹±é‡Œ/å°æ—¶çš„é€Ÿåº¦è¡Œé©¶ï¼Œç„¶åé©¶å…¥é«˜é€Ÿå…¬è·¯ï¼Œåœ¨é‚£é‡Œæˆ‘ä»¬ä»¥å¤§çº¦ 80 è‹±é‡Œ/å°æ—¶çš„é€Ÿåº¦è¡Œé©¶ï¼Œç„¶åæ³¨æ„åˆ°å‘ç”Ÿäº‹æ•…å¹¶çªç„¶åˆ¹è½¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we keep in mind that the ultimate goal of an analytics solution is to build a predictive model that predicts a target feature from a set of descriptive features, domain concepts are the characteristics of the prediction subject that domain experts and analytics experts believe are likely to be useful in making this prediction.",
            "zh": "å¦‚æœæˆ‘ä»¬è®°ä½ï¼Œåˆ†æè§£å†³æ–¹æ¡ˆçš„æœ€ç»ˆç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»ä¸€ç»„æè¿°æ€§ç‰¹å¾ä¸­é¢„æµ‹ç›®æ ‡ç‰¹å¾ï¼Œåˆ™é¢†åŸŸæ¦‚å¿µæ˜¯é¢†åŸŸä¸“å®¶å’Œåˆ†æä¸“å®¶è®¤ä¸ºå¯èƒ½æœ‰åŠ©äºè¿›è¡Œæ­¤é¢„æµ‹çš„é¢„æµ‹ä¸»é¢˜çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4.2â€…â€…â€…â€…Histograms",
            "zh": "A.4.2 ç›´æ–¹å›¾"
        }
    },
    {
        "translation": {
            "en": "4.1â€…â€…â€…Big Idea",
            "zh": "4.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "If we compare this equation with Equation (7.24)[341], it is apparent that a perceptron network is identical to a multivariate linear regression model with a threshold applied to it.",
            "zh": "å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªæ–¹ç¨‹ä¸æ–¹ç¨‹ï¼ˆ7.24ï¼‰[341]è¿›è¡Œæ¯”è¾ƒï¼Œå¾ˆæ˜æ˜¾ï¼Œæ„ŸçŸ¥å™¨ç½‘ç»œä¸åº”ç”¨äº†é˜ˆå€¼çš„å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Deep learning (Chapter 8[381])",
            "zh": "æ·±åº¦å­¦ä¹ ï¼ˆç¬¬8ç« [381]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "There are many other indexes and metrics we could have presented, for example, Tanimoto similarity (which is a generalization of the Jaccard similarity to non-binary data), and correlation-based approaches such as the Pearson correlation.",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥æå‡ºè®¸å¤šå…¶ä»–ç´¢å¼•å’ŒæŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼Œè°·æœ¬ç›¸ä¼¼æ€§ï¼ˆè¿™æ˜¯ Jaccard ç›¸ä¼¼æ€§ä¸éäºŒè¿›åˆ¶æ•°æ®çš„æ¨å¹¿ï¼‰å’ŒåŸºäºç›¸å…³æ€§çš„æ–¹æ³•ï¼Œä¾‹å¦‚ Pearson ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that the transfer of hidden neuron activations to the memory buffer is a simple copy operation.",
            "zh": "åŸå› æ˜¯å°†éšè—çš„ç¥ç»å…ƒæ¿€æ´»è½¬ç§»åˆ°å†…å­˜ç¼“å†²åŒºæ˜¯ä¸€ä¸ªç®€å•çš„å¤åˆ¶æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 12.7[701] shows the stunted tree Ross generated for the churn problem, where the depth of the tree is limited to five layers.",
            "zh": "å›¾ 12.7[701] æ˜¾ç¤ºäº† Ross ä¸ºæ…åŠ¨é—®é¢˜ç”Ÿæˆçš„å‘è‚²ä¸è‰¯æ ‘ï¼Œå…¶ä¸­æ ‘çš„æ·±åº¦é™åˆ¶ä¸ºäº”å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Gaussian mixture model, 629",
            "zh": "é«˜æ–¯æ··åˆæ¨¡å‹ï¼Œ629"
        }
    },
    {
        "translation": {
            "en": "where the value of the LIFE EXP feature is unknown for the country. This means that in the network, one of the parents of the target feature node, CPI, is unknown. Consequently, we need to sum out this feature for each level of the target. We can calculate the probability for CPI = high as follows:28",
            "zh": "å…¶ä¸­ LIFE EXP åŠŸèƒ½çš„ä»·å€¼åœ¨å›½å®¶/åœ°åŒºæœªçŸ¥ã€‚è¿™æ„å‘³ç€åœ¨ç½‘ç»œä¸­ï¼Œç›®æ ‡ç‰¹å¾èŠ‚ç‚¹ CPI çš„çˆ¶èŠ‚ç‚¹ä¹‹ä¸€æœªçŸ¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ç›®æ ‡çš„æ¯ä¸ªçº§åˆ«æ€»ç»“æ­¤åŠŸèƒ½ã€‚æˆ‘ä»¬å¯ä»¥è®¡ç®— CPI = é«˜çš„æ¦‚ç‡å¦‚ä¸‹ï¼š28"
        }
    },
    {
        "translation": {
            "en": "In this chapter we discuss the ways in which concepts from information theory can be used to build prediction models.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¿¡æ¯è®ºä¸­çš„æ¦‚å¿µå¯ç”¨äºæ„å»ºé¢„æµ‹æ¨¡å‹çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "fraud detection, 262, 538",
            "zh": "æ¬ºè¯ˆæ£€æµ‹ï¼Œ262,538"
        }
    },
    {
        "translation": {
            "en": "One of the most attractive features of the regression models discussed in this chapter is that they are based on a large body of research and best practice in statistics, a much older discipline than machine learning.",
            "zh": "æœ¬ç« è®¨è®ºçš„å›å½’æ¨¡å‹æœ€å¸å¼•äººçš„ç‰¹ç‚¹ä¹‹ä¸€æ˜¯ï¼Œå®ƒä»¬åŸºäºç»Ÿè®¡å­¦çš„å¤§é‡ç ”ç©¶å’Œæœ€ä½³å®è·µï¼Œè¿™æ˜¯ä¸€é—¨æ¯”æœºå™¨å­¦ä¹ æ›´å¤è€çš„å­¦ç§‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "A further benefit of implementing a neural network using matrix operations is that it enables the use of specialized hardware known as graphical processing units (GPUs).",
            "zh": "ä½¿ç”¨çŸ©é˜µè¿ç®—å®ç°ç¥ç»ç½‘ç»œçš„å¦ä¸€ä¸ªå¥½å¤„æ˜¯ï¼Œå®ƒå…è®¸ä½¿ç”¨ç§°ä¸ºå›¾å½¢å¤„ç†å•å…ƒ ï¼ˆGPUï¼‰ çš„ä¸“ç”¨ç¡¬ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example the sample should represent the voting populationâ€”for example, there should be a representative proportion of males compared to females and of different age categories within the sample.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ ·æœ¬åº”ä»£è¡¨æŠ•ç¥¨äººå£ï¼Œä¾‹å¦‚ï¼Œæ ·æœ¬ä¸­ç”·æ€§ä¸å¥³æ€§ç›¸æ¯”ï¼Œä»¥åŠä¸åŒå¹´é¾„ç±»åˆ«çš„ä»£è¡¨æ€§æ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider a problem in which we are trying to predict whether a customer will default on a loan obligation.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¯•å›¾é¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šæ‹–æ¬ è´·æ¬¾ä¹‰åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The easiest way to implement this weighting scheme is to weight each neighbor by the reciprocal6 of the squared distance between the neighbor d and the query q:",
            "zh": "å®ç°æ­¤åŠ æƒæ–¹æ¡ˆçš„æœ€ç®€å•æ–¹æ³•æ˜¯é€šè¿‡é‚»åŸŸ d å’ŒæŸ¥è¯¢ q ä¹‹é—´å¹³æ–¹è·ç¦»çš„å€’æ•° 6 å¯¹æ¯ä¸ªé‚»åŸŸè¿›è¡ŒåŠ æƒï¼š"
        }
    },
    {
        "translation": {
            "en": "It is worth mentioning that to use profit as a performance measure, we donâ€™t need to quantify the profit associated with each outcome as completely as we have done in this example.",
            "zh": "å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¦ä½¿ç”¨åˆ©æ¶¦ä½œä¸ºç»©æ•ˆè¡¡é‡æ ‡å‡†ï¼Œæˆ‘ä»¬ä¸éœ€è¦åƒåœ¨æœ¬ä¾‹ä¸­é‚£æ ·å®Œå…¨é‡åŒ–ä¸æ¯ä¸ªç»“æœç›¸å…³çš„åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s consider an example.",
            "zh": "è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.13â€…â€…â€…The K-S chart for the email classification predictions shown in Table 9.11[557].",
            "zh": "9.13 è¡¨9.11[557]æ‰€ç¤ºçš„ç”µå­é‚®ä»¶åˆ†ç±»é¢„æµ‹çš„K-Så›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note especially that we do not need to know the full dynamics of an MDP, in particular the state transition probabilities that are captured in a transition matrix.",
            "zh": "ç‰¹åˆ«éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦çŸ¥é“ MDP çš„å®Œæ•´åŠ¨æ€ï¼Œç‰¹åˆ«æ˜¯è½¬æ¢çŸ©é˜µä¸­æ•è·çš„çŠ¶æ€è½¬æ¢æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Moon, Todd K. 1996. The expectation-maximization algorithm. IEEE Signal Processing Magazine 13 (6): 47â€“60.",
            "zh": "æœˆäº®ï¼ŒTodd K. 1996 å¹´ã€‚æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ã€‚IEEEä¿¡å·å¤„ç†æ‚å¿—13ï¼ˆ6ï¼‰ï¼š47â€“60ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the histogram we can see an unusual number of zero values for INCOME that seems set apart from the central tendency of the data, which appears to be at about 40,000.",
            "zh": "åœ¨ç›´æ–¹å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° INCOME çš„é›¶å€¼æ•°é‡ä¸å¯»å¸¸ï¼Œè¿™ä¼¼ä¹ä¸æ•°æ®çš„ä¸­å¿ƒè¶‹åŠ¿ä¸åŒï¼Œè¯¥è¶‹åŠ¿ä¼¼ä¹çº¦ä¸º 40,000ã€‚"
        }
    },
    {
        "translation": {
            "en": "(2000) generalized the AdaBoost algorithm and developed another popular boosting algorithm, the LogitBoost algorithm.",
            "zh": "ï¼ˆ2000ï¼‰ æ¨å¹¿äº† AdaBoost ç®—æ³•ï¼Œå¹¶å¼€å‘äº†å¦ä¸€ç§æµè¡Œçš„æå‡ç®—æ³•ï¼Œå³ LogitBoost ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The value of the error function for every possible weight combination defines an error surface, similar to the one shown in Figure 7.24(a)[368]â€”for each combination of weight values, we get a point on the surface whose coordinates are the weight values, with an elevation defined by the error of the model using the weight values.",
            "zh": "æ¯ä¸ªå¯èƒ½çš„æƒé‡ç»„åˆçš„è¯¯å·®å‡½æ•°å€¼å®šä¹‰äº†ä¸€ä¸ªè¯¯å·®é¢ï¼Œç±»ä¼¼äºå›¾ 7.24ï¼ˆaï¼‰[368] æ‰€ç¤ºçš„è¯¯å·®é¢â€”â€”å¯¹äºæ¯ä¸ªæƒé‡å€¼ç»„åˆï¼Œæˆ‘ä»¬åœ¨è¡¨é¢ä¸Šå¾—åˆ°ä¸€ä¸ªç‚¹ï¼Œå…¶åæ ‡æ˜¯æƒé‡å€¼ï¼Œå…¶é«˜ç¨‹ç”±ä½¿ç”¨æƒé‡å€¼çš„æ¨¡å‹è¯¯å·®å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38",
            "zh": "å›¾ 8.38"
        }
    },
    {
        "translation": {
            "en": "7.3â€…â€…â€…Standard Approach: Multivariable Linear Regression with Gradient Descent",
            "zh": "7.3 æ ‡å‡†æ–¹æ³•ï¼šæ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "Applying the decision tree from Figure 4.4(a)[122] to this query, we see that the root node of this tree tests the CONTAINS IMAGES feature.",
            "zh": "å°†å›¾4.4ï¼ˆaï¼‰[122]ä¸­çš„å†³ç­–æ ‘åº”ç”¨äºæ­¤æŸ¥è¯¢ï¼Œæˆ‘ä»¬çœ‹åˆ°è¯¥æ ‘çš„æ ¹èŠ‚ç‚¹æµ‹è¯•äº†CONTAINS IMAGESåŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two related phenomena in Figure 8.33[484] that, in some instances, maybe undesirable consequences of how the receptive fields for the neurons have been defined.",
            "zh": "å›¾8.33[484]ä¸­æœ‰ä¸¤ä¸ªç›¸å…³çš„ç°è±¡ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå®ƒä»¬å¯èƒ½æ˜¯ç¥ç»å…ƒæ„Ÿå—é‡å®šä¹‰æ–¹å¼çš„ä¸è‰¯åæœã€‚"
        }
    },
    {
        "translation": {
            "en": "9.3â€ƒStandard Approach: Misclassification Rate on a Hold-Out Test Set",
            "zh": "9.3 æ ‡å‡†æ–¹æ³•ï¼šä¿æŒæµ‹è¯•é›†çš„é”™è¯¯åˆ†ç±»ç‡"
        }
    },
    {
        "translation": {
            "en": "We use different notation for location and scale parameters, Ï• and Ï, than we do for mean and standard deviation parameters of the normal, Î¼ and Ïƒ, because the values of these parameters are estimated using different techniques: generally, the location and scale parameters for distributions are fitted to the data using a guided search process.18 The student-t distribution, however, takes an extra parameter Îº.",
            "zh": "æˆ‘ä»¬å¯¹ä½ç½®å’Œå°ºåº¦å‚æ•° Ï† å’Œ Ï ä½¿ç”¨ä¸åŒçš„ç¬¦å·ï¼Œè€Œä¸æ˜¯å¯¹æ­£æ€ã€Î¼ å’Œ Ïƒ çš„å‡å€¼å’Œæ ‡å‡†å·®å‚æ•°ä½¿ç”¨ä¸åŒçš„ç¬¦å·ï¼Œå› ä¸ºè¿™äº›å‚æ•°çš„å€¼æ˜¯ä½¿ç”¨ä¸åŒçš„æŠ€æœ¯ä¼°è®¡çš„ï¼šé€šå¸¸ï¼Œåˆ†å¸ƒçš„ä½ç½®å’Œå°ºåº¦å‚æ•°ä½¿ç”¨å¼•å¯¼å¼æœç´¢è¿‡ç¨‹æ‹Ÿåˆåˆ°æ•°æ®ä¸­.18 å­¦ç”Ÿ-t åˆ†å¸ƒï¼Œ ä½†æ˜¯ï¼Œéœ€è¦ä¸€ä¸ªé¢å¤–çš„å‚æ•° Îºã€‚"
        }
    },
    {
        "translation": {
            "en": "The most important part to the gradient descent algorithm is the line on which the weights are updated, Line 4[326].",
            "zh": "æ¢¯åº¦ä¸‹é™ç®—æ³•æœ€é‡è¦çš„éƒ¨åˆ†æ˜¯æ›´æ–°æƒé‡çš„çº¿ï¼Œå³ç¬¬ 4 è¡Œ[326]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Features with a cardinality of 1 should first be investigated to ensure that the issue is not due to an ABT generation error.",
            "zh": "åº”é¦–å…ˆè°ƒæŸ¥åŸºæ•°ä¸º 1 çš„ç‰¹å¾ï¼Œä»¥ç¡®ä¿é—®é¢˜ä¸æ˜¯ç”± ABT ç”Ÿæˆé”™è¯¯å¼•èµ·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The output layer was a fully connected layer with 4 outputs (one per action) using linear activations.",
            "zh": "è¾“å‡ºå±‚æ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå…·æœ‰ 4 ä¸ªè¾“å‡ºï¼ˆæ¯ä¸ªåŠ¨ä½œä¸€ä¸ªï¼‰ï¼Œä½¿ç”¨çº¿æ€§æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we assume that d2 was the first example processed21 and that we have set the learning rate hyper-parameter to Î± = 0.2, then we would update weight w7,5 as follows:",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾ d2 æ˜¯ç¬¬ä¸€ä¸ªå¤„ç†çš„ç¤ºä¾‹21ï¼Œå¹¶ä¸”æˆ‘ä»¬å·²å°†å­¦ä¹ ç‡è¶…å‚æ•°è®¾ç½®ä¸º Î± = 0.2ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†æ›´æ–°æƒé‡ w7,5ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "-0.62",
            "zh": "-0.62"
        }
    },
    {
        "translation": {
            "en": "Typically, we are not able to increase the number of instances in our dataset, and we face the scenario of a sparsely populated feature space,27 as illustrated in Figures 5.18(b)[226] and 5.18(c)[226].",
            "zh": "é€šå¸¸ï¼Œæˆ‘ä»¬æ— æ³•å¢åŠ æ•°æ®é›†ä¸­çš„å®ä¾‹æ•°é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬é¢ä¸´ç€ç¨€ç–å¡«å……çš„ç‰¹å¾ç©ºé—´27ï¼Œå¦‚å›¾5.18ï¼ˆbï¼‰[226]å’Œ5.18ï¼ˆcï¼‰[226]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "where the terms have the same meaning as before.",
            "zh": "å…¶ä¸­æœ¯è¯­çš„å«ä¹‰ä¸ä»¥å‰ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts by descending through the tree from the root node, taking the branch at each interior node that matches the value of the query for the feature tested at that node, until it comes to a leaf node (Line 3 of the algorithm).",
            "zh": "è¯¥ç®—æ³•é¦–å…ˆä»æ ¹èŠ‚ç‚¹ä¸‹é™åˆ°æ ‘ä¸­ï¼Œåœ¨æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹ä¸Šè·å–ä¸è¯¥èŠ‚ç‚¹ä¸Šæµ‹è¯•çš„ç‰¹å¾çš„æŸ¥è¯¢å€¼åŒ¹é…çš„åˆ†æ”¯ï¼Œç›´åˆ°å®ƒåˆ°è¾¾å¶èŠ‚ç‚¹ï¼ˆç®—æ³•çš„ç¬¬ 3 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability mass functions have two properties: (1) they always return a value between 0.0 and 1.0; and (2) the sum of the probabilities over the set of events covering all the possible assignments of values to features must equal 1.0. Formally these properties are defined as follows:",
            "zh": "æ¦‚ç‡è´¨é‡å‡½æ•°æœ‰ä¸¤ä¸ªå±æ€§ï¼šï¼ˆ1ï¼‰å®ƒä»¬æ€»æ˜¯è¿”å›ä¸€ä¸ªä»‹äº 0.0 å’Œ 1.0 ä¹‹é—´çš„å€¼;ï¼ˆ2ï¼‰ æ¶µç›–è¦ç´ å€¼æ‰€æœ‰å¯èƒ½èµ‹å€¼çš„äº‹ä»¶é›†çš„æ¦‚ç‡ä¹‹å’Œå¿…é¡»ç­‰äº 1.0ã€‚ä»å½¢å¼ä¸Šè®²ï¼Œè¿™äº›å±æ€§å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Jocelyn showed that even the SDSS scientists themselves disagreed on the types of certain galaxies.",
            "zh": "Jocelynè¡¨æ˜ï¼Œå³ä½¿æ˜¯SDSSç§‘å­¦å®¶è‡ªå·±ä¹Ÿå¯¹æŸäº›æ˜Ÿç³»çš„ç±»å‹å­˜åœ¨åˆ†æ­§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The same result obtained by calculating the dot product of the descriptive features of a support vector and a query instance after having applied the basis functions can be obtained by applying a much less costly kernel function, kernel, to the original descriptive feature values of the support vector and the query.24 The prediction equation becomes",
            "zh": "åœ¨åº”ç”¨åŸºå‡½æ•°åï¼Œé€šè¿‡è®¡ç®—æ”¯æŒå‘é‡å’ŒæŸ¥è¯¢å®ä¾‹çš„æè¿°æ€§ç‰¹å¾çš„ç‚¹ç§¯è€Œè·å¾—çš„ç»“æœä¸å°†æˆæœ¬ä½å¾—å¤šçš„æ ¸å‡½æ•° kernel åº”ç”¨äºæ”¯æŒå‘é‡å’ŒæŸ¥è¯¢çš„åŸå§‹æè¿°æ€§ç‰¹å¾å€¼å¯ä»¥è·å¾—ç›¸åŒçš„ç»“æœ.24 é¢„æµ‹æ–¹ç¨‹å˜ä¸º"
        }
    },
    {
        "translation": {
            "en": "The result of multiplying two matrices is another matrix whose dimensions are equal to the number of rows in the left matrix and the number of columns in the right matrix. For example, multiplying a 2 Ã— 3 matrix by a 3 Ã— 3 matrix results in a 2 Ã— 3. Each value in the resulting matrix is calculated as follows, where i iterates over the columns in the first matrix (D) and the rows in the second matrix (E)",
            "zh": "ä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜çš„ç»“æœæ˜¯å¦ä¸€ä¸ªçŸ©é˜µï¼Œå…¶ç»´åº¦ç­‰äºå·¦çŸ©é˜µä¸­çš„è¡Œæ•°å’Œå³çŸ©é˜µä¸­çš„åˆ—æ•°ã€‚ä¾‹å¦‚ï¼Œå°† 2 Ã— 3 çŸ©é˜µä¹˜ä»¥ 3 Ã— 3 çŸ©é˜µå¾—åˆ° 2 Ã— 3ã€‚ç»“æœçŸ©é˜µä¸­çš„æ¯ä¸ªå€¼çš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼Œå…¶ä¸­ i éå†ç¬¬ä¸€ä¸ªçŸ©é˜µ ï¼ˆDï¼‰ ä¸­çš„åˆ—å’Œç¬¬äºŒä¸ªçŸ©é˜µ ï¼ˆEï¼‰ ä¸­çš„è¡Œ"
        }
    },
    {
        "translation": {
            "en": "If the descriptive features in a dataset are binary, it is often a good idea to use a similarity index that defines similarity between instances specifically in terms of co-presence or co-absence of features, rather than an index based on distance.",
            "zh": "å¦‚æœæ•°æ®é›†ä¸­çš„æè¿°æ€§è¦ç´ æ˜¯äºŒè¿›åˆ¶çš„ï¼Œåˆ™é€šå¸¸æœ€å¥½ä½¿ç”¨ç›¸ä¼¼æ€§ç´¢å¼•ï¼Œè¯¥ç´¢å¼•ä¸“é—¨æ ¹æ®è¦ç´ çš„å…±å­˜æˆ–å…±ç¼ºæ¥å®šä¹‰å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œè€Œä¸æ˜¯åŸºäºè·ç¦»çš„ç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, we use batch gradient descent for training and treat Table 8.1[422] as a batch.",
            "zh": "æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰¹æ¬¡æ¢¯åº¦ä¸‹é™è¿›è¡Œè®­ç»ƒï¼Œå¹¶å°†è¡¨8.1[422]è§†ä¸ºä¸€ä¸ªæ‰¹æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate how a decision tree works, we use the dataset listed in Table 4.2[121].",
            "zh": "ä¸ºäº†è¯´æ˜å†³ç­–æ ‘æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¡¨4.2[121]ä¸­åˆ—å‡ºçš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "19. The Cohenâ€™s kappa statistic was first described in Cohen (1960). Using the Cohenâ€™s kappa statistic, a value of 1.0 indicates total agreement, while a value of 0.0 indicates agreement no better than chance. Values around 0.6 are typically understood to indicate an acceptable level of agreement, although the exact nature of what is and is not acceptable is very task dependent.",
            "zh": "19. Cohen's kappa ç»Ÿè®¡é‡æœ€æ—©æ˜¯åœ¨ Cohen ï¼ˆ1960ï¼‰ ä¸­æè¿°çš„ã€‚ä½¿ç”¨ Cohen çš„ kappa ç»Ÿè®¡é‡ï¼Œå€¼ 1.0 è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œè€Œå€¼ 0.0 è¡¨ç¤ºä¸€è‡´æ€§ä¸æ¯”å¶ç„¶æ€§å¥½ã€‚0.6 å·¦å³çš„å€¼é€šå¸¸è¢«ç†è§£ä¸ºè¡¨ç¤ºå¯æ¥å—çš„ä¸€è‡´æ€§æ°´å¹³ï¼Œå°½ç®¡å¯æ¥å—å’Œä¸å¯æ¥å—çš„ç¡®åˆ‡æ€§è´¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Evaluation: Before models can be deployed for use within an organization, it is important that they are fully evaluated and proved to be fit for the purpose. This phase of CRISP-DM covers all the evaluation tasks required to show that a prediction model will be able to make accurate predictions after being deployed and that it does not suffer from overfitting or underfitting.",
            "zh": "è¯„ä¼°ï¼šåœ¨éƒ¨ç½²æ¨¡å‹ä»¥åœ¨ç»„ç»‡å†…ä½¿ç”¨ä¹‹å‰ï¼Œå¿…é¡»å¯¹æ¨¡å‹è¿›è¡Œå…¨é¢è¯„ä¼°å¹¶è¯æ˜å®ƒä»¬é€‚åˆè¯¥ç›®çš„ã€‚CRISP-DM çš„è¿™ä¸€é˜¶æ®µæ¶µç›–äº†æ‰€æœ‰å¿…è¦çš„è¯„ä¼°ä»»åŠ¡ï¼Œä»¥è¡¨æ˜é¢„æµ‹æ¨¡å‹åœ¨éƒ¨ç½²åèƒ½å¤Ÿåšå‡ºå‡†ç¡®çš„é¢„æµ‹ï¼Œå¹¶ä¸”ä¸ä¼šå—åˆ°è¿‡åº¦æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆçš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.5.3â€ƒMahalanobis distanceâ€ƒThe final measure of similarity that we will introduce is the Mahalanobis distance, which is a metric that can be used to measure the similarity between instances with continuous descriptive features.",
            "zh": "5.4.5.3 é©¬æ°è·ç¦» æˆ‘ä»¬å°†ä»‹ç»çš„ç›¸ä¼¼æ€§çš„æœ€åä¸€ä¸ªåº¦é‡æ˜¯é©¬æ°è·ç¦»ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯ç”¨äºæµ‹é‡å…·æœ‰è¿ç»­æè¿°æ€§ç‰¹å¾çš„å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Until recently, spirits have been very high in the lab due to the discovery earlier the previous year of a new form of electromagnetic radiation called N rays (Blondlot, 1903).",
            "zh": "ç›´åˆ°æœ€è¿‘ï¼Œç”±äºå‰ä¸€å¹´æ—©äº›æ—¶å€™å‘ç°äº†ä¸€ç§ç§°ä¸ºNå°„çº¿çš„æ–°å½¢å¼çš„ç”µç£è¾å°„ï¼ˆBlondlotï¼Œ1903ï¼‰ï¼Œå®éªŒå®¤ä¸­çš„ç²¾ç¥ä¸€ç›´éå¸¸é«˜æ¶¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a naive Bayes model trained on a churn prediction problem.",
            "zh": "åœ¨æµå¤±é¢„æµ‹é—®é¢˜ä¸Šè®­ç»ƒçš„æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "It would be almost impossible to ask the full voting population their voting intentions before an actual electionâ€”after all, that is what the actual election is forâ€”so polling companies take a sample.",
            "zh": "åœ¨å®é™…é€‰ä¸¾ä¹‹å‰ï¼Œå‡ ä¹ä¸å¯èƒ½è¯¢é—®æ‰€æœ‰æŠ•ç¥¨äººå£çš„æŠ•ç¥¨æ„å‘â€”â€”æ¯•ç«Ÿï¼Œè¿™å°±æ˜¯å®é™…é€‰ä¸¾çš„ç›®çš„â€”â€”æ‰€ä»¥æ°‘æ„è°ƒæŸ¥å…¬å¸ä¼šæŠ½å–æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two standard approaches to creating ensembles: bagging and boosting. The remainder of this section explains each of these basic approaches. Commonly used, high-performing extensions to both of the basic approaches are also described: random forests in the case of bagging and gradient boosting in the case of boosting.",
            "zh": "åˆ›å»ºåˆå¥æœ‰ä¸¤ç§æ ‡å‡†æ–¹æ³•ï¼šè£…è¢‹å’Œæå‡ã€‚æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†å°†ä»‹ç»è¿™äº›åŸºæœ¬æ–¹æ³•ä¸­çš„æ¯ä¸€ç§ã€‚è¿˜æè¿°äº†ä¸¤ç§åŸºæœ¬æ–¹æ³•çš„å¸¸ç”¨é«˜æ€§èƒ½æ‰©å±•ï¼šè¢‹è£…æƒ…å†µä¸‹çš„éšæœºæ£®æ—å’Œæå‡æƒ…å†µä¸‹çš„æ¢¯åº¦æå‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the rare event that the player is dealt two aces, giving a total of 22, they are awarded a TwentyTwo and win regardless of the cards dealt to the dealer.",
            "zh": "åœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼Œç©å®¶è¢«å‘äº†ä¸¤å¼ Aï¼Œæ€»å…±æœ‰22å¼ Aï¼Œæ— è®ºå‘ç»™åº„å®¶çš„ç‰Œå¦‚ä½•ï¼Œä»–ä»¬éƒ½ä¼šè·å¾—äºŒåäºŒå¼ ç‰Œå¹¶è·èƒœã€‚"
        }
    },
    {
        "translation": {
            "en": "This chapter begins by establishing the fundamental setup of the reinforcement learning scenario and then describes temporal-difference learning, a common approach to reinforcement learning.",
            "zh": "æœ¬ç« é¦–å…ˆå»ºç«‹å¼ºåŒ–å­¦ä¹ åœºæ™¯çš„åŸºæœ¬è®¾ç½®ï¼Œç„¶åä»‹ç»æ—¶é—´å·®å¼‚å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§å¸¸è§çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A good way to build multinomial logistic regression models is to use a set of one-versus-all models.19 If we have r target levels, we create r one-versus-all logistic regression models.",
            "zh": "æ„å»ºå¤šé¡¹å¼é€»è¾‘å›å½’æ¨¡å‹çš„ä¸€ä¸ªå¥½æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ç»„ one-versus-all æ¨¡å‹.19 å¦‚æœæˆ‘ä»¬æœ‰ r ä¸ªç›®æ ‡æ°´å¹³ï¼Œæˆ‘ä»¬åˆ›å»º r ä¸ª 1-vsus-all é€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "On subsequent attempts, surfers will slowly reduce their error by slightly adjusting their position until they home in on the sweet spot at which they can keep their board perfectly balanced to allow a seamless transition to tickling the face of an awesome toob!",
            "zh": "åœ¨éšåçš„å°è¯•ä¸­ï¼Œå†²æµªè€…ä¼šé€šè¿‡ç¨å¾®è°ƒæ•´ä»–ä»¬çš„ä½ç½®æ¥æ…¢æ…¢å‡å°‘ä»–ä»¬çš„é”™è¯¯ï¼Œç›´åˆ°ä»–ä»¬å›åˆ°æœ€ä½³ä½ç½®ï¼Œä»–ä»¬å¯ä»¥ä¿æŒä»–ä»¬çš„å†²æµªæ¿å®Œç¾å¹³è¡¡ï¼Œä»è€Œæ— ç¼è¿‡æ¸¡åˆ°æŒ ç—’ç—’çš„è„¸ï¼"
        }
    },
    {
        "translation": {
            "en": "where the newly added categorical features allow the original ENERGY RATING feature to be included. Everything else about using such a model is exactly the same as before.",
            "zh": "å…¶ä¸­ï¼Œæ–°æ·»åŠ çš„åˆ†ç±»ç‰¹å¾å…è®¸åŒ…å«åŸå§‹çš„ ENERGY RATING ç‰¹å¾ã€‚ä½¿ç”¨è¿™ç§æ¨¡å‹çš„å…¶ä»–ä¸€åˆ‡éƒ½ä¸ä»¥å‰å®Œå…¨ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset showing the positions and monthly training expenses of a school basketball team.",
            "zh": "æ˜¾ç¤ºå­¦æ ¡ç¯®çƒé˜Ÿçš„ä½ç½®å’Œæ¯æœˆè®­ç»ƒè´¹ç”¨çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.7[547] illustrates the process of out-of-time sampling.",
            "zh": "å›¾9.7[547]è¯´æ˜äº†è¶…æ—¶é‡‡æ ·çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The configuration of receptive fields in Figure 8.33[484] uses a horizontal and vertical stride of 1; this means that as we move from one neuron to the next horizontally, the corresponding receptive fields also move by one column in the input space.",
            "zh": "å›¾ 8.33[484] ä¸­æ„Ÿå—é‡çš„é…ç½®ä½¿ç”¨æ°´å¹³å’Œå‚ç›´æ­¥å¹… 1;è¿™æ„å‘³ç€å½“æˆ‘ä»¬ä»ä¸€ä¸ªç¥ç»å…ƒæ°´å¹³ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªç¥ç»å…ƒæ—¶ï¼Œç›¸åº”çš„æ„Ÿå—é‡ä¹Ÿä¼šåœ¨è¾“å…¥ç©ºé—´ä¸­ç§»åŠ¨ä¸€åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are a few points worth noting about the product rule. First, it defines the probability of a joint event P(X,Y) in terms of a conditional (or posterior) probability P(X | Y) multiplied by an unconditional (or prior) probability P(Y). Second, the order of the events in the product rule is not important, and we can condition the calculation on any of the events listed in the and (in logic, the and operation is symmetric):",
            "zh": "å…³äºäº§å“è§„åˆ™ï¼Œæœ‰å‡ ç‚¹å€¼å¾—æ³¨æ„ã€‚é¦–å…ˆï¼Œå®ƒæ ¹æ®æ¡ä»¶ï¼ˆæˆ–åéªŒï¼‰æ¦‚ç‡ Pï¼ˆX |Yï¼‰ ä¹˜ä»¥æ— æ¡ä»¶ï¼ˆæˆ–å…ˆéªŒï¼‰æ¦‚ç‡ Pï¼ˆYï¼‰ã€‚å…¶æ¬¡ï¼Œä¹˜ç§¯è§„åˆ™ä¸­äº‹ä»¶çš„é¡ºåºå¹¶ä¸é‡è¦ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ® and ä¸­åˆ—å‡ºçš„ä»»ä½•äº‹ä»¶æ¥è®¡ç®—ï¼ˆåœ¨é€»è¾‘ä¸­ï¼Œand è¿ç®—æ˜¯å¯¹ç§°çš„ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "This burn-in time is to allow the Markov chain to settle into a state that is independent of the initial random state and that is a probable state for the distribution we are sampling from.",
            "zh": "è¿™ä¸ªè€åŒ–æ—¶é—´æ˜¯ä¸ºäº†è®©é©¬å°”å¯å¤«é“¾è¿›å…¥ä¸€ä¸ªç‹¬ç«‹äºåˆå§‹éšæœºçŠ¶æ€çš„çŠ¶æ€ï¼Œè¿™ä¸ªçŠ¶æ€æ˜¯æˆ‘ä»¬æ­£åœ¨é‡‡æ ·çš„åˆ†å¸ƒçš„å¯èƒ½çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.36",
            "zh": "å›¾ 8.36"
        }
    },
    {
        "translation": {
            "en": "5.4.1â€…â€…â€…Handling Noisy Data",
            "zh": "5.4.1 å¤„ç†å˜ˆæ‚æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "A taxonomy of models based on the parametric versus non-parametric and generative versus discriminative distinctions.",
            "zh": "åŸºäºå‚æ•°ä¸éå‚æ•°ä»¥åŠç”Ÿæˆä¸åˆ¤åˆ«åŒºåˆ«çš„æ¨¡å‹åˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ROC index is quite robust in the presence of imbalanced data, which makes it a common choice for practitioners, especially when multiple modeling techniques are being compared to one another.",
            "zh": "åœ¨æ•°æ®ä¸å¹³è¡¡çš„æƒ…å†µä¸‹ï¼ŒROCæŒ‡æ•°éå¸¸ç¨³å¥ï¼Œè¿™ä½¿å…¶æˆä¸ºä»ä¸šè€…çš„å¸¸è§é€‰æ‹©ï¼Œå°¤å…¶æ˜¯åœ¨å°†å¤šç§å»ºæ¨¡æŠ€æœ¯ç›¸äº’æ¯”è¾ƒæ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Application prediction] Data Requirements: Again, a historical collection of claims marked as fraudulent or non-fraudulent along with all relevant details would be required.",
            "zh": "[åº”ç”¨é¢„æµ‹]æ•°æ®è¦æ±‚ï¼šåŒæ ·ï¼Œéœ€è¦æä¾›æ ‡è®°ä¸ºæ¬ºè¯ˆæ€§æˆ–éæ¬ºè¯ˆæ€§ç´¢èµ”çš„å†å²é›†åˆä»¥åŠæ‰€æœ‰ç›¸å…³è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before attempting to build predictive models based on an ABT, it is important that we undertake some exploratory analysis, or data exploration, of the data contained in the ABT.",
            "zh": "åœ¨å°è¯•æ„å»ºåŸºäº ABT çš„é¢„æµ‹æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»å¯¹ ABT ä¸­åŒ…å«çš„æ•°æ®è¿›è¡Œä¸€äº›æ¢ç´¢æ€§åˆ†ææˆ–æ•°æ®æ¢ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "As the algorithm proceeds, the model that it is building will become more and more fitted to the nuances of the training data.",
            "zh": "éšç€ç®—æ³•çš„è¿›è¡Œï¼Œå®ƒæ­£åœ¨æ„å»ºçš„æ¨¡å‹å°†è¶Šæ¥è¶Šé€‚åˆè®­ç»ƒæ•°æ®çš„ç»†å¾®å·®åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.4.3â€ƒOutliersâ€ƒFrom an examination of the minimum and maximum values for each continuous feature in Table 3.3(a)[57], CLAIM AMOUNT jumps out as having an unusual minimum value of âˆ’ 99,999.",
            "zh": "3.3.4.3 å¼‚å¸¸å€¼ é€šè¿‡å¯¹è¡¨3.3ï¼ˆaï¼‰[57]ä¸­æ¯ä¸ªè¿ç»­ç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼çš„æ£€æŸ¥ï¼ŒCLAIM AMOUNTè·³å‡ºä¸ºå…·æœ‰å¼‚å¸¸çš„æœ€å°å€¼-99,999ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Using this dataset, construct the decision tree that would be generated by the ID3 algorithm, using entropy-based information gain.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œä½¿ç”¨åŸºäºç†µçš„ä¿¡æ¯å¢ç›Šæ„å»ºç”± ID3 ç®—æ³•ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "To test a new medicine, doctors typically assemble a group of patients who suffer from the problem that the medicine is designed to address.",
            "zh": "ä¸ºäº†æµ‹è¯•ä¸€ç§æ–°è¯ï¼ŒåŒ»ç”Ÿé€šå¸¸ä¼šå¬é›†ä¸€ç¾¤æ‚£æœ‰è¯¥è¯ç‰©æ—¨åœ¨è§£å†³çš„é—®é¢˜çš„æ‚£è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can find the point at which overfitting begins to happen by comparing the performance of a model at making predictions for instances in the training dataset used to build it versus its ability to make predictions for instances in a validation dataset as the training process continues.",
            "zh": "éšç€è®­ç»ƒè¿‡ç¨‹çš„ç»§ç»­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒæ¨¡å‹åœ¨ç”¨äºæ„å»ºæ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ä¸­å¯¹å®ä¾‹è¿›è¡Œé¢„æµ‹çš„æ€§èƒ½ä¸å…¶å¯¹éªŒè¯æ•°æ®é›†ä¸­çš„å®ä¾‹è¿›è¡Œé¢„æµ‹çš„èƒ½åŠ›æ¥æ‰¾åˆ°è¿‡æ‹Ÿåˆå¼€å§‹å‘ç”Ÿçš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have focused on using the data quality report to explore the data in an ABT.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»å¦‚ä½•ä½¿ç”¨æ•°æ®è´¨é‡æŠ¥å‘Šæ¥æ¢ç´¢ ABT ä¸­çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "One thing about evaluating unsupervised machine learning approaches that is a little easier than the supervised case is that we can do it without the need to divide a dataset into training, testing, and validation partitions. Although techniques such as k-fold cross validation can be useful in using external criteria for evaluation, in using internal criteria for evaluation we typically just use all the data both for generating the clustering and evaluating the clustering.",
            "zh": "è¯„ä¼°æ— ç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•æ¯”æœ‰ç›‘ç£æƒ…å†µå®¹æ˜“ä¸€ç‚¹çš„ä¸€ä»¶äº‹æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè€Œæ— éœ€å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯åˆ†åŒºã€‚å°½ç®¡ k æŠ˜å äº¤å‰éªŒè¯ç­‰æŠ€æœ¯åœ¨ä½¿ç”¨å¤–éƒ¨æ ‡å‡†è¿›è¡Œè¯„ä¼°æ—¶å¾ˆæœ‰ç”¨ï¼Œä½†åœ¨ä½¿ç”¨å†…éƒ¨æ ‡å‡†è¿›è¡Œè¯„ä¼°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸åªä½¿ç”¨æ‰€æœ‰æ•°æ®æ¥ç”Ÿæˆèšç±»å’Œè¯„ä¼°èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "FN, 537",
            "zh": "FNï¼Œ537"
        }
    },
    {
        "translation": {
            "en": "There are several different ways to smooth probabilities. We will use Laplace smoothing. Note, that in general, it does not make sense to smooth the unconditional (prior) probabilities for the different target feature levels,15 so here we will focus on smoothing the conditional probabilities for the features. Laplace smoothing for conditional probabilities is defined as",
            "zh": "æœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥å¹³æ»‘æ¦‚ç‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€‚è¯·æ³¨æ„ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œå¹³æ»‘ä¸åŒç›®æ ‡ç‰¹å¾çº§åˆ«çš„æ— æ¡ä»¶ï¼ˆå…ˆéªŒï¼‰æ¦‚ç‡æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œ15 å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨å¹³æ»‘ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ã€‚æ¡ä»¶æ¦‚ç‡çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "4.2â€…â€…â€…An email spam prediction dataset.",
            "zh": "4.2 åƒåœ¾é‚®ä»¶é¢„æµ‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will explain in more detail why we need non-linear activation functions in neurons in Section 8.2.4[394].",
            "zh": "æˆ‘ä»¬å°†åœ¨ç¬¬ 8.2.4 èŠ‚[394]ä¸­æ›´è¯¦ç»†åœ°è§£é‡Šä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ç¥ç»å…ƒä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "By including the bias term in the set of weights along with a dummy descriptive feature, the function implemented by multiplying the weights by the extended descriptive features is now an affine function.",
            "zh": "é€šè¿‡å°†åç½®é¡¹ä¸è™šæ‹Ÿæè¿°æ€§ç‰¹å¾ä¸€èµ·åŒ…å«åœ¨æƒé‡é›†ä¸­ï¼Œé€šè¿‡å°†æƒé‡ä¹˜ä»¥æ‰©å±•çš„æè¿°æ€§ç‰¹å¾æ¥å®ç°çš„å‡½æ•°ç°åœ¨æ˜¯ä»¿å°„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Murphy, Kevin P. 2012. Machine learning: A probabilistic perspective. MIT Press.",
            "zh": "å¢¨è²ï¼Œå‡¯æ–‡ P. 2012 å¹´ã€‚æœºå™¨å­¦ä¹ ï¼šæ¦‚ç‡è§†è§’ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a mixture of Gaussians distribution assumes that all the subpopulations in the data are distributed following a normal distribution, but that each of these subpopulation normal distributions has a different mean and may also have a different standard deviation.",
            "zh": "ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„æ··åˆå‡å®šæ•°æ®ä¸­çš„æ‰€æœ‰å­ç§ç¾¤éƒ½æ²¿æ­£æ€åˆ†å¸ƒåˆ†å¸ƒï¼Œä½†è¿™äº›å­ç§ç¾¤ä¸­çš„æ¯ä¸€ä¸ªæ­£æ€åˆ†å¸ƒéƒ½å…·æœ‰ä¸åŒçš„å‡å€¼ï¼Œå¹¶ä¸”ä¹Ÿå¯èƒ½å…·æœ‰ä¸åŒçš„æ ‡å‡†å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ROC index can be calculated as",
            "zh": "ROCæŒ‡æ•°å¯ä»¥è®¡ç®—ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "83,000",
            "zh": "83,000"
        }
    },
    {
        "translation": {
            "en": "0.1â€…â€…â€…How the notation used in the book relates to the elements of a dataset.",
            "zh": "0.1 æœ¬ä¹¦ä¸­ä½¿ç”¨çš„ç¬¦å·ä¸æ•°æ®é›†å…ƒç´ çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Does the person wear glasses?",
            "zh": "2. è¿™ä¸ªäººæˆ´çœ¼é•œå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This model has been used to make predictions for the instances in the training set above. These predictions, and the related calculations required for calculating error and errorDelta values are shown in the following table.",
            "zh": "æ­¤æ¨¡å‹å·²ç”¨äºå¯¹ä¸Šè¿°è®­ç»ƒé›†ä¸­çš„å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚ä¸‹è¡¨æ˜¾ç¤ºäº†è¿™äº›é¢„æµ‹ä»¥åŠè®¡ç®— error å’Œ errorDelta å€¼æ‰€éœ€çš„ç›¸å…³è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "APERFLUX7IVAR_U/G/R/I/Z",
            "zh": "APERFLUX7IVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Model Scoring",
            "zh": "æ¨¡å‹è¯„åˆ†"
        }
    },
    {
        "translation": {
            "en": "Each activation vector is augmented with a new first row (filled in black) containing the dummy descriptive feature d[0] = 1.",
            "zh": "æ¯ä¸ªæ¿€æ´»å‘é‡éƒ½å¢åŠ äº†ä¸€ä¸ªæ–°çš„ç¬¬ä¸€è¡Œï¼ˆç”¨é»‘è‰²å¡«å……ï¼‰ï¼Œå…¶ä¸­åŒ…å«è™šæ‹Ÿæè¿°æ€§ç‰¹å¾ d[0] = 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 14.2",
            "zh": "å›¾ 14.2"
        }
    },
    {
        "translation": {
            "en": "When matching machine learning approaches to the characteristics of a dataset, it is important to remember that almost every approach can be made to work for both continuous and categorical descriptive and target features.",
            "zh": "åœ¨å°†æœºå™¨å­¦ä¹ æ–¹æ³•ä¸æ•°æ®é›†çš„ç‰¹å¾ç›¸åŒ¹é…æ—¶ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå‡ ä¹æ¯ç§æ–¹æ³•éƒ½å¯ä»¥ç”¨äºè¿ç»­å’Œåˆ†ç±»çš„æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "margin of error, 751",
            "zh": "è¯¯å·®å¹…åº¦ï¼Œ751"
        }
    },
    {
        "translation": {
            "en": "First, only about a quarter of the people who were surveyed responded to the survey (2.4 million out of 10 million).",
            "zh": "é¦–å…ˆï¼Œåªæœ‰å¤§çº¦å››åˆ†ä¹‹ä¸€çš„å—è®¿è€…å¯¹è°ƒæŸ¥åšå‡ºäº†å›åº”ï¼ˆ1000ä¸‡äººä¸­æœ‰240ä¸‡äººï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the weights connected to neurons that are dropped for an example do not receive updates on that example.",
            "zh": "ä¾‹å¦‚ï¼Œè¿æ¥åˆ°æŸä¸ªç¤ºä¾‹ä¸­ä¸¢å¼ƒçš„ç¥ç»å…ƒçš„æƒé‡ä¸ä¼šæ¥æ”¶è¯¥ç¤ºä¾‹çš„æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cell state is then updated by adding the vector generated by the elementwise produce of the tanh and sigmoid activations.",
            "zh": "ç„¶åé€šè¿‡æ·»åŠ ç”± tanh å’Œ sigmoid æ¿€æ´»çš„å…ƒç´ äº§ç”Ÿçš„å‘é‡æ¥æ›´æ–°ç»†èƒçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.2â€…â€…â€…The Chain Rule",
            "zh": "C.2 è¿é”æ³•åˆ™"
        }
    },
    {
        "translation": {
            "en": "Reinforcement learning approaches have been used in automated game playing since TD-Gammon (Tesauro, 1994) was developed in the 1990s.",
            "zh": "è‡ª 1990 å¹´ä»£å¼€å‘ TD-Gammon ï¼ˆTesauroï¼Œ 1994ï¼‰ ä»¥æ¥ï¼Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸€ç›´ç”¨äºè‡ªåŠ¨åŒ–æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10(a)[201] illustrates the first stage of the retrieval of the nearest neighbor.",
            "zh": "å›¾5.10ï¼ˆaï¼‰[201]è¯´æ˜äº†æ£€ç´¢æœ€è¿‘é‚»çš„ç¬¬ä¸€é˜¶æ®µã€‚"
        }
    },
    {
        "translation": {
            "en": "If we divided by n, we would have a biased estimator that on average underestimates the variance.",
            "zh": "å¦‚æœæˆ‘ä»¬é™¤ä»¥ nï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªæœ‰åå·®çš„ä¼°è®¡å™¨ï¼Œå¹³å‡ä½ä¼°æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Table 4.14[162] the column labeled 0(d) shows the predictions made by this model.",
            "zh": "åœ¨è¡¨4.14[162]ä¸­ï¼Œæ ‡è®°ä¸º0ï¼ˆdï¼‰çš„åˆ—æ˜¾ç¤ºäº†è¯¥æ¨¡å‹æ‰€åšçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Discuss the different issues that should be taken into account when evaluating the suitability of different machine learning approaches for use in this system.",
            "zh": "ï¼ˆaï¼‰ è®¨è®ºåœ¨è¯„ä¼°ä¸åŒæœºå™¨å­¦ä¹ æ–¹æ³•æ˜¯å¦é€‚åˆç”¨äºè¯¥ç³»ç»Ÿæ—¶åº”è€ƒè™‘çš„ä¸åŒé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The MIT Press",
            "zh": "éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾"
        }
    },
    {
        "translation": {
            "en": "Somewhat surprisingly, people seem to be able to easily do this on the basis of intuition.",
            "zh": "ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œäººä»¬ä¼¼ä¹èƒ½å¤Ÿæ ¹æ®ç›´è§‰è½»æ¾åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Doctorow, Corey. 2010. Little brother. Macmillan.",
            "zh": "å¤šå…‹æ‰˜ç½—ï¼Œç§‘é‡Œã€‚2010. å°å¼Ÿå¼Ÿ.éº¦å…‹ç±³ä¼¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy to adapt the k nearest neighbor approach to handle continuous target features. To do this we simply change the approach to return a prediction of the average target value of the nearest neighbors, rather than the majority target level. The prediction for a continuous target feature by a k nearest neighbor model is therefore",
            "zh": "é‡‡ç”¨kä¸ªæœ€è¿‘é‚»æ–¹æ³•å¤„ç†è¿ç»­ç›®æ ‡ç‰¹å¾ç›¸å¯¹å®¹æ˜“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€æ›´æ”¹æ–¹æ³•ä»¥è¿”å›æœ€è¿‘é‚»çš„å¹³å‡ç›®æ ‡å€¼çš„é¢„æµ‹ï¼Œè€Œä¸æ˜¯å¤§å¤šæ•°ç›®æ ‡æ°´å¹³ã€‚å› æ­¤ï¼Œkä¸ªæœ€è¿‘é‚»æ¨¡å‹å¯¹è¿ç»­ç›®æ ‡ç‰¹å¾çš„é¢„æµ‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Note that here we use the notation hxâŠº to write the transpose of the vector hx; we use transpose of the vector to ensure that this matrix and vector product is defined. We can illustrate the process of calculating a weight update for the weights in W(f) by using the context provided by the forward pass example shown in Figure 8.41[514]. For the purposes of this example, we assume that the following error gradients are already calculated:",
            "zh": "è¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç¬¦å· hxâŠº æ¥å†™å‘é‡ hx çš„è½¬ç½®;æˆ‘ä»¬ä½¿ç”¨å‘é‡çš„è½¬ç½®æ¥ç¡®ä¿å®šä¹‰æ­¤çŸ©é˜µå’Œå‘é‡ä¹˜ç§¯ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å›¾ 8.41[514] æ‰€ç¤ºçš„å‰å‘ä¼ é€’ç¤ºä¾‹æä¾›çš„ä¸Šä¸‹æ–‡æ¥è¯´æ˜è®¡ç®— Wï¼ˆfï¼‰ ä¸­æƒé‡æ›´æ–°çš„è¿‡ç¨‹ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å·²ç»è®¡ç®—äº†ä»¥ä¸‹è¯¯å·®æ¢¯åº¦ï¼š"
        }
    },
    {
        "translation": {
            "en": "For the email classification dataset shown in Table 9.1[537], the F 1 measure (again assuming that the spam level is the positive level) is calculated as",
            "zh": "å¯¹äºè¡¨ 9.1[537] ä¸­æ‰€ç¤ºçš„ç”µå­é‚®ä»¶åˆ†ç±»æ•°æ®é›†ï¼ŒF 1 åº¦é‡ï¼ˆå†æ¬¡å‡è®¾åƒåœ¾é‚®ä»¶çº§åˆ«ä¸ºæ­£çº§åˆ«ï¼‰è®¡ç®—ä¸º"
        }
    },
    {
        "translation": {
            "en": "Chapter 9[533]",
            "zh": "ç¬¬9ç« [533]"
        }
    },
    {
        "translation": {
            "en": "For example, we use the matrix representation to present elements of the worked example in Section 8.3.5[421], in which we step through the training of a feedforward neural network using backpropagation.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨çŸ©é˜µè¡¨ç¤ºæ¥å‘ˆç°ç¬¬ 8.3.5 èŠ‚[421] ä¸­å·¥ä½œç¤ºä¾‹çš„å…ƒç´ ï¼Œå…¶ä¸­æˆ‘ä»¬é€æ­¥å®Œæˆäº†ä½¿ç”¨åå‘ä¼ æ’­çš„å‰é¦ˆç¥ç»ç½‘ç»œçš„è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case, there are maximum grayscale values (255) across the middle row of the neurons receptive field, and as a result of the interaction between this input pattern and the weights in Equation (8.85)[480], this neuron has a very large activation for this input.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¥ç»å…ƒæ„Ÿå—é‡çš„ä¸­é—´ä¸€æ’æœ‰æœ€å¤§çš„ç°åº¦å€¼ï¼ˆ255ï¼‰ï¼Œå¹¶ä¸”ç”±äºè¯¥è¾“å…¥æ¨¡å¼ä¸æ–¹ç¨‹ï¼ˆ8.85ï¼‰[480]ä¸­çš„æƒé‡ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œè¯¥ç¥ç»å…ƒå¯¹è¯¥è¾“å…¥å…·æœ‰éå¸¸å¤§çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we change the data too much, then the models that we build will not relate well to the original data sources when we deploy them.",
            "zh": "å¦‚æœæˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œè¿‡å¤šçš„æ›´æ”¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ„å»ºçš„æ¨¡å‹åœ¨éƒ¨ç½²å®ƒä»¬æ—¶å°†æ— æ³•å¾ˆå¥½åœ°ä¸åŸå§‹æ•°æ®æºç›¸å…³è”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The state of the decision tree after the ğ’Ÿ7 partition has been split using STREAM.",
            "zh": "ä½¿ç”¨ STREAM æ‹†åˆ† D7 åˆ†åŒºåçš„å†³ç­–æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Obviously the computational costs associated with non-parametric models and large datasets cannot be ignored.",
            "zh": "æ˜¾ç„¶ï¼Œä¸éå‚æ•°æ¨¡å‹å’Œå¤§å‹æ•°æ®é›†ç›¸å…³çš„è®¡ç®—æˆæœ¬ä¸å®¹å¿½è§†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Details of the first two iterations when the gradient descent algorithm is used to train a multivariable linear regression model for the office rentals dataset (using only the continuous descriptive features).",
            "zh": "å½“æ¢¯åº¦ä¸‹é™ç®—æ³•ç”¨äºè®­ç»ƒåŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹ï¼ˆä»…ä½¿ç”¨è¿ç»­æè¿°æ€§ç‰¹å¾ï¼‰æ—¶ï¼Œå‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "prior probability, 251, 759",
            "zh": "å…ˆéªŒæ¦‚ç‡ï¼Œ251,759"
        }
    },
    {
        "translation": {
            "en": "The idea of a control group might be familiar to readers from reading about medical trials.",
            "zh": "è¯»è€…å¯èƒ½åœ¨é˜…è¯»æœ‰å…³åŒ»å­¦è¯•éªŒçš„æ–‡ç« æ—¶ç†Ÿæ‚‰å¯¹ç…§ç»„çš„æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "The important thing to notice about this decision surface, in contrast to the decision surface in Figure 7.11(b)[341], is that there is a gentle transition from predictions of the faulty target level to predictions of the good generator target level.",
            "zh": "ä¸å›¾7.11ï¼ˆbï¼‰[341]ä¸­çš„å†³ç­–é¢ç›¸æ¯”ï¼Œè¿™ä¸ªå†³ç­–é¢éœ€è¦æ³¨æ„çš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œä»å¯¹é”™è¯¯ç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ°å¯¹è‰¯å¥½ç”Ÿæˆå™¨ç›®æ ‡æ°´å¹³çš„é¢„æµ‹æœ‰ä¸€ä¸ªæ¸©å’Œçš„è¿‡æ¸¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with the simple two-event version, the order of events in the chain rule is not important.",
            "zh": "ä¸ç®€å•çš„åŒäº‹ä»¶ç‰ˆæœ¬ä¸€æ ·ï¼Œé“¾å¼è§„åˆ™ä¸­äº‹ä»¶çš„é¡ºåºå¹¶ä¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.5[607] shows a selection of sets of initial centroids selected by the k-means process.",
            "zh": "å›¾10.5[607]æ˜¾ç¤ºäº†é€šè¿‡k-meansè¿‡ç¨‹é€‰æ‹©çš„ä¸€ç»„åˆå§‹è´¨å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Illustration of the organization of a set of neurons that share weights (use the same filter) and their local receptive fields such that together the receptive fields cover the entirety of the input image.",
            "zh": "ä¸€ç»„ç¥ç»å…ƒçš„ç»„ç»‡å›¾ç¤ºï¼Œè¿™äº›ç¥ç»å…ƒå…±äº«æƒé‡ï¼ˆä½¿ç”¨ç›¸åŒçš„è¿‡æ»¤å™¨ï¼‰åŠå…¶å±€éƒ¨æ„Ÿå—é‡ï¼Œä½¿å¾—æ„Ÿå—é‡ä¸€èµ·è¦†ç›–æ•´ä¸ªè¾“å…¥å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.17",
            "zh": "è¡¨ 9.17"
        }
    },
    {
        "translation": {
            "en": "padding, 487",
            "zh": "å¡«å……ç‰©ï¼Œ 487"
        }
    },
    {
        "translation": {
            "en": "10.5â€…â€…â€…Distance matrices that detail the first three iterations of the AHC algorithm applied to the reduced version of the mobile phone customer dataset in Table 10.1[604].",
            "zh": "10.5 è·ç¦»çŸ©é˜µï¼Œè¯¦ç»†è¯´æ˜äº†åº”ç”¨äºè¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ç®€åŒ–ç‰ˆæœ¬çš„AHCç®—æ³•çš„å‰ä¸‰æ¬¡è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "The information gain of the SUSPICIOUS WORDS feature is 1 bit.",
            "zh": "SUSPICIOUS WORDS åŠŸèƒ½çš„ä¿¡æ¯å¢ç›Šä¸º 1 ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes patients are readmitted for a recurrence of the same problem for which they were originally hospitalized, but at other times readmission is for different problems.",
            "zh": "æœ‰æ—¶ï¼Œæ‚£è€…å› æœ€åˆä½é™¢çš„ç›¸åŒé—®é¢˜å¤å‘è€Œå†æ¬¡å…¥é™¢ï¼Œä½†åœ¨å…¶ä»–æ—¶å€™ï¼Œå†æ¬¡å…¥é™¢æ˜¯é’ˆå¯¹ä¸åŒçš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of the action it has taken, the agent now makes an update to Q(0-3,left) (Line 13[658]) using Equation (13)[658].",
            "zh": "æ ¹æ®å®ƒæ‰€é‡‡å–çš„è¡ŒåŠ¨ï¼Œä»£ç†ç°åœ¨ä½¿ç”¨å…¬å¼ ï¼ˆ13ï¼‰[658] å¯¹ Qï¼ˆ0-3ï¼Œleftï¼‰ï¼ˆç¬¬ 13 è¡Œ [658]ï¼‰ è¿›è¡Œæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Count",
            "zh": "è®¡æ•°"
        }
    },
    {
        "translation": {
            "en": "As a result, convolutional networks can learn to identify, extract, and use multiple different features in the input.",
            "zh": "å› æ­¤ï¼Œå·ç§¯ç½‘ç»œå¯ä»¥å­¦ä¹ è¯†åˆ«ã€æå–å’Œä½¿ç”¨è¾“å…¥ä¸­çš„å¤šä¸ªä¸åŒç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Le Cun, Yann, LÃ©on Bottou, Yoshua Bengio, and Haffner Patrick. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86 (11): 2278â€“2324.",
            "zh": "Le Cunã€Yannã€LÃ©on Bottouã€Yoshua Bengio å’Œ Haffner Patrickã€‚1998. åŸºäºæ¢¯åº¦çš„å­¦ä¹ åœ¨æ–‡æ¡£è¯†åˆ«ä¸­çš„åº”ç”¨.IEEE ä¼šè®®è®°å½• 86 ï¼ˆ11ï¼‰ï¼š2278â€“2324ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see that increasing office size leads to increasing rental prices; that lower building floors lead to higher rental prices; and that rental prices increase with broadband rates.",
            "zh": "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒåŠå…¬å®¤è§„æ¨¡çš„å¢åŠ å¯¼è‡´ç§Ÿé‡‘ä»·æ ¼ä¸Šæ¶¨;è¾ƒä½çš„å»ºç­‘æ¥¼å±‚å¯¼è‡´æ›´é«˜çš„ç§Ÿé‡‘ä»·æ ¼;ç§Ÿé‡‘ä»·æ ¼éšç€å®½å¸¦è´¹ç‡çš„å¢åŠ è€Œå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "So when calculating the overall majority vote across the k nearest neighbors, the votes of the neighbors that are close to the query get a lot of weight, and the votes of the neighbors that are farther away from the query get less weight.",
            "zh": "å› æ­¤ï¼Œåœ¨è®¡ç®— k ä¸ªæœ€è¿‘é‚»åŸŸçš„æ€»ä½“å¤šæ•°ç¥¨æ•°æ—¶ï¼Œé è¿‘æŸ¥è¯¢çš„é‚»åŸŸçš„æŠ•ç¥¨æƒé‡è¾ƒå¤§ï¼Œè€Œè·ç¦»æŸ¥è¯¢è¾ƒè¿œçš„é‚»åŸŸçš„æŠ•ç¥¨æƒé‡è¾ƒå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although it makes sense to do it, the rewards do not have to be so closely tied to the winnings within the game, and different reward structures could be designed to encourage different playing strategiesâ€”for example, more conservative or more aggressive play.",
            "zh": "è™½ç„¶è¿™æ ·åšæ˜¯æœ‰é“ç†çš„ï¼Œä½†å¥–åŠ±ä¸å¿…ä¸æ¸¸æˆä¸­çš„å¥–é‡‘å¯†åˆ‡ç›¸å…³ï¼Œå¹¶ä¸”å¯ä»¥è®¾è®¡ä¸åŒçš„å¥–åŠ±ç»“æ„æ¥é¼“åŠ±ä¸åŒçš„æ¸¸æˆç­–ç•¥â€”â€”ä¾‹å¦‚ï¼Œæ›´ä¿å®ˆæˆ–æ›´æ¿€è¿›çš„æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "and decreases the weights for the instances correctly classified by the model using30",
            "zh": "å¹¶é™ä½æ¨¡å‹æ­£ç¡®åˆ†ç±»çš„å®ä¾‹çš„æƒé‡ using 30"
        }
    },
    {
        "translation": {
            "en": "She did, however, explain to Edwin that because the categorization of galaxy morphologies is a somewhat subjective task (even human experts donâ€™t always fully agree on the category that a night sky object should belong to), it was unlikely that classification accuracies beyond 90% would be achievable.",
            "zh": "ç„¶è€Œï¼Œå¥¹ç¡®å®å‘åŸƒå¾·æ¸©è§£é‡Šè¯´ï¼Œç”±äºæ˜Ÿç³»å½¢æ€çš„åˆ†ç±»æ˜¯ä¸€é¡¹æœ‰ç‚¹ä¸»è§‚çš„ä»»åŠ¡ï¼ˆå³ä½¿æ˜¯äººç±»ä¸“å®¶ä¹Ÿå¹¶ä¸æ€»æ˜¯å®Œå…¨åŒæ„å¤œç©ºç‰©ä½“åº”è¯¥å±äºå“ªä¸ªç±»åˆ«ï¼‰ï¼Œå› æ­¤ä¸å¤ªå¯èƒ½å®ç°è¶…è¿‡90%çš„åˆ†ç±»ç²¾åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Including a ratio between two values can often be much more powerful in a predictive model than including the two values themselves.",
            "zh": "åœ¨é¢„æµ‹æ¨¡å‹ä¸­ï¼ŒåŒ…å«ä¸¤ä¸ªå€¼ä¹‹é—´çš„æ¯”ç‡é€šå¸¸æ¯”åŒ…å«ä¸¤ä¸ªå€¼æœ¬èº«è¦å¼ºå¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "The height of the density curve defined by a PDF at a particular feature value gives us this, so we can avoid the effort of calculating the actual probability.",
            "zh": "PDF åœ¨ç‰¹å®šç‰¹å¾å€¼ä¸‹å®šä¹‰çš„å¯†åº¦æ›²çº¿çš„é«˜åº¦ä¸ºæˆ‘ä»¬æä¾›äº†è¿™ä¸€ç‚¹ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é¿å…è®¡ç®—å®é™…æ¦‚ç‡çš„å·¥ä½œé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. The following image illustrates the topology of a feedforward neural network that has two sensing neurons (Neurons 1 and 2), two hidden processing neuron (Neurons 3, and 4), and two processing output neurons (Neurons 5 and 6).",
            "zh": "6. ä¸‹å›¾è¯´æ˜äº†å‰é¦ˆç¥ç»ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ï¼Œè¯¥ç¥ç»ç½‘ç»œå…·æœ‰ä¸¤ä¸ªæ„ŸçŸ¥ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 1 å’Œ 2ï¼‰ã€ä¸¤ä¸ªéšè—å¤„ç†ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 3 å’Œ 4ï¼‰å’Œä¸¤ä¸ªå¤„ç†è¾“å‡ºç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 5 å’Œ 6ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, the first row in the Activations Hidden Layer 1 matrix contains the activations for Neuron 3 (a3) for the d1, d2, d3, and d4, respectively.",
            "zh": "åŒæ ·ï¼Œæ¿€æ´»éšè—å±‚ 1 çŸ©é˜µä¸­çš„ç¬¬ä¸€è¡Œåˆ†åˆ«åŒ…å« d1ã€d2ã€d3 å’Œ d4 çš„ç¥ç»å…ƒ 3 ï¼ˆa3ï¼‰ æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ai is a specific value of feature a, and lower and upper are the lower and upper thresholds.",
            "zh": "å…¶ä¸­ AI æ˜¯è¦ç´  A çš„ç‰¹å®šå€¼ï¼Œä¸‹é™å’Œä¸Šé™æ˜¯é˜ˆå€¼çš„ä¸‹é™å’Œä¸Šé™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.95)[491] illustrates an extended version of the convolutional network that would implement the data processing illustrated in Equation (8.94)[490].",
            "zh": "ç­‰å¼ï¼ˆ8.95ï¼‰[491]è¯´æ˜äº†å·ç§¯ç½‘ç»œçš„æ‰©å±•ç‰ˆæœ¬ï¼Œè¯¥ç‰ˆæœ¬å°†å®ç°ç­‰å¼ï¼ˆ8.94ï¼‰[490]ä¸­æ‰€ç¤ºçš„æ•°æ®å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, within any small region or neighborhood of the feature space, real data tends to manifest a smooth correlation between changes in descriptive feature values and the values of the target feature.",
            "zh": "å…¶æ¬¡ï¼Œåœ¨ç‰¹å¾ç©ºé—´çš„ä»»ä½•å°åŒºåŸŸæˆ–é‚»åŸŸå†…ï¼ŒçœŸå®æ•°æ®å¾€å¾€ä¼šè¡¨ç°å‡ºæè¿°æ€§ç‰¹å¾å€¼çš„å˜åŒ–ä¸ç›®æ ‡ç‰¹å¾å€¼ä¹‹é—´çš„å¹³æ»‘ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was shown after two months that the churn rate within the sample for which the retention team used the new model to build their call list was approximately 7.4%, while for the group using the old model, it was over 10%.",
            "zh": "ä¸¤ä¸ªæœˆåæ˜¾ç¤ºï¼Œä¿ç•™å›¢é˜Ÿä½¿ç”¨æ–°æ¨¡å‹æ„å»ºå‘¼å«åˆ—è¡¨çš„æ ·æœ¬ä¸­çš„æµå¤±ç‡çº¦ä¸º 7.4%ï¼Œè€Œä½¿ç”¨æ—§æ¨¡å‹çš„ç»„çš„æµå¤±ç‡è¶…è¿‡ 10%ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix resulting from this test is shown in Table 13.11[726].",
            "zh": "è¯¥æµ‹è¯•äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.11[726]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure C.3",
            "zh": "å›¾ C.3"
        }
    },
    {
        "translation": {
            "en": "6. Famously, an experiment in which doctors were asked this question about the probability of the patientâ€™s having the disease showed that most of them got this question wrong (Casscells et al., 1978).",
            "zh": "6. è‘—åçš„æ˜¯ï¼Œä¸€é¡¹å®éªŒä¸­ï¼ŒåŒ»ç”Ÿè¢«é—®åˆ°å…³äºæ‚£è€…æ‚£ç—…æ¦‚ç‡çš„é—®é¢˜ï¼Œç»“æœæ˜¾ç¤ºä»–ä»¬ä¸­çš„å¤§å¤šæ•°äººéƒ½å¼„é”™äº†è¿™ä¸ªé—®é¢˜ï¼ˆCasscells ç­‰äººï¼Œ1978 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we were building a model to predict the outcomes of soccer matches, we might consider including the attendance at the match as a descriptive feature.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è¶³çƒæ¯”èµ›çš„ç»“æœï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè€ƒè™‘å°†æ¯”èµ›çš„å‡ºå¸­ç‡ä½œä¸ºæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "weighted variance, 149",
            "zh": "åŠ æƒæ–¹å·®ï¼Œ149"
        }
    },
    {
        "translation": {
            "en": "7.2.1â€ƒSimple Linear Regression",
            "zh": "7.2.1 ç®€å•çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "The brute-force search approach that was mentioned in Section 7.2.3[317] is not feasible eitherâ€”especially as the number of descriptive features, and subsequently the number of weights, increases.",
            "zh": "ç¬¬7.2.3èŠ‚[317]ä¸­æåˆ°çš„æš´åŠ›æœç´¢æ–¹æ³•ä¹Ÿä¸å¯è¡Œï¼Œç‰¹åˆ«æ˜¯éšç€æè¿°æ€§ç‰¹å¾çš„æ•°é‡ä»¥åŠéšä¹‹è€Œæ¥çš„æƒé‡æ•°é‡çš„å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the logistic function, the rectifier function saturates in part of its domain, and this can lead to a dying ReLU dynamic in which a unit does not activate for any of the training instances, and consequently the neuron is stuck in a dead non-active state.",
            "zh": "ä¸é€»è¾‘å‡½æ•°ç±»ä¼¼ï¼Œæ•´æµå™¨å‡½æ•°åœ¨å…¶éƒ¨åˆ†åŸŸä¸­é¥±å’Œï¼Œè¿™å¯èƒ½å¯¼è‡´å‚æ­»çš„ ReLU åŠ¨æ€ï¼Œå…¶ä¸­å•å…ƒä¸ä¼šä¸ºä»»ä½•è®­ç»ƒå®ä¾‹æ¿€æ´»ï¼Œå› æ­¤ç¥ç»å…ƒé™·å…¥æ­»éæ´»åŠ¨çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we describe Bayesâ€™ Theorem and the important fundamentals of probability theory that are required to use it.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»è´å¶æ–¯å®šç†ä»¥åŠä½¿ç”¨å®ƒæ‰€éœ€çš„æ¦‚ç‡è®ºçš„é‡è¦åŸºç¡€çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons use a rectifier activation functions, that the input to the network is Neuron 1 = 0.3 and Neuron 2 = 0.6 and that the desired output for this input is Neuron 5 = 0.7 and Neuron 6 = 0.4:",
            "zh": "ï¼ˆbï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒä½¿ç”¨æ•´æµå™¨æ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.3 å’Œç¥ç»å…ƒ 2 = 0.6ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æ‰€éœ€è¾“å‡ºæ˜¯ç¥ç»å…ƒ 5 = 0.7 å’Œç¥ç»å…ƒ 6 = 0.4ï¼š"
        }
    },
    {
        "translation": {
            "en": "The learning approaches described in this chapter are value-based and model-free.",
            "zh": "æœ¬ç« ä¸­æè¿°çš„å­¦ä¹ æ–¹æ³•æ˜¯åŸºäºå€¼ä¸”æ— æ¨¡å‹çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chen, Tianqi, and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 785â€“794. ACM.",
            "zh": "é™ˆå¤©çªå’Œå¡æ´›æ–¯Â·ç›–æ–¯ç‰¹æ—ã€‚2016. Xgboostï¼šå¯æ‰©å±•çš„æ ‘æå‡ç³»ç»Ÿã€‚åœ¨ç¬¬ 22 å±Š ACM SIGKDD çŸ¥è¯†å‘ç°å’Œæ•°æ®æŒ–æ˜å›½é™…ä¼šè®®è®ºæ–‡é›†ä¸­ï¼Œ785â€“794ã€‚ACMã€‚"
        }
    },
    {
        "translation": {
            "en": "6. This is almost identical to the definition of Shannonâ€™s entropy model given in Equation (4.1)[125]. We have extended the definition to include an explicit parameter for the dataset ğ’Ÿ for which we are computing the entropy, and we have specified the base as 2.",
            "zh": "6. è¿™ä¸æ–¹ç¨‹ï¼ˆ4.1ï¼‰[125]ä¸­ç»™å‡ºçš„é¦™å†œç†µæ¨¡å‹çš„å®šä¹‰å‡ ä¹ç›¸åŒã€‚æˆ‘ä»¬æ‰©å±•äº†å®šä¹‰ï¼Œä»¥åŒ…å«æˆ‘ä»¬æ­£åœ¨è®¡ç®—ç†µçš„æ•°æ®é›† D çš„æ˜¾å¼å‚æ•°ï¼Œå¹¶å°†åŸºæ•°æŒ‡å®šä¸º 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are essentially a composition of a set of local models (recall our discussion on Voronoi tessellation) with the predictions made being a function of the target feature value of the instance in the dataset closest to the query.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯ä¸€ç»„å±€éƒ¨æ¨¡å‹çš„ç»„åˆï¼ˆå›æƒ³ä¸€ä¸‹æˆ‘ä»¬å¯¹ Voronoi æ›²é¢ç»†åˆ†çš„è®¨è®ºï¼‰ï¼Œå…¶é¢„æµ‹æ˜¯æœ€æ¥è¿‘æŸ¥è¯¢çš„æ•°æ®é›†ä¸­å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, there is no guarantee that this instance will be the nearest neighbor, although it should be a good approximate neighbor for the query.",
            "zh": "é—æ†¾çš„æ˜¯ï¼Œä¸èƒ½ä¿è¯æ­¤å®ä¾‹å°†æ˜¯æœ€è¿‘é‚»ï¼Œå°½ç®¡å®ƒåº”è¯¥æ˜¯æŸ¥è¯¢çš„è‰¯å¥½è¿‘ä¼¼é‚»åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Osowski, Stainslaw, Linh Tran Hoai, and T. Markiewicz. 2004. Support vector machine-based expert system for reliable heartbeat recognition. IEEE Transactions on Biomedical Engineering 51 (4): 582â€“589. doi:10.1109/TBME.2004.824138.",
            "zh": "Osowskiã€Stainslawã€Linh Tran Hoai å’Œ T. Markiewiczã€‚2004. æ”¯æŒåŸºäºçŸ¢é‡æœºçš„ä¸“å®¶ç³»ç»Ÿï¼Œå®ç°å¯é çš„å¿ƒè·³è¯†åˆ«ã€‚IEEEç”Ÿç‰©åŒ»å­¦å·¥ç¨‹å­¦æŠ¥51ï¼ˆ4ï¼‰ï¼š582â€“589ã€‚doiï¼š10.1109/TBME.2004.824138."
        }
    },
    {
        "translation": {
            "en": "timing, 33",
            "zh": "æ—¶æœºï¼Œ33"
        }
    },
    {
        "translation": {
            "en": "In some cases we might even remove a complete instance from a dataset based on the presence of an outlier.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç”šè‡³å¯èƒ½ä¼šæ ¹æ®å¼‚å¸¸å€¼çš„å­˜åœ¨ä»æ•°æ®é›†ä¸­åˆ é™¤ä¸€ä¸ªå®Œæ•´çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.3â€ƒChoosing the Number of Clusters",
            "zh": "10.4.3 é€‰æ‹©é›†ç¾¤æ•°é‡"
        }
    },
    {
        "translation": {
            "en": "(c) Do you think that the model that you rejected in Part (a) of this question is overfitting or underfitting the data?",
            "zh": "ï¼ˆcï¼‰ ä½ è®¤ä¸ºä½ åœ¨æœ¬é—®é¢˜ï¼ˆaï¼‰éƒ¨åˆ†æ‹’ç»çš„æ¨¡å‹æ˜¯å¦å¯¹æ•°æ®è¿‡åº¦æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The tanh activation function outputs values in the range [âˆ’1,+1].",
            "zh": "tanh æ¿€æ´»å‡½æ•°è¾“å‡º [âˆ’1ï¼Œ+1] èŒƒå›´å†…çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.13",
            "zh": "å›¾ 7.13"
        }
    },
    {
        "translation": {
            "en": "4.8â€…â€…â€…Dataset for predicting the vegetation in an area with a continuous ELEVATION feature (measured in feet).",
            "zh": "4.8 ç”¨äºé¢„æµ‹å…·æœ‰è¿ç»­é«˜ç¨‹ç‰¹å¾ï¼ˆä»¥è‹±å°ºä¸ºå•ä½ï¼‰çš„åŒºåŸŸä¸­çš„æ¤è¢«çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cats donâ€™t like storms either, and if there is a storm, they like to go inside.",
            "zh": "çŒ«ä¹Ÿä¸å–œæ¬¢æš´é£é›¨ï¼Œå¦‚æœæœ‰æš´é£é›¨ï¼Œå®ƒä»¬å–œæ¬¢è¿›å»ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, an image processing system should be able to detect whether a visual feature occurs in an image irrespective of where in the image it occurs.",
            "zh": "ä½†æ˜¯ï¼Œå›¾åƒå¤„ç†ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿæ£€æµ‹å›¾åƒä¸­æ˜¯å¦å‡ºç°è§†è§‰ç‰¹å¾ï¼Œè€Œä¸ç®¡å®ƒå‡ºç°åœ¨å›¾åƒä¸­çš„å“ªä¸ªä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kohavi, Ron. 1996. Scaling up the accuracy of Naive-Bayes classifiers: A decision-tree hybrid. In Proceedings of the twenty-fifth ACM SIGKDD international conference on knowledge discovery and data mining KDD, 202â€“207.",
            "zh": "ç§‘å“ˆç»´ï¼Œç½—æ©ã€‚1996. æé«˜æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„å‡†ç¡®æ€§ï¼šå†³ç­–æ ‘æ··åˆä½“ã€‚åœ¨ç¬¬äºŒåäº”å±Š ACM SIGKDD çŸ¥è¯†å‘ç°å’Œæ•°æ®æŒ–æ˜å›½é™…ä¼šè®®è®ºæ–‡é›† KDD ä¸­ï¼Œ202â€“207ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4.1â€ƒBar Plots",
            "zh": "A.4.1 æ¡å½¢å›¾"
        }
    },
    {
        "translation": {
            "en": "There are contexts, however, in which the focus of a course is not primarily on machine learning.",
            "zh": "ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¯¾ç¨‹çš„é‡ç‚¹å¹¶ä¸ä¸»è¦æ”¾åœ¨æœºå™¨å­¦ä¹ ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that the naive Bayes domain representation defines a conditional probability for each possible value in the domain of a descriptive feature for each level in the domain of the target.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œæœ´ç´ è´å¶æ–¯åŸŸè¡¨ç¤ºä¸ºç›®æ ‡åŸŸä¸­æ¯ä¸ªçº§åˆ«çš„æè¿°æ€§ç‰¹å¾åŸŸä¸­çš„æ¯ä¸ªå¯èƒ½å€¼å®šä¹‰äº†ä¸€ä¸ªæ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Equation (8.67)[466] we can now calculate a loss for the networkâ€™s predictions over a set of exclusive categories.",
            "zh": "ä½¿ç”¨ç­‰å¼ï¼ˆ8.67ï¼‰[466]ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥è®¡ç®—ä¸€ç»„æ’ä»–æ€§ç±»åˆ«çš„ç½‘ç»œé¢„æµ‹çš„æŸå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "preference bias, 11",
            "zh": "åå¥½åå·®ï¼Œ11"
        }
    },
    {
        "translation": {
            "en": "The vertical bar symbol can be read as given that.",
            "zh": "å‚ç›´æ¡ç¬¦å·å¯ä»¥è¿™æ ·ç†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, DEVAB_R had a range as small as [0.05,1.00] while APERFLUX7IVAR_U had a range as large as [âˆ’265,862,15,274].",
            "zh": "ä¾‹å¦‚ï¼ŒDEVAB_R çš„èŒƒå›´å°è‡³ [0.05,1.00]ï¼Œè€ŒAPERFLUX7IVAR_Uçš„èŒƒå›´å¤§è‡³ [âˆ’265,862,15,274]ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the European Union the 1999 Treaty of Amsterdam6 prohibits discrimination on the basis of sex, racial or ethnic origin, religion or belief, disability, age, or sexual orientation.",
            "zh": "åœ¨æ¬§æ´²è”ç›Ÿï¼Œ1999å¹´ã€Šé˜¿å§†æ–¯ç‰¹ä¸¹æ¡çº¦ã€‹6 ç¦æ­¢åŸºäºæ€§åˆ«ã€ç§æ—æˆ–æ—è£”ã€å®—æ•™æˆ–ä¿¡ä»°ã€æ®‹ç–¾ã€å¹´é¾„æˆ–æ€§å–å‘çš„æ­§è§†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the set shown in Figure 4.5(f)[124] has a large number of card types, each represented only once, which leads to the high entropy value of 3.58 bits.",
            "zh": "æœ€åï¼Œå›¾4.5ï¼ˆfï¼‰[124]æ‰€ç¤ºçš„é›†åˆå…·æœ‰å¤§é‡çš„å¡ç±»å‹ï¼Œæ¯ç§å¡ç±»å‹ä»…è¡¨ç¤ºä¸€æ¬¡ï¼Œè¿™å¯¼è‡´äº†3.58ä½çš„é«˜ç†µå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many ways, the easy part of a predictive data analytics project is building the models.",
            "zh": "åœ¨è®¸å¤šæ–¹é¢ï¼Œé¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®çš„ç®€å•éƒ¨åˆ†æ˜¯æ„å»ºæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Outliers identified in this way are likely to be invalid outliers and should immediately be either corrected, if data sources allow this, or removed and marked as missing values if correction is not possible.",
            "zh": "ä»¥è¿™ç§æ–¹å¼è¯†åˆ«çš„å¼‚å¸¸å€¼å¾ˆå¯èƒ½æ˜¯æ— æ•ˆçš„å¼‚å¸¸å€¼ï¼Œå¦‚æœæ•°æ®æºå…è®¸ï¼Œåº”ç«‹å³æ›´æ­£ï¼Œå¦‚æœæ— æ³•æ›´æ­£ï¼Œåˆ™åº”å°†å…¶åˆ é™¤å¹¶æ ‡è®°ä¸ºç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table A.3",
            "zh": "è¡¨ A.3"
        }
    },
    {
        "translation": {
            "en": "6â€…â€…â€…Probability-Based Learning",
            "zh": "6 åŸºäºæ¦‚ç‡çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "A data quality report includes tabular reports (one for continuous features and one for categorical features) that describe the characteristics of each feature in an ABT using standard statistical measures of central tendency and variation.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘ŠåŒ…æ‹¬è¡¨æ ¼æŠ¥å‘Šï¼ˆä¸€ä¸ªç”¨äºè¿ç»­ç‰¹å¾ï¼Œä¸€ä¸ªç”¨äºåˆ†ç±»ç‰¹å¾ï¼‰ï¼Œè¿™äº›æŠ¥å‘Šä½¿ç”¨é›†ä¸­è¶‹åŠ¿å’Œå˜å¼‚çš„æ ‡å‡†ç»Ÿè®¡åº¦é‡æ¥æè¿° ABT ä¸­æ¯ä¸ªç‰¹å¾çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activation for Neuron B, however, was the maximum value for the local receptive field the neuron is in, and so the Î´ value for Neuron B is calculated as shown in Equation (8.97)[492].",
            "zh": "ç„¶è€Œï¼Œç¥ç»å…ƒBçš„æ¿€æ´»æ˜¯ç¥ç»å…ƒæ‰€åœ¨å±€éƒ¨æ„Ÿå—é‡çš„æœ€å¤§å€¼ï¼Œå› æ­¤ç¥ç»å…ƒBçš„Î´å€¼è®¡ç®—å¦‚å…¬å¼ï¼ˆ8.97ï¼‰[492]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In contrast, discriminative models learn the boundary between classes rather than the characteristics of the distributions of the different classes.",
            "zh": "ç›¸åï¼Œåˆ¤åˆ«æ¨¡å‹å­¦ä¹ ç±»ä¹‹é—´çš„è¾¹ç•Œï¼Œè€Œä¸æ˜¯ä¸åŒç±»åˆ†å¸ƒçš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, alternatives to k-d trees.",
            "zh": "ä½†æ˜¯ï¼Œk-d æ ‘è¿˜æœ‰å…¶ä»–é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the error, Îµ, associated with the set of predictions made by the model ğ•„4 given in the table above.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—ä¸ä¸Šè¡¨ä¸­ç»™å‡ºçš„æ¨¡å‹M4æ‰€ä½œçš„ä¸€ç»„é¢„æµ‹ç›¸å…³çš„è¯¯å·®Îµã€‚"
        }
    },
    {
        "translation": {
            "en": "A few key data manipulation operations are frequently used to calculate derived feature values: joining data sources, filtering rows in a data source, filtering fields in a data source, deriving new features by combining or transforming existing features, and aggregating data sources. Data manipulation operations are implemented in and performed by database management systems, data management tools, or data manipulation tools, and are often referred to as an extract-transform-load (ETL) process.",
            "zh": "ä¸€äº›å…³é”®çš„æ•°æ®æ“ä½œæ“ä½œç»å¸¸ç”¨äºè®¡ç®—æ´¾ç”Ÿè¦ç´ å€¼ï¼šè”æ¥æ•°æ®æºã€ç­›é€‰æ•°æ®æºä¸­çš„è¡Œã€ç­›é€‰æ•°æ®æºä¸­çš„å­—æ®µã€é€šè¿‡ç»„åˆæˆ–è½¬æ¢ç°æœ‰è¦ç´ æ¥æ´¾ç”Ÿæ–°è¦ç´ ä»¥åŠèšåˆæ•°æ®æºã€‚æ•°æ®æ“ä½œåœ¨æ•°æ®åº“ç®¡ç†ç³»ç»Ÿã€æ•°æ®ç®¡ç†å·¥å…·æˆ–æ•°æ®æ“ä½œå·¥å…·ä¸­å®ç°å¹¶ç”±æ•°æ®åº“æ“ä½œå·¥å…·æ‰§è¡Œï¼Œé€šå¸¸ç§°ä¸ºæå–-è½¬æ¢-åŠ è½½ ï¼ˆETLï¼‰ è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, there are fewer output activations from a sub-sampling layer than there are inputs: one output per local receptive field and multiple inputs per field.",
            "zh": "å› æ­¤ï¼Œå­é‡‡æ ·å±‚çš„è¾“å‡ºæ¿€æ´»å°‘äºè¾“å…¥ï¼šæ¯ä¸ªå±€éƒ¨æ„Ÿå—é‡ä¸€ä¸ªè¾“å‡ºï¼Œæ¯ä¸ªåœºå¤šä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "experience replay, 671",
            "zh": "ä½“éªŒå›æ”¾ï¼Œ671"
        }
    },
    {
        "translation": {
            "en": "In mathematics, the process of passing a function over a sequence of values is known as convolving a function, and by analogy a set of neurons that share a filter (and thereby each implements the same function) and that are organized such that together their receptive fields cover the input are convolving a function over the input.42",
            "zh": "åœ¨æ•°å­¦ä¸­ï¼Œå°†å‡½æ•°ä¼ é€’åˆ°ä¸€ç³»åˆ—å€¼ä¸Šçš„è¿‡ç¨‹ç§°ä¸ºå·ç§¯å‡½æ•°ï¼Œä»¥æ­¤ç±»æ¨ï¼Œä¸€ç»„ç¥ç»å…ƒå…±äº«ä¸€ä¸ªæ»¤æ³¢å™¨ï¼ˆå› æ­¤æ¯ä¸ªç¥ç»å…ƒéƒ½å®ç°ç›¸åŒçš„å‡½æ•°ï¼‰ï¼Œå¹¶ä¸”å®ƒä»¬çš„ç»„ç»‡æ–¹å¼ä½¿å®ƒä»¬çš„æ„Ÿå—é‡ä¸€èµ·è¦†ç›–è¾“å…¥ï¼Œåœ¨è¾“å…¥ä¸Šå·ç§¯ä¸€ä¸ªå‡½æ•°42ã€‚"
        }
    },
    {
        "translation": {
            "en": "By doing this, we relax the requirement that, to avoid probabilities of zero, all the evidence events must hold in at least one instance for each value in the domain of the target.",
            "zh": "é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬æ”¾å®½äº†ä»¥ä¸‹è¦æ±‚ï¼šä¸ºäº†é¿å…æ¦‚ç‡ä¸ºé›¶ï¼Œæ‰€æœ‰è¯æ®äº‹ä»¶å¿…é¡»è‡³å°‘ä¿å­˜åœ¨ä¸€ä¸ªå®ä¾‹ä¸­ï¼Œç”¨äºç›®æ ‡åŸŸä¸­çš„æ¯ä¸ªå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is the potential for features to go stale if something about the environment from which they are generated changes.",
            "zh": "å¦‚æœç”ŸæˆåŠŸèƒ½çš„ç¯å¢ƒå‘ç”Ÿå˜åŒ–ï¼Œåˆ™åŠŸèƒ½å¯èƒ½ä¼šè¿‡æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The best advice we can give is that, based on empirical evidence, choosing random initial weights uniformly from the range [âˆ’0.2, 0.2] tends to work well.",
            "zh": "æˆ‘ä»¬èƒ½ç»™å‡ºçš„æœ€å¥½çš„å»ºè®®æ˜¯ï¼Œæ ¹æ®ç»éªŒè¯æ®ï¼Œä»[âˆ’0.2,0.2]èŒƒå›´å†…å‡åŒ€é€‰æ‹©éšæœºåˆå§‹æƒé‡å¾€å¾€æ•ˆæœå¾ˆå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.10â€…â€…â€…The state of the decision tree after the ğ’Ÿ2 partition has been split using SLOPE.",
            "zh": "4.10 ä½¿ç”¨ SLOPE æ‹†åˆ† D2 åˆ†åŒºåçš„å†³ç­–æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remember that each stratum will contain a different number of instances, so by sampling on a percentage basis from each stratum, the number of instances taken from each stratum will be proportional to the number of instances in each stratum.",
            "zh": "è¯·è®°ä½ï¼Œæ¯ä¸ªå±‚å°†åŒ…å«ä¸åŒæ•°é‡çš„å®ä¾‹ï¼Œå› æ­¤é€šè¿‡æŒ‰ç™¾åˆ†æ¯”ä»æ¯ä¸ªå±‚æŠ½æ ·ï¼Œä»æ¯ä¸ªå±‚ä¸­è·å–çš„å®ä¾‹æ•°å°†ä¸æ¯ä¸ªå±‚ä¸­çš„å®ä¾‹æ•°æˆæ­£æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Two different Bayesian networks, each defining the same full joint probability distribution.",
            "zh": "ä¸¤ä¸ªä¸åŒçš„è´å¶æ–¯ç½‘ç»œï¼Œæ¯ä¸ªç½‘ç»œéƒ½å®šä¹‰äº†ç›¸åŒçš„å…¨è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "We first use only the extra ACCOUNT BALANCE feature in the dataset (ignoring LOAN AMOUNT, which we return to later in this chapter) to demonstrate how PDFs allow us to include continuous features in a naive Bayes model.",
            "zh": "æˆ‘ä»¬é¦–å…ˆåœ¨æ•°æ®é›†ä¸­ä»…ä½¿ç”¨é¢å¤–çš„ ACCOUNT BALANCE ç‰¹å¾ï¼ˆå¿½ç•¥ LOAN AMOUNTï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« åé¢è¿”å›ï¼‰æ¥æ¼”ç¤º PDF å¦‚ä½•å…è®¸æˆ‘ä»¬åœ¨æœ´ç´ è´å¶æ–¯æ¨¡å‹ä¸­åŒ…å«è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "A bar plot includes a vertical bar for each level of a categorical feature.",
            "zh": "æ¡å½¢å›¾åŒ…æ‹¬ç”¨äºåˆ†ç±»è¦ç´ çš„æ¯ä¸ªçº§åˆ«çš„å‚ç›´æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the next iteration of the AHC algorithm the distance between this new cluster and all other clusters is calculated.",
            "zh": "åœ¨ AHC ç®—æ³•çš„ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œå°†è®¡ç®—æ­¤æ–°é›†ç¾¤ä¸æ‰€æœ‰å…¶ä»–é›†ç¾¤ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´s for each of the neurons in the network for Example 2.",
            "zh": "ç¤ºä¾‹ 2 ä¸­ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„ Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chapter 9 explains how to evaluate the performance of prediction models and presents a range of different evaluation metrics.",
            "zh": "ç¬¬9ç« è§£é‡Šäº†å¦‚ä½•è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a second example, in Chapter 4[117] we introduce the Iterative Dichotomizer 3 (ID3) machine learning algorithm, which uses a restriction bias of considering only tree prediction models in which each branch encodes a sequence of checks on individual descriptive features but also uses a preference bias by considering shallower (less complex) trees over larger trees.",
            "zh": "ä½œä¸ºç¬¬äºŒä¸ªä¾‹å­ï¼Œåœ¨ç¬¬ 4 ç« [117]ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†è¿­ä»£äºŒåˆ†æ³•å™¨ 3 ï¼ˆID3ï¼‰ æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•ä½¿ç”¨ä»…è€ƒè™‘æ ‘é¢„æµ‹æ¨¡å‹çš„é™åˆ¶åå·®ï¼Œå…¶ä¸­æ¯ä¸ªåˆ†æ”¯å¯¹å•ä¸ªæè¿°æ€§ç‰¹å¾çš„æ£€æŸ¥åºåˆ—è¿›è¡Œç¼–ç ï¼Œä½†ä¹Ÿé€šè¿‡è€ƒè™‘è¾ƒæµ…ï¼ˆä¸å¤ªå¤æ‚ï¼‰çš„æ ‘è€Œä¸æ˜¯è¾ƒå¤§çš„æ ‘æ¥ä½¿ç”¨åå¥½åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even in cases where one of the target levels is very rare, it may not be appropriate to smooth the target level priors.",
            "zh": "å³ä½¿åœ¨å…¶ä¸­ä¸€ä¸ªç›®æ ‡æ°´å¹³éå¸¸ç½•è§çš„æƒ…å†µä¸‹ï¼Œå¹³æ»‘ç›®æ ‡æ°´å¹³å…ˆéªŒä¹Ÿå¯èƒ½ä¸åˆé€‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sarle, Warren S. 1983. Cubic clustering criterion, Technical Report SAS Technical Report A-108, SAS Institute.",
            "zh": "è¨å°”ï¼Œæ²ƒä¼¦ S. 1983 å¹´ã€‚ç«‹æ–¹èšç±»å‡†åˆ™ï¼ŒSASæŠ€æœ¯æŠ¥å‘ŠA-108æŠ€æœ¯æŠ¥å‘Šï¼ŒSASç ”ç©¶æ‰€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Whenever the target one-hot encoding is a 0, we use Equation (8.81)[469] to calculate the Î´; and whenever it is a 1, we use Equation (8.80)[469] to calculate the Î´.",
            "zh": "æ¯å½“ç›®æ ‡å•çƒ­ç¼–ç ä¸º 0 æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¼ ï¼ˆ8.81ï¼‰[469] æ¥è®¡ç®—Î´;æ¯å½“å®ƒæ˜¯ 1 æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–¹ç¨‹ ï¼ˆ8.80ï¼‰[469] æ¥è®¡ç®—Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Information-based machine learning algorithms use the same idea.",
            "zh": "åŸºäºä¿¡æ¯çš„æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ç›¸åŒçš„æ€è·¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, in the context of predicting categorical targets, supervised machine learning creates models that distinguish between the target levels that are present in the dataset from which they are induced.",
            "zh": "å…¶æ¬¡ï¼Œåœ¨é¢„æµ‹åˆ†ç±»ç›®æ ‡çš„èƒŒæ™¯ä¸‹ï¼Œç›‘ç£æœºå™¨å­¦ä¹ åˆ›å»ºæ¨¡å‹ï¼Œä»¥åŒºåˆ†è¯±å¯¼ç›®æ ‡çš„æ•°æ®é›†ä¸­å­˜åœ¨çš„ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "37.11Â°C",
            "zh": "37.11Â°æ‘„æ°åº¦"
        }
    },
    {
        "translation": {
            "en": "A Bayesian network is a directed acyclical graph (there are no cycles in the graph) that is composed of three basic elements:",
            "zh": "è´å¶æ–¯ç½‘ç»œæ˜¯ä¸€ä¸ªæœ‰å‘éå¾ªç¯å›¾ï¼ˆå›¾ä¸­æ²¡æœ‰å¾ªç¯ï¼‰ï¼Œç”±ä¸‰ä¸ªåŸºæœ¬å…ƒç´ ç»„æˆï¼š"
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic space, 559",
            "zh": "æ¥æ”¶æœºå·¥ä½œç‰¹æ€§ç©ºé—´ï¼Œ559"
        }
    },
    {
        "translation": {
            "en": "As indicated by the third item in the list above, there is more to evaluation than measuring model performance. For a model to be successfully deployed, we must consider issues like how quickly the model makes predictions, how easy it easy for human analysts to understand the predictions made by a model, and how easy it is to retrain a model should it go stale over time. We return to these issues in the final section of this chapter.",
            "zh": "å¦‚ä¸Šè¡¨ç¬¬ä¸‰é¡¹æ‰€ç¤ºï¼Œè¯„ä¼°ä¸ä»…ä»…æ˜¯è¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†æˆåŠŸéƒ¨ç½²æ¨¡å‹ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘æ¨¡å‹åšå‡ºé¢„æµ‹çš„é€Ÿåº¦ï¼Œäººç±»åˆ†æå¸ˆç†è§£æ¨¡å‹æ‰€åšçš„é¢„æµ‹çš„éš¾æ˜“ç¨‹åº¦ï¼Œä»¥åŠå¦‚æœæ¨¡å‹éšç€æ—¶é—´çš„æ¨ç§»è€Œè¿‡æ—¶ï¼Œé‡æ–°è®­ç»ƒæ¨¡å‹çš„éš¾æ˜“ç¨‹åº¦ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„æœ€åä¸€èŠ‚ä¸­å›åˆ°è¿™äº›é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "All are correct, although they focus on different characteristics of the letter magnetsâ€”color, case, and character.",
            "zh": "æ‰€æœ‰è¿™äº›éƒ½æ˜¯æ­£ç¡®çš„ï¼Œå°½ç®¡å®ƒä»¬ä¾§é‡äºå­—æ¯ç£é“çš„ä¸åŒç‰¹å¾â€”â€”é¢œè‰²ã€å¤–å£³å’Œå­—ç¬¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.2.2â€ƒMeasuring Similarity Using Distance Metrics",
            "zh": "5.2.2 ä½¿ç”¨è·ç¦»æŒ‡æ ‡è¡¡é‡ç›¸ä¼¼æ€§"
        }
    },
    {
        "translation": {
            "en": "In a mobile phone scenario, we might include three ratio features to indicate the mix between voice, data, and SMS services that a customer uses.",
            "zh": "åœ¨ç§»åŠ¨ç”µè¯åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½åŒ…æ‹¬ä¸‰ä¸ªæ¯”ç‡ç‰¹å¾ï¼Œä»¥æŒ‡ç¤ºå®¢æˆ·ä½¿ç”¨çš„è¯­éŸ³ã€æ•°æ®å’ŒçŸ­ä¿¡æœåŠ¡ä¹‹é—´çš„ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Because this vector of activations from the hidden layer is passed on to another layer for processing, it has to be augmented with the dummy feature d[0] = 1; this is represented by the label on the arrow linking the top row of operations with the bottom row.",
            "zh": "ç”±äºéšè—å±‚çš„æ¿€æ´»å‘é‡è¢«ä¼ é€’åˆ°å¦ä¸€å±‚è¿›è¡Œå¤„ç†ï¼Œå› æ­¤å¿…é¡»ä½¿ç”¨è™šæ‹Ÿç‰¹å¾ d[0] = 1 å¯¹å…¶è¿›è¡Œå¢å¼º;è¿™ç”±ç®­å¤´ä¸Šçš„æ ‡ç­¾è¡¨ç¤ºï¼Œè¯¥æ ‡ç­¾å°†æ“ä½œçš„é¡¶è¡Œä¸åº•è¡Œè¿æ¥èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "product rule, 245, 249, 757, 762",
            "zh": "äº§å“è§„åˆ™ï¼Œ 245ï¼Œ 249ï¼Œ 757ï¼Œ 762"
        }
    },
    {
        "translation": {
            "en": "We use the symbol Î´ to indicate the rate of change of the error of the network with respect to changes in the weighted sum calculated in a neuron.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç¬¦å· Î´ æ¥è¡¨ç¤ºç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒä¸­è®¡ç®—çš„åŠ æƒå’Œçš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The machine learning algorithms tell us how to do this.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•å‘Šè¯‰æˆ‘ä»¬å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. Symmetry: metric(a,b) = metric(b,a)",
            "zh": "3. å¯¹ç§°æ€§ï¼šmetricï¼ˆaï¼Œbï¼‰ = metricï¼ˆbï¼Œaï¼‰"
        }
    },
    {
        "translation": {
            "en": "Machine Learning for Predictive Data Analytics",
            "zh": "ç”¨äºé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "A simple grid world. The start position is annotated with an S and the goal with a G. The squares marked f denote fire, which is very damaging to an agent.",
            "zh": "ä¸€ä¸ªç®€å•çš„ç½‘æ ¼ä¸–ç•Œã€‚èµ·å§‹ä½ç½®ç”¨ S æ ‡æ³¨ï¼Œç›®æ ‡ç”¨ G æ ‡æ³¨ã€‚æ ‡æœ‰ f çš„æ–¹å—è¡¨ç¤ºç«ï¼Œè¿™å¯¹ç‰¹å·¥çš„ä¼¤å®³éå¸¸å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Zhou, Zhi-Hua. 2012. Ensemble methods: Foundations and algorithms. CRC Press.",
            "zh": "å‘¨ï¼Œ å.2012. é›†æˆæ–¹æ³•ï¼šåŸºç¡€å’Œç®—æ³•.CRCå‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "curse of dimensionality, 225, 232, 255, 262, 740, 762",
            "zh": "ç»´åº¦è¯…å’’ï¼Œ225,232,255,262,740,762"
        }
    },
    {
        "translation": {
            "en": "Eulerâ€™s number, 342, 580",
            "zh": "æ¬§æ‹‰æ•°ï¼Œ342,580"
        }
    },
    {
        "translation": {
            "en": "Although there is a mixture in each of these sets, however, it seems to be the case that when UNKNOWN SENDER = true, the majority of emails are spam, and when UNKNOWN SENDER = false, the majority of emails are ham.",
            "zh": "ç„¶è€Œï¼Œå°½ç®¡è¿™äº›é›†åˆä¸­çš„æ¯ä¸€ä¸ªéƒ½å­˜åœ¨æ··åˆï¼Œä½†ä¼¼ä¹æƒ…å†µæ˜¯ï¼Œå½“ UNKNOWN SENDER = true æ—¶ï¼Œå¤§å¤šæ•°ç”µå­é‚®ä»¶éƒ½æ˜¯åƒåœ¾é‚®ä»¶ï¼Œè€Œå½“ UNKNOWN SENDER = false æ—¶ï¼Œå¤§å¤šæ•°ç”µå­é‚®ä»¶éƒ½æ˜¯ hamã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first iteration of the algorithm a dataset is sampled using this distribution, and the number of times each training instance is included in this sample is given in the Freq.",
            "zh": "åœ¨ç®—æ³•çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œä½¿ç”¨æ­¤åˆ†å¸ƒå¯¹æ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä¸”æ¯ä¸ªè®­ç»ƒå®ä¾‹åŒ…å«åœ¨æ­¤æ ·æœ¬ä¸­çš„æ¬¡æ•°åœ¨é¢‘ç‡ä¸­ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, we recommend the use of complete case analysis only to remove instances that are missing the value of the target feature.",
            "zh": "é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä»…ä½¿ç”¨å®Œæ•´çš„æ¡ˆä¾‹åˆ†ææ¥åˆ é™¤ç¼ºå°‘ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The table below shows the policy type held by customers at a life insurance company.",
            "zh": "2. ä¸‹è¡¨æ˜¾ç¤ºå®¢æˆ·åœ¨äººå¯¿ä¿é™©å…¬å¸æŒæœ‰çš„ä¿å•ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.15â€…â€…â€…Scatter plots of three bivariate datasets with the same center point A and two queries B and C both equidistant from A; (a) a dataset uniformly spread around the center point; (b) a dataset with negative covariance; and (c) a dataset with positive covariance.",
            "zh": "5.15 ä¸­å¿ƒç‚¹ç›¸åŒAçš„ä¸‰ä¸ªäºŒå…ƒæ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œä»¥åŠä¸¤ä¸ªæŸ¥è¯¢Bå’ŒCéƒ½ä¸Aç­‰è·;ï¼ˆaï¼‰ å‡åŒ€åˆ†å¸ƒåœ¨ä¸­å¿ƒç‚¹å‘¨å›´çš„æ•°æ®é›†;ï¼ˆbï¼‰ å…·æœ‰è´Ÿåæ–¹å·®çš„æ•°æ®é›†;ï¼ˆcï¼‰å…·æœ‰æ­£åæ–¹å·®çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This matrix multiplication generates the weighted sums for all neurons in the layer for all the examples in the mini-batch and stores the results in the matrix Z(l).",
            "zh": "æ­¤çŸ©é˜µä¹˜æ³•ä¸ºå°æ‰¹é‡ä¸­çš„æ‰€æœ‰ç¤ºä¾‹ç”Ÿæˆå±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒçš„åŠ æƒå’Œï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨çŸ©é˜µ Zï¼ˆlï¼‰ ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that the tanh function has a range of [âˆ’1,+1] means that activations in the cell state can be both increased and decreased at each time-step.",
            "zh": "tanh å‡½æ•°çš„èŒƒå›´ä¸º [âˆ’1ï¼Œ+1] è¿™ä¸€äº‹å®æ„å‘³ç€ç»†èƒçŠ¶æ€çš„æ¿€æ´»å¯ä»¥åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿å¢åŠ å’Œå‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The heights of the players in this second team vary much more than those of the first team (see Figures A.1[746] and A.3[747]).",
            "zh": "ç¬¬äºŒæ”¯çƒé˜Ÿçš„çƒå‘˜èº«é«˜å˜åŒ–æ¯”ç¬¬ä¸€æ”¯çƒé˜Ÿå¤§å¾—å¤šï¼ˆè§å›¾A.1[746]å’ŒA.3[747]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process of apportioning blame for the Î´s in one layer back to the neurons in the preceding layer and then summing the blame for each neuron in the preceding layer to calculate its Î´ is repeated until all the neurons in the first hidden layer of the network have a Î´ term.",
            "zh": "é‡å¤è¿™ä¸€è¿‡ç¨‹ï¼Œå°†ä¸€å±‚ä¸­ Î´ çš„å½’å’åˆ†æ‘Šç»™å‰ä¸€å±‚çš„ç¥ç»å…ƒï¼Œç„¶åå°†å‰ä¸€å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„å½’å’ç›¸åŠ ä»¥è®¡ç®—å…¶Î´ï¼Œç›´åˆ°ç½‘ç»œç¬¬ä¸€éšè—å±‚ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½å…·æœ‰Î´é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (6.17)[286] can be generalized to the statement that for any network with N nodes, the probability of an event x1,â€¦,xn, can be computed using the following formula:",
            "zh": "æ–¹ç¨‹ï¼ˆ6.17ï¼‰[286]å¯ä»¥æ¨å¹¿ä¸ºä»¥ä¸‹è¯­å¥ï¼šå¯¹äºä»»ä½•å…·æœ‰Nä¸ªèŠ‚ç‚¹çš„ç½‘ç»œï¼Œäº‹ä»¶x1,...,xnçš„æ¦‚ç‡å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "4.14â€…â€…â€…A simple bicycle demand predictions dataset and the workings of the first three iterations of training an ensemble model using boosting to predict RENTALS given TEMP.",
            "zh": "4.14 ä¸€ä¸ªç®€å•çš„è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®é›†å’Œè®­ç»ƒé›†æˆæ¨¡å‹çš„å‰ä¸‰ä¸ªè¿­ä»£çš„å·¥ä½œåŸç†ï¼Œä½¿ç”¨æå‡æ¥é¢„æµ‹ç»™å®šæ¸©åº¦çš„ç§Ÿèµã€‚"
        }
    },
    {
        "translation": {
            "en": "where ps is a prediction score value, CP(positive, ps) is the cumulative probability distribution of positive value scores, and CP(negative, ps) is the cumulative probability distribution of negative value scores.",
            "zh": "å…¶ä¸­ ps æ˜¯é¢„æµ‹åˆ†æ•°å€¼ï¼ŒCPï¼ˆpositiveï¼Œ psï¼‰ æ˜¯æ­£å€¼åˆ†æ•°çš„ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒï¼ŒCPï¼ˆnegativeï¼Œ psï¼‰ æ˜¯è´Ÿå€¼åˆ†æ•°çš„ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The CPT associated with each node defines the probabilities of each feature taking a value given the value(s) of its parent node(s).",
            "zh": "ä¸æ¯ä¸ªèŠ‚ç‚¹å…³è”çš„ CPT å®šä¹‰æ¯ä¸ªç‰¹å¾çš„æ¦‚ç‡ï¼Œç»™å®šå…¶çˆ¶èŠ‚ç‚¹çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming the random forest model you have created uses majority voting, what prediction will it return for the following query:",
            "zh": "ï¼ˆbï¼‰ å‡è®¾æ‚¨åˆ›å»ºçš„éšæœºæ£®æ—æ¨¡å‹ä½¿ç”¨å¤šæ•°æŠ•ç¥¨ï¼Œå®ƒå°†ä¸ºä»¥ä¸‹æŸ¥è¯¢è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 10.1[598] shows how the three Murphy children organized the letters on the fridge.",
            "zh": "å›¾10.1[598]æ˜¾ç¤ºäº†å¢¨è²çš„ä¸‰ä¸ªå­©å­æ˜¯å¦‚ä½•æ•´ç†å†°ç®±ä¸Šçš„ä¿¡ä»¶çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. The log of a to the base b, written as logb(a), is the number to which we must raise b to get a. For example, log2(8) = 3 because 23 = 8 and log5(625) = 4 because 54 = 625.",
            "zh": "4. a åˆ°åŸºæ•° b çš„å¯¹æ•°ï¼Œå†™æˆ logbï¼ˆaï¼‰ï¼Œæ˜¯æˆ‘ä»¬å¿…é¡»å°† b æé«˜åˆ°çš„æ•°å­—æ‰èƒ½å¾—åˆ° aã€‚ä¾‹å¦‚ï¼Œlog2ï¼ˆ8ï¼‰ = 3 æ˜¯å› ä¸º 23 = 8ï¼Œlog5ï¼ˆ625ï¼‰ = 4 æ˜¯å› ä¸º 54 = 625ã€‚"
        }
    },
    {
        "translation": {
            "en": "fully observable environment, 640, 640, 673",
            "zh": "å®Œå…¨å¯è§‚æµ‹çš„ç¯å¢ƒï¼Œ640ã€640ã€673"
        }
    },
    {
        "translation": {
            "en": "The distributions of predictions made by a model trained for the bacterial species identification problem for (a) the original evaluation test set, and for (b) and (c) two periods of time after model deployment; (d) shows how the stability index can be tracked over time to monitor for concept drift.",
            "zh": "ä¸ºç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜è®­ç»ƒçš„æ¨¡å‹åœ¨ ï¼ˆaï¼‰ åŸå§‹è¯„ä¼°æµ‹è¯•é›†ä»¥åŠ ï¼ˆbï¼‰ å’Œ ï¼ˆcï¼‰ æ¨¡å‹éƒ¨ç½²åçš„ä¸¤ä¸ªæ—¶é—´æ®µå†…åšå‡ºçš„é¢„æµ‹åˆ†å¸ƒ;ï¼ˆdï¼‰ æ˜¾ç¤ºäº†å¦‚ä½•éšæ—¶é—´è·Ÿè¸ªç¨³å®šæ€§æŒ‡æ•°ä»¥ç›‘æµ‹æ¦‚å¿µæ¼‚ç§»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the RPM and VIBRATION descriptive features from the generators dataset shown in Table 7.6[339], where good generators are shown as crosses, and faulty generators are shown as triangles; and (b) as decision boundary separating good generators (crosses) from faulty generators (triangles).",
            "zh": "ï¼ˆaï¼‰ è¡¨7.6[339]æ‰€ç¤ºçš„å‘ç”µæœºæ•°æ®é›†ä¸­çš„RPMå’ŒVIBRATIONæè¿°æ€§ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼Œå…¶ä¸­å¥½çš„å‘ç”µæœºæ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œæ•…éšœå‘ç”µæœºæ˜¾ç¤ºä¸ºä¸‰è§’å½¢;ï¼ˆbï¼‰ä½œä¸ºå°†è‰¯å¥½å‘ç”µæœºï¼ˆåå­—æ¶ï¼‰ä¸æ•…éšœå‘ç”µæœºï¼ˆä¸‰è§’å½¢ï¼‰åˆ†å¼€çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "2. We could also formulate the generative model as learning the joint distribution P(d,tl) directly and then computing the required posteriors from this distribution.",
            "zh": "2. æˆ‘ä»¬è¿˜å¯ä»¥å°†ç”Ÿæˆæ¨¡å‹è¡¨è¿°ä¸ºç›´æ¥å­¦ä¹ è”åˆåˆ†å¸ƒ Pï¼ˆdï¼Œtlï¼‰ï¼Œç„¶åä»è¯¥åˆ†å¸ƒä¸­è®¡ç®—æ‰€éœ€çš„åéªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "This heuristic highlights the interaction between how we choose to initialize the weights in the network and how the error gradients flow during backpropagation.",
            "zh": "è¿™ç§å¯å‘å¼æ–¹æ³•çªå‡ºäº†æˆ‘ä»¬å¦‚ä½•é€‰æ‹©åˆå§‹åŒ–ç½‘ç»œä¸­çš„æƒé‡ä¸è¯¯å·®æ¢¯åº¦åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å¦‚ä½•æµåŠ¨ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that there is a chapparal leaf node at the end of the branch ELEVATION = low even though there are no instances in the dataset where ELEVATION = low and VEGETATION = chapparal. This leaf node is the result of an empty partition being generated when the partition at the ELEVATION node was split. This leaf node was assigned the target level chapparal because this was the majority target level in the partition at the ELEVATION node.",
            "zh": "è¯·æ³¨æ„ï¼Œå³ä½¿æ•°æ®é›†ä¸­æ²¡æœ‰ ELEVATION = low ä¸” VEGETATION = chapporal çš„å®ä¾‹ï¼Œåˆ†æ”¯ ELEVATION = low çš„æœ«å°¾ä¹Ÿå­˜åœ¨ä¸€ä¸ª chapparal å¶èŠ‚ç‚¹ã€‚æ­¤å¶èŠ‚ç‚¹æ˜¯æ‹†åˆ† ELEVATION èŠ‚ç‚¹ä¸Šçš„åˆ†åŒºæ—¶ç”Ÿæˆç©ºåˆ†åŒºçš„ç»“æœã€‚ä¸ºæ­¤å¶èŠ‚ç‚¹åˆ†é…äº†ç›®æ ‡çº§åˆ« chapparalï¼Œå› ä¸ºè¿™æ˜¯ ELEVATION èŠ‚ç‚¹å¤„åˆ†åŒºä¸­çš„å¤§å¤šæ•°ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "This reflects that ELEVATION and STREAM have already been used on the path from the root node to each of these partitions and so cannot be used again.",
            "zh": "è¿™åæ˜ å‡º ELEVATION å’Œ STREAM å·²åœ¨ä»æ ¹èŠ‚ç‚¹åˆ°æ¯ä¸ªåˆ†åŒºçš„è·¯å¾„ä¸Šä½¿ç”¨ï¼Œå› æ­¤ä¸èƒ½å†æ¬¡ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.3â€…â€…The members of a rival school basketball team. Player heights are listed below each player. The dashed gray line shows the arithmetic mean of the playersâ€™ heights.",
            "zh": "A.3 æ•Œå¯¹å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ã€‚æ¯ä¸ªç©å®¶ä¸‹æ–¹åˆ—å‡ºäº†ç©å®¶çš„èº«é«˜ã€‚ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we have already discussed the solution to this problem.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºäº†è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The filter dimension hyper-parameter specifies the size of the filter in each dimension.",
            "zh": "è¿‡æ»¤å™¨ç»´åº¦è¶…å‚æ•°æŒ‡å®šæ¯ä¸ªç»´åº¦ä¸­è¿‡æ»¤å™¨çš„å¤§å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "over-sampling, 93",
            "zh": "è¿‡é‡‡æ ·ï¼Œ93"
        }
    },
    {
        "translation": {
            "en": "Usually small stacks of screenshots (e.g.",
            "zh": "é€šå¸¸æ˜¯ä¸€å°å †å±å¹•æˆªå›¾ï¼ˆä¾‹å¦‚"
        }
    },
    {
        "translation": {
            "en": "A plot of this function would pass through the origin because there is no y-intercept (or bias term) included in the calculation.",
            "zh": "æ­¤å‡½æ•°çš„å›¾å°†é€šè¿‡åŸç‚¹ï¼Œå› ä¸ºè®¡ç®—ä¸­ä¸åŒ…å« y æˆªè·ï¼ˆæˆ–åç½®é¡¹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Non-negativity: metric(a,b) â‰¥ 0",
            "zh": "1. éè´Ÿæ€§ï¼šæŒ‡æ ‡ï¼ˆaï¼Œbï¼‰â‰¥0"
        }
    },
    {
        "translation": {
            "en": "Decision trees also have difficulty with domains that have a large number of descriptive features, particularly if the number of instances in the training dataset is small. In these situations overfitting becomes very likely. The probability-based models discussed in Chapter 6[243] do a better job of handling high-dimensional data.",
            "zh": "å¯¹äºå…·æœ‰å¤§é‡æè¿°æ€§ç‰¹å¾çš„åŸŸï¼Œå†³ç­–æ ‘ä¹Ÿå­˜åœ¨å›°éš¾ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒæ•°æ®é›†ä¸­çš„å®ä¾‹æ•°é‡è¾ƒå°‘çš„æƒ…å†µä¸‹ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè¿‡æ‹Ÿåˆå˜å¾—éå¸¸æœ‰å¯èƒ½ã€‚ç¬¬6ç« [243]ä¸­è®¨è®ºçš„åŸºäºæ¦‚ç‡çš„æ¨¡å‹åœ¨å¤„ç†é«˜ç»´æ•°æ®æ–¹é¢åšå¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the errorDelta(ğ’Ÿ,w[j]) for a weight has been calculated, we can then update the weight using Equation (7.17)[327]. This weight update occurs on Line 4[326] of Algorithm 4[326]. The update involves multiplying the errorDelta(ğ’Ÿ,w[j]) for a given weight by the learning rate and then adding this to the current weight to give a new, updated, weight. The new set of weights is labeled New Weights (after Iteration 1) in Table 7.3[331].",
            "zh": "ä¸€æ—¦è®¡ç®—å‡ºæƒé‡çš„è¯¯å·®Deltaï¼ˆDï¼Œw[j]ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å…¬å¼ï¼ˆ7.17ï¼‰[327]æ›´æ–°æƒé‡ã€‚æ­¤æƒé‡æ›´æ–°å‘ç”Ÿåœ¨ç®—æ³• 4[326] çš„ç¬¬ 4 è¡Œ [326]ã€‚æ›´æ–°æ¶‰åŠå°†ç»™å®šæƒé‡çš„ errorDeltaï¼ˆDï¼Œw[j]ï¼‰ ä¹˜ä»¥å­¦ä¹ ç‡ï¼Œç„¶åå°†å…¶æ·»åŠ åˆ°å½“å‰æƒé‡ä¸­ä»¥ç»™å‡ºæ–°çš„æ›´æ–°æƒé‡ã€‚åœ¨è¡¨7.3[331]ä¸­ï¼Œæ–°çš„æƒé‡é›†è¢«æ ‡è®°ä¸ºæ–°æƒé‡ï¼ˆè¿­ä»£1ä¹‹åï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Target network freezing makes the training process more stable and leads to faster convergence.",
            "zh": "ç›®æ ‡ç½‘ç»œå†»ç»“ä½¿è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œå¹¶å¯¼è‡´æ›´å¿«çš„æ”¶æ•›ã€‚"
        }
    },
    {
        "translation": {
            "en": "In clustering, unsupervised algorithms are used to partition the instances in a dataset into coherent groups.",
            "zh": "åœ¨èšç±»åˆ†æä¸­ï¼Œæ— ç›‘ç£ç®—æ³•ç”¨äºå°†æ•°æ®é›†ä¸­çš„å®ä¾‹åˆ’åˆ†ä¸ºè¿è´¯çš„ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.8[269] lists the prior and smoothed conditional probabilities for the fraud domain that are relevant to a naive Bayes model. Notice that there are no zero probabilities, so the model will be able to return a prediction for any query in this domain. We can illustrate the extended coverage of the model by returning to the query from the beginning of this section:",
            "zh": "è¡¨ 6.8[269] åˆ—å‡ºäº†ä¸æœ´ç´ è´å¶æ–¯æ¨¡å‹ç›¸å…³çš„æ¬ºè¯ˆåŸŸçš„å…ˆéªŒå’Œå¹³æ»‘æ¡ä»¶æ¦‚ç‡ã€‚è¯·æ³¨æ„ï¼Œæ²¡æœ‰é›¶æ¦‚ç‡ï¼Œå› æ­¤æ¨¡å‹å°†èƒ½å¤Ÿè¿”å›æ­¤åŸŸä¸­ä»»ä½•æŸ¥è¯¢çš„é¢„æµ‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿”å›æœ¬èŠ‚å¼€å¤´çš„æŸ¥è¯¢æ¥è¯´æ˜æ¨¡å‹çš„æ‰©å±•è¦†ç›–èŒƒå›´ï¼š"
        }
    },
    {
        "translation": {
            "en": "To illustrate these characteristics, we have created three artificial datasets and trained four different models on each of these datasets.",
            "zh": "ä¸ºäº†è¯´æ˜è¿™äº›ç‰¹å¾ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸‰ä¸ªäººå·¥æ•°æ®é›†ï¼Œå¹¶åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒäº†å››ä¸ªä¸åŒçš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These predictions do not solve business problems; rather, they provide insights that help the organization make better decisions to solve their business problems.",
            "zh": "è¿™äº›é¢„æµ‹å¹¶ä¸èƒ½è§£å†³ä¸šåŠ¡é—®é¢˜;ç›¸åï¼Œå®ƒä»¬æä¾›çš„è§è§£å¯å¸®åŠ©ç»„ç»‡åšå‡ºæ›´å¥½çš„å†³ç­–æ¥è§£å†³å…¶ä¸šåŠ¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.1",
            "zh": "è¡¨ 4.1"
        }
    },
    {
        "translation": {
            "en": "Consider, however, the dataset presented in Table 1.2[8], which shows a more complete representation of the same problem. This dataset lists more instances, and there are extra descriptive features describing the AMOUNT that a mortgage holder borrows, the mortgage holderâ€™s SALARY, the type of PROPERTY that the mortgage relates to (which can be farm, house, or apartment), and the TYPE of mortgage (which can be ftb for first-time buyers or stb for second-time buyers).",
            "zh": "ç„¶è€Œï¼Œè€ƒè™‘è¡¨1.2[8]ä¸­æ˜¾ç¤ºçš„æ•°æ®é›†ï¼Œå®ƒæ˜¾ç¤ºäº†åŒä¸€é—®é¢˜çš„æ›´å®Œæ•´è¡¨ç¤ºã€‚è¯¥æ•°æ®é›†åˆ—å‡ºäº†æ›´å¤šå®ä¾‹ï¼Œå¹¶ä¸”æœ‰é¢å¤–çš„æè¿°æ€§ç‰¹å¾æè¿°äº†æŠµæŠ¼è´·æ¬¾æŒæœ‰äººå€Ÿæ¬¾çš„é‡‘é¢ã€æŠµæŠ¼è´·æ¬¾æŒæœ‰äººçš„å·¥èµ„ã€æŠµæŠ¼è´·æ¬¾ç›¸å…³çš„è´¢äº§ç±»å‹ï¼ˆå¯ä»¥æ˜¯å†œåœºã€æˆ¿å±‹æˆ–å…¬å¯“ï¼‰å’ŒæŠµæŠ¼è´·æ¬¾ç±»å‹ï¼ˆé¦–æ¬¡è´­æˆ¿è€…å¯ä»¥æ˜¯ ftbï¼Œç¬¬äºŒæ¬¡è´­æˆ¿è€…å¯ä»¥æ˜¯ stbï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. ROC curves are often plotted with sensitivity on the vertical axis and 1 âˆ’ specificity on the horizontal axis. Recall that sensitivity is equal to TPR, and specificity is equal to TNR, so these are equivalent.",
            "zh": "14. ROCæ›²çº¿é€šå¸¸åœ¨çºµè½´ä¸Šå…·æœ‰çµæ•åº¦ï¼Œåœ¨æ°´å¹³è½´ä¸Šå…·æœ‰1 âˆ’ç‰¹å¼‚æ€§ã€‚å›æƒ³ä¸€ä¸‹ï¼Œçµæ•åº¦ç­‰äº TPRï¼Œç‰¹å¼‚æ€§ç­‰äº TNRï¼Œå› æ­¤å®ƒä»¬æ˜¯ç­‰æ•ˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Training a neural network involves finding a good set of values for these weights.",
            "zh": "è®­ç»ƒç¥ç»ç½‘ç»œæ¶‰åŠä¸ºè¿™äº›æƒé‡æ‰¾åˆ°ä¸€ç»„å¥½çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "A depiction of the Markov blanket of a node. The gray nodes define the Markov blanket of the black node. The black node is conditionally independent of the white nodes given the state of the gray nodes.",
            "zh": "èŠ‚ç‚¹çš„é©¬å°”å¯å¤«æ¯¯çš„æè¿°ã€‚ç°è‰²èŠ‚ç‚¹å®šä¹‰é»‘è‰²èŠ‚ç‚¹çš„é©¬å°”å¯å¤«æ¯¯ã€‚ç»™å®šç°è‰²èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œé»‘è‰²èŠ‚ç‚¹æœ‰æ¡ä»¶åœ°ç‹¬ç«‹äºç™½è‰²èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, instructors using this book can plan their courses by simply selecting the sections of the book they wish to cover without worrying about dependencies between the sections.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨æœ¬ä¹¦çš„æ•™å¸ˆåªéœ€é€‰æ‹©ä»–ä»¬å¸Œæœ›æ¶µç›–çš„ä¹¦ä¸­çš„éƒ¨åˆ†å³å¯è®¡åˆ’ä»–ä»¬çš„è¯¾ç¨‹ï¼Œè€Œä¸å¿…æ‹…å¿ƒå„éƒ¨åˆ†ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the way that we analyzed the questions in the Guess Who game, we measure the discriminatory power of a descriptive feature by analyzing the size and probability of each set of instances created when we test the value of the feature and how pure each set of instances is with respect to the target feature values of the instances it contains.",
            "zh": "ä¸æˆ‘ä»¬åœ¨â€œçŒœçŒœè°â€æ¸¸æˆä¸­åˆ†æé—®é¢˜çš„æ–¹å¼ç±»ä¼¼ï¼Œæˆ‘ä»¬é€šè¿‡åˆ†æåœ¨æµ‹è¯•ç‰¹å¾å€¼æ—¶åˆ›å»ºçš„æ¯ç»„å®ä¾‹çš„å¤§å°å’Œæ¦‚ç‡ä»¥åŠæ¯ç»„å®ä¾‹ç›¸å¯¹äºå…¶åŒ…å«çš„å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼çš„çº¯åº¦æ¥è¡¡é‡æè¿°æ€§ç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "CBR, 234",
            "zh": "CBRï¼Œ234"
        }
    },
    {
        "translation": {
            "en": "When making predictions about categorical targets, we need performance measures that capture how often the model makes correct predictions and the severity of the mistakes that the model makes when it is incorrect.",
            "zh": "åœ¨å¯¹åˆ†ç±»ç›®æ ‡è¿›è¡Œé¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ€§èƒ½åº¦é‡æ¥æ•è·æ¨¡å‹åšå‡ºæ­£ç¡®é¢„æµ‹çš„é¢‘ç‡ä»¥åŠæ¨¡å‹ä¸æ­£ç¡®æ—¶æ‰€çŠ¯é”™è¯¯çš„ä¸¥é‡ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Bayesâ€™ Theorem is named after the Reverend Thomas Bayes, who wrote an essay that described how to update beliefs as new information arises. After Thomas Bayes died, this essay was edited and published by the Reverend Richard Price (Bayes and Price, 1763). The modern mathematical form of Bayesâ€™ Theorem, however, was developed by Simon Pierre Laplace.",
            "zh": "4. è´å¶æ–¯å®šç†ä»¥æ‰˜é©¬æ–¯Â·è´å¶æ–¯ç‰§å¸ˆçš„åå­—å‘½åï¼Œä»–å†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œæè¿°äº†å¦‚ä½•åœ¨æ–°ä¿¡æ¯å‡ºç°æ—¶æ›´æ–°ä¿¡å¿µã€‚æ‰˜é©¬æ–¯Â·è´å¶æ–¯å»ä¸–åï¼Œè¿™ç¯‡æ–‡ç« ç”±ç†æŸ¥å¾·Â·æ™®è±æ–¯ç‰§å¸ˆç¼–è¾‘å’Œå‡ºç‰ˆï¼ˆè´å¶æ–¯å’Œæ™®è±æ–¯ï¼Œ1763 å¹´ï¼‰ã€‚ç„¶è€Œï¼Œè´å¶æ–¯å®šç†çš„ç°ä»£æ•°å­¦å½¢å¼æ˜¯ç”±è¥¿è’™Â·çš®åŸƒå°”Â·æ‹‰æ™®æ‹‰æ–¯ï¼ˆSimon Pierre Laplaceï¼‰å¼€å‘çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This assumption is important because these internal activation functions may be as complex as, or even more complex than, the target function that the network is attempting to represent.",
            "zh": "è¿™ä¸ªå‡è®¾å¾ˆé‡è¦ï¼Œå› ä¸ºè¿™äº›å†…éƒ¨æ¿€æ´»å‡½æ•°å¯èƒ½ä¸ç½‘ç»œè¯•å›¾è¡¨ç¤ºçš„ç›®æ ‡å‡½æ•°ä¸€æ ·å¤æ‚ï¼Œç”šè‡³æ›´å¤æ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates a feature that has the same value for every instance and contains no information useful for building predictive models.",
            "zh": "è¿™è¡¨ç¤ºä¸€ä¸ªåŠŸèƒ½å¯¹æ¯ä¸ªå®ä¾‹éƒ½å…·æœ‰ç›¸åŒçš„å€¼ï¼Œå¹¶ä¸”ä¸åŒ…å«å¯¹æ„å»ºé¢„æµ‹æ¨¡å‹æœ‰ç”¨çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kaiming initialization, 461",
            "zh": "å¼€æ˜åˆå§‹åŒ–ï¼Œ461"
        }
    },
    {
        "translation": {
            "en": "EDUCATION, a categorical feature listing the highest education award achieved by the individual (high school, bachelors, doctorate);",
            "zh": "EDUCATIONï¼Œä¸€ä¸ªåˆ†ç±»ç‰¹å¾ï¼Œåˆ—å‡ºäº†ä¸ªäººè·å¾—çš„æœ€é«˜æ•™è‚²å¥–é¡¹ï¼ˆé«˜ä¸­ã€å­¦å£«ã€åšå£«å­¦ä½ï¼‰;"
        }
    },
    {
        "translation": {
            "en": "mini-batches, 417",
            "zh": "å°æ‰¹é‡ï¼Œ417"
        }
    },
    {
        "translation": {
            "en": "For example, in our example network, if Neuron 8 is dead, the network will never converge on the training stop criterion, because no error gradients will be backpropagated to the earlier layers and so no training will occur.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ç½‘ç»œä¸­ï¼Œå¦‚æœ Neuron 8 æ˜¯æ­»çš„ï¼Œåˆ™ç½‘ç»œå°†æ°¸è¿œä¸ä¼šæ”¶æ•›åˆ°è®­ç»ƒåœæ­¢æ ‡å‡†ä¸Šï¼Œå› ä¸ºæ²¡æœ‰è¯¯å·®æ¢¯åº¦ä¼šåå‘ä¼ æ’­åˆ°è¾ƒæ—©çš„å±‚ï¼Œå› æ­¤ä¸ä¼šå‘ç”Ÿè®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "input gate, 508, 511",
            "zh": "è¾“å…¥é—¨ï¼Œ 508ï¼Œ 511"
        }
    },
    {
        "translation": {
            "en": "The descriptive features of the mysterious newly discovered animal are as follows:",
            "zh": "è¿™ç§æ–°å‘ç°çš„ç¥ç§˜åŠ¨ç‰©çš„æè¿°æ€§ç‰¹å¾å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Modeling points in time using an observation period and an outcome period.",
            "zh": "ä½¿ç”¨è§‚å¯ŸæœŸå’Œç»“æœæœŸå¯¹æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "When mistakes are made, it would be useful for the production line operators to be able to query the model to understand why it made the prediction that led to a mistake.",
            "zh": "å½“å‡ºç°é”™è¯¯æ—¶ï¼Œç”Ÿäº§çº¿æ“ä½œå‘˜èƒ½å¤ŸæŸ¥è¯¢æ¨¡å‹ä»¥äº†è§£å®ƒä¸ºä»€ä¹ˆåšå‡ºå¯¼è‡´é”™è¯¯çš„é¢„æµ‹ä¼šå¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each row should also include the percentage of instances in the ABT that are missing a value for the feature and the cardinality of the feature.",
            "zh": "æ¯è¡Œè¿˜åº”åŒ…æ‹¬ ABT ä¸­ç¼ºå°‘ç‰¹å¾å€¼å’Œç‰¹å¾åŸºæ•°çš„å®ä¾‹çš„ç™¾åˆ†æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The candidate feature subset that leads to the best-performing model is then selected.",
            "zh": "ç„¶åé€‰æ‹©å¯¼è‡´æ€§èƒ½æœ€ä½³æ¨¡å‹çš„å€™é€‰ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "discount rate, 642",
            "zh": "è´´ç°ç‡ï¼Œ 642"
        }
    },
    {
        "translation": {
            "en": "10. Because this is a higher-dimensional problem (three dimensions in the feature space and four dimensions in the weight space), it is not possible to draw the same graphs of the error surfaces that were shown for the previous examples.",
            "zh": "10. ç”±äºè¿™æ˜¯ä¸€ä¸ªæ›´é«˜ç»´çš„é—®é¢˜ï¼ˆç‰¹å¾ç©ºé—´ä¸­çš„ä¸‰ç»´ç©ºé—´å’Œæƒé‡ç©ºé—´ä¸­çš„å››ç»´ï¼‰ï¼Œå› æ­¤ä¸å¯èƒ½ç»˜åˆ¶ä¸å‰é¢ç¤ºä¾‹ç›¸åŒçš„è¯¯å·®é¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "11. Understanding the probabilities associated with the dynamics of card games has a history stretching back to the origins of probability theory (Bernstein, 1996), through early applications of computing technology (Scarne, 1986), right to the modern day (Brown and Sandholm, 2017).",
            "zh": "11. äº†è§£ä¸çº¸ç‰Œæ¸¸æˆåŠ¨åŠ›å­¦ç›¸å…³çš„æ¦‚ç‡çš„å†å²å¯ä»¥è¿½æº¯åˆ°æ¦‚ç‡è®ºçš„èµ·æºï¼ˆBernsteinï¼Œ1996ï¼‰ï¼Œé€šè¿‡è®¡ç®—æŠ€æœ¯çš„æ—©æœŸåº”ç”¨ï¼ˆScarneï¼Œ1986ï¼‰ï¼Œä¸€ç›´åˆ°ç°ä»£ï¼ˆBrown and Sandholmï¼Œ2017ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.19",
            "zh": "å›¾ 8.19"
        }
    },
    {
        "translation": {
            "en": "The fact that the derivative of the rectifier function takes either a 0 or a 1 value means that during backpropagation for some neurons in a network, the Î´ value will be pushed to zero.",
            "zh": "æ•´æµå™¨å‡½æ•°çš„å¯¼æ•°é‡‡ç”¨ 0 æˆ– 1 å€¼è¿™ä¸€äº‹å®æ„å‘³ç€åœ¨ç½‘ç»œä¸­æŸäº›ç¥ç»å…ƒçš„åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼ŒÎ´å€¼å°†è¢«æ¨è‡³é›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because the same inverse covariance matrix based on the entire dataset was used in each case.",
            "zh": "è¿™æ˜¯å› ä¸ºåœ¨æ¯ç§æƒ…å†µä¸‹éƒ½ä½¿ç”¨äº†åŸºäºæ•´ä¸ªæ•°æ®é›†çš„ç›¸åŒé€†åæ–¹å·®çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "One overarching point about reinforcement learning that is worth mentioning is that it comes at the cost of hugely increased computation. Training reinforcement learning agents for sophisticated tasks in complex, dynamic environments can required large computational resources for significant amounts of time. This is especially the case when approximate methods based on deep neural networks are used.",
            "zh": "å…³äºå¼ºåŒ–å­¦ä¹ ï¼Œå€¼å¾—ä¸€æçš„ä¸€ä¸ªæ€»ä½“ç‚¹æ˜¯ï¼Œå®ƒæ˜¯ä»¥å¤§å¹…å¢åŠ è®¡ç®—ä¸ºä»£ä»·çš„ã€‚åœ¨å¤æ‚ã€åŠ¨æ€çš„ç¯å¢ƒä¸­è®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ä»¥å®Œæˆå¤æ‚çš„ä»»åŠ¡å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼ŒæŒç»­å¾ˆé•¿æ—¶é—´ã€‚å½“ä½¿ç”¨åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„è¿‘ä¼¼æ–¹æ³•æ—¶ï¼Œæƒ…å†µå°¤å…¶å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "database management systems, 42",
            "zh": "æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼Œ42"
        }
    },
    {
        "translation": {
            "en": "Furthermore, if we want to make a MAP prediction, we donâ€™t necessarily have to calculate the actual probabilities for each level in the target domain; we simply need to know which of the levels in the target domain has the largest probability.",
            "zh": "æ­¤å¤–ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¿›è¡Œ MAP é¢„æµ‹ï¼Œæˆ‘ä»¬ä¸ä¸€å®šå¿…é¡»è®¡ç®—ç›®æ ‡åŸŸä¸­æ¯ä¸ªæ°´å¹³çš„å®é™…æ¦‚ç‡;æˆ‘ä»¬åªéœ€è¦çŸ¥é“ç›®æ ‡åŸŸä¸­å“ªä¸ªçº§åˆ«çš„æ¦‚ç‡æœ€å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard approach to addressing this problem is to use the independence and conditional independence relationships between the features in a domain to factorize the full joint distribution of the domain.",
            "zh": "è§£å†³æ­¤é—®é¢˜çš„æ ‡å‡†æ–¹æ³•æ˜¯ä½¿ç”¨åŸŸä¸­ç‰¹å¾ä¹‹é—´çš„ç‹¬ç«‹æ€§å’Œæ¡ä»¶ç‹¬ç«‹æ€§å…³ç³»æ¥åˆ†è§£åŸŸçš„å®Œå…¨è”åˆåˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, neural networks with no hidden layer (i.e., perceptrons) cannot represent non-linearly separable functions.",
            "zh": "æ€»ä¹‹ï¼Œæ²¡æœ‰éšè—å±‚ï¼ˆå³æ„ŸçŸ¥å™¨ï¼‰çš„ç¥ç»ç½‘ç»œä¸èƒ½è¡¨ç¤ºéçº¿æ€§å¯åˆ†ç¦»çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "spam filtering, 262",
            "zh": "åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼Œ 262"
        }
    },
    {
        "translation": {
            "en": "As the oft-quoted maxim states: correlation does not imply causation!",
            "zh": "æ­£å¦‚ç»å¸¸è¢«å¼•ç”¨çš„æ ¼è¨€æ‰€è¯´ï¼šç›¸å…³æ€§å¹¶ä¸æ„å‘³ç€å› æœå…³ç³»ï¼"
        }
    },
    {
        "translation": {
            "en": "Once these tables have been created, for each weight we sum the âˆ‚â„°/âˆ‚wi,k for that weight across the tables.",
            "zh": "åˆ›å»ºè¿™äº›è¡¨åï¼Œå¯¹äºæ¯ä¸ªæƒé‡ï¼Œæˆ‘ä»¬å°†è¯¥æƒé‡çš„ âˆ‚E/âˆ‚wiï¼Œk ç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "non-linear model, 311",
            "zh": "éçº¿æ€§æ¨¡å‹ï¼Œ311"
        }
    },
    {
        "translation": {
            "en": "Edwin was assigned to Jocelyn as her key scientific contact from SDSS and was eager to answer any questions Jocelyn had as he saw real value in the model she was developing.",
            "zh": "Edwin è¢«æŒ‡æ´¾ç»™ Jocelyn ä½œä¸º SDSS çš„ä¸»è¦ç§‘å­¦è”ç³»äººï¼Œå¹¶æ¸´æœ›å›ç­” Jocelyn çš„ä»»ä½•é—®é¢˜ï¼Œå› ä¸ºä»–çœ‹åˆ°äº†å¥¹æ­£åœ¨å¼€å‘çš„æ¨¡å‹çš„çœŸæ­£ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The different data sources typically combined to create an analytics base table.",
            "zh": "é€šå¸¸å°†ä¸åŒçš„æ•°æ®æºç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºåˆ†æåŸºè¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to multiply one matrix by another, the number of columns in the matrix on the left of the product must equal the number of rows in the matrix on the right.",
            "zh": "ä¸ºäº†å°†ä¸€ä¸ªçŸ©é˜µä¹˜ä»¥å¦ä¸€ä¸ªçŸ©é˜µï¼Œä¹˜ç§¯å·¦ä¾§çŸ©é˜µä¸­çš„åˆ—æ•°å¿…é¡»ç­‰äºå³ä¾§çŸ©é˜µä¸­çš„è¡Œæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The following image illustrates the topology of a simple feedforward neural network that has a single sensing neuron (Neuron 1), three hidden processing neuron (Neurons 2, 3, and 4), and a single processing output neuron (Neuron 5).",
            "zh": "5. ä¸‹å›¾è¯´æ˜äº†ä¸€ä¸ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ï¼Œè¯¥ç½‘ç»œå…·æœ‰å•ä¸ªä¼ æ„Ÿç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 1ï¼‰ã€ä¸‰ä¸ªéšè—å¤„ç†ç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 2ã€3 å’Œ 4ï¼‰å’Œä¸€ä¸ªå¤„ç†è¾“å‡ºç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 5ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, we have a situation where the posterior for a given prediction given the evidence is quite low (here P(m | h,Â¬f,v) = 0.3333), even though the likelihood of the evidence if we assume the prediction to be correct is quite high, P(h,Â¬f,v | m) = 0.6666.",
            "zh": "äº‹å®ä¸Šï¼Œæˆ‘ä»¬é‡åˆ°è¿™æ ·ä¸€ç§æƒ…å†µï¼Œå³ç»™å®šè¯æ®çš„ç»™å®šé¢„æµ‹çš„åéªŒéå¸¸ä½ï¼ˆè¿™é‡Œ Pï¼ˆm | hï¼ŒÂ¬fï¼Œvï¼‰ = 0.3333ï¼‰ï¼Œå³ä½¿å¦‚æœæˆ‘ä»¬å‡è®¾é¢„æµ‹æ˜¯æ­£ç¡®çš„ï¼Œè¯æ®çš„å¯èƒ½æ€§ç›¸å½“é«˜ï¼ŒPï¼ˆhï¼ŒÂ¬fï¼Œv | mï¼‰ = 0.6666ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can seem counterintuitive at first.",
            "zh": "ä¹ä¸€çœ‹ï¼Œè¿™ä¼¼ä¹æœ‰æ‚–å¸¸ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an example of the compactness of a naive Bayes representation.",
            "zh": "è¿™æ˜¯æœ´ç´ è´å¶æ–¯è¡¨ç¤ºçš„ç´§å‡‘æ€§çš„ä¸€ä¸ªä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.2â€…â€…â€…Weight Initialization and Unstable Gradients",
            "zh": "8.4.2 æƒé‡åˆå§‹åŒ–å’Œä¸ç¨³å®šæ¢¯åº¦"
        }
    },
    {
        "translation": {
            "en": "In this figure, the imaginary pixels are shown in gray, and the valid (real) pixels are in the center of the matrix, shown in black.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œè™šåƒç´ ä»¥ç°è‰²æ˜¾ç¤ºï¼Œæœ‰æ•ˆï¼ˆå®é™…ï¼‰åƒç´ ä½äºçŸ©é˜µçš„ä¸­å¿ƒï¼Œä»¥é»‘è‰²æ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In contrast with supervised learning, there is no target feature that we build a model to predict; rather, we perform modeling to find structure within a set of instances defined by descriptive features alone.",
            "zh": "ä¸ç›‘ç£å­¦ä¹ ç›¸æ¯”ï¼Œæˆ‘ä»¬æ²¡æœ‰æ„å»ºæ¨¡å‹æ¥é¢„æµ‹çš„ç›®æ ‡ç‰¹å¾;ç›¸åï¼Œæˆ‘ä»¬æ‰§è¡Œå»ºæ¨¡ä»¥åœ¨ä»…ç”±æè¿°æ€§ç‰¹å¾å®šä¹‰çš„ä¸€ç»„å®ä¾‹ä¸­æŸ¥æ‰¾ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "To determine the best value for k we can repeatedly cluster the data for all values of k within a given range, calculate a clustering performance measure for each clustering found, and then select the value of k that gives the clustering with the highest performance measure.",
            "zh": "ä¸ºäº†ç¡®å®š k çš„æœ€ä½³å€¼ï¼Œæˆ‘ä»¬å¯ä»¥é‡å¤èšç±»ç»™å®šèŒƒå›´å†…æ‰€æœ‰ k å€¼çš„æ•°æ®ï¼Œä¸ºæ‰¾åˆ°çš„æ¯ä¸ªèšç±»è®¡ç®—èšç±»æ€§èƒ½åº¦é‡ï¼Œç„¶åé€‰æ‹© k å€¼ï¼Œè¯¥å€¼ä¸ºå…·æœ‰æœ€é«˜æ€§èƒ½åº¦é‡çš„èšç±»æä¾›èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn discussed this model with Edwin, and they both agreed that the performance was not at the level required by the SDSS scientists for inclusion in the SDSS processing pipeline.",
            "zh": "Jocelyn ä¸ Edwin è®¨è®ºäº†è¿™ä¸ªæ¨¡å‹ï¼Œä»–ä»¬éƒ½åŒæ„è¯¥æ¨¡å‹çš„æ€§èƒ½æ²¡æœ‰è¾¾åˆ° SDSS ç§‘å­¦å®¶çº³å…¥ SDSS å¤„ç†ç®¡é“æ‰€éœ€çš„æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "forget gate, 508",
            "zh": "å¿˜è®°é—¨ï¼Œ508"
        }
    },
    {
        "translation": {
            "en": "Rather, analytics projects are initiated in response to a business problem, and it is our jobâ€”as analytics practitionersâ€”to decide how to address this business problem using analytics techniques.",
            "zh": "ç›¸åï¼Œåˆ†æé¡¹ç›®æ˜¯ä¸ºäº†å“åº”ä¸šåŠ¡é—®é¢˜è€Œå¯åŠ¨çš„ï¼Œä½œä¸ºåˆ†æä»ä¸šè€…ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯å†³å®šå¦‚ä½•ä½¿ç”¨åˆ†ææŠ€æœ¯è§£å†³æ­¤ä¸šåŠ¡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "To train a naive Bayes model using this data, we need to compute the prior probabilities of the target feature taking each level in its domain, and the conditional probability of each feature taking each level in its domain conditioned for each level that the target can take.",
            "zh": "ä¸ºäº†ä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒæœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ç›®æ ‡ç‰¹å¾åœ¨å…¶åŸŸä¸­è·å–æ¯ä¸ªæ°´å¹³çš„å…ˆéªŒæ¦‚ç‡ï¼Œä»¥åŠæ¯ä¸ªç‰¹å¾åœ¨å…¶åŸŸä¸­è·å–æ¯ä¸ªå±‚æ¬¡çš„æ¡ä»¶æ¦‚ç‡ï¼Œä»¥ç›®æ ‡å¯ä»¥è·å–çš„æ¯ä¸ªæ°´å¹³ä¸ºæ¡ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Have gotten to know the features within the ABT, especially their central tendencies, variations, and distributions.",
            "zh": "1. äº†è§£ ABT ä¸­çš„ç‰¹å¾ï¼Œå°¤å…¶æ˜¯å®ƒä»¬çš„ä¸­å¿ƒè¶‹åŠ¿ã€å˜åŒ–å’Œåˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "17. The data used in this question have been artificially generated for this book. This type of application of machine learning techniques, however, is common; for example, see Osowski et al. (2004).",
            "zh": "17. æœ¬é—®é¢˜ä¸­ä½¿ç”¨çš„æ•°æ®æ˜¯ä¸ºæœ¬ä¹¦äººä¸ºç”Ÿæˆçš„ã€‚ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ æŠ€æœ¯çš„è¿™ç§åº”ç”¨å¾ˆå¸¸è§;ä¾‹å¦‚ï¼Œå‚è§Osowski et al. ï¼ˆ2004ï¼‰ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.9[672] illustrates this architecture.",
            "zh": "å›¾ 11.9[672] è¯´æ˜äº†è¿™ç§æ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cybenko, George. 1988. Continuous valued neural networks with two hidden layers are sufficient, Technical report, Department of Computer Science, Tufts University.",
            "zh": "èµ›å®¾ç§‘ï¼Œä¹”æ²»ã€‚1988. å…·æœ‰ä¸¤ä¸ªéšè—å±‚çš„è¿ç»­å€¼ç¥ç»ç½‘ç»œå°±è¶³å¤Ÿäº†ï¼ŒæŠ€æœ¯æŠ¥å‘Šï¼Œå¡”å¤«èŒ¨å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The if statement on Line 8, which tests the distance between the query and the hyperplane defined by the current best node, is executed next.",
            "zh": "æ¥ä¸‹æ¥æ‰§è¡Œç¬¬ 8 è¡Œçš„ if è¯­å¥ï¼Œè¯¥è¯­å¥æµ‹è¯•æŸ¥è¯¢ä¸å½“å‰æœ€ä½³èŠ‚ç‚¹å®šä¹‰çš„è¶…å¹³é¢ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "We return to these kinds of evaluation experiments in Chapter 9[533].",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬9ç« [533]ä¸­å›åˆ°è¿™äº›è¯„ä¼°å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "information gain ratio, 142, 174",
            "zh": "ä¿¡æ¯å¢ç›Šæ¯”ï¼Œ142,174"
        }
    },
    {
        "translation": {
            "en": "The distance between the query instance and the hyperplane defined by the node that indexes instance d21 is 0.75 (recall that because the hyperplane at this node is defined by the SPEED value of 6.75, we only compare this to the SPEED value of the query instance, 6.00).",
            "zh": "æŸ¥è¯¢å®ä¾‹ä¸ç´¢å¼•å®ä¾‹ d21 çš„èŠ‚ç‚¹å®šä¹‰çš„è¶…å¹³é¢ä¹‹é—´çš„è·ç¦»ä¸º 0.75ï¼ˆå›æƒ³ä¸€ä¸‹ï¼Œç”±äºæ­¤èŠ‚ç‚¹ä¸Šçš„è¶…å¹³é¢ç”± SPEED å€¼ 6.75 å®šä¹‰ï¼Œå› æ­¤æˆ‘ä»¬ä»…å°†å…¶ä¸æŸ¥è¯¢å®ä¾‹çš„ SPEED å€¼ 6.00 è¿›è¡Œæ¯”è¾ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The representational limitation of single-layer networks can be overcome by adding a single hidden layer to the network.",
            "zh": "å•å±‚ç½‘ç»œçš„è¡¨ç¤ºé™åˆ¶å¯ä»¥é€šè¿‡å‘ç½‘ç»œæ·»åŠ å•ä¸ªéšè—å±‚æ¥å…‹æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Keeping all the weights in a network small helps to keep a modelâ€™s predictions relatively stable with respect to small changes in the input: if a model has some relatively large weights, then the model can be very sensitive to small changes in features to which these weights are applied.",
            "zh": "å°†ç½‘ç»œä¸­çš„æ‰€æœ‰æƒé‡ä¿æŒåœ¨è¾ƒå°å€¼æœ‰åŠ©äºä½¿æ¨¡å‹çš„é¢„æµ‹ç›¸å¯¹äºè¾“å…¥ä¸­çš„å¾®å°å˜åŒ–ä¿æŒç›¸å¯¹ç¨³å®šï¼šå¦‚æœæ¨¡å‹å…·æœ‰ä¸€äº›ç›¸å¯¹è¾ƒå¤§çš„æƒé‡ï¼Œåˆ™æ¨¡å‹å¯ä»¥å¯¹åº”ç”¨è¿™äº›æƒé‡çš„ç‰¹å¾çš„å¾®å°å˜åŒ–éå¸¸æ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "In this evaluation, Edwin and four of his colleagues independently examined 200 galaxy images randomly selected from the final test set and classified them as belonging to one of the three galaxy types.",
            "zh": "åœ¨è¿™æ¬¡è¯„ä¼°ä¸­ï¼ŒåŸƒå¾·æ¸©å’Œä»–çš„å››ä½åŒäº‹ç‹¬ç«‹æ£€æŸ¥äº†ä»æœ€ç»ˆæµ‹è¯•é›†ä¸­éšæœºé€‰æ‹©çš„200å¼ æ˜Ÿç³»å›¾åƒï¼Œå¹¶å°†å®ƒä»¬å½’ç±»ä¸ºå±äºä¸‰ç§æ˜Ÿç³»ç±»å‹ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "density, 752, 753",
            "zh": "å¯†åº¦ï¼Œ 752ï¼Œ 753"
        }
    },
    {
        "translation": {
            "en": "For example, we might use a Euclidean distance metric to handle the continuous features in a dataset and the Jaccard similarity index to handle the categorical features.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»åº¦é‡æ¥å¤„ç†æ•°æ®é›†ä¸­çš„è¿ç»­ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨ Jaccard ç›¸ä¼¼æ€§æŒ‡æ•°æ¥å¤„ç†åˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Prediction Subject Details: Descriptive details of any aspect of the prediction subject.",
            "zh": "é¢„æµ‹ä¸»é¢˜è¯¦ç»†ä¿¡æ¯ï¼šé¢„æµ‹ä¸»é¢˜ä»»ä½•æ–¹é¢çš„æè¿°æ€§è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have already described the normal distribution, in some detail, in Section 3.2.1[61], so we wonâ€™t repeat that introduction here, but we will describe the other distributions in a little detail.",
            "zh": "æˆ‘ä»¬å·²ç»åœ¨ç¬¬ 3.2.1 èŠ‚[61]ä¸­è¯¦ç»†æè¿°äº†æ­£æ€åˆ†å¸ƒï¼Œå› æ­¤æˆ‘ä»¬ä¸ä¼šåœ¨è¿™é‡Œé‡å¤ä»‹ç»ï¼Œä½†æˆ‘ä»¬å°†ç¨å¾®è¯¦ç»†æè¿°å…¶ä»–åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "11. These images were generated using equal-width binning. However, the points discussed in the text are also relevant to equal-frequency binning.",
            "zh": "11. è¿™äº›å›¾åƒæ˜¯ä½¿ç”¨ç­‰å®½åˆ†ç®±ç”Ÿæˆçš„ã€‚ä½†æ˜¯ï¼Œæœ¬æ–‡ä¸­è®¨è®ºçš„è¦ç‚¹ä¹Ÿä¸ç­‰é¢‘åˆå¹¶æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "So if we have a training dataset of m examples in stochastic gradient descent, it would take m iterations to complete a single epoch, and this epoch would involve m weight updates.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªéšæœºæ¢¯åº¦ä¸‹é™ä¸­ m ä¸ªæ ·æœ¬çš„è®­ç»ƒæ•°æ®é›†ï¼Œåˆ™éœ€è¦ m æ¬¡è¿­ä»£æ‰èƒ½å®Œæˆä¸€ä¸ª epochï¼Œè€Œè¿™ä¸ª epoch å°†æ¶‰åŠ m ä¸ªæƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.2â€…â€…â€…(a)â€“(c) Histograms for the features from the AT ABT with irregular cardinality; (d)â€“(g) histograms for the features from the AT ABT that are potentially suffering from outliers.",
            "zh": "12.2 ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ å…·æœ‰ä¸è§„åˆ™åŸºæ•°çš„ AT ABT ç‰¹å¾çš„ç›´æ–¹å›¾;ï¼ˆdï¼‰â€“ï¼ˆgï¼‰ æ¥è‡ª AT ABT çš„å¯èƒ½å—åˆ°å¼‚å¸¸å€¼å½±å“çš„ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, the size of a joint probability distribution grows exponentially as the number of features and the number of values in the domains of the features grow.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œè”åˆæ¦‚ç‡åˆ†å¸ƒçš„å¤§å°éšç€ç‰¹å¾çš„æ•°é‡å’Œç‰¹å¾åŸŸä¸­çš„å€¼æ•°é‡çš„å¢é•¿è€Œå‘ˆæŒ‡æ•°å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure C.2",
            "zh": "å›¾ C.2"
        }
    },
    {
        "translation": {
            "en": "Most of the time the technical distinction between a metric and an index is not that important; we simply focus on choosing the right measure of similarity for the type of instances we are comparing.",
            "zh": "å¤§å¤šæ•°æ—¶å€™ï¼ŒæŒ‡æ ‡å’ŒæŒ‡æ•°ä¹‹é—´çš„æŠ€æœ¯åŒºåˆ«å¹¶ä¸é‚£ä¹ˆé‡è¦;æˆ‘ä»¬åªæ˜¯ä¸“æ³¨äºä¸ºæˆ‘ä»¬æ­£åœ¨æ¯”è¾ƒçš„å®ä¾‹ç±»å‹é€‰æ‹©æ­£ç¡®çš„ç›¸ä¼¼åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "type I errors, 538",
            "zh": "I ç±»é”™è¯¯ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "hold-out sampling, 541, 547",
            "zh": "ä¿æŒé‡‡æ ·ï¼Œ541,547"
        }
    },
    {
        "translation": {
            "en": "This distance is less than the current best-distance (in Figure 5.11(a)[203], the hyperplane defined by the node that indexes instance d21 intersects with the target hypersphere).",
            "zh": "è¯¥è·ç¦»å°äºå½“å‰æœ€ä½³è·ç¦»ï¼ˆåœ¨å›¾ 5.11ï¼ˆaï¼‰[203] ä¸­ï¼Œç”±ç´¢å¼•å®ä¾‹ d21 çš„èŠ‚ç‚¹å®šä¹‰çš„è¶…å¹³é¢ä¸ç›®æ ‡è¶…çƒç›¸äº¤ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If power station administrators could predict upcoming generator failures before the generators actually fail, they could improve power station safety and save money on maintenance.11 Using this dataset, we would like to train a model to distinguish between properly operating power station generators and faulty generators using the RPM and VIBRATION measurements.",
            "zh": "å¦‚æœå‘ç”µç«™ç®¡ç†å‘˜èƒ½å¤Ÿåœ¨å‘ç”µæœºå®é™…å‘ç”Ÿæ•…éšœä¹‹å‰é¢„æµ‹å³å°†åˆ°æ¥çš„å‘ç”µæœºæ•…éšœï¼Œä»–ä»¬å°±å¯ä»¥æé«˜å‘ç”µç«™çš„å®‰å…¨æ€§å¹¶èŠ‚çœç»´æŠ¤è´¹ç”¨.11 ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬æƒ³è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½¿ç”¨ RPM å’Œ VIBRATION æµ‹é‡æ¥åŒºåˆ†æ­£å¸¸è¿è¡Œçš„å‘ç”µç«™å‘ç”µæœºå’Œæ•…éšœå‘ç”µæœºã€‚"
        }
    },
    {
        "translation": {
            "en": "AVGBILL",
            "zh": "AVGBILLå…¬å¸"
        }
    },
    {
        "translation": {
            "en": "1.9â€…â€…â€…Exercises",
            "zh": "1.9 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "14. Sometimes the task of predicting a continuous target is referred to as a regression task.",
            "zh": "14. æœ‰æ—¶ï¼Œé¢„æµ‹è¿ç»­ç›®æ ‡çš„ä»»åŠ¡ç§°ä¸ºå›å½’ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D. 2016. Fundamentals of machine learning for neural machine translation. In Translating europe forum 2016: Focus on translation technologies. European Commission Directorate-General for Translation.",
            "zh": "å‡¯è±èµ«ï¼Œçº¦ç¿° D. 2016 å¹´ã€‚ç¥ç»æœºå™¨ç¿»è¯‘çš„æœºå™¨å­¦ä¹ åŸºç¡€ã€‚2016å¹´æ¬§æ´²ç¿»è¯‘è®ºå›ï¼šèšç„¦ç¿»è¯‘æŠ€æœ¯ã€‚æ¬§ç›Ÿå§”å‘˜ä¼šç¿»è¯‘æ€»å±€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The consultant generated the following data quality report from the ABT.",
            "zh": "é¡¾é—®ä»ABTç”Ÿæˆäº†ä»¥ä¸‹æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Parametric ReLU, 445",
            "zh": "å‚æ•°åŒ– ReLUï¼Œ 445"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the sum of squared error of the network for this example using the new weights, compared with using the original weights.",
            "zh": "ä¸ä½¿ç”¨åŸå§‹æƒé‡ç›¸æ¯”ï¼Œä½¿ç”¨æ–°æƒé‡è®¡ç®—æ­¤ç¤ºä¾‹ä¸­ç½‘ç»œå¹³æ–¹è¯¯å·®å’Œçš„å‡å°‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2.2â€ƒMeasuring Error",
            "zh": "7.2.2 æµ‹é‡è¯¯å·®"
        }
    },
    {
        "translation": {
            "en": "Îµ-greedy action selection policy, 656, 658, 674",
            "zh": "Îµè´ªå©ªçš„è¡ŒåŠ¨é€‰æ‹©ç­–ç•¥ï¼Œ656ã€658ã€674"
        }
    },
    {
        "translation": {
            "en": "A statistical significance test works by stating a null hypothesis and then determining whether there is enough evidence to accept or reject this hypothesis. This accept/reject decision is carried out in three steps:",
            "zh": "ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒçš„å·¥ä½œåŸç†æ˜¯é™ˆè¿°ä¸€ä¸ªåŸå‡è®¾ï¼Œç„¶åç¡®å®šæ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯æ®æ¥æ¥å—æˆ–æ‹’ç»è¯¥å‡è®¾ã€‚æ­¤æ¥å—/æ‹’ç»å†³å®šåˆ†ä¸‰ä¸ªæ­¥éª¤æ‰§è¡Œï¼š"
        }
    },
    {
        "translation": {
            "en": "We illustrate the calculation of Î´s for neurons in a softmax output layer using the mini-batch of examples listed in Table 8.13[464] and the network architecture shown in Figure 8.27[465].",
            "zh": "æˆ‘ä»¬ä½¿ç”¨è¡¨8.13[464]ä¸­åˆ—å‡ºçš„å°æ‰¹é‡ç¤ºä¾‹å’Œå›¾8.27[465]ä¸­æ‰€ç¤ºçš„ç½‘ç»œæ¶æ„æ¥è¯´æ˜softmaxè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„Î´sè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "By examining the data quality report, analytics practitioners can get a complete picture of the data that they will work with for the rest of an analytics project.",
            "zh": "é€šè¿‡æ£€æŸ¥æ•°æ®è´¨é‡æŠ¥å‘Šï¼Œåˆ†æä»ä¸šäººå‘˜å¯ä»¥å…¨é¢äº†è§£ä»–ä»¬å°†åœ¨åˆ†æé¡¹ç›®çš„å…¶ä½™éƒ¨åˆ†ä½¿ç”¨çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, extending a loan to a borrower who turns out to be bad is a very costly mistake.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œå‘è¢«è¯æ˜æ˜¯åçš„å€Ÿæ¬¾äººæä¾›è´·æ¬¾æ˜¯ä¸€ä¸ªéå¸¸æ˜‚è´µçš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrix is shown in Table 13.9[724].",
            "zh": "ç”±æ­¤äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.9[724]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Indeed, early stopping can also be understood as a regularization technique because it limits the number of updates to the weights in a model and by so doing keeps individual weights from getting too large.",
            "zh": "äº‹å®ä¸Šï¼Œæå‰åœæ­¢ä¹Ÿå¯ä»¥ç†è§£ä¸ºä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå› ä¸ºå®ƒé™åˆ¶äº†æ¨¡å‹ä¸­æƒé‡çš„æ›´æ–°æ¬¡æ•°ï¼Œä»è€Œé˜²æ­¢å•ä¸ªæƒé‡å˜å¾—å¤ªå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given the Markov assumption, we can write the probability of transitioning between two states",
            "zh": "ç»™å®šé©¬å°”å¯å¤«å‡è®¾ï¼Œæˆ‘ä»¬å¯ä»¥å†™å‡ºä¸¤ç§çŠ¶æ€ä¹‹é—´è½¬æ¢çš„æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "Dâ€…â€…â€…Introduction to Linear Algebra",
            "zh": "D çº¿æ€§ä»£æ•°å¯¼è®º"
        }
    },
    {
        "translation": {
            "en": "Markov process, 644, 679, 681",
            "zh": "é©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œ 644ï¼Œ 679ï¼Œ 681"
        }
    },
    {
        "translation": {
            "en": "In Section 7.3[319] we described how a multivariable linear regression model trained using gradient descent can be used to make predictions for continuous target features.",
            "zh": "åœ¨ç¬¬ 7.3 èŠ‚[319]ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•ä½¿ç”¨æ¢¯åº¦ä¸‹é™è®­ç»ƒçš„å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹è¿ç»­ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is difficult, however, because when we design descriptive features, we tend not to know exactly which ones will be predictive and which ones will not.",
            "zh": "ç„¶è€Œï¼Œè¿™å¾ˆå›°éš¾ï¼Œå› ä¸ºå½“æˆ‘ä»¬è®¾è®¡æè¿°æ€§ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬å¾€å¾€ä¸çŸ¥é“å“ªäº›æ˜¯é¢„æµ‹æ€§çš„ï¼Œå“ªäº›ä¸æ˜¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.4â€ƒSummary",
            "zh": "B.4 æ€»ç»“"
        }
    },
    {
        "translation": {
            "en": "Here, however, the focus is on covering a range of machine learning approaches, and again, evaluation is covered in detail.",
            "zh": "ç„¶è€Œï¼Œè¿™é‡Œçš„é‡ç‚¹æ˜¯æ¶µç›–ä¸€ç³»åˆ—æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¹¶ä¸”å†æ¬¡è¯¦ç»†ä»‹ç»äº†è¯„ä¼°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability functions for categorical features are referred to as probability mass functions, while probability functions for continuous features are known as probability density functions.",
            "zh": "åˆ†ç±»ç‰¹å¾çš„æ¦‚ç‡å‡½æ•°ç§°ä¸ºæ¦‚ç‡è´¨é‡å‡½æ•°ï¼Œè€Œè¿ç»­ç‰¹å¾çš„æ¦‚ç‡å‡½æ•°ç§°ä¸ºæ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For illustrative purposes, in this instance we assume that the output neuron uses a logistic activation function and expand the definition of âˆ‚ak/âˆ‚zk accordingly in the last two lines of the equation.",
            "zh": "ä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾è¾“å‡ºç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œå¹¶åœ¨ç­‰å¼çš„æœ€åä¸¤è¡Œç›¸åº”åœ°æ‰©å±• âˆ‚ak/âˆ‚zk çš„å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The key decision making component of a reinforcement learning agent is referred to as a policy, Ï€. A policy is simply a mapping from states to actions",
            "zh": "å¼ºåŒ–å­¦ä¹ ä»£ç†çš„å…³é”®å†³ç­–ç»„ä»¶è¢«ç§°ä¸ºç­–ç•¥ï¼ŒÏ€ã€‚ç­–ç•¥åªæ˜¯ä»çŠ¶æ€åˆ°æ“ä½œçš„æ˜ å°„"
        }
    },
    {
        "translation": {
            "en": "This for loop iterates through the examples in the batch, and for each example the Î´s for the neurons are calculated and backpropagated.",
            "zh": "æ­¤ for å¾ªç¯éå†æ‰¹å¤„ç†ä¸­çš„ç¤ºä¾‹ï¼Œå¹¶ä¸”å¯¹äºæ¯ä¸ªç¤ºä¾‹ï¼Œè®¡ç®—å¹¶åå‘ä¼ æ’­ç¥ç»å…ƒçš„ Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, an evenly connected network typically has a relatively short mixing time (for the size of the graph).",
            "zh": "æ­¤å¤–ï¼Œå‡åŒ€è¿æ¥çš„ç½‘ç»œé€šå¸¸å…·æœ‰ç›¸å¯¹è¾ƒçŸ­çš„æ··åˆæ—¶é—´ï¼ˆå¯¹äºå›¾å½¢çš„å¤§å°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is more interesting is that instances not actually on the decision boundary behave in a very regular way.",
            "zh": "æ›´æœ‰è¶£çš„æ˜¯ï¼Œå®é™…ä¸Šä¸åœ¨å†³ç­–è¾¹ç•Œä¸Šçš„å®ä¾‹ä»¥éå¸¸æœ‰è§„å¾‹çš„æ–¹å¼è¿è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(d) Striking a balance between overfitting and underfitting in trying to predict income from age.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ åœ¨è¯•å›¾ä»å¹´é¾„é¢„æµ‹æ”¶å…¥æ—¶ï¼Œåœ¨è¿‡åº¦æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆä¹‹é—´å–å¾—å¹³è¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neural networks with two hidden layers and using smooth activation functions can represent any function and generally can do so using fewer neurons than networks with only a single hidden layer.",
            "zh": "å…·æœ‰ä¸¤ä¸ªéšè—å±‚å¹¶ä½¿ç”¨å¹³æ»‘æ¿€æ´»å‡½æ•°çš„ç¥ç»ç½‘ç»œå¯ä»¥è¡¨ç¤ºä»»ä½•å‡½æ•°ï¼Œå¹¶ä¸”é€šå¸¸å¯ä»¥ä½¿ç”¨æ¯”åªæœ‰ä¸€ä¸ªéšè—å±‚çš„ç½‘ç»œæ›´å°‘çš„ç¥ç»å…ƒæ¥è¡¨ç¤ºä»»ä½•å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data Quality Issue",
            "zh": "æ•°æ®è´¨é‡é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4",
            "zh": "å›¾ 5.4"
        }
    },
    {
        "translation": {
            "en": "Artificial neural network models are composed of large numbers of simple processing units, called neurons, that typically are arranged into layers and are highly interconnected.",
            "zh": "äººå·¥ç¥ç»ç½‘ç»œæ¨¡å‹ç”±å¤§é‡ç§°ä¸ºç¥ç»å…ƒçš„ç®€å•å¤„ç†å•å…ƒç»„æˆï¼Œè¿™äº›å•å…ƒé€šå¸¸æ’åˆ—æˆå±‚å¹¶é«˜åº¦äº’è¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sample dataset used in this section has been purposefully selected to include just two descriptive features so that the visualizations in Figure 10.3[602] could be easily shown.",
            "zh": "æœ¬èŠ‚ä¸­ä½¿ç”¨çš„ç¤ºä¾‹æ•°æ®é›†ç»è¿‡ç‰¹æ„é€‰æ‹©ï¼Œä»…åŒ…å«ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œä»¥ä¾¿å¯ä»¥è½»æ¾æ˜¾ç¤ºå›¾ 10.3[602] ä¸­çš„å¯è§†åŒ–æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "To ensure a successful project outcome, we should inform the decisions that we make by",
            "zh": "ä¸ºç¡®ä¿é¡¹ç›®æˆåŠŸï¼Œæˆ‘ä»¬åº”è¯¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸ºæˆ‘ä»¬åšå‡ºçš„å†³ç­–æä¾›ä¿¡æ¯"
        }
    },
    {
        "translation": {
            "en": "For example, consider Table A.3[751], which shows a set of results for polls run shortly before the 2012 United States presidential election, in which Mitt Romney and Barack Obama were the front-runners.3 In the first poll in the table, from Pew Research, we can see that a sample of just 2,709 likely voters4 was used.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘è¡¨ A.3[751]ï¼Œå®ƒæ˜¾ç¤ºäº† 2012 å¹´ç¾å›½æ€»ç»Ÿå¤§é€‰å‰ä¸ä¹…è¿›è¡Œçš„ä¸€ç»„æ°‘æ„è°ƒæŸ¥ç»“æœï¼Œå…¶ä¸­ç±³ç‰¹Â·ç½—å§†å°¼å’Œå·´æ‹‰å…‹Â·å¥¥å·´é©¬æ˜¯é¢†è·‘è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "4,000",
            "zh": "4,000"
        }
    },
    {
        "translation": {
            "en": "If the value of the stability index is between 0.1 and 0.25, then some change has occurred and further investigation may be useful.",
            "zh": "å¦‚æœç¨³å®šæ€§æŒ‡æ•°çš„å€¼ä»‹äº 0.1 å’Œ 0.25 ä¹‹é—´ï¼Œåˆ™å‘ç”Ÿäº†ä¸€äº›å˜åŒ–ï¼Œè¿›ä¸€æ­¥è°ƒæŸ¥å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is illustrated in Figure 10.17[628].",
            "zh": "è¯¥è¿‡ç¨‹å¦‚å›¾10.17[628]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "For a data analytics practitioner, the key outcomes of the data exploration process (which straddles the Data Understanding and Data Preparation phases of CRISP-DM) are that the practitioner should",
            "zh": "å¯¹äºæ•°æ®åˆ†æä»ä¸šè€…æ¥è¯´ï¼Œæ•°æ®æ¢ç´¢è¿‡ç¨‹ï¼ˆè·¨è¶ŠCRISP-DMçš„æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µï¼‰çš„å…³é”®ç»“æœæ˜¯ï¼Œä»ä¸šè€…åº”è¯¥"
        }
    },
    {
        "translation": {
            "en": "The main advantages of normalizing descriptive feature values are that all weights become directly comparable with each other (as all descriptive features are on the same scale), and the behavior of the gradient descent algorithm used to train the model becomes much less sensitive to the learning rate and the initial weights.",
            "zh": "è§„èŒƒåŒ–æè¿°æ€§ç‰¹å¾å€¼çš„ä¸»è¦ä¼˜ç‚¹æ˜¯ï¼Œæ‰€æœ‰æƒé‡éƒ½å˜å¾—å½¼æ­¤ç›´æ¥å¯æ¯”ï¼ˆå› ä¸ºæ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½åœ¨åŒä¸€å°ºåº¦ä¸Šï¼‰ï¼Œå¹¶ä¸”ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ¢¯åº¦ä¸‹é™ç®—æ³•çš„è¡Œä¸ºå¯¹å­¦ä¹ ç‡å’Œåˆå§‹æƒé‡çš„æ•æ„Ÿåº¦å¤§å¤§é™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "For ease of reference each of the neurons in the network has been labeled: 1,2,3,4,5,6,7.",
            "zh": "ä¸ºäº†ä¾¿äºå‚è€ƒï¼Œç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½è¢«æ ‡è®°ä¸ºï¼š1,2,3,4,5,6,7ã€‚"
        }
    },
    {
        "translation": {
            "en": "20. Remember that for problems with more than two descriptive features, the decision boundary is a hyperplane rather than a line.",
            "zh": "20. è¯·è®°ä½ï¼Œå¯¹äºå…·æœ‰ä¸¤ä¸ªä»¥ä¸Šæè¿°æ€§ç‰¹å¾çš„é—®é¢˜ï¼Œå†³ç­–è¾¹ç•Œæ˜¯ä¸€ä¸ªè¶…å¹³é¢è€Œä¸æ˜¯ä¸€æ¡çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, k-means is a special case of the Gaussian mixture model (Murphy, 2012) approach to clustering (assuming spherical distributions), which in turn has been extended into model-based clustering (Scrucca et al., 2016) algorithms, all of which can be very effective.",
            "zh": "ä¾‹å¦‚ï¼Œk-meansæ˜¯é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆMurphyï¼Œ2012ï¼‰èšç±»æ–¹æ³•ï¼ˆå‡è®¾çƒé¢åˆ†å¸ƒï¼‰çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œè€Œè¯¥æ–¹æ³•åˆå·²æ‰©å±•åˆ°åŸºäºæ¨¡å‹çš„èšç±»ï¼ˆScrucca et al.ï¼Œ2016ï¼‰ç®—æ³•ä¸­ï¼Œæ‰€æœ‰è¿™äº›éƒ½éå¸¸æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "These weight matrices are organized so that each row contains the weights for the connections coming into one neuron.",
            "zh": "è¿™äº›æƒé‡çŸ©é˜µè¢«ç»„ç»‡èµ·æ¥ï¼Œä»¥ä¾¿æ¯ä¸€è¡Œéƒ½åŒ…å«è¿›å…¥ä¸€ä¸ªç¥ç»å…ƒçš„è¿æ¥çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "condensed nearest neighbor, 233",
            "zh": "å‡èšçš„æœ€è¿‘é‚»ï¼Œ233"
        }
    },
    {
        "translation": {
            "en": "For many years the logistic function was the default activation function used in neural networks.",
            "zh": "å¤šå¹´æ¥ï¼Œé€»è¾‘å‡½æ•°æ˜¯ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨çš„é»˜è®¤æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantage of using a programming language for predictive data analytics projects is that it gives the data analyst huge flexibility.",
            "zh": "åœ¨é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä¸­ä½¿ç”¨ç¼–ç¨‹è¯­è¨€çš„ä¼˜åŠ¿åœ¨äºï¼Œå®ƒä¸ºæ•°æ®åˆ†æå¸ˆæä¾›äº†å·¨å¤§çš„çµæ´»æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "IIIâ€…â€…â€…BEYOND PREDICTION",
            "zh": "ä¸‰ã€è¶…è¶Šé¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "The third consideration is the longevity of any feature we design.",
            "zh": "ç¬¬ä¸‰ä¸ªè€ƒè™‘å› ç´ æ˜¯æˆ‘ä»¬è®¾è®¡çš„ä»»ä½•åŠŸèƒ½çš„å¯¿å‘½ã€‚"
        }
    },
    {
        "translation": {
            "en": "; ACCIDENT REGION: REGION.",
            "zh": ";äº‹æ•…åŒºåŸŸï¼šåŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "They did spend some time, however, discussing the AVGOVERBUNDLEMINS.",
            "zh": "ç„¶è€Œï¼Œä»–ä»¬ç¡®å®èŠ±äº†ä¸€äº›æ—¶é—´è®¨è®º AVGOVERBUNDLEMINSã€‚"
        }
    },
    {
        "translation": {
            "en": "The absence of a large bar at âˆ’ 99,999 in Figure 3.1(c)[58] confirms that there are not multiple occurrences of this value.",
            "zh": "å›¾3.1ï¼ˆcï¼‰[58]ä¸­æ²¡æœ‰âˆ’99,999å¤„çš„å¤§æŸ±çº¿ï¼Œè¿™è¯å®äº†è¯¥å€¼æ²¡æœ‰å¤šæ¬¡å‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3.5â€ƒA Worked Example: Using Backpropagation to Train a Feedforward Network for a Regression Task",
            "zh": "8.3.5 å·¥ä½œç¤ºä¾‹ï¼šä½¿ç”¨åå‘ä¼ æ’­ä¸ºå›å½’ä»»åŠ¡è®­ç»ƒå‰é¦ˆç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "0.00",
            "zh": "0.00"
        }
    },
    {
        "translation": {
            "en": "First the expected return can be written as a sum across the expected returns of all possible actions at+1 that could be taken in state st+1",
            "zh": "é¦–å…ˆï¼Œé¢„æœŸå›æŠ¥å¯ä»¥å†™æˆåœ¨çŠ¶æ€ st+1 ä¸­å¯èƒ½é‡‡å–çš„æ‰€æœ‰ +1 å¤„å¯èƒ½æ“ä½œçš„é¢„æœŸå›æŠ¥çš„æ€»å’Œ"
        }
    },
    {
        "translation": {
            "en": "Following these explanations we present a worked example to show how the backpropagation and gradient descent algorithm can be used in partnership to train a neural network with hidden layers.",
            "zh": "æ ¹æ®è¿™äº›è§£é‡Šï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå·¥ä½œç¤ºä¾‹æ¥å±•ç¤ºå¦‚ä½•ååŒä½¿ç”¨åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™ç®—æ³•æ¥è®­ç»ƒå…·æœ‰éšè—å±‚çš„ç¥ç»ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.8[613] shows each of the clusterings found in the mobile phone customer dataset for values of k in [2,9] using k-means clustering, and their corresponding silhouettes (Figure 10.8(g)[613]).",
            "zh": "å›¾10.8[613]æ˜¾ç¤ºäº†ä½¿ç”¨k-meansèšç±»åœ¨[2,9]ä¸­kå€¼çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­å‘ç°çš„æ¯ä¸ªèšç±»ï¼Œä»¥åŠå®ƒä»¬ç›¸åº”çš„è½®å»“[å›¾10.8ï¼ˆgï¼‰[613]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The relative frequency of an event is calculated as how often the event happened divided by how often it could have happened.",
            "zh": "äº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡è®¡ç®—ä¸ºäº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡é™¤ä»¥äº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "linearly separable, 338, 354, 365, 396",
            "zh": "çº¿æ€§å¯åˆ†ç¦»ï¼Œ 338ï¼Œ 354ï¼Œ 365ï¼Œ 396"
        }
    },
    {
        "translation": {
            "en": "where the counts come from Table 9.21[581]. The stability index for New Sample 2, calculated in the same way, is 0.331. This suggests that at the point in time at which New Sample 1 was collected, the outputs produced by the model followed much the same distribution as when the model was originally evaluated, but that when New Sample 2 was collected, the distribution of the outputs produced by the model had changed significantly.",
            "zh": "å…¶ä¸­è®¡æ•°æ¥è‡ªè¡¨9.21[581]ã€‚ä»¥åŒæ ·çš„æ–¹å¼è®¡ç®—ï¼Œæ–°æ ·æœ¬ 2 çš„ç¨³å®šæ€§æŒ‡æ•°ä¸º 0.331ã€‚è¿™è¡¨æ˜ï¼Œåœ¨æ”¶é›†æ–°æ ·æœ¬ 1 çš„æ—¶é—´ç‚¹ï¼Œæ¨¡å‹äº§ç”Ÿçš„è¾“å‡ºä¸æœ€åˆè¯„ä¼°æ¨¡å‹æ—¶çš„åˆ†å¸ƒå¤§è‡´ç›¸åŒï¼Œä½†æ˜¯åœ¨æ”¶é›†æ–°æ ·æœ¬ 2 æ—¶ï¼Œæ¨¡å‹äº§ç”Ÿçš„è¾“å‡ºåˆ†å¸ƒå‘ç”Ÿäº†é‡å¤§å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "With the addition of more neurons in each layer, the network could represent a function that maps to multiple disconnected convex regions and refines the shapes of these regions.",
            "zh": "éšç€æ¯ä¸€å±‚ä¸­å¢åŠ æ›´å¤šçš„ç¥ç»å…ƒï¼Œè¯¥ç½‘ç»œå¯ä»¥è¡¨ç¤ºä¸€ä¸ªæ˜ å°„åˆ°å¤šä¸ªä¸ç›¸è¿çš„å‡¸åŒºåŸŸå¹¶ç»†åŒ–è¿™äº›åŒºåŸŸå½¢çŠ¶çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices for the models after feature selection.",
            "zh": "ç‰¹å¾é€‰æ‹©åæ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "3. Termination Condition: This component determines when the search process should stop. Typically we stop when the subset selection component indicates that none of the feature subsets (search states) that can be generated from the current feature subset is more desirable than the current subset. Once the search process is terminated, the features in the dataset that are not members of the selected feature subset are pruned from the dataset before the prediction model is induced.",
            "zh": "3. ç»ˆæ­¢æ¡ä»¶ï¼šæ­¤ç»„ä»¶ç¡®å®šæœç´¢è¿‡ç¨‹ä½•æ—¶åœæ­¢ã€‚é€šå¸¸ï¼Œå½“å­é›†é€‰æ‹©ç»„ä»¶æŒ‡ç¤ºå¯ä»¥ä»å½“å‰ç‰¹å¾å­é›†ç”Ÿæˆçš„ç‰¹å¾å­é›†ï¼ˆæœç´¢çŠ¶æ€ï¼‰éƒ½ä¸æ¯”å½“å‰å­é›†æ›´ç†æƒ³æ—¶ï¼Œæˆ‘ä»¬ä¼šåœæ­¢ã€‚æœç´¢è¿‡ç¨‹ç»ˆæ­¢åï¼Œåœ¨è¯±å¯¼é¢„æµ‹æ¨¡å‹ä¹‹å‰ï¼Œå°†ä»æ•°æ®é›†ä¸­ä¿®å‰ªæ•°æ®é›†ä¸­ä¸å±äºæ‰€é€‰ç‰¹å¾å­é›†æˆå‘˜çš„è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.7â€ƒPredictive Data Analytics Tools",
            "zh": "1.7 é¢„æµ‹æ•°æ®åˆ†æå·¥å…·"
        }
    },
    {
        "translation": {
            "en": "To understand the characteristics of a continuous feature, there are two things that are important to measure: the central tendency of the feature and the variation within the feature. These are the basic building blocks of everything else that will follow, so it is important to fully understand them.",
            "zh": "è¦ç†è§£è¿ç»­ç‰¹å¾çš„ç‰¹å¾ï¼Œæœ‰ä¸¤ä»¶äº‹å¾ˆé‡è¦ï¼šç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿å’Œç‰¹å¾å†…çš„å˜åŒ–ã€‚è¿™äº›æ˜¯æ¥ä¸‹æ¥å…¶ä»–ä¸€åˆ‡çš„åŸºæœ¬æ„å»ºå—ï¼Œå› æ­¤å……åˆ†ç†è§£å®ƒä»¬å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why the activations of all neurons are recorded during the forward pass.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨å‰å‘ä¼ é€’æœŸé—´è®°å½•æ‰€æœ‰ç¥ç»å…ƒçš„æ¿€æ´»çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov chain Monte Carlo, 298, 733",
            "zh": "é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼Œ 298ï¼Œ 733"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38[504] is based on a figure from Kelleher (2016).",
            "zh": "å›¾8.38[504]åŸºäºKelleherï¼ˆ2016ï¼‰çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a bag-of-words representation, the descriptive features that describe a document (in our case, an email) each represent how many times a particular word occurs in the document.",
            "zh": "åœ¨è¯è¢‹è¡¨ç¤ºä¸­ï¼Œæè¿°æ–‡æ¡£ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸ºç”µå­é‚®ä»¶ï¼‰çš„æè¿°æ€§ç‰¹å¾åˆ†åˆ«è¡¨ç¤ºç‰¹å®šå•è¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is done by organizing neurons into groups in which all the neurons in the group apply the same filter to their inputs.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†ç¥ç»å…ƒç»„ç»‡æˆç»„æ¥å®Œæˆçš„ï¼Œå…¶ä¸­ç»„ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒå¯¹å…¶è¾“å…¥åº”ç”¨ç›¸åŒçš„è¿‡æ»¤å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The examples throughout this book so far have focused on supervised machine learning methods for building predictive models.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæœ¬ä¹¦ä¸­çš„ç¤ºä¾‹ä¸»è¦é›†ä¸­åœ¨ç”¨äºæ„å»ºé¢„æµ‹æ¨¡å‹çš„ç›‘ç£å¼æœºå™¨å­¦ä¹ æ–¹æ³•ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Well-designed evaluation experiments are the best way to find this balance (we discuss evaluation in detail in Chapter 9[533]).",
            "zh": "ç²¾å¿ƒè®¾è®¡çš„è¯„ä¼°å®éªŒæ˜¯æ‰¾åˆ°è¿™ç§å¹³è¡¡çš„æœ€ä½³æ–¹å¼ï¼ˆæˆ‘ä»¬å°†åœ¨ç¬¬9ç« [533]ä¸­è¯¦ç»†è®¨è®ºè¯„ä¼°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Natural language is an example of this type of data: it is naturally sequential, one word follows the other, each sentence may have a different number of words (varying length), and it contains long-distance dependencies between elements.",
            "zh": "è‡ªç„¶è¯­è¨€æ˜¯è¿™ç±»æ•°æ®çš„ä¸€ä¸ªä¾‹å­ï¼šå®ƒæ˜¯è‡ªç„¶é¡ºåºçš„ï¼Œä¸€ä¸ªè¯è·Ÿç€å¦ä¸€ä¸ªè¯ï¼Œæ¯ä¸ªå¥å­å¯èƒ½æœ‰ä¸åŒæ•°é‡çš„å•è¯ï¼ˆä¸åŒçš„é•¿åº¦ï¼‰ï¼Œå¹¶ä¸”å®ƒåŒ…å«å…ƒç´ ä¹‹é—´çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This often occurs in document classification problems, when a bag-of-words representation is used to represent documents as the frequency of occurrence of each word in a dictionary (the eponymous bag-of-words).",
            "zh": "è¿™é€šå¸¸å‘ç”Ÿåœ¨æ–‡æ¡£åˆ†ç±»é—®é¢˜ä¸­ï¼Œå½“ä½¿ç”¨è¯è¢‹è¡¨ç¤ºæ³•å°†æ–‡æ¡£è¡¨ç¤ºä¸ºå­—å…¸ä¸­æ¯ä¸ªå•è¯çš„å‡ºç°é¢‘ç‡ï¼ˆåŒåè¯è¢‹ï¼‰æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.8[718] shows small multiple box plots divided by galaxy type for a selection of features from the ABT.",
            "zh": "å›¾13.8[718]æ˜¾ç¤ºäº†æŒ‰æ˜Ÿç³»ç±»å‹åˆ’åˆ†çš„å°å¤šç®±å½¢å›¾ï¼Œç”¨äºABTä¸­çš„ä¸€äº›ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7(b)[194] shows the decision boundary for a weighted k nearest neighbor model for the dataset in Table 5.4[191] with k = 21 (the size of the dataset) and weights computed using the reciprocal of the squared distance.",
            "zh": "å›¾5.7ï¼ˆbï¼‰[194]æ˜¾ç¤ºäº†è¡¨5.4[191]ä¸­æ•°æ®é›†çš„åŠ æƒkæœ€è¿‘é‚»æ¨¡å‹çš„å†³ç­–è¾¹ç•Œï¼Œå…¶ä¸­k = 21ï¼ˆæ•°æ®é›†çš„å¤§å°ï¼‰å’Œä½¿ç”¨å¹³æ–¹è·ç¦»çš„å€’æ•°è®¡ç®—çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "unsupervised learning, xvi, 5, 20, 597, 598, 628, 674, 740",
            "zh": "æ— ç›‘ç£å­¦ä¹ ï¼Œ xviï¼Œ 5ï¼Œ 20ï¼Œ 597ï¼Œ 598ï¼Œ 628ï¼Œ 674ï¼Œ 740"
        }
    },
    {
        "translation": {
            "en": "where ai and bi are values of features a and b for the ith instance in a dataset, and Ä and b are the sample means of features a and b. Covariance values fall into the range [âˆ’âˆ,âˆ] where negative values indicate a negative relationship, positive values indicate a positive relationship, and values near zero indicate that there is little or no relationship between the features.",
            "zh": "å…¶ä¸­ ai å’Œ bi æ˜¯æ•°æ®é›†ä¸­ç¬¬ i ä¸ªå®ä¾‹çš„ç‰¹å¾ a å’Œ b çš„å€¼ï¼ŒÄ å’Œ b æ˜¯ç‰¹å¾ A å’Œ B çš„æ ·æœ¬å‡å€¼ã€‚åæ–¹å·®å€¼å±äº [âˆ’âˆï¼Œâˆ] èŒƒå›´ï¼Œå…¶ä¸­è´Ÿå€¼è¡¨ç¤ºè´Ÿç›¸å…³å…³ç³»ï¼Œæ­£å€¼è¡¨ç¤ºæ­£ç›¸å…³å…³ç³»ï¼Œæ¥è¿‘é›¶çš„å€¼è¡¨ç¤ºç‰¹å¾ä¹‹é—´å‡ ä¹æ²¡æœ‰å…³ç³»æˆ–æ²¡æœ‰å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.4[543] illustrates how the available data is split during the k-fold cross validation process.",
            "zh": "å›¾ 9.4[543] è¯´æ˜äº†åœ¨ k æŠ˜äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­å¦‚ä½•æ‹†åˆ†å¯ç”¨æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Figure 3.14[92] to compare these two approaches to binning, we can see that by varying the width of the bins, equal-frequency binning uses bins to more accurately model the heavily populated areas of the range of values the continuous feature can take. The downside to this is that the resulting bins can appear slightly less intuitive because they are of varying sizes.",
            "zh": "ä½¿ç”¨å›¾ 3.14[92] æ¥æ¯”è¾ƒè¿™ä¸¤ç§åˆ†ç®±æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡æ”¹å˜æ¡æŸ±çš„å®½åº¦ï¼Œç­‰é¢‘åˆ†ç®±ä½¿ç”¨æ¡æŸ±æ¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿè¿ç»­ç‰¹å¾å¯ä»¥é‡‡ç”¨çš„å€¼èŒƒå›´çš„äººå£ç¨ å¯†åŒºåŸŸã€‚è¿™æ ·åšçš„ç¼ºç‚¹æ˜¯ï¼Œç”Ÿæˆçš„ç®±å¯èƒ½çœ‹èµ·æ¥ä¸å¤ªç›´è§‚ï¼Œå› ä¸ºå®ƒä»¬çš„å¤§å°å„ä¸ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10(b)[201] illustrates the location of the query in the feature space (the ?",
            "zh": "å›¾ 5.10ï¼ˆbï¼‰[201] è¯´æ˜äº†æŸ¥è¯¢åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„ä½ç½®ï¼ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The distinction between stochastic gradient descent and batch gradient descent can be used to clarify the meanings of two related terms often used in neural network training: epoch and iteration.",
            "zh": "éšæœºæ¢¯åº¦ä¸‹é™å’Œæ‰¹é‡æ¢¯åº¦ä¸‹é™ä¹‹é—´çš„åŒºåˆ«å¯ä»¥ç”¨æ¥é˜æ˜ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ç»å¸¸ä½¿ç”¨çš„ä¸¤ä¸ªç›¸å…³æœ¯è¯­çš„å«ä¹‰ï¼šçºªå…ƒå’Œè¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "15. It is worth noting that the temporal-difference learning approach to reinforcement learning takes a very similar approach to the gradient descent algorithm described in Section 7.3[319].",
            "zh": "15. å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¼ºåŒ–å­¦ä¹ çš„æ—¶é—´å·®åˆ†å­¦ä¹ æ–¹æ³•ä¸ç¬¬ 7.3 èŠ‚[319]ä¸­æè¿°çš„æ¢¯åº¦ä¸‹é™ç®—æ³•éå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Textual: Free-form, usually short, text data (e.g., name, address)",
            "zh": "æ–‡æœ¬ï¼šè‡ªç”±æ ¼å¼ï¼Œé€šå¸¸å¾ˆçŸ­çš„æ–‡æœ¬æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œå§“åã€åœ°å€ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Table A.1",
            "zh": "è¡¨A.1"
        }
    },
    {
        "translation": {
            "en": "He would also like to thank his parents (John and Betty) and his sisters (Elizabeth and Marianne), without whose support he would not have gotten past long division and basic spelling.",
            "zh": "ä»–è¿˜è¦æ„Ÿè°¢ä»–çš„çˆ¶æ¯ï¼ˆçº¦ç¿°å’Œè´è’‚ï¼‰å’Œä»–çš„å§å¦¹ï¼ˆä¼Šä¸½èç™½å’Œç›ä¸½å®‰ï¼‰ï¼Œæ²¡æœ‰ä»–ä»¬çš„æ”¯æŒï¼Œä»–å°†æ— æ³•é€šè¿‡é•¿é™¤æ³•å’ŒåŸºæœ¬æ‹¼å†™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Alternatively, we may be dealing with a dataset where there is covariance between the descriptive features, in which case we should consider using the Mahalanobis distance as our measure of similarity.",
            "zh": "æˆ–è€…ï¼Œæˆ‘ä»¬å¯èƒ½æ­£åœ¨å¤„ç†æè¿°æ€§ç‰¹å¾ä¹‹é—´å­˜åœ¨åæ–¹å·®çš„æ•°æ®é›†ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘ä½¿ç”¨é©¬æ°è·ç¦»ä½œä¸ºç›¸ä¼¼æ€§çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In temporal-difference learning, the relevant value in the table is updated after each action that the agent takes.",
            "zh": "åœ¨æ—¶é—´å·®åˆ†å­¦ä¹ ä¸­ï¼Œè¡¨ä¸­çš„ç›¸å…³å€¼åœ¨æ™ºèƒ½ä½“æ‰§è¡Œçš„æ¯ä¸ªæ“ä½œåéƒ½ä¼šæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Deep learning models can have millions of parameters, and this complexity makes them prone to overfitting. Two of the most commonly used methods to avoid overfitting in neural networks are early stopping and dropout (Srivastava et al., 2014).",
            "zh": "æ·±åº¦å­¦ä¹ æ¨¡å‹å¯èƒ½æœ‰æ•°ç™¾ä¸‡ä¸ªå‚æ•°ï¼Œè¿™ç§å¤æ‚æ€§ä½¿å®ƒä»¬å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆã€‚é¿å…ç¥ç»ç½‘ç»œè¿‡æ‹Ÿåˆçš„ä¸¤ç§æœ€å¸¸ç”¨æ–¹æ³•æ˜¯æ—©æœŸåœæ­¢å’Œé€€å‡ºï¼ˆSrivastavaç­‰äººï¼Œ2014ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "These measures place less emphasis on the performance of the model on the negative target level.",
            "zh": "è¿™äº›æªæ–½ä¸å¤ªå¼ºè°ƒæ¨¡å‹åœ¨è´Ÿç›®æ ‡æ°´å¹³ä¸Šçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bishop, Christopher M. 1996. Neural networks for pattern recognition. Oxford University Press.",
            "zh": "ä¸»æ•™ï¼Œå…‹é‡Œæ–¯æ‰˜å¼— M. 1996 å¹´ã€‚ç”¨äºæ¨¡å¼è¯†åˆ«çš„ç¥ç»ç½‘ç»œã€‚ç‰›æ´¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in data analytics a prediction is the assignment of a value to any unknown variable.",
            "zh": "ç„¶è€Œï¼Œåœ¨æ•°æ®åˆ†æä¸­ï¼Œé¢„æµ‹æ˜¯å°†å€¼åˆ†é…ç»™ä»»ä½•æœªçŸ¥å˜é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We should also examine the minimum and maximum values to understand the range that is possible for each feature.",
            "zh": "æˆ‘ä»¬è¿˜åº”è¯¥æ£€æŸ¥æœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œä»¥äº†è§£æ¯ä¸ªç‰¹å¾çš„å¯èƒ½èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.16â€…â€…â€…An image of the digit 2 and reconstructions of this image by the auto-encoder after various amounts of network training. The pixel values of the reconstructed images are shown alongside the images, as is the reconstruction error calculated by comparing these to the pixel values of the original image.",
            "zh": "10.16 æ•°å­— 2 çš„å›¾åƒï¼Œä»¥åŠè‡ªåŠ¨ç¼–ç å™¨åœ¨ç»è¿‡ä¸åŒæ•°é‡çš„ç½‘ç»œè®­ç»ƒåå¯¹è¯¥å›¾åƒçš„é‡å»ºã€‚é‡å»ºå›¾åƒçš„åƒç´ å€¼ä¸å›¾åƒä¸€èµ·æ˜¾ç¤ºï¼Œé€šè¿‡å°†è¿™äº›åƒç´ å€¼ä¸åŸå§‹å›¾åƒçš„åƒç´ å€¼è¿›è¡Œæ¯”è¾ƒè®¡ç®—çš„é‡å»ºè¯¯å·®ä¹Ÿæ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "where levels(t) is the set of levels that the target feature, t, can assume; |levels(t)| is the size of this set; and recalll refers to the recall achieved by a model for level l.9 The average class accuracies for the model performances shown in Tables 9.5[551] and 9.6[551] are and respectively, which would indicate that the second model is actually a better performer than the first.",
            "zh": "å…¶ä¸­ levelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡è¦ç´  t å¯ä»¥å‡å®šçš„ä¸€ç»„çº§åˆ«; |levelsï¼ˆtï¼‰|æ˜¯æ­¤é›†åˆçš„å¤§å°;9 è¡¨ 9.5[551] å’Œ 9.6[551] æ‰€ç¤ºæ¨¡å‹æ€§èƒ½çš„å¹³å‡ç­‰çº§ç²¾åº¦åˆ†åˆ«ä¸º å’Œ ï¼Œè¿™è¡¨æ˜ç¬¬äºŒä¸ªæ¨¡å‹å®é™…ä¸Šæ¯”ç¬¬ä¸€ä¸ªæ¨¡å‹è¡¨ç°æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "complete linkage: the distance between the most dissimilar instances in two clusters is used as the overall distance between the clusters;",
            "zh": "å®Œå…¨è”åŠ¨ï¼šä»¥ä¸¤ä¸ªé›†ç¾¤ä¸­æœ€ä¸ç›¸å¹²çš„å®ä¾‹ä¹‹é—´çš„è·ç¦»ä½œä¸ºé›†ç¾¤ä¹‹é—´çš„æ€»è·ç¦»;"
        }
    },
    {
        "translation": {
            "en": "For a first example of how to evaluate the performance of a predictive model, let us assume that we are dealing with an email classification problem with a binary categorical target feature distinguishing between spam and ham emails.",
            "zh": "å¯¹äºå¦‚ä½•è¯„ä¼°é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„ç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼Œè®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬æ­£åœ¨å¤„ç†ä¸€ä¸ªç”µå­é‚®ä»¶åˆ†ç±»é—®é¢˜ï¼Œè¯¥é—®é¢˜å…·æœ‰åŒºåˆ†åƒåœ¾é‚®ä»¶å’Œä¸šä½™ç”µå­é‚®ä»¶çš„äºŒå…ƒåˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The optimism associated with finding multimodally distributed data stems from the fact that, if we are lucky, the separate peaks in the distribution will be associated with the different target levels we are trying to predict.",
            "zh": "ä¸å¯»æ‰¾å¤šæ¨¡æ€åˆ†å¸ƒæ•°æ®ç›¸å…³çš„ä¹è§‚æƒ…ç»ªæºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å¦‚æœæˆ‘ä»¬å¹¸è¿çš„è¯ï¼Œåˆ†å¸ƒä¸­çš„å•ç‹¬å³°å€¼å°†ä¸æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„ä¸åŒç›®æ ‡æ°´å¹³ç›¸å…³è”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Neural network models are especially effective in this use case, and the chapter presented an example of using an auto-encoder to learn a feature representation that could be used by a supervised machine learning model.",
            "zh": "ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨æ­¤ç”¨ä¾‹ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œæœ¬ç« ä»‹ç»äº†ä¸€ä¸ªä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨æ¥å­¦ä¹ å¯ç”±ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹ä½¿ç”¨çš„ç‰¹å¾è¡¨ç¤ºçš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bache, K., and M. Lichman. 2013. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml.",
            "zh": "Bacheï¼Œ K. å’Œ M. Lichmanã€‚2013. UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ã€‚http://archive.ics.uci.edu/mlã€‚"
        }
    },
    {
        "translation": {
            "en": "As is always the case when a committee is working together, however, steps should be taken to guard against group think.",
            "zh": "ç„¶è€Œï¼Œä¸å§”å‘˜ä¼šä¸€èµ·å·¥ä½œæ—¶çš„æƒ…å†µä¸€æ ·ï¼Œåº”è¯¥é‡‡å–æªæ–½é˜²æ­¢ç¾¤ä½“æ€ç»´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that there are three target levels, a prediction probability of approximately 0.333 indicates that the prediction made by the model is really quite unsure.",
            "zh": "å‡è®¾æœ‰ä¸‰ä¸ªç›®æ ‡æ°´å¹³ï¼Œé¢„æµ‹æ¦‚ç‡çº¦ä¸º 0.333ï¼Œè¡¨æ˜æ¨¡å‹åšå‡ºçš„é¢„æµ‹ç¡®å®éå¸¸ä¸ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "The 7 and 8 partitions, however, contain instances with a mixture of target feature levels, so the algorithm needs to continue splitting these partitions.",
            "zh": "ä½†æ˜¯ï¼Œ7 å’Œ 8 åˆ†åŒºåŒ…å«æ··åˆäº†ç›®æ ‡åŠŸèƒ½çº§åˆ«çš„å®ä¾‹ï¼Œå› æ­¤ç®—æ³•éœ€è¦ç»§ç»­æ‹†åˆ†è¿™äº›åˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "The XOR example shows that a network with a single hidden layer can represent a non-linearly separable function.",
            "zh": "XOR ç¤ºä¾‹è¡¨æ˜ï¼Œå…·æœ‰å•ä¸ªéšè—å±‚çš„ç½‘ç»œå¯ä»¥è¡¨ç¤ºéçº¿æ€§å¯åˆ†å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.3â€…â€…â€…The probabilities needed by a naive Bayes prediction model, calculated from the data in Table 6.2[263].",
            "zh": "6.3 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.2[263]ä¸­çš„æ•°æ®è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "It is difficult to provide a detailed worked example of the DQN algorithm because the number of weights to be learned and steps required for anything interesting is too large for clear presentation.",
            "zh": "å¾ˆéš¾æä¾› DQN ç®—æ³•çš„è¯¦ç»†å·¥ä½œç¤ºä¾‹ï¼Œå› ä¸ºè¦å­¦ä¹ çš„æƒé‡æ•°é‡å’Œä»»ä½•æœ‰è¶£çš„ä¸œè¥¿æ‰€éœ€çš„æ­¥éª¤éƒ½å¤ªå¤§ï¼Œæ— æ³•æ¸…æ™°åœ°å‘ˆç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. This is not as extreme an assumption as it might sound, as cards in Blackjack are usually dealt from a shoe containing 6 to 8 standard playing card decks.",
            "zh": "9. è¿™å¹¶ä¸åƒå¬èµ·æ¥é‚£ä¹ˆæç«¯ï¼Œå› ä¸ºäºŒåä¸€ç‚¹ä¸­çš„ç‰Œé€šå¸¸æ˜¯ä»åŒ…å« 6 åˆ° 8 å‰¯æ ‡å‡†æ‰‘å…‹ç‰Œçš„é‹å­ä¸­å‘ç‰Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the feature occurs in the neuronâ€™s local receptive field, then the neuron will have a high activation.",
            "zh": "å¦‚æœè¯¥ç‰¹å¾å‘ç”Ÿåœ¨ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ä¸­ï¼Œåˆ™ç¥ç»å…ƒå°†å…·æœ‰é«˜åº¦æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use bold notation to distinguish between a probability distribution, P(), and a probability function, P().",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ç²—ä½“è¡¨ç¤ºæ³•æ¥åŒºåˆ†æ¦‚ç‡åˆ†å¸ƒ Pï¼ˆï¼‰ å’Œæ¦‚ç‡å‡½æ•° Pï¼ˆï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, they designed a model of the neuron that would take in multiple inputs and then output either a high signal, a 1, or a low signal, a 0.",
            "zh": "å› æ­¤ï¼Œä»–ä»¬è®¾è®¡äº†ä¸€ä¸ªç¥ç»å…ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†æ¥å—å¤šä¸ªè¾“å…¥ï¼Œç„¶åè¾“å‡ºé«˜ä¿¡å·ï¼ˆ1ï¼‰æˆ–ä½ä¿¡å·ï¼ˆ0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Brian would like to thank his parents (Liam and RoisÃ­n) and family for all of their support on this book (and everything else). He would also like to thank all his colleagues and students at University College Dublin (and previously at the Dublin Institute of Technology)â€”especially PÃ¡draig Cunningham and Sarah Jane Delany, who opened his eyes to machine learning.",
            "zh": "å¸ƒè±æ©è¦æ„Ÿè°¢ä»–çš„çˆ¶æ¯ï¼ˆåˆ©äºšå§†å’Œç½—ä¼Šè¾›ï¼‰å’Œå®¶äººå¯¹è¿™æœ¬ä¹¦ï¼ˆä»¥åŠå…¶ä»–ä¸€åˆ‡ï¼‰çš„æ‰€æœ‰æ”¯æŒã€‚ä»–è¿˜è¦æ„Ÿè°¢ä»–åœ¨éƒ½æŸæ—å¤§å­¦å­¦é™¢ï¼ˆä»¥åŠä¹‹å‰åœ¨éƒ½æŸæ—ç†å·¥å­¦é™¢ï¼‰çš„æ‰€æœ‰åŒäº‹å’Œå­¦ç”Ÿï¼Œå°¤å…¶æ˜¯ PÃ¡draig Cunningham å’Œ Sarah Jane Delanyï¼Œä»–ä»¬è®©ä»–å¯¹æœºå™¨å­¦ä¹ å¤§å¼€çœ¼ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that all the weights and the inputs are independent and identically distributed,34 then the products in the weighted sum can be considered uncorrelated and we can state the variance of z as follows:",
            "zh": "å‡è®¾æ‰€æœ‰æƒé‡å’Œè¾“å…¥éƒ½æ˜¯ç‹¬ç«‹çš„å¹¶ä¸”åˆ†å¸ƒç›¸åŒï¼Œ34 é‚£ä¹ˆåŠ æƒå’Œä¸­çš„ä¹˜ç§¯å¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸ç›¸å…³çš„ï¼Œæˆ‘ä»¬å¯ä»¥å°† z çš„æ–¹å·®è¡¨ç¤ºå¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, the number of factors required by a naive Bayes model is only dependent on the number of features in the domain and is independent of the number of instances.",
            "zh": "ä¾‹å¦‚ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹æ‰€éœ€çš„å› å­æ•°ä»…å–å†³äºåŸŸä¸­çš„ç‰¹å¾æ•°ï¼Œè€Œä¸å®ä¾‹æ•°æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather, they will require the predictions made by a model to be explained and justified.",
            "zh": "ç›¸åï¼Œå®ƒä»¬å°†è¦æ±‚å¯¹æ¨¡å‹åšå‡ºçš„é¢„æµ‹è¿›è¡Œè§£é‡Šå’Œè¯æ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting sets both contain a mixture of spam and ham instances.",
            "zh": "ç”Ÿæˆçš„é›†åˆéƒ½åŒ…å«åƒåœ¾é‚®ä»¶å’Œç«è…¿å®ä¾‹çš„æ··åˆä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "On-policy temporal-difference learning is an alternative in which the behavior policy is used to select the next action at the update step.",
            "zh": "ç­–ç•¥æ—¶é—´å·®å¼‚å­¦ä¹ æ˜¯ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œå…¶ä¸­è¡Œä¸ºç­–ç•¥ç”¨äºåœ¨æ›´æ–°æ­¥éª¤ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªæ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, these case studies highlight how a range of issues and tasks beyond model buildingâ€”such as business understanding, problem definition, data gathering and preparation, and communication of insightâ€”are crucial to the success of a predictive analytics project.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼Œè¿™äº›æ¡ˆä¾‹ç ”ç©¶å¼ºè°ƒäº†æ¨¡å‹æ„å»ºä¹‹å¤–çš„ä¸€ç³»åˆ—é—®é¢˜å’Œä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸šåŠ¡ç†è§£ã€é—®é¢˜å®šä¹‰ã€æ•°æ®æ”¶é›†å’Œå‡†å¤‡ä»¥åŠè§è§£äº¤æµï¼‰å¯¹äºé¢„æµ‹åˆ†æé¡¹ç›®çš„æˆåŠŸè‡³å…³é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.25",
            "zh": "0.25"
        }
    },
    {
        "translation": {
            "en": "This is exactly what we do to update the weights in our recurrent neural network.",
            "zh": "è¿™æ­£æ˜¯æˆ‘ä»¬æ›´æ–°é€’å½’ç¥ç»ç½‘ç»œä¸­çš„æƒé‡æ‰€åšçš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, we would be able to understand how office size affects office rental price.",
            "zh": "é¦–å…ˆï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿäº†è§£åŠå…¬å®¤å¤§å°å¦‚ä½•å½±å“åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROFLUX_U/G/R/I/Z",
            "zh": "PETROFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "In fact, a large difference between the mean and median of a feature is an indication that there may be outliers among the feature values.",
            "zh": "äº‹å®ä¸Šï¼Œç‰¹å¾çš„å‡å€¼å’Œä¸­ä½æ•°ä¹‹é—´çš„è¾ƒå¤§å·®å¼‚è¡¨æ˜ç‰¹å¾å€¼ä¹‹é—´å¯èƒ½å­˜åœ¨å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2500",
            "zh": "0.2500"
        }
    },
    {
        "translation": {
            "en": "Note that this time we have separated w0 from the other weights, w, as this will make later equations simpler.21 Recall from Section 7.4.4[338] that for instances above a separating hyperplane",
            "zh": "è¯·æ³¨æ„ï¼Œè¿™æ¬¡æˆ‘ä»¬å·²å°† w0 ä¸å…¶ä»–æƒé‡ w åˆ†ç¦»ï¼Œå› ä¸ºè¿™å°†ä½¿åé¢çš„æ–¹ç¨‹æ›´ç®€å•.21 å›æƒ³ä¸€ä¸‹ç¬¬ 7.4.4 èŠ‚[338]ï¼Œå¯¹äºåˆ†ç¦»è¶…å¹³é¢ä¸Šæ–¹çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "CHURN",
            "zh": "æ…ä¹³å™¨"
        }
    },
    {
        "translation": {
            "en": "Error Gradients (Deltas) Î´",
            "zh": "è¯¯å·®æ¢¯åº¦ ï¼ˆDeltaï¼‰ Î´"
        }
    },
    {
        "translation": {
            "en": "Second, once a feature has been tested, it is not considered for selection again along that path in the tree.",
            "zh": "å…¶æ¬¡ï¼Œä¸€æ—¦æµ‹è¯•äº†ç‰¹å¾ï¼Œå°±ä¸ä¼šå†è€ƒè™‘æ²¿ç€æ ‘ä¸­çš„è¯¥è·¯å¾„è¿›è¡Œé€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What will be the value of ct if",
            "zh": "ï¼ˆbï¼‰ ct çš„å€¼æ˜¯å¤šå°‘ï¼Œå¦‚æœ"
        }
    },
    {
        "translation": {
            "en": "For this reason, there are a variety of different performance measures and no single approach that is appropriate for all scenarios.",
            "zh": "å› æ­¤ï¼Œæœ‰å„ç§ä¸åŒçš„æ€§èƒ½åº¦é‡ï¼Œæ²¡æœ‰ä¸€ç§æ–¹æ³•é€‚åˆæ‰€æœ‰æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "On each time-step, the information stored in the memory buffer is concatenated with the next input to each neuron.",
            "zh": "åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸Šï¼Œå­˜å‚¨åœ¨å†…å­˜ç¼“å†²åŒºä¸­çš„ä¿¡æ¯ä¸æ¯ä¸ªç¥ç»å…ƒçš„ä¸‹ä¸€ä¸ªè¾“å…¥è¿æ¥èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The expected target values for a test set, the predictions made by a model, and the resulting errors based on these predictions for a blood-thinning drug dosage prediction problem.",
            "zh": "æµ‹è¯•é›†çš„é¢„æœŸç›®æ ‡å€¼ã€æ¨¡å‹åšå‡ºçš„é¢„æµ‹ä»¥åŠåŸºäºè¿™äº›é¢„æµ‹çš„è¡€æ¶²ç¨€é‡Šè¯ç‰©å‰‚é‡é¢„æµ‹é—®é¢˜çš„ç»“æœè¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This final formulation of the action-value function simply states that the expected return from taking action at in state st is the expected reward for taking that action plus the expected return from all of the subsequent actions that the agent will take as it moves between states if it continues to follow the policy Ï€.",
            "zh": "è¡ŒåŠ¨ä»·å€¼å‡½æ•°çš„æœ€ç»ˆè¡¨è¿°ç®€å•åœ°æŒ‡å‡ºï¼Œåœ¨çŠ¶æ€ st å¤„é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥æ˜¯é‡‡å–è¯¥è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥ï¼ŒåŠ ä¸Šä»£ç†åœ¨ç»§ç»­éµå¾ªç­–ç•¥Ï€æ—¶åœ¨çŠ¶æ€ä¹‹é—´ç§»åŠ¨æ—¶å°†é‡‡å–çš„æ‰€æœ‰åç»­è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.2â€…â€…â€…Unsupervised machine learning as a single-step process.",
            "zh": "10.2 æ— ç›‘ç£æœºå™¨å­¦ä¹ ä½œä¸ºå•æ­¥è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first is by mistaking the order of a causal relationship.",
            "zh": "ç¬¬ä¸€ç§æ˜¯å¼„é”™äº†å› æœå…³ç³»çš„é¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.4â€ƒUnderstanding Clustering Results",
            "zh": "10.4.4 äº†è§£èšç±»ç»“æœ"
        }
    },
    {
        "translation": {
            "en": "When we first mentioned the ID3 algorithm, we stated that it tries to create the shallowest decision tree that is consistent with the data given.",
            "zh": "å½“æˆ‘ä»¬ç¬¬ä¸€æ¬¡æåˆ° ID3 ç®—æ³•æ—¶ï¼Œæˆ‘ä»¬è¯´è¿‡å®ƒè¯•å›¾åˆ›å»ºä¸ç»™å®šæ•°æ®ä¸€è‡´çš„æœ€æµ…å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is this selection of the best action, rather than one selected using the behavior policy, that makes Q-learning an off-policy approach.",
            "zh": "æ­£æ˜¯è¿™ç§å¯¹æœ€ä½³è¡ŒåŠ¨çš„é€‰æ‹©ï¼Œè€Œä¸æ˜¯ä½¿ç”¨è¡Œä¸ºç­–ç•¥é€‰æ‹©çš„è¡ŒåŠ¨ï¼Œä½¿Q-learningæˆä¸ºä¸€ç§éç­–ç•¥æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. the summation of the results of these two dot products with the bias terms for the hidden layer neurons; and finally,",
            "zh": "3. è¿™ä¸¤ä¸ªç‚¹ç§¯çš„ç»“æœä¸éšè—å±‚ç¥ç»å…ƒçš„åå·®é¡¹çš„æ€»å’Œ;æœ€åï¼Œ"
        }
    },
    {
        "translation": {
            "en": "To do this we simply modify the algorithm to return the majority target level within the set of k nearest neighbors to the query q:",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€ä¿®æ”¹ç®—æ³•ï¼Œå³å¯è¿”å›æŸ¥è¯¢ q çš„ k ä¸ªæœ€è¿‘é‚»é›†åˆä¸­çš„å¤šæ•°ç›®æ ‡æ°´å¹³ï¼š"
        }
    },
    {
        "translation": {
            "en": "The ROC curve is drawn by plotting a point for every feasible threshold value and joining them.",
            "zh": "ROC æ›²çº¿æ˜¯é€šè¿‡ä¸ºæ¯ä¸ªå¯è¡Œçš„é˜ˆå€¼ç»˜åˆ¶ä¸€ä¸ªç‚¹å¹¶å°†å®ƒä»¬è¿æ¥èµ·æ¥æ¥ç»˜åˆ¶çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature SEX and the target feature, CLASS.",
            "zh": "ï¼ˆcï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†åˆ†ç±»ç‰¹å¾ ä¸ç›®æ ‡ç‰¹å¾ CLASS ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, we need a more efficient way to find the best combination of weights.",
            "zh": "ç›¸åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æ‰¾åˆ°æœ€ä½³çš„æƒé‡ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Approximate methods are an alternative to tabular approaches to reinforcement learning that learn a generalized version of the action-value function (or the value function) and can handle much larger state spaces than tabular methods.",
            "zh": "è¿‘ä¼¼æ–¹æ³•æ˜¯è¡¨æ ¼å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„æ›¿ä»£æ–¹æ³•ï¼Œå®ƒå­¦ä¹ åŠ¨ä½œ-ä»·å€¼å‡½æ•°ï¼ˆæˆ–ä»·å€¼å‡½æ•°ï¼‰çš„å¹¿ä¹‰ç‰ˆæœ¬ï¼Œå¹¶ä¸”å¯ä»¥å¤„ç†æ¯”è¡¨æ ¼æ–¹æ³•å¤§å¾—å¤šçš„çŠ¶æ€ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "To use a PDF to calculate a probability, we need to think in terms of the area under an interval of the PDF curve.",
            "zh": "è¦ä½¿ç”¨ PDF æ¥è®¡ç®—æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ PDF æ›²çº¿åŒºé—´ä¸‹çš„é¢ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.9",
            "zh": "å›¾ 6.9"
        }
    },
    {
        "translation": {
            "en": "For each of the other neurons in the softmax output layer, their Î´ is simply their activation",
            "zh": "å¯¹äºsoftmaxè¾“å‡ºå±‚ä¸­çš„å…¶ä»–æ¯ä¸ªç¥ç»å…ƒï¼Œå®ƒä»¬çš„Î´åªæ˜¯å®ƒä»¬çš„æ¿€æ´»"
        }
    },
    {
        "translation": {
            "en": "8.9â€…â€…â€…(left) The XOR function implemented as a two-layer neural network. (right) The network processing the four possible input combinations.",
            "zh": "8.9ï¼ˆå·¦ï¼‰ä½œä¸ºä¸¤å±‚ç¥ç»ç½‘ç»œå®ç°çš„ XOR å‡½æ•°ã€‚ï¼ˆå³ï¼‰å¤„ç†å››ç§å¯èƒ½çš„è¾“å…¥ç»„åˆçš„ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "additive models, 165",
            "zh": "å¢ææ¨¡å‹ï¼Œ165"
        }
    },
    {
        "translation": {
            "en": "To demonstrate how this process works, imagine that we were given the query email SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, CONTAINS IMAGES = true, and asked to predict whether it is spam or ham.",
            "zh": "ä¸ºäº†æ¼”ç¤ºæ­¤è¿‡ç¨‹çš„å·¥ä½œåŸç†ï¼Œå‡è®¾æˆ‘ä»¬æ”¶åˆ°æŸ¥è¯¢ç”µå­é‚®ä»¶ SUSPICIOUS WORDS = trueã€UNKNOWN SENDER = trueã€CONTAINS IMAGES = trueï¼Œå¹¶è¢«è¦æ±‚é¢„æµ‹å®ƒæ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯ç«è…¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The chain rule, however, doesnâ€™t specify any constraints on which features in the domain we choose to condition on. We could just as easily have decomposed the probability of the joint event as follows:",
            "zh": "ä½†æ˜¯ï¼Œé“¾å¼è§„åˆ™å¹¶æœªæŒ‡å®šä»»ä½•çº¦æŸï¼Œè¯´æ˜æˆ‘ä»¬é€‰æ‹©ä»¥åŸŸä¸­çš„å“ªäº›ç‰¹å¾ä¸ºæ¡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ†è§£è”åˆäº‹ä»¶çš„æ¦‚ç‡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "The term population is used in statistics to represent all possible measurements or outcomes that are of interest to us in a particular study or piece of analysis.",
            "zh": "äººå£ä¸€è¯åœ¨ç»Ÿè®¡å­¦ä¸­ç”¨äºè¡¨ç¤ºæˆ‘ä»¬åœ¨ç‰¹å®šç ”ç©¶æˆ–åˆ†æä¸­æ„Ÿå…´è¶£çš„æ‰€æœ‰å¯èƒ½çš„æµ‹é‡æˆ–ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.09089",
            "zh": "-0.09089"
        }
    },
    {
        "translation": {
            "en": "Table 6.13[281] shows the extended domain representation.",
            "zh": "è¡¨ 6.13[281] æ˜¾ç¤ºäº†æ‰©å±•åŸŸè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Generally, the later layers of a convolutional network will include one or more fully connected layers (such as those shown in previous examples) with a softmax output layer if the model is being used for classification.",
            "zh": "é€šå¸¸ï¼Œå¦‚æœæ¨¡å‹ç”¨äºåˆ†ç±»ï¼Œå·ç§¯ç½‘ç»œçš„åé¢å±‚å°†åŒ…æ‹¬ä¸€ä¸ªæˆ–å¤šä¸ªå…·æœ‰ softmax è¾“å‡ºå±‚çš„å…¨è¿æ¥å±‚ï¼ˆä¾‹å¦‚å‰é¢ç¤ºä¾‹ä¸­æ‰€ç¤ºçš„å±‚ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "categorical data, 34",
            "zh": "åˆ†ç±»æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "The path through the tree to make predictions for instances d2, d5, and d6 from the validation dataset leads to this subtree.",
            "zh": "é€šè¿‡æ ‘å¯¹éªŒè¯æ•°æ®é›†ä¸­çš„å®ä¾‹ d2ã€d5 å’Œ d6 è¿›è¡Œé¢„æµ‹çš„è·¯å¾„æŒ‡å‘æ­¤å­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ideally, we should use the threshold that results in the highest information gain when the feature is used to split the dataset.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨åœ¨ä½¿ç”¨ç‰¹å¾æ‹†åˆ†æ•°æ®é›†æ—¶äº§ç”Ÿæœ€é«˜ä¿¡æ¯å¢ç›Šçš„é˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SALARY and AGE section of Table 5.6[206] lists these distances and the ranking that the model applies to the instances in the dataset using them.",
            "zh": "è¡¨ 5.6[206] çš„ SALARY å’Œ AGE éƒ¨åˆ†åˆ—å‡ºäº†è¿™äº›è·ç¦»ä»¥åŠæ¨¡å‹åº”ç”¨äºæ•°æ®é›†ä¸­ä½¿ç”¨å®ƒä»¬çš„å®ä¾‹çš„æ’åã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce the concept of a feature space as a representation for a training dataset and then illustrate how we can compute measures of similarity between instances in a feature space.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç‰¹å¾ç©ºé—´çš„æ¦‚å¿µï¼Œä½œä¸ºè®­ç»ƒæ•°æ®é›†çš„è¡¨ç¤ºå½¢å¼ï¼Œç„¶åè¯´æ˜å¦‚ä½•è®¡ç®—ç‰¹å¾ç©ºé—´ä¸­å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The major drawback of naive Bayes models is the inability of the model to handle the interactions between features.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„ä¸»è¦ç¼ºç‚¹æ˜¯æ¨¡å‹æ— æ³•å¤„ç†ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.27[465] illustrates a fully connected feedforward neural network with a softmax output layer with three neurons for our three-level (low, medium and high) target feature; the dotted rectangle around the softmax layer highlights that the activation function Ï† normalizes the logit values across the neurons in the layer.",
            "zh": "å›¾ 8.27[465] å±•ç¤ºäº†ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œå…·æœ‰ä¸€ä¸ª softmax è¾“å‡ºå±‚ï¼Œå…¶ä¸­æœ‰ä¸‰ä¸ªç¥ç»å…ƒï¼Œç”¨äºæˆ‘ä»¬çš„ä¸‰çº§ï¼ˆä½ã€ä¸­å’Œé«˜ï¼‰ç›®æ ‡ç‰¹å¾;SoftMax å±‚å‘¨å›´çš„è™šçº¿çŸ©å½¢çªå‡ºæ˜¾ç¤ºäº†æ¿€æ´»å‡½æ•°Ï†å¯¹å±‚ä¸­ç¥ç»å…ƒçš„ logit å€¼è¿›è¡Œå½’ä¸€åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Later we add information on potential handling strategies for each data quality issue.",
            "zh": "ç¨åï¼Œæˆ‘ä»¬å°†æ·»åŠ æœ‰å…³æ¯ä¸ªæ•°æ®è´¨é‡é—®é¢˜çš„æ½œåœ¨å¤„ç†ç­–ç•¥çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "11. We discuss exactly this type of visualization, a scatter plot, in detail in Chapter 3[53]. For this example it is sufficient to say that a point is shown for each person in the dataset, placed to represent the personâ€™s age (horizontally) and salary (vertically).",
            "zh": "11. æˆ‘ä»¬åœ¨ç¬¬3ç« [53]ä¸­è¯¦ç»†è®¨è®ºäº†è¿™ç§ç±»å‹çš„å¯è§†åŒ–ï¼Œå³æ•£ç‚¹å›¾ã€‚å¯¹äºæ­¤ç¤ºä¾‹ï¼Œåªéœ€è¯´æ•°æ®é›†ä¸­ä¸ºæ¯ä¸ªäººæ˜¾ç¤ºä¸€ä¸ªç‚¹å°±è¶³å¤Ÿäº†ï¼Œè¯¥ç‚¹ç”¨äºè¡¨ç¤ºè¯¥äººçš„å¹´é¾„ï¼ˆæ°´å¹³ï¼‰å’Œè–ªæ°´ï¼ˆå‚ç›´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "23. The example of predicting where post-operative patients should be sent is inspired by the research reported in Woolery et al. (1991). A real dataset related to this research is available through the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Post-Operative+Patient/.",
            "zh": "23. é¢„æµ‹æœ¯åæ‚£è€…åº”è¢«é€å¾€ä½•å¤„çš„ä¾‹å­æ˜¯å—åˆ°Wooleryç­‰äººï¼ˆ1991å¹´ï¼‰æŠ¥å‘Šçš„ç ”ç©¶çš„å¯å‘ã€‚ä¸è¿™é¡¹ç ”ç©¶ç›¸å…³çš„çœŸå®æ•°æ®é›†å¯é€šè¿‡ archive.ics.uci.edu/ml/datasets/Post-Operative+Patient/ çš„UCIæœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBacheå’ŒLichmanï¼Œ2013ï¼‰è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, comparing the covariance between pairs of features only makes sense if each pair of features is composed of the same mixture of units.",
            "zh": "å› æ­¤ï¼Œåªæœ‰å½“æ¯å¯¹ç‰¹å¾éƒ½ç”±ç›¸åŒçš„å•å…ƒç»„åˆç»„æˆæ—¶ï¼Œæ¯”è¾ƒç‰¹å¾å¯¹ä¹‹é—´çš„åæ–¹å·®æ‰æœ‰æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Histograms, using a bin size of 250 units, and density curves for the ACCOUNT BALANCE feature: (a) the fraudulent instances overlaid with a fitted exponential distribution; and (b) the non-fraudulent instances overlaid with a fitted normal distribution.",
            "zh": "ä½¿ç”¨ 250 ä¸ªå•ä½çš„ç®±å¤§å°çš„ç›´æ–¹å›¾å’Œ ACCOUNT BALANCE ç‰¹å¾çš„å¯†åº¦æ›²çº¿ï¼šï¼ˆaï¼‰ ç”¨æ‹ŸåˆæŒ‡æ•°åˆ†å¸ƒå åŠ çš„æ¬ºè¯ˆå®ä¾‹;ï¼ˆbï¼‰éæ¬ºè¯ˆæ€§å®ä¾‹ä¸æ‹Ÿåˆæ­£æ€åˆ†å¸ƒå åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn used the information gain measure to rank the predictiveness of the different features in the dataset (for this analysis, missing values were simply omitted).",
            "zh": "Jocelyn ä½¿ç”¨ä¿¡æ¯å¢ç›Šåº¦é‡å¯¹æ•°æ®é›†ä¸­ä¸åŒç‰¹å¾çš„é¢„æµ‹æ€§è¿›è¡Œæ’åï¼ˆå¯¹äºæ­¤åˆ†æï¼Œç¼ºå¤±å€¼è¢«ç®€å•åœ°çœç•¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.7â€ƒSupport Vector Machines",
            "zh": "7.4.7 æ”¯æŒå‘é‡æœº"
        }
    },
    {
        "translation": {
            "en": "A subtree is pruned if the error rate on the validation set of the decision tree with the subtree removed is no greater than the error rate of the decision tree when the subtree is included.",
            "zh": "å¦‚æœåˆ é™¤äº†å­æ ‘çš„å†³ç­–æ ‘çš„éªŒè¯é›†ä¸Šçš„é”™è¯¯ç‡ä¸å¤§äºåŒ…å«å­æ ‘æ—¶å†³ç­–æ ‘çš„é”™è¯¯ç‡ï¼Œåˆ™ä¿®å‰ªå­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is one of the great arts of machine learning and something that we return to throughout this book.",
            "zh": "è¿™æ˜¯æœºå™¨å­¦ä¹ çš„ä¼Ÿå¤§è‰ºæœ¯ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­å›å½’çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The root mean squared error (RMSE) for a set of predictions made by a model on a test set is calculated as",
            "zh": "æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œçš„ä¸€ç»„é¢„æµ‹çš„å‡æ–¹æ ¹è¯¯å·® ï¼ˆRMSEï¼‰ è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "We have structured this presentation around five approaches to learning: information-based, similarity-based, probability-based, error-based, and deep learning.",
            "zh": "æˆ‘ä»¬å›´ç»•äº”ç§å­¦ä¹ æ–¹æ³•æ„å»ºäº†æœ¬æ¬¡æ¼”è®²ï¼šåŸºäºä¿¡æ¯ã€åŸºäºç›¸ä¼¼æ€§ã€åŸºäºæ¦‚ç‡ã€åŸºäºé”™è¯¯å’Œæ·±åº¦å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3.1â€ƒBackpropagation: The General Structure of the Algorithm",
            "zh": "8.3.1 åå‘ä¼ æ’­ï¼šç®—æ³•çš„ä¸€èˆ¬ç»“æ„"
        }
    },
    {
        "translation": {
            "en": "There are a variety of different recurrent neural network architectures; in this section we introduce two of the most popular: simple recurrent networks (also known as Elman networks (Elman, 1990)), and long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, 1997).",
            "zh": "æœ‰å„ç§ä¸åŒçš„é€’å½’ç¥ç»ç½‘ç»œæ¶æ„;åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ç§æœ€æµè¡Œçš„ç½‘ç»œï¼šç®€å•é€’å½’ç½‘ç»œï¼ˆä¹Ÿç§°ä¸ºElmanç½‘ç»œï¼ˆElmanï¼Œ1990ï¼‰ï¼‰å’Œé•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œï¼ˆHochreiterå’ŒSchmidhuberï¼Œ1997ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example, using a k-d tree saved us calculating the distance between the query node and 14 of the instances in the dataset.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨ k-d æ ‘å¯ä»¥èŠ‚çœæˆ‘ä»¬è®¡ç®—æŸ¥è¯¢èŠ‚ç‚¹ä¸æ•°æ®é›†ä¸­ 14 ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fundamental building block of a neural network is a computational model known as an artificial neuron.",
            "zh": "ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ„å»ºå—æ˜¯ç§°ä¸ºäººå·¥ç¥ç»å…ƒçš„è®¡ç®—æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "During landing the agent receives a reward of + 10 each time one of its legs touches the ground gently.",
            "zh": "åœ¨ç€é™†è¿‡ç¨‹ä¸­ï¼Œæ¯å½“å®ƒçš„ä¸€æ¡è…¿è½»è½»æ¥è§¦åœ°é¢æ—¶ï¼Œä»£ç†å°±ä¼šè·å¾— + 10 çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. Whereas previously we referred to recall as something calculated only for the positive level, we can calculate recall for any level as the accuracy of the predictions made for that level.",
            "zh": "9. ä»¥å‰æˆ‘ä»¬æŠŠå¬å›ç‡ç§°ä¸ºåªé’ˆå¯¹æ­£æ°´å¹³è®¡ç®—çš„ä¸œè¥¿ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä»»ä½•æ°´å¹³çš„å¬å›ç‡ï¼Œä½œä¸ºå¯¹è¯¥æ°´å¹³åšå‡ºçš„é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, chapparal is a type of evergreen shrubland that can be fire-prone.",
            "zh": "é¦–å…ˆï¼Œchapparal æ˜¯ä¸€ç§å¸¸ç»¿çŒæœ¨ï¼Œå®¹æ˜“å‘ç”Ÿç«ç¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "25. Note that comparing the sum of squared errors for the logistic network in Table 8.4[426] with the sum of squared errors for the ReLU model in Table 8.10[441] is not useful, because both of these are errors for random networks.",
            "zh": "25. è¯·æ³¨æ„ï¼Œå°†è¡¨8.4[426]ä¸­é€»è¾‘ç½‘ç»œçš„å¹³æ–¹è¯¯å·®æ€»å’Œä¸è¡¨8.10[441]ä¸­ReLUæ¨¡å‹çš„å¹³æ–¹è¯¯å·®æ€»å’Œè¿›è¡Œæ¯”è¾ƒæ˜¯æ²¡æœ‰ç”¨çš„ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªéƒ½æ˜¯éšæœºç½‘ç»œçš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In information theory, the meaning of the word information deliberately excludes the psychological aspects of the communication and should be understood as measuring the optimal encoding length of a message given the set of possible messages that could be sent within the communication.",
            "zh": "åœ¨ä¿¡æ¯è®ºä¸­ï¼Œâ€œä¿¡æ¯â€ä¸€è¯çš„å«ä¹‰æ•…æ„æ’é™¤äº†é€šä¿¡çš„å¿ƒç†æ–¹é¢ï¼Œå¹¶ä¸”åº”è¯¥è¢«ç†è§£ä¸ºåœ¨ç»™å®šé€šä¿¡ä¸­å¯èƒ½å‘é€çš„ä¸€ç»„å¯èƒ½æ¶ˆæ¯çš„æƒ…å†µä¸‹æµ‹é‡æ¶ˆæ¯çš„æœ€ä½³ç¼–ç é•¿åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is one of these error gradients for each weight in the network.",
            "zh": "ç½‘ç»œä¸­æ¯ä¸ªæƒé‡éƒ½æœ‰ä¸€ä¸ªè¿™æ ·çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Careful readers might note a contradiction in the paragraph above, however.",
            "zh": "ç„¶è€Œï¼Œç»†å¿ƒçš„è¯»è€…å¯èƒ½ä¼šæ³¨æ„åˆ°ä¸Šé¢æ®µè½ä¸­çš„çŸ›ç›¾ä¹‹å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, average customer purchases per month, loan-to-value ratios, or changes in usage frequencies for different periods are all descriptive features that could be useful in an ABT but that most likely need to be derived from multiple raw data sources.",
            "zh": "ä¾‹å¦‚ï¼Œæ¯æœˆçš„å¹³å‡å®¢æˆ·è´­ä¹°é‡ã€è´·æ¬¾ä»·å€¼æ¯”ç‡æˆ–ä¸åŒæ—¶æœŸçš„ä½¿ç”¨é¢‘ç‡å˜åŒ–éƒ½æ˜¯æè¿°æ€§ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨ ABT ä¸­å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†å¾ˆå¯èƒ½éœ€è¦ä»å¤šä¸ªåŸå§‹æ•°æ®æºæ´¾ç”Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "8. This algorithm was first published in Quinlan (1986).",
            "zh": "8. è¯¥ç®—æ³•é¦–æ¬¡å‘è¡¨åœ¨Quinlanï¼ˆ1986ï¼‰ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, we can simply return the target level that has the highest score from the numerator term.",
            "zh": "ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¿”å›åˆ†å­é¡¹ä¸­å¾—åˆ†æœ€é«˜çš„ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The rule given in Equation (7.32)[345] assumes that only a single training instance exists. To modify this to take into account a full training dataset, we simply need to sum across all the training instances as we did before in Equation (7.17)[327]. This gives us the weight update rule for multivariable logistic regression:",
            "zh": "ç­‰å¼ï¼ˆ7.32ï¼‰[345]ä¸­ç»™å‡ºçš„è§„åˆ™å‡è®¾åªå­˜åœ¨ä¸€ä¸ªè®­ç»ƒå®ä¾‹ã€‚ä¸ºäº†ä¿®æ”¹å®ƒä»¥è€ƒè™‘å®Œæ•´çš„è®­ç»ƒæ•°æ®é›†ï¼Œæˆ‘ä»¬åªéœ€è¦åƒä¹‹å‰åœ¨ç­‰å¼ï¼ˆ7.17ï¼‰[327]ä¸­æ‰€åšçš„é‚£æ ·å¯¹æ‰€æœ‰è®­ç»ƒå®ä¾‹æ±‚å’Œã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å¤šå˜é‡é€»è¾‘å›å½’çš„æƒé‡æ›´æ–°è§„åˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "(a) A set of instances on a continuous number line; (b), (c), and (d) depict some of the potential groupings that could be applied to these instances.",
            "zh": "ï¼ˆaï¼‰ è¿ç»­æ•°å­—çº¿ä¸Šçš„ä¸€ç»„å®ä¾‹;ï¼ˆbï¼‰ã€ï¼ˆcï¼‰å’Œï¼ˆdï¼‰æè¿°äº†å¯ä»¥åº”ç”¨äºè¿™äº›å®ä¾‹çš„ä¸€äº›æ½œåœ¨åˆ†ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other cases, particularly where data arises from manual entry, certain personally sensitive values (for example, salary, age, or weight) may be entered only for a small number of instances.",
            "zh": "åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œç‰¹åˆ«æ˜¯å½“æ•°æ®æ¥è‡ªæ‰‹åŠ¨è¾“å…¥æ—¶ï¼ŒæŸäº›ä¸ªäººæ•æ„Ÿå€¼ï¼ˆä¾‹å¦‚ï¼Œå·¥èµ„ã€å¹´é¾„æˆ–ä½“é‡ï¼‰å¯èƒ½ä»…åœ¨å°‘æ•°æƒ…å†µä¸‹è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(c)[626] shows reconstructions of the same images after just five epochs of network training.",
            "zh": "å›¾10.15ï¼ˆcï¼‰[626]æ˜¾ç¤ºäº†åœ¨ä»…ä»…äº”ä¸ªç½‘ç»œè®­ç»ƒå‘¨æœŸåå¯¹ç›¸åŒå›¾åƒçš„é‡å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of this difference, the estimate for the action-value entry QÏ€(st,at) is updated slightly.",
            "zh": "åœ¨æ­¤å·®å¼‚çš„åŸºç¡€ä¸Šï¼ŒåŠ¨ä½œå€¼æ¡ç›® QÏ€ï¼ˆstï¼Œatï¼‰ çš„ä¼°è®¡å€¼ç•¥æœ‰æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in the motor insurance fraud detection example that we used in this chapter, the claims in the ABT were all historical.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬åœ¨æœ¬ç« ä¸­ä½¿ç”¨çš„æ±½è½¦ä¿é™©æ¬ºè¯ˆæ£€æµ‹ç¤ºä¾‹ä¸­ï¼ŒABT ä¸­çš„ç´¢èµ”éƒ½æ˜¯å†å²æ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the retail scenario, there are only three binary descriptive features, so there are 23 = 8 possible combinations of descriptive feature values.",
            "zh": "å¯¹äºé›¶å”®æ–¹æ¡ˆï¼Œåªæœ‰ä¸‰ä¸ªäºŒè¿›åˆ¶æè¿°æ€§ç‰¹å¾ï¼Œå› æ­¤æœ‰ 23 = 8 ç§æè¿°æ€§ç‰¹å¾å€¼çš„å¯èƒ½ç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "LIFE EXP measures life expectancy at birth.",
            "zh": "LIFE EXPè¡¡é‡å‡ºç”Ÿæ—¶çš„é¢„æœŸå¯¿å‘½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.11[359] shows a sample from a dataset of mobile customers that includes details of customersâ€™ shopping habits with a large national retail chain.",
            "zh": "è¡¨7.11[359]æ˜¾ç¤ºäº†æ¥è‡ªç§»åŠ¨å®¢æˆ·æ•°æ®é›†çš„æ ·æœ¬ï¼Œå…¶ä¸­åŒ…æ‹¬å®¢æˆ·åœ¨å¤§å‹å…¨å›½é›¶å”®è¿é”åº—çš„è´­ç‰©ä¹ æƒ¯çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with the regression examples in Chapter 7[311], the profile of this error reduction over the course of the training is sensitive to a number of factors, for example, the learning rate Î± and how it is updated throughout the training (see Section 7.3.3[328]).",
            "zh": "ä¸ç¬¬ 7 ç« [311] ä¸­çš„å›å½’ç¤ºä¾‹ä¸€æ ·ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™ç§è¯¯å·®å‡å°‘çš„æ¦‚å†µå¯¹è®¸å¤šå› ç´ éƒ½å¾ˆæ•æ„Ÿï¼Œä¾‹å¦‚ï¼Œå­¦ä¹ ç‡Î±ä»¥åŠåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ›´æ–°æ–¹å¼ï¼ˆå‚è§ç¬¬ 7.3.3 èŠ‚[328]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Classification: LCC Q325.5.K455 2020 | DDC 519.2/870285631â€“dc23",
            "zh": "ä¸­å›¾åˆ†ç±»å·ï¼š LCC Q325.5.K455 2020 |DDC 519.2/870285631â€“DC23"
        }
    },
    {
        "translation": {
            "en": "To find these other types of clusterings, it can be more useful to use a clustering algorithm that is driven more by local relationships in a dataset than an expected global structure.",
            "zh": "è¦æŸ¥æ‰¾è¿™äº›å…¶ä»–ç±»å‹çš„èšç±»ï¼Œä½¿ç”¨èšç±»åˆ†æç®—æ³•å¯èƒ½æ›´æœ‰ç”¨ï¼Œè¯¥ç®—æ³•æ›´å¤šåœ°ç”±æ•°æ®é›†ä¸­çš„å±€éƒ¨å…³ç³»é©±åŠ¨ï¼Œè€Œä¸æ˜¯é¢„æœŸçš„å…¨å±€ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In many cases the primary requirement of a project is to create an accurate prediction model.",
            "zh": "åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œé¡¹ç›®çš„ä¸»è¦è¦æ±‚æ˜¯åˆ›å»ºå‡†ç¡®çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because it takes so long and relies on experienced, expert tax inspectors, performing an audit is an expensive exercise.",
            "zh": "ç”±äºå®¡è®¡æ—¶é—´å¾ˆé•¿ï¼Œå¹¶ä¸”ä¾èµ–äºç»éªŒä¸°å¯Œçš„ä¸“ä¸šç¨åŠ¡æ£€æŸ¥å‘˜ï¼Œå› æ­¤è¿›è¡Œå®¡è®¡æ˜¯ä¸€é¡¹æ˜‚è´µçš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "0.35",
            "zh": "0.35"
        }
    },
    {
        "translation": {
            "en": "This means that they understand enough about a business so that they can converse with partners in the business in a way that these business partners understand.",
            "zh": "è¿™æ„å‘³ç€ä»–ä»¬å¯¹ä¸šåŠ¡æœ‰è¶³å¤Ÿçš„äº†è§£ï¼Œä»¥ä¾¿ä»–ä»¬å¯ä»¥ä»¥è¿™äº›ä¸šåŠ¡åˆä½œä¼™ä¼´ç†è§£çš„æ–¹å¼ä¸ä¸šåŠ¡ä¸­çš„åˆä½œä¼™ä¼´äº¤è°ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The average number of calls received each month by the customer",
            "zh": "å®¢æˆ·æ¯æœˆå¹³å‡æ¥åˆ°çš„ç”µè¯æ•°"
        }
    },
    {
        "translation": {
            "en": "Using a full joint probability distribution, we can do probabilistic inference by summing out the features we are not interested in.",
            "zh": "ä½¿ç”¨å®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ€»ç»“æˆ‘ä»¬ä¸æ„Ÿå…´è¶£çš„ç‰¹å¾æ¥è¿›è¡Œæ¦‚ç‡æ¨ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.2â€ƒFundamentals",
            "zh": "10.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "This involves performing an evaluation experiment31 for each candidate feature subset, in which a model is induced using only the features in the subset, and its performance is evaluated.",
            "zh": "è¿™æ¶‰åŠå¯¹æ¯ä¸ªå€™é€‰ç‰¹å¾å­é›†æ‰§è¡Œè¯„ä¼°å®éªŒ31ï¼Œå…¶ä¸­ä»…ä½¿ç”¨å­é›†ä¸­çš„ç‰¹å¾è¯±å¯¼æ¨¡å‹ï¼Œå¹¶è¯„ä¼°å…¶æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, however, weights on the connections from the memory buffer to each of the neurons.",
            "zh": "ç„¶è€Œï¼Œä»è®°å¿†ç¼“å†²åŒºåˆ°æ¯ä¸ªç¥ç»å…ƒçš„è¿æ¥æ˜¯æœ‰æƒé‡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "parameterized model, 311, 312, 314",
            "zh": "å‚æ•°åŒ–æ¨¡å‹ï¼Œ 311ï¼Œ 312ï¼Œ 314"
        }
    },
    {
        "translation": {
            "en": "where Parents(xi) describes the set of nodes in the graph that directly link into node xi, and Children(xi) describes the set of nodes in the graph that xi directly links into. Applying this definition to the network in Figure 6.9(b)[287], we can calculate the probability of P(c | Â¬a,b,d) as",
            "zh": "å…¶ä¸­ Parentsï¼ˆä¹ ï¼‰ æè¿°å›¾ä¸­ç›´æ¥é“¾æ¥åˆ°èŠ‚ç‚¹ ä¹  çš„èŠ‚ç‚¹é›†ï¼ŒChildrenï¼ˆä¹ ï¼‰ æè¿°å›¾ä¸­ ä¹  ç›´æ¥é“¾æ¥åˆ°çš„èŠ‚ç‚¹é›†ã€‚å°†è¿™ä¸ªå®šä¹‰åº”ç”¨äºå›¾6.9ï¼ˆbï¼‰[287]ä¸­çš„ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºPï¼ˆc | Â¬aï¼Œbï¼Œdï¼‰çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "In processing a sequence, the network takes one input from the sequence at each time point.",
            "zh": "åœ¨å¤„ç†åºåˆ—æ—¶ï¼Œç½‘ç»œä»æ¯ä¸ªæ—¶é—´ç‚¹çš„åºåˆ—ä¸­è·å–ä¸€ä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Many machine learning tools will allow the maximum depth of a tree to be specified as a parameter, which allows for the creation of such stunted trees.",
            "zh": "è®¸å¤šæœºå™¨å­¦ä¹ å·¥å…·å°†å…è®¸å°†æ ‘çš„æœ€å¤§æ·±åº¦æŒ‡å®šä¸ºå‚æ•°ï¼Œä»è€Œå…è®¸åˆ›å»ºæ­¤ç±»å‘è‚²ä¸è‰¯çš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first Î´ we calculate is for Neuron 8: Î´8. Neuron 8 is an output neuron and so we use the process illustrated in Equation (8.21)[411]. As shown by Equation (8.21)[411] and following Equation (8.20)[411], the term âˆ‚â„°/âˆ‚a is the error of the neuron multiplied by âˆ’ 1, and so from Table 8.4[426] we see that for d2",
            "zh": "æˆ‘ä»¬è®¡ç®—çš„ç¬¬ä¸€ä¸ªÎ´æ˜¯ç¥ç»å…ƒ 8ï¼šÎ´8ã€‚ç¥ç»å…ƒ 8 æ˜¯ä¸€ä¸ªè¾“å‡ºç¥ç»å…ƒï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨å…¬å¼ ï¼ˆ8.21ï¼‰[411] ä¸­æ‰€ç¤ºçš„è¿‡ç¨‹ã€‚å¦‚å…¬å¼ï¼ˆ8.21ï¼‰[411]å’Œå…¬å¼ï¼ˆ8.20ï¼‰[411]æ‰€ç¤ºï¼Œé¡¹âˆ‚E/âˆ‚aæ˜¯ç¥ç»å…ƒçš„è¯¯å·®ä¹˜ä»¥âˆ’1ï¼Œå› æ­¤ä»è¡¨8.4[426]ä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºd2"
        }
    },
    {
        "translation": {
            "en": "The most easily calculated measure of variation is range. The range of a sample of n values for a feature a is calculated as",
            "zh": "æœ€å®¹æ˜“è®¡ç®—çš„å˜å¼‚åº¦é‡æ˜¯èŒƒå›´ã€‚è¦ç´  a çš„ n ä¸ªå€¼æ ·æœ¬çš„èŒƒå›´è®¡ç®—ä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16[430] shows the network from the worked example in a graph form with each of the neurons labeled with the Î´ for the neuron.",
            "zh": "å›¾ 8.16[430] ä»¥å›¾å½¢å½¢å¼æ˜¾ç¤ºäº†å·¥ä½œç¤ºä¾‹ä¸­çš„ç½‘ç»œï¼Œå…¶ä¸­æ¯ä¸ªç¥ç»å…ƒéƒ½æ ‡æœ‰ç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the condensed nearest neighbor approach (Hart, 1968) was one of the earliest attempts at this and removes the instances not near target level boundaries in a feature space, as they are not required to make predictions.",
            "zh": "ä¾‹å¦‚ï¼Œæµ“ç¼©æœ€è¿‘é‚»æ–¹æ³•ï¼ˆHartï¼Œ1968ï¼‰æ˜¯æœ€æ—©çš„å°è¯•ä¹‹ä¸€ï¼Œå®ƒåˆ é™¤äº†ç‰¹å¾ç©ºé—´ä¸­ä¸é è¿‘ç›®æ ‡çº§è¾¹ç•Œçš„å®ä¾‹ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset of mobile phone customers described by their average monthly data (DATA USAGE) and call (CALL VOLUME) usage. Details of the first two iterations of the k-means clustering algorithm are also shown. The clustering in the second iteration is actually the final clustering in this simple example.",
            "zh": "ç§»åŠ¨ç”µè¯å®¢æˆ·çš„æ•°æ®é›†ï¼Œç”±å…¶å¹³å‡æ¯æœˆæ•°æ®ï¼ˆDATA USAGEï¼‰å’Œé€šè¯é‡ï¼ˆCALL VOLUMEï¼‰ä½¿ç”¨æƒ…å†µæè¿°ã€‚è¿˜æ˜¾ç¤ºäº† k-means èšç±»ç®—æ³•çš„å‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œç¬¬äºŒæ¬¡è¿­ä»£ä¸­çš„èšç±»å®é™…ä¸Šæ˜¯æœ€ç»ˆèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examining the histogram in Figure 3.1(c)[58] is useful in considering the impact of applying the clamp transformation using these thresholds.",
            "zh": "æ£€æŸ¥å›¾3.1ï¼ˆcï¼‰[58]ä¸­çš„ç›´æ–¹å›¾æœ‰åŠ©äºè€ƒè™‘ä½¿ç”¨è¿™äº›é˜ˆå€¼åº”ç”¨é’³ä½å˜æ¢çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "If all values in a sample occur with equal frequency, then there is no mode.",
            "zh": "å¦‚æœæ ·æœ¬ä¸­çš„æ‰€æœ‰å€¼éƒ½ä»¥ç›¸åŒçš„é¢‘ç‡å‡ºç°ï¼Œåˆ™ä¸å­˜åœ¨æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.11",
            "zh": "è¡¨ 4.11"
        }
    },
    {
        "translation": {
            "en": "Although it might seem that we now have a good solution for building probability-based prediction models, we are not quite done yet. There is one fundamental flaw with the approach that we have developed. To illustrate this, we will consider a second query instance for the meningitis diagnosis problem, this time with descriptive feature values HEADACHE = true, FEVER = true, and VOMITING = false. The probability of MENINGITIS = true given this query is",
            "zh": "è™½ç„¶æˆ‘ä»¬ç°åœ¨ä¼¼ä¹æœ‰ä¸€ä¸ªå¾ˆå¥½çš„è§£å†³æ–¹æ¡ˆæ¥æ„å»ºåŸºäºæ¦‚ç‡çš„é¢„æµ‹æ¨¡å‹ï¼Œä½†æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œå…¨å®Œæˆã€‚æˆ‘ä»¬åˆ¶å®šçš„æ–¹æ³•å­˜åœ¨ä¸€ä¸ªæ ¹æœ¬ç¼ºé™·ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†è€ƒè™‘è„‘è†œç‚è¯Šæ–­é—®é¢˜çš„ç¬¬äºŒä¸ªæŸ¥è¯¢å®ä¾‹ï¼Œè¿™æ¬¡ä½¿ç”¨æè¿°æ€§ç‰¹å¾å€¼ HEADACHE = trueã€FEVER = true å’Œ VOMITING = falseã€‚ç»™å®šæ­¤æŸ¥è¯¢ï¼Œè„‘è†œç‚ = true çš„æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "20. It is important to remember that for a prediction problem with four target levels, uniform random guessing will give an accuracy of just 25%.",
            "zh": "20. é‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå¯¹äºå…·æœ‰å››ä¸ªç›®æ ‡æ°´å¹³çš„é¢„æµ‹é—®é¢˜ï¼Œç»Ÿä¸€éšæœºçŒœæµ‹çš„å‡†ç¡®ç‡ä»…ä¸º 25%ã€‚"
        }
    },
    {
        "translation": {
            "en": "family",
            "zh": "å®¶åº­"
        }
    },
    {
        "translation": {
            "en": "logistic regression, 311, 338, 342, 368, 556, 719, 732, 733, 735, 736",
            "zh": "é€»è¾‘å›å½’ï¼Œ 311ï¼Œ 338ï¼Œ 342ï¼Œ 368ï¼Œ 556ï¼Œ 719ï¼Œ 732ï¼Œ 733ï¼Œ 735ï¼Œ 736"
        }
    },
    {
        "translation": {
            "en": "Feature subset space for a dataset with three features X, Y, and Z.",
            "zh": "å…·æœ‰ä¸‰ä¸ªè¦ç´  Xã€Y å’Œ Z çš„æ•°æ®é›†çš„ç‰¹å¾å­é›†ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The density of this unit hypercube is (there are 10 instances inside the hypercube).",
            "zh": "è¿™ä¸ªå•ä½è¶…ç«‹æ–¹ä½“çš„å¯†åº¦æ˜¯ï¼ˆè¶…ç«‹æ–¹ä½“å†…æœ‰ 10 ä¸ªå®ä¾‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Environments in which the state contains all information about the environment and any agents in it are known as fully observable environments. Environments in which this is not the case are known as partially observable environments. The use of a state generation function allows us to treat some partially observable environments as if they were fully observable and apply the mechanics of reinforcement learning where otherwise it would not be possible.",
            "zh": "1. çŠ¶æ€åŒ…å«æœ‰å…³ç¯å¢ƒåŠå…¶ä¸­ä»»ä½•ä»£ç†çš„æ‰€æœ‰ä¿¡æ¯çš„ç¯å¢ƒç§°ä¸ºå®Œå…¨å¯è§‚å¯Ÿç¯å¢ƒã€‚å¹¶éå¦‚æ­¤çš„ç¯å¢ƒç§°ä¸ºéƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒã€‚ä½¿ç”¨çŠ¶æ€ç”Ÿæˆå‡½æ•°å…è®¸æˆ‘ä»¬å°†ä¸€äº›éƒ¨åˆ†å¯è§‚å¯Ÿçš„ç¯å¢ƒè§†ä¸ºå®Œå…¨å¯è§‚å¯Ÿçš„ç¯å¢ƒï¼Œå¹¶åœ¨å…¶ä»–æƒ…å†µä¸‹åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„æœºåˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.11",
            "zh": "å›¾ 10.11"
        }
    },
    {
        "translation": {
            "en": "8.7â€…â€…â€…The calculation of Î”w7,5 across our four examples.",
            "zh": "8.7 æˆ‘ä»¬å››ä¸ªä¾‹å­ä¸­ Î”w7,5 çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This dataset contains a set of training instances that can be used to build a model to predict whether emails are spam or ham (genuine).",
            "zh": "æ­¤æ•°æ®é›†åŒ…å«ä¸€ç»„è®­ç»ƒå®ä¾‹ï¼Œå¯ç”¨äºæ„å»ºæ¨¡å‹æ¥é¢„æµ‹ç”µå­é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯ç«è…¿ï¼ˆçœŸå®ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we take the partial derivative of this with respect to w[0], all the terms that do not contain w[0] are treated as constants, so",
            "zh": "å¦‚æœæˆ‘ä»¬å¯¹ w[0] å–æ­¤çš„åå¯¼æ•°ï¼Œåˆ™æ‰€æœ‰ä¸åŒ…å« w[0] çš„é¡¹éƒ½è¢«è§†ä¸ºå¸¸æ•°ï¼Œå› æ­¤"
        }
    },
    {
        "translation": {
            "en": "Personal data is defined as data that relates to an identified or identifiable individual, who is known as a data subject.",
            "zh": "ä¸ªäººæ•°æ®è¢«å®šä¹‰ä¸ºä¸å·²è¯†åˆ«æˆ–å¯è¯†åˆ«çš„ä¸ªäººï¼ˆç§°ä¸ºæ•°æ®ä¸»ä½“ï¼‰ç›¸å…³çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.1â€…â€…â€…What Is Predictive Data Analytics?",
            "zh": "1.1 ä»€ä¹ˆæ˜¯é¢„æµ‹æ•°æ®åˆ†æï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The data that the features in an ABT contain can be of a number of different types:",
            "zh": "ABT ä¸­çš„è¦ç´ åŒ…å«çš„æ•°æ®å¯ä»¥æ˜¯å¤šç§ä¸åŒçš„ç±»å‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "It is possible to look at the probabilities for each descriptive feature and analyze how that value contributed to the final prediction.",
            "zh": "å¯ä»¥æŸ¥çœ‹æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„æ¦‚ç‡ï¼Œå¹¶åˆ†æè¯¥å€¼å¦‚ä½•å¯¹æœ€ç»ˆé¢„æµ‹åšå‡ºè´¡çŒ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "When this representation learning is successful, the mapping from the representation the output layer receives to the target output is simpler than the mapping from the original input features to the target feature, and this can result in the modelâ€™s being more accurate.",
            "zh": "å½“æ­¤åˆ¶å›¾è¡¨è¾¾å­¦ä¹ æˆåŠŸæ—¶ï¼Œä»è¾“å‡ºå›¾å±‚æ¥æ”¶åˆ°çš„åˆ¶å›¾è¡¨è¾¾åˆ°ç›®æ ‡è¾“å‡ºçš„æ˜ å°„æ¯”ä»åŸå§‹è¾“å…¥è¦ç´ åˆ°ç›®æ ‡ç‰¹å¾çš„æ˜ å°„æ›´ç®€å•ï¼Œè¿™å¯ä»¥ä½¿æ¨¡å‹æ›´åŠ å‡†ç¡®ã€‚"
        }
    },
    {
        "translation": {
            "en": "These methods offer two advantages over basic k-means: they can find initial centroids less likely to lead to sub-optimal clusterings, and they can select initial centroids that allow the algorithm to converge much more quickly than when seeds are randomly chosen.",
            "zh": "ä¸åŸºæœ¬ k å‡å€¼ç›¸æ¯”ï¼Œè¿™äº›æ–¹æ³•å…·æœ‰ä¸¤ä¸ªä¼˜åŠ¿ï¼šå®ƒä»¬å¯ä»¥æ‰¾åˆ°ä¸å¤ªå¯èƒ½å¯¼è‡´æ¬¡ä¼˜èšç±»çš„åˆå§‹è´¨å¿ƒï¼Œå¹¶ä¸”å®ƒä»¬å¯ä»¥é€‰æ‹©åˆå§‹è´¨å¿ƒï¼Œä½¿ç®—æ³•æ¯”éšæœºé€‰æ‹©ç§å­æ—¶æ”¶æ•›å¾—æ›´å¿«ã€‚"
        }
    },
    {
        "translation": {
            "en": "These would act as baseline performance scores that she would try to improve upon.",
            "zh": "è¿™äº›å°†ä½œä¸ºå¥¹å°†å°è¯•æ”¹è¿›çš„åŸºçº¿ç»©æ•ˆåˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second interesting observation about the division of the right-hand side of Bayesâ€™ Theorem by P(Y) is that we can calculate P(Y) in two different ways. First, we can calculate P(Y) directly from a dataset as",
            "zh": "å…³äºè´å¶æ–¯å®šç†å³ä¾§é™¤ä»¥ Pï¼ˆYï¼‰ çš„ç¬¬äºŒä¸ªæœ‰è¶£çš„è§‚å¯Ÿç»“æœæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸¤ç§ä¸åŒçš„æ–¹å¼è®¡ç®— Pï¼ˆYï¼‰ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä»æ•°æ®é›†ä¸­è®¡ç®— Pï¼ˆYï¼‰ ä¸º"
        }
    },
    {
        "translation": {
            "en": "The members of the school basketball team from Figure A.1[746] with one very tall ringer added: (a) the dashed gray line shows the mean of the playersâ€™ heights; and (b) the dashed gray line shows the median of the playersâ€™ heights, with the players ordered by height.",
            "zh": "å›¾A.1[746]ä¸­å­¦æ ¡ç¯®çƒé˜Ÿçš„æˆå‘˜ï¼ŒåŠ ä¸Šä¸€ä¸ªéå¸¸é«˜çš„é“ƒå£°ï¼šï¼ˆaï¼‰ç°è‰²è™šçº¿è¡¨ç¤ºçƒå‘˜èº«é«˜çš„å¹³å‡å€¼;ï¼ˆbï¼‰ç°è‰²è™šçº¿æ˜¾ç¤ºçƒå‘˜èº«é«˜çš„ä¸­ä½æ•°ï¼Œçƒå‘˜æŒ‰èº«é«˜æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "(c)â€“(e) A representation of the changing weights used to generate sample datasets for the first iterations of the boosting process.",
            "zh": "ï¼ˆcï¼‰â€“ï¼ˆeï¼‰ ç”¨äºä¸ºæå‡è¿‡ç¨‹çš„ç¬¬ä¸€æ¬¡è¿­ä»£ç”Ÿæˆæ ·æœ¬æ•°æ®é›†çš„å˜åŒ–æƒé‡çš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "As we will see when we look at the machine learning algorithms covered in Chapters 4[117] to 7[311], the presence of different types of descriptive and target features can have a big impact on how an algorithm works.",
            "zh": "æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬æŸ¥çœ‹ç¬¬ 4 ç« [117] è‡³ 7[311] ä¸­ä»‹ç»çš„æœºå™¨å­¦ä¹ ç®—æ³•æ—¶ï¼Œä¸åŒç±»å‹çš„æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾çš„å­˜åœ¨ä¼šå¯¹ç®—æ³•çš„å·¥ä½œæ–¹å¼äº§ç”Ÿé‡å¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "pass",
            "zh": "é€šè¿‡"
        }
    },
    {
        "translation": {
            "en": "These processing steps are described mathematically in the following equations:",
            "zh": "è¿™äº›å¤„ç†æ­¥éª¤åœ¨ä»¥ä¸‹å…¬å¼ä¸­ä»¥æ•°å­¦æ–¹å¼æè¿°ï¼š"
        }
    },
    {
        "translation": {
            "en": "Apart from the grid nature of the inputs, the rest of the processing within the neuron is the same as previously described in this chapter: the result of a weighted sum of inputs is passed through a non-linear activation function.",
            "zh": "é™¤äº†è¾“å…¥çš„ç½‘æ ¼æ€§è´¨å¤–ï¼Œç¥ç»å…ƒå†…çš„å…¶ä½™å¤„ç†ä¸æœ¬ç« å‰é¢æè¿°çš„ç›¸åŒï¼šè¾“å…¥åŠ æƒå’Œçš„ç»“æœé€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on these frequency counts and proportions, the mode of a categorical feature can be calculated. The mode is a measure of the central tendency of a categorical feature and is simply the most frequent level. Based on the counts in Table A.2[750], the mode of the POSITION feature is guard. We often also calculate a second mode, which is just the second most common level of a feature. In this example, the second mode is forward.",
            "zh": "æ ¹æ®è¿™äº›é¢‘ç‡è®¡æ•°å’Œæ¯”ä¾‹ï¼Œå¯ä»¥è®¡ç®—åˆ†ç±»ç‰¹å¾çš„æ¨¡å¼ã€‚è¯¥æ¨¡å¼æ˜¯åˆ†ç±»ç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿çš„åº¦é‡ï¼Œå¹¶ä¸”åªæ˜¯æœ€å¸¸è§çš„æ°´å¹³ã€‚æ ¹æ®è¡¨ A.2[750] ä¸­çš„è®¡æ•°ï¼ŒPOSITION ç‰¹å¾çš„æ¨¡å¼ä¸º guardã€‚æˆ‘ä»¬é€šå¸¸è¿˜ä¼šè®¡ç®—ç¬¬äºŒç§æ¨¡å¼ï¼Œè¿™åªæ˜¯åŠŸèƒ½çš„ç¬¬äºŒå¸¸è§çº§åˆ«ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œç¬¬äºŒç§æ¨¡å¼æ˜¯è½¬å‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(c)[74] shows a scatter plot of the HEIGHT and AGE features.",
            "zh": "å›¾3.5ï¼ˆcï¼‰[74]æ˜¾ç¤ºäº†HEIGHTå’ŒAGEç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the terms x2 and 2x are treated as constants as they do not include y. Figures C.3(b)[769] and C.3(c)[769] show these partial derivatives.",
            "zh": "å…¶ä¸­é¡¹ x2 å’Œ 2x è¢«è§†ä¸ºå¸¸æ•°ï¼Œå› ä¸ºå®ƒä»¬ä¸åŒ…æ‹¬ yã€‚ å›¾ C.3ï¼ˆbï¼‰[769] å’Œ C.3ï¼ˆcï¼‰[769] æ˜¾ç¤ºäº†è¿™äº›åå¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the majority of ABTs there are multiple continuous features between which we would like to explore relationships.",
            "zh": "åœ¨å¤§å¤šæ•° ABT ä¸­ï¼Œæœ‰å¤šä¸ªè¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬æƒ³æ¢ç´¢å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This ensures that the training set and test set are sufficiently large to train an accurate model and fully evaluate the performance of that model.",
            "zh": "è¿™å¯ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¶³å¤Ÿå¤§ï¼Œå¯ä»¥è®­ç»ƒå‡†ç¡®çš„æ¨¡å‹å¹¶å…¨é¢è¯„ä¼°è¯¥æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "From the feature map in Equation (8.94)[490] we can ascertain that a A = 0 and aB = 255.",
            "zh": "ä»ç­‰å¼ï¼ˆ8.94ï¼‰[490]ä¸­çš„ç‰¹å¾å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®ša A = 0ï¼ŒaB = 255ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each feature takes one of two values, yes or no.",
            "zh": "æ¯ä¸ªè¦ç´ é‡‡ç”¨ä¸¤ä¸ªå€¼ä¹‹ä¸€ï¼Œå³â€œæ˜¯â€æˆ–â€œå¦â€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Reading from left to right, the theorem shows us how to calculate the probability of an event given the evidence we have of that event in terms of the likelihood of the event causing this evidence. This is useful because reasoning from the evidence to events (inverse reasoning) is often much more difficult than reasoning from an event to the evidence it causes (forward reasoning). Bayesâ€™ Theorem allows us to easily swap back and forth between these two types of reasoning.",
            "zh": "ä»å·¦åˆ°å³é˜…è¯»ï¼Œè¯¥å®šç†å‘æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•æ ¹æ®äº‹ä»¶å¯¼è‡´è¯¥è¯æ®çš„å¯èƒ½æ€§æ¥è®¡ç®—äº‹ä»¶çš„æ¦‚ç‡ã€‚è¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºä»è¯æ®åˆ°äº‹ä»¶çš„æ¨ç†ï¼ˆé€†å‘æ¨ç†ï¼‰é€šå¸¸æ¯”ä»äº‹ä»¶åˆ°å®ƒå¼•èµ·çš„è¯æ®ï¼ˆæ­£å‘æ¨ç†ï¼‰è¦å›°éš¾å¾—å¤šã€‚è´å¶æ–¯å®šç†å…è®¸æˆ‘ä»¬è½»æ¾åœ°åœ¨è¿™ä¸¤ç§æ¨ç†ä¹‹é—´æ¥å›åˆ‡æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, they are difficult to generate because of the curse of dimensionality: computing the probability for each cell in a joint probability table requires a set of instances and, because the number of cells grows exponentially as features and feature values are added, so does the size of the dataset required to generate the joint probability distribution.",
            "zh": "å› æ­¤ï¼Œç”±äºç»´åº¦çš„è¯…å’’ï¼Œå®ƒä»¬å¾ˆéš¾ç”Ÿæˆï¼šè®¡ç®—è”åˆæ¦‚ç‡è¡¨ä¸­æ¯ä¸ªåƒå…ƒçš„æ¦‚ç‡éœ€è¦ä¸€ç»„å®ä¾‹ï¼Œå¹¶ä¸”ç”±äºåƒå…ƒçš„æ•°é‡éšç€ç‰¹å¾å’Œç‰¹å¾å€¼çš„å¢åŠ å‘ˆæŒ‡æ•°å¢é•¿ï¼Œå› æ­¤ç”Ÿæˆè”åˆæ¦‚ç‡åˆ†å¸ƒæ‰€éœ€çš„æ•°æ®é›†çš„å¤§å°ä¹Ÿéšä¹‹å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that this plot was generated using input data that had been standardized, and so var(d) = 1.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œæ­¤å›¾æ˜¯ä½¿ç”¨å·²æ ‡å‡†åŒ–çš„è¾“å…¥æ•°æ®ç”Ÿæˆçš„ï¼Œå› æ­¤ varï¼ˆdï¼‰ = 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.3â€…â€…â€…A simple retail dataset.",
            "zh": "1.3 ä¸€ä¸ªç®€å•çš„é›¶å”®æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, Cybenko (1988) proved that a network with at least three layers (two hidden and one output) using sigmoid activation functions can approximate any function (not just bounded continuous functions) with arbitrary accuracy.",
            "zh": "æ­¤å¤–ï¼ŒCybenkoï¼ˆ1988ï¼‰è¯æ˜ï¼Œä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°çš„è‡³å°‘ä¸‰å±‚ï¼ˆä¸¤ä¸ªéšè—å’Œä¸€ä¸ªè¾“å‡ºï¼‰çš„ç½‘ç»œå¯ä»¥ä»»æ„ç²¾åº¦è¿‘ä¼¼ä»»ä½•å‡½æ•°ï¼ˆä¸ä»…ä»…æ˜¯æœ‰ç•Œè¿ç»­å‡½æ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.8â€…â€…â€…Calculating covariance.",
            "zh": "3.8 è®¡ç®—åæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "recurrent neural network, 434, 499",
            "zh": "é€’å½’ç¥ç»ç½‘ç»œï¼Œ434,499"
        }
    },
    {
        "translation": {
            "en": "bimodal distribution, 60",
            "zh": "åŒå³°åˆ†å¸ƒï¼Œ60"
        }
    },
    {
        "translation": {
            "en": "The weights used in this aggregation are the confidence factors associated with each model.",
            "zh": "æ­¤èšåˆä¸­ä½¿ç”¨çš„æƒé‡æ˜¯ä¸æ¯ä¸ªæ¨¡å‹å…³è”çš„ç½®ä¿¡å› å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A graph illustrating how the value of a binary log (the log to the base 2) of a probability changes across the range of probability values; and (b) the impact of multiplying these values by âˆ’ 1.",
            "zh": "ï¼ˆaï¼‰ è¯´æ˜æ¦‚ç‡çš„äºŒè¿›åˆ¶å¯¹æ•°ï¼ˆä»¥ 2 ä¸ºåŸºæ•°çš„å¯¹æ•°ï¼‰çš„å€¼åœ¨æ¦‚ç‡å€¼èŒƒå›´å†…å¦‚ä½•å˜åŒ–çš„å›¾è¡¨;ï¼ˆbï¼‰å°†è¿™äº›å€¼ä¹˜ä»¥âˆ’1çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate these error gradients we must backpropagate âˆ‚â„°/âˆ‚oâ€¡ through a tanh layer and then merge the resulting gradients with the error gradients from the next time-step with respect to the current cell state.",
            "zh": "ä¸ºäº†è®¡ç®—è¿™äº›è¯¯å·®æ¢¯åº¦ï¼Œæˆ‘ä»¬å¿…é¡»é€šè¿‡tanhå±‚åå‘ä¼ æ’­âˆ‚E/âˆ‚oâ€¡ï¼Œç„¶åå°†å¾—åˆ°çš„æ¢¯åº¦ä¸ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¯¯å·®æ¢¯åº¦åˆå¹¶åˆ°å½“å‰å•å…ƒçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "How many new numbers the customer is frequently calling this month",
            "zh": "å®¢æˆ·æœ¬æœˆç»å¸¸æ‹¨æ‰“å¤šå°‘ä¸ªæ–°å·ç "
        }
    },
    {
        "translation": {
            "en": "Cross validation approaches are generally preferred unless datasets are very large, in which case the likelihood of the lucky split becomes very low, and hold-out approaches can be used.",
            "zh": "äº¤å‰éªŒè¯æ–¹æ³•é€šå¸¸æ˜¯é¦–é€‰ï¼Œé™¤éæ•°æ®é›†éå¸¸å¤§ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¹¸è¿åˆ†è£‚çš„å¯èƒ½æ€§å˜å¾—éå¸¸ä½ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ä¿ç•™æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cardano, Gerolamo, 243",
            "zh": "å¡å°”è¾¾è¯ºï¼Œæ°ç½—æ‹‰è«ï¼Œ243"
        }
    },
    {
        "translation": {
            "en": "It is extremely important that the system not in any way slow the production line and that the possibility of defective components being passed by the system be minimized as much as possible.",
            "zh": "æå…¶é‡è¦çš„æ˜¯ï¼Œç³»ç»Ÿä¸èƒ½ä»¥ä»»ä½•æ–¹å¼å‡æ…¢ç”Ÿäº§çº¿çš„é€Ÿåº¦ï¼Œå¹¶å°½å¯èƒ½å‡å°‘ç³»ç»Ÿé€šè¿‡ç¼ºé™·éƒ¨ä»¶çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the beginning of the first episode of the Q-learning process (Line 13[658]), the agent is placed in the starting cell in the grid world (s0 = 0-3).",
            "zh": "åœ¨ Q å­¦ä¹ è¿‡ç¨‹çš„ç¬¬ä¸€é›†ï¼ˆç¬¬ 13 è¡Œ[658]ï¼‰å¼€å§‹æ—¶ï¼Œæ™ºèƒ½ä½“è¢«æ”¾ç½®åœ¨ç½‘æ ¼ä¸–ç•Œçš„èµ·å§‹å•å…ƒä¸­ ï¼ˆs0 = 0-3ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Richter and Weber (2013) is a good introduction, and overview, to CBR.",
            "zh": "Richter and Weber ï¼ˆ2013ï¼‰ æ˜¯å¯¹ CBR çš„ä¸€ä¸ªå¾ˆå¥½çš„ä»‹ç»å’Œæ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Accuracy can often be related to the power of a machine learning algorithm to capture the interaction between descriptive features and the target feature.",
            "zh": "å‡†ç¡®æ€§é€šå¸¸ä¸æœºå™¨å­¦ä¹ ç®—æ³•æ•è·æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„äº¤äº’çš„èƒ½åŠ›æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before going any further, Ross had to define the prediction subject for the ABT and the target feature. The goal was to develop a model that would predict whether a customer would churn in the coming months. This meant that the prediction subject in this case was a customer, so the ABT would need to be built to contain one row per customer.",
            "zh": "åœ¨ç»§ç»­ä¹‹å‰ï¼ŒRoss å¿…é¡»å®šä¹‰ ABT çš„é¢„æµ‹ä¸»é¢˜å’Œç›®æ ‡ç‰¹å¾ã€‚ç›®æ ‡æ˜¯å¼€å‘ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šåœ¨æœªæ¥å‡ ä¸ªæœˆå†…æµå¤±ã€‚è¿™æ„å‘³ç€åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢„æµ‹ä¸»ä½“æ˜¯å®¢æˆ·ï¼Œå› æ­¤éœ€è¦å°† ABT æ„å»ºä¸ºåŒ…å«æ¯ä¸ªå®¢æˆ·ä¸€è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "WINE",
            "zh": "é…’"
        }
    },
    {
        "translation": {
            "en": "The goal of the intelligent agent is to complete a task as successfully as possible. To frame the reinforcement learning problem, this needs to be more formally definedâ€”what does it mean to successfully complete a task? The next section explores this.",
            "zh": "æ™ºèƒ½ä»£ç†çš„ç›®æ ‡æ˜¯å°½å¯èƒ½æˆåŠŸåœ°å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†æ„å»ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œéœ€è¦æ›´æ­£å¼åœ°å®šä¹‰è¿™ä¸€ç‚¹â€”â€”æˆåŠŸå®Œæˆä»»åŠ¡æ„å‘³ç€ä»€ä¹ˆï¼Ÿä¸‹ä¸€èŠ‚å°†å¯¹æ­¤è¿›è¡Œæ¢è®¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, AGE is being virtually ignored by the metric.",
            "zh": "å› æ­¤ï¼Œè¯¥æŒ‡æ ‡å‡ ä¹å¿½ç•¥äº† AGEã€‚"
        }
    },
    {
        "translation": {
            "en": "A Markov chain is a system that has a set of finite states and a set of transition probabilities that define the likelihood of the system moving from one state to another.",
            "zh": "é©¬å°”å¯å¤«é“¾æ˜¯ä¸€ä¸ªç³»ç»Ÿï¼Œå®ƒå…·æœ‰ä¸€ç»„æœ‰é™çŠ¶æ€å’Œä¸€ç»„è½¬ç§»æ¦‚ç‡ï¼Œè¿™äº›æ¦‚ç‡å®šä¹‰äº†ç³»ç»Ÿä»ä¸€ä¸ªçŠ¶æ€ç§»åŠ¨åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "treatment group, 583",
            "zh": "æ²»ç–—ç»„ï¼Œ583"
        }
    },
    {
        "translation": {
            "en": "So the algorithm then searches the tree looking for instances that are closer to the query than the instance stored in best (Lines 4-11 of the algorithm control this search).",
            "zh": "å› æ­¤ï¼Œè¯¥ç®—æ³•éšåæœç´¢æ ‘ï¼ŒæŸ¥æ‰¾æ¯”å­˜å‚¨åœ¨ best ä¸­çš„å®ä¾‹æ›´æ¥è¿‘æŸ¥è¯¢çš„å®ä¾‹ï¼ˆç®—æ³•çš„ç¬¬ 4-11 è¡Œæ§åˆ¶æ­¤æœç´¢ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If two events X and Y are independent, then",
            "zh": "å¦‚æœä¸¤ä¸ªäº‹ä»¶ X å’Œ Y æ˜¯ç‹¬ç«‹çš„ï¼Œåˆ™"
        }
    },
    {
        "translation": {
            "en": "irrelevant features, 227",
            "zh": "ä¸ç›¸å…³çš„åŠŸèƒ½ï¼Œ227"
        }
    },
    {
        "translation": {
            "en": "Figure 5.2",
            "zh": "å›¾ 5.2"
        }
    },
    {
        "translation": {
            "en": "10.4.4â€…â€…â€…Understanding Clustering Results",
            "zh": "10.4.4 äº†è§£èšç±»ç»“æœ"
        }
    },
    {
        "translation": {
            "en": "Friedman, J., T. Hastie, and R. Tibshirani. 2001. The elements of statistical learning, Vol. 1. Springer.",
            "zh": "å¼—é‡Œå¾·æ›¼ï¼ŒJ.ï¼ŒT.å“ˆæ–¯è’‚å’ŒR.è’‚å¸ƒå¸Œæ‹‰å°¼ã€‚2001. ç»Ÿè®¡å­¦ä¹ çš„è¦ç´ ï¼Œç¬¬ 1 å·ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.37",
            "zh": "å›¾ 8.37"
        }
    },
    {
        "translation": {
            "en": "It is standard that hidden state h and the cell state c have the same size.",
            "zh": "éšè—çŠ¶æ€ h å’Œå•å…ƒçŠ¶æ€ c å…·æœ‰ç›¸åŒçš„å¤§å°æ˜¯æ ‡å‡†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first thing we need to do is figure out how many different possible models actually exist for the scenario.",
            "zh": "æˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å¼„æ¸…æ¥šè¯¥åœºæ™¯å®é™…ä¸Šå­˜åœ¨å¤šå°‘ç§ä¸åŒçš„å¯èƒ½æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This vertical concatenation operation is illustrated in Figure 8.6[393] with d[0] added to the activation matrix as it is propagated forward from one layer to the next.",
            "zh": "è¿™ç§å‚ç›´ä¸²è”æ“ä½œå¦‚å›¾8.6[393]æ‰€ç¤ºï¼Œå½“æ¿€æ´»çŸ©é˜µä»ä¸€å±‚å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€å±‚æ—¶ï¼Œå°†d[0]æ·»åŠ åˆ°æ¿€æ´»çŸ©é˜µä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "The collection limitation principle states that personal data should only be obtained by lawful means with the knowledge and consent of a data subject.",
            "zh": "æ”¶é›†é™åˆ¶åŸåˆ™è§„å®šï¼Œä¸ªäººæ•°æ®åªèƒ½åœ¨æ•°æ®ä¸»ä½“çŸ¥æƒ…å’ŒåŒæ„çš„æƒ…å†µä¸‹é€šè¿‡åˆæ³•æ–¹å¼è·å–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5(b)[273] shows a histogram of the same dataset after some outliers have been added to the extreme right of the distribution.",
            "zh": "å›¾ 6.5ï¼ˆbï¼‰[273] æ˜¾ç¤ºäº†å°†ä¸€äº›å¼‚å¸¸å€¼æ·»åŠ åˆ°åˆ†å¸ƒçš„æœ€å³ä¾§ååŒä¸€æ•°æ®é›†çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The use of prior probabilities in Bayesâ€™ Theorem is what distinguishes between Bayesian and maximum likelihood approaches to probability.",
            "zh": "åœ¨è´å¶æ–¯å®šç†ä¸­ä½¿ç”¨å…ˆéªŒæ¦‚ç‡æ˜¯åŒºåˆ†è´å¶æ–¯æ¦‚ç‡æ–¹æ³•å’Œæœ€å¤§ä¼¼ç„¶æ–¹æ³•çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "derivative, 765",
            "zh": "è¡ç”Ÿç‰©ï¼Œ765"
        }
    },
    {
        "translation": {
            "en": "LC record available at https://lccn.loc.gov/2020002998",
            "zh": "LC è®°å½•å¯åœ¨ https://lccn.loc.gov/2020002998"
        }
    },
    {
        "translation": {
            "en": "The last step in deployment was to put in place an ongoing model validation plan to raise an alarm if evidence arose indicating that the deployed model had gone stale.",
            "zh": "éƒ¨ç½²çš„æœ€åä¸€æ­¥æ˜¯åˆ¶å®šä¸€ä¸ªæŒç»­çš„æ¨¡å‹éªŒè¯è®¡åˆ’ï¼Œä»¥ä¾¿åœ¨å‡ºç°è¯æ®è¡¨æ˜éƒ¨ç½²çš„æ¨¡å‹å·²ç»è¿‡æ—¶æ—¶å‘å‡ºè­¦æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "As with any other significant project, the chances of success for a predictive data analytics project are greatly increased if a standard process is used to manage the project through the project lifecycle.",
            "zh": "ä¸ä»»ä½•å…¶ä»–é‡è¦é¡¹ç›®ä¸€æ ·ï¼Œå¦‚æœåœ¨æ•´ä¸ªé¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸­ä½¿ç”¨æ ‡å‡†æµç¨‹æ¥ç®¡ç†é¡¹ç›®ï¼Œåˆ™é¢„æµ‹æ€§æ•°æ®åˆ†æé¡¹ç›®çš„æˆåŠŸæœºä¼šå°†å¤§å¤§å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The backpropagation algorithm solves the blame assignment problem.",
            "zh": "åå‘ä¼ æ’­ç®—æ³•è§£å†³äº†å½’å’åˆ†é…é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "When moving fast, the car moves forward two cells per time-step; when moving slowly the car moves forward one cell per time-step; and when stationary does not move forward at all.",
            "zh": "å¿«é€Ÿè¡Œé©¶æ—¶ï¼Œæ±½è½¦æ¯æ—¶é—´æ­¥å‘å‰ç§»åŠ¨ä¸¤ä¸ªå•å…ƒæ ¼;ç¼“æ…¢è¡Œé©¶æ—¶ï¼Œæ±½è½¦æ¯æ—¶é—´æ­¥å‘å‰ç§»åŠ¨ä¸€ä¸ªå•å…ƒæ ¼;é™æ­¢æ—¶æ ¹æœ¬ä¸å‘å‰ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "447.14",
            "zh": "447.14"
        }
    },
    {
        "translation": {
            "en": "The time it takes for the Markov chain to forget the initial random state is called the mixing time.",
            "zh": "é©¬å°”å¯å¤«é“¾å¿˜è®°åˆå§‹éšæœºçŠ¶æ€æ‰€éœ€çš„æ—¶é—´ç§°ä¸ºæ··åˆæ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.15â€…â€…â€…The LOAN AMOUNT continuous feature discretized into four equal-frequency bins.",
            "zh": "6.15 LOAN AMOUNT è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºå››ä¸ªç­‰é¢‘ç®±ã€‚"
        }
    },
    {
        "translation": {
            "en": "This MDP captures the dynamics of the TwentyTwos game, and it also hints toward some strategies for successful play. For example, choosing to Stick when the value of the playerâ€™s hand is low and the value of the dealerâ€™s hand is high, state PL-DH, rarely leads to the player winning, . The MDP alone, however, is not sufficient to describe optimal behavior for successfully playing the game. The next section describes how an MDP can be used as the basis for reasoning about optimal behavior.",
            "zh": "è¿™ä¸ª MDP æ•æ‰äº† TwentyTwos æ¸¸æˆçš„åŠ¨æ€ï¼Œå®ƒè¿˜æš—ç¤ºäº†ä¸€äº›æˆåŠŸæ¸¸æˆçš„ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œå½“ç©å®¶çš„æ‰‹ç‰Œä»·å€¼è¾ƒä½è€Œåº„å®¶æ‰‹ç‰Œçš„ä»·å€¼è¾ƒé«˜æ—¶é€‰æ‹©åšæŒï¼ŒçŠ¶æ€PL-DHï¼Œå¾ˆå°‘ä¼šå¯¼è‡´ç©å®¶è·èƒœï¼Œã€‚ç„¶è€Œï¼Œä»…é  MDP ä¸è¶³ä»¥æè¿°æˆåŠŸç©æ¸¸æˆçš„æœ€ä½³è¡Œä¸ºã€‚ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¦‚ä½•å°† MDP ç”¨ä½œæ¨ç†æœ€ä½³è¡Œä¸ºçš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recurrent networks also use weight sharing with the same weight matrices being reused at each time-step in a sequence.",
            "zh": "å¾ªç¯ç½‘ç»œè¿˜ä½¿ç”¨æƒé‡å…±äº«ï¼Œåœ¨åºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥é‡ç”¨ç›¸åŒçš„æƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Mitchell, T. 1997. Machine learning. McGraw Hill.",
            "zh": "ç±³åˆ‡å°”ï¼ŒT. 1997 å¹´ã€‚æœºå™¨å­¦ä¹ ã€‚éº¦æ ¼åŠ³Â·å¸Œå°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "An RGB image has three channels, and a grayscale image will have one channel.",
            "zh": "RGB å›¾åƒæœ‰ä¸‰ä¸ªé€šé“ï¼Œç°åº¦å›¾åƒå°†æœ‰ä¸€ä¸ªé€šé“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The motivation for structuring these technical chapters in two parts is that it provides a natural break in the chapter material.",
            "zh": "å°†è¿™äº›æŠ€æœ¯ç« èŠ‚åˆ†ä¸ºä¸¤éƒ¨åˆ†çš„åŠ¨æœºæ˜¯ï¼Œå®ƒä¸ºç« èŠ‚ææ–™æä¾›äº†ä¸€ä¸ªè‡ªç„¶çš„ä¸­æ–­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Black segments represent weights that have increased, and gray segments represent weights that have decreased (all segments for the distribution at the first iteration are white because they have done neither).",
            "zh": "é»‘è‰²æ®µè¡¨ç¤ºå·²å¢åŠ çš„æƒé‡ï¼Œç°è‰²æ®µè¡¨ç¤ºå·²å‡å°‘çš„æƒé‡ï¼ˆç¬¬ä¸€æ¬¡è¿­ä»£æ—¶åˆ†å¸ƒçš„æ‰€æœ‰æ®µå‡ä¸ºç™½è‰²ï¼Œå› ä¸ºå®ƒä»¬ä¸¤è€…éƒ½æ²¡æœ‰æ‰§è¡Œä»»ä½•æ“ä½œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM",
            "zh": "CRISP-DMå‹"
        }
    },
    {
        "translation": {
            "en": "fit, 315, 367",
            "zh": "é€‚åˆï¼Œ 315ï¼Œ 367"
        }
    },
    {
        "translation": {
            "en": "11.1â€…â€…â€…An agent behaving in an environment and the observation, reward, action cycle. The transition from observations of the environment to a state is shown by the state generation function, Ï†.",
            "zh": "11.1 æ™ºèƒ½ä½“åœ¨ç¯å¢ƒä¸­çš„è¡Œä¸ºä»¥åŠè§‚å¯Ÿã€å¥–åŠ±ã€è¡ŒåŠ¨å‘¨æœŸã€‚ä»ç¯å¢ƒè§‚å¯Ÿåˆ°çŠ¶æ€çš„è½¬å˜ç”±çŠ¶æ€ç”Ÿæˆå‡½æ•° Ï† è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "AT already had a customer retention team proactively making interventions in an effort to reduce customer churn.",
            "zh": "ATå·²ç»æœ‰ä¸€ä¸ªå®¢æˆ·ä¿ç•™å›¢é˜Ÿï¼Œç§¯æä¸»åŠ¨åœ°è¿›è¡Œå¹²é¢„ï¼Œä»¥å‡å°‘å®¢æˆ·æµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, leaf nodes with small variance in the target feature values across the set of instances at the node are preferred over leaf nodes where the variance in the target feature values across the set of instances at the node is large.",
            "zh": "å› æ­¤ï¼ŒèŠ‚ç‚¹ä¸Šå®ä¾‹é›†çš„ç›®æ ‡ç‰¹å¾å€¼æ–¹å·®è¾ƒå°çš„å¶èŠ‚ç‚¹ä¼˜å…ˆäºèŠ‚ç‚¹ä¸Šå®ä¾‹é›†çš„ç›®æ ‡ç‰¹å¾å€¼æ–¹å·®è¾ƒå¤§çš„å¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agglomerative hierarchical clustering (AHC) algorithm is a simple, effective, bottom-up clustering approach that is driven by local structure within a dataset rather than a global expectation of what a cluster structure should be. A pseudocode description of the AHC algorithm is given in Algorithm 9[601].",
            "zh": "é›†èšåˆ†å±‚èšç±» ï¼ˆAHCï¼‰ ç®—æ³•æ˜¯ä¸€ç§ç®€å•ã€æœ‰æ•ˆã€è‡ªä¸‹è€Œä¸Šçš„èšç±»æ–¹æ³•ï¼Œå®ƒç”±æ•°æ®é›†ä¸­çš„å±€éƒ¨ç»“æ„é©±åŠ¨ï¼Œè€Œä¸æ˜¯å¯¹èšç±»ç»“æ„çš„å…¨å±€æœŸæœ›ã€‚AHCç®—æ³•çš„ä¼ªä»£ç æè¿°åœ¨ç®—æ³•9[601]ä¸­ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we presented a range of measures of similarity, including distance metrics (such as the Euclidean, Manhattan, and Mahalanobis) and similarity indexes (such as the Russel-Rao, Sokal-Michener, Jaccard, and Cosine).",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç³»åˆ—ç›¸ä¼¼åº¦é‡ï¼ŒåŒ…æ‹¬è·ç¦»åº¦é‡ï¼ˆå¦‚æ¬§å‡ é‡Œå¾—ã€æ›¼å“ˆé¡¿å’Œé©¬å“ˆæ‹‰è¯ºæ¯”æ–¯ï¼‰å’Œç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆå¦‚ç½—ç´ -æ‹‰å¥¥ã€ç´¢å¡å°”-ç±³åˆ‡çº³ã€æ°å¡å¾·å’Œä½™å¼¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.26",
            "zh": "å›¾ 8.26"
        }
    },
    {
        "translation": {
            "en": "Notice that in this domain representation, we blend different approaches to continuous features: we are retaining the PDFs developed in Section 6.4.2[269] for the ACCOUNT BALANCE feature and extend the representation with the binned version of the LOAN AMOUNT feature, BINNED LOAN AMOUNT.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨æ­¤åŸŸè¡¨ç¤ºä¸­ï¼Œæˆ‘ä»¬æ··åˆäº†è¿ç»­åŠŸèƒ½çš„ä¸åŒæ–¹æ³•ï¼šæˆ‘ä»¬ä¿ç•™äº†ç¬¬ 6.4.2 èŠ‚ä¸­ä¸º ACCOUNT BALANCE åŠŸèƒ½å¼€å‘çš„ PDFï¼Œå¹¶ä½¿ç”¨ LOAN AMOUNT åŠŸèƒ½çš„ binned ç‰ˆæœ¬ BINNED LOAN AMOUNT æ‰©å±•äº†è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "These experiments were performed in Nancy and confirmed, to the satisfaction of everyone involved, that N rays did indeed exist.",
            "zh": "è¿™äº›å®éªŒæ˜¯åœ¨å—é”¡è¿›è¡Œçš„ï¼Œå¹¶è¯å®äº†Nå°„çº¿ç¡®å®å­˜åœ¨ï¼Œè¿™è®©æ‰€æœ‰å‚ä¸è€…éƒ½æ„Ÿåˆ°æ»¡æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A large set of historical labeled data is available for training the system.",
            "zh": "å¤§é‡å†å²æ ‡è®°æ•°æ®å¯ç”¨äºè®­ç»ƒç³»ç»Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Spercher, David A. 1965. On the structure of continuous functions of several variables. Transactions of teh American Mathematical Society 115 (3): 340â€“355.",
            "zh": "æ–¯ç€å½»ï¼Œå¤§å« A. 1965 å¹´ã€‚å…³äºå‡ ä¸ªå˜é‡çš„è¿ç»­å‡½æ•°çš„ç»“æ„ã€‚ç¾å›½æ•°å­¦ä¼šå­¦æŠ¥ 115 ï¼ˆ3ï¼‰ï¼š340â€“355ã€‚"
        }
    },
    {
        "translation": {
            "en": "To my family.",
            "zh": "ç»™æˆ‘çš„å®¶äººã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Have recorded any data quality issues due to valid data in a data quality plan along with potential handling strategies.",
            "zh": "4. åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­è®°å½•äº†ç”±äºæœ‰æ•ˆæ•°æ®è€Œå¯¼è‡´çš„ä»»ä½•æ•°æ®è´¨é‡é—®é¢˜ä»¥åŠå¯èƒ½çš„å¤„ç†ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The observation period is the time before the claim event, across which the descriptive features capturing the claimantâ€™s behavior are calculated, while the outcome period is the time immediately after the claim event, during which it will emerge whether the claim is fraudulent or genuine.",
            "zh": "è§‚å¯ŸæœŸæ˜¯ç´¢èµ”äº‹ä»¶å‘ç”Ÿå‰çš„æ—¶é—´ï¼Œåœ¨æ­¤æœŸé—´è®¡ç®—æ•è·ç´¢èµ”äººè¡Œä¸ºçš„æè¿°æ€§ç‰¹å¾ï¼Œè€Œç»“æœæœŸæ˜¯ç´¢èµ”äº‹ä»¶å‘ç”Ÿåç«‹å³å‡ºç°çš„æ—¶é—´ï¼Œåœ¨æ­¤æœŸé—´ï¼Œç´¢èµ”æ˜¯æ¬ºè¯ˆæ€§çš„è¿˜æ˜¯çœŸå®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is the overall lifetime value of a customer?",
            "zh": "å®¢æˆ·çš„æ•´ä½“ç”Ÿå‘½å‘¨æœŸä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The distribution defined by a Bayesian network doesnâ€™t change during Gibbs sampling, so this requirement always holds in this context.",
            "zh": "è´å¶æ–¯ç½‘ç»œå®šä¹‰çš„åˆ†å¸ƒåœ¨å‰å¸ƒæ–¯é‡‡æ ·æœŸé—´ä¸ä¼šæ”¹å˜ï¼Œå› æ­¤æ­¤è¦æ±‚åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­å§‹ç»ˆæˆç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can continue to build the tree by recursively extending each branch as we did in the previous decision tree examples.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡é€’å½’æ‰©å±•æ¯ä¸ªåˆ†æ”¯æ¥ç»§ç»­æ„å»ºæ ‘ï¼Œå°±åƒæˆ‘ä»¬åœ¨å‰é¢çš„å†³ç­–æ ‘ç¤ºä¾‹ä¸­æ‰€åšçš„é‚£æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "For every possible combination of weights, w[0] and w[1], there is a corresponding sum of squared errors value.",
            "zh": "å¯¹äºæƒé‡ w[0] å’Œ w[1] çš„æ¯ä¸ªå¯èƒ½ç»„åˆï¼Œéƒ½æœ‰ä¸€ä¸ªç›¸åº”çš„è¯¯å·®å€¼çš„å¹³æ–¹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "In preparation for this campaign, the financial institution has decided to create a nearest neighbor model using a Euclidean distance metric to predict which customers are most likely to respond to direct marketing.",
            "zh": "ä¸ºäº†å‡†å¤‡æ­¤æ´»åŠ¨ï¼Œè¯¥é‡‘èæœºæ„å†³å®šä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»åº¦é‡åˆ›å»ºä¸€ä¸ªæœ€è¿‘é‚»æ¨¡å‹ï¼Œä»¥é¢„æµ‹å“ªäº›å®¢æˆ·æœ€æœ‰å¯èƒ½å¯¹ç›´æ¥è¥é”€åšå‡ºååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.5[266] lists the relevant probabilities needed to make a prediction for this query, and the calculation of the scores for each of the possible target levels.",
            "zh": "è¡¨ 6.5[266] åˆ—å‡ºäº†å¯¹æ­¤æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ï¼Œä»¥åŠæ¯ä¸ªå¯èƒ½çš„ç›®æ ‡æ°´å¹³çš„åˆ†æ•°è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.3.2â€ƒKolmogorov-Smirnov statisticâ€ƒThe Kolmogorov-Smirnov statistic (K-S statistic) is another performance measure that captures the separation between the distribution of prediction scores for the different target levels in a classification problem. To calculate the K-S statistic, we first determine the cumulative probability distributions of the prediction scores for the positive and negative target levels. This is done as follows:",
            "zh": "9.4.3.2 Kolmogorov-Smirnov ç»Ÿè®¡é‡ Kolmogorov-Smirnov ç»Ÿè®¡é‡ï¼ˆK-S ç»Ÿè®¡é‡ï¼‰æ˜¯å¦ä¸€ç§æ€§èƒ½åº¦é‡ï¼Œç”¨äºæ•è·åˆ†ç±»é—®é¢˜ä¸­ä¸åŒç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒä¹‹é—´çš„åˆ†ç¦»ã€‚ä¸ºäº†è®¡ç®— K-S ç»Ÿè®¡é‡ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šæ­£è´Ÿç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ†æ•°çš„ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒã€‚å…·ä½“æ“ä½œå¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "domain concept, 23, 30, 45, 688, 689, 707",
            "zh": "åŸŸæ¦‚å¿µï¼Œ 23ï¼Œ 30ï¼Œ 45ï¼Œ 688ï¼Œ 689ï¼Œ 707"
        }
    },
    {
        "translation": {
            "en": "Table 4.6",
            "zh": "è¡¨ 4.6"
        }
    },
    {
        "translation": {
            "en": "Categorical cross entropy is another loss function that is commonly used for classification models. Categorical cross entropy is defined as",
            "zh": "åˆ†ç±»äº¤å‰ç†µæ˜¯å¦ä¸€ä¸ªå¸¸ç”¨äºåˆ†ç±»æ¨¡å‹çš„æŸå¤±å‡½æ•°ã€‚åˆ†ç±»äº¤å‰ç†µå®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "Scaling a weight update using a learning rate works because the error derivative defines only the direction the weight update should take and not the update size; and, scaling by the learning rate changes only the step size and not the direction of the update.",
            "zh": "ä½¿ç”¨å­¦ä¹ ç‡ç¼©æ”¾æƒé‡æ›´æ–°æ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºè¯¯å·®å¯¼æ•°ä»…å®šä¹‰æƒé‡æ›´æ–°åº”é‡‡å–çš„æ–¹å‘ï¼Œè€Œä¸æ˜¯æ›´æ–°å¤§å°;è€Œä¸”ï¼ŒæŒ‰å­¦ä¹ ç‡ç¼©æ”¾åªä¼šæ”¹å˜æ­¥é•¿ï¼Œè€Œä¸ä¼šæ”¹å˜æ›´æ–°çš„æ–¹å‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, for a categorical feature with N levels, we need only N âˆ’ 1 probabilities in each row, with the final probability being understood as equal to 1 minus the sum of the other N âˆ’ 1 probabilities.",
            "zh": "å› æ­¤ï¼Œå¯¹äºå…·æœ‰ N ä¸ªæ°´å¹³çš„åˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬åªéœ€è¦æ¯è¡Œ N âˆ’ 1 ä¸ªæ¦‚ç‡ï¼Œæœ€ç»ˆæ¦‚ç‡è¢«ç†è§£ä¸ºç­‰äº 1 å‡å»å…¶ä»– N âˆ’ 1 ä¸ªæ¦‚ç‡çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "If we have sampled our weights from a distribution with mean 0, then E(W) = 0, and if the inputs have been standardized, then E(d) = 0, and so the Equation (8.56)[455] simplifies to",
            "zh": "å¦‚æœæˆ‘ä»¬ä»å‡å€¼ä¸º 0 çš„åˆ†å¸ƒä¸­æŠ½å–æƒé‡ï¼Œåˆ™ Eï¼ˆWï¼‰ = 0ï¼Œå¦‚æœè¾“å…¥å·²æ ‡å‡†åŒ–ï¼Œåˆ™ Eï¼ˆdï¼‰ = 0ï¼Œå› æ­¤æ–¹ç¨‹ ï¼ˆ8.56ï¼‰[455] ç®€åŒ–ä¸º"
        }
    },
    {
        "translation": {
            "en": "Once a threshold has been set, the continuous feature can compete with the other categorical features for selection as the splitting feature at any node.",
            "zh": "è®¾ç½®é˜ˆå€¼åï¼Œè¿ç»­ç‰¹å¾å¯ä»¥ä¸å…¶ä»–åˆ†ç±»ç‰¹å¾ç«äº‰ï¼Œä»¥é€‰æ‹©ä½œä¸ºä»»ä½•èŠ‚ç‚¹çš„åˆ†å‰²ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "SVM models are trained in a slightly different way than regression models, but the concepts underpinning both approaches are similar.",
            "zh": "SVM æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ä¸å›å½’æ¨¡å‹ç•¥æœ‰ä¸åŒï¼Œä½†æ”¯æŒè¿™ä¸¤ç§æ–¹æ³•çš„æ¦‚å¿µæ˜¯ç›¸ä¼¼çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. Stoughton et al. (2002) provides an in-depth discussion of the data collected by the SDSS. A shorter overview is provided at skyserver.sdss3.org/dr9/en/sdss/data/data.asp.",
            "zh": "6. Stoughtonç­‰äººï¼ˆ2002å¹´ï¼‰å¯¹SDSSæ”¶é›†çš„æ•°æ®è¿›è¡Œäº†æ·±å…¥è®¨è®ºã€‚skyserver.sdss3.org/dr9/en/sdss/data/data.asp æä¾›äº†è¾ƒçŸ­çš„æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.20[358] shows three one-versus-all prediction models for a prediction problem with three target levels (these models are based on the dataset in Table 7.11[359] that is introduced subsequently in this section).",
            "zh": "å›¾ 7.20[358] æ˜¾ç¤ºäº†å…·æœ‰ä¸‰ä¸ªç›®æ ‡æ°´å¹³çš„é¢„æµ‹é—®é¢˜çš„ä¸‰ç§ä¸€å¯¹ä¸€é¢„æµ‹æ¨¡å‹ï¼ˆè¿™äº›æ¨¡å‹åŸºäºè¡¨ 7.11[359] ä¸­çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å°†åœ¨æœ¬èŠ‚åé¢ä»‹ç»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "concept drift, 232, 578, 579, 657, 727",
            "zh": "æ¦‚å¿µæ¼‚ç§»ï¼Œ 232ï¼Œ 578ï¼Œ 579ï¼Œ 657ï¼Œ 727"
        }
    },
    {
        "translation": {
            "en": "Another factor that can help us deal with the curse of dimensionality is that some learning algorithms have a natural resistance to the problem.",
            "zh": "å¦ä¸€ä¸ªå¯ä»¥å¸®åŠ©æˆ‘ä»¬åº”å¯¹ç»´åº¦è¯…å’’çš„å› ç´ æ˜¯ï¼Œä¸€äº›å­¦ä¹ ç®—æ³•å¯¹è¿™ä¸ªé—®é¢˜æœ‰ä¸€ç§å¤©ç„¶çš„æŠµæŠ—åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.6",
            "zh": "å›¾ 5.6"
        }
    },
    {
        "translation": {
            "en": "soft margin, 366",
            "zh": "è½¯è¾¹è·ï¼Œ366"
        }
    },
    {
        "translation": {
            "en": "15. The reuse of the term batch in mini-batch learning can lead to confusion. To clarify the distinctive meanings: the terms batch learning or batch gradient descent typically indicate that the entire training set is processed between each weight update, whereas the term batch can also be used to indicate a set of examples in a mini-batch training regime (as in a batch of examples), and the term batch size describes the number of examples in each batch (or mini-batch).",
            "zh": "15. åœ¨å°æ‰¹é‡å­¦ä¹ ä¸­é‡å¤ä½¿ç”¨æœ¯è¯­â€œæ‰¹å¤„ç†â€ä¼šå¯¼è‡´æ··æ·†ã€‚ä¸ºäº†é˜æ˜ä¸åŒçš„å«ä¹‰ï¼šæœ¯è¯­â€œæ‰¹é‡å­¦ä¹ â€æˆ–â€œæ‰¹é‡æ¢¯åº¦ä¸‹é™â€é€šå¸¸è¡¨ç¤ºåœ¨æ¯æ¬¡æƒé‡æ›´æ–°ä¹‹é—´å¤„ç†æ•´ä¸ªè®­ç»ƒé›†ï¼Œè€Œæœ¯è¯­â€œæ‰¹å¤„ç†â€ä¹Ÿå¯ç”¨äºè¡¨ç¤ºå°æ‰¹é‡è®­ç»ƒåˆ¶åº¦ä¸­çš„ä¸€ç»„ç¤ºä¾‹ï¼ˆå¦‚åœ¨ä¸€æ‰¹ç¤ºä¾‹ä¸­ï¼‰ï¼Œæœ¯è¯­â€œæ‰¹é‡å¤§å°â€æè¿°äº†æ¯ä¸ªæ‰¹æ¬¡ï¼ˆæˆ–å°æ‰¹é‡ï¼‰ä¸­çš„ç¤ºä¾‹æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 2001. Random forests. Machine Learning 45 (1): 5â€“32.",
            "zh": "å¸ƒè±æ›¼ï¼Œç‹®å­åº§ã€‚2001. éšæœºæ£®æ—.æœºå™¨å­¦ä¹  45 ï¼ˆ1ï¼‰ï¼š5â€“32ã€‚"
        }
    },
    {
        "translation": {
            "en": "FNR, 548",
            "zh": "FNRï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "3. The following table lists a sample of data from a census.38",
            "zh": "3. ä¸‹è¡¨åˆ—å‡ºäº†äººå£æ™®æŸ¥çš„æ•°æ®æ ·æœ¬38ã€‚"
        }
    },
    {
        "translation": {
            "en": "By convex we mean that the error surfaces are shaped like a bowl.",
            "zh": "æˆ‘ä»¬æ‰€è¯´çš„å‡¸æ˜¯æŒ‡è¯¯å·®é¢çš„å½¢çŠ¶åƒä¸€ä¸ªç¢—ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.21â€…â€…â€…A duck-billed platypus.",
            "zh": "5.21 é¸­å˜´å…½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The GUARANTOR/COAPPLICANT feature records whether the loan applicant has a guarantor or coapplicant associated with the application.",
            "zh": "æ‹…ä¿äºº/å…±åŒç”³è¯·äººåŠŸèƒ½è®°å½•è´·æ¬¾ç”³è¯·äººæ˜¯å¦æœ‰ä¸ç”³è¯·ç›¸å…³çš„æ‹…ä¿äººæˆ–å…±åŒç”³è¯·äººã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.1981",
            "zh": "-0.1981"
        }
    },
    {
        "translation": {
            "en": "Equation (8.21)[411] illustrates the calculation of Î´k for neuron k in the output layer.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.21ï¼‰[411]è¯´æ˜äº†è¾“å‡ºå±‚ä¸­ç¥ç»å…ƒkçš„Î´kè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the model has been trained we do not use dropout. Using dropout during inference would introduce random noise to the inference process. Dropout is both simple and very effective, and applying dropout is standard practice in most deep learning research today. The Ï parameter is a hyper-parameter that is preset before training. Typical values for Ï are 0.8 for the input layer, and 0.5 for hidden layers (Goodfellow et al., 2016, p. 253).",
            "zh": "ä¸€æ—¦æ¨¡å‹è¢«è®­ç»ƒï¼Œæˆ‘ä»¬å°±ä¸ä¼šä½¿ç”¨dropoutã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨è¾å­¦ä¼šç»™æ¨ç†è¿‡ç¨‹å¸¦æ¥éšæœºå™ªå£°ã€‚è¾å­¦æ—¢ç®€å•åˆéå¸¸æœ‰æ•ˆï¼Œåº”ç”¨è¾å­¦æ˜¯å½“ä»Šå¤§å¤šæ•°æ·±åº¦å­¦ä¹ ç ”ç©¶çš„æ ‡å‡†åšæ³•ã€‚Ï å‚æ•°æ˜¯åœ¨è®­ç»ƒå‰é¢„è®¾çš„è¶…å‚æ•°ã€‚è¾“å…¥å±‚çš„ Ï å…¸å‹å€¼ä¸º 0.8ï¼Œéšè—å±‚çš„ Ï å€¼ä¸º 0.5ï¼ˆGoodfellow ç­‰äººï¼Œ2016 å¹´ï¼Œç¬¬ 253 é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) What is the prediction subject for the model that will be trained using this ABT?",
            "zh": "ï¼ˆaï¼‰ å°†ä½¿ç”¨æ­¤ ABT è®­ç»ƒçš„æ¨¡å‹çš„é¢„æµ‹ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The impact of the clamp transformation should then be evaluated by comparing the performance of different models trained on datasets where the transformation has been applied and where it has not.",
            "zh": "ç„¶åï¼Œåº”é€šè¿‡æ¯”è¾ƒåœ¨å·²åº”ç”¨å’Œæœªåº”ç”¨è½¬æ¢çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„ä¸åŒæ¨¡å‹çš„æ€§èƒ½æ¥è¯„ä¼°é’³ä½å˜æ¢çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, even when we use a learning rate to scale updates, large weights can still result in exploding gradients, which in turn result in inappropriately large weight updates.",
            "zh": "ç„¶è€Œï¼Œå³ä½¿æˆ‘ä»¬ä½¿ç”¨å­¦ä¹ ç‡æ¥ç¼©æ”¾æ›´æ–°ï¼Œå¤§æƒé‡ä»ç„¶ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ï¼Œè¿›è€Œå¯¼è‡´ä¸é€‚å½“çš„å¤§æƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "In some cases we wish to refer to the vector of Î´s for the neurons in a layer l; in these cases we write Î´(l)",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›å‚è€ƒå±‚ l ä¸­ç¥ç»å…ƒçš„ Î´s å‘é‡;åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å†™Î´ï¼ˆlï¼‰"
        }
    },
    {
        "translation": {
            "en": "A grayscale image of a 4 after padding has been applied to the original 6-by-6 matrix representation, and the local receptive field of a neuron that includes both valid and padded pixels.",
            "zh": "å¡«å……å 4 çš„ç°åº¦å›¾åƒå·²åº”ç”¨äºåŸå§‹ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠåŒ…å«æœ‰æ•ˆåƒç´ å’Œå¡«å……åƒç´ çš„ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "where CP(positive, ps) and CP(negative, ps) are as described above.",
            "zh": "å…¶ä¸­ CPï¼ˆæ­£ï¼Œpsï¼‰å’Œ CPï¼ˆè´Ÿï¼Œpsï¼‰å¦‚ä¸Šæ‰€è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The techniques described in this chapter cover the Business Understanding, Data Understanding, and (partially) Data Preparation phases of the CRISP-DM process.",
            "zh": "æœ¬ç« ä¸­ä»‹ç»çš„æŠ€æœ¯æ¶µç›–äº† CRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£ã€æ•°æ®ç†è§£å’Œï¼ˆéƒ¨åˆ†ï¼‰æ•°æ®å‡†å¤‡é˜¶æ®µã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we motivate and explain the key architectural characteristics of convolutional neural networks (or CNNs) which are primarily tailored to process grid like data, such as image data.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¿€åŠ±å’Œè§£é‡Šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„å…³é”®æ¶æ„ç‰¹å¾ï¼Œè¿™äº›ç½‘ç»œä¸»è¦ç”¨äºå¤„ç†ç±»ä¼¼ç½‘æ ¼çš„æ•°æ®ï¼Œä¾‹å¦‚å›¾åƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Everything else about the process was the same as before.",
            "zh": "å…³äºè¯¥è¿‡ç¨‹çš„å…¶ä»–ä¸€åˆ‡éƒ½ä¸ä»¥å‰ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, W(2) and W(1) can be replaced by the matrix that is generated by their product; letting Wâ€² = W(2)W(1) we get",
            "zh": "æ­¤å¤–ï¼ŒWï¼ˆ2ï¼‰ å’Œ Wï¼ˆ1ï¼‰ å¯ä»¥æ›¿æ¢ä¸ºç”±å…¶ä¹˜ç§¯ç”Ÿæˆçš„çŸ©é˜µ;è®© Wâ€² = Wï¼ˆ2ï¼‰Wï¼ˆ1ï¼‰ æˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "Figure 3.4[63] illustrates this rule.",
            "zh": "å›¾3.4[63]è¯´æ˜äº†è¿™ä¸€è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "interacting features, 227",
            "zh": "äº¤äº’åŠŸèƒ½ï¼Œ227"
        }
    },
    {
        "translation": {
            "en": "2.2â€…â€…â€…Assessing Feasibility",
            "zh": "2.2 è¯„ä¼°å¯è¡Œæ€§"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23(b)[364] shows the position of two new query instances for this problem.",
            "zh": "å›¾ 7.23ï¼ˆbï¼‰[364] æ˜¾ç¤ºäº†æ­¤é—®é¢˜çš„ä¸¤ä¸ªæ–°æŸ¥è¯¢å®ä¾‹çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This ranking of the features by information gain mirrors the intuitions that we developed about the usefulness of these features during our previous discussion.",
            "zh": "è¿™ç§æŒ‰ä¿¡æ¯å¢ç›Šå¯¹ç‰¹å¾è¿›è¡Œæ’åºçš„åšæ³•åæ˜ äº†æˆ‘ä»¬åœ¨å‰é¢çš„è®¨è®ºä¸­å¯¹è¿™äº›ç‰¹å¾çš„æœ‰ç”¨æ€§æ‰€å½¢æˆçš„ç›´è§‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 11.1[639] we show how the observations made about the environment at time-step t are converted into a state, st, using a state generation function, Ï•.",
            "zh": "åœ¨å›¾11.1[639]ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨çŠ¶æ€ç”Ÿæˆå‡½æ•°Ï†åœ¨æ—¶é—´æ­¥é•¿tå¤„å¯¹ç¯å¢ƒçš„è§‚å¯Ÿè½¬æ¢ä¸ºçŠ¶æ€stã€‚"
        }
    },
    {
        "translation": {
            "en": "7. The product rule is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "7. äº§å“è§„åˆ™è¯¦è§é™„å½•B[757]ç¬¬B.3[762]èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability theory underpins a great deal of machine learning.",
            "zh": "æ¦‚ç‡è®ºæ˜¯å¤§é‡æœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "20. For example, the R language provides the fitdistr() method, as part of the MASS package, that implements a maximum-likelihood fitting of a number of univariate distributions to a given dataset.",
            "zh": "20. ä¾‹å¦‚ï¼ŒR è¯­è¨€æä¾›äº† fitdistrï¼ˆï¼‰ æ–¹æ³•ï¼Œä½œä¸º MASS åŒ…çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥æ–¹æ³•å®ç°äº†å¯¹ç»™å®šæ•°æ®é›†çš„å¤šä¸ªå•å˜é‡åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The direction and magnitude of the adjustment to be made to a weight is determined by the gradient of the error surface at the current position in the weight space.",
            "zh": "å¯¹æƒé‡è¿›è¡Œè°ƒæ•´çš„æ–¹å‘å’Œå¹…åº¦ç”±æƒé‡ç©ºé—´ä¸­å½“å‰ä½ç½®çš„è¯¯å·®æ›²é¢æ¢¯åº¦å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) Calculate the information gain ratio (based on entropy) for EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "ï¼ˆeï¼‰ è®¡ç®—æ•™è‚²ã€å©šå§»çŠ¶å†µå’ŒèŒä¸šç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¯”ï¼ˆåŸºäºç†µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is what makes auto-encoders useful for representation learning.",
            "zh": "è¿™å°±æ˜¯è‡ªåŠ¨ç¼–ç å™¨å¯¹è¡¨ç¤ºå­¦ä¹ æœ‰ç”¨çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "27. The most common way to achieve this for the other model types covered in this book is to impute the missing values in the query instance using one of the techniques described in Section 3.4.1[69].",
            "zh": "27. å¯¹äºæœ¬ä¹¦ä¸­ä»‹ç»çš„å…¶ä»–æ¨¡å‹ç±»å‹ï¼Œæœ€å¸¸è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨ç¬¬ 3.4.1 èŠ‚[69]ä¸­æè¿°çš„æŠ€æœ¯ä¹‹ä¸€æ’è¡¥æŸ¥è¯¢å®ä¾‹ä¸­çš„ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.5",
            "zh": "å›¾ 9.5"
        }
    },
    {
        "translation": {
            "en": "As with everything else, there is an application-specific component to the selection of an experimental designâ€”for example, out-of-time sampling is a good choice in scenarios where a time dimension is important.",
            "zh": "ä¸å…¶ä»–æ‰€æœ‰äº‹æƒ…ä¸€æ ·ï¼Œåœ¨é€‰æ‹©å®éªŒè®¾è®¡æ—¶æœ‰ä¸€ä¸ªç‰¹å®šäºåº”ç”¨çš„ç»„ä»¶ï¼Œä¾‹å¦‚ï¼Œåœ¨æ—¶é—´ç»´åº¦å¾ˆé‡è¦çš„åœºæ™¯ä¸­ï¼Œè¶…æ—¶é‡‡æ ·æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The following rules of thumb may be useful (although the usual caveats that all scenarios are slightly different apply).",
            "zh": "ä»¥ä¸‹ç»éªŒæ³•åˆ™å¯èƒ½å¾ˆæœ‰ç”¨ï¼ˆå°½ç®¡æ‰€æœ‰æ–¹æ¡ˆéƒ½ç•¥æœ‰ä¸åŒçš„é€šå¸¸è­¦å‘Šé€‚ç”¨ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rousseeuw, Peter J. 1987. Silhouettes: A graphical aid to the interpretation and validation of cluster analysis. Journal of computational and applied mathematics 20: 53â€“65.",
            "zh": "Rousseeuwï¼ŒPeter J. 1987 å¹´ã€‚Silhouettesï¼šç”¨äºè§£é‡Šå’ŒéªŒè¯èšç±»åˆ†æçš„å›¾å½¢è¾…åŠ©å·¥å…·ã€‚è®¡ç®—ä¸åº”ç”¨æ•°å­¦æ‚å¿— 20ï¼š53-65ã€‚"
        }
    },
    {
        "translation": {
            "en": "To explain the relationship between the weighted sum calculation and the phenomena of vanishing and exploding z and Î´ values, we will analyze the relationship between the variance of z for a single neuron in the first hidden layer of a network and the variance of the weights used in calculating that z.",
            "zh": "ä¸ºäº†è§£é‡ŠåŠ æƒå’Œè®¡ç®—ä¸zå’ŒÎ´å€¼æ¶ˆå¤±å’Œçˆ†ç‚¸ç°è±¡ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘ä»¬å°†åˆ†æç½‘ç»œç¬¬ä¸€éšè—å±‚ä¸­å•ä¸ªç¥ç»å…ƒçš„zæ–¹å·®ä¸è®¡ç®—è¯¥zçš„æƒé‡æ–¹å·®ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "After selection of the initial cluster centroids, the next step step in the algorithm is to calculate the Euclidean distance from each instance in the dataset to each cluster centroid.",
            "zh": "é€‰æ‹©åˆå§‹èšç±»è´¨å¿ƒåï¼Œç®—æ³•çš„ä¸‹ä¸€æ­¥æ˜¯è®¡ç®—æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹åˆ°æ¯ä¸ªèšç±»è´¨å¿ƒçš„æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This example network has two neurons in the input layer (Neurons 1 and 2), three neurons in the hidden layer (Neurons 3, 4, and 5), and two neurons in the output layer (Neurons 6 and 7).",
            "zh": "æ­¤ç¤ºä¾‹ç½‘ç»œåœ¨è¾“å…¥å±‚ä¸­æœ‰ä¸¤ä¸ªç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 1 å’Œ 2ï¼‰ï¼Œåœ¨éšè—å±‚ä¸­æœ‰ä¸‰ä¸ªç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 3ã€4 å’Œ 5ï¼‰ï¼Œåœ¨è¾“å‡ºå±‚ä¸­æœ‰ä¸¤ä¸ªç¥ç»å…ƒï¼ˆç¥ç»å…ƒ 6 å’Œ 7ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this way the limited claims investigation time could be targeted at the claims that are most likely to be fraudulent, thereby increasing the number of fraudulent claims detected and reducing the amount of money lost to fraud.",
            "zh": "è¿™æ ·ä¸€æ¥ï¼Œæœ‰é™çš„ç´¢èµ”è°ƒæŸ¥æ—¶é—´å°±å¯ä»¥é’ˆå¯¹æœ€æœ‰å¯èƒ½æ˜¯æ¬ºè¯ˆæ€§çš„ç´¢èµ”ï¼Œä»è€Œå¢åŠ å‘ç°çš„æ¬ºè¯ˆæ€§ç´¢èµ”æ•°é‡ï¼Œå‡å°‘å› æ¬ºè¯ˆè€ŒæŸå¤±çš„é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a well-performing model, the lift curve should start well above 1.0 and cross 1.0 at one of the lower deciles.",
            "zh": "å¯¹äºæ€§èƒ½è‰¯å¥½çš„æ¨¡å‹ï¼Œæå‡æ›²çº¿åº”ä»è¿œé«˜äº 1.0 å¼€å§‹ï¼Œå¹¶åœ¨è¾ƒä½çš„ååˆ†ä½æ•°ä¹‹ä¸€å¤„è¶Šè¿‡ 1.0ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the Î´s for Neurons 6 and 7 have been calculated, we are ready to propagate the error gradients back to the first hidden layer. The process used to calculate the Î´s for Neurons 3, 4, and 5 is the same as that used to calculate Î´6 and Î´7. Equation (8.35)[429] steps through this calculation for Î´ 3, Equation (8.36)[429] shows the calculation of Î´4, and Equation (8.37)[429] lists the calculations of Î´5",
            "zh": "ä¸€æ—¦è®¡ç®—äº†ç¥ç»å…ƒ 6 å’Œ 7 çš„ Î´ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è¯¯å·®æ¢¯åº¦ä¼ æ’­å›ç¬¬ä¸€ä¸ªéšè—å±‚ã€‚ç”¨äºè®¡ç®—ç¥ç»å…ƒ 3ã€4 å’Œ 5 çš„ Î´ çš„è¿‡ç¨‹ä¸ç”¨äºè®¡ç®— Î´6 å’Œ Î´7 çš„è¿‡ç¨‹ç›¸åŒã€‚æ–¹ç¨‹ï¼ˆ8.35ï¼‰[429]é€æ­¥è®¡ç®—Î´ 3ï¼Œæ–¹ç¨‹ï¼ˆ8.36ï¼‰[429]æ˜¾ç¤ºäº†Î´4çš„è®¡ç®—ï¼Œæ–¹ç¨‹ï¼ˆ8.37ï¼‰[429]åˆ—å‡ºäº†Î´5çš„è®¡ç®—"
        }
    },
    {
        "translation": {
            "en": "10.4.1â€ƒChoosing Initial Cluster Centroids",
            "zh": "10.4.1 é€‰æ‹©åˆå§‹èšç±»è´¨å¿ƒ"
        }
    },
    {
        "translation": {
            "en": "These cycles, or recurrent links, are the reason these networks are called recurrent networks.",
            "zh": "è¿™äº›å¾ªç¯æˆ–å¾ªç¯é“¾æ¥æ˜¯è¿™äº›ç½‘ç»œè¢«ç§°ä¸ºå¾ªç¯ç½‘ç»œçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "regression tree, 149, 165",
            "zh": "å›å½’æ ‘ï¼Œ 149ï¼Œ 165"
        }
    },
    {
        "translation": {
            "en": "For example, all the bin3 values have a target feature value of false.",
            "zh": "ä¾‹å¦‚ï¼Œæ‰€æœ‰ bin3 å€¼çš„ç›®æ ‡ç‰¹å¾å€¼å‡ä¸º falseã€‚"
        }
    },
    {
        "translation": {
            "en": "ETL, 42",
            "zh": "ETLï¼Œ42"
        }
    },
    {
        "translation": {
            "en": "The network in Figure 6.9(a)[287] could be simplified in this way, and we will use this simplification for all networks drawn from now on.",
            "zh": "å›¾6.9ï¼ˆaï¼‰[287]ä¸­çš„ç½‘ç»œå¯ä»¥è¿™æ ·ç®€åŒ–ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ç§ç®€åŒ–ç”¨äºä»ç°åœ¨å¼€å§‹ç»˜åˆ¶çš„æ‰€æœ‰ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "EXAMPLE",
            "zh": "ä¾‹"
        }
    },
    {
        "translation": {
            "en": "The shape of the curve is determined by (a) the statistical distribution that is used to define the PDF, and (b) the values of the statistical distribution parameters.",
            "zh": "æ›²çº¿çš„å½¢çŠ¶ç”± ï¼ˆaï¼‰ ç”¨äºå®šä¹‰ PDF çš„ç»Ÿè®¡åˆ†å¸ƒå’Œ ï¼ˆbï¼‰ ç»Ÿè®¡åˆ†å¸ƒå‚æ•°çš„å€¼ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Boltzmann action selection, 658",
            "zh": "ç»å°”å…¹æ›¼åŠ¨ä½œé€‰æ‹©ï¼Œ658"
        }
    },
    {
        "translation": {
            "en": "-0.02990",
            "zh": "-0.02990"
        }
    },
    {
        "translation": {
            "en": "the rate of change of the weighted sum function with respect to changes in one of the weights (âˆ‚zi/âˆ‚wi,k);",
            "zh": "åŠ æƒå’Œå‡½æ•°ç›¸å¯¹äºå…¶ä¸­ä¸€ä¸ªæƒé‡å˜åŒ–çš„å˜åŒ–ç‡ ï¼ˆâˆ‚zi/âˆ‚wiï¼Œkï¼‰;"
        }
    },
    {
        "translation": {
            "en": "CLAIMS 3 MONTHS; AVERAGE CLAIMS PER YEAR BY CLAIMANT: AVG.",
            "zh": "ç´¢èµ” 3 ä¸ªæœˆ;ç´¢èµ”äººæ¯å¹´çš„å¹³å‡ç´¢èµ”é¢ï¼šå¹³å‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œWhen I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.â€",
            "zh": "â€œå½“æˆ‘çœ‹åˆ°ä¸€åªé¸Ÿèµ°è·¯åƒé¸­å­ï¼Œåƒé¸­å­ä¸€æ ·æ¸¸æ³³ï¼Œåƒé¸­å­ä¸€æ ·å˜å˜å«æ—¶ï¼Œæˆ‘å°±ç§°é‚£åªé¸Ÿä¸ºé¸­å­ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "As we mentioned previously, this is similar to the way the error gradients for shared weights in a convolutional neural network are summed, and then the weight is updated once using this summed gradient.",
            "zh": "æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œè¿™ç±»ä¼¼äºå·ç§¯ç¥ç»ç½‘ç»œä¸­å…±äº«æƒé‡çš„è¯¯å·®æ¢¯åº¦æ±‚å’Œçš„æ–¹å¼ï¼Œç„¶åä½¿ç”¨æ­¤æ±‚å’Œæ¢¯åº¦æ›´æ–°æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The expectation is that a linear separating hyperplane will exist in this higher-dimensional space even though it does not in the original feature space.",
            "zh": "æœŸæœ›æ˜¯çº¿æ€§åˆ†ç¦»è¶…å¹³é¢å°†å­˜åœ¨äºè¿™ä¸ªé«˜ç»´ç©ºé—´ä¸­ï¼Œå³ä½¿å®ƒä¸åœ¨åŸå§‹ç‰¹å¾ç©ºé—´ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.5520",
            "zh": "0.5520"
        }
    },
    {
        "translation": {
            "en": "The final model trained is",
            "zh": "è®­ç»ƒçš„æœ€ç»ˆæ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Public companies also must file public documents every year that outline how they have been performing, details of any changes in directorship, and so on.",
            "zh": "ä¸Šå¸‚å…¬å¸è¿˜å¿…é¡»æ¯å¹´æäº¤å…¬å¼€æ–‡ä»¶ï¼Œæ¦‚è¿°ä»–ä»¬çš„è¡¨ç°ã€è‘£äº‹èŒä½ä»»ä½•å˜åŒ–çš„ç»†èŠ‚ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "CALLMINUTESCHANGEPCT",
            "zh": "CALLMINUTESCHANGEPCT"
        }
    },
    {
        "translation": {
            "en": "It is a good idea to add suggestions for the best technique to handle each data quality issue in the data quality plan during data exploration as it will save time during modeling.",
            "zh": "åœ¨æ•°æ®æµè§ˆæœŸé—´ï¼Œæœ€å¥½æ·»åŠ æœ‰å…³å¤„ç†æ•°æ®è´¨é‡è®¡åˆ’ä¸­æ¯ä¸ªæ•°æ®è´¨é‡é—®é¢˜çš„æœ€ä½³æŠ€æœ¯çš„å»ºè®®ï¼Œå› ä¸ºè¿™å°†èŠ‚çœå»ºæ¨¡æœŸé—´çš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "For an illustrative example of Bayesâ€™ Theorem in action, imagine that after a yearly checkup, a doctor informs a patient that there is both bad news and good news.",
            "zh": "å¯¹äºè´å¶æ–¯å®šç†çš„ä¸€ä¸ªè¯´æ˜æ€§ä¾‹å­ï¼Œæƒ³è±¡ä¸€ä¸‹ï¼Œåœ¨æ¯å¹´ä¸€æ¬¡çš„æ£€æŸ¥ä¹‹åï¼ŒåŒ»ç”Ÿå‘Šè¯‰ç—…äººï¼Œæ—¢æœ‰åæ¶ˆæ¯ä¹Ÿæœ‰å¥½æ¶ˆæ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "A binary dataset listing the behavior of two individuals on a website during a trial period and whether they subsequently signed up for the website.",
            "zh": "ä¸€ä¸ªäºŒè¿›åˆ¶æ•°æ®é›†ï¼Œåˆ—å‡ºäº†ä¸¤ä¸ªäººåœ¨è¯•ç”¨æœŸé—´åœ¨ç½‘ç«™ä¸Šçš„è¡Œä¸ºï¼Œä»¥åŠä»–ä»¬éšåæ˜¯å¦æ³¨å†Œäº†è¯¥ç½‘ç«™ã€‚"
        }
    },
    {
        "translation": {
            "en": "By using basis functions such as those given in the examples in this section, we relax the restriction on the algorithm to consider only linear models and instead allow more complex model types such as the higher-order polynomial models seen in these examples.",
            "zh": "é€šè¿‡ä½¿ç”¨æœ¬èŠ‚ç¤ºä¾‹ä¸­ç»™å‡ºçš„åŸºå‡½æ•°ï¼Œæˆ‘ä»¬æ”¾å®½äº†å¯¹ç®—æ³•çš„é™åˆ¶ï¼Œåªè€ƒè™‘çº¿æ€§æ¨¡å‹ï¼Œè€Œæ˜¯å…è®¸æ›´å¤æ‚çš„æ¨¡å‹ç±»å‹ï¼Œä¾‹å¦‚è¿™äº›ç¤ºä¾‹ä¸­çœ‹åˆ°çš„é«˜é˜¶å¤šé¡¹å¼æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can also add instances to the tree after if has been created.",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥åœ¨åˆ›å»º if åå°†å®ä¾‹æ·»åŠ åˆ°æ ‘ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the algorithm is sensitive to noise because any errors in the description or labeling of training data results in erroneous local models and hence incorrect predictions.",
            "zh": "å› æ­¤ï¼Œè¯¥ç®—æ³•å¯¹å™ªå£°å¾ˆæ•æ„Ÿï¼Œå› ä¸ºè®­ç»ƒæ•°æ®çš„æè¿°æˆ–æ ‡è®°ä¸­çš„ä»»ä½•é”™è¯¯éƒ½ä¼šå¯¼è‡´é”™è¯¯çš„å±€éƒ¨æ¨¡å‹ï¼Œä»è€Œå¯¼è‡´é”™è¯¯çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.7â€…â€…â€…The updated version of Table 5.6[206] once we have applied range normalization to the SALARY and AGE features in the dataset and to the query instance.",
            "zh": "5.7 è¡¨ 5.6[206] çš„æ›´æ–°ç‰ˆæœ¬ï¼Œä¸€æ—¦æˆ‘ä»¬å°†èŒƒå›´å½’ä¸€åŒ–åº”ç”¨äºæ•°æ®é›†ä¸­çš„ SALARY å’Œ AGE ç‰¹å¾ä»¥åŠæŸ¥è¯¢å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each time a node is updated, a new sample state has been generated.",
            "zh": "æ¯æ¬¡æ›´æ–°èŠ‚ç‚¹æ—¶ï¼Œéƒ½ä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„ç¤ºä¾‹çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2â€…â€…â€…Fundamentals",
            "zh": "4.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "The new weights result in slightly more accurate predictions, evident from the slightly reduced sum of squared errors of 12.0262.",
            "zh": "æ–°çš„æƒé‡å¯¼è‡´é¢„æµ‹æ›´åŠ å‡†ç¡®ï¼Œè¿™ä»12.0262çš„å¹³æ–¹è¯¯å·®æ€»å’Œç•¥æœ‰å‡å°‘ä¸­å¯ä»¥çœ‹å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "TN and FN are defined similarly.",
            "zh": "TN å’Œ FN çš„å®šä¹‰ç±»ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Frequently, in discussing deep learning we use an elementwise product of two matrices, known as the Hadamard product. The symbol âŠ™ denotes the Hadamard product, and the Hadamard product of two matrices D and E is written D âŠ™ E. The Hadamard product assumes that both matrices have the same dimensions, and it produces a matrix with the same dimensions as the two inputs. Each value in the resulting matrix is the product of the corresponding cells in the two input matrices:",
            "zh": "åœ¨è®¨è®ºæ·±åº¦å­¦ä¹ æ—¶ï¼Œæˆ‘ä»¬ç»å¸¸ä½¿ç”¨ä¸¤ä¸ªçŸ©é˜µçš„å…ƒç´ ä¹˜ç§¯ï¼Œç§°ä¸º Hadamard ç§¯ã€‚ç¬¦å· âŠ™ è¡¨ç¤º Hadamard ä¹˜ç§¯ï¼Œä¸¤ä¸ªçŸ©é˜µ D å’Œ E çš„ Hadamard ä¹˜ç§¯å†™ä¸º D âŠ™ Eã€‚Hadamard ä¹˜ç§¯å‡è®¾ä¸¤ä¸ªçŸ©é˜µå…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªä¸ä¸¤ä¸ªè¾“å…¥å…·æœ‰ç›¸åŒç»´åº¦çš„çŸ©é˜µã€‚ç»“æœçŸ©é˜µä¸­çš„æ¯ä¸ªå€¼éƒ½æ˜¯ä¸¤ä¸ªè¾“å…¥çŸ©é˜µä¸­ç›¸åº”å•å…ƒæ ¼çš„ä¹˜ç§¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "Often, however, the observation period and outcome period will be measured over different dates for each prediction subject.",
            "zh": "ç„¶è€Œï¼Œé€šå¸¸ï¼Œè§‚å¯ŸæœŸå’Œç»“æœæœŸå°†åœ¨æ¯ä¸ªé¢„æµ‹å¯¹è±¡çš„ä¸åŒæ—¥æœŸè¿›è¡Œæµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As such, pruning can be viewed as a noise dampening mechanism that removes nodes that have been created because of a small set of noisy instances.",
            "zh": "å› æ­¤ï¼Œä¿®å‰ªå¯ä»¥è¢«è§†ä¸ºä¸€ç§å™ªå£°æŠ‘åˆ¶æœºåˆ¶ï¼Œå®ƒåˆ é™¤äº†ç”±äºä¸€å°ç»„å™ªå£°å®ä¾‹è€Œåˆ›å»ºçš„èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The approach to training multivariable linear regression models described so far is more specifically known as batch gradient descent.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢æè¿°çš„è®­ç»ƒå¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„æ–¹æ³•æ›´å…·ä½“åœ°ç§°ä¸ºæ‰¹æ¬¡æ¢¯åº¦ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.2.1â€…â€…â€…Decision Trees",
            "zh": "4.2.1 å†³ç­–æ ‘"
        }
    },
    {
        "translation": {
            "en": "Spectral clustering (Ng et al., 2002) is another approach worth investigating, and for very large spatial datasets, the DBScan (Ester et al., 1996) can be a good approach.",
            "zh": "å…‰è°±èšç±»ï¼ˆNg et al.ï¼Œ 2002ï¼‰æ˜¯å¦ä¸€ç§å€¼å¾—ç ”ç©¶çš„æ–¹æ³•ï¼Œå¯¹äºéå¸¸å¤§çš„ç©ºé—´æ•°æ®é›†ï¼ŒDBScan ï¼ˆEster et al.ï¼Œ 1996ï¼‰å¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the number of levels of one of the features being compared is small (we recommend no more than three), we can use stacked bar plots as an alternative to the small multiples bar plots approach.",
            "zh": "å¦‚æœè¢«æ¯”è¾ƒçš„å…¶ä¸­ä¸€ä¸ªç‰¹å¾çš„å±‚çº§æ•°å¾ˆå°ï¼ˆæˆ‘ä»¬å»ºè®®ä¸è¶…è¿‡ä¸‰ä¸ªï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å †ç§¯æ¡å½¢å›¾ä½œä¸ºå°å€æ•°æ¡å½¢å›¾æ–¹æ³•çš„æ›¿ä»£æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "One way of addressing this issue is to use information gain ratio instead of entropy.",
            "zh": "è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”è€Œä¸æ˜¯ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "26. If we have a very large dataset, we mayâ€”for computational reasonsâ€”want to create bootstrap samples that are smaller than the original dataset. If this is the case, then sampling without replacement is preferred. This is known as subagging.",
            "zh": "26. å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸å¤§çš„æ•°æ®é›†ï¼Œå‡ºäºè®¡ç®—åŸå› ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦åˆ›å»ºæ¯”åŸå§‹æ•°æ®é›†å°çš„å¼•å¯¼æ ·æœ¬ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œåˆ™é¦–é€‰ä¸æ›´æ¢çš„é‡‡æ ·ã€‚è¿™ç§°ä¸ºä¸‹å¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. We divide by n âˆ’ 1 (as opposed to n) because we are calculating the variance using only a sample, and on average, dividing by n âˆ’ 1 gives a better estimate of the population variance than using n.",
            "zh": "1. æˆ‘ä»¬é™¤ä»¥ n âˆ’ 1ï¼ˆè€Œä¸æ˜¯ nï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬åªä½¿ç”¨æ ·æœ¬è®¡ç®—æ–¹å·®ï¼Œå¹³å‡è€Œè¨€ï¼Œé™¤ä»¥ n âˆ’ 1 æ¯”ä½¿ç”¨ n æ›´å¥½åœ°ä¼°è®¡æ€»ä½“æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Larger graphs will tend to have longer mixing times.",
            "zh": "è¾ƒå¤§çš„å›¾å½¢å¾€å¾€å…·æœ‰æ›´é•¿çš„æ··åˆæ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The original baseline target frequencies are based on the predictions in Table 9.18[573] and are visualized in Figure 9.18(a)[582].",
            "zh": "åŸå§‹åŸºçº¿ç›®æ ‡é¢‘ç‡åŸºäºè¡¨9.18[573]ä¸­çš„é¢„æµ‹ï¼Œå¹¶åœ¨å›¾9.18ï¼ˆaï¼‰[582]ä¸­å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The r one-versus-all logistic regression models used are trained in parallel, and the revised model outputs, â€²wk(d), are used in calculating the sum of squared errors for each model during the training process.",
            "zh": "æ‰€ä½¿ç”¨çš„ r ä¸€å¯¹å…¨é€»è¾‘å›å½’æ¨¡å‹æ˜¯å¹¶è¡Œè®­ç»ƒçš„ï¼Œä¿®è®¢åçš„æ¨¡å‹è¾“å‡º â€²wkï¼ˆdï¼‰ ç”¨äºè®¡ç®—è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªæ¨¡å‹çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "To perform binning, we define a series of ranges (called bins) for the continuous feature that correspond to the levels of the new categorical feature we are creating.",
            "zh": "ä¸ºäº†æ‰§è¡Œåˆ†ç®±ï¼Œæˆ‘ä»¬ä¸ºè¿ç»­ç‰¹å¾å®šä¹‰äº†ä¸€ç³»åˆ—èŒƒå›´ï¼ˆç§°ä¸ºæ¡æŸ±ï¼‰ï¼Œè¿™äº›èŒƒå›´å¯¹åº”äºæˆ‘ä»¬æ­£åœ¨åˆ›å»ºçš„æ–°åˆ†ç±»ç‰¹å¾çš„çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard deviation of the heights of the players on the first basketball team is 7.945 and for the second team is 31.803. As these measures are in the same units as the heights, they afford us a more intuitive understanding of the data and make comparison easier. We can say that, on average, players on the first team vary by almost 8cm from the average of 149.375cm, while on the second team, they vary by approximately 32cm.",
            "zh": "ç¬¬ä¸€ç¯®çƒé˜Ÿçƒå‘˜èº«é«˜çš„æ ‡å‡†å·®ä¸º7.945ï¼Œç¬¬äºŒç¯®çƒé˜Ÿä¸º31.803ã€‚ç”±äºè¿™äº›åº¦é‡ä¸é«˜åº¦çš„å•ä½ç›¸åŒï¼Œå› æ­¤å®ƒä»¬ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´ç›´è§‚åœ°ç†è§£æ•°æ®ï¼Œå¹¶ä½¿æ¯”è¾ƒæ›´å®¹æ˜“ã€‚å¯ä»¥è¯´ï¼Œå¹³å‡è€Œè¨€ï¼Œä¸€çº¿é˜Ÿçš„çƒå‘˜ä¸å¹³å‡ 149.375 å˜ç±³ç›¸å·®è¿‘ 8 å˜ç±³ï¼Œè€Œåœ¨äºŒé˜Ÿä¸­ï¼Œä»–ä»¬ç›¸å·®çº¦ 32 å˜ç±³ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Three normal distributions with different means but identical standard deviations; and (b) three normal distributions with identical means but different standard deviations.",
            "zh": "ï¼ˆaï¼‰ å‡å€¼ä¸åŒä½†æ ‡å‡†å·®ç›¸åŒçš„ä¸‰ç§æ­£æ€åˆ†å¸ƒ;ï¼ˆbï¼‰å‡å€¼ç›¸åŒä½†æ ‡å‡†å·®ä¸åŒçš„ä¸‰ç§æ­£æ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Before this action Q(6-5,left) gave an expected return from the action-value table of âˆ’ 0.267.",
            "zh": "åœ¨æ­¤æ“ä½œä¹‹å‰ï¼ŒQï¼ˆ6-5ï¼Œå·¦ï¼‰ä»æ“ä½œå€¼è¡¨ä¸­ç»™å‡ºäº† âˆ’ 0.267 çš„é¢„æœŸå›æŠ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is that simple!",
            "zh": "å°±æ˜¯è¿™ä¹ˆç®€å•ï¼"
        }
    },
    {
        "translation": {
            "en": "At this point Jocelyn was primarily interested in understanding the amount of data available, any issues that might arise from missing values, and the types of each column in the dataset.",
            "zh": "æ­¤æ—¶ï¼ŒJocelyn ä¸»è¦æ„Ÿå…´è¶£çš„æ˜¯äº†è§£å¯ç”¨æ•°æ®é‡ã€ç¼ºå¤±å€¼å¯èƒ½å¼•èµ·çš„ä»»ä½•é—®é¢˜ä»¥åŠæ•°æ®é›†ä¸­æ¯åˆ—çš„ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the conditional independence assumption enables us to factorize the distribution of the domain, and consequently we need fewer probabilities with fewer constraints to represent the domain.",
            "zh": "æ­¤å¤–ï¼Œæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ†è§£åŸŸçš„åˆ†å¸ƒï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ›´å°‘çš„æ¦‚ç‡å’Œæ›´å°‘çš„çº¦æŸæ¥è¡¨ç¤ºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "If the error rate at the subtree root node is less than or equal to the combined error rate at the leaves, the subtree is pruned.",
            "zh": "å¦‚æœå­æ ‘æ ¹èŠ‚ç‚¹å¤„çš„é”™è¯¯ç‡å°äºæˆ–ç­‰äºå¶å­å¤„çš„ç»„åˆé”™è¯¯ç‡ï¼Œåˆ™ä¿®å‰ªå­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, randomly sampling each mini-batch from a very large dataset may be impractical.",
            "zh": "ä½†æ˜¯ï¼Œä»éå¸¸å¤§çš„æ•°æ®é›†ä¸­éšæœºæŠ½æ ·æ¯ä¸ªå°æ‰¹é‡å¯èƒ½æ˜¯ä¸åˆ‡å®é™…çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A Markov chain is ergodic if every state is reachable from every other state and there are no cycles in the chain.",
            "zh": "å¦‚æœæ¯ä¸ªçŠ¶æ€éƒ½å¯ä»¥ä»å…¶ä»–æ¯ä¸ªçŠ¶æ€åˆ°è¾¾å¹¶ä¸”é“¾ä¸­æ²¡æœ‰å¾ªç¯ï¼Œåˆ™é©¬å°”å¯å¤«é“¾æ˜¯éå†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because of the size of the ABT, Jocelyn decided to split the dataset into a training set and a large hold-out test set.",
            "zh": "ç”±äº ABT çš„å¤§å°ï¼ŒJocelyn å†³å®šå°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œå¤§å‹ä¿æŒæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, the error gradients for a weight are summed and then the weight is updated once.",
            "zh": "åŒæ ·ï¼Œå°†æƒé‡çš„è¯¯å·®æ¢¯åº¦ç›¸åŠ ï¼Œç„¶åå¯¹æƒé‡è¿›è¡Œä¸€æ¬¡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This chapter also adopts the two-part structure of standard approach followed by extensions and variations.",
            "zh": "æœ¬ç« è¿˜é‡‡ç”¨äº†æ ‡å‡†æ–¹æ³•çš„ä¸¤éƒ¨åˆ†ç»“æ„ï¼Œç„¶åæ˜¯æ‰©å±•å’Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.11(a)[341] illustrates the consistent relationship between Equation (7.23)[339] and the decision boundary by plotting the value of Equation (7.23)[339] for all values of RPM and VIBRATION.12",
            "zh": "å›¾7.11ï¼ˆaï¼‰[341]é€šè¿‡ç»˜åˆ¶æ‰€æœ‰RPMå’ŒVIBRATIONå€¼çš„ç­‰å¼ï¼ˆ7.23ï¼‰[339]çš„å€¼ï¼Œè¯´æ˜äº†ç­‰å¼ï¼ˆ7.23ï¼‰[339]ä¸å†³ç­–è¾¹ç•Œä¹‹é—´çš„ä¸€è‡´å…³ç³»12ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this point ğ’Ÿ8 is the only partition that is not a pure set. There are two descriptive features that can be used to split ğ’Ÿ8: STREAM and SLOPE. The decision regarding which of these features to use for the split is made by calculating which feature has the higher information gain for ğ’Ÿ8. The overall entropy for ğ’Ÿ8 is calculated",
            "zh": "æ­¤æ—¶ï¼ŒD8 æ˜¯å”¯ä¸€ä¸æ˜¯çº¯é›†çš„åˆ†åŒºã€‚æœ‰ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾å¯ç”¨äºæ‹†åˆ† D8ï¼šSTREAM å’Œ SLOPEã€‚é€šè¿‡è®¡ç®—å“ªä¸ªç‰¹å¾å¯¹ D8 å…·æœ‰æ›´é«˜çš„ä¿¡æ¯å¢ç›Šï¼Œå¯ä»¥å†³å®šä½¿ç”¨è¿™äº›ç‰¹å¾ä¸­çš„å“ªä¸€ä¸ªè¿›è¡Œæ‹†åˆ†ã€‚è®¡ç®— D8 çš„æ€»ç†µ"
        }
    },
    {
        "translation": {
            "en": "6.19â€…â€…â€…Examples of the samples generated using Gibbs sampling.",
            "zh": "6.19 ä½¿ç”¨å‰å¸ƒæ–¯æŠ½æ ·ç”Ÿæˆçš„æ ·æœ¬ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Regardless of the binning approach used, once the values for a continuous feature have been binned, the continuous feature is discarded and replaced by a categorical feature, which has a level for each binâ€”the bin numbers can be used, or a more meaningful label can be manually generated.",
            "zh": "æ— è®ºä½¿ç”¨ä½•ç§åˆ†ç®±æ–¹æ³•ï¼Œä¸€æ—¦è¿ç»­è¦ç´ çš„å€¼è¢«åˆ†ç®±ï¼Œè¿ç»­è¦ç´ å°†è¢«ä¸¢å¼ƒå¹¶æ›¿æ¢ä¸ºåˆ†ç±»è¦ç´ ï¼Œè¯¥åˆ†ç±»è¦ç´ å¯¹æ¯ä¸ªæ¡æŸ±éƒ½æœ‰ä¸€ä¸ªçº§åˆ« - å¯ä»¥ä½¿ç”¨æ¡æŸ±ç¼–å·ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æ ‡æ³¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. We use some simple elements of probability theory in this chapter. Readers unfamiliar with the way probabilities are calculated based on the relative frequencies of events should read the first section of Appendix B[757] before continuing with this chapter.",
            "zh": "3. åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¦‚ç‡è®ºçš„ä¸€äº›ç®€å•å…ƒç´ ã€‚ä¸ç†Ÿæ‚‰æ ¹æ®äº‹ä»¶çš„ç›¸å¯¹é¢‘ç‡è®¡ç®—æ¦‚ç‡çš„è¯»è€…ï¼Œåœ¨ç»§ç»­æœ¬ç« ä¹‹å‰ï¼Œåº”é˜…è¯»é™„å½•B[757]çš„ç¬¬ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this model, the company could save on claims investigations and reduce the amount of money paid out on fraudulent claims.",
            "zh": "ä½¿ç”¨è¿™ç§æ¨¡å¼ï¼Œå…¬å¸å¯ä»¥èŠ‚çœç´¢èµ”è°ƒæŸ¥è´¹ç”¨ï¼Œå¹¶å‡å°‘æ¬ºè¯ˆæ€§ç´¢èµ”çš„é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "These under-sampled groups are then combined to create the overall under-sampled dataset.",
            "zh": "ç„¶åå°†è¿™äº›æ¬ é‡‡æ ·ç»„ç»„åˆåœ¨ä¸€èµ·ï¼Œä»¥åˆ›å»ºæ•´ä½“æ¬ é‡‡æ ·æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "heating load prediction, 371",
            "zh": "çƒ­è´Ÿè·é¢„æµ‹ï¼Œ371"
        }
    },
    {
        "translation": {
            "en": "This is why that ELEVATION feature is listed in both the partitions (7 and 8) shown in Figure 4.13[149].",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå›¾ 4.13[149] æ‰€ç¤ºçš„ä¸¤ä¸ªåˆ†åŒºï¼ˆ7 å’Œ 8ï¼‰ä¸­éƒ½åˆ—å‡ºäº† ELEVATION ç‰¹å¾çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "error function, 312, 315, 315, 367, 409",
            "zh": "é”™è¯¯å‡½æ•°ï¼Œ 312ï¼Œ 315ï¼Œ 315ï¼Œ 367ï¼Œ 409"
        }
    },
    {
        "translation": {
            "en": "ğ•„w(d) refers to the output of a model ğ•„ parameterized by parameters w for descriptive features d.",
            "zh": "Mwï¼ˆdï¼‰ æ˜¯æŒ‡æ¨¡å‹ M çš„è¾“å‡ºï¼Œç”±æè¿°æ€§ç‰¹å¾ d çš„å‚æ•° w å‚æ•°åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example:",
            "zh": "ä¾‹å¦‚ï¼š"
        }
    },
    {
        "translation": {
            "en": "In contrast with Table 5.6[206], where there was a close match between the SALARY and AGE distances and the SALARY only distances and related rankings, in Table 5.7[208] there is much more variation between the SALARY and AGE distances and the SALARY only distances.",
            "zh": "ä¸è¡¨5.6[206]ç›¸æ¯”ï¼ŒSALARY å’Œ AGE è·ç¦»ä¸ä»… SALARY è·ç¦»å’Œç›¸å…³æ’åä¹‹é—´çš„åŒ¹é…åº¦éå¸¸æ¥è¿‘ï¼Œè€Œåœ¨è¡¨ 5.7[208] ä¸­ï¼ŒSALARY å’Œ AGE è·ç¦»ä»¥åŠä»… SALARY è·ç¦»ä¹‹é—´çš„å·®å¼‚è¦å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1â€…â€…â€…Designing Evaluation Experiments",
            "zh": "9.4.1 è®¾è®¡è¯„ä¼°å®éªŒ"
        }
    },
    {
        "translation": {
            "en": "What makes this approach really attractive is that, although this new model stated in terms of basis functions captures the non-linear relationship between rainfall and grass growth, the model is still linear in terms of the weights and so can be trained using gradient descent without making any changes to the algorithm. Figure 7.17[354] shows the final non-linear model that results from this training process, along with a number of the interim steps on the way to this model. The final model is",
            "zh": "è¿™ç§æ–¹æ³•çœŸæ­£å¸å¼•äººçš„æ˜¯ï¼Œå°½ç®¡è¿™ä¸ªæ–°æ¨¡å‹åœ¨åŸºå‡½æ•°æ–¹é¢æ•è·äº†é™é›¨å’Œè‰ç”Ÿé•¿ä¹‹é—´çš„éçº¿æ€§å…³ç³»ï¼Œä½†è¯¥æ¨¡å‹åœ¨æƒé‡æ–¹é¢ä»ç„¶æ˜¯çº¿æ€§çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿›è¡Œè®­ç»ƒï¼Œè€Œæ— éœ€å¯¹ç®—æ³•è¿›è¡Œä»»ä½•æ›´æ”¹ã€‚å›¾ 7.17[354] æ˜¾ç¤ºäº†è¯¥è®­ç»ƒè¿‡ç¨‹äº§ç”Ÿçš„æœ€ç»ˆéçº¿æ€§æ¨¡å‹ï¼Œä»¥åŠé€šå¾€è¯¥æ¨¡å‹çš„ä¸€äº›è¿‡æ¸¡æ­¥éª¤ã€‚æœ€ç»ˆæ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "Organizations donâ€™t exist to do predictive data analytics.",
            "zh": "ç»„ç»‡ä¸å­˜åœ¨è¿›è¡Œé¢„æµ‹æ€§æ•°æ®åˆ†æã€‚"
        }
    },
    {
        "translation": {
            "en": "The net effect of this is that instance d1 is now ranked as the nearest neighbor to the queryâ€”this is in line with the feature space representation in Figure 5.12(b)[205].",
            "zh": "è¿™æ ·åšçš„æœ€ç»ˆç»“æœæ˜¯ï¼Œå®ä¾‹ d1 ç°åœ¨è¢«åˆ—ä¸ºæŸ¥è¯¢çš„æœ€è¿‘é‚»åŸŸï¼Œè¿™ä¸å›¾ 5.12ï¼ˆbï¼‰[205] ä¸­çš„ç‰¹å¾ç©ºé—´è¡¨ç¤ºä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The AND function returns TRUE if both inputs are TRUE and FALSE otherwise.",
            "zh": "å¦‚æœä¸¤ä¸ªè¾“å…¥å‡ä¸º TRUEï¼Œåˆ™ AND å‡½æ•°è¿”å› TRUEï¼Œå¦åˆ™è¿”å› FALSEã€‚"
        }
    },
    {
        "translation": {
            "en": "perceptron learning rule, 342",
            "zh": "æ„ŸçŸ¥å™¨å­¦ä¹ è§„åˆ™ï¼Œ342"
        }
    },
    {
        "translation": {
            "en": "The computational speedups achieved by using matrix multiplications address the computational challenge of iterating through both a large number of neurons and a large number of examples.",
            "zh": "é€šè¿‡ä½¿ç”¨çŸ©é˜µä¹˜æ³•å®ç°çš„è®¡ç®—åŠ é€Ÿè§£å†³äº†é€šè¿‡å¤§é‡ç¥ç»å…ƒå’Œå¤§é‡ç¤ºä¾‹è¿›è¡Œè¿­ä»£çš„è®¡ç®—æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the error term âˆ‚â„°/âˆ‚ak is multiplied by two weights: wj,i and wk,j.",
            "zh": "è¯·æ³¨æ„ï¼Œè¯¯å·®é¡¹ âˆ‚E/âˆ‚ak ä¹˜ä»¥ä¸¤ä¸ªæƒé‡ï¼šwjï¼Œi å’Œ wkï¼Œjã€‚"
        }
    },
    {
        "translation": {
            "en": "One implication of this assumption is that supervised machine learning assumes that new target levelsâ€”such as previously unknown animalsâ€”donâ€™t suddenly appear in the data from which queries that are input to the model are sampled.",
            "zh": "è¿™ç§å‡è®¾çš„ä¸€ä¸ªå«ä¹‰æ˜¯ï¼Œç›‘ç£æœºå™¨å­¦ä¹ å‡è®¾æ–°çš„ç›®æ ‡æ°´å¹³ï¼ˆä¾‹å¦‚ä»¥å‰æœªçŸ¥çš„åŠ¨ç‰©ï¼‰ä¸ä¼šçªç„¶å‡ºç°åœ¨æ•°æ®ä¸­ï¼Œä»ä¸­å¯¹è¾“å…¥åˆ°æ¨¡å‹çš„æŸ¥è¯¢è¿›è¡Œé‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Wirth, RÃ¼diger, and Jochen Hipp. 2000. CRISP-DM: Towards a standard process model for data mining. In Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining, 29â€“39. Citeseer.",
            "zh": "Wirthã€RÃ¼diger å’Œ Jochen Hippã€‚2000. CRISP-DMï¼šè¿ˆå‘æ•°æ®æŒ–æ˜çš„æ ‡å‡†è¿‡ç¨‹æ¨¡å‹ã€‚ç¬¬å››å±ŠçŸ¥è¯†å‘ç°å’Œæ•°æ®æŒ–æ˜å®é™…åº”ç”¨å›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œç¬¬29-39é¡µã€‚Citeseerã€‚"
        }
    },
    {
        "translation": {
            "en": "Put in subjective terms, Bayesâ€™ Theorem tells us that by modifying our initial beliefs about what has happened (our prior beliefs about the world) proportionally with how our observations relate to their potential causes (inverse probability), we can update our beliefs regarding what has happened to cause our observations (forward probability).",
            "zh": "ä»ä¸»è§‚çš„è§’åº¦æ¥çœ‹ï¼Œè´å¶æ–¯å®šç†å‘Šè¯‰æˆ‘ä»¬ï¼Œé€šè¿‡ä¿®æ”¹æˆ‘ä»¬å¯¹æ‰€å‘ç”Ÿçš„äº‹æƒ…çš„åˆå§‹ä¿¡å¿µï¼ˆæˆ‘ä»¬å¯¹ä¸–ç•Œçš„å…ˆå‰ä¿¡å¿µï¼‰ä¸æˆ‘ä»¬çš„è§‚å¯Ÿç»“æœä¸å…¶æ½œåœ¨åŸå› çš„å…³ç³»ï¼ˆåå‘æ¦‚ç‡ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ–°æˆ‘ä»¬å¯¹å¯¼è‡´æˆ‘ä»¬è§‚å¯Ÿç»“æœçš„æ‰€å‘ç”Ÿäº‹ä»¶çš„ä¿¡å¿µï¼ˆæ­£å‘æ¦‚ç‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The XOR function returns TRUE if either but not both of its inputs are TRUE.",
            "zh": "å¦‚æœ XOR å‡½æ•°çš„ä»»ä¸€è¾“å…¥ï¼ˆä½†ä¸æ˜¯ä¸¤ä¸ªï¼‰å‡ä¸º TRUEï¼Œåˆ™è¿”å› TRUEã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.2â€…â€…â€…Setting the Learning Rate Using Weight Decay",
            "zh": "7.4.2 ä½¿ç”¨æƒé‡è¡°å‡è®¾ç½®å­¦ä¹ ç‡"
        }
    },
    {
        "translation": {
            "en": "6.7â€…â€…â€…(a) The area under a density curve between the limits and (b) the approximation of this area computed by PDF (x) Ã— Ïµ; and (c) the error in the approximation is equal to the difference between area A, the area under the curve omitted from the approximation, and area B, the area above the curve erroneously included in the approximation. Both of these areas will get smaller as the width of the interval gets smaller, resulting in a smaller error in the approximation.",
            "zh": "6.7 ï¼ˆaï¼‰ æé™ä¹‹é—´çš„å¯†åº¦æ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œä»¥åŠ ï¼ˆbï¼‰ PDF ï¼ˆxï¼‰ Ã— Îµ è®¡ç®—çš„è¯¥é¢ç§¯çš„è¿‘ä¼¼å€¼;ï¼ˆcï¼‰è¿‘ä¼¼è¯¯å·®ç­‰äºé¢ç§¯Aï¼ˆä»è¿‘ä¼¼ä¸­çœç•¥çš„æ›²çº¿ä¸‹é¢ç§¯ï¼‰å’Œé¢ç§¯Bï¼ˆæ›²çº¿ä¸Šæ–¹çš„é¢ç§¯é”™è¯¯åœ°åŒ…å«åœ¨è¿‘ä¼¼å€¼ä¸­ï¼‰ä¹‹é—´çš„å·®å€¼ã€‚éšç€é—´éš”å®½åº¦å˜å°ï¼Œè¿™ä¸¤ä¸ªåŒºåŸŸéƒ½ä¼šå˜å°ï¼Œä»è€Œå¯¼è‡´è¿‘ä¼¼è¯¯å·®å˜å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "gold, silver, or bronze) could be used as a proxy ground truth, and the ability of the clustering to separate the dataset into groups of the same tariff type could be used as a measure of the quality of the clustering.",
            "zh": "é‡‘ã€é“¶æˆ–é’é“œï¼‰å¯ä»¥ç”¨ä½œä»£ç†åœ°é¢äº‹å®ï¼Œèšç±»å°†æ•°æ®é›†åˆ†æˆç›¸åŒå…³ç¨ç±»å‹çš„ç»„çš„èƒ½åŠ›å¯ä»¥ç”¨ä½œèšç±»è´¨é‡çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Here unsupervised machine learning techniques are used to learn new sets of generated features to represent instance in a dataset.",
            "zh": "åœ¨è¿™é‡Œï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ç”¨äºå­¦ä¹ ç”Ÿæˆçš„æ–°ç‰¹å¾é›†ï¼Œä»¥è¡¨ç¤ºæ•°æ®é›†ä¸­çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning, the degree to which an agent has achieved a goal is measured only by the cumulative rewards it has received from each action taken in pursuit of that goal.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“å®ç°ç›®æ ‡çš„ç¨‹åº¦ä»…é€šè¿‡å…¶ä¸ºè¿½æ±‚è¯¥ç›®æ ‡è€Œé‡‡å–çš„æ¯é¡¹è¡ŒåŠ¨ä¸­è·å¾—çš„ç´¯ç§¯å¥–åŠ±æ¥è¡¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that we use different equations to calculate the Î´ value for a neuron, depending on whether the neuron is an output neuron or a neuron in a hidden layer.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„æ–¹ç¨‹æ¥è®¡ç®—ç¥ç»å…ƒçš„Î´å€¼ï¼Œå…·ä½“å–å†³äºè¯¥ç¥ç»å…ƒæ˜¯è¾“å‡ºç¥ç»å…ƒè¿˜æ˜¯éšè—å±‚ä¸­çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The per example error of the ReLU network after the forward pass illustrated in Figure 8.18[440], the per example âˆ‚â„°/âˆ‚a 8, and the sum of squared errors for the ReLU model.",
            "zh": "å›¾ 8.18[440] æ‰€ç¤ºçš„å‰å‘ä¼ é€’å ReLU ç½‘ç»œçš„æ¯ä¸ªç¤ºä¾‹è¯¯å·®ã€æ¯ä¸ªç¤ºä¾‹ âˆ‚E/âˆ‚a 8 ä»¥åŠ ReLU æ¨¡å‹çš„å¹³æ–¹è¯¯å·®æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast, in most predictive analytics projects, our focus is on determining the best model for a specific problem.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨å¤§å¤šæ•°é¢„æµ‹åˆ†æé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬çš„é‡ç‚¹æ˜¯ç¡®å®šç‰¹å®šé—®é¢˜çš„æœ€ä½³æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next step is to compute the entropy remaining after we split the dataset using each of the descriptive features. The computation for the SUSPICIOUS WORDS feature is7",
            "zh": "ä¸‹ä¸€æ­¥æ˜¯è®¡ç®—ä½¿ç”¨æ¯ä¸ªæè¿°æ€§ç‰¹å¾æ‹†åˆ†æ•°æ®é›†åå‰©ä½™çš„ç†µã€‚SUSPICIOUS WORDS ç‰¹å¾çš„è®¡ç®—ä¸º 7"
        }
    },
    {
        "translation": {
            "en": "For each of these cases, what we wish to calculate during backpropagation is the rate of change of the error with respect to changes in each of the inputs to the product.",
            "zh": "å¯¹äºè¿™äº›æƒ…å†µä¸­çš„æ¯ä¸€ç§ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨åå‘ä¼ æ’­æœŸé—´è®¡ç®—çš„æ˜¯ç›¸å¯¹äºä¹˜ç§¯çš„æ¯ä¸ªè¾“å…¥å˜åŒ–çš„è¯¯å·®å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "New methods that expand on the ideas described in this section are being proposed all the time and some of the most promising are discussed in section 11.6[677].",
            "zh": "åœ¨æœ¬èŠ‚ä¸­æè¿°çš„æƒ³æ³•çš„åŸºç¡€ä¸Šï¼Œä¸æ–­æå‡ºæ‰©å±•çš„æ–°æ–¹æ³•ï¼Œç¬¬11.6èŠ‚[677]è®¨è®ºäº†ä¸€äº›æœ€æœ‰å‰é€”çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Forks in the forward computation flow are handled in backpropagation by summing the derivatives that are flowing back along each of the fork branches.",
            "zh": "å‰å‘è®¡ç®—æµä¸­çš„åˆ†å‰åœ¨åå‘ä¼ æ’­ä¸­é€šè¿‡å¯¹æ²¿æ¯ä¸ªåˆ†å‰åˆ†æ”¯å›æµçš„å¯¼æ•°æ±‚å’Œæ¥å¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "To show how reduced error pruning works, we consider the task of predicting whether a post-operative patient should be sent to an intensive care unit (ICU) or to a general ward for recovery.23 Hypothermia is a major concern for post-operative patients, so many of the descriptive features relevant to this domain relate to a patientâ€™s body temperature.",
            "zh": "ä¸ºäº†è¯´æ˜å‡å°‘è¯¯å·®ä¿®å‰ªæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬è€ƒè™‘äº†é¢„æµ‹æœ¯åæ‚£è€…æ˜¯å¦åº”è¯¥è¢«é€å¾€é‡ç—‡ç›‘æŠ¤ç—…æˆ¿ï¼ˆICUï¼‰æˆ–æ™®é€šç—…æˆ¿è¿›è¡Œåº·å¤çš„ä»»åŠ¡.23ä½“æ¸©è¿‡ä½æ˜¯æœ¯åæ‚£è€…çš„ä¸»è¦å…³æ³¨ç‚¹ï¼Œå› æ­¤ä¸è¯¥é¢†åŸŸç›¸å…³çš„è®¸å¤šæè¿°æ€§ç‰¹å¾éƒ½ä¸æ‚£è€…çš„ä½“æ¸©æœ‰å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2.2â€…â€…â€…Matching Machine Learning Approaches to Data",
            "zh": "14.2.2 å°†æœºå™¨å­¦ä¹ æ–¹æ³•ä¸æ•°æ®ç›¸åŒ¹é…"
        }
    },
    {
        "translation": {
            "en": "For clarity there are some extra notational conventions used in Chapter 6[243] on probability.",
            "zh": "ä¸ºäº†æ¸…æ¥šèµ·è§ï¼Œåœ¨ç¬¬6ç« [243]ä¸­å…³äºæ¦‚ç‡ä½¿ç”¨äº†ä¸€äº›é¢å¤–çš„ç¬¦å·çº¦å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "These figures indicate that there is a strong positive relationship between the height and weight of a player, and a much smaller positive relationship between height and age. This supports the relationships suggested by the scatter plots of these pairs of features shown in Figures 3.5(a)[74] and 3.5(c)[74].",
            "zh": "è¿™äº›æ•°å­—è¡¨æ˜ï¼Œçƒå‘˜çš„èº«é«˜å’Œä½“é‡ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„æ­£ç›¸å…³å…³ç³»ï¼Œè€Œèº«é«˜å’Œå¹´é¾„ä¹‹é—´çš„æ­£ç›¸å…³å…³ç³»è¦å°å¾—å¤šã€‚è¿™æ”¯æŒäº†å›¾3.5ï¼ˆaï¼‰[74]å’Œå›¾3.5ï¼ˆcï¼‰[74]æ‰€ç¤ºçš„è¿™äº›ç‰¹å¾å¯¹çš„æ•£ç‚¹å›¾æ‰€æš—ç¤ºçš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This extra weight term allows the model to define lines that do not go through the origin of the input space: setting the w[0] to a value other than 0 translates the line defined by the model away from the origin of the input space, just as changing the value of the y-intercept in the equation of a line moves a line up and down the y-axis away from the origin.",
            "zh": "è¿™ä¸ªé¢å¤–çš„æƒé‡é¡¹å…è®¸æ¨¡å‹å®šä¹‰ä¸ç»è¿‡è¾“å…¥ç©ºé—´åŸç‚¹çš„çº¿ï¼šå°† w[0] è®¾ç½®ä¸º 0 ä»¥å¤–çš„å€¼ä¼šå°†æ¨¡å‹å®šä¹‰çš„çº¿ä»è¾“å…¥ç©ºé—´çš„åŸç‚¹è½¬æ¢ï¼Œå°±åƒæ›´æ”¹ç›´çº¿æ–¹ç¨‹ä¸­çš„ y æˆªè·å€¼ä¼šä½¿ y è½´ä¸Šä¸‹ç§»åŠ¨ä¸€æ¡çº¿è¿œç¦»åŸç‚¹ä¸€æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activation (or output) of single neuron i is denoted by ai",
            "zh": "å•ä¸ªç¥ç»å…ƒ i çš„æ¿€æ´»ï¼ˆæˆ–è¾“å‡ºï¼‰ç”¨ ai è¡¨ç¤º"
        }
    },
    {
        "translation": {
            "en": "7.5â€…â€…â€…Summary",
            "zh": "7.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "We knew when we began writing this book that it would take a huge amount of work to complete.",
            "zh": "å½“æˆ‘ä»¬å¼€å§‹å†™è¿™æœ¬ä¹¦æ—¶ï¼Œæˆ‘ä»¬å°±çŸ¥é“éœ€è¦å¤§é‡çš„å·¥ä½œæ‰èƒ½å®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "At each time-step a new input vector is presented to the network; this flows forward to the hidden layer.",
            "zh": "åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ï¼Œä¸€ä¸ªæ–°çš„è¾“å…¥å‘é‡è¢«å‘ˆç°ç»™ç½‘ç»œ;è¿™å‘å‰æµå‘éšè—å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.10â€…â€…â€…An illustration of how the representational capacity of a network increases as more layers are added to the network.",
            "zh": "8.10 è¯´æ˜éšç€ç½‘ç»œä¸­å¢åŠ æ›´å¤šå±‚ï¼Œç½‘ç»œçš„ä»£è¡¨èƒ½åŠ›å¦‚ä½•å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The human brain is, of course, much more complex and sophisticated than even the most advanced deep learning models.",
            "zh": "å½“ç„¶ï¼Œäººè„‘ç”šè‡³æ¯”æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¦å¤æ‚å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "DOSE2",
            "zh": "å‰‚é‡2"
        }
    },
    {
        "translation": {
            "en": "The difference in the distribution between hidden layer 1 (HL1) and the other hidden layers is caused by the fact that there are only two inputs into each of the neurons in HL1 whereas there are 100 inputs into each of the neurons in the other hidden layers.",
            "zh": "éšè—å±‚ 1 ï¼ˆHL1ï¼‰ å’Œå…¶ä»–éšè—å±‚ä¹‹é—´åˆ†å¸ƒçš„å·®å¼‚æ˜¯ç”±äº HL1 ä¸­æ¯ä¸ªç¥ç»å…ƒåªæœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œè€Œå…¶ä»–éšè—å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒæœ‰ 100 ä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to calculate the Î´s for the neurons in each of these layers, we must multiply these error gradients by the derivative of the activation function for the layer with respect to the inputs to the activation function (i.e., âˆ‚a/âˆ‚z).",
            "zh": "ä¸ºäº†è®¡ç®—æ¯ä¸€å±‚ä¸­ç¥ç»å…ƒçš„Î´sï¼Œæˆ‘ä»¬å¿…é¡»å°†è¿™äº›è¯¯å·®æ¢¯åº¦ä¹˜ä»¥è¯¥å±‚çš„æ¿€æ´»å‡½æ•°ç›¸å¯¹äºæ¿€æ´»å‡½æ•°è¾“å…¥çš„å¯¼æ•°ï¼ˆå³âˆ‚a/âˆ‚zï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, there is no error gradient with respect to the non-max values that the max function received.",
            "zh": "å› æ­¤ï¼Œmax å‡½æ•°æ¥æ”¶åˆ°çš„é max å€¼æ²¡æœ‰è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The random action selected in this case is down.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹é€‰æ‹©çš„éšæœºæ“ä½œä¸ºå…³é—­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 2.2",
            "zh": "è¡¨ 2.2"
        }
    },
    {
        "translation": {
            "en": "With help from Grace to implement the actual data manipulation and data integration scripts using the tools available at AT, Ross populated an ABT containing all the features listed in Table 12.1[692].",
            "zh": "åœ¨ Grace çš„å¸®åŠ©ä¸‹ï¼Œä½¿ç”¨ AT æä¾›çš„å·¥å…·å®ç°å®é™…çš„æ•°æ®æ“ä½œå’Œæ•°æ®é›†æˆè„šæœ¬ï¼ŒRoss å¡«å……äº†ä¸€ä¸ªåŒ…å«è¡¨ 12.1[692] ä¸­åˆ—å‡ºçš„æ‰€æœ‰åŠŸèƒ½çš„ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "This always simply predicts the average value of the target feature from the datasetâ€”in this case a rental demand of 1,287.1 bicycles.",
            "zh": "è¿™å§‹ç»ˆåªæ˜¯ç®€å•åœ°é¢„æµ‹æ•°æ®é›†ä¸­ç›®æ ‡è¦ç´ çš„å¹³å‡å€¼ï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸º 1,287.1 è¾†è‡ªè¡Œè½¦çš„ç§Ÿèµéœ€æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. The image below shows a set of eight Scrabble pieces.",
            "zh": "1. ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ç»„å…«ä¸ªæ‹¼å­—æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œgambling for funâ€",
            "zh": "â€œèµŒåšå¥½ç©â€"
        }
    },
    {
        "translation": {
            "en": "In the predictive analytics context, the standard approach is to use relative frequency, and we focus on this approach in this chapter.",
            "zh": "åœ¨é¢„æµ‹åˆ†æä¸Šä¸‹æ–‡ä¸­ï¼Œæ ‡å‡†æ–¹æ³•æ˜¯ä½¿ç”¨ç›¸å¯¹é¢‘ç‡ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« ä¸­é‡ç‚¹ä»‹ç»è¿™ç§æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The decision boundary using majority vote of the nearest 15 neighbors; and (b) the weighted k nearest neighbor model decision boundary (with k = 21).",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨æœ€è¿‘çš„15ä¸ªé‚»å›½çš„å¤šæ•°ç¥¨ä½œå‡ºçš„å†³å®šè¾¹ç•Œ;ï¼ˆbï¼‰åŠ æƒkæœ€è¿‘é‚»æ¨¡å‹å†³ç­–è¾¹ç•Œï¼ˆk = 21ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Not long afterward, however, Mr. Murphyâ€™s son, Andrew, ran in to say that he had fixed the letters in the kitchen because they had been so badly organized.",
            "zh": "ç„¶è€Œï¼Œä¸ä¹…ä¹‹åï¼Œå¢¨è²çš„å„¿å­å®‰å¾·é²è·‘è¿›æ¥ï¼Œè¯´ä»–æŠŠè¿™äº›ä¿¡æ”¾åœ¨å¨æˆ¿é‡Œä¿®å¥½äº†ï¼Œå› ä¸ºå®ƒä»¬å¤ªç³Ÿç³•äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "They are also the basis for a whole range of different performance measures that can highlight different aspects of the performance of a predictive model.",
            "zh": "å®ƒä»¬ä¹Ÿæ˜¯ä¸€ç³»åˆ—ä¸åŒæ€§èƒ½åº¦é‡çš„åŸºç¡€ï¼Œè¿™äº›åº¦é‡å¯ä»¥çªå‡ºé¢„æµ‹æ¨¡å‹æ€§èƒ½çš„ä¸åŒæ–¹é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "The plot of the density curve for the exponential distribution (Figure 6.3(b)[270]) shows that it assigns a high probability to values near the left of the distribution and that the probability of a value occurring drops dramatically as we move to the right.",
            "zh": "æŒ‡æ•°åˆ†å¸ƒçš„å¯†åº¦æ›²çº¿å›¾ï¼ˆå›¾6.3ï¼ˆbï¼‰[270]ï¼‰è¡¨æ˜ï¼Œå®ƒä¸ºåˆ†å¸ƒå·¦ä¾§é™„è¿‘çš„å€¼åˆ†é…äº†é«˜æ¦‚ç‡ï¼Œå¹¶ä¸”å½“æˆ‘ä»¬å‘å³ç§»åŠ¨æ—¶ï¼Œè¯¥å€¼å‡ºç°çš„æ¦‚ç‡æ€¥å‰§ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can now complete the information gain calculation for each descriptive feature",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å®Œæˆæ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šè®¡ç®—"
        }
    },
    {
        "translation": {
            "en": "7. Assuming a fully connected feedforward network where all the neurons uses a linear activation function (i.e., ai = zi) and with the following topology:",
            "zh": "7. å‡è®¾ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œï¼Œå…¶ä¸­æ‰€æœ‰ç¥ç»å…ƒéƒ½ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå³ ai = ziï¼‰å¹¶å…·æœ‰ä»¥ä¸‹æ‹“æ‰‘ç»“æ„ï¼š"
        }
    },
    {
        "translation": {
            "en": "Blackjack, 645",
            "zh": "äºŒåä¸€ç‚¹ï¼Œ645"
        }
    },
    {
        "translation": {
            "en": "Based on her understanding of the SDSS process, Jocelyn sketched out the first draft of the domain concepts diagram for the galaxy classification problem shown in Figure 13.2[708].",
            "zh": "åŸºäºå¥¹å¯¹SDSSè¿‡ç¨‹çš„ç†è§£ï¼ŒJocelynå‹¾å‹’å‡ºå›¾13.2[708]æ‰€ç¤ºæ˜Ÿç³»åˆ†ç±»é—®é¢˜çš„é¢†åŸŸæ¦‚å¿µå›¾çš„åˆç¨¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.0904",
            "zh": "0.0904"
        }
    },
    {
        "translation": {
            "en": "11.7â€ƒExercises",
            "zh": "11.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "-0.47",
            "zh": "-0.47"
        }
    },
    {
        "translation": {
            "en": "Finally, as discussed in the Information Based Learning chapter, in which we discussed tree pruning to avoid overfitting, using the performance of the model on the validation set to decide when to stop the training and weight updates is nearly always the case in training a neural network.",
            "zh": "æœ€åï¼Œæ­£å¦‚åœ¨â€œåŸºäºä¿¡æ¯çš„å­¦ä¹ â€ä¸€ç« ä¸­æ‰€è®¨è®ºçš„ï¼Œæˆ‘ä»¬åœ¨å…¶ä¸­è®¨è®ºäº†æ ‘ä¿®å‰ªä»¥é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œåœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œä½¿ç”¨æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½æ¥å†³å®šä½•æ—¶åœæ­¢è®­ç»ƒå’Œæƒé‡æ›´æ–°å‡ ä¹æ€»æ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will, however, leave this calculation to the interested reader (the result should still be 0.7).",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ä¸ªè®¡ç®—ç•™ç»™æ„Ÿå…´è¶£çš„è¯»è€…ï¼ˆç»“æœä»åº”ä¸º 0.7ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "U_U/G/R/I/Z",
            "zh": "U_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "4.20â€…â€…â€…The process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "4.20 ä½¿ç”¨è£…è¢‹å’Œå­ç©ºé—´é‡‡æ ·åˆ›å»ºæ¨¡å‹é›†åˆçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "They found that on average, ensemble models and support vector machines were among the most accurate models.",
            "zh": "ä»–ä»¬å‘ç°ï¼Œå¹³å‡è€Œè¨€ï¼Œé›†æˆæ¨¡å‹å’Œæ”¯æŒå‘é‡æœºæ˜¯æœ€å‡†ç¡®çš„æ¨¡å‹ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) What value would a weighted k-NN prediction modelâ€”with k = 16 (i.e., the full dataset) and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the queryâ€”return for the CPI of Russia when it is applied to the range-normalized data?",
            "zh": "ï¼ˆdï¼‰ å½“ä¿„ç½—æ–¯çš„ CPI åº”ç”¨äºèŒƒå›´å½’ä¸€åŒ–æ•°æ®æ—¶ï¼ŒåŠ æƒ k-NN é¢„æµ‹æ¨¡å‹ï¼ˆk = 16ï¼ˆå³å®Œæ•´æ•°æ®é›†ï¼‰å¹¶ä½¿ç”¨é‚»åŸŸå’ŒæŸ¥è¯¢ä¹‹é—´æ¬§å‡ é‡Œå¾—è·ç¦»å¹³æ–¹çš„å€’æ•°åŠ æƒæ–¹æ¡ˆï¼‰ä¼šè¿”å›ä»€ä¹ˆå€¼ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "To address this issue, we can use average class accuracy7 instead of classification accuracy.8 The average class accuracy is calculated as",
            "zh": "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¹³å‡ç±»å‡†ç¡®ç‡7è€Œä¸æ˜¯åˆ†ç±»å‡†ç¡®ç‡8ï¼Œå¹³å‡ç±»å‡†ç¡®ç‡çš„è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "4. This kind of classification is not unusual because supermarket chains can collect huge amounts of data about customersâ€™ shopping habits through a loyalty card scheme but find it expensive and time consuming to collect more personal data, such as demographic classifications. Demographic classifications, however, are extremely useful to marketing departments in designing special offers and other customer incentives.",
            "zh": "4. è¿™ç§åˆ†ç±»å¹¶ä¸ç½•è§ï¼Œå› ä¸ºè¿é”è¶…å¸‚å¯ä»¥é€šè¿‡ä¼šå‘˜å¡è®¡åˆ’æ”¶é›†å¤§é‡æœ‰å…³é¡¾å®¢è´­ç‰©ä¹ æƒ¯çš„æ•°æ®ï¼Œä½†å‘ç°æ”¶é›†æ›´å¤šä¸ªäººæ•°æ®ï¼ˆä¾‹å¦‚äººå£ç»Ÿè®¡åˆ†ç±»ï¼‰æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚ç„¶è€Œï¼Œäººå£ç»Ÿè®¡åˆ†ç±»å¯¹äºè¥é”€éƒ¨é—¨åœ¨è®¾è®¡ç‰¹åˆ«ä¼˜æƒ å’Œå…¶ä»–å®¢æˆ·æ¿€åŠ±æªæ–½æ—¶éå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.1â€…â€…â€…(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset; and (b) the scatter plot from (a) with a linear model relating RENTAL PRICE to SIZE overlaid.",
            "zh": "7.1 ï¼ˆaï¼‰ å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†ä¸­ SIZE å’Œ RENTAL PRICE ç‰¹å¾çš„æ•£ç‚¹å›¾;ï¼ˆbï¼‰æ¥è‡ªï¼ˆaï¼‰çš„æ•£ç‚¹å›¾ï¼Œå…¶ä¸­å åŠ äº†ä¸RENTAL PRICEå’ŒSIZEç›¸å…³çš„çº¿æ€§æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The classification accuracy of 79.03% is well above the target agreed on with the business.",
            "zh": "79.03%çš„åˆ†ç±»å‡†ç¡®ç‡è¿œé«˜äºä¸ä¸šåŠ¡å•†å®šçš„ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.14",
            "zh": "è¡¨ 6.14"
        }
    },
    {
        "translation": {
            "en": "In this iteration, the error rate of the root node (1) is greater than the error rate of the three leaf nodes, (0 + 0 + 0 = 0), so the tree is left unchanged.",
            "zh": "åœ¨æ­¤è¿­ä»£ä¸­ï¼Œæ ¹èŠ‚ç‚¹ ï¼ˆ1ï¼‰ çš„é”™è¯¯ç‡å¤§äºä¸‰ä¸ªå¶èŠ‚ç‚¹çš„é”™è¯¯ç‡ ï¼ˆ0 + 0 + 0 = 0ï¼‰ï¼Œå› æ­¤æ ‘ä¿æŒä¸å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We highlight this distinction by using different for loops for each of these conditions.",
            "zh": "æˆ‘ä»¬é€šè¿‡å¯¹æ¯ä¸ªæ¡ä»¶ä½¿ç”¨ä¸åŒçš„ for å¾ªç¯æ¥å¼ºè°ƒè¿™ç§åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The standard error for the overall model is calculated as follows:",
            "zh": "æ•´ä¸ªæ¨¡å‹çš„æ ‡å‡†è¯¯å·®è®¡ç®—å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Accessing the results of the SDSS processing pipeline turned out to be reasonably straightforward, as it was already collected into a single large table in the SDSS data repository.",
            "zh": "è®¿é—® SDSS å¤„ç†ç®¡é“çš„ç»“æœå˜å¾—ç›¸å½“ç®€å•ï¼Œå› ä¸ºå®ƒå·²ç»æ”¶é›†åˆ° SDSS æ•°æ®å­˜å‚¨åº“ä¸­çš„ä¸€ä¸ªå¤§è¡¨ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "To address these different project requirements, there is a spectrum of different approaches to measuring the performance of a model, and it is important to align the correct approach with a given modeling task.",
            "zh": "ä¸ºäº†æ»¡è¶³è¿™äº›ä¸åŒçš„é¡¹ç›®è¦æ±‚ï¼Œæœ‰ä¸€ç³»åˆ—ä¸åŒçš„æ–¹æ³•æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¿…é¡»ä½¿æ­£ç¡®çš„æ–¹æ³•ä¸ç»™å®šçš„å»ºæ¨¡ä»»åŠ¡ä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The CRISP-DM process documentation (Chapman et al., 2000) is surprisingly readable, and adds a lot of extra detail to the tasks described in this chapter. For details on developing business concepts and designing features, Svolba (2007) is excellent (the approaches described can be applied to any tool, not just SAS, which is the focus of Svolbaâ€™s book).",
            "zh": "CRISP-DMè¿‡ç¨‹æ–‡æ¡£ï¼ˆChapmanç­‰äººï¼Œ2000ï¼‰å…·æœ‰ä»¤äººæƒŠè®¶çš„å¯è¯»æ€§ï¼Œå¹¶ä¸ºæœ¬ç« ä¸­æè¿°çš„ä»»åŠ¡å¢åŠ äº†è®¸å¤šé¢å¤–çš„ç»†èŠ‚ã€‚å¯¹äºå¼€å‘ä¸šåŠ¡æ¦‚å¿µå’Œè®¾è®¡åŠŸèƒ½çš„ç»†èŠ‚ï¼ŒSvolba ï¼ˆ2007ï¼‰éå¸¸å‡ºè‰²ï¼ˆæ‰€æè¿°çš„æ–¹æ³•å¯ä»¥åº”ç”¨äºä»»ä½•å·¥å…·ï¼Œè€Œä¸ä»…ä»…æ˜¯SASï¼Œè¿™æ˜¯Svolbaä¹¦çš„é‡ç‚¹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The threshold â‰¥4,175 has the highest information gain of any of the candidate thresholds (0.8631 bits), and this information gain is also higher than the information gain for either of the other two descriptive features.",
            "zh": "é˜ˆå€¼ â‰¥4,175 åœ¨æ‰€æœ‰å€™é€‰é˜ˆå€¼ ï¼ˆ0.8631 ä½ï¼‰ ä¸­å…·æœ‰æœ€é«˜çš„ä¿¡æ¯å¢ç›Šï¼Œå¹¶ä¸”æ­¤ä¿¡æ¯å¢ç›Šä¹Ÿé«˜äºå…¶ä»–ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ä¸­ä»»ä¸€çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This makes sense because if a model is performing accurately, we would expect negative instances to have low scores (close to 0.0) and positive instances to have high scores (close to 1.0).",
            "zh": "è¿™æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå¦‚æœæ¨¡å‹æ‰§è¡Œå‡†ç¡®ï¼Œæˆ‘ä»¬é¢„è®¡è´Ÿå®ä¾‹çš„åˆ†æ•°è¾ƒä½ï¼ˆæ¥è¿‘ 0.0ï¼‰ï¼Œæ­£å®ä¾‹çš„åˆ†æ•°å¾ˆé«˜ï¼ˆæ¥è¿‘ 1.0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The learning rate, Î±, determines the size of the adjustments made to weights at each iteration of the algorithm and is discussed further in Section 7.3.3[328].",
            "zh": "Î±ï¼Œå­¦ä¹ ç‡å†³å®šäº†ç®—æ³•æ¯æ¬¡è¿­ä»£æ—¶å¯¹æƒé‡æ‰€åšçš„è°ƒæ•´å¤§å°ï¼Œå¹¶åœ¨ç¬¬ 7.3.3 èŠ‚[328]ä¸­è¿›ä¸€æ­¥è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In the trained model the value of w0 is 0.3074, and the values of the Î± parameters are âŸ¨7.1655,6.9060,2.0033,6.1144,5.9538âŸ©.",
            "zh": "åœ¨è®­ç»ƒæ¨¡å‹ä¸­ï¼Œw0 çš„å€¼ä¸º 0.3074ï¼ŒÎ±å‚æ•°çš„å€¼ä¸º âŸ¨7.1655ã€6.9060ã€2.0033ã€6.1144ã€5.9538âŸ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because the action is now selected using the Îµ-greedy policy, whereas the action used during the update was selected off-policy.",
            "zh": "è¿™æ˜¯å› ä¸ºç°åœ¨ä½¿ç”¨Îµè´ªå©ªç­–ç•¥é€‰æ‹©æ“ä½œï¼Œè€Œæ›´æ–°æœŸé—´ä½¿ç”¨çš„æ“ä½œæ˜¯åœ¨ç­–ç•¥å¤–é€‰æ‹©çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "To highlight this change in activation functions between the layers, we have labeled the Ï† symbol in the figure with the name of the activation function it represents.",
            "zh": "ä¸ºäº†çªå‡ºæ˜¾ç¤ºå±‚ä¹‹é—´æ¿€æ´»å‡½æ•°çš„è¿™ç§å˜åŒ–ï¼Œæˆ‘ä»¬ç”¨å®ƒæ‰€ä»£è¡¨çš„æ¿€æ´»å‡½æ•°çš„åç§°æ ‡è®°äº†å›¾ä¸­çš„Ï†ç¬¦å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 10.12(c)[621], and Table 10.5(b)[620] shows an updated distance matrix including these new clusters.",
            "zh": "å¦‚å›¾10.12ï¼ˆcï¼‰[621]æ‰€ç¤ºï¼Œè¡¨10.5ï¼ˆbï¼‰[620]æ˜¾ç¤ºäº†åŒ…æ‹¬è¿™äº›æ–°èšç±»åœ¨å†…çš„æ›´æ–°è·ç¦»çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "14. The Bellman Equations were first introduced by Richard Bellman in the 1950s (Bellman, 1957a,b) as part of very early work on reinforcement learning.",
            "zh": "14. è´å°”æ›¼æ–¹ç¨‹æœ€æ—©æ˜¯ç”±ç†æŸ¥å¾·Â·è´å°”æ›¼åœ¨1950å¹´ä»£æå‡ºçš„ï¼ˆè´å°”æ›¼ï¼Œ1957aï¼Œbï¼‰ï¼Œä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„æ—©æœŸå·¥ä½œçš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "As such, it balances the search goals of model accuracy and simplicity.",
            "zh": "å› æ­¤ï¼Œå®ƒå¹³è¡¡äº†æ¨¡å‹å‡†ç¡®æ€§å’Œç®€å•æ€§çš„æœç´¢ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For consistency with the notation that we use in this book, we can rewrite the simple linear regression model",
            "zh": "ä¸ºäº†ä¸æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ä½¿ç”¨çš„ç¬¦å·ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬å¯ä»¥é‡å†™ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹"
        }
    },
    {
        "translation": {
            "en": "The statistical significance test we use to analyze the importance of a descriptive feature d[j] in a linear regression model is the t-test.",
            "zh": "æˆ‘ä»¬ç”¨äºåˆ†ææè¿°æ€§ç‰¹å¾ d[j] åœ¨çº¿æ€§å›å½’æ¨¡å‹ä¸­çš„é‡è¦æ€§çš„ç»Ÿè®¡æ˜¾ç€æ€§æ£€éªŒæ˜¯ t æ£€éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "In this scenario, everything else being equal, the weight updates for the salary feature will generally be larger than those for the age feature because the weight updates are scaled by the feature values.",
            "zh": "åœ¨æ­¤æ–¹æ¡ˆä¸­ï¼Œåœ¨å…¶ä»–æ¡ä»¶ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œå·¥èµ„è¦ç´ çš„æƒé‡æ›´æ–°é€šå¸¸å¤§äºå¹´é¾„è¦ç´ çš„æƒé‡æ›´æ–°ï¼Œå› ä¸ºæƒé‡æ›´æ–°æ˜¯æŒ‰è¦ç´ å€¼ç¼©æ”¾çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 12.4",
            "zh": "è¡¨ 12.4"
        }
    },
    {
        "translation": {
            "en": "Table 4.4[137] shows the calculation of the information gain for each feature using this result.",
            "zh": "è¡¨4.4[137]æ˜¾ç¤ºäº†ä½¿ç”¨æ­¤ç»“æœè®¡ç®—æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "However, for the purpose of illustration it is worth noting that the model would return the class label with the highest probability for each example; hence the model would return a prediction of low for all four examples in the mini-batch.",
            "zh": "ä½†æ˜¯ï¼Œå‡ºäºè¯´æ˜ç›®çš„ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ¨¡å‹å°†è¿”å›æ¯ä¸ªç¤ºä¾‹æ¦‚ç‡æœ€é«˜çš„ç±»æ ‡ç­¾;å› æ­¤ï¼Œè¯¥æ¨¡å‹å°†è¿”å›å°æ‰¹é‡ä¸­æ‰€æœ‰å››ä¸ªç¤ºä¾‹çš„ä½é¢„æµ‹å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final three dense layers had 4096 neurons each.",
            "zh": "æœ€åä¸‰å±‚å¯†é›†å±‚å„æœ‰4096ä¸ªç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "8.15â€…â€…â€…The calculation of the softmax activations for each of the neurons in the output layer for each example in the mini-batch, and the calculation of the Î´ for each neuron in the output layer for each example in the mini-batch.",
            "zh": "8.15 è®¡ç®—å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ softmax æ¿€æ´»æ¬¡æ•°ï¼Œä»¥åŠè®¡ç®—å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "We should always consider normalizing our data, but it is particularly important to do this when the descriptive features are measured in different units.",
            "zh": "æˆ‘ä»¬åº”è¯¥å§‹ç»ˆè€ƒè™‘å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†æ˜¯å½“ä»¥ä¸åŒçš„å•ä½æµ‹é‡æè¿°æ€§ç‰¹å¾æ—¶ï¼Œè¿™æ ·åšå°¤ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "A feature is any measure derived from a domain concept that can be directly included in an ABT for use by a machine learning algorithm.",
            "zh": "ç‰¹å¾æ˜¯ä»é¢†åŸŸæ¦‚å¿µæ´¾ç”Ÿçš„ä»»ä½•åº¦é‡ï¼Œå¯ä»¥ç›´æ¥åŒ…å«åœ¨ ABT ä¸­ä»¥ä¾›æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This region exists because one of the no instances occurs far away from the rest of the instances with this target level.",
            "zh": "ä¹‹æ‰€ä»¥å­˜åœ¨æ­¤åŒºåŸŸï¼Œæ˜¯å› ä¸ºå…¶ä¸­ä¸€ä¸ª no å®ä¾‹è¿œç¦»å…·æœ‰æ­¤ç›®æ ‡çº§åˆ«çš„å…¶ä½™å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because we can expect the error surface to be convex and possess a global minimum, we can find the optimal weights at the point where the partial derivatives of the error surface with respect to w[0] and w[1] are equal to 0.",
            "zh": "å› ä¸ºæˆ‘ä»¬å¯ä»¥é¢„æœŸè¯¯å·®æ›²é¢æ˜¯å‡¸çš„å¹¶ä¸”å…·æœ‰å…¨å±€æœ€å°å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨è¯¯å·®æ›²é¢ç›¸å¯¹äº w[0] å’Œ w[1] çš„åå¯¼æ•°ç­‰äº 0 çš„ç‚¹æ‰¾åˆ°æœ€ä½³æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, as is the case with the learning rate, there are no well-established, proven methods for choosing initial weights.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œä¸å­¦ä¹ ç‡ä¸€æ ·ï¼Œæ²¡æœ‰æˆç†Ÿçš„ã€è¡Œä¹‹æœ‰æ•ˆçš„æ–¹æ³•æ¥é€‰æ‹©åˆå§‹æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term iteration is used to refer to a single forward and backward pass plus weight update of the backpropagation algorithm.",
            "zh": "æœ¯è¯­è¿­ä»£ç”¨äºæŒ‡åå‘ä¼ æ’­ç®—æ³•çš„å•æ¬¡æ­£å‘å’Œåå‘ä¼ é€’ä»¥åŠæƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.2â€ƒAssessing Feasibility",
            "zh": "2.2 è¯„ä¼°å¯è¡Œæ€§"
        }
    },
    {
        "translation": {
            "en": "8.31â€…â€…â€…A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a receptive field that covers the top-left corner of the image.",
            "zh": "8.31 4 ç°åº¦å›¾åƒçš„ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠå…·æœ‰è¦†ç›–å›¾åƒå·¦ä¸Šè§’çš„æ„Ÿå—é‡çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Illustration of how a mixture of Gaussians model is composed of a number of normal distributions. The curve plotted using a solid line is the mixture of Gaussians density curve, created using an appropriately weighted summation of the three normal curves, plotted using dashed and dotted lines.",
            "zh": "é«˜æ–¯æ¨¡å‹çš„æ··åˆå¦‚ä½•ç”±è®¸å¤šæ­£æ€åˆ†å¸ƒç»„æˆçš„å›¾ç¤ºã€‚ä½¿ç”¨å®çº¿ç»˜åˆ¶çš„æ›²çº¿æ˜¯é«˜æ–¯å¯†åº¦æ›²çº¿çš„æ··åˆï¼Œä½¿ç”¨ä½¿ç”¨è™šçº¿å’Œè™šçº¿ç»˜åˆ¶çš„ä¸‰æ¡æ­£æ€æ›²çº¿çš„é€‚å½“åŠ æƒæ±‚å’Œåˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In this table, the instances in the dataset have been reordered in ascending order based on their LOAN AMOUNT values.",
            "zh": "åœ¨æ­¤è¡¨ä¸­ï¼Œæ•°æ®é›†ä¸­çš„å®ä¾‹å·²æ ¹æ®å…¶ LOAN AMOUNT å€¼æŒ‰å‡åºé‡æ–°æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "Each weight is considered independently, and for each one a small adjustment is made by adding a small value, called a delta value, to the current weight, w[j].",
            "zh": "æ¯ä¸ªæƒé‡éƒ½æ˜¯ç‹¬ç«‹è€ƒè™‘çš„ï¼Œå¯¹äºæ¯ä¸ªæƒé‡ï¼Œé€šè¿‡åœ¨å½“å‰æƒé‡ w[j] ä¸Šæ·»åŠ ä¸€ä¸ªå°å€¼ï¼ˆç§°ä¸ºå¢é‡å€¼ï¼‰æ¥è¿›è¡Œå°è°ƒæ•´ã€‚"
        }
    },
    {
        "translation": {
            "en": "To begin the gradient descent process, random starting values for the weights within the model, w[0],w[1],w[2], are selected. In this example, random values were selected from the range [âˆ’3, 3] to give w[0] = âˆ’2.9465, w[1] = âˆ’1.0147, and w[2] = 2.1610. Using these weights, a prediction is made for every instance in the training dataset, and the resulting sum of squared errors is calculated. The predictions made using these weights and the related error are shown in Table 7.8[348] under Iteration 1.",
            "zh": "è¦å¼€å§‹æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ï¼Œéœ€è¦é€‰æ‹©æ¨¡å‹ä¸­æƒé‡çš„éšæœºèµ·å§‹å€¼ w[0]ï¼Œw[1]ï¼Œw[2]ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œä»èŒƒå›´ [âˆ’3ï¼Œ 3] ä¸­é€‰æ‹©éšæœºå€¼ï¼Œå¾—å‡º w[0] = âˆ’2.9465ã€w[1] = âˆ’1.0147 å’Œ w[2] = 2.1610ã€‚ä½¿ç”¨è¿™äº›æƒé‡ï¼Œå¯¹è®­ç»ƒæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—ç»“æœçš„è¯¯å·®å¹³æ–¹å’Œã€‚ä½¿ç”¨è¿™äº›æƒé‡å’Œç›¸å…³è¯¯å·®è¿›è¡Œçš„é¢„æµ‹æ˜¾ç¤ºåœ¨è¿­ä»£ 1 ä¸‹çš„è¡¨ 7.8[348] ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„Î”1 is the model trained to predict the errors made by the base model, ğ•„0.",
            "zh": "å…¶ä¸­ MÎ”1 æ˜¯ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹åŸºç¡€æ¨¡å‹ M0 æ‰€çŠ¯çš„é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Other parts of the business that Ross spent significant time interviewing included the billing department, the sales and marketing team, and the network management.",
            "zh": "Ross èŠ±äº†å¤§é‡æ—¶é—´é‡‡è®¿çš„å…¶ä»–ä¸šåŠ¡éƒ¨é—¨åŒ…æ‹¬è®¡è´¹éƒ¨é—¨ã€é”€å”®å’Œè¥é”€å›¢é˜Ÿä»¥åŠç½‘ç»œç®¡ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "MITOSES: A measure of how fast cells are growing (1 to 10).",
            "zh": "æœ‰ä¸åˆ†è£‚ï¼šè¡¡é‡ç»†èƒç”Ÿé•¿é€Ÿåº¦çš„æŒ‡æ ‡ï¼ˆ1 åˆ° 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "During the training process, this is repeated multiple times.",
            "zh": "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™ä¼šé‡å¤å¤šæ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "While using profit might appear to be the ideal way to evaluate model performance for categorical targets, unfortunately, this is not the case.",
            "zh": "è™½ç„¶ä½¿ç”¨åˆ©æ¶¦ä¼¼ä¹æ˜¯è¯„ä¼°åˆ†ç±»ç›®æ ‡çš„æ¨¡å‹æ€§èƒ½çš„ç†æƒ³æ–¹æ³•ï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "identity matrix, 219",
            "zh": "å•ä½çŸ©é˜µï¼Œ219"
        }
    },
    {
        "translation": {
            "en": "Finally, the nearest neighbor algorithm is what is known as a lazy learner.",
            "zh": "æœ€åï¼Œæœ€è¿‘é‚»ç®—æ³•å°±æ˜¯æ‰€è°“çš„æ‡’æƒ°å­¦ä¹ è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was an iterative process in which Ross moved back and forth between Kate at the AT retention team, Grace, the CTO, and other parts of the business identified as having insight into the data associated with customer churn.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼ŒRoss åœ¨ AT ä¿ç•™å›¢é˜Ÿçš„ Kateã€é¦–å¸­æŠ€æœ¯å®˜ Grace å’Œå…¶ä»–ä¸šåŠ¡éƒ¨é—¨ä¹‹é—´æ¥å›ç§»åŠ¨ï¼Œè¿™äº›éƒ¨é—¨è¢«è®¤ä¸ºèƒ½å¤Ÿæ´å¯Ÿä¸å®¢æˆ·æµå¤±ç›¸å…³çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the indices in the weight subscripts are in reverse order from what might be expected: the first subscript is the index of the neuron to which the activation is flowing, and the second subscript is the index of the neuron that generated the activation.",
            "zh": "è¯·æ³¨æ„ï¼Œæƒé‡ä¸‹æ ‡ä¸­çš„ç´¢å¼•é¡ºåºä¸é¢„æœŸç›¸åï¼šç¬¬ä¸€ä¸ªä¸‹æ ‡æ˜¯æ¿€æ´»æµå‘çš„ç¥ç»å…ƒçš„ç´¢å¼•ï¼Œç¬¬äºŒä¸ªä¸‹æ ‡æ˜¯ç”Ÿæˆæ¿€æ´»çš„ç¥ç»å…ƒçš„ç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics can be used to build models that predict future customer actions on the basis of historical behavior.",
            "zh": "é¢„æµ‹æ€§æ•°æ®åˆ†æå¯ç”¨äºæ„å»ºæ¨¡å‹ï¼Œæ ¹æ®å†å²è¡Œä¸ºé¢„æµ‹æœªæ¥çš„å®¢æˆ·è¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Irrelevant: an irrelevant descriptive feature does not provide information that is useful in estimating the value of the target feature.",
            "zh": "ä¸ç›¸å…³ï¼šä¸ç›¸å…³çš„æè¿°æ€§ç‰¹å¾ä¸æä¾›å¯ç”¨äºä¼°è®¡ç›®æ ‡ç‰¹å¾å€¼çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm begins by choosing the best descriptive feature to test (i.e., the best question to ask first).",
            "zh": "è¯¥ç®—æ³•é¦–å…ˆé€‰æ‹©è¦æµ‹è¯•çš„æœ€ä½³æè¿°æ€§ç‰¹å¾ï¼ˆå³é¦–å…ˆè¦é—®çš„æœ€ä½³é—®é¢˜ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A distinctive aspect of this book is that we have chosen to present machine learning in context.",
            "zh": "æœ¬ä¹¦çš„ä¸€ä¸ªç‹¬ç‰¹ä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨ä¸Šä¸‹æ–‡ä¸­å‘ˆç°æœºå™¨å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "All these approaches are similar to k-d trees in that they are trying to set up indexes that enable efficient retrieval from a dataset.",
            "zh": "æ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½ç±»ä¼¼äº k-d æ ‘ï¼Œå› ä¸ºå®ƒä»¬éƒ½è¯•å›¾å»ºç«‹ç´¢å¼•ï¼Œä»¥ä¾¿ä»æ•°æ®é›†ä¸­é«˜æ•ˆæ£€ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability-based prediction approaches are heavily based on Bayesâ€™ Theorem, and the fundamentals section of this chapter introduces this important cornerstone of computer science after covering some other fundamentals of probability theory.",
            "zh": "åŸºäºæ¦‚ç‡çš„é¢„æµ‹æ–¹æ³•ä¸»è¦åŸºäºè´å¶æ–¯å®šç†ï¼Œæœ¬ç« çš„åŸºç¡€éƒ¨åˆ†åœ¨ä»‹ç»äº†æ¦‚ç‡è®ºçš„å…¶ä»–ä¸€äº›åŸºç¡€çŸ¥è¯†ä¹‹åï¼Œä»‹ç»äº†è®¡ç®—æœºç§‘å­¦çš„è¿™ä¸€é‡è¦åŸºçŸ³ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can also be seen in the top left-hand image of Figure 7.15[350],which shows the candidate model corresponding to this initial set of weights.",
            "zh": "è¿™ä¹Ÿå¯ä»¥åœ¨å›¾7.15[350]çš„å·¦ä¸Šè§’å›¾åƒä¸­çœ‹åˆ°ï¼Œè¯¥å›¾åƒæ˜¾ç¤ºäº†ä¸è¯¥åˆå§‹æƒé‡é›†ç›¸å¯¹åº”çš„å€™é€‰æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use Î”wi,k to write the sum of error gradients calculated for the weight wi,k. We sum errors in this way during batch gradient descent with which we sum over the examples in the batch; see Equation (8.30)[416] and also in cases in which the weight is shared by a number of neurons, whether in a convolutional neural network or during backpropagation through time.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ Î”wiï¼Œk æ¥å†™å‡ºä¸ºæƒé‡ wiï¼Œk è®¡ç®—çš„è¯¯å·®æ¢¯åº¦ä¹‹å’Œã€‚åœ¨æ‰¹æ¬¡æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»¥è¿™ç§æ–¹å¼å¯¹è¯¯å·®æ±‚å’Œï¼Œæˆ‘ä»¬å¯¹æ‰¹æ¬¡ä¸­çš„ç¤ºä¾‹æ±‚å’Œ;å‚è§æ–¹ç¨‹ï¼ˆ8.30ï¼‰[416]ï¼Œä»¥åŠæƒé‡ç”±å¤šä¸ªç¥ç»å…ƒå…±äº«çš„æƒ…å†µï¼Œæ— è®ºæ˜¯åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­è¿˜æ˜¯åœ¨éšæ—¶é—´åå‘ä¼ æ’­æœŸé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "D.1â€ƒBasic Types",
            "zh": "D.1 åŸºæœ¬ç±»å‹"
        }
    },
    {
        "translation": {
            "en": "This could be predicting the price that something will be sold for in the future; alternatively, it could mean predicting the type of document.",
            "zh": "è¿™å¯èƒ½æ˜¯é¢„æµ‹æœªæ¥æŸç‰©çš„å”®ä»·;æˆ–è€…ï¼Œè¿™å¯èƒ½æ„å‘³ç€é¢„æµ‹æ–‡æ¡£çš„ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.7â€ƒSummary",
            "zh": "3.7 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "The first things to check the cardinality column for are features with a cardinality of 1.",
            "zh": "é¦–å…ˆè¦æ£€æŸ¥åŸºæ•°åˆ—çš„æ˜¯åŸºæ•°ä¸º 1 çš„è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "This forward pass follows the set of operations illustrated in Figure 8.6[393].",
            "zh": "æ­¤å‰å‘ä¼ é€’éµå¾ªå›¾ 8.6[393] æ‰€ç¤ºçš„ä¸€ç»„æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "sampling without replacement, 159",
            "zh": "ä¸æ›´æ¢çš„é‡‡æ ·ï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "Using one of these tools, it is possible to train, evaluate, and deploy a predictive data analytics model in less than an hour!",
            "zh": "ä½¿ç”¨è¿™äº›å·¥å…·ä¹‹ä¸€ï¼Œå¯ä»¥åœ¨ä¸åˆ°ä¸€ä¸ªå°æ—¶çš„æ—¶é—´å†…è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²é¢„æµ‹æ€§æ•°æ®åˆ†ææ¨¡å‹ï¼"
        }
    },
    {
        "translation": {
            "en": "Instead, a reinforcement learning agent can be deployed into an environment and learn from experimenting within that environment.",
            "zh": "ç›¸åï¼Œå¯ä»¥å°†å¼ºåŒ–å­¦ä¹ ä»£ç†éƒ¨ç½²åˆ°ç¯å¢ƒä¸­ï¼Œå¹¶ä»è¯¥ç¯å¢ƒä¸­çš„å®éªŒä¸­å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the variance of the z values across for the neurons in the last hidden layer in the first iteration of training.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¸­æœ€åä¸€ä¸ªéšè—å±‚ä¸­ç¥ç»å…ƒçš„ z å€¼çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a different receptive field from the neuron in Figure 8.31[480]. This figure was inspired by Figure 2 of Kelleher and Dobnik (2017).",
            "zh": "å›¾ 4 çš„ç°åº¦å›¾åƒçš„ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠä¸å›¾ 8.31 [480] ä¸­ç¥ç»å…ƒå…·æœ‰ä¸åŒæ„Ÿå—é‡çš„ç¥ç»å…ƒã€‚è¯¥å›¾çš„çµæ„Ÿæ¥è‡ªKelleherå’ŒDobnikï¼ˆ2017ï¼‰çš„å›¾2ã€‚"
        }
    },
    {
        "translation": {
            "en": "True Negative (TN): an instance in the test set that had a negative target feature value and that was predicted to have a negative target feature value",
            "zh": "çœŸè´Ÿ ï¼ˆTNï¼‰ï¼šæµ‹è¯•é›†ä¸­å…·æœ‰è´Ÿç›®æ ‡ç‰¹å¾å€¼ä¸”é¢„æµ‹å…·æœ‰è´Ÿç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹"
        }
    },
    {
        "translation": {
            "en": "In order to use control groups in evaluation, we need to be able to divide a population into two groups, run two versions of a business process in parallel, and accurately measure the performance of the business process.",
            "zh": "ä¸ºäº†åœ¨è¯„ä¼°ä¸­ä½¿ç”¨å¯¹ç…§ç»„ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿå°†æ€»ä½“åˆ†ä¸ºä¸¤ç»„ï¼Œå¹¶è¡Œè¿è¡Œä¸¤ä¸ªç‰ˆæœ¬çš„ä¸šåŠ¡æµç¨‹ï¼Œå¹¶å‡†ç¡®è¡¡é‡ä¸šåŠ¡æµç¨‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems, 5998â€“6008.",
            "zh": "ç“¦æ–¯ç“¦å°¼ã€é˜¿å¸Œä»€ã€è¯ºå§†Â·æ²™æ³½å°”ã€å°¼åŸºÂ·å¸•å°”é©¬ã€é›…å„å¸ƒÂ·ä¹Œæ–¯ç§‘é›·ç‰¹ã€åˆ©æ˜‚Â·ç¼æ–¯ã€è‰¾ä¸¹Â·æˆˆéº¦æ–¯ã€å¢å¡æ–¯Â·å‡¯æ’’å’Œä¼Šåˆ©äºšÂ·æ³¢æ´›è‹æ¬£ã€‚2017. æ³¨æ„åŠ›å°±æ˜¯ä½ æ‰€éœ€è¦çš„ã€‚åœ¨ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•ä¸­ï¼Œ5998-6008ã€‚"
        }
    },
    {
        "translation": {
            "en": "termination condition, 229",
            "zh": "ç«¯æ¥æ¡ä»¶ï¼Œ229"
        }
    },
    {
        "translation": {
            "en": "Instead, this decision is made on a case-by-case basis and is dependent on the precision required in answering a question.",
            "zh": "ç›¸åï¼Œæ­¤å†³å®šæ˜¯æ ¹æ®å…·ä½“æƒ…å†µåšå‡ºçš„ï¼Œå¹¶ä¸”å–å†³äºå›ç­”é—®é¢˜æ‰€éœ€çš„ç²¾ç¡®åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The table below shows the frequencies of predictions of the three different levels made by the model for the original validation dataset at the time the model was built, for the month after deployment, and for a monthlong period six months after deployment.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†æ¨¡å‹åœ¨æ„å»ºæ¨¡å‹æ—¶ã€éƒ¨ç½²åä¸€ä¸ªæœˆå’Œéƒ¨ç½²åå…­ä¸ªæœˆå†…å¯¹åŸå§‹éªŒè¯æ•°æ®é›†è¿›è¡Œçš„ä¸‰ä¸ªä¸åŒçº§åˆ«çš„é¢„æµ‹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_R_I",
            "zh": "PETROMAGDIFF_R_I"
        }
    },
    {
        "translation": {
            "en": "The remaining entropy for the CONTAINS IMAGES feature is",
            "zh": "CONTAINS IMAGES ç‰¹å¾çš„å‰©ä½™ç†µä¸º"
        }
    },
    {
        "translation": {
            "en": "action, 643, 676",
            "zh": "è¡ŒåŠ¨ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Once a set of candidate analytics solutions that address a business problem have been defined, the next task is to evaluate the feasibility of each solution. This involves considering the following questions:",
            "zh": "ä¸€æ—¦å®šä¹‰äº†ä¸€ç»„è§£å†³ä¸šåŠ¡é—®é¢˜çš„å€™é€‰åˆ†æè§£å†³æ–¹æ¡ˆï¼Œä¸‹ä¸€ä¸ªä»»åŠ¡å°±æ˜¯è¯„ä¼°æ¯ä¸ªè§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚è¿™æ¶‰åŠè€ƒè™‘ä»¥ä¸‹é—®é¢˜ï¼š"
        }
    },
    {
        "translation": {
            "en": "Dick: What?",
            "zh": "è¿ªå…‹ï¼šä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The relevant smoothed probabilities, from Table 6.16[284], needed by the naive Bayes model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, AB = 759.07, and LA = 8,000, and the calculation of the scores for each candidate prediction.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹éœ€è¦ä»è¡¨ 6.16[284] ä¸­å¯¹ CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹ã€AB = 759.07 å’Œ LA = 8,000 çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå€™é€‰é¢„æµ‹çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "By applying a set of basis functions (Section 7.4.5[351]) to descriptive features, models that represent non-linear relationships can be created.",
            "zh": "é€šè¿‡å°†ä¸€ç»„åŸºå‡½æ•°ï¼ˆç¬¬ 7.4.5 èŠ‚ [351]ï¼‰åº”ç”¨äºæè¿°æ€§ç‰¹å¾ï¼Œå¯ä»¥åˆ›å»ºè¡¨ç¤ºéçº¿æ€§å…³ç³»çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The transpose of a matrix flips the matrix on its main diagonal (the main diagonal of a matrix contain all the elements whose indices are equal, e.g., c1,1,c2,2, and so on). To create the transpose of a matrix, take the first row of the matrix and write it as the first column; then write the second row of the matrix and write it as the second column; and so on. For example:",
            "zh": "çŸ©é˜µçš„è½¬ç½®åœ¨å…¶ä¸»å¯¹è§’çº¿ä¸Šç¿»è½¬çŸ©é˜µï¼ˆçŸ©é˜µçš„ä¸»å¯¹è§’çº¿åŒ…å«ç´¢å¼•ç›¸ç­‰çš„æ‰€æœ‰å…ƒç´ ï¼Œä¾‹å¦‚ c1,1ï¼Œc2,2 ç­‰ï¼‰ã€‚è¦åˆ›å»ºçŸ©é˜µçš„è½¬ç½®ï¼Œè¯·å–çŸ©é˜µçš„ç¬¬ä¸€è¡Œå¹¶å°†å…¶å†™ä¸ºç¬¬ä¸€åˆ—;ç„¶åå†™çŸ©é˜µçš„ç¬¬äºŒè¡Œï¼Œå†™æˆç¬¬äºŒåˆ—;ç­‰ç­‰ã€‚ä¾‹å¦‚ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 8.14[425] illustrates the forward pass for the examples in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "å›¾8.14[425]è¯´æ˜äº†è¡¨8.3[423]ä¸­ç¤ºä¾‹é€šè¿‡å›¾8.4[390]ä¸­çš„ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.5â€ƒOther Measures of Similarity",
            "zh": "5.4.5 å…¶ä»–ç›¸ä¼¼åº¦è¡¡é‡æ ‡å‡†"
        }
    },
    {
        "translation": {
            "en": "For example, in the spam filtering problem described previously, all we need to use are the relative profits of classifying a ham email as spam, classifying a spam email as ham, and so on.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å‰é¢æè¿°çš„åƒåœ¾é‚®ä»¶è¿‡æ»¤é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨çš„åªæ˜¯å°† ham ç”µå­é‚®ä»¶å½’ç±»ä¸ºåƒåœ¾é‚®ä»¶ã€å°†åƒåœ¾é‚®ä»¶å½’ç±»ä¸º ham ç­‰çš„ç›¸å¯¹åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Propose an inductive bias that would enable a machine learning algorithm to make the same preference choice that you made in Part (a).",
            "zh": "ï¼ˆbï¼‰ æå‡ºä¸€ç§å½’çº³åå·®ï¼Œä½¿æœºå™¨å­¦ä¹ ç®—æ³•èƒ½å¤Ÿåšå‡ºä¸æ‚¨åœ¨ ï¼ˆaï¼‰ éƒ¨åˆ†ä¸­æ‰€åšçš„ç›¸åŒçš„åå¥½é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.5.2â€ƒCosine similarityâ€ƒCosine similarity is an index that can be used as a measure of the similarity between instances with continuous descriptive features. The cosine similarity between two instances is the cosine of the inner angle between the two vectors that extend from the origin of a feature space to each instance. Figure 5.14(a)[218] illustrates the inner angle, Î¸, between the vector from the origin to two instances in a feature space defined by two descriptive features, SMS and VOICE.",
            "zh": "5.4.5.2 ä½™å¼¦ç›¸ä¼¼åº¦ ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯ä¸€ä¸ªç´¢å¼•ï¼Œå¯ä»¥ç”¨æ¥è¡¡é‡å…·æœ‰è¿ç»­æè¿°æ€§ç‰¹å¾çš„å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ä¸¤ä¸ªå®ä¾‹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯ä»ç‰¹å¾ç©ºé—´çš„åŸç‚¹å»¶ä¼¸åˆ°æ¯ä¸ªå®ä¾‹çš„ä¸¤ä¸ªå‘é‡ä¹‹é—´å†…è§’çš„ä½™å¼¦ã€‚å›¾ 5.14ï¼ˆaï¼‰[218] è¯´æ˜äº†ç”±ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ SMS å’Œ VOICE å®šä¹‰çš„ç‰¹å¾ç©ºé—´ä¸­ä»åŸç‚¹åˆ°ä¸¤ä¸ªå®ä¾‹çš„å‘é‡ä¹‹é—´çš„å†…è§’ Î¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically we will use letters from the end of the alphabet (e.g., X, Y, Z) for this purpose.",
            "zh": "é€šå¸¸ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å­—æ¯è¡¨æœ«å°¾çš„å­—æ¯ï¼ˆä¾‹å¦‚ï¼ŒXã€Yã€Zï¼‰æ¥å®ç°æ­¤ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the updated instance distribution, w[5], based on the predictions made by ğ•„4.",
            "zh": "ï¼ˆcï¼‰ æ ¹æ® M4 çš„é¢„æµ‹è®¡ç®—æ›´æ–°çš„å®ä¾‹åˆ†å¸ƒ w[5]ã€‚"
        }
    },
    {
        "translation": {
            "en": "The description of the support vector machine approach given in this section assumes that it is possible to separate the instances with the two different target feature levels with a linear hyperplane.",
            "zh": "æœ¬èŠ‚ä¸­ç»™å‡ºçš„æ”¯æŒå‘é‡æœºæ–¹æ³•çš„æè¿°å‡è®¾å¯ä»¥ä½¿ç”¨çº¿æ€§è¶…å¹³é¢å°†å…·æœ‰ä¸¤ä¸ªä¸åŒç›®æ ‡ç‰¹å¾çº§åˆ«çš„å®ä¾‹åˆ†å¼€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bertin, Jacques. 2010. Semiology of graphics: Diagrams, networks, maps. ESRI Press.",
            "zh": "è´å°”å»·ï¼Œé›…å…‹ã€‚2010. å›¾å½¢ç¬¦å·å­¦ï¼šå›¾è¡¨ã€ç½‘ç»œã€åœ°å›¾.ESRIå‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "TOTALINCOME",
            "zh": "æ€»æ”¶å…¥"
        }
    },
    {
        "translation": {
            "en": "The first step in defining the two PDFs is to decide which distribution we will use to define the PDFs for each target feature level.",
            "zh": "å®šä¹‰ä¸¤ä¸ª PDF çš„ç¬¬ä¸€æ­¥æ˜¯ç¡®å®šæˆ‘ä»¬å°†ä½¿ç”¨å“ªä¸ªåˆ†å‘æ¥å®šä¹‰æ¯ä¸ªç›®æ ‡åŠŸèƒ½çº§åˆ«çš„ PDFã€‚"
        }
    },
    {
        "translation": {
            "en": "3.2â€…â€…â€…Getting to Know the Data",
            "zh": "3.2 äº†è§£æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "The first real model trained for this ensemble, Î”1, is then trained to predict these errors on the basis of the descriptive features in the training set.",
            "zh": "ç„¶åï¼Œä¸ºè¯¥é›†æˆè®­ç»ƒçš„ç¬¬ä¸€ä¸ªçœŸå®æ¨¡å‹ Î”1 è¢«è®­ç»ƒä¸ºæ ¹æ®è®­ç»ƒé›†ä¸­çš„æè¿°æ€§ç‰¹å¾é¢„æµ‹è¿™äº›è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, as previously noted, these proofs assume that the neurons in the network include functions that are much more complex (or rougher) than the smooth activation functions used in most networks (such as the logistic functions).",
            "zh": "ç„¶è€Œï¼Œå¦‚å‰æ‰€è¿°ï¼Œè¿™äº›è¯æ˜å‡è®¾ç½‘ç»œä¸­çš„ç¥ç»å…ƒåŒ…å«æ¯”å¤§å¤šæ•°ç½‘ç»œä¸­ä½¿ç”¨çš„å¹³æ»‘æ¿€æ´»å‡½æ•°ï¼ˆä¾‹å¦‚é€»è¾‘å‡½æ•°ï¼‰å¤æ‚å¾—å¤šï¼ˆæˆ–æ›´ç²—ç³™ï¼‰çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "In scenarios that include a time dimension, this can be particularly effective and is often referred to as out-of-time sampling, because we use data from one period to build a training set and data out of another period to build a test set.",
            "zh": "åœ¨åŒ…å«æ—¶é—´ç»´åº¦çš„æ–¹æ¡ˆä¸­ï¼Œè¿™å¯èƒ½ç‰¹åˆ«æœ‰æ•ˆï¼Œé€šå¸¸ç§°ä¸ºæ—¶é—´å¤–æŠ½æ ·ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ—¶æœŸçš„æ•°æ®æ¥æ„å»ºè®­ç»ƒé›†ï¼Œå¹¶ä½¿ç”¨å¦ä¸€ä¸ªæ—¶æœŸçš„æ•°æ®æ¥æ„å»ºæµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "During DQN training the size of the replay memory was 50,000 and the target action-value function network, , was replaced every 10,000 steps.",
            "zh": "åœ¨ DQN è®­ç»ƒæœŸé—´ï¼Œé‡æ”¾è®°å¿†çš„å¤§å°ä¸º 50,000ï¼Œç›®æ ‡åŠ¨ä½œå€¼å‡½æ•°ç½‘ç»œ ï¼Œæ¯ 10,000 æ­¥æ›´æ¢ä¸€æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on these results, Jocelyn determined that the logistic regression model trained using the reduced set of features was the best model to use for galaxy classification.",
            "zh": "åŸºäºè¿™äº›ç»“æœï¼ŒJocelynç¡®å®šä½¿ç”¨ç®€åŒ–çš„ç‰¹å¾é›†è®­ç»ƒçš„é€»è¾‘å›å½’æ¨¡å‹æ˜¯ç”¨äºæ˜Ÿç³»åˆ†ç±»çš„æœ€ä½³æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "On top of a preference for caution in a final target policy, if training is being undertaken in the real world with potentially expensive equipment, SARSA might be favored over Q-Learning.",
            "zh": "é™¤äº†åœ¨æœ€ç»ˆç›®æ ‡æ”¿ç­–ä¸­è°¨æ…è¡Œäº‹ä¹‹å¤–ï¼Œå¦‚æœåœ¨ç°å®ä¸–ç•Œä¸­ä½¿ç”¨å¯èƒ½æ˜‚è´µçš„è®¾å¤‡è¿›è¡ŒåŸ¹è®­ï¼ŒSARSAå¯èƒ½æ¯”Q-Learningæ›´å—é’çã€‚"
        }
    },
    {
        "translation": {
            "en": "The representational capacity of a network is the set of functions (or mappings from inputs to outputs) that the network can implement as its weights are varied (Reed and Marks, 1999).",
            "zh": "ç½‘ç»œçš„è¡¨å¾èƒ½åŠ›æ˜¯ç½‘ç»œåœ¨å…¶æƒé‡å˜åŒ–æ—¶å¯ä»¥å®ç°çš„ä¸€ç»„å‡½æ•°ï¼ˆæˆ–ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„ï¼‰ï¼ˆReed and Marksï¼Œ1999ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we wish to train a deep network, we want the behavior of the network, in terms of the variance of the layerâ€™s z values, activations, and error gradients, to be similar across all the layers of the network.",
            "zh": "å¦‚æœæˆ‘ä»¬å¸Œæœ›è®­ç»ƒæ·±åº¦ç½‘ç»œï¼Œæˆ‘ä»¬å¸Œæœ›ç½‘ç»œçš„è¡Œä¸ºï¼ˆå°±å±‚çš„ z å€¼ã€æ¿€æ´»å’Œè¯¯å·®æ¢¯åº¦çš„æ–¹å·®è€Œè¨€ï¼‰åœ¨ç½‘ç»œçš„æ‰€æœ‰å±‚ä¸­éƒ½æ˜¯ç›¸ä¼¼çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.18",
            "zh": "å›¾ 9.18"
        }
    },
    {
        "translation": {
            "en": "DEVRADERR_U/G/R/I/Z",
            "zh": "DEVRADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "PSFMAGERR_U/G/R/I/Z",
            "zh": "PSFMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "10.11â€…â€…â€…(a)â€“(d) Different linkage methods that can be used to compare the distances between clusters in agglomerative hierarchical clustering. (Arrows for only some indicative distances are shown in the average linkage diagram (d).)",
            "zh": "10.11 ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ å¯ç”¨äºæ¯”è¾ƒé›†èšåˆ†å±‚èšç±»ä¸­èšç±»ä¹‹é—´è·ç¦»çš„ä¸åŒé“¾æ¥æ–¹æ³•ã€‚ï¼ˆå¹³å‡è¿æ†å›¾ ï¼ˆdï¼‰ ä¸­ä»…æ˜¾ç¤ºä¸€äº›æŒ‡ç¤ºè·ç¦»çš„ç®­å¤´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Pascal, Blaise, 243",
            "zh": "å¸•æ–¯å¡ï¼Œå¸ƒè±æ–¯ï¼Œ243"
        }
    },
    {
        "translation": {
            "en": "The main novelty in this scenario is that the neurons in the hidden layer of a simple recurrent neural network have two weight matrices associated with them: Whx and Whh.",
            "zh": "è¿™ä¸ªåœºæ™¯çš„ä¸»è¦æ–°é¢–ä¹‹å¤„åœ¨äºï¼Œç®€å•å¾ªç¯ç¥ç»ç½‘ç»œéšè—å±‚ä¸­çš„ç¥ç»å…ƒæœ‰ä¸¤ä¸ªä¸ä¹‹ç›¸å…³çš„æƒé‡çŸ©é˜µï¼šWhx å’Œ Whhã€‚"
        }
    },
    {
        "translation": {
            "en": "The is why in Figure 8.42[516] both of the paths emerging from the elementwise summation are labeled with the same term as the input arrow: âˆ‚â„°/âˆ‚ct.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨å›¾ 8.42[516] ä¸­ï¼Œä»å…ƒç´ æ±‚å’Œä¸­å‡ºç°çš„ä¸¤æ¡è·¯å¾„éƒ½ç”¨ä¸è¾“å…¥ç®­å¤´ç›¸åŒçš„é¡¹è¿›è¡Œæ ‡è®°ï¼šâˆ‚E/âˆ‚ctã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence, an aggregate across multiple runs should still be used.",
            "zh": "å› æ­¤ï¼Œä»åº”ä½¿ç”¨è·¨å¤šä¸ªè¿è¡Œçš„èšåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Subset Generation: This component generates a set of candidate feature subsets that are successors of the current best feature subset.",
            "zh": "1. å­é›†ç”Ÿæˆï¼šæ­¤ç»„ä»¶ç”Ÿæˆä¸€ç»„å€™é€‰ç‰¹å¾å­é›†ï¼Œè¿™äº›å­é›†æ˜¯å½“å‰æœ€ä½³ç‰¹å¾å­é›†çš„ç»§æ‰¿è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.6.2â€ƒBinning",
            "zh": "3.6.2 åƒç´ åˆå¹¶"
        }
    },
    {
        "translation": {
            "en": "Doubt has begun to surround the phenomenon of N rays, however, as a number of international physicists have not been able to reproduce the results of the experiments that demonstrate their existence.",
            "zh": "ç„¶è€Œï¼Œäººä»¬å¯¹Nå°„çº¿ç°è±¡çš„æ€€ç–‘å·²ç»å¼€å§‹ï¼Œå› ä¸ºè®¸å¤šå›½é™…ç‰©ç†å­¦å®¶æ— æ³•é‡ç°è¯æ˜å®ƒä»¬å­˜åœ¨çš„å®éªŒç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The following image provides a template diagram for the sequence of matrix operations that our neural network would use to process the input vector Neuron 1 = 0.7 and Neuron 2 = 0.3. Assuming that the processing neurons in the network use a ReLU activation function, fill in the diagram with the appropriate weights, bias terms, weighted sum values, and activations.",
            "zh": "ï¼ˆcï¼‰ ä¸‹å›¾æä¾›äº†çŸ©é˜µæ“ä½œåºåˆ—çš„æ¨¡æ¿å›¾ï¼Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå°†ç”¨äºå¤„ç†è¾“å…¥å‘é‡ç¥ç»å…ƒ 1 = 0.7 å’Œç¥ç»å…ƒ 2 = 0.3ã€‚å‡è®¾ç½‘ç»œä¸­çš„å¤„ç†ç¥ç»å…ƒä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°ï¼Œè¯·åœ¨å›¾ä¸­å¡«å†™é€‚å½“çš„æƒé‡ã€åå·®é¡¹ã€åŠ æƒæ€»å’Œå€¼å’Œæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) What would be the output from this neuron if the activation function Ï† is a threshold activation with Î¸ = 1?",
            "zh": "ï¼ˆbï¼‰ å¦‚æœæ¿€æ´»å‡½æ•°Ï†æ˜¯ Î¸ = 1 çš„é˜ˆå€¼æ¿€æ´»ï¼Œé‚£ä¹ˆè¯¥ç¥ç»å…ƒçš„è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Topics covered include interpreting a linear regression model, using weight decay to set the learning rate, handling categorical descriptive and target features, using feature selection, using multivariable linear regression models to model non-linear relationships, and using support vector machines (SVMs) as an alternative to linear regression models.",
            "zh": "æ¶µç›–çš„ä¸»é¢˜åŒ…æ‹¬è§£é‡Šçº¿æ€§å›å½’æ¨¡å‹ã€ä½¿ç”¨æƒé‡è¡°å‡è®¾ç½®å­¦ä¹ ç‡ã€å¤„ç†åˆ†ç±»æè¿°æ€§å’Œç›®æ ‡ç‰¹å¾ã€ä½¿ç”¨ç‰¹å¾é€‰æ‹©ã€ä½¿ç”¨å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹å¯¹éçº¿æ€§å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œä»¥åŠä½¿ç”¨æ”¯æŒå‘é‡æœº ï¼ˆSVMï¼‰ ä½œä¸ºçº¿æ€§å›å½’æ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C., and George C. Runger. 2010. Applied statistics and probability for engineers. Wiley.",
            "zh": "è’™å“¥é©¬åˆ©ã€é“æ ¼æ‹‰æ–¯ C. å’Œä¹”æ²» C. æœ—æ ¼ã€‚2010. å·¥ç¨‹å¸ˆåº”ç”¨ç»Ÿè®¡ä¸æ¦‚ç‡.å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "TOP-10 INCOME, the percentage of the annual income of the country that goes to the top 10% of earners",
            "zh": "TOP-10 INCOMEï¼Œè¯¥å›½å¹´æ”¶å…¥ä¸­æ”¶å…¥æœ€é«˜çš„ 10% çš„ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "This is due to the trade-offs between false positives and false negatives.",
            "zh": "è¿™æ˜¯ç”±äºè¯¯æŠ¥å’Œæ¼æŠ¥ä¹‹é—´çš„æƒè¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.16[284] shows the Laplace smoothed (with k = 3) probabilities required by a naive Bayes prediction model calculated from the dataset in Table 6.11[278].",
            "zh": "è¡¨6.16[284]æ˜¾ç¤ºäº†ä»è¡¨6.11[278]ä¸­çš„æ•°æ®é›†è®¡ç®—å‡ºçš„æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm uses a top-down, recursive, depth-first partitioning of the dataset to build a tree model beginning at the root node and finishing at the leaf nodes.",
            "zh": "ID3 ç®—æ³•ä½¿ç”¨è‡ªä¸Šè€Œä¸‹çš„é€’å½’ã€æ·±åº¦ä¼˜å…ˆçš„æ•°æ®é›†åˆ†åŒºæ¥æ„å»ºä»æ ¹èŠ‚ç‚¹å¼€å§‹åˆ°å¶èŠ‚ç‚¹ç»“æŸçš„æ ‘æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "When no relationship exists, the box plots should all appear similar.",
            "zh": "å½“ä¸å­˜åœ¨ä»»ä½•å…³ç³»æ—¶ï¼Œç®±å½¢å›¾åº”å…¨éƒ¨æ˜¾ç¤ºä¸ºç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.1.1â€ƒCase Study: Motor Insurance Fraud",
            "zh": "3.1.1 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated all these error gradients for a sequence, we then update each weight by summing all the error gradients for that weight and then using the summed error gradient to update the weight.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†ä¸€ä¸ªåºåˆ—çš„æ‰€æœ‰è¿™äº›è¯¯å·®æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±ä¼šé€šè¿‡å°†è¯¥æƒé‡çš„æ‰€æœ‰è¯¯å·®æ¢¯åº¦ç›¸åŠ ï¼Œç„¶åä½¿ç”¨æ€»å’Œçš„è¯¯å·®æ¢¯åº¦æ¥æ›´æ–°æƒé‡æ¥æ›´æ–°æ¯ä¸ªæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "When you first see the game played, because the dealer lays out the three cards so quickly, you think that there is no way to tell where the queen lands.",
            "zh": "å½“ä½ ç¬¬ä¸€æ¬¡çœ‹åˆ°æ¸¸æˆæ—¶ï¼Œå› ä¸ºåº„å®¶æŠŠä¸‰å¼ ç‰Œæ‘†å¾—å¤ªå¿«äº†ï¼Œä½ ä»¥ä¸ºæ²¡æœ‰åŠæ³•åˆ†è¾¨çš‡åè½åœ¨å“ªé‡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Others, however, arise because of perfectly valid data that may cause difficulty to some machine learning techniques.",
            "zh": "ç„¶è€Œï¼Œå…¶ä»–é—®é¢˜åˆ™æ˜¯å› ä¸ºå®Œå…¨æœ‰æ•ˆçš„æ•°æ®å¯èƒ½ä¼šç»™æŸäº›æœºå™¨å­¦ä¹ æŠ€æœ¯å¸¦æ¥å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a medical diagnosis problem, we might confidently say that a false negative (telling a sick patient that they do not have a disease) is worse than a false positive (telling a healthy patient that they do have a disease), but it is unlikely that we will be able to quantify this as twice as bad, or four times as bad, or 10.75 times as bad.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦è¯Šæ–­é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè‡ªä¿¡åœ°è¯´å‡é˜´æ€§ï¼ˆå‘Šè¯‰ç—…äººä»–ä»¬æ²¡æœ‰ç–¾ç—…ï¼‰æ¯”å‡é˜³æ€§ï¼ˆå‘Šè¯‰å¥åº·æ‚£è€…ä»–ä»¬ç¡®å®æœ‰ç–¾ç—…ï¼‰æ›´ç³Ÿç³•ï¼Œä½†æˆ‘ä»¬ä¸å¤ªå¯èƒ½å°†å…¶é‡åŒ–ä¸ºä¸¤å€çš„ç³Ÿç³•ç¨‹åº¦ã€‚ æˆ–å››å€çš„åï¼Œæˆ–ååˆ†ä¸ƒåäº”çš„åã€‚"
        }
    },
    {
        "translation": {
            "en": "15. The website kdnuggets.com runs a regular poll on the most popular programming languages for predictive data analytics, which R and Python regularly top, www.kdnuggets.com/polls/2013/languages-analytics-data-mining-data-science.html. For further details about R and Python, see www.r-project.org and www.python.org.",
            "zh": "15. è¯¥ç½‘ç«™ kdnuggets.com å¯¹æœ€æµè¡Œçš„é¢„æµ‹æ•°æ®åˆ†æç¼–ç¨‹è¯­è¨€è¿›è¡Œå®šæœŸæ°‘æ„è°ƒæŸ¥ï¼Œå…¶ä¸­ R å’Œ Python ç»å¸¸ååˆ—å‰èŒ…ï¼Œwww.kdnuggets.com/polls/2013/languages-analytics-data-mining-data-science.htmlã€‚æœ‰å…³ R å’Œ Python çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… www.r-project.org å’Œ www.python.orgã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantage of using evaluation approaches based on comparing the distribution of a modelâ€™s output, such as the stability index, is that they do not require that the true targets for query instances become available shortly after predictions have been made.",
            "zh": "ä½¿ç”¨åŸºäºæ¯”è¾ƒæ¨¡å‹è¾“å‡ºï¼ˆå¦‚ç¨³å®šæ€§æŒ‡æ•°ï¼‰åˆ†å¸ƒçš„è¯„ä¼°æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒä»¬ä¸è¦æ±‚æŸ¥è¯¢å®ä¾‹çš„çœŸæ­£ç›®æ ‡åœ¨åšå‡ºé¢„æµ‹åä¸ä¹…å°±å¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The updated cluster memberships based on these distances are shown in the rightmost column of Table 10.1[604].",
            "zh": "åŸºäºè¿™äº›è·ç¦»çš„æ›´æ–°çš„é›†ç¾¤æˆå‘˜èº«ä»½æ˜¾ç¤ºåœ¨è¡¨ 10.1[604] çš„æœ€å³è¾¹åˆ—ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "We will always use 2 as the base, s, when we calculate entropy, which means that we measure entropy in bits.5 Equation (4.1)[125] is the cornerstone of modern information theory and is an excellent measure of the impurityâ€”heterogeneityâ€”of a set.",
            "zh": "å½“æˆ‘ä»¬è®¡ç®—ç†µæ—¶ï¼Œæˆ‘ä»¬æ€»æ˜¯ä½¿ç”¨ 2 ä½œä¸ºåŸºæ•° sï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬ä»¥æ¯”ç‰¹ä¸ºå•ä½æµ‹é‡ç†µ.5 æ–¹ç¨‹ ï¼ˆ4.1ï¼‰[125] æ˜¯ç°ä»£ä¿¡æ¯è®ºçš„åŸºçŸ³ï¼Œä¹Ÿæ˜¯è¡¡é‡é›†åˆçš„ä¸çº¯æ€§ï¼ˆå¼‚è´¨æ€§ï¼‰çš„æå¥½æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table A.4",
            "zh": "è¡¨ A.4"
        }
    },
    {
        "translation": {
            "en": "When framed as a greedy local search problem, feature selection is defined in terms of an iterative process consisting of the following components:",
            "zh": "å½“è¢«æ¡†å®šä¸ºè´ªå©ªçš„å±€éƒ¨æœç´¢é—®é¢˜æ—¶ï¼Œç‰¹å¾é€‰æ‹©æ˜¯æ ¹æ®ç”±ä»¥ä¸‹ç»„ä»¶ç»„æˆçš„è¿­ä»£è¿‡ç¨‹æ¥å®šä¹‰çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "Over the course of this chapter, we look at the ways in which all these descriptive features can be used to train an error-based model to predict office rental prices.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç ”ç©¶æ‰€æœ‰è¿™äº›æè¿°æ€§ç‰¹å¾å¯ç”¨äºè®­ç»ƒåŸºäºé”™è¯¯çš„æ¨¡å‹æ¥é¢„æµ‹åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the definition of churn as a customer who had not made any calls or paid a bill for one month, Ross was able to identify churn events throughout this time period.",
            "zh": "ä½¿ç”¨æµå¤±çš„å®šä¹‰ï¼Œå³ä¸€ä¸ªæœˆæ²¡æœ‰æ‹¨æ‰“ä»»ä½•ç”µè¯æˆ–æ”¯ä»˜è´¦å•çš„å®¢æˆ·ï¼ŒRoss èƒ½å¤Ÿè¯†åˆ«æ•´ä¸ªæ—¶é—´æ®µçš„æµå¤±äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "critical value pruning, 155",
            "zh": "ä¸´ç•Œå€¼ä¿®å‰ªï¼Œ155"
        }
    },
    {
        "translation": {
            "en": "Table 8.8",
            "zh": "è¡¨ 8.8"
        }
    },
    {
        "translation": {
            "en": "This algorithm is very similar to the Q-learning algorithm in Algorithm 13[658].",
            "zh": "è¯¥ç®—æ³•ä¸ç®—æ³•13[658]ä¸­çš„Qå­¦ä¹ ç®—æ³•éå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The logistic function14 is given by",
            "zh": "é€»è¾‘å‡½æ•°14ç”±ä¸‹å¼ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "PETROR90_U/G/R/I/Z",
            "zh": "PETROR90_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The algorithm stores the instance indexed by the leaf node in the best variable and sets the best-distance variable to the distance between the instance indexed by the leaf node and the query instance (Lines 5, 6, and 7).",
            "zh": "è¯¥ç®—æ³•å°†å¶èŠ‚ç‚¹ç´¢å¼•çš„å®ä¾‹å­˜å‚¨åœ¨æœ€ä½³å˜é‡ä¸­ï¼Œå¹¶å°†æœ€ä½³è·ç¦»å˜é‡è®¾ç½®ä¸ºå¶èŠ‚ç‚¹ç´¢å¼•çš„å®ä¾‹ä¸æŸ¥è¯¢å®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼ˆç¬¬ 5ã€6 å’Œ 7 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "THICKNESS",
            "zh": "åšåº¦"
        }
    },
    {
        "translation": {
            "en": "LIFETIME",
            "zh": "è¾ˆå­"
        }
    },
    {
        "translation": {
            "en": "The SDSS spectrographs perform this task for manually identified night sky objects and produce spectrograms across wavelengths from visible blue light to near-infrared light.",
            "zh": "SDSSå…‰è°±ä»ªå¯¹æ‰‹åŠ¨è¯†åˆ«çš„å¤œç©ºç‰©ä½“æ‰§è¡Œæ­¤ä»»åŠ¡ï¼Œå¹¶ç”Ÿæˆä»å¯è§è“å…‰åˆ°è¿‘çº¢å¤–å…‰çš„æ³¢é•¿çš„å…‰è°±å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "When datasets are small, a parametric model may perform well because the strong assumptions made by the modelâ€”if correctâ€”can help the model to avoid overfitting.",
            "zh": "å½“æ•°æ®é›†è¾ƒå°æ—¶ï¼Œå‚æ•°åŒ–æ¨¡å‹å¯èƒ½è¡¨ç°è‰¯å¥½ï¼Œå› ä¸ºæ¨¡å‹åšå‡ºçš„å¼ºå‡è®¾ï¼ˆå¦‚æœæ­£ç¡®ï¼‰å¯ä»¥å¸®åŠ©æ¨¡å‹é¿å…è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "It is tempting to infer the relative importance of the different descriptive features in the model from the magnitude of the weightsâ€”that is, the descriptive features associated with higher weights are more predictive than those with lower weights.",
            "zh": "ä»æƒé‡çš„å¤§å°æ¨æ–­æ¨¡å‹ä¸­ä¸åŒæè¿°æ€§ç‰¹å¾çš„ç›¸å¯¹é‡è¦æ€§æ˜¯å¾ˆè¯±äººçš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸è¾ƒé«˜æƒé‡ç›¸å…³çš„æè¿°æ€§ç‰¹å¾æ¯”æƒé‡è¾ƒä½çš„æè¿°æ€§ç‰¹å¾æ›´å…·é¢„æµ‹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the distributions we wish to use, to define a PDF for a descriptive feature that is conditioned on a particular target, we fit the parameters of the selected distribution to the subset of the data where the target has that value.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨çš„åˆ†å¸ƒï¼Œä¸ºä»¥ç‰¹å®šç›®æ ‡ä¸ºæ¡ä»¶çš„æè¿°æ€§ç‰¹å¾å®šä¹‰ PDFï¼Œæˆ‘ä»¬å°±ä¼šå°†æ‰€é€‰åˆ†å¸ƒçš„å‚æ•°æ‹Ÿåˆåˆ°ç›®æ ‡å…·æœ‰è¯¥å€¼çš„æ•°æ®å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the problems faced by ecological management practitioners is that it is often too expensive to do large-scale, high-resolution land surveys.",
            "zh": "ç”Ÿæ€ç®¡ç†ä»ä¸šè€…é¢ä¸´çš„é—®é¢˜ä¹‹ä¸€æ˜¯ï¼Œè¿›è¡Œå¤§è§„æ¨¡ã€é«˜åˆ†è¾¨ç‡çš„åœŸåœ°è°ƒæŸ¥å¾€å¾€æˆæœ¬å¤ªé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in some instances we may wish to set bias terms to non-zero values; for example, ReLUs saturate when z < 0, and so to avoid dead ReLUs, the heuristic of initializing the bias terms for ReLU units to a small positive number (such as 0.1) is sometimes used (Goodfellow et al., 2016, pp.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›å°†åå·®é¡¹è®¾ç½®ä¸ºéé›¶å€¼;ä¾‹å¦‚ï¼Œå½“ z < 0 æ—¶ï¼ŒReLU ä¼šé¥±å’Œï¼Œå› æ­¤ä¸ºäº†é¿å…æ­» ReLUï¼Œæœ‰æ—¶ä¼šä½¿ç”¨å°† ReLU å•å…ƒçš„åå·®é¡¹åˆå§‹åŒ–ä¸ºä¸€ä¸ªå°æ­£æ•°ï¼ˆä¾‹å¦‚ 0.1ï¼‰çš„å¯å‘å¼æ–¹æ³•ï¼ˆGoodfellow ç­‰äººï¼Œ2016 å¹´ï¼Œç¬¬ 1 é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "By this time a clear optimal route through the graph has emerged running straight down from the top to the bottom, and we can say that the agent has learned to perform the navigation task.",
            "zh": "æ­¤æ—¶ï¼Œå›¾ä¸­å‡ºç°äº†ä¸€æ¡æ¸…æ™°çš„æœ€ä½³è·¯çº¿ï¼Œä»ä¸Šåˆ°ä¸‹ä¸€ç›´å‘ä¸‹å»¶ä¼¸ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ä»£ç†å·²ç»å­¦ä¼šäº†æ‰§è¡Œå¯¼èˆªä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The prediction model could be easily integrated with ATâ€™s current business processes. AT already had a retention team in place that was making proactive interventions to help prevent churn, albeit using a very simple system to identify which customers to contact. By creating a more sophisticated model to identify those customers, this existing process would be improved.",
            "zh": "é¢„æµ‹æ¨¡å‹å¯ä»¥å¾ˆå®¹æ˜“åœ°ä¸ATå½“å‰çš„ä¸šåŠ¡æµç¨‹é›†æˆã€‚ATå·²ç»æœ‰ä¸€ä¸ªä¿ç•™å›¢é˜Ÿï¼Œè¯¥å›¢é˜Ÿæ­£åœ¨é‡‡å–ç§¯æçš„å¹²é¢„æªæ–½æ¥å¸®åŠ©é˜²æ­¢å®¢æˆ·æµå¤±ï¼Œå°½ç®¡ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„ç³»ç»Ÿæ¥è¯†åˆ«è¦è”ç³»çš„å®¢æˆ·ã€‚é€šè¿‡åˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„æ¨¡å‹æ¥è¯†åˆ«è¿™äº›å®¢æˆ·ï¼Œè¿™ä¸ªç°æœ‰çš„æµç¨‹å°†å¾—åˆ°æ”¹è¿›ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this stage we simply record any data quality issues due to valid data in a data quality plan so that we remain aware of them and can handle them later if required.",
            "zh": "åœ¨æ­¤é˜¶æ®µï¼Œæˆ‘ä»¬åªéœ€åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­è®°å½•ç”±äºæœ‰æ•ˆæ•°æ®è€Œå¯¼è‡´çš„ä»»ä½•æ•°æ®è´¨é‡é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘ä»¬éšæ—¶äº†è§£è¿™äº›é—®é¢˜ï¼Œå¹¶åœ¨éœ€è¦æ—¶ç¨åå¤„ç†å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "conditional probability tables: each node has a conditional probability table (CPT) associated with it. A CPT lists the probability distribution of the feature represented by the node conditioned on the features represented by the other nodes to which a node is connected by edges.",
            "zh": "æ¡ä»¶æ¦‚ç‡è¡¨ï¼šæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ä¸€ä¸ªä¸ä¹‹å…³è”çš„æ¡ä»¶æ¦‚ç‡è¡¨ï¼ˆCPTï¼‰ã€‚CPT åˆ—å‡ºèŠ‚ç‚¹æ‰€è¡¨ç¤ºçš„ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¯¥ç‰¹å¾ä»¥èŠ‚ç‚¹é€šè¿‡è¾¹è¿æ¥åˆ°çš„å…¶ä»–èŠ‚ç‚¹æ‰€è¡¨ç¤ºçš„ç‰¹å¾ä¸ºæ¡ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.1â€…â€…â€…Big Idea",
            "zh": "7.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "Data Preparation: Building predictive data analytics models requires specific kinds of data, organized in a specific kind of structure known as an analytics base table (ABT).13 This phase of CRISP-DM includes all the activities required to convert the disparate data sources that are available in an organization to a well-formed ABT from which machine learning models can be induced.",
            "zh": "æ•°æ®å‡†å¤‡ï¼šæ„å»ºé¢„æµ‹æ€§æ•°æ®åˆ†ææ¨¡å‹éœ€è¦ç‰¹å®šç±»å‹çš„æ•°æ®ï¼Œè¿™äº›æ•°æ®ä»¥ç§°ä¸ºåˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ çš„ç‰¹å®šç»“æ„è¿›è¡Œç»„ç»‡.13 CRISP-DM çš„è¿™ä¸€é˜¶æ®µåŒ…æ‹¬å°†ç»„ç»‡ä¸­å¯ç”¨çš„ä¸åŒæ•°æ®æºè½¬æ¢ä¸ºæ ¼å¼è‰¯å¥½çš„ ABT æ‰€éœ€çš„æ‰€æœ‰æ´»åŠ¨ï¼Œä»ä¸­å¯ä»¥è¡ç”Ÿå‡ºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "in all tables).",
            "zh": "åœ¨æ‰€æœ‰è¡¨ä¸­ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The bold lines show the path taken to descend the tree from the root to a leaf node based on the values of the query instance (use Figure 5.9(a)[199] to trace this path in detail).",
            "zh": "ç²—ä½“çº¿æ˜¾ç¤ºäº†æ ¹æ®æŸ¥è¯¢å®ä¾‹çš„å€¼å°†æ ‘ä»æ ¹é™åˆ°å¶èŠ‚ç‚¹æ‰€é‡‡ç”¨çš„è·¯å¾„ï¼ˆä½¿ç”¨å›¾ 5.9ï¼ˆaï¼‰[199] è¯¦ç»†è·Ÿè¸ªæ­¤è·¯å¾„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "false positive, 254, 537, 556",
            "zh": "è¯¯æŠ¥ï¼Œ 254ï¼Œ 537ï¼Œ 556"
        }
    },
    {
        "translation": {
            "en": "Polynomial relationships allow multiplication of descriptive feature values by each other and raising of descriptive features to exponents.",
            "zh": "å¤šé¡¹å¼å…³ç³»å…è®¸æè¿°æ€§ç‰¹å¾å€¼ç›¸äº’ç›¸ä¹˜ï¼Œå¹¶å°†æè¿°æ€§ç‰¹å¾æå‡ä¸ºæŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, if the representations become too sparse, then the performance of the network may deteriorate.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœè¡¨ç¤ºå½¢å¼å˜å¾—è¿‡äºç¨€ç–ï¼Œåˆ™ç½‘ç»œçš„æ€§èƒ½å¯èƒ½ä¼šä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "We explain subsequently why this is the case, but first we note that for ease of exposition in this discussion, we will ignore the bias terms in the weights of a neuron.",
            "zh": "æˆ‘ä»¬éšåè§£é‡Šäº†ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Œä½†é¦–å…ˆæˆ‘ä»¬æ³¨æ„åˆ°ï¼Œä¸ºäº†ä¾¿äºåœ¨æœ¬æ¬¡è®¨è®ºä¸­é˜è¿°ï¼Œæˆ‘ä»¬å°†å¿½ç•¥ç¥ç»å…ƒæƒé‡ä¸­çš„åå·®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "During this backward pass, an error gradient for each neuron is calculated.",
            "zh": "åœ¨æ­¤å‘åä¼ é€’è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Boltzmann action selection is another commonly used alternative that uses the action-value function values, Q(st,at), for each possible action to build a softmax probability distribution, .",
            "zh": "ç»å°”å…¹æ›¼åŠ¨ä½œé€‰æ‹©æ˜¯å¦ä¸€ç§å¸¸ç”¨çš„æ›¿ä»£æ–¹æ³•ï¼Œå®ƒä½¿ç”¨åŠ¨ä½œ-å€¼å‡½æ•°å€¼ Qï¼ˆstï¼Œatï¼‰ æ¥æ„å»ºè½¯æœ€å¤§æ¦‚ç‡åˆ†å¸ƒ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The policy can be thought of as a simple lookup table that records the action that should be taken in every state, and reinforcement learning problems can be framed as an effort to learn this table directly.4 Policies can also be encoded as a rule used to choose an action from those available in a particular state, and this is the approach we focus on in this chapter.",
            "zh": "è¯¥ç­–ç•¥å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªç®€å•çš„æŸ¥æ‰¾è¡¨ï¼Œå®ƒè®°å½•äº†åœ¨æ¯ä¸ªçŠ¶æ€ä¸‹åº”è¯¥é‡‡å–çš„è¡ŒåŠ¨ï¼Œè€Œå¼ºåŒ–å­¦ä¹ é—®é¢˜å¯ä»¥è¢«æ¡†å®šä¸ºç›´æ¥å­¦ä¹ è¿™ä¸ªè¡¨çš„åŠªåŠ›ã€‚4 ç­–ç•¥ä¹Ÿå¯ä»¥ç¼–ç ä¸ºä¸€ä¸ªè§„åˆ™ï¼Œç”¨äºä»ç‰¹å®šçŠ¶æ€ä¸­å¯ç”¨çš„æ“ä½œä¸­é€‰æ‹©ä¸€ä¸ªæ“ä½œï¼Œ è¿™å°±æ˜¯æˆ‘ä»¬åœ¨æœ¬ç« ä¸­é‡ç‚¹è®¨è®ºçš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1â€ƒDesigning Evaluation Experiments",
            "zh": "9.4.1 è®¾è®¡è¯„ä¼°å®éªŒ"
        }
    },
    {
        "translation": {
            "en": "deep Q learning, 677",
            "zh": "æ·±åº¦ Q å­¦ä¹ ï¼Œ677"
        }
    },
    {
        "translation": {
            "en": "What is the relationship between a measure of heterogeneity of a set and predictive analytics? If we can construct a sequence of tests that splits the training data into pure sets with respect to the target feature values, then we can label queries by applying the same sequence of tests to a query and labeling it with the target feature value of instances in the set in which it ends up.",
            "zh": "é›†åˆçš„å¼‚è´¨æ€§åº¦é‡ä¸é¢„æµ‹åˆ†æä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿå¦‚æœæˆ‘ä»¬å¯ä»¥æ„é€ ä¸€ä¸ªæµ‹è¯•åºåˆ—ï¼Œå°†è®­ç»ƒæ•°æ®æ‹†åˆ†ä¸ºç›¸å¯¹äºç›®æ ‡ç‰¹å¾å€¼çš„çº¯é›†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†ç›¸åŒçš„æµ‹è¯•åºåˆ—åº”ç”¨äºæŸ¥è¯¢å¹¶ä½¿ç”¨æœ€ç»ˆæ‰€åœ¨çš„é›†åˆä¸­å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼æ¥æ ‡è®°æŸ¥è¯¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Correlation7 is a normalized form of covariance that ranges between âˆ’ 1 and + 1.",
            "zh": "Correlation7 æ˜¯åæ–¹å·®çš„å½’ä¸€åŒ–å½¢å¼ï¼ŒèŒƒå›´ä»‹äº âˆ’ 1 å’Œ + 1 ä¹‹é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.3â€…â€…â€…Data Preparation",
            "zh": "12.3 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "The Q-learning algorithm (Algorithm 13[658])) starts by randomly initializing the action-value table (Line 13[658]). In this example all entries have been initialized to random numbers in [âˆ’1,1]. There are 196 entries in the full action-value tableâ€”one for each of the four actions that can be taken in each of the 49 states that make up the grid world. Table 11.3[661] shows a portion of the action-value table.",
            "zh": "Q å­¦ä¹ ç®—æ³•ï¼ˆç®—æ³• 13[658]ï¼‰ï¼‰é¦–å…ˆéšæœºåˆå§‹åŒ–åŠ¨ä½œå€¼è¡¨ï¼ˆç¬¬ 13 è¡Œ[658]ï¼‰ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ‰€æœ‰æ¡ç›®éƒ½å·²åˆå§‹åŒ–ä¸º [âˆ’1,1] ä¸­çš„éšæœºæ•°ã€‚å®Œæ•´çš„æ“ä½œå€¼è¡¨ä¸­æœ‰ 196 ä¸ªæ¡ç›®ï¼Œæ¯ä¸ªæ¡ç›®å¯¹åº”åœ¨æ„æˆç½‘æ ¼ä¸–ç•Œçš„ 49 ä¸ªçŠ¶æ€ä¸­æ¯ä¸ªçŠ¶æ€ä¸­å¯ä»¥æ‰§è¡Œçš„å››ä¸ªæ“ä½œã€‚è¡¨ 11.3[661] æ˜¾ç¤ºäº†æ“ä½œå€¼è¡¨çš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.3.1â€…â€…â€…A Worked Example",
            "zh": "5.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "There is, therefore, a delicate balance that we need to strike between preparing the data so that it is appropriate for use with machine learning algorithms and keeping the data true to the underlying processes that generate it.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å‡†å¤‡æ•°æ®ä»¥ä½¿å…¶é€‚åˆä¸æœºå™¨å­¦ä¹ ç®—æ³•ä¸€èµ·ä½¿ç”¨å’Œä¿æŒæ•°æ®å¿ å®äºç”Ÿæˆæ•°æ®çš„åº•å±‚è¿‡ç¨‹ä¹‹é—´å–å¾—å¾®å¦™çš„å¹³è¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Xavier initialization, 458, 458, 459, 461",
            "zh": "Xavier åˆå§‹åŒ–ã€458ã€458ã€459ã€461"
        }
    },
    {
        "translation": {
            "en": "This is a very common scenario and a real thorn in the side of the predictive model builderâ€”although there is often an almost endless amount of data available for training, little or none of it is labeled with the relevant target feature, making it effectively useless.",
            "zh": "è¿™æ˜¯ä¸€ä¸ªéå¸¸å¸¸è§çš„åœºæ™¯ï¼Œä¹Ÿæ˜¯é¢„æµ‹æ¨¡å‹æ„å»ºå™¨çš„çœŸæ­£éš¾é¢˜â€”â€”å°½ç®¡é€šå¸¸æœ‰å‡ ä¹æ— ç©·æ— å°½çš„æ•°æ®å¯ç”¨äºè®­ç»ƒï¼Œä½†å¾ˆå°‘æœ‰æˆ–æ ¹æœ¬æ²¡æœ‰ç”¨ç›¸å…³çš„ç›®æ ‡ç‰¹å¾æ ‡è®°ï¼Œè¿™ä½¿å¾—å®ƒå®é™…ä¸Šæ¯«æ— ç”¨å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "To make things manageable for this example, we aggressively discretize the representation of the value of the cards in the playerâ€™s and dealerâ€™s hands. For the playerâ€™s hand, just three levels (low, medium, and high) are modeled",
            "zh": "ä¸ºäº†ä½¿è¿™ä¸ªä¾‹å­çš„äº‹æƒ…æ˜“äºç®¡ç†ï¼Œæˆ‘ä»¬ç§¯æåœ°ç¦»æ•£äº†ç©å®¶å’Œåº„å®¶æ‰‹ä¸­çš„ç‰Œå€¼çš„è¡¨ç¤ºã€‚å¯¹äºç©å®¶çš„æ‰‹ç‰Œï¼Œåªæ¨¡æ‹Ÿäº†ä¸‰ä¸ªçº§åˆ«ï¼ˆä½ã€ä¸­å’Œé«˜ï¼‰"
        }
    },
    {
        "translation": {
            "en": "5.5â€…â€…â€…(a) The Voronoi tessellation of the feature space when the dataset has been updated to include the query instance; and (b) the updated decision boundary reflecting the addition of the query instance in the training set.",
            "zh": "5.5 ï¼ˆaï¼‰ å½“æ•°æ®é›†æ›´æ–°ä¸ºåŒ…å«æŸ¥è¯¢å®ä¾‹æ—¶ï¼Œç‰¹å¾ç©ºé—´çš„ Voronoi æ›²é¢ç»†åˆ†;ï¼ˆbï¼‰ æ›´æ–°çš„å†³ç­–è¾¹ç•Œï¼Œåæ˜ äº†åœ¨è®­ç»ƒé›†ä¸­æ·»åŠ æŸ¥è¯¢å®ä¾‹çš„æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "EFFECTIVETAXRATE: The effective tax rate paid by the taxpayer (this is simply tax paid divided by total income).",
            "zh": "æœ‰æ•ˆç¨ç‡ï¼šçº³ç¨äººæ”¯ä»˜çš„æœ‰æ•ˆç¨ç‡ï¼ˆè¿™åªæ˜¯æ”¯ä»˜çš„ç¨æ¬¾é™¤ä»¥æ€»æ”¶å…¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the derivative of speed with respect to time at time index 21 is the speed at time index 21 minus the speed at time index 20, which is 44.28 âˆ’ 51.42 = 7.14.",
            "zh": "ä¾‹å¦‚ï¼Œé€Ÿåº¦ç›¸å¯¹äºæ—¶é—´ç´¢å¼• 21 çš„å¯¼æ•°æ˜¯æ—¶é—´ç´¢å¼• 21 çš„é€Ÿåº¦å‡å»æ—¶é—´ç´¢å¼• 20 çš„é€Ÿåº¦ï¼Œå³ 44.28 âˆ’ 51.42 = 7.14ã€‚"
        }
    },
    {
        "translation": {
            "en": "List of Figures",
            "zh": "å›¾è¡¨ä¸€è§ˆè¡¨"
        }
    },
    {
        "translation": {
            "en": "When 2,000 samples were generated, the relative frequency rose to 0.1975.",
            "zh": "å½“ç”Ÿæˆ2,000ä¸ªæ ·æœ¬æ—¶ï¼Œç›¸å¯¹é¢‘ç‡ä¸Šå‡åˆ°0.1975ã€‚"
        }
    },
    {
        "translation": {
            "en": "Implementing a raw feature is simply a matter of copying the relevant raw value into the ABT.",
            "zh": "å®ç°åŸå§‹åŠŸèƒ½åªéœ€å°†ç›¸å…³çš„åŸå§‹å€¼å¤åˆ¶åˆ° ABT ä¸­å³å¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This stage of data exploration is mostly an information-gathering exercise, the output of which is just a better understanding of the contents of an ABT. It does, however, also present a good opportunity to discuss anything unusual that we notice about the central tendency and variation of features within the ABT. For example, a salary feature with a mean of 40 would seem unlikely (40,000 would seem more reasonable) and should be investigated.",
            "zh": "è¿™ä¸€é˜¶æ®µçš„æ•°æ®æ¢ç´¢ä¸»è¦æ˜¯ä¿¡æ¯æ”¶é›†æ´»åŠ¨ï¼Œå…¶è¾“å‡ºåªæ˜¯æ›´å¥½åœ°ç†è§£ ABT çš„å†…å®¹ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿæä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„æœºä¼šæ¥è®¨è®ºæˆ‘ä»¬æ³¨æ„åˆ°çš„å…³äºABTä¸­ç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–çš„ä»»ä½•ä¸å¯»å¸¸çš„äº‹æƒ…ã€‚ä¾‹å¦‚ï¼Œå¹³å‡å€¼ä¸º 40 çš„å·¥èµ„ç‰¹å¾ä¼¼ä¹ä¸å¤ªå¯èƒ½ï¼ˆ40,000 ä¼¼ä¹æ›´åˆç†ï¼‰ï¼Œåº”è¯¥è¿›è¡Œè°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "A credit scoring dataset.",
            "zh": "ä¿¡ç”¨è¯„åˆ†æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.8â€…â€…â€…The Road Ahead",
            "zh": "1.8 å‰æ–¹çš„é“è·¯"
        }
    },
    {
        "translation": {
            "en": "Predicting the number of bike rentals on a given day is useful because it can give the administrators of the bike sharing program an insight into the number of resources they need to have ready each day.",
            "zh": "é¢„æµ‹ç»™å®šæ—¥æœŸçš„è‡ªè¡Œè½¦ç§Ÿèµæ•°é‡å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥è®©è‡ªè¡Œè½¦å…±äº«è®¡åˆ’çš„ç®¡ç†å‘˜æ·±å…¥äº†è§£ä»–ä»¬æ¯å¤©éœ€è¦å‡†å¤‡çš„èµ„æºæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2491",
            "zh": "0.2491"
        }
    },
    {
        "translation": {
            "en": "If there is more time available, then â€œP.D.A.",
            "zh": "å¦‚æœæœ‰æ›´å¤šæ—¶é—´ï¼Œé‚£ä¹ˆâ€œP.D.A."
        }
    },
    {
        "translation": {
            "en": "Claude Shannonâ€™s entropy model defines a computational measure of the impurity of the elements in a set.",
            "zh": "å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰çš„ç†µæ¨¡å‹å®šä¹‰äº†é›†åˆä¸­å…ƒç´ æ‚è´¨çš„è®¡ç®—åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.8",
            "zh": "å›¾ 9.8"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7[329] shows how different learning ratesâ€”0.002, 0.08, and 0.18â€”result in very different journeys across the error surface.8 The changing sum of squared errors that result from these journeys are also shown.",
            "zh": "å›¾ 7.7[329] æ˜¾ç¤ºäº†ä¸åŒçš„å­¦ä¹ ç‡ï¼ˆ0.002ã€0.08 å’Œ 0.18ï¼‰å¦‚ä½•å¯¼è‡´åœ¨è¯¯å·®é¢ä¸Šæˆªç„¶ä¸åŒçš„æ—…ç¨‹8ï¼Œè¿˜æ˜¾ç¤ºäº†è¿™äº›æ—…ç¨‹å¯¼è‡´çš„å¹³æ–¹è¯¯å·®çš„å˜åŒ–å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "To allow learning to take place in temporal-difference learning, we need to revisit the idea of a policy, and use policies that allow a balance of exploration and exploitation.",
            "zh": "ä¸ºäº†è®©å­¦ä¹ åœ¨æ—¶é—´å·®å¼‚å­¦ä¹ ä¸­å‘ç”Ÿï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®¡è§†æ”¿ç­–çš„æƒ³æ³•ï¼Œå¹¶ä½¿ç”¨å…è®¸æ¢ç´¢å’Œåˆ©ç”¨å¹³è¡¡çš„æ”¿ç­–ã€‚"
        }
    },
    {
        "translation": {
            "en": "training instance, 6",
            "zh": "è®­ç»ƒå®ä¾‹ï¼Œ6"
        }
    },
    {
        "translation": {
            "en": "45. This omission of the sub-sampling layer is done simply to illustrate that it is optional.",
            "zh": "45. çœç•¥å­é‡‡æ ·å±‚åªæ˜¯ä¸ºäº†è¯´æ˜å®ƒæ˜¯å¯é€‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The problem, however, is that with a continuous feature, there is an infinite number of thresholds to choose from.",
            "zh": "ç„¶è€Œï¼Œé—®é¢˜åœ¨äºï¼Œå¯¹äºè¿ç»­ç‰¹å¾ï¼Œæœ‰æ— é™æ•°é‡çš„é˜ˆå€¼å¯ä¾›é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Potential Handling Strategies",
            "zh": "å¯èƒ½çš„å¤„ç†ç­–ç•¥"
        }
    },
    {
        "translation": {
            "en": "To train the model, the institution has created a dataset from the results of previous marketing campaigns that list customer informationâ€”specifically the annual salary (SALARY) and age (AGE) of the customerâ€”and whether the customer bought a product after they had been contacted via a direct marketing message (PURCH).",
            "zh": "ä¸ºäº†è®­ç»ƒè¯¥æ¨¡å‹ï¼Œè¯¥æœºæ„æ ¹æ®ä»¥å‰çš„è¥é”€æ´»åŠ¨çš„ç»“æœåˆ›å»ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åˆ—å‡ºäº†å®¢æˆ·ä¿¡æ¯ï¼ˆç‰¹åˆ«æ˜¯å®¢æˆ·çš„å¹´è–ª ï¼ˆSALARYï¼‰ å’Œå¹´é¾„ ï¼ˆAGEï¼‰ï¼Œä»¥åŠå®¢æˆ·æ˜¯å¦åœ¨é€šè¿‡ç›´æ¥è¥é”€æ¶ˆæ¯ ï¼ˆPURCHï¼‰ è”ç³»åè´­ä¹°äº†äº§å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "This value can be seen in the dark shading of the cell corresponding to state 6-5 in the right grid in Figure 11.5(a)[663]. There are also some very lightly shaded cells in Figure 11.5(a)[663]â€”for example, cell 1-2 in the down panelâ€”illustrating large negative values resulting from trips into the fiery cells and subsequent negative reward.",
            "zh": "è¯¥å€¼å¯ä»¥åœ¨å›¾11.5ï¼ˆaï¼‰[663]ä¸­å³ç½‘æ ¼ä¸­ä¸çŠ¶æ€6-5ç›¸å¯¹åº”çš„å•å…ƒæ ¼çš„æ·±è‰²é˜´å½±ä¸­çœ‹åˆ°ã€‚å›¾11.5ï¼ˆaï¼‰[663]ä¸­è¿˜æœ‰ä¸€äº›éå¸¸æµ…è‰²çš„å•å…ƒæ ¼ï¼Œä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­çš„å•å…ƒæ ¼1-2ï¼Œè¯´æ˜äº†ç”±äºç»Šå€’åˆ°ç‚½çƒ­çš„å•å…ƒæ ¼å’Œéšåçš„è´Ÿå¥–åŠ±è€Œäº§ç”Ÿçš„å¤§è´Ÿå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The median is not as sensitive to outliers as the arithmetic mean and therefore can be a more accurate estimate of the central tendency of a set of values if outliers exist.",
            "zh": "ä¸­ä½æ•°å¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿåº¦ä¸å¦‚ç®—æœ¯å¹³å‡å€¼ï¼Œå› æ­¤å¦‚æœå­˜åœ¨å¼‚å¸¸å€¼ï¼Œåˆ™å¯ä»¥æ›´å‡†ç¡®åœ°ä¼°è®¡ä¸€ç»„å€¼çš„ä¸­å¿ƒè¶‹åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "frequency counts, 749",
            "zh": "é¢‘ç‡è®¡æ•°ï¼Œ749"
        }
    },
    {
        "translation": {
            "en": "Gibbs sampling, 298",
            "zh": "å‰å¸ƒæ–¯é‡‡æ ·ï¼Œ298"
        }
    },
    {
        "translation": {
            "en": "The simplest performance measure we can use to assess how well this model has performed for this problem is the misclassification rate. The misclassification rate is the number of incorrect predictions made by the model divided by the total number of predictions made:",
            "zh": "æˆ‘ä»¬å¯ä»¥ç”¨æ¥è¯„ä¼°è¯¥æ¨¡å‹åœ¨è¿™ä¸ªé—®é¢˜ä¸Šçš„è¡¨ç°å¦‚ä½•çš„æœ€ç®€å•çš„æ€§èƒ½åº¦é‡æ˜¯é”™è¯¯åˆ†ç±»ç‡ã€‚é”™è¯¯åˆ†ç±»ç‡æ˜¯æ¨¡å‹åšå‡ºçš„é”™è¯¯é¢„æµ‹æ•°é™¤ä»¥åšå‡ºçš„é¢„æµ‹æ€»æ•°ï¼š"
        }
    },
    {
        "translation": {
            "en": "6.4â€…â€…â€…Histograms of two unimodal datasets: (a) the distribution has light tails; and (b) the distribution has fat tails.",
            "zh": "6.4 ä¸¤ä¸ªå•å³°æ•°æ®é›†çš„ç›´æ–¹å›¾ï¼šï¼ˆaï¼‰åˆ†å¸ƒæœ‰å…‰å°¾;ï¼ˆbï¼‰åˆ†å¸ƒæœ‰è‚¥å°¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.7â€…â€…â€…(a) The decision boundary using majority vote of the nearest 15 neighbors; and (b) the weighted k nearest neighbor model decision boundary (with k = 21).",
            "zh": "5.7 ï¼ˆaï¼‰ ä½¿ç”¨æœ€è¿‘çš„15ä¸ªç›¸é‚»ç‚¹çš„å¤šæ•°ç¥¨ä½œå‡ºçš„å†³å®šè¾¹ç•Œ;ï¼ˆbï¼‰åŠ æƒkæœ€è¿‘é‚»æ¨¡å‹å†³ç­–è¾¹ç•Œï¼ˆk = 21ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see from this histogram that AGE follows a uniform distribution across a range from about 19 to about 35.",
            "zh": "ä»è¿™ä¸ªç›´æ–¹å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒAGE åœ¨å¤§çº¦ 19 åˆ°å¤§çº¦ 35 çš„èŒƒå›´å†…éµå¾ªå‡åŒ€åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "D.2â€ƒTranspose",
            "zh": "D.2 è½¬ç½®"
        }
    },
    {
        "translation": {
            "en": "Code was then written to replace the previous simple rule about customer care contacts with the decision tree when retention call lists were generated.",
            "zh": "ç„¶åç¼–å†™ä»£ç ï¼Œåœ¨ç”Ÿæˆä¿ç•™å‘¼å«åˆ—è¡¨æ—¶ï¼Œå°†ä¹‹å‰å…³äºå®¢æˆ·æœåŠ¡è”ç³»äººçš„ç®€å•è§„åˆ™æ›¿æ¢ä¸ºå†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "column in the data quality report shows the number of distinct values present for a feature within an ABT.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„åˆ—æ˜¾ç¤º ABT ä¸­è¦ç´ å­˜åœ¨çš„éé‡å¤å€¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Zhang, Nevin Lianwen, and David Poole. 1994. A simple approach to bayesian network computations. In Proceedings of the tenth biennial Canadian artificial intelligence conference, 171â€“178.",
            "zh": "Zhangã€Nevin Lianwen å’Œ David Pooleã€‚1994. è´å¶æ–¯ç½‘ç»œè®¡ç®—çš„ç®€å•æ–¹æ³•.ç¬¬åå±Šä¸¤å¹´ä¸€åº¦çš„åŠ æ‹¿å¤§äººå·¥æ™ºèƒ½ä¼šè®®è®ºæ–‡é›†ï¼Œ171-178ã€‚"
        }
    },
    {
        "translation": {
            "en": "Data analytics practitioners can often be frustrated by legislation that stops them from including features that appear to be particularly well suited to an analytics solution in an ABT. Organizations must operate within the relevant legislation that is in place in the jurisdictions in which they operate, and it is important that models are not in breach of this. There are significant differences in legislation in different jurisdictions, but a couple of key relevant principles almost always apply.",
            "zh": "æ•°æ®åˆ†æä»ä¸šè€…é€šå¸¸ä¼šå› ç«‹æ³•è€Œæ„Ÿåˆ°æ²®ä¸§ï¼Œè¿™äº›ç«‹æ³•é˜»æ­¢ä»–ä»¬åœ¨ ABT ä¸­åŒ…å«ä¼¼ä¹ç‰¹åˆ«é€‚åˆåˆ†æè§£å†³æ–¹æ¡ˆçš„åŠŸèƒ½ã€‚ ç»„ç»‡å¿…é¡»åœ¨å…¶è¿è¥æ‰€åœ¨å¸æ³•ç®¡è¾–åŒºçš„ç›¸å…³ç«‹æ³•èŒƒå›´å†…è¿è¥ï¼Œé‡è¦çš„æ˜¯æ¨¡å‹ä¸è¿åè¿™ä¸€ç‚¹ã€‚ä¸åŒå¸æ³•ç®¡è¾–åŒºçš„ç«‹æ³•å­˜åœ¨é‡å¤§å·®å¼‚ï¼Œä½†ä¸€äº›å…³é”®çš„ç›¸å…³åŸåˆ™å‡ ä¹æ€»æ˜¯é€‚ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "All state transition probabilities based on the Twist action can be calculated in a similar way.",
            "zh": "æ‰€æœ‰åŸºäº Twist åŠ¨ä½œçš„çŠ¶æ€è½¬æ¢æ¦‚ç‡éƒ½å¯ä»¥ç”¨ç±»ä¼¼çš„æ–¹å¼è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because an event defines a partition of a dataset (the rows from the dataset that match the event), then each Yi defines a set of rows from a dataset, and the set of data partitions defined by Y1 to Yk must cover the full dataset and not overlap with each other.",
            "zh": "å› ä¸ºä¸€ä¸ªäº‹ä»¶å®šä¹‰äº†ä¸€ä¸ªæ•°æ®é›†çš„åˆ†åŒºï¼ˆæ•°æ®é›†ä¸­ä¸äº‹ä»¶åŒ¹é…çš„è¡Œï¼‰ï¼Œæ‰€ä»¥æ¯ä¸ª Yi å®šä¹‰äº†æ•°æ®é›†ä¸­çš„ä¸€ç»„è¡Œï¼Œè€Œ Y1 åˆ° Yk å®šä¹‰çš„æ•°æ®åˆ†åŒºé›†å¿…é¡»è¦†ç›–æ•´ä¸ªæ•°æ®é›†ï¼Œå¹¶ä¸”ä¸èƒ½ç›¸äº’é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, for example, the ROC index for the ROC curve shown in Figure 9.12(a)[562] is 0.798, and the ROC indices for Models 1 to 4 in Figure 9.12(b)[562] are 0.996, 0.887, 0.764, and 0.595 (as shown in the legend).",
            "zh": "ä¾‹å¦‚ï¼Œå›¾9.12ï¼ˆaï¼‰[562]æ‰€ç¤ºçš„ROCæ›²çº¿çš„ROCæŒ‡æ•°ä¸º0.798ï¼Œå›¾9.12ï¼ˆbï¼‰[562]ä¸­æ¨¡å‹1è‡³4çš„ROCæŒ‡æ•°ä¸º0.996ã€0.887ã€0.764å’Œ0.595ï¼ˆå¦‚å›¾æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is the capacity of the business to utilize the insights that the analytics solution will provide?",
            "zh": "ä¼ä¸šåˆ©ç”¨åˆ†æè§£å†³æ–¹æ¡ˆå°†æä¾›çš„è§è§£çš„èƒ½åŠ›å¦‚ä½•ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "A.1â€ƒDescriptive Statistics for Continuous Features",
            "zh": "A.1 è¿ç»­ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡"
        }
    },
    {
        "translation": {
            "en": "In the bar plots in Figure 3.1[58], the different levels in the domain of each categorical feature, and how these levels are distributed, are obvious.",
            "zh": "åœ¨å›¾3.1[58]çš„æ¡å½¢å›¾ä¸­ï¼Œæ¯ä¸ªåˆ†ç±»ç‰¹å¾åŸŸä¸­çš„ä¸åŒæ°´å¹³ä»¥åŠè¿™äº›æ°´å¹³çš„åˆ†å¸ƒæ–¹å¼æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This tells us not only something about how accurate the churn prediction model is but, more important, that using the model actually made a difference in the business problem that the company was trying to address.25",
            "zh": "è¿™ä¸ä»…å‘Šè¯‰æˆ‘ä»¬å®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œä½¿ç”¨è¯¥æ¨¡å‹å®é™…ä¸Šå¯¹å…¬å¸è¯•å›¾è§£å†³çš„ä¸šåŠ¡é—®é¢˜äº§ç”Ÿäº†å½±å“25ã€‚"
        }
    },
    {
        "translation": {
            "en": "Plots of the journeys made across the error surface for the simple office rentals prediction problem for different learning rates: (a) a very small learning rate (0.002); (b) a medium learning rate (0.08); and (c) a very large learning rate (0.18). The changing sum of squared errors are also shown.",
            "zh": "é’ˆå¯¹ä¸åŒå­¦ä¹ ç‡çš„ç®€å•åŠå…¬å®¤ç§Ÿèµé¢„æµ‹é—®é¢˜ï¼Œåœ¨è¯¯å·®é¢ä¸Šè¿›è¡Œçš„æ—…ç¨‹å›¾ï¼šï¼ˆaï¼‰éå¸¸å°çš„å­¦ä¹ ç‡ï¼ˆ0.002ï¼‰;ï¼ˆbï¼‰ä¸­ç­‰å­¦ä¹ ç‡ï¼ˆ0.08ï¼‰;ï¼ˆcï¼‰éå¸¸é«˜çš„å­¦ä¹ ç‡ï¼ˆ0.18ï¼‰ã€‚è¿˜æ˜¾ç¤ºäº†å¹³æ–¹è¯¯å·®çš„å˜åŒ–å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Models whose output changes drastically in response to small changes in the input are likely overfitting the data, because a small amount of noise in the input data can have a large effect on the outputs generated by the model.",
            "zh": "å¦‚æœæ¨¡å‹çš„è¾“å‡ºä¼šå› è¾“å…¥ä¸­çš„å¾®å°å˜åŒ–è€Œå‘ç”Ÿå·¨å¤§å˜åŒ–ï¼Œåˆ™å¯èƒ½æ˜¯æ•°æ®è¿‡åº¦æ‹Ÿåˆï¼Œå› ä¸ºè¾“å…¥æ•°æ®ä¸­çš„å°‘é‡å™ªå£°ä¼šå¯¹æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºäº§ç”Ÿå¾ˆå¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "multimodal distribution, 60, 274",
            "zh": "å¤šå¼è”è¿é…é€ï¼Œ 60ï¼Œ 274"
        }
    },
    {
        "translation": {
            "en": "The existence of a high level of correlation between measurements indicated to Jocelyn that feature selection would be important later during the modeling phase as it had the potential to massively reduce the dimensionality of the dataset.",
            "zh": "æµ‹é‡å€¼ä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸å…³æ€§ï¼Œè¿™å‘ Jocelyn è¡¨æ˜ï¼Œç‰¹å¾é€‰æ‹©åœ¨å»ºæ¨¡é˜¶æ®µçš„åæœŸéå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒæœ‰å¯èƒ½å¤§å¤§é™ä½æ•°æ®é›†çš„ç»´æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The features included under this subconcept, all of which are derived features, are shown in Figure 2.10[44].",
            "zh": "è¯¥å­æ¦‚å¿µä¸‹åŒ…å«çš„ç‰¹å¾ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯æ´¾ç”Ÿç‰¹å¾ï¼Œå¦‚å›¾2.10æ‰€ç¤º[44]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the ground truth labels, calculate the squared error loss for each query instance (assume that benign = 0 and malignant = 1).",
            "zh": "ä½¿ç”¨çœŸå€¼æ ‡ç­¾ï¼Œè®¡ç®—æ¯ä¸ªæŸ¥è¯¢å®ä¾‹çš„å¹³æ–¹è¯¯å·®æŸå¤±ï¼ˆå‡è®¾è‰¯æ€§ = 0ï¼Œæ¶æ€§ = 1ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.4â€…â€…â€…A Worked Example",
            "zh": "7.3.4 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "t represents the target feature.",
            "zh": "t è¡¨ç¤ºç›®æ ‡è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "From calculus, the derivative of the natural log is",
            "zh": "ä»å¾®ç§¯åˆ†æ¥çœ‹ï¼Œè‡ªç„¶å¯¹æ•°çš„å¯¼æ•°æ˜¯"
        }
    },
    {
        "translation": {
            "en": "3. Have corrected any data quality issues due to invalid data.",
            "zh": "3. æ›´æ­£äº†å› æ•°æ®æ— æ•ˆè€Œå¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the SDSS dataset are primarily continuous. For this reason, Jocelyn considered trying a similarity-based model, the k nearest neighbor, and two error-based models, the logistic regression model and the support vector machine. Jocelyn began by constructing a simple baseline model using the 3-level target feature.",
            "zh": "SDSS æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾ä¸»è¦æ˜¯è¿ç»­çš„ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼ŒJocelyn è€ƒè™‘å°è¯•ä¸€ä¸ªåŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹ï¼Œå³ k ä¸ªæœ€è¿‘é‚»ï¼Œä»¥åŠä¸¤ä¸ªåŸºäºé”™è¯¯çš„æ¨¡å‹ï¼Œå³é€»è¾‘å›å½’æ¨¡å‹å’Œæ”¯æŒå‘é‡æœºã€‚Jocelyn é¦–å…ˆä½¿ç”¨ 3 çº§ç›®æ ‡ç‰¹å¾æ„å»ºäº†ä¸€ä¸ªç®€å•çš„åŸºçº¿æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fit the parameters of the selected distribution to the feature values in the dataset.",
            "zh": "å°†æ‰€é€‰åˆ†å¸ƒçš„å‚æ•°æ‹Ÿåˆåˆ°æ•°æ®é›†ä¸­çš„è¦ç´ å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 14.1",
            "zh": "å›¾ 14.1"
        }
    },
    {
        "translation": {
            "en": "Pearson, Karl, 82",
            "zh": "çš®å°”é€Šï¼Œå¡å°”ï¼Œ82 å²"
        }
    },
    {
        "translation": {
            "en": "Consequently, the weights used during the backpropagation of the Î´s plotted in Figure 8.24(d)[454] are sampled from a normal distribution with Î¼ = 0.0 and Ïƒ = 0.2, which means that for all the layers var(W(k)) = Ïƒ2 = 0.22 = 0.04.",
            "zh": "å› æ­¤ï¼Œå›¾8.24ï¼ˆdï¼‰[454]ä¸­ç»˜åˆ¶çš„Î´såå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æƒé‡æ˜¯ä»Î¼ = 0.0å’ŒÏƒ = 0.2çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œè¿™æ„å‘³ç€å¯¹äºæ‰€æœ‰å±‚ï¼Œvarï¼ˆWï¼ˆkï¼‰ï¼‰ = Ïƒ2 = 0.22 = 0.04ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use P to write the true probability distribution over the categories of the target; to write the distribution over the target categories that the model has predicted; and to indicate the predicted probability for the true category.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ P æ¥å†™å‡ºç›®æ ‡ç±»åˆ«ä¸Šçš„çœŸå®æ¦‚ç‡åˆ†å¸ƒ;å†™å…¥æ¨¡å‹é¢„æµ‹çš„ç›®æ ‡ç±»åˆ«çš„åˆ†å¸ƒ;å¹¶æŒ‡ç¤ºçœŸå®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. and then applying a decision rule over the class posteriors to return a target level.",
            "zh": "2. ç„¶åå¯¹ç±»åéªŒåº”ç”¨å†³ç­–è§„åˆ™ä»¥è¿”å›ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.1(b)[55] shows the structure of the table in a data quality report that describes categorical features.",
            "zh": "è¡¨3.1ï¼ˆbï¼‰[55]æ˜¾ç¤ºäº†æè¿°åˆ†ç±»ç‰¹å¾çš„æ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„è¡¨æ ¼ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "inter-annotator agreement, 726",
            "zh": "æ³¨é‡Šè€…é—´åè®®ï¼Œ726"
        }
    },
    {
        "translation": {
            "en": "11.1â€…â€…â€…Some episodes of games played by the TwentyTwos agent showing the cards dealt, as well as the states, actions, and rewards. Note that rewards are shown on the row indicating the action that led to them, not the state that followed that action.",
            "zh": "11.1 TwentyTwosç‰¹å·¥ç©çš„ä¸€äº›æ¸¸æˆç‰‡æ®µæ˜¾ç¤ºäº†å‘ç‰Œï¼Œä»¥åŠçŠ¶æ€ã€è¡ŒåŠ¨å’Œå¥–åŠ±ã€‚è¯·æ³¨æ„ï¼Œå¥–åŠ±æ˜¾ç¤ºåœ¨æŒ‡ç¤ºå¯¼è‡´å¥–åŠ±çš„æ“ä½œçš„è¡Œä¸Šï¼Œè€Œä¸æ˜¯è¯¥æ“ä½œä¹‹åçš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3â€…â€…â€…The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places.",
            "zh": "8.3 è”åˆå¾ªç¯ç”µå‚ç¯å¢ƒå› ç´ å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„èŒƒå›´å½’ä¸€åŒ–å°æ—¶æ ·æœ¬ï¼Œå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "customer relationship management, 572",
            "zh": "å®¢æˆ·å…³ç³»ç®¡ç†ï¼Œ572"
        }
    },
    {
        "translation": {
            "en": "9.9â€…â€…â€…(a) The confusion matrix for a k-NN model trained on the payday loan credit scoring problem (average class accuracyHM = 83.824%); and (b) the confusion matrix for a decision tree model trained on the payday loan credit scoring problem (average class accuracyHM = 80.761%).",
            "zh": "9.9 ï¼ˆaï¼‰ åœ¨å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜ä¸Šè®­ç»ƒçš„ k-NN æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡HM = 83.824%ï¼‰;ï¼ˆbï¼‰åœ¨å‘è–ªæ—¥è´·æ¬¾ä¿¡ç”¨è¯„åˆ†é—®é¢˜ä¸Šè®­ç»ƒçš„å†³ç­–æ ‘æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡HM = 80.761%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.2â€ƒFundamentals",
            "zh": "9.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "Figure 9.9[557] illustrates this: assuming that prediction scores are normally distributed, the distributions of the scores for the two target levels are shown for two different classification models.",
            "zh": "å›¾ 9.9[557] è¯´æ˜äº†è¿™ä¸€ç‚¹ï¼šå‡è®¾é¢„æµ‹åˆ†æ•°å‘ˆæ­£æ€åˆ†å¸ƒï¼Œåˆ™æ˜¾ç¤ºäº†ä¸¤ç§ä¸åŒåˆ†ç±»æ¨¡å‹çš„ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "AVGMINS",
            "zh": "AVGMINSçš„"
        }
    },
    {
        "translation": {
            "en": "email classification, 536",
            "zh": "ç”µå­é‚®ä»¶åˆ†ç±»ï¼Œ536"
        }
    },
    {
        "translation": {
            "en": "Analysis of a subset of the features in the SDSS dataset.",
            "zh": "åˆ†æ SDSS æ•°æ®é›†ä¸­è¦ç´ çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The blindfold makes this quite challenging!",
            "zh": "çœ¼ç½©ä½¿è¿™éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼"
        }
    },
    {
        "translation": {
            "en": "For some Markov chains, mixing may require only a few iterations, but for others, it may require hundreds or thousands of iterations.",
            "zh": "å¯¹äºæŸäº›é©¬å°”å¯å¤«é“¾ï¼Œæ··åˆå¯èƒ½åªéœ€è¦å‡ æ¬¡è¿­ä»£ï¼Œä½†å¯¹äºå…¶ä»–é©¬å°”å¯å¤«é“¾ï¼Œå¯èƒ½éœ€è¦æ•°ç™¾æˆ–æ•°åƒæ¬¡è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "30. The architecture followed the architecture described by Mnih et al. (2013).",
            "zh": "30. è¯¥æ¶æ„éµå¾ª Mnih ç­‰äºº ï¼ˆ2013ï¼‰ æè¿°çš„æ¶æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.9â€…â€…â€…A small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the professional basketball team dataset in Table 3.7[73], showing the result of range normalization and standardization.",
            "zh": "3.9 è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†çš„HEIGHTå’ŒSPONSORSHIP EARNSç‰¹å¾çš„å°æ ·æœ¬ï¼Œæ˜¾ç¤ºäº†èŒƒå›´æ ‡å‡†åŒ–å’Œæ ‡å‡†åŒ–çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.6.1â€ƒMonitoring changes in performance measuresâ€ƒThe simplest way to get a signal that concept drift has occurred is to repeatedly evaluate models with the same performance measures used to evaluate them before deployment.",
            "zh": "9.4.6.1 ç›‘è§†æ€§èƒ½åº¦é‡çš„å˜åŒ– è¦è·å¾—æ¦‚å¿µåç§»å·²å‘ç”Ÿçš„ä¿¡å·ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯åœ¨éƒ¨ç½²å‰ä½¿ç”¨ä¸è¯„ä¼°æ¨¡å‹ç›¸åŒçš„æ€§èƒ½åº¦é‡æ¥åå¤è¯„ä¼°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout this section we use the terms similarity and distance almost interchangeably, because we often judge the similarity between two instances in terms of the distance between them in a feature space.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å‡ ä¹å¯ä»¥äº’æ¢ä½¿ç”¨æœ¯è¯­â€œç›¸ä¼¼æ€§â€å’Œâ€œè·ç¦»â€ï¼Œå› ä¸ºæˆ‘ä»¬ç»å¸¸æ ¹æ®ç‰¹å¾ç©ºé—´ä¸­ä¸¤ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»æ¥åˆ¤æ–­å®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is not possible to know the actual return that will be earned by the agent across the entire episode until the episode is complete, and so it would not be possible to apply this update rule after early actions in the episode.",
            "zh": "åœ¨å‰§é›†å®Œæˆä¹‹å‰ï¼Œä¸å¯èƒ½çŸ¥é“ä»£ç†åœ¨æ•´ä¸ªå‰§é›†ä¸­å°†è·å¾—çš„å®é™…å›æŠ¥ï¼Œå› æ­¤åœ¨å‰§é›†ä¸­çš„æ—©æœŸæ“ä½œä¹‹åï¼Œæ— æ³•åº”ç”¨æ­¤æ›´æ–°è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "network freezing, 671",
            "zh": "ç½‘ç»œå†»ç»“ï¼Œ671"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41[514] shows the dimensions of the different weight matrices in the unit where H = 2 and n = 1.",
            "zh": "å›¾ 8.41[514] æ˜¾ç¤ºäº† H = 2 ä¸” n = 1 çš„å•ä½ä¸­ä¸åŒæƒé‡çŸ©é˜µçš„ç»´åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The last issue to consider in relation to data when selecting machine learning approaches is the curse of dimensionality.",
            "zh": "åœ¨é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•æ—¶ï¼Œè¦è€ƒè™‘çš„æœ€åä¸€ä¸ªä¸æ•°æ®ç›¸å…³çš„é—®é¢˜æ˜¯ç»´åº¦çš„è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.6â€…â€…â€…Sequential Models: Recurrent Neural Networks and Long Short-Term Memory Networks",
            "zh": "8.4.6 é¡ºåºæ¨¡å‹ï¼šé€’å½’ç¥ç»ç½‘ç»œå’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "4. Some might argue that the information on the application form summarizes an applicantâ€™s entire life, so this constitutes the observation period in this case!",
            "zh": "4. æœ‰äººå¯èƒ½ä¼šäº‰è¾©è¯´ï¼Œç”³è¯·è¡¨ä¸Šçš„ä¿¡æ¯æ¦‚æ‹¬äº†ç”³è¯·äººçš„æ•´ä¸ªç”Ÿæ´»ï¼Œæ‰€ä»¥è¿™æ„æˆäº†æœ¬æ¡ˆçš„è§‚å¯ŸæœŸï¼"
        }
    },
    {
        "translation": {
            "en": "lower quartile, 749, 755",
            "zh": "ä¸‹å››åˆ†ä½æ•°ï¼Œ 749ï¼Œ 755"
        }
    },
    {
        "translation": {
            "en": "target level imbalance, 719",
            "zh": "ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡ï¼Œ719"
        }
    },
    {
        "translation": {
            "en": "Figure 2.10",
            "zh": "å›¾ 2.10"
        }
    },
    {
        "translation": {
            "en": "pruning, 117, 170",
            "zh": "ä¿®å‰ªï¼Œ 117ï¼Œ 170"
        }
    },
    {
        "translation": {
            "en": "early stopping criteria, 152, 155",
            "zh": "æå‰åœæ­¢æ ‡å‡†ï¼Œ152,155"
        }
    },
    {
        "translation": {
            "en": "To conclude, the weaknesses of similarity-based learning approaches are that they are sensitive to the curse of dimensionality, they are slower than other models at making predictions (particularly with very large datasets), and they may not be able to achieve the same levels of accuracy as other learning approaches.",
            "zh": "æ€»è€Œè¨€ä¹‹ï¼ŒåŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ æ–¹æ³•çš„å¼±ç‚¹æ˜¯å®ƒä»¬å¯¹ç»´åº¦çš„è¯…å’’å¾ˆæ•æ„Ÿï¼Œå®ƒä»¬åœ¨è¿›è¡Œé¢„æµ‹æ–¹é¢æ¯”å…¶ä»–æ¨¡å‹æ…¢ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºéå¸¸å¤§çš„æ•°æ®é›†ï¼‰ï¼Œå¹¶ä¸”å®ƒä»¬å¯èƒ½æ— æ³•è¾¾åˆ°ä¸å…¶ä»–å­¦ä¹ æ–¹æ³•ç›¸åŒçš„å‡†ç¡®æ€§æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given a joint probability distribution, we can compute the probability of any event in the domain that it covers by summing over the cells in the distribution where that event is true.",
            "zh": "ç»™å®šä¸€ä¸ªè”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹åˆ†å¸ƒä¸­è¯¥äº‹ä»¶ä¸ºçœŸçš„å•å…ƒæ ¼æ±‚å’Œæ¥è®¡ç®—å®ƒæ‰€è¦†ç›–çš„åŸŸä¸­ä»»ä½•äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, for these matrices it is important to highlight the end of the connections the weights are applied to; we use a double subscript (similar to the subscript for a single weight), writing Whx for the weight matrix on the connections between the input (x) and the hidden layer (h).",
            "zh": "å› æ­¤ï¼Œå¯¹äºè¿™äº›çŸ©é˜µï¼Œé‡è¦çš„æ˜¯è¦çªå‡ºæ˜¾ç¤ºæ–½åŠ æƒé‡çš„è¿æ¥çš„æœ«ç«¯;æˆ‘ä»¬ä½¿ç”¨åŒä¸‹æ ‡ï¼ˆç±»ä¼¼äºå•ä¸ªæƒé‡çš„ä¸‹æ ‡ï¼‰ï¼Œåœ¨è¾“å…¥ ï¼ˆxï¼‰ å’Œéšè—å±‚ ï¼ˆhï¼‰ ä¹‹é—´çš„è¿æ¥ä¸Šä¸ºæƒé‡çŸ©é˜µå†™å…¥ Whxã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have shown how k-d trees (Bentley, 1975; Friedman et al., 1977) can be used to speed up the retrieval of nearest neighbors.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº† k-d æ ‘ï¼ˆBentleyï¼Œ1975 å¹´;Friedmanç­‰äººï¼Œ1977ï¼‰å¯ç”¨äºåŠ é€Ÿæœ€è¿‘é‚»çš„æ£€ç´¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "gain chart, 567, 570",
            "zh": "å¢ç›Šå›¾ï¼Œ 567ï¼Œ 570"
        }
    },
    {
        "translation": {
            "en": "The left side of Figure 8.5[392] presents a graph-based representation of a neural network; this network has a single hidden layer containing three neurons and an output layer with a single neuron in it.",
            "zh": "å›¾ 8.5[392] çš„å·¦ä¾§æ˜¾ç¤ºäº†ç¥ç»ç½‘ç»œçš„åŸºäºå›¾çš„è¡¨ç¤º;è¯¥ç½‘ç»œæœ‰ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç¥ç»å…ƒçš„éšè—å±‚å’Œä¸€ä¸ªåŒ…å«å•ä¸ªç¥ç»å…ƒçš„è¾“å‡ºå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Sloan Digital Sky Survey (SDSS) is a landmark project that is cataloging the night sky in intricate detail and is facing exactly the problem described above.1 The SDSS telescopes collect over 175GB of data every night, and for the data collected to be fully exploited for science, each night sky object captured must be identified and cataloged within this data in almost real time.",
            "zh": "æ–¯éš†æ•°å­—å·¡å¤© ï¼ˆSDSSï¼‰ æ˜¯ä¸€ä¸ªå…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„é¡¹ç›®ï¼Œå®ƒä»¥å¤æ‚çš„ç»†èŠ‚å¯¹å¤œç©ºè¿›è¡Œç¼–ç›®ï¼Œå¹¶ä¸”æ­£é¢ä¸´ç€ä¸Šè¿°é—®é¢˜.1 SDSS æœ›è¿œé•œæ¯æ™šæ”¶é›†è¶…è¿‡ 175GB çš„æ•°æ®ï¼Œä¸ºäº†å……åˆ†åˆ©ç”¨æ”¶é›†åˆ°çš„æ•°æ®ç”¨äºç§‘å­¦ï¼Œæ•è·çš„æ¯ä¸ªå¤œç©ºç‰©ä½“éƒ½å¿…é¡»åœ¨è¿™äº›æ•°æ®ä¸­å‡ ä¹å®æ—¶åœ°è¯†åˆ«å’Œç¼–ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.4â€ƒLegal Issues",
            "zh": "2.4.4 æ³•å¾‹é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "Ng, Andrew Y., Michael I. Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Advances in neural information processing systems, 849â€“856.",
            "zh": "å´æ©è¾¾ã€å®‰å¾·é² Y.ã€è¿ˆå…‹å°” I. ä¹”ä¸¹å’Œäºšå°”Â·éŸ¦æ–¯ã€‚2002. å…³äºå…‰è°±èšç±»ï¼šåˆ†æå’Œç®—æ³•.åœ¨ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•ä¸­ï¼Œ849-856ã€‚"
        }
    },
    {
        "translation": {
            "en": "The animal species typically found in this vegetation include gray foxes, bobcats, skunks, and rabbits.",
            "zh": "é€šå¸¸åœ¨è¿™ç§æ¤è¢«ä¸­å‘ç°çš„åŠ¨ç‰©ç‰©ç§åŒ…æ‹¬ç°ç‹ã€å±±çŒ«ã€è‡­é¼¬å’Œå…”å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.1â€…â€…â€…Converting Business Problems into Analytics Solutions",
            "zh": "2.1 å°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆ"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with Î¼ = 0.0 and Ïƒ = 0.2.",
            "zh": "å›¾ 8.22[450] ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨ Î¼ = 0.0 å’Œ Ïƒ = 0.2 çš„æ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. Provide complete worked examples. In this book we have presented complete workings for all examples, because this enables readers to check their understanding in detail.",
            "zh": "3. æä¾›å®Œæ•´çš„å·¥ä½œç¤ºä¾‹ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ‰€æœ‰ç¤ºä¾‹çš„å®Œæ•´å·¥ä½œåŸç†ï¼Œå› ä¸ºè¿™ä½¿è¯»è€…èƒ½å¤Ÿè¯¦ç»†æ£€æŸ¥ä»–ä»¬çš„ç†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "ai refers to the value for feature a of the ith instance in a dataset.",
            "zh": "AI æ˜¯æŒ‡æ•°æ®é›†ä¸­ç¬¬ i ä¸ªå®ä¾‹çš„ç‰¹å¾ A çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for the sample mobile phone customer data used in this section, the type of tariff that customers had (e.g.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºæœ¬èŠ‚ä¸­ä½¿ç”¨çš„ç¤ºä¾‹ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®ï¼Œå®¢æˆ·æ‹¥æœ‰çš„èµ„è´¹ç±»å‹ï¼ˆä¾‹å¦‚"
        }
    },
    {
        "translation": {
            "en": "The following table describes a set of students in terms of their grades out of 100 on two other modules (MODULE 1 and MODULE 2) and the GRADE they got in the lecturerâ€™s module: first-class honors, second-class honors, pass, or fail.",
            "zh": "ä¸‹è¡¨æè¿°äº†ä¸€ç»„å­¦ç”Ÿåœ¨å…¶ä»–ä¸¤ä¸ªæ¨¡å—ï¼ˆæ¨¡å— 1 å’Œæ¨¡å— 2ï¼‰ä¸­çš„æˆç»©ï¼ˆæ»¡åˆ† 100 åˆ†ï¼‰ä»¥åŠä»–ä»¬åœ¨è®²å¸ˆæ¨¡å—ä¸­è·å¾—çš„æˆç»©ï¼šä¸€ç­‰è£èª‰ã€äºŒç­‰è£èª‰ã€é€šè¿‡æˆ–å¤±è´¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Bayesian network models described in Chapter 6[243] are examples of generative models.1 Indeed, Markov chain Monte Carlo methods for estimating probabilities are based on the fact that we can run these models to generate data that approximate the distributions of the dataset from which the model was induced.",
            "zh": "ç¬¬6ç« [243]ä¸­æè¿°çš„è´å¶æ–¯ç½‘ç»œæ¨¡å‹æ˜¯ç”Ÿæˆæ¨¡å‹çš„ä¾‹å­.1äº‹å®ä¸Šï¼Œç”¨äºä¼°è®¡æ¦‚ç‡çš„é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›æ–¹æ³•åŸºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³æˆ‘ä»¬å¯ä»¥è¿è¡Œè¿™äº›æ¨¡å‹æ¥ç”Ÿæˆè¿‘ä¼¼äºæ¨¡å‹æ‰€è¡ç”Ÿçš„æ•°æ®é›†åˆ†å¸ƒçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) What would be the output from this neuron if the activation function Ï† is the rectified linear function?",
            "zh": "ï¼ˆdï¼‰ å¦‚æœæ¿€æ´»å‡½æ•°Ï†æ˜¯æ•´æµçº¿æ€§å‡½æ•°ï¼Œé‚£ä¹ˆè¿™ä¸ªç¥ç»å…ƒçš„è¾“å‡ºä¼šæ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure A.3[747] shows a rival school basketball team of that shown in Figure A.1[746].",
            "zh": "å›¾A.3[747]æ˜¾ç¤ºäº†å›¾A.1[746]æ‰€ç¤ºçš„æ•Œå¯¹å­¦æ ¡ç¯®çƒé˜Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13",
            "zh": "å›¾ 8.13"
        }
    },
    {
        "translation": {
            "en": "9.11â€…â€…â€…(a) The changing values of TPR and TNR for the test data shown in Table 9.13 [560] as the threshold is altered; and (b) points in ROC space for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "9.11 ï¼ˆaï¼‰ è¡¨9.13 [560]æ‰€ç¤ºæµ‹è¯•æ•°æ®çš„TPRå’ŒTNRå€¼éšç€é˜ˆå€¼çš„æ”¹å˜è€Œå˜åŒ–;ï¼ˆbï¼‰ ROC ç©ºé—´ä¸­é˜ˆå€¼ä¸º 0.25ã€0.5 å’Œ 0.75 çš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of classifying an unknown animal by matching the features of the animal against the features of animals you have encountered before neatly encapsulates the big idea underpinning similarity-based learning: if you are trying to make a prediction for a current situation, then you should search your memory to find situations that are similar to the current one and make a prediction based on what was true for the most similar situation in your memory.",
            "zh": "é€šè¿‡å°†åŠ¨ç‰©çš„ç‰¹å¾ä¸ä½ ä¹‹å‰é‡åˆ°çš„åŠ¨ç‰©çš„ç‰¹å¾ç›¸åŒ¹é…æ¥å¯¹æœªçŸ¥åŠ¨ç‰©è¿›è¡Œåˆ†ç±»çš„è¿‡ç¨‹ï¼Œå·§å¦™åœ°æ¦‚æ‹¬äº†åŸºäºç›¸ä¼¼æ€§å­¦ä¹ çš„å¤§æ¦‚å¿µï¼šå¦‚æœä½ è¯•å›¾å¯¹å½“å‰æƒ…å†µè¿›è¡Œé¢„æµ‹ï¼Œé‚£ä¹ˆä½ åº”è¯¥æœç´¢ä½ çš„è®°å¿†ï¼Œæ‰¾åˆ°ä¸å½“å‰æƒ…å†µç›¸ä¼¼çš„æƒ…å†µï¼Œå¹¶æ ¹æ®ä½ æœ€ç›¸ä¼¼çš„æƒ…å†µåšå‡ºé¢„æµ‹è®°å¿†ã€‚"
        }
    },
    {
        "translation": {
            "en": "global minimum, 318, 319",
            "zh": "å…¨çƒæœ€å°å€¼ï¼Œ318,319"
        }
    },
    {
        "translation": {
            "en": "We use the â‹† symbol to indicate the index of the true category in the distribution.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ â‹† ç¬¦å·æ¥è¡¨ç¤ºåˆ†å¸ƒä¸­çœŸå®ç±»åˆ«çš„ç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Subsequent centroids are then chosen randomly but following a distribution defined by the square of the distances between an instance and the nearest cluster centroid out of those found so far.",
            "zh": "ç„¶åéšæœºé€‰æ‹©åç»­è´¨å¿ƒï¼Œä½†éµå¾ªç”±å®ä¾‹ä¸è¿„ä»Šä¸ºæ­¢å‘ç°çš„èšç±»è´¨å¿ƒä¹‹é—´çš„è·ç¦»å¹³æ–¹å®šä¹‰çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we were trying to predict gender from a set of physiological measurements, height would most likely be a very predictive value, as it would separate people into male and female groups.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¯•å›¾ä»ä¸€ç»„ç”Ÿç†æµ‹é‡ä¸­é¢„æµ‹æ€§åˆ«ï¼Œèº«é«˜å¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªéå¸¸å…·æœ‰é¢„æµ‹æ€§çš„å€¼ï¼Œå› ä¸ºå®ƒä¼šå°†äººä»¬åˆ†ä¸ºç”·æ€§å’Œå¥³æ€§ç¾¤ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.19(c)[158] illustrates the final iteration of the algorithm.",
            "zh": "å›¾4.19ï¼ˆcï¼‰[158]è¯´æ˜äº†ç®—æ³•çš„æœ€ç»ˆè¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Stepping through Equation 8.104[501] we have the following four operations:",
            "zh": "é€šè¿‡æ–¹ç¨‹ 8.104[501]ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹å››ä¸ªè¿ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "In Line 5[420] the matrix of descriptive features for the examples in the mini-batch that is about to be processed is presented to the input layer of the network.",
            "zh": "åœ¨ç¬¬ 5 è¡Œ [420] ä¸­ï¼Œå³å°†å¤„ç†çš„å°æ‰¹é‡ç¤ºä¾‹çš„æè¿°æ€§ç‰¹å¾çŸ©é˜µå‘ˆç°ç»™ç½‘ç»œçš„è¾“å…¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we may be in a retail domain in which there are so many items that most people havenâ€™t seen, listened to, bought, or visited the vast majority of them, and as a result, the majority of features will be co-absences.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¤„äºä¸€ä¸ªé›¶å”®é¢†åŸŸï¼Œå…¶ä¸­æœ‰å¤ªå¤šçš„å•†å“ï¼Œå¤§å¤šæ•°äººæ²¡æœ‰çœ‹è¿‡ã€å¬è¿‡ã€ä¹°è¿‡æˆ–è®¿é—®è¿‡å…¶ä¸­çš„ç»å¤§å¤šæ•°ï¼Œå› æ­¤ï¼Œå¤§å¤šæ•°åŠŸèƒ½å°†åŒæ—¶ç¼ºå¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we use a decision tree to make predictions for a continuous target, we refer to the tree as a regression tree.14 Typically, the value output by the leaf node of a regression tree is the mean of the target feature values of the instances from the training set that reached that node.",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨å†³ç­–æ ‘å¯¹è¿ç»­ç›®æ ‡è¿›è¡Œé¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å°†è¯¥æ ‘ç§°ä¸ºå›å½’æ ‘ã€‚14 é€šå¸¸ï¼Œå›å½’æ ‘çš„å¶èŠ‚ç‚¹è¾“å‡ºçš„å€¼æ˜¯åˆ°è¾¾è¯¥èŠ‚ç‚¹çš„è®­ç»ƒé›†ä¸­å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼çš„å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "In particular, the SDSS scientists wanted a system that could reliably classify galaxies into the important morphological (i.e., shape) types: elliptical galaxies and spiral galaxies.",
            "zh": "ç‰¹åˆ«æ˜¯ï¼ŒSDSSç§‘å­¦å®¶æƒ³è¦ä¸€ä¸ªèƒ½å¤Ÿå¯é åœ°å°†æ˜Ÿç³»åˆ†ç±»ä¸ºé‡è¦çš„å½¢æ€ï¼ˆå³å½¢çŠ¶ï¼‰ç±»å‹çš„ç³»ç»Ÿï¼šæ¤­åœ†æ˜Ÿç³»å’Œèºæ—‹æ˜Ÿç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "arithmetic mean, 550, 551, 577, 591, 745, 745",
            "zh": "ç®—æœ¯å¹³å‡å€¼ï¼Œ 550ï¼Œ 551ï¼Œ 577ï¼Œ 591ï¼Œ 745ï¼Œ 745"
        }
    },
    {
        "translation": {
            "en": "The functioning of the output gate has a similar interpretation as the input gate: the tanh layer decides what information might be relevant to output from the current cell state, and the sigmoid layer uses the hxt vector to decide which activations are most relevant to output at this time-step.",
            "zh": "è¾“å‡ºé—¨çš„åŠŸèƒ½ä¸è¾“å…¥é—¨å…·æœ‰ç±»ä¼¼çš„è§£é‡Šï¼štanh å±‚å†³å®šå“ªäº›ä¿¡æ¯å¯èƒ½ä¸å½“å‰å•å…ƒçŠ¶æ€çš„è¾“å‡ºç›¸å…³ï¼Œè€Œ sigmoid å±‚ä½¿ç”¨ hxt å‘é‡æ¥å†³å®šå“ªäº›æ¿€æ´»ä¸æ­¤æ—¶é—´æ­¥çš„è¾“å‡ºæœ€ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.7",
            "zh": "å›¾ 11.7"
        }
    },
    {
        "translation": {
            "en": "From these it is clear that instances from the dataset are being used as cluster centroids and that typically there is good diversity across the feature space in the centroids shown.",
            "zh": "ä»è¿™äº›ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œæ•°æ®é›†ä¸­çš„å®ä¾‹è¢«ç”¨ä½œèšç±»è´¨å¿ƒï¼Œå¹¶ä¸”é€šå¸¸åœ¨æ‰€ç¤ºè´¨å¿ƒçš„ç‰¹å¾ç©ºé—´ä¸­å…·æœ‰è‰¯å¥½çš„å¤šæ ·æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "second mode, 749",
            "zh": "ç¬¬äºŒæ¨¡å¼ï¼Œ749"
        }
    },
    {
        "translation": {
            "en": "6.4.1â€ƒSmoothing",
            "zh": "6.4.1 å¹³æ»‘"
        }
    },
    {
        "translation": {
            "en": "Table 3.8",
            "zh": "è¡¨ 3.8"
        }
    },
    {
        "translation": {
            "en": "Data quality issues due to valid data can arise for a range of domain-specific reasons (we discuss some of these later in this section), and we do not necessarily need to take any corrective action to address these issues.",
            "zh": "ç”±äºæœ‰æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜å¯èƒ½ç”±ä¸€ç³»åˆ—ç‰¹å®šé¢†åŸŸçš„åŸå› å¼•èµ·ï¼ˆæˆ‘ä»¬å°†åœ¨æœ¬èŠ‚åé¢è®¨è®ºå…¶ä¸­çš„ä¸€äº›åŸå› ï¼‰ï¼Œæˆ‘ä»¬ä¸ä¸€å®šéœ€è¦é‡‡å–ä»»ä½•çº æ­£æªæ–½æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "A financial institution is planning a direct marketing campaign to sell a pension product to its customer base.",
            "zh": "ä¸€å®¶é‡‘èæœºæ„æ­£åœ¨è®¡åˆ’å¼€å±•ç›´æ¥è¥é”€æ´»åŠ¨ï¼Œå‘å…¶å®¢æˆ·ç¾¤é”€å”®å…»è€é‡‘äº§å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.16â€…â€…â€…The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the data in Tables 6.11[278] and 6.15[283].",
            "zh": "6.16 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.11[278]å’Œè¡¨6.15[283]ä¸­çš„æ•°æ®è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "5.9â€…â€…â€…(a) The final k-d tree generated for the dataset in Table 5.4[191]; and (b) the partitioning of the feature space defined by this k-d tree.",
            "zh": "5.9 ï¼ˆaï¼‰ ä¸ºè¡¨5.4[191]ä¸­çš„æ•°æ®é›†ç”Ÿæˆçš„æœ€ç»ˆk-dæ ‘;ï¼ˆbï¼‰ç”±è¯¥k-dæ ‘å®šä¹‰çš„ç‰¹å¾ç©ºé—´çš„åˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "For most activation functions, avoiding saturation at initialization is achieved by avoiding large (positive or negative) z values, which in turn are avoided by initializing the weights to be close to 0.",
            "zh": "å¯¹äºå¤§å¤šæ•°æ¿€æ´»å‡½æ•°ï¼Œé€šè¿‡é¿å…å¤§ï¼ˆæ­£æˆ–è´Ÿï¼‰z å€¼æ¥å®ç°åˆå§‹åŒ–æ—¶çš„é¥±å’Œï¼Œè€Œ z å€¼åˆé€šè¿‡åˆå§‹åŒ–æƒé‡æ¥è¿‘ 0 æ¥é¿å…é¥±å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.2[263].",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹æ‰€éœ€çš„æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼ˆk = 3ï¼‰æ¦‚ç‡ï¼Œæ ¹æ®è¡¨6.2[263]ä¸­çš„æ•°æ®é›†è®¡ç®—å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "1.3â€…â€…â€…(a)â€“(d) Striking a balance between overfitting and underfitting in trying to predict income from age.",
            "zh": "1.3 ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ åœ¨è¯•å›¾ä»å¹´é¾„é¢„æµ‹æ”¶å…¥æ—¶ï¼Œåœ¨è¿‡åº¦æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆä¹‹é—´å–å¾—å¹³è¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important that this is included at this stage because target features often need to be derived from multiple raw data sources, and the effort that will be involved in this should not be forgotten.",
            "zh": "åœ¨æ­¤é˜¶æ®µå°†å…¶åŒ…æ‹¬åœ¨å†…éå¸¸é‡è¦ï¼Œå› ä¸ºç›®æ ‡ç‰¹å¾é€šå¸¸éœ€è¦ä»å¤šä¸ªåŸå§‹æ•°æ®æºæ´¾ç”Ÿï¼Œå¹¶ä¸”ä¸åº”å¿˜è®°å…¶ä¸­æ¶‰åŠçš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Using box plots to visualize the relationships between categorical and continuous features from Table 3.7[73]: (a) and (b) show the relationship between the POSITION feature and the AGE feature; and (c) and (d) show the relationship between the POSITION feature and the HEIGHT feature.",
            "zh": "ä½¿ç”¨ç®±å½¢å›¾å¯è§†åŒ–è¡¨3.7[73]ä¸­çš„åˆ†ç±»ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼šï¼ˆaï¼‰å’Œï¼ˆbï¼‰æ˜¾ç¤ºPOSITIONç‰¹å¾ä¸AGEç‰¹å¾ä¹‹é—´çš„å…³ç³»;ï¼ˆcï¼‰å’Œï¼ˆdï¼‰æ˜¾ç¤ºäº†POSITIONç‰¹å¾å’ŒHEIGHTç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A duck, no matter how strange, is not a dangerous animal, so you tell the men to get ready for another expedition up the river the next day.",
            "zh": "é¸­å­ï¼Œæ— è®ºå¤šä¹ˆå¥‡æ€ªï¼Œéƒ½ä¸æ˜¯å±é™©çš„åŠ¨ç‰©ï¼Œæ‰€ä»¥ä½ å‘Šè¯‰è¿™äº›äººå‡†å¤‡ç¬¬äºŒå¤©å†å»æ²³ä¸Šæ¢é™©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although an MDP tells us everything we need to know about how an agent can take actions to move between states in an environment, it does not tell us anything about what actions the agent should take to be most successful.",
            "zh": "å°½ç®¡ MDP å‘Šè¯‰æˆ‘ä»¬æœ‰å…³ä»£ç†å¦‚ä½•é‡‡å–æªæ–½åœ¨ç¯å¢ƒä¸­çš„çŠ¶æ€ä¹‹é—´ç§»åŠ¨çš„æ‰€æœ‰ä¿¡æ¯ï¼Œä½†å®ƒå¹¶æ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬ä»£ç†åº”è¯¥é‡‡å–å“ªäº›æ“ä½œæ‰èƒ½æœ€æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The corresponding calculation for P(Â¬m | h,Â¬f,v) is:",
            "zh": "Pï¼ˆÂ¬m | hï¼ŒÂ¬fï¼Œvï¼‰ çš„ç›¸åº”è®¡ç®—ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "C.3â€ƒPartial Derivatives",
            "zh": "C.3 åå¯¼æ•°"
        }
    },
    {
        "translation": {
            "en": "4.19â€…â€…â€…The iterations of reduced error pruning for the decision tree in Figure 4.18[156] using the validation set in Table 4.13[157]. The subtree that is being considered for pruning in each iteration is highlighted in black. The prediction returned by each non-leaf node is listed in square brackets. The error rate for each node is given in parantheses.",
            "zh": "4.19 ä½¿ç”¨è¡¨4.13[157]ä¸­çš„éªŒè¯é›†ï¼Œå¯¹å›¾4.18[156]ä¸­çš„å†³ç­–æ ‘è¿›è¡Œå‡å°‘è¯¯å·®ä¿®å‰ªçš„è¿­ä»£ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­è€ƒè™‘ä¿®å‰ªçš„å­æ ‘ä»¥é»‘è‰²çªå‡ºæ˜¾ç¤ºã€‚æ¯ä¸ªéå¶èŠ‚ç‚¹è¿”å›çš„é¢„æµ‹åˆ—åœ¨æ–¹æ‹¬å·ä¸­ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„é”™è¯¯ç‡ä»¥å‚æ•°å½¢å¼ç»™å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, this figure could be reconfigured as three separate neurons, each receiving the same input vector.",
            "zh": "äº‹å®ä¸Šï¼Œè¿™ä¸ªæ•°å­—å¯ä»¥é‡æ–°é…ç½®ä¸ºä¸‰ä¸ªç‹¬ç«‹çš„ç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒæ¥æ”¶ç›¸åŒçš„è¾“å…¥å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This set of domain concepts would have been determined through consultations between the analytics practitioner and domain experts within the business.",
            "zh": "è¿™ç»„é¢†åŸŸæ¦‚å¿µæ˜¯é€šè¿‡åˆ†æä»ä¸šè€…å’Œä¼ä¸šå†…éƒ¨é¢†åŸŸä¸“å®¶ä¹‹é—´çš„åå•†æ¥ç¡®å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "standardization, 87, 101, 421, 450, 455",
            "zh": "æ ‡å‡†åŒ–ï¼Œ 87ï¼Œ 101ï¼Œ 421ï¼Œ 450ï¼Œ 455"
        }
    },
    {
        "translation": {
            "en": "Rob: Autobiographical.â€",
            "zh": "Robï¼šè‡ªä¼ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics models are reliant on the data that is used to build themâ€”the analytics base table (ABT) is the key data resource in this regard.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹ä¾èµ–äºç”¨äºæ„å»ºå®ƒä»¬çš„æ•°æ®ï¼Œåˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ æ˜¯è¿™æ–¹é¢çš„å…³é”®æ•°æ®èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "We use this handwritten digit recognition task as the basis for our examples in this section.",
            "zh": "æˆ‘ä»¬å°†è¿™ä¸ªæ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡ä½œä¸ºæœ¬èŠ‚ç¤ºä¾‹çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process then starts again using these new weights as the basis for the predictions and errors marked as Iteration 2 in Table 7.8[348].",
            "zh": "ç„¶åï¼Œè¯¥è¿‡ç¨‹å†æ¬¡å¼€å§‹ï¼Œä½¿ç”¨è¿™äº›æ–°æƒé‡ä½œä¸ºè¡¨7.8[348]ä¸­æ ‡è®°ä¸ºè¿­ä»£2çš„é¢„æµ‹å’Œè¯¯å·®çš„åŸºç¡€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The if statement on line 8 will succeed, and the search process will descend down the other branch of the current node (Line 9), because there is possibly an instance closer than the current best instance stored down this branch.",
            "zh": "ç¬¬ 8 è¡Œçš„ if è¯­å¥å°†æˆåŠŸï¼Œæœç´¢è¿‡ç¨‹å°†ä¸‹é™åˆ°å½“å‰èŠ‚ç‚¹çš„å¦ä¸€ä¸ªåˆ†æ”¯ï¼ˆç¬¬ 9 è¡Œï¼‰ï¼Œå› ä¸ºå¯èƒ½æœ‰ä¸€ä¸ªå®ä¾‹æ¯”å­˜å‚¨åœ¨è¯¥åˆ†æ”¯ä¸‹çš„å½“å‰æœ€ä½³å®ä¾‹æ›´æ¥è¿‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.7â€…â€…â€…Summary",
            "zh": "3.7 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39",
            "zh": "å›¾ 8.39"
        }
    },
    {
        "translation": {
            "en": "She even occasionally made it all the way across the stream without stepping into the water and experienced the elation of landing on the grassy bank of the far side of the river.",
            "zh": "å¥¹ç”šè‡³å¶å°”ä¸è¸å…¥æ°´ä¸­å°±ä¸€è·¯ç©¿è¿‡æºªæµï¼Œä½“éªŒåˆ°é™è½åœ¨æ²³å¯¹å²¸è‰åœ°ä¸Šçš„å…´é«˜é‡‡çƒˆã€‚"
        }
    },
    {
        "translation": {
            "en": "posterior probability, 759",
            "zh": "åéªŒæ¦‚ç‡ï¼Œ759"
        }
    },
    {
        "translation": {
            "en": "sparse data, 215, 223, 225, 237, 262",
            "zh": "ç¨€ç–æ•°æ®ã€215ã€223ã€225ã€237ã€262"
        }
    },
    {
        "translation": {
            "en": "To investigate outliers, we should always start by locating the instance in the dataset that contains the strange maximum or minimum values.",
            "zh": "è¦è°ƒæŸ¥å¼‚å¸¸å€¼ï¼Œæˆ‘ä»¬åº”è¯¥å§‹ç»ˆä»åœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾åŒ…å«å¥‡æ€ªçš„æœ€å¤§å€¼æˆ–æœ€å°å€¼çš„å®ä¾‹å¼€å§‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Weighted Sums and Logits",
            "zh": "åŠ æƒæ€»å’Œå’Œå¯¹æ•°"
        }
    },
    {
        "translation": {
            "en": "SOCIOECONOMIC BAND C",
            "zh": "ç¤¾ä¼šç»æµç­‰çº§ C"
        }
    },
    {
        "translation": {
            "en": "A grid for each action (up, down, left, and right) is shown where the shading in the grid illustrates the current estimate of the expected return of that action in the state corresponding to the grid cell position (darker shading indicates higher expected return with lighter shading indicating lower expected return).",
            "zh": "æ¯ä¸ªæ“ä½œï¼ˆå‘ä¸Šã€å‘ä¸‹ã€å‘å·¦å’Œå‘å³ï¼‰çš„ç½‘æ ¼æ˜¾ç¤ºï¼Œå…¶ä¸­ç½‘æ ¼ä¸­çš„åº•çº¹è¡¨ç¤ºè¯¥æ“ä½œåœ¨ä¸ç½‘æ ¼åƒå…ƒä½ç½®ç›¸å¯¹åº”çš„çŠ¶æ€ä¸‹çš„é¢„æœŸå›æŠ¥çš„å½“å‰ä¼°è®¡å€¼ï¼ˆè¾ƒæ·±çš„é˜´å½±è¡¨ç¤ºè¾ƒé«˜çš„é¢„æœŸå›æŠ¥ï¼Œè¾ƒæµ…çš„é˜´å½±è¡¨ç¤ºè¾ƒä½çš„é¢„æœŸå›æŠ¥ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.2â€…â€…â€…Efficient Memory Search",
            "zh": "5.4.2 é«˜æ•ˆå†…å­˜æœç´¢"
        }
    },
    {
        "translation": {
            "en": "This kind of data is very common in real-world scenarios.",
            "zh": "è¿™ç§æ•°æ®åœ¨å®é™…åœºæ™¯ä¸­å¾ˆå¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œWe cannot solve our problems with the same thinking we used when we created them.â€",
            "zh": "â€œæˆ‘ä»¬ä¸èƒ½ç”¨æˆ‘ä»¬åˆ›é€ é—®é¢˜æ—¶ä½¿ç”¨çš„ç›¸åŒæ€ç»´æ¥è§£å†³æˆ‘ä»¬çš„é—®é¢˜ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "2. Assigning a query a target value interpolated (for instance, by majority vote or average) from the target values of individual training instances that are near the query in the feature space.",
            "zh": "2. ä¸ºæŸ¥è¯¢åˆ†é…ä¸€ä¸ªç›®æ ‡å€¼ï¼Œè¯¥ç›®æ ‡å€¼ä»ç‰¹å¾ç©ºé—´ä¸­æŸ¥è¯¢é™„è¿‘çš„å•ä¸ªè®­ç»ƒå®ä¾‹çš„ç›®æ ‡å€¼ä¸­æ’å€¼ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡å¤šæ•°æŠ•ç¥¨æˆ–å¹³å‡å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Described in Section 5.2.2[184]. Although it is possible to use other distance measures, such as those described in Chapter 5[181], in k-means clustering this can break the guarantees that the algorithm makes about convergence. The k-medoids clustering algorithm (Kaufman and Rousseeuw, 1990) was developed to address these problems.",
            "zh": "2. åœ¨ç¬¬ 5.2.2 èŠ‚ä¸­æè¿°[184]ã€‚å°½ç®¡å¯ä»¥ä½¿ç”¨å…¶ä»–è·ç¦»åº¦é‡ï¼Œä¾‹å¦‚ç¬¬ 5 ç« ä¸­æè¿°çš„è·ç¦»åº¦é‡[181]ï¼Œä½†åœ¨ k å‡å€¼èšç±»ä¸­ï¼Œè¿™å¯èƒ½ä¼šç ´åç®—æ³•å¯¹æ”¶æ•›æ€§çš„ä¿è¯ã€‚k-medoidsèšç±»ç®—æ³•ï¼ˆKaufmanå’ŒRousseeuwï¼Œ1990ï¼‰å°±æ˜¯ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜è€Œå¼€å‘çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the probabilities used in the calculation are read directly from the CPTs in Figure 6.9(a)[287].",
            "zh": "å…¶ä¸­ï¼Œè®¡ç®—ä¸­ä½¿ç”¨çš„æ¦‚ç‡ç›´æ¥ä»å›¾6.9ï¼ˆaï¼‰ä¸­çš„CPTä¸­è¯»å–[287]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, unless care is taken, training a network can take an inordinately long time, compared with other machine learning models.",
            "zh": "å› æ­¤ï¼Œé™¤éå°å¿ƒè°¨æ…ï¼Œå¦åˆ™ä¸å…¶ä»–æœºå™¨å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œè®­ç»ƒç½‘ç»œå¯èƒ½éœ€è¦éå¸¸é•¿çš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix is a very quick way to explore the relationships within a whole set of continuous features. The effectiveness of scatter plot matrices, however, diminishes once the number of features in the set goes beyond 8 because the graphs become too small. Using interactive tools that aid data exploration can help overcome this limitation.",
            "zh": "æ•£ç‚¹å›¾çŸ©é˜µæ˜¯æ¢ç´¢ä¸€æ•´å¥—è¿ç»­è¦ç´ ä¸­å…³ç³»çš„ä¸€ç§éå¸¸å¿«é€Ÿçš„æ–¹æ³•ã€‚ä½†æ˜¯ï¼Œä¸€æ—¦é›†åˆä¸­çš„è¦ç´ æ•°é‡è¶…è¿‡ 8ï¼Œæ•£ç‚¹å›¾çŸ©é˜µçš„æœ‰æ•ˆæ€§å°±ä¼šé™ä½ï¼Œå› ä¸ºå›¾å½¢å˜å¾—å¤ªå°ã€‚ä½¿ç”¨æœ‰åŠ©äºæ•°æ®æ¢ç´¢çš„äº¤äº’å¼å·¥å…·å¯ä»¥å¸®åŠ©å…‹æœè¿™ä¸€é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is equivalent to the approach described in Section 3.5.1[72] for visually examining associations between descriptive features and a target feature, in which the cluster that instances belong to are used instead of an actual target feature.",
            "zh": "è¿™ç›¸å½“äºç¬¬ 3.5.1 èŠ‚[72]ä¸­æè¿°çš„æ–¹æ³•ï¼Œç”¨äºç›´è§‚åœ°æ£€æŸ¥æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„å…³è”ï¼Œå…¶ä¸­ä½¿ç”¨å®ä¾‹æ‰€å±çš„é›†ç¾¤è€Œä¸æ˜¯å®é™…çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The overall performance on this balanced dataset was not as good as the performance on the original dataset; however, balancing the training set did result in the performance on each target level being more equal.",
            "zh": "è¯¥å¹³è¡¡æ•°æ®é›†çš„æ•´ä½“æ€§èƒ½ä¸å¦‚åŸå§‹æ•°æ®é›†çš„æ€§èƒ½;ç„¶è€Œï¼Œå¹³è¡¡è®­ç»ƒé›†ç¡®å®å¯¼è‡´æ¯ä¸ªç›®æ ‡æ°´å¹³çš„è¡¨ç°æ›´åŠ å¹³ç­‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "So that we are consistent with the terminology throughout this book, in the rest of this chapter, we use the predictive analytics terms (feature, dataset, prediction, and event) rather than the traditional terms from probability.",
            "zh": "ä¸ºäº†ä¸æœ¬ä¹¦ä¸­çš„æœ¯è¯­ä¿æŒä¸€è‡´ï¼Œåœ¨æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„æµ‹åˆ†ææœ¯è¯­ï¼ˆç‰¹å¾ã€æ•°æ®é›†ã€é¢„æµ‹å’Œäº‹ä»¶ï¼‰ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„æ¦‚ç‡æœ¯è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, a distinction is made that sampling bias affects the ability of a trained model to generalize appropriately beyond the sample training data to the rest of a population, whereas selection bias is more focused on the validity of similarities and differences found within the sample.",
            "zh": "ç„¶è€Œï¼Œæœ‰æ—¶éœ€è¦åŒºåˆ†çš„æ˜¯ï¼ŒæŠ½æ ·åå·®ä¼šå½±å“è®­ç»ƒæ¨¡å‹åœ¨æ ·æœ¬è®­ç»ƒæ•°æ®ä¹‹å¤–é€‚å½“åœ°æ¨å¹¿åˆ°æ€»ä½“å…¶ä½™éƒ¨åˆ†çš„èƒ½åŠ›ï¼Œè€Œé€‰æ‹©åå·®åˆ™æ›´ä¾§é‡äºæ ·æœ¬ä¸­å‘ç°çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§çš„æœ‰æ•ˆæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second consideration is the timing with which data becomes available for inclusion in a feature.",
            "zh": "ç¬¬äºŒä¸ªè€ƒè™‘å› ç´ æ˜¯æ•°æ®å¯ç”¨äºåŒ…å«åœ¨åŠŸèƒ½ä¸­çš„æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The legal considerations surrounding predictive analytics are of growing importance and need to be seriously considered during the design of any analytics project. Although larger organizations have legal departments to whom proposed features can be handed over for assessment, in smaller organizations analysts are often required to make these assessments themselves, and consequently they need to be aware of the legal implications relating to their decisions.",
            "zh": "å›´ç»•é¢„æµ‹åˆ†æçš„æ³•å¾‹è€ƒè™‘å› ç´ è¶Šæ¥è¶Šé‡è¦ï¼Œåœ¨ä»»ä½•åˆ†æé¡¹ç›®çš„è®¾è®¡è¿‡ç¨‹ä¸­éƒ½éœ€è¦è®¤çœŸè€ƒè™‘ã€‚å°½ç®¡è¾ƒå¤§çš„ç»„ç»‡æœ‰æ³•å¾‹éƒ¨é—¨ï¼Œå¯ä»¥å°†æè®®çš„åŠŸèƒ½ç§»äº¤ç»™ä»–ä»¬è¿›è¡Œè¯„ä¼°ï¼Œä½†åœ¨è¾ƒå°çš„ç»„ç»‡ä¸­ï¼Œåˆ†æå¸ˆé€šå¸¸éœ€è¦è‡ªå·±è¿›è¡Œè¿™äº›è¯„ä¼°ï¼Œå› æ­¤ä»–ä»¬éœ€è¦äº†è§£ä¸å…¶å†³ç­–ç›¸å…³çš„æ³•å¾‹å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "SVM models are just one of a whole range of error-based approaches that are active areas for machine learning research, and new approaches are constantly being developed.",
            "zh": "SVM æ¨¡å‹åªæ˜¯ä¸€ç³»åˆ—åŸºäºé”™è¯¯çš„æ–¹æ³•ä¹‹ä¸€ï¼Œè¿™äº›æ–¹æ³•æ˜¯æœºå™¨å­¦ä¹ ç ”ç©¶çš„æ´»è·ƒé¢†åŸŸï¼Œå¹¶ä¸”æ–°æ–¹æ³•æ­£åœ¨ä¸æ–­å¼€å‘ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 11.4",
            "zh": "è¡¨ 11.4"
        }
    },
    {
        "translation": {
            "en": "harmonic mean, 550, 551, 552, 554, 577, 586, 698",
            "zh": "è°æ³¢å¹³å‡å€¼ï¼Œ550ã€551ã€552ã€554ã€577ã€586ã€698"
        }
    },
    {
        "translation": {
            "en": "The labels on the rectangles indicate whether the rectangle represents the input layer xt, the hidden layer ht, the output layer yt, or the activation buffer that stores the activations of the hidden layer from the previous time-step htâˆ’1.",
            "zh": "çŸ©å½¢ä¸Šçš„æ ‡ç­¾æŒ‡ç¤ºçŸ©å½¢æ˜¯è¡¨ç¤ºè¾“å…¥å±‚ xtã€éšè—å±‚ htã€è¾“å‡ºå±‚ ytï¼Œè¿˜æ˜¯å­˜å‚¨ä¸Šä¸€ä¸ªæ—¶é—´æ­¥é•¿ htâˆ’1 ä¸­éšè—å±‚æ¿€æ´»çš„æ¿€æ´»ç¼“å†²åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "tree pruning, 154, 169",
            "zh": "æ ‘æœ¨ä¿®å‰ªï¼Œ 154ï¼Œ 169"
        }
    },
    {
        "translation": {
            "en": "For example, some functions can be implemented exactly using a small neural network with two layers but require an infinite number of nodes to approximate with a single hidden layer (Makhoul et al., 1989; Reed and Marks, 1999).",
            "zh": "ä¾‹å¦‚ï¼ŒæŸäº›å‡½æ•°å¯ä»¥ä½¿ç”¨å…·æœ‰ä¸¤å±‚çš„å°å‹ç¥ç»ç½‘ç»œç²¾ç¡®å®ç°ï¼Œä½†éœ€è¦æ— é™æ•°é‡çš„èŠ‚ç‚¹æ‰èƒ½è¿‘ä¼¼äºå•ä¸ªéšè—å±‚ï¼ˆMakhoul et al.ï¼Œ 1989;Reed å’Œ Marksï¼Œ1999 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic is the maximum of these distances.",
            "zh": "K-S ç»Ÿè®¡é‡æ˜¯è¿™äº›è·ç¦»çš„æœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This expansion in the number of terms arises from the fact that for all hidden neurons the Î´ term is calculated by a product of (1) âˆ‚â„°/âˆ‚ai, which itself is a product of the weighted sum of the Î´s backpropagated to the neuron; and (2) the derivative of the neuronâ€™s activation function, that is, a term of the form âˆ‚ak/âˆ‚zk (see Equation (8.23)[412]).",
            "zh": "é¡¹æ•°çš„è¿™ç§æ‰©å±•æºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å¯¹äºæ‰€æœ‰éšè—ç¥ç»å…ƒï¼ŒÎ´é¡¹æ˜¯ç”± ï¼ˆ1ï¼‰ âˆ‚E/âˆ‚ai çš„ä¹˜ç§¯è®¡ç®—çš„ï¼Œå®ƒæœ¬èº«æ˜¯åå‘ä¼ æ’­åˆ°ç¥ç»å…ƒçš„ Î´s åŠ æƒå’Œçš„ä¹˜ç§¯;ï¼ˆ2ï¼‰ç¥ç»å…ƒæ¿€æ´»å‡½æ•°çš„å¯¼æ•°ï¼Œå³âˆ‚ak/âˆ‚zkå½¢å¼çš„é¡¹ï¼ˆå‚è§æ–¹ç¨‹ï¼ˆ8.23ï¼‰[412]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Then, using the feature at the start of the list for the first split, we select the next feature in the list for each subsequent split.",
            "zh": "ç„¶åï¼Œä½¿ç”¨åˆ—è¡¨å¼€å¤´çš„ç‰¹å¾è¿›è¡Œç¬¬ä¸€æ¬¡æ‹†åˆ†ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªåç»­æ‹†åˆ†é€‰æ‹©åˆ—è¡¨ä¸­çš„ä¸‹ä¸€ä¸ªç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.1â€ƒBig Idea",
            "zh": "8.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "interpretability of models, 739",
            "zh": "æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œ739"
        }
    },
    {
        "translation": {
            "en": "8.2â€…â€…â€…The minimum and maximum values for the AMBIENT TEMPERATURE, RELATIVE HUMIDITY, and ELECTRICAL OUTPUT features in the power plant dataset.",
            "zh": "8.2 ç”µå‚æ•°æ®é›†ä¸­ç¯å¢ƒæ¸©åº¦ã€ç›¸å¯¹æ¹¿åº¦å’Œç”µè¾“å‡ºè¦ç´ çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The figure also shows that the derivative is 0 (or near 0) for the saturated regions of the function: the logistic function saturates for large negative ( â‰ˆ z < âˆ’2) or positive values (z > +2); this means that the rate of change of the output of the logistic function with respect to small changes in z, when z has a large negative or positive value, is 0 (or near 0).",
            "zh": "è¯¥å›¾è¿˜æ˜¾ç¤ºï¼Œå‡½æ•°é¥±å’ŒåŒºåŸŸçš„å¯¼æ•°ä¸º 0ï¼ˆæˆ–æ¥è¿‘ 0ï¼‰ï¼šå¯¹äºå¤§çš„è´Ÿå€¼ ï¼ˆ â‰ˆ z < âˆ’2ï¼‰ æˆ–æ­£å€¼ ï¼ˆz > +2ï¼‰ï¼Œé€»è¾‘å‡½æ•°é¥±å’Œ;è¿™æ„å‘³ç€å½“ z å…·æœ‰è¾ƒå¤§çš„è´Ÿå€¼æˆ–æ­£å€¼æ—¶ï¼Œé€»è¾‘å‡½æ•°è¾“å‡ºç›¸å¯¹äº z çš„å¾®å°å˜åŒ–çš„å˜åŒ–ç‡ä¸º 0ï¼ˆæˆ–æ¥è¿‘ 0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence if the model assigns the maximum probability mass to an incorrect category, this will reduce and, as Figure (4.6)[125] illustrates, this will result in the negative log of the rapidly increasing.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæ¨¡å‹å°†æœ€å¤§æ¦‚ç‡è´¨é‡åˆ†é…ç»™ä¸æ­£ç¡®çš„ç±»åˆ«ï¼Œè¿™å°†å‡å°‘ï¼Œå¹¶ä¸”å¦‚å›¾ï¼ˆ4.6ï¼‰[125]æ‰€ç¤ºï¼Œè¿™å°†å¯¼è‡´å¿«é€Ÿå¢åŠ çš„è´Ÿå¯¹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "29. Feature selection is sometimes also known as variable selection.",
            "zh": "29. ç‰¹å¾é€‰æ‹©æœ‰æ—¶ä¹Ÿç§°ä¸ºå˜é‡é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is reflected in the stability index calculations in Table 9.21[581], which are determined using Equation (9.31)[580].",
            "zh": "è¿™åæ˜ åœ¨è¡¨9.21[581]ä¸­çš„ç¨³å®šæ€§æŒ‡æ•°è®¡ç®—ä¸­ï¼Œè¯¥è®¡ç®—ä½¿ç”¨å…¬å¼ï¼ˆ9.31ï¼‰[580]ç¡®å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "missing values, 63, 64, 94, 231, 693",
            "zh": "ç¼ºå°‘å€¼ã€63ã€64ã€94ã€231ã€693"
        }
    },
    {
        "translation": {
            "en": "A simple linear regression model cannot handle this non-linear relationship. Figure 7.16(b)[352] shows the best simple linear regression model that can be trained for this prediction problem. This model is",
            "zh": "ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹æ— æ³•å¤„ç†è¿™ç§éçº¿æ€§å…³ç³»ã€‚å›¾7.16ï¼ˆbï¼‰[352]æ˜¾ç¤ºäº†å¯ä»¥é’ˆå¯¹æ­¤é¢„æµ‹é—®é¢˜è®­ç»ƒçš„æœ€ä½³ç®€å•çº¿æ€§å›å½’æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The sample space for a domain is the set of all possible combinations of assignments of values to features.",
            "zh": "åŸŸçš„æ ·æœ¬ç©ºé—´æ˜¯è¦ç´ å€¼èµ‹å€¼çš„æ‰€æœ‰å¯èƒ½ç»„åˆçš„é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Score",
            "zh": "å¾—åˆ†"
        }
    },
    {
        "translation": {
            "en": "The advantage of a local receptive field is that for a given neuron, the learning task is simplified to learning whether a particular feature occurs in a specific local region rather than learning to activate when one or more features occur anywhere in the visual field.",
            "zh": "å±€éƒ¨æ„Ÿå—é‡çš„ä¼˜ç‚¹æ˜¯ï¼Œå¯¹äºç»™å®šçš„ç¥ç»å…ƒï¼Œå­¦ä¹ ä»»åŠ¡è¢«ç®€åŒ–ä¸ºå­¦ä¹ ç‰¹å®šç‰¹å¾æ˜¯å¦å‘ç”Ÿåœ¨ç‰¹å®šçš„å±€éƒ¨åŒºåŸŸï¼Œè€Œä¸æ˜¯å­¦ä¹ åœ¨è§†é‡ä¸­çš„ä»»ä½•ä½ç½®å‡ºç°ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾æ—¶æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5",
            "zh": "å›¾ 6.5"
        }
    },
    {
        "translation": {
            "en": "2.4.6â€ƒCase Study: Motor Insurance Fraud",
            "zh": "2.4.6 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce the fundamental statistical measures of central tendency and variation. We also introduce three of the most important and useful data visualization techniques that can be used to visualize a single feature: the bar plot, the histogram, and the box plot.",
            "zh": "åœ¨æœ¬é™„å½•ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†é›†ä¸­è¶‹åŠ¿å’Œå˜åŒ–çš„åŸºæœ¬ç»Ÿè®¡æµ‹é‡æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸‰ç§æœ€é‡è¦å’Œæœ€æœ‰ç”¨çš„æ•°æ®å¯è§†åŒ–æŠ€æœ¯ï¼Œå¯ç”¨äºå¯è§†åŒ–å•ä¸ªç‰¹å¾ï¼šæ¡å½¢å›¾ã€ç›´æ–¹å›¾å’Œç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.2.1â€ƒConfusion matrix-based performance measuresâ€ƒConfusion matrices are a convenient way to fully describe the performance of a predictive model when applied to a test set.",
            "zh": "9.4.2.1 åŸºäºæ··æ·†çŸ©é˜µçš„æ€§èƒ½æµ‹é‡ æ··æ·†çŸ©é˜µæ˜¯å……åˆ†æè¿°é¢„æµ‹æ¨¡å‹åº”ç”¨äºæµ‹è¯•é›†æ—¶æ€§èƒ½çš„ä¾¿æ·æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "We do not cover these techniques here, but they are covered in most standard linear algebra textbooks such as Anton and Rorres (2010).",
            "zh": "æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä»‹ç»è¿™äº›æŠ€æœ¯ï¼Œä½†å®ƒä»¬åœ¨å¤§å¤šæ•°æ ‡å‡†çº¿æ€§ä»£æ•°æ•™ç§‘ä¹¦ä¸­éƒ½æœ‰æ‰€ä»‹ç»ï¼Œä¾‹å¦‚Antonå’ŒRorres ï¼ˆ2010ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. If data had been more scarce, pruning using a statistical test, such as Ï‡2, would have been a more sensible route to take.",
            "zh": "9. å¦‚æœæ•°æ®æ›´åŠ ç¨€ç¼ºï¼Œä½¿ç”¨ç»Ÿè®¡æ£€éªŒï¼ˆå¦‚Ï‡2ï¼‰è¿›è¡Œä¿®å‰ªå°†æ˜¯æ›´æ˜æ™ºçš„é€”å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.1â€ƒMissing Values",
            "zh": "3.3.1 ç¼ºå¤±å€¼"
        }
    },
    {
        "translation": {
            "en": "There are also situations, however, where we wish to change the size and/or the distributions of target values within the ABT.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æ›´æ”¹ ABT ä¸­ç›®æ ‡å€¼çš„å¤§å°å’Œ/æˆ–åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features used by these models often can be automatically extracted from digitized maps, aerial photographs, or satellite imageryâ€”for example, the elevation, steepness, color, and spectral reflection of the terrain and the presence or absence of features such as rivers, roads, or lakes.",
            "zh": "è¿™äº›æ¨¡å‹ä½¿ç”¨çš„æè¿°æ€§è¦ç´ é€šå¸¸å¯ä»¥ä»æ•°å­—åŒ–åœ°å›¾ã€èˆªç©ºç…§ç‰‡æˆ–å«æ˜Ÿå½±åƒä¸­è‡ªåŠ¨æå–ï¼Œä¾‹å¦‚ï¼Œåœ°å½¢çš„é«˜ç¨‹ã€é™¡åº¦ã€é¢œè‰²å’Œå…‰è°±åå°„ï¼Œä»¥åŠæ²³æµã€é“è·¯æˆ–æ¹–æ³Šç­‰è¦ç´ çš„å­˜åœ¨ä¸å¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This loss function is called cross-entropy because in information theory cross-entropy is used to describe a measure of the difference in nats between two probability distributions over the same set of events.",
            "zh": "è¿™ç§æŸå¤±å‡½æ•°ç§°ä¸ºäº¤å‰ç†µï¼Œå› ä¸ºåœ¨ä¿¡æ¯è®ºä¸­ï¼Œäº¤å‰ç†µç”¨äºæè¿°åŒä¸€ç»„äº‹ä»¶çš„ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„ nats å·®å¼‚çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Absolute rarity refers to scenarios in which there simply do not exist many examples of the minority target levelsâ€”for example, in automated inspection tasks on production lines, it is often the case that there are simply very few examples of defective products that can be used for training.",
            "zh": "ç»å¯¹ç¨€æœ‰æ€§æ˜¯æŒ‡æ ¹æœ¬ä¸å­˜åœ¨å°‘æ•°ç›®æ ‡æ°´å¹³çš„ä¾‹å­çš„åœºæ™¯â€”â€”ä¾‹å¦‚ï¼Œåœ¨ç”Ÿäº§çº¿ä¸Šçš„è‡ªåŠ¨åŒ–æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œå¯ç”¨äºåŸ¹è®­çš„ç¼ºé™·äº§å“çš„ä¾‹å­å¾ˆå°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "To convert these information gain scores into information gain ratios, we need to compute the entropy of each feature and then divide the information gain scores by the respective entropy values. The entropy calculations for these descriptive features are",
            "zh": "ä¸ºäº†å°†è¿™äº›ä¿¡æ¯å¢ç›Šåˆ†æ•°è½¬æ¢ä¸ºä¿¡æ¯å¢ç›Šæ¯”ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ç†µï¼Œç„¶åå°†ä¿¡æ¯å¢ç›Šåˆ†æ•°é™¤ä»¥ç›¸åº”çš„ç†µå€¼ã€‚è¿™äº›æè¿°æ€§ç‰¹å¾çš„ç†µè®¡ç®—æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The result is shown in Table 4.9[147].",
            "zh": "ç»“æœå¦‚è¡¨4.9[147]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Only 2% of the values for the NUM.",
            "zh": "ä»…å  NUM å€¼çš„ 2%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability-based learning (Chapter 6[243])",
            "zh": "åŸºäºæ¦‚ç‡çš„å­¦ä¹ ï¼ˆç¬¬6ç« [243]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "To start the search, the algorithm is given a seed network and then iteratively adapts this network by adding, removing, or reversing links (and/or adding and removing hidden nodes), accompanied by iterations of parameter learning after each network structure adaptation.",
            "zh": "ä¸ºäº†å¼€å§‹æœç´¢ï¼Œç®—æ³•è¢«èµ‹äºˆä¸€ä¸ªç§å­ç½‘ç»œï¼Œç„¶åé€šè¿‡æ·»åŠ ã€åˆ é™¤æˆ–åè½¬é“¾æ¥ï¼ˆå’Œ/æˆ–æ·»åŠ å’Œåˆ é™¤éšè—èŠ‚ç‚¹ï¼‰æ¥è¿­ä»£åœ°é€‚åº”è¿™ä¸ªç½‘ç»œï¼Œå¹¶åœ¨æ¯ä¸ªç½‘ç»œç»“æ„é€‚åº”åè¿›è¡Œå‚æ•°å­¦ä¹ çš„è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "AlphaGo, 677",
            "zh": "é˜¿å°”æ³•å›´æ£‹ï¼Œ677"
        }
    },
    {
        "translation": {
            "en": "Considering the distribution of the instances in the feature space as depicted in Figure 5.12(a)[205], the result that instance d6 is the nearest neighbor to the query is surprising. Several other instances appear to be much closer to the query, and importantly, several of these instances have a target level of no, for example, instance d1. Why do we get this strange result?",
            "zh": "è€ƒè™‘åˆ°å›¾5.12ï¼ˆaï¼‰[205]ä¸­æè¿°çš„å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†å¸ƒï¼Œå®ä¾‹d6æ˜¯æŸ¥è¯¢çš„æœ€è¿‘é‚»çš„ç»“æœä»¤äººæƒŠè®¶ã€‚å…¶ä»–å‡ ä¸ªå®ä¾‹ä¼¼ä¹æ›´æ¥è¿‘æŸ¥è¯¢ï¼Œé‡è¦çš„æ˜¯ï¼Œå…¶ä¸­ä¸€äº›å®ä¾‹çš„ç›®æ ‡çº§åˆ«ä¸º noï¼Œä¾‹å¦‚å®ä¾‹ d1ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼šå¾—åˆ°è¿™ä¸ªå¥‡æ€ªçš„ç»“æœï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "(d) What target level will a naive Bayes model predict for the following query:",
            "zh": "ï¼ˆdï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹å°†é¢„æµ‹ä»¥ä¸‹æŸ¥è¯¢çš„ç›®æ ‡æ°´å¹³ï¼š"
        }
    },
    {
        "translation": {
            "en": "The whiskers that emerge from the top and bottom of the main rectangle in a box plot are designed to show the range of the data. The top whisker extends to whichever is lower of the maximum value of the feature or the upper quartile plus 1.5 times the IQR. Similarly, the bottom whisker extends to whichever is higher of the minimum value of the feature or the lower quartile minus 1.5 times the IQR. Values that fall outside the whiskers are referred to as outliers and are shown as small circles.",
            "zh": "ä»ç®±å½¢å›¾ä¸­ä¸»çŸ©å½¢çš„é¡¶éƒ¨å’Œåº•éƒ¨å‡ºç°çš„æ™¶é¡»æ—¨åœ¨æ˜¾ç¤ºæ•°æ®çš„èŒƒå›´ã€‚é¡¶éƒ¨èƒ¡é¡»å»¶ä¼¸åˆ°ç‰¹å¾çš„æœ€å¤§å€¼æˆ–ä¸Šå››åˆ†ä½æ•°åŠ ä¸Š IQR çš„ 1.5 å€çš„è¾ƒä½è€…ã€‚åŒæ ·ï¼Œåº•éƒ¨æ™¶é¡»å»¶ä¼¸åˆ°ç‰¹å¾æœ€å°å€¼æˆ–ä¸‹å››åˆ†ä½æ•°å‡å» IQR 1.5 å€çš„è¾ƒé«˜è€…ã€‚ä½äºèƒ¡é¡»ä¹‹å¤–çš„å€¼ç§°ä¸ºå¼‚å¸¸å€¼ï¼Œå¹¶æ˜¾ç¤ºä¸ºå°åœ†åœˆã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.1â€ƒDifferent Types of Data",
            "zh": "2.4.1 ä¸åŒç±»å‹çš„æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "7.2.3â€…â€…â€…Error Surfaces",
            "zh": "7.2.3 é”™è¯¯é¢"
        }
    },
    {
        "translation": {
            "en": "Using this identity, we can define the first term in the product in Equation (8.72)[467]",
            "zh": "ä½¿ç”¨è¿™ä¸ªæ’ç­‰å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ–¹ç¨‹ï¼ˆ8.72ï¼‰[467]ä¸­å®šä¹‰ä¹˜ç§¯ä¸­çš„ç¬¬ä¸€é¡¹"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(d)[663] shows the total cumulative reward (or return) earned by the agent for each of 350 learning episodes that the agent performs in this grid world environment (to make it easier to see the overall trend in this graph a rolling mean across 10 episodes is shown).",
            "zh": "å›¾ 11.5ï¼ˆdï¼‰[663] æ˜¾ç¤ºäº†æ™ºèƒ½ä½“åœ¨æ­¤ç½‘æ ¼ä¸–ç•Œç¯å¢ƒä¸­æ‰§è¡Œçš„ 350 ä¸ªå­¦ä¹ äº‹ä»¶ä¸­æ¯ä¸ªäº‹ä»¶æ‰€è·å¾—çš„æ€»ç´¯ç§¯å¥–åŠ±ï¼ˆæˆ–å›æŠ¥ï¼‰ï¼ˆä¸ºäº†ä¾¿äºæŸ¥çœ‹æ­¤å›¾ä¸­çš„æ€»ä½“è¶‹åŠ¿ï¼Œæ˜¾ç¤ºäº† 10 ä¸ªäº‹ä»¶çš„æ»šåŠ¨å¹³å‡å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The cardinality value indicates that every instance has the same value for this feature, ci.",
            "zh": "åŸºæ•°å€¼è¡¨ç¤ºæ¯ä¸ªå®ä¾‹å¯¹æ­¤åŠŸèƒ½ ci å…·æœ‰ç›¸åŒçš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although monitoring changes in the performance of a model is the easiest way to tell whether it has gone stale, this method makes the rather large assumption that the correct target feature value for a query instance will be made available shortly after the query has been presented to a deployed model.",
            "zh": "å°½ç®¡ç›‘è§†æ¨¡å‹æ€§èƒ½çš„å˜åŒ–æ˜¯åˆ¤æ–­æ¨¡å‹æ˜¯å¦è¿‡æ—¶çš„æœ€ç®€å•æ–¹æ³•ï¼Œä½†æ­¤æ–¹æ³•åšå‡ºäº†ç›¸å½“å¤§çš„å‡è®¾ï¼Œå³æŸ¥è¯¢å®ä¾‹çš„æ­£ç¡®ç›®æ ‡ç‰¹å¾å€¼å°†åœ¨æŸ¥è¯¢å‘ˆç°ç»™å·²éƒ¨ç½²çš„æ¨¡å‹åä¸ä¹…å¯ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This AHC algorithm requires two decisions to be made in order for it to be complete.",
            "zh": "æ­¤ AHC ç®—æ³•éœ€è¦åšå‡ºä¸¤ä¸ªå†³ç­–æ‰èƒ½å®Œæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, the gradients in this network will not be affected by saturated activation functions.29 Apart from adjusting the network architecture, we also increase the size of the training data to a sample of 100 examples, and we standardize30 all the features to have a mean of 0 and a standard deviation of 1.31",
            "zh": "å› æ­¤ï¼Œè¯¥ç½‘ç»œä¸­çš„æ¢¯åº¦ä¸ä¼šå—åˆ°é¥±å’Œæ¿€æ´»å‡½æ•°çš„å½±å“.29 é™¤äº†è°ƒæ•´ç½‘ç»œæ¶æ„å¤–ï¼Œæˆ‘ä»¬è¿˜å°†è®­ç»ƒæ•°æ®çš„å¤§å°å¢åŠ åˆ° 100 ä¸ªæ ·æœ¬ï¼Œå¹¶å°†æ‰€æœ‰ç‰¹å¾æ ‡å‡†åŒ– 30ï¼Œå¹³å‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1.31"
        }
    },
    {
        "translation": {
            "en": "The Art of Machine Learning for Predictive Data Analytics",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ è‰ºæœ¯"
        }
    },
    {
        "translation": {
            "en": "(c) Assuming that these models are part of an ensemble trained using boosting and that the confidence factors, Î±, for the models are as follows:",
            "zh": "ï¼ˆcï¼‰ å‡è®¾è¿™äº›æ¨¡å‹æ˜¯ä½¿ç”¨æå‡è®­ç»ƒçš„é›†æˆçš„ä¸€éƒ¨åˆ†ï¼Œå¹¶ä¸”æ¨¡å‹çš„ç½®ä¿¡å› å­Î±å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "The performance of the model measured using appropriate performance measures",
            "zh": "ä½¿ç”¨é€‚å½“çš„æ€§èƒ½åº¦é‡è¡¡é‡æ¨¡å‹çš„æ€§èƒ½"
        }
    },
    {
        "translation": {
            "en": "Consequently, a Bayesian network representation is generally more compact than a full joint distribution (because it can encode conditional independence relationships), yet it is not forced to assert a global conditional independence between all descriptive features.",
            "zh": "å› æ­¤ï¼Œè´å¶æ–¯ç½‘ç»œè¡¨ç¤ºé€šå¸¸æ¯”å®Œå…¨è”åˆåˆ†å¸ƒæ›´ç´§å‡‘ï¼ˆå› ä¸ºå®ƒå¯ä»¥ç¼–ç æ¡ä»¶ç‹¬ç«‹å…³ç³»ï¼‰ï¼Œä½†å®ƒå¹¶ä¸å¼ºåˆ¶æ–­è¨€æ‰€æœ‰æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å…¨å±€æ¡ä»¶ç‹¬ç«‹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "As part of this type of broader evaluation, the use of comparative experiments that include a control group can be quite effective.",
            "zh": "ä½œä¸ºè¿™ç§æ›´å¹¿æ³›è¯„ä¼°çš„ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨åŒ…æ‹¬å¯¹ç…§ç»„åœ¨å†…çš„æ¯”è¾ƒå®éªŒå¯èƒ½éå¸¸æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This states that the expected return of taking action at in state st is the immediate expected reward from taking that action plus the sum of discounted expected rewards that will arise if we continue to follow policy Ï€.",
            "zh": "è¿™è¡¨æ˜ï¼Œåœ¨çŠ¶æ€ä¸‹é‡‡å–è¡ŒåŠ¨çš„é¢„æœŸå›æŠ¥æ˜¯é‡‡å–è¯¥è¡ŒåŠ¨çš„ç›´æ¥é¢„æœŸå›æŠ¥åŠ ä¸Šå¦‚æœæˆ‘ä»¬ç»§ç»­éµå¾ªæ”¿ç­–Ï€å°†äº§ç”Ÿçš„è´´ç°é¢„æœŸå›æŠ¥çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Neuron 8 is the only output neuron in the network, and so once Î´8 has been calculated, we can then proceed to backpropagate the error gradient of the network for d2 and calculate the Î´s for Neurons 6 and 7. These are hidden neurons, so we use the Equation (8.23)[412] to calculate Î´ 6 and Î´7; Equation (8.33)[428] steps through the calculation of Î´6 and Equation (8.34)[428] steps through the calculation for Î´7",
            "zh": "ç¥ç»å…ƒ 8 æ˜¯ç½‘ç»œä¸­å”¯ä¸€çš„è¾“å‡ºç¥ç»å…ƒï¼Œå› æ­¤ä¸€æ—¦è®¡ç®—äº† Î´8ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç»§ç»­åå‘ä¼ æ’­ d2 çš„ç½‘ç»œè¯¯å·®æ¢¯åº¦ï¼Œå¹¶è®¡ç®—ç¥ç»å…ƒ 6 å’Œ 7 çš„ Î´ã€‚è¿™äº›æ˜¯éšè—çš„ç¥ç»å…ƒï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨æ–¹ç¨‹ï¼ˆ8.23ï¼‰[412]æ¥è®¡ç®—Î´ 6å’ŒÎ´7;æ–¹ç¨‹ï¼ˆ8.33ï¼‰[428]é€æ­¥è®¡ç®—Î´6ï¼Œæ–¹ç¨‹ï¼ˆ8.34ï¼‰[428]é€æ­¥è®¡ç®—Î´7"
        }
    },
    {
        "translation": {
            "en": "9.5â€…â€…â€…A confusion matrix for a k-NN model trained on a churn prediction problem.",
            "zh": "9.5 åŸºäºæµå¤±é¢„æµ‹é—®é¢˜è®­ç»ƒçš„ k-NN æ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "In designing an ABT, the first decision an analytics practitioner needs to make is on the prediction subject for the model they are trying to build.",
            "zh": "åœ¨è®¾è®¡ ABT æ—¶ï¼Œåˆ†æä»ä¸šè€…éœ€è¦åšå‡ºçš„ç¬¬ä¸€ä¸ªå†³å®šæ˜¯ä»–ä»¬è¯•å›¾æ„å»ºçš„æ¨¡å‹çš„é¢„æµ‹ä¸»é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The primary reason why we apply smoothing is to remove zero probabilities from a modelâ€™s representation of a domain, and in the vast majority of cases, all the unconditional target level probabilities will be non-zero (because there will be at least one instance with each target level in the training data).",
            "zh": "æˆ‘ä»¬åº”ç”¨å¹³æ»‘çš„ä¸»è¦åŸå› æ˜¯ä»æ¨¡å‹çš„åŸŸè¡¨ç¤ºä¸­åˆ é™¤é›¶æ¦‚ç‡ï¼Œå¹¶ä¸”åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ— æ¡ä»¶ç›®æ ‡æ°´å¹³æ¦‚ç‡éƒ½å°†ä¸ä¸ºé›¶ï¼ˆå› ä¸ºè®­ç»ƒæ•°æ®ä¸­æ¯ä¸ªç›®æ ‡æ°´å¹³è‡³å°‘æœ‰ä¸€ä¸ªå®ä¾‹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this instance the prediction subject is an insurance claim, and so the ABT for this problem will contain details of historical claims described by a set of descriptive features that capture likely indicators of fraud, and a target feature indicating whether a claim was ultimately considered fraudulent.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼Œé¢„æµ‹ä¸»é¢˜æ˜¯ä¿é™©ç´¢èµ”ï¼Œå› æ­¤æ­¤é—®é¢˜çš„ ABT å°†åŒ…å«ç”±ä¸€ç»„æè¿°æ€§ç‰¹å¾æè¿°çš„å†å²ç´¢èµ”çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¿™äº›ç‰¹å¾æ•è·å¯èƒ½çš„æ¬ºè¯ˆæŒ‡æ ‡ï¼Œä»¥åŠæŒ‡ç¤ºç´¢èµ”æœ€ç»ˆæ˜¯å¦è¢«è§†ä¸ºæ¬ºè¯ˆçš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the insurance company divides their operations into a number of geographic areas defined internally based on the location of their branches, and a feature is included that maps raw address data to these regions.",
            "zh": "æœ€åï¼Œä¿é™©å…¬å¸æ ¹æ®å…¶åˆ†æ”¯æœºæ„çš„ä½ç½®å°†å…¶ä¸šåŠ¡åˆ’åˆ†ä¸ºå†…éƒ¨å®šä¹‰çš„å¤šä¸ªåœ°ç†åŒºåŸŸï¼Œå¹¶åŒ…å«å°†åŸå§‹åœ°å€æ•°æ®æ˜ å°„åˆ°è¿™äº›åŒºåŸŸçš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "equal-width binning, 89, 90, 102, 280",
            "zh": "ç­‰å®½åˆ†æ¡£ï¼Œ 89ï¼Œ 90ï¼Œ 102ï¼Œ 280"
        }
    },
    {
        "translation": {
            "en": "Generative models tend to have a higher biasâ€”they make more assumptions about the form of the distribution they are learning.",
            "zh": "ç”Ÿæˆæ¨¡å‹å¾€å¾€å…·æœ‰æ›´é«˜çš„åå·®â€”â€”å®ƒä»¬å¯¹æ­£åœ¨å­¦ä¹ çš„åˆ†å¸ƒå½¢å¼åšå‡ºæ›´å¤šçš„å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "becoming situationally fluent so that we can converse with experts in the application domain;",
            "zh": "å˜å¾—æƒ…å¢ƒæµåˆ©ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä¸åº”ç”¨é¢†åŸŸçš„ä¸“å®¶äº¤è°ˆ;"
        }
    },
    {
        "translation": {
            "en": "Any measure of central tendency is, however, just an approximation, so we must be aware of the limitations of any measure that we use.",
            "zh": "ç„¶è€Œï¼Œä»»ä½•é›†ä¸­è¶‹åŠ¿çš„åº¦é‡éƒ½åªæ˜¯ä¸€ä¸ªè¿‘ä¼¼å€¼ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»æ„è¯†åˆ°æˆ‘ä»¬ä½¿ç”¨çš„ä»»ä½•åº¦é‡çš„å±€é™æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "3,800",
            "zh": "3,800"
        }
    },
    {
        "translation": {
            "en": "Once a Î´ has been calculated for every neuron in the network, the backward pass has completed (and in a sense so has the backpropagation algorithm, at least insofar as the algorithm is a solution to the blame assignment problem), and we are now ready to update the weights of the network using the Î´s as part of the gradient descent weight update rule.",
            "zh": "ä¸€æ—¦è®¡ç®—äº†ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ï¼Œå‘åä¼ é€’å°±å®Œæˆäº†ï¼ˆä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œåå‘ä¼ æ’­ç®—æ³•ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œè‡³å°‘å°±è¯¥ç®—æ³•æ˜¯å½’å’åˆ†é…é—®é¢˜çš„è§£å†³æ–¹æ¡ˆè€Œè¨€ï¼‰ï¼Œæˆ‘ä»¬ç°åœ¨å‡†å¤‡ä½¿ç”¨ Î´s ä½œä¸ºæ¢¯åº¦ä¸‹é™æƒé‡æ›´æ–°è§„åˆ™çš„ä¸€éƒ¨åˆ†æ¥æ›´æ–°ç½‘ç»œçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on a set of descriptive features extracted from the loan application (e.g., AGE, OCCUPATION, and ASSETS), the model will classify potential borrowers as belonging to one of two groups: good borrowers, who will repay their loans in full; and bad borrowers, who will default on some portion of their loans.",
            "zh": "æ ¹æ®ä»è´·æ¬¾ç”³è¯·ä¸­æå–çš„ä¸€ç»„æè¿°æ€§ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œå¹´é¾„ã€èŒä¸šå’Œèµ„äº§ï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ½œåœ¨å€Ÿæ¬¾äººåˆ†ä¸ºä¸¤ç±»ï¼šè‰¯å¥½çš„å€Ÿæ¬¾äººï¼Œä»–ä»¬å°†å…¨é¢å¿è¿˜è´·æ¬¾;ä»¥åŠä¸è‰¯å€Ÿæ¬¾äººï¼Œä»–ä»¬å°†æ‹–æ¬ éƒ¨åˆ†è´·æ¬¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.12[443] lists the predictions of the trained ReLU network for each of the examples and the calculation of the sum of squared errors once training has converged.",
            "zh": "è¡¨ 8.12[443] åˆ—å‡ºäº†æ¯ä¸ªç¤ºä¾‹çš„è®­ç»ƒ ReLU ç½‘ç»œçš„é¢„æµ‹ï¼Œä»¥åŠè®­ç»ƒæ”¶æ•›åè¯¯å·®å¹³æ–¹å’Œçš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "13â€…â€…â€…Case Study: Galaxy Classification",
            "zh": "13 æ¡ˆä¾‹ç ”ç©¶ï¼šæ˜Ÿç³»åˆ†ç±»"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection terminates when no accessible feature subset is better than or as good as the current subset.",
            "zh": "å½“æ²¡æœ‰å¯è®¿é—®çš„ç‰¹å¾å­é›†ä¼˜äºæˆ–ä¸å½“å‰å­é›†ä¸€æ ·å¥½æ—¶ï¼Œå‘åé¡ºåºé€‰æ‹©ç»ˆæ­¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "Palaniappan, Sellappan, and Rafiah Awang. 2008. Intelligent heart disease prediction system using data mining techniques. International Journal of Computer Science and Network Security 8 (8): 343â€“350.",
            "zh": "Palaniappanã€Sellappan å’Œ Rafiah Awangã€‚2008. åŸºäºæ•°æ®æŒ–æ˜æŠ€æœ¯çš„æ™ºèƒ½å¿ƒè„ç—…é¢„æµ‹ç³»ç»Ÿ.å›½é™…è®¡ç®—æœºç§‘å­¦ä¸ç½‘ç»œå®‰å…¨æ‚å¿— 8 ï¼ˆ8ï¼‰ï¼š343â€“350ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.8",
            "zh": "è¡¨ 5.8"
        }
    },
    {
        "translation": {
            "en": "There are many excellent books on linear algebra; one of the standard textbooks on the topic is (Strang, 2016).",
            "zh": "æœ‰è®¸å¤šå…³äºçº¿æ€§ä»£æ•°çš„ä¼˜ç§€ä¹¦ç±;å…³äºè¯¥ä¸»é¢˜çš„æ ‡å‡†æ•™ç§‘ä¹¦ä¹‹ä¸€æ˜¯ï¼ˆStrangï¼Œ2016ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the z values, activations, and Î´s have a relatively similar distribution across each of the layers of the network; that is, the training of the network is not suffering from either exploding z values (which would saturate activation functions if they were used) or exploding or vanishing Î´s.",
            "zh": "è¯·æ³¨æ„ï¼Œz å€¼ã€æ¿€æ´»å€¼å’Œ Î´ åœ¨ç½‘ç»œçš„æ¯ä¸ªå±‚ä¸­å…·æœ‰ç›¸å¯¹ç›¸ä¼¼çš„åˆ†å¸ƒ;ä¹Ÿå°±æ˜¯è¯´ï¼Œç½‘ç»œçš„è®­ç»ƒæ—¢ä¸ä¼šå—åˆ°çˆ†ç‚¸ z å€¼ï¼ˆå¦‚æœä½¿ç”¨å®ƒä»¬ä¼šä½¿æ¿€æ´»å‡½æ•°é¥±å’Œï¼‰æˆ–çˆ†ç‚¸æˆ–æ¶ˆå¤± Î´ çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this simple example no cluster reassignments are made at the third iteration, and so the process is considered to have converged.",
            "zh": "åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œåœ¨ç¬¬ä¸‰æ¬¡è¿­ä»£æ—¶æ²¡æœ‰è¿›è¡Œé›†ç¾¤é‡æ–°åˆ†é…ï¼Œå› æ­¤è¯¥è¿‡ç¨‹è¢«è§†ä¸ºå·²æ”¶æ•›ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can intuitively see from Figure C.2(b)[767] for f(x) = x2 that the rate of change of the value of this function is likely to be high at the steep edges of the curve and low at the bottom (imagine a ball rolling around inside this shape!).",
            "zh": "æˆ‘ä»¬å¯ä»¥ä»å›¾ C.2ï¼ˆbï¼‰[767] ä¸­ç›´è§‚åœ°çœ‹åˆ°ï¼Œå½“ fï¼ˆxï¼‰ = x2 æ—¶ï¼Œè¯¥å‡½æ•°å€¼çš„å˜åŒ–ç‡å¯èƒ½åœ¨æ›²çº¿çš„é™¡å³­è¾¹ç¼˜å¾ˆé«˜ï¼Œåœ¨åº•éƒ¨å¾ˆä½ï¼ˆæƒ³è±¡ä¸€ä¸ªçƒåœ¨è¿™ä¸ªå½¢çŠ¶å†…æ»šåŠ¨ï¼"
        }
    },
    {
        "translation": {
            "en": "(c) What is the maximum possible entropy in bits for a set of eight Scrabble pieces?",
            "zh": "ï¼ˆcï¼‰ ä¸€ç»„å…«ä¸ªæ‹¼å­—æ¸¸æˆæ£‹å­çš„æœ€å¤§å¯èƒ½ç†µæ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Several important rules in probability theory allow us to compute new probabilities in terms of previously computed probabilities.",
            "zh": "æ¦‚ç‡è®ºä¸­çš„å‡ ä¸ªé‡è¦è§„åˆ™å…è®¸æˆ‘ä»¬æ ¹æ®å…ˆå‰è®¡ç®—çš„æ¦‚ç‡æ¥è®¡ç®—æ–°çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Caruana and Niculescu-Mizil (2006) and Caruana et al.",
            "zh": "Caruanaå’ŒNiculescu-Mizilï¼ˆ2006å¹´ï¼‰å’ŒCaruanaç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "A multivariate linear regression model has been built to predict the heating load in a residential building on the basis of a set of descriptive features describing the characteristics of the building.",
            "zh": "å»ºç«‹äº†ä¸€ä¸ªå¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œæ ¹æ®ä¸€ç»„æè¿°å»ºç­‘ç‰©ç‰¹å¾çš„æè¿°æ€§ç‰¹å¾æ¥é¢„æµ‹ä½å®…å»ºç­‘ç‰©çš„ä¾›çƒ­è´Ÿè·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another advantage is that pruning often increases the accuracy of the trees when there is noise in the training dataset.",
            "zh": "å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯ï¼Œå½“è®­ç»ƒæ•°æ®é›†ä¸­å­˜åœ¨å™ªå£°æ—¶ï¼Œä¿®å‰ªé€šå¸¸ä¼šæé«˜æ ‘æœ¨çš„å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "PDF, 269",
            "zh": "PDFæ ¼å¼ï¼Œ 269"
        }
    },
    {
        "translation": {
            "en": "The input to all three of these gates is the vector of hidden state activations propagated forward from the previous time-step htâˆ’1 concatenated with the current input vector xt. In Figure 8.40[509] this concatenation is depicted by the intersection of the htâˆ’1 and xt lines in the bottom-left corner of the figure. We use the term hxt to write the vector that is the result of concatenating htâˆ’1 with xt. For example, if htâˆ’1 = [a,b] and xt = [c,d], then hxt = [a,b,c,d].",
            "zh": "æ‰€æœ‰è¿™ä¸‰ä¸ªé—¨çš„è¾“å…¥éƒ½æ˜¯ä»ä¸å½“å‰è¾“å…¥å‘é‡ xt è¿æ¥çš„å‰ä¸€ä¸ªæ—¶é—´æ­¥é•¿ htâˆ’1 å‘å‰ä¼ æ’­çš„éšè—çŠ¶æ€æ¿€æ´»å‘é‡ã€‚åœ¨å›¾8.40[509]ä¸­ï¼Œè¿™ç§ä¸²è”ç”±å›¾å·¦ä¸‹è§’çš„htâˆ’1å’Œxtçº¿çš„äº¤ç‚¹è¡¨ç¤ºã€‚æˆ‘ä»¬ä½¿ç”¨æœ¯è¯­ hxt æ¥ç¼–å†™å‘é‡ï¼Œå®ƒæ˜¯å°† htâˆ’1 ä¸ xt è¿æ¥èµ·æ¥çš„ç»“æœã€‚ä¾‹å¦‚ï¼Œå¦‚æœ htâˆ’1 = [aï¼Œb] å’Œ xt = [cï¼Œd]ï¼Œåˆ™ hxt = [aï¼Œbï¼Œcï¼Œd]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that consistency with the dataset is not an adequate criterion to select the best prediction model, which criteria should we use?",
            "zh": "é‰´äºä¸æ•°æ®é›†çš„ä¸€è‡´æ€§ä¸æ˜¯é€‰æ‹©æœ€ä½³é¢„æµ‹æ¨¡å‹çš„å……åˆ†æ ‡å‡†ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªäº›æ ‡å‡†ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "EFFECTIVETAXRATE",
            "zh": "æœ‰æ•ˆç¨ç‡"
        }
    },
    {
        "translation": {
            "en": "This chapter covers a range of approaches for evaluating the performance of prediction models.",
            "zh": "æœ¬ç« ä»‹ç»äº†è¯„ä¼°é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„ä¸€ç³»åˆ—æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts by initializing the Q values for every action in every state to the same values used before, shown in Table 11.3[661].",
            "zh": "è¯¥ç®—æ³•é¦–å…ˆå°†æ¯ä¸ªçŠ¶æ€ä¸‹æ¯ä¸ªåŠ¨ä½œçš„ Q å€¼åˆå§‹åŒ–ä¸ºä¹‹å‰ä½¿ç”¨çš„ç›¸åŒå€¼ï¼Œå¦‚è¡¨ 11.3[661] æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "CPI is the Corruption Perception Index (CPI), and it is the target feature. The CPI measures the perceived level of corruption in the public sector of a country and ranges from 0 (highly corrupt) to 100 (very clean).",
            "zh": "CPI æ˜¯æ¸…å»‰æŒ‡æ•° ï¼ˆCPIï¼‰ï¼Œå®ƒæ˜¯ç›®æ ‡ç‰¹å¾ã€‚CPIè¡¡é‡ä¸€ä¸ªå›½å®¶å…¬å…±éƒ¨é—¨çš„è…è´¥ç¨‹åº¦ï¼ŒèŒƒå›´ä»0ï¼ˆé«˜åº¦è…è´¥ï¼‰åˆ°100ï¼ˆéå¸¸å¹²å‡€ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.10",
            "zh": "è¡¨ 7.10"
        }
    },
    {
        "translation": {
            "en": "However, the forward propagation through the network still occurs along an active path through Neuron 5.",
            "zh": "ç„¶è€Œï¼Œé€šè¿‡ç½‘ç»œçš„å‰å‘ä¼ æ’­ä»ç„¶æ²¿ç€é€šè¿‡ç¥ç»å…ƒ 5 çš„æ´»åŠ¨è·¯å¾„å‘ç”Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "This is done by assigning a portion of the Î´ of each output neuron to each of the hidden neurons connecting to it.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†æ¯ä¸ªè¾“å‡ºç¥ç»å…ƒçš„ä¸€éƒ¨åˆ†Î´åˆ†é…ç»™è¿æ¥åˆ°å®ƒçš„æ¯ä¸ªéšè—ç¥ç»å…ƒæ¥å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "More challenging, there is the assumption that the company has the capacity to contact members based on this analysis and can design a way to discuss this issue with customers highlighted as likely to commit fraud without damaging the customer relationship so badly as to lose the customer.",
            "zh": "æ›´å…·æŒ‘æˆ˜æ€§çš„æ˜¯ï¼Œå‡è®¾å…¬å¸æœ‰èƒ½åŠ›æ ¹æ®è¿™ç§åˆ†æè”ç³»æˆå‘˜ï¼Œå¹¶å¯ä»¥è®¾è®¡ä¸€ç§æ–¹æ³•æ¥ä¸å¯èƒ½è¿›è¡Œæ¬ºè¯ˆçš„å®¢æˆ·è®¨è®ºè¿™ä¸ªé—®é¢˜ï¼Œè€Œä¸ä¼šä¸¥é‡æŸå®³å®¢æˆ·å…³ç³»ä»¥è‡´å¤±å»å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Letâ€™s look at an example.",
            "zh": "è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mappings: Mappings are used to convert continuous features into categorical features and are often used to reduce the number of unique values that a model will have to deal with. For example, rather than using a continuous feature measuring salary, we might instead map the salary values to low, medium, and high levels to create a categorical feature.",
            "zh": "æ˜ å°„ï¼šæ˜ å°„ç”¨äºå°†è¿ç»­ç‰¹å¾è½¬æ¢ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œé€šå¸¸ç”¨äºå‡å°‘æ¨¡å‹å¿…é¡»å¤„ç†çš„å”¯ä¸€å€¼çš„æ•°é‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†å·¥èµ„å€¼æ˜ å°„åˆ°ä½ã€ä¸­å’Œé«˜çº§åˆ«ï¼Œä»¥åˆ›å»ºåˆ†ç±»ç‰¹å¾ï¼Œè€Œä¸æ˜¯ä½¿ç”¨è¿ç»­ç‰¹å¾æ¥è¡¡é‡å·¥èµ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We calculate the correlation between two features by dividing the covariance between the two features by the product of their standard deviations.",
            "zh": "æˆ‘ä»¬é€šè¿‡å°†ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„åæ–¹å·®é™¤ä»¥å®ƒä»¬çš„æ ‡å‡†å·®ä¹˜ç§¯æ¥è®¡ç®—ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Over-sampling addresses the same issue as under-sampling but in the opposite way around.",
            "zh": "è¿‡é‡‡æ ·ä¸é‡‡æ ·ä¸è¶³è§£å†³ç›¸åŒçš„é—®é¢˜ï¼Œä½†æ–¹å¼ç›¸åã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Albert Einstein",
            "zh": "â€”â€”é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦"
        }
    },
    {
        "translation": {
            "en": "McCandlish, Sam, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. 2018. An empirical model of large-batch training. CoRR abs/1812.06162. http://arxiv.org/abs/1812.06162.",
            "zh": "McCandlishã€Samã€Jared Kaplanã€Dario Amodei å’Œ OpenAI Dota å›¢é˜Ÿã€‚2018. å¤§æ‰¹é‡è®­ç»ƒçš„ç»éªŒæ¨¡å‹.CoRR abs/1812.06162ã€‚http://arxiv.org/abs/1812.06162ã€‚"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that if a neuron uses a logistic activation function, then we can train the neuron in the same way that we train a logistic regression function: using the gradient descent algorithm (introduced in Chapter 7[311]) and with the weight update rule defined in Equation (7.33)[346].",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªç»“æœæ˜¯ï¼Œå¦‚æœç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç”¨ä¸è®­ç»ƒé€»è¾‘å›å½’å‡½æ•°ç›¸åŒçš„æ–¹å¼è®­ç»ƒç¥ç»å…ƒï¼šä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆåœ¨ç¬¬ 7 ç« [311]ä¸­ä»‹ç»ï¼‰å’Œæ–¹ç¨‹ ï¼ˆ7.33ï¼‰[346] ä¸­å®šä¹‰çš„æƒé‡æ›´æ–°è§„åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The disadvantage of this, however, is that these types of measures by themselves are not sufficient to judge whether a model is making accurate predictions without deep knowledge of a domain.",
            "zh": "ç„¶è€Œï¼Œè¿™æ ·åšçš„ç¼ºç‚¹æ˜¯ï¼Œè¿™äº›ç±»å‹çš„åº¦é‡æœ¬èº«ä¸è¶³ä»¥åˆ¤æ–­æ¨¡å‹æ˜¯å¦åœ¨æ²¡æœ‰æ·±å…¥äº†è§£é¢†åŸŸçš„æƒ…å†µä¸‹åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "To intuitively understand the weight update rule given in Equation (7.17)[327], it helps to think in terms of what the weight update rule does to weights based on the error in the predictions made by the current candidate model:",
            "zh": "ä¸ºäº†ç›´è§‚åœ°ç†è§£ç­‰å¼ï¼ˆ7.17ï¼‰[327]ä¸­ç»™å‡ºçš„æƒé‡æ›´æ–°è§„åˆ™ï¼Œæ ¹æ®å½“å‰å€™é€‰æ¨¡å‹çš„é¢„æµ‹è¯¯å·®ï¼Œæ€è€ƒæƒé‡æ›´æ–°è§„åˆ™å¯¹æƒé‡çš„ä½œç”¨æ˜¯æœ‰å¸®åŠ©çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "This result is contrary to the conclusion drawn from classification accuracy but is more appropriate in this case due to the target level imbalance present in the data.",
            "zh": "è¿™ä¸€ç»“æœä¸ä»åˆ†ç±»å‡†ç¡®æ€§å¾—å‡ºçš„ç»“è®ºç›¸åï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹æ›´åˆé€‚ï¼Œå› ä¸ºæ•°æ®ä¸­å­˜åœ¨ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Imagine that we are dealers in rare whiskey, and we would like some assistance in setting the reserve price for bottles of whiskey that we are selling at auction.",
            "zh": "æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æ˜¯ç¨€æœ‰å¨å£«å¿Œçš„ç»é”€å•†ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ä¸ºæˆ‘ä»¬åœ¨æ‹å–ä¼šä¸Šå‡ºå”®çš„å¨å£«å¿Œç“¶è®¾å®šåº•ä»·æ–¹é¢å¾—åˆ°ä¸€äº›å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we recommended the use of harmonic mean over arithmetic mean when calculating average class accuracy, we recommend the use of root mean squared error over mean absolute error because it is better to be pessimistic when estimating the performance of models.",
            "zh": "ç”±äºæˆ‘ä»¬å»ºè®®åœ¨è®¡ç®—å¹³å‡ç±»å‡†ç¡®ç‡æ—¶ä½¿ç”¨è°ƒå’Œå‡å€¼è€Œä¸æ˜¯ç®—æœ¯å¹³å‡å€¼ï¼Œå› æ­¤æˆ‘ä»¬å»ºè®®ä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®è€Œä¸æ˜¯å¹³å‡ç»å¯¹è¯¯å·®ï¼Œå› ä¸ºåœ¨ä¼°è®¡æ¨¡å‹æ€§èƒ½æ—¶æœ€å¥½ä¿æŒæ‚²è§‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "A model could be built to predict the overall value that AT was likely to receive from a particular customer over the personâ€™s entire customer lifecycle.",
            "zh": "å¯ä»¥å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ATåœ¨ä¸ªäººçš„æ•´ä¸ªå®¢æˆ·ç”Ÿå‘½å‘¨æœŸä¸­å¯èƒ½ä»ç‰¹å®šå®¢æˆ·é‚£é‡Œè·å¾—çš„æ€»ä½“ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are also the only two rows that fulfill the conditions of the second term in the chain sequence, P(f | h,m).",
            "zh": "è¿™ä¹Ÿæ˜¯æ»¡è¶³é“¾åºåˆ—ä¸­ç¬¬äºŒé¡¹æ¡ä»¶çš„ä»…æœ‰çš„ä¸¤è¡Œï¼ŒPï¼ˆf | hï¼Œmï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equations (7.11)[324] to (7.14)[324] step through the derivation of the rate of change of the error of a model (in that case, a linear regression model) for a single input example d with respect to changes in one of the modelâ€™s weights âˆ‚L2(ğ•„w, d)/âˆ‚w[j], resulting in",
            "zh": "æ–¹ç¨‹ï¼ˆ7.11ï¼‰[324]è‡³ï¼ˆ7.14ï¼‰[324]é€æ­¥æ¨å¯¼äº†å•ä¸ªè¾“å…¥ç¤ºä¾‹dçš„æ¨¡å‹ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œçº¿æ€§å›å½’æ¨¡å‹ï¼‰çš„è¯¯å·®å˜åŒ–ç‡ï¼Œè¯¥æ¨¡å‹ç›¸å¯¹äºæ¨¡å‹æƒé‡ä¹‹ä¸€âˆ‚L2ï¼ˆMwï¼Œ dï¼‰/âˆ‚w[j]çš„å˜åŒ–ï¼Œç»“æœä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "When performing data exploration, data visualization can help enormously. In this section we describe three important data visualization techniques that can be used to visualize the values in a single feature: the bar plot, the histogram, and the box plot. For the examples throughout this section, we will use the dataset in Table A.1[750], which lists the position that each player on a school basketball team plays at and the average training expenses they accrue each month.",
            "zh": "åœ¨æ‰§è¡Œæ•°æ®æ¢ç´¢æ—¶ï¼Œæ•°æ®å¯è§†åŒ–å¯ä»¥æå¤§åœ°å¸®åŠ©ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§é‡è¦çš„æ•°æ®å¯è§†åŒ–æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯å¯ç”¨äºå¯è§†åŒ–å•ä¸ªè¦ç´ ä¸­çš„å€¼ï¼šæ¡å½¢å›¾ã€ç›´æ–¹å›¾å’Œç®±å½¢å›¾ã€‚å¯¹äºæœ¬èŠ‚ä¸­çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¡¨ A.1[750] ä¸­çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åˆ—å‡ºäº†å­¦æ ¡ç¯®çƒé˜Ÿä¸­æ¯ä¸ªçƒå‘˜æ‰€å¤„çš„ä½ç½®ä»¥åŠä»–ä»¬æ¯æœˆäº§ç”Ÿçš„å¹³å‡è®­ç»ƒè´¹ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The Theorem of Total Probability is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "5. æ€»æ¦‚ç‡å®šç†åœ¨é™„å½•B[757]çš„B.3[762]èŠ‚ä¸­æœ‰è¯¦ç»†è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "These memberships are illustrated in Figure 10.3(c)[602].",
            "zh": "è¿™äº›éš¶å±å…³ç³»å¦‚å›¾10.3ï¼ˆcï¼‰[602]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The year is 1904, and you are a research assistant working in the lab of physicist Professor RenÃ© Blondlot, at the University of Nancy, in France.",
            "zh": "è¿™ä¸€å¹´æ˜¯1904å¹´ï¼Œä½ æ˜¯æ³•å›½å—é”¡å¤§å­¦ç‰©ç†å­¦å®¶RenÃ© Blondlotæ•™æˆå®éªŒå®¤çš„ä¸€åç ”ç©¶åŠ©ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 11.2[654] shows an example action-value table for the TwentyTwos playing agent discussed in Section 11.2.3[643].",
            "zh": "è¡¨ 11.2[654] æ˜¾ç¤ºäº†ç¬¬ 11.2.3 èŠ‚[643] ä¸­è®¨è®ºçš„ TwentyTwos æ¸¸æˆä»£ç†çš„ç¤ºä¾‹æ“ä½œå€¼è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the end of the first episode the agent reached the goal cell, state 6-4, by moving left from state 6-5.",
            "zh": "åœ¨ç¬¬ä¸€é›†ç»“æŸæ—¶ï¼Œæ™ºèƒ½ä½“ä»çŠ¶æ€ 6-5 å‘å·¦ç§»åŠ¨ï¼Œåˆ°è¾¾ç›®æ ‡å•å…ƒæ ¼ï¼ŒçŠ¶æ€ 6-4ã€‚"
        }
    },
    {
        "translation": {
            "en": "variable selection, 227",
            "zh": "å˜é‡é€‰æ‹©ï¼Œ227"
        }
    },
    {
        "translation": {
            "en": "A matrix of weighted sums calculations for a layer of neurons processing a batch of examples is denoted by Z(k) where k identifies the layer.",
            "zh": "å¤„ç†ä¸€æ‰¹æ ·æœ¬çš„ç¥ç»å…ƒå±‚çš„åŠ æƒå’Œè®¡ç®—çŸ©é˜µç”¨ Zï¼ˆkï¼‰ è¡¨ç¤ºï¼Œå…¶ä¸­ k æ ‡è¯†è¯¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "If two features are unrelated, then we would expect to see the same proportion of each level of the second feature within the bars for each level of the first.",
            "zh": "å¦‚æœä¸¤ä¸ªç‰¹å¾ä¸ç›¸å…³ï¼Œé‚£ä¹ˆæˆ‘ä»¬æœŸæœ›åœ¨æ¡å½¢å›¾ä¸­çœ‹åˆ°ç¬¬äºŒä¸ªç‰¹å¾çš„æ¯ä¸ªçº§åˆ«çš„ç›¸åŒæ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Working with Kate, Ross defined an active customer as a current customer who made at least five calls per week and who had been a customer for at least six months.4 This definition ensured that the non-churn instances in the dataset would include only customers with a relatively normal behavior profile and for which there was a long enough data history that realistic descriptive features could be calculated for them.",
            "zh": "Ross ä¸ Kate åˆä½œï¼Œå°†æ´»è·ƒå®¢æˆ·å®šä¹‰ä¸ºæ¯å‘¨è‡³å°‘æ‹¨æ‰“ 5 ä¸ªç”µè¯ä¸”æˆä¸ºå®¢æˆ·è‡³å°‘ 6 ä¸ªæœˆçš„å½“å‰å®¢æˆ·ã€‚4 æ­¤å®šä¹‰ç¡®ä¿æ•°æ®é›†ä¸­çš„éæµå¤±å®ä¾‹ä»…åŒ…æ‹¬å…·æœ‰ç›¸å¯¹æ­£å¸¸è¡Œä¸ºé…ç½®æ–‡ä»¶çš„å®¢æˆ·ï¼Œå¹¶ä¸”å…·æœ‰è¶³å¤Ÿé•¿çš„æ•°æ®å†å²è®°å½•ï¼Œå¯ä»¥ä¸ºä»–ä»¬è®¡ç®—å®é™…çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "After feature selection, the classification accuracy of the models on the test set were 85.557%, 88.829%, and 87.188% for the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "ç‰¹å¾é€‰æ‹©åï¼Œkæœ€è¿‘é‚»æ¨¡å‹ã€é€»è¾‘å›å½’æ¨¡å‹å’Œæ”¯æŒå‘é‡æœºæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡åˆ†åˆ«ä¸º85.557%ã€88.829%å’Œ87.188%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fortunately, because the hyperplanes created by the k-d tree are all axis-aligned, the algorithm can test for this condition quite easily.",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œç”±äº k-d æ ‘åˆ›å»ºçš„è¶…å¹³é¢éƒ½æ˜¯è½´å¯¹é½çš„ï¼Œå› æ­¤è¯¥ç®—æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°æµ‹è¯•è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "For further discussion of the legal issues surrounding data analytics, Tene and Polonetsky (2013) and Schwartz (2010) are useful. Chapter 2 of Siegel (2013) discusses the ethical issues surrounding predictive analytics.",
            "zh": "å¯¹äºå›´ç»•æ•°æ®åˆ†æçš„æ³•å¾‹é—®é¢˜çš„è¿›ä¸€æ­¥è®¨è®ºï¼ŒTene and Polonetsky ï¼ˆ2013ï¼‰ å’Œ Schwartz ï¼ˆ2010ï¼‰ æ˜¯æœ‰ç”¨çš„ã€‚Siegelï¼ˆ2013ï¼‰çš„ç¬¬2ç« è®¨è®ºäº†å›´ç»•é¢„æµ‹åˆ†æçš„ä¼¦ç†é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have also introduced decision tree models, which make predictions based on sequences of tests on the descriptive feature values of a query.",
            "zh": "æˆ‘ä»¬è¿˜å¼•å…¥äº†å†³ç­–æ ‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŸºäºå¯¹æŸ¥è¯¢çš„æè¿°æ€§ç‰¹å¾å€¼çš„æµ‹è¯•åºåˆ—è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.21â€…â€…â€…A selection of the models developed during the gradient descent process for the customer group dataset from Table 7.11[359]. Squares represent instances with the single target level, triangles the business level, and crosses the family level. The bottom-right panel illustrates the overall decision boundaries between the three target levels.",
            "zh": "7.21 è¡¨7.11[359]ä¸­å®¢æˆ·ç»„æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚æ­£æ–¹å½¢è¡¨ç¤ºå…·æœ‰å•ä¸ªç›®æ ‡çº§åˆ«çš„å®ä¾‹ï¼Œä¸‰è§’å½¢è¡¨ç¤ºä¸šåŠ¡çº§åˆ«ï¼Œå¹¶è·¨ç³»åˆ—çº§åˆ«ã€‚å³ä¸‹è§’çš„é¢æ¿è¯´æ˜äº†ä¸‰ä¸ªç›®æ ‡çº§åˆ«ä¹‹é—´çš„æ€»ä½“å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "This phenomenon is often referred to as concept drift.",
            "zh": "è¿™ç§ç°è±¡é€šå¸¸è¢«ç§°ä¸ºæ¦‚å¿µæ¼‚ç§»ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we allowed this to happen, then our model will be affected by accidental data collection factors, such as the units used to measure something.",
            "zh": "å¦‚æœæˆ‘ä»¬å…è®¸è¿™ç§æƒ…å†µå‘ç”Ÿï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„æ¨¡å‹å°†å—åˆ°æ„å¤–æ•°æ®æ”¶é›†å› ç´ çš„å½±å“ï¼Œä¾‹å¦‚ç”¨äºæµ‹é‡æŸç‰©çš„å•ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "This approach to finding weights is known as least squares optimization.",
            "zh": "è¿™ç§æŸ¥æ‰¾æƒé‡çš„æ–¹æ³•ç§°ä¸ºæœ€å°äºŒä¹˜ä¼˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "This will ensure that the agent never takes potentially dangerous random actions but limits the ability of an agent to continue to learn after being deployed, which could be useful if aspects of the environment changed over time.18",
            "zh": "è¿™å°†ç¡®ä¿ä»£ç†æ°¸è¿œä¸ä¼šé‡‡å–å…·æœ‰æ½œåœ¨å±é™©çš„éšæœºæ“ä½œï¼Œä½†ä¼šé™åˆ¶ä»£ç†åœ¨éƒ¨ç½²åç»§ç»­å­¦ä¹ çš„èƒ½åŠ›ï¼Œå¦‚æœç¯å¢ƒçš„å„ä¸ªæ–¹é¢éšæ—¶é—´å˜åŒ–ï¼Œè¿™å¯èƒ½å¾ˆæœ‰ç”¨18ã€‚"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the customerâ€™s bill has changed from last month to this month",
            "zh": "å®¢æˆ·è´¦å•ä»ä¸Šä¸ªæœˆåˆ°æœ¬æœˆçš„å˜åŒ–ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "The target level in square brackets at each interior node in the tree shows the majority target level for the data partition at that node.",
            "zh": "æ ‘ä¸­æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹çš„æ–¹æ‹¬å·ä¸­çš„ç›®æ ‡çº§åˆ«æ˜¾ç¤ºè¯¥èŠ‚ç‚¹ä¸Šæ•°æ®åˆ†åŒºçš„å¤šæ•°ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Suggestions for further reading are given at the end of the chapter.",
            "zh": "æœ¬ç« æœ«å°¾ç»™å‡ºäº†è¿›ä¸€æ­¥é˜…è¯»çš„å»ºè®®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the McCulloch and Pitts model the weights were manually set, but subsequently in this chapter we explain how these weights can be learned from data using backpropagation.",
            "zh": "åœ¨ McCulloch å’Œ Pitts æ¨¡å‹ä¸­ï¼Œæƒé‡æ˜¯æ‰‹åŠ¨è®¾ç½®çš„ï¼Œä½†éšååœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è§£é‡Šå¦‚ä½•ä½¿ç”¨åå‘ä¼ æ’­ä»æ•°æ®ä¸­å­¦ä¹ è¿™äº›æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on a recent evaluation of historical performance, AT management believed at the time of this project that their current system for identifying likely churners had an accuracy of approximately 60%, so any newly developed system would have to perform considerably better than this to be deemed worthwhile.",
            "zh": "æ ¹æ®æœ€è¿‘å¯¹å†å²æ€§èƒ½çš„è¯„ä¼°ï¼ŒATç®¡ç†å±‚åœ¨è¿›è¡Œè¯¥é¡¹ç›®æ—¶è®¤ä¸ºï¼Œä»–ä»¬ç›®å‰ç”¨äºè¯†åˆ«æ½œåœ¨æµå¤±è€…çš„ç³»ç»Ÿå‡†ç¡®ç‡çº¦ä¸º60%ï¼Œå› æ­¤ä»»ä½•æ–°å¼€å‘çš„ç³»ç»Ÿéƒ½å¿…é¡»æ¯”è¿™æ€§èƒ½å¥½å¾—å¤šï¼Œæ‰è¢«è®¤ä¸ºæ˜¯å€¼å¾—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "They give us a quick overview of all the levels in the domain of each categorical feature and the frequencies of these levels.",
            "zh": "å®ƒä»¬ä¸ºæˆ‘ä»¬æä¾›äº†æ¯ä¸ªåˆ†ç±»ç‰¹å¾åŸŸä¸­çš„æ‰€æœ‰æ°´å¹³ä»¥åŠè¿™äº›æ°´å¹³çš„é¢‘ç‡çš„å¿«é€Ÿæ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second segment in Table 8.15[471] lists e raised to the power of the corresponding logit (eli) and also the per example sum of these values (âˆ‘ieli).",
            "zh": "è¡¨ 8.15[471] ä¸­çš„ç¬¬äºŒæ®µåˆ—å‡ºäº† e çš„å¹‚ logit ï¼ˆeliï¼‰ ä»¥åŠè¿™äº›å€¼ ï¼ˆâˆ‘ieliï¼‰ çš„æ¯æ¬¡ç¤ºä¾‹æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of summing out is a key concept in probability-based prediction.",
            "zh": "æ€»ç»“è¿‡ç¨‹æ˜¯åŸºäºæ¦‚ç‡çš„é¢„æµ‹ä¸­çš„ä¸€ä¸ªå…³é”®æ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "9.16â€…â€…â€…Tabulating the workings required to calculate gain, cumulative gain, lift, and cumulative lift for the data given in Table 9.11[557].",
            "zh": "9.16 å°†è®¡ç®—è¡¨9.11[557]ä¸­ç»™å‡ºçš„æ•°æ®çš„å¢ç›Šã€ç´¯ç§¯å¢ç›Šã€å‡åŠ›å’Œç´¯ç§¯å‡åŠ›æ‰€éœ€çš„å·¥ä½œåˆ¶æˆè¡¨æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ABT for the motor insurance claims fraud detection solution.",
            "zh": "ç”¨äºæ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹è§£å†³æ–¹æ¡ˆçš„ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "There are just two continuous features in this dataset, DOSE1 and DOSE2 (both normalized to the range (âˆ’1,1) using range normalization), and two target levels, dangerous and safe.",
            "zh": "è¯¥æ•°æ®é›†ä¸­åªæœ‰ä¸¤ä¸ªè¿ç»­ç‰¹å¾ï¼ŒDOSE1 å’Œ DOSE2ï¼ˆå‡ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–å½’ä¸€åŒ–å½’ä¸€åŒ–åˆ°èŒƒå›´ ï¼ˆâˆ’1,1ï¼‰ï¼Œä»¥åŠä¸¤ä¸ªç›®æ ‡æ°´å¹³ï¼Œå±é™©å’Œå®‰å…¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout this book we discuss the many different ways we can use machine learning techniques to build predictive data analytics models. In these discussions we do not refer to specific tools or implementations of these techniques. There are, however, many different, easy-to-use options for implementing machine learning models that interested readers can use to follow along with the examples in this book.",
            "zh": "åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä½¿ç”¨æœºå™¨å­¦ä¹ æŠ€æœ¯æ„å»ºé¢„æµ‹æ€§æ•°æ®åˆ†ææ¨¡å‹çš„å¤šç§ä¸åŒæ–¹æ³•ã€‚åœ¨è¿™äº›è®¨è®ºä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰æåˆ°è¿™äº›æŠ€æœ¯çš„å…·ä½“å·¥å…·æˆ–å®ç°ã€‚ä½†æ˜¯ï¼Œæœ‰è®¸å¤šä¸åŒçš„ã€æ˜“äºä½¿ç”¨çš„é€‰é¡¹å¯ç”¨äºå®ç°æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥ä½¿ç”¨è¿™äº›é€‰é¡¹æ¥éµå¾ªæœ¬ä¹¦ä¸­çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4â€…â€…â€…Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "4.4 è¡¨4.3[136]ä¸­æ•°æ®é›†çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "hypercube, 224",
            "zh": "è¶…ç«‹æ–¹ä½“ï¼Œ224"
        }
    },
    {
        "translation": {
            "en": "Gwiazda, J., E. Ong, R. Held, and F. Thorn. 2000. Vision: Myopia and ambient night-time lighting. Nature 404 (6774): 144â€“144. http://dx.doi.org/10.1038/35004663.",
            "zh": "Gwiazdaï¼Œ J.ï¼Œ E. Ongï¼Œ R. Heldï¼Œ å’Œ F. Thorn.2000. è§†è§‰ï¼šè¿‘è§†å’Œå¤œé—´ç¯å¢ƒç…§æ˜ã€‚è‡ªç„¶404ï¼ˆ6774ï¼‰ï¼š144-144ã€‚http://dx.doi.org/10.1038/35004663ã€‚"
        }
    },
    {
        "translation": {
            "en": "It has been shown that there is no particular inductive bias that on average is the best one to use.10 Also, in general, there is no way of knowing for a given predictive task which inductive bias will work best.",
            "zh": "10 æ­¤å¤–ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œå¯¹äºç»™å®šçš„é¢„æµ‹ä»»åŠ¡ï¼Œæ²¡æœ‰åŠæ³•çŸ¥é“å“ªç§å½’çº³åå·®æ•ˆæœæœ€å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recurrent neural networks (RNN) are designed to process this type of data.",
            "zh": "é€’å½’ç¥ç»ç½‘ç»œ ï¼ˆRNNï¼‰ æ—¨åœ¨å¤„ç†æ­¤ç±»æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Or it may be that the features in the dataset are continuousâ€”typically indicating that a Minkowski distance metric is appropriateâ€”but that the majority of the descriptive features for each instance have zero values,25 in which case we may want to use a similarity index that ignores descriptive features with zero values in both features, for example, cosine similarity.",
            "zh": "æˆ–è€…ï¼Œæ•°æ®é›†ä¸­çš„ç‰¹å¾å¯èƒ½æ˜¯è¿ç»­çš„ï¼ˆé€šå¸¸è¡¨ç¤ºé—µå¯å¤«æ–¯åŸºè·ç¦»åº¦é‡æ˜¯åˆé€‚çš„ï¼‰ï¼Œä½†æ¯ä¸ªå®ä¾‹çš„å¤§å¤šæ•°æè¿°æ€§ç‰¹å¾çš„å€¼ä¸ºé›¶ï¼Œ25åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ä½¿ç”¨ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œè¯¥æŒ‡æ•°å¿½ç•¥ä¸¤ä¸ªç‰¹å¾ä¸­å€¼ä¸ºé›¶çš„æè¿°æ€§ç‰¹å¾ï¼Œ ä¾‹å¦‚ï¼Œä½™å¼¦ç›¸ä¼¼åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, a model is likely to overfit the data for any query where one or more of the evidence events match the conditioned event of one of these zero probabilities.",
            "zh": "å› æ­¤ï¼Œå¯¹äºä»»ä½•æŸ¥è¯¢ï¼Œå¦‚æœä¸€ä¸ªæˆ–å¤šä¸ªè¯æ®äº‹ä»¶ä¸è¿™äº›é›¶æ¦‚ç‡ä¹‹ä¸€çš„æ¡ä»¶äº‹ä»¶åŒ¹é…ï¼Œåˆ™æ¨¡å‹å¯èƒ½ä¼šå¯¹æ•°æ®è¿›è¡Œè¿‡æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This gradient is given by",
            "zh": "è¯¥æ¢¯åº¦ç”±ä¸‹å¼ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "(a) A 3D surface plot and (b) a birdâ€™s-eye view contour plot of the error surface generated by plotting the sum of squared errors for the office rentals training set for each possible combination of values for w[0] (from the range [âˆ’10,20]) and w[1] (from the range [âˆ’2,3]).",
            "zh": "ï¼ˆaï¼‰ 3D æ›²é¢å›¾å’Œ ï¼ˆbï¼‰ è¯¯å·®æ›²é¢çš„é¸Ÿç°å›¾ï¼Œè¯¥å›¾é€šè¿‡ç»˜åˆ¶ w[0]ï¼ˆèŒƒå›´ [âˆ’10,20]ï¼‰å’Œ w[1]ï¼ˆèŒƒå›´ [âˆ’2,3]ï¼‰çš„æ¯ç§å¯èƒ½å€¼ç»„åˆçš„åŠå…¬å®¤ç§Ÿèµè®­ç»ƒé›†çš„å¹³æ–¹è¯¯å·®æ€»å’Œç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the following query instances.",
            "zh": "ä½¿ç”¨æ­¤æ¨¡å‹å¯¹ä»¥ä¸‹æ¯ä¸ªæŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The tree shown in Figure 12.5[699] is reasonably straightforward to interpret, but when taken out to other parts of the business, it may be hard for people to deal with this much information, so Ross decided to create a purposefully stunted version of the decision tree, with only a small number of levels shown for the presentation of the model to the business (although he intended to use the larger pruned tree for actual deployment).",
            "zh": "å›¾ 12.5[699] ä¸­æ‰€ç¤ºçš„æ ‘ç›¸å½“å®¹æ˜“è§£é‡Šï¼Œä½†æ˜¯å½“è¢«å¸¦åˆ°ä¸šåŠ¡çš„å…¶ä»–éƒ¨åˆ†æ—¶ï¼Œäººä»¬å¯èƒ½å¾ˆéš¾å¤„ç†è¿™ä¹ˆå¤šä¿¡æ¯ï¼Œå› æ­¤ Ross å†³å®šåˆ›å»ºå†³ç­–æ ‘çš„æ•…æ„å‘è‚²ä¸è‰¯ç‰ˆæœ¬ï¼Œåªæ˜¾ç¤ºå°‘é‡çº§åˆ«ä»¥å‘ä¸šåŠ¡éƒ¨é—¨å±•ç¤ºæ¨¡å‹ï¼ˆå°½ç®¡ä»–æ‰“ç®—ä½¿ç”¨æ›´å¤§çš„ä¿®å‰ªæ ‘æ¥å®é™…deploymentï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "data analytics, 3",
            "zh": "æ•°æ®åˆ†æï¼Œ 3"
        }
    },
    {
        "translation": {
            "en": "3. This data has been artificially generated for this example.",
            "zh": "3. æ­¤æ•°æ®æ˜¯é’ˆå¯¹æ­¤ç¤ºä¾‹äººå·¥ç”Ÿæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.3â€…â€…â€…Choosing Learning Rates and Initial Weights",
            "zh": "7.3.3 é€‰æ‹©å­¦ä¹ ç‡å’Œåˆå§‹æƒé‡"
        }
    },
    {
        "translation": {
            "en": "9.21â€…â€…â€…Calculating the stability index for the bacterial species identification problem given new test data for two periods after model deployment.",
            "zh": "9.21 è®¡ç®—æ¨¡å‹éƒ¨ç½²åä¸¤ä¸ªæ—¶æœŸçš„æ–°æµ‹è¯•æ•°æ®ä¸‹ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜çš„ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Be aware of the relationships between features in an ABT.",
            "zh": "1. æ³¨æ„ ABT ä¸­ç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. This is captured in Suttonâ€™s reward hypothesis (Sutton and Barto, 2018): â€œThat all of what we mean by goals and purposes can be well thought of as maximization of the expected value of the cumulative sum of a received scalar signal (reward).â€",
            "zh": "3. è¿™åœ¨è¨é¡¿çš„å¥–åŠ±å‡è®¾ï¼ˆè¨é¡¿å’Œå·´æ‰˜ï¼Œ2018 å¹´ï¼‰ä¸­å¾—åˆ°äº†ä½“ç°ï¼šâ€œæˆ‘ä»¬æ‰€è¯´çš„ç›®æ ‡å’Œç›®çš„çš„æ‰€æœ‰å«ä¹‰éƒ½å¯ä»¥å¾ˆå¥½åœ°è¢«è®¤ä¸ºæ˜¯æ¥æ”¶åˆ°çš„æ ‡é‡ä¿¡å·ï¼ˆå¥–åŠ±ï¼‰çš„ç´¯ç§¯æ€»å’Œçš„æœŸæœ›å€¼çš„æœ€å¤§åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "variational auto-encoders, 630",
            "zh": "å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼Œ630"
        }
    },
    {
        "translation": {
            "en": "For example, the United States Civil Rights Act of 19645 made it illegal to discriminate against a person on the basis of race, color, religion, national origin, or sex.",
            "zh": "ä¾‹å¦‚ï¼Œ19645 å¹´çš„ã€Šç¾å›½æ°‘æƒæ³•æ¡ˆã€‹è§„å®šï¼ŒåŸºäºç§æ—ã€è‚¤è‰²ã€å®—æ•™ã€å›½ç±æˆ–æ€§åˆ«æ­§è§†æŸäººæ˜¯éæ³•çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hence a neuron that uses a logistic activation function is referred to as a logistic unit, and a unit that uses the rectifier function is known as a rectified linear unit or ReLU.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒç§°ä¸ºé€»è¾‘å•å…ƒï¼Œä½¿ç”¨æ•´æµå™¨åŠŸèƒ½çš„å•å…ƒç§°ä¸ºæ•´æµçº¿æ€§å•å…ƒæˆ– ReLUã€‚"
        }
    },
    {
        "translation": {
            "en": "The out-of-time sampling process.",
            "zh": "è¶…æ—¶é‡‡æ ·è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This structural information can bias the model in such as way as to help it avoid overfitting the data.",
            "zh": "è¿™ç§ç»“æ„ä¿¡æ¯å¯ä»¥ä½¿æ¨¡å‹äº§ç”Ÿåå·®ï¼Œä»è€Œå¸®åŠ©æ¨¡å‹é¿å…è¿‡åº¦æ‹Ÿåˆæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we computed a conditional probability for the target feature using a naive Bayes model, we used the following calculation:",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹è®¡ç®—ç›®æ ‡ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»¥ä¸‹è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "These predictions can then be compared to the predictions we expected the model to make.",
            "zh": "ç„¶åï¼Œå¯ä»¥å°†è¿™äº›é¢„æµ‹ä¸æˆ‘ä»¬æœŸæœ›æ¨¡å‹åšå‡ºçš„é¢„æµ‹è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "5.1â€…â€…â€…A feature space plot of the college athlete data in Table 5.2[183].",
            "zh": "5.1 è¡¨5.2[183]ä¸­å¤§å­¦è¿åŠ¨å‘˜æ•°æ®çš„ç‰¹å¾ç©ºé—´å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice how the orientation of the axes and the scaling of the distance contours are consistent across the figures.",
            "zh": "è¯·æ³¨æ„ï¼Œè½´çš„æ–¹å‘å’Œè·ç¦»ç­‰å€¼çº¿çš„ç¼©æ”¾åœ¨å„å›¾å½¢ä¸­æ˜¯ä¸€è‡´çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each cell in a confusion matrix represents one of these outcomes (TP, TN, FP, FN) and counts the number of times this outcome occurred when the test dataset was presented to the model.",
            "zh": "æ··æ·†çŸ©é˜µä¸­çš„æ¯ä¸ªå•å…ƒæ ¼è¡¨ç¤ºè¿™äº›ç»“æœä¹‹ä¸€ï¼ˆTPã€TNã€FPã€FNï¼‰ï¼Œå¹¶è®¡ç®—å°†æµ‹è¯•æ•°æ®é›†å‘ˆç°ç»™æ¨¡å‹æ—¶å‡ºç°æ­¤ç»“æœçš„æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "After taking the action, instead of performing a single step of stochastic gradient descent, the agent randomly selects a random sample of b instances from the replay memory, and performs an iteration of mini-batch gradient descent28 using this sample as the mini-batch.",
            "zh": "æ‰§è¡Œæ“ä½œåï¼Œä»£ç†ä¸ä¼šæ‰§è¡Œéšæœºæ¢¯åº¦ä¸‹é™çš„å•ä¸ªæ­¥éª¤ï¼Œè€Œæ˜¯ä»å›æ”¾å†…å­˜ä¸­éšæœºé€‰æ‹© b å®ä¾‹çš„éšæœºæ ·æœ¬ï¼Œå¹¶ä½¿ç”¨æ­¤æ ·æœ¬ä½œä¸ºå°æ‰¹é‡æ‰§è¡Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ 28 çš„è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "This distinction between the processing paths is why the weight matrix in Equation (8.110)[511] has a â€  in the superscript (i.e., W(iâ€ )) whereas the weight matrix in Equation (8.111)[511] has a â€¡.",
            "zh": "å¤„ç†è·¯å¾„ä¹‹é—´çš„è¿™ç§åŒºåˆ«å°±æ˜¯ä¸ºä»€ä¹ˆæ–¹ç¨‹ï¼ˆ8.110ï¼‰[511]ä¸­çš„æƒé‡çŸ©é˜µåœ¨ä¸Šæ ‡ï¼ˆå³Wï¼ˆiâ€ ï¼‰ï¼‰ä¸­å…·æœ‰â€ ï¼Œè€Œæ–¹ç¨‹ï¼ˆ8.111ï¼‰[511]ä¸­çš„æƒé‡çŸ©é˜µå…·æœ‰â€¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we backpropagate through each time-step in the unrolled network, we use the corresponding weighted sum z and activation a for a neuron at that time-step to backpropagate the error gradient for that neuron.",
            "zh": "å½“æˆ‘ä»¬åœ¨å±•å¼€çš„ç½‘ç»œä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥ä¸­åå‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸åº”çš„åŠ æƒæ€»å’Œ z å’Œæ¿€æ´»è¯¥æ—¶é—´æ­¥çš„ç¥ç»å…ƒæ¥åå‘ä¼ æ’­è¯¥ç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œWhen my information changes, I alter my conclusions. What do you do, sir?When my information changes, I alter my conclusions. What do you do, sir?â€",
            "zh": "â€œå½“æˆ‘çš„ä¿¡æ¯å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæˆ‘ä¼šæ”¹å˜æˆ‘çš„ç»“è®ºã€‚ä½ æ˜¯åšä»€ä¹ˆçš„ï¼Œå…ˆç”Ÿï¼Ÿå½“æˆ‘çš„ä¿¡æ¯å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæˆ‘ä¼šæ”¹å˜æˆ‘çš„ç»“è®ºã€‚ä½ æ˜¯åšä»€ä¹ˆçš„ï¼Œå…ˆç”Ÿï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "3.5â€…â€…â€…The data quality plan for the motor insurance fraud prediction ABT.",
            "zh": "3.5 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹ABTçš„æ•°æ®è´¨é‡è®¡åˆ’ã€‚"
        }
    },
    {
        "translation": {
            "en": "root mean squared error, 577, 578",
            "zh": "å‡æ–¹æ ¹è¯¯å·®ï¼Œ 577ï¼Œ 578"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm uses the information gain metric to choose the best feature to test at each node in the tree.",
            "zh": "ID3 ç®—æ³•ä½¿ç”¨ä¿¡æ¯å¢ç›ŠæŒ‡æ ‡æ¥é€‰æ‹©è¦åœ¨æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šæµ‹è¯•çš„æœ€ä½³ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the Î´ values you have calculated in the preceding, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., âˆ‚â„°/âˆ‚w3,2, âˆ‚â„°/âˆ‚w3,0, âˆ‚â„°/âˆ‚w2,1, âˆ‚â„°/âˆ‚w2,0).",
            "zh": "ä½¿ç”¨æ‚¨åœ¨å‰é¢è®¡ç®—çš„Î´å€¼ï¼Œè®¡ç®—ç½‘ç»œè¯¯å·®å¯¹ç½‘ç»œæ¯ä¸ªæƒé‡å˜åŒ–çš„æ•æ„Ÿæ€§ï¼ˆå³ âˆ‚E/âˆ‚w3,2ã€âˆ‚E/âˆ‚w3,0ã€âˆ‚E/âˆ‚w2,1ã€âˆ‚E/âˆ‚w2,0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Russel-Rao index, 214, 231",
            "zh": "ç½—ç´ -æ‹‰å¥¥æŒ‡æ•°ï¼Œ214,231"
        }
    },
    {
        "translation": {
            "en": "To repurpose the gradient descent algorithm for training logistic regression models, the only change that needs to be made is in the error delta function, which is used in the weight update rule given on Line 4[326] of Algorithm 4[326]. To derive this new weight update rule, imagine that there is just a single training instance, (d,t), in our training dataset. The partial derivative of the error function, L2, is then",
            "zh": "ä¸ºäº†é‡æ–°åˆ©ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹ï¼Œå”¯ä¸€éœ€è¦åšçš„æ›´æ”¹æ˜¯è¯¯å·®å¢é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°ç”¨äºç®—æ³• 4[326] çš„ç¬¬ 4 è¡Œ[326]ä¸­ç»™å‡ºçš„æƒé‡æ›´æ–°è§„åˆ™ã€‚ä¸ºäº†æ¨å¯¼å‡ºè¿™ä¸ªæ–°çš„æƒé‡æ›´æ–°è§„åˆ™ï¼Œå‡è®¾æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ä¸­åªæœ‰ä¸€ä¸ªè®­ç»ƒå®ä¾‹ ï¼ˆdï¼Œtï¼‰ã€‚è¯¯å·®å‡½æ•°çš„åå¯¼æ•° L2 ä¸º"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm is actually quite straightforward, and it is easiest to explain in the context of a prediction problem with a continuous target. Given a training dataset, ğ’Ÿ, made up of descriptive feature and target feature pairs, (d,t), the algorithm begins by training a very simple base model, ğ•„0. For problems with a continuous target, this model typically simply predicts the overall average target value from the training dataset",
            "zh": "æ¢¯åº¦æå‡ç®—æ³•å®é™…ä¸Šéå¸¸ç®€å•ï¼Œåœ¨å…·æœ‰è¿ç»­ç›®æ ‡çš„é¢„æµ‹é—®é¢˜çš„ä¸Šä¸‹æ–‡ä¸­æœ€å®¹æ˜“è§£é‡Šã€‚ç»™å®šä¸€ä¸ªç”±æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾å¯¹ ï¼ˆdï¼Œtï¼‰ ç»„æˆçš„è®­ç»ƒæ•°æ®é›† Dï¼Œè¯¥ç®—æ³•é¦–å…ˆè®­ç»ƒä¸€ä¸ªéå¸¸ç®€å•çš„åŸºç¡€æ¨¡å‹ M0ã€‚å¯¹äºå…·æœ‰è¿ç»­ç›®æ ‡çš„é—®é¢˜ï¼Œæ­¤æ¨¡å‹é€šå¸¸åªæ˜¯ä»è®­ç»ƒæ•°æ®é›†ä¸­é¢„æµ‹æ€»ä½“å¹³å‡ç›®æ ‡å€¼"
        }
    },
    {
        "translation": {
            "en": "This example illustrates the power of Bayesian networks. When complete knowledge of the state of all the nodes in the network is not available, we clamp the values of nodes that we do have knowledge of and sum out the unknown nodes. Furthermore, during these calculations, we only need to condition a node on its Markov blanket, which dramatically reduces the number of probabilities required by the network.",
            "zh": "è¿™ä¸ªä¾‹å­è¯´æ˜äº†è´å¶æ–¯ç½‘ç»œçš„å¼ºå¤§åŠŸèƒ½ã€‚å½“æ— æ³•å®Œå…¨äº†è§£ç½‘ç»œä¸­æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€æ—¶ï¼Œæˆ‘ä»¬é’³åˆ¶æˆ‘ä»¬æ‰€çŸ¥é“çš„èŠ‚ç‚¹çš„å€¼ï¼Œå¹¶æ€»ç»“å‡ºæœªçŸ¥èŠ‚ç‚¹ã€‚æ­¤å¤–ï¼Œåœ¨è¿™äº›è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨å…¶é©¬å°”å¯å¤«æ¯¯ä¸Šè°ƒèŠ‚ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿™å¤§å¤§å‡å°‘äº†ç½‘ç»œæ‰€éœ€çš„æ¦‚ç‡æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is the benefit of using a k-d tree and becomes especially apparent when datasets are very large.",
            "zh": "è¿™æ˜¯ä½¿ç”¨ k-d æ ‘çš„å¥½å¤„ï¼Œå½“æ•°æ®é›†éå¸¸å¤§æ—¶ï¼Œè¿™ä¸€ç‚¹å°¤å…¶æ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.1916",
            "zh": "-0.1916"
        }
    },
    {
        "translation": {
            "en": "Note that each line in Figure 8.40[509] represents a vector of activations, and the + symbol represents an elementwise vector addition and âŠ™ represents an elementwise vector product.",
            "zh": "è¯·æ³¨æ„ï¼Œå›¾ 8.40[509] ä¸­çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ¿€æ´»å‘é‡ï¼Œ+ ç¬¦å·è¡¨ç¤ºé€å‘é‡åŠ æ³•ï¼ŒâŠ™ è¡¨ç¤ºé€å‘é‡ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, she used a 5-target-level model to make predictions.",
            "zh": "é¦–å…ˆï¼Œå¥¹ä½¿ç”¨5ä¸ªç›®æ ‡çº§åˆ«çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in the loan scenario a ratio between salary and requested loan amount might have a much longer useful life span than the salary and loan amount values alone.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨è´·æ¬¾æ–¹æ¡ˆä¸­ï¼Œå·¥èµ„å’Œè¯·æ±‚çš„è´·æ¬¾é‡‘é¢ä¹‹é—´çš„æ¯”ç‡å¯èƒ½æ¯”å•ç‹¬çš„å·¥èµ„å’Œè´·æ¬¾é‡‘é¢å€¼å…·æœ‰æ›´é•¿çš„ä½¿ç”¨å¯¿å‘½ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.9â€…â€…â€…(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (Î±0 = 0.25, c = 100); (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "7.9 ï¼ˆaï¼‰ ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡æ—¶ï¼ŒåŠå…¬å®¤ç§Ÿèµé¢„æµ‹é—®é¢˜çš„è¯¯å·®é¢ï¼ˆÎ±0 = 0.25ï¼Œc = 100ï¼‰;ï¼ˆbï¼‰ æ­¤æ—…ç¨‹ä¸­è¯¯å·®å¹³æ–¹å’Œçš„å˜åŒ–å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weight matrices are arranged so that there is one row per set of weights per neuron in the layer.",
            "zh": "æƒé‡çŸ©é˜µçš„æ’åˆ—æ–¹å¼æ˜¯ï¼Œå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„æ¯ç»„æƒé‡éƒ½æœ‰ä¸€è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important that once a model is deployed, we put in place an ongoing model validation scheme to monitor the model to catch the point at which it begins to go stale.",
            "zh": "é‡è¦çš„æ˜¯ï¼Œä¸€æ—¦éƒ¨ç½²äº†æ¨¡å‹ï¼Œæˆ‘ä»¬å°±ä¼šå®æ–½ä¸€ä¸ªæŒç»­çš„æ¨¡å‹éªŒè¯æ–¹æ¡ˆæ¥ç›‘æ§æ¨¡å‹ï¼Œä»¥æ•æ‰å®ƒå¼€å§‹è¿‡æ—¶çš„ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the topic of converting business problems into analytics solutions, Davenport (2006) and Davenport and Kim (2013) are good business-focused sources. Levitt and Dubner (2005), Ayres (2008), Silver (2012), and Siegel (2013) all provide nice dicusssions of different applications of predictive data analytics.",
            "zh": "å…³äºå°†ä¸šåŠ¡é—®é¢˜è½¬åŒ–ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆçš„ä¸»é¢˜ï¼ŒDavenportï¼ˆ2006ï¼‰å’ŒDavenportå’ŒKimï¼ˆ2013ï¼‰æ˜¯ä»¥ä¸šåŠ¡ä¸ºä¸­å¿ƒçš„è‰¯å¥½æ¥æºã€‚Levitt å’Œ Dubner ï¼ˆ2005ï¼‰ã€Ayres ï¼ˆ2008ï¼‰ã€Silver ï¼ˆ2012ï¼‰ å’Œ Siegel ï¼ˆ2013ï¼‰ éƒ½å¯¹é¢„æµ‹æ•°æ®åˆ†æçš„ä¸åŒåº”ç”¨è¿›è¡Œäº†å¾ˆå¥½çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "11.9â€…â€…â€…An illustration of the DQN algorithm including experience replay and target network freezing.",
            "zh": "11.9 DQNç®—æ³•çš„å›¾ç¤ºï¼ŒåŒ…æ‹¬ä½“éªŒå›æ”¾å’Œç›®æ ‡ç½‘ç»œå†»ç»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.708",
            "zh": "2.708"
        }
    }
]
[
    {
        "translation": {
            "en": "D’Arcy, Aoife, 1978- author.",
            "zh": "D'Arcy，Aoife，1978-作者。"
        }
    },
    {
        "translation": {
            "en": "median, 54, 69, 550, 745, 746, 749, 755",
            "zh": "中位数， 54， 69， 550， 745， 746， 749， 755"
        }
    },
    {
        "translation": {
            "en": "However, as the δs vanish, the learning signal attenuates, and this can slow down the rate at which the early layers of the network learn.",
            "zh": "然而，随着δs的消失，学习信号会衰减，这可能会减慢网络早期层的学习速度。"
        }
    },
    {
        "translation": {
            "en": "In particular, it has not been possible for the SDSS to develop a solution to automatically categorize galaxies into the different morphological groups—for example, spiral galaxies or elliptical galaxies.",
            "zh": "特别是，SDSS不可能开发出一种解决方案来自动将星系分类为不同的形态组，例如螺旋星系或椭圆星系。"
        }
    },
    {
        "translation": {
            "en": "(a) The θ represents the inner angle between the vector emanating from the origin to instance d1 and the vector emanating from the origin to instance d2; and (b) shows d1 and d2 normalized to the unit circle.",
            "zh": "（a） θ表示从原点到实例d1的向量与从原点到实例d2的向量之间的内角;（b） 显示归一化为单位圆的 d1 和 d2。"
        }
    },
    {
        "translation": {
            "en": "which gives an average of 1.931. For 𝒞3 the distances are",
            "zh": "平均值为 1.931。对于 C3，距离为"
        }
    },
    {
        "translation": {
            "en": "The state representation is simple, with each cell that an agent can occupy in the grid world defining a state.",
            "zh": "状态表示很简单，代理在网格世界中可以占据的每个单元格都定义了一个状态。"
        }
    },
    {
        "translation": {
            "en": "So, which impurity measure should be used, Gini or entropy? The best advice that we can give is that it is good practice in building decision tree models to try out different impurity metrics and compare the results to see which suits a dataset best.",
            "zh": "那么，应该使用哪种杂质度量，基尼系数还是熵呢？我们可以给出的最佳建议是，在构建决策树模型时，尝试不同的杂质指标并比较结果以查看最适合数据集是一种很好的做法。"
        }
    },
    {
        "translation": {
            "en": "4.22   (a) A plot of the bike rental dataset from Table 4.15[166]. (b)–(e) Visualizations of the prediction models trained in the early iterations of the gradient boosting process. (f) The final ensemble model trained after 20 iterations of gradient boosting.",
            "zh": "4.22 （a） 表4.15[166]中的自行车租赁数据集图。（b）–（e） 在梯度提升过程的早期迭代中训练的预测模型的可视化。（f） 经过 20 次梯度提升迭代后训练的最终集成模型。"
        }
    },
    {
        "translation": {
            "en": "The first thing that should always be done is a careful examination of a set of summary statistics describing the members of each cluster.",
            "zh": "首先要做的是仔细检查一组描述每个集群成员的汇总统计量。"
        }
    },
    {
        "translation": {
            "en": "-0.7986",
            "zh": "-0.7986"
        }
    },
    {
        "translation": {
            "en": "11.4   Extensions and Variations",
            "zh": "11.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "0.31",
            "zh": "0.31"
        }
    },
    {
        "translation": {
            "en": "Figure 8.42",
            "zh": "图 8.42"
        }
    },
    {
        "translation": {
            "en": "standard scores, 87, 717",
            "zh": "标准分数，87,717"
        }
    },
    {
        "translation": {
            "en": "The number of instances in the smallest group is the under-sampling target size.",
            "zh": "最小组中的实例数是欠采样目标大小。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the overall network output of 1.7 has no particular meaning.",
            "zh": "因此，1.7 的整体网络输出没有特别的意义。"
        }
    },
    {
        "translation": {
            "en": "Chapman, Pete, Julian Clinton, Randy Kerber, Thomas Khabaza, Thomas Reinartz, Colin Shearer, and Rudiger Wirth. 2000. CRISP-DM 1.0 Step-by-step data mining guide, Technical report, CRISP-DM consortium.",
            "zh": "查普曼、皮特、朱利安·克林顿、兰迪·科贝尔、托马斯·哈巴扎、托马斯·莱纳茨、科林·希勒和吕迪格·沃斯。2000. CRISP-DM 1.0 分步数据挖掘指南，技术报告，CRISP-DM 联盟。"
        }
    },
    {
        "translation": {
            "en": "5. See Goodfellow et al. (2016, p. 195) for relevant references.",
            "zh": "5. 参见 Goodfellow et al. （2016， p. 195） 的相关参考资料。"
        }
    },
    {
        "translation": {
            "en": "There are two types of inductive bias that a machine learning algorithm can use, a restriction bias and a preference bias.",
            "zh": "机器学习算法可以使用两种类型的归纳偏差，即限制偏差和偏好偏差。"
        }
    },
    {
        "translation": {
            "en": "From Table 8.5[428], for Neuron 8, ∂a/∂z = 0.2492.",
            "zh": "从表8.5[428]中，对于神经元8，∂a/∂z = 0.2492。"
        }
    },
    {
        "translation": {
            "en": "(a) The image below shows an ROC curve for each model. Each curve has a point missing.",
            "zh": "（a） 下图显示了每个模型的 ROC 曲线。每条曲线都缺少一个点。"
        }
    },
    {
        "translation": {
            "en": "These are well-known, reasonably effective approaches to clustering.",
            "zh": "这些是众所周知的、相当有效的聚类方法。"
        }
    },
    {
        "translation": {
            "en": "From a computational point of view it makes no difference, as long as consistency is maintained in notation and computation.",
            "zh": "从计算的角度来看，只要在符号和计算中保持一致性，就没有区别。"
        }
    },
    {
        "translation": {
            "en": "This is what we try to achieve in reinforcement learning.",
            "zh": "这就是我们在强化学习中试图实现的目标。"
        }
    },
    {
        "translation": {
            "en": "greedy action selection policy, 641, 656, 680",
            "zh": "贪婪行动选择策略，641、656、680"
        }
    },
    {
        "translation": {
            "en": "From a programming perspective, we would recommend Charniak (2019) as an introduction to programming deep learning models using TensorFlow, and Trask (2019) provides a great introduction to implementing neural networks using Numpy.",
            "zh": "从编程的角度来看，我们推荐 Charniak （2019） 作为使用 TensorFlow 编程深度学习模型的介绍，而 Trask （2019） 则提供了使用 Nupy 实现神经网络的精彩介绍。"
        }
    },
    {
        "translation": {
            "en": "mixing time, 300",
            "zh": "混合时间，300"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows the possible transitions between states in TwentyTwos based on these actions.",
            "zh": "图11.3[648]显示了基于这些动作的TwentyTwos中状态之间的可能转换。"
        }
    },
    {
        "translation": {
            "en": "13.9   The confusion matrix for the logistic regression model that distinguished between only the spiral galaxy types (classification accuracy: 68.225%, average class accuracy: 56.621%).",
            "zh": "13.9 仅区分螺旋星系类型的逻辑回归模型的混淆矩阵（分类准确率：68.225%，平均分类准确率：56.621%）。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the weighted sum for this neuron for the input vector",
            "zh": "（a） 计算输入向量的该神经元的加权和"
        }
    },
    {
        "translation": {
            "en": "(b) A range normalization that generates data in the range (−1,1)",
            "zh": "（b） 范围归一化，生成范围 （−1,1） 中的数据"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19",
            "zh": "图 7.19"
        }
    },
    {
        "translation": {
            "en": "levels, 34",
            "zh": "级别，34"
        }
    },
    {
        "translation": {
            "en": "8.13   The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places, and with the (binned) target feature represented using one-hot encoding.",
            "zh": "8.13 联合循环电厂环境因素和满负荷电力输出的范围归一化小时样本，四舍五入到小数点后两位，并用单热编码表示（分档）目标特征。"
        }
    },
    {
        "translation": {
            "en": "FPR, 548",
            "zh": "FPR，548"
        }
    },
    {
        "translation": {
            "en": "RNN, 499",
            "zh": "RNN，499"
        }
    },
    {
        "translation": {
            "en": "Figure 10.2",
            "zh": "图 10.2"
        }
    },
    {
        "translation": {
            "en": "A prediction model is going to be built for in-line quality assurance in a factory that manufactures electronic components for the automotive industry.",
            "zh": "将建立一个预测模型，用于为汽车行业制造电子元件的工厂提供在线质量保证。"
        }
    },
    {
        "translation": {
            "en": "cubic function, 766",
            "zh": "三次函数，766"
        }
    },
    {
        "translation": {
            "en": "A neuron functions as an all-or-none switch: if the electrical stimuli gathered by its dendrites are strong enough, the neuron transmits an electrical pulse, known as an action potential, along its axon; otherwise it has no output.",
            "zh": "神经元起着全有或全无开关的作用：如果树突聚集的电刺激足够强，神经元就会沿着其轴突传输电脉冲，称为动作电位;否则它没有输出。"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm described here does not have an explicit aggregation step, as do the bagging and boosting algorithms described previously (in which individual model predictions were combined through averaging or voting).",
            "zh": "这里描述的梯度提升算法没有明确的聚合步骤，就像前面描述的装袋和提升算法一样（其中通过平均或投票组合单个模型预测）。"
        }
    },
    {
        "translation": {
            "en": "aggregate features, 35",
            "zh": "聚合特征，35"
        }
    },
    {
        "translation": {
            "en": "Missing values can also arise for legitimate reasons, however.",
            "zh": "但是，由于正当原因，也可能出现缺失值。"
        }
    },
    {
        "translation": {
            "en": "Indeed, when a neuron uses the logistic function as an activation function, then these two models are identical.",
            "zh": "事实上，当神经元使用逻辑函数作为激活函数时，这两个模型是相同的。"
        }
    },
    {
        "translation": {
            "en": "We can now calculate the probability for CPI = high as",
            "zh": "我们现在可以计算 CPI = 高的概率为"
        }
    },
    {
        "translation": {
            "en": "The characteristic appearance of the decision boundaries is related to the representations used within the models and the inductive biases that the algorithms used to build them encode.",
            "zh": "决策边界的特征外观与模型中使用的表示以及用于构建模型的算法编码的归纳偏差有关。"
        }
    },
    {
        "translation": {
            "en": "The null hypothesis that we adopt for this test is that the feature does not have a significant impact on the model.",
            "zh": "我们在此检验中采用的原假设是该特征对模型没有显著影响。"
        }
    },
    {
        "translation": {
            "en": "where α0 is an initial learning rate (this is typically quite large, e.g., 1.0), c is a constant that controls how quickly the learning rate decays (the value of this parameter depends on how quickly the algorithm converges, but it is often set to quite a large value, e.g., 100), and τ is the current iteration of the gradient descent algorithm.",
            "zh": "其中 α0 是初始学习率（通常相当大，例如 1.0），c 是控制学习率衰减速度的常数（此参数的值取决于算法收敛的速度，但它通常设置为相当大的值，例如 100），τ 是梯度下降算法的当前迭代。"
        }
    },
    {
        "translation": {
            "en": "People grow older, inflation drives up salaries, the content of the spam emails changes, and the way people use technologies changes.",
            "zh": "人们变老，通货膨胀推高了工资，垃圾邮件的内容发生了变化，人们使用技术的方式也发生了变化。"
        }
    },
    {
        "translation": {
            "en": "When experience replay is used, each time an agent uses an action-value network QW to select and take an action, at, in a state, st, earning a reward, rt, and moving the agent to a new state, st+1, an instance of the form s = st, a = at, r = rt, s′ = st+1 is added to a replay memory, .",
            "zh": "使用体验回放时，每次智能体使用动作值网络 QW 选择并执行操作时，在状态 st，获得奖励，rt，并将智能体移动到新状态 st+1，s = st， a = at， r = rt， s′ = st+1 形式的实例被添加到回放内存中， ."
        }
    },
    {
        "translation": {
            "en": "If we don’t know whether the patient has meningitis, then knowing that the patient has a headache may increase the probability we assign to the patient of suffering from a fever.",
            "zh": "如果我们不知道患者是否患有脑膜炎，那么知道患者头痛可能会增加我们分配给患者发烧的可能性。"
        }
    },
    {
        "translation": {
            "en": "The underlying distribution of churners and non-churners within the larger AT customer base, however, is much different.",
            "zh": "然而，在更大的AT客户群中，流失者和非流失者的基本分布却大不相同。"
        }
    },
    {
        "translation": {
            "en": "(d) The employee ID numbers of the academic staff at a university.",
            "zh": "（d） 大学学术人员的雇员身份证号码。"
        }
    },
    {
        "translation": {
            "en": "Although the assumption of conditional independence extends the coverage of a naive Bayes model and allows it to generalize beyond the contents of the training data, naive Bayes models still do not have complete coverage of the set of all possible queries.",
            "zh": "尽管条件独立性的假设扩展了朴素贝叶斯模型的覆盖范围，并允许它泛化到训练数据的内容之外，但朴素贝叶斯模型仍然没有完全覆盖所有可能的查询集。"
        }
    },
    {
        "translation": {
            "en": "We can see this if we compare the Euclidean and Manhattan distances between instances d12 and d5 with the Euclidean and Manhattan distances between instances d12 and d17 (SPEED = 5.25, AGILITY = 9.50). Figure 5.2(b)[186] plots the Manhattan and Euclidean distances between these pairs of instances.",
            "zh": "如果我们将实例 d12 和 d5 之间的欧几里得和曼哈顿距离与实例 d12 和 d17 之间的欧几里得和曼哈顿距离进行比较，我们可以看到这一点（SPEED = 5.25，敏捷 = 9.50）。图5.2（b）[186]绘制了这两对实例之间的曼哈顿距离和欧几里得距离。"
        }
    },
    {
        "translation": {
            "en": "0.00153726",
            "zh": "0.00153726"
        }
    },
    {
        "translation": {
            "en": "Precision and recall can be collapsed to a single performance measure known as the F1 measure,6 which offers a useful alternative to the simpler misclassification rate. The F1 measure is the harmonic mean of precision and recall and is defined as",
            "zh": "精确度和召回率可以折叠为称为 F1 度量的单个性能度量，6 它为更简单的错误分类率提供了有用的替代方案。F1 度量是精确度和召回率的谐波平均值，定义为"
        }
    },
    {
        "translation": {
            "en": "Given this context, the processing of the forget gate would be as follows (note that in this calculation hxt is augmented with a bias input 1):",
            "zh": "在此上下文中，遗忘门的处理如下（请注意，在此计算中，hxt 用偏置输入 1 进行增强）："
        }
    },
    {
        "translation": {
            "en": "In the complementary scenario, the model makes an incorrect prediction and the maximum probability in is assigned to the incorrect category.",
            "zh": "在互补方案中，模型做出错误的预测，并将最大概率分配给不正确的类别。"
        }
    },
    {
        "translation": {
            "en": "5.18   A set of scatter plots illustrating the curse of dimensionality.",
            "zh": "5.18 一组散点图，说明维度的诅咒。"
        }
    },
    {
        "translation": {
            "en": "The player asking the questions wins by guessing who is on the card within a small number of questions and loses otherwise.",
            "zh": "提出问题的玩家通过在少数问题中猜测谁在卡片上而获胜，否则就输了。"
        }
    },
    {
        "translation": {
            "en": "The derivative of a function can be understood as the slope of the graph of the function at each point on the graph.",
            "zh": "函数的导数可以理解为函数图在图上每个点的斜率。"
        }
    },
    {
        "translation": {
            "en": "eligibility traces, 655",
            "zh": "资格跟踪，655"
        }
    },
    {
        "translation": {
            "en": "As a result, irrespective of the width of the input x, the activation vectors for these layers will be the same size as the cell state c, and so the dimensions of the vectors in the elementwise operations that update the cell state will match.",
            "zh": "因此，无论输入 x 的宽度如何，这些层的激活向量都将与单元状态 c 的大小相同，因此更新单元格状态的元素操作中的向量维度将匹配。"
        }
    },
    {
        "translation": {
            "en": "Table 6.10[271] shows the definition of some of the standard probability distributions—the normal, exponential, and mixture of Gaussians distributions—that are commonly used in probabilistic prediction models, and Figure 6.3[270] illustrates the shapes of the density curves of these distributions.",
            "zh": "表6.10[271]显示了概率预测模型中常用的一些标准概率分布（正态分布、指数分布和混合分布）的定义，图6.3[270]说明了这些分布的密度曲线的形状。"
        }
    },
    {
        "translation": {
            "en": "Similarly, if Neurons 6 and 7 are dead, then no error gradients will be backpropagated past this layer of neurons and the network is essentially reduced to a perceptron network composed of just Neuron 8, as none of the other neurons will have their input weights updated during training.",
            "zh": "同样，如果神经元 6 和 7 是死的，那么没有误差梯度会反向传播超过这一层神经元，并且网络基本上被简化为仅由神经元 8 组成的感知器网络，因为其他神经元都不会在训练期间更新其输入权重。"
        }
    },
    {
        "translation": {
            "en": "0.7458",
            "zh": "0.7458"
        }
    },
    {
        "translation": {
            "en": "The basis of this theory was that complex behavior emerges from the interactions between massive numbers of highly interconnected neurons rather than from complex processing within neurons.",
            "zh": "该理论的基础是，复杂行为来自大量高度互连的神经元之间的相互作用，而不是神经元内部的复杂处理。"
        }
    },
    {
        "translation": {
            "en": "A better choice, and our recommended default, is random sampling, which randomly selects a proportion of s% of the instances from a large dataset to create a smaller set. Random sampling is a good choice in most cases, as the random nature of the selection of instances should avoid introducing bias.",
            "zh": "更好的选择（也是我们推荐的默认值）是随机抽样，它从大型数据集中随机选择一定比例的 s% 实例以创建较小的集合。在大多数情况下，随机抽样是一个不错的选择，因为选择实例的随机性应避免引入偏差。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.8",
            "zh": "图 11.8"
        }
    },
    {
        "translation": {
            "en": "clustering evaluation internal criterion, 608",
            "zh": "聚类评估内部准则，608"
        }
    },
    {
        "translation": {
            "en": "ME2E2ERR_U/G/R/I/Z",
            "zh": "ME2E2ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Description",
            "zh": "描述"
        }
    },
    {
        "translation": {
            "en": "However, naively initializing weights can result in unstable behavior within the dynamics of a network during training, resulting in saturated activation functions (as a consequence of z values becoming too large or small) or unstable error gradients.",
            "zh": "然而，幼稚地初始化权重可能会导致训练期间网络动态中的行为不稳定，从而导致激活函数饱和（由于 z 值变得过大或过小）或不稳定的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "These values immediately suggest that the model is better at predicting the ham level (TNR) than it is at predicting the spam level (TPR).",
            "zh": "这些值立即表明，该模型在预测火腿水平 （TNR） 方面比在预测垃圾邮件水平 （TPR） 方面更好。"
        }
    },
    {
        "translation": {
            "en": "However, if these backpropagated δs came from hidden neurons, then they were also calculated as a product of the weighted sum of the δs backpropagated to those hidden neurons and the ∂ak/∂zk term for those neurons.",
            "zh": "然而，如果这些反向传播的δ来自隐藏的神经元，那么它们也被计算为反向传播到这些隐藏神经元的δs的加权和这些神经元的∂ak/∂zk项的乘积。"
        }
    },
    {
        "translation": {
            "en": "36. Loss functions are discussed in much more detail in Chapters 7[311] and 8[381]. We can view the gradient boosting process as equivalent to the gradient descent process described in those chapters.",
            "zh": "36. 损失函数在第7章[311]和第8章[381]中有更详细的讨论。我们可以将梯度提升过程视为等同于这些章节中描述的梯度下降过程。"
        }
    },
    {
        "translation": {
            "en": "0.4571",
            "zh": "0.4571"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5[273] illustrates how outliers affect normal and student-t distributions.",
            "zh": "图 6.5[273] 说明了异常值如何影响正态分布和学生 t 分布。"
        }
    },
    {
        "translation": {
            "en": "0.0694",
            "zh": "0.0694"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, a probability distribution for three binary features A, B, and C. The probability for a joint event in this domain P(A,B,C) can be decomposed using the chain rule in the following way:",
            "zh": "例如，考虑三个二元特征 A、B 和 C 的概率分布。可以使用链式法则按以下方式分解此域中联合事件的概率 P（A，B，C）："
        }
    },
    {
        "translation": {
            "en": "This model gave the best prediction accuracy and offered the potential for very fast classification times, which was attractive for integration into the SDSS pipeline.",
            "zh": "该模型提供了最佳的预测准确性，并提供了非常快的分类时间的潜力，这对于集成到 SDSS 管道中很有吸引力。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.29",
            "zh": "图 8.29"
        }
    },
    {
        "translation": {
            "en": "If this test succeeds, the algorithm descends to a leaf node of this subtree, using the same process it used to find the original leaf node (Line 9).",
            "zh": "如果此测试成功，则算法将下降到此子树的叶节点，使用与查找原始叶节点相同的过程（第 9 行）。"
        }
    },
    {
        "translation": {
            "en": "Equal-width binning is simple and intuitive, and can work well in practice.",
            "zh": "等宽分箱简单直观，在实践中可以很好地工作。"
        }
    },
    {
        "translation": {
            "en": "Ester, Martin, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proceedings of the second international conference on knowledge discovery and data mining KDD, Vol. 96, 226–231.",
            "zh": "Ester、Martin、Hans-Peter Kriegel、Jörg Sander 和 Xiaowei Xu。1996. 一种基于密度的算法，用于发现具有噪声的大型空间数据库中的聚类。在第二届知识发现和数据挖掘国际会议论文集 KDD 中，第 96 卷，第 226-231 页。"
        }
    },
    {
        "translation": {
            "en": "23. The inverse of the identity matrix 𝕀 is 𝕀. Therefore, if there is no covariance between the features, both the covariance and the inverse covariance matrix will be equal to 𝕀.",
            "zh": "23. 单位矩阵 I 的倒数是 I。因此，如果特征之间没有协方差，则协方差和逆协方差矩阵都将等于 I。"
        }
    },
    {
        "translation": {
            "en": "The Gini index is 0 when all the instances in the dataset have the same target level, and it is when there are k possible target levels with equal likelihood.",
            "zh": "当数据集中的所有实例都具有相同的目标水平时，基尼指数为 0，并且当有 k 个可能的目标水平具有相等的可能性时，基尼指数为 0。"
        }
    },
    {
        "translation": {
            "en": "A large change in the root mean squared error value would flag that the model had gone stale.",
            "zh": "均方根误差值的较大变化将表明模型已过时。"
        }
    },
    {
        "translation": {
            "en": "Each element in a matrix is identified by two indices, the row index and then the column index. For example,",
            "zh": "矩阵中的每个元素都由两个索引标识，即行索引和列索引。例如"
        }
    },
    {
        "translation": {
            "en": "The dealer encourages you to play again, but you know that you’ve got to know when to walk away, so you head off with an extra dollar in your pocket.",
            "zh": "庄家鼓励你再玩一次，但你知道你必须知道什么时候该走开，所以你口袋里多了一块钱。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(d)[151] depicts one of the problems that can arise when a variance measure is used to split a continuous target feature.",
            "zh": "图 4.15（d）[151] 描述了使用方差度量分割连续目标特征时可能出现的问题之一。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(c)[151] shows that the instances have been gathered into two groups that have a relatively low variance compared with the single group in Figure 4.15(b)[151].",
            "zh": "图4.15（c）[151]显示，与图4.15（b）[151]中的单组相比，这些实例被收集到两组，方差相对较低。"
        }
    },
    {
        "translation": {
            "en": "However, matrix multiplication is associative (i.e., X(YZ) is equal to (XY)Z); this means that we can rewrite Equation (8.9)[395]",
            "zh": "然而，矩阵乘法是关联的（即 X（YZ） 等于 （XY）Z）;这意味着我们可以重写方程（8.9）[395]"
        }
    },
    {
        "translation": {
            "en": "0.45",
            "zh": "0.45"
        }
    },
    {
        "translation": {
            "en": "As the name suggests, the mixture of Gaussians distribution is the distribution that results when a number of normal (or Gaussian) distributions are merged.",
            "zh": "顾名思义，高斯分布的混合是合并多个正态（或高斯）分布时产生的分布。"
        }
    },
    {
        "translation": {
            "en": "8.15   An illustration of the forward propagation of d2 through the network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "8.15 d2 通过网络向前传播的图示，显示了每个连接上的权重，以及网络中每个神经元的加权总和 z 和激活值。"
        }
    },
    {
        "translation": {
            "en": "No Free Lunch Theorem, 13, 736",
            "zh": "没有免费的午餐定理，13,736"
        }
    },
    {
        "translation": {
            "en": "A family of error-based machine learning algorithms takes the same approach. A parameterized prediction model is initialized with a set of random parameters, and an error function is used to judge how well this initial model performs when making predictions for instances in a training dataset. Based on the value of the error function, the parameters are iteratively adjusted to create a more and more accurate model.",
            "zh": "一系列基于错误的机器学习算法采用相同的方法。参数化预测模型使用一组随机参数进行初始化，误差函数用于判断该初始模型在对训练数据集中的实例进行预测时的表现。根据误差函数的值，对参数进行迭代调整，以创建越来越准确的模型。"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean, on the other hand, emphasizes the importance of smaller values and so can give a slightly more realistic measure of how well a model is performing.",
            "zh": "另一方面，谐波均值强调较小值的重要性，因此可以更真实地衡量模型的性能。"
        }
    },
    {
        "translation": {
            "en": "One way we can reduce the impact of this is that for each categorical feature we transform, we can reduce the number of newly added features by one by assuming that a zero in all the new features implies that the original feature had the final level.",
            "zh": "我们可以减少这种影响的一种方法是，对于我们转换的每个分类特征，我们可以将新添加的特征数量减少 1，方法是假设所有新特征中的零意味着原始特征具有最终级别。"
        }
    },
    {
        "translation": {
            "en": "There are two ways that an episode can end: an agent can either land successfully or crash.",
            "zh": "剧集有两种结束方式：特工可以成功着陆或坠毁。"
        }
    },
    {
        "translation": {
            "en": "This will make the model appear much more accurate than it will actually be when deployed.",
            "zh": "这将使模型看起来比部署时实际准确得多。"
        }
    },
    {
        "translation": {
            "en": "Hunter, Elizabeth, Brian Mac Namee, and John Kelleher. 2018. An open-data-driven agent-based model to simulate infectious disease outbreaks. PloS One 13 (12): 0208775.",
            "zh": "亨特、伊丽莎白、布莱恩·麦克·纳梅和约翰·凯莱赫。2018. 基于开放数据驱动的基于智能体的模型，用于模拟传染病暴发.公共科学图书馆一号13（12）：0208775。"
        }
    },
    {
        "translation": {
            "en": "By contrast, if we apply Equation (7.23)[339] to the instance RPM = 650 and VIBRATION = 240, which is below the decision boundary in Figure 7.10(b)[340], we get",
            "zh": "相反，如果我们将方程（7.23）[339]应用于RPM = 650和VIBRATION = 240（低于图7.10（b）[340]中的决策边界）的实例，我们得到"
        }
    },
    {
        "translation": {
            "en": "To choose which action to take in a given state the agent uses a policy.",
            "zh": "若要选择在给定状态下要执行的操作，代理使用策略。"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wished to evaluate the performance of a prediction model built to estimate the daily energy demand in a residential building based on features describing the family that lives in the house, the weather on a given day, and the time of the year.",
            "zh": "例如，假设我们希望评估一个预测模型的性能，该模型旨在根据描述居住在房屋中的家庭、给定日期的天气和一年中的时间的特征来估计住宅楼的每日能源需求。"
        }
    },
    {
        "translation": {
            "en": "It is not feasible for an analytics practitioner to learn everything about the businesses with which they work as they will probably move quickly between different areas of an organization, or even different industries.",
            "zh": "对于分析从业者来说，了解他们所从事的企业的所有信息是不可行的，因为他们可能会在组织的不同领域甚至不同的行业之间快速移动。"
        }
    },
    {
        "translation": {
            "en": "ongoing model validation, 579, 702",
            "zh": "正在进行的模型验证，579,702"
        }
    },
    {
        "translation": {
            "en": "For categorical features we are interested primarily in frequency counts and proportions.",
            "zh": "对于分类特征，我们主要对频率计数和比例感兴趣。"
        }
    },
    {
        "translation": {
            "en": "In the ID3 algorithm we created a leaf node when there were no instances left in the partition being processed (Line 1), when there were no features left on which to split the data (Line 1), or when we had created a pure partition of the dataset with respect to the target feature levels (Line 1).",
            "zh": "在 ID3 算法中，当正在处理的分区中没有剩余实例时（第 1 行），当没有剩余的特征可以拆分数据时（第 1 行），或者当我们创建了相对于目标特征级别的数据集的纯分区时（第 1 行），我们创建了一个叶节点。"
        }
    },
    {
        "translation": {
            "en": "event, 246, 757, 758, 758",
            "zh": "事件， 246， 757， 758， 758"
        }
    },
    {
        "translation": {
            "en": "The number of instances placed in each bin is simply the total number of instances divided by the number of bins, b.",
            "zh": "放置在每个 bin 中的实例数只是实例总数除以 b。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.90)[486] and Equation (8.91)[486] illustrate how the feature map generated by the neurons in Figure 8.33[484] changes if the filter used by the neurons to process the example input is changed.",
            "zh": "方程（8.90）[486]和方程（8.91）[486]说明了如果神经元用于处理示例输入的过滤器发生变化，图8.33[484]中的神经元生成的特征图将如何变化。"
        }
    },
    {
        "translation": {
            "en": "Note, however, that in the section on Handling Categorical Target features, we switch to the term logit to refer to the output of the weight sum in a neuron and update the notation to reflect this switch; see the previous notation section on Categorical Targets for more details.",
            "zh": "但是请注意，在处理分类目标特征一节中，我们切换到术语 logit 来指代神经元中权重总和的输出，并更新符号以反映此切换;有关详细信息，请参阅前面关于分类目标的表示法部分。"
        }
    },
    {
        "translation": {
            "en": "Appendix B[757] provides a comprehensive introduction to these aspects of probability theory, so we recommend that readers unfamiliar with them review this appendix before continuing with this chapter.",
            "zh": "附录B[757]全面介绍了概率论的这些方面，因此我们建议不熟悉它们的读者在继续本章之前先查看本附录。"
        }
    },
    {
        "translation": {
            "en": "MDP, 645",
            "zh": "MDP，645"
        }
    },
    {
        "translation": {
            "en": "To calculate the distance between the query instance and the hyperplane defined by the node indexing d15 (the boundaryDist function on Line 8), we use only the AGILITY feature, as it is the splitting feature at this node.",
            "zh": "为了计算查询实例与节点索引 d15（第 8 行的 boundaryDist 函数）定义的超平面之间的距离，我们只使用 AGILITY 特征，因为它是该节点的拆分特征。"
        }
    },
    {
        "translation": {
            "en": "In Chapter 2[23] we described the process of moving from a business problem to an analytics solution and, from there, to the design and construction of an analytics base table (ABT).",
            "zh": "在第 2 章[23]中，我们描述了从业务问题转向分析解决方案的过程，以及从那里到分析基表 （ABT） 的设计和构建的过程。"
        }
    },
    {
        "translation": {
            "en": "In this approach, an instance is chosen randomly (following a uniform distribution) from the dataset as the first centroid.",
            "zh": "在这种方法中，从数据集中随机选择一个实例（遵循均匀分布）作为第一个质心。"
        }
    },
    {
        "translation": {
            "en": "Every instance in this ABT should have that value, and this feature was removed from the ABT.",
            "zh": "此 ABT 中的每个实例都应具有该值，并且此功能已从 ABT 中删除。"
        }
    },
    {
        "translation": {
            "en": "Even with this cautious strategy, in an evaluation in which an agent plays a bout of 1,000 hands of TwentyTwos 100,000 times, this player will on average earn a profit of $198 ± 24 in 1,000 hands.",
            "zh": "即使采用这种谨慎的策略，在经纪人玩 1,000 手 100,000 次 TwentyTwos 的评估中，该玩家在 1,000 手牌中平均赚取 198 美元± 24 美元的利润。"
        }
    },
    {
        "translation": {
            "en": "loss, 168, 625",
            "zh": "损失， 168， 625"
        }
    },
    {
        "translation": {
            "en": "This means that the Euclidean difference is more influenced by a single large difference in one feature rather than a lot of small differences across a set of features, whereas the opposite is true of Manhattan distance.",
            "zh": "这意味着欧几里得差分更多地受一个特征的单个大差异的影响，而不是一组特征之间的许多小差异，而曼哈顿距离则相反。"
        }
    },
    {
        "translation": {
            "en": "Gradient boosting then iteratively adds new models to the ensemble.",
            "zh": "然后，梯度提升会迭代地将新模型添加到整体中。"
        }
    },
    {
        "translation": {
            "en": "We can see the reason for this in Table 6.3[264], where there are still some probabilities equal to zero, for example, P(CH = none | ¬fr).",
            "zh": "我们可以在表 6.3[264] 中看到其原因，其中仍然有一些概率等于零，例如，P（CH = none | ¬fr）。"
        }
    },
    {
        "translation": {
            "en": "Table 9.13",
            "zh": "表 9.13"
        }
    },
    {
        "translation": {
            "en": "Similarly, the correlation matrix is just a normalized version of the covariance matrix and shows the correlation between each pair of features:",
            "zh": "类似地，相关矩阵只是协方差矩阵的归一化版本，并显示每对特征之间的相关性："
        }
    },
    {
        "translation": {
            "en": "Figure 11.9",
            "zh": "图 11.9"
        }
    },
    {
        "translation": {
            "en": "extract-transform-load, 42, 702",
            "zh": "提取-转换-加载， 42， 702"
        }
    },
    {
        "translation": {
            "en": "Figure 4.8",
            "zh": "图 4.8"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18(a)[226] plots a one-dimensional dataset consisting of 29 instances spread evenly between 0.0 and 3.0.",
            "zh": "图 5.18（a）[226] 绘制了一个由 29 个实例组成的一维数据集，这些实例均匀分布在 0.0 和 3.0 之间。"
        }
    },
    {
        "translation": {
            "en": "For example, the instances in Table 6.15[283] are ordered in ascending order based on the magnitude of their original LOAN AMOUNT value.",
            "zh": "例如，表 6.15[283] 中的实例根据其原始 LOAN AMOUNT 值的大小按升序排序。"
        }
    },
    {
        "translation": {
            "en": "Strang, Gilbert. 2016. Introduction to linear algebra, 5th ed. Wellesley-Cambridge Press.",
            "zh": "斯特朗，吉尔伯特。2016. 线性代数导论，第 5 版，韦尔斯利-剑桥出版社。"
        }
    },
    {
        "translation": {
            "en": "6.1   A game of find the lady: (a) the cards used; (b) the cards dealt facedown on a table; (c) the initial likelihoods of the queen ending up in each position; and (d) a revised set of likelihoods for the position of the queen based on evidence collected.",
            "zh": "6.1 寻找女士的游戏：（a）使用的牌;（b） 在桌子上发牌面朝下;（c） 女王最终担任每个职位的最初可能性;（d）根据收集到的证据，对女王职位的一系列可能性进行了修订。"
        }
    },
    {
        "translation": {
            "en": "For the heights of the players in the extended basketball team in Figure A.2[746], the mode is 140, as it is the only value that appears twice.",
            "zh": "对于图 A.2[746] 中扩展篮球队中球员的身高，该模式为 140，因为它是唯一出现两次的值。"
        }
    },
    {
        "translation": {
            "en": "Weights and standard errors for each feature in the office rentals model.",
            "zh": "办公室租赁模型中每个要素的权重和标准误差。"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we present describe how different data types can be handled, how overfitting can be avoided using decision tree pruning, and how multiple prediction models can be combined in ensembles to improve prediction accuracy.",
            "zh": "我们介绍的这种标准方法的扩展和变体描述了如何处理不同的数据类型，如何使用决策树修剪来避免过度拟合，以及如何将多个预测模型组合成集成以提高预测准确性。"
        }
    },
    {
        "translation": {
            "en": "For example, if you were to randomly select a card from the set shown in Figure 4.5(a)[124], you would have zero uncertainty, as you would know for sure that you would select an ace of spades.",
            "zh": "例如，如果你从图4.5（a）[124]所示的牌集中随机选择一张牌，你的不确定性为零，因为你肯定知道你会选择黑桃A。"
        }
    },
    {
        "translation": {
            "en": "The population mean of a feature is usually denoted by μ, and in general, given a sufficiently large sample, we use the sample mean ā as a point estimate of μ.",
            "zh": "特征的总体均值通常用 μ 表示，通常，给定足够大的样本，我们使用样本均值 ā 作为 μ 的点估计值。"
        }
    },
    {
        "translation": {
            "en": "To create a sample that is larger than the size of the group that we are sampling from, we use random sampling with replacement.",
            "zh": "为了创建一个大于我们抽样的组大小的样本，我们使用随机抽样和替换。"
        }
    },
    {
        "translation": {
            "en": "Based on this comparison, a performance measure can be used to capture, numerically, how well the predictions made by the model match those that were expected.",
            "zh": "基于这种比较，可以使用性能度量值从数值上捕获模型所做的预测与预期预测的匹配程度。"
        }
    },
    {
        "translation": {
            "en": "9.4 Extensions and Variations",
            "zh": "9.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "sample covariance, 81",
            "zh": "样本协方差，81"
        }
    },
    {
        "translation": {
            "en": "42. Technically, what a convolution network is actually calculating should be called a cross-correlation (Charniak, 2019, p. 52), but we ignore this technicality for the purposes of this discussion.",
            "zh": "42. 从技术上讲，卷积网络实际计算的内容应该称为互相关（Charniak，2019 年，第 52 页），但出于本讨论的目的，我们忽略了这种技术性。"
        }
    },
    {
        "translation": {
            "en": "The values in Table 9.8[554] are based on these figures.",
            "zh": "表9.8[554]中的值基于这些数字。"
        }
    },
    {
        "translation": {
            "en": "This was referred to as the under-sampled training set.",
            "zh": "这被称为欠样本训练集。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5",
            "zh": "图 2.5"
        }
    },
    {
        "translation": {
            "en": "Using the equivalence defined in Equation (8.14)[408], this product of three terms can be simplified",
            "zh": "使用等式（8.14）[408]中定义的等价性，可以简化三个项的乘积"
        }
    },
    {
        "translation": {
            "en": "knowledge elicitation, 31",
            "zh": "知识获取， 31"
        }
    },
    {
        "translation": {
            "en": "Figure 12.2",
            "zh": "图 12.2"
        }
    },
    {
        "translation": {
            "en": "Figure 8.22[450] illustrates this new network architecture.",
            "zh": "图 8.22[450] 说明了这种新的网络架构。"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(a)[620] shows these distances and is referred to as a distance matrix.9 The pair of instances in the dataset that are closest together are then selected and combined into a cluster.",
            "zh": "表 10.5（a）[620] 显示了这些距离，称为距离矩阵.9 然后选择数据集中最接近的一对实例并将其组合成一个集群。"
        }
    },
    {
        "translation": {
            "en": "The next section provides a case study of the process for converting a business problem into a set of candidate analytics solutions.",
            "zh": "下一节将提供将业务问题转换为一组候选分析解决方案的过程的案例研究。"
        }
    },
    {
        "translation": {
            "en": "The state of the decision tree after the 𝒟8 partition has been split using SLOPE.",
            "zh": "使用 SLOPE 拆分 D8 分区后的决策树状态。"
        }
    },
    {
        "translation": {
            "en": "SKYIVAR_U/G/R/I/Z",
            "zh": "SKYIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "We present an approach in which we first develop a set of domain concepts that describe the prediction subject, and then expand these into concrete descriptive features.",
            "zh": "我们提出了一种方法，其中我们首先开发一组描述预测主题的领域概念，然后将这些概念扩展为具体的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "For the first query instance, q1, the output of the support vector machine model is:",
            "zh": "对于第一个查询实例 q1，支持向量机模型的输出为："
        }
    },
    {
        "translation": {
            "en": "The main difference between the McCulloch and Pitts model and modern artificial neurons is that the thresholding function is replaced by other functions.",
            "zh": "McCulloch 和 Pitts 模型与现代人工神经元之间的主要区别在于阈值函数被其他函数取代。"
        }
    },
    {
        "translation": {
            "en": "In this unit each of these weight matrices has dimensions 2 × 4.",
            "zh": "在这个单位中，每个权重矩阵的维度为 2 × 4。"
        }
    },
    {
        "translation": {
            "en": "The reason is that pruning typically affects the lower parts of the decision tree, where noisy training data is most likely to cause overfitting.",
            "zh": "原因是修剪通常会影响决策树的下部，其中嘈杂的训练数据最有可能导致过拟合。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.1",
            "zh": "图 10.1"
        }
    },
    {
        "translation": {
            "en": "Throughout the early stages of the project, Ross had been consciously working on developing his situational fluency.",
            "zh": "在项目的早期阶段，罗斯一直在有意识地努力提高他的情境流畅性。"
        }
    },
    {
        "translation": {
            "en": "For example, in the drug dosage prediction problem, we cannot say by how many milligrams we expect the model to be incorrect based on the mean squared error values.",
            "zh": "例如，在药物剂量预测问题中，我们不能根据均方误差值来判断我们期望模型不正确的毫克数。"
        }
    },
    {
        "translation": {
            "en": "Rather, the algorithm finds a hierarchical agglomeration (or grouping) of the instances in a dataset that can then be used to cluster the instances into any number of groups.",
            "zh": "相反，该算法在数据集中查找实例的分层聚集（或分组），然后可用于将实例聚类为任意数量的组。"
        }
    },
    {
        "translation": {
            "en": "9.4.6.2 Monitoring model output distribution changes An alternative to using changing model performance is to use changes in the distribution of model outputs as a signal for concept drift.",
            "zh": "9.4.6.2 监测模型输出分布变化 使用模型性能变化的另一种方法是将模型输出分布的变化用作概念漂移的信号。"
        }
    },
    {
        "translation": {
            "en": "Similar to the filter dimensions, finding the appropriate stride for a given dataset involves trial-and-error experimentation.",
            "zh": "与筛选器维度类似，为给定数据集找到适当的步幅涉及试错试验。"
        }
    },
    {
        "translation": {
            "en": "Bar plot of the continuous TRAINING EXPENSES feature from Table A.1[750].",
            "zh": "表A.1[750]中连续训练费用特征的条形图。"
        }
    },
    {
        "translation": {
            "en": "This distance is 2.75, which is greater than best-distance (we can see this in Figure 5.10(b)[201], as the hyperplane defined at the node indexing d15 does not intersect with the target hypersphere).",
            "zh": "该距离为 2.75，大于最佳距离（我们可以在图 5.10（b）[201] 中看到这一点，因为在节点索引 d15 处定义的超平面不与目标超球相交）。"
        }
    },
    {
        "translation": {
            "en": "Although there are four sets of connections in this network (input to hidden, hidden to output, hidden to buffer, and buffer to hidden), there are only three weight matrices in the network.",
            "zh": "尽管该网络中有四组连接（输入到隐藏、隐藏到输出、隐藏到缓冲区和缓冲区到隐藏），但网络中只有三个权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "8.20   A plot showing how the sum of squared errors of the ReLU network changed during training when α = 0.2.",
            "zh": "8.20 当 α = 0.2 时，ReLU 网络的平方误差和在训练期间如何变化的图。"
        }
    },
    {
        "translation": {
            "en": "The boosting algorithm presented here can be easily adapted to work with continuous targets by changing the weight update rules to be based on error rather than misclassification, and in this case the aggregation calculates a weighted mean prediction from the base models in the ensemble.31",
            "zh": "通过将权重更新规则更改为基于误差而不是错误分类，可以很容易地调整此处介绍的提升算法以处理连续目标，在这种情况下，聚合从集成中的基本模型计算加权平均预测31。"
        }
    },
    {
        "translation": {
            "en": "Ioffe, Sergey, and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the thirty-second international conference on machine learning, 448–456. JMLR.",
            "zh": "约菲、谢尔盖和克里斯蒂安·塞格迪。2015. 批量归一化：通过减少内部协变量偏移来加速深度网络训练。在第三十二届机器学习国际会议论文集，448-456。JMLR。"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce the fundamental concepts of probability theory that are used in probability-based machine learning algorithms. Specifically, we present the basics of calculating probabilities based on relative frequencies, calculating conditional probabilities, the probability product rule, the probability chain rule, and the Theorem of Total Probability.",
            "zh": "在本附录中，我们介绍了基于概率的机器学习算法中使用的概率论的基本概念。具体来说，我们介绍了基于相对频率计算概率、计算条件概率、概率乘积规则、概率链规则和总概率定理的基础知识。"
        }
    },
    {
        "translation": {
            "en": "2.3 Designing the Analytics Base Table",
            "zh": "2.3 设计分析基表"
        }
    },
    {
        "translation": {
            "en": "Also, each arrow is labeled with the weight that the neuron receiving the activation flowing along that connection applies to that activation during the weighted sum calculation.",
            "zh": "此外，每个箭头都标有在加权和计算期间接收沿该连接流动的激活的神经元应用于该激活的权重。"
        }
    },
    {
        "translation": {
            "en": "Comparing these results to the information gain calculated using entropy (see Table 4.4[137]), we can see that although the resulting numbers are different, the relative ranking of the features is the same—in both cases ELEVATION has the highest information gain.",
            "zh": "将这些结果与使用熵计算的信息增益进行比较（见表4.4[137]），我们可以看到，尽管结果数字不同，但特征的相对排名是相同的——在这两种情况下，ELEVATION的信息增益最高。"
        }
    },
    {
        "translation": {
            "en": "The key component of the gradient descent algorithm presented in this chapter is the use of differentiation to compute the slope of the error surface.",
            "zh": "本章介绍的梯度下降算法的关键组成部分是使用微分来计算误差面的斜率。"
        }
    },
    {
        "translation": {
            "en": "FREQ",
            "zh": "频率"
        }
    },
    {
        "translation": {
            "en": "Glasses",
            "zh": "眼镜"
        }
    },
    {
        "translation": {
            "en": "18. This means that the distribution over the target feature will be different between a training set sample and the full population.",
            "zh": "18. 这意味着训练集样本和整个总体之间目标特征的分布将不同。"
        }
    },
    {
        "translation": {
            "en": "The density of the marked unit hypercube is now (there are only 4 instances inside the hypercube).",
            "zh": "标记单位超立方体的密度现在为（超立方体内只有 4 个实例）。"
        }
    },
    {
        "translation": {
            "en": "In some cases, the size of the interval is defined as part of the problem we are trying to solve, or there may be a natural interval to use because of the domain.",
            "zh": "在某些情况下，区间的大小被定义为我们试图解决的问题的一部分，或者由于域的原因，可能有一个自然区间可以使用。"
        }
    },
    {
        "translation": {
            "en": "1.4 Inductive Bias Versus Sample Bias",
            "zh": "1.4 电感偏差与样本偏差"
        }
    },
    {
        "translation": {
            "en": "For example, in Figure 2.4[35] the levels of the CREDIT RATING feature are {aa, a, b, c} and the levels of the GENDER feature are {male, female}.",
            "zh": "例如，在图2.4[35]中，信用评级特征的级别为{aa，a，b，c}，性别特征的级别为{男性，女性}。"
        }
    },
    {
        "translation": {
            "en": "Some of the topics that, space permitting, we would have included are batch normalization (Ioffe and Szegedy, 2015), which can speed up the training of very deep networks; algorithms that adaptively adjust the learning rate parameter such as Adam (Kingma and Ba, 2014); and more recent neural network architectures such as Generative Adversarial Networks (Goodfellow et al., 2014), and attention-based architectures, such as the Transformer (Vaswani et al., 2017).",
            "zh": "在空间允许的情况下，我们将包括的一些主题是批量归一化（Ioffe 和 Szegedy，2015 年），它可以加快非常深度网络的训练;自适应调整学习率参数的算法，如Adam（Kingma和Ba，2014）;以及最近的神经网络架构，如生成对抗网络（Goodfellow等人，2014年），以及基于注意力的架构，如Transformer（Vaswani等人，2017年）。"
        }
    },
    {
        "translation": {
            "en": "Preface to the 1st Edition",
            "zh": "第一版前言"
        }
    },
    {
        "translation": {
            "en": "It is clear from the values along the diagonal, the true positives and true negatives, that the model is doing a reasonably good job of making accurate predictions. We can actually calculate the misclassification rate directly from the confusion matrix as follows:",
            "zh": "从沿对角线的值、真正值和真负值中可以清楚地看出，该模型在做出准确预测方面做得相当好。我们实际上可以直接从混淆矩阵中计算错误分类率，如下所示："
        }
    },
    {
        "translation": {
            "en": "max, 489",
            "zh": "最大值，489"
        }
    },
    {
        "translation": {
            "en": "We also present two course paths that focus on the context of predictive data analytics.",
            "zh": "我们还介绍了两条课程路径，重点介绍预测数据分析的背景。"
        }
    },
    {
        "translation": {
            "en": "Policies rely on being able to assess the expected return of taking an action in a particular state, and an action-value function can be used to calculate this.6",
            "zh": "策略依赖于能够评估在特定状态下采取行动的预期回报，而行动价值函数可用于计算此回报6。"
        }
    },
    {
        "translation": {
            "en": "8   Deep Learning",
            "zh": "8 深度学习"
        }
    },
    {
        "translation": {
            "en": "3. A city tax service has performed a clustering of individual taxpayers using k-means clustering in order to better understand groups that might exist within their taxpayer base. The clustering has divided the taxpayers into three clusters. Four descriptive features have been used to describe each taxpayer:",
            "zh": "3. 一家城市税务局使用 k-means 聚类对个人纳税人进行了聚类，以便更好地了解其纳税人群体中可能存在的群体。该集群将纳税人分为三个集群。我们用四个描述性特征来描述每个纳税人："
        }
    },
    {
        "translation": {
            "en": "where w ·d is the dot product of the vectors w and d. The dot product of two vectors is the sum of the products of their corresponding elements.",
            "zh": "其中 w ·d 是向量 w 和 d 的点积。两个向量的点积是它们对应元素的乘积之和。"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor algorithm delays abstracting from the data until it is asked to make a prediction.",
            "zh": "最近邻算法会延迟从数据中抽象出来，直到被要求进行预测。"
        }
    },
    {
        "translation": {
            "en": "Gleick, James. 2011. The information: A history, a theory, a flood. HarperCollins UK.",
            "zh": "格莱克，詹姆斯。2011. 信息：历史、理论、洪水.英国哈珀柯林斯。"
        }
    },
    {
        "translation": {
            "en": "The advantage of this index ordering becomes clear when we describe how matrix multiplications can be used to speed up the training and inference in neural networks (see Section 8.2.3[390]).",
            "zh": "当我们描述如何使用矩阵乘法来加速神经网络的训练和推理时，这种索引排序的优势就变得很明显了（参见第 8.2.3 节[390]）。"
        }
    },
    {
        "translation": {
            "en": "nodes, 286",
            "zh": "节点，286"
        }
    },
    {
        "translation": {
            "en": "Figure 3.6",
            "zh": "图 3.6"
        }
    },
    {
        "translation": {
            "en": "The algorithm was first proposed, however, as an approach to playing video games in which the only inputs were screenshots of the game.",
            "zh": "然而，该算法最初是作为一种玩视频游戏的方法提出的，其中唯一的输入是游戏的屏幕截图。"
        }
    },
    {
        "translation": {
            "en": "If for di the average intra-cluster distance, a(i), is much smaller than the average inter-cluster distance to members of the nearest next cluster, b(i), then the silhouette width, s(i), will be close to 1 and we can be confident that di really belongs to the cluster in which it has been placed.",
            "zh": "如果对于 di，平均簇内距离 a（i） 远小于到最近的下一个簇 b（i） 成员的平均簇间距离，则轮廓宽度 s（i） 将接近 1，我们可以确信 di 确实属于放置它的簇。"
        }
    },
    {
        "translation": {
            "en": "The sum of a probability distribution must equal 1.0.",
            "zh": "概率分布的总和必须等于 1.0。"
        }
    },
    {
        "translation": {
            "en": "It should be no surprise to learn that the derivative of the function with respect to x also gives us the slope of the function at that value of x.",
            "zh": "知道函数相对于 x 的导数也为我们提供了函数在 x 值处的斜率，这应该不足为奇。"
        }
    },
    {
        "translation": {
            "en": "Logistic regression models also produce confidences along with the predictions, which was attractive to Edwin as it meant that he could build tests into the pipeline that would redirect galaxies with low confidence classifications for manual confirmation of the predictions made by the automated system.",
            "zh": "逻辑回归模型还可以在预测的同时产生置信度，这对 Edwin 很有吸引力，因为这意味着他可以在管道中构建测试，这些测试将重定向具有低置信度分类的星系，以便手动确认自动化系统做出的预测。"
        }
    },
    {
        "translation": {
            "en": "There is growing empirical evidence that creating deeper networks improves the generalization ability of models across a number of tasks.5 However, adding depth to a network comes with a cost.",
            "zh": "越来越多的经验证据表明，创建更深的网络可以提高模型在许多任务中的泛化能力.5 然而，增加网络的深度是有代价的。"
        }
    },
    {
        "translation": {
            "en": "The normal distribution is a member of this location-scale family, with the mean μ specifying the location, and the standard deviation σ acting as the scale parameter.",
            "zh": "正态分布是此位置尺度系列的成员，均值μ指定位置，标准差σ充当尺度参数。"
        }
    },
    {
        "translation": {
            "en": "For example, a 1-NN model has the flexibility to model a discontinuous decision surface; however, it runs into time and space complexity issues as the number of instances grows.",
            "zh": "例如，1-NN 模型可以灵活地对不连续的决策面进行建模;但是，随着实例数量的增加，它会遇到时间和空间复杂性问题。"
        }
    },
    {
        "translation": {
            "en": "Using the δ values you calculated above, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., ∂ℰ/∂w3,2, ∂ℰ/∂w3,0, ∂ℰ/∂w2,1, ∂ℰ/∂w2,0).",
            "zh": "使用上面计算的δ值，计算网络误差对网络每个权重变化的敏感度（即 ∂E/∂w3,2、∂E/∂w3,0、∂E/∂w2,1、∂E/∂w2,0）。"
        }
    },
    {
        "translation": {
            "en": "Also, the total error of the model on the dataset, measured here by the sum of squared errors, has dropped slightly from 0.17921847 to 0.17896823, an error reduction of 0.00025024.",
            "zh": "此外，数据集上模型的总误差（此处通过平方误差之和测量）从 0.17921847 略微下降到 0.17896823，误差减少了 0.00025024。"
        }
    },
    {
        "translation": {
            "en": "We saw in Section 9.4.2[547] how the true positive rate (TPR) and true negative rate (TNR) can be calculated from a confusion matrix.",
            "zh": "我们在第 9.4.2[547] 节中看到了如何从混淆矩阵计算真阳性率 （TPR） 和真阴性率 （TNR）。"
        }
    },
    {
        "translation": {
            "en": "one-hot encoding, 463",
            "zh": "单热编码，463"
        }
    },
    {
        "translation": {
            "en": "Gädenfors, Peter. 2004. Conceptual spaces: The geometry of thought. MIT Press.",
            "zh": "Gädenfors，彼得。2004. 概念空间：思想的几何学.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "These calculations make it apparent that even in this small example domain, the calculation of a probability becomes computationally complex very quickly, particularly when we need to sum out one or more features.",
            "zh": "这些计算清楚地表明，即使在这个小示例域中，概率的计算也很快变得非常复杂，特别是当我们需要总结一个或多个特征时。"
        }
    },
    {
        "translation": {
            "en": "Business",
            "zh": "商"
        }
    },
    {
        "translation": {
            "en": "Table 13.9",
            "zh": "表 13.9"
        }
    },
    {
        "translation": {
            "en": "P_MG",
            "zh": "P_MG"
        }
    },
    {
        "translation": {
            "en": "27. Question 5 in the Exercises section at the end of this chapter explores bagging and random forest ensemble models in more detail, and worked examples are provided in the solution.",
            "zh": "27. 本章末尾的“练习”部分的问题 5 更详细地探讨了装袋和随机森林集成模型，并在解决方案中提供了工作示例。"
        }
    },
    {
        "translation": {
            "en": "Interpretability: In many instances a business will not be happy to simply accept the predictions made by a model and incorporate these into their decision making.",
            "zh": "可解释性：在许多情况下，企业不会乐于简单地接受模型做出的预测并将其纳入决策中。"
        }
    },
    {
        "translation": {
            "en": "In this network, for the neurons in the first hidden layer nin(HL1) = 2 and for neurons in all the other hidden layers nin = 100.",
            "zh": "在这个网络中，对于第一个隐藏层中的神经元，nin（HL1） = 2，对于所有其他隐藏层中的神经元，nin = 100。"
        }
    },
    {
        "translation": {
            "en": "(long)” expands on the “P.D.A.",
            "zh": "（long）“扩展了”P.D.A."
        }
    },
    {
        "translation": {
            "en": "Recall that is the reward received when state st+1 is reached from state st after taking action at.",
            "zh": "回想一下，这是在采取行动后从状态 st 到达状态 st+1 时收到的奖励。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.8[79] shows two examples of using stacked bar plots.",
            "zh": "图3.8[79]显示了使用堆叠条形图的两个示例。"
        }
    },
    {
        "translation": {
            "en": "Using Equation (4.2)[129] and Equation (4.3)[129], we can now formally define information gain made from splitting the dataset 𝒟 using the feature d",
            "zh": "使用方程（4.2）[129]和方程（4.3）[129]，我们现在可以使用特征d正式定义通过拆分数据集D获得的信息增益"
        }
    },
    {
        "translation": {
            "en": "Typically, the number of basis functions in ϕ is larger than the number of descriptive features, so the application of the basis functions moves the data into a higher-dimensional space.",
            "zh": "通常，φ 中基函数的数量大于描述性特征的数量，因此基函数的应用会将数据移动到更高维的空间中。"
        }
    },
    {
        "translation": {
            "en": "8.3.1   Backpropagation: The General Structure of the Algorithm",
            "zh": "8.3.1 反向传播：算法的一般结构"
        }
    },
    {
        "translation": {
            "en": "However, all these models learn a boundary.",
            "zh": "但是，所有这些模型都学习了一个边界。"
        }
    },
    {
        "translation": {
            "en": "In TwentyTwos the player has two actions available to them in each non-terminal state: Stick or Twist.",
            "zh": "在《TwentyTwos》中，玩家在每个非终端状态下有两个动作可供他们使用：Stick或Twist。"
        }
    },
    {
        "translation": {
            "en": "The cell provides a path that carries the activations of the network forward through the time-steps as the network processes a sequence.",
            "zh": "该单元提供了一条路径，当网络处理序列时，该路径通过时间步长将网络的激活向前推进。"
        }
    },
    {
        "translation": {
            "en": "Geometrically, the dot product can be interpreted as equivalent to the cosine of the angle between the two vectors multiplied by the length of the two vectors:",
            "zh": "从几何上讲，点积可以解释为等价于两个向量之间角度的余弦乘以两个向量的长度："
        }
    },
    {
        "translation": {
            "en": "13.1 Business Understanding",
            "zh": "13.1 业务理解"
        }
    },
    {
        "translation": {
            "en": "proportions, 749",
            "zh": "比例，749"
        }
    },
    {
        "translation": {
            "en": "For example, an event in this domain would be represented as Dice1 = , Dice2 = .",
            "zh": "例如，此域中的事件将表示为 Dice1 = ， Dice2 = 。"
        }
    },
    {
        "translation": {
            "en": "Gaussian radial basis kernel, 366",
            "zh": "高斯径向基核，366"
        }
    },
    {
        "translation": {
            "en": "DERED_U/G/R/I/Z",
            "zh": "DERED_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "On the basis of these distances, each instance in is assigned to one of these clusters, as shown in the column labeled Cluster.",
            "zh": "根据这些距离，将中的每个实例分配给其中一个集群，如标记为“集群”的列中所示。"
        }
    },
    {
        "translation": {
            "en": "simple linear regression, 314, 732, 735",
            "zh": "简单线性回归， 314， 732， 735"
        }
    },
    {
        "translation": {
            "en": "Further, to aid in presentation we have rounded the activations for each layer to four decimal places and used these rounded activations as inputs to the later calculations.",
            "zh": "此外，为了便于演示，我们将每层的激活四舍五入到小数点后四位，并将这些四舍五入的激活用作后续计算的输入。"
        }
    },
    {
        "translation": {
            "en": "We use lowercase letters with subscripts to iterate across values in the domain of a feature.",
            "zh": "我们使用带有下标的小写字母来迭代特征域中的值。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also performed a simple first-pass feature selection using the 3-level model to see which features might stand out as predictive of galaxy morphology.",
            "zh": "Jocelyn还使用3级模型进行了简单的首次特征选择，以查看哪些特征可能突出地预测星系形态。"
        }
    },
    {
        "translation": {
            "en": "Table 13.7",
            "zh": "表 13.7"
        }
    },
    {
        "translation": {
            "en": "batch size, 417",
            "zh": "批量大小，417"
        }
    },
    {
        "translation": {
            "en": "1. local receptive fields;",
            "zh": "1.局部感受野;"
        }
    },
    {
        "translation": {
            "en": "The type of the claim and amount of the claim are raw features calculated directly from a claims table contained in one of the insurance company’s operational databases.",
            "zh": "索赔类型和索赔金额是直接从保险公司运营数据库之一中包含的索赔表计算的原始要素。"
        }
    },
    {
        "translation": {
            "en": "This neuron has two large negative weights (w4,0 = −0.19 and w4,2 = −0.13).",
            "zh": "该神经元有两个大的负权重（w4,0 = -0.19 和 w4,2 = -0.13）。"
        }
    },
    {
        "translation": {
            "en": "This is an example of a data issue due to valid data, so if this occurs for features in an ABT, it should be noted in the data quality plan.",
            "zh": "这是由于有效数据导致的数据问题的示例，因此，如果 ABT 中的要素出现这种情况，则应在数据质量计划中注明。"
        }
    },
    {
        "translation": {
            "en": "The customer’s age",
            "zh": "客户的年龄"
        }
    },
    {
        "translation": {
            "en": "Using pruning, Ross was able to increase the average class accuracy on the hold-out test set to 79.03%, a significant improvement over the previous model. Table 12.3[699] shows the confusion matrix from this test. The confusion matrix shows that this model was slightly more accurate when classifying instances with the non-churn target level than with the churn target level. Based on these, results Ross was confident that this tree was a good solution for the AT churn prediction problem.",
            "zh": "使用修剪，Ross 能够将保持测试集的平均类准确率提高到 79.03%，与之前的模型相比有了显着改进。表12.3[699]显示了该测试的混淆矩阵。混淆矩阵显示，在对具有非流失目标级别的实例进行分类时，此模型的准确性略高于使用流失目标级别。基于这些结果，Ross 确信这棵树是 AT 流失预测问题的良好解决方案。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning scenarios where episodes involve long sequences of actions, balancing exploration and exploitation is even more important.",
            "zh": "在强化学习场景中，剧集涉及长序列的动作，平衡探索和利用更为重要。"
        }
    },
    {
        "translation": {
            "en": "This performance is based on a stratified hold-out test set, which contains the same number of churners and non-churners.",
            "zh": "此性能基于分层保留测试集，该测试集包含相同数量的流失者和非流失者。"
        }
    },
    {
        "translation": {
            "en": "There is one partition created for each possible test result, which contains the training instances that returned that result.",
            "zh": "为每个可能的测试结果创建一个分区，其中包含返回该结果的训练实例。"
        }
    },
    {
        "translation": {
            "en": "co-absence (CA), how often a false value occurred for the same feature in both the query data q and the data for the comparison user (d1 or d2)",
            "zh": "共缺 （CA），同一要素在查询数据 q 和比较用户（d1 或 d2）的数据中出现 false 值的频率"
        }
    },
    {
        "translation": {
            "en": "The levels are none, guarantor, and coapplicant.",
            "zh": "级别为无、担保人和共同申请人。"
        }
    },
    {
        "translation": {
            "en": "Confusion matrices, however, cannot be ordered and so cannot be used to rank the performance of the set of models.",
            "zh": "但是，混淆矩阵不能排序，因此不能用于对模型集的性能进行排名。"
        }
    },
    {
        "translation": {
            "en": "value function, 642",
            "zh": "值函数，642"
        }
    },
    {
        "translation": {
            "en": "2. Increases the weights for the instances misclassified by the model using",
            "zh": "2. 增加模型错误分类的实例的权重"
        }
    },
    {
        "translation": {
            "en": "8.8   The per example error after each weight has been updated once, the per example ∂ℰ/∂a8, and the sum of squared errors for the model.",
            "zh": "8.8 每个权重更新一次后的每个示例误差、每个示例 ∂E/∂a8 以及模型的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "long short-term memory, 508",
            "zh": "长短期记忆，508"
        }
    },
    {
        "translation": {
            "en": "The sigmoid activation function outputs values in the range 0 to 1 so that the multiplication of the cell state by the sigmoid layer activations has the effect of pushing all the cell state activations that have a corresponding sigmoid activation near 0 to 0 (i.e., these activations are forgotten) and all the cell state activations that have a corresponding sigmoid activation near 1 to be maintained (i.e., they are remembered) and propagated forward.",
            "zh": "sigmoid 激活函数输出 0 到 1 范围内的值，因此细胞状态乘以 sigmoid 层激活具有将所有具有相应 s 形激活的细胞状态激活推接近 0 到 0（即，这些激活被遗忘）和所有在 1 附近具有相应 s 形激活的细胞状态激活（即 他们被记住）并向前传播。"
        }
    },
    {
        "translation": {
            "en": "Let’s step through Equation (5.16)[219] bit by bit.",
            "zh": "让我们一点一点地完成等式（5.16）[219]。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.33[484] illustrates how the local receptive fields of a set of neurons can be organized so that together they cover the entirety of the input.",
            "zh": "图8.33[484]说明了如何组织一组神经元的局部感受野，以便它们一起覆盖整个输入。"
        }
    },
    {
        "translation": {
            "en": "Should it be based on the distance between the centroids of two clusters, or the distance between the two closest instances in two clusters, or the average distance between all instances in two clusters, or some other method?",
            "zh": "它应该基于两个聚类的质心之间的距离，还是两个聚类中两个最近实例之间的距离，还是两个聚类中所有实例之间的平均距离，还是其他方法？"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16",
            "zh": "图 8.16"
        }
    },
    {
        "translation": {
            "en": "In this chapter we are going to see how this type of reasoning can be implemented as a machine learning algorithm.",
            "zh": "在本章中，我们将了解如何将这种类型的推理实现为机器学习算法。"
        }
    },
    {
        "translation": {
            "en": "6. See Section 3.4[69].",
            "zh": "6. 参见第 3.4 节[69]。"
        }
    },
    {
        "translation": {
            "en": "Cards are worth their number value, with picture cards worth 10, and aces always worth 11 (this is one of the simplifications of this version of the game).",
            "zh": "卡牌值其数字值，图片卡值 10，A 总值 11（这是此版本游戏的简化之一）。"
        }
    },
    {
        "translation": {
            "en": "The ReLU in the first layer has a 3-by-1 receptive field, and there is a stride of 1 used in this layer.",
            "zh": "第一层的 ReLU 具有 3×1 的感受野，并且该层使用的步幅为 1。"
        }
    },
    {
        "translation": {
            "en": "So, in order to maintain the sampling density of the feature space as the number of descriptive features increases, we need to dramatically, indeed, exponentially, increase the number of instances.",
            "zh": "因此，为了随着描述性特征数量的增加而保持特征空间的采样密度，我们需要大幅增加实例的数量。"
        }
    },
    {
        "translation": {
            "en": "7.6 Further Reading",
            "zh": "7.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "In terms of using deep learning for a machine learning task, the first question to ask is whether deep learning is really necessary or appropriate.",
            "zh": "在将深度学习用于机器学习任务方面，首先要问的问题是深度学习是否真的必要或合适。"
        }
    },
    {
        "translation": {
            "en": "From Table 11.3[661] we can see the Q values of the actions available to the agent from the starting state: Q(0-3,up) = −0.308, Q(0-3,down) = 0.247, Q(0-3,left) = 0.963, and Q(0-3,right) = 0.455.",
            "zh": "从表 11.3[661] 中，我们可以看到从起始状态开始代理可用的操作的 Q 值：Q（0-3，up） = −0.308，Q（0-3，down） = 0.247，Q（0-3，left） = 0.963，Q（0-3，right） = 0.455。"
        }
    },
    {
        "translation": {
            "en": "Hastie, T., R. Tibshirani, and J. Friedman. 2001. The elements of statistical learning. Springer.",
            "zh": "Hastie， T.、R. Tibshirani 和 J. Friedman。2001. 统计学习的要素.斯普林格。"
        }
    },
    {
        "translation": {
            "en": "It should also be noted that the range of values for the binary logarithm of a probability, [−∞, 0], is much larger than those taken by the probability itself [0,1].",
            "zh": "还应该注意的是，概率的二进制对数 [−∞， 0] 的值范围比概率本身 [0,1] 取的值范围大得多。"
        }
    },
    {
        "translation": {
            "en": "The output of this layer of neurons is a vector mask, in which each element in the vector is in the range [0,1].",
            "zh": "这层神经元的输出是一个向量掩码，其中向量中的每个元素都在 [0,1] 范围内。"
        }
    },
    {
        "translation": {
            "en": "Successful applications of propensity modeling include predicting the likelihood of customers to leave one mobile phone operator for another, to respond to particular marketing efforts, or to buy different products.",
            "zh": "倾向建模的成功应用包括预测客户离开一个移动电话运营商到另一个移动电话运营商的可能性，响应特定的营销工作或购买不同的产品。"
        }
    },
    {
        "translation": {
            "en": "We can build a model ensemble using any type of prediction model—or indeed, a mixture of model types.",
            "zh": "我们可以使用任何类型的预测模型（或者实际上是模型类型的混合）来构建模型集成。"
        }
    },
    {
        "translation": {
            "en": "There was no obvious relationship, so Jocelyn was confident that removing rows containing missing values would not affect one target level more than the others.",
            "zh": "两者之间没有明显的关系，因此 Jocelyn 确信删除包含缺失值的行不会对某个目标级别产生比其他目标级别更大的影响。"
        }
    },
    {
        "translation": {
            "en": "k-medoids clustering, 601",
            "zh": "K-Medoids聚类，601"
        }
    },
    {
        "translation": {
            "en": "We return subsequently to this vanishing z dynamic to explain in more detail how it arises.",
            "zh": "我们随后回到这个消失的 z 动态，更详细地解释它是如何产生的。"
        }
    },
    {
        "translation": {
            "en": "Investigation of this issue with the business revealed that nothing had gone wrong during the ABT generation process, and that ci refers to car insurance.",
            "zh": "对企业对此问题的调查显示，在 ABT 生成过程中没有任何问题，ci 指的是汽车保险。"
        }
    },
    {
        "translation": {
            "en": "Table 6.3",
            "zh": "表 6.3"
        }
    },
    {
        "translation": {
            "en": "Histograms that follow a normal distribution can also be described as unimodal because they have a single peak around the central tendency.",
            "zh": "遵循正态分布的直方图也可以描述为单峰，因为它们在中心趋势附近有一个峰。"
        }
    },
    {
        "translation": {
            "en": "smoothing, 243, 265, 266, 282",
            "zh": "平滑， 243， 265， 266， 282"
        }
    },
    {
        "translation": {
            "en": "In order to plan the expedition for the next day, you decide that you need to classify the animal so that you can determine whether it is dangerous to approach it or not.",
            "zh": "为了计划第二天的探险，您决定需要对动物进行分类，以便确定接近它是否危险。"
        }
    },
    {
        "translation": {
            "en": "(c) What target level would a weighted k-NN model with k = 5 and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query, return for the query?",
            "zh": "（c） k = 5 并使用邻域和查询之间欧几里得距离平方的倒数加权方案的加权方案，查询的目标水平是多少？"
        }
    },
    {
        "translation": {
            "en": "If we are calculating the probability of a single event given some evidence, then calculating P(Y) directly from the data using Equation (6.2)[248] is the easier option.",
            "zh": "如果我们在给定一些证据的情况下计算单个事件的概率，那么使用方程（6.2）[248]直接从数据中计算P（Y）是更简单的选择。"
        }
    },
    {
        "translation": {
            "en": "Each of the four figures in Figure 8.23[453] uses side-by-side violin plots32 to illustrate the distribution of a network property (weights, weighted sums, activations, or δs) across the five hidden layers in the architecture during the first training iteration.",
            "zh": "图 8.23[453] 中的四个图中的每一个都使用并排的小提琴图32来说明在第一次训练迭代期间，网络属性（权重、加权和、激活或 δ）在架构中五个隐藏层中的分布。"
        }
    },
    {
        "translation": {
            "en": "All standard PDFs have parameters that alter the shape of the density curve defining that distribution.",
            "zh": "所有标准 PDF 都具有改变定义该分布的密度曲线形状的参数。"
        }
    },
    {
        "translation": {
            "en": "K2 score, 293",
            "zh": "K2 分数，293"
        }
    },
    {
        "translation": {
            "en": "ethics, 47",
            "zh": "伦理学，47"
        }
    },
    {
        "translation": {
            "en": "The probability of a joint event is simply the relative frequency of the joint event within the dataset.",
            "zh": "联合事件的概率只是数据集中联合事件的相对频率。"
        }
    },
    {
        "translation": {
            "en": "For example, assuming that we continue to train the network on just our small sample dataset with α = 0.2 and updating the weights after each pass through our data, then the training of the network would converge to an SSE < 0.0001 after 7,656 epochs.22 Table 8.9[433] lists the model predictions for each of the examples and the calculation of the sum of squared errors once training has converged.",
            "zh": "例如，假设我们继续在α = 0.2的小样本数据集上训练网络，并在每次通过我们的数据后更新权重，那么网络的训练将在7,656个周期后收敛到SSE <0.0001.22表8.9[433]列出了每个示例的模型预测以及训练收敛后误差平方和的计算。"
        }
    },
    {
        "translation": {
            "en": "FAQ: Did the user read the frequently asked questions page?",
            "zh": "常见问题解答：用户是否阅读了常见问题页面？"
        }
    },
    {
        "translation": {
            "en": "mixture of Gaussians distribution, 270, 274",
            "zh": "高斯分布的混合，270,274"
        }
    },
    {
        "translation": {
            "en": "Features that have no correlation are said to be independent.",
            "zh": "没有相关性的特征被称为独立的。"
        }
    },
    {
        "translation": {
            "en": "If the error gradient (the derivative) becomes too large, then the weights will be updated by a large amount, and the resulting changes in the output of a neuron, from one iteration to the next, will be so large that the training will become unstable.28 Conversely, if weights are very small (too close to 0), then the error gradient will tend to vanish, and the weight updates will be so small that training the network will take an inordinate amount of time.",
            "zh": "如果误差梯度（导数）变得太大，那么权重将大量更新，并且从一次迭代到下一次迭代的神经元输出的最终变化将如此之大，以至于训练将变得不稳定.28相反，如果权重非常小（太接近0），那么误差梯度将趋于消失， 而且权重更新将如此之小，以至于训练网络将花费过多的时间。"
        }
    },
    {
        "translation": {
            "en": "The customer retention team contacts these customers with special offers designed to entice them to stay with AT.",
            "zh": "客户保留团队会通过特别优惠联系这些客户，以吸引他们留在 AT 公司。"
        }
    },
    {
        "translation": {
            "en": "In some cases the observation period and outcome period are measured over the same time for all prediction subjects.",
            "zh": "在某些情况下，观察期和结果期是在同一时间测量所有预测对象的。"
        }
    },
    {
        "translation": {
            "en": "Finally, on the basis of cumulative gain scores, which model would you recommend the company use for the pre-annotation filtering task?",
            "zh": "最后，根据累积增益分数，您会推荐公司使用哪种模型进行预注释过滤任务？"
        }
    },
    {
        "translation": {
            "en": "Figures 3.10(c)[80] and 3.10(d)[80] show a similar pair of visualizations for the HEIGHT and POSITION features. Figure 3.10(d)[80] is typical of a series of box plots showing a strong relationship between a continuous and a categorical feature. We can see that the average height of centers is above that of forwards, which in turn is above that of guards. Although the whiskers show that there is some overlap between the three groups, they do appear to be well separated.",
            "zh": "图 3.10（c）[80] 和 3.10（d）[80] 显示了 HEIGHT 和 POSITION 特征的一对类似可视化。图3.10（d）[80]是一系列箱形图的典型特征，显示了连续特征和分类特征之间的强关系。我们可以看到，中锋的平均身高高于前锋，而前锋又高于后卫。尽管胡须显示这三组之间存在一些重叠，但它们似乎确实分开得很好。"
        }
    },
    {
        "translation": {
            "en": "Note that the decision boundaries in these examples are equally positioned between positive and negative instances, which is a consequence of the fact that decision boundaries satisfy these constraints.",
            "zh": "请注意，这些示例中的决策边界在正实例和负实例之间位置相同，这是决策边界满足这些约束的结果。"
        }
    },
    {
        "translation": {
            "en": "The easiest way to handle a continuous descriptive feature in a decision tree is to define a threshold within the range of values that the continuous feature can take and to use this threshold to partition the instances on the basis of whether their values for the feature are above or below the threshold.13 The only challenge is to determine the best threshold to use.",
            "zh": "在决策树中处理连续描述性特征的最简单方法是在连续特征可以采用的值范围内定义一个阈值，并使用此阈值根据实例的特征值是高于还是低于阈值来对实例进行分区。13 唯一的挑战是确定要使用的最佳阈值。"
        }
    },
    {
        "translation": {
            "en": "(a) The changing values of TPR and TNR for the test data shown in Table 9.13[560] as the threshold is altered; and (b) points in ROC space for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "（a） 表9.13[560]所示测试数据的TPR和TNR值随着阈值的改变而变化;（b） ROC 空间中阈值为 0.25、0.5 和 0.75 的点。"
        }
    },
    {
        "translation": {
            "en": "10. The instances have been arranged in an order that leads to a nice dendrogram visualization, and this was also the order used in the distance matrices to make it easy to follow the combination of instances into clusters.",
            "zh": "10. 实例的排列顺序导致了良好的树状图可视化，这也是距离矩阵中使用的顺序，以便于将实例组合成集群。"
        }
    },
    {
        "translation": {
            "en": "The outliers present in the CLAIM AMOUNT and AMOUNT RECEIVED features could be easily handled using a clamp transformation.",
            "zh": "CLAIM AMOUNT 和 AMOUNT RECEIVED 特征中存在的异常值可以使用钳位变换轻松处理。"
        }
    },
    {
        "translation": {
            "en": "This was a reasonably straightforward process with just a few issues that needed discussion.",
            "zh": "这是一个相当简单的过程，只有几个问题需要讨论。"
        }
    },
    {
        "translation": {
            "en": "PETROMAG_U/G/R/I/Z",
            "zh": "PETROMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems 27: Annual conference on neural information processing systems 2014, December 8–13, 2014, Montreal, Quebec, Canada, 2672–2680.",
            "zh": "Goodfellow、Ian、Jean Pouget-Abadie、Mehdi Mirza、Bing Xu、David Warde-Farley、Sherjil Ozair、Aaron Courville 和 Yoshua Bengio。2014. 生成对抗网络.神经信息处理系统进展 27：2014 年神经信息处理系统年会，2014 年 12 月 8 日至 13 日，加拿大魁北克省蒙特利尔，2672–2680。"
        }
    },
    {
        "translation": {
            "en": "Using the factors in Equation (6.15)[259], we calculate the posterior distribution for meningitis given the query instance using Equation (6.14)[258] as",
            "zh": "使用等式（6.15）[259]中的因子，我们使用等式（6.14）[258]计算给定查询实例的脑膜炎的后验分布，如下所示"
        }
    },
    {
        "translation": {
            "en": "(a) The set of cards after the wind blows over the one on the right; (b) the revised likelihoods for the position of the queen based on this new evidence; and (c) the final positions of the cards in the game.",
            "zh": "（a） 风吹过右边的那套牌;（b） 根据这些新证据修订女王职位的可能性;及（c）牌在游戏中的最终位置。"
        }
    },
    {
        "translation": {
            "en": "Although weight initialization is clearly important, at present relatively little is known in principle about how to select a good set of initial weights.",
            "zh": "尽管权重初始化显然很重要，但目前原则上对如何选择一组好的初始权重知之甚少。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.8",
            "zh": "图 2.8"
        }
    },
    {
        "translation": {
            "en": "1,900",
            "zh": "1,900"
        }
    },
    {
        "translation": {
            "en": "In order to update the weights on the connections coming into a neuron, we must connect the rate of change of the error of the network to changes in each weight.",
            "zh": "为了更新进入神经元的连接的权重，我们必须将网络误差的变化率与每个权重的变化联系起来。"
        }
    },
    {
        "translation": {
            "en": "9.4.3.3 Measuring gain and lift In scenarios in which we have a positive target level that we are especially interested in (for example, spam emails, fraudulent transactions, or customers who will respond to an offer), it can often be useful to focus in on how well a model is making predictions for just those instances, rather than how well the model is distinguishing between two target levels.",
            "zh": "9.4.3.3 衡量增益和提升 在我们有一个我们特别感兴趣的积极目标水平（例如，垃圾邮件、欺诈易或将响应报价的客户）的情况下，关注模型对这些实例的预测程度，而不是模型区分两个目标水平的程度，通常是有用的。"
        }
    },
    {
        "translation": {
            "en": "Algorithms, Worked Examples, and Case Studies",
            "zh": "算法、工作示例和案例研究"
        }
    },
    {
        "translation": {
            "en": "We will see in forthcoming chapters that using binning to transform a continuous feature into a categorical feature is often the easiest way for some of the machine learning approaches to handle a continuous feature.",
            "zh": "在接下来的章节中，我们将看到，使用分箱将连续特征转换为分类特征通常是某些机器学习方法处理连续特征的最简单方法。"
        }
    },
    {
        "translation": {
            "en": "12. Interested readers might find Tempel et al. (2011), Ball et al. (2004) and Banerji et al. (2010) good references on this topic.",
            "zh": "12. 有兴趣的读者可能会发现 Tempel et al. （2011）、Ball et al. （2004） 和 Banerji et al. （2010） 关于这一主题的良好参考资料。"
        }
    },
    {
        "translation": {
            "en": "The first is related to anti-discrimination legislation.",
            "zh": "第一个问题与反歧视立法有关。"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm works in exactly the same way for larger, more complicated datasets; there is simply more computation involved. Since it was first proposed, there have been many modifications to the original ID3 algorithm to handle variations that are common in real-world datasets. We explore the most important of these modifications in the following sections.",
            "zh": "ID3 算法的工作方式与更大、更复杂的数据集完全相同;只是涉及更多的计算。自首次提出以来，对原始 ID3 算法进行了许多修改，以处理现实世界数据集中常见的变化。我们将在以下各节中探讨这些修改中最重要的内容。"
        }
    },
    {
        "translation": {
            "en": "2.5   Modeling points in time using an observation period and an outcome period.",
            "zh": "2.5 使用观察期和结果期对时间点进行建模。"
        }
    },
    {
        "translation": {
            "en": "Deep Q networks are a temporal-difference based approach that use a deep neural network to learn a generalize action-value function.",
            "zh": "深度 Q 网络是一种基于时间差分的方法，它使用深度神经网络来学习广义动作值函数。"
        }
    },
    {
        "translation": {
            "en": "Neapolitan, Richard E. 2004. Learning Bayesian networks. Pearson Prentice Hall.",
            "zh": "那不勒斯人，理查德 E. 2004 年。学习贝叶斯网络。皮尔逊·普伦蒂斯·霍尔（Pearson Prentice Hall）。"
        }
    },
    {
        "translation": {
            "en": "Because of the dense fog, it is not possible for her to see the way to her destination at the bottom of the valley.",
            "zh": "由于浓雾，她无法看到山谷底部通往目的地的路。"
        }
    },
    {
        "translation": {
            "en": "35. Learning rate values are typically in (0, 1], and gradient boosting implementations that use a learning rate often refer to it as incremental shrinkage.",
            "zh": "35. 学习率值通常在 （0， 1） 中，使用学习率的梯度提升实现通常将其称为增量收缩。"
        }
    },
    {
        "translation": {
            "en": "Different randomly selected starting points can lead to different, often sub-optimal, clusterings.",
            "zh": "随机选择的不同起点可能导致不同的、通常是次优的聚类。"
        }
    },
    {
        "translation": {
            "en": "This error is then backpropagated through the unrolled network, in the same way that ℰt=3 is backpropagated in Figure 8.39[506] resulting in a single error gradient for each weight in Wyh and three separate error gradients for each weight in Whh and Whx.",
            "zh": "然后，该误差通过展开的网络进行反向传播，就像图8.39[506]中Et=3的反向传播方式一样，导致Wyh中的每个权重都有一个误差梯度，Whh和Whx中的每个权重都有三个单独的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Table 7.5",
            "zh": "表 7.5"
        }
    },
    {
        "translation": {
            "en": "(2015) introduced the Parametric ReLU (PReLU) for which the main distinction from the Leaky ReLU was that rather than using a fixed predefined gradient for z ≤ 0, this gradient can be learned as a parameter for each neuron in the network.",
            "zh": "（2015）引入了参数化ReLU（PReLU），其与Leaky ReLU的主要区别在于，该梯度可以作为网络中每个神经元的参数来学习，而不是使用z≤0的固定预定义梯度。"
        }
    },
    {
        "translation": {
            "en": "7.2.2   Measuring Error",
            "zh": "7.2.2 测量误差"
        }
    },
    {
        "translation": {
            "en": "Guo, Yanming, Yu Liu, Ard Oerlemans, Songyang Lao, Song Wu, and Michael S. Lew. 2016. Deep learning for visual understanding: A review. Neurocomputing 187: 27–48.",
            "zh": "Guo， Yanming， Yu Liu， Ard Oerlemans， Songyang Lao， Song Wu， and Michael S. Lew.2016. 视觉理解的深度学习：综述.神经计算187：27-48。"
        }
    },
    {
        "translation": {
            "en": "As well as being simple to understand and computationally efficient, it is also quite effective and often a good solution to clustering problems.",
            "zh": "除了易于理解和计算效率高之外，它还非常有效，通常是聚类问题的好方法。"
        }
    },
    {
        "translation": {
            "en": "To do this we simply sum the values in the cells containing h, in other words, the cells in the first column of the distribution.",
            "zh": "为此，我们只需对包含 h 的单元格中的值求和，换句话说，就是分布第一列中的单元格。"
        }
    },
    {
        "translation": {
            "en": "CPT, 286",
            "zh": "CPT，286"
        }
    },
    {
        "translation": {
            "en": "Second, performance measured using hold-out sampling can be misleading if we happen to make a lucky split of the data that places the difficult instances into the training set and the easy ones into the test set.",
            "zh": "其次，如果我们碰巧幸运地将数据拆分，将困难的实例放入训练集，将简单的实例放入测试集，则使用保持抽样测量的性能可能会产生误导。"
        }
    },
    {
        "translation": {
            "en": "false negative rate, 548",
            "zh": "假阴性率，548"
        }
    },
    {
        "translation": {
            "en": "The process used to calculate the term ∂ℰ/∂ak for a neuron k is dependent on whether the neuron is in the output layer or in one of the hidden layers of the network.",
            "zh": "用于计算神经元 k 的术语 ∂E/∂ak 的过程取决于神经元是在输出层还是在网络的隐藏层之一中。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the standard practice in deep learning is to use mini-batch gradient descent.",
            "zh": "因此，深度学习的标准做法是使用小批量梯度下降。"
        }
    },
    {
        "translation": {
            "en": "P(t = l) is simply the relative frequency with which the target feature takes the level l in a dataset.",
            "zh": "P（t = l） 只是目标要素在数据集中达到 l 级的相对频率。"
        }
    },
    {
        "translation": {
            "en": "4. The use of the kernel trick is key in writing efficient implementations of the support vector machine approach to predictive modelling. The kernel trick is based on the fact that the result of a kernel function applied to a support vector and a query instance is equivalent to the result of calculating the dot product between the support vector and the query instance after a specific set of basis functions have been applied to both—in other words, kernel(d, q) = ϕ(d) · ϕ(q).",
            "zh": "4. 核技巧的使用是编写支持向量机预测建模方法的有效实现的关键。内核技巧基于这样一个事实，即应用于支持向量和查询实例的内核函数的结果等效于在将一组特定的基函数应用于支持向量和查询实例之后计算点积的结果，换句话说， 内核（d， q） = φ（d） ·φ（q）。"
        }
    },
    {
        "translation": {
            "en": "The other important distinction that is often made between classification models is whether they are generative or discriminative.",
            "zh": "分类模型之间经常出现的另一个重要区别是它们是生成性的还是歧视性的。"
        }
    },
    {
        "translation": {
            "en": "Gleick (2011) provides an excellent and accessible introduction to information theory and its history. Shannon and Weaver (1949) is taken as the foundational book in information theory, and Cover and Thomas (1991) is a well-regarded textbook on the topic. MacKay (2003) is an excellent textbook on information theory and machine learning.",
            "zh": "Gleick（2011）对信息论及其历史进行了出色且易于理解的介绍。Shannon and Weaver （1949） 被认为是信息论的基础书籍，而 Cover and Thomas （1991） 是一本关于该主题的广受好评的教科书。MacKay （2003）是一本关于信息论和机器学习的优秀教科书。"
        }
    },
    {
        "translation": {
            "en": "Calculate the sum of squared errors for this network for this example.",
            "zh": "在此示例中，计算此网络的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "range normalization, 87, 87, 101, 206, 322, 340, 342, 374, 375, 421, 422",
            "zh": "范围归一化， 87， 87， 101， 206， 322， 340， 342， 374， 375， 421， 422"
        }
    },
    {
        "translation": {
            "en": "The right side of Figure 8.5[392] illustrates the sequence of matrix operations that this network would carry out to process a single input vector.",
            "zh": "图 8.5[392] 的右侧说明了该网络为处理单个输入向量而执行的矩阵操作序列。"
        }
    },
    {
        "translation": {
            "en": "HEALTH: Health spending as a percentage of GDP",
            "zh": "卫生：卫生支出占国内生产总值的百分比"
        }
    },
    {
        "translation": {
            "en": "Eventually, the algorithm will converge to a point on the error surface where any subsequent changes to weights do not lead to a noticeably better model (within some tolerance).",
            "zh": "最终，该算法将收敛到误差曲面上的一个点，在该点上，任何后续的权重变化都不会导致明显更好的模型（在一定的公差范围内）。"
        }
    },
    {
        "translation": {
            "en": "These missing values are due to valid data, so they do not need to be handled but should instead be recorded in the data quality plan.",
            "zh": "这些缺失值是由于有效数据造成的，因此不需要处理它们，而应记录在数据质量计划中。"
        }
    },
    {
        "translation": {
            "en": "We will, however, be specific in distinguishing between metrics and indexes.",
            "zh": "但是，我们将具体区分指标和索引。"
        }
    },
    {
        "translation": {
            "en": "These were all as the business expected.",
            "zh": "这些都符合企业的预期。"
        }
    },
    {
        "translation": {
            "en": "where d is a set of descriptive features for an instance; w is the set of weights in the model; and the good and faulty generator target feature levels are represented as 0 and 1 respectively. Figure 7.11(b)[341] shows the value of Equation (7.24)[341] for every possible value of RPM and VIBRATION. This surface is known as a decision surface.",
            "zh": "其中 d 是实例的一组描述性特征;w 是模型中的权重集;良好和故障生成器目标特征级别分别表示为 0 和 1。图7.11（b）[341]显示了RPM和VIBRATION每个可能值的公式（7.24）[341]的值。此曲面称为决策曲面。"
        }
    },
    {
        "translation": {
            "en": "We can see that the misclassification rate doesn’t change that much as the threshold changes.",
            "zh": "我们可以看到，误分类率的变化不会随着阈值的变化而变化。"
        }
    },
    {
        "translation": {
            "en": "—Edge of Tomorrow",
            "zh": "——《明日边缘》"
        }
    },
    {
        "translation": {
            "en": "In other words, small changes in descriptive features result in small changes in the target feature.",
            "zh": "换言之，描述性特征的微小变化会导致目标特征的微小变化。"
        }
    },
    {
        "translation": {
            "en": "This calculation is known as a weighted sum because it involves summing the weighted inputs.",
            "zh": "此计算称为加权总和，因为它涉及对加权输入求和。"
        }
    },
    {
        "translation": {
            "en": "Full details of all the data tables available from the SDSS are available at skyserver.sdss3.org/dr9/en/help/docs/tabledesc.asp.",
            "zh": "SDSS提供的所有数据表的完整详细信息可在 skyserver.sdss3.org/dr9/en/help/docs/tabledesc.asp 上找到。"
        }
    },
    {
        "translation": {
            "en": "data subject, 40",
            "zh": "数据主体，40"
        }
    },
    {
        "translation": {
            "en": "At this point Ross just made note of these outliers as something he might have to deal with during the modeling phase.",
            "zh": "在这一点上，Ross 只是注意到了这些异常值，这是他在建模阶段可能必须处理的事情。"
        }
    },
    {
        "translation": {
            "en": "We can see from the information in Table 4.4[137] that ELEVATION has the largest information gain of the three features and therefore is selected by the algorithm at the root node of the tree.",
            "zh": "从表4.4[137]中的信息可以看出，ELEVATION在三个特征中具有最大的信息增益，因此是由算法在树的根节点处选择的。"
        }
    },
    {
        "translation": {
            "en": "The design of the book is informed by our many years of experience in teaching machine learning, and the approach and material in the book has been developed and “road-tested” in the classroom. In writing this book, we have adopted the following guiding principles to make the material accessible:",
            "zh": "本书的设计基于我们多年的机器学习教学经验，书中的方法和材料已经在课堂上开发和“道路测试”。在撰写本书时，我们采用了以下指导原则，使材料易于访问："
        }
    },
    {
        "translation": {
            "en": "A model could be built to predict the amount most likely to be paid out by an insurance company after having investigated a claim.",
            "zh": "可以建立一个模型来预测保险公司在调查索赔后最有可能支付的金额。"
        }
    },
    {
        "translation": {
            "en": "3. To fully understand how a model is performing, it can often be useful to look beyond a single performance measure.",
            "zh": "3. 为了充分了解模型的性能，超越单一的性能度量通常很有用。"
        }
    },
    {
        "translation": {
            "en": "The business was interested in the features that were selected as important to the tree, and there was a good deal of discussion on the omission of the features describing customers’ interactions with AT customer care (these had been the basis of the organization’s previous model).",
            "zh": "该业务部门对被选为对树很重要的特征感兴趣，并且对省略描述客户与 AT 客户服务交互的特征进行了大量讨论（这些是该组织先前模型的基础）。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from this test is shown in Table 13.8[724].",
            "zh": "该测试的混淆矩阵如表13.8[724]所示。"
        }
    },
    {
        "translation": {
            "en": "As part of a medical decision making system, a prediction system that can automatically determine the orientation of chest X-rays (the orientations can be lateral or frontal) is built.4 Based on a full dataset of 1,000 instances, we decide to evaluate the performance of this system with classification accuracy using 5-fold cross validation.",
            "zh": "作为医疗决策系统的一部分，构建了一个可以自动确定胸部X光片方向（方向可以是横向或正面）的预测系统.4基于1,000个实例的完整数据集，我们决定使用5倍交叉验证来评估该系统的性能和分类精度。"
        }
    },
    {
        "translation": {
            "en": "The data quality report tables are shown in Table 12.2[694].",
            "zh": "数据质量报告表如表12.2[694]所示。"
        }
    },
    {
        "translation": {
            "en": "The accuracy for the model associated with the confusion matrix shown in Table 9.5[551] is 91%, while for the model associated with the confusion matrix shown in Table 9.6[551], the accuracy is just 78%.",
            "zh": "与表9.5[551]所示的混淆矩阵相关的模型的准确率为91%，而对于与表9.6[551]所示的混淆矩阵相关的模型，准确率仅为78%。"
        }
    },
    {
        "translation": {
            "en": "Due to the inclusion of the squared term, the root mean squared error tends to overestimate error slightly as it overemphasizes individual large errors. An alternative measure that addresses this problem is the mean absolute error (MAE), which does not include a squared term.22 Mean absolute error is calculated as",
            "zh": "由于包含平方项，均方根误差往往会略微高估误差，因为它过分强调单个大误差。解决此问题的另一种度量是平均绝对误差 （MAE），它不包括平方项。22 平均绝对误差的计算公式为"
        }
    },
    {
        "translation": {
            "en": "Once we have stored the instances in a dataset in a k-d tree, we can use the tree to quickly retrieve the nearest neighbor for a query instance.",
            "zh": "一旦我们将实例存储在 k-d 树的数据集中，我们就可以使用该树快速检索查询实例的最近邻居。"
        }
    },
    {
        "translation": {
            "en": "After lengthy discussion, both Jocelyn and Edwin agreed that in order for the system to be useful, a classification accuracy of approximately 80% would be required.",
            "zh": "经过长时间的讨论，Jocelyn 和 Edwin 一致认为，为了使该系统有用，需要大约 80% 的分类准确率。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16[430] shows the network with each neuron labeled with its corresponding δ.",
            "zh": "图8.16[430]显示了每个神经元都标有其相应δ的网络。"
        }
    },
    {
        "translation": {
            "en": "7. See Section 4.2.3[127].",
            "zh": "7. 参见第 4.2.3 节[127]。"
        }
    },
    {
        "translation": {
            "en": "In the second tree that he built, Ross employed post-pruning using reduced error pruning,8 which used the validation partition that was created from the initial dataset.",
            "zh": "在他构建的第二棵树中，Ross 使用减少误差修剪 8 进行后修剪，该修剪使用从初始数据集创建的验证分区。"
        }
    },
    {
        "translation": {
            "en": "In other words, the general rule that is induced from a sample may not be true for all instances in a population.",
            "zh": "换言之，从样本中得出的一般规则可能不适用于总体中的所有实例。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.24",
            "zh": "图 7.24"
        }
    },
    {
        "translation": {
            "en": "So, for example, Figure 9.15(b)[569] shows that by the 4th decile (40% of the test data), 66.667% of the spam emails in the entire test set will have been identified.",
            "zh": "因此，例如，图 9.15（b）[569] 显示，到第 4 个十分位数（占测试数据的 40%）时，整个测试集中 66.667% 的垃圾邮件将被识别。"
        }
    },
    {
        "translation": {
            "en": "Each machine learning algorithm uses different model selection criteria to drive its search for the best predictive model.",
            "zh": "每种机器学习算法都使用不同的模型选择标准来推动其对最佳预测模型的搜索。"
        }
    },
    {
        "translation": {
            "en": "Together these descriptive features will make up the ABT.",
            "zh": "这些描述性特征将共同构成 ABT。"
        }
    },
    {
        "translation": {
            "en": "22. The conditional independence relationship between any two nodes in a Bayesian network can be specified using the framework of d-separation (the “d” stands for directed) (Pearl, 1988). We don’t discuss d-separation in this book as it is not required for our discussion.",
            "zh": "22. 贝叶斯网络中任意两个节点之间的条件独立关系可以使用 d 分离框架（“d”代表有向）来指定（Pearl，1988）。在本书中，我们没有讨论 d-分离，因为我们的讨论不需要它。"
        }
    },
    {
        "translation": {
            "en": "1. They build multiple different models from the same dataset by inducing each model using a modified version of the dataset.",
            "zh": "1. 他们通过使用数据集的修改版本诱导每个模型，从同一数据集构建多个不同的模型。"
        }
    },
    {
        "translation": {
            "en": "This is done by incrementally adapting the dataset used to train the models.",
            "zh": "这是通过逐步调整用于训练模型的数据集来完成的。"
        }
    },
    {
        "translation": {
            "en": "The customer retention team monitors the number of calls made to the AT customer support center by each customer and identifies the customers who make a large number of customer support calls as churn risks.",
            "zh": "客户保留团队监控每个客户向 AT 客户支持中心拨打的电话数量，并将拨打大量客户支持电话的客户识别为流失风险。"
        }
    },
    {
        "translation": {
            "en": "Conversely, a proportion of (100 − i)/100 values in a sample take values larger than the ith percentile.",
            "zh": "相反，样本中 （100 − i）/100 个值的比例取的值大于第 i 个百分位数。"
        }
    },
    {
        "translation": {
            "en": "The coordinate systems defined by the Mahalanobis distance using the covariance matrix for the dataset in Figure 5.15(c)[219] using three different origins: (a) (50,50); (b) (63,71); and (c) (42,35). The ellipses in each figure plot the 1, 3, and 5 unit distance contours.",
            "zh": "使用图5.15（c）[219]中数据集的协方差矩阵定义的马氏距离的坐标系，使用三个不同的原点：（a）（50,50）;（b）（63,71）;以及（c）（42,35）。每个图中的椭圆绘制了 1、3 和 5 单位距离等值线。"
        }
    },
    {
        "translation": {
            "en": "If the current estimate is higher than the actual return, then the estimate is lowered slightly, and vice versa.",
            "zh": "如果当前估计值高于实际回报，则估计值会略有降低，反之亦然。"
        }
    },
    {
        "translation": {
            "en": "Structure of the Book",
            "zh": "本书的结构"
        }
    },
    {
        "translation": {
            "en": "To help with situational fluency for this scenario, here is a brief outline of how companies interact with the revenue commission.",
            "zh": "为了帮助在这种情况畅地了解情况，以下是公司如何与收入委员会互动的简要概述。"
        }
    },
    {
        "translation": {
            "en": "0.60",
            "zh": "0.60"
        }
    },
    {
        "translation": {
            "en": "How does the business currently work?",
            "zh": "该业务目前如何运作？"
        }
    },
    {
        "translation": {
            "en": "2.4.3 Handling Time",
            "zh": "2.4.3 处理时间"
        }
    },
    {
        "translation": {
            "en": "For example, in the churn prediction example, correctly classifying a customer as likely to churn is worth the same as correctly classifying a customer as not likely to churn.",
            "zh": "例如，在客户流失预测示例中，将客户正确分类为可能流失与正确将客户分类为不太可能流失的价值相同。"
        }
    },
    {
        "translation": {
            "en": "This dataset has been prepared by an analytics team who are developing a model as a decision support tool for doctors.16 The goal of the model is to classify individuals into groups on the basis of their risk of suffering a stroke STROKE RISK.",
            "zh": "该数据集由一个分析团队准备，他们正在开发一个模型作为医生的决策支持工具.16 该模型的目标是根据个人患中风的风险将个人分类为中风风险。"
        }
    },
    {
        "translation": {
            "en": "We can illustrate the speed up in training that can be achieved by switching a network from using the logistic activation function to a rectified linear activation function if we compare the number of epochs required for the network from the worked example to converge to an SSE < 0.0001 when it uses ReLUs instead of logistic units.",
            "zh": "如果我们比较网络从工作示例收敛到 SSE 所需的纪元数，当它使用 ReLU 而不是逻辑单元时，< 0.0001，我们可以说明通过将网络从使用逻辑激活函数切换到修正线性激活函数可以实现的训练速度。"
        }
    },
    {
        "translation": {
            "en": "For example, a categorical feature storing gender with a cardinality of 6 is worthy of further investigation.",
            "zh": "例如，存储基数为 6 的性别的分类特征值得进一步研究。"
        }
    },
    {
        "translation": {
            "en": "and spending time designing the evaluation process correctly.",
            "zh": "并花时间正确设计评估过程。"
        }
    },
    {
        "translation": {
            "en": "artificial neuron, 383",
            "zh": "人工神经元，383"
        }
    },
    {
        "translation": {
            "en": "outliers, 63, 65, 87, 91, 94, 696, 745, 755",
            "zh": "异常值、63、65、87、91、94、696、745、755"
        }
    },
    {
        "translation": {
            "en": "3.3.3 Outliers",
            "zh": "3.3.3 异常值"
        }
    },
    {
        "translation": {
            "en": "However, this is not the only vector of error gradients that are backpropagated; recall, the ∂ℰt/∂ct−1 is also backpropagated to the previous time-step.",
            "zh": "然而，这并不是反向传播的误差梯度的唯一向量;回想一下，∂Et/∂ct−1 也被反向传播到上一个时间步长。"
        }
    },
    {
        "translation": {
            "en": "(a) The speed of a car during a journey along a minor road before joining a highway and finally coming to a sudden halt; and (b) the acceleration, the derivative of speed with respect to time, for this journey.",
            "zh": "（a） 汽车在进入高速公路并最终突然停下来之前沿一条小路行驶时的速度;（b）加速度，即速度相对于时间的导数。"
        }
    },
    {
        "translation": {
            "en": "The name inverted dropout comes from this division of the non-zeroed activations by the ρ parameter.",
            "zh": "倒置辍学的名称来自非归零激活除以 ρ 参数。"
        }
    },
    {
        "translation": {
            "en": "The disadvantage is that these approaches can struggle to learn very long-term strategies in which reward does not accrue until long after actions have been taken.",
            "zh": "缺点是，这些方法可能很难学习非常长期的策略，在这些策略中，奖励直到采取行动很久之后才会累积。"
        }
    },
    {
        "translation": {
            "en": "sequential gradient descent, 415",
            "zh": "顺序梯度下降，415"
        }
    },
    {
        "translation": {
            "en": "Figure 4.1[118] shows the set of cards that we will use for our game.",
            "zh": "图 4.1[118] 显示了我们将用于游戏的卡牌集。"
        }
    },
    {
        "translation": {
            "en": "Given a large population of independent models, an ensemble can be very accurate, even if the individual models in the ensemble perform only marginally better than random guessing.",
            "zh": "给定大量独立模型，即使集成中的单个模型仅比随机猜测略好，集成也可以非常准确。"
        }
    },
    {
        "translation": {
            "en": "Therefore, if the entire training set is presented to this model, its performance will appear to be perfect.",
            "zh": "因此，如果将整个训练集呈现给此模型，则其性能将看起来很完美。"
        }
    },
    {
        "translation": {
            "en": "The calculation of the z values and activations of each neuron during the forward pass of the backpropagation algorithm. This figure is based on Figure 6.5 of Kelleher (2019).",
            "zh": "在反向传播算法的前向传递过程中计算每个神经元的 z 值和激活。该数字基于Kelleher（2019）的图6.5。"
        }
    },
    {
        "translation": {
            "en": "The online store would like to cluster their customers to see if they could define meaningful groups to whom they could target special offers. The table below shows a distance matrix calculated using the Jaccard similarity measure (see Section 5.4.5[211]). A number of items have been left out of this matrix (indicated by ??).",
            "zh": "在线商店希望将他们的客户聚集在一起，看看他们是否可以定义有意义的群体，他们可以针对这些群体提供特别优惠。下表显示了使用 Jaccard 相似度度量计算的距离矩阵（参见第 5.4.5 节 [211]）。许多项目已被排除在该矩阵之外（用 ？？"
        }
    },
    {
        "translation": {
            "en": "Table 5.5",
            "zh": "表 5.5"
        }
    },
    {
        "translation": {
            "en": "Spectrography data may be useful in galaxy classification because different galaxy types are likely to emit different amounts of different light wavelengths, so spectrograms might be a good indicator for galaxy type.",
            "zh": "光谱学数据可能在星系分类中有用，因为不同的星系类型可能会发射不同数量的不同波长的光，因此光谱图可能是星系类型的一个很好的指标。"
        }
    },
    {
        "translation": {
            "en": "incremental shrinkage, 168",
            "zh": "增量收缩率，168"
        }
    },
    {
        "translation": {
            "en": "To complete the process of building the ensemble model, the algorithm continues to iteratively calculate errors and train new models to predict these errors, which are added as correction terms to the previous model output.",
            "zh": "为了完成构建集成模型的过程，该算法将继续迭代计算误差并训练新模型来预测这些误差，这些误差将作为校正项添加到以前的模型输出中。"
        }
    },
    {
        "translation": {
            "en": "9.4.1.2 k-Fold cross validation When k-fold cross validation is used, the available data is divided into k equal-sized folds (or partitions), and k separate evaluation experiments are performed.",
            "zh": "9.4.1.2 k-fold交叉验证 当使用k-fold交叉验证时，可用数据被分成k个大小相等的折叠（或分区），并进行k个单独的评估实验。"
        }
    },
    {
        "translation": {
            "en": "max pooling, 490",
            "zh": "最大池化，490"
        }
    },
    {
        "translation": {
            "en": "10. Many systems use values like − 9,999 to indicate that values are actually missing.",
            "zh": "10. 许多系统使用 − 9,999 等值来表示实际缺少值。"
        }
    },
    {
        "translation": {
            "en": "Chapelle, Olivier, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-supervised learning (Chapelle, O. et al., eds.; 2006) [book reviews]. IEEE Transactions on Neural Networks 20 (3): 542–542.",
            "zh": "Chapelle、Olivier、Bernhard Scholkopf 和 Alexander Zien。2009. 半监督学习 （Chapelle， O. et al.， eds.; 2006） [书评].IEEE神经网络汇刊20（3）：542–542。"
        }
    },
    {
        "translation": {
            "en": "Aside from the fact that the logarithm function returns negative numbers, the magnitude of the numbers it returns is ideal as a measure of entropy: large numbers for low probabilities and small numbers (near zero) for high probabilities.",
            "zh": "除了对数函数返回负数这一事实之外，它返回的数字的大小是理想的熵度量：大数表示低概率，小数（接近零）表示高概率。"
        }
    },
    {
        "translation": {
            "en": "churn prediction, 584, 685",
            "zh": "流失预测，584,685"
        }
    },
    {
        "translation": {
            "en": "Just as we did when we played Guess Who, an effective way to generate a prediction is to carry out a series of tests on the values of the descriptive features describing a query instance and use the answers to these tests to determine the prediction.",
            "zh": "就像我们在玩 Guess Who 时所做的那样，生成预测的有效方法是对描述查询实例的描述性特征的值执行一系列测试，并使用这些测试的答案来确定预测。"
        }
    },
    {
        "translation": {
            "en": "The normal distribution (also known as a Gaussian distribution) is so important that it is worth spending a little extra time discussing its characteristics. Standard probability distributions have associated probability density functions, which define the characteristics of the distribution. The probability density function for the normal distribution is",
            "zh": "正态分布（也称为高斯分布）非常重要，值得花一点额外的时间讨论其特征。标准概率分布具有关联的概率密度函数，这些函数定义了分布的特征。正态分布的概率密度函数为"
        }
    },
    {
        "translation": {
            "en": "Type",
            "zh": "类型"
        }
    },
    {
        "translation": {
            "en": "However, decision trees are often used in model ensembles due to the sensitivity of tree induction to changes in the dataset, and this is why we introduced model ensembles in this chapter.",
            "zh": "然而，由于树归纳对数据集变化的敏感性，决策树经常用于模型集成，这就是我们在本章中引入模型集成的原因。"
        }
    },
    {
        "translation": {
            "en": "The calculated posterior probabilities indicate that it is a certainty that the patient does not have meningitis!",
            "zh": "计算出的后验概率表明，患者没有脑膜炎是肯定的！"
        }
    },
    {
        "translation": {
            "en": "(a) The information gain (calculated using entropy) of the feature AGE at the root node of the tree is 0.247. A colleague has suggested that the STUDENT feature would be better at the root node of the tree. Show that this is not the case.",
            "zh": "（a） 树根节点处特征AGE的信息增益（使用熵计算）为0.247。一位同事建议，在树的根节点上使用 STUDENT 功能会更好。表明事实并非如此。"
        }
    },
    {
        "translation": {
            "en": "The first detail that Jocelyn needed to agree on with Edwin was the set of categories into which sky objects should be categorized.",
            "zh": "Jocelyn 需要与 Edwin 达成一致的第一个细节是天空天体应该被归类的一组类别。"
        }
    },
    {
        "translation": {
            "en": "The search finishes when it reaches the root node and both its branches have been either searched or pruned.",
            "zh": "当搜索到达根节点并且其两个分支都已搜索或修剪时，搜索结束。"
        }
    },
    {
        "translation": {
            "en": "The decision boundary learned by the logistic regression model best matches the underlying decision boundary for the dataset in the first column, the decision tree model seems most appropriate for the dataset in the second column, and the k-NN model appears best for the dataset in the third column.",
            "zh": "逻辑回归模型学习的决策边界与第一列中数据集的基础决策边界最匹配，决策树模型似乎最适合第二列中的数据集，而 k-NN 模型最适合第三列中的数据集。"
        }
    },
    {
        "translation": {
            "en": "For example, in medical applications, a prediction that a patient has a disease is much more important than a prediction that a patient does not.",
            "zh": "例如，在医疗应用中，预测患者患有疾病比预测患者没有疾病要重要得多。"
        }
    },
    {
        "translation": {
            "en": "13. This is simply the definition of expectation as defined in probability theory for any random variable: , where X is a random variable, x1 to xk are the possible values of the random variable, and p1 to pk are the probabilities of these different values occurring.",
            "zh": "13. 这只是概率论中对任何随机变量的期望定义：其中 X 是随机变量，x1 到 xk 是随机变量的可能值，p1 到 pk 是这些不同值发生的概率。"
        }
    },
    {
        "translation": {
            "en": "When a model predicts a continuous target, the target range is divided into bins, and the distribution of values into these bins is used in the calculation.",
            "zh": "当模型预测连续目标时，目标范围被划分为条柱，并在计算中使用这些条柱中的值分布。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices for the baseline models.",
            "zh": "基线模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "XGBoost, 171",
            "zh": "XGBoost， 171"
        }
    },
    {
        "translation": {
            "en": "identity function, 624",
            "zh": "恒等函数，624"
        }
    },
    {
        "translation": {
            "en": "What is happening here is that, as Bayes’ Theorem states, when calculating a posterior prediction, we weight the likelihood of the evidence given the prediction by the prior of the prediction.",
            "zh": "这里发生的事情是，正如贝叶斯定理所指出的那样，在计算后验预测时，我们通过预测的先验来加权给定预测的证据的可能性。"
        }
    },
    {
        "translation": {
            "en": "At a certain point in training, further adjustments to the weights will not result in significant changes to the network error, and the convergence criterion specifies a decision process whereby we decide when to stop training.",
            "zh": "在训练的某个点上，对权重的进一步调整不会导致网络误差的重大变化，收敛准则指定了一个决策过程，我们通过该过程决定何时停止训练。"
        }
    },
    {
        "translation": {
            "en": "This gives a state representation with six states to represent all possible combinations of the value of the cards in the player’s hand and the value of the dealer’s visible card: PL-DL, PM-DL, PH-DL, PL-DH, PM-DH, and PH-DH.",
            "zh": "这给出了一个具有六种状态的状态表示，以表示玩家手中的牌值和庄家可见牌的价值的所有可能组合：PL-DL、PM-DL、PH-DL、PL-DH、PM-DH 和 PH-DH。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the gradient for the max function (∂a/∂z) for the max value is 1, because the output of the activation function will be linear for small changes in the input value that achieved the max (i.e., it will change by the same amount as that input value is changed).",
            "zh": "此外，最大值的最大值 （∂a/∂z） 的梯度为 1，因为激活函数的输出对于达到最大值的输入值的微小变化将是线性的（即，它将随着输入值的变化而变化相同的量）。"
        }
    },
    {
        "translation": {
            "en": "To monitor the ongoing performance of a model, we need a signal that indicates that something has changed. There are three sources from which we can extract such a signal:",
            "zh": "为了监控模型的持续性能，我们需要一个信号来指示某些东西发生了变化。我们可以从三个来源中提取这样的信号："
        }
    },
    {
        "translation": {
            "en": "We use this dataset to illustrate training a deep feedforward network.",
            "zh": "我们用这个数据集来说明深度前馈网络的训练。"
        }
    },
    {
        "translation": {
            "en": "INCOME",
            "zh": "收入"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the 5-level logistic regression model (classification accuracy: 77.528%, average class accuracy: 43.018%).",
            "zh": "5级logistic回归模型的混淆矩阵（分类准确率：77.528%，平均类准确率：43.018%）。"
        }
    },
    {
        "translation": {
            "en": "This means that the error of a regression tree in making a prediction for a query instance is the difference between the mean of the training instances that reached the leaf node that returns the prediction and the correct value that should have been returned for that query.",
            "zh": "这意味着回归树在对查询实例进行预测时的错误是到达返回预测的叶节点的训练实例的平均值与应为该查询返回的正确值之间的差值。"
        }
    },
    {
        "translation": {
            "en": "0.167",
            "zh": "0.167"
        }
    },
    {
        "translation": {
            "en": "This is why the variance of the z values rapidly increases as we move forward through the network as shown in Figure 8.24(b)[454].",
            "zh": "这就是为什么当我们在网络中前进时，z值的方差会迅速增加，如图8.24（b）[454]所示。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.92)[489] and Equation (8.93)[489] each list a filter weight matrix and the feature map generated by using a set of neurons to process our example input in Equation (8.84)[478] after the input has had padding applied and using a stride length of 1.",
            "zh": "等式（8.92）[489]和等式（8.93）[489]分别列出了一个滤波器权重矩阵和特征图，该矩阵是使用一组神经元在应用填充并使用步幅长度1后处理等式（8.84）[478]中的示例输入而生成的。"
        }
    },
    {
        "translation": {
            "en": "Table 11.4[665] shows the same portion of the action-value table shown in Table 11.3[661] after the final episode has completed.",
            "zh": "表11.4[665]显示了最后一集结束后表11.3[661]中显示的动作值表的相同部分。"
        }
    },
    {
        "translation": {
            "en": "The dot product of F and G, written F ·G (and thus named) is equivalent to the matrix product FG⊺",
            "zh": "F 和 G 的点积，写成 F ·G（因此得名）等价于矩阵积 FG⊺"
        }
    },
    {
        "translation": {
            "en": "CASE STUDIES AND CONCLUSIONS",
            "zh": "案例研究和结论"
        }
    },
    {
        "translation": {
            "en": "This was confirmed with the business in this case, and this value was treated as an invalid outlier and replaced with a missing value.",
            "zh": "在这种情况下，业务部门确认了这一点，并且此值被视为无效的异常值，并替换为缺失值。"
        }
    },
    {
        "translation": {
            "en": "Using satellite photos of their competitor’s premises, the retailer was able to count the number of cars in the competitor’s parking lots and use this as a proxy measure of activity within the competitor’s stores!",
            "zh": "利用竞争对手场所的卫星照片，零售商能够计算竞争对手停车场的汽车数量，并将其用作竞争对手商店内活动的代理指标！"
        }
    },
    {
        "translation": {
            "en": "One consequence of this observation is that naive Bayes models are not really suitable for predicting continuous targets.",
            "zh": "这一观察结果的一个结果是，朴素贝叶斯模型并不真正适合预测连续目标。"
        }
    },
    {
        "translation": {
            "en": "For example, the AT team felt that a customer beginning to frequently call other networks would be a good indicator of churn, but a suitable data feature could not be extracted to capture this.",
            "zh": "例如，AT 团队认为，客户开始频繁呼叫其他网络将是一个很好的客户流失指标，但无法提取合适的数据特征来捕获这一点。"
        }
    },
    {
        "translation": {
            "en": "The purpose of the second part of the evaluation was to encourage confidence in the models that Jocelyn had built among the SDSS scientists.",
            "zh": "评估的第二部分的目的是鼓励对 SDSS 科学家建立的 Jocelyn 模型的信心。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.12",
            "zh": "图 10.12"
        }
    },
    {
        "translation": {
            "en": "The fact that active customers were defined as current customers means that they were all active on the same date—namely, whatever day the ABT was generated.",
            "zh": "活跃客户被定义为当前客户这一事实意味着他们都在同一天处于活动状态，即生成 ABT 的任何一天。"
        }
    },
    {
        "translation": {
            "en": "For the discussion in this section, however, we assume that biases are initialized to 0.",
            "zh": "然而，对于本节的讨论，我们假设偏差初始化为 0。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10 shows how the representational capacity of a neural network increases as more layers are added to the network.",
            "zh": "图 8.10 显示了神经网络的表示能力如何随着更多层添加到网络中而增加。"
        }
    },
    {
        "translation": {
            "en": "The squares overlaying connections coming out of a neuron illustrate the regions of the input space that the neurons activate on: neurons output high activations in response to inputs patterns from the white region in the corresponding square, and low (or no activations) in response to input patterns from the gray regions in the corresponding square.",
            "zh": "覆盖来自神经元的连接的方块说明了神经元激活的输入空间区域：神经元响应来自相应方块中白色区域的输入模式输出高激活，而响应来自相应方块中灰色区域的输入模式的低激活（或无激活）。"
        }
    },
    {
        "translation": {
            "en": "Pareto charts, 752",
            "zh": "帕累托图，752"
        }
    },
    {
        "translation": {
            "en": "Taking advantage of this information, the randomly selected weights are adjusted slightly in the direction of the error surface gradient to move to a new position on the error surface.",
            "zh": "利用此信息，随机选择的权重在误差表面梯度方向上略微调整，以移动到误差表面上的新位置。"
        }
    },
    {
        "translation": {
            "en": "The fact that we can define an infinite number of distance metrics is not merely an academic curiosity.",
            "zh": "事实上，我们可以定义无限数量的距离指标，这不仅仅是一种学术上的好奇心。"
        }
    },
    {
        "translation": {
            "en": "stratification feature, 93",
            "zh": "分层特征，93"
        }
    },
    {
        "translation": {
            "en": "Figure 5.20[230] illustrates how filter selection fits into the model induction process. It is important to remember that feature selection can be used in conjunction with almost any machine learning algorithm, not just similarity-based approaches. Feature selection is appropriate when there are large numbers of features, so we do not present a worked example here. We do, however, discuss the application of feature selection in the case study in Chapter 13[703].",
            "zh": "图 5.20[230] 说明了滤波器选择如何适应模型归纳过程。重要的是要记住，特征选择可以与几乎任何机器学习算法结合使用，而不仅仅是基于相似性的方法。当有大量特征时，特征选择是合适的，因此我们在这里不提供工作示例。然而，我们确实在第13章[703]的案例研究中讨论了特征选择的应用。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics moving from data to insight to decision.",
            "zh": "预测性数据分析从数据到洞察再到决策。"
        }
    },
    {
        "translation": {
            "en": "In these saturated regions the derivative of the logistic function is approximately 0.",
            "zh": "在这些饱和区域中，逻辑函数的导数约为 0。"
        }
    },
    {
        "translation": {
            "en": "2. Have begun the feature selection exercise by removing some features from the ABT.",
            "zh": "2. 通过从 ABT 中删除一些功能来开始功能选择练习。"
        }
    },
    {
        "translation": {
            "en": "This is often known as pre-pruning.",
            "zh": "这通常称为预修剪。"
        }
    },
    {
        "translation": {
            "en": "In convolutional neural networks, sub-sampling is done using sub-sampling layers.",
            "zh": "在卷积神经网络中，子采样是使用子采样层完成的。"
        }
    },
    {
        "translation": {
            "en": "The multinomial logistic regression18 model is an extension that handles categorical target features with more than two levels.",
            "zh": "多项式逻辑回归18 模型是一个扩展，用于处理具有两个以上级别的分类目标特征。"
        }
    },
    {
        "translation": {
            "en": "By contrast, recurrent neural networks are designed to process sequential data that may have long distances between dependent features in the input sequence.",
            "zh": "相比之下，递归神经网络旨在处理序列中相关特征之间可能具有较长距离的顺序数据。"
        }
    },
    {
        "translation": {
            "en": "This gives us a way to choose between a set of different decision trees that are all consistent with a set of training instances.",
            "zh": "这为我们提供了一种在一组不同的决策树之间进行选择的方法，这些决策树都与一组训练实例一致。"
        }
    },
    {
        "translation": {
            "en": "z-transform, 87",
            "zh": "z 变换，87"
        }
    },
    {
        "translation": {
            "en": "(a) Frames from an episode early in the training process in which the agent performs poorly. (b) Frames from an episode near the end of the learning process where the agent is starting to be very effective. (c) Changing episode returns during DQN training. The gray line shows a 50-episode moving average to better highlight the trend.",
            "zh": "（a） 在训练过程早期，代理表现不佳的情节。（b） 在学习过程接近尾声时，智能体开始变得非常有效的一集的帧。（c） 在 DQN 训练期间更改剧集返回。灰线显示 50 集的移动平均线，以更好地突出趋势。"
        }
    },
    {
        "translation": {
            "en": "12. There are many applications of predictive analytics in healthcare, and predicting readmittance rates for diabetes patients, as well as patients suffering from other issues, is well studied, for example, by Rubin (2015) and Kansagara et al. (2011).",
            "zh": "12. 预测分析在医疗保健中有许多应用，例如，Rubin （2015） 和 Kansagara 等人 （2011） 对预测糖尿病患者以及患有其他问题的患者的再入院率进行了充分研究。"
        }
    },
    {
        "translation": {
            "en": "For example, we might sample the weights from a normal distribution with mean μ = 0.0 and σ = 0.01.",
            "zh": "例如，我们可以从均值 μ = 0.0 且 σ = 0.01 的正态分布中对权重进行采样。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that we need to be able to bin the features of any query instances appropriately before we make predictions for them.",
            "zh": "这样做的原因是，在对任何查询实例进行预测之前，我们需要能够适当地对它们的功能进行分箱。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, this dataset is not based on precise measurements of stroke risk.",
            "zh": "此外，该数据集并非基于对中风风险的精确测量。"
        }
    },
    {
        "translation": {
            "en": "In our example, the target feature, FRAUD, is binary, so we need to define two conditional probabilities for each value in the domain of the new descriptive feature: P(AB = x | fr) and P(AB = x | ¬fr).",
            "zh": "在我们的示例中，目标特征 FRAUD 是二进制的，因此我们需要为新描述性特征域中的每个值定义两个条件概率：P（AB = x | fr） 和 P（AB = x | ¬fr）。"
        }
    },
    {
        "translation": {
            "en": "This is known as the No Free Lunch Theorem (Wolpert, 1996).",
            "zh": "这被称为“没有免费的午餐定理”（Wolpert，1996）。"
        }
    },
    {
        "translation": {
            "en": "interval size, 276",
            "zh": "间隔大小，276"
        }
    },
    {
        "translation": {
            "en": "4.11   A dataset listing the number of bike rentals per day.",
            "zh": "4.11 列出每天自行车租赁次数的数据集。"
        }
    },
    {
        "translation": {
            "en": "temporal-difference learning, 637, 638, 654, 654, 676",
            "zh": "时差学习， 637， 638， 654， 654， 676"
        }
    },
    {
        "translation": {
            "en": "An illustration of three different one-versus-all prediction models for the customer type dataset in Table 7.11[359], with three target levels: (a) single (squares), (b) business (triangles), and (c) family (crosses).",
            "zh": "表 7.11[359] 中客户类型数据集的三种不同的一对一预测模型的图示，具有三个目标级别：（a） 单（正方形）、（b） 业务（三角形）和 （c） 系列（交叉）。"
        }
    },
    {
        "translation": {
            "en": "Gini coefficient, 294, 563, 586, 590",
            "zh": "基尼系数，294,563,586,590"
        }
    },
    {
        "translation": {
            "en": "Hence for a PReLU i, the activation function is defined as",
            "zh": "因此，对于 PReLU i，激活函数定义为"
        }
    },
    {
        "translation": {
            "en": "Bienaymé formula, 455",
            "zh": "Bienaymé 公式，455"
        }
    },
    {
        "translation": {
            "en": "CLASS",
            "zh": "类"
        }
    },
    {
        "translation": {
            "en": "An effective way in which to do this is to start by defining a set of domain concepts in collaboration with the business, and then designing features that express these concepts in order to form the actual ABT.",
            "zh": "要做到这一点，一个有效的方法是首先与业务部门合作定义一组领域概念，然后设计表达这些概念的功能，以形成实际的 ABT。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.88)[482] shows some other sets of weights that our example neurons could use.",
            "zh": "方程（8.88）[482]显示了我们的示例神经元可以使用的其他一些权重集。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the relative ranking of the likelihood of the target levels are, to a certain extent, robust to errors in the calculation of the exact probabilities.13",
            "zh": "因此，目标水平可能性的相对排序在一定程度上对精确概率计算中的误差具有鲁棒性13。"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons in this network use a logistic activation function, what would be the output of Neuron 5 if the network received the input vector: Neuron 1 = 0.7 and Neuron 2 = 0.3?",
            "zh": "（a） 假设该网络中的处理神经元使用逻辑激活函数，如果网络接收到输入向量：神经元 1 = 0.7 和神经元 2 = 0.3，神经元 5 的输出是什么？"
        }
    },
    {
        "translation": {
            "en": "Table 9.1",
            "zh": "表 9.1"
        }
    },
    {
        "translation": {
            "en": "presence-absence, 214",
            "zh": "存在-缺席，214"
        }
    },
    {
        "translation": {
            "en": "5.6   Further Reading",
            "zh": "5.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "B.1   Probability Basics",
            "zh": "B.1 概率基础"
        }
    },
    {
        "translation": {
            "en": "(a) Minimum, maximum, and range",
            "zh": "（a） 最小值、最大值和范围"
        }
    },
    {
        "translation": {
            "en": "In some cases we may wish to avoid this reduction in dimensionality between the input and the feature map.",
            "zh": "在某些情况下，我们可能希望避免输入和特征图之间的这种维度降低。"
        }
    },
    {
        "translation": {
            "en": "This algorithm assumes an episodic scenario in which the agent will repeat multiple episodes of the task that is performing (for example, multiple iterations of a game or attempts to navigate an environment).",
            "zh": "此算法假定一个情节场景，在该场景中，代理将重复正在执行的任务的多个情节（例如，游戏的多次迭代或尝试导航环境）。"
        }
    },
    {
        "translation": {
            "en": "The problem of gradients becoming too large is known as exploding gradients.",
            "zh": "梯度变得太大的问题称为梯度爆炸。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.29)[416] and Equation (8.30)[416] work for mini-batch training in much the same way as they do for batch training; the only difference is that the summation in Equation (8.29)[416] is over the examples in the mini-batch rather than the entire dataset.",
            "zh": "方程（8.29）[416]和方程（8.30）[416]在小批量训练中的作用与在批处理训练中的作用大致相同;唯一的区别是，等式（8.29）[416]中的总和是小批量中的示例，而不是整个数据集。"
        }
    },
    {
        "translation": {
            "en": "The downside, however, is that such measures do not directly measure the performance of the model, and consequently, a high stability index may reflect a change in the underlying population rather than a change in model performance.",
            "zh": "然而，缺点是这些措施不能直接衡量模型的性能，因此，高稳定性指数可能反映了基础群体的变化，而不是模型性能的变化。"
        }
    },
    {
        "translation": {
            "en": "In all three cases the question we would like to answer is, are instance B, located at at (30,70), and instance C, located at (70,70), likely to be from the same population from which the dataset has been sampled?",
            "zh": "在这三种情况下，我们想要回答的问题是，位于 （30,70） 的实例 B 和位于 （70,70） 的实例 C 是否可能来自从中抽取数据集的同一总体？"
        }
    },
    {
        "translation": {
            "en": "Then the results of these three calculations are summed together along with the bias, to generate a single scalar value that is pushed through the activation function and then stored in the feature map.44 Equation (8.99)[493] lists a 2-by-2-by-3 filter that has been annotated to indicate which parts of the filter are applied to which channel",
            "zh": "然后，将这三个计算的结果与偏差相加，生成一个单个标量值，该标量值通过激活函数推送，然后存储在特征图中.44 公式（8.99）[493]列出了一个2×2×3滤波器，该滤波器已被注释以指示滤波器的哪些部分应用于哪个通道"
        }
    },
    {
        "translation": {
            "en": "The optimal values for the weights are the ones that allow the model to best capture the relationship between the descriptive features and a target feature.",
            "zh": "权重的最佳值是允许模型最好地捕获描述性特征与目标特征之间关系的值。"
        }
    },
    {
        "translation": {
            "en": "In this section we discuss common and useful extensions to the basic multivariable linear regression with gradient descent approach described in Section 7.3[319].",
            "zh": "在本节中，我们将讨论第 7.3 节[319] 中描述的具有梯度下降方法的基本多变量线性回归的常见且有用的扩展。"
        }
    },
    {
        "translation": {
            "en": "The year is 1798, and you are Lieutenant-Colonel David Collins of HMS Calcutta exploring the region around Hawkesbury River, in New South Wales.",
            "zh": "这一年是 1798 年，你是 HMS 加尔各答的大卫柯林斯中校，正在探索新南威尔士州霍克斯伯里河周围的地区。"
        }
    },
    {
        "translation": {
            "en": "The probabilities needed by a naive Bayes prediction model, calculated from the data in Table 6.2[263].",
            "zh": "朴素贝叶斯预测模型所需的概率，根据表6.2[263]中的数据计算得出。"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset.",
            "zh": "在没有目标特征的情况下使用无监督机器学习技术，并对数据集中描述性特征中的底层结构进行建模。"
        }
    },
    {
        "translation": {
            "en": "The technical term for this splitting of the data into smaller and smaller sets based on larger and larger sets of conditions is data fragmentation.",
            "zh": "根据越来越大的条件集将数据拆分为越来越小的集合的技术术语是数据碎片。"
        }
    },
    {
        "translation": {
            "en": "Two tools that can be useful for this are the covariance matrix and the correlation matrix.",
            "zh": "为此，有两个工具是协方差矩阵和相关矩阵。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4",
            "zh": "图 1.4"
        }
    },
    {
        "translation": {
            "en": "Figure 4.16",
            "zh": "图 4.16"
        }
    },
    {
        "translation": {
            "en": "Essentially, here we are using Bayes’ Theorem to invert the dependencies between the nodes.",
            "zh": "从本质上讲，这里我们使用贝叶斯定理来反转节点之间的依赖关系。"
        }
    },
    {
        "translation": {
            "en": "The fact that we have a range of parameterized distributions to choose from means that in order to define a probability density function (PDF), we must",
            "zh": "事实上，我们有一系列参数化分布可供选择，这意味着为了定义概率密度函数 （PDF），我们必须"
        }
    },
    {
        "translation": {
            "en": "Inverse probability reasons from effects to causes: if we know that a particular event has occurred, then we can increase the probability that one or more of the events that could cause the observed event have also happened.",
            "zh": "从结果到原因的反概率原因：如果我们知道某个特定事件已经发生，那么我们可以增加可能导致观察到的事件的一个或多个事件也发生的概率。"
        }
    },
    {
        "translation": {
            "en": "These features contained no actual information, so should be removed from the dataset.",
            "zh": "这些要素不包含任何实际信息，因此应从数据集中删除。"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder model is a special type of feedforward neural network that is trained to reproduce its inputs at its output layer.",
            "zh": "自动编码器模型是一种特殊类型的前馈神经网络，经过训练可以在其输出层重现其输入。"
        }
    },
    {
        "translation": {
            "en": "To do this, we first introduce the term Δwi,k to denote the sum of the error gradients for the weight wi,k over one complete pass through all the examples in the training dataset.",
            "zh": "为此，我们首先引入术语 Δwi，k 来表示权重 wi，k 在训练数据集中所有示例中一次完整传递中的误差梯度之和。"
        }
    },
    {
        "translation": {
            "en": "A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "汽车保险欺诈预测分析解决方案的领域概念和相关功能的子集。"
        }
    },
    {
        "translation": {
            "en": "Michie, D. 1961. Trial and error. In Science survey, part 2, eds. S. A. Barnett and A. McLaren, 129–145. Penguin.",
            "zh": "米奇，D. 1961 年。反复试验。在科学调查中，第 2 部分，编辑 SA Barnett 和 A. McLaren，129-145。企鹅。"
        }
    },
    {
        "translation": {
            "en": "10. This is known as the No Free Lunch Theorem (Wolpert, 1996).",
            "zh": "10. 这被称为“没有免费的午餐”定理（Wolpert，1996）。"
        }
    },
    {
        "translation": {
            "en": "Examples of using small multiple bar plot visualizations to illustrate the relationship between two categorical features: (a) the CAREER STAGE and SHOE SPONSOR features; and (b) the POSITION and SHOE SPONSOR features. All data comes from Table 3.7[73].",
            "zh": "使用小的多条形图可视化来说明两个分类特征之间的关系的示例：（a） CAREER STAGE 和 SHOE SPONSOR 特征;以及 （b） POSITION 和 SHOE SPONSOR 功能。所有数据均来自表3.7[73]。"
        }
    },
    {
        "translation": {
            "en": "Since the first edition of this book was released in 2015, things have been moving very fast in the world of machine learning.",
            "zh": "自 2015 年本书第一版发布以来，机器学习领域的发展非常迅速。"
        }
    },
    {
        "translation": {
            "en": "price prediction, 3",
            "zh": "价格预测，3"
        }
    },
    {
        "translation": {
            "en": "When we normalize the features in a dataset, we control for the variation across the variances of features and ensure that each feature can contribute equally to the distance metric.",
            "zh": "当我们对数据集中的要素进行归一化时，我们会控制要素方差的变化，并确保每个要素对距离指标的贡献相等。"
        }
    },
    {
        "translation": {
            "en": "Table 8.4[426] shows the calculation of the per example error for the four examples and the sum of squared errors for the model.",
            "zh": "表 8.4[426] 显示了四个示例的每个示例误差的计算结果以及模型的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "First, the instances in the dataset are sorted according to the values of the continuous feature.",
            "zh": "首先，根据连续特征的值对数据集中的实例进行排序。"
        }
    },
    {
        "translation": {
            "en": "The process is then repeated for each branch using the relevant partition of the training set in place of the full training set and with the selected test feature excluded from further testing.",
            "zh": "然后，使用训练集的相关分区代替完整的训练集，并将所选测试特征排除在进一步测试之外，对每个分支重复该过程。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.3",
            "zh": "图 10.3"
        }
    },
    {
        "translation": {
            "en": "(c) If you used a 4-NN model, what class would be assigned to the mystery animal? Would this be a good value for k for this dataset?",
            "zh": "（c）如果你使用4-NN模型，神秘动物会被分配到什么类别？对于这个数据集来说，这对 k 来说是一个很好的值吗？"
        }
    },
    {
        "translation": {
            "en": "The standard range for the exponential distribution is from zero upward (i.e., the density assigned to values less than zero is zero).",
            "zh": "指数分布的标准范围是从零开始（即，分配给小于零的值的密度为零）。"
        }
    },
    {
        "translation": {
            "en": "A flag is also included to indicate that the claimant has had at least one claim refused in the past, because this might be indicative of a pattern of making speculative claims.",
            "zh": "还包括一个标志，表明索赔人过去至少有一项索赔被拒绝，因为这可能表明提出投机性索赔的模式。"
        }
    },
    {
        "translation": {
            "en": "on-policy reinforcement learning, 664, 676",
            "zh": "政策强化学习，664,676"
        }
    },
    {
        "translation": {
            "en": "B   Introduction to Probability for Machine Learning",
            "zh": "B 机器学习概率论"
        }
    },
    {
        "translation": {
            "en": "The second-to-last layer is a dense fully connected layer (i.e., each neuron in this layer receives the complete feature maps generated by Filters 3 and 4 as input) that feeds forward to the softmax output layer.",
            "zh": "倒数第二层是一个密集的全连接层（即，该层中的每个神经元接收由过滤器 3 和 4 生成的完整特征图作为输入），它转发到 softmax 输出层。"
        }
    },
    {
        "translation": {
            "en": "Together this set of neurons could determine whether the visual feature occurred anywhere in the screen.",
            "zh": "这组神经元一起可以确定视觉特征是否发生在屏幕的任何位置。"
        }
    },
    {
        "translation": {
            "en": "8.16   The δs for each of the neurons in the network for Example 2.",
            "zh": "8.16 示例 2 中网络中每个神经元的 δ。"
        }
    },
    {
        "translation": {
            "en": "All these examples have two things in common.",
            "zh": "所有这些例子都有两个共同点。"
        }
    },
    {
        "translation": {
            "en": "The learning rate, α, in the gradient descent algorithm determines the size of the adjustment made to each weight at each step in the process.",
            "zh": "梯度下降算法中的学习率 α 决定了在过程中每个步骤对每个权重所做的调整大小。"
        }
    },
    {
        "translation": {
            "en": "For the 1936 election Literary Digest ran one of the largest pre-election polls in the U.S. To run the poll Literary Digest created a list of 10 million names by integrating every telephone directory in the U.S., and a number of other sources, and then mailing everyone on the list a mock ballot and asking them to return the ballot to the magazine.",
            "zh": "在1936年的选举中，《文学文摘》进行了美国最大的选举前民意调查之一。为了进行民意调查，《文学文摘》通过整合美国的所有电话簿和许多其他来源，创建了一个包含1000万个名字的名单，然后向名单上的每个人邮寄一张模拟选票，并要求他们将选票退还给杂志。"
        }
    },
    {
        "translation": {
            "en": "This could be handled reasonably easily using an imputation approach,6 but Ross held off on performing this at this stage.",
            "zh": "使用插补方法可以相当容易地处理这个问题，6 但 Ross 在这个阶段推迟了执行此操作。"
        }
    },
    {
        "translation": {
            "en": "7.11   A dataset of customers of a large national retail chain.",
            "zh": "7.11 一家大型全国性零售连锁店的客户数据集。"
        }
    },
    {
        "translation": {
            "en": "(b) Examine the descriptive features in the dataset and list the features that you would exclude before you would use the dataset to build a predictive model. For each feature you decide to exclude, explain why you have made this decision.",
            "zh": "（b） 检查数据集中的描述性特征，并列出在使用数据集构建预测模型之前要排除的特征。对于您决定排除的每个功能，请解释您做出此决定的原因。"
        }
    },
    {
        "translation": {
            "en": "This means that at each decision node, the algorithm will select the feature that partitions the dataset to most reduce the weighted variance of the partitions.",
            "zh": "这意味着在每个决策节点上，算法将选择对数据集进行分区的特征，以最大限度地减少分区的加权方差。"
        }
    },
    {
        "translation": {
            "en": "In Gaeltacht towns people speak the native Irish language rather than English (spoken in the rest of the country).",
            "zh": "在盖尔塔赫特镇，人们说的是爱尔兰本土语言，而不是英语（在该国其他地区使用）。"
        }
    },
    {
        "translation": {
            "en": "When a profit matrix is available, however, profit is a very effective performance measure to use.",
            "zh": "然而，当利润矩阵可用时，利润是一种非常有效的绩效衡量标准。"
        }
    },
    {
        "translation": {
            "en": "7.9   A dataset describing grass growth on Irish farms in July 2012.",
            "zh": "7.9 描述2012年7月爱尔兰农场草生长情况的数据集。"
        }
    },
    {
        "translation": {
            "en": "The fourth part of the book covers the Deployment phases of CRISP-DM. Chapters 12[685] and 13[703] present case studies describing specific predictive analytics projects from Business Understanding up to Deployment. These case studies demonstrate how everything described in the preceding chapters comes together in a successful predictive data analytics project.",
            "zh": "本书的第四部分介绍了 CRISP-DM 的部署阶段。第 12 章[685] 和 13[703] 介绍了从业务理解到部署的特定预测分析项目的案例研究。这些案例研究展示了前几章中描述的所有内容如何整合到一个成功的预测数据分析项目中。"
        }
    },
    {
        "translation": {
            "en": "A feature can take one or more values from a domain, and we can find out the likelihood of a feature taking any particular value using a probability function, P().",
            "zh": "一个特征可以从域中获取一个或多个值，我们可以使用概率函数 P（） 找出特征获取任何特定值的可能性。"
        }
    },
    {
        "translation": {
            "en": "The joint probability distribution for the four binary features from Table B.2[760] (HEADACHE, FEVER, VOMITING, and MENINGITIS) would be written as",
            "zh": "表B.2[760]（头痛、发烧、呕吐和脑膜炎）中四个二元特征的联合概率分布将写为"
        }
    },
    {
        "translation": {
            "en": "Leshno, Moshe, Vladimir Ya Lin, Allan Pinkus, and Shimon Schocken. 1993. Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks 6: 861–867.",
            "zh": "莱什诺、摩西、弗拉基米尔·亚林、艾伦·平库斯和西蒙·肖肯。1993. 具有非多项式激活函数的多层前馈网络可以近似任何函数.神经网络 6：861–867。"
        }
    },
    {
        "translation": {
            "en": "Table 13.5",
            "zh": "表 13.5"
        }
    },
    {
        "translation": {
            "en": "Adding extra descriptive features that give a more complete picture of a domain concept can lead to better predictive models.",
            "zh": "添加额外的描述性特征，使领域概念更全面地了解，可以产生更好的预测模型。"
        }
    },
    {
        "translation": {
            "en": "The first type of error gradient is the rate of change of the network error with respect to changes in the weighted sum calculation of a neuron.",
            "zh": "第一种类型的误差梯度是网络误差相对于神经元加权和计算变化的变化率。"
        }
    },
    {
        "translation": {
            "en": "The main advantage of decision tree models is that they are interpretable.",
            "zh": "决策树模型的主要优点是它们是可解释的。"
        }
    },
    {
        "translation": {
            "en": "If we have multiple target levels, the structure of the confusion matrix shown in Figure 9.2[538] no longer fits the data. Similarly, the notion of thinking about a positive level and a negative level doesn’t apply any more. The confusion matrix can, however, be easily extended to handle multiple target levels by including a row and column for each one. Table 9.17[572] shows the structure of a confusion matrix for a multinomial prediction problem in which the target feature has l levels.",
            "zh": "如果我们有多个目标水平，则图9.2[538]所示的混淆矩阵的结构不再适合数据。同样，思考积极水平和消极水平的概念不再适用。但是，混淆矩阵可以很容易地扩展为处理多个目标级别，方法是为每个目标级别包含一行和一列。表 9.17[572] 显示了多项式预测问题的混淆矩阵结构，其中目标特征具有 l 级。"
        }
    },
    {
        "translation": {
            "en": "When the car changes speed, the action has an immediate effect on the car’s progress in the current time-step. If the car is stationary, taking the action to move left or right has no effect on the car’s position. If the car is moving slowly, then moving left or right moves the car one cell in that direction at that time-step, but not any distance forward. If the car is moving fast, then moving left or right moves the car one cell in that direction at that time-step and one cell forward.",
            "zh": "当汽车改变速度时，该动作会立即影响汽车在当前时间步长中的进度。如果汽车静止不动，则向左或向右移动的动作对汽车的位置没有影响。如果汽车移动缓慢，则向左或向右移动会使汽车在该时间步长上沿该方向移动一个单元格，但不会向前移动任何距离。如果汽车移动得很快，那么向左或向右移动会使汽车在该时间步长上向该方向移动一个单元格，并在该时间步长上移动一个单元格。"
        }
    },
    {
        "translation": {
            "en": "C.3   Partial Derivatives",
            "zh": "C.3 偏导数"
        }
    },
    {
        "translation": {
            "en": "There are three descriptive features in the dataset. STREAM is a binary feature that describes whether or not there is a stream in the area. SLOPE describes the steepness of the terrain in an area and has the levels flat, moderate, and steep. ELEVATION describes the elevation of an area and has the levels low, medium, high, and highest.",
            "zh": "数据集中有三个描述性特征。STREAM 是一个二进制要素，用于描述该区域中是否存在流。SLOPE 描述了一个区域中地形的陡峭程度，并具有平坦、中等和陡峭的级别。ELEVATION 描述区域的高程，并具有低、中、高和最高级别。"
        }
    },
    {
        "translation": {
            "en": "APPENDICES",
            "zh": "附录"
        }
    },
    {
        "translation": {
            "en": "EEG, 353",
            "zh": "脑电图，353"
        }
    },
    {
        "translation": {
            "en": "0.57",
            "zh": "0.57"
        }
    },
    {
        "translation": {
            "en": "Lift captures this more formally.",
            "zh": "Lift 更正式地捕捉到了这一点。"
        }
    },
    {
        "translation": {
            "en": "5.5   Summary",
            "zh": "5.5 小结"
        }
    },
    {
        "translation": {
            "en": "Data quality issues due to invalid data typically arise because of errors in the process used to generate an ABT, usually in relation to calculating derived features.",
            "zh": "由于无效数据导致的数据质量问题通常是由于用于生成 ABT 的过程中的错误而引起的，通常与计算派生特征有关。"
        }
    },
    {
        "translation": {
            "en": "The goal that the agent is being trained to achieve is to learn to drive as far as possible in the shortest amount of time possible without crashing. The car moves forward along an infinite highway, and an episode ends if the car crashes into a barrier or another car.",
            "zh": "智能体正在接受训练以实现的目标是学会在尽可能短的时间内尽可能远地驾驶而不会撞车。汽车沿着无限的高速公路向前行驶，如果汽车撞上障碍物或另一辆车，则一集结束。"
        }
    },
    {
        "translation": {
            "en": "For this reason, it is very important to perform a second evaluation in which the test data reflect the actual distribution of target feature values in the business scenario.",
            "zh": "因此，进行第二次评估非常重要，其中测试数据反映了业务场景中目标特征值的实际分布。"
        }
    },
    {
        "translation": {
            "en": "Table 5.2[183] lists an example dataset containing two descriptive features, the SPEED and AGILITY ratings for college athletes (both measures out of 10), and one target feature that lists whether the athletes were drafted to a professional team.1 We can represent this dataset in a feature space by taking each of the descriptive features to be the axes of a coordinate system.",
            "zh": "表 5.2[183] 列出了一个示例数据集，其中包含两个描述性特征，即大学运动员的速度和敏捷性评级（均为 10 分），以及一个列出运动员是否被选入专业团队的目标特征。"
        }
    },
    {
        "translation": {
            "en": "We can see this if we compare the dimensionality of the features maps in Equation (8.90)[486] and Equation (8.91)[486] with the number of neurons shown in Figure 8.33[484].",
            "zh": "如果我们将等式（8.90）[486]和等式（8.91）[486]中特征图的维数与图8.33[484]所示的神经元数量进行比较，我们可以看到这一点。"
        }
    },
    {
        "translation": {
            "en": "An imbalanced dataset is a dataset that contains significantly more instances of one target level than another.",
            "zh": "不平衡数据集是指包含一个目标级别的实例明显多于另一个目标级别的数据集。"
        }
    },
    {
        "translation": {
            "en": "You have been asked by a San Francisco property investment company to create a predictive model that will generate house price estimates for properties they are considering purchasing as rental properties.",
            "zh": "旧金山一家房地产投资公司要求您创建一个预测模型，该模型将为他们正在考虑购买的出租物业生成房价估算。"
        }
    },
    {
        "translation": {
            "en": "Table 13.3",
            "zh": "表 13.3"
        }
    },
    {
        "translation": {
            "en": "So, grouping galaxies by morphological type is a fundamentally important step in analyzing the characteristics of galaxies.",
            "zh": "因此，按形态类型对星系进行分组是分析星系特征的基本重要步骤。"
        }
    },
    {
        "translation": {
            "en": "If we set the number of bins to a high number—for example, 10 or more—then, just because there are more bin boundaries, it is more likely that at least some of our bins will align with interesting features of the distribution of the original continuous feature. This means that our binning categories will provide a better representation of this distribution. However, the more bins we have, the fewer instances we will have in each bin. Indeed, as the number of bins grows, we can end up with empty bins.",
            "zh": "如果我们将条柱的数量设置为一个较高的数字（例如，10 个或更多），那么，仅仅因为有更多的条柱边界，就更有可能至少有一些条柱与原始连续特征分布的有趣特征对齐。这意味着我们的分箱类别将更好地表示此分布。但是，我们拥有的 bin 越多，每个 bin 中的实例就越少。事实上，随着垃圾箱数量的增加，我们最终可能会得到空垃圾箱。"
        }
    },
    {
        "translation": {
            "en": "Just like descriptive features, target features are based on a domain concept, and we must determine what actual implementation is useful, feasible, and correct according to the specifics of the domain in question.",
            "zh": "就像描述性特征一样，目标特征也是基于领域概念的，我们必须根据所讨论领域的具体情况来确定哪些实际实现是有用的、可行的和正确的。"
        }
    },
    {
        "translation": {
            "en": "This means that for the example in Figure 8.39[506] we would sum three error gradients for each weight in Wyh and six error gradients for each weight in Whh and each weight in Wyx.",
            "zh": "这意味着，对于图 8.39[506] 中的示例，我们将对 Wyh 中的每个权重的三个误差梯度求和，对 Whh 中的每个权重和 Wyx 中的每个权重的六个误差梯度求和。"
        }
    },
    {
        "translation": {
            "en": "For the first of these terms, P(h | m), only three instances in the dataset fulfill the condition of m (d5, d8 and d10).",
            "zh": "对于这些项中的第一个项 P（h | m），数据集中只有三个实例满足 m 的条件（d5、d8 和 d10）。"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the mini-batch of examples listed in Table 8.13[464] through the network in Figure 8.27[465].",
            "zh": "表8.13[464]中列出的小批量示例通过图8.27[465]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "In many cases, although it may be possible to say that some outcomes are more desirable than others, it is simply not possible to quantify this.",
            "zh": "在许多情况下，尽管可以说某些结果比其他结果更可取，但根本无法量化这一点。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.6",
            "zh": "图 11.6"
        }
    },
    {
        "translation": {
            "en": "By summing the weight updates across the neurons that use it, we retain a single consistent weight for all the neurons.",
            "zh": "通过对使用它的神经元的权重更新求和，我们为所有神经元保留了一个一致的权重。"
        }
    },
    {
        "translation": {
            "en": "first",
            "zh": "第一"
        }
    },
    {
        "translation": {
            "en": "In this example we might also include the number of claims made by the claimant in the last three months, the average number of claims made by the claimant per year, and the ratio of the average number of claims made by the claimant per year to the claims made by the claimant in the last twelve months.",
            "zh": "在这个例子中，我们还可以包括索赔人在过去三个月内提出的索赔数量、索赔人每年提出的平均索赔数量，以及索赔人每年提出的平均索赔数量与索赔人在过去十二个月内提出的索赔的比率。"
        }
    },
    {
        "translation": {
            "en": "ME1E1ERR_U/G/R/I/Z",
            "zh": "ME1E1ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "policy-based reinforcement learning, 643",
            "zh": "基于策略的强化学习，643"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity is an especially useful measure of similarity when the descriptive features describing instances in a dataset are related to each other.",
            "zh": "当描述数据集中实例的描述性特征相互关联时，余弦相似度是衡量相似度的特别有用的度量。"
        }
    },
    {
        "translation": {
            "en": "For this example, the weight matrices were randomly initialized from the range [−0.5,+0.5]",
            "zh": "在此示例中，权重矩阵是从 [−0.5，+0.5] 范围随机初始化的"
        }
    },
    {
        "translation": {
            "en": "Bostrom, Nick. 2003. Ethical issues in advanced artificial intelligence. In Science fiction and philosophy: From time travel to superintelligence, 277–284. Wiley-Blackwell.",
            "zh": "博斯特罗姆，尼克。2003. 先进人工智能中的伦理问题.在科幻小说和哲学中：从时间旅行到超级智能，277-284。威利-布莱克威尔。"
        }
    },
    {
        "translation": {
            "en": "To find the optimal set of weights, we begin with a set of random weight values that corresponds to some random point on the error surface.",
            "zh": "为了找到最佳权重集，我们从一组随机权重值开始，这些值对应于误差曲面上的某个随机点。"
        }
    },
    {
        "translation": {
            "en": "Table 9.10",
            "zh": "表 9.10"
        }
    },
    {
        "translation": {
            "en": "Figure B.1",
            "zh": "图 B.1"
        }
    },
    {
        "translation": {
            "en": "7.4 Extensions and Variations",
            "zh": "7.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Each normal distribution has a different mean but the same standard deviation.",
            "zh": "每个正态分布具有不同的均值，但标准差相同。"
        }
    },
    {
        "translation": {
            "en": "distance metric, 184, 231",
            "zh": "距离公制， 184， 231"
        }
    },
    {
        "translation": {
            "en": "The whiskey dataset after the descriptive features have been normalized.",
            "zh": "描述性特征归一化后的威士忌数据集。"
        }
    },
    {
        "translation": {
            "en": "These individual delta contributions are then summed so that the weight update rule (Equation (7.33)[346]) can be applied, in this example using a learning rate of 0.02.",
            "zh": "然后将这些单独的增量贡献相加，以便可以应用权重更新规则（等式 （7.33）[346]），在本例中，学习率为 0.02。"
        }
    },
    {
        "translation": {
            "en": "The line in Figure 1.3(b)[15] represents one model of the relationship between the AGE and INCOME features.",
            "zh": "图1.3（b）[15]中的线代表了年龄和收入特征之间关系的一个模型。"
        }
    },
    {
        "translation": {
            "en": "two-stage model, 722, 725",
            "zh": "两级型号，722、725"
        }
    },
    {
        "translation": {
            "en": "5.13   The AGE and RATING feature space for the whiskey dataset. The location of the query instance is indicated by the ? symbol. The circle plotted with a dashed line demarcates the border of the neighborhood around the query when k = 3. The three nearest neighbors to the query are labeled with their ID values.",
            "zh": "5.13 威士忌数据集的 AGE 和 RATING 特征空间。查询实例的位置由 ？象征。当 k = 3 时，用虚线绘制的圆圈划定了查询周围邻域的边界。查询的三个最近邻域标有其 ID 值。"
        }
    },
    {
        "translation": {
            "en": "Should we count one missed payment as a default or, to avoid predicting that good customers will default, should we consider a customer to have defaulted only after they miss three consecutive payments?",
            "zh": "我们是否应该将一次错过的付款视为违约，或者为了避免预测好客户会违约，我们是否应该认为客户仅在连续错过三次付款后才违约？"
        }
    },
    {
        "translation": {
            "en": "More recent attempts to do this include Segata et al.",
            "zh": "最近尝试这样做的包括 Segata 等人。"
        }
    },
    {
        "translation": {
            "en": "HELPFORUM: Did the user post a question on the help forum?",
            "zh": "HELPFORUM：用户是否在帮助论坛上发布了问题？"
        }
    },
    {
        "translation": {
            "en": "3.7   Examples of using small multiple bar plot visualizations to illustrate the relationship between two categorical features: (a) the CAREER STAGE and SHOE SPONSOR features; and (b) the POSITION and SHOE SPONSOR features. All data comes from Table 3.7[73].",
            "zh": "3.7 使用小多条形图可视化来说明两个分类特征之间的关系的示例：（a） CAREER STAGE 和 SHOE SPONSOR 特征;以及 （b） POSITION 和 SHOE SPONSOR 功能。所有数据均来自表3.7[73]。"
        }
    },
    {
        "translation": {
            "en": "With all model ensembles, however, the cost of their high performance is increased learning and model complexity.",
            "zh": "然而，对于所有模型集成，其高性能的代价是增加了学习和模型复杂性。"
        }
    },
    {
        "translation": {
            "en": "The initial weights in the auto-encoder are randomly initialized, and therefore it should not be a surprise that these reconstructions bear no resemblance to the original images and are basically noise.",
            "zh": "自动编码器中的初始权重是随机初始化的，因此这些重建与原始图像没有相似之处并且基本上是噪声也就不足为奇了。"
        }
    },
    {
        "translation": {
            "en": "Sometimes there are very specific relationships in a dataset that we want to maintain in a sample.",
            "zh": "有时，数据集中存在我们想要在样本中维护的非常具体的关系。"
        }
    },
    {
        "translation": {
            "en": "In most cases random sampling will maintain distributions; however, if there are one or more levels of a categorical feature that only a very small proportion of instances in a dataset have, there is a chance that these will be omitted or underrepresented by random sampling.",
            "zh": "在大多数情况下，随机抽样将保持分布;但是，如果数据集中只有极少数实例具有一个或多个类别特征级别，则随机抽样可能会忽略这些级别或表示不足。"
        }
    },
    {
        "translation": {
            "en": "Jim and Martha always go shopping separately. If Jim does the shopping he buys wine, but not always. If Martha does the shopping, she buys wine, but not always. If Jim tells Martha that he has done the shopping, then Martha doesn’t go shopping, but sometimes Jim forgets to tell Martha, and so sometimes both Jim and Martha go shopping.",
            "zh": "吉姆和玛莎总是分开去购物。如果吉姆去购物，他会买酒，但并非总是如此。如果玛莎去购物，她会买酒，但并非总是如此。如果吉姆告诉玛莎他已经买完了东西，那么玛莎就不会去购物，但有时吉姆忘记告诉玛莎，所以有时吉姆和玛莎都去购物。"
        }
    },
    {
        "translation": {
            "en": "Table 9.14[565] shows an example for the email classification problem predictions given in Table 9.11[557].",
            "zh": "表9.14[565]显示了表9.11[557]中给出的电子邮件分类问题预测示例。"
        }
    },
    {
        "translation": {
            "en": "There is one, non-obvious, aspect of this example that is particularly interesting.",
            "zh": "这个例子有一个不明显的方面特别有趣。"
        }
    },
    {
        "translation": {
            "en": "When training a support vector machine, we wish to find a hyperplane that distinguishes between the two target levels, − 1 and + 1. So, the required constraints required by the training process are",
            "zh": "在训练支持向量机时，我们希望找到一个区分两个目标水平 − 1 和 + 1 的超平面。因此，训练过程所需的约束是"
        }
    },
    {
        "translation": {
            "en": "Consequently, the plot of values for HL1 is generated from a much smaller sample of weight values than the plots for the other hidden layers.",
            "zh": "因此，HL1 的值图是从比其他隐藏层的图小得多的权重值样本生成的。"
        }
    },
    {
        "translation": {
            "en": "Now, imagine a scenario in which the model makes a correct prediction and the maximum probability in is assigned to the correct category.",
            "zh": "现在，假设模型做出正确的预测，并将最大概率分配给正确的类别。"
        }
    },
    {
        "translation": {
            "en": "There are, for example, a number of non-modifiable risk factors such as age and gender.",
            "zh": "例如，有许多不可改变的风险因素，例如年龄和性别。"
        }
    },
    {
        "translation": {
            "en": "This elementwise product is depicted in Figure 8.40[509] by the ⊙ symbol at the intersection of the cell state and the output of the forget gate sigmoid layer in the top-left of the figure.",
            "zh": "图8.40[509]中，该元素乘积由图左上角的单元状态和遗忘门S形结晶层输出交点处的⊙符号表示。"
        }
    },
    {
        "translation": {
            "en": "sampling, 87, 91",
            "zh": "采样， 87， 91"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3",
            "zh": "图 11.3"
        }
    },
    {
        "translation": {
            "en": "One way to do this (similar to the ranking and pruning approach described previously) is to use a filter to evaluate the predictiveness of each candidate set of features and select the most predictive one.",
            "zh": "一种方法（类似于前面描述的排名和修剪方法）是使用过滤器来评估每组候选特征的预测性，并选择最具预测性的特征。"
        }
    },
    {
        "translation": {
            "en": "Once these three conditions hold (stationary distribution, ergodicity, and independent states), the samples generated will eventually converge with the distribution, and it is appropriate to use Gibbs sampling.",
            "zh": "一旦这三个条件（稳态分布、遍历性和独立状态）成立，生成的样本最终将与分布收敛，使用吉布斯采样是合适的。"
        }
    },
    {
        "translation": {
            "en": "The GOOD BEHAVIOR feature has a value of true if the prisoner had not committed any infringements during incarceration, the AGE < 30 has a value of true if the prisoner was under 30 years of age when granted parole, and the DRUG DEPENDENT feature is true if the prisoner had a drug addiction at the time of parole.",
            "zh": "如果囚犯在监禁期间没有犯任何侵权行为，则 GOOD BEHAVIOR 特征的值为 true，如果囚犯在获得假释时未满 30 岁，则 AGE < 30 的值为 true，如果囚犯在假释时吸毒成瘾，则 DRUG DEPENDENT 特征为 true。"
        }
    },
    {
        "translation": {
            "en": "Table 7.9",
            "zh": "表 7.9"
        }
    },
    {
        "translation": {
            "en": "Using a sparse representation can reduce the energy consumed by a network (Reagen et al., 2017) and is also more biologically plausible (Glorot et al., 2011).",
            "zh": "使用稀疏表示可以减少网络消耗的能量（Reagen等人，2017），并且在生物学上也更合理（Glorot等人，2011）。"
        }
    },
    {
        "translation": {
            "en": "Bejar, J., U. Cortés, and M. Poch. 1991. LINNEO+: A classification methodology for ill-structured domains, Research report RT-93-10-R, Dept. Llenguatges i Sistemes Informatics, Universitat Politècnica de Catalunya.",
            "zh": "Bejar， J.， U. Cortés， 和 M. Poch.1991. LINNEO+：结构不良域的分类方法，研究报告RT-93-10-R，加泰罗尼亚理工大学信息学系。"
        }
    },
    {
        "translation": {
            "en": "1. In order to allow this dataset fit on one page, only a subset of the features described in the domain concept diagrams in Figures 2.9[43], 2.10[44], and 2.11[45] are included.",
            "zh": "1. 为了使该数据集适合一页，仅包含图 2.9[43]、2.10[44] 和 2.11[45] 中领域概念图中描述的特征子集。"
        }
    },
    {
        "translation": {
            "en": "For example, if you ask Question 2, and we answer yes, you can be sure that we have picked Brian without asking any more questions.",
            "zh": "例如，如果您问问题 2，而我们的回答是肯定的，您可以确定我们已经选择了 Brian，而无需再问任何问题。"
        }
    },
    {
        "translation": {
            "en": "Directly solving the large series of simultaneous equations that arise from the Bellman optimality equation for MDPs of interesting scale, however, is computationally very expensive and requires full knowledge of the dynamics of an MDP for a given scenario that can be unavailable in practice.",
            "zh": "然而，对于具有有趣规模的 MDP，直接求解由贝尔曼最优方程产生的大量联立方程在计算上非常昂贵，并且需要充分了解给定场景下的 MDP 动力学，而这在实践中可能不可用。"
        }
    },
    {
        "translation": {
            "en": "In predictive data analytics we use a broad definition of the word prediction.",
            "zh": "在预测数据分析中，我们使用“预测”一词的广义定义。"
        }
    },
    {
        "translation": {
            "en": "Aphra",
            "zh": "阿芙拉"
        }
    },
    {
        "translation": {
            "en": "9,235",
            "zh": "9,235"
        }
    },
    {
        "translation": {
            "en": "Table 6.4[265] shows the relevant probabilities needed to make a prediction for this query and the calculation of the scores for each possible prediction.",
            "zh": "表 6.4[265] 显示了对此查询进行预测所需的相关概率以及每个可能预测的分数计算。"
        }
    },
    {
        "translation": {
            "en": "Bayesian network, 243, 265, 285, 304, 732, 733, 735",
            "zh": "贝叶斯网络， 243， 265， 285， 304， 732， 733， 735"
        }
    },
    {
        "translation": {
            "en": "As a result, a topic can be included in a course by covering just the first part of a chapter (Big Idea, fundamentals, standard algorithm, and worked example); and then—time permitting—the coverage of the topic can be extended to some or all of the material in the second part.",
            "zh": "因此，只需涵盖一章的第一部分（大创意、基础知识、标准算法和工作示例）即可将主题包含在课程中;然后，如果时间允许，该主题的覆盖范围可以扩展到第二部分的部分或全部材料。"
        }
    },
    {
        "translation": {
            "en": "The main disadvantage is that programming is a skill that takes time and effort to learn.",
            "zh": "主要缺点是编程是一项需要时间和精力来学习的技能。"
        }
    },
    {
        "translation": {
            "en": "Table 9.13[560] shows how the predictions made for test instances change as the threshold changes.",
            "zh": "表 9.13[560] 显示了对测试实例所做的预测如何随着阈值的变化而变化。"
        }
    },
    {
        "translation": {
            "en": "stationary distribution, 299",
            "zh": "稳态分布，299"
        }
    },
    {
        "translation": {
            "en": "For the value of the visible card dealt to the dealer, just two levels (low and high) are modeled",
            "zh": "对于发给庄家的可见牌的价值，只建模了两个级别（低和高）"
        }
    },
    {
        "translation": {
            "en": "The amount of sub-sampling applied is dependent on the dimensions of the receptive fields of the neurons; for example, using non-overlapping 2-by-2 receptive fields, the output from a sub-sampling layer will have half the number of rows and columns as the feature map input to the layer.",
            "zh": "应用的子采样量取决于神经元感受野的尺寸;例如，使用不重叠的 2×2 感受野，子采样图层的输出将具有一半的行数和列数作为图层的特征图输入。"
        }
    },
    {
        "translation": {
            "en": "missing indicator feature, 69",
            "zh": "缺少指示器功能，69"
        }
    },
    {
        "translation": {
            "en": "This weight initialization heuristic is known as He initialization (or sometimes it is called Kaiming initialization) and is defined as follows:",
            "zh": "这种权重初始化启发式称为 He 初始化（有时也称为 Kaim 初始化），定义如下："
        }
    },
    {
        "translation": {
            "en": "To illustrate how information gain ratio is computed, we compute the information gain ratio for the descriptive features STREAM, SLOPE, and ELEVATION in the vegetation classification dataset in Table 4.3[136]. We already know the information gain for these features (see Table 4.4[137])",
            "zh": "为了说明如何计算信息增益比，我们计算了表4.3[136]中植被分类数据集中描述性特征STREAM、SLOPE和ELEVATION的信息增益比。我们已经知道这些特征的信息增益（见表4.4[137]）"
        }
    },
    {
        "translation": {
            "en": "As well as being required to select appropriate performance measures to use when evaluating trained models, we also need to ensure that we are using the appropriate evaluation experiment design. The goal here is to ensure that we calculate the best estimate of how a prediction model will perform when actually deployed in the wild. In this section we will describe the most important evaluation experiment designs and indicate when each is most appropriate.",
            "zh": "除了在评估训练模型时需要选择适当的性能度量外，我们还需要确保我们使用适当的评估实验设计。这里的目标是确保我们计算出预测模型在实际部署在野外时的表现的最佳估计。在本节中，我们将描述最重要的评估实验设计，并指出每种实验设计何时最合适。"
        }
    },
    {
        "translation": {
            "en": "Hence using the softmax function, the activation of each neuron is dependent on the size of its z value relative to the z values of the other neurons in the output layer.",
            "zh": "因此，使用 softmax 函数，每个神经元的激活取决于其 z 值相对于输出层中其他神经元的 z 值的大小。"
        }
    },
    {
        "translation": {
            "en": "Interval: Values that allow ordering and subtraction, but do not allow other arithmetic operations (e.g., date, time)",
            "zh": "间隔：允许排序和减法，但不允许其他算术运算（例如日期、时间）的值"
        }
    },
    {
        "translation": {
            "en": "However, this still requires the selection of a set of initial approaches.",
            "zh": "但是，这仍然需要选择一组初始方法。"
        }
    },
    {
        "translation": {
            "en": "uniform distribution, 59",
            "zh": "均匀分布，59"
        }
    },
    {
        "translation": {
            "en": "For example, if we decreased the dimension of our filter to a 2-by-2 dimension then we would need to increase the set of neurons to a 5-by-5 layer in order to cover the input, and this would result in a 5-by-5 feature map.",
            "zh": "例如，如果我们将过滤器的维度降低到 2×2 的维度，那么我们需要将神经元集增加到 5×5 层以覆盖输入，这将产生 5×5 的特征图。"
        }
    },
    {
        "translation": {
            "en": "linear, 386, 625",
            "zh": "线性， 386， 625"
        }
    },
    {
        "translation": {
            "en": "On the other hand, k nearest neighbor models are very slow to make predictions as they must perform a comparison of a query instance to every instance in a, typically large, training set.",
            "zh": "另一方面，k 个最近邻模型的预测速度非常慢，因为它们必须将查询实例与训练集中的每个实例（通常是大型训练集）进行比较。"
        }
    },
    {
        "translation": {
            "en": "9.14   Tabulating the workings required to generate a K-S statistic.",
            "zh": "9.14 将生成 K-S 统计量所需的工作量制成表格。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.5",
            "zh": "图 5.5"
        }
    },
    {
        "translation": {
            "en": "In fact, the predictions produced by a similarity-based model will change depending on the exact Minkowski distance used (i.e., p = 1,2,…,∞).",
            "zh": "事实上，基于相似性的模型产生的预测将根据所使用的确切闵可夫斯基距离（即 p = 1,2,...,∞）而变化。"
        }
    },
    {
        "translation": {
            "en": "The neurons in this network all use the logistic function as their activation function, and so the derivative of this function is given by Equation (8.15)[408].",
            "zh": "该网络中的神经元都使用逻辑函数作为它们的激活函数，因此该函数的导数由方程（8.15）[408]给出。"
        }
    },
    {
        "translation": {
            "en": "intra-cluster distance, 608",
            "zh": "集群内距离，608"
        }
    },
    {
        "translation": {
            "en": "0.34",
            "zh": "0.34"
        }
    },
    {
        "translation": {
            "en": "From these values we can see that the error gradient will be able to flow backward through Neurons 8, 7, and 6 without being scaled down by the multiplication by ∂a/∂z in the δ calculations.",
            "zh": "从这些值中，我们可以看到误差梯度将能够向后流过神经元 8、7 和 6，而不会在δ计算中被乘以 ∂a/∂z 缩小。"
        }
    },
    {
        "translation": {
            "en": "It is much easier to select initial weights for normalized feature values than for raw feature values, as the range in which weights for normalized feature values might reasonably fall (particularly for the intercept weight, w[0]) is much better defined than the corresponding range when raw feature values are used.",
            "zh": "为归一化特征值选择初始权重比为原始特征值选择初始权重要容易得多，因为归一化特征值的权重可能合理下降的范围（特别是对于截距权重 w[0]）比使用原始特征值时的相应范围定义得更好。"
        }
    },
    {
        "translation": {
            "en": "Finally, Edwin and Jocelyn discussed how fast the model built would need to be to allow its inclusion in the existing SDSS pipeline.",
            "zh": "最后，Edwin 和 Jocelyn 讨论了构建模型的速度需要多快才能将其包含在现有的 SDSS 管道中。"
        }
    },
    {
        "translation": {
            "en": "In this case, the number of channels in the input to this layer would be equal to the number of filters in the preceding convolutional layer.",
            "zh": "在这种情况下，该层输入中的通道数将等于前一个卷积层中的滤波器数。"
        }
    },
    {
        "translation": {
            "en": "Caruana et al.",
            "zh": "卡鲁阿纳等人。"
        }
    },
    {
        "translation": {
            "en": "MRRCCERR_U/G/R/I/Z",
            "zh": "MRRCCERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Bayes, Thomas, 248",
            "zh": "贝叶斯，托马斯，248"
        }
    },
    {
        "translation": {
            "en": "pre-pruning, 155, 169",
            "zh": "预修剪， 155， 169"
        }
    },
    {
        "translation": {
            "en": "So ∑iP(mi) = P(m) + P(¬m).",
            "zh": "所以∑iP（mi） = P（m） + P（¬m）。"
        }
    },
    {
        "translation": {
            "en": "Ayres, Ian. 2008. Super crunchers: Why thinking-by-numbers is the new way to be smart. Bantam.",
            "zh": "艾尔斯，伊恩。2008. 超级紧缩者：为什么用数字思考是变得聪明的新方法。矮脚鸡。"
        }
    },
    {
        "translation": {
            "en": "and then, if required, Do they have long hair?",
            "zh": "然后，如果需要，他们有长发吗？"
        }
    },
    {
        "translation": {
            "en": "The mean squared error allows us to rank the performance of multiple models on a prediction problem with a continuous target. Mean squared error values fall in the range [0,∞], and smaller values indicate better model performance.",
            "zh": "均方误差允许我们在具有连续目标的预测问题上对多个模型的性能进行排名。均方误差值在 [0，∞] 范围内，值越小表示模型性能越好。"
        }
    },
    {
        "translation": {
            "en": "A.4.3    Box Plots",
            "zh": "A.4.3 箱形图"
        }
    },
    {
        "translation": {
            "en": "The effect of using different numbers of bins when using binning to convert a continuous feature into a categorical feature.",
            "zh": "使用分箱将连续要素转换为分类要素时使用不同数量的条柱的效果。"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance can be understood as defining an orthonormal coordinate system with (1) an origin at the instance we are calculating the distance from (a in Equation (5.16)[219]); (2) a primary axis aligned with the direction of the greatest spread in the dataset; and (3) the units of all the axes scaled so that the dataset has unit variance along each axis.",
            "zh": "马氏距离可以理解为定义一个正交坐标系，其特点是：（1）在我们计算距离的实例处有一个原点（方程（5.16）[219]中的a）;（2）与数据集中最大传播方向对齐的主轴;（3）所有轴的单位缩放，使数据集沿每个轴具有单位方差。"
        }
    },
    {
        "translation": {
            "en": "Having performed this initial analysis, Jocelyn met again with Edwin and Ted to discuss the data quality issues and, more generally, to review the domain concepts outlined in Figure 13.2[708] so as to begin designing the actual descriptive features that would populate the ABT.",
            "zh": "在进行了初步分析之后，Jocelyn 再次与 Edwin 和 Ted 会面，讨论数据质量问题，并更广泛地回顾图 13.2[708] 中概述的领域概念，以便开始设计将填充 ABT 的实际描述性特征。"
        }
    },
    {
        "translation": {
            "en": "MIL. SPEND, the percentage of GDP spent on the military",
            "zh": "MIL. 支出，用于军事的 GDP 百分比"
        }
    },
    {
        "translation": {
            "en": "(c) Design a reward function for this scenario.",
            "zh": "（c） 为这种情况设计一个奖励函数。"
        }
    },
    {
        "translation": {
            "en": "The domain concepts are those areas that the business believes have an impact on a customer’s decision to churn.",
            "zh": "领域概念是企业认为对客户客户流失决策有影响的领域。"
        }
    },
    {
        "translation": {
            "en": "If we divide both sides of this equation by the prior probability on the left-hand side, P(Y), we get",
            "zh": "如果我们将这个方程的两边除以左侧的先验概率 P（Y），我们得到"
        }
    },
    {
        "translation": {
            "en": "Table B.1[758] lists a small dataset of instances from the sample space shown in Figure B.1[757]. We will use this example dataset to illustrate how to map the terminology of probability into the language of predictive analytics:",
            "zh": "表B.1[758]列出了图B.1[757]所示样本空间中的一小部分实例数据集。我们将使用此示例数据集来说明如何将概率术语映射到预测分析的语言中："
        }
    },
    {
        "translation": {
            "en": "S-I-R models, 644",
            "zh": "S-I-R 型号，644"
        }
    },
    {
        "translation": {
            "en": "One of the things that makes learning the structure of a Bayesian network so difficult is that it is possible to define several different Bayesian networks as representations for the same full joint probability distribution.",
            "zh": "学习贝叶斯网络结构如此困难的原因之一是，可以将几个不同的贝叶斯网络定义为相同完全联合概率分布的表示。"
        }
    },
    {
        "translation": {
            "en": "It is also possible to directly illustrate the hierarchical nature of AHC using a dendrogram.",
            "zh": "也可以使用树状图直接说明AHC的层次结构。"
        }
    },
    {
        "translation": {
            "en": "The simple linear regression model we looked at in Section 7.2.1[312] handled only a single descriptive feature. Interesting problems in predictive analytics, however, are multivariable4 in nature. Fortunately, extending the simple linear regression model to a multivariable linear regression model is straightforward. We can define a multivariable linear regression model as",
            "zh": "我们在 Section 7.2.1[312] 中查看的简单线性回归模型只处理了一个描述性特征。然而，预测分析中有趣的问题本质上是多变量的4。幸运的是，将简单的线性回归模型扩展到多变量线性回归模型很简单。我们可以将多变量线性回归模型定义为"
        }
    },
    {
        "translation": {
            "en": "This is a row vector that is created by subtracting each descriptive feature value of instance b from the corresponding feature values of a.",
            "zh": "这是一个行向量，通过从实例 b 的相应特征值中减去实例 b 的每个描述性特征值而创建。"
        }
    },
    {
        "translation": {
            "en": "Predictive: a predictive descriptive feature provides information that is useful in estimating the correct value of a target feature.",
            "zh": "预测性：预测性描述性特征提供的信息可用于估计目标特征的正确值。"
        }
    },
    {
        "translation": {
            "en": "SHOP FREQUENCY",
            "zh": "店铺频率"
        }
    },
    {
        "translation": {
            "en": "The network schematic on the right of Figure 8.37[502] illustrates the details of how neurons within the different layers of a specific example simple recurrent network are connected.",
            "zh": "图8.37[502]右侧的网络示意图说明了特定示例简单循环网络的不同层内的神经元如何连接的细节。"
        }
    },
    {
        "translation": {
            "en": "range, 747",
            "zh": "范围，747"
        }
    },
    {
        "translation": {
            "en": "6.4.4   Bayesian Networks",
            "zh": "6.4.4 贝叶斯网络"
        }
    },
    {
        "translation": {
            "en": "Unsupervised learning presents us with a more complicated evaluation challenge than supervised learning.",
            "zh": "无监督学习给我们带来了比监督学习更复杂的评估挑战。"
        }
    },
    {
        "translation": {
            "en": "Once the instances have been sorted, we look for adjacent pairs that have different target levels. In Table 4.9[147] we can see that four pairs of adjacent instances have a transition between the target levels: instances d2 and d4, d4 and d3, d3 and d7, and d1 and d5. The boundary value between each of these pairs is simply the average of their ELEVATION values:",
            "zh": "对实例进行排序后，我们将查找具有不同目标级别的相邻对。在表 4.9[147] 中，我们可以看到四对相邻实例在目标级别之间有转换：实例 d2 和 d4、d4 和 d3、d3 和 d7 以及 d1 和 d5。这些对之间的边界值只是其 ELEVATION 值的平均值："
        }
    },
    {
        "translation": {
            "en": "The information gain ratio is computed by dividing the information gain of a feature by the amount of information used to determine the value of the feature",
            "zh": "信息增益比的计算方法是将特征的信息增益除以用于确定特征值的信息量"
        }
    },
    {
        "translation": {
            "en": "3. One of the best-known and earliest applications of solving a problem by reducing the sum of squared errors occurred in 1801, when Carl Friedrich Gauss used it to minimize the measurement error in astronomical data and by doing so was able to extrapolate the position of the dwarf planet Ceres, which had recently been found but then was lost behind the glare of the sun.",
            "zh": "3. 通过减少平方误差之和来解决问题的最著名和最早的应用之一发生在 1801 年，当时卡尔·弗里德里希·高斯 （Carl Friedrich Gauss） 用它来最小化天文数据中的测量误差，并由此能够推断出矮行星谷神星的位置，这颗行星最近被发现，但后来消失在太阳的眩光后面。"
        }
    },
    {
        "translation": {
            "en": "di refers to the descriptive features of the ith instance in a dataset.",
            "zh": "di 是指数据集中第 i 个实例的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm is the most well-known approach to clustering.",
            "zh": "k-means 聚类算法是最著名的聚类方法。"
        }
    },
    {
        "translation": {
            "en": "data management tools, 42",
            "zh": "数据管理工具，42"
        }
    },
    {
        "translation": {
            "en": "5.4.4   Predicting Continuous Targets",
            "zh": "5.4.4 预测连续目标"
        }
    },
    {
        "translation": {
            "en": "After it has been trained to accurately encode its inputs into a low-dimensional space and then decode them back into the original feature space, an auto-encoder can be used for feature generation by focusing on the output of the first encoder part of the network.",
            "zh": "在训练其输入准确编码到低维空间，然后将它们解码回原始特征空间后，自动编码器可以通过关注网络第一个编码器部分的输出来用于特征生成。"
        }
    },
    {
        "translation": {
            "en": "We use a subscript to identify the particular neuron that the δ is associated with; for example, δi is the δ for neuron i and is equivalent to the term .",
            "zh": "我们使用下标来识别与δ相关的特定神经元;例如，δi 是神经元 i 的δ，等价于项 。"
        }
    },
    {
        "translation": {
            "en": "Long short-term memory (LSTM) networks have addressed instability in the propagation of weights through a sequential model by removing this repeated multiplication by the shared weights.",
            "zh": "长短期记忆 （LSTM） 网络通过顺序模型消除了共享权重的重复乘法，解决了权重传播的不稳定性问题。"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance is different from the other distance metrics we have looked at because it allows us to take into account how spread out the instances in a dataset are when judging similarities.",
            "zh": "马氏距离与我们研究过的其他距离指标不同，因为它允许我们在判断相似性时考虑数据集中实例的分布程度。"
        }
    },
    {
        "translation": {
            "en": "The silhouette described in the previous section, however, can be used effectively to achieve the latter, and this approach to choosing k is described in this section.",
            "zh": "然而，上一节中描述的轮廓可以有效地用于实现后者，本节将介绍这种选择 k 的方法。"
        }
    },
    {
        "translation": {
            "en": "The SPEED and AGILITY ratings for 20 college athletes and whether they were drafted by a professional team.",
            "zh": "20 名大学运动员的速度和敏捷性评级，以及他们是否由专业团队选拔。"
        }
    },
    {
        "translation": {
            "en": "Modeling points in time for a scenario with no real outcome period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "对没有实际结果周期的场景的时间点进行建模（每条线代表一个客户，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "9.8   The profit matrix for the payday loan credit scoring problem.",
            "zh": "9.8 发薪日贷款信用评分问题的利润矩阵。"
        }
    },
    {
        "translation": {
            "en": "Klubička, Filip, Giancarlo D. Salton, and John D. Kelleher. 2018. Is it worth it? Budget-related evaluation metrics for model selection. In Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018).",
            "zh": "Klubička、Filip、Giancarlo D. Salton 和 John D. Kelleher。2018. 值得吗？用于模型选择的预算相关评估指标。第十一届语言资源与评估国际会议（LREC 2018）论文集。"
        }
    },
    {
        "translation": {
            "en": "So, for any instance that is actually on the decision boundary, the RPM and VIBRATION values satisfy the equality in Equation (7.23)[339].",
            "zh": "因此，对于任何实际位于决策边界上的实例，RPM 和 VIBRATION 值满足等式 （7.23）[339] 中的相等性。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.13[296] illustrates a Bayesian network with a topology that encodes this causal theory.",
            "zh": "图6.13[296]显示了一个贝叶斯网络，其拓扑结构编码了这种因果理论。"
        }
    },
    {
        "translation": {
            "en": "Similarly, under Claimant Links, the Links with Other Claims and Links with Current Claim domain subconcepts highlight the fact that the links to or from this claimant can be broken down into links related to the current claim and links relating to other claims.",
            "zh": "同样，在“索赔人链接”下，“与其他权利要求的链接”和“与当前权利要求域的链接”子概念突出了这样一个事实，即与该索赔人之间的链接可以分解为与当前索赔相关的链接和与其他索赔相关的链接。"
        }
    },
    {
        "translation": {
            "en": "Consequently, in each iteration of the training algorithm we will complete a single epoch (a single pass through our four examples and hence through the full dataset), and there will be a single weight update per epoch.",
            "zh": "因此，在训练算法的每次迭代中，我们将完成一个 epoch（通过我们的四个示例进行一次传递，从而通过整个数据集），并且每个 epoch 将有一个权重更新。"
        }
    },
    {
        "translation": {
            "en": "In this section we discuss extensions and variations of the naive Bayes model that increase its ability to generalize and avoid overfitting (smoothing) and that allow it to handle continuous descriptive features. We also describe Bayesian networks, which are a probability-based modeling approach that allows us to include more subtle assumptions in a model than the global assumption of conditional independence between all descriptive features that the naive Bayes model makes.",
            "zh": "在本节中，我们将讨论朴素贝叶斯模型的扩展和变体，这些扩展和变体提高了其泛化和避免过度拟合（平滑）的能力，并允许它处理连续的描述性特征。我们还描述了贝叶斯网络，这是一种基于概率的建模方法，它允许我们在模型中包含比朴素贝叶斯模型所做的所有描述性特征之间的条件独立性的全局假设更微妙的假设。"
        }
    },
    {
        "translation": {
            "en": "business problem, 23",
            "zh": "业务问题， 23"
        }
    },
    {
        "translation": {
            "en": "Occam’s razor, 123, 292",
            "zh": "奥卡姆剃刀，123,292"
        }
    },
    {
        "translation": {
            "en": "46. This example is taken from (Mahalunkar and Kelleher, 2018), which reports on experiments that use formal grammars to understand the representational capacity of recurrent neural networks to model long-distance dependencies.",
            "zh": "46. 这个例子取自（Mahalunkar and Kelleher， 2018），它报告了使用形式语法来理解递归神经网络对长距离依赖关系进行建模的表示能力的实验。"
        }
    },
    {
        "translation": {
            "en": "Typically, the third dimension of a filter is referred to as the depth of the filter, with the term channel specifically used to describe the depth of the data representation of a color image.",
            "zh": "通常，滤波器的第三个维度称为滤波器的深度，术语通道专门用于描述彩色图像的数据表示的深度。"
        }
    },
    {
        "translation": {
            "en": "Out of the candidate models shown, the third model from the top (with w[1] set to 0.62), passes most closely through the actual dataset and is the one that most accurately fits the relationship between office sizes and office rental prices—but how do we measure this formally?",
            "zh": "在所示的候选模型中，从顶部开始的第三个模型（w[1] 设置为 0.62）最接近实际数据集，并且最准确地拟合办公室规模和办公室租金价格之间的关系——但是我们如何正式衡量这一点？"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature LOC and the target feature, PREFCHANNEL.",
            "zh": "（c） 下面的可视化图说明了分类特征 LOC 与目标特征 PREFCHANNEL 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "4.2   The different question sequences that can follow in a game of Guess Who beginning with the question Does the person wear glasses?",
            "zh": "4.2 猜猜谁游戏中可以遵循的不同问题序列，从问题开始：这个人戴眼镜吗？"
        }
    },
    {
        "translation": {
            "en": "In cases in which a subtree is deemed to be overfitting, pruning the subtree means replacing the subtree with a leaf node that makes a prediction on the basis of the majority target feature level (or average target feature value) of the dataset created by merging the instances from all the leaf nodes in the subtree.",
            "zh": "在子树被视为过拟合的情况下，修剪子树意味着将子树替换为叶节点，该叶节点根据通过合并子树中所有叶节点的实例创建的数据集的大多数目标特征级别（或平均目标特征值）进行预测。"
        }
    },
    {
        "translation": {
            "en": "Because a single consistent model cannot be found on the basis of the sample training dataset alone, we say that machine learning is fundamentally an ill-posed problem.",
            "zh": "因为仅基于样本训练数据集无法找到一个单一的一致模型，所以我们说机器学习从根本上说是一个病态的问题。"
        }
    },
    {
        "translation": {
            "en": "CMODELFLUX_U/G/R/I/Z",
            "zh": "CMODELFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "In this way the revenue commission hopes to maximize the yield from the audits that it performs.",
            "zh": "通过这种方式，收入委员会希望最大限度地提高其执行的审计的收益。"
        }
    },
    {
        "translation": {
            "en": "1. a dot product between the information stored in the memory buffer (the hidden layer activations from the previous time-step encoded as vector ht−1) and the weight matrix for the weights on the connections from the memory buffer to the hidden neurons;",
            "zh": "1. 存储在内存缓冲区中的信息（编码为向量 HT-1 的前一个时间步长的隐藏层激活）与从内存缓冲区到隐藏神经元的连接上的权重的权重矩阵之间的点积;"
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic index, 558, 561, 586, 593",
            "zh": "接收机工作特征指数，558、561、586、593"
        }
    },
    {
        "translation": {
            "en": "In fact, swallows migrate to warmer countries, windmills are made to spin by wind, and tall people often choose to play basketball because of the advantage their height gives them in that game.",
            "zh": "事实上，燕子会迁徙到温暖的国家，风车会被风吹动，高个子经常选择打篮球，因为他们的身高在比赛中给他们带来了优势。"
        }
    },
    {
        "translation": {
            "en": "This is an example of a greedy action selection policy.",
            "zh": "这是贪婪操作选择策略的一个示例。"
        }
    },
    {
        "translation": {
            "en": "Observation and outcome periods defined by an event rather than by a fixed point in time (each line represents a prediction subject, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "由事件而不是由固定时间点定义的观测和结果周期（每条线代表一个预测主题，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "We can measure the sampling density across a feature space in terms of the average density of a unit hypercube26 in the feature space.",
            "zh": "我们可以根据特征空间中单位超立方体 26 的平均密度来测量特征空间中的采样密度。"
        }
    },
    {
        "translation": {
            "en": "Preparation",
            "zh": "制备"
        }
    },
    {
        "translation": {
            "en": "We will use an example from social science to illustrate how to construct a causal graph using this hybrid approach. In this example, we will build a Bayesian network that enables us to predict the level of corruption in a country based on a number of macroeconomic and social descriptive features. Table 6.18[295] lists some countries described using the following features:26",
            "zh": "我们将使用社会科学中的一个例子来说明如何使用这种混合方法构建因果图。在这个例子中，我们将建立一个贝叶斯网络，使我们能够根据一些宏观经济和社会描述性特征来预测一个国家的腐败程度。表6.18[295]列出了一些使用以下特征描述的国家：26"
        }
    },
    {
        "translation": {
            "en": "The 6 and 9 partitions each contain just one instance.",
            "zh": "6 和 9 分区各只包含一个实例。"
        }
    },
    {
        "translation": {
            "en": "measures of similarity, 181",
            "zh": "相似度量，181"
        }
    },
    {
        "translation": {
            "en": "(b) If you used a 1-NN model, what class would be assigned to the mystery animal?",
            "zh": "（乙）假如你使用1-NN模型，神秘动物会被分到什么类别？"
        }
    },
    {
        "translation": {
            "en": "error rate, 155",
            "zh": "错误率，155"
        }
    },
    {
        "translation": {
            "en": "To illustrate how this is done, we use a modified version of the vegetation classification dataset given in Table 4.3[136] in which the ELEVATION feature now contains actual elevations in feet.",
            "zh": "为了说明如何做到这一点，我们使用了表 4.3[136] 中给出的植被分类数据集的修改版本，其中 ELEVATION 要素现在包含以英尺为单位的实际高程。"
        }
    },
    {
        "translation": {
            "en": "It is relatively standard in image processing to use ReLUs for the network, and so we assume throughout this section that the neurons use the rectified linear function as their activation function.",
            "zh": "在图像处理中，将 ReLU 用于网络是相对标准的，因此我们在本节中假设神经元使用校正的线性函数作为它们的激活函数。"
        }
    },
    {
        "translation": {
            "en": "2. In fact,it can be argued that a preference toward shallower decision trees is a good idea in general and can be viewed as following Occam’s razor. Occam’s razor is the principle of keeping theories as simple as possible. It is named after a 14th-century Franciscan monk, William of Occam (sometimes spelled Ockham), who was one of the first to formulate this principle. The razor in the title comes from the idea of shaving off any unnecessary assumptions from a theory.",
            "zh": "2. 事实上，可以说，偏爱较浅的决策树总体上是一个好主意，可以被视为遵循奥卡姆剃刀。奥卡姆剃刀是保持理论尽可能简单的原则。它以 14 世纪的方济各会修道士奥卡姆的威廉（有时拼写为奥卡姆）的名字命名，他是最早制定这一原则的人之一。标题中的剃须刀来自从理论中去除任何不必要的假设的想法。"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors is a particularly convenient error function to use because the model errors on different examples and also the errors on different outputs (e.g., consider a network that has multiple neurons in the output layer) are independent and therefore the overall error is just the sum of the individual errors.",
            "zh": "平方误差之和是一个特别方便使用的误差函数，因为不同示例上的模型误差以及不同输出上的误差（例如，考虑一个在输出层中有多个神经元的网络）是独立的，因此总体误差只是单个误差的总和。"
        }
    },
    {
        "translation": {
            "en": "9.4.2.3 Average class accuracy Classification accuracy can mask poor performance.",
            "zh": "9.4.2.3 平均类准确率 分类准确度可以掩盖性能不佳。"
        }
    },
    {
        "translation": {
            "en": "Anscombe’s quartet, 84",
            "zh": "安斯科姆的四重奏，84"
        }
    },
    {
        "translation": {
            "en": "6.1 Big Idea",
            "zh": "6.1 大创意"
        }
    },
    {
        "translation": {
            "en": "Table 8.1",
            "zh": "表 8.1"
        }
    },
    {
        "translation": {
            "en": "Wrapper approaches are more computationally expensive than filters, as they involve training multiple models during each iteration.",
            "zh": "包装器方法的计算成本高于过滤器，因为它们涉及在每次迭代期间训练多个模型。"
        }
    },
    {
        "translation": {
            "en": "To calculate the vector of gradients ∂ℰt/∂ht−1, we first need to calculate the error gradient with respect to changes in hxt for each of the four layers of neurons that receive hxt as input: the forget gate sigmoid layer, the input gate sigmoid layer, the input gate tanh layer, and the output gate sigmoid layer.",
            "zh": "为了计算梯度向量 ∂Et/∂ht−1，我们首先需要计算接收 hxt 作为输入的四层神经元中每一层的 hxt 变化的误差梯度：忘记门 S 形结肠层、输入门 S 形结肠层、输入门 Tanh 层和输出门 S 形结肠层。"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(b)[620] shows an updated distance matrix including 10.",
            "zh": "表10.5（b）[620]显示了包括10在内的更新距离矩阵。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7",
            "zh": "图 4.7"
        }
    },
    {
        "translation": {
            "en": "That said, filter approaches are faster and often result in models with good accuracy.",
            "zh": "也就是说，滤波方法速度更快，并且通常会产生具有良好精度的模型。"
        }
    },
    {
        "translation": {
            "en": "Consequently, feature selection is a particularly important process for nearest neighbor algorithms.",
            "zh": "因此，特征选择对于最近邻算法来说是一个特别重要的过程。"
        }
    },
    {
        "translation": {
            "en": "3.9   Example of using small multiple histograms to visualize the relationship between a categorical feature and a continuous feature. All examples use data from the professional basketball team dataset in Table 3.7[73]: (a) a histogram of the AGE feature; (b) a histogram of the HEIGHT feature; (c) histograms of the AGE feature for instances displaying each level of the POSITION feature; and (d) histograms of the HEIGHT feature for instances displaying each level of the POSITION feature.",
            "zh": "3.9 使用小的多个直方图可视化分类特征和连续特征之间关系的示例。所有示例均使用表3.7[73]中职业篮球队数据集的数据：（a）AGE特征的直方图;（b） 高度特征的直方图;（c） 显示 POSITION 特征每个级别的实例的 AGE 特征直方图;以及 （d） 显示 POSITION 特征每个级别的实例的 HEIGHT 特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "She generated two possible target features from the data provided.",
            "zh": "她根据提供的数据生成了两个可能的目标特征。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.8[398] illustrates the distinction between linearly separable and non-linearly separable functions, using examples from Boolean logic: AND, OR, and XOR functions.",
            "zh": "图 8.8[398] 使用布尔逻辑示例说明了线性可分离函数和非线性可分离函数之间的区别：AND、OR 和 XOR 函数。"
        }
    },
    {
        "translation": {
            "en": "Quinn, Graham E., Chai H. Shin, Maureen G. Maguire, and Richard A. Stone. 1999. Myopia and ambient lighting at night. Nature 399 (6732): 113–114. http://dx.doi.org/10.1038/20094.",
            "zh": "奎因、格雷厄姆 E.、柴 H. 辛、莫琳 G. 马奎尔和理查德 A. 斯通。1999. 近视和夜间环境照明.自然399（6732）：113-114。http://dx.doi.org/10.1038/20094。"
        }
    },
    {
        "translation": {
            "en": "There is also an array of modifiable risk factors, including alcohol and drug use, unhealthy diet, stress and depression, and lack of physical exercise.",
            "zh": "还有一系列可改变的风险因素，包括酗酒和吸毒、不健康的饮食、压力和抑郁以及缺乏体育锻炼。"
        }
    },
    {
        "translation": {
            "en": "In generating this figure we have assumed that the algorithm selected the features to split on using the following ordering over the features: SPEED, AGILITY.",
            "zh": "在生成此图时，我们假设算法使用以下特征排序来选择要拆分的特征：速度、敏捷性。"
        }
    },
    {
        "translation": {
            "en": "So, at each node the algorithm will choose the feature to split on by selecting the feature with the lowest weighted variance for the target feature",
            "zh": "因此，在每个节点上，算法将通过选择目标特征加权方差最低的特征来选择要拆分的特征"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the 5-level two-stage model (classification accuracy: 79.410%, average class accuracy: 53.118%).",
            "zh": "5级两阶段模型的混淆矩阵（分类准确率：79.410%，平均类准确率：53.118%）。"
        }
    },
    {
        "translation": {
            "en": "Appendix D is a new section covering the fundamentals of linear algebra that underpin the new chapter on deep learning.",
            "zh": "附录 D 是一个新章节，涵盖了线性代数的基础知识，支撑了深度学习的新章节。"
        }
    },
    {
        "translation": {
            "en": "FIBER2FLUXIVAR_U/G/R/I/Z",
            "zh": "FIBER2FLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "5.4.5.4 Summary In this section we have introduced a number of commonly used metrics and indexes for judging similarity between instances in a feature space.",
            "zh": "5.4.5.4 小结 在本节中，我们介绍了一些常用的指标和索引，用于判断特征空间中实例之间的相似性。"
        }
    },
    {
        "translation": {
            "en": "If we increase the number of descriptive features, the dimensionality of the feature space increases.",
            "zh": "如果我们增加描述性特征的数量，特征空间的维数就会增加。"
        }
    },
    {
        "translation": {
            "en": "d_r0",
            "zh": "d_r0"
        }
    },
    {
        "translation": {
            "en": "In this example, is it better to classify a galaxy that should be other as an elliptical galaxy or vice versa?",
            "zh": "在这个例子中，将一个应该是其他星系的星系归类为椭圆星系更好，反之亦然吗？"
        }
    },
    {
        "translation": {
            "en": "In either case, the search continues from the new node as before.",
            "zh": "无论哪种情况，搜索都会像以前一样从新节点继续。"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.18(e)[226] we have, again, maintained the sampling density (the density of the marked unit hypercube is ) at the expense of a very large increase in the number of instances—there are 29 × 29 × 29 = 24,389 instances in this figure!",
            "zh": "在图 5.18（e）[226] 中，我们再次保持了采样密度（标记单位超立方体的密度为 ），但代价是实例数量的大幅增加——此图中有 29 个× 29 个× 29 = 24,389 个实例！"
        }
    },
    {
        "translation": {
            "en": "Price Prediction: Businesses such as hotel chains, airlines, and online retailers need to constantly adjust their prices in order to maximize returns based on factors such as seasonal changes, shifting customer demand, and the occurrence of special events. Predictive analytics models can be trained to predict optimal prices on the basis of historical sales records. Businesses can then use these predictions as an input into their pricing strategy decisions.",
            "zh": "价格预测：连锁酒店、航空公司和在线零售商等企业需要不断调整价格，以便根据季节变化、客户需求变化和特殊事件的发生等因素实现回报最大化。可以训练预测分析模型，以根据历史销售记录预测最佳价格。然后，企业可以将这些预测用作其定价策略决策的输入。"
        }
    },
    {
        "translation": {
            "en": "We can use a value from a PDF as a relative measure of likelihood because when the interval is very small, the actual area under a PDF curve for that interval can be approximated (with a small error proportional to the width of the interval) by the height of the PDF curve at the center of the interval multiplied by the width of the interval.",
            "zh": "我们可以使用 PDF 中的值作为似然的相对度量，因为当区间非常小时，该区间的 PDF 曲线下的实际面积可以近似（与区间宽度成正比的小误差）乘以区间中心的 PDF 曲线高度乘以区间的宽度。"
        }
    },
    {
        "translation": {
            "en": "chain rule (differentiation), 312, 325, 345, 381, 410, 413, 435, 731, 765, 768",
            "zh": "链式法则（微分）， 312， 325， 345， 381， 410， 413， 435， 731， 765， 768"
        }
    },
    {
        "translation": {
            "en": "symmetry criterion, 184, 211",
            "zh": "对称准则，184,211"
        }
    },
    {
        "translation": {
            "en": "If we compare this decision tree to the decision tree generated using information gain (see Figure 4.11[141]), it is obvious that the structure of the two trees is very different.",
            "zh": "如果我们将这个决策树与使用信息增益生成的决策树进行比较（见图4.11[141]），很明显，这两个树的结构非常不同。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4(b)[190] illustrates the decision boundary within the feature space for the two target levels in the college athlete dataset.",
            "zh": "图 5.4（b）[190] 说明了大学运动员数据集中两个目标水平的特征空间内的决策边界。"
        }
    },
    {
        "translation": {
            "en": "4.17   The final decision tree induced from the dataset in Table 4.11[152]. To illustrate how the tree generates predictions, this tree lists the instances that ended up at each leaf node and the prediction (PRED.) made by each leaf node.",
            "zh": "4.17 从表4.11[152]中的数据集中得出的最终决策树。为了说明树如何生成预测，此树列出了最终出现在每个叶节点上的实例以及每个叶节点所做的预测 （PRED.）。"
        }
    },
    {
        "translation": {
            "en": "Many of these methods make an assumption that a good clustering is a clustering in which the instances that belong to a given cluster are very close together, whereas the instances that belong to different clusters are far apart.",
            "zh": "其中许多方法都假设一个好的聚类是一种聚类，其中属于给定聚类的实例非常接近，而属于不同聚类的实例相距很远。"
        }
    },
    {
        "translation": {
            "en": "This has the advantage that the outputs of the network do not have to be transformed back into the original target feature range.",
            "zh": "这样做的优点是，网络的输出不必转换回原始目标特征范围。"
        }
    },
    {
        "translation": {
            "en": "The insurance claims fraud scenario we have been discussing throughout this section is a good example of this.",
            "zh": "我们在本节中讨论的保险索赔欺诈场景就是一个很好的例子。"
        }
    },
    {
        "translation": {
            "en": "B.2   Probability Distributions and Summing Out",
            "zh": "B.2 概率分布和求和"
        }
    },
    {
        "translation": {
            "en": "49. Forthis discussion we treat all neurons in an unrolled network that use the same set of weights as instances of the same neuron; for example, for a neuron in the hidden layer, a different instance of that neuron will occur in each time-step.",
            "zh": "49. 在这次讨论中，我们将展开网络中使用相同权重集的所有神经元视为同一神经元的实例;例如，对于隐藏层中的神经元，该神经元的不同实例将在每个时间步中出现。"
        }
    },
    {
        "translation": {
            "en": "z-score, 87",
            "zh": "Z-分数，87"
        }
    },
    {
        "translation": {
            "en": "Figure 4.10[140] illustrates the state of the decision tree after 8 has been split.",
            "zh": "图 4.10[140] 说明了 8 拆分后决策树的状态。"
        }
    },
    {
        "translation": {
            "en": "(c) Twenty people flip a fair coin. What is the probability that at least four of them will get heads?",
            "zh": "（c） 二十个人掷一枚公平的硬币。他们中至少有四个人获得头部的概率是多少？"
        }
    },
    {
        "translation": {
            "en": "11. The MAP prediction is the prediction mechanism that we assume throughout this book. An alternative mechanism is the Bayesian optimal classifier, but we won’t discuss it in this text. See Mitchell (1997) for more details.",
            "zh": "11. MAP预测是我们在本书中假设的预测机制。另一种机制是贝叶斯最优分类器，但本文中我们不会讨论它。详见Mitchell （1997）。"
        }
    },
    {
        "translation": {
            "en": "We are also very grateful to the anonymous reviewers who provided insightful and helpful comments on early drafts of the manuscript.",
            "zh": "我们也非常感谢匿名审稿人，他们对手稿的早期草稿提供了有见地和有益的意见。"
        }
    },
    {
        "translation": {
            "en": "MODULE 2",
            "zh": "模块 2"
        }
    },
    {
        "translation": {
            "en": "These new features can then be used to encode a level of the original categorical descriptive feature by setting the value of the new feature corresponding to the level of the categorical feature to 1 and the other new continuous features to 0.",
            "zh": "然后，可以使用这些新特征对原始分类描述性特征的级别进行编码，方法是将与分类特征级别对应的新特征的值设置为 1，并将其他新的连续特征设置为 0。"
        }
    },
    {
        "translation": {
            "en": "Once the constraints and optimization criterion have been defined, the solution to the constrained quadratic optimization process will identify and define all the components in Equation (7.41)[363] (the support vectors, w 0, and the α parameters) for the optimal decision boundary.",
            "zh": "一旦定义了约束条件和优化准则，约束二次优化过程的解将识别并定义方程（7.41）[363]中的所有分量（支持向量、w 0 和 α 参数）以获得最优决策边界。"
        }
    },
    {
        "translation": {
            "en": "Compare the sentences “The dog in that house is aggressive” with “The dogs in that house are aggressive.” In the first sentence, the subject of the sentence is singular, dog, and so we use the singular form of the verb is; in the second sentence, the subject is plural, dogs, and so we use the plural form of the verb are.46 Processing data of this type requires a model that has the capacity to remember relevant information from earlier in the sequence.",
            "zh": "比较句子“那所房子里的狗很有攻击性”和“那所房子里的狗很有攻击性”。在第一句话中，句子的主语是单数，狗，所以我们使用动词的单数形式是;在第二句话中，主语是复数，狗，因此我们使用动词的复数形式are.46处理这种类型的数据需要一个模型，该模型能够记住序列中前面的相关信息。"
        }
    },
    {
        "translation": {
            "en": "This means that we will generate two sets of error gradients when we backpropagate through an elementwise vector product, one for each branch of data that flows into the product.",
            "zh": "这意味着当我们通过逐元素向量乘积反向传播时，我们将生成两组误差梯度，每组用于流入乘积的每个数据分支。"
        }
    },
    {
        "translation": {
            "en": "What evaluation process will we follow? What performance measures will we use? Is the model fit for purpose?",
            "zh": "我们将遵循什么评估流程？我们将使用哪些绩效衡量标准？该模型是否适合目的？"
        }
    },
    {
        "translation": {
            "en": "partial derivative, 312, 318, 381, 765, 768",
            "zh": "偏导数， 312， 318， 381， 765， 768"
        }
    },
    {
        "translation": {
            "en": "where dec refers to a particular decile. Table 9.16[568] shows how gain is calculated for each decile in the email classification test set. The number of positive and negative instances in each decile is shown. Based on these numbers, the gain for each decile is calculated using Equation (9.19)[567] (the calculation of some other measures are also included in this table, and these will be explained shortly).",
            "zh": "其中 dec 是指特定的十分位数。表 9.16[568] 显示了如何计算电子邮件分类测试集中每个十分位数的增益。显示了每个十分位数中的正实例和负实例数。根据这些数字，使用公式（9.19）[567]计算每个十分位数的增益（此表中还包括其他一些测量值的计算，这些测量值将在稍后解释）。"
        }
    },
    {
        "translation": {
            "en": "The ‡ symbol marks the path of processing that generates the candidate cell update, prior to the filtering by the vector mask (see Equation (8.111)[511]).",
            "zh": "‡ 符号标记在矢量掩码过滤之前生成候选单元格更新的处理路径（参见公式 （8.111）[511]）。"
        }
    },
    {
        "translation": {
            "en": "However, the second value in ct−1 is also 1 but this is multiplied by an ft value near zero resulting in a c‡ value of 0.002472623.",
            "zh": "但是，ct−1 中的第二个值也是 1，但将其乘以接近零的 ft 值，得出 c‡ 值为 0.002472623。"
        }
    },
    {
        "translation": {
            "en": "In contrast to stratified sampling, sometimes we would like a sample to contain different relative frequencies of the levels of a particular feature than the distribution in the original dataset. For example, we may wish to create a sample in which the levels of a particular categorical feature are represented equally, rather than with whatever distribution they had in the original dataset. To do this, we can use under-sampling or over-sampling.",
            "zh": "与分层抽样相比，有时我们希望样本包含与原始数据集中的分布不同的特定特征水平的相对频率。例如，我们可能希望创建一个样本，其中特定分类特征的水平是平等的，而不是用它们在原始数据集中的任何分布来表示。为此，我们可以使用欠采样或过采样。"
        }
    },
    {
        "translation": {
            "en": "It also highlights the fact that the nearest neighbor algorithm uses multiple local models to create an implicit global model to map from the descriptive feature values to the target feature.",
            "zh": "它还强调了一个事实，即最近邻算法使用多个局部模型来创建一个隐式全局模型，以从描述性特征值映射到目标特征。"
        }
    },
    {
        "translation": {
            "en": "With this minimal information temporal-difference learning can be used to learn sophisticated, long-term behaviors.",
            "zh": "有了这个最小的信息，时间差异学习就可以用来学习复杂的、长期的行为。"
        }
    },
    {
        "translation": {
            "en": "The most important rule in evaluating models is not to use the same data sample both to evaluate the performance of a predictive model and to train it.",
            "zh": "评估模型时最重要的规则是不要使用相同的数据样本来评估预测模型的性能并对其进行训练。"
        }
    },
    {
        "translation": {
            "en": "Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. Long short-term memory. Neural Computation 9 (8): 1735–1780.",
            "zh": "Hochreiter、Sepp 和 Jürgen Schmidhuber。1997. 长短期记忆.神经计算 9 （8）：1735–1780。"
        }
    },
    {
        "translation": {
            "en": "The other key differentiating factor between reinforcement learning and the other approaches we have looked at in this book is that reinforcement learning relies less on using a dataset to drive learning and more on the ability to repeatedly attempt tasks in an environment.",
            "zh": "强化学习与我们在本书中研究的其他方法之间的另一个关键区别因素是，强化学习较少依赖于使用数据集来推动学习，而更多地依赖于在环境中重复尝试任务的能力。"
        }
    },
    {
        "translation": {
            "en": "similarity index, 212, 231",
            "zh": "相似度指数， 212， 231"
        }
    },
    {
        "translation": {
            "en": "This is the case because there were no instances in 8 that had a value of moderate for the SLOPE feature.",
            "zh": "之所以出现这种情况，是因为 8 中没有 SLOPE 特征的值为 moderate 的实例。"
        }
    },
    {
        "translation": {
            "en": "Consequently, before we can use the gradient descent algorithm to update the weights of a neuron in a hidden layer of the network, we must calculate a measure of how the neuron contributed to the overall error of the network at the output layer.",
            "zh": "因此，在使用梯度下降算法更新网络隐藏层中神经元的权重之前，我们必须计算出神经元如何导致输出层网络整体误差的度量。"
        }
    },
    {
        "translation": {
            "en": "Further, deep learning generally requires relatively powerful computer hardware.",
            "zh": "此外，深度学习通常需要相对强大的计算机硬件。"
        }
    },
    {
        "translation": {
            "en": "The insights that these prediction models produce are used to help organizations make data-driven decisions.",
            "zh": "这些预测模型产生的见解用于帮助组织做出数据驱动的决策。"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection is a popular alternative to forward sequential selection.",
            "zh": "向后顺序选择是前向顺序选择的常用替代方法。"
        }
    },
    {
        "translation": {
            "en": "A last point to make about this example is that careful examination of Table 7.3[331] shows why such a low learning rate is used in this example.",
            "zh": "关于这个例子的最后一点是，仔细检查表7.3[331]可以看出为什么在这个例子中使用了如此低的学习率。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7(a)[76] shows an example for the CAREER STAGE and SHOE SPONSOR features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "图3.7（a）[76]显示了表3.7[73]中职业篮球队数据集中的CAREER STAGE和SHOE SPONSOR特征的示例。"
        }
    },
    {
        "translation": {
            "en": "The definition of the student-t probability density function uses the gamma function, Γ(), which is a standard statistical function.16 The student-t distribution is a member of the location-scale family of distributions.17 These distributions take two parameters: a location parameter ϕ, which specifies the position of the peak density of the distribution, and a non-negative scale parameter ρ, which specifies how spread out the distribution is; the higher the scale the more spread out the distribution.",
            "zh": "学生-t 概率密度函数的定义使用伽马函数 Γ（），这是一个标准的统计函数。16 学生-t 分布是位置尺度分布族的成员。17 这些分布采用两个参数：位置参数 φ，它指定分布的峰值密度的位置，以及非负尺度参数 ρ， 指定分布的分布程度;比例越高，分布越分散。"
        }
    },
    {
        "translation": {
            "en": "leave-one-out cross validation, 545",
            "zh": "留一交叉验证，545"
        }
    },
    {
        "translation": {
            "en": "One of the most common uses of basis functions in linear regression is to train models to capture polynomial relationships.",
            "zh": "基函数在线性回归中最常见的用途之一是训练模型以捕获多项式关系。"
        }
    },
    {
        "translation": {
            "en": "Some functions are not defined in terms of just one variable.",
            "zh": "有些函数不是仅根据一个变量定义的。"
        }
    },
    {
        "translation": {
            "en": "Therefore, the network in Figure 8.4[390] has three layers.",
            "zh": "因此，图8.4[390]中的网络有三层。"
        }
    },
    {
        "translation": {
            "en": "Each instance in the dataset is then assigned to be a member of the cluster, i, to whose cluster centroid, ci, it is closest.",
            "zh": "然后，数据集中的每个实例都被指定为聚类 i 的成员，该聚类质心 ci 最接近其聚类质心 ci。"
        }
    },
    {
        "translation": {
            "en": "7.7   An extended version of the generators dataset from Table 7.6[339].",
            "zh": "7.7 表7.6[339]中生成器数据集的扩展版本。"
        }
    },
    {
        "translation": {
            "en": "density curve, 61",
            "zh": "密度曲线，61"
        }
    },
    {
        "translation": {
            "en": "This process continues until k evaluation experiments have been conducted and k sets of performance measures have been recorded.",
            "zh": "这个过程一直持续到进行了 k 个评估实验并记录了 k 组性能测量。"
        }
    },
    {
        "translation": {
            "en": "This probability, which is 0.4, can be counted directly from the dataset.",
            "zh": "这个概率是 0.4，可以直接从数据集中计数。"
        }
    },
    {
        "translation": {
            "en": "(b) What prediction will the decision tree generated in Part (a) of this question return for the following query?",
            "zh": "（b） 本问题（a）部分生成的决策树对以下查询将返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "6.4.4.1 Building Bayesian networks Bayesian networks can be constructed by hand or learned from data.",
            "zh": "6.4.4.1 构建贝叶斯网络 贝叶斯网络可以手工构建，也可以从数据中学习。"
        }
    },
    {
        "translation": {
            "en": "Acme Telephonica (AT) is a mobile phone operator that has customers across every state of the USA.",
            "zh": "Acme Telephonica （AT） 是一家移动电话运营商，客户遍布美国各州。"
        }
    },
    {
        "translation": {
            "en": "The Galaxy Zoo project started in 2007 and since then has collected millions of classifications of hundreds of thousands of galaxies.",
            "zh": "银河动物园项目始于2007年，从那时起已经收集了数十万个星系的数百万个分类。"
        }
    },
    {
        "translation": {
            "en": "For example, in Figure 8.42[516] the vector of error gradients ∂ℰ/∂ot is calculated using an elementwise addition of ∂ℰt/∂ot and ∂ℰt+1/∂ht",
            "zh": "例如，在图 8.42[516] 中，误差梯度 ∂E/∂ot 的向量是使用 ∂Et/∂ot 和 ∂Et+1/∂ht 的元素相加来计算的"
        }
    },
    {
        "translation": {
            "en": "NUMHANDSETS",
            "zh": "NUMPHONES手机"
        }
    },
    {
        "translation": {
            "en": "13. The bins created when equal-frequency binning is used are equivalent to percentiles (discussed in Section A.1[745]).",
            "zh": "13. 使用等频分档时产生的分档等同于百分位数（在第 A.1 节 [745] 中讨论）。"
        }
    },
    {
        "translation": {
            "en": "The question of which is the best one to use, however, still remains.",
            "zh": "然而，哪个是最好的使用的问题仍然存在。"
        }
    },
    {
        "translation": {
            "en": "3. To save space, throughout this chapter, named features are denoted by the uppercase initial letters of their names (e.g., the MENINGITIS feature is denoted M). If a named feature is binary, we use either the lowercase initial letter of the feature name to denote that the feature is true or the lowercase initial letter preceded by the ¬ symbol to denote that it is false (e.g., m denotes MENINGITIS = true, and ¬m denotes MENINGITIS = false).",
            "zh": "3. 为了节省篇幅，在本章中，命名特征用其名称的大写首字母表示（例如，脑膜炎特征表示为 M）。如果命名特征是二进制的，我们使用特征名称的小写首字母表示该特征为真，或者使用小写的首字母前面加上 ¬ 符号表示它是假的（例如，m 表示脑膜炎 = 真，μm 表示脑膜炎 = 假）。"
        }
    },
    {
        "translation": {
            "en": "The training dataset is then partitioned using the test.",
            "zh": "然后使用测试对训练数据集进行分区。"
        }
    },
    {
        "translation": {
            "en": "1.5 What Can Go Wrong with Machine Learning?",
            "zh": "1.5 机器学习会出什么问题？"
        }
    },
    {
        "translation": {
            "en": "16. The ROC index is in fact equivalent to the Wilcoxon-Mann-Whitney statistic used in significance testing.",
            "zh": "16. ROC指数实际上等同于显著性检验中使用的Wilcoxon-Mann-Whitney统计量。"
        }
    },
    {
        "translation": {
            "en": "Cybenko, George. 1989. Approximation by superpositions of sigmoids. Mathematics of Control, Signals and Systems 2: 303–314.",
            "zh": "赛宾科，乔治。1989. 通过sigmoids叠加的近似。控制、信号和系统数学 2：303–314。"
        }
    },
    {
        "translation": {
            "en": "Kollar, Daphne, and Nir Friedman. 2009. Probabilistic graphical models: Principles and techniques. MIT Press.",
            "zh": "科拉尔、达芙妮和尼尔弗里德曼。2009. 概率图形模型：原理和技术.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "and the product required to calculate the probability of any joint event in the domain using these four factors is",
            "zh": "使用这四个因子计算域中任何联合事件的概率所需的乘积是"
        }
    },
    {
        "translation": {
            "en": "In Section 8.2.1[384] we described how adding a dummy feature d[0] = 1 to the input vector of a neuron and also including the y-intercept term (or bias term) from the equation of a line as part of the weight vector of the neuron, as w[0], permitted us to calculate the weighted sum of the neuron using a single dot product between the weight vector and the input vector.",
            "zh": "在第 8.2.1 节[384]中，我们描述了如何将虚拟特征 d[0] = 1 添加到神经元的输入向量中，并将线方程中的 y 截距项（或偏差项）作为神经元权重向量的一部分，如 w[0]，允许我们使用权重向量和输入向量之间的单点积计算神经元的加权和。"
        }
    },
    {
        "translation": {
            "en": "The support vectors are highlighted in Figure 7.23[364] for each of the decision boundaries shown.",
            "zh": "图7.23[364]中突出显示了所示每个决策边界的支持向量。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the transformation implemented by the single weight matrix, generated by the product of weight matrices of the linear layers, will also implement a linear transformation on the input data.",
            "zh": "此外，由线性层的权重矩阵乘积生成的单个权重矩阵实现的变换也将对输入数据实现线性变换。"
        }
    },
    {
        "translation": {
            "en": "fat tails, 272",
            "zh": "肥尾巴，272"
        }
    },
    {
        "translation": {
            "en": "Table 4.12",
            "zh": "表 4.12"
        }
    },
    {
        "translation": {
            "en": "Find the lady is a card game that hucksters have been using to earn money from unsuspecting marks for centuries.1 In a game, the dealer holds three cards—one queen and two aces (as shown in Figure 6.1(a)[244])—and, typically with a little bit of flair, quickly drops these cards facedown onto a table.",
            "zh": "“寻找女士”是一种纸牌游戏，几个世纪以来，小贩们一直用它来从毫无戒心的标记中赚钱.1在游戏中，庄家持有三张牌——一张皇后牌和两张A牌（如图6.1（a）[244]所示）——并且通常有一点天赋，迅速将这些牌面朝下扔到桌子上。"
        }
    },
    {
        "translation": {
            "en": "(a) Intra-cluster distance; (b) inter-cluster distance; (c) a good clustering; and (d) a bad clustering.",
            "zh": "（a） 集群内距离;（b） 集群间距离;（c） 良好的聚类;（d）聚类不良。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.1(a)[314] shows a scatter plot of the office rentals dataset with RENTAL PRICE on the vertical (or y) axis and SIZE on the horizontal (or x) axis.",
            "zh": "图7.1（a）[314]显示了写字楼租赁数据集的散点图，其中RENTAL PRICE在垂直（或y）轴上，SIZE在水平（或x）轴上。"
        }
    },
    {
        "translation": {
            "en": "4.3.1   A Worked Example: Predicting Vegetation Distributions",
            "zh": "4.3.1 工作示例：预测植被分布"
        }
    },
    {
        "translation": {
            "en": "However, as the distribution of values in the continuous feature moves away from a uniform distribution, then some bins will end up with very few instances in them, and other bins will have a lot of instances in them.",
            "zh": "但是，随着连续特征中值的分布远离均匀分布，因此某些条柱中将包含很少的实例，而其他条柱中将包含大量实例。"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, B., P. Cunningham, S. Byrne, and O. I. Corrigan. 2002. The problem of bias in training data in regression problems in medical decision support. Artificial Intelligence in Medicine 24 (1): 51–70.",
            "zh": "Mac Namee， B.、P. Cunningham、S. Byrne 和 O. I. Corrigan。2002. 医疗决策支持中回归问题中的训练数据偏差问题.医学人工智能24（1）：51-70。"
        }
    },
    {
        "translation": {
            "en": "Guisan, Antoine, and Niklaus E. Zimmermann. 2000. Predictive habitat distribution models in ecology. Ecological Modelling 135 (2): 147–186.",
            "zh": "Guisan、Antoine 和 Niklaus E. Zimmermann。2000. 生态学中的预测生境分布模型.生态建模135（2）：147-186。"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1986. Induction of decision trees. Machine Learning 1 (1): 81–106.",
            "zh": "昆兰，J.罗斯。1986. 决策树的归纳。机器学习 1 （1）：81–106。"
        }
    },
    {
        "translation": {
            "en": "quadratic function, 352, 766",
            "zh": "二次函数， 352， 766"
        }
    },
    {
        "translation": {
            "en": "Three Laws of Robotics, 677",
            "zh": "机器人三定律，677"
        }
    },
    {
        "translation": {
            "en": "As a result, a generative model may outperform a discriminative model when trained on a small dataset with good prior knowledge.",
            "zh": "因此，当在具有良好先验知识的小型数据集上进行训练时，生成模型的性能可能优于判别模型。"
        }
    },
    {
        "translation": {
            "en": "This phenomenon is known as the vanishing gradient problem, because in deep networks the δ terms tend toward zero and vanish as we propagate the δs back to the early layers.",
            "zh": "这种现象被称为消失梯度问题，因为在深度网络中，δ项趋向于零，当我们将δ传播回早期层时，梯度项就会消失。"
        }
    },
    {
        "translation": {
            "en": "If both these weights are > 1, then the error gradient term will get larger each time it is multiplied; conversely, if both these weights are < 1, then the error gradient term will get smaller each time it is multiplied.",
            "zh": "如果这两个权重都> 1，则误差梯度项每次乘以时都会变大;相反，如果这两个权重都< 1，则误差梯度项每次相乘都会变小。"
        }
    },
    {
        "translation": {
            "en": "For example, in a medical diagnosis scenario, we would require that a prediction model be very accurate in its diagnoses and, in particular, never incorrectly predict that a sick patient is healthy, as that patient will then leave the health-care system and could subsequently develop serious complications.",
            "zh": "例如，在医学诊断场景中，我们要求预测模型的诊断非常准确，特别是永远不要错误地预测病人是健康的，因为该病人随后将离开医疗保健系统，随后可能出现严重的并发症。"
        }
    },
    {
        "translation": {
            "en": "Note that for space considerations we have rounded δ8 to four decimal places, and we will round the δs for other neurons similarly and use the rounded values in our calculations so that the results of the calculations match the numbers that are presented on the page.",
            "zh": "请注意，出于空间考虑，我们将 δ8 四舍五入到小数点后四位，我们将以类似的方式对其他神经元的 δ 进行四舍五入，并在计算中使用舍入值，以便计算结果与页面上显示的数字相匹配。"
        }
    },
    {
        "translation": {
            "en": "The top left cell in the confusion matrix, labeled TP, shows the number of instances in a test set that have a positive target feature value that were also predicted by the model to have a positive target feature value.",
            "zh": "混淆矩阵中标记为 TP 的左上角单元格显示测试集中具有正目标特征值的实例数，这些实例也被模型预测为具有正目标特征值。"
        }
    },
    {
        "translation": {
            "en": "Obviously, the differences between them make them more or less appropriate for a given dataset, and it often requires some experiments to figure out which is the best one for a given problem.",
            "zh": "显然，它们之间的差异使它们或多或少适合给定的数据集，并且通常需要一些实验来确定哪个是给定问题的最佳数据集。"
        }
    },
    {
        "translation": {
            "en": "13.2   The first draft of the domain concepts diagram developed by Jocelyn for the galaxy classification task.",
            "zh": "13.2 Jocelyn为星系分类任务开发的领域概念图初稿。"
        }
    },
    {
        "translation": {
            "en": "The motivation for highlighting the calculation of the weighted sum and activations during the forward pass of the algorithm is that these values are stored in memory after they are calculated and then used as part of the calculations involved in the backpropagation of the error gradients during the backward pass of the algorithm.",
            "zh": "在算法的前向传递期间突出显示加权和和激活的计算的动机是，这些值在计算后存储在内存中，然后用作算法向后传递期间误差梯度反向传播所涉及的计算的一部分。"
        }
    },
    {
        "translation": {
            "en": "If the input happens to be a color image, then we can distinguish the different layers of depth by the color channels.",
            "zh": "如果输入恰好是彩色图像，那么我们可以通过颜色通道区分不同的深度层。"
        }
    },
    {
        "translation": {
            "en": "convex surface, 318",
            "zh": "凸面，318"
        }
    },
    {
        "translation": {
            "en": "Furthermore, to align with most explanations of recurrent neural networks, in the subsequent discussion we adopt the following conventions: x denotes an input; h denotes a hidden layer; and y denotes the output from the network.",
            "zh": "此外，为了与大多数对递归神经网络的解释保持一致，在随后的讨论中，我们采用以下约定：x 表示输入;h 表示隐藏层;y 表示网络的输出。"
        }
    },
    {
        "translation": {
            "en": "Table 6.11",
            "zh": "表 6.11"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of α = 0.1, calculate the updated values for each of the weights in the network (w3,2,w3,0,,w2,1,w2,0) after the processing of this single training example.",
            "zh": "假设学习率为 α = 0.1，在处理完此训练示例后，计算网络中每个权重 （w3,2，w3,0，，w2,1，w2,0） 的更新值。"
        }
    },
    {
        "translation": {
            "en": "agent, 639",
            "zh": "特工，639"
        }
    },
    {
        "translation": {
            "en": "Rather than waiting for the episode to complete to find out the actual return of taking action at in state st, the update rule uses the current estimate of the expected return, Qπ(st+1,at+1).",
            "zh": "更新规则不是等待剧集完成来找出在状态 st 处执行操作的实际回报，而是使用预期回报的当前估计值 Qπ（st+1，at+1）。"
        }
    },
    {
        "translation": {
            "en": "20. This is just a slight modification of Equation (11.23)[655].",
            "zh": "20. 这只是对等式（11.23）[655]的轻微修改。"
        }
    },
    {
        "translation": {
            "en": "state generation function, 640, 673",
            "zh": "状态生成函数，640,673"
        }
    },
    {
        "translation": {
            "en": "Following this policy will lead to the best outcomes on the basis of current knowledge, but does not allow any opportunities for learning.",
            "zh": "遵循此政策将在当前知识的基础上取得最佳结果，但不允许任何学习机会。"
        }
    },
    {
        "translation": {
            "en": "On top of the inductive bias encoded in a machine learning algorithm, we also bias the outcome of a predictive data analytics project in lots of other ways. Consider the following questions:",
            "zh": "除了机器学习算法中编码的归纳偏差之外，我们还以许多其他方式对预测数据分析项目的结果产生偏差。请考虑以下问题："
        }
    },
    {
        "translation": {
            "en": "Although the task of inducing the optimal network structure from data is strictly intractable, algorithms that encode various assumptions exist that allow good models to be learned.",
            "zh": "尽管从数据中归纳出最佳网络结构的任务非常棘手，但存在编码各种假设的算法，可以学习良好的模型。"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling can divide the full data into training, validation, and test sets.",
            "zh": "保持抽样可以将完整数据分为训练集、验证集和测试集。"
        }
    },
    {
        "translation": {
            "en": "To understand how gradient descent works, imagine a hiker unlucky enough to be stranded on the side of a valley on a foggy day.",
            "zh": "要了解梯度下降的工作原理，请想象一个徒步旅行者不幸在大雾天被困在山谷的一侧。"
        }
    },
    {
        "translation": {
            "en": "consistent model, 6, 7, 121, 141",
            "zh": "一致型号，6、7、121、141"
        }
    },
    {
        "translation": {
            "en": "CLAIMS; NUMBER OF CLAIMS BY CLAIMANT IN LAST 3 MONTHS: NUM.",
            "zh": "索赔;索赔人在过去3个月内的索赔数量：NUM。"
        }
    },
    {
        "translation": {
            "en": "The first big term we come to in the equation is [a[1] − b[1],…, a[m] − b[m .",
            "zh": "我们在方程中得出的第一个大项是 [a[1] − b[1],..., a[m] − b[m ."
        }
    },
    {
        "translation": {
            "en": "4.12   The vegetation classification decision tree generated using information gain ratio.",
            "zh": "4.12 利用信息增益比生成的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "After these values have been found, a simple policy that gives a zero probability to any action that does not give the maximum return available from a state and a non-zero probability to any action (there might be more than one) that does lead to the maximum return available from that state is an optimal policy to use with any MDP.",
            "zh": "找到这些值后，一个简单的策略是，对于任何未提供状态可用最大回报的操作，以及为任何操作（可能有多个）提供非零概率，该操作（可能不止一个）可从该状态获得最大回报，是用于任何 MDP 的最佳策略。"
        }
    },
    {
        "translation": {
            "en": "1. ∂ℰ/∂ai is positive when ai > ti (see Equation (8.20)[411]); and",
            "zh": "1. ∂当 ai > ti 时，E/∂ai 为正（见等式 （8.20）[411]）;和"
        }
    },
    {
        "translation": {
            "en": "Evaluation, 17, 19, 534, 698, 725, 730",
            "zh": "评价， 17， 19， 534， 698， 725， 730"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE feature would be to use imputation.",
            "zh": "SOFT TISSUE 功能是使用插补。"
        }
    },
    {
        "translation": {
            "en": "Pearl, Judea. 1988. Probabilistic reasoning in intelligent systems: Networks of plausible inference. Morgan Kaufmann.",
            "zh": "珍珠，犹太。1988. 智能系统中的概率推理：似是而非的推理网络.摩根·考夫曼（Morgan Kaufmann）。"
        }
    },
    {
        "translation": {
            "en": "To generate these partitions for an iteration of the ε0 bootstrap, a random selection of m instances is taken from the full dataset to generate a test set, and the remaining instances are used as the training set.",
            "zh": "为了为 ε0 引导程序的迭代生成这些分区，从完整数据集中随机选择 m 个实例来生成测试集，其余实例用作训练集。"
        }
    },
    {
        "translation": {
            "en": "6.17   The relevant smoothed probabilities, from Table 6.16[284], needed by the naive Bayes model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, AB = 759.07, and LA = 8,000, and the calculation of the scores for each candidate prediction.",
            "zh": "6.17 朴素贝叶斯模型需要表6.16[284]中的相关平滑概率，以便对CH = 付费、GC = 担保人、ACC = 免费、AB = 759.07 和 LA = 8,000 的查询进行预测，并计算每个候选预测的分数。"
        }
    },
    {
        "translation": {
            "en": "The gain in a particular decile can be interpreted as a measure of how much better than random guessing the predictions made by a model are.",
            "zh": "特定十分位数的增益可以解释为衡量模型所做的预测比随机猜测好多少的指标。"
        }
    },
    {
        "translation": {
            "en": "In everyday usage, the word prediction has a temporal aspect—we predict what will happen in the future.",
            "zh": "在日常使用中，预测这个词有一个时间方面——我们预测未来会发生什么。"
        }
    },
    {
        "translation": {
            "en": "For categorical features, we should first examine the mode, 2nd mode, mode %, and 2nd mode % in the categorical features table in the data quality report.",
            "zh": "对于分类特征，我们应该首先检查数据质量报告的分类特征表中的模式、第二模式、模式%和第二模式%。"
        }
    },
    {
        "translation": {
            "en": "random forest, 159, 159, 171, 175",
            "zh": "随机森林， 159， 159， 171， 175"
        }
    },
    {
        "translation": {
            "en": "behavior policy, 657, 659, 664",
            "zh": "行为政策， 657， 659， 664"
        }
    },
    {
        "translation": {
            "en": "In contrast, the predictions made at the leaf nodes of this subtree are incorrect for d2 and d5 (because these patients are female, the prediction made is gen which does not match the validation dataset), so the error rate for the leaf nodes of this subtree is 0 + 2 = 2.",
            "zh": "相反，在该子树的叶节点上所做的预测对于 d2 和 d5 是不正确的（因为这些患者是女性，所以所做的预测是与验证数据集不匹配的 gen），因此该子树的叶节点的错误率为 0 + 2 = 2。"
        }
    },
    {
        "translation": {
            "en": "The way to solve this problem is to visualize intervals rather than specific values, and this is what a histogram does.",
            "zh": "解决这个问题的方法是可视化区间而不是特定值，这就是直方图的作用。"
        }
    },
    {
        "translation": {
            "en": "A sample test set with prediction scores and resulting predictions based on different threshold values.",
            "zh": "具有预测分数和基于不同阈值的预测结果的示例测试集。"
        }
    },
    {
        "translation": {
            "en": "The book provides case studies illustrating the application of machine learning within the industry context of data analytics, which also makes it a suitable text for practitioners looking for an introduction to the field and a textbook for industry training courses in these areas.",
            "zh": "本书提供了案例研究，说明了机器学习在数据分析行业背景下的应用，这也使其成为寻找该领域介绍的从业者的合适教材，也是这些领域行业培训课程的教科书。"
        }
    },
    {
        "translation": {
            "en": "As you know that the card is not in the position on the right, the likelihood that you had associated with this position is redistributed among the other two possibilities.",
            "zh": "如您所知，这张牌不在右侧的位置，因此您与该位置关联的可能性将重新分配给其他两种可能性。"
        }
    },
    {
        "translation": {
            "en": "The representation of a network as a sequence of matrix operations provides a transparent view on the depth of the network: a network depth is equal to the number of layers that have a weight matrix associated with them. This is why the input layer is not counted as part of the depth of the network.",
            "zh": "将网络表示为一系列矩阵操作提供了网络深度的透明视图：网络深度等于具有与之关联的权重矩阵的层数。这就是为什么输入层不计入网络深度的原因。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the variance of the δs values across for the neurons in the first hidden layer in the first iteration of training.",
            "zh": "（b） 计算训练第一次迭代中第一个隐藏层中神经元的 δs 值的方差。"
        }
    },
    {
        "translation": {
            "en": "Figure A.8",
            "zh": "图 A.8"
        }
    },
    {
        "translation": {
            "en": "In statistics it is very important to understand the difference between a population and a sample.",
            "zh": "在统计学中，了解总体和样本之间的差异非常重要。"
        }
    },
    {
        "translation": {
            "en": "vector, 216, 771",
            "zh": "矢量， 216， 771"
        }
    },
    {
        "translation": {
            "en": "The non-leaf nodes in the trees list the ID of the instance the node indexes and the feature and value pair that define the hyperplane partition on the feature space defined by the node.",
            "zh": "树中的非叶节点列出了实例的 ID、节点索引以及定义节点定义的特征空间上的超平面分区的特征和值对。"
        }
    },
    {
        "translation": {
            "en": "Shannon worked for AT&T Bell Labs, where he worked on the efficient encoding of messages for telephone communication.",
            "zh": "Shannon 曾在 AT&T 贝尔实验室工作，在那里他致力于对电话通信的消息进行高效编码。"
        }
    },
    {
        "translation": {
            "en": "As a result, the set of events that fulfill the conditions for each conditional probability in the sequence, and hence that are considered when we compute the probability, get smaller and smaller as more and more conditions are added.",
            "zh": "因此，随着添加的条件越来越多，满足序列中每个条件概率条件的事件集（因此在计算概率时考虑的事件集）变得越来越小。"
        }
    },
    {
        "translation": {
            "en": "In this case, the ABT was composed of a mixture of continuous and categorical descriptive features and had a categorical target feature.",
            "zh": "在这种情况下，ABT由连续和分类描述性特征的混合组成，并具有分类目标特征。"
        }
    },
    {
        "translation": {
            "en": "Data, however, like everything else in the world, is not constant.",
            "zh": "然而，与世界上其他一切事物一样，数据并不是恒定的。"
        }
    },
    {
        "translation": {
            "en": "6. Recall that in Section 3.2[55] we discussed the 68−95−99.7 rule associated with the normal distribution. This approach to handling outliers is based directly on this rule.",
            "zh": "6. 回想一下，在第 3.2 节[55]中，我们讨论了与正态分布相关的 68−95−99.7 规则。这种处理异常值的方法直接基于此规则。"
        }
    },
    {
        "translation": {
            "en": "For example, the calculation of the softmax activation for Neuron 8 and example d1 is 1.113661238/3.326635258 ≈ 0.3348.",
            "zh": "例如，Neuron 8 和示例 d1 的 softmax 激活计算为 1.113661238/3.326635258 ≈ 0.3348。"
        }
    },
    {
        "translation": {
            "en": "For example, for each neuron i that neuron k connects forward to",
            "zh": "例如，对于神经元 k 向前连接到的每个神经元 i"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm, like many other clustering algorithms, requires that the analyst choose the value for k as an input to the algorithm.",
            "zh": "与许多其他聚类算法一样，k 均值聚类算法要求分析人员选择 k 的值作为算法的输入。"
        }
    },
    {
        "translation": {
            "en": "The transactional record of calls made by individuals, stretching back over a time horizon of 18 months",
            "zh": "个人拨打电话的交易记录，可以追溯到 18 个月的时间跨度"
        }
    },
    {
        "translation": {
            "en": "This analysis will eliminate some solutions altogether and for those solutions that appear feasible will generate a list of the data and capacity required for successful implementation.",
            "zh": "这种分析将完全消除一些解决方案，对于那些看起来可行的解决方案，将生成成功实施所需的数据和容量列表。"
        }
    },
    {
        "translation": {
            "en": "3.5   Example scatter plots for pairs of features from the dataset in Table 3.7[73], showing (a) the strong positive covariance between HEIGHT and WEIGHT; (b) the strong negative covariance between SPONSORSHIP EARNINGS and AGE; and (c) the lack of strong covariance between HEIGHT and AGE.",
            "zh": "3.5 表3.7[73]中数据集中特征对的示例散点图，显示（a）身高和体重之间的强正协方差;（b）赞助收入与年龄之间的强负协方差;（c）身高和年龄之间缺乏强协方差。"
        }
    },
    {
        "translation": {
            "en": "Finally, Chapter 14 discusses a range of fundamental topics in machine learning and highlights that the selection of an appropriate machine learning approach for a given task involves factors beyond model accuracy—we must also match the characteristics of the model to the needs of the business.",
            "zh": "最后，第 14 章讨论了机器学习中的一系列基本主题，并强调为给定任务选择合适的机器学习方法涉及模型准确性之外的因素——我们还必须将模型的特征与业务需求相匹配。"
        }
    },
    {
        "translation": {
            "en": "0.33",
            "zh": "0.33"
        }
    },
    {
        "translation": {
            "en": "8.3.2 Backpropagation: Backpropagating the Error Gradients",
            "zh": "8.3.2 反向传播：反向传播误差梯度"
        }
    },
    {
        "translation": {
            "en": "where levels(t) is the set of levels in the domain of the target feature t; and P(t = l) is the probability of a randomly selected instance having the target feature level l.",
            "zh": "其中 levels（t） 是目标要素 t 域中的级别集;P（t = l） 是随机选择的实例具有目标特征级别 l 的概率。"
        }
    },
    {
        "translation": {
            "en": "Another commonly used measure of impurity is the Gini index",
            "zh": "另一个常用的杂质衡量标准是基尼系数"
        }
    },
    {
        "translation": {
            "en": "Table 5.7[208] lists the dataset from Table 5.5[204] after we have applied range normalization using a range of [0,1] to the SALARY and AGE features. When we normalize the features in a dataset, we also need to normalize the features in any query instances using the same normalization process and parameters. We normalize the query instance with SALARY =56,000 and AGE = 35 as follows:",
            "zh": "表 5.7[208] 列出了表 5.5[204] 中的数据集，之后我们使用 [0,1] 的范围对 SALARY 和 AGE 特征进行了范围归一化。当我们对数据集中的特征进行规范化时，我们还需要使用相同的规范化过程和参数对任何查询实例中的特征进行规范化。我们对 SALARY =56,000 和 AGE = 35 的查询实例进行规范化，如下所示："
        }
    },
    {
        "translation": {
            "en": "Features following a normal distribution are characterized by a strong tendency toward a central value and symmetrical variation to either side of this central tendency.",
            "zh": "遵循正态分布的特征是向中心值的强烈趋势和该中心趋势两侧的对称变化。"
        }
    },
    {
        "translation": {
            "en": "For example, rather than using full connectivity between layers (as we have done so far), we might decide to constrain the connectivity between layers so that each neuron in one layer connects only to a subset of the neurons in the next layer.",
            "zh": "例如，我们可能决定限制层之间的连接，以便一层中的每个神经元仅连接到下一层中的神经元子集，而不是在层之间使用完全连接（正如我们到目前为止所做的那样）。"
        }
    },
    {
        "translation": {
            "en": "Kansagara, Devan, Honora Englander, Amanda Salanitro, David Kagen, Cecelia Theobald, Michele Freeman, and Sunil Kripalani. 2011. Risk prediction models for hospital readmission: A systematic review. JAMA 306 (15): 1688–1698.",
            "zh": "Kansagara、Devan、Honora Englander、Amanda Salanitro、David Kagen、Cecelia Theobald、Michele Freeman 和 Sunil Kripalani。2011. 再入院风险预测模型：系统评价.美国医学会杂志 306 （15）：1688–1698。"
        }
    },
    {
        "translation": {
            "en": "In comparison with a box plot, an individual histogram provides more information; for example, histograms show the distribution of the values of a feature.",
            "zh": "与箱形图相比，单个直方图提供了更多信息;例如，直方图显示要素值的分布。"
        }
    },
    {
        "translation": {
            "en": "The resulting classification accuracies (average class accuracies and classification accuracies are the same in this case because the dataset is balanced) from the 10-fold cross validation experiment were 73.965%, 78.805%, and 78.226% for the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "对于k最近邻、逻辑回归和支持向量机模型，10倍交叉验证实验得到的分类精度（在这种情况下，平均类精度和分类精度相同，因为数据集是平衡的）分别为73.965%、78.805%和78.226%。"
        }
    },
    {
        "translation": {
            "en": "This is interesting because there are no instances listed in Table 4.3[136] where SLOPE = moderate and VEGETATION = chapparal. This example illustrates one way in which the predictions made by the model generalize beyond the dataset. Whether the generalizations made by the model are correct will depend on whether the assumptions used in generating the model (i.e., the inductive bias) are appropriate.",
            "zh": "这很有趣，因为表 4.3[136] 中没有列出 SLOPE = 中等且 VEGETATION = chapparal 的实例。此示例说明了模型所做的预测在数据集之外泛化的一种方式。模型的概括是否正确将取决于生成模型时使用的假设（即归纳偏差）是否合适。"
        }
    },
    {
        "translation": {
            "en": "The pattern that is evident in the two examples presented above continues as the threshold value is modified: as the threshold increases, TPR decreases and TNR increases, and as the threshold decreases, the opposite occurs.",
            "zh": "在上面的两个示例中显而易见的模式随着阈值的修改而继续：随着阈值的增加，TPR 降低，TNR 增加，而随着阈值的降低，情况正好相反。"
        }
    },
    {
        "translation": {
            "en": "The fact that more features contribute to the predictions made by the model has the effect that the weight updates get spread out across more weights because more weights will have been involved in the prediction and hence will have contributed to the error.",
            "zh": "更多的特征有助于模型做出的预测，这一事实的效果是，权重更新会分散到更多的权重中，因为预测中将涉及更多的权重，因此会导致误差。"
        }
    },
    {
        "translation": {
            "en": "Large-scale sky scanning projects are being used to map the whole of the night sky in intricate detail.",
            "zh": "大规模的天空扫描项目被用于绘制整个夜空的复杂细节。"
        }
    },
    {
        "translation": {
            "en": "An answer to Question 1, Is it a man?, splits the game domain into two sets of equal size: one containing Brian and John and one containing Aphra and Aoife.",
            "zh": "对问题 1 的回答是，它是一个男人吗？，将游戏域分成两组大小相等的集合：一组包含 Brian 和 John，另一组包含 Aphra 和 Aoife。"
        }
    },
    {
        "translation": {
            "en": "www.machinelearningbook.com",
            "zh": "www.machinelearningbook.com"
        }
    },
    {
        "translation": {
            "en": "On one hand, this analysis reveals that the variance of z is dependent on the number of inputs the neuron receives, nin; in general, the larger the number of inputs, the larger the variance.",
            "zh": "一方面，该分析表明 z 的方差取决于神经元接收的输入数量 nin;一般来说，输入数量越大，方差越大。"
        }
    },
    {
        "translation": {
            "en": "Deployment",
            "zh": "部署"
        }
    },
    {
        "translation": {
            "en": "light tails, 272",
            "zh": "光尾，272"
        }
    },
    {
        "translation": {
            "en": "In this case the customer contacting the company to cancel their service is the key event in time.",
            "zh": "在这种情况下，客户联系公司取消他们的服务是及时的关键事件。"
        }
    },
    {
        "translation": {
            "en": "9.12   (a) A complete ROC curve for the email classification example; and (b) a selection of ROC curves for different models trained on the same prediction task.",
            "zh": "9.12 （a） 电子邮件分类示例的完整 ROC 曲线;（b）为在同一预测任务上训练的不同模型选择ROC曲线。"
        }
    },
    {
        "translation": {
            "en": "7.4.3   Handling Categorical Descriptive Features",
            "zh": "7.4.3 处理分类描述性特征"
        }
    },
    {
        "translation": {
            "en": "15. We introduce variance in Section A.1.2[746], and although we extend the formal definition of variance here to include a dataset parameter 𝒟—we do this to explicitly highlight the fact that we are calculating the variance of a feature within a particular dataset, usually the dataset at a node in the tree—the measure of variance we are using is identical to the variance defined in Equation (A.3)[747].",
            "zh": "15. 我们在A.1.2[746]节中引入了方差，尽管我们在这里扩展了方差的正式定义，以包括数据集参数D，但我们这样做是为了明确强调我们正在计算特定数据集中特征的方差，通常是树中节点上的数据集，但我们使用的方差度量与方程（A.3）[747]中定义的方差相同。"
        }
    },
    {
        "translation": {
            "en": "Bellman Equations, 653",
            "zh": "贝尔曼方程，653"
        }
    },
    {
        "translation": {
            "en": "Although this may seem like an insignificant difference, the fact that both features now cover the same range has a huge impact on the performance of a similarity-based prediction model that uses this data.",
            "zh": "尽管这似乎是一个微不足道的差异，但两个特征现在覆盖相同的范围这一事实对使用此数据的基于相似性的预测模型的性能产生了巨大影响。"
        }
    },
    {
        "translation": {
            "en": "where k(q) is the prediction of the model for the query q given the parameter of the model k; levels(t) is the set of levels in the domain of the target feature, and l is an element of this set; i iterates over the instances di in increasing distance from the query q; ti is the value of the target feature for instance di; and δ(ti,l) is the Kronecker delta function, which takes two parameters and returns 1 if they are equal and 0 otherwise.",
            "zh": "其中 k（q） 是给定模型 k 参数的查询 q 的模型预测;levels（t） 是目标特征域中的级别集，l 是该集合中的元素;i 遍历实例 di，以增加与查询 q 的距离;ti 是目标特征的值，例如 di;δ（ti，l） 是 Kronecker delta 函数，它接受两个参数，如果它们相等，则返回 1，否则返回 0。"
        }
    },
    {
        "translation": {
            "en": "Over the next two iterations, two more pairs of instances from the original dataset are combined into clusters: d5 and d19 into 11, and d7 and d23 into 12.",
            "zh": "在接下来的两次迭代中，原始数据集中的另外两对实例被合并到集群中：d5 和 d19 合并为 11，d7 和 d23 合并为 12。"
        }
    },
    {
        "translation": {
            "en": "C   Differentiation Techniques for Machine Learning",
            "zh": "C 机器学习的微分技术"
        }
    },
    {
        "translation": {
            "en": "This is useful information that the business can use to attempt to devise other churn handling strategies in parallel to using this model to create call lists for the retention team.",
            "zh": "这是有用的信息，企业可以使用这些信息来尝试设计其他流失处理策略，同时使用此模型为保留团队创建呼叫列表。"
        }
    },
    {
        "translation": {
            "en": "The R2 measure",
            "zh": "R2 度量"
        }
    },
    {
        "translation": {
            "en": "Anton, H., and C. Rorres. 2010. Elementary linear algebra: Applications version. Wiley. http://books.google.ie/books?id=1PJ-WHepeBsC.",
            "zh": "安东，H. 和 C. 罗雷斯。2010. 初等线性代数：应用版.威利。http://books.google.ie/books?id=1PJ-WHepeBsC。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix (SPLOM) shows scatter plots for a whole collection of features arranged into a matrix.",
            "zh": "散点图矩阵 （SPLOM） 显示排列成矩阵的整个要素集合的散点图。"
        }
    },
    {
        "translation": {
            "en": "The prioritization given by the information gain values is extremely helpful for dealing with this.",
            "zh": "信息增益值给出的优先级对于处理此问题非常有帮助。"
        }
    },
    {
        "translation": {
            "en": "Another approach to scaling nearest neighbor models is to remove redundant or noisy instances from the dataset in which we search for neighbors.",
            "zh": "扩展最近邻模型的另一种方法是从我们搜索邻域的数据集中删除冗余或嘈杂的实例。"
        }
    },
    {
        "translation": {
            "en": "For different recurring fees, customers received different-sized bundles of call time.",
            "zh": "对于不同的经常性费用，客户会收到不同大小的通话时间捆绑包。"
        }
    },
    {
        "translation": {
            "en": "lucky split, 543, 586",
            "zh": "幸运斯普利特， 543， 586"
        }
    },
    {
        "translation": {
            "en": "The final attendance at a match is not available until midway through the game, so if we were trying to make predictions before kickoff, this feature would not be feasible.",
            "zh": "比赛的最终上座率要到比赛进行到一半时才能获得，因此如果我们试图在开球前进行预测，则此功能将不可行。"
        }
    },
    {
        "translation": {
            "en": "0.02999",
            "zh": "0.02999"
        }
    },
    {
        "translation": {
            "en": "The real skill in developing situational fluency is determining how much knowledge about the application domain the analytics professional requires in order to complete the project successfully.",
            "zh": "发展情境流畅性的真正技能是确定分析专业人员需要多少关于应用领域的知识才能成功完成项目。"
        }
    },
    {
        "translation": {
            "en": "In the model the value of w0 is − 0.0216, and the values of the α parameters are ⟨1.6811,0.2384,0.2055,1.7139⟩. What predictions would this model make for the following query instances?",
            "zh": "在模型中，w0 的值为 − 0.0216，α参数的值为 ⟨1.6811,0.2384,0.2055,1.7139⟩。此模型将对以下查询实例做出哪些预测？"
        }
    },
    {
        "translation": {
            "en": "The instances shown in Figure 5.14(a)[218] are based on this mobile telecoms scenario.",
            "zh": "图5.14（a）[218]中所示的实例基于此移动电信场景。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22(b)[361] shows a similar diagram but with a different decision boundary, which has a much larger margin.",
            "zh": "图7.22（b）[361]显示了一个类似的图表，但决策边界不同，其余量要大得多。"
        }
    },
    {
        "translation": {
            "en": "Note that in generating the feature map for each of these equations, we have applied the rectified linear activation function to the results of the weighted sum of each receptive field and the filter.43",
            "zh": "请注意，在为每个方程生成特征图时，我们已将修正线性激活函数应用于每个感受野和滤波器的加权和的结果43。"
        }
    },
    {
        "translation": {
            "en": "Table 6.18",
            "zh": "表 6.18"
        }
    },
    {
        "translation": {
            "en": "0.2466",
            "zh": "0.2466"
        }
    },
    {
        "translation": {
            "en": "Once distributions have been fitted to the data, we can extend the naive Bayes domain representation to include the PDFs.",
            "zh": "一旦分布拟合到数据中，我们就可以扩展朴素贝叶斯域表示以包括 PDF。"
        }
    },
    {
        "translation": {
            "en": "generative model, 733",
            "zh": "生成模型，733"
        }
    },
    {
        "translation": {
            "en": "Edwin agreed with both of these suggestions.",
            "zh": "埃德温同意这两个建议。"
        }
    },
    {
        "translation": {
            "en": "Table 4.13[157] lists a validation dataset for this domain, and Figure 4.19[158] illustrates how this validation dataset is used to perform reduced error pruning.",
            "zh": "表 4.13[157] 列出了该域的验证数据集，图 4.19[158] 说明了如何使用此验证数据集执行减少错误修剪。"
        }
    },
    {
        "translation": {
            "en": "A simple bicycle demand predictions dataset and the workings of the first iterations of training a gradient boosting model.",
            "zh": "一个简单的自行车需求预测数据集和训练梯度提升模型的第一次迭代的工作原理。"
        }
    },
    {
        "translation": {
            "en": "We use 𝕄 to refer to a model.",
            "zh": "我们使用 M 来指代模型。"
        }
    },
    {
        "translation": {
            "en": "Table 7.7",
            "zh": "表 7.7"
        }
    },
    {
        "translation": {
            "en": "Table 6.13",
            "zh": "表 6.13"
        }
    },
    {
        "translation": {
            "en": "A predictive model overfits the training set when at least some of the predictions it returns are based on spurious patterns present in the training data used to induce the model.",
            "zh": "当预测模型返回的至少一些预测基于用于诱导模型的训练数据中存在的虚假模式时，预测模型会过度拟合训练集。"
        }
    },
    {
        "translation": {
            "en": "The second phenomenon is that there is a difference in the number of times that each pixel in the image is used as an input to a neuron in the grid.",
            "zh": "第二个现象是，图像中每个像素被用作网格中神经元输入的次数存在差异。"
        }
    },
    {
        "translation": {
            "en": "The absence of ground truth, as discussed in the previous section, makes this choice notoriously difficult.",
            "zh": "正如上一节所讨论的，缺乏基本事实使得这种选择变得非常困难。"
        }
    },
    {
        "translation": {
            "en": "Ross further divided this dataset into three randomly sampled partitions—a training partition (50%), a validation partition (20%) and a test partition (30%). The training partition was used as the core training data for the prediction models built. The validation partition was used for tuning tasks, and the test partition was used for nothing other than a final test of the model to evaluate its performance.",
            "zh": "Ross 进一步将该数据集分为三个随机抽样分区——训练分区 （50%）、验证分区 （20%） 和测试分区 （30%）。训练分区被用作构建的预测模型的核心训练数据。验证分区用于调整任务，而测试分区仅用于对模型进行最终测试以评估其性能。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the variance of the δs across for the neurons in the last hidden layer in the first iteration of training.",
            "zh": "（a） 计算训练第一次迭代中最后一个隐藏层中神经元的 δs 方差。"
        }
    },
    {
        "translation": {
            "en": "There is a slight shift in emphasis here from evaluating the performance of one model, to evaluating the performance of a set of k models.",
            "zh": "这里的重点略有变化，从评估一个模型的性能，到评估一组 k 个模型的性能。"
        }
    },
    {
        "translation": {
            "en": "There are different ways in which a test set can be constructed from a dataset, but the simplest is to use what is referred to as a hold-out test set. A hold-out test set is created by randomly sampling a portion of the data in the ABT we created in the Data Preparation phase. This random sample is never used in the training process but reserved until after the model has been trained, when we would like to evaluate its performance. Figure 9.1[536] illustrates this process.",
            "zh": "从数据集构建测试集的方法有很多种，但最简单的方法是使用所谓的保留测试集。通过随机抽取我们在数据准备阶段创建的 ABT 中的部分数据来创建保留测试集。这个随机样本永远不会在训练过程中使用，而是保留到模型训练完毕后，我们想评估它的性能。图 9.1[536] 说明了这一过程。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35[497] presents a schematic of how two convolutional layers might be sequenced in a simple convolutional neural network.",
            "zh": "图 8.35[497] 显示了如何在简单的卷积神经网络中对两个卷积层进行测序的示意图。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.4[660] shows a grid world in which an agent must traverse an environment fraught with dangers.",
            "zh": "图 11.4[660] 显示了一个网格世界，在这个世界中，智能体必须穿越一个充满危险的环境。"
        }
    },
    {
        "translation": {
            "en": "CLUMPTHICKNESS",
            "zh": "结块厚度"
        }
    },
    {
        "translation": {
            "en": "Schematic of the typical sequences of layers found in a convolutional neural network.",
            "zh": "在卷积神经网络中发现的典型层序列的示意图。"
        }
    },
    {
        "translation": {
            "en": "equal-frequency binning, 89, 91, 102, 280, 294, 307",
            "zh": "等频分档， 89， 91， 102， 280， 294， 307"
        }
    },
    {
        "translation": {
            "en": "This reflects the fact that if we use a bigger sample, we can be more confident in our approximations of the characteristics of the full population.",
            "zh": "这反映了这样一个事实，即如果我们使用更大的样本，我们可以对整个总体特征的近似值更有信心。"
        }
    },
    {
        "translation": {
            "en": "31. In this case, we chose to standardize the features in the data rather than range-normalize them, in order to align the data configurations used to generate the plots in this section with the assumptions made in the accompanying mathematical analysis.",
            "zh": "31. 在这种情况下，我们选择对数据中的特征进行标准化，而不是对它们进行范围归一化，以便使用于生成本节中绘图的数据配置与随附的数学分析中所做的假设保持一致。"
        }
    },
    {
        "translation": {
            "en": "4.11   The final vegetation classification decision tree.",
            "zh": "4.11 最终的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "Table 7.1",
            "zh": "表 7.1"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23",
            "zh": "图 8.23"
        }
    },
    {
        "translation": {
            "en": "12.1 Business Understanding",
            "zh": "12.1 业务理解"
        }
    },
    {
        "translation": {
            "en": "ME1E2ERR_U/G/R/I/Z",
            "zh": "ME1E2ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "cosine, 216",
            "zh": "余弦， 216"
        }
    },
    {
        "translation": {
            "en": "The existence of N rays was first hinted at in an experiment performed at the lab that was designed to answer questions about the exact nature of the recently discovered X-ray radiation.",
            "zh": "N射线的存在最初是在实验室进行的一项实验中暗示的，该实验旨在回答有关最近发现的X射线辐射的确切性质的问题。"
        }
    },
    {
        "translation": {
            "en": "Consequently they are pure sets, and these partitions can be converted into leaf nodes.",
            "zh": "因此，它们是纯集合，这些分区可以转换为叶节点。"
        }
    },
    {
        "translation": {
            "en": "This tree results in a slightly lower classification accuracy on the test partition, 78.5%, but is very easy to interpret—the key features in determining churn are clearly AVGOVERBUNDLEMINS, BILLAMOUNTCHANGEPCT, and HANDSETAGE.",
            "zh": "此树导致测试分区的分类准确率略低，为 78.5%，但非常易于解释 — 确定流失的关键特征显然是 AVGOVERBUNDLEMINS、BILLAMOUNTCHANGEPCT 和 HANDSETAGE。"
        }
    },
    {
        "translation": {
            "en": "ENERGY",
            "zh": "能源"
        }
    },
    {
        "translation": {
            "en": "Bertsekas (2017) is also an excellent and detailed textbook that covers the fundamentals of reinforcement learning, with a leaning toward solutions based on dynamic programming.",
            "zh": "Bertsekas（2017）也是一本优秀而详细的教科书，涵盖了强化学习的基础知识，倾向于基于动态规划的解决方案。"
        }
    },
    {
        "translation": {
            "en": "The max pooling units have a receptive field of 2-by-1, and there is no overlap between the receptive fields of the max pooling units.",
            "zh": "最大池化单元的感受野为 2×1，并且最大池化单元的感受野之间没有重叠。"
        }
    },
    {
        "translation": {
            "en": "Friedman, J., J. Bently, and R. Finkel. 1977. An algorithm for finding the best matches in logarithmic expected time. ACM Transactions on Mathematical Software 3 (3): 209–226.",
            "zh": "弗里德曼，J.，J.本特利和R.芬克尔。1977. 一种在对数预期时间内寻找最佳匹配的算法。ACM 数学软件汇刊 3 （3）：209–226。"
        }
    },
    {
        "translation": {
            "en": "replicated training set, 160",
            "zh": "复制训练集，160"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the sum of squared errors for the set of predictions generated in Part (a).",
            "zh": "（b） 计算（a）部分中生成的一组预测的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "In TwentyTwos the player tries to collect a hand of cards that have a total value higher than the total value of the cards in the dealer’s hand, but not exceeding 22—a player is said to go bust when they exceed 22.",
            "zh": "在 TwentyTwos 中，玩家试图收集一手总价值高于庄家手中牌总价值但不超过 22 的牌——当玩家超过 22 时，据说玩家会破产。"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a k-NN model trained on a churn prediction problem.",
            "zh": "针对流失预测问题训练的 k-NN 模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Which customers were most likely to churn in the near future?",
            "zh": "哪些客户最有可能在不久的将来流失？"
        }
    },
    {
        "translation": {
            "en": "Franklin, Janet, Paul McCullough, and Curtis Gray. 2000. Terrain variables used for predictive mapping of vegetation communities in Southern California. In Terrain analysis: Principles and applications, eds. John P. Wilson and John C. Gallant. Wiley.",
            "zh": "富兰克林、珍妮特、保罗·麦卡洛和柯蒂斯·格雷。2000. 用于南加州植被群落预测测绘的地形变量.在《地形分析：原理和应用》中，John P. Wilson 和 John C. Gallant 编辑。威利。"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov statistic, 563, 583",
            "zh": "Kolmogorov-Smirnov统计，563,583"
        }
    },
    {
        "translation": {
            "en": "feature, 45, 758",
            "zh": "功能， 45， 758"
        }
    },
    {
        "translation": {
            "en": "In Line 7[476] the elementwise multiplication of the vector containing the activations of the neurons in the layer and the DropMask vector is performed (we use the notation ⊙ to denote an elementwise product).39 In the updated activation vector a(l)′ generated by this multiplication, the activations for all the neurons whose position in the activation vector correspond with a 0 value in DropMask will be 0.",
            "zh": "在第 7 行[476] 中，对包含层中神经元激活的向量和 DropMask 向量进行逐元素乘法（我们使用符号 ⊙ 表示逐元素乘积）.39 在由此乘法生成的更新激活向量 a（l）′ 中，所有神经元的激活在激活向量中的位置与 DropMask 中的 0 值相对应，将为 0。"
        }
    },
    {
        "translation": {
            "en": "First, the larger the variance of a feature, the less weight the difference between the values for that feature will contribute to the distance calculation.",
            "zh": "首先，要素的方差越大，该要素值之间的差对距离计算的影响就越小。"
        }
    },
    {
        "translation": {
            "en": "A grid world environment is defined by a rectangular grid in which an agent occupies a single cell and can move horizontally or vertically, one cell at a time, across the world.",
            "zh": "网格世界环境由矩形网格定义，其中代理占据单个像元，并且可以水平或垂直移动，一次一个像元，遍布整个世界。"
        }
    },
    {
        "translation": {
            "en": "This section covers the reasonably simple adjustments that must be made to the multivariable linear regression with gradient descent algorithm to handle categorical target features, in particular, logistic regression.",
            "zh": "本节介绍必须对具有梯度下降算法的多变量线性回归进行相当简单的调整，以处理分类目标特征，特别是逻辑回归。"
        }
    },
    {
        "translation": {
            "en": "4.4.5 Model Ensembles",
            "zh": "4.4.5 模型集合"
        }
    },
    {
        "translation": {
            "en": "The matrix in the middle of Equation (8.95)[491] represents the 3-by-3 sub-sampling layer.",
            "zh": "方程（8.95）[491]中间的矩阵表示3×3子采样层。"
        }
    },
    {
        "translation": {
            "en": "As the error rate of the root node of the subtree is higher than the error rate of the leaf nodes, the tree is not pruned.",
            "zh": "由于子树根节点的错误率高于叶节点的错误率，因此不会修剪树。"
        }
    },
    {
        "translation": {
            "en": "The product of two vectors of the same dimensions is known as the dot product. For example, given two row vectors F and G, both of which have dimensions 1 × 3",
            "zh": "两个相同维度的向量的乘积称为点积。例如，给定两个行向量 F 和 G，它们的维度分别为 1 × 3"
        }
    },
    {
        "translation": {
            "en": "Each subfigure highlights the local receptive field in the input of the highlighted neuron in the set of neurons.",
            "zh": "每个子图突出显示了一组神经元中突出显示的神经元输入中的局部感受野。"
        }
    },
    {
        "translation": {
            "en": "9.7   The out-of-time sampling process.",
            "zh": "9.7 不合时宜的抽样过程。"
        }
    },
    {
        "translation": {
            "en": "fail",
            "zh": "失败"
        }
    },
    {
        "translation": {
            "en": "In defining target features, it is especially important to seek input from domain experts.",
            "zh": "在定义目标特征时，寻求领域专家的意见尤为重要。"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are based on the concepts of a feature space and measures of similarity within this feature space. We have claimed that this is a very natural way for humans to think, and indeed, there is evidence from cognitive science to support a geometric basis to human thought (Gädenfors, 2004). Gädenfors (2004) also provides an excellent introduction and overview of distance metrics.",
            "zh": "最近邻模型基于特征空间的概念和该特征空间内相似性的度量。我们声称这是人类思维的一种非常自然的方式，事实上，认知科学的证据支持人类思维的几何基础（Gädenfors，2004）。Gädenfors（2004）也对距离指标进行了很好的介绍和概述。"
        }
    },
    {
        "translation": {
            "en": "The four factors required to represent the full joint distribution over the features HEADACHE, FEVER, VOMITING, and MENINGITIS (when the first three are assumed to be conditionally independent given MENINGITIS) can be stated as",
            "zh": "表示头痛、发热、呕吐和脑膜炎特征的完整关节分布所需的四个因素（当前三个因素被假定为有条件独立于脑膜炎时）可以表示为"
        }
    },
    {
        "translation": {
            "en": "1. Many computational models have the ability of universal approximation of bounded continuous functions; this property is not unique to neural networks (Reed and Marks, 1999). However, these results are still important because they show that neural networks with at least one hidden layer do have the representational capacity to approximate most functions that we would like them to. If neural networks were not capable of universal approximation, then they would be much less useful for prediction.",
            "zh": "1.许多计算模型具有有界连续函数的普遍逼近能力;这种特性并非神经网络所独有（Reed and Marks， 1999）。然而，这些结果仍然很重要，因为它们表明，具有至少一个隐藏层的神经网络确实具有近似我们希望它们实现的大多数函数的表示能力。如果神经网络不能进行普遍近似，那么它们对预测的用处就会小得多。"
        }
    },
    {
        "translation": {
            "en": "In this book we do not describe this step of the process in detail.23 Instead, we focus on explaining how the process is set up and how the training process reflects the inductive bias of searching for the separating hyperplane with the maximum margin.",
            "zh": "在本书中，我们没有详细描述该过程的这一步骤.23 相反，我们专注于解释该过程是如何建立的，以及训练过程如何反映搜索具有最大余量的分离超平面的归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "Plots of the logistic function and its derivative. This figure is Figure 4.6 of Kelleher (2019) and is used here with permission.",
            "zh": "逻辑函数及其导数的图。此图是 Kelleher （2019） 的图 4.6，经许可在此处使用。"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection has the advantage that it allows for the inclusion of sets of interacting features that individually may not be predictive (because all features are included at the beginning), with the extra computational cost of evaluating larger feature subsets.",
            "zh": "向后顺序选择的优点是，它允许包含一组相互作用的特征，这些特征单独可能无法预测（因为所有特征都包含在开始时），并且评估更大的特征子集会产生额外的计算成本。"
        }
    },
    {
        "translation": {
            "en": "Therefore, Neuron 3 illustrates that even with the heuristic of setting the bias weights to 0.1, a ReLU may still not activate to every (or in extreme cases any) input pattern.",
            "zh": "因此，Neuron 3 表明，即使采用将偏置权重设置为 0.1 的启发式方法，ReLU 可能仍然无法激活到每个（或在极端情况下任何）输入模式。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.30",
            "zh": "图 8.30"
        }
    },
    {
        "translation": {
            "en": "For example, in a customer churn scenario, we might use details of customer behavior from one year to build a training set and details of customer behavior from a subsequent year to build a test set.",
            "zh": "例如，在客户流失场景中，我们可能会使用一年的客户行为详细信息来构建训练集，并使用下一年的客户行为详细信息来构建测试集。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.19[441] illustrates the forward pass for d2 through the ReLU network.",
            "zh": "图 8.19[441] 说明了 d2 通过 ReLU 网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "MAE, 577",
            "zh": "梅，577"
        }
    },
    {
        "translation": {
            "en": "A new model, Δ2, is trained to predict these errors on the basis of the original descriptive feature values.",
            "zh": "训练新模型 Δ2 以根据原始描述性特征值预测这些误差。"
        }
    },
    {
        "translation": {
            "en": "True Positive (TP): an instance in the test set that had a positive target feature value and that was predicted to have a positive target feature value",
            "zh": "真阳性 （TP）：测试集中具有正目标特征值且预测具有正目标特征值的实例"
        }
    },
    {
        "translation": {
            "en": "Each iteration of the for loop (Lines 4[420] to 31[420]) involves the processing of a single mini-batch, including both a forward and backward pass of the algorithm and a single set of weight updates.",
            "zh": "for 循环的每次迭代（第 4 行 [420] 到 31[420]）都涉及单个小批量的处理，包括算法的正向和向后传递以及一组权重更新。"
        }
    },
    {
        "translation": {
            "en": "BMI: The patient’s body mass index (BMI) which is calculated as where weight is measured in kilograms and height in meters.",
            "zh": "BMI：患者的体重指数 （BMI），计算为以公斤为单位测量体重，以米为单位测量身高。"
        }
    },
    {
        "translation": {
            "en": "We have introduced information theory as a method of determining the shortest sequence of descriptive feature tests required to make a prediction.",
            "zh": "我们引入了信息论作为确定进行预测所需的最短描述性特征测试序列的方法。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6",
            "zh": "图 6.6"
        }
    },
    {
        "translation": {
            "en": "6.7   Exercises",
            "zh": "6.7 练习"
        }
    },
    {
        "translation": {
            "en": "(short) (broad)” is another one-semester machine learning course.",
            "zh": "（短）（broad）“是另一门为期一学期的机器学习课程。"
        }
    },
    {
        "translation": {
            "en": "Table 3.7",
            "zh": "表 3.7"
        }
    },
    {
        "translation": {
            "en": "3.4   An illustration of the 68–95–99.7 rule. The gray region defines the area where 95% of values in a sample are expected.",
            "zh": "3.4 68-95-99.7规则的例证。灰色区域定义了样本中 95% 的值的预期区域。"
        }
    },
    {
        "translation": {
            "en": "30. For more on the standardization of inputs, see the discussion on data preprocessing at the start of the worked example in Section 8.3.5[421].",
            "zh": "30. 有关输入标准化的更多信息，请参阅第 8.3.5 节 [421] 中工作示例开头关于数据预处理的讨论。"
        }
    },
    {
        "translation": {
            "en": "The median is another very useful measure of the central tendency of a sample.",
            "zh": "中位数是衡量样本集中趋势的另一个非常有用的指标。"
        }
    },
    {
        "translation": {
            "en": "Consequently, error gradients with respect to the cell state, c, are not repeatedly multiplied by a (weight) term that is shared across time-steps, and so these gradients are relatively stable as they flow backward along the cell state path.",
            "zh": "因此，与单元状态 c 相关的误差梯度不会重复乘以跨时间步长共享的（权重）项，因此这些梯度在沿单元状态路径向后流动时相对稳定。"
        }
    },
    {
        "translation": {
            "en": "The sequence of convolving a filter over an input, then applying a non-linear activation function, and finally sub-sampling the resulting feature maps is relatively standard in most modern convolutional networks, and often this sequence of operations is taken as defining a convolutional layer.",
            "zh": "在大多数现代卷积网络中，对输入进行卷积滤波器，然后应用非线性激活函数，最后对生成的特征图进行子采样的顺序是相对标准的，并且通常将此操作序列视为定义卷积层。"
        }
    },
    {
        "translation": {
            "en": "Grid worlds have long been used as a good way to illustrate the operation of reinforcement learning algorithms, and we will use this type of example in this section.",
            "zh": "长期以来，网格世界一直被用作说明强化学习算法操作的好方法，我们将在本节中使用这种类型的示例。"
        }
    },
    {
        "translation": {
            "en": "These books are suitable as reference texts for experienced practitioners and postgraduate researchers in machine learning.",
            "zh": "这些书籍适合作为机器学习领域经验丰富的从业者和研究生研究人员的参考书。"
        }
    },
    {
        "translation": {
            "en": "This dominance is reflected in the ranking of the instances as neighbors.",
            "zh": "这种优势反映在实例作为邻居的排名上。"
        }
    },
    {
        "translation": {
            "en": "Depending on how the value of the dealer’s hand that results from this compares to the value of the player’s hand the agent will move into one of the terminal states: LOSE, TIE, WIN, or TWENTYTWO.",
            "zh": "根据由此产生的庄家手牌的价值与玩家手牌的价值的比较情况，代理将进入最终状态之一：LOSE、TIE、WIN 或 TWENTYTWO。"
        }
    },
    {
        "translation": {
            "en": "Throughout this chapter we use rt to refer to the reward received after taking an action, at, at time-step t.",
            "zh": "在本章中，我们使用 rt 来指代在时间步长 t 处采取行动后获得的奖励。"
        }
    },
    {
        "translation": {
            "en": "couple",
            "zh": "夫妇"
        }
    },
    {
        "translation": {
            "en": "The volume of data involved. The amount of data that is available to an analytics project is important because (a) some modern datasets are so large that they can stretch even state-of-the-art machine learning tools; and (b) conversely, very small datasets can limit our ability to evaluate the expected performance of a model after deployment.",
            "zh": "涉及的数据量。可用于分析项目的数据量很重要，因为 （a） 一些现代数据集非常大，甚至可以扩展最先进的机器学习工具;（b）相反，非常小的数据集会限制我们在部署后评估模型预期性能的能力。"
        }
    },
    {
        "translation": {
            "en": "A logistic regression model has been trained to classify digits as either 0 or 1. The weights in this model are as follows:",
            "zh": "逻辑回归模型已经过训练，可将数字分类为 0 或 1。该模型中的权重如下："
        }
    },
    {
        "translation": {
            "en": "So, the only thing that needs to be taken into account in the state representation is the total value of the cards in the player’s hand and the value of the visible card dealt to the dealer.",
            "zh": "因此，在状态表示中唯一需要考虑的是玩家手中的牌的总价值以及发给庄家的可见牌的价值。"
        }
    },
    {
        "translation": {
            "en": "R, 222, 276",
            "zh": "R，222,276"
        }
    },
    {
        "translation": {
            "en": "The size of the individual normal density curves is proportional to the weight for that normal used in the mixture.",
            "zh": "单个法线密度曲线的大小与混合物中使用的法线的重量成正比。"
        }
    },
    {
        "translation": {
            "en": "To calculate the probability P(h | f) from P(H,F,V,M), we sum the values in all the cells where h and f are the case (the top four cells in the first column).",
            "zh": "为了从 P（H，F，V，M） 计算概率 P（h | f），我们将 h 和 f 为情况的所有单元格（第一列中的前四个单元格）中的值相加。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the 68−95−99.7 rule. The gray region defines the area where 95% of values in a sample are expected.",
            "zh": "68−95−99.7 规则的图示。灰色区域定义了样本中 95% 的值的预期区域。"
        }
    },
    {
        "translation": {
            "en": "Freund and Schapire (1995) introduced the AdaBoost algorithm, which is one of the seminal boosting algorithms.",
            "zh": "Freund 和 Schapire （1995） 引入了 AdaBoost 算法，这是开创性的提升算法之一。"
        }
    },
    {
        "translation": {
            "en": "Before attempting this conversion, Ross had to fully understand the business objectives of AT.",
            "zh": "在尝试这种转换之前，Ross 必须充分了解 AT 的业务目标。"
        }
    },
    {
        "translation": {
            "en": "This can help analysts know where to focus when investigating the data quality reports and visualizations created describing each cluster.",
            "zh": "这可以帮助分析人员知道在调查描述每个集群的数据质量报告和可视化效果时应该关注哪里。"
        }
    },
    {
        "translation": {
            "en": "subagging, 159",
            "zh": "下坡，159"
        }
    },
    {
        "translation": {
            "en": "Because of this, Jocelyn suspected that there would be a large amount of redundancy in the data as the measurements in the different bands were likely to be highly correlated.",
            "zh": "正因为如此，Jocelyn 怀疑数据中会存在大量冗余，因为不同波段的测量结果可能高度相关。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the different iterations of backpropagation during backpropagation through time.",
            "zh": "在反向传播过程中反向传播的不同迭代的图示。"
        }
    },
    {
        "translation": {
            "en": "de Fermat, Pierre, 243",
            "zh": "德·费马，皮埃尔，243"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the bike rental dataset from Table 4.14[162].",
            "zh": "（a） 表4.14[162]中的自行车租赁数据集图。"
        }
    },
    {
        "translation": {
            "en": "0.72",
            "zh": "0.72"
        }
    },
    {
        "translation": {
            "en": "Training a logistic regression model using this set of basis functions leads to the following model:",
            "zh": "使用这组基函数训练逻辑回归模型可生成以下模型："
        }
    },
    {
        "translation": {
            "en": "Acceleration is a measure of the rate of change of speed over time.",
            "zh": "加速度是速度随时间变化率的量度。"
        }
    },
    {
        "translation": {
            "en": "We can recalculate all the elements of the joint probability distribution using the product of these four factors:",
            "zh": "我们可以使用这四个因子的乘积重新计算联合概率分布的所有元素："
        }
    },
    {
        "translation": {
            "en": "This is not always the case, and making any of these partitions too small can result in a poor evaluation.",
            "zh": "情况并非总是如此，使这些分区中的任何一个都太小都可能导致评估不佳。"
        }
    },
    {
        "translation": {
            "en": "The problems of outliers and skewed distributions is clearly visible in these distributions.",
            "zh": "在这些分布中，异常值和偏态分布的问题清晰可见。"
        }
    },
    {
        "translation": {
            "en": "The decision tree in Figure 4.4(b)[122] would have returned the same prediction for the query instance. Indeed, both of the decision trees in Figures 4.4(a)[122] and 4.4(b)[122] are consistent with the dataset in Table 4.2[121] and can generalize sufficiently to make predictions for query instances like the one considered in our example. The fact that there are, at least, two decision trees that can do this raises the question: How do we decide which is the best decision tree to use?",
            "zh": "图 4.4（b）[122] 中的决策树将返回查询实例的相同预测。事实上，图4.4（a）[122]和图4.4（b）[122]中的决策树都与表4.2[121]中的数据集一致，并且可以充分泛化，以便对查询实例进行预测，就像我们示例中考虑的那样。事实上，至少有两棵决策树可以做到这一点，这就提出了一个问题：我们如何决定使用哪种决策树是最好的？"
        }
    },
    {
        "translation": {
            "en": "This leaf node indexes instance d12 (SPEED = 5.00, AGILITY = 2.50).",
            "zh": "此叶节点为实例 d12 （SPEED = 5.00， AGILITY = 2.50） 编制索引。"
        }
    },
    {
        "translation": {
            "en": "GINI COEF measures the equality in a society, where a larger Gini coefficient indicates a more unequal society.",
            "zh": "基尼系数COEF衡量一个社会的平等，基尼系数越大，表明社会越不平等。"
        }
    },
    {
        "translation": {
            "en": "sub-sampling layers, 489",
            "zh": "子采样层，489"
        }
    },
    {
        "translation": {
            "en": "One of the most commonly used processes for predictive data analytics projects is the Cross Industry Standard Process for Data Mining (CRISP-DM).12 Key features of the CRISP-DM process that make it attractive to data analytics practitioners are that it is non-proprietary; it is application, industry, and tool neutral; and it explicitly views the data analytics process from both an application-focused and a technical perspective.",
            "zh": "预测数据分析项目最常用的流程之一是数据挖掘的跨行业标准流程 （CRISP-DM）.12 CRISP-DM 流程的主要特点使其对数据分析从业者具有吸引力，因为它是非专有的;它是应用、行业和工具中立的;它明确地从以应用程序为中心的和技术角度看待数据分析过程。"
        }
    },
    {
        "translation": {
            "en": "where",
            "zh": "哪里"
        }
    },
    {
        "translation": {
            "en": "These histograms show a slight tendency for centers to be a little older than guards and forwards, but the relationship does not appear very strong, as each of the smaller histograms are similar to the overall uniform distribution of the AGE feature.",
            "zh": "这些直方图显示，中锋比后卫和前锋稍大一些，但这种关系似乎不是很强，因为每个较小的直方图都类似于 AGE 特征的整体均匀分布。"
        }
    },
    {
        "translation": {
            "en": "The target feature, PRICE, lists the prices that these properties were sold for in dollars.",
            "zh": "目标要素 PRICE 列出了这些属性以美元为单位的销售价格。"
        }
    },
    {
        "translation": {
            "en": "11. The co-occurrence of multiple missing values in a row is something that it is hard to find through summary analysis of the data and one of the reasons analytics practitioners should always eyeball extracts from a dataset during the data exploration process.",
            "zh": "11. 通过对数据的总结分析很难发现连续多个缺失值的共现，这也是分析从业者在数据探索过程中应始终关注数据集中提取的内容的原因之一。"
        }
    },
    {
        "translation": {
            "en": "Table 9.6",
            "zh": "表 9.6"
        }
    },
    {
        "translation": {
            "en": "domain, 34, 757",
            "zh": "域， 34， 757"
        }
    },
    {
        "translation": {
            "en": "The table that follows shows a historical dataset that has been collected for this task.",
            "zh": "下表显示了为此任务收集的历史数据集。"
        }
    },
    {
        "translation": {
            "en": "The members of the rival school basketball team from Figure A.3[747] ordered by height.",
            "zh": "图A.3[747]中敌对学校篮球队的成员按身高排序。"
        }
    },
    {
        "translation": {
            "en": "McGrayne, Sharon Bertsch. 2011. The theory that would not die: How Bayes’ rule cracked the enigma code, hunted down Russian submarines, and emerged triumphant from two centuries of controversy. Yale University Press.",
            "zh": "麦克格雷恩，莎朗·伯奇。2011. 不会消亡的理论：贝叶斯规则如何破解谜团密码，追捕俄罗斯潜艇，并在两个世纪的争议中取得胜利。耶鲁大学出版社。"
        }
    },
    {
        "translation": {
            "en": "Relative rarity, on the other hand, refers to scenarios in which the proportion of examples of the majority target levels in a dataset is much higher than the proportion of examples of the minority target level, but there is actually no shortage of examples of the minority target level.",
            "zh": "另一方面，相对稀有性是指数据集中多数目标水平的样本比例远高于少数目标水平的样本比例，但实际上不乏少数目标水平的例子。"
        }
    },
    {
        "translation": {
            "en": "bottleneck layer, 624, 628",
            "zh": "瓶颈层， 624， 628"
        }
    },
    {
        "translation": {
            "en": "Good",
            "zh": "好"
        }
    },
    {
        "translation": {
            "en": "The iterations of reduced error pruning for the decision tree in Figure 4.18[156] using the validation set in Table 4.13[157]. The subtree that is being considered for pruning in each iteration is highlighted in black. The prediction returned by each non-leaf node is listed in square brackets. The error rate for each node is given in parantheses.",
            "zh": "使用表4.13[157]中的验证集对决策树进行减少误差修剪的迭代[156]。在每次迭代中考虑修剪的子树以黑色突出显示。每个非叶节点返回的预测列在方括号中。每个节点的错误率以参数形式给出。"
        }
    },
    {
        "translation": {
            "en": "In the optimal control domain in which the Bellman optimality equations were originally conceived, solutions are calculated using dynamic programming.",
            "zh": "在最初构想贝尔曼最优方程的最优控制域中，使用动态规划计算解。"
        }
    },
    {
        "translation": {
            "en": "Both of these strategies depend on a reasonable sampling density of the training instances across the feature space.",
            "zh": "这两种策略都依赖于整个特征空间中训练实例的合理采样密度。"
        }
    },
    {
        "translation": {
            "en": "(a) The confusion matrix for a k-NN model trained on the payday loan credit scoring problem (average class accuracyHM = 83.824%); and (b) the confusion matrix for a decision tree model trained on the payday loan credit scoring problem (average class accuracyHM = 80.761%).",
            "zh": "（a） 在发薪日贷款信用评分问题上训练的 k-NN 模型的混淆矩阵（平均类准确率HM = 83.824%）;（b）在发薪日贷款信用评分问题上训练的决策树模型的混淆矩阵（平均类准确率HM = 80.761%）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.29[475] illustrates how different small networks are generated for each training example by randomly dropping neurons from the original large network.",
            "zh": "图 8.29[475] 说明了如何通过从原始大网络中随机丢弃神经元来为每个训练示例生成不同的小网络。"
        }
    },
    {
        "translation": {
            "en": "At this point in the motor insurance fraud detection project, we have decided to proceed with the proposed claim prediction solution, in which a model will be built that can predict the likelihood that an insurance claim is fraudulent.",
            "zh": "在汽车保险欺诈检测项目的这一点上，我们决定继续使用拟议的索赔预测解决方案，其中将建立一个模型来预测保险索赔欺诈的可能性。"
        }
    },
    {
        "translation": {
            "en": "The flow of information in Figure 8.40[509] is from left to right.",
            "zh": "图8.40[509]中的信息流是从左到右的。"
        }
    },
    {
        "translation": {
            "en": "8.2.1 Artificial Neurons",
            "zh": "8.2.1 人工神经元"
        }
    },
    {
        "translation": {
            "en": "After taking this action (Line 14[666]) and recording the reward, r0 = −1, and next state, s1 = 0-2, the behavior policy is used to select the next action that the agent will take (Line 14[666]).",
            "zh": "在执行此操作（第 14 行 [666]）并记录奖励 r0 = −1 和下一个状态 s1 = 0-2 后，行为策略用于选择代理将执行的下一个操作（第 14 行[666]）。"
        }
    },
    {
        "translation": {
            "en": "14. Although we didn’t mention it explicitly in other cases where we mentioned random sampling, we meant random sampling without replacement.",
            "zh": "14. 虽然我们在提到随机抽样的其他情况下没有明确提到它，但我们指的是没有替换的随机抽样。"
        }
    },
    {
        "translation": {
            "en": "Library of Congress Cataloging-in-Publication Data",
            "zh": "美国国会图书馆出版编目数据"
        }
    },
    {
        "translation": {
            "en": "(a) Some of the model predictions are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "（a） 上表中缺少一些模型预测（标有？）。计算这些。"
        }
    },
    {
        "translation": {
            "en": "These factors aside, the effectiveness of descriptive feature selection metrics can vary from domain to domain.",
            "zh": "撇开这些因素不谈，描述性特征选择指标的有效性可能因域而异。"
        }
    },
    {
        "translation": {
            "en": "This information should help if the model is to be rebuilt to address the fact that it has gone stale.",
            "zh": "如果要重建模型以解决模型已经过时的事实，则此信息应该会有所帮助。"
        }
    },
    {
        "translation": {
            "en": "If she repeats this process over and over again, she will make steady progress down the mountain until eventually she arrives at the bottom.",
            "zh": "如果她一遍又一遍地重复这个过程，她就会稳步下山，直到最终到达山脚下。"
        }
    },
    {
        "translation": {
            "en": "7.24   (a) The journey across an error surface; and (b) the changing sums of squared errors during this journey.",
            "zh": "7.24 （a） 穿越误差面的旅程;（b）在此过程中平方误差和的变化。"
        }
    },
    {
        "translation": {
            "en": "An advantage of the lazy learning strategy, however, is that similarity-based machine learning approaches are robust to concept drift.",
            "zh": "然而，惰性学习策略的一个优点是，基于相似性的机器学习方法对概念漂移具有鲁棒性。"
        }
    },
    {
        "translation": {
            "en": "In other words we must backpropagate the error back through the previous states of the network.",
            "zh": "换句话说，我们必须通过网络的先前状态将错误反向传播回来。"
        }
    },
    {
        "translation": {
            "en": "Note also that the weight matrix labels on the left of the figure are also the correct neuron labels for the weighted sum Z and activation matrix rows on that line.",
            "zh": "另请注意，图左侧的权重矩阵标签也是该线上加权总和 Z 和激活矩阵行的正确神经元标签。"
        }
    },
    {
        "translation": {
            "en": "Each iteration of this for loop propagates the activations for the mini-batch forward through the next layer of the network.",
            "zh": "此 for 循环的每次迭代都会将小批量的激活向前传播到网络的下一层。"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce a simple model of linear regression, some metrics for measuring the error of a model, and the concept of an error surface.",
            "zh": "在本节中，我们将介绍一个简单的线性回归模型、一些用于测量模型误差的指标以及误差面的概念。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5",
            "zh": "图 11.5"
        }
    },
    {
        "translation": {
            "en": "The bottom row illustrates the operations carried out in the output layer of the network.",
            "zh": "底行说明了在网络输出层中执行的操作。"
        }
    },
    {
        "translation": {
            "en": "This is why this set has very high entropy.",
            "zh": "这就是为什么这个集合具有非常高的熵。"
        }
    },
    {
        "translation": {
            "en": "We recommend that, in general, when calculating average class accuracy, the harmonic mean should be used rather than the arithmetic mean.",
            "zh": "我们建议，一般来说，在计算平均类精度时，应使用谐波平均值而不是算术平均值。"
        }
    },
    {
        "translation": {
            "en": "The prediction subject defines the basic level at which predictions are made, and each row in the ABT will represent one instance of the prediction subject—the phrase one-row-per-subject is often used to describe this structure.",
            "zh": "预测主体定义了进行预测的基本级别，ABT 中的每一行将代表预测主体的一个实例 - 短语 one-row-per subject 通常用于描述这种结构。"
        }
    },
    {
        "translation": {
            "en": "All these factors taken together indicated that decision trees were an appropriate modeling choice for this problem.",
            "zh": "所有这些因素加在一起表明，决策树是这个问题的合适建模选择。"
        }
    },
    {
        "translation": {
            "en": "(a) The path taken from the root node to a leaf node when we search the tree with a query SPEED = 6.00, AGILITY = 3.50; and (b) the ? marks the location of the query, and the dashed circle plots the extent of the target, and for convenience in the discussion, we have labeled some of the nodes with the IDs of the instances they index (12, 15, 18, and 21).",
            "zh": "（a） 当我们使用查询 SPEED = 6.00， AGILITY = 3.50 搜索树时，从根节点到叶节点的路径;及 （b） ？标记查询的位置，虚线圆圈绘制目标的范围，为了方便讨论，我们用它们索引的实例的 ID（12、15、18 和 21）标记了一些节点。"
        }
    },
    {
        "translation": {
            "en": "This removes the scaling of the δs by the derivative of the activation function, and so in this instance these vanishing gradients are caused by both the repeated multiplication by small weights during backpropagation and the fact that the calculation of a δ for a neuron involves a weighted sum calculation33 that in this network configuration results in the variance of the δs shrinking as they are backpropagated through the layers.",
            "zh": "这消除了激活函数导数对 δ 的缩放，因此在这种情况下，这些消失的梯度是由反向传播期间小权重的重复乘法引起的，以及神经元δ的计算涉及加权和计算33，在这种网络配置中，当它们通过层反向传播时，会导致 δ 的方差缩小。"
        }
    },
    {
        "translation": {
            "en": "So the large positive reward achieved when moving to the terminal state can only impact the Q value of the state that immediately preceded it.",
            "zh": "因此，在移动到最终状态时获得的大量正奖励只能影响紧接其之前状态的 Q 值。"
        }
    },
    {
        "translation": {
            "en": "Even if we discretized each of these 7 characteristics allowing just 5 levels (very low, low, medium, high, and very high), which would be a gross approximation, this would lead to 75 = 16,807 possible states.",
            "zh": "即使我们对这 7 个特征中的每一个都进行离散化，只允许 5 个级别（非常低、低、中、高和非常高），这将是一个粗略的近似值，这将导致 75 = 16,807 个可能的状态。"
        }
    },
    {
        "translation": {
            "en": "List of Tables",
            "zh": "表格列表"
        }
    },
    {
        "translation": {
            "en": "Figure 10.16",
            "zh": "图 10.16"
        }
    },
    {
        "translation": {
            "en": "Non-parametric models are more flexible but can struggle with large datasets.",
            "zh": "非参数模型更灵活，但在处理大型数据集时可能遇到困难。"
        }
    },
    {
        "translation": {
            "en": "Tanimoto similarity, 223",
            "zh": "谷本相似度，223"
        }
    },
    {
        "translation": {
            "en": "Also, we will use subscripts on uppercase letters to iterate over events.",
            "zh": "此外，我们将使用大写字母的下标来迭代事件。"
        }
    },
    {
        "translation": {
            "en": "Once Jocelyn had populated the ABT, she generated a data quality report (the initial data quality report covered the data in the raw SDSS dataset only, so a second one was required that covered the actual ABT) and performed an in-depth analysis of the characteristics of each descriptive feature. An extract from this data quality report is shown in Table 13.4[716].",
            "zh": "Jocelyn 填充 ABT 后，她生成了数据质量报告（初始数据质量报告仅涵盖原始 SDSS 数据集中的数据，因此需要第二份报告来涵盖实际 ABT），并对每个描述性特征的特征进行了深入分析。该数据质量报告的摘录如表13.4[716]所示。"
        }
    },
    {
        "translation": {
            "en": "Franklin, Janet. 2009. Mapping species distributions: Spatial inference and prediction (ecology, biodiversity and conservation). Cambridge University Press.",
            "zh": "富兰克林，珍妮特。2009. 绘制物种分布图：空间推断和预测（生态学、生物多样性和保护）。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "The simplest approach to normalization is range normalization, which performs a linear scaling of the original values of the continuous feature into a given range.",
            "zh": "归一化的最简单方法是范围归一化，它将连续特征的原始值线性缩放到给定范围内。"
        }
    },
    {
        "translation": {
            "en": "breast cancer, 109",
            "zh": "乳腺癌，109"
        }
    },
    {
        "translation": {
            "en": "11.8   Framing the action-value function as a prediction problem.",
            "zh": "11.8 将动作值函数构建为预测问题。"
        }
    },
    {
        "translation": {
            "en": "In backward sequential selection, we start with a feature subset including all the possible features in a dataset (shown on the right of Figure 5.19[228]).",
            "zh": "在向后顺序选择中，我们从包含数据集中所有可能特征的特征子集开始（如图 5.19[228] 右侧所示）。"
        }
    },
    {
        "translation": {
            "en": "If we initialize the network with the same initial set of weights that we used in Section 8.3.5 [421] and use the same data, training regime, and learning rate (α = 0.2), then the ReLU version of the network converges to an SSE < 0.0001 in just 424 epochs, as compared with the 7,656 epochs required to train the logistic network.",
            "zh": "如果我们使用在第 8.3.5 节 [421] 中使用的相同初始权重集初始化网络，并使用相同的数据、训练机制和学习率 （α = 0.2），那么网络的 ReLU 版本只需 424 个周期即可收敛到 SSE < 0.0001，而训练逻辑网络需要 7,656 个周期。"
        }
    },
    {
        "translation": {
            "en": "The potential difficulty in learning the class conditional densities, relative to the posterior class probabilities, is exacerbated in situations where we have a lot of descriptive features because, as the dimensionality of d increases, we will need more and more data to create good estimates for P(tl|d).",
            "zh": "相对于后验类概率，学习类条件密度的潜在困难在我们有很多描述性特征的情况下会加剧，因为随着 d 的维数增加，我们将需要越来越多的数据来创建对 P（tl|d） 的良好估计。"
        }
    },
    {
        "translation": {
            "en": "Because we start sampling from a random state, however, we do not know whether the initial state is an appropriate state from which to start generating samples.",
            "zh": "但是，由于我们从随机状态开始采样，因此我们不知道初始状态是否是开始生成样本的适当状态。"
        }
    },
    {
        "translation": {
            "en": "where ϕ is a set of basis functions applied to the descriptive features d, and w is a set of weights containing one weight for each member of ϕ.",
            "zh": "其中 φ 是应用于描述性特征 D 的一组基函数，W 是一组权重，其中包含 φ 的每个成员的一个权重。"
        }
    },
    {
        "translation": {
            "en": "The cardinality of the CREDITCARD and REGIONTYPE categorical features were higher than expected (the histograms for these features are shown in Figures 12.2(b)[695] and 12.2(c)[695]).",
            "zh": "CREDITCARD和REGIONTYPE分类特征的基数高于预期（这些特征的直方图如图12.2（b）[695]和12.2（c）[695]所示）。"
        }
    },
    {
        "translation": {
            "en": "inter-quartile range, 70, 749, 755",
            "zh": "四分位距， 70， 749， 755"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7",
            "zh": "图 7.7"
        }
    },
    {
        "translation": {
            "en": "A dataset of customers of a large national retail chain.",
            "zh": "一家大型全国性零售连锁店的客户数据集。"
        }
    },
    {
        "translation": {
            "en": "4.3   The vegetation classification dataset.",
            "zh": "4.3 植被分类数据集。"
        }
    },
    {
        "translation": {
            "en": "However, for a hidden neuron k, ak only indirectly affects ℰ, via the effect it has on the activations of downstream neurons that the ak is directly propagated to (and the chain reaction that these subsequent activations have on still later neuron activations).",
            "zh": "然而，对于一个隐藏的神经元k，ak只是间接影响E，通过它对ak直接传播到的下游神经元的激活的影响（以及这些后续激活对后来的神经元激活的连锁反应）。"
        }
    },
    {
        "translation": {
            "en": "Chang, Winston. 2012. R graphics cookbook: Practical recipes for visualizing data. O’Reilly Media.",
            "zh": "张，温斯顿。2012. R 图形说明书：可视化数据的实用方法。O'Reilly 媒体。"
        }
    },
    {
        "translation": {
            "en": "The first two of these probabilities are easy to calculate.",
            "zh": "这些概率中的前两个很容易计算。"
        }
    },
    {
        "translation": {
            "en": "We also took our first steps toward building predictive models in this chapter when we looked at correlation. A descriptive feature that correlates strongly with a target feature would be a good place to start building a predictive model, and we return to correlations in later chapters. Examining correlation between features as part of data exploration allows us to add extra outcomes to the list at the beginning of this section:",
            "zh": "在本章中，当我们研究相关性时，我们也迈出了构建预测模型的第一步。与目标特征密切相关的描述性特征将是开始构建预测模型的好地方，我们将在后面的章节中返回相关性。作为数据探索的一部分，检查要素之间的相关性允许我们将额外的结果添加到本节开头的列表中："
        }
    },
    {
        "translation": {
            "en": "9.9   Prediction score distributions for two different prediction models. The distributions in (a) are much better separated than those in (b).",
            "zh": "9.9 两种不同预测模型的预测分数分布。（a）中的分布比（b）中的分布分离得更好。"
        }
    },
    {
        "translation": {
            "en": "23. The K2 score is named after the K2 algorithm, one of the earliest and best-known algorithms for learning Bayesian networks (Cooper and Herskovits, 1992).",
            "zh": "23. K2 分数以 K2 算法命名，K2 算法是学习贝叶斯网络最早和最著名的算法之一（Cooper 和 Herskovits，1992 年）。"
        }
    },
    {
        "translation": {
            "en": "A schematic of the internal structure of a long short-term memory unit.",
            "zh": "长短期记忆单元的内部结构示意图。"
        }
    },
    {
        "translation": {
            "en": "In order to formally measure the fit of a linear regression model with a set of training data, we require an error function.",
            "zh": "为了正式测量线性回归模型与一组训练数据的拟合，我们需要一个误差函数。"
        }
    },
    {
        "translation": {
            "en": "This means that the sum of squared errors function is changed slightly to",
            "zh": "这意味着平方误差和函数略微更改为"
        }
    },
    {
        "translation": {
            "en": "5.4   The extended version of the college athletes dataset.",
            "zh": "5.4 大学运动员数据集的扩展版本。"
        }
    },
    {
        "translation": {
            "en": "Table 5.7",
            "zh": "表 5.7"
        }
    },
    {
        "translation": {
            "en": "prediction score, 556, 574",
            "zh": "预测得分，556,574"
        }
    },
    {
        "translation": {
            "en": "We then use the updated δs to backpropagate the error gradients to the preceding layer and also for the weight update calculations.",
            "zh": "然后，我们使用更新的 δ 将误差梯度反向传播到前一层，并用于权重更新计算。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.37[502] illustrates the architecture of a simple recurrent network.",
            "zh": "图 8.37[502] 说明了简单循环网络的架构。"
        }
    },
    {
        "translation": {
            "en": "Most people will remain in the SUSCEPTIBLE state indefinitely, P(S S) = 0.98, but with a small probability, P(S I) = 0.02, can transition to the INFECTED state.",
            "zh": "大多数人将无限期地保持易感状态，P（S S） = 0.98，但概率很小，P（S I） = 0.02，可以过渡到感染状态。"
        }
    },
    {
        "translation": {
            "en": "However, even when the gradients are defined, very large gradients are a problem.",
            "zh": "但是，即使定义了梯度，非常大的梯度也是一个问题。"
        }
    },
    {
        "translation": {
            "en": "For example, a dataset may record whether or not someone liked a movie, a customer bought a product, or someone visited a particular webpage.",
            "zh": "例如，数据集可以记录是否有人喜欢电影、客户是否购买了产品或是否有人访问了特定网页。"
        }
    },
    {
        "translation": {
            "en": "The for loop on Lines 12[420] to 14[420] is where the variables used to store these totals are initialized.",
            "zh": "第 12[420] 行到 14[420] 上的 for 循环是用于存储这些总数的变量初始化的位置。"
        }
    },
    {
        "translation": {
            "en": "It is also possible, however, for this function to be more elaborate when the observations over multiple time-steps are accumulated into a state.1 Using states instead of observations, Equation (11.1)[639] can be restated2",
            "zh": "然而，当多个时间步长上的观测值累积成一个状态时，这个函数也有可能更复杂.1使用状态而不是观测值，方程（11.1）[639]可以重述2"
        }
    },
    {
        "translation": {
            "en": "0.5015",
            "zh": "0.5015"
        }
    },
    {
        "translation": {
            "en": "clamp transformation, 70, 715",
            "zh": "钳位转换， 70， 715"
        }
    },
    {
        "translation": {
            "en": "Confident that your study will help you, you lay a dollar down to play a game, ready to guess that the queen is in the position on the right.",
            "zh": "你相信你的研究会对你有所帮助，于是你放下一美元来玩一个游戏，准备猜测女王在右边的位置。"
        }
    },
    {
        "translation": {
            "en": "Table 3.4[64] shows the structure of a data quality plan.",
            "zh": "表3.4[64]显示了数据质量计划的结构。"
        }
    },
    {
        "translation": {
            "en": "Smyth, B., and M. Keane. 1995. Remembering to forget: A competence preserving case deletion policy for case-based reasoning systems. In The fourteenth international joint conference on artificial intelligence (IJCAI-95), ed. C. Mellish, 337–382. ACM.",
            "zh": "史密斯，B. 和 M. 基恩。1995. 记住忘记：基于案例的推理系统的能力保留案例删除策略。第十四届国际人工智能联合会议（IJCAI-95），C. Mellish编辑，337-382。ACM。"
        }
    },
    {
        "translation": {
            "en": "k-fold cross validation, 543, 611",
            "zh": "K-fold 交叉验证， 543， 611"
        }
    },
    {
        "translation": {
            "en": "Support vector machines (SVM) are another approach to predictive modeling that is based on error-based learning.",
            "zh": "支持向量机 （SVM） 是另一种基于基于误差的学习的预测建模方法。"
        }
    },
    {
        "translation": {
            "en": "If we were to include the interval width when calculating conditional probabilities for a continuous descriptive feature in a naive Bayes prediction model, using Equation (6.16)[261], we would multiply the value returned by the PDF by the same interval width each time we calculated the likelihood score for a level of the target feature. Consequently, we can drop this multiplication and just use the value returned by the PDF as a relative measure of the likelihood that the feature takes a specific value.",
            "zh": "如果我们在朴素贝叶斯预测模型中计算连续描述性特征的条件概率时包括区间宽度，使用方程 （6.16）[261]，每次计算目标特征水平的似然分数时，我们都会将 PDF 返回的值乘以相同的区间宽度。因此，我们可以放弃此乘法，而仅使用 PDF 返回的值作为特征采用特定值的可能性的相对度量。"
        }
    },
    {
        "translation": {
            "en": "In particular, it preferences features with many levels because these features split the data into many small subsets, which tend to be pure irrespective of any correlation between the descriptive feature and the target feature.",
            "zh": "特别是，它优先选择具有多个级别的特征，因为这些特征将数据拆分为许多小子集，这些子集往往是纯的，而不管描述性特征和目标特征之间的任何相关性如何。"
        }
    },
    {
        "translation": {
            "en": "If we were to simply add these together, the positive and negative errors would effectively cancel each other out.",
            "zh": "如果我们简单地将这些加在一起，正误差和负误差将有效地相互抵消。"
        }
    },
    {
        "translation": {
            "en": "Worked example illustrating the dataflow through a multilayer, multifilter CNN.",
            "zh": "工作示例说明了通过多层、多滤波器 CNN 的数据流。"
        }
    },
    {
        "translation": {
            "en": "We say that features with this kind of relationship are positively covariant.",
            "zh": "我们说具有这种关系的特征是正协变的。"
        }
    },
    {
        "translation": {
            "en": "When we originally tried to calculate probabilities for this query, a problem arose from the requirement that we have instances in the training dataset where all the evidence events hold.",
            "zh": "当我们最初尝试计算此查询的概率时，出现了一个问题，即要求我们在训练数据集中具有所有证据事件都成立的实例。"
        }
    },
    {
        "translation": {
            "en": "We then present the naive Bayes model, the standard approach to using probability-based approaches to machine learning.",
            "zh": "然后，我们提出了朴素贝叶斯模型，这是使用基于概率的机器学习方法的标准方法。"
        }
    },
    {
        "translation": {
            "en": "Based on the updated errors, a new set of weights is calculated, marked in Table 7.8[348] as New Weights (after Iteration 2).",
            "zh": "根据更新的误差，计算一组新的权重，在表7.8[348]中标记为新权重（迭代2之后）。"
        }
    },
    {
        "translation": {
            "en": "There are three target levels, so three one-versus-all models are built.",
            "zh": "有三个目标级别，因此构建了三个一对一的模型。"
        }
    },
    {
        "translation": {
            "en": "Maria noticed that her baby could occupy one of three states—HAPPY, CRYING, or SLEEPING—and moved quite freely between them.",
            "zh": "玛丽亚注意到她的孩子可以占据三种状态之一——快乐、哭泣或睡觉——并在它们之间自由移动。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of the P20 and P45 features from the EEG dataset. Instances representing positive images are shown as crosses, and those representing negative images as triangles.",
            "zh": "EEG 数据集中 P20 和 P45 特征的散点图。表示正图像的实例显示为十字形，表示负图像的实例显示为三角形。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the college athlete dataset are both continuous, which means that the feature space representing this data is technically known as a Euclidean coordinate space, and we can compute the distance between instances in it using Euclidean distance. For example, the Euclidean distance between instances d12 (SPEED = 5.00, AGILITY = 2.50) and d5 (SPEED = 2.75, AGILITY = 7.50) from Table 5.2[183] is",
            "zh": "大学运动员数据集中的描述性特征都是连续的，这意味着表示此数据的特征空间在技术上称为欧几里得坐标空间，我们可以使用欧几里得距离计算其中实例之间的距离。例如，表 5.2[183] 中的实例 d12 （SPEED = 5.00， AGILITY = 2.50） 和 d5 （SPEED = 2.75， AGILITY = 7.50） 之间的欧几里得距离为"
        }
    },
    {
        "translation": {
            "en": "Figure 12.7",
            "zh": "图 12.7"
        }
    },
    {
        "translation": {
            "en": "The next section describes how we can train networks with multiple layers of neurons using the backpropagation algorithm and explains how the vanishing gradient problem can negatively affect the training of deep networks.",
            "zh": "下一节将介绍如何使用反向传播算法训练具有多层神经元的网络，并解释消失梯度问题如何对深度网络的训练产生负面影响。"
        }
    },
    {
        "translation": {
            "en": "We can use exactly this idea to define a loss function that can be used to train a neural network",
            "zh": "我们可以用这个想法来定义一个损失函数，该函数可用于训练神经网络"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41[514] presents a worked example of the forward propagation of activations through an LSTM unit.",
            "zh": "图 8.41[514] 展示了通过 LSTM 单元前向传播激活的工作示例。"
        }
    },
    {
        "translation": {
            "en": "Unsupervised learning is a huge topic in its own right, and so the goal of this chapter is to give a flavor of the most important approaches involved.",
            "zh": "无监督学习本身就是一个巨大的话题，因此本章的目标是介绍所涉及的最重要的方法。"
        }
    },
    {
        "translation": {
            "en": "where E is the expectation. This value function returns the expected cumulative reward that an agent will earn if it follows policy π starting from state st.",
            "zh": "其中 E 是期望值。此值函数返回代理在遵循从状态 st 开始的策略π时将获得的预期累积奖励。"
        }
    },
    {
        "translation": {
            "en": "For example, Business Understanding and Data Understanding are tightly coupled, and projects typically spend some time moving back and forth between these phases.",
            "zh": "例如，业务理解和数据理解是紧密耦合的，项目通常会花费一些时间在这些阶段之间来回移动。"
        }
    },
    {
        "translation": {
            "en": "6.2   A dataset from a loan application fraud detection domain.",
            "zh": "6.2 来自贷款申请欺诈检测域的数据集。"
        }
    },
    {
        "translation": {
            "en": "As shown in Figure 3.2(e)[60], exponential distributions have a long tail, and so very high values are not uncommon.",
            "zh": "如图3.2（e）[60]所示，指数分布具有长尾，因此非常高的值并不少见。"
        }
    },
    {
        "translation": {
            "en": "The cumulative gain for each decile of the email classification dataset is shown in Table 9.16[568].",
            "zh": "电子邮件分类数据集每个十分位数的累积增益如表9.16所示[568]。"
        }
    },
    {
        "translation": {
            "en": "Finally, if we examine the partitioning of the dataset based on the CONTAINS IMAGES feature, shown in Figure 4.7(c)[128], it looks like this feature is not very discriminatory for spam and ham at all.",
            "zh": "最后，如果我们根据图 4.7（c）[128] 所示的 CONTAINS IMAGES 特征检查数据集的分区，看起来这个功能对垃圾邮件和火腿的歧视性并不大。"
        }
    },
    {
        "translation": {
            "en": "(a) The Voronoi tessellation of the feature space for the dataset in Table 5.2[183], with the position of the query represented by the ? marker; and (b) the decision boundary created by aggregating the neighboring Voronoi regions that belong to the same target level.",
            "zh": "（a） 表5.2[183]中数据集特征空间的Voronoi细分，查询的位置由？标记;（b）通过汇总属于同一目标级别的邻近Voronoi地区而创建的决策边界。"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 12.3(a)[697] shows a slightly higher propensity of people in rural areas to churn.",
            "zh": "例如，图12.3（a）[697]显示农村地区人们的流失倾向略高。"
        }
    },
    {
        "translation": {
            "en": "8. As Figure 8.13[410] illustrates, logistic(0) = 0.5",
            "zh": "8. 如图 8.13[410] 所示，logistic（0） = 0.5"
        }
    },
    {
        "translation": {
            "en": "spending time cleaning the data;",
            "zh": "花时间清理数据;"
        }
    },
    {
        "translation": {
            "en": "As we will see, a fundamental component of creating probabilistic prediction models is deciding on the conditional independence assumptions we wish to make and the resulting factorization of the domain.",
            "zh": "正如我们将看到的，创建概率预测模型的一个基本组成部分是决定我们希望做出的条件独立性假设以及由此产生的域因式分解。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn extracted two key measurements by comparing these manual classifications to the classifications made by the model she had built.",
            "zh": "Jocelyn 通过将这些手动分类与她构建的模型所做的分类进行比较，提取了两个关键测量值。"
        }
    },
    {
        "translation": {
            "en": "1. There are several different ways to explain the k-means clustering algorithm. For example, as k-means is actually a special case of the expectation maximization algorithm (Moon, 1996), it is often described in a probabilisitic context more similar to typical descriptions of that algorithm. To align with Chapter 5[181] we present a similarity-based description of the algorithm.",
            "zh": "1. 有几种不同的方法可以解释 k-means 聚类算法。例如，由于 k-means 实际上是期望最大化算法的一个特例 （Moon， 1996），因此它通常在更类似于该算法的典型描述的概率上下文中描述。为了与第5章[181]保持一致，我们提出了一个基于相似性的算法描述。"
        }
    },
    {
        "translation": {
            "en": "where x is a numeric value and e is Euler’s number and is approximately equal to 2.7183.",
            "zh": "其中 x 是数值，e 是欧拉数，大约等于 2.7183。"
        }
    },
    {
        "translation": {
            "en": "The resulting K-S statistics are 0.940, 0.631, 0.432, and 0.164. These results show that Model 1 is doing a much better job of separating the two target levels than the other models. We can see this in the score histograms and the K-S charts, but it is also nicely captured in the K-S statistics.",
            "zh": "生成的 K-S 统计量为 0.940、0.631、0.432 和 0.164。这些结果表明，模型 1 在分离两个目标水平方面比其他模型做得更好。我们可以在分数直方图和 K-S 图表中看到这一点，但在 K-S 统计数据中也很好地捕捉到了这一点。"
        }
    },
    {
        "translation": {
            "en": "14.1   (a) The class conditional densities for two classes (l1,l2) with a single descriptive feature d. (b) The class posterior probabilities plotted for each class for different values of d.",
            "zh": "14.1 （a） 具有单个描述性特征 d 的两个类 （l1，l2） 的类条件密度。 （b） 针对不同的 d 值为每个类绘制的类后验概率。"
        }
    },
    {
        "translation": {
            "en": "convergence, 323",
            "zh": "收敛，323"
        }
    },
    {
        "translation": {
            "en": "Figure 10.8",
            "zh": "图 10.8"
        }
    },
    {
        "translation": {
            "en": "It is known as a one-hot representation because at most one element in the vector will have the value 1 and all the other elements will be 0, with the value of the feature indicated by whichever element is 1.",
            "zh": "它被称为单热表示，因为向量中最多有一个元素的值为 1，而所有其他元素的值为 0，特征的值由哪个元素表示为 1。"
        }
    },
    {
        "translation": {
            "en": "Some socioeconomic data for a set of countries, and a version of the data after equal-frequency binning has been applied.",
            "zh": "一组国家/地区的一些社会经济数据，以及应用等频合并后的数据版本。"
        }
    },
    {
        "translation": {
            "en": "Std. Dev.",
            "zh": "标准开发"
        }
    },
    {
        "translation": {
            "en": "During data exploration we don’t need to go any further than simply recognizing that features seem to follow particular distributions, and this can be done from examining the histogram for each feature.",
            "zh": "在数据探索过程中，我们只需要简单地识别特征似乎遵循特定的分布，这可以通过检查每个特征的直方图来完成。"
        }
    },
    {
        "translation": {
            "en": "Probability Distributions",
            "zh": "概率分布"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the boundaries shown in Figure 7.20[358] were trained in isolation, whereas the boundaries shown in Figure 7.21[360] were trained in parallel and so are interconnected.",
            "zh": "这样做的原因是图7.20[358]中所示的边界是孤立训练的，而图7.21[360]中显示的边界是并行训练的，因此是相互连接的。"
        }
    },
    {
        "translation": {
            "en": "8.39   An illustration of the different iterations of backpropagation during backpropagation through time.",
            "zh": "8.39 反向传播过程中反向传播的不同迭代的例证。"
        }
    },
    {
        "translation": {
            "en": "This avoids disappointment and difficulties at later stages in a project.",
            "zh": "这样可以避免项目后期的失望和困难。"
        }
    },
    {
        "translation": {
            "en": "One reason why this makes sense is that many activation functions have a small output range (e.g., the output of the logistic function has the range [0,1]) and it is appropriate that the range of the target feature matches the output range of the activation function.",
            "zh": "这有意义的一个原因是许多激活函数的输出范围很小（例如，逻辑函数的输出范围为 [0,1]），并且目标特征的范围与激活函数的输出范围匹配是合适的。"
        }
    },
    {
        "translation": {
            "en": "For example, HANDSETPRICE can take only a small number of values—e.g., 59.99, 129.99, 499.99, and so on.",
            "zh": "例如，HANDSETPRICE 只能采用少量值，例如 59.99、129.99、499.99 等。"
        }
    },
    {
        "translation": {
            "en": "If this test fails, the algorithm ascends the tree to the parent of the current node and prunes the subtree containing the region on the other side of the hyperplane without testing the instances in that region (Line 11).",
            "zh": "如果此测试失败，则算法会将树提升到当前节点的父节点，并修剪包含超平面另一侧区域的子树，而不测试该区域中的实例（第 11 行）。"
        }
    },
    {
        "translation": {
            "en": "external criteria, 611",
            "zh": "外部标准，611"
        }
    },
    {
        "translation": {
            "en": "2.5 Summary",
            "zh": "2.5 小结"
        }
    },
    {
        "translation": {
            "en": "Figure 11.1",
            "zh": "图 11.1"
        }
    },
    {
        "translation": {
            "en": "collection limitation principle, 41",
            "zh": "收集限制原则，41"
        }
    },
    {
        "translation": {
            "en": "The dimensions of the weight matrices are determined by the size of the hidden state.",
            "zh": "权重矩阵的维度由隐藏状态的大小决定。"
        }
    },
    {
        "translation": {
            "en": "differentiation, 370, 765",
            "zh": "微分， 370， 765"
        }
    },
    {
        "translation": {
            "en": "exponential distribution, 60, 72, 270, 274",
            "zh": "指数分布，60、72、270、274"
        }
    },
    {
        "translation": {
            "en": "target policy, 657, 664, 680",
            "zh": "目标策略，657、664、680"
        }
    },
    {
        "translation": {
            "en": "Therefore, the profit arising from correctly predicting the good level for a potential borrower is $140.",
            "zh": "因此，正确预测潜在借款人的良好水平所产生的利润为 140 美元。"
        }
    },
    {
        "translation": {
            "en": "(a)–(i) A plot of the blobs, circles, and half-moons datasets and the clusterings achieved by the k-means clustering and agglomerative hierarchical clustering algorithms (where k is set to 3, 2, and 2, respectively).",
            "zh": "（a）–（i） 斑点、圆圈和半月形数据集的图，以及通过 k 均值聚类和集聚分层聚类算法实现的聚类（其中 k 分别设置为 3、2 和 2）。"
        }
    },
    {
        "translation": {
            "en": "The neurons in this network use a simple threshold activation function, but the intuition holds for logistic functions and the rectifier function because these functions also divide the input space of a neuron into two half-spaces: one in which the neuron activates and one in which it doesn’t activate.",
            "zh": "该网络中的神经元使用简单的阈值激活函数，但直觉适用于逻辑函数和整流器函数，因为这些函数还将神经元的输入空间划分为两个半空间：一个神经元激活，另一个不激活。"
        }
    },
    {
        "translation": {
            "en": "Adding 4 possible actions (left, right, up, and none) to this would give an action-value table with 67,228 entries.",
            "zh": "将 4 个可能的操作（左、右、向上和无）添加到其中将得到一个包含 67,228 个条目的操作值表。"
        }
    },
    {
        "translation": {
            "en": "In a business context where people are using models to inform decision making, being able to understand how the model works gives people more confidence in the model and, hence, in the insight that it provides.",
            "zh": "在人们使用模型为决策提供信息的商业环境中，能够理解模型的工作原理会让人们对模型更有信心，从而对它提供的洞察力更有信心。"
        }
    },
    {
        "translation": {
            "en": "Although it is less important for simple linear regression models, for logistic regression models we recommend that descriptive feature values always be normalized.",
            "zh": "尽管对于简单的线性回归模型来说，它不太重要，但对于逻辑回归模型，我们建议始终对描述性特征值进行归一化。"
        }
    },
    {
        "translation": {
            "en": "2.2.1   Case Study: Motor Insurance Fraud",
            "zh": "2.2.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "weighted sum, 524",
            "zh": "加权总和，524"
        }
    },
    {
        "translation": {
            "en": "This has led to the field receiving significant attention from the media (both positive and negative) and a greater interest than ever before from people who want to become machine learning practitioners.",
            "zh": "这导致该领域受到媒体的极大关注（无论是正面的还是负面的），以及想要成为机器学习从业者的人们比以往任何时候都更感兴趣。"
        }
    },
    {
        "translation": {
            "en": "Indeed, for the vegetation dataset, the decision tree that will be generated using information gain based on the Gini index will be identical to the one generated using information gain based on entropy (see Figure 4.11[141]).",
            "zh": "事实上，对于植被数据集，使用基于基尼指数的信息增益生成的决策树将与使用基于熵的信息增益生成的决策树相同（见图4.11[141]）。"
        }
    },
    {
        "translation": {
            "en": "(a)–(d) Initial centroids chosen using the k-means++ approach (all with k = 3) for the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "（a）–（d） 使用k-means++方法（均为k = 3）为表10.1[604]中给出的移动电话客户数据集选择的初始质心。"
        }
    },
    {
        "translation": {
            "en": "This reflects the fact that a support vector machine uses the support vectors to define the separating hyperplane and hence to make the actual model predictions.",
            "zh": "这反映了这样一个事实，即支持向量机使用支持向量来定义分离的超平面，从而进行实际的模型预测。"
        }
    },
    {
        "translation": {
            "en": "The gray column in the matrix Z(1) contains the weighted sums for the neurons 3, 4, and 5 for this input vector; e.g., for Neuron 3 the weighted sum for d2 is z3 = −0.0042.",
            "zh": "矩阵 Z（1） 中的灰色列包含该输入向量的神经元 3、4 和 5 的加权和;例如，对于神经元 3，d2 的加权和是 z3 = −0.0042。"
        }
    },
    {
        "translation": {
            "en": "where var(t, d=l) is the variance of the target feature in the partition of the dataset containing the instances where d = l, |d=l| is the size of this partition and || is the size of the dataset.",
            "zh": "其中 var（t， d=l） 是数据集分区中目标特征的方差，其中包含 d = l， |d=l|是此分区的大小，||是数据集的大小。"
        }
    },
    {
        "translation": {
            "en": "A data quality report for the motor insurance claims fraud detection ABT displayed in Table 3.2[56].",
            "zh": "表3.2[56]中显示的汽车保险理赔欺诈检测ABT的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Error-based models would be preferred if the target feature is also continuous.",
            "zh": "如果目标特征也是连续的，则首选基于错误的模型。"
        }
    },
    {
        "translation": {
            "en": "The debate regarding the advantages and disadvantages of generative and discriminative models can be extended beyond model accuracy to include their ability to handle missing data, unlabeled data, and feature preprocessing, among other topics.",
            "zh": "关于生成模型和判别模型的优缺点的争论可以扩展到模型准确性之外，包括它们处理缺失数据、未标记数据和特征预处理的能力等主题。"
        }
    },
    {
        "translation": {
            "en": "What we have presented here is a very short introduction to some of the most basic operations.",
            "zh": "我们在这里介绍的是对一些最基本操作的非常简短的介绍。"
        }
    },
    {
        "translation": {
            "en": "So by giving all the instances in the dataset a weighted vote, we have at least reduced the impact of the noisy instance.",
            "zh": "因此，通过对数据集中的所有实例进行加权投票，我们至少减少了嘈杂实例的影响。"
        }
    },
    {
        "translation": {
            "en": "In some domains co-absence is important. For example, in a medical domain when judging the similarity between two patients, it may be as important to capture the fact that neither patient had a particular symptom as it is to capture the symptoms that the patients have in common. The Sokal-Michener similarity index takes this into account and is defined as the ratio between the total number of co-presences and co-absences and the total number of binary features considered:",
            "zh": "在某些领域，共同缺席很重要。例如，在医学领域，在判断两名患者之间的相似性时，捕捉两个患者都没有特定症状的事实可能与捕捉患者共同的症状一样重要。Sokal-Michener 相似性指数考虑到了这一点，并被定义为共存和共缺总数与所考虑的二元特征总数之间的比率："
        }
    },
    {
        "translation": {
            "en": "If there is an even number of values in the sample, then the median is obtained by calculating the arithmetic mean of the middle two values.",
            "zh": "如果样本中的值为偶数，则通过计算中间两个值的算术平均值来获得中位数。"
        }
    },
    {
        "translation": {
            "en": "Another, less well-known, distance metric is the Manhattan distance.2 The Manhattan distance between two instances a and b in a feature space with m dimensions is defined as",
            "zh": "另一个鲜为人知的距离度量是曼哈顿距离。2 在具有 m 维的特征空间中，两个实例 a 和 b 之间的曼哈顿距离定义为"
        }
    },
    {
        "translation": {
            "en": "Changes in Usage: Any changes in the frequency, recency, or monetary value of a customer’s or user’s interactions with an organization (for example, has a cable TV subscriber changed packages in recent months?).",
            "zh": "使用情况的变化：客户或用户与组织互动的频率、新近度或货币价值的任何变化（例如，有线电视用户最近几个月是否更改了套餐？"
        }
    },
    {
        "translation": {
            "en": "(e) Assuming that a greedy action selection policy is used again and that Q-learning is still being used with α = 0.2 and γ = 0.9, select the next action that the agent will perform, simulate this action, and update the entry in the action-value table for the action. (Note: If cards need to be dealt to the player or dealer, continue to use cards from the list given at the beginning of this question.)",
            "zh": "（e） 假设再次使用贪婪操作选择策略，并且 Q-learning 仍在使用 α = 0.2 且 γ = 0.9，则选择代理将执行的下一个操作，模拟此操作，并更新操作值表中的条目。 （注意：如果需要发牌给玩家或庄家， 继续使用本问题开头给出的列表中的卡片。"
        }
    },
    {
        "translation": {
            "en": "Instance d1 has a target level of no, so the nearest neighbor model now predicts a target level of no for the query, meaning that the marketing department won’t include the customer in their list of direct marketing prospects.",
            "zh": "实例 d1 的目标级别为 no，因此最近邻模型现在预测查询的目标级别为 no，这意味着营销部门不会将客户包含在其直接营销潜在客户列表中。"
        }
    },
    {
        "translation": {
            "en": "For two events, X and Y, that are conditionally independent given knowledge of a third event, here Z, we can say that",
            "zh": "对于两个事件，X 和 Y，它们在给定第三个事件的知识的情况下是有条件独立的，这里是 Z，我们可以说"
        }
    },
    {
        "translation": {
            "en": "—Alfred Korzybski, Science and Sanity, p. 58",
            "zh": "——阿尔弗雷德·科兹布斯基，《科学与理智》，第58页"
        }
    },
    {
        "translation": {
            "en": "Once the forward pass is complete, we calculate an error term for each of the outputs of the network.",
            "zh": "前向传递完成后，我们计算网络每个输出的误差项。"
        }
    },
    {
        "translation": {
            "en": "(c) Outliers",
            "zh": "（c） 异常值"
        }
    },
    {
        "translation": {
            "en": "continuous data, 34",
            "zh": "连续数据，34"
        }
    },
    {
        "translation": {
            "en": "1,500,500",
            "zh": "1,500,500"
        }
    },
    {
        "translation": {
            "en": "summing out, 247, 761–763",
            "zh": "总结，247,761-763"
        }
    },
    {
        "translation": {
            "en": "A final hidden layer flattened the outputs of the previous convolutional layer and contained 512 fully connected units with rectified linear activations.",
            "zh": "最后一个隐藏层使前一个卷积层的输出变平，并包含 512 个具有整流线性激活的全连接单元。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.4",
            "zh": "图 9.4"
        }
    },
    {
        "translation": {
            "en": "Investigation of this claim with the business revealed that this is in fact a valid outlier and represents an unusually large claim for a very serious injury.",
            "zh": "对企业提出的索赔进行调查后发现，这实际上是一个有效的异常值，代表了对非常严重伤害的异常大额索赔。"
        }
    },
    {
        "translation": {
            "en": "30. See Section 4.2.3[127].",
            "zh": "30. 参见第 4.2.3 节[127]。"
        }
    },
    {
        "translation": {
            "en": "In designing state representations the principle of parsimony applies: we should strive for the simplest representation that gives sufficient flexibility to model the important aspects of an environment and task.",
            "zh": "在设计状态表示时，适用简约原则：我们应该努力实现最简单的表示，以提供足够的灵活性来对环境和任务的重要方面进行建模。"
        }
    },
    {
        "translation": {
            "en": "capacity for model retraining, 739",
            "zh": "模型再训练能力，739"
        }
    },
    {
        "translation": {
            "en": "The revenue commissioner would like to solve this problem by targeting audits at companies who are likely to be in breach of tax regulations, rather than selecting companies for audit at random.",
            "zh": "税务局局长希望通过针对可能违反税收法规的公司进行审计来解决这个问题，而不是随机选择公司进行审计。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.5[546] illustrates how the available data is split during the leave-one-out cross validation process.",
            "zh": "图 9.5[546] 说明了在“留一”交叉验证过程中如何拆分可用数据。"
        }
    },
    {
        "translation": {
            "en": "Table 9.8",
            "zh": "表 9.8"
        }
    },
    {
        "translation": {
            "en": "As a comparator, the filters used in these two equations are the same as those used in Equation (8.90)[486] and Equation (8.91)[486 the difference now is that the generated feature maps are larger, and indeed some of the new cells have positive values.",
            "zh": "作为比较器，这两个方程中使用的滤波器与等式（8.90）[486]和等式（8.91）[486]中使用的滤波器相同，现在的区别在于生成的特征图更大，并且确实一些新单元格具有正值。"
        }
    },
    {
        "translation": {
            "en": "Although it might look like the decision boundary for the single target level shown by the solid line does not discriminate between the instances with the single target level and those with the other target levels, when used in conjunction with the other two decision boundaries, it does.",
            "zh": "尽管看起来实线显示的单个目标级别的决策边界不会区分具有单个目标级别的实例和具有其他目标级别的实例，但当与其他两个决策边界结合使用时，它确实会区分。"
        }
    },
    {
        "translation": {
            "en": "The covariance and correlation matrices for the HEIGHT, WEIGHT and AGE features are",
            "zh": "HEIGHT、WEIGHT 和 AGE 特征的协方差和相关矩阵为"
        }
    },
    {
        "translation": {
            "en": "Given a full joint probability distribution, we can compute the probability of any event in a domain by summing over the cells in the distribution where that event is true.",
            "zh": "给定一个完整的联合概率分布，我们可以通过对分布中该事件为真的单元格求和来计算域中任何事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Modeling, 17, 19, 20, 87, 697, 719, 730",
            "zh": "建模， 17， 19， 20， 87， 697， 719， 730"
        }
    },
    {
        "translation": {
            "en": "During the forward pass for each input and hidden layer in the network a vector DropMask of 0 or 1 values is sampled from a Bernoulli distribution with probability ρ that a sampled value will be 1.",
            "zh": "在网络中每个输入层和隐藏层的前向传递期间，从伯努利分布中采样一个值为 0 或 1 的向量 DropMask，采样值的概率 ρ 为 1。"
        }
    },
    {
        "translation": {
            "en": "Cristianini, Nello, and John Shawe-Taylor. 2000. An introduction to support vector machines and other kernel-based learning methods. Cambridge University Press.",
            "zh": "克里斯蒂亚尼尼、内洛和约翰·沙威-泰勒。2000. 介绍支持向量机和其他基于核的学习方法。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "When we identify data quality issues due to invalid data, we should take immediate action to correct them, regenerate the ABT, and re-create the data quality report.",
            "zh": "当我们发现由于无效数据导致的数据质量问题时，我们应该立即采取措施进行纠正，重新生成 ABT，并重新创建数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.8",
            "zh": "图 8.8"
        }
    },
    {
        "translation": {
            "en": "We need to be careful when sampling, however, to ensure that the resulting datasets are still representative of the original data and that no unintended bias is introduced during this process.",
            "zh": "然而，在采样时，我们需要小心，以确保生成的数据集仍然代表原始数据，并且在此过程中不会引入意外的偏差。"
        }
    },
    {
        "translation": {
            "en": "We can solve both these problems by using a more sophisticated threshold function that is continuous, and therefore differentiable, and that allows for the subtlety desired: the logistic function.13",
            "zh": "我们可以通过使用一个更复杂的阈值函数来解决这两个问题，该阈值函数是连续的，因此是可微的，并且允许所需的微妙之处：逻辑函数13。"
        }
    },
    {
        "translation": {
            "en": "Starting on the left of the figure, the column of 7 three-channel (RGB) pixels is fed into the first convolutional layer.",
            "zh": "从图的左侧开始，将 7 个三通道 （RGB） 像素列输入到第一个卷积层中。"
        }
    },
    {
        "translation": {
            "en": "14. It is more common to split an ABT in the opposite proportions (70% for the training set and 30% for the test set). In this case, however, because the ABT was so large it was more useful to have a very large test sample, as 200,000 instances should be more than enough for the training set.",
            "zh": "14. 更常见的是以相反的比例拆分 ABT（训练集为 70%，测试集为 30%）。然而，在这种情况下，由于 ABT 非常大，因此拥有非常大的测试样本更有用，因为 200,000 个实例对于训练集来说应该绰绰有余。"
        }
    },
    {
        "translation": {
            "en": "MOTORVALUE: The value of the car on the motor policy",
            "zh": "MOTORVALUE：汽车在汽车保单上的价值"
        }
    },
    {
        "translation": {
            "en": "As a result, the information gain for a particular descriptive feature may be different at different nodes in the tree because it will be computed on different subsets of the full training dataset.",
            "zh": "因此，特定描述性特征的信息增益在树中的不同节点上可能不同，因为它将在完整训练数据集的不同子集上计算。"
        }
    },
    {
        "translation": {
            "en": "The internal layers in the network, which are neither input nor output layers, are called hidden layers.",
            "zh": "网络中的内部层既不是输入层也不是输出层，称为隐藏层。"
        }
    },
    {
        "translation": {
            "en": "This is because the k-NN makes the mistake of misclassifying a bad borrower as good more often than the decision tree model, and this is the more costly mistake.",
            "zh": "这是因为 k-NN 比决策树模型更频繁地错误地将不良借款人归类为好借款人，这是代价更高的错误。"
        }
    },
    {
        "translation": {
            "en": "This distinction between fat and light tailed distributions is important because it highlights that when we use a normal distribution, we are implicitly assuming that the likelihood of values that differ from the mean of the distribution drops quite dramatically as we move away from the mean.",
            "zh": "脂肪分布和轻尾分布之间的这种区别很重要，因为它强调了当我们使用正态分布时，我们隐含地假设，当我们远离均值时，与分布均值不同的可能性会急剧下降。"
        }
    },
    {
        "translation": {
            "en": "Notice that the full dataset has been split into four partitions (labeled 6, 7, 8, and 9 in Table 4.4[137]) and that the feature ELEVATION is no longer listed in these partitions because it has already been used to split the data.",
            "zh": "请注意，完整数据集已拆分为四个分区（在表 4.4[137] 中标记为 6、7、8 和 9），并且这些分区中不再列出特征 ELEVATION，因为它已被用于拆分数据。"
        }
    },
    {
        "translation": {
            "en": "This increases the size of the weight space through which we need to search when training the model.",
            "zh": "这增加了我们在训练模型时需要搜索的权重空间的大小。"
        }
    },
    {
        "translation": {
            "en": "Due to space limitations, this dataset covers only a sample of the risk factors for stroke.",
            "zh": "由于篇幅所限，该数据集仅涵盖中风危险因素的样本。"
        }
    },
    {
        "translation": {
            "en": "This is clear in the visualization of the action-value table after 35 episodes of Q-learning have elapsed that is shown in Figure 11.5(b)[663].",
            "zh": "这在经过35集Q学习后的动作值表的可视化中可以清楚地看出，如图11.5（b）[663]所示。"
        }
    },
    {
        "translation": {
            "en": "The individual silhouette widths for the instances in a dataset can also be used to produce a useful visual tool for inspecting a clustering.",
            "zh": "数据集中实例的各个侧面影像宽度也可用于生成用于检查聚类的有用可视化工具。"
        }
    },
    {
        "translation": {
            "en": "15. See Chapter 8[381] for a discussion of mini-batch gradient descent.",
            "zh": "15. 参见第8章[381]，了解小批量梯度下降的讨论。"
        }
    },
    {
        "translation": {
            "en": "4.1 Big Idea",
            "zh": "4.1 大创意"
        }
    },
    {
        "translation": {
            "en": "Performance then became stable with a return of about 40 after the agent learned a useful path through the environment.",
            "zh": "然后，在代理学习了环境中的有用路径后，性能变得稳定，返回率约为 40。"
        }
    },
    {
        "translation": {
            "en": "Currently geologists at the company identify potential drilling sites by manually examining information from a variety of different sources. These include ordinance survey maps, aerial photographs, characteristics of rock and soil samples taken from potential sites, and measurements from sensitive gravitational and seismic instruments.",
            "zh": "目前，该公司的地质学家通过手动检查来自各种不同来源的信息来识别潜在的钻探地点。这些包括法令测量地图、航空照片、从潜在地点采集的岩石和土壤样本的特征，以及敏感的重力和地震仪器的测量结果。"
        }
    },
    {
        "translation": {
            "en": "Silver, Nate. 2012. The signal and the noise: Why so many predictions fail — but some don’t. Penguin Press.",
            "zh": "银牌，内特。2012. 信号与噪音：为什么这么多预测失败——但有些却没有。企鹅出版社。"
        }
    },
    {
        "translation": {
            "en": "SCORE",
            "zh": "得分"
        }
    },
    {
        "translation": {
            "en": "We noted in this section that a heuristic that is used to help avoid saturating the rectifier function is to initialize the bias weights in the network to 0.1.",
            "zh": "我们在本节中指出，用于帮助避免整流器功能饱和的启发式方法是将网络中的偏置权重初始化为 0.1。"
        }
    },
    {
        "translation": {
            "en": "The Gibbs sampling algorithm initializes a Bayesian network by clamping the values of the evidence nodes and randomly assigning values to the non-evidence nodes.",
            "zh": "Gibbs 抽样算法通过钳位证据节点的值并将值随机分配给非证据节点来初始化贝叶斯网络。"
        }
    },
    {
        "translation": {
            "en": "The most common approach to handling categorical features in linear regression models is to use a transformation that converts a single categorical descriptive feature into a number of continuous descriptive feature values that can encode the levels of the categorical feature.",
            "zh": "处理线性回归模型中分类特征的最常见方法是使用转换，将单个分类描述性特征转换为多个连续描述性特征值，这些值可以对分类特征的级别进行编码。"
        }
    },
    {
        "translation": {
            "en": "This example shows that the algorithm converges to the global minimum more quickly than any of the approaches shown in Figure 7.7[329].",
            "zh": "这个例子表明，该算法比图7.7[329]所示的任何方法更快地收敛到全局最小值。"
        }
    },
    {
        "translation": {
            "en": "In order to compare distributions, we measure the distribution of model outputs on the test set that was used to originally evaluate a model and then repeat this measurement on new sets of query instances collected during periods after the model has been deployed.",
            "zh": "为了比较分布，我们测量最初用于评估模型的测试集上模型输出的分布，然后在模型部署后的一段时间内收集的新查询实例集上重复此测量。"
        }
    },
    {
        "translation": {
            "en": "action-value function, 642, 643, 651, 676",
            "zh": "动作值函数， 642， 643， 651， 676"
        }
    },
    {
        "translation": {
            "en": "19. Taleb (2008) discusses the problems that arise when analysts use normal distributions to model social and economic features, where the assumptions regarding light tails don’t hold.",
            "zh": "19. Taleb（2008）讨论了当分析师使用正态分布对社会和经济特征进行建模时出现的问题，其中关于光尾的假设不成立。"
        }
    },
    {
        "translation": {
            "en": "From a distribution perspective, the main distinction between a normal distribution and a student-t is that a normal distribution has light tails whereas the student-t distribution has fat tails.",
            "zh": "从分布的角度来看，正态分布和 student-t 之间的主要区别在于正态分布具有浅尾，而 student-t 分布具有肥尾。"
        }
    },
    {
        "translation": {
            "en": "What about the other features?",
            "zh": "其他功能呢？"
        }
    },
    {
        "translation": {
            "en": "data quality issues, 53, 63, 94",
            "zh": "数据质量问题， 53， 63， 94"
        }
    },
    {
        "translation": {
            "en": "Finally, we hope that you find machine learning as fascinating and rewarding a topic as we do, and we wish you the best in your future learning.",
            "zh": "最后，我们希望您能像我们一样发现机器学习是一个引人入胜且有益的主题，并祝您在未来的学习中一切顺利。"
        }
    },
    {
        "translation": {
            "en": "2.2.1 Case Study: Motor Insurance Fraud",
            "zh": "2.2.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Understanding",
            "zh": "理解"
        }
    },
    {
        "translation": {
            "en": "Equality directly affects both health and education, so there are directed arcs from GINI COEF to both LIFE EXP and SCHOOL YEARS.",
            "zh": "平等直接影响健康和教育，因此从基尼COEF到LIFE EXP和学年都有定向的弧线。"
        }
    },
    {
        "translation": {
            "en": "It would be useful for farmers to be able to predict grass growth for different amounts of forecasted rainfall so that they could plan the optimal times to harvest their grass for making hay.",
            "zh": "对于农民来说，能够预测不同预测降雨量的草生长情况将是有用的，这样他们就可以计划收获草以制作干草的最佳时间。"
        }
    },
    {
        "translation": {
            "en": "Another relevant textbook by the same author is (Strang, 2019), which specifically focuses on introducing linear algebra from the perspective of understanding deep learning.",
            "zh": "同一作者的另一本相关教科书是（Strang，2019），该教科书特别侧重于从理解深度学习的角度介绍线性代数。"
        }
    },
    {
        "translation": {
            "en": "We will introduce two of the more popular: equal-width binning and equal-frequency binning.",
            "zh": "我们将介绍两种更流行的方法：等宽分档和等频分档。"
        }
    },
    {
        "translation": {
            "en": "4.4.5   Model Ensembles",
            "zh": "4.4.5 模型集合"
        }
    },
    {
        "translation": {
            "en": "“Information is the resolution of uncertainty.”",
            "zh": "“信息是不确定性的解决方案。”"
        }
    },
    {
        "translation": {
            "en": "information gain, 117, 120, 129, 130, 133, 135, 172, 174, 227, 614, 717",
            "zh": "信息增益， 117， 120， 129， 130， 133， 135， 172， 174， 227， 614， 717"
        }
    },
    {
        "translation": {
            "en": "This process of storing activations in the memory buffer at one time-step and reading from the buffer at the next time-step is how the recurrent connections are implemented.",
            "zh": "在一个时间步长将激活存储在内存缓冲区中，并在下一个时间步从缓冲区读取，这个过程是循环连接的实现方式。"
        }
    },
    {
        "translation": {
            "en": "10. We introduce the subscript k on the target t k into this equation to allow for situations in which the network has multiple neurons in the output layer, and the target output then defines a separate target tk for each of these neurons.",
            "zh": "10. 我们将目标 t k 上的下标 k 引入该等式，以允许网络在输出层中有多个神经元的情况，然后目标输出为每个神经元定义一个单独的目标 tk。"
        }
    },
    {
        "translation": {
            "en": "ANNUAL INCOME, the target feature with 3 levels ( <25K, 25K–50K, >50K).",
            "zh": "年收入，目标特征有 3 个级别（<25K、25K–50K、>50K）。"
        }
    },
    {
        "translation": {
            "en": "The REGIONTYPE and OCCUPATION categorical features both suffered from a significant number of missing values—74% and 47.8% respectively.",
            "zh": "REGIONTYPE 和 OCCUPATION 分类特征都存在大量缺失值，分别为 74% 和 47.8%。"
        }
    },
    {
        "translation": {
            "en": "[Claim prediction] A model could be built to predict the likelihood that an insurance claim is fraudulent.",
            "zh": "[索赔预测]可以建立一个模型来预测保险索赔欺诈的可能性。"
        }
    },
    {
        "translation": {
            "en": "Network Links: Links between an item and other related items (for example, links between different customers or different products, or social network links between customers).",
            "zh": "网络链接：商品与其他相关商品之间的链接（例如，不同客户或不同产品之间的链接，或客户之间的社交网络链接）。"
        }
    },
    {
        "translation": {
            "en": "The aggregate class accuracy measure can then be calculated from this combined confusion matrix and, in this case, turns out to be 84%.",
            "zh": "然后，可以从这个组合混淆矩阵中计算出聚合类准确度量，在本例中，结果是 84%。"
        }
    },
    {
        "translation": {
            "en": "Feature spaces can, however, have many more dimensions—in document classification tasks, for example, it is not uncommon to have thousands of descriptive features and therefore thousands of dimensions in the associated feature space.",
            "zh": "但是，要素空间可以具有更多维度，例如，在文档分类任务中，在关联的特征空间中具有数千个描述性要素并因此具有数千个维度的情况并不少见。"
        }
    },
    {
        "translation": {
            "en": "9.10   (a) Overall profit for the k-NN model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(a)[555]; and (b) overall profit for the decision tree model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(b)[555].",
            "zh": "9.10 （a） 使用表9.8[554]中的利润矩阵和表9.9（a）[555]中的混淆矩阵计算的k-NN模型的总利润;（b）使用表9.8[554]中的利润矩阵和表9.9（b）[555]中的混淆矩阵的决策树模型的总利润。"
        }
    },
    {
        "translation": {
            "en": "Acknowledgments",
            "zh": "确认"
        }
    },
    {
        "translation": {
            "en": "As the term similarity-based learning suggests, a key component of this approach to prediction is defining a computational measure of similarity between instances.",
            "zh": "正如术语“基于相似性的学习”所暗示的那样，这种预测方法的一个关键组成部分是定义实例之间相似性的计算度量。"
        }
    },
    {
        "translation": {
            "en": "imbalanced data, 193, 550, 693",
            "zh": "不平衡数据， 193， 550， 693"
        }
    },
    {
        "translation": {
            "en": "Although fully automated approaches to answering this question do not exist, analysts can use an approach based on the data exploration tools presented in Chapter 3[53] to understand the results of a clustering.",
            "zh": "尽管不存在回答这个问题的全自动方法，但分析师可以使用基于第 3 章[53] 中介绍的数据探索工具的方法来理解聚类的结果。"
        }
    },
    {
        "translation": {
            "en": "2. if ak, is negative, we should increase the weight wi,k. However, in this case ∂ℰ/∂wi,k = δi × ak will be negative, because the product involves a positive and a negative term. And, so to increase wi,k, we should again subtract ∂ℰ/∂wi,k from wi,k.",
            "zh": "2. 如果 AK 为负数，则应增加权重 Wi，K。但是，在这种情况下，∂E/∂wi，k = δi × ak 将为负数，因为乘积涉及正项和负项。因此，为了增加 wi，k，我们应该再次从 wi，k 中减去 ∂E/∂wi，k。"
        }
    },
    {
        "translation": {
            "en": "average linkage, 619, 635",
            "zh": "平均连杆，619,635"
        }
    },
    {
        "translation": {
            "en": "In the case of a nearest neighbor algorithm, as the number of instances becomes large, the model will become slower because it has more instances to check when defining the neighborhood.",
            "zh": "对于最近邻算法，随着实例数变大，模型将变慢，因为在定义邻域时要检查的实例更多。"
        }
    },
    {
        "translation": {
            "en": "and denominator as:",
            "zh": "分母为："
        }
    },
    {
        "translation": {
            "en": "The task in this question is to create a naive Bayes model to monitor a wastewater treatment plant.33 The table below lists a dataset containing details of activities at a wastewater treatment plant for 14 days.",
            "zh": "33 下表列出了一个数据集，其中包含废水处理厂 14 天的活动详细信息。"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance, however, also rescales the differences between feature values (using the inverse covariance matrix) so that all the features have unit variance, and the effects of covariance are removed.",
            "zh": "但是，马氏距离还重新缩放了特征值之间的差异（使用逆协方差矩阵），以便所有特征都具有单位方差，并且去除了协方差的影响。"
        }
    },
    {
        "translation": {
            "en": "So the distance between two points in the feature space is a useful measure of the similarity of the descriptive features of the two instances.",
            "zh": "因此，特征空间中两点之间的距离是衡量两个实例的描述性特征相似性的有用度量。"
        }
    },
    {
        "translation": {
            "en": "8.3.4   Backpropagation: The Algorithm",
            "zh": "8.3.4 反向传播：算法"
        }
    },
    {
        "translation": {
            "en": "While the first option is often used, Jocelyn was lucky that another data source became available.",
            "zh": "虽然经常使用第一个选项，但 Jocelyn 很幸运，有另一个数据源可用。"
        }
    },
    {
        "translation": {
            "en": "It is clear from these histograms that the distribution of values taken by the ACCOUNT BALANCE feature in the set of instances where FRAUD = true follows an exponential distribution; whereas, the distribution of the values taken by the ACCOUNT BALANCE feature in the set of instances where the FRAUD = false is similar to a normal distribution.",
            "zh": "从这些直方图中可以清楚地看出，在 FRAUD = true 的一组实例中，ACCOUNT BALANCE 特征所获取的值分布遵循指数分布;而 ACCOUNT BALANCE 特征在 FRAUD = false 的一组实例中获取的值分布类似于正态分布。"
        }
    },
    {
        "translation": {
            "en": "probability function, 246, 758",
            "zh": "概率函数， 246， 758"
        }
    },
    {
        "translation": {
            "en": "The good news, however, is that the disease is extremely rare, striking only 1 in 10,000 people.",
            "zh": "然而，好消息是，这种疾病极为罕见，每10,000人中只有1人患病。"
        }
    },
    {
        "translation": {
            "en": "2. This dataset has been artificially generated for this example. Siddiqi (2005) gives an excellent overview of building predictive data analytics models for financial credit scoring.",
            "zh": "2. 此数据集是针对此示例人工生成的。Siddiqi（2005）对构建用于金融信用评分的预测数据分析模型进行了很好的概述。"
        }
    },
    {
        "translation": {
            "en": "Calculate the stability index for the two new periods and determine whether the model should be retrained at either of these points.",
            "zh": "计算两个新周期的稳定性指数，并确定是否应在这两个点中的任何一个点重新训练模型。"
        }
    },
    {
        "translation": {
            "en": "The histogram represents the bins.",
            "zh": "直方图表示条柱。"
        }
    },
    {
        "translation": {
            "en": "The final evaluation that Jocelyn performed was in two parts.",
            "zh": "Jocelyn 进行的最终评估分为两部分。"
        }
    },
    {
        "translation": {
            "en": "interpolate, 748",
            "zh": "插值，748"
        }
    },
    {
        "translation": {
            "en": "As discussed in the introduction, the goal of this chapter is to give a flavor of the most important unsupervised machine learning techniques, and there are many more clustering algorithms not covered here.",
            "zh": "正如引言中所讨论的，本章的目标是介绍最重要的无监督机器学习技术，这里还有更多的聚类算法没有介绍。"
        }
    },
    {
        "translation": {
            "en": "The naive approach to training a neural network using this loss function would be to use the backpropagation of error algorithm with stochastic gradient descent. This would mean that every time the agent took an action, at, to move from st to st+1, accumulating reward rt, a loss would be calculated using Equation (11.27)[670] and the gradient of this loss Equation (11.28)[670] would be backpropagated through the network to update the weights. Algorithm 15[671] outlines this naive approach.",
            "zh": "使用此损失函数训练神经网络的朴素方法是使用具有随机梯度下降的误差反向传播算法。这意味着，每当智能体采取行动时，从st移动到st+1，累积奖励rt，将使用方程（11.27）[670]计算损失，并且该损失方程（11.28）[670]的梯度将通过网络反向传播以更新权重。算法15[671]概述了这种幼稚的方法。"
        }
    },
    {
        "translation": {
            "en": "Anguita, Davide, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones. In Proceedings of the 21st international European symposium on artificial neural networks, computational intelligence, and machine learning (ESANN’13), 437–442.",
            "zh": "安吉塔、戴维德、亚历山德罗·吉奥、卢卡·奥内托、泽维尔·帕拉和豪尔赫·路易斯·雷耶斯-奥尔蒂斯。2013. 使用智能手机识别人类活动的公共领域数据集.在第 21 届欧洲人工神经网络、计算智能和机器学习研讨会 （ESANN'13） 的会议记录中，第 437–442 页。"
        }
    },
    {
        "translation": {
            "en": "A dataset listing features for a number of generators.",
            "zh": "列出多个生成器的特征的数据集。"
        }
    },
    {
        "translation": {
            "en": "Plainly, this model is not performing well.",
            "zh": "显然，这种模式表现不佳。"
        }
    },
    {
        "translation": {
            "en": "(2016) provides a comprehensive overview of the field.",
            "zh": "（2016）提供了该领域的全面概述。"
        }
    },
    {
        "translation": {
            "en": "RELATIVE HUMIDITY",
            "zh": "相对湿度"
        }
    },
    {
        "translation": {
            "en": "The equation of a line predicts a y value for every x value given the slope and the y-intercept, and we can use this simple model to capture the relationship between two features such as SIZE and RENTAL PRICE.",
            "zh": "给定斜率和 y 截距，直线方程预测每个 x 值的 y 值，我们可以使用这个简单的模型来捕获两个特征之间的关系，例如 SIZE 和 RENTAL PRICE。"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wish to calculate the probability of h given f when we don’t care what values V or M take.",
            "zh": "例如，假设我们希望计算给定 f 的 h 的概率，而我们不在乎 V 或 M 取什么值。"
        }
    },
    {
        "translation": {
            "en": "The advantages of using basis functions is that they allow models that represent non-linear relationships to be built even though these models themselves remain a linear combination of inputs (e.g., we still use something very similar to Equation (7.48)[367] to predict continuous targets).",
            "zh": "使用基函数的优点是，它们允许构建表示非线性关系的模型，即使这些模型本身仍然是输入的线性组合（例如，我们仍然使用与方程（7.48）[367]非常相似的东西来预测连续目标）。"
        }
    },
    {
        "translation": {
            "en": "The fundamentals of unsupervised learning have already largely been covered in previous chapters. The clustering methods discussed in this chapter use the ideas of a feature space and a distance measure discussed in Chapter 5[181], and the feature generation techniques largely build upon the ideas of error-based learning and neural networks discussed in Chapters 7[311] and 8[381].",
            "zh": "无监督学习的基础知识在前面的章节中已经基本介绍过了。本章讨论的聚类方法使用了第5章[181]中讨论的特征空间和距离度量的思想，而特征生成技术在很大程度上建立在第7章[311]和第8章[381]中讨论的基于错误的学习和神经网络的思想之上。"
        }
    },
    {
        "translation": {
            "en": "Finally, he would like to acknowledge and thank Aphra; this book would not have been started without her inspiration and would not have been completed without her support and patience.",
            "zh": "最后，他要感谢阿芙拉;没有她的启发，这本书就不会开始，没有她的支持和耐心，这本书就不会完成。"
        }
    },
    {
        "translation": {
            "en": "Table 1.4[10] illustrates the relationship between combinations of descriptive feature values and prediction models for the retail scenario.",
            "zh": "表 1.4[10] 说明了零售场景的描述性特征值组合和预测模型之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Again, the result of the calculation matches the probability computed directly from the dataset (see Equation (B.2)[760]).",
            "zh": "同样，计算结果与直接从数据集计算的概率相匹配（参见公式（B.2）[760]）。"
        }
    },
    {
        "translation": {
            "en": "9.17   Cumulative gain, lift, and cumulative lift charts for four different models for the extended email classification test set.",
            "zh": "9.17 扩展电子邮件分类测试集的四种不同模型的累计增益、提升和累积提升图表。"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with μ=0.0,σ=0.01.",
            "zh": "图 8.22[450] 中第一次训练迭代期间网络的内部动力学，当时权重使用 μ=0.0，σ=0.01 的正态分布进行初始化。"
        }
    },
    {
        "translation": {
            "en": "Unlike categorical features, continuous features can be used at multiple points along a path in a decision tree, although the threshold applied to the feature at each of these tests will be different.",
            "zh": "与分类特征不同，连续特征可以在决策树中路径上的多个点上使用，尽管在每个测试中应用于特征的阈值会有所不同。"
        }
    },
    {
        "translation": {
            "en": "1. we represent the target feature using one-hot encoding;",
            "zh": "1.我们用one-hot编码来表示目标特征;"
        }
    },
    {
        "translation": {
            "en": "Other strides are possible, and it is possible to use different horizontal and vertical strides.",
            "zh": "其他步幅是可能的，并且可以使用不同的水平和垂直步幅。"
        }
    },
    {
        "translation": {
            "en": "joint probability, 246, 251, 759",
            "zh": "联合概率，246,251,759"
        }
    },
    {
        "translation": {
            "en": "Focusing on the cumulative gain charts, we can see that for Model 1, 80% of the spam messages are identified in the top 40% of the model predictions.",
            "zh": "关注累积增益图表，我们可以看到，对于模型 1,80% 的垃圾邮件在模型预测的前 40% 中被识别出来。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6",
            "zh": "图 2.6"
        }
    },
    {
        "translation": {
            "en": "In these cases the probability calculated is known as a joint probability.",
            "zh": "在这些情况下，计算出的概率称为联合概率。"
        }
    },
    {
        "translation": {
            "en": "Case Study: Customer Churn",
            "zh": "案例研究：客户流失"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 10.12(b)[621].",
            "zh": "如图10.12（b）[621]所示。"
        }
    },
    {
        "translation": {
            "en": "Each normal that is merged is known as a component of the mixture.",
            "zh": "合并的每个法线都称为混合物的一个组成部分。"
        }
    },
    {
        "translation": {
            "en": "11.4.2   Deep Q Networks",
            "zh": "11.4.2 Deep Q 网络"
        }
    },
    {
        "translation": {
            "en": "12.4   An unpruned decision tree built for the AT churn prediction problem (shown only to indicate its size and complexity). The excessive complexity and depth of the tree are evidence that overfitting has probably occurred.",
            "zh": "12.4 为 AT 流失预测问题构建的未修剪决策树（仅显示其大小和复杂性）。树的过度复杂性和深度是可能发生过拟合的证据。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, some groups of neurons reacted to the same visual feature, but each neuron in the group reacted when the feature occurred at different locations; for example, one neuron would react to the feature if it occurred in the bottom-right of the screen whereas a different neuron would react if the feature occurred in the top-left of the screen.",
            "zh": "此外，一些神经元组对相同的视觉特征有反应，但该组中的每个神经元在特征发生在不同位置时都会做出反应;例如，如果特征发生在屏幕的右下角，则一个神经元会对该特征做出反应，而如果该特征发生在屏幕的左上角，则另一个神经元会做出反应。"
        }
    },
    {
        "translation": {
            "en": "All the descriptive features are Boolean, taking two levels: true or false.",
            "zh": "所有描述性特征都是布尔值，分为两个级别：true 或 false。"
        }
    },
    {
        "translation": {
            "en": "B.4   Summary",
            "zh": "B.4 总结"
        }
    },
    {
        "translation": {
            "en": "We then conclude the extensions and variations of deep learning by introducing two of the most popular network architectures used in deep learning: convolutional neural networks (Section 8.4.5[477]) and recurrent neural networks (Section 8.4.6[499]).",
            "zh": "然后，我们通过介绍深度学习中使用的两种最流行的网络架构来总结深度学习的扩展和变化：卷积神经网络（第 8.4.5 节[477]）和循环神经网络（第 8.4.6 节[499]）。"
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the breast cancer prediction dataset from Question 11 (after some data quality issues present in the dataset have been corrected).",
            "zh": "以下数据可视化基于问题 11 中的乳腺癌预测数据集（在数据集中存在的一些数据质量问题已得到纠正后）。"
        }
    },
    {
        "translation": {
            "en": "These error gradients are often denoted using the δ symbol with a subscript indicating the relevant neuron.",
            "zh": "这些误差梯度通常使用δ符号表示，下标表示相关神经元。"
        }
    },
    {
        "translation": {
            "en": "Linear models work very well when the underlying relationships in the data are linear.",
            "zh": "当数据中的基础关系是线性的时，线性模型可以很好地工作。"
        }
    },
    {
        "translation": {
            "en": "We recommend Fawcett (2006) as an excellent introduction and overview to ROC analysis that covers the topic of imbalance in the test set.",
            "zh": "我们推荐Fawcett（2006）作为ROC分析的一个很好的介绍和概述，涵盖了测试集中的不平衡主题。"
        }
    },
    {
        "translation": {
            "en": "Generative",
            "zh": "生成"
        }
    },
    {
        "translation": {
            "en": "5.6   The dataset from Table 5.5[204] with the Euclidean distance between each instance and the query SALARY = 56,000, AGE = 35 when we use both the SALARY and AGE features, just the SALARY feature, and just the AGE feature.",
            "zh": "5.6 表 5.5[204] 中的数据集，每个实例与查询之间的欧几里得距离 SALARY = 56,000，AGE = 35，当我们同时使用 SALARY 和 AGE 特征时，只使用 SALARY 特征，并且只使用 AGE 特征。"
        }
    },
    {
        "translation": {
            "en": "Machine learning is defined as an automated process that extracts patterns from data. To build the models used in predictive data analytics applications, we use supervised machine learning. Supervised machine learning1 techniques automatically learn a model of the relationship between a set of descriptive features and a target feature based on a set of historical examples, or instances. We can then use this model to make predictions for new instances. These two separate steps are shown in Figure 1.2[5].",
            "zh": "机器学习被定义为从数据中提取模式的自动化过程。为了构建预测数据分析应用程序中使用的模型，我们使用了监督机器学习。监督式机器学习1 技术基于一组历史示例或实例自动学习一组描述性特征与目标特征之间关系的模型。然后，我们可以使用此模型对新实例进行预测。这两个单独的步骤如图1.2所示[5]。"
        }
    },
    {
        "translation": {
            "en": "10.2   Fundamentals",
            "zh": "10.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the current weights in a multivariate linear regression model are w[0] = −59.50, w[1] = −0.15, and w[2] = 0.60, make a prediction for each training instance using this model.",
            "zh": "（a） 假设多元线性回归模型中的当前权重为 w[0] = −59.50、w[1] = −0.15 和 w[2] = 0.60，使用该模型对每个训练实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "In these equations we distinguish between these two paths of data processing and the weight matrices using the † and ‡.",
            "zh": "在这些方程中，我们使用 † 和 ‡ 区分了这两种数据处理路径和权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "31. Adaboost.R2 (Drucker, 1997) is a nice early example of a boosting algorithm designed to work with continuous targets.",
            "zh": "31. Adaboost.R2 （Drucker， 1997） 是设计用于连续目标的提升算法的一个很好的早期示例。"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we describe are how to handle categorical descriptive features, the use of logistic regression to make predictions for categorical target features, fine-tuning regression models, techniques for building non-linear and multinomial models, and support vector machines, which take a slightly different approach to using error to build prediction models.",
            "zh": "我们描述的这种标准方法的扩展和变体是如何处理分类描述性特征，使用逻辑回归对分类目标特征进行预测，微调回归模型，构建非线性和多项式模型的技术，以及支持向量机，它们采用略有不同的方法来使用误差来构建预测模型。"
        }
    },
    {
        "translation": {
            "en": "Throughout these technical chapters, the link to the broader predictive analytics context is maintained through detailed and complete real-world examples, along with references to the datasets and/or papers on which the examples are based.",
            "zh": "在这些技术章节中，通过详细而完整的真实示例以及对示例所基于的数据集和/或论文的引用，保持了与更广泛的预测分析上下文的链接。"
        }
    },
    {
        "translation": {
            "en": "Woolery, L., J. Grzymala-Busse, S. Summers, and A. Budihardjo. 1991. The use of machine learning program LERS-LB 2.5 in knowledge acquisition for expert system development in nursing. Computers in Nursing 9: 227–234.",
            "zh": "Woolery， L.、J. Grzymala-Busse、S. Summers 和 A. Budihardjo。1991. 机器学习程序 LERS-LB 2.5 在知识获取中的应用，用于护理专家系统开发。护理计算机 9：227-234。"
        }
    },
    {
        "translation": {
            "en": "The outcome of an attempt to catch a wave is a judgment on how well the surfer is doing, so an attempt constitutes an error function: lying too far back on the board leads to a medium error, lying too far forward on the board leads to a more dramatic error, while successfully catching a wave means really no error at all.",
            "zh": "尝试捕捉波浪的结果是对冲浪者表现的判断，因此尝试构成误差函数：在冲浪板上躺得太靠后会导致中等误差，在冲浪板上躺得太靠前会导致更严重的错误，而成功捕捉波浪意味着实际上根本没有错误。"
        }
    },
    {
        "translation": {
            "en": "Forward probability reasons from causes to effects: if we know that a particular causal event has happened, then we increase the probability associated with the known effects that it causes.",
            "zh": "从原因到结果的正向概率原因：如果我们知道一个特定的因果事件已经发生，那么我们就会增加与它引起的已知结果相关的概率。"
        }
    },
    {
        "translation": {
            "en": "We do this by defining an error function to measure the error between the predictions a model makes on the basis of the descriptive features for each instance in the training data and the actual target values for each instance in the training data.",
            "zh": "为此，我们定义了一个误差函数来衡量模型根据训练数据中每个实例的描述性特征做出的预测与训练数据中每个实例的实际目标值之间的误差。"
        }
    },
    {
        "translation": {
            "en": "If, however, you were to randomly select an element from the set in Figure 4.5(f)[124], you would be very uncertain about any prediction as there are 12 possible outcomes, each of which is equally likely.",
            "zh": "但是，如果您从图 4.5（f）[124] 中的集合中随机选择一个元素，您将非常不确定任何预测，因为有 12 种可能的结果，每种结果的可能性都相同。"
        }
    },
    {
        "translation": {
            "en": "The next section explains how use of the logistic function allows us to build logistic regression models that predict categorical target features.",
            "zh": "下一节将解释如何使用 logistic 函数来构建预测分类目标特征的逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "(b) Using the k-d tree that you created in the first part of this question, find the nearest neighbor to the following query: SIZE = 1,000, RENT = 2,200.",
            "zh": "（b） 使用您在本问题第一部分中创建的 k-d 树，找到与以下查询最近的相邻项：SIZE = 1,000，RENT = 2,200。"
        }
    },
    {
        "translation": {
            "en": "The data quality plan with potential handling strategies for the motor insurance fraud prediction ABT.",
            "zh": "具有潜在处理策略的数据质量计划，用于汽车保险欺诈预测 ABT。"
        }
    },
    {
        "translation": {
            "en": "Although it is evident from the confusion matrix that the model could distinguish between the edge-on spiral galaxies and the other two types, it could not accurately distinguish between the clockwise and anti-clockwise spiral galaxies.",
            "zh": "虽然从混淆矩阵中可以明显看出，该模型可以区分边缘螺旋星系和其他两种类型，但它无法准确区分顺时针和逆时针螺旋星系。"
        }
    },
    {
        "translation": {
            "en": "6.1   Big Idea",
            "zh": "6.1 大创意"
        }
    },
    {
        "translation": {
            "en": "In the first example, Figure 3.8(a)[73], a bar plot of the CAREER STAGE feature is shown above a 100% stacked bar plot showing how the levels of the SHOE SPONSOR feature are distributed in instances having each level of CAREER STAGE.",
            "zh": "在第一个示例中，图 3.8（a）[73]，CAREER STAGE 特征的条形图显示在 100% 堆叠条形图上方，显示了 SHOE SPONSOR 特征的级别在具有每个 CAREER STAGE 级别的实例中的分布情况。"
        }
    },
    {
        "translation": {
            "en": "We already used Equation (6.19)[288] when we were making predictions for a naive Bayes classifier.",
            "zh": "当我们对朴素贝叶斯分类器进行预测时，我们已经使用了方程（6.19）[288]。"
        }
    },
    {
        "translation": {
            "en": "12.5   Evaluation",
            "zh": "12.5 评估"
        }
    },
    {
        "translation": {
            "en": "8.4.5.4 Pooling The precise location of a visual feature in an image may not be relevant for an image-processing task.",
            "zh": "8.4.5.4 池化 图像中视觉特征的精确位置可能与图像处理任务无关。"
        }
    },
    {
        "translation": {
            "en": "Therefore, we can read the relevant probability distribution for CPI directly from the CPT for the CPI node.",
            "zh": "因此，我们可以直接从 CPI 节点的 CPT 中读取 CPI 的相关概率分布。"
        }
    },
    {
        "translation": {
            "en": "In some of the literature on neural networks, the term logit is used to refer to the result of a weighted sum calculation in a neuron (i.e., the value we normally denote z).",
            "zh": "在一些关于神经网络的文献中，术语 logit 用于指代神经元中加权和计算的结果（即我们通常表示的值 z）。"
        }
    },
    {
        "translation": {
            "en": "In these cases the insurance company goes through an expensive investigation process but still must make a reduced payment in relation to a claim.",
            "zh": "在这些情况下，保险公司要经过昂贵的调查过程，但仍然必须减少与索赔有关的付款。"
        }
    },
    {
        "translation": {
            "en": "Each image is labeled with the digit it contains, and the prediction task is to return the correct label for each image.",
            "zh": "每个图像都用它包含的数字进行标记，预测任务是为每个图像返回正确的标签。"
        }
    },
    {
        "translation": {
            "en": "correlation matrix, 83",
            "zh": "相关矩阵，83"
        }
    },
    {
        "translation": {
            "en": "8.10   The per example error of the ReLU network after the forward pass illustrated in Figure 8.18[440], the per example ∂ℰ/∂a 8, and the sum of squared errors for the ReLU model.",
            "zh": "8.10 图 8.18[440] 所示的前向传递后 ReLU 网络的每例误差、每例 ∂E/∂a 8 以及 ReLU 模型的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.7",
            "zh": "图 13.7"
        }
    },
    {
        "translation": {
            "en": "3.10   Using box plots to visualize the relationships between categorical and continuous features from Table 3.7[73]: (a) and (b) show the relationship between the POSITION feature and the AGE feature; and (c) and (d) show the relationship between the POSITION feature and the HEIGHT feature.",
            "zh": "3.10 使用箱形图可视化表3.7[73]中的分类特征和连续特征之间的关系：（a）和（b）显示POSITION特征与AGE特征之间的关系;（c）和（d）显示了POSITION特征和HEIGHT特征之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.7[277] illustrates this approximation.",
            "zh": "图6.7[277]说明了这种近似值。"
        }
    },
    {
        "translation": {
            "en": "The first rule we will introduce defines conditional probability in terms of joint probability:",
            "zh": "我们将介绍的第一条规则根据联合概率定义条件概率："
        }
    },
    {
        "translation": {
            "en": "6.2   Fundamentals",
            "zh": "6.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "In order to evaluate which machine learning model to use as the pre-annotator filter, the company created a test set of 10 phrases extracted at random from the set of 50,000 candidates.",
            "zh": "为了评估使用哪种机器学习模型作为预注释器过滤器，该公司创建了一个测试集，其中包含从50,000个候选者中随机提取的10个短语。"
        }
    },
    {
        "translation": {
            "en": "Comment on the appropriateness of these outputs.",
            "zh": "评论这些产出的适当性。"
        }
    },
    {
        "translation": {
            "en": "Notice that both Neurons 3 and 4 have an activation of zero for d2.",
            "zh": "请注意，神经元 3 和 4 对 d2 的激活均为零。"
        }
    },
    {
        "translation": {
            "en": "The derivative of the rectifier function is:",
            "zh": "整流器功能的导数为："
        }
    },
    {
        "translation": {
            "en": "It is particularly common to use deciles for this task.",
            "zh": "在此任务中使用十分位数特别常见。"
        }
    },
    {
        "translation": {
            "en": "Often the ROC curves for multiple predictive models will be plotted on a single ROC plot, allowing easy comparison of their performance.",
            "zh": "通常，多个预测模型的 ROC 曲线将绘制在单个 ROC 图上，以便轻松比较其性能。"
        }
    },
    {
        "translation": {
            "en": "For example, if the network shown on the right of Figure 8.37[502] was applied only to a single input, then we would calculate the δs for the neurons in the output layer.47 and then backpropagate these δs to the hidden layer neurons.",
            "zh": "例如，如果图8.37[502]右侧显示的网络仅应用于单个输入，那么我们将计算输出层中神经元的δs.47，然后将这些δ反向传播到隐藏层神经元。"
        }
    },
    {
        "translation": {
            "en": "Given that (1) the SDSS data that Jocelyn downloaded was already in a single table; (2) the data was already at the right prediction subject level (one row per galaxy); and (3) many of the columns in this dataset would most likely be used directly as features in the ABT that she was building, Jocelyn decided to produce a data quality report on this dataset.",
            "zh": "鉴于 （1） Jocelyn 下载的 SDSS 数据已经在单个表中;（2）数据已经处于正确的预测主题水平（每个星系一行）;（3） 该数据集中的许多列很可能直接用作她正在构建的 ABT 中的特征，Jocelyn 决定生成有关此数据集的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the query instances shown in the following table (question marks refer to missing values).",
            "zh": "使用此模型对下表中显示的每个查询实例进行预测（问号是指缺失值）。"
        }
    },
    {
        "translation": {
            "en": "7.4.4.2 Logistic regression To build a logistic regression model, we threshold the output of the basic linear regression model using the logistic function. So, instead of the regression function simply being the dot product of the weights and the descriptive features (as given in Equation (7.9)[320]), the dot product of weights and descriptive feature values is passed through the logistic function",
            "zh": "7.4.4.2 逻辑回归 为了构建逻辑回归模型，我们使用逻辑函数对基本线性回归模型的输出进行阈值。因此，回归函数不是简单地是权重和描述性特征的点积（如公式（7.9）[320]所示），而是通过逻辑函数传递权重和描述性特征值的点积"
        }
    },
    {
        "translation": {
            "en": "For every step that the agent is firing one of its thrusters it receives a reward of − 0.3.",
            "zh": "对于智能体发射其推进器的每一步，它都会获得 − 0.3 的奖励。"
        }
    },
    {
        "translation": {
            "en": "2.12   A summary of the tasks in the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process.",
            "zh": "2.12 CRISP-DM 流程的业务理解、数据理解和数据准备阶段的任务摘要。"
        }
    },
    {
        "translation": {
            "en": "Because the instances in the validation set are not used during training, the error rate on the validation set provides a good estimate of the generalization capability of a decision tree.",
            "zh": "由于验证集中的实例在训练期间未使用，因此验证集上的错误率可以很好地估计决策树的泛化能力。"
        }
    },
    {
        "translation": {
            "en": "Similarly, as we move from one neuron to the next vertically, the receptive fields also move by one row in the input space.",
            "zh": "同样，当我们从一个神经元垂直移动到下一个神经元时，感受野也会在输入空间中移动一行。"
        }
    },
    {
        "translation": {
            "en": "Uppercase letters denote generic events where an unspecified feature (or set of features) is assigned a value (or set of values). Typically, we use letters from the end of the alphabet—e.g., X, Y, Z—for this purpose.",
            "zh": "大写字母表示为未指定要素（或要素集）分配一个值（或一组值）的通用事件。通常，我们使用字母表末尾的字母（例如 X、Y、Z）来实现此目的。"
        }
    },
    {
        "translation": {
            "en": "Although the arithmetic mean and median are two of the most commonly known such measures, there are more, including the harmonic mean.",
            "zh": "虽然算术平均值和中位数是两个最常见的此类度量，但还有更多，包括谐波平均值。"
        }
    },
    {
        "translation": {
            "en": "In particular, in any neuron where the input to the rectifier function is greater than zero (z > 0) then the neuron will activate during the forward pass and the partial derivative of the activation function will be 1 during the backward pass.",
            "zh": "特别是，在任何整流器函数的输入大于零（z > 0）的神经元中，神经元将在正向传递期间激活，而激活函数的偏导数在向后传递期间将为 1。"
        }
    },
    {
        "translation": {
            "en": "7.3.4 A Worked Example",
            "zh": "7.3.4 工作示例"
        }
    },
    {
        "translation": {
            "en": "We then do the forward and backward pass of the backpropagation and the weight update as usual for that example; the distinction is just that these processes will be run on the smaller network that remains after the selected neurons were dropped.",
            "zh": "然后，对于该示例，我们像往常一样进行反向传播的前向和向后传递以及权重更新;区别仅在于这些进程将在选定的神经元被丢弃后剩余的较小网络上运行。"
        }
    },
    {
        "translation": {
            "en": "Fry, Ben. 2007. Visualizing data: Exploring and explaining data with the processing environment. O’Reilly Media.",
            "zh": "弗莱，本。2007. 可视化数据：在处理环境中探索和解释数据。O'Reilly 媒体。"
        }
    },
    {
        "translation": {
            "en": "This is why, rather than just using the sum of the errors, we use the sum of the squared errors because this means all values will be positive.",
            "zh": "这就是为什么我们不仅使用误差之和，还使用误差平方之和，因为这意味着所有值都是正数。"
        }
    },
    {
        "translation": {
            "en": "cell, 508",
            "zh": "细胞， 508"
        }
    },
    {
        "translation": {
            "en": "The first consideration is data availability, because we must have data available to implement any feature we would like to use. For example, in an online payments service scenario, we might define a feature that calculates the average of a customer’s account balance over the past six months. Unless the company maintains a historical record of account balances covering the full six-month period, however, it will not be possible to implement this feature.",
            "zh": "首先要考虑的是数据可用性，因为我们必须有可用的数据来实现我们想要使用的任何功能。例如，在在线支付服务场景中，我们可以定义一个功能来计算客户过去六个月的账户余额的平均值。但是，除非公司保留涵盖整个六个月期间的账户余额的历史记录，否则将无法实现此功能。"
        }
    },
    {
        "translation": {
            "en": "By having multiple such groups of neurons, in which each group contained neurons that specialized in identifying a particular visual feature and that as a whole inspected the entire visual field for the target feature, the cat was able to perceive multiple different features occurring at different locations at the same time.",
            "zh": "通过拥有多个这样的神经元组，其中每组都包含专门识别特定视觉特征的神经元，并且作为一个整体检查目标特征的整个视野，猫能够感知同时发生在不同位置的多个不同特征。"
        }
    },
    {
        "translation": {
            "en": "Perhaps the most important thing to remember in relation to correlation is that correlation does not necessarily imply causation.",
            "zh": "也许要记住的最重要的事情是，相关性并不一定意味着因果关系。"
        }
    },
    {
        "translation": {
            "en": "Using the notation φsm to denote the softmax activation function, φsm(l) denotes applying the softmax function to the vector of logits l, and φsm(li) refers to the calculation of the softmax value for the ith logit, that is, the output activation of the i neuron in the layer.",
            "zh": "使用符号 φsm 表示 softmax 激活函数，φsm（l） 表示将 softmax 函数应用于 logits l 的向量，φsm（li） 表示计算第 i 个 logit 的 softmax 值，即层中 i 神经元的输出激活。"
        }
    },
    {
        "translation": {
            "en": "So, if on alternate evenings Conor swapped between choosing his favorite menu item and choosing a menu item at random (ε = 0.5), by the end of the two weeks he will have enjoyed a whole selection of meals from the hotel restaurant’s dishes of chicken, beef, pork, mushrooms, and salmon.17",
            "zh": "因此，如果在隔天晚上，康纳在选择他最喜欢的菜单项和随机选择菜单项之间切换（ε = 0.5），到两周结束时，他将享受到酒店餐厅的鸡肉、牛肉、猪肉、蘑菇和鲑鱼等各种菜肴17。"
        }
    },
    {
        "translation": {
            "en": "where (d1,t1)…(dn,tn) are n training instances, and di[j] is the jth descriptive feature of training instance (di,ti). The direction of the gradient calculated using this equation is toward the highest values on the error surface. The error delta function from Line 4[326] of Algorithm 4[326] should return a small step toward a lower value on the error surface. Therefore, we move in the opposite direction of the calculated gradient, and the error delta function can be written",
            "zh": "其中 （d1，t1）...（dn，tn） 是 n 个训练实例，di[j] 是训练实例 （di，ti） 的第 j 个描述性特征。使用此方程计算的梯度方向朝向误差曲面上的最高值。算法 4[326] 的第 4 行 [326] 中的误差增量函数应返回一小步，朝着误差面上的较低值迈进。因此，我们沿计算梯度的相反方向移动，可以写出误差增量函数"
        }
    },
    {
        "translation": {
            "en": "The ROC index can take values in the range [0,1] (although values less than 0.5 are unlikely and indicative of a target labeling error), and larger values indicate better model performance.",
            "zh": "ROC 指数可以取 [0,1] 范围内的值（尽管小于 0.5 的值不太可能，并且指示目标标记错误），较大的值表示更好的模型性能。"
        }
    },
    {
        "translation": {
            "en": "The fact that the nearest neighbor algorithm stores the entire training dataset in memory has a negative effect on the time complexity of the algorithm.",
            "zh": "最近邻算法将整个训练数据集存储在内存中这一事实对算法的时间复杂度有负面影响。"
        }
    },
    {
        "translation": {
            "en": "A.1   A dataset showing the positions and monthly training expenses of a school basketball team.",
            "zh": "A.1 显示学校篮球队的位置和每月训练费用的数据集。"
        }
    },
    {
        "translation": {
            "en": "In Figure 8.40[509] the cell is depicted by the line extending from ct−1 to ct across the top of the diagram.",
            "zh": "在图8.40[509]中，单元格由从ct−1延伸到ct的线穿过图的顶部表示。"
        }
    },
    {
        "translation": {
            "en": "The following table shows a small dataset used for human activity recognition from a wearable accelerometer sensor.16 Each instance describes the average acceleration in the X, Y, and Z directions within a short time window.",
            "zh": "下表显示了用于从可穿戴加速度计传感器识别人体活动的小型数据集。16 每个实例都描述了短时间窗口内 X、Y 和 Z 方向的平均加速度。"
        }
    },
    {
        "translation": {
            "en": "1st New",
            "zh": "1st 新品"
        }
    },
    {
        "translation": {
            "en": "Locating 25,630.3 on the horizontal axis shows that this upper threshold would cause a relatively large number of values to be changed.",
            "zh": "在水平轴上定位 25,630.3 表明此上限阈值将导致相对较多的值发生更改。"
        }
    },
    {
        "translation": {
            "en": "This new node indexes d15.",
            "zh": "这个新节点索引 d15。"
        }
    },
    {
        "translation": {
            "en": "stacked bar plot, 77",
            "zh": "堆叠条形图，77"
        }
    },
    {
        "translation": {
            "en": "Poll results from the run-up to the 2012 U.S. presidential election.",
            "zh": "2012年美国总统大选前的民意调查结果。"
        }
    },
    {
        "translation": {
            "en": "Second, as the number of features in the domain grows, the difference between the number of probabilities required for a factorized representation and the number of probabilities in the full joint probability distribution gets larger.",
            "zh": "其次，随着域中特征数量的增加，分解表示所需的概率数与完全联合概率分布中的概率数之间的差异会变大。"
        }
    },
    {
        "translation": {
            "en": "So, the assumed conditional independence between the features permits us to factorize the distribution and in doing so reduces the number of probabilities we need to calculate and store from the data.",
            "zh": "因此，特征之间的假设条件独立性允许我们对分布进行因式分解，从而减少了我们需要从数据中计算和存储的概率数量。"
        }
    },
    {
        "translation": {
            "en": "9.4.6.4 Comparative experiments using a control group At the beginning of this chapter, we emphasized that it is important that the evaluation of prediction models not just focus on predictive power but also take into account the suitability of the model for the task to which it will be deployed.",
            "zh": "9.4.6.4 使用对照组的比较实验 在本章开始时，我们强调，重要的是，预测模型的评估不仅要关注预测能力，还要考虑模型对将要部署的任务的适用性。"
        }
    },
    {
        "translation": {
            "en": "8.40   A schematic of the internal structure of a long short-term memory unit.",
            "zh": "8.40 长短期记忆单元的内部结构示意图。"
        }
    },
    {
        "translation": {
            "en": "The categorical target feature, in particular, makes decision trees a suitable choice for this modeling task.",
            "zh": "特别是分类目标特征，使决策树成为此建模任务的合适选择。"
        }
    },
    {
        "translation": {
            "en": "Astronomy has gone through a revolution in recent years as the reducing costs of digital imaging has made it possible to collect orders of magnitude more data than ever before.",
            "zh": "近年来，天文学经历了一场革命，因为数字成像成本的降低使得收集的数据比以往任何时候都多。"
        }
    },
    {
        "translation": {
            "en": "6.12   Partitioning the dataset based on the value of the target feature and fitting the parameters of a statistical distribution to model the ACCOUNT BALANCE feature in each partition.",
            "zh": "6.12 根据目标特征的值对数据集进行分区，并拟合统计分布的参数，以对每个分区中的 ACCOUNT BALANCE 特征进行建模。"
        }
    },
    {
        "translation": {
            "en": "R2, 578, 586",
            "zh": "R2、578、586"
        }
    },
    {
        "translation": {
            "en": "If, however, a graph is composed of a number of clusters connected via bottleneck nodes, this would typically indicate a longer mixing time.",
            "zh": "但是，如果一个图由许多通过瓶颈节点连接的集群组成，这通常表明混合时间更长。"
        }
    },
    {
        "translation": {
            "en": "However, using this regime also allowed us to highlight some of the problems that arise when weights are set naively, such as the problem of vanishing gradients, and dead neurons.",
            "zh": "然而，使用这种机制也使我们能够突出一些在天真地设置权重时出现的问题，例如梯度消失和神经元死亡的问题。"
        }
    },
    {
        "translation": {
            "en": "First, Jocelyn had put the SDSS data through a preprocessing step, standardizing all descriptive features.",
            "zh": "首先，Jocelyn 对 SDSS 数据进行了预处理，将所有描述性特征标准化。"
        }
    },
    {
        "translation": {
            "en": "bag-of-words, 223, 236",
            "zh": "词袋，223,236"
        }
    },
    {
        "translation": {
            "en": "The final ABT contained 10,000 instances equally split between customers who churned and customers who did not churn.",
            "zh": "最终的 ABT 包含 10,000 个实例，在流失的客户和未流失的客户之间平均分配。"
        }
    },
    {
        "translation": {
            "en": "4.4.4   Tree Pruning",
            "zh": "4.4.4 树木修剪"
        }
    },
    {
        "translation": {
            "en": "In that section we also explained that most practitioners use rules of thumb and trial and error to set the learning rate.",
            "zh": "在本节中，我们还解释了大多数从业者使用经验法则和反复试验来设定学习率。"
        }
    },
    {
        "translation": {
            "en": "For example, the goal in the insurance claim fraud scenario we have been considering is to make predictions about whether an insurance claim will turn out to be fraudulent after investigation based on the details of the claim itself and the details of the claimant’s behavior in the time preceding the claim.",
            "zh": "例如，我们一直在考虑的保险索赔欺诈场景中的目标是根据索赔本身的细节和索赔人在索赔前一段时间的行为细节，预测保险索赔在调查后是否会被证明是欺诈性的。"
        }
    },
    {
        "translation": {
            "en": "di[j] denotes the value of the jth descriptive feature of the ith instance in a dataset.",
            "zh": "di[j] 表示数据集中第 i 个实例的第 j 个描述性特征的值。"
        }
    },
    {
        "translation": {
            "en": "In this example the actual population of interest was the voting population of the United States, which was approximately 240,926,957 people.",
            "zh": "在此示例中，感兴趣的实际人口是美国的投票人口，约为 240,926,957 人。"
        }
    },
    {
        "translation": {
            "en": "The number of soft tissue injury claims the claimant has made in the past and the ratio between the number of soft tissue injury claims and other claims made by the claimant are both included as descriptive features in the ABT.",
            "zh": "索赔人过去提出的软组织损伤索赔数量以及软组织损伤索赔数量与索赔人提出的其他索赔数量之间的比率均作为描述性特征列入ABT。"
        }
    },
    {
        "translation": {
            "en": "A scalar is a single number.",
            "zh": "标量是一个数字。"
        }
    },
    {
        "translation": {
            "en": "The parameter λ is learned in tandem with the weights of the network. Similar to the weights of the network, the λ parameter is initialized to a value and is then iteratively updated as training progresses. In their experiments He et al. (2015) initialized the λ parameters in their networks to 0.25. Also similar to the weights in a network, the updating of a λ is proportional to the error gradient of the network with respect to changes in that parameter",
            "zh": "参数 λ 与网络的权重一起学习。与网络的权重类似，λ 参数被初始化为一个值，然后随着训练的进行进行迭代更新。在他们的实验中，He等人（2015）将网络中的λ参数初始化为0.25。与网络中的权重类似，λ 的更新与网络相对于该参数变化的误差梯度成正比"
        }
    },
    {
        "translation": {
            "en": "The matrix labeled Input Layer contains the inputs for the examples, augmented with the bias inputs for each neuron.",
            "zh": "标记为输入层的矩阵包含示例的输入，并用每个神经元的偏差输入进行增强。"
        }
    },
    {
        "translation": {
            "en": "8. Francis Anscombe was a famous statistician who published his quartet in 1973 (Anscombe, 1973).",
            "zh": "8. 弗朗西斯·安斯科姆（Francis Anscombe）是一位著名的统计学家，他于1973年出版了他的四重奏（Anscombe，1973）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.6[393] illustrates how the same sequence of operations shown in Figure 8.5[392] to process one example can be used to enable the same network to process four examples in parallel.",
            "zh": "图 8.6[393] 说明了如何使用图 8.5[392] 中所示的相同操作序列来处理一个示例，以使同一网络能够并行处理四个示例。"
        }
    },
    {
        "translation": {
            "en": "However, as networks become deeper they can become more difficult to train.",
            "zh": "然而，随着网络变得越来越深，它们可能会变得更加难以训练。"
        }
    },
    {
        "translation": {
            "en": "The drawback of batch gradient descent is that the entire dataset must be processed between each weight update.",
            "zh": "批量梯度下降的缺点是必须在每次权重更新之间处理整个数据集。"
        }
    },
    {
        "translation": {
            "en": "Error-based learning (Chapter 7[311])",
            "zh": "基于错误的学习（第7章[311]）"
        }
    },
    {
        "translation": {
            "en": "Edwin was broadly in agreement with the set of domain concepts that Jocelyn had developed and was very positive about the use of Galaxy Zoo classifications as a source for generating the target feature.",
            "zh": "Edwin 大体上同意 Jocelyn 开发的一组领域概念，并且非常积极地使用 Galaxy Zoo 分类作为生成目标特征的来源。"
        }
    },
    {
        "translation": {
            "en": "deep Q network, 637, 664, 671, 673, 676",
            "zh": "深Q网络， 637， 664， 671， 673， 676"
        }
    },
    {
        "translation": {
            "en": "10.6   (a) Intra-cluster distance; (b) inter-cluster distance; (c) a good clustering; and (d) a bad clustering.",
            "zh": "10.6 （a） 集群内距离;（b） 集群间距离;（c） 良好的聚类;（d）聚类不良。"
        }
    },
    {
        "translation": {
            "en": "The particular choices of filter size, stride length, and padding is task dependent.",
            "zh": "滤镜大小、步幅和填充的特定选择取决于任务。"
        }
    },
    {
        "translation": {
            "en": "In this figure, the activation flow through the gates is ordered vertically: the top row of the figure illustrates the flow through the forget gate; the next two rows illustrate the flow through the two paths of the input gate; and the bottom two rows illustrate the flow through the two paths of the output gate.",
            "zh": "在此图中，通过闸门的激活流是垂直排序的：图的顶行说明了通过遗忘闸门的流;接下来的两行说明了通过输入门的两条路径的流量;底部两行表示通过输出门的两条路径的流量。"
        }
    },
    {
        "translation": {
            "en": "The age of the customer’s current handset",
            "zh": "客户当前手机的使用年限"
        }
    },
    {
        "translation": {
            "en": "Is it better for a genuine email to be marked as spam and deleted, or for a spam email to end up in our in-box?",
            "zh": "是将真正的电子邮件标记为垃圾邮件并删除，还是将垃圾邮件最终发送到我们的收件箱更好？"
        }
    },
    {
        "translation": {
            "en": "multivariable, 319",
            "zh": "多变量，319"
        }
    },
    {
        "translation": {
            "en": "With that caveat regarding bias terms stated, we return to the question of why non-linear activation functions are necessary in a neural network. It turns out that understanding that a neural network can be implemented as a sequence of matrix multiplications with the non-linearity of the activation functions introduced between the matrix multiplications can help answer this question.",
            "zh": "在对偏差项提出警告之后，我们回到为什么非线性激活函数在神经网络中是必要的问题。事实证明，理解神经网络可以实现为矩阵乘法序列，矩阵乘法之间引入的激活函数的非线性可以帮助回答这个问题。"
        }
    },
    {
        "translation": {
            "en": "(a) Assign each instance to its nearest cluster to generate the clustering at the first iteration of k-means on the basis of the initial cluster centroids.",
            "zh": "（a） 将每个实例分配到其最近的聚类，以在基于初始聚类质心的 k 均值的第一次迭代中生成聚类。"
        }
    },
    {
        "translation": {
            "en": "Linear algebra is an important topic in machine learning.",
            "zh": "线性代数是机器学习中的一个重要主题。"
        }
    },
    {
        "translation": {
            "en": "These are not massively different from the values calculated using root mean squared error.",
            "zh": "这些值与使用均方根误差计算的值没有太大差异。"
        }
    },
    {
        "translation": {
            "en": "The weights used by this ReLU are shown on the edges feeding into the unit.",
            "zh": "该 ReLU 使用的砝码显示在送入装置的边缘上。"
        }
    },
    {
        "translation": {
            "en": "We can, however, use the values in the profit matrix to calculate the overall profit associated with the predictions made by these two models.",
            "zh": "但是，我们可以使用利润矩阵中的值来计算与这两个模型所做的预测相关的总利润。"
        }
    },
    {
        "translation": {
            "en": "To make this decision, we partition the training data based on the target feature and generate histograms of the values of the descriptive feature for each of the splits.",
            "zh": "为了做出这个决定，我们根据目标特征对训练数据进行分区，并为每个拆分生成描述性特征值的直方图。"
        }
    },
    {
        "translation": {
            "en": "Montúfar, Guido. 2014. Universal approximation depth and errors of narrow belief networks with discrete units. Neural Computation 26 (7): 1386–1407.",
            "zh": "蒙图法尔，圭多。2014. 具有离散单元的狭义信念网络的普遍近似深度和误差.神经计算 26 （7）：1386–1407。"
        }
    },
    {
        "translation": {
            "en": "The Claim Details domain concept, for example, highlights the importance of the details of the claim itself in distinguishing between fraudulent and genuine claims.",
            "zh": "例如，“权利要求详细信息”域概念强调了权利要求本身的详细信息在区分欺诈性权利要求和真实权利要求方面的重要性。"
        }
    },
    {
        "translation": {
            "en": "The initial cluster centroids for the two clusters 1 and 2 are c1 = −0.235,0.253,0.438 and c2 = 0.232,0.325,−0.159.",
            "zh": "两个聚类 1 和 2 的初始聚类质心为 c1 = −0.235,0.253,0.438 和 c2 = 0.232,0.325，−0.159。"
        }
    },
    {
        "translation": {
            "en": "After dividing the dataset into groups, the number of instances in the largest group becomes the over-sampling target size.",
            "zh": "将数据集划分为组后，最大组中的实例数成为过采样目标大小。"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_G_R",
            "zh": "PETROMAGDIFF_G_R"
        }
    },
    {
        "translation": {
            "en": "whiskers, 755",
            "zh": "晶须，755"
        }
    },
    {
        "translation": {
            "en": "Table 9.20",
            "zh": "表 9.20"
        }
    },
    {
        "translation": {
            "en": "Once the number of bins, b, has been chosen, the equal-width binning algorithm splits the range of the feature values into b bins each of size . For example, if the values for a feature fell between zero and 100 and we wished to have 10 bins, then bin 1 would cover the interval12 [0,10), bin 2 would cover the interval [10,20), and so on, up to bin 10, which would cover the interval [90,100]. Consequently, an instance with a feature value of 18 would be placed into bin 2.",
            "zh": "选择箱数 b 后，等宽分箱算法将特征值的范围拆分为 b 箱，每个箱的大小为 。例如，如果一个特征的值介于 0 和 100 之间，并且我们希望有 10 个箱，则箱 1 将覆盖区间 12 [0,10]，箱 2 将覆盖区间 [10,20]，依此类推，直到箱 10，它将覆盖区间 [90,100]。因此，特征值为 18 的实例将被放入 bin 2 中。"
        }
    },
    {
        "translation": {
            "en": "Categorical Targets In the context of handling categorical target features (see Section 8.4.3[463]) using a softmax function, we use the following symbols:",
            "zh": "分类目标 在使用 softmax 函数处理分类目标特征的上下文中（参见 Section 8.4.3[463]），我们使用以下符号："
        }
    },
    {
        "translation": {
            "en": "The distances calculated using only the SALARY feature are almost exactly the same as the distances calculated using both the SALARY and AGE features.",
            "zh": "仅使用 SALARY 特征计算的距离与使用 SALARY 和 AGE 特征计算的距离几乎完全相同。"
        }
    },
    {
        "translation": {
            "en": "5.4.6   Feature Selection",
            "zh": "5.4.6 功能选择"
        }
    },
    {
        "translation": {
            "en": "6.4.4.2 Using a Bayesian network to make predictions Once a network has been created, it is relatively straightforward to use to make a prediction. We simply compute the probability distribution for the target feature conditioned on the state of the descriptive features in the query and return the target feature level with the maximum a posteriori probability:",
            "zh": "6.4.4.2 使用贝叶斯网络进行预测 一旦创建了网络，就可以相对简单地使用它进行预测。我们只需根据查询中描述性特征的状态计算目标特征的概率分布，并返回具有最大后验概率的目标特征级别："
        }
    },
    {
        "translation": {
            "en": "cubic clustering criterion, 609",
            "zh": "三次聚类准则，609"
        }
    },
    {
        "translation": {
            "en": "The bulk of this chapter discusses these different approaches and the kinds of modeling tasks that they best suit.",
            "zh": "本章的大部分内容将讨论这些不同的方法以及它们最适合的建模任务类型。"
        }
    },
    {
        "translation": {
            "en": "The two plots on the right show the distributions for those players with and without a shoe sponsor.",
            "zh": "右边的两张图显示了有和没有球鞋赞助商的球员的分布情况。"
        }
    },
    {
        "translation": {
            "en": "We will not discuss these topics here.",
            "zh": "我们不会在这里讨论这些话题。"
        }
    },
    {
        "translation": {
            "en": "(a) Using equal-frequency binning, transform the AGE feature into a categorical feature with three levels: young, middle-aged, mature.",
            "zh": "（a） 使用等频分箱，将 AGE 特征转换为具有三个级别的分类特征：年轻、中年、成熟。"
        }
    },
    {
        "translation": {
            "en": "The player has just three controls: thrusters that turn the spacecraft left and right, and one that pushes it up.",
            "zh": "玩家只有三个控制：左右转动航天器的推进器，以及一个推动它向上的推进器。"
        }
    },
    {
        "translation": {
            "en": "Instance d6 has a target value of yes, and this is why the model will return a positive prediction for the query.",
            "zh": "实例 d6 的目标值为 yes，这就是模型将返回查询的正预测的原因。"
        }
    },
    {
        "translation": {
            "en": "When time is a factor in a scenario, the descriptive features and the target feature will not necessarily both be time dependent. In some cases only the descriptive features have a time component to them, and the target feature is time independent. Conversely, the target feature may have a time component and the descriptive features may not.",
            "zh": "当时间是场景中的一个因素时，描述性特征和目标特征不一定都与时间相关。在某些情况下，只有描述性特征具有时间分量，而目标特征与时间无关。相反，目标特征可能具有时间分量，而描述性特征可能没有。"
        }
    },
    {
        "translation": {
            "en": "In particular, we use the 6-by-6 matrix grayscale encoding of a 4, shown in Equation (8.84)[478] as the input pattern for our examples",
            "zh": "具体而言，我们使用公式（8.84）[478]中所示的4的6×6矩阵灰度编码作为示例的输入模式"
        }
    },
    {
        "translation": {
            "en": "The action-value target network is frozen and not updated at each iteration of the algorithm.",
            "zh": "动作值目标网络被冻结，并且在算法的每次迭代时都不会更新。"
        }
    },
    {
        "translation": {
            "en": "First, when we are dealing with large datasets, it is likely that there is noise3 in the data, and prediction models that are consistent with noisy data make incorrect predictions.",
            "zh": "首先，当我们处理大型数据集时，数据中很可能存在噪声3，与噪声数据一致的预测模型会做出错误的预测。"
        }
    },
    {
        "translation": {
            "en": "This figure was inspired by Figure 4.2 in (Reed and Marks, 1999) and Figure 3.10 in (Marsland, 2011).",
            "zh": "这个数字的灵感来自图4.2（Reed和Marks，1999）和图3.10（Marsland，2011）。"
        }
    },
    {
        "translation": {
            "en": "For example, if we dropped the d[0] dummy feature and then multiplied each of the real descriptive features by a weight and summed the results, we would be applying a linear function to the inputs.",
            "zh": "例如，如果我们去掉 d[0] 虚拟特征，然后将每个真实的描述性特征乘以一个权重并将结果相加，我们将对输入应用线性函数。"
        }
    },
    {
        "translation": {
            "en": "This means that a nearest neighbor model may not be appropriate in domains where speed of prediction is of the essence.",
            "zh": "这意味着最近邻模型可能不适合预测速度至关重要的领域。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23",
            "zh": "图 7.23"
        }
    },
    {
        "translation": {
            "en": "This introduction is focused primarily on supporting your understanding of the content in this book, in particular the chapter on deep learning, rather than on providing a comprehensive introduction to linear algebra.",
            "zh": "本介绍主要侧重于支持您理解本书的内容，特别是关于深度学习的章节，而不是提供线性代数的全面介绍。"
        }
    },
    {
        "translation": {
            "en": "(c) The ROC index is insensitive to changes in class distribution within the test set. This means that if the proportion of positive to negative instances changes in a test set, the ROC index will remain the same if the performance of the models on each class is constant. Consequently, the ROC index is robust to class imbalance or skew in the test set. Why do you think this is the case?26",
            "zh": "（c） ROC指数对测试集中类别分布的变化不敏感。这意味着，如果测试集中正实例与负实例的比例发生变化，则如果模型在每个类上的性能保持不变，则 ROC 指数将保持不变。因此，ROC 指数对测试集中的类别不平衡或偏斜具有鲁棒性。你认为为什么会这样？26"
        }
    },
    {
        "translation": {
            "en": "The statistics outlined in the previous section work well to describe continuous features, but they do not work for categorical features.",
            "zh": "上一节中概述的统计量适用于描述连续要素，但不适用于分类要素。"
        }
    },
    {
        "translation": {
            "en": "In this situation, the observation period for all the prediction subjects, in this case, customers, might be defined as the six months prior to the launch of the new product, and the outcome period might cover the three months after the launch.",
            "zh": "在这种情况下，所有预测对象（在本例中为客户）的观察期可能定义为新产品发布前的六个月，结果期可能涵盖发布后的三个月。"
        }
    },
    {
        "translation": {
            "en": "Designing solutions based on unsupervised machine learning techniques can be more creative than designing solutions based on supervised learning because the solutions tend not to follow quite so obvious a pattern.",
            "zh": "基于无监督机器学习技术设计解决方案可能比基于监督学习设计解决方案更具创造性，因为解决方案往往不遵循如此明显的模式。"
        }
    },
    {
        "translation": {
            "en": "Grace explained to Ross that incomes were actually recorded in bands rather than as exact values, so this was really a categorical feature.",
            "zh": "格蕾丝向罗斯解释说，收入实际上是以波段记录的，而不是作为精确值记录的，所以这确实是一个分类特征。"
        }
    },
    {
        "translation": {
            "en": "When padding is applied it is generally added to all edges as equally as is possible.",
            "zh": "应用填充时，通常会尽可能平均地将其添加到所有边缘。"
        }
    },
    {
        "translation": {
            "en": "10.3   Summary statistics for the three clusters found in the mobile phone customer dataset in Table 10.1[604] using k-means clustering (k = 3). Note, that the % missing and cardinality columns usually used are omitted here for legibility as these data quality issues will not arise in this simple example. They could be included when this approach is used on real datasets.",
            "zh": "10.3 使用k-means聚类（k = 3）对表10.1[604]中的移动电话客户数据集中发现的三个聚类进行汇总统计。请注意，为了便于阅读，此处省略了通常使用的缺失百分比和基数列，因为在这个简单示例中不会出现这些数据质量问题。当这种方法用于实际数据集时，可以包括它们。"
        }
    },
    {
        "translation": {
            "en": "The three weight matrices are",
            "zh": "这三个权重矩阵是"
        }
    },
    {
        "translation": {
            "en": "We have seen that switching a network from a logistic activation function to a rectified linear activation function can speed up training; however, a less obvious effect of this switch is that it also tends to make the representations learned by a network sparse.",
            "zh": "我们已经看到，将网络从逻辑激活函数切换到整流线性激活函数可以加快训练速度;然而，这种切换的一个不太明显的效果是，它还倾向于使网络学习的表示变得稀疏。"
        }
    },
    {
        "translation": {
            "en": "To ground our discussion of PDFs, and to illustrate how they can be used in making naive Bayes prediction models, we will extend our loan application fraud detection scenario to have two extra continuous features: ACCOUNT BALANCE, which specifies the amount of money in the account of the loan applicant at the time of the application; and LOAN AMOUNT, which specifies the amount of the loan being applied for.",
            "zh": "为了奠定我们对 PDF 的讨论的基础，并说明如何使用它们来制作朴素的贝叶斯预测模型，我们将扩展我们的贷款申请欺诈检测场景，以具有两个额外的连续功能：账户余额，指定申请时贷款申请人账户中的金额;和 LOAN AMOUNT，指定所申请的贷款金额。"
        }
    },
    {
        "translation": {
            "en": "Table 9.16[568] shows the lift for each decile for the predictions shown in Table 9.11[557] for the email classification problem.",
            "zh": "表 9.16[568] 显示了表 9.11[557] 中针对电子邮件分类问题的预测，每个十分位数的提升。"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values and target feature values for the support vectors in these cases are (−0.225, 0.217, + 1), (−0.066, −0.069,−1), and (−0.273, −0.080, −1).",
            "zh": "在这些情况下，支持向量的描述性特征值和目标特征值为 （−0.225， 0.217， + 1）、（−0.066， −0.069，−1） 和 （−0.273， −0.080， −1）。"
        }
    },
    {
        "translation": {
            "en": "This has the impact of first greatly reducing the dimensionality of the input data, before reproducing the inputs from this lower-dimensional representation.",
            "zh": "这首先会大大降低输入数据的维数，然后再从这种低维表示法重现输入。"
        }
    },
    {
        "translation": {
            "en": "calculus, 765",
            "zh": "微积分，765"
        }
    },
    {
        "translation": {
            "en": "4.9   Dataset for predicting the vegetation in an area sorted by the continuous ELEVATION feature.",
            "zh": "4.9 用于预测按连续高程要素排序的区域内植被的数据集。"
        }
    },
    {
        "translation": {
            "en": "CLASS: The clinician’s assessment of the biopsy sample as either benign or malignant.",
            "zh": "CLASS：临床医生对活检样本的评估是良性还是恶性。"
        }
    },
    {
        "translation": {
            "en": "The silhouette is a well-known and widely used performance measure that assesses how well a clustering meets these criteria.5 Calculating the silhouette for a clustering involves a reasonable amount of computation. Algorithm 11[610] outlines the steps involved. To calculate the silhouette for a clustering, 𝒞, over a dataset, 𝒟, we calculate a silhouette width for each instance, di, in 𝒟 and average these over all instances in the dataset.",
            "zh": "轮廓缩小是一种广为人知且广泛使用的性能度量，用于评估聚类满足这些条件的程度。5 计算聚类的轮廓需要进行合理的计算。算法11[610]概述了所涉及的步骤。为了计算聚类 C 在数据集 D 上的轮廓，我们计算每个实例的轮廓宽度 di，以 D 为单位，并将这些宽度平均到数据集中的所有实例。"
        }
    },
    {
        "translation": {
            "en": "Because these differences are squared in the Euclidean distance calculation, the larger maximum single difference between d12 and d17 results in a larger overall distance being calculated for this pair of instances.",
            "zh": "由于这些差值在欧几里得距离计算中是平方的，因此 d12 和 d17 之间的最大单差值越大，就会为这对实例计算出更大的总距离。"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection is a commonly used implementation of the greedy local search approach to feature selection.",
            "zh": "前向顺序选择是贪婪局部搜索方法的特征选择的常用实现。"
        }
    },
    {
        "translation": {
            "en": "where .",
            "zh": "哪里。"
        }
    },
    {
        "translation": {
            "en": "Propensity Modeling: Most business decision making would be much easier if we could predict the likelihood, or propensity, of individual customers to take particular actions.",
            "zh": "倾向建模：如果我们能够预测单个客户采取特定行动的可能性或倾向，那么大多数业务决策就会容易得多。"
        }
    },
    {
        "translation": {
            "en": "Finally, Table 10.4[616] lists the features in the mobile phone customer dataset in order of importance in defining membership of each of the three clusters found.",
            "zh": "最后，表10.4[616]列出了移动电话客户数据集中的特征，按重要性排序，以定义所发现的三个集群中每个集群的成员资格。"
        }
    },
    {
        "translation": {
            "en": "If the gap between the 3rd quartile and the maximum value is noticeably larger than the gap between the median and the 3rd quartile, this suggests that the maximum value is unusual and is likely to be an outlier.",
            "zh": "如果第 3 个四分位数和最大值之间的差距明显大于中位数和第 3 个四分位数之间的差距，则表明最大值不寻常，很可能是异常值。"
        }
    },
    {
        "translation": {
            "en": "Silhouette plots show a useful overview of a clustering, including the size of each cluster and an indication of how well each instance belongs to its cluster, which can be an easy way to identify outliers in clusterings.",
            "zh": "轮廓图显示了聚类的有用概述，包括每个聚类的大小以及每个实例与其聚类的归属程度的指示，这是识别聚类中异常值的一种简单方法。"
        }
    },
    {
        "translation": {
            "en": "The sudden braking at the end of the journey results in large negative values that slowly taper off to match the speed profile in Figure C.1(a)[765].",
            "zh": "旅程结束时的突然制动会导致较大的负值，这些负值会慢慢逐渐变细，以匹配图C.1（a）[765]中的速度曲线。"
        }
    },
    {
        "translation": {
            "en": "However, for the purposes of updating the weights on the connections into a hidden layer neuron, this distinction is irrelevant and the same δ is used to update all the weights on the connections into a neuron.",
            "zh": "然而，为了将连接上的权重更新为隐藏层神经元，这种区别是无关紧要的，并且使用相同的δ将连接上的所有权重更新为神经元。"
        }
    },
    {
        "translation": {
            "en": "By optimizing her decisions to maximize these immediate rewards, Sarah learned how to complete the overall task successfully.",
            "zh": "通过优化她的决策以最大化这些即时奖励，Sarah 学会了如何成功完成整个任务。"
        }
    },
    {
        "translation": {
            "en": "This means that a very low learning rate is required in order to ensure that the changes made to the weights at each iteration of the learning process are small enough for the algorithm to work effectively.",
            "zh": "这意味着需要非常低的学习率，以确保在学习过程的每次迭代中对权重所做的更改足够小，以使算法能够有效工作。"
        }
    },
    {
        "translation": {
            "en": "Equation (7.46)[366] requires a dot product calculation between the result of applying the basis functions to the query instance and to each of the support vectors.",
            "zh": "等式（7.46）[366]要求在将基函数应用于查询实例和每个支持向量的结果之间进行点积计算。"
        }
    },
    {
        "translation": {
            "en": "Updating weights after each training example is known as on-line, sequential, or stochastic gradient descent.",
            "zh": "在每个训练示例之后更新权重称为在线、顺序或随机梯度下降。"
        }
    },
    {
        "translation": {
            "en": "The distinction between easy learners and lazy learners is based on when the algorithm abstracts from the data.",
            "zh": "轻松学习者和懒惰学习者之间的区别取决于算法何时从数据中抽象出来。"
        }
    },
    {
        "translation": {
            "en": "If we get to a point where we have already split on all the features, we go back to the start of the feature list.",
            "zh": "如果我们已经拆分了所有功能，我们将回到功能列表的开头。"
        }
    },
    {
        "translation": {
            "en": "37. We can also use one-hot encodings to represent categorical descriptive features (see Section 7.4.3[336]).",
            "zh": "37. 我们还可以使用单热编码来表示分类描述性特征（参见第 7.4.3 节[336]）。"
        }
    },
    {
        "translation": {
            "en": "For example, if a chess-playing agent never took good early moves, the agent would never have a chance to learn how to behave in potentially game-winning situations.",
            "zh": "例如，如果一个下棋的代理人从来没有采取良好的早期行动，那么这个代理人将永远没有机会学习如何在可能赢得比赛的情况下表现。"
        }
    },
    {
        "translation": {
            "en": "7. All average class accuracies used in this section use a harmonic mean.",
            "zh": "7. 本节中使用的所有平均等级精度均使用谐波平均值。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.9",
            "zh": "图 7.9"
        }
    },
    {
        "translation": {
            "en": "Consequently, the sum of all the cells in a joint probability distribution must be 1.0.",
            "zh": "因此，联合概率分布中所有像元的总和必须为 1.0。"
        }
    },
    {
        "translation": {
            "en": "gradient descent, 168, 272, 274, 275, 319, 321, 368, 403, 541, 655",
            "zh": "梯度下降， 168， 272， 274， 275， 319， 321， 368， 403， 541， 655"
        }
    },
    {
        "translation": {
            "en": "24. Section 3.5.2[81] describes the calculation of covariance matrices. The inverse covariance matrix was calculated using the solve function from the R programming language.",
            "zh": "24. 第3.5.2节[81]描述了协方差矩阵的计算。逆协方差矩阵是使用 R 编程语言的求解函数计算的。"
        }
    },
    {
        "translation": {
            "en": "As a result, it is a good idea to run the network for a number of iterations before the generated states are recorded as samples.",
            "zh": "因此，在将生成的状态记录为样本之前，最好先运行网络进行多次迭代。"
        }
    },
    {
        "translation": {
            "en": "Typically, in the ε0 bootstrap, k is set to values greater than or equal to 200, much larger values than when k-fold cross validation is used.",
            "zh": "通常，在 ε0 引导程序中，k 设置为大于或等于 200 的值，比使用 k 折叠交叉验证时的值大得多。"
        }
    },
    {
        "translation": {
            "en": "The full set of descriptive features Ross developed, along with a short description of each, is shown in Table 12.1[692].",
            "zh": "Ross 开发的全套描述性特征以及每个特征的简短描述如表 12.1[692] 所示。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we can use feature selection29 to help reduce the number of descriptive features in a dataset to just the subset that is most useful. Before we begin our discussion of approaches to feature selection, it is useful to distinguish between different types of descriptive features.",
            "zh": "幸运的是，我们可以使用 feature selection29 来帮助将数据集中描述性特征的数量减少到最有用的子集。在我们开始讨论特征选择的方法之前，区分不同类型的描述性特征是很有用的。"
        }
    },
    {
        "translation": {
            "en": "1. ∂ℰt/∂ot: the rate of change of the error of the network at time-step t with respect to changes in the activation vector ot that was propagated to the output layer during the forward pass;",
            "zh": "1. ∂Et/∂ot：网络在时间步长t处的误差相对于在前向传递期间传播到输出层的激活向量ot的变化率;"
        }
    },
    {
        "translation": {
            "en": "DBScan, 630",
            "zh": "DBS扫描，630"
        }
    },
    {
        "translation": {
            "en": "where each Yi is one of a set of events Y1 to Yk that cover all the possible outcomes in a domain and have no overlap between them.",
            "zh": "其中，每个 Yi 都是 Y1 到 Yk 的一组事件之一，这些事件涵盖了域中所有可能的结果，并且它们之间没有重叠。"
        }
    },
    {
        "translation": {
            "en": "Two issues arise when using hold-out sampling.",
            "zh": "使用保持采样时会出现两个问题。"
        }
    },
    {
        "translation": {
            "en": "Then we introduce a well-known extension to backpropagation training known as dropout, which can help stop a network from overfitting.",
            "zh": "然后，我们引入了一个众所周知的反向传播训练扩展，称为 dropout，它可以帮助阻止网络过度拟合。"
        }
    },
    {
        "translation": {
            "en": "8.11   The calculation of the z values and activations of each neuron during the forward pass of the backpropagation algorithm.",
            "zh": "8.11 反向传播算法前向传递过程中每个神经元的z值和激活的计算。"
        }
    },
    {
        "translation": {
            "en": "0.70",
            "zh": "0.70"
        }
    },
    {
        "translation": {
            "en": "Figure 8.17",
            "zh": "图 8.17"
        }
    },
    {
        "translation": {
            "en": "gradient, 321, 368",
            "zh": "梯度， 321， 368"
        }
    },
    {
        "translation": {
            "en": "Our first task is to sort the dataset based on the ELEVATION feature.",
            "zh": "我们的第一个任务是根据 ELEVATION 特征对数据集进行排序。"
        }
    },
    {
        "translation": {
            "en": "The dotted diagonal line on the cumulative gain chart shows the performance we would expect from random guessing, and the closer the cumulative gain line is to the top left-hand corner of the chart, the better the model is performing.",
            "zh": "累积增益图上的虚线对角线显示了我们从随机猜测中预期的性能，累积增益线越靠近图表的左上角，模型的表现就越好。"
        }
    },
    {
        "translation": {
            "en": "AHC has an advantage over k-means that it does not require k to be set before the algorithm starts.",
            "zh": "AHC 与 k 均值相比具有优势，即它不需要在算法开始之前设置 k。"
        }
    },
    {
        "translation": {
            "en": "Activations",
            "zh": "激活"
        }
    },
    {
        "translation": {
            "en": "As mentioned in the chapter, ReLUs (or variants) are now the default activation function to use, although if a network architecture specifies a particular activation function, then follow the specification (e.g., LSTMs specify the use of sigmoid and tanh activations).",
            "zh": "如本章所述，ReLU（或变体）现在是默认使用的激活函数，但如果网络架构指定了特定的激活函数，则遵循规范（例如，LSTM 指定使用 sigmoid 和 tanh 激活）。"
        }
    },
    {
        "translation": {
            "en": "8.30   Samples of the handwritten digit images from the MNIST dataset.",
            "zh": "8.30 来自MNIST数据集的手写数字图像样本。"
        }
    },
    {
        "translation": {
            "en": "The set of weight parameters for the mixture must sum to 1.",
            "zh": "混合物的重量参数集总和必须为 1。"
        }
    },
    {
        "translation": {
            "en": "(e) There are a lot of zero entries in the spam bag-of-words dataset. This is indicative of sparse data and is typical for text analytics. Cosine similarity is often a good choice when dealing with sparse non-binary data. What target level would a 3-NN model using cosine similarity return for the query?",
            "zh": "（e） 垃圾邮件词袋数据集中有很多零条目。这表示数据稀疏，是文本分析的典型特征。在处理稀疏的非二进制数据时，余弦相似性通常是一个不错的选择。使用余弦相似度的 3-NN 模型会为查询返回什么目标级别？"
        }
    },
    {
        "translation": {
            "en": "10.17   The process of using an unsupervised auto-encoder network to generate a feature representation used to train a supervised model.",
            "zh": "10.17 使用无监督自动编码器网络生成用于训练监督模型的特征表示的过程。"
        }
    },
    {
        "translation": {
            "en": "population parameters, 751",
            "zh": "种群参数，751"
        }
    },
    {
        "translation": {
            "en": "(a) Design a state representation for the car agent in this scenario. How many states will exist in the representation?",
            "zh": "（a） 在此方案中为汽车代理设计状态表示。表示形式中将存在多少个州？"
        }
    },
    {
        "translation": {
            "en": "5.12   (a) The feature space defined by the SALARY and AGE features in Table 5.5[204]; and (b) the normalized SALARY and AGE feature space based on the normalized data in Table 5.7[208].",
            "zh": "5.12 （a） 表5.5[204]中SALARY 和 AGE 特征定义的特征空间;（b）基于表5.7[208]中归一化数据的归一化SALAW和AGE特征空间。"
        }
    },
    {
        "translation": {
            "en": "10. In this simplified version of Blackjack, the complication of the player having to choose a wager for each hand is ignored.",
            "zh": "10. 在这个简化版的二十一点中，玩家必须为每手牌选择赌注的复杂性被忽略了。"
        }
    },
    {
        "translation": {
            "en": "hits, 538",
            "zh": "点击数，538"
        }
    },
    {
        "translation": {
            "en": "A little investigation revealed that this minimum value arises from d3 in Table 3.2[56].",
            "zh": "稍加调查后发现，该最小值来自表3.2中的d3[56]。"
        }
    },
    {
        "translation": {
            "en": "Properly constructed Bayesian networks are relatively powerful models that can capture the interactions between descriptive features in determining a prediction.",
            "zh": "正确构建的贝叶斯网络是相对强大的模型，可以在确定预测时捕获描述性特征之间的相互作用。"
        }
    },
    {
        "translation": {
            "en": "Stratified sampling is a sampling method that ensures that the relative frequencies of the levels of a specific stratification feature are maintained in the sampled dataset.",
            "zh": "分层抽样是一种抽样方法，可确保在抽样数据集中保持特定分层要素水平的相对频率。"
        }
    },
    {
        "translation": {
            "en": "An event is then an experiment whose outcome fixes the values of the random variables.",
            "zh": "然后，事件是一个实验，其结果固定随机变量的值。"
        }
    },
    {
        "translation": {
            "en": "5. We return to this discussion in Section 12.5[698] and Section 13.4.1[719].",
            "zh": "5. 我们回到第 12.5 节[698] 和第 13.4.1 节[719] 中的讨论。"
        }
    },
    {
        "translation": {
            "en": "The formal definition of Bayes’ Theorem is",
            "zh": "贝叶斯定理的正式定义是"
        }
    },
    {
        "translation": {
            "en": "One of the key skills the novice surfer has to learn is how to successfully catch a wave.",
            "zh": "新手冲浪者必须学习的关键技能之一是如何成功捕捉海浪。"
        }
    },
    {
        "translation": {
            "en": "If the index is a whole number, we take the value at that position in the ordered list of values as the ith percentile.",
            "zh": "如果索引是整数，则我们将有序列值列表中该位置的值作为第 i 个百分位数。"
        }
    },
    {
        "translation": {
            "en": "distance measure, 599, 601, 618",
            "zh": "距离测量， 599， 601， 618"
        }
    },
    {
        "translation": {
            "en": "The calculations in Table 4.5[138] show that STREAM has a higher information gain than SLOPE and so is the best feature with which to split 7.",
            "zh": "表4.5[138]中的计算表明，STREAM的信息增益高于SLOPE，因此是分割7的最佳特征。"
        }
    },
    {
        "translation": {
            "en": "The third way in which a data quality issue can arise due to an irregular cardinality is if a categorical feature has a much higher cardinality than we would expect given the definition of the feature.",
            "zh": "由于不规则基数而导致数据质量问题的第三种方式是，如果分类特征的基数比我们给定的特征定义预期的要高得多。"
        }
    },
    {
        "translation": {
            "en": "(a) The final k-d tree generated for the dataset in Table 5.4[191]; and (b) the partitioning of the feature space defined by this k-d tree.",
            "zh": "（a） 为表5.4[191]中的数据集生成的最终k-d树;（b）由该k-d树定义的特征空间的分区。"
        }
    },
    {
        "translation": {
            "en": "Network Error",
            "zh": "网络错误"
        }
    },
    {
        "translation": {
            "en": "The table below lists the bag-of-words representation for the following five emails and a target feature, SPAM, whether they are spam emails or genuine emails:",
            "zh": "下表列出了以下五封电子邮件和目标功能“垃圾邮件”的词袋表示形式，无论它们是垃圾邮件还是正版电子邮件："
        }
    },
    {
        "translation": {
            "en": "Cumulatively, however, these differences will lead to quite different behavior.",
            "zh": "然而，累积起来，这些差异将导致完全不同的行为。"
        }
    },
    {
        "translation": {
            "en": "electroencephalography pattern recognition, 353",
            "zh": "脑电图模式识别，353"
        }
    },
    {
        "translation": {
            "en": "normal distribution, 59, 61, 71, 78, 269, 270, 557",
            "zh": "正态分布， 59， 61， 71， 78， 269， 270， 557"
        }
    },
    {
        "translation": {
            "en": "8.4.5.1 Local receptive fields and filters The concept of local receptive field comes from research on visual perception in cats.",
            "zh": "8.4.5.1 局部感受野和滤波器 局部感受野的概念来自对猫视觉知觉的研究。"
        }
    },
    {
        "translation": {
            "en": "39. This example is inspired by the research reported in Palaniappan and Awang (2008).",
            "zh": "39. 这个例子的灵感来自Palaniappan和Awang（2008年）报告的研究。"
        }
    },
    {
        "translation": {
            "en": "1. Is it a man?",
            "zh": "1.是男人吗？"
        }
    },
    {
        "translation": {
            "en": "Although this is not unheard of (particularly in cases like the SDSS project in which data is generated in a fully automated process), it is very unusual.",
            "zh": "虽然这并非闻所未闻（特别是在像SDSS项目这样的情况下，数据是在完全自动化的过程中生成的），但这是非常不寻常的。"
        }
    },
    {
        "translation": {
            "en": "parsimony, 646",
            "zh": "吝啬，646"
        }
    },
    {
        "translation": {
            "en": "The height of each bar indicates the frequency of the associated level (readers will most likely already be familiar with the bar plot).",
            "zh": "每个柱的高度表示相关水平的频率（读者很可能已经熟悉柱形图）。"
        }
    },
    {
        "translation": {
            "en": "Once we have discretized the data using binning, we need to record the raw continuous feature thresholds between the bins.",
            "zh": "一旦我们使用分箱对数据进行离散化，我们就需要记录分箱之间的原始连续特征阈值。"
        }
    },
    {
        "translation": {
            "en": "However, to train the network we must backpropagate this loss through the network.",
            "zh": "但是，要训练网络，我们必须通过网络反向传播这种损失。"
        }
    },
    {
        "translation": {
            "en": "4.2.3   Information Gain",
            "zh": "4.2.3 信息增益"
        }
    },
    {
        "translation": {
            "en": "Note that neurons are often referred to as units, and they are distinguished by the type of activation function they use.",
            "zh": "请注意，神经元通常被称为单位，它们通过它们使用的激活函数类型来区分。"
        }
    },
    {
        "translation": {
            "en": "This tree is shown in Figure 12.4[698], and the lack of pruning is obvious in its complexity.",
            "zh": "这棵树如图 12.4[698] 所示，其复杂性明显缺乏修剪。"
        }
    },
    {
        "translation": {
            "en": "backpropagation of error, 387, 403, 404, 624, 731",
            "zh": "误差反向传播， 387， 403， 404， 624， 731"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed for the revenue commission, outline the type of data that would be required.",
            "zh": "（b） 对于您为收入委员会提出的每个分析解决方案，概述所需的数据类型。"
        }
    },
    {
        "translation": {
            "en": "(c) The ensemble contains 21 independent models, all of which have an error rate of 0.49.",
            "zh": "（c） 该集合包含21个独立模型，所有模型的错误率为0.49。"
        }
    },
    {
        "translation": {
            "en": "As is the case in most predictive data analytics projects, AT did not approach Ross with a well-specified predictive analytics solution.",
            "zh": "与大多数预测性数据分析项目一样，AT没有向Ross提供明确的预测分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "Although internal measures such as the silhouette and external measures calculated against a proxy ground truth are useful in measuring how well a clustering matches an ideal expectation, they do not tell analysts anything about what has been found in the clustering, or whether or not the clustering will be useful for a particular task.",
            "zh": "尽管内部度量（如轮廓）和根据代理实况计算的外部度量对于衡量聚类与理想期望的匹配程度很有用，但它们不会告诉分析人员任何关于聚类中发现的内容，或者聚类是否对特定任务有用。"
        }
    },
    {
        "translation": {
            "en": "If the domain is not complex, or if the available data is small, or if the available hardware is not powerful enough for deep learning, then it is likely that you will have more success by exploring whether an alternative machine learning model can be used to develop a viable solution for the task.",
            "zh": "如果域不复杂，或者可用数据很小，或者可用的硬件不够强大，无法进行深度学习，那么通过探索是否可以使用替代机器学习模型来为任务开发可行的解决方案，您可能会取得更大的成功。"
        }
    },
    {
        "translation": {
            "en": "Decision Trees",
            "zh": "决策树"
        }
    },
    {
        "translation": {
            "en": "Table B.2",
            "zh": "表B.2"
        }
    },
    {
        "translation": {
            "en": "1. Other types of machine learning include unsupervised learning, semi-supervised learning, and reinforcement learning. In this book, however, we focus mainly on supervised machine learning and in most of the book use the terms supervised machine learning and machine learning interchangeably. Chapters 10[597] and 11[637] provide overviews of unsupervised learning and reinforcement learning, respectively.",
            "zh": "1. 其他类型的机器学习包括无监督学习、半监督学习和强化学习。然而，在本书中，我们主要关注监督机器学习，并且在本书的大部分内容中，监督机器学习和机器学习这两个术语可以互换使用。第10章[597]和第11章[637]分别概述了无监督学习和强化学习。"
        }
    },
    {
        "translation": {
            "en": "The first goal is to fully understand the characteristics of the data in the ABT.",
            "zh": "第一个目标是充分了解 ABT 中数据的特征。"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM, 16",
            "zh": "CRISP-DM，16"
        }
    },
    {
        "translation": {
            "en": "6.4 Extensions and Variations",
            "zh": "6.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Recall from Chapter 7[311] that w[0] is the equivalent of the y-intercept in the equation of the line from high school geometry (see (7.2.1)[313]), and d[0] is a dummy descriptive feature used for notational convenience and is always equal to 1 (see (7.9)[320]).",
            "zh": "回想一下第7章[311]，w[0]等价于高中几何中直线方程中的y截距（参见（7.2.1）[313]），而d[0]是一个用于符号方便的虚拟描述特征，并且始终等于1（参见（7.9）[320]）。"
        }
    },
    {
        "translation": {
            "en": "We divide by n− 1 so that the sample variance is an unbiased estimate of the population variance.",
            "zh": "我们除以 n− 1，使样本方差是总体方差的无偏估计值。"
        }
    },
    {
        "translation": {
            "en": "The techniques described in Section 10.4.2[607] for evaluating clusterings can be used here to set the best value for k.",
            "zh": "第 10.4.2 节[607] 中描述的用于评估聚类的技术可用于设置 k 的最佳值。"
        }
    },
    {
        "translation": {
            "en": "(d) Generate a cumulative gain chart for each model.",
            "zh": "（d） 为每个模型生成累积增益图。"
        }
    },
    {
        "translation": {
            "en": "For each of these layers we calculate the error gradient with respect to the layer’s input (hxt) by multiplying the δ values for the neurons in the layer by the weights the neuron uses.",
            "zh": "对于这些层中的每一个，我们通过将层中神经元的δ值乘以神经元使用的权重来计算相对于层输入 （hxt） 的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "6.6   Illustration of how a mixture of Gaussians model is composed of a number of normal distributions. The curve plotted using a solid line is the mixture of Gaussians density curve, created using an appropriately weighted summation of the three normal curves, plotted using dashed and dotted lines.",
            "zh": "6.6 说明高斯模型的混合如何由许多正态分布组成。使用实线绘制的曲线是高斯密度曲线的混合，使用使用虚线和虚线绘制的三条正态曲线的适当加权求和创建。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.7[612] shows the silhouette plot for the clustering of the mobile phone customer dataset.",
            "zh": "图10.7[612]显示了移动电话客户数据集聚类的轮廓图。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons are ReLUs, that the input to the network is Neuron 1 = 0.2, and that the desired output for this input is 0.7:",
            "zh": "（b） 假设处理神经元是 ReLU，网络的输入是神经元 1 = 0.2，并且该输入的期望输出是 0.7："
        }
    },
    {
        "translation": {
            "en": "SOCIOECONOMIC BAND B",
            "zh": "社会经济等级 B"
        }
    },
    {
        "translation": {
            "en": "The structure of the dataset required for this task would contain one row per galaxy, and each row would include a set of descriptive features describing the characteristics of that galaxy object and a target feature indicating the morphological category of the galaxy object.",
            "zh": "这项任务所需的数据集结构将包含每个星系一行，每行将包括一组描述该星系天体特征的描述性特征和一个指示星系天体形态类别的目标特征。"
        }
    },
    {
        "translation": {
            "en": "It is primarily this path of error gradients flow (rather than the backpropagated hidden state ∂ℰt/∂ht−1 gradients) that enable LSTMs to learn long-distance dependencies",
            "zh": "主要是这种误差梯度流路径（而不是反向传播的隐藏状态∂Et/∂ht−1梯度）使LSTM能够学习长距离依赖关系"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons are ReLUs, that the input to the network is Neuron 1 = 0.5 and that the desired output for this input is 0.9",
            "zh": "（b） 假设处理神经元是 ReLU，网络的输入是神经元 1 = 0.5，并且该输入的期望输出是 0.9"
        }
    },
    {
        "translation": {
            "en": "where f is a feature and levels(f) is the set of levels in the domain of the feature. This means that we have a total probability mass of 1.0 that is shared out between the different assignments of a level to a feature based on their relative frequency. Smoothing involves taking some of the probability mass from the assignments with probability greater than average and spreading it across the probabilities that are below average, or even equal to zero.",
            "zh": "其中 f 是特征，levels（f） 是特征域中的一组级别。这意味着我们有一个总概率质量 1.0，该概率质量根据它们的相对频率在级别对特征的不同分配之间共享。平滑涉及从概率大于平均值的赋值中获取一些概率质量，并将其分布在低于平均值甚至等于零的概率中。"
        }
    },
    {
        "translation": {
            "en": "11.5   (a)–(c) The evolution of the entries in the action-value table over episodes of Q-learning off-policy temporal-difference learning across the grid world. (d) The cumulative reward earned from each episode. (e) An illustration of the target policy learned by the agent after 350 episodes. (f) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "11.5 （a）–（c） 行动-价值表中条目在整个网格世界的 Q-learning 政策外时间差异学习事件中的演变。（d） 每集的累积奖励。（e） 代理人在350集后了解到的目标政策的说明。（f） 当贪婪地遵循目标策略时，代理从开始状态到目标状态的路径。"
        }
    },
    {
        "translation": {
            "en": "The Claim Types subconcept of the Claim History is also time dependent.",
            "zh": "“声明历史记录”的“声明类型”子概念也与时间有关。"
        }
    },
    {
        "translation": {
            "en": "A pseudocode description of the deep Q network algorithm is given in Algorithm 16[673].",
            "zh": "算法16[673]给出了深度Q网络算法的伪代码描述。"
        }
    },
    {
        "translation": {
            "en": "independent features, 83",
            "zh": "独立功能， 83"
        }
    },
    {
        "translation": {
            "en": "PREDICTIVE DATA ANALYTICS",
            "zh": "预测性数据分析"
        }
    },
    {
        "translation": {
            "en": "Control Group",
            "zh": "控制组"
        }
    },
    {
        "translation": {
            "en": "An action-value table for an agent trained to play the card game TwentyTwos (the simplified version of Blackjack described in Section 11.2.3[643]).",
            "zh": "一个动作值表，供受过训练的代理玩纸牌游戏 TwentyTwos（第 11.2.3 节中描述的 Blackjack 的简化版本）[643]。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.32",
            "zh": "图 8.32"
        }
    },
    {
        "translation": {
            "en": "In both these cases we should subtract ∂ℰ/∂wi,k from wi,k. The same conclusion can be reached via similar reasoning for the case ai < ti. Hence we update the weights as follows:",
            "zh": "在这两种情况下，我们都应该从 wi，k 中减去 ∂E/∂wi，k。通过对案例的类似推理，可以得出相同的结论 ai < ti.因此，我们更新权重如下："
        }
    },
    {
        "translation": {
            "en": "The fact that a weight matrix may be involved multiple times in the generation of an output means that backpropagating the error for an output can result in multiple error gradients being calculated for a weight: one error gradient for each time the weight was involved in generating the output.",
            "zh": "权重矩阵在输出生成过程中可能涉及多个，这意味着反向传播输出的误差可能会导致为一个权重计算多个误差梯度：每次生成输出时涉及权重时，都会计算一个误差梯度。"
        }
    },
    {
        "translation": {
            "en": "In this example d15 and d8 are separated by a distance of just 0.06 and are combined together into the cluster 10.",
            "zh": "在此示例中，d15 和 d8 相距仅 0.06，并组合成簇 10。"
        }
    },
    {
        "translation": {
            "en": "Figures 10.3(e)[602] and 10.3(f)[602] show the remaining steps of the k-means clustering process.",
            "zh": "图10.3（e）[602]和图10.3（f）[602]显示了k-means聚类过程的其余步骤。"
        }
    },
    {
        "translation": {
            "en": "2. P(q[1],…,q[m]), the joint probability of the descriptive features of a query instance taking a specific set of values",
            "zh": "2. P（q[1],...,q[m]），查询实例的描述性特征的联合概率，采用一组特定的值"
        }
    },
    {
        "translation": {
            "en": "6.14   The probabilities, from Table 6.13[281], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, and AB = 759.07, and the calculation of the scores for each candidate prediction.",
            "zh": "6.14 从表6.13[281]可以看出，朴素贝叶斯预测模型对CH = paid、GC = guarantor、ACC = free和AB = 759.07的查询进行预测所需的概率，以及计算每个候选预测的分数。"
        }
    },
    {
        "translation": {
            "en": "Again, following the ε-greedy policy a random number is generated, 0.073, which this time is below ε, and so a random action from those available from state 0-2 is selected.",
            "zh": "同样，按照ε贪婪策略，将生成一个随机数 0.073，这次该随机数低于 ε，因此从状态 0-2 中可用的随机操作中选择一个随机操作。"
        }
    },
    {
        "translation": {
            "en": "10   Beyond Prediction: Unsupervised Learning",
            "zh": "10 超越预测：无监督学习"
        }
    },
    {
        "translation": {
            "en": "The next stage is to backpropagate the δs for the neurons in the network.",
            "zh": "下一阶段是反向传播网络中神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "The following table shows the information gain calculated when each descriptive feature is used to predict the membership of a single cluster versus the rest of the population.",
            "zh": "下表显示了当使用每个描述性特征来预测单个聚类与其余聚类的成员时计算的信息增益。"
        }
    },
    {
        "translation": {
            "en": "5   Similarity-Based Learning",
            "zh": "5 基于相似性的学习"
        }
    },
    {
        "translation": {
            "en": "5.2.1   Feature Space",
            "zh": "5.2.1 功能空间"
        }
    },
    {
        "translation": {
            "en": "To fit the normal distribution to the set of instances where FRAUD = false, we compute the sample mean and sample standard deviation for the ACCOUNT BALANCE feature for this set of instances and set the parameters of the normal distribution to these values.",
            "zh": "为了将正态分布拟合到 FRAUD = false 的实例集，我们计算了这组实例的 ACCOUNT BALANCE 特征的样本均值和样本标准差，并将正态分布的参数设置为这些值。"
        }
    },
    {
        "translation": {
            "en": "For each known animal, you count how many features it has in common with the unknown animal.",
            "zh": "对于每种已知动物，您可以计算它与未知动物有多少共同点。"
        }
    },
    {
        "translation": {
            "en": "augment data, 599, 629",
            "zh": "增强数据，599,629"
        }
    },
    {
        "translation": {
            "en": "credit scoring, 538, 553, 563",
            "zh": "信用评分，538、553、563"
        }
    },
    {
        "translation": {
            "en": "or slightly more succinctly:",
            "zh": "或者更简洁一点："
        }
    },
    {
        "translation": {
            "en": "5.4.2 Efficient Memory Search",
            "zh": "5.4.2 高效内存搜索"
        }
    },
    {
        "translation": {
            "en": "As a result, the model is unable to return a prediction for this query.",
            "zh": "因此，模型无法返回此查询的预测。"
        }
    },
    {
        "translation": {
            "en": "A dataset is composed of n instances, (d1, t1) to (dn, tn), where d is a set of m descriptive features, and t is a target feature.",
            "zh": "数据集由 n 个实例 （d1， t1） 到 （dn， tn） 组成，其中 d 是一组 m 描述性特征，t 是目标特征。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the term ∂ℰ/∂ak connects the activation of the neuron ak to the output error of the network ℰ.",
            "zh": "这样做的原因是术语 ∂E/∂ak 将神经元 ak 的激活与网络 E 的输出错误联系起来。"
        }
    },
    {
        "translation": {
            "en": "If you lie too far toward the back of the board, the board will sink and create so much drag that even big waves will pass by, leaving you behind.",
            "zh": "如果你离冲浪板的后面太远，冲浪板会下沉并产生很大的阻力，即使是大浪也会经过，把你甩在后面。"
        }
    },
    {
        "translation": {
            "en": "The big idea in deep learning is to develop computational models that are inspired by the structure and operations of the human brain.",
            "zh": "深度学习的主要理念是开发受人脑结构和操作启发的计算模型。"
        }
    },
    {
        "translation": {
            "en": "Finally, a feature is included that expresses the variety of different claim types made by the claimant in the past.",
            "zh": "最后，还包括一个功能，表示索赔人过去提出的各种不同索赔类型。"
        }
    },
    {
        "translation": {
            "en": "DEVFLUX_U/G/R/I/Z",
            "zh": "DEVFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The next step in the algorithm is to calculate the average distance from d1 to each member of the other two clusters, 𝒞2 and 𝒞3—the inter-cluster distances. The distances from d1 to the members of 𝒞2 are",
            "zh": "该算法的下一步是计算从 d1 到其他两个聚类 C2 和 C3 的每个成员的平均距离，即聚类间距离。从 d1 到 C2 成员的距离为"
        }
    },
    {
        "translation": {
            "en": "All the examples that we have looked at so far have been regression problems. To create a neural network that can predict a multi-level categorical feature, we make three adjustments:",
            "zh": "到目前为止，我们看到的所有示例都是回归问题。为了创建一个可以预测多级分类特征的神经网络，我们进行了三个调整："
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, co-absences aren’t that meaningful.",
            "zh": "然而，有时，共同缺席并没有那么有意义。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.2",
            "zh": "图 4.2"
        }
    },
    {
        "translation": {
            "en": "Looking at the decision trees in Figures 4.4(a)[122] and 4.4(b)[122], we notice that the tree in Figure 4.4(a)[122] performs tests on two features in order to make a prediction, whereas the decision tree in Figure 4.4(b)[122] needs to test only the value of one feature.",
            "zh": "查看图4.4（a）[122]和图4.4（b）[122]中的决策树，我们注意到图4.4（a）[122]中的决策树对两个特征进行测试以做出预测，而图4.4（b）[122]中的决策树只需要测试一个特征的值。"
        }
    },
    {
        "translation": {
            "en": "In the remainder of this section, we examine this in some detail.",
            "zh": "在本节的其余部分，我们将对此进行一些详细的研究。"
        }
    },
    {
        "translation": {
            "en": "Following this action it was updated as follows:",
            "zh": "在此操作之后，它已更新如下："
        }
    },
    {
        "translation": {
            "en": "11.1 Big Idea",
            "zh": "11.1 大创意"
        }
    },
    {
        "translation": {
            "en": "For example, the density histograms in Figure 9.10[558] show the distributions of prediction scores for the spam and ham target levels based on the data in Table 9.11[557].",
            "zh": "例如，图 9.10[558] 中的密度直方图显示了基于表 9.11[557] 中的数据的垃圾邮件和火腿目标水平的预测分数分布。"
        }
    },
    {
        "translation": {
            "en": "In Section 7.3.3[328] we illustrated the impact of a learning rate parameter on the gradient descent algorithm.",
            "zh": "在第 7.3.3 节[328]中，我们说明了学习率参数对梯度下降算法的影响。"
        }
    },
    {
        "translation": {
            "en": "confusion matrix, 537, 553, 572, 591",
            "zh": "混淆矩阵， 537， 553， 572， 591"
        }
    },
    {
        "translation": {
            "en": "Reagen, Brandon, Robert Adolf, Paul Whatmough, Gu-Yeon Wei, and David Brooks. 2017. Deep learning for computer architects. Morgan and Claypool.",
            "zh": "里根、布兰登、罗伯特·阿道夫、保罗·沃特莫、魏谷妍和大卫·布鲁克斯。2017. 面向计算机架构师的深度学习.摩根和克莱普尔。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.2",
            "zh": "图 6.2"
        }
    },
    {
        "translation": {
            "en": "Anything that the analyst can imagine can be implemented.",
            "zh": "分析师可以想象到的任何事情都可以实施。"
        }
    },
    {
        "translation": {
            "en": "Samples of the handwritten digit images from the MNIST dataset. Image attribution: Josef Steppan, used here under the Creative Commons Attribution-Share Alike 4.0 International license https://creativecommons.org/licenses/by-sa/4.0) and was sourced via Wikimedia Commons https://commons.wikimedia.org/wiki/File:MnistExamples.png.",
            "zh": "来自MNIST数据集的手写数字图像样本。图片归属：约瑟夫·斯蒂芬潘（Josef Steppan），此处根据知识共享署名-相同方式共享4.0国际许可 https://creativecommons.org/licenses/by-sa/4.0）使用，来源于维基共享资源 https://commons.wikimedia.org/wiki/File:MnistExamples.png。"
        }
    },
    {
        "translation": {
            "en": "If we treat the evidence events as conditionally independent given the target feature, however, then we can factorize the evidence into its component events and calculate probabilities for each of these events separately.",
            "zh": "但是，如果我们在给定目标特征的情况下将证据事件视为条件独立的事件，那么我们可以将证据分解为其组件事件，并分别计算每个事件的概率。"
        }
    },
    {
        "translation": {
            "en": "where W are the network weights; and ti, the target feature value, is defined as the actual return earned from taking an action. We can calculate a gradient of this function",
            "zh": "其中 W 是网络权重;而 Ti，即目标特征值，定义为通过采取行动获得的实际回报。我们可以计算这个函数的梯度"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic is calculated by determining the maximum difference between the cumulative probability distributions for the positive and negative target levels. This can be given formally as",
            "zh": "K-S 统计量是通过确定正目标水平和负目标水平的累积概率分布之间的最大差值来计算的。这可以正式给出"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10",
            "zh": "图 5.10"
        }
    },
    {
        "translation": {
            "en": "DEVFLUXIVAR_U/G/R/I/Z",
            "zh": "DEVFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This can help indicate which descriptive features might be useful for predicting a target feature and help find pairs of descriptive features that are closely related.",
            "zh": "这有助于指示哪些描述性特征可能有助于预测目标特征，并帮助找到密切相关的描述性特征对。"
        }
    },
    {
        "translation": {
            "en": "0.44",
            "zh": "0.44"
        }
    },
    {
        "translation": {
            "en": "Before presenting the formal version of this, it is worth stating the intuition.",
            "zh": "在介绍正式版本之前，值得说明一下直觉。"
        }
    },
    {
        "translation": {
            "en": "Cohen’s kappa, 726",
            "zh": "科恩的河童，726"
        }
    },
    {
        "translation": {
            "en": "Having used the measures of central tendency to describe where our data is centered, we will now turn our attention to the variation in our data.",
            "zh": "在使用集中趋势的度量来描述我们的数据中心位置之后，我们现在将注意力转向数据的变化。"
        }
    },
    {
        "translation": {
            "en": "However, Chapter 5 (Similarity-Based Learning) and/or 6 (Probability-Based Learning) could be used instead.",
            "zh": "但是，可以使用第 5 章（基于相似性的学习）和/或第 6 章（基于概率的学习）来代替。"
        }
    },
    {
        "translation": {
            "en": "Much of the focus of machine learning is on developing the single most accurate prediction model possible for a given task. The techniques we introduce in this section take a slightly different approach. Rather than creating a single model, they generate a set of models and then make predictions by aggregating the outputs of these models. A prediction model that is composed of a set of models is called a model ensemble.",
            "zh": "机器学习的大部分重点是为给定任务开发最准确的预测模型。我们在本节中介绍的技术采用的方法略有不同。他们不是创建单个模型，而是生成一组模型，然后通过聚合这些模型的输出进行预测。由一组模型组成的预测模型称为模型集成。"
        }
    },
    {
        "translation": {
            "en": "On Line 8[420] the bias inputs vector and the matrix of activations from the previous layer Al−1 are vertically concatenated so that the bias inputs are now stored in the first row of Al−1; we use the notation [v;A] to represent the vertical concatenation of the vector/matrix v and A.",
            "zh": "在第 8 行[420]上，偏置输入矢量和来自前一层 Al−1 的激活矩阵垂直连接，因此偏置输入现在存储在 Al−1 的第一行中;我们使用符号 [v;A] 来表示向量/矩阵 v 和 A 的垂直连接。"
        }
    },
    {
        "translation": {
            "en": "5.1   Matching animals you remember to the features of the unknown animal described by the sailor.",
            "zh": "5.1 将你记得的动物与水手描述的未知动物的特征相匹配。"
        }
    },
    {
        "translation": {
            "en": "A partial derivative (denoted by the symbol ∂) of a function of more than one variable is its derivative with respect to one of those variables with the other variables held constant.",
            "zh": "一个以上变量的函数的偏导数（用符号 ∂ 表示）是其相对于其中一个变量的导数，而其他变量保持不变。"
        }
    },
    {
        "translation": {
            "en": "Dunn, Joseph C. 1974. Well-separated clusters and optimal fuzzy partitions. Journal of Cybernetics 4 (1): 95–104.",
            "zh": "邓恩，约瑟夫 C. 1974 年。分离良好的聚类和最佳的模糊分区。控制论杂志4（1）：95-104。"
        }
    },
    {
        "translation": {
            "en": "The first iteration of training is done on the first mini-batch in the sequence, the second iteration on the second mini-batch, and so on until the epoch is completed.",
            "zh": "训练的第一次迭代在序列中的第一个小批量上完成，第二次迭代在第二个小批量上完成，依此类推，直到纪元完成。"
        }
    },
    {
        "translation": {
            "en": "Instead, the best policy for Conor to take for learning is to balance exploration and exploitation.",
            "zh": "相反，康纳学习的最佳策略是平衡探索和开发。"
        }
    },
    {
        "translation": {
            "en": "Consequently, both the trees are attempting to generalize beyond the dataset.",
            "zh": "因此，这两棵树都试图在数据集之外进行泛化。"
        }
    },
    {
        "translation": {
            "en": "The training phase needed to build a nearest neighbor model is very simple and just involves storing all the training instances in memory.",
            "zh": "构建最近邻模型所需的训练阶段非常简单，只需将所有训练实例存储在内存中即可。"
        }
    },
    {
        "translation": {
            "en": "inverse covariance matrix, 219, 242",
            "zh": "逆协方差矩阵， 219， 242"
        }
    },
    {
        "translation": {
            "en": "In this clustering d1 is a member of 𝒞1. The first step is calculating the silhouette value for d1 is to calculate a(i), the average distance between d1 and the other members of cluster 𝒞1. The distance from d1 to each other member of 𝒞1 is",
            "zh": "在此聚类中，d1 是 C1 的成员。第一步是计算 d1 的轮廓值，即计算 a（i），即 d1 与聚类 C1 的其他成员之间的平均距离。从 d1 到 C1 的每个其他成员的距离为"
        }
    },
    {
        "translation": {
            "en": "Note that all the neurons in this network are ReLU, so each of these activations was calculated in each neuron by passing the result of the weighted sum calculation through a rectified linear activation function (similar to the calculation listed in Equation (8.102)[494]).",
            "zh": "请注意，该网络中的所有神经元都是 ReLU，因此每个神经元中的每一个激活都是通过通过修正线性激活函数传递加权和计算结果来计算的（类似于公式 （8.102）[494] 中列出的计算）。"
        }
    },
    {
        "translation": {
            "en": "We can demonstrate how this retrieval algorithm works by showing how the algorithm finds the nearest neighbor for a query instance with SPEED = 6.00 and AGILITY = 3.50.",
            "zh": "我们可以通过展示算法如何为 SPEED = 6.00 和 AGILITY = 3.50 的查询实例查找最近邻来演示此检索算法的工作原理。"
        }
    },
    {
        "translation": {
            "en": "It is important that analytics professionals have a basic grasp of the work their scientific partners are undertaking so that they can converse fluently with them.",
            "zh": "重要的是，分析专业人员必须对他们的科学合作伙伴正在开展的工作有一个基本的了解，以便他们能够与他们流利地交谈。"
        }
    },
    {
        "translation": {
            "en": "All instances are normalized so as to lie on a hypersphere of radius 1.0 with its center at the origin of the feature space.",
            "zh": "所有实例都经过归一化，以便位于半径为 1.0 的超球体上，其中心位于特征空间的原点。"
        }
    },
    {
        "translation": {
            "en": "In a simple random sample, each item in the population is equally likely to make it into the sample.",
            "zh": "在简单的随机样本中，总体中的每个项目进入样本的可能性都相等。"
        }
    },
    {
        "translation": {
            "en": "Two different networks are used in the training process: an action-value behavior network that is used to predict the values of actions for making decisions and an action-value target network that is used to predict the value of taking subsequent actions in subsequent states when generating target feature values.",
            "zh": "训练过程中使用了两种不同的网络：一种是用于预测用于做出决策的动作值的动作-价值行为网络，另一种是用于预测生成目标特征值时在后续状态下采取后续动作的价值的动作-价值目标网络。"
        }
    },
    {
        "translation": {
            "en": "We write the model trained at the first iteration of gradient boosting",
            "zh": "我们编写了在梯度提升的第一次迭代中训练的模型"
        }
    },
    {
        "translation": {
            "en": "Samet, Hanan. 1990. The design and analysis of spatial data structures, Vol. 199. Addison-Wesley.",
            "zh": "萨梅特，哈南。1990. 空间数据结构的设计与分析， Vol. 199.艾迪生-卫斯理。"
        }
    },
    {
        "translation": {
            "en": "This gives a series of discrete steps that make up an episode",
            "zh": "这给出了构成剧集的一系列离散步骤"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the grass growth dataset from Table 7.9[351].",
            "zh": "表7.9[351]中草生长数据集的梯度下降过程中开发的模型选择。"
        }
    },
    {
        "translation": {
            "en": "The problem here is that our dataset is not large enough to be truly representative of the meningitis diagnosis scenario, and our model is overfitting to the training data.",
            "zh": "这里的问题是，我们的数据集不够大，无法真正代表脑膜炎诊断场景，而且我们的模型对训练数据过度拟合。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10(a)[340] shows a scatter plot of this dataset in which we can see that there is a good separation between the two types of generator.",
            "zh": "图7.10（a）[340]显示了该数据集的散点图，从中我们可以看到两种类型的生成器之间存在良好的分离。"
        }
    },
    {
        "translation": {
            "en": "You ask him to describe the animal to you, and he explains that he didn’t see it very well because, as he approached it, the animal growled at him, so he didn’t approach too closely.",
            "zh": "你让他向你描述这只动物，他解释说他看得不是很清楚，因为当他接近它时，动物对他咆哮，所以他没有靠近太近。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.2(a)[644] shows these states and how an individual can move between them.7",
            "zh": "图11.2（a）[644]显示了这些状态以及个体如何在它们之间移动7。"
        }
    },
    {
        "translation": {
            "en": "(b) What target level will a naive Bayes model predict for the following query document: “christmas family fun”?",
            "zh": "（b） 朴素贝叶斯模型将预测以下查询文档的目标水平：“圣诞家庭乐趣”？"
        }
    },
    {
        "translation": {
            "en": "Mnih, Volodymyr, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.",
            "zh": "Mnih、Volodymyr、Koray Kavukcuoglu、David Silver、Alex Graves、Ioannis Antonoglou、Daan Wierstra 和 Martin Riedmiller。2013. 用深度强化学习玩雅达利.arXiv 预印本 arXiv：1312.5602。"
        }
    },
    {
        "translation": {
            "en": "As a result, the variance of the z values across the neurons in HL1 is var(Z(HL1)) = 2 × 0.04 = 0.08 (i.e., σ ≈ 0.283), and this is then scaled by 100 × 0.04 = 4 at each of the other hidden layers in the network.",
            "zh": "因此，HL1 中神经元的 z 值方差为 var（Z（HL1）） = 2 × 0.04 = 0.08（即 σ ≈ 0.283），然后在网络中每个其他隐藏层处将其按 100 × 0.04 = 4 进行缩放。"
        }
    },
    {
        "translation": {
            "en": "disease diagnosis, 538",
            "zh": "疾病诊断，538"
        }
    },
    {
        "translation": {
            "en": "3.177",
            "zh": "3.177"
        }
    },
    {
        "translation": {
            "en": "Sarah had a task that she wanted to get better at, and so she practiced it many times.",
            "zh": "莎拉有一项她想做得更好的任务，所以她练习了很多次。"
        }
    },
    {
        "translation": {
            "en": "The technical term to describe a dataset in which most of the features have zero values is sparse data.",
            "zh": "用于描述大多数要素值为零的数据集的技术术语是稀疏数据。"
        }
    },
    {
        "translation": {
            "en": "The parameters required for the normal, exponential, and mixture of Gaussians PDFs are shown in Table 6.10[271].",
            "zh": "高斯PDF的正态、指数和混合所需的参数如表6.10所示[271]。"
        }
    },
    {
        "translation": {
            "en": "As time went by, Sarah found herself feeling this excitement more and more often as she became better and better at quickly assessing her situation when the blindfold was cleared and making better decisions about which direction to step in.",
            "zh": "随着时间的流逝，莎拉发现自己越来越频繁地感受到这种兴奋，因为她越来越善于在眼罩被清除时快速评估自己的处境，并更好地决定向哪个方向迈进。"
        }
    },
    {
        "translation": {
            "en": "Many modern convolutional networks use a max function that simply returns the maximum value in the region of the feature map covered by the local receptive field.",
            "zh": "许多现代卷积网络都使用 max 函数，该函数仅返回局部感受野所覆盖的特征图区域中的最大值。"
        }
    },
    {
        "translation": {
            "en": "7.6   Further Reading",
            "zh": "7.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "Concept drift is a phenomenon that occurs when the relationship between the target feature and the descriptive features changes over time.",
            "zh": "概念漂移是当目标特征和描述性特征之间的关系随时间变化时发生的现象。"
        }
    },
    {
        "translation": {
            "en": "Recalling that the error surface is defined by the error function, L2 (given in Equation (7.10)[320]), the gradient at any point on this error surface is given by the value of the partial derivative of the error function with respect to a particular weight at that point.",
            "zh": "回想一下，误差面由误差函数 L2 定义（在等式 （7.10）[320] 中给出），该误差曲面上任何点的梯度由误差函数相对于该点特定权重的偏导数值给出。"
        }
    },
    {
        "translation": {
            "en": "PETROFLUXIVAR_U/G/R/I/Z",
            "zh": "PETROFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "conditional probability, 245, 246, 251, 757, 759, 759, 762",
            "zh": "条件概率， 245， 246， 251， 757， 759， 759， 762"
        }
    },
    {
        "translation": {
            "en": "Each cluster centroid is then updated by calculating the mean value of each descriptive feature for all instances that are a member of the cluster. For example, there are nine members of 𝒞1: {d1,d2,d3,d6,d8,d11,d13,d20,d24}. So, c1 is updated to",
            "zh": "然后，通过计算作为聚类成员的所有实例的每个描述性特征的平均值来更新每个聚类质心。例如，C1 有 9 个成员：{d1，d2，d3，d6，d8，d11，d13，d20，d24}。因此，c1 更新为"
        }
    },
    {
        "translation": {
            "en": "The easiest way to handle outliers is to use a clamp transformation. This clamps all values above an upper threshold and below a lower threshold to these threshold values, thus removing the offending outliers:",
            "zh": "处理异常值的最简单方法是使用钳位变换。这会将高于上限阈值和低于阈值下限的所有值限制在这些阈值上，从而删除有问题的异常值："
        }
    },
    {
        "translation": {
            "en": "Jocelyn performed the same baseline test on the three model types using this new dataset.",
            "zh": "Jocelyn 使用这个新数据集对三种模型类型执行了相同的基线测试。"
        }
    },
    {
        "translation": {
            "en": "Subspace sampling further encourages the diversity of the trees within the ensemble and has the advantage of reducing the training time for each tree.",
            "zh": "子空间采样进一步鼓励了集合中树的多样性，并具有减少每棵树的训练时间的优点。"
        }
    },
    {
        "translation": {
            "en": "Later in this section we return to the question of how to counteract this property of weighted sum calculations.",
            "zh": "在本节的后面，我们将回到如何抵消加权和计算的这一特性的问题。"
        }
    },
    {
        "translation": {
            "en": "What makes predictive data analytics difficult, but also fascinating, is figuring out how to answer all the questions that surround the modeling phase of a project.",
            "zh": "预测数据分析之所以困难，但又令人着迷的是弄清楚如何回答围绕项目建模阶段的所有问题。"
        }
    },
    {
        "translation": {
            "en": "The process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "使用装袋和子空间采样创建模型集合的过程。"
        }
    },
    {
        "translation": {
            "en": "decision tree, 117, 121, 121, 169, 541, 554, 556, 732, 733, 735, 736",
            "zh": "决策树， 117， 121， 121， 169， 541， 554， 556， 732， 733， 735， 736"
        }
    },
    {
        "translation": {
            "en": "10.7   The silhouette plot for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3).",
            "zh": "10.7 使用k均值算法（k = 3）找到的移动电话客户数据集最终聚类的轮廓图（表10.1[604]）。"
        }
    },
    {
        "translation": {
            "en": "Chapter 10 is a new chapter covering the most important ideas and techniques in unsupervised learning. This chapter is one-half of a new part of the book, Beyond Prediction, that expands beyond the focus of the first edition on supervised learning to allow broader coverage of machine learning.",
            "zh": "第10章是一个新的章节，涵盖了无监督学习中最重要的思想和技术。本章是本书新部分“超越预测”的一半，该部分超出了第一版对监督学习的关注范围，从而扩大了机器学习的覆盖范围。"
        }
    },
    {
        "translation": {
            "en": "Lowercase letters represent a single feature (e.g., f, a, b, c …).",
            "zh": "小写字母表示单个特征（例如，f、a、b、c 等）。"
        }
    },
    {
        "translation": {
            "en": "Features recording salaries often follow a right skewed distribution, as most people are paid salaries near a well-defined central tendency, but there are usually a small number of people who are paid very large salaries.",
            "zh": "记录工资的特征通常遵循右偏态分布，因为大多数人的工资接近明确定义的中心趋势，但通常有少数人的工资非常高。"
        }
    },
    {
        "translation": {
            "en": "target network freezing, 672",
            "zh": "目标网络冻结，672"
        }
    },
    {
        "translation": {
            "en": "Freund, Yoav, and Robert E. Schapire. 1995. A desicion-theoretic generalization of on-line learning and an application to boosting. In Computational Learning Theory, 23–37. Springer.",
            "zh": "Freund、Yoav 和 Robert E. Schapire。1995. 在线学习的决策理论推广及其在提升中的应用.在计算学习理论中，23-37。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "Stepping through the processing of the network in Figure 8.5[392], the sequence of calculations necessary to generate the activations for the neurons in the hidden layer is illustrated in the top row of the figure.",
            "zh": "通过图8.5[392]中网络的处理，图的顶行显示了为隐藏层中的神经元生成激活所需的计算顺序。"
        }
    },
    {
        "translation": {
            "en": "We also mentioned that this global minimum can be found at the point at which the partial derivatives of the error surface, with respect to the weights, are equal to zero.",
            "zh": "我们还提到，这个全局最小值可以在误差面的偏导数相对于权重等于零的点上找到。"
        }
    },
    {
        "translation": {
            "en": "We will use Russia as our query country for this question. The table below lists the descriptive features for Russia.",
            "zh": "我们将使用俄罗斯作为这个问题的查询国家。下表列出了俄罗斯的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The CPTs are shown in Figure 6.13[296].",
            "zh": "CPT如图6.13所示[296]。"
        }
    },
    {
        "translation": {
            "en": "We also introduced the ID3 algorithm as a standard algorithm for inducing decision trees from a dataset.",
            "zh": "我们还引入了 ID3 算法作为从数据集中诱导决策树的标准算法。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the correspondence between graphical and matrix representations of a neural network. This figure is inspired by Figure 3.9 of Kelleher (2019).",
            "zh": "神经网络的图形表示和矩阵表示之间的对应关系的图示。该图的灵感来自Kelleher（2019）的图3.9。"
        }
    },
    {
        "translation": {
            "en": "Sloan Digital Sky Survey, 703",
            "zh": "仕龙数字巡天，703"
        }
    },
    {
        "translation": {
            "en": "Title: Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies / John D. Kelleher, Brian Mac Namee and Aoife D’Arcy.",
            "zh": "题目：预测数据分析的机器学习基础：算法、工作示例和案例研究 / John D. Kelleher、Brian Mac Namee 和 Aoife D'Arcy。"
        }
    },
    {
        "translation": {
            "en": "For ease of reading, the instances have been ordered in descending order of the score the model assigned to each instance.",
            "zh": "为了便于阅读，实例已按模型分配给每个实例的分数的降序排序。"
        }
    },
    {
        "translation": {
            "en": "The player wins if their total is less than or equal to 22 and is greater than the dealer’s total, or if the dealer goes bust.",
            "zh": "如果玩家的总和小于或等于 22 且大于庄家的总数，或者庄家破产，则玩家获胜。"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm builds the tree in a recursive, depth-first manner, beginning at the root node and working down to the leaf nodes.",
            "zh": "ID3 算法以递归、深度优先的方式构建树，从根节点开始，一直到叶节点。"
        }
    },
    {
        "translation": {
            "en": "(e) The following table shows handwritten examples of the digits 7 and 8 and their corresponding histogram values.",
            "zh": "（e） 下表显示了数字 7 和 8 的手写示例及其相应的直方图值。"
        }
    },
    {
        "translation": {
            "en": "In an experiment performed to capture this data, participants were shown a series of different images, and their neural responses were measured using electroencephalography (EEG).",
            "zh": "在为捕获这些数据而进行的实验中，向参与者展示了一系列不同的图像，并使用脑电图（EEG）测量了他们的神经反应。"
        }
    },
    {
        "translation": {
            "en": "The goal of any feature selection approach is to identify the smallest subset of descriptive features that maintains overall model performance. Ideally, a feature selection approach will return the subset of features that includes the predictive and interacting features while excluding the irrelevant and redundant features.",
            "zh": "任何特征选择方法的目标都是确定描述性特征的最小子集，以保持整体模型性能。理想情况下，特征选择方法将返回包含预测特征和交互特征的特征子集，同时排除不相关和冗余特征。"
        }
    },
    {
        "translation": {
            "en": "Grayscale images are stored as a matrix of pixel values in the range [0,1] where 0 represents a black pixel and 1 represents a white one.",
            "zh": "灰度图像存储为 [0,1] 范围内的像素值矩阵，其中 0 表示黑色像素，1 表示白色像素。"
        }
    },
    {
        "translation": {
            "en": "This choice is made by computing the information gain of the descriptive features in the training dataset.",
            "zh": "这种选择是通过计算训练数据集中描述性特征的信息增益来做出的。"
        }
    },
    {
        "translation": {
            "en": "B.1  The sample space for the domain of two dice.",
            "zh": "B.1 两个骰子域的样本空间。"
        }
    },
    {
        "translation": {
            "en": "The fundamental information processing pattern within the forget gate can be characterized as passing the concatenated hxt vector through a layer of sigmoid neurons in order to generate a vector mask, and then using an elementwise product of this mask with the cell state to update (or filter) the cell’s activations. This information processing pattern of creating a vector mask and then using it in an elementwise product to update another activation vector is present in both of the other gates in an LSTM.",
            "zh": "遗忘门内的基本信息处理模式可以表征为将串联的 hxt 向量通过乙状结肠神经元层以生成向量掩码，然后使用该掩码的元素乘积与细胞状态来更新（或过滤）细胞的激活。这种创建向量掩码，然后在逐元乘积中使用它来更新另一个激活向量的信息处理模式存在于 LSTM 的其他两个门中。"
        }
    },
    {
        "translation": {
            "en": "In this case the maximum values for TOTAL CLAIMED and NUM.",
            "zh": "在本例中，TOTAL CLAIM 和 NUM."
        }
    },
    {
        "translation": {
            "en": "One way to think about this process is that we change the dataset from two dimensions to a higher-dimensional space.",
            "zh": "考虑此过程的一种方法是将数据集从二维空间更改为更高维空间。"
        }
    },
    {
        "translation": {
            "en": "index, 211, 212",
            "zh": "索引， 211， 212"
        }
    },
    {
        "translation": {
            "en": "The decision tree resulting from splitting the data in Table 4.11[152] using the feature SEASON.",
            "zh": "使用特征 SEASON 拆分表 4.11[152] 中的数据生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "The simplicity of the derivative of the logistic function is one of the reasons why the logistic function was such a popular activation function in neural networks: using logistic activation functions made it relatively easy to implement the backpropagation algorithm.",
            "zh": "逻辑函数导数的简单性是逻辑函数在神经网络中如此流行的激活函数的原因之一：使用逻辑激活函数使得实现反向传播算法变得相对容易。"
        }
    },
    {
        "translation": {
            "en": "At the time Jocelyn arrived, the SDSS pipeline included rule-based systems that could classify night sky objects into broad categories—for example, stars and galaxies.",
            "zh": "在Jocelyn到达时，SDSS管道包括基于规则的系统，可以将夜空物体分类为大类，例如恒星和星系。"
        }
    },
    {
        "translation": {
            "en": "(d) What value will the Bayesian network predict for ALARM, given that there is a storm but we don’t know if a burglar has broken in or where the cat is?",
            "zh": "（d） 贝叶斯网络对 ALARM 的预测值是多少，假设有暴风雨，但我们不知道窃贼是否闯入或猫在哪里？"
        }
    },
    {
        "translation": {
            "en": "0.84",
            "zh": "0.84"
        }
    },
    {
        "translation": {
            "en": "This makes sense because their activation will not have been used to generate the output of the model and so will not have contributed to the error of the model.",
            "zh": "这是有道理的，因为它们的激活不会用于生成模型的输出，因此不会导致模型的错误。"
        }
    },
    {
        "translation": {
            "en": "Functionally, an individual neuron can be understood as a simple signal processing system.",
            "zh": "从功能上讲，单个神经元可以理解为一个简单的信号处理系统。"
        }
    },
    {
        "translation": {
            "en": "In a predictive analytics task, we will often be interested in calculating the probability of more than one event.",
            "zh": "在预测分析任务中，我们通常会对计算多个事件的概率感兴趣。"
        }
    },
    {
        "translation": {
            "en": "In the diagrams in Figure 4.4[122], ellipses represent root or interior nodes, and rectangles represent leaf nodes. The labels of the ellipses indicate which descriptive feature is tested at that node. The labels on each branch indicate one of the possible feature levels that the descriptive feature at the node above can take. The labels on the rectangular leaf nodes indicate the target level that should be predicted when the tests on the interior nodes create a path that terminates at that leaf node.",
            "zh": "在图4.4[122]的图中，椭圆表示根节点或内部节点，矩形表示叶节点。椭圆的标签指示在该节点上测试哪个描述性特征。每个分支上的标签指示上述节点上的描述性特征可以采用的可能特征级别之一。矩形叶节点上的标签指示在内部节点上的测试创建终止于该叶节点的路径时应预测的目标级别。"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling is sometimes extended to include a third sample, the validation set.",
            "zh": "保持抽样有时会扩展到包括第三个样本，即验证集。"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D. 2019. Deep learning. Essential Knowledge Series. MIT Press.",
            "zh": "凯莱赫，约翰 D. 2019 年。深度学习。基本知识系列。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "However, the general idea of a convergence criterion is that as the training progresses, the error of the network should generally decrease.",
            "zh": "然而，收敛准则的一般思想是，随着训练的进行，网络的误差通常应该会减小。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the output for Neuron 5 for the input vector: Neuron 1 = 0.9, Neuron 2 = 0.5.",
            "zh": "（a） 计算输入向量的神经元 5 的输出：神经元 1 = 0.9，神经元 2 = 0.5。"
        }
    },
    {
        "translation": {
            "en": "21. A nice example of building machine learning models for drug dosage prediction can be found in Mac Namee et al. (2002).",
            "zh": "21. Mac Namee et al. （2002） 是构建用于药物剂量预测的机器学习模型的一个很好的例子。"
        }
    },
    {
        "translation": {
            "en": "For the student-t distribution, the degrees of freedom is always set to the sample size (number of rows in the dataset) minus one.",
            "zh": "对于 student-t 分布，自由度始终设置为样本数量（数据集中的行数）减去 1。"
        }
    },
    {
        "translation": {
            "en": "13.6   Histograms of a selection of features from the SDSS dataset.",
            "zh": "13.6 SDSS 数据集中所选要素的直方图。"
        }
    },
    {
        "translation": {
            "en": "Another way to understand how dropout helps is to notice that the training data looks different at every epoch because each time an example is presented to a network a different set of input neurons is set to 0.",
            "zh": "理解辍学如何帮助的另一种方法是注意到训练数据在每个时期看起来都不同，因为每次向网络呈现示例时，都会将一组不同的输入神经元设置为 0。"
        }
    },
    {
        "translation": {
            "en": "Similar to the equations for the input gate, we use the symbols † and ‡ to distinguish the different paths of information processing in the output gate.",
            "zh": "与输入门的方程类似，我们使用符号 † 和 ‡ 来区分输出门中信息处理的不同路径。"
        }
    },
    {
        "translation": {
            "en": "The main structural difference is that the network in Figure 8.36[498] does not include a softmax output layer.",
            "zh": "主要的结构区别在于图8.36[498]中的网络不包括softmax输出层。"
        }
    },
    {
        "translation": {
            "en": "25. A formal test for statistical significance could easily be used to reinforce this conclusion.",
            "zh": "25. 可以很容易地使用统计显著性的正式检验来加强这一结论。"
        }
    },
    {
        "translation": {
            "en": "6.11   The dataset from the loan application fraud detection domain (from Table 6.2[263]) with two continuous descriptive features added: ACCOUNT BALANCE and LOAN AMOUNT.",
            "zh": "6.11 来自贷款申请欺诈检测域的数据集（来自表6.2[263]），增加了两个连续的描述性特征：账户余额和贷款金额。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the simple accuracy and average class accuracy (using an arithmetic mean) for each model.",
            "zh": "（b） 计算每个模型的简单准确率和平均类准确率（使用算术平均值）。"
        }
    },
    {
        "translation": {
            "en": "As a consequence, the weights on a dropped neuron won’t receive any weight updates for that example.",
            "zh": "因此，对于该示例，丢弃神经元上的权重不会收到任何权重更新。"
        }
    },
    {
        "translation": {
            "en": "In Appendix C[765] we provide an introduction to differentiation that covers all the techniques required to understand how the gradient descent algorithm works.",
            "zh": "在附录C[765]中，我们介绍了微分，涵盖了理解梯度下降算法工作原理所需的所有技术。"
        }
    },
    {
        "translation": {
            "en": "DEVMAGERR_U/G/R/I/Z",
            "zh": "DEVMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This single value, however, may not capture all the relevant information.",
            "zh": "但是，此单个值可能无法捕获所有相关信息。"
        }
    },
    {
        "translation": {
            "en": "This dataset contains measurements of the revolutions per minute (RPM) that power station generators are running at, the amount of vibration in the generators (VIBRATION), and an indicator to show whether the generators proved to be working or faulty the day after these measurements were taken.",
            "zh": "该数据集包含电站发电机运行的每分钟转数 （RPM） 的测量值、发电机中的振动量 （VIBRATION） 以及一个指示器，用于显示发电机在进行这些测量后的第二天是否被证明是工作还是故障。"
        }
    },
    {
        "translation": {
            "en": "-0.8945",
            "zh": "-0.8945"
        }
    },
    {
        "translation": {
            "en": "This threshold can be changed, however, which leads to different predictions and a different confusion matrix.",
            "zh": "但是，此阈值可以更改，这会导致不同的预测和不同的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "(a) The target hypersphere after instance d21 has been stored as best, and best-distance has been updated; and (b) the extent of the search process: white nodes were checked by the search process, and the node with the bold outline indexed instance d21, which was returned as the nearest neighbor to the query. Grayed-out branches indicate the portions of the k-d tree pruned from the search.",
            "zh": "（a） 实例d21之后的目标超球体已存储为最佳，最佳距离已更新;（b） 搜索过程的范围：搜索过程检查了白色节点，具有粗体轮廓的节点索引了实例 d21，该实例作为查询的最近邻居返回。灰色的树枝表示从搜索中修剪的 k-d 树部分。"
        }
    },
    {
        "translation": {
            "en": "The key point to remember here is that if a sample of data is not representative of a population, then inferences based on that sample will not generalize to the larger population.",
            "zh": "这里要记住的关键点是，如果数据样本不能代表总体，那么基于该样本的推论将不会推广到更大的总体。"
        }
    },
    {
        "translation": {
            "en": "For example, eating cake almost always seems like a good idea in the moment, but in terms of long-term health is probably not always a strong choice.",
            "zh": "例如，吃蛋糕在当下似乎总是一个好主意，但就长期健康而言，可能并不总是一个强有力的选择。"
        }
    },
    {
        "translation": {
            "en": "other features, 36",
            "zh": "其他功能， 36"
        }
    },
    {
        "translation": {
            "en": "Padding may be applied to retain dimensionality, and in some cases the non-linearity activation or sub-sampling may be dropped in some convolutional layers.",
            "zh": "可以应用填充来保持维数，在某些情况下，在某些卷积层中可能会丢弃非线性激活或子采样。"
        }
    },
    {
        "translation": {
            "en": "However, the downside to not normalizing the target feature in a regression problem is that if the target feature has a large range, then during training the error of the network on an example can be very large, resulting in very large error gradients, which in turn can result in large weight updates and an unstable learning process (similar to the instability that can arise with large inputs, but in this case the instability arises from large errors).",
            "zh": "然而，在回归问题中不规范化目标特征的缺点是，如果目标特征的范围很大，那么在训练过程中，示例上的网络误差可能非常大，从而导致非常大的误差梯度，这反过来又会导致大量的权重更新和不稳定的学习过程（类似于大输入可能产生的不稳定性， 但在这种情况下，不稳定性是由大错误引起的）。"
        }
    },
    {
        "translation": {
            "en": "CRM, 572",
            "zh": "客户关系管理，572"
        }
    },
    {
        "translation": {
            "en": "Figure 3.10(a)[80] shows a box plot for AGE across the full dataset, while Figure 3.10(b)[80] shows individual box plots for AGE for each level of the POSITION feature.",
            "zh": "图 3.10（a）[80] 显示了整个数据集中 AGE 的箱形图，而图 3.10（b）[80] 显示了 POSITION 特征每个级别的 AGE 的单独箱形图。"
        }
    },
    {
        "translation": {
            "en": "hypersphere, 201, 217",
            "zh": "超球体， 201， 217"
        }
    },
    {
        "translation": {
            "en": "The problem with this is that we are essentially wasting bins because some of the bins end up representing a very small number of instances (the height of the bars in the diagram shows the number of instances in each bin).",
            "zh": "这样做的问题在于，我们本质上是在浪费垃圾箱，因为一些垃圾箱最终代表了非常少量的实例（图中条形的高度显示了每个垃圾桶中的实例数量）。"
        }
    },
    {
        "translation": {
            "en": "Sample",
            "zh": "样本"
        }
    },
    {
        "translation": {
            "en": "The k-means algorithm is a well-known example of this kind of algorithm and is used as the default clustering implementation in many machine learning packages and tools.",
            "zh": "k 均值算法是此类算法的一个众所周知的例子，在许多机器学习包和工具中用作默认聚类实现。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11(b)[203] illustrates the parts of the k-d tree that were checked or pruned during the search process.",
            "zh": "图5.11（b）[203]说明了在搜索过程中检查或修剪的k-d树部分。"
        }
    },
    {
        "translation": {
            "en": "Events Involving Binary Features",
            "zh": "涉及二进制特征的事件"
        }
    },
    {
        "translation": {
            "en": "Each of these instances is described in terms of three binary descriptive features (GOOD BEHAVIOR, AGE < 30, DRUG DEPENDENT) and a binary target feature (RECIDIVIST).",
            "zh": "这些实例中的每一个都根据三个二元描述特征（良好行为、年龄 < 30、药物依赖）和一个二元目标特征（累犯）进行描述。"
        }
    },
    {
        "translation": {
            "en": "The minus sign at the beginning of the equation is simply added to convert the negative numbers returned by the log function to positive ones (as described above).",
            "zh": "只需添加等式开头的减号即可将对数函数返回的负数转换为正数（如上所述）。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to use the clamp transformation to change the values of these outliers to something closer to the central tendency of the features.",
            "zh": "Jocelyn 决定使用钳位变换将这些异常值的值更改为更接近特征中心趋势的值。"
        }
    },
    {
        "translation": {
            "en": "6.4.3 Continuous Features: Binning",
            "zh": "6.4.3 连续功能：分箱"
        }
    },
    {
        "translation": {
            "en": "The boundary between imaginary and valid pixels is highlighted by a thickly outlined rectangle enclosing the valid pixels.",
            "zh": "虚像素和有效像素之间的边界由包围有效像素的粗轮廓矩形突出显示。"
        }
    },
    {
        "translation": {
            "en": "CALLMINUTESCHANGEPCT: Derived from the raw call data, this feature captured the amount by which the number of minutes a customer used had changed that month compared to the previous month.",
            "zh": "CALLMINUTESCHANGEPCT：此功能源自原始呼叫数据，可捕获客户当月使用的分钟数与上个月相比的变化量。"
        }
    },
    {
        "translation": {
            "en": "This derivation was based on the chain rule and is the product of the rate of change of the error of the model with respect to its output—the term (t− 𝕄w(d))—and the rate of change of the output of the linear regression model with respect to a change in the weight j, the term −d[j].",
            "zh": "该推导基于链式法则，是模型相对于其输出的误差变化率（项 （t− Mw（d）））和线性回归模型输出相对于权重 j 变化的变化率（项 −d[j]）的乘积。"
        }
    },
    {
        "translation": {
            "en": "An individual can belong to only one of these states at a time and moves between them according to a Markov process.",
            "zh": "一个人一次只能属于这些状态中的一种，并根据马尔可夫过程在它们之间移动。"
        }
    },
    {
        "translation": {
            "en": "7.4   Weights and standard errors for each feature in the office rentals model.",
            "zh": "7.4 办公室租赁模型中每个特征的权重和标准误差。"
        }
    },
    {
        "translation": {
            "en": "Following the flow of d2 through all three layers of the network, the prediction output by the model for this example is 0.4718 (see Cell 2, the gray cell, in the Activations Output Layer matrix).",
            "zh": "在 d2 流经网络的所有三层之后，此示例的模型的预测输出为 0.4718（请参阅激活输出层矩阵中的单元格 2，灰色单元格）。"
        }
    },
    {
        "translation": {
            "en": "7.2   Calculating the sum of squared errors for the candidate model (with w [0] = 6.47 and w [1]= 0.62) to make predictions for the office rentals dataset.",
            "zh": "7.2 计算候选模型的平方误差之和（w [0] = 6.47，w [1]= 0.62），以对办公室租赁数据集进行预测。"
        }
    },
    {
        "translation": {
            "en": "The multiplication operation calculates the weighted sum for the output neuron z(2), and this is passed through the neuron’s activation function φ to generate the output of the network.",
            "zh": "乘法运算计算输出神经元 z（2） 的加权和，并通过神经元的激活函数φ生成网络的输出。"
        }
    },
    {
        "translation": {
            "en": "Adam, 523",
            "zh": "亚当，523"
        }
    },
    {
        "translation": {
            "en": "This pattern was investigated with the business to understand whether this was an issue due to valid or invalid data.",
            "zh": "与业务部门一起调查了此模式，以了解这是由于有效数据还是无效数据造成的问题。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.14(b)[218] highlights the normalization of descriptive feature values that takes place as part of calculating cosine similarity.",
            "zh": "图5.14（b）[218]突出显示了描述性特征值的归一化，这是计算余弦相似度的一部分。"
        }
    },
    {
        "translation": {
            "en": "Mixture of Gaussians distributions are used to represent data that is composed of multiple subpopulations.",
            "zh": "高斯分布的混合用于表示由多个子群体组成的数据。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.76)[469] is taken from Equation (8.72)[467 the step to Equation (8.77)[469] uses Equation (8.74)[468 the rewrite in Equation (8.78)[469] uses Equation (8.75)[468 and finally Equation (8.79)[469] is the simplification we get when the terms cancel out after the product.",
            "zh": "方程（8.76）[469]取自方程（8.72）[467]，方程（8.77）[469]的步骤使用方程（8.74）[468]，方程（8.78）[469]中的重写使用方程（8.75）[468]，最后方程（8.79）[469]是当项在乘积后抵消时我们得到的简化。"
        }
    },
    {
        "translation": {
            "en": "Maintaining long histories of actions, rewards, and observations (which are possibly only very slightly different from one iteration to the next) is not a very efficient way to reason about the world, particularly as episodes might cover hundreds or thousands of time-steps.",
            "zh": "保持行动、奖励和观察的长历史（在一次迭代到下一次迭代之间可能只有很小的差异）并不是推理世界的非常有效的方法，特别是当剧集可能涵盖数百或数千个时间步长时。"
        }
    },
    {
        "translation": {
            "en": "Because AT was already using a process in which its retention team generated call lists based on collected data, deployment of the new decision tree model was reasonably straightforward.",
            "zh": "由于 AT 已经在使用其保留团队根据收集的数据生成呼叫列表的流程，因此部署新的决策树模型相当简单。"
        }
    },
    {
        "translation": {
            "en": "full joint probability distribution, 284, 302, 761",
            "zh": "全联合概率分布，284,302,761"
        }
    },
    {
        "translation": {
            "en": "We can show that both of the networks in Figure 6.12[291] represent the same joint probability by using each of them to calculate the probability of an arbitrarily chosen joint event from the domain. We should get the same probability for the joint event from both of the networks. For this example, we will calculate the probability of the event ¬a, b, c. Using the Bayesian network in Figure 6.12(a)[291], we would carry out the calculation as follows:",
            "zh": "我们可以证明，图 6.12[291] 中的两个网络都表示相同的联合概率，方法是使用它们中的每一个来计算从域中任意选择的联合事件的概率。我们应该从两个网络获得相同的联合事件概率。在这个例子中，我们将计算事件 ¬a、b、c 的概率。使用图6.12（a）[291]中的贝叶斯网络，我们将进行如下计算："
        }
    },
    {
        "translation": {
            "en": "Using the δ values you have calculated, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., ∂ℰ/∂w5,4, ∂ℰ/∂w5,3,∂ℰ/∂w5,0,∂ℰ/∂w4,2,∂ℰ/∂w4,0,∂ℰ/∂w3,2,∂ℰ/∂w3,0,∂ℰ/∂w2,1,∂ℰ/∂w2,0).",
            "zh": "使用您计算的δ值，计算网络误差对网络每个权重变化的敏感度（即 ∂E/∂w5,4、∂E/∂w5、3、∂E/∂w5,0、∂E/∂w4,2，∂E/∂w4,0，∂E/∂w3,2，∂E/∂w3,0，∂E/∂w2,1，∂E/∂w2,0）。"
        }
    },
    {
        "translation": {
            "en": "Similar to the normal distribution, the λ parameter for the exponential distribution can be easily calculated by using the value of 1 divided by the mean of the data.",
            "zh": "与正态分布类似，指数分布的 λ 参数可以通过使用 1 除以数据平均值来轻松计算。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(c)[329] shows the impact of a large learning rate.",
            "zh": "图7.7（c）[329]显示了高学习率的影响。"
        }
    },
    {
        "translation": {
            "en": "The term channel is used to describe the number of matrices used to encode the information in an image.",
            "zh": "术语通道用于描述用于对图像中的信息进行编码的矩阵数量。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5[392] highlights how bias terms are introduced into the activation vectors in such a way that they are aligned with the bias term weights during the matrix multiplication.",
            "zh": "图 8.5[392] 突出显示了如何在矩阵乘法过程中将偏置项引入激活向量，使其与偏置项权重对齐。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.8",
            "zh": "图 13.8"
        }
    },
    {
        "translation": {
            "en": "to estimate how the model will perform when deployed",
            "zh": "估计模型在部署时的性能"
        }
    },
    {
        "translation": {
            "en": "sampling variance, 153",
            "zh": "抽样方差，153"
        }
    },
    {
        "translation": {
            "en": "B.3   Some Useful Probability Rules",
            "zh": "B.3 一些有用的概率规则"
        }
    },
    {
        "translation": {
            "en": "Once the set of models has been created, the ensemble makes predictions using a weighted aggregate of the predictions made by the individual models.",
            "zh": "创建模型集后，集成将使用各个模型所做的预测的加权聚合进行预测。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2",
            "zh": "图 7.2"
        }
    },
    {
        "translation": {
            "en": "Similarly, the gradients for the inputs to the elementwise product in the forget gate are calculated",
            "zh": "类似地，计算遗忘门中逐元乘积输入的梯度"
        }
    },
    {
        "translation": {
            "en": "The original gradient boosting paper by Friedman (2001) gives a detailed explanation on the fundamentals of gradient boosting.",
            "zh": "Friedman（2001）的原始梯度提升论文对梯度提升的基本原理进行了详细的解释。"
        }
    },
    {
        "translation": {
            "en": "5.4 Extensions and Variations",
            "zh": "5.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Notice that one of the partitions created by splitting 8 on the basis of SLOPE is empty: 18.",
            "zh": "请注意，通过在 SLOPE 的基础上拆分 8 创建的分区之一是空的：18。"
        }
    },
    {
        "translation": {
            "en": "As a result, machine learning is an ill-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available.",
            "zh": "因此，机器学习是一个病态的问题，也就是说，一个无法仅使用可用信息确定唯一解决方案的问题。"
        }
    },
    {
        "translation": {
            "en": "To fully capture the game dynamics we could represent TwentyTwos using the 190 different hand states plus five more terminal states representing the outcomes of going bust, losing, tying, winning, and winning with a TwentyTwo.",
            "zh": "为了充分捕捉游戏动态，我们可以使用 190 种不同的手牌状态加上另外 5 种最终状态来表示 TwentyTwo，这些状态代表了 TwentyTwo 破产、输家、平局、赢牌和获胜的结果。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.21",
            "zh": "图 8.21"
        }
    },
    {
        "translation": {
            "en": "This is also an attractive characteristic of this function.",
            "zh": "这也是此功能的一个吸引人的特点。"
        }
    },
    {
        "translation": {
            "en": "The correlations between the HEIGHT and WEIGHT and AGE features can be calculated, using the covariances and standard deviations from Table 3.8[82], as follows:",
            "zh": "使用表3.8[82]中的协方差和标准差，可以计算身高、体重和年龄特征之间的相关性，如下所示："
        }
    },
    {
        "translation": {
            "en": "For example, the probability of the joint event2 DICE1 = , DICE2 = would be calculated as",
            "zh": "例如，联合事件 2 DICE1 = ， DICE2 = 的概率计算公式为"
        }
    },
    {
        "translation": {
            "en": "There is always a trade-off in setting the value of k. If we set k too low, we run the risk of the algorithm being sensitive to noise in the data and overfitting.",
            "zh": "在设置 k 的值时总是需要权衡取舍。如果我们将 k 设置得太低，我们就会面临算法对数据中的噪声敏感和过度拟合的风险。"
        }
    },
    {
        "translation": {
            "en": "An edge-on disk is a spiral galaxy viewed from the edge, which makes the direction of the spiral arms unclear.",
            "zh": "边缘圆盘是从边缘观察的螺旋星系，这使得旋臂的方向不清晰。"
        }
    },
    {
        "translation": {
            "en": "0.48",
            "zh": "0.48"
        }
    },
    {
        "translation": {
            "en": "Lintott, C., K. Schawinski, S. Bamford, A. Slosar, K. Land, D. Thomas, E. Edmondson, K. Masters, R. C. Nichol, M. J. Raddick, A. Szalay, D. Andreescu, P. Murray, and J. Vandenberg. 2011. Galaxy Zoo 1: Data release of morphological classifications for nearly 900 000 galaxies. Monthly Notices of the Royal Astronomical Society 410: 166–178. doi:10.1111/j.1365-2966.2010.17432.x.",
            "zh": "Lintott， C.， K. Schawinski， S. Bamford， A. Slosar， K. Land， D. Thomas， E. Edmondson， K. Masters， RC Nichol， MJ Raddick， A. Szalay， D. Andreescu， P. Murray， and J. Vandenberg.2011. 银河动物园1号：近90万个星系形态分类数据发布。皇家天文学会月刊 410：166-178。doi：10.1111/j.1365-2966.2010.17432.x."
        }
    },
    {
        "translation": {
            "en": "The 6 neurons in the top layer share the weights in Filter 1, and the 6 neurons in the bottom layer share the weights in Filter 2.",
            "zh": "顶层的 6 个神经元共享过滤器 1 中的权重，底层的 6 个神经元共享过滤器 2 中的权重。"
        }
    },
    {
        "translation": {
            "en": "The product ED⊺ is however defined because D⊺ is a 3 × 2 matrix and the number of columns is E (3) equals the number of rows in D⊺ (3).",
            "zh": "然而，乘积 ED⊺ 的定义是因为 D⊺ 是一个 3 × 2 矩阵，列数为 E （3） 等于 D⊺ （3） 中的行数。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we shift the focus to unsupervised machine learning methods.",
            "zh": "在本章中，我们将重点转移到无监督机器学习方法上。"
        }
    },
    {
        "translation": {
            "en": "The vanishing gradient problem is a direct consequence of the fact that the backpropagation algorithm is based on the chain rule.",
            "zh": "梯度消失问题是反向传播算法基于链式法则这一事实的直接结果。"
        }
    },
    {
        "translation": {
            "en": "Measures of flux and magnitude are made in each of the five photometric bands used by the SDSS imaging system.",
            "zh": "在SDSS成像系统使用的五个光度波段中，每个波段都测量了通量和量级。"
        }
    },
    {
        "translation": {
            "en": "Claude Shannon is considered to be the father of information theory.",
            "zh": "克劳德·香农（Claude Shannon）被认为是信息论之父。"
        }
    },
    {
        "translation": {
            "en": "Ordinal: Values that allow ordering but do not permit arithmetic (e.g., size measured as small, medium, or large)",
            "zh": "序号：允许排序但不允许算术的值（例如，测量为小、中或大的大小）"
        }
    },
    {
        "translation": {
            "en": "Chapter 13 of Hastie et al. (2009) gives an introduction to the statistical theory underpinning nearest neighbor models. The measure used to judge similarity is a key element in a nearest neighbor model. In this chapter, we have described a number of different distance metrics and similarity indexes. Cunningham (2009) provides a broader introduction to the range of metrics and indexes that are available.",
            "zh": "Hastie et al. （2009）的第13章介绍了支撑最近邻模型的统计理论。用于判断相似性的度量是最近邻模型中的关键要素。在本章中，我们描述了许多不同的距离度量和相似性指数。Cunningham（2009）对可用的指标和指数范围进行了更广泛的介绍。"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the hierarchical grouping of the instances in the mobile phone customer dataset from Table 10.1[604] found by the AHC algorithm (using Euclidean distance and single linkage). (b) The clustering returned when the tree is cut at k = 3. (c) The clustering returned when the tree is cut at k = 6.",
            "zh": "（a） AHC算法（使用欧几里得距离和单链接）找到的表10.1[604]中移动电话客户数据集中实例的分层图。（b） 当树木在k = 3时被砍伐时返回的聚类。（c） 在k = 6时砍伐树木时返回的聚类。"
        }
    },
    {
        "translation": {
            "en": "Probability functions are the basic building blocks of probability theory, and they are very easy to create from a dataset.",
            "zh": "概率函数是概率论的基本组成部分，它们很容易从数据集中创建。"
        }
    },
    {
        "translation": {
            "en": "The final two extensions and variations sections introduce well-known neural network architectures, including convolutional neural networks and recurrent neural networks.",
            "zh": "最后两个扩展和变体部分介绍了众所周知的神经网络架构，包括卷积神经网络和递归神经网络。"
        }
    },
    {
        "translation": {
            "en": "FP, 537",
            "zh": "FP，537"
        }
    },
    {
        "translation": {
            "en": "One disadvantage of using basis functions, however, is that the analyst has to design the basis function set that will be used.",
            "zh": "但是，使用基函数的一个缺点是，分析人员必须设计将要使用的基函数集。"
        }
    },
    {
        "translation": {
            "en": "To make Bayesian predictions, we generate the probability of the event that a target feature, t, takes a specific level, l, given the assignment of values to a set of descriptive features, q, from a query instance. We can restate Bayes’ Theorem using this terminology and generalize the definition of Bayes’ Theorem so that it can take into account more than one piece of evidence (each descriptive feature value is a separate piece of evidence). The Generalized Bayes’ Theorem is defined as",
            "zh": "为了进行贝叶斯预测，我们生成目标特征 t 具有特定水平 l 的事件的概率，给定从查询实例中为一组描述性特征 q 赋值。我们可以使用这个术语重述贝叶斯定理，并推广贝叶斯定理的定义，以便它可以考虑多个证据（每个描述性特征值都是一个单独的证据）。广义贝叶斯定理定义为"
        }
    },
    {
        "translation": {
            "en": "TD-Gammon, 677",
            "zh": "TD-金门， 677"
        }
    },
    {
        "translation": {
            "en": "The eleven states are shown as the nodes in the graph with transitions based on different actions represented by the edges (transitions for Twist actions are shown as solid lines and transitions for Stick actions are shown as dashed lines).",
            "zh": "这 11 个状态在图中显示为节点，其过渡基于边表示的不同动作（Twist 动作的过渡显示为实线，摇杆动作的过渡显示为虚线）。"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m + 1 descriptive features (including the dummy d[0] feature), d[0],d[1],…,d[m w is a vector of m + 1 weights (including the bias term) w[0],w[1] , …,w[m and φ represents the activation function (threshold, tanh, logistic, or rectifier, etc.)",
            "zh": "其中 d 是 m + 1 描述性特征（包括虚拟 d[0] 特征）的向量，d[0]，d[1],...,d[m w 是 m + 1 权重（包括偏置项）w[0]，w[1] ， ...，w[m 的向量，φ 表示激活函数（阈值、tanh、逻辑或整流器等）"
        }
    },
    {
        "translation": {
            "en": "In this chapter we introduce probability-based approaches to machine learning.",
            "zh": "在本章中，我们将介绍基于概率的机器学习方法。"
        }
    },
    {
        "translation": {
            "en": "Similarly, for every floor we go up in an office building, we can expect the rental price to decrease by 0.1781 Euro per month.",
            "zh": "同样，对于我们在办公楼中每上升一层，我们可以预期租金价格每月将下降 0.1781 欧元。"
        }
    },
    {
        "translation": {
            "en": "Consequently, if the relationship between the number of inputs to a weighted sum and the variance of the weights is incorrect, then the result of a weighted sum can have either a larger variance than the variance of its inputs or a smaller variance than the variance of its inputs.",
            "zh": "因此，如果加权和的输入数与权重方差之间的关系不正确，则加权和的结果的方差可能大于其输入的方差，或者方差小于其输入的方差。"
        }
    },
    {
        "translation": {
            "en": "Input images were scaled to 84×84 and the network contained hidden convolutional layers with 32, 64 and 64 units.30 Filter sizes were 8 × 8 (stride 4), 4 × 4 (stride 3), and 3 × 3 (stride 1).",
            "zh": "输入图像被缩放到84×84，网络包含32、64和64个单元的隐藏卷积层.30滤波器大小为8×8（步幅4）、4×4（步幅3）和3×3（步幅1）。"
        }
    },
    {
        "translation": {
            "en": "We return to the topic of weight initialization strategies in Section 8.4.2[447].",
            "zh": "我们回到第8.4.2节[447]中的权重初始化策略主题。"
        }
    },
    {
        "translation": {
            "en": "A preference bias guides the learning algorithm to prefer certain models over others.",
            "zh": "偏好偏差会引导学习算法优先选择某些模型而不是其他模型。"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the customer group dataset from Table 7.11[359]. Squares represent instances with the single target level, triangles the business level, and crosses the family level. The bottom-right panel illustrates the overall decision boundaries between the three target levels.",
            "zh": "表7.11[359]中客户组数据集的梯度下降过程中开发的模型选择。正方形表示具有单个目标级别的实例，三角形表示业务级别，并跨系列级别。右下角的面板说明了三个目标级别之间的总体决策边界。"
        }
    },
    {
        "translation": {
            "en": "We use a bold capital W to indicate a weight matrix, and we use a superscript in brackets to indicate the layer of the network the matrix is associated with.",
            "zh": "我们使用粗体大写字母 W 来表示权重矩阵，并使用括号中的上标来表示与矩阵关联的网络层。"
        }
    },
    {
        "translation": {
            "en": "7. When defining intervals, a square bracket, [ or ], indicates that the boundary value is included in the interval, and a parenthesis, ( or ), indicates that it is excluded from the interval.",
            "zh": "7. 定义区间时，方括号 [ 或 ]， 表示边界值包含在区间中，括号 （ 或 ） 表示它被排除在区间之外。"
        }
    },
    {
        "translation": {
            "en": "Now that we know that the row and column vector both contain the difference between the feature values of the two instances, it should be clear that, similar to Euclidean distance, the Mahalanobis distance squares the differences of the features.",
            "zh": "现在我们知道行向量和列向量都包含两个实例的特征值之间的差值，应该很清楚，与欧几里得距离类似，马氏距离对特征的差值进行平方。"
        }
    },
    {
        "translation": {
            "en": "The formal measure we use to do this is Shannon’s entropy model.",
            "zh": "我们用来做到这一点的形式度量是香农的熵模型。"
        }
    },
    {
        "translation": {
            "en": "The reason why we need two different derivatives for the softmax function to handle these two cases is that when we are taking the derivative with respect to changes in the logit for the neuron whose activation is (i.e.",
            "zh": "我们之所以需要两个不同的导数来处理 softmax 函数来处理这两种情况，是因为当我们取导数时，对于激活为 （即"
        }
    },
    {
        "translation": {
            "en": "From a probability point of view, each feature in a dataset is a random variable, and the sample space for the domain associated with a prediction problem is the set of all possible combinations of assignments of values to features.",
            "zh": "从概率的角度来看，数据集中的每个特征都是一个随机变量，与预测问题关联的域的样本空间是特征值分配的所有可能组合的集合。"
        }
    },
    {
        "translation": {
            "en": "The completed transition matrix for the Stick action, 𝒫Stick, is",
            "zh": "摇杆动作 PStick 的完整过渡矩阵为"
        }
    },
    {
        "translation": {
            "en": "Figure 2.9",
            "zh": "图 2.9"
        }
    },
    {
        "translation": {
            "en": "Consequently, decision trees naturally lend themselves to being trained using information-based metrics.",
            "zh": "因此，决策树自然适合使用基于信息的指标进行训练。"
        }
    },
    {
        "translation": {
            "en": "Alternatively, we can use the Theorem of Total Probability to calculate P(Y):",
            "zh": "或者，我们可以使用总概率定理来计算 P（Y）："
        }
    },
    {
        "translation": {
            "en": "A range of techniques can also be used to make a decision tree more robust to noise in the data.",
            "zh": "还可以使用一系列技术来使决策树对数据中的噪声更具鲁棒性。"
        }
    },
    {
        "translation": {
            "en": "LOC: The customer’s location (rural or urban)",
            "zh": "LOC：客户的位置（农村或城市）"
        }
    },
    {
        "translation": {
            "en": "Choosing a high value for γ gives almost equal importance to all rewards. For example, with γ = 0.9",
            "zh": "为γ选择高价值对所有奖励几乎同等重要。例如，γ = 0.9"
        }
    },
    {
        "translation": {
            "en": "Analysts will often input a suggested starting point for this search based on their own analysis of the data in order to guide the process.",
            "zh": "分析师通常会根据自己对数据的分析，为这次搜索输入一个建议的起点，以指导该过程。"
        }
    },
    {
        "translation": {
            "en": "The data, filter weights, and scale of the network shown in Figure 8.36[498] have been simplified for the purposes of illustration.",
            "zh": "图 8.36[498] 中所示的网络数据、滤波器权重和比例已简化，以便于说明。"
        }
    },
    {
        "translation": {
            "en": "In this case the initial model predicts a likelihood that an instance belongs to each of the possible target levels, and subsequent models predict corrections to these likelihoods.",
            "zh": "在这种情况下，初始模型预测实例属于每个可能的目标级别的可能性，后续模型预测对这些可能性的修正。"
        }
    },
    {
        "translation": {
            "en": "unbiased estimate, 752",
            "zh": "无偏估计，752"
        }
    },
    {
        "translation": {
            "en": "We will use the dataset2 in Table 6.1[246] to illustrate how the terminology of probability is mapped into the language of machine learning for predictive data analytics. The target being predicted in this dataset is whether a patient is suffering from MENINGITIS, and the descriptive features are common symptoms associated with this disease (HEADACHE, FEVER, and VOMITING).",
            "zh": "我们将使用表 6.1[246] 中的 dataset2 来说明如何将概率术语映射到用于预测数据分析的机器学习语言中。该数据集中预测的目标是患者是否患有脑膜炎，描述性特征是与该疾病相关的常见症状（头痛、发烧和呕吐）。"
        }
    },
    {
        "translation": {
            "en": "Note that each time we observe a decrease in the best validation error, we reset the patience count to zero.",
            "zh": "请注意，每次我们观察到最佳验证错误减少时，我们都会将耐心计数重置为零。"
        }
    },
    {
        "translation": {
            "en": "Comparing Figure 5.5(b)[192] with Figure 5.4(b)[190], we can see that the main difference is that the decision boundary in the bottom-right region of the feature space has moved to the left.",
            "zh": "将图5.5（b）[192]与图5.4（b）[190]进行比较，可以看出主要区别在于特征空间右下角区域的决策边界向左移动。"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the data in Tables 6.11[278] and 6.15[283].",
            "zh": "朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表6.11[278]和表6.15[283]中的数据计算得出。"
        }
    },
    {
        "translation": {
            "en": "The second course (“M.L.",
            "zh": "第二道菜（“M.L."
        }
    },
    {
        "translation": {
            "en": "A dataset that represents the characters in the Guess Who game.",
            "zh": "表示 Guess Who 游戏中角色的数据集。"
        }
    },
    {
        "translation": {
            "en": "So the probability of DICE1 = given that DICE2 = would be written as",
            "zh": "因此，DICE1 = 的概率给定 DICE2 = 将写为"
        }
    },
    {
        "translation": {
            "en": "-0.19558",
            "zh": "-0.19558"
        }
    },
    {
        "translation": {
            "en": "We use the term rem(d, ) to denote this quantity and define it formally",
            "zh": "我们使用术语 rem（d， ） 来表示这个量并正式定义它"
        }
    },
    {
        "translation": {
            "en": "Toward the end of the chapter, we introduce some more advanced data exploration techniques that, although not part of the standard data quality report, can be useful at this stage of an analytics project and present some data preparation techniques that can be applied to the data in an ABT prior to modeling.",
            "zh": "在本章的最后，我们将介绍一些更高级的数据探索技术，这些技术虽然不是标准数据质量报告的一部分，但在分析项目的这个阶段很有用，并介绍了一些数据准备技术，这些技术可以在建模之前应用于 ABT 中的数据。"
        }
    },
    {
        "translation": {
            "en": "To enable the naive Bayes model to handle the ACCOUNT BALANCE feature, we have to extend the set of probabilities used by the model to represent the domain to include the probabilities for this feature.",
            "zh": "为了使朴素贝叶斯模型能够处理 ACCOUNT BALANCE 特征，我们必须扩展模型用于表示域的概率集，以包含此特征的概率。"
        }
    },
    {
        "translation": {
            "en": "38. This census dataset is based on the Census Income Dataset (Kohavi, 1996), which is available from the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Census+Income/.",
            "zh": "38. 该人口普查数据集以人口普查收入数据集（Kohavi，1996年）为基础，该数据集可从 archive.ics.uci.edu/ml/datasets/Census+Income/ 的UCI机器学习资料库（Bache和Lichman，2013年）获得。"
        }
    },
    {
        "translation": {
            "en": "Starting on the right, we calculate ∂ℰ/∂ot per Equation (8.118)[516] and then backpropagate this through the output gate elementwise product to calculate ∂ℰ/∂o‡ (Equation (8.119)[516]) and ∂ℰ/∂o‡ (Equation (8.120)[516]).",
            "zh": "从右边开始，我们根据方程 （8.118）[516] 计算 ∂E/∂ot，然后通过输出门逐元乘积反向传播以计算 ∂E/∂o‡（方程 （8.119）[516]）和 ∂E/∂o‡（方程 （8.120）[516]）。"
        }
    },
    {
        "translation": {
            "en": "0.66",
            "zh": "0.66"
        }
    },
    {
        "translation": {
            "en": "We reiterate the factors required to represent the full joint distribution for the meningitis diagnosis scenario when we assume that the descriptive features are conditionally independent given the target, this time including the actual probabilities calculated from the dataset:",
            "zh": "当我们假设描述性特征在给定目标的情况下是有条件独立的时，我们重申了表示脑膜炎诊断场景的完整关节分布所需的因素，这次包括从数据集计算的实际概率："
        }
    },
    {
        "translation": {
            "en": "3.2.2 Case Study: Motor Insurance Fraud",
            "zh": "3.2.2 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "With regard to the network training, take care with the weight initialization process, and it is generally a good idea to include dropout.",
            "zh": "关于网络训练，注意权重初始化过程，通常最好包括 dropout。"
        }
    },
    {
        "translation": {
            "en": "This means that if we represent a set of input vectors as a matrix of inputs, we can get the network to process all the inputs in parallel.",
            "zh": "这意味着，如果我们将一组输入向量表示为输入矩阵，我们可以让网络并行处理所有输入。"
        }
    },
    {
        "translation": {
            "en": "8.5 Summary",
            "zh": "8.5 小结"
        }
    },
    {
        "translation": {
            "en": "Figure 9.6",
            "zh": "图 9.6"
        }
    },
    {
        "translation": {
            "en": "The final domain concept diagram is shown in Figure 13.4[712].",
            "zh": "最终的领域概念图如图13.4[712]所示。"
        }
    },
    {
        "translation": {
            "en": "To combat overfitting, we allow algorithms to train models beyond this point but save the model generated at each iteration.",
            "zh": "为了防止过拟合，我们允许算法训练超过这一点的模型，但保存每次迭代时生成的模型。"
        }
    },
    {
        "translation": {
            "en": "12.1   Business Understanding",
            "zh": "12.1 业务理解"
        }
    },
    {
        "translation": {
            "en": "The management of a large hospital group are concerned about the readmission rate for patients who are hospitalized with problems relating to diabetes.",
            "zh": "一家大型医院集团的管理层担心因糖尿病相关问题住院的患者的再入院率。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.3",
            "zh": "图 13.3"
        }
    },
    {
        "translation": {
            "en": "Working from the right of the equation, first we calculate ∂ℰ/∂ak by subtracting ak from tk and multiplying the result by − 1.",
            "zh": "从等式的右边开始，首先我们通过从 tk 中减去 ak 并将结果乘以 − 1 来计算 ∂E/∂ak。"
        }
    },
    {
        "translation": {
            "en": "The different question sequences that can follow in a game of Guess Who beginning with the question Does the person wear glasses?",
            "zh": "猜猜谁游戏中可以遵循的不同问题序列，从问题开始：这个人戴眼镜吗？"
        }
    },
    {
        "translation": {
            "en": "8.18   The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390] when all the neurons are ReLUs.",
            "zh": "8.18 当所有神经元都是ReLU时，表8.3[423]中列出的示例通过图8.4[390]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms address this issue by encoding an inductive bias—or set of assumptions—that guide the algorithm to prefer certain models over others.",
            "zh": "机器学习算法通过编码归纳偏差（或一组假设）来解决这个问题，这些偏差或假设引导算法优先选择某些模型而不是其他模型。"
        }
    },
    {
        "translation": {
            "en": "In this section we work through an example to illustrate how the ID3 is used to induce a decision tree.",
            "zh": "在本节中，我们将通过一个示例来说明如何使用 ID3 来诱导决策树。"
        }
    },
    {
        "translation": {
            "en": "By contrast, a discriminative model works by",
            "zh": "相比之下，判别模型的工作原理是"
        }
    },
    {
        "translation": {
            "en": "where is the normalized feature value, ai is the original value, ā is the mean for feature a, and sd(a) is the standard deviation for a. Standardizing feature values in this ways squashes the values of the feature so that the feature values have a mean of 0 and a standard deviation of 1.",
            "zh": "其中 是归一化特征值，ai 是原始值，ā 是特征 A 的平均值，sd（a） 是 a 的标准差。以这种方式标准化特征值会压缩特征值，使特征值的平均值为 0，标准差为 1。"
        }
    },
    {
        "translation": {
            "en": "A.3 Populations and Samples",
            "zh": "A.3 种群和样本"
        }
    },
    {
        "translation": {
            "en": "If H is the size of the hidden state, and the input x has a dimension of n (in this example n = 1), then the dimensions of the weight matrices in the forget gate and input gate (W(f), W(i†), and W(i‡)) and the sigmoid layer in the output gate (W(o†)), including bias terms is: H × (1 + n + H).",
            "zh": "如果 H 是隐藏状态的大小，并且输入 x 的维数为 n（在本例中为 n = 1），则遗忘门和输入门 （W（f）、W（i†） 和 W（i‡）） 中的权重矩阵和输出门 （W（o†）） 中的 s 形结肠层（包括偏置项）的维数为： H × （1 + n + H）。"
        }
    },
    {
        "translation": {
            "en": "Given the sensitivity of the algorithm to the value of k, how should we set this parameter?",
            "zh": "鉴于算法对 k 值的敏感性，我们应该如何设置这个参数？"
        }
    },
    {
        "translation": {
            "en": "Burges (1998) is still a good, freely available tutorial on support vector machines. For more details, Cristianini and Shawe-Taylor (2000) is a well-respected textbook on the topic and covers the extensions mentioned in Section 7.4.7[361], while Vapnik (2000) gives a good overview of the theoretical underpinnings of support vector machines.",
            "zh": "Burges （1998） 仍然是一个关于支持向量机的很好的、免费提供的教程。有关更多详细信息，Cristianini 和 Shawe-Taylor （2000） 是一本关于该主题的备受推崇的教科书，涵盖了第 7.4.7 节中提到的扩展[361]，而 Vapnik （2000） 很好地概述了支持向量机的理论基础。"
        }
    },
    {
        "translation": {
            "en": "where ∑i P(Xi) should be interpreted as summing over the set of events that are a complete assignment to the features in X. The reason that the division functions as a normalization mechanism is that the prior probability of the evidence, P(Y), is not conditional on Xi, and as a result, it is constant for all Xi.",
            "zh": "其中 ∑i P（习） 应解释为对 X 中特征的完整赋值的事件集求和。划分作为归一化机制的原因是证据的先验概率 P（Y） 不以 习 为条件，因此，它对所有 习 都是恒定的。"
        }
    },
    {
        "translation": {
            "en": "Richter, Michael M., and Rosina O. Weber. 2013. Case-based reasoning: A textbook. Springer.",
            "zh": "Richter、Michael M. 和 Rosina O. Weber。2013. 基于案例的推理：一本教科书.斯普林格。"
        }
    },
    {
        "translation": {
            "en": "We can illustrate how machine learning is an ill-posed problem using an example in which the analytics team at a supermarket chain wants to be able to classify customer households into the demographic groups single, couple, or family, solely on the basis of their shopping habits.4 The dataset given in Table 1.3[9] contains descriptive features describing the shopping habits of five customers.",
            "zh": "我们可以通过一个例子来说明机器学习如何成为一个病态的问题，在这个例子中，一家连锁超市的分析团队希望能够仅根据他们的购物习惯将客户家庭分类为单身、夫妻或家庭的人口统计群体.4 表 1.3[9] 中给出的数据集包含描述五个客户购物习惯的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "For example, for the analytics solutions proposed for the motor insurance fraud scenario, the prediction subject of the claim prediction and payment prediction models would be an insurance claim; for the member prediction model, the prediction subject would be a member; and for the application prediction model, it would be an application.",
            "zh": "例如，对于针对汽车保险欺诈场景提出的分析解决方案，索赔预测和付款预测模型的预测主体将是保险索赔;对于成员预测模型，预测主体为成员;对于应用程序预测模型，它将是一个应用程序。"
        }
    },
    {
        "translation": {
            "en": "Table 8.14[464] illustrates the calculation of the softmax function for a vector of three logits (i.e., three z values),",
            "zh": "表 8.14[464] 说明了 softmax 函数对三个 logits 向量（即三个 z 值）的计算，"
        }
    },
    {
        "translation": {
            "en": "sampling bias, 12",
            "zh": "采样偏差，12"
        }
    },
    {
        "translation": {
            "en": "12. See Chapter 8[381] for descriptions of these different activation functions.",
            "zh": "12. 有关这些不同激活函数的描述，请参阅第 8 章[381]。"
        }
    },
    {
        "translation": {
            "en": "Discuss the strength of the relationships shown in each visualization.",
            "zh": "讨论每个可视化中显示的关系的强度。"
        }
    },
    {
        "translation": {
            "en": "The conditional independence assumption means that naive Bayes models use very few parameters to represent a domain.",
            "zh": "条件独立性假设意味着朴素贝叶斯模型使用很少的参数来表示域。"
        }
    },
    {
        "translation": {
            "en": "Last, a conditional probability refers to the probability of one feature taking a specific value given that we already know the value of a different feature, for example, P(MENINGITIS = true | HEADACHE = true) = 0.2857.",
            "zh": "最后，条件概率是指一个特征取特定值的概率，假设我们已经知道另一个特征的值，例如，P（MENINGITIS = true |头痛 = 真） = 0.2857。"
        }
    },
    {
        "translation": {
            "en": "The decision tree that would be generated for the vegetation classification dataset listed in Table 4.9[147] using information gain.",
            "zh": "使用信息增益为表4.9[147]中列出的植被分类数据集生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "As we noted in our discussion regarding handling time, the motor insurance claim prediction scenario is a good example of a situation in which the observation period and outcome period are measured over different dates for each insurance claim (the prediction subject for this case study).",
            "zh": "正如我们在关于处理时间的讨论中所指出的，汽车保险索赔预测场景是一个很好的例子，其中观察期和结果期是在每个保险索赔的不同日期（本案例研究的预测主题）上测量的。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, for the purpose of simplifying the discussion and examples in this section, we drop the bias term in this figure and throughout most of this section.",
            "zh": "此外，为了简化本节中的讨论和示例，我们删除了本图和本节大部分内容中的偏差项。"
        }
    },
    {
        "translation": {
            "en": "We can see this easily in Figure 5.10(b)[201], as d15 is well outside the target hypersphere.",
            "zh": "我们可以在图5.10（b）[201]中很容易看到这一点，因为d15远远超出目标超球体。"
        }
    },
    {
        "translation": {
            "en": "Given that it is the policy, π, that determines which action an agent will take in a given state, it is reasonable to assume that if an agent follows different policies, then the agent can expect to earn different levels of return—some higher and some lower.",
            "zh": "鉴于政策π决定了代理人在给定状态下将采取的行动，因此可以合理地假设，如果代理人遵循不同的政策，那么代理人可以期望获得不同水平的回报——有些更高，有些更低。"
        }
    },
    {
        "translation": {
            "en": "Also, the decision boundary is much smoother than the decision boundaries of the other models we have looked at in this section.",
            "zh": "此外，决策边界比我们在本节中查看的其他模型的决策边界要平滑得多。"
        }
    },
    {
        "translation": {
            "en": "9.4.5.2 Domain independent measures of error The fact that root mean squared error and mean absolute error are in the same units as the target feature itself can be attractive, as it gives a very intuitive measure of how well a model is performing—for example, a model is typically 1.38mg out in its dosage predictions.",
            "zh": "9.4.5.2 与域无关的误差度量 均方根误差和平均绝对误差与目标特征本身的单位相同这一事实可能很有吸引力，因为它可以非常直观地衡量模型的性能，例如，模型的剂量预测通常为 1.38mg。"
        }
    },
    {
        "translation": {
            "en": "Therefore, to align with this general terminology, for this discussion we switch from discussing z values for a neuron to discussing the logit of the neuron.",
            "zh": "因此，为了与这个通用术语保持一致，在本次讨论中，我们从讨论神经元的 z 值切换到讨论神经元的 logit。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, beyond highlighting that the Jaccard index is useful for sparse binary data, we cannot give a hard and fast rule for how to choose between these indexes.",
            "zh": "不幸的是，除了强调 Jaccard 索引对稀疏二进制数据有用之外，我们无法给出如何在这些索引之间进行选择的硬性规则。"
        }
    },
    {
        "translation": {
            "en": "8.5   Summary",
            "zh": "8.5 小结"
        }
    },
    {
        "translation": {
            "en": "As the decision boundary is a linear separator, it can be defined using the equation of the line (remember Equation (7.2.1)[313]).",
            "zh": "由于决策边界是线性分隔符，因此可以使用直线方程来定义（记住方程（7.2.1）[313]）。"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.11[278], extended to include the conditional probabilities for the new ACCOUNT BALANCE feature, which are defined in terms of PDFs.",
            "zh": "朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表 6.11[278] 中的数据集计算得出，扩展为包括新的 ACCOUNT BALANCE 特征的条件概率，这些概率是根据 PDF 定义的。"
        }
    },
    {
        "translation": {
            "en": "The behavior policy used was ε greedy, but linear annealing was also used.",
            "zh": "使用的行为策略ε贪婪，但也使用了线性退火。"
        }
    },
    {
        "translation": {
            "en": "A dot product of two high-dimensional vectors is a computationally expensive operation, but a clever trick—the kernel trick—is used to avoid it.",
            "zh": "两个高维向量的点积是一项计算成本高昂的操作，但使用了一个聪明的技巧——核技巧——来避免它。"
        }
    },
    {
        "translation": {
            "en": "negative",
            "zh": "阴性"
        }
    },
    {
        "translation": {
            "en": "So to obtain independent sample states, we often sub-sample from the sequence (sub-sampling in this way is also known as thinning).",
            "zh": "因此，为了获得独立的采样状态，我们经常从序列中进行子采样（这种方式的子采样也称为稀释）。"
        }
    },
    {
        "translation": {
            "en": "The depth of a neural network is equal to the number of hidden layers plus the output layer.",
            "zh": "神经网络的深度等于隐藏层数加上输出层。"
        }
    },
    {
        "translation": {
            "en": "A matrix is a 2-dimensional (n × m) array of numbers.",
            "zh": "矩阵是二维 （n × m） 数字数组。"
        }
    },
    {
        "translation": {
            "en": "Several different linkage methods for AHC exist in the literature; some of the most common are",
            "zh": "文献中存在几种不同的AHC连接方法;一些最常见的是"
        }
    },
    {
        "translation": {
            "en": "Using the distance weighted k nearest neighbor approach, the prediction returned for a given query is the target level with the highest score when we sum the weights of the votes of the instances in the neighborhood of k nearest neighbors for each target level. The weighted k nearest neighbor model is defined as",
            "zh": "使用距离加权 k 最近邻方法，当我们将每个目标水平的 k 个最近邻邻域中的实例的投票权重相加时，为给定查询返回的预测是得分最高的目标级别。加权 k 最近邻模型定义为"
        }
    },
    {
        "translation": {
            "en": "Jaynes, Edwin T. 2003. Probability theory: The logic of science. Cambridge University Press.",
            "zh": "杰恩斯，埃德温 T. 2003 年。概率论：科学的逻辑。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "APERFLUX7_U/G/R/I/Z",
            "zh": "APERFLUX7_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Because this is the initial descent down the tree, best is automatically set to d12, and best-distance is set to the distance between instance d12 and the query, which is 1.4142 (we use Euclidean distance throughout this example).",
            "zh": "因为这是树的初始下降，所以 best 会自动设置为 d12，best-distance 设置为实例 d12 和查询之间的距离，即 1.4142（我们在此示例中使用欧几里得距离）。"
        }
    },
    {
        "translation": {
            "en": "For Model 2, we need to look almost as far as the top 50% of predictions to find the same percentage of spam messages.",
            "zh": "对于模型 2，我们需要查看几乎与前 50% 的预测一样远，才能找到相同百分比的垃圾邮件。"
        }
    },
    {
        "translation": {
            "en": "This structure directly reflects the assumption, made by naive Bayes models, of the conditional independence between descriptive features given knowledge of the target feature and is why the conditional probabilities of the descriptive features in a naive Bayes model are conditioned only on the target feature.",
            "zh": "这种结构直接反映了朴素贝叶斯模型在给定目标特征知识的情况下描述性特征之间的条件独立性的假设，这就是为什么朴素贝叶斯模型中描述性特征的条件概率仅以目标特征为条件的原因。"
        }
    },
    {
        "translation": {
            "en": "6.13   A Bayesian network that encodes the causal relationships between the features in the corruption domain. The CPT entries have been calculated using the binned data from Table 6.18[295].",
            "zh": "6.13 贝叶斯网络，用于编码损坏域中特征之间的因果关系。CPT条目是使用表6.18[295]中的分箱数据计算的。"
        }
    },
    {
        "translation": {
            "en": "where n is the number of instances in the training dataset. A standard error calculation is then done for a descriptive feature as follows:",
            "zh": "其中 n 是训练数据集中的实例数。然后对描述性特征进行标准误差计算，如下所示："
        }
    },
    {
        "translation": {
            "en": "Most of the deep network models described in Chapter 8[381] are also discriminative models, although the auto-encoder network described in Chapter 10[597] is a nice example of a generative neural network.",
            "zh": "尽管第10章[597]中描述的自动编码器网络是生成神经网络的一个很好的例子，但第8章[381]中描述的大多数深度网络模型也是判别模型。"
        }
    },
    {
        "translation": {
            "en": "Returning to the motor insurance fraud detection case study, below we evaluate the feasibility of each proposed analytics solution in terms of data and business capacity requirements.",
            "zh": "回到汽车保险欺诈检测案例研究，下面我们从数据和业务容量要求的角度评估每个拟议的分析解决方案的可行性。"
        }
    },
    {
        "translation": {
            "en": "This process is repeated until all the instances in a partition have the same target level, at which point a leaf node is created and labeled with that level.",
            "zh": "重复此过程，直到分区中的所有实例都具有相同的目标级别，此时将创建一个叶节点并使用该级别进行标记。"
        }
    },
    {
        "translation": {
            "en": "4.12   The partitioning of the dataset in Table 4.11[152] based on SEASON and WORK DAY features and the computation of the weighted variance for each partitioning.",
            "zh": "4.12 表4.11[152]中基于SEASON和WORK DAY特征的数据集分区，以及每个分区的加权方差计算。"
        }
    },
    {
        "translation": {
            "en": "Table 7.8",
            "zh": "表 7.8"
        }
    },
    {
        "translation": {
            "en": "cross-sell model, 572",
            "zh": "交叉销售模型，572"
        }
    },
    {
        "translation": {
            "en": "Using a hold-out test set avoids this problem, because none of the instances in the test set will have been used in the training process.",
            "zh": "使用保留测试集可以避免此问题，因为测试集中的任何实例都不会在训练过程中使用。"
        }
    },
    {
        "translation": {
            "en": "Consequently, to connect the activation of a hidden neuron ak to the network error ℰ, we have to create a chain of connection via the activations of the downstream neurons.",
            "zh": "因此，为了将隐藏神经元 ak 的激活与网络错误 E 联系起来，我们必须通过激活下游神经元来创建连接链。"
        }
    },
    {
        "translation": {
            "en": "It is important that the details of any data preparation techniques we perform on the data in the ABT be saved (usually in the data quality plan) so that we can also apply the same techniques to newly arising data.",
            "zh": "重要的是，我们对 ABT 中的数据执行的任何数据准备技术的详细信息都应保存（通常在数据质量计划中），以便我们也可以将相同的技术应用于新出现的数据。"
        }
    },
    {
        "translation": {
            "en": "Using basis functions is a simple and effective way in which to capture non-linear relationships within a linear regression model.",
            "zh": "使用基函数是捕获线性回归模型中非线性关系的一种简单有效的方法。"
        }
    },
    {
        "translation": {
            "en": "We don’t know exactly what state an agent will arrive in after taking action at from state st, but from the transition matrix, at, we do know the probability of each possible transition between states, .",
            "zh": "我们不知道代理在从状态 st 采取行动后将到达什么状态，但从转换矩阵 at 中，我们确实知道状态之间每个可能的转换的概率。"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 8.32[481] shows a second neuron with a different local receptive field, and Equation (8.87)[482] shows the calculation of the activation of this neuron if it uses the same set of weights.",
            "zh": "例如，图8.32[481]显示了具有不同局部感受野的第二个神经元，而方程（8.87）[482]显示了如果该神经元使用相同的权重集，则该神经元的激活计算。"
        }
    },
    {
        "translation": {
            "en": "Comparing Table 8.8[433] with Table 8.4[426], we see that the model made a slightly different prediction for each example; the prediction for d2 is now 0.4741 whereas the original prediction was 0.4718.",
            "zh": "将表8.8[433]与表8.4[426]进行比较，我们发现模型对每个示例的预测略有不同;D2的预测现在是0.4741，而最初的预测是0.4718。"
        }
    },
    {
        "translation": {
            "en": "The last two layers of the network are typical of the types of layers that are used near the output of a convolutional network when it is used for image classification.",
            "zh": "网络的最后两层是卷积网络用于图像分类时在输出附近使用的典型层类型。"
        }
    },
    {
        "translation": {
            "en": "Alongside these descriptive features is a target feature, GRP, that describes the demographic group for each customer (single, couple, or family).",
            "zh": "除了这些描述性功能之外，还有一个目标功能 GRP，用于描述每个客户（单身、夫妻或家庭）的人口统计组。"
        }
    },
    {
        "translation": {
            "en": "Siddiqi, Naeem. 2005. Credit risk scorecards: Developing and implementing intelligent credit scoring. Wiley.",
            "zh": "西迪奇，纳伊姆。2005. 信用风险记分卡：开发和实施智能信用评分。威利。"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy scores achieved by the models were 54.663%, 62.137%, and 58.107% by the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "k最近邻模型、逻辑回归模型和支持向量机模型的平均类准确率得分分别为54.663%、62.137%和58.107%。"
        }
    },
    {
        "translation": {
            "en": "The overall accuracy of this model is somewhat comparable with the overall accuracy of the 3-level model.",
            "zh": "该模型的整体精度与三电平模型的整体精度相当。"
        }
    },
    {
        "translation": {
            "en": "data manipulation tools, 42",
            "zh": "数据操作工具，42"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE features was found to be valid, because these are categorical features and can only take values in a small range, as people tend not to make very many claims.",
            "zh": "SOFT TISSUE 特征被发现是有效的，因为这些是分类特征，并且只能在很小的范围内取值，因为人们往往不会提出很多主张。"
        }
    },
    {
        "translation": {
            "en": "One of the difficulties with learning a network structure is that we can always improve the likelihood of the data given a network by simply adding new links into the network.",
            "zh": "学习网络结构的困难之一是，我们总是可以通过简单地在网络中添加新链接来提高给定网络数据的可能性。"
        }
    },
    {
        "translation": {
            "en": "11.4.2 Deep Q Networks",
            "zh": "11.4.2 Deep Q 网络"
        }
    },
    {
        "translation": {
            "en": "The reason for its fame is that its victory in the ImageNet LargeScale Visual Recognition Challenges (ILSVRC) in 2012 was a watershed moment for deep learning that reinvigorated a lot of interest in the field of neural networks.",
            "zh": "它之所以成名，是因为它在 2012 年的 ImageNet 大规模视觉识别挑战赛 （ILSVRC） 中的胜利是深度学习的分水岭，重新激发了人们对神经网络领域的浓厚兴趣。"
        }
    },
    {
        "translation": {
            "en": "The curved shape of the harmonic mean surface shows that the harmonic mean emphasizes the contribution of smaller values more than the arithmetic mean—note how the sides of the surface are pulled down to the base of the graph by the harmonic mean.",
            "zh": "谐波平均曲面的弯曲形状表明，谐波均值比算术均值更强调较小值的贡献 - 请注意，谐波均值如何将曲面的侧面拉到图形的底部。"
        }
    },
    {
        "translation": {
            "en": "Recognizing that a feature follows an exponential distribution is another clear warning sign that outliers are likely.",
            "zh": "识别特征遵循指数分布是另一个明确的警告信号，表明可能存在异常值。"
        }
    },
    {
        "translation": {
            "en": "0.3668",
            "zh": "0.3668"
        }
    },
    {
        "translation": {
            "en": "These initial baseline results were promising; however, one key issue did emerge.",
            "zh": "这些初步基线结果是有希望的;然而，一个关键问题确实出现了。"
        }
    },
    {
        "translation": {
            "en": "The reason is that the MNIST handwriting recognition case study we are using in this section involves grayscale images.",
            "zh": "原因是我们在本节中使用的 MNIST 手写识别案例研究涉及灰度图像。"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning, and its Q-learning (off-policy) and SARSA (on-policy) variants, are standard approaches to reinforcement learning and have been used effectively in a variety of environments.",
            "zh": "时间差分学习及其 Q 学习（策略外）和 SARSA（策略内）变体是强化学习的标准方法，并已在各种环境中有效使用。"
        }
    },
    {
        "translation": {
            "en": "If the errors show that, in general, predictions made by the candidate model are too high, then w[j] should be decreased if di[j] is positive and increased if di[j] is negative.",
            "zh": "如果误差表明，一般来说，候选模型的预测值太高，那么如果 di[j] 为正，则 w[j] 应减小，如果 di[j] 为负，则应增加。"
        }
    },
    {
        "translation": {
            "en": "P_ACW",
            "zh": "P_ACW"
        }
    },
    {
        "translation": {
            "en": "A portion of the action-value table for the grid world example after 350 episodes of Q-learning have elapsed.",
            "zh": "在 350 集 Q 学习之后，网格世界示例的操作值表的一部分已经过去。"
        }
    },
    {
        "translation": {
            "en": "6.9   (a) A Bayesian network for a domain consisting of two binary features. The structure of the network states that the value of feature A directly influences the value of feature B. (b) A Bayesian network consisting of four binary features with a path containing three generations of nodes: D, C, and B.",
            "zh": "6.9 （a） 由两个二进制特征组成的域的贝叶斯网络。（b） 贝叶斯网络，由四个二进制特征组成，其路径包含三代节点：D、C 和 B。"
        }
    },
    {
        "translation": {
            "en": "The columns labeled i(d) give the predictions made by the model trained at iteration i for each instance in the training dataset.",
            "zh": "标记为 i（d） 的列给出了在迭代 i 中训练的模型对训练数据集中每个实例所做的预测。"
        }
    },
    {
        "translation": {
            "en": "4.2 Fundamentals",
            "zh": "4.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "No model will ever be perfect, so some fraction of the predictions made by every model will be incorrect.",
            "zh": "没有一个模型是完美的，因此每个模型所做的预测中都有一部分是不正确的。"
        }
    },
    {
        "translation": {
            "en": "As with all tree representations, a decision tree consists of a root node (or starting node), interior nodes, and leaf nodes (or terminating nodes) that are connected by branches.",
            "zh": "与所有树表示一样，决策树由根节点（或起始节点）、内部节点和叶节点（或终止节点）组成，这些节点由分支连接。"
        }
    },
    {
        "translation": {
            "en": "To calculate L2 we use our candidate model w to make a prediction for each member of the training dataset, , and then calculate the error (or residual) between these predictions and the actual target feature values in the training set.",
            "zh": "为了计算 L2，我们使用候选模型 w 对训练数据集的每个成员进行预测，然后计算这些预测与训练集中的实际目标特征值之间的误差（或残差）。"
        }
    },
    {
        "translation": {
            "en": "We use the notation l to denote a vector of logits for a layer of neurons, and li to indicate the logit for the ith neuron in the layer.",
            "zh": "我们使用符号 l 表示一层神经元的 logits 向量，并使用 li 表示该层中第 i 个神经元的 logit。"
        }
    },
    {
        "translation": {
            "en": "Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research 15 (1): 1929–1958.",
            "zh": "斯里瓦斯塔瓦、尼蒂什、杰弗里·辛顿、亚历克斯·克里热夫斯基、伊利亚·苏茨克弗和鲁斯兰·萨拉胡迪诺夫。2014. Dropout：一种防止神经网络过拟合的简单方法。机器学习研究杂志 15 （1）： 1929–1958."
        }
    },
    {
        "translation": {
            "en": "Lift can take values in the range [0,∞], and higher values indicate that a model is performing well at a particular decile.",
            "zh": "提升可以取 [0，∞] 范围内的值，较高的值表示模型在特定十分位数上表现良好。"
        }
    },
    {
        "translation": {
            "en": "A probability function is a function that takes an event (an assignment of values to features) as a parameter and returns the likelihood of that event.",
            "zh": "概率函数是将事件（为要素赋值）作为参数并返回该事件的可能性的函数。"
        }
    },
    {
        "translation": {
            "en": "In this appendix we present the basic differentiation techniques that are required to understand how linear regression can be used to build predictive analytics models. In particular we explain what a derivative is, how to calculate derivatives for continuous functions, the chain rule for differentiation, and what a partial derivative is.",
            "zh": "在本附录中，我们将介绍了解如何使用线性回归构建预测分析模型所需的基本微分技术。特别是，我们解释了什么是导数，如何计算连续函数的导数，微分的链式法则以及什么是偏导数。"
        }
    },
    {
        "translation": {
            "en": "7.3.1   Multivariable Linear Regression",
            "zh": "7.3.1 多变量线性回归"
        }
    },
    {
        "translation": {
            "en": "Given that the preceding analysis in Section 8.2.4[394] showed that a network with multiple layers of linear neurons is equivalent to a single-layer network of linear functions, a natural question is, why is adding extra layers to a network (even with non-linearities) a useful thing to do?",
            "zh": "鉴于前面在第8.2.4节[394]中的分析表明，具有多层线性神经元的网络等同于线性函数的单层网络，一个自然的问题是，为什么向网络添加额外的层（即使具有非线性）是一件有用的事情？"
        }
    },
    {
        "translation": {
            "en": "As a result, the CPT representation is sufficient to handle both categorical and (binned) continuous features.",
            "zh": "因此，CPT 表示足以处理分类特征和（分箱）连续特征。"
        }
    },
    {
        "translation": {
            "en": "Table 12.2",
            "zh": "表 12.2"
        }
    },
    {
        "translation": {
            "en": "channel, 492",
            "zh": "频道，492"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, adding nodes in this way results in the tree becoming unbalanced, which can have a detrimental effect on the efficiency of the tree.",
            "zh": "不幸的是，以这种方式添加节点会导致树变得不平衡，这可能会对树的效率产生不利影响。"
        }
    },
    {
        "translation": {
            "en": "where the inverse covariance matrix used in the calculations is based on the covariance matrix24 calculated directly from the dataset:",
            "zh": "其中，计算中使用的逆协方差矩阵基于直接从数据集计算的协方差矩阵24："
        }
    },
    {
        "translation": {
            "en": "With the target feature suitably defined, Ross’s next task was to determine the domain concepts that would underpin the design of the ABT.",
            "zh": "在正确定义了目标功能后，Ross 的下一个任务是确定支撑 ABT 设计的领域概念。"
        }
    },
    {
        "translation": {
            "en": "Burglary is also rare, and if it is a stormy night, burglars are likely to stay at home (burglars don’t like going out in storms).",
            "zh": "入室盗窃也很少见，如果是暴风雨的夜晚，窃贼很可能会呆在家里（窃贼不喜欢在暴风雨中外出）。"
        }
    },
    {
        "translation": {
            "en": "12. In interval notation, a square bracket, [ or ], indicates that the boundary value is included in the interval, and a parenthesis, ( or ), indicates that it is excluded from the interval.",
            "zh": "12. 在区间表示法中，方括号 [ 或 ]， 表示边界值包含在区间中，括号 （ 或 ） 表示它被排除在区间之外。"
        }
    },
    {
        "translation": {
            "en": "The bad news is that the patient has tested positive for a serious disease and that the test the doctor used is 99% accurate (i.e., the probability of testing positive when a patient has the disease is 0.99, as is the probability of testing negative when a patient does not have the disease).",
            "zh": "坏消息是，患者对严重疾病的检测呈阳性，而医生使用的检测准确率为 99%（即，当患者患有疾病时检测呈阳性的概率为 0.99，当患者没有疾病时检测呈阴性的概率也是如此）。"
        }
    },
    {
        "translation": {
            "en": "Each non-leaf node (root and interior) in the tree specifies a test to be carried out on a descriptive feature.",
            "zh": "树中的每个非叶节点（根节点和内部节点）都指定要对描述性特征执行的测试。"
        }
    },
    {
        "translation": {
            "en": "Mr. Murphy walked to the kitchen to have a look and agreed with his son that he too had done a great job of organizing the letters.",
            "zh": "墨菲先生走到厨房看了看，并同意儿子的意见，说他在整理信件方面也做得很好。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13[410] illustrates this relationship between the slope of the graph of a function and its derivative.",
            "zh": "图8.13[410]说明了函数图的斜率与其导数之间的这种关系。"
        }
    },
    {
        "translation": {
            "en": "The AHC algorithm begins by considering each instance in a dataset to be the only member of a cluster, which gives n initial clusters, 𝒞1 to 𝒞n. The two clusters that are nearest are then merged (or agglomerated) to form a new cluster. This process repeats over and over until a single cluster containing all instances in the dataset is formed. Figure 10.10[617] shows how AHC can be used for find the intuitive clusterings in the half-moons and circles datasets as well as the blobs dataset.",
            "zh": "AHC 算法首先将数据集中的每个实例视为集群的唯一成员，这给出了 n 个初始集群，从 C1 到 Cn。然后，将最近的两个集群合并（或聚集）以形成一个新集群。此过程一遍又一遍地重复，直到形成包含数据集中所有实例的单个集群。图 10.10[617] 显示了如何使用 AHC 在半月和圆数据集以及 blobs 数据集中查找直观的聚类。"
        }
    },
    {
        "translation": {
            "en": "8.1   Big Idea",
            "zh": "8.1 大创意"
        }
    },
    {
        "translation": {
            "en": "An illustration of how different small networks are generated for different training examples by applying dropout to the original large network. The gray nodes mark the neurons that have been dropped from the network for the training example.",
            "zh": "通过对原始大型网络应用dropout，如何为不同的训练示例生成不同的小型网络的说明。灰色节点标记了已从网络中删除的神经元，以用于训练示例。"
        }
    },
    {
        "translation": {
            "en": "At this stage, these reconstructed images are already beginning to resemble the originals on which they are based.",
            "zh": "在这个阶段，这些重建的图像已经开始类似于它们所基于的原始图像。"
        }
    },
    {
        "translation": {
            "en": "ti refers to the value of the target feature of the ith instance in a dataset",
            "zh": "Ti 是指数据集中第 i 个实例的目标特征的值"
        }
    },
    {
        "translation": {
            "en": "23. See Equation (8.4)[386] and Figure 8.2[387].",
            "zh": "23. 参见公式（8.4）[386]和图8.2[387]。"
        }
    },
    {
        "translation": {
            "en": "The classification accuracies achieved during the cross validation experiment were 82.912%, 86.041%, and 85.942% by the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "在交叉验证实验中，k最近邻模型、逻辑回归和支持向量机模型的分类精度分别为82.912%、86.041%和85.942%。"
        }
    },
    {
        "translation": {
            "en": "The advantage of this is that learning can happen quickly as updates are made after each action the agent takes.",
            "zh": "这样做的好处是，学习可以快速进行，因为在代理采取的每个操作之后都会进行更新。"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm and other algorithms like it impose an expected global structure onto the clustering process—essentially, the k-means algorithm searches for tightly packed spherical clusters.",
            "zh": "k 均值聚类算法和其他类似算法将预期的全局结构强加给聚类过程，从本质上讲，k 均值算法搜索紧密堆积的球形聚类。"
        }
    },
    {
        "translation": {
            "en": "The word batch is used because only one adjustment is made to each weight at each iteration of the algorithm based on summing the squared error made by the candidate model for each instance in the training dataset.7 Batch gradient descent is a straightforward, accurate, and reasonably efficient approach to training multivariable linear regression models and is used widely in practice.",
            "zh": "之所以使用“批处理”一词，是因为在算法的每次迭代中，根据训练数据集中每个实例的候选模型所犯误差的平方相加，只对每个权重进行一次调整.7 批处理梯度下降是一种简单、准确且相当有效的训练多变量线性回归模型的方法，在实践中被广泛使用。"
        }
    },
    {
        "translation": {
            "en": "For example, Equation (6.1)[247] listed the joint probability distribution for the four binary features in the meningitis diagnosis dataset in Table 6.1[246].",
            "zh": "例如，方程（6.1）[247]在表6.1[246]中列出了脑膜炎诊断数据集中四个二元特征的联合概率分布。"
        }
    },
    {
        "translation": {
            "en": "2. The Manhattan distance, or taxi-cab distance, is so called because it is the distance that a taxi driver would have to cover if going from one point to another on a road system that is laid out in blocks, like the Manhattan road system.",
            "zh": "2. 曼哈顿距离，或出租车距离，之所以如此称呼，是因为它是出租车司机在分块布局的道路系统（如曼哈顿道路系统）上从一个点到另一个点时必须覆盖的距离。"
        }
    },
    {
        "translation": {
            "en": "Returning to 1798 and HMS Calcutta, the next day you accompany your men on the expedition up the river, and you encounter the strange animal the sailor had described to you. This time when you see the animal yourself, you realize that it definitely isn’t a duck! It turns out that you and your men are the first Europeans to encounter a platypus.33",
            "zh": "回到 1798 年和 HMS 加尔各答，第二天你陪你的手下沿河探险，你遇到了水手向你描述的奇怪动物。这一次，当你亲眼看到这只动物时，你意识到它绝对不是鸭子！事实证明，你和你的手下是第一批遇到鸭嘴兽的欧洲人33。"
        }
    },
    {
        "translation": {
            "en": "11.2.2 Fundamentals of Reinforcement Learning",
            "zh": "11.2.2 强化学习基础"
        }
    },
    {
        "translation": {
            "en": "430.37",
            "zh": "430.37"
        }
    },
    {
        "translation": {
            "en": "Machine learning is a huge topic, however, and one book can only be so long.",
            "zh": "然而，机器学习是一个巨大的话题，一本书只能这么长。"
        }
    },
    {
        "translation": {
            "en": "The typical value of a loan is $1,000, and the interest rate charged is 14%.",
            "zh": "贷款的典型价值为 1,000 美元，收取的利率为 14%。"
        }
    },
    {
        "translation": {
            "en": "If this is done correctly, then the total probability mass for the set will remain equal to 1.0, but the spread of probabilities across the set will be smoother (hence the name smoothing).",
            "zh": "如果操作正确，则集合的总概率质量将保持等于 1.0，但整个集合中的概率分布将更平滑（因此称为平滑）。"
        }
    },
    {
        "translation": {
            "en": "The easiest way to solve this problem is to employ a k nearest neighbor model, which uses a function of the target feature values of the k closest instances to a query.",
            "zh": "解决此问题的最简单方法是使用 k 最近邻模型，该模型使用查询最接近的 k 个实例的目标特征值的函数。"
        }
    },
    {
        "translation": {
            "en": "P_EL",
            "zh": "P_EL"
        }
    },
    {
        "translation": {
            "en": "Like stratified sampling, under-sampling begins by dividing a dataset into groups, where each group contains only instances that have a particular level for the feature to be under-sampled.",
            "zh": "与分层抽样一样，欠采样首先将数据集划分为多个组，其中每个组仅包含具有要欠采样的特征的特定级别的实例。"
        }
    },
    {
        "translation": {
            "en": "It is not always correct to treat all outcomes equally.",
            "zh": "平等对待所有结果并不总是正确的。"
        }
    },
    {
        "translation": {
            "en": "This is why the variance of z rapidly decreases for each layer as we move forward through the network as shown in Figure 8.23(b)[453].",
            "zh": "这就是为什么当我们在网络中前进时，每一层的 z 方差会迅速减小，如图 8.23（b）[453] 所示。"
        }
    },
    {
        "translation": {
            "en": "The second convolutional layer uses two filters (Filters 3 and 4) and so contains two layers of neurons that share weights.",
            "zh": "第二个卷积层使用两个滤波器（滤波器 3 和 4），因此包含两层共享权重的神经元。"
        }
    },
    {
        "translation": {
            "en": "They achieve this goal by removing the repeated multiplication by the Whh matrix during backpropagation.",
            "zh": "他们通过消除反向传播期间 Whh 矩阵的重复乘法来实现这一目标。"
        }
    },
    {
        "translation": {
            "en": "As a result, for any domain of reasonable complexity, it is not tractable to define the full joint probability distribution, and therefore probability-based prediction models build more compact representations of full joint probability distributions instead.",
            "zh": "因此，对于任何具有合理复杂度的领域，定义完整的联合概率分布都是不容易处理的，因此基于概率的预测模型会构建更紧凑的全联合概率分布表示。"
        }
    },
    {
        "translation": {
            "en": "The simplest way to prune a decision tree is to introduce early stopping criteria (similar to the early stopping criterion discussed in the preceding section) into the tree induction algorithm.",
            "zh": "修剪决策树的最简单方法是在树诱导算法中引入早期停止标准（类似于上一节中讨论的早期停止标准）。"
        }
    },
    {
        "translation": {
            "en": "Monte Carlo methods, 298, 677",
            "zh": "蒙特卡罗方法，298,677"
        }
    },
    {
        "translation": {
            "en": "8.3.2   Backpropagation: Backpropagating the Error Gradients",
            "zh": "8.3.2 反向传播：反向传播误差梯度"
        }
    },
    {
        "translation": {
            "en": "Patients are not aware which group they have been assigned to during the trial (hence the need for the placebo).",
            "zh": "患者不知道他们在试验期间被分配到哪一组（因此需要安慰剂）。"
        }
    },
    {
        "translation": {
            "en": "We calculate the numerator in this term as follows:",
            "zh": "我们计算该项中的分子如下："
        }
    },
    {
        "translation": {
            "en": "Figure 7.20",
            "zh": "图 7.20"
        }
    },
    {
        "translation": {
            "en": "This could be expressed in a single descriptive feature counting the number of claims that the claimant has made in the past.",
            "zh": "这可以用一个单一的描述性特征来表示，即计算索赔人过去提出的索赔数目。"
        }
    },
    {
        "translation": {
            "en": "This information can be useful in informing the development of more powerful models later in a project.",
            "zh": "这些信息可用于为项目后期更强大的模型的开发提供信息。"
        }
    },
    {
        "translation": {
            "en": "Examination of the histograms in Figures 3.1(c)[58] and 3.1(h)[58] show that the CLAIM AMOUNT and AMOUNT RECEIVED features have a number of large values (evidenced by the small bars to the right-hand side of these histograms) and that d302 is not unique.",
            "zh": "对图3.1（c）[58]和图3.1（h）[58]中的直方图的检查表明，CLAIM AMOUNT和AMOUNT RECEIVED特征具有许多大值（由这些直方图右侧的小条证明），并且d302不是唯一的。"
        }
    },
    {
        "translation": {
            "en": "These thresholded units are also known as perceptron networks (Rosenblatt, 1958); we introduce this terminology here because it is useful in the following discussion.",
            "zh": "这些阈值单元也称为感知器网络（Rosenblatt，1958）;我们在这里介绍这个术语，因为它在下面的讨论中很有用。"
        }
    },
    {
        "translation": {
            "en": "If a model has a relatively large weight on one input feature, then the output of the model can be very sensitive to small changes in the value of the feature and hence the outputs of the model can be very different for similar input vectors.",
            "zh": "如果模型在一个输入特征上具有相对较大的权重，则模型的输出可能对特征值的微小变化非常敏感，因此对于相似的输入向量，模型的输出可能会有很大不同。"
        }
    },
    {
        "translation": {
            "en": "3.6   A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "3.6 表3.7[73]中职业篮球队数据集中连续特征散点图的散点图矩阵。"
        }
    },
    {
        "translation": {
            "en": "Including this dummy feature makes the d and w vectors have the same length, and this allows us to write the equation as the dot product of the two vectors (i.e., w ·d).",
            "zh": "包括这个虚拟特征使 d 和 w 向量具有相同的长度，这使我们能够将方程写成两个向量（即 w ·d）的点积。"
        }
    },
    {
        "translation": {
            "en": "The reason that only the states immediately surrounding those that led to large positive or negative rewards reflect these rewards is that Q-learning, and temporal-difference learning in general, uses bootstrapping and updates Q values immediately after actions rather than waiting until the end of an episode.",
            "zh": "只有那些导致大量积极或消极奖励的状态才能反映这些奖励的原因是，Q学习和一般的时间差分学习使用引导并在行动后立即更新Q值，而不是等到一集结束。"
        }
    },
    {
        "translation": {
            "en": "depth of a neural network, 389",
            "zh": "神经网络的深度，389"
        }
    },
    {
        "translation": {
            "en": "where d[j] is some descriptive feature and d[j] is the mean value of that descriptive feature in the training set.",
            "zh": "其中 d[j] 是一些描述性特征，d[j] 是该描述性特征在训练集中的平均值。"
        }
    },
    {
        "translation": {
            "en": "8.4.4   Early Stopping and Dropout: Preventing Overfitting",
            "zh": "8.4.4 提前停止和退出：防止过拟合"
        }
    },
    {
        "translation": {
            "en": "This means that neurons with saturated activation functions can get stuck: their weights never change substantially during training because the incremental updates are either 0 or are tiny.",
            "zh": "这意味着具有饱和激活函数的神经元可能会被卡住：它们的权重在训练过程中永远不会发生实质性变化，因为增量更新要么为 0，要么很小。"
        }
    },
    {
        "translation": {
            "en": "Although for some simple problems, like those presented in our office rentals dataset, it is possible to try out every reasonable combination of weights and through this brute-force search find the best combination, for most real-world problems this is not feasible—the computation required would take far too long.",
            "zh": "虽然对于一些简单的问题，比如我们的办公室租赁数据集中出现的问题，可以尝试每一个合理的权重组合，并通过这种蛮力搜索找到最佳组合，但对于大多数现实世界的问题来说，这是不可行的——所需的计算将花费太长时间。"
        }
    },
    {
        "translation": {
            "en": "8.6   An illustration of how a batch of examples can be processed in parallel using matrix operations.",
            "zh": "8.6 说明如何使用矩阵运算并行处理一批示例。"
        }
    },
    {
        "translation": {
            "en": "expected reward, 651",
            "zh": "预期奖励，651"
        }
    },
    {
        "translation": {
            "en": "9.17   The structure of a confusion matrix for a multinomial prediction problem with l target levels.",
            "zh": "9.17 具有 l 个目标水平的多项式预测问题的混淆矩阵结构。"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 6.4(a)[273] follows a light tail distribution—the bars at the extreme left and right of the distribution have zero height.",
            "zh": "图6.4（a）[273]中的数据集遵循光尾分布，即分布最左边和最右边的条形高度为零。"
        }
    },
    {
        "translation": {
            "en": "7.17   A selection of the models developed during the gradient descent process for the grass growth dataset from Table 7.9[351].",
            "zh": "7.17 表7.9[351]中草生长数据集的梯度下降过程中开发的模型选择。"
        }
    },
    {
        "translation": {
            "en": "In both cases, the target feature level was set to the galaxy category that received the majority of the votes.",
            "zh": "在这两种情况下，目标特征级别都被设置为获得大多数选票的星系类别。"
        }
    },
    {
        "translation": {
            "en": "The target feature, RECIDIVIST, has a true value if the prisoner was arrested within two years of being released; otherwise it has a value of false.",
            "zh": "如果囚犯在获释后两年内被捕，则目标特征“累犯”具有真正的价值;否则，它的值为 false。"
        }
    },
    {
        "translation": {
            "en": "parent node, 286",
            "zh": "父节点，286"
        }
    },
    {
        "translation": {
            "en": "One way of judging similarity is to focus solely on co-presence. For example, in an online retail setting, co-presence could capture what two users jointly viewed, liked, or bought. The Russel-Rao similarity index focuses on this and is measured in terms of the ratio between the number of co-presences and the total number of binary features considered:",
            "zh": "判断相似性的一种方法是只关注共同存在。例如，在在线零售环境中，共同存在可以捕获两个用户共同查看、喜欢或购买的内容。Russel-Rao相似性指数关注这一点，并根据共存数量与所考虑的二元特征总数之间的比率来衡量："
        }
    },
    {
        "translation": {
            "en": "The algorithm assumes a dataset is available; it also requires that values for the learning rate α and the batch size B hyper-parameters have been selected.",
            "zh": "该算法假定数据集可用;它还要求已选择学习率α和批量大小 B 超参数的值。"
        }
    },
    {
        "translation": {
            "en": "In this case you can only assume that the queen is equally likely to be in any of the three possible positions: left, center, or right.",
            "zh": "在这种情况下，您只能假设女王同样可能处于三个可能位置中的任何一个：左、中或右。"
        }
    },
    {
        "translation": {
            "en": "To train a support vector machine, we need to find values for each of the components in Equation (7.41)[363] (the support vectors, w 0, and the α parameters) that define the optimal decision boundary between the target levels.",
            "zh": "为了训练支持向量机，我们需要找到方程（7.41）[363]中每个分量的值（支持向量、w 0 和 α 参数），这些分量定义了目标水平之间的最佳决策边界。"
        }
    },
    {
        "translation": {
            "en": "We explore the most important of these modifications in the following sections.",
            "zh": "我们将在以下各节中探讨这些修改中最重要的内容。"
        }
    },
    {
        "translation": {
            "en": "In other words, the δ term for a neuron is the partial derivative of the error of the network with respect to the weighted sum (z) of the neuron. The δs for all neurons in a network (irrespective of whether they are in the output layer or a hidden layer) are calculated as the product of two terms:",
            "zh": "换句话说，神经元δ项是网络误差相对于神经元加权和 （z） 的偏导数。网络中所有神经元（无论它们位于输出层还是隐藏层）的 δ 计算为两项的乘积："
        }
    },
    {
        "translation": {
            "en": "Algorithm 8[507] provides a pseudocode definition of the backpropagation through time algorithm for a single sequence of input-output pairs of length n.",
            "zh": "算法8[507]为长度为n的单个输入输出对序列提供了反向传播时间算法的伪代码定义。"
        }
    },
    {
        "translation": {
            "en": "When a relationship exists between the two features, the box plots should show differing central tendencies and variations.",
            "zh": "当两个特征之间存在关系时，箱形图应显示不同的中心趋势和变化。"
        }
    },
    {
        "translation": {
            "en": "More generally, we can mathematically define the weighted sum calculation",
            "zh": "更一般地说，我们可以用数学方式定义加权和计算"
        }
    },
    {
        "translation": {
            "en": "Another commonly used approach to setting the upper and lower thresholds is to use the mean value of a feature plus or minus 2 times the standard deviation.6 Again this works well, but it does assume that the underlying data follows a normal distribution.",
            "zh": "设置上限和下限阈值的另一种常用方法是使用特征的平均值正负标准差的 2 倍。6 同样，这很有效，但它确实假设基础数据遵循正态分布。"
        }
    },
    {
        "translation": {
            "en": "This is why these networks are useful for processing sequential data that exhibit long-distance dependencies.",
            "zh": "这就是为什么这些网络对于处理表现出长距离依赖关系的顺序数据很有用的原因。"
        }
    },
    {
        "translation": {
            "en": "The calculation of expected return for actions at+1 and beyond refers to the policy, π, that is used to select the action that will be taken in each state (as did all other calculations of expected return). We can define the policy as a function that returns a probability distribution over the set of possible actions that can be taken from a state, as described in Equation (11.5)[641]. Using this definition we can rewrite Equation (11.19)[652]",
            "zh": "+1 及以上操作的预期回报计算是指用于选择在每个状态下将采取的行动的策略 π（与预期回报的所有其他计算一样）。我们可以将策略定义为一个函数，该函数返回可以从状态中采取的一组可能操作的概率分布，如公式 （11.5）[641] 中所述。使用这个定义，我们可以重写等式（11.19）[652]"
        }
    },
    {
        "translation": {
            "en": "weight sharing, 483",
            "zh": "重量分摊， 483"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: The challenge in this case would be to integrate the automated application assessment process into whatever application approval process currently exists within the company.",
            "zh": "容量要求：在这种情况下，挑战在于将自动化应用程序评估流程集成到公司内部当前存在的任何应用程序审批流程中。"
        }
    },
    {
        "translation": {
            "en": "(a) A good measure of distance between two instances with categorical features is the overlap metric (also known as the hamming distance), which simply counts the number of descriptive features that have different values. Using this measure of distance, compute the distances between the mystery animal and each of the animals in the animal dataset.",
            "zh": "（a） 重叠度量（也称为汉明距离）是衡量两个具有分类特征的实例之间距离的一个很好的度量标准，它简单地计算具有不同值的描述性特征的数量。使用此距离度量，计算神秘动物与动物数据集中每只动物之间的距离。"
        }
    },
    {
        "translation": {
            "en": "invalid outliers, 65, 68, 715",
            "zh": "无效异常值、65、68、715"
        }
    },
    {
        "translation": {
            "en": "(2009) and Smyth and Keane (1995).",
            "zh": "（2009）和史密斯和基恩（1995）。"
        }
    },
    {
        "translation": {
            "en": "The occurrence of tachycardia can have serious implications including increased risk of stroke or sudden cardiac arrest.",
            "zh": "心动过速的发生可能会产生严重的影响，包括增加中风或心脏骤停的风险。"
        }
    },
    {
        "translation": {
            "en": "29. Monte Carlo methods are named after the Mediterranean principality that is famous for its casino.",
            "zh": "29. 蒙特卡洛方法以以其赌场而闻名的地中海公国命名。"
        }
    },
    {
        "translation": {
            "en": "We begin by illustrating the key differences between supervised and unsupervised machine learning before describing clustering, one of the main applications of unsupervised learning; and the standard approach for clustering, the k-means clustering algorithm.",
            "zh": "我们首先说明监督机器学习和无监督机器学习之间的主要区别，然后描述聚类，这是无监督学习的主要应用之一;以及聚类的标准方法，即 k-means 聚类算法。"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of using a logistic regression model is that along with classifications, it also produces probabilities.",
            "zh": "使用逻辑回归模型的优点之一是，除了分类之外，它还会产生概率。"
        }
    },
    {
        "translation": {
            "en": "A.2  The members of the school basketball team from Figure A.1[746] with one very tall ringer added: (a) the dashed gray line shows the mean of the players’ heights; and (b) the dashed gray line shows the median of the players’ heights, with the players ordered by height.",
            "zh": "A.2 图A.1[746]中学校篮球队的成员，加上一个非常高的铃声：（a）灰色虚线表示球员身高的平均值;（b）灰色虚线显示球员身高的中位数，球员按身高排序。"
        }
    },
    {
        "translation": {
            "en": "In all cases the extreme values were determined to be valid outliers.",
            "zh": "在所有情况下，极值都被确定为有效的异常值。"
        }
    },
    {
        "translation": {
            "en": "4.13   The vegetation classification decision tree after the dataset has been split using ELEVATION > 4,175.",
            "zh": "4.13 使用ELEVATION > 4,175分割数据集后的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "(a) Which of these two models do you think will generalize better to instances not contained in the dataset?",
            "zh": "（a） 您认为这两种模型中的哪一种可以更好地推广到数据集中未包含的实例？"
        }
    },
    {
        "translation": {
            "en": "Because the descriptive feature ACCOUNT BALANCE is continuous, there is an infinite number of values in the feature’s domain.",
            "zh": "由于描述性要素 ACCOUNT BALANCE 是连续的，因此要素域中存在无限数量的值。"
        }
    },
    {
        "translation": {
            "en": "BLANDCHROMATIN",
            "zh": "布兰德染色质"
        }
    },
    {
        "translation": {
            "en": "(c) What value will the Bayesian network predict for ALARM, given that there is both a burglar and a cat in the house but there is no storm?",
            "zh": "（c） 贝叶斯网络对 ALARM 的预测值是多少，因为房子里既有窃贼又有猫，但没有暴风雨？"
        }
    },
    {
        "translation": {
            "en": "There is a range of simple pre-pruning strategies.",
            "zh": "有一系列简单的预修剪策略。"
        }
    },
    {
        "translation": {
            "en": "A model is generative if it can be used to generate data that will have the same characteristics as the dataset from which the model was produced.",
            "zh": "如果模型可用于生成与生成模型的数据集具有相同特征的数据，则该模型是生成性的。"
        }
    },
    {
        "translation": {
            "en": "Gibbs sampling is one of the best-known MCMC algorithms and is particularly suitable when we wish to generate probabilities that are conditioned on some evidence, so this is the algorithm we discuss in this section.",
            "zh": "吉布斯采样是最著名的 MCMC 算法之一，特别适用于我们希望生成以某些证据为条件的概率，因此这就是我们在本节中讨论的算法。"
        }
    },
    {
        "translation": {
            "en": "However, in this section, we focus on showing how a sequence of linear layers can be replaced by a single linear function (as distinct from an affine transformation).",
            "zh": "然而，在本节中，我们重点展示如何用单个线性函数（与仿射变换不同）替换线性层序列。"
        }
    },
    {
        "translation": {
            "en": "If this is the case, these missing values are due to invalid data, so the data integration errors can be corrected, and the ABT can be regenerated to populate the missing values.",
            "zh": "如果是这种情况，这些缺失值是由于无效数据造成的，因此可以更正数据集成错误，并且可以重新生成 ABT 以填充缺失值。"
        }
    },
    {
        "translation": {
            "en": "Descriptive Statistics and Data Visualization for Machine Learning",
            "zh": "机器学习的描述性统计和数据可视化"
        }
    },
    {
        "translation": {
            "en": "Figure 4.9[139] depicts the state of the decision tree after the 7 partition has been split.",
            "zh": "图 4.9[139] 描述了 7 分区拆分后的决策树状态。"
        }
    },
    {
        "translation": {
            "en": "situational fluency, 24, 48, 686, 706",
            "zh": "情境流畅度，24,48,686,706"
        }
    },
    {
        "translation": {
            "en": "In a second experiment, the refractive effect of passing N rays through a prism (something that does not happen to X-rays) is demonstrated.",
            "zh": "在第二个实验中，演示了通过棱镜的 N 射线的折射效应（X 射线不会发生）。"
        }
    },
    {
        "translation": {
            "en": "When this occurs, the model needs to be changed in some way to adapt to the new scenario.",
            "zh": "发生这种情况时，需要以某种方式更改模型以适应新场景。"
        }
    },
    {
        "translation": {
            "en": "The image-based measures of overall galaxy shape are extracted from the images using morphological and moment image processing operations.",
            "zh": "使用形态学和矩图像处理操作从图像中提取基于图像的整体星系形状测量值。"
        }
    },
    {
        "translation": {
            "en": "The first two extensions and variations sections explain why the backpropagation algorithm can struggle with unstable gradients when training a deep network and how a number of important hyper-parameter decisions, such as the choice of the network weight initialization process, and activation functions, can help with the challenge of unstable gradients.",
            "zh": "前两个扩展和变体部分解释了为什么反向传播算法在训练深度网络时会遇到不稳定的梯度问题，以及一些重要的超参数决策（例如网络权重初始化过程的选择和激活函数）如何帮助应对不稳定梯度的挑战。"
        }
    },
    {
        "translation": {
            "en": "Gradient descent works in exactly the same way.",
            "zh": "梯度下降的工作方式完全相同。"
        }
    },
    {
        "translation": {
            "en": "instance, 5, 28",
            "zh": "实例， 5， 28"
        }
    },
    {
        "translation": {
            "en": "A simple dataset for a MENINGITIS diagnosis with descriptive features that describe the presence or absence of three common symptoms of the disease: HEADACHE, FEVER, and VOMITING.",
            "zh": "用于脑膜炎诊断的简单数据集，具有描述性特征，描述是否存在该疾病的三种常见症状：头痛、发烧和呕吐。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.86)[481] lists the calculation of the activation for this neuron for this set of inputs.",
            "zh": "等式（8.86）[481]列出了这组输入中该神经元激活的计算。"
        }
    },
    {
        "translation": {
            "en": "It is often useful to talk about the probabilities for all the possible assignments to a feature.",
            "zh": "讨论对一个特征的所有可能赋值的概率通常很有用。"
        }
    },
    {
        "translation": {
            "en": "This structure is typically captured in new generated features that can be appended to the original dataset and so augment or enrich it.",
            "zh": "此结构通常捕获在新生成的特征中，这些特征可以附加到原始数据集中，从而增强或丰富它。"
        }
    },
    {
        "translation": {
            "en": "feature space, 181, 183, 184, 231, 599",
            "zh": "功能空间， 181， 183， 184， 231， 599"
        }
    },
    {
        "translation": {
            "en": "Deep learning has grown out of research on neural networks.",
            "zh": "深度学习是从对神经网络的研究发展而来的。"
        }
    },
    {
        "translation": {
            "en": "When these cases occur, the algorithm will create a leaf node that returns the mean value of the target feature in a data partition, rather than the majority level.",
            "zh": "当这些情况发生时，该算法将创建一个叶节点，该节点返回数据分区中目标特征的平均值，而不是多数级别。"
        }
    },
    {
        "translation": {
            "en": "For a more in-depth treatment of regression models and their underpinnings in statistics, Chapter 14 of Rice (2006) offers a nice treatment of the topic, and Kutner et al. (2004) provides massive detail. Ayres (2008) gives a lighter discussion of the many different ways in which regression models are applied in practice.",
            "zh": "为了更深入地研究回归模型及其在统计学中的基础，Rice （2006） 的第 14 章提供了对该主题的良好处理，Kutner et al. （2004） 提供了大量细节。Ayres（2008）对回归模型在实践中应用的许多不同方式进行了较轻松的讨论。"
        }
    },
    {
        "translation": {
            "en": "Chapter 11, in the second half of the new Beyond Prediction part of the book, describes reinforcement learning from the fundamental ideas that underpin it to the use of deep neural networks in modern reinforcement learning systems.",
            "zh": "第11章是本书新的“超越预测”部分的后半部分，描述了强化学习，从支撑强化学习的基本思想到深度神经网络在现代强化学习系统中的使用。"
        }
    },
    {
        "translation": {
            "en": "These locations can be thought of as sensing neurons that permit the network to sense the external inputs.",
            "zh": "这些位置可以被认为是允许网络感知外部输入的感知神经元。"
        }
    },
    {
        "translation": {
            "en": "This value was calculated by multiplying the prediction error for d1 (226.74) by the SIZE value for this instance (500).",
            "zh": "该值的计算方法是将 d1 的预测误差 （226.74） 乘以此实例的 SIZE 值 （500）。"
        }
    },
    {
        "translation": {
            "en": "5.2 Fundamentals",
            "zh": "5.2 基础"
        }
    },
    {
        "translation": {
            "en": "One advantage of AHC is that the number of clusters to be found, k, is not a required input for the algorithm.",
            "zh": "AHC 的一个优点是要找到的聚类数 k 不是算法的必需输入。"
        }
    },
    {
        "translation": {
            "en": "Out of the different approaches we have considered, the information-based and probability-based approaches are least well suited in this case.",
            "zh": "在我们考虑过的不同方法中，基于信息和基于概率的方法最不适合这种情况。"
        }
    },
    {
        "translation": {
            "en": "17.667",
            "zh": "17.667"
        }
    },
    {
        "translation": {
            "en": "Figure 3.6[75] shows an example scatter plot matrix for the continuous features from the professional basketball team dataset in Table 3.7[73]: HEIGHT, WEIGHT, AGE, and SPONSORSHIP EARNINGS.",
            "zh": "图3.6[75]显示了表3.7[73]中职业篮球队数据集中连续特征的散点图矩阵示例：身高、体重、年龄和赞助收入。"
        }
    },
    {
        "translation": {
            "en": "Custom metrics aside, the standard distance metrics and similarity indexes weight all features equally.",
            "zh": "撇开自定义指标不谈，标准距离指标和相似性指数对所有要素的权重相同。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics is the art of building and using models that make predictions based on patterns extracted from historical data. Applications of predictive data analytics include",
            "zh": "预测数据分析是构建和使用模型的艺术，这些模型根据从历史数据中提取的模式进行预测。预测数据分析的应用包括"
        }
    },
    {
        "translation": {
            "en": "The weighted variance is computed by summing the variance of the target feature within each partition created by splitting a dataset on a descriptive feature multiplied by the fraction of the dataset in each partition.",
            "zh": "加权方差的计算方法是将每个分区中目标要素的方差相加，方法是将描述性要素上的数据集拆分乘以每个分区中数据集的分数。"
        }
    },
    {
        "translation": {
            "en": "This means that we need to calculate 2 + (2 × 4) + (2 × 3) + (2 × 3) = 22 probabilities.",
            "zh": "这意味着我们需要计算 2 + （2 × 4） + （2 × 3） + （2 × 3） = 22 个概率。"
        }
    },
    {
        "translation": {
            "en": "Prediction score distributions for two different prediction models. The distributions in (a) are much better separated than those in (b).",
            "zh": "两种不同预测模型的预测分数分布。（a）中的分布比（b）中的分布分离得更好。"
        }
    },
    {
        "translation": {
            "en": "The agent has no map of the environment and begins with knowledge only of the actions that can be taken—left, right, up, or down—and its current state.",
            "zh": "智能体没有环境地图，一开始只知道可以采取的行动（左、右、上或下）及其当前状态。"
        }
    },
    {
        "translation": {
            "en": "We then rewrite Equation (8.28)[415] as Equation (8.30)[416] to use this new term",
            "zh": "然后，我们将等式（8.28）[415]改写为等式（8.30）[416]以使用这个新术语"
        }
    },
    {
        "translation": {
            "en": "The differences between SARSA and Q-learning can be illustrated by examining the behavior of a SARSA agent in the same grid world environment used in Section 11.3.1[659] (we assume the same sequence of random numbers are generated for easy comparison).",
            "zh": "SARSA 和 Q 学习之间的差异可以通过检查 SARSA 代理在第 11.3.1 节[659] 中使用的相同网格世界环境中的行为来说明（我们假设生成相同的随机数序列以便于比较）。"
        }
    },
    {
        "translation": {
            "en": "The most naturally suited learning approaches in these scenarios are probably those that are best suited for the majority feature type.",
            "zh": "在这些场景中，最自然的学习方法可能是那些最适合大多数特征类型的学习方法。"
        }
    },
    {
        "translation": {
            "en": "3.3.4 Case Study: Motor Insurance Fraud",
            "zh": "3.3.4 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Larger values of k mean that more smoothing occurs—that is, more probability mass is taken from the larger probabilities and given to the small probabilities.",
            "zh": "k 值越大，意味着平滑发生越多，也就是说，从较大的概率中获取更多的概率质量，并赋予较小的概率。"
        }
    },
    {
        "translation": {
            "en": "In this figure the arrows carry activations in the direction the arrow is pointing, the weight label on each arrow represents the weight that will be applied to the descriptive feature carried along the arrow, the ∑ symbol represents the weighted sum of the inputs, and the φ symbol represents the threshold function being applied to the result of the weighted sum to convert it into an activation.",
            "zh": "在此图中，箭头沿箭头指向的方向进行激活，每个箭头上的权重标签表示将应用于沿箭头携带的描述性特征的权重，∑符号表示输入的加权总和，φ符号表示应用于加权总和结果以将其转换为激活的阈值函数。"
        }
    },
    {
        "translation": {
            "en": "So the rest of the search process will involve a descent down to the node, indexing d18 and a direct ascent to the root node where the search process will then terminate and return d21 as the nearest neighbor (we will skip the details of these steps).",
            "zh": "因此，搜索过程的其余部分将涉及下降到节点，索引 d18 并直接上升到根节点，然后搜索过程将终止并返回 d21 作为最近的邻居（我们将跳过这些步骤的细节）。"
        }
    },
    {
        "translation": {
            "en": "8.2.1   Artificial Neurons",
            "zh": "8.2.1 人工神经元"
        }
    },
    {
        "translation": {
            "en": "SHOP VALUE",
            "zh": "店面价值"
        }
    },
    {
        "translation": {
            "en": "Two key innovations that helped with the unstable gradient problem were the adoption of the rectified linear activation function and the development of new techniques for weight initialization.",
            "zh": "有助于解决不稳定梯度问题的两项关键创新是采用整流线性激活函数和开发用于权重初始化的新技术。"
        }
    },
    {
        "translation": {
            "en": "The dashed line in Figure 9.3[542] shows the performance of the model being trained on a validation dataset.",
            "zh": "图 9.3[542] 中的虚线显示了在验证数据集上训练的模型的性能。"
        }
    },
    {
        "translation": {
            "en": "Once the initial design for the features in an ABT has been completed, we can begin to implement the technical processes that are needed to extract, create, and aggregate the features into an ABT.",
            "zh": "完成 ABT 中特征的初始设计后，我们就可以开始实施提取、创建和聚合到 ABT 中所需的技术流程。"
        }
    },
    {
        "translation": {
            "en": "4. The axes in Figure 8.8[398] are slightly offset for ease of reading.",
            "zh": "4. 图8.8[398]中的轴略有偏移，以便于阅读。"
        }
    },
    {
        "translation": {
            "en": "In this way the cluster centroids are moved to be representative of the members of that cluster.",
            "zh": "这样，聚类质心被移动以代表该聚类的成员。"
        }
    },
    {
        "translation": {
            "en": "We can rearrange Equation (5.13)[216] to calculate the cosine of the inner angle between two vectors as the normalized dot product",
            "zh": "我们可以重新排列方程（5.13）[216]，以计算两个向量之间内角的余弦作为归一化点积"
        }
    },
    {
        "translation": {
            "en": "A matrix of activations for a layer of neurons processing a batch of examples is denoted by A(k) where k identifies the layer.",
            "zh": "处理一批样本的神经元层的激活矩阵用 A（k） 表示，其中 k 标识该层。"
        }
    },
    {
        "translation": {
            "en": "Although we consider these memory locations as (sensing) neurons within the network, the inputs presented to the network are not transformed by these sensing neurons.",
            "zh": "尽管我们将这些记忆位置视为网络中的（感知）神经元，但呈现给网络的输入不会被这些感知神经元转换。"
        }
    },
    {
        "translation": {
            "en": "The number of layers required for a network to be considered deep is an open question; however, Cybenko (1988) proved that a network with three layers of (processing) neurons (i.e., two hidden layers and an output layer) can approximate any function to arbitrary accuracy.",
            "zh": "将网络视为深度所需的层数是一个悬而未决的问题;然而，Cybenko（1988）证明，具有三层（处理）神经元（即两个隐藏层和一个输出层）的网络可以以任意精度近似任何函数。"
        }
    },
    {
        "translation": {
            "en": "It is important when choosing the periods for out-of-time sampling that the time spans are large enough to take into account any cyclical behavioral patterns or that other approaches are used to account for these.",
            "zh": "在选择时间外抽样的时间段时，重要的是时间跨度足够大，可以考虑任何周期性行为模式，或者使用其他方法来解释这些行为模式。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12(a)[562] shows a complete ROC curve for the email predictions in Table 9.13[560].",
            "zh": "图9.12（a）[562]显示了表9.13[560]中电子邮件预测的完整ROC曲线。"
        }
    },
    {
        "translation": {
            "en": "The company estimates that it has an annotation budget that will cover the human annotation of 20,000 phrases (i.e., 40% of the set of candidate phrases).",
            "zh": "该公司估计，它的注释预算将涵盖 20,000 个短语的人工注释（即候选短语集的 40%）。"
        }
    },
    {
        "translation": {
            "en": "Each row represents an iteration of the process, in which the black rectangles indicate the data used for testing while the white spaces indicate the data used for training.",
            "zh": "每一行表示过程的迭代，其中黑色矩形表示用于测试的数据，而白色空格表示用于训练的数据。"
        }
    },
    {
        "translation": {
            "en": "9.4.1.1 Hold-out sampling In Section 9.3[535] we used a hold-out test set to evaluate the performance of a model.",
            "zh": "9.4.1.1 保持抽样 在第 9.3[535] 节中，我们使用保持测试集来评估模型的性能。"
        }
    },
    {
        "translation": {
            "en": "Finally, a domain concept, Fraud Outcome, is included to cover the target feature.",
            "zh": "最后，包括一个领域概念，即欺诈结果，以涵盖目标功能。"
        }
    },
    {
        "translation": {
            "en": "nodes: each feature in a domain is represented by a single node in the graph.",
            "zh": "节点：域中的每个要素都由图形中的单个节点表示。"
        }
    },
    {
        "translation": {
            "en": "All the neurons in this network use the following threshold activation function:",
            "zh": "该网络中的所有神经元都使用以下阈值激活函数："
        }
    },
    {
        "translation": {
            "en": "12.4   Modeling",
            "zh": "12.4 建模"
        }
    },
    {
        "translation": {
            "en": "This figure shows the weights on each connection and for each neuron shows the weighted sum z calculated by that neuron (the number on the left of the neuron) and the activation a for the neuron (the number on the right of the neuron).",
            "zh": "该图显示了每个连接上的权重，并且对于每个神经元显示了由该神经元（神经元左侧的数字）计算的加权总和z和神经元的激活a（神经元右侧的数字）。"
        }
    },
    {
        "translation": {
            "en": "supervised learning, 5, 21, 597, 598, 674",
            "zh": "监督学习， 5， 21， 597， 598， 674"
        }
    },
    {
        "translation": {
            "en": "exploding gradients, 448, 452, 507",
            "zh": "爆炸梯度，448、452、507"
        }
    },
    {
        "translation": {
            "en": "precision, 548, 549, 572",
            "zh": "精度， 548， 549， 572"
        }
    },
    {
        "translation": {
            "en": "Ross also needed to define the lengths of the observation period and the outcome period for the model.",
            "zh": "Ross 还需要定义模型的观察期长度和结果期。"
        }
    },
    {
        "translation": {
            "en": "where T is a set of thresholds, |T| is the number of thresholds tested, and TPR(T[i]) and FPR(T[i]) are the true positive and false positive rates at threshold i respectively.",
            "zh": "其中 T 是一组阈值，|T|是测试的阈值数，TPR（T[i]） 和 FPR（T[i]） 分别是阈值 i 处的真阳性率和假阳性率。"
        }
    },
    {
        "translation": {
            "en": "Remember that during the prediction stage, the nearest neighbor algorithm iterates across all the instances in the training dataset and computes the distance between each instance and the query.",
            "zh": "请记住，在预测阶段，最近邻算法会遍历训练数据集中的所有实例，并计算每个实例与查询之间的距离。"
        }
    },
    {
        "translation": {
            "en": "12.6 Deployment",
            "zh": "12.6 部署"
        }
    },
    {
        "translation": {
            "en": "3.4.1 Handling Missing Values",
            "zh": "3.4.1 处理缺失值"
        }
    },
    {
        "translation": {
            "en": "Table 9.22",
            "zh": "表 9.22"
        }
    },
    {
        "translation": {
            "en": "Usage: The frequency and recency with which customers or users have interacted with an organization. The monetary value of a customer’s interactions with a service. The mix of products or services offered by the organization that a customer or user has used.",
            "zh": "使用情况：客户或用户与组织交互的频率和新近度。客户与服务交互的货币价值。客户或用户使用的组织提供的产品或服务的组合。"
        }
    },
    {
        "translation": {
            "en": "For this reason selecting which type of model to use should be informed by the specific priorities of a project and the types of the descriptive and target features in the data.",
            "zh": "因此，选择要使用的模型类型时，应根据项目的特定优先级以及数据中描述性和目标特征的类型来决定。"
        }
    },
    {
        "translation": {
            "en": "We use the symbol φ to generically represent activation functions. In some cases we use a subscript to indicate the use of a particular activation function. For example, φSM indicates the use of a softmax function activation function, whereas φReLU indicates the use of a rectified linear activation function.",
            "zh": "我们使用符号 φ 来通用地表示激活函数。在某些情况下，我们使用下标来指示使用特定的激活函数。例如，φSM 表示使用 softmax 函数激活函数，而 φReLU 表示使用修正线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "Each group containing more instances than the smallest one is then randomly sampled by the appropriate percentage to create a subset that is the under-sampling target size.",
            "zh": "然后，每个包含比最小实例多的组按适当的百分比随机抽样，以创建一个子集，该子集是欠采样的目标大小。"
        }
    },
    {
        "translation": {
            "en": "These measures capture how well objects match template shapes—although none is accurate enough to actually perform the galaxy morphology prediction itself.",
            "zh": "这些测量捕获了物体与模板形状的匹配程度，尽管没有一个足够准确，无法实际执行星系形态预测本身。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.14",
            "zh": "图 10.14"
        }
    },
    {
        "translation": {
            "en": "A.2   Descriptive Statistics for Categorical Features",
            "zh": "A.2 分类特征的描述性统计"
        }
    },
    {
        "translation": {
            "en": "are continuous functions with a single variable x. Graphs of these functions are shown in Figure C.2[767]. Each graph also shows the derivative of the function. We will return to these shortly.",
            "zh": "是具有单个变量 x 的连续函数。这些函数的图形如图C.2[767]所示。每个图形还显示了函数的导数。我们稍后将回到这些问题。"
        }
    },
    {
        "translation": {
            "en": "As with the analysis of the scaling of the variances for z in the forward pass, the scaling of the variance of the δ values as they are backpropagated through each layer k is a function of number of inputs to each neuron in the layer (here nout(k)) multiplied by the variance of the weights for that layer var(W(k)).",
            "zh": "与前向传递中 z 方差的缩放分析一样，δ值在每层 k 中反向传播时方差的缩放是该层中每个神经元的输入数（此处为 nout（k））乘以该层的权重方差 var（W（k））。"
        }
    },
    {
        "translation": {
            "en": "predictive data analytics, 3, 3, 21",
            "zh": "预测数据分析， 3， 3， 21"
        }
    },
    {
        "translation": {
            "en": "LIFE EXP., the mean life expectancy at birth",
            "zh": "LIFE EXP.，出生时的平均预期寿命"
        }
    },
    {
        "translation": {
            "en": "where the training set is composed of n training instances; each training instance is composed of descriptive features d and a target feature t; 𝕄w(di) is the prediction made by a candidate model 𝕄w for a training instance with descriptive features di; and the candidate model 𝕄w is defined by the weight vector w. For our simple scenario in which each instance is described with a single descriptive feature, Equation (7.4)[316] expands to",
            "zh": "其中训练集由 n 个训练实例组成;每个训练实例由描述性特征 D 和目标特征 T 组成;Mw（di） 是候选模型 Mw 对具有描述性特征 di 的训练实例所做的预测;候选模型 Mw 由权重向量 w 定义。对于每个实例都用单个描述性特征描述的简单场景，等式 （7.4）[316] 扩展为"
        }
    },
    {
        "translation": {
            "en": "Linear annealing allows the value for ε used in ε greedy policy to change over time.",
            "zh": "线性退火允许贪婪策略中使用ε ε值随时间变化。"
        }
    },
    {
        "translation": {
            "en": "8.19   An illustration of the forward propagation of d2 through the ReLU network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "8.19 d2 通过 ReLU 网络向前传播的图示，显示了每个连接上的权重，以及网络中每个神经元的加权总和 z 和激活值。"
        }
    },
    {
        "translation": {
            "en": "The term sample refers to the subset of the population that is selected for analysis.",
            "zh": "术语“样本”是指选择进行分析的总体子集。"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.18(b)[226] we have added a second descriptive feature, Y, and assigned each of the instances in the dataset a random Y value in the range [0.0,3.0].",
            "zh": "在图 5.18（b）[226] 中，我们添加了第二个描述性特征 Y，并为数据集中的每个实例分配了一个 [0.0,3.0] 范围内的随机 Y 值。"
        }
    },
    {
        "translation": {
            "en": "Table 1.4",
            "zh": "表 1.4"
        }
    },
    {
        "translation": {
            "en": "To best handle image inputs a convolutional neural network29 was used.",
            "zh": "为了最好地处理图像输入，使用了卷积神经网络29。"
        }
    },
    {
        "translation": {
            "en": "Using the version of the support vector machine prediction model that uses a kernel function (see Equation 7.47) with the polynomial kernel function, calculate the output of the model for a query instance with DOSE1 = 0.22 and DOSE2 = 0.16.",
            "zh": "使用使用核函数（参见公式 7.47）和多项式核函数的支持向量机预测模型版本，计算 DOSE1 = 0.22 和 DOSE2 = 0.16 的查询实例的模型输出。"
        }
    },
    {
        "translation": {
            "en": "Kollar and Friedman (2009) is a comprehensive text on the theory and methods of graphical models and is a good reference text for postgraduate students who are doing research using graphical models.",
            "zh": "Kollar and Friedman （2009） 是一本关于图形模型理论和方法的综合性文本，对于使用图形模型进行研究的研究生来说是一个很好的参考文本。"
        }
    },
    {
        "translation": {
            "en": "To measure error rate, we set aside some of the training data as a validation dataset22 that is not used during tree induction.",
            "zh": "为了测量错误率，我们将一些训练数据留作验证数据集22，在树归纳期间不使用。"
        }
    },
    {
        "translation": {
            "en": "The prediction subject is a component, and the descriptive features are a set of characteristics of the component that can be gathered on the production line.",
            "zh": "预测主体是一个组件，描述性特征是可以在生产线上收集的组件的一组特征。"
        }
    },
    {
        "translation": {
            "en": "Careful readers will have noticed that in the equation for variance given in Equation (A.3)[747], we divided the sum of the differences between the values of the feature a and ā not by n, the number of values for a in the ABT, but by n − 1.",
            "zh": "细心的读者会注意到，在方程（A.3）[747]中给出的方差方程中，我们将特征a和ā的值之间的差值之和除以n，即ABT中a的值数，而是除以n − 1。"
        }
    },
    {
        "translation": {
            "en": "sparse, 443",
            "zh": "稀疏，443"
        }
    },
    {
        "translation": {
            "en": "The curve defined by a normal probability distribution is symmetric around a single peak value.",
            "zh": "由正态概率分布定义的曲线围绕单个峰值对称。"
        }
    },
    {
        "translation": {
            "en": "Bootstrapping uses the existing estimates of expected returns in the action-value table to make action-value table updates rather than waiting for an episode to finish to discover what the actual return is.",
            "zh": "Bootstrapping 使用操作值表中预期回报的现有估计值来更新操作值表，而不是等待剧集结束来发现实际回报是多少。"
        }
    },
    {
        "translation": {
            "en": "least squares optimization, 318",
            "zh": "最小二乘优化，318"
        }
    },
    {
        "translation": {
            "en": "This gives the new set of weights shown as New Weights (after Iteration 1).",
            "zh": "这将给出显示为“新权重”（在迭代 1 之后）的新权重集。"
        }
    },
    {
        "translation": {
            "en": "so there are four weights—w[0], w[1], w[2], and w[3]—for which optimal values must be found. For this example, let’s assume that the learning rate, α, is 0.00000002 and the initial weights are chosen from a uniform random distribution in the range [−0.2, 0.2] to be w[0] = −0.146, w[1] = 0.185, w[2] = −0.044, and w[3] = 0.119. Table 7.3[331] details the important values from the first two iterations of the gradient descent algorithm when applied to this data.9",
            "zh": "因此，有四个权重 - W[0]、W[1]、W[2] 和 W[3]——必须找到最佳值。在此示例中，假设学习率 α 为 0.000000002，初始权重从 [−0.2， 0.2] 范围内的均匀随机分布中选择为 w[0] = −0.146、w[1] = 0.185、w[2] = −0.044 和 w[3] = 0.119。表 7.3[331] 详细介绍了梯度下降算法前两次迭代中应用于此数据时的重要值9。"
        }
    },
    {
        "translation": {
            "en": "7.4.3 Handling Categorical Descriptive Features",
            "zh": "7.4.3 处理分类描述性特征"
        }
    },
    {
        "translation": {
            "en": "Sarah spent days training to get better at this challenge.",
            "zh": "莎拉花了几天时间训练，以更好地应对这一挑战。"
        }
    },
    {
        "translation": {
            "en": "In practice, the simplest way to calculate a K-S statistic for the predictions made by a model for a test dataset is to first tabulate the positive and negative cumulative probabilities for the scores predicted for each instance in the test dataset, in ascending order by prediction score.",
            "zh": "在实践中，计算模型对测试数据集所做的预测的 K-S 统计量的最简单方法是首先将测试数据集中每个实例预测的分数的正负累积概率制成表格，按预测分数升序排列。"
        }
    },
    {
        "translation": {
            "en": "To build shallow trees, we need to put the descriptive features that best discriminate between instances that have different target feature values toward the top of the tree.",
            "zh": "为了构建浅层树，我们需要将最能区分具有不同目标特征值的实例的描述性特征放在树的顶部。"
        }
    },
    {
        "translation": {
            "en": "Initially, though, we will focus on a simplified version of this task in which just SIZE is used to predict RENTAL PRICE.",
            "zh": "不过，最初，我们将专注于此任务的简化版本，其中仅使用 SIZE 来预测 RENTAL PRICE。"
        }
    },
    {
        "translation": {
            "en": "The correlation between two features, a and b, can be calculated as",
            "zh": "两个特征 a 和 b 之间的相关性可以计算为"
        }
    },
    {
        "translation": {
            "en": "and for MENINGITIS = false",
            "zh": "脑膜炎 = 假"
        }
    },
    {
        "translation": {
            "en": "This layer of neurons is the same width as the LSTM cell, and so there is one activation in the output of the sigmoid layer for each activation in the cell state.",
            "zh": "该神经元层的宽度与LSTM细胞相同，因此在细胞状态下，对于每次激活，在乙状结肠层的输出中都有一次激活。"
        }
    },
    {
        "translation": {
            "en": "Normalizing the data is an important thing to do for almost all machine learning algorithms, not just nearest neighbor.",
            "zh": "对于几乎所有机器学习算法来说，规范化数据是一件重要的事情，而不仅仅是最近邻算法。"
        }
    },
    {
        "translation": {
            "en": "K-S statistic, 563",
            "zh": "K-S 统计，563"
        }
    },
    {
        "translation": {
            "en": "3. Obviously, churn events will happen on different dates for different customers; therefore, to build the ABT, the observation and outcome periods for different customers would have to be aligned. This situation is an example of the propensity model scenario illustrated in Figure 2.6[39] in Section 2.4.3[36].",
            "zh": "3. 显然，不同客户的流失事件会在不同的日期发生;因此，要构建 ABT，必须对不同客户的观察期和结果期保持一致。这种情况是第 2.4.3 节[36] 的图 2.6[39] 中所示的倾向模型场景的一个示例。"
        }
    },
    {
        "translation": {
            "en": "The first question addresses data availability.",
            "zh": "第一个问题涉及数据可用性。"
        }
    },
    {
        "translation": {
            "en": "(short)” course so that students gain a deeper and broader understanding of machine learning, and it includes the second case study.",
            "zh": "（short）“课程，以便学生对机器学习有更深入、更广泛的了解，其中包括第二个案例研究。"
        }
    },
    {
        "translation": {
            "en": "Each of the approaches to machine learning that we have presented in this book induces distinct types of prediction models with different strengths and weaknesses.",
            "zh": "我们在本书中介绍的每种机器学习方法都会诱导出具有不同优势和劣势的不同类型的预测模型。"
        }
    },
    {
        "translation": {
            "en": "The extended version of the college athletes dataset.",
            "zh": "大学运动员数据集的扩展版本。"
        }
    },
    {
        "translation": {
            "en": "The inductive bias encoded in this algorithm includes a preference bias to prefer models that minimize the sum of squared errors function and a restriction bias introduced by the facts that we consider only linear combinations of descriptive features and that we take a single path through the error gradient from a random starting point.",
            "zh": "该算法中编码的归纳偏差包括偏好偏差最小化平方误差函数之和的模型，以及由我们仅考虑描述性特征的线性组合的事实引入的限制偏差，以及我们从随机起点通过误差梯度的单一路径。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10[340] illustrates a linearly separable dataset; in that case the two classes of inputs were good generators and faulty generators.",
            "zh": "图 7.10[340] 展示了一个线性可分离的数据集;在这种情况下，两类输入是良好的发电机和故障发电机。"
        }
    },
    {
        "translation": {
            "en": "The name convolutional neural network comes from the fact that it is possible to implement the processing of an image by a set of neurons that share a filter with a single neuron that applies the filter to each region of the image in sequence and stores the result for each region.",
            "zh": "卷积神经网络的名称来源于这样一个事实，即可以通过一组神经元来实现图像的处理，这些神经元与单个神经元共享一个过滤器，该神经元按顺序将过滤器应用于图像的每个区域并存储每个区域的结果。"
        }
    },
    {
        "translation": {
            "en": "10.4.5   Agglomerative Hierarchical Clustering",
            "zh": "10.4.5 集聚分层聚类"
        }
    },
    {
        "translation": {
            "en": "4.4   Extensions and Variations",
            "zh": "4.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "There are three types of vegetation that should be recognized by this model.",
            "zh": "此模型应识别三种类型的植被。"
        }
    },
    {
        "translation": {
            "en": "Extreme cases of exploding gradients can result in numerical overflow generating NaN (not-a-number) gradients.",
            "zh": "梯度爆炸的极端情况可能导致数值溢出，生成 NaN（非数字）梯度。"
        }
    },
    {
        "translation": {
            "en": "Finally, unsupervised learning is a fascinating research area, and it is probably fair to say that it has many more significant open research challenges than supervised learning.",
            "zh": "最后，无监督学习是一个引人入胜的研究领域，可以公平地说，它比监督学习面临更重要的开放研究挑战。"
        }
    },
    {
        "translation": {
            "en": "The relationship between rainfall and grass growth in the grass growth dataset can be accurately represented as a second order polynomial through the following model:",
            "zh": "草生长数据集中降雨量与草生长之间的关系可以通过以下模型准确地表示为二阶多项式："
        }
    },
    {
        "translation": {
            "en": "Kutner, Michael, Christopher Nachtsheim, John Neter, and William Li. 2004. Applied linear statistical models. McGraw-Hill.",
            "zh": "Kutner、Michael、Christopher Nachtsheim、John Neter 和 William Li. 2004 年。应用线性统计模型。麦格劳-希尔。"
        }
    },
    {
        "translation": {
            "en": "true positive, 537",
            "zh": "真阳性， 537"
        }
    },
    {
        "translation": {
            "en": "26. The implementation of Lunar Lander used in this example comes from the Gym toolkit developed by OpenAI (Brockman et al., 2016). This is a fantastic resource for experimenting with reinforcement learning agents.",
            "zh": "26. 本例中使用的 Lunar Lander 的实现来自 OpenAI 开发的 Gym 工具包（Brockman 等人，2016 年）。这是试验强化学习代理的绝佳资源。"
        }
    },
    {
        "translation": {
            "en": "6.4   Extensions and Variations",
            "zh": "6.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "The ratio between peak and off-peak calls made by the customer this month",
            "zh": "本月客户拨打的高峰和非高峰呼叫之间的比率"
        }
    },
    {
        "translation": {
            "en": "the probability of a patient having a headache and meningitis is",
            "zh": "患者头痛和脑膜炎的概率是"
        }
    },
    {
        "translation": {
            "en": "component, 274",
            "zh": "组件，274"
        }
    },
    {
        "translation": {
            "en": "During the process of determining which analytics solution was most suitable for the current situation at AT, Ross had already begun to understand the data resources available.",
            "zh": "在确定哪种分析解决方案最适合 AT 当前情况的过程中，Ross 已经开始了解可用的数据资源。"
        }
    },
    {
        "translation": {
            "en": "11.2.4 The Bellman Equations",
            "zh": "11.2.4 贝尔曼方程"
        }
    },
    {
        "translation": {
            "en": "domain subconcept, 32",
            "zh": "领域子概念，32"
        }
    },
    {
        "translation": {
            "en": "12.3   The confusion matrix from the test of the AT churn prediction stratified hold-out test set using the pruned decision tree in Figure 12.5[699].",
            "zh": "12.3 使用图12.5[699]中修剪后的决策树，来自AT流失预测分层保持测试集的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce Claude Shannon’s approach to measuring information,1 in particular his model of entropy and how it is used in the information gain measure to capture the informativeness of a descriptive feature. Before this we introduce decision trees, the actual prediction models that we are trying to build.",
            "zh": "在本节中，我们将介绍克劳德·香农（Claude Shannon）测量信息的方法，1特别是他的熵模型，以及如何在信息增益测量中使用它来捕获描述性特征的信息性。在此之前，我们介绍决策树，即我们尝试构建的实际预测模型。"
        }
    },
    {
        "translation": {
            "en": "This means that there are 190 different combinations of the values of the hands held by the player and the dealer.",
            "zh": "这意味着玩家和庄家所持手牌的值有 190 种不同的组合。"
        }
    },
    {
        "translation": {
            "en": "8.41   The flow of activations through a long short-term memory unit during forward propagation when ct−1 = [0.3, 0.6], ht = [0.1, 0.8], and xt = [0.9].",
            "zh": "8.41 当ct−1 = [0.3， 0.6]， ht = [0.1， 0.8]， and xt = [0.9]时，正向传播期间通过长短期记忆单元的激活流。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.4",
            "zh": "图 2.4"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11(b)[290] illustrates the network structure of the naive Bayes model for predicting a fraudulent loan application that was built in Section 6.3.1[262].",
            "zh": "图6.11（b）[290]说明了第6.3.1节[262]中构建的用于预测欺诈性贷款申请的朴素贝叶斯模型的网络结构。"
        }
    },
    {
        "translation": {
            "en": "The top row of images in Figure 14.2[737] illustrates how the three artificial datasets were created.",
            "zh": "图14.2[737]中的最上面一行图像说明了三个人工数据集的创建方式。"
        }
    },
    {
        "translation": {
            "en": "population mean, 61",
            "zh": "人口平均数，61"
        }
    },
    {
        "translation": {
            "en": "The player then repeatedly chooses to either be dealt another card, Twist, or to stop on their current total, Stick.8 When the player is finished, the dealer turns over their second card and must continue to deal themselves cards until they reach a total value of 17 or more, or go bust by exceeding a value of 22.",
            "zh": "然后，玩家反复选择发另一张牌，Twist，或者停止他们当前的总数，Stick.8 当玩家完成时，庄家交出他们的第二张牌，必须继续发牌，直到他们达到 17 或更多的总价值，或者超过价值 22 而破产。"
        }
    },
    {
        "translation": {
            "en": "1. The table below shows the predictions made for a categorical target feature by a model for a test dataset. Based on this test set, calculate the evaluation measures listed below.",
            "zh": "1. 下表显示了模型对测试数据集的分类目标特征所做的预测。根据此测试集，计算下面列出的评估度量。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.17[222] shows a contour plot of these Mahalanobis distances.",
            "zh": "图5.17[222]显示了这些马氏距离的等值线图。"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a Markov process diagram to capture the behavior of a small baby as described.",
            "zh": "（b） 绘制马尔可夫过程图以捕捉所描述的小婴儿的行为。"
        }
    },
    {
        "translation": {
            "en": "13.2 Data Understanding",
            "zh": "13.2 数据理解"
        }
    },
    {
        "translation": {
            "en": "Percentiles are another useful measure of the variation of the values for a feature.",
            "zh": "百分位数是衡量要素值变化的另一个有用度量。"
        }
    },
    {
        "translation": {
            "en": "In fact, not only is a different randomly selected set of neurons dropped for each training example, but a different set of neurons is randomly selected for each presentation of a training example.",
            "zh": "事实上，不仅每个训练示例都会丢弃一组不同的随机选择的神经元，而且每个训练示例的呈现都会随机选择一组不同的神经元。"
        }
    },
    {
        "translation": {
            "en": "For example, δk would denote the error gradient for neuron k. It is these δ error gradients that are calculated and backpropagated during the backward pass of the backpropagation algorithm.",
            "zh": "例如，δk 表示神经元 k 的误差梯度。正是这些δ误差梯度在反向传播算法的向后传递过程中被计算和反向传播。"
        }
    },
    {
        "translation": {
            "en": "Transitions related to a Twist action are shown as solid lines, and transitions related to a Stick action are shown with dashed lines.",
            "zh": "与 Twist 操作相关的过渡显示为实线，与摇杆操作相关的过渡以虚线显示。"
        }
    },
    {
        "translation": {
            "en": "The impact this has on designing features for inclusion in an ABT is that the use of some features in analytics solutions that leads to some people being given preferential treatment is in breach of anti-discrimination law. For example, credit scoring models such as the one discussed in Section 1.2[5] cannot use race as a descriptive feature because this would discriminate against people on this basis.",
            "zh": "这对设计包含在 ABT 中的功能的影响是，在分析解决方案中使用某些功能导致某些人获得优惠待遇违反了反歧视法。例如，信用评分模型（如第1.2节[5]中讨论的模型不能使用种族作为描述性特征，因为这会在此基础上歧视人们。"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the categorical feature GENDER and the target feature PREFCHANNEL.",
            "zh": "（b） 下面的可视化说明了分类特征 GENDER 和目标特征 PREFCHANNEL 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "For the example function f(x,y) = x2 − y2 + 2x + 4y − xy + 2, we get two partial derivatives:",
            "zh": "对于示例函数 f（x，y） = x2 − y2 + 2x + 4y − xy + 2，我们得到两个偏导数："
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors",
            "zh": "误差的平方和"
        }
    },
    {
        "translation": {
            "en": "The most popular method for implementing dropout is known as inverted dropout.38 When we use inverted dropout we drop a neuron by multiplying the activation of the neuron during the forward pass by zero.",
            "zh": "实现 dropout 的最流行方法称为倒置辍学.38 当我们使用倒置辍学时，我们通过将神经元在前向传递期间的激活乘以零来丢弃神经元。"
        }
    },
    {
        "translation": {
            "en": "Another benefit of using the logistic function is that logistic regression model outputs can be interpreted as probabilities of the occurrence of a target level.",
            "zh": "使用逻辑函数的另一个好处是，逻辑回归模型的输出可以解释为目标水平出现的概率。"
        }
    },
    {
        "translation": {
            "en": "(a) A Bayesian network for a domain consisting of two binary features. The structure of the network states that the value of feature A directly influences the value of feature B. (b) A Bayesian network consisting of four binary features with a path containing three generations of nodes: D, C, and B.",
            "zh": "（a） 由两个二进制特征组成的域的贝叶斯网络。（b） 贝叶斯网络，由四个二进制特征组成，其路径包含三代节点：D、C 和 B。"
        }
    },
    {
        "translation": {
            "en": "Figure 12.4",
            "zh": "图 12.4"
        }
    },
    {
        "translation": {
            "en": "A pruned and stunted decision tree built for the Acme Telephonica churn prediction problem.",
            "zh": "为 Acme Telephonica 流失预测问题构建的修剪和发育不良的决策树。"
        }
    },
    {
        "translation": {
            "en": "(c) Based on the average class accuracy measures, which model appears to perform best at this task?",
            "zh": "（c） 根据平均类别准确性测量，哪个模型似乎在这项任务中表现最好？"
        }
    },
    {
        "translation": {
            "en": "2.1.1 Case Study: Motor Insurance Fraud",
            "zh": "2.1.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "7.7   Exercises",
            "zh": "7.7 练习"
        }
    },
    {
        "translation": {
            "en": "Heating load is the amount of heat energy required to keep a building at a specified temperature, usually 65° Fahrenheit during the winter regardless of outside temperature.",
            "zh": "供暖负荷是将建筑物保持在指定温度所需的热能量，无论外部温度如何，冬季通常为 65° 华氏度。"
        }
    },
    {
        "translation": {
            "en": "Based on the expected volumes of images that would be produced by the SDSS pipeline, Jocelyn and Edwin agreed that the model developed should be capable of performing approximately 1,000 classifications per second on a dedicated server of modest specification.",
            "zh": "根据 SDSS 管道将产生的预期图像量，Jocelyn 和 Edwin 一致认为，开发的模型应该能够在中等规格的专用服务器上每秒执行大约 1,000 次分类。"
        }
    },
    {
        "translation": {
            "en": "0.32",
            "zh": "0.32"
        }
    },
    {
        "translation": {
            "en": "The revised predictions are also used in making predictions for query instances. The predicted level for a query, q, is the level associated with the one-versus-all model that outputs the highest result after normalization. We can write this",
            "zh": "修订后的预测还用于对查询实例进行预测。查询的预测级别 q 是与规范化后输出最高结果的一对多模型关联的级别。我们可以这样写"
        }
    },
    {
        "translation": {
            "en": "The stride parameter specifies the distance between the center of the local receptive field of one neuron and the center of the local receptive fields of its horizontal or vertical neighbor in the set of neurons sharing the filter.",
            "zh": "步幅参数指定一个神经元的局部感受野中心与共享滤波器的一组神经元中其水平或垂直邻居的局部感受野中心之间的距离。"
        }
    },
    {
        "translation": {
            "en": "So, this set has zero entropy.",
            "zh": "所以，这个集合的熵为零。"
        }
    },
    {
        "translation": {
            "en": "If the two features being visualized have a strong relationship, then the bar plots for each level of the second feature will look noticeably different from one another and from the overall bar plot for the first feature.",
            "zh": "如果要可视化的两个要素具有很强的关系，则第二个要素的每个级别的条形图看起来彼此明显不同，并且与第一个要素的整体条形图明显不同。"
        }
    },
    {
        "translation": {
            "en": "Description: Second edition. | Cambridge, Massachusetts: The MIT Press, 2020. | Includes bibliographical references and index.",
            "zh": "描述：第二版。|马萨诸塞州剑桥：麻省理工学院出版社，2020 年。|包括参考书目和索引。"
        }
    },
    {
        "translation": {
            "en": "Daelemans and van den Bosch (2005) discuss why nearest neighbor models are so suitable for text analytics.",
            "zh": "Daelemans 和 van den Bosch （2005） 讨论了为什么最近邻模型如此适用于文本分析。"
        }
    },
    {
        "translation": {
            "en": "0.3057",
            "zh": "0.3057"
        }
    },
    {
        "translation": {
            "en": "The impact of this larger standard deviation on the weights in the network is evident if we compare Figure 8.23(a)[453] with Figure 8.24(a)[454]: although the distribution of weights within each layer looks similar in the two figures, the scales on the weights axes show that the weights plotted in Figure 8.24(a)[454] have a larger variance from the median 0, indicating that the weights tend to be larger.",
            "zh": "如果我们将图8.23（a）[453]与图8.24（a）[454]进行比较，这种较大的标准差对网络中权重的影响是显而易见的：尽管在两个图中，每层内的权重分布看起来相似，但权重轴上的刻度显示，图8.24（a）[454]中绘制的权重与中位数0的方差更大， 表示权重往往更大。"
        }
    },
    {
        "translation": {
            "en": "[Payment prediction] Data Requirements: This solution would require the full details of policies and claims as well as data on the original amount specified in a claim and the amount ultimately paid out. Capacity Requirements: Again, this solution assumes that the company has the potential to run this model in a timely fashion whenever new claims rise and also has the capacity to make offers to claimants. This assumes the existence of a customer contact center or something similar.",
            "zh": "[付款预测]数据要求：此解决方案将需要保单和索赔的完整详细信息，以及索赔中指定的原始金额和最终支付的金额的数据。容量要求：同样，此解决方案假设公司有可能在新索赔出现时及时运行此模型，并且还有能力向索赔人提出报价。这假定存在客户联络中心或类似的东西。"
        }
    },
    {
        "translation": {
            "en": "It is more convenient for us to convert the output of the log function to positive numbers by multiplying them by − 1.",
            "zh": "通过将对数函数的输出乘以 − 1，将对数转换为正数对我们来说更方便。"
        }
    },
    {
        "translation": {
            "en": "2.4.2 Different Types of Features",
            "zh": "2.4.2 不同类型的功能"
        }
    },
    {
        "translation": {
            "en": "5. Fat finger is a phrase often used in financial trading to refer to mistakes that arise when a trader enters extra zeros by mistake and buys or sells much more of a stock than intended.",
            "zh": "5. 胖手指是金融交易中经常使用的一个短语，指的是当交易者错误地输入额外的零并买入或卖出比预期多得多的股票时出现的错误。"
        }
    },
    {
        "translation": {
            "en": "5. Instances should be added to the training dataset only if we have determined after making the prediction that the prediction was, in fact, correct. In this example, we assume that at the draft, the query player was drafted.",
            "zh": "5. 只有当我们在做出预测后确定预测实际上是正确的时，才应将实例添加到训练数据集中。在此示例中，我们假设在草稿时，查询播放器是草稿。"
        }
    },
    {
        "translation": {
            "en": "For example, consider Neuron 4 in our example network.",
            "zh": "例如，考虑我们示例网络中的神经元 4。"
        }
    },
    {
        "translation": {
            "en": "From these domain concepts, Ross worked on deriving a set of descriptive features.",
            "zh": "从这些领域概念中，Ross 致力于推导出一组描述性特征。"
        }
    },
    {
        "translation": {
            "en": "An alternative to entirely deleting features that suffer from large numbers of missing values is to derive a missing indicator feature from them.",
            "zh": "完全删除存在大量缺失值的特征的替代方法是从中派生缺失指标特征。"
        }
    },
    {
        "translation": {
            "en": "3.4091",
            "zh": "3.4091"
        }
    },
    {
        "translation": {
            "en": "This was reasonably straightforward as AT management had stated that their goal was to reduce their customer churn rates.",
            "zh": "这相当简单，因为 AT 管理层曾表示他们的目标是降低客户流失率。"
        }
    },
    {
        "translation": {
            "en": "The spiral category further divided into clockwise spiral and anti-clockwise spiral subcategories.",
            "zh": "螺旋类别进一步分为顺时针螺旋和逆时针螺旋子类别。"
        }
    },
    {
        "translation": {
            "en": "28. Schapire (1999) gives a readable introduction to boosting by one of the originators of the technique.",
            "zh": "28. Schapire （1999） 对该技术的创始人之一的提升进行了可读的介绍。"
        }
    },
    {
        "translation": {
            "en": "A joint probability distribution is a probability distribution over more than one feature assignment and is written as a multidimensional matrix in which each cell lists the probability of a particular combination of feature values being assigned.",
            "zh": "联合概率分布是多个特征分配的概率分布，写成一个多维矩阵，其中每个单元格列出了分配特征值的特定组合的概率。"
        }
    },
    {
        "translation": {
            "en": "13. This approach is related to binning, as described in Section 3.6.2[89]. Simply binning continuous features to convert them into categorical features is another valid approach to handling continuous features in decision trees.",
            "zh": "13. 这种方法与分箱有关，如第 3.6.2 节所述[89]。简单地将连续特征装箱以将它们转换为分类特征是处理决策树中连续特征的另一种有效方法。"
        }
    },
    {
        "translation": {
            "en": "Table 6.11[278] lists this extended dataset.",
            "zh": "表6.11[278]列出了这个扩展数据集。"
        }
    },
    {
        "translation": {
            "en": "Table 8.2",
            "zh": "表 8.2"
        }
    },
    {
        "translation": {
            "en": "12   Case Study: Customer Churn",
            "zh": "12 案例研究：客户流失"
        }
    },
    {
        "translation": {
            "en": "Outliers are values that lie far away from the central tendency of a feature.",
            "zh": "异常值是远离特征中心趋势的值。"
        }
    },
    {
        "translation": {
            "en": "For clarity of explanation, however, we have ignored these in this discussion of the fundamentals required to understand the approaches to reinforcement learning that are discussed in this chapter.",
            "zh": "然而，为了清楚解释，我们在讨论理解本章讨论的强化学习方法所需的基础知识时忽略了这些。"
        }
    },
    {
        "translation": {
            "en": "Designing ABTs that properly represent the characteristics of a prediction subject is a key skill for analytics practitioners.",
            "zh": "设计正确表示预测主体特征的 ABT 是分析从业者的一项关键技能。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn suggested that she would first work on the coarse classification of galaxies into elliptical and spiral categories, and then, depending on how this model performed, look at classifying spirals into the more fine-grained categories.",
            "zh": "Jocelyn建议她首先将星系粗略地分类为椭圆星系和螺旋星系，然后根据该模型的表现，将星系分类为更细粒度的类别。"
        }
    },
    {
        "translation": {
            "en": "(a) The ensemble contains 11 independent models, all of which have an error rate of 0.2.",
            "zh": "（a） 该集合包含11个独立模型，所有模型的错误率为0.2。"
        }
    },
    {
        "translation": {
            "en": "In these stacked feature map inputs, each channel then encodes the information from a particular filter spectrum (for example, the information from the horizontal edge detector filter spectrum) instead of encoding the information in a particular color spectrum (Charniak, 2019).",
            "zh": "在这些堆叠的特征图输入中，每个通道然后对来自特定滤波器光谱的信息（例如，来自水平边缘检测器滤波器光谱的信息）进行编码，而不是对特定色谱中的信息进行编码（Charniak，2019）。"
        }
    },
    {
        "translation": {
            "en": "A derived feature containing the ratio between the claim amount and the total value of the premiums paid to date on the policy is included.",
            "zh": "包括一个派生特征，其中包含索赔金额与保单迄今为止已支付的保费总价值之间的比率。"
        }
    },
    {
        "translation": {
            "en": "false positive rate, 548",
            "zh": "误报率，548"
        }
    },
    {
        "translation": {
            "en": "This is the partial derivative of the error surface with respect to a particular weight w[j] and indicates the gradient of the error surface. Using this formulation for the gradient, we can write the weight update rule for logistic regression as",
            "zh": "这是误差曲面相对于特定权重 w[j] 的偏导数，表示误差曲面的梯度。使用这个梯度公式，我们可以将逻辑回归的权重更新规则写为"
        }
    },
    {
        "translation": {
            "en": "0.62",
            "zh": "0.62"
        }
    },
    {
        "translation": {
            "en": "There are two important observations regarding the division in Bayes’ Theorem by the denominator P(Y). The first is that this division functions as a normalization mechanism ensuring that",
            "zh": "关于贝叶斯定理中分母 P（Y） 的除法有两个重要的观察结果。首先，这种划分作为一种规范化机制，确保"
        }
    },
    {
        "translation": {
            "en": "Chapter 3[53]",
            "zh": "第3章[53]"
        }
    },
    {
        "translation": {
            "en": "4.2.2   Shannon’s Entropy Model",
            "zh": "4.2.2 香农熵模型"
        }
    },
    {
        "translation": {
            "en": "0.120800",
            "zh": "0.120800"
        }
    },
    {
        "translation": {
            "en": "BLANDCHROMATIN: A measure of the texture of cell nuclei (1 to 10).",
            "zh": "BLANDCHROMATIN：细胞核质地的量度（1 到 10）。"
        }
    },
    {
        "translation": {
            "en": "The actual process for determining domain concepts is essentially one of knowledge elicitation—attempting to extract from domain experts the knowledge about the scenario we are trying to model. Often, this process will take place across multiple meetings, involving the analytics and domain experts, where the set of relevant domain concepts for the analytics solution are developed and refined.",
            "zh": "确定领域概念的实际过程本质上是知识获取的过程之一，即试图从领域专家那里提取有关我们试图建模的场景的知识。通常，此过程将在多个会议中进行，涉及分析和领域专家，在这些会议中，分析解决方案的相关领域概念集被开发和完善。"
        }
    },
    {
        "translation": {
            "en": "It turns out that these slightly larger weight values can dramatically affect the internal dynamics of the network during training.",
            "zh": "事实证明，这些稍大的权重值可以极大地影响训练期间网络的内部动态。"
        }
    },
    {
        "translation": {
            "en": "weight update rule, 327, 403",
            "zh": "重量更新规则，327,403"
        }
    },
    {
        "translation": {
            "en": "The prediction model that we would build using this data would be deployed to predict whether newly arising claims are likely to be fraudulent.",
            "zh": "我们将使用这些数据构建的预测模型将用于预测新出现的索赔是否可能是欺诈性的。"
        }
    },
    {
        "translation": {
            "en": "The maximum entropy for sets with three elements is 1.58 and occurs when there are equal numbers of each type in the set, as is the case shown in Figure 4.5(e)[124].",
            "zh": "具有三个元素的集合的最大熵为1.58，当集合中每种类型的数量相等时，就会发生，如图4.5（e）所示[124]。"
        }
    },
    {
        "translation": {
            "en": "For support vector machines, we first set the negative target feature level to − 1 and the positive target feature level to + 1. We then build a support vector machine prediction model so that instances with the negative target level result in the model outputting ≤−1 and instances with the positive target level result in the model outputting ≥ +1. The space between the outputs of − 1 and + 1 allows for the margin.",
            "zh": "对于支持向量机，我们首先将负目标特征级别设置为 − 1，将正目标特征级别设置为 + 1。然后，我们构建了一个支持向量机预测模型，以便具有负目标水平的实例导致模型输出 ≤−1，具有正目标水平的实例导致模型输出≥ +1。− 1 和 + 1 输出之间的空间允许裕量。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.9(a)[287] illustrates a simple Bayesian network. This network describes a domain consisting of two features A and B. The directed link from A to B indicates that the value of A directly influences the value of B. In probability terms, the directed edge from A to B in Figure 6.9(a)[287] states that",
            "zh": "图6.9（a）[287]说明了一个简单的贝叶斯网络。该网络描述了由两个特征 A 和 B 组成的域。从 A 到 B 的定向链接表明 A 的值直接影响 B 的值。从概率的角度来看，图6.9（a）[287]中从A到B的有向边表示"
        }
    },
    {
        "translation": {
            "en": "To further support his model, Ross organized a control group test (see Section 9.4.6[578]) in which for two months, the AT customer base was randomly divided into two groups, and call lists for the retention team were selected from the first group using the old approach based on calls to customer care, and for the second group using the new decision tree model.",
            "zh": "为了进一步支持他的模型，Ross 组织了一个对照组测试（参见第 9.4.6 节 [578]），在两个月的时间里，AT 客户群被随机分为两组，保留团队的呼叫列表使用基于客户服务呼叫的旧方法从第一组中选择，第二组使用新的决策树模型。"
        }
    },
    {
        "translation": {
            "en": "Throughout the discussion in the previous sections about central tendency and variation, we consistently used the word sample to refer to the set of values in an ABT for a particular feature.",
            "zh": "在前几节中关于集中趋势和变化的讨论中，我们一直使用“样本”一词来指代 ABT 中特定特征的值集。"
        }
    },
    {
        "translation": {
            "en": "13.3   Features from the ABT for the SDSS galaxy classification problem.",
            "zh": "13.3 ABT中关于SDSS星系分类问题的特征。"
        }
    },
    {
        "translation": {
            "en": "To show how boosting works in practice, we use a modified version of the bike rentals dataset used in Section 4.4.3[149].",
            "zh": "为了展示提升在实践中的工作原理，我们使用了第 4.4.3 节[149] 中使用的自行车租赁数据集的修改版本。"
        }
    },
    {
        "translation": {
            "en": "Recall that we are dealing with vectors of gradients, and so for each layer we will do an elementwise product with a vector of activation function derivatives; also, the derivatives of the activation functions are dependent on whether the neurons in the layer are using a sigmoid or tanh function.",
            "zh": "回想一下，我们正在处理梯度向量，因此对于每一层，我们将使用激活函数导数的向量进行逐元素乘积;此外，激活函数的导数取决于该层中的神经元是使用 S 形结肠还是 tanh 函数。"
        }
    },
    {
        "translation": {
            "en": "The second term in the product, ∂a i/∂λi, is the gradient of the activation function with respect to changes in λi.",
            "zh": "乘积中的第二项 ∂a i/∂λi 是激活函数相对于 λi 变化的梯度。"
        }
    },
    {
        "translation": {
            "en": "Equation 8.52[449] shows the last line from Equation 8.41[436] and is annotated to explain how extreme weights can make gradients unstable.",
            "zh": "等式 8.52[449] 显示了等式 8.41[436] 的最后一行，并进行了注释以解释极端权重如何使梯度不稳定。"
        }
    },
    {
        "translation": {
            "en": "Different models offer different levels of explanation capacity and therefore different levels of interpretability.",
            "zh": "不同的模型提供不同程度的解释能力，因此提供不同程度的可解释性。"
        }
    },
    {
        "translation": {
            "en": "Chapter 8 is a new chapter on deep learning that covers the fundamentals of artificial neural networks as well as the most important network architectures used in modern machine learning applications for images, language, and more. This brings the book right up to date with the most recent developments in machine learning.",
            "zh": "第 8 章是关于深度学习的新章节，涵盖了人工神经网络的基础知识以及现代机器学习应用程序中使用的最重要的网络架构，用于图像、语言等。这使本书与机器学习的最新发展保持同步。"
        }
    },
    {
        "translation": {
            "en": "We now have the two terms we need to calculate δ8, and Equation 8.32[427] steps through the calculation of δ8 for d2.",
            "zh": "我们现在有了计算 δ8 所需的两个项，方程 8.32[427] 逐步计算了 d2 的 δ8。"
        }
    },
    {
        "translation": {
            "en": "19. For example, there might be errors in the target feature or descriptive feature values of one or more of the training instances.",
            "zh": "19. 例如，一个或多个训练实例的目标特征或描述性特征值可能存在错误。"
        }
    },
    {
        "translation": {
            "en": "Once again he went to the kitchen to inspect and agreed that Amalia had also done a great job of organizing the letters.",
            "zh": "他又一次去厨房检查，并同意阿玛利亚在整理信件方面也做得很好。"
        }
    },
    {
        "translation": {
            "en": "Each element in a vector is identified by a single index. For example:",
            "zh": "向量中的每个元素都由单个索引标识。例如："
        }
    },
    {
        "translation": {
            "en": "(a) A 3D plot of an error surface and (b) a bird’s-eye view contour plot of the same error surface. The lines indicate the path that the gradient descent algorithm would take across this error surface from four different starting positions to the global minimum—marked as the white dot in the center.",
            "zh": "（a） 误差面的 3D 图和 （b） 同一误差面的鸟瞰等值线图。这些线表示梯度下降算法从四个不同的起始位置到全局最小值（标记为中心的白点）穿过此误差表面的路径。"
        }
    },
    {
        "translation": {
            "en": "In Section 3.6.1[87] we discussed variance and introduced a number of normalization techniques that normalize the variances in a set of features.",
            "zh": "在第 3.6.1 节[87]中，我们讨论了方差，并介绍了一些归一化技术，这些技术可以归一化一组特征中的方差。"
        }
    },
    {
        "translation": {
            "en": "However, it is because deep learning models are inspired by the human brain that they are known as artificial neural networks: they are designed (at least at a very abstract level) to mirror the structure of the brain, and the adoption of a learning mechanism based on adjusting the connections between neurons can be understood as mimicking Hebb’s theory of how the brain learns.",
            "zh": "然而，正是因为深度学习模型受到人脑的启发，它们才被称为人工神经网络：它们被设计（至少在非常抽象的层面上）来反映大脑的结构，并且采用基于调整神经元之间连接的学习机制可以理解为模仿Hebb的大脑如何学习的理论。"
        }
    },
    {
        "translation": {
            "en": "Illustration of the robustness of the student-t distribution to outliers: (a) a density histogram of a unimodal dataset overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data; and (b) a density histogram of the same dataset with outliers added, overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data. (This figure is inspired by Figure 2.16 in Bishop (2006).)",
            "zh": "学生 t 分布对异常值的鲁棒性说明：（a） 单峰数据集的密度直方图，叠加了已拟合到数据的正态分布和学生 t 分布的密度曲线;（b）添加了异常值的同一数据集的密度直方图，与已拟合到数据的正态分布和学生-t分布的密度曲线叠加。（这个数字的灵感来自Bishop （2006）中的图2.16。"
        }
    },
    {
        "translation": {
            "en": "Examining the INCOME row in the data quality report also shows a large difference between the mean and median values, which is unusual.",
            "zh": "检查数据质量报告中的 INCOME 行还显示平均值和中位数之间存在很大差异，这是不寻常的。"
        }
    },
    {
        "translation": {
            "en": "6. When using the reciprocal of the squared distance as a weighting function, we need to be careful to avoid division by zero in the case in which the query is exactly the same as its nearest neighbor. Typically this problem case is handled by assigning the query the target level of the training instance d that it exactly matches.",
            "zh": "6. 当使用平方距离的倒数作为加权函数时，我们需要注意避免在查询与其最近邻完全相同的情况下除以零。通常，此问题案例是通过为查询分配完全匹配的训练实例 d 的目标级别来处理的。"
        }
    },
    {
        "translation": {
            "en": "Each of the images in the top row shows a feature space defined by two continuous descriptive features, F1 and F2, partitioned into good and bad regions by three different, artificially created decision boundaries.3 In the subsequent images, we show the decision boundaries that are learned by four different machine learning algorithms based on training datasets generated according to the decision boundaries shown in the top row.",
            "zh": "顶行中的每张图像都显示了一个由两个连续描述性特征 F1 和 F2 定义的特征空间，由三个不同的、人工创建的决策边界划分为好区域和坏区域.3 在随后的图像中，我们展示了由四种不同的机器学习算法根据根据顶行所示的决策边界生成的训练数据集学习的决策边界。"
        }
    },
    {
        "translation": {
            "en": "3.11   A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73] with correlation coefficients included.",
            "zh": "3.11 一个散点图矩阵，显示了表3.7[73]中职业篮球队数据集中连续特征的散点图，包括相关系数。"
        }
    },
    {
        "translation": {
            "en": "7.6   A dataset listing features for a number of generators.",
            "zh": "7.6 列出许多生成器特征的数据集。"
        }
    },
    {
        "translation": {
            "en": "Table 9.19",
            "zh": "表 9.19"
        }
    },
    {
        "translation": {
            "en": "Mac Namee (2009) provides an overview of the dominant approaches in using intelligent agent systems in games and entertainment applications.",
            "zh": "Mac Namee（2009）概述了在游戏和娱乐应用中使用智能代理系统的主要方法。"
        }
    },
    {
        "translation": {
            "en": "OCCUPATION",
            "zh": "职业"
        }
    },
    {
        "translation": {
            "en": "A.4  The members of the rival school basketball team from Figure A.3[747] ordered by height.",
            "zh": "A.4 图A.3[747]中对手学校篮球队的成员按身高排序。"
        }
    },
    {
        "translation": {
            "en": "density histogram, 753",
            "zh": "密度直方图，753"
        }
    },
    {
        "translation": {
            "en": "11.2.3 Markov Decision Processes",
            "zh": "11.2.3 马尔可夫决策过程"
        }
    },
    {
        "translation": {
            "en": "We are delighted to take this opportunity to acknowledge these contributions to the book.",
            "zh": "我们很高兴借此机会感谢这些对本书的贡献。"
        }
    },
    {
        "translation": {
            "en": "Therefore, we should use ELEVATION ≥ 4,175 as the test at the root node of the tree, as shown in Figure 4.13[149].",
            "zh": "因此，我们应该使用 ELEVATION ≥ 4,175 作为树根节点的测试，如图 4.13[149] 所示。"
        }
    },
    {
        "translation": {
            "en": "12.2   A data quality report for the Acme Telephonica ABT.",
            "zh": "12.2 Acme Telephonica ABT的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Traditionally, the most frequent heuristic used to initialize the weights of a neural network was randomly sampling values from a normal or uniform distribution with a mean of 0.",
            "zh": "传统上，用于初始化神经网络权重的最常见启发式方法是从均值为 0 的正态分布或均匀分布中随机抽样值。"
        }
    },
    {
        "translation": {
            "en": "In the first part of this chapter we present an approach to developing analytics solutions that address specific business problems.",
            "zh": "在本章的第一部分中，我们将介绍一种开发解决特定业务问题的分析解决方案的方法。"
        }
    },
    {
        "translation": {
            "en": "stratified sampling, 93, 710",
            "zh": "分层抽样， 93， 710"
        }
    },
    {
        "translation": {
            "en": "The model shown in Equation (7.2)[313] is defined by the weights w[0] = 6.47 and w[1] = 0.62.",
            "zh": "公式（7.2）[313]中所示的模型由权重w[0] = 6.47和w[1] = 0.62定义。"
        }
    },
    {
        "translation": {
            "en": "The dynamics of an environment in which an agent transitions between states, a Markov process, can be captured in a transition matrix",
            "zh": "智能体在状态之间转换的环境（马尔可夫过程）的动态可以在转换矩阵中捕获"
        }
    },
    {
        "translation": {
            "en": "neural network, 369, 381, 383, 599, 624, 629, 669, 735",
            "zh": "神经网络， 369， 381， 383， 599， 624， 629， 669， 735"
        }
    },
    {
        "translation": {
            "en": "Often states and actions are explicitly named, in which case we use the following formatting: STATE and action.",
            "zh": "通常，状态和操作是显式命名的，在这种情况下，我们使用以下格式：STATE 和 action。"
        }
    },
    {
        "translation": {
            "en": "Post-pruning is an alternative approach to tree pruning in which the tree induction algorithm is allowed to grow a tree to completion, and then each branch on the tree is examined in turn.",
            "zh": "修剪后是树木修剪的另一种方法，其中允许树木诱导算法将一棵树生长到完成，然后依次检查树上的每个分支。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7",
            "zh": "图 5.7"
        }
    },
    {
        "translation": {
            "en": "Doctors could use the outputs of such a system to help them make better dosing decisions.21 The mean squared error for the multivariable linear regression model is 1.905 and for the k-NN model is 4.394.",
            "zh": "21 多变量线性回归模型的均方误差为 1.905，k-NN 模型的均方误差为 4.394。"
        }
    },
    {
        "translation": {
            "en": "For example, the confusion matrices shown in Tables 9.5[551] and 9.6[551] show the performance of two different models on a test dataset that relates to a prediction problem in which we would like to predict whether a customer will churn or not.",
            "zh": "例如，表 9.5[551] 和 9.6[551] 中所示的混淆矩阵显示了两个不同模型在测试数据集上的性能，这些模型与预测问题有关，我们希望在该问题中预测客户是否会流失。"
        }
    },
    {
        "translation": {
            "en": "The time horizon for which data is available. It is important that the data available covers the period required for the analytics solution. For example, in an online gaming scenario, it might be possible to find out every customer’s account balance today but utterly impossible to find out what their balance was last month, or even yesterday.",
            "zh": "数据可用的时间范围。重要的是，可用数据必须涵盖分析解决方案所需的时间段。例如，在在线游戏场景中，今天可能可以找到每个客户的账户余额，但完全不可能找出他们上个月甚至昨天的余额。"
        }
    },
    {
        "translation": {
            "en": "3.09",
            "zh": "3.09"
        }
    },
    {
        "translation": {
            "en": "Figure 2.9[43] shows these descriptive features in a portion of the domain concept diagram.",
            "zh": "图 2.9[43] 在领域概念图的一部分中显示了这些描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The churn model replaced the random selection of customers by assigning every customer in the company’s customer base a churn risk score and selecting the 1,000 customers with the highest churn risk scores to receive a call from the customer contact center.",
            "zh": "客户流失模型取代了随机选择客户，方法是为公司客户群中的每个客户分配一个客户流失风险评分，并选择流失风险评分最高的 1,000 名客户来接听来自客户联络中心的电话。"
        }
    },
    {
        "translation": {
            "en": "Grace had played a significant role in developing the process that had made information about customer support contacts available to the customer retention team.",
            "zh": "Grace 在开发流程方面发挥了重要作用，该流程向客户保留团队提供有关客户支持联系人的信息。"
        }
    },
    {
        "translation": {
            "en": "In fact, there are now as many neurons in the grid as there are valid pixels in the image.",
            "zh": "事实上，现在网格中的神经元数量与图像中的有效像素数量一样多。"
        }
    },
    {
        "translation": {
            "en": "centroid linkage: the distance between the centroids of two clusters is used as the overall distance between the clusters.",
            "zh": "质心联动：两个簇的质心之间的距离作为簇之间的总距离。"
        }
    },
    {
        "translation": {
            "en": "Figure 12.1",
            "zh": "图 12.1"
        }
    },
    {
        "translation": {
            "en": "8.2.4   Why Are Non-Linear Activation Functions Necessary?",
            "zh": "8.2.4 为什么需要非线性激活函数？"
        }
    },
    {
        "translation": {
            "en": "So, when you consider both the likelihood of an answer and how an answer splits up the domain of solutions, it becomes clear that an answer to Question 2 leaves you with more work to do to solve the game than an answer to Question 1.",
            "zh": "因此，当你同时考虑答案的可能性以及答案如何划分解决方案领域时，很明显，问题 2 的答案比问题 1 的答案让你有更多的工作要做来解决游戏。"
        }
    },
    {
        "translation": {
            "en": "We backpropagate through the other elementwise products that occur in the forward pass within the LSTM using a similar strategy: in order to calculate the backpropagated error gradient for one input to a product, we multiply the error gradient for the result of the product by the other input to the product.",
            "zh": "我们使用类似的策略在 LSTM 中前向传递中出现的其他逐向乘积进行反向传播：为了计算乘积的一个输入的反向传播误差梯度，我们将乘积结果的误差梯度乘以乘积的另一个输入。"
        }
    },
    {
        "translation": {
            "en": "Sometimes it is useful to talk about the probabilities for all the possible assignments to a feature.",
            "zh": "有时，讨论对一个特征的所有可能赋值的概率是很有用的。"
        }
    },
    {
        "translation": {
            "en": "Each instance in a dataset is represented by a point on the plot determined by the values for that instance of the two features being plotted.",
            "zh": "数据集中的每个实例都由绘图上的一个点表示，该点由正在绘制的两个要素的该实例的值确定。"
        }
    },
    {
        "translation": {
            "en": "The most important tool used during data exploration is the data quality report.",
            "zh": "数据浏览过程中使用的最重要的工具是数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "The conditional probability for an event given that we know another event is true is calculated by dividing the number of rows in the dataset where both events are true by the number of rows in the dataset where just the given event is true. For example, the conditional probability for the event DICE1 = given that DICE2 = would be calculated as",
            "zh": "假设我们知道另一个事件为真，则事件的条件概率是通过将数据集中两个事件都为真的行数除以数据集中仅给定事件为真的行数来计算的。例如，事件 DICE1 = 的条件概率 DICE2 = 的计算公式为"
        }
    },
    {
        "translation": {
            "en": "32. These errors are often known as the model residuals.",
            "zh": "32. 这些误差通常称为模型残差。"
        }
    },
    {
        "translation": {
            "en": "In Table 10.1[604] the columns labeled Cluster Distances Iter.",
            "zh": "在表 10.1[604] 中，标记为 Cluster Distances Iter 的列。"
        }
    },
    {
        "translation": {
            "en": "crowdsourcing, 708",
            "zh": "众包，708"
        }
    },
    {
        "translation": {
            "en": "The first step in creating an interior node is to decide which descriptive feature should be tested at this node (Line 8 of Algorithm 1[134]).",
            "zh": "创建内部节点的第一步是决定应在此节点上测试哪个描述性特征（算法 1 的第 8 行[134]）。"
        }
    },
    {
        "translation": {
            "en": "The second requirement is that the Markov chain used to generate the samples must be ergodic.",
            "zh": "第二个要求是用于生成样品的马尔可夫链必须是遍历的。"
        }
    },
    {
        "translation": {
            "en": "A common business model for online services is to allow users a free trial period after which time they have to sign up to a paid account to continue using the service.",
            "zh": "在线服务的一种常见商业模式是允许用户免费试用期，之后他们必须注册付费帐户才能继续使用该服务。"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM remains an appropriate process to follow, the approach to designing data representations based on domain concepts is still very useful, and the project flow presented in Section 2.5[44] is still appropriate.",
            "zh": "CRISP-DM仍然是一个合适的过程，基于领域概念设计数据表示的方法仍然非常有用，第2.5节[44]中介绍的项目流程仍然适用。"
        }
    },
    {
        "translation": {
            "en": "This is an example of an imbalanced dataset, in which the different levels of the target feature—in this case, churners and non-churners—are not equally represented in the data.",
            "zh": "这是一个不平衡数据集的示例，其中目标要素的不同级别（在本例中为流失者和非流失者）在数据中的表示方式不相等。"
        }
    },
    {
        "translation": {
            "en": "normalization constant, 251",
            "zh": "归一化常数，251"
        }
    },
    {
        "translation": {
            "en": "We can measure the performance of a decision tree by presenting the instances in the validation to the decision tree and comparing the predictions made for these instances with the actual target feature values in the dataset.",
            "zh": "我们可以通过将验证中的实例呈现给决策树并将对这些实例所做的预测与数据集中的实际目标特征值进行比较来衡量决策树的性能。"
        }
    },
    {
        "translation": {
            "en": "The reason is that during the backward pass, error gradients will be multiplied by the Whh matrix multiple times—once for each time-step through which we backpropagate.",
            "zh": "原因是在向后传递过程中，误差梯度将多次乘以 Whh 矩阵——对于我们反向传播的每个时间步长，一次。"
        }
    },
    {
        "translation": {
            "en": "11.4 Extensions and Variations",
            "zh": "11.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "In this instance, both possible predictions have a score of zero!",
            "zh": "在这种情况下，两种可能的预测的分数均为零！"
        }
    },
    {
        "translation": {
            "en": "So, here we define the minimum number of hidden layers necessary for a network to be considered deep as two; under this definition the network in shown Figure 8.4[390] would be described as a deep network.",
            "zh": "因此，在这里，我们将网络视为深度所需的最小隐藏层数定义为两个;根据该定义，图8.4[390]中的网络将被描述为深度网络。"
        }
    },
    {
        "translation": {
            "en": "balanced sample, 693",
            "zh": "平衡样品，693"
        }
    },
    {
        "translation": {
            "en": "Table 8.11",
            "zh": "表 8.11"
        }
    },
    {
        "translation": {
            "en": "We have in fact already come across the weighted sum calculation in Chapter 7[311] when we defined the multivariate linear regression model (see Equation (7.9)[320]).",
            "zh": "事实上，当我们定义多元线性回归模型时，我们已经在第 7 章[311]中遇到了加权和计算（参见方程 （7.9）[320]）。"
        }
    },
    {
        "translation": {
            "en": "expectation, 652",
            "zh": "期望，652"
        }
    },
    {
        "translation": {
            "en": "An ABT for a predictive analytics solution contains a set of instances that are represented by a set of descriptive features and a target feature.",
            "zh": "预测分析解决方案的 ABT 包含一组实例，这些实例由一组描述性特征和一个目标特征表示。"
        }
    },
    {
        "translation": {
            "en": "Calculating covariance.",
            "zh": "计算协方差。"
        }
    },
    {
        "translation": {
            "en": "The vertical gaps between cluster linkages indicate the distance between the two clusters that have been merged.",
            "zh": "集群链接之间的垂直间隙表示已合并的两个集群之间的距离。"
        }
    },
    {
        "translation": {
            "en": "3.8 Further Reading",
            "zh": "3.8 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "Example bar plots for the POSITION feature in Table A.1[750]: (a) frequency bar plot, (b) density bar plot, and (c) order density bar plot.",
            "zh": "表A.1[750]中POSITION特征的示例条形图：（a）频率条形图，（b）密度条形图和（c）阶密度条形图。"
        }
    },
    {
        "translation": {
            "en": "Instead, the ABT has to be created by combining a range of operational data sources together.",
            "zh": "相反，ABT 必须通过将一系列操作数据源组合在一起来创建。"
        }
    },
    {
        "translation": {
            "en": "5.1   Big Idea",
            "zh": "5.1 大创意"
        }
    },
    {
        "translation": {
            "en": "The average monthly bill amount",
            "zh": "平均每月账单金额"
        }
    },
    {
        "translation": {
            "en": "In this instance, the error rate for the root node of this subtree (the STABLE-TEMP node) is 2, whereas the error rate of the leaf nodes of the tree is 0 + 0 = 0.",
            "zh": "在本例中，此子树的根节点（STABLE-TEMP 节点）的错误率为 2，而树的叶节点的错误率为 0 + 0 = 0。"
        }
    },
    {
        "translation": {
            "en": "For example, if we changed the threshold used to generate the predictions shown in Table 9.11[557] from 0.5 to 0.75, the predictions for instances d17, d8, and d6 would change from spam to ham, resulting in their outcomes changing to TN, FN, and FN respectively.",
            "zh": "例如，如果我们将用于生成表 9.11[557] 中所示预测的阈值从 0.5 更改为 0.75，则实例 d17、d8 和 d6 的预测将从 spam 更改为 ham，从而导致其结果分别更改为 TN、FN 和 FN。"
        }
    },
    {
        "translation": {
            "en": "To see the use of a profit matrix in action, consider a prediction problem in which a payday loan company has built a credit scoring model to predict the likelihood that a borrower will default on a loan.",
            "zh": "要了解利润矩阵的实际使用，请考虑一个预测问题，其中发薪日贷款公司建立了一个信用评分模型来预测借款人拖欠贷款的可能性。"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity allows us to do this.",
            "zh": "余弦相似性允许我们这样做。"
        }
    },
    {
        "translation": {
            "en": "(a)–(c) Small multiple box plots (split by the target feature) of some of the features from the SDSS ABT.",
            "zh": "（a）–（c） SDSS ABT中某些特征的小型多箱形图（按目标特征划分）。"
        }
    },
    {
        "translation": {
            "en": "Bernstein, Peter L. 1996. Against the gods: The remarkable story of risk. Wiley.",
            "zh": "伯恩斯坦，彼得 L. 1996 年。与众神对抗：关于风险的非凡故事。威利。"
        }
    },
    {
        "translation": {
            "en": "(a) Missing values",
            "zh": "（a） 缺失值"
        }
    },
    {
        "translation": {
            "en": "8.4 Extensions and Variations",
            "zh": "8.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "The predictions shown in Table 9.11[557] and in the confusion matrix in Table 9.3[539] are based on a prediction score threshold of 0.5.",
            "zh": "表9.11[557]和表9.3[539]中的混淆矩阵中显示的预测基于0.5的预测分数阈值。"
        }
    },
    {
        "translation": {
            "en": "ROC index, 558",
            "zh": "中华民国指数，558"
        }
    },
    {
        "translation": {
            "en": "This is happening because the salary values are much larger than the age values.",
            "zh": "发生这种情况是因为工资值远大于年龄值。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, for prediction problems like those posed by the office rentals dataset, the associated error surfaces have two properties that help us find the optimal combination of weights: they are convex, and they have a global minimum.",
            "zh": "幸运的是，对于像办公室租赁数据集这样的预测问题，相关的误差曲面有两个属性可以帮助我们找到权重的最佳组合：它们是凸的，并且它们具有全局最小值。"
        }
    },
    {
        "translation": {
            "en": "(d) Assuming that Q-learning is being used with α = 0.2 and γ = 0.9, update the entry in the action-value table for the action simulated in Part (c).",
            "zh": "（d） 假设 Q 学习在 α = 0.2 和 γ = 0.9 的情况下使用，则更新 （c） 部分中模拟的动作值表中的条目。"
        }
    },
    {
        "translation": {
            "en": "cardinality, 54, 54, 693",
            "zh": "基数，54,54,693"
        }
    },
    {
        "translation": {
            "en": "mode, 54, 69, 746, 749",
            "zh": "模式，54、69、746、749"
        }
    },
    {
        "translation": {
            "en": "2.3   Designing the Analytics Base Table",
            "zh": "2.3 设计分析基表"
        }
    },
    {
        "translation": {
            "en": "There is one case in which we might deal directly with missing values that arise from valid data during data exploration. If the proportion of missing values for a feature is very high, a good rule of thumb is anything in excess of 60%, then the amount of information stored in the feature is so low that it is probably a good idea to simply remove that feature from the ABT.",
            "zh": "在一种情况下，我们可以直接处理在数据探索过程中由有效数据产生的缺失值。如果某个特征的缺失值比例非常高，一个好的经验法则是超过 60%，那么存储在特征中的信息量非常低，因此从 ABT 中删除该特征可能是个好主意。"
        }
    },
    {
        "translation": {
            "en": "Measuring the difference in descriptive feature distributions can be useful, however, in understanding what has changed to make a model go stale.",
            "zh": "然而，测量描述性特征分布的差异对于理解哪些变化使模型过时很有用。"
        }
    },
    {
        "translation": {
            "en": "(a) What is the entropy in bits of the letters in this set?",
            "zh": "（甲）这组字母的熵是多少？"
        }
    },
    {
        "translation": {
            "en": "Q-learning, 637, 657, 657, 676, 680, 741",
            "zh": "Q-learning， 637， 657， 657， 676， 680， 741"
        }
    },
    {
        "translation": {
            "en": "This variation in the data stops the model from memorizing the training data and forces it to learn patterns that generalize over sets of features rather than relying on a particular feature (or small subset of features).",
            "zh": "数据中的这种变化会阻止模型记住训练数据，并迫使它学习在特征集上泛化的模式，而不是依赖于特定特征（或特征的一小部分）。"
        }
    },
    {
        "translation": {
            "en": "That said, sampling bias is a difficult problem to tackle.",
            "zh": "也就是说，抽样偏差是一个难以解决的问题。"
        }
    },
    {
        "translation": {
            "en": "However, for many of the other statistical distributions, for example, the mixture of Gaussians distribution, we cannot define an equation over the data that estimates the parameters appropriately.",
            "zh": "但是，对于许多其他统计分布，例如高斯分布的混合，我们无法在数据上定义一个方程来适当估计参数。"
        }
    },
    {
        "translation": {
            "en": "dataset, 5, 758",
            "zh": "数据集， 5， 758"
        }
    },
    {
        "translation": {
            "en": "0.65",
            "zh": "0.65"
        }
    },
    {
        "translation": {
            "en": "CNN, 477",
            "zh": "美国有线电视新闻网，477"
        }
    },
    {
        "translation": {
            "en": "5.7   Epilogue",
            "zh": "5.7 结语"
        }
    },
    {
        "translation": {
            "en": "Figure 10.3(b)[602] shows the initial randomly selected cluster centroids overlaid onto the dataset, where c1 = −1.1048,−0.1324, c2 = −0.8431,−1.2239, and c3 = −1.2744,0.2187.",
            "zh": "图10.3（b）[602]显示了叠加在数据集上的初始随机选择的聚类质心，其中c1 = −1.1048，−0.1324，c2 = −0.8431，−1.2239，c3 = −1.2744,0.2187。"
        }
    },
    {
        "translation": {
            "en": "Ted quickly made two observations.",
            "zh": "泰德很快提出了两个意见。"
        }
    },
    {
        "translation": {
            "en": "Finally, a feature characterized by a multimodal distribution has two or more very commonly occurring ranges of values that are clearly separated.",
            "zh": "最后，以多峰分布为特征的特征具有两个或多个非常常见的值范围，这些值范围是明确分开的。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.18",
            "zh": "图 7.18"
        }
    },
    {
        "translation": {
            "en": "This is why the XOR function is not linearly separable.",
            "zh": "这就是为什么 XOR 函数不是线性可分的。"
        }
    },
    {
        "translation": {
            "en": "The range of the basketball player heights in Figure A.1[746] is 163 − 140 = 23 and for those in Figure A.3[747] is 192 − 102 = 90. These measures match what we intuitively see in these figures—the heights of the second team vary much more than those of the first team. The main advantage of using the range is the ease with which it is calculated. The major disadvantage of the range, however, is that it is highly sensitive to outliers.",
            "zh": "图A.1[746]中篮球运动员的身高范围为163 − 140 = 23，图A.3[747]中的篮球运动员身高范围为192 − 102 = 90。这些衡量标准与我们在这些数字中直观地看到的相符——二队的身高变化比一队的高要大得多。使用范围的主要优点是易于计算。然而，该范围的主要缺点是它对异常值高度敏感。"
        }
    },
    {
        "translation": {
            "en": "Table 3.9",
            "zh": "表 3.9"
        }
    },
    {
        "translation": {
            "en": "8.4   The per example error after the forward pass illustrated in Figure 8.14[425], the per example ∂ℰ/∂a 8, and the sum of squared errors for the model over the dataset of four examples.",
            "zh": "8.4 图 8.14[425] 所示的前向传递后的每例误差、每例 ∂E/∂a 8 以及模型在四个示例数据集上的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "This table is ordered so that the weights for inputs to Neuron 8 are at the top, and then as we move down the table, we move back through the network.",
            "zh": "这个表是有序的，这样Neuron 8的输入权重就放在了顶部，然后当我们在表格中向下移动时，我们又通过网络向后移动。"
        }
    },
    {
        "translation": {
            "en": "Once the player enters one of the terminal states (BUST, LOSE, TIE, WIN, or TWENTYTWO) the game is over and there are no more actions to take.",
            "zh": "一旦玩家进入最终状态之一（BUST、LOSE、TIE、WIN 或 TWENTYTWO），游戏就结束了，没有更多的行动可做。"
        }
    },
    {
        "translation": {
            "en": "7.4.5 Modeling Non-Linear Relationships",
            "zh": "7.4.5 非线性关系建模"
        }
    },
    {
        "translation": {
            "en": "(a) The following table presents the scoring by two models of the test set of candidate idioms. Which model would be chosen to filter candidate idioms if the decision were taken on the basis of the F1 score for each model, assuming both models use a threshold of > 0.5 for classifying a candidate as an idiom.",
            "zh": "（a） 下表列出了两种模型对候选习语测试集的评分情况。假设两个模型都使用>阈值 0.5 将候选习语分类为习语，则如果根据每个模型的 F1 分数做出决定，则选择哪个模型来过滤候选习语。"
        }
    },
    {
        "translation": {
            "en": "When using small multiples, it is important that all the small charts are kept consistent because this ensures that only genuine differences within the data are highlighted, rather than differences that arise from formatting.",
            "zh": "使用小倍数时，所有小图表保持一致非常重要，因为这样可以确保仅突出显示数据中的真正差异，而不是因格式设置而产生的差异。"
        }
    },
    {
        "translation": {
            "en": "By doing this, the Bayesian prediction model is able to calculate reasonable probabilities for queries with combinations of evidence that do not occur in the dataset.",
            "zh": "通过这样做，贝叶斯预测模型能够计算出具有数据集中未出现的证据组合的查询的合理概率。"
        }
    },
    {
        "translation": {
            "en": "21. Covariance between features means that knowing the value of one feature tells us something about the value of the other feature. See Section 3.5.2[219] for more information.",
            "zh": "21. 特征之间的协方差意味着知道一个特征的价值可以告诉我们有关另一个特征的价值的一些信息。有关更多信息，请参见第 3.5.2[219] 节。"
        }
    },
    {
        "translation": {
            "en": "For example, it may be that the network outputs only a single value once it has processed the whole sequence; this scenario might hold if we were training a network to process a sentence and then return a label describing the sentiment—positive or negative—expressed in the sentence.",
            "zh": "例如，网络在处理完整个序列后可能只输出一个值;如果我们训练一个网络来处理一个句子，然后返回一个标签来描述句子中表达的情绪（积极或消极），这种情况可能会成立。"
        }
    },
    {
        "translation": {
            "en": "Backward Pass The error of the network is calculated by comparing the output generated by the forward pass with the target output specified in the dataset.",
            "zh": "后向传递 通过将前向传递生成的输出与数据集中指定的目标输出进行比较来计算网络的误差。"
        }
    },
    {
        "translation": {
            "en": "NUMRETENTIONOFFERS",
            "zh": "NUMRETENTION优惠"
        }
    },
    {
        "translation": {
            "en": "This model is",
            "zh": "这个模型是"
        }
    },
    {
        "translation": {
            "en": "40. The data in this table has been artificially generated for this question, but is inspired by the results from the Framingham Heart Study: www.framinghamheartstudy.org.",
            "zh": "40. 本表中的数据是针对这个问题人为生成的，但受到弗雷明汉心脏研究结果的启发：www.framinghamheartstudy.org。"
        }
    },
    {
        "translation": {
            "en": "To illustrate how adjusting the variance of the sample distribution used to initialize the weights of a network affects the dynamics of the network during training, we will scale up our example network so that the effects become apparent.",
            "zh": "为了说明调整用于初始化网络权重的样本分布的方差如何影响训练期间网络的动态，我们将扩展示例网络，以便效果变得明显。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 5[420] brings together the different topics covered in the preceding sections.",
            "zh": "算法 5[420] 汇集了前面各节中涵盖的不同主题。"
        }
    },
    {
        "translation": {
            "en": "(a) Looking up the results on the other modules of the student whose script hasn’t been corrected, the lecturer finds that the student got the following marks: MODULE 1=60, and MODULE 2=85. Assuming that the k-nearest neighbor model uses k=1 and Euclidean distance as its similarity metric, what GRADE would the model assign the student?",
            "zh": "（a） 查找脚本未被纠正的学生的其他模块的结果，讲师发现该学生获得了以下分数：模块 1=60，模块 2=85。假设 k 最近邻模型使用 k=1 和欧几里得距离作为其相似度指标，该模型会给学生分配什么 GRADE？"
        }
    },
    {
        "translation": {
            "en": "So which approach should we use?",
            "zh": "那么我们应该使用哪种方法呢？"
        }
    },
    {
        "translation": {
            "en": "33. The story recounted here of the discovery of the platypus is loosely based on real events. See Eco (1999) for a more faithful account of what happened and for a discussion of the implications of this discovery for classification systems in general. The platypus is not the only animal from Australia whose discovery by Europeans has relevance to predictive machine learning. See Taleb (2008) regarding the discovery of black swans and its relevance to predictive models.",
            "zh": "33. 这里讲述的鸭嘴兽发现的故事大致是根据真实事件改编的。参见Eco （1999）对所发生事件的更忠实的描述，并讨论了这一发现对一般分类系统的影响。鸭嘴兽并不是唯一一种来自澳大利亚的动物，欧洲人的发现与预测机器学习有关。参见Taleb （2008）关于黑天鹅的发现及其与预测模型的相关性。"
        }
    },
    {
        "translation": {
            "en": "0.74572",
            "zh": "0.74572"
        }
    },
    {
        "translation": {
            "en": "Unless a project is focused on clearly stated goals, it is unlikely to be successful.",
            "zh": "除非一个项目专注于明确规定的目标，否则它不太可能成功。"
        }
    },
    {
        "translation": {
            "en": "Dealer High (DH): 8 − 11",
            "zh": "经销商最高价 （DH）： 8 − 11"
        }
    },
    {
        "translation": {
            "en": "There are a couple of interesting things that are evident, however.",
            "zh": "然而，有几件有趣的事情是显而易见的。"
        }
    },
    {
        "translation": {
            "en": "2. See Kelleher (2019) for a history of the development of neural network models and the emergence of deep learning.",
            "zh": "2. 参见 Kelleher （2019） 了解神经网络模型的发展和深度学习的出现的历史。"
        }
    },
    {
        "translation": {
            "en": "2. What is supervised machine learning?",
            "zh": "2. 什么是监督机器学习？"
        }
    },
    {
        "translation": {
            "en": "Example of using small multiple histograms to visualize the relationship between a categorical feature and a continuous feature. All examples use data from the professional basketball team dataset in Table 3.7[73]: (a) a histogram of the AGE feature; (b) a histogram of the HEIGHT feature; (c) histograms of the AGE feature for instances displaying each level of the POSITION feature; and (d) histograms of the HEIGHT feature for instances displaying each level of the POSITION feature.",
            "zh": "使用小型多重直方图可视化分类要素和连续要素之间关系的示例。所有示例均使用表3.7[73]中职业篮球队数据集的数据：（a）AGE特征的直方图;（b） 高度特征的直方图;（c） 显示 POSITION 特征每个级别的实例的 AGE 特征直方图;以及 （d） 显示 POSITION 特征每个级别的实例的 HEIGHT 特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Consequently, we can counteract this scaling by the number of inputs by setting var(W) = 1/nin; that is, by setting the variance of the distribution that the weights for a neuron are sampled from to 1/nin.",
            "zh": "因此，我们可以通过设置 var（W） = 1/nin 来抵消输入数量来抵消这种缩放;也就是说，通过将神经元权重采样的分布方差设置为 1/nin。"
        }
    },
    {
        "translation": {
            "en": "Table 9.7",
            "zh": "表 9.7"
        }
    },
    {
        "translation": {
            "en": "Another approach to avoiding dead ReLUs is to modify the rectified linear function so that it does not saturate for z < 0.",
            "zh": "避免死 ReLU 的另一种方法是修改整流后的线性函数，使其在 z < 0 时不会饱和。"
        }
    },
    {
        "translation": {
            "en": "This is because if a parent node is unknown, then to compute the distribution for the node, we must sum out this parent.",
            "zh": "这是因为如果父节点是未知的，那么要计算该节点的分布，我们必须对这个父节点求和。"
        }
    },
    {
        "translation": {
            "en": "(a) A number of values are missing from these workings (indicated by ??). Calculate the missing values. The distances between each instance in the dataset from Question 1 (using Euclidean distance) are shown in the following distance matrix, and will be useful for this exercise.",
            "zh": "（a） 这些工作方式中缺少一些值（用？？）表示。计算缺失值。问题 1 中数据集中每个实例之间的距离（使用欧几里得距离）显示在以下距离矩阵中，对本练习很有用。"
        }
    },
    {
        "translation": {
            "en": "It is clear from this figure that the weighted sum of the three normals does an excellent job of modeling the multimodal density distribution.",
            "zh": "从这张图中可以清楚地看出，三个正态的加权和在模拟多模态密度分布方面做得非常出色。"
        }
    },
    {
        "translation": {
            "en": "1. Note that subtraction is viewed as addition of negative numbers, and division is seen as multiplication by reciprocals, so both are also allowed.",
            "zh": "1. 请注意，减法被视为负数的加法，除法被视为倒数的乘法，因此两者都是允许的。"
        }
    },
    {
        "translation": {
            "en": "9. Hence the name Iterative Dichotomizer.",
            "zh": "9. 因此得名迭代二分法器。"
        }
    },
    {
        "translation": {
            "en": "The simple nature of this first trained model is evident from the predictions made by Δ1 shown in Table 4.15[166].",
            "zh": "从表4.15[166]所示的Δ1的预测中可以明显看出第一个训练模型的简单性。"
        }
    },
    {
        "translation": {
            "en": "FIBER2MAG_U/G/R/I/Z",
            "zh": "FIBER2MAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The consequence of this is that each instance from the original dataset can appear more than once in the sampled dataset.14 After having created the larger samples from each group, we combine these to form the overall over-sampled dataset.",
            "zh": "这样做的结果是，原始数据集中的每个实例都可以在采样数据集中出现不止一次。14 在从每个组创建较大的样本后，我们将这些样本组合在一起以形成整个过采样数据集。"
        }
    },
    {
        "translation": {
            "en": "The evaluation of machine learning models is a live research issue, and a large body of material addresses all the questions that have been discussed in this chapter.",
            "zh": "机器学习模型的评估是一个实时研究问题，大量材料解决了本章中讨论的所有问题。"
        }
    },
    {
        "translation": {
            "en": "2.4.4   Legal Issues",
            "zh": "2.4.4 法律问题"
        }
    },
    {
        "translation": {
            "en": "Figure A.5",
            "zh": "图 A.5"
        }
    },
    {
        "translation": {
            "en": "similarity measure, 181",
            "zh": "相似度测量，181"
        }
    },
    {
        "translation": {
            "en": "So, for example, each row in Table 6.1[246] represents an experiment, and the assignment of the descriptive features to the values shown in each row can be referred to as a distinct event.",
            "zh": "因此，例如，表 6.1[246] 中的每一行都代表一个实验，并且将描述性特征分配给每行中显示的值可以称为一个不同的事件。"
        }
    },
    {
        "translation": {
            "en": "Sometimes Conor would be very happy with his choices (his reward would be high), but sometimes he would be disappointed (his reward would be low).",
            "zh": "有时康纳会对他的选择感到非常满意（他的回报会很高），但有时他会感到失望（他的回报会很低）。"
        }
    },
    {
        "translation": {
            "en": "Adaboost.R2, 161",
            "zh": "Adaboost.R2,161"
        }
    },
    {
        "translation": {
            "en": "In a grid world scenario an agent must learn to navigate an environment from a start position to a goal position, often avoiding obstacles along the way.",
            "zh": "在网格世界场景中，智能体必须学会将环境从起始位置导航到目标位置，并经常避开沿途的障碍物。"
        }
    },
    {
        "translation": {
            "en": "information theory, 117, 126",
            "zh": "信息论， 117， 126"
        }
    },
    {
        "translation": {
            "en": "stride, 486",
            "zh": "步幅，486"
        }
    },
    {
        "translation": {
            "en": "Creating models that can identify queries as being sufficiently different from what was in a training dataset so as to be considered a new type of entity is a difficult research problem. Some of the areas of research relevant to this problem include outlier detection and one-class classification.",
            "zh": "创建能够识别查询与训练数据集中的内容有足够差异的模型，从而被视为一种新型实体是一个困难的研究问题。与此问题相关的一些研究领域包括异常值检测和一类分类。"
        }
    },
    {
        "translation": {
            "en": "Rather, it is because of the way that the answer to each question splits the character cards into different sets based on the value of the descriptive feature the question is asked about (MAN, LONG HAIR or GLASSES) and the likelihood of each possible answer to the question.",
            "zh": "相反，这是因为每个问题的答案根据问题所提出的描述性特征（男人、长发或眼镜）的值以及每个可能答案的可能性将角色卡分成不同的集合。"
        }
    },
    {
        "translation": {
            "en": "batch normalization, 523",
            "zh": "批量归一化，523"
        }
    },
    {
        "translation": {
            "en": "This is quite a dramatic increase; however, it gets even more dramatic when we increase from two to three descriptive features.",
            "zh": "这是一个相当大的增长;然而，当我们从两个描述性特征增加到三个描述性特征时，它变得更加戏剧化。"
        }
    },
    {
        "translation": {
            "en": "1. Detailed descriptions of the story of Professor Blondlot and N rays are available in Klotz (1980) and Ashmore (1993).",
            "zh": "1. Klotz （1980） 和 Ashmore （1993） 对 Blondlot 教授和 N 射线的故事进行了详细描述。"
        }
    },
    {
        "translation": {
            "en": "The gray columns in each of the activation and z matrices trace the processing of the second example through the sequence of operations.",
            "zh": "每个激活矩阵和 z 矩阵中的灰色列通过操作序列跟踪第二个示例的处理过程。"
        }
    },
    {
        "translation": {
            "en": "In the model visualizations black circles show the training dataset, gray squares show the predictions made for the instances in the training dataset by the current model, and the dotted line shows the predictions that would be made by the current model for the full range of input temperatures.",
            "zh": "在模型可视化中，黑色圆圈表示训练数据集，灰色方块表示当前模型对训练数据集中的实例所做的预测，虚线表示当前模型将对整个输入温度范围进行的预测。"
        }
    },
    {
        "translation": {
            "en": "The prediction score distributions shown in Figure 9.9(a)[557] are much better separated than those in Figure 9.9(b)[557].",
            "zh": "图9.9（a）[557]所示的预测分数分布比图9.9（b）[557]中的预测分数分布要好得多。"
        }
    },
    {
        "translation": {
            "en": "These kinds of publications are an invaluable resource for an analytics professional trying to come to grips with a new topic.",
            "zh": "对于试图掌握新主题的分析专业人员来说，这些类型的出版物是宝贵的资源。"
        }
    },
    {
        "translation": {
            "en": "The second target feature allowed three levels for spiral galaxies: spiral_cw (P_CW majority), spiral_acw (P_ACW majority), and spiral_edge (P_EDGE majority).",
            "zh": "第二个目标特征允许螺旋星系分为三个层次：spiral_cw（P_CW多数）、spiral_acw（P_ACW多数）和spiral_edge（P_EDGE多数）。"
        }
    },
    {
        "translation": {
            "en": "-0.39",
            "zh": "-0.39"
        }
    },
    {
        "translation": {
            "en": "There are two important things to remember in designing these base cases.",
            "zh": "在设计这些基本情况时，需要记住两件重要的事情。"
        }
    },
    {
        "translation": {
            "en": "To calculate the probability of an event, we have simply counted how often the event occurred and divided this number by how often the event could have occurred. A continuous feature can have an infinite number of values in its domain, so any particular value will occur a negligible amount of the time. In fact, the relative frequency of any particular value for a continuous feature will be indistinguishable from zero given a large dataset.",
            "zh": "为了计算事件的概率，我们只需计算事件发生的频率，然后将该数字除以事件发生的频率。连续要素在其域中可以有无限数量的值，因此任何特定值的出现时间可以忽略不计。事实上，在给定大型数据集的情况下，连续特征的任何特定值的相对频率都无法与零区分开来。"
        }
    },
    {
        "translation": {
            "en": "Bagging/Boosting",
            "zh": "装袋/提升"
        }
    },
    {
        "translation": {
            "en": "data, 3",
            "zh": "数据， 3"
        }
    },
    {
        "translation": {
            "en": "A multi-layer feedforward neural network that uses only linear neurons (i.e., neurons that do not include a non-linear activation function) is equivalent to a single-layer network with linear neurons; in other words, it can represent only a linear mapping on the inputs.",
            "zh": "仅使用线性神经元（即不包含非线性激活函数的神经元）的多层前馈神经网络等效于具有线性神经元的单层网络;换句话说，它只能表示输入上的线性映射。"
        }
    },
    {
        "translation": {
            "en": "John D. Kelleher, Brian Mac Namee, and Aoife D’Arcy",
            "zh": "John D. Kelleher、Brian Mac Namee 和 Aoife D'Arcy"
        }
    },
    {
        "translation": {
            "en": "This example demonstrates that, using the DQN algorithm, it is possible to train agents to perform very sophisticated tasks using modern deep neural networks combined with very basic state representations—in this case just screenshots from the game.",
            "zh": "此示例演示了使用 DQN 算法，可以使用现代深度神经网络结合非常基本的状态表示来训练代理执行非常复杂的任务，在本例中只是游戏的屏幕截图。"
        }
    },
    {
        "translation": {
            "en": "Finally, we cover a second use case of unsupervised learning, to generate representations that will be used in other machine learning approaches rather than as an end result in their own right.",
            "zh": "最后，我们介绍了无监督学习的第二个用例，以生成将用于其他机器学习方法的表示，而不是作为最终结果。"
        }
    },
    {
        "translation": {
            "en": "This means that the if statement on Line 8 fails, and the search moves to the parent of the current node (Line 11).",
            "zh": "这意味着第 8 行的 if 语句失败，搜索将移动到当前节点的父节点（第 11 行）。"
        }
    },
    {
        "translation": {
            "en": "Perhaps one of the other items on the menu is even better than chicken, but following a greedy policy will never allow Conor the opportunity to learn this.",
            "zh": "也许菜单上的其他项目之一甚至比鸡肉更好，但遵循贪婪的政策永远不会让康纳有机会学习这一点。"
        }
    },
    {
        "translation": {
            "en": "Using this dataset, generate the following binned versions of the IQ feature:",
            "zh": "使用此数据集，生成以下 IQ 特征的分箱版本："
        }
    },
    {
        "translation": {
            "en": "© 2020 Massachusetts Institute of Technology",
            "zh": "© 2020 麻省理工学院"
        }
    },
    {
        "translation": {
            "en": "chain rule (probability), 245, 251, 257, 291, 757, 763, 768",
            "zh": "链式法则（概率），245、251、257、291、757、763、768"
        }
    },
    {
        "translation": {
            "en": "Figure 7.9[336] shows an example of this in which learning rate decay is used with α0 = 0.25 and c = 100.",
            "zh": "图 7.9[336] 显示了一个示例，其中学习率衰减用于 α0 = 0.25 和 c = 100。"
        }
    },
    {
        "translation": {
            "en": "The heavier the weight of the line used to plot the hyperplane, the earlier in the tree the split occurred.",
            "zh": "用于绘制超平面的线的权重越重，树中分裂发生得越早。"
        }
    },
    {
        "translation": {
            "en": "For example, we cannot train error-based models with data that contains missing values, and data that contains outliers significantly damages the performance of similarity-based models.",
            "zh": "例如，我们无法使用包含缺失值的数据训练基于错误的模型，而包含异常值的数据会严重损害基于相似性的模型的性能。"
        }
    },
    {
        "translation": {
            "en": "At this point the design of the ABT had fallen into place. For the most part, Jocelyn would use descriptive features directly from the raw SDSS data. These would be augmented with a small number of derived features that the literature review undertaken with Edwin had identified. Jocelyn was now ready to move into the Data Preparation phase, during which she would populate the ABT, analyze its contents in detail, and perform any transformations that were required to handle data quality issues.",
            "zh": "至此，ABT的设计已经到位。在大多数情况下，Jocelyn 会直接使用原始 SDSS 数据中的描述性特征。这些将通过与Edwin一起进行的文献综述所确定的少量衍生特征来增强。Jocelyn 现在已准备好进入数据准备阶段，在此期间，她将填充 ABT，详细分析其内容，并执行处理数据质量问题所需的任何转换。"
        }
    },
    {
        "translation": {
            "en": "These models are used to inform resource management and conservation activities,10 such as managing the distribution of animal species and vegetation across geographic regions.",
            "zh": "这些模型用于为资源管理和保护活动提供信息，10 例如管理动物物种和植被在地理区域的分布。"
        }
    },
    {
        "translation": {
            "en": "deep learning, xvi, 19, 381, 396, 599, 624, 629, 637, 676, 773",
            "zh": "深度学习， xvi， 19， 381， 396， 599， 624， 629， 637， 676， 773"
        }
    },
    {
        "translation": {
            "en": "While there are no hard and fast rules about what constitutes an acceptable value for the ROC index, and this is really an application-specific decision, a good rule of thumb is that a value above 0.7 indicates a strong model, while a value below 0.6 indicates a weak model.",
            "zh": "虽然对于ROC指数的可接受值没有硬性规定，这实际上是一个特定于应用的决定，但一个好的经验法则是，高于0.7的值表示强模型，而低于0.6的值表示弱模型。"
        }
    },
    {
        "translation": {
            "en": "Similarly, the Data Preparation and Modeling phases are closely linked, and analytics projects often spend some time alternating between these two phases.",
            "zh": "同样，数据准备和建模阶段密切相关，分析项目通常会在这两个阶段之间交替花费一些时间。"
        }
    },
    {
        "translation": {
            "en": "In general, parametric models make stronger assumptions about the underlying distributions of the data in a domain.",
            "zh": "通常，参数化模型对域中数据的基本分布做出更强的假设。"
        }
    },
    {
        "translation": {
            "en": "Neural network models are particularly useful for representation learning, and this is a large part of the promise of deep learning, as discussed in Chapter 8[381].",
            "zh": "神经网络模型对于表征学习特别有用，这是深度学习的很大一部分，如第8章[381]所述。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this dataset are defined as follows:",
            "zh": "此数据集中的描述性特征定义如下："
        }
    },
    {
        "translation": {
            "en": "If the event of the target feature t taking the level l causes the assignment of values to the descriptive features, q[1],…,q[m], then the events of each descriptive feature taking a value are conditionally independent of each other given the value of the target feature. This means that the chain rule definition can be simplified as follows:",
            "zh": "如果目标特征 t 的事件达到 l 级别，导致将值分配给描述性特征 q[1],...,q[m]，则在给定目标特征的值的情况下，每个获取值的描述性特征的事件在条件上彼此独立。这意味着链式规则的定义可以简化如下："
        }
    },
    {
        "translation": {
            "en": "0.40",
            "zh": "0.40"
        }
    },
    {
        "translation": {
            "en": "− 13.92",
            "zh": "− 13.92"
        }
    },
    {
        "translation": {
            "en": "The ε-greedy policy is often used together with Q-learning for choosing actions that balance exploration and exploitation and will be used in this section.19",
            "zh": "ε贪婪策略通常与 Q-learning 一起使用，用于选择平衡探索和利用的行动，本节将使用19。"
        }
    },
    {
        "translation": {
            "en": "Table 7.10[355] shows a dataset, the EEG dataset, based on a neurological experiment designed to capture how neural responses change when experiment participants view positive images (e.g., a picture of a smiling baby) and negative images (e.g., a picture of rotting food).",
            "zh": "表7.10[355]显示了一个数据集，即脑电图数据集，该数据集基于神经学实验，旨在捕捉实验参与者看到正面图像（例如，微笑的婴儿的照片）和负面图像（例如，腐烂食物的图片）时神经反应的变化。"
        }
    },
    {
        "translation": {
            "en": "The link between temporal-difference learning and gradient descent was already made in Section 11.2.5[654].",
            "zh": "时间差分学习和梯度下降之间的联系已经在第 11.2.5 节中建立[654]。"
        }
    },
    {
        "translation": {
            "en": "probability-based learning, 19, 243",
            "zh": "基于概率的学习， 19， 243"
        }
    },
    {
        "translation": {
            "en": "where the values used are again extracted from Table 3.3[57]. Examining the histogram in Figure 3.1(h)[58] is again a good indication of the impact of using this transformation. This impact can be reduced by changing the multiplier used to calculate the thresholds from 2 to a larger value.",
            "zh": "其中使用的值再次从表3.3[57]中提取。检查图3.1（h）[58]中的直方图再次很好地表明了使用这种变换的影响。通过将用于计算阈值的乘数从 2 更改为更大的值，可以减少这种影响。"
        }
    },
    {
        "translation": {
            "en": "First, the two squares on the left of the figure represent the two memory locations through which inputs are presented to this network.",
            "zh": "首先，图左侧的两个方块表示输入呈现给该网络的两个内存位置。"
        }
    },
    {
        "translation": {
            "en": "dosage prediction, 3",
            "zh": "剂量预测，3"
        }
    },
    {
        "translation": {
            "en": "the probability that an event has happened given a set of evidence for it is equal to the probability of the evidence being caused by the event multiplied by the probability of the event itself",
            "zh": "给定一组证据，事件发生的概率等于证据由事件引起的概率乘以事件本身的概率"
        }
    },
    {
        "translation": {
            "en": "The division of data during the leave-one-out cross validation process. Black rectangles indicate instances in the test set, and white spaces indicate training data.",
            "zh": "在“留一”交叉验证过程中的数据划分。黑色矩形表示测试集中的实例，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor model uses both the SALARY and AGE features when it calculates distances to find the nearest neighbor to the query.",
            "zh": "最近邻模型在计算距离以查找查询的最近邻时同时使用 SALARY 和 AGE 特征。"
        }
    },
    {
        "translation": {
            "en": "In a box plot the vertical axis shows the range of values that a feature can take.",
            "zh": "在箱形图中，纵轴显示要素可以采用的值范围。"
        }
    },
    {
        "translation": {
            "en": "Original",
            "zh": "源语言"
        }
    },
    {
        "translation": {
            "en": "3.4   Handling Data Quality Issues",
            "zh": "3.4 处理数据质量问题"
        }
    },
    {
        "translation": {
            "en": "(a) The area under a density curve between the limits and ; (b) the approximation of this area computed by PDF(x)×ε; and (c) the error in the approximation is equal to the difference between area A, the area under the curve omitted from the approximation, and area B, the area above the curve erroneously included in the approximation. Both of these areas will get smaller as the width of the interval gets smaller, resulting in a smaller error in the approximation.",
            "zh": "（a） 边界和 之间的密度曲线下的面积;（b） 由PDF（x）×ε计算的面积的近似值;（c）近似误差等于面积A（从近似中省略的曲线下面积）和面积B（曲线上方的面积错误地包含在近似值中）之间的差值。随着间隔宽度变小，这两个区域都会变小，从而导致近似误差变小。"
        }
    },
    {
        "translation": {
            "en": "In this example, before the training process begins, both descriptive features are normalized to the range [−1, 1].",
            "zh": "在此示例中，在训练过程开始之前，两个描述性特征都归一化为范围 [−1， 1]。"
        }
    },
    {
        "translation": {
            "en": "1   Machine Learning for Predictive Data Analytics",
            "zh": "1 用于预测数据分析的机器学习"
        }
    },
    {
        "translation": {
            "en": "Equation (8.71)[467] specifies that the cross-entropy loss for the network is dependent solely on the negative natural log of the probability of the correct prediction, per Equation (8.67)[466].",
            "zh": "方程（8.71）[467]指出，根据方程（8.67）[466]，网络的交叉熵损失仅取决于正确预测概率的负自然对数。"
        }
    },
    {
        "translation": {
            "en": "noise, 7, 66, 69, 191",
            "zh": "噪音， 7， 66， 69， 191"
        }
    },
    {
        "translation": {
            "en": "Once domain concepts have been agreed on, the next task is to design and implement concrete features based on these concepts.",
            "zh": "一旦领域概念达成一致，下一个任务就是基于这些概念设计和实现具体功能。"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that predictive data analytics models built using machine learning techniques are tools that we can use to help make better decisions within an organization and are not an end in themselves.",
            "zh": "重要的是要记住，使用机器学习技术构建的预测数据分析模型是我们可以用来帮助在组织内做出更好决策的工具，其本身并不是目的。"
        }
    },
    {
        "translation": {
            "en": "The business problem and goals should always be expressed in business terms and not yet be concerned with the actual analytics work at this stage.",
            "zh": "业务问题和目标应始终以业务术语表达，而在此阶段还不关心实际的分析工作。"
        }
    },
    {
        "translation": {
            "en": "This line is known as a decision boundary.",
            "zh": "这条线称为决策边界。"
        }
    },
    {
        "translation": {
            "en": "For example, consider the number of features we can derive from the monthly payment a customer makes on an electricity bill.",
            "zh": "例如，考虑我们可以从客户每月支付的电费中获得的功能数量。"
        }
    },
    {
        "translation": {
            "en": "Calculate the ROC index for this model using the trapezoidal method and the following set of thresholds: 1.0, 0.5, and 0.0.",
            "zh": "使用梯形方法和以下一组阈值计算此模型的 ROC 指数：1.0、0.5 和 0.0。"
        }
    },
    {
        "translation": {
            "en": "For example, decision trees and linear regression models are very easily interpreted, while support vector machines, ensembles, and deep neural networks are almost entirely uninterpretable (because of this, they are often referred to as a black box).",
            "zh": "例如，决策树和线性回归模型很容易解释，而支持向量机、集成和深度神经网络几乎完全无法解释（因此，它们通常被称为黑匣子）。"
        }
    },
    {
        "translation": {
            "en": "(a) Before training data becomes available.",
            "zh": "（a） 在训练数据可用之前。"
        }
    },
    {
        "translation": {
            "en": "For example, if D is a 2 × 3 matrix (i.e., a matrix with 2 rows and 3 columns) and E is a 3 × 3 matrix, then the product of these two matrices DE is defined, because the number of columns in D (3) equals the number of rows in E (3).",
            "zh": "例如，如果 D 是 2 × 3 矩阵（即具有 2 行和 3 列的矩阵），而 E 是 3 × 3 矩阵，则定义这两个矩阵 DE 的乘积，因为 D （3） 中的列数等于 E （3） 中的行数。"
        }
    },
    {
        "translation": {
            "en": "As a result, no learning is taking place because the set of consistent models tells us nothing about the underlying relationship between the descriptive and target features beyond what a simple look-up of the training dataset would provide.",
            "zh": "因此，没有进行任何学习，因为除了对训练数据集的简单查找之外，一组一致的模型没有告诉我们描述性和目标特征之间的基本关系。"
        }
    },
    {
        "translation": {
            "en": "This is true no matter how large the sample is.",
            "zh": "无论样本有多大，都是如此。"
        }
    },
    {
        "translation": {
            "en": "Scrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. Mclust 5: Clustering, classification and density estimation using gaussian finite mixture models. The R Journal 8 (1): 289.",
            "zh": "斯克鲁卡、卢卡、迈克尔·福普、T. Brendan Murphy 和 Adrian E. Raftery。2016. Mclust 5：使用高斯有限混合模型进行聚类、分类和密度估计。R杂志8（1）：289。"
        }
    },
    {
        "translation": {
            "en": "-0.3825",
            "zh": "-0.3825"
        }
    },
    {
        "translation": {
            "en": "However, the network now has five fully connected hidden layers with 100 neurons in each layer.",
            "zh": "然而，该网络现在有五个完全连接的隐藏层，每层有 100 个神经元。"
        }
    },
    {
        "translation": {
            "en": "ground truth, 607",
            "zh": "地面实况，607"
        }
    },
    {
        "translation": {
            "en": "Figure 6.4[273] illustrates the distinction between fat and light tail distributions using histograms of two datasets.",
            "zh": "图6.4[273]使用两个数据集的直方图说明了脂肪和轻尾分布之间的区别。"
        }
    },
    {
        "translation": {
            "en": "Bayes, Thomas, and Richard Price. 1763. An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, FRS communicated by Mr. Price, in a letter to John Canton, AMFRS. Philosophical Transactions (1683-1775).",
            "zh": "贝叶斯、托马斯和理查德·普莱斯。1763. 一篇关于解决机会学说中问题的文章。由已故的贝叶斯牧师先生，FRS由Price先生在给AMFRS的John Canton的一封信中传达。哲学汇刊（1683-1775）。"
        }
    },
    {
        "translation": {
            "en": "Having continuous features in an ABT that cover very different ranges can cause difficulty for some machine learning algorithms.",
            "zh": "在 ABT 中具有涵盖非常不同范围的连续特征可能会给某些机器学习算法带来困难。"
        }
    },
    {
        "translation": {
            "en": "valid pixels, 487",
            "zh": "有效像素，487"
        }
    },
    {
        "translation": {
            "en": "This offers huge potential for new science based on this massive data collection effort.",
            "zh": "这为基于这种大规模数据收集工作的新科学提供了巨大的潜力。"
        }
    },
    {
        "translation": {
            "en": "Before we examine the mathematical definition of entropy, we first provide an intuitive explanation of what it means.",
            "zh": "在我们研究熵的数学定义之前，我们首先要直观地解释它的含义。"
        }
    },
    {
        "translation": {
            "en": "Predicting churn is a form of propensity modeling,2 where the event of interest in this case is a customer making the decision to churn.",
            "zh": "预测流失是倾向建模的一种形式，2在这种情况下，感兴趣的事件是客户做出流失的决定。"
        }
    },
    {
        "translation": {
            "en": "4.6   Further Reading",
            "zh": "4.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "Target network freezing is used to address this.",
            "zh": "目标网络冻结用于解决此问题。"
        }
    },
    {
        "translation": {
            "en": "Often we condition the probability of an agent transitioning from one state, s1, to another, s2, on the agent taking a specific action, a. We write this",
            "zh": "通常，我们以智能体采取特定操作 a 来决定智能体从一种状态 s1 过渡到另一种状态 s2 的概率。我们写这个"
        }
    },
    {
        "translation": {
            "en": "The four examples in Table 8.1[422] are only a sample from a larger dataset;18 however, for this example, for ease of illustration we treat these four examples as if they were our full dataset.",
            "zh": "表8.1[422]中的四个示例只是来自较大数据集的样本;18 然而，对于这个例子，为了便于说明，我们将这四个例子视为我们的完整数据集。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.3(a)[62] illustrates how the location of the peak moves as the value for μ changes, and Figure 3.3(b)[62] illustrates how the shape of the curve changes as we vary the value for σ.",
            "zh": "图3.3（a）[62]说明了峰的位置如何随着μ值的变化而移动，图3.3（b）[62]说明了曲线的形状如何随着σ值的变化而变化。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.14[150] shows the decision tree that is ultimately generated from this process.",
            "zh": "图 4.14[150] 显示了最终从该过程生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "The first term in this product, ∂ℰ/∂ai, is the rate of change of the error of the network with respect to changes in the activation function and is calculated as it would be for the weights in the network; for neurons in the output layer, it is calculated using Equation 8.20[411], and for neurons in the hidden layer, it is calculated as the weighted sum of the δs backpropagated to the neuron, per Equation 8.22[412].",
            "zh": "本产品中的第一个项 ∂E/∂ai 是网络误差相对于激活函数变化的变化率，其计算方式与网络中的权重相同;对于输出层中的神经元，使用公式 8.20[411] 计算，对于隐藏层中的神经元，根据公式 8.22[412]，将其计算为反向传播到神经元的 δ 的加权和。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6(a)[39] shows an example in which, rather than being defined by a fixed date, the observation period and outcome period are defined relative to an event that occurs at different dates for each prediction subject.",
            "zh": "图2.6（a）[39]显示了一个示例，其中观察期和结果期不是由固定日期定义的，而是相对于每个预测对象在不同日期发生的事件定义的。"
        }
    },
    {
        "translation": {
            "en": "The per example error after the forward pass illustrated in Figure 8.14[425], the per example ∂ℰ/∂a 8, and the sum of squared errors for the model over the dataset of four examples.",
            "zh": "图 8.14[425] 所示的前向传递之后的每例误差、每例 ∂E/∂a 8 以及模型在四个示例数据集上的平方误差总和。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.16[627] shows a more detailed view of the reconstructions of the first example from Figure 10.15(a)[626], an image of the digit 2. Reconstructed images and the underlying pixel values from before, during, and after training are shown, as well as the corresponding reconstruction errors. It is clear from both the quality of the image shown and the reconstruction errors that the quality of the reconstruction improves as training progresses.",
            "zh": "图10.16[627]显示了图10.15（a）[626]中第一个示例重建的更详细视图，这是数字2的图像。显示了训练前、训练中和训练后的重建图像和基础像素值，以及相应的重建误差。从显示的图像质量和重建错误中可以清楚地看出，随着训练的进行，重建的质量会提高。"
        }
    },
    {
        "translation": {
            "en": "For these reasons, analysts often must rely more heavily on domain experts in projects using unsupervised learning than in performing supervised machine learning tasks.",
            "zh": "由于这些原因，分析师在使用无监督学习的项目中通常必须更多地依赖领域专家，而不是执行监督机器学习任务。"
        }
    },
    {
        "translation": {
            "en": "We can also calculate the expected value from the starting point of an agent’s taking a specific action, at, in a given state, st. This is known as an action-value function and returns the cumulative reward that an agent can expect to earn if it takes an action at in state st and then continues to select actions using policy, π, all the way to the end of an episode. We can write this5",
            "zh": "我们还可以从智能体采取特定操作的起点开始计算期望值，在给定状态下，st。这称为操作值函数，并返回代理在状态 st 时执行操作，然后继续使用策略 （π） 选择操作，一直到剧集结束时可以预期获得的累积奖励。我们可以这样写5"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, in this case we cannot just use the gradient descent algorithm.",
            "zh": "不幸的是，在这种情况下，我们不能只使用梯度下降算法。"
        }
    },
    {
        "translation": {
            "en": "Next, an elementwise product of the vector of activations in the cell state ct−1 with the vector of activations from the sigmoid layer is performed.",
            "zh": "接下来，执行细胞状态 ct-1 中激活向量与来自 S 形结肠层的激活向量的元素乘积。"
        }
    },
    {
        "translation": {
            "en": "true",
            "zh": "真"
        }
    },
    {
        "translation": {
            "en": "Skewed distributions are often said to have long tails toward these very high or very low values.",
            "zh": "通常说偏态分布在这些非常高或非常低的值上有长尾。"
        }
    },
    {
        "translation": {
            "en": "It is obvious from Figure 5.11(a)[203] that the search process will not find any instances closer to the query than d21, nor are there any other hyperplanes that intersect with the target hypersphere.",
            "zh": "从图5.11（a）[203]中可以明显看出，搜索过程不会找到比d21更接近查询的任何实例，也没有任何其他与目标超球体相交的超平面。"
        }
    },
    {
        "translation": {
            "en": "one-versus-all model, 357, 357, 358, 367, 369",
            "zh": "一对多型号，357、357、358、367、369"
        }
    },
    {
        "translation": {
            "en": "In some extreme cases we may have to abandon a domain concept completely if the data required to express it isn’t available.",
            "zh": "在某些极端情况下，如果表达域概念所需的数据不可用，我们可能不得不完全放弃它。"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE feature are missing, so removal would be extreme in this case.",
            "zh": "缺少软组织功能，因此在这种情况下，移除将是极端的。"
        }
    },
    {
        "translation": {
            "en": "Finally, the CONTAINS IMAGES feature has an information gain score of 0 bits.",
            "zh": "最后，CONTAINS IMAGES 功能的信息增益分数为 0 位。"
        }
    },
    {
        "translation": {
            "en": "There are two points worth highlighting:",
            "zh": "有两点值得强调："
        }
    },
    {
        "translation": {
            "en": "In these situations we should use a metric that ignores co-absences.",
            "zh": "在这些情况下，我们应该使用忽略共同缺席的指标。"
        }
    },
    {
        "translation": {
            "en": "To find the optimal decision boundary for a logistic regression problem, we use the gradient descent algorithm (Algorithm 4[326]) to minimize the sum of squared errors based on the training dataset. Figure 7.13[344] shows a series of the candidate models that were explored on the way to finding this boundary. The final panel in Figure 7.13[344] shows how the sum of squared errors changed during the training process.",
            "zh": "为了找到逻辑回归问题的最佳决策边界，我们使用梯度下降算法（算法 4[326]）来最小化基于训练数据集的平方误差之和。图7.13[344]显示了在寻找该边界的过程中探索的一系列候选模型。图 7.13[344] 中的最后一个面板显示了在训练过程中平方误差的总和是如何变化的。"
        }
    },
    {
        "translation": {
            "en": "10.7 Exercises",
            "zh": "10.7 练习"
        }
    },
    {
        "translation": {
            "en": "Table 8.12",
            "zh": "表 8.12"
        }
    },
    {
        "translation": {
            "en": "This configuration means that variance of z values across the neurons in layer HL1 is",
            "zh": "这种配置意味着 HL1 层中神经元之间的 z 值方差为"
        }
    },
    {
        "translation": {
            "en": "5.4.3   Data Normalization",
            "zh": "5.4.3 数据规范化"
        }
    },
    {
        "translation": {
            "en": "In general, however, we are more interested in creating prediction models that generalize well to new data rather than that are strictly consistent with training data, so it is common to sacrifice consistency for generalization capacity.",
            "zh": "然而，总的来说，我们更感兴趣的是创建能够很好地泛化到新数据的预测模型，而不是与训练数据严格一致的预测模型，因此为了泛化能力而牺牲一致性是很常见的。"
        }
    },
    {
        "translation": {
            "en": "Once Ross had reviewed the full data quality report in detail, he made the following decisions regarding the problematic features he had identified.",
            "zh": "一旦 Ross 详细审查了完整的数据质量报告，他就他发现的问题特征做出了以下决定。"
        }
    },
    {
        "translation": {
            "en": "The typical situation where conditional independence holds between events is when the events share the same cause.",
            "zh": "事件之间有条件独立性的典型情况是事件具有相同的原因。"
        }
    },
    {
        "translation": {
            "en": "prediction subject, 23, 29, 689, 707",
            "zh": "预测对象， 23， 29， 689， 707"
        }
    },
    {
        "translation": {
            "en": "(a) Overall profit for the k-NN model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(a)[555]; and (b) overall profit for the decision tree model using the profit matrix in Table 9.8[554] and the confusion matrix in Table 9.9(b)[555].",
            "zh": "（a） 使用表9.8[554]中的利润矩阵和表9.9（a）[555]中的混淆矩阵的k-NN模型的总利润;（b）使用表9.8[554]中的利润矩阵和表9.9（b）[555]中的混淆矩阵的决策树模型的总利润。"
        }
    },
    {
        "translation": {
            "en": "Table 9.22[584] shows the number of customers who churned from each of these two groups during the 12 weeks of the trial, and the associated means and standard deviations.",
            "zh": "表 9.22[584] 显示了在试验的 12 周内从这两组中每组流失的客户数量，以及相关的均值和标准差。"
        }
    },
    {
        "translation": {
            "en": "In this figure, the input to the network is a 6-by-6 matrix of grayscale values to represent a 6-by-6 image41 of a 4; the 4 is shown in the matrix by 255 values.",
            "zh": "在此图中，网络的输入是一个 6×6 的灰度值矩阵，用于表示 4 的 6×6 图像41;4 在矩阵中用 255 个值表示。"
        }
    },
    {
        "translation": {
            "en": "The average distance between d1 and the other members of 𝒞1, the average intra-cluster distance, is the average of these values, which is equal to 0.401, the a(i) value for d1 given in Table 10.2[611].",
            "zh": "d1 和 C1 的其他成员之间的平均距离，即平均簇内距离，是这些值的平均值，等于 0.401，即表 10.2[611] 中给出的 d1 的 a（i） 值。"
        }
    },
    {
        "translation": {
            "en": "Surprisingly, however, as the number of descriptive features in a dataset increases, there often comes a point at which continuing to add new features to the dataset results in a decrease in the predictive power of the induced models.",
            "zh": "然而，令人惊讶的是，随着数据集中描述性特征数量的增加，通常会出现一个点，即继续向数据集添加新特征会导致诱导模型的预测能力下降。"
        }
    },
    {
        "translation": {
            "en": "We can see that, initially, the performance of the model on the validation set falls almost in line with the performance of the model on the training dataset (we usually expect the model to perform slightly better on the training set).",
            "zh": "我们可以看到，最初，模型在验证集上的性能几乎与模型在训练数据集上的性能一致（我们通常期望模型在训练集上的表现略好）。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.12",
            "zh": "图 6.12"
        }
    },
    {
        "translation": {
            "en": "The office rentals dataset from Table 7.1[313] adjusted to handle the categorical ENERGY RATING descriptive feature in linear regression models.",
            "zh": "表7.1[313]中的办公室租赁数据集进行了调整，以处理线性回归模型中的分类ENERGY RATING描述性特征。"
        }
    },
    {
        "translation": {
            "en": "In a non-parametric model the number of parameters used by the model increases as the number of instances increases.",
            "zh": "在非参数模型中，模型使用的参数数随着实例数的增加而增加。"
        }
    },
    {
        "translation": {
            "en": "There are 6 neurons in each of these layers because we are assuming a step size of 1, and so it requires six neurons to convolve one of these filters over the 7-by-1-by-3 input.",
            "zh": "每层都有 6 个神经元，因为我们假设步长为 1，因此需要 6 个神经元在 7×1×3 输入上卷积其中一个滤波器。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.13",
            "zh": "图 4.13"
        }
    },
    {
        "translation": {
            "en": "12. Similar to a hyperplane, a hypersphere is a generalization of the geometric concept of a sphere across multiple dimensions. Hence, in a 2D space the term hypersphere denotes a circle, in 3D it denotes a sphere, and so on.",
            "zh": "12. 与超平面类似，超球体是球体几何概念在多个维度上的推广。因此，在二维空间中，术语超球体表示一个圆，在三维空间中，它表示一个球体，依此类推。"
        }
    },
    {
        "translation": {
            "en": "AGE: The patient’s age",
            "zh": "年龄：患者的年龄"
        }
    },
    {
        "translation": {
            "en": "For transitions based on the Stick action a large number of games of TwentyTwos have been simulated and transition probabilities have been calculated based on this simulation.11",
            "zh": "对于基于摇杆动作的过渡，已经模拟了大量的 TwentyTwo 游戏，并基于此模拟计算了过渡概率11。"
        }
    },
    {
        "translation": {
            "en": "The argument for using a wrapper approach is that to get the best predictive accuracy, the inductive bias of the particular machine learning algorithm that will be used should be taken into consideration during feature selection.",
            "zh": "使用包装方法的论点是，为了获得最佳的预测准确性，在特征选择过程中应考虑将使用的特定机器学习算法的归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "The neurons in these max pooling layers have non-overlapping local receptive fields, and each local receptive field covers two cells in a feature map.",
            "zh": "这些最大池化层中的神经元具有不重叠的局部感受野，并且每个局部感受野覆盖特征图中的两个细胞。"
        }
    },
    {
        "translation": {
            "en": "The defining characteristic of a feedforward network is that there are no loops or cycles in the network connections that would allow the output of a neuron to flow back into the neuron as an input (even indirectly).",
            "zh": "前馈网络的定义特征是，网络连接中没有允许神经元输出作为输入（甚至间接）流回神经元的循环或循环。"
        }
    },
    {
        "translation": {
            "en": "There are a lot of potential answers to this question, and that is why there are a lot of different machine learning algorithms.",
            "zh": "这个问题有很多可能的答案，这就是为什么有很多不同的机器学习算法。"
        }
    },
    {
        "translation": {
            "en": "From this CPT we can see that when SCHOOL YEARS = high, and LIFE EXP = high, then the most likely level is CPI = high.",
            "zh": "从这个 CPT 中我们可以看到，当 SCHOOL YEARS = 高，而 LIFE EXP = 高时，那么最有可能的水平是 CPI = 高。"
        }
    },
    {
        "translation": {
            "en": "The output gate uses a three-step process:",
            "zh": "输出门采用三步工艺："
        }
    },
    {
        "translation": {
            "en": "2. we change the output layer of the network to be a softmax layer; and",
            "zh": "2. 我们将网络的输出层更改为 softmax 层;和"
        }
    },
    {
        "translation": {
            "en": "The intelligent agent view of artificial intelligence overlaps to a large extent with machine learning but is a vibrant field in its own right.",
            "zh": "人工智能的智能代理观点在很大程度上与机器学习重叠，但其本身就是一个充满活力的领域。"
        }
    },
    {
        "translation": {
            "en": "Ross first assessed the level of missing values within the data.",
            "zh": "Ross 首先评估了数据中的缺失值水平。"
        }
    },
    {
        "translation": {
            "en": "center",
            "zh": "中心"
        }
    },
    {
        "translation": {
            "en": "Figure 9.18(d)[582] shows how the stability index could be tracked for the bacterial species identification problem every month for a period of 12 months after model deployment.",
            "zh": "图9.18（d）[582]显示了在模型部署后的12个月内，如何每月跟踪细菌物种识别问题的稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "ensemble, 117",
            "zh": "合奏， 117"
        }
    },
    {
        "translation": {
            "en": "Levitt, Steven D., and Stephen J. Dubner. 2005. Freakonomics: A rogue economist explores the hidden side of everything. Penguin.",
            "zh": "莱维特、史蒂文 D. 和斯蒂芬 J. 杜布纳。2005. 怪胎经济学：一个流氓经济学家探索一切隐藏的一面。企鹅。"
        }
    },
    {
        "translation": {
            "en": "For more detail on unsupervised machine learning algorithms (Friedman et al., 2001) has a fairly comprehensive unsupervised learning section that gives a broader sweep of approaches than those covered in this chapter.",
            "zh": "有关无监督机器学习算法的更多详细信息（Friedman et al.， 2001），有一个相当全面的无监督学习部分，它提供了比本章涵盖的方法更广泛的方法。"
        }
    },
    {
        "translation": {
            "en": "During the backward pass, once we have calculated the δs for the neurons in a layer, we multiply each neuron’s δ by the corresponding element the DropMask vector that was created for that layer during the forward pass (Line 7[476]).",
            "zh": "在向后传递过程中，一旦我们计算了一层中神经元的 δ，我们将每个神经元的δ乘以相应的元素，即在前向传递期间为该层创建的 DropMask 向量（第 7 行[476]）。"
        }
    },
    {
        "translation": {
            "en": "3.3.2   Irregular Cardinality",
            "zh": "3.3.2 不规则基数"
        }
    },
    {
        "translation": {
            "en": "selection bias, 12",
            "zh": "选择偏差，12"
        }
    },
    {
        "translation": {
            "en": "Ideally, the topology of a network should reflect the causal relationships between the entities in a domain.",
            "zh": "理想情况下，网络的拓扑应反映域中实体之间的因果关系。"
        }
    },
    {
        "translation": {
            "en": "Because both the parent nodes for CPI are known (SCHOOL YEARS and LIFE EXP), the probability distribution for CPI is independent of the GINI COEF feature.",
            "zh": "由于 CPI 的两个父节点（SCHOOL YEARS 和 LIFE EXP）都是已知的，因此 CPI 的概率分布与 GINI COEF 特征无关。"
        }
    },
    {
        "translation": {
            "en": "Gradient descent starts by selecting a random point within the weight space (i.e., each weight in the multivariable linear regression equation is assigned a random value within some sensible range) and calculating the sum of squared errors associated with this point based on predictions made for each instance in the training set using the randomly selected weights (as shown in Section 7.2.2[315]).",
            "zh": "梯度下降首先在权重空间中选择一个随机点（即，多变量线性回归方程中的每个权重在某个合理范围内分配一个随机值），并根据使用随机选择的权重对训练集中每个实例所做的预测计算与该点相关的平方误差之和（如第 7.2.2 节[315]所示）。"
        }
    },
    {
        "translation": {
            "en": "In the answers to the following questions, assume that after the initial cards have been dealt to the player and the dealer, the following cards are coming up next in the deck: 10 ♥, 2 ♣, 7 ♣, K ♥, 9 ♦.",
            "zh": "在以下问题的答案中，假设在将初始牌发给玩家和庄家后，以下牌将出现在牌组中：10 ♥、2 ♣、7 ♣、K ♥、9 ♦。"
        }
    },
    {
        "translation": {
            "en": "Normalization techniques can be used to change a continuous feature to fall within a specified range while maintaining the relative differences between the values for the feature.",
            "zh": "归一化技术可用于将连续要素更改为落在指定范围内，同时保持要素值之间的相对差异。"
        }
    },
    {
        "translation": {
            "en": "Bayesian information criterion, 292",
            "zh": "贝叶斯信息准则，292"
        }
    },
    {
        "translation": {
            "en": "identity criterion, 184, 211",
            "zh": "身份标准，184,211"
        }
    },
    {
        "translation": {
            "en": "The template structure of these computational models was first defined by McCulloch and Pitts (1943).",
            "zh": "这些计算模型的模板结构首先由 McCulloch 和 Pitts （1943） 定义。"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 1996. Bagging predictors. Machine Learning 24 (2): 123–140.",
            "zh": "布莱曼，狮子座。1996. 装袋预测因子。机器学习 24 （2）：123–140。"
        }
    },
    {
        "translation": {
            "en": "Table 5.6[206] lists these distances when we include both the SALARY and AGE features, only the SALARY features, and only the AGE feature in the distance calculation.",
            "zh": "表 5.6[206] 列出了当我们在距离计算中同时包括 SALARY 和 AGE 特征、仅包括 SALARY 特征和 AGE 特征时的这些距离。"
        }
    },
    {
        "translation": {
            "en": "probability density function, 61, 246, 269, 758",
            "zh": "概率密度函数， 61， 246， 269， 758"
        }
    },
    {
        "translation": {
            "en": "A good approach is to use box plots to initially determine which pairs of features might have a strong relationship and then further investigate these pairs using small multiple histograms.",
            "zh": "一个好的方法是使用箱形图来初步确定哪些特征对可能具有很强的关系，然后使用小的多重直方图进一步研究这些特征对。"
        }
    },
    {
        "translation": {
            "en": "V   APPENDICES",
            "zh": "五 附录"
        }
    },
    {
        "translation": {
            "en": "Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. 2018. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science 362 (6419): 1140–1144. doi:10.1126/science.aar6404.",
            "zh": "西尔弗、大卫、托马斯·休伯特、朱利安·施里特维瑟、扬尼斯·安东诺格鲁、马修·赖、亚瑟·盖兹、马克·兰克托、洛朗·西弗尔、达山·库马兰、索尔·格雷佩尔、蒂莫西·利利克拉普、凯伦·西蒙尼扬和德米斯·哈萨比斯。2018. 掌握国际象棋、将棋和自学的通用强化学习算法.科学362（6419）：1140-1144。doi：10.1126/science.aar6404."
        }
    },
    {
        "translation": {
            "en": "It is possible, however, to successfully use measures of similarity in similarity-based models that do not satisfy all four of these criteria.",
            "zh": "然而，在基于相似性的模型中，有可能成功地使用相似性度量，而这些模型并不满足所有这四个标准。"
        }
    },
    {
        "translation": {
            "en": "Consequently, if there is an interaction effect between two or more descriptive features, a decision tree can model this.",
            "zh": "因此，如果两个或多个描述性特征之间存在交互效应，则决策树可以对此进行建模。"
        }
    },
    {
        "translation": {
            "en": "This insight into the likely future behavior of a customer can help a marketing department decide which customers coming close to the end of their trial period the department should contact to promote the benefits of signup to the paid service.",
            "zh": "这种对客户未来可能行为的洞察可以帮助营销部门决定哪些客户即将结束试用期，该部门应该联系哪些客户，以促进注册付费服务的好处。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.6[608] illustrates these two types of distances along with examples of a good and a bad clustering—according to this definition.",
            "zh": "图 10.6[608] 根据此定义，说明了这两种类型的距离以及良好和不良聚类的示例。"
        }
    },
    {
        "translation": {
            "en": "Trask, Andrew. 2019. Grokking deep learning. Manning.",
            "zh": "特拉斯克，安德鲁。2019. Grokking 深度学习.曼宁。"
        }
    },
    {
        "translation": {
            "en": "Consequently, there is rapid progress within the field, with new techniques and network architectures being published every month.",
            "zh": "因此，该领域取得了快速进展，每个月都会发布新技术和网络架构。"
        }
    },
    {
        "translation": {
            "en": "Table 9.21[581] shows an example of how the stability index could be calculated for two different sets of query instances collected at two different times after model deployment based on the bacterial species identification problem given in Table 9.18[573].",
            "zh": "表9.21[581]显示了如何根据表9.18[573]中给出的细菌物种识别问题，计算模型部署后在两个不同时间收集的两组不同查询实例的稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "The transition matrix is also shown.",
            "zh": "还显示了过渡矩阵。"
        }
    },
    {
        "translation": {
            "en": "Using the training set to train a model and the test set to evaluate it, a performance measure (or measures) is calculated for this iteration.",
            "zh": "使用训练集来训练模型，使用测试集来评估模型，为此迭代计算一个或多个性能度量。"
        }
    },
    {
        "translation": {
            "en": "PETROMAGERR_U/G/R/I/Z",
            "zh": "PETROMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "state, 640, 643, 676",
            "zh": "州， 640， 643， 676"
        }
    },
    {
        "translation": {
            "en": "A joint probability distribution is a multidimensional matrix where each cell in the matrix lists the probability for one of the events in the sample space defined by the combination of feature values.",
            "zh": "联合概率分布是一个多维矩阵，其中矩阵中的每个单元格都列出了由特征值组合定义的样本空间中某个事件的概率。"
        }
    },
    {
        "translation": {
            "en": "11.2.3   Markov Decision Processes",
            "zh": "11.2.3 马尔可夫决策过程"
        }
    },
    {
        "translation": {
            "en": "The final one-versus-all decision boundaries shown in the bottom-middle panel of Figure 7.21[360] do not look like the individual one-versus-all decision boundaries shown in Figure 7.20[358].",
            "zh": "图7.21[360]底部面板中显示的最终一对全决策边界看起来与图7.20[358]中显示的单个一对全决策边界不同。"
        }
    },
    {
        "translation": {
            "en": "With the exception of the definition of the target feature, data that will be used to define a feature must be available before the event around which we are trying to make predictions occurs.",
            "zh": "除了目标特征的定义之外，将用于定义特征的数据必须在我们试图进行预测的事件发生之前可用。"
        }
    },
    {
        "translation": {
            "en": "In many instances the SDSS dataset contained the same measurement for a night sky object measured separately for each of the five photometric bands covered by the SDSS telescope.",
            "zh": "在许多情况下，SDSS数据集包含对夜空天体的相同测量值，分别测量SDSS望远镜覆盖的五个光度波段中的每一个。"
        }
    },
    {
        "translation": {
            "en": "Factorizing the domain representation reduces the number of interactions between the features and reduces the number of model parameters.",
            "zh": "分解域表示可减少特征之间的交互次数并减少模型参数的数量。"
        }
    },
    {
        "translation": {
            "en": "Recall that a dataset in which the majority of descriptive features have zero as the value is known as sparse data.",
            "zh": "回想一下，大多数描述性特征的值为零的数据集称为稀疏数据。"
        }
    },
    {
        "translation": {
            "en": "RISK",
            "zh": "风险"
        }
    },
    {
        "translation": {
            "en": "Lines 1–6 of Algorithm 1[134] control when a new leaf node is created in the tree.",
            "zh": "算法 1[134] 的第 1-6 行控制何时在树中创建新的叶节点。"
        }
    },
    {
        "translation": {
            "en": "6.4.2 Continuous Features: Probability Density Functions",
            "zh": "6.4.2 连续特征：概率密度函数"
        }
    },
    {
        "translation": {
            "en": "GALAXY_CLASS_3",
            "zh": "GALAXY_CLASS_3"
        }
    },
    {
        "translation": {
            "en": "outcome, 757, 758",
            "zh": "成果， 757， 758"
        }
    },
    {
        "translation": {
            "en": "8.2   Plots for activation functions that have been popular in the history of neural networks.",
            "zh": "8.2 神经网络历史上流行的激活函数图。"
        }
    },
    {
        "translation": {
            "en": "With this model selected as the best performing approach, Jocelyn was ready to perform the final evaluation experiment.",
            "zh": "将该模型选为最佳性能方法后，Jocelyn 已准备好进行最终评估实验。"
        }
    },
    {
        "translation": {
            "en": "7.4.5   Modeling Non-Linear Relationships",
            "zh": "7.4.5 非线性关系建模"
        }
    },
    {
        "translation": {
            "en": "restriction bias, 11, 357",
            "zh": "限制偏差， 11， 357"
        }
    },
    {
        "translation": {
            "en": "5.2.1 Feature Space",
            "zh": "5.2.1 功能空间"
        }
    },
    {
        "translation": {
            "en": "Histograms show more detail than box plots, so small multiple histograms offer a more detailed view of the relationship between two features.",
            "zh": "直方图比箱形图显示更多细节，因此较小的多个直方图可以更详细地查看两个要素之间的关系。"
        }
    },
    {
        "translation": {
            "en": "In this chapter1 we introduce deep learning, an approach to machine learning that is inspired by how the brain is structured and operates.",
            "zh": "在本章1中，我们将介绍深度学习，这是一种机器学习方法，其灵感来自大脑的结构和运作方式。"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "表8.3[423]中列出的示例通过图8.4[390]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "Therefore, although this feature doesn’t perfectly discriminate between spam and ham, it does give us some information that we might be able to use in conjunction with other features to help decide whether a new email is spam or ham.",
            "zh": "因此，尽管此功能不能完全区分垃圾邮件和火腿，但它确实为我们提供了一些信息，我们可以将这些信息与其他功能结合使用，以帮助确定新电子邮件是垃圾邮件还是火腿。"
        }
    },
    {
        "translation": {
            "en": "For categorical prediction problems, use average class accuracy based on a harmonic mean.",
            "zh": "对于分类预测问题，请使用基于谐波均值的平均类准确率。"
        }
    },
    {
        "translation": {
            "en": "3.2 Getting to Know the Data",
            "zh": "3.2 了解数据"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(b)[329] shows that a well-chosen learning rate strikes a good balance, converging quickly but also ensuring that the global minimum is reached.",
            "zh": "图7.7（b）[329]显示，精心选择的学习率可以达到良好的平衡，快速收敛，但也能确保达到全球最低限度。"
        }
    },
    {
        "translation": {
            "en": "Once this tipping point in dataset size has been surpassed, a discriminative model will outperform a generative model.",
            "zh": "一旦超过数据集大小的这个临界点，判别模型的性能将优于生成模型。"
        }
    },
    {
        "translation": {
            "en": "Precision tells us how confident we can be that an instance predicted to have the positive target level actually has the positive target level.",
            "zh": "精度告诉我们，预测具有正目标水平的实例实际上具有正目标水平，我们可以有多大的信心。"
        }
    },
    {
        "translation": {
            "en": "3. In the extreme case with p = ∞, the Minkowski metric simply returns the maximum difference between any of the features. This is known as the Chebyshev distance but is also sometimes called the chessboard distance because it is the number of moves a king must make in chess to go from one square on the board to any other.",
            "zh": "3. 在 p = ∞ 的极端情况下，Minkowski 度量仅返回任何特征之间的最大差值。这被称为切比雪夫距离，但有时也被称为棋盘距离，因为它是国王在国际象棋中从棋盘上的一个方格到另一个方格必须走的步数。"
        }
    },
    {
        "translation": {
            "en": "It also, however, illustrates an issue with using variance.",
            "zh": "但是，它也说明了使用方差的问题。"
        }
    },
    {
        "translation": {
            "en": "In this chapter, affine and linear functions are so closely associated that we often use the term linear to refer to affine operations.",
            "zh": "在本章中，仿射函数和线性函数密切相关，以至于我们经常使用术语线性来指代仿射操作。"
        }
    },
    {
        "translation": {
            "en": "where d is a set of m descriptive features, w is a set of b weights, and ϕ0 to ϕb are a series of b basis functions that each transform the input vector d in a different way. It is worth noting that there is no reason that b must equal m, and usually b is quite a bit larger than m—that is, there are usually more basis functions than there are descriptive features.",
            "zh": "其中 d 是一组 m 描述性特征，w 是一组 b 权重，φ0 到 φb 是一系列 b 基函数，每个函数以不同的方式转换输入向量 d。值得注意的是，没有理由 b 必须等于 m，而且通常 b 比 m 大得多——也就是说，基函数通常多于描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The deep Q network algorithm can be used with any state representation that can be input into a neural network, and can use different neural network architectures.",
            "zh": "深度 Q 网络算法可以与任何可以输入到神经网络中的状态表示一起使用，并且可以使用不同的神经网络架构。"
        }
    },
    {
        "translation": {
            "en": "6. These charts are often referred to as Pareto charts, especially when they also include a line indicating the cumulative total frequency or density.",
            "zh": "6. 这些图表通常被称为帕累托图，特别是当它们还包括一条表示累积总频率或密度的线时。"
        }
    },
    {
        "translation": {
            "en": "7.4.6   Multinomial Logistic Regression",
            "zh": "7.4.6 多项式逻辑回归"
        }
    },
    {
        "translation": {
            "en": "So, even when we take the evidence into account, the posterior probability of having meningitis remains low.",
            "zh": "因此，即使我们考虑到证据，患脑膜炎的后验概率仍然很低。"
        }
    },
    {
        "translation": {
            "en": "Although the history of artificial neural networks can be traced back to the 1940s, the term deep learning came to prominence only in the mid-2000s.2 The term deep learning emphasizes that modern networks are deeper (in terms of number of layers) than previous networks.",
            "zh": "尽管人工神经网络的历史可以追溯到 1940 年代，但深度学习一词直到 2000 年代中期才开始崭露头角.2 深度学习一词强调现代网络（就层数而言）比以前的网络更深。"
        }
    },
    {
        "translation": {
            "en": "8.4.2 Weight Initialization and Unstable Gradients",
            "zh": "8.4.2 权重初始化和不稳定梯度"
        }
    },
    {
        "translation": {
            "en": "The book is detailed, rigorous, and easy to read.",
            "zh": "这本书详细、严谨、易于阅读。"
        }
    },
    {
        "translation": {
            "en": "separating hyperplane, 362",
            "zh": "分离超平面，362"
        }
    },
    {
        "translation": {
            "en": "Table 7.2",
            "zh": "表 7.2"
        }
    },
    {
        "translation": {
            "en": "Indexes",
            "zh": "指标"
        }
    },
    {
        "translation": {
            "en": "subset generation, 228",
            "zh": "子集生成，228"
        }
    },
    {
        "translation": {
            "en": "The value of w0 is − 0.1838, and the values of the α parameters are 23.056, 6.998, 16.058).",
            "zh": "w0 的值为 − 0.1838，α参数的值为 23.056、6.998、16.058）。"
        }
    },
    {
        "translation": {
            "en": "In order to evaluate the effect this model was having on the company’s churn problem, they performed a comparative experiment.",
            "zh": "为了评估该模型对公司流失问题的影响，他们进行了一项比较实验。"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network can have any structure, but a layer-based organization of neurons is common.",
            "zh": "人工神经网络可以具有任何结构，但基于层的神经元组织很常见。"
        }
    },
    {
        "translation": {
            "en": "The covariance matrix, usually denoted as ∑, between a set of continuous features, {a,b,…,z}, is given as",
            "zh": "一组连续特征 {a，b,...,z} 之间的协方差矩阵（通常表示为 ∑）表示为"
        }
    },
    {
        "translation": {
            "en": "Equation (8.27)[414] defined how the rate of change of the error of a network with respect to a weight in the network ∂ℰ/∂wi,k can be calculated using the chain rule.",
            "zh": "方程（8.27）[414]定义了如何使用链式法则计算网络误差相对于网络权重的变化率∂E/∂wi，k。"
        }
    },
    {
        "translation": {
            "en": "This means that we must backpropagate the error at time t to all the parameters that contributed to the error.",
            "zh": "这意味着我们必须将时间 t 的误差反向传播到导致误差的所有参数。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19(f)[356] shows a 3D plot of the final decision surface.",
            "zh": "图7.19（f）[356]显示了最终决策面的3D图。"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of prediction models built for continuous targets, there are fewer options to choose from.",
            "zh": "在评估为连续目标构建的预测模型的性能时，可供选择的选项较少。"
        }
    },
    {
        "translation": {
            "en": "What is the organizational problem being addressed? In what ways could a prediction model address the organizational problem? Do we have situational fluency? What is the capacity of the organization to utilize the output of a prediction model? What data is available?",
            "zh": "正在解决的组织问题是什么？预测模型可以通过哪些方式解决组织问题？我们有情境流畅性吗？组织利用预测模型输出的能力如何？有哪些数据可用？"
        }
    },
    {
        "translation": {
            "en": "k Nearest Neighbor",
            "zh": "k 最近邻"
        }
    },
    {
        "translation": {
            "en": "𝕄w refers to a model 𝕄 parameterized by a parameter vector w.",
            "zh": "Mw 是指由参数向量 w 参数化的模型 M。"
        }
    },
    {
        "translation": {
            "en": "A frequency table for the POSITION feature from the school basketball team dataset in Table A.1[750].",
            "zh": "表A.1[750]中学校篮球队数据集中POSITION特征的频率表。"
        }
    },
    {
        "translation": {
            "en": "For example, the developers of a smartphone app might decide that by turning on location tracking, they could gather data that would be extremely useful in predicting future usage of the app.",
            "zh": "例如，智能手机应用程序的开发人员可能会决定，通过打开位置跟踪，他们可以收集数据，这些数据对于预测应用程序的未来使用情况非常有用。"
        }
    },
    {
        "translation": {
            "en": "This means that the partial derivative of a weighted sum function with respect to a weight simplifies to the derivative of the product of the weight by its input that is equal to the input the weight is applied to",
            "zh": "这意味着加权和函数相对于权重的偏导数简化为权重乘积的导数，其输入等于施加权重的输入"
        }
    },
    {
        "translation": {
            "en": "If the LSTM used only sigmoid units, then the activations in the cell would monotonically increase across time and this would have the unwanted consequence of the cell state tending to saturate with maximum activations as the sequence of time-steps increases, irrespective of the inputs.",
            "zh": "如果LSTM仅使用乙状结肠单位，则细胞中的激活将随时间单调增加，这将产生不良后果，即随着时间步长序列的增加，细胞状态趋于饱和，具有最大的激活，而与输入无关。"
        }
    },
    {
        "translation": {
            "en": "Demographics: Demographic features of users or customers such as age, gender, occupation, and address.",
            "zh": "人口统计：用户或客户的人口统计特征，例如年龄、性别、职业和地址。"
        }
    },
    {
        "translation": {
            "en": "Kaufman, Leonard, and Peter J. Rousseeuw. 1990. Finding groups in data: An introduction to cluster analysis. Wiley.",
            "zh": "考夫曼、伦纳德和彼得 J. Rousseeuw。1990. 在数据中查找组：聚类分析简介。威利。"
        }
    },
    {
        "translation": {
            "en": "The probability mass is simply the probability of an event.",
            "zh": "概率质量只是事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Each δ expresses the rate of change (or sensitivity) of the error of the network with respect to changes in the weighted sum calculation of a specific neuron.",
            "zh": "每个δ表示网络误差的变化率（或灵敏度）与特定神经元的加权和计算的变化。"
        }
    },
    {
        "translation": {
            "en": "11. This artificially generated example dataset is inspired by the research reported in Franklin et al. (2000).",
            "zh": "11. 这个人工生成的示例数据集的灵感来自Franklin等人（2000年）报告的研究。"
        }
    },
    {
        "translation": {
            "en": "10.5   (a)–(d) Initial centroids chosen using the k-means++ approach (all with k = 3) for the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "10.5 （a）–（d） 使用表 10.1[604] 中给出的移动电话客户数据集的 k-means++ 方法选择的初始质心（均为 k = 3）。"
        }
    },
    {
        "translation": {
            "en": "Section 7.6[370] recommends further reading on this topic.",
            "zh": "第7.6节[370]建议进一步阅读此主题。"
        }
    },
    {
        "translation": {
            "en": "In spite of the model’s difficulty distinguishing between the clockwise and anti-clockwise spiral galaxies, Jocelyn did perform an evaluation of the two-stage model.",
            "zh": "尽管该模型难以区分顺时针和逆时针螺旋星系，但Jocelyn确实对两阶段模型进行了评估。"
        }
    },
    {
        "translation": {
            "en": "Range normalization has the drawback that it is quite sensitive to the presence of outliers in a dataset. Another way to normalize data is to standardize it into standard scores.10 A standard score measures how many standard deviations a feature value is from the mean for that feature. To calculate a standard score, we compute the mean and standard deviation for the feature and normalize the feature values using the following equation:",
            "zh": "范围归一化的缺点是它对数据集中异常值的存在非常敏感。规范化数据的另一种方法是将其标准化为标准分数。10 标准分数衡量特征值与该特征的平均值有多少个标准差。为了计算标准分数，我们计算特征的平均值和标准差，并使用以下公式对特征值进行归一化："
        }
    },
    {
        "translation": {
            "en": "11.10   (a) Frames from an episode early in the training process in which the agent performs poorly. (b) Frames from an episode near the end of the learning process where the agent is starting to be very effective. (c) Changing episode returns during DQN training. The gray line shows a 50-episode moving average to better highlight the trend.",
            "zh": "11.10 （a） 在训练过程早期，智能体表现不佳的情节。（b） 在学习过程接近尾声时，智能体开始变得非常有效的一集的帧。（c） 在 DQN 训练期间更改剧集返回。灰线显示 50 集的移动平均线，以更好地突出趋势。"
        }
    },
    {
        "translation": {
            "en": "Things become a little more complex when a recurrent network is applied to a sequence of inputs.",
            "zh": "当将循环网络应用于一系列输入时，事情会变得更加复杂。"
        }
    },
    {
        "translation": {
            "en": "Tempel, E., E. Saar, L. J. Liivamägi, A. Tamm, J. Einasto, M. Einasto, and V. Müller. 2011. Galaxy morphology, luminosity, and environment in the SDSS DR7. A&A 529: 53. doi:10.1051/0004-6361/201016196.",
            "zh": "Tempel， E.， E. Saar， L. J. Liivamägi， A. Tamm， J. Einasto， M. Einasto， 和 V. Müller.2011. SDSS DR7 中的星系形态、光度和环境.A&A 529：53。doi：10.1051/0004-6361/201016196."
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the tachycardia prediction dataset from Question 9 (after the instances with missing TACHYCARDIA values have been removed and all outliers have been handled).",
            "zh": "以下数据可视化基于问题 9 中的心动过速预测数据集（在删除缺少心动过速值的实例并处理所有异常值之后）。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.8[198] illustrates the creation of the first two nodes of a k-d tree for the college athlete dataset in Table 5.4[191].",
            "zh": "图5.8[198]说明了表5.4[191]中大学运动员数据集的k-d树的前两个节点的创建。"
        }
    },
    {
        "translation": {
            "en": "The set of nodes in a graph that make a node independent of the rest of the graph are known as the Markov blanket of a node.",
            "zh": "图中使节点独立于图的其余部分的节点集称为节点的马尔可夫毯。"
        }
    },
    {
        "translation": {
            "en": "The last point worth mentioning is that this chapter relates to deployment.",
            "zh": "最后一点值得一提的是，本章与部署有关。"
        }
    },
    {
        "translation": {
            "en": "This calculation reduces to multiplying the δ for the neuron that uses the weight in its weighted sum by the activation that the weight was applied to in the weighted sum.",
            "zh": "此计算简化为将使用加权和中的权重的神经元的δ乘以加权和中应用权重的激活。"
        }
    },
    {
        "translation": {
            "en": "Named Features",
            "zh": "命名功能"
        }
    },
    {
        "translation": {
            "en": "The next section discusses this interaction in more detail and introduces some popular weight initialization schemes for deep networks.",
            "zh": "下一节将更详细地讨论这种交互，并介绍一些流行的深度网络权重初始化方案。"
        }
    },
    {
        "translation": {
            "en": "The price of the customer’s current handset",
            "zh": "客户当前手机的价格"
        }
    },
    {
        "translation": {
            "en": "Using variance as our measure of impurity, the impurity at a node can be calculated",
            "zh": "使用方差作为杂质的度量，可以计算节点处的杂质"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the ABT developed for the Acme Telephonica churn prediction task.",
            "zh": "ABT 中的描述性功能是为 Acme Telephonica 流失预测任务开发的。"
        }
    },
    {
        "translation": {
            "en": "They also need to reflect on the processes they use to preprocess and manage the data, and whether any of these processes introduce bias into the sample.9 So, in summary, although inductive bias is necessary for machine learning, and in a sense, a key goal of a data analyst is to find the correct inductive bias, sample bias is something that a data analyst should proactively work hard to remove from the data used in any data analytics project.",
            "zh": "他们还需要反思他们用于预处理和管理数据的过程，以及这些过程中的任何一个是否会在样本中引入偏差.9 因此，总而言之，尽管归纳偏差对于机器学习是必要的，从某种意义上说，数据分析师的一个关键目标是找到正确的归纳偏差， 样本偏差是数据分析师应该主动努力从任何数据分析项目中使用的数据中去除的东西。"
        }
    },
    {
        "translation": {
            "en": "This would allow him to sample every item and update his knowledge about what he likes and what he doesn’t like.",
            "zh": "这将使他能够对每件物品进行采样，并更新他对喜欢什么和不喜欢什么的知识。"
        }
    },
    {
        "translation": {
            "en": "2.1.1   Case Study: Motor Insurance Fraud",
            "zh": "2.1.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "A similar rule is used for instances with the ENERGY RATING feature levels of B and C.",
            "zh": "类似的规则用于 ENERGY RATING 特征级别为 B 和 C 的实例。"
        }
    },
    {
        "translation": {
            "en": "As before, for a naive Bayes model, we calculate the prior probability distribution for the target feature and the posterior distribution for each descriptive feature conditioned on the target feature.",
            "zh": "如前所述，对于朴素贝叶斯模型，我们计算目标特征的先验概率分布和以目标特征为条件的每个描述性特征的后验分布。"
        }
    },
    {
        "translation": {
            "en": "Our new network is designed to work with our scenario of predicting the electrical output of a combined cycle power plant: the network has two neurons in the input layer for the inputs AMBIENT TEMPERATURE and the RELATIVE HUMIDITY, and one neuron in the output layer for the target ELECTRICAL OUTPUT.",
            "zh": "我们的新网络旨在与预测联合循环发电厂的电力输出的场景配合使用：该网络在输入层中有两个神经元用于输入环境温度和相对湿度，在输出层中有一个神经元用于目标电输出。"
        }
    },
    {
        "translation": {
            "en": "Although this simple model goes some way toward capturing the general trend of the relationship between AGE and INCOME, it does not manage to capture any of the subtlety of the relationship.",
            "zh": "尽管这个简单的模型在某种程度上可以捕捉到年龄和收入之间关系的总体趋势，但它并没有设法捕捉到这种关系的任何微妙之处。"
        }
    },
    {
        "translation": {
            "en": "The earlier in the network a weight occurs, the more terms there are in the product.",
            "zh": "权重在网络中出现得越早，乘积中的项就越多。"
        }
    },
    {
        "translation": {
            "en": "where G(st,at) is the actual return received from the point of taking action at to the end of the episode. By repeatedly applying this update rule, the values in the action-value table slowly converge to good estimates of their true values.15",
            "zh": "其中 G（st，at） 是从在剧集结束时采取行动到结束时收到的实际回报。通过反复应用此更新规则，操作值表中的值会慢慢收敛到对其真实值的良好估计值15。"
        }
    },
    {
        "translation": {
            "en": "The black circles show the training dataset, the gray squares show the predictions made for the instances in the training dataset by the ensemble model, and the dotted line shows the predictions that would be made by the ensemble model for the full range of input temperatures.",
            "zh": "黑色圆圈表示训练数据集，灰色方块表示集成模型对训练数据集中的实例所做的预测，虚线表示集成模型将对整个输入温度范围做出的预测。"
        }
    },
    {
        "translation": {
            "en": "This might seem a little surprising given that the patient is suffering from a headache and is vomiting, two key symptoms of meningitis.",
            "zh": "这似乎有点令人惊讶，因为患者患有头痛和呕吐，这是脑膜炎的两个主要症状。"
        }
    },
    {
        "translation": {
            "en": "This ensures that the output of all models sums to 1.",
            "zh": "这确保了所有模型的输出总和为 1。"
        }
    },
    {
        "translation": {
            "en": "The main observation that Jocelyn made from these is that galaxies in the dataset were not evenly distributed across the different morphology types.",
            "zh": "Jocelyn从中得出的主要观察结果是，数据集中的星系在不同的形态类型中分布不均匀。"
        }
    },
    {
        "translation": {
            "en": "“Essentially, all models are wrong, but some are useful.”",
            "zh": "“从本质上讲，所有模型都是错误的，但有些模型是有用的。"
        }
    },
    {
        "translation": {
            "en": "9.4   Extensions and Variations",
            "zh": "9.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "12.6   (a) Cumulative gain, (b) lift, and (c) cumulative lift charts for the predictions made on the large test data sample.",
            "zh": "12.6 （a） 对大型测试数据样本进行预测的累积增益、（b） 提升和 （c） 累积提升图。"
        }
    },
    {
        "translation": {
            "en": "In Section 6.2.3[256], however, we showed how conditional independence between features allows us to factorize the joint distribution, and this helps with the curse of dimensionality problem by reducing the number of probabilities we are required to calculate from the data as well as the number of conditioning constraints on these probabilities.",
            "zh": "然而，在第 6.2.3 节[256]中，我们展示了特征之间的条件独立性如何允许我们对联合分布进行因式分解，这有助于解决维数问题的诅咒，减少我们需要从数据中计算的概率数量以及这些概率的条件约束的数量。"
        }
    },
    {
        "translation": {
            "en": "Conor does, however, recognize the Irish word for chicken, sicín, on the hotel restaurant menu, and he does like chicken.",
            "zh": "然而，康纳确实在酒店餐厅的菜单上认出了爱尔兰语中的鸡肉单词sicín，而且他确实喜欢鸡肉。"
        }
    },
    {
        "translation": {
            "en": "positive",
            "zh": "阳性"
        }
    },
    {
        "translation": {
            "en": "FRAUD FLAG was changed to be a categorical feature.",
            "zh": "FRAUD FLAG 已更改为分类功能。"
        }
    },
    {
        "translation": {
            "en": "11.3   A Markov decision process representation for TwentyTwos, a simplified version of the card game Blackjack.",
            "zh": "11.3 TwentyTwos的马尔可夫决策过程表示，TwentyTwos是纸牌游戏Blackjack的简化版本。"
        }
    },
    {
        "translation": {
            "en": "outcome period, 37, 689",
            "zh": "成果期， 37， 689"
        }
    },
    {
        "translation": {
            "en": "To illustrate how information gain is calculated and to check how well it models our intuitions described at the beginning of this section, we compute the information gain for each descriptive feature in the spam dataset. The first step is to compute the entropy for the whole dataset using Equation (4.2)[129]",
            "zh": "为了说明如何计算信息增益，并检查它如何模拟本节开头描述的直觉，我们计算垃圾邮件数据集中每个描述性特征的信息增益。第一步是使用公式（4.2）计算整个数据集的熵[129]"
        }
    },
    {
        "translation": {
            "en": "Agents need to make sequences of good decisions in order to get the opportunity to explore deeper into action sequences and so need to exploit before exploring in some episodes.",
            "zh": "特工需要做出一系列正确的决定，以便有机会更深入地探索动作序列，因此在某些情节中需要在探索之前进行利用。"
        }
    },
    {
        "translation": {
            "en": "Admittedly, this drop in error is tiny, but it is a reduction in error, and this reduction was achieved by updating randomly initialized weights once.",
            "zh": "诚然，这种误差下降很小，但它是误差的减少，而这种减少是通过更新一次随机初始化的权重来实现的。"
        }
    },
    {
        "translation": {
            "en": "This system will examine new claims as they arise and flag for further investigation those that look like they might be fraud risks.",
            "zh": "该系统将在出现新索赔时对其进行检查，并标记那些看起来可能存在欺诈风险的索赔以供进一步调查。"
        }
    },
    {
        "translation": {
            "en": "second",
            "zh": "第二"
        }
    },
    {
        "translation": {
            "en": "The standard technique for applying dropout to a recurrent neural network during training is known as variational RNN (Goldberg, 2017).",
            "zh": "在训练期间将辍学应用于递归神经网络的标准技术称为变分RNN（Goldberg，2017）。"
        }
    },
    {
        "translation": {
            "en": "factors, 258",
            "zh": "因子， 258"
        }
    },
    {
        "translation": {
            "en": "The activations in the cell can take values in the range [−1,+1].",
            "zh": "细胞中的激活可以取 [−1，+1] 范围内的值。"
        }
    },
    {
        "translation": {
            "en": "9.4.2.2 Precision, recall, and F1 measure Precision, recall, and the F1 measure are another frequently used set of performance measures that can be calculated directly from the confusion matrix. Precision and recall are defined as follows:",
            "zh": "9.4.2.2 精确率、召回率和 F1 度量 精确率、召回率和 F1 度量是另一组常用的性能度量，可以直接从混淆矩阵中计算出来。精确度和召回率定义如下："
        }
    },
    {
        "translation": {
            "en": "The reason is that the network uses the same weights to process Input 1 as it does to process Input 3.",
            "zh": "原因是网络使用相同的权重来处理输入 1 和处理输入 3。"
        }
    },
    {
        "translation": {
            "en": "There are two cases that we need to handle with this derivative (1) when lk is the logit for the neuron whose activation is the probability of the correct category (i.e., k = ⋆), and (2) when lk is the logit for a neuron whose activation is the probability for one of the incorrect categories (i.e., k ≠ ⋆).",
            "zh": "我们需要用这个导数处理两种情况：（1）当 lk 是神经元的 logit 时，其激活是正确类别的概率（即 k = ⋆），以及 （2） 当 lk 是神经元的 logit 时，其激活是其中一个错误类别的概率（即 k ≠ ⋆）。"
        }
    },
    {
        "translation": {
            "en": "agglomerative hierarchical clustering, 618, 618, 629, 635",
            "zh": "集聚分层聚类， 618， 618， 629， 635"
        }
    },
    {
        "translation": {
            "en": "9.11   A sample test set with model predictions and scores.",
            "zh": "9.11 具有模型预测和分数的样本测试集。"
        }
    },
    {
        "translation": {
            "en": "In calculus, when we take the partial derivative of a function with respect to a particular input, all the terms in the function that are not involved in the input disappear, because they are constants when the input changes.",
            "zh": "在微积分中，当我们对特定输入取函数的偏导数时，函数中所有不涉及输入的项都消失了，因为它们在输入发生变化时是常数。"
        }
    },
    {
        "translation": {
            "en": "The benefit of this is that the z values for the neurons in the next layer will be of a similar magnitude during training, when we are using dropout, as they will be during testing/inference (when we do not use dropout).",
            "zh": "这样做的好处是，当我们使用dropout时，下一层中神经元的z值在训练期间将具有相似的量级，就像在测试/推理期间（当我们不使用dropout时）一样。"
        }
    },
    {
        "translation": {
            "en": "However, if we are trying to build a predictive model that automatically assigns a target level to a query instance, then we need to decide how the model will make a prediction based on the computed probabilities.",
            "zh": "但是，如果我们尝试构建一个自动将目标级别分配给查询实例的预测模型，那么我们需要决定模型将如何根据计算的概率进行预测。"
        }
    },
    {
        "translation": {
            "en": "11.1   Big Idea",
            "zh": "11.1 大创意"
        }
    },
    {
        "translation": {
            "en": "It is clear that the different outcomes have different profit and loss associated with them.",
            "zh": "很明显，不同的结果具有不同的损益。"
        }
    },
    {
        "translation": {
            "en": "A quick comment on our notation.",
            "zh": "对我们的符号进行快速评论。"
        }
    },
    {
        "translation": {
            "en": "Charniak, Eugene. 2019. Introduction to deep learning. MIT Press.",
            "zh": "查尼亚克，尤金。2019. 深度学习简介.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "This results in a query with AGE = 0.0667 and RATING = 1.00.",
            "zh": "这将导致 AGE = 0.0667 和 RATING = 1.00 的查询。"
        }
    },
    {
        "translation": {
            "en": "post-pruning, 155, 698",
            "zh": "修剪后， 155， 698"
        }
    },
    {
        "translation": {
            "en": "LIFEEXPECTANCY: The average life expectancy (in years)",
            "zh": "预期寿命：平均预期寿命（以年为单位）"
        }
    },
    {
        "translation": {
            "en": "4.4.5.2 Boosting When we use boosting,28 each new model added to an ensemble is biased to pay more attention to instances that previous models misclassified.",
            "zh": "4.4.5.2 提升 当我们使用提升时，28 添加到集成中的每个新模型都会偏向于更多地关注先前模型错误分类的实例。"
        }
    },
    {
        "translation": {
            "en": "This means that when an instance is randomly selected from the original dataset, it is replaced into the dataset so that it might be selected again.",
            "zh": "这意味着，当从原始数据集中随机选择实例时，该实例将被替换到数据集中，以便可以再次选择该实例。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix calculates the frequencies of each possible outcome of the predictions made by a model for a test dataset in order to show, in detail, how the model is performing.",
            "zh": "混淆矩阵计算模型对测试数据集所做的预测的每个可能结果的频率，以便详细显示模型的执行情况。"
        }
    },
    {
        "translation": {
            "en": "This type of histogram is often referred to as a frequency histogram.",
            "zh": "这种类型的直方图通常称为频率直方图。"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov chart, 563",
            "zh": "Kolmogorov-Smirnov 图表，563"
        }
    },
    {
        "translation": {
            "en": "If she takes a small step in the direction in which the ground slopes most steeply downward (the direction of the gradient of the mountain), she will be headed toward the bottom of the mountain.",
            "zh": "如果她向地面最陡峭的方向（山坡的方向）迈出一小步，她就会朝着山底前进。"
        }
    },
    {
        "translation": {
            "en": "taxi-cab distance, 185",
            "zh": "出租车距离，185"
        }
    },
    {
        "translation": {
            "en": "We can, in fact, use the gradient descent algorithm to train a single-layer network (or perceptron), such as the one shown in Figure 8.7[397].",
            "zh": "事实上，我们可以使用梯度下降算法来训练单层网络（或感知器），如图8.7[397]所示。"
        }
    },
    {
        "translation": {
            "en": "This is simply 1 divided by the model’s predicted probability for the correct category.",
            "zh": "这只是 1 除以模型对正确类别的预测概率。"
        }
    },
    {
        "translation": {
            "en": "8.14   The calculation of the softmax activation function ϕsm over a vector of three logits l.",
            "zh": "8.14 softmax激活函数φsm在3logits l的向量上的计算。"
        }
    },
    {
        "translation": {
            "en": "The extent of the rectangular box in the middle of the plot is determined by the 3rd quartile at the top and the 1st quartile at the bottom.",
            "zh": "图中间矩形框的范围由顶部的第 3 个四分位数和底部的第 1 个四分位数确定。"
        }
    },
    {
        "translation": {
            "en": "Biases are introduced when, due to the sampling process, the distributions of features in the sampled dataset are very different from the distributions of features in the original dataset.",
            "zh": "当由于采样过程的原因，采样数据集中的特征分布与原始数据集中的特征分布有很大不同时，就会引入偏差。"
        }
    },
    {
        "translation": {
            "en": "(d) At the fourth iteration of AHC, the first hierarchical cluster combination is created when a single instance, d11 is combined with the cluster 10 to create a new cluster, 13.",
            "zh": "（d） 在AHC的第四次迭代中，当单个实例d11与簇10合并以创建新簇13时，将创建第一个分层簇组合。"
        }
    },
    {
        "translation": {
            "en": "AHC begins by considering each instance in the dataset as a simple cluster containing just one instance.",
            "zh": "AHC 首先将数据集中的每个实例视为仅包含一个实例的简单集群。"
        }
    },
    {
        "translation": {
            "en": "As a result, we can calculate the rate of change of the error of the network ℰ with respect to the changes in the activation ak by taking the product: wi,k × δi.",
            "zh": "因此，我们可以通过取乘积 wi，k × δi 来计算网络 E 的误差相对于激活 ak 变化的变化率。"
        }
    },
    {
        "translation": {
            "en": "Similarity-based prediction models attempt to mimic a very human way of reasoning by basing predictions for a target feature value on the most similar instances in memory.",
            "zh": "基于相似性的预测模型试图通过基于内存中最相似的实例来模拟对目标特征值的预测，从而模仿一种非常人性的推理方式。"
        }
    },
    {
        "translation": {
            "en": "Indeed, any instances with a missing value for the target feature should always be removed from an ABT.",
            "zh": "事实上，应始终从 ABT 中删除任何缺少目标特征值的实例。"
        }
    },
    {
        "translation": {
            "en": "That means that three out of every four times you ask Question 2, the answer will be no, and you will still have to distinguish between the three remaining characters.",
            "zh": "这意味着你每问四次问题 2 中就有三次，答案是否定的，你仍然需要区分剩下的三个字符。"
        }
    },
    {
        "translation": {
            "en": "For this reason, we present machine learning within the context of predictive data analytics, an important industry application of machine learning.",
            "zh": "出于这个原因，我们在预测数据分析的背景下介绍了机器学习，这是机器学习的重要行业应用。"
        }
    },
    {
        "translation": {
            "en": "If the values of a descriptive feature are normally distributed, then standardizing the feature is appropriate; however, this is relatively rare, and the default is to use range normalization into either [−1,+1] or [0,1] for preprocessing.",
            "zh": "如果描述性特征的值呈正态分布，则标准化特征是合适的;但是，这种情况相对罕见，默认情况下使用范围归一化为 [−1，+1] 或 [0,1] 进行预处理。"
        }
    },
    {
        "translation": {
            "en": "The shaded cells in Image (a) below show the region that these sensors cover.",
            "zh": "下图（a）中的阴影单元格显示了这些传感器覆盖的区域。"
        }
    },
    {
        "translation": {
            "en": "Data Exploration",
            "zh": "数据探索"
        }
    },
    {
        "translation": {
            "en": "In other words, in a feedforward network the activations in the network always flow forward through the sequence of layers.",
            "zh": "换句话说，在前馈网络中，网络中的激活总是通过层序列向前流动。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn’s options at this stage were (1) to embark on a large-scale manual data labeling project for which she would hire experts to manually label a suitably large set of historical night sky object observations, or (2) to find some other data source that she could add to the SDSS data to use as a target feature.",
            "zh": "Jocelyn 在这个阶段的选择是 （1） 开始一个大规模的手动数据标记项目，为此她将聘请专家手动标记一组适当大的历史夜空天体观测，或者 （2） 找到一些其他数据源，她可以将其添加到 SDSS 数据中以用作目标特征。"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms learn prediction models by inducing a generalized model of the relationship between a set of descriptive features and a target feature from a set of specific training instances.",
            "zh": "机器学习算法通过从一组特定训练实例中诱导出一组描述性特征与目标特征之间关系的广义模型来学习预测模型。"
        }
    },
    {
        "translation": {
            "en": "Readers who are not already familiar with standard measures of central tendency (mean, mode, and median), standard measures of variation (standard deviation and percentiles), and standard data visualization plots (bar plots, histograms, and box plots) should read Appendix A[745] for the necessary introduction.",
            "zh": "如果读者还不熟悉集中趋势的标准度量（均值、众数和中位数）、标准变异度量（标准差和百分位数）和标准数据可视化图（条形图、直方图和箱形图），则应阅读附录 A[745] 以获取必要的介绍。"
        }
    },
    {
        "translation": {
            "en": "Equation (7.14)[324] calculates the gradient based only on a single training instance. To take into account multiple training instances, we calculate the sum of the squared errors for each training instance (as we did in all our previous examples). So, Equation (7.14)[324] becomes",
            "zh": "方程（7.14）[324]仅基于单个训练实例计算梯度。为了考虑多个训练实例，我们计算每个训练实例的平方误差之和（就像我们在之前的所有示例中所做的那样）。因此，方程（7.14）[324]变为"
        }
    },
    {
        "translation": {
            "en": "Due to the fact that the differences are squared, variances are not in the same units as the original values, so they are not especially informative—telling someone that the variance of the heights on one team is 63.125 and on another is 1,011.411 doesn’t give them any particularly useful information other than the fact that the variance of one team is bigger than that of the other.",
            "zh": "由于差值是平方的，因此方差与原始值的单位不同，因此它们不是特别有用的信息——告诉某人一个团队的高度方差是 63.125，另一个团队的高度方差是 1,011.411 除了一个团队的方差大于另一个团队的方差这一事实之外，并没有给他们任何特别有用的信息。"
        }
    },
    {
        "translation": {
            "en": "An indication of the performance of the model is also evident from this ordering—the Target column shows that the instances that actually should get predictions of the ham level generally have lower scores, and those that should get predictions of the spam level generally have higher scores.",
            "zh": "从此排序中也可以明显看出模型的性能 - “目标”列显示，实际应获得 ham 级别预测的实例通常具有较低的分数，而那些应该获得垃圾邮件级别预测的实例通常具有较高的分数。"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the ReLU network changed during training when α = 0.2.",
            "zh": "该图显示了当 α = 0.2 时，ReLU 网络的平方误差总和在训练期间如何变化。"
        }
    },
    {
        "translation": {
            "en": "Consequently, we begin the worked example by explaining why normalization is important for neural networks and normalizing the data in Table 8.1[422].",
            "zh": "因此，我们通过解释为什么归一化对神经网络很重要，并在表 8.1[422] 中对数据进行归一化来开始工作示例。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.13",
            "zh": "图 5.13"
        }
    },
    {
        "translation": {
            "en": "Given that there are multiple Bayesian networks for any domain, an obvious question to ask is, what is the best topological structure to give the algorithm as input?",
            "zh": "鉴于任何域都有多个贝叶斯网络，一个显而易见的问题是，将算法作为输入的最佳拓扑结构是什么？"
        }
    },
    {
        "translation": {
            "en": "At some point in this process, however, overfitting will begin to occur, and the ability of the model to generalize well to new query instances will diminish.",
            "zh": "但是，在此过程中的某个时刻，将开始发生过度拟合，并且模型很好地泛化到新查询实例的能力将减弱。"
        }
    },
    {
        "translation": {
            "en": "As well as visually inspecting scatter plots, we can calculate formal measures of the relationship between two continuous features using covariance and correlation. For two features, a and b, in a dataset of n instances, the sample covariance between a and b is",
            "zh": "除了目视检查散点图外，我们还可以使用协方差和相关性计算两个连续特征之间关系的形式度量。对于包含 n 个实例的数据集中的两个特征 a 和 b，a 和 b 之间的样本协方差为"
        }
    },
    {
        "translation": {
            "en": "[Payment prediction] Many fraudulent insurance claims simply over-exaggerate the amount that should actually be paid out.",
            "zh": "[付款预测]许多欺诈性保险索赔只是夸大了实际应该支付的金额。"
        }
    },
    {
        "translation": {
            "en": "There are lots of options for the state representation that can be used to model an agent playing the game TwentyTwos.",
            "zh": "状态表示有很多选项可用于对玩游戏 TwentyTwo 的代理进行建模。"
        }
    },
    {
        "translation": {
            "en": "As the name constrained quadratic optimization problem suggests, this type of problem is defined in terms of (1) a set of constraints and (2) an optimization criterion.",
            "zh": "顾名思义，约束二次优化问题，这类问题的定义是：（1）一组约束条件和（2）一个优化准则。"
        }
    },
    {
        "translation": {
            "en": "Dataset for predicting the vegetation in an area sorted by the continuous ELEVATION feature.",
            "zh": "用于预测按连续高程要素排序的区域内植被的数据集。"
        }
    },
    {
        "translation": {
            "en": "binning, 89, 102, 146, 280",
            "zh": "分档、89、102、146、280"
        }
    },
    {
        "translation": {
            "en": "For a query instance with SPEND = 25.67 and FREQ = 6.12, which are normalized to SPEND = −0.7279 and FREQ = 0.4789, the predictions of the individual models would be",
            "zh": "对于 SPEND = 25.67 和 FREQ = 6.12 的查询实例，它们被归一化为 SPEND = −0.7279 和 FREQ = 0.4789，各个模型的预测将是"
        }
    },
    {
        "translation": {
            "en": "6.8   The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.2[263].",
            "zh": "6.8 朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表6.2[263]中的数据集计算得出。"
        }
    },
    {
        "translation": {
            "en": "7.10   (a) A scatter plot of the RPM and VIBRATION descriptive features from the generators dataset shown in Table 7.6[339], where good generators are shown as crosses, and faulty generators are shown as triangles; and (b) as decision boundary separating good generators (crosses) from faulty generators (triangles).",
            "zh": "7.10 （a） 表7.6[339]所示的发电机数据集中的RPM和VIBRATION描述性特征的散点图，其中好的发电机显示为十字形，故障发电机显示为三角形;（b）作为将良好发电机（十字架）与故障发电机（三角形）分开的决策边界。"
        }
    },
    {
        "translation": {
            "en": "At the beginning, a large value 0.9 is used and this slowly moves down toward a small value 0.05.",
            "zh": "一开始，使用大值 0.9，然后慢慢向下移动到小值 0.05。"
        }
    },
    {
        "translation": {
            "en": "The sampling density is the average density of training instances across the feature space.",
            "zh": "采样密度是整个特征空间中训练实例的平均密度。"
        }
    },
    {
        "translation": {
            "en": "Randomly dropping neurons from a network during training may seem like a surprising way to improve the performance of the model.",
            "zh": "在训练期间从网络中随机丢弃神经元似乎是提高模型性能的一种令人惊讶的方法。"
        }
    },
    {
        "translation": {
            "en": "A further advantage that results from this simplicity is the compactness of the naive Bayes model with which a very large dataset can be represented.",
            "zh": "这种简单性带来的另一个优势是朴素贝叶斯模型的紧凑性，可以表示非常大的数据集。"
        }
    },
    {
        "translation": {
            "en": "Ted’s second observation was that, although there was a huge amount of data available on past observations of night sky objects, only a tiny fraction of these contained manual labels indicating the morphological category to which they belonged.",
            "zh": "泰德的第二个观察结果是，尽管过去对夜空天体的观测有大量数据可用，但其中只有一小部分包含手动标签，表明它们所属的形态类别。"
        }
    },
    {
        "translation": {
            "en": "Bayes’ Theorem relates these two views of probability by using the notion of a prior probability.",
            "zh": "贝叶斯定理通过使用先验概率的概念将这两种概率观点联系起来。"
        }
    },
    {
        "translation": {
            "en": "The original feature values shown in Table 6.18[295] are continuous, so we use the standard approach of converting them to categorical features using equal-frequency binning, with two bins for each feature: low and high. The columns labeled Binned Feature Values in Table 6.18[295] show the data after it has been binned.",
            "zh": "表6.18[295]中显示的原始特征值是连续的，因此我们使用标准方法，使用等频分箱将它们转换为分类特征，每个特征有两个条柱：低和高。表 6.18[295] 中标有“分箱要素值”的列显示数据分箱后的数据。"
        }
    },
    {
        "translation": {
            "en": "Each of the circles in the network represents a processing neuron that transforms its input using the previously described two-step process of a weighted sum followed by an activation function.",
            "zh": "网络中的每个圆圈都代表一个处理神经元，该神经元使用前面描述的两步过程（加权和后跟激活函数）来转换其输入。"
        }
    },
    {
        "translation": {
            "en": "0.558",
            "zh": "0.558"
        }
    },
    {
        "translation": {
            "en": "13.5   Evaluation",
            "zh": "13.5 评估"
        }
    },
    {
        "translation": {
            "en": "This observation is important because it highlights that machine learning has the same properties as inductive learning.",
            "zh": "这一观察结果很重要，因为它强调了机器学习具有与归纳学习相同的属性。"
        }
    },
    {
        "translation": {
            "en": "The other two functions are known as polynomial functions as they include addition, multiplication, and raising to exponents.",
            "zh": "另外两个函数称为多项式函数，因为它们包括加法、乘法和提升到指数。"
        }
    },
    {
        "translation": {
            "en": "(a) A selection of images from the handwritten digits dataset; (b) image reconstructions generated by the auto-encoder network before training; (c) image reconstructions generated by the auto-encoder network after minimal training (10 epochs); and (d) image reconstructions generated by the auto-encoder network after complete training (1,000 epochs).",
            "zh": "（a） 从手写数字数据集中选出的图像;（b）自编码器网络在训练前生成的图像重建;（c） 自动编码器网络在最小训练（10 个周期）后生成的图像重建;（d）自动编码器网络在完成训练后生成的图像重建（1,000个周期）。"
        }
    },
    {
        "translation": {
            "en": "For each feature, we should examine the central tendency and variation to understand the types of values that each feature can take.",
            "zh": "对于每个特征，我们应该检查中心趋势和变化，以了解每个特征可以采用的值类型。"
        }
    },
    {
        "translation": {
            "en": "3.1 The Data Quality Report",
            "zh": "3.1 数据质量报告"
        }
    },
    {
        "translation": {
            "en": "There is no closed form solution to calculate the parameters to fit a mixture of Gaussians distribution to a set of feature values, as there is for the exponential and normal distributions.",
            "zh": "没有闭式解来计算参数以将高斯分布的混合拟合到一组特征值，就像指数分布和正态分布一样。"
        }
    },
    {
        "translation": {
            "en": "R2 coefficient values fall in the range [0,1) and larger values indicate better model performance. A useful interpretation of the R2 coefficient is as the amount of variation in the target feature that is explained by the descriptive features in the model.",
            "zh": "R2 系数值在 [0,1] 范围内，值越大表示模型性能越好。R2 系数的一个有用解释是目标特征的变异量，由模型中的描述性特征解释。"
        }
    },
    {
        "translation": {
            "en": "There are 10 values that the dealer’s visible card can represent: 2 to 11.",
            "zh": "庄家的可见卡片可以表示 10 个值：2 到 11。"
        }
    },
    {
        "translation": {
            "en": "We explain the early stopping algorithm in Section 8.4.4[472].",
            "zh": "我们在 Section 8.4.4[472] 中解释了早期停止算法。"
        }
    },
    {
        "translation": {
            "en": "There are two goals in data exploration.",
            "zh": "数据探索有两个目标。"
        }
    },
    {
        "translation": {
            "en": "7.16   (a) A scatter plot of the RAIN and GROWTH feature from the grass growth dataset; and (b) the same plot with a simple linear regression model trained to capture the relationship between the grass growth and rainfall.",
            "zh": "7.16 （a） 草生长数据集中雨水和生长特征的散点图;（b）使用简单的线性回归模型训练相同的图，以捕捉草生长和降雨之间的关系。"
        }
    },
    {
        "translation": {
            "en": "This problem is illustrated very clearly in the famous example of Anscombe’s quartet,8 shown in Figure 3.12[86]. This is a series of four pairs of features that all have the same correlation value of 0.816, even though they exhibit very different relationships.",
            "zh": "这个问题在著名的Anscombe四重奏8中得到了非常清晰的说明，如图3.12所示[86]。这是一系列四对特征，它们都具有相同的相关值 0.816，尽管它们表现出非常不同的关系。"
        }
    },
    {
        "translation": {
            "en": "The large gap between the two apparent clusters in this dataset results in a large variance, which indicates that we are probably underfitting with this grouping.",
            "zh": "该数据集中两个明显聚类之间的巨大差距导致了很大的方差，这表明我们可能与这种分组拟合不足。"
        }
    },
    {
        "translation": {
            "en": "A single-layer network.",
            "zh": "单层网络。"
        }
    },
    {
        "translation": {
            "en": "gates, 508",
            "zh": "盖茨，508"
        }
    },
    {
        "translation": {
            "en": "Figure C.1(b)[765] shows a profile of the acceleration during this journey.",
            "zh": "图C.1（b）[765]显示了这一过程中的加速度曲线。"
        }
    },
    {
        "translation": {
            "en": "In this section we describe the most popular performance measures used for continuous targets.",
            "zh": "在本节中，我们将介绍用于连续目标的最常用的绩效度量。"
        }
    },
    {
        "translation": {
            "en": "The multiplication of w[4] × ENERGY RATING causes a problem here. Energy rating is a categorical feature, so multiplying the values of this feature by a numeric weight is simply not sensible. The basic structure of the multivariable linear regression model allows for only continuous descriptive features. Obviously, though, in real-world datasets, we often encounter categorical descriptive features, so for the linear regression approach to be really useful, we need a way to handle these.",
            "zh": "w[4] × ENERGY RATING 的乘法在这里会导致一个问题。能量额定值是一个分类特征，因此将该特征的值乘以数字权重是不明智的。多变量线性回归模型的基本结构只允许连续的描述性特征。然而，显然，在现实世界的数据集中，我们经常会遇到分类描述性特征，因此，要使线性回归方法真正有用，我们需要一种方法来处理这些特征。"
        }
    },
    {
        "translation": {
            "en": "In dealing with an elementwise vector product, this is applied to each of the separate products in turn.",
            "zh": "在处理逐元素向量乘积时，这依次应用于每个单独的乘积。"
        }
    },
    {
        "translation": {
            "en": "For this reason, unless a model uses a very small number of descriptive features (generally fewer than 10), we do not recommend this approach.",
            "zh": "因此，除非模型使用极少量的描述性特征（通常少于 10 个），否则我们不建议使用这种方法。"
        }
    },
    {
        "translation": {
            "en": "This illustrates that a decision boundary is a global representation of the predictions made by the local models associated with each instance in the training set.",
            "zh": "这说明决策边界是与训练集中每个实例关联的局部模型所做的预测的全局表示。"
        }
    },
    {
        "translation": {
            "en": "1.00",
            "zh": "1.00"
        }
    },
    {
        "translation": {
            "en": "All the different model selection criteria consist of a set of assumptions about the characteristics of the model that we would like the algorithm to induce.",
            "zh": "所有不同的模型选择标准都由一组关于模型特征的假设组成，我们希望算法能够诱导出这些假设。"
        }
    },
    {
        "translation": {
            "en": "3.1   The Data Quality Report",
            "zh": "3.1 数据质量报告"
        }
    },
    {
        "translation": {
            "en": "The data quality issues we identify from a data quality report will be of two types: data quality issues due to invalid data and data quality issues due to valid data.",
            "zh": "我们从数据质量报告中识别的数据质量问题分为两种类型：无效数据导致的数据质量问题和有效数据导致的数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "For example, if we sum across the posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false, we will get a value of 1.0 (see Table 6.6[267]).",
            "zh": "例如，如果我们在 FRAUD = false 的条件下对 GUARANTOR/COAPPLICANT 特征的后验概率分布求和，我们将得到 1.0 的值（参见表 6.6[267]）。"
        }
    },
    {
        "translation": {
            "en": "In summary, distance computations are sensitive to the value ranges of the features in the dataset.",
            "zh": "总之，距离计算对数据集中要素的值范围很敏感。"
        }
    },
    {
        "translation": {
            "en": "This is calculated by summing over all the instances in the training set the prediction error multiplied by the value of the relevant feature for that instance (see Equation (7.16)[327]).",
            "zh": "这是通过将训练集中的所有实例的预测误差乘以该实例的相关特征值相加来计算的（参见公式 （7.16）[327]）。"
        }
    },
    {
        "translation": {
            "en": "However, it is important to remember that neurons in a convolutional network do have bias terms and that they are learned in the same way, as they are feedforward networks.",
            "zh": "然而，重要的是要记住，卷积网络中的神经元确实有偏差项，并且它们的学习方式与前馈网络相同。"
        }
    },
    {
        "translation": {
            "en": "14.2   Choosing a Machine Learning Approach",
            "zh": "14.2 选择机器学习方法"
        }
    },
    {
        "translation": {
            "en": "Once the required probabilities are calculated, our naive Bayes model is ready to make predictions for queries.",
            "zh": "一旦计算出所需的概率，我们的朴素贝叶斯模型就可以对查询进行预测了。"
        }
    },
    {
        "translation": {
            "en": "(a) At the beginning of the first episode the player is dealt (2 ♥,K ♣), the dealer is dealt (A ♦,3 ♦), and the dealer’s visible card is the A ♦. Given these cards, what state is the TwentyTwos playing agent in?",
            "zh": "（a）在第一集开始时，玩家被发牌（2，K），庄家被发牌（A，3 ♦ ♦），庄家的可见牌是A ♦。 ♥ ♣有了这些牌，二十二队的特工处于什么状态？"
        }
    },
    {
        "translation": {
            "en": "Table 5.4[191] lists the updated dataset when the example query instance with its prediction of yes is included.5 Figure 5.5(a)[192] illustrates the Voronoi tessellation of the feature space that results from this update, and Figure 5.5(b)[192] presents the updated decision boundary.",
            "zh": "表 5.4[191] 列出了包含预测为 yes 的示例查询实例时更新的数据集。5 图 5.5（a）[192] 说明了此更新导致的特征空间的 Voronoi 细分，图 5.5（b）[192] 显示了更新后的决策边界。"
        }
    },
    {
        "translation": {
            "en": "25.56%",
            "zh": "25.56%"
        }
    },
    {
        "translation": {
            "en": "5.2   The SPEED and AGILITY ratings for 20 college athletes and whether they were drafted by a professional team.",
            "zh": "5.2 20 名大学运动员的速度和敏捷性评级，以及他们是否由专业团队选拔。"
        }
    },
    {
        "translation": {
            "en": "The dimensions of the matrix are dependent on the number of features and the number of values in the domains of the features.",
            "zh": "矩阵的维度取决于特征的数量和特征域中的值的数量。"
        }
    },
    {
        "translation": {
            "en": "It is at this point that the distinction between raw and derived features becomes apparent.",
            "zh": "正是在这一点上，原始特征和派生特征之间的区别变得明显。"
        }
    },
    {
        "translation": {
            "en": "probability distribution, 59, 94, 247, 752, 761",
            "zh": "概率分布， 59， 94， 247， 752， 761"
        }
    },
    {
        "translation": {
            "en": "The main conclusions from this, and other similar studies, is that no machine learning approach is universally best, and experimentation with different approaches is the best way to ensure that an accurate model is built.",
            "zh": "从这项研究和其他类似研究中得出的主要结论是，没有一种机器学习方法普遍是最好的，使用不同的方法进行实验是确保构建准确模型的最佳方法。"
        }
    },
    {
        "translation": {
            "en": "The calculation of the softmax activation function φsm over a vector of three logits l.",
            "zh": "softmax 激活函数 φsm 在 3 logits l 的向量上的计算。"
        }
    },
    {
        "translation": {
            "en": "If we do this when sampling the weights for each of the layers in the network, then the variance of the z values across all the layers will be stable.",
            "zh": "如果我们在对网络中每个层的权重进行采样时这样做，那么所有层的 z 值的方差将是稳定的。"
        }
    },
    {
        "translation": {
            "en": "In 2010 AT hired Ross, a predictive data analytics specialist, to take a new approach to reducing customer churn. This case study describes the work carried out by Ross when he took AT through the CRISP-DM process1 in order to develop a predictive data analytics solution to this business problem. The remainder of this chapter will discuss how each phase of the CRISP-DM process was addressed in this project.",
            "zh": "2010 年，AT 聘请了预测数据分析专家 Ross 来采用一种新方法来减少客户流失。本案例研究描述了 Ross 在使用 CRISP-DM 流程 1 时所做的工作，以便为该业务问题开发预测性数据分析解决方案。本章的其余部分将讨论如何在该项目中解决 CRISP-DM 过程的每个阶段。"
        }
    },
    {
        "translation": {
            "en": "Finally, there are possibly legal restrictions associated with making this kind of contact.",
            "zh": "最后，进行这种接触可能存在法律限制。"
        }
    },
    {
        "translation": {
            "en": "Consequently, here we assume that the weight matrices do not include bias terms.",
            "zh": "因此，这里我们假设权重矩阵不包括偏差项。"
        }
    },
    {
        "translation": {
            "en": "It is also important that densities are shown rather than frequencies, as the overall bar plots on the left of each visualization cover much more of the dataset than the other two plots, so frequency-based plots would look very uneven.",
            "zh": "显示密度而不是频率也很重要，因为每个可视化左侧的整体条形图比其他两个图覆盖了更多的数据集，因此基于频率的图看起来非常不均匀。"
        }
    },
    {
        "translation": {
            "en": "As a result, the elements along the main diagonal list the covariance between a feature and itself, in other words, the variance of the feature.",
            "zh": "因此，沿主对角线的元素列出了特征与自身之间的协方差，换句话说，就是特征的方差。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.16",
            "zh": "图 5.16"
        }
    },
    {
        "translation": {
            "en": "Figure 8.14",
            "zh": "图 8.14"
        }
    },
    {
        "translation": {
            "en": "2. Is the approach suitable for the type of prediction we want to make and the types of descriptive features we are using?",
            "zh": "2. 该方法是否适合我们想要进行的预测类型和我们正在使用的描述性特征类型？"
        }
    },
    {
        "translation": {
            "en": "Table 6.16",
            "zh": "表 6.16"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11(a)[561] shows the changing values for TPR and TNR for the prediction scores shown in Table 9.13[560] as the threshold is varied from 0 to 1.13 This graph shows that changing the value of the threshold results in a trade-off between accuracy for predictions of positive target levels and accuracy for predictions of negative target levels. Capturing this trade-off is the basis of the ROC curve.",
            "zh": "图 9.11（a）[561] 显示了表 9.13[560] 中所示预测分数的 TPR 和 TNR 值的变化值，因为阈值从 0 到 1.13 变化。捕捉这种权衡是 ROC 曲线的基础。"
        }
    },
    {
        "translation": {
            "en": "false alarms, 538",
            "zh": "误报，538"
        }
    },
    {
        "translation": {
            "en": "This w[0] term is often referred to as the bias parameter because in the absence of any other input, the output of the weighted sum is biased to be the value of w[0].",
            "zh": "这个 w[0] 项通常被称为偏置参数，因为在没有任何其他输入的情况下，加权和的输出偏置为 w[0] 的值。"
        }
    },
    {
        "translation": {
            "en": "100.16%",
            "zh": "100.16%"
        }
    },
    {
        "translation": {
            "en": "This ensures that no error gradients flow back through the neurons that were dropped for this example.",
            "zh": "这确保了没有误差梯度回流回本示例中丢弃的神经元。"
        }
    },
    {
        "translation": {
            "en": "13.4   The revised domain concepts diagram for the galaxy classification task.",
            "zh": "13.4 修订后的星系分类任务领域概念图。"
        }
    },
    {
        "translation": {
            "en": "(b) Clinicians often use BMI as a combined measure of an individual’s WEIGHT and HEIGHT. BMI is defined as an individual’s weight in kilograms divided by their height in meters-squared. Assuming that the profiles of the five individuals in the system were updated so that the features WEIGHT and HEIGHT were replaced by a single feature BMI and also that the doctor entered the patient’s BMI into the system, what prediction would the system return for this patient?",
            "zh": "（b） 临床医生经常使用 BMI 作为个人体重和身高的综合衡量标准。BMI 定义为个人的体重（公斤）除以身高（米）的平方。假设系统中五个人的个人资料被更新，以便将特征 WEIGHT 和 HEIGHT 替换为单个特征 BMI，并且医生将患者的 BMI 输入系统，系统会为该患者返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "slope of a line, 313, 766",
            "zh": "直线的斜率，313,766"
        }
    },
    {
        "translation": {
            "en": "Correctly predicting the bad level for a potential borrower results in no profit as no money is loaned.11 Incorrectly predicting the good level for a potential borrower who goes on to default on the loan, however, results in a loan not being repaid.",
            "zh": "11 然而，错误地预测潜在借款人的不良水平会导致没有利润，因为没有钱被借出.11 然而，错误地预测了继续拖欠贷款的潜在借款人的良好水平，会导致贷款无法偿还。"
        }
    },
    {
        "translation": {
            "en": "The same can actually be done for models that predict binary categorical targets by dividing the prediction scores into deciles.",
            "zh": "对于通过将预测分数划分为十分位数来预测二元分类目标的模型，实际上也可以这样做。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the selection of a machine learning approach also depends on the aspects of an application scenario described above (speed, capacity for retraining, interpretability), and often, these factors are a bigger driver for the selection of a machine learning approach than prediction accuracy.",
            "zh": "此外，机器学习方法的选择还取决于上述应用场景的各个方面（速度、再训练能力、可解释性），通常，这些因素是选择机器学习方法的更大驱动因素，而不是预测准确性。"
        }
    },
    {
        "translation": {
            "en": "binary data, 34",
            "zh": "二进制数据，34"
        }
    },
    {
        "translation": {
            "en": "7.10   A dataset showing participants’ responses to viewing positive and negative images measured on the EEG P20 and P45 potentials.",
            "zh": "7.10 一个数据集，显示参与者对观看在 EEG P20 和 P45 电位上测量的正面和负面图像的反应。"
        }
    },
    {
        "translation": {
            "en": "In forward sequential selection, the search starts in a state with no features (shown on the left of Figure 5.19[228]).",
            "zh": "在前向顺序选择中，搜索以没有特征的状态开始（如图 5.19[228] 左侧所示）。"
        }
    },
    {
        "translation": {
            "en": "For example, if a prediction model is being used as a diagnostic tool in a medical scenario, it is not sufficient for the system to simply return a diagnosis.",
            "zh": "例如，如果预测模型在医疗场景中用作诊断工具，则系统仅返回诊断是不够的。"
        }
    },
    {
        "translation": {
            "en": "Then in Section 8.4.3[463] we explain how to adapt the design of a neural network to classification problems by using a softmax output layer and the cross-entropy loss function.",
            "zh": "然后，在第 8.4.3 节[463]中，我们解释了如何通过使用 softmax 输出层和交叉熵损失函数来调整神经网络的设计以适应分类问题。"
        }
    },
    {
        "translation": {
            "en": "discontinuous function, 341",
            "zh": "不连续函数，341"
        }
    },
    {
        "translation": {
            "en": "Multiplying the difference in feature values by the inverse covariance matrix has two effects.",
            "zh": "将特征值的差值乘以逆协方差矩阵有两个效果。"
        }
    },
    {
        "translation": {
            "en": "matrix product, 385",
            "zh": "矩阵乘积，385"
        }
    },
    {
        "translation": {
            "en": "(a)–(b) Visualizations of the distributions of the descriptive features in the mobile phone customer dataset in Table 10.1[604] across the complete dataset, and divided by the clustering found using k-means clustering (k = 3).",
            "zh": "（a）–（b） 表10.1[604]中移动电话客户数据集中描述性特征在整个数据集中的分布可视化，并除以使用k-means聚类（k = 3）找到的聚类。"
        }
    },
    {
        "translation": {
            "en": "3.6.1   Normalization",
            "zh": "3.6.1 归一化"
        }
    },
    {
        "translation": {
            "en": "A PDF is an abstraction over a density histogram and, as such, defines a density curve.",
            "zh": "PDF 是对密度直方图的抽象，因此定义了密度曲线。"
        }
    },
    {
        "translation": {
            "en": "Only 3 of these scenarios, however, will lead to the agent staying in the PM-DH state.",
            "zh": "然而，这些场景中只有 3 种会导致代理保持 PM-DH 状态。"
        }
    },
    {
        "translation": {
            "en": "In Figure 7.10(b)[340] the decision boundary is defined as",
            "zh": "在图7.10（b）[340]中，决策边界定义为"
        }
    },
    {
        "translation": {
            "en": "Using a horizontal and vertical stride of 1 means that there is a relatively large overlap in the receptive fields between a neuron and its neighbors.",
            "zh": "使用水平和垂直步幅 1 意味着神经元与其邻居之间的感受野存在相对较大的重叠。"
        }
    },
    {
        "translation": {
            "en": "Near-sighted parents are more likely to have near-sighted children, and it is this that accounts for the correlation between night-light use and near-sightedness in children, rather than any causal link.",
            "zh": "近视的父母更有可能生出近视的孩子，正是这一点解释了儿童使用夜灯与近视之间的相关性，而不是任何因果关系。"
        }
    },
    {
        "translation": {
            "en": "2. The table below gives details of symptoms that patients presented and whether they were suffering from meningitis.",
            "zh": "2. 下表详细介绍了患者出现的症状以及他们是否患有脑膜炎。"
        }
    },
    {
        "translation": {
            "en": "Table 5.10[212] shows the calculation of the numerator and denominator of Equation (5.8)[210] for our whiskey bottle example, using the normalized dataset with k set to 20 (the full size of the dataset). The final prediction for the price of the bottle of whiskey we plan to sell is",
            "zh": "表5.10[212]显示了我们的威士忌酒瓶示例的等式（5.8）[210]的分子和分母的计算，使用k设置为20（数据集的全大小）的归一化数据集。我们计划出售的一瓶威士忌价格的最终预测是"
        }
    },
    {
        "translation": {
            "en": "Figure 8.9",
            "zh": "图 8.9"
        }
    },
    {
        "translation": {
            "en": "Figure 9.3",
            "zh": "图 9.3"
        }
    },
    {
        "translation": {
            "en": "For more information on stroke and risk factors related to stroke, please see the National Heart, Lung, and Blood Institute on Stroke: https://www.nhlbi.nih.gov/health-topics/stroke.",
            "zh": "有关卒中和卒中相关危险因素的更多信息，请参阅美国国家心肺血液研究所卒中：https://www.nhlbi.nih.gov/health-topics/stroke。"
        }
    },
    {
        "translation": {
            "en": "(e) The charity for which the model is being built typically has only enough money to send a mailshot to the top 20% of its contact list. Based on the cumulative gain chart generated in the previous part, would you recommend that Model 1 or Model 2 would perform best for the charity?",
            "zh": "（e） 为之构建模型的慈善机构通常只有足够的资金向其联系人列表中的前 20% 发送邮件。根据上一部分生成的累积收益图表，您认为模型 1 或模型 2 对慈善机构来说表现最好吗？"
        }
    },
    {
        "translation": {
            "en": "6.3   Standard Approach: The Naive Bayes Model",
            "zh": "6.3 标准方法：朴素贝叶斯模型"
        }
    },
    {
        "translation": {
            "en": "Most of the advice given in the previous sections on choosing machine learning approaches and completing successful projects, also equally applies to these machine learning approaches, and a good grounding in predictive modeling makes adding these approaches to your toolkit relatively straight-forward.",
            "zh": "前面几节中给出的关于选择机器学习方法和完成成功项目的大多数建议也同样适用于这些机器学习方法，并且预测建模的良好基础使得将这些方法添加到您的工具包中变得相对简单。"
        }
    },
    {
        "translation": {
            "en": "Sampling techniques can be used to reduce the size of a large ABT to make exploratory analysis easier, to change the distributions of target features in an ABT, and to generate different portions of an ABT to use for training and evaluating a model.",
            "zh": "采样技术可用于减小大型 ABT 的大小，以便更轻松地进行探索性分析，更改 ABT 中目标特征的分布，并生成 ABT 的不同部分以用于训练和评估模型。"
        }
    },
    {
        "translation": {
            "en": "Table 6.12[280] shows how these values are calculated, and the dashed lines in Figure 6.8[279] plot the density curves that result from this process.",
            "zh": "表6.12[280]显示了这些值的计算方法，图6.8[279]中的虚线绘制了这一过程产生的密度曲线。"
        }
    },
    {
        "translation": {
            "en": "We use a lowercase z to represent the result of the weighted sum of the inputs in a neuron.",
            "zh": "我们使用小写的 z 来表示神经元中输入的加权和的结果。"
        }
    },
    {
        "translation": {
            "en": "Equation (11.18)[652] still includes the expected return that arises from taking all of the actions after at essentially as it was stated before in Equation (11.17)[651].",
            "zh": "等式（11.18）[652]仍然包括在等式（11.17）[651]中陈述的在at之后采取所有行动所产生的预期回报。"
        }
    },
    {
        "translation": {
            "en": "A hidden feature is a feature whose value is not specified as part of the evidence.",
            "zh": "隐藏特征是指其值未指定为证据的一部分的特征。"
        }
    },
    {
        "translation": {
            "en": "For example, in a mobile telecoms scenario, we could represent customers with just two descriptive features: the average number of SMS messages a customer sends per month, and the average number of VOICE calls a customer makes per month.",
            "zh": "例如，在移动电信场景中，我们可以仅使用两个描述性特征来表示客户：客户每月发送的平均短信数，以及客户每月拨打 VOICE 的平均次数。"
        }
    },
    {
        "translation": {
            "en": "The mathematical foundation of these approaches can be described using five simple (but important) equations: Claude Shannon’s model of entropy (Equation (14.1)[731]), Euclidean distance (Equation (14.2)[731]), Bayes’ Theorem (Equation (14.3)[731]), the sum of squared errors (Equation (14.4)[731]), and the application of the chain rule to backpropagate error gradients in a neural network (Equation (14.5)[731]).",
            "zh": "这些方法的数学基础可以用五个简单（但很重要）的方程来描述：克劳德·香农的熵模型（方程（14.1）[731]）、欧几里得距离（方程（14.2）[731]）、贝叶斯定理（方程（14.3）[731]）、误差的平方和（方程（14.4）[731]），以及链式法则在神经网络中反向传播误差梯度的应用（方程（14.5）[731]）。"
        }
    },
    {
        "translation": {
            "en": "INTRODUCTION TO MACHINE LEARNING AND DATA ANALYTICS",
            "zh": "机器学习和数据分析简介"
        }
    },
    {
        "translation": {
            "en": "Unique SDSS object identifier",
            "zh": "唯一 SDSS 对象标识符"
        }
    },
    {
        "translation": {
            "en": "The partitioning of the dataset in Table 4.11[152] based on SEASON and WORK DAY features and the computation of the weighted variance for each partitioning.",
            "zh": "表4.11[152]中基于SEASON和WORK DAY特征对数据集进行分区，并计算每个分区的加权方差。"
        }
    },
    {
        "translation": {
            "en": "; CLAIM TO PREMIUM PAID RATIO: CLAIM TO PREM.",
            "zh": ";理赔与已付保费比率：理赔至预付款。"
        }
    },
    {
        "translation": {
            "en": "—Sherlock Holmes",
            "zh": "——夏洛克·福尔摩斯"
        }
    },
    {
        "translation": {
            "en": "In the email classification example, the percentage of positive (spam) instances in the full test dataset is .",
            "zh": "在电子邮件分类示例中，完整测试数据集中阳性（垃圾邮件）实例的百分比为 。"
        }
    },
    {
        "translation": {
            "en": "Using a patience parameter allows the validation error to fluctuate a bit during training while still allow training to progress; it is only when we have observed a clear trend over multiple iterations of a relatively high validation error that we stop training.",
            "zh": "使用耐心参数允许验证错误在训练期间略有波动，同时仍允许训练进行;只有当我们在多次迭代中观察到相对较高的验证误差的明显趋势时，我们才会停止训练。"
        }
    },
    {
        "translation": {
            "en": "This leads to the same conclusion with regard to model ranking as the root mean squared error measures: namely, that the regression model has better performance on this task than the nearest neighbor model.",
            "zh": "这导致了与均方根误差度量相同的模型排序结论：即回归模型在此任务上比最近邻模型具有更好的性能。"
        }
    },
    {
        "translation": {
            "en": "We subsequently explain what is causing both these vanishing and exploding z values.",
            "zh": "随后，我们将解释导致这些消失和爆炸的 z 值的原因。"
        }
    },
    {
        "translation": {
            "en": "On completion of each action the agent receives an immediate scalar reward indicating whether the outcome of the action was positive or negative, and to what degree.",
            "zh": "在完成每个操作后，智能体会立即收到标量奖励，指示操作的结果是积极的还是消极的，以及程度如何。"
        }
    },
    {
        "translation": {
            "en": "transpose, 772",
            "zh": "转置，772"
        }
    },
    {
        "translation": {
            "en": "The backpropagation algorithm begins by initializing the weights of the network.",
            "zh": "反向传播算法首先初始化网络的权重。"
        }
    },
    {
        "translation": {
            "en": "This trend has continued and recent, high-profile successes include Deep Q Learning for Atari video games (Mnih et al., 2013), AlphaGo for Go (Silver et al., 2017), AlphaZero for chess (Silver et al., 2018), and the OpenAI Five player for DOTA 2 (McCandlish et al., 2018).",
            "zh": "这种趋势仍在继续，最近备受瞩目的成功包括用于 Atari 视频游戏的 Deep Q Learning（Mnih 等人，2013 年）、用于围棋的 AlphaGo（Silver 等人，2017 年）、用于国际象棋的 AlphaZero（Silver 等人，2018 年）和 DOTA 2 的 OpenAI Five 玩家（McCandlish 等人，2018 年）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.34",
            "zh": "图 8.34"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values of all instances above the decision boundary will result in a negative value when plugged into the decision boundary equation, whereas the descriptive features of all instances below the decision boundary will result in a positive value.",
            "zh": "当代入决策边界方程时，决策边界以上所有实例的描述性特征值将产生负值，而决策边界以下所有实例的描述性特征将产生正值。"
        }
    },
    {
        "translation": {
            "en": "A number of other features exhibited a similar pattern.",
            "zh": "许多其他特征也表现出类似的模式。"
        }
    },
    {
        "translation": {
            "en": "LSTM, 508",
            "zh": "LSTM，508"
        }
    },
    {
        "translation": {
            "en": "7.5   (a) A 3D surface plot and (b) a bird’s-eye view contour plot of the error surface for the office rentals dataset showing the path that the gradient descent algorithm takes toward the best-fit model.",
            "zh": "7.5 （a） 写字楼租赁数据集误差面的 3D 曲面图和 （b） 鸟瞰等值线图，显示了梯度下降算法走向最佳拟合模型的路径。"
        }
    },
    {
        "translation": {
            "en": "What this means is that for any given input vector, only a subset of the neurons in the network will activate (i.e., ai > 0).",
            "zh": "这意味着，对于任何给定的输入向量，网络中只有一部分神经元会激活（即 ai > 0）。"
        }
    },
    {
        "translation": {
            "en": "Normalization also has a part to play here.",
            "zh": "归一化在这里也发挥了作用。"
        }
    },
    {
        "translation": {
            "en": "In order from top to bottom, we show decision trees (without pruning), nearest neighbor models (with k = 3 and using majority voting), naive Bayes models (using normal distributions to represent the two continuous feature values), and logistic regression models (using a simple linear model).",
            "zh": "从上到下，我们展示了决策树（不修剪）、最近邻模型（k = 3 并使用多数投票）、朴素贝叶斯模型（使用正态分布来表示两个连续特征值）和逻辑回归模型（使用简单的线性模型）。"
        }
    },
    {
        "translation": {
            "en": "So, the big idea here is to figure out which features are the most informative ones to ask questions about by considering the effects of the different answers to the questions, in terms of how the domain is split up after the answer is received and the likelihood of each of the answers.",
            "zh": "因此，这里的大想法是通过考虑问题的不同答案的影响，在收到答案后如何划分域以及每个答案的可能性方面，找出哪些功能是最有用的问题。"
        }
    },
    {
        "translation": {
            "en": "7. Sometimes target levels in categorical prediction problems are referred to as classes, which is where this name comes from.",
            "zh": "7. 有时分类预测问题中的目标水平被称为类，这就是这个名字的由来。"
        }
    },
    {
        "translation": {
            "en": "Implementing the target feature for an ABT can demand significant effort.",
            "zh": "实现 ABT 的目标功能可能需要付出巨大的努力。"
        }
    },
    {
        "translation": {
            "en": "So if model performance is more important than computational considerations, backward sequential selection may be the better option; otherwise use forward sequential selection.",
            "zh": "因此，如果模型性能比计算考虑更重要，那么向后顺序选择可能是更好的选择;否则，请使用前向顺序选择。"
        }
    },
    {
        "translation": {
            "en": "9.19   A confusion matrix for a model trained on the bacterial species identification problem.",
            "zh": "9.19 针对细菌种类识别问题训练的模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "For many functions the requirement of sufficient neurons turns out to be exponential with respect to the dimensions of the network inputs.",
            "zh": "对于许多功能，相对于网络输入的维度，对足够神经元的需求呈指数级增长。"
        }
    },
    {
        "translation": {
            "en": "wrapper-based feature selection, 228, 541, 722",
            "zh": "基于包装器的功能选择，228、541、722"
        }
    },
    {
        "translation": {
            "en": "We believe that this book will provide you with an understanding of the broader context and core techniques of machine learning that will enable you to have a successful career in predictive data analytics.",
            "zh": "我们相信，本书将使您了解机器学习的更广泛背景和核心技术，这将使您在预测数据分析领域取得成功。"
        }
    },
    {
        "translation": {
            "en": "This process, working backward from the output to the input layer, constructs for each neuron in the network a chain of connections linking the weighted sum of the neuron to the error of the network.",
            "zh": "这个过程从输出层到输入层向后工作，为网络中的每个神经元构建了一条连接链，将神经元的加权和与网络的误差联系起来。"
        }
    },
    {
        "translation": {
            "en": "In the next section, we introduce the standard algorithm for growing decision trees in this way.",
            "zh": "在下一节中，我们将介绍以这种方式种植决策树的标准算法。"
        }
    },
    {
        "translation": {
            "en": "The mistake is to confuse the probability of a prediction given the evidence with the probability of the evidence given the prediction and is another example of the paradox of the false positive.10",
            "zh": "错误在于混淆了给定证据的预测概率和给定预测的证据的概率，这是误报悖论的另一个例子10。"
        }
    },
    {
        "translation": {
            "en": "“free money for free gambling fun”",
            "zh": "“免费赚钱，享受免费赌博的乐趣”"
        }
    },
    {
        "translation": {
            "en": "Identifiers: LCCN 2020002998 | ISBN 9780262044691 (hardcover)",
            "zh": "标识符：LCCN 2020002998 |ISBN 9780262044691 （精装）"
        }
    },
    {
        "translation": {
            "en": "27. The similarity of this update rule to the standard weight update rule is apparent if we compare this equation with Equation 8.28[415].",
            "zh": "27. 如果我们将这个等式与等式8.28[415]进行比较，这个更新规则与标准砝码更新规则的相似性是显而易见的。"
        }
    },
    {
        "translation": {
            "en": "The downside to this approach is that it introduces a number of extra weights for which optimal values must be found—in this simple example for only four descriptive features, we need seven weights.",
            "zh": "这种方法的缺点是它引入了许多额外的权重，必须找到最佳值 - 在这个只有四个描述性特征的简单示例中，我们需要七个权重。"
        }
    },
    {
        "translation": {
            "en": "LSTMs have a complex internal structure containing multiple layers of neurons, and they can be considered networks in their own right. However, they can also be used as the building block of a recurrent neural network. This is achieved by replacing the hidden layer in a recurrent neural network with an LSTM unit. LSTMs have proven very successful at processing language; for example, they are currently the standard network used for speech recognition on mobile phones.",
            "zh": "LSTM 具有复杂的内部结构，包含多层神经元，它们本身可以被视为网络。但是，它们也可以用作循环神经网络的构建块。这是通过用 LSTM 单元替换递归神经网络中的隐藏层来实现的。事实证明，LSTM 在处理语言方面非常成功;例如，它们目前是用于手机语音识别的标准网络。"
        }
    },
    {
        "translation": {
            "en": "We then use an appropriate measure to calculate the difference between the distributions collected after deployment and the original distribution.",
            "zh": "然后，我们使用适当的度量来计算部署后收集的分布与原始分布之间的差异。"
        }
    },
    {
        "translation": {
            "en": "How to Use This Book",
            "zh": "如何使用本书"
        }
    },
    {
        "translation": {
            "en": "Figure 7.19[356] shows a series of the models built during the gradient descent process.",
            "zh": "图7.19[356]显示了在梯度下降过程中构建的一系列模型。"
        }
    },
    {
        "translation": {
            "en": "fully connected network, 389",
            "zh": "全连接网络，389"
        }
    },
    {
        "translation": {
            "en": "This was the challenge that the SDSS had hired Jocelyn to address.",
            "zh": "这是 SDSS 聘请 Jocelyn 来应对的挑战。"
        }
    },
    {
        "translation": {
            "en": "There are, however, some situations where decision tree models are not the best option. Although decision trees can handle both categorical and continuous features, they tend to become quite large when dealing with continuous descriptive features. This can result in trees becoming difficult to interpret. Consequently, in dealing with purely continuous data, other prediction models may be more appropriate, for example, the error-based models discussed in Chapter 7[311].",
            "zh": "但是，在某些情况下，决策树模型不是最佳选择。尽管决策树可以处理分类特征和连续特征，但在处理连续描述性特征时，它们往往会变得相当大。这可能导致树木变得难以解释。因此，在处理纯连续数据时，其他预测模型可能更合适，例如第7章[311]中讨论的基于误差的模型。"
        }
    },
    {
        "translation": {
            "en": "This section describes two of the most common such techniques: binning and normalization.",
            "zh": "本节介绍两种最常见的此类技术：分箱和归一化。"
        }
    },
    {
        "translation": {
            "en": "For the score predicted by the model for each instance in the test set, the distance between the positive and negative cumulative probabilities at that score can then be calculated.",
            "zh": "对于模型预测的测试集中每个实例的分数，可以计算该分数处的正负累积概率之间的距离。"
        }
    },
    {
        "translation": {
            "en": "8.4.5   Convolutional Neural Networks",
            "zh": "8.4.5 卷积神经网络"
        }
    },
    {
        "translation": {
            "en": "A probability density function (PDF) represents the probability distribution of a continuous feature using a mathematical function, and there are a large number of standard, well-defined probability distributions—such as the normal distribution—that we can use to model the probability of a continuous feature taking different values in its range.",
            "zh": "概率密度函数 （PDF） 使用数学函数表示连续特征的概率分布，并且有大量标准、定义明确的概率分布（例如正态分布），可用于对连续特征在其范围内取不同值的概率进行建模。"
        }
    },
    {
        "translation": {
            "en": "Target",
            "zh": "目标"
        }
    },
    {
        "translation": {
            "en": "; CLAIM AMOUNT: CLAIM AMT.",
            "zh": ";索赔金额：索赔AMT。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5(a)[273] shows a histogram of a dataset that has been overlaid with the curves of a normal and a student-t distribution that have been fitted to the data.",
            "zh": "图 6.5（a）[273] 显示了数据集的直方图，该直方图已叠加到数据的正态分布和学生 t 分布曲线。"
        }
    },
    {
        "translation": {
            "en": "The distance between instance d15 and the query instance is 3.0208, which is not less than the current value of best-distance, so the if statement on Line 5 will fail.",
            "zh": "实例 d15 与查询实例之间的距离为 3.0208，不小于当前 best-distance 值，因此第 5 行的 if 语句将失败。"
        }
    },
    {
        "translation": {
            "en": "1,050",
            "zh": "1,050"
        }
    },
    {
        "translation": {
            "en": "When using out-of-time sampling, we should be careful to ensure that the times from which the training and test sets are taken do not introduce a bias into the evaluation process, because the two different time samples are not really representative.",
            "zh": "在使用时间外抽样时，我们应该小心确保训练集和测试集的获取时间不会在评估过程中引入偏差，因为两个不同的时间样本并不真正具有代表性。"
        }
    },
    {
        "translation": {
            "en": "The vector of activations that the unit would propagate forward as the cell state for the next time (ct) step is shown on the top right of the figure, and the vector of activations ot that the unit would propagate both to the output layer for this time-step and on to the next time-step as the hidden state is shown in the bottom-right of the figure.",
            "zh": "该单元将作为下一次 （ct） 步长的单元状态向前传播的激活向量显示在图的右上角，而该单元将在此时间步长和下一个时间步长（隐藏状态）中传播到下一个时间步的激活向量显示在图的右下角。"
        }
    },
    {
        "translation": {
            "en": "Any of the distance measures discussed in this book (as well as many others not discussed in this book) can be used for this.",
            "zh": "本书中讨论的任何距离测量（以及本书中未讨论的许多其他测量方法）都可以用于此目的。"
        }
    },
    {
        "translation": {
            "en": "6.4.4.3 Making predictions with missing descriptive feature values One real advantage of Bayesian networks over the other predictive model types that we discuss in this book is they a provide an elegant solution to making predictions for a target feature when one or more of the descriptive feature values in a query instance are missing.27 For example, we may wish to predict the CPI for a country with the following profile:",
            "zh": "6.4.4.3 使用缺失的描述性特征值进行预测 与本书中讨论的其他预测模型类型相比，贝叶斯网络的一个真正的优势是，当查询实例中的一个或多个描述性特征值缺失时，它们为对目标特征进行预测提供了一种优雅的解决方案27。 我们不妨预测一个国家/地区的 CPI："
        }
    },
    {
        "translation": {
            "en": "evolutionary reinforcement learning, 641",
            "zh": "进化强化学习，641"
        }
    },
    {
        "translation": {
            "en": "9.16   The (a) lift and (b) cumulative lift at each decile for the email predictions given in Table 9.11[557].",
            "zh": "9.16 表9.11[557]中给出的电子邮件预测的（a）提升和（b）每个十分位数的累积提升。"
        }
    },
    {
        "translation": {
            "en": "At this point all the remaining partitions are pure with respect to the target feature. Consequently, the algorithm converts each partition into a leaf node and returns the final decision tree. Figure 4.11[141] shows this decision tree. If the prediction strategy encoded in this tree is applied to the original dataset in Table 4.3[136], it will correctly classify all the instances in the dataset. In machine learning terms, the induced model is consistent with the training data.",
            "zh": "此时，所有剩余的分区相对于目标特征都是纯的。因此，该算法将每个分区转换为一个叶节点，并返回最终的决策树。图4.11[141]显示了这个决策树。如果将此树中编码的预测策略应用于表4.3[136]中的原始数据集，它将正确分类数据集中的所有实例。在机器学习方面，诱导模型与训练数据一致。"
        }
    },
    {
        "translation": {
            "en": "paradox of the false positive, 254",
            "zh": "误报悖论，254"
        }
    },
    {
        "translation": {
            "en": "5.2   (a) A generalized illustration of the Manhattan and Euclidean distances between two points; and (b) a plot of the Manhattan and Euclidean distances between instances d12 and d5, and between d12 and d17 from Table 5.2[183].",
            "zh": "5.2 （a） 两点之间曼哈顿距离和欧几里得距离的广义图示;（b）表5.2[183]中实例d12和d5之间以及d12和d17之间的曼哈顿和欧几里得距离图。"
        }
    },
    {
        "translation": {
            "en": "Predictive models are based on the assumption that the patterns learned in the training data will be relevant to unseen instances that are presented to the model in the future.",
            "zh": "预测模型基于这样的假设，即在训练数据中学习的模式将与将来呈现给模型的看不见的实例相关。"
        }
    },
    {
        "translation": {
            "en": "6.2.3   Conditional Independence and Factorization",
            "zh": "6.2.3 条件独立性和因式分解"
        }
    },
    {
        "translation": {
            "en": "For ease of explanation, we will assume that each of these three neurons uses a threshold activation function.",
            "zh": "为了便于解释，我们将假设这三个神经元中的每一个都使用阈值激活函数。"
        }
    },
    {
        "translation": {
            "en": "The SDSS pipeline takes the data captured by the SDSS instruments and processes it, before storing the results of this processing in a centrally accessible database.",
            "zh": "SDSS 管道获取 SDSS 仪器捕获的数据并对其进行处理，然后将此处理的结果存储在可集中访问的数据库中。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, the predictive analytics models that we can build do not do any of these things.",
            "zh": "不幸的是，我们可以构建的预测分析模型无法执行任何这些事情。"
        }
    },
    {
        "translation": {
            "en": "(See Section 3.5.2[81] for further discussion.)",
            "zh": "（有关进一步讨论，请参见第 3.5.2 节[81]。"
        }
    },
    {
        "translation": {
            "en": "8.3   A schematic of an artificial neuron.",
            "zh": "8.3 人工神经元示意图。"
        }
    },
    {
        "translation": {
            "en": "Three of these—2, 4, and 5—are shown in Table 1.4[10].",
            "zh": "其中三个（2、4 和 5）如表 1.4[10] 所示。"
        }
    },
    {
        "translation": {
            "en": "The ∂a/∂z for each neuron for Example 2 rounded to four decimal places.",
            "zh": "示例 2 中每个神经元的 ∂a/∂z 四舍五入到小数点后四位。"
        }
    },
    {
        "translation": {
            "en": "This is important because one of the key advantages of a nearest neighbor approach is that it can be updated with new instances as more labeled data arrive.",
            "zh": "这很重要，因为最近邻方法的主要优点之一是，随着更多标记数据的到来，它可以使用新实例进行更新。"
        }
    },
    {
        "translation": {
            "en": "When two or more neurons share a filter, then each weight in the filter is used multiple times during the forward pass of the training algorithm to process a given input (once by each neuron that uses the filter).",
            "zh": "当两个或多个神经元共享一个过滤器时，过滤器中的每个权重在训练算法的前向传递期间被多次使用，以处理给定的输入（每个使用过滤器的神经元一次）。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the selection of the best feature on which to split a dataset is based on the purity, or homogeneity, of the resulting partitions in the datasets.",
            "zh": "因此，选择用于拆分数据集的最佳特征是基于数据集中结果分区的纯度或同质性。"
        }
    },
    {
        "translation": {
            "en": "Whether the customer’s current handset is a smartphone",
            "zh": "客户当前的手机是否为智能手机"
        }
    },
    {
        "translation": {
            "en": "The architecture of the network consists of ReLUs that share a filter (Neurons 1,2,3,4), followed by a sub-sampling layer containing two max pooling units (Neurons 5,6), and then a fully connected layer containing a single ReLU (Neuron 7).",
            "zh": "该网络的架构由共享一个过滤器的 ReLU （神经元 1,2,3,4） 组成，然后是包含两个最大池化单元的子采样层（神经元 5,6），然后是包含单个 ReLU 的全连接层（神经元 7）。"
        }
    },
    {
        "translation": {
            "en": "Gradient-descent-like algorithms for training neural networks assume training instances are independent from each other.",
            "zh": "用于训练神经网络的类似梯度下降的算法假定训练实例彼此独立。"
        }
    },
    {
        "translation": {
            "en": "We use machine learning to train these models.",
            "zh": "我们使用机器学习来训练这些模型。"
        }
    },
    {
        "translation": {
            "en": "For now we continue with using two-dimensional filters, but we return to this topic in Section 8.4.5.5[492].",
            "zh": "现在，我们继续使用二维过滤器，但我们在第 8.4.5.5 节[492]中回到了这个主题。"
        }
    },
    {
        "translation": {
            "en": "(c) Based on the AUC values for Model 1 and Model 2, calculate the Gini coefficient for each model.",
            "zh": "（c） 根据模型1和模型2的AUC值，计算每个模型的基尼系数。"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo labels were available for approximately 600,000 SDSS galaxies, which Jocelyn felt would be more than enough to use to train and test a galaxy morphology classification model.",
            "zh": "银河动物园的标签可用于大约600,000个SDSS星系，Jocelyn认为这些标签足以用于训练和测试星系形态分类模型。"
        }
    },
    {
        "translation": {
            "en": "Equation 8.58[456] states that the variance of z is equal to the variance of the inputs (var(d)) scaled by nin var(W).",
            "zh": "公式 8.58[456] 指出，z 的方差等于输入的方差 （var（d）） 用 nin var（W） 缩放。"
        }
    },
    {
        "translation": {
            "en": "semi-supervised learning, 5, 742",
            "zh": "半监督学习，5,742"
        }
    },
    {
        "translation": {
            "en": "It is important that after the feature selection process is complete, a separate test set still exists that can be used to evaluate the expected performance of the model on future unseen data after deployment.",
            "zh": "重要的是，在功能选择过程完成后，仍然存在一个单独的测试集，可用于评估模型在部署后对未来看不见的数据的预期性能。"
        }
    },
    {
        "translation": {
            "en": "This means that they can learn to behave effectively in an environment with only minimal knowledge of that environment—the states that can be occupied and the actions that the agent can take are all that the agent needs to know.",
            "zh": "这意味着他们可以学会在一个环境中有效地表现，而对该环境只有最少的了解——可以占据的状态和代理可以采取的行动是代理需要知道的。"
        }
    },
    {
        "translation": {
            "en": "When we switch a network from ReLUs to Leaky ReLUs, we sacrifice the potential benefits in terms of energy efficiency of sparse representations for a gradient that may potentially be more robust during training.",
            "zh": "当我们将网络从 ReLU 切换到 Leaky ReLU 时，我们牺牲了稀疏表示在能量效率方面的潜在好处，以获得在训练期间可能更健壮的梯度。"
        }
    },
    {
        "translation": {
            "en": "SVM, 361",
            "zh": "支持向量机，361"
        }
    },
    {
        "translation": {
            "en": "Representation learning essentially tries to automatically extract new descriptive features from a dataset.",
            "zh": "表征学习本质上是尝试从数据集中自动提取新的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "9. Because Euclidean distance between any two points is symmetrical (dist(a,b) = dist(b,a)), we show only half of the distance matrix.",
            "zh": "9. 因为任何两点之间的欧几里得距离是对称的（dist（a，b） = dist（b，a）），所以我们只显示距离矩阵的一半。"
        }
    },
    {
        "translation": {
            "en": "As part of a natural language processing project, a company is creating a dictionary of idiomatic phrases.27 The company has used an automatic process to extract a set of 50,000 candidate idioms from a large corpus and now are planning to use a machine learning model to filter this set of candidates before presenting them to a human annotator who decides whether a candidate phrase should be added to the dictionary or not.",
            "zh": "作为自然语言处理项目的一部分，一家公司正在创建一本惯用短语词典.27 该公司使用自动过程从大型语料库中提取一组 50,000 个候选习语，现在正计划使用机器学习模型来过滤这组候选习语，然后再将它们呈现给人工注释者，由人工注释者决定是否应将候选短语添加到词典中。"
        }
    },
    {
        "translation": {
            "en": "Using the CRISP-DM process improves the likelihood that predictive data analytics projects will be successful, and we recommend its use.",
            "zh": "使用 CRISP-DM 流程可以提高预测数据分析项目成功的可能性，我们建议使用它。"
        }
    },
    {
        "translation": {
            "en": "This chapter moved away from the supervised machine learning techniques for training predictive models discussed in the rest of the book to focus on unsupervised machine learning.",
            "zh": "本章摒弃了本书其余部分讨论的用于训练预测模型的监督机器学习技术，转而关注无监督机器学习。"
        }
    },
    {
        "translation": {
            "en": "10.4.2   Evaluating Clustering",
            "zh": "10.4.2 评估聚类"
        }
    },
    {
        "translation": {
            "en": "13.11   The confusion matrix for the final logistic regression model on the large hold-out test set (classification accuracy: 87.979%, average class accuracy: 67.305%).",
            "zh": "13.11 大型保持测试集上最终逻辑回归模型的混淆矩阵（分类准确率：87.979%，平均类准确率：67.305%）。"
        }
    },
    {
        "translation": {
            "en": "action-value target network, 672",
            "zh": "动作值目标网络，672"
        }
    },
    {
        "translation": {
            "en": "The data listed in this table is real.",
            "zh": "此表中列出的数据是真实的。"
        }
    },
    {
        "translation": {
            "en": "The forward and backward pass is then carried out on each subsequence in turn: in the forward pass the network is unrolled over a subsequence, and in the backward pass the error gradients are backpropagated only through this truncated unrolled network.",
            "zh": "然后依次对每个子序列进行正向和向后传递：在前向传递中，网络在子序列上展开，而在向后传递中，误差梯度仅通过这个截断的展开网络进行反向传播。"
        }
    },
    {
        "translation": {
            "en": "4.5   Summary",
            "zh": "4.5 小结"
        }
    },
    {
        "translation": {
            "en": "3.6.3   Sampling",
            "zh": "3.6.3 抽样"
        }
    },
    {
        "translation": {
            "en": "Although in a neural network it is relatively straightforward to calculate the gradient of the error for neurons in the output layer by directly comparing the activations of these neurons with the expected outputs, it is not possible to directly compare the activation of a hidden neuron with the expected activation for that neuron, and so we cannot directly calculate an error gradient for hidden neurons.",
            "zh": "虽然在神经网络中，通过直接比较输出层中神经元的激活来计算输出层中神经元的误差梯度相对简单，但不可能直接将隐藏神经元的激活与该神经元的预期激活进行比较，因此我们不能直接计算隐藏神经元的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "(Model Selection)",
            "zh": "（型号选择）"
        }
    },
    {
        "translation": {
            "en": "4.4.5.1 Bagging When we use bagging (or bootstrap aggregating), each model in the ensemble is trained on a random sample25 of the dataset where, importantly, each random sample is the same size as the dataset, and sampling with replacement is used.",
            "zh": "4.4.5.1 装袋 当我们使用装袋（或引导聚合）时，集合中的每个模型都是在数据集的随机样本25上训练的，其中重要的是，每个随机样本的大小与数据集相同，并且使用带替换的采样。"
        }
    },
    {
        "translation": {
            "en": "This efficiency gain, however, is at the cost of the likely exclusion of interacting features.",
            "zh": "然而，这种效率的提高是以可能排除交互功能为代价的。"
        }
    },
    {
        "translation": {
            "en": "6.7 Exercises",
            "zh": "6.7 练习"
        }
    },
    {
        "translation": {
            "en": "The patience parameter is a predefined threshold (i.e., it is a hyper-parameter) that specifies the number of times in a row we will permit the error on the validation set to be higher than the lowest recorded so far before we stop training.",
            "zh": "耐心参数是一个预定义的阈值（即，它是一个超参数），它指定在停止训练之前，我们将允许验证集上的误差高于迄今为止记录的最低值的连续次数。"
        }
    },
    {
        "translation": {
            "en": "Table 3.3",
            "zh": "表 3.3"
        }
    },
    {
        "translation": {
            "en": "Line 4[326] of Algorithm 4[326] can therefore be rewritten as what is known as the weight update rule for multivariable linear regression with gradient descent",
            "zh": "因此，算法 4[326] 的第 4 行 [326] 可以改写为具有梯度下降的多变量线性回归的权重更新规则"
        }
    },
    {
        "translation": {
            "en": "Decision trees are induced by recursively partitioning the feature space into regions belonging to the different classes, and consequently they define a decision boundary by aggregating the neighboring regions belonging to the same class.",
            "zh": "决策树是通过递归地将特征空间划分为属于不同类的区域来诱导的，因此它们通过聚合属于同一类的相邻区域来定义决策边界。"
        }
    },
    {
        "translation": {
            "en": "RENT",
            "zh": "租金"
        }
    },
    {
        "translation": {
            "en": "Table 8.13[464] lists the power plant dataset after the target feature ELECTRICAL OUTPUT has been converted to a three-level categorical feature, by applying binning to the range-normalized values (low ≤ 0.33, medium ≤ 0.66, high > 0.66), and then encoded using one-hot encoding.",
            "zh": "表 8.13[464] 列出了将目标特征 ELECTRICAL OUTPUT 转换为三级分类特征后的发电厂数据集，方法是对范围归一化值（低≤ 0.33、中≤ 0.66、高> 0.66）进行分箱，然后使用单热编码进行编码。"
        }
    },
    {
        "translation": {
            "en": "The prediction problem in this case is to determine the dosage of a blood-thinning drug (in milligrams) that should be given to a patient in order to achieve a particular level of blood-thinning.",
            "zh": "在这种情况下，预测问题是确定应给予患者的血液稀释药物的剂量（以毫克为单位），以达到特定的血液稀释水平。"
        }
    },
    {
        "translation": {
            "en": "19. The length of a vector, |a|, is computed as the square root of the sum of the elements of the vector squared: .",
            "zh": "19. 向量的长度 |a|，计算为向量元素之和的平方根： 。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.4",
            "zh": "图 7.4"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a bar plot for the POLICY feature.",
            "zh": "（b） 绘制 POLICY 特征的条形图。"
        }
    },
    {
        "translation": {
            "en": "10. See Guisan and Zimmermann (2000) and Franklin (2009) for an introduction to uses of predictive analytics in ecological modeling.",
            "zh": "10. 参见 Guisan and Zimmermann （2000） 和 Franklin （2009） 关于预测分析在生态建模中的应用的介绍。"
        }
    },
    {
        "translation": {
            "en": "Doing this without the permission of the users of the app, however, would be in breach of this principle.",
            "zh": "但是，未经应用程序用户许可而这样做将违反此原则。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.2",
            "zh": "图 9.2"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the algorithm occurs in the for loop Lines 6[420] to 11[420].",
            "zh": "算法的前向传递发生在 for 循环行 6[420] 到 11[420] 中。"
        }
    },
    {
        "translation": {
            "en": "stationarity assumption, 234",
            "zh": "平稳性假设，234"
        }
    },
    {
        "translation": {
            "en": "Figure 10.4[606] illustrates this, showing other clusterings that are possible given different random initial cluster centroids for the mobile phone customer dataset presented in Table 10.1[604].",
            "zh": "图10.4[606]说明了这一点，显示了表10.1[604]中显示的移动电话客户数据集的不同随机初始聚类质心下可能的其他聚类。"
        }
    },
    {
        "translation": {
            "en": "Naturally occurring phenomena—for example, the heights or weights of a randomly selected group of men or women—tend to follow a normal distribution.",
            "zh": "自然发生的现象（例如，随机选择的一组男性或女性的身高或体重）往往遵循正态分布。"
        }
    },
    {
        "translation": {
            "en": "10.4.3   Choosing the Number of Clusters",
            "zh": "10.4.3 选择集群数量"
        }
    },
    {
        "translation": {
            "en": "then",
            "zh": "然后"
        }
    },
    {
        "translation": {
            "en": "Vanishing gradients are a serious challenge for training deep networks because the δs are the learning signal that tells each neuron how it should update its weights in order to improve the network’s performance on an example.",
            "zh": "梯度消失对于训练深度网络来说是一个严峻的挑战，因为δ是学习信号，它告诉每个神经元应该如何更新其权重，以提高网络的性能。"
        }
    },
    {
        "translation": {
            "en": "Because all the features in this example are binary, we need to store only the probabilities for the events where the features are true under the different combinations of values for the conditioning cases, as the probabilities for the complementary events can be computed by subtracting the stored probabilities from 1.0.",
            "zh": "由于此示例中的所有特征都是二进制的，因此我们只需要在条件情况的不同值组合下存储特征为真的事件的概率，因为互补事件的概率可以通过从 1.0 中减去存储的概率来计算。"
        }
    },
    {
        "translation": {
            "en": "In the same way we calculated cumulative gain, we can calculate lift cumulatively. The cumulative lift at decile dec is defined as",
            "zh": "以计算累积收益的方式相同，我们可以累积计算提升。十分位数 dec 的累积提升定义为"
        }
    },
    {
        "translation": {
            "en": "5.4   Extensions and Variations",
            "zh": "5.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "This point is at the global minimum of the error surface, and the coordinates of this point define the weights for the prediction model with the lowest sum of squared errors on the dataset.",
            "zh": "该点位于误差面的全局最小值处，该点的坐标定义了数据集上误差平方和最低的预测模型的权重。"
        }
    },
    {
        "translation": {
            "en": "However, using a k-d tree is not always appropriate; k-d trees are reasonably efficient when there are a lot more instances than there are features.",
            "zh": "但是，使用 k-d 树并不总是合适的;当实例数量远远多于特征时，K-D 树是相当有效的。"
        }
    },
    {
        "translation": {
            "en": "Player Medium (PM): 15 − 18",
            "zh": "玩家中等值 （PM）： 15 − 18"
        }
    },
    {
        "translation": {
            "en": "The game is tied if the dealer and the player have the same total, less than or equal to 22.",
            "zh": "如果庄家和玩家的总数相同，小于或等于 22，则游戏打成平手。"
        }
    },
    {
        "translation": {
            "en": "It should be corrected through a mapping to a standard set of levels, and the ABT should be regenerated.",
            "zh": "它应该通过映射到一组标准级别来校正，并且应该重新生成 ABT。"
        }
    },
    {
        "translation": {
            "en": "Both scores are set to zero because one of the conditional probabilities used to calculate them is zero.",
            "zh": "这两个分数都设置为零，因为用于计算它们的条件概率之一为零。"
        }
    },
    {
        "translation": {
            "en": "Applying a max function to a local receptive field is often referred to as max pooling.",
            "zh": "将 max 函数应用于局部感受野通常称为 max 池化。"
        }
    },
    {
        "translation": {
            "en": "7. Note that we have shortened feature names in these calculations to save space.",
            "zh": "7. 请注意，为了节省空间，我们在这些计算中缩短了特征名称。"
        }
    },
    {
        "translation": {
            "en": "Information Gain",
            "zh": "信息增益"
        }
    },
    {
        "translation": {
            "en": "Figure 10.10[617] illustrates this using three well-known simple two-dimensional artificial datasets: blobs, circles, and half-moons.",
            "zh": "图10.10[617]使用三个著名的简单二维人工数据集来说明这一点：斑点、圆圈和半月形。"
        }
    },
    {
        "translation": {
            "en": "Bentley, Jon Louis. 1975. Multidimensional binary search trees used for associative searching. Communications of the ACM 18 (9): 509–517. doi:10.1145/361002.361007.",
            "zh": "宾利，乔恩·路易斯。1975. 用于关联搜索的多维二叉搜索树.ACM 通讯 18 （9）：509–517。doi：10.1145/361002.361007."
        }
    },
    {
        "translation": {
            "en": "The strengths of these models, however, are that they are easy to interpret, they can handle different types of descriptive features, they are relatively robust to noise (when k is set appropriately), and they may be more robust to concept drift than models induced by eager learning algorithms.",
            "zh": "然而，这些模型的优势在于它们易于解释，它们可以处理不同类型的描述性特征，它们对噪声相对鲁棒（当 k 设置得当时），并且它们可能比渴望学习算法诱导的模型对概念漂移更鲁棒。"
        }
    },
    {
        "translation": {
            "en": "HEIGHT",
            "zh": "高度"
        }
    },
    {
        "translation": {
            "en": "By contrast, a naive Bayes model uses a very compact representation of a domain.",
            "zh": "相比之下，朴素贝叶斯模型使用非常紧凑的域表示。"
        }
    },
    {
        "translation": {
            "en": "So far in this chapter we have been initializing the bias terms and weights in our worked examples by sampling from a uniform distribution with a range of [−0.5,+0.5].",
            "zh": "到目前为止，在本章中，我们通过从范围为 [−0.5，+0.5] 的均匀分布中抽样来初始化工作示例中的偏差项和权重。"
        }
    },
    {
        "translation": {
            "en": "That a recurrent network contains cycles means that the output from a neuron at one time point may be fed back into the same neuron at another time point.",
            "zh": "循环网络包含周期意味着一个时间点的神经元输出可能会在另一个时间点反馈到同一个神经元。"
        }
    },
    {
        "translation": {
            "en": "So, relying solely on a stability index can lead to models being rebuilt when it is not required.",
            "zh": "因此，仅依赖稳定性指数可能会导致在不需要时重建模型。"
        }
    },
    {
        "translation": {
            "en": "But 𝕄w(d) = logistic(w ·d), so",
            "zh": "但是 Mw（d） = logistic（w ·d），所以"
        }
    },
    {
        "translation": {
            "en": "A dataset listing salary and age information for customers and whether they purchased a product.",
            "zh": "列出客户的工资和年龄信息以及他们是否购买了产品的数据集。"
        }
    },
    {
        "translation": {
            "en": "The only factor left unspecified was what the magnitude of that reduction was expected to be.",
            "zh": "唯一没有具体说明的因素是预计减少的幅度是多少。"
        }
    },
    {
        "translation": {
            "en": "—John Maynard Keynes",
            "zh": "——约翰·梅纳德·凯恩斯"
        }
    },
    {
        "translation": {
            "en": "Also, in general, it is not a good idea to select just one machine learning approach at the beginning of a project and to exclusively use that.",
            "zh": "此外，一般来说，在项目开始时只选择一种机器学习方法并专门使用它并不是一个好主意。"
        }
    },
    {
        "translation": {
            "en": "For example, a learning rate34 parameter, α, can be added to Equation (4.17)[164] to cause predictions of later errors to have less impact on the overall model than earlier ones, which makes models more robust to outliers.35",
            "zh": "例如，可以将学习率34参数α添加到方程（4.17）[164]中，以使对后期误差的预测对整个模型的影响小于早期误差，这使得模型对异常值更具鲁棒性35。"
        }
    },
    {
        "translation": {
            "en": "Both of these decompositions are valid, and both define different Bayesian networks for the domain. Figure 6.12(a)[291] illustrates the Bayesian network representing the decomposition defined in Equation (6.20)[291], and Figure 6.12(b)[291] illustrates the Bayesian network representing the decompositions defined in Equation (6.21)[291].",
            "zh": "这两种分解都是有效的，并且都为域定义了不同的贝叶斯网络。图6.12（a）[291]示出了表示等式（6.20）[291]中定义的分解的贝叶斯网络，图6.12（b）[291]示出了表示等式（6.21）[291]中定义的分解的贝叶斯网络。"
        }
    },
    {
        "translation": {
            "en": "To restate Equation (11.17)[651] using the components of an MDP we must explicitly represent the uncertainty associated with state transitions.",
            "zh": "为了使用MDP的组件重述方程（11.17）[651]，我们必须明确表示与状态转换相关的不确定性。"
        }
    },
    {
        "translation": {
            "en": "naive neural Q-learning, 671",
            "zh": "朴素的神经Q学习，671"
        }
    },
    {
        "translation": {
            "en": "To understand why Equation (8.67)[466] is an appropriate measure to use as the loss function for categorical training, we should first remember that the loss function is the function that we wish to minimize during training, and so we wish the loss function to return a large value when there is a large difference between the true and predicted probability distributions, and a small value when t and are similar or identical.",
            "zh": "为了理解为什么方程（8.67）[466]是用作分类训练损失函数的合适度量，我们首先应该记住，损失函数是我们希望在训练过程中最小化的函数，因此我们希望损失函数在真实和预测概率分布之间存在较大差异时返回一个大值， 当 t 和 相似或相同时，值很小。"
        }
    },
    {
        "translation": {
            "en": "Table 9.20[576] shows the expected target values for a test set, the predictions made by two different models (a multivariable linear regression model and a k-NN model), and the resulting errors based on these predictions (the additional error measures will be explained shortly).",
            "zh": "表9.20[576]显示了测试集的预期目标值、两个不同模型（多变量线性回归模型和k-NN模型）的预测，以及基于这些预测得出的误差（其他误差度量将在稍后解释）。"
        }
    },
    {
        "translation": {
            "en": "Once the relative likelihoods for each target level have been calculated, we simply return the maximum a posteriori (MAP) prediction.",
            "zh": "一旦计算了每个目标水平的相对似然，我们只需返回最大后验 （MAP） 预测。"
        }
    },
    {
        "translation": {
            "en": "Evaluation",
            "zh": "评估"
        }
    },
    {
        "translation": {
            "en": "Table 9.7[553]shows the structure of a profit matrix, which is the same as the structure of a confusion matrix.",
            "zh": "表9.7[553]显示了利润矩阵的结构，该结构与混淆矩阵的结构相同。"
        }
    },
    {
        "translation": {
            "en": "However, as the size of the dataset grows, particularly if the decision boundary between the classes is very complex, it may make more sense to allow the data to inform the predictions more directly.",
            "zh": "但是，随着数据集大小的增长，特别是如果类之间的决策边界非常复杂，则允许数据更直接地为预测提供信息可能更有意义。"
        }
    },
    {
        "translation": {
            "en": "The algorithm can, however, be extended to handle continuous descriptive features and continuous target features.",
            "zh": "但是，该算法可以扩展为处理连续描述性特征和连续目标特征。"
        }
    },
    {
        "translation": {
            "en": "We noted previously that we can often increase the learning rate α when using batch gradient descent.",
            "zh": "我们之前提到过，使用批量梯度下降时，我们通常可以提高学习率α。"
        }
    },
    {
        "translation": {
            "en": "3.3.3   Outliers",
            "zh": "3.3.3 异常值"
        }
    },
    {
        "translation": {
            "en": "Chapter",
            "zh": "章"
        }
    },
    {
        "translation": {
            "en": "Finally, decision trees are relatively easy to interpret, which means that the structure of the model can give some insight into customer behavior.",
            "zh": "最后，决策树相对容易解释，这意味着模型的结构可以对客户行为提供一些见解。"
        }
    },
    {
        "translation": {
            "en": "10.15   (a) A selection of images from the handwritten digits dataset; (b)–(d) image reconstructions generated by the auto-encoder network after 0, 10, and 1,000 training epochs.",
            "zh": "10.15 （a） 从手写数字数据集中选出的图像;（b）–（d） 自动编码器网络在 0、10 和 1,000 个训练周期后生成的图像重建。"
        }
    },
    {
        "translation": {
            "en": "In all three figures, B and C are equidistant from A based on Euclidean distance.",
            "zh": "在所有三个图形中，基于欧几里得距离，B 和 C 与 A 等距。"
        }
    },
    {
        "translation": {
            "en": "Now, when updating the value for Q(0-3,left), the Q value for this action, down, from the next state is used rather than the Q value for the best possible action, left, that was used in Q-learning.",
            "zh": "现在，在更新 Q（0-3，left） 的值时，将使用此操作的 Q 值（从下一个状态向下），而不是在 Q 学习中使用的最佳可能操作（左）的 Q 值。"
        }
    },
    {
        "translation": {
            "en": "We use an error function to measure how well a set of weights fits the relationship in the training data.",
            "zh": "我们使用误差函数来衡量一组权重与训练数据中关系的拟合程度。"
        }
    },
    {
        "translation": {
            "en": "The model evaluations based on misclassification rate described in the previous section are the first step in evaluating the performance of the prediction model created.",
            "zh": "基于上一节所述的错误分类率的模型评估是评估所创建的预测模型性能的第一步。"
        }
    },
    {
        "translation": {
            "en": "Table 14.1",
            "zh": "表 14.1"
        }
    },
    {
        "translation": {
            "en": "MARGINALADHESION: A measure of how much cells in the biopsy stick together (1 to 10).",
            "zh": "边缘粘附：测量活检中有多少细胞粘在一起（1 到 10）。"
        }
    },
    {
        "translation": {
            "en": "In summary, non-normalized descriptive features can result in unstable or slow learning and a more unstable model in relation to generalization.",
            "zh": "总之，非规范化的描述性特征会导致学习不稳定或缓慢，并且与泛化相关的模型更不稳定。"
        }
    },
    {
        "translation": {
            "en": "The Jaccard similarity index is often used in these contexts.",
            "zh": "Jaccard 相似性索引通常用于这些上下文。"
        }
    },
    {
        "translation": {
            "en": "However, although its derivative is simple, that it has a max value of 0.25 contributes to the vanishing gradient problem in neural networks.",
            "zh": "然而，尽管它的导数很简单，但它的最大值为 0.25 导致了神经网络中梯度消失的问题。"
        }
    },
    {
        "translation": {
            "en": "Overall there is a general trend that deeper networks have better performance than shallower networks, and that deeper networks are often more efficient in terms of the number of neurons they require.",
            "zh": "总体而言，有一个普遍的趋势，即更深的网络比较浅的网络具有更好的性能，并且更深的网络在所需的神经元数量方面通常更有效。"
        }
    },
    {
        "translation": {
            "en": "Choosing a good filter size for a given dataset often involves a trial-and-error process of experimenting with different options.",
            "zh": "为给定数据集选择一个好的过滤器大小通常涉及试验不同选项的试错过程。"
        }
    },
    {
        "translation": {
            "en": "The ROC index or area under the curve (AUC) measures the area underneath an ROC curve.",
            "zh": "ROC 指数或曲线下面积 （AUC） 衡量 ROC 曲线下方的面积。"
        }
    },
    {
        "translation": {
            "en": "A model able to distinguish between instances that are very close to the boundary and those that are farther away would be preferable.",
            "zh": "一个能够区分非常接近边界的实例和那些距离较远的实例的模型会更可取。"
        }
    },
    {
        "translation": {
            "en": "This exponential growth rate is partially due to the fact that a full joint probability distribution ignores the structural relationships between features, such as direct influence and conditional independence relationships.",
            "zh": "这种指数增长率部分是由于完全联合概率分布忽略了特征之间的结构关系，例如直接影响和条件独立关系。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5(b)[38] illustrates how the observation and outcome period for multiple customers are measured over the same period.",
            "zh": "图2.5（b）[38]说明了如何在同一时期内测量多个客户的观察期和结果期。"
        }
    },
    {
        "translation": {
            "en": "Despite the lack of any instances that perfectly match the evidence, the fact that we were still able to calculate a score for each target level and make a prediction for the query highlights how the conditional independence assumption between the evidence given the target level both increases the coverage of the model and allows the model to generalize beyond the data used to induce it.",
            "zh": "尽管缺乏任何与证据完全匹配的实例，但我们仍然能够计算每个目标水平的分数并对查询进行预测，这一事实突出了给定目标水平的证据之间的条件独立性假设如何增加模型的覆盖范围，并允许模型在用于诱导它的数据之外进行推广。"
        }
    },
    {
        "translation": {
            "en": "In some cases a lack of appropriate data will simply rule out proposed analytics solutions to a business problem.",
            "zh": "在某些情况下，缺乏适当的数据只会排除针对业务问题的拟议分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "Specifically, if the value of one feature directly influences, or causes, the value taken by another feature, then this should be reflected in the structure of the graph by having a link from the cause feature to the effect feature.",
            "zh": "具体而言，如果一个特征的值直接影响或导致另一个特征所获取的值，则应通过从原因特征到结果特征的链接来反映在图形结构中。"
        }
    },
    {
        "translation": {
            "en": "This involves an analysis of the needs of the business, the data we have available for use, and the capacity of the business to use analytics.",
            "zh": "这涉及对业务需求、我们可供使用的数据以及业务使用分析的能力的分析。"
        }
    },
    {
        "translation": {
            "en": "(b) On the basis of the clustering calculated in Part (a), calculate a set of new cluster centroids.",
            "zh": "（b） 根据（a）部分计算的聚类，计算一组新的聚类质心。"
        }
    },
    {
        "translation": {
            "en": "If, on the other hand, the target feature is categorical, then information-based and probability-based approaches are likely to work very well.",
            "zh": "另一方面，如果目标特征是分类的，那么基于信息和基于概率的方法可能会非常有效。"
        }
    },
    {
        "translation": {
            "en": "linkage method, 618",
            "zh": "联动方式，618"
        }
    },
    {
        "translation": {
            "en": "There is a simple, well-known mathematical model that can capture the relationship between two continuous features like those in our dataset. Many readers will remember from high school geometry that the equation of a line can be written",
            "zh": "有一个简单、众所周知的数学模型可以捕获两个连续特征之间的关系，就像我们数据集中的特征一样。许多读者会记得高中几何学中可以写出一条线的方程"
        }
    },
    {
        "translation": {
            "en": "Modeling points in time for a scenario with no real observation period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "对没有实际观测期的场景的时间点进行建模（每条线代表一个客户，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "variable elimination, 298",
            "zh": "变量消除，298"
        }
    },
    {
        "translation": {
            "en": "8.4.6.1 Simple recurrent neural networks A simple recurrent neural network architecture is a feedforward architecture with one hidden layer that has been extended with a memory buffer that is used to store the activations from the hidden layer for one time-step.",
            "zh": "8.4.6.1 简单的递归神经网络 简单的递归神经网络架构是一种前馈架构，具有一个隐藏层，该隐藏层已使用内存缓冲区进行扩展，该内存缓冲区用于存储隐藏层的激活一个时间步长。"
        }
    },
    {
        "translation": {
            "en": "In Section 6.2[245] we described how a full joint probability distribution could be used to compute the probability for any event in a domain.",
            "zh": "在第 6.2 节[245]中，我们描述了如何使用完整的联合概率分布来计算域中任何事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Then working backward in a layer-by-layer manner, the δ for the hidden neurons are calculated using Equation (8.23)[412].",
            "zh": "然后以逐层方式向后工作，使用公式（8.23）[412]计算隐藏神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "This would, however, ignore the fact that sometimes reward is delayed and that taking an action that gives a low immediate reward can be a good idea if it leads the agent to a state that could give it large positive rewards later on.",
            "zh": "然而，这将忽略这样一个事实，即有时奖励是延迟的，如果它导致代理进入一个可以在以后给它带来大量积极奖励的状态，那么采取一个立即奖励较低的行动可能是一个好主意。"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for elliptical galaxy category",
            "zh": "椭圆星系类别的得票分数"
        }
    },
    {
        "translation": {
            "en": "Histograms of a selection of features from the SDSS dataset.",
            "zh": "SDSS 数据集中所选要素的直方图。"
        }
    },
    {
        "translation": {
            "en": "This empty partition will result in a leaf node that returns a prediction of the majority target level in 8, chapparal.",
            "zh": "这个空分区将产生一个叶节点，该节点返回对 8 chapparal 中多数目标水平的预测。"
        }
    },
    {
        "translation": {
            "en": "Table 10.5",
            "zh": "表 10.5"
        }
    },
    {
        "translation": {
            "en": "where q and d are two instances, |q| is the total number of features in the dataset, and CP(q,d) measures the total number of co-presences between q and d. Using Russel-Rao, q has a higher similarity to d1 than to d2:",
            "zh": "其中 q 和 d 是两个实例，|q|是数据集中的特征总数，CP（q，d） 测量 q 和 d 之间的共存总数。 使用 Russel-Rao，q 与 d1 的相似度高于与 d2 的相似度："
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset.",
            "zh": "（a） 写字楼租赁数据集中 SIZE 和 RENTAL PRICE 特征的散点图。"
        }
    },
    {
        "translation": {
            "en": "7.3 Standard Approach: Multivariable Linear Regression with Gradient Descent",
            "zh": "7.3 标准方法：梯度下降的多变量线性回归"
        }
    },
    {
        "translation": {
            "en": "Derived descriptive features do not exist in any raw data source, so they must be constructed from data in one or more raw data sources.",
            "zh": "派生的描述性特征在任何原始数据源中都不存在，因此必须根据一个或多个原始数据源中的数据构造它们。"
        }
    },
    {
        "translation": {
            "en": "Second, as the number of basis functions grows beyond the number of descriptive features, the complexity of our models increases, so the gradient descent process must search through a more complex weight space.",
            "zh": "其次，随着基函数的数量超过描述性特征的数量，我们模型的复杂性增加，因此梯度下降过程必须搜索更复杂的权重空间。"
        }
    },
    {
        "translation": {
            "en": "The calculation of the softmax activations for each of the neurons in the output layer for each example in the mini-batch, and the calculation of the δ for each neuron in the output layer for each example in the mini-batch.",
            "zh": "计算小批量中每个示例的输出层中每个神经元的 softmax 激活次数，以及计算小批量中每个示例的输出层中每个神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "Table 5.5[204] lists a sample from this dataset.",
            "zh": "表5.5[204]列出了该数据集中的一个样本。"
        }
    },
    {
        "translation": {
            "en": "The main challenge was a return to the Data Preparation phase to make the routines used to extract the data for the ABT robust and reliable enough to be used to generate new query instances every month.",
            "zh": "主要挑战是返回数据准备阶段，使用于提取 ABT 数据的例程足够强大和可靠，以便每月生成新的查询实例。"
        }
    },
    {
        "translation": {
            "en": "Which of the two descriptive features should we use as the testing criterion at the root node of a decision tree to predict students’ scores?",
            "zh": "我们应该使用两个描述性特征中的哪一个作为决策树根节点的测试标准来预测学生的分数？"
        }
    },
    {
        "translation": {
            "en": "The node is not NULL, so the while loop on Line 4 succeeds.",
            "zh": "节点不为 NULL，因此第 4 行上的 while 循环成功。"
        }
    },
    {
        "translation": {
            "en": "4.1   Cards showing character faces and names for the Guess Who game.",
            "zh": "4.1 显示猜猜谁游戏角色面孔和名字的卡片。"
        }
    },
    {
        "translation": {
            "en": "3.9 Exercises",
            "zh": "3.9 练习"
        }
    },
    {
        "translation": {
            "en": "Fortunately, there is an easy calculation that can be made from the ROC curve that achieves this.",
            "zh": "幸运的是，可以从 ROC 曲线进行简单的计算来实现这一点。"
        }
    },
    {
        "translation": {
            "en": "One common approach to evaluating clustering is to use an internal criterion to evaluate how well the clustering found by an algorithm matches some idealized notion of what a good clustering would look like.",
            "zh": "评估聚类的一种常用方法是使用内部标准来评估算法发现的聚类与良好聚类的理想化概念的匹配程度。"
        }
    },
    {
        "translation": {
            "en": "There are four descriptive features and one target feature in this dataset, as follows:",
            "zh": "该数据集中有四个描述性特征和一个目标特征，如下所示："
        }
    },
    {
        "translation": {
            "en": "Figure 6.8[279] shows the histograms of the values of the ACCOUNT BALANCE feature partitioned on the two levels of the FRAUD target feature.",
            "zh": "图 6.8[279] 显示了在 FRAUD 目标特征的两个级别上划分的 ACCOUNT BALANCE 特征值的直方图。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.1",
            "zh": "图 8.1"
        }
    },
    {
        "translation": {
            "en": "Furthermore, large weight updates can result in instability in model training.",
            "zh": "此外，较大的权重更新会导致模型训练的不稳定性。"
        }
    },
    {
        "translation": {
            "en": "—Sam Walton",
            "zh": "——山姆·沃尔顿"
        }
    },
    {
        "translation": {
            "en": "4.4.1 Alternative Feature Selection and Impurity Metrics",
            "zh": "4.4.1 替代特征选择和杂质指标"
        }
    },
    {
        "translation": {
            "en": "A.4 Data Visualization",
            "zh": "A.4 数据可视化"
        }
    },
    {
        "translation": {
            "en": "This transformation from a joint probability conditioned on a single event into a product of conditional probabilities with just one event being conditioned in each term may not appear to achieve much. We will see shortly, however, that this transformation is incredibly useful.",
            "zh": "这种从以单个事件为条件的联合概率到条件概率的乘积（每个项中只有一个事件被条件条件）的转变似乎并没有取得多大成就。然而，我们很快就会看到，这种转变是非常有用的。"
        }
    },
    {
        "translation": {
            "en": "In this case the median value of 0.0 (shown in Table 3.3(a)[57]) is the most appropriate value to use to replace the missing values; because this feature only actually takes discrete values, the mean value of 0.2 never naturally occurs in the dataset.",
            "zh": "在这种情况下，中值 0.0（如表 3.3（a）[57] 所示）是用于替换缺失值的最合适值;由于此特征实际上仅采用离散值，因此 0.2 的平均值永远不会自然地出现在数据集中。"
        }
    },
    {
        "translation": {
            "en": "11.3   Standard Approach: Q-Learning, Off-Policy Temporal-Difference Learning",
            "zh": "11.3 标准方法：Q-学习、非政策时间差异学习"
        }
    },
    {
        "translation": {
            "en": "In many cases, however, it does not make sense to consider one target level as being more important.",
            "zh": "然而，在许多情况下，将一个目标级别视为更重要是没有意义的。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.11",
            "zh": "图 7.11"
        }
    },
    {
        "translation": {
            "en": "Each neuron in a sub-sampling layer has a local receptive field in a feature map generated by the previous layer, which will have convolved a filter over the input to that layer.",
            "zh": "子采样层中的每个神经元在前一层生成的特征图中都有一个局部感受野，该特征图将在该层的输入上卷积一个滤波器。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.19",
            "zh": "图 5.19"
        }
    },
    {
        "translation": {
            "en": "Exponential or skewed distributions in histograms are also good indicators of the presence of outliers.",
            "zh": "直方图中的指数分布或偏态分布也是异常值存在的良好指标。"
        }
    },
    {
        "translation": {
            "en": "ordinal data, 34",
            "zh": "序数数据，34"
        }
    },
    {
        "translation": {
            "en": "The sum of all the cells in a joint probability distribution must be 1.0.",
            "zh": "联合概率分布中所有单元格的总和必须为 1.0。"
        }
    },
    {
        "translation": {
            "en": "As learning continues, however, values start to propagate across the states in the environment on subsequent episodes.",
            "zh": "然而，随着学习的继续，价值观在随后的情节中开始在环境中的各个州传播。"
        }
    },
    {
        "translation": {
            "en": "(c) P(HEADACHE = true,VOMITING = false)",
            "zh": "（c） P（头痛 = 真，呕吐 = 假）"
        }
    },
    {
        "translation": {
            "en": "-1.0836",
            "zh": "-1.0836"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39[506] also shows how often each weight matrix was used in the generation of each output.",
            "zh": "图8.39[506]还显示了在生成每个输出时使用每个权重矩阵的频率。"
        }
    },
    {
        "translation": {
            "en": "Mitchell, Tom M., Svetlana V. Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L. Malave, Robert A. Mason, and Marcel A. Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science 320 (5880): 1191–1195. doi:10.1126/science.1152876.",
            "zh": "Mitchell、Tom M.、Svetlana V. Shinkareva、Andrew Carlson、Kai-Min Chang、Vicente L. Malave、Robert A. Mason 和 Marcel A. Just。2008. 预测与名词含义相关的人脑活动.科学320（5880）：1191-1195。doi：10.1126/science.1152876."
        }
    },
    {
        "translation": {
            "en": "The second thing that the examples listed have in common is that a model is trained to make predictions based on a set of historical examples.",
            "zh": "列出的示例的第二个共同点是，模型经过训练，可以根据一组历史示例进行预测。"
        }
    },
    {
        "translation": {
            "en": "Ranking the models by profit, we are able to take this into account, which is impossible using classification accuracy or average class accuracy.",
            "zh": "按利润对模型进行排名，我们能够考虑到这一点，这使用分类精度或平均类精度是不可能的。"
        }
    },
    {
        "translation": {
            "en": "A line along the diagonal of ROC space from (0,0) to (1,0), shown as a dotted line in Figure 9.12(a)[562], is a reference line representing the expected performance of a model that makes random predictions.",
            "zh": "从（0,0）到（1,0）沿ROC空间对角线的一条线，在图9.12（a）[562]中显示为虚线，是表示进行随机预测的模型的预期性能的参考线。"
        }
    },
    {
        "translation": {
            "en": "where Parents(xi) describes the set of nodes in the graph that directly link into node xi. Using this equation, we can compute any joint event in the domain represented by the Bayesian network. For example, using the slightly more complex Bayesian network in Figure 6.9(b)[287], we can calculate the probability of the joint event P(a,¬b,¬c,d) as",
            "zh": "其中 Parents（习） 描述图中直接链接到节点 习 的节点集。使用这个方程，我们可以计算贝叶斯网络表示的域中的任何联合事件。例如，使用图6.9（b）[287]中稍微复杂的贝叶斯网络，我们可以计算联合事件P（a，¬b，¬c，d）的概率为："
        }
    },
    {
        "translation": {
            "en": "34. This is a naive assumption because we are making it to simplify the discussion irrespective of whether or not it is true.",
            "zh": "34. 这是一个幼稚的假设，因为我们这样做是为了简化讨论，而不管它是否属实。"
        }
    },
    {
        "translation": {
            "en": "6. Learning a general rule from a finite set of examples is called inductive learning. This is why machine learning is sometimes described as inductive learning, and the set of assumptions used by the machine algorithm that biases it toward selecting a single model is called the inductive bias of the algorithm.",
            "zh": "6. 从一组有限的例子中学习一般规则称为归纳学习。这就是为什么机器学习有时被描述为归纳学习，而机器算法使用的偏向于选择单个模型的一组假设称为算法的归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "That the neurons in this network use a linear activation function means that var(Z(HL1)) is also the variance of the activations propagated forward to the next hidden layer, and so it is also the variance of the inputs to the next layer: var(Z(HL1)) = var(A(HL1)) = var(d(HL2)).",
            "zh": "该网络中的神经元使用线性激活函数意味着 var（Z（HL1）） 也是向前传播到下一个隐藏层的激活的方差，因此它也是下一层输入的方差：var（Z（HL1）） = var（A（HL1）） = var（d（HL2））。"
        }
    },
    {
        "translation": {
            "en": "14. Figure 5.12(a)[205] further misleads us because when we draw scatter plots, we scale the values to make the plot fit into a square-shaped image. If we were to plot the axis for the SALARY feature to the same scale as the AGE feature in Figure 5.12(a)[205], it would stretch over almost 400 pages.",
            "zh": "14. 图5.12（a）[205]进一步误导了我们，因为当我们绘制散点图时，我们会缩放这些值以使图适合正方形图像。如果我们将 SALARY 特征的轴绘制到与图 5.12（a）[205] 中的 AGE 特征相同的比例，它将延伸近 400 页。"
        }
    },
    {
        "translation": {
            "en": "Another well-known variant of the ID3 algorithm is the CART algorithm.",
            "zh": "ID3 算法的另一个著名变体是 CART 算法。"
        }
    },
    {
        "translation": {
            "en": "∂ℰ/∂w4,0, ∂ℰ/∂w3,2, ∂ℰ/∂w3,1, ∂ℰ/∂w3,0).",
            "zh": "∂E/∂w4,0、∂E/∂w3,2、∂E/∂w3,1、∂E/∂w3,0）。"
        }
    },
    {
        "translation": {
            "en": "The end result of clustering is a single new generated feature that indicates the cluster that an instance belongs to, and the generation of this new feature is typically the end goal of the clustering task.",
            "zh": "聚类的最终结果是单个新生成的特征，该特征指示实例所属的聚类，生成此新特征通常是聚类任务的最终目标。"
        }
    },
    {
        "translation": {
            "en": "TD(0), 655",
            "zh": "TD（0）， 655"
        }
    },
    {
        "translation": {
            "en": "There were two fundamental problems with how Literary Digest collected its sample, and the result of both was that the sample used for prediction (the survey responses) was not representative of the overall population.",
            "zh": "《文学文摘》收集样本的方式存在两个基本问题，两者的结果是用于预测的样本（调查回复）不能代表总体人口。"
        }
    },
    {
        "translation": {
            "en": "For categorical features, we use a specific typography to indicate the levels in the domain of the feature when referring to a feature by name in the text (e.g., center, aa, and soft tissue).",
            "zh": "对于分类特征，当在文本中按名称引用特征时，我们使用特定的排版来指示特征域中的级别（例如，中心、aa 和软组织）。"
        }
    },
    {
        "translation": {
            "en": "19.31",
            "zh": "19.31"
        }
    },
    {
        "translation": {
            "en": "More recently, Leshno et al.",
            "zh": "最近，Leshno 等人。"
        }
    },
    {
        "translation": {
            "en": "The player and dealer are initially each dealt two cards.",
            "zh": "玩家和庄家最初各发两张牌。"
        }
    },
    {
        "translation": {
            "en": "This backward pass gives the network its name: backpropagation.",
            "zh": "这种向后传递使网络得名：反向传播。"
        }
    },
    {
        "translation": {
            "en": "natural language processing, 234",
            "zh": "自然语言处理，234"
        }
    },
    {
        "translation": {
            "en": "inter-cluster distance, 608",
            "zh": "集群间距离，608"
        }
    },
    {
        "translation": {
            "en": "Hand, David J., and Christoforos Anagnostopoulos. 2013. When is the area under the receiver operating characteristic curve an appropriate measure of classifier performance? Pattern Recognition Letters 34 (5): 492–495.",
            "zh": "Hand、David J. 和 Christoforos Anagnostopoulos。2013. 何时，受试者工作特征曲线下的面积是分级器性能的适当衡量标准？模式识别快报34（5）：492–495。"
        }
    },
    {
        "translation": {
            "en": "backpropagation through time, 502, 518",
            "zh": "随时间反向传播，502,518"
        }
    },
    {
        "translation": {
            "en": "8.12   The ReLU network’s per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "8.12 ReLU 网络每个示例的预测、误差和训练后的平方误差之和收敛到 SSE < 0.0001。"
        }
    },
    {
        "translation": {
            "en": "The activations for the other three neurons using this filter would be calculated in a similar way, resulting in the following feature map being generated by this 2-by-2 layer of neurons:",
            "zh": "使用此过滤器的其他三个神经元的激活将以类似的方式计算，从而由此 2×2 神经元层生成以下特征图："
        }
    },
    {
        "translation": {
            "en": "perceptron, 396",
            "zh": "感知器，396"
        }
    },
    {
        "translation": {
            "en": "The outliers shown in box plots also help to make this comparison.",
            "zh": "箱形图中显示的异常值也有助于进行此比较。"
        }
    },
    {
        "translation": {
            "en": "8.22   The architecture of the neural network used in the weight initialization experiments. Note that the neurons in this network use a linear activation function: ai = zi.",
            "zh": "8.22 权重初始化实验中使用的神经网络架构。请注意，该网络中的神经元使用线性激活函数：ai = zi。"
        }
    },
    {
        "translation": {
            "en": "However, if the neurons in the early layers of the network take a long time to train, then the neurons in the later layers cannot efficiently build upon the outputs of these early neurons.",
            "zh": "然而，如果网络早期层的神经元需要很长时间来训练，那么后期层的神经元就无法有效地建立在这些早期神经元的输出之上。"
        }
    },
    {
        "translation": {
            "en": "simple multivariable linear regression, 367",
            "zh": "简单多变量线性回归，367"
        }
    },
    {
        "translation": {
            "en": "Using basis functions is an interesting way to change the inductive bias, in particular the restriction bias, encoded in the gradient descent algorithm for learning regression models.",
            "zh": "使用基函数是改变归纳偏差的一种有趣方法，特别是限制偏差，编码在梯度下降算法中，用于学习回归模型。"
        }
    },
    {
        "translation": {
            "en": "The most popular strategy to define a convergence criterion to stop training a neural network is early stopping.",
            "zh": "定义收敛标准以停止训练神经网络的最流行策略是早期停止。"
        }
    },
    {
        "translation": {
            "en": "From each smaller group, we then create a sample containing that number of instances.",
            "zh": "然后，我们从每个较小的组中创建一个包含该数量实例的样本。"
        }
    },
    {
        "translation": {
            "en": "The posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false.",
            "zh": "GUARANTOR/COAPPLICANT 特征在 FRAUD = false 条件下的后验概率分布。"
        }
    },
    {
        "translation": {
            "en": "box plot, 54, 451, 745, 752, 755",
            "zh": "箱形地块， 54， 451， 745， 752， 755"
        }
    },
    {
        "translation": {
            "en": "Loan default prediction is an example where the definition of the target feature has a time element but the descriptive features are time independent.",
            "zh": "贷款违约预测是一个示例，其中目标特征的定义具有时间元素，但描述性特征与时间无关。"
        }
    },
    {
        "translation": {
            "en": "2.1 Converting Business Problems into Analytics Solutions",
            "zh": "2.1 将业务问题转化为分析解决方案"
        }
    },
    {
        "translation": {
            "en": "ME1_U/G/R/I/Z",
            "zh": "ME1_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "the bias imposed on a generative model can become larger than the error of the trained model.",
            "zh": "施加在生成模型上的偏差可能大于训练模型的误差。"
        }
    },
    {
        "translation": {
            "en": "The histograms for each continuous feature included in a data quality report are a very easy way for us to understand how the values for a feature are distributed across the range they can take.2 When we generate histograms of features, there are a number of common, well-understood shapes that we should look out for.",
            "zh": "数据质量报告中包含的每个连续特征的直方图是一种非常简单的方法，可以让我们了解特征的值如何在它们可以采用的范围内分布。2 当我们生成特征的直方图时，我们应该注意许多常见的、易于理解的形状。"
        }
    },
    {
        "translation": {
            "en": "Finding a good equilibrium for a given prediction task involves experimenting with different architectures to see which performs best.",
            "zh": "为给定的预测任务找到良好的平衡需要尝试不同的架构，看看哪种架构表现最好。"
        }
    },
    {
        "translation": {
            "en": "If the performance changes significantly, this is a strong indication that concept drift has occurred and that the model has gone stale.",
            "zh": "如果性能发生重大变化，则强烈表明发生了概念漂移，并且模型已经过时。"
        }
    },
    {
        "translation": {
            "en": "6.2.1 Bayes’ Theorem",
            "zh": "6.2.1 贝叶斯定理"
        }
    },
    {
        "translation": {
            "en": "Glorot, Xavier, and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (AISTATS), 249–256. JMLR.",
            "zh": "格洛罗特、泽维尔和约书亚·本吉奥。2010. 了解训练深度前馈神经网络的难度.第十三届人工智能与统计国际会议（AISTATS）论文集，第249-256页。JMLR。"
        }
    },
    {
        "translation": {
            "en": "In a full network training scenario there would be many such weight updates as the training progressed through multiple epochs and, for each epoch, multiple mini-batches; the reduction of the network error would accumulate over these weight updates.",
            "zh": "在完整的网络训练场景中，随着训练经过多个周期的进展，并且对于每个周期，会有多个小批量的权重更新;网络误差的减少将累积在这些权重更新中。"
        }
    },
    {
        "translation": {
            "en": "So, m will denote the event MENINGITIS = true and ¬m will denote MENINGITIS = false.",
            "zh": "因此，m 表示事件 MENINGITIS = true，¬m 表示 MENINGITIS = false。"
        }
    },
    {
        "translation": {
            "en": "As we see when we discuss the vanishing gradient problem, adding depth to a network can slow down the rate at which a network learns.",
            "zh": "正如我们在讨论梯度消失问题时所看到的，增加网络的深度会减慢网络的学习速度。"
        }
    },
    {
        "translation": {
            "en": "The δ for a neuron in the last hidden layer is calculated by summing the portions of the δs backpropagated to it from all the neurons in the output layer that it connects to.",
            "zh": "最后一个隐藏层中神经元的δ是通过将它所连接的输出层中所有神经元反向传播到它的 δ 部分相加来计算的。"
        }
    },
    {
        "translation": {
            "en": "To investigate this idea, she generated SPLOM charts for different photometric band versions of a selection of columns from the dataset (see Figure 13.5[714]), and these showed significant relationships, which confirmed her suspicion.",
            "zh": "为了研究这个想法，她为数据集中选择的列的不同光度波段版本生成了SPLOM图表（见图13.5[714]），这些图表显示出显着的关系，这证实了她的怀疑。"
        }
    },
    {
        "translation": {
            "en": "This new node indexes d21, which is not NULL, so the while loop on Line 4 succeeds.",
            "zh": "这个新节点索引 d21，它不是 NULL，因此第 4 行上的 while 循环成功。"
        }
    },
    {
        "translation": {
            "en": "7. We have already discussed the derivative of the logistic function in Chapter 7[311] (see Equation (7.28)[345]); we rewrite it here using z in place of x for convenience.",
            "zh": "7. 我们已经在第7章[311]中讨论了逻辑函数的导数（见方程（7.28）[345]）;为了方便起见，我们在这里用 z 代替 x 重写它。"
        }
    },
    {
        "translation": {
            "en": "The reason is that we have been focusing on processing a grayscale image that is a two-dimensional input.",
            "zh": "原因是我们一直专注于处理作为二维输入的灰度图像。"
        }
    },
    {
        "translation": {
            "en": "Therefore, Δwi,k is the error gradient for weight wi,k for one epoch.",
            "zh": "因此，Δwi，k 是一个纪元的权重 wi，k 的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2(a)[316] shows a scatter plot of the SIZE and RENTAL PRICE descriptive features from the office rentals dataset and a number of different simple linear regression models that might be used to capture this relationship.",
            "zh": "图7.2（a）[316]显示了来自办公室租赁数据集的SIZE和RENTAL PRICE描述性特征的散点图，以及可用于捕获这种关系的许多不同的简单线性回归模型。"
        }
    },
    {
        "translation": {
            "en": "EXPMAGERR_U/G/R/I/Z",
            "zh": "EXPMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "dendrogram, 622",
            "zh": "树状图，622"
        }
    },
    {
        "translation": {
            "en": "8. Advanced features of Blackjack, like doubling down, insurance, and splitting pairs, are not allowed in our TwentyTwos game.",
            "zh": "8. 二十一点的高级功能，如加倍、保险和拆分对子，在我们的 TwentyTwos 游戏中是不允许的。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.14",
            "zh": "图 5.14"
        }
    },
    {
        "translation": {
            "en": "The effect of these negative weights is apparent in the Z(1) matrix in forward pass of the mini-batch through the ReLU network in Figure 8.18[440]: for all four examples of the mini-batch z 4 < 0, and hence a4 = 0.",
            "zh": "这些负权重的影响在图 8.18[440] 中小批量通过 ReLU 网络的前向传递的 Z（1） 矩阵中很明显：对于小批量的所有四个示例，z 4 < 0，因此 a4 = 0。"
        }
    },
    {
        "translation": {
            "en": "32. A violin plot is a box plot that has been augmented to show the probability density of a data at different values in the range. The use of violin plots to illustrate the variance across layers within a network was inspired by a blog post by Daniel Godoy (see https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404).",
            "zh": "32. 小提琴图是一种箱形图，经过扩充以显示范围内不同值的数据的概率密度。使用小提琴图来说明网络内各层之间的差异的灵感来自丹尼尔·戈多伊（Daniel Godoy）的一篇博客文章（见 https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404）。"
        }
    },
    {
        "translation": {
            "en": "return, 640",
            "zh": "回程， 640"
        }
    },
    {
        "translation": {
            "en": "Second, Figure 8.24(d)[454] shows that the network now has an exploding gradient dynamic during backpropagation, with the variance of δ values rapidly increasing as they are backpropagated through the network.",
            "zh": "其次，图8.24（d）[454]显示，网络在反向传播过程中具有爆炸性的梯度动态，δ值的方差随着它们通过网络的反向传播而迅速增加。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38[504] provides a graphical representation of a recurrent neural network unrolled through three time-steps.48 The subscripts on the x, h, and y layer labels indicate that these layers have a different state at each time-step.",
            "zh": "图 8.38[504] 提供了通过三个时间步长展开的循环神经网络的图形表示.48 x、h 和 y 层标签上的下标表示这些层在每个时间步长具有不同的状态。"
        }
    },
    {
        "translation": {
            "en": "8.4.3 Handling Categorical Target Features: Softmax Output Layers and Cross-Entropy Loss Functions",
            "zh": "8.4.3 处理分类目标特征：Softmax 输出层和交叉熵损失函数"
        }
    },
    {
        "translation": {
            "en": "Once the δs for the output neurons have been calculated, the backpropagation of the δs through the network and the updating of the weights progresses as in the previous examples. For example, to update weight w9,6 we would first calculate Δw9,6 using Equation (8.29)[416]. Equation (8.82)[472] shows this calculation with the per example δs for neuron 9 taken from Table 8.15[471], and the activations for Neuron 6 are from Figure 8.28[470]",
            "zh": "一旦计算出输出神经元的 δ，δ 在网络中的反向传播和权重的更新就会像前面的例子一样进行。例如，为了更新权重w9,6，我们首先使用公式（8.29）[416]计算Δw9,6。方程（8.82）[472]显示了该计算，每个示例中神经元9的δs取自表8.15[471]，神经元6的激活来自图8.28[470]"
        }
    },
    {
        "translation": {
            "en": "Second, the magnitudes of the weights show how much the value of the target feature changes for a unit change in the value of a particular descriptive feature.",
            "zh": "其次，权重的大小显示目标特征的值随着特定描述性特征值的单位变化而变化的程度。"
        }
    },
    {
        "translation": {
            "en": "This is a simple one-level decision tree composed of a root note that performs one split on the basis of TEMPERATURE (because TEMPERATURE is a continuous target, the process for training regression trees described in Section 4.4.3[149] is used).",
            "zh": "这是一个简单的单级决策树，由一个根注释组成，该根注释基于 TEMPERATURE 执行一次拆分（因为 TEMPERATURE 是一个连续目标，所以使用了第 4.4.3 节[149]中描述的训练回归树的过程）。"
        }
    },
    {
        "translation": {
            "en": "The architecture of the neural network used in the weight initialization experiments. Note that the neurons in this network use a linear activation function: ai = zi.",
            "zh": "权重初始化实验中使用的神经网络架构。请注意，该网络中的神经元使用线性激活函数：ai = zi。"
        }
    },
    {
        "translation": {
            "en": "The font sizes of the correlation coefficients are scaled according to the absolute value of the strength of the correlation to draw attention to those pairs of features with the strongest relationships.",
            "zh": "相关系数的字体大小根据相关性强度的绝对值进行缩放，以引起人们对关系最强的特征对的注意。"
        }
    },
    {
        "translation": {
            "en": "TPProfit represents the profit arising from a correct positive prediction, FNProfit is the profit arising from an incorrect negative prediction, and so on (note that profit can refer to a positive or a negative value).",
            "zh": "TPProfit 表示正确的正预测产生的利润，FNProfit 表示不正确的负预测产生的利润，依此类推（请注意，利润可以指正值或负值）。"
        }
    },
    {
        "translation": {
            "en": "Given the dataset in Table B.2[760], the probability of a patient having a headache is",
            "zh": "给定表B.2[760]中的数据集，患者头痛的概率为"
        }
    },
    {
        "translation": {
            "en": "The target feature, STATUS, reports the current situation at the plant: ok, everything is working correctly; settler, there is a problem with the plant settler equipment; or solids, there is a problem with the amount of solids going through the plant.",
            "zh": "目标功能 STATUS 报告工厂的当前情况：正常，一切正常;定居者，植物定居者设备有问题;或固体，通过工厂的固体量存在问题。"
        }
    },
    {
        "translation": {
            "en": "1.4   Inductive Bias Versus Sample Bias",
            "zh": "1.4 电感偏差与样本偏差"
        }
    },
    {
        "translation": {
            "en": "This is something we need to control for when we are creating a model, as otherwise we are allowing an unwanted bias to affect the learning process.",
            "zh": "这是我们在创建模型时需要控制的事情，否则我们就会允许不必要的偏见影响学习过程。"
        }
    },
    {
        "translation": {
            "en": "This is evidence of just how well the model is performing.",
            "zh": "这证明了该模型的性能有多好。"
        }
    },
    {
        "translation": {
            "en": "It is striking, however, that the Euclidean distance between d12 and d17 is 8.25, which is greater than the Euclidean distance between d12 and d5, which is just 5.48.",
            "zh": "然而，令人惊讶的是，d12 和 d17 之间的欧几里得距离为 8.25，大于 d12 和 d5 之间的欧几里得距离，后者仅为 5.48。"
        }
    },
    {
        "translation": {
            "en": "Although it is possible to calculate this point directly for some simpler problems, this approach is not computationally feasible for most interesting predictive analytics problems.",
            "zh": "尽管对于一些较简单的问题，可以直接计算这一点，但对于大多数有趣的预测分析问题，这种方法在计算上是不可行的。"
        }
    },
    {
        "translation": {
            "en": "t-test, 333",
            "zh": "t 检验，333"
        }
    },
    {
        "translation": {
            "en": "(a) What target level would a nearest neighbor model using Euclidean distance return for the following email: “machine learning for free”?",
            "zh": "（a） 使用欧几里得距离的最近邻模型会为以下电子邮件返回什么目标水平：“免费机器学习”？"
        }
    },
    {
        "translation": {
            "en": "8.5   An illustration of the correspondence between graphical and matrix representations of a neural network.",
            "zh": "8.5 神经网络的图形和矩阵表示之间的对应关系的图示。"
        }
    },
    {
        "translation": {
            "en": "9.4.5   Performance Measures: Continuous Targets",
            "zh": "9.4.5 绩效衡量：持续目标"
        }
    },
    {
        "translation": {
            "en": "(c) If average linkage were used with AHC instead of single linkage, which agglomerations would be made in the first three iterations of the algorithm?",
            "zh": "（c） 如果将平均链接与AHC一起使用，而不是单次链接，则在算法的前三次迭代中将进行哪些集聚？"
        }
    },
    {
        "translation": {
            "en": "The dataset has three binary descriptive features: SUSPICIOUS WORDS is true if an email contains one or more words that are typically found in spam email (e.g., casino, viagra, bank, or account); UNKNOWN SENDER is true if the email is from an address that is not listed in the contacts of the person who received the email; and CONTAINS IMAGES is true if the email contains one or more images.",
            "zh": "该数据集具有三个二进制描述性特征：如果电子邮件包含垃圾邮件中常见的一个或多个单词（例如，赌场、伟哥、银行或账户），则 SUSPICIOUS WORDS 为真;如果电子邮件来自未在接收电子邮件的人的联系人中列出的地址，则 UNKNOWN SENDER 为 true;如果电子邮件包含一个或多个图像，则 CONTAINS IMAGES 为 true。"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms automate the process of learning a model that captures the relationship between the descriptive features and the target feature in a dataset. For simple datasets like the one presented in Table 1.1[6], we may be able to manually create a prediction model; in an example of this scale, machine learning has little to offer us.",
            "zh": "机器学习算法可自动执行学习模型的过程，该模型捕获数据集中描述性特征与目标特征之间的关系。对于表1.1[6]中所示的简单数据集，我们也许可以手动创建预测模型;在这种规模的例子中，机器学习几乎没有为我们提供什么。"
        }
    },
    {
        "translation": {
            "en": "The outputs of the second model for the same test dataset are shown in the table below.",
            "zh": "下表显示了同一测试数据集的第二个模型的输出。"
        }
    },
    {
        "translation": {
            "en": "under-sampled training set, 720",
            "zh": "欠采样训练集，720"
        }
    },
    {
        "translation": {
            "en": "The top layer of neurons share the weights in Filter 3, and the bottom layer share the weights in Filter 4.",
            "zh": "顶层神经元共享过滤器 3 中的权重，底层共享过滤器 4 中的权重。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS both come from d460 in Table 3.2[56].",
            "zh": "CLAIMS均来自表3.2中的d460[56]。"
        }
    },
    {
        "translation": {
            "en": "One way to understand why depth is important to the representational capacity of a neural network is to consider what types of functions a network that has only a single layer of processing neurons, such as the one shown in Figure 8.7[397], is capable of representing.",
            "zh": "理解为什么深度对神经网络的表示能力很重要的一种方法是考虑只有一层处理神经元的网络能够表示哪些类型的功能，例如图 8.7[397] 所示的网络。"
        }
    },
    {
        "translation": {
            "en": "The cluster centroids are then updated to the average value of the descriptive features of the members of a cluster.",
            "zh": "然后，将聚类质心更新为聚类成员的描述性特征的平均值。"
        }
    },
    {
        "translation": {
            "en": "Preface",
            "zh": "前言"
        }
    },
    {
        "translation": {
            "en": "3.6   The data quality plan with potential handling strategies for the motor insurance fraud prediction ABT.",
            "zh": "3.6 汽车保险欺诈预测ABT的数据质量计划，以及潜在的处理策略。"
        }
    },
    {
        "translation": {
            "en": "This can be an attractive alternative to the manual work of designing features that we described in Chapter 2[23].",
            "zh": "对于我们在第 2 章[23]中描述的手动设计功能的工作，这可能是一个有吸引力的替代方案。"
        }
    },
    {
        "translation": {
            "en": "This dataset lists six instances in which prisoners were granted parole.",
            "zh": "该数据集列出了囚犯获得假释的六个实例。"
        }
    },
    {
        "translation": {
            "en": "In 1949 Donald O. Hebb proposed a theory that attempted to explain how general human behavior emerged from the physiology of the brain.",
            "zh": "1949年，唐纳德·赫布（Donald O. Hebb）提出了一个理论，试图解释一般人类行为是如何从大脑的生理学中产生的。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.11",
            "zh": "图 3.11"
        }
    },
    {
        "translation": {
            "en": "Figure 8.24",
            "zh": "图 8.24"
        }
    },
    {
        "translation": {
            "en": "Table 13.8",
            "zh": "表 13.8"
        }
    },
    {
        "translation": {
            "en": "(f) 12th percentile",
            "zh": "（f） 第12个百分位"
        }
    },
    {
        "translation": {
            "en": "absolute rarity, 720",
            "zh": "绝对稀有，720"
        }
    },
    {
        "translation": {
            "en": "For the examples in this section, we introduce a new dataset. Table 3.7[73] shows the details of 30 players on a professional basketball team. The dataset includes the HEIGHT, WEIGHT, and AGE of each player; the POSITION that the player normally plays (guard, center, or forward); the CAREER STAGE of the player (rookie, mid-career, or veteran); the average weekly SPONSORSHIP EARNINGS of each player; and whether the player has a SHOE SPONSOR (yes or no).",
            "zh": "对于本节中的示例，我们将介绍一个新的数据集。表3.7[73]显示了一支职业篮球队中30名球员的详细信息。数据集包括每个球员的身高、体重和年龄;球员通常踢的位置（后卫、中锋或前锋）;球员的职业生涯阶段（新秀、职业生涯中期或老将）;每个球员的平均每周赞助收入;以及球员是否有鞋子赞助商（是或否）。"
        }
    },
    {
        "translation": {
            "en": "The first two items in this list focus on measuring and comparing the performance of a group of models to determine which model best performs the prediction task that the models have been built to address.",
            "zh": "此列表中的前两项侧重于测量和比较一组模型的性能，以确定哪个模型最能执行模型构建要解决的预测任务。"
        }
    },
    {
        "translation": {
            "en": "Until recently, one of the most popular functions used in artificial neurons was the logistic function introduced in Chapter 7 (see Equation (7.25)[342] and Figure 7.12[343]).",
            "zh": "直到最近，人工神经元中使用的最流行的功能之一是第7章中介绍的逻辑函数（参见公式（7.25）[342]和图7.12[343]）。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also suggested that a third other category be included to take into account the fact that all the sky objects labeled as galaxies in the previous step in the SDSS may not actually be galaxies.",
            "zh": "Jocelyn还建议包括第三个其他类别，以考虑到在SDSS的上一步中标记为星系的所有天空物体实际上可能不是星系。"
        }
    },
    {
        "translation": {
            "en": "chessboard distance, 186",
            "zh": "棋盘距离，186"
        }
    },
    {
        "translation": {
            "en": "A scatter plot is based on two axes: the horizontal axis represents one feature, and the vertical axis represents a second.",
            "zh": "散点图基于两个轴：水平轴表示一个要素，垂直轴表示第二个要素。"
        }
    },
    {
        "translation": {
            "en": "For example, if we used a horizontal and vertical stride of 3 in Figure 8.33[484], then there would be no overlap between the receptive fields of different neurons, and this would also reduce the number of neurons required to cover the input.",
            "zh": "例如，如果我们在图8.33[484]中使用3的水平和垂直步幅，那么不同神经元的感受野之间就不会有重叠，这也将减少覆盖输入所需的神经元数量。"
        }
    },
    {
        "translation": {
            "en": "Figure 12.2[695] presents the histograms for these features.",
            "zh": "图12.2[695]显示了这些特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "9.2   The structure of a confusion matrix.",
            "zh": "9.2 混淆矩阵的结构。"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.7(a)[128], we can see that splitting the dataset based on the SUSPICIOUS WORDS feature provides a lot of information about whether an email is spam or ham.",
            "zh": "在图4.7（a）[128]中，我们可以看到，基于可疑词特征拆分数据集可以提供大量有关电子邮件是垃圾邮件还是火腿的信息。"
        }
    },
    {
        "translation": {
            "en": "The diagnoses made by predictive analytics models usually become an input into the professional’s existing diagnosis process.",
            "zh": "预测分析模型做出的诊断通常成为专业人员现有诊断过程的输入。"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of the nearest neighbor approach to prediction is that it is relatively straightforward to update the model when new labeled instances become available—we simply add them to the training dataset.",
            "zh": "最近邻预测方法的优点之一是，当新的标记实例可用时，更新模型相对简单 - 我们只需将它们添加到训练数据集中即可。"
        }
    },
    {
        "translation": {
            "en": "When we use dropout, each time we load a training example we choose a random set of neurons from the input and hidden layers and drop (or delete) them from the network for that training instance.",
            "zh": "当我们使用 dropout 时，每次加载训练示例时，我们都会从输入层和隐藏层中随机选择一组神经元，并将它们从该训练实例的网络中删除（或删除）。"
        }
    },
    {
        "translation": {
            "en": "So, the lift at decile dec is the ratio between the percentage of positive instances in that decile and the percentage of positive instances overall in the population:",
            "zh": "因此，十分位数 dec 的提升是该十分位数中阳性实例的百分比与总体中阳性实例的百分比之间的比率："
        }
    },
    {
        "translation": {
            "en": "Second, riparian vegetation occurs near streams and is characterized by trees and shrubs.",
            "zh": "其次，河岸植被出现在溪流附近，以树木和灌木为特征。"
        }
    },
    {
        "translation": {
            "en": "alert",
            "zh": "警报"
        }
    },
    {
        "translation": {
            "en": "The results of each of the max pooling layers are then stacked together to create a multi-channel input for the second layer.",
            "zh": "然后，将每个最大池化层的结果堆叠在一起，为第二层创建多通道输入。"
        }
    },
    {
        "translation": {
            "en": "7.1   A dataset that includes office rental prices and a number of descriptive features for 10 Dublin city-center offices.",
            "zh": "7.1 一个数据集，包括都柏林市中心 10 个办公室的办公室租金价格和一些描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Hence, we can expect our 730-square-foot office to rent for about 460 Euro per month. This kind of model is known as a simple linear regression model. This approach to modeling the relationships between features is extremely common in both machine learning and statistics.",
            "zh": "因此，我们可以预期我们 730 平方英尺的办公室每月租金约为 460 欧元。这种模型称为简单线性回归模型。这种对特征之间关系进行建模的方法在机器学习和统计学中都非常常见。"
        }
    },
    {
        "translation": {
            "en": "There are three categorical descriptive features in this dataset.",
            "zh": "此数据集中有三个分类描述性特征。"
        }
    },
    {
        "translation": {
            "en": "A schematic of an artificial neuron.",
            "zh": "人工神经元的示意图。"
        }
    },
    {
        "translation": {
            "en": "When checking this against Figure 8.23(b)[453], note that a variance of σ2 = 0.0002 is equivalent to a standard deviation of σ ≈ 0.014.",
            "zh": "当与图 8.23（b）[453] 进行核对时，请注意 σ2 = 0.0002 的方差相当于 σ ≈ 0.014 的标准差。"
        }
    },
    {
        "translation": {
            "en": "For the purposes of illustration, imagine that we are using this filter to process the following 3-by-3 RGB image (the pixel values here are not real; they have been selected to ease the calculations in the example):",
            "zh": "为了便于说明，假设我们正在使用此过滤器来处理以下 3×3 RGB 图像（此处的像素值不是真实的;选择它们是为了简化示例中的计算）："
        }
    },
    {
        "translation": {
            "en": "2.1   The different data sources typically combined to create an analytics base table.",
            "zh": "2.1 不同的数据源通常组合在一起以创建分析基表。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.3[32] shows some domain concepts that are likely to be useful in this case.",
            "zh": "图2.3[32]显示了一些在这种情况下可能有用的领域概念。"
        }
    },
    {
        "translation": {
            "en": "Mingers, John. 1989. An empirical comparison of selection measures for decision-tree induction. Machine Learning 3 (4): 319–342.",
            "zh": "明格斯，约翰。1989. 决策树归纳选择措施的实证比较.机器学习 3 （4）：319–342。"
        }
    },
    {
        "translation": {
            "en": "However, if all the descriptive features are conditionally independent given the target feature, we can factorize the joint distribution and represent it using just 19 probabilities (one for the prior of the target and two conditional probabilities for each descriptive feature).",
            "zh": "但是，如果给定目标特征，所有描述性特征在条件上都是独立的，我们可以分解联合分布并仅使用 19 个概率（一个用于目标的先验，两个条件概率用于每个描述性特征）。"
        }
    },
    {
        "translation": {
            "en": "Finally, we also recommend Goldberg (2017) for an accessible introduction to the use of deep learning for natural language processing and Reagen et al.",
            "zh": "最后，我们还推荐Goldberg（2017）对使用深度学习进行自然语言处理和Reagen等人的通俗易懂的介绍。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to begin her data exploration work by focusing on the target feature. The structure of the data available from the Galaxy Zoo project is shown in Table 13.1[709]. The category of each galaxy is voted on by multiple Galaxy Zoo participants, and the data includes the fraction of these votes for each of the categories.",
            "zh": "Jocelyn 决定通过专注于目标特征来开始她的数据探索工作。Galaxy Zoo项目提供的数据结构如表13.1[709]所示。每个星系的类别由多个银河动物园参与者投票选出，数据包括每个类别的这些投票的比例。"
        }
    },
    {
        "translation": {
            "en": "Mingers, John. 1987. Expert systems - rule induction with statistical data. Journal of the Operational Research Society 38: 39–47.",
            "zh": "明格斯，约翰。1987. 专家系统 - 统计数据的规则归纳。运筹学学会杂志38：39-47。"
        }
    },
    {
        "translation": {
            "en": "Even more dramatically, he reports that he actually interfered with the second experiment by removing the prism from the apparatus during the demonstration (because the experiment was completed in darkness, Wood was able to do this without anybody noticing), which made no difference to the results that you measured and reported, so it completely undermines them.",
            "zh": "更戏剧性的是，他报告说，他实际上干扰了第二个实验，在演示过程中从设备上取下了棱镜（因为实验是在黑暗中完成的，伍德能够在没有人注意到的情况下做到这一点），这对你测量和报告的结果没有影响，所以它完全破坏了它们。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the next action that the agent will take is selected using a greedy action selection policy, what action will the agent choose to take (Stick or Twist)?",
            "zh": "（b） 假设使用贪婪行动选择策略选择代理将采取的下一个行动，代理将选择采取什么行动（坚持或扭曲）？"
        }
    },
    {
        "translation": {
            "en": "Valid outliers are correct values that are simply very different from the rest of the values for a feature, for example, a billionaire who has a massive salary compared to everyone else in a sample.",
            "zh": "有效异常值是与要素的其余值有很大差异的正确值，例如，与样本中的其他人相比，一位亿万富翁的薪水很高。"
        }
    },
    {
        "translation": {
            "en": "A key step, then, in any data analytics project is to understand the business problem that the organization wants to solve and, based on this, to determine the kind of insight that a predictive analytics model can provide to help the organization address this problem. This defines the analytics solution that the analytics practitioner will set out to build using machine learning. Defining the analytics solution is the most important task in the Business Understanding phase of the CRISP-DM process.",
            "zh": "因此，在任何数据分析项目中，一个关键步骤是了解组织想要解决的业务问题，并在此基础上确定预测分析模型可以提供的洞察力类型，以帮助组织解决这个问题。这定义了分析从业者将着手使用机器学习构建的分析解决方案。定义分析解决方案是 CRISP-DM 流程的业务理解阶段最重要的任务。"
        }
    },
    {
        "translation": {
            "en": "Neapolitan (2004) is a good textbook on Bayesian networks.",
            "zh": "那不勒斯（2004）是一本关于贝叶斯网络的好教科书。"
        }
    },
    {
        "translation": {
            "en": "As previously, the bias term is simply an extra weight that is multiplied by the dummy input value 1, and the result of this product is included in the weighted sum of the neuron.",
            "zh": "如前所述，偏差项只是一个额外的权重乘以虚拟输入值 1，并且该乘积的结果包含在神经元的加权和中。"
        }
    },
    {
        "translation": {
            "en": "Taleb, Nassim Nicholas. 2008. The black swan: The impact of the highly improbable. Penguin.",
            "zh": "塔勒布，纳西姆·尼古拉斯。2008. 黑天鹅：极不可能的影响。企鹅。"
        }
    },
    {
        "translation": {
            "en": "The weight can then be updated using the batch weight update rule (see Equation (8.30)[416]), where we assume a learning rate of α = 0.01, as shown in Equation (8.83)[472]",
            "zh": "然后可以使用批量权重更新规则更新权重（参见等式（8.30）[416]），其中我们假设学习率为α = 0.01，如等式（8.83）[472]所示"
        }
    },
    {
        "translation": {
            "en": "We write t to indicate the one-hot encoding vector of a categorical target.",
            "zh": "我们写 t 来表示分类目标的单热编码向量。"
        }
    },
    {
        "translation": {
            "en": "However, for each of these 8 possible combinations of descriptive feature values, there are 3 possible target feature values, so this means that there are 38 = 6,561 possible prediction models that could be used.",
            "zh": "但是，对于这 8 种描述性特征值的可能组合中的每一种，都有 3 个可能的目标特征值，因此这意味着可以使用 38 = 6,561 个可能的预测模型。"
        }
    },
    {
        "translation": {
            "en": "For HL2 we know that and var(W(HL2)) = 0.0001, and so we can now calculate the variance of z across the neurons in layer HL2 as follows:",
            "zh": "对于 HL2，我们知道 和 var（W（HL2）） = 0.0001，因此我们现在可以计算 HL2 层中神经元的 z 方差，如下所示："
        }
    },
    {
        "translation": {
            "en": "Figure 8.3",
            "zh": "图 8.3"
        }
    },
    {
        "translation": {
            "en": "Instances",
            "zh": "实例"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that naive Bayes models can be trained using a relatively small dataset: with so few parameters and so few conditions on each parameter—only the state of the target feature—it is possible to make reasonable estimates for the parameters using a small dataset.",
            "zh": "这样做的一个结果是，朴素的贝叶斯模型可以使用相对较小的数据集进行训练：由于参数如此之少，每个参数的条件也如此之少（只有目标特征的状态），因此可以使用较小的数据集对参数进行合理的估计。"
        }
    },
    {
        "translation": {
            "en": "∂a/∂z",
            "zh": "∂a/∂z"
        }
    },
    {
        "translation": {
            "en": "Figure 5.17",
            "zh": "图 5.17"
        }
    },
    {
        "translation": {
            "en": "23. We provide references in Section 7.6[370].",
            "zh": "23. 我们在第7.6节[370]中提供了参考资料。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.3 presents a graphical representation of this same function.",
            "zh": "图 8.3 显示了同一函数的图形表示。"
        }
    },
    {
        "translation": {
            "en": "1. if ak, the activation from neuron k that the weight wi,k was applied to, is positive, we should decrease the weight wi,k. In this case ∂ℰ/∂wi,k = δi × ak will be positive, because both terms in the product are positive, and so to decrease the weight wi,k we should subtract ∂ℰ/∂wi,k from wi,k.",
            "zh": "1. 如果 AK，即施加权重 Wi，K 的神经元 K 的激活是正的，我们应该降低权重 Wi，K。在这种情况下，∂E/∂wi，k = δi × ak 将为正，因为乘积中的两个项都是正的，因此为了降低权重 wi，k，我们应该从 wi，k 中减去 ∂E/∂wi，k。"
        }
    },
    {
        "translation": {
            "en": "AVGRECURRINGCHARGE",
            "zh": "AVGRECURRING费用"
        }
    },
    {
        "translation": {
            "en": "The values chosen for the learning rate and initial weights can have a significant impact on how the gradient descent algorithm proceeds. Unfortunately, there are no theoretical results that help in choosing the optimal values for these parameters. Instead, these algorithm parameters must be chosen using rules of thumb gathered through experience.",
            "zh": "为学习率和初始权重选择的值可能会对梯度下降算法的进行方式产生重大影响。不幸的是，没有理论结果有助于选择这些参数的最佳值。相反，这些算法参数必须使用通过经验收集的经验法则来选择。"
        }
    },
    {
        "translation": {
            "en": "Subsequently in this chapter we introduce network architectures that are not feedforward and also architectures that are not fully connected.",
            "zh": "在本章的后续中，我们将介绍非前馈网络架构以及未完全连接的架构。"
        }
    },
    {
        "translation": {
            "en": "weak learners, 165",
            "zh": "弱学习者，165"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions.",
            "zh": "具有模型预测的示例测试集。"
        }
    },
    {
        "translation": {
            "en": "Having covered how we backpropagate through branches, elementwise products, and elementwise additions in the forward pass, we are now able to backpropagate the error gradients through the LSTM.",
            "zh": "在介绍了如何在前向传递中通过分支、逐元乘积和逐元加法进行反向传播之后，我们现在能够通过 LSTM 反向传播误差梯度。"
        }
    },
    {
        "translation": {
            "en": "The query instance value for CONTAINS IMAGES is true so the process descends the left branch from the root node, labeled true, to an interior node that tests the SUSPICIOUS WORDS feature.",
            "zh": "CONTAINS IMAGES 的查询实例值为 true，因此该进程将左侧分支从标记为 true 的根节点下降到测试 SUSPICIOUS WORDS 功能的内部节点。"
        }
    },
    {
        "translation": {
            "en": "The error delta function invoked on Line 4[326] of Algorithm 4[326] performs this calculation to determine the delta value by which each weight should be adjusted.",
            "zh": "在算法 4[326] 的第 4 行 [326] 上调用的误差 delta 函数执行此计算以确定应调整每个权重的 delta 值。"
        }
    },
    {
        "translation": {
            "en": "Each of the leaf nodes specifies a predicted level of the target feature.",
            "zh": "每个叶节点指定目标要素的预测级别。"
        }
    },
    {
        "translation": {
            "en": "Recall is equivalent to true positive rate (TPR) (compare Equations (9.4)[548] and (9.9)[549]).",
            "zh": "召回率等同于真阳性率（TPR）（比较公式（9.4）[548]和（9.9）[549]）。"
        }
    },
    {
        "translation": {
            "en": "Gaussian distribution, 61",
            "zh": "高斯分布，61"
        }
    },
    {
        "translation": {
            "en": "He dismisses the experimental setup for the experiments you demonstrated as entirely inappropriate.",
            "zh": "他驳回了你演示的实验的实验设置，认为这是完全不合适的。"
        }
    },
    {
        "translation": {
            "en": "Notice that SLOPE is the only descriptive feature that is listed in 10 and 11.",
            "zh": "请注意，SLOPE 是 10 和 11 中列出的唯一描述性特征。"
        }
    },
    {
        "translation": {
            "en": "9.4.6.3 Monitoring descriptive feature distribution changes In the same way we can compare the distributions of model outputs between the time that the model was built and after deployment, we can also make the same type of comparison for the distributions of the descriptive features used by the model. We can use any appropriate measure that captures the difference between two different distributions for this, including the stability index, the χ2 statistic, and the K-S statistic.",
            "zh": "9.4.6.3 监测描述性特征分布变化 同样，我们可以比较模型生成和部署后模型输出的分布，也可以对模型使用的描述性特征的分布进行相同类型的比较。为此，我们可以使用任何适当的度量来捕获两个不同分布之间的差异，包括稳定性指数、χ2 统计量和 K-S 统计量。"
        }
    },
    {
        "translation": {
            "en": "When we compare, the three images, 14 bins seems to best model the data.",
            "zh": "当我们比较这三张图像时，14 个箱似乎可以最好地对数据进行建模。"
        }
    },
    {
        "translation": {
            "en": "The choice is really a matter of convenience.",
            "zh": "选择确实是一个方便的问题。"
        }
    },
    {
        "translation": {
            "en": "8.3 Standard Approach: Backpropagation and Gradient Descent",
            "zh": "8.3 标准方法：反向传播和梯度下降"
        }
    },
    {
        "translation": {
            "en": "Figure 8.34[488] illustrates what happens if we pad the boundary of an image with imaginary pixels.",
            "zh": "图8.34[488]说明了如果我们用假想像素填充图像的边界会发生什么。"
        }
    },
    {
        "translation": {
            "en": "Both the resulting sets contain a balanced mixture of spam and ham instances.",
            "zh": "生成的两个集合都包含垃圾邮件和火腿实例的平衡组合。"
        }
    },
    {
        "translation": {
            "en": "After removing a large number of the columns from the raw SDSS dataset, introducing a number of derived features, and generating two target features, Jocelyn generated an ABT containing 327 descriptive features and two target features. Table 13.3[715] lists these features (features that occur over all five photometric bands are listed as NAME_U/G/R/I/Z to save space).13",
            "zh": "从原始 SDSS 数据集中删除大量列，引入大量派生特征并生成两个目标特征后，Jocelyn 生成了一个包含 327 个描述性特征和两个目标特征的 ABT。表13.3[715]列出了这些特征（为了节省空间，在所有五个光度波段上出现的特征被列为NAME_U/G/R/I/Z）13。"
        }
    },
    {
        "translation": {
            "en": "Similarly, the details of each claim, the related policy, and the related claimant would need to be available.",
            "zh": "同样，需要提供每项索赔、相关保单和相关索赔人的详细信息。"
        }
    },
    {
        "translation": {
            "en": "Faced with the backs of three cards (as shown in Figure 6.1(b)[244]), the player then has to guess where the queen has landed.",
            "zh": "面对三张牌的背面（如图6.1（b）[244]所示），玩家必须猜测女王降落在哪里。"
        }
    },
    {
        "translation": {
            "en": "A.3   Poll results from the run-up to the 2012 U.S. presidential election.",
            "zh": "A.3 2012年美国总统大选前的民意调查结果。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(c)[663] visualizes the action-value table after 350 episodes have elapsed.",
            "zh": "图 11.5（c）[663] 显示了 350 集后的动作值表。"
        }
    },
    {
        "translation": {
            "en": "HEALTHUSD: Health spending per person converted into US dollars",
            "zh": "HEALTHUSD：人均医疗支出换算成美元"
        }
    },
    {
        "translation": {
            "en": "For example, the decision tree learning algorithms we looked at in the last chapter worked by selecting subsets of features from which to build predictive trees and so naturally reduce dimensionality.",
            "zh": "例如，我们在上一章中研究的决策树学习算法通过选择特征子集来构建预测树，从而自然地降低维度。"
        }
    },
    {
        "translation": {
            "en": "On the other hand, misclassifying a customer who really was a churn risk probably has a much larger cost associated with it because that customer will be lost when a small bonus may have enticed the customer to stay.",
            "zh": "另一方面，错误地将真正存在流失风险的客户分类可能会产生更大的成本，因为当小额奖金可能诱使客户留下来时，该客户就会流失。"
        }
    },
    {
        "translation": {
            "en": "This gives a large set of low-information descriptive features.",
            "zh": "这提供了大量低信息描述性特征。"
        }
    },
    {
        "translation": {
            "en": "A.8  (a) The structure of a box plot; and (b) a box plot for the TRAINING EXPENSES feature from the basketball team dataset in Table A.1[750].",
            "zh": "A.8 （a） 箱形图的结构;（b）表A.1[750]中篮球队数据集的训练费用特征的箱形图。"
        }
    },
    {
        "translation": {
            "en": "Finally, we use the matrix representation of a network as a compact representation of neural networks in the worked examples.",
            "zh": "最后，我们使用网络的矩阵表示作为工作示例中神经网络的紧凑表示。"
        }
    },
    {
        "translation": {
            "en": "tolerance, 323",
            "zh": "公差， 323"
        }
    },
    {
        "translation": {
            "en": "It is not easy to apply the measures based on prediction scores to multinomial problems. Although there are some examples of doing it, there is no broad consensus in the community on how it should best be done in all cases, so we do not discuss it further in this book.",
            "zh": "将基于预测分数的度量应用于多项式问题并不容易。尽管有一些这样做的例子，但社区中并没有就如何在所有情况下最好地做到这一点达成广泛的共识，因此我们不会在本书中进一步讨论它。"
        }
    },
    {
        "translation": {
            "en": "This book had a major impact and is attributed with killing interest in neural networks for nearly a decade.",
            "zh": "这本书产生了重大影响，并被认为扼杀了近十年来对神经网络的兴趣。"
        }
    },
    {
        "translation": {
            "en": "There are two neurons in each of these layers because we are assuming a step size of 1, and so it requires two neurons to convolve a 2-by-1-by-2 filter over the 3-by-2-by-2 input.",
            "zh": "每一层都有两个神经元，因为我们假设步长为 1，因此需要两个神经元在 3×2×2 输入上卷积 2×1×2 滤波器。"
        }
    },
    {
        "translation": {
            "en": "On the basis of these predictions, ε is calculated as 0.200, the sum of the weights of the two instances misclassified by the model (d9 and d10). The weights of all correctly classified instances are then updated using Equation (4.13)[161]. For example, the weight for d1 is updated",
            "zh": "根据这些预测，ε计算为 0.200，即模型错误分类的两个实例的权重之和（d9 和 d10）。然后使用公式（4.13）[161]更新所有正确分类的实例的权重。例如，d1 的权重已更新"
        }
    },
    {
        "translation": {
            "en": "variation, 54, 745, 746",
            "zh": "变体， 54， 745， 746"
        }
    },
    {
        "translation": {
            "en": "Figure 4.17[154] illustrates the final decision tree that will be generated for this dataset. This tree will predict the mean target feature value of the leaf node indicated by the descriptive features of a query instance. For example, given a query instance with SEASON = summer and WORK DAY = true, this decision tree will predict that there will be 6,000 bike rentals on that day.",
            "zh": "图 4.17[154] 说明了将为该数据集生成的最终决策树。此树将预测由查询实例的描述性特征指示的叶节点的平均目标特征值。例如，给定一个 SEASON = summer 且 WORK DAY = true 的查询实例，此决策树将预测当天将有 6,000 辆自行车租赁。"
        }
    },
    {
        "translation": {
            "en": "HANDSETAGE",
            "zh": "手机"
        }
    },
    {
        "translation": {
            "en": "burn-in time, 300",
            "zh": "老化时间，300"
        }
    },
    {
        "translation": {
            "en": "At each node encountered in the search, the algorithm does three things.",
            "zh": "在搜索中遇到的每个节点上，该算法会执行三件事。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, although there is still a differential between some of the valid pixels in terms of the number of neurons that take them as input, this differential has been decreased; each of the valid corner pixels is now present in four receptive fields, as opposed to one as previously, whereas the count of receptive fields covering a pixel in the center of the image is not affected by the padding.",
            "zh": "此外，尽管在将它们作为输入的神经元数量方面，一些有效像素之间仍然存在差异，但这种差异已经减少;每个有效的角像素现在都存在于四个感受野中，而不是像以前那样存在一个感受野，而覆盖图像中心像素的感受野计数不受填充的影响。"
        }
    },
    {
        "translation": {
            "en": "There is an ongoing argument regarding whether descriptive features should be normalized before being used in linear regression models.",
            "zh": "关于描述性特征在用于线性回归模型之前是否应该归一化，一直存在争议。"
        }
    },
    {
        "translation": {
            "en": "7.4.1 Interpreting Multivariable Linear Regression Models",
            "zh": "7.4.1 解释多变量线性回归模型"
        }
    },
    {
        "translation": {
            "en": "This can limit the amount of data that an organization collects and, sometimes, restricts implementing features to capture certain domain concepts because consent has not been granted to collect the required data.",
            "zh": "这可能会限制组织收集的数据量，有时还会限制实现功能以捕获某些领域概念，因为尚未授予收集所需数据的同意。"
        }
    },
    {
        "translation": {
            "en": "Table 8.7[432] illustrates this calculation for weight w7,5, and Equation 8.39[432] shows how the Δw 7,5 is used as part of Equation 8.30[416] to update the weight after the batch of four examples has been processed; again, in this weight update we assume that α = 0.2.",
            "zh": "表 8.7[432] 说明了重量 w7,5 的计算，等式 8.39[432] 显示了如何在处理完批次四个示例后将 Δw 7,5 用作等式 8.30[416] 的一部分来更新重量;同样，在此权重更新中，我们假设 α = 0.2。"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that would be needed in order to utilize the analytics-based insight that your solution would provide.",
            "zh": "（c） 对于您提出的每个分析解决方案，概述利用您的解决方案将提供的基于分析的见解所需的容量。"
        }
    },
    {
        "translation": {
            "en": "For a more broad discussion, Isaac Asimov’s I, Robot (Asimov, 1950), in which the Three Laws of Robotics first appear, is a fun exploration of the challenges of defining reward and utility functions. Similarly, Bostrom’s paperclip maximizer thought experiment (Bostrom, 2003) is an interesting exploration of the potential negative consequences of a highly functional intelligent agent pursuing cumulative reward.",
            "zh": "对于更广泛的讨论，艾萨克·阿西莫夫（Isaac Asimov）的《我，机器人》（阿西莫夫，1950年）首次出现了机器人三定律，这是对定义奖励和效用函数的挑战的有趣探索。同样，Bostrom的回形针最大化器思想实验（Bostrom，2003）是对追求累积奖励的高功能智能代理的潜在负面后果的有趣探索。"
        }
    },
    {
        "translation": {
            "en": "where IG(d, 𝒟) is the information gain of the feature d for the dataset 𝒟 (computed using Equation (4.4)[130] from Section 4.2.3[127]), and the divisor is the entropy of the dataset 𝒟 with respect to the feature d (note that levels(d) is the set of levels that the feature d can take). This divisor biases information gain ratio away from features that take on a large number of values and as such counteracts the bias in information gain toward these features.",
            "zh": "其中 IG（d， D） 是数据集 D 的特征 d 的信息增益（使用第 4.2.3 节[127] 中的公式 （4.4）[130] 计算），除数是数据集 D 相对于特征 d 的熵（请注意，levels（d） 是特征 d 可以采用的水平集）。该除数使信息增益比偏离具有大量值的特征，从而抵消了信息增益对这些特征的偏差。"
        }
    },
    {
        "translation": {
            "en": "step-wise sequential search, 722, 723",
            "zh": "逐步顺序搜索，722,723"
        }
    },
    {
        "translation": {
            "en": "Vertically aligning the columns in the input matrix with the columns in the output matrix shows that the network correctly maps all four inputs combinations to XOR outputs: < 0,0 > → 0, < 0,1 > → 1, < 1,0 > → 1, and < 1,1 > → 0.",
            "zh": "将输入矩阵中的列与输出矩阵中的列垂直对齐表明，网络正确地将所有四个输入组合映射到 XOR 输出：< 0,0 > → 0、< 0,1 > → 1、< 1,0 > → 1 和 < 1,1 > → 0。"
        }
    },
    {
        "translation": {
            "en": "Calculate the cumulative gain of each of the models for the 4th decile.",
            "zh": "计算第 4 个十分位数的每个模型的累积增益。"
        }
    },
    {
        "translation": {
            "en": "1. An online movie streaming company has a business problem of growing customer churn—subscription customers canceling their subscriptions to join a competitor. Create a list of ways in which predictive data analytics could be used to help address this business problem. For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original business problem.",
            "zh": "1. 一家在线电影流媒体公司面临着客户流失率不断增长的业务问题——订阅客户取消订阅以加入竞争对手。创建一个列表，列出可以使用预测数据分析来帮助解决此业务问题的方法。对于每个建议的方法，描述将要构建的预测模型、业务部门如何使用该模型，以及使用该模型将如何帮助解决原始业务问题。"
        }
    },
    {
        "translation": {
            "en": "On the basis of this feedback, Sarah learned what constituted a good decision and and became better and better at assessing her situation and choosing which direction to step in next and how far.",
            "zh": "根据这些反馈，莎拉了解了什么是正确的决定，并且越来越善于评估自己的处境，并选择下一步要走哪个方向以及走多远。"
        }
    },
    {
        "translation": {
            "en": "Recall tells us how confident we can be that all the instances with the positive target level have been found by the model.",
            "zh": "召回告诉我们，模型已经找到了所有具有正目标水平的实例，我们可以有多大的信心。"
        }
    },
    {
        "translation": {
            "en": "learning rate, 168, 323, 332, 379, 422, 654",
            "zh": "学习率， 168， 323， 332， 379， 422， 654"
        }
    },
    {
        "translation": {
            "en": "partially observable environments, 640",
            "zh": "部分可观测环境，640"
        }
    },
    {
        "translation": {
            "en": "The inclusion of the weight w[0] means that there is one more weight term than there are real descriptive features.",
            "zh": "包含权重 w[0] 意味着权重项比实际描述性特征多一个。"
        }
    },
    {
        "translation": {
            "en": "rank and prune, 227, 614",
            "zh": "等级和修剪，227,614"
        }
    },
    {
        "translation": {
            "en": "where the parameter p is typically set to a positive value and defines the behavior of the distance metric. Different distance metrics result from adjusting the value of p. For example, the Minkowski distance with p = 1 is the Manhattan distance, and with p = 2 is the Euclidean distance. Continuing in this manner, we can define an infinite number of distance metrics.",
            "zh": "其中，参数 p 通常设置为正值，并定义距离指标的行为。调整 p 的值会产生不同的距离度量。例如，p = 1 的闵可夫斯基距离是曼哈顿距离，p = 2 的闵可夫斯基距离是欧几里得距离。以这种方式继续，我们可以定义无限数量的距离度量。"
        }
    },
    {
        "translation": {
            "en": "As a result, these models are very sensitive to noise in the target feature.",
            "zh": "因此，这些模型对目标特征中的噪声非常敏感。"
        }
    },
    {
        "translation": {
            "en": "Therefore, manually setting upper and lower thresholds based on domain knowledge is most appropriate in this case.",
            "zh": "因此，在这种情况下，根据领域知识手动设置上限和下限是最合适的。"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address the problem that the oil exploration company is facing. For each proposed approach, describe the predictive model that will be built, how the model will be used by the company, and how using the model will help address the original problem.",
            "zh": "（a） 提出两种方法，利用预测性数据分析来帮助解决石油勘探公司面临的问题。对于每个建议的方法，描述将要构建的预测模型、公司如何使用该模型，以及使用该模型将如何帮助解决原始问题。"
        }
    },
    {
        "translation": {
            "en": "0.207122",
            "zh": "0.207122"
        }
    },
    {
        "translation": {
            "en": "We discuss sampling methods in more detail in Section 3.6.3[91].",
            "zh": "我们将在第3.6.3节[91]中更详细地讨论采样方法。"
        }
    },
    {
        "translation": {
            "en": "No individual feature stood out as having a very strong relationship, but the evidence of connections between the descriptive features and the target feature could be seen.",
            "zh": "没有一个单独的特征具有非常强的关系，但可以看到描述性特征和目标特征之间联系的证据。"
        }
    },
    {
        "translation": {
            "en": "bootstrapping, 546, 655, 662, 676",
            "zh": "引导， 546， 655， 662， 676"
        }
    },
    {
        "translation": {
            "en": "where for a given state the model outputs the value of the action-value function for every action that could be taken in that state. To simplify notation we refer to action-value functions implemented as predictive models as Q𝕄. Figure 11.8[669] illustrates this framing of the action-value function learning problem.",
            "zh": "其中，对于给定状态，模型输出在该状态下可以执行的每个操作的 action-value 函数的值。为了简化符号，我们将作为预测模型实现的动作值函数称为 QM。图11.8[669]说明了动作-价值函数学习问题的框架。"
        }
    },
    {
        "translation": {
            "en": "The CART algorithm uses the Gini index (introduced in Section 4.4.1[142]) instead of information gain to select features to add to the tree.",
            "zh": "CART算法使用基尼指数（在第4.4.1节[142]中介绍）而不是信息增益来选择要添加到树中的特征。"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks provide a more flexible representation for encoding the conditional independence assumptions between the features in a domain.",
            "zh": "贝叶斯网络为编码域中特征之间的条件独立性假设提供了更灵活的表示形式。"
        }
    },
    {
        "translation": {
            "en": "The fact that the judgment of similarity between current trial user and the other users in the dataset changed dramatically depending on which similarity index was employed illustrates the importance of choosing the correct index for the task.",
            "zh": "当前试验用户与数据集中其他用户之间的相似性判断根据所采用的相似性指数而发生巨大变化，这一事实说明了为任务选择正确指数的重要性。"
        }
    },
    {
        "translation": {
            "en": "So, the ROC curve gives us an immediate visual indication of the strength of a model—the closer the curve is to the top left, the more predictive the model.",
            "zh": "因此，ROC 曲线为我们提供了模型强度的直接视觉指示——曲线越靠近左上角，模型的预测性就越强。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the discounted return at time t = 0 on the basis of this sequence of rewards using a discount rate of 0.22.",
            "zh": "（b） 使用贴现率为 0.22 的贴现率，根据这一系列奖励计算时间 t = 0 时的贴现回报。"
        }
    },
    {
        "translation": {
            "en": "That cumulative gain chart allows us to understand how many of the positive instances in a complete test set we can expect to have identified at each decile of the dataset.",
            "zh": "该累积增益图使我们能够了解在数据集的每个十分位数可以识别出完整测试集中有多少个阳性实例。"
        }
    },
    {
        "translation": {
            "en": "The main difference in processing examples in parallel is that instead of augmenting the input and activation matrices with a single dummy feature value, they are now augmented with a row of dummy features values, one per example.",
            "zh": "并行处理示例的主要区别在于，现在不是用单个虚拟特征值来扩充输入和激活矩阵，而是用一行虚拟特征值来扩充它们，每个示例一个。"
        }
    },
    {
        "translation": {
            "en": "A model is trained using the training set, and the relevant performance measures on the test set are recorded.",
            "zh": "使用训练集训练模型，并记录测试集上的相关性能度量。"
        }
    },
    {
        "translation": {
            "en": "This dynamic of a ReLU being in a state where it is inactive for all (or nearly all) inputs and consequently it never updated and so never becomes active is known as the dying ReLU problem.",
            "zh": "ReLU 处于对所有（或几乎所有）输入都处于非活动状态的这种动态，因此它永远不会更新，因此永远不会变得活跃，这被称为垂死的 ReLU 问题。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15[151] illustrates the type of partitioning we are trying to achieve when we use a variance measure to select the features to split on in a decision tree.",
            "zh": "图 4.15[151] 说明了当我们使用方差度量来选择要在决策树中拆分的特征时，我们试图实现的分区类型。"
        }
    },
    {
        "translation": {
            "en": "In practice, unfortunately, this doesn’t work, for a number of reasons.",
            "zh": "不幸的是，在实践中，由于多种原因，这不起作用。"
        }
    },
    {
        "translation": {
            "en": "-0.5795",
            "zh": "-0.5795"
        }
    },
    {
        "translation": {
            "en": "Logistic regression models, for example, are very fast at making predictions as all that is involved is calculating the regression equation and performing a thresholding operation.",
            "zh": "例如，逻辑回归模型在进行预测时非常快，因为所涉及的只是计算回归方程并执行阈值运算。"
        }
    },
    {
        "translation": {
            "en": "There are strong relationships between these measures, for example: FNR = 1 − TPR, and FPR = 1 − TNR.",
            "zh": "这些措施之间存在很强的关系，例如：FNR = 1 − TPR 和 FPR = 1 − TNR。"
        }
    },
    {
        "translation": {
            "en": "A.1.2 Variation",
            "zh": "A.1.2 变化"
        }
    },
    {
        "translation": {
            "en": "The model is designed to award a grade to a student on the basis of how similar they are to other students in the module in terms of their grades on other modules.",
            "zh": "该模型旨在根据学生在其他模块中的成绩与模块中其他学生的相似程度来授予学生成绩。"
        }
    },
    {
        "translation": {
            "en": "If this approach were to be used for the CLAIM AMOUNT feature from the motor claims insurance fraud detection scenario, then the upper and lower thresholds would be defined as follows:",
            "zh": "如果此方法用于汽车索赔保险欺诈检测方案中的 CLAIM AMOUNT 功能，则上限和下限将定义如下："
        }
    },
    {
        "translation": {
            "en": "conditional probability table, 286",
            "zh": "条件概率表，286"
        }
    },
    {
        "translation": {
            "en": "1. Parts of this chapter assume a familiarity with calculus, in particular the concepts of a partial derivative and the chain rule; see Appendix C[765] for an introduction to these concepts. This chapter also draws on a number of concepts introduced in Chapter 7[311], including the gradient descent algorithm, and logistic regression models.",
            "zh": "1. 本章的部分内容假定您熟悉微积分，特别是偏导数和链式法则的概念;有关这些概念的介绍，请参阅附录C[765]。本章还借鉴了第7章[311]中介绍的一些概念，包括梯度下降算法和逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "Well-designed application-based, or point-and-click, tools make it very quick and easy to develop and evaluate models and to perform associated data manipulation tasks.",
            "zh": "精心设计的基于应用程序或点击式工具使开发和评估模型以及执行相关数据操作任务变得非常快速和容易。"
        }
    },
    {
        "translation": {
            "en": "Full independence between events is quite rare.",
            "zh": "事件之间的完全独立性是相当罕见的。"
        }
    },
    {
        "translation": {
            "en": "risk assessment, 3",
            "zh": "风险评估，3"
        }
    },
    {
        "translation": {
            "en": "13.1   Examples of the different galaxy morphology categories into which SDSS scientists categorize galaxy objects.",
            "zh": "13.1 SDSS科学家将星系天体分类为不同星系形态类别的例子。"
        }
    },
    {
        "translation": {
            "en": "This is evident in Figure 11.6[667], which shows a visualization of the final action-value table learned by an agent training using SARSA for the grid world.",
            "zh": "这在图 11.6[667] 中很明显，它显示了使用 SARSA 在网格世界中训练的智能体所学习的最终行动值表的可视化。"
        }
    },
    {
        "translation": {
            "en": "feature map, 485",
            "zh": "特征地图，485"
        }
    },
    {
        "translation": {
            "en": "This issue should be noted in the data quality plan.",
            "zh": "此问题应在数据质量计划中注明。"
        }
    },
    {
        "translation": {
            "en": "This distinction is not absolute, but it generally describes whether the size of the domain representation used to define a model is solely determined by the number of features in the domain or is affected by the number of instances in the dataset.",
            "zh": "这种区别不是绝对的，但它通常描述了用于定义模型的域表示的大小是仅由域中的要素数决定的，还是受数据集中的实例数的影响。"
        }
    },
    {
        "translation": {
            "en": "However, the actual result was a massive win for Roosevelt, with 62% of the votes.",
            "zh": "然而，实际结果是罗斯福以62%的选票大获全胜。"
        }
    },
    {
        "translation": {
            "en": "(a) The height of employees in a trucking company.",
            "zh": "（a） 卡车运输公司雇员的身高。"
        }
    },
    {
        "translation": {
            "en": "Returning to our example, the regression equation for this RENTAL PRICE model would change to",
            "zh": "回到我们的示例，这个 RENTAL PRICE 模型的回归方程将变为"
        }
    },
    {
        "translation": {
            "en": "To perform this ranking, we need to reduce the information contained in the confusion matrix to a single measure, for example, misclassification rate.",
            "zh": "为了执行此排名，我们需要将混淆矩阵中包含的信息简化为单个度量，例如错误分类率。"
        }
    },
    {
        "translation": {
            "en": "Unless, however, this second use was stated at the time of collection, this use would be in breach of this principle.",
            "zh": "但是，除非在收集时说明第二次使用，否则这种使用将违反这一原则。"
        }
    },
    {
        "translation": {
            "en": "When this happens, it indicates that all the chains are sampling from the same distribution and, hence, that it is likely that they have all forgotten their starting states.",
            "zh": "当这种情况发生时，它表明所有链都从同一分布中采样，因此，它们很可能都忘记了它们的起始状态。"
        }
    },
    {
        "translation": {
            "en": "covariance, 81, 218",
            "zh": "协方差， 81， 218"
        }
    },
    {
        "translation": {
            "en": "The cells above and below the diagonal show scatter plots of the features in the row and column that meet at that cell.",
            "zh": "对角线上方和下方的像元显示行和列中在该像元处相交的要素的散点图。"
        }
    },
    {
        "translation": {
            "en": "Computing a conditional probability for a node becomes more complex if the value of one or more of the parent nodes is unknown.",
            "zh": "如果一个或多个父节点的值未知，则计算节点的条件概率会变得更加复杂。"
        }
    },
    {
        "translation": {
            "en": "The reason that partitioning the dataset into single instances is indicative of overfitting is that if there is any noise in the training data (something that is likely in real applications), then the leaf nodes generated due to noisy instances will result in unreliable predictions for queries.",
            "zh": "将数据集划分为单个实例表示过度拟合的原因是，如果训练数据中存在任何噪声（在实际应用程序中可能存在），则由于噪声实例而生成的叶节点将导致查询预测不可靠。"
        }
    },
    {
        "translation": {
            "en": "convolutional neural network, 434, 477, 485, 673, 674",
            "zh": "卷积神经网络， 434， 477， 485， 673， 674"
        }
    },
    {
        "translation": {
            "en": "classes, 551",
            "zh": "类，551"
        }
    },
    {
        "translation": {
            "en": "2. ∂ai/∂zi is always ≥ 0 for a logistic function.",
            "zh": "2. ∂ai/∂zi 对于逻辑函数始终≥ 0。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices and class accuracy measures arising from each fold are shown in Table 9.4[544].",
            "zh": "每个折叠产生的混淆矩阵和类精度测量如表9.4[544]所示。"
        }
    },
    {
        "translation": {
            "en": "8.17   A plot showing how the sum of squared errors of the network changed during training.",
            "zh": "8.17 显示网络误差平方和在训练期间如何变化的图。"
        }
    },
    {
        "translation": {
            "en": "coordinate system, 183",
            "zh": "坐标系，183"
        }
    },
    {
        "translation": {
            "en": "At any point in time, t, the agent observes the current state of its environment, ot; considers these observations to select an action, at; and takes this action, receiving immediate feedback, rt, from the environment about whether this was a good or bad action to take.",
            "zh": "在任何时间点 t，代理观察其环境的当前状态，ot;考虑这些观察结果以选择一个动作，在;并采取此操作，从环境中接收即时反馈 RT，了解这是要采取的操作是好是坏。"
        }
    },
    {
        "translation": {
            "en": "This makes bar plots comparable across datasets or samples of different sizes and is referred to as a probability distribution, because the densities actually tell us the probability that we would pick each level if we were to select one instance at random from the dataset.",
            "zh": "这使得条形图在不同大小的数据集或样本之间具有可比性，并且被称为概率分布，因为密度实际上告诉我们，如果我们从数据集中随机选择一个实例，我们将选择每个水平的概率。"
        }
    },
    {
        "translation": {
            "en": "Table 5.1[182] illustrates this process by listing some of the animals you have encountered before and how they compare with the growling, web-footed, duck-billed animal that the sailor described.",
            "zh": "表5.1[182]通过列出你以前遇到的一些动物，以及它们与水手描述的咆哮、蹼足、鸭嘴动物的比较，来说明这个过程。"
        }
    },
    {
        "translation": {
            "en": "Computational considerations aside, Euclidean distance is often used as the default.",
            "zh": "撇开计算考虑不谈，欧几里得距离通常被用作默认值。"
        }
    },
    {
        "translation": {
            "en": "17. The concept of a convergence criterion is also used in the gradient decent algorithm discussed in Chapter 7[311]; see Algorithm 4[326].",
            "zh": "17. 收敛准则的概念也用于第7章[311]讨论的梯度体面算法;参见算法4[326]。"
        }
    },
    {
        "translation": {
            "en": "12.2 Data Understanding",
            "zh": "12.2 数据理解"
        }
    },
    {
        "translation": {
            "en": "Linear Regression",
            "zh": "线性回归"
        }
    },
    {
        "translation": {
            "en": "0.36",
            "zh": "0.36"
        }
    },
    {
        "translation": {
            "en": "These two classes are linearly separable because as Figure 7.10[340](b) shows, it is possible to draw a single straight line that separates one class from the other.",
            "zh": "这两个类是线性可分离的，因为如图 7.10[340]（b） 所示，可以绘制一条直线将一个类与另一个类分开。"
        }
    },
    {
        "translation": {
            "en": "This extra depth enables the networks to learn more complex input-output mappings.",
            "zh": "这种额外的深度使网络能够学习更复杂的输入-输出映射。"
        }
    },
    {
        "translation": {
            "en": "3.14   (a)–(c) Equal-frequency binning of normally distributed data with different numbers of bins; and (d)–(f) the same data binned into the same number of bins using equal-width binning. The dashed lines illustrate the distribution of the original continuous feature values, and the gray boxes represent the bins.",
            "zh": "3.14 （a）–（c） 具有不同箱数的正态分布数据的等频分箱;（d）–（f）使用等宽分箱将相同的数据分箱到相同数量的分箱中。虚线表示原始连续要素值的分布，灰色框表示条柱。"
        }
    },
    {
        "translation": {
            "en": "Consequently, if you ask Question 2 first, the average number of questions you have to ask per game is",
            "zh": "因此，如果您先问问题 2，则每场比赛必须问的平均问题数为"
        }
    },
    {
        "translation": {
            "en": "The completed transition matrix for the Twist action, 𝒫Twist, is",
            "zh": "Twist 动作 PTwist 的完整过渡矩阵为"
        }
    },
    {
        "translation": {
            "en": "Each loop of the repeat loop from Line 3[420] to Line 33[420] involves an epoch of training (i.e., a full traversal of the training data completed via a single pass through all the mini-batches).",
            "zh": "从第 3 行 [420] 到第 33 行 [420] 的重复循环的每个循环都涉及一个训练周期（即，通过所有小批量的单次遍历完成的训练数据的完整遍历）。"
        }
    },
    {
        "translation": {
            "en": "where t is a target feature with a set of levels, levels(t), and q is a query instance with a set of descriptive features, q[1],…,q[m].",
            "zh": "其中 t 是具有一组级别的目标特征 levels（t），q 是具有一组描述性特征的查询实例，q[1],...,q[m]。"
        }
    },
    {
        "translation": {
            "en": "hold-out test set, 533, 535, 540, 579, 719",
            "zh": "保持测试仪，533、535、540、579、719"
        }
    },
    {
        "translation": {
            "en": "9.1   Big Idea",
            "zh": "9.1 大创意"
        }
    },
    {
        "translation": {
            "en": "For example, in a banking scenario, we might include a ratio between a loan applicant’s salary and the amount for which they are requesting a loan rather than including these two values themselves.",
            "zh": "例如，在银行业务场景中，我们可能会包括贷款申请人的工资与他们申请贷款的金额之间的比率，而不是包括这两个值本身。"
        }
    },
    {
        "translation": {
            "en": "This arises from the fact that the tests carried out at each node in the tree are performed in the context of the results of the tests on the other descriptive features that were tested at the preceding nodes on the path from the root.",
            "zh": "这是因为在树中的每个节点上执行的测试是在对其他描述性特征的测试结果的上下文中执行的，这些描述性特征在根路径上的先前节点上进行了测试。"
        }
    },
    {
        "translation": {
            "en": "In our example, CORE-TEMP describes the core temperature of the patient (which can be low or high), and STABLE-TEMP describes whether the patient’s current temperature is stable (true or false).",
            "zh": "在我们的示例中，CORE-TEMP 描述患者的核心温度（可低或高），STABLE-TEMP 描述患者当前温度是否稳定（真或假）。"
        }
    },
    {
        "translation": {
            "en": "Widdows (2004) provides a very readable and interesting introduction to geometry and linguistic meaning; see, in particular, Chapter 4 for an excellent introduction to similarity and distance.",
            "zh": "Widdows（2004）对几何学和语言意义进行了非常可读和有趣的介绍;特别是，参见第 4 章，了解相似性和距离的精彩介绍。"
        }
    },
    {
        "translation": {
            "en": "-3.82398",
            "zh": "-3.82398"
        }
    },
    {
        "translation": {
            "en": "The basis of data exploration is statistics. Montgomery and Runger (2010) is an excellent applied introductory text in statistics and covers, in more detail, all the basic measures used in this chapter. It also covers advanced topics, such as the χ2 test and ANOVA test mentioned in the notes for Section 3.5.2[81]. Rice (2006) provides a good—if more theoretical—treatment of statistics.",
            "zh": "数据探索的基础是统计。Montgomery and Runger （2010）是一本优秀的统计学应用介绍性著作，更详细地涵盖了本章中使用的所有基本措施。它还涵盖了高级主题，例如第 3.5.2 节注释中提到的 χ2 检验和方差分析检验[81]。Rice（2006）对统计学进行了很好的理论化处理。"
        }
    },
    {
        "translation": {
            "en": "where t1…tn is a set of n expected target values, and 𝕄(d1)…𝕄(dn) is a set of n predictions for a set of test instances, d1…dn. We modify this very slightly to give us the mean squared error performance measure, which captures the average difference between the expected target values in the test set and the values predicted by the model. The mean squared error (MSE) performance measure is defined as",
            "zh": "其中 t1...tn 是 n 个预期目标值的集合，M（d1）...M（dn） 是一组测试实例的 n 个预测，d1...DN中。我们对此进行了非常轻微的修改，为我们提供了均方误差性能度量，该度量捕获了测试集中的预期目标值与模型预测的值之间的平均差异。均方误差 （MSE） 性能度量定义为"
        }
    },
    {
        "translation": {
            "en": "While this random action selection policy is good for learning, pursuing it into the second week of Conor’s stay would seem like a bad idea.",
            "zh": "虽然这种随机行动选择策略有利于学习，但将其延续到康纳逗留的第二周似乎是一个坏主意。"
        }
    },
    {
        "translation": {
            "en": "One feature of equal-width binning is that it can result in a very uneven distribution of instances across the bins, with some bins containing a large number of instances and other bins being nearly empty.",
            "zh": "等宽分箱的一个特点是，它可能导致实例在箱中的分布非常不均匀，一些箱包含大量实例，而其他箱几乎是空的。"
        }
    },
    {
        "translation": {
            "en": "The aggregate confusion matrix, generated by summing together the corresponding cells in the individual confusion matrices for each fold, is shown at the bottom of Table 9.4[544].",
            "zh": "通过将每个折叠的各个混淆矩阵中的相应单元格相加而生成的聚合混淆矩阵显示在表9.4[544]的底部。"
        }
    },
    {
        "translation": {
            "en": "Clamp transformation (manual: 0, 80,000)",
            "zh": "夹具转换（手动：0,80,000）"
        }
    },
    {
        "translation": {
            "en": "The left action is the most attractive in this instance on the basis of its Q value.",
            "zh": "在这种情况下，左边的动作最有吸引力，因为它的 Q 值。"
        }
    },
    {
        "translation": {
            "en": "The reason is that both these neurons happen to have large negative weights on at least one of their inputs.",
            "zh": "原因是这两个神经元碰巧在它们的至少一个输入上有很大的负权重。"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the error of the network for this example using the new weights, compared with using the original weights.",
            "zh": "与使用原始权重相比，使用新权重计算此示例中网络误差的减少量。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.31[480] illustrates the concept of a local receptive field in a neural network.",
            "zh": "图8.31[480]说明了神经网络中局部感受野的概念。"
        }
    },
    {
        "translation": {
            "en": "This ensures that there are H neurons in the layers in these gates.",
            "zh": "这确保了这些门的层中有 H 神经元。"
        }
    },
    {
        "translation": {
            "en": "The design of the ID3 algorithm is based on the assumption that a correct decision tree for a domain will classify instances from that domain in the same proportion as the target level occurs in the domain.",
            "zh": "ID3 算法的设计基于以下假设：域的正确决策树将按照域中目标级别出现的相同比例对来自该域的实例进行分类。"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the call minutes used by the customer has changed from last month to this month",
            "zh": "客户使用的通话分钟数从上个月到本月的变化百分比"
        }
    },
    {
        "translation": {
            "en": "Consequently, in this schematic we have abstracted away from some of the details of a network architecture: for example, the layers of neurons are represented by rectangles with rounded corners; and the (multiple) connections between neurons in different layers are represented by single arrows labeled with the name of the weight matrix for the weights on those connections.",
            "zh": "因此，在这个示意图中，我们抽象出网络架构的一些细节：例如，神经元层由圆角的矩形表示;不同层中神经元之间的（多个）连接由单个箭头表示，箭头标有这些连接上权重矩阵的名称。"
        }
    },
    {
        "translation": {
            "en": "1.6 The Predictive Data Analytics Project Lifecycle: CRISP-DM",
            "zh": "1.6 预测数据分析项目生命周期：CRISP-DM"
        }
    },
    {
        "translation": {
            "en": "Just like the proverbial cat, there is more than one way to skin a probability problem!",
            "zh": "就像众所周知的猫一样，概率问题的方法不止一种！"
        }
    },
    {
        "translation": {
            "en": "In order to calculate and backpropagate the δs for d2 through the network, we need the ∂a/∂z for each neuron in the network for this example, Table 8.11[442] lists these values; because all the neurons use a rectified linear activation function, the ∂a/∂z are either 0 or 1 (as per derivative of the rectified linear function given in Equation 8.43[437]).",
            "zh": "为了通过网络计算和反向传播 d2 的 δs，我们需要网络中每个神经元的 ∂a/∂z，表 8.11[442] 列出了这些值;因为所有的神经元都使用整流线性激活函数，所以∂a/∂z要么是0，要么是1（根据等式8.43[437]中给出的整流线性函数的导数）。"
        }
    },
    {
        "translation": {
            "en": "So, when a loan is repaid in full, the profit made by the company is usually $140.",
            "zh": "因此，当贷款全额偿还时，公司的利润通常为 140 美元。"
        }
    },
    {
        "translation": {
            "en": "However, these approaches are more complex, take a longer time to train, and are harder to interpret than the simpler approaches that we have presented.",
            "zh": "然而，这些方法比我们介绍的更简单的方法更复杂，需要更长的时间来训练，并且更难解释。"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_U_G",
            "zh": "DEREDDIFF_U_G"
        }
    },
    {
        "translation": {
            "en": "The relationship between probability-based and information-based learning is simply that the amount of information provided by an observation—such as a descriptive feature taking a particular value—is reflected in the difference between the prior and posterior probabilities caused by the observation.",
            "zh": "基于概率的学习和基于信息的学习之间的关系很简单，即观察提供的信息量（例如采用特定值的描述性特征）反映在观察引起的先验概率和后验概率之间的差异中。"
        }
    },
    {
        "translation": {
            "en": "The gradient descent algorithm for training multivariable regression models is formally presented in Algorithm 4[326].",
            "zh": "用于训练多变量回归模型的梯度下降算法在算法4[326]中正式提出。"
        }
    },
    {
        "translation": {
            "en": "For clarity there are some extra notational conventions used in Chapter 11[637] on reinforcement learning (this chapter also heavily uses the notation from the probability chapter).",
            "zh": "为了清楚起见，在第11章[637]中，关于强化学习，使用了一些额外的符号约定（本章也大量使用了概率一章中的符号）。"
        }
    },
    {
        "translation": {
            "en": "Table 6.4",
            "zh": "表 6.4"
        }
    },
    {
        "translation": {
            "en": "We start off by playing a game.",
            "zh": "我们从玩游戏开始。"
        }
    },
    {
        "translation": {
            "en": "One thing to note is that many of the rules and techniques we presented were different ways of achieving the same thing—for example, we can calculate P(h) by simple counting, by summing out from a full joint probability distribution, or by using the Theorem of Total Probability.",
            "zh": "需要注意的一点是，我们提出的许多规则和技术都是实现同一目标的不同方法——例如，我们可以通过简单的计数、从完整的联合概率分布中求和或使用总概率定理来计算 P（h）。"
        }
    },
    {
        "translation": {
            "en": "dot product, 216, 320, 342, 385, 773",
            "zh": "点积， 216， 320， 342， 385， 773"
        }
    },
    {
        "translation": {
            "en": "Descriptive statistics provides us with a range of tools that we can use to formally measure variation and so distinguish between the sets of heights in the two basketball teams.",
            "zh": "描述性统计为我们提供了一系列工具，我们可以用这些工具来正式测量变化，从而区分两支篮球队的身高集。"
        }
    },
    {
        "translation": {
            "en": "integration, 276",
            "zh": "集成，276"
        }
    },
    {
        "translation": {
            "en": "6. The full text of the EU Treaty of Amsterdam is available at www.europa.eu/eu-law/decision-making/treaties/pdf/treaty_of_amsterdam/treaty_of_amsterdam_en.pdf.",
            "zh": "6. 《欧盟阿姆斯特丹条约》全文见 www.europa.eu/eu-law/decision-making/treaties/pdf/treaty_of_amsterdam/treaty_of_amsterdam_en.pdf。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS and AMOUNT RECEIVED all seem to have unusually high maximum values, especially when compared to their median and 3rd quartile values.",
            "zh": "CLAIMS 和 AMOUNT RECEIVED 似乎都具有异常高的最大值，尤其是与它们的中位数和第 3 个四分位数值相比。"
        }
    },
    {
        "translation": {
            "en": "7. Most consumer digital cameras capture full-color images by capturing separate images on red, green, and blue imaging sensors and combining these. The colors red, green, and blue are known as photometric bands. The photometric bands captured by the SDSS imaging camera are the same as these bands; they are just defined on different parts of the spectrum.",
            "zh": "7. 大多数消费类数码相机通过在红色、绿色和蓝色成像传感器上捕获单独的图像并将它们组合在一起来捕获全彩色图像。红色、绿色和蓝色被称为光度波段。SDSS成像相机捕获的光度波段与这些波段相同;它们只是在频谱的不同部分定义。"
        }
    },
    {
        "translation": {
            "en": "Table 9.9",
            "zh": "表 9.9"
        }
    },
    {
        "translation": {
            "en": "Target level imbalance typically arises through either absolute rarity or relative rarity of the minority target levels.",
            "zh": "目标水平的不平衡通常是由于少数目标水平的绝对稀有性或相对稀有性而产生的。"
        }
    },
    {
        "translation": {
            "en": "0.3073",
            "zh": "0.3073"
        }
    },
    {
        "translation": {
            "en": "Although the performance of the two-stage model was better than the performance of the simpler 5-level model, it still did a very poor job of distinguishing between the different spiral galaxy types.",
            "zh": "尽管两级模型的性能优于简单的五级模型，但它在区分不同的螺旋星系类型方面仍然做得很差。"
        }
    },
    {
        "translation": {
            "en": "This set of domain concepts was felt to be extensive enough to cover all the characteristics that were likely to contribute to a customer’s likelihood to churn and is shown in Figure 12.1[690].",
            "zh": "这组领域概念被认为足够广泛，足以涵盖可能导致客户流失的所有特征，如图 12.1[690] 所示。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.14",
            "zh": "图 4.14"
        }
    },
    {
        "translation": {
            "en": "However, it also tells us that the scaling of the variance of z is dependent on the product nin var(W).",
            "zh": "然而，它也告诉我们，z 方差的缩放取决于乘积 nin var（W）。"
        }
    },
    {
        "translation": {
            "en": "4. Lehmann et al. (2003) discusses building prediction models to perform this task.",
            "zh": "4. Lehmann et al. （2003） 讨论了建立预测模型来执行这项任务。"
        }
    },
    {
        "translation": {
            "en": "(a)–(c) Equal-frequency binning of normally distributed data with different numbers of bins; and (d)–(f) the same data binned into the same number of bins using equal-width binning. The dashed lines illustrate the distribution of the original continuous feature values, and the gray boxes represent the bins.",
            "zh": "（a）–（c） 具有不同箱数的正态分布数据的等频分箱;（d）–（f）使用等宽分箱将相同的数据分箱到相同数量的分箱中。虚线表示原始连续要素值的分布，灰色框表示条柱。"
        }
    },
    {
        "translation": {
            "en": "Up to this point we have outlined descriptive statistics that we can use to describe the values in a sample.",
            "zh": "到目前为止，我们已经概述了可用于描述样本中值的描述性统计量。"
        }
    },
    {
        "translation": {
            "en": "WEIGHT: The patient’s weight",
            "zh": "体重：患者的体重"
        }
    },
    {
        "translation": {
            "en": "An understanding of these five equations is a strong basis for understanding the mathematical fundamentals of many areas of scientific modeling. Adding an understanding of how these five equations are used in the machine learning algorithms we have described (ID3, k nearest neighbor, multivariable linear regression with gradient descent, naive Bayes, and the backpropagation of error algorithm) is a strong foundation on which to build a career in predictive data analytics.",
            "zh": "对这五个方程的理解是理解科学建模许多领域的数学基础的坚实基础。了解这五个方程在我们描述的机器学习算法中的使用方式（ID3、k 最近邻、梯度下降的多变量线性回归、朴素贝叶斯和误差算法的反向传播）是建立预测数据分析职业生涯的坚实基础。"
        }
    },
    {
        "translation": {
            "en": "PETROR50_U/G/R/I/Z",
            "zh": "PETROR50_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "This allows us an important reformulation of the chain rule for situations in which conditional independence applies. Recall that the chain rule for calculating the probability that a set of descriptive features, q[1],…,q[m], takes a specific set of values when a target feature, t, takes a specific level, l, is",
            "zh": "这使我们能够对适用条件独立性的情况的连锁规则进行重要的重新表述。回想一下，当目标特征 t 采用特定水平 l 时，用于计算一组描述性特征 q[1],...,q[m] 采用特定值的概率的链式法则"
        }
    },
    {
        "translation": {
            "en": "For all the remaining hidden layers in this network nin = 100, and so this process of scaling the variance of z by 100 × 0.0001 = 0.01 will continue through each of the subsequent hidden layers in this network.",
            "zh": "对于此网络中所有剩余的隐藏层，nin = 100，因此将 z 的方差缩放 100 × 0.0001 = 0.01 的过程将继续通过该网络中的每个后续隐藏层。"
        }
    },
    {
        "translation": {
            "en": "As this example shows, if a neuron k uses the logistic function as its activation function, then we can calculate the term ∂ak/∂zk by simply inputting the weighted sum for the neuron zk into Equation (8.15)[408].",
            "zh": "如这个例子所示，如果神经元 k 使用逻辑函数作为其激活函数，那么我们可以通过简单地将神经元 zk 的加权和输入方程 （8.15）[408] 来计算项 ∂ak/∂zk。"
        }
    },
    {
        "translation": {
            "en": "7. The full discussion of these principles is available at www.oecd.org/sti/ieconomy/privacy.htm.",
            "zh": "7. 有关这些原则的完整讨论，请见 www.oecd.org/sti/ieconomy/privacy.htm。"
        }
    },
    {
        "translation": {
            "en": "Figure A.1",
            "zh": "图 A.1"
        }
    },
    {
        "translation": {
            "en": "0.157248",
            "zh": "0.157248"
        }
    },
    {
        "translation": {
            "en": "Figure 7.5",
            "zh": "图 7.5"
        }
    },
    {
        "translation": {
            "en": "The most common issues in this regard are missing values and outliers, which are both examples of noise in the data.",
            "zh": "这方面最常见的问题是缺失值和异常值，它们都是数据中噪声的示例。"
        }
    },
    {
        "translation": {
            "en": "Batch gradient descent14 involves calculating the error gradients for each weight for all the examples in a dataset and summing the gradients for each weight, and only then updating the weights using the summed error gradients calculated over the entire dataset.",
            "zh": "批量梯度下降14 涉及计算数据集中所有示例的每个权重的误差梯度，并将每个权重的梯度求和，然后才使用在整个数据集上计算的误差梯度求和来更新权重。"
        }
    },
    {
        "translation": {
            "en": "The fact that the input gate has two paths of processing means that it uses two separate weight matrices to process the input, one on each processing path.",
            "zh": "输入门有两条处理路径，这意味着它使用两个独立的权重矩阵来处理输入，每个处理路径上一个。"
        }
    },
    {
        "translation": {
            "en": "8.26   The internal dynamics of the network in Figure 8.22[450], using ReLUs, during the first training iteration when the weights were initialized using He initialization.",
            "zh": "8.26 图 8.22[450] 中网络的内部动力学，使用 ReLU 在第一次训练迭代期间，当权重使用 He 初始化进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "The set of random variables in a domain maps to the set of features in a dataset (both descriptive and target). DICE1 and DICE2 are the equivalent of random variables.",
            "zh": "域中的随机变量集映射到数据集中的要素集（描述性和目标性）。DICE1 和 DICE2 等价于随机变量。"
        }
    },
    {
        "translation": {
            "en": "kernel function, 366, 373",
            "zh": "内核函数，366,373"
        }
    },
    {
        "translation": {
            "en": "8.5   The ∂a/∂z for each neuron for Example 2 rounded to four decimal places.",
            "zh": "8.5 例 2 中每个神经元的 ∂a/∂z 四舍五入到小数点后四位。"
        }
    },
    {
        "translation": {
            "en": "The second equation defines how we compute the entropy remaining after we partition the dataset using a particular descriptive feature d. When we partition the dataset using the descriptive feature d, we create a number of partitions (or sets) d=l1…d=lk, where l1…lk are the k levels that feature d can take.",
            "zh": "第二个方程定义了我们如何计算使用特定描述性特征 d 对数据集进行分区后的剩余熵。当我们使用描述性特征 d 对数据集进行分区时，我们会创建许多分区（或集合）d=l1...d=lk，其中 l1...LK 是功能 D 可以采用的 K 级。"
        }
    },
    {
        "translation": {
            "en": "Table 6.9[270] illustrates how a naive Bayes model would calculate the scores for each candidate target level for this query using the smoothed probabilities from Table 6.8[269]. Using our smoothed probabilities, we are able to calculate a score for both target levels: 0.0036 for true and 0.0043 for false. The target level false has the highest score (if only marginally) and is the MAP prediction for this query. Therefore, our naive Bayes model will predict that this loan application is not fraudulent.",
            "zh": "表6.9[270]说明了朴素贝叶斯模型如何使用表6.8[269]中的平滑概率计算此查询的每个候选目标水平的分数。使用我们的平滑概率，我们能够计算出两个目标水平的分数：0.0036 表示真值，0.0043 表示假值。目标级别 false 的得分最高（如果只是略微），并且是此查询的 MAP 预测。因此，我们的朴素贝叶斯模型将预测该贷款申请不是欺诈性的。"
        }
    },
    {
        "translation": {
            "en": "information-based learning, 19, 117",
            "zh": "基于信息的学习， 19， 117"
        }
    },
    {
        "translation": {
            "en": "Such a network configuration is likely to result in the network overfitting the training data (i.e., memorizing all the training examples, including the noise, rather than learning the general patterns in the data).",
            "zh": "这样的网络配置可能会导致网络过度拟合训练数据（即，记住所有训练示例，包括噪声，而不是学习数据中的一般模式）。"
        }
    },
    {
        "translation": {
            "en": "Although we can’t easily draw feature spaces beyond three dimensions, the ideas underpinning them remain the same.",
            "zh": "尽管我们不能轻易地绘制三维以外的特征空间，但支撑它们的想法保持不变。"
        }
    },
    {
        "translation": {
            "en": "(a) A 3D surface plot and (b) a bird’s-eye view contour plot of the error surface for the office rentals dataset showing the path that the gradient descent algorithm takes toward the best-fit model.",
            "zh": "（a） 办公室租赁数据集的 3D 表面图和 （b） 误差表面的鸟瞰视图等值线图，显示了梯度下降算法通往最佳拟合模型的路径。"
        }
    },
    {
        "translation": {
            "en": "Instances d1 and d9 are duplicated in this sample, and instances d3 and d10 are not included at all.",
            "zh": "此示例中重复了实例 d1 和 d9，完全不包括实例 d3 和 d10。"
        }
    },
    {
        "translation": {
            "en": "inverted dropout, 474, 475, 530",
            "zh": "倒置压差，474、475、530"
        }
    },
    {
        "translation": {
            "en": "There are no labels, so this data is being clustered in an attempt to recognize different activity from this simple data stream.",
            "zh": "没有标签，因此正在对这些数据进行聚类，以尝试从这个简单的数据流中识别不同的活动。"
        }
    },
    {
        "translation": {
            "en": "(a) The class conditional densities for two classes (l1,l2) with a single descriptive feature d. The height of each curve reflects the density of the instances from that class for that value of d. (b) The class posterior probabilities plotted for each class for different values of d. Notice that the class posterior probability P(t = l1|d) is not affected by the multimodal structure of the corresponding class conditional density P(d|t = l1).",
            "zh": "（a） 具有单个描述性特征 d 的两个类 （l1，l2） 的类条件密度。每条曲线的高度反映了该类中该 d 值的实例的密度。 （b） 针对不同的 d 值为每个类绘制的类后验概率。请注意，类后验概率 P（t = l1|d） 不受相应类条件密度 P（d|t = l1） 的多模态结构的影响。"
        }
    },
    {
        "translation": {
            "en": "Other approaches to efficient memory access have been developed, for example, locality sensitivity hashing, R-Trees, B-Trees, M-Trees, and VoRTrees, among others.",
            "zh": "已经开发了其他高效内存访问的方法，例如局部敏感度哈希、R 树、B 树、M 树和 VoRTrees 等。"
        }
    },
    {
        "translation": {
            "en": "The samples have then been manually categorized by clinicians as either benign or malignant.19 The descriptive features in this dataset are defined as follows:",
            "zh": "然后，临床医生手动将样本分类为良性或恶性.19 该数据集中的描述性特征定义如下："
        }
    },
    {
        "translation": {
            "en": "Business Understanding, 16, 19, 24, 28, 46, 685, 704, 730",
            "zh": "商业理解， 16， 19， 24， 28， 46， 685， 704， 730"
        }
    },
    {
        "translation": {
            "en": "Table 8.14",
            "zh": "表 8.14"
        }
    },
    {
        "translation": {
            "en": "kernel trick, 366, 373",
            "zh": "内核技巧，366,373"
        }
    },
    {
        "translation": {
            "en": "The reason is that to ensure that the weight updates for all the weights on the network are on a similar scale.",
            "zh": "原因是要确保网络上所有权重的权重更新都处于相似的比例上。"
        }
    },
    {
        "translation": {
            "en": "This vanishing z values dynamic is a result of the fact that the z values are calculated using a weighted sum, and in this network configuration the relationship between the number of inputs to each weighted sum and the variances of the weights is such that the variance of the z values is scaled down at each layer in the network.",
            "zh": "这种 z 值的动态消失是由于 z 值是使用加权和计算的，并且在此网络配置中，每个加权和的输入数与权重方差之间的关系使得 z 值的方差在网络中的每一层都按比例缩小。"
        }
    },
    {
        "translation": {
            "en": "4.13   An example validation set for the post-operative patient routing task.",
            "zh": "4.13 术后患者路由任务的示例验证集。"
        }
    },
    {
        "translation": {
            "en": "true negative, 537",
            "zh": "真阴性，537"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, Brian. 2009. Agent based modeling in computer graphics and games. In Encyclopedia of complexity andsystems science, ed. R. A. Meyers. Dublin Institute of Technology.",
            "zh": "麦克·纳梅，布莱恩。2009. 计算机图形学和游戏中基于智能体的建模.在复杂性和系统科学百科全书中，R. A. Meyers编辑。都柏林理工学院。"
        }
    },
    {
        "translation": {
            "en": "An event is any subset of an experiment. An event may describe an assignment of values to all the features in the domain (e.g., a full row in the dataset) or an assignment to one or more features in the domain. DICE1 = is an example of an event. DICE1 = , DICE2 = is also an event.",
            "zh": "事件是实验的任何子集。事件可以描述对域中所有要素的值分配（例如，数据集中的一整行）或对域中的一个或多个要素的赋值。DICE1 = 是事件的示例。DICE1 = ， DICE2 = 也是一个事件。"
        }
    },
    {
        "translation": {
            "en": "The course “P.D.A.",
            "zh": "课程“P.D.A."
        }
    },
    {
        "translation": {
            "en": "Prediction speed: How quickly can a model make predictions?",
            "zh": "预测速度：模型做出预测的速度有多快？"
        }
    },
    {
        "translation": {
            "en": "Individuals can belong to one of three states: SUSCEPTIBLE, INFECTED, or RECOVERED (these are often referred to as S-I-R models).",
            "zh": "个体可以属于以下三种状态之一：易感、感染或康复（这些通常称为 S-I-R 模型）。"
        }
    },
    {
        "translation": {
            "en": "The expansion of the sum of squared errors loss function, L2, that we gave in Equation (7.5)[316] changes slightly to reflect the new regression equation",
            "zh": "我们在方程（7.5）[316]中给出的平方误差损失函数和的展开略有变化，以反映新的回归方程"
        }
    },
    {
        "translation": {
            "en": "This model is said to underfit the data as it is not complex enough to fully capture the relationship between the descriptive feature and the target feature.",
            "zh": "据说该模型对数据拟合不足，因为它不够复杂，无法完全捕获描述性特征和目标特征之间的关系。"
        }
    },
    {
        "translation": {
            "en": "5.16   The coordinate systems defined by the Mahalanobis distance using the covariance matrix for the dataset in Figure 5.15(c)[219] using three different origins: (a) (50, 50); (b) (63,71); and (c) (42, 35). The ellipses in each figure plot the 1, 3, and 5 unit distance contours.",
            "zh": "5.16 使用图5.15（c）[219]中数据集的协方差矩阵定义的马氏距离的坐标系，使用三个不同的原点：（a）（50,50）;（b）（63,71）;以及（c）（42、35）。每个图中的椭圆绘制了 1、3 和 5 单位距离等值线。"
        }
    },
    {
        "translation": {
            "en": "This means that even though the network is unrolled through three time-steps, it still has only 3 weight matrices (not 9).",
            "zh": "这意味着即使网络通过三个时间步长展开，它仍然只有 3 个权重矩阵（而不是 9 个）。"
        }
    },
    {
        "translation": {
            "en": "Data Understanding: Once the manner in which predictive data analytics will be used to address a business problem has been decided, it is important that the data analyst fully understand the different data sources available within an organization and the different kinds of data that are contained in these sources.",
            "zh": "数据理解：一旦确定了使用预测数据分析来解决业务问题的方式，数据分析师就必须充分了解组织内可用的不同数据源以及这些源中包含的不同类型的数据。"
        }
    },
    {
        "translation": {
            "en": "Edwin agreed that it was likely that correlations existed between measurements in the different photometric bands but stressed, however, that differences across these bands would exist and might be quite important in predicting galaxy morphology.",
            "zh": "埃德温同意不同光度波段的测量结果之间可能存在相关性，但他强调，这些波段之间的差异将存在，并且可能在预测星系形态方面非常重要。"
        }
    },
    {
        "translation": {
            "en": "Also, we may have to use some proxy features to capture something that is closely related to a domain concept when direct measurement is not possible.",
            "zh": "此外，当无法直接测量时，我们可能不得不使用一些代理特征来捕获与领域概念密切相关的内容。"
        }
    },
    {
        "translation": {
            "en": "The important characteristic of this test set was that it was not used in the process of training the model.",
            "zh": "该测试集的重要特征是，在训练模型的过程中没有使用它。"
        }
    },
    {
        "translation": {
            "en": "Table 9.3",
            "zh": "表 9.3"
        }
    },
    {
        "translation": {
            "en": "-0.189800",
            "zh": "-0.189800"
        }
    },
    {
        "translation": {
            "en": "To illustrate the effect that switching to a rectified linear activation function has on a network, we step through the forward and backward pass of the backpropagation algorithm for d2.",
            "zh": "为了说明切换到整流线性激活函数对网络的影响，我们逐步介绍了 d2 的反向传播算法的前向和后向传递。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.13[90] illustrates the effect of using different numbers of bins.11 In this example, the dashed line represents a multimodal distribution from which a set of continuous feature values has been generated.",
            "zh": "图 3.13[90] 说明了使用不同数量的条柱的效果.11 在此示例中，虚线表示多模态分布，从中生成了一组连续特征值。"
        }
    },
    {
        "translation": {
            "en": "In these cases the error gradients are able to be backpropagated through the neuron without scaling.",
            "zh": "在这些情况下，误差梯度能够在神经元中反向传播而不会缩放。"
        }
    },
    {
        "translation": {
            "en": "The function f(x) = 2x + 3 is known as a linear function because the output is a combination of only additions and multiplications1 involving x.",
            "zh": "函数 f（x） = 2x + 3 被称为线性函数，因为输出仅是涉及 x 的加法和乘法1 的组合。"
        }
    },
    {
        "translation": {
            "en": "Other algorithms, such as the nearest neighbor algorithm, which use all the descriptive features when making a prediction, are particularly sensitive to the curse.",
            "zh": "其他算法，例如最近邻算法，在进行预测时使用所有描述性特征，对诅咒特别敏感。"
        }
    },
    {
        "translation": {
            "en": "Typically, stochastic gradient descent still works because generally descending the error gradient on an individual example will move the weight in a similar direction as descending the gradient over the entire dataset.",
            "zh": "通常，随机梯度下降仍然有效，因为通常对单个示例的误差梯度进行降序会使权重向与在整个数据集上降序类似的方向移动。"
        }
    },
    {
        "translation": {
            "en": "Therefore, the performance measured on this test set should be a good indicator of how well the model will perform on future unseen data for which it will be used to make predictions after deployment.",
            "zh": "因此，在此测试集上测量的性能应该是一个很好的指标，表明模型在未来看不见的数据上的表现如何，这些数据将在部署后用于进行预测。"
        }
    },
    {
        "translation": {
            "en": "During a trial period, half of the patients, the treatment group, are given the new drug, and the other half, the control group, are given a placebo (essentially a fake drug that has no actual medical effect).",
            "zh": "在试验期间，一半的患者（治疗组）服用新药，另一半（对照组）服用安慰剂（本质上是一种没有实际医疗效果的假药）。"
        }
    },
    {
        "translation": {
            "en": "As a rough rule of thumb, we should have around 2m instances for m descriptive features.",
            "zh": "作为一个粗略的经验法则，我们应该有大约 2m 个实例来描述性特征。"
        }
    },
    {
        "translation": {
            "en": "valid data, 63, 94",
            "zh": "有效数据， 63， 94"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m descriptive features, d[1]…d[m], and w[0]…w[m] are (m + 1) weights. We can make Equation (7.8)[320] look a little neater by inventing a dummy descriptive feature, d[0], that is always equal to 1. This then gives us",
            "zh": "其中 d 是 m 描述性特征的向量，d[1]...d[m] 和 w[0]...w[m] 是 （m + 1） 权重。我们可以通过发明一个始终等于 1 的虚拟描述特征 d[0] 来使方程 （7.8）[320] 看起来更整洁一些。这给了我们"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm for building decision trees and the gradient descent algorithm for building regression models are two examples of this type of approach.",
            "zh": "用于构建决策树的 ID3 算法和用于构建回归模型的梯度下降算法是此类方法的两个示例。"
        }
    },
    {
        "translation": {
            "en": "It is much simpler to construct a Bayesian network using a hybrid approach, where the topology of the network is given to the learning algorithm, and the learning task involves inducing the CPT entries from the data.",
            "zh": "使用混合方法构建贝叶斯网络要简单得多，其中网络的拓扑结构被赋予学习算法，学习任务涉及从数据中诱导出 CPT 条目。"
        }
    },
    {
        "translation": {
            "en": "The alarm on your house is designed to be triggered if a burglar breaks into your house, but sometimes it can be set off by your cat coming into the house, and sometimes it might not be triggered even if a burglar breaks in (it could be faulty or the burglar might be very good).",
            "zh": "您家的警报器设计为在窃贼闯入您的房子时触发，但有时它可以被您的猫进入房屋引发，有时即使窃贼闯入也可能不会被触发（它可能有故障或窃贼可能非常好）。"
        }
    },
    {
        "translation": {
            "en": "Q-learning is referred to as off-policy learning, as when the update to the value function is made the behavior policy (for example, ε-greedy action selection) to select the action used to calculate the expected future return. Rather, the agent uses a greedy policy—it is assumed that the agent will always take the best possible next action (based on the current action-value table). This leads Q-learning to be optimistic about what will happen in the future.",
            "zh": "Q-learning被称为非策略学习，因为当对价值函数进行更新时，行为策略（例如，ε贪婪行为选择）选择用于计算预期未来回报的行动。相反，代理使用贪婪策略 - 假设代理将始终采取最佳的下一步操作（基于当前操作值表）。这导致Q-learning对未来发生的事情持乐观态度。"
        }
    },
    {
        "translation": {
            "en": "We have also simplified the RGB values to be only 1s or 0s, and similarly we have selected values for the filter weight that, hopefully, make it easier to follow the flow of the data processing (rather than filter values that encode meaningful feature detectors).",
            "zh": "我们还将 RGB 值简化为仅为 1 或 0，同样，我们选择了滤波器权重值，希望能够更轻松地跟踪数据处理流程（而不是编码有意义的特征检测器的滤波器值）。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.15[219] illustrates why this is important.",
            "zh": "图5.15[219]说明了为什么这很重要。"
        }
    },
    {
        "translation": {
            "en": "Finally, Figure 3.13(c)[90] illustrates what happens when we used 60 bins.",
            "zh": "最后，图 3.13（c）[90] 说明了当我们使用 60 个箱子时会发生什么。"
        }
    },
    {
        "translation": {
            "en": "It is paramount that, when tasked with creating a predictive model, we fully understand the business problem that this model is being constructed to address and ensure that it does address it.",
            "zh": "至关重要的是，在创建预测模型时，我们完全了解构建该模型所要解决的业务问题，并确保它确实解决了它。"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks use a graph-based representation to encode the structural relationships (such as direct influence and conditional independence) between subsets of features in a domain.",
            "zh": "贝叶斯网络使用基于图的表示来编码域中特征子集之间的结构关系（例如直接影响和条件独立性）。"
        }
    },
    {
        "translation": {
            "en": "Ross learned that AT had reasonably sophisticated transactional systems for recording recent call activity and billing information.",
            "zh": "Ross 了解到，AT 拥有相当复杂的交易系统，用于记录最近的呼叫活动和计费信息。"
        }
    },
    {
        "translation": {
            "en": "Models",
            "zh": "模型"
        }
    },
    {
        "translation": {
            "en": "The reasonably large dataset that Ross had to begin with, which in turn led to a reasonably large validation partition, meant that reduced error pruning was appropriate in this case.9 Figure 12.5[699] shows the tree resulting from this training iteration.",
            "zh": "Ross 必须从相当大的数据集开始，这反过来又导致了相当大的验证分区，这意味着在这种情况下减少错误修剪是合适的.9 图 12.5[699] 显示了此训练迭代产生的树。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(a)[453] illustrates the distribution of weight values across each of the five hidden laters immediately after initialization.",
            "zh": "图 8.23（a）[453] 说明了初始化后立即在五个隐藏的后面每个后面的权重值的分布。"
        }
    },
    {
        "translation": {
            "en": "The differentiation is performed in two steps. First, treating g(x) as a unit, we differentiate f(g(x)) with respect to g(x), and then we differentiate g(x) with respect to x, in both cases using the differentiation rules from the previous section. The derivative of f(g(x)) with respect to x is the product of these two pieces.",
            "zh": "分两步进行区分。首先，将 g（x） 视为一个单位，我们根据 g（x） 对 f（g（x）） 进行微分，然后对 x 对 g（x） 进行微分，在这两种情况下都使用上一节的微分规则进行微分。f（g（x）） 相对于 x 的导数是这两部分的乘积。"
        }
    },
    {
        "translation": {
            "en": "7.3   (a) A 3D surface plot and (b) a bird’s-eye view contour plot of the error surface generated by plotting the sum of squared errors for the office rentals training set for each possible combination of values for w [0] (from the range [–10, 20]) and w [1] (from the range [–2,3]).",
            "zh": "7.3 （a） 3D 曲面图和 （b） 误差曲面的鸟瞰图，通过绘制 w [0]（范围 [–10， 20]）和 w [1]（范围 [–2,3]）的每种可能值组合的办公室租赁训练集的平方误差总和生成。"
        }
    },
    {
        "translation": {
            "en": "flag features, 35",
            "zh": "标记特征， 35"
        }
    },
    {
        "translation": {
            "en": "Table 3.4",
            "zh": "表 3.4"
        }
    },
    {
        "translation": {
            "en": "The clustering returned by the k-means clustering algorithm, however, can accurately find these intuitive clusterings only for the blobs dataset.",
            "zh": "但是，k-means 聚类分析算法返回的聚类只能为 blob 数据集准确找到这些直观的聚类。"
        }
    },
    {
        "translation": {
            "en": "In general, evaluating the feasibility of an analytics solution in terms of its data requirements involves aligning the following issues with the requirements of the analytics solution:",
            "zh": "通常，根据数据要求评估分析解决方案的可行性涉及将以下问题与分析解决方案的要求保持一致："
        }
    },
    {
        "translation": {
            "en": "This distance is indicated by the vertical dotted line in Figure 9.13[564], from which it is clear that the K-S statistic is the largest distance between the positive and negative cumulative distributions.",
            "zh": "该距离由图 9.13[564] 中的垂直虚线表示，从中可以清楚地看出 K-S 统计量是正分布和负累积分布之间的最大距离。"
        }
    },
    {
        "translation": {
            "en": "For example, Ross learned that the retention team believed that one of the main reasons customers churned was the availability of new, high-end handsets at other networks.",
            "zh": "例如，Ross 了解到，客户客户流失的主要原因之一是其他网络上有新的高端手机。"
        }
    },
    {
        "translation": {
            "en": "In a typical scenario with two target levels, a prediction score in the range [0,1] is generated by a model, and a threshold of 0.5 is used to convert this score into a categorical prediction as follows:",
            "zh": "在具有两个目标水平的典型场景中，模型生成 [0,1] 范围内的预测分数，并使用阈值 0.5 将该分数转换为分类预测，如下所示："
        }
    },
    {
        "translation": {
            "en": "There is, however, a reliable approach that the hiker can take that will guide her to the bottom (assuming, somewhat ideally, that the valley is convex and has a global minimum).",
            "zh": "然而，徒步旅行者可以采取一种可靠的方法，将她引导到底部（假设，在某种程度上，山谷是凸的并且具有全球最小值）。"
        }
    },
    {
        "translation": {
            "en": "19. See De Bruyne et al. (2011) for an example of machine learning models being used for this task.",
            "zh": "19. 参见De Bruyne et al. （2011）关于用于此任务的机器学习模型的示例。"
        }
    },
    {
        "translation": {
            "en": "For example, consider an input feature recording salaries in dollars; this feature could have a spread of values in the range of millions or more.",
            "zh": "例如，考虑以美元记录工资的输入要素;此功能的值分布可能在数百万或更多范围内。"
        }
    },
    {
        "translation": {
            "en": "HEIGHT: The patient’s height",
            "zh": "身高：患者的身高"
        }
    },
    {
        "translation": {
            "en": "The algorithm then continues merging clusters until only a single cluster containing all instances remains.",
            "zh": "然后，该算法继续合并集群，直到只剩下包含所有实例的单个集群。"
        }
    },
    {
        "translation": {
            "en": "3.9   Exercises",
            "zh": "3.9 练习"
        }
    },
    {
        "translation": {
            "en": "Focusing on the top cell of column 7, we see the value 113,370.05.",
            "zh": "聚焦于第 7 列的顶部单元格，我们看到值 113,370.05。"
        }
    },
    {
        "translation": {
            "en": "Clustering is a technique that partitions the instances in a dataset into groups, or clusters, that are similar to each other.",
            "zh": "聚类分析是一种将数据集中的实例划分为彼此相似的组或聚类的技术。"
        }
    },
    {
        "translation": {
            "en": "Although k can be set to any value, 10-fold cross validation is probably the most common variant used in practice.",
            "zh": "虽然 k 可以设置为任何值，但 10 倍交叉验证可能是实践中最常用的变体。"
        }
    },
    {
        "translation": {
            "en": "The first distinction between models that we will discuss is the distinction between parametric and non-parametric models.",
            "zh": "我们将讨论的模型之间的第一个区别是参数模型和非参数模型之间的区别。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, if ai > ti, we know that we should decrease the output ai. Therefore,",
            "zh": "此外，如果 ai > ti，我们知道我们应该减少输出 ai。因此"
        }
    },
    {
        "translation": {
            "en": "Predictive analytics models can help professionals make better diagnoses by leveraging large collections of historical examples at a scale beyond anything one individual would see over his or her career.",
            "zh": "预测分析模型可以帮助专业人员通过利用大量历史示例来做出更好的诊断，其规模超出了个人在其职业生涯中所能看到的任何东西。"
        }
    },
    {
        "translation": {
            "en": "Bins that contain only a few instances may have extremely small or extremely large conditional probabilities (depending on how the instances are divided when conditioned on the target feature), and these extreme conditional probabilities may bias a model based on the parameters of the binning technique (for example, the number of bins we choose to have) rather than on real distributions in the data.",
            "zh": "仅包含几个实例的 bin 可能具有极小或极大的条件概率（取决于实例在以目标特征为条件时如何划分），并且这些极端条件概率可能会根据分箱技术的参数（例如，我们选择拥有的 bins 数量）而不是数据中的实际分布来偏差模型。"
        }
    },
    {
        "translation": {
            "en": "The weights can either be excitatory (having a positive value, which increases the probability of the neuron activating) or inhibitory (having a negative value, which decreases the probability of a neuron firing).",
            "zh": "权重可以是兴奋性的（具有正值，这会增加神经元激活的概率）或抑制性的（具有负值，这会降低神经元放电的概率）。"
        }
    },
    {
        "translation": {
            "en": "11.4   A portion of the action-value table for the grid world example after 350 episodes of Q-learning have elapsed.",
            "zh": "11.4 经过 350 集 Q 学习后，网格世界示例的动作值表的一部分。"
        }
    },
    {
        "translation": {
            "en": "This would also require that information about claims become available in a suitably timely manner so that the claims investigation process would not be delayed by the model.",
            "zh": "这还要求以适当的方式及时提供关于索赔的信息，以便索赔调查过程不会因模型而延误。"
        }
    },
    {
        "translation": {
            "en": "All is not lost, however, as the concepts of conditional independence and factorization can help us overcome this flaw of our current approach.",
            "zh": "然而，一切都没有丢失，因为条件独立性和因式分解的概念可以帮助我们克服当前方法的这一缺陷。"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 5.6(b)[193] illustrates what happens to the decision boundary in our example feature space when k = 5.",
            "zh": "例如，图 5.6（b）[193] 说明了当 k = 5 时，我们的示例特征空间中的决策边界会发生什么变化。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11(a)[203] illustrates the extent of the revised target hypersphere once these updates have been made.",
            "zh": "图5.11（a）[203]显示了进行这些更新后修订后的目标超球体的范围。"
        }
    },
    {
        "translation": {
            "en": "2. ∂ℰt+1/∂ht: the rate of change of the error of the network at time-step t+1 with respect to changes in the activation vector ht that was propagated forward to the next time-step during the forward pass; and",
            "zh": "2. ∂Et+1/∂ht：在时间步长 t+1 处，网络误差相对于在前向传递期间向前传播到下一个时间步长的激活向量 ht 的变化率;和"
        }
    },
    {
        "translation": {
            "en": "It is extremely important that analytics professionals manage the expectations of their clients during the business understanding process, and agreeing on expected levels of model performance is one of the easiest ways in which to do this.",
            "zh": "分析专业人员在业务理解过程中管理客户的期望非常重要，而就模型性能的预期水平达成一致是实现这一目标的最简单方法之一。"
        }
    },
    {
        "translation": {
            "en": "The first tree that Ross built used an entropy-based information gain as the splitting criterion, limited continuous splits to binary choices, and no pruning.",
            "zh": "Ross 构建的第一棵树使用基于熵的信息增益作为拆分标准，将连续拆分为二元选择，并且没有修剪。"
        }
    },
    {
        "translation": {
            "en": "Using backpropagation, the error gradient at any point in the network is a product of the gradients up to that point; for convenience, we repeat Equation (8.25)[414] here",
            "zh": "使用反向传播，网络中任何一点的误差梯度都是该点的梯度的乘积;为方便起见，我们在这里重复等式（8.25）[414]"
        }
    },
    {
        "translation": {
            "en": "13.4   A data quality report for a subset of the features in the SDSS ABT.",
            "zh": "13.4 SDSS ABT中要素子集的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "6.3 Standard Approach: The Naive Bayes Model",
            "zh": "6.3 标准方法：朴素贝叶斯模型"
        }
    },
    {
        "translation": {
            "en": "Widdows, Dominic. 2004. Geometry and meaning. CSLI Publications.",
            "zh": "寡妇，多米尼克。2004. 几何与意义.CSLI出版物。"
        }
    },
    {
        "translation": {
            "en": "The hard decision boundary given in Equation (7.24)[341] is discontinuous, so is not differentiable, which means we cannot calculate the gradient of the error surface using the derivative.",
            "zh": "方程（7.24）[341]中给出的硬决策边界是不连续的，因此不可微分，这意味着我们不能使用导数计算误差面的梯度。"
        }
    },
    {
        "translation": {
            "en": "9.4.1.5 Out-of-time sampling The sampling methods discussed in the previous section all rely on random sampling from a large dataset in order to create test sets.",
            "zh": "9.4.1.5 超时抽样 上一节中讨论的抽样方法都依赖于从大型数据集中随机抽样来创建测试集。"
        }
    },
    {
        "translation": {
            "en": "How the notation used in the book relates to the elements of a dataset.",
            "zh": "本书中使用的符号与数据集元素的关系。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects use machine learning algorithms to induce prediction models from historical data.",
            "zh": "预测数据分析项目使用机器学习算法从历史数据中引入预测模型。"
        }
    },
    {
        "translation": {
            "en": "Kate explained that at the end of every month, a call list was generated, capturing the customers who had made more than three calls to the AT customer support service in the previous two months.",
            "zh": "Kate解释说，每个月底都会生成一个呼叫列表，捕获在过去两个月中向AT客户支持服务拨打过三次以上电话的客户。"
        }
    },
    {
        "translation": {
            "en": "However, in a simple recurrent network we distinguish the weight matrices on the basis of whether the matrix is on the connections between the input and the hidden layer, the hidden layer and the output, or the activation memory buffer and the hidden layer.",
            "zh": "然而，在一个简单的循环网络中，我们根据矩阵是在输入和隐藏层、隐藏层和输出之间的连接上，还是在激活存储器缓冲区和隐藏层上的连接来区分权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "PSFFLUX_U/G/R/I/Z",
            "zh": "PSFFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "With these baseline performance measures established, Jocelyn turned her attention to feature selection in an effort to improve on these performance scores.",
            "zh": "建立这些基线性能度量后，Jocelyn 将注意力转向功能选择，以努力提高这些性能分数。"
        }
    },
    {
        "translation": {
            "en": "Incorrectly predicting the bad level for a potential borrower who would have repaid the loan in full will result in a negative profit (or loss) of − $140, as the company has forgone potential interest payments.",
            "zh": "错误地预测了本来可以全额偿还贷款的潜在借款人的不良水平将导致 -140 美元的负利润（或损失），因为公司已经放弃了潜在的利息支付。"
        }
    },
    {
        "translation": {
            "en": "Given these good results Ross decided that it was appropriate to present the model to other parts of the business.",
            "zh": "鉴于这些良好的结果，Ross 决定将该模型展示给业务的其他部门是合适的。"
        }
    },
    {
        "translation": {
            "en": "Consequently, developing algorithms to learn the structure of Bayesian networks is an ongoing research challenge.24",
            "zh": "因此，开发算法来学习贝叶斯网络的结构是一项持续的研究挑战24。"
        }
    },
    {
        "translation": {
            "en": "(a) Using the Jaccard similarity index (reproduced here from Section 5.4.5[211])",
            "zh": "（a） 使用 Jaccard 相似性指数（此处转载自第 5.4.5 节 [211]）"
        }
    },
    {
        "translation": {
            "en": "Figure 7.10",
            "zh": "图 7.10"
        }
    },
    {
        "translation": {
            "en": "Because correlation is normalized, it is dimensionless and, consequently, does not suffer from the interpretability difficulties associated with covariance.",
            "zh": "由于相关性是归一化的，因此它是无量纲的，因此不会受到与协方差相关的可解释性困难的影响。"
        }
    },
    {
        "translation": {
            "en": "The simplest form of sampling is top sampling, which simply selects the top s% of instances from a dataset to create a sample. Top sampling runs a serious risk of introducing bias, however, as the sample will be affected by any ordering of the original dataset. For this reason, we recommend that top sampling be avoided.",
            "zh": "最简单的抽样形式是顶部抽样，它只是从数据集中选择前 s% 的实例来创建样本。然而，顶部采样存在引入偏差的严重风险，因为样本将受到原始数据集的任何排序的影响。因此，我们建议避免顶部采样。"
        }
    },
    {
        "translation": {
            "en": "The basic structure of the AT business was that customers had a contract for call services that AT provided.",
            "zh": "AT业务的基本结构是客户与AT提供的呼叫服务签订合同。"
        }
    },
    {
        "translation": {
            "en": "So far our treatment of probability has assumed that the evidence we have collected affects the probability of the event we are trying to predict.",
            "zh": "到目前为止，我们对概率的处理假设我们收集的证据会影响我们试图预测的事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Cunningham, Padraig. 2009. A taxonomy of similarity mechanisms for case-based reasoning. IEEE Transactions on Knowledge and Data Engineering 21 (11): 1532–1543.",
            "zh": "坎宁安，帕德雷格。2009. 基于案例的推理相似性机制分类法.IEEE知识与数据工程汇刊21（11）：1532–1543。"
        }
    },
    {
        "translation": {
            "en": "41. The data in this table has been artificially generated for this question. The American Cancer Society does, however, provide information on the causes of cancer: www.cancer.org/cancer/cancercauses/.",
            "zh": "41. 本表中的数据是针对这个问题人为生成的。然而，美国癌症协会确实提供了有关癌症原因的信息：www.cancer.org/cancer/cancercauses/。"
        }
    },
    {
        "translation": {
            "en": "16. The example given here is based on artificial data generated for the purposes of this book. Predicting the prices of assets such as whiskey or wine using machine learning is, however, done in reality. For example, Ashenfelter (2008) deals with predicting wine prices and was covered in Ayres (2008).",
            "zh": "16. 这里给出的例子是基于为本书的目的而生成的人工数据。然而，使用机器学习预测威士忌或葡萄酒等资产的价格是在现实中完成的。例如，Ashenfelter（2008）涉及预测葡萄酒价格，并在Ayres（2008）中有所介绍。"
        }
    },
    {
        "translation": {
            "en": "We can see bootstrapping quite clearly in the definition of the actual temporal-difference learning update rule",
            "zh": "我们可以在实际时差学习更新规则的定义中非常清楚地看到引导"
        }
    },
    {
        "translation": {
            "en": "It would also require that any changes to a policy are recorded and available historically.",
            "zh": "它还要求对政策的任何更改都记录在历史记录中并提供。"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE features, and its low cardinality arises from their low cardinality.",
            "zh": "SOFT TISSUE 特征，其低基数源于它们的低基数。"
        }
    },
    {
        "translation": {
            "en": "Having normalized the dataset, we first need to normalize the descriptive feature values of this query instance using the same normalization process.",
            "zh": "对数据集进行规范化后，我们首先需要使用相同的规范化过程规范化此查询实例的描述性特征值。"
        }
    },
    {
        "translation": {
            "en": "The information gain for a feature based on the Gini index can be calculated in the same way that it is using entropy: calculate the Gini index for the full dataset and then subtract the sum of the weighted Gini index scores for the partitions created by splitting with the feature.",
            "zh": "基于基尼指数的特征的信息增益可以采用与使用熵相同的方式计算：计算完整数据集的基尼指数，然后减去通过与特征拆分创建的分区的加权基尼指数分数的总和。"
        }
    },
    {
        "translation": {
            "en": "For example, in Chapter 7[311] we introduce a machine learning algorithm called multivariable linear regression with gradient descent, which implements the restriction bias of considering only prediction models that produce predictions on the basis of a linear combination of the descriptive feature values and applies a preference bias over the order of the linear models it considers in terms of a gradient descent approach through a weight space.",
            "zh": "例如，在第 7 章[311]中，我们介绍了一种称为梯度下降的多变量线性回归的机器学习算法，该算法实现了仅考虑基于描述性特征值的线性组合生成预测的预测模型的限制偏差，并在通过权重空间的梯度下降方法考虑的线性模型的顺序上应用偏好偏差。"
        }
    },
    {
        "translation": {
            "en": "The probability that the feature f is equal to the value v is written P(f = v).",
            "zh": "特征 f 等于值 v 的概率写为 P（f = v）。"
        }
    },
    {
        "translation": {
            "en": "(d) In general, which is preferable when you are playing Scrabble: a set of letters with high entropy or a set of letters with low entropy?",
            "zh": "（d） 一般来说，当你玩拼字游戏时，哪个更可取：一组高熵的字母还是一组低熵的字母？"
        }
    },
    {
        "translation": {
            "en": "However, it is quite possible to use one-dimensional filters or filters with three or more dimensions.",
            "zh": "但是，很有可能使用一维滤镜或具有三维或更多维度的滤镜。"
        }
    },
    {
        "translation": {
            "en": "The combination of features listed in this query does not occur in the dataset.",
            "zh": "此查询中列出的要素组合不会出现在数据集中。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(a)[626] shows a selection of these digits.",
            "zh": "图10.15（a）[626]显示了这些数字的选择。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.1",
            "zh": "图 1.1"
        }
    },
    {
        "translation": {
            "en": "The “P.D.A.",
            "zh": "“P.D.A."
        }
    },
    {
        "translation": {
            "en": "Shannon’s model of entropy is a weighted sum of the logs of the probabilities of each possible outcome when we make a random selection from a set. The weights used in the sum are the probabilities of the outcomes themselves, so that outcomes with high probabilities contribute more to the overall entropy of a set than outcomes with low probabilities. Shannon’s model of entropy is defined as",
            "zh": "Shannon 的熵模型是当我们从集合中随机选择时，每个可能结果的概率对数的加权和。总和中使用的权重是结果本身的概率，因此高概率的结果比低概率的结果对集合的整体熵的贡献更大。香农的熵模型定义为"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes classifier is a Bayesian network with a specific topological structure.",
            "zh": "朴素贝叶斯分类器是具有特定拓扑结构的贝叶斯网络。"
        }
    },
    {
        "translation": {
            "en": "Asimov, Isaac. 1950. I, robot. Gnome Press.",
            "zh": "阿西莫夫，艾萨克。1950. 我，机器人。侏儒出版社。"
        }
    },
    {
        "translation": {
            "en": "7. See Section 3.1[54].",
            "zh": "7. 参见第 3.1 节[54]。"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.12(a)[205] the SALARY axis ranged from 45,000 to 75,000, and the AGE axis ranged from 25 to 60.",
            "zh": "在图5.12（a）[205]中，工资轴范围为45,000至75,000，年龄轴范围为25至60。"
        }
    },
    {
        "translation": {
            "en": "The SDSS project captures two distinct kinds of data—images of night-sky objects and spectrographs of night sky objects—using two distinct types of instrument, an imaging camera and a spectrograph.",
            "zh": "SDSS项目使用两种不同类型的仪器（成像相机和光谱仪）捕获两种不同类型的数据 - 夜空天体的图像和夜空天体的光谱仪。"
        }
    },
    {
        "translation": {
            "en": "0.1253",
            "zh": "0.1253"
        }
    },
    {
        "translation": {
            "en": "This c‡ value is very close to the original ct−1, which shows that the forget gate has largely retained the value in the cell state (or in other words, the cell state has largely remembered this value).",
            "zh": "该 c‡ 值非常接近原始 ct−1，这表明遗忘门在很大程度上保留了单元状态中的值（或者换句话说，单元状态在很大程度上记住了该值）。"
        }
    },
    {
        "translation": {
            "en": "For this example we set k = 3.",
            "zh": "在这个例子中，我们设置 k = 3。"
        }
    },
    {
        "translation": {
            "en": "Surfaces generated by calculating (a) the arithmetic mean and (b) the harmonic mean of all combinations of features A and B that range from 0 to 100.",
            "zh": "通过计算 （a） 算术平均值和 （b） 范围为 0 到 100 的所有要素 A 和 B 组合的谐波平均值生成的曲面。"
        }
    },
    {
        "translation": {
            "en": "In representation learning the goal of unsupervised machine learning is to create a new way to represent the instances in a dataset, usually with the expectation that this new representation will be more useful for a later, usually supervised, machine learning process. The origins of deep learning discussed in Chapter 8[381] lie in this application of unsupervised machine learning.",
            "zh": "在表示学习中，无监督机器学习的目标是创建一种新的方法来表示数据集中的实例，通常期望这种新表示对于以后的（通常是监督的）机器学习过程更有用。第8章[381]中讨论的深度学习的起源在于无监督机器学习的应用。"
        }
    },
    {
        "translation": {
            "en": "ME2_U/G/R/I/Z",
            "zh": "ME2_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The s% of the instances in each stratum are then randomly selected, and these selections are combined to give an overall sample of s% of the original dataset.",
            "zh": "然后随机选择每个层中实例的 s%，并将这些选择组合在一起，以提供原始数据集的 s% 的总样本。"
        }
    },
    {
        "translation": {
            "en": "This is why, as Figure 8.11[406] highlights, the weighted sum for each neuron is stored in the forward pass of the algorithm: it is used to calculate the ∂ak/∂zk term during the backpropagation process.",
            "zh": "这就是为什么，如图8.11[406]所示，每个神经元的加权和存储在算法的前向传递中：它用于在反向传播过程中计算∂ak/∂zk项。"
        }
    },
    {
        "translation": {
            "en": "He decided to keep the REGIONTYPE feature, however, because it appeared to have some relationship with the target.",
            "zh": "但是，他决定保留 REGIONTYPE 功能，因为它似乎与目标有某种关系。"
        }
    },
    {
        "translation": {
            "en": "If we compare the δ for Neuron 8 (the output neuron) with the δs for the neurons in the first hidden layer (Neurons 3, 4, and 5), it becomes clear that the δ values become smaller as they are propagated back from the output layer to the earlier layers in the network: δ8 = 0.0851, whereas δ3 = −0.0006, δ4 = −0.0003, and δ5 = 0.0003 are all smaller in magnitude.",
            "zh": "如果我们将神经元 8（输出神经元）的δ与第一个隐藏层（神经元 3、4 和 5）中神经元的 δ 进行比较，很明显，当它们从输出层传播回网络中的早期层时，δ值会变小：δ8 = 0.0851，而 δ3 = −0.0006， δ4 = −0.0003 和 δ5 = 0.0003 的量级都较小。"
        }
    },
    {
        "translation": {
            "en": "In particular, this terminology is often used in the explanation of softmax functions; therefore, in the section on handling categorical features, we switch from our normal z notation, and instead follow this logit nomenclature, using the notation l to denote a vector of logits for a layer of neurons, and li to indicate the logit for the ith neuron in the layer.",
            "zh": "特别是，这个术语经常用于解释softmax函数;因此，在处理分类特征的一节中，我们从正常的 Z 表示法切换，而是遵循这个 Logit 命名法，使用符号 l 表示神经元层的 logits 向量，并使用 li 表示该层中第 i 个神经元的 logit。"
        }
    },
    {
        "translation": {
            "en": "In this equation the subscript j indexes over the examples in the dataset and subscripts i and k index over neurons in the network.",
            "zh": "在这个等式中，下标 j 索引数据集中的示例，下标 i 和 k 索引网络中的神经元。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.1",
            "zh": "图 5.1"
        }
    },
    {
        "translation": {
            "en": "10.6 Further Reading",
            "zh": "10.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "A feature space plot of the college athlete data in Table 5.2[183].",
            "zh": "表5.2[183]中大学运动员数据的特征空间图。"
        }
    },
    {
        "translation": {
            "en": "Chapter 2[23]",
            "zh": "第2章[23]"
        }
    },
    {
        "translation": {
            "en": "Generalized Bayes’ Theorem, 251",
            "zh": "广义贝叶斯定理，251"
        }
    },
    {
        "translation": {
            "en": "2. a dot product between the input vector for this time-step xt and the weight matrix for the weights on the connections between the input layer and the hidden layer Whx;",
            "zh": "2. 该时间步长 xt 的输入向量与输入层和隐藏层 Whx 之间连接的权重的权重矩阵之间的点积;"
        }
    },
    {
        "translation": {
            "en": "location-scale family of distributions, 271",
            "zh": "位置尺度分布系列，271"
        }
    },
    {
        "translation": {
            "en": "For example, in English, the subject and verb of a sentence should agree.",
            "zh": "例如，在英语中，句子的主语和动词应该一致。"
        }
    },
    {
        "translation": {
            "en": "2. Informally explain what an algorithm has been designed to do before presenting the technical formal description of how it does it. Providing this informal introduction to each topic gives students a solid basis from which to attack the more technical material. Our experience with teaching this material to mixed audiences of undergraduates, postgraduates, and professionals has shown that these informal introductions enable students to easily access the topic.",
            "zh": "2. 在介绍算法如何实现的技术正式描述之前，非正式地解释算法的设计目的。为每个主题提供这种非正式的介绍，为学生提供了一个坚实的基础，从中攻击更具技术性的材料。我们向本科生、研究生和专业人士的混合受众教授这些材料的经验表明，这些非正式的介绍使学生能够轻松访问该主题。"
        }
    },
    {
        "translation": {
            "en": "When we are representing the target feature in a dataset using a one-hot encoding, then for each instance in the dataset there is a one-hot vector encoding the level of the target for that instance.",
            "zh": "当我们使用单热编码表示数据集中的目标特征时，对于数据集中的每个实例，都有一个单热向量对该实例的目标级别进行编码。"
        }
    },
    {
        "translation": {
            "en": "Table 6.15[283] shows the discretization of the LOAN AMOUNT feature into four equal-frequency bins.",
            "zh": "表 6.15[283] 显示了 LOAN AMOUNT 特征离散化为四个等频箱。"
        }
    },
    {
        "translation": {
            "en": "Nearly 2.4 million people responded to the survey, and on the basis of this sample, Literary Digest very publicly and confidently predicted that Alfred Landon would win by a landslide.",
            "zh": "近 240 万人对调查做出了回应，根据这个样本，《文学文摘》非常公开和自信地预测阿尔弗雷德·兰登将以压倒性优势获胜。"
        }
    },
    {
        "translation": {
            "en": "Player High (PH): 19 − 22",
            "zh": "球员最高值 （PH）： 19 − 22"
        }
    },
    {
        "translation": {
            "en": "In this scenario, feedback on the performance of the model implicitly arises within a reasonably short amount of time after predictions are made—churn predictions can be easily compared to actual customer behavior (taking into account interventions made by the business).",
            "zh": "在这种情况下，在做出预测后，在相当短的时间内隐式地出现对模型性能的反馈 - 流失预测可以很容易地与实际客户行为进行比较（考虑到业务部门的干预）。"
        }
    },
    {
        "translation": {
            "en": "squared error, 378",
            "zh": "平方误差，378"
        }
    },
    {
        "translation": {
            "en": "The convolutional neural networks discussed in Section 8.4.5[477] are ideally suited to processing data that have a fixed-size grid-like structure and where the basic features have a local extent, such as images.",
            "zh": "第8.4.5节[477]中讨论的卷积神经网络非常适合处理具有固定大小的网格状结构且基本特征具有局部范围的数据，例如图像。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23[364] shows two different decision boundaries that satisfy these constraints.",
            "zh": "图 7.23[364] 显示了满足这些约束的两个不同的决策边界。"
        }
    },
    {
        "translation": {
            "en": "D.2   Transpose",
            "zh": "D.2 转置"
        }
    },
    {
        "translation": {
            "en": "The fact that a neural network can represent a function does not guarantee that we will be able to train it to learn the function: the training algorithm may not be able to find the correct set of weights, or it may choose weights that overfit the data (i.e., choose the wrong function) (Goodfellow et al., 2016).",
            "zh": "神经网络可以表示一个函数这一事实并不能保证我们能够训练它来学习该函数：训练算法可能无法找到正确的权重集，或者它可能会选择过度拟合数据的权重（即选择错误的函数）（Goodfellow等人， 2016)."
        }
    },
    {
        "translation": {
            "en": "Hornik, Kur, Maxwell Stinchcombe, and Halber White. 1989. Multilayer feedforward networks are universal approximators. Neural Networks 2: 359–366.",
            "zh": "霍尼克、库尔、麦克斯韦·斯廷奇科姆和哈尔伯·怀特。1989. 多层前馈网络是通用逼近器。神经网络 2：359–366。"
        }
    },
    {
        "translation": {
            "en": "where 𝕄(q) is the prediction returned by the model 𝕄 using a MAP prediction mechanism for a query, q, composed of q[1],…,q[m] descriptive features; levels(t) is the set of levels the target feature can take; and arg maxl∈levels(t) specifies that we return the level, l, that has the maximum value computed using the function on the right of the arg max term.",
            "zh": "其中 M（q） 是模型 M 使用 MAP 预测机制对由 q[1],...,q[m] 描述性特征组成的查询 q 返回的预测;levels（t） 是目标要素可以采用的一组级别;arg maxl∈levels（t） 指定我们返回级别 l，该级别具有使用 arg max 项右侧的函数计算的最大值。"
        }
    },
    {
        "translation": {
            "en": "Shannon’s model of information is designed to reflect this intuition, and the entropy value for this set is 0.00 bits.",
            "zh": "Shannon 的信息模型旨在反映这种直觉，该集合的熵值为 0.00 位。"
        }
    },
    {
        "translation": {
            "en": "Because the chain rule specifies the product of a sequence of probabilities, if any of the probabilities in the sequence is zero, then the overall probability will be zero.",
            "zh": "由于链式法则指定了概率序列的乘积，因此如果序列中的任何概率为零，则总概率将为零。"
        }
    },
    {
        "translation": {
            "en": "2.6   Observation and outcome periods defined by an event rather than by a fixed point in time (each line represents a prediction subject, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.6 由事件而不是固定时间点定义的观察和结果周期（每条线代表一个预测主题，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "where is the normalized feature value, ai is the original value, min(a) is the minimum value of feature a, max(a) is the maximum value of feature a, and low and high are the minimum and maximum values of the desired range. Typical ranges used for normalizing feature values are [0,1] and [−1,1]. Table 3.9[88] shows the effect of applying range normalization to a small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the dataset in Table 3.7[73].",
            "zh": "其中，为归一化特征值，ai为原始值，min（a）为特征A的最小值，max（a）为特征A的最大值，low和high为所需范围的最小值和最大值。用于归一化特征值的典型范围是 [0,1] 和 [−1,1]。表3.9[88]显示了对表3.7[73]中数据集中HEIGHT和SPONSORSHIP EARNS特征的小样本应用范围归一化的效果。"
        }
    },
    {
        "translation": {
            "en": "From inspecting Figure 5.12(a)[205], it would appear as if instance d1—which has a target level no—is the closest neighbor to the query.",
            "zh": "通过检查图 5.12（a）[205]，实例 d1（目标级别为 no）似乎是与查询最接近的邻居。"
        }
    },
    {
        "translation": {
            "en": "Bellman optimality equation, 653",
            "zh": "贝尔曼最优方程，653"
        }
    },
    {
        "translation": {
            "en": "The main difference is in the Q value update step, where the next action to be taken, at+1, from the new state, st+1, is chosen using the behavior policy (Line 14[666]) and then used in updating the value of Q(st,at) (Line 14[666]).",
            "zh": "主要区别在于 Q 值更新步骤，其中使用行为策略（第 14 行[666]）选择从新状态 st+1 要执行的下一个操作 at+1，然后用于更新 Q（st，at） 的值（第 14 行[666]）。"
        }
    },
    {
        "translation": {
            "en": "If all the descriptive features in a dataset are continuous, then a similarity-based approach is a natural fit, especially when there is also a categorical target feature.",
            "zh": "如果数据集中的所有描述性特征都是连续的，则基于相似性的方法很自然地适合，尤其是当还存在分类目标特征时。"
        }
    },
    {
        "translation": {
            "en": "For the network in Figure 8.38[504] we would calculate three errors: one for y1, one for y2, and one for y3.",
            "zh": "对于图 8.38[504] 中的网络，我们将计算三个误差：一个用于 y1，一个用于 y2，一个用于 y3。"
        }
    },
    {
        "translation": {
            "en": "upsell model, 213, 572",
            "zh": "追加销售模型，213,572"
        }
    },
    {
        "translation": {
            "en": "The fact that our single-layer network in Figure 8.7[397] contains three independent neurons means that the network has the potential to represent three separate linear decision boundaries. However, none of the neurons in the output layer are capable of representing a non-linear decision boundary on the inputs, and therefore the network as a whole cannot represent a non-linear function.",
            "zh": "图8.7[397]中的单层网络包含三个独立的神经元，这意味着该网络有可能表示三个独立的线性决策边界。然而，输出层中没有一个神经元能够表示输入上的非线性决策边界，因此整个网络不能表示非线性函数。"
        }
    },
    {
        "translation": {
            "en": "6.4.3   Continuous Features: Binning",
            "zh": "6.4.3 连续功能：分箱"
        }
    },
    {
        "translation": {
            "en": "The second useful thing that can be done is to prepare a series of data visualizations that examine the distribution of each feature for the members of each cluster found.",
            "zh": "可以做的第二件有用的事情是准备一系列数据可视化，以检查找到的每个聚类成员的每个特征的分布。"
        }
    },
    {
        "translation": {
            "en": "“There is only one boss. The customer. And he can fire everybody in the company from the chairman on down, simply by spending his money somewhere else.”",
            "zh": "“只有一个老板。客户。他可以解雇公司里的每一个人，从董事长到下层，只要把钱花在其他地方。"
        }
    },
    {
        "translation": {
            "en": "The k-means algorithm is still stochastic in the manner in which initial cluster centroids are selected, and it does not completely remove the possibility of a poor starting point that leads to a sub-optimal clustering.",
            "zh": "k-means 算法在选择初始聚类质心的方式上仍然是随机的，并且它并没有完全消除导致次优聚类的不良起点的可能性。"
        }
    },
    {
        "translation": {
            "en": "Table 6.1",
            "zh": "表 6.1"
        }
    },
    {
        "translation": {
            "en": "correlation, 81, 82, 94, 103, 223",
            "zh": "相关性， 81， 82， 94， 103， 223"
        }
    },
    {
        "translation": {
            "en": "Andoni and Indyk (2006) provide a survey of these hash-based approaches.",
            "zh": "Andoni和Indyk（2006）对这些基于哈希的方法进行了调查。"
        }
    },
    {
        "translation": {
            "en": "Once the δs for all the neurons in the last hidden layer is calculated, the process is repeated in order to calculate δs for the neurons in the preceding hidden layer.",
            "zh": "一旦计算出最后一个隐藏层中所有神经元的 δs，就会重复该过程以计算前一个隐藏层中神经元的 δs。"
        }
    },
    {
        "translation": {
            "en": "6.2.1   Bayes’ Theorem",
            "zh": "6.2.1 贝叶斯定理"
        }
    },
    {
        "translation": {
            "en": "This is why in recent years most researchers have switched to using the rectifier function (or variants) as the default activation function.",
            "zh": "这就是为什么近年来大多数研究人员都转而使用整流器功能（或变体）作为默认激活功能的原因。"
        }
    },
    {
        "translation": {
            "en": "When different performance measures are used, the aggregates can be calculated in the same way.",
            "zh": "当使用不同的性能度量时，可以以相同的方式计算聚合。"
        }
    },
    {
        "translation": {
            "en": "This model could be run whenever new claims arise, and the policyholder could be offered the amount predicted by the model as settlement as an alternative to going through a claims investigation process.",
            "zh": "每当出现新的索赔时，都可以运行该模型，并且可以向投保人提供模型预测的金额作为结算，作为通过索赔调查过程的替代方案。"
        }
    },
    {
        "translation": {
            "en": "Notice that because of the way that the sigmoid activation function operates, large positive values in the Zt(f) vector (i.e., + 6) are mapped to values close to 1 in ft: 0.002472623, whereas large negative values in Zt(f) (such as − 6) are mapped to values near 0; and Zt(f) values near 0 are mapped to values around 0.5.",
            "zh": "请注意，由于 S 形激活函数的运作方式，Zt（f） 向量中的大正值（即 + 6）映射到接近 ft 的 1 值：0.002472623，而 Zt（f） 中的大负值（例如 − 6）映射到接近 0 的值;接近 0 的 Zt（f） 值映射到 0.5 附近的值。"
        }
    },
    {
        "translation": {
            "en": "Sample descriptive feature data illustrating numeric, binary, ordinal, interval, categorical, and textual types.",
            "zh": "示例描述性特征数据，说明数值、二进制、序数、区间、分类和文本类型。"
        }
    },
    {
        "translation": {
            "en": "CMODELMAGERR_U/G/R/I/Z",
            "zh": "CMODELMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "From these calculations we can see that SLOPE has the highest information gain ratio score, even though ELEVATION has the highest information gain. The implication is that if we built a decision tree for the dataset in Table 4.3[136] using information gain ratio, then SLOPE (rather than ELEVATION) would be the feature chosen for the root of the tree. Figure 4.12[144] illustrates the tree that would be generated for this dataset using information gain ratio.",
            "zh": "从这些计算中，我们可以看到 SLOPE 具有最高的信息增益比得分，即使 ELEVATION 具有最高的信息增益。这意味着，如果我们使用信息增益比为表4.3[136]中的数据集构建决策树，那么SLOPE（而不是ELEVATION）将是为树根选择的特征。图4.12[144]说明了使用信息增益比为该数据集生成的树。"
        }
    },
    {
        "translation": {
            "en": "Each partition, d=li, contains the instances in that have a value of level li for the d feature.",
            "zh": "每个分区 d=li 都包含其中的实例，其中 d 特征的值为 li 级别。"
        }
    },
    {
        "translation": {
            "en": "A root node is then added to the tree and labeled with the selected test feature.",
            "zh": "然后，将根节点添加到树中，并使用所选测试特征进行标记。"
        }
    },
    {
        "translation": {
            "en": "This means that we can generate good predictions for queries by interpolating from nearby instances with known target values.",
            "zh": "这意味着我们可以通过从具有已知目标值的附近实例进行插值来生成良好的查询预测。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, estimating how long the burn-in should be is difficult.",
            "zh": "不幸的是，估计老化应该持续多长时间是很困难的。"
        }
    },
    {
        "translation": {
            "en": "Typically, bias terms are initialized to 0.",
            "zh": "通常，偏置项初始化为 0。"
        }
    },
    {
        "translation": {
            "en": "3. we change the error (or loss) function we use for training to be the cross-entropy function.",
            "zh": "3. 我们将用于训练的误差（或损失）函数更改为交叉熵函数。"
        }
    },
    {
        "translation": {
            "en": "insights, 3",
            "zh": "见解，3"
        }
    },
    {
        "translation": {
            "en": "8.4   A schematic of a feedforward artificial neural network.",
            "zh": "8.4 前馈人工神经网络示意图。"
        }
    },
    {
        "translation": {
            "en": "NUM. SOFT TISSUE",
            "zh": "软组织数量"
        }
    },
    {
        "translation": {
            "en": "36. Xavier initialization is named after the first author (Xavier Glorot) of the paper that introduced this layer-wise approach to weight initialization, Glorot and Bengio (2010). However, in some places the author’s second name is used instead of his first name to describe the same initialization algorithm, so that it is sometimes called Glorot initialization.",
            "zh": "36. Xavier 初始化以介绍这种逐层权重初始化方法的论文的第一作者 （Xavier Glorot） 的名字命名，Glorot 和 Bengio （2010）。但是，在某些地方，使用作者的第二个名字而不是他的名字来描述相同的初始化算法，因此有时称为 Glorot 初始化。"
        }
    },
    {
        "translation": {
            "en": "Therefore, Ross’s first goal was to convert this business problem into a concrete analytics solution.",
            "zh": "因此，Ross 的首要目标是将这个业务问题转化为具体的分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "parametric model, 732",
            "zh": "参数模型，732"
        }
    },
    {
        "translation": {
            "en": "14.1 Different Perspectives on Prediction Models",
            "zh": "14.1 预测模型的不同视角"
        }
    },
    {
        "translation": {
            "en": "The taxonomy we have used to distinguish between different machine learning algorithms is based on human approaches to learning that the algorithms can be said to emulate. This is not the only set of distinctions that can be made between the algorithms and the resulting models. It is useful to understand some of the other commonly used distinctions, because this understanding can provide insight into which learning algorithm and related model is most appropriate for a given scenario.",
            "zh": "我们用来区分不同机器学习算法的分类法是基于人类的学习方法，这些算法可以说是模仿的。这并不是算法和结果模型之间唯一可以区分的一组。了解其他一些常用的区别是很有用的，因为这种理解可以深入了解哪种学习算法和相关模型最适合给定场景。"
        }
    },
    {
        "translation": {
            "en": "Beyond Prediction: Reinforcement Learning",
            "zh": "超越预测：强化学习"
        }
    },
    {
        "translation": {
            "en": "An easy way to understand the entropy of a set is to think in terms of the uncertainty associated with guessing the result if you were to make a random selection from the set.",
            "zh": "理解集合熵的一个简单方法是，如果您要从集合中随机选择，则考虑与猜测结果相关的不确定性。"
        }
    },
    {
        "translation": {
            "en": "where 𝕄k(q) is the prediction returned by the model using parameter value k for the query q, i iterates over the k nearest neighbors to q in the dataset, and ti is the value of the target feature for instance i.",
            "zh": "其中 Mk（q） 是模型使用参数值 k 返回的查询 q 的预测，i 遍历数据集中 q 的 k 个最近邻，ti 是实例 i 的目标特征的值。"
        }
    },
    {
        "translation": {
            "en": "The shape of the derivative in Figure C.2(c)[767] can be understood similarly.",
            "zh": "图C.2（c）[767]中导数的形状可以类似地理解。"
        }
    },
    {
        "translation": {
            "en": "We can demonstrate the product rule by recalculating the probability P(m,h) using previously computed probabilities:",
            "zh": "我们可以通过使用先前计算的概率重新计算概率 P（m，h） 来证明乘积规则："
        }
    },
    {
        "translation": {
            "en": "Figure 10.9",
            "zh": "图 10.9"
        }
    },
    {
        "translation": {
            "en": "An illustration of how the representational capacity of a network increases as more layers are added to the network.",
            "zh": "说明网络的表示能力如何随着向网络添加更多层而增加。"
        }
    },
    {
        "translation": {
            "en": "So, for example, for our ENERGY RATING feature, instead of adding three new features (ENERGY RATING A, ENERGY RATING B, and ENERGY RATING C), we could just add ENERGY RATING A and ENERGY RATING B and assume that whenever they both have a value of 0, ENERGY RATING C is implicitly set.",
            "zh": "因此，例如，对于我们的 ENERGY RATING 功能，我们可以添加 ENERGY RATING A 和 ENERGY RATING B，并假设只要它们的值都为 0，则不添加三个新功能（ENERGY RATING A、ENERGY RATING B 和 ENERGY RATING C），并假设只要它们的值都为 0，就会隐式设置 ENERGY RATING C。"
        }
    },
    {
        "translation": {
            "en": "There are very few missing values for this feature (2%), so replacing them with an imputed value should not excessively affect the variance of the feature.",
            "zh": "此特征的缺失值很少 （2%），因此将其替换为插补值不应过度影响特征的方差。"
        }
    },
    {
        "translation": {
            "en": "These two paths of processing are then merged using an elementwise product operation between the tanh activations and the sigmoid activations (i.e., the vector mask).",
            "zh": "然后，使用tanh激活和sigmoid激活（即向量掩码）之间的元素乘积操作合并这两种处理路径。"
        }
    },
    {
        "translation": {
            "en": "For example, the k-d trees described in Section 5.4.2[196] require that the measure of similarity used be a metric (in particular that the measure conform to the triangular inequality constraint).",
            "zh": "例如，第 5.4.2 节[196] 中描述的 k-d 树要求使用的相似度量是度量（特别是度量符合三角不等式约束）。"
        }
    },
    {
        "translation": {
            "en": "29. Normally in machine learning, we do not test a model using the same dataset that we use to train it. Boosting, however, is an exception to this rule.",
            "zh": "29. 通常，在机器学习中，我们不会使用用于训练模型的相同数据集来测试模型。然而，提升是这条规则的例外。"
        }
    },
    {
        "translation": {
            "en": "A support vector machine model is defined as",
            "zh": "支持向量机模型定义为"
        }
    },
    {
        "translation": {
            "en": "CHROMATIN",
            "zh": "染色质"
        }
    },
    {
        "translation": {
            "en": "The scatter plot matrices (SPLOMs) described in Section 3.5.1[72] are really a visualization of the correlation matrix.",
            "zh": "第3.5.1节[72]中描述的散点图矩阵（SPLOM）实际上是相关矩阵的可视化。"
        }
    },
    {
        "translation": {
            "en": "Diagnosis: Doctors, engineers, and scientists regularly make diagnoses as part of their work.",
            "zh": "诊断：医生、工程师和科学家定期进行诊断，作为他们工作的一部分。"
        }
    },
    {
        "translation": {
            "en": "In many cases organizations begin analytics projects because they have a clear issue that they want to address.",
            "zh": "在许多情况下，组织开始分析项目是因为他们想要解决一个明确的问题。"
        }
    },
    {
        "translation": {
            "en": "This is exactly the behavior we desire from a loss function: small values for correct predictions and large values for incorrect predictions.",
            "zh": "这正是我们期望从损失函数中获得的行为：正确预测的小值和错误预测的大值。"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1987. Simplifying decision trees. International Journal of Man-Machine Studies 27 (3): 221–234.",
            "zh": "昆兰，J.罗斯。1987. 简化决策树。国际人机研究杂志 27 （3）： 221–234."
        }
    },
    {
        "translation": {
            "en": "where is the dataset that has reached the node; n is the number of instances in ; is the mean of the target feature for the dataset ; and ti iterates across the target value of each instance in .",
            "zh": "其中 是已到达节点的数据集;n 是 中的实例数;是数据集目标特征的平均值;和 ti 遍历 中每个实例的目标值。"
        }
    },
    {
        "translation": {
            "en": "We also assume that all the neurons use a logistic activation function.",
            "zh": "我们还假设所有神经元都使用逻辑激活函数。"
        }
    },
    {
        "translation": {
            "en": "Using these results, we can compute the information gain ratio for each descriptive feature by dividing the feature’s information gain by the entropy for that feature",
            "zh": "利用这些结果，我们可以通过将特征的信息增益除以该特征的熵来计算每个描述性特征的信息增益比"
        }
    },
    {
        "translation": {
            "en": "(left) The XOR function implemented as a two-layer neural network. (right) The network processing the four possible input combinations, one combination plus bias input per column: [bias, FALSE,FALSE] → [1,0,0]; [bias, FALSE,TRUE] → [1,0,1]; [bias, TRUE,FALSE] → [1,1,0]; [bias, TRUE,TRUE] → [1,1,1].",
            "zh": "（左）XOR 函数作为两层神经网络实现。（右）处理四种可能的输入组合的网络，每列一个组合加上偏置输入：[bias， FALSE，FALSE] → [1,0,0];[bias， FALSE，TRUE] → [1,0,1];[偏差，真，假] → [1,1,0];[bias， TRUE，TRUE] → [1,1,1]。"
        }
    },
    {
        "translation": {
            "en": "Regardless of the dataset used, the k-means clustering algorithm will always find the number of clusters requested from it regardless of whether these define meaningful structure within the dataset.",
            "zh": "无论使用何种数据集，k-means 聚类算法将始终找到从中请求的聚类数量，无论这些聚类是否在数据集中定义有意义的结构。"
        }
    },
    {
        "translation": {
            "en": "The network’s weight matrices are initialized in Line 2[420].",
            "zh": "网络的权重矩阵在第 2 行 [420] 中初始化。"
        }
    },
    {
        "translation": {
            "en": "Once we have decided which analytics solution we are going to develop in response to a business problem, we need to begin to design the data structures that will be used to build, evaluate, and ultimately deploy the model. This work sits primarily in the Data Understanding phase of the CRISP-DM process (see Figure 1.4[16]) but also overlaps with the Business Understanding and Data Preparation phases (remember that the CRISP-DM process is not strictly linear).",
            "zh": "一旦我们决定了要开发哪种分析解决方案来响应业务问题，我们就需要开始设计数据结构，这些结构将用于构建、评估和最终部署模型。这项工作主要位于 CRISP-DM 流程的数据理解阶段（参见图 1.4[16]），但也与业务理解和数据准备阶段重叠（请记住，CRISP-DM 流程不是严格线性的）。"
        }
    },
    {
        "translation": {
            "en": "Batista, Gustavo E. A. P. A., and Maria Carolina Monard. 2003. An analysis of four missing data treatment methods for supervised learning. Applied Artificial Intelligence 17 (5-6): 519–533.",
            "zh": "巴蒂斯塔、古斯塔沃 E. A. P. A. 和玛丽亚·卡罗莱纳·莫纳德。2003. 监督学习的四种缺失数据处理方法的分析.应用人工智能17（5-6）：519-533。"
        }
    },
    {
        "translation": {
            "en": "Based on previous projects he had worked on, the current approach to customer retention that AT was taking, and AT’s historical data, Ross agreed with AT management that a target reduction from the current high of approximately 10% to approximately 7.5% was realistic and probably achievable.",
            "zh": "根据他之前参与的项目、AT目前采取的客户保留方法以及AT的历史数据，Ross同意AT管理层的观点，即将目标从目前的约10%的高点降低到约7.5%是现实的，并且可能是可以实现的。"
        }
    },
    {
        "translation": {
            "en": "Assuming that we want to use shallow decision trees, is there a way in which we can automatically create them from data? One of the best known decision tree induction algorithms is the Iterative Dichotomizer 3 (ID3) algorithm.8 This algorithm attempts to create the shallowest decision tree that is consistent with the data given.",
            "zh": "假设我们想使用浅层决策树，有没有办法从数据中自动创建它们？最著名的决策树归纳算法之一是迭代二分法器 3 （ID3） 算法.8 该算法试图创建与给定数据一致的最浅决策树。"
        }
    },
    {
        "translation": {
            "en": "SMARTPHONE: This feature indicated whether the customer’s current handset was a smartphone, which was derived from the customer’s most recent handset entry.",
            "zh": "智能手机：此功能指示客户当前的手机是否为智能手机，该智能手机源自客户最近的手机条目。"
        }
    },
    {
        "translation": {
            "en": "If we replace A(1) in Equation (8.8)[395] with the right-hand side of Equation (8.7)[395] we get",
            "zh": "如果我们用等式（8.7）[395]的右边替换方程（8.8）[395]中的A（1），我们得到"
        }
    },
    {
        "translation": {
            "en": "The risks associated with setting k to a high value are particularly acute when we are dealing with an imbalanced dataset.",
            "zh": "当我们处理不平衡的数据集时，将 k 设置为高值的相关风险尤为严重。"
        }
    },
    {
        "translation": {
            "en": "LogitBoost, 171",
            "zh": "LogitBoost，171"
        }
    },
    {
        "translation": {
            "en": "The raw data did not contain a single column that could be used as a target feature, so Jocelyn had to design one from the data sources that were present.",
            "zh": "原始数据不包含可用作目标要素的单个列，因此 Jocelyn 必须根据存在的数据源设计一个列。"
        }
    },
    {
        "translation": {
            "en": "Many of the predictive models that we build are propensity models, which predict the likelihood (or propensity) of a future outcome based on a set of descriptive features describing the past.",
            "zh": "我们构建的许多预测模型都是倾向模型，它根据一组描述过去的描述性特征来预测未来结果的可能性（或倾向）。"
        }
    },
    {
        "translation": {
            "en": "folds, 543",
            "zh": "褶皱，543"
        }
    },
    {
        "translation": {
            "en": "An illustration of the DQN algorithm including experience replay and target network freezing.",
            "zh": "DQN 算法的图示，包括体验回放和目标网络冻结。"
        }
    },
    {
        "translation": {
            "en": "This means the overall prediction for the query instance is single, as this gets the highest normalized score.",
            "zh": "这意味着查询实例的总体预测是单一的，因为这会获得最高的规范化分数。"
        }
    },
    {
        "translation": {
            "en": "binomial distribution, 178",
            "zh": "二项分布，178"
        }
    },
    {
        "translation": {
            "en": "Figure 8.11[406] illustrates the forward pass in a little more detail.",
            "zh": "图 8.11[406] 更详细地说明了前向传递。"
        }
    },
    {
        "translation": {
            "en": "It is generally used when networks use logistic or tanh activation functions.",
            "zh": "它通常用于网络使用 logistic 或 tanh 激活函数。"
        }
    },
    {
        "translation": {
            "en": "In particular, the values of the commonly used P20 and P45 potentials were measured while a participant viewed each image.",
            "zh": "特别是，在参与者查看每张图像时测量常用的 P20 和 P45 电位值。"
        }
    },
    {
        "translation": {
            "en": "Processing these inputs, the hidden neurons generate activations that are then propagated forward to the output layer and also written to the activation memory buffer (overwriting whatever information was in the memory buffer).",
            "zh": "处理这些输入时，隐藏的神经元产生激活，然后向前传播到输出层，并写入激活内存缓冲区（覆盖内存缓冲区中的任何信息）。"
        }
    },
    {
        "translation": {
            "en": "Dietterich (2000) give an excellent explanation of the motivations behind using ensembles, and Kuncheva (2004) and Zhou (2012) both provide good overviews of ensemble learning methods.",
            "zh": "Dietterich（2000）很好地解释了使用集成背后的动机，Kuncheva（2004）和周（2012）都对集成学习方法进行了很好的概述。"
        }
    },
    {
        "translation": {
            "en": "The goal of the agent is to complete the task as successfully as possible.",
            "zh": "代理的目标是尽可能成功地完成任务。"
        }
    },
    {
        "translation": {
            "en": "One final thing worth noting is that temporal-difference learning is model-free.",
            "zh": "最后一件值得注意的事情是，时间差分学习是无模型的。"
        }
    },
    {
        "translation": {
            "en": "Now, imagine that we have picked one of these cards and you have to guess which one by asking questions. Which of the following questions would you ask first?",
            "zh": "现在，想象一下，我们选择了其中一张卡片，您必须通过提问来猜测是哪一张。您首先会问以下哪个问题？"
        }
    },
    {
        "translation": {
            "en": "—Nick Hornby, High Fidelity",
            "zh": "—Nick Hornby，High Fidelity"
        }
    },
    {
        "translation": {
            "en": "-0.6653",
            "zh": "-0.6653"
        }
    },
    {
        "translation": {
            "en": "subjective estimate, 757",
            "zh": "主观估计，757"
        }
    },
    {
        "translation": {
            "en": "A game of find the lady: (a) the cards used; (b) the cards dealt facedown on a table; (c) the initial likelihoods of the queen ending up in each position; and (d) a revised set of likelihoods for the position of the queen based on evidence collected.",
            "zh": "寻找女士的游戏：（a）使用的牌;（b） 在桌子上发牌面朝下;（c） 女王最终担任每个职位的最初可能性;（d）根据收集到的证据，对女王职位的一系列可能性进行了修订。"
        }
    },
    {
        "translation": {
            "en": "The fact that nearest neighbor models use the full set of descriptive features when making a prediction makes them particularly sensitive to the occurrence of missing descriptive feature values.",
            "zh": "最近邻模型在进行预测时使用完整的描述性特征集，这一事实使它们对缺少描述性特征值的发生特别敏感。"
        }
    },
    {
        "translation": {
            "en": "Models trained using error-based approaches can become overly complicated when the number of levels of the target feature goes above two, although deep neural network models handle these scenarios easily.",
            "zh": "当目标特征的级别数超过两个时，使用基于错误的方法训练的模型可能会变得过于复杂，尽管深度神经网络模型可以轻松处理这些场景。"
        }
    },
    {
        "translation": {
            "en": "Even if significant computational resources were to be deployed for such a problem, it may not be possible for a k nearest neighbor model to perform fast enough to meet this requirement.",
            "zh": "即使要为此类问题部署大量计算资源，k个最近邻模型的执行速度也可能不足以满足此要求。"
        }
    },
    {
        "translation": {
            "en": "1.1   A credit scoring dataset.",
            "zh": "1.1 信用评分数据集。"
        }
    },
    {
        "translation": {
            "en": "As mentioned before this game has four actions available to the agent: None, Up, Left, and Right.",
            "zh": "如前所述，该游戏有四个操作可供代理使用：无、向上、向左和向右。"
        }
    },
    {
        "translation": {
            "en": "Where a named feature is binary, we use the lowercase initial letter of the name of the feature to denote the event where the feature is true and the lowercase initial letter preceded by the ¬ symbol to denote the event where it is false. So, m will represent the event MENINGITIS = true, and ¬m will denote MENINGITIS = false.",
            "zh": "如果命名特征是二进制的，则我们使用特征名称的小写首字母来表示特征为真的事件，并使用前面的小写首字母 ¬ 符号来表示为假的事件。因此，m 表示事件 MENINGITIS = true，¬m 表示 MENINGITIS = false。"
        }
    },
    {
        "translation": {
            "en": "(d) What target level would a k-NN model with k = 3 and using Manhattan distance return for the same query?",
            "zh": "（d） 对于同一查询，k = 3 并使用曼哈顿距离的 k-NN 模型将返回什么目标水平？"
        }
    },
    {
        "translation": {
            "en": "The model output is less than − 1, so this query is predicted to be a faulty generator. For the second query instance, the model output is calculated similarly and is 1.592. This is greater than + 1, so this instance is predicted to be a good generator.",
            "zh": "模型输出小于 − 1，因此此查询被预测为有故障的生成器。对于第二个查询实例，模型输出的计算方式类似，为 1.592。这大于 + 1，因此预计此实例将是一个很好的生成器。"
        }
    },
    {
        "translation": {
            "en": "In the ID3 algorithm the base cases are the situations in which we stop splitting the dataset and construct a leaf node with an associated target level.",
            "zh": "在 ID3 算法中，基本情况是我们停止拆分数据集并构造具有关联目标级别的叶节点的情况。"
        }
    },
    {
        "translation": {
            "en": "This suggests the need for a more sophisticated measure of the value of taking an action in a given state and leads to the final fundamental component of a reinforcement learning agent: a value function.",
            "zh": "这表明需要对在给定状态下采取行动的价值进行更复杂的度量，并导致强化学习代理的最后一个基本组成部分：价值函数。"
        }
    },
    {
        "translation": {
            "en": "Their inspiration for this work was linking the fact that propositional logic using a Boolean representation (TRUE/FALSE or 1/0) and neurons in the brain are somewhat similar, insofar as they have an all-or-none character (i.e., they act as a switch that responds to a set of inputs by outputting either a high activation or no activation).",
            "zh": "他们这项工作的灵感来自于将使用布尔表示（TRUE/FALSE 或 1/0）的命题逻辑与大脑中的神经元有些相似的事实联系起来，因为它们具有全有或全无的特征（即，它们充当开关，通过输出高激活或不激活来响应一组输入）。"
        }
    },
    {
        "translation": {
            "en": "The P(Y) terms on the left-hand side of this equation, however, cancel each other out to give us Bayes’ Theorem",
            "zh": "然而，这个方程左侧的 P（Y） 项相互抵消，为我们提供了贝叶斯定理"
        }
    },
    {
        "translation": {
            "en": "Also, as the differences between the values of the descriptive features of two instances grows, so too does the distance between the points in the feature space that represent these instances.",
            "zh": "此外，随着两个实例的描述性特征值之间的差异增大，特征空间中表示这些实例的点之间的距离也会增大。"
        }
    },
    {
        "translation": {
            "en": "This is the goal behind the process of converting business problems into analytics solutions as part of the Business Understanding phase of the CRISP-DM process.",
            "zh": "这是将业务问题转化为分析解决方案的过程背后的目标，作为 CRISP-DM 流程的业务理解阶段的一部分。"
        }
    },
    {
        "translation": {
            "en": "4.6 Further Reading",
            "zh": "4.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "The ∂a/∂z for each neuron for d2 rounded to four decimal places.",
            "zh": "d2 中每个神经元的 ∂a/∂z 四舍五入到小数点后四位。"
        }
    },
    {
        "translation": {
            "en": "In its call records, AT did not include information about which network calls are made to, and with the free movement of numbers among operators, numbers themselves were no longer a reliable indicator of network.",
            "zh": "在其通话记录中，AT没有包括有关向哪些网络呼叫进行的信息，并且随着号码在运营商之间的自由移动，号码本身不再是网络的可靠指标。"
        }
    },
    {
        "translation": {
            "en": "So far we have focused on calculating the probability of an individual event.",
            "zh": "到目前为止，我们专注于计算单个事件的概率。"
        }
    },
    {
        "translation": {
            "en": "The larger the value of σ, the lower the maximum height of the curve and the shallower the slope.",
            "zh": "σ值越大，曲线的最大高度越低，斜率越浅。"
        }
    },
    {
        "translation": {
            "en": "A better way to determine the importance of each descriptive feature in the model is to perform a statistical significance test.",
            "zh": "确定模型中每个描述性特征的重要性的更好方法是执行统计显著性检验。"
        }
    },
    {
        "translation": {
            "en": "ROC curve, 558",
            "zh": "ROC曲线，558"
        }
    },
    {
        "translation": {
            "en": "Consequently, these theorems are not relevant to the practical task of training a network to learn a function because the inclusion of these complex functions within the neurons of the network shifts the learning burden from approximating the target function to finding these complex internal functions (Reed and Marks, 1999).",
            "zh": "因此，这些定理与训练网络学习函数的实际任务无关，因为将这些复杂函数包含在网络的神经元中会将学习负担从近似目标函数转移到找到这些复杂的内部函数（Reed and Marks， 1999）。"
        }
    },
    {
        "translation": {
            "en": "The purpose of this book is to give readers a solid grounding in the theoretical underpinnings of the most commonly used machine learning techniques and a clear view of the ways machine learning techniques are used in practice in predictive data analytics projects. With this in mind, readers can view the book as four parts that are mapped to the phases of the CRISP-DM process.",
            "zh": "本书的目的是为读者提供最常用的机器学习技术的理论基础的坚实基础，并清楚地了解机器学习技术在预测数据分析项目中的实践使用方式。考虑到这一点，读者可以将本书视为映射到 CRISP-DM 过程各个阶段的四个部分。"
        }
    },
    {
        "translation": {
            "en": "Some days Conor should order the item he knows he likes best, and some days he should choose something new.",
            "zh": "有些日子，康纳应该订购他知道自己最喜欢的商品，有些日子他应该选择新的东西。"
        }
    },
    {
        "translation": {
            "en": "4.4   Two decision trees, (a) and (b), that are consistent with the instances in the spam dataset; and (c) the path taken through the tree shown in (a) to make a prediction for the query instance SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, and CONTAINS IMAGES = true.",
            "zh": "4.4 两个决策树，（a）和（b），与垃圾邮件数据集中的实例一致;以及 （c） 通过 （a） 所示的树对查询实例 SUSPICIOUS WORDS = true、UNKNOWN SENDER = true 和 CONTAINS IMAGES = true 进行预测的路径。"
        }
    },
    {
        "translation": {
            "en": "comparative experiments, 583",
            "zh": "比较实验，583"
        }
    },
    {
        "translation": {
            "en": "Model",
            "zh": "型"
        }
    },
    {
        "translation": {
            "en": "(b) Draw a Markov process diagram to capture the behavior of the taxi driver as described.",
            "zh": "（b） 绘制马尔可夫过程图，以捕捉出租车司机的行为。"
        }
    },
    {
        "translation": {
            "en": "(c) In building a decision tree, the easiest way to handle a continuous feature is to define a threshold around which splits will be made. What would be the optimal threshold to split the continuous AGE feature (use information gain based on entropy as the feature selection measure)?",
            "zh": "（c） 在构建决策树时，处理连续特征的最简单方法是定义一个阈值，围绕该阈值进行拆分。拆分连续AGE特征的最佳阈值是多少（使用基于熵的信息增益作为特征选择度量）？"
        }
    },
    {
        "translation": {
            "en": "In fact, partitioning the data by this feature creates two pure sets: one containing only instances with the target level spam and the other set containing only instances with the target level ham.",
            "zh": "事实上，按此功能对数据进行分区会创建两个纯集：一个仅包含具有目标级别垃圾邮件的实例，另一个仅包含具有目标级别 ham 的实例的集合。"
        }
    },
    {
        "translation": {
            "en": "A single majority classification was calculated from the five manual classifications for each galaxy.",
            "zh": "根据每个星系的五个手动分类计算出一个单一多数分类。"
        }
    },
    {
        "translation": {
            "en": "3.2.1   The Normal Distribution",
            "zh": "3.2.1 正态分布"
        }
    },
    {
        "translation": {
            "en": "Table 10.2[611] shows an example of calculating the silhouette for the final clustering of the mobile phone customer dataset found using the k-means algorithm (with k = 3) (Table 10.1[604]). The cluster to which each instance has been assigned, the nearest other cluster to each instance, the values of a(i) and b(i), and the final silhouette value, s(i), are all shown. We discuss in detail the calculation of the silhouette width for the first instance in the dataset, d1.",
            "zh": "表10.2[611]显示了使用k-means算法（k = 3）计算移动电话客户数据集最终聚类的轮廓的示例（表10.1[604]）。将显示每个实例分配到的聚类、离每个实例最近的其他聚类、a（i） 和 b（i） 的值以及最终的剪影效果值 s（i）。我们详细讨论了数据集中第一个实例 d1 的轮廓宽度的计算。"
        }
    },
    {
        "translation": {
            "en": "8.4.5.5 Handling color images and multiple filters All the example filters that we previously presented were two-dimensional.",
            "zh": "8.4.5.5 处理彩色图像和多个滤镜 我们之前介绍的所有示例滤镜都是二维的。"
        }
    },
    {
        "translation": {
            "en": "Definitions of some standard probability distributions.",
            "zh": "一些标准概率分布的定义。"
        }
    },
    {
        "translation": {
            "en": "0.4106",
            "zh": "0.4106"
        }
    },
    {
        "translation": {
            "en": "Since all three plots show very similar distributions, we can conclude that no real relationship exists between these two features and that players of any career stage are equally likely to have a shoe sponsor or not.",
            "zh": "由于这三个图都显示出非常相似的分布，我们可以得出结论，这两个特征之间不存在真正的关系，并且任何职业阶段的球员都有同样的可能性有鞋赞助商。"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 1993. Classification and regression trees. CRC Press.",
            "zh": "布莱曼，狮子座。1993. 分类和回归树.CRC出版社。"
        }
    },
    {
        "translation": {
            "en": "This is similar to the way we calculate the error gradients with respect to the weights of a neuron, the difference here being that we want the error gradient with respect to the input hxt, and so in this case we multiply the δ by the weights rather than the inputs.",
            "zh": "这类似于我们计算相对于神经元权重的误差梯度的方式，这里的区别在于我们想要相对于输入 hxt 的误差梯度，因此在这种情况下，我们将δ乘以权重而不是输入。"
        }
    },
    {
        "translation": {
            "en": "3. For example, some of the feature values will be mislabeled.",
            "zh": "3. 例如，某些特征值将被错误标记。"
        }
    },
    {
        "translation": {
            "en": "Table 9.1[537] shows the expected targets for a small sample test set and a set of predictions made by a model trained for this prediction problem (the FP and FN comments in the Outcome column will be explained shortly).",
            "zh": "表 9.1[537] 显示了小型样本测试集的预期目标，以及针对此预测问题训练的模型所做的一组预测（“结果”列中的 FP 和 FN 注释将很快解释）。"
        }
    },
    {
        "translation": {
            "en": "The standardization parameters (the mean and standard deviation of each feature) needed to be included in the pipeline so that the same preprocessing step could be applied to newly arriving instances before presenting them to the models.",
            "zh": "标准化参数（每个特征的平均值和标准差）需要包含在管道中，以便在将新到达的实例呈现给模型之前，可以将相同的预处理步骤应用于这些实例。"
        }
    },
    {
        "translation": {
            "en": "Rewriting logistic(w ·d) as 𝕄w(d) for readability, we get",
            "zh": "为了提高可读性，将 logistic（w ·d） 重写为 Mw（d），我们得到"
        }
    },
    {
        "translation": {
            "en": "The simplest approach to handling missing values is to simply drop from an ABT any features that have them.",
            "zh": "处理缺失值的最简单方法是简单地从 ABT 中删除具有缺失值的任何特征。"
        }
    },
    {
        "translation": {
            "en": "If, however, you wish to get a broader understanding of calculus, we recommend Stewart (2012) as an excellent textbook on all aspects of calculus.",
            "zh": "但是，如果您希望更广泛地了解微积分，我们推荐Stewart（2012）作为一本关于微积分各个方面的优秀教科书。"
        }
    },
    {
        "translation": {
            "en": "The sequence of observations, actions and rewards that precede any time-step, t, is referred to as a history, Ht. The job of the agent in the environment is to make decisions at each time-step, t, about what action to take next on the basis of its current observations of the environment, ot, and the history, Ht.",
            "zh": "任何时间步长 t 之前的观察、操作和奖励序列称为历史记录 Ht。智能体在环境中的工作是在每个时间步 t 根据其当前对环境的观察 ot 和历史 Ht 来决定下一步要采取什么行动。"
        }
    },
    {
        "translation": {
            "en": "(2001), Bishop (2006), and Murphy (2012) for broad coverage of machine learning algorithms, including more in-depth coverage of unsupervised and reinforcement learning approaches than included in this book.",
            "zh": "（2001）、Bishop （2006） 和 Murphy （2012） 对机器学习算法的广泛覆盖，包括对无监督和强化学习方法的更深入的覆盖。"
        }
    },
    {
        "translation": {
            "en": "3.3 Identifying Data Quality Issues",
            "zh": "3.3 识别数据质量问题"
        }
    },
    {
        "translation": {
            "en": "In fact, searching for predictive models that are consistent with the dataset is equivalent to just memorizing the dataset.",
            "zh": "事实上，搜索与数据集一致的预测模型等同于仅仅记住数据集。"
        }
    },
    {
        "translation": {
            "en": "7.1 Big Idea",
            "zh": "7.1 大创意"
        }
    },
    {
        "translation": {
            "en": "The regression equation for a multivariable linear regression model for the full dataset shown in Table 7.1[313] would look like",
            "zh": "表7.1[313]所示的完整数据集的多变量线性回归模型的回归方程如下所示"
        }
    },
    {
        "translation": {
            "en": "13.4.3   The 5-Level Model",
            "zh": "13.4.3 五级模型"
        }
    },
    {
        "translation": {
            "en": "This equation is equivalent to Equation (6.19)[288]. The fact that the probability P(t) is an unconditional probability simply reflects the structure of the naive Bayes’ network where the target feature has no parent nodes (see Figure 6.11(a)[290]).",
            "zh": "该等价于等式（6.19）[288]。概率 P（t） 是无条件概率这一事实仅反映了朴素贝叶斯网络的结构，其中目标特征没有父节点（参见图 6.11（a）[290]）。"
        }
    },
    {
        "translation": {
            "en": "(b) The table below lists a set of instances from the house alarm domain. Using the data in this table, create the conditional probability tables (CPTs) for the network you created in Part (a) of this question.",
            "zh": "（b） 下表列出了房屋报警域中的一组实例。使用此表中的数据，为您在本问题 （a） 部分中创建的网络创建条件概率表 （CPT）。"
        }
    },
    {
        "translation": {
            "en": "Calculating exact probabilities for each of the possible target levels is often very useful to a human decision maker, for example, a doctor.",
            "zh": "计算每个可能的目标水平的精确概率通常对人类决策者（例如医生）非常有用。"
        }
    },
    {
        "translation": {
            "en": "Table 13.10",
            "zh": "表 13.10"
        }
    },
    {
        "translation": {
            "en": "This works out really well when the set containing the single element contains the solution.",
            "zh": "当包含单个元素的集合包含溶液时，这非常有效。"
        }
    },
    {
        "translation": {
            "en": "linear separator, 339",
            "zh": "线性分离器，339"
        }
    },
    {
        "translation": {
            "en": "In this example we use Euclidean distance as the distance measure.",
            "zh": "在此示例中，我们使用欧几里得距离作为距离度量。"
        }
    },
    {
        "translation": {
            "en": "Another problem with this model is that the model always makes completely confident predictions of 0 or 1.",
            "zh": "该模型的另一个问题是，该模型始终对 0 或 1 做出完全自信的预测。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.3",
            "zh": "图 3.3"
        }
    },
    {
        "translation": {
            "en": "This is important because it allows multiple splits within a range of a continuous feature to be considered on a path.",
            "zh": "这很重要，因为它允许在路径上考虑连续特征范围内的多个拆分。"
        }
    },
    {
        "translation": {
            "en": "(b) The average class accuracy (harmonic mean)",
            "zh": "（b） 平均等级精度（谐波平均值）"
        }
    },
    {
        "translation": {
            "en": "8.2.2   Artificial Neural Networks",
            "zh": "8.2.2 人工神经网络"
        }
    },
    {
        "translation": {
            "en": "In this example the ε-greedy policy with ε = 0.1 is used throughout, and the hyper-parameters α and γ are set to α = 0.2 and γ = 0.9.23",
            "zh": "在此示例中，始终使用 ε = 0.1 的贪婪ε策略，并将超参数 α 和 γ 设置为 α = 0.2 和 γ = 0.9.23"
        }
    },
    {
        "translation": {
            "en": "The optimal values for the weights are the values that define the model with the minimum prediction error.",
            "zh": "权重的最优值是定义具有最小预测误差的模型的值。"
        }
    },
    {
        "translation": {
            "en": "6.5   Illustration of the robustness of the student-t distribution to outliers: (a) a density histogram of a unimodal dataset overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data; and (b) a density histogram of the same dataset with outliers added, overlaid with the density curves of a normal and a student-t distribution that have been fitted to the data.",
            "zh": "6.5 学生-t分布对异常值的鲁棒性说明：（a）单峰数据集的密度直方图，上面覆盖着已拟合到数据的正态分布和学生-t分布的密度曲线;（b）添加了异常值的同一数据集的密度直方图，与已拟合到数据的正态分布和学生-t分布的密度曲线叠加。"
        }
    },
    {
        "translation": {
            "en": "In the next chapter, we describe the process we should follow to evaluate the quality of the data in the ABT and the actions we can take if the quality isn’t good enough.",
            "zh": "在下一章中，我们将介绍评估 ABT 中数据质量时应遵循的流程，以及如果质量不够好，我们可以采取的措施。"
        }
    },
    {
        "translation": {
            "en": "The motivation for using a row vector to hold one copy of the feature differences and a column vector to hold the second copy of the features differences is to facilitate matrix multiplication.",
            "zh": "使用行向量来保存特征差异的一个副本，并使用列向量来保存特征差异的第二个副本的动机是为了促进矩阵乘法。"
        }
    },
    {
        "translation": {
            "en": "In such a network, immediately after initialization, approximately half the hidden neurons in the network will have activations equal to zero; in a sense, in a network with a sparse representation, each input vector flows through a subset of active pathways in the network (Glorot et al., 2011).",
            "zh": "在这样的网络中，初始化后，网络中大约一半的隐藏神经元的激活次数将等于零;从某种意义上说，在具有稀疏表示的网络中，每个输入向量都流经网络中活动路径的子集（Glorot等人，2011）。"
        }
    },
    {
        "translation": {
            "en": "A data quality issue arises when the cardinality for a feature does not match what we expect, a mismatch called an irregular cardinality.",
            "zh": "当要素的基数与我们预期的不匹配时，就会出现数据质量问题，这种不匹配称为不规则基数。"
        }
    },
    {
        "translation": {
            "en": "For example, the AGE, GENDER, CREDITRATING, and OCCUPATION columns from the customer demographics data warehouse could be directly included as descriptive features in the ABT to capture the CUSTOMER DEMOGRAPHICS domain concept.",
            "zh": "例如，客户人口统计数据仓库中的 AGE、GENDER、CREDITRATING 和 OCCUPATION 列可以作为描述性特征直接包含在 ABT 中，以捕获 CUSTOMER DEMOGRAPHICS 域概念。"
        }
    },
    {
        "translation": {
            "en": "This indicates that the SUSPICIOUS WORDS feature is a good feature to test if we are trying to decide whether a new email—not listed in the training dataset—is spam or not.",
            "zh": "这表明 SUSPICIOUS WORDS 功能是一个很好的功能，可以测试我们是否试图确定新电子邮件（未在训练数据集中列出）是否为垃圾邮件。"
        }
    },
    {
        "translation": {
            "en": "In Equation (8.121)[517] we calculate a vector containing δ values for the neurons in the output gate tanh layer by backpropagating the error gradients ∂ℰ/∂o‡ back through that tanh activation function. Then in Equation (8.122)[517] we merge the two sets of gradients that arise from the fork in the forward propagation of ct to both the next time-step (as the cell state) and the output layer for this time-step.",
            "zh": "在方程（8.121）[517]中，我们通过将误差梯度∂E/∂o‡反向传播回该tanh激活函数，计算出输出门tanh层中神经元值的δ向量。然后，在等式（8.122）[517]中，我们合并了从ct前向传播到下一个时间步长（作为单元状态）和该时间步长的输出层的分叉产生的两组梯度。"
        }
    },
    {
        "translation": {
            "en": "The area under an ROC curve is calculated as the integral of the curve.",
            "zh": "ROC 曲线下的面积计算为曲线的积分。"
        }
    },
    {
        "translation": {
            "en": "9.4   The performance measures from the five individual evaluation experiments and an overall aggregate from the 5-fold cross validation performed on the chest X-ray classification dataset.",
            "zh": "9.4 来自五个单独评估实验的性能测量和对胸部 X 射线分类数据集进行的 5 倍交叉验证的总体汇总。"
        }
    },
    {
        "translation": {
            "en": "Indeed, in training an image processing model we typically want the model to generalize over the precise locations of features in training images so that it can still use these features when they occur in offset configurations in new images.",
            "zh": "事实上，在训练图像处理模型时，我们通常希望模型对训练图像中特征的精确位置进行泛化，以便在新图像中以偏移配置出现这些特征时，它仍然可以使用这些特征。"
        }
    },
    {
        "translation": {
            "en": "The goal of the network schematic on the left of Figure 8.37[502] is to provide a high-level overview of the template structure of a simple recurrent neural network.",
            "zh": "图8.37[502]左侧的网络原理图的目的是提供简单循环神经网络的模板结构的高级概述。"
        }
    },
    {
        "translation": {
            "en": "We always expect the ROC curve for a trained model to be above this random reference line.15 In fact, as the strength of a predictive model increases, the ROC curve moves farther away from the random line toward the top left-hand corner of ROC space—toward a TPR of 1.0 and an FPR of 0.0.",
            "zh": "15 事实上，随着预测模型强度的增加，ROC 曲线会从随机线向 ROC 空间的左上角移动，TPR 为 1.0，FPR 为 0.0。"
        }
    },
    {
        "translation": {
            "en": "Calculating the stability index for the bacterial species identification problem given new test data for two periods after model deployment.",
            "zh": "计算模型部署后两个时期的新测试数据下细菌物种识别问题的稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "These networks have been shown to be especially effective, particularly when states are stored in very low-level representations, such as the arrangement of pieces on a game board or a screenshot of a game.",
            "zh": "这些网络已被证明特别有效，特别是当状态以非常低级的表示形式存储时，例如游戏板上的棋子排列或游戏的屏幕截图。"
        }
    },
    {
        "translation": {
            "en": "This time, however, as the dealer drops the cards onto the table, a sudden gust of wind turns over the card on the right to reveal that it is the ace of spades (shown in Figure 6.2(a)[245]).",
            "zh": "然而，这一次，当庄家将牌扔到桌子上时，一阵突如其来的风吹翻了右边的牌，显示它是黑桃A（如图6.2（a）[245]所示）。"
        }
    },
    {
        "translation": {
            "en": "8.4.1   Vanishing Gradients and ReLUs",
            "zh": "8.4.1 消失梯度和 ReLU"
        }
    },
    {
        "translation": {
            "en": "Throughout the course of a predictive data analytics project, we are forced to use our intuition and experience, and experimentation, to steer the project toward the best solution.",
            "zh": "在预测数据分析项目的整个过程中，我们被迫利用我们的直觉、经验和实验来引导项目走向最佳解决方案。"
        }
    },
    {
        "translation": {
            "en": "Table A.4(a)[755] shows the density and probability calculations for the TRAINING EXPENSES feature when we use ten 200-unit intervals, and Table A.4(b)[755] shows the same calculations when we use four 500-unit intervals.7 Recall that we compute the density for each interval by dividing the number of observations in the interval by the width of the interval multiplied by the total number of observations.",
            "zh": "表 A.4（a）[755] 显示了当我们使用 10 个 200 个单位的区间时，训练费用特征的密度和概率计算，表 A.4（b）[755] 显示了当我们使用 4 个 500 个单位的区间时的相同计算。"
        }
    },
    {
        "translation": {
            "en": "This is one of the key benefits of using logistic regression.",
            "zh": "这是使用逻辑回归的主要好处之一。"
        }
    },
    {
        "translation": {
            "en": "silhouette method, 612",
            "zh": "剪影法，612"
        }
    },
    {
        "translation": {
            "en": "In this example, the hidden state has a size of 2; however, typically the size of the hidden state is much larger.",
            "zh": "在此示例中，隐藏状态的大小为 2;但是，通常隐藏状态的大小要大得多。"
        }
    },
    {
        "translation": {
            "en": "Schematic of the simple recurrent neural architecture.",
            "zh": "简单递归神经架构的示意图。"
        }
    },
    {
        "translation": {
            "en": "The different weight initialization regimes that have been developed vary, depending on whether they take both nin and nout into account and the activation functions with which they work best.",
            "zh": "已经开发的不同权重初始化机制各不相同，这取决于它们是否同时考虑了 nin 和 nout，以及它们最适合的激活函数。"
        }
    },
    {
        "translation": {
            "en": "10.3.1 A Worked Example",
            "zh": "10.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "For the simple version of the office rentals example that uses only the SIZE descriptive feature, described in Section 7.2.1[312], it is easy to visualize how the gradient descent algorithm would move iteratively toward a model that best fits the training data, making small adjustments each time—with each adjustment reducing the error of the model, just as our surfer from Section 7.1[311] did.",
            "zh": "对于仅使用 SIZE 描述性特征的办公室租赁示例的简单版本，如第 7.2.1 节[312]所述，很容易可视化梯度下降算法如何迭代地向最适合训练数据的模型移动，每次都进行小的调整——每次调整都会减少模型的误差， 就像我们第 7.1 节[311] 中的冲浪者一样。"
        }
    },
    {
        "translation": {
            "en": "This means that each fold of the test set contains only one instance, and the training set contains the remainder of the data.",
            "zh": "这意味着测试集的每个折叠只包含一个实例，而训练集包含剩余的数据。"
        }
    },
    {
        "translation": {
            "en": "For example, consider that the mean value of the distribution shown in Figure 3.2(f)[60] is likely to sit right in the valley between the two peaks, even though very few instances actually have this value.",
            "zh": "例如，假设图3.2（f）[60]所示的分布平均值可能正好位于两个峰值之间的谷值中，尽管实际上很少有实例具有此值。"
        }
    },
    {
        "translation": {
            "en": "2. They make a prediction by aggregating the predictions of the different models in the ensemble. For categorical target features, this can be done using different types of voting mechanisms; and for continuous target features, this can be done using a measure of the central tendency of the different model predictions, such as the mean or the median.",
            "zh": "2. 他们通过聚合集成中不同模型的预测来做出预测。对于分类目标特征，可以使用不同类型的投票机制来完成;对于连续目标特征，可以使用不同模型预测（例如均值或中位数）的中心趋势度量来完成。"
        }
    },
    {
        "translation": {
            "en": "All the performance measures described in the previous section assumed that the prediction problem being evaluated had only two target levels. Many of the prediction problems for which we build models are multinomial, that is, there are multiple target levels. When we deal with multinomial prediction problems, we need a different set of performance measures. This section describes the most common of these. We begin by discussing how the confusion matrix can be extended to handle multiple target levels.",
            "zh": "上一节中描述的所有性能度量都假定正在评估的预测问题只有两个目标水平。我们构建模型的许多预测问题都是多项式的，也就是说，有多个目标水平。当我们处理多项式预测问题时，我们需要一组不同的性能度量。本节介绍其中最常见的方法。我们首先讨论如何扩展混淆矩阵以处理多个目标级别。"
        }
    },
    {
        "translation": {
            "en": "In Section 8.4.4[472] we introduced dropout as one of the standard methods used to stop a deep learning network from overfitting.",
            "zh": "在第 8.4.4 节[472]中，我们引入了 dropout 作为用于阻止深度学习网络过拟合的标准方法之一。"
        }
    },
    {
        "translation": {
            "en": "random action selection policy, 656",
            "zh": "随机操作选择策略，656"
        }
    },
    {
        "translation": {
            "en": "Then during training after each iteration (or number of iterations), the current model is run on the validation set and its error is recorded.",
            "zh": "然后，在每次迭代（或迭代次数）后的训练期间，在验证集上运行当前模型并记录其错误。"
        }
    },
    {
        "translation": {
            "en": "Hart, P. 1968. The condensed nearest neighbor rule. IEEE Transactions on Information Theory 14 (3): 515–516.",
            "zh": "哈特，第 1968 页。浓缩的最近邻规则。IEEE信息理论汇刊14（3）：515–516。"
        }
    },
    {
        "translation": {
            "en": "gradient boosting, xvi, 159, 164",
            "zh": "梯度提升， xvi， 159， 164"
        }
    },
    {
        "translation": {
            "en": "If we update all the weights in the network using the process illustrated in Equation 8.39[432] for weight w 7,5 and then run the same examples through a forward pass of the network, we reduce the error of the model by a small amount; Table 8.8[433] lists the per example error and sum of squared errors for the four examples after all the weights have been updated.",
            "zh": "如果我们使用公式 8.39[432] 中所示的权重 w 7,5 的过程更新网络中的所有权重，然后通过网络的前向传递运行相同的示例，我们将模型的误差减少少量;表 8.8[433] 列出了所有权重更新后每个示例的误差和四个示例的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the weight matrix for the single layer network that would implement the equivalent mapping that this two-layer network implements.",
            "zh": "（b） 计算单层网络的权重矩阵，该矩阵将实现该双层网络实现的等效映射。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.16",
            "zh": "图 7.16"
        }
    },
    {
        "translation": {
            "en": "If this assumption does not hold, then standardization may introduce some distortions.",
            "zh": "如果这个假设不成立，那么标准化可能会引入一些扭曲。"
        }
    },
    {
        "translation": {
            "en": "The decision boundary is the boundary between regions of the feature space in which different target levels will be predicted.",
            "zh": "决策边界是特征空间区域之间的边界，其中将预测不同的目标级别。"
        }
    },
    {
        "translation": {
            "en": "The first category of proofs that assume the use of complex functions within the neurons is based on the foundational mathematical theorems from Kolmogorov (1963) and Spercher (1965).",
            "zh": "第一类假设在神经元内使用复杂函数的证明是基于Kolmogorov（1963）和Spercher（1965）的基础数学定理。"
        }
    },
    {
        "translation": {
            "en": "D.1   Basic Types",
            "zh": "D.1 基本类型"
        }
    },
    {
        "translation": {
            "en": "As such, Bayesian network models are an intermediary between full joint distributions and naive Bayes models and offer a useful compromise between model compactness and predictive accuracy.",
            "zh": "因此，贝叶斯网络模型是全联合分布和朴素贝叶斯模型之间的中介，并在模型紧凑性和预测准确性之间提供了有用的折衷方案。"
        }
    },
    {
        "translation": {
            "en": "3.4 Handling Data Quality Issues",
            "zh": "3.4 处理数据质量问题"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values for these query instances are q1 = −0.314, −0.251 and q2 = −0.117, 0.31.",
            "zh": "这些查询实例的描述性特征值为 q1 = −0.314、−0.251 和 q2 = −0.117、0.31。"
        }
    },
    {
        "translation": {
            "en": "When learning rate decay is used, there is much less thrashing back and forth across the error surface than when the large static learning rate is used.",
            "zh": "当使用学习率衰减时，与使用大型静态学习率时相比，在错误表面上来回晃动要少得多。"
        }
    },
    {
        "translation": {
            "en": "One advantage of this was notational convenience; we were able to simplify Equation (8.2)[385].",
            "zh": "这样做的一个优点是符号的便利性;我们能够简化方程（8.2）[385]。"
        }
    },
    {
        "translation": {
            "en": "The predictions for this very simple ensemble model are given in Table 4.15[166] and visualized in Figure 4.22(c)[167], from which the characteristic step pattern of a decision tree is very obvious.",
            "zh": "表4.15[166]给出了这个非常简单的集成模型的预测，并在图4.22（c）[167]中可视化，从中可以明显看出决策树的特征步进模式。"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy measure shown in Equation (9.11)[551] uses an arithmetic mean and so can be more fully labeled averageclassaccuracyAM.",
            "zh": "公式（9.11）[551]中所示的平均类准确度度量使用算术平均值，因此可以更完整地标记为averageclassaccuracyAM。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41",
            "zh": "图 8.41"
        }
    },
    {
        "translation": {
            "en": "The topology of the network can provide some insight into this problem.",
            "zh": "网络的拓扑结构可以提供对此问题的一些见解。"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, organizations begin analytics projects simply because somebody in the organization feels that this is an important new technique that they should be using.",
            "zh": "然而，有时组织开始分析项目仅仅是因为组织中的某个人认为这是他们应该使用的重要新技术。"
        }
    },
    {
        "translation": {
            "en": "CLAIMANTS, NUM.",
            "zh": "索赔人，编号。"
        }
    },
    {
        "translation": {
            "en": "0.0599",
            "zh": "0.0599"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7(a)[194] illustrates the decision boundary when k = 15.",
            "zh": "图5.7（a）[194]说明了k = 15时的决策边界。"
        }
    },
    {
        "translation": {
            "en": "lift, 567, 569, 700",
            "zh": "升降机， 567， 569， 700"
        }
    },
    {
        "translation": {
            "en": "0.0095",
            "zh": "0.0095"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming conditional independence between features given the target feature value, calculate the probability (rounded to four places of decimal) of each outcome (PURCHASED=true, and PURCHASED=false) for the following book:",
            "zh": "（b） 假设给定目标特征值的特征之间的条件独立性，计算以下书籍的每个结果（PURCHASED=true 和 PURCHASED=false）的概率（四舍五入到小数点后四位）："
        }
    },
    {
        "translation": {
            "en": "columns in the data quality report highlight the percentage of missing values for each feature (both continuous and categorical) in an ABT, and so it is very easy to identify which features suffer from this issue.",
            "zh": "数据质量报告中的列突出显示了 ABT 中每个特征（连续和分类）的缺失值的百分比，因此很容易识别哪些特征存在此问题。"
        }
    },
    {
        "translation": {
            "en": "Any objects classified as belonging to the spiral target level were then presented to a model trained to distinguish between the three different spiral types.",
            "zh": "然后，将任何被归类为属于螺旋目标级别的物体呈现给经过训练以区分三种不同螺旋类型的模型。"
        }
    },
    {
        "translation": {
            "en": "The target feature is the Corruption Perception Index (CPI). The CPI measures the perceived levels of corruption in the public sector of countries and ranges from 0 (highly corrupt) to 100 (very clean).34",
            "zh": "目标特征是清廉指数 （CPI）。消费物价指数衡量的是各国公共部门的腐败程度，范围从0（高度腐败）到100（非常干净）34。"
        }
    },
    {
        "translation": {
            "en": "Calculate the δ values for each of the processing neurons in the network (i.e., δ6, δ5, δ4, δ3).",
            "zh": "计算网络中每个处理神经元（即 δ6、δ5、δ4、δ3）的δ值。"
        }
    },
    {
        "translation": {
            "en": "14.1   The alignment between the phases of CRISP-DM, key questions for analytics projects, and the chapters and sections of this book.",
            "zh": "14.1 CRISP-DM的各个阶段、分析项目的关键问题以及本书的章节和部分之间的一致性。"
        }
    },
    {
        "translation": {
            "en": "Once the vector of error gradients with respect to hxt has been calculated for each of the layers, ∂ℰ/∂hx is calculated using an elementwise sum of these vectors of gradients",
            "zh": "一旦计算了每个层的误差梯度向量，就会使用这些梯度向量的元素和来计算 ∂E/∂hx"
        }
    },
    {
        "translation": {
            "en": "environment, 643, 676",
            "zh": "环境， 643， 676"
        }
    },
    {
        "translation": {
            "en": "Figure 6.10[288] illustrates the Markov blanket of a node.",
            "zh": "图6.10[288]说明了节点的马尔可夫毯。"
        }
    },
    {
        "translation": {
            "en": "1.2   What Is Machine Learning?",
            "zh": "1.2 什么是机器学习？"
        }
    },
    {
        "translation": {
            "en": "If the agent is in the PM-DH state, they must have a total value in their hand of either 15, 16, 17, or 18.",
            "zh": "如果代理处于 PM-DH 状态，则他们手中的总值必须为 15、16、17 或 18。"
        }
    },
    {
        "translation": {
            "en": "data quality plan, 64, 94",
            "zh": "数据质量计划，64,94"
        }
    },
    {
        "translation": {
            "en": "Agents trained using SARSA tend to learn more conservative strategies than agents trained using Q-learning.",
            "zh": "使用 SARSA 训练的智能体往往比使用 Q-learning 训练的智能体学习更保守的策略。"
        }
    },
    {
        "translation": {
            "en": "This is often referred to as a small multiples visualization.",
            "zh": "这通常称为小倍数可视化。"
        }
    },
    {
        "translation": {
            "en": "In the context of a softmax layer, the non-normalized z values are often referred to as logits.",
            "zh": "在 softmax 层的上下文中，非规范化的 z 值通常称为 logits。"
        }
    },
    {
        "translation": {
            "en": "We can see from these examples that calculating derivatives of simple functions is a matter of, fairly mechanically, applying these four simple rules. Calculating the derivatives of the other two functions are left as exercises for the reader. Some of the functions that we will encounter later on in this chapter will be a little more complex, and we need two more differentiation rules to handle these.",
            "zh": "从这些例子中我们可以看出，计算简单函数的导数是相当机械地应用这四个简单规则的问题。计算其他两个函数的导数留给读者作为练习。我们将在本章后面遇到的一些函数会稍微复杂一些，我们需要更多的微分规则来处理这些规则。"
        }
    },
    {
        "translation": {
            "en": "off-policy reinforcement learning, 659, 676",
            "zh": "非政策强化学习，659,676"
        }
    },
    {
        "translation": {
            "en": "mean squared error loss, 625",
            "zh": "均方误差损耗，625"
        }
    },
    {
        "translation": {
            "en": "14.4   Your Next Steps",
            "zh": "14.4 您的下一步"
        }
    },
    {
        "translation": {
            "en": "The story of Professor Blondlot and N rays is true,1 and it is one of the most famous examples in all of science of how badly designed experiments can lead to completely inappropriate conclusions.",
            "zh": "布隆德洛特教授和 N 射线的故事是真实的，1 它是所有科学中最著名的例子之一，说明设计糟糕的实验会导致完全不恰当的结论。"
        }
    },
    {
        "translation": {
            "en": "Banerji, Manda, Ofer Lahav, Chris J. Lintott, Filipe B. Abdalla, Kevin Schawinski, Steven P. Bamford, Dan Andreescu, Phil Murray, M. Jordan Raddick, Anze Slosar, Alex Szalay, Daniel Thomas, and Jan Vandenberg. 2010. Galaxy zoo: Reproducing galaxy morphologies via machine learning. Monthly Notices of the Royal Astronomical Society 406 (1): 342–353.",
            "zh": "班纳吉、曼达、奥弗·拉哈夫、克里斯·林托特、菲利普·阿卜杜拉、凯文·沙温斯基、史蒂文·班福德、丹·安德莱斯库、菲尔·默里、M·乔丹·拉迪克、安泽·斯洛萨尔、亚历克斯·萨莱、丹尼尔·托马斯和扬·范登堡。2010. 星系动物园：通过机器学习再现星系形态。皇家天文学会月刊 406 （1）：342–353。"
        }
    },
    {
        "translation": {
            "en": "We concluded by explaining model ensembles.",
            "zh": "最后，我们解释了模型集合。"
        }
    },
    {
        "translation": {
            "en": "Krizhevsky, A., I. Sutskever, and G. E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 1097–1105.",
            "zh": "Krizhevsky， A.、I. Sutskever 和 GE Hinton。2012. 基于深度卷积神经网络的 Imagenet 分类.在神经信息处理系统进展中，1097-1105。"
        }
    },
    {
        "translation": {
            "en": "In this example, the cell state propagated forward from the previous time-step is ct−1 = [0.3,0.6 the hidden state propagated forward from the previous time-step is ht = [0.1,0.8 and the input at the xt = [0.9].",
            "zh": "在此示例中，从前一个时间步长向前传播的单元状态为 ct−1 = [0.3,0.6，从前一个时间步向前传播的隐藏状态为 ht = [0.1,0.8，xt = [0.9] 处的输入。"
        }
    },
    {
        "translation": {
            "en": "So, in complex domains, discriminative models are likely to be more accurate.",
            "zh": "因此，在复杂领域中，判别模型可能更准确。"
        }
    },
    {
        "translation": {
            "en": "Consequently, under this factorization, we need to calculate only seven probabilities directly from the data: P(m), P(h | m), P(h | ¬m), P(f | m), P(f | ¬m), P(v | m), and P(v | ¬m).",
            "zh": "因此，在这种因式分解下，我们只需要直接从数据中计算七个概率：P（m）、P（h | m）、P（h | ¬m）、P（f | m）、P（f | m）、P（v | m） 和 P（v | ¬m）。"
        }
    },
    {
        "translation": {
            "en": "Although any model can be used at the model training steps in gradient boosting, it is most common to use very shallow decision trees, or decision stumps—often just one level deep. This is using the same approach taken in random forests, which aims to combine a large number of weak learners into an overall strong learner.",
            "zh": "尽管任何模型都可以在梯度提升的模型训练步骤中使用，但最常见的是使用非常浅的决策树或决策树桩，通常只有一层深度。这使用了与随机森林相同的方法，旨在将大量弱学习者组合成一个整体强学习者。"
        }
    },
    {
        "translation": {
            "en": "A one-hot encoding is a vector-based representation of a categorial feature value.37 A one-hot vector has one element per level of the categorical feature.",
            "zh": "单热编码是分类特征值的基于向量的表示。37 单热向量在分类特征的每个级别都有一个元素。"
        }
    },
    {
        "translation": {
            "en": "A vector is an array of numbers, organized in a specific order. A vector can be either a column vector or a row vector. For example, a is a column vector, and b is a row vector.",
            "zh": "向量是按特定顺序组织的数字数组。向量可以是列向量，也可以是行向量。例如，a 是列向量，b 是行向量。"
        }
    },
    {
        "translation": {
            "en": "The hospital will use this model to make predictions for each patient when they visit the clinic and offer increased monitoring for those deemed to be at risk.",
            "zh": "医院将使用该模型对每位患者就诊时进行预测，并加强对被认为有风险的患者的监测。"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks are a network architecture that have been very successful at image processing tasks.",
            "zh": "卷积神经网络是一种在图像处理任务中非常成功的网络架构。"
        }
    },
    {
        "translation": {
            "en": "7.4.4.3 A worked example of multivariable logistic regression One of the advantages of using a logistic regression model is that it works well for datasets in which the instances with target features set to different levels overlap with each other in the feature space.",
            "zh": "7.4.4.3 多变量逻辑回归的有效示例 使用逻辑回归模型的优点之一是，它适用于目标特征设置为不同级别的实例在特征空间中相互重叠的数据集。"
        }
    },
    {
        "translation": {
            "en": "categorical cross entropy, 378",
            "zh": "分类交叉熵，378"
        }
    },
    {
        "translation": {
            "en": "It was understood by the AT retention team that customers often made a decision to churn if their bill increased significantly due to changing call patterns, or when they began to make large numbers of calls to new friends or colleagues on other networks.",
            "zh": "据 AT 保留团队了解，如果客户的账单因通话模式的改变而大幅增加，或者当他们开始向其他网络上的新朋友或同事拨打大量电话时，他们通常会做出流失的决定。"
        }
    },
    {
        "translation": {
            "en": "For ease of presentation we have reduced the input image to be a single column of 7 color pixels.",
            "zh": "为了便于演示，我们已将输入图像简化为一列 7 个颜色像素。"
        }
    },
    {
        "translation": {
            "en": "sampling with replacement, 159",
            "zh": "取样与更换，159"
        }
    },
    {
        "translation": {
            "en": "We noted at the start of this section that in order to train a deep network, it is important to keep the internal behavior of the network (i.e., the variance of the z values, activations, and δs) similar across all the layers during training, because doing so allows us to add more layers to the network while avoiding saturated units (by avoiding extreme z values) and exploding or vanishing δs.",
            "zh": "我们在本节开头指出，为了训练深度网络，在训练期间保持网络内部行为（即 z 值、激活和 δ 的方差）在所有层中相似是很重要的，因为这样做可以让我们向网络添加更多层，同时避免饱和单位（通过避免极端 z 值）和爆炸或消失 δs。"
        }
    },
    {
        "translation": {
            "en": "However, a popular combination is to use a stride length of 1 and to pad the image with imaginary pixels (Charniak, 2019, p. 56).",
            "zh": "然而，一种流行的组合是使用 1 的步幅并用假想像素填充图像（Charniak，2019 年，第 56 页）。"
        }
    },
    {
        "translation": {
            "en": "Like simpler boosting algorithms, gradient boosting iteratively trains prediction models trying to make later models specialize in areas that earlier models struggled with.",
            "zh": "与更简单的提升算法一样，梯度提升以迭代方式训练预测模型，试图使后来的模型专注于早期模型难以解决的领域。"
        }
    },
    {
        "translation": {
            "en": "There are, however, at least two reasons why simply searching for consistent models is not sufficient for learning useful prediction models.",
            "zh": "然而，至少有两个原因可以解释为什么仅仅搜索一致的模型不足以学习有用的预测模型。"
        }
    },
    {
        "translation": {
            "en": "unimodal distribution, 59, 272",
            "zh": "单峰分布， 59， 272"
        }
    },
    {
        "translation": {
            "en": "enrich data, 599, 629",
            "zh": "丰富数据，599,629"
        }
    },
    {
        "translation": {
            "en": "In this edition we have sought to expand the topics covered in the first edition to bring them up to date with modern developments, while at the same time staying true to the approach used in the first edition of covering the core concepts in the field in depth with fully worked examples.",
            "zh": "在本版中，我们试图扩展第一版中涵盖的主题，以使其与现代发展保持同步，同时忠实于第一版中使用的方法，即通过充分的实例深入涵盖该领域的核心概念。"
        }
    },
    {
        "translation": {
            "en": "A learning rate is used to control the size of the changes that are made to the action-value estimates at each iteration.",
            "zh": "学习率用于控制每次迭代时对操作值估计值所做的更改的大小。"
        }
    },
    {
        "translation": {
            "en": "First, it checks that the node is not NULL.",
            "zh": "首先，它检查节点是否为 NULL。"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.3 and Neuron 2 = 0.6, and that the desired output for this input is Neuron 5 = 0.7 and Neuron 6 = 0.4:",
            "zh": "（a） 假设处理神经元使用逻辑激活函数，网络的输入是神经元 1 = 0.3 和神经元 2 = 0.6，并且该输入的期望输出是神经元 5 = 0.7 和神经元 6 = 0.4："
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from the test of the AT churn prediction non-stratified hold-out test set.",
            "zh": "来自 AT 流失预测非分层保持测试集的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "OBJID",
            "zh": "OBJID的"
        }
    },
    {
        "translation": {
            "en": "NUMRETENTIONCALLS",
            "zh": "NUMRETENTIONCALLS"
        }
    },
    {
        "translation": {
            "en": "Technically, a filter can be defined as a heuristic rule that assesses the predictiveness of a feature using only the intrinsic properties of the data, independently of the learning algorithm that will use the features to induce the model.",
            "zh": "从技术上讲，过滤器可以定义为一种启发式规则，该规则仅使用数据的内在属性来评估特征的预测性，而与将使用特征来诱导模型的学习算法无关。"
        }
    },
    {
        "translation": {
            "en": "Conversely, if the feature we are dealing with is a continuous feature, the probability function is known as a probability density function.",
            "zh": "相反，如果我们处理的特征是连续特征，则概率函数称为概率密度函数。"
        }
    },
    {
        "translation": {
            "en": "“A map is not the territory it represents, but, if correct, it has a similar structure to the territory, which accounts for its usefulness.”",
            "zh": "“地图不是它所代表的领土，但是，如果正确的话，它与领土具有相似的结构，这解释了它的有用性。”"
        }
    },
    {
        "translation": {
            "en": "A key step in any predictive analytics project is deciding which type of predictive analytics model to use.",
            "zh": "任何预测分析项目的一个关键步骤是确定要使用的预测分析模型类型。"
        }
    },
    {
        "translation": {
            "en": "The silhouette width for an individual instance is essentially a localized ratio of inter-cluster and intra-cluster distances capturing how well the instance di has been clustered.",
            "zh": "单个实例的轮廓宽度实质上是集群间和集群内距离的局部比率，用于捕获实例 di 的聚类程度。"
        }
    },
    {
        "translation": {
            "en": "labeled dataset, 9",
            "zh": "标记数据集，9"
        }
    },
    {
        "translation": {
            "en": "The logistic regression approach (and the SVM approach) discussed in this chapter is at a disadvantage to those discussed in the previous chapters in that in its basic form, it can only handle categorical target features with two levels.",
            "zh": "本章讨论的逻辑回归方法（和 SVM 方法）与前几章讨论的方法相比处于劣势，因为它的基本形式只能处理具有两个级别的分类目标特征。"
        }
    },
    {
        "translation": {
            "en": "Andoni, Alexandr, and Piotr Indyk. 2006. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In Proceedings of the 47th annual IEEE symposium on foundations of computer science (FOCS’06), 459–468. IEEE.",
            "zh": "Andoni、Alexandr 和 Piotr Indyk。2006. 高维近似最近邻的近似哈希算法.在第 47 届年度 IEEE 计算机科学基础研讨会 （FOCS'06） 的论文集中，第 459–468 页。IEEE的。"
        }
    },
    {
        "translation": {
            "en": "For example, we might want to know the probability of the target feature taking a particular value and one of the descriptive features taking a particular value at the same time.",
            "zh": "例如，我们可能想知道目标特征采用特定值和描述性特征之一同时采用特定值的概率。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.10",
            "zh": "图 6.10"
        }
    },
    {
        "translation": {
            "en": "In Chapter 1[3] of this book we described supervised machine learning techniques as automatically learning a model of the relationship between a set of descriptive features and a target feature on the basis of a set of historical instances.",
            "zh": "在本书的第 1 章[3]中，我们将监督机器学习技术描述为基于一组历史实例自动学习一组描述性特征和目标特征之间关系的模型。"
        }
    },
    {
        "translation": {
            "en": "From top to bottom, the models use 0.4, 0.5, 0.62, 0.7, and 0.8, respectively, for w[1].",
            "zh": "从上到下，模型分别使用 0.4、0.5、0.62、0.7 和 0.8 表示 w[1]。"
        }
    },
    {
        "translation": {
            "en": "Adding depth to a filter not only enables a convolutional neural network to process color images that contain multiple channels; it also enables a convolutional network to have a sequence of multi-filter convolutional layers.",
            "zh": "为滤波器添加深度不仅使卷积神经网络能够处理包含多个通道的彩色图像;它还使卷积网络具有一系列多滤波器卷积层。"
        }
    },
    {
        "translation": {
            "en": "“free machine learning”",
            "zh": "“免费机器学习”"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks achieve translation equivariant feature detection through weight sharing.",
            "zh": "卷积神经网络通过权重共享实现平移等变特征检测。"
        }
    },
    {
        "translation": {
            "en": "The derivative of a saturated activation function is 0 (or near 0).",
            "zh": "饱和激活函数的导数为 0（或接近 0）。"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean tends toward the smaller values in a list of numbers and so can be less sensitive to large outliers than the arithmetic mean, which tends toward higher values.",
            "zh": "谐波平均值趋向于数字列表中的较小值，因此对大异常值的敏感度低于算术平均值，而算术平均值趋向于较高的值。"
        }
    },
    {
        "translation": {
            "en": "8. Target level imbalance affects misclassification rate in the same way, and average misclassification rate can also be calculated to combat this problem.",
            "zh": "8.目标水平不平衡以同样的方式影响误分类率，平均误分类率也可以计算出来解决这个问题。"
        }
    },
    {
        "translation": {
            "en": "2.4.3   Handling Time",
            "zh": "2.4.3 处理时间"
        }
    },
    {
        "translation": {
            "en": "To complete the network, we need to add the CPTs.",
            "zh": "为了完成网络，我们需要添加 CPT。"
        }
    },
    {
        "translation": {
            "en": "An analysis of historical data suggests that the rate of readmission within 30 days of being discharged for patients who were hospitalized for complications relating to diabetes is approximately 20%, compared to an overall average for all patients of approximately 11%.",
            "zh": "对历史数据的分析表明，因糖尿病相关并发症住院的患者在出院后 30 天内的再入院率约为 20%，而所有患者的总体平均水平约为 11%。"
        }
    },
    {
        "translation": {
            "en": "Despite this simplifying assumption, however, the naive Bayes approach has been found to be surprisingly accurate across a large range of domains.",
            "zh": "然而，尽管有这种简化的假设，但人们发现朴素的贝叶斯方法在广泛的领域中出奇地准确。"
        }
    },
    {
        "translation": {
            "en": "(b) Given the state representation that you have defined in Part (a) and the actions available to the agent, how many entries would the action-value function table for a tabular reinforcement learning agent trained for this task have?",
            "zh": "（b） 鉴于您在 （a） 部分中定义的状态表示以及代理可用的操作，为此任务训练的表格强化学习代理的动作值函数表将有多少个条目？"
        }
    },
    {
        "translation": {
            "en": "A key part of doing this is being able to decide which tests should be included in the sequence and in what order.",
            "zh": "这样做的一个关键部分是能够决定哪些测试应该包含在序列中以及以什么顺序。"
        }
    },
    {
        "translation": {
            "en": "k-d tree, 181, 196, 212, 232, 241",
            "zh": "K-D树， 181， 196， 212， 232， 241"
        }
    },
    {
        "translation": {
            "en": "There are two ways that this can speed up neural network training and data processing:",
            "zh": "有两种方法可以加快神经网络训练和数据处理速度："
        }
    },
    {
        "translation": {
            "en": "Multiplying the weight matrix by the augmented input vector generates the vector of weighted sums for the hidden layer neurons, z(1).",
            "zh": "将权重矩阵乘以增强的输入向量，生成隐藏层神经元的加权和向量 z（1）。"
        }
    },
    {
        "translation": {
            "en": "backward sequential selection, 229",
            "zh": "向后顺序选择，229"
        }
    },
    {
        "translation": {
            "en": "10.8   (a)–(f) Different clusterings found for the mobile phone customer dataset in Table 10.1[604] for values of k in (2, 9). (g) shows the silhouette for each clustering.",
            "zh": "10.8 （a）–（f） 表10.1[604]中（2,9）中k值的移动电话客户数据集发现不同的聚类。（g） 显示每个聚类的轮廓。"
        }
    },
    {
        "translation": {
            "en": "We describe a range of different sampling techniques that can be used to do this.",
            "zh": "我们描述了一系列可用于执行此操作的不同采样技术。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.140)[521] expands out the full set of operations and terms that are used in the calculation of ∂ℰt/∂ct−1.",
            "zh": "方程（8.140）[521]扩展了用于计算∂Et/∂ct−1的全套运算和项。"
        }
    },
    {
        "translation": {
            "en": "This introduces something of an explosion in the number of weights required for a model, as we have an individual set of weights for every target feature level.",
            "zh": "这引入了模型所需的权重数量的爆炸式增长，因为我们为每个目标特征级别都有一组单独的权重。"
        }
    },
    {
        "translation": {
            "en": "The system will be integrated into the factory’s production line and determine whether components are of an acceptable quality standard based on a set of test results.",
            "zh": "该系统将被集成到工厂的生产线中，并根据一组测试结果确定组件是否符合可接受的质量标准。"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning is a simple, iterative, tabular approach to learning the action-value function, Qπ(st,at), that is quite effective.",
            "zh": "时间差分学习是一种简单的、迭代的、表格化的方法来学习动作-价值函数 Qπ（st，at），非常有效。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.20",
            "zh": "图 8.20"
        }
    },
    {
        "translation": {
            "en": "recall, 548, 549, 551, 572",
            "zh": "召回， 548， 549， 551， 572"
        }
    },
    {
        "translation": {
            "en": "On the other hand, some of the machine learning techniques that we discuss in upcoming chapters perform poorly in the presence of outliers.",
            "zh": "另一方面，我们在接下来的章节中讨论的一些机器学习技术在存在异常值的情况下表现不佳。"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature AGE and the target feature, CLASS.",
            "zh": "（a） 下面的可视化图说明了连续特征 AGE 与目标特征 CLASS 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "For example, a large negative z value ( ≈ z < −2) or a large positive z value ( ≈ z > +2) will cause the logistic function to saturate, and a large negative z < 0 will cause the rectified linear function to saturate.",
            "zh": "例如，较大的负 z 值 （ ≈ z < −2） 或较大的正 z 值 （ ≈ z > +2） 将导致逻辑函数饱和，而较大的负 z < 0 将导致整流后的线性函数饱和。"
        }
    },
    {
        "translation": {
            "en": "This sampling of the feature set is known as subspace sampling.",
            "zh": "特征集的这种采样称为子空间采样。"
        }
    },
    {
        "translation": {
            "en": "This is done as follows:",
            "zh": "具体操作如下："
        }
    },
    {
        "translation": {
            "en": "Continuous",
            "zh": "连续的"
        }
    },
    {
        "translation": {
            "en": "Histograms of the EXPRAD_R feature split by target feature level.",
            "zh": "按目标特征级别划分的EXPRAD_R特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "The data quality report gives an in-depth picture of the data in an ABT, and we should study it in detail in order to get to know the data that we will work with.",
            "zh": "数据质量报告提供了 ABT 中数据的深入图片，我们应该详细研究它，以便了解我们将要处理的数据。"
        }
    },
    {
        "translation": {
            "en": "7.2   (a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset. A collection of possible simple linear regression models capturing the relationship between these two features are also shown. (b) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset showing a candidate prediction model and the resulting errors.",
            "zh": "7.2 （a） 写字楼租赁数据集中 SIZE 和 RENTAL PRICE 特征的散点图。还显示了一组可能的简单线性回归模型，用于捕获这两个特征之间的关系。（b） 写字楼租赁数据集中 SIZE 和 RENTAL PRICE 特征的散点图，显示候选预测模型和由此产生的误差。"
        }
    },
    {
        "translation": {
            "en": "Notice that within this set, P(GC = none | ¬fr) is quite large, and at the other extreme, P(GC = guarantor | ¬fr) = is equal to zero.",
            "zh": "请注意，在此集合中，P（GC = none | ¬fr） 非常大，而在另一个极端，P（GC = 担保人 | ¬fr） = 等于零。"
        }
    },
    {
        "translation": {
            "en": "9.4.2 Performance Measures: Categorical Targets",
            "zh": "9.4.2 绩效衡量：分类目标"
        }
    },
    {
        "translation": {
            "en": "In the next section we discuss the standard approach to clustering, the k-means clustering algorithm.",
            "zh": "在下一节中，我们将讨论聚类的标准方法，即 k-means 聚类算法。"
        }
    },
    {
        "translation": {
            "en": "Consequently, if we wish to calculate the error gradient of a network with multiple outputs over multiple examples, we simply sum the error gradients for each output over the examples.",
            "zh": "因此，如果我们想计算多个示例上具有多个输出的网络的误差梯度，我们只需将每个输出的误差梯度相加即可。"
        }
    },
    {
        "translation": {
            "en": "Recall that the expected return is the cumulative reward that the agent expects to receive if it takes action at in state st and then follows the policy π all the way to the end of the episode.",
            "zh": "回想一下，预期回报是代理在状态 st 采取行动，然后一直遵循策略π直到剧集结束时期望获得的累积奖励。"
        }
    },
    {
        "translation": {
            "en": "For example, a set of confusion matrices gives a detailed description of how a set of models trained on a categorical prediction problem performed and can be used for a detailed comparison of performances.",
            "zh": "例如，一组混淆矩阵详细描述了一组在分类预测问题上训练的模型的执行方式，并可用于详细的性能比较。"
        }
    },
    {
        "translation": {
            "en": "The plot on the left of Figure 8.8[398] shows the input space for the AND with the convention that FALSE has been mapped to 0 and TRUE has been mapped to 1.4 In the plot each of the four possible input combinations is labeled as either triggering a TRUE response (shown in the figure by a clear dot) or FALSE (shown in the figure by a black dot).",
            "zh": "图 8.8[398] 左侧的图显示了 AND 的输入空间，其约定是 FALSE 已映射到 0，TRUE 已映射到 1.4 在图中，四种可能的输入组合中的每一种都被标记为触发 TRUE 响应（在图中用明点显示）或 FALSE（在图中用黑点显示）。"
        }
    },
    {
        "translation": {
            "en": "Table 9.16",
            "zh": "表 9.16"
        }
    },
    {
        "translation": {
            "en": "The granularity of the data that the business has available. In a bricks-and-mortar retail scenario, data on sales might only be stored as a total number of sales per product type per day, rather than as individual items sold to individual customers.",
            "zh": "业务可用数据的粒度。在实体零售方案中，销售数据可能仅存储为每种产品类型每天的销售总数，而不是作为销售给单个客户的单个商品。"
        }
    },
    {
        "translation": {
            "en": "These first two questions are not always easy to answer.",
            "zh": "前两个问题并不总是容易回答。"
        }
    },
    {
        "translation": {
            "en": "Subscripts are used to index into a list of instances.",
            "zh": "下标用于索引到实例列表中。"
        }
    },
    {
        "translation": {
            "en": "A dataset of instances from the sample space in Figure B.1[757].",
            "zh": "图B.1[757]中样本空间中的实例数据集。"
        }
    },
    {
        "translation": {
            "en": "7. This is a simple manufactured example for this book, but this type of model is often used in epidemiology Hunter et al. (2018).",
            "zh": "7. 这是本书的一个简单制造示例，但这种类型的模型经常用于流行病学 Hunter 等人（2018 年）。"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_U_G",
            "zh": "PETROMAGDIFF_U_G"
        }
    },
    {
        "translation": {
            "en": "If index is not a whole number, then we interpolate the value for the ith percentile as",
            "zh": "如果 index 不是整数，则我们将第 i 个百分位数的值代值为"
        }
    },
    {
        "translation": {
            "en": "The book is intended for use in machine learning, data mining, data analytics, or artificial intelligence modules of undergraduate and postgraduate computer science, natural and social science, engineering, and business courses.",
            "zh": "本书旨在用于本科和研究生计算机科学、自然和社会科学、工程和商业课程的机器学习、数据挖掘、数据分析或人工智能模块。"
        }
    },
    {
        "translation": {
            "en": "Imagine that we attempt to learn a prediction model for this retail scenario by searching for a model that is consistent with the dataset.",
            "zh": "想象一下，我们尝试通过搜索与数据集一致的模型来学习此零售场景的预测模型。"
        }
    },
    {
        "translation": {
            "en": "invariant distribution, 299",
            "zh": "不变分布，299"
        }
    },
    {
        "translation": {
            "en": "In this figure, SPEED has been plotted on the horizontal axis, and AGILITY has been plotted on the vertical axis.",
            "zh": "在此图中，SPEED绘制在横轴上，AGILITY绘制在纵轴上。"
        }
    },
    {
        "translation": {
            "en": "13.4   Modeling",
            "zh": "13.4 建模"
        }
    },
    {
        "translation": {
            "en": "We believe that this book will give you the knowledge and skills that you will need to explore these topics yourself.",
            "zh": "我们相信这本书将为您提供自己探索这些主题所需的知识和技能。"
        }
    },
    {
        "translation": {
            "en": "“It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.”",
            "zh": "“在拥有数据之前就进行理论化是一个大错误。不知不觉中，人们开始歪曲事实以适应理论，而不是理论以适应事实。"
        }
    },
    {
        "translation": {
            "en": "Table 6.19",
            "zh": "表 6.19"
        }
    },
    {
        "translation": {
            "en": "Once the individual models in an ensemble have been induced, the ensemble makes predictions by returning the majority vote or the median, depending on the type of prediction required.",
            "zh": "一旦集成中的单个模型被诱导出来，集成就会通过返回多数投票或中位数来进行预测，具体取决于所需的预测类型。"
        }
    },
    {
        "translation": {
            "en": "Calculate the output of the model (using the updated weights calculated in the previous part) for these two instances.",
            "zh": "计算这两个实例的模型输出（使用上一部分中计算的更新权重）。"
        }
    },
    {
        "translation": {
            "en": "However, it will implement a function, and once the network has been initialized we can now train the network to implement a useful function by iteratively presenting examples to the network and using the error of the network on the examples to update the weights so that the network converges on a set of weights that implement a useful function relative to the patterns in the training data.",
            "zh": "但是，它将实现一个函数，一旦网络被初始化，我们现在可以通过迭代地向网络提供示例并使用示例上的网络误差来更新权重来训练网络来实现一个有用的函数，以便网络收敛到一组权重上，这些权重实现了一个相对于训练数据中的模式的有用函数。"
        }
    },
    {
        "translation": {
            "en": "The only way that this can happen is if there is at least one instance on the other side of the hyperplane boundary that bisects the node that is closer to the query than the current best-distance.",
            "zh": "发生这种情况的唯一方法是，如果超平面边界的另一侧至少有一个实例将比当前最佳距离更接近查询的节点一分为二。"
        }
    },
    {
        "translation": {
            "en": "1. Explain the most important and popular algorithms clearly, rather than overview the full breadth of machine learning. As teachers we believe that giving students a deep knowledge of the core concepts underpinning a field provides them with a solid basis from which they can explore the field themselves. This sharper focus allows us to spend more time introducing, explaining, illustrating, and contextualizing the algorithms that are fundamental to the field and their uses.",
            "zh": "1. 清楚地解释最重要和最流行的算法，而不是概述机器学习的全部广度。作为教师，我们相信，让学生深入了解支撑一个领域的核心概念，为他们提供了坚实的基础，让他们可以从中自己探索该领域。这种更敏锐的关注使我们能够花更多的时间来介绍、解释、说明和背景化对该领域及其用途至关重要的算法。"
        }
    },
    {
        "translation": {
            "en": "4.5 Summary",
            "zh": "4.5 小结"
        }
    },
    {
        "translation": {
            "en": "Both equal-width and equal-frequency binning require that we manually specify how many bins we would like to use. Deciding on the number of bins can be difficult. The general trade-off is this:",
            "zh": "等宽和等频分箱都要求我们手动指定要使用的箱数。确定垃圾箱的数量可能很困难。一般的权衡是这样的："
        }
    },
    {
        "translation": {
            "en": "These predictions would be normalized as follows:",
            "zh": "这些预测将按如下方式规范化："
        }
    },
    {
        "translation": {
            "en": "Michie, D. 1963. Experiments on the mechanisation of game learning. Computer Journal 1: 232–263.",
            "zh": "米奇，D. 1963 年。游戏学习机械化的实验。计算机杂志 1：232-263。"
        }
    },
    {
        "translation": {
            "en": "0.1   Suggested course syllabi.",
            "zh": "0.1 建议的课程大纲。"
        }
    },
    {
        "translation": {
            "en": "There are two kinds of outliers that might occur in an ABT: invalid outliers and valid outliers.",
            "zh": "ABT 中可能出现两种异常值：无效异常值和有效异常值。"
        }
    },
    {
        "translation": {
            "en": "Table 1.2",
            "zh": "表 1.2"
        }
    },
    {
        "translation": {
            "en": "The bar plots shown in the data quality report are also very useful here.",
            "zh": "数据质量报告中显示的条形图在这里也非常有用。"
        }
    },
    {
        "translation": {
            "en": "Usually the player bets money on their ability to do this, and the dealer uses a little manual trickery to misdirect the player toward the wrong card.",
            "zh": "通常，玩家将钱押在他们这样做的能力上，而庄家使用一些手动技巧将玩家误导到错误的牌上。"
        }
    },
    {
        "translation": {
            "en": "The dotted line indicates a stability index value of 0.1, above which a model should be closely monitored, and the dashed line indicates a stability index of 0.25, above which corrective action is recommended.",
            "zh": "虚线表示稳定性指数值为 0.1，高于该值时应密切监控模型，虚线表示稳定性指数为 0.25，高于该值建议采取纠正措施。"
        }
    },
    {
        "translation": {
            "en": "The ReLU network’s per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "ReLU 网络的每个示例预测、误差和训练后的平方误差之和已收敛到 SSE < 0.0001。"
        }
    },
    {
        "translation": {
            "en": "The second way that a naive weight initialization can lead to instability during training is that very small or large weights can result in unstable gradients.",
            "zh": "朴素权重初始化可能导致训练期间不稳定的第二种方式是，非常小或很大的权重都会导致梯度不稳定。"
        }
    },
    {
        "translation": {
            "en": "Although reinforcement learning can be used for many different tasks, its most common application is in learning to control the behaviors of autonomous systems—for example, training robots to perform tasks, or automated players to play games—and this is the application that this chapter focuses on.",
            "zh": "尽管强化学习可以用于许多不同的任务，但其最常见的应用是学习控制自主系统的行为，例如，训练机器人执行任务，或训练自动玩家玩游戏，这是本章重点介绍的应用。"
        }
    },
    {
        "translation": {
            "en": "A full joint probability distribution encodes the probabilities for all joint events in the domain.",
            "zh": "完整的联合概率分布对域中所有联合事件的概率进行编码。"
        }
    },
    {
        "translation": {
            "en": "3.13   The effect of using different numbers of bins when using binning to convert a continuous feature into a categorical feature.",
            "zh": "3.13 使用分箱将连续特征转换为分类特征时使用不同数量的条柱的效果。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.1",
            "zh": "图 2.1"
        }
    },
    {
        "translation": {
            "en": "The basic principle informing how weights in a neural network should be adjusted is that a weight should be updated in proportion to the sensitivity of the network error to changes in the weight.",
            "zh": "告知如何调整神经网络中的权重的基本原则是，权重应根据网络误差对权重变化的敏感性成比例地更新。"
        }
    },
    {
        "translation": {
            "en": "The reason is that although a convolutional layer that runs multiple filters in parallel over its input will generate multiple feature maps, the next convolutional layer can treat these multiple feature maps as if they were a single multi-channel input.",
            "zh": "原因是，尽管在其输入上并行运行多个滤波器的卷积层将生成多个特征图，但下一个卷积层可以将这些多个特征图视为单个多通道输入。"
        }
    },
    {
        "translation": {
            "en": "EXPFLUX_U/G/R/I/Z",
            "zh": "EXPFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It does, however, need to be updated occasionally because otherwise the estimated values used in the loss function will be inaccurate.",
            "zh": "但是，它确实需要偶尔更新，否则损失函数中使用的估计值将不准确。"
        }
    },
    {
        "translation": {
            "en": "Ratios: Ratios are continuous features that capture the relationship between two or more raw data values.",
            "zh": "比率：比率是捕获两个或多个原始数据值之间关系的连续要素。"
        }
    },
    {
        "translation": {
            "en": "In a sense, the unrolled recurrent neural network is similar to a convolutional neural network in that weights are shared between different neurons: the neurons in the hidden layer at time t = 1 use exactly the same weights as the neurons in the hidden layer at time t = 2 and t = 3, and so on.",
            "zh": "从某种意义上说，展开的循环神经网络类似于卷积神经网络，因为权重在不同的神经元之间共享：在时间 t = 1 时隐藏层中的神经元使用与在时间 t = 2 和 t = 3 时隐藏层中的神经元完全相同的权重，依此类推。"
        }
    },
    {
        "translation": {
            "en": "4.3   Standard Approach: The ID3 Algorithm",
            "zh": "4.3 标准方法：ID3 算法"
        }
    },
    {
        "translation": {
            "en": "Calculate the output generated by the network in response to this input.",
            "zh": "计算网络响应此输入生成的输出。"
        }
    },
    {
        "translation": {
            "en": "The starting position is shown marked with an S and the goal position is marked with a G. The cells marked with an f represent fiery ground that will damage the agent if it is crossed.",
            "zh": "起始位置标有 S，目标位置标有 G。标有 f 的单元格代表炽热的地面，如果穿过它会损坏代理。"
        }
    },
    {
        "translation": {
            "en": "In consultation with the members of the AT executive team and the retention team, Ross agreed that his goal would be to create a churn prediction system that would achieve a prediction accuracy in excess of 75%.",
            "zh": "在与 AT 执行团队和保留团队成员协商后，Ross 一致认为他的目标是创建一个客户流失预测系统，该系统的预测准确率将超过 75%。"
        }
    },
    {
        "translation": {
            "en": "Contrast this with a feature that measures age in years; this feature is likely to have a spread of values with a maximum of just over 100.",
            "zh": "与此形成鲜明对比的是以年为单位测量年龄的功能;此功能可能具有最大值略高于 100 的值分布。"
        }
    },
    {
        "translation": {
            "en": "If we are defining the probability function for a categorical feature, then the function is known as a probability mass function because it can be understood as returning a discrete probability mass for each level in the domain of the feature.",
            "zh": "如果我们要为分类特征定义概率函数，则该函数称为概率质量函数，因为它可以理解为返回特征域中每个水平的离散概率质量。"
        }
    },
    {
        "translation": {
            "en": "10.1   A dataset of mobile phone customers described by their average monthly data (DATA USAGE) and call (CALL VOLUME) usage. Details of the first two iterations of the k-means clustering algorithm are also shown. The clustering in the second iteration is actually the final clustering in this simple example.",
            "zh": "10.1 移动电话客户的数据集，由其平均每月数据（DATA USAGE）和通话量（CALL VOLUME）使用情况描述。还显示了 k-means 聚类算法的前两次迭代的详细信息。在这个简单示例中，第二次迭代中的聚类实际上是最终聚类。"
        }
    },
    {
        "translation": {
            "en": "10.14   The architecture of an auto-encoder network made up of an encoder and a decoder connected by a bottleneck layer.",
            "zh": "10.14 由编码器和解码器组成的自动编码器网络的架构，通过瓶颈层连接。"
        }
    },
    {
        "translation": {
            "en": "Differentiation Techniques for Machine Learning",
            "zh": "机器学习的差异化技术"
        }
    },
    {
        "translation": {
            "en": "classification accuracy, 539, 545, 550",
            "zh": "分类精度，539、545、550"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that in reality, the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process are performed iteratively rather than linearly.",
            "zh": "重要的是要记住，在现实中，CRISP-DM 流程的业务理解、数据理解和数据准备阶段是迭代执行的，而不是线性执行的。"
        }
    },
    {
        "translation": {
            "en": "17. The term arising from ϕ7 is commonly referred to as an interaction term because it allows two descriptive features to interact in the model.",
            "zh": "17. 由φ7产生的项通常被称为交互项，因为它允许两个描述性特征在模型中相互作用。"
        }
    },
    {
        "translation": {
            "en": "Notice how the model gets closer and closer to a model that accurately captures the relationship between SIZE and RENTAL PRICE.",
            "zh": "请注意，该模型如何越来越接近准确捕获 SIZE 和 RENTAL PRICE 之间关系的模型。"
        }
    },
    {
        "translation": {
            "en": "Similar to the histograms in Figure 3.9[79], this visualization shows a slight indication that centers tend to be older than forwards and guards, but the three box plots overlap significantly, suggesting that this relationship is not very strong.",
            "zh": "与图3.9[79]中的直方图类似，该可视化显示了一个轻微的迹象，即中锋往往比前锋和后卫更老，但三个箱形图明显重叠，表明这种关系不是很强。"
        }
    },
    {
        "translation": {
            "en": "calculate the overall output of the ensemble for each instance in the test dataset.",
            "zh": "计算测试数据集中每个实例的集成总输出。"
        }
    },
    {
        "translation": {
            "en": "vanishing gradients, 387, 403, 435, 451, 507",
            "zh": "消失梯度，387、403、435、451、507"
        }
    },
    {
        "translation": {
            "en": "mode imputation, 374",
            "zh": "模态插补，374"
        }
    },
    {
        "translation": {
            "en": "The entropy remaining after we have tested d is a weighted sum of the entropy, still with respect to the target feature, of each partition.",
            "zh": "我们测试 d 后剩余的熵是每个分区的熵的加权和，仍然相对于目标特征。"
        }
    },
    {
        "translation": {
            "en": "Ross hoped that this would make his task a little easier because Grace was the main gatekeeper to all the data resources at AT, and having her support for the project would be important.",
            "zh": "Ross 希望这会让他的任务变得更容易一些，因为 Grace 是 AT 所有数据资源的主要看门人，获得她对项目的支持非常重要。"
        }
    },
    {
        "translation": {
            "en": "3. This explanation is inspired by the discussion in Reagen et al. (2017, p. 14).",
            "zh": "3. 这种解释的灵感来自 Reagen 等人（2017 年，第 14 页）中的讨论。"
        }
    },
    {
        "translation": {
            "en": "This can be seen in the increasing sums of squared errors in Figure 7.9(b)[336].",
            "zh": "这可以从图7.9（b）[336]中平方误差和的增加中看出。"
        }
    },
    {
        "translation": {
            "en": "What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia when the descriptive features have been normalized using range normalization?",
            "zh": "当使用范围归一化对描述性特征进行归一化时，使用欧几里得距离的 3 最近邻预测模型对俄罗斯的 CPI 返回的值是多少？"
        }
    },
    {
        "translation": {
            "en": "This is done by creating one new binary descriptive feature for every level of the categorical feature.",
            "zh": "这是通过为分类特征的每个级别创建一个新的二进制描述性特征来完成的。"
        }
    },
    {
        "translation": {
            "en": "When an axon of a cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased. (Hebb, 1949, p. 62)",
            "zh": "当细胞 A 的轴突足够接近以激发细胞 B 并反复或持续地参与发射它时，一个或两个细胞中会发生一些生长过程或代谢变化，使得 A 的效率，作为发射 B 的细胞之一，会增加。（Hebb，1949 年，第 62 页）"
        }
    },
    {
        "translation": {
            "en": "Generative/",
            "zh": "生成/"
        }
    },
    {
        "translation": {
            "en": "We use the network architecture illustrated in Figure 8.4[390] as the structure for the model we train.",
            "zh": "我们使用图 8.4[390] 所示的网络架构作为我们训练的模型的结构。"
        }
    },
    {
        "translation": {
            "en": "5.1 Big Idea",
            "zh": "5.1 大创意"
        }
    },
    {
        "translation": {
            "en": "When we talk about categorical features, we refer to the set of possible values that a categorical feature can take as the levels of the feature or the domain of the feature.",
            "zh": "当我们谈论分类特征时，我们指的是分类特征可以作为特征的级别或特征域的可能值集。"
        }
    },
    {
        "translation": {
            "en": "For categorical target features, the ensemble returns the majority target level using a weighted vote.",
            "zh": "对于分类目标要素，集成使用加权投票返回多数目标级别。"
        }
    },
    {
        "translation": {
            "en": "We indicate the identity of the neuron in which the calculation occurred using a subscript.",
            "zh": "我们使用下标指示发生计算的神经元的身份。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.12",
            "zh": "图 8.12"
        }
    },
    {
        "translation": {
            "en": "population, 750",
            "zh": "人口， 750"
        }
    },
    {
        "translation": {
            "en": "valid outliers, 65, 68, 715",
            "zh": "有效异常值、65、68、715"
        }
    },
    {
        "translation": {
            "en": "nearest neighbor, 303, 732, 736",
            "zh": "最近邻， 303， 732， 736"
        }
    },
    {
        "translation": {
            "en": "3. Machine learning is often referred to as an ill-posed problem. What does this mean?",
            "zh": "3. 机器学习通常被称为一个病态的问题。这是什么意思？"
        }
    },
    {
        "translation": {
            "en": "5.3   Standard Approach: The Nearest Neighbor Algorithm",
            "zh": "5.3 标准方法：最近邻算法"
        }
    },
    {
        "translation": {
            "en": "We will see in the next section how the best-fit set of weights for this equation are found, but for now we will set w[0] = −0.1513, w[1] = 0.6270, w[2] = −0.1781, and w[3] = 0.0714. This means that the model is rewritten",
            "zh": "我们将在下一节中看到如何找到该方程的最佳拟合权重集，但现在我们将设置 w[0] = −0.1513、w[1] = 0.6270、w[2] = −0.1781 和 w[3] = 0.0714。这意味着模型被重写"
        }
    },
    {
        "translation": {
            "en": "6.13   The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.11[278], extended to include the conditional probabilities for the new ACCOUNT BALANCE feature, which are defined in terms of PDFs.",
            "zh": "6.13 朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表6.11[278]中的数据集计算得出，扩展为包括新的账户余额特征的条件概率，这些概率是用PDF定义的。"
        }
    },
    {
        "translation": {
            "en": "The distances (Dist.) between the query instance with SPEED = 6.75 and AGILITY = 3.00 and each instance in Table 5.2[183].",
            "zh": "SPEED = 6.75 且 AGILITY = 3.00 的查询实例与表 5.2[183] 中每个实例之间的距离 （Dist.）。"
        }
    },
    {
        "translation": {
            "en": "This section describes some of the most important of these measures.",
            "zh": "本节介绍其中一些最重要的措施。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS; DIVERSITY OF CLAIM TYPES: CLAIM DIV.",
            "zh": "索赔;索赔类型的多样性：索赔科"
        }
    },
    {
        "translation": {
            "en": "In a reinforcement learning scenario an agent inhabiting an environment attempts to achieve a goal by taking a sequence of actions to move it between states.",
            "zh": "在强化学习场景中，居住在环境中的智能体试图通过采取一系列操作在状态之间移动目标来实现目标。"
        }
    },
    {
        "translation": {
            "en": "The ELECTRICAL OUTPUT feature is the target feature for this example.",
            "zh": "ELECTRICAL OUTPUT 特征是此示例的目标特征。"
        }
    },
    {
        "translation": {
            "en": "14.2 Choosing a Machine Learning Approach",
            "zh": "14.2 选择机器学习方法"
        }
    },
    {
        "translation": {
            "en": "In one of these experiments, the brightening of a small spark that occurs when an object that supposedly emits N rays is brought close to it is measured.",
            "zh": "在其中一个实验中，测量了当一个据称发射N射线的物体靠近它时发生的小火花的增亮。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the outcome period was defined as three months.3",
            "zh": "因此，结果期被定义为三个月。"
        }
    },
    {
        "translation": {
            "en": "The conclusion is that in order to create networks that can represent complex non-linear functions, it is not enough to add layers; we must also include non-linearities between these layers.",
            "zh": "结论是，为了创建可以表示复杂非线性函数的网络，仅仅添加层是不够的;我们还必须包括这些层之间的非线性。"
        }
    },
    {
        "translation": {
            "en": "If a neural network (see Chapter 8[381]) is used for this task (and that is what we will use in the approach described in this section), we can output the value of all actions in a given state at the same time across the output layer of a network. So, the problem is reframed",
            "zh": "如果神经网络（参见第 8 章 [381]）用于此任务（我们将在本节描述的方法中使用），我们可以在网络的输出层中同时输出给定状态下所有操作的值。因此，问题被重新定义"
        }
    },
    {
        "translation": {
            "en": "9   Evaluation",
            "zh": "9 评估"
        }
    },
    {
        "translation": {
            "en": "exploring the data to understand it correctly;",
            "zh": "探索数据以正确理解数据;"
        }
    },
    {
        "translation": {
            "en": "The value returned by a probability function for an event is simply the relative frequency of that event in the dataset.",
            "zh": "事件的概率函数返回的值只是该事件在数据集中的相对频率。"
        }
    },
    {
        "translation": {
            "en": "With this in mind, it is instructive to refer to Figure 8.13[410], which plots the logistic function and the derivative of the logistic function.",
            "zh": "考虑到这一点，参考图 8.13[410] 很有启发性，它绘制了逻辑函数和逻辑函数的导数。"
        }
    },
    {
        "translation": {
            "en": "Table 3.1(a)[55] shows the structure of the table in a data quality report that describes continuous features.",
            "zh": "表 3.1（a）[55] 显示了描述连续特征的数据质量报告中的表的结构。"
        }
    },
    {
        "translation": {
            "en": "The PRICE achieved at auction by the each bottle is also included.",
            "zh": "每瓶酒在拍卖会上达到的价格也包括在内。"
        }
    },
    {
        "translation": {
            "en": "In order to do this, a generative model must learn, or encode, the distribution of the data belonging to each class.",
            "zh": "为此，生成模型必须学习或编码属于每个类的数据的分布。"
        }
    },
    {
        "translation": {
            "en": "model-based reinforcement learning, 643",
            "zh": "基于模型的强化学习，643"
        }
    },
    {
        "translation": {
            "en": "1.4   Potential prediction models (a) before and (b) after training data becomes available.",
            "zh": "1.4 潜在的预测模型（a）在训练数据可用之前和（b）之后。"
        }
    },
    {
        "translation": {
            "en": "8.1   Hourly samples of ambient factors and full load electrical power output of a combined cycle power plant.",
            "zh": "8.1 联合循环电厂环境因素和满负荷电力输出的每小时样本。"
        }
    },
    {
        "translation": {
            "en": "Sampling bias is closely related to the problem of selection bias, and the terms are often treated as synonyms.",
            "zh": "抽样偏差与选择偏差问题密切相关，这些术语通常被视为同义词。"
        }
    },
    {
        "translation": {
            "en": "Imagine a very simple two layer network (one hidden layer and an output layer) with linear neurons (neurons that don’t include an activation function, so that the output activation is just the weighted sum of the inputs).3 The calculation of the activations for the neurons in the first layer can be expressed as follows:",
            "zh": "想象一个非常简单的两层网络（一个隐藏层和一个输出层），其中有线性神经元（不包括激活函数的神经元，因此输出激活只是输入的加权和）.3 第一层中神经元激活的计算可以表示如下："
        }
    },
    {
        "translation": {
            "en": "Varying the value λ changes the rate at which the density drops off.",
            "zh": "改变值 λ 会改变密度下降的速率。"
        }
    },
    {
        "translation": {
            "en": "The similarity between the current trial user, q, and the two users in the dataset, d1 and d2, in terms of co-presence (CP), co-absence (CA), presence-absence (PA), and absence-presence (AP).",
            "zh": "当前试验用户 q 与数据集中的两个用户 d1 和 d2 在共存 （CP）、共缺 （CA）、缺勤 （PA） 和缺勤 （AP） 方面的相似性。"
        }
    },
    {
        "translation": {
            "en": "8.4.6.3 Long short-term memory networks Recurrent neural networks are particularly susceptible to the exploding gradients and vanishing gradients problems we discussed in Section 8.4.1[434] and Section 8.4.2[447].",
            "zh": "8.4.6.3 长短期记忆网络 递归神经网络特别容易受到我们在 8.4.1[434] 和 8.4.2[447] 中讨论的梯度爆炸和梯度消失问题的影响。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the error gradients in the backward pass can propagate along the paths of active neurons in the network, and because ∂ak/∂zk = 1 along these paths, the gradients can flow back through a deeper network (Glorot et al., 2011).",
            "zh": "因此，向后传递中的误差梯度可以沿着网络中活跃神经元的路径传播，并且由于∂ak / ∂zk = 1沿着这些路径，梯度可以通过更深的网络流回（Glorot等人，2011）。"
        }
    },
    {
        "translation": {
            "en": "Maas, Andrew L., Awni Y. Hannun, and Andrew Y. Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In Proceedings of thirtieth international conference on machine learning (ICML 13), Vol. 30. JMLR.",
            "zh": "Maas、Andrew L.、Awni Y. Hannun 和 Andrew Y. Ng. 2013。整流器非线性改善了神经网络声学模型。第30届机器学习国际会议（ICML 13）论文集，第30卷。JMLR。"
        }
    },
    {
        "translation": {
            "en": "MCMC, 298",
            "zh": "MCMC，298"
        }
    },
    {
        "translation": {
            "en": "The same is true for large range variations across the descriptive features in a dataset and normalization techniques (like those described in Section 3.6.1[87]) should almost always be applied when nearest neighbor models are used.",
            "zh": "对于数据集中描述性特征之间的大范围变化也是如此，当使用最近邻模型时，归一化技术（如第 3.6.1 节 [87] 中描述的技术）几乎总是应用。"
        }
    },
    {
        "translation": {
            "en": "The following short summary of the important things she learned illustrates the level of situational fluency required for this kind of scenario.",
            "zh": "以下是她所学到的重要内容的简短总结，说明了这种场景所需的情境流畅程度。"
        }
    },
    {
        "translation": {
            "en": "“Fail to prepare, prepare to fail.”",
            "zh": "“没有准备，准备失败。”"
        }
    },
    {
        "translation": {
            "en": "9.4.4   Performance Measures: Multinomial Targets",
            "zh": "9.4.4 绩效衡量：多项式目标"
        }
    },
    {
        "translation": {
            "en": "Notice that the sum of the probabilities (the bar areas in the histograms) in both of these tables is 1.0, which is what we would expect with a probability distribution—all probability distributions sum to 1.0.",
            "zh": "请注意，这两个表中的概率（直方图中的条形区域）之和均为 1.0，这是我们对概率分布的预期 - 所有概率分布的总和均为 1.0。"
        }
    },
    {
        "translation": {
            "en": "Data Preparation, 17, 19, 28, 46, 53, 87, 94, 95, 535, 691, 713, 730",
            "zh": "数据准备， 17， 19， 28， 46， 53， 87， 94， 95， 535， 691， 713， 730"
        }
    },
    {
        "translation": {
            "en": "A range of other approaches we do not cover in this book can be used to do other in-depth analysis of regression models.",
            "zh": "本书中没有介绍的一系列其他方法可用于对回归模型进行其他深入分析。"
        }
    },
    {
        "translation": {
            "en": "That there are no weights on these connections is indicated in Figure 8.37[502] by a dashed arrow that represents these connections.",
            "zh": "图 8.37[502] 中用虚线箭头表示这些连接上没有权重。"
        }
    },
    {
        "translation": {
            "en": "In preparing to create predictive models, it is always a good idea to investigate the relationships between pairs of features.",
            "zh": "在准备创建预测模型时，研究特征对之间的关系始终是一个好主意。"
        }
    },
    {
        "translation": {
            "en": "analytics base table, 17, 23, 28, 28, 45, 49, 50, 52, 53, 94, 97, 600, 625, 688",
            "zh": "分析基表、17、23、28、28、45、49、50、52、53、94、97、600、625、688"
        }
    },
    {
        "translation": {
            "en": "24. See Kollar and Friedman (2009) for a discussion of algorithms that seek to address this research challenge.",
            "zh": "24. 参见Kollar and Friedman （2009）关于旨在解决这一研究挑战的算法的讨论。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2[60] shows a selection of histogram shapes that exhibit characteristics commonly seen when analyzing features and that are indicative of standard, well-known probability distributions.",
            "zh": "图 3.2[60] 显示了一系列直方图形状，这些直方图形状具有分析特征时常见的特征，并指示标准的、众所周知的概率分布。"
        }
    },
    {
        "translation": {
            "en": "ii. Mode % and 2nd mode %",
            "zh": "ii. 模式 % 和第二模式 %"
        }
    },
    {
        "translation": {
            "en": "Aggregates: These are aggregate measures defined over a group or period and are usually defined as the count, sum, average, minimum, or maximum of the values within a group. For example, the total number of insurance claims that a member of an insurance company has made over his or her lifetime might be a useful derived feature. Similarly, the average amount of money spent by a customer at an online retailer over periods of one, three, and six months might make an interesting set of derived features.",
            "zh": "聚合：这些是在一个组或期间内定义的聚合度量，通常定义为组内值的计数、总和、平均值、最小值或最大值。例如，保险公司成员在其一生中提出的保险索赔总数可能是一个有用的派生特征。同样，客户在一、三和六个月内在在线零售商处花费的平均金额可能会产生一组有趣的派生特征。"
        }
    },
    {
        "translation": {
            "en": "The per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "每个示例的预测、误差和训练后的平方误差之和已收敛到 SSE < 0.0001。"
        }
    },
    {
        "translation": {
            "en": "Tsoumakas, Grigorios, Min-Ling Zhang, and Zhi-Hua Zhou. 2012. Introduction to the special issue on learning from multi-label data. Machine Learning 88 (1-2): 1–4.",
            "zh": "Tsoumakas、Grigorios、Min-Ling Zhang 和 Zhi-华 周。2012. 关于从多标签数据中学习的特刊介绍.机器学习 88 （1-2）：1-4。"
        }
    },
    {
        "translation": {
            "en": "Another approach to evaluating clustering is to use external criteria in which some measure from outside the clustering is used as a proxy ground truth.",
            "zh": "评估聚类的另一种方法是使用外部标准，其中来自聚类外部的某些度量用作代理事实。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4[16] shows six key phases of the predictive data analytics project lifecycle that are defined by the CRISP-DM:",
            "zh": "图 1.4[16] 显示了 CRISP-DM 定义的预测数据分析项目生命周期的六个关键阶段："
        }
    },
    {
        "translation": {
            "en": "The second term we need in order to calculate δ8 is the rate of change of the activation function with respect to the changes in the weighted sum z: ∂a/∂z.",
            "zh": "为了计算 δ8，我们需要的第二个项是激活函数相对于加权总和 z 的变化率：∂a/∂z。"
        }
    },
    {
        "translation": {
            "en": "7.4.7   Support Vector Machines",
            "zh": "7.4.7 支持向量机"
        }
    },
    {
        "translation": {
            "en": "A point that we didn’t discuss in this chapter is that it is possible to create custom measures for datasets with both continuous and categorical descriptive features by combining measures.",
            "zh": "我们在本章中没有讨论的一点是，通过组合度量，可以为具有连续和分类描述性特征的数据集创建自定义度量。"
        }
    },
    {
        "translation": {
            "en": "In some predictive analytics scenarios, the dataset we have is so large that we do not use all the data available to us in an ABT and instead sample a smaller percentage from the larger dataset.",
            "zh": "在某些预测分析场景中，我们拥有的数据集非常大，以至于我们没有使用 ABT 中可用的所有数据，而是从较大的数据集中抽取较小百分比的数据。"
        }
    },
    {
        "translation": {
            "en": "Converting business problems into solutions based on unsupervised machine learning also relies mainly on the techniques discussed in the context of supervised learning in Chapter 2[23].",
            "zh": "将业务问题转化为基于无监督机器学习的解决方案也主要依赖于第2章[23]中监督学习背景下讨论的技术。"
        }
    },
    {
        "translation": {
            "en": "LSTMs were specifically designed to be able to model long-distance dependencies in a sequence.",
            "zh": "LSTM 经过专门设计，能够对序列中的长距离依赖关系进行建模。"
        }
    },
    {
        "translation": {
            "en": "Out-of-time sampling is essentially a form of hold-out sampling in which the sampling is done in a targeted rather than a random fashion.",
            "zh": "超时抽样本质上是一种保留抽样形式，其中抽样是以有针对性的方式而不是随机方式进行的。"
        }
    },
    {
        "translation": {
            "en": "Instead, to illustrate the DQN algorithm we will examine at a higher level how an automated player of the Lunar Lander game can be trained.",
            "zh": "相反，为了说明DQN算法，我们将在更高层次上研究如何训练月球着陆器游戏的自动玩家。"
        }
    },
    {
        "translation": {
            "en": "Glorot initialization, 458",
            "zh": "Glorot 初始化，458"
        }
    },
    {
        "translation": {
            "en": "Frequently, features will have very strong non-linear relationships that correlation does not respond to.",
            "zh": "通常，特征将具有非常强的非线性关系，相关性不会响应这些关系。"
        }
    },
    {
        "translation": {
            "en": "Once the most informative feature, d[best], has been chosen, the algorithm adds a new node, labeled with the feature d[best], to the tree (Line 9).",
            "zh": "一旦选择了信息量最大的特征 d[best]，算法就会在树中添加一个标有特征 d[best] 的新节点（第 9 行）。"
        }
    },
    {
        "translation": {
            "en": "Note that there is an entry for each action-state combination and that the terminal states always have a value of 0.000 for every action.",
            "zh": "请注意，每个操作状态组合都有一个条目，并且每个操作的终端状态的值始终为 0.000。"
        }
    },
    {
        "translation": {
            "en": "7.7 Exercises",
            "zh": "7.7 练习"
        }
    },
    {
        "translation": {
            "en": "8.3.4 Backpropagation: The Algorithm",
            "zh": "8.3.4 反向传播：算法"
        }
    },
    {
        "translation": {
            "en": "LIKED: Did the user Like the website on Facebook?",
            "zh": "喜欢：用户喜欢Facebook上的网站吗？"
        }
    },
    {
        "translation": {
            "en": "For example, after starting with the feature subset including no features, the process will move to the most desirable of the feature subsets containing just one feature.",
            "zh": "例如，从不包含特征的特征子集开始后，该过程将移动到仅包含一个特征的最理想的特征子集。"
        }
    },
    {
        "translation": {
            "en": "A stationary distribution is a distribution that doesn’t change.",
            "zh": "稳态分布是不变的分布。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.6",
            "zh": "图 10.6"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows a visualization of an MDP for TwentyTwos using this representation where the circles represent the 11 states.",
            "zh": "图 11.3[648] 显示了使用此表示的 TwentyTwo 的 MDP 的可视化，其中圆圈表示 11 个状态。"
        }
    },
    {
        "translation": {
            "en": "This involved working with the AT IT department to develop deployment-ready extract-transform-load (ETL) routines.",
            "zh": "这涉及与 AT IT 部门合作开发部署就绪的提取-转换-加载 （ETL） 例程。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10 illustrates how using just three layers and threshold activation functions, a network is able to represent a function that maps to a convex region.",
            "zh": "图 8.10 说明了仅使用三层和阈值激活函数，网络如何能够表示映射到凸区域的函数。"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks have three distinctive characteristics:",
            "zh": "卷积神经网络具有三个显著特征："
        }
    },
    {
        "translation": {
            "en": "Table 13.4",
            "zh": "表 13.4"
        }
    },
    {
        "translation": {
            "en": "In order to find this single best model, a machine learning algorithm must use some criteria for choosing among the candidate models it considers during its search.",
            "zh": "为了找到这个单一的最佳模型，机器学习算法必须使用一些标准来选择它在搜索过程中考虑的候选模型。"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature combinations are listed on the left-hand side of the table, and the set of potential models for this domain are shown as 1 to 6,561 on the right-hand side of the table.",
            "zh": "描述性特征组合列在表格的左侧，该域的潜在模型集在表格的右侧显示为 1 到 6,561。"
        }
    },
    {
        "translation": {
            "en": "28. The discussion relating to the features of real data that help with the induction of models in high-dimensional spaces is based on Bishop (2006), pp. 33–38.",
            "zh": "28. 关于有助于在高维空间中归纳模型的真实数据特征的讨论基于Bishop（2006），第33-38页。"
        }
    },
    {
        "translation": {
            "en": "16. See Goodfellow et al. (2016, p. 272) and references therein for further discussion on the trade-offs in batch size.",
            "zh": "16. 参见 Goodfellow 等人（2016 年，第 272 页）及其参考文献，以进一步讨论批量大小的权衡。"
        }
    },
    {
        "translation": {
            "en": "Discriminative",
            "zh": "判别"
        }
    },
    {
        "translation": {
            "en": "Agents, States, and Actions",
            "zh": "代理、状态和操作"
        }
    },
    {
        "translation": {
            "en": "To collect instances of customers who had not churned, Ross randomly sampled customers who did not match the churn definition but who also could be deemed active customers.",
            "zh": "为了收集未流失的客户实例，Ross 随机抽取了不符合流失定义但也可以被视为活跃客户的客户。"
        }
    },
    {
        "translation": {
            "en": "16. The features selected were AE_I, APERFLUX7IVAR_G, APERFLUX7IVAR_I, APERFLUX7_U, DERED_U, DEVAB_R, DEVRADERR_Z, DEVRAD_U, DEREDDIFF_G_R, EXPRAD_G, EXPRAD_R, FIBER2FLUXIVAR_Z, FIBER2MAGERR_G, FIBERFLUXIVAR_R, FRACDEV_Z, LNLDEV_G, LNLDEV_R, LNLDEV_U, LNLDEV_Z, MCR4_Z, PETROFLUXIVAR_G, PETROFLUXIVAR_I, PETROR50ERR_R, PETROR50_G, PETROR90_G, PETRORATIO_R, PSFFLUXIVAR_I, PSFMAGERR_R, PSFMAG_R, SKYIVAR_U, and SKYIVAR_Z.",
            "zh": "16. 选定的特征是AE_I、APERFLUX7IVAR_G、APERFLUX7IVAR_I、APERFLUX7_U、DERED_U、DEVAB_R、DEVRADERR_Z、DEVRAD_U、DEREDDIFF_G_R、EXPRAD_G、EXPRAD_R、FIBER2FLUXIVAR_Z、FIBER2MAGERR_G、FIBERFLUXIVAR_R、FRACDEV_Z、LNLDEV_G、LNLDEV_R、LNLDEV_U、LNLDEV_Z、MCR4_Z、PETROFLUXIVAR_G、PETROFLUXIVAR_I、PETROR50ERR_R、PETROR50_G、PETROR90_G、 PETRORATIO_R、PSFFLUXIVAR_I、PSFMAGERR_R、PSFMAG_R、SKYIVAR_U 和 SKYIVAR_Z。"
        }
    },
    {
        "translation": {
            "en": "For continuous targets there is no such thing as a pure split, so we will need to change the final base case.",
            "zh": "对于连续目标，没有纯粹的拆分，因此我们需要更改最终的基本情况。"
        }
    },
    {
        "translation": {
            "en": "Indeed, it is possible to represent the XOR function using a very simple two-layer network.",
            "zh": "事实上，可以使用非常简单的两层网络来表示 XOR 函数。"
        }
    },
    {
        "translation": {
            "en": "Table 12.3",
            "zh": "表 12.3"
        }
    },
    {
        "translation": {
            "en": "8.4.1 Vanishing Gradients and ReLUs",
            "zh": "8.4.1 消失梯度和 ReLU"
        }
    },
    {
        "translation": {
            "en": "Mean",
            "zh": "意味 着"
        }
    },
    {
        "translation": {
            "en": "All the performance measures that we have discussed so far focus on prediction problems with categorical targets.",
            "zh": "到目前为止，我们讨论的所有绩效指标都集中在分类目标的预测问题上。"
        }
    },
    {
        "translation": {
            "en": "3.6.3 Sampling",
            "zh": "3.6.3 抽样"
        }
    },
    {
        "translation": {
            "en": "propensity modeling, 4, 36, 689",
            "zh": "倾向建模， 4， 36， 689"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy on the non-stratified hold-out test set was 79.284%. Ross also generated cumulative gain, lift, and cumulative lift charts for the dataset.10 These are shown in Figure 12.6[700]. The cumulative gain chart in particular shows that if AT were to call just 40% of their customer base, they would identify approximately 80% of the customers who are likely to churn, which is strong evidence that the model is doing a good job of distinguishing between different customer types.",
            "zh": "非分层保持测试集的平均类准确率为 79.284%。Ross 还为数据集生成了累积增益、提升和累积提升图表10，如图 12.6[700] 所示。特别是累积收益图表显示，如果 AT 只打电话给 40% 的客户群，他们将识别大约 80% 可能流失的客户，这有力地证明了该模型在区分不同客户类型方面做得很好。"
        }
    },
    {
        "translation": {
            "en": "13.4.1 Baseline Models",
            "zh": "13.4.1 基线模型"
        }
    },
    {
        "translation": {
            "en": "The bag-of-words representation is covered more in Question 2[236] at the end of this chapter.",
            "zh": "本章末尾的问题2[236]中详细介绍了词袋表示。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.70)[467] restates this definition in terms of the error of the network as calculated using the cross-entropy loss function and also taking the partial derivative with respect to a change in the logit for neuron k in the output layer.",
            "zh": "方程（8.70）[467]根据使用交叉熵损失函数计算的网络误差，并采用偏导数来解释输出层中神经元k的logit变化。"
        }
    },
    {
        "translation": {
            "en": "This means that the performance of the model on the non-churn level overwhelms the performance on the churn level in the accuracy calculation and illustrates how classification accuracy can be a misleading measure of model performance.",
            "zh": "这意味着，在准确性计算中，模型在非流失级别的性能会压倒流失率级别的性能，并说明分类准确性如何成为模型性能的误导性度量。"
        }
    },
    {
        "translation": {
            "en": "This can easily be done by calculating the information gain7 for each descriptive feature as a predictor of binary flags indicating membership of each cluster and ranking features according to these information gain values.8",
            "zh": "这可以通过计算每个描述性特征的信息增益7作为二进制标志的预测因子来轻松完成，该二进制标志指示每个聚类的成员资格，并根据这些信息增益值对特征进行排名8。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS RATIO; NUMBER OF SOFT TISSUE CLAIMS: NUM.",
            "zh": "索赔比率;软组织索赔数量：数量。"
        }
    },
    {
        "translation": {
            "en": "Cooper, Gregory F., and Edward Herskovits. 1992. A Bayesian method for the induction of probabilistic networks from data. Machine Learning 9 (4): 309–347.",
            "zh": "库珀、格雷戈里 F. 和爱德华·赫斯科维茨。1992. 一种从数据中归纳概率网络的贝叶斯方法.机器学习 9 （4）：309–347。"
        }
    },
    {
        "translation": {
            "en": "To perform stratified sampling, the instances in a dataset are first divided into groups (or strata), where each group contains only instances that have a particular level for the stratification feature.",
            "zh": "要执行分层采样，首先将数据集中的实例划分为组（或层），其中每个组仅包含具有特定分层特征级别的实例。"
        }
    },
    {
        "translation": {
            "en": "interior nodes, 121",
            "zh": "内部节点，121"
        }
    },
    {
        "translation": {
            "en": "Features such as the number of times a person has made an insurance claim or the number of times a person has been married tend to follow an exponential distribution.",
            "zh": "诸如一个人提出保险索赔的次数或一个人结婚的次数等特征往往遵循指数分布。"
        }
    },
    {
        "translation": {
            "en": "The impact of the clamp transformation can be reduced by changing the multiplier used to calculate the thresholds from 1.5 to a larger value.",
            "zh": "通过将用于计算阈值的乘数从 1.5 更改为更大的值，可以减少钳位变换的影响。"
        }
    },
    {
        "translation": {
            "en": "Error-Based Learning",
            "zh": "基于错误的学习"
        }
    },
    {
        "translation": {
            "en": "After discussing some extensions and variations of this approach, the chapter focuses on how deep learning techniques have been recently integrated into reinforcement learning to impressive effect.",
            "zh": "在讨论了这种方法的一些扩展和变化之后，本章重点介绍了深度学习技术最近如何被整合到强化学习中，并取得了令人印象深刻的效果。"
        }
    },
    {
        "translation": {
            "en": "Table 5.9",
            "zh": "表 5.9"
        }
    },
    {
        "translation": {
            "en": "The standard value of 1.5 times the inter-quartile range was changed to 2.5 to slightly reduce the impact of this operation.",
            "zh": "将四分位距 1.5 倍的标准值更改为 2.5，以略微降低此操作的影响。"
        }
    },
    {
        "translation": {
            "en": "Hastie, T., R. Tibshirani, and J. Friedman. 2009. The elements of statistical learning. Springer.",
            "zh": "Hastie， T.、R. Tibshirani 和 J. Friedman。2009. 统计学习的要素.斯普林格。"
        }
    },
    {
        "translation": {
            "en": "skew, 59",
            "zh": "歪斜，59"
        }
    },
    {
        "translation": {
            "en": "Equations (8.69)[467] to (8.72)[467] step through the definition of the δk for a neuron in a softmax output layer when a cross-entropy loss function is used.",
            "zh": "方程（8.69）[467]至（8.72）[467]逐步介绍了使用交叉熵损失函数时softmax输出层中神经元的δk的定义。"
        }
    },
    {
        "translation": {
            "en": "Statistics that describe the population are referred to as population parameters.",
            "zh": "描述总体的统计数据称为总体参数。"
        }
    },
    {
        "translation": {
            "en": "A.4.3 Box Plots",
            "zh": "A.4.3 箱形图"
        }
    },
    {
        "translation": {
            "en": "Furthermore, decision tree algorithms are capable of handling both categorical and continuous descriptive features as well as handling missing values and outliers without any need to transform the data.",
            "zh": "此外，决策树算法能够处理分类和连续描述性特征，以及处理缺失值和异常值，而无需转换数据。"
        }
    },
    {
        "translation": {
            "en": "3. the two vectors of activations generated by Steps 1 and 2 are merged using an elementwise product, and the result of this operation is the vector of activations that is propagated to the output layer.",
            "zh": "3. 使用逐元乘积合并步骤 1 和 2 生成的两个激活向量，此操作的结果是传播到输出层的激活向量。"
        }
    },
    {
        "translation": {
            "en": "Most weight initialization processes are based on heuristics that try to ensure that the weights are neither too big nor too small.",
            "zh": "大多数权重初始化过程都基于启发式方法，试图确保权重既不太大也不太小。"
        }
    },
    {
        "translation": {
            "en": "Calculating probabilities in this way is known as summing out.",
            "zh": "以这种方式计算概率称为求和。"
        }
    },
    {
        "translation": {
            "en": "Chapters 4[117], 5[181], 6[243], 7[311] and 8[381]",
            "zh": "第4章[117]、第5章[181]、第6章[243]、第7章[311]和第8章[381]"
        }
    },
    {
        "translation": {
            "en": "The term representation learning is sometimes used to describe what the neurons in the hidden layers of a network are doing; in a sense, each subsequent layer in the network projects the inputs it receives into a new representation, and the output layer of the network then learns a mapping from a learned representation to the final output.",
            "zh": "术语表征学习有时用于描述网络隐藏层中的神经元在做什么;从某种意义上说，网络中的每一层后续层都将其接收到的输入投射到新的表示中，然后网络的输出层学习从学习到的表示到最终输出的映射。"
        }
    },
    {
        "translation": {
            "en": "This is an example of using a sampling method to evaluate the performance of a model, as we take distinct, random, non-overlapping samples from a larger dataset and use these for training and testing a prediction model.",
            "zh": "这是使用抽样方法评估模型性能的一个示例，因为我们从更大的数据集中获取不同的、随机的、不重叠的样本，并使用这些样本来训练和测试预测模型。"
        }
    },
    {
        "translation": {
            "en": "We can see how the cumulative likelihood of finding a ham (or negative) instance increases much more quickly than that of finding a spam (or positive) instance.",
            "zh": "我们可以看到，与查找垃圾邮件（或正面）实例相比，找到火腿（或负面）实例的累积可能性增加得更快。"
        }
    },
    {
        "translation": {
            "en": "9.4.2   Performance Measures: Categorical Targets",
            "zh": "9.4.2 绩效衡量：分类目标"
        }
    },
    {
        "translation": {
            "en": "Each weight is iteratively adjusted by a small amount based on the error in the predictions made by the current candidate model so as to generate subsequently more and more accurate candidate models.",
            "zh": "根据当前候选模型的预测误差，对每个权重进行少量迭代调整，以便生成越来越准确的候选模型。"
        }
    },
    {
        "translation": {
            "en": "So, the threshold between bin1 and bin2 will be the midpoint between the LOAN AMOUNT values for d12 (9,850) and d4 (10,000) which is 9,925.",
            "zh": "因此，bin1 和 bin2 之间的阈值将是 d12 （9,850） 和 d4 （10,000） 的 LOAN AMOUNT 值之间的中点，即 9,925。"
        }
    },
    {
        "translation": {
            "en": "To Grandad D’Arcy, for the inspiration.",
            "zh": "给达西爷爷，灵感来源。"
        }
    },
    {
        "translation": {
            "en": "The instances in a training dataset that fall along the margin extents, and therefore the margins, are known as the support vectors. These are the most important instances in the dataset because they define the decision boundary. There will always be at least one support vector for each level of the target feature, but there is no limit to how many support vectors there can be in total.",
            "zh": "训练数据集中沿边距范围（因此也位于边距）的实例称为支持向量。这些是数据集中最重要的实例，因为它们定义了决策边界。对于目标要素的每个级别，始终至少有一个支持向量，但总共可以有多少个支持向量没有限制。"
        }
    },
    {
        "translation": {
            "en": "silhouette width, 609",
            "zh": "轮廓宽度，609"
        }
    },
    {
        "translation": {
            "en": "13.1   Business Understanding",
            "zh": "13.1 业务理解"
        }
    },
    {
        "translation": {
            "en": "The customer’s income level",
            "zh": "客户的收入水平"
        }
    },
    {
        "translation": {
            "en": "Peak time was 08:00 to 18:00 from Monday to Friday, and calls made during peak time were more expensive than calls made during off-peak times.",
            "zh": "周一至周五的高峰时间为08：00至18：00，高峰时段的电话比非高峰时段的电话更贵。"
        }
    },
    {
        "translation": {
            "en": "We use bold notation P() to distinguish a probability distribution from a probability mass function P().",
            "zh": "我们使用粗体符号 P（） 来区分概率分布和概率质量函数 P（）。"
        }
    },
    {
        "translation": {
            "en": "Note that neurons that use a rectified linear activation function are known as ReLUs (short for rectified linear units).",
            "zh": "请注意，使用整流线性激活函数的神经元称为 ReLU（整流线性单元的缩写）。"
        }
    },
    {
        "translation": {
            "en": "With respect to the general ability of bagging and boosting ensembles to make accurate predictions, the results reported in Caruana et al.",
            "zh": "关于装袋和增强集合做出准确预测的一般能力，Caruana 等人报告的结果。"
        }
    },
    {
        "translation": {
            "en": "(e) The actual 2011 CPI for Russia was 2.4488. Which of the predictions made was the most accurate? Why do you think this was?",
            "zh": "（e） 俄罗斯2011年实际消费物价指数为2.4488。哪个预测最准确？你认为这是为什么？"
        }
    },
    {
        "translation": {
            "en": "If, however, we need to calculate the posterior probability distribution over X given Y, that is P(X | Y), then we will be actually calculating each of the P(Y | Xi)P(Xi) values in Equation (6.5)[250] as part of this calculation, and it is more efficient to use Equation (6.7)[250].",
            "zh": "但是，如果我们需要计算给定 Y 的 X 上的后验概率分布，则为 P（X |Y），那么我们将实际计算每个 P（Y |公式（6.5）[250]中的习P（习）值作为此计算的一部分，使用公式（6.7）[250]更有效。"
        }
    },
    {
        "translation": {
            "en": "These methods have been in existence since at least the early 1990s but have seen a resurgence of interest in the 2010s with the emergence of deep learning.",
            "zh": "这些方法至少从 1990 年代初就已经存在，但随着深度学习的出现，在 2010 年代重新引起了人们的兴趣。"
        }
    },
    {
        "translation": {
            "en": "Discuss this data quality report in terms of the following:",
            "zh": "从以下方面讨论此数据质量报告："
        }
    },
    {
        "translation": {
            "en": "Figure 5.18(c)[226] illustrates the distribution of the original 29 instances when we move to a three-dimensional feature space (each instance has been given a random value in the range [0.0,3.0] for the Z feature).",
            "zh": "图 5.18（c）[226] 说明了当我们移动到三维特征空间时原始 29 个实例的分布（每个实例都被赋予了 Z 特征范围内 [0.0,3.0] 的随机值）。"
        }
    },
    {
        "translation": {
            "en": "action-value table, 654",
            "zh": "动作值表，654"
        }
    },
    {
        "translation": {
            "en": "thinning, 299",
            "zh": "变薄，299"
        }
    },
    {
        "translation": {
            "en": "The target feature",
            "zh": "目标功能"
        }
    },
    {
        "translation": {
            "en": "If we needed to do it, the most sensible approach to handling the missing values in the NUM.",
            "zh": "如果我们需要这样做，处理 NUM 中缺失值的最明智的方法。"
        }
    },
    {
        "translation": {
            "en": "However, this heuristic is not guaranteed to avoid dead ReLUs: returning to the forward propagation of d2 through the ReLU network (see Figure 8.19[441]), in this network Neuron 3 already has a bias of w3,0 = 0.1, but this positive bias is dominated by the large negative weight w3,1 = −0.20.",
            "zh": "然而，这种启发式方法并不能保证避免死 ReLU：通过 ReLU 网络返回 d2 的前向传播（参见图 8.19[441]），在这个网络中，神经元 3 已经具有 w3,0 = 0.1 的偏差，但这种正偏差由大负权重 w3,1 = −0.20 主导。"
        }
    },
    {
        "translation": {
            "en": "This first candidate model is not particularly accurate with an initial sum of squared errors of 12.2369.",
            "zh": "第一个候选模型不是特别准确，初始平方误差之和为 12.2369。"
        }
    },
    {
        "translation": {
            "en": "test set, 535, 541",
            "zh": "测试集， 535， 541"
        }
    },
    {
        "translation": {
            "en": "The fundamental concepts required to build a system on the basis of this idea are feature spaces and measures of similarity, and these are covered in the fundamentals section of this chapter.",
            "zh": "基于这个想法构建系统所需的基本概念是特征空间和相似度量，这些在本章的基础部分中都有介绍。"
        }
    },
    {
        "translation": {
            "en": "This algorithm is built on two fundamental concepts: (1) a feature space, and (2) measures of similarity between instances within the feature space.",
            "zh": "该算法建立在两个基本概念之上：（1） 特征空间，以及 （2） 特征空间内实例之间的相似度度量。"
        }
    },
    {
        "translation": {
            "en": "We will find this useful when we are trying to decide whether to search both branches of a node when we are looking for the nearest neighbor or whether we can prune one of them.",
            "zh": "当我们试图决定是否在寻找最近的邻居时搜索节点的两个分支，或者我们是否可以修剪其中一个分支时，我们会发现这很有用。"
        }
    },
    {
        "translation": {
            "en": "We then present the standard approach to building error-based predictive models: multivariable linear regression with gradient descent.",
            "zh": "然后，我们提出了构建基于误差的预测模型的标准方法：梯度下降的多变量线性回归。"
        }
    },
    {
        "translation": {
            "en": "The basic approach to learning the structure of a Bayesian network is to use a local search algorithm that moves through the space of possible networks and parameters, and searches for the network topology and CPT parameters that best fit with the data.",
            "zh": "学习贝叶斯网络结构的基本方法是使用本地搜索算法，该算法在可能的网络和参数的空间中移动，并搜索与数据最匹配的网络拓扑和 CPT 参数。"
        }
    },
    {
        "translation": {
            "en": "11.3.1 A Worked Example",
            "zh": "11.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "Examining the actual raw data in Table 3.2[56] shows that these zeros always co-occur with missing values in the MARITAL STATUS feature.",
            "zh": "检查表3.2[56]中的实际原始数据表明，这些零总是与婚姻状况特征中的缺失值同时出现。"
        }
    },
    {
        "translation": {
            "en": "Note that for ease of presentation the network schematics in this figure have been rotated so that the forward flow of information through each network is from the input layer at the bottom to the output layer at the top.",
            "zh": "请注意，为了便于演示，此图中的网络原理图已旋转，以便通过每个网络的信息流从底部的输入层到顶部的输出层。"
        }
    },
    {
        "translation": {
            "en": "using the 6th and 7th values in the list, 165 and 188. We have actually already come across a percentile in the measures of central tendency. The median is the 50th percentile.",
            "zh": "使用列表中的第 6 个和第 7 个值 165 和 188。实际上，我们已经在集中趋势的衡量标准中遇到了一个百分位数。中位数是第 50 个百分位数。"
        }
    },
    {
        "translation": {
            "en": "The following table contains an extract from this ABT—the full ABT contains 2,440 instances.",
            "zh": "下表包含此 ABT 的摘录 - 完整的 ABT 包含 2,440 个实例。"
        }
    },
    {
        "translation": {
            "en": "Adding depth to a filter does not involve a major change in the way a neuron applies a filter to its local receptive field.",
            "zh": "向过滤器添加深度并不涉及神经元将过滤器应用于其局部感受野的方式的重大变化。"
        }
    },
    {
        "translation": {
            "en": "Dosage Prediction: Doctors and scientists frequently decide how much of a medicine or other chemical to include in a treatment. Predictive analytics models can be used to assist this decision making by predicting optimal dosages based on data about past dosages and associated outcomes.",
            "zh": "剂量预测：医生和科学家经常决定在治疗中加入多少药物或其他化学物质。预测分析模型可用于根据过去剂量和相关结果的数据预测最佳剂量，从而协助做出此决策。"
        }
    },
    {
        "translation": {
            "en": "The biggest challenge in creating a Bayesian prediction model is overcoming the exponential growth in the number of probabilities (model parameters) that are required as the dimensionality of the feature space increases.",
            "zh": "创建贝叶斯预测模型的最大挑战是克服随着特征空间维数的增加而所需的概率（模型参数）数量的指数增长。"
        }
    },
    {
        "translation": {
            "en": "For example, with just 20 descriptive features, there are 220 = 1,048,576 possible feature subsets.",
            "zh": "例如，只有 20 个描述性特征，就有 220 = 1,048,576 个可能的特征子集。"
        }
    },
    {
        "translation": {
            "en": "Consequently, a common practice when training a recurrent neural network to process a long sequence is to break the sequence up into subsequences.",
            "zh": "因此，在训练递归神经网络处理长序列时，一种常见的做法是将序列分解为子序列。"
        }
    },
    {
        "translation": {
            "en": "Building a churn prediction model was also attractive to the AT executive team, as they hoped that as well as being useful in reducing churn rates, it would help to explain the main drivers behind customer churn. A better understanding of the main drivers of customer churn would be useful to many other parts of the AT business.",
            "zh": "构建客户流失预测模型对 AT 执行团队也很有吸引力，因为他们希望它不仅有助于降低客户流失率，还有助于解释客户流失背后的主要驱动因素。更好地了解客户流失的主要驱动因素将对AT业务的许多其他部分有用。"
        }
    },
    {
        "translation": {
            "en": "The third way in which naive weights initialization can cause unstable gradients arises from the fact that the variance of the output of a weighted sum is a function of three factors: the number of inputs to the weighted sum, the variance of the inputs, and the variance of the weights.",
            "zh": "朴素权重初始化可能导致不稳定梯度的第三种方式源于这样一个事实，即加权和的输出方差是三个因素的函数：加权和的输入数、输入的方差和权重的方差。"
        }
    },
    {
        "translation": {
            "en": "Instead, given the set of values for a continuous feature, we fit a mixture of Gaussians distribution to this data by searching for the number of components and set of parameters for each component that best matches the data.",
            "zh": "相反，给定连续特征的一组值，我们通过搜索与数据最匹配的每个分量的分量数和参数集，将高斯分布的混合拟合到该数据。"
        }
    },
    {
        "translation": {
            "en": "This can be problematic because modern datasets can be very large—it is quite possible to have datasets containing millions or even billions of examples.",
            "zh": "这可能是有问题的，因为现代数据集可能非常大——很可能拥有包含数百万甚至数十亿个示例的数据集。"
        }
    },
    {
        "translation": {
            "en": "14.2.1 Matching Machine Learning Approaches to Projects",
            "zh": "14.2.1 将机器学习方法与项目相匹配"
        }
    },
    {
        "translation": {
            "en": "In general, the histogram heights follow the dashed line, so the resulting bins can be considered a reasonable representation of the continuous feature.",
            "zh": "通常，直方图高度遵循虚线，因此生成的条柱可以被视为连续要素的合理表示。"
        }
    },
    {
        "translation": {
            "en": "4.16   The decision tree resulting from splitting the data in Table 4.11[152] using the feature SEASON.",
            "zh": "4.16 使用特征 SEASON 拆分表 4.11[152] 中的数据生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "The other change we need to make to Algorithm 1[134] to handle continuous targets relates to the base cases that cause the algorithm to stop processing data partitions and to create a leaf node.",
            "zh": "我们需要对算法 1[134] 进行的另一个更改是处理连续目标，这与导致算法停止处理数据分区并创建叶节点的基本情况有关。"
        }
    },
    {
        "translation": {
            "en": "0.63",
            "zh": "0.63"
        }
    },
    {
        "translation": {
            "en": "99.97",
            "zh": "99.97"
        }
    },
    {
        "translation": {
            "en": "Certain approaches, however, are a more natural fit for some kinds of data than others, so we can make some recommendations.",
            "zh": "但是，某些方法比其他方法更适合某些类型的数据，因此我们可以提出一些建议。"
        }
    },
    {
        "translation": {
            "en": "The upper and lower thresholds can be set manually based on domain knowledge or can be calculated from data. One common way to calculate clamp thresholds is to set the lower threshold to the 1st quartile value minus 1.5 times the inter-quartile range and the upper threshold to the 3rd quartile plus 1.5 times the inter-quartile range. This works effectively and takes into account the fact that the variation in a dataset can be different on either side of a central tendency.",
            "zh": "上限和下限阈值可以根据领域知识手动设置，也可以根据数据计算。计算钳位阈值的一种常用方法是将下限阈值设置为第 1 个四分位数值减去四分位数间范围的 1.5 倍，将上限阈值设置为第 3 个四分位数加上四分位数间范围的 1.5 倍。这很有效，并考虑到数据集中的变化在中心趋势的任何一侧都可能不同。"
        }
    },
    {
        "translation": {
            "en": "NEWFREQUENTNUMBERS: Derived from analysis of the actual numbers dialed in the raw call data, this feature attempted to capture how many new numbers a customer has begun calling frequently that month. A frequent number was defined as a number that constituted more than 15% of a customer’s total calls.",
            "zh": "NEWFREQUENTNUMBERS：根据对原始呼叫数据中实际拨打的号码的分析，此功能试图捕获客户当月开始频繁呼叫的新号码数量。频繁号码被定义为占客户总呼叫量 15% 以上的号码。"
        }
    },
    {
        "translation": {
            "en": "Precision, recall, and the F1 measure work best in prediction problems with binary target features and place an emphasis on capturing the performance of a prediction model on the positive, or most important, level.",
            "zh": "精度、召回率和 F1 度量在具有二元目标特征的预测问题中效果最好，并强调在正或最重要的水平上捕获预测模型的性能。"
        }
    },
    {
        "translation": {
            "en": "where the terms in the equation have the same meaning as before, and abs refers to the absolute value. Mean absolute error values fall in the range [0,∞], and smaller values indicate better model performance.",
            "zh": "其中等式中的项具有与前面相同的含义，并且 abs 表示绝对值。平均绝对误差值在 [0，∞] 范围内，值越小表示模型性能越好。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 10[607] shows a pseudocode description of the k-means algorithm.",
            "zh": "算法10[607]显示了k-means算法的伪代码描述。"
        }
    },
    {
        "translation": {
            "en": "Edwin also agreed that Ted was correct about the unavailability of spectrograph data for most objects, so this was also removed.",
            "zh": "埃德温也同意泰德关于大多数物体的光谱仪数据不可用是正确的，所以这也被删除了。"
        }
    },
    {
        "translation": {
            "en": "For example, if the age of a customer was used as a descriptive feature in a financial credit scoring model, it is more difficult to talk about changes in normalized age on a scale from 0 to 1 than it is to discuss original age values on their natural scale, about 18 to 80.",
            "zh": "例如，如果客户的年龄被用作金融信用评分模型中的描述性特征，那么在从 0 到 1 的范围内谈论标准化年龄的变化比在自然量表（大约 18 到 80 岁）上讨论原始年龄值更困难。"
        }
    },
    {
        "translation": {
            "en": "19. See Section 7.4.2[334].",
            "zh": "19. 参见第 7.4.2 节[334]。"
        }
    },
    {
        "translation": {
            "en": "Some argue that reinforcement learning is closer to supervised learning because the reward signal is a form of supervision.",
            "zh": "一些人认为强化学习更接近于监督学习，因为奖励信号是一种监督形式。"
        }
    },
    {
        "translation": {
            "en": "1.1 What Is Predictive Data Analytics?",
            "zh": "1.1 什么是预测数据分析？"
        }
    },
    {
        "translation": {
            "en": "If all the neurons in a network use a logistic activation function or another activation function whose derivative has a small range less than 1, then the error gradient will get smaller and smaller as it is backpropagated through the networks layers, and the scaling down of the gradient is particularly severe for neurons whose z value is in the saturated region of the activation function.",
            "zh": "如果网络中的所有神经元都使用逻辑激活函数或其他激活函数，其导数范围小于 1，则误差梯度在网络层中反向传播时会越来越小，并且梯度的缩小对于z值在激活函数饱和区域的神经元尤其严重。"
        }
    },
    {
        "translation": {
            "en": "The single classification accuracy performance measure hides this poor performance on the minority target levels.",
            "zh": "单一的分类准确性绩效衡量标准掩盖了少数目标水平上的这种糟糕表现。"
        }
    },
    {
        "translation": {
            "en": "A network can represent a function if a set of weights exist for that network for which the network implements the function.",
            "zh": "如果网络为其实现函数的网络存在一组权重，则网络可以表示该函数。"
        }
    },
    {
        "translation": {
            "en": "(c) After three iterations of the AHC algorithm, three pairs of instances have been combined into clusters, 10, 11, and 12.",
            "zh": "（c） 经过 AHC 算法的三次迭代，三对实例被组合成集群 10、11 和 12。"
        }
    },
    {
        "translation": {
            "en": "conditionally independent, 285, 288",
            "zh": "有条件独立，285,288"
        }
    },
    {
        "translation": {
            "en": "Returning to the backward pass of the backpropagation algorithm, Figure 8.12[407] shows that the backward pass begins by calculating the δ for each of the neurons in the output layer of the network.",
            "zh": "回到反向传播算法的向后传递，图8.12[407]显示，向后传递从计算网络输出层中每个神经元的δ开始。"
        }
    },
    {
        "translation": {
            "en": "The first part—Chapters 2[23] and 3[53]—covers the Business Understanding, Data Understanding, and Data Preparation phases of the process. In this part we discuss how a business problem is converted into a data analytics solution, how data can be prepared for this task, and the data exploration tasks that should be performed during these phases.",
            "zh": "第一部分（第 2 章[23] 和 3 章[53]）涵盖了流程的业务理解、数据理解和数据准备阶段。在这一部分中，我们将讨论如何将业务问题转换为数据分析解决方案，如何为此任务准备数据，以及在这些阶段应执行的数据探索任务。"
        }
    },
    {
        "translation": {
            "en": "As a result, it is not possible in a single chapter to cover all possible deep learning topics.",
            "zh": "因此，不可能在一章中涵盖所有可能的深度学习主题。"
        }
    },
    {
        "translation": {
            "en": "The target feature is binary and labels components as good or bad.",
            "zh": "目标功能是二进制的，并将组件标记为好或坏。"
        }
    },
    {
        "translation": {
            "en": "target feature, 5, 19, 28, 598",
            "zh": "目标特征， 5， 19， 28， 598"
        }
    },
    {
        "translation": {
            "en": "The roots of probability are in gambling, where, understandably, gamblers wanted to be able to predict future events based on their likelihood.",
            "zh": "概率的根源在于赌博，可以理解的是，赌徒希望能够根据他们的可能性预测未来事件。"
        }
    },
    {
        "translation": {
            "en": "This is also illustrated in Figure 11.9[672].",
            "zh": "图11.9[672]也说明了这一点。"
        }
    },
    {
        "translation": {
            "en": "We recommend using early stopping as the default strategy to control when to stop training a neural network.",
            "zh": "我们建议使用提前停止作为默认策略来控制何时停止训练神经网络。"
        }
    },
    {
        "translation": {
            "en": "k nearest neighbor, 181, 192, 231, 536, 554, 575, 719, 731, 733, 735",
            "zh": "k 最近邻， 181， 192， 231， 536， 554， 575， 719， 731， 733， 735"
        }
    },
    {
        "translation": {
            "en": "The exponential distribution is often used to model waiting times (for example, how long it will take for a call to be answered at a help desk, how long you will have to wait for a bus, or how long before a piece of hardware fails), where the parameter λ is equal to 1 divided by the average time it takes for the event.",
            "zh": "指数分布通常用于对等待时间进行建模（例如，在服务台接听电话需要多长时间，您必须等待公交车多长时间，或者硬件故障之前需要多长时间），其中参数 λ 等于 1 除以事件所需的平均时间。"
        }
    },
    {
        "translation": {
            "en": "For datasets that only sparsely populate the feature space, however, weighted k nearest neighbor models usually make more accurate predictions, as they take into account the fact that some of the nearest neighbors can actually be quite far away.",
            "zh": "然而，对于仅稀疏填充特征空间的数据集，加权 k 最近邻模型通常会做出更准确的预测，因为它们考虑到一些最近邻实际上可能非常远的事实。"
        }
    },
    {
        "translation": {
            "en": "Two useful performance measures in this regard are gain and lift (we will see that the related performance measures of cumulative gain and cumulative lift are also useful).",
            "zh": "在这方面，两个有用的绩效指标是增益和提升（我们将看到累积增益和累积提升的相关绩效指标也很有用）。"
        }
    },
    {
        "translation": {
            "en": "The most straightforward way to make a model abstract away from the precise location of visual features is to sub-sample the feature maps.",
            "zh": "使模型抽象出视觉特征的精确位置的最直接方法是对特征图进行子采样。"
        }
    },
    {
        "translation": {
            "en": "These corrections are combined with the 0 predictions to give the ensemble predictions after the first iteration, 1.",
            "zh": "这些修正与 0 个预测相结合，以在第一次迭代 1 之后给出集成预测。"
        }
    },
    {
        "translation": {
            "en": "The fundamental idea underpinning reinforcement learning is that the only goal of an intelligent agent is to maximize cumulative reward across an episode.3 The cumulative reward earned across an episode is referred to as the return from the episode and can be defined as",
            "zh": "支撑强化学习的基本思想是，智能代理的唯一目标是在一集中最大化累积奖励.3 在一集中获得的累积奖励称为从一集中获得的回报，可以定义为"
        }
    },
    {
        "translation": {
            "en": "If a three-layer network can represent any function with arbitrary accuracy, is it helpful to go deeper, or is it better to make the layers wider?",
            "zh": "如果一个三层网络可以以任意精度表示任何函数，那么更深一点是有帮助的，还是让层更宽更好？"
        }
    },
    {
        "translation": {
            "en": "The fact that the ReLU activation function for Neuron 4 is saturated for all four examples means that Neuron 4 is essentially dead during the forward pass of the algorithm (it does not activate for any example) and this reduces the representational capacity of the network.",
            "zh": "Neuron 4 的 ReLU 激活函数在所有四个示例中都饱和，这意味着 Neuron 4 在算法的前向传递期间基本上是死的（它不会激活任何示例），这降低了网络的表示能力。"
        }
    },
    {
        "translation": {
            "en": "Each of the terms ∂ℰ/∂f (Equation (8.126)[518]), ∂ℰ/∂i† (Equation (8.124)[518]), ∂ℰ/∂i‡ (Equation (8.123)[518]), and ∂ℰ/∂o† (Equation (8.120)[516]) describes a vector of error gradients with respect to the output activations of the neurons in one of the sigmoid and tanh layers in the LSTM.",
            "zh": "每个项 ∂E/∂f （等式 （8.126）[518]）、∂E/∂i† （等式 （8.124）[518]）、∂E/∂i‡ （等式 （8.123）[518]） 和 ∂E/∂o† （等式 （8.120）[516]） 描述了与 LSTM 中 sigmoid 和 tanh 层之一的神经元输出激活相关的误差梯度向量。"
        }
    },
    {
        "translation": {
            "en": "The majority of this book is focused on building predictive models. Machine learning, however, can be used for many other tasks. In Chapters 10[597] and 11[637] we described two of the major uses of machine learning that go beyond prediction: unsupervised learning and reinforcement learning.",
            "zh": "本书的大部分内容都集中在构建预测模型上。然而，机器学习可以用于许多其他任务。在第 10 章[597] 和 11 章[637]中，我们描述了机器学习的两个主要用途，它们超越了预测：无监督学习和强化学习。"
        }
    },
    {
        "translation": {
            "en": "A Markov decision process representation for TwentyTwos, a simplified version of the card game Blackjack.",
            "zh": "TwentyTwos的马尔可夫决策过程表示，TwentyTwos是纸牌游戏Blackjack的简化版本。"
        }
    },
    {
        "translation": {
            "en": "Therefore, we should experiment with different metrics to find which one results in the best models for each dataset.",
            "zh": "因此，我们应该尝试不同的指标，以找到哪个指标可以产生每个数据集的最佳模型。"
        }
    },
    {
        "translation": {
            "en": "This is why they are represented by squares to visually distinguish them from the other neurons in the network that do transform their inputs.",
            "zh": "这就是为什么它们用正方形表示，以便在视觉上将它们与网络中转换其输入的其他神经元区分开来。"
        }
    },
    {
        "translation": {
            "en": "The caution comes from the fact that measures of central tendency and variation tend to break down for multimodal data.",
            "zh": "这种谨慎来自于这样一个事实，即多模态数据的集中趋势和变化的度量往往会崩溃。"
        }
    },
    {
        "translation": {
            "en": "Table 1.1",
            "zh": "表 1.1"
        }
    },
    {
        "translation": {
            "en": "The outputs of this model for the training dataset instances are shown in Table 4.15[166] and Figure 4.22(d)[167].",
            "zh": "该模型对训练数据集实例的输出如表4.15[166]和图4.22（d）[167]所示。"
        }
    },
    {
        "translation": {
            "en": "A greedy local search process moves across a feature subset space like this search in order to find the best feature subset.",
            "zh": "贪婪的本地搜索过程在特征子集空间中移动，例如此搜索，以找到最佳特征子集。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.4",
            "zh": "图 4.4"
        }
    },
    {
        "translation": {
            "en": "Sometimes this is not possible, even after using a kernel function to move the data to a higher-dimensional feature space.",
            "zh": "有时这是不可能的，即使在使用内核函数将数据移动到更高维的特征空间之后也是如此。"
        }
    },
    {
        "translation": {
            "en": "distance matrix, 620, 621",
            "zh": "距离矩阵， 620， 621"
        }
    },
    {
        "translation": {
            "en": "Deep learning is a relatively new term that describes research on modern artificial neural networks.",
            "zh": "深度学习是一个相对较新的术语，用于描述对现代人工神经网络的研究。"
        }
    },
    {
        "translation": {
            "en": "We begin this section by introducing the basic building block of all deep learning models, the artificial neuron (see Section 8.2.1[384]); we then describe how the artificial neurons can be connected together to create an artificial neural network (see Section 8.2.2[388]).",
            "zh": "在本节的开头，我们介绍了所有深度学习模型的基本构建块，即人工神经元（参见第 8.2.1 节[384]）;然后，我们描述了如何将人工神经元连接在一起以创建人工神经网络（参见第 8.2.2 节[388]）。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features used are the overall surface area of the building, the height of the building, the area of the building’s roof, and the percentage of wall area in the building that is glazed.",
            "zh": "使用的描述性特征是建筑物的整体表面积、建筑物的高度、建筑物屋顶的面积以及建筑物中玻璃墙面积的百分比。"
        }
    },
    {
        "translation": {
            "en": "In the second stage of the McCulloch and Pitts model, the result of the weighted sum calculation, z, is then converted into a high or a low activation by comparing the value of z with a manually preset threshold; if z is greater than or equal to the threshold, the artificial neuron outputs a 1 (high activation), and otherwise it outputs a 0 (low activation).",
            "zh": "在 McCulloch 和 Pitts 模型的第二阶段，通过将 z 的值与手动预设阈值进行比较，将加权和计算结果 z 转换为高激活或低激活;如果 z 大于或等于阈值，则人工神经元输出 1（高激活），否则输出 0（低激活）。"
        }
    },
    {
        "translation": {
            "en": "The successors of the current best feature subset generated in backward sequential selection are the set of feature subsets that can be generated from the current best subset by removing just a single extra feature.",
            "zh": "在向后顺序选择中生成的当前最佳特征子集的后继者是一组特征子集，只需删除一个额外的特征即可从当前最佳子集生成。"
        }
    },
    {
        "translation": {
            "en": "Using this simplification, the Bayesian MAP prediction model can be restated as",
            "zh": "使用这种简化，贝叶斯 MAP 预测模型可以重述为"
        }
    },
    {
        "translation": {
            "en": "Table 8.6[431] lists the calculations of ∂ℰ/∂w i,k for each weight in the network for d2.",
            "zh": "表 8.6[431] 列出了 d2 网络中每个权重的 ∂E/∂w i，k 计算。"
        }
    },
    {
        "translation": {
            "en": "This illustrates how sensitive the training of a deep neural network can be to a range of hyper-parameters, such as the learning rate and activation function.",
            "zh": "这说明了深度神经网络的训练对一系列超参数（例如学习速率和激活函数）的敏感性。"
        }
    },
    {
        "translation": {
            "en": "equation of a line, 313, 385",
            "zh": "直线方程，313,385"
        }
    },
    {
        "translation": {
            "en": "This trade-off between the number of descriptive features and the density of the instances in the feature space is known as the curse of dimensionality.",
            "zh": "描述性特征的数量与特征空间中实例的密度之间的这种权衡称为维度诅咒。"
        }
    },
    {
        "translation": {
            "en": "Chebyshev distance, 186",
            "zh": "切比雪夫距离，186"
        }
    },
    {
        "translation": {
            "en": "However, the action-value function given in Equation (11.9)[643] can be expressed in terms of the components of an MDP to do just this.",
            "zh": "然而，等式（11.9）[643]中给出的动作-值函数可以用MDP的分量来表示。"
        }
    },
    {
        "translation": {
            "en": "NEWSLETTER: Did the user sign up for the weekly newsletter?",
            "zh": "时事通讯：用户是否注册了每周时事通讯？"
        }
    },
    {
        "translation": {
            "en": "This is one reason that other approaches are often favored over logistic regression for predicting categorical targets with many levels.",
            "zh": "这就是为什么其他方法在预测具有多个层次的分类目标时通常比逻辑回归更受青睐的原因之一。"
        }
    },
    {
        "translation": {
            "en": "In these contexts both the doctor and the patient would want the system to provide some explanation of how it arrives at the predictions it makes.",
            "zh": "在这些情况下，医生和患者都希望系统提供一些解释，说明它是如何得出预测的。"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE, % SOFT TISSUE, and FRAUD FLAG all have cardinality less than 10, which is unusual in a dataset of 500 instances.",
            "zh": "SOFT TISSUE、% SOFT TISSUE 和 FRAUD FLAG 的基数都小于 10，这在包含 500 个实例的数据集中是不寻常的。"
        }
    },
    {
        "translation": {
            "en": "For the drug dosage predictions given in Table 9.20[576], the mean absolute error is 0.975 for the regression model and 1.750 for the nearest neighbor model.",
            "zh": "对于表9.20[576]中给出的药物剂量预测，回归模型的平均绝对误差为0.975，最近邻模型的平均绝对误差为1.750。"
        }
    },
    {
        "translation": {
            "en": "If the distribution used to generate the samples for a Monte Carlo method is a Markov chain, then the specific algorithms we use to implement this approach come from a family known as Markov chain Monte Carlo (MCMC) algorithms.",
            "zh": "如果用于生成蒙特卡洛方法样本的分布是马尔可夫链，那么我们用于实现此方法的特定算法来自称为马尔可夫链蒙特卡洛 （MCMC） 算法的家族。"
        }
    },
    {
        "translation": {
            "en": "The different question sequences that can follow in a game of Guess Who beginning with the question Is it a man?",
            "zh": "猜猜谁游戏中可以遵循的不同问题序列，从问题开始：是男人吗？"
        }
    },
    {
        "translation": {
            "en": "The big idea to take from this example to predictive data analytics projects is that when we evaluate predictive models, we must ensure that the evaluation experiments are designed so that they give an accurate estimate of how the models will perform when deployed. The most important part of the design of an evaluation experiment for a predictive model is ensuring that the data used to evaluate the model is not the same as the data used to train the model.",
            "zh": "从这个例子中可以借鉴到预测数据分析项目的主要想法是，当我们评估预测模型时，我们必须确保评估实验的设计能够准确估计模型在部署时的表现。预测模型评估实验设计中最重要的部分是确保用于评估模型的数据与用于训练模型的数据不同。"
        }
    },
    {
        "translation": {
            "en": "2.6   Further Reading",
            "zh": "2.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "tanh, 387, 461",
            "zh": "谭， 387， 461"
        }
    },
    {
        "translation": {
            "en": "MITOSES",
            "zh": "有丝分裂"
        }
    },
    {
        "translation": {
            "en": "where 𝕄w1 to 𝕄wr are r different one-versus-all logistic regression models, and w1 to wr are r different sets of weights. To combine the outputs of these different models, we normalize their results as follows:",
            "zh": "其中 Mw1 到 Mwr 是 r 个不同的一对多逻辑回归模型，w1 到 wr 是 r 个不同的权重集。为了结合这些不同模型的输出，我们将其结果归一化如下："
        }
    },
    {
        "translation": {
            "en": "Figure 8.4",
            "zh": "图 8.4"
        }
    },
    {
        "translation": {
            "en": "Instead of explicitly handling problems like noise within the data in an ABT, some data preparation techniques change the way data is represented just to make it more compatible with certain machine learning algorithms.",
            "zh": "一些数据准备技术不是在 ABT 中显式处理数据中的噪声等问题，而是改变数据的表示方式，使其与某些机器学习算法更兼容。"
        }
    },
    {
        "translation": {
            "en": "Even these algorithms, however, do eventually succumb to the curse as the dimensionality grows.",
            "zh": "然而，即使是这些算法，随着维度的增长，最终也会屈服于诅咒。"
        }
    },
    {
        "translation": {
            "en": "Consequently, an exponential increase is required in the size of the dataset as each new descriptive feature is added to ensure that for any conditional probability, there are enough instances in the training dataset matching the conditions so that the resulting probability is reasonable.",
            "zh": "因此，当添加每个新的描述性特征时，数据集的大小需要呈指数增长，以确保对于任何条件概率，训练数据集中有足够的实例与条件匹配，以便结果概率是合理的。"
        }
    },
    {
        "translation": {
            "en": "where 𝕄(q) is the prediction made by the model for the query q, levels(t) is the set of levels in the domain of the target feature t, and Gibbs(t = l,q) returns the probability for the event t = l given the evidence specified in the query q using Gibbs sampling.",
            "zh": "其中 M（q） 是模型对查询 q 所做的预测，levels（t） 是目标特征 t 域中的水平集，Gibbs（t = l，q） 返回事件 t = l 的概率，给定查询 q 中使用 Gibbs 采样指定的证据。"
        }
    },
    {
        "translation": {
            "en": "The maturity of regression-based approaches means that they are easily accepted in other disciplines (e.g., biological, physical, and social sciences) and that there is a range of techniques that allow a degree of analysis of regression models beyond what is possible for other approaches.",
            "zh": "基于回归的方法的成熟意味着它们很容易被其他学科（例如，生物、物理和社会科学）所接受，并且有一系列技术可以对回归模型进行一定程度的分析，这超出了其他方法所能达到的水平。"
        }
    },
    {
        "translation": {
            "en": "8.38   A simple RNN model unrolled through time (in this instance, three time-steps).",
            "zh": "8.38 一个简单的RNN模型在时间上展开（在本例中为三个时间步长）。"
        }
    },
    {
        "translation": {
            "en": "In this figure we have set k = 3, and this modification has resulted in the no region in the top right corner of the feature space disappearing.",
            "zh": "在此图中，我们设置了 k = 3，此修改导致特征空间右上角的 no 区域消失。"
        }
    },
    {
        "translation": {
            "en": "[Application prediction] A model could be built to predict, at the point of application, the likelihood that a policy someone has applied for will ultimately result in a fraudulent claim. The company could run this model every time a new application is made and reject those applications that are predicted likely to result in a fraudulent claim. The company would therefore reduce the number of fraudulent claims and reduce the amount of money they would lose to these claims.",
            "zh": "[应用预测]可以建立一个模型来预测，在申请时，某人申请的保单最终导致欺诈性索赔的可能性。该公司可以在每次提出新申请时运行此模型，并拒绝那些预计可能导致欺诈性索赔的申请。因此，该公司将减少欺诈性索赔的数量，并减少他们因这些索赔而损失的金额。"
        }
    },
    {
        "translation": {
            "en": "The INCOME feature stood out as unusual with only 10 distinct values (the histogram for this feature confirmed this; see Figure 12.2(a)[695]).",
            "zh": "INCOME 特征非常不寻常，只有 10 个不同的值（该特征的直方图证实了这一点;参见图 12.2（a）[695]）。"
        }
    },
    {
        "translation": {
            "en": "(short) (deep)”) is designed to be a one-semester machine learning course with a focus on giving students a deep understanding of two approaches to machine learning, along with an understanding of the correct methodology to use when evaluating a machine learning model.",
            "zh": "（短）（deep）“） 被设计为一门为期一学期的机器学习课程，重点是让学生深入了解机器学习的两种方法，以及了解在评估机器学习模型时使用的正确方法。"
        }
    },
    {
        "translation": {
            "en": "This is a particularly pertinent question, considering that the adoption of the term deep learning in the mid-2000s to describe modern neural networks was to emphasize that these modern networks are deeper than most of the networks that were developed between the 1940s and the early 2000s.",
            "zh": "考虑到在 2000 年代中期采用深度学习一词来描述现代神经网络是为了强调这些现代网络比 1940 年代和 2000 年代初之间开发的大多数网络更深入，这是一个特别相关的问题。"
        }
    },
    {
        "translation": {
            "en": "Deployment: Machine learning models are built to serve a purpose within an organization, and the last phase of CRISP-DM covers all the work that must be done to successfully integrate a machine learning model into the processes within an organization.",
            "zh": "部署：机器学习模型是为了在组织内服务于某个目的而构建的，CRISP-DM 的最后阶段涵盖了将机器学习模型成功集成到组织内流程中必须完成的所有工作。"
        }
    },
    {
        "translation": {
            "en": "The test statistic we calculate is called the t-statistic.",
            "zh": "我们计算的检验统计量称为 t 统计量。"
        }
    },
    {
        "translation": {
            "en": "A wide range of standard kernel functions can be used with support vector machines. Some popular options are",
            "zh": "各种标准内核函数可用于支持向量机。一些流行的选项是"
        }
    },
    {
        "translation": {
            "en": "multinomial logistic regression, 357, 376",
            "zh": "多项式逻辑回归， 357， 376"
        }
    },
    {
        "translation": {
            "en": "A.4.2 Histograms",
            "zh": "A.4.2 直方图"
        }
    },
    {
        "translation": {
            "en": "The other cells in these columns are populated with similar calculations.",
            "zh": "这些列中的其他单元格填充了类似的计算。"
        }
    },
    {
        "translation": {
            "en": "Figure A.4",
            "zh": "图 A.4"
        }
    },
    {
        "translation": {
            "en": "Examining the arrows in the network shows that the input to the processing neurons can be any of the following: an external input presented to the network via the sensing neurons, the output activation of another processing neuron in the network, or a dummy input that is always set to 1 (the input from a black circle).",
            "zh": "检查网络中的箭头表明，处理神经元的输入可以是以下任何一种：通过感知神经元呈现给网络的外部输入，网络中另一个处理神经元的输出激活，或始终设置为 1 的虚拟输入（来自黑色圆圈的输入）。"
        }
    },
    {
        "translation": {
            "en": "These smoother curves are more representative of the kind of ROC curves we typically encounter in practice.",
            "zh": "这些更平滑的曲线更能代表我们在实践中通常遇到的 ROC 曲线类型。"
        }
    },
    {
        "translation": {
            "en": "32. Obviously we must verify that the prediction made was correct before adding a new instance to the dataset.",
            "zh": "32. 显然，在向数据集添加新实例之前，我们必须验证所做的预测是否正确。"
        }
    },
    {
        "translation": {
            "en": "probability mass function, 246, 758",
            "zh": "概率质量函数， 246， 758"
        }
    },
    {
        "translation": {
            "en": "So, for example, the new value of w[0] is calculated as the old value plus the learning rate times the sum of the errorDelta(,w[0]) contributions to give − 2.9465 + 0.02 × 2.7031 = −2.8924.",
            "zh": "因此，例如，w[0] 的新值计算为旧值加上学习率乘以 errorDelta（，w[0]） 贡献之和，得出 − 2.9465 + 0.02 × 2.7031 = −2.8924。"
        }
    },
    {
        "translation": {
            "en": "The remaining entropy for the UNKNOWN SENDER feature is",
            "zh": "UNKNOWN SENDER 特征的剩余熵为"
        }
    },
    {
        "translation": {
            "en": "6.18   Some socioeconomic data for a set of countries, and a version of the data after equal-frequency binning has been applied.",
            "zh": "6.18 一组国家的一些社会经济数据，以及应用了等频分档后的数据版本。"
        }
    },
    {
        "translation": {
            "en": "9. There are approaches to formally measuring the relationship between a pair of categorical features (for example, the χ2 test) and for measuring the relationship between a categorical feature and a continuous feature (for example, the ANOVA test). We do not cover these in this book, however, and readers are directed to the further reading section at the end of this chapter for information on these approaches.",
            "zh": "9. 有一些方法可以正式测量一对分类特征之间的关系（例如，χ2检验）和测量分类特征与连续特征之间的关系（例如，方差分析检验）。然而，我们在本书中没有涉及这些，读者可以到本章末尾的进一步阅读部分，以获取有关这些方法的信息。"
        }
    },
    {
        "translation": {
            "en": "When var(W) = 1/nin then nin var(W) = 1 and the variance of z for the neuron is solely dependent on the variance of the inputs, which if standardized will have a variance of 1.",
            "zh": "当 var（W） = 1/nin 时，则 nin var（W） = 1，神经元的 z 方差完全取决于输入的方差，如果标准化，则方差为 1。"
        }
    },
    {
        "translation": {
            "en": "Conor knows the expected reward for ordering chicken is high compared with the expected reward for ordering the other unknown items (which he assumes to be low), and so this policy will return a consistently high reward.",
            "zh": "Conor 知道，与订购其他未知物品的预期奖励相比，订购鸡肉的预期奖励很高（他认为奖励很低），因此此策略将返回始终如一的高奖励。"
        }
    },
    {
        "translation": {
            "en": "Table 7.3",
            "zh": "表 7.3"
        }
    },
    {
        "translation": {
            "en": "auto-encoder, 624, 624, 629, 733",
            "zh": "自动编码器， 624， 624， 629， 733"
        }
    },
    {
        "translation": {
            "en": "Vectors are often treated as special cases of matrices. For example, a column vector can be thought of as a matrix with just one column, and a row vector can be thought of as a matrix with a single row.",
            "zh": "向量通常被视为矩阵的特例。例如，可以将列向量视为只有一列的矩阵，而行向量可以将其视为具有单行的矩阵。"
        }
    },
    {
        "translation": {
            "en": "For example, imagine our data followed a normal distribution: then the bins covering the intervals of the feature range at the tails of the normal distribution will have very few instances, and the bins covering the intervals of the feature range near the mean will contain a lot of instances.",
            "zh": "例如，假设我们的数据遵循正态分布：那么在正态分布的尾部覆盖特征范围间隔的条柱将具有很少的实例，而覆盖接近均值的特征范围区间的条柱将包含大量实例。"
        }
    },
    {
        "translation": {
            "en": "The defining characteristic of a recurrent neural network is that it contains feedback connections, and so, unlike a feedforward network, which is a directed acyclic graph, a recurrent neural network is a directed cyclic graph.",
            "zh": "递归神经网络的定义特征是它包含反馈连接，因此，与前馈网络不同，前馈网络是有向无环图，递归神经网络是有向循环图。"
        }
    },
    {
        "translation": {
            "en": "A simple bicycle demand predictions dataset and the workings of the first three iterations of training an ensemble model using boosting to predict RENTALS given TEMP.",
            "zh": "一个简单的自行车需求预测数据集和训练集成模型的前三个迭代的工作原理，使用提升来预测给定温度的租赁。"
        }
    },
    {
        "translation": {
            "en": "We can say more formally that acceleration is, in fact, the derivative of speed with respect to time.",
            "zh": "我们可以更正式地说，加速度实际上是速度相对于时间的导数。"
        }
    },
    {
        "translation": {
            "en": "We can see that on the left-hand side of the graph (for large negative values of x), the rate of change has a high negative value, while on the right-hand side of the graph (for large positive values of x), the rate of change has a large positive value.",
            "zh": "我们可以看到，在图形的左侧（对于 x 的大负值），变化率具有很高的负值，而在图形的右侧（对于 x 的大正值），变化率具有较大的正值。"
        }
    },
    {
        "translation": {
            "en": "The learning in Q-learning takes place when an entry in the action-value table is updated after an action has taken place using Equation (13)[658] at Line 13.20 The intuition behind this update is that the value of taking a specific action in a specific state, Q(st,at), should increase if that action leads to an immediate positive reward and/or it takes the agent to a state from which the agent can expect to receive a positive future return.",
            "zh": "Q-learning中的学习发生在操作发生后，使用公式（13）[658]在第13.20行更新动作值表中的条目时，此更新背后的直觉是，如果该动作导致立即的正奖励和/或将智能体带到智能体可以预期的状态，则在特定状态下采取特定操作的价值Q（st，at）应该增加以获得积极的未来回报。"
        }
    },
    {
        "translation": {
            "en": "Indeed, controlling the size of weight updates in order to stabilize convergence during training is one of the reasons why the learning rate hyper-parameter α is included in the weight update rules.19 In addition, having a large variance on the weight updates applied to input connections can result in the network’s having relatively large weights for some features.",
            "zh": "事实上，控制权重更新的大小以在训练期间稳定收敛是将学习率超参数α包含在权重更新规则中的原因之一。19 此外，应用于输入连接的权重更新存在较大差异可能导致网络对某些特征具有相对较大的权重。"
        }
    },
    {
        "translation": {
            "en": "The fact that the softmax function returns a normalized set of positive values across the layer allows us to interpret the activation of each neuron in the layer as a probability.",
            "zh": "softmax 函数在整个层中返回一组归一化的正值，这一事实允许我们将层中每个神经元的激活解释为概率。"
        }
    },
    {
        "translation": {
            "en": "4.7   Partition sets (Part.), entropy, Gini index, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "4.7 表4.3[136]中数据集的分区集（部分）、熵、基尼指数、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "For instance, the rectangle on the very left represents the feature subset that includes no features at all, and the rectangle at the top of the second column from the left represents the feature subset including just the feature X.",
            "zh": "例如，最左边的矩形表示完全不包含要素的特征子集，左起第二列顶部的矩形表示仅包含要素 X 的特征子集。"
        }
    },
    {
        "translation": {
            "en": "prediction speed, 738",
            "zh": "预测速度，738"
        }
    },
    {
        "translation": {
            "en": "In the second part of this chapter we move our attention to the data structures that are required to build predictive analytics models, and in particular the analytics base table (ABT).",
            "zh": "在本章的第二部分中，我们将注意力转移到构建预测分析模型所需的数据结构上，特别是分析基表 （ABT）。"
        }
    },
    {
        "translation": {
            "en": "diagnosis, 4",
            "zh": "诊断， 4"
        }
    },
    {
        "translation": {
            "en": "Although it is useful to visually compare the performance of different models using an ROC curve, it is often preferable to have a single numeric performance measure with which models can be assessed.",
            "zh": "尽管使用 ROC 曲线直观地比较不同模型的性能很有用，但通常最好使用单一的数值性能度量来评估模型。"
        }
    },
    {
        "translation": {
            "en": "In general we use the sample statistics, which we have already calculated, as estimates for the population parameters.",
            "zh": "通常，我们使用已经计算过的样本统计量作为总体参数的估计值。"
        }
    },
    {
        "translation": {
            "en": "Table 8.10",
            "zh": "表 8.10"
        }
    },
    {
        "translation": {
            "en": "This ensures that the output vector from this layer o‡t is the same size as H and so is the correct dimensions for the elementwise product with the o†t vector, and also that the vector resulting from this operation will have a size of H. This is important because it ensures that ht−1 and ht are the same size.",
            "zh": "这确保了该层 o‡t 的输出向量与 H 的大小相同，因此具有 o†t 向量的逐元乘积的尺寸也相同，并且此操作产生的向量的大小为 H。这很重要，因为它确保 ht−1 和 ht 的大小相同。"
        }
    },
    {
        "translation": {
            "en": "While the overall classification accuracy for this set of predictions is 80%,20 the individual recall scores for each target level show that the performance of the model is not the same for all four levels: the accuracy on the ficulneus and fructosus levels is quite high (85.714% and 90.909% respectively), while for the durionis and pseudoficulneus levels, the accuracy is considerably lower (71.429% and 60.000%).",
            "zh": "虽然这组预测的总体分类准确率为 80%，20 但每个目标水平的单独召回分数表明，模型在所有四个水平上的性能并不相同：ficulneus 和 fructosus 水平的准确率相当高（分别为 85.714% 和 90.909%），而对于 durionis 和 pseudoficulneus 水平， 准确率要低得多（71.429% 和 60.000%）。"
        }
    },
    {
        "translation": {
            "en": "The definition of best is important here.",
            "zh": "在这里，最好的定义很重要。"
        }
    },
    {
        "translation": {
            "en": "(a) On the basis of this behavior sequence, calculate a transition matrix that gives the probability of moving between all the four states.",
            "zh": "（a） 在此行为序列的基础上，计算一个转移矩阵，该矩阵给出在所有四种状态之间移动的概率。"
        }
    },
    {
        "translation": {
            "en": "The density calculation for the TRAINING EXPENSES feature from Table A.1[750] using (a) ten 200-unit intervals and (b) four 500-unit intervals.",
            "zh": "使用 （a） 10 个 200 单位的间隔和 （b） 4 个 500 单位的间隔计算表 A.1[750] 中训练费用特征的密度计算。"
        }
    },
    {
        "translation": {
            "en": "Table 10.1",
            "zh": "表 10.1"
        }
    },
    {
        "translation": {
            "en": "2. A convicted criminal who reoffends after release is known as a recidivist. The following table lists a dataset that describes prisoners released on parole and whether they reoffended within two years of release.37",
            "zh": "2. 被定罪的罪犯在释放后再次犯罪，称为累犯。下表列出了一个数据集，该数据集描述了假释的囚犯以及他们在释放后两年内是否再次犯罪37。"
        }
    },
    {
        "translation": {
            "en": "First, the decision boundaries learned by each algorithm are characteristic of that algorithm.",
            "zh": "首先，每个算法学习的决策边界是该算法的特征。"
        }
    },
    {
        "translation": {
            "en": "Imputation replaces missing feature values with a plausible estimated value based on the feature values that are present. The most common approach to imputation is to replace missing values for a feature with a measure of the central tendency of that feature. For continuous features, the mean or median is most commonly used, and for categorical features, the mode is most commonly used.",
            "zh": "插补将缺失的特征值替换为基于存在的特征值的合理估计值。最常见的插补方法是将特征的缺失值替换为特征的中心趋势的度量。对于连续特征，最常使用均值或中位数，对于分类特征，最常使用众数。"
        }
    },
    {
        "translation": {
            "en": "It is important, however, to know if a measure is a metric or an index, as there are some similarity-based techniques that strictly require measures of similarity to be metrics.",
            "zh": "但是，重要的是要知道度量值是度量值还是索引，因为有一些基于相似性的技术严格要求相似度量值是度量值。"
        }
    },
    {
        "translation": {
            "en": "In fact, instances 1 and 2 are the only instances at this stage that are given predictions of the faulty target level, level 1 (note that their prediction values are the only ones greater than 0.5).",
            "zh": "事实上，实例 1 和 2 是此阶段唯一给出错误目标水平（级别 1）预测的实例（请注意，它们的预测值是唯一大于 0.5 的预测值）。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the variance of the z values across for the neurons in the first hidden layer in the first iteration of training.",
            "zh": "（a） 计算第一次训练迭代中第一个隐藏层中神经元的 z 值的方差。"
        }
    },
    {
        "translation": {
            "en": "13.4.3 The 5-Level Model",
            "zh": "13.4.3 五级模型"
        }
    },
    {
        "translation": {
            "en": "Lewis, Michael. 2004. Moneyball: The art of winning an unfair game. Norton.",
            "zh": "刘易斯，迈克尔。2004. 点球成金：赢得不公平游戏的艺术。诺顿。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the gradient descent algorithm uses the error gradient of a model (neuron or regression model) to update the weights on the inputs into the model.",
            "zh": "这样做的原因是梯度下降算法使用模型（神经元或回归模型）的误差梯度来更新模型输入的权重。"
        }
    },
    {
        "translation": {
            "en": "Table 3.2[56] shows a portion of the ABT that has been developed for the motor insurance claims fraud detection solution based on the design described in Section 2.4.6[42].1 The data quality report for this ABT is shown across Table 3.3[57] (tabular reports for continuous and categorical features) and Figure 3.1[58] (data visualizations for each feature in the dataset).",
            "zh": "表 3.2[56] 显示了基于第 2.4.6 节[42]1 中描述的设计为汽车保险索赔欺诈检测解决方案开发的 ABT 的一部分。表 3.3[57]（连续和分类特征的表格报告）和图 3.1[58]（数据集中每个特征的数据可视化）显示了此 ABT 的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Rob: Nope…",
            "zh": "Rob： 不..."
        }
    },
    {
        "translation": {
            "en": "The only difference to keep in mind is that when we use distances, smaller values mean that instances are closer together in a feature space, whereas when we use similarities, larger values indicate this.",
            "zh": "唯一要记住的区别是，当我们使用距离时，较小的值意味着实例在特征空间中靠得更近，而当我们使用相似性时，较大的值表示这一点。"
        }
    },
    {
        "translation": {
            "en": "An example of a very simple prediction model for this domain is",
            "zh": "这个领域的一个非常简单的预测模型的例子是"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the confidence factor, α, associated with 𝕄4.",
            "zh": "（b） 计算与M4相关的置信因子α。"
        }
    },
    {
        "translation": {
            "en": "Figure 0.1",
            "zh": "图 0.1"
        }
    },
    {
        "translation": {
            "en": "Imagine that you are at a county fair and a stall owner is offering all comers a game of find the lady.",
            "zh": "想象一下，你在一个县集市上，一个摊主正在为所有来者提供寻找女士的游戏。"
        }
    },
    {
        "translation": {
            "en": "As each generated state is a modified version of the preceding state, it is clear that successive states will be correlated with each other.",
            "zh": "由于每个生成的状态都是前一个状态的修改版本，因此很明显，连续的状态将相互关联。"
        }
    },
    {
        "translation": {
            "en": "24. Question 4 in the Exercises at the end of this chapter explores the kernel trick in more detail, and worked examples are provided in the solution.",
            "zh": "24. 本章末尾的练习中的问题 4 更详细地探讨了内核技巧，并在解决方案中提供了工作示例。"
        }
    },
    {
        "translation": {
            "en": "In total, AlexNet had 60 million weights and 650,000 neurons.",
            "zh": "AlexNet总共有6000万个权重和65万个神经元。"
        }
    },
    {
        "translation": {
            "en": "So, frequently, at the start of training the dataset is shuffled and then split into a sequence of mini-batches.",
            "zh": "因此，通常，在训练开始时，数据集会被洗牌，然后拆分为一系列小批量。"
        }
    },
    {
        "translation": {
            "en": "prediction model, 3, 19",
            "zh": "预测模型， 3， 19"
        }
    },
    {
        "translation": {
            "en": "For this reason we use the term sampling bias here; however, for the purposes of this book, the distinction is not particularly important and in general we use the terms as synonyms.",
            "zh": "出于这个原因，我们在这里使用术语抽样偏差;然而，就本书而言，这种区别并不是特别重要，一般来说，我们使用这些术语作为同义词。"
        }
    },
    {
        "translation": {
            "en": "For example, the characteristics of spam emails change both cyclically through the year (typical spam emails at Christmastime are different from typical spam at other times of the year) and also longitudinally (spam in 2014 is very different from spam in 1994).",
            "zh": "例如，垃圾邮件的特征在一年中循环变化（圣诞节期间的典型垃圾邮件与一年中其他时间的典型垃圾邮件不同）和纵向变化（2014 年的垃圾邮件与 1994 年的垃圾邮件有很大不同）。"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov-Smirnov test, 272",
            "zh": "Kolmogorov-Smirnov 测试，272"
        }
    },
    {
        "translation": {
            "en": "13.6   The confusion matrices showing the performance of models on the under-sampled training set.",
            "zh": "13.6 显示模型在欠采样训练集上的性能的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we do not need to add complex non-linearities between the layers; introducing simple non-linearities, such as the logistic or rectifier functions, between each layer is sufficient to enable neural networks to represent arbitrarily complex functions, as long as the network contains enough layers; in other words, as long as the networks are deep enough.",
            "zh": "幸运的是，我们不需要在层之间添加复杂的非线性;在每一层之间引入简单的非线性，例如逻辑函数或整流函数，足以使神经网络表示任意复杂的函数，只要网络包含足够的层;换句话说，只要网络足够深。"
        }
    },
    {
        "translation": {
            "en": "We can then place each instance within the feature space based on the values of its descriptive features.",
            "zh": "然后，我们可以根据每个实例的描述性特征的值将每个实例放置在特征空间中。"
        }
    },
    {
        "translation": {
            "en": "12. This is an example of how machine learning is an ill-posed problem, as discussed in Section 1.3[7].",
            "zh": "12. 这是机器学习如何成为一个不恰当的问题的一个例子，如第 1.3 节[7]所述。"
        }
    },
    {
        "translation": {
            "en": "(b) For this task, discuss the suitability of the decision tree, k nearest neighbor, naive Bayes, and logistic regression models. Which one do you think would be most appropriate?",
            "zh": "（b） 对于此任务，讨论决策树、k 最近邻、朴素贝叶斯和逻辑回归模型的适用性。你认为哪一个最合适？"
        }
    },
    {
        "translation": {
            "en": "The first way that a naive weight initialization can result in instability during training is that the weights on the connections into a neuron are too large.",
            "zh": "在训练过程中，朴素的权重初始化可能导致不稳定的第一种方式是神经元连接上的权重太大。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22(a)[361] shows a scatter plot of a reduced version of the generators dataset (shown in Table 7.6[339]) with a decision boundary drawn across it.",
            "zh": "图7.22（a）[361]显示了生成器数据集的简化版本的散点图（如表7.6[339]所示），并在其上绘制了决策边界。"
        }
    },
    {
        "translation": {
            "en": "Weights",
            "zh": "权重"
        }
    },
    {
        "translation": {
            "en": "In a dendrogram each instance in a dataset is represented by its ID label at the bottom of the figure,10 and the horizontal linkages indicate where clusters have been created.",
            "zh": "在树状图中，数据集中的每个实例都由图底部的 ID 标签表示，10 水平链接指示集群的创建位置。"
        }
    },
    {
        "translation": {
            "en": "Because the values of this equation are so well behaved, we can use it to predict a categorical target feature. Reverting to our previous notation, we have",
            "zh": "由于此方程的值表现良好，因此我们可以使用它来预测分类目标特征。回到我们之前的符号，我们有"
        }
    },
    {
        "translation": {
            "en": "Reduced error pruning (Quinlan, 1987) is a popular version of post-pruning based on error rates.",
            "zh": "减少错误修剪（Quinlan，1987）是基于错误率的后修剪的流行版本。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.10",
            "zh": "图 11.10"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, PREFCHANNEL.",
            "zh": "每个可视化都说明了描述性要素与目标要素 PREFCHANNEL 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Even in decision trees, the prediction is based on the majority target level at a leaf node, and the proportion of this level gives us a prediction score.",
            "zh": "即使在决策树中，预测也是基于叶节点上的多数目标水平，并且该水平的比例为我们提供了预测分数。"
        }
    },
    {
        "translation": {
            "en": "An episode involves an attempt to land the spaceship from a position at the top of the screen and ends when either the spaceship successfully touches down gently on the landing pad or crashes.",
            "zh": "一集涉及尝试从屏幕顶部的位置降落宇宙飞船，并在宇宙飞船成功轻轻降落在着陆垫上或坠毁时结束。"
        }
    },
    {
        "translation": {
            "en": "ELECTRICAL OUTPUT",
            "zh": "电气输出"
        }
    },
    {
        "translation": {
            "en": "These calculations tell us that it is twice as probable that the patient does not have meningitis as it is that the patient does.",
            "zh": "这些计算告诉我们，患者没有脑膜炎的可能性是患者的两倍。"
        }
    },
    {
        "translation": {
            "en": "In this section we look at how auto-encoder models, a particular type of neural network, can be used to learn a new feature representation that can be a useful step as part of a larger machine learning process.",
            "zh": "在本节中，我们将介绍如何使用自动编码器模型（一种特定类型的神经网络）来学习新的特征表示，作为更大的机器学习过程的一部分，这可能是一个有用的步骤。"
        }
    },
    {
        "translation": {
            "en": "7.4.4   Handling Categorical Target Features: Logistic Regression",
            "zh": "7.4.4 处理分类目标特征：逻辑回归"
        }
    },
    {
        "translation": {
            "en": "C4.5, 169",
            "zh": "C4.5， 169"
        }
    },
    {
        "translation": {
            "en": "GRADE",
            "zh": "年级"
        }
    },
    {
        "translation": {
            "en": "We have marked the unit hypercube covering the interval 0 to 1 in this figure.",
            "zh": "在此图中，我们标记了覆盖区间 0 到 1 的单位超立方体。"
        }
    },
    {
        "translation": {
            "en": "The intuition behind support vector machines is that this second decision boundary should distinguish between the two target levels much more reliably than the first.",
            "zh": "支持向量机背后的直觉是，第二个决策边界应该比第一个更可靠地区分两个目标水平。"
        }
    },
    {
        "translation": {
            "en": "11. See Chapter 8[381].",
            "zh": "[11]见第8章[381]。"
        }
    },
    {
        "translation": {
            "en": "Markov assumption, 644",
            "zh": "马尔可夫假设，644"
        }
    },
    {
        "translation": {
            "en": "Then the z value for the neuron will be large, which can result in the activation function for the neuron becoming saturated.",
            "zh": "然后神经元的 z 值会很大，这可能导致神经元的激活函数变得饱和。"
        }
    },
    {
        "translation": {
            "en": "3.4.3   Case Study: Motor Insurance Fraud",
            "zh": "3.4.3 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Hebb, Donald O. 1949. The organization of behavior; A neuropsychological theory. Wiley.",
            "zh": "赫布，唐纳德 O. 1949 年。行为的组织;一种神经心理学理论。威利。"
        }
    },
    {
        "translation": {
            "en": "24. The natural logarithm of a value a, loge(a), is the logarithm of a to the base e, where e is Euler’s number, equal to approximately 2.718.",
            "zh": "24. 值 a 的自然对数 loge（a） 是 a 到底数 e 的对数，其中 e 是欧拉数，大约等于 2.718。"
        }
    },
    {
        "translation": {
            "en": "This is equivalent to the total entropy for the entire dataset.",
            "zh": "这相当于整个数据集的总熵。"
        }
    },
    {
        "translation": {
            "en": "Performing evaluation experiments using different model types is really the only way to determine which variant will work best for a specific problem.",
            "zh": "使用不同的模型类型执行评估实验实际上是确定哪种变体最适合特定问题的唯一方法。"
        }
    },
    {
        "translation": {
            "en": "universal approximation theorem, 400",
            "zh": "通用近似定理，400"
        }
    },
    {
        "translation": {
            "en": "Another advantage of AHC is that it is deterministic, and doesn’t suffer from the impact of different seeds as k-means or k-means++ does. This means that it will give exactly the same result every time it is run on the same dataset and that the issues around finding seeds discussed in Section 10.4.1[605] do not arise. These two advantages are present in most hierarchical clustering algorithms.",
            "zh": "AHC 的另一个优点是它是确定性的，并且不会像 k-means 或 k-means++ 那样受到不同种子的影响。这意味着每次在相同的数据集上运行时，它都会给出完全相同的结果，并且不会出现第 10.4.1 节[605] 中讨论的查找种子的问题。这两个优点存在于大多数分层聚类算法中。"
        }
    },
    {
        "translation": {
            "en": "(a) A continuous function in two variables, x and y; (b) the partial derivative of this function with respect to x; and (c) the partial derivative of this function with respect to y.",
            "zh": "（a） x和y两个变量的连续函数;（b） 该函数相对于 x 的偏导数;（c）该函数相对于 y 的偏导数。"
        }
    },
    {
        "translation": {
            "en": "bar plot, 54, 745, 752",
            "zh": "条形图， 54， 745， 752"
        }
    },
    {
        "translation": {
            "en": "4. The following is a description of the causal relationship between storms, the behavior of burglars and cats, and house alarms:",
            "zh": "4.以下是对暴风雨、窃贼和猫的行为以及房屋警报之间的因果关系的描述："
        }
    },
    {
        "translation": {
            "en": "Hence, the size of the domain representation used by a support vector machine may change as instances are added to the dataset.",
            "zh": "因此，支持向量机使用的域表示的大小可能会随着实例添加到数据集而改变。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.9[672] illustrates this process.",
            "zh": "图11.9[672]说明了这一过程。"
        }
    },
    {
        "translation": {
            "en": "45) for a discussion on how to train a probability-based prediction model in situations where one of the target levels is rare.",
            "zh": "45） 讨论如何在目标水平之一很少的情况下训练基于概率的预测模型。"
        }
    },
    {
        "translation": {
            "en": "The depth of a filter must match the depth of the input.",
            "zh": "筛选器的深度必须与输入的深度匹配。"
        }
    },
    {
        "translation": {
            "en": "In general, given a sufficiently large sample, we use the sample variance, var(a), as a point estimate of σ2.",
            "zh": "通常，给定足够大的样本，我们使用样本方差 var（a） 作为 σ2 的点估计值。"
        }
    },
    {
        "translation": {
            "en": "The extensions and variations to this standard approach that we describe are the use of smoothing to combat overfitting, the modifications required to the standard naive Bayes model to allow it to handle continuous features, and Bayesian network models that give us more control than a naive Bayes model over the assumptions that are encoded in a model.",
            "zh": "我们描述的这种标准方法的扩展和变化是使用平滑来对抗过拟合，对标准朴素贝叶斯模型进行必要的修改以使其能够处理连续特征，以及贝叶斯网络模型，这些模型为我们提供了比朴素贝叶斯模型更多的控制权，可以控制模型中编码的假设。"
        }
    },
    {
        "translation": {
            "en": "A silhouette plot shows the silhouette width for each instance in the dataset grouped by the clusters to which they belong.",
            "zh": "轮廓图显示数据集中每个实例的轮廓宽度，这些实例按其所属的聚类分组。"
        }
    },
    {
        "translation": {
            "en": "For this reason, Jocelyn chose to use a step-wise sequential search for feature selection for each of the three model types.",
            "zh": "出于这个原因，Jocelyn 选择对三种模型类型中的每一种都使用逐步顺序搜索来选择特征。"
        }
    },
    {
        "translation": {
            "en": "Similarly, the partial derivative with respect to w[4] is",
            "zh": "类似地，关于 w[4] 的偏导数为"
        }
    },
    {
        "translation": {
            "en": "Voronoi tessellation, 189, 231",
            "zh": "Voronoi 镶嵌， 189， 231"
        }
    },
    {
        "translation": {
            "en": "If we have developed a predictive model that is used in a particular business process, we can run that business process in parallel both with the predictive model, the treatment group, and without the predictive model, the control group, in order to evaluate how much the use of the predictive model has improved the business process.",
            "zh": "如果我们开发了一个用于特定业务流程的预测模型，我们可以与预测模型（处理组）和没有预测模型（对照组）并行运行该业务流程，以评估预测模型的使用在多大程度上改善了业务流程。"
        }
    },
    {
        "translation": {
            "en": "(b) An illustration of the final ensemble model trained using the boosting algorithm.",
            "zh": "（b） 使用提升算法训练的最终集成模型的图示。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.6",
            "zh": "图 7.6"
        }
    },
    {
        "translation": {
            "en": "Therefore, the inclusion of the translation by the bias term allows the weighted sum to define a linear function on its inputs that does not pass through the origin.",
            "zh": "因此，通过偏置项包含平移，加权和可以在其输入上定义一个不通过原点的线性函数。"
        }
    },
    {
        "translation": {
            "en": "Comparing Figure 6.5(a)[273] and Figure 6.5(b)[273], we can see clearly that the introduction of outliers has a much larger effect on the normal distribution than it does on the student-t distribution.",
            "zh": "比较图6.5（a）[273]和图6.5（b）[273]，我们可以清楚地看到，引入异常值对正态分布的影响比对学生t分布的影响要大得多。"
        }
    },
    {
        "translation": {
            "en": "which has a sum of squared errors of 1.8804. Obviously, because there are instances with different levels for the target feature overlapping in the feature space, it is not possible in this case to build a model that perfectly separates the good and faulty machines. The model trained, however, strikes a good balance between mistaking good machines for faulty ones and vice versa.",
            "zh": "其平方误差之和为 1.8804。显然，由于在特征空间中存在具有不同级别的目标特征重叠的实例，因此在这种情况下，不可能构建一个完美区分良好和故障机器的模型。然而，经过训练的模型在将好机器误认为有缺陷的机器之间取得了很好的平衡，反之亦然。"
        }
    },
    {
        "translation": {
            "en": "One complaint that is often leveled against mean squared error is that, although it can be used to effectively rank models, the actual mean squared error values themselves are not especially meaningful in relation to the scenario that a model is being used for.",
            "zh": "经常针对均方误差的一个抱怨是，尽管它可用于有效地对模型进行排名，但实际的均方误差值本身对于模型所用于的场景并不是特别有意义。"
        }
    },
    {
        "translation": {
            "en": "We can consider the scout to be an intelligent agent (or simply agent) attempting to complete a task within an environment.",
            "zh": "我们可以将侦察员视为试图在环境中完成任务的智能代理（或简称代理）。"
        }
    },
    {
        "translation": {
            "en": "Just like our imagined mountain climber, the algorithm can use only very localized information.",
            "zh": "就像我们想象中的登山者一样，该算法只能使用非常本地化的信息。"
        }
    },
    {
        "translation": {
            "en": "Finally, the temporal-difference learning approach, which is the basis for the standard approach to reinforcement learning that will be discussed in the following chapter, is explained.",
            "zh": "最后，解释了时间差分学习方法，该方法是下一章将讨论的标准强化学习方法的基础。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.2(a)[186] illustrates the difference between the Manhattan and Euclidean distances between two points in a two-dimensional feature space. If we compare Equation (5.1)[185] and Equation (5.2)[185], we can see that both distance metrics are essentially functions of the differences between the values of the features. Indeed, the Euclidean and Manhattan distances are special cases of the Minkowski distance, which defines a family of distance metrics based on differences between features.",
            "zh": "图5.2（a）[186]说明了二维特征空间中两点之间的曼哈顿距离和欧几里得距离之间的差异。如果我们比较等式（5.1）[185]和等式（5.2）[185]，我们可以看到，这两个距离度量本质上都是特征值之间差异的函数。事实上，欧几里得距离和曼哈顿距离是闵可夫斯基距离的特例，闵可夫斯基距离根据要素之间的差异定义了一系列距离度量。"
        }
    },
    {
        "translation": {
            "en": "It is important to remember that when we perform data preparations (such as those in Section 3.6[87] or those described in Section 3.4[69]), we are changing the data that we will use to subsequently train predictive models.",
            "zh": "重要的是要记住，当我们执行数据准备时（例如第 3.6 节[87] 或第 3.4 节[69]中描述的数据），我们正在更改将用于后续训练预测模型的数据。"
        }
    },
    {
        "translation": {
            "en": "If this number changed significantly from what was seen in the data used to build the model, the model would be deemed stale, and retraining would be required.",
            "zh": "如果此数字与用于构建模型的数据中显示的数字发生显著变化，则该模型将被视为过时，需要重新训练。"
        }
    },
    {
        "translation": {
            "en": "10.9   (a)–(b) Visualizations of the distributions of the descriptive features in the mobile phone customer dataset in Table 10.1[604] across the complete dataset, and divided by the clustering found using k-means clustering (k = 3).",
            "zh": "10.9 （a）–（b） 表10.1[604]中移动电话客户数据集中描述性特征分布在整个数据集中的可视化，并除以使用k-means聚类（k = 3）找到的聚类。"
        }
    },
    {
        "translation": {
            "en": "The validation set is used when data outside the training set is required in order to tune particular aspects of a model.",
            "zh": "当需要训练集之外的数据来优化模型的特定方面时，使用验证集。"
        }
    },
    {
        "translation": {
            "en": "(a) What target level will the naive Bayes model predict for the following query:",
            "zh": "（a） 朴素贝叶斯模型将预测以下查询的目标水平："
        }
    },
    {
        "translation": {
            "en": "mapping features, 36, 65",
            "zh": "映射要素， 36， 65"
        }
    },
    {
        "translation": {
            "en": "The optimal threshold is found by computing the information gain for each of the target level transition boundaries and selecting the boundary with the highest information gain as the threshold.",
            "zh": "通过计算每个目标电平转换边界的信息增益并选择具有最高信息增益的边界作为阈值，可以找到最佳阈值。"
        }
    },
    {
        "translation": {
            "en": "At first, this choice of question might seem ineffective.",
            "zh": "起初，这种问题选择似乎是无效的。"
        }
    },
    {
        "translation": {
            "en": "These measures, however, are intrinsically tied to the threshold used to convert prediction scores into target levels.",
            "zh": "然而，这些度量与用于将预测分数转换为目标水平的阈值有着内在的联系。"
        }
    },
    {
        "translation": {
            "en": "10.5 Summary",
            "zh": "10.5 总结"
        }
    },
    {
        "translation": {
            "en": "Lintott, C. J., K. Schawinski, A. Slosar, K. Land, S. Bamford, D. Thomas, M. J. Raddick, R. C. Nichol, A. Szalay, D. Andreescu, P. Murray, and J. Vandenberg. 2008. Galaxy Zoo: Morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey. Monthly Notices of the Royal Astronomical Society 389: 1179–1189. doi:10.1111/j.1365-2966.2008.13689.x.",
            "zh": "林托特、CJ、K. Schawinski、A. Slosar、K. Land、S. Bamford、D. Thomas、MJ Raddick、RC Nichol、A. Szalay、D. Andreescu、P. Murray 和 J. Vandenberg。2008. 银河动物园：斯隆数字巡天对星系的目视检查得出的形态学。皇家天文学会月刊 389：1179–1189。doi：10.1111/j.1365-2966.2008.13689.x."
        }
    },
    {
        "translation": {
            "en": "4.14   The decision tree that would be generated for the vegetation classification dataset listed in Table 4.9[147] using information gain.",
            "zh": "4.14 使用信息增益为表4.9[147]中列出的植被分类数据集生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "(a) Create a k-d tree for this dataset. Assume the following order over the features: RENT then SIZE.",
            "zh": "（a） 为此数据集创建 k-d 树。假设要素的顺序如下：RENT 和 SIZE。"
        }
    },
    {
        "translation": {
            "en": "As TD(0) updates an entry in the action-value table every time an action has been taken, it has the advantage that an agent can start to learn very quickly; however, this approach can take a long time to converge toward the optimal values in the action-value table.16",
            "zh": "由于 TD（0） 在每次执行操作时都会更新操作值表中的条目，因此它的优点是代理可以非常快速地开始学习;但是，这种方法可能需要很长时间才能收敛到操作值表中的最佳值16。"
        }
    },
    {
        "translation": {
            "en": "8.1   A high-level schematic of the structure of a neuron.",
            "zh": "8.1 神经元结构的高级示意图。"
        }
    },
    {
        "translation": {
            "en": "where var(W(k)) is the variance of all the weights in layer k; nin(k) is the number of neurons that feed inputs to layer k; and nout(k) is the number of neurons that neurons in layer k connect forward to (in a fully connected feedforward network nin(k) is equal to the number of neurons in layer k − 1 and nout(k) is the number of neurons in layer k + 1). Often in practice, however, a simpler variant of Xavier initialization is used that just considers nin(k)",
            "zh": "其中 var（W（k）） 是层 k 中所有权重的方差;nin（k） 是将输入馈送到第 k 层的神经元数量;nout（k） 是 k 层神经元向前连接的神经元数（在全连接的前馈网络中，nin（k） 等于 k 层 − 1 中的神经元数，nout（k） 是 k 层 + 1 中的神经元数）。然而，在实践中，通常使用更简单的 Xavier 初始化变体，只考虑 nin（k）"
        }
    },
    {
        "translation": {
            "en": "The Minkowski distance between two instances a and b in a feature space with m descriptive features is defined as",
            "zh": "在具有 m 个描述性特征的特征空间中，两个实例 a 和 b 之间的闵可夫斯基距离定义为"
        }
    },
    {
        "translation": {
            "en": "This uncertainty is one of the key things that the MDP formulation allows us to model.",
            "zh": "这种不确定性是 MDP 公式允许我们建模的关键因素之一。"
        }
    },
    {
        "translation": {
            "en": "The reason why Equation 8.104[501] has a more complicated form then previously is that the neuron has two sets of inputs (from the input layer and the activation buffer), and so it has two separate weight matrices; also, to be as transparent as possible, we have explicitly represented the bias terms for the weights in a separate vector w0.",
            "zh": "方程 8.104[501] 的形式比以前更复杂的原因是神经元有两组输入（来自输入层和激活缓冲区），因此它有两个独立的权重矩阵;此外，为了尽可能透明，我们在单独的向量 W0 中明确表示了权重的偏差项。"
        }
    },
    {
        "translation": {
            "en": "This does assume that the width of the layers is sufficient to permit the network to represent the function; however, for a given function the number of neurons required in each of the hidden layers is not known, in general.",
            "zh": "这确实假设层的宽度足以允许网络表示函数;然而，对于给定的函数，通常每个隐藏层中所需的神经元数量是未知的。"
        }
    },
    {
        "translation": {
            "en": "11.7   The Lunar Lander environment. The aim of the game is to control the spaceship starting from the top of the world and attempting to land on the landing pad.",
            "zh": "11.7 月球着陆器环境。游戏的目的是控制宇宙飞船从世界之巅开始，试图降落在着陆台上。"
        }
    },
    {
        "translation": {
            "en": "4.4.2   Handling Continuous Descriptive Features",
            "zh": "4.4.2 处理连续描述性特征"
        }
    },
    {
        "translation": {
            "en": "frequency histogram, 752",
            "zh": "频率直方图，752"
        }
    },
    {
        "translation": {
            "en": "Switching the focus to the calculation of δs for hidden neurons, the calculation of ∂ℰ/∂ak for a hidden neuron k requires that the δs for all downstream neurons be calculated first (i.e., all the neurons that the activation ak is directly propagated to during the forward pass).",
            "zh": "将焦点切换到隐藏神经元的 δs 计算，隐藏神经元 k 的 ∂E/∂ak 计算需要首先计算所有下游神经元的 δs（即激活 ak 在前向传递期间直接传播到的所有神经元）。"
        }
    },
    {
        "translation": {
            "en": "CLAIM AMOUNT, TOTAL CLAIMED, NUM.",
            "zh": "索赔金额，索赔总额，编号。"
        }
    },
    {
        "translation": {
            "en": "The number of customers who left the mobile phone network operator each week during the comparative experiment from both the control group (random selection) and the treatment group (model selection).",
            "zh": "在对照组（随机选择）和治疗组（模型选择）的比较实验期间每周离开移动电话网络运营商的客户数量。"
        }
    },
    {
        "translation": {
            "en": "to determine which of the models that we have built for a particular task is most suited to that task",
            "zh": "确定我们为特定任务构建的哪些模型最适合该任务"
        }
    },
    {
        "translation": {
            "en": "It is important to recognize that using an inductive bias is a necessary prerequisite for learning to occur; without inductive bias, a machine learning algorithm cannot learn anything beyond what is in the data.",
            "zh": "重要的是要认识到，使用归纳偏差是学习发生的必要先决条件;如果没有归纳偏差，机器学习算法就无法学习数据之外的任何内容。"
        }
    },
    {
        "translation": {
            "en": "A multivariate logistic regression model has been built to predict the propensity of shoppers to perform a repeat purchase of a free gift that they are given.",
            "zh": "已经建立了一个多变量逻辑回归模型来预测购物者重复购买免费礼物的倾向。"
        }
    },
    {
        "translation": {
            "en": "Notice that each row in the CPT tables sum to 1.",
            "zh": "请注意，CPT 表中的每一行总和为 1。"
        }
    },
    {
        "translation": {
            "en": "A portion of the action-value table for the grid world example at its first initialization.",
            "zh": "首次初始化时网格世界示例的操作值表的一部分。"
        }
    },
    {
        "translation": {
            "en": "In particular, Ross needed to understand the current analytics capability of the company and its readiness to take action in response to the insights that an analytics solution would provide.",
            "zh": "特别是，Ross 需要了解公司当前的分析能力，以及它是否准备好采取行动以响应分析解决方案将提供的见解。"
        }
    },
    {
        "translation": {
            "en": "In order to explain how matrix multiplications are used in a neural network, we need to introduce some notation and then define the order of the matrices in the multiplication.",
            "zh": "为了解释矩阵乘法在神经网络中的使用方式，我们需要引入一些符号，然后定义乘法中矩阵的顺序。"
        }
    },
    {
        "translation": {
            "en": "Throughout the discussion of the data quality report and how we use it, we return to the motor insurance fraud case study from Chapter 2[23].",
            "zh": "在对数据质量报告以及我们如何使用它的讨论中，我们回到了第 2 章[23] 的汽车保险欺诈案例研究。"
        }
    },
    {
        "translation": {
            "en": "12. This is a slight departure from Equation (11.9)[643] as it sums to infinity rather than to the end of an episode. This, however, makes no difference in the discussion that follows but is the normal formulation of the Bellman Equations.",
            "zh": "12. 这与等式（11.9）[643]略有不同，因为它的总和是无穷大，而不是一集的末尾。然而，这在随后的讨论中没有区别，但这是贝尔曼方程的正常公式。"
        }
    },
    {
        "translation": {
            "en": "Neural network texts that we would recommend include Bishop (1996) and Reed and Marks (1999).",
            "zh": "我们推荐的神经网络文本包括Bishop（1996）和Reed and Marks（1999）。"
        }
    },
    {
        "translation": {
            "en": "Second, the algorithm checks if the instance indexed by the node is closer to the query than the instance at the current best node.",
            "zh": "其次，该算法检查节点索引的实例是否比当前最佳节点的实例更接近查询。"
        }
    },
    {
        "translation": {
            "en": "6. See Section 3.1[54].",
            "zh": "6. 参见第 3.1 节[54]。"
        }
    },
    {
        "translation": {
            "en": "68.50",
            "zh": "68.50"
        }
    },
    {
        "translation": {
            "en": "In an example like the car journey just described, where we have a set of discrete measurements, calculating the derivative is simply a matter of determining the difference between subsequent pairs of measurements.",
            "zh": "在像刚才描述的汽车旅程这样的例子中，我们有一组离散的测量值，计算导数只是确定后续测量对之间的差异。"
        }
    },
    {
        "translation": {
            "en": "10.2   Calculating the silhouette for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3). The overall silhouette index value is 0.66.",
            "zh": "10.2 计算使用 k 均值算法（k = 3）找到的移动电话客户数据集最终聚类的轮廓（表 10.1[604]）。整体轮廓指数值为 0.66。"
        }
    },
    {
        "translation": {
            "en": "Intercept (w[0])",
            "zh": "拦截 （w[0]）"
        }
    },
    {
        "translation": {
            "en": "The remainder of this section focuses on the error delta function, which calculates the delta value that determines the direction (either positive or negative) and the magnitude of the adjustments made to each weight.",
            "zh": "本节的其余部分重点介绍误差增量函数，该函数计算确定方向（正或负）的增量值以及对每个权重所做的调整幅度。"
        }
    },
    {
        "translation": {
            "en": "ABT, 17",
            "zh": "ABT，17"
        }
    },
    {
        "translation": {
            "en": "OECD. 2013. The OECD privacy framework. Organisation for Economic Co-operation and Development.",
            "zh": "经合组织。2013. 经合组织隐私框架。经济合作与发展组织。"
        }
    },
    {
        "translation": {
            "en": "(b) What would be the reduction in entropy (i.e., the information gain) in bits if we split these letters into two sets, one containing the vowels and the other containing the consonants?",
            "zh": "（乙）如果我们把这些字母分成两组，一组包含元音，另一组包含辅音，熵（即信息增益）会减少多少？"
        }
    },
    {
        "translation": {
            "en": "The Gini coefficient can take values in the range [0,1], and higher values indicate better model performance. The Gini coefficient for the model shown in Figure 9.12(a)[562] is 0.596, and the Gini coefficients for the four models shown in Figure 9.12(a)[562] are 0.992, 0.774, 0.527, and 0.190. The Gini coefficient is very commonly used in financial modeling scenarios such as credit scoring.",
            "zh": "基尼系数可以取 [0,1] 范围内的值，值越大表示模型性能越好。图9.12（a）[562]所示模型的基尼系数为0.596，图9.12（a）[562]所示的四个模型的基尼系数分别为0.992、0.774、0.527和0.190。基尼系数非常常用于信用评分等金融建模场景。"
        }
    },
    {
        "translation": {
            "en": "An extension of the standard support vector machine approach that allows a soft margin, however, caters for this and allows overlap between instances with target features of the two different levels.",
            "zh": "然而，标准支持向量机方法的扩展允许软裕量，可以满足这一点，并允许具有两个不同级别目标特征的实例之间重叠。"
        }
    },
    {
        "translation": {
            "en": "The units in all hidden layers use a rectified linear activation function.",
            "zh": "所有隐藏层中的单元都使用校正的线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "An algorithm to learn decision trees for a continuous target can use the first two base cases.",
            "zh": "学习连续目标决策树的算法可以使用前两个基本情况。"
        }
    },
    {
        "translation": {
            "en": "Table 3.6",
            "zh": "表 3.6"
        }
    },
    {
        "translation": {
            "en": "The figure also illustrates the local receptive field of the first neuron in the grid; note that this receptive field includes imaginary pixels.",
            "zh": "该图还说明了网格中第一个神经元的局部感受野;请注意，此感受野包括虚像素。"
        }
    },
    {
        "translation": {
            "en": "Once the decision to use deep learning has been made, the next decision is to choose the network architecture to use.",
            "zh": "一旦决定使用深度学习，下一个决定就是选择要使用的网络架构。"
        }
    },
    {
        "translation": {
            "en": "If the distribution of model outputs changes dramatically, for example, if a model that previously made positive predictions 80% of the time is suddenly making positive predictions only 20% of the time, then we can assume that there is a strong possibility that concept drift has occurred and that the model has gone stale.",
            "zh": "如果模型输出的分布发生了巨大变化，例如，如果一个模型之前在 80% 的时间里做出了积极的预测，而现在只有 20% 的时间做出了积极的预测，那么我们可以假设很有可能发生了概念漂移，并且模型已经过时了。"
        }
    },
    {
        "translation": {
            "en": "histogram, 54, 745, 752, 752",
            "zh": "直方图， 54， 745， 752， 752"
        }
    },
    {
        "translation": {
            "en": "Obviously, the competitor would not give the retailer this information, and so the analytics team at the retailer sought to find some proxy feature that would give them much the same information.",
            "zh": "显然，竞争对手不会向零售商提供这些信息，因此零售商的分析团队试图找到一些代理功能，为他们提供大致相同的信息。"
        }
    },
    {
        "translation": {
            "en": "The activation vector created by this division a(l)′′ is the activation vector propagated forward to the next layer.",
            "zh": "由此划分 a（l）′′ 创建的激活向量是向前传播到下一层的激活向量。"
        }
    },
    {
        "translation": {
            "en": "38. This explanation of inverted dropout is inspired by a description given in Andrew Ng’s Coursera course; the video is available at https://www.youtube.com/watch?v=D8PJAL-MZv8&feature=youtu.be.",
            "zh": "38. 这种对倒置辍学的解释的灵感来自吴恩达的 Coursera 课程中的描述;该视频可在 https://www.youtube.com/watch?v=D8PJAL-MZv8&feature=youtu.be 上观看。"
        }
    },
    {
        "translation": {
            "en": "Vectors of Features",
            "zh": "特征向量"
        }
    },
    {
        "translation": {
            "en": "John",
            "zh": "John"
        }
    },
    {
        "translation": {
            "en": "The overall measure of similarity could then be based on a weighted combination of the two.",
            "zh": "然后，相似性的总体衡量标准可以基于两者的加权组合。"
        }
    },
    {
        "translation": {
            "en": "1. Does a machine learning approach match the requirements of the project?",
            "zh": "1. 机器学习方法是否符合项目的要求？"
        }
    },
    {
        "translation": {
            "en": "The units in the output layer use a sigmoid activation function.",
            "zh": "输出层中的单位使用 S 形激活函数。"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification decision tree after the dataset has been split using ELEVATION ≥ 4,175.",
            "zh": "使用 ELEVATION ≥ 4,175 分割数据集后的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "Sarah’s training for the stepping-stone challenge has many of the characteristics of a reinforcement learning problem.",
            "zh": "Sarah 的垫脚石挑战训练具有强化学习问题的许多特征。"
        }
    },
    {
        "translation": {
            "en": "The descriptive feature values for d1 are SMS = 97 and VOICE = 21, and for d2 are SMS = 181 and VOICE = 184.",
            "zh": "d1 的描述性特征值为 SMS = 97 和 VOICE = 21，d2 的描述性特征值为 SMS = 181 和 VOICE = 184。"
        }
    },
    {
        "translation": {
            "en": "This introduces the second art of reinforcement learning: the design of effective reward functions.",
            "zh": "这引入了强化学习的第二种艺术：有效奖励函数的设计。"
        }
    },
    {
        "translation": {
            "en": "Segata, N., E. Blanzieri, S. J. Delany, and Padraig Cunningham. 2009. Noise reduction for instance-based learning with a local maximal margin approach. Journal of Intelligent Information Systems 35: 301–331.",
            "zh": "Segata， N.、E. Blanzieri、SJ Delany 和 Padraig Cunningham。2009. 基于实例的学习的降噪与局部最大边距方法.智能信息系统杂志 35：301–331。"
        }
    },
    {
        "translation": {
            "en": "(c) On the basis of the silhouette, would you choose 2 or 3 for the value of k for this dataset?",
            "zh": "（c） 根据轮廓，您会选择 2 还是 3 作为该数据集的 k 值？"
        }
    },
    {
        "translation": {
            "en": "Also, all our filter examples so far have been two-dimensional filters.",
            "zh": "此外，到目前为止，我们所有的过滤器示例都是二维过滤器。"
        }
    },
    {
        "translation": {
            "en": "silhouette plot, 610",
            "zh": "剪影图，610"
        }
    },
    {
        "translation": {
            "en": "The plot of activation values directly mirrors the plot of the z values because the neurons are using a linear activation function.",
            "zh": "激活值的图直接反映了 z 值的图，因为神经元使用的是线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "So, given a dataset representing a domain with two target levels C1 and C2, an arbitrary instance from the domain should be classified as being associated with target level C1 with the probability and to target level C2 with the probability , where |C1| and |C2| refer to the number of instances in associated with C1 and C2, respectively.",
            "zh": "因此，给定一个数据集，该数据集表示具有两个目标级别 C1 和 C2 的域，域中的任意实例应分类为与目标级别 C1 相关联，概率与目标级别 C2 相关联，其中 |C1|以及 |C2|分别指与 C1 和 C2 关联的实例数。"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the continuous HEIGHT feature and the target feature TACHYCARDIA.",
            "zh": "（b） 下面的可视化说明了连续 HEIGHT 特征与目标特征心动过速之间的关系。"
        }
    },
    {
        "translation": {
            "en": "SMARTPHONE",
            "zh": "智能手机"
        }
    },
    {
        "translation": {
            "en": "Goodfellow et al.",
            "zh": "Goodfellow等人。"
        }
    },
    {
        "translation": {
            "en": "Kolmogorov, Andrei Nikolaevich. 1963. On the representation of continuous functions of several variables by superpositions of continuous functions of one variable and addition. American Mathematical Society Translations.",
            "zh": "科尔莫戈罗夫，安德烈·尼古拉耶维奇。1963. 关于通过一个变量的连续函数的叠加和加法来表示多个变量的连续函数.美国数学学会翻译。"
        }
    },
    {
        "translation": {
            "en": "The dashed circle centered on the query location has a radius equal to the best-distance.",
            "zh": "以查询位置为中心的虚线圆的半径等于最佳距离。"
        }
    },
    {
        "translation": {
            "en": "The dashed lines plot the axes of the coordinate system, and the ellipses plot the 1, 3, and 5 unit distance contours.",
            "zh": "虚线绘制坐标系的轴，椭圆绘制 1、3 和 5 单位距离等值线。"
        }
    },
    {
        "translation": {
            "en": "That said, there are some other features of this plot that are encouraging.",
            "zh": "也就是说，这个情节还有一些其他特点是令人鼓舞的。"
        }
    },
    {
        "translation": {
            "en": "These three functions have the same structure; they all take two inputs that can be either TRUE or FALSE, and they return either TRUE or FALSE.",
            "zh": "这三个函数具有相同的结构;它们都接受两个可以是 TRUE 或 FALSE 的输入，并返回 TRUE 或 FALSE。"
        }
    },
    {
        "translation": {
            "en": "State can be represented as a stack of the last 4 frames in the game.",
            "zh": "状态可以表示为游戏中最后 4 帧的堆栈。"
        }
    },
    {
        "translation": {
            "en": "Table 4.4",
            "zh": "表 4.4"
        }
    },
    {
        "translation": {
            "en": "This characteristic is useful in the generation of performance measures like the F1 measure, as we typically prefer measures to highlight shortcomings in our models rather than hide them.",
            "zh": "此特性在生成性能度量（如 F1 度量）时很有用，因为我们通常更喜欢突出模型中的缺点而不是隐藏它们的度量。"
        }
    },
    {
        "translation": {
            "en": "Notice that in both figures, the normal distribution plotted with the continuous black line has mean μ = 0 and standard deviation σ = 1.",
            "zh": "请注意，在这两个图中，用连续黑线绘制的正态分布均值 μ = 0，标准差 σ = 1。"
        }
    },
    {
        "translation": {
            "en": "Data with which to implement features based on these domain concepts would likely come from the raw camera imaging and spectrograph images themselves, or from the results of the SDSS processing pipeline.",
            "zh": "基于这些领域概念实现功能的数据可能来自原始相机成像和光谱仪图像本身，或者来自 SDSS 处理管道的结果。"
        }
    },
    {
        "translation": {
            "en": "1.1   Predictive data analytics moving from data to insight to decision.",
            "zh": "1.1 预测性数据分析从数据到洞察再到决策。"
        }
    },
    {
        "translation": {
            "en": "An alternative approach to using small multiples to visualize the relationship between a categorical feature and a continuous feature is to use a collection of box plots.",
            "zh": "使用小倍数可视化分类要素和连续要素之间关系的另一种方法是使用箱形图集合。"
        }
    },
    {
        "translation": {
            "en": "Table 11.2",
            "zh": "表 11.2"
        }
    },
    {
        "translation": {
            "en": "model-free reinforcement learning, 657, 676",
            "zh": "无模型强化学习， 657， 676"
        }
    },
    {
        "translation": {
            "en": "Figure 8.28[470] illustrates the forward pass for this mini-batch through this network.",
            "zh": "图 8.28[470] 说明了该小批次通过该网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "The fundamental element in an LSTM network is the cell.",
            "zh": "LSTM 网络中的基本元素是小区。"
        }
    },
    {
        "translation": {
            "en": "A.7  (a) and (b) frequency histograms and (c) and (d) density histograms for the continuous TRAINING EXPENSES feature from Table A.1[750], illustrating how using intervals overcomes the problem seen in Figure A.6[753] and the effect of varying interval sizes.",
            "zh": "表A.1[750]中连续训练费用特征的A.7（a）和（b）频率直方图以及（c）和（d）密度直方图，说明了使用间隔如何克服图A.6[753]中的问题以及不同间隔大小的影响。"
        }
    },
    {
        "translation": {
            "en": "This step defines the set of prediction models the machine learning algorithm will search.",
            "zh": "此步骤定义机器学习算法将搜索的预测模型集。"
        }
    },
    {
        "translation": {
            "en": "26. By unbounded, we mean that, unlike the logistic function where the maximum value it will return is 1, the rectifier linear function may return any value up to + ∞.",
            "zh": "26. 我们所说的无界，是指，与逻辑函数不同，逻辑函数将返回的最大值为 1，整流器线性函数可以返回高达 + ∞ 的任何值。"
        }
    },
    {
        "translation": {
            "en": "However, color images typically encode three types of information for each pixel—the red, green and blue information, with other colors generated via the combination of these three primary colors.",
            "zh": "但是，彩色图像通常对每个像素的三种类型的信息进行编码 - 红色、绿色和蓝色信息，其他颜色通过这三种原色的组合生成。"
        }
    },
    {
        "translation": {
            "en": "The final model is then a model that makes a basic prediction and adds a number of improvements to this prediction. We can see this if we consider the model trained after four iterations of gradient boosting33",
            "zh": "然后，最终模型是一个进行基本预测的模型，并对该预测进行了许多改进。如果我们考虑在梯度提升的四次迭代后训练的模型，我们可以看到这一点33"
        }
    },
    {
        "translation": {
            "en": "The reason we perform this division by ρ is to scale up the non-zero activations in the new activation vector so that the weighted sum calculations in the next layer are of a similar magnitude to what they would have been if none of the activations had been set to 0.",
            "zh": "我们按 ρ 进行除法的原因是为了放大新激活向量中的非零激活，以便下一层中的加权和计算与没有激活设置为 0 时的大小相似。"
        }
    },
    {
        "translation": {
            "en": "Ross’s previous discussions with Grace, the AT CTO, had established that the data required to build a churn prediction model were likely to be available and reasonably easily accessible.",
            "zh": "Ross 之前与 AT 首席技术官 Grace 的讨论已经确定，构建客户流失预测模型所需的数据很可能是可用的，并且相当容易访问。"
        }
    },
    {
        "translation": {
            "en": "2. See the discussion in Section 2.1[23] relating to data availability, data connections, data granularity, data volume, and data time horizons.",
            "zh": "2. 请参阅第 2.1 节[23]中有关数据可用性、数据连接、数据粒度、数据量和数据时间范围的讨论。"
        }
    },
    {
        "translation": {
            "en": "2nd New",
            "zh": "第 2 个新品"
        }
    },
    {
        "translation": {
            "en": "noise dampening mechanism, 157",
            "zh": "降噪机构，157"
        }
    },
    {
        "translation": {
            "en": "Both of these phenomena are a consequence of the fact that we are applying the filter only to valid pixels in the image.",
            "zh": "这两种现象都是由于我们仅将滤镜应用于图像中的有效像素这一事实的结果。"
        }
    },
    {
        "translation": {
            "en": "1. Weights are also known as model parameters, and so regression models are often known as parameterized models.",
            "zh": "1. 权重也称为模型参数，因此回归模型通常称为参数化模型。"
        }
    },
    {
        "translation": {
            "en": "Sejnowski, Terrence J. 2018. The deep learning revolution. MIT Press.",
            "zh": "Sejnowski，Terrence J. 2018 年。深度学习革命。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "If it is, best and best-distance are updated to reflect this (Lines 5, 6, and 7).",
            "zh": "如果是，则更新最佳和最佳距离以反映这一点（第 5、6 和 7 行）。"
        }
    },
    {
        "translation": {
            "en": "With regard to defining the outcome period, the company agreed that it would be most useful to make a prediction that a customer was likely to churn three months before the churn event took place, as this gave them time to take retention actions.",
            "zh": "关于定义结果期，该公司一致认为，在客户流失事件发生前三个月预测客户可能会流失是最有用的，因为这给了他们时间采取保留措施。"
        }
    },
    {
        "translation": {
            "en": "These error gradients can then be used by the gradient descent weight update rule to update the weights for each neuron.",
            "zh": "然后，梯度下降权重更新规则可以使用这些误差梯度来更新每个神经元的权重。"
        }
    },
    {
        "translation": {
            "en": "where d is a vector of m + 1 descriptive features, d[0]…d[m]; and w[0]…w[m] are (m + 1) weights. However, no matter which way we choose to define the weighted sum, the operation remains the same.",
            "zh": "其中 d 是 m + 1 个描述性特征的向量，d[0]...d[m];和 w[0]...w[m] 是 （m + 1） 权重。但是，无论我们选择哪种方式定义加权和，操作都保持不变。"
        }
    },
    {
        "translation": {
            "en": "In the same way we used basis functions with logistic regression models in Section 7.4.5[351], basis functions can be used with support vector machines to handle training data that is not linearly separable. In order to use basis functions, we must update Equation (7.44)[364] to",
            "zh": "就像我们在第7.4.5节[351]中将基函数与逻辑回归模型一起使用一样，基函数可以与支持向量机一起使用，以处理不可线性分离的训练数据。为了使用基函数，我们必须将方程（7.44）[364]更新为"
        }
    },
    {
        "translation": {
            "en": "Logistic Regression",
            "zh": "逻辑回归"
        }
    },
    {
        "translation": {
            "en": "For continuous target features, the median is preferred to the mean because the mean is more heavily affected by outliers.27",
            "zh": "对于连续目标特征，中位数优于均值，因为均值受异常值的影响更大27。"
        }
    },
    {
        "translation": {
            "en": "This is not always the case.",
            "zh": "但情况并非总是如此。"
        }
    },
    {
        "translation": {
            "en": "Table 4.13",
            "zh": "表 4.13"
        }
    },
    {
        "translation": {
            "en": "Sometimes a blend of Xavier and He initialization is used.",
            "zh": "有时使用 Xavier 和 He 初始化的混合。"
        }
    },
    {
        "translation": {
            "en": "To begin the backpropagation process through the convolutional layer, we assume that the δs for the neurons D and E have already been calculated. We can now calculate the δ for Neuron C",
            "zh": "为了开始通过卷积层的反向传播过程，我们假设已经计算了神经元 D 和 E 的 δ。我们现在可以计算神经元 C 的δ"
        }
    },
    {
        "translation": {
            "en": "However, a modified version of this weight initialization heuristic is recommended when the network uses rectified linear units (He et al., 2015).",
            "zh": "然而，当网络使用整流线性单元时，建议使用这种权重初始化启发式的修改版本（He et al.， 2015）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.42[516] indicates the flow of error gradients back through the elementwise product in the output gate by labeling each path emerging from the operation with its respective error gradient vector: ∂ℰ/∂o‡ and ∂ℰ/∂o‡, respectively.",
            "zh": "图 8.42[516] 通过分别用其各自的误差梯度向量标记操作中出现的每条路径：∂E/∂o‡ 和 ∂E/∂o‡，来指示误差梯度流回输出门中的逐元乘积。"
        }
    },
    {
        "translation": {
            "en": "Learning requires an opportunity to explore as well as to exploit.",
            "zh": "学习需要一个探索和利用的机会。"
        }
    },
    {
        "translation": {
            "en": "percentiles, 54, 91, 567, 748",
            "zh": "百分位数， 54， 91， 567， 748"
        }
    },
    {
        "translation": {
            "en": "A schematic of a feedforward artificial neural network with a three-neuron softmax output layer.",
            "zh": "具有三神经元softmax输出层的前馈人工神经网络示意图。"
        }
    },
    {
        "translation": {
            "en": "Figures 9.18(b)[582] and 9.18(c)[582] show the target distributions for the two points in time after deployment for which the stability index is to be calculated.",
            "zh": "图9.18（b）[582]和图9.18（c）[582]显示了部署后两个时间点的目标分布，这些时间点将计算稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "5.4.5.1 Similarity indexes for binary descriptive features There are lots of datasets that contain binary descriptive features—categorical features that have only two levels.",
            "zh": "5.4.5.1 二元描述性特征的相似性索引 有许多数据集包含二元描述性特征，即只有两个级别的分类特征。"
        }
    },
    {
        "translation": {
            "en": "At the end of the chapter, unsupervised machine learning for feature generation will be discussed.",
            "zh": "在本章的最后，将讨论用于特征生成的无监督机器学习。"
        }
    },
    {
        "translation": {
            "en": "equivariant, 483",
            "zh": "等变量，483"
        }
    },
    {
        "translation": {
            "en": "Jocelyn discussed this issue and the results of these two baseline experiments with Edwin, and both decided that it would be best to pursue the optimal performance measured by overall classification accuracy because, in practice, the important thing for the SDSS system was to classify elliptical and spiral galaxies as accurately as possible.",
            "zh": "Jocelyn 与 Edwin 讨论了这个问题以及这两个基线实验的结果，两人都认为最好追求通过整体分类精度来衡量的最佳性能，因为在实践中，SDSS 系统的重要事情是尽可能准确地对椭圆星系和螺旋星系进行分类。"
        }
    },
    {
        "translation": {
            "en": "This new discovery caused ripples of great excitement in the international physics community and greatly enhanced the reputations of the lab at Nancy and Professor Blondlot.",
            "zh": "这一新发现在国际物理学界引起了极大的兴奋，并大大提高了南希实验室和布隆德洛特教授的声誉。"
        }
    },
    {
        "translation": {
            "en": "Only when you are positioned at the sweet spot in the middle of the board—neither too far forward nor too far back—will you be able to use your paddling efforts to successfully catch a wave.",
            "zh": "只有当你被定位在冲浪板中间的最佳位置时——既不要太靠前，也不要太靠后——你才能利用你的划桨努力成功地赶上一个波浪。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5[124] shows a collection of sets of playing cards of contrasting entropy.",
            "zh": "图4.5[124]显示了一组对比熵的扑克牌。"
        }
    },
    {
        "translation": {
            "en": "For some modeling approaches this is quite easy, while for others it is almost impossible to adapt a model, and the only option is to discard the current model and train a new one using an updated dataset.",
            "zh": "对于某些建模方法来说，这很容易，而对于其他方法来说，几乎不可能调整模型，唯一的选择是丢弃当前模型并使用更新的数据集训练新模型。"
        }
    },
    {
        "translation": {
            "en": "The reason is that the intuitive clusters in the other two datasets do not conform to the assumption of spherical clusters that underlies the k-means clustering algorithm.",
            "zh": "原因是其他两个数据集中的直观聚类不符合球形聚类的假设，而球形聚类是 k 均值聚类算法的基础。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the if statement on Line 5 succeeds, and best is set to d21, and best-distance is set to 0.9014 (Lines 6 and 7).",
            "zh": "因此，第 5 行的 if 语句成功，best 设置为 d21，best distance 设置为 0.9014（第 6 行和第 7 行）。"
        }
    },
    {
        "translation": {
            "en": "Examples of continuous functions (shown as solid lines) and their derivatives (shown as dashed lines).",
            "zh": "连续函数（显示为实线）及其导数（显示为虚线）的示例。"
        }
    },
    {
        "translation": {
            "en": "For the customers in the treatment group, the company applied the process using the predictive model to determine which customers to contact regarding customer satisfaction.",
            "zh": "对于治疗组中的客户，该公司使用预测模型应用该过程来确定要联系哪些客户了解客户满意度。"
        }
    },
    {
        "translation": {
            "en": "There are also a number of different ways in which evaluation experiments can be performed, as described in Section 9.4.1[540].",
            "zh": "还有许多不同的方法可以进行评估实验，如第9.4.1节[540]所述。"
        }
    },
    {
        "translation": {
            "en": "Categorical: A finite set of values that cannot be ordered and allow no arithmetic (e.g., country, product type)",
            "zh": "分类：一组有限的值，不能排序，也不允许算术（例如，国家/地区、产品类型）"
        }
    },
    {
        "translation": {
            "en": "3.12   Anscombe’s quartet. For all four samples, the correlation measure returns the same value (0.816) even though the relationship between the features is very different in each case.",
            "zh": "3.12 安斯科姆的四重奏。对于所有四个样本，相关度量返回相同的值 （0.816），尽管每种情况下特征之间的关系都非常不同。"
        }
    },
    {
        "translation": {
            "en": "In loan default prediction, the likelihood that an applicant will default on a loan is predicted based on the information the applicant provides on the application form.",
            "zh": "在贷款违约预测中，申请人拖欠贷款的可能性是根据申请人在申请表上提供的信息来预测的。"
        }
    },
    {
        "translation": {
            "en": "It is somewhat surprising how often a linear multivariable regression model can accurately represent the relationship between descriptive features and a target feature without the use of basis functions. We recommend that simple linear models be evaluated first and basis functions introduced only when the performance of the simpler models is deemed unsatisfactory.",
            "zh": "令人惊讶的是，线性多变量回归模型在不使用基函数的情况下可以准确表示描述性特征与目标特征之间的关系。我们建议首先评估简单的线性模型，只有在认为简单模型的性能不令人满意时才引入基函数。"
        }
    },
    {
        "translation": {
            "en": "8.32   A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a different receptive field from the neuron in Figure 8.31[480].",
            "zh": "8.32 图 4 的灰度图像的 6×6 矩阵表示，以及与图 8.31 [480] 中神经元具有不同感受野的神经元。"
        }
    },
    {
        "translation": {
            "en": "5.5   A dataset listing salary and age information for customers and whether they purchased a product.",
            "zh": "5.5 列出客户工资和年龄信息以及他们是否购买产品的数据集。"
        }
    },
    {
        "translation": {
            "en": "3.3.4   Case Study: Motor Insurance Fraud",
            "zh": "3.3.4 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "1. In the notation used in this book, d1 refers to the instance in a dataset with an ID of 1, and so on.",
            "zh": "1. 在本书使用的符号中，d1 指的是 ID 为 1 的数据集中的实例，依此类推。"
        }
    },
    {
        "translation": {
            "en": "We also take the opportunity to introduce the use of data normalization and feature selection in the context of similarity-based learning.",
            "zh": "我们还借此机会介绍了在基于相似性的学习背景下使用数据规范化和特征选择。"
        }
    },
    {
        "translation": {
            "en": "Non-Parametric",
            "zh": "非参数"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "表4.3[136]中数据集的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.14[625] shows the architecture of a typical auto-encoder network.",
            "zh": "图10.14[625]显示了典型自动编码器网络的架构。"
        }
    },
    {
        "translation": {
            "en": "where the abs() function returns the absolute value. For example, the Manhattan distance between instances d12 (SPEED = 5.00, AGILITY = 2.50) and d5 (SPEED = 2.75, AGILITY = 7.50) in Table 5.2[183] is",
            "zh": "其中 abs（） 函数返回绝对值。例如，表 5.2[183] 中的实例 d12 （SPEED = 5.00， AGILITY = 2.50） 和 d5 （SPEED = 2.75， AGILITY = 7.50） 之间的曼哈顿距离为"
        }
    },
    {
        "translation": {
            "en": "residual, 315",
            "zh": "残差，315"
        }
    },
    {
        "translation": {
            "en": "The values for the new categorical feature are then created by assigning to instances in the dataset the level of the new feature that corresponds to the range that their value of the continuous feature falls into.",
            "zh": "然后，通过将新特征的级别分配给数据集中的实例来创建新分类特征的值，该级别对应于其连续特征值所属的范围。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 3[200] lists the algorithm we use to retrieve the nearest neighbor for a query.",
            "zh": "算法3[200]列出了我们用来检索查询的最近邻的算法。"
        }
    },
    {
        "translation": {
            "en": "Kelleher (2019) provides an overview of the history of deep learning that highlights the major developments in the field and the trends that are driving its adoption across a broad range of domains, and it discusses likely future developments in the field.",
            "zh": "Kelleher（2019）概述了深度学习的历史，突出了该领域的主要发展以及推动其在广泛领域采用的趋势，并讨论了该领域未来可能的发展。"
        }
    },
    {
        "translation": {
            "en": "regularization, 477",
            "zh": "正则化， 477"
        }
    },
    {
        "translation": {
            "en": "The numbers along the arrows in Figure 11.2[644] show the probabilities of moving between the different sates in this model.",
            "zh": "图11.2[644]中箭头沿线的数字显示了该模型中不同位置之间移动的概率。"
        }
    },
    {
        "translation": {
            "en": "The result of this calculation is − 0.6668.",
            "zh": "计算结果为− 0.6668。"
        }
    },
    {
        "translation": {
            "en": "Apart from the advantage of descending the true error gradient for the entire dataset, batch gradient descent is also able to take advantage of the fact that a neural network, implemented as a sequence of matrix operations, can process multiple examples in parallel (as illustrated by Figure 8.6[393] and Figure 8.9[399]).",
            "zh": "除了对整个数据集的真实误差梯度进行降序的优点外，批量梯度下降还能够利用以下事实：作为矩阵操作序列实现的神经网络可以并行处理多个示例（如图 8.6[393] 和图 8.9[399] 所示）。"
        }
    },
    {
        "translation": {
            "en": "Again, the prediction task is a binary classification task, and the instances in the test set are labeled as belonging to the positive or negative class.",
            "zh": "同样，预测任务是一个二元分类任务，测试集中的实例被标记为属于正类或负类。"
        }
    },
    {
        "translation": {
            "en": "Understanding these two equations, and the core algorithms that they underpin (k-means clustering and Q-learning), is an excellent step toward broadening your knowledge out to the many other uses of machine learning beyond prediction.",
            "zh": "了解这两个方程，以及它们所支撑的核心算法（k-means聚类和Q-learning），是将你的知识扩展到机器学习的许多其他用途（除了预测之外）的一个很好的步骤。"
        }
    },
    {
        "translation": {
            "en": "-0.43",
            "zh": "-0.43"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7[128] shows how the instances in the spam dataset are split when we partition it using each of the three descriptive features.",
            "zh": "图 4.7[128] 显示了当我们使用三个描述性特征中的每一个对垃圾邮件数据集进行分区时，垃圾邮件数据集中的实例是如何拆分的。"
        }
    },
    {
        "translation": {
            "en": "If the features are related, however, then the shapes and/or the central tendencies of the histograms will be different.",
            "zh": "但是，如果特征是相关的，则直方图的形状和/或中心趋势将不同。"
        }
    },
    {
        "translation": {
            "en": "Tukey, John W. 1977. Exploratory data analysis. Addison-Wesley.",
            "zh": "Tukey，John W. 1977 年。探索性数据分析。艾迪生-卫斯理。"
        }
    },
    {
        "translation": {
            "en": "The backward pass starts by using the calculation illustrated by Equation (8.21)[411] to calculate a δ for each neuron in the output layer.",
            "zh": "向后传递首先使用公式 （8.21）[411] 所示的计算来计算输出层中每个神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "The challenge is if two clusters, each containing multiple instances, have been found, how should the distance between them be calculated?",
            "zh": "挑战在于，如果找到了两个集群，每个集群都包含多个实例，那么应该如何计算它们之间的距离？"
        }
    },
    {
        "translation": {
            "en": "CREDITRATING",
            "zh": "信用评级"
        }
    },
    {
        "translation": {
            "en": "For example, early moves in a game of chess do not lead to large positive rewards but set the ground for later high-reward moves.",
            "zh": "例如，国际象棋游戏中的早期走法不会带来巨大的积极奖励，但会为以后的高回报走法奠定基础。"
        }
    },
    {
        "translation": {
            "en": "Assume that we are using the dataset in Table 5.2[183] as our labeled training dataset, and we want to make a prediction to tell us whether a query instance with SPEED = 6.75 and AGILITY = 3.00 is likely to be drafted or not. Figure 5.3[188] illustrates the feature space of the training dataset with the query, represented by the ? marker.",
            "zh": "假设我们使用表 5.2[183] 中的数据集作为标记的训练数据集，并且我们想要进行预测以告诉我们是否可能起草 SPEED = 6.75 且 AGILITY = 3.00 的查询实例。 图 5.3[188] 说明了带有查询的训练数据集的特征空间， 由 ？标记。"
        }
    },
    {
        "translation": {
            "en": "complete case analysis, 69, 712",
            "zh": "完整案例分析，69,712"
        }
    },
    {
        "translation": {
            "en": "A.4.1    Bar Plots",
            "zh": "A.4.1 条形图"
        }
    },
    {
        "translation": {
            "en": "Assuming that the agent generates the same random number as before (0.634), which is greater than ε, greedy action selection will be used and, again, a0 = left will be chosen as it has the highest Q value for the start state, 0-3.",
            "zh": "假设代理生成与之前相同的随机数 （0.634），该随机数大于 ε，则将使用贪婪操作选择，并且再次选择 a0 = left，因为它具有初始状态的最高 Q 值 0-3。"
        }
    },
    {
        "translation": {
            "en": "Table 6.19[301] lists a some of the samples generated using Gibbs sampling for the Bayesian network in Figure 6.13[296] for the query",
            "zh": "表6.19[301]列出了图6.13[296]中使用吉布斯采样为贝叶斯网络生成的一些样本"
        }
    },
    {
        "translation": {
            "en": "The problem with this reasoning, however, is that, on average, the answer to Question 2 will be yes only one out of every four times you play.",
            "zh": "然而，这种推理的问题在于，平均而言，问题 2 的答案是肯定的，每玩四次中只有一次。"
        }
    },
    {
        "translation": {
            "en": "The dataset in the college athlete example is imbalanced—there are 13 no instances and only 7 yes instances.",
            "zh": "大学运动员示例中的数据集是不平衡的——有 13 个没有实例，只有 7 个是实例。"
        }
    },
    {
        "translation": {
            "en": "Using the initial weights predictions are made for all the instances in the training dataset, as shown in the Predictions column (column 3) of Table 7.3[331]. By comparing these predicted values with the actual RENTAL PRICE (column 2), we can compute an error and a squared error term for each training instance, columns 4 and 5 of the table.",
            "zh": "使用初始权重对训练数据集中的所有实例进行预测，如表 7.3[331] 的“预测”列（第 3 列）所示。通过将这些预测值与实际的 RENTAL PRICE（第 2 列）进行比较，我们可以计算每个训练实例的误差和误差项的平方误差项，即表的第 4 列和第 5 列。"
        }
    },
    {
        "translation": {
            "en": "Such a definition, however, has the complication that the same customer could appear in the ABT as both an active and a churn customer, although admittedly the descriptive features for these two instances would be calculated over different periods of time.",
            "zh": "然而，这样的定义具有复杂性，即同一客户可能同时作为活跃客户和流失客户出现在 ABT 中，尽管不可否认，这两个实例的描述性特征将在不同的时间段内计算。"
        }
    },
    {
        "translation": {
            "en": "Another simple approach to handling missing values is complete case analysis, which deletes from an ABT any instances that are missing one or more feature values.",
            "zh": "处理缺失值的另一种简单方法是完整案例分析，它从 ABT 中删除任何缺少一个或多个特征值的实例。"
        }
    },
    {
        "translation": {
            "en": "The monitoring system that Ross put in place generated a report at the end of every quarter that evaluated the performance of the model in the previous quarter by comparing how many of the people not contacted by the retention team actually churned.",
            "zh": "Ross 实施的监控系统在每个季度末都会生成一份报告，通过比较保留团队未联系的人员中有多少人实际流失，来评估模型在上一季度的绩效。"
        }
    },
    {
        "translation": {
            "en": "Using a threshold on the error of the model error on the training set as a convergence criterion—as we are doing here—is very likely to result in the model overfitting the training data.",
            "zh": "使用训练集上模型误差的阈值作为收敛标准（就像我们在这里所做的那样），很可能导致模型过度拟合训练数据。"
        }
    },
    {
        "translation": {
            "en": "This means that the standard deviation is measured in the original units of the sample, which makes it much more interpretable than the variance. It is very common to see the mean and standard deviation provided as a full description of a sample.",
            "zh": "这意味着标准差是以样本的原始单位测量的，这使得它比方差更容易解释。通常将均值和标准差视为样本的完整描述。"
        }
    },
    {
        "translation": {
            "en": "where index_w is the whole part of index, index_f is the fractional part of index, and aindex_w is the value in the ordered list at position index_w.",
            "zh": "其中 index_w 是索引的全部部分，index_f 是索引的小数部分，aindex_w 是位置 index_w 处的有序列表中的值。"
        }
    },
    {
        "translation": {
            "en": "Using Jaccard similarity, the current trial user in the online retail example is judged to be equally similar to instance d1 and d2:",
            "zh": "使用 Jaccard 相似性，判断在线零售示例中的当前试用用户与实例 d1 和 d2 的相似度相同："
        }
    },
    {
        "translation": {
            "en": "Once we have calculated a δ for each of the neurons in the sub-sampling layer, we can then backpropagate these δs to the layer of neurons that convolve the filter.",
            "zh": "一旦我们计算了子采样层中每个神经元的δ，我们就可以将这些 δ 反向传播到卷积滤波器的神经元层。"
        }
    },
    {
        "translation": {
            "en": "This is appropriate in many applications.",
            "zh": "这在许多应用中都是适用的。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.24[454] illustrates what happens in the internal dynamics of the network if we increase the standard deviation of the distribution from which we sample, in this instance a normal distribution with μ = 0.0 and σ = 0.2.",
            "zh": "图 8.24[454] 说明了如果我们增加采样分布的标准差，网络内部动力学会发生什么，在本例中为 μ = 0.0 且 σ = 0.2 的正态分布。"
        }
    },
    {
        "translation": {
            "en": "The time differences arising from these different computational loads can have an influence on model selection.",
            "zh": "这些不同的计算负载产生的时间差可能会对模型选择产生影响。"
        }
    },
    {
        "translation": {
            "en": "The optimization criterion used when training a support vector machine allows us to choose between multiple different decision boundaries that satisfy the constraint given in Equation (7.44)[364], such as those shown in Figure 7.23[364]. The optimization criterion used is defined in terms of the perpendicular distance from any instance to the decision boundary and is given by",
            "zh": "训练支持向量机时使用的优化标准允许我们在满足方程（7.44）[364]中给出的约束的多个不同决策边界之间进行选择，如图7.23[364]所示。使用的优化标准是根据从任何实例到决策边界的垂直距离来定义的，由下式给出"
        }
    },
    {
        "translation": {
            "en": "Using the information provided, write a description of what it means for a taxpayer to be a member of each of the clusters.",
            "zh": "使用提供的信息，描述纳税人成为每个集群成员意味着什么。"
        }
    },
    {
        "translation": {
            "en": "Figure A.6[753] is a bar plot of the TRAINING EXPENSES feature from Table A.1[750]. The figure illustrates why a bar plot is not an appropriate graphic to use to visualize a continuous feature: as is generally the case with a continuous feature, there are as many distinct values as there are instances in the dataset, and therefore there are as many bars in the histogram as there are instances, each bar having a height of 1.0.",
            "zh": "图A.6[753]是表A.1[750]中培训费用特征的条形图。该图说明了为什么条形图不适合用于可视化连续要素的图形：与连续要素的一般情况一样，数据集中的实例具有相同的不同值，因此直方图中的条形与实例一样多，每个条形的高度为 1.0。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, it is unlikely that a change in the distribution of just one descriptive feature in a multi-feature model will have a large impact on model performance.",
            "zh": "此外，在多特征模型中，仅一个描述性特征的分布变化不太可能对模型性能产生重大影响。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS PER YEAR; RATIO OF AVERAGE CLAIMS PER YEAR TO NUMBER OF CLAIMS IN LAST 12 MONTHS: AVG.",
            "zh": "每年的索赔;每年平均申领人数与过去12个月申领人数的比率：平均"
        }
    },
    {
        "translation": {
            "en": "11.2 Fundamentals",
            "zh": "11.2 基础"
        }
    },
    {
        "translation": {
            "en": "The number of times the customer has been called by the retention team",
            "zh": "保留团队呼叫客户的次数"
        }
    },
    {
        "translation": {
            "en": "Table 3.2",
            "zh": "表 3.2"
        }
    },
    {
        "translation": {
            "en": "A Bayesian network that encodes the causal relationships between the features in the corruption domain. The CPT entries have been calculated using the binned data from Table 6.18[295].",
            "zh": "一个贝叶斯网络，用于对损坏域中特征之间的因果关系进行编码。CPT条目是使用表6.18[295]中的分箱数据计算的。"
        }
    },
    {
        "translation": {
            "en": "The choice of which one to use mostly depends on how much data is available.",
            "zh": "选择使用哪一个主要取决于可用的数据量。"
        }
    },
    {
        "translation": {
            "en": "If the cardinality of a continuous feature is significantly less than the number of instances in the dataset, then it should be investigated.",
            "zh": "如果连续要素的基数明显小于数据集中的实例数，则应对其进行调查。"
        }
    },
    {
        "translation": {
            "en": "Δw7,5=",
            "zh": "Δw7,5="
        }
    },
    {
        "translation": {
            "en": "4.6   Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset 𝒟8 in Figure 4.9[139].",
            "zh": "4.6 图4.9[139]中数据集D8的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "To illustrate this growth in the number of terms in the chain of products as we move back through a network, imagine a simple feedforward network with just three neurons, i, j, and k, arranged so that i feeds forward into j and j into k",
            "zh": "为了说明当我们通过网络向后移动时，产品链中项数量的增长，想象一个简单的前馈网络，只有三个神经元，i、j 和 k，排列成 i 前馈到 J 中，j 进到 k 中"
        }
    },
    {
        "translation": {
            "en": "multi-armed bandit problem, 656",
            "zh": "多臂土匪问题，656"
        }
    },
    {
        "translation": {
            "en": "where ⊙ is an elementwise vector product, o† was calculated in the forward pass using Equation (8.114)[512 and o‡ was calculated in the forward pass using Equation (8.115)[512].",
            "zh": "其中 ⊙ 是逐元素向量积，o† 在前向传递中使用方程 （8.114）[512] 计算，o‡ 在前向传递中使用方程 （8.115）[512] 计算。"
        }
    },
    {
        "translation": {
            "en": "The arithmetic mean, for example, is very sensitive to very large or very small values in a sample.",
            "zh": "例如，算术平均值对样本中非常大或非常小的值非常敏感。"
        }
    },
    {
        "translation": {
            "en": "Lowercase boldface letters refer to a vector of features. For example, d denotes a vector of descriptive features for an instance in a dataset, and q denotes a vector of descriptive features in a query.",
            "zh": "小写粗体字母表示要素向量。例如，d 表示数据集中实例的描述性特征向量，q 表示查询中的描述性特征向量。"
        }
    },
    {
        "translation": {
            "en": "A particularly useful feature of linear regression models is that the weights used by the model indicate the effect of each descriptive feature on the predictions returned by the model.",
            "zh": "线性回归模型的一个特别有用的功能是，模型使用的权重表示每个描述性特征对模型返回的预测的影响。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 2[188] provides a pseudocode definition of the algorithm for the prediction stage.",
            "zh": "算法2[188]为预测阶段提供了算法的伪代码定义。"
        }
    },
    {
        "translation": {
            "en": "For the email classification data given in Table 9.1[537], the confusion matrix-based values can be calculated as follows:",
            "zh": "对于表9.1[537]中给出的电子邮件分类数据，基于混淆矩阵的值可以计算如下："
        }
    },
    {
        "translation": {
            "en": "The key step in this iterative weight update process is solving the blame assignment problem. The general structure of the backpropagation algorithm is a two-step process that results in an assignment of blame (or an error gradient) to each of the neurons in the network:",
            "zh": "此迭代权重更新过程的关键步骤是解决归咎分配问题。反向传播算法的一般结构是一个两步过程，导致将责任（或误差梯度）分配给网络中的每个神经元："
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(b)[453] illustrates how the z values vary across the layers of the network during the forward pass of the algorithm.",
            "zh": "图8.23（b）[453]说明了在算法的前向传递过程中，z值在网络层中是如何变化的。"
        }
    },
    {
        "translation": {
            "en": "6. Subsequently, in this chapter we illustrate how this can be done for ReLU, neurons using rectifier activation functions.",
            "zh": "6. 随后，在本章中，我们将说明如何使用整流器激活函数的 ReLU 神经元来做到这一点。"
        }
    },
    {
        "translation": {
            "en": "For each level of the categorical feature, a box plot of the corresponding values of the continuous feature is drawn.",
            "zh": "对于分类要素的每个水平，绘制连续要素相应值的箱形图。"
        }
    },
    {
        "translation": {
            "en": "For example, if we have a third instance with SMS = 194 and VOICE = 42, the cosine similarity between this instance and d1 will be 1.0, because even though the magnitudes of their feature values are different, the relationship between the feature values for both instances is the same: both customers use about four times as many SMS messages as VOICE calls.",
            "zh": "例如，如果我们有第三个实例，其 SMS = 194 且 VOICE = 42，则此实例与 d1 之间的余弦相似度将为 1.0，因为即使它们的特征值大小不同，两个实例的特征值之间的关系是相同的：两个客户使用的 SMS 消息数量大约是 VOICE 呼叫的四倍。"
        }
    },
    {
        "translation": {
            "en": "Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT Press.",
            "zh": "Goodfellow、Ian、Yoshua Bengio 和 Aaron Courville。2016. 深度学习.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "In particular, if we are working with a large dataset, the time cost in computing the distances between a query and all the training instances and retrieving the k nearest neighbors may be prohibitive.",
            "zh": "特别是，如果我们使用的是大型数据集，则计算查询与所有训练实例之间的距离以及检索 k 个最近邻的时间成本可能会令人望而却步。"
        }
    },
    {
        "translation": {
            "en": "This figure is based on Figure 5.4 of Kelleher (2019), which in turn was inspired by an image by Christopher Olah (available at: http://colah.github.io/posts/2015-08-Understanding-LSTMs/).",
            "zh": "该图基于Kelleher（2019）的图5.4，而该图的灵感来自Christopher Olah的图像（可在 http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 获得）。"
        }
    },
    {
        "translation": {
            "en": "3. The following image shows an artificial network with two layers of linear neurons (i.e., neurons that have no activation function and whose output is simply the result of the weighted sum of their inputs). Furthermore, these neurons have no bias terms.",
            "zh": "3. 下图显示了一个具有两层线性神经元的人工网络（即，没有激活函数的神经元，其输出只是其输入的加权和的结果）。此外，这些神经元没有偏差项。"
        }
    },
    {
        "translation": {
            "en": "(a) 100 neurons in the input layer",
            "zh": "（a） 输入层中有 100 个神经元"
        }
    },
    {
        "translation": {
            "en": "The last data visualization technique we will discuss for visualizing the values of a single feature is the box plot.8 A box plot is a visual representation of the five key descriptive statistics for a continuous feature: minimum, 1st quartile, median, 3rd quartile, and maximum.",
            "zh": "我们将讨论的最后一个数据可视化技术是箱形图。8 箱形图是连续特征的五个关键描述性统计量的可视化表示：最小值、第一四分位数、中位数、第三四分位数和最大值。"
        }
    },
    {
        "translation": {
            "en": "21. See Frank (2000) for a detailed discussion and analysis on the use of statistical tests in decision tree pruning.",
            "zh": "21. 参见Frank （2000）关于在决策树修剪中使用统计检验的详细讨论和分析。"
        }
    },
    {
        "translation": {
            "en": "If the value of the stability index is less than 0.1, then the distribution of the newly collected test set is broadly similar to the distribution in the original test set.",
            "zh": "如果稳定性指数的值小于 0.1，则新收集的测试集的分布与原始测试集中的分布大致相似。"
        }
    },
    {
        "translation": {
            "en": "1. Induces a model using the weighted dataset and calculates the total error, ε, in the set of predictions made by the model for the instances in the training dataset.29 The ε value is calculated by summing the weights of the training instances for which the predictions made by the model are incorrect.",
            "zh": "1. 使用加权数据集诱导模型，并计算模型对训练数据集中的实例所做的预测集中的总误差 ε.29 ε值是通过将模型做出的预测不正确的训练实例的权重相加来计算的。"
        }
    },
    {
        "translation": {
            "en": "Choosing between models in this sort of scenario is difficult as it really comes down to balancing the needs of the application—when the system makes errors (as it inevitably will from time to time), what error is least bad?",
            "zh": "在这种情况下，在模型之间进行选择是很困难的，因为它实际上归结为平衡应用程序的需求——当系统出错时（不可避免地会不时出现错误），哪个错误最不严重？"
        }
    },
    {
        "translation": {
            "en": "Assuming a stride length of 1 and no padding on the input, we would require a 2-by-2 layer of neurons to convolve the filter over this image. The top-left neuron in this layer would have a local receptive field covering the 2-by-2 square in the top-left of each of the channels. Equation 8.101[494] lists the values from the image that are inside this neuron’s local receptive field",
            "zh": "假设步幅为 1 并且输入上没有填充，我们需要一个 2×2 的神经元层来卷积此图像上的滤波器。该层中左上角的神经元将有一个局部感受野，覆盖每个通道左上角的 2×2 正方形。公式 8.101[494] 列出了该神经元局部感受野内的图像值"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12(b)[562] shows ROC curves for four models tested on a version of the email classification test set in Table 9.13[560], containing many more instances than the one we have been discussing so far, which is why the curves are so much smoother than the curve shown in Figure 9.12(a)[562].",
            "zh": "图9.12（b）[562]显示了在表9.13[560]中的电子邮件分类测试集版本上测试的四个模型的ROC曲线，其中包含的实例比我们目前讨论的实例多得多，这就是为什么曲线比图9.12（a）[562]中显示的曲线平滑得多的原因。"
        }
    },
    {
        "translation": {
            "en": "cross-entropy, 434, 463, 465",
            "zh": "交叉熵， 434， 463， 465"
        }
    },
    {
        "translation": {
            "en": "We can now define the calculation of the δ for a neuron in a softmax output layer using a cross-entropy loss function as follows:",
            "zh": "现在，我们可以使用交叉熵损失函数定义softmax输出层中神经元δ的计算，如下所示："
        }
    },
    {
        "translation": {
            "en": "Table 9.8[554] shows the profit matrix for this problem.",
            "zh": "表 9.8[554] 显示了该问题的利润矩阵。"
        }
    },
    {
        "translation": {
            "en": "The best performing model is the logistic regression model.",
            "zh": "性能最好的模型是逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "Specifically, it represents how sensitive the error of the network ℰ is to changes in ak.",
            "zh": "具体来说，它表示网络 E 的误差对 ak 变化的敏感程度。"
        }
    },
    {
        "translation": {
            "en": "First, this equation computes a distance between two instances a and b, each with m descriptive features.",
            "zh": "首先，该方程计算两个实例 a 和 b 之间的距离，每个实例都有 m 个描述性特征。"
        }
    },
    {
        "translation": {
            "en": "In the preceding figure, the image on the right shows a simple linear logistic regression model trained to perform this task. This model is",
            "zh": "在上图中，右图显示了为执行此任务而训练的简单线性逻辑回归模型。这个模型是"
        }
    },
    {
        "translation": {
            "en": "The first is that if we use a 4-by-4 layer of neurons, to cover a 6-by-6 input matrix, the dimensionality of the resulting feature map is also 4-by-4.",
            "zh": "首先，如果我们使用 4×4 的神经元层来覆盖 6×6 的输入矩阵，则生成的特征图的维数也是 4×4。"
        }
    },
    {
        "translation": {
            "en": "The distance of each instance in the dataset to each of these cluster centroids is then calculated using the distance measure Dist.",
            "zh": "然后，使用距离测量 Dist."
        }
    },
    {
        "translation": {
            "en": "In these instances, a margin cannot be defined, as we have done in this example.",
            "zh": "在这些情况下，无法定义边距，就像我们在此示例中所做的那样。"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_R_I",
            "zh": "DEREDDIFF_R_I"
        }
    },
    {
        "translation": {
            "en": "Obviously, the set of domain concepts that are important change from one analytics solution to another. However, there are a number of general domain concepts that are often useful:",
            "zh": "显然，重要的领域概念集从一个分析解决方案更改为另一个分析解决方案。但是，有许多通用域概念通常很有用："
        }
    },
    {
        "translation": {
            "en": "Unfortunately, Conor doesn’t speak any Irish and the staff in the hotel restaurant don’t speak any English.",
            "zh": "不幸的是，康纳不会说爱尔兰语，酒店餐厅的工作人员也不会说英语。"
        }
    },
    {
        "translation": {
            "en": "Table B.1",
            "zh": "表B.1"
        }
    },
    {
        "translation": {
            "en": "This is because having a headache increases the probability of the patient having meningitis, which in turn increases the probability of the patient having a fever.",
            "zh": "这是因为头痛会增加患者患脑膜炎的概率，从而增加患者发烧的概率。"
        }
    },
    {
        "translation": {
            "en": "This uneven distribution of instances across bins can have dramatic and unwanted consequences for probability-based models.",
            "zh": "这种实例在 bin 中的不均匀分布可能会对基于概率的模型产生严重且不必要的后果。"
        }
    },
    {
        "translation": {
            "en": "Quinlan, J. Ross. 1993. C4.5: Programs for machine learning. Morgan Kaufmann.",
            "zh": "昆兰，J.罗斯。1993. C4.5：机器学习程序。摩根·考夫曼（Morgan Kaufmann）。"
        }
    },
    {
        "translation": {
            "en": "4.3.1 A Worked Example: Predicting Vegetation Distributions",
            "zh": "4.3.1 工作示例：预测植被分布"
        }
    },
    {
        "translation": {
            "en": "The following website:",
            "zh": "以下网站："
        }
    },
    {
        "translation": {
            "en": "The type of region the customer lives in",
            "zh": "客户居住的区域类型"
        }
    },
    {
        "translation": {
            "en": "4.4.3 Predicting Continuous Targets",
            "zh": "4.4.3 预测连续目标"
        }
    },
    {
        "translation": {
            "en": "(b) Measure the performance of this bagged ensemble using misclassification rate (misclassification rate is discussed in detail in Section 9.3[535]; it is simply the percentage of instances in the test dataset that a model has incorrectly classified).",
            "zh": "（b） 使用错误分类率（错误分类率在第 9.3[535] 节中详细讨论;它只是测试数据集中模型错误分类的实例的百分比）来衡量这个袋装集成的性能。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.6",
            "zh": "图 8.6"
        }
    },
    {
        "translation": {
            "en": "Figure 2.3",
            "zh": "图 2.3"
        }
    },
    {
        "translation": {
            "en": "When Jocelyn first arrived at SDSS, she was pleased to find that the business problem she was being asked to help with was already pretty well defined in predictive analytics terms.",
            "zh": "当 Jocelyn 第一次来到 SDSS 时，她很高兴地发现，她被要求帮助解决的业务问题已经在预测分析术语中得到了很好的定义。"
        }
    },
    {
        "translation": {
            "en": "2.10   A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.10 汽车保险欺诈预测分析分析解决方案的领域概念和相关功能的子集。"
        }
    },
    {
        "translation": {
            "en": "Scatter plots of three bivariate datasets with the same center point A and two queries B and C both equidistant from A; (a) a dataset uniformly spread around the center point; (b) a dataset with negative covariance; and (c) a dataset with positive covariance.",
            "zh": "具有相同中心点 A 的三个双变量数据集和两个查询 B 和 C 的散点图，它们都与 A 等距;（a） 均匀分布在中心点周围的数据集;（b） 具有负协方差的数据集;（c）具有正协方差的数据集。"
        }
    },
    {
        "translation": {
            "en": "This means that instances far away from the current set of centroids are much more likely to be selected than those close to already selected centroids.",
            "zh": "这意味着远离当前质心集的实例比靠近已选择质心的实例更有可能被选中。"
        }
    },
    {
        "translation": {
            "en": "Indeed, over 60% of the values for MARITAL STATUS are missing, so this feature should almost certainly be removed from the ABT (we return to this feature shortly).",
            "zh": "事实上，超过60%的婚姻状况值缺失，因此几乎可以肯定的是，这个功能应该从ABT中删除（我们很快就会回到这个功能）。"
        }
    },
    {
        "translation": {
            "en": "We describe these regions as saturated: in economics when a market becomes saturated with a product, the growth in the consumption of the product flattens out; by analogy, regions of curves that are flat are said to be saturated.",
            "zh": "我们将这些区域描述为饱和：在经济学中，当市场对产品饱和时，产品消费的增长趋于平缓;以此类推，平坦的曲线区域被称为饱和的。"
        }
    },
    {
        "translation": {
            "en": "This scenario is illustrated in Figures 3.14(a)[92] to 3.14(c)[92], which shows a continuous feature following a normal distribution converted into different numbers of bins using equal-width binning.",
            "zh": "图 3.14（a）[92] 至 3.14（c）[92] 说明了这种情况，图显示了使用等宽分箱转换为不同数量的箱数的正态分布后的连续特征。"
        }
    },
    {
        "translation": {
            "en": "(c) What value will the Bayesian network predict for WINE if:",
            "zh": "（c） 如果出现以下情况，贝叶斯网络将预测 WINE 的值："
        }
    },
    {
        "translation": {
            "en": "polynomial functions, 766",
            "zh": "多项式函数，766"
        }
    },
    {
        "translation": {
            "en": "The problem with setting k to a high value arises because the algorithm starts taking into account neighbors that are far away from the query instance in the feature space.",
            "zh": "将 k 设置为高值的问题出现，因为算法开始考虑远离特征空间中查询实例的邻居。"
        }
    },
    {
        "translation": {
            "en": "Data fragmentation is essentially an instance of the curse of dimensionality.",
            "zh": "数据碎片化本质上是维度诅咒的一个实例。"
        }
    },
    {
        "translation": {
            "en": "Grid worlds are an excellent environment in which to study reinforcement learning because, as we will see, it is easy to examine how the action-value table evolves over time.",
            "zh": "网格世界是研究强化学习的绝佳环境，因为正如我们将看到的，很容易检查动作-价值表如何随时间演变。"
        }
    },
    {
        "translation": {
            "en": "For example, the model makes a prediction of ham incorrectly 3 times out of the 9 times that the correct prediction should be spam (33.333% of the time), while it makes a prediction of spam incorrectly just 2 times out the 11 times that the correct prediction should be ham (18.182% of the time).",
            "zh": "例如，该模型在正确预测应该是垃圾邮件的 9 次中，有 3 次错误地预测了火腿（33.333% 的时间），而在正确预测应该是火腿的 11 次中，它只对垃圾邮件进行了 2 次错误预测（18.182% 的时间）。"
        }
    },
    {
        "translation": {
            "en": "Consequently, many books on neural networks cover the fundamentals of deep learning.",
            "zh": "因此，许多关于神经网络的书籍都涵盖了深度学习的基础知识。"
        }
    },
    {
        "translation": {
            "en": "First, the correlation measure given in Equation (3.4)[82] responds only to linear relationships between features.",
            "zh": "首先，等式（3.4）[82]中给出的相关性度量仅响应特征之间的线性关系。"
        }
    },
    {
        "translation": {
            "en": "The population variance of a feature is usually denoted by σ2.",
            "zh": "特征的总体方差通常用 σ2 表示。"
        }
    },
    {
        "translation": {
            "en": "We can generate the decision boundary by aggregating the neighboring local models (in this case, Voronoi regions) that make the same prediction.",
            "zh": "我们可以通过聚合做出相同预测的相邻局部模型（在本例中为 Voronoi 区域）来生成决策边界。"
        }
    },
    {
        "translation": {
            "en": "The algorithm begins by randomly selecting k cluster centroids, c1 to ck, where a cluster centroid is composed of a value for each descriptive feature present in a dataset (these initial cluster centroids are often referred to as seeds).",
            "zh": "该算法首先随机选择 k 个聚类质心（c1 到 ck），其中聚类质心由数据集中存在的每个描述性特征的值组成（这些初始聚类质心通常称为种子）。"
        }
    },
    {
        "translation": {
            "en": "PETRORAD_U/G/R/I/Z",
            "zh": "PETRORAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "If an ε-greedy behavior policy (or any other similar behavior policy that encourages exploration) is used, then occasionally random actions rather than the best action will be used in this step.",
            "zh": "如果使用ε贪婪行为策略（或任何其他鼓励探索的类似行为策略），则在此步骤中偶尔会使用随机操作而不是最佳操作。"
        }
    },
    {
        "translation": {
            "en": "d-separation, 289",
            "zh": "D-分离，289"
        }
    },
    {
        "translation": {
            "en": "Finally, Equation (8.113)[511] specifies how the cell state, post the forget gate, is updated by the input gate to generate the cell state for this time-step ct.",
            "zh": "最后，方程（8.113）[511]指定了输入门如何更新遗忘门后的单元状态，以生成该时间步长ct的单元状态。"
        }
    },
    {
        "translation": {
            "en": "Subsequent legislation has added to this list (for example, disability was later added as a further basis for non-discrimination).",
            "zh": "随后的立法也增加了这一清单（例如，后来又增加了残疾作为不歧视的进一步基础）。"
        }
    },
    {
        "translation": {
            "en": "We then explain some variations on the standard algorithm as well as how clustering can be evaluated and interpreted.",
            "zh": "然后，我们解释了标准算法的一些变化，以及如何评估和解释聚类。"
        }
    },
    {
        "translation": {
            "en": "So, in the move between Equations (7.13)[324] and (7.14)[324], becomes −d[j] (remember that in this equation, t is a constant and so becomes zero when differentiated).",
            "zh": "因此，在方程（7.13）[324]和（7.14）[324]之间的移动中，变为−d[j]（请记住，在这个方程中，t是一个常数，因此在微分时变为零）。"
        }
    },
    {
        "translation": {
            "en": "Decision tree models have a feature selection mechanism built into the algorithm and so are more robust to this issue.",
            "zh": "决策树模型在算法中内置了特征选择机制，因此对这个问题更可靠。"
        }
    },
    {
        "translation": {
            "en": "18. Any percentiles (see Section A.1[745]) can be used, but deciles are particularly common.",
            "zh": "18. 可以使用任何百分位数（见第A.1[745]节），但十分位数特别常见。"
        }
    },
    {
        "translation": {
            "en": "Both networks return the same probability for the joint event. In fact, these networks will return identical probabilities for all events in this domain.",
            "zh": "两个网络为联合事件返回相同的概率。事实上，这些网络将为该域中的所有事件返回相同的概率。"
        }
    },
    {
        "translation": {
            "en": "Tachycardia is a condition that causes the heart to beat faster than normal at rest.",
            "zh": "心动过速是一种导致心脏在休息时跳动比正常人快的疾病。"
        }
    },
    {
        "translation": {
            "en": "The AGE and RATING feature space for the whiskey dataset. The location of the query instance is indicated by the ? symbol. The circle plotted with a dashed line demarcates the border of the neighborhood around the query when k = 3. The three nearest neighbors to the query are labeled with their ID values.",
            "zh": "威士忌数据集的 AGE 和 RATING 特征空间。查询实例的位置由 ？象征。当 k = 3 时，用虚线绘制的圆圈划定了查询周围邻域的边界。查询的三个最近邻域标有其 ID 值。"
        }
    },
    {
        "translation": {
            "en": "So, even a small increase in k can have a significant impact on the decision boundary.",
            "zh": "因此，即使 k 的微小增加也会对决策边界产生重大影响。"
        }
    },
    {
        "translation": {
            "en": "PETRORATIO_R",
            "zh": "PETRORATIO_R"
        }
    },
    {
        "translation": {
            "en": "By looking at these five key families, we cover the most commonly used approaches to inductive machine learning that can be used to build most predictive data analytics solutions. The second part of the book concludes with Chapter 9[533], which describes a range of approaches to evaluating prediction models.",
            "zh": "通过研究这五个关键系列，我们涵盖了最常用的归纳机器学习方法，这些方法可用于构建大多数预测性数据分析解决方案。本书的第二部分以第9章[533]结束，该章描述了评估预测模型的一系列方法。"
        }
    },
    {
        "translation": {
            "en": "The activation memory buffer is not shown in this figure because the feedback loop of storing the hidden state activations from one time-step in the buffer and reading from the buffer at the next time-step is represented by the horizontal arrows between each ht layer.",
            "zh": "此图中未显示激活内存缓冲区，因为将一个时间步的隐藏状态激活存储在缓冲区中并在下一个时间步从缓冲区读取的反馈循环由每个 ht 层之间的水平箭头表示。"
        }
    },
    {
        "translation": {
            "en": "(b) Irregular cardinality",
            "zh": "（b） 不规则基数"
        }
    },
    {
        "translation": {
            "en": "The curved arrows in Figure 2.12[47] show the most common iterations in the process.",
            "zh": "图 2.12[47] 中的弯曲箭头显示了该过程中最常见的迭代。"
        }
    },
    {
        "translation": {
            "en": "33. Because of the way that they make a number of additions to a basic model, gradient boosting models can be considered an instance of a generic family of mathematical models known as additive models.",
            "zh": "33. 由于梯度提升模型对基本模型进行了大量补充，因此可以将其视为称为加法模型的通用数学模型系列的一个实例。"
        }
    },
    {
        "translation": {
            "en": "The cardinality of 2 for the FRAUD FLAG feature highlights the fact that this is not really a continuous feature.",
            "zh": "FRAUD FLAG 特征的基数为 2 突出了一个事实，即这并不是一个真正的连续特征。"
        }
    },
    {
        "translation": {
            "en": "The decision of which node to move to next is made by checking if any instances indexed by nodes in the subtree on the other branch of the current node could be the nearest neighbor.",
            "zh": "通过检查当前节点另一个分支上的子树中的节点索引的任何实例是否可以是最近的邻居来决定下一步移动到哪个节点。"
        }
    },
    {
        "translation": {
            "en": "SDSS, 703",
            "zh": "SDSS，703"
        }
    },
    {
        "translation": {
            "en": "There are L layers in this network and so there are L weight matrices, where W(i) represents the weight matrix for layer i.",
            "zh": "该网络中有 L 层，因此有 L 个权重矩阵，其中 W（i） 表示第 i 层的权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "The main decision to be made in this process is how to select the feature to split on.",
            "zh": "在此过程中要做出的主要决策是如何选择要拆分的功能。"
        }
    },
    {
        "translation": {
            "en": "(b)–(e) Visualizations of the prediction models trained in the early iterations of the gradient boosting process.",
            "zh": "（b）–（e） 在梯度提升过程的早期迭代中训练的预测模型的可视化。"
        }
    },
    {
        "translation": {
            "en": "scale parameter, 271",
            "zh": "刻度参数，271"
        }
    },
    {
        "translation": {
            "en": "This intuition is mirrored in the derivative of the function with respect to x.",
            "zh": "这种直觉反映在函数相对于 x 的导数中。"
        }
    },
    {
        "translation": {
            "en": "(a) Define the topology of a Bayesian network that encodes these causal relationships.",
            "zh": "（a） 定义编码这些因果关系的贝叶斯网络的拓扑结构。"
        }
    },
    {
        "translation": {
            "en": "0.2166",
            "zh": "0.2166"
        }
    },
    {
        "translation": {
            "en": "This leaves us with the tasks of calculating the best threshold on which to split the ELEVATION feature, and calculating the information gain when we partition the dataset with ELEVATION using this optimal threshold.",
            "zh": "这给我们留下了计算拆分 ELEVATION 特征的最佳阈值的任务，以及使用此最佳阈值使用 ELEVATION 对数据集进行分区时计算信息增益。"
        }
    },
    {
        "translation": {
            "en": "Cambridge, Massachusetts",
            "zh": "马萨诸塞州剑桥市"
        }
    },
    {
        "translation": {
            "en": "where var(ZHL1) denotes the shared scalar variance of all the z values across the neurons in layer HL1; ninHL1 is the number of inputs coming into each neuron in layer HL1; var(W(HL1)) denotes the shared scalar variance of all the weights across the neurons in layer HL1; and var(d(HL1) denotes the shared scalar variance of all the inputs to layer HL1.",
            "zh": "其中 var（ZHL1） 表示 HL1 层神经元中所有 z 值的共享标量方差;ninHL1 是进入 HL1 层中每个神经元的输入数量;var（W（HL1）） 表示 HL1 层中神经元上所有权重的共享标量方差;var（d（HL1） 表示层 HL1 的所有输入的共享标量方差。"
        }
    },
    {
        "translation": {
            "en": "Support vector machines and the other classification models described in Chapter 7[311] are examples of discriminative prediction models.",
            "zh": "支持向量机和第7章[311]中描述的其他分类模型是判别预测模型的示例。"
        }
    },
    {
        "translation": {
            "en": "cost function, 409",
            "zh": "成本函数，409"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) for the candidate ELEVATION thresholds: ≥750, ≥1,350, ≥2,250 and ≥4,175.",
            "zh": "候选 ELEVATION 阈值的分区集 （Part.）、熵、余数 （Rem.） 和信息增益 （Info. Gain）：≥750、≥1,350、≥2,250 和 ≥4,175。"
        }
    },
    {
        "translation": {
            "en": "491.35",
            "zh": "491.35"
        }
    },
    {
        "translation": {
            "en": "Examples of the different galaxy morphology categories into which SDSS scientists categorize galaxy objects. Credits for these images belong to the Sloan Digital Sky Survey, www.sdss3.org.",
            "zh": "SDSS科学家将星系天体分类为不同星系形态类别的例子。这些图像的版权归斯隆数字巡天 www.sdss3.org 所有。"
        }
    },
    {
        "translation": {
            "en": "Dalgaard, Peter. 2008. Introductory statistics with R. Springer.",
            "zh": "达尔加德，彼得。2008. R. Springer 的介绍性统计。"
        }
    },
    {
        "translation": {
            "en": "galaxy morphology, 704",
            "zh": "星系形态学，704"
        }
    },
    {
        "translation": {
            "en": "The three smaller histograms depart from this distribution and suggest that centers tend to be taller than forwards, who in turn tend to be taller than guards.",
            "zh": "三个较小的直方图偏离了这个分布，表明中锋往往比前锋高，而前锋又往往比后卫高。"
        }
    },
    {
        "translation": {
            "en": "0.38",
            "zh": "0.38"
        }
    },
    {
        "translation": {
            "en": "Data visualization is a mix of statistics, graphic design, art, and psychology. Chang (2012) and Fry (2007) both provide great detail on visualization in general and the R language in particular (the visualizations in this book are almost all generated in R). For more conceptual discussions of data visualization, Tufte (2001) and Bertin (2010) are important works in the field.",
            "zh": "数据可视化是统计学、平面设计、艺术和心理学的混合体。Chang （2012） 和 Fry （2007） 都提供了关于可视化的细节，特别是 R 语言（本书中的可视化几乎都是用 R 语言生成的）。对于数据可视化的更多概念性讨论，Tufte （2001） 和 Bertin （2010） 是该领域的重要著作。"
        }
    },
    {
        "translation": {
            "en": "In all these tasks, the absence of a target feature makes determining what descriptive features are likely to be useful in an ABT and evaluating the performance of a proposed solution a little more challenging.",
            "zh": "在所有这些任务中，由于缺少目标特征，因此确定哪些描述性特征可能在 ABT 中有用，并评估所建议解决方案的性能更具挑战性。"
        }
    },
    {
        "translation": {
            "en": "8.4   Extensions and Variations",
            "zh": "8.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "4. Triangular Inequality: metric(a,b) ≤ metric(a,c) + metric(b,c)",
            "zh": "4. 三角不等式：metric（a，b） ≤ metric（a，c） + metric（b，c）"
        }
    },
    {
        "translation": {
            "en": "An affine function is composed of a linear function followed by a translation; this simply means that the mapping defined by an affine function from inputs to outputs is linear but the plot of this mapping does not necessarily pass through the origin.",
            "zh": "仿射函数由线性函数后跟平移组成;这仅仅意味着仿射函数定义的从输入到输出的映射是线性的，但此映射的绘图不一定通过原点。"
        }
    },
    {
        "translation": {
            "en": "A feature space plot of the data in Table 5.2[183], with the position in the feature space of the query represented by the ? marker.",
            "zh": "表5.2[183]中数据的特征空间图，查询在特征空间中的位置用 ？标记。"
        }
    },
    {
        "translation": {
            "en": "This first convolutional layer contains two layers of 6 neurons.",
            "zh": "第一卷积层包含两层 6 个神经元。"
        }
    },
    {
        "translation": {
            "en": "artificial intelligence, 304, 677",
            "zh": "人工智能， 304， 677"
        }
    },
    {
        "translation": {
            "en": "Imputation techniques tend to give good results and avoid the data loss associated with deleting features or complete case analysis. It is important to note, however, that all imputation techniques suffer from the fact that they change the underlying data in an ABT and can cause the variation within a feature to be underestimated, which can negatively bias the relationships between a descriptive feature and a target feature.",
            "zh": "插补技术往往会给出良好的结果，并避免与删除特征或完整的案例分析相关的数据丢失。然而，需要注意的是，所有插补技术都受到以下事实的影响：它们会改变 ABT 中的基础数据，并可能导致特征内的变化被低估，这可能会对描述性特征和目标特征之间的关系产生负面影响。"
        }
    },
    {
        "translation": {
            "en": "A series of charts for different model performance on the same large email classification test set used to generate the ROC curves in Figure 9.12(b)[562]. Each column from top to bottom: a histogram of the ham scores predicted by the model, a histogram of the spam scores predicted by the model, and the K-S chart.",
            "zh": "图9.12（b）中用于生成ROC曲线的同一大型电子邮件分类测试集上不同模型性能的一系列图表[562]。每列从上到下：模型预测的火腿分数的直方图、模型预测的垃圾邮件分数的直方图以及 K-S 控制图。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS and NUM.",
            "zh": "CLAIMS 和 NUM."
        }
    },
    {
        "translation": {
            "en": "(a) The feature space defined by the SALARY and AGE features in Table 5.5[204]; and (b) the normalized SALARY and AGE feature space based on the normalized data in Table 5.7[208]. The instances are labeled with their IDs; triangles represent instances with the no target level; and crosses represent instances with the yes target level. The location of the query SALARY = 56,000, AGE = 35 is indicated by the ?.",
            "zh": "（a） 表5.5[204]中SALARY 和 AGE 特征定义的特征空间;（b）基于表5.7[208]中归一化数据的归一化SALAW和AGE特征空间。实例标有其 ID;三角形表示具有无目标级别的实例;叉表示具有 yes 目标级别的实例。查询的位置 SALARY = 56,000， AGE = 35 由 ？."
        }
    },
    {
        "translation": {
            "en": "true positive rate, 548, 549, 558",
            "zh": "真阳性率，548、549、558"
        }
    },
    {
        "translation": {
            "en": "If this is the case, then the algorithm has reached the parent node of the root of the tree and should terminate (Line 4) by returning the instance stored in best (Line 12).",
            "zh": "如果是这种情况，则算法已到达树根的父节点，并且应通过返回存储在 best（第 12 行）中的实例来终止（第 4 行）。"
        }
    },
    {
        "translation": {
            "en": "Typically, the offer was a reduced call rate for the next three months, although retention team members had the freedom to make other offers.",
            "zh": "通常，该提议是在接下来的三个月内降低呼叫费率，尽管保留团队成员可以自由提出其他提议。"
        }
    },
    {
        "translation": {
            "en": "2.2   The ABT for the motor insurance claims fraud detection solution.",
            "zh": "2.2 用于汽车保险索赔欺诈检测解决方案的 ABT。"
        }
    },
    {
        "translation": {
            "en": "13.4.2 Feature Selection",
            "zh": "13.4.2 功能选择"
        }
    },
    {
        "translation": {
            "en": "CMODELMAG_U/G/R/I/Z",
            "zh": "CMODELMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It is usual in k-means clustering for Dist to calculate Euclidean distance.2 As discussed in Section 5.4.3[204] in relation to similarity models for predictive modeling, it is important that all descriptive features are normalized before using k-means clustering so that distance contributions across features are comparable.",
            "zh": "2 正如第 5.4.3 节[204]中关于预测建模的相似性模型所讨论的，在使用 k-means 聚类之前，必须对所有描述性特征进行归一化，以便特征之间的距离贡献具有可比性。"
        }
    },
    {
        "translation": {
            "en": "regression task, 149",
            "zh": "回归任务，149"
        }
    },
    {
        "translation": {
            "en": "8.35   Schematic of the typical sequences of layers found in a convolutional neural network.",
            "zh": "8.35 卷积神经网络中典型层序列的示意图。"
        }
    },
    {
        "translation": {
            "en": "In this scenario, then will be relatively close to 1 (and the better the model’s prediction the closer to one will be).",
            "zh": "在这种情况下，则相对接近 1（模型的预测越好，就越接近 1）。"
        }
    },
    {
        "translation": {
            "en": "These low cardinalities were investigated with the business.",
            "zh": "这些低基数与企业一起进行了调查。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.23)[412] illustrates how the term ∂ℰ/∂a k is calculated for a hidden neuron and how this term is then used to calculate the δ for a hidden neuron by multiplying it by the term ∂ak/∂zk (which, as previously described, is calculated by plugging the zk into the derivative of the activation function).",
            "zh": "方程（8.23）[412]说明了如何计算隐藏神经元的项∂E/∂a k，以及如何使用该项通过将其乘以项∂ak/∂zk（如前所述，通过将zk代入激活函数的导数来计算）来计算隐藏神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "We do not derive the derivatives of the softmax for each of these cases, as that is relatively convoluted, involving in quotient rule from calculus; instead, we simply state them",
            "zh": "对于每种情况，我们都没有推导出软最大值的导数，因为这相对复杂，涉及微积分的商规则;相反，我们只是简单地陈述它们"
        }
    },
    {
        "translation": {
            "en": "complete linkage, 619",
            "zh": "完全联动，619"
        }
    },
    {
        "translation": {
            "en": "The reason why this difference is considered a rate of change is that the larger the difference between ak and tk, the faster the error of the network can be changed by changing the activation. However, the direction of the calculated gradient is toward the highest value on the error surface, and therefore to move down the error surface we should multiply it by − 1.11 Hence, using the sum of squared errors error function, the error gradient for a single output neuron k on a single example is",
            "zh": "之所以将这种差异视为变化率，是因为 ak 和 tk 之间的差异越大，通过更改激活可以更快地改变网络的误差。然而，计算出的梯度的方向朝向误差曲面上的最高值，因此要向下移动误差曲面，我们应该将其乘以 − 1.11 因此，使用误差误差函数的平方和，单个示例上单个输出神经元 k 的误差梯度为"
        }
    },
    {
        "translation": {
            "en": "The Claimant History domain concept that we developed for this scenario indicates the importance of information regarding the previous claims made by the claimant to the task of identifying fraudulent claims.",
            "zh": "我们为此方案开发的“索赔人历史记录”域概念表明，有关索赔人先前提出的索赔的信息对于识别欺诈性索赔的任务非常重要。"
        }
    },
    {
        "translation": {
            "en": "14. For further details, see www.ibm.com/software/ie/analytics/spss, www.knime.org, www.rapidminer.com, www.sas.com, and www.cs.waikato.ac.nz/ml/weka.",
            "zh": "14. 有关详细信息，请参阅 www.ibm.com/software/ie/analytics/spss、www.knime.org、www.rapidminer.com、www.sas.com 和 www.cs.waikato.ac.nz/ml/weka。"
        }
    },
    {
        "translation": {
            "en": "However, if we already know that the patient has meningitis, then also knowing that the patient has a headache will not affect the probability of the patient having a fever.",
            "zh": "但是，如果我们已经知道患者患有脑膜炎，那么也知道患者头痛不会影响患者发烧的概率。"
        }
    },
    {
        "translation": {
            "en": "The Q-learning algorithm discussed in Section 11.3[657] is referred to as off-policy as the behavior policy is not used to select the action to be taken in the next state when Q values are updated (a greedy target policy is used instead).",
            "zh": "第 11.3 节[657] 中讨论的 Q 学习算法称为 off-policy，因为当 Q 值更新时，行为策略不用于选择在下一个状态下要执行的操作（而是使用贪婪目标策略）。"
        }
    },
    {
        "translation": {
            "en": "Table 5.12[214] presents a pairwise analysis of similarity between the current trial user, q, and the two customers in the dataset in Table 5.11[213] in terms of",
            "zh": "表5.12[214]对当前试验用户q与表5.11[213]中数据集中的两个客户之间的相似性进行了成对分析，包括："
        }
    },
    {
        "translation": {
            "en": "Algorithm 6[474] lists the early stopping algorithm.",
            "zh": "算法6[474]列出了早期停止算法。"
        }
    },
    {
        "translation": {
            "en": "420.26MW",
            "zh": "420.26兆瓦"
        }
    },
    {
        "translation": {
            "en": "2.7   Exercises",
            "zh": "2.7 练习"
        }
    },
    {
        "translation": {
            "en": "This shows that the clustering with three clusters has the highest silhouette score and could be chosen as the most appropriate clustering given the assumptions that underlie the silhouette.",
            "zh": "这表明具有三个聚类的聚类具有最高的轮廓得分，并且可以根据轮廓基础的假设选择为最合适的聚类。"
        }
    },
    {
        "translation": {
            "en": "An easy way to address this issue is to perform multiple runs of the k-means clustering algorithm starting from different initial centroids and then aggregate the results.",
            "zh": "解决此问题的一种简单方法是从不同的初始质心开始多次运行 k 均值聚类算法，然后聚合结果。"
        }
    },
    {
        "translation": {
            "en": "We will look at application-based solutions first.",
            "zh": "我们将首先研究基于应用程序的解决方案。"
        }
    },
    {
        "translation": {
            "en": "The concept of a probability distribution also applies to joint probabilities, which gives us the concept of a joint probability distribution.",
            "zh": "概率分布的概念也适用于联合概率，这给了我们联合概率分布的概念。"
        }
    },
    {
        "translation": {
            "en": "IQR, 749",
            "zh": "四分线，749"
        }
    },
    {
        "translation": {
            "en": "patience, 473",
            "zh": "耐心，473"
        }
    },
    {
        "translation": {
            "en": "Second, Jocelyn calculated an inter-annotator agreement statistic for the manual classifications given by the five SDSS scientists.",
            "zh": "其次，Jocelyn 计算了五位 SDSS 科学家给出的手动分类的注释者间一致性统计量。"
        }
    },
    {
        "translation": {
            "en": "7.2 Fundamentals",
            "zh": "7.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "Also, there are no gaps between the histogram bars, which indicates that there are no empty bins.",
            "zh": "此外，直方图条之间没有间隙，这表明没有空箱。"
        }
    },
    {
        "translation": {
            "en": "The old approach of doing all this manually has become obsolete because the volume of data involved is just too large.",
            "zh": "手动完成所有这些操作的旧方法已经过时，因为涉及的数据量太大。"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors error function, L2, is formally defined as",
            "zh": "误差误差函数的平方和误差函数 L2 被正式定义为"
        }
    },
    {
        "translation": {
            "en": "Note that φsm(li) can be understood as equivalent to φsm(zi) in Equation (8.65)[463 the notational differences arise because we are now specifying the parameter as an index of a logit rather than specifying the z score directly.",
            "zh": "请注意，φsm（li）可以理解为等价于等式（8.65）[463中的φsm（zi）[463，之所以出现符号差异，是因为我们现在将参数指定为logit的索引，而不是直接指定z分数。"
        }
    },
    {
        "translation": {
            "en": "8.2.4 Why Are Non-Linear Activation Functions Necessary?",
            "zh": "8.2.4 为什么需要非线性激活函数？"
        }
    },
    {
        "translation": {
            "en": "average class accuracy, 550, 551, 554, 577, 586, 591, 698",
            "zh": "平均等级精度，550、551、554、577、586、591、698"
        }
    },
    {
        "translation": {
            "en": "decoder, 624",
            "zh": "解码器，624"
        }
    },
    {
        "translation": {
            "en": "However, rather than training these models to perform the original prediction task—to predict the target feature t based on the descriptive features d—these models are trained to predict the errors that the previous model is likely to have made.32 In this way the newly trained models are directly trying to correct, and therefore improve, the predictions made by the models previously added to the ensemble.",
            "zh": "然而，这些模型不是训练这些模型来执行原始的预测任务——根据描述性特征 d 预测目标特征 t——而是训练这些模型来预测先前模型可能犯的错误.32 以这种方式，新训练的模型直接尝试纠正，从而改进， 先前添加到集合中的模型所做的预测。"
        }
    },
    {
        "translation": {
            "en": "We note these types of data quality issues during exploration for potential handling when we reach the Modeling phase of a project.",
            "zh": "当我们到达项目的建模阶段时，我们会在探索潜在处理过程中注意到这些类型的数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "The standard reinforcement learning approach, Q-learning, a form of temporal-difference learning, is then described.",
            "zh": "然后描述了标准的强化学习方法，即Q-learning，一种时间差异学习形式。"
        }
    },
    {
        "translation": {
            "en": "For each proposed solution, the following points should be described: (1) the predictive model that will be built; (2) how the predictive model will be used by the business; and (3) how using the predictive model will help address the original business problem.",
            "zh": "对于每个提出的解决方案，应描述以下几点：（1）将要构建的预测模型;（2）企业如何使用预测模型;（3）使用预测模型将如何帮助解决原始业务问题。"
        }
    },
    {
        "translation": {
            "en": "peeking, 536",
            "zh": "偷看，536"
        }
    },
    {
        "translation": {
            "en": "If we were processing RGB images, then we would use three-dimensional filters: height by width by channel.",
            "zh": "如果我们要处理RGB图像，那么我们将使用三维滤镜：高度和宽度，通道。"
        }
    },
    {
        "translation": {
            "en": "This distance from the decision boundary to the nearest training instance is known as the margin.",
            "zh": "从决策边界到最近的训练实例的距离称为边际。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.11",
            "zh": "图 2.11"
        }
    },
    {
        "translation": {
            "en": "11. A hyperplane is a geometric concept that generalizes the idea of a plane into different dimensions. For example, a hyperplane in 2D space is a line and in a 3D space is a plane.",
            "zh": "11. 超平面是一个几何概念，它将平面的概念推广到不同的维度。例如，2D 空间中的超平面是一条线，而 3D 空间中的超平面是平面。"
        }
    },
    {
        "translation": {
            "en": "The rate of change of the network error with respect to changes in a weight is written mathematically as ∂ℰ/∂wi,k for the weight on the connection from neuron k to neuron i. Using the chain rule12 we can rewrite this term as a product of three terms",
            "zh": "网络误差相对于权重变化的变化率在数学上写为 ∂E/∂wi，k，表示从神经元 k 到神经元 i 的连接上的权重。使用链式法则12，我们可以将该术语重写为三个术语的乘积"
        }
    },
    {
        "translation": {
            "en": "The algorithm really is very simple, so we can move straight to looking at a worked example of it in action.",
            "zh": "该算法非常简单，因此我们可以直接查看它的实际操作示例。"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor model is now factoring both SALARY and AGE into the ranking of the instances.",
            "zh": "最近邻模型现在将 SALARY 和 AGE 都考虑在实例的排名中。"
        }
    },
    {
        "translation": {
            "en": "Frequently, when bagging is used with decision trees, the sampling process is extended so that each bootstrap sample uses only a randomly selected subset of the descriptive features in the dataset.",
            "zh": "通常，当将装袋与决策树一起使用时，采样过程会扩展，以便每个引导样本仅使用数据集中随机选择的描述性特征子集。"
        }
    },
    {
        "translation": {
            "en": "cumulative lift, 567, 570, 700",
            "zh": "累计扬程， 567， 570， 700"
        }
    },
    {
        "translation": {
            "en": "1. Forward Pass An input pattern is presented to the network, and the activations flow forward through the network until an output is generated.",
            "zh": "1. 前向传递 输入模式呈现给网络，激活在网络中向前流动，直到生成输出。"
        }
    },
    {
        "translation": {
            "en": "Cohen, Jacob. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement 20 (1): 34–46.",
            "zh": "科恩，雅各布。1960. 标称尺度的一致性系数。教育和心理测量20（1）：34-46。"
        }
    },
    {
        "translation": {
            "en": "We can see in this structure that the target feature, FRAUD, has no parents and is the single parent for all the descriptive feature nodes.",
            "zh": "在这个结构中，我们可以看到目标特征 FRAUD 没有父级，并且是所有描述性特征节点的单父级。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.9",
            "zh": "图 5.9"
        }
    },
    {
        "translation": {
            "en": "You should notice, however, that, in general, the larger the sample, the smaller the margin of error.",
            "zh": "但是，您应该注意到，一般来说，样本越大，误差范围越小。"
        }
    },
    {
        "translation": {
            "en": "There is, however, a challenge here, as usually, there are a large number of descriptive features for which measures need to be calculated and tracked.",
            "zh": "然而，这里有一个挑战，像往常一样，有大量的描述性特征需要计算和跟踪度量。"
        }
    },
    {
        "translation": {
            "en": "To restate Equation (11.9)[643] in terms of the components of an MDP, we modify Equation (11.9)[643] to sum to infinity rather than just the end of an episode,12 and we state the equation a little more succinctly",
            "zh": "为了根据 MDP 的组成部分重述等式 （11.9）[643]，我们将等式 （11.9）[643] 修改为求和为无穷大，而不仅仅是一集的结尾，12 并且我们更简洁地陈述了等式"
        }
    },
    {
        "translation": {
            "en": "HEALTHINS: Whether the customer holds a health insurance policy with the company (yes or no)",
            "zh": "HEALTHINS：客户是否持有公司的健康保险单（是或否）"
        }
    },
    {
        "translation": {
            "en": "3. The table below shows a sample of a larger dataset containing details of policyholders at an insurance company. The descriptive features included in the table describe each policy holders’ ID, occupation, gender, age, the value of their car, the type of insurance policy they hold, and their preferred contact channel.",
            "zh": "3. 下表显示了一个更大的数据集的样本，其中包含保险公司投保人的详细信息。表中包含的描述性特征描述了每个投保人的 ID、职业、性别、年龄、他们的汽车价值、他们持有的保险单类型以及他们首选的联系渠道。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that the model assumes that all the descriptive features are conditionally independent of each other given the value of the target feature.",
            "zh": "这样做的原因是，模型假设所有描述性特征在给定目标特征的值时都是有条件地相互独立的。"
        }
    },
    {
        "translation": {
            "en": "In this case, Jocelyn addressed the target level imbalance problem by using under-sampling to generate a new training dataset in which all three target levels had an equal distribution.",
            "zh": "在本例中，Jocelyn 通过使用欠采样来生成一个新的训练数据集，其中所有三个目标水平的分布相等，从而解决了目标水平不平衡问题。"
        }
    },
    {
        "translation": {
            "en": "We might be tempted to think that having multiple models that are consistent with the data is a good thing.",
            "zh": "我们可能会认为拥有多个与数据一致的模型是一件好事。"
        }
    },
    {
        "translation": {
            "en": "edges: nodes are connected by directed links; the connectivity of the links in a graph encodes the influence and conditional independence relationships between nodes.",
            "zh": "边：节点通过有向链接连接;图中链接的连通性对节点之间的影响和条件独立性关系进行编码。"
        }
    },
    {
        "translation": {
            "en": "Understanding that we are dealing with shared weights is important because the standard process for updating a shared weight is (a) to calculate the weight update for the weight at each location in the network where it is used; (b) to sum these weight updates together; and (c) finally to update the weight once using this summed weight update.",
            "zh": "了解我们正在处理共享权重很重要，因为更新共享权重的标准过程是 （a） 计算网络中使用权重的每个位置的权重更新;（b） 将这些重量更新相加;（c）最后使用此总重更新更新一次权重。"
        }
    },
    {
        "translation": {
            "en": "Therefore, the lift at each decile dec is the percentage of spam instances in that decile divided by 0.45.",
            "zh": "因此，每个十分位数的提升是该十分位数中垃圾邮件实例的百分比除以 0.45。"
        }
    },
    {
        "translation": {
            "en": "For example, range normalization using the range [0,1] is applied to instance d1 from Table 5.5[204] as follows:",
            "zh": "例如，使用范围 [0,1] 的范围归一化应用于表 5.5[204] 中的实例 d1，如下所示："
        }
    },
    {
        "translation": {
            "en": "(a)–(h) Different clusterings (all with k = 3) that can be found for the mobile phone customer dataset given in Table 10.1[604] when different initial cluster centroids are used.",
            "zh": "（a）–（h） 当使用不同的初始聚类质心时，可以在表 10.1[604] 中给出的移动电话客户数据集中找到不同的聚类（均为 k = 3）。"
        }
    },
    {
        "translation": {
            "en": "connectionism, 382",
            "zh": "联结主义，382"
        }
    },
    {
        "translation": {
            "en": "The idea that human mental phenomena emerge through the interconnections between neurons became known as connectionism.",
            "zh": "人类心理现象通过神经元之间的相互连接而出现的想法被称为联结主义。"
        }
    },
    {
        "translation": {
            "en": "The path through the decision tree for this query instance is shown in Figure 4.4(c)[122].",
            "zh": "图 4.4（c）[122] 显示了此查询实例的决策树路径。"
        }
    },
    {
        "translation": {
            "en": "purpose specification principle, 41",
            "zh": "目的规范原则，41"
        }
    },
    {
        "translation": {
            "en": "The model predicts a correction value of − 460.9 for input temperatures less than or equal to 9.5 degrees, and a correction value of 691.4 for temperatures above this threshold.",
            "zh": "该模型预测，当输入温度小于或等于 9.5 度时，校正值为 − 460.9，对于高于此阈值的温度，校正值为 691.4。"
        }
    },
    {
        "translation": {
            "en": "As a result of these considerations, feature design and implementation is an iterative process in which data exploration informs the design and implementation of features, which in turn inform further data exploration, and so on.",
            "zh": "由于这些考虑因素，功能设计和实现是一个迭代过程，在这个过程中，数据探索为功能的设计和实现提供信息，而功能和实现又为进一步的数据探索提供信息，依此类推。"
        }
    },
    {
        "translation": {
            "en": "8.14   The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "8.14 表8.3[423]所列示例通过图8.4[390]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "Gradient boosting can be said to do this in a more aggressive way than the boosting algorithm described previously.",
            "zh": "可以说梯度提升以比前面描述的提升算法更激进的方式做到这一点。"
        }
    },
    {
        "translation": {
            "en": "This normal distribution is known as the standard normal distribution.",
            "zh": "这种正态分布称为标准正态分布。"
        }
    },
    {
        "translation": {
            "en": "The values in this matrix are based on historical data that the company has on loans given out in the past.",
            "zh": "此矩阵中的值基于公司过去发放的贷款的历史数据。"
        }
    },
    {
        "translation": {
            "en": "Decision tree model ensembles based on bagging and boosting are also discriminative models.",
            "zh": "基于bagging和boosting的决策树模型集合也是判别模型。"
        }
    },
    {
        "translation": {
            "en": "Using variance as our measure of impurity, we can select which feature to split on at a node by selecting the feature that minimizes the weighted variance across the resulting partitions.",
            "zh": "使用方差作为杂质的度量，我们可以通过选择最小化结果分区中加权方差的特征来选择要在节点上拆分的特征。"
        }
    },
    {
        "translation": {
            "en": "Burges, Christopher J. C. 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery 2 (2): 121–167.",
            "zh": "伯吉斯，克里斯托弗 JC 1998 年。关于模式识别的支持向量机的教程。数据挖掘与知识发现 2 （2）：121–167。"
        }
    },
    {
        "translation": {
            "en": "First, he decided to delete the AGE and OCCUPATION features because of the level of missing values in each of these features.",
            "zh": "首先，他决定删除 AGE 和 OCCUPATION 要素，因为每个要素的缺失值级别。"
        }
    },
    {
        "translation": {
            "en": "Table 5.4",
            "zh": "表 5.4"
        }
    },
    {
        "translation": {
            "en": "The other two partitions created by splitting 8 are pure with respect to the target feature: 17 contains one instance with a conifer target level, and 19 contains two instances that both have a chapparal target level.",
            "zh": "通过拆分 8 创建的另外两个分区相对于目标特征是纯的：17 包含一个具有针叶树目标级别的实例，19 包含两个实例，这两个实例都具有 chapparal 目标级别。"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Probabilities",
            "zh": "概率的符号约定"
        }
    },
    {
        "translation": {
            "en": "Stoughton, Chris, Robert H. Lupton, Mariangela Bernardi, Michael R. Blanton, Scott Burles, Francisco J. Castander, A. J. Connolly, Daniel J. Eisenstein, Joshua A. Frieman, G. S. Hennessy, et al.. 2002. Sloan digital sky survey: Early data release. The Astronomical Journal 123 (1): 485. http://stacks.iop.org/1538-3881/123/i=1/a=485.",
            "zh": "斯托顿、克里斯、罗伯特·卢普顿、玛丽安吉拉·伯纳迪、迈克尔·布兰顿、斯科特·伯尔斯、弗朗西斯科·卡斯坦德、AJ 康诺利、丹尼尔·爱森斯坦、约书亚·弗里曼、GS 轩尼诗等。2002. 斯隆数字巡天：早期数据发布。天文学杂志123（1）：485。http://stacks.iop.org/1538-3881/123/i=1/a=485。"
        }
    },
    {
        "translation": {
            "en": "For example, if the patience parameter is set to 10 and we test the model on the validation set after every iteration, then we would allow training to continue until we observe 10 successive validation errors higher than the lowest recorded so far at which point our patience would run out and we stop training.",
            "zh": "例如，如果耐心参数设置为 10，并且我们在每次迭代后在验证集上测试模型，那么我们将允许训练继续进行，直到我们观察到 10 个连续的验证错误高于迄今为止记录的最低错误，此时我们的耐心将耗尽并停止训练。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.11",
            "zh": "图 5.11"
        }
    },
    {
        "translation": {
            "en": "outlier detection, 235",
            "zh": "异常值检测，235"
        }
    },
    {
        "translation": {
            "en": "Every analytics solution will have its own set of data requirements, and it is useful, as early as possible, to determine if the business has sufficient data available to meet these requirements.",
            "zh": "每个分析解决方案都有自己的一组数据要求，尽早确定企业是否有足够的可用数据来满足这些要求是很有用的。"
        }
    },
    {
        "translation": {
            "en": "8.11   The ∂a/∂z for each neuron for d2 rounded to four decimal places.",
            "zh": "8.11 d2 中每个神经元的 ∂a/∂z 四舍五入到小数点后四位。"
        }
    },
    {
        "translation": {
            "en": "Using the δ values you calculated above, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., ∂ℰ/∂w6,4, ∂ℰ/∂w6,3, ∂ℰ/∂w6,0, ∂ℰ/∂w5,4, ∂ℰ/∂w5,3, ∂ℰ/∂w5,0, ∂ℰ/∂w4,2, ∂ℰ/∂w4,1,",
            "zh": "使用上面计算的δ值，计算网络误差对网络每个权重变化的敏感度（即 ∂E/∂w6,4、∂E/∂w6,3、∂E/∂w6,0、∂E/∂w5,4、∂E/∂w5,3、∂E/∂w5,0、∂E/∂w4,2、∂E/∂w4,1、"
        }
    },
    {
        "translation": {
            "en": "4.4.3   Predicting Continuous Targets",
            "zh": "4.4.3 预测连续目标"
        }
    },
    {
        "translation": {
            "en": "Mahalunkar, Abhijit, and John D Kelleher. 2018. Using regular languages to explore the representational capacity of recurrent neural architectures. In International conference on artificial neural networks, 189–198. Springer.",
            "zh": "Mahalunkar、Abhijit 和 John D Kelleher。2018. 使用常规语言探索递归神经架构的表征能力.在人工神经网络国际会议上，189-198。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "The reason is that a max function allows through only the maximum value from its inputs, and so the non-max values did not affect the output (and hence the error) of the network.",
            "zh": "原因是 max 函数只允许通过其输入的最大值，因此非 max 值不会影响网络的输出（因此也会影响误差）。"
        }
    },
    {
        "translation": {
            "en": "It should be clear that this is a much simpler tree than the previous one.",
            "zh": "应该清楚的是，这是一棵比前一棵简单得多的树。"
        }
    },
    {
        "translation": {
            "en": "Feature selection approaches that search through subsets of features (known as wrapper approaches) are better at removing redundant features than rank and prune approaches because they consider groups of features together.",
            "zh": "搜索特征子集的特征选择方法（称为包装方法）比排名和修剪方法更能去除冗余特征，因为它们将特征组放在一起考虑。"
        }
    },
    {
        "translation": {
            "en": "cumulative gain, 567, 567, 594, 700",
            "zh": "累计增益， 567， 567， 594， 700"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes are particularly useful for formalizing this structure and provide the scaffolding for reasoning about reinforcement learning problems.",
            "zh": "马尔可夫决策过程对于形式化这种结构特别有用，并为推理强化学习问题提供了脚手架。"
        }
    },
    {
        "translation": {
            "en": "As is so often the case in predictive analytics, making the right choice requires an understanding of the requirements of the task that we are trying to accomplish and matching these requirements with the features we want to emphasize in our model.",
            "zh": "正如预测分析中经常出现的情况一样，做出正确的选择需要了解我们试图完成的任务的要求，并将这些要求与我们想要在模型中强调的特征相匹配。"
        }
    },
    {
        "translation": {
            "en": "i. Mode and 2nd mode",
            "zh": "i. 模式和第二模式"
        }
    },
    {
        "translation": {
            "en": "dying ReLU, 444",
            "zh": "垂死的 ReLU，444"
        }
    },
    {
        "translation": {
            "en": "The table below lists a sample of properties that have recently been sold for rental in the city.",
            "zh": "下表列出了最近在该市出售出租的房产示例。"
        }
    },
    {
        "translation": {
            "en": "There are also specific measures that are often used for this, for example normalized mutual information (NMI), which is based on information-theoretic ideas including entropy, as discussed in Chapter 4[117 however, these are outside the scope of this chapter.",
            "zh": "此外，还经常使用一些特定的措施，例如规范化互信息（NMI），它基于包括熵在内的信息理论思想，如第4章所述[117，但这些都超出了本章的范围。"
        }
    },
    {
        "translation": {
            "en": "where ϕ0, ϕ1, and ϕ2 are as described before. This model captures the non-linear relationship in the data very well but was still easy to train using a gradient descent approach. Basis functions can also be used for multivariable simple linear regression models in the same way, the only extra requirement being the definition of more basis functions.",
            "zh": "其中 φ0、φ1 和 φ2 如前所述。该模型很好地捕获了数据中的非线性关系，但仍然很容易使用梯度下降方法进行训练。基函数也可以以同样的方式用于多变量简单线性回归模型，唯一的额外要求是定义更多的基函数。"
        }
    },
    {
        "translation": {
            "en": "Just as we saw in Figure 5.3[188], this shows that the nearest neighbor to the query is instance d18, with a distance of 1.2749 and a target level of yes.",
            "zh": "正如我们在图 5.3[188] 中看到的，这表明与查询最近的邻居是实例 d18，距离为 1.2749，目标级别为 yes。"
        }
    },
    {
        "translation": {
            "en": "Indeed, the goal of machine learning is to find the predictive model that generalizes best.",
            "zh": "事实上，机器学习的目标是找到最能概括的预测模型。"
        }
    },
    {
        "translation": {
            "en": "8.42   The flow of error gradients through a long short-term memory unit during backpropagation.",
            "zh": "8.42 反向传播过程中通过长短期记忆单元的误差梯度流动。"
        }
    },
    {
        "translation": {
            "en": "This is why during the forward pass we unrolled the network and stored a separate weighted sum z and activation a for each occurrence of a neuron in the unrolled network.",
            "zh": "这就是为什么在前向传递期间，我们展开网络，并为展开网络中每个出现的神经元存储一个单独的加权总和 z 和激活 a。"
        }
    },
    {
        "translation": {
            "en": "forward",
            "zh": "向前"
        }
    },
    {
        "translation": {
            "en": "The performance recorded in Table 9.1[537] shows that this system is slightly more likely to make the second kind of mistake than the first.",
            "zh": "表9.1[537]中记录的性能表明，该系统比第一种系统更容易犯第二种错误。"
        }
    },
    {
        "translation": {
            "en": "N rays, 533",
            "zh": "N射线，533"
        }
    },
    {
        "translation": {
            "en": "When a distance weighted k nearest neighbor approach is used, the contribution of each neighbor to the prediction is a function of the inverse distance between the neighbor and the query.",
            "zh": "当使用距离加权 k 最近邻方法时，每个邻域对预测的贡献是邻域与查询之间反距离的函数。"
        }
    },
    {
        "translation": {
            "en": "DEVRAD_U/G/R/I/Z",
            "zh": "DEVRAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "1. (a) Three people flip a fair coin. What is the probability that exactly two of them will get heads?",
            "zh": "1.（甲）三个人抛硬币。他们中的两个获得正面的概率是多少？"
        }
    },
    {
        "translation": {
            "en": "3.8   Examples of using stacked bar plot visualizations to illustrate the relationship between two categorical features: (a) CAREER STAGE and SHOE SPONSOR features; and (b) POSITION and SHOE SPONSOR features, all from Table 3.7[73].",
            "zh": "3.8 使用堆积条形图可视化来说明两个分类特征之间关系的示例：（a） CAREER STAGE 和 SHOE SPONSOR 特征;（b）POSITION和SHOE SPONSOR特征，均来自表3.7[73]。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects are not handed to data analytics practitioners fully formed.",
            "zh": "预测性数据分析项目没有交给完全形成的数据分析从业者。"
        }
    },
    {
        "translation": {
            "en": "Ross also spoke to the chief technology officer (CTO) at AT, Grace, in order to understand the available data resources.",
            "zh": "Ross 还与 AT 的首席技术官 （CTO） Grace 进行了交谈，以了解可用的数据资源。"
        }
    },
    {
        "translation": {
            "en": "I    INTRODUCTION TO MACHINE LEARNING AND DATA ANALYTICS",
            "zh": "一、机器学习和数据分析简介"
        }
    },
    {
        "translation": {
            "en": "47. The details of how this is done depend on how the output layer is organized. For networks trained using the sum of squared errors loss function, the δ for output neurons is calculated using Equation (8.21)[411]; for neurons in a softmax output layer the δ is calculated using Equation 8.72[467].",
            "zh": "47. 如何完成此操作的细节取决于输出层的组织方式。对于使用误差损失函数平方和训练的网络，输出神经元的δ使用公式（8.21）[411]计算;对于softmax输出层中的神经元，δ使用公式8.72[467]计算。"
        }
    },
    {
        "translation": {
            "en": "Barber, David. 2012. Bayesian reasoning and machine learning. Cambridge University Press.",
            "zh": "理发师，大卫。2012. 贝叶斯推理与机器学习.剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "Following the ε-greedy policy, the agent generates a random number (uniformly from [0,1]) of 0.634, which is greater than ε, and the agent uses greedy action selection and chooses a0 = left.",
            "zh": "按照贪婪ε策略，代理生成一个随机数（从 [0,1] 均匀地取自 [0,1]），该随机数大于 ε，代理使用贪婪操作选择并选择 a0 = left。"
        }
    },
    {
        "translation": {
            "en": "The agent’s task is to navigate the environment from the start state to the goal state as quickly as possible while avoiding damage from fiery ground.",
            "zh": "智能体的任务是尽快将环境从开始状态导航到目标状态，同时避免火热地面的损坏。"
        }
    },
    {
        "translation": {
            "en": "There are, however, a range of variations to this standard approach to evaluating prediction model performance, and the remainder of this chapter covers the most important of these.",
            "zh": "然而，这种评估预测模型性能的标准方法存在一系列变化，本章的其余部分将介绍其中最重要的方法。"
        }
    },
    {
        "translation": {
            "en": "The three descriptive features, PRESSURE, TEMPERATURE, and VOLUME measure characteristics of the oil flowing through the valve when it was opened.",
            "zh": "压力、温度和体积这三个描述性特征测量阀门打开时流经阀门的油的特性。"
        }
    },
    {
        "translation": {
            "en": "10. A standard score is equivalent to a z-score, and standardizing in the way described here is also known as applying a z-transform to the data.",
            "zh": "10. 标准分数等同于 z 分数，以此处描述的方式进行标准化也称为对数据应用 z 转换。"
        }
    },
    {
        "translation": {
            "en": "This will continue almost indefinitely as the model becomes more and more tuned to the instances in the training set.",
            "zh": "随着模型越来越适应训练集中的实例，这种情况几乎会无限期地持续下去。"
        }
    },
    {
        "translation": {
            "en": "A similar dynamic emerges between weight updates for the bias inputs, which are always equal to 1 (a0 = 1), and weights on inputs with values much larger than 1.",
            "zh": "偏置输入的权重更新（始终等于 1 （a0 = 1））和输入的权重（值远大于 1））之间也出现了类似的动态。"
        }
    },
    {
        "translation": {
            "en": "Having encouraged his two younger children to play outside, Mr. Murphy had just sat down to read the newspaper when his third child Amalia ran in to say that she had fixed the letters on the fridge because they were all out of order.",
            "zh": "墨菲鼓励他的两个年幼的孩子到外面玩，刚坐下来看报纸，他的第三个孩子阿玛利亚跑进来说，她已经把信放在冰箱上了，因为它们都坏了。"
        }
    },
    {
        "translation": {
            "en": "(b) In designing a dataset, it is generally a bad idea if all the descriptive features are indicators of the target feature taking a particular value. For example, a potential criticism of the design of the dataset in this question is that all the descriptive features are indicators of the CANCER RISK target feature taking the same level, high. Can you think of any descriptive features that could be added to this dataset that are indicators of the low target level?",
            "zh": "（b） 在设计数据集时，如果所有描述性特征都是目标特征具有特定值的指标，则通常是一个坏主意。例如，对本问题中数据集设计的潜在批评是，所有描述性特征都是 CANCER RISK 目标特征处于相同水平的指标，即高。您能想到任何可以添加到此数据集中的描述性特征，这些特征是低目标水平的指标吗？"
        }
    },
    {
        "translation": {
            "en": "Dunn index, 609",
            "zh": "邓恩指数，609"
        }
    },
    {
        "translation": {
            "en": "This preference for caution is often the reason for choosing between SARSA and Q-Learning (although this can also be managed through careful design of rewards).",
            "zh": "这种谨慎的偏好通常是在SARSA和Q-Learning之间做出选择的原因（尽管这也可以通过精心设计的奖励来管理）。"
        }
    },
    {
        "translation": {
            "en": "Not only is the learning more stable (i.e., smoother) but the training of the network actually converges on the stop criterion of SSE < 0.0001 in fewer epochs, 412 instead of 424.",
            "zh": "不仅学习更稳定（即更平滑），而且网络的训练实际上收敛于SSE的停止标准，<更少的纪元，412而不是424。"
        }
    },
    {
        "translation": {
            "en": "Rosenblatt, Frank. 1958. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review 65 (6): 386–408.",
            "zh": "罗森布拉特，弗兰克。1958. 感知器：大脑中信息存储和组织的概率模型。心理学评论65（6）：386-408。"
        }
    },
    {
        "translation": {
            "en": "0.64",
            "zh": "0.64"
        }
    },
    {
        "translation": {
            "en": "Concept drift means that almost all the predictive models that we build will at some point go stale, and the relationships that they have learned between descriptive features and target features will no longer apply.",
            "zh": "概念漂移意味着我们构建的几乎所有预测模型都会在某个时候过时，并且它们在描述性特征和目标特征之间学到的关系将不再适用。"
        }
    },
    {
        "translation": {
            "en": "Before we can start to aggregate the data from these different sources, however, a significant amount of work is required to determine the appropriate design for the ABT.",
            "zh": "然而，在我们开始汇总来自这些不同来源的数据之前，需要大量的工作来确定 ABT 的适当设计。"
        }
    },
    {
        "translation": {
            "en": "The effect of the rectified linear activation function is evident in Figure 8.26(c)[462], where the activations are all positive.",
            "zh": "在图8.26（c）[462]中，整流线性激活函数的效果很明显，其中激活都是正的。"
        }
    },
    {
        "translation": {
            "en": "5.4.1 Handling Noisy Data",
            "zh": "5.4.1 处理嘈杂数据"
        }
    },
    {
        "translation": {
            "en": "The version of the gradient boosting algorithm described here searches for an ensemble model that minimizes the mean squared error between the target feature values from the training dataset and the model predictions. We often describe this as minimizing mean squared error (or L2) loss.36 Gradient boosting can be extended to learn to minimize other loss functions, which makes it an extremely effective and flexible approach to predictive modeling.",
            "zh": "此处描述的梯度提升算法版本搜索一个集成模型，该模型将训练数据集中的目标特征值与模型预测之间的均方误差降至最低。我们经常将其描述为最小化均方误差（或L2）损失.36梯度提升可以扩展以学习最小化其他损失函数，这使其成为一种非常有效和灵活的预测建模方法。"
        }
    },
    {
        "translation": {
            "en": "The number of months the customer has been with AT",
            "zh": "客户在 AT 工作的月数"
        }
    },
    {
        "translation": {
            "en": "11. This is always an interesting category to determine a value for. Some people might argue that some profit arises as no loss was made.",
            "zh": "11. 这始终是确定其值的有趣类别。有些人可能会争辩说，由于没有亏损，因此产生了一些利润。"
        }
    },
    {
        "translation": {
            "en": "The first draft of the domain concepts diagram developed by Jocelyn for the galaxy classification task.",
            "zh": "Jocelyn 为星系分类任务开发的域概念图的初稿。"
        }
    },
    {
        "translation": {
            "en": "8.7 Exercises",
            "zh": "8.7 练习"
        }
    },
    {
        "translation": {
            "en": "For the customers in the control group, the random selection process was used.",
            "zh": "对于对照组中的客户，使用随机选择过程。"
        }
    },
    {
        "translation": {
            "en": "All the descriptive statistics and data visualization techniques that we have used in the previous sections of this chapter have focused on the characteristics of individual features. This section will introduce techniques that enable us to examine relationships between pairs of features.",
            "zh": "我们在本章前几节中使用的所有描述性统计和数据可视化技术都集中在单个特征的特征上。本节将介绍使我们能够检查特征对之间的关系的技术。"
        }
    },
    {
        "translation": {
            "en": "This indicates that the regression model is more accurately predicting the correct drug dosages than the nearest neighbor model.",
            "zh": "这表明回归模型比最近邻模型更准确地预测了正确的药物剂量。"
        }
    },
    {
        "translation": {
            "en": "When the gradient descent algorithm is used to find optimal weights for linear regression models, the initial weights are chosen randomly from a predefined range that must be specified as an input to the algorithm.",
            "zh": "当使用梯度下降算法为线性回归模型查找最佳权重时，将从预定义范围内随机选择初始权重，该范围必须指定为算法的输入。"
        }
    },
    {
        "translation": {
            "en": "indicates the predicted probability for the true category (i.e., the category encoded as a 1 in the one-hot encoded vector t). To illustrate this simplification with a case study, we assume that our distribution is over three categories, and the target distribution is encoded as a one-hot vector. Now if the target distribution over a particular instance is t = [0,1,0] (i.e., the second category is the correct category), then the cross-entropy summation in Equation (8.66)[465] expands as follows:",
            "zh": "表示真类别（即，在单热编码向量 t 中编码为 1 的类别）的预测概率。为了通过案例研究来说明这种简化，我们假设我们的分布超过三个类别，并且目标分布被编码为一个热向量。现在，如果特定实例的目标分布为 t = [0,1,0]（即，第二个类别是正确的类别），则方程 （8.66）[465] 中的交叉熵求和展开如下："
        }
    },
    {
        "translation": {
            "en": "For example, consider a feedforward network that has been initialized with weights randomly sampled with uniform probability from a range such as [−0.5,+0.5].",
            "zh": "例如，考虑一个前馈网络，该网络已初始化权重，权重从 [−0.5，+0.5] 等范围内以均匀的概率随机采样。"
        }
    },
    {
        "translation": {
            "en": "If the agent chooses the Twist action they will be dealt one of the 13 types of cards in a deck with a value between 2 and 11 (remember that there are four cards in the deck with a value of 10: 10, J, Q, and K).",
            "zh": "如果代理选择 Twist 动作，他们将获得一副牌中 13 种牌中的一种，其值在 2 到 11 之间（请记住，牌组中有四张牌的值为 10：10、J、Q 和 K）。"
        }
    },
    {
        "translation": {
            "en": "silhouette, 609, 610",
            "zh": "剪影， 609， 610"
        }
    },
    {
        "translation": {
            "en": "3. Calculates a confidence factor, α, for the model such that α increases as ε decreases. A common way to calculate the confidence factor is",
            "zh": "3. 计算模型的置信因子 α，使α随着ε的减少而增加。计算置信因子的常用方法是"
        }
    },
    {
        "translation": {
            "en": "This mean height is shown by the dashed gray line in Figure A.1[746]. The arithmetic mean is one measure of the central tendency of a sample (for our purposes, a sample is just a set of values for a feature in an ABT). Because it is easy to calculate and easy to interpret, the mean is commonly used as part of the data exploration process as a good estimate of the central tendencies of features in an ABT.",
            "zh": "该平均高度由图A.1[746]中的灰色虚线表示。算术平均值是样本集中趋势的一种度量（就我们的目的而言，样本只是 ABT 中特征的一组值）。由于均值易于计算和解释，因此通常用作数据探索过程的一部分，作为对 ABT 中特征中心趋势的良好估计。"
        }
    },
    {
        "translation": {
            "en": "posterior probability distribution, 250",
            "zh": "后验概率分布，250"
        }
    },
    {
        "translation": {
            "en": "Deep learning works best in complex domains with lots of features and large datasets.",
            "zh": "深度学习在具有大量特征和大型数据集的复杂领域中效果最佳。"
        }
    },
    {
        "translation": {
            "en": "This may seem like a trivial task—it is essentially an identity function—but it is made more interesting by a network architecture that transforms the data through a series of narrower and narrower layers.",
            "zh": "这似乎是一项微不足道的任务——它本质上是一个身份函数——但它通过一系列越来越窄的层转换数据的网络架构使它变得更加有趣。"
        }
    },
    {
        "translation": {
            "en": "Obviously, a network with random weights is unlikely to implement a useful function.",
            "zh": "显然，具有随机权重的网络不太可能实现有用的功能。"
        }
    },
    {
        "translation": {
            "en": "We can see this in the solid line in Figure 9.3[542].",
            "zh": "我们可以在图 9.3[542] 的实线中看到这一点。"
        }
    },
    {
        "translation": {
            "en": "In the terminology of Bayesian networks, node A is a parent node of B, and node B is a child node of A, because there is a direct edge from A into B.",
            "zh": "在贝叶斯网络的术语中，节点 A 是 B 的父节点，节点 B 是 A 的子节点，因为从 A 到 B 有一条直接边。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn stressed that until she had looked at the data and performed experiments, she could not make any predictions as to what classification accuracy would be possible.",
            "zh": "Jocelyn强调，在她查看数据并进行实验之前，她无法预测分类精度的可能。"
        }
    },
    {
        "translation": {
            "en": "First, Figure 8.24(b)[454] shows that now the z values consistently become larger as we move forward through the network; this is a complete reversal of the vanishing z value dynamic shown in Figure 8.23(b)[453].",
            "zh": "首先，图 8.24（b）[454] 显示，随着我们在网络中前进，现在 z 值不断变大;这是图8.23（b）[453]所示的Z值消失动态的完全逆转。"
        }
    },
    {
        "translation": {
            "en": "3.2   Portions of the ABT for the motor insurance claims fraud detection problem discussed in Section 2.4.6[42].",
            "zh": "3.2 ABT中关于第2.4.6节[42]中讨论的汽车保险索赔欺诈检测问题的部分。"
        }
    },
    {
        "translation": {
            "en": "bias, 91, 385, 751",
            "zh": "偏置， 91， 385， 751"
        }
    },
    {
        "translation": {
            "en": "This figure shows scatter plots for three bivariate datasets that have the same central tendency, marked A and located in the feature space at (50,50), but whose instances are spread out differently across the feature space.",
            "zh": "此图显示了三个双变量数据集的散点图，这些数据集具有相同的中心趋势，标记为 A，位于特征空间 （50,50） 处，但其实例在特征空间中的分布方式不同。"
        }
    },
    {
        "translation": {
            "en": "For example, suppose our basketball team manages to sign a ringer measuring in at 229cm, as shown in Figure A.2(a)[746].",
            "zh": "例如，假设我们的篮球队设法签下了一个 229 厘米的铃声，如图 A.2（a）[746] 所示。"
        }
    },
    {
        "translation": {
            "en": "lazy learner, 232",
            "zh": "懒惰的学习者，232"
        }
    },
    {
        "translation": {
            "en": "Again, remember that each node is constructed in a context consisting of a dataset of instances containing a subset of the instances used to construct its parent node and the set of descriptive features that have not been tested on the path between the root node and parent node.",
            "zh": "同样，请记住，每个节点都是在上下文中构建的，该上下文由实例数据集组成，该数据集包含用于构造其父节点的实例子集以及尚未在根节点和父节点之间的路径上测试的描述性特征集。"
        }
    },
    {
        "translation": {
            "en": "We then present extensions and variations of this approach that describe different performance measures for models predicting categorical, continuous, and multinomial targets; how to design effective evaluation experiments; and how to continually measure the performance of models after deployment.",
            "zh": "然后，我们介绍了这种方法的扩展和变体，这些扩展和变体描述了预测分类、连续和多项式目标的模型的不同性能度量;如何设计有效的评估实验;以及如何在部署后持续测量模型的性能。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.139)[520] may appear to undermine this design goal, because the calculation of the backpropagated error gradients in the vector ∂ℰt/∂ht−1 involves a multiplication by weight matrices.",
            "zh": "方程（8.139）[520]似乎破坏了这一设计目标，因为计算向量∂Et/∂ht−1中的反向传播误差梯度涉及乘以权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "9.7 Exercises",
            "zh": "9.7 练习"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the correlations between instances are broken because mini-batches are randomly selected from the replay memory.",
            "zh": "此外，实例之间的相关性被破坏，因为小批量是从重放内存中随机选择的。"
        }
    },
    {
        "translation": {
            "en": "ID3, 133",
            "zh": "ID3,133"
        }
    },
    {
        "translation": {
            "en": "Hence the name backpropagation through time: as we backpropagate through the previous states of the network, we are in effect going back through time.",
            "zh": "因此，我们得名“时间反向传播”：当我们通过网络的先前状态进行反向传播时，我们实际上是在回溯时间。"
        }
    },
    {
        "translation": {
            "en": "The company can run this model whenever a new loan application is made and only extend credit to those borrowers predicted to belong to the good target level.",
            "zh": "每当提出新的贷款申请时，公司都可以运行此模型，并且仅向预测属于良好目标水平的借款人提供信贷。"
        }
    },
    {
        "translation": {
            "en": "This differential is largest between the pixels at the corners of the image versus the pixels in the middle of the image; only one of the receptive fields covers the top-left pixel in the image, whereas nine receptive fields cover the pixel at coordinate (3,3).",
            "zh": "图像角落的像素与图像中间的像素之间的差异最大;只有一个感受野覆盖图像中左上角的像素，而九个感受野覆盖坐标处的像素 （3,3）。"
        }
    },
    {
        "translation": {
            "en": "11.4.1 SARSA, On-Policy Temporal-Difference Learning",
            "zh": "11.4.1 SARSA，政策时间差异学习"
        }
    },
    {
        "translation": {
            "en": "This is the same process that we use for the forward pass of a standard feedforward network (see Figure 8.11[406]); the slightly complicating factor here is that in an unrolled recurrent network a neuron may occur multiple times (for example, neurons in the hidden layer will occur once for each time-step), and so for each neuron we have a time-stamped sequence of z and a values.",
            "zh": "这与我们用于标准前馈网络的前向传递的过程相同（参见图 8.11[406]）;这里稍微复杂的因素是，在展开的循环网络中，一个神经元可能会出现多次（例如，隐藏层中的神经元在每个时间步长中都会出现一次），因此对于每个神经元，我们都有一个带有时间戳的 z 和 a 值序列。"
        }
    },
    {
        "translation": {
            "en": "To summarize, the backward pass of the backpropagation algorithm propagates the δ error gradients back through the network.",
            "zh": "总而言之，反向传播算法的向后传递通过网络将δ误差梯度传播回去。"
        }
    },
    {
        "translation": {
            "en": "The ID3 decision tree induction algorithm described in the previous section provides the basic approach to decision tree induction: a top-down, recursive, depth-first partitioning of the dataset beginning at the root node and finishing at the leaf nodes.",
            "zh": "上一节中描述的 ID3 决策树归纳算法提供了决策树归纳的基本方法：数据集的自上而下、递归、深度优先的分区，从根节点开始，到叶节点结束。"
        }
    },
    {
        "translation": {
            "en": "Esposito, Floriana, Donato Malerba, and Giovanni Semeraro. 1997. A comparative analysis of methods for pruning decision trees. IEEE Transactions on Pattern Analysis and Machine Intelligence 19 (5): 476–491.",
            "zh": "埃斯波西托、弗洛里亚纳、多纳托·马勒巴和乔瓦尼·塞梅拉罗。1997. 决策树修剪方法的比较分析.IEEE模式分析与机器智能汇刊19（5）：476–491。"
        }
    },
    {
        "translation": {
            "en": "8.2.2 Artificial Neural Networks",
            "zh": "8.2.2 人工神经网络"
        }
    },
    {
        "translation": {
            "en": "The members of a rival school basketball team. Player heights are listed below each player. The dashed gray line shows the arithmetic mean of the players’ heights.",
            "zh": "敌对学校篮球队的成员。每个玩家下方列出了玩家的身高。灰色虚线表示球员身高的算术平均值。"
        }
    },
    {
        "translation": {
            "en": "bits, 126",
            "zh": "位，126"
        }
    },
    {
        "translation": {
            "en": "The final probability that we need to calculate, P(q[1],…,q[m] | t = l), can be calculated either directly from a dataset (by calculating the relative frequency of the joint event q[1],…,q[m] within the set of instances where t = l), or alternatively, it can be calculated using the probability chain rule.9 The chain rule states that the probability of a joint event can be rewritten as a product of conditional probabilities. So, we can rewrite P(q[1],…,q[m]) as",
            "zh": "我们需要计算的最终概率 P（q[1],...,q[m] | t = l） 可以直接从数据集中计算（通过计算 t = l 的实例集中的联合事件 q[1],...,q[m] 的相对频率），也可以使用概率链规则进行计算.9 链式规则指出，联合事件的概率可以改写为条件概率的乘积。因此，我们可以将 P（q[1],...,q[m]） 改写为"
        }
    },
    {
        "translation": {
            "en": "The expectation is that each domain concept, or domain subconcept, will lead to one or more actual descriptive features derived directly from organizational data sources.",
            "zh": "期望每个领域概念或领域子概念都会导致一个或多个直接从组织数据源派生的实际描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Table 6.7[268] illustrates the steps in smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature when conditioned on FRAUD = false. We can see that after smoothing, the probability mass is more evenly distributed across the events in the set. Crucially, the posterior probability for P(GC = guarantor | ¬fr) is no longer zero, and as a result, the coverage of the model has been extended to include queries with GUARANTOR/COAPPLICANT values of guarantor.",
            "zh": "表 6.7[268] 说明了在以 FRAUD = false 为条件时，对 GUARANTOR/COAPPLICANT 特征的后验概率进行平滑处理的步骤。我们可以看到，在平滑之后，概率质量更均匀地分布在集合中的事件中。至关重要的是，P（GC = guarantor | ¬fr） 的后验概率不再为零，因此，该模型的覆盖范围已扩展到包括具有 GUARANTOR/COAPPLICANT 值的 guarantor 的查询。"
        }
    },
    {
        "translation": {
            "en": "AVGOVERBUNDLEMINS",
            "zh": "AVGOVERBUNDLEMINS"
        }
    },
    {
        "translation": {
            "en": "In this dataset there are three categories of risk: low, medium, and high.",
            "zh": "在此数据集中，有三类风险：低、中和高。"
        }
    },
    {
        "translation": {
            "en": "A dataset from a loan application fraud detection domain.",
            "zh": "来自贷款申请欺诈检测域的数据集。"
        }
    },
    {
        "translation": {
            "en": "For r target feature levels, we build r separate logistic regression models 𝕄w1 to 𝕄wr:",
            "zh": "对于 r 目标特征级别，我们构建了 r 个单独的逻辑回归模型 Mw1 到 Mwr："
        }
    },
    {
        "translation": {
            "en": "There are two main ways that the data quality report can be used to identify outliers within a dataset.",
            "zh": "数据质量报告可用于识别数据集中的异常值有两种主要方式。"
        }
    },
    {
        "translation": {
            "en": "The important thing to remember, though, is that the different approaches exist because in different scenarios it will often be easier to apply one approach over the others.",
            "zh": "但是，要记住的重要一点是，存在不同的方法，因为在不同的场景中，应用一种方法通常比其他方法更容易。"
        }
    },
    {
        "translation": {
            "en": "This kind of insight that we can get from the confusion matrix can help in trying to improve a model, as it can suggest to us where we should focus our work.",
            "zh": "我们可以从混淆矩阵中获得的这种见解可以帮助尝试改进模型，因为它可以向我们建议我们应该将工作重点放在哪里。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.11[619] illustrates these options. In the AHC examples shown in Figure 10.10[617], Euclidean distance and single linkage are used. The choice of linkage method can lead to quite different results when AHC is used. For example, using centroid linkage leads to results very similar to a k-means clustering approach, whereas using single linkage leads to results much more heavily reliant on local distances within a dataset.",
            "zh": "图 10.11[619] 说明了这些选项。在图10.10[617]所示的AHC示例中，使用了欧几里得距离和单连杆。当使用AHC时，联动方法的选择会导致完全不同的结果。例如，使用质心链接会导致结果与 k 均值聚类方法非常相似，而使用单链接会导致结果更严重地依赖于数据集中的局部距离。"
        }
    },
    {
        "translation": {
            "en": "For example, if we examine Figure 8.39[506] we see that when ℰ t=3 is backpropagated through the network, a single error gradient is calculated for each weight in Wyh because this matrix occurs only once in the unrolled network, but three separate error gradients are calculated for each weight in Whh and Whx.",
            "zh": "例如，如果我们检查图 8.39[506]，我们会看到当 E t=3 通过网络反向传播时，每个权重（Wyh）都会计算一个误差梯度，因为该矩阵在展开的网络中只出现一次，但每个权重（以 Whh 和 Whx 为单位）计算三个单独的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "We will use the dataset presented in Table 6.2[263] to illustrate how to create and use a naive Bayes model for a prediction problem.",
            "zh": "我们将使用表 6.2[263] 中提供的数据集来说明如何为预测问题创建和使用朴素贝叶斯模型。"
        }
    },
    {
        "translation": {
            "en": "(b) The ensemble contains 11 independent models, all of which have an error rate of 0.49.",
            "zh": "（b） 该集合包含11个独立模型，所有模型的错误率为0.49。"
        }
    },
    {
        "translation": {
            "en": "With the knowledge that the Galaxy Zoo labels would provide her with a target feature, Jocelyn returned to speak with Ted again about getting access to the SDSS data.",
            "zh": "在知道银河动物园标签会为她提供目标功能后，乔斯琳再次与泰德讨论如何访问SDSS数据。"
        }
    },
    {
        "translation": {
            "en": "It is important to explore these possibilities and, in conjunction with the business, to agree on the most suitable solution for the business.",
            "zh": "重要的是要探索这些可能性，并与业务部门一起，就最适合业务的解决方案达成一致。"
        }
    },
    {
        "translation": {
            "en": "We begin, however, by introducing some of the metrics, other than entropy-based information gain, that can be used to select the next feature to split on as we build the tree.",
            "zh": "然而，我们首先介绍了一些指标，除了基于熵的信息增益之外，这些指标可用于在构建树时选择下一个要拆分的特征。"
        }
    },
    {
        "translation": {
            "en": "We can see that the logistic function is a threshold function that pushes values above zero to 1 and values below zero to 0.",
            "zh": "我们可以看到，逻辑函数是一个阈值函数，它将高于零的值推送到 1，将低于零的值推送到 0。"
        }
    },
    {
        "translation": {
            "en": "The silhouette plot for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3).",
            "zh": "使用 k 均值算法（k = 3）找到的移动电话客户数据集最终聚类的轮廓图（表 10.1[604]）。"
        }
    },
    {
        "translation": {
            "en": "In other words, in a convolutional neural network, when two neurons share weights, they share all their weights, because they use the same filter.",
            "zh": "换句话说，在卷积神经网络中，当两个神经元共享权重时，它们共享所有权重，因为它们使用相同的滤波器。"
        }
    },
    {
        "translation": {
            "en": "interaction effect, 169",
            "zh": "交互作用，169"
        }
    },
    {
        "translation": {
            "en": "If treated as a continuous feature in a data quality report, this would have a cardinality of 2.",
            "zh": "如果在数据质量报告中被视为连续特征，则基数为 2。"
        }
    },
    {
        "translation": {
            "en": "(c) Variance and standard deviation",
            "zh": "（c） 方差和标准差"
        }
    },
    {
        "translation": {
            "en": "There are two ways of computing the likelihood of a future event: (1) use the relative frequency of the event in the past, or (2) use a subjective estimate (ideally from an expert!).",
            "zh": "有两种方法可以计算未来事件的可能性：（1）使用过去事件的相对频率，或（2）使用主观估计（最好来自专家！"
        }
    },
    {
        "translation": {
            "en": "where ′wk(d) is a revised, normalized prediction for the one-versus-all model for the target level k. The denominator in this equation sums the predictions of each of the one-versus-all models for the r levels of the target feature and acts as a normalization term.",
            "zh": "其中 ′wk（d） 是针对目标水平 k 的一对全模型的修订版归一化预测。此等式中的分母将目标特征的 r 级的每个一对多模型的预测求和，并用作归一化项。"
        }
    },
    {
        "translation": {
            "en": "Rather than defining a curve (as was the case for all the previous examples), this function defines a surface, as shown in Figure C.3(a)[769].",
            "zh": "该函数不是定义曲线（如前面所有示例的情况），而是定义曲面，如图C.3（a）[769]所示。"
        }
    },
    {
        "translation": {
            "en": "The probability distribution for a categorical feature is a vector that lists the probabilities associated with each of the values in the domain of the feature.",
            "zh": "分类特征的概率分布是一个向量，它列出了与特征域中每个值关联的概率。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.2[541] illustrates how a large ABT can be divided into a training set, a validation set, and a test set.",
            "zh": "图 9.2[541] 说明了如何将大型 ABT 划分为训练集、验证集和测试集。"
        }
    },
    {
        "translation": {
            "en": "As a result, we cannot use the set of consistent models to make predictions for these queries.",
            "zh": "因此，我们不能使用一组一致的模型来对这些查询进行预测。"
        }
    },
    {
        "translation": {
            "en": "The generated feature maps have the same 6-by-6 dimensionality as the input image (before padding was applied).",
            "zh": "生成的特征图具有与输入图像相同的 6×6 维度（在应用填充之前）。"
        }
    },
    {
        "translation": {
            "en": "The Fundamentals section of this chapter introduces the key ideas of a parameterized model, measuring error, and an error surface.",
            "zh": "本章的基础知识部分介绍了参数化模型、测量误差和误差曲面的关键思想。"
        }
    },
    {
        "translation": {
            "en": "Smoothing takes some of the probability mass from the events with high probability and shares this with the events with low probabilities.",
            "zh": "平滑从高概率事件中获取一些概率质量，并与低概率事件共享。"
        }
    },
    {
        "translation": {
            "en": "Obviously, pruning will result in the creation of decision trees that are not consistent with the training set used to build them.",
            "zh": "显然，修剪将导致决策树的创建与用于构建它们的训练集不一致。"
        }
    },
    {
        "translation": {
            "en": "Each visualization is composed of four plots: one plot of the distribution of the descriptive feature values in the entire dataset, and three plots illustrating the distribution of the descriptive feature values for each level of the target.",
            "zh": "每个可视化效果都由四个图组成：一个图是整个数据集中描述性特征值的分布图，三个图是说明每个目标级别的描述性特征值的分布图。"
        }
    },
    {
        "translation": {
            "en": "—Roy Keane",
            "zh": "——罗伊·基恩"
        }
    },
    {
        "translation": {
            "en": "Figure 12.5",
            "zh": "图 12.5"
        }
    },
    {
        "translation": {
            "en": "sensitivity, 548, 559",
            "zh": "灵敏度， 548， 559"
        }
    },
    {
        "translation": {
            "en": "As with the hidden layer, the first operation is the multiplication of the layer’s weight matrix by the (augmented) vector of activations from the previous layer.",
            "zh": "与隐藏层一样，第一个操作是将层的权重矩阵乘以来自前一层的（增强）激活向量。"
        }
    },
    {
        "translation": {
            "en": "The simple linear regression and logistic regression models that we first looked at were only capable of representing linear relationships between descriptive features and a target feature.",
            "zh": "我们首先研究的简单线性回归和逻辑回归模型只能表示描述性特征和目标特征之间的线性关系。"
        }
    },
    {
        "translation": {
            "en": "Anti-discrimination legislation in most jurisdictions prohibits discrimination on the basis of some set of the following grounds: sex, age, race, ethnicity, nationality, sexual orientation, religion, disability, and political opinions.",
            "zh": "大多数司法管辖区的反歧视立法禁止基于以下几方面的歧视：性别、年龄、种族、民族、国籍、性取向、宗教、残疾和政治观点。"
        }
    },
    {
        "translation": {
            "en": "From Figure 3.9(b)[79] we can see that HEIGHT follows a normal distribution centered around a mean of approximately 194.",
            "zh": "从图3.9（b）[79]中，我们可以看到HEIGHT遵循以大约194的平均值为中心的正态分布。"
        }
    },
    {
        "translation": {
            "en": "We also assume cards are dealt from an infinite deck, which simplifies some of the modeling of the game.9",
            "zh": "我们还假设牌是从无限套牌中发牌的，这简化了游戏的一些建模9。"
        }
    },
    {
        "translation": {
            "en": "5.10   (a) The path taken from the root node to a leaf node when we search the tree with a query; and (b) the ? marks the location of the query, and the dashed circle plots the extent of the target.",
            "zh": "5.10 （a） 当我们使用查询搜索树时，从根节点到叶节点的路径;及 （b） ？标记查询的位置，虚线圆圈绘制目标的范围。"
        }
    },
    {
        "translation": {
            "en": "Missing values (2%)",
            "zh": "缺失值 （2%）"
        }
    },
    {
        "translation": {
            "en": "The compactness of the representation is at the cost of making a naive assumption that may adversely affect the predictive accuracy of the model.",
            "zh": "表示的紧凑性是以做出可能对模型的预测准确性产生不利影响的幼稚假设为代价的。"
        }
    },
    {
        "translation": {
            "en": "The network is trained for 1,000 epochs using mini-batch gradient descent with a batch size of 32.15",
            "zh": "该网络使用批量大小为 32.15 的小型批量梯度下降训练了 1,000 个周期"
        }
    },
    {
        "translation": {
            "en": "Features can be of many different types, but it is useful to think of a distinction between raw features that come directly from existing data sources and derived features that are constructed by manipulating values from existing data sources.",
            "zh": "要素可以有许多不同的类型，但考虑区分直接来自现有数据源的原始要素和通过操作现有数据源中的值而构造的派生要素是很有用的。"
        }
    },
    {
        "translation": {
            "en": "First, recall that when gradient descent was discussed, the instances in the training data were shuffled at the beginning of each epoch.",
            "zh": "首先，回想一下，当讨论梯度下降时，训练数据中的实例在每个纪元开始时被洗牌。"
        }
    },
    {
        "translation": {
            "en": "For clarity in the graph, rewards at non-terminal nodes are left out and rewards are shown just once at each terminal node; the BUST state is shown twice to avoid overlapping transition arrows; and only an illustrative selection of transition probabilities are shown (the full set of transitions probabilities is shown in the transition matrices in Equations (11.15)[650] and (11.14)[650]).",
            "zh": "为了图中的清晰起见，非终端节点的奖励被省略，每个终端节点的奖励只显示一次;BUST 状态显示两次，以避免重叠过渡箭头;并且仅显示了转移概率的说明性选择（完整的转移概率集显示在方程（11.15）[650]和（11.14）[650]的转移矩阵中）。"
        }
    },
    {
        "translation": {
            "en": "Table 3.9[88] also shows the effect of applying standardization to the HEIGHT and SPONSORSHIP EARNINGS features.",
            "zh": "表3.9[88]还显示了对HEIGHT和SPONSORSHIP EARNS特征进行标准化的效果。"
        }
    },
    {
        "translation": {
            "en": "The criterion of consistency with the training data doesn’t provide any guidance with regard to which of the consistent models to prefer in dealing with queries that are outside the training dataset.",
            "zh": "与训练数据的一致性标准没有提供任何指导，说明在处理训练数据集之外的查询时首选哪种一致模型。"
        }
    },
    {
        "translation": {
            "en": "Let’s return to the motor insurance fraud detection solution to consider the design and implementation of the features that will populate the ABT.",
            "zh": "让我们回到汽车保险欺诈检测解决方案，以考虑将填充 ABT 的功能的设计和实现。"
        }
    },
    {
        "translation": {
            "en": "Decision trees look very like the game trees that we developed for the Guess Who game.",
            "zh": "决策树看起来非常像我们为 Guess Who 游戏开发的游戏树。"
        }
    },
    {
        "translation": {
            "en": "31. See Davies (2005, pp. 693–696).",
            "zh": "31. 参见Davies（2005年，第693-696页）。"
        }
    },
    {
        "translation": {
            "en": "(a)–(c) Histograms for the features from the AT ABT with irregular cardinality; (d)–(g) histograms for the features from the AT ABT that are potentially suffering from outliers.",
            "zh": "（a）–（c） 具有不规则基数的 AT ABT 特征的直方图;（d）–（g） 来自 AT ABT 的可能受到异常值影响的特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Table 4.11[152] lists a small dataset from this domain.17",
            "zh": "表4.11[152]列出了来自该域的一个小数据集17。"
        }
    },
    {
        "translation": {
            "en": "0.75",
            "zh": "0.75"
        }
    },
    {
        "translation": {
            "en": "If none of these cases holds, the algorithm continues to recursively create interior nodes, Lines 7–13 of Algorithm 1[134].",
            "zh": "如果这些情况都不成立，则算法继续递归创建内部节点，即算法 1 的第 7-13 行[134]。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.9",
            "zh": "图 9.9"
        }
    },
    {
        "translation": {
            "en": "By contrast, consider the example of calculating the entropy of a set of 52 playing cards if we distinguish between cards on the sole basis of their suit (hearts ♥, clubs ♣, diamonds ♦ or, spades ♠). This time, there are only four possible outcomes when a random card is selected from this set, each with a reasonably large probability of . The entropy associated with this set can be calculated",
            "zh": "相比之下，如果我们仅根据花色（红心♥、梅花♣、方块♦或黑桃♠）来区分牌，请考虑计算一组 52 张扑克牌的熵的例子。这一次，当从这组牌中随机选择一张牌时，只有四种可能的结果，每种结果的概率都相当大。可以计算与此集合相关的熵"
        }
    },
    {
        "translation": {
            "en": "1 show the distances between each instance and these initial cluster centroids.",
            "zh": "图 1 显示了每个实例与这些初始聚类质心之间的距离。"
        }
    },
    {
        "translation": {
            "en": "(d) Measure the performance of this boosted ensemble using misclassification rate.",
            "zh": "（d） 使用错误分类率来衡量这种增强集合的性能。"
        }
    },
    {
        "translation": {
            "en": "This adjustment is repeated over and over until the global minimum on the error surface is reached.",
            "zh": "一遍又一遍地重复此调整，直到达到误差曲面上的全局最小值。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.17",
            "zh": "图 10.17"
        }
    },
    {
        "translation": {
            "en": "The following image labeled (a) shows a simple schematic of a system used to train a self-driving car to drive on a four-lane highway.",
            "zh": "下图标记为（a）显示了用于训练自动驾驶汽车在四车道高速公路上行驶的系统的简单示意图。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, there is no guaranteed way of finding the optimal number of bins for a set of values for a continuous feature.",
            "zh": "遗憾的是，无法保证为连续特征的一组值找到最佳条柱数。"
        }
    },
    {
        "translation": {
            "en": "Within a few years of the publication of this article, the consensus within the physics research community is that N rays do not exist.",
            "zh": "在这篇文章发表后的几年内，物理学研究界的共识是N射线不存在。"
        }
    },
    {
        "translation": {
            "en": "bootstrap samples, 159",
            "zh": "Bootstrap 示例，159"
        }
    },
    {
        "translation": {
            "en": "Table 6.3[264] lists the probabilities we need for our naive Bayes fraud detection model.",
            "zh": "表 6.3[264] 列出了朴素贝叶斯欺诈检测模型所需的概率。"
        }
    },
    {
        "translation": {
            "en": "Transition Probabilities",
            "zh": "转移概率"
        }
    },
    {
        "translation": {
            "en": "There are three technical requirements that must hold for distribution of states generated from Gibbs sampling to converge with the distribution that we are sampling from—in this case, the distribution defined by the Bayesian network.",
            "zh": "对于从吉布斯采样生成的状态分布，必须满足三个技术要求，以便与我们从中采样的分布收敛，在本例中，由贝叶斯网络定义的分布。"
        }
    },
    {
        "translation": {
            "en": "A Markov decision process (MDP) extends the Markov process by adding decision making and rewards. We extend the formulation of the Markov process to include a finite set of actions that can be taken, A, and add actions from this set to the formulation of transition probabilities",
            "zh": "马尔可夫决策过程 （MDP） 通过添加决策和奖励来扩展马尔可夫过程。我们扩展了马尔可夫过程的公式，以包括一组可以采取的有限动作，A，并将该集合中的动作添加到转移概率的公式中"
        }
    },
    {
        "translation": {
            "en": "In the context of a predictive analytics scenario, the sample is the set of values that occur in an ABT. The population is the set of all the values that could possibly occur. For example, in an ABT for a motor insurance claims fraud prediction problem, we may include details of 500 claims that have happened in the past. This would be our sample. The population would be all the claims that have ever happened.",
            "zh": "在预测分析方案的上下文中，示例是 ABT 中出现的一组值。总体是可能发生的所有值的集合。例如，在汽车保险索赔欺诈预测问题的 ABT 中，我们可能会包括过去发生的 500 项索赔的详细信息。这将是我们的示例。人口将是曾经发生过的所有索赔。"
        }
    },
    {
        "translation": {
            "en": "When we are computing a conditional probability, we need to be aware of the state of both the parents of a node and the children of a node and their parents. This is because knowledge of the state of a child node can tell us something about the state of the parent node. For example, returning to our simple Bayesian network in Figure 6.9(a)[287], we can compute P(a | ¬b) using Bayes’ Theorem as follows:",
            "zh": "当我们计算条件概率时，我们需要了解节点的父节点和节点的子节点及其父节点的状态。这是因为了解子节点的状态可以告诉我们有关父节点状态的一些信息。例如，回到图6.9（a）[287]中的简单贝叶斯网络，我们可以使用贝叶斯定理计算P（a | ¬b），如下所示："
        }
    },
    {
        "translation": {
            "en": "What are the goals that the business wants to achieve?",
            "zh": "企业想要实现的目标是什么？"
        }
    },
    {
        "translation": {
            "en": "MRRCC_U/G/R/I/Z",
            "zh": "MRRCC_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The measure of brightness used in the SDSS pipeline is referred to as magnitude.",
            "zh": "SDSS 管道中使用的亮度度量称为幅度。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(d)[626] shows the final reconstructions generated by the network after 1,000 epochs of network training.",
            "zh": "图 10.15（d）[626] 显示了网络在 1,000 个网络训练周期后生成的最终重建。"
        }
    },
    {
        "translation": {
            "en": "SMOKER, do they smoke",
            "zh": "吸烟者，他们抽烟吗"
        }
    },
    {
        "translation": {
            "en": "Tables 9.10(a)[555] and 9.10(b)[555] show this calculation for the k-NN and the decision tree models.",
            "zh": "表9.10（a）[555]和表9.10（b）[555]显示了k-NN和决策树模型的计算结果。"
        }
    },
    {
        "translation": {
            "en": "stability index, 580, 590, 591, 727",
            "zh": "稳定性指数， 580， 590， 591， 727"
        }
    },
    {
        "translation": {
            "en": "The SDSS download that Jocelyn had access to was a big dataset—over 600,000 rows. Although modern predictive analytics and machine learning tools can handle data of this size, a large dataset can be cumbersome when performing data exploration operations—calculating summary statistics, generating visualizations, and performing correlation tests can just take too long. For this reason, Jocelyn extracted a small sample of 10,000 rows from the full dataset for exploratory analysis using stratified sampling.",
            "zh": "Jocelyn 可以访问的 SDSS 下载是一个大型数据集，超过 600,000 行。尽管现代预测分析和机器学习工具可以处理这种大小的数据，但在执行数据探索操作时，大型数据集可能会很麻烦 - 计算汇总统计、生成可视化效果和执行相关性测试可能需要很长时间。出于这个原因，Jocelyn 从完整数据集中提取了 10,000 行的小样本，以使用分层抽样进行探索性分析。"
        }
    },
    {
        "translation": {
            "en": "The mapping between the features we have discussed here and the column names in Table 2.2[46] is as follows: NUMBER OF CLAIMANTS: NUM.",
            "zh": "我们在这里讨论的特征与表2.2[46]中的列名之间的映射如下： 索赔人数量：数量。"
        }
    },
    {
        "translation": {
            "en": "machine learning, 4, 5",
            "zh": "机器学习， 4， 5"
        }
    },
    {
        "translation": {
            "en": "This first path of information processing in the input gate is similar to the process used in the forget gate; however, in this case the generate vector mask is not applied directly to the cell state but rather is used to filter the vector of output activations generated by the second path of processing in the input gate.",
            "zh": "输入门中信息处理的第一条路径类似于遗忘门中使用的过程;但是，在这种情况下，生成向量掩码不会直接应用于单元状态，而是用于过滤由输入门中的第二条处理路径生成的输出激活向量。"
        }
    },
    {
        "translation": {
            "en": "information, 120",
            "zh": "信息，120"
        }
    },
    {
        "translation": {
            "en": "The link between machine learning and data analytics runs through every chapter in the book but is especially strong in Part I, which includes Chapters 1 to 3.",
            "zh": "机器学习和数据分析之间的联系贯穿了本书的每一章，但在第一部分（包括第 1 章到第 3 章）中尤为突出。"
        }
    },
    {
        "translation": {
            "en": "The boundary between d4 and d3 is",
            "zh": "d4 和 d3 之间的边界是"
        }
    },
    {
        "translation": {
            "en": "Note that in this diagram the BUST state has been included twice to make the illustration a little more clear by avoiding too many overlapping arrows.",
            "zh": "请注意，在此图中，BUST 状态已包含两次，通过避免太多重叠箭头使插图更加清晰。"
        }
    },
    {
        "translation": {
            "en": "6.6   The posterior probability distribution for the GUARANTOR/COAPPLICANT feature under the condition that FRAUD = false.",
            "zh": "6.6 FRAUD=false条件下担保人/共同申请人特征的后验概率分布。"
        }
    },
    {
        "translation": {
            "en": "derived features, 34, 41, 45",
            "zh": "派生特征， 34， 41， 45"
        }
    },
    {
        "translation": {
            "en": "This will repeat for some pre-specified number of episodes after which the expectation is that the agent will have learned to perform the task well.",
            "zh": "这将在一些预先指定的剧集中重复，之后期望代理已经学会很好地执行任务。"
        }
    },
    {
        "translation": {
            "en": "Applying this to the example f(x) = (x2 + 1)2 we get",
            "zh": "将其应用于示例 f（x） = （x2 + 1）2 我们得到"
        }
    },
    {
        "translation": {
            "en": "The ability of deep neural networks to learn and represent complex mappings from inputs to outputs is why these networks have been so successful at so many complex tasks. However, this representational capacity also means that deep networks are likely to suffer from overfitting. Dropout is a very simple and effective method that helps to stop overfitting.",
            "zh": "深度神经网络能够学习和表示从输入到输出的复杂映射，这就是为什么这些网络在如此多的复杂任务中如此成功的原因。然而，这种表示能力也意味着深度网络可能会遭受过拟合的影响。Dropout 是一种非常简单有效的方法，有助于阻止过度拟合。"
        }
    },
    {
        "translation": {
            "en": "The narrow middle layer is often referred to as a bottleneck layer.",
            "zh": "狭窄的中间层通常被称为瓶颈层。"
        }
    },
    {
        "translation": {
            "en": "linear kernel, 366",
            "zh": "线性内核，366"
        }
    },
    {
        "translation": {
            "en": "We use rt to refer to feedback, as in reinforcement learning feedback is more commonly referred to as reward (where reward can be either positive or negative).",
            "zh": "我们使用 rt 来指代反馈，因为在强化学习中，反馈通常被称为奖励（奖励可以是积极的，也可以是消极的）。"
        }
    },
    {
        "translation": {
            "en": "The definition of the mixture of Gaussians distribution in Table 6.10[271] shows how the individual normal distributions in a mixture of Gaussians distribution are combined using a weighted sum.",
            "zh": "表6.10[271]中高斯分布混合的定义显示了如何使用加权和组合高斯分布混合中的各个正态分布。"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE; RATIO OF SOFT TISSUE CLAIMS TO OTHER CLAIMS: % SOFT TISSUE; UNSUCCESSFUL CLAIM MADE: UNSUCC.",
            "zh": "软组织;软组织权利要求与其他权利要求的比率：%软组织;索赔不成功：UNSUCC。"
        }
    },
    {
        "translation": {
            "en": "Each subsequent layer in the network is able to use the functions learned by the previous layer to construct a more complex function; this process of using the outputs from one or more functions and inputs to another function to create a new function is known as function composition.",
            "zh": "网络中的每一层都能够使用前一层学习到的函数来构造更复杂的函数;使用一个或多个函数的输出和另一个函数的输入来创建新函数的过程称为函数组合。"
        }
    },
    {
        "translation": {
            "en": "data quality report, 53, 54, 94, 98, 105, 110, 614, 693, 710",
            "zh": "数据质量报告， 53， 54， 94， 98， 105， 110， 614， 693， 710"
        }
    },
    {
        "translation": {
            "en": "The result of this product is the δk for the neuron.",
            "zh": "该乘积的结果是神经元的 δk。"
        }
    },
    {
        "translation": {
            "en": "When the algorithm exits the for loop on Line 11[420], the mini-batch examples will have been propagated through all L layers of the network, and A(L) will store the activations for all the neurons in the output layer for all the examples in the mini-batch; as per Figure 8.6[393] the activations are arranged so that the output layer activations for each example will be stored as a column in A(L).",
            "zh": "当算法在第 11 行退出 for 循环时[420]，小批量示例将通过网络的所有 L 层传播，并且 A（L） 将存储小批量中所有示例的输出层中所有神经元的激活;根据图 8.6[393]，激活的排列方式使得每个示例的输出层激活将存储为 A（L） 中的一列。"
        }
    },
    {
        "translation": {
            "en": "The decision boundary using majority vote of the nearest 3 and 5 instances.",
            "zh": "使用最接近的 3 个和 5 个实例的多数票的决策边界。"
        }
    },
    {
        "translation": {
            "en": "0.71",
            "zh": "0.71"
        }
    },
    {
        "translation": {
            "en": "18. This is related to the idea of concept drift discussed in Section 9.4.6[578].",
            "zh": "18. 这与第9.4.6节[578]中讨论的概念漂移的概念有关。"
        }
    },
    {
        "translation": {
            "en": "where levels(f) returns the set of levels in the domain of the feature f.",
            "zh": "其中 levels（f） 返回特征 f 域中的级别集。"
        }
    },
    {
        "translation": {
            "en": "TACHYCARDIA: Is the patient at high risk of suffering from tachycardia in the next month?",
            "zh": "心动过速：患者在下个月患心动过速的风险是否很高？"
        }
    },
    {
        "translation": {
            "en": "Once the data has been prepared, there are two stages to building the Bayesian network. First, we define the topology of the network. Second, we create the network CPTs. The topology of the network will be a causal graph that models this domain. In order to build this, we must have a theory of the causal relationships between the features in the domain. A potential causal theory between the features in this dataset is that",
            "zh": "准备好数据后，构建贝叶斯网络分为两个阶段。首先，我们定义网络的拓扑结构。其次，我们创建网络 CPT。网络的拓扑结构将是模拟此域的因果图。为了建立这一点，我们必须有一个关于域中特征之间因果关系的理论。该数据集中特征之间的潜在因果理论是"
        }
    },
    {
        "translation": {
            "en": "So the effect of multiplying feature values by an inverse covariance matrix is to rescale the variances of all features to 1 and to set the covariance between all feature pairs to 0.",
            "zh": "因此，将特征值乘以逆协方差矩阵的效果是将所有特征的方差重新缩放为 1，并将所有特征对之间的协方差设置为 0。"
        }
    },
    {
        "translation": {
            "en": "MODELFLUXIVAR_U/G/R/I/Z",
            "zh": "MODELFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The company would like to evaluate how well the model is helping to address the churn problem.",
            "zh": "该公司希望评估该模型在帮助解决客户流失问题方面的效果。"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrices are shown in Table 13.6[721].",
            "zh": "由此产生的混淆矩阵如表13.6[721]所示。"
        }
    },
    {
        "translation": {
            "en": "In email classification, identifying spam emails is the most important issue, so the spam level is referred to as the positive level.",
            "zh": "在电子邮件分类中，识别垃圾邮件是最重要的问题，因此垃圾邮件级别称为正面级别。"
        }
    },
    {
        "translation": {
            "en": "29. Note that using linear activation functions in this way means that the network as a whole implements a linear function. However, in this instance, this simplification is appropriate because the purpose of this network architecture design is to illustrate the effect of different weight initialization regimes rather than to be accurate on the task.",
            "zh": "29. 请注意，以这种方式使用线性激活函数意味着整个网络实现了线性函数。但是，在这种情况下，这种简化是适当的，因为此网络架构设计的目的是说明不同权重初始化机制的影响，而不是在任务上准确。"
        }
    },
    {
        "translation": {
            "en": "Similar to using small multiples for categorical features, if the features are unrelated (or independent), then the histograms for each level should be very similar.",
            "zh": "与对分类要素使用小倍数类似，如果要素不相关（或独立），则每个级别的直方图应非常相似。"
        }
    },
    {
        "translation": {
            "en": "MODULE 1",
            "zh": "模块 1"
        }
    },
    {
        "translation": {
            "en": "gain, 567, 569",
            "zh": "增益， 567， 569"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy was 78.278%, which was similar to the accuracies measured on the overall test set.",
            "zh": "平均类准确率为78.278%，与整个测试集测量的准确度相似。"
        }
    },
    {
        "translation": {
            "en": "OpenAI Gym, 668",
            "zh": "OpenAI 健身房，668"
        }
    },
    {
        "translation": {
            "en": "For example, if the target feature originally had the range [min,max] and range normalization has been applied to map this to the range of [0,1], then the activation of a logistic unit in the output layer of the network ai can be mapped to the corresponding value in the original range of the target feature by max × ai.",
            "zh": "例如，如果目标要素原来具有 [min，max] 的范围，并且已应用范围归一化将其映射到 [0,1] 的范围，则可以通过 max × ai 将网络 ai 输出层中逻辑单元的激活映射到目标要素原始范围内的相应值。"
        }
    },
    {
        "translation": {
            "en": "We are using the term valid here to distinguish the pixels that occur in the image from imaginary (or padding) pixels that we might invent around the border of an image.",
            "zh": "我们在这里使用有效的术语来区分图像中出现的像素和我们可能在图像边界周围发明的虚构（或填充）像素。"
        }
    },
    {
        "translation": {
            "en": "The dataset contains 60,000 training and 10,000 test images of handwritten digits from approximately 250 writers.",
            "zh": "该数据集包含来自大约 250 名作家的 60,000 张训练图像和 10,000 张手写数字测试图像。"
        }
    },
    {
        "translation": {
            "en": "Therefore, this rewriting shows that the output of this two-layer network with linear neurons is equivalent to a single-layer network with linear neurons.",
            "zh": "因此，这种重写表明，这个具有线性神经元的两层网络的输出等价于具有线性神经元的单层网络。"
        }
    },
    {
        "translation": {
            "en": "Open Questions",
            "zh": "开放性问题"
        }
    },
    {
        "translation": {
            "en": "We can see from Table 7.4[333] that only the SIZE descriptive feature has a significant impact on the model.",
            "zh": "从表7.4[333]中可以看出，只有SIZE描述性特征对模型有显著影响。"
        }
    },
    {
        "translation": {
            "en": "In our example, convergence occurred after 100 iterations, and the final values for the weights were w[0] = −0.1513, w[1] = 0.6270, w[2] = −0.1781, and w[3] = 0.0714.",
            "zh": "在我们的示例中，收敛发生在 100 次迭代后，权重的最终值为 w[0] = −0.1513、w[1] = 0.6270、w[2] = −0.1781 和 w[3] = 0.0714。"
        }
    },
    {
        "translation": {
            "en": "We can calculate performance measures for a deployed model and compare these to the performance achieved in evaluations before the model was deployed.",
            "zh": "我们可以计算已部署模型的性能度量，并将其与部署模型之前在评估中实现的性能进行比较。"
        }
    },
    {
        "translation": {
            "en": "This domain concept is inherently related to the notion of an observation period, and as we will see, the descriptive features derived from the domain subconcepts under Claimant History are time dependent.",
            "zh": "这个领域概念与观察期的概念有着内在的联系，正如我们将看到的，从索赔人历史下的领域子概念派生的描述性特征是与时间相关的。"
        }
    },
    {
        "translation": {
            "en": "Many of the continuous features in the dataset also have very low cardinality values.",
            "zh": "数据集中的许多连续要素也具有非常低的基数值。"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy, however, to extend the ID3 algorithm to handle continuous descriptive features and continuous target features.",
            "zh": "但是，扩展 ID3 算法以处理连续描述性特征和连续目标特征相对容易。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix is a very useful analysis tool to capture what has happened in an evaluation test in a little more detail and is the basis for calculating many other performance measures.",
            "zh": "混淆矩阵是一个非常有用的分析工具，可以更详细地捕获评估测试中发生的情况，并且是计算许多其他性能度量的基础。"
        }
    },
    {
        "translation": {
            "en": "Together the strong performance by the model on the large test dataset and the confidence built through the manual annotation exercise meant that Edwin and his colleagues were happy to integrate the 3-level model into the SDSS processing pipeline.",
            "zh": "该模型在大型测试数据集上的强大性能以及通过手动注释练习建立的信心意味着 Edwin 和他的同事们很高兴将 3 级模型集成到 SDSS 处理管道中。"
        }
    },
    {
        "translation": {
            "en": "Typically, i is used to index instances in a dataset, and j is used to index features in a vector.",
            "zh": "通常，i 用于索引数据集中的实例，j 用于索引向量中的要素。"
        }
    },
    {
        "translation": {
            "en": "The choice of the range from which these initial weights are selected affects how quickly the gradient descent algorithm will converge to a solution.",
            "zh": "选择这些初始权重的范围会影响梯度下降算法收敛到解决方案的速度。"
        }
    },
    {
        "translation": {
            "en": "Details of the first two iterations when the gradient descent algorithm is used to train a logistic regression model for the extended generators dataset given in Table 7.7[347].",
            "zh": "表7.7[347]中给出的梯度下降算法用于训练扩展生成器数据集的逻辑回归模型时，前两次迭代的详细信息。"
        }
    },
    {
        "translation": {
            "en": "The Manhattan distances between both pairs of instances are the same: 7.25.",
            "zh": "两对实例之间的曼哈顿距离相同：7.25。"
        }
    },
    {
        "translation": {
            "en": "Neural networks with a single hidden layer have been proven to be capable of universal approximation of (bounded) continuous functions as long as either (1) complex functions are integrated into the structure of the neurons, or (2) the hidden layer of the network is sufficiently (potentially exponentially) wide.",
            "zh": "具有单个隐藏层的神经网络已被证明能够普遍近似（有界）连续函数，只要 （1） 复杂函数集成到神经元结构中，或 （2） 网络的隐藏层足够（可能呈指数）宽。"
        }
    },
    {
        "translation": {
            "en": "Again, assume both models use a threshold of > 0.5 for the idiom class.",
            "zh": "同样，假设两个模型都对习语类使用阈值 > 0.5。"
        }
    },
    {
        "translation": {
            "en": "These new generated features can then replace the original descriptive features in an ABT for later tasks in a pipeline, for example, training a supervised machine learning model.",
            "zh": "然后，这些新生成的特征可以替换 ABT 中的原始描述性特征，用于管道中的后续任务，例如，训练监督机器学习模型。"
        }
    },
    {
        "translation": {
            "en": "(2008) report empirical evaluations of the accuracy of a range of model types across a range of domains.",
            "zh": "（2008）报告了对一系列模型类型在一系列领域的准确性的实证评估。"
        }
    },
    {
        "translation": {
            "en": "AMBIENT TEMPERATURE",
            "zh": "环境温度"
        }
    },
    {
        "translation": {
            "en": "Figure 7.8[335] shows the journey across the error surface and related plot of the sums of squared errors for the office rentals problem—using just the SIZE descriptive feature—when error decay is used with α0 = 0.18 and c = 10 (this is a pretty simple problem, so smaller values for these parameters are suitable).",
            "zh": "图 7.8[335] 显示了当误差衰减与 α0 = 0.18 和 c = 10 一起使用时，仅使用 SIZE 描述性特征时，办公室租赁问题的误差面和平方总和的相关图（这是一个非常简单的问题，因此这些参数的较小值是合适的）。"
        }
    },
    {
        "translation": {
            "en": "Rice, John A. 2006. Mathematical statistics and data analysis. Cengage Learning.",
            "zh": "赖斯，约翰 A. 2006 年。数理统计和数据分析。圣智学习。"
        }
    },
    {
        "translation": {
            "en": "INFANT MORT., the number of infant deaths per 1,000 births",
            "zh": "INFANT MORT.，每1000名新生儿的婴儿死亡人数"
        }
    },
    {
        "translation": {
            "en": "Figure 4.18[156] illustrates a decision tree that has been trained for this post-operative patient routing task.",
            "zh": "图 4.18[156] 说明了已针对此术后患者路由任务训练的决策树。"
        }
    },
    {
        "translation": {
            "en": "The query instance value for this feature is true, and so on the basis of the result of the test at this node, the process descends the left branch, labeled true, to a leaf node labeled spam.",
            "zh": "此功能的查询实例值为 true，因此，根据此节点上的测试结果，该进程将标记为 true 的左侧分支下降到标记为 spam 的叶节点。"
        }
    },
    {
        "translation": {
            "en": "The simple multivariable linear regression (Section 7.3[319]) model (for convenience, repeated here as Equation (7.48)[367]) makes a prediction for a continuous target feature based on a weighted sum of the values of a set of descriptive features.",
            "zh": "简单的多变量线性回归（第 7.3 节[319]）模型（为方便起见，此处重复为方程 （7.48）[367]）基于一组描述性特征值的加权和对连续目标特征进行预测。"
        }
    },
    {
        "translation": {
            "en": "This dataset contained 600,000 rows and 547 columns,9 with one row for each galaxy observation, containing identifiers, position information, and measures describing the characteristics of the galaxy.",
            "zh": "该数据集包含 600,000 行和 547 列，9 每个星系观测一行，包含标识符、位置信息和描述星系特征的度量。"
        }
    },
    {
        "translation": {
            "en": "Also, in domains where the causal relationships between features are known, Bayesian networks have the advantage of providing a natural framework for integrating expert human knowledge with data-driven induction.",
            "zh": "此外，在已知特征之间因果关系的领域中，贝叶斯网络的优势在于提供了一个自然的框架，用于将专家人类知识与数据驱动的归纳相结合。"
        }
    },
    {
        "translation": {
            "en": "An average class accuracy performance measure, however, brings this issue to the fore.",
            "zh": "然而，平均类准确性性能测量使这个问题凸显出来。"
        }
    },
    {
        "translation": {
            "en": "This neuron receives nin inputs d1,…,dnin (note that for this discussion we ignore the bias input and weight, and we drop the layer (k) superscript when we are discussing a single neuron).",
            "zh": "该神经元接收 nin 输入 d1,...,dnin（请注意，在本次讨论中，我们忽略了偏差输入和权重，并且在讨论单个神经元时会删除层 （k） 上标）。"
        }
    },
    {
        "translation": {
            "en": "The solid vertical line in (b) plots the decision boundary for d that gives the minimum misclassification rate assuming uniform prior for the two target levels (i.e., P(t = l1) = P(t = l2)).",
            "zh": "（b）中的垂直实线绘制了d的决策边界，该边界给出了最小误分类率，假设两个目标水平的先验一致（即P（t = l1） = P（t = l2））。"
        }
    },
    {
        "translation": {
            "en": "It is evident that the instances are getting farther and farther away from each other, and the feature space is becoming very sparsely populated, with relatively large areas where there are no or very few instances.",
            "zh": "很明显，实例之间的距离越来越远，要素空间的人口变得非常稀少，没有实例或实例很少的区域相对较大。"
        }
    },
    {
        "translation": {
            "en": "An unusually large or small value like this is referred to as an outlier, and the arithmetic mean is very sensitive to the presence of outliers.",
            "zh": "像这样的异常大或小的值称为异常值，算术平均值对异常值的存在非常敏感。"
        }
    },
    {
        "translation": {
            "en": "P_EDGE",
            "zh": "P_EDGE"
        }
    },
    {
        "translation": {
            "en": "An extended version of the generators dataset from Table 7.6[339].",
            "zh": "表7.6[339]中生成器数据集的扩展版本。"
        }
    },
    {
        "translation": {
            "en": "child node, 286",
            "zh": "子节点，286"
        }
    },
    {
        "translation": {
            "en": "SCHOOL YEARS, the mean number years spent in school by adult females",
            "zh": "学龄，成年女性在校的平均年限"
        }
    },
    {
        "translation": {
            "en": "Although in some applications the target feature is a raw value copied directly from an existing data source, in many others it must be derived.",
            "zh": "尽管在某些应用程序中，目标特征是直接从现有数据源复制的原始值，但在许多其他应用程序中，它必须派生出来。"
        }
    },
    {
        "translation": {
            "en": "Many argue that performing this type of transformation may remove the most interesting and, from a predictive modeling point of view, informative instances from a dataset.",
            "zh": "许多人认为，执行这种类型的转换可能会从数据集中删除最有趣的，并且从预测建模的角度来看，信息量最大的实例。"
        }
    },
    {
        "translation": {
            "en": "Throughout our worked example using the college athlete dataset, the top-right corner of the feature space contained a no region (see Figure 5.4[190]).",
            "zh": "在我们使用大学运动员数据集的工作示例中，特征空间的右上角包含一个 no 区域（参见图 5.4[190]）。"
        }
    },
    {
        "translation": {
            "en": "Capacity for retraining: In Section 9.4.6[578] we discussed approaches that can be used to monitor the performance of a model so as to flag the occurrence of concept drift and indicate if a model has gone stale.",
            "zh": "再训练能力：在第 9.4.6[578] 节中，我们讨论了可用于监控模型性能的方法，以便标记概念漂移的发生并指示模型是否过时。"
        }
    },
    {
        "translation": {
            "en": "These customers were deemed to be at risk of churning in the coming month, so the customer retention team set about contacting them with a special offer.",
            "zh": "这些客户被认为在下个月有流失的风险，因此客户保留团队开始与他们联系，提供特别优惠。"
        }
    },
    {
        "translation": {
            "en": "8. The primary papers introducing k-d trees are Bentley (1975) and Friedman et al. (1977). Also note that the k here has no relationship with the k used in k nearest neighbor. It simply specifies the number of levels in the depth of the tree, which is arbitrary and typically determined by the algorithm that constructs the tree.",
            "zh": "8. 介绍k-d树的主要论文是Bentley（1975）和Friedman等人（1977）。另请注意，此处的 k 与 k 最近邻中使用的 k 没有关系。它只是指定树深度中的级别数，这是任意的，通常由构造树的算法确定。"
        }
    },
    {
        "translation": {
            "en": "The first thing to consider in regard to data is whether the target feature is continuous or categorical.",
            "zh": "关于数据，首先要考虑的是目标特征是连续的还是分类的。"
        }
    },
    {
        "translation": {
            "en": "As a result, the algorithm tends toward the majority target level in the dataset.",
            "zh": "因此，该算法倾向于数据集中的多数目标水平。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.106)[509] defines the calculation of the forget mask for time-step t, and Equation (8.107)[509] defines the filtering of the cell state by the forget mask.",
            "zh": "方程（8.106）[509]定义了时间步长t的遗忘掩码的计算，等式（8.107）[509]定义了遗忘掩码对单元状态的滤波。"
        }
    },
    {
        "translation": {
            "en": "0.04",
            "zh": "0.04"
        }
    },
    {
        "translation": {
            "en": "Figure 3.1",
            "zh": "图 3.1"
        }
    },
    {
        "translation": {
            "en": "SPLOM, 74",
            "zh": "斯普洛姆，74"
        }
    },
    {
        "translation": {
            "en": "20.500",
            "zh": "20.500"
        }
    },
    {
        "translation": {
            "en": "Brockman, Greg, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. arXiv:1606.01540.",
            "zh": "布罗克曼、格雷格、张薇琪、路德维希·佩特森、乔纳斯·施耐德、约翰·舒尔曼、唐杰和沃伊切赫·扎伦巴。2016. OpenAI 健身房。arXiv：1606.01540。"
        }
    },
    {
        "translation": {
            "en": "It might, at first, seem like all is lost and that it will be impossible for the hiker to find her way down to the bottom of the valley.",
            "zh": "乍一看，似乎一切都失去了，徒步旅行者不可能找到通往谷底的路。"
        }
    },
    {
        "translation": {
            "en": "The consultant generated the following data quality report from the ABT (visualizations of binary features have been omitted for space saving).",
            "zh": "顾问从 ABT 生成了以下数据质量报告（为了节省空间，省略了二进制特征的可视化）。"
        }
    },
    {
        "translation": {
            "en": "2. the rate of change of the activation of the neuron with respect to changes in the weighted sum calculated at the neuron: ∂ak/∂zk.",
            "zh": "2. 神经元激活相对于在神经元处计算的加权和变化的变化率：∂ak/∂zk。"
        }
    },
    {
        "translation": {
            "en": "Conversely, in batch gradient descent, assuming we process all the training examples in parallel, we complete a single epoch in each iteration of the algorithm and so there is a single weight update per epoch.",
            "zh": "相反，在批量梯度下降中，假设我们并行处理所有训练示例，我们在算法的每次迭代中完成一个 epoch，因此每个 epoch 都有一个权重更新。"
        }
    },
    {
        "translation": {
            "en": "A fork in computational flow during forward propagation results in the same activation vector flowing in two directions, with each path generating error gradients that must be merged in the backpropagation stage.",
            "zh": "在前向传播过程中，计算流的分叉会导致相同的激活向量在两个方向上流动，每条路径都会产生必须在反向传播阶段合并的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2000. Additive logistic regression: A statistical view of boosting. The Annals of Statistics 28 (2): 337–407.",
            "zh": "弗里德曼、杰罗姆、特雷弗·哈斯蒂和罗伯特·蒂布希拉尼。2000. 加性逻辑回归：提升的统计观点.统计年鉴28（2）：337-407。"
        }
    },
    {
        "translation": {
            "en": "13.6   Deployment",
            "zh": "13.6 部署"
        }
    },
    {
        "translation": {
            "en": "Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. 2011. Deep sparse rectifier neural networks. In Proceedings of the fourteenth international conference on artificial intelligence and statistics (AISTATS), 315–323. JMLR.",
            "zh": "格洛罗特、泽维尔、安托万·博尔德斯和约书亚·本吉奥。2011. 深度稀疏整流器神经网络.第十四届人工智能与统计国际会议（AISTATS）论文集，第315-323页。JMLR。"
        }
    },
    {
        "translation": {
            "en": "Figure C.2(d)[767] shows this example function and its derivative calculated using the chain rule.",
            "zh": "图C.2（d）[767]显示了使用链式法则计算的示例函数及其导数。"
        }
    },
    {
        "translation": {
            "en": "Table 8.6",
            "zh": "表 8.6"
        }
    },
    {
        "translation": {
            "en": "The data quality report is the most important tool of the data exploration process.",
            "zh": "数据质量报告是数据探索过程中最重要的工具。"
        }
    },
    {
        "translation": {
            "en": "It would most likely be possible to create a model that could distinguish between the clockwise and anti-clockwise spiral galaxies, but this would probably require the calculation of new features based on the application of image processing techniques to the raw galaxy images.",
            "zh": "最有可能创建一个可以区分顺时针和逆时针螺旋星系的模型，但这可能需要根据图像处理技术对原始星系图像的应用来计算新特征。"
        }
    },
    {
        "translation": {
            "en": "Different margins that satisfy the constraint in Equation (7.44)[364], the instances that define the margin are highlighted in each case; (b) shows the maximum margin and also shows two query instances represented as black dots.",
            "zh": "满足等式（7.44）[364]中约束条件的不同边距，定义边距的实例在每种情况下都突出显示;（b） 显示最大边距，并显示两个表示为黑点的查询实例。"
        }
    },
    {
        "translation": {
            "en": "Schwartz, Paul M. 2010. Data protection law and the ethical use of analytics, Technical report, The Centre for Information Policy Leadership (at Hunton & Williams LLP).",
            "zh": "施瓦茨，保罗 M. 2010 年。数据保护法和分析的道德使用，技术报告，信息政策领导中心（Hunton & Williams LLP）。"
        }
    },
    {
        "translation": {
            "en": "D.4 Summary",
            "zh": "D.4 概述"
        }
    },
    {
        "translation": {
            "en": "reinforcement learning, xvi, 5, 20, 637, 638, 674, 740",
            "zh": "强化学习， xvi， 5， 20， 637， 638， 674， 740"
        }
    },
    {
        "translation": {
            "en": "Similarly, if the gap between the 1st quartile and the minimum value is noticeably larger than the gap between the median and the 1st quartile, this suggests that the minimum value is unusual and is likely to be an outlier.",
            "zh": "同样，如果第 1 个四分位数和最小值之间的差距明显大于中位数和第 1 个四分位数之间的差距，则表明最小值是不寻常的，并且可能是一个异常值。"
        }
    },
    {
        "translation": {
            "en": "Model ensembles are among the most powerful machine learning algorithms; Caruana and Niculescu-Mizil (2006) report a large-scale comparison between seven different types of prediction model in which bagged and boosted tree ensembles are reported as among the best-performing.",
            "zh": "模型集成是最强大的机器学习算法之一;Caruana和Niculescu-Mizil（2006）报告了七种不同类型的预测模型之间的大规模比较，其中袋装和提升的树木集合被报告为表现最好的模型之一。"
        }
    },
    {
        "translation": {
            "en": "Where appropriate, conditional independence not only simplifies the calculations but also enables us to compactly represent the full joint probability distribution for a domain. Rather than calculating and storing the probabilities of all the joint events in a domain, we can break up the distribution into data structures called factors, which define distributions over subsets of features. We can then compute any of the probabilities in the joint probability distribution using the product of these factors.",
            "zh": "在适当的情况下，条件独立性不仅简化了计算，而且使我们能够紧凑地表示域的完整联合概率分布。我们可以将分布分解为称为因子的数据结构，而不是计算和存储域中所有联合事件的概率，这些数据结构定义特征子集的分布。然后，我们可以使用这些因子的乘积计算联合概率分布中的任何概率。"
        }
    },
    {
        "translation": {
            "en": "We will see as we proceed through this book that the selection of a machine learning algorithm is not the only way that we can bias the predictive data analytics process.",
            "zh": "在继续阅读本书的过程中，我们将看到，选择机器学习算法并不是我们偏向预测数据分析过程的唯一方法。"
        }
    },
    {
        "translation": {
            "en": "32. See Mitchell (1997, pp. 164–167).",
            "zh": "32. 参见Mitchell（1997年，第164-167页）。"
        }
    },
    {
        "translation": {
            "en": "Classifying galaxies according to galaxy morphology is standard practice in astronomy,3 and morphological categories have been shown to be strongly correlated with other important galaxy features.",
            "zh": "根据星系形态对星系进行分类是天文学的标准做法，3 形态学类别已被证明与其他重要的星系特征密切相关。"
        }
    },
    {
        "translation": {
            "en": "For example, we could have used four 500-unit intervals to generate the histogram instead—see Figure A.7(b)[754], based on frequencies from Table A.4(b)[755]—or, indeed, any other set of intervals.",
            "zh": "例如，我们可以使用四个 500 单位的区间来生成直方图——参见图 A.7（b）[754]，基于表 A.4（b）[755] 中的频率——或者，实际上，任何其他区间集。"
        }
    },
    {
        "translation": {
            "en": "(b) A simple approach to adapting a logistic regression model to learn this type of decision boundary is to introduce a set of basis functions that will allow a non-linear decision boundary to be learned. In this case, a set of basis functions that generate a cubic decision boundary will work well. An appropriate set of basis functions is as follows:",
            "zh": "（b） 调整逻辑回归模型以学习这种决策边界的一种简单方法是引入一组基础函数，这些函数将允许学习非线性决策边界。在这种情况下，一组生成三次决策边界的基函数将很好地工作。一组适当的基函数如下所示："
        }
    },
    {
        "translation": {
            "en": "Figure 8.31",
            "zh": "图 8.31"
        }
    },
    {
        "translation": {
            "en": "If the p-value is less than the required significance level, typically 0.05, we reject the null hypothesis and say that the descriptive feature has a significant impact on the model; otherwise we say that it does not.",
            "zh": "如果 p 值小于所需的显著性水平（通常为 0.05），则我们拒绝原假设，并说描述性特征对模型有显著影响;否则我们说它没有。"
        }
    },
    {
        "translation": {
            "en": "27. This question is inspired by the work reported in Klubička et al. (2018).",
            "zh": "27. 这个问题的灵感来自Klubička等人（2018年）报告的工作。"
        }
    },
    {
        "translation": {
            "en": "3. The example given here is based on artificial data generated for the purposes of this book. Performing customer segmentation in this way, however, is very common (see, for example, Berry and Linoff (2004)).",
            "zh": "3. 这里给出的例子是基于为本书的目的而生成的人工数据。然而，以这种方式进行客户细分是很常见的（例如，参见Berry and Linoff （2004））。"
        }
    },
    {
        "translation": {
            "en": "OCCUPATION (transport = works in the transportation industry; professional = doctor, lawyer, or similar; agriculture = works in the agricultural industry; armed forces = is a member of the armed forces); and",
            "zh": "职业（运输=运输业工作;专业=医生、律师或类似行业;农业=农业工作;武装部队=是武装部队成员）;和"
        }
    },
    {
        "translation": {
            "en": "This is the standard calculation we would use to calculate the δ for any hidden neuron, see Equation (8.23)[412], with the slight simplification that, as mentioned previously, the gradient of the activation function ∂ac/∂zC = 1. We calculate the δs for the other neurons in the sub-sampling layer in a similar fashion.",
            "zh": "这是我们用来计算任何隐藏神经元δ的标准计算，参见方程（8.23）[412]，如前所述，稍微简化为激活函数的梯度∂ac/∂zC = 1。我们以类似的方式计算子采样层中其他神经元的δs。"
        }
    },
    {
        "translation": {
            "en": "(c) The precision, recall, and F1 measure",
            "zh": "（c） 精度、召回率和 F1 测量值"
        }
    },
    {
        "translation": {
            "en": "K-S chart, 563",
            "zh": "K-S 图表，563"
        }
    },
    {
        "translation": {
            "en": "4. The following diagram shows a decision tree for the task of predicting heart disease.39 The descriptive features in this domain describe whether the patient suffers from chest pain (CHEST PAIN) and the blood pressure of the patient (BLOOD PRESSURE). The binary target feature is HEART DISEASE. The table beside the diagram lists a pruning set from this domain.",
            "zh": "4. 下图显示了预测心脏病任务的决策树.39 该领域的描述性特征描述了患者是否患有胸痛 （CHEST PAIN） 和患者的血压 （BLOOD PRESSURE）。二元目标特征是 HEART DISEASE。图旁边的表格列出了此域中的修剪集。"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning as a single-step process.",
            "zh": "无监督机器学习是一个单步过程。"
        }
    },
    {
        "translation": {
            "en": "9.2   Hold-out sampling can divide the full data into training, validation, and test sets.",
            "zh": "9.2 保持抽样可以将完整数据分为训练集、验证集和测试集。"
        }
    },
    {
        "translation": {
            "en": "After watching the dealer play 30 games with other players, you notice that he has a tendency to drop the queen in the position on the right (19 times) more than the left (3 times) or center (8 times). Based on this, you update your beliefs about where the queen is likely to land based on the evidence that you have collected. This is shown in Figure 6.1(d)[244], where the bars have been redistributed to illustrate the revised likelihoods.",
            "zh": "在观看庄家与其他玩家玩 30 场比赛后，您注意到他倾向于将皇后放在右侧位置（19 次）而不是左侧（3 次）或中间（8 次）。基于此，你根据你收集的证据更新了你对女王可能降落地点的信念。如图6.1（d）[244]所示，其中条形图已重新分布，以说明修订后的可能性。"
        }
    },
    {
        "translation": {
            "en": "Samet (1990) gives an introduction to r-trees and other related approaches.",
            "zh": "Samet（1990）介绍了r树和其他相关方法。"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.13(b)[90] there are 14 bins.",
            "zh": "在图3.13（b）[90]中，有14个箱。"
        }
    },
    {
        "translation": {
            "en": "From this plot we can get a concise, but detailed, description of the feature and notice the inclusion of an outlier value.",
            "zh": "从此图中，我们可以得到一个简洁但详细的特征描述，并注意到包含一个异常值。"
        }
    },
    {
        "translation": {
            "en": "For example, Hand and Anagnostopoulos (2013) discusses issues with the use of the ROC index.",
            "zh": "例如，Hand and Anagnostopoulos （2013） 讨论了使用 ROC 指数的问题。"
        }
    },
    {
        "translation": {
            "en": "In upcoming chapters we use normalization to prepare data for use with machine learning algorithms that require descriptive features to be in particular ranges. As is so often the case in data analytics, there is no hard and fast rule that says which is the best normalization technique, and this decision is generally made based on experimentation.",
            "zh": "在接下来的章节中，我们将使用归一化来准备数据，以便与机器学习算法一起使用，这些算法要求描述性特征在特定范围内。正如数据分析中经常出现的情况一样，没有硬性规定哪种是最好的归一化技术，并且通常根据实验做出此决定。"
        }
    },
    {
        "translation": {
            "en": "6.4.4 Bayesian Networks",
            "zh": "6.4.4 贝叶斯网络"
        }
    },
    {
        "translation": {
            "en": "18. The featuresselected were AE_I, APERFLUX7IVAR_R, CMODELFLUXIVAR_U, DEVABERR_G, DEVABERR_Z, DEVAB_G, DEVAB_I, DEVFLUXIVAR_U, DEVMAGERR_U, DEVRAD_G, DEVRAD_U, DEREDDIFF_U_G, EXPABERR_U, EXPAB_G, EXPMAG_Z, EXPRADERR_U, FIBER2FLUXIVAR_R, FIBER2MAG_I, FIBERFLUXIVAR_G, FIBERFLUX_G, FIBERFLUX_R, FIBERFLUX_Z, LNLDEV_R, MCR4_Z, ME1E1ERR_Z, ME1_U, MODELMAGDIFF_R_I, PETROMAGDIFF_R_I, PETROR90_R, PSFMAG_U, SKYIVAR_U, and U_R.",
            "zh": "18. 选择的特征是AE_I、APERFLUX7IVAR_R、CMODELFLUXIVAR_U、DEVABERR_G、DEVABERR_Z、DEVAB_G、DEVAB_I、DEVFLUXIVAR_U、DEVMAGERR_U、DEVRAD_G、DEVRAD_U、DEREDDIFF_U_G、EXPABERR_U、EXPAB_G、EXPMAG_Z、EXPRADERR_U、FIBER2FLUXIVAR_R、FIBER2MAG_I、FIBERFLUXIVAR_G、FIBERFLUX_G、FIBERFLUX_R、FIBERFLUX_Z、LNLDEV_R、MCR4_Z、ME1E1ERR_Z、ME1_U、 MODELMAGDIFF_R_I、PETROMAGDIFF_R_I、PETROR90_R、PSFMAG_U、SKYIVAR_U和U_R。"
        }
    },
    {
        "translation": {
            "en": "16. It is also common to use a minimum partition variance as an early stopping criterion. If the variance in the partition being processed is below a set threshold, then the algorithm will not partition the data and will instead create a leaf node.",
            "zh": "16. 使用最小分区方差作为早期停止标准也很常见。如果正在处理的分区中的方差低于设定的阈值，则算法不会对数据进行分区，而是创建叶节点。"
        }
    },
    {
        "translation": {
            "en": "Tijms, Henk. 2012. Understanding probability. Cambridge University Press.",
            "zh": "蒂姆斯，亨克。2012. 理解概率.剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "batches, 391, 417",
            "zh": "批次，391,417"
        }
    },
    {
        "translation": {
            "en": "These tell us the most common levels within these features and will identify if any levels dominate the dataset (these levels will have a very high mode %).",
            "zh": "这些告诉我们这些特征中最常见的级别，并将确定是否有任何级别在数据集中占主导地位（这些级别将具有非常高的模式%）。"
        }
    },
    {
        "translation": {
            "en": "In the early part of this chapter, we focus on categorical features, but we return to continuous features in Section 6.4[265].",
            "zh": "在本章的开头部分，我们专注于分类特征，但我们回到了第 6.4 节中的连续特征[265]。"
        }
    },
    {
        "translation": {
            "en": "One of the biggest challenges in training a deep neural network is to ensure that the flow of error gradients back through the layers of a network is stable during training.",
            "zh": "训练深度神经网络的最大挑战之一是确保在训练期间，通过网络层的误差梯度流是稳定的。"
        }
    },
    {
        "translation": {
            "en": "Although the error value at this point in the weight space can be calculated, we know little else about the relative position of this point on the error surface.",
            "zh": "虽然可以计算出权重空间中该点的误差值，但我们对这个点在误差曲面上的相对位置知之甚少。"
        }
    },
    {
        "translation": {
            "en": "maximum likelihood, 301",
            "zh": "最大似然，301"
        }
    },
    {
        "translation": {
            "en": "2.3.1 Case Study: Motor Insurance Fraud",
            "zh": "2.3.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Another way to make models robust to outliers is to train the models to predict only the sign of the errors of the previous predictions rather than the magnitudes of the errors; this is a frequently used adjustment.",
            "zh": "使模型对异常值具有鲁棒性的另一种方法是训练模型仅预测先前预测的误差符号，而不是误差的大小;这是一个常用的调整。"
        }
    },
    {
        "translation": {
            "en": "They generally work very well on data that has a grid-like structure and in which the low-level features in the data have a local extent.",
            "zh": "它们通常适用于具有网格状结构的数据，并且数据中的低级要素具有局部范围。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this case would be the level of blood-thinning desired, demographic details for the patient, and the results of various medical tests performed on the patient.",
            "zh": "在这种情况下，描述性特征是所需的血液稀释水平、患者的人口统计学详细信息以及对患者进行的各种医学检查的结果。"
        }
    },
    {
        "translation": {
            "en": "loss given default, 554",
            "zh": "违约损失，554"
        }
    },
    {
        "translation": {
            "en": "30.59",
            "zh": "30.59"
        }
    },
    {
        "translation": {
            "en": "Next we calculate ∂ℰ/∂ct.",
            "zh": "接下来我们计算 ∂E/∂ct。"
        }
    },
    {
        "translation": {
            "en": "This means that di doesn’t really belong to the cluster in which it has been placed.",
            "zh": "这意味着 di 实际上并不属于放置它的集群。"
        }
    },
    {
        "translation": {
            "en": "Overall the Euclidean distance weights features with larger differences in values more than features with smaller differences in values.",
            "zh": "总体而言，欧几里得距离对值差异较大的特征进行加权，对值差异较大的特征进行加权。"
        }
    },
    {
        "translation": {
            "en": "AGE: The age of the person screened.",
            "zh": "年龄：被筛查者的年龄。"
        }
    },
    {
        "translation": {
            "en": "Part V of the book contains appendices covering background material required to support the content of the other chapters of the book. This includes descriptive statistics and data visualization (Appendix A), probability (Appendix B), differentiation (Appendix C), and linear algebra (Appendix D).",
            "zh": "本书的第五部分包含附录，涵盖了支持本书其他章节内容所需的背景材料。这包括描述性统计和数据可视化（附录 A）、概率（附录 B）、微分（附录 C）和线性代数（附录 D）。"
        }
    },
    {
        "translation": {
            "en": "0.5012",
            "zh": "0.5012"
        }
    },
    {
        "translation": {
            "en": "All the values of acceleration have been calculated in this way.",
            "zh": "所有加速度值都是以这种方式计算的。"
        }
    },
    {
        "translation": {
            "en": "data exploration, 34, 53, 94",
            "zh": "数据探索， 34， 53， 94"
        }
    },
    {
        "translation": {
            "en": "The final example of a data quality issue due to an irregular cardinality is when a categorical feature simply has a very high number of levels—anything over 50 is worth investigation.",
            "zh": "由于不规则基数导致的数据质量问题的最后一个例子是，当分类特征具有非常高的级别数时，任何超过 50 的级别都值得调查。"
        }
    },
    {
        "translation": {
            "en": "Sutton, Richard S., and Andrew G. Barto. 1998. Reinforcement learning: An introduction. MIT Press.",
            "zh": "萨顿、理查德 S. 和安德鲁 G. 巴托。1998. 强化学习：简介.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "This section covers a selection of the most important performance measures. We also describe different experimental designs for evaluating prediction models and ways to monitor model performance after a model has been deployed.",
            "zh": "本节介绍一些最重要的绩效指标。我们还描述了用于评估预测模型的不同实验设计，以及在部署模型后监控模型性能的方法。"
        }
    },
    {
        "translation": {
            "en": "3.7   The details of a professional basketball team.",
            "zh": "3.7 职业篮球队的细节。"
        }
    },
    {
        "translation": {
            "en": "Stewart, James. 2012. Calculus, 7th ed. Cengage Learning.",
            "zh": "斯图尔特，詹姆斯。2012. 微积分，第 7 版。"
        }
    },
    {
        "translation": {
            "en": "We refer to measures of similarity of this type as indexes.",
            "zh": "我们将这种类型的相似度量称为索引。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn’s first step in fully understanding the data available to her was to define the prediction subject.",
            "zh": "Jocelyn 充分了解她可用的数据的第一步是定义预测主题。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.3)[386] defines how the McCulloch and Pitts neuron, or perceptron network, maps an input vector to an output activation.",
            "zh": "方程（8.3）[386]定义了McCulloch和Pitts神经元或感知器网络如何将输入向量映射到输出激活。"
        }
    },
    {
        "translation": {
            "en": "There are no fixed recommendations for how large the different datasets should be when hold-out sampling is used, although training:validation:test splits of 50:20:30 or 40:20:40 are common.",
            "zh": "对于使用保持抽样时不同数据集的大小，没有固定的建议，尽管 50：20：30 或 40：20：40 的 training：validation：test 拆分很常见。"
        }
    },
    {
        "translation": {
            "en": "This meant that the data available at the SDSS did not contain a suitable target feature that Jocelyn could use to train prediction models.",
            "zh": "这意味着 SDSS 上可用的数据不包含 Jocelyn 可用于训练预测模型的合适目标特征。"
        }
    },
    {
        "translation": {
            "en": "For example, knowing that there is an eye in the top-left region of an image is useful for face recognition, but the extra precision of knowing that it is centered at pixel (998,742) may not be useful.",
            "zh": "例如，知道图像的左上角区域有一只眼睛对于面部识别很有用，但知道它以像素 （998,742） 为中心的额外精度可能没有用。"
        }
    },
    {
        "translation": {
            "en": "The LOAN AMOUNT continuous feature discretized into four equal-frequency bins.",
            "zh": "LOAN AMOUNT 连续特征离散化为四个等频箱。"
        }
    },
    {
        "translation": {
            "en": "18. This guided search process is similar to the gradient descent search we use to fit our regression models in Chapter 7[311]. Many data analytics packages and programming APIs provide functions that implement methods to fit a distribution to a dataset.",
            "zh": "18. 这种引导式搜索过程类似于我们在第 7 章[311] 中用于拟合回归模型的梯度下降搜索。许多数据分析包和编程 API 都提供函数，这些函数实现将分布拟合到数据集的方法。"
        }
    },
    {
        "translation": {
            "en": "(b) There is a cost associated with each item presented to the human annotator, and the company wants to maximize the number of items that end up in the dictionary.",
            "zh": "（b） 呈现给人工注释员的每个项目都有相关的成本，公司希望最大限度地增加最终出现在字典中的项目数量。"
        }
    },
    {
        "translation": {
            "en": "9.20   The expected target values for a test set, the predictions made by a model, and the resulting errors based on these predictions for a blood-thinning drug dosage prediction problem.",
            "zh": "9.20 测试集的预期目标值、模型的预测以及基于这些预测得出的血液稀释药物剂量预测问题的错误。"
        }
    },
    {
        "translation": {
            "en": "This is in contrast to Q-learning, which always assumes the action with the highest expected return will be chosen when computing the update.",
            "zh": "这与Q-learning形成鲜明对比，Q-learning在计算更新时总是假设将选择具有最高预期回报的操作。"
        }
    },
    {
        "translation": {
            "en": "As such, the prediction for the query instance should be yes.",
            "zh": "因此，查询实例的预测应为 yes。"
        }
    },
    {
        "translation": {
            "en": "11.4.1   SARSA, On-Policy Temporal-Difference Learning",
            "zh": "11.4.1 SARSA，政策时间差异学习"
        }
    },
    {
        "translation": {
            "en": "EXPRAD_U/G/R/I/Z",
            "zh": "EXPRAD_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The number of retention offers the customer has accepted",
            "zh": "客户已接受的保留产品/服务数"
        }
    },
    {
        "translation": {
            "en": "Also, Neuron B is a ReLU and so ∂aB/∂zB = 1 because aB > 0",
            "zh": "此外，神经元 B 是 ReLU，因此 ∂aB/∂zB = 1，因为 aB > 0"
        }
    },
    {
        "translation": {
            "en": "data-driven decisions, 19",
            "zh": "数据驱动型决策，19"
        }
    },
    {
        "translation": {
            "en": "The distance between each of these single-instance clusters is then calculated (in this example Euclidean distance is used).",
            "zh": "然后计算每个单实例集群之间的距离（在本例中，使用欧几里得距离）。"
        }
    },
    {
        "translation": {
            "en": "marginalization, 761",
            "zh": "边缘化，761"
        }
    },
    {
        "translation": {
            "en": "At their first attempt, new surfers will typically position themselves either too far forward or too far backward on their board when they attempt to catch their first wave, resulting in a bad outcome.",
            "zh": "在第一次尝试时，新冲浪者在尝试捕捉第一波冲浪时，通常会将自己的位置放在板上太靠前或太靠后，从而导致糟糕的结果。"
        }
    },
    {
        "translation": {
            "en": "The dashed lines on either side of the decision boundary show the extent of the margin, and we refer to these as the margin extents.",
            "zh": "决策边界两侧的虚线表示边距范围，我们将这些虚线称为边距范围。"
        }
    },
    {
        "translation": {
            "en": "False Negative (FN): an instance in the test set that had a positive target feature value but that was predicted to have a negative target feature value",
            "zh": "假阴性 （FN）：测试集中具有正目标特征值但预测具有负目标特征值的实例"
        }
    },
    {
        "translation": {
            "en": "Consequently, the performance of the model on the test set is a better measure of how the model is likely to perform when actually deployed and shows how well the model can generalize beyond the instances used to train it.",
            "zh": "因此，模型在测试集上的性能可以更好地衡量模型在实际部署时可能执行的性能，并显示模型在用于训练它的实例之外的泛化程度。"
        }
    },
    {
        "translation": {
            "en": "This deviation from the norm was investigated with the business, and it turned out that although these figures were correct, this policy was actually a company policy rather than an individual policy, which was included in the ABT by mistake.",
            "zh": "与企业一起调查了这种偏离规范的情况，结果发现，尽管这些数字是正确的，但该政策实际上是公司政策而不是个人政策，错误地包含在 ABT 中。"
        }
    },
    {
        "translation": {
            "en": "The final vegetation classification decision tree.",
            "zh": "最终的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "CART, 169",
            "zh": "手推车， 169"
        }
    },
    {
        "translation": {
            "en": "8.3   Standard Approach: Backpropagation and Gradient Descent",
            "zh": "8.3 标准方法：反向传播和梯度下降"
        }
    },
    {
        "translation": {
            "en": "AHC, 618",
            "zh": "AHC，618"
        }
    },
    {
        "translation": {
            "en": "NEURON",
            "zh": "神经元"
        }
    },
    {
        "translation": {
            "en": "Reward is often delayed, and the real value of an action is not reflected immediately but rather by the fact that an action takes us toward a later state that will ultimately allow an agent to earn a reward.",
            "zh": "奖励经常被延迟，一个行动的真正价值不会立即反映出来，而是通过一个行动将我们带入一个最终允许代理人获得奖励的后期状态这一事实。"
        }
    },
    {
        "translation": {
            "en": "The other unsupervised machine learning use case covered in this chapter was representation learning.",
            "zh": "本章介绍的另一个无监督机器学习用例是表示学习。"
        }
    },
    {
        "translation": {
            "en": "To illustrate a series of similarity indexes for binary descriptive features, we will use an example of predicting upsell in an online service.",
            "zh": "为了说明二进制描述性特征的一系列相似性指数，我们将使用一个预测在线服务中的追加销售的示例。"
        }
    },
    {
        "translation": {
            "en": "If the training sample covered a period in the summer and the testing sample covered a period in the winter, the results of any evaluation would not provide a reliable measure of how likely the model might actually perform when deployed.",
            "zh": "如果训练样本覆盖了夏季的一段时间，而测试样本覆盖了冬季的一段时间，则任何评估的结果都无法可靠地衡量模型在部署时实际执行的可能性。"
        }
    },
    {
        "translation": {
            "en": "Today some deep networks have tens or even hundreds of layers.",
            "zh": "今天，一些深度网络有几十层甚至几百层。"
        }
    },
    {
        "translation": {
            "en": "This is similar to the way we summed the weight updates for a weight during batch training (see Equation (8.30)[416]); the difference here is that for each training example we sum over the weight updates for each neuron that uses the weight (as opposed to weight updates for different training examples).",
            "zh": "这类似于我们在批量训练期间对权重更新进行权重更新求和的方式（参见公式（8.30）[416]）;这里的区别在于，对于每个训练示例，我们将使用权重的每个神经元的权重更新相加（而不是不同训练示例的权重更新）。"
        }
    },
    {
        "translation": {
            "en": "There are, though, a range of ways in which models can be incorrect, and different analytics projects will emphasize some over others.",
            "zh": "但是，模型可能以多种方式不正确，不同的分析项目会强调某些方法而不是其他方法。"
        }
    },
    {
        "translation": {
            "en": "Table 6.12",
            "zh": "表 6.12"
        }
    },
    {
        "translation": {
            "en": "The second term in the product in Equation (8.72)[467] is the rate of change of the predicted probability for the true category with respect to the logit for one of the neurons in the softmax layer.",
            "zh": "等式（8.72）[467]中乘积中的第二项是真实类别的预测概率相对于softmax层中一个神经元的logit的变化率。"
        }
    },
    {
        "translation": {
            "en": "In this example we assume that the hidden neurons and the output layer are ReLUs.",
            "zh": "在这个例子中，我们假设隐藏的神经元和输出层是ReLU。"
        }
    },
    {
        "translation": {
            "en": "Histograms of two unimodal datasets: (a) the distribution has light tails; and (b) the distribution has fat tails.",
            "zh": "两个单峰数据集的直方图：（a）分布有光尾;（b）分布有肥尾。"
        }
    },
    {
        "translation": {
            "en": "(c) Simulate taking the action that the agent selected in Part (b) and determine the state that the agent will move to following this action and the reward that they will receive. (Note: If cards need to be dealt to the player or dealer, use cards from the list given at the beginning of this question.)",
            "zh": "（c） 模拟采取代理人在（b）部分中选择的行动，并确定代理人在采取该行动后将进入的状态以及他们将获得的奖励。（注意：如果需要发牌给玩家或庄家，请使用本问题开头给出的列表中的牌。"
        }
    },
    {
        "translation": {
            "en": "The first column of each weight matrix (filled in black) contains the bias term weights for each neuron in the layer.",
            "zh": "每个权重矩阵的第一列（以黑色填充）包含层中每个神经元的偏差项权重。"
        }
    },
    {
        "translation": {
            "en": "3.1   The structures of the tables included in a data quality report to describe (a) continuous features and (b) categorical features.",
            "zh": "3.1 数据质量报告中描述（a）连续特征和（b）分类特征的表格结构。"
        }
    },
    {
        "translation": {
            "en": "The measures of predictiveness are called filters because they are used to filter apparently irrelevant features before learning occurs.",
            "zh": "预测性的度量被称为过滤器，因为它们用于在学习发生之前过滤明显不相关的特征。"
        }
    },
    {
        "translation": {
            "en": "From a computational perspective, the Manhattan distance has a slight advantage over the Euclidean distance—the computation of the squaring and the square root is saved—and computational considerations can become important when dealing with very large datasets.",
            "zh": "从计算的角度来看，曼哈顿距离比欧几里得距离略有优势（节省了平方和平方根的计算），在处理非常大的数据集时，计算考虑因素可能变得很重要。"
        }
    },
    {
        "translation": {
            "en": "Bayesian Network",
            "zh": "贝叶斯网络"
        }
    },
    {
        "translation": {
            "en": "There are three hyper-parameters that affect the number of neurons required to cover the entirety of an input and hence the dimensionality of the resulting feature map; these are filter dimensions, the stride, and the padding.",
            "zh": "有三个超参数会影响覆盖整个输入所需的神经元数量，从而影响生成的特征图的维数;这些是过滤器尺寸、步幅和填充。"
        }
    },
    {
        "translation": {
            "en": "10. Revenue commissioners around the world use predictive data analytics techniques to keep their processes as efficient as possible. Cleary and Tax (2011) is a good example.",
            "zh": "10. 世界各地的税务专员使用预测数据分析技术来保持其流程尽可能高效。Cleary and Tax（2011）就是一个很好的例子。"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, CLASS and is composed of three plots: a plot of the distribution of the descriptive feature values in the full dataset, and plots showing the distribution of the descriptive feature values for each level of the target.",
            "zh": "每个可视化都说明了描述性特征与目标特征 CLASS 之间的关系，并由三个图组成：完整数据集中描述性特征值的分布图，以及显示目标每个级别的描述性特征值分布的图。"
        }
    },
    {
        "translation": {
            "en": "The animals that may be found in these forests include bears, deer, and cougars.",
            "zh": "在这些森林中可能发现的动物包括熊、鹿和美洲狮。"
        }
    },
    {
        "translation": {
            "en": "This chapter discusses reinforcement learning, an approach to machine learning that is sufficiently different from supervised and unsupervised machine learning to be often considered the third leg of the machine learning stool.",
            "zh": "本章讨论强化学习，这是一种机器学习方法，它与有监督和无监督的机器学习有很大不同，通常被认为是机器学习凳子的第三条腿。"
        }
    },
    {
        "translation": {
            "en": "This results in the majority of feature values being in a range of [−1,1].",
            "zh": "这导致大多数特征值在 [−1,1] 的范围内。"
        }
    },
    {
        "translation": {
            "en": "These synapses allow electrical signals to pass from the axon of one neuron to a dendrite of another.",
            "zh": "这些突触允许电信号从一个神经元的轴突传递到另一个神经元的树突。"
        }
    },
    {
        "translation": {
            "en": "Ross sampled data from the period 2008 to 2013.",
            "zh": "Ross 对 2008 年至 2013 年期间的数据进行了抽样。"
        }
    },
    {
        "translation": {
            "en": "In summary, machine learning works by searching through a set of potential models to find the prediction model that best generalizes beyond the dataset. Machine learning algorithms use two sources of information to guide this search, the training dataset and the inductive bias assumed by the algorithm.",
            "zh": "总之，机器学习的工作原理是搜索一组潜在模型，以找到最能在数据集之外泛化的预测模型。机器学习算法使用两个信息源来指导这种搜索，即训练数据集和算法假设的归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "0.73",
            "zh": "0.73"
        }
    },
    {
        "translation": {
            "en": "Laplace smoothing, 267, 308",
            "zh": "拉普拉斯平滑，267,308"
        }
    },
    {
        "translation": {
            "en": "8.2.5 Why Is Network Depth Important?",
            "zh": "8.2.5 为什么网络深度很重要？"
        }
    },
    {
        "translation": {
            "en": "Once we have discretized the continuous features and calculated the thresholds for binning query features, we are ready to create our predictive model.",
            "zh": "一旦我们对连续特征进行了离散化并计算了分箱查询特征的阈值，我们就可以创建预测模型了。"
        }
    },
    {
        "translation": {
            "en": "Encoding the red, green, and blue (RGB) information is normally done using a separate two-dimensional matrix for each color, with the dimensions of each of these two-dimensional matrices equal to the pixel resolution of the image.",
            "zh": "对红色、绿色和蓝色 （RGB） 信息进行编码通常使用每种颜色的单独二维矩阵来完成，每个二维矩阵的尺寸等于图像的像素分辨率。"
        }
    },
    {
        "translation": {
            "en": "The dataset from Table 5.5[204] with the Euclidean distance between each instance and the query SALARY = 56,000, AGE = 35 when we use both the SALARY and AGE features, just the SALARY feature, and just the AGE feature.",
            "zh": "表 5.5[204] 中的数据集，每个实例之间的欧氏距离与查询 SALARY = 56,000，AGE = 35，当我们同时使用 SALARY 和 AGE 特征时，仅使用 SALARY 特征，并且仅使用 AGE 特征。"
        }
    },
    {
        "translation": {
            "en": "28. These images are based on the dataset from the UCI Machine Learning repository Dua and Graff (2017) and originally described by Alimoglu and Alpaydin (1996).",
            "zh": "28. 这些图像基于 UCI 机器学习存储库 Dua 和 Graff （2017） 的数据集，最初由 Alimoglu 和 Alpaydin （1996） 描述。"
        }
    },
    {
        "translation": {
            "en": "In these scenarios we need to process millions of examples and to calculate and accumulate millions of error gradients for each weight update.",
            "zh": "在这些场景中，我们需要处理数百万个示例，并为每次权重更新计算和累积数百万个误差梯度。"
        }
    },
    {
        "translation": {
            "en": "A simple RNN model unrolled through time (in this instance, three time-steps).",
            "zh": "一个简单的 RNN 模型随时间展开（在本例中为三个时间步长）。"
        }
    },
    {
        "translation": {
            "en": "The rotation and scaling of the axes are the result of the multiplication by the inverse covariance matrix of the dataset (∑−1).",
            "zh": "轴的旋转和缩放是乘以数据集的逆协方差矩阵 （∑−1） 的结果。"
        }
    },
    {
        "translation": {
            "en": "Often missing values arise from errors in data integration or in the process of generating values for derived fields.",
            "zh": "丢失值通常是由于数据集成或为派生字段生成值过程中的错误引起的。"
        }
    },
    {
        "translation": {
            "en": "One of the more unusual challenges involved in earning this badge is to learn to cross a stream using a set of stepping-stones while wearing an electronic blindfold.",
            "zh": "获得此徽章所涉及的更不寻常的挑战之一是在戴着电子眼罩的情况下学习使用一组垫脚石穿越溪流。"
        }
    },
    {
        "translation": {
            "en": "If we do not do this, then as we continue to increase the dimensionality of the feature space, the instances will continue to spread out until we reach a point in a high-dimensional feature space where most of the feature space is empty.",
            "zh": "如果我们不这样做，那么随着我们继续增加特征空间的维数，实例将继续扩散，直到我们到达高维特征空间中大部分特征空间为空的点。"
        }
    },
    {
        "translation": {
            "en": "We now understand the theory of how to calculate a simple unconditional probability, a joint probability, and a conditional probability using a dataset. Now is a good point to ground this knowledge in a more interesting example focused on predictive data analytics. We will use the dataset in Table B.2[760] for this.3 The target being predicted in this dataset is whether or not a patient is suffering from meningitis, and the descriptive features are common symptoms associated with meningitis.",
            "zh": "我们现在了解了如何使用数据集计算简单无条件概率、联合概率和条件概率的理论。现在是一个很好的点，将这些知识建立在一个更有趣的例子中，重点是预测数据分析。我们将使用表B.2[760]中的数据集.3该数据集中预测的目标是患者是否患有脑膜炎，描述性特征是与脑膜炎相关的常见症状。"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, Figure 10.13(a)[623] returns to the full mobile phone customer dataset from Table 10.1[604] and shows the dendrogram capturing the result of running the AHC algorithm on this dataset.",
            "zh": "为了说明这一点，图10.13（a）[623]从表10.1[604]返回到完整的移动电话客户数据集，并显示了捕获在该数据集上运行AHC算法结果的树状图。"
        }
    },
    {
        "translation": {
            "en": "This dataset is listed in Table 4.8[147].",
            "zh": "该数据集列于表4.8[147]。"
        }
    },
    {
        "translation": {
            "en": "For example, in a real-time credit card fraud prediction system, it may be required that a model perform thousands of predictions per second.",
            "zh": "例如，在实时信用卡欺诈预测系统中，可能需要模型每秒执行数千次预测。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning a value function returns the cumulative reward that an agent can expect to earn if it starts from a particular state, st, and follows a specific policy, π all the way to the end of an episode. We can write this",
            "zh": "在强化学习中，值函数返回智能体从特定状态 st 开始并遵循特定策略（π一直到剧集结束）可以期望获得的累积奖励。我们可以这样写"
        }
    },
    {
        "translation": {
            "en": "In the next section we combine the ideas of temporal-difference learning and a specific behavior policy to define the standard approach to reinforcement learning: Q-learning.",
            "zh": "在下一节中，我们将时间差异学习的思想与特定的行为策略相结合，以定义强化学习的标准方法：Q-learning。"
        }
    },
    {
        "translation": {
            "en": "single",
            "zh": "单"
        }
    },
    {
        "translation": {
            "en": "social science, 293",
            "zh": "社会科学， 293"
        }
    },
    {
        "translation": {
            "en": "Being a large retailer, they had considerable resources at their disposal, one of which was the ability to regularly take high-resolution satellite photos.",
            "zh": "作为一家大型零售商，他们拥有大量资源可供使用，其中之一就是能够定期拍摄高分辨率卫星照片。"
        }
    },
    {
        "translation": {
            "en": "3. An analytics consultant at an insurance company has built an ABT that will be used to train a model to predict the best communications channel to use to contact a potential customer with an offer of a new insurance product.15 The following table contains an extract from this ABT—the full ABT contains 5,200 instances.",
            "zh": "3. 一家保险公司的分析顾问构建了一个 ABT，该模型将用于训练模型，以预测用于联系潜在客户并提供新保险产品的最佳沟通渠道。15 下表包含此 ABT 的摘录 - 完整的 ABT 包含 5,200 个实例。"
        }
    },
    {
        "translation": {
            "en": "The choice of the correct performance measure for a particular problem depends on a combination of the nature of the prediction problem (e.g., continuous versus categorical), the characteristics of the dataset (e.g., balanced versus imbalanced), and the needs of the application (e.g., medical diagnosis versus marketing response prediction).",
            "zh": "为特定问题选择正确的性能度量取决于预测问题的性质（例如，连续与分类）、数据集的特征（例如，平衡与不平衡）以及应用程序的需求（例如，医学诊断与营销响应预测）。"
        }
    },
    {
        "translation": {
            "en": "A probability function, P(), returns the probability of an event.",
            "zh": "概率函数 P（） 返回事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.12",
            "zh": "图 3.12"
        }
    },
    {
        "translation": {
            "en": "Both Filters 1 and 2 have a dimensionality of 2-by-1-by-3.",
            "zh": "过滤器 1 和 2 的维度均为 2×1×3。"
        }
    },
    {
        "translation": {
            "en": "If we compare the visualization of lift for these predictions shown in Figure 9.16(a)[570] to the gain chart for the same set of predictions in Figure 9.15(a)[569], we can see that the shapes are the same.",
            "zh": "如果我们将图9.16（a）[570]中所示的这些预测的升力可视化与图9.15（a）[569]中同一组预测的增益图表进行比较，我们可以看到形状是相同的。"
        }
    },
    {
        "translation": {
            "en": "At the end of this process, a δ has been calculated for every neuron in the network.",
            "zh": "在此过程结束时，已经为网络中的每个神经元计算了δ。"
        }
    },
    {
        "translation": {
            "en": "This model first used a 3-level logistic regression model to distinguish between the elliptical, spiral, and other target levels.",
            "zh": "该模型首先使用 3 级逻辑回归模型来区分椭圆、螺旋和其他目标水平。"
        }
    },
    {
        "translation": {
            "en": "Equation (11.22)[655] states that the action-value table is updated using the actual return received by an agent across a full episode, whereas we also said that this update takes place after every action.",
            "zh": "等式（11.22）[655]指出，操作值表是使用代理在整个剧集中收到的实际回报来更新的，而我们还说，此更新发生在每个操作之后。"
        }
    },
    {
        "translation": {
            "en": "linear activations, 674",
            "zh": "线性激活，674"
        }
    },
    {
        "translation": {
            "en": "Davenport, Thomas H. 2006. Competing on analytics. Harvard Business Review 84 (1): 98–107. http://hbr.harvardbusiness.org/2006/01/competing-on-analytics/ar/1.",
            "zh": "达文波特，托马斯 H. 2006 年。在分析方面展开竞争。哈佛商业评论84（1）：98-107。http://hbr.harvardbusiness.org/2006/01/competing-on-analytics/ar/1。"
        }
    },
    {
        "translation": {
            "en": "The matrix on the right of Equation (8.95)[491] represents an extension to the architecture that we have discussed.",
            "zh": "等式（8.95）[491]右边的矩阵代表了我们讨论的架构的扩展。"
        }
    },
    {
        "translation": {
            "en": "Using predictive analytics, however, the results of small-scale surveys can be used to create predictive models that can be applied across large regions.",
            "zh": "但是，使用预测分析，小规模调查的结果可用于创建可应用于大型区域的预测模型。"
        }
    },
    {
        "translation": {
            "en": "13.7   Histograms of the EXPRAD_R feature split by target feature level.",
            "zh": "13.7 按目标特征级别划分的EXPRAD_R特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "When the algorithm is searching for the nearest neighbor using Euclidean distance, it is partitioning the feature space into what is known as a Voronoi tessellation,4 and it is trying to decide which Voronoi region the query belongs to.",
            "zh": "当算法使用欧几里得距离搜索最近邻时，它会将特征空间划分为所谓的 Voronoi 曲面细分，4 并尝试确定查询属于哪个 Voronoi 区域。"
        }
    },
    {
        "translation": {
            "en": "(c) What prediction will the decision tree generated in Part (a) of this question return for the following query?",
            "zh": "（c） 本问题（a）部分生成的决策树对以下查询将返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "FIBER2MAGERR_U/G/R/I/Z",
            "zh": "FIBER2MAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Gapminder, 237",
            "zh": "Gapminder，237"
        }
    },
    {
        "translation": {
            "en": "In some applications there is a natural structure in the data that we can take advantage of to form test sets.",
            "zh": "在某些应用程序中，数据中有一个自然结构，我们可以利用它来形成测试集。"
        }
    },
    {
        "translation": {
            "en": "In this situation the node becomes dependent on the ancestors of its unknown parent.",
            "zh": "在这种情况下，节点将依赖于其未知父节点的祖先。"
        }
    },
    {
        "translation": {
            "en": "For example, it would seem reasonable to argue that the behavior of an octopus in a swimming tank should not affect the outcome of a soccer match.12 If knowledge of one event has no effect on the probability of another event, and vice versa, then the two events are said to be independent of each other.",
            "zh": "例如，认为章鱼在水箱中的行为不应影响足球比赛的结果似乎是合理的.12如果对一个事件的了解对另一个事件的概率没有影响，反之亦然，那么这两个事件被认为是相互独立的。"
        }
    },
    {
        "translation": {
            "en": "Rectified linear activation functions were used in all hidden layer units.",
            "zh": "所有隐藏层单元都使用了整流线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "2.4   Designing and Implementing Features",
            "zh": "2.4 设计和实现功能"
        }
    },
    {
        "translation": {
            "en": "ANOVA test, 86, 95",
            "zh": "方差分析检验，86,95"
        }
    },
    {
        "translation": {
            "en": "The data quality plan for the motor insurance fraud prediction ABT.",
            "zh": "汽车保险欺诈预测ABT的数据质量计划。"
        }
    },
    {
        "translation": {
            "en": "For example, P(FEVER = true) returns the probability of the FEVER feature taking the value true.",
            "zh": "例如，P（FEVER = true） 返回 FEVER 特征取值 true 的概率。"
        }
    },
    {
        "translation": {
            "en": "Analytics practitioners must, however, possess what is referred to as situational fluency.",
            "zh": "然而，分析从业者必须具备所谓的情境流畅性。"
        }
    },
    {
        "translation": {
            "en": "The neuron in the figure takes 9 inputs, arranged in a two-dimensional 3-by-3 grid, mirroring the two-dimensional nature of the image.",
            "zh": "图中的神经元接受 9 个输入，排列成二维 3×3 网格，反映了图像的二维性质。"
        }
    },
    {
        "translation": {
            "en": "0.0481",
            "zh": "0.0481"
        }
    },
    {
        "translation": {
            "en": "800,000",
            "zh": "800,000"
        }
    },
    {
        "translation": {
            "en": "LNLSTAR_U/G/R/I/Z",
            "zh": "LNLSTAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "AE_I",
            "zh": "AE_I"
        }
    },
    {
        "translation": {
            "en": "The complexity of the calculations can be reduced by being careful with the positioning of features with respect to summations and by using dynamic programming techniques to avoid repeated computations.",
            "zh": "通过仔细定位相对于求和的特征，以及使用动态规划技术来避免重复计算，可以降低计算的复杂性。"
        }
    },
    {
        "translation": {
            "en": "Understanding, at least in principle, whether a particular network architecture is capable of representing a function, or not, is very important, because the fundamental task in predictive modeling is to learn functions from data, and if the network cannot represent a function, then it cannot learn it, no matter how much data we provide to the training algorithm.",
            "zh": "至少在原则上，了解特定的网络架构是否能够表示函数非常重要，因为预测建模的基本任务是从数据中学习函数，如果网络不能表示函数，那么它就无法学习它，无论我们向训练算法提供多少数据。"
        }
    },
    {
        "translation": {
            "en": "Each of these measures is suitable for different types of data, and matching the appropriate measure to the data is an important step in inducing an accurate similarity-based prediction model.",
            "zh": "这些度量中的每一个都适用于不同类型的数据，将适当的度量与数据相匹配是诱导基于相似性的准确预测模型的重要步骤。"
        }
    },
    {
        "translation": {
            "en": "Choosing to Twist in any of the non-terminal states will take the agent to the same non-terminal state, another non-terminal state representing a higher player hand value, or—if they are unlucky—the BUST state.",
            "zh": "选择在任何非终端状态下进行 Twist 都会将代理带到相同的非终端状态，另一个非终端状态代表更高的玩家手牌值，或者——如果他们运气不好——BUST 状态。"
        }
    },
    {
        "translation": {
            "en": "11.2   An action-value table for an agent trained to play the card game TwentyTwos (the simplified version of Blackjack described in Section 11.2.3[643]).",
            "zh": "11.2 一个动作值表，供一个受过训练玩纸牌游戏TwentyTwos（第11.2.3[643]节中描述的二十一点的简化版本）的代理使用。"
        }
    },
    {
        "translation": {
            "en": "The % SOFT TISSUE feature is a ratio of the NUM.",
            "zh": "% SOFT TISSUE 特征是 NUM 的比率。"
        }
    },
    {
        "translation": {
            "en": "k-NN, 181",
            "zh": "k-NN，181"
        }
    },
    {
        "translation": {
            "en": "There are two advantages to using a causal graph: (1) people find it relatively easy to think in terms of causal relationships, and as a result, networks that encode these relationships are relatively easy to understand; (2) often networks that reflect the causal structure of a domain are more compact in terms of the number of links between nodes and hence are more compact with respect to the number of CPT entries.",
            "zh": "使用因果图有两个优点：（1）人们发现从因果关系的角度思考相对容易，因此，编码这些关系的网络相对容易理解;（2）通常，反映域因果结构的网络在节点之间的链接数量方面更紧凑，因此在CPT条目数量方面更紧凑。"
        }
    },
    {
        "translation": {
            "en": "support vectors, 362",
            "zh": "支持向量，362"
        }
    },
    {
        "translation": {
            "en": "The simple prediction model using only the loan-salary ratio feature is no longer consistent with the dataset. It turns out, however, that there is at least one prediction model that is consistent with the dataset; it is just a little harder to find than the previous one:",
            "zh": "仅使用贷款-工资比特征的简单预测模型不再与数据集一致。然而，事实证明，至少有一个预测模型与数据集一致;它只是比前一个更难找到："
        }
    },
    {
        "translation": {
            "en": "Contents",
            "zh": "内容"
        }
    },
    {
        "translation": {
            "en": "5.6 Further Reading",
            "zh": "5.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "You are currently preparing for a visit by the American physicist Professor Robert W. Wood to whom Professor Blondlot has agreed to demonstrate the experiments that show the effects of N rays.",
            "zh": "您目前正在准备美国物理学家罗伯特·伍德（Robert W. Wood）教授的访问，布隆德洛特教授已同意向他演示显示N射线效应的实验。"
        }
    },
    {
        "translation": {
            "en": "2,700",
            "zh": "2,700"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification decision tree generated using information gain ratio.",
            "zh": "使用信息增益比生成的植被分类决策树。"
        }
    },
    {
        "translation": {
            "en": "The menu is quite simple, displaying only five words: sicín, mairteoil, muiceoil, muisiriún, and bradán.",
            "zh": "菜单非常简单，只显示五个词：sicín、mairteoil、muiceoil、muisiriún 和 bradán。"
        }
    },
    {
        "translation": {
            "en": "4.7   How the instances in the spam dataset split when we partition using each of the different descriptive features from the spam dataset in Table 4.2[121].",
            "zh": "4.7 当我们使用表 4.2[121] 中垃圾邮件数据集中的每个不同描述性特征进行分区时，垃圾邮件数据集中的实例是如何分裂的。"
        }
    },
    {
        "translation": {
            "en": "9.6   The division of data during the ɛ0 bootstrap process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "9.6 ɛ0 引导过程中的数据划分。黑色矩形表示测试数据，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "In hindsight, the general criticisms of neural networks made by Minsky and Papert have not stood the test of time; however, their criticism of the representational capacity of single-layer networks is valid.",
            "zh": "事后看来，Minsky 和 Papert 对神经网络的普遍批评并没有经受住时间的考验;然而，他们对单层网络表示能力的批评是有道理的。"
        }
    },
    {
        "translation": {
            "en": "13.5   The confusion matrices for the baseline models.",
            "zh": "13.5 基线模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "This dataset had not been used in the training process, so the performance of the model on this dataset should give a fair indication of how well the model would perform when deployed on real, unseen data.",
            "zh": "该数据集未在训练过程中使用，因此模型在此数据集上的性能应公平地表明该模型在部署在真实、看不见的数据上的性能。"
        }
    },
    {
        "translation": {
            "en": "(a) If xt = [1,0.5] and ht−1 = [0.05,0.2,0.15], calculate the value of yt.",
            "zh": "（a） 如果 xt = [1,0.5] 和 ht−1 = [0.05,0.2,0.15]，则计算 yt 的值。"
        }
    },
    {
        "translation": {
            "en": "4. Summing out is sometimes referred to as marginalization because statisticians used to carry out these calculations in the margins of the probability tables they were working with!",
            "zh": "4. 求和有时被称为边缘化，因为统计学家过去常常在他们正在使用的概率表的边缘进行这些计算！"
        }
    },
    {
        "translation": {
            "en": "In an error-based model, learning equates to finding the optimal values for these weights.",
            "zh": "在基于误差的模型中，学习等同于找到这些权重的最佳值。"
        }
    },
    {
        "translation": {
            "en": "Gaeltacht, 655",
            "zh": "盖尔塔赫特，655"
        }
    },
    {
        "translation": {
            "en": "However, the posterior probabilities are not as extreme as those calculated when we did not assume conditional independence.",
            "zh": "然而，后验概率并不像我们没有假设条件独立性时计算的概率那么极端。"
        }
    },
    {
        "translation": {
            "en": "The key objects in the company’s data model and the data available regarding them. For example, in a bricks-and-mortar retail scenario, the key objects are likely to be customers, products, sales, suppliers, stores, and staff. In an insurance scenario, the key objects are likely to be policyholders, policies, claims, policy applications, investigations, brokers, members, investigators, and payments.",
            "zh": "公司数据模型中的关键对象以及有关它们的可用数据。例如，在实体零售场景中，关键对象可能是客户、产品、销售、供应商、商店和员工。在保险场景中，关键对象可能是投保人、保单、索赔、保单申请、调查、经纪人、成员、调查员和付款。"
        }
    },
    {
        "translation": {
            "en": "6.4.1   Smoothing",
            "zh": "6.4.1 平滑"
        }
    },
    {
        "translation": {
            "en": "Online Resources",
            "zh": "在线资源"
        }
    },
    {
        "translation": {
            "en": "2.3   Example domain concepts for a motor insurance fraud prediction analytics solution.",
            "zh": "2.3 汽车保险欺诈预测分析解决方案的示例域概念。"
        }
    },
    {
        "translation": {
            "en": "We can make predictions using Gibbs sampling in the same way that we made predictions using exact probabilistic inference by predicting the target level with the maximum a posteriori probability:",
            "zh": "我们可以使用 Gibbs 抽样进行预测，就像我们使用精确概率推理进行预测一样，通过以最大后验概率预测目标水平："
        }
    },
    {
        "translation": {
            "en": "Equation (8.112)[511] defines how these the two paths of processing are merged using an elementwise product, denoted by the ⊙ term.",
            "zh": "等式（8.112）[511]定义了如何使用逐元乘积（用⊙项表示）合并这两种处理路径。"
        }
    },
    {
        "translation": {
            "en": "12. See Appendix C[765].",
            "zh": "[12]见附录C[765]。"
        }
    },
    {
        "translation": {
            "en": "Marsland, Stephen. 2011. Machine learning: An algorithmic perspective. CRC Press.",
            "zh": "马斯兰，斯蒂芬。2011. 机器学习：算法视角。CRC出版社。"
        }
    },
    {
        "translation": {
            "en": "An error function captures the error between the predictions made by a model and the actual values in a training dataset.2 There are many different kinds of error functions, but for measuring the fit of simple linear regression models, the most commonly used is the sum of squared errors error function, or L2.",
            "zh": "误差函数捕获模型做出的预测与训练数据集中实际值之间的误差.2 有许多不同类型的误差函数，但对于测量简单线性回归模型的拟合度，最常用的是误差误差总和误差函数，或 L2。"
        }
    },
    {
        "translation": {
            "en": "The graph of the logistic function is relatively flat for large (positive or negative) values.",
            "zh": "对于大（正或负）值，逻辑函数的图形相对平坦。"
        }
    },
    {
        "translation": {
            "en": "9. A binary tree is simply a tree in which every node in the tree has at most two branches.",
            "zh": "9. 二叉树只是一棵树，其中树中的每个节点最多有两个分支。"
        }
    },
    {
        "translation": {
            "en": "The bias terms are the weights on the dummy inputs.",
            "zh": "偏置项是虚拟输入的权重。"
        }
    },
    {
        "translation": {
            "en": "Gain is a measure of how many of the positive instances in the overall test set are found in a particular decile. To find this, we count the number of positive instances (based on the known target values) found in each decile and divide these by the total number of positive instances in the test set. So, the gain in a given decile is calculated as",
            "zh": "增益是衡量在特定十分位数中发现整个测试集中有多少阳性实例的度量。为了找到这一点，我们计算在每个十分位数中找到的阳性实例数（基于已知目标值），并将其除以测试集中阳性实例的总数。因此，给定十分位数的增益计算为"
        }
    },
    {
        "translation": {
            "en": "The player is allowed to see one of the two cards dealt to the dealer, but the dealer’s other card remains hidden until the player is finished taking their actions.",
            "zh": "玩家可以看到发给庄家的两张牌中的一张，但庄家的另一张牌保持隐藏状态，直到玩家完成他们的行动。"
        }
    },
    {
        "translation": {
            "en": "The next iteration of the algorithm is interesting because the smallest distance found in the distance matrix is a distance of 0.16 between cluster 10 and instance d11.",
            "zh": "该算法的下一次迭代很有趣，因为在距离矩阵中找到的最小距离是聚类 10 和实例 d11 之间的距离 0.16。"
        }
    },
    {
        "translation": {
            "en": "9. The probability chain rule is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "9. 概率链规则在附录B[757]第B.3[762]节有详细解释。"
        }
    },
    {
        "translation": {
            "en": "The first time that Sarah took a step that reached a stepping-stone, however, she felt a huge rush of excitement.",
            "zh": "然而，当莎拉第一次迈出踏脚石的一步时，她感到了巨大的兴奋。"
        }
    },
    {
        "translation": {
            "en": "Because a machine learning algorithm encodes an inductive bias, it can induce models that generalize beyond the instances in a training dataset.",
            "zh": "由于机器学习算法对归纳偏差进行编码，因此它可以诱导超出训练数据集中实例范围的模型。"
        }
    },
    {
        "translation": {
            "en": "Siegel, Eric. 2013. Predictive analytics: The power to predict who will click, buy, lie, or die, 1st ed. Wiley.",
            "zh": "西格尔，埃里克。2013. 预测分析：预测谁会点击、购买、撒谎或死亡的力量，第 1 版。"
        }
    },
    {
        "translation": {
            "en": "In choosing a sample, it is important that it be representative of the population.",
            "zh": "在选择样本时，重要的是它要代表总体。"
        }
    },
    {
        "translation": {
            "en": "SIZE",
            "zh": "大小"
        }
    },
    {
        "translation": {
            "en": "Figure 4.3",
            "zh": "图 4.3"
        }
    },
    {
        "translation": {
            "en": "Similarly, the difference between the mean and median values for the LNLSTAR_R feature suggested that the distribution of this feature was heavily skewed and also suggested the presence of outliers.",
            "zh": "同样，LNLSTAR_R特征的平均值和中位数值之间的差异表明该特征的分布严重偏斜，并且还表明存在异常值。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.4",
            "zh": "图 6.4"
        }
    },
    {
        "translation": {
            "en": "P_CW",
            "zh": "P_CW"
        }
    },
    {
        "translation": {
            "en": "Knime, RapidMiner, and Weka are interesting because they are all open-source, freely available solutions that readers can begin to use without any financial investment.",
            "zh": "Knime、RapidMiner 和 Weka 很有趣，因为它们都是开源的、免费提供的解决方案，读者无需任何财务投资即可开始使用。"
        }
    },
    {
        "translation": {
            "en": "9.15   The test set with model predictions and scores from Table 9.11[557] extended to include deciles.",
            "zh": "9.15 包含表9.11[557]的模型预测和分数的测试集扩展至包括十分位数。"
        }
    },
    {
        "translation": {
            "en": "(2006) and Hinton (2005)) was the starting point for the wave of renewed interest in neural network models that began in the early 2000s and became known as deep learning.",
            "zh": "（2006）和Hinton（2005））是2000年代初开始的对神经网络模型重新产生兴趣的起点，后来被称为深度学习。"
        }
    },
    {
        "translation": {
            "en": "To understand how Shannon’s entropy model works, consider the example of a set of 52 different playing cards. The probability of randomly selecting any specific card i from this set, P(card = i), is quite low, just . The entropy of the set of 52 playing cards is calculated",
            "zh": "要理解香农的熵模型是如何工作的，请考虑一组 52 张不同扑克牌的例子。从这组 P（card = i） 中随机选择任何特定牌 i 的概率非常低，只是 .计算一组 52 张扑克牌的熵"
        }
    },
    {
        "translation": {
            "en": "An information gain score for a feature that matches the entropy for the entire dataset indicates that the feature is perfectly discriminatory with respect to the target feature values.",
            "zh": "与整个数据集的熵匹配的特征的信息增益分数表示该特征相对于目标特征值具有完全的判别力。"
        }
    },
    {
        "translation": {
            "en": "We only need to calculate the relative likelihood of a continuous feature taking a value given different levels of a target feature.",
            "zh": "我们只需要计算连续特征在给定目标特征的不同级别时取值的相对似然。"
        }
    },
    {
        "translation": {
            "en": "Hence it is worth emphasizing that we are using this convergence criterion only for ease of explanation, and in general we recommend that you use early stopping when you are training a neural network.",
            "zh": "因此，值得强调的是，我们使用这个收敛标准只是为了便于解释，一般来说，我们建议你在训练神经网络时使用提前停止。"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset; and (b) the scatter plot from (a) with a linear model relating RENTAL PRICE to SIZE overlaid.",
            "zh": "（a） 写字楼租赁数据集中“大小”和“租金价格”特征的散点图;（b）来自（a）的散点图，其中叠加了与RENTAL PRICE和SIZE相关的线性模型。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.1[705] shows illustrations of these different galaxy types.",
            "zh": "图13.1[705]显示了这些不同星系类型的图示。"
        }
    },
    {
        "translation": {
            "en": "Post-pruning relies on a criterion that can distinguish between subtrees that model relevant aspects of the data and subtrees that model irrelevant random patterns in the data.",
            "zh": "修剪后依赖于一个标准，该标准可以区分对数据相关方面进行建模的子树和对数据中不相关的随机模式进行建模的子树。"
        }
    },
    {
        "translation": {
            "en": "Figure A.7(a)[754] shows the frequency histogram for the TRAINING EXPENSES feature when we define ten 200-unit intervals spanning the range that this feature can take (the frequencies come from Table A.4(a)[755]).",
            "zh": "图 A.7（a）[754] 显示了当我们定义跨越该特征可以采用的范围的 10 个 200 单位间隔时，TRAINING EXPENSES 特征的频率直方图（频率来自表 A.4（a）[755]）。"
        }
    },
    {
        "translation": {
            "en": "Once this happens, the target probability can be computed by calculating the relative frequency of the event within the selected subset of generated states.",
            "zh": "一旦发生这种情况，就可以通过计算所选生成状态子集中事件的相对频率来计算目标概率。"
        }
    },
    {
        "translation": {
            "en": "boosting, 159, 159, 171, 178, 179, 733, 735",
            "zh": "提升， 159， 159， 171， 178， 179， 733， 735"
        }
    },
    {
        "translation": {
            "en": "Hence δi,j is the δ value for neuron i for example j.",
            "zh": "因此，δi，j 是神经元 i 的δ值，例如 j。"
        }
    },
    {
        "translation": {
            "en": "Also, during backpropagation no error gradients flow back through the dropped neurons; their δs are set to 0.",
            "zh": "此外，在反向传播过程中，没有误差梯度流回掉落的神经元;它们的 δ 设置为 0。"
        }
    },
    {
        "translation": {
            "en": "So, care must be taken to ensure that the objective function used by the search process avoids overfitting the data by simply creating a very highly connected graph.",
            "zh": "因此，必须注意确保搜索过程使用的目标函数通过简单地创建一个高度连接的图来避免数据过度拟合。"
        }
    },
    {
        "translation": {
            "en": "One way of counterbalancing this tendency is to use a distance weighted k nearest neighbor approach.",
            "zh": "平衡这种趋势的一种方法是使用距离加权 k 最近邻方法。"
        }
    },
    {
        "translation": {
            "en": "Other: There are no restrictions to the ways in which we can combine data to make derived features.",
            "zh": "其他：我们组合数据以生成派生特征的方式没有限制。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(a)[74] shows an example scatter plot for the HEIGHT and WEIGHT features from the dataset in Table 3.7[73].",
            "zh": "图3.5（a）[74]显示了表3.7[73]中数据集中HEIGHT和WEIGHT特征的散点图示例。"
        }
    },
    {
        "translation": {
            "en": "Transitions into the BUST or LOSE states return a reward of − 1, transitions into the TIE state earn a reward of 0, transitions into the WIN state return a reward of + 1, and transitions into the TWENTYTWO state return a reward of + 2.",
            "zh": "过渡到 BUST 或 LOSE 状态返回 − 1 的奖励，过渡到 TIE 状态获得 0 的奖励，过渡到 WIN 状态返回 + 1 的奖励，过渡到 TWENTYTWO 状态返回 + 2 的奖励。"
        }
    },
    {
        "translation": {
            "en": "It quickly became apparent that the key data resources within AT that would be important for this project were",
            "zh": "很明显，AT中对这个项目很重要的关键数据资源是"
        }
    },
    {
        "translation": {
            "en": "So, ∑iP(Xi) should be interpreted as summing over all the possible combinations of value assignments to the features in X.",
            "zh": "因此，∑iP（习） 应该被解释为 X 中特征的所有可能的值赋值组合的总和。"
        }
    },
    {
        "translation": {
            "en": "The problem with this, however, is that generating full joint probability distributions suffers from the curse of dimensionality, and as a result, this approach is not tractable for domains involving more than a few features.",
            "zh": "然而，这样做的问题在于，生成完整的联合概率分布会受到维数的诅咒，因此，这种方法对于涉及多个特征的域来说是不可行的。"
        }
    },
    {
        "translation": {
            "en": "The following is a query instance for the fraud detection domain:",
            "zh": "以下是欺诈检测域的查询实例："
        }
    },
    {
        "translation": {
            "en": "Through the 1950s and 1960s there was a lot of interest in neural networks.",
            "zh": "在 1950 年代和 1960 年代，人们对神经网络产生了浓厚的兴趣。"
        }
    },
    {
        "translation": {
            "en": "After remaining in the RECOVERED state for some time, P(R R) = 0.20, most people will soon transition back to the SUSCEPTIBLE state, P(R S) = 0.75, but a small part of the population will instead relapse and return to the INFECTED state, P(R I) = 0.05.",
            "zh": "在保持恢复状态一段时间后，P（R R） = 0.20，大多数人将很快过渡到易感状态，P（R S） = 0.75，但一小部分人会复发并回到感染状态，P（R I） = 0.05。"
        }
    },
    {
        "translation": {
            "en": "Each visualization illustrates the relationship between a descriptive feature and the target feature, TACHYCARDIA and is composed of three plots: a plot of the distribution of the descriptive feature values in the full dataset, and plots showing the distribution of the descriptive feature values for each level of the target.",
            "zh": "每个可视化都说明了描述性特征与目标特征（心动过速）之间的关系，并由三个图组成：完整数据集中描述性特征值的分布图，以及显示目标每个级别的描述性特征值分布的图。"
        }
    },
    {
        "translation": {
            "en": "We know from this result that the probability for CPI = low must be 0.8. So, the network will predict CPI = low as the MAP target value for the query. This tells us that an unequal society that has a good education system but for which we have no evidence about the health system is still likely to suffer from corruption.",
            "zh": "我们从这个结果中知道，CPI = 低的概率必须为 0.8。因此，网络将预测 CPI = low 作为查询的 MAP 目标值。这告诉我们，一个不平等的社会，如果有一个良好的教育系统，但我们没有关于卫生系统的证据，仍然有可能遭受腐败。"
        }
    },
    {
        "translation": {
            "en": "This new type of radiation was named the N ray (after the University of Nancy), and experiments were designed to demonstrate its existence.",
            "zh": "这种新型辐射被命名为N射线（以南锡大学的名字命名），并设计了实验来证明它的存在。"
        }
    },
    {
        "translation": {
            "en": "For example, neurons A and B are both in the receptive field of Neuron C, but neither A nor B feeds forward into any of the other neurons in the sub-sampling layer.",
            "zh": "例如，神经元 A 和 B 都位于神经元 C 的感受野中，但 A 和 B 都没有转发到子采样层中的任何其他神经元。"
        }
    },
    {
        "translation": {
            "en": "Using a simple random sample is the most straightforward way of avoiding biased samples.",
            "zh": "使用简单的随机样本是避免有偏差样本的最直接方法。"
        }
    },
    {
        "translation": {
            "en": "intelligent agent, 638, 639, 643, 676, 677",
            "zh": "智能代理， 638， 639， 643， 676， 677"
        }
    },
    {
        "translation": {
            "en": "root node, 121",
            "zh": "根节点，121"
        }
    },
    {
        "translation": {
            "en": "The distributions of the outputs of a model",
            "zh": "模型输出的分布"
        }
    },
    {
        "translation": {
            "en": "3. ∂ℰt+1/∂ct: the rate of change of the error of the network at time-step t+1 with respect to changes in the cell state ct that was propagated forward to the next time-step during the forward pass.",
            "zh": "3. ∂Et+1/∂ct：网络在时间步长 t+1 处的误差相对于在前向传递期间向前传播到下一个时间步的单元状态 ct 变化的变化率。"
        }
    },
    {
        "translation": {
            "en": "Using linear units in the output layer means that the output of the network can have the same range as the non-normalized target feature.",
            "zh": "在输出图层中使用线性单位意味着网络的输出可以与非归一化目标要素具有相同的范围。"
        }
    },
    {
        "translation": {
            "en": "These cumulative probability distributions can be plotted on a Kolmogorov-Smirnov chart (K-S chart).",
            "zh": "这些累积概率分布可以绘制在 Kolmogorov-Smirnov 控制图（K-S 控制图）上。"
        }
    },
    {
        "translation": {
            "en": "11.2.5 Temporal-Difference Learning",
            "zh": "11.2.5 时差学习"
        }
    },
    {
        "translation": {
            "en": "Doing this requires us to store the parameters of the model each time we observe a drop in the validation error.",
            "zh": "这样做需要我们在每次观察到验证误差下降时存储模型的参数。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.5(a)[38] shows these two different periods, assuming that the customer’s shopping behavior was measured from August 2012 through January 2013, and that whether they bought the product of interest was observed from February 2013 through April 2013.",
            "zh": "图2.5（a）[38]显示了这两个不同的时期，假设客户的购物行为是从2012年8月到2013年1月测量的，而他们是否购买了感兴趣的产品是从2013年2月到2013年4月。"
        }
    },
    {
        "translation": {
            "en": "In the context of model ensembles, this means that each model should make predictions independently of the other models in the ensemble.",
            "zh": "在模型集成的上下文中，这意味着每个模型都应独立于集成中的其他模型进行预测。"
        }
    },
    {
        "translation": {
            "en": "Consequently, data analysts need to think about the sources of the data they are using and understand how the data was collected and whether the collection processes introduced a bias relative to the population.",
            "zh": "因此，数据分析师需要考虑他们正在使用的数据来源，并了解数据是如何收集的，以及收集过程是否引入了相对于总体的偏差。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.22",
            "zh": "图 8.22"
        }
    },
    {
        "translation": {
            "en": "5.8   Exercises",
            "zh": "5.8 练习"
        }
    },
    {
        "translation": {
            "en": "In this instance, the human expert specifies that topology of the network, and the learning algorithm induces the CPT entries for nodes in the topology in the same way that we computed the conditional probabilities for the naive Bayes model.25",
            "zh": "在这个例子中，人类专家指定了网络的拓扑结构，学习算法以我们计算朴素贝叶斯模型的条件概率的方式诱导拓扑中节点的 CPT 条目25。"
        }
    },
    {
        "translation": {
            "en": "13.8   The confusion matrix for the 5-level logistic regression model (classification accuracy: 77.528%, average class accuracy: 43.018%).",
            "zh": "13.8 五级logistic回归模型的混淆矩阵（分类准确率：77.528%，平均类准确率：43.018%）。"
        }
    },
    {
        "translation": {
            "en": "The expectation maximization algorithm sits behind all of these and more than warrants careful study (Moon, 1996).",
            "zh": "期望最大化算法位于所有这些算法的背后，值得仔细研究（Moon，1996）。"
        }
    },
    {
        "translation": {
            "en": "22. Note that TwentyTwos is a much easier game to win than Blackjack, in which it is well known that the house always wins!",
            "zh": "22. 请注意，TwentyTwos 是一款比二十一点更容易获胜的游戏，众所周知，在二十一点中，房子总是赢！"
        }
    },
    {
        "translation": {
            "en": "Examples were labeled as don’t know when a Galaxy Zoo participant could not place the object in question into one of the other categories.",
            "zh": "示例被标记为不知道银河动物园参与者何时无法将有问题的物体放入其他类别之一。"
        }
    },
    {
        "translation": {
            "en": "FIBERFLUXIVAR_U/G/R/I/Z",
            "zh": "FIBERFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "To successfully model the relationship between grass growth and rainfall, we need to introduce non-linear elements.",
            "zh": "为了成功地模拟草生长和降雨之间的关系，我们需要引入非线性单元。"
        }
    },
    {
        "translation": {
            "en": "The position of your body on the board is key to doing this successfully.",
            "zh": "你的身体在棋盘上的位置是成功做到这一点的关键。"
        }
    },
    {
        "translation": {
            "en": "In this network the neurons are organized into a sequence of layers.",
            "zh": "在这个网络中，神经元被组织成一系列层。"
        }
    },
    {
        "translation": {
            "en": "The values for these cluster centroids can be selected randomly following uniform distributions bounded by the minimum and maximum values of each feature.",
            "zh": "这些聚类质心的值可以按照均匀分布随机选择，这些分布由每个特征的最小值和最大值限制。"
        }
    },
    {
        "translation": {
            "en": "0.2492",
            "zh": "0.2492"
        }
    },
    {
        "translation": {
            "en": "To calculate gain and lift, we first rank the predictions made for a test set in descending order by prediction score and then divide them into deciles.18 A decile is a group containing 10% of a dataset. Table 9.15[568] shows the data from Table 9.11[557] divided into deciles. There are 20 instances, so each decile contains just 2 instances. The first decile contains instances 9 and 4, the second decile contains instances 18 and 20, and so on.",
            "zh": "为了计算增益和提升，我们首先按预测分数按降序对测试集所做的预测进行排名，然后将它们划分为十分位数.18 十分位数是包含数据集 10% 的组。表9.15[568]显示了表9.11[557]中的数据，这些数据被划分为十分位数。有 20 个实例，因此每个十分位数仅包含 2 个实例。第一个十分位数包含实例 9 和 4，第二个十分位数包含实例 18 和 20，依此类推。"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce some of the fundamental operations in linear algebra. In particular, we introduce the vector and matrix operations that we use in the book.",
            "zh": "在本附录中，我们介绍了线性代数中的一些基本运算。特别是，我们介绍了我们在书中使用的向量和矩阵运算。"
        }
    },
    {
        "translation": {
            "en": "This analysis shows that adding layers to a network without including a non-linear activation function between the layers appears to add complexity to the network, but in reality the network remains equivalent to a single-layer linear network.",
            "zh": "该分析表明，在网络中添加层而不在层之间包含非线性激活函数似乎增加了网络的复杂性，但实际上网络仍然等同于单层线性网络。"
        }
    },
    {
        "translation": {
            "en": "For example, if we are dealing with binary features, it may be more appropriate to use the Russel-Rao, Sokal-Michener, or Jaccard similarity metric.",
            "zh": "例如，如果我们处理的是二进制特征，那么使用 Russel-Rao、Sokal-Michener 或 Jaccard 相似度量可能更合适。"
        }
    },
    {
        "translation": {
            "en": "This approach, however, can result in significant amounts of data loss and can introduce a bias into the dataset if the distribution of missing values in the dataset is not completely random.",
            "zh": "但是，如果数据集中缺失值的分布不是完全随机的，则这种方法可能会导致大量数据丢失，并且可能会在数据集中引入偏差。"
        }
    },
    {
        "translation": {
            "en": "This shows how the misclassification rate made by a model on a set of training instances changes as the training process continues.",
            "zh": "这显示了模型在一组训练实例上的错误分类率如何随着训练过程的继续而变化。"
        }
    },
    {
        "translation": {
            "en": "Different heuristics are often used for the bias terms and the weights.",
            "zh": "偏差项和权重通常使用不同的启发式方法。"
        }
    },
    {
        "translation": {
            "en": "A decision tree is then trained using the sample, and it is used to make predictions for each instance in the complete training set.",
            "zh": "然后使用样本训练决策树，并使用它对完整训练集中的每个实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "Zadnik, Karla, Lisa A. Jones, Brett C. Irvin, Robert N. Kleinstein, Ruth E. Manny, Julie A. Shin, and Donald O. Mutti. 2000. Vision: Myopia and ambient night-time lighting. Nature 404 (6774): 143–144. http://dx.doi.org/10.1038/35004661.",
            "zh": "Zadnik、Karla、Lisa A. Jones、Brett C. Irvin、Robert N. Kleinstein、Ruth E. Manny、Julie A. Shin 和 Donald O. Mutti。2000. 视觉：近视和夜间环境照明。自然404（6774）：143-144。http://dx.doi.org/10.1038/35004661。"
        }
    },
    {
        "translation": {
            "en": "locality sensitive hashing, 233",
            "zh": "局部敏感哈希，233"
        }
    },
    {
        "translation": {
            "en": "7. Stochastic gradient descent is a slightly different approach, in which an adjustment to each weight is made on the basis of the error in the prediction made by the candidate model for each training instance individually. This means that many more adjustments are made to the weights. We do not discuss stochastic gradient descent in any detail in this book, although the modifications that need to be made to the gradient descent algorithm for stochastic gradient descent are fairly simple.",
            "zh": "7. 随机梯度下降是一种略有不同的方法，其中根据候选模型对每个训练实例的预测误差对每个权重进行调整。这意味着对权重进行了更多的调整。在本书中，我们没有详细讨论随机梯度下降，尽管需要对随机梯度下降的梯度下降算法进行修改相当简单。"
        }
    },
    {
        "translation": {
            "en": "Hand, David, 586",
            "zh": "手，大卫，586"
        }
    },
    {
        "translation": {
            "en": "The most common way to tackle this issue is to perform evaluation experiments to investigate the performance of models with different values for k and to select the one that performs best.",
            "zh": "解决此问题的最常见方法是执行评估实验，以调查具有不同 k 值的模型的性能，并选择性能最佳的模型。"
        }
    },
    {
        "translation": {
            "en": "The issue with redundant and irrelevant features is inherent in any large dataset, and the feature selection techniques described in this chapter are generally applicable when any type of machine learning algorithm is being used.",
            "zh": "冗余和不相关的特征问题是任何大型数据集所固有的，本章中描述的特征选择技术通常适用于使用任何类型的机器学习算法。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, calculating a direction of descent by taking an average over a set of noisy examples can make the descent of the error surface smoother, which often means that we can use a larger learning rate α with batch gradient descent (i.e., we can take larger steps between weight updates because we are more confident of the direction we are moving).",
            "zh": "此外，通过对一组嘈杂的示例取平均值来计算下降方向可以使误差曲面的下降更平滑，这通常意味着我们可以使用更大的学习率α批量梯度下降（即，我们可以在权重更新之间采取更大的步骤，因为我们对移动的方向更有信心）。"
        }
    },
    {
        "translation": {
            "en": "Figure 12.6",
            "zh": "图 12.6"
        }
    },
    {
        "translation": {
            "en": "An agent behaving in an environment and the observation, reward, action cycle. The transition from observations of the environment to a state is shown by the state generation function, ϕ.",
            "zh": "智能体在环境中的行为以及观察、奖励、行动循环。从环境观察到状态的转变由状态生成函数 φ 表示。"
        }
    },
    {
        "translation": {
            "en": "Table 3.5",
            "zh": "表 3.5"
        }
    },
    {
        "translation": {
            "en": "13.1.1   Situational Fluency",
            "zh": "13.1.1 情境流畅性"
        }
    },
    {
        "translation": {
            "en": "Calculate the missing point in the ROC curves for Model 1 and Model 2. To generate the point for Model 1, use a threshold value of 0.51. To generate the point for Model 2, use a threshold value of 0.43.",
            "zh": "计算模型 1 和模型 2 的 ROC 曲线中的缺失点。要生成模型 1 的点，请使用阈值 0.51。要生成模型 2 的点，请使用阈值 0.43。"
        }
    },
    {
        "translation": {
            "en": "In statistics the degrees of freedom of a distribution is the number of variables in the calculation of the statistic that are free to vary.",
            "zh": "在统计学中，分布的自由度是统计量计算中可以自由变化的变量数。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.18[440] shows the forward propagation of the examples in Table 8.3[423] through the same network that we used in the worked example, with the single difference that all the neurons in the network are now ReLUs.24 Table 8.10[441] lists the per example error of this ReLU network resulting from the forward pass in Figure 8.18[440]. This table also lists the sum of squared errors for the ReLU model.25",
            "zh": "图8.18[440]显示了表8.3[423]中示例通过我们在工作示例中使用的相同网络的前向传播，唯一的区别是网络中的所有神经元现在都是ReLU.24表8.10[441]列出了图8.18[440]中前向传递导致的ReLU网络的每个示例错误。此表还列出了 ReLU 模型的平方误差总和25。"
        }
    },
    {
        "translation": {
            "en": "We can see the assumptions encoded in each algorithm reflected in the distinctive characteristics of the decision boundaries that they learn for categorical prediction tasks.",
            "zh": "我们可以看到每个算法中编码的假设反映在它们为分类预测任务学习的决策边界的显着特征中。"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy to understand the sequences of tests a decision tree carried out in order to make a prediction.",
            "zh": "理解决策树为了做出预测而执行的测试序列相对容易。"
        }
    },
    {
        "translation": {
            "en": "Parametric",
            "zh": "参数"
        }
    },
    {
        "translation": {
            "en": "To help with this, we would recommend Hastie et al.",
            "zh": "为了帮助解决这个问题，我们推荐 Hastie 等人。"
        }
    },
    {
        "translation": {
            "en": "There are, however, many domains in which the data has a sequential varying-length structure and in which interactions between data points may span long distances in the sequence.",
            "zh": "但是，在许多域中，数据具有顺序可变长度结构，并且数据点之间的交互可能跨越序列中的长距离。"
        }
    },
    {
        "translation": {
            "en": "Hence dropout can be understood as a regularization technique that improves the stability of the resulting model.",
            "zh": "因此，dropout 可以理解为一种正则化技术，可以提高结果模型的稳定性。"
        }
    },
    {
        "translation": {
            "en": "The values in Table 11.2[654] actually show the entries in the action-value table learned for TwentyTwos after 100,000 episodes of Q-learning.21 Examining the actions with the maximum expected return in each state shows that the target policy learned is overwhelmingly to Stick, with Twist being the best action only in the PL-DL, PL-DH, and PM-DH states.",
            "zh": "表 11.2[654] 中的值实际上显示了 100,000 集 Q-learning 后为 TwentyTwos 学习的动作值表中的条目。21 检查每个状态中具有最大预期回报的动作表明，学习的目标策略绝大多数是坚持，而 Twist 仅在 PL-DL、PL-DH 和 PM-DH 状态中是最佳动作。"
        }
    },
    {
        "translation": {
            "en": "ε0 bootstrap, 546",
            "zh": "ε0 自举，546"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we want to compute the probability of P(h) in the domain specified by the joint probability distribution P(H,F,V,M).",
            "zh": "例如，假设我们要计算由联合概率分布 P（H，F，V，M） 指定的域中 P（h） 的概率。"
        }
    },
    {
        "translation": {
            "en": "In this section we provide a short overview of the technical notation used throughout this book.",
            "zh": "在本节中，我们将简要概述本书中使用的技术符号。"
        }
    },
    {
        "translation": {
            "en": "Table A.2",
            "zh": "表 A.2"
        }
    },
    {
        "translation": {
            "en": "data fragmentation, 255, 262",
            "zh": "数据碎片， 255， 262"
        }
    },
    {
        "translation": {
            "en": "If a model were performing no better than random guessing, we would expect that within each decile, the percentage of positive instances should be the same as the percentage of positive instances overall in the complete dataset.",
            "zh": "如果一个模型的表现并不比随机猜测好，我们预计在每个十分位数内，阳性实例的百分比应该与整个数据集中总体阳性实例的百分比相同。"
        }
    },
    {
        "translation": {
            "en": "Throughout this book we discuss the use of machine learning algorithms to train prediction models based on datasets. The following list explains the notation used to refer to different elements in a dataset. Figure 0.1[xxiii] illustrates the key notation using a simple sample dataset.",
            "zh": "在本书中，我们讨论了使用机器学习算法来训练基于数据集的预测模型。以下列表说明了用于引用数据集中不同元素的表示法。图 0.1[xxiii] 使用简单的示例数据集说明了键表示法。"
        }
    },
    {
        "translation": {
            "en": "It is important that for each feature in the ABT, we understand characteristics such as the types of values a feature can take, the ranges into which the values in a feature fall, and how the values in a dataset for a feature are distributed across the range that they can take.",
            "zh": "对于 ABT 中的每个特征，我们必须了解特征，例如特征可以采用的值类型、特征中的值所属范围以及特征数据集中的值如何在它们可以采用的范围内分布。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9(a)[79] shows a histogram of the AGE feature from the dataset in Table 3.7[73].",
            "zh": "图3.9（a）[79]显示了表3.7[73]中数据集中AGE特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "0.0542",
            "zh": "0.0542"
        }
    },
    {
        "translation": {
            "en": "1. The table below lists a dataset that was used to create a nearest neighbor model that predicts whether it will be a good day to go surfing.",
            "zh": "1. 下表列出了一个数据集，该数据集用于创建最近邻模型，该模型预测今天是否是冲浪的好日子。"
        }
    },
    {
        "translation": {
            "en": "The goal of k-means clustering is to take a dataset, , consisting of n instances, d1 to dn, where di is a set of m descriptive features, and divide this dataset into k disjoint clusters, 1 to k. The number of clusters to be found, k, is an input to the algorithm and each instance can belong to only one cluster.",
            "zh": "k-means 聚类的目标是获取一个数据集，该数据集由 n 个实例（d1 到 dn）组成，其中 di 是一组 m 描述性特征，并将该数据集划分为 k 个不相交聚类（1 到 k）。要找到的聚类数 k 是算法的输入，每个实例只能属于一个聚类。"
        }
    },
    {
        "translation": {
            "en": "For example, the probability distribution for the binary feature MENINGITIS from Table 6.1[246] is P(MENINGITIS) = 0.3,0.7 (by convention we give the true probability first).",
            "zh": "例如，表 6.1[246] 中二元特征脑膜炎的概率分布为 P（MENINGITIS） = 0.3,0.7（按照惯例，我们首先给出真实概率）。"
        }
    },
    {
        "translation": {
            "en": "This last issue is interesting because sometimes particular performance measures become especially popular in certain industries, and in many cases, this dictates the choice of performance measure.",
            "zh": "最后一个问题很有意思，因为有时特定的绩效衡量标准在某些行业中变得特别流行，在许多情况下，这决定了绩效衡量标准的选择。"
        }
    },
    {
        "translation": {
            "en": "B.2   A simple dataset for MENINGITIS with three common symptoms of the disease listed as descriptive features: HEADACHE, FEVER, and VOMITING.",
            "zh": "B.2 脑膜炎的简单数据集，该疾病的三种常见症状被列为描述性特征：头痛、发烧和呕吐。"
        }
    },
    {
        "translation": {
            "en": "We have used the convention of a gray background to track the flow of the second example (d2) through the network: the input vector for d2 is < bias = 1, AMBIENT TEMPERATURE = 0.84, RELATIVE HUMIDITY = 0.58 >.",
            "zh": "我们使用灰色背景的约定来跟踪第二个示例 （d2） 通过网络的流量：d2 的输入向量<偏置 = 1，环境温度 = 0.84，相对湿度 = 0.58 >。"
        }
    },
    {
        "translation": {
            "en": "8. The table is too wide to fit on a page, so it has been split into three sections.",
            "zh": "8. 表格太宽，无法放在页面上，因此将其分为三个部分。"
        }
    },
    {
        "translation": {
            "en": "This is known as discounted return.",
            "zh": "这被称为折扣退货。"
        }
    },
    {
        "translation": {
            "en": "6.4.2   Continuous Features: Probability Density Functions",
            "zh": "6.4.2 连续特征：概率密度函数"
        }
    },
    {
        "translation": {
            "en": "A new set of errors are then calculated by comparing the 1 predictions to the target feature values.",
            "zh": "然后，通过将 1 个预测值与目标要素值进行比较来计算一组新的误差。"
        }
    },
    {
        "translation": {
            "en": "To do this, the algorithm needs to decide which of the remaining descriptive features has the highest information gain for each partition.",
            "zh": "为此，算法需要确定每个分区的其余描述性特征中哪个具有最高的信息增益。"
        }
    },
    {
        "translation": {
            "en": "One descriptive feature is included for each word in a predefined dictionary.",
            "zh": "预定义词典中的每个单词都包含一个描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Having both of these numbers is useful as it allows us to think about tuning the model toward one kind of error or the other.",
            "zh": "拥有这两个数字很有用，因为它允许我们考虑将模型调整为一种或另一种错误。"
        }
    },
    {
        "translation": {
            "en": "Similarity-based learning (Chapter 5[181])",
            "zh": "基于相似性的学习（第5章[181]）"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the probabilities required by a naive Bayes model to represent this domain.",
            "zh": "（c） 计算朴素贝叶斯模型表示该域所需的概率。"
        }
    },
    {
        "translation": {
            "en": "random sampling with replacement, 93",
            "zh": "随机抽样替换，93"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor prediction algorithm creates a set of local models, or neighborhoods, across the feature space where each model is defined by a subset of the training dataset (in this case, one instance).",
            "zh": "最近邻预测算法在特征空间中创建一组局部模型或邻域，其中每个模型由训练数据集的子集（在本例中为一个实例）定义。"
        }
    },
    {
        "translation": {
            "en": "In the two-dimensional feature space in Figure 5.18(d)[226], we have maintained the sampling density (the density of the marked unit hypercube is ) at the expense of a very large increase in the number of instances—there are 29 × 29 = 841 instances plotted in this figure.",
            "zh": "在图5.18（d）[226]的二维特征空间中，我们保持了采样密度（标记单位超立方体的密度是），但代价是实例数量的大幅增加——该图中绘制了 29 个实例× 29 = 841 个实例。"
        }
    },
    {
        "translation": {
            "en": "For example, the Claim Frequency domain subconcept under the Claimant History concept should capture the fact that the number of claims a claimant has made in the past has an impact on the likelihood of a new claim being fraudulent.",
            "zh": "例如，“索赔人历史记录”概念下的“索赔频域子概念应涵盖索赔人过去提出的索赔数量对新索赔具有欺诈性的可能性有影响的事实。"
        }
    },
    {
        "translation": {
            "en": "To change the ID3 algorithm in Algorithm 1[134] to select features to split on based on variance, we replace Line 1 with Equation 4.11[150].",
            "zh": "为了改变算法1[134]中的ID3算法，以选择要根据方差进行拆分的特征，我们将线1替换为公式4.11[150]。"
        }
    },
    {
        "translation": {
            "en": "Part II[117] of the book includes Chapters 4 to 9 and covers the main supervised machine learning material.",
            "zh": "本书的第二部分[117]包括第4章至第9章，涵盖了主要的监督机器学习材料。"
        }
    },
    {
        "translation": {
            "en": "We use this data to train and evaluate a machine learning model that will then be deployed for use on newly arising data.",
            "zh": "我们使用这些数据来训练和评估机器学习模型，然后部署该模型以用于新出现的数据。"
        }
    },
    {
        "translation": {
            "en": "Another advantage of binning, especially equal-frequency binning, is that it goes some way toward handling outliers.",
            "zh": "像素合并（尤其是等频像素合并）的另一个优点是，它在某种程度上可以处理异常值。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.2(b)[316] shows the office rentals dataset and the candidate model with w[0] = 6.47 and w[1] = 0.62 and also includes error bars to highlight the differences between the predictions made by the model and the actual RENTAL PRICE values in the training data.",
            "zh": "图 7.2（b）[316] 显示了 w[0] = 6.47 和 w[1] = 0.62 的办公室租赁数据集和候选模型，还包括误差线，以突出模型所做的预测与训练数据中的实际 RENTAL PRICE 值之间的差异。"
        }
    },
    {
        "translation": {
            "en": "How do we relate these values to the actual underlying population?",
            "zh": "我们如何将这些值与实际的潜在人口联系起来？"
        }
    },
    {
        "translation": {
            "en": "Cross-referencing Figure 8.14[425], these z and a values are found in the corresponding gray boxes in that figure.",
            "zh": "交叉引用图8.14[425]，这些z值和a值位于该图中相应的灰色框中。"
        }
    },
    {
        "translation": {
            "en": "In this example single linkage is used and so the distance between two clusters is calculated as the minimum distance between their member instances.",
            "zh": "在此示例中，使用单链接，因此两个集群之间的距离计算为其成员实例之间的最小距离。"
        }
    },
    {
        "translation": {
            "en": "Mahalanobis distance, 217, 223, 231, 242",
            "zh": "马哈拉诺比斯距离， 217， 223， 231， 242"
        }
    },
    {
        "translation": {
            "en": "Table 8.15",
            "zh": "表 8.15"
        }
    },
    {
        "translation": {
            "en": "The Corruption Perception Index is for 2011 and was retrieved from Transparency International (www.transparency.org).",
            "zh": "清廉指数是2011年的，取自透明国际（www.transparency.org）。"
        }
    },
    {
        "translation": {
            "en": "34. Learning rates are discussed in much more detail in Chapter 7[311].",
            "zh": "34. 学习率在第7章[311]中有更详细的讨论。"
        }
    },
    {
        "translation": {
            "en": "1. An agent in an environment completes an episode and receives the following rewards:",
            "zh": "1. 环境中的代理完成一集并获得以下奖励："
        }
    },
    {
        "translation": {
            "en": "The first step in building a gradient boosting model for this problem is to train the initial model, 0.",
            "zh": "为这个问题构建梯度提升模型的第一步是训练初始模型 0。"
        }
    },
    {
        "translation": {
            "en": "The matrix on the left of Equation (8.95)[491] represents the 6-by-6 layer of neurons that share the filter listed in Equation (8.94)[490].",
            "zh": "等式（8.95）[491]左侧的矩阵表示共享等式（8.94）[490]中列出的滤波器的6×6神经元层。"
        }
    },
    {
        "translation": {
            "en": "The forget gate removes information from the cell, the input gate adds information to the cell, and the output gate decides which information should be output by the network at the current time-step.",
            "zh": "遗忘门从小区中删除信息，输入门向小区添加信息，输出门决定网络在当前时间步长应输出哪些信息。"
        }
    },
    {
        "translation": {
            "en": "These δ values are the error gradients that are backpropagated during the backward pass of the backpropagation algorithm.",
            "zh": "这些δ值是在反向传播算法向后传递期间反向传播的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Tables 9.9(a)[555] and 9.9(b)[555] show confusion matrices for two different prediction models, a k-NN model and a decision tree model, trained for the payday loans credit scoring problem. The average class accuracy (using a harmonic mean) for the k-NN model is 83.824% and for the decision tree model is 80.761%, which suggests that the k-NN model is quite a bit better than the decision tree.",
            "zh": "表9.9（a）[555]和表9.9（b）[555]显示了两种不同预测模型的混淆矩阵，即k-NN模型和决策树模型，针对发薪日贷款信用评分问题进行了训练。k-NN模型的平均类准确率（使用谐波平均值）为83.824%，决策树模型的平均类准确率为80.761%，这表明k-NN模型比决策树好得多。"
        }
    },
    {
        "translation": {
            "en": "The implication of this is that once we have calculated the δ for a neuron, all we need to do to calculate the sensitivity of the network error with respect to a weight on a connection coming into the neuron is to multiply the neuron’s δ by the activation that was propagated forward on that connection. Equation (8.27)[414] shows how the chain rule product is eventually simplified to the simple product of a δ by an activation",
            "zh": "这意味着，一旦我们计算了神经元的δ，我们需要做的就是计算网络误差相对于进入神经元的连接上的权重的敏感性，就是将神经元的δ乘以在该连接上向前传播的激活。方程（8.27）[414]显示了链式法则乘积如何通过激活最终简化为δ的简单乘积"
        }
    },
    {
        "translation": {
            "en": "The Organisation for Economic Co-operation and Development (OECD, 2013) defines a set of eight general principles of data protection legislation.7 For the design of analytics base tables, three are especially relevant: the collection limitation principle, the purpose specification principle, and the use limitation principle.",
            "zh": "经济合作与发展组织（OECD，2013）定义了一套八项数据保护立法的一般原则.7对于分析基表的设计，有三项特别相关：收集限制原则、目的规范原则和使用限制原则。"
        }
    },
    {
        "translation": {
            "en": "The second example, Figure 3.8(b)[79], shows the POSITION and SHOE SPONSOR features.",
            "zh": "第二个示例，图 3.8（b）[79]，显示了 POSITION 和 SHOE SPONSOR 功能。"
        }
    },
    {
        "translation": {
            "en": "Similarly, in fraud detection, the fraud events would most likely be the positive level; in credit scoring, the default events would most likely be the positive level; and in disease diagnosis, a confirmation that a patient has the disease would most likely be the positive level.",
            "zh": "同样，在欺诈检测中，欺诈事件很可能是正值;在信用评分中，违约事件很可能是正值;在疾病诊断中，确认患者患有该疾病很可能是阳性水平。"
        }
    },
    {
        "translation": {
            "en": "One of the drawbacks of using this method to detect that a model has gone stale is that estimating how large this change needs to be in order to signal that the model has gone stale is entirely domain dependent.23",
            "zh": "使用此方法检测模型是否过时的缺点之一是，估计此更改需要多大才能发出模型已过时的信号，这完全取决于领域23。"
        }
    },
    {
        "translation": {
            "en": "(c) A standardization of the data",
            "zh": "（c） 数据标准化"
        }
    },
    {
        "translation": {
            "en": "(a) A stacked bar plot for the REGIONTYPE feature; and (b) histograms for the AVGOVERBUNDLEMINS feature by target feature value.",
            "zh": "（a） REGIONTYPE 特征的堆积条形图;以及 （b） 按目标特征值划分的 AVGOVERBUNDLEMINS 特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "A single screenshot of a game does not contain sufficient information about the state of an environment and an agent for the environment to be considered fully observable, and so the Markov assumption does not hold.",
            "zh": "游戏的单个屏幕截图不包含有关环境状态和环境代理的足够信息，因此马尔可夫假设不成立。"
        }
    },
    {
        "translation": {
            "en": "3. This practice was first systematically applied by Edwin Hubble in 1936 (Hubble, 1936).",
            "zh": "3. 埃德温·哈勃（Edwin Hubble）于1936年首次系统地应用了这种做法（哈勃，1936年）。"
        }
    },
    {
        "translation": {
            "en": "Often when an ABT is generated, some instances will be missing values for one or more features.",
            "zh": "通常，在生成 ABT 时，某些实例将缺少一个或多个特征的值。"
        }
    },
    {
        "translation": {
            "en": "This is an instance of a constrained quadratic optimization problem, and there are well-known approaches to solving this type of problem.",
            "zh": "这是约束二次优化问题的一个实例，并且有众所周知的方法可以解决此类问题。"
        }
    },
    {
        "translation": {
            "en": "This can cause the network training process to become unstable as small change in the outputs of the action-value network can lead to sudden changes in the policy as a different action is suddenly favored in a type of state.",
            "zh": "这可能会导致网络训练过程变得不稳定，因为动作值网络输出的微小变化可能会导致策略的突然变化，因为在一种状态下突然偏爱不同的动作。"
        }
    },
    {
        "translation": {
            "en": "When undertaking this process, it is important to take into account the availability of data and the capacity of a business to take advantage of insights arising from analytics models, as otherwise it is possible to construct an apparently accurate prediction model that is in fact useless.",
            "zh": "在进行此过程时，重要的是要考虑数据的可用性和企业利用分析模型产生的见解的能力，否则就有可能构建一个看似准确的预测模型，但实际上毫无用处。"
        }
    },
    {
        "translation": {
            "en": "ROC space, 559",
            "zh": "中华民国空间，559"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12(a)[205] presents a plot of the feature space defined by the SALARY and AGE features, containing the dataset in Table 5.5[204].",
            "zh": "图5.12（a）[205]显示了由PAYRY和AGE特征定义的特征空间图，其中包含表5.5[204]中的数据集。"
        }
    },
    {
        "translation": {
            "en": "For any business problem, there are a number of different analytics solutions that we could build to address it.",
            "zh": "对于任何业务问题，我们可以构建许多不同的分析解决方案来解决它。"
        }
    },
    {
        "translation": {
            "en": "This issue often arises because multiple levels are used to represent the same thing—for example, in a feature storing gender, we might find levels of male, female, m, f, M, and F, which all represent male and female in slightly different ways.",
            "zh": "之所以出现此问题，通常是因为使用多个级别来表示同一事物 - 例如，在存储性别的特征中，我们可能会发现 male、female、m、f、M 和 F 的级别，它们都以略微不同的方式表示男性和女性。"
        }
    },
    {
        "translation": {
            "en": "7.5 Summary",
            "zh": "7.5 小结"
        }
    },
    {
        "translation": {
            "en": "This dataset contains just nine instances (the instance labels have been kept consistent so that this example can be compared with previous ones) and is shown in Figure 10.12(a)[621].",
            "zh": "该数据集仅包含 9 个实例（实例标签保持一致，以便此示例可以与以前的示例进行比较），如图 10.12（a）[621] 所示。"
        }
    },
    {
        "translation": {
            "en": "Concretely, this means that in each weight update, the weights in the earlier layers in the network are updated by smaller amounts than the neurons in the later layers.",
            "zh": "具体来说，这意味着在每次权重更新中，网络中早期层的权重更新量小于后层神经元的权重。"
        }
    },
    {
        "translation": {
            "en": "This may not be a good thing if this instance is due to noise in the data, and this demonstrates that there is no silver bullet solution to handling noise in datasets.",
            "zh": "如果此实例是由于数据中的噪声引起的，这可能不是一件好事，这表明处理数据集中的噪声没有灵丹妙药解决方案。"
        }
    },
    {
        "translation": {
            "en": "cumulative reward, 640, 643, 676",
            "zh": "累计奖励， 640， 643， 676"
        }
    },
    {
        "translation": {
            "en": "It is usually home to small animals, including raccoons, frogs, and toads.",
            "zh": "它通常是小动物的家园，包括浣熊、青蛙和蟾蜍。"
        }
    },
    {
        "translation": {
            "en": "In the case of Claimant History, the domain subconcept of Claim Types explicitly recognizes the importance of designing descriptive features to capture the different types of claims the claimant has been involved in in the past, and the Claim Frequency domain subconcept identifies the need to have descriptive features relating to the frequency with which the claimant has been involved in claims.",
            "zh": "就索赔人历史而言，索赔类型的领域子概念明确认识到设计描述性特征以捕捉索赔人过去参与的不同类型的索赔的重要性，而索赔频域子概念则确定需要具有与索赔人参与索赔的频率相关的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The dendrites of one neuron connect to the axons of other neurons via connections known as synapses.",
            "zh": "一个神经元的树突通过称为突触的连接连接到其他神经元的轴突。"
        }
    },
    {
        "translation": {
            "en": "sampling method, 541, 546",
            "zh": "抽样法，541,546"
        }
    },
    {
        "translation": {
            "en": "The C4.5 algorithm is a well-known variant of the ID3 algorithm that uses these extensions to handle continuous and categorical descriptive features and missing features.",
            "zh": "C4.5 算法是 ID3 算法的一个众所周知的变体，它使用这些扩展来处理连续和分类的描述性特征和缺失的特征。"
        }
    },
    {
        "translation": {
            "en": "This section introduces the fundamentals of reinforcement learning.",
            "zh": "本节介绍强化学习的基础知识。"
        }
    },
    {
        "translation": {
            "en": "The agent earns a reward of + 100 for landing successfully and a reward of − 100 for crashing.",
            "zh": "特工成功着陆可获得 + 100 的奖励，坠毁可获得 − 100 的奖励。"
        }
    },
    {
        "translation": {
            "en": "This epilogue illustrates two important, and related, aspects of supervised machine learning.",
            "zh": "本结语说明了监督机器学习的两个重要且相关的方面。"
        }
    },
    {
        "translation": {
            "en": "6. The following table shows the IQs for a group of people who applied to take part in a television general-knowledge quiz.",
            "zh": "6. 下表显示了一组申请参加电视常识测验的人的智商。"
        }
    },
    {
        "translation": {
            "en": "This calculation shows that if a neuron uses the set of weights in Equation (8.85)[480], then the activation of the neuron is solely dependent on the values along the middle row of inputs.",
            "zh": "该计算表明，如果神经元使用方程（8.85）[480]中的权重集，则神经元的激活完全取决于沿中间输入行的值。"
        }
    },
    {
        "translation": {
            "en": "11.2   A simple Markov process to model the evolution of an infectious disease in individuals during an epidemic using the SUSCEPTIBLE-INFECTED-RECOVERED (S-I-R) model.",
            "zh": "11.2 一个简单的马尔可夫过程，使用易感-感染-康复 （S-I-R） 模型对流行病期间个体传染病的演变进行建模。"
        }
    },
    {
        "translation": {
            "en": "For example, in 1936 it was not necessarily obvious that using telephone directories to create an initial list of names would skew the resulting sample toward a particular group in the population (in this instance, Republicans).",
            "zh": "例如，在 1936 年，使用电话簿创建初始姓名列表会使结果样本偏向人口中的特定群体（在本例中为共和党人）并不一定很明显。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the SALARY feature dominates the computation of the Euclidean distance whether we include the AGE feature or not.",
            "zh": "因此，无论我们是否包括 AGE 特征，SALARY 特征都主导着欧几里得距离的计算。"
        }
    },
    {
        "translation": {
            "en": "The second kind of mistake that makes people incorrectly infer causation between two features is ignoring a third important, but hidden, feature.",
            "zh": "使人们错误地推断两个特征之间因果关系的第二种错误是忽略了第三个重要但隐藏的特征。"
        }
    },
    {
        "translation": {
            "en": "This indicates that the UNKNOWN SENDER feature is not as good at discriminating between spam and ham emails as the SUSPICIOUS WORDS feature.",
            "zh": "这表明 UNKNOWN SENDER 功能在区分垃圾邮件和业余电子邮件方面不如 SUSPICIOUS WORDS 功能。"
        }
    },
    {
        "translation": {
            "en": "Doing this does necessitate that in order to retrieve the predicted value of the target in the original range of the target feature, the output from the network must be mapped back to the original scale for the target feature, but generally, this is not a difficult thing to do.",
            "zh": "这样做确实需要，为了在目标要素的原始范围内检索目标的预测值，必须将网络的输出映射回目标要素的原始比例，但一般来说，这不是一件难事。"
        }
    },
    {
        "translation": {
            "en": "We have a test set containing instances for which we know the correct target values, and we have a set of predictions made by a model.",
            "zh": "我们有一个测试集，其中包含我们知道正确目标值的实例，并且我们有一组由模型做出的预测。"
        }
    },
    {
        "translation": {
            "en": "cut a hierarchical agglomeration, 622",
            "zh": "切割一个等级集聚，622"
        }
    },
    {
        "translation": {
            "en": "Each time a prediction is made, the query instance can be added into the dataset and used in subsequent predictions.32 In this way, a nearest neighbor model can be easily updated, which makes it relatively robust to concept drift (we will return to concept drift in Section 9.4.6[578]).",
            "zh": "每次进行预测时，都可以将查询实例添加到数据集中，并在后续预测中使用.32 通过这种方式，最近邻模型可以很容易地更新，这使得它对概念漂移相对鲁棒（我们将在第 9.4.6 节中返回概念漂移[578]）。"
        }
    },
    {
        "translation": {
            "en": "14.2.2 Matching Machine Learning Approaches to Data",
            "zh": "14.2.2 将机器学习方法与数据相匹配"
        }
    },
    {
        "translation": {
            "en": "4.18   The decision tree for the post-operative patient routing task.",
            "zh": "4.18 术后患者路由任务的决策树。"
        }
    },
    {
        "translation": {
            "en": "subset selection, 228",
            "zh": "子集选择，228"
        }
    },
    {
        "translation": {
            "en": "The minimum and maximum values for the AMBIENT TEMPERATURE, RELATIVE HUMIDITY, and ELECTRICAL OUTPUT features in the power plant dataset.",
            "zh": "电厂数据集中 AMBIENT TEMPERATURE、RELATIVE HUMIDITY 和 ELECTRICAL OUTPUT 要素的最小值和最大值。"
        }
    },
    {
        "translation": {
            "en": "We are now ready to use Bayes’ Theorem to generate predictions based on a dataset. The next section will examine how this is done.",
            "zh": "我们现在可以使用贝叶斯定理来生成基于数据集的预测。下一节将研究如何做到这一点。"
        }
    },
    {
        "translation": {
            "en": "The network architecture shown in Figure 8.4[390] is an example of a feedforward network.",
            "zh": "图 8.4[390] 所示的网络架构是前馈网络的一个示例。"
        }
    },
    {
        "translation": {
            "en": "Imputation, however, should not be used for features that have very large numbers of missing values because imputing a very large number of missing values will change the central tendency of a feature too much. We would be reluctant to use imputation on features missing in excess of 30% of their values and would strongly recommend against the use of imputation on features missing in excess of 50% of their values.",
            "zh": "但是，不应将插补用于具有大量缺失值的特征，因为插补大量缺失值会过多地改变特征的中心趋势。我们不愿意对缺失超过其值 30% 的要素使用插补，并强烈建议不要对缺失超过其值 50% 的要素使用插补。"
        }
    },
    {
        "translation": {
            "en": "Root mean squared error values are in the same units as the target value and so allow us to say something more meaningful about what the error for predictions made by the model will be.",
            "zh": "均方根误差值与目标值的单位相同，因此允许我们说明模型所做的预测误差将是多少更有意义。"
        }
    },
    {
        "translation": {
            "en": "thank you for your love, support, and patience.",
            "zh": "感谢您的爱、支持和耐心。"
        }
    },
    {
        "translation": {
            "en": "BLAND",
            "zh": "乏味"
        }
    },
    {
        "translation": {
            "en": "If we were able to merge the bins in the regions where there are very few instances, then the resulting spare bins could be used to represent the differences between instances in the regions where lots of instances are clustered together.",
            "zh": "如果我们能够合并实例很少的区域中的 bin，那么生成的备用 bin 可用于表示大量实例聚集在一起的区域中实例之间的差异。"
        }
    },
    {
        "translation": {
            "en": "Table 5.2",
            "zh": "表 5.2"
        }
    },
    {
        "translation": {
            "en": "Due to its expanded size, this edition of the book has been organized into five parts: Part I: Introduction to Machine Learning and Data Analytics; Part II: Predictive Data Analytics; Part III: Beyond Prediction; Part IV: Case Studies and Conclusions; and Part V: Appendices.",
            "zh": "由于篇幅较大，本版本书分为五个部分：第一部分：机器学习和数据分析简介;第二部分：预测性数据分析;第三部分：超越预测;第四部分：案例研究和结论;第五部分：附录。"
        }
    },
    {
        "translation": {
            "en": "The agent then continues to move across the environment making sequential updates to the action-value table until eventually it reaches the goal state after making 150 moves and accumulating a total reward of − 891.",
            "zh": "然后，智能体继续在环境中移动，对操作值表进行顺序更新，直到在移动 150 次并累积总奖励 − 891 后最终达到目标状态。"
        }
    },
    {
        "translation": {
            "en": "We would also like to thank the staff at MIT Press, particularly Marie Lufkin Lee and our editors Melanie Mallon (1st Edition), as well as Theresa Carcaldi of Westchester Publishing Services (2nd Edition).",
            "zh": "我们还要感谢麻省理工学院出版社的工作人员，特别是 Marie Lufkin Lee 和我们的编辑 Melanie Mallon（第 1 版），以及 Westchester Publishing Services（第 2 版）的 Theresa Carcaldi。"
        }
    },
    {
        "translation": {
            "en": "The standard deviation, sd, of a sample is calculated by taking the square root of the variance of the sample:",
            "zh": "样本的标准差 sd 是通过取样本方差的平方根来计算的："
        }
    },
    {
        "translation": {
            "en": "Notice that the vertical axes in these histograms are labeled density, rather than frequency.",
            "zh": "请注意，这些直方图中的垂直轴标记为密度，而不是频率。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.6(a)[39] shows an illustration of this kind of data, while Figure 2.6(b)[39] shows how this is aligned so that descriptive and target features can be extracted to build an ABT.",
            "zh": "图 2.6（a）[39] 显示了此类数据的插图，而图 2.6（b）[39] 显示了如何对齐，以便可以提取描述性和目标特征以构建 ABT。"
        }
    },
    {
        "translation": {
            "en": "This would mean that the confusion matrix would change to that shown in Table 9.12(a)[559] and, in turn, that the TPR and TNR measures would change to 0.5 and 0.833 respectively.",
            "zh": "这意味着混淆矩阵将更改为表9.12（a）[559]所示的矩阵，反过来，TPR和TNR测量值将分别更改为0.5和0.833。"
        }
    },
    {
        "translation": {
            "en": "Minsky, Marvin, and Seymour Papert. 1969. Perceptrons. MIT Press.",
            "zh": "明斯基、马文和西摩·帕珀特。1969. 感知器。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "long tails, 59",
            "zh": "长尾巴，59"
        }
    },
    {
        "translation": {
            "en": "A consequence of this, and a somewhat less obvious requirement of similarity-based learning, is that if we are going to compute distances between instances, we need to have a concept of space in the representation of the domain used by our model.",
            "zh": "这样做的一个结果，以及基于相似性的学习的一个不太明显的要求是，如果我们要计算实例之间的距离，我们需要在模型使用的域的表示中有一个空间概念。"
        }
    },
    {
        "translation": {
            "en": "The first three types are self-explanatory and match directly with the categories of interest to the SDSS project.",
            "zh": "前三种类型是不言自明的，与SDSS项目感兴趣的类别直接匹配。"
        }
    },
    {
        "translation": {
            "en": "We will explain why the logistic function became so popular as an activation function when we introduce the backpropagation algorithm (see Section 8.3[403]), and why the rectified linear function replaced it when we explain the vanishing gradient problem (see Section 8.4.1[434]).",
            "zh": "当我们引入反向传播算法时，我们将解释为什么逻辑函数作为激活函数如此受欢迎（参见第 8.3 节[403]），以及为什么当我们解释消失梯度问题时，整流线性函数取代了它（参见第 8.4.1 节[434]）。"
        }
    },
    {
        "translation": {
            "en": "A general principle that we can derive from this is that neurons with saturated activation functions learn slowly (or not at all), and so we should take care when initializing weights to avoid saturating neurons.",
            "zh": "我们可以从中得出一个一般原则，即具有饱和激活函数的神经元学习缓慢（或根本不学习），因此我们在初始化权重时应该小心，以避免神经元饱和。"
        }
    },
    {
        "translation": {
            "en": "We use the symbol ℰ to denote the error of the network at the output layer.",
            "zh": "我们使用符号 E 来表示输出层的网络误差。"
        }
    },
    {
        "translation": {
            "en": "9.4.2.4 Measuring profit and loss One of the problems faced by all the performance measures discussed so far is that they place the same value on all the cells within a confusion matrix.",
            "zh": "9.4.2.4 衡量损益 迄今为止讨论的所有绩效衡量标准面临的一个问题是，它们对混淆矩阵中的所有单元格都具有相同的值。"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are often used in text analytics applications.",
            "zh": "最近邻模型通常用于文本分析应用程序。"
        }
    },
    {
        "translation": {
            "en": "Table 7.4[333] repeats the final weights for the office rentals model trained in Section 7.3.4[330].",
            "zh": "表 7.4[333] 重复了第 7.3.4 节[330] 中训练的办公室租赁模型的最终权重。"
        }
    },
    {
        "translation": {
            "en": "In this model, the reward for all transitions to non-terminal states (e.g., PL-DL or PM-DH) is 0; these are not shown in Figure 11.3[648].",
            "zh": "在该模型中，所有跃迁到非终末状态（例如，PL-DL 或 PM-DH）的奖励为 0;图11.3[648]中未显示这些内容。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(f)[60] shows a bimodal distribution with two clear peaks—we can think of this as two normal distributions pushed together.",
            "zh": "图3.2（f）[60]显示了具有两个清晰峰的双峰分布，我们可以将其视为两个正态分布推在一起。"
        }
    },
    {
        "translation": {
            "en": "Why is this?",
            "zh": "为什么会这样？"
        }
    },
    {
        "translation": {
            "en": "validation dataset, 155, 473, 541, 541, 719",
            "zh": "验证数据集，155、473、541、541、719"
        }
    },
    {
        "translation": {
            "en": "As we discussed previously, a network may have multiple convolutional layers in sequence because the outputs from a sub-sampling layer may be passed as an input to another filter convolution, and so this sequence of operations may be repeated multiple times.",
            "zh": "正如我们之前所讨论的，一个网络可能有多个卷积层，因为子采样层的输出可以作为输入传递到另一个滤波器卷积，因此这个操作序列可以重复多次。"
        }
    },
    {
        "translation": {
            "en": "The business advised that for both features, a lower threshold of 0 and an upper threshold of 80,000 would make sense.",
            "zh": "该业务建议，对于这两个功能，阈值为 0 的下限和 80,000 的上限是有意义的。"
        }
    },
    {
        "translation": {
            "en": "expectation maximization algorithm, 600, 629",
            "zh": "期望最大化算法， 600， 629"
        }
    },
    {
        "translation": {
            "en": "17. The student-t distribution can be defined in a number of ways. For example, it can be defined so that it takes only one parameter, degrees of freedom. In this text we use the extended location-scale definition.",
            "zh": "17. 学生-t 分布可以通过多种方式定义。例如，可以定义它，以便它只接受一个参数，即自由度。在本文中，我们使用扩展的位置尺度定义。"
        }
    },
    {
        "translation": {
            "en": "Essentially, in this network, because of the use of linear activations, the variance of z for layer k in the network is the variance of z in the preceding layer, var(z(k−1)), scaled by nin(k) × var(W(k)).",
            "zh": "从本质上讲，在这个网络中，由于使用了线性激活，网络中第 k 层的 z 方差是前一层 var（z（k−1）） 中 z 的方差，由 nin（k） × var（W（k）） 缩放）。"
        }
    },
    {
        "translation": {
            "en": "9.5 Summary",
            "zh": "9.5 小结"
        }
    },
    {
        "translation": {
            "en": "Calculating probabilities in this way is known as summing out or marginalization.4",
            "zh": "以这种方式计算概率被称为总结或边缘化4。"
        }
    },
    {
        "translation": {
            "en": "Hecht-Nielsen, Robert. 1987. Kolmogorov’s mapping neural network existence theorem. In Proceedings of the IEEE first international conference on neural networks, Vol. 3, 11–13.",
            "zh": "赫克特-尼尔森，罗伯特。1987. Kolmogorov 映射神经网络存在定理.IEEE第一届神经网络国际会议论文集，第3卷，第11-13页。"
        }
    },
    {
        "translation": {
            "en": "Although the gradient descent algorithm will converge to the global minimum eventually, it takes a very long time as tiny changes are made to the weights at each iteration of the algorithm.",
            "zh": "尽管梯度下降算法最终会收敛到全局最小值，但这需要很长时间，因为在算法的每次迭代中都会对权重进行微小的更改。"
        }
    },
    {
        "translation": {
            "en": "To illustrate the backpropagation process through a convolutional layer, we need to shift our focus from the flow of data through the layer to the neural architecture of the layer.",
            "zh": "为了说明通过卷积层的反向传播过程，我们需要将注意力从通过层的数据流转移到层的神经架构上。"
        }
    },
    {
        "translation": {
            "en": "The explanation of the backpropagation algorithm presented in this chapter is based on Chapter 6 of Kelleher (2019).",
            "zh": "本章中介绍的反向传播算法的解释基于Kelleher （2019）的第6章。"
        }
    },
    {
        "translation": {
            "en": "What tells us that these weights suitably capture the relationship within the training dataset?",
            "zh": "什么告诉我们这些权重可以适当地捕获训练数据集中的关系？"
        }
    },
    {
        "translation": {
            "en": "After the training process has completed, we find the point at which performance on the validation set began to disimprove and revert back to the model trained at that point.",
            "zh": "训练过程完成后，我们会发现验证集上的性能开始下降并恢复到当时训练的模型的点。"
        }
    },
    {
        "translation": {
            "en": "forward reasoning, 248",
            "zh": "正向推理，248"
        }
    },
    {
        "translation": {
            "en": "The offending large maximums for CLAIM AMOUNT and AMOUNT RECEIVED both come from d302 in Table 3.2[56].",
            "zh": "CLAIM AMOUNT 和 AMOUNT RECEIVED 的违规最大值均来自表 3.2 中的 d302[56]。"
        }
    },
    {
        "translation": {
            "en": "A   Descriptive Statistics and Data Visualization for Machine Learning",
            "zh": "机器学习的描述性统计和数据可视化"
        }
    },
    {
        "translation": {
            "en": "The classification accuracy was 87.979% (with an average class accuracy of 67.305%), which was similar to performance on the training data and well above the target that Jocelyn and Edwin had agreed on at the beginning of the project.",
            "zh": "分类准确率为 87.979%（平均类准确率为 67.305%），这与训练数据的表现相似，远高于 Jocelyn 和 Edwin 在项目开始时商定的目标。"
        }
    },
    {
        "translation": {
            "en": "Using the ground truth labels previously given, calculate the categorical cross entropy for the query set. Compare these values to the squared error loss values for each instance.",
            "zh": "使用前面给出的基本真值标签，计算查询集的分类交叉熵。将这些值与每个实例的平方误差损失值进行比较。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.3",
            "zh": "图 6.3"
        }
    },
    {
        "translation": {
            "en": "These changes in the rankings of the instances is a direct result of normalizing the features and reflects the fact that the distance calculations are no longer dominated by the SALARY feature.",
            "zh": "实例排名的这些变化是规范化特征的直接结果，反映了距离计算不再由 SALARY 特征主导的事实。"
        }
    },
    {
        "translation": {
            "en": "This adjustment should ensure that the change in the weight leads to a move downward on the error surface.",
            "zh": "这种调整应确保权重的变化导致误差曲面上的向下移动。"
        }
    },
    {
        "translation": {
            "en": "unconditional probability, 759",
            "zh": "无条件概率，759"
        }
    },
    {
        "translation": {
            "en": "For example, the first value in ct−1 is 1, and this is multiplied by an ft value near 1 resulting in a c‡ value of 0.997527377.",
            "zh": "例如，ct−1 中的第一个值是 1，然后乘以 1 附近的 ft 值，得出 c‡ 值 0.997527377。"
        }
    },
    {
        "translation": {
            "en": "0.1830",
            "zh": "0.1830"
        }
    },
    {
        "translation": {
            "en": "This can be useful if the reason that specific values for a feature are missing might have some relationship to the target feature—for example, if a feature that has missing values represented sensitive personal data, people’s readiness to provide this data (or not) might tell us something about them.",
            "zh": "如果缺少要素的特定值的原因可能与目标要素有某种关系，则此方法非常有用，例如，如果缺少值的要素表示敏感的个人数据，则人们是否愿意提供此数据可能会告诉我们有关它们的一些信息。"
        }
    },
    {
        "translation": {
            "en": "1. Compute the distribution for C given D: P(c | d) = 0.2, P(¬c | d) = 0.8",
            "zh": "1. 计算给定 D 的 C 分布：P（c | d） = 0.2，P（¬c | d） = 0.8"
        }
    },
    {
        "translation": {
            "en": "The natural consequence of this is that using a softmax layer, each neuron is trained to predict the probability of one of the levels of the categorical target feature.",
            "zh": "这样做的自然结果是，使用 softmax 层，每个神经元都被训练来预测分类目标特征的一个水平的概率。"
        }
    },
    {
        "translation": {
            "en": "4.2.1 Decision Trees",
            "zh": "4.2.1 决策树"
        }
    },
    {
        "translation": {
            "en": "The non-linear decision boundary that is just about perceivable in Figure 7.18[355] can be represented using a third-order polynomial in the two descriptive features, P20 and P45. The simple regression model we trained previously cannot cope with a non-linear decision boundary like the one seen in Figure 7.18[355]. We can, however, rewrite the logistic regression equation from Equation (7.26)[342] to use basis functions as follows:",
            "zh": "图7.18[355]中几乎可以感知的非线性决策边界可以使用两个描述性特征P20和P45中的三阶多项式表示。我们之前训练的简单回归模型无法处理图 7.18[355] 所示的非线性决策边界。然而，我们可以重写等式（7.26）[342]中的逻辑回归方程，以使用基函数，如下所示："
        }
    },
    {
        "translation": {
            "en": "AlphaZero, 677",
            "zh": "阿尔法零，677"
        }
    },
    {
        "translation": {
            "en": "Then, for each level of the second feature, we draw a bar plot of the first feature using only the instances in the dataset for which the second feature has that level.",
            "zh": "然后，对于第二个特征的每个级别，我们仅使用数据集中第二个特征具有该级别的实例绘制第一个特征的条形图。"
        }
    },
    {
        "translation": {
            "en": "Feature selection is an important process in any machine learning project and should generally be applied no matter what type of models are being developed.",
            "zh": "特征选择是任何机器学习项目中的一个重要过程，无论正在开发哪种类型的模型，通常都应该应用。"
        }
    },
    {
        "translation": {
            "en": "These examples also highlight that covariance is one way of measuring the spread of a dataset.",
            "zh": "这些示例还强调了协方差是衡量数据集分布的一种方法。"
        }
    },
    {
        "translation": {
            "en": "A full joint probability distribution is simply a joint probability distribution over all the features in a domain.",
            "zh": "完全联合概率分布只是域中所有特征的联合概率分布。"
        }
    },
    {
        "translation": {
            "en": "By the time her test came around, Sarah had become an expert at the river-crossing challenge. No matter how awkwardly the scout leaders laid out the stepping-stones, she could quickly assess the situation each time the blindfold was cleared and choose the right direction to step in. She completed the challenge in record time and was awarded the pioneering badge.",
            "zh": "当她的测试到来时，莎拉已经成为过河挑战的专家。无论侦察队长布置的垫脚石多么笨拙，她都能在每次蒙眼被清除时迅速评估情况，并选择正确的方向介入。她以创纪录的时间完成了挑战，并被授予开拓者徽章。"
        }
    },
    {
        "translation": {
            "en": "The flow of error gradients through a long short-term memory unit during backpropagation.",
            "zh": "反向传播期间通过长短期记忆单元的误差梯度流。"
        }
    },
    {
        "translation": {
            "en": "The members of a school basketball team. The height of each player is listed below the player. The dashed gray line shows the arithmetic mean of the players’ heights.",
            "zh": "学校篮球队的成员。每个玩家的身高都列在玩家下方。灰色虚线表示球员身高的算术平均值。"
        }
    },
    {
        "translation": {
            "en": "24. See Esposito et al. (1997) and Mingers (1989) for overviews and empirical comparisons of a range of decision tree pruning methods based on error rate.",
            "zh": "24. 参见Esposito等人（1997年）和Mingers（1989年）对一系列基于错误率的决策树修剪方法的概述和实证比较。"
        }
    },
    {
        "translation": {
            "en": "14. This dataset is from the UCI Machine Learning repository Dua and Graff (2017) and was originally described by Alimoglu and Alpaydin (1996).",
            "zh": "14. 该数据集来自 UCI 机器学习存储库 Dua 和 Graff （2017），最初由 Alimoglu 和 Alpaydin （1996） 描述。"
        }
    },
    {
        "translation": {
            "en": "What we need to do at this point is to develop a formal model that captures the intuitions about the informativeness of these features. Unsurprisingly, we do this using Shannon’s entropy model. The measure of informativeness that we use is known as information gain, which is a measure of the reduction in the overall entropy of a set of instances that is achieved by testing on a descriptive feature. Computing information gain is a three-step process:",
            "zh": "在这一点上，我们需要做的是开发一个正式的模型来捕捉关于这些特征的信息性的直觉。不出所料，我们使用 Shannon 的熵模型来做到这一点。我们使用的信息量度量称为信息增益，它是通过测试描述性特征来实现的一组实例的整体熵减少的度量。计算信息增益是一个三步过程："
        }
    },
    {
        "translation": {
            "en": "Consequently, backpropagating the error gradient through the neuron that uses a logistic activation function involves multiplying the error term by a value ≤ 0.25 and that is ≈ 0 for z values in the saturated regions of the logistic function.",
            "zh": "因此，在使用逻辑激活函数的神经元中反向传播误差梯度涉及将误差项乘以 0.25 ≤值，对于逻辑函数饱和区域的 z 值，该值≈ 0。"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: This solution first assumes that it is possible to run a process every quarter that performs an analysis of the behavior of each customer.",
            "zh": "容量要求：此解决方案首先假定可以每季度运行一个流程，该流程对每个客户的行为进行分析。"
        }
    },
    {
        "translation": {
            "en": "The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places.",
            "zh": "联合循环电厂的环境因子和满负荷电力输出的范围归一化小时样本，四舍五入到小数点后两位。"
        }
    },
    {
        "translation": {
            "en": "The boundary between d3 and d7 is",
            "zh": "d3 和 d7 之间的边界是"
        }
    },
    {
        "translation": {
            "en": "This exploding z value dynamic is a problem because if we wish to avoid saturated activation functions, we need to stop the z values in neurons taking an extreme value (where the concept of extreme is dependent on the activation function).",
            "zh": "这种爆炸性的 z 值动态是一个问题，因为如果我们想避免饱和激活函数，我们需要停止神经元中的 z 值取极值（其中极值的概念取决于激活函数）。"
        }
    },
    {
        "translation": {
            "en": "Indeed, the ability to select the appropriate machine learning algorithm (and hence inductive bias) to use for a given predictive task is one of the core skills that a data analyst must develop.",
            "zh": "事实上，选择适当的机器学习算法（以及归纳偏差）来用于给定预测任务的能力是数据分析师必须培养的核心技能之一。"
        }
    },
    {
        "translation": {
            "en": "This dataset relates to a fraud detection scenario in which we would like to build a model that predicts whether loan applications are fraudulent or genuine.",
            "zh": "该数据集与欺诈检测场景相关，我们希望在该场景中构建一个模型来预测贷款申请是欺诈性还是真实的。"
        }
    },
    {
        "translation": {
            "en": "4. A Voronoi tessellation is a way of decomposing a space into regions in which each region belongs to an instance and contains all the points in the space whose distance to that instance is less than the distance to any other instance.",
            "zh": "4. Voronoi 曲面细分是一种将空间分解为区域的方法，其中每个区域都属于一个实例，并包含空间中与该实例的距离小于与任何其他实例的距离的所有点。"
        }
    },
    {
        "translation": {
            "en": "In this case, the forget gate has largely erased the original cell value from the cell state (i.e., the cell state has now forgotten the original value).",
            "zh": "在这种情况下，遗忘门在很大程度上从单元状态中删除了原始单元值（即，单元状态现在已经忘记了原始值）。"
        }
    },
    {
        "translation": {
            "en": "branches, 121",
            "zh": "分支， 121"
        }
    },
    {
        "translation": {
            "en": "low risk",
            "zh": "低风险"
        }
    },
    {
        "translation": {
            "en": "convergence criterion, 418",
            "zh": "收敛准则，418"
        }
    },
    {
        "translation": {
            "en": "Overfitting happens for a number of reasons, including sampling variance18 and noise in the training set.19 The problem of overfitting can affect any machine learning algorithm; however, the fact that decision tree induction algorithms work by recursively splitting the training data means that they have a natural tendency to segregate noisy instances and to create leaf nodes around these instances.",
            "zh": "过拟合的发生有多种原因，包括采样方差18和训练集中的噪声19，过拟合问题会影响任何机器学习算法;然而，决策树归纳算法通过递归拆分训练数据来工作，这意味着它们有一种自然的倾向，即隔离嘈杂的实例，并在这些实例周围创建叶节点。"
        }
    },
    {
        "translation": {
            "en": "batch learning, 417",
            "zh": "批量学习，417"
        }
    },
    {
        "translation": {
            "en": "Equation (8.28)[415] illustrates how a weight in a network is updated after a single training example has been processed.",
            "zh": "等式（8.28）[415]说明了在处理单个训练示例后如何更新网络中的权重。"
        }
    },
    {
        "translation": {
            "en": "0.94",
            "zh": "0.94"
        }
    },
    {
        "translation": {
            "en": "where α is a learning rate.",
            "zh": "其中α是学习率。"
        }
    },
    {
        "translation": {
            "en": "A recurrent neural network works in discrete time.",
            "zh": "递归神经网络在离散时间内工作。"
        }
    },
    {
        "translation": {
            "en": "data availability, 33",
            "zh": "数据可用性， 33"
        }
    },
    {
        "translation": {
            "en": "A prediction model that makes the correct predictions for these queries captures the underlying relationship between the descriptive and target features and is said to generalize well.",
            "zh": "对这些查询进行正确预测的预测模型可以捕获描述性特征和目标特征之间的基本关系，并且可以说可以很好地泛化。"
        }
    },
    {
        "translation": {
            "en": "This can be done by preparing a data quality report6 for each cluster that describes the instances that belong to that cluster.",
            "zh": "为此，可以为每个集群准备一份数据质量报告6，该报告描述了属于该集群的实例。"
        }
    },
    {
        "translation": {
            "en": "SARSA, 664, 664, 666, 676",
            "zh": "SARSA， 664， 664， 666， 676"
        }
    },
    {
        "translation": {
            "en": "At the time not every household in U.S. had telephones, and of those that did, a disproportionate number (relative to the total voting population of the U.S.) were Republican voters.",
            "zh": "当时，并非美国每个家庭都有电话，在那些有电话的家庭中，共和党选民的数量（相对于美国的总投票人口）不成比例。"
        }
    },
    {
        "translation": {
            "en": "First, using hold-out sampling requires that we have enough data available to make suitably large training, test, and if required, validation sets.",
            "zh": "首先，使用保持抽样需要我们有足够的可用数据来制作适当大的训练、测试以及需要的验证集。"
        }
    },
    {
        "translation": {
            "en": "The customer demographic records from the AT data warehouse",
            "zh": "来自 AT 数据仓库的客户人口统计记录"
        }
    },
    {
        "translation": {
            "en": "11.7   Exercises",
            "zh": "11.7 练习"
        }
    },
    {
        "translation": {
            "en": "greedy local search problem, 228",
            "zh": "贪婪的本地搜索问题，228"
        }
    },
    {
        "translation": {
            "en": "This is calculated by plugging the z for the neuron into the derivative of the activation function.",
            "zh": "这是通过将神经元的 z 代入激活函数的导数来计算的。"
        }
    },
    {
        "translation": {
            "en": "(a)–(f) Different clusterings found for the mobile phone customer dataset in Table 10.1[604] for values of k in (2,9). (g) shows the silhouette for each clustering.",
            "zh": "（a）–（f） 表 10.1[604] 中 k 值的移动电话客户数据集发现不同的聚类。（g） 显示每个聚类的轮廓。"
        }
    },
    {
        "translation": {
            "en": "that converts the result of the weighted sum to the output activation.",
            "zh": "这会将加权总和的结果转换为输出激活。"
        }
    },
    {
        "translation": {
            "en": "The second part of each chapter explains different ways that the standard algorithm can be extended and well-known variations on the algorithm.",
            "zh": "每章的第二部分解释了标准算法可以扩展的不同方式以及算法的众所周知的变体。"
        }
    },
    {
        "translation": {
            "en": "The following table contains an extract from this ABT—the full ABT contains 680 instances.",
            "zh": "下表包含此 ABT 的摘录 - 完整的 ABT 包含 680 个实例。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2",
            "zh": "图 8.2"
        }
    },
    {
        "translation": {
            "en": "Once the target feature has been normalized, then during training the error of the network on an example can be calculated by directly comparing the output of the network with the normalized target feature value.",
            "zh": "一旦目标特征被归一化，那么在训练期间，可以通过直接将网络的输出与归一化的目标特征值进行比较来计算示例上的网络误差。"
        }
    },
    {
        "translation": {
            "en": "25. See Section 3.6.3[91].",
            "zh": "25. 参见第 3.6.3 节[91]。"
        }
    },
    {
        "translation": {
            "en": "The instances have moved away from each other, and the sampling density has decreased.",
            "zh": "实例彼此远离，采样密度降低。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.1",
            "zh": "图 6.1"
        }
    },
    {
        "translation": {
            "en": "5.20   The process of model induction with feature selection.",
            "zh": "5.20 特征选择的模型归纳过程。"
        }
    },
    {
        "translation": {
            "en": "imputation, 69, 296",
            "zh": "插补， 69， 296"
        }
    },
    {
        "translation": {
            "en": "Keri, Jonah. 2007. Baseball between the numbers: Why everything you know about the game is wrong. Basic Books.",
            "zh": "凯丽，约拿。2007. 数字之间的棒球：为什么你对比赛的了解都是错误的。基本书籍。"
        }
    },
    {
        "translation": {
            "en": "8.4.3   Handling Categorical Target Features: Softmax Output Layers and Cross-Entropy Loss Functions",
            "zh": "8.4.3 处理分类目标特征：Softmax 输出层和交叉熵损失函数"
        }
    },
    {
        "translation": {
            "en": "The main advantage of this initialization regime is its simplicity.",
            "zh": "这种初始化制度的主要优点是其简单性。"
        }
    },
    {
        "translation": {
            "en": "Table 14.2[735] summarizes the different perspectives on the model types that we have presented in this book.",
            "zh": "表14.2[735]总结了我们在本书中提出的关于模型类型的不同观点。"
        }
    },
    {
        "translation": {
            "en": "Equation 8.44[442] lists the calculations of the δs for d2 for all the neurons in the ReLU network.",
            "zh": "公式 8.44[442] 列出了 ReLU 网络中所有神经元的 d2 的 δs 计算。"
        }
    },
    {
        "translation": {
            "en": "The layer of tanh units is as wide as the cell state and so there is one tanh activation per activation in the cell state.",
            "zh": "tanh 单元的层与细胞状态一样宽，因此在细胞状态中每次激活都有一个 tanh 激活。"
        }
    },
    {
        "translation": {
            "en": "To understand how to calculate the value of the partial derivative of the error function with respect to a particular weight, let us imagine for a moment that our training dataset, 𝒟, contains just one training instance: (d,t), where d is a set of descriptive features and t is a target feature. The gradient of the error surface is given as the partial derivative of L2 with respect to each weight, w[j]",
            "zh": "为了理解如何计算误差函数相对于特定权重的偏导数值，让我们想象一下，我们的训练数据集 D 只包含一个训练实例：（d，t），其中 d 是一组描述性特征，t 是目标特征。误差面的梯度是 L2 相对于每个权重 w[j] 的偏导数"
        }
    },
    {
        "translation": {
            "en": "We then present the ID3 algorithm, the standard algorithm used to induce a decision tree from a dataset.",
            "zh": "然后，我们提出了 ID3 算法，这是用于从数据集中诱导出决策树的标准算法。"
        }
    },
    {
        "translation": {
            "en": "Events Involving Non-Binary Features",
            "zh": "涉及非二进制特征的事件"
        }
    },
    {
        "translation": {
            "en": "We can use percentiles to describe another measure of variation known as the inter-quartile range (IQR). The inter-quartile range is calculated as the difference between the 25th percentile and the 75th percentile. These percentiles are also known as the lower quartile (or 1st quartile) and the upper quartile (or 3rd quartile), hence the name inter-quartile range. For the heights of the first basketball team, the inter-quartile range is 151 − 140 = 11, while for the second team, it is 165 − 123 = 42.",
            "zh": "我们可以使用百分位数来描述另一种称为四分位距 （IQR） 的变异度量。四分位数间范围计算为第 25 个百分位数和第 75 个百分位数之间的差值。这些百分位数也称为下四分位数（或第一四分位数）和上四分位数（或第三四分位数），因此称为四分位数间范围。对于第一支篮球队的身高，四分位数范围为 151 − 140 = 11，而对于第二支球队，则为 165 − 123 = 42。"
        }
    },
    {
        "translation": {
            "en": "The first operation in this sequence is the multiplication of the matrix containing the weights on the connections into the neurons in the hidden layer by the outputs of the input layer.",
            "zh": "此序列中的第一个操作是将包含与隐藏层中神经元的连接的权重的矩阵乘以输入层的输出。"
        }
    },
    {
        "translation": {
            "en": "While it is interesting to see how derivatives can be calculated for discrete examples, it is much more common that we need to calculate the derivative of a continuous function. A continuous function, f(x), generates an output for every value of a variable x based on some expression involving x. For example:",
            "zh": "虽然了解如何计算离散示例的导数很有趣，但更常见的是我们需要计算连续函数的导数。连续函数 f（x） 根据涉及 x 的某个表达式为变量 x 的每个值生成输出。例如："
        }
    },
    {
        "translation": {
            "en": "7   Error-Based Learning",
            "zh": "7 基于错误的学习"
        }
    },
    {
        "translation": {
            "en": "Schapire, Robert E. 1999. A brief introduction to boosting. In Proceedings of the sixteenth international joint conference on artificial intelligence (IJCAI-99), Vol. 2, 1401–1406.",
            "zh": "Schapire， Robert E. 1999 年。提升的简要介绍。第十六届国际人工智能联合会议（IJCAI-99）论文集，第2卷，第1401-1406页。"
        }
    },
    {
        "translation": {
            "en": "9.4.5 Performance Measures: Continuous Targets",
            "zh": "9.4.5 绩效衡量：持续目标"
        }
    },
    {
        "translation": {
            "en": "The way to solve the problem of zero probabilities is to think in terms of how the probability of a continuous feature taking a value is distributed across the range of values that a continuous feature can take.",
            "zh": "解决零概率问题的方法是考虑连续特征取值的概率如何分布在连续特征可以取的值范围内。"
        }
    },
    {
        "translation": {
            "en": "C.1   Derivatives of Continuous Functions",
            "zh": "C.1 连续函数的导数"
        }
    },
    {
        "translation": {
            "en": "absence-presence (AP), how often a false value occurred in the query data q when a true value occurred in the data for the comparison user (d1 or d2) for the same feature",
            "zh": "不存在 （AP），当同一功能的比较用户（d1 或 d2）的数据中出现真值时，查询数据 q 中出现假值的频率"
        }
    },
    {
        "translation": {
            "en": "The lines in this figure indicate the hyperplanes partitioning the feature space that were created by the splits encoded in the non-leaf nodes in the tree.",
            "zh": "此图中的线表示分区特征空间的超平面，这些超平面是由树中的非叶节点中编码的拆分创建的。"
        }
    },
    {
        "translation": {
            "en": "Therefore, when we wish to increase the representational power of a network, there is often a trade-off between making a network deeper and making the layers wider.",
            "zh": "因此，当我们希望增加网络的表示能力时，通常会在使网络更深和更宽之间进行权衡。"
        }
    },
    {
        "translation": {
            "en": "underfitting, 14, 193",
            "zh": "欠拟合， 14， 193"
        }
    },
    {
        "translation": {
            "en": "2,000,000",
            "zh": "2,000,000"
        }
    },
    {
        "translation": {
            "en": "Invalid outliers are values that have been included in a sample through error and are often referred to as noise in the data.",
            "zh": "无效异常值是通过误差包含在样本中的值，通常称为数据中的噪声。"
        }
    },
    {
        "translation": {
            "en": "One thing that is immediately apparent in Table 5.8[209] is that the AGE and RATING features have different ranges. We should normalize these features before we build a model. Table 5.9[210] lists the whiskey dataset after the descriptive features have been normalized, using range normalization to the range [0,1].",
            "zh": "在表5.8[209]中显而易见的一件事是，AGE和RATING特征具有不同的范围。在构建模型之前，我们应该对这些特征进行规范化。表5.9[210]列出了描述性特征归一化后的威士忌数据集，使用范围归一化到范围[0,1]。"
        }
    },
    {
        "translation": {
            "en": "AVGRECEIVEDMINS",
            "zh": "AVGRECEIVEDMINS"
        }
    },
    {
        "translation": {
            "en": "1.5   The age-income dataset.",
            "zh": "1.5 年龄-收入数据集。"
        }
    },
    {
        "translation": {
            "en": "(a) As part of the study, researchers have decided to create a predictive model to screen participants based on their risk of heart disease. You have been asked to implement this screening model using a random forest. The three tables below list three bootstrap samples that have been generated from the above dataset. Using these bootstrap samples, create the decision trees that will be in the random forest model (use entropy-based information gain as the feature selection criterion).",
            "zh": "（a）作为研究的一部分，研究人员决定创建一个预测模型，根据参与者患心脏病的风险进行筛查。我们要求您使用随机森林实现此筛选模型。下面的三个表列出了从上述数据集生成的三个引导样本。使用这些 bootstrap 样本，创建将位于随机森林模型中的决策树（使用基于熵的信息增益作为特征选择标准）。"
        }
    },
    {
        "translation": {
            "en": "As a result, although in principle a recurrent neural network has the ability to propagate information across the spans of long-distance dependencies in input sequences, the vanishing and exploding gradient problems limit the ability of these networks to learn these dependencies.",
            "zh": "因此，尽管原则上递归神经网络具有在输入序列中长距离依赖关系的跨度中传播信息的能力，但消失和爆炸梯度问题限制了这些网络学习这些依赖关系的能力。"
        }
    },
    {
        "translation": {
            "en": "One problem that we need to solve in order to use the model defined in Equation (7.24)[341] is how to determine the values for the weights, w, that will minimize the error function for our hypothesis w(d).",
            "zh": "为了使用方程（7.24）[341]中定义的模型，我们需要解决的一个问题是如何确定权重w的值，这将使我们的假设w（d）的误差函数最小化。"
        }
    },
    {
        "translation": {
            "en": "Typically mini-batches are all of the same size.",
            "zh": "通常，小批量的大小都相同。"
        }
    },
    {
        "translation": {
            "en": "0.047",
            "zh": "0.047"
        }
    },
    {
        "translation": {
            "en": "Lift tells us how much higher the actual percentage of positive instances in a decile dec is than the rate expected.",
            "zh": "Lift 告诉我们十分位数 dec 中阳性实例的实际百分比比预期比率高多少。"
        }
    },
    {
        "translation": {
            "en": "Table 7.11",
            "zh": "表 7.11"
        }
    },
    {
        "translation": {
            "en": "Generally, finding a good combination of values for the batch size and learning rate hyper-parameters involves trial-and-error experimentation.",
            "zh": "通常，要找到批量大小和学习率超参数值的良好组合，需要进行试错试验。"
        }
    },
    {
        "translation": {
            "en": "The ∂ℰ/∂wi,k calculations for d2 for every weight in the network. We use the neuron index 0 to denote the bias input for each neuron.",
            "zh": "∂E/∂wi，k 计算网络中每个权重的 d2。我们使用神经元索引 0 来表示每个神经元的偏差输入。"
        }
    },
    {
        "translation": {
            "en": "In contrast with this, unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset.",
            "zh": "与此相反，无监督机器学习技术在没有目标特征的情况下使用，并对数据集中描述性特征中的底层结构进行建模。"
        }
    },
    {
        "translation": {
            "en": "Feature",
            "zh": "特征"
        }
    },
    {
        "translation": {
            "en": "There are a number of different ways to find this point. In this chapter we describe a guided search approach known as the gradient descent algorithm. This is one of the most important algorithms in machine learning and, as we discuss in other chapters, can be used for many different purposes. The next section describes how gradient descent can be used to find the optimal weights for linear regression models that handle multiple descriptive features: multivariable linear regression models.",
            "zh": "有许多不同的方法可以找到这一点。在本章中，我们将介绍一种称为梯度下降算法的引导式搜索方法。这是机器学习中最重要的算法之一，正如我们在其他章节中讨论的那样，可以用于许多不同的目的。下一节将介绍如何使用梯度下降来查找处理多个描述性特征的线性回归模型的最佳权重：多变量线性回归模型。"
        }
    },
    {
        "translation": {
            "en": "There are no weights on the connections between the output of the hidden layer and the memory buffer.",
            "zh": "隐藏层的输出和内存缓冲区之间的连接没有权重。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12(b)[205] shows a plot of the feature space after the features have been normalized.",
            "zh": "图5.12（b）[205]显示了特征归一化后的特征空间图。"
        }
    },
    {
        "translation": {
            "en": "There are two values in the domain of the MENINGITIS feature, true and false, so we have to do this calculation once for each. Considering first the calculation for m, we need the following probabilities, which can be computed directly from Table 6.1[246]",
            "zh": "脑膜炎特征的域中有两个值，true 和 false，因此我们必须对每个值进行一次计算。首先考虑 m 的计算，我们需要以下概率，这些概率可以直接从表 6.1[246] 中计算出来"
        }
    },
    {
        "translation": {
            "en": "There are many genuine examples of features that will have such high cardinality, but some of the machine learning algorithms that we will look at will struggle to effectively use features with such high cardinality.",
            "zh": "有许多具有如此高基数的特征的真实示例，但是我们将要研究的一些机器学习算法将难以有效地使用具有如此高基数的特征。"
        }
    },
    {
        "translation": {
            "en": "(a) Based on this data, calculate the following summary statistics for the POLICY feature:",
            "zh": "（a） 根据此数据，计算 POLICY 特征的以下汇总统计量："
        }
    },
    {
        "translation": {
            "en": "Lifecycle Phase: The position of a customer or user in their lifecycle (for example, is a customer a new customer, a loyal customer, or a lapsing customer?).",
            "zh": "生命周期阶段：客户或用户在其生命周期中的位置（例如，客户是新客户、忠诚客户还是即将离职的客户？"
        }
    },
    {
        "translation": {
            "en": "Another important property of inductive learning is that learning cannot occur unless the learning process is biased in some way. This means that we need to tell the learning process what types of patterns to look for in the data. This bias is referred to as inductive bias. The inductive bias of a learning algorithm comprises the set of assumptions that define the search space the algorithm explores, and the search process it uses.",
            "zh": "归纳学习的另一个重要特性是，除非学习过程在某种程度上有偏见，否则学习不会发生。这意味着我们需要告诉学习过程在数据中寻找哪些类型的模式。这种偏差被称为归纳偏差。学习算法的归纳偏差包括一组假设，这些假设定义了算法探索的搜索空间及其使用的搜索过程。"
        }
    },
    {
        "translation": {
            "en": "Table 8.9",
            "zh": "表 8.9"
        }
    },
    {
        "translation": {
            "en": "For example, some are percentages, others are measured in years, and others are measured in counts per 1,000.",
            "zh": "例如，有些是百分比，有些是以年为单位，有些是以每 1,000 人的计数来衡量的。"
        }
    },
    {
        "translation": {
            "en": "We started this section with the idea that if we could construct a sequence of tests that splits the training data into pure sets with respect to the target feature values, then we could do prediction by applying the same sequence of tests to the prediction queries and labeling them with the target feature of the set in which they end up.",
            "zh": "我们从本节开始的想法是，如果我们可以构造一个测试序列，将训练数据拆分为相对于目标特征值的纯集，那么我们可以通过将相同的测试序列应用于预测查询并用它们最终所在的集合的目标特征标记它们来进行预测。"
        }
    },
    {
        "translation": {
            "en": "20. Critical value pruning (Mingers, 1987) is a well-known version of this pruning technique.",
            "zh": "20. 临界值修剪（Mingers，1987）是这种修剪技术的一个著名版本。"
        }
    },
    {
        "translation": {
            "en": "Note that in order to keep the number of decimal points required to represent the calculations through this forward pass manageable for presentation purposes, the outputs of the logistic functions for each layer have been rounded to four decimal places, and these rounded activations were the activations used in the subsequent calculations.",
            "zh": "请注意，为了保持通过此前向传递表示计算所需的小数点数易于管理，以便于演示目的，每层的逻辑函数输出已四舍五入到小数点后四位，这些四舍五入的激活是后续计算中使用的激活。"
        }
    },
    {
        "translation": {
            "en": "Are there data quality issues? How will we handle missing values? How will we normalize our features? What features will we include?",
            "zh": "是否存在数据质量问题？我们将如何处理缺失值？我们将如何规范化我们的功能？我们将包括哪些功能？"
        }
    },
    {
        "translation": {
            "en": "Figure 4.20[160] illustrates the process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "图4.20[160]说明了使用装袋和子空间采样创建模型集成的过程。"
        }
    },
    {
        "translation": {
            "en": "In the next section we introduce the naive Bayes model, a probability-based machine learning algorithm that asserts a global conditional independence between the descriptive features given the target. As a result of this conditional independence assumption, naive Bayes models are very compact and relatively robust to overfitting the data, making them one of the most popular predictive modeling approaches.",
            "zh": "在下一节中，我们将介绍朴素贝叶斯模型，这是一种基于概率的机器学习算法，它断言给定目标的描述性特征之间的全局条件独立性。由于这种条件独立性假设，朴素贝叶斯模型非常紧凑，并且对数据过拟合相对鲁棒，使其成为最流行的预测建模方法之一。"
        }
    },
    {
        "translation": {
            "en": "2. weight sharing; and",
            "zh": "2.重量分担;和"
        }
    },
    {
        "translation": {
            "en": "(a) State whether each descriptive feature contains numeric, interval, ordinal, categorical, binary, or textual data.",
            "zh": "（a） 说明每个描述性特征是否包含数字、区间、序数、分类、二进制或文本数据。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21(b)[163] shows an illustration of the final ensemble model trained using five iterations of the boosting algorithm. Even this simple example can nicely illustrate the power of boosting as, although all the individual decision trees in the ensemble are limited to a single split at the root node of the tree, the ensemble is able to learn a more sophisticated prediction model that none of the individual models within it are capable of representing.",
            "zh": "图 4.21（b）[163] 显示了使用提升算法的五次迭代训练的最终集成模型的图示。即使是这个简单的例子也可以很好地说明提升的力量，因为尽管集成中的所有单个决策树都仅限于树根节点处的单个分裂，但集成能够学习一个更复杂的预测模型，其中的单个模型都无法表示。"
        }
    },
    {
        "translation": {
            "en": "Calculate the δ values for each of the neurons in the network (i.e., δ3, δ2).",
            "zh": "计算网络中每个神经元的δ值（即δ3，δ2）。"
        }
    },
    {
        "translation": {
            "en": "The argument stems from a disagreement about when a discrete moment of time ends—after the action completes or after the reward is received?",
            "zh": "争论源于对离散时刻何时结束的分歧——在行动完成之后还是在收到奖励之后？"
        }
    },
    {
        "translation": {
            "en": "Table 9.18",
            "zh": "表 9.18"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2[387] makes it apparent that a common characteristic of all of these activation functions is that they are not linear functions.",
            "zh": "图8.2[387]清楚地表明，所有这些激活函数的一个共同特征是它们不是线性函数。"
        }
    },
    {
        "translation": {
            "en": "dropout, 434, 472, 473, 507",
            "zh": "辍学， 434， 472， 473， 507"
        }
    },
    {
        "translation": {
            "en": "representational capacity, 396",
            "zh": "代表能力，396"
        }
    },
    {
        "translation": {
            "en": "A more complex credit scoring dataset.",
            "zh": "更复杂的信用评分数据集。"
        }
    },
    {
        "translation": {
            "en": "-0.4549",
            "zh": "-0.4549"
        }
    },
    {
        "translation": {
            "en": "For each iteration of the boosting process the columns labeled Dist.",
            "zh": "对于提升过程的每次迭代，标记为 Dist."
        }
    },
    {
        "translation": {
            "en": "PRICE",
            "zh": "价格"
        }
    },
    {
        "translation": {
            "en": "Square brackets [] are used to index into a vector of features (e.g., d[j] denotes the value of the jth feature in the vector d).",
            "zh": "方括号 [] 用于索引特征向量（例如，d[j] 表示向量 d 中第 j 个特征的值）。"
        }
    },
    {
        "translation": {
            "en": "At a glance, the confusion matrix can show us that a model is performing well if the numbers on its diagonal, representing the true positives and true negatives, are high. Looking at the other cells within the confusion matrix can show us what kind of mistakes the model is making. Table 9.3[539] shows the confusion matrix for the set of predictions shown in Table 9.1[537] (in this case, we refer to the spam target level as the positive level and ham as the negative level).3",
            "zh": "一目了然，混淆矩阵可以向我们显示，如果模型对角线上的数字（代表真正数和真负数）很高，则模型表现良好。查看混淆矩阵中的其他单元格可以向我们展示模型犯了什么样的错误。表 9.3[539] 显示了表 9.1[537] 中所示的一组预测的混淆矩阵（在本例中，我们将垃圾邮件目标级别称为正级别，将 ham 称为负级别）3。"
        }
    },
    {
        "translation": {
            "en": "1. Whx containing the weights for the connections between the input layer (x) and the hidden layer (h);",
            "zh": "1. Whx 包含输入层 （x） 和隐藏层 （h） 之间连接的权重;"
        }
    },
    {
        "translation": {
            "en": "11.3   A portion of the action-value table for the grid world example at its first initialization.",
            "zh": "11.3 网格世界示例首次初始化时操作值表的一部分。"
        }
    },
    {
        "translation": {
            "en": "More specifically, a Bayesian network can be viewed as defining a Markov chain.",
            "zh": "更具体地说，贝叶斯网络可以被视为定义马尔可夫链。"
        }
    },
    {
        "translation": {
            "en": "Table 7.8[348] shows just the first two iterations of the gradient descent process for this model.",
            "zh": "表7.8[348]仅显示了该模型梯度下降过程的前两次迭代。"
        }
    },
    {
        "translation": {
            "en": "9.5   Summary",
            "zh": "9.5 小结"
        }
    },
    {
        "translation": {
            "en": "A.2   A frequency table for the POSITION feature from the school basketball team dataset in Table A.1[750].",
            "zh": "A.2 表A.1[750]中学校篮球队数据集中POSITION特征的频率表。"
        }
    },
    {
        "translation": {
            "en": "During the European Soccer Championships in 2008 and the 2010 Soccer World Cup, an octopus in Germany, called Paul, was attributed with achieving an 85% success rate at predicting the results of the matches involving Germany.",
            "zh": "在 2008 年的欧洲足球锦标赛和 2010 年足球世界杯期间，德国的一只名叫保罗的章鱼被认为在预测涉及德国的比赛结果方面取得了 85% 的成功率。"
        }
    },
    {
        "translation": {
            "en": "This is not a coincidence.",
            "zh": "这并非巧合。"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of α = 0.1, calculate the updated values for each of the weights in the network (w6,4,w6,3,w6,0,w5,4, w5,3, w5,0, w4,2,w4,1,w4,0, w3,2, w3,1, w3,0,) after the processing of this single training example.",
            "zh": "假设学习率为 α = 0.1，计算网络中每个权重（w6,4，w6,3，w6,0，w5,4、w5,3、w5,0、w4,2、w4,1、w4,0、w3,2、w3,1、w3,0，）的更新值。"
        }
    },
    {
        "translation": {
            "en": "The middle column in this weight matrix represents the weights on the connections from Neuron 1 to each of the neurons in hidden layer 1: Neurons 3, 4 and 5, respectively.",
            "zh": "此权重矩阵中的中间列分别表示从神经元 1 到隐藏层 1 中每个神经元的连接上的权重：神经元 3、4 和 5。"
        }
    },
    {
        "translation": {
            "en": "de-noising auto-encoders, 630",
            "zh": "降噪自动编码器，630"
        }
    },
    {
        "translation": {
            "en": "Implementing a derived feature, however, requires data from multiple sources to be combined into a set of single feature values.",
            "zh": "但是，实现派生特征需要将来自多个源的数据组合成一组单个特征值。"
        }
    },
    {
        "translation": {
            "en": "If the sampling density is too low, then large regions of the feature space do not contain any training instances, and it doesn’t make sense to associate such a region with any cluster of training instances or to look for training instances that are nearby.",
            "zh": "如果采样密度太低，则特征空间的大区域不包含任何训练实例，并且将此类区域与任何训练实例聚类相关联或查找附近的训练实例是没有意义的。"
        }
    },
    {
        "translation": {
            "en": "Another potential issue with decision trees is that they are eager learners. As such, they are not suitable for modeling concepts that change over time, because they will need to be retrained. In these scenarios, the similarity-based prediction models that are the topic of Chapter 5[181] perform better, as these models can be incrementally retrained.",
            "zh": "决策树的另一个潜在问题是它们是渴望学习的人。因此，它们不适合对随时间变化的概念进行建模，因为它们需要重新训练。在这些场景中，第 5 章[181] 主题的基于相似性的预测模型表现更好，因为这些模型可以增量重新训练。"
        }
    },
    {
        "translation": {
            "en": "Using dropout during the training of a recurrent neural network can be problematic because dropping different neurons from the network at different time-steps across a sequence can stop the network from propagating important information forward through the sequence.",
            "zh": "在循环神经网络的训练过程中使用dropout可能会有问题，因为在序列的不同时间步长从网络中删除不同的神经元可能会阻止网络通过序列向前传播重要信息。"
        }
    },
    {
        "translation": {
            "en": "For example, when we are dealing with a financial feature, we might use intervals that represent cents, while if we were dealing with temperature, we might define the interval to be 1 degree.",
            "zh": "例如，当我们处理财务特征时，我们可能会使用表示美分的区间，而如果我们处理温度，我们可以将区间定义为 1 度。"
        }
    },
    {
        "translation": {
            "en": "BEYOND PREDICTION",
            "zh": "超越预测"
        }
    },
    {
        "translation": {
            "en": "We refer to this as getting to know the data.",
            "zh": "我们将其称为了解数据。"
        }
    },
    {
        "translation": {
            "en": "Not long afterward the three Murphy children came to their father together to ask how it was that he had told each of them that they had done a great job of arranging the letters when they had all done something different.",
            "zh": "不久之后，墨菲的三个孩子一起来找他们的父亲，问他为什么告诉他们每个人，当他们都做了一些不同的事情时，他们在整理信件方面做得很好。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73].",
            "zh": "一个散点图矩阵，显示了表3.7[73]中职业篮球队数据集中连续特征的散点图。"
        }
    },
    {
        "translation": {
            "en": "This was based on the assumption that such a call made to customers considering switching to a different network would encourage them to stay with their current network.",
            "zh": "这是基于这样的假设，即向考虑切换到其他网络的客户拨打此类电话会鼓励他们继续使用当前网络。"
        }
    },
    {
        "translation": {
            "en": "Using the pruning set, apply reduced error pruning to the decision tree. Assume that the algorithm is applied in a bottom-up, left-to-right fashion. For each iteration of the algorithm, indicate the subtrees considered as pruning candidates, explain why the algorithm chooses to prune or leave these subtrees in the tree, and illustrate the tree that results from each iteration.",
            "zh": "使用修剪集，将减少误差的修剪应用于决策树。假设该算法以自下而上、从左到右的方式应用。对于算法的每次迭代，请指出被视为修剪候选项的子树，解释算法选择修剪或将这些子树保留在树中的原因，并说明每次迭代产生的树。"
        }
    },
    {
        "translation": {
            "en": "In the scatter plot, DOSE1 is shown on the horizontal axis, DOSE2 is shown on the vertical axis, and the shapes of the points represent the target level—crosses represent dangerous interactions and triangles represent safe interactions.",
            "zh": "在散点图中，DOSE1 显示在横轴上，DOSE2 显示在纵轴上，点的形状表示目标水平，十字表示危险相互作用，三角形表示安全相互作用。"
        }
    },
    {
        "translation": {
            "en": "We can analyze why this happens if we examine the Euclidean distance computations between the query and the instances in the dataset.",
            "zh": "如果我们检查查询和数据集中实例之间的欧几里得距离计算，我们可以分析为什么会发生这种情况。"
        }
    },
    {
        "translation": {
            "en": "Hospital management would like to explore the use of predictive analytics to address this issue.12 They would like to reduce the readmittance rate of diabetes patients, while at the same time not keeping patients in the hospital longer than they need to be.",
            "zh": "12 他们希望降低糖尿病患者的再入院率，同时不要让患者住院时间超过他们需要的时间。"
        }
    },
    {
        "translation": {
            "en": "4.6   (a) A graph illustrating how the value of a binary log (the log to the base 2) of a probability changes across the range of probability values; and (b) the impact of multiplying these values by – 1.",
            "zh": "4.6 （a） 说明概率的二进制对数（以 2 为基数的对数）的值在概率值范围内如何变化的图表;以及 （b） 将这些值乘以 – 1 的影响。"
        }
    },
    {
        "translation": {
            "en": "Table 2.1",
            "zh": "表 2.1"
        }
    },
    {
        "translation": {
            "en": "As in the previous analysis, in this network the instability in gradient propagation (in this instance exploding gradients) is not due to a scaling of the gradients by the derivative of the activation function; the linear activation function used by the neurons in this network has a derivative of 1, and so the gradients are not changed by this derivative during backpropagation.",
            "zh": "与前面的分析一样，在这个网络中，梯度传播的不稳定性（在本例中为爆炸梯度）不是由于激活函数导数对梯度的缩放;该网络中神经元使用的线性激活函数的导数为 1，因此在反向传播过程中梯度不会因该导数而改变。"
        }
    },
    {
        "translation": {
            "en": "The plot on the right of Figure 8.8[398] shows the input space for the XOR and labels the input combinations as resulting in TRUE responses or FALSE responses.",
            "zh": "图8.8[398]右侧的图显示了XOR的输入空间，并将输入组合标记为产生TRUE响应或FALSE响应。"
        }
    },
    {
        "translation": {
            "en": "Because a probability distribution must sum to 1, an increase in one probability results in a decrease in one or more of the other probabilities in the distribution.",
            "zh": "由于概率分布的总和必须为 1，因此一个概率的增加会导致分布中一个或多个其他概率的减少。"
        }
    },
    {
        "translation": {
            "en": "When an audit reveals that a company is complying with all tax requirements, there is a sense that the time spent performing the audit was wasted, and more important, that another business who is not tax compliant has been spared an investigation.",
            "zh": "当审计显示一家公司遵守所有税务要求时，就会有一种感觉，即执行审计所花费的时间被浪费了，更重要的是，另一家不遵守税务规定的企业幸免于难。"
        }
    },
    {
        "translation": {
            "en": "3.6   Data Preparation",
            "zh": "3.6 数据准备"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices from the evaluation of these models are shown in Table 13.5[720].",
            "zh": "这些模型评估的混淆矩阵如表13.5[720]所示。"
        }
    },
    {
        "translation": {
            "en": "Once identified, these features should be recoded as categorical features.",
            "zh": "一旦识别，这些特征应重新编码为分类特征。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11",
            "zh": "图 6.11"
        }
    },
    {
        "translation": {
            "en": "The propagation of activations along the cell is controlled by three gates: the forget gate, the input gate, and the output gate.",
            "zh": "激活沿细胞的传播由三个门控制：遗忘门、输入门和输出门。"
        }
    },
    {
        "translation": {
            "en": "The ε-greedy action selection policy is a simple action selection policy that balances exploration and exploitation.",
            "zh": "ε贪婪行动选择策略是一种平衡探索和利用的简单行动选择策略。"
        }
    },
    {
        "translation": {
            "en": "For simplicity in later calculations, we can combine the two constraints in Equations (7.42)[363] and (7.43)[363] into a single constraint (remember that ti is always equal to either − 1 or + 1)",
            "zh": "为了在以后的计算中简单起见，我们可以将方程（7.42）[363]和（7.43）[363]中的两个约束组合成一个约束（请记住，ti总是等于−1或+ 1）"
        }
    },
    {
        "translation": {
            "en": "The moral here is that the curse of dimensionality is a problem for all inductive learning approaches, and given that acquiring new labeled instances is typically not an option, the best way to avoid it is to restrict the number of descriptive features in a dataset to the smallest set possible, while still providing the learning algorithm with enough information about the instances to be able to build a useful model.",
            "zh": "这里的寓意是，维度的诅咒是所有归纳学习方法的问题，鉴于获取新的标记实例通常不是一种选择，避免它的最佳方法是将数据集中描述性特征的数量限制为尽可能小的集合，同时仍然为学习算法提供有关实例的足够信息，以便能够构建有用的模型。"
        }
    },
    {
        "translation": {
            "en": "However, the two-part structure of the McCulloch and Pitts model of the neuron is the blueprint for the neurons used in modern neural networks.",
            "zh": "然而，神经元的 McCulloch 和 Pitts 模型的两部分结构是现代神经网络中使用的神经元的蓝图。"
        }
    },
    {
        "translation": {
            "en": "Tüfekci, Pinar. 2014. Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods. International Journal of Electrical Power & Energy Systems 60: 126–140.",
            "zh": "图费克奇，皮纳尔。2014. 使用机器学习方法预测基本负荷运行的联合循环电厂的满载电力输出.国际电力与能源系统杂志60：126-140。"
        }
    },
    {
        "translation": {
            "en": "When he considered cardinality, Ross noticed that a number of the continuous features had very low cardinality—for example, INCOME, AGE, NUMHANDSETS, HANDSETPRICE, and NUMRETENTIONCALLS.",
            "zh": "在考虑基数时，Ross 注意到许多连续特征的基数非常低，例如，INCOME、AGE、NUMHANDETS、HANDSETPRICE 和 NUMRETENTIONCALLS。"
        }
    },
    {
        "translation": {
            "en": "Table 8.13",
            "zh": "表 8.13"
        }
    },
    {
        "translation": {
            "en": "The decision trees described in Chapter 4[117] are an example of this type of abstraction.",
            "zh": "第4章[117]中描述的决策树就是这种抽象的一个例子。"
        }
    },
    {
        "translation": {
            "en": "The δs for the downstream neurons are the links in this chain, and therefore we must calculate these downstream δs prior to calculating ∂ℰ/∂ak.",
            "zh": "下游神经元的 δ 是这条链中的环节，因此我们必须在计算 ∂E/∂ak 之前计算这些下游 δ。"
        }
    },
    {
        "translation": {
            "en": "Notice that unlike the layers, the weight matrices do not have a time subscript on them.",
            "zh": "请注意，与图层不同，权重矩阵上没有时间下标。"
        }
    },
    {
        "translation": {
            "en": "Modern organizations collect massive amounts of data. To be of value to an organization, this data must be analyzed to extract insights that can be used to make better decisions. The progression from data to insights to decisions is illustrated in Figure 1.1[4]. Extracting insights from data is the job of data analytics. This book focuses on predictive data analytics, which is an important subfield of data analytics.",
            "zh": "现代组织收集大量数据。为了对组织有价值，必须分析这些数据以提取可用于做出更好决策的见解。图1.1[4]说明了从数据到洞察再到决策的过程。从数据中提取见解是数据分析的工作。本书重点介绍预测数据分析，这是数据分析的一个重要子领域。"
        }
    },
    {
        "translation": {
            "en": "cluster centroids, 600",
            "zh": "簇质心，600"
        }
    },
    {
        "translation": {
            "en": "data protection legislation, 40",
            "zh": "数据保护立法，40"
        }
    },
    {
        "translation": {
            "en": "9.4.4 Performance Measures: Multinomial Targets",
            "zh": "9.4.4 绩效衡量：多项式目标"
        }
    },
    {
        "translation": {
            "en": "The forget gate works by passing hxt through a layer of neurons that use sigmoid activation functions.",
            "zh": "遗忘门的工作原理是将 hxt 传递到使用 S 形激活函数的神经元层。"
        }
    },
    {
        "translation": {
            "en": "In the first evaluation experiment, the data in the 1st fold is used as the test set, and the data in the remaining k − 1 folds is used as the training set.",
            "zh": "在第一个评估实验中，第 1 个折叠中的数据用作测试集，其余 k − 1 个折叠中的数据用作训练集。"
        }
    },
    {
        "translation": {
            "en": "GALAXY_CLASS_5",
            "zh": "GALAXY_CLASS_5"
        }
    },
    {
        "translation": {
            "en": "So, in some cases prediction has a temporal aspect but not in all.",
            "zh": "因此，在某些情况下，预测具有时间方面，但不是全部。"
        }
    },
    {
        "translation": {
            "en": "It was this focus on encoding that motivated his approach to measuring information.",
            "zh": "正是这种对编码的关注激发了他测量信息的方法。"
        }
    },
    {
        "translation": {
            "en": "This includes all financial details of the company’s operations during the year and is the basis of calculating the tax liability of a company.",
            "zh": "这包括公司当年运营的所有财务细节，是计算公司纳税义务的基础。"
        }
    },
    {
        "translation": {
            "en": "The reason for this phenomenon is that, fundamentally, the predictive power of an induced model is based on one of the following:",
            "zh": "造成这种现象的原因是，从根本上说，诱导模型的预测能力基于以下因素之一："
        }
    },
    {
        "translation": {
            "en": "PETROR50ERR_U/G/R/I/Z",
            "zh": "PETROR50ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "61,000",
            "zh": "61,000"
        }
    },
    {
        "translation": {
            "en": "Once this ratio drops, the efficiency of the k-d tree diminishes.",
            "zh": "一旦这个比率下降，k-d树的效率就会降低。"
        }
    },
    {
        "translation": {
            "en": "2. Error functions are commonly referred to as loss functions because they represent what we lose by reducing the training set to a simple model.",
            "zh": "2. 误差函数通常被称为损失函数，因为它们代表了我们通过将训练集简化为简单模型而失去的东西。"
        }
    },
    {
        "translation": {
            "en": "Data",
            "zh": "数据"
        }
    },
    {
        "translation": {
            "en": "Some of the other machine learning topics that you might like to explore include semi-supervised learning (Chapelle et al., 2009), multi-label classification (Tsoumakas et al., 2012), and graphical models (Kollar and Friedman, 2009).",
            "zh": "您可能想要探索的其他一些机器学习主题包括半监督学习（Chapelle et al.， 2009）、多标签分类（Tsoumakas et al.， 2012）和图形模型（Kollar and Friedman，2009）。"
        }
    },
    {
        "translation": {
            "en": "mean, 54, 69, 745, 746",
            "zh": "平均值， 54， 69， 745， 746"
        }
    },
    {
        "translation": {
            "en": "For example, we might use a greedy action selection policy that says the agent should always take the action that will give it this highest immediate reward.",
            "zh": "例如，我们可以使用贪婪的行动选择策略，该策略规定代理应始终采取能够为其提供最高即时奖励的行动。"
        }
    },
    {
        "translation": {
            "en": "9.2   Fundamentals",
            "zh": "9.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "This involved working very closely with Grace to understand what data was available, the formats that the data was kept in, and where the data resided.",
            "zh": "这涉及与 Grace 密切合作，以了解哪些数据可用、数据的保存格式以及数据驻留的位置。"
        }
    },
    {
        "translation": {
            "en": "In a softmax output layer there is a single neuron for each level of the target feature. For example, if the prediction task is to predict the level of a categorical feature that can take three levels (e.g., low, medium, high), then the output layer of the network would have three neurons. The activation function used by the neurons in a softmax layer is the softmax function; for an output layer with m neurons, the softmax activation function is defined as follows:",
            "zh": "在 softmax 输出层中，目标要素的每个级别都有一个神经元。例如，如果预测任务是预测可以采取三个级别（例如，低、中、高）的分类特征的级别，那么网络的输出层将有三个神经元。softmax层中神经元使用的激活函数是softmax函数;对于具有 m 个神经元的输出层，softmax 激活函数定义如下："
        }
    },
    {
        "translation": {
            "en": "Overall, although naive Bayes models may not be as powerful as some other prediction models, they often provide reasonable accuracy results, for prediction tasks with categorical targets, while being robust to the curse of dimensionality and also being easy to train. As a result, a naive Bayes model is often a good prediction model to use to define a baseline accuracy score or when working with limited data.",
            "zh": "总体而言，尽管朴素贝叶斯模型可能不如其他一些预测模型强大，但它们通常为具有分类目标的预测任务提供合理的准确性结果，同时对维数的诅咒具有鲁棒性，并且易于训练。因此，朴素贝叶斯模型通常是一个很好的预测模型，可用于定义基线准确性分数或处理有限数据时。"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.11[85] the cells above the diagonal show the correlation coefficients for each pair of features.",
            "zh": "在图3.11[85]中，对角线上方的单元格显示了每对特征的相关系数。"
        }
    },
    {
        "translation": {
            "en": "40. NIST is the acronym for the institute that collected the data, the National Institute for Standards and Technology, and M indicates that the original data has been modified to make it easier to use for machine learning. The MNIST dataset is available at http://yann.lecun.com/exdb/mnist/.",
            "zh": "40. NIST是收集数据的机构美国国家标准与技术研究所的首字母缩写，M表示原始数据已被修改，使其更易于用于机器学习。MNIST数据集可在 http://yann.lecun.com/exdb/mnist/ 上获得。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the sample of the population surveyed was skewed toward Republican voters, and so the predictions based on these surveys were also skewed.",
            "zh": "因此，接受调查的人口样本偏向于共和党选民，因此基于这些调查的预测也存在偏差。"
        }
    },
    {
        "translation": {
            "en": "This McCulloch and Pitts model had a two-part structure.",
            "zh": "这个 McCulloch 和 Pitts 模型具有两部分结构。"
        }
    },
    {
        "translation": {
            "en": "8. Box plots are one of the collection of visual data exploration techniques first presented in Tukey’s influential 1977 book Exploratory Data Analysis (Tukey, 1977).",
            "zh": "8. 箱形图是 Tukey 1977 年出版的有影响力的著作《探索性数据分析》（Tukey，1977 年）中首次提出的视觉数据探索技术集合之一。"
        }
    },
    {
        "translation": {
            "en": "Conversely, however, as the amount of training data increases.",
            "zh": "然而，相反，随着训练数据量的增加。"
        }
    },
    {
        "translation": {
            "en": "21. We can do this either by consulting a probability table or by using integration to calculate the area under the curve within the bounds of the interval. There are many excellent statistical textbooks that explain how to do both of these, for example, Montgomery and Runger (2010).",
            "zh": "21. 我们可以通过查阅概率表或使用积分来计算区间范围内的曲线下面积来做到这一点。有许多优秀的统计教科书解释了如何做到这两点，例如Montgomery和Runger（2010）。"
        }
    },
    {
        "translation": {
            "en": "The first convolutional layer uses a max pooling layer to sub-sample each of the feature maps.",
            "zh": "第一个卷积层使用最大池化层对每个特征图进行子采样。"
        }
    },
    {
        "translation": {
            "en": "It is clear that the variance of the distribution of z values dramatically reduces as we move forward through the network, and this reduction in the variance together with the fact that the median of the z values is 0 across all the layers indicates that the z values are consistently getting smaller.",
            "zh": "很明显，当我们在网络中前进时，z 值分布的方差会急剧减小，并且方差的这种减小以及所有层中 z 值的中位数为 0 这一事实表明 z 值一直在变小。"
        }
    },
    {
        "translation": {
            "en": "This course gives students an introduction to predictive data analytics, a solid understanding of how machine learning solutions should be designed to meet a business need, insight into how prediction models work and should be evaluated, and one of the case studies.",
            "zh": "本课程向学生介绍了预测数据分析，深入了解了机器学习解决方案应如何设计以满足业务需求，深入了解预测模型的工作原理和评估方式，以及其中一个案例研究。"
        }
    },
    {
        "translation": {
            "en": "For example, imagine we wanted to use the Bayesian network in Figure 6.13[296] to predict the CPI for a country with the following profile:",
            "zh": "例如，假设我们想使用图 6.13[296] 中的贝叶斯网络来预测具有以下配置文件的国家的 CPI："
        }
    },
    {
        "translation": {
            "en": "Using this dataset, calculate the following probabilities:",
            "zh": "使用此数据集，计算以下概率："
        }
    },
    {
        "translation": {
            "en": "Figure 9.16",
            "zh": "图 9.16"
        }
    },
    {
        "translation": {
            "en": "The data from the Galaxy Zoo project was publicly available and therefore easily accessible to Jocelyn.",
            "zh": "银河动物园项目的数据是公开的，因此Jocelyn很容易访问。"
        }
    },
    {
        "translation": {
            "en": "Backpropagation works by using the chain rule to assign blame to each of the model’s parameters (weights) in proportion to the sensitivity of the network’s error to changes in those weights.",
            "zh": "反向传播的工作原理是使用链式法则将责任分配给模型的每个参数（权重），该参数（权重）与网络误差对这些权重变化的敏感性成比例。"
        }
    },
    {
        "translation": {
            "en": "Figures 3.14(d)[92] to 3.14(f)[92] show the same normally distributed continuous feature mentioned previously binned into different numbers of bins using equal-frequency binning.13",
            "zh": "图3.14（d）[92]至3.14（f）[92]显示了前面提到的相同的正态分布连续特征，使用等频分档到不同数量的分档中13。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21",
            "zh": "图 4.21"
        }
    },
    {
        "translation": {
            "en": "If the distributions of prediction scores from predictive models perfectly followed a normal distribution, similar to those in Figure 9.9[557], calculating the degree of separation between distributions would be very simple and only involve a simple comparison of means and standard deviations.",
            "zh": "如果预测模型的预测分数分布完全遵循正态分布，类似于图9.9[557]中的分布，则计算分布之间的分离程度将非常简单，并且仅涉及均值和标准差的简单比较。"
        }
    },
    {
        "translation": {
            "en": "Prediction score distributions for the (a) spam and (b) ham target levels based on the data in Table 9.11[557].",
            "zh": "（a）垃圾邮件和（b）火腿目标水平的预测分数分布基于表9.11[557]中的数据。"
        }
    },
    {
        "translation": {
            "en": "where m is the slope of the line, and b is known as the y-intercept of the line (i.e., the position at which the line meets the vertical axis when the value of x is set to zero).",
            "zh": "其中 m 是直线的斜率，b 称为直线的 y 截距（即，当 x 值设置为零时直线与垂直轴相交的位置）。"
        }
    },
    {
        "translation": {
            "en": "Using this model, we can, for example, predict the expected rental price of a 690-square-foot office on the 11th floor of a building with a broadband rate of 50 Mb per second",
            "zh": "例如，使用这个模型，我们可以预测位于建筑物 11 楼的 690 平方英尺办公室的预期租金价格，宽带速率为每秒 50 Mb"
        }
    },
    {
        "translation": {
            "en": "The threshold boundaries for the four bins used to discretize the LOAN AMOUNT feature are",
            "zh": "用于离散化 LOAN AMOUNT 特征的四个箱的阈值边界为"
        }
    },
    {
        "translation": {
            "en": "For this introduction, we focus on categorical features and probability mass functions.",
            "zh": "在本介绍中，我们重点介绍分类特征和概率质量函数。"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection terminates when no accessible feature subset is better than the current subset.",
            "zh": "当没有可访问的特征子集优于当前子集时，前向顺序选择终止。"
        }
    },
    {
        "translation": {
            "en": "After covering the standard algorithm, we then look at extensions and variations that allow us to handle noisy data (the k nearest neighbor, or k-NN, algorithm), to make predictions more efficiently (k-d trees), to predict continuous targets, and to handle different kinds of descriptive features with varying measures of similarity.",
            "zh": "在介绍了标准算法之后，我们研究了扩展和变体，这些扩展和变体允许我们处理噪声数据（k 最近邻或 k-NN 算法）、更有效地进行预测（k-d 树）、预测连续目标以及处理具有不同相似度量的不同类型的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The number of possible levels that a descriptive feature can take determines the number of downward branches from a non-leaf node.",
            "zh": "描述性特征可以采用的可能级别数决定了从非叶节点向下分支的数量。"
        }
    },
    {
        "translation": {
            "en": "The deep Q network (DQN) algorithm addresses these issues using two key ideas: experience replay and network freezing.",
            "zh": "深度 Q 网络 （DQN） 算法使用两个关键思想来解决这些问题：体验回放和网络冻结。"
        }
    },
    {
        "translation": {
            "en": "Table 5.3",
            "zh": "表 5.3"
        }
    },
    {
        "translation": {
            "en": "Figure 4.11",
            "zh": "图 4.11"
        }
    },
    {
        "translation": {
            "en": "Shannon, Claude, 731",
            "zh": "香农，克劳德，731"
        }
    },
    {
        "translation": {
            "en": "OpenAI, 668",
            "zh": "OpenAI，668"
        }
    },
    {
        "translation": {
            "en": "Figure 10.10",
            "zh": "图 10.10"
        }
    },
    {
        "translation": {
            "en": "11. Gross et al. (2006) describes a real-world example of this kind of application of predictive analytics.",
            "zh": "11. Gross et al. （2006） 描述了这种预测分析应用的真实例子。"
        }
    },
    {
        "translation": {
            "en": "(f) Calculate information gain using the Gini index for the EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "（f） 使用基尼指数计算教育、婚姻状况和职业特征的信息增益。"
        }
    },
    {
        "translation": {
            "en": "For example, during a manual data entry process, a fat fingered5 analyst may have entered 100,000 instead of 1,000.",
            "zh": "例如，在手动数据输入过程中，一个胖手指5分析师可能输入了 100,000 而不是 1,000。"
        }
    },
    {
        "translation": {
            "en": "Binning involves converting a continuous feature into a categorical feature.",
            "zh": "分箱涉及将连续特征转换为分类特征。"
        }
    },
    {
        "translation": {
            "en": "We can use the separation of the prediction score distributions to construct performance measures for categorical prediction models.",
            "zh": "我们可以使用预测分数分布的分离来构建分类预测模型的性能度量。"
        }
    },
    {
        "translation": {
            "en": "The † symbol marks the path of processing that generates the vector mask that controls which activations in the cell state are updated (see Equation (8.110)[511]).",
            "zh": "†符号标记了生成矢量掩码的处理路径，该矢量掩码控制细胞状态中的哪些激活被更新（参见公式（8.110）[511]）。"
        }
    },
    {
        "translation": {
            "en": "The weight matrix is organized so that each row contains the weights for a single neuron.",
            "zh": "权重矩阵的组织方式是，每一行都包含单个神经元的权重。"
        }
    },
    {
        "translation": {
            "en": "After the player chooses to Stick, the dealer will reveal their hidden card and keep dealing more cards until they reach a total greater than or equal to 17.",
            "zh": "在玩家选择坚持后，庄家将展示他们的隐藏牌并继续发更多的牌，直到他们达到大于或等于 17 的总数。"
        }
    },
    {
        "translation": {
            "en": "We then select the statistical distribution that is most similar in shape to each of the resulting histograms.",
            "zh": "然后，我们选择形状与每个结果直方图最相似的统计分布。"
        }
    },
    {
        "translation": {
            "en": "Figure A.3",
            "zh": "图 A.3"
        }
    },
    {
        "translation": {
            "en": "PROFILE: Did the user complete the profile form when registering for the free trial?",
            "zh": "个人资料：用户在注册免费试用时是否填写了个人资料表单？"
        }
    },
    {
        "translation": {
            "en": "Figure 3.8",
            "zh": "图 3.8"
        }
    },
    {
        "translation": {
            "en": "Based on this error another new set of weights is calculated using the error deltas shown.",
            "zh": "基于此误差，使用所示的误差增量计算另一组新的权重。"
        }
    },
    {
        "translation": {
            "en": "Focusing on the softmax activations for the output layer for all four examples, all three neurons output similar values; this is not surprising given that this is a randomly initialized network.",
            "zh": "关注所有四个示例的输出层的 softmax 激活，所有三个神经元输出的值都相似;这并不奇怪，因为这是一个随机初始化的网络。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.12",
            "zh": "图 9.12"
        }
    },
    {
        "translation": {
            "en": "Actions are then selected randomly following this distribution.",
            "zh": "然后，根据此分布随机选择操作。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5",
            "zh": "图 4.5"
        }
    },
    {
        "translation": {
            "en": "The rows in the table are labeled Target-positive and Target-negative and represent the target feature values that were expected.",
            "zh": "表中的行标有“目标阳性”和“目标阴性”，表示预期的目标要素值。"
        }
    },
    {
        "translation": {
            "en": "Consequently, as we build the rest of the tree, we may reuse the ELEVATION feature.",
            "zh": "因此，当我们构建树的其余部分时，我们可以重用 ELEVATION 特征。"
        }
    },
    {
        "translation": {
            "en": "There are two kinds of mistakes that an inappropriate inductive bias can lead to: underfitting and overfitting. Underfitting occurs when the prediction model selected by the algorithm is too simplistic to represent the underlying relationship in the dataset between the descriptive features and the target feature. Overfitting, by contrast, occurs when the prediction model selected by the algorithm is so complex that the model fits the dataset too closely and becomes sensitive to noise in the data.",
            "zh": "不适当的归纳偏差会导致两种错误：欠拟合和过拟合。当算法选择的预测模型过于简单，无法表示数据集中描述性特征与目标特征之间的基本关系时，就会发生欠拟合。相反，当算法选择的预测模型非常复杂，以至于模型与数据集拟合得太紧密并且对数据中的噪声变得敏感时，就会发生过拟合。"
        }
    },
    {
        "translation": {
            "en": "17. If we extended this example so that the restaurant was slightly hip and prepared different dishes based on the main ingredient chosen every night, some that Conor likes more than others (for example, chicken satay one night and chicken pie the next), this would become an example of a multi-armed bandit problem. Multi-armed bandit problems are a common framework for solving optimization problems where choices have uncertain outcomes and can be viewed as a very simple form of reinforcement learning.",
            "zh": "17. 如果我们扩展这个例子，让餐厅稍微时髦一点，根据每晚选择的主要食材准备不同的菜肴，其中一些是康纳比其他食材更喜欢的（例如，前一天晚上的鸡肉沙爹和第二天的鸡肉馅饼），这将成为多臂强盗问题的一个例子。多臂强盗问题是解决优化问题的常见框架，其中选择具有不确定的结果，可以被视为一种非常简单的强化学习形式。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons in this network use a ReLU activation function, what would be the output of Neuron 5 if the network received the input vector: Neuron 1 = 0.7 and Neuron 2 = 0.3?",
            "zh": "（b） 假设该网络中的处理神经元使用 ReLU 激活函数，如果网络接收到输入向量：神经元 1 = 0.7 和神经元 2 = 0.3，神经元 5 的输出是什么？"
        }
    },
    {
        "translation": {
            "en": "(a) Use this model to make predictions for each of the following query instances.",
            "zh": "（a） 使用此模型对以下每个查询实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.9[399] illustrates such a network: the left uses a directed graph representation to show the topology of the network, and the weights on the connections; the right uses the matrix representation of the network to illustrate it processing the four possible input combinations to the XOR function in parallel.",
            "zh": "图8.9[399]说明了这样一个网络：左边使用有向图表示来显示网络的拓扑结构和连接上的权重;右图使用网络的矩阵表示来说明它并行处理 XOR 函数的四种可能的输入组合。"
        }
    },
    {
        "translation": {
            "en": "86.34",
            "zh": "86.34"
        }
    },
    {
        "translation": {
            "en": "This circle covers the area in the feature space that we know must contain all the instances that are closer to the query than best.",
            "zh": "这个圆圈覆盖了特征空间中的区域，我们知道该区域必须包含比最佳实例更接近查询的所有实例。"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks whose topological structure correctly reflects the causal relationships between the features in a dataset are called causal graphs.",
            "zh": "贝叶斯网络的拓扑结构正确地反映了数据集中特征之间的因果关系，称为因果图。"
        }
    },
    {
        "translation": {
            "en": "The same weights are used during the forward and backward passes of a single iteration of backpropagation.",
            "zh": "在反向传播的单次迭代的正向和向后传递期间使用相同的权重。"
        }
    },
    {
        "translation": {
            "en": "To understand underfitting and overfitting, consider the task of inducing a model to predict a person’s INCOME (the target feature) based on AGE (a single descriptive feature). Table 1.5[14] lists a simple dataset that gives ages and salaries for five people. A visualization11 of this dataset is shown in Figure 1.3(a)[15].",
            "zh": "要理解欠拟合和过拟合，请考虑诱导模型的任务，以根据 AGE（单个描述性特征）预测一个人的收入（目标特征）。表1.5[14]列出了一个简单的数据集，其中给出了五个人的年龄和工资。该数据集的可视化11如图1.3（a）[15]所示。"
        }
    },
    {
        "translation": {
            "en": "Another interesting point of comparison between these two trees is that even though they are both consistent with the dataset given in Table 4.3[136], they do not always return the same prediction.",
            "zh": "这两个树之间另一个有趣的比较点是，即使它们都与表4.3[136]中给出的数据集一致，但它们并不总是返回相同的预测。"
        }
    },
    {
        "translation": {
            "en": "Of those, f(x) = x2 is an example of a second order polynomial function, also known as a quadratic function, as its highest exponent is 2, and f(x) = 3x3 + 2x2 − x − 2 is a third order polynomial function, also known as a cubic function, as its highest exponent is 3.",
            "zh": "其中，f（x） = x2 是二阶多项式函数的一个例子，也称为二次函数，因为它的最高指数是 2，而 f（x） = 3x3 + 2x2 − x − 2 是三阶多项式函数，也称为三次函数，因为它的最高指数是 3。"
        }
    },
    {
        "translation": {
            "en": "2.8   Modeling points in time for a scenario with no real observation period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.8 对没有实际观测期的场景的时间点进行建模（每条线代表一个客户，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "Based on the predictions of these models, perform the following tasks to compare their performance.",
            "zh": "根据这些模型的预测，执行以下任务以比较其性能。"
        }
    },
    {
        "translation": {
            "en": "The minimum values of − 9,999 for the SKYIVAR_U/G/R/I/Z columns (and some others not shown in Table 13.2[711]), which were so different from the means for those columns, suggested that maybe there were missing values after all.10 There were also a number of columns, such as ROWC_U/G/R/I/Z, that had cardinality of 1 (and standard deviations of zero) indicating that every row had the same.",
            "zh": "SKYIVAR_U/G/R/I/Z 列（以及表 13.2[711] 中未显示的其他一些列）的最小值为 − 9,999，这与这些列的平均值大不相同，这表明可能毕竟存在缺失值ROWC_U。 基数为 1（标准差为零），表示每行都相同。"
        }
    },
    {
        "translation": {
            "en": "This combination of multiple examples processed in parallel and a larger learning rate can result in much faster training times using batch gradient descent.",
            "zh": "这种并行处理的多个示例和更大的学习率的组合可以导致使用批量梯度下降的训练时间更快。"
        }
    },
    {
        "translation": {
            "en": "It was not reasonable, nor necessary, to expect that Jocelyn would become fully familiar with the intricacies of the SDSS and the astronomy that it performs.",
            "zh": "期望Jocelyn完全熟悉SDSS的复杂性及其所执行的天文学是不合理的，也没有必要。"
        }
    },
    {
        "translation": {
            "en": "The weights in this weighted sum are the probabilities of the state transitions13",
            "zh": "此加权和中的权重是状态转换的概率13"
        }
    },
    {
        "translation": {
            "en": "This type of instability can be indicative that the learning rate α is too high.",
            "zh": "这种类型的不稳定性可能表明α学习率太高。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, several features of real data can help us to induce reasonable models in high-dimensional feature spaces.28 First, although real data does spread out, it doesn’t spread out quite as randomly and quickly as we have illustrated here.",
            "zh": "幸运的是，真实数据的几个特征可以帮助我们在高维特征空间中诱导出合理的模型.28首先，尽管真实数据确实会分散开来，但它并不像我们在这里说明的那样随机和快速地散开。"
        }
    },
    {
        "translation": {
            "en": "The decision surface resulting from Equation (7.27)[342] is shown in Figure 7.12(b)[343].",
            "zh": "由方程（7.27）[342]得出的决策面如图7.12（b）[343]所示。"
        }
    },
    {
        "translation": {
            "en": "Information gain for each descriptive feature as a predictor of membership of each cluster based on the clustering of the mobile phone customer dataset in Table 10.1[604] found using k-means clustering (k = 3).",
            "zh": "根据表10.1[604]中使用k均值聚类（k = 3）发现的移动电话客户数据集的聚类，每个描述性特征的信息增益作为每个聚类成员的预测因子。"
        }
    },
    {
        "translation": {
            "en": "The business agreed that a customer who had been inactive for one month (i.e., had not made any calls or paid a bill) or who had explicitly canceled or not renewed a contract would be considered to have churned.",
            "zh": "该企业同意，一个月不活跃的客户（即没有拨打任何电话或支付账单）或明确取消或未续签合同的客户将被视为已流失。"
        }
    },
    {
        "translation": {
            "en": "Hebb’s theory that learning occurs through changes in the connections between neurons and that behavior emerges through the flow of information across these connections has been very influential both in neuroscience and, as we will discuss, in deep learning.",
            "zh": "Hebb 的理论认为，学习是通过神经元之间连接的变化发生的，而行为是通过这些连接中的信息流出现的，这在神经科学中都非常有影响力，正如我们将要讨论的那样，在深度学习中也非常有影响力。"
        }
    },
    {
        "translation": {
            "en": "For example, zi is the result of the weighted sum calculation carried out in neuron i.",
            "zh": "例如，zi 是在神经元 i 中执行的加权和计算的结果。"
        }
    },
    {
        "translation": {
            "en": "1. This example dataset is inspired by the use of analytics in professional and college sports, often referred to as sabremetrics. Two accessible introductions to this field are Lewis (2004) and Keri (2007).",
            "zh": "1. 此示例数据集的灵感来自在职业和大学体育运动中使用分析，通常称为 sabremetrics。Lewis （2004） 和 Keri （2007） 对这一领域的两个无障碍介绍。"
        }
    },
    {
        "translation": {
            "en": "A covariance matrix contains a row and column for each feature, and each element of the matrix lists the covariance between the corresponding pairs of features.",
            "zh": "协方差矩阵包含每个特征的行和列，矩阵的每个元素都列出了相应特征对之间的协方差。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5",
            "zh": "图 3.5"
        }
    },
    {
        "translation": {
            "en": "Cards showing character faces and names for the Guess Who game.",
            "zh": "显示“猜猜谁”游戏的角色面孔和名字的卡片。"
        }
    },
    {
        "translation": {
            "en": "We can see in Figure 5.10(b)[201] that this circle intersects with the triangle marking the location of d12, which is currently stored in best (i.e., it is our current best guess for the nearest neighbor).",
            "zh": "我们可以在图5.10（b）[201]中看到，这个圆与标记d12位置的三角形相交，d12目前存储在最佳位置（即，这是我们目前对最近邻居的最佳猜测）。"
        }
    },
    {
        "translation": {
            "en": "Pearl, Judea. 2000. Causality: Models, reasoning and inference, Vol. 29. Cambridge University Press.",
            "zh": "珍珠，犹太。2000. 因果关系：模型、推理和推理，第 29 卷。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "C.1 Derivatives of Continuous Functions",
            "zh": "C.1 连续函数的导数"
        }
    },
    {
        "translation": {
            "en": "39. This operation is sometimes called the Hadamard product (see Appendix D[771]).",
            "zh": "39. 这种操作有时被称为Hadamard积（见附录D[771]）。"
        }
    },
    {
        "translation": {
            "en": "Here we can see that the decision boundary may have been pushed too far back into the yes region (one of the crosses is now on the wrong side of the decision boundary).",
            "zh": "在这里，我们可以看到决策边界可能被推得太远了，回到了“是”区域（其中一个交叉现在位于决策边界的错误一侧）。"
        }
    },
    {
        "translation": {
            "en": "The weighting is determined by the size of each partition—so a large partition should contribute more to the overall remaining entropy than a smaller partition.",
            "zh": "权重由每个分区的大小决定，因此大分区对整体剩余熵的贡献应该比较小的分区更大。"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic ranges from 0 to 1, and higher values indicate better model performance, reflecting the fact that there is a clear distinction between the distributions of the scores predicted by the model for the negative and the positive instances.",
            "zh": "K-S 统计量范围从 0 到 1，值越高表示模型性能越好，这反映了模型预测的负实例和正实例的分数分布之间存在明显区别。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.6[547] illustrates how the data is divided during the ε0 bootstrap process.",
            "zh": "图 9.6[547] 说明了在 ε0 引导过程中如何划分数据。"
        }
    },
    {
        "translation": {
            "en": "Two popular variants of ReLU that adopt this strategy are the Leaky ReLU (Maas et al., 2013) and the Parametric ReLU (He et al., 2015).",
            "zh": "采用这种策略的两种流行的 ReLU 变体是 Leaky ReLU （Maas et al.， 2013） 和 Parametric ReLU （He et al.， 2015）。"
        }
    },
    {
        "translation": {
            "en": "2.4.1   Different Types of Data",
            "zh": "2.4.1 不同类型的数据"
        }
    },
    {
        "translation": {
            "en": "For example, a minimum age value of − 12 would jump out as an error.",
            "zh": "例如，最小年龄值 − 12 将作为错误跳出。"
        }
    },
    {
        "translation": {
            "en": "For example, the layers of neurons are here represented by rectangles with rounded corners with the labels on the rectangles indicating whether the rectangle represents the input layer xt, the hidden layer ht, the output layer yt, or the hidden layer from the previous time-step ht−1; and the (multiple) connections between neurons in different layers are here represented by a single arrow labeled with the name of the weight matrix for the weights on those connections.",
            "zh": "例如，神经元层在这里由圆角矩形表示，矩形上的标签指示矩形是代表输入层 xt、隐藏层 ht、输出层 yt，还是来自前一个时间步长 ht−1 的隐藏层;不同层中神经元之间的（多个）连接在这里由一个箭头表示，箭头标有这些连接上的权重矩阵的名称。"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for the set of predictions shown in Table 9.1[537].",
            "zh": "表9.1[537]所示的一组预测的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Figure C.1(a)[765] shows a profile of the speed during this journey measured at different points in time.",
            "zh": "图C.1（a）[765]显示了在不同时间点测量的这段旅程中的速度曲线。"
        }
    },
    {
        "translation": {
            "en": "Finally, for those interested in experimenting with different evaluation measures, the ROCR package (Sing et al., 2005) for the R programming language includes a wide range of measures.",
            "zh": "最后，对于那些有兴趣尝试不同评估措施的人来说，R 编程语言的 ROCR 包（Sing et al.， 2005）包括广泛的措施。"
        }
    },
    {
        "translation": {
            "en": "There are a number of fundamental mathematical types that are the building blocks of linear algebra. These include",
            "zh": "有许多基本的数学类型是线性代数的组成部分。这些包括"
        }
    },
    {
        "translation": {
            "en": "business",
            "zh": "商"
        }
    },
    {
        "translation": {
            "en": "BILLAMOUNTCHANGEPCT",
            "zh": "账单金额更改PCT"
        }
    },
    {
        "translation": {
            "en": "13. The staircase nature of this graph arises from the fact that there are ranges for the threshold in which no instances occur (for example, from 0.348 to 0.657), during which the TPR and TNR values do not change. Larger test sets cause these curves to smoothen significantly.",
            "zh": "13. 该图的阶梯性质源于这样一个事实，即阈值存在不发生任何实例的范围（例如，从 0.348 到 0.657），在此期间 TPR 和 TNR 值不会改变。较大的测试集会导致这些曲线显著平滑。"
        }
    },
    {
        "translation": {
            "en": "Table 9.2",
            "zh": "表 9.2"
        }
    },
    {
        "translation": {
            "en": "When we have a small dataset (introducing the possibility of a lucky split), measuring aggregate performance using a set of models gives a better estimate of post-deployment performance than measuring performance using a single model.",
            "zh": "当我们有一个较小的数据集时（引入了幸运拆分的可能性），使用一组模型来衡量总体性能比使用单个模型来衡量性能可以更好地估计部署后的性能。"
        }
    },
    {
        "translation": {
            "en": "(e) The salaries of car insurance policyholders.",
            "zh": "（e） 汽车保险投保人的薪金。"
        }
    },
    {
        "translation": {
            "en": "11.6   (a) A visualization of the final action-value table for an agent trained using SARSA on-policy temporal-difference learning across the grid world after 350 episodes. (b) The cumulative reward earned from each episode. (c) An illustration of the target policy learned by the agent after 350 episodes. (d) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "11.6 （a） 在 350 集后，在整个网格世界中使用 SARSA 政策时间差异学习训练的智能体的最终行动值表的可视化。（b） 每集所获得的累积奖励。（c） 代理人在350集后了解到的目标政策的说明。（d） 当贪婪地遵循目标策略时，代理从开始状态到目标状态的路径。"
        }
    },
    {
        "translation": {
            "en": "(a) The Voronoi tessellation of the feature space when the dataset has been updated to include the query instance; and (b) the updated decision boundary reflecting the addition of the query instance in the training set.",
            "zh": "（a） 当数据集更新为包含查询实例时，特征空间的 Voronoi 曲面细分;（b） 更新的决策边界，反映了在训练集中添加查询实例的情况。"
        }
    },
    {
        "translation": {
            "en": "This section assumes a basic understanding of probability theory, including the basics of calculating probabilities based on relative frequencies, calculating conditional probabilities, the probability product rule, the probability chain rule, and the Theorem of Total Probability.",
            "zh": "本节假设对概率论有基本的了解，包括基于相对频率计算概率、计算条件概率、概率乘积规则、概率链规则和总概率定理的基础知识。"
        }
    },
    {
        "translation": {
            "en": "Sometimes this expected global structure does not match actual patterns within a dataset that we might want to take advantage of.",
            "zh": "有时，这种预期的全局结构与我们可能想要利用的数据集中的实际模式不匹配。"
        }
    },
    {
        "translation": {
            "en": "68−95−99.7 rule, 62, 71",
            "zh": "68−95−99.7 规则、62、71"
        }
    },
    {
        "translation": {
            "en": "Consequently, there is a diminishing return on the improvement of the network relative to the time spent on training.",
            "zh": "因此，相对于花在培训上的时间，网络改进的回报是递减的。"
        }
    },
    {
        "translation": {
            "en": "cumulative gain chart, 569, 570, 592",
            "zh": "累计增益图，569、570、592"
        }
    },
    {
        "translation": {
            "en": "The average monthly recurring charge paid by the customer",
            "zh": "客户每月支付的平均经常性费用"
        }
    },
    {
        "translation": {
            "en": "(2008) indicate that boosted decision tree ensembles were the best-performing model of those tested for datasets containing up to 4,000 descriptive features.",
            "zh": "（2008）指出，在包含多达4,000个描述性特征的数据集中，增强决策树集成是性能最好的模型。"
        }
    },
    {
        "translation": {
            "en": "It may, for example, be a state that has a very low probability in the distribution.",
            "zh": "例如，它可能是分布中概率非常低的状态。"
        }
    },
    {
        "translation": {
            "en": "We use an example to illustrate how a prediction is made using a multinomial regression model.",
            "zh": "我们用一个例子来说明如何使用多项式回归模型进行预测。"
        }
    },
    {
        "translation": {
            "en": "Cars occupy an area covered by two cells (one above the other as shown in Image (a)).",
            "zh": "汽车占据由两个单元格覆盖的区域（一个在另一个单元格之上，如图（a）所示）。"
        }
    },
    {
        "translation": {
            "en": "13.5 Evaluation",
            "zh": "13.5 评估"
        }
    },
    {
        "translation": {
            "en": "Consequently, Ross needed to agree with the business (in particular the customer retention team) on a definition of churn.",
            "zh": "因此，Ross 需要与业务部门（尤其是客户保留团队）就客户流失的定义达成一致。"
        }
    },
    {
        "translation": {
            "en": "DIABETES",
            "zh": "糖尿病"
        }
    },
    {
        "translation": {
            "en": "2. To try to better understand the slightly baffling behavior of her new baby, Maria—a scientifically minded new mother—monitored her baby girl over the course of a day recording her activity at 20 minute intervals. The activity stream looked like this (with time flowing down through the columns):",
            "zh": "2. 为了更好地理解她新生婴儿略微莫名其妙的行为，玛丽亚——一位具有科学头脑的新妈妈——在一天的时间里监测她的女婴，每隔 20 分钟记录一次她的活动。活动流如下所示（时间流过列）："
        }
    },
    {
        "translation": {
            "en": "4. Likely voters are the subset of registered voters who have been identified as most likely to actually vote in an election.",
            "zh": "4. 可能选民是被确定为最有可能在选举中实际投票的登记选民的子集。"
        }
    },
    {
        "translation": {
            "en": "sum of squared errors, 315, 367, 409, 411, 424, 426, 433, 441, 575, 578, 731",
            "zh": "误差的平方和，315、367、409、411、424、426、433、441、575、578、731"
        }
    },
    {
        "translation": {
            "en": "At first she was terrible at it, and almost every step she took led to the disappointing sensation of wet feet.",
            "zh": "起初，她对此很糟糕，几乎每走一步都会导致令人失望的湿脚感。"
        }
    },
    {
        "translation": {
            "en": "If we have knowledge of these parent and children nodes, however, then the node is conditionally independent of the rest of the nodes in the graph.",
            "zh": "但是，如果我们了解这些父节点和子节点，则该节点在条件上独立于图中的其余节点。"
        }
    },
    {
        "translation": {
            "en": "In this section we describe the techniques used to address these issues as well as the use of ensemble methods that allow us to combine the predictions made by multiple models.",
            "zh": "在本节中，我们将介绍用于解决这些问题的技术，以及集成方法的使用，这些方法允许我们组合多个模型的预测。"
        }
    },
    {
        "translation": {
            "en": "PREFCHANNEL: The customer’s preferred contact channel (email, phone, or sms)",
            "zh": "PREFCHANNEL：客户的首选联系渠道（电子邮件、电话或短信）"
        }
    },
    {
        "translation": {
            "en": "Figure 8.21[444] plots the SSE of the ReLU network across the training epochs when we use a smaller learning rate, in this case α = 0.1.",
            "zh": "图 8.21[444] 绘制了当我们使用较小的学习率（在本例中为 α = 0.1）时，ReLU 网络在整个训练时期的 SSE。"
        }
    },
    {
        "translation": {
            "en": "Long short-term memory (LSTM) networks are specifically designed to improve the ability of a recurrent network to model dependencies over long distances in a sequence (Hochreiter and Schmidhuber, 1997).",
            "zh": "长短期记忆（LSTM）网络专门设计用于提高循环网络在序列中长距离建模依赖性的能力（Hochreiter和Schmidhuber，1997）。"
        }
    },
    {
        "translation": {
            "en": "All the performance measures described in Chapter 9[533] for supervised learning relied on the existence of ground truth labels to which the predictions made by a model can be compared to measure its performance.",
            "zh": "第9章[533]中描述的监督学习的所有性能测量都依赖于基本实况标签的存在，模型所做的预测可以与这些标签进行比较以衡量其性能。"
        }
    },
    {
        "translation": {
            "en": "5. Using binary logs, the maximum entropy for a set with two types of elements is 1.00 bit, but the entropy for a set with more than two types of elements may be greater than 1.00 bit. The choice of base used in Shannon’s model, in the context in which it is used in this chapter, is arbitrary. The choice of base 2 is due partly to a conventional computer science background and partly to its allowing us to use the bits unit of information.",
            "zh": "5. 使用二进制对数，具有两种类型元素的集合的最大熵为 1.00 位，但具有两种以上元素的集合的最大熵可能大于 1.00 位。在本章使用的上下文中，香农模型中使用的基数的选择是任意的。选择以 2 为基数的部分原因是传统的计算机科学背景，部分原因是它允许我们使用信息的比特单位。"
        }
    },
    {
        "translation": {
            "en": "Scarne, John. 1986. Scarne’s new complete guide to gambling. Simon & Schuster.",
            "zh": "斯卡恩，约翰。1986. 斯卡恩的新赌博完整指南。西蒙和舒斯特。"
        }
    },
    {
        "translation": {
            "en": "FAMILY, did any of their parents or siblings suffer from heart disease",
            "zh": "家庭，他们的父母或兄弟姐妹是否患有心脏病"
        }
    },
    {
        "translation": {
            "en": "The fact that the same weights are applied on the feedback loop within a recurrent network means that these networks are very susceptible to unstable gradients, as the repeated multiplication by the same weight of the gradient as it is propagated back through the unrolled network can cause the gradient to explode or vanish.",
            "zh": "在循环网络中的反馈回路上施加相同的权重这一事实意味着这些网络非常容易受到不稳定梯度的影响，因为在梯度通过展开网络传播回来时，重复乘以相同权重的梯度会导致梯度爆炸或消失。"
        }
    },
    {
        "translation": {
            "en": "As the figure shows, it is possible to draw a straight line between these two classes of inputs.",
            "zh": "如图所示，可以在这两类输入之间画一条直线。"
        }
    },
    {
        "translation": {
            "en": "Most people would ask Question 1 first.",
            "zh": "大多数人会先问问题 1。"
        }
    },
    {
        "translation": {
            "en": "logistic unit, 386",
            "zh": "后勤单位，386"
        }
    },
    {
        "translation": {
            "en": "The other main advantage of using a programming language is that, in most cases, the newest advanced analytics techniques become available in programming languages long before they are implemented in application-based solutions.",
            "zh": "使用编程语言的另一个主要优点是，在大多数情况下，最新的高级分析技术早在基于应用程序的解决方案中实现之前，就已经在编程语言中可用。"
        }
    },
    {
        "translation": {
            "en": "Stormy nights are rare.",
            "zh": "暴风雨的夜晚很少见。"
        }
    },
    {
        "translation": {
            "en": "A data quality report, however, can also be used to explore any dataset and is commonly used to understand the data in the raw data sources that are used to populate an ABT.",
            "zh": "但是，数据质量报告也可用于浏览任何数据集，并且通常用于了解用于填充 ABT 的原始数据源中的数据。"
        }
    },
    {
        "translation": {
            "en": "So what is the actual probability that the patient has the disease?",
            "zh": "那么患者患上这种疾病的实际概率是多少呢？"
        }
    },
    {
        "translation": {
            "en": "The issue was that some levels had multiple representations—for example, for the REGIONTYPE feature, towns were represented as town and as t. Ross easily corrected this issue by mapping the levels of the feature to one consistent labeling scheme.",
            "zh": "问题在于某些级别具有多个表示形式，例如，对于 REGIONTYPE 特征，城镇表示为城镇和 t。Ross 通过将特征级别映射到一个一致的标记方案，轻松纠正了这个问题。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, automated approaches to answering this question don’t really exist, and it falls on analysts to understand what a clustering result tells them about a dataset.",
            "zh": "不幸的是，回答这个问题的自动化方法并不存在，分析师需要了解聚类结果对数据集的了解。"
        }
    },
    {
        "translation": {
            "en": "4.1   A dataset that represents the characters in the Guess Who game.",
            "zh": "4.1 表示猜猜谁游戏中角色的数据集。"
        }
    },
    {
        "translation": {
            "en": "“Dick: I guess it looks as if you’re reorganizing your records. What is this though? Chronological?",
            "zh": "“迪克：我猜你好像在重新整理你的记录。这是什么呢？按时间先后？"
        }
    },
    {
        "translation": {
            "en": "To calculate the ith percentile of the n values of a feature a, we first order the values in ascending order and then multiply n by to determine the index.",
            "zh": "为了计算特征 a 的 n 个值的第 i 个百分位数，我们首先按升序对值进行排序，然后将 n 乘以以确定指数。"
        }
    },
    {
        "translation": {
            "en": "The fact that we can use a sequence of matrix operations to implement how a neural network processes a single example can be generalized to processing a number of examples in parallel.",
            "zh": "我们可以使用一系列矩阵运算来实现神经网络如何处理单个示例，这一事实可以推广到并行处理多个示例。"
        }
    },
    {
        "translation": {
            "en": "The three closest neighbors to the query are instances d12, d16 and d3.",
            "zh": "查询的三个最近邻居是实例 d12、d16 和 d3。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.12",
            "zh": "图 2.12"
        }
    },
    {
        "translation": {
            "en": "Howard, R. 1960. Dynamic programming and Markov processes. MIT Press.",
            "zh": "霍华德，R. 1960 年。动态规划和马尔可夫过程。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "If a predictive model is to be useful, it must be able to make predictions for queries that are not present in the data.",
            "zh": "如果预测模型要有用，它必须能够对数据中不存在的查询进行预测。"
        }
    },
    {
        "translation": {
            "en": "Rewards can also often be somewhat contradictory, and an action that gives an immediate positive reward may turn out to be a bad one in the longer term.",
            "zh": "奖励也常常有些矛盾，从长远来看，立即给予积极奖励的行动可能会变成一个糟糕的行为。"
        }
    },
    {
        "translation": {
            "en": "13.3 Data Preparation",
            "zh": "13.3 数据准备"
        }
    },
    {
        "translation": {
            "en": "The remaining rewards are based on the winnings earned within the game.",
            "zh": "其余奖励基于在游戏中获得的奖金。"
        }
    },
    {
        "translation": {
            "en": "Wood, Robert W. 1904. The n-rays. Nature 70: 530–531.",
            "zh": "伍德，罗伯特 W. 1904 年。n射线。自然70：530-531。"
        }
    },
    {
        "translation": {
            "en": "third order polynomial function, 766",
            "zh": "三阶多项式函数，766"
        }
    },
    {
        "translation": {
            "en": "A linear relationship implies that the target is calculated from the descriptive features using only the addition of the descriptive feature values multiplied by weight values.",
            "zh": "线性关系意味着仅使用描述性特征值乘以权重值相加，即可根据描述性特征计算目标。"
        }
    },
    {
        "translation": {
            "en": "The input gate uses separate paths of information processing to make each of these decisions and then merges the results of these decisions using an elementwise product.",
            "zh": "输入门使用单独的信息处理路径来做出这些决策中的每一个，然后使用逐元乘积合并这些决策的结果。"
        }
    },
    {
        "translation": {
            "en": "co-presence (CP), how often a true value occurred for the same feature in both the query data q and the data for the comparison user (d1 or d2)",
            "zh": "共存 （CP），同一要素在查询数据 q 和比较用户（d1 或 d2）的数据中出现真值的频率"
        }
    },
    {
        "translation": {
            "en": "Figure 5.8",
            "zh": "图 5.8"
        }
    },
    {
        "translation": {
            "en": "bagging, 159, 159, 171, 179, 733, 735",
            "zh": "装袋， 159， 159， 171， 179， 733， 735"
        }
    },
    {
        "translation": {
            "en": "The sample space for the domain of two dice.",
            "zh": "两个骰子的域的样本空间。"
        }
    },
    {
        "translation": {
            "en": "The pattern 99,999 also suggests that this is most likely a data entry error or a system default remaining in the ABT.",
            "zh": "模式 99,999 还表明，这很可能是数据输入错误或 ABT 中残留的系统默认值。"
        }
    },
    {
        "translation": {
            "en": "Bayesian score, 293",
            "zh": "贝叶斯评分，293"
        }
    },
    {
        "translation": {
            "en": "However, he did notice that the animal had webbed feet and a duck-billed snout.",
            "zh": "然而，他确实注意到这只动物有蹼的脚和鸭嘴的鼻子。"
        }
    },
    {
        "translation": {
            "en": "0.6353",
            "zh": "0.6353"
        }
    },
    {
        "translation": {
            "en": "Elman, Jeffrey L. 1990. Finding structure in time. Cognitive Science 14 (2): 179–211.",
            "zh": "埃尔曼，杰弗里 L. 1990 年。及时找到结构。认知科学14（2）：179-211。"
        }
    },
    {
        "translation": {
            "en": "We do not correct data quality issues due to valid data unless the predictive models we will use the data in the ABT to train require that particular data quality issues be corrected.",
            "zh": "我们不会纠正由于有效数据而导致的数据质量问题，除非我们将使用 ABT 中的数据进行训练的预测模型需要纠正特定的数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "To achieve this a reward structure has been designed.",
            "zh": "为了实现这一目标，设计了一种奖励结构。"
        }
    },
    {
        "translation": {
            "en": "Friedman, Jerome H. 2001. Greedy function approximation: A gradient boosting machine. Annals of Statistics 21 (5): 1189–1232.",
            "zh": "弗里德曼，杰罗姆 H. 2001 年。贪婪函数近似：梯度提升机。统计年鉴21（5）：1189-1232。"
        }
    },
    {
        "translation": {
            "en": "0.1828",
            "zh": "0.1828"
        }
    },
    {
        "translation": {
            "en": "Table 14.2",
            "zh": "表 14.2"
        }
    },
    {
        "translation": {
            "en": "Table 4.5",
            "zh": "表 4.5"
        }
    },
    {
        "translation": {
            "en": "The simple version of gradient boosting described here can be extended in many ways.",
            "zh": "此处描述的梯度提升的简单版本可以通过多种方式进行扩展。"
        }
    },
    {
        "translation": {
            "en": "This illustrates how two different models that are both consistent with a dataset can make different generalizations.12 So, which feature selection metric should be used, information gain or information gain ratio?",
            "zh": "这说明了两个与数据集一致的不同模型如何进行不同的泛化.12那么，应该使用哪种特征选择指标，信息增益还是信息增益比？"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the final logistic regression model on the large hold-out test set (classification accuracy: 87.979%, average class accuracy: 67.305%).",
            "zh": "大型保持检验集上最终逻辑回归模型的混淆矩阵（分类准确率：87.979%，平均类准确率：67.305%）。"
        }
    },
    {
        "translation": {
            "en": "PSFMAG_U/G/R/I/Z",
            "zh": "PSFMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "false",
            "zh": "假"
        }
    },
    {
        "translation": {
            "en": "The definition would be used to identify churn events in AT’s historical data and, consequently, was fundamental to building the ABT for the project.",
            "zh": "该定义将用于识别 AT 历史数据中的流失事件，因此对于为项目构建 ABT 至关重要。"
        }
    },
    {
        "translation": {
            "en": "The design of model evaluation experiments is an example of the application of techniques from the larger discipline of experimental design, which is used extensively in the manufacturing industry amongst others. Montgomery (2012) is an excellent reference for this topic and well worth reading.",
            "zh": "模型评估实验的设计是应用实验设计这一更大学科的技术的一个例子，该学科在制造业等领域被广泛使用。Montgomery（2012）是该主题的极好参考，非常值得一读。"
        }
    },
    {
        "translation": {
            "en": "Notice that the weight matrices do not change shape, nor does the sequence of operations, and the activation functions φ are still applied elementwise to all the elements in z matrices.",
            "zh": "请注意，权重矩阵不会改变形状，操作顺序也不会改变，并且激活函数φ仍按元素应用于 z 矩阵中的所有元素。"
        }
    },
    {
        "translation": {
            "en": "These are typically used in situations where a Minkowski distance is not appropriate.",
            "zh": "这些通常用于闵可夫斯基距离不合适的情况下。"
        }
    },
    {
        "translation": {
            "en": "Like every telecommunications company, AT struggles with customer churn—customers leaving AT for other mobile phone operators.",
            "zh": "与每家电信公司一样，AT也在努力应对客户流失问题，即客户将AT留给其他移动电话运营商。"
        }
    },
    {
        "translation": {
            "en": "To facilitate its use in these different contexts, the book has been designed to be modular—with very few dependencies between chapters.",
            "zh": "为了便于在这些不同的上下文中使用，本书被设计为模块化的，章节之间的依赖关系非常小。"
        }
    },
    {
        "translation": {
            "en": "Instead, the company approached him with a business problem—reducing customer churn.",
            "zh": "相反，该公司向他提出了一个业务问题——减少客户流失。"
        }
    },
    {
        "translation": {
            "en": "While complex scientific scenarios can make this process more difficult than is the case for more typical business applications, there is also the advantage that scientific projects typically produce publications clearly explaining their work.",
            "zh": "虽然复杂的科学场景可能会使这个过程比更典型的业务应用程序更加困难，但还有一个优势，即科学项目通常会产生清楚地解释其工作的出版物。"
        }
    },
    {
        "translation": {
            "en": "11.2.1 Intelligent Agents",
            "zh": "11.2.1 智能代理"
        }
    },
    {
        "translation": {
            "en": "After approximately 150 epochs the rate of decrease of the sum of squared errors increases, but training also becomes a bit unstable with the sum of squared errors of the network sometimes increasing and decreasing dramatically.",
            "zh": "大约150个周期后，平方误差和的减少率增加，但训练也变得有点不稳定，网络的平方误差总和有时会急剧增加和减少。"
        }
    },
    {
        "translation": {
            "en": "This observation is the basis for a number of weight initialization regimes that adjust the variance of the distribution used to sample the weights for a neuron based on its connections to other neurons in the network.",
            "zh": "这一观察结果是许多权重初始化方案的基础，这些方案根据神经元与网络中其他神经元的连接来调整用于对神经元的权重进行采样的分布方差。"
        }
    },
    {
        "translation": {
            "en": "Corruption Perception Index, 237, 294",
            "zh": "清廉指数， 237， 294"
        }
    },
    {
        "translation": {
            "en": "DropMask, 530",
            "zh": "滴面膜，530"
        }
    },
    {
        "translation": {
            "en": "F1 score, 549",
            "zh": "F1得分，549"
        }
    },
    {
        "translation": {
            "en": "This is an example of using a state generation function as discussed in Section 11.2[638].",
            "zh": "这是使用状态生成函数的示例，如第 11.2 节[638]所述。"
        }
    },
    {
        "translation": {
            "en": "Having a dominant target level, like the elliptical target level in this example, means that models trained on this data can overcompensate for the majority target level and ignore the minority ones.",
            "zh": "具有主导目标水平（如本例中的椭圆目标水平）意味着在此数据上训练的模型可以过度补偿多数目标水平并忽略少数目标水平。"
        }
    },
    {
        "translation": {
            "en": "top sampling, 92",
            "zh": "顶部采样，92"
        }
    },
    {
        "translation": {
            "en": "Equal-frequency binning does this.",
            "zh": "等频合并可以做到这一点。"
        }
    },
    {
        "translation": {
            "en": "As a general rule of thumb, only features that are missing in excess of 60% of their values should be considered for complete removal, and more subtle handling techniques should be used for features missing less data.",
            "zh": "作为一般经验法则，只有缺失超过其值 60% 的特征才应考虑完全删除，并且对于缺少较少数据的特征，应使用更精细的处理技术。"
        }
    },
    {
        "translation": {
            "en": "11.5 Summary",
            "zh": "11.5 小结"
        }
    },
    {
        "translation": {
            "en": "The following table also shows the distance to these three cluster centers for each instance in the dataset.",
            "zh": "下表还显示了数据集中每个实例到这三个聚类中心的距离。"
        }
    },
    {
        "translation": {
            "en": "2. The table below shows the predictions made for a continuous target feature by two different prediction models for a test dataset.",
            "zh": "2. 下表显示了两种不同的预测模型对测试数据集的连续目标特征所做的预测。"
        }
    },
    {
        "translation": {
            "en": "Either way, this instance is likely to be an example of noise in the dataset.",
            "zh": "无论哪种方式，此实例都可能是数据集中噪声的一个示例。"
        }
    },
    {
        "translation": {
            "en": "For example, the decision boundaries associated with decision trees have a characteristic stepped appearance because of the way feature values are split in a decision tree, while the decision boundaries associated with k-NN models are noticeably jagged because of their local focus.",
            "zh": "例如，由于特征值在决策树中的分割方式，与决策树关联的决策边界具有特征阶梯外观，而与 k-NN 模型关联的决策边界由于其局部焦点而明显呈锯齿状。"
        }
    },
    {
        "translation": {
            "en": "If you don’t understand any of these concepts, see Appendix C[765] for the necessary introduction.",
            "zh": "如果您不理解这些概念中的任何一个，请参阅附录 C[765] 以获取必要的介绍。"
        }
    },
    {
        "translation": {
            "en": "Schapire (1990) desscribed some of the early work on weak learners and computational learning theory.",
            "zh": "Schapire（1990）描述了一些关于弱学习者和计算学习理论的早期工作。"
        }
    },
    {
        "translation": {
            "en": "5.14   (a) The θ represents the inner angle between the vector emanating from the origin to instance d1 and the vector emanating from the origin to instance d2; and (b) shows d1 and d2 normalized to the unit circle.",
            "zh": "5.14 （a） θ表示从原点到实例d1的向量与从原点到实例d2的向量之间的内角;（b） 显示归一化为单位圆的 d1 和 d2。"
        }
    },
    {
        "translation": {
            "en": "Since agents using SARSA use a policy with some exploration in their action-value table update equation, they will often base their estimation of expected return on next actions with quite poor return.",
            "zh": "由于使用 SARSA 的代理在其行动-价值表更新方程中使用了一些探索的策略，因此他们通常会根据回报相当低的下一步行动来估计预期回报。"
        }
    },
    {
        "translation": {
            "en": "Aoife",
            "zh": "奥伊夫"
        }
    },
    {
        "translation": {
            "en": "where hxt is the concatenation of ht−1 and xt; and W(f) is the forget gate matrix of weights. For example, imagine an LSTM unit with the inputs and W(f) matrix (the zeros are the bias terms) as listed in Equation (8.108)[510]",
            "zh": "其中 hxt 是 ht−1 和 xt 的串联;W（f） 是权重的遗忘门矩阵。例如，假设一个LSTM单元具有输入和W（f）矩阵（零点是偏置项），如公式（8.108）[510]所示"
        }
    },
    {
        "translation": {
            "en": "Some of the bins are very tall and other bins are empty, as indicated by the gaps between the bars.",
            "zh": "一些垃圾箱非常高，而其他垃圾箱是空的，如栏杆之间的间隙所示。"
        }
    },
    {
        "translation": {
            "en": "A high-level schematic of the structure of a neuron. This figure illustrates three interconnected neurons; the middle neuron is highlighted in black, and the major structural components of this neuron are labeled cell body, dendrites, and axon. Also marked are the synapses connecting the axon of one neuron and the dendrite of another, which allow signals to pass between the neurons.",
            "zh": "神经元结构的高级示意图。该图说明了三个相互连接的神经元;中间神经元以黑色突出显示，该神经元的主要结构成分被标记为细胞体、树突和轴突。还标记了连接一个神经元的轴突和另一个神经元的树突的突触，它们允许信号在神经元之间传递。"
        }
    },
    {
        "translation": {
            "en": "1. What is predictive data analytics?",
            "zh": "1. 什么是预测性数据分析？"
        }
    },
    {
        "translation": {
            "en": "HEALTHDEPSKIDS: How many dependent children are included on the health insurance policy",
            "zh": "HEALTHDEPSKIDS：健康保险单中包括多少受抚养子女"
        }
    },
    {
        "translation": {
            "en": "We can, if we wish, sum out more than one feature. For example, we could compute P(h) by summing out all the other features in the dataset:",
            "zh": "如果我们愿意，我们可以总结出多个功能。例如，我们可以通过对数据集中的所有其他特征求和来计算 P（h）："
        }
    },
    {
        "translation": {
            "en": "23. Systems like the Western Electric rules (Montgomery, 2004), used widely in process engineering to detect out-of-control processes, can be useful in this regard.",
            "zh": "23. 西部电气规则（Montgomery，2004年）等系统在过程工程中被广泛用于检测失控的过程，在这方面是有用的。"
        }
    },
    {
        "translation": {
            "en": "local models, 189",
            "zh": "本地模型，189"
        }
    },
    {
        "translation": {
            "en": "DQN, 664",
            "zh": "DQN，664"
        }
    },
    {
        "translation": {
            "en": "unit hypercube, 224",
            "zh": "单位超立方体，224"
        }
    },
    {
        "translation": {
            "en": "If features have missing values, we must first determine why the values are missing.",
            "zh": "如果要素缺少值，我们必须首先确定缺少值的原因。"
        }
    },
    {
        "translation": {
            "en": "Consequently, no matter how long we train the network, Neuron 4 will remain in this dead state.",
            "zh": "因此，无论我们训练网络多长时间，Neuron 4 都将保持这种死状态。"
        }
    },
    {
        "translation": {
            "en": "The only knowledge an agent using temporal-difference learning requires is a list of states that exist in the environment, a way to recognize what state it is in, and a list of the actions that it is possible for the agent to take.",
            "zh": "使用时差学习的智能体需要的唯一知识是环境中存在的状态列表、识别其处于何种状态的方法以及智能体可能采取的操作列表。"
        }
    },
    {
        "translation": {
            "en": "directed cyclic graph, 499",
            "zh": "有向循环图，499"
        }
    },
    {
        "translation": {
            "en": "A dataset that includes office rental prices and a number of descriptive features for 10 Dublin city-center offices.",
            "zh": "一个数据集，包括都柏林市中心 10 个办公室的办公室租金价格和一些描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Models that either underfit or overfit do not generalize well and so will not be able to make good predictions for query instances beyond the content of the training dataset.",
            "zh": "欠拟合或过拟合的模型不能很好地泛化，因此无法对训练数据集内容之外的查询实例做出良好的预测。"
        }
    },
    {
        "translation": {
            "en": "7.3.2   Gradient Descent",
            "zh": "7.3.2 梯度下降"
        }
    },
    {
        "translation": {
            "en": "The problem is caused by features having different variance.",
            "zh": "该问题是由具有不同方差的特征引起的。"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are also sensitive to the presence of redundant and irrelevant descriptive features in training data.",
            "zh": "最近邻模型对训练数据中是否存在冗余和不相关的描述性特征也很敏感。"
        }
    },
    {
        "translation": {
            "en": "We completed the data quality plan by including these potential handling strategies. The final data quality plan is shown in Table 3.6[72]. Together with the data quality report, these are the outputs of the data exploration work for the motor insurance fraud detection project.",
            "zh": "我们通过包括这些潜在的处理策略来完成数据质量计划。最终的数据质量计划如表3.6所示[72]。与数据质量报告一起，这些是汽车保险欺诈检测项目数据探索工作的成果。"
        }
    },
    {
        "translation": {
            "en": "For our example we apply range normalization to both the descriptive features and the target feature. Note that for range normalization of the features we need the minimum and maximum values for each feature. Table 8.2[423] lists these values for the original complete dataset20 (as distinct from our sample of four examples). Table 8.3[423] lists the examples after the features have been range-normalized into the range [0,1].",
            "zh": "在我们的示例中，我们将范围归一化应用于描述性特征和目标特征。请注意，对于要素的范围归一化，我们需要每个要素的最小值和最大值。表 8.2[423] 列出了原始完整数据集 20 的这些值（与我们的四个示例样本不同）。表 8.3[423] 列出了将特征归一化为范围 [0,1] 后的示例。"
        }
    },
    {
        "translation": {
            "en": "guard",
            "zh": "警卫"
        }
    },
    {
        "translation": {
            "en": "(a) The company has decided to use a similarity-based model to implement the recommender system. Which of the following three similarity indexes do you think the system should be based on?",
            "zh": "（a） 公司决定使用基于相似性的模型来实施推荐系统。您认为系统应该基于以下三个相似性指数中的哪一个？"
        }
    },
    {
        "translation": {
            "en": "cumulative lift curve, 570",
            "zh": "累积提升曲线，570"
        }
    },
    {
        "translation": {
            "en": "random sampling without replacement, 94",
            "zh": "无替换的随机抽样，94"
        }
    },
    {
        "translation": {
            "en": "The number of instances in the training set and the number of weights for which we need to find values simply make the problem too large.",
            "zh": "训练集中的实例数和我们需要查找值的权重数只会使问题变得太大。"
        }
    },
    {
        "translation": {
            "en": "Careful examination of the workings of the different classification models that we have discussed in Chapters 4[117] to 7[311] shows that none of them simply produces a target feature level as its output.",
            "zh": "仔细研究我们在第 4 章[117] 至 7[311] 中讨论的不同分类模型的工作原理表明，它们都没有简单地产生目标特征级别作为其输出。"
        }
    },
    {
        "translation": {
            "en": "For example, the first row in Z(1) contains the weighted sum for Neuron 3 (i.e., z3) for d1, d2, d3, and d4, respectively.",
            "zh": "例如，Z（1） 中的第一行分别包含神经元 3（即 z3）对 d1、d2、d3 和 d4 的加权和。"
        }
    },
    {
        "translation": {
            "en": "The set of domain concepts for the Acme Telephonica customer churn prediction problem.",
            "zh": "Acme Telephonica 客户流失预测问题的域概念集。"
        }
    },
    {
        "translation": {
            "en": "Multiplying any matrix by the identity matrix leaves the original matrix unchanged—this is the equivalent of multiplying by 1 for real numbers.",
            "zh": "将任何矩阵乘以单位矩阵会使原始矩阵保持不变，这相当于将实数乘以 1。"
        }
    },
    {
        "translation": {
            "en": "Figure A.7(c)[754] illustrates the density histogram of the TRAINING EXPENSES feature using ten 200-unit intervals, and Figure A.7(d)[754] illustrates the density histogram using four 500-unit intervals.",
            "zh": "图 A.7（c）[754] 使用十个 200 单位间隔说明了训练费用特征的密度直方图，图 A.7（d）[754] 说明了使用四个 500 单位间隔的密度直方图。"
        }
    },
    {
        "translation": {
            "en": "More formally, for a network with three nodes x1,x2,x3, using a predefined node selection order of x1,x2,x3,x1,… and assuming that at iteration τ each node has the values , the next four states generated will be",
            "zh": "更正式地说，对于具有三个节点 x1，x2，x3 的网络，使用预定义的节点选择顺序 x1，x2，x3，x1,...假设在迭代 τ 时每个节点都有 的值，接下来生成的四个状态将是"
        }
    },
    {
        "translation": {
            "en": "Although the ABT is the key structure that we use in developing machine learning models, data in organizations is rarely kept in neat tables ready to be used to build predictive models. Instead, we need to construct the ABT from the raw data sources that are available in an organization. These may be very diverse in nature. Figure 2.1[29] illustrates some of the different data sources that are typically combined to create an ABT.",
            "zh": "尽管 ABT 是我们用于开发机器学习模型的关键结构，但组织中的数据很少保存在整洁的表格中，以便用于构建预测模型。相反，我们需要从组织中可用的原始数据源构建 ABT。这些在性质上可能非常多样化。图 2.1[29] 说明了通常组合在一起以创建 ABT 的一些不同数据源。"
        }
    },
    {
        "translation": {
            "en": "McGrayne (2011) is an accessible book on the development and history of Bayes’ Theorem. All data analysts should have at least one good textbook on statistics and probability. We would recommend either Montgomery and Runger (2010) or Tijms (2012) (or both). Jaynes (2003) deals with the use of probability theory in science and is a suitable text for postgraduate students.",
            "zh": "McGrayne （2011） 是一本关于贝叶斯定理发展和历史的通俗易懂的书。所有数据分析师都应该至少有一本关于统计和概率的好教科书。我们推荐Montgomery和Runger（2010）或Tijms（2012）（或两者兼而有之）。Jaynes（2003）涉及概率论在科学中的应用，是一本适合研究生的教材。"
        }
    },
    {
        "translation": {
            "en": "total sum of squares, 578",
            "zh": "平方总和，578"
        }
    },
    {
        "translation": {
            "en": "4.4.5.3 Gradient boosting Gradient boosting is a more recently developed, and very effective, algorithm for training ensemble models using boosting.",
            "zh": "4.4.5.3 梯度提升 梯度提升是最近开发的一种非常有效的算法，用于使用提升来训练集成模型。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.4[390] illustrates the structure of a basic artificial neural network.",
            "zh": "图8.4[390]说明了基本人工神经网络的结构。"
        }
    },
    {
        "translation": {
            "en": "Struggling to entertain his daughter one afternoon, Mr. Murphy asked little Abigail to tidy them up.",
            "zh": "一天下午，墨菲先生努力招待女儿，让小阿比盖尔收拾他们。"
        }
    },
    {
        "translation": {
            "en": "reward hypothesis, 640",
            "zh": "奖励假说，640"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(b)[151] depicts one of the extremes for grouping these instances, in which we treat them all as belonging to one partition.",
            "zh": "图 4.15（b）[151] 描述了对这些实例进行分组的极端情况之一，其中我们将它们全部视为属于一个分区。"
        }
    },
    {
        "translation": {
            "en": "495.76MW",
            "zh": "495.76兆瓦"
        }
    },
    {
        "translation": {
            "en": "7.7   Plots of the journeys made across the error surface for the simple office rentals prediction problem for different learning rates: (a) a very small learning rate (0.002); (b) a medium learning rate (0.08); and (c) a very large learning rate (0.18). The changing sum of squared errors are also shown.",
            "zh": "7.7 不同学习率的简单办公室租赁预测问题在误差面上的旅程图：（a）学习率非常小（0.002）;（b）中等学习率（0.08）;（c）非常高的学习率（0.18）。还显示了平方误差的变化和。"
        }
    },
    {
        "translation": {
            "en": "37. This example of predicting recidivism is based on a real application of machine learning: parole boards do rely on machine learning prediction models to help them when they are making their decisions. See Berk and Bleich (2013) for a recent comparison of different machine learning models used for this task. Datasets dealing with prisoner recidivism are available online, for example, catalog.data.gov/dataset/prisoner-recidivism/. The dataset presented here is not based on real data.",
            "zh": "37. 这个预测累犯的例子是基于机器学习的实际应用：假释委员会确实依靠机器学习预测模型来帮助他们做出决定。参见Berk and Bleich （2013） 最近对用于此任务的不同机器学习模型的比较。例如，catalog.data.gov/dataset/prisoner-recidivism/ 可以在线获得有关囚犯累犯的数据集。这里介绍的数据集不是基于真实数据。"
        }
    },
    {
        "translation": {
            "en": "Table 9.5",
            "zh": "表 9.5"
        }
    },
    {
        "translation": {
            "en": "(2008) suggest that a potential explanation for this pattern of results is that boosted ensembles are prone to overfitting, and in domains with large numbers of features, overfitting becomes a serious problem.",
            "zh": "（2008）认为，对这种结果模式的一个潜在解释是，增强集成容易出现过拟合，而在具有大量特征的领域中，过拟合成为一个严重的问题。"
        }
    },
    {
        "translation": {
            "en": "policy, 641, 643, 676",
            "zh": "政策， 641， 643， 676"
        }
    },
    {
        "translation": {
            "en": "Unsupervised machine learning techniques are used in the absence of a target feature and model the underlying structure within the descriptive features in a dataset. Usually this is done either to divide a dataset into clusters of similar examples, or to generate new features that can be appended to a dataset.",
            "zh": "在没有目标特征的情况下使用无监督机器学习技术，并对数据集中描述性特征中的底层结构进行建模。通常，这样做是为了将数据集划分为具有相似示例的聚类，或者生成可追加到数据集的新特征。"
        }
    },
    {
        "translation": {
            "en": "Confusion matrices for the set of predictions shown in Table 9.11[557] using (a) a prediction score threshold of 0.75 and (b) a prediction score threshold of 0.25.",
            "zh": "表 9.11[557] 所示的一组预测的混淆矩阵，使用 （a） 预测分数阈值为 0.75 和 （b） 预测分数阈值为 0.25。"
        }
    },
    {
        "translation": {
            "en": "Another approach used to determine the appropriate burn-in time is to start several Markov chains with different initial states and wait until all the chains are generating states with similar distribution characteristics (mean state, mode state, etc.).",
            "zh": "用于确定适当老化时间的另一种方法是启动几个具有不同初始状态的马尔可夫链，并等待所有链生成具有相似分布特征（平均状态、模式状态等）的状态。"
        }
    },
    {
        "translation": {
            "en": "where w[j] is the weight associated with descriptive feature d[j].",
            "zh": "其中w[j]是与描述性特征d[j]相关的权重。"
        }
    },
    {
        "translation": {
            "en": "Table 13.2[711] shows an extract from this data quality report.",
            "zh": "表13.2[711]显示了此数据质量报告的摘录。"
        }
    },
    {
        "translation": {
            "en": "This assumption allows a naive Bayes model to radically reduce the number of probabilities it requires, resulting in a very compact, highly factored representation of a domain.",
            "zh": "这个假设允许朴素贝叶斯模型从根本上减少它所需的概率数，从而产生一个非常紧凑、高度分解的域表示。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.3",
            "zh": "图 7.3"
        }
    },
    {
        "translation": {
            "en": "-0.2843",
            "zh": "-0.2843"
        }
    },
    {
        "translation": {
            "en": "Artificial neural networks are some of the most powerful machine learning models, able to learn complex non-linear mappings from inputs to outputs.",
            "zh": "人工神经网络是一些最强大的机器学习模型，能够学习从输入到输出的复杂非线性映射。"
        }
    },
    {
        "translation": {
            "en": "The algorithm then iteratively generates samples by changing the value of one of the non-evidence nodes.",
            "zh": "然后，该算法通过更改其中一个非证据节点的值来迭代生成样本。"
        }
    },
    {
        "translation": {
            "en": "Just as we might be more excited about receiving a gift of $100 today than a promise to receive a gift of $100 in a year’s time, it is reasonable when calculating expected return to pay more attention to the immediate reward we expect to receive from taking the next action than to the rewards that we expect to receive in 10 or even 100 actions’ time.",
            "zh": "正如我们今天收到 100 美元的礼物可能比承诺在一年内收到 100 美元的礼物更兴奋一样，在计算预期回报时，我们更关注我们期望从采取下一个行动中获得的即时奖励，而不是我们期望在 10 次甚至 100 次行动后收到的奖励。"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, the version of the classic Lunar Lander video game shown in Figure 11.7[669].26 In this game the player must land the spacecraft on the Moon’s surface without damaging it.",
            "zh": "例如，考虑图11.7[669]所示的经典月球着陆器视频游戏的版本.26在这个游戏中，玩家必须在不损坏月球表面的情况下将航天器降落在月球表面。"
        }
    },
    {
        "translation": {
            "en": "Either way, it is joined to the current node with a branch labeled with the appropriate level of the selected feature.",
            "zh": "无论采用哪种方式，它都会通过标有所选要素相应级别的分支连接到当前节点。"
        }
    },
    {
        "translation": {
            "en": "where α is the learning rate hyper-parameter and has the same function as the learning rate in gradient descent.13 This equation states that the updated weight after processing a training example is equal to the weight used to process the training example minus α times the sensitivity of the error of the network with respect to changes in the weight.",
            "zh": "其中 α 是学习率超参数，与梯度下降中的学习率具有相同的函数.13 该等式指出，处理训练示例后的更新权重等于用于处理训练示例的权重减去网络误差对权重变化的敏感度的 α 倍。"
        }
    },
    {
        "translation": {
            "en": "In summary, in a reinforcement learning scenario, an agent inhabiting an environment attempts to achieve a goal by taking a sequence of actions to move it between states.",
            "zh": "总之，在强化学习场景中，居住在环境中的智能体试图通过采取一系列操作在状态之间移动目标来实现目标。"
        }
    },
    {
        "translation": {
            "en": "The x-y plane is known as a weight space, and the surface is known as an error surface.",
            "zh": "x-y 平面称为权重空间，曲面称为误差曲面。"
        }
    },
    {
        "translation": {
            "en": "To train a recurrent neural network using backpropagation through time, we first do a forward pass by presenting each input in the sequence in turn and unrolling the network through time (as shown in Figure 8.38[504]).",
            "zh": "为了使用随时间反向传播来训练递归神经网络，我们首先通过依次呈现序列中的每个输入并随时间展开网络来进行前向传递（如图 8.38[504] 所示）。"
        }
    },
    {
        "translation": {
            "en": "NUMHANDSETS: This was a count of how many different handsets the customer had had in the past three years. This was derived from a count of all the handset entries for a particular customer.",
            "zh": "NUMHANDSETS：这是对客户在过去三年中拥有的不同手机数量的统计。这是从特定客户的所有手机条目的计数中得出的。"
        }
    },
    {
        "translation": {
            "en": "We return to the discussion of weights in the next section, Section 8.4.2[447 our focus in this section is on the effect of repeatedly multiplying the error gradient by the derivative of an activation function",
            "zh": "我们回到下一节中对权重的讨论，第 8.4.2 节[447 本节的重点是将误差梯度重复乘以激活函数的导数的效果"
        }
    },
    {
        "translation": {
            "en": "The experiments designed to show the existence of N rays simply relied too much on subjective measurements (the changes in the brightness of the spark was measured by simple human observation) and did not account for all the reasons other than the presence of N rays that could have created the phenomena observed.",
            "zh": "旨在证明N射线存在的实验过于依赖主观测量（火花亮度的变化是通过简单的人类观察来测量的），并且没有解释除N射线的存在之外的所有原因，这些原因可能产生观察到的现象。"
        }
    },
    {
        "translation": {
            "en": "—George E. P. Box",
            "zh": "——乔治·博克斯（George E. P. Box）"
        }
    },
    {
        "translation": {
            "en": "3.3.4.1 Missing values The % Miss.",
            "zh": "3.3.4.1 缺失值 未命中百分比"
        }
    },
    {
        "translation": {
            "en": "For example, if we had used root mean squared error on a hold-out test set to evaluate the performance of a model before deployment, we could collect all the query instances presented to the model for a period after deployment and, once their true target feature values became available, calculate the root mean squared error on this new set of query instances.",
            "zh": "例如，如果我们在部署之前对保持测试集使用均方根误差来评估模型的性能，则我们可以在部署后的一段时间内收集提供给模型的所有查询实例，并在其真正的目标特征值可用后，计算这组新查询实例的均方根误差。"
        }
    },
    {
        "translation": {
            "en": "saturated, 437, 447",
            "zh": "饱和， 437， 447"
        }
    },
    {
        "translation": {
            "en": "Xavier initialization has empirically been shown to often lead to faster training and is one of the most popular weight initialization approaches in deep learning.",
            "zh": "经验表明，Xavier 初始化通常可以更快地进行训练，并且是深度学习中最流行的权重初始化方法之一。"
        }
    },
    {
        "translation": {
            "en": "degrees of freedom, 272",
            "zh": "自由度，272"
        }
    },
    {
        "translation": {
            "en": "If the prior and posterior probabilities are very different, then the information content in the observation was high.",
            "zh": "如果先验概率和后验概率差异很大，则观察中的信息含量很高。"
        }
    },
    {
        "translation": {
            "en": "6.5 Summary",
            "zh": "6.5 小结"
        }
    },
    {
        "translation": {
            "en": "This ability led to a resurgence of interest in reinforcement learning in the 2010s after somewhat of a quiet period.",
            "zh": "这种能力导致在经历了一段平静期后，2010 年代对强化学习的兴趣重新抬头。"
        }
    },
    {
        "translation": {
            "en": "First, we will empirically show how different variations of weight initialization can interact with this property of weighted sum calculations in order to introduce different types instability into the internal training dynamics within a network.",
            "zh": "首先，我们将实证地展示权重初始化的不同变化如何与加权和计算的这种属性相互作用，以便将不同类型的不稳定性引入网络内的内部训练动态中。"
        }
    },
    {
        "translation": {
            "en": "To illustrate how a K-S statistic and K-S chart can give insight into model performance, Figure 9.14[566] shows a series of charts for the four different prediction models trained on the email classification task and evaluated on a large test set. The charts are a histogram of the spam scores predicted by the model, a histogram of the ham scores predicted by the model, and the resulting K-S chart with the K-S statistic highlighted.",
            "zh": "为了说明 K-S 统计量和 K-S 控制图如何深入了解模型性能，图 9.14[566] 显示了在电子邮件分类任务上训练并在大型测试集上评估的四种不同预测模型的一系列图表。这些图表是模型预测的垃圾邮件分数的直方图、模型预测的火腿分数的直方图，以及突出显示 K-S 统计量的结果 K-S 图表。"
        }
    },
    {
        "translation": {
            "en": "MARITAL STATUS (never married, married, divorced);",
            "zh": "婚姻状况（未婚、已婚、离婚）;"
        }
    },
    {
        "translation": {
            "en": "These weights are used as a distribution over which the dataset is sampled to create a replicated training set, in which the number of times an instance is replicated is proportional to its weight.",
            "zh": "这些权重用作对数据集进行采样以创建复制训练集的分布，其中复制实例的次数与其权重成正比。"
        }
    },
    {
        "translation": {
            "en": "The most common error function used for error-based models is the sum of squared errors.",
            "zh": "用于基于误差的模型的最常见误差函数是误差的平方和。"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (α0 = 0.25, c = 100); (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "（a） 使用学习率衰减时，办公室租金预测问题的误差面行程 （α0 = 0.25， c = 100）;（b） 此旅程中误差平方和的变化图。"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 5.15(b)[219], however, demonstrates a strong negative covariance21 between the features.",
            "zh": "然而，图5.15（b）[219]中的数据集显示了特征之间的强负协方差21。"
        }
    },
    {
        "translation": {
            "en": "The former criterion is very domain specific, and so it is not discussed further here.",
            "zh": "前一个标准是非常特定于领域的，因此这里不再进一步讨论。"
        }
    },
    {
        "translation": {
            "en": "A small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the professional basketball team dataset in Table 3.7[73], showing the result of range normalization and standardization.",
            "zh": "表3.7[73]中职业篮球队数据集的HEIGHT和SPONSORSHIP EARNS特征的一小部分样本，显示了范围标准化和标准化的结果。"
        }
    },
    {
        "translation": {
            "en": "This is partly because errors in the calculation of the posterior probabilities for the different target levels do not necessarily result in prediction errors.",
            "zh": "这在一定程度上是因为不同目标水平的后验概率计算误差不一定会导致预测误差。"
        }
    },
    {
        "translation": {
            "en": "sample, 541, 745, 750, 751",
            "zh": "样品， 541， 745， 750， 751"
        }
    },
    {
        "translation": {
            "en": "So, in an m-dimensional feature space, the cosine similarity between two instances a and b is defined as",
            "zh": "因此，在 m 维特征空间中，两个实例 a 和 b 之间的余弦相似度定义为"
        }
    },
    {
        "translation": {
            "en": "Capacity Requirements: Given that the insurance company already has a claims investigation team, the main requirements would be that a mechanism could be put in place to inform claims investigators that some claims were prioritized above others.",
            "zh": "能力要求：鉴于保险公司已经有一个索赔调查小组，主要要求是可以建立一种机制，告知索赔调查员某些索赔优先于其他索赔。"
        }
    },
    {
        "translation": {
            "en": "There are other statistics that we can use to measure central tendency that are not as sensitive to outliers.",
            "zh": "我们可以使用其他统计数据来衡量对异常值不那么敏感的中心趋势。"
        }
    },
    {
        "translation": {
            "en": "We find these Goldilocks models by using machine learning algorithms with appropriate inductive biases.",
            "zh": "我们通过使用具有适当归纳偏差的机器学习算法来找到这些金发姑娘模型。"
        }
    },
    {
        "translation": {
            "en": "The flow of activations through a long short-term memory unit during forward propagation when ct−1 = [0.3,0.6], ht = [0.1,0.8], and xt = [0.9].",
            "zh": "当 ct−1 = [0.3,0.6]、ht = [0.1,0.8] 和 xt = [0.9] 时，在正向传播过程中通过长短期记忆单元的激活流。"
        }
    },
    {
        "translation": {
            "en": "Finally, it can be shown that, under some assumptions, any learning algorithm that minimizes the squared error of the model over the data will output a maximum likelihood prediction.32 The relevance of this finding is that it provides a probabilistic justification for the approach to learning we present in Chapter 7[311].",
            "zh": "最后，可以证明，在某些假设下，任何最小化模型对数据的平方误差的学习算法都将输出最大似然预测.32这一发现的相关性在于，它为我们在第7章[311]中介绍的学习方法提供了概率论的合理性。"
        }
    },
    {
        "translation": {
            "en": "7.4.2 Setting the Learning Rate Using Weight Decay",
            "zh": "7.4.2 使用权重衰减设置学习率"
        }
    },
    {
        "translation": {
            "en": "3.4.1   Handling Missing Values",
            "zh": "3.4.1 处理缺失值"
        }
    },
    {
        "translation": {
            "en": "Instead, the exploding exploding gradients exhibited in Figure 8.24(d)[454] is caused by a similar process to the vanishing z values plotted in Figure 8.23(b)[453] and the exploding z values plotted in Figure 8.24(b)[454 the connection between these three processes is that they all involve a weighted sum.",
            "zh": "相反，图8.24（d）[454]中显示的爆炸爆炸梯度是由与图8.23（b）[453]中绘制的消失z值和图8.24（b）[454中绘制的爆炸z值相似的过程引起的，这三个过程之间的联系是它们都涉及加权和。"
        }
    },
    {
        "translation": {
            "en": "A commonly used alternative to representing a continuous feature using a probability density function is to convert the feature into a categorical feature using binning.",
            "zh": "使用概率密度函数表示连续特征的常用方法是使用分箱将特征转换为分类特征。"
        }
    },
    {
        "translation": {
            "en": "Finally, conifer refers to forested areas that contain a variety of tree species (including pine, cedar, and fir trees), with a mixture of shrubs on the forest floor.",
            "zh": "最后，针叶树是指包含各种树种（包括松树、雪松和冷杉）的森林地区，森林地面上混合了灌木。"
        }
    },
    {
        "translation": {
            "en": "We have already calculated the conditional probability of the event m given h directly from the dataset in Table B.2[760] as P(m | h) = 0.2857 (see Equation (B.3)[761]). We will now recalculate this probability using our rule-based definition of conditional probability. From our previous calculations, we already know that P(h) = 0.7 (see Equation (B.1)[760]) and P(m,h) = 0.2 (see Equation (B.2)[760]). So our calculation for P(m | h) is",
            "zh": "我们已经直接从表B.2[760]中的数据集中计算了事件m给定h的条件概率为P（m | h） = 0.2857（参见方程（B.3）[761]）。现在，我们将使用基于规则的条件概率定义重新计算此概率。从我们之前的计算中，我们已经知道 P（h） = 0.7（参见方程 （B.1）[760]）和 P（m，h） = 0.2（参见方程 （B.2）[760]）。所以我们对 P（m | h） 的计算是"
        }
    },
    {
        "translation": {
            "en": "The scores are 0.0139 for a prediction of true and 0.0245 for a prediction of false.",
            "zh": "预测为真时得分为 0.0139，预测为假时得分为 0.0245。"
        }
    },
    {
        "translation": {
            "en": "This is because the information we get from knowing that the patient has a headache is already contained within the information that the patient has meningitis.",
            "zh": "这是因为我们从知道患者头痛中获得的信息已经包含在患者患有脑膜炎的信息中。"
        }
    },
    {
        "translation": {
            "en": "This dataset has been used to build a decision tree to predict which customers will respond to future special offers. The decision tree, created using the ID3 algorithm, is the following:",
            "zh": "该数据集已用于构建决策树，以预测哪些客户将响应未来的特别优惠。使用 ID3 算法创建的决策树如下所示："
        }
    },
    {
        "translation": {
            "en": "The third segment lists the per neuron and per example softmax activations; these values are calculated by dividing the eli value in the corresponding cell in the second segment by the sum for that column ∑ieli.",
            "zh": "第三部分列出了每个神经元和每个示例的 softmax 激活;这些值的计算方法是将第二段中相应单元格中的 ELI 值除以该列的总和 ∑ieli。"
        }
    },
    {
        "translation": {
            "en": "This model tells us that for every increase of a square foot in SIZE, RENTAL PRICE increases by 0.62 Euro. We can also use this model to determine the expected rental price of the 730-square-foot office mentioned previously by simply plugging this value for SIZE into the model",
            "zh": "该模型告诉我们，面积每增加一平方英尺，租金价格就会增加 0.62 欧元。我们还可以使用此模型来确定前面提到的 730 平方英尺办公室的预期租金价格，只需将 SIZE 的这个值代入模型即可"
        }
    },
    {
        "translation": {
            "en": "(a) and (b) frequency histograms and (c) and (d) density histograms for the continuous TRAINING EXPENSES feature from Table A.1[750], illustrating how using intervals overcomes the problem seen in Figure A.6[753] and the effect of varying interval sizes.",
            "zh": "表A.1[750]中连续训练费用特征的（a）和（b）频率直方图以及（c）和（d）密度直方图，说明了使用间隔如何克服图A.6[753]中的问题以及不同间隔大小的影响。"
        }
    },
    {
        "translation": {
            "en": "It was encouraging that in many cases distinct distributions for each galaxy type were apparent in the histograms.",
            "zh": "令人鼓舞的是，在许多情况下，每种星系类型的不同分布在直方图中都很明显。"
        }
    },
    {
        "translation": {
            "en": "The target feature in this domain, DECISION, records the decision of whether the patient is sent to the icu or to a general ward (gen) for recovery.",
            "zh": "此域中的目标功能 DECISION 记录了患者是被送往 ICU 还是普通病房 （gen） 进行康复的决定。"
        }
    },
    {
        "translation": {
            "en": "The large values of the RENTAL PRICE feature, [320,620], cause the squared errors and, in turn, the error delta values to become very large.",
            "zh": "RENTAL PRICE 特征 [320,620] 的大值会导致平方误差，进而导致误差增量值变得非常大。"
        }
    },
    {
        "translation": {
            "en": "Table 5.7[208] also repeats the calculations from Table 5.6[206] using the normalized dataset and the normalized query instance.",
            "zh": "表 5.7[208] 还使用规范化数据集和规范化查询实例重复了表 5.6[206] 中的计算。"
        }
    },
    {
        "translation": {
            "en": "In the first part, she performed a performance test of the final model selected—the 3-level logistic regression model using the selected feature subset—on the large test dataset mentioned at the beginning of Section 13.4[719].",
            "zh": "在第一部分中，她对第 13.4 节开头提到的大型测试数据集执行了最终选择的模型（使用所选特征子集的 3 级逻辑回归模型）的性能测试[719]。"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that these models are part of an ensemble training using bagging, calculate the overall output of the ensemble for each instance in the test dataset.",
            "zh": "（a） 假设这些模型是使用袋装的集成训练的一部分，计算测试数据集中每个实例的集成的总输出。"
        }
    },
    {
        "translation": {
            "en": "Each customer’s average weekly spending with the chain, SPEND, and average number of visits per week to the chain, FREQ, are included along with the TYPE of customer: single, business, or family.",
            "zh": "每个客户在连锁店的平均每周支出、支出和每周对连锁店的平均访问次数 FREQ 与客户类型一起包括在内：单身、企业或家庭。"
        }
    },
    {
        "translation": {
            "en": "The errorDelta(,w[j]) for each weight is then the summation of the relevant column, for example, errorDelta(,w[0]) = 3,185.61 and errorDelta(,w[1]) = 2,412,073.90.",
            "zh": "每个权重的 errorDelta（，w[j]） 是相关列的总和，例如，errorDelta（，w[0]） = 3,185.61 和 errorDelta（，w[1]） = 2,412,073.90。"
        }
    },
    {
        "translation": {
            "en": "1.3 How Does Machine Learning Work?",
            "zh": "1.3 机器学习是如何工作的？"
        }
    },
    {
        "translation": {
            "en": "Case Study: Galaxy Classification",
            "zh": "案例研究：星系分类"
        }
    },
    {
        "translation": {
            "en": "The company’s entire customer base was divided randomly into two groups, the treatment group and the control group—and each group contained approximately 400,000 customers.",
            "zh": "该公司的整个客户群被随机分为两组，治疗组和对照组，每组包含大约 400,000 名客户。"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes prediction model returns the MAP prediction, so our naive Bayes model would make a prediction of false and so classify this loan application query as not fraudulent.",
            "zh": "朴素贝叶斯预测模型返回 MAP 预测，因此我们的朴素贝叶斯模型将做出错误的预测，从而将此贷款申请查询归类为非欺诈性查询。"
        }
    },
    {
        "translation": {
            "en": "We can illustrate how the AHC algorithm works using a reduced version of the mobile phone customer dataset from Table 10.1[604].",
            "zh": "我们可以使用表 10.1[604] 中移动电话客户数据集的简化版本来说明 AHC 算法的工作原理。"
        }
    },
    {
        "translation": {
            "en": "This illustrates how the class posterior probabilities can be simpler than the class conditional densities.",
            "zh": "这说明了类后验概率如何比类条件密度更简单。"
        }
    },
    {
        "translation": {
            "en": "The problem is even more serious than this, however, as in practice, it is almost never possible to collect a dataset that is big enough to sufficiently cover all the possible combinations of descriptive feature values that can occur in a dataset so as to avoid this.",
            "zh": "然而，问题比这更严重，因为在实践中，几乎不可能收集到足够大的数据集，以充分涵盖数据集中可能出现的所有描述性特征值组合，以避免这种情况。"
        }
    },
    {
        "translation": {
            "en": "The main additions in the second edition are the following:",
            "zh": "第二版的主要新增内容如下："
        }
    },
    {
        "translation": {
            "en": "The retention team could focus their retention efforts on these customers.",
            "zh": "保留团队可以将保留工作重点放在这些客户上。"
        }
    },
    {
        "translation": {
            "en": "This is in contrast to application-based solutions, in which the analyst can really achieve only what the tool developers had in mind when they designed the tool.",
            "zh": "这与基于应用程序的解决方案形成鲜明对比，在基于应用程序的解决方案中，分析师只能真正实现工具开发人员在设计工具时所考虑的内容。"
        }
    },
    {
        "translation": {
            "en": "The presence of large numbers of outliers can also be seen.",
            "zh": "还可以看到大量异常值的存在。"
        }
    },
    {
        "translation": {
            "en": "In selecting the appropriate model type to use, all these aspects, along with the structure of the data, should be taken into account.",
            "zh": "在选择要使用的适当模型类型时，应考虑所有这些方面以及数据的结构。"
        }
    },
    {
        "translation": {
            "en": "false negative, 537, 556",
            "zh": "假阴性， 537， 556"
        }
    },
    {
        "translation": {
            "en": "metric, 184, 211",
            "zh": "公制， 184， 211"
        }
    },
    {
        "translation": {
            "en": "overfitting, 14, 153, 157, 193, 256, 265, 432, 434, 472, 541",
            "zh": "过拟合， 14， 153， 157， 193， 256， 265， 432， 434， 472， 541"
        }
    },
    {
        "translation": {
            "en": "As such, support vector machines are often a good choice in complex domains with lots of data.",
            "zh": "因此，在具有大量数据的复杂领域中，支持向量机通常是一个不错的选择。"
        }
    },
    {
        "translation": {
            "en": "AGE: The customer’s age",
            "zh": "年龄：客户的年龄"
        }
    },
    {
        "translation": {
            "en": "HEALTHDEPSADULTS: How many dependent adults are included on the health insurance policy",
            "zh": "HEALTHDEPSADULTS：健康保险单中包括多少受抚养成年人"
        }
    },
    {
        "translation": {
            "en": "4.3   The different question sequences that can follow in a game of Guess Who beginning with the question Is it a man?",
            "zh": "4.3 猜猜谁游戏中可以遵循的不同问题序列，从问题开始 是男人吗？"
        }
    },
    {
        "translation": {
            "en": "0.2351",
            "zh": "0.2351"
        }
    },
    {
        "translation": {
            "en": "In Section 3.4[69] we introduced a number of techniques for handling missing values, and particular care should be taken to handle missing values if a nearest neighbor model is being used.",
            "zh": "在第 3.4 节[69]中，我们介绍了一些处理缺失值的技术，如果使用最近邻模型，则应特别注意处理缺失值。"
        }
    },
    {
        "translation": {
            "en": "A shorter time later than Mr. Murphy would have liked, Abigail skipped back in to her father to say that she was finished.",
            "zh": "比墨菲先生希望的要晚了一小段时间，阿比盖尔跳回她父亲那里，说她完蛋了。"
        }
    },
    {
        "translation": {
            "en": "We can write this action-value table update rule",
            "zh": "我们可以编写这个操作值表更新规则"
        }
    },
    {
        "translation": {
            "en": "Transparency International, 237",
            "zh": "透明国际，237"
        }
    },
    {
        "translation": {
            "en": "An important decision to be made in designing any recursive process is what the base cases that stop the recursion will be.",
            "zh": "在设计任何递归过程时，要做出的一个重要决定是停止递归的基本情况是什么。"
        }
    },
    {
        "translation": {
            "en": "leaf nodes, 121",
            "zh": "叶节点，121"
        }
    },
    {
        "translation": {
            "en": "Cleary, Duncan, and Revenue Irish Tax. 2011. Predictive analytics in the public sector: Using data mining to assist better target selection for audit. In The proceedings of the 11th European conference on egovernment: Faculty of administration, University of Ljubljana, Ljubljana, Slovenia, 16–17 June 2011, 168. Academic Conferences Limited.",
            "zh": "Cleary、Duncan 和爱尔兰税务局。2011. 公共部门的预测分析：使用数据挖掘来帮助更好地选择审计目标。第11届欧洲电子政务会议论文集：卢布尔雅那大学行政学院，斯洛文尼亚卢布尔雅那，2011年6月16-17日，第168页。学术会议有限公司。"
        }
    },
    {
        "translation": {
            "en": "binary tree, 196",
            "zh": "二叉树，196"
        }
    },
    {
        "translation": {
            "en": "Extracting the action with the highest Q value in each state from the action-value table gives the greedy target policy that the agent, now trained to complete the task, would use after deployment.",
            "zh": "从 action-value 表中提取每个状态中 Q 值最高的操作，可提供代理（现已训练完成任务）在部署后将使用的贪婪目标策略。"
        }
    },
    {
        "translation": {
            "en": "For a more general textbook on natural language processing, we recommend Jurafsky and Martin (2008).",
            "zh": "对于自然语言处理的更通用的教科书，我们推荐Jurafsky and Martin （2008）。"
        }
    },
    {
        "translation": {
            "en": "His next task was to add much more depth to this understanding, following the process described in Section 2.3[28].",
            "zh": "他的下一个任务是按照第2.3节[28]中描述的过程，为这种理解增加更多的深度。"
        }
    },
    {
        "translation": {
            "en": "26. A hypercube is a generalization of the geometric concept of a cube across multiple dimensions. Hence in a two-dimensional space, the term hypercube denotes a square; in three-dimensional space, it denotes a cube; and so on. A unit hypercube is a hypercube in which the length of every side is 1 unit.",
            "zh": "26. 超立方体是立方体几何概念在多个维度上的概括。因此，在二维空间中，术语超立方体表示正方形;在三维空间中，它表示一个立方体;等等。单位超立方体是每边长度为 1 个单位的超立方体。"
        }
    },
    {
        "translation": {
            "en": "misclassification rate, 179, 533, 536, 539, 540, 549, 551",
            "zh": "误分类率，179、533、536、539、540、549、551"
        }
    },
    {
        "translation": {
            "en": "Tufte, Edward R. 2001. The visual display of quantitative information. Graphics Press.",
            "zh": "塔夫特，爱德华 R. 2001 年。定量信息的可视化显示。图形出版社。"
        }
    },
    {
        "translation": {
            "en": "The fact that the most informative features occupy berths toward the top of a tree means that stunted trees usually capture the most important information.",
            "zh": "事实上，信息量最大的特征占据了树顶的泊位，这意味着发育不良的树木通常会捕获最重要的信息。"
        }
    },
    {
        "translation": {
            "en": "Finally, Chapter 14[729] provides some overarching perspectives on machine learning for predictive data analytics and summarizes some of the key differences between the different approaches covered in this book.",
            "zh": "最后，第14章[729]提供了一些关于机器学习用于预测数据分析的总体观点，并总结了本书中涵盖的不同方法之间的一些关键区别。"
        }
    },
    {
        "translation": {
            "en": "0.2115",
            "zh": "0.2115"
        }
    },
    {
        "translation": {
            "en": "This summation gives us the Δwi,k term in Equation (8.30)[416].",
            "zh": "这个求和给出了方程（8.30）[416]中的Δwi，k项。"
        }
    },
    {
        "translation": {
            "en": "The columns identified as being most predictive of galaxy morphology were EXPRAD_G (0.3908), EXPRAD_R (0.3649), DEVRAD_G (0.3607), EXPRAD_I (0.3509), DEVRAD_R (0.3467), EXPRAD_Z (0.3457), and MRRCC_G (0.3365).",
            "zh": "被确定为最能预测星系形态的列是EXPRAD_G（0.3908）、EXPRAD_R（0.3649）、DEVRAD_G（0.3607）、EXPRAD_I（0.3509）、DEVRAD_R（0.3467）、EXPRAD_Z（0.3457）和MRRCC_G（0.3365）。"
        }
    },
    {
        "translation": {
            "en": "units, 386",
            "zh": "单位， 386"
        }
    },
    {
        "translation": {
            "en": "A more common phenomenon is that two or more events may be independent if we know that a third event has happened.",
            "zh": "一个更常见的现象是，如果我们知道发生了第三个事件，那么两个或多个事件可能是独立的。"
        }
    },
    {
        "translation": {
            "en": "The robustness of the student-t to outliers is another reason to consider using this distribution, as opposed to a normal distribution, to model unimodal data in situations with relatively small or possibly noisy datasets.",
            "zh": "student-t 对异常值的鲁棒性是考虑使用此分布（而不是正态分布）在数据集相对较小或可能嘈杂的情况下对单峰数据进行建模的另一个原因。"
        }
    },
    {
        "translation": {
            "en": "This means that we can expect the predictions made by the regression model to be 1.38mg out on average, whereas those made by the nearest neighbor model will be, on average, 2.096mg out.",
            "zh": "这意味着我们可以预期回归模型做出的预测平均为 1.38 毫克，而最近邻模型做出的预测平均为 2.096 毫克。"
        }
    },
    {
        "translation": {
            "en": "All the other input values are ignored because they are given a weight of 0.",
            "zh": "所有其他输入值都将被忽略，因为它们的权重为 0。"
        }
    },
    {
        "translation": {
            "en": "Both these new partitions are pure sets with respect to the target feature (indeed, they contain only one instance each), and consequently these sets do not need to be split any further and can be converted into leaf nodes.",
            "zh": "这两个新分区都是相对于目标功能的纯集（实际上，它们每个只包含一个实例），因此这些集不需要进一步拆分，可以转换为叶节点。"
        }
    },
    {
        "translation": {
            "en": "This time we will predict the expected rental demand on the basis of a single descriptive feature, the forecasted temperature for a day.",
            "zh": "这一次，我们将根据一个描述性特征，即一天的预测温度来预测预期的租赁需求。"
        }
    },
    {
        "translation": {
            "en": "B.1   A dataset of instances from the sample space in Figure B.1[757].",
            "zh": "B.1 图B.1[757]中样本空间中的实例数据集。"
        }
    },
    {
        "translation": {
            "en": "In this scenario it is interesting to take a perspective on the similarity between customers that focuses on the mix of these two types of services they use, rather than the volumes of the services they use.",
            "zh": "在此方案中，有趣的是，从客户之间的相似性的角度来看，重点关注他们使用的这两种类型的服务的组合，而不是他们使用的服务量。"
        }
    },
    {
        "translation": {
            "en": "We are now ready to process a query that has the continuous LOAN AMOUNT feature as part of the evidence:",
            "zh": "现在，我们已准备好处理一个查询，该查询具有连续贷款金额特征作为证据的一部分："
        }
    },
    {
        "translation": {
            "en": "tired",
            "zh": "累"
        }
    },
    {
        "translation": {
            "en": "thinking hard about the best ways to represent features;",
            "zh": "认真思考表示特征的最佳方式;"
        }
    },
    {
        "translation": {
            "en": "Table 6.6",
            "zh": "表 6.6"
        }
    },
    {
        "translation": {
            "en": "Although this example is small, the same approach can be used effectively for large multivariate datasets, with the only difference being a need to examine summary statistics and visualizations for many more features.",
            "zh": "尽管此示例很小，但相同的方法可以有效地用于大型多变量数据集，唯一的区别是需要检查更多特征的汇总统计和可视化。"
        }
    },
    {
        "translation": {
            "en": "Policies rely on being able to assess the expected return of taking an action in a particular state, and an action-value function is used to calculate this.",
            "zh": "策略依赖于能够评估在特定状态下采取行动的预期回报，并使用操作值函数来计算此回报。"
        }
    },
    {
        "translation": {
            "en": "7.4.1   Interpreting Multivariable Linear Regression Models",
            "zh": "7.4.1 解释多变量线性回归模型"
        }
    },
    {
        "translation": {
            "en": "Over the last four chapters, we have discussed a range of approaches to building machine learning models that make various kinds of predictions. The question that we must answer in the Evaluation phase of the CRISP-DM process (recall Section 1.6[15]) is Can the model generated do the job that it has been built for? The purpose of evaluation is threefold:",
            "zh": "在过去的四章中，我们讨论了构建机器学习模型的一系列方法，这些模型可以进行各种预测。在CRISP-DM过程的评估阶段（回想一下第1.6节[15]），我们必须回答的问题是：生成的模型能否完成其构建的工作？评估的目的有三个："
        }
    },
    {
        "translation": {
            "en": "scatter plot, 73, 183",
            "zh": "散点图，73,183"
        }
    },
    {
        "translation": {
            "en": "To calculate these thresholds, we take the midpoint in the feature range between the instance with the highest feature value in one bin and the feature with the lowest feature value in the next bin.",
            "zh": "为了计算这些阈值，我们取一个 bin 中特征值最高的实例和下一个 bin 中特征值最低的特征之间的特征范围的中点。"
        }
    },
    {
        "translation": {
            "en": "2. The following image shows an artificial neural network with two sensing neurons (Neurons 1 and 2) and 3 processing neurons (Neurons 3, 4, and 5)",
            "zh": "2. 下图显示了一个人工神经网络，其中包含两个传感神经元（神经元 1 和 2）和 3 个处理神经元（神经元 3、4 和 5）"
        }
    },
    {
        "translation": {
            "en": "We also need to calculate the likelihood of the descriptive feature values of the query given that the target is true. We could calculate this directly from the dataset, but in this example, we will illustrate the chain rule approach just described. Using the chain rule approach, we compute the overall likelihood of the descriptive feature values given a target value of true as the product of a set of conditional probabilities that are themselves calculated from the dataset",
            "zh": "我们还需要计算查询的描述性特征值的可能性，前提是目标为真。我们可以直接从数据集中计算出来，但在这个例子中，我们将说明刚才描述的链式规则方法。使用链式规则方法，我们计算给定目标值为true的描述性特征值的总体可能性，作为一组条件概率的乘积，这些条件概率本身是从数据集计算得出的"
        }
    },
    {
        "translation": {
            "en": "Figure 4.7(b)[128] shows how the UNKNOWN SENDER feature partitions the dataset.",
            "zh": "图 4.7（b）[128] 显示了 UNKNOWN SENDER 特征如何对数据集进行分区。"
        }
    },
    {
        "translation": {
            "en": "INFANTMORTALITY: The infant mortality rate (per 1,000 live births)",
            "zh": "婴儿死亡率：婴儿死亡率（每1000名活产婴儿）"
        }
    },
    {
        "translation": {
            "en": "The a(i), b(i), and s(i) values in Table 10.2[611] are calculated similarly for each other instance, and the overall silhouette for the clustering is the average of these values, in this case, 0.656. This suggests a reasonably good clustering.",
            "zh": "表 10.2[611] 中的 a（i）、b（i） 和 s（i） 值的计算方式类似，聚类的总体轮廓是这些值的平均值，在本例中为 0.656。这表明了一个相当好的聚类。"
        }
    },
    {
        "translation": {
            "en": "Pearson correlation, 82, 223",
            "zh": "皮尔逊相关性，82,223"
        }
    },
    {
        "translation": {
            "en": "8. See Section 4.4.4[153].",
            "zh": "8. 参见第 4.4.4 节[153]。"
        }
    },
    {
        "translation": {
            "en": "However, the rate of error reduction after each weight update will also decrease.",
            "zh": "但是，每次权重更新后的错误减少率也会降低。"
        }
    },
    {
        "translation": {
            "en": "In two out of these three rows (d8 and d10), h is the case, so the conditional probability P(h | m) = 0.6666.",
            "zh": "在这三行中的两行（d8 和 d10）中，h 是这种情况，因此条件概率 P（h | m） = 0.6666。"
        }
    },
    {
        "translation": {
            "en": "(c) What will be the value of ct if",
            "zh": "（c） 如果 ct 的值是多少"
        }
    },
    {
        "translation": {
            "en": "AGE, a continuous feature listing the age of the individual;",
            "zh": "年龄，列出个人年龄的连续特征;"
        }
    },
    {
        "translation": {
            "en": "In this book we have presented some of the most commonly used prediction models and the machine learning algorithms used to build them.",
            "zh": "在本书中，我们介绍了一些最常用的预测模型以及用于构建它们的机器学习算法。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.1 presents a schematic of the structure of a neuron that illustrates how the neuron’s cell body, dendrites, and axon are interconnected and how one neuron connects to other neurons in the brain.",
            "zh": "图 8.1 显示了神经元结构的示意图，说明了神经元的细胞体、树突和轴突如何相互连接，以及一个神经元如何连接到大脑中的其他神经元。"
        }
    },
    {
        "translation": {
            "en": "The second is the linkage method, ℒ, that will be used to allow distances between whole clusters rather than just single instances to be compared.",
            "zh": "第二种是链接方法 L，它将用于比较整个集群之间的距离，而不仅仅是单个实例。"
        }
    },
    {
        "translation": {
            "en": "This results in four candidate thresholds: ≥750, ≥1,350, ≥2,250, and ≥4,175.",
            "zh": "这会产生四个候选阈值：≥750、≥1,350、≥2,250 和 ≥4,175。"
        }
    },
    {
        "translation": {
            "en": "Leaky ReLUs always activate to some extent for every input; however, given that for z ≤ 0 the derivative of the rectifierleaky function is very small (0.01), a leaky ReLU with large negative weight will still learn very slowly.",
            "zh": "对于每个输入，泄漏的 ReLU 总是在某种程度上激活;然而，鉴于 z ≤ 0 整流器泄漏函数的导数非常小 （0.01），具有大负权重的泄漏 ReLU 仍然会学习得很慢。"
        }
    },
    {
        "translation": {
            "en": "Human Activity Recognition Using Smartphones Dataset, 636",
            "zh": "使用智能手机的人类活动识别数据集，636"
        }
    },
    {
        "translation": {
            "en": "stochastic gradient descent, 327, 415",
            "zh": "随机梯度下降， 327， 415"
        }
    },
    {
        "translation": {
            "en": "TP, 537",
            "zh": "TP， 537"
        }
    },
    {
        "translation": {
            "en": "This means that each of the neurons in the output layer is equivalent to the McCulloch and Pitts neuron described in Section 8.2.1[384].",
            "zh": "这意味着输出层中的每个神经元都等同于第 8.2.1 节中描述的 McCulloch 和 Pitts 神经元[384]。"
        }
    },
    {
        "translation": {
            "en": "(b) Yet another colleague has suggested that the ID feature would be a very effective at the root node of the tree. Would you agree with this suggestion?",
            "zh": "（b） 另一位同事建议，ID功能在树的根节点上将非常有效。你同意这个建议吗？"
        }
    },
    {
        "translation": {
            "en": "To plot an ROC curve, we create a chart with true positive rate on the vertical access and false positive rate (or 1 − true negative rate) on the horizontal axis.14 The values for these measures, when any threshold value is used on a collection of score predictions, gives a point on this plot, or a point in receiver operating characteristic space (ROC space).",
            "zh": "为了绘制 ROC 曲线，我们创建了一个图表，在垂直访问上具有真阳性率，在水平轴上具有假阳性率（或 1 − 真阴性率）.14 当任何阈值用于分数预测的集合时，这些度量的值在此图上给出了一个点，或在接收器工作特征空间（ROC 空间）中给出了一个点。"
        }
    },
    {
        "translation": {
            "en": "margin extents, 361, 364",
            "zh": "边距范围， 361， 364"
        }
    },
    {
        "translation": {
            "en": "We say that the naive Bayes model is naive because the assumption of conditional independence between the features in the evidence given the target level is a simplifying assumption that is made whether or not it is incorrect.",
            "zh": "我们说朴素贝叶斯模型是朴素的，因为给定目标水平的证据中特征之间的条件独立性假设是一个简化的假设，无论它是否不正确，都会做出这种假设。"
        }
    },
    {
        "translation": {
            "en": "Given these two pieces of information, we can compute the relative likelihood of a particular instance having a particular target level as",
            "zh": "给定这两条信息，我们可以计算出特定实例具有特定目标水平的相对可能性为"
        }
    },
    {
        "translation": {
            "en": "Jaccard similarity measure, 635",
            "zh": "Jaccard相似度量，635"
        }
    },
    {
        "translation": {
            "en": "bootstrap aggregating, 159",
            "zh": "引导聚合，159"
        }
    },
    {
        "translation": {
            "en": "Technically, the derivative of the rectifier function is undefined when zk = 0, so strictly, the rectifier function is not an appropriate choice for gradient descent and backpropagation, which assume differentiable functions. However, a common practice in neural networks is to choose a derivative value for zk = 0 of zero, and we have integrated this convention into the definition of Equation (8.43)[437]. This convention has been found generally to work well.",
            "zh": "从技术上讲，当 zk = 0 时，整流器函数的导数是未定义的，因此严格来说，整流器函数不是梯度下降和反向传播的合适选择，梯度下降和反向传播假设可微函数。然而，神经网络中的一种常见做法是为 zk = 0 的零选择一个导数值，我们已将此约定集成到方程 （8.43）[437] 的定义中。人们普遍认为，这一惯例运作良好。"
        }
    },
    {
        "translation": {
            "en": "Subjects: LCSH: Machine learning. | Data mining. | Prediction theory.",
            "zh": "主题：LCSH：机器学习。|数据挖掘。|预测理论。"
        }
    },
    {
        "translation": {
            "en": "Moreover, reinforcement learning agents can often find exceptional solutions to problems that a human operator would not be aware of.",
            "zh": "此外，强化学习代理通常可以为人类操作员无法意识到的问题找到特殊的解决方案。"
        }
    },
    {
        "translation": {
            "en": "This covers a deep theoretical framing of the reinforcement learning problem, as well as a collection of approaches including dynamic programming, Monte Carlo methods, temporal-difference learning, and other extensions.",
            "zh": "这涵盖了强化学习问题的深入理论框架，以及一系列方法，包括动态规划、蒙特卡罗方法、时差学习和其他扩展。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the entropy for this dataset.",
            "zh": "（a） 计算该数据集的熵。"
        }
    },
    {
        "translation": {
            "en": "Bertsekas, Dimitri. 2017. Dynamic programming and optimal control. Athena Scientific.",
            "zh": "贝尔塞卡斯，迪米特里。2017. 动态规划与优化控制.雅典娜科学。"
        }
    },
    {
        "translation": {
            "en": "F measure, 549",
            "zh": "F 测量，549"
        }
    },
    {
        "translation": {
            "en": "Given that the vanishing gradients exhibited in Figure 8.23(d)[453] are partly caused by the repeated multiplication by small weights, we can try to avoid this problem by making the network weights larger.",
            "zh": "鉴于图8.23（d）[453]中显示的梯度消失部分是由小权重的重复乘法引起的，我们可以尝试通过使网络权重更大来避免这个问题。"
        }
    },
    {
        "translation": {
            "en": "Flags: Flags are binary features that indicate the presence or absence of some characteristic within a dataset. For example, a flag indicating whether or not a bank account has ever been overdrawn might be a useful descriptive feature.",
            "zh": "标志：标志是二进制特征，用于指示数据集中是否存在某些特征。例如，指示银行账户是否曾经透支的标志可能是一个有用的描述性功能。"
        }
    },
    {
        "translation": {
            "en": "For each of the data quality issues found, we include the feature it was found in and the details of the data quality issue.",
            "zh": "对于发现的每个数据质量问题，我们都会包括发现它的功能以及数据质量问题的详细信息。"
        }
    },
    {
        "translation": {
            "en": "The forward computational flow through the LSTM input gates include an elementwise addition of two activation vectors.",
            "zh": "通过 LSTM 输入门的前向计算流程包括两个激活向量的元素相加。"
        }
    },
    {
        "translation": {
            "en": "For example, in a domain with one target feature and nine descriptive features, all of which are binary, the full joint probability distribution will contain 210 = 1,024 probabilities.",
            "zh": "例如，在具有一个目标特征和九个描述性特征（所有特征都是二进制的）的域中，完整的联合概率分布将包含 210 = 1,024 个概率。"
        }
    },
    {
        "translation": {
            "en": "document classification, 4, 223",
            "zh": "文件分类， 4， 223"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11(b)[561] shows three such points in ROC space and associated confusion matrices for the email classification dataset for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "图 9.11（b）[561] 显示了 ROC 空间中的三个此类点以及阈值为 0.25、0.5 和 0.75 的电子邮件分类数据集的相关混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Table 7.7[347] shows an extended version of the generators dataset given in Table 7.6[339], including extra instances that make the separation between good generators and faulty generators less clear cut.",
            "zh": "表 7.7[347] 显示了表 7.6[339] 中给出的发电机数据集的扩展版本，包括使良好发电机和故障发电机之间区分不太清晰的额外实例。"
        }
    },
    {
        "translation": {
            "en": "This case study2 describes the work undertaken when, in 2011, the SDSS hired Jocelyn, an analytics professional, to build a galaxy morphology classification model to include in their data processing pipeline. The remainder of this chapter describes the work undertaken by Jocelyn on this project within each phase of the CRISP-DM process.",
            "zh": "本案例研究2描述了2011年SDSS聘请分析专家Jocelyn构建星系形态分类模型以纳入其数据处理管道时所做的工作。本章的其余部分描述了 Jocelyn 在 CRISP-DM 流程的每个阶段对该项目所做的工作。"
        }
    },
    {
        "translation": {
            "en": "2. Remember, we refer to each value that a particular categorical feature can take as the levels of the categorical feature.",
            "zh": "2. 请记住，我们将特定分类特征可以采用的每个值称为分类特征的级别。"
        }
    },
    {
        "translation": {
            "en": "(f) The final ensemble model trained after 20 iterations of gradient boosting.",
            "zh": "（f） 经过 20 次梯度提升迭代后训练的最终集成模型。"
        }
    },
    {
        "translation": {
            "en": "Table 4.15",
            "zh": "表 4.15"
        }
    },
    {
        "translation": {
            "en": "There is some argument in the reinforcement learning literature about whether the reward that follows an action, at, taken in a state, st, should be referred to as rt or rt+1.",
            "zh": "在强化学习文献中，关于在状态 st 中采取的动作之后的奖励是否应该称为 rt 或 rt+1，存在一些争论。"
        }
    },
    {
        "translation": {
            "en": "The calculation of ∂ℰ/∂ak for output neurons is dependent on the error function9 that is used during training. We have already introduced the sum of squared errors, or L2, error function (see Equation 7.4[316]), repeated here for convenience",
            "zh": "输出神经元的 ∂E/∂ak 计算取决于训练期间使用的误差函数9。我们已经介绍了误差的平方和，或L2，误差函数（参见公式7.4[316]），为了方便起见，这里重复了一遍"
        }
    },
    {
        "translation": {
            "en": "text analytics, 262",
            "zh": "文本分析，262"
        }
    },
    {
        "translation": {
            "en": "The fact that we have emphasized feature selection in this chapter does not mean that it is not important to predictive analytics in general.",
            "zh": "我们在本章中强调特征选择这一事实并不意味着它对一般的预测分析不重要。"
        }
    },
    {
        "translation": {
            "en": "In this case good is the positive level and set to + 1, and faulty is the negative level and set to − 1.",
            "zh": "在本例中，good 是正电平，设置为 + 1，faulty 是负电平，设置为 − 1。"
        }
    },
    {
        "translation": {
            "en": "At the time Literary Digest was a well-known magazine that had accurately predicted the outcomes of previous presidential elections.",
            "zh": "当时，《文学文摘》是一本著名的杂志，它准确地预测了历届总统选举的结果。"
        }
    },
    {
        "translation": {
            "en": "The forward pass of the examples listed in Table 8.3[423] through the network in Figure 8.4[390] when all the neurons are ReLUs.",
            "zh": "当所有神经元都是 ReLU 时，表 8.3[423] 中列出的示例通过图 8.4[390] 中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "Once a company has been registered, it must provide a tax return at the end of every financial year.",
            "zh": "公司注册后，必须在每个财政年度结束时提供纳税申报表。"
        }
    },
    {
        "translation": {
            "en": "A burn-in of 30 iterations was used, and the samples were thinned by sub-sampling every 7th iteration.",
            "zh": "使用了 30 次迭代的老化，并且每 7 次迭代通过子采样来稀释样本。"
        }
    },
    {
        "translation": {
            "en": "The middle plot shows a similar plot for the OR function, and again it is possible to draw a single straight line to separate the two classes of inputs.",
            "zh": "中间的图显示了OR函数的类似图，同样可以画一条直线来分隔两类输入。"
        }
    },
    {
        "translation": {
            "en": "This assignment of blame back to the neurons connecting into a neuron is dependent on the weight on the connection between the neurons and also on the activation of the hidden neuron during the forward pass.",
            "zh": "这种将责任归咎于连接到神经元的神经元的分配取决于神经元之间连接的权重，也取决于前向传递过程中隐藏神经元的激活。"
        }
    },
    {
        "translation": {
            "en": "where cov(a,b) is the covariance between features a and b and sd(a) and sd(b) are the standard deviations of a and b respectively.",
            "zh": "其中 Cov（a，b） 是特征 A 和 B 之间的协方差，SD（A） 和 SD（B） 分别是 A 和 B 的标准差。"
        }
    },
    {
        "translation": {
            "en": "The weights in this network have been initialized so that all the bias terms are equal to + 1.0 and the other weights are listed in the weight matrices shown in Figure 8.28[470].",
            "zh": "该网络中的权重已经初始化，因此所有偏差项都等于 + 1.0，其他权重列在图 8.28[470] 所示的权重矩阵中。"
        }
    },
    {
        "translation": {
            "en": "There is, however, a simple approach to learning weights that we can take based on the facts that, even though they are hard to visualize, the error surfaces that correspond to these high-dimensional weight spaces still have the convex shape seen in Figure 7.3[318] (albeit in multiple dimensions), and that a single global minimum exists. This approach uses a guided search from a random starting position and is known as gradient descent.",
            "zh": "然而，有一种简单的方法来学习权重，我们可以基于以下事实：即使它们很难可视化，与这些高维权重空间相对应的误差曲面仍然具有图7.3[318]所示的凸形（尽管是多维的），并且存在单个全局最小值。这种方法使用从随机起始位置的引导式搜索，称为梯度下降。"
        }
    },
    {
        "translation": {
            "en": "The differences in central tendency and variation between levels can, however, be easier to see in box plots.",
            "zh": "然而，在箱形图中更容易看到中心趋势和水平之间变化的差异。"
        }
    },
    {
        "translation": {
            "en": "Adding this padding to the image increases the number of neurons required to cover the image, assuming that the filter size and horizontal and vertical strides are maintained.",
            "zh": "在图像中添加此填充会增加覆盖图像所需的神经元数量，前提是保持滤镜大小以及水平和垂直步幅。"
        }
    },
    {
        "translation": {
            "en": "Technically, this property is described as the model being equivariant to the translation of features.",
            "zh": "从技术上讲，此属性被描述为模型与特征的平移等变。"
        }
    },
    {
        "translation": {
            "en": "The (a) gain and (b) cumulative gain at each decile for the email predictions given in Table 9.11[557].",
            "zh": "表9.11[557]中给出的电子邮件预测在每个十分位数处的（a）增益和（b）累积增益。"
        }
    },
    {
        "translation": {
            "en": "true negative rate, 548, 558",
            "zh": "真阴性率，548,558"
        }
    },
    {
        "translation": {
            "en": "6.2 Fundamentals",
            "zh": "6.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "Similar to k-fold cross validation, the ε0 bootstrap iteratively performs multiple evaluation experiments using sightly different training and test sets each time to evaluate the expected performance of a model.",
            "zh": "与 k 倍交叉验证类似，ε0 引导程序每次都使用截然不同的训练和测试集迭代执行多个评估实验，以评估模型的预期性能。"
        }
    },
    {
        "translation": {
            "en": "Based on Table B.1[758], the probability of the event DICE1 = is1",
            "zh": "根据表 B.1[758]，事件 DICE1 = 的概率为 1"
        }
    },
    {
        "translation": {
            "en": "For example, we can use information gain30 as a filter in a rank and prune approach.",
            "zh": "例如，我们可以在排名和修剪方法中使用信息增益30作为过滤器。"
        }
    },
    {
        "translation": {
            "en": "Machine learning models are being used for a more diverse range of applications than ever before, and new developments in machine learning methods are opening up even more opportunities.",
            "zh": "机器学习模型被用于比以往任何时候都更多样化的应用，机器学习方法的新发展正在开辟更多的机会。"
        }
    },
    {
        "translation": {
            "en": "In this figure each rectangle represents a state in the search space that is a particular feature subset.",
            "zh": "在此图中，每个矩形表示搜索空间中的一个状态，该状态是特定功能子集。"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder can be trained to learn a more compact representation of these images.",
            "zh": "可以训练自动编码器来学习这些图像的更紧凑的表示。"
        }
    },
    {
        "translation": {
            "en": "AUC, 561",
            "zh": "AUC，561"
        }
    },
    {
        "translation": {
            "en": "Part III covers fundamental techniques in machine learning beyond the supervised machine learning approaches described in Part II. Chapter 10 describes unsupervised machine learning, and Chapter 11 describes reinforcement learning. These chapters follow the same two-part structure as the chapters in Part II.",
            "zh": "第三部分涵盖了机器学习的基本技术，超出了第二部分中描述的监督机器学习方法。第 10 章介绍了无监督机器学习，第 11 章介绍了强化学习。这些章节遵循与第二部分章节相同的两部分结构。"
        }
    },
    {
        "translation": {
            "en": "where π(st+1,at+1) returns the likelihood of taking action at+1 from state st+1 under policy π, and Qπ(st+1,at+1) is a recursive call to the action-value function itself.",
            "zh": "其中 π（st+1，at+1） 返回策略 π 下状态 st+1 在 at+1 上采取行动的可能性，Qπ（st+1，at+1） 是对动作值函数本身的递归调用。"
        }
    },
    {
        "translation": {
            "en": "27. The data in this question has been artificially created but is inspired by the famous Wisconsin breast cancer dataset first described in Mangasarian and Wolberg (1990) and is available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "27. 本问题中的数据是人工创建的，但灵感来自著名的威斯康星州乳腺癌数据集，该数据集首次在 Mangasarian 和 Wolberg （1990） 中描述，可从 UCI 机器学习存储库（Bache 和 Lichman，2013 年）获得。"
        }
    },
    {
        "translation": {
            "en": "stunted trees, 701",
            "zh": "发育不良的树木，701"
        }
    },
    {
        "translation": {
            "en": "At this point the retrieval process will have executed Lines 1–7 of the algorithm.",
            "zh": "此时，检索过程将执行算法的第 1-7 行。"
        }
    },
    {
        "translation": {
            "en": "PEAKRATIOCHANGEPCT",
            "zh": "峰值比率变化PCT"
        }
    },
    {
        "translation": {
            "en": "Returning to our loan application fraud detection example, we will show how binning can be used to include the LOAN AMOUNT feature (see Table 6.11[278]) in a naive Bayes prediction model for this scenario.",
            "zh": "回到我们的贷款申请欺诈检测示例，我们将展示如何使用分箱来包含此场景的朴素贝叶斯预测模型中的 LOAN AMOUNT 特征（参见表 6.11[278]）。"
        }
    },
    {
        "translation": {
            "en": "If this approach were to be used for the AMOUNT RECEIVED feature from the motor claims insurance fraud detection scenario, then the upper and lower thresholds would be defined as follows:",
            "zh": "如果将此方法用于汽车索赔保险欺诈检测方案中的“收到金额”特征，则上限和下限阈值将定义如下："
        }
    },
    {
        "translation": {
            "en": "3.5.1.1 Visualizing pairs of continuous features The scatter plot is one of the most important tools in data visualization.",
            "zh": "3.5.1.1 连续特征对的可视化 散点图是数据可视化中最重要的工具之一。"
        }
    },
    {
        "translation": {
            "en": "To summarize, although the inclusion of a non-linear activation function within neurons in a network enables the network to represent non-linear mappings from inputs to outputs, the selection of which non-linear function we use can have a significant effect on the training speed of a deep network.",
            "zh": "总而言之，尽管在网络中的神经元中包含非线性激活函数使网络能够表示从输入到输出的非线性映射，但我们选择使用哪种非线性函数会对深度网络的训练速度产生重大影响。"
        }
    },
    {
        "translation": {
            "en": "The task of the output gate is to decide which parts of the ct should be passed to the output layer of the network and on to the next time-step as the propagated hidden state.",
            "zh": "输出门的任务是决定 ct 的哪些部分应该传递到网络的输出层，并作为传播的隐藏状态传递到下一个时间步长。"
        }
    },
    {
        "translation": {
            "en": "machine learning algorithm, 6, 19",
            "zh": "机器学习算法， 6， 19"
        }
    },
    {
        "translation": {
            "en": "inductive bias, 11, 11, 19, 22, 123, 141, 328, 357, 362, 729, 736",
            "zh": "电感偏置， 11， 11， 19， 22， 123， 141， 328， 357， 362， 729， 736"
        }
    },
    {
        "translation": {
            "en": "iteration, 416",
            "zh": "迭代，416"
        }
    },
    {
        "translation": {
            "en": "Each row in a dataset represents an experiment, which associates a target feature value with a set of descriptive feature values, and the assignment of a set of descriptive features with values is an event.",
            "zh": "数据集中的每一行都表示一个实验，该实验将目标要素值与一组描述性要素值相关联，并且将一组描述性要素与值的赋值是一个事件。"
        }
    },
    {
        "translation": {
            "en": "Table 1.5",
            "zh": "表 1.5"
        }
    },
    {
        "translation": {
            "en": "The reason why keeping the behavior of a network across its layers similar is useful in creating deep networks is that it allows us to add more layers to the network.",
            "zh": "在创建深度网络时，保持网络各层行为相似的原因是，它允许我们向网络添加更多层。"
        }
    },
    {
        "translation": {
            "en": "Each link in this chain of products is the rate of change of the output of a function (loss function, activation function, or weighted sum function) with respect to one of its inputs. Working from a network weight wi,k forward toward the network error, we have",
            "zh": "该乘积链中的每个环节都是函数输出（损失函数、激活函数或加权和函数）相对于其输入之一的变化率。从网络权重 wi，k 向前向网络错误工作，我们有"
        }
    },
    {
        "translation": {
            "en": "The zig-zagging line in Figure 7.24(a)[368] shows an example journey across an error surface, and Figure 7.24(b)[368] shows the reduction in the sum of squared errors as the search for the optimal weights progresses down the error surface.",
            "zh": "图7.24（a）[368]中的锯齿形线显示了穿越误差表面的示例旅程，图7.24（b）[368]显示了随着误差表面对最佳权重的搜索，平方误差总和的减少。"
        }
    },
    {
        "translation": {
            "en": "A.1.1 Central Tendency",
            "zh": "A.1.1 集中趋势"
        }
    },
    {
        "translation": {
            "en": "This figure contains 16 subfigures, with each subfigure containing a matrix of input data (on the left) representing the input image and a grid of 16 circles (on the right) in which each circle represents a neuron.",
            "zh": "该图包含 16 个子图，每个子图包含一个输入数据矩阵（左侧）代表输入图像和一个由 16 个圆圈（右侧）组成的网格，其中每个圆圈代表一个神经元。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.12",
            "zh": "图 7.12"
        }
    },
    {
        "translation": {
            "en": "8.2.5   Why Is Network Depth Important?",
            "zh": "8.2.5 为什么网络深度很重要？"
        }
    },
    {
        "translation": {
            "en": "Figure 13.6[717] shows histograms for these features.",
            "zh": "图13.6[717]显示了这些特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Caruana, Rich, and Alexandru Niculescu-Mizil. 2006. An empirical comparison of supervised learning algorithms. In Proceedings of the 23rd international conference on machine learning, 161–168. ACM.",
            "zh": "卡鲁阿纳、里奇和亚历山德鲁·尼古列斯库-米齐尔。2006. 监督学习算法的实证比较.在第 23 届机器学习国际会议论文集，161–168。ACM。"
        }
    },
    {
        "translation": {
            "en": "The leaky rectified linear function has a small (predefined) non-zero gradient when z < 0. Maas et al. (2013) set the non-zero gradient for z < 0 to 0.01, giving the following definition of this function:",
            "zh": "当 z < 0 时，泄漏整流线性函数具有小的（预定义的）非零梯度。Maas等人（2013）将z的非零梯度设置为0<0到0.01，给出了该函数的以下定义："
        }
    },
    {
        "translation": {
            "en": "To make these judgments it is necessary to have a normalized, domain independent measure of model performance.",
            "zh": "为了做出这些判断，有必要对模型性能进行标准化的、与领域无关的测量。"
        }
    },
    {
        "translation": {
            "en": "where w[j] is a single weight from the set of weights w. Applying the chain rule to this, we get",
            "zh": "其中 w[j] 是权重 w 集合中的单个权重。将链式法则应用于此，我们得到"
        }
    },
    {
        "translation": {
            "en": "In churn analysis, and in any sort of propensity modeling, change is usually a key driver of customer behavior.",
            "zh": "在客户流失分析和任何类型的倾向建模中，变化通常是客户行为的关键驱动因素。"
        }
    },
    {
        "translation": {
            "en": "Assuming that the training set will remain relatively stable, this time issue can be offset by investing in some one-off computation to create an index of the instances that enables efficient retrieval of the nearest neighbors without doing an exhaustive search of the entire dataset.",
            "zh": "假设训练集将保持相对稳定，则可以通过投资一些一次性计算来创建实例索引来抵消此时间问题，从而可以有效地检索最近邻，而无需对整个数据集进行详尽的搜索。"
        }
    },
    {
        "translation": {
            "en": "In cases with very small datasets (approximately fewer than 300 instances), bootstrapping approaches are preferred over cross validation approaches.",
            "zh": "对于数据集非常小（大约少于 300 个实例）的情况，引导方法优于交叉验证方法。"
        }
    },
    {
        "translation": {
            "en": "7.13   A selection of the logistic regression models developed during the gradient descent process for the machinery dataset from Table 7.6[339]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.13 表7.6[339]中机械数据集的梯度下降过程中开发的逻辑回归模型的选择。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "The Theorem of Total Probability is a formal specification of the summing out process we introduced earlier in Section B.2[761].",
            "zh": "总概率定理是我们前面在B.2节[761]中介绍的求和过程的正式规范。"
        }
    },
    {
        "translation": {
            "en": "For the purposes of the case study, we assume that after the feasibility review, it was decided to proceed with the claim prediction solution, in which a model will be built that can predict the likelihood that an insurance claim is fraudulent.",
            "zh": "出于案例研究的目的，我们假设在可行性审查之后，决定继续进行索赔预测解决方案，其中将建立一个模型来预测保险索赔欺诈的可能性。"
        }
    },
    {
        "translation": {
            "en": "The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for a query with CH = paid, GC = none, and ACC = rent, and the calculation of the scores for each target level.",
            "zh": "朴素贝叶斯预测模型对 CH = paid、GC = none 和 ACC = rent 的查询进行预测所需的相关概率，以及每个目标级别的分数计算所需的相关概率。"
        }
    },
    {
        "translation": {
            "en": "However, typically the local receptive fields of neurons in a sub-sampling layer do not overlap (in contrast with the overlapping receptive fields used when we arrange neurons to convolve a filter).",
            "zh": "然而，通常子采样层中神经元的局部感受野不会重叠（与我们安排神经元卷积滤波器时使用的重叠感受野相反）。"
        }
    },
    {
        "translation": {
            "en": "Consequently, we don’t necessarily have to normalize the scores for each target level—something we would have to do if we wanted the actual probabilities.",
            "zh": "因此，我们不必对每个目标水平的分数进行标准化——如果我们想要实际概率，我们就必须这样做。"
        }
    },
    {
        "translation": {
            "en": "9.6 Further Reading",
            "zh": "9.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "The auto-encoders presented in this chapter are fairly simple, and more sophisticated approaches have emerged, for example, convolutional auto-encoders, de-noising auto-encoders, and variational auto-encoders. Guo et al. (2016) provide a readable, coherent overview of these different types.",
            "zh": "本章介绍的自动编码器相当简单，并且出现了更复杂的方法，例如卷积自动编码器、去噪自动编码器和变分自动编码器。Guo et al. （2016） 对这些不同类型的进行了可读、连贯的概述。"
        }
    },
    {
        "translation": {
            "en": "35. The variance of the product of two independent random variables X and Y is given by var(X × Y) = [E(X)]2var(Y ) + [E(Y )]2var(X) + var(X)var(Y ).",
            "zh": "35. 两个自随机变量 X 和 Y 的乘积方差由 var（X × Y） = [E（X）]2var（Y ） + [E（Y ）]2var（X） + var（X）var（Y） 给出。"
        }
    },
    {
        "translation": {
            "en": "basis functions, 351, 365, 368",
            "zh": "基函数， 351， 365， 368"
        }
    },
    {
        "translation": {
            "en": "When this happens, most of the queries will be in locations where none of the training instances are nearby, and as a result, the predictive power of the models based on these training instances will begin to decrease.",
            "zh": "发生这种情况时，大多数查询将位于附近没有训练实例的位置，因此，基于这些训练实例的模型的预测能力将开始下降。"
        }
    },
    {
        "translation": {
            "en": "The next section discusses recommended readings for more information on the regression approaches discussed in this chapter and on some of the more recent developments in error-based learning.",
            "zh": "下一节将讨论推荐的阅读材料，以获取有关本章中讨论的回归方法以及基于错误学习的一些最新发展的更多信息。"
        }
    },
    {
        "translation": {
            "en": "Leave-one-out cross validation is useful when the amount of data available is too small to allow big enough training sets in a k-fold cross validation.",
            "zh": "当可用数据量太小而无法在 k 倍交叉验证中允许足够大的训练集时，留一交叉验证非常有用。"
        }
    },
    {
        "translation": {
            "en": "A merger is a sky object in which multiple galaxies appear grouped together.",
            "zh": "合并是一个天体，其中多个星系组合在一起。"
        }
    },
    {
        "translation": {
            "en": "Based on the performance of the logistic regression model on the 3-level classification problem, Jocelyn trained a logistic regression classifier on the 5-level dataset and evaluated it using a 10-fold cross validation.",
            "zh": "基于逻辑回归模型在 3 级分类问题上的表现，Jocelyn 在 5 级数据集上训练了逻辑回归分类器，并使用 10 倍交叉验证对其进行了评估。"
        }
    },
    {
        "translation": {
            "en": "In a feature following an exponential distribution, as shown in Figure 3.2(e)[60], the likelihood of low values occurring is very high but diminishes rapidly for higher values.",
            "zh": "在指数分布后的特征中，如图3.2（e）[60]所示，出现低值的可能性非常高，但对于较高值，则会迅速降低。"
        }
    },
    {
        "translation": {
            "en": "One of these sets contains the solution, which leaves you with just one more question to ask to finish the game.",
            "zh": "其中一组包含解决方案，让您只需再问一个问题即可完成游戏。"
        }
    },
    {
        "translation": {
            "en": "The derivative of this activation function with respect to z is always 1: each unit change in the value of zi results in a unit change in the value of ai.",
            "zh": "此激活函数相对于 z 的导数始终为 1：zi 值的每个单位变化都会导致 ai 值的单位变化。"
        }
    },
    {
        "translation": {
            "en": "interaction term, 355",
            "zh": "交互项，355"
        }
    },
    {
        "translation": {
            "en": "There are two key main use cases for unsupervised learning: clustering and representation learning.",
            "zh": "无监督学习有两个关键的主要用例：聚类和表示学习。"
        }
    },
    {
        "translation": {
            "en": "STUDIED",
            "zh": "研究"
        }
    },
    {
        "translation": {
            "en": "We now understand the two fundamental components of similarity-based learning: a feature space representation of the instances in a dataset and a measure of similarity between instances.",
            "zh": "现在，我们了解了基于相似性学习的两个基本组成部分：数据集中实例的特征空间表示和实例之间相似性的度量。"
        }
    },
    {
        "translation": {
            "en": "All entries in the action-value table are first initialized to random values (or sometimes zeros).",
            "zh": "action-value 表中的所有条目首先初始化为随机值（有时为零）。"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts at the position marked 1 on the error surface, and learning steps actually cause it to move farther and farther up the error surface.",
            "zh": "该算法从误差面上标记为 1 的位置开始，学习步骤实际上会导致它在误差面上越走越远。"
        }
    },
    {
        "translation": {
            "en": "Hebb also postulated a mechanism for how lasting memories are learned in the brain on the basis of a process of changes to the connections between neurons:",
            "zh": "Hebb还假设了一种机制，即在神经元之间连接发生变化的过程中，大脑中如何学习持久的记忆："
        }
    },
    {
        "translation": {
            "en": "We can see here that the large positive Q values from actions taken in states near the goal state have started to propagate through the environment, although there are not yet large positive values near the start state.",
            "zh": "我们在这里可以看到，在接近目标状态的状态下所采取的行动的大正 Q 值已经开始在环境中传播，尽管在开始状态附近还没有大的正值。"
        }
    },
    {
        "translation": {
            "en": "Each attempt at the task is referred to as an episode.",
            "zh": "对任务的每次尝试都称为一个情节。"
        }
    },
    {
        "translation": {
            "en": "observation period, 37, 689",
            "zh": "观察期， 37， 689"
        }
    },
    {
        "translation": {
            "en": "Finding features that exhibit a normal distribution is a good thing, as many of the modeling techniques we discuss in later chapters work particularly well with normally distributed data.",
            "zh": "找到表现出正态分布的特征是一件好事，因为我们在后面的章节中讨论的许多建模技术都特别适用于正态分布的数据。"
        }
    },
    {
        "translation": {
            "en": "stale model, 578, 580, 583, 702",
            "zh": "陈旧型号，578、580、583、702"
        }
    },
    {
        "translation": {
            "en": "Once a signal has identified that concept drift has occurred and that a model has indeed gone stale, corrective action is required. The nature of this corrective action depends on the application and the type of model being used. In most cases, however, corrective action involves gathering a new labeled dataset and restarting the model building process using this new dataset.",
            "zh": "一旦信号确定发生了概念漂移，并且模型确实已经过时，就需要采取纠正措施。此纠正措施的性质取决于应用程序和所使用的模型类型。但是，在大多数情况下，纠正措施包括收集新的标记数据集并使用此新数据集重新启动模型构建过程。"
        }
    },
    {
        "translation": {
            "en": "An illustration of how a batch of examples can be processed in parallel using matrix operations.",
            "zh": "如何使用矩阵运算并行处理一批示例的图示。"
        }
    },
    {
        "translation": {
            "en": "In all cases performance of the models improved with feature selection.",
            "zh": "在所有情况下，模型的性能都通过特征选择而得到改善。"
        }
    },
    {
        "translation": {
            "en": "heterogeneity, 126",
            "zh": "异质性，126"
        }
    },
    {
        "translation": {
            "en": "The major difference between Figure 5.12(a)[205] and Figure 5.12(b)[205] is that the axes are scaled differently.",
            "zh": "图5.12（a）[205]和图5.12（b）[205]之间的主要区别在于轴的缩放方式不同。"
        }
    },
    {
        "translation": {
            "en": "Early stopping is designed to avoid a model overfitting the training data.",
            "zh": "提前停止旨在避免模型过度拟合训练数据。"
        }
    },
    {
        "translation": {
            "en": "This is why for datasets such as the one depicted in Figure 5.15(a)[219], where there is no covariance between the features, the Mahalanobis distance is simply the Euclidean distance.23",
            "zh": "这就是为什么对于图5.15（a）[219]中描述的数据集，特征之间没有协方差，马氏距离只是欧几里得距离23。"
        }
    },
    {
        "translation": {
            "en": "filters, 227, 482",
            "zh": "过滤器， 227， 482"
        }
    },
    {
        "translation": {
            "en": "If we examine the graph of the binary logarithm (a logarithm to the base 2) of probabilities ranging from 0 to 1, shown in Figure 4.6(a)[125], we see that the logarithm function returns large negative numbers for low probabilities and small negative numbers for high probabilities.",
            "zh": "如果我们检查概率范围为 0 到 1 的二进制对数（以 2 为底的对数）的图形，如图 4.6（a）[125] 所示，我们会看到对数函数为低概率返回大负数，高概率返回小负数。"
        }
    },
    {
        "translation": {
            "en": "The result of this pruning is visible on the left branch of the tree shown in Figure 4.19(b)[158].",
            "zh": "这种修剪的结果在图4.19（b）[158]所示的树的左侧分支上可见。"
        }
    },
    {
        "translation": {
            "en": "Note that although this decision surface is more complex than the ones we have seen before (e.g., Figure 7.12[343]), the logistic shape is still maintained.",
            "zh": "请注意，尽管这个决策面比我们之前看到的决策面更复杂（例如，图7.12[343]），但逻辑形状仍然保持不变。"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the error for this example using the new weights for the network, compared with using the original weights.",
            "zh": "与使用原始权重相比，使用网络的新权重计算此示例的误差减少量。"
        }
    },
    {
        "translation": {
            "en": "This understanding would form the basis of Ross’s work on designing the domain concepts and descriptive features that would make up the analytics base table (ABT), which would drive the creation of the predictive model.",
            "zh": "这种理解将构成 Ross 设计构成分析基表 （ABT） 的领域概念和描述性特征的工作基础，这将推动预测模型的创建。"
        }
    },
    {
        "translation": {
            "en": "Fawcett, Tom. 2006. An introduction to ROC analysis. Pattern Recognition Letters 27 (8): 861–874.",
            "zh": "福塞特，汤姆。2006. ROC分析简介.模式识别快报27（8）：861–874。"
        }
    },
    {
        "translation": {
            "en": "SPEND",
            "zh": "花费"
        }
    },
    {
        "translation": {
            "en": "Similarly, the weights of all incorrectly classified instances are updated using Equation (4.12)[161]. For example, the weight for d9 is updated",
            "zh": "同样，所有错误分类的实例的权重都使用公式（4.12）[161]进行更新。例如，d9 的权重已更新"
        }
    },
    {
        "translation": {
            "en": "9.4.1.3 Leave-one-out cross validation Leave-one-out cross validation, also known as jackknifing, is an extreme form of k-fold cross validation in which the number of folds is the same as the number of training instances.",
            "zh": "9.4.1.3 留一交叉验证 留一交叉验证，也称为 jackknifing，是 k 折叠交叉验证的一种极端形式，其中折叠数与训练实例数相同。"
        }
    },
    {
        "translation": {
            "en": "The starting point for our explanation of the relationship between weighted sum calculations and vanishing and exploding z and δ values is the Bienaymé formula from statistics, which states that the variance of the sum of uncorrelated random variables is the sum of their variance",
            "zh": "我们解释加权和计算与消失和爆炸 z 和 δ 值之间关系的起点是统计学中的 Bienaymé 公式，该公式指出不相关随机变量之和的方差是它们的方差之和"
        }
    },
    {
        "translation": {
            "en": "Let’s look at an example of how we can now use Bayes’ Theorem to make predictions based on the meningitis diagnosis dataset in Table 6.1[246] for a query instance with HEADACHE = true, FEVER = false, and VOMITING = true. Returning to the shortened notation that we used previously, a predicted diagnosis for this query instance can be given using Bayes’ Theorem as",
            "zh": "让我们看一个示例，说明我们现在如何使用贝叶斯定理根据表 6.1[246] 中的脑膜炎诊断数据集对 HEADACHE = true、FEVER = false 和 VOMITING = true 的查询实例进行预测。回到我们之前使用的缩短符号，可以使用贝叶斯定理给出此查询实例的预测诊断，因为"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(a)[663] shows a representation of the action-value table after this first episode.",
            "zh": "图11.5（a）[663]显示了第一集之后的动作值表的表示。"
        }
    },
    {
        "translation": {
            "en": "In the first stage of the McCulloch and Pitts model, each input is multiplied by a weight, and the results of these multiplications are then added together.",
            "zh": "在 McCulloch 和 Pitts 模型的第一阶段，将每个输入乘以一个权重，然后将这些乘法的结果相加。"
        }
    },
    {
        "translation": {
            "en": "17. The Gini coefficient should not be confused with the Gini index described in Section 4.4.1[142]. Their only connection is that they are both named after the Italian statistician Corrado Gini.",
            "zh": "17. 基尼系数不应与第4.4.1节[142]中描述的基尼系数相混淆。它们唯一的联系是它们都是以意大利统计学家科拉多·基尼（Corrado Gini）的名字命名的。"
        }
    },
    {
        "translation": {
            "en": "3.6.2   Binning",
            "zh": "3.6.2 像素合并"
        }
    },
    {
        "translation": {
            "en": "An extreme case of this problem happens when k nearest neighbor models are used.",
            "zh": "当使用 k 个最近邻模型时，会发生此问题的极端情况。"
        }
    },
    {
        "translation": {
            "en": "Brian",
            "zh": "布莱恩"
        }
    },
    {
        "translation": {
            "en": "Sampling bias arises when the sample of data used within a data-driven process is collected in such a way that the sample is not representative of the population the sample is used to represent.",
            "zh": "当在数据驱动过程中使用的数据样本的收集方式使得样本不能代表样本所代表的总体时，就会出现抽样偏差。"
        }
    },
    {
        "translation": {
            "en": "10.4.1   Choosing Initial Cluster Centroids",
            "zh": "10.4.1 选择初始聚类质心"
        }
    },
    {
        "translation": {
            "en": "Figure 7.17",
            "zh": "图 7.17"
        }
    },
    {
        "translation": {
            "en": "That said, some models are more susceptible to the curse of dimensionality than others.",
            "zh": "也就是说，有些模型比其他模型更容易受到维度的诅咒。"
        }
    },
    {
        "translation": {
            "en": "data mining, 16",
            "zh": "数据挖掘， 16"
        }
    },
    {
        "translation": {
            "en": "9.3   Standard Approach: Misclassification Rate on a Hold-Out Test Set",
            "zh": "9.3 标准方法：保持测试集的错误分类率"
        }
    },
    {
        "translation": {
            "en": "history, 639",
            "zh": "历史，639"
        }
    },
    {
        "translation": {
            "en": "Table 4.3",
            "zh": "表 4.3"
        }
    },
    {
        "translation": {
            "en": "One problem with updating the weights of a network after each example is that the error gradient calculated on a single example sampled from the training set is likely to be a noisy approximation of the true gradient over the entire dataset; in other words, the error gradient calculated on a single example may not point in the same direction as the steepest gradient when we average the gradients over the entire dataset.",
            "zh": "在每个示例之后更新网络权重的一个问题是，从训练集采样的单个示例上计算的误差梯度可能是整个数据集上真实梯度的噪声近似值;换言之，当我们对整个数据集的梯度进行平均时，在单个示例上计算的误差梯度可能与最陡峭的梯度指向的方向不同。"
        }
    },
    {
        "translation": {
            "en": "As noted, the activation vector ht of the hidden layer for input t is propagated forward to the output layer, and also to the memory buffer where it is stored for one time-step. Equation (8.105)[501] specifies how the output activations yt for input t are then generated: a weighted sum is calculated via a dot product operation between the weight matrix Wyh and the activations vector from the hidden layer ht, and this is passed through a non-linear activation function φ.",
            "zh": "如前所述，输入 t 的隐藏层的激活向量 ht 向前传播到输出层，并传播到存储一个时间步长的内存缓冲区。方程（8.105）[501]指定了如何生成输入t的输出激活yt：通过权重矩阵Wyh和隐藏层ht的激活向量之间的点积运算计算加权和，并通过非线性激活函数φ传递。"
        }
    },
    {
        "translation": {
            "en": "The chapter finishes by describing the deep Q network algorithm.",
            "zh": "本章最后介绍了深度 Q 网络算法。"
        }
    },
    {
        "translation": {
            "en": "There are many different types of neurons in the brain; however, in general, neurons have a simple three-part structure consisting of (1) a cell body; (2) a set of relatively short fibers connected to the cell body, called dendrites; and (3) a single long fiber connected to the cell body, called an axon.",
            "zh": "大脑中有许多不同类型的神经元;然而，一般来说，神经元具有简单的三部分结构，包括 （1） 细胞体;（2）一组连接到细胞体的相对较短的纤维，称为树突;（3）连接到细胞体的单根长纤维，称为轴突。"
        }
    },
    {
        "translation": {
            "en": "5.8   A dataset of whiskeys listing the age (in years), the rating (between 1 and 5, with 5 being the best), and the bottle price of each whiskey.",
            "zh": "5.8 威士忌数据集，列出每种威士忌的年龄（以年为单位）、评级（在 1 到 5 之间，5 为最佳）和瓶价。"
        }
    },
    {
        "translation": {
            "en": "There are two defining characteristics of ensemble models:",
            "zh": "集成模型有两个定义特征："
        }
    },
    {
        "translation": {
            "en": "This rise in relative frequency illustrates that, as the number of samples generated increases, the resulting distribution approaches the actual distribution.",
            "zh": "这种相对频率的增加表明，随着生成的样本数量的增加，得到的分布接近实际分布。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35",
            "zh": "图 8.35"
        }
    },
    {
        "translation": {
            "en": "Figure 2.7",
            "zh": "图 2.7"
        }
    },
    {
        "translation": {
            "en": "AVGROAMCALLS",
            "zh": "AVGROAMCALLS"
        }
    },
    {
        "translation": {
            "en": "13. See Section 9.4.5[574].",
            "zh": "13. 参见第 9.4.5 节[574]。"
        }
    },
    {
        "translation": {
            "en": "To help illustrate this, imagine Conor has gone to a small Gaeltacht town in Ireland on a two-week business trip.",
            "zh": "为了帮助说明这一点，想象一下康纳去爱尔兰的一个盖尔塔赫特小镇进行了为期两周的商务旅行。"
        }
    },
    {
        "translation": {
            "en": "33. The dataset in this question is inspired by the Waste Water Treatment Dataset that is available from the UCI Machine Learning repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/machine-learning-databases/water-treatment. The creators of this dataset reported their work in Bejar et al. (1991).",
            "zh": "33. 本问题中的数据集的灵感来自 archive.ics.uci.edu/ml/machine-learning-databases/water-treatment 的UCI机器学习存储库（Bache和Lichman，2013年）提供的废水处理数据集。该数据集的创建者在Bejar等人（1991）中报告了他们的工作。"
        }
    },
    {
        "translation": {
            "en": "This rule highlights that in data that follows a normal distribution, there is a very low probability of observations occurring that differ from the mean by more than two standard deviations.",
            "zh": "此规则强调，在遵循正态分布的数据中，发生与均值相差超过两个标准差的观测值的概率非常低。"
        }
    },
    {
        "translation": {
            "en": "The default distance metric used in nearest neighbor models is Euclidean distance.",
            "zh": "最近邻模型中使用的默认距离度量是欧几里得距离。"
        }
    },
    {
        "translation": {
            "en": "27. This should not be confused with the concept of sparse data that was introduced earlier.",
            "zh": "27. 这不应与前面介绍的稀疏数据概念相混淆。"
        }
    },
    {
        "translation": {
            "en": "Demsar, Janez. 2006. Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research 7: 1–30.",
            "zh": "德姆萨尔，贾内斯。2006. 分类器在多个数据集上的统计比较.机器学习研究杂志 7：1-30。"
        }
    },
    {
        "translation": {
            "en": "We can use the chain rule for conditional probabilities by just adding the conditioning term to each term in the expression, so",
            "zh": "我们可以通过将条件项添加到表达式中的每个项来使用条件概率链式法则，因此"
        }
    },
    {
        "translation": {
            "en": "This is because the rectified linear function has a zero output value for half its domain (i.e., for all z ≤ 0).",
            "zh": "这是因为整流线性函数在其一半域（即所有 z ≤ 0）的输出值为零。"
        }
    },
    {
        "translation": {
            "en": "2.11   A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.11 汽车保险欺诈预测分析解决方案的领域概念和相关功能的子集。"
        }
    },
    {
        "translation": {
            "en": "Note that this action is different from the action used in the update equation previously (left).",
            "zh": "请注意，此操作与之前更新公式中使用的操作（左）不同。"
        }
    },
    {
        "translation": {
            "en": "The main disadvantage of normalization is that the interpretative analysis discussed in Section 7.4.4[338] becomes more difficult as the descriptive feature values used in the model do not relate to the actual feature values in the data.",
            "zh": "归一化的主要缺点是，由于模型中使用的描述性特征值与数据中的实际特征值无关，因此第 7.4.4 节[338] 中讨论的解释性分析变得更加困难。"
        }
    },
    {
        "translation": {
            "en": "A.1.1    Central Tendency",
            "zh": "A.1.1 集中趋势"
        }
    },
    {
        "translation": {
            "en": "Once Edwin had approved the models that Jocelyn had built, Jocelyn met again with Ted to begin the process of integrating the models into the SDSS processing pipeline.",
            "zh": "Edwin 批准了 Jocelyn 构建的模型后，Jocelyn 再次与 Ted 会面，开始将模型集成到 SDSS 处理管道中。"
        }
    },
    {
        "translation": {
            "en": "The Mahalanobis distance uses covariance to scale distances so that distances along a direction where the dataset is very spread out are scaled down, and distances along directions where the dataset is tightly packed are scaled up. For example, in Figure 5.15(b)[219] the Mahalanobis distance between B and A will be less than the Mahalanobis distance between C and A, whereas in Figure 5.15(c)[219] the opposite will be true. The Mahalanobis distance is defined as",
            "zh": "马氏距离使用协方差来缩放距离，以便沿数据集非常分散的方向的距离按比例缩小，沿数据集紧密堆积的方向的距离按比例放大。例如，在图5.15（b）[219]中，B和A之间的马氏距离将小于C和A之间的马氏距离，而在图5.15（c）[219]中，情况正好相反。马氏距离定义为"
        }
    },
    {
        "translation": {
            "en": "Because they explicitly model the distribution of the data for each class k nearest neighbor models are also generative models.",
            "zh": "因为它们显式地对每个类的数据分布进行建模，所以 k 最近邻模型也是生成模型。"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for clockwise spiral galaxy category",
            "zh": "顺时针螺旋星系类别的得票分数"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of these two features is shown in Figure 7.16(a)[352], from which the strong non-linear relationship between rainfall and grass growth is clearly apparent—grass does not grow well when there is very little rain or too much rain, but hits a sweet spot at rainfall of about 2.5mm per day.",
            "zh": "这两个特征的散点图如图7.16（a）[352]所示，从中可以清楚地看出降雨量与草生长之间的强非线性关系——当雨水很少或雨水过多时，草生长不好，但在每天降雨量约2.5毫米时达到最佳状态。"
        }
    },
    {
        "translation": {
            "en": "In a linear relationship between two features, as one feature increases or decreases, the other feature increases or decreases by a corresponding amount.",
            "zh": "在两个特征之间的线性关系中，当一个特征增加或减少时，另一个特征会相应增加或减少。"
        }
    },
    {
        "translation": {
            "en": "The Fundamentals section of this chapter introduces the standard artificial neural network architecture: a feedforward neural network. We then present the backpropagation algorithm, the standard algorithm used to train neural networks, and illustrate how the algorithm functions with a worked example.",
            "zh": "本章的基础部分介绍了标准的人工神经网络架构：前馈神经网络。然后，我们介绍了反向传播算法，这是用于训练神经网络的标准算法，并用一个工作示例说明了该算法是如何工作的。"
        }
    },
    {
        "translation": {
            "en": "To do this, we compute the required conditional probabilities from the binned data in Table 6.18[295].",
            "zh": "为此，我们从表6.18[295]中的分箱数据中计算所需的条件概率。"
        }
    },
    {
        "translation": {
            "en": "The information about the scenario gives us the probability of having the disease as P(d) = 0.0001 and the probability of not having the disease as P(¬d) = 0.9999. The accuracy of the test is captured as P(t | d) = 0.99 and P(t | ¬d) = 0.01. The overall probability of the test returning a positive value, P(t), is not given in the description above, but it can be easily calculated using the Theorem of Total Probability5 as",
            "zh": "有关该场景的信息为我们提供了 P（d） = 0.0001 的疾病概率和 P（¬d） = 0.9999 的不疾病概率。测试的精度为 P（t | d） = 0.99 和 P（t | ¬d） = 0.01。上面的描述中没有给出检验返回正值 P（t） 的总概率，但可以使用总概率定理 5 轻松计算为"
        }
    },
    {
        "translation": {
            "en": "Equation (7.12)[324] is calculated from Equation (7.11)[324] by applying the differentiation chain rule.6 To understand the move from Equation (7.13)[324] to Equation (7.14)[324], imagine a problem with four descriptive features d[1]…d[4]. Remembering that we always include the dummy feature d[0] with a value of 1, the dot product w ·d becomes",
            "zh": "方程（7.12）[324]是根据方程（7.11）[324]通过应用微分链法则计算的.6要理解从方程（7.13）[324]到方程（7.14）[324]的移动，想象一个具有四个描述性特征d[1]的问题......d[4]。请记住，我们始终包含值为 1 的虚拟特征 d[0]，点积 w ·d 变为"
        }
    },
    {
        "translation": {
            "en": "Finally, the k sets of performance measures are aggregated to give one overall set of performance measures.",
            "zh": "最后，将 k 组绩效度量汇总在一起，给出一组整体绩效度量。"
        }
    },
    {
        "translation": {
            "en": "Rather than use individual pixel values, which can lead to very high-dimensional feature vectors, a simpler way to represent images for use with regression models is to calculate a histogram for each image and use this as the feature vector instead. In this case the histograms simply count the frequency of occurrence of each possible gray level in each image. The table that follows shows the histograms for a small dataset of 16 images split between examples of digits 0 and 1.",
            "zh": "表示图像以用于回归模型的一种更简单的方法是计算每个图像的直方图，并将其用作特征向量，而不是使用单个像素值，这可能会导致非常高维的特征向量。在这种情况下，直方图只是计算每个图像中每个可能的灰度级别的出现频率。下表显示了一个包含 16 个图像的小型数据集的直方图，这些图像分为数字 0 和 1 的示例。"
        }
    },
    {
        "translation": {
            "en": "EXPRADERR_U/G/R/I/Z",
            "zh": "EXPRADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 5.16[221] illustrates how the Mahalanobis distance defines this coordinate system, which is translated, rotated, and scaled with respect to the standard coordinates of a feature space.",
            "zh": "图 5.16[221] 说明了马氏距离如何定义此坐标系，该坐标系相对于要素空间的标准坐标进行平移、旋转和缩放。"
        }
    },
    {
        "translation": {
            "en": "personal data, 40",
            "zh": "个人资料， 40"
        }
    },
    {
        "translation": {
            "en": "(d) Are there likely to be any legal issues associated with the domain concepts you have included?",
            "zh": "（d） 你所包含的领域概念是否可能存在任何法律问题？"
        }
    },
    {
        "translation": {
            "en": "SARSA24 is the most well-known on-policy temporal-difference learning algorithm, and is described in Algorithm 14[666].",
            "zh": "SARSA24是最广为人知的策略时差学习算法，在算法14[666]中进行了描述。"
        }
    },
    {
        "translation": {
            "en": "To do this we use a weighted dataset in which each instance has an associated weight wi ≥ 0, initially set to where n is the number of instances in the dataset.",
            "zh": "为此，我们使用一个加权数据集，其中每个实例都有一个关联的权重 wi ≥ 0，最初设置为其中 n 是数据集中的实例数。"
        }
    },
    {
        "translation": {
            "en": "L2 loss, 168",
            "zh": "L2 损失，168"
        }
    },
    {
        "translation": {
            "en": "(b) An equal-frequency binning using 5 bins",
            "zh": "（b） 使用 5 个分档的等频分档"
        }
    },
    {
        "translation": {
            "en": "3.1.1   Case Study: Motor Insurance Fraud",
            "zh": "3.1.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo, 708",
            "zh": "银河动物园，708"
        }
    },
    {
        "translation": {
            "en": "The purpose specification principle states that data subjects should be informed of the purpose for which data will be used at the time of its collection.",
            "zh": "目的指明原则规定，在收集数据时，应告知数据主体使用数据的目的。"
        }
    },
    {
        "translation": {
            "en": "Although the goal of finding the best decision boundary is the same for algorithms that build support vector machines as it is for logistic regression models, the inductive bias encoded in the algorithms to select this boundary is different, which leads to different decision boundaries being found.",
            "zh": "尽管对于构建支持向量机的算法来说，找到最佳决策边界的目标与逻辑回归模型的目标相同，但算法中编码的用于选择此边界的归纳偏差是不同的，这导致找到不同的决策边界。"
        }
    },
    {
        "translation": {
            "en": "We use the convention of a bold capital letter to denote a matrix and a superscript in parentheses to list the relevant layer.",
            "zh": "我们使用粗体大写字母表示矩阵的惯例，并使用括号中的上标来列出相关层。"
        }
    },
    {
        "translation": {
            "en": "As we noted when we dropped the denominator of Bayes’ Theorem from the MAP prediction model (Equation (6.11)[254]), for a categorical prediction task, we are primarily interested in the relative size of the posterior probabilities for the different target levels rather than the exact probabilities.",
            "zh": "正如我们从MAP预测模型中删除贝叶斯定理的分母时所指出的（方程（6.11）[254]），对于分类预测任务，我们主要感兴趣的是不同目标水平的后验概率的相对大小，而不是确切的概率。"
        }
    },
    {
        "translation": {
            "en": "This means that we typically need to move beyond the performance measures described in Chapter 9[533].",
            "zh": "这意味着我们通常需要超越第 9 章[533] 中描述的性能度量。"
        }
    },
    {
        "translation": {
            "en": "Bishop, C. M. 2006. Pattern recognition and machine learning. Springer.",
            "zh": "主教，CM 2006。模式识别和机器学习。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "Ideally, we would like to use the network whose structure most accurately reflects the causal relationships in the domain.",
            "zh": "理想情况下，我们希望使用其结构最准确地反映域中因果关系的网络。"
        }
    },
    {
        "translation": {
            "en": "The fact that the joint receptive fields of the neurons in each set cover the entire input means that if the relevant visual feature (where relevance is defined by the filter used by a set of neurons) occurs anywhere in the input, then at least one of the neurons in the set will have a high activation.",
            "zh": "事实上，每个集合中神经元的联合感受野覆盖了整个输入，这意味着如果相关的视觉特征（相关性由一组神经元使用的过滤器定义）发生在输入的任何位置，那么集合中至少有一个神经元将具有高度激活。"
        }
    },
    {
        "translation": {
            "en": "Instead, the tree branching and the depth of the tree are related to the complexity of the dataset it is trained on.",
            "zh": "相反，树的分支和树的深度与训练它的数据集的复杂性有关。"
        }
    },
    {
        "translation": {
            "en": "Applying these rules to the first of our previous examples, f(x) = 2x + 3 (Figure C.2(a)[767]), we first apply Rule 3 to split this function into two parts, 2x and 3, and then apply differentiation rules to each. By Rule 2 we can differentiate 2x to 2 (remember that x is really x1). The 3 is a constant, so by Rule 1 differentiates to zero. The derivative of the function, then, is .",
            "zh": "将这些规则应用于我们前面的第一个示例，f（x） = 2x + 3（图C.2（a）[767]），我们首先应用规则3将该函数拆分为两部分，2x和3，然后对每个部分应用微分规则。根据规则 2，我们可以将 2x 区分为 2（请记住，x 实际上是 x1）。3 是一个常数，因此根据规则 1 分化为零。因此，该函数的导数为 。"
        }
    },
    {
        "translation": {
            "en": "The likelihood of overfitting increases as a tree gets deeper because the resulting predictions are based on smaller and smaller subsets as the dataset is partitioned after each feature test in the path.",
            "zh": "随着树的深入，过拟合的可能性也会增加，因为生成的预测基于越来越小的子集，因为数据集在路径中的每个特征测试后都会进行分区。"
        }
    },
    {
        "translation": {
            "en": "1. See Section 1.6[15].",
            "zh": "1. 参见第 1.6 节[15]。"
        }
    },
    {
        "translation": {
            "en": "To fit an exponential distribution to a continuous feature, we set λ equal to 1 divided by the mean of the feature.",
            "zh": "为了将指数分布拟合到连续特征，我们将 λ 设置为等于 1 除以特征的平均值。"
        }
    },
    {
        "translation": {
            "en": "This backward process builds these chains in an efficient manner because the linking of a new neuron to the chain can be done by extending the chains created for the neurons downstream of it.",
            "zh": "这种向后过程以有效的方式构建这些链，因为可以通过扩展为其下游神经元创建的链来完成新神经元与链的链接。"
        }
    },
    {
        "translation": {
            "en": "5. The full text of the Civil Rights Act of 1964 is available at www.gpo.gov/fdsys/granule/STATUTE-78/STATUTE-78-Pg241/content-detail.html.",
            "zh": "5. 1964年《民权法案》全文见 www.gpo.gov/fdsys/granule/STATUTE-78/STATUTE-78-Pg241/content-detail.html。"
        }
    },
    {
        "translation": {
            "en": "This is not uncommon in this kind of scenario, in which the classifications have a certain amount of fuzziness around their boundaries—e.g., the exact line between an elliptical and a spiral galaxy can be hard to define—and led to very interesting discussions for the scientists!",
            "zh": "这种情况并不少见，在这种情况下，分类在其边界周围有一定的模糊性 - 例如，椭圆星系和螺旋星系之间的确切线可能很难定义 - 并引发了科学家非常有趣的讨论！"
        }
    },
    {
        "translation": {
            "en": "null hypothesis, 333",
            "zh": "原假设，333"
        }
    },
    {
        "translation": {
            "en": "Three of these, broken limb, soft tissue, and back, are quite frequent in the ABT, while serious is quite rare.",
            "zh": "其中三种，肢体骨折、软组织骨折和背部骨折，在 ABT 中很常见，而严重则非常罕见。"
        }
    },
    {
        "translation": {
            "en": "6.3.1   A Worked Example",
            "zh": "6.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "-0.113108",
            "zh": "-0.113108"
        }
    },
    {
        "translation": {
            "en": "Casscells, Ward, Arno Schoenberger, and Thomas B. Graboys. 1978. Interpretation by physicians of clinical laboratory results. New England Journal of Medicine 299 (18): 999–1001.",
            "zh": "Casscells、Ward、Arno Schoenberger 和 Thomas B. Graboys。1978. 医生对临床实验室结果的解释。新英格兰医学杂志299（18）：999-1001。"
        }
    },
    {
        "translation": {
            "en": "In this context, instance B is much more likely to be a member of the dataset than instance C. Figure 5.15(c)[219] shows a dataset with a strong positive covariance, and for this dataset, instance C is much more likely to be a member than instance B.",
            "zh": "图5.15（c）[219]显示了一个具有强正协方差的数据集，对于这个数据集，实例C比实例B更有可能成为成员。"
        }
    },
    {
        "translation": {
            "en": "This means that each element in z(2) is the result of multiplying each element in a row in W(2) by the corresponding element in the column vector a(1) and summing the results.",
            "zh": "这意味着 z（2） 中的每个元素都是将 W（2） 中一行中的每个元素乘以列向量 a（1） 中的相应元素并将结果相加的结果。"
        }
    },
    {
        "translation": {
            "en": "(d) Calculate a new set of weights for this model using a learning rate of 0.01.",
            "zh": "（d） 使用0.01的学习率计算该模型的一组新权重。"
        }
    },
    {
        "translation": {
            "en": "Monte Carlo methods work well in conjunction with Bayesian networks because a Bayesian network models the probability distribution over the features.",
            "zh": "蒙特卡罗方法与贝叶斯网络配合使用效果很好，因为贝叶斯网络对特征的概率分布进行建模。"
        }
    },
    {
        "translation": {
            "en": "0.235460",
            "zh": "0.235460"
        }
    },
    {
        "translation": {
            "en": "Predictions for the other target level are actually being performed this time, whereas in the previous example, this target level was essentially being ignored.",
            "zh": "这次实际上是对另一个目标水平的预测，而在前面的例子中，这个目标水平基本上被忽略了。"
        }
    },
    {
        "translation": {
            "en": "This policyholder seems to have made many more claims than anyone else, and the total amount claimed reflects this.",
            "zh": "这位投保人提出的索赔似乎比其他任何人都多，索赔总额反映了这一点。"
        }
    },
    {
        "translation": {
            "en": "statistical inference, 751",
            "zh": "统计推断，751"
        }
    },
    {
        "translation": {
            "en": "Frequently, the term activation function is used as a general term to refer to whatever function is employed in the second stage of an artificial neuron, because the function maps the weighted sum value, z, into the output value, or activation, of the neuron.",
            "zh": "通常，术语激活函数被用作通用术语来指代人工神经元第二阶段使用的任何功能，因为该函数将加权和值 z 映射到神经元的输出值或激活值。"
        }
    },
    {
        "translation": {
            "en": "3.3.4.2 Irregular cardinality Reading down the Card.",
            "zh": "3.3.4.2 不规则基数 读卡。"
        }
    },
    {
        "translation": {
            "en": "We can see from Iteration 2 in the bottom half of Table 7.3[331] that the new set of predictions made using the updated set of weights calculated in iteration 1 result in a lower sum of squared errors, 443,361.52.",
            "zh": "从表7.3[331]下半部分的迭代2中可以看出，使用迭代1中计算的更新权重集进行的新预测集导致的平方误差总和较低，为443,361.52。"
        }
    },
    {
        "translation": {
            "en": "This input matrix is organized so that each column contains the feature vector for a single example.",
            "zh": "此输入矩阵的组织方式是，每列都包含单个示例的特征向量。"
        }
    },
    {
        "translation": {
            "en": "where w is the vector w[0], w[1 the parameters w[0] and w[1] are referred to as weights;1 d is an instance defined by a single descriptive feature d[1 and w(d) is the prediction output by the model for the instance d. The key to using simple linear regression models is determining the optimal values for the weights in the model.",
            "zh": "其中 w 是向量 w[0]，w[1 参数 w[0] 和 w[1] 称为权重;1 d 是由单个描述性特征 d[1] 定义的实例，w（d） 是模型对实例 d 的预测输出。使用简单线性回归模型的关键是确定模型中权重的最佳值。"
        }
    },
    {
        "translation": {
            "en": "43. In some texts, such as Goodfellow et al. (2016), the application of the activation function is treated as a separate step after the feature map has been generated by the application of the filter. Here we include the application function as part of the generation of the feature map.",
            "zh": "43. 在一些文本中，例如Goodfellow等人（2016年），在应用过滤器生成特征图后，激活函数的应用被视为一个单独的步骤。在这里，我们将应用程序功能作为功能图生成的一部分。"
        }
    },
    {
        "translation": {
            "en": "We need to define three equations to formally specify information gain (one for each step). The first equation calculates the entropy for a dataset with respect to a target feature6",
            "zh": "我们需要定义三个方程来正式指定信息增益（每个步骤一个）。第一个方程计算数据集相对于目标特征的熵6"
        }
    },
    {
        "translation": {
            "en": "Figure 11.4",
            "zh": "图 11.4"
        }
    },
    {
        "translation": {
            "en": "2. The overall performance of a model can be captured in a single performance measure, for example, misclassification rate.",
            "zh": "2. 模型的整体性能可以在单个性能度量中捕获，例如错误分类率。"
        }
    },
    {
        "translation": {
            "en": "data preprocessing, 421",
            "zh": "数据预处理，421"
        }
    },
    {
        "translation": {
            "en": "For example, a feature representing customer ages might cover the range [16,96], whereas a feature representing customer salaries might cover the range [10,000, 100,000].",
            "zh": "例如，表示客户年龄的特征可能涵盖范围 [16,96]，而表示客户工资的特征可能涵盖范围 [10,000， 100,000]。"
        }
    },
    {
        "translation": {
            "en": "3. We discuss probability distributions in more depth in Chapter 6[243].",
            "zh": "3. 我们在第6章[243]中更深入地讨论了概率分布。"
        }
    },
    {
        "translation": {
            "en": "Pre-pruning approaches are computationally efficient and can work well for small datasets. By stopping the partitioning of the data early, however, induction algorithms that use pre-pruning can fail to create the most effective trees because they miss interactions between features that emerge within subtrees that are not obvious when the parent nodes are being considered. Pre-pruning can mean that these useful subtrees are never created.",
            "zh": "预修剪方法在计算上是有效的，可以很好地用于小型数据集。但是，通过提前停止数据分区，使用预修剪的归纳算法可能无法创建最有效的树，因为它们会错过子树中出现的特征之间的交互，而这些特征在考虑父节点时并不明显。预修剪可能意味着永远不会创建这些有用的子树。"
        }
    },
    {
        "translation": {
            "en": "These two feature maps are then stacked together and fed forward as input to the second convolutional layer.",
            "zh": "然后将这两个特征图堆叠在一起，并作为输入转发到第二个卷积层。"
        }
    },
    {
        "translation": {
            "en": "In this way the most common clustering is chosen as the final result.",
            "zh": "这样，将选择最常见的聚类作为最终结果。"
        }
    },
    {
        "translation": {
            "en": "Risk Assessment: Risk is one of the key influencers in almost every decision an organization makes. Predictive analytics models can be used to predict the risk associated with decisions such as issuing a loan or underwriting an insurance policy. These models are trained using historical data from which they extract the key indicators of risk. The output from risk prediction models can be used by organizations to make better risk judgments.",
            "zh": "风险评估：风险是组织做出的几乎每个决策的关键影响因素之一。预测分析模型可用于预测与决策相关的风险，例如发放贷款或承保保险单。这些模型使用历史数据进行训练，从中提取关键风险指标。组织可以使用风险预测模型的输出来做出更好的风险判断。"
        }
    },
    {
        "translation": {
            "en": "However, in domains where we have good prior knowledge of the independence relationships between features, we can encode this prior structural information into a generative model.",
            "zh": "然而，在我们对特征之间的独立关系有很好的先验知识的领域中，我们可以将这些先验结构信息编码到生成模型中。"
        }
    },
    {
        "translation": {
            "en": "where the notation meanings are the same as for Equation (9.11)[551]. The average class accuracyHM for the model performances shown in Tables 9.5[551] and 9.6[551] are",
            "zh": "其中符号含义与等式（9.11）[551]相同。表9.5[551]和表9.6[551]所示模型性能的平均等级精度HM为："
        }
    },
    {
        "translation": {
            "en": "Figure 2.12[47] shows how the major tasks described in this chapter align with these phases.",
            "zh": "图2.12[47]显示了本章中描述的主要任务如何与这些阶段保持一致。"
        }
    },
    {
        "translation": {
            "en": "This choice of these initial seeds, unfortunately, can have a big impact on the performance of the algorithm.",
            "zh": "不幸的是，这些初始种子的选择可能会对算法的性能产生重大影响。"
        }
    },
    {
        "translation": {
            "en": "Imputation (median: 0.0)",
            "zh": "插补（中位数：0.0）"
        }
    },
    {
        "translation": {
            "en": "In these images the training data instances are shown as symbols on the feature space (triangles for good and crosses for bad), the decision boundaries learned by each algorithm are represented by thick black lines, and the underlying actual decision boundaries are shown by the background shading.",
            "zh": "在这些图像中，训练数据实例在特征空间上显示为符号（三角形表示好，十字表示坏），每个算法学习的决策边界用粗黑线表示，底层的实际决策边界由背景阴影显示。"
        }
    },
    {
        "translation": {
            "en": "A prediction model that works in this way is making a maximum a posteriori (MAP) prediction.11 We can formally define a Bayesian MAP prediction model as",
            "zh": "以这种方式工作的预测模型正在进行最大后验 （MAP） 预测.11 我们可以将贝叶斯 MAP 预测模型正式定义为"
        }
    },
    {
        "translation": {
            "en": "EXPFLUXIVAR_U/G/R/I/Z",
            "zh": "EXPFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "It is in small differences like this that we see the impact of working on samples rather than populations.",
            "zh": "正是在这样的微小差异中，我们看到了对样本而不是总体的影响。"
        }
    },
    {
        "translation": {
            "en": "Numeric: True numeric values that allow arithmetic operations (e.g., price, age)",
            "zh": "数值：允许算术运算的真实数值（例如，价格、年龄）"
        }
    },
    {
        "translation": {
            "en": "artificial neural network, 369",
            "zh": "人工神经网络，369"
        }
    },
    {
        "translation": {
            "en": "We begin by explaining the concept of an intelligent agent and then describe the fundamental building blocks of reinforcement learning.",
            "zh": "我们首先解释智能代理的概念，然后描述强化学习的基本构建块。"
        }
    },
    {
        "translation": {
            "en": "9.3   A confusion matrix for the set of predictions shown in Table 9.1[537].",
            "zh": "9.3 表9.1[537]所示的一组预测的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "hidden layers, 389",
            "zh": "隐藏层， 389"
        }
    },
    {
        "translation": {
            "en": "Document Classification: Predictive data analytics can be used to automatically classify documents into different categories. Examples include email spam filtering, news sentiment analysis, customer complaint redirection, and medical decision making. In fact, the definition of a document can be expanded to include images, sounds, and videos, all of which can be classified using predictive data analytics models.",
            "zh": "文档分类：预测数据分析可用于自动将文档分类为不同的类别。示例包括垃圾邮件过滤、新闻情绪分析、客户投诉重定向和医疗决策。事实上，文档的定义可以扩展到包括图像、声音和视频，所有这些都可以使用预测数据分析模型进行分类。"
        }
    },
    {
        "translation": {
            "en": "These values are marked in Figure C.1[765].",
            "zh": "这些值标记在图C.1[765]中。"
        }
    },
    {
        "translation": {
            "en": "Next-best-offer models provide an example scenario where the descriptive features are time dependent but the target feature is not.",
            "zh": "次优产品/服务模型提供了一个示例方案，其中描述性要素与时间相关，但目标要素与时间无关。"
        }
    },
    {
        "translation": {
            "en": "7.4   (a) A 3D plot of an error surface and (b) a bird’s-eye view contour plot of the same error surface. The lines indicate the path that the gradient descent algorithm would take across this error surface from four different starting positions to the global minimum—marked as the white dot in the center.",
            "zh": "7.4 （a） 误差面的 3D 图和 （b） 同一误差面的鸟瞰等值线图。这些线表示梯度下降算法从四个不同的起始位置到全局最小值（标记为中心的白点）穿过此误差表面的路径。"
        }
    },
    {
        "translation": {
            "en": "7,000",
            "zh": "7,000"
        }
    },
    {
        "translation": {
            "en": "Note that even though the shape of the curve in Figure 7.7(e)[329] is similar to the shape in Figure 7.7(d)[329], it takes far fewer iterations to reach the global minimum.",
            "zh": "请注意，尽管图7.7（e）[329]中的曲线形状与图7.7（d）[329]中的形状相似，但达到全局最小值所需的迭代次数要少得多。"
        }
    },
    {
        "translation": {
            "en": "8.27   A schematic of a feedforward artificial neural network with a three-neuron softmax output layer.",
            "zh": "8.27 具有三神经元softmax输出层的前馈人工神经网络示意图。"
        }
    },
    {
        "translation": {
            "en": "Individual Features in a Particular Instance",
            "zh": "特定实例中的单个功能"
        }
    },
    {
        "translation": {
            "en": "Decision trees take this approach.",
            "zh": "决策树采用这种方法。"
        }
    },
    {
        "translation": {
            "en": "In this instance, the weights for the different matrices in the LSTM unit are randomly sampled from a normal distribution μ = 0,σ = 0.1, and the bias terms have been initialized to 0.",
            "zh": "在本例中，LSTM 单元中不同矩阵的权重从正态分布 μ = 0，σ = 0.1 中随机采样，并且偏差项已初始化为 0。"
        }
    },
    {
        "translation": {
            "en": "Similarly, Figure 12.3(b)[697] shows that customers who churned tended to make more calls outside their bundle than those who did not.",
            "zh": "同样，图12.3（b）[697]显示，流失的客户往往比没有流失的客户在捆绑包之外拨打更多的电话。"
        }
    },
    {
        "translation": {
            "en": "4.7 Exercises",
            "zh": "4.7 练习"
        }
    },
    {
        "translation": {
            "en": "Each row represents a fold in the process, in which the black rectangles indicate the data used for testing while the white spaces indicate the data used for training.",
            "zh": "每一行表示流程中的一个折叠，其中黑色矩形表示用于测试的数据，而白色空格表示用于训练的数据。"
        }
    },
    {
        "translation": {
            "en": "The CNN architecture was originally applied to handwritten digit recognition, and much of the early work on CNNs was based on the MNIST (pronounced em-nist) dataset40 (Le Cun et al., 1998).",
            "zh": "CNN架构最初应用于手写数字识别，CNN的大部分早期工作都是基于MNIST（发音为em-nist）数据集40（Le Cun et al.， 1998）。"
        }
    },
    {
        "translation": {
            "en": "However, in this example we use batch gradient descent training, and so for each weight update we must first calculate a table equivalent to Table 8.6[431] for each example.",
            "zh": "然而，在这个例子中，我们使用批量梯度下降训练，因此对于每个权重更新，我们必须首先计算一个相当于每个示例的表8.6[431]的表格。"
        }
    },
    {
        "translation": {
            "en": "Just about any state representation we could design that would accurately capture the dynamics of this game would result in an action-value table with thousands or hundreds of thousands of entries.",
            "zh": "我们可以设计的任何能够准确捕捉这个游戏动态的状态表示，都会产生一个包含数千或数十万个条目的动作值表。"
        }
    },
    {
        "translation": {
            "en": "Individual Features",
            "zh": "个性化功能"
        }
    },
    {
        "translation": {
            "en": "Assuming that the variance of the δs for the output layer is equal to 1:",
            "zh": "假设输出层的 δs 方差等于 1："
        }
    },
    {
        "translation": {
            "en": "A simple Markov process to model the evolution of an infectious disease in individuals during an epidemic using the SUSCEPTIBLE-INFECTED-RECOVERED (S-I-R) model.",
            "zh": "一个简单的马尔可夫过程，使用易感-感染-康复 （S-I-R） 模型对流行病期间个体传染病的演变进行建模。"
        }
    },
    {
        "translation": {
            "en": "We use bold notation P() to distinguish between a probability distribution and a probability function P().",
            "zh": "我们使用粗体符号 P（） 来区分概率分布和概率函数 P（）。"
        }
    },
    {
        "translation": {
            "en": "batch gradient descent, 327, 416, 417",
            "zh": "批量梯度下降，327、416、417"
        }
    },
    {
        "translation": {
            "en": "For example, if a feature can take three levels (e.g., low, medium, high), then the vector would have three elements.",
            "zh": "例如，如果一个特征可以采用三个级别（例如，低、中、高），则向量将具有三个元素。"
        }
    },
    {
        "translation": {
            "en": "error-based learning, 19, 311, 599",
            "zh": "基于错误的学习，19,311,599"
        }
    },
    {
        "translation": {
            "en": "On the other hand, if a(i) is much larger than b(i), then di is closer on average to members of another cluster than it is on average to the members of its own cluster, and s(i) will be close to − 1.",
            "zh": "另一方面，如果 a（i） 比 b（i） 大得多，则 di 平均更接近另一个聚类的成员，而不是平均接近其自身聚类的成员，并且 s（i） 将接近 − 1。"
        }
    },
    {
        "translation": {
            "en": "Since 2012, however, several larger convolutional networks have been developed, and new and larger models continue to be announced.",
            "zh": "然而，自 2012 年以来，已经开发了几个更大的卷积网络，并且不断宣布新的和更大的模型。"
        }
    },
    {
        "translation": {
            "en": "Applying the chain rule again to the partial derivative part of this equation, and remembering that , we get",
            "zh": "再次将链式法则应用于该方程的偏导数部分，并记住这一点，我们得到"
        }
    },
    {
        "translation": {
            "en": "7.11   (a) A surface showing the value of Equation (7.23)[339] for all values of RPM and VIBRATION, with the decision boundary given in Equation (7.23)[339] highlighted; and (b) the same surface linearly thresholded at zero to operate as a predictor.",
            "zh": "7.11 （a） 显示所有RPM和VIBRATION值的公式（7.23）[339]的表面，并突出显示公式（7.23）[339]中给出的决定边界;（b）同一曲面线性阈值为零，可作为预测变量。"
        }
    },
    {
        "translation": {
            "en": "Euclidean distance, 185, 200, 231, 237, 577, 601, 602, 620, 631, 632, 636, 731",
            "zh": "欧几里得距离， 185， 200， 231， 237， 577， 601， 602， 620， 631， 632， 636， 731"
        }
    },
    {
        "translation": {
            "en": "Very large or very small values simply end up in the highest or lowest bin.",
            "zh": "非常大或非常小的值最终都会进入最高或最低的箱中。"
        }
    },
    {
        "translation": {
            "en": "This generative versus discriminative distinction is more than just a labeling exercise. Generative and discriminative models learn different concepts. In probabilistic terms, using d to represent the vector of descriptive feature values and tl to represent a target level, a generative model works by",
            "zh": "这种生成性与歧视性的区别不仅仅是一种标签练习。生成模型和判别模型学习不同的概念。在概率术语中，使用 d 表示描述性特征值的向量，使用 tl 表示目标水平，生成模型的工作原理是"
        }
    },
    {
        "translation": {
            "en": "This stability in the internal dynamics of the network, particularly with respect to the gradients, is likely to result in the network learning much faster than networks affected by vanishing or exploding gradients, and it is a result of careful weight initialization.",
            "zh": "网络内部动态的这种稳定性，特别是关于梯度的稳定性，可能导致网络学习速度比受梯度消失或爆炸影响的网络快得多，这是仔细的权重初始化的结果。"
        }
    },
    {
        "translation": {
            "en": "The basic data requirements for predictive models are surprisingly simple.",
            "zh": "预测模型的基本数据要求非常简单。"
        }
    },
    {
        "translation": {
            "en": "In this approach an agent is deployed into the world and acts sequentially, observing the state of the world and taking actions that move it to new states and generate reward.",
            "zh": "在这种方法中，智能体被部署到世界中并按顺序行动，观察世界的状态并采取行动将其移动到新的状态并产生奖励。"
        }
    },
    {
        "translation": {
            "en": "For example, in a model that is sensitive to the relative size of the feature values, a feature that was measured in millimeters would have a larger effect on the resulting model predictions than a feature that was measured in meters.14 Clearly we need to address this issue.",
            "zh": "例如，在对特征值的相对大小敏感的模型中，以毫米为单位测量的特征比以米为单位的特征对最终模型预测的影响更大。14 显然，我们需要解决这个问题。"
        }
    },
    {
        "translation": {
            "en": "(a) Cumulative gain, (b) lift, and (c) cumulative lift charts for the predictions made on the large test data sample.",
            "zh": "（a） 对大型测试数据样本进行预测的累积增益、（b） 提升和 （c） 累积提升图。"
        }
    },
    {
        "translation": {
            "en": "Table 13.11",
            "zh": "表 13.11"
        }
    },
    {
        "translation": {
            "en": "4. Sometimes, the variance of a feature, σ2, rather than its standard deviation, σ, is listed as the parameter for the normal distribution. In this text we always use the standard deviation σ.",
            "zh": "4. 有时，特征的方差 σ2 而不是其标准差 σ 被列为正态分布的参数。在本文中，我们始终使用标准差σ。"
        }
    },
    {
        "translation": {
            "en": "He et al.",
            "zh": "他等人。"
        }
    },
    {
        "translation": {
            "en": "This process is illustrated in Figure 10.12(e)[621].",
            "zh": "该过程如图10.12（e）[621]所示。"
        }
    },
    {
        "translation": {
            "en": "Fundamentally, the nearest neighbor algorithm is a set of local models, each defined using a single instance.",
            "zh": "从根本上说，最近邻算法是一组局部模型，每个模型都使用单个实例定义。"
        }
    },
    {
        "translation": {
            "en": "Decision trees are also discriminative models.",
            "zh": "决策树也是判别模型。"
        }
    },
    {
        "translation": {
            "en": "Real predictive data analytics projects use datasets that are much more complex than those shown in Figure 14.2[737].",
            "zh": "真正的预测数据分析项目使用的数据集比图14.2[737]所示的数据集复杂得多。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the objective functions used by these algorithms are often based on the minimum description length principle, which asserts that the solution with the fewest parameters (shortest description) is the best one.",
            "zh": "因此，这些算法使用的目标函数通常基于最小描述长度原则，该原则断言参数最少（最短描述）的解决方案是最佳解决方案。"
        }
    },
    {
        "translation": {
            "en": "A.5 Example bar plots for the POSITION feature in Table A.1[750]: (a) frequency bar plot, (b) density bar plot, and (c) order density bar plot.",
            "zh": "A.5 表A.1[750]中POSITION特征的示例条形图：（a）频率条形图，（b）密度条形图和（c）阶密度条形图。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.14",
            "zh": "图 3.14"
        }
    },
    {
        "translation": {
            "en": "A plot of the logistic function for values of x in the range [−10, 10] is shown in Figure 7.12(a)[343].",
            "zh": "图7.12（a）[343]显示了[−10,10]范围内x值的逻辑函数图。"
        }
    },
    {
        "translation": {
            "en": "The average number of roaming calls made by the customer each month",
            "zh": "客户每月拨打的平均漫游电话数"
        }
    },
    {
        "translation": {
            "en": "2. The set of features left to test is empty. This means that we have already tested every feature on the path between the root node and the current node. We have no more features we can use to distinguish between the instances, so we return a single leaf node tree with the majority target level of the dataset as its target level (Algorithm 1[134] Lines 3–4).",
            "zh": "2. 剩下的要测试的特征集是空的。这意味着我们已经测试了根节点和当前节点之间路径上的每个特征。我们没有更多的特征可以用来区分实例，因此我们返回一个单叶节点树，其中数据集的大多数目标级别作为其目标级别（算法 1[134] 第 3-4 行）。"
        }
    },
    {
        "translation": {
            "en": "Consequently we require only a two-dimensional filter because all pixel information for an image can be represented in a two-dimensional matrix indexing over the height and width of the grayscale image.",
            "zh": "因此，我们只需要一个二维滤波器，因为图像的所有像素信息都可以在二维矩阵中表示，并在灰度图像的高度和宽度上进行索引。"
        }
    },
    {
        "translation": {
            "en": "Different machine learning algorithms encode different inductive biases.",
            "zh": "不同的机器学习算法编码不同的归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "A small sample of the generators dataset with two features, RPM and VIBRATION, and two target levels, good (shown as crosses) and faulty (shown as triangles): (a) a decision boundary with a very small margin; and (b) a decision boundary with a much larger margin. In both cases, the instances along the margins are highlighted.",
            "zh": "生成器数据集的一个小样本，具有两个特征，RPM 和 VIBRATION，以及两个目标水平，良好（显示为十字）和错误（显示为三角形）：（a） 边际非常小的决策边界;（b）具有更大余地的决策边界。在这两种情况下，边距上的实例都会突出显示。"
        }
    },
    {
        "translation": {
            "en": "Near the end of this chapter we covered support vector machines (SVM).",
            "zh": "在本章接近尾声时，我们介绍了支持向量机 （SVM）。"
        }
    },
    {
        "translation": {
            "en": "Vertical bars | | refer to counts of occurrences (e.g., |a = l| represents the number of times that a = l occurs in a dataset).",
            "zh": "竖杆 | |请参阅出现次数（例如，|a = l| 表示数据集中 a = l 出现的次数）。"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix.",
            "zh": "混淆矩阵的结构。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4(a)[190] illustrates the Voronoi tessellation of the feature space using the training instances from Table 5.2[183] and shows the position of our sample query instance within this decomposition.",
            "zh": "图5.4（a）[190]使用表5.2[183]中的训练实例说明了特征空间的Voronoi细分，并显示了示例查询实例在此分解中的位置。"
        }
    },
    {
        "translation": {
            "en": "single linkage, 619, 620, 635",
            "zh": "单连杆，619、620、635"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across an error surface; and (b) the changing sums of squared errors during this journey.",
            "zh": "（a） 穿越误差面的旅程;（b）在此过程中平方误差和的变化。"
        }
    },
    {
        "translation": {
            "en": "The car can move at three speeds: stationary, slow, and fast.",
            "zh": "汽车可以以三种速度移动：静止、慢速和快速。"
        }
    },
    {
        "translation": {
            "en": "For example, the top row of the matrix shown in Figure 8.4[390] labeled Hidden layer 1 Weight Matrix contains the weights on the connections coming into Neuron 3 in Figure 8.4[390 hence this row has the label 3.",
            "zh": "例如，图 8.4[390] 中所示的矩阵的顶行标记为隐藏层 1 权重矩阵，其中包含图 8.4[390] 中进入神经元 3 的连接上的权重，因此该行具有标签 3。"
        }
    },
    {
        "translation": {
            "en": "Any information reduction process will result in some information loss, and a single measure of model performance will be designed to emphasize some aspects of model performance and de-emphasize, or lose, others.",
            "zh": "任何信息缩减过程都会导致一些信息丢失，并且模型性能的单一度量将被设计为强调模型性能的某些方面，而不强调或丢失其他方面。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.2[119] illustrates the possible question sequences that can follow in a game beginning with Question 2.",
            "zh": "图 4.2[119] 说明了从问题 2 开始的游戏中可能出现的问题序列。"
        }
    },
    {
        "translation": {
            "en": "SCHOOL YEARS refers to the mean number of years spent in school for adult females.",
            "zh": "学龄是指成年女性在校的平均年限。"
        }
    },
    {
        "translation": {
            "en": "violin plot, 451",
            "zh": "小提琴情节，451"
        }
    },
    {
        "translation": {
            "en": "Jocelyn decided to build a second set of models in which she would address the target level imbalance issue.",
            "zh": "Jocelyn 决定建立第二组模型，以解决目标水平不平衡问题。"
        }
    },
    {
        "translation": {
            "en": "The age-income dataset.",
            "zh": "年龄-收入数据集。"
        }
    },
    {
        "translation": {
            "en": "The second issue affecting the feasibility of an analytics solution is the ability of the business to utilize the insight that the solution provides. If a business is required to drastically revise all their processes to take advantage of the insights that can be garnered from a predictive model, the business may not be ready to do this no matter how good the model is. In many cases the best predictive analytics solutions are those that fit easily into an existing business process.",
            "zh": "影响分析解决方案可行性的第二个问题是企业利用解决方案提供的洞察力的能力。如果企业需要大幅修改其所有流程以利用可以从预测模型中获得的见解，那么无论模型有多好，企业都可能还没有准备好这样做。在许多情况下，最好的预测分析解决方案是那些容易适应现有业务流程的解决方案。"
        }
    },
    {
        "translation": {
            "en": "The average number of customer calls dropped each month",
            "zh": "每个月的平均客户电话数量下降"
        }
    },
    {
        "translation": {
            "en": "Chapter 6 of Mitchell (1997) provides an excellent overview of Bayesian learning. Barber (2012) is a more recent machine learning textbook that adopts a Bayesian approach to learning and inference.",
            "zh": "Mitchell（1997）的第6章对贝叶斯学习进行了很好的概述。Barber （2012） 是一本较新的机器学习教科书，采用贝叶斯方法来学习和推理。"
        }
    },
    {
        "translation": {
            "en": "BLOOD",
            "zh": "血"
        }
    },
    {
        "translation": {
            "en": "to the much simpler",
            "zh": "到更简单"
        }
    },
    {
        "translation": {
            "en": "Treatment Group",
            "zh": "治疗组"
        }
    },
    {
        "translation": {
            "en": "12.5   A pruned decision tree built for the AT churn prediction problem. Gray leaf nodes indicate a churn prediction, and clear leaf nodes indicate a non-churn prediction. For space reasons, we show only the features tested at the top-level nodes.",
            "zh": "12.5 针对 AT 流失预测问题构建的修剪决策树。灰叶节点表示流失预测，清除叶节点表示非流失预测。由于篇幅原因，我们只显示在顶级节点上测试的功能。"
        }
    },
    {
        "translation": {
            "en": "type II errors, 538",
            "zh": "类型 II 错误，538"
        }
    },
    {
        "translation": {
            "en": "We can say that this model is consistent with the dataset because there are no instances in the dataset for which the model does not make a correct prediction. When new mortgage applications are made, we can use this model to predict whether the applicant will repay the mortgage or default on it and make lending decisions on the basis of this prediction.",
            "zh": "我们可以说这个模型与数据集是一致的，因为数据集中没有模型没有做出正确预测的实例。当提出新的抵押贷款申请时，我们可以使用这个模型来预测申请人是偿还抵押贷款还是违约，并根据这个预测做出贷款决定。"
        }
    },
    {
        "translation": {
            "en": "Figure A.2(b)[746] shows the extended basketball team ordered from smallest to tallest, with the height of the each player listed below the player. The median value of this set is 150 and is shown as the dashed gray line in Figure A.2(b)[746]. In this case the median better captures the central tendency of the set of values.",
            "zh": "图A.2（b）[746]显示了从小到高的扩展篮球队，每个球员的身高列在球员的下方。该集合的中值为150，在图A.2（b）[746]中显示为灰色虚线。在这种情况下，中位数更好地捕捉了值集的中心趋势。"
        }
    },
    {
        "translation": {
            "en": "8.2   Fundamentals",
            "zh": "8.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "If, however, a neuron used a different activation function, then we would use the derivative of that function when we are calculating ∂ak/∂zk; however, we would do so in the same way, by plugging the zk value into the derivative.",
            "zh": "但是，如果神经元使用不同的激活函数，那么我们在计算 ∂ak/∂zk;但是，我们将以相同的方式执行此操作，方法是将 ZK 值代入导数中。"
        }
    },
    {
        "translation": {
            "en": "The bar plot on the left shows the distribution of the different levels of the CAREER STAGE feature across the entire dataset.",
            "zh": "左侧的条形图显示了 CAREER STAGE 特征不同级别的分布在整个数据集中的分布。"
        }
    },
    {
        "translation": {
            "en": "A value near 1 indicates that the corresponding element of the cell state should be updated, and a value near 0 indicates that the corresponding element of the cell state should be preserved as is.",
            "zh": "接近 1 的值表示应更新单元格状态的相应元素，接近 0 的值表示单元格状态的相应元素应按原样保留。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.13",
            "zh": "图 9.13"
        }
    },
    {
        "translation": {
            "en": "where γ is a discount rate and is a value in [0,1]. This implements an exponential discounting so that future expected rewards have less and less impact on the value calculated for an action. Choosing a low value for γ makes the action-value function focus heavily on the most immediate rewards. For example, with γ = 0.1",
            "zh": "其中 γ 是贴现率，是 [0,1] 中的值。这实现了指数折扣，因此未来的预期奖励对为操作计算的价值的影响越来越小。为γ选择低值会使行动价值函数主要关注最直接的奖励。例如，γ = 0.1"
        }
    },
    {
        "translation": {
            "en": "interval data, 34",
            "zh": "区间数据，34"
        }
    },
    {
        "translation": {
            "en": "One of the most common uses of a validation set is to avoid overfitting when using machine learning algorithms that iteratively build more and more complex models.",
            "zh": "验证集最常见的用途之一是在使用以迭代方式构建越来越复杂的模型的机器学习算法时避免过度拟合。"
        }
    },
    {
        "translation": {
            "en": "The calculations for the weighted k nearest neighbor prediction.",
            "zh": "加权 k 最近邻预测的计算。"
        }
    },
    {
        "translation": {
            "en": "There are two levels in the target feature domain, four levels in the CREDIT HISTORY domain, three in the GUARANTOR/COAPPLICANT domain, and three in the ACCOMMODATION domain.",
            "zh": "目标特征域中有两个级别，信用记录域中有四个级别，担保人/共同申请人域中有三个级别，ACCOMMODATION域中有三个级别。"
        }
    },
    {
        "translation": {
            "en": "As long as both the treatment group and the control group are representative of the overall population, at the end of the trial period, the doctors running the trial can be confident that any improvement they see in the patients in the treatment group that they do not see in the control group is due to the new medicine.",
            "zh": "只要治疗组和对照组都代表了整个人群，在试验期结束时，进行试验的医生可以确信，他们在治疗组患者身上看到的任何改善，他们在对照组中没有看到，都是由于新药。"
        }
    },
    {
        "translation": {
            "en": "1. Compute the entropy of the original dataset with respect to the target feature. This gives us a measure of how much information is required to organize the dataset into pure sets.",
            "zh": "1. 计算原始数据集相对于目标特征的熵。这为我们提供了将数据集组织成纯集所需的信息量度。"
        }
    },
    {
        "translation": {
            "en": "graphical models, 304, 742",
            "zh": "图形模型，304,742"
        }
    },
    {
        "translation": {
            "en": "guided search, 274, 319, 321",
            "zh": "引导式搜索， 274， 319， 321"
        }
    },
    {
        "translation": {
            "en": "For example, recall Neuron 4 in the ReLU network in Section 8.4.1[434 this neuron was inactive for all the input examples and so the weights of the neuron would never be updated, and it was therefore stuck in this dead state.",
            "zh": "例如，回想一下第 8.4.1 节中 ReLU 网络中的神经元 4[434 该神经元在所有输入示例中都处于非活动状态，因此神经元的权重永远不会更新，因此它处于这种死状态。"
        }
    },
    {
        "translation": {
            "en": "The point on the error surface at which the partial derivatives with respect to w[0] and w[1] are equal to 0 is simply the point at the very bottom of the bowl defined by the error surface—there is no slope at the bottom of the bowl.",
            "zh": "误差曲面上相对于 w[0] 和 w[1] 的偏导数等于 0 的点就是由误差曲面定义的碗最底部的点，即碗底部没有斜率。"
        }
    },
    {
        "translation": {
            "en": "13.3   Data Preparation",
            "zh": "13.3 数据准备"
        }
    },
    {
        "translation": {
            "en": "The next section describes one of the most important of these, temporal-difference learning.",
            "zh": "下一节将介绍其中最重要的一种，即时间差分学习。"
        }
    },
    {
        "translation": {
            "en": "This model will be used to target the marketing campaign only to those customers who are most likely to purchase the pension product.",
            "zh": "该模型将用于仅针对最有可能购买养老金产品的客户进行营销活动。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23[453] illustrates the internal dynamics of the network shown in Figure 8.22[450] during the first iteration of training if we initialize the weights of the network by sampling from a normal distribution with μ = 0.0 and σ = 0.01 and pass our 100 examples through the network as a single mini-batch.",
            "zh": "图 8.23[453] 说明了图 8.22[450] 所示的网络内部动力学，如果我们通过从 μ = 0.0 和 σ = 0.01 的正态分布中采样来初始化网络的权重，并将我们的 100 个示例作为单个小批量通过网络传递。"
        }
    },
    {
        "translation": {
            "en": "8.29   An illustration of how different small networks are generated for different training examples by applying dropout to the original large network.",
            "zh": "8.29 举例说明如何通过对原来的大型网络应用dropout，为不同的训练实例生成不同的小型网络。"
        }
    },
    {
        "translation": {
            "en": "We can capture the full dynamics of the TwentyTwos MDP in a pair of transition matrices, one for each possible action. For the Twist action the structure of the state transition matrix, 𝒫Twist, is",
            "zh": "我们可以在一对过渡矩阵中捕获 TwentyTwos MDP 的完整动态，每个可能的动作一个。对于 Twist 动作，状态转换矩阵 PTwist 的结构为"
        }
    },
    {
        "translation": {
            "en": "Figure 7.21[360] shows the training sequence for a multinomial logistic regression model trained using this data (after the data had been range normalized to [−1, 1]).",
            "zh": "图 7.21[360] 显示了使用此数据训练的多项式逻辑回归模型的训练序列（在数据范围归一化为 [−1， 1] 之后）。"
        }
    },
    {
        "translation": {
            "en": "Notice as well that the distribution of the z and δ values is relatively stable across the layers (see Figure 8.26(b)[462] and Figure 8.26(d)[462]).",
            "zh": "还要注意的是，z和δ值在各层中的分布相对稳定（参见图8.26（b）[462]和图8.26（d）[462]）。"
        }
    },
    {
        "translation": {
            "en": "As a result, we simply need to define two PDFs for the new feature with each PDF conditioned on a different level of the target feature: P(AB = x | fr) = PDF1(AB = x | fr) and P(AB = x | ¬fr) = PDF2(AB = x | ¬fr).",
            "zh": "因此，我们只需要为新功能定义两个 PDF，每个 PDF 都以目标功能的不同级别为条件：P（AB = x | fr） = PDF1（AB = x | fr） 和 P（AB = x | ¬fr） = PDF2（AB = x | ¬fr）。"
        }
    },
    {
        "translation": {
            "en": "For this discussion it may be useful to quickly refer to Figure (4.6)[125] to see a plot of how the negative log of a probability changes as the probability changes (Figure (4.6)[125] shows this plot for binary logs, but the general shape of the plot is similar for natural logs).",
            "zh": "对于这个讨论，快速参考图（4.6）[125]，查看概率的负对数如何随概率变化的图（图（4.6）[125]显示了二进制对数的图，但图的一般形状与自然对数相似）。"
        }
    },
    {
        "translation": {
            "en": "In Figure 2.3[32] the domain concepts Claimant History and Claimant Links have both been broken down into a number of domain subconcepts.",
            "zh": "在图2.3[32]中，域名概念“索赔人历史”和“域名链接”都被分解为许多域名子概念。"
        }
    },
    {
        "translation": {
            "en": "More recently, hash-based indexes, such as locality sensitive hashing, have been developed.",
            "zh": "最近，基于哈希的索引（例如位置敏感哈希）已经开发出来。"
        }
    },
    {
        "translation": {
            "en": "Also shown are the resulting TPR, TNR, FPR, and FNR values, as well as the misclassification rate for each threshold.",
            "zh": "此外，还显示了生成的 TPR、TNR、FPR 和 FNR 值，以及每个阈值的错误分类率。"
        }
    },
    {
        "translation": {
            "en": "This index ignores co-absences and is defined as the ratio between the number of co-presences and the total number of features, excluding those that record a co-absence between a pair of instances:18",
            "zh": "此索引忽略共缺，定义为共存数量与要素总数之间的比率，不包括记录一对实例之间共缺的特征：18"
        }
    },
    {
        "translation": {
            "en": "The Lunar Lander environment. The aim of the game is to control the spaceship starting from the top of the world and attempting to land on the landing pad.",
            "zh": "月球着陆器环境。游戏的目的是控制宇宙飞船从世界之巅开始，试图降落在着陆台上。"
        }
    },
    {
        "translation": {
            "en": "Even worse, because there are no rows in the dataset where f, h, and m are true, there are no rows in the dataset where the conditions for the third term P(¬v | f,h,m) hold, so this probability is actually undefined, as calculating it involves a division by zero.",
            "zh": "更糟糕的是，由于数据集中没有 f、h 和 m 为真的行，数据集中没有第三项 P（¬v | f，h，m） 条件成立的行，因此该概率实际上是未定义的，因为计算它涉及除以零。"
        }
    },
    {
        "translation": {
            "en": "On the other hand, a model built to predict which customers would be most likely to respond to an online ad only needs to do a slightly better than random job of selecting those customers that will actually respond in order to make a profit for the company.",
            "zh": "另一方面，一个模型是为了预测哪些客户最有可能对在线广告做出反应，只需要比随机选择那些实际响应的客户稍微好一点，以便为公司创造利润。"
        }
    },
    {
        "translation": {
            "en": "Remember that d[0] is a dummy descriptive feature, added to match w[0], with a value of 1 for all training instances.",
            "zh": "请记住，d[0] 是一个虚拟描述性特征，添加以匹配 w[0]，所有训练实例的值均为 1。"
        }
    },
    {
        "translation": {
            "en": "The two-stage model achieved a classification accuracy of 79.410%.",
            "zh": "两阶段模型的分类准确率为79.410%。"
        }
    },
    {
        "translation": {
            "en": "2. Wyh containing the weights for the connections between the hidden layer (h) and the output layer (y); and",
            "zh": "2. Wyh 包含隐藏层 （h） 和输出层 （y） 之间连接的权重;和"
        }
    },
    {
        "translation": {
            "en": "Minkowski distance, 185, 186",
            "zh": "闵可夫斯基距离，185,186"
        }
    },
    {
        "translation": {
            "en": "In this example the test dataset is quite imbalanced, containing 90 instances with the non-churn level and just 10 instances with the churn level.",
            "zh": "在此示例中，测试数据集非常不平衡，包含 90 个具有非流失级别的实例，而只有 10 个具有流失级别的实例。"
        }
    },
    {
        "translation": {
            "en": "Based on historical examples, the expected loss in this case, referred to as the loss given default, is $700 (most borrowers will repay some of their loan before defaulting).",
            "zh": "根据历史示例，在这种情况下，预期损失（称为违约损失）为 700 美元（大多数借款人会在违约前偿还部分贷款）。"
        }
    },
    {
        "translation": {
            "en": "We can see that when the car is driving at a constant speed, on the minor road or the highway, acceleration is zero as the speed is not changing.",
            "zh": "我们可以看到，当汽车以恒定速度行驶时，在小路或高速公路上，由于速度不变，加速度为零。"
        }
    },
    {
        "translation": {
            "en": "34. The data listed in this table is real and is for 2010/11 (or the most recent year prior to 2010/11 when the data was available). The data for the descriptive features in this table was amalgamated from a number of surveys retrieved from Gapminder (www.gapminder.org). The Corruption Perception Index is generated annually by Transparency International (www.transparency.org).",
            "zh": "34. 本表所列数据为实数，为2010/11年度（或2010/11年度之前有数据的最近一年）。该表中描述性特征的数据是从Gapminder（www.gapminder.org）检索到的一些调查中合并的。清廉指数由透明国际（www.transparency.org）每年发布。"
        }
    },
    {
        "translation": {
            "en": "Deep neural networks can contain millions of neurons.",
            "zh": "深度神经网络可以包含数百万个神经元。"
        }
    },
    {
        "translation": {
            "en": "This graph shows that the agent’s performance initially declined, and it started to perform quite badly, until after about 40 episodes its performance began to improve.",
            "zh": "这张图显示，特工的表现最初有所下降，并且开始表现得很差，直到大约 40 集后，它的表现开始改善。"
        }
    },
    {
        "translation": {
            "en": "For this reason, and based on discussions with the AT team, Ross included the BILL CHANGE and SOCIAL NETWORK CHANGE domain concepts.",
            "zh": "出于这个原因，在与AT团队的讨论中，Ross加入了BILL CHANGE和SOCIAL NETWORK CHANGE领域的概念。"
        }
    },
    {
        "translation": {
            "en": "This ensures that the dummy descriptive feature (row 0) will be multiplied by the bias terms weights (column 0) in the multiplication operation.",
            "zh": "这可确保在乘法运算中将虚拟描述特征（第 0 行）乘以偏差项权重（第 0 列）。"
        }
    },
    {
        "translation": {
            "en": "An auto-encoder model can be trained like any other feedforward neural network using the backpropagation of error algorithm.11 The only difference is that rather than having a separate target feature vector against which loss is measured, the loss functions used to train these measure the ability of the network to reproduce the inputs for particular instances at its output layer.",
            "zh": "自动编码器模型可以像任何其他前馈神经网络一样使用误差反向传播算法进行训练.11 唯一的区别是，用于训练这些特征的损失函数测量网络在其输出层重现特定实例输入的能力，而不是具有用于测量损失的单独目标特征向量。"
        }
    },
    {
        "translation": {
            "en": "Notice that the tree uses a mixture of continuous and categorical features and that the ELEVATION feature is used twice with different thresholds in each case.",
            "zh": "请注意，该树混合使用连续要素和分类要素，并且 ELEVATION 要素在每种情况下都使用两次，阈值不同。"
        }
    },
    {
        "translation": {
            "en": "The first is that the distribution we are sampling from must be a stationary distribution (also known as an invariant distribution).",
            "zh": "首先，我们从中采样的分布必须是平稳分布（也称为不变分布）。"
        }
    },
    {
        "translation": {
            "en": "logistic function, 342, 386, 461",
            "zh": "逻辑功能，342,386,461"
        }
    },
    {
        "translation": {
            "en": "The continuing process that finds the final model is illustrated in Figure 7.15[350], which shows a selection of the candidate models generated on the way to generating the final model, and the bottom-right panel shows how the sum of squared errors changed during the process.",
            "zh": "图 7.15[350] 说明了找到最终模型的连续过程，该过程显示了在生成最终模型的过程中生成的候选模型的选择，右下角的面板显示了在此过程中平方误差的总和如何变化。"
        }
    },
    {
        "translation": {
            "en": "In modern reinforcement learning, however, iterative approaches that calculate approximate solutions are typically used.",
            "zh": "然而，在现代强化学习中，通常使用计算近似解的迭代方法。"
        }
    },
    {
        "translation": {
            "en": "An examination of the histogram for the INCOME feature (shown in Figure 3.1(a)[58]) and the actual data for this feature in Table 3.2[56] reveals an interesting pattern.",
            "zh": "对INCOME特征的直方图（如图3.1（a）[58]所示）和表3.2[56]中该特征的实际数据的检查揭示了一个有趣的模式。"
        }
    },
    {
        "translation": {
            "en": "463.00",
            "zh": "463.00"
        }
    },
    {
        "translation": {
            "en": "Figure 7.15",
            "zh": "图 7.15"
        }
    },
    {
        "translation": {
            "en": "Wooldridge, Michael. 2009. An introduction to multiagent systems. Wiley.",
            "zh": "伍尔德里奇，迈克尔。2009. 多智能体系统简介.威利。"
        }
    },
    {
        "translation": {
            "en": "In these cases, unless the dimensionality is maintained by using imaginary pixels, then the dimensionality of the input to each layer reduces for each subsequent layer.",
            "zh": "在这些情况下，除非通过使用虚构像素来保持维数，否则每个层的输入维数都会在每个后续层中减小。"
        }
    },
    {
        "translation": {
            "en": "The ROC index can be interpreted probabilistically as the probability that a model will assign a higher rank to a randomly selected positive instance than to a randomly selected negative instance.16 The Gini coefficient17 is another commonly used performance measure that is just a linear rescaling of the ROC index:",
            "zh": "ROC 指数可以概率地解释为模型为随机选择的正实例分配比随机选择的负实例更高的排名的概率.16 基尼系数 17 是另一种常用的绩效衡量标准，它只是 ROC 指数的线性重新调整："
        }
    },
    {
        "translation": {
            "en": "Another useful property of ez is that e0 is 1; as a result, even in the unlikely event that all the zs are 0, we avoid the problem of a division by 0, and each neuron will have an activation of 1/m.",
            "zh": "ez 的另一个有用属性是 e0 是 1;因此，即使在所有 z 都为 0 的不太可能的情况下，我们也避免了除以 0 的问题，并且每个神经元的激活度为 1/m。"
        }
    },
    {
        "translation": {
            "en": "For this model, just 31 out of the total 327 features were selected.16 This was not surprising given the large amount of redundancy within the feature set.",
            "zh": "对于此模型，总共 327 个功能中只有 31 个被选中。16 考虑到功能集中的大量冗余，这并不奇怪。"
        }
    },
    {
        "translation": {
            "en": "The basic normalization technique we introduced was range normalization,15 and we can apply it to the pension plan prediction dataset to normalize the variance in the SALARY and AGE features.",
            "zh": "我们引入的基本归一化技术是范围归一化，15 我们可以将其应用于养老金计划预测数据集，以归一化 SALARY 和 AGE 特征中的方差。"
        }
    },
    {
        "translation": {
            "en": "(a) How many possible models exist for the scenario described by the features in this dataset?",
            "zh": "（a） 对于本数据集中的特征所描述的情景，有多少种可能的模型？"
        }
    },
    {
        "translation": {
            "en": "For example, consider a mobile phone network operator that has built a churn prediction model to help address a problem with customers leaving to join other networks.",
            "zh": "例如，假设移动电话网络运营商已经构建了一个客户流失预测模型，以帮助解决客户离开加入其他网络的问题。"
        }
    },
    {
        "translation": {
            "en": "In machine learning terms, each row in the dataset is referred to as a training instance, and the overall dataset is referred to as a training dataset.",
            "zh": "在机器学习术语中，数据集中的每一行都称为训练实例，整个数据集称为训练数据集。"
        }
    },
    {
        "translation": {
            "en": "0.28",
            "zh": "0.28"
        }
    },
    {
        "translation": {
            "en": "A simple heuristic that is sometimes used to try to avoid dead ReLUs is to initialize all the bias weights of a network to small positive values, such as 0.1, because this increases the likelihood that most of the neurons will initially be active for most of the training examples and so these neurons can learn from these examples (Goodfellow et al., 2016, p. 187).",
            "zh": "有时用于尝试避免死 ReLU 的简单启发式方法是将网络的所有偏差权重初始化为小的正值，例如 0.1，因为这增加了大多数神经元最初在大多数训练示例中处于活动状态的可能性，因此这些神经元可以从这些示例中学习（Goodfellow 等人， 2016 年，第 187 页）。"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 6.4(b)[273] has a fat tail distribution—the bars on the extreme left and right of the distribution are still above zero, if only just.",
            "zh": "图6.4（b）[273]中的数据集具有肥尾分布，即分布最左边和最右边的条形仍然高于零，即使只是零。"
        }
    },
    {
        "translation": {
            "en": "A simple retail dataset.",
            "zh": "一个简单的零售数据集。"
        }
    },
    {
        "translation": {
            "en": "The XGBoost (Chen and Guestrin, 2016) gradient boosting implementation played a significant role in popularizing the approach and is a good example of how the basic algorithm can be optimized for performance.",
            "zh": "XGBoost （Chen and Guestrin， 2016） 梯度提升实现在普及该方法方面发挥了重要作用，并且是一个很好的例子，说明如何优化基本算法以提高性能。"
        }
    },
    {
        "translation": {
            "en": "For all models w[0] is set to 6.47.",
            "zh": "对于所有型号，w[0] 设置为 6.47。"
        }
    },
    {
        "translation": {
            "en": "The backpropagation of the δ values during the backward pass of the backpropagation algorithm. This figure is based on Figure 6.6 of Kelleher (2019).",
            "zh": "反向传播算法向后传递期间δ值的反向传播。该数字基于Kelleher（2019）的图6.6。"
        }
    },
    {
        "translation": {
            "en": "experimental design, 586",
            "zh": "实验设计，586"
        }
    },
    {
        "translation": {
            "en": "Figure 8.10",
            "zh": "图 8.10"
        }
    },
    {
        "translation": {
            "en": "He would have no opportunity to exploit the knowledge he established in the first week about the rewards associated with ordering different items.",
            "zh": "他将没有机会利用他在第一周建立的关于订购不同物品的奖励的知识。"
        }
    },
    {
        "translation": {
            "en": "A joint probability refers to the probability of an assignment of specific values to multiple different features, for example, P(MENINGITIS = true,HEADACHE = true) = 0.2.",
            "zh": "联合概率是指将特定值分配给多个不同特征的概率，例如，P（MENINGITIS = true，HEADACHE = true） = 0.2。"
        }
    },
    {
        "translation": {
            "en": "give the number of times a training instance was included in the training set sampled using the sampling distribution.",
            "zh": "给出使用抽样分布采样的训练集中包含训练实例的次数。"
        }
    },
    {
        "translation": {
            "en": "This reduction of a network to a single weight matrix by using a matrix product can be done no matter how many layers there are in a network, so long as none of the network layers includes non-linear activation functions.",
            "zh": "无论网络中有多少层，只要网络层中没有一个包含非线性激活函数，就可以通过使用矩阵乘积将网络简化为单个权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "With this extended network architecture, the question arises of how we will initialize the weights.",
            "zh": "有了这种扩展的网络架构，问题就出现了，我们将如何初始化权重。"
        }
    },
    {
        "translation": {
            "en": "Tabulating the workings required to generate a K-S statistic.",
            "zh": "将生成 K-S 统计量所需的工作制成表格。"
        }
    },
    {
        "translation": {
            "en": "12.5 Evaluation",
            "zh": "12.5 评估"
        }
    },
    {
        "translation": {
            "en": "0.13",
            "zh": "0.13"
        }
    },
    {
        "translation": {
            "en": "5.8 Exercises",
            "zh": "5.8 练习"
        }
    },
    {
        "translation": {
            "en": "In other words, the updates applied to a weight are a function of the δ for the neuron that uses the weight in its weighted sum.",
            "zh": "换句话说，应用于权重的更新是神经元的δ函数，该神经元在其加权总和中使用权重。"
        }
    },
    {
        "translation": {
            "en": "summary statistics, 96",
            "zh": "汇总统计，96"
        }
    },
    {
        "translation": {
            "en": "The final prediction is then made by taking the feature level whose neuron predicts the highest probability.",
            "zh": "然后通过获取其神经元预测最高概率的特征级别来做出最终预测。"
        }
    },
    {
        "translation": {
            "en": "The net result is that the vanishing gradient problem can cause deep networks to take a very long time to train.",
            "zh": "最终结果是，梯度消失问题可能导致深度网络需要很长时间来训练。"
        }
    },
    {
        "translation": {
            "en": "2. Note that in a density histogram, the height of each bar represents the likelihood that a value in the range defining that bar will occur in a data sample (see Section A.4.2[752]).",
            "zh": "2. 请注意，在密度直方图中，每个柱的高度表示定义该柱的范围内的值出现在数据样本中的可能性（参见第 A.4.2[752] 节）。"
        }
    },
    {
        "translation": {
            "en": "Bayes’ Theorem defines the conditional probability of an event, X, given some evidence, Y, in terms of the product of the inverse conditional probability, P(Y | X), and the prior probability of the event P(X).",
            "zh": "贝叶斯定理根据逆条件概率 P（Y |X）和事件P（X）的先验概率。"
        }
    },
    {
        "translation": {
            "en": "The information theory basis for this function can be seen in the similarity between Equation (8.66)[465] and the equation for Shannon’s entropy, Equation (4.1)[125].",
            "zh": "该函数的信息论基础可以从方程（8.66）[465]和香农熵方程（4.1）[125]之间的相似性中看出。"
        }
    },
    {
        "translation": {
            "en": "Let’s now make a prediction using this model for a two-year-old bottle of whiskey that received a magazine rating of 5.",
            "zh": "现在让我们使用这个模型对一瓶两年前的威士忌进行预测，该威士忌的杂志评分为 5。"
        }
    },
    {
        "translation": {
            "en": "An unpruned decision tree built for the AT churn prediction problem (shown only to indicate its size and complexity). The excessive complexity and depth of the tree are evidence that overfitting has probably occurred.",
            "zh": "为 AT 流失预测问题构建的未修剪决策树（显示仅用于指示其大小和复杂性）。树的过度复杂性和深度是可能发生过拟合的证据。"
        }
    },
    {
        "translation": {
            "en": "The information gain model we have developed allows us to decide which test we should add to the sequence next because it enables us to select the best feature to use on a given dataset.",
            "zh": "我们开发的信息增益模型允许我们决定接下来应该将哪个测试添加到序列中，因为它使我们能够选择要在给定数据集上使用的最佳特征。"
        }
    },
    {
        "translation": {
            "en": "Frequencies and proportions are typically presented in a frequency table, which shows the frequency and proportion of each level for a particular feature—usually sorted by descending frequency.",
            "zh": "频率和比例通常显示在频率表中，该表显示特定特征的每个电平的频率和比例，通常按降序排序。"
        }
    },
    {
        "translation": {
            "en": "This is the opposite of the prediction made using the original dataset.",
            "zh": "这与使用原始数据集做出的预测相反。"
        }
    },
    {
        "translation": {
            "en": "The learning challenges raised by the second point in the preceding list highlight the main motivation for using networks with more than one hidden layer.",
            "zh": "前面列表中的第二点提出的学习挑战突出了使用具有多个隐藏层的网络的主要动机。"
        }
    },
    {
        "translation": {
            "en": "Figure A.7",
            "zh": "图 A.7"
        }
    },
    {
        "translation": {
            "en": "Ashenfelter, Orley. 2008. Predicting the quality and prices of bordeaux wine. The Economic Journal 118 (529): 174–184. doi:10.1111/j.1468-0297.2008.02148.x.",
            "zh": "阿申费尔特，奥利。2008. 预测波尔多葡萄酒的质量和价格。经济杂志118（529）：174-184。doi：10.1111/j.1468-0297.2008.02148.x."
        }
    },
    {
        "translation": {
            "en": "This is shown in Figure 11.5(e)[663].",
            "zh": "如图11.5（e）[663]所示。"
        }
    },
    {
        "translation": {
            "en": "Essentially, the dendrites are the neuron’s input channels, and the axon is the output channel.",
            "zh": "从本质上讲，树突是神经元的输入通道，轴突是输出通道。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.8",
            "zh": "图 6.8"
        }
    },
    {
        "translation": {
            "en": "The agent performs this action (Line 13[658]), moving to the left, and records the next state, s1 = 0-2, and the reward received, r0 = −1.",
            "zh": "代理执行此操作（第 13 行 [658]），向左移动，并记录下一个状态 s1 = 0-2 和收到的奖励 r0 = −1。"
        }
    },
    {
        "translation": {
            "en": "18. Multinomial logistic regression models are often known as maximum entropy, conditional maximum entropy, or MaxEnt models.",
            "zh": "18. 多项式逻辑回归模型通常被称为最大熵、条件最大熵或 MaxEnt 模型。"
        }
    },
    {
        "translation": {
            "en": "weighted k nearest neighbor, 194, 209, 237, 238",
            "zh": "加权 k 最近邻， 194， 209， 237， 238"
        }
    },
    {
        "translation": {
            "en": "Long Hair",
            "zh": "長髮"
        }
    },
    {
        "translation": {
            "en": "If a model could be trained to classify brain activity as being associated with positive images or negative images, doctors could use this model to help in assessing the brain function of people who have suffered severe brain injuries and are non-communicative.16 Figure 7.18[355] shows a scatter plot of this dataset, from which it is clear that the decision boundary between the two different types of images is not linear—that is, the two types of images are not linearly separable.",
            "zh": "如果可以训练一个模型将大脑活动分类为与正面图像或负面图像相关，医生可以使用该模型来帮助评估遭受严重脑损伤且无法交流的人的大脑功能.16图7.18[355]显示了该数据集的散点图，从中可以清楚地看出，两种不同类型的图像之间的决策边界不是线性的，即 这两种类型的图像不是线性可分离的。"
        }
    },
    {
        "translation": {
            "en": "exploitation, 655, 656",
            "zh": "剥削， 655， 656"
        }
    },
    {
        "translation": {
            "en": "Consequently, understanding and exploring the data sources related to each domain concept that are available within an organization is a fundamental component of feature design.",
            "zh": "因此，了解和探索与组织内可用的每个领域概念相关的数据源是功能设计的基本组成部分。"
        }
    },
    {
        "translation": {
            "en": "Based on this data, calculate the following summary statistics for the AGE feature:",
            "zh": "根据此数据，计算 AGE 要素的以下汇总统计量："
        }
    },
    {
        "translation": {
            "en": "For propensity modeling, there are two key periods: the observation period, over which descriptive features are calculated, and the outcome period, over which the target feature is calculated.3",
            "zh": "对于倾向建模，有两个关键时期：观察期（计算描述性特征）和结果期（计算目标特征）3。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn also made the decision to normalize all the descriptive features into standard scores.The differences in the ranges of values of the set of descriptive features in the ABT was huge.",
            "zh": "Jocelyn 还决定将所有描述性特征规范化为标准分数。ABT中描述性特征集的值范围差异很大。"
        }
    },
    {
        "translation": {
            "en": "1. A test statistic is computed.",
            "zh": "1. 计算检验统计量。"
        }
    },
    {
        "translation": {
            "en": "In fact, these proofs fail if the neurons are restricted to using smooth functions.",
            "zh": "事实上，如果神经元被限制为使用平滑函数，这些证明就会失败。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn showed these charts to Edwin.",
            "zh": "乔斯林把这些图表拿给埃德温看。"
        }
    },
    {
        "translation": {
            "en": "The arithmetic mean for the full group is now 158.222cm and, as shown by the dashed gray line in Figure A.2(a)[746], no longer really represents the central tendency of the group.",
            "zh": "整个组的算术平均值现在是158.222厘米，如图A.2（a）[746]中的灰色虚线所示，不再真正代表该组的中心趋势。"
        }
    },
    {
        "translation": {
            "en": "dynamic programming, 653, 677",
            "zh": "动态规划， 653， 677"
        }
    },
    {
        "translation": {
            "en": "5.2   Fundamentals",
            "zh": "5.2 基础"
        }
    },
    {
        "translation": {
            "en": "So if we add a lot of new instances, we may find that the tree has become too unbalanced and that we will need to construct a new tree from scratch using the extended dataset to restore the efficiency of the retrieval process.",
            "zh": "因此，如果我们添加大量新实例，我们可能会发现树变得太不平衡，我们需要使用扩展数据集从头开始构建新树，以恢复检索过程的效率。"
        }
    },
    {
        "translation": {
            "en": "Comparing each term in ct−1 with the corresponding term in c‡ illustrates how the elementwise product of ft updates the cell state.",
            "zh": "将 ct−1 中的每个项与 c‡ 中的相应项进行比较，说明了 ft 的逐元素乘积如何更新细胞状态。"
        }
    },
    {
        "translation": {
            "en": "To actually calculate the derivative, referred to as , of a simple continuous function, f(x), we use a small number of differentiation rules:",
            "zh": "为了实际计算简单连续函数 f（x） 的导数，我们使用少量微分规则："
        }
    },
    {
        "translation": {
            "en": "Crawford, Kate. 2017. The trouble with bias. Conference on Neural Information Processing Systems, invited speaker.",
            "zh": "克劳福德，凯特。2017. 偏见的麻烦。神经信息处理系统会议，特邀演讲人。"
        }
    },
    {
        "translation": {
            "en": "The architecture of the auto-encoder used in this example is shown in Figure 10.14[625].",
            "zh": "本例中使用的自动编码器的架构如图10.14[625]所示。"
        }
    },
    {
        "translation": {
            "en": "2.5   Summary",
            "zh": "2.5 小结"
        }
    },
    {
        "translation": {
            "en": "Notice that the model sometimes overestimates the office rental price, and sometimes underestimates the office rental price.",
            "zh": "请注意，该模型有时会高估办公室租金价格，有时会低估办公室租金价格。"
        }
    },
    {
        "translation": {
            "en": "Bayes’ Theorem, 243, 245, 248, 731",
            "zh": "贝叶斯定理， 243， 245， 248， 731"
        }
    },
    {
        "translation": {
            "en": "Each histogram includes only those instances in the dataset that have the associated level of the categorical feature.",
            "zh": "每个直方图仅包括数据集中具有分类要素关联级别的实例。"
        }
    },
    {
        "translation": {
            "en": "Invalid outliers can arise for all sorts of different reasons.",
            "zh": "无效的异常值可能由于各种不同的原因而出现。"
        }
    },
    {
        "translation": {
            "en": "The vector of gradients ∂ℰ/∂hx includes error gradients for each element of ht−1 and xt. This is because ht−1 and xt were concatenated together in the forward pass. Hence the vector of gradients ∂ℰt/∂ht−1 is extracted from ∂ℰ/∂hx by splitting the vector at the index that joined ht−1 and xt when they were concatenated.",
            "zh": "梯度向量 ∂E/∂hx 包括 ht−1 和 xt 的每个元素的误差梯度。这是因为 ht−1 和 xt 在前向传递中连接在一起。因此，梯度 ∂Et/∂ht−1 的向量是从 ∂E/∂hx 中提取的，方法是在连接 ht−1 和 xt 的索引处拆分向量。"
        }
    },
    {
        "translation": {
            "en": "From the rankings we can see that the nearest neighbor to the query is instance d6 (indicated by its rank of 1).",
            "zh": "从排名中我们可以看到，与查询最近的邻居是实例 d6（由其排名 1 表示）。"
        }
    },
    {
        "translation": {
            "en": "Table 5.10",
            "zh": "表 5.10"
        }
    },
    {
        "translation": {
            "en": "(a) Based on these predictions, calculate the evaluation measures listed below for each model.",
            "zh": "（a） 根据这些预测，计算下列各模型的评价措施。"
        }
    },
    {
        "translation": {
            "en": "Just by visually inspecting Figure 5.3[188], we can see that the nearest neighbor to the query instance has a target level of yes, so this is the prediction that the model should return.",
            "zh": "只需目视检查图 5.3[188]，我们就可以看到查询实例的最近邻域的目标级别为 yes，因此这是模型应返回的预测。"
        }
    },
    {
        "translation": {
            "en": "This normalization is what makes cosine similarity so useful in scenarios in which we are interested in the relative spread of values across a set of descriptive features rather than the magnitudes of the values themselves.",
            "zh": "这种归一化使余弦相似性在我们感兴趣的场景中如此有用，在这些场景中，我们感兴趣的是值在一组描述性特征上的相对分布，而不是值本身的大小。"
        }
    },
    {
        "translation": {
            "en": "A.1   Descriptive Statistics for Continuous Features",
            "zh": "A.1 连续特征的描述性统计"
        }
    },
    {
        "translation": {
            "en": "We can illustrate this using the simplified version of the RENTAL PRICE prediction problem based only on office size (SIZE).",
            "zh": "我们可以使用仅基于办公室大小 （SIZE） 的 RENTAL PRICE 预测问题的简化版本来说明这一点。"
        }
    },
    {
        "translation": {
            "en": "In this simple example the decision tree is limited to a single root node with one split based on a value of TEMP (in this case the tree predicts Low rental demand for temperatures less than or equal to 8.5 degrees and High rental demand for all other temperatures).",
            "zh": "在这个简单示例中，决策树仅限于单个根节点，其中有一个基于 TEMP 值的拆分（在本例中，该树预测温度小于或等于 8.5 度的低租赁需求和所有其他温度的高租赁需求）。"
        }
    },
    {
        "translation": {
            "en": "The outputs of the bottleneck layer in the network can be used as a new representation of the original input features.",
            "zh": "网络中瓶颈层的输出可以用作原始输入特征的新表示。"
        }
    },
    {
        "translation": {
            "en": "A popular metric used by these algorithms is the Bayesian information criterion (BIC):",
            "zh": "这些算法使用的常用指标是贝叶斯信息准则 （BIC）："
        }
    },
    {
        "translation": {
            "en": "3.6 Data Preparation",
            "zh": "3.6 数据准备"
        }
    },
    {
        "translation": {
            "en": "The first decision that must be made in choosing a machine learning platform is whether to use an application-based solution or to use a programming language.",
            "zh": "在选择机器学习平台时，必须做出的第一个决定是使用基于应用程序的解决方案还是使用编程语言。"
        }
    },
    {
        "translation": {
            "en": "It is also commonly known as a conditional probability, because the probability calculated is valid conditional on the given events (or evidence).When we want to express this type of probability, formally we use a vertical bar, |, to separate the events we want the probability for (listed on the left-hand side of the bar) from the events that we know have already happened.",
            "zh": "它通常也称为条件概率，因为计算出的概率在给定事件（或证据）的条件下是有效的。当我们想要表达这种类型的概率时，我们正式使用垂直条|来将我们想要概率的事件（列在条的左侧）与我们知道已经发生的事件分开。"
        }
    },
    {
        "translation": {
            "en": "2,200",
            "zh": "2,200"
        }
    },
    {
        "translation": {
            "en": "The car has sensors on the front, the rear, and the sides that indicate the presence of other cars or lane barriers in the area immediately surrounding the car.",
            "zh": "汽车的前部、后部和侧面都有传感器，可指示汽车周围区域是否存在其他汽车或车道障碍物。"
        }
    },
    {
        "translation": {
            "en": "-0.1175",
            "zh": "-0.1175"
        }
    },
    {
        "translation": {
            "en": "The same error gradient vector flows back along both paths that feed into the elementwise summation in the forward path.",
            "zh": "相同的误差梯度向量沿着两条路径回流，这些路径馈送到正向路径中的元素求和中。"
        }
    },
    {
        "translation": {
            "en": "It then splits the dataset that was considered at this node, , into partitions, 1,…,k, according to the levels that d[best] can take, {l1,…,lk} (Line 10).",
            "zh": "然后，根据 d[best] 可以采用的级别，将在此节点 上考虑的数据集拆分为 1,...,k 分区 {l1,...,lk}（第 10 行）。"
        }
    },
    {
        "translation": {
            "en": "4. The following image illustrates the topology of a simple feedforward neural network that has a single sensing neuron (Neuron 1), a single hidden processing neuron (Neuron 2), and a single processing output neuron (Neuron 3).",
            "zh": "4. 下图说明了具有单个感知神经元（神经元 1）、单个隐藏处理神经元（神经元 2）和单个处理输出神经元（神经元 3）的简单前馈神经网络的拓扑结构。"
        }
    },
    {
        "translation": {
            "en": "4. The following table lists a dataset from the credit scoring domain that we discussed in the chapter. Underneath the table we list two prediction models consistent with this dataset, Model 1 and Model 2.",
            "zh": "4. 下表列出了我们在本章中讨论的信用评分域中的数据集。在表格下方，我们列出了与此数据集一致的两个预测模型，即模型 1 和模型 2。"
        }
    },
    {
        "translation": {
            "en": "First, we draw a simple bar plot showing the densities of the different levels of the first feature.",
            "zh": "首先，我们绘制一个简单的条形图，显示第一个特征的不同级别的密度。"
        }
    },
    {
        "translation": {
            "en": "By contrast, an answer to Question 2 splits the game domain into one set containing one element, Brian, and another set containing three elements: John, Aphra, and Aoife.",
            "zh": "相比之下，问题 2 的答案将游戏域拆分为一个包含一个元素 Brian 的集合和另一个包含三个元素的集合：John、Aphra 和 Aoife。"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address this problem for the hospital group. For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original problem.",
            "zh": "（a） 提出两种方法，利用预测性数据分析来帮助医院集团解决这一问题。对于每个建议的方法，描述将要构建的预测模型、业务部门如何使用该模型，以及使用该模型将如何帮助解决原始问题。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.11(a)[290] illustrates the network structure of a naive Bayes classifier and how it encodes the conditional independence between the descriptive features given assumed knowledge of the target.",
            "zh": "图6.11（a）[290]说明了朴素贝叶斯分类器的网络结构，以及它如何对给定目标知识的描述性特征之间的条件独立性进行编码。"
        }
    },
    {
        "translation": {
            "en": "1. the probability of an instance having a particular set of descriptive feature values given that it has a particular target level P(d | t)",
            "zh": "1. 给定实例具有特定目标级别 P（d | t） 的实例具有一组特定描述性特征值的概率"
        }
    },
    {
        "translation": {
            "en": "We do not want our model to bias toward a particular feature simply because the values of that feature happen to be large relative to the other features in the dataset.",
            "zh": "我们不希望我们的模型仅仅因为该特征的值相对于数据集中的其他特征而言恰好很大而偏向于特定特征。"
        }
    },
    {
        "translation": {
            "en": "Ross spent a significant amount of time meeting with Kate, the leader of the customer retention team, in order to understand how they worked.",
            "zh": "Ross 花了大量时间与客户保留团队的负责人 Kate 会面，以了解他们的工作方式。"
        }
    },
    {
        "translation": {
            "en": "Drucker, Harris. 1997. Improving regressors using boosting techniques. In International conference on machine learning ICML, Vol. 97, 107–115.",
            "zh": "德鲁克，哈里斯。1997. 使用提升技术改进回归器.在机器学习国际会议上，ICML，第97卷，107-115。"
        }
    },
    {
        "translation": {
            "en": "The universal approximation theorem (Hornik et al., 1989; Cybenko, 1989) proved that neural networks with a single hidden layer of neurons using smooth functions (such as sigmoids or logistic functions) can approximate any bounded continuous function, provided there are sufficient neurons in the hidden layer of the network.",
            "zh": "普遍近似定理（Hornik et al.， 1989;Cybenko，1989）证明，具有单个隐藏神经元层的神经网络使用光滑函数（例如sigmoids或逻辑函数）可以近似任何有界连续函数，前提是网络的隐藏层中有足够的神经元。"
        }
    },
    {
        "translation": {
            "en": "The distributions of the descriptive features in query instances presented to the model",
            "zh": "呈现给模型的查询实例中描述性特征的分布"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network consists of a network of interconnected artificial neurons.",
            "zh": "人工神经网络由相互连接的人工神经元网络组成。"
        }
    },
    {
        "translation": {
            "en": "multi-layer perceptron, 673",
            "zh": "多层感知器，673"
        }
    },
    {
        "translation": {
            "en": "To select the best feature to use at the root of the tree, we need to calculate the information gain for each feature.",
            "zh": "为了选择在树的根部使用的最佳特征，我们需要计算每个特征的信息增益。"
        }
    },
    {
        "translation": {
            "en": "A simple dataset for MENINGITIS with three common symptoms of the disease listed as descriptive features: HEADACHE, FEVER, and VOMITING.",
            "zh": "脑膜炎的简单数据集，该疾病的三种常见症状被列为描述性特征：头痛、发烧和呕吐。"
        }
    },
    {
        "translation": {
            "en": "random variable, 246, 652, 757, 758",
            "zh": "随机变量， 246， 652， 757， 758"
        }
    },
    {
        "translation": {
            "en": "Here, each pair of weights w[0] and w[1] defines a point on the x-y plane, and the sum of squared errors for the model using these weights determines the height of the error surface above the x-y plane for that pair of weights.",
            "zh": "在这里，每对权重 w[0] 和 w[1] 定义 x-y 平面上的一个点，使用这些权重的模型的平方误差之和决定了该对权重在 x-y 平面上方的误差曲面的高度。"
        }
    },
    {
        "translation": {
            "en": "Typically, these diagnoses are based on their extensive training, expertise, and experience.",
            "zh": "通常，这些诊断基于他们广泛的培训、专业知识和经验。"
        }
    },
    {
        "translation": {
            "en": "For a prediction problem with a binary target feature (where, by convention, we refer to the two levels as positive and negative), there are just four outcomes when the model makes a prediction:",
            "zh": "对于具有二元目标特征的预测问题（按照惯例，我们将两个级别称为正值和负值），模型进行预测时只有四个结果："
        }
    },
    {
        "translation": {
            "en": "The rationale is that if the network error is not sensitive to changes in a weight (i.e., the error does not change when the weight changes), then the error is independent of the weight, or to put it another way, the weight did not contribute to the error.",
            "zh": "其基本原理是，如果网络误差对权重的变化不敏感（即，当权重变化时，误差不会改变），则误差与权重无关，或者换句话说，权重对误差没有贡献。"
        }
    },
    {
        "translation": {
            "en": "In general, there is no special symbol used to denote a matrix product. Instead, we write the matrix product by writing the names of the two matrices side by side. For example, DE is the way we write the product for two matrices D and E, although sometimes a dot may be inserted between the two matrices (a · is frequently used to highlight that one or both of the matrices is a vector):",
            "zh": "通常，没有用于表示矩阵乘积的特殊符号。取而代之的是，我们通过并排写两个矩阵的名称来编写矩阵产品。例如，DE 是我们为两个矩阵 D 和 E 编写乘积的方式，尽管有时可能会在两个矩阵之间插入一个点（a · 经常用于突出显示一个或两个矩阵是向量）："
        }
    },
    {
        "translation": {
            "en": "PRESSURE",
            "zh": "压力"
        }
    },
    {
        "translation": {
            "en": "The models that analytics practitioners build simply make predictions based on patterns extracted from historical datasets.",
            "zh": "分析从业者构建的模型只是根据从历史数据集中提取的模式进行预测。"
        }
    },
    {
        "translation": {
            "en": "The first course listed (column “M.L.",
            "zh": "列出的第一门课程（“M.L."
        }
    },
    {
        "translation": {
            "en": "To illustrate how the Theorem of Total Probability can be used to calculate probabilities, we will compute P(h) by summing out M (note: earlier, in Equation (B.1)[760], we computed P(h) = 0.7):",
            "zh": "为了说明如何使用总概率定理来计算概率，我们将通过求和M来计算P（h）（注意：在前面的方程（B.1）[760]中，我们计算了P（h）= 0.7）："
        }
    },
    {
        "translation": {
            "en": "Goldilocks model, 14",
            "zh": "金发姑娘模型，14"
        }
    },
    {
        "translation": {
            "en": "(d) 1st quartile (25th percentile) and 3rd quartile (75th percentile)",
            "zh": "（d） 第1个四分位数（第25个百分位数）和第3个四分位数（第75个百分位数）"
        }
    },
    {
        "translation": {
            "en": "There are many more scenarios, however, in which the correct target feature values either never become available or do not become available early enough to be useful for ongoing model validation.",
            "zh": "但是，在更多情况下，正确的目标特征值要么永远不会可用，要么无法足够早地用于正在进行的模型验证。"
        }
    },
    {
        "translation": {
            "en": "Having a global minimum means that on an error surface, there is a unique set of optimal weights with the lowest sum of squared errors.",
            "zh": "具有全局最小值意味着在误差曲面上，存在一组唯一的最佳权重，其平方误差之和最小。"
        }
    },
    {
        "translation": {
            "en": "In some cases we may not have data for all the features; and in these instances, the standard approach to learning the CPT entries is to use a gradient descent approach (similar to the one we introduce in Chapter 7[311]), where the objective function of the local search algorithm is simply how well the product of the induced conditional probabilities match the relative frequency of each joint event in the data.",
            "zh": "在某些情况下，我们可能没有所有功能的数据;在这些情况下，学习 CPT 条目的标准方法是使用梯度下降方法（类似于我们在第 7 章[311]中介绍的方法），其中局部搜索算法的目标函数只是诱导条件概率的乘积与数据中每个联合事件的相对频率的匹配程度。"
        }
    },
    {
        "translation": {
            "en": "Often, however, we want to know the probability of an event in the context where one or more other events are known to have happened.",
            "zh": "然而，通常，我们想知道在已知一个或多个其他事件发生的上下文中事件发生的概率。"
        }
    },
    {
        "translation": {
            "en": "13. Recall that each non-leaf node in the tree indexes an instance in the dataset and also defines a hyperplane that partitions the feature space. For example, the horizontal and vertical lines in Figure 5.9(b)[199] plot the hyperplanes defined by the non-leaf nodes of the k-d tree shown in Figure 5.9(a)[199].",
            "zh": "13. 回想一下，树中的每个非叶节点都为数据集中的一个实例编制索引，并定义一个用于划分特征空间的超平面。例如，图5.9（b）[199]中的水平线和垂直线绘制了由图5.9（a）[199]所示的k-d树的非叶节点定义的超平面。"
        }
    },
    {
        "translation": {
            "en": "Machine learning models can be built to help predict optimal dosages of drugs so as to achieve a medical practitioner’s goals.26 In the following figure, the image on the left shows a scatter plot of a dataset used to train a model to distinguish between dosages of two drugs that cause a dangerous interaction and those that cause a safe interaction.",
            "zh": "26 在下图中，左图显示了数据集的散点图，该数据集用于训练模型，以区分导致危险相互作用的两种药物的剂量和引起安全相互作用的药物剂量。"
        }
    },
    {
        "translation": {
            "en": "Once this hierarchical tree structure has been found, it can be cut to any level to give a clustering with that many clusters.",
            "zh": "一旦找到这个分层树结构，就可以将其切割到任何级别，以提供具有该多聚类的聚类。"
        }
    },
    {
        "translation": {
            "en": "10.3   Standard Approach: The k-Means Clustering Algorithm",
            "zh": "10.3 标准方法：k-Means 聚类算法"
        }
    },
    {
        "translation": {
            "en": "Figure C.1",
            "zh": "图 C.1"
        }
    },
    {
        "translation": {
            "en": "As a result, when we define the activation function for a PReLU, we introduce a subscript on the terms to identify the neuron and the corresponding gradient being used.",
            "zh": "因此，当我们定义 PReLU 的激活函数时，我们在项上引入了一个下标来识别神经元和正在使用的相应梯度。"
        }
    },
    {
        "translation": {
            "en": "However, the activation ak may be propagated to many downstream neurons, and therefore to calculate the total sensitivity of the network error ℰ to changes in ak, we must sum this product for all n neurons that ak is directly propagated to",
            "zh": "然而，激活 ak 可以传播到许多下游神经元，因此要计算网络误差 E 对 ak 变化的总敏感性，我们必须将 ak 直接传播到的所有 n 个神经元的乘积求和"
        }
    },
    {
        "translation": {
            "en": "The F1 measure can assume values in the range (0,1], and higher values indicate better performance.",
            "zh": "F1 度量值可以假定值在 （0,1） 范围内，值越高表示性能越好。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.10",
            "zh": "图 9.10"
        }
    },
    {
        "translation": {
            "en": "5.4.3 Data Normalization",
            "zh": "5.4.3 数据规范化"
        }
    },
    {
        "translation": {
            "en": "Player Low (PL): 4 − 14",
            "zh": "低球员 （PL）： 4 − 14"
        }
    },
    {
        "translation": {
            "en": "To ensure that the resulting decision tree classifies in the correct proportions, the decision tree is constructed by repeatedly partitioning9 the training dataset until every instance in a partition maps to the same target level.",
            "zh": "为确保生成的决策树以正确的比例进行分类，决策树是通过对训练数据集进行重复分区9来构建的，直到分区中的每个实例都映射到相同的目标级别。"
        }
    },
    {
        "translation": {
            "en": "Table 6.15",
            "zh": "表 6.15"
        }
    },
    {
        "translation": {
            "en": "lift chart, 570",
            "zh": "升降图，570"
        }
    },
    {
        "translation": {
            "en": "There are two key use cases for unsupervised learning: clustering and representation learning.",
            "zh": "无监督学习有两个关键用例：聚类和表示学习。"
        }
    },
    {
        "translation": {
            "en": "When this approach is used, we show a bar plot of the first feature above a bar plot that shows the relative distribution of the levels of the second feature within each level of the first.",
            "zh": "当使用这种方法时，我们在条形图上方显示第一个特征的条形图，该条形图显示了第一个特征的每个水平内第二个特征的相对分布。"
        }
    },
    {
        "translation": {
            "en": "The goal in temporal-difference learning is to find the true values for each entry in this table, and this is achieved by deploying the agent into the environment and updating the values in the table on the basis of the performance of the agent.",
            "zh": "时差学习的目标是找到此表中每个条目的真实值，这是通过将代理部署到环境中并根据代理的性能更新表中的值来实现的。"
        }
    },
    {
        "translation": {
            "en": "Figures 5.18(b)[226] and 5.18(c)[226] illustrate what happens if we increase the number of descriptive features in a dataset but do not increase the number of instances.",
            "zh": "图 5.18（b）[226] 和 5.18（c）[226] 说明了如果我们增加数据集中描述性特征的数量但不增加实例的数量会发生什么。"
        }
    },
    {
        "translation": {
            "en": "1. Select which probability distribution we believe will best model the distribution of the values of the feature. The simplest and most direct way to choose a distribution for a feature is to create a density histogram of the feature’s values and compare the shape of this histogram to the shapes of the standard distributions. We should choose whichever standard distribution best matches the shape of the histogram to model the feature.",
            "zh": "1. 选择我们认为最能对特征值分布进行建模的概率分布。为要素选择分布的最简单、最直接的方法是创建要素值的密度直方图，并将该直方图的形状与标准分布的形状进行比较。我们应该选择与直方图形状最匹配的标准分布来对特征进行建模。"
        }
    },
    {
        "translation": {
            "en": "Han, Jiawei, Jian Pei, and Micheline Kamber. 2011. Data mining: concepts and techniques. Elsevier.",
            "zh": "Han、Jiawei、Jian Pei 和 Micheline Kamber。2011. 数据挖掘：概念和技术.爱思唯尔。"
        }
    },
    {
        "translation": {
            "en": "5.4.5   Other Measures of Similarity",
            "zh": "5.4.5 其他相似度衡量标准"
        }
    },
    {
        "translation": {
            "en": "Inductive bias is not the only type of bias that affects machine learning. An in-depth review of the range of biases that affect machine learning and the social harms that they can cause are beyond the scope of this book.7 However, we highlight sampling bias8 as a particular form of bias that a data analyst should be aware of and should proactively guard against in any data analytics project.",
            "zh": "归纳偏差并不是影响机器学习的唯一偏差类型。对影响机器学习的偏见范围及其可能造成的社会危害的深入审查超出了本书的范围.7 然而，我们强调抽样偏见8是一种特殊形式的偏见，数据分析师应该意识到，并且应该在任何数据分析项目中主动防范。"
        }
    },
    {
        "translation": {
            "en": "Table 6.8",
            "zh": "表 6.8"
        }
    },
    {
        "translation": {
            "en": "(b) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset showing a candidate prediction model (with w[0] = 6.47 and w[1] = 0.62) and the resulting errors.",
            "zh": "（b） 来自办公室租赁数据集的 SIZE 和 RENTAL PRICE 特征的散点图，显示了候选预测模型（w[0] = 6.47 和 w[1] = 0.62）和由此产生的误差。"
        }
    },
    {
        "translation": {
            "en": "Gal, Yarin, and Zoubin Ghahramani. 2016. A theoretically grounded application of dropout in recurrent neural networks. In Advances in neural information processing systems 29: Annual conference on neural information processing systems 2016, December 5–10, 2016, Barcelona, Spain, 1019–1027.",
            "zh": "Gal、Yarin 和 Zoubin Ghahramani。2016. 辍学在递归神经网络中的理论应用.神经信息处理系统进展 29：2016 年神经信息处理系统年会，2016 年 12 月 5 日至 10 日，西班牙巴塞罗那，1019–1027。"
        }
    },
    {
        "translation": {
            "en": "TOTALINCOME: The taxpayer’s total income for the current tax year.",
            "zh": "总收入：纳税人在当前纳税年度的总收入。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the correlation between the LIFEEXPECTANCY and INFANTMORTALITY features.",
            "zh": "（a） 计算预期寿命和婴儿死亡率特征之间的相关性。"
        }
    },
    {
        "translation": {
            "en": "Table 11.3",
            "zh": "表 11.3"
        }
    },
    {
        "translation": {
            "en": "Maintaining the dimensionality between input and output becomes important in convolutional neural networks when we use multiple layers of neurons, the output for one layer being interpreted as the image input to the next layer.",
            "zh": "当我们使用多层神经元时，保持输入和输出之间的维度在卷积神经网络中变得很重要，一层的输出被解释为下一层的图像输入。"
        }
    },
    {
        "translation": {
            "en": "A feature will be tested only once on any path in the tree, but it may occur several times in the tree on different paths.",
            "zh": "一个要素只会在树中的任何路径上测试一次，但它可能会在树中的不同路径上出现几次。"
        }
    },
    {
        "translation": {
            "en": "Armed with the unsuccessful outcome of their first attempt, surfers usually overcompensate on the second attempt, resulting in the opposite problem.",
            "zh": "由于第一次尝试的结果不成功，冲浪者通常会在第二次尝试时过度补偿，从而导致相反的问题。"
        }
    },
    {
        "translation": {
            "en": "The maximum entropy for a set with two types of elements is 1.00 bit, which occurs when there are equal numbers of each type in the set.",
            "zh": "具有两种类型元素的集合的最大熵为 1.00 位，当集合中每种类型的元素数量相等时，就会发生这种情况。"
        }
    },
    {
        "translation": {
            "en": "margin, 361",
            "zh": "保证金，361"
        }
    },
    {
        "translation": {
            "en": "Surprisingly, given the naivete and strength of the assumption it depends upon, naive Bayes models often perform well.",
            "zh": "令人惊讶的是，考虑到它所依赖的假设的幼稚性和强度，朴素贝叶斯模型通常表现良好。"
        }
    },
    {
        "translation": {
            "en": "8.4.6 Sequential Models: Recurrent Neural Networks and Long Short-Term Memory Networks",
            "zh": "8.4.6 顺序模型：递归神经网络和长短期记忆网络"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9(c)[79] shows small multiple histograms for values of AGE broken down by the different levels of the POSITION feature.",
            "zh": "图3.9（c）[79]显示了按位置特征的不同级别细分的AGE值的小倍数直方图。"
        }
    },
    {
        "translation": {
            "en": "In other words, there are more weight parameters on the model than there are dimensions in the input space.",
            "zh": "换言之，模型上的权重参数多于输入空间中的维度。"
        }
    },
    {
        "translation": {
            "en": "For a given prediction task, all that is required to train a naive Bayes model is to calculate the priors for each target level and the conditional probability for each feature given each target level.",
            "zh": "对于给定的预测任务，训练朴素贝叶斯模型所需的只是计算每个目标水平的先验和给定每个目标水平的每个特征的条件概率。"
        }
    },
    {
        "translation": {
            "en": "generalization, 11, 14, 536",
            "zh": "概括， 11， 14， 536"
        }
    },
    {
        "translation": {
            "en": "A greedy policy exploits current knowledge of the rewards that actions are expected to return.",
            "zh": "贪婪的政策利用了当前对行动预期回报的回报的了解。"
        }
    },
    {
        "translation": {
            "en": "Remember that the neurons in this network all use a linear activation function that has a derivative value of 1.",
            "zh": "请记住，该网络中的神经元都使用导数值为 1 的线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "The net effect of this is that the distribution of real data tends to have a lower effective dimensionality than the dimensionality of the feature space.",
            "zh": "这样做的最终结果是，实际数据的分布往往具有低于特征空间维数的有效维数。"
        }
    },
    {
        "translation": {
            "en": "There is, however, a simple way to find the optimal threshold, which avoids testing an infinite number of possible thresholds.",
            "zh": "但是，有一种简单的方法可以找到最佳阈值，从而避免测试无限数量的可能阈值。"
        }
    },
    {
        "translation": {
            "en": "For the practical details of building a data quality report, Svolba (2012, 2007) are very good, even if the SAS language is not being used. Similarly, Dalgaard (2008) is very good even if the R language is not being used. As an example of a detailed investigation into the impact of applying data preparation techniques, Batista and Monard (2003) is interesting.",
            "zh": "对于构建数据质量报告的实际细节，Svolba（2012,2007）非常好，即使没有使用SAS语言。同样，Dalgaard （2008）即使没有使用R语言也非常好。作为对应用数据准备技术的影响进行详细调查的一个例子，Batista 和 Monard （2003） 很有趣。"
        }
    },
    {
        "translation": {
            "en": "There are, however, a number of methods designed to more carefully select the initial centroids.",
            "zh": "然而，有许多方法可以更仔细地选择初始质心。"
        }
    },
    {
        "translation": {
            "en": "For example, if a new customer starts shopping at the supermarket and buys baby food, alcohol, and organic vegetables, our set of consistent models will contradict each other with respect to the prediction that should be returned for this customer; for example, 2 will return GRP = single, 4 will return GRP = family, and 5 will return GRP = couple.",
            "zh": "例如，如果一个新客户开始在超市购物并购买婴儿食品、酒精和有机蔬菜，我们的一组一致模型将在应该为该客户返回的预测方面相互矛盾;例如，2 将返回 GRP = 单，4 将返回 GRP = 家庭，5 将返回 GRP = couple。"
        }
    },
    {
        "translation": {
            "en": "binary logarithm, 124",
            "zh": "二进制对数，124"
        }
    },
    {
        "translation": {
            "en": "Correlation values fall into the range [−1, 1], where values close to − 1 indicate a very strong negative correlation (or covariance), values close to 1 indicate a very strong positive correlation, and values around 0 indicate no correlation.",
            "zh": "相关值落在 [−1， 1] 范围内，其中接近 − 1 的值表示非常强的负相关（或协方差），接近 1 的值表示非常强的正相关，而 0 附近的值表示没有相关性。"
        }
    },
    {
        "translation": {
            "en": "Sometimes this means that data collected by an organization cannot be included in an ABT because this would be incompatible with the original use for which the data was collected.",
            "zh": "有时，这意味着组织收集的数据不能包含在 ABT 中，因为这与收集数据的原始用途不兼容。"
        }
    },
    {
        "translation": {
            "en": "Calculate the δ values for each of the processing neurons in the network (i.e., δ5, δ4, δ3, δ2).",
            "zh": "计算网络中每个处理神经元的δ值（即 δ5、δ4、δ3、δ2）。"
        }
    },
    {
        "translation": {
            "en": "Indeed, a nice feature of the Gini index is that Gini index scores are always between 0 and 1, and in some contexts this may make it easier to compare Gini indexes across features.",
            "zh": "事实上，基尼指数的一个很好的特点是基尼指数得分总是在0到1之间，在某些情况下，这可能更容易比较不同特征的基尼指数。"
        }
    },
    {
        "translation": {
            "en": "A full dataset can be passed through the encoder network, and the outputs of the bottleneck layer can be saved as new generated features.",
            "zh": "完整的数据集可以通过编码器网络传递，瓶颈层的输出可以保存为新生成的特征。"
        }
    },
    {
        "translation": {
            "en": "There are two questions to consider:",
            "zh": "有两个问题需要考虑："
        }
    },
    {
        "translation": {
            "en": "This is a binary feature that flags whether the value was present or missing in the original feature.",
            "zh": "这是一个二进制特征，用于标记原始特征中是否存在该值。"
        }
    },
    {
        "translation": {
            "en": "The algorithm returns the instance stored in the best variable as the nearest neighbor.",
            "zh": "该算法将存储在最佳变量中的实例作为最近邻返回。"
        }
    },
    {
        "translation": {
            "en": "Berry and Linoff (2004) provide a good specialized treatment of clustering algorithms for customer segmentation applications. Han et al. (2011) is also very good on describing unsupervised machine learning techniques with customer applications in mind.",
            "zh": "Berry 和 Linoff （2004） 为客户细分应用程序提供了很好的聚类算法专业化处理。Han et al. （2011） 也非常擅长描述无监督机器学习技术，并考虑到客户应用。"
        }
    },
    {
        "translation": {
            "en": "Instead, we collapse this information into a single representation, referred to as a state.",
            "zh": "取而代之的是，我们将这些信息折叠成一个单一的表示形式，称为状态。"
        }
    },
    {
        "translation": {
            "en": "At the start of the second epoch, the sequence of mini-batches is shuffled and the training iterations are carried out on this new sequence of mini-batches.",
            "zh": "在第二个纪元开始时，对小批量的序列进行洗牌，并对这个新的小批量序列进行训练迭代。"
        }
    },
    {
        "translation": {
            "en": "When presented in class, the material in Chapters 1, 2, 12, 13, and 14 typically takes two to three lecture hours per chapter to cover; and the material in Chapters 3, 4, 5, 6, 7, 8, 9, 10, and 11 normally takes four to six lecture hours per chapter to cover.",
            "zh": "在课堂上展示时，第 1、2、12、13 和 14 章中的材料通常每章需要两到三个课时才能涵盖;第 3、4、5、6、7、8、9、10 和 11 章中的材料通常每章需要四到六个课时才能涵盖。"
        }
    },
    {
        "translation": {
            "en": "Each column in this matrix contains the descriptive features for one of the examples in Table 8.3[423].",
            "zh": "此矩阵中的每一列都包含表 8.3[423] 中其中一个示例的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Gauss-Jordan elimination, 220",
            "zh": "高斯-乔丹淘汰赛，220"
        }
    },
    {
        "translation": {
            "en": "Finally, nearest neighbor models are the basis of case-based reasoning (CBR), which is an umbrella term for applications based on similarity-based machine learning.",
            "zh": "最后，最近邻模型是基于案例的推理 （CBR） 的基础，CBR 是基于相似性的机器学习的应用程序的总称。"
        }
    },
    {
        "translation": {
            "en": "So, we recommend that if a model has been flagged as having gone stale using either performance measure monitoring or output distribution monitoring, then the distributions of the descriptive features at the time that the model was built and the distributions of the features at the time that the model went stale should be compared in an effort to understand what has changed.",
            "zh": "因此，我们建议，如果使用性能度量监视或输出分布监视将模型标记为已过时，则应比较模型构建时描述性特征的分布和模型过时时特征的分布，以了解发生了什么变化。"
        }
    },
    {
        "translation": {
            "en": "For example, the size of a no region in the top right of the feature space is smaller than the corresponding region for the nearest neighbor model with k = 1 (see Figure 5.4(b)[190]).",
            "zh": "例如，特征空间右上角的无区域的大小小于 k = 1 的最近邻模型的相应区域（参见图 5.4（b）[190]）。"
        }
    },
    {
        "translation": {
            "en": "The effect of using a Mahalanobis versus Euclidean distance. A marks the central tendency of the dataset in Figure 5.15(c)[219]. The ellipses plot the Mahalanobis distance contours from A that B and C lie on. In Euclidean terms, B and C are equidistant from A; however, using the Mahalanobis distance, C is much closer to A than B.",
            "zh": "使用马氏距离与欧几里得距离的效果。A在图5.15（c）中标记了数据集的中心趋势[219]。椭圆绘制了 B 和 C 所在的 A 的马氏距离等值线。在欧几里得术语中，B 和 C 与 A 等距;然而，使用马氏距离，C 比 B 更接近 A。"
        }
    },
    {
        "translation": {
            "en": "We previously mentioned that the ID3 algorithm constructs the decision tree by recursively partitioning the dataset.",
            "zh": "我们之前提到过，ID3 算法通过递归分区数据集来构建决策树。"
        }
    },
    {
        "translation": {
            "en": "In order to calculate this test statistic, we first have to calculate the standard error for the overall model and the standard error for the descriptive feature we are investigating the importance of.",
            "zh": "为了计算这个检验统计量，我们首先必须计算整个模型的标准误差和我们正在研究的描述性特征的标准误差。"
        }
    },
    {
        "translation": {
            "en": "Ashmore, Malcolm. 1993. The theatre of the blind: Starring a promethean prankster, a phoney phenomenon, a prism, a pocket, and a piece of wood. Social Studies of Science 23 (1): 67–106.",
            "zh": "阿什莫尔，马尔科姆。1993. 盲人剧院：主演一个普罗米修斯式的恶作剧者、一个虚假现象、一个棱镜、一个口袋和一块木头。科学社会研究23（1）：67-106。"
        }
    },
    {
        "translation": {
            "en": "(a) Propose two ways in which predictive data analytics could be used to help address this business problem.10 For each proposed approach, describe the predictive model that will be built, how the model will be used by the business, and how using the model will help address the original business problem.",
            "zh": "10 对于每一种提议的方法，请描述将要建立的预测模型、业务部门如何使用该模型以及使用该模型将如何帮助解决原始业务问题。"
        }
    },
    {
        "translation": {
            "en": "It is also important to remember that the purpose of an analytics project is to solve a real-world problem and to keep focus on this rather than being distracted by the, admittedly sometimes fascinating, technical challenges of model building.",
            "zh": "同样重要的是要记住，分析项目的目的是解决现实世界的问题，并专注于此，而不是被模型构建的不可否认的有时令人着迷的技术挑战分散注意力。"
        }
    },
    {
        "translation": {
            "en": "The following table shows a small dataset in which each instance describes measurements taken using three sensors when a valve in an oil well was opened.",
            "zh": "下表显示了一个小型数据集，其中每个实例都描述了当油井中的阀门打开时使用三个传感器进行的测量。"
        }
    },
    {
        "translation": {
            "en": "bins, 89",
            "zh": "垃圾箱，89"
        }
    },
    {
        "translation": {
            "en": "Building predictive data analytics solutions for the kinds of applications described in Section 1.1[3] involves a lot more than just choosing the right machine learning algorithm.",
            "zh": "为第1.1节[3]中描述的各类应用构建预测性数据分析解决方案涉及的不仅仅是选择正确的机器学习算法。"
        }
    },
    {
        "translation": {
            "en": "The distributions of the levels of SHOE SPONSOR are almost the same for each level of CAREER STAGE, and therefore we can conclude that there is no relationship between these two features.",
            "zh": "SHOE SPONSOR的等级分布在CAREER STAGE的每个级别几乎相同，因此我们可以得出结论，这两个特征之间没有关系。"
        }
    },
    {
        "translation": {
            "en": "In gradient boosting later models are trained to directly correct errors made by earlier models, rather than the more subtle approach of simply changing weights in a sampling distribution to encourage this.",
            "zh": "在梯度提升中，后来的模型被训练为直接纠正早期模型所犯的错误，而不是简单地改变采样分布中的权重来鼓励这一点的更微妙的方法。"
        }
    },
    {
        "translation": {
            "en": "The height and slope of the curve is dependent on the parameter σ (pronounced sigma), which denotes the population standard deviation.",
            "zh": "曲线的高度和斜率取决于参数 σ（发音为 sigma），它表示总体标准差。"
        }
    },
    {
        "translation": {
            "en": "5.4   (a) The Voronoi tessellation of the feature space for the dataset in Table 5.2[183], with the position of the query represented by the? marker; and (b) the decision boundary created by aggregating the neighboring Voronoi regions that belong to the same target level.",
            "zh": "5.4 （a） 表 5.2[183] 中数据集特征空间的 Voronoi 曲面细分，查询的位置用 ？标记;（b）通过汇总属于同一目标级别的邻近Voronoi地区而创建的决策边界。"
        }
    },
    {
        "translation": {
            "en": "The matrix representation of a neural network is also useful in terms of understanding why we need to include a non-linear function as part of the information processing within each of the neurons in a network (see Section 8.2.4[394]) and why the depth of a network (i.e., the number of layers) is important (see Section 8.2.5[395]).",
            "zh": "神经网络的矩阵表示也有助于理解为什么我们需要将非线性函数作为网络中每个神经元内信息处理的一部分（参见第 8.2.4 节[394]），以及为什么网络的深度（即层数）很重要（参见第 8.2.5 节[395]）。"
        }
    },
    {
        "translation": {
            "en": "The information gained by splitting 𝒟7 for using STREAM and SLOPE is then computed as presented in Table 4.5[138].",
            "zh": "然后计算通过拆分 D7 使用 STREAM 和 SLOPE 获得的信息，如表 4.5 所示[138]。"
        }
    },
    {
        "translation": {
            "en": "Table 3.8[82] shows the workings for the calculation of the covariance between the HEIGHT feature and the WEIGHT and AGE features from the dataset in Table 3.7[73]. The table shows how the portion of Equation (3.3)[81] is calculated for each instance in the dataset for the two covariance calculations. Given this table we can calculate the covariances as follows:",
            "zh": "表3.8[82]显示了从表3.7[73]的数据集中计算HEIGHT特征与WEIGHT和AGE特征之间的协方差的工作原理。下表显示了如何为数据集中的两个协方差计算计算方程 （3.3）[81] 中的部分。给定此表，我们可以按如下方式计算协方差："
        }
    },
    {
        "translation": {
            "en": "It is apparent from this figure that it is not possible to separate the inputs that generate TRUE from those that generate FALSE with a single straight line.",
            "zh": "从这张图中可以明显看出，不可能用一条直线将生成 TRUE 的输入与生成 FALSE 的输入分开。"
        }
    },
    {
        "translation": {
            "en": "Table 4.7[146] shows the calculation of the information gain using the Gini index for the descriptive features in the vegetation classification dataset.",
            "zh": "表4.7[146]显示了使用基尼指数计算植被分类数据集中描述性特征的信息增益。"
        }
    },
    {
        "translation": {
            "en": "Basis functions can also be used to train logistic regression models for categorical prediction problems that involve non-linear relationships.",
            "zh": "基函数还可用于训练涉及非线性关系的分类预测问题的逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "De Bruyne, Katrien, Bram Slabbinck, Willem Waegeman, Paul Vauterin, Bernard De Baets, and Peter Vandamme. 2011. Bacterial species identification from maldi-tof mass spectra through data analysis and machine learning. Systematic and Applied Microbiology 34 (1): 20–29.",
            "zh": "德布劳内、卡特里安、布拉姆·斯拉宾克、威廉·韦格曼、保罗·沃特林、伯纳德·德贝茨和彼得·范达姆。2011. 通过数据分析和机器学习从maldi-tof质谱鉴定细菌种类.系统与应用微生物学34（1）：20-29。"
        }
    },
    {
        "translation": {
            "en": "12.7   A pruned and stunted decision tree built for the Acme Telephonica churn prediction problem.",
            "zh": "12.7 为 Acme Telephonica 流失预测问题构建的修剪和发育不良的决策树。"
        }
    },
    {
        "translation": {
            "en": "The observation period that the descriptive features will be based on is the customer’s entire behavior up to the point at which they make this contact.",
            "zh": "描述性特征所基于的观察期是客户在进行此联系之前的整个行为。"
        }
    },
    {
        "translation": {
            "en": "7.4.4.1 Predicting categorical targets using linear regression Table 7.6[339] shows a sample dataset with a categorical target feature.",
            "zh": "7.4.4.1 使用线性回归预测分类目标 表 7.6[339] 显示了具有分类目标特征的样本数据集。"
        }
    },
    {
        "translation": {
            "en": "Second Edition",
            "zh": "再版"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the interval size, we need to calculate the area under the density curve for that interval.21",
            "zh": "一旦我们选择了区间大小，我们就需要计算该区间的密度曲线下的面积21。"
        }
    },
    {
        "translation": {
            "en": "Each row in an ABT is composed of a set of descriptive features and a target feature. The actual features themselves can be based on any of the data sources within an organization, and defining them can appear to be a mammoth task at first. This task can be made easier by making a hierarchical distinction between the actual features contained in an ABT and a set of domain concepts upon which features are based—see Figure 2.2[30].",
            "zh": "ABT 中的每一行都由一组描述性特征和一个目标特征组成。实际功能本身可以基于组织内的任何数据源，定义它们起初似乎是一项艰巨的任务。通过对 ABT 中包含的实际特征和特征所基于的一组领域概念进行分层区分，可以简化此任务——参见图 2.2[30]。"
        }
    },
    {
        "translation": {
            "en": "If more than one instance in a dataset has the median value for a feature we are splitting on, then we select one of these instances to represent the median and place the other instances with the median value in the set containing the instances whose values are greater than the median.",
            "zh": "如果数据集中有多个实例具有我们正在拆分的特征的中值，则我们选择其中一个实例来表示中位数，并将中位数值的其他实例放在包含其值大于中位数的实例的集合中。"
        }
    },
    {
        "translation": {
            "en": "This is based on an expectation that fraudulent claims may be made early in the lifetime of a policy before too much has been spent on premiums.",
            "zh": "这是基于一种预期，即在保单寿命的早期，在保费上花费过多之前，可能会提出欺诈性索赔。"
        }
    },
    {
        "translation": {
            "en": "The softmax activation function normalizes the z scores for a layer of neurons so that the sum of the activations of the neurons is 1.",
            "zh": "softmax 激活函数对一层神经元的 z 分数进行归一化，使神经元的激活总和为 1。"
        }
    },
    {
        "translation": {
            "en": "The logit for an output neuron k, lk, can only indirectly affect the loss in terms of how it changes the predicted probability for the true category: .",
            "zh": "输出神经元 k， lk 的 logit 只能间接影响损失，即它如何改变真实类别的预测概率：。"
        }
    },
    {
        "translation": {
            "en": "Using the version of the support vector machine prediction model that uses basis functions (see Equation 7.46) with the basis functions given in Part (a), calculate the output of the model for a query instance with DOSE1 = 0.90 and DOSE2 = −0.90.",
            "zh": "使用使用基函数（参见公式 7.46）的支持向量机预测模型版本和第 （a） 部分给出的基函数，计算 DOSE1 = 0.90 和 DOSE2 = −0.90 的查询实例的模型输出。"
        }
    },
    {
        "translation": {
            "en": "It is often (but not always) the case that using a deeper network can drastically reduce the number of neurons required to enable the network to represent a target function.",
            "zh": "通常（但并非总是如此）情况是，使用更深的网络可以大大减少使网络能够表示目标函数所需的神经元数量。"
        }
    },
    {
        "translation": {
            "en": "The final model can accurately distinguish between the two different types of image based on the measured P20 and P45 activity.",
            "zh": "最终模型可以根据测得的P20和P45活性准确区分两种不同类型的图像。"
        }
    },
    {
        "translation": {
            "en": "In this example the observation period and outcome period are both defined relative to the date of the claim event, which will happen on different dates for different claims.",
            "zh": "在此示例中，观察期和结果期都是相对于索赔事件的日期定义的，对于不同的索赔，这将在不同的日期发生。"
        }
    },
    {
        "translation": {
            "en": "Data Understanding, 17, 19, 28, 46, 53, 94, 688, 707, 730",
            "zh": "数据理解， 17， 19， 28， 46， 53， 94， 688， 707， 730"
        }
    },
    {
        "translation": {
            "en": "where η is as defined in Equation (6.5)[250].",
            "zh": "其中η如等式（6.5）[250]所定义。"
        }
    },
    {
        "translation": {
            "en": "Each calculation applies Equation (6.16)[261] and can be understood as a product of the four factors that the naive Bayes model represents: P(FR), P(CH | FR), P(GC | FR), and P(ACC | FR).",
            "zh": "每个计算都应用方程（6.16）[261]，可以理解为朴素贝叶斯模型所表示的四个因素的乘积：P（FR），P（CH |FR）、P（GC |FR） 和 P（ACC |FR）。"
        }
    },
    {
        "translation": {
            "en": "The three scatter plots in this image are of the dataset in Figure 5.15(c)[219].",
            "zh": "该图像中的三个散点图是图5.15（c）[219]中的数据集。"
        }
    },
    {
        "translation": {
            "en": "AHC is, however, much more computationally expensive than k-means, which can be a barrier to using it on very large datasets.",
            "zh": "然而，AHC 的计算成本比 k 均值高得多，这可能是在非常大的数据集上使用它的障碍。"
        }
    },
    {
        "translation": {
            "en": "Demsar (2006) gives another excellent overview of comparing multiple modeling types and has been the basis for much discussion in the machine learning community.",
            "zh": "Demsar （2006） 对比较多种建模类型进行了另一个出色的概述，并且一直是机器学习社区中许多讨论的基础。"
        }
    },
    {
        "translation": {
            "en": "The emergence of knowledge about how to traverse the environment is also reflected in the fact that the cumulative reward earned by the agent at episode 35 is − 115 based on a journey taking 50 actions.",
            "zh": "关于如何穿越环境的知识的出现也反映在以下事实中：特工在第 35 集获得的累积奖励是 -115，基于采取 50 次行动的旅程。"
        }
    },
    {
        "translation": {
            "en": "Table 8.1[422] lists the hourly averages for the AMBIENT TEMPERATURE and the RELATIVE HUMIDITY when a power plant is working at full load and the net hourly ELECTRICAL OUTPUT for the plant under these conditions.",
            "zh": "表8.1[422]列出了电厂满负荷工作时环境温度和相对湿度的每小时平均值，以及电厂在这些条件下的每小时净电力输出。"
        }
    },
    {
        "translation": {
            "en": "Not feeling quite brave enough to play a game, you decide to instead study the dealer playing games with other people.",
            "zh": "你觉得自己不够勇敢去玩游戏，于是决定转而研究庄家和其他人一起玩游戏。"
        }
    },
    {
        "translation": {
            "en": "In fact, given that the weights are real numbers, there are infinitely many combinations of weights, and we are using only integer values in the examples for the sake of clarity in presentation.",
            "zh": "事实上，鉴于权重是实数，权重的组合有无限多，为了表示清楚起见，我们在示例中只使用整数值。"
        }
    },
    {
        "translation": {
            "en": "The fact that both Neurons 3 and 4 had an activation of 0 in response to d2 resulted in both of these neurons having a δ = 0.",
            "zh": "神经元 3 和 4 对 d2 的激活均为 0，这一事实导致这两个神经元的δ = 0。"
        }
    },
    {
        "translation": {
            "en": "student-t distribution, 271, 272",
            "zh": "学生-T 分布，271、272"
        }
    },
    {
        "translation": {
            "en": "The “M.L.",
            "zh": "“M.L."
        }
    },
    {
        "translation": {
            "en": "The state at time-step t, st, should contain all the important information about the environment at that time-step, any important information about what has been happening in the environment at preceding time-steps, and any important information about the internal composition of the agent.",
            "zh": "时间步长 t， st 的状态应包含有关该时间步环境的所有重要信息、有关前一个时间步环境中发生的情况的任何重要信息，以及有关代理内部组成的任何重要信息。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2",
            "zh": "图 3.2"
        }
    },
    {
        "translation": {
            "en": "reduced error pruning, 155, 174, 698",
            "zh": "减少错误修剪，155,174,698"
        }
    },
    {
        "translation": {
            "en": "Remember that the sum of all the elements in a probability distribution must be 1.0.",
            "zh": "请记住，概率分布中所有元素的总和必须为 1.0。"
        }
    },
    {
        "translation": {
            "en": "The following data quality report has been generated from the ABT.",
            "zh": "以下数据质量报告已从 ABT 生成。"
        }
    },
    {
        "translation": {
            "en": "0.2473",
            "zh": "0.2473"
        }
    },
    {
        "translation": {
            "en": "These algorithms determine which descriptive features provide the most information about a target feature and make predictions by sequentially testing the features in order of their informativeness.",
            "zh": "这些算法确定哪些描述性特征提供有关目标特征的最多信息，并通过按信息顺序测试特征进行预测。"
        }
    },
    {
        "translation": {
            "en": "The second approach to identifying outliers is to compare the gaps between the median, minimum, maximum, 1st quartile, and 3rd quartile values.",
            "zh": "识别异常值的第二种方法是比较中位数、最小值、最大值、第一四分位数和第三四分位数值之间的差距。"
        }
    },
    {
        "translation": {
            "en": "Each neuron in this layer has a local receptive field of dimensions 2-by-2, and there is no overlap between the receptive fields of the neurons in this layer.",
            "zh": "该层中的每个神经元都有一个维度为 2×2 的局部感受野，并且该层中神经元的感受野之间没有重叠。"
        }
    },
    {
        "translation": {
            "en": "1.6   The Predictive Data Analytics Project Lifecycle: CRISP-DM",
            "zh": "1.6 预测数据分析项目生命周期：CRISP-DM"
        }
    },
    {
        "translation": {
            "en": "Figure 5.6(a)[193] demonstrates how this approach can regularize the decision boundary for the dataset in Table 5.4[191].",
            "zh": "图5.6（a）[193]演示了这种方法如何规范表5.4[191]中数据集的决策边界。"
        }
    },
    {
        "translation": {
            "en": "The last four columns on the right of the table list for each instance the product of the prediction error and the feature value.",
            "zh": "表格右侧的最后四列列出了每个实例的预测误差和特征值的乘积。"
        }
    },
    {
        "translation": {
            "en": "This is known as conditional independence.",
            "zh": "这称为有条件独立性。"
        }
    },
    {
        "translation": {
            "en": "The problem is, however, that although these models agree on which predictions should be made for the instances in the training dataset, they disagree with regard to which predictions should be returned for instances that are not in the training dataset.",
            "zh": "然而，问题在于，尽管这些模型同意应该对训练数据集中的实例进行哪些预测，但它们不同意应该为不在训练数据集中的实例返回哪些预测。"
        }
    },
    {
        "translation": {
            "en": "For example, the probability of the event a and ¬b is",
            "zh": "例如，事件 a 和 ¬b 的概率为"
        }
    },
    {
        "translation": {
            "en": "(a) Would the similarity-based, information-based, or probability-based predictive modeling approaches already covered in this book be likely to do a better job of learning this model than the simple linear regression model?",
            "zh": "（a） 本书中已经介绍的基于相似性、基于信息或基于概率的预测建模方法是否可能比简单的线性回归模型更好地学习该模型？"
        }
    },
    {
        "translation": {
            "en": "The way that a convolutional neural network uses weight sharing to achieve translation equivariant feature detection is by organizing the local receptive fields of a set of neurons that share a filter (and hence share their weights) so that (1) each neuron’s receptive field covers a slightly different region of the visual field compared with the other neurons in the set; and (2) together the receptive fields of the neurons in the set cover the entire visual field.",
            "zh": "卷积神经网络使用权重共享来实现平移等变特征检测的方式是通过组织一组共享过滤器（因此共享其权重）的神经元的局部感受野，以便 （1） 与集合中的其他神经元相比，每个神经元的感受野覆盖的视野区域略有不同;（2）集合中神经元的感受野一起覆盖了整个视野。"
        }
    },
    {
        "translation": {
            "en": "Convolutional layer 2 includes Filters 3 and 4, and it does not include a sub-sampling layer.45 Filters 3 and 4 will both have a depth of 2 because the input to the second convolutional layer is the two stacked features maps generated by Convolutional layer 1.",
            "zh": "卷积层 2 包括滤波器 3 和 4，它不包括子采样层。45 滤波器 3 和 4 的深度均为 2，因为第二个卷积层的输入是由卷积层 1 生成的两个堆叠特征图。"
        }
    },
    {
        "translation": {
            "en": "This is one of the Bellman Equations,14 which are the foundation stones of reinforcement learning.",
            "zh": "这是贝尔曼方程14之一，它是强化学习的基石。"
        }
    },
    {
        "translation": {
            "en": "Histograms for six different sets of data, each of which exhibit well-known, common characteristics.",
            "zh": "六组不同数据集的直方图，每组数据都具有众所周知的共同特征。"
        }
    },
    {
        "translation": {
            "en": "Given that the vanishing gradient problem arises from repeatedly multiplying the error gradients by the derivative of the activation functions, one way to address the vanishing gradient problem is to use a different activation function. At the start of the chapter we introduced the rectified linear function:23",
            "zh": "鉴于梯度消失问题是由于误差梯度反复乘以激活函数的导数而产生的，因此解决梯度消失问题的一种方法是使用不同的激活函数。在本章的开头，我们介绍了整流线性函数：23"
        }
    },
    {
        "translation": {
            "en": "statistical significance, 585",
            "zh": "统计显著性，585"
        }
    },
    {
        "translation": {
            "en": "Figure 2.2",
            "zh": "图 2.2"
        }
    },
    {
        "translation": {
            "en": "This is slightly more of a concern to machine learning researchers who are interested in comparing the overall power of different machine learning algorithms.",
            "zh": "对于有兴趣比较不同机器学习算法的整体能力的机器学习研究人员来说，这是一个稍微关心的问题。"
        }
    },
    {
        "translation": {
            "en": "So, .",
            "zh": "所以。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.15[427] illustrates the forward pass of d2 through the network.",
            "zh": "图 8.15[427] 说明了 d2 通过网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "We can do this by adapting the ID3 algorithm to use a measure of variance15 rather than a measure of entropy in selecting the best feature.",
            "zh": "为此，我们可以调整 ID3 算法，使其在选择最佳特征时使用方差度量15，而不是熵度量。"
        }
    },
    {
        "translation": {
            "en": "If the errors show that, in general, predictions made by the candidate model are too low, then w[j] should be increased if di[j] is positive and decreased if di[j] is negative.",
            "zh": "如果误差表明，一般来说，候选模型的预测值太低，那么如果 di[j] 为正，则 w[j] 应增加，如果 di[j] 为负，则 w[j] 应减小。"
        }
    },
    {
        "translation": {
            "en": "mean squared error, 575",
            "zh": "均方误差，575"
        }
    },
    {
        "translation": {
            "en": "6.2.2 Bayesian Prediction",
            "zh": "6.2.2 贝叶斯预测"
        }
    },
    {
        "translation": {
            "en": "In this example each instance has been put into an individual partition, and although these partitions each have a variance of zero, this is indicative of overfitting the data.",
            "zh": "在此示例中，每个实例都已放入单独的分区中，尽管每个分区的方差均为零，但这表示数据过度拟合。"
        }
    },
    {
        "translation": {
            "en": "These δs were calculated by backpropagating the error on Example 2.",
            "zh": "这些δ是通过反向传播示例2上的误差来计算的。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, this is not the case, as the distribution of prediction scores for a model can follow any distribution.",
            "zh": "不幸的是，事实并非如此，因为模型的预测分数分布可以遵循任何分布。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we describe how to evaluate machine learning models built for predictive data analytics tasks.",
            "zh": "在本章中，我们将介绍如何评估为预测数据分析任务构建的机器学习模型。"
        }
    },
    {
        "translation": {
            "en": "In the SDSS dataset, many of the features are represented multiple times for each of the five different photometric bands, and this made Jocelyn suspect that many of these features might be redundant and so ripe for removal from the dataset.",
            "zh": "在 SDSS 数据集中，五个不同光度波段中的每一个都多次表示了许多特征，这让 Jocelyn 怀疑其中许多特征可能是多余的，因此可以从数据集中删除。"
        }
    },
    {
        "translation": {
            "en": "For this reason, we recommend the use of equal-frequency binning to convert continuous features to categorical ones for probability-based models.",
            "zh": "因此，对于基于概率的模型，我们建议使用等频分箱将连续特征转换为分类特征。"
        }
    },
    {
        "translation": {
            "en": "An email spam prediction dataset.",
            "zh": "垃圾邮件预测数据集。"
        }
    },
    {
        "translation": {
            "en": "distributions, 102",
            "zh": "分布，102"
        }
    },
    {
        "translation": {
            "en": "Care must be taken, however, when selecting the parameter k, particularly when working with imbalanced datasets.",
            "zh": "但是，在选择参数 k 时必须小心，尤其是在使用不平衡数据集时。"
        }
    },
    {
        "translation": {
            "en": "However, as is so often the case in machine learning, this is not the end of the generative versus discriminative debate.",
            "zh": "然而，正如机器学习中经常出现的情况一样，这并不是生成性与歧视性辩论的结束。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7(b)[76] shows another example, for the POSITION and SHOE SPONSOR features from the same dataset. In this case, the three plots are very different, so we can conclude that there is a relationship between these two features. It seems that players who play in the guard position are much more likely to have a shoe sponsor than forwards or centers.",
            "zh": "图 3.7（b）[76] 显示了来自同一数据集的 POSITION 和 SHOE SPONSOR 要素的另一个示例。在这种情况下，这三个图非常不同，因此我们可以得出结论，这两个特征之间存在关系。似乎在后卫位置上踢球的球员比前锋或中锋更有可能拥有鞋子赞助商。"
        }
    },
    {
        "translation": {
            "en": "Four continuous features stood out as possibly suffering from the presence of outliers: HANDSETPRICE, with a minimum value of 0, which seemed unusual; AVGMINS, with a maximum of 6,336.25, which was very different from the mean and the 3rd quartile values for that feature; AVGRECEIVEDMINS, with a maximum of 2,006.29, which was also very different from the mean and the 3rd quartile values for that feature; and AVGOVERBUNDLEMINS, with minimum, 1st quartile, and median values of 0 compared to a mean of 40.",
            "zh": "四个连续的特征可能受到异常值的影响：HANDSETPRICE，最小值为 0，这似乎不寻常;AVGMINS，最大值为 6,336.25，与该特征的平均值和第 3 个四分位数值相差很大;AVGRECEIVEDMINS，最大值为 2,006.29，也与该特征的平均值和第 3 个四分位数值有很大差异;和 AVGOVERBUNDLEMINS，最小值、第一四分位数和中位数值为 0，而平均值为 40。"
        }
    },
    {
        "translation": {
            "en": "More likely, the easy availability of data for some solutions might favor them over others.",
            "zh": "更有可能的是，某些解决方案的数据易于获得可能比其他解决方案更有利于它们。"
        }
    },
    {
        "translation": {
            "en": "This is useful for exploring the relationships between groups of features—for example, all the continuous features in an ABT.",
            "zh": "这对于探索特征组之间的关系非常有用，例如，ABT 中的所有连续特征。"
        }
    },
    {
        "translation": {
            "en": "Paul’s impressive accuracy should not be taken to suggest that octopus behavior affects soccer matches but rather that independent events may be correlated, at least for an interval of time, without the events actually being dependent.",
            "zh": "保罗令人印象深刻的准确性不应该被理解为章鱼的行为会影响足球比赛，而是认为独立的事件可能是相关的，至少在一段时间内是这样，而这些事件实际上并不具有依赖性。"
        }
    },
    {
        "translation": {
            "en": "Hadamard product, xxvii, 475, 773",
            "zh": "Hadamard 产品，xxvii，475,773"
        }
    },
    {
        "translation": {
            "en": "clusters, 599",
            "zh": "集群，599"
        }
    },
    {
        "translation": {
            "en": "The distance between the query instance and d21 is 0.9014, which is less than the value stored in best-distance (we can see this in Figure 5.10(b)[201], as d21 is inside the target hypersphere).",
            "zh": "查询实例和 d21 之间的距离为 0.9014，小于存储在 best-distance 中的值（我们可以在图 5.10（b）[201] 中看到这一点，因为 d21 位于目标超球体内）。"
        }
    },
    {
        "translation": {
            "en": "The first is to examine the minimum and maximum values for each feature and use domain knowledge to determine whether these are plausible values.",
            "zh": "首先是检查每个特征的最小值和最大值，并使用领域知识来确定这些值是否合理。"
        }
    },
    {
        "translation": {
            "en": "(a) A Bayesian network representation of the conditional independence asserted by a naive Bayes model between the descriptive features given knowledge of the target feature; and (b) a Bayesian network representation of the conditional independence assumption for the naive Bayes model in the fraud example.",
            "zh": "（a） 朴素贝叶斯模型在给定目标特征知识的描述性特征之间断言的条件独立性的贝叶斯网络表示;（b）欺诈示例中朴素贝叶斯模型的条件独立性假设的贝叶斯网络表示。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.14",
            "zh": "图 7.14"
        }
    },
    {
        "translation": {
            "en": "−0.00176664",
            "zh": "−0.00176664"
        }
    },
    {
        "translation": {
            "en": "An example of a commonly used sampling method that attempts to address these two issues is k-fold cross validation.",
            "zh": "尝试解决这两个问题的常用抽样方法的一个例子是 k 倍交叉验证。"
        }
    },
    {
        "translation": {
            "en": "10. Remember that a harmonic mean is used in the F 1 measure given in Equation (9.10)[550].",
            "zh": "10. 请记住，在等式（9.10）[550]中给出的F 1度量中使用了调和平均值。"
        }
    },
    {
        "translation": {
            "en": "Each image is grayscale and can be represented as a grid of 28 by 28 integers in the range [0,255] where a 0 value indicates a white pixel, a value of 255 indicates a black pixel, and numbers between 0 and 255 indicate shades of gray.",
            "zh": "每个图像都是灰度的，可以表示为 [0,255] 范围内的 28 x 28 整数网格，其中 0 值表示白色像素，值 255 表示黑色像素，0 到 255 之间的数字表示灰色阴影。"
        }
    },
    {
        "translation": {
            "en": "What types of models will we use? How will we set the parameters of the machine learning algorithms? Have underfitting or overfitting occurred?",
            "zh": "我们将使用哪些类型的模型？我们将如何设置机器学习算法的参数？是否发生过欠拟合或过拟合？"
        }
    },
    {
        "translation": {
            "en": "15. The data used in this question have been artificially generated for this book. Channel propensity modeling is used widely in industry; for example, see Hirschowitz (2001).",
            "zh": "15. 本问题中使用的数据是为本书人工生成的。信道倾向建模在工业中被广泛使用;例如，请参阅Hirschowitz （2001） 。"
        }
    },
    {
        "translation": {
            "en": "Guess Who is a two-player game in which one player chooses a card with a picture of a character on it from a deck, and the other player tries to guess which character is on the card by asking a series of questions to which the answer can be only yes or no.",
            "zh": "猜猜是谁是一款双人游戏，其中一名玩家从一副牌中选择一张带有角色图片的卡片，另一名玩家试图通过提出一系列问题来猜测卡片上的哪个角色，答案只能是或否。"
        }
    },
    {
        "translation": {
            "en": "There are many scenarios in which this is the case.",
            "zh": "在许多情况下都是这种情况。"
        }
    },
    {
        "translation": {
            "en": "minimum description length principle, 292",
            "zh": "最小描述长度原则，292"
        }
    },
    {
        "translation": {
            "en": "10.3.1   A Worked Example",
            "zh": "10.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "“Study the past if you would define the future.”",
            "zh": "“如果你要定义未来，就要研究过去。”"
        }
    },
    {
        "translation": {
            "en": "Two decision trees, (a) and (b), that are consistent with the instances in the spam dataset; and (c) the path taken through the tree shown in (a) to make a prediction for the query instance SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, and CONTAINS IMAGES = true.",
            "zh": "两个决策树 （a） 和 （b），与垃圾邮件数据集中的实例一致;以及 （c） 通过 （a） 所示的树对查询实例 SUSPICIOUS WORDS = true、UNKNOWN SENDER = true 和 CONTAINS IMAGES = true 进行预测的路径。"
        }
    },
    {
        "translation": {
            "en": "(a) What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia?",
            "zh": "（a） 使用欧几里得距离的三最近邻预测模型对俄罗斯 CPI 的返回值是多少？"
        }
    },
    {
        "translation": {
            "en": "The galaxy types that Galaxy Zoo citizen scientists could choose from were elliptical, clockwise spiral, anti-clockwise spiral, edge-on disk, merger, and don’t know.",
            "zh": "银河动物园公民科学家可以选择的星系类型是椭圆形、顺时针螺旋、逆时针螺旋、边缘圆盘、合并和不知道。"
        }
    },
    {
        "translation": {
            "en": "Finally, the fact that deep learning models are combined by connecting artificial neurons together means that we can tailor the structure of a network toward the characteristics of the data on which we are planning to run the network.",
            "zh": "最后，通过将人工神经元连接在一起来组合深度学习模型这一事实意味着我们可以根据我们计划运行网络的数据特征来定制网络的结构。"
        }
    },
    {
        "translation": {
            "en": "Using this, the R2 coefficient for the regression model can be calculated as 0.889 and for the nearest neighbor model as 0.776.",
            "zh": "使用此方法，回归模型的 R2 系数可以计算为 0.889，最近邻模型的 R2 系数可以计算为 0.776。"
        }
    },
    {
        "translation": {
            "en": "Consequently, each of the neurons in the first layer connects only to a single neuron in the sub-sampling layer.",
            "zh": "因此，第一层中的每个神经元仅连接到子采样层中的单个神经元。"
        }
    },
    {
        "translation": {
            "en": "This is achieved by replacing the input vector containing a single example with an input matrix containing multiple examples.",
            "zh": "这是通过将包含单个示例的输入向量替换为包含多个示例的输入矩阵来实现的。"
        }
    },
    {
        "translation": {
            "en": "This is one of the reasons why creating a data quality report7 and spending time on cleaning the dataset is such an important part of any machine learning project.",
            "zh": "这就是为什么创建数据质量报告7 并花时间清理数据集是任何机器学习项目如此重要的一部分的原因之一。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.2",
            "zh": "图 1.2"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in this dataset are SIZE (the property size in square feet) and RENT (the estimated monthly rental value of the property in dollars).",
            "zh": "此数据集中的描述性特征是 SIZE（以平方英尺为单位的房产面积）和 RENT（以美元为单位的房产的估计月租金价值）。"
        }
    },
    {
        "translation": {
            "en": "The following data visualizations are based on the channel prediction dataset given in Question 3.",
            "zh": "以下数据可视化基于问题 3 中给出的信道预测数据集。"
        }
    },
    {
        "translation": {
            "en": "WEIGHT",
            "zh": "重量"
        }
    },
    {
        "translation": {
            "en": "Hecht-Nielsen (1987) showed how these proofs could be applied to neural networks.",
            "zh": "Hecht-Nielsen（1987）展示了如何将这些证明应用于神经网络。"
        }
    },
    {
        "translation": {
            "en": "B.3 Some Useful Probability Rules",
            "zh": "B.3 一些有用的概率规则"
        }
    },
    {
        "translation": {
            "en": "This scenario is illustrated in Figure 2.8[40].",
            "zh": "图2.8[40]说明了这种情况。"
        }
    },
    {
        "translation": {
            "en": "After deployment it can often make sense to restrict an agent to greedy action selection and allow no further exploration.",
            "zh": "部署后，通常将代理限制为贪婪的操作选择，并且不允许进一步探索。"
        }
    },
    {
        "translation": {
            "en": "specificity, 548, 559",
            "zh": "特异性，548,559"
        }
    },
    {
        "translation": {
            "en": "The prediction model shown in Figure 1.3(d)[15], however, is a Goldilocks model: it is just right, striking a good balance between underfitting and overfitting.",
            "zh": "然而，图1.3（d）[15]所示的预测模型是一个金发姑娘模型：它恰到好处，在欠拟合和过拟合之间取得了很好的平衡。"
        }
    },
    {
        "translation": {
            "en": "Efficiently indexing and accessing memory is an important consideration in scaling nearest neighbor models to large datasets.",
            "zh": "有效地索引和访问内存是将最近邻模型扩展到大型数据集的重要考虑因素。"
        }
    },
    {
        "translation": {
            "en": "Tsanas, Athanasios, and Angeliki Xifara. 2012. Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. Energy and Buildings 49: 560–567.",
            "zh": "Tsanas、Athanasios 和 Angeliki Xifara。2012. 使用统计机器学习工具对住宅建筑能源性能进行准确定量估计.能源与建筑49：560-567。"
        }
    },
    {
        "translation": {
            "en": "One of the advantages of working in scientific scenarios is that there is a body of literature that discusses how other scientists have addressed similar problems.",
            "zh": "在科学场景中工作的好处之一是，有大量文献讨论了其他科学家如何解决类似问题。"
        }
    },
    {
        "translation": {
            "en": "1.8 The Road Ahead",
            "zh": "1.8 前方的道路"
        }
    },
    {
        "translation": {
            "en": "It is important to remember, though, that no matter how well it is done, binning always discards information from the dataset because it abstracts from a continuous representation to a coarser categorical resolution.",
            "zh": "但是，重要的是要记住，无论它做得多么好，分箱总是会丢弃数据集中的信息，因为它从连续表示抽象到更粗略的分类分辨率。"
        }
    },
    {
        "translation": {
            "en": "If we set the number of bins to a very low number—for example, two or three bins—(in other words, we abstract to a very low level of resolution), we may lose a lot of information with respect to the distribution of values in the original continuous feature. Using a small number of bins, however, has the advantage of having a large number of instances in each bin.",
            "zh": "如果我们将条柱的数量设置为一个非常低的数字（例如，两个或三个条柱），（换句话说，我们抽象到一个非常低的分辨率级别），我们可能会丢失很多关于原始连续特征中值分布的信息。但是，使用少量 bin 的优点是每个 bin 中都有大量实例。"
        }
    },
    {
        "translation": {
            "en": "(a) A doctor has carried out a regular checkup on a patient and measured the patient’s WEIGHT to be 65 kilograms and their HEIGHT to be 1.7 meters. The doctor inputs these details into a k-NN classifier to check whether the patient is at risk of DIABETES. Assuming that k = 1, and that the model uses Euclidean distance as its similarity metric, will the model return true or false for this patient?",
            "zh": "（a） 医生对病人进行定期检查，测量病人的体重为65公斤，身高为1.7米。医生将这些详细信息输入到 k-NN 分类器中，以检查患者是否有患糖尿病的风险。假设 k = 1，并且模型使用欧几里得距离作为其相似度指标，则该模型会返回该患者的真值还是假值？"
        }
    },
    {
        "translation": {
            "en": "As a result, the area of each bar (the bar height times the bar width) gives the probability for the feature taking a value in the interval represented by that bar.",
            "zh": "因此，每个条形的面积（条形高度乘以条形宽度）给出了要素在该条形所表示的区间内取一个值的概率。"
        }
    },
    {
        "translation": {
            "en": "The error rate measures the number of predictions made by the tree that are incorrect.",
            "zh": "错误率衡量树做出的不正确预测的数量。"
        }
    },
    {
        "translation": {
            "en": "Given these terms we calculate the update for the weights in W(f) using the sequence of calculations listed in Equations (8.132)[519] to (8.138)[520]",
            "zh": "给定这些项，我们使用方程（8.132）[519]至（8.138）[520]中列出的计算顺序来计算W（f）中权重的更新"
        }
    },
    {
        "translation": {
            "en": "FIBERFLUX_U/G/R/I/Z",
            "zh": "FIBERFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "When an ε-greedy policy is used, an agent chooses the best action most of the time, but occasionally—with a probability of ε—selects a random action uniformly from those available.",
            "zh": "当使用ε贪婪策略时，代理大多数时候会选择最佳操作，但偶尔（概率为 ε）会从可用操作中统一选择随机操作。"
        }
    },
    {
        "translation": {
            "en": "In Figure 3.13(a)[90] there are three bins that are each quite wide, and the histogram heights don’t really follow the dashed line.",
            "zh": "在图 3.13（a）[90] 中，有三个条柱，每个条柱都很宽，直方图高度并不真正遵循虚线。"
        }
    },
    {
        "translation": {
            "en": "However, let’s step through how the algorithm makes this prediction.",
            "zh": "但是，让我们逐步了解算法如何进行此预测。"
        }
    },
    {
        "translation": {
            "en": "A Markov process, a more basic framework than an MDP that does not include decision making, can be used to model a discrete random process that transitions through a finite set of states, S. For example, we could use a Markov process to model how infection progresses in an individual when a disease epidemic breaks out.",
            "zh": "马尔可夫过程是一个比不包括决策的 MDP 更基本的框架，可用于模拟通过一组有限状态 S 转换的离散随机过程。例如，我们可以使用马尔可夫过程来模拟疾病流行爆发时个体的感染进展情况。"
        }
    },
    {
        "translation": {
            "en": "This chapter begins by describing the structure of a data quality report and explaining how it is used to get to know the data in an ABT and to identify data quality issues.",
            "zh": "本章首先描述了数据质量报告的结构，并解释了如何使用它来了解 ABT 中的数据并识别数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "This suggests that when the model makes mistakes, it more commonly incorrectly predicts the spam level than the ham level.",
            "zh": "这表明，当模型犯错误时，它更常见地错误地预测垃圾邮件级别，而不是业余水平。"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, Gini index, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "表4.3[136]中数据集的分区集（部分）、熵、基尼指数、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "Although, data protection legislation changes significantly across different jurisdictions, there are some common tenets on which there is broad agreement.",
            "zh": "尽管不同司法管辖区的数据保护立法有很大变化，但有一些共同的原则得到了广泛的认同。"
        }
    },
    {
        "translation": {
            "en": "One consequence of abstracting away from the training data is that models induced using an eager learning algorithm are typically faster at making predictions than models based on a lazy learner.",
            "zh": "从训练数据中抽象出来的一个后果是，使用渴望学习算法诱导的模型通常比基于懒惰学习者的模型更快地进行预测。"
        }
    },
    {
        "translation": {
            "en": "Markov processes are built on the Markov assumption that the probability of transitioning to a particular state at the next time-step relies only on the current state, and does not require any knowledge of the history of states that came before that, or",
            "zh": "马尔可夫过程建立在马尔可夫假设之上，即在下一个时间步过渡到特定状态的概率仅取决于当前状态，并且不需要任何关于之前状态历史的知识，或者"
        }
    },
    {
        "translation": {
            "en": "When we use a hold-out test set, we take one sample from the overall dataset to use to train a model and another separate sample to test the model.",
            "zh": "当我们使用保留测试集时，我们从整个数据集中获取一个样本用于训练模型，并从另一个单独的样本中获取模型来测试模型。"
        }
    },
    {
        "translation": {
            "en": "As well as showing that it is hard to make money in the payday loans business, this reverses the ordering implied using the average class accuracy.",
            "zh": "除了表明在发薪日贷款业务中很难赚钱外，这还颠倒了使用平均类准确性隐含的排序。"
        }
    },
    {
        "translation": {
            "en": "This example also illustrates a problem with using covariance.",
            "zh": "此示例还说明了使用协方差的问题。"
        }
    },
    {
        "translation": {
            "en": "The final component of the MDP shown in Figure 11.3[648] is the reward associated with each transition to a new state based on taking a particular action.",
            "zh": "图 11.3[648] 所示的 MDP 的最后一个组成部分是基于采取特定行动的每次过渡到新状态的奖励。"
        }
    },
    {
        "translation": {
            "en": "weighted dataset, 160",
            "zh": "加权数据集，160"
        }
    },
    {
        "translation": {
            "en": "-0.71",
            "zh": "-0.71"
        }
    },
    {
        "translation": {
            "en": "The weight matrix for the tanh layer in the output gate (W(o‡), including bias terms, has dimensions H × (1 + H).",
            "zh": "输出栅极 （W（o‡） 中 tanh 层的权重矩阵（包括偏置项）的尺寸为 H × （1 + H）。"
        }
    },
    {
        "translation": {
            "en": "We can formally define a feature space as an abstract m-dimensional space that is created by making each descriptive feature in a dataset an axis of an m-dimensional coordinate system and mapping each instance in the dataset to a point in this coordinate system based on the values of its descriptive features.",
            "zh": "我们可以将特征空间正式定义为一个抽象的 m 维空间，该空间是通过使数据集中的每个描述性特征成为 m 维坐标系的轴，并根据其描述性特征的值将数据集中的每个实例映射到该坐标系中的某个点来创建的。"
        }
    },
    {
        "translation": {
            "en": "If too many neurons in a network are dead, then the network will not converge during training.",
            "zh": "如果网络中有太多的神经元死亡，那么网络在训练期间就不会收敛。"
        }
    },
    {
        "translation": {
            "en": "EXPMAG_U/G/R/I/Z",
            "zh": "EXPMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The simplest version of this would be a numeric state vector input into a multi-layer perceptron feedforward network.",
            "zh": "最简单的版本是将数字状态向量输入到多层感知器前馈网络中。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.23(d)[453] clearly illustrates vanishing gradients across layers in the network; that the δ values are tending toward 0 is indicated by the fact that the median of the δ values across the layers is 0 but the variance of δ values rapidly shrinks as we move backward from the last hidden layer (HL5) to the first layer (HL1).",
            "zh": "图8.23（d）[453]清楚地说明了网络中各层的梯度消失;δ值趋向于 0 的事实表明，各层的 δ 值的中位数为 0，但当我们从最后一个隐藏层 （HL5） 向后移动到第一层 （HL1） 时，δ值的方差会迅速缩小。"
        }
    },
    {
        "translation": {
            "en": "unstable gradients, 449",
            "zh": "不稳定梯度，449"
        }
    },
    {
        "translation": {
            "en": "The algorithm finds the division of instances into clusters by minimizing",
            "zh": "该算法通过最小化来找到将实例划分为集群的方法"
        }
    },
    {
        "translation": {
            "en": "8.4.5 Convolutional Neural Networks",
            "zh": "8.4.5 卷积神经网络"
        }
    },
    {
        "translation": {
            "en": "1.2   The two steps in supervised machine learning: (a) learning and (b) predicting.",
            "zh": "1.2 监督机器学习的两个步骤：（a）学习和（b）预测。"
        }
    },
    {
        "translation": {
            "en": "TwentyTwos is a game played between a single player and a dealer.",
            "zh": "TwentyTwos是单人玩家和庄家之间的游戏。"
        }
    },
    {
        "translation": {
            "en": "5. Be confident that enough good-quality data exists to continue with a project.",
            "zh": "5. 确信存在足够多的高质量数据来继续项目。"
        }
    },
    {
        "translation": {
            "en": "The agent chooses the next action to take, however, using its policy (Line 13[658]), in this case ε-greedy with ε = 0.1.",
            "zh": "但是，代理使用其策略（第 13 行[658]）选择要执行的下一个操作，在本例中为 ε = 0.1 的贪婪ε。"
        }
    },
    {
        "translation": {
            "en": "For example, the probability distribution for the binary feature MENINGITIS from Table B.2[760], with a probability of 0.3 of being true and using the convention of the first element in the vector being the probability for a true value, would be written as P(M) = 0.3,0.7.",
            "zh": "例如，表B.2[760]中二元特征脑膜炎的概率分布，其为真的概率为0.3，并且使用向量中第一个元素的约定为真值的概率，将写为P（M） = 0.3,0.7。"
        }
    },
    {
        "translation": {
            "en": "All three gates in an LSTM involve an elementwise product of two activation vectors (see Equations (8.107)[509], (8.112)[511], and (8.116)[512]).",
            "zh": "LSTM中的所有三个门都涉及两个激活向量的元素乘积（参见方程（8.107）[509]，（8.112）[511]和（8.116）[512]）。"
        }
    },
    {
        "translation": {
            "en": "Markov decision process, 638, 643, 645",
            "zh": "马尔可夫决策过程，638,643,645"
        }
    },
    {
        "translation": {
            "en": "At this point the information in the query is used to define a neighborhood in the feature space, and a prediction is made based on the instances in this neighborhood.",
            "zh": "此时，查询中的信息用于定义要素空间中的邻域，并根据该邻域中的实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "Email classification is a good application scenario in which the different information provided by precision and recall is useful.",
            "zh": "电子邮件分类是一个很好的应用场景，其中精度和召回率提供的不同信息很有用。"
        }
    },
    {
        "translation": {
            "en": "The electrical power output from a combined cycle power plant is influenced by a number of ambient parameters, such as temperature and humidity; being able to accurately predict the output of the power plant working a full load with respect to these parameters can significantly reduce the cost of energy production (Tüfekci, 2014).",
            "zh": "联合循环发电厂的电力输出受许多环境参数的影响，例如温度和湿度;能够准确预测发电厂根据这些参数满负荷工作的输出可以显着降低能源生产成本（Tüfekci，2014）。"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a model trained on the bacterial species identification problem.",
            "zh": "针对细菌物种识别问题训练的模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "One problem with sparse data is that with so few non-zero values, the variation between two instances may be dominated by noise.",
            "zh": "稀疏数据的一个问题是，由于非零值很少，两个实例之间的变化可能以噪声为主。"
        }
    },
    {
        "translation": {
            "en": "If we perform the same calculation for the other candidate models shown in Figure 7.2(a)[316], we find that with w[1] set to 0.4, 0.5, 0.7, and 0.8, the sums of squared errors are 136,218, 42,712, 20,092, and 90,978 respectively. The fact that the sums of squared errors for these models are larger than for the model with w[1] set to 0.62 demonstrates that our previous visual intuition that this model most accurately fits the training data was correct.",
            "zh": "如果我们对图7.2（a）[316]中所示的其他候选模型执行相同的计算，我们发现，当w[1]设置为0.4、0.5、0.7和0.8时，平方误差之和分别为136,218、42,712、20,092和90,978。这些模型的平方误差之和大于设置为 0.62 的模型的平方误差总和这一事实表明，我们之前的视觉直觉认为该模型最准确地拟合训练数据是正确的。"
        }
    },
    {
        "translation": {
            "en": "In other words, each neuron in the network learns a separate gradient for its activation function for the region z ≤ 0.",
            "zh": "换句话说，网络中的每个神经元都为其区域 z ≤ 0 的激活函数学习一个单独的梯度。"
        }
    },
    {
        "translation": {
            "en": "Identifying pairs of closely related descriptive features is one way to reduce the size of an ABT because if the relationship between two descriptive features is strong enough, we may not need to include both.",
            "zh": "识别密切相关的描述性特征对是减小 ABT 大小的一种方法，因为如果两个描述性特征之间的关系足够强，我们可能不需要同时包含两者。"
        }
    },
    {
        "translation": {
            "en": "The first thing to understand is that there is not one best approach that always outperforms the others.",
            "zh": "首先要了解的是，没有一种最佳方法总是优于其他方法。"
        }
    },
    {
        "translation": {
            "en": "Table 5.6",
            "zh": "表 5.6"
        }
    },
    {
        "translation": {
            "en": "These two approaches ran in parallel for 12 weeks, and at the end of this period, the company measured the number of customers within each group who had left the company to join another network.",
            "zh": "这两种方法并行运行了 12 周，在这段时间结束时，该公司测量了每个组中离开公司加入另一个网络的客户数量。"
        }
    },
    {
        "translation": {
            "en": "The fundamental idea underpinning early stopping is that we can identify the point during an iterative training algorithm (such as backpropagation) when a model begins to overfit the training data as being the point when the error of the model on a validation dataset begins to increase.",
            "zh": "支持早期停止的基本思想是，我们可以在迭代训练算法（例如反向传播）期间确定模型开始过度拟合训练数据的点，即模型在验证数据集上的误差开始增加的点。"
        }
    },
    {
        "translation": {
            "en": "3.5.1 Visualizing Relationships between Features",
            "zh": "3.5.1 可视化要素之间的关系"
        }
    },
    {
        "translation": {
            "en": "(a) What target level will a naive Bayes model predict for the following query document: “machine learning is fun”?",
            "zh": "（a） 朴素贝叶斯模型将预测以下查询文档的目标水平：“机器学习很有趣”？"
        }
    },
    {
        "translation": {
            "en": "Although from an analytics perspective, there is really little difference, using the correct terminology makes it much easier for business partners to engage with the analytics project.",
            "zh": "尽管从分析的角度来看，实际上几乎没有区别，但使用正确的术语可以使业务合作伙伴更容易参与分析项目。"
        }
    },
    {
        "translation": {
            "en": "3.4.3 Case Study: Motor Insurance Fraud",
            "zh": "3.4.3 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "We would like to measure how accurately the predicted values match the correct target values.",
            "zh": "我们想衡量预测值与正确目标值匹配的准确性。"
        }
    },
    {
        "translation": {
            "en": "weights, 314",
            "zh": "重量，314"
        }
    },
    {
        "translation": {
            "en": "In variational RNN, the dropout mask is selected once per sequence (rather than at each input), and so the same neurons are dropped across all time-steps in the sequence; for more details see Gal and Ghahramani (2016).",
            "zh": "在变分RNN中，每个序列（而不是在每个输入中）选择一次缺失掩码，因此在序列中的所有时间步长中都丢弃相同的神经元;有关更多详细信息，请参阅Gal and Ghahramani （2016） 。"
        }
    },
    {
        "translation": {
            "en": "Each image contains a single digit that has been size-normalized and centered.",
            "zh": "每个图像都包含一个已标准化大小并居中的单个数字。"
        }
    },
    {
        "translation": {
            "en": "These techniques are generally applicable to all machine learning algorithms but are especially important when similarity-based approaches are used.",
            "zh": "这些技术通常适用于所有机器学习算法，但在使用基于相似性的方法时尤为重要。"
        }
    },
    {
        "translation": {
            "en": "What retention offer would a particular customer best respond to? A system could be built to predict which offer, from a set of possible retention offers, a particular customer would be most likely respond to when contacted by the AT retention team. This could help the retention team convince more customers to stay with AT.",
            "zh": "特定客户最能响应哪些保留优惠？可以构建一个系统来预测，当 AT 保留团队联系时，特定客户最有可能从一组可能的保留产品/服务中响应哪些产品/服务。这可以帮助留存团队说服更多客户留在 AT。"
        }
    },
    {
        "translation": {
            "en": "In the basic form of k-means clustering, the initial cluster centroids, or seeds, are chosen at random uniformly within the feature space.",
            "zh": "在 k 均值聚类的基本形式中，初始聚类质心或种子在特征空间内被随机均匀选择。"
        }
    },
    {
        "translation": {
            "en": "variance, 149, 206, 220, 747, 747, 748, 752",
            "zh": "方差， 149， 206， 220， 747， 747， 748， 752"
        }
    },
    {
        "translation": {
            "en": "Figures 3.2(c)[60] and 3.2(d)[60] show unimodal histograms that exhibit skew.",
            "zh": "图3.2（c）[60]和图3.2（d）[60]显示了表现出偏斜的单峰直方图。"
        }
    },
    {
        "translation": {
            "en": "For each claim the observation and output periods are defined relative to the specific date of that claim.",
            "zh": "对于每一项索赔，观察期和输出期是相对于该索赔的具体日期确定的。"
        }
    },
    {
        "translation": {
            "en": "(b) What items will the system recommend to the following customer? Assume that the recommender system uses the similarity index you chose in the first part of this question and is trained on the sample dataset listed above. Also assume that the system generates recommendations for query customers by finding the customer most similar to them in the dataset and then recommending the items that this similar customer has bought but that the query customer has not bought.",
            "zh": "（b） 系统将向以下客户推荐哪些项目？假设推荐系统使用您在本问题第一部分中选择的相似性指数，并在上面列出的示例数据集上进行训练。此外，假设系统通过在数据集中查找与他们最相似的客户，然后推荐该类似客户已购买但查询客户尚未购买的物料，为查询客户生成建议。"
        }
    },
    {
        "translation": {
            "en": "The effects that can occur when different drugs are taken together can be difficult for doctors to predict.",
            "zh": "当不同的药物一起服用时可能发生的影响对于医生来说可能很难预测。"
        }
    },
    {
        "translation": {
            "en": "All the imaginary pixels have been given a value of 000.",
            "zh": "所有虚像素的值均为 000。"
        }
    },
    {
        "translation": {
            "en": "The fundamental question that analysts must answer is how do the members of a particular cluster differ from the overall population—what makes the members of this cluster special?",
            "zh": "分析师必须回答的基本问题是，特定聚类的成员与总体群体有何不同——是什么让这个聚类的成员与众不同？"
        }
    },
    {
        "translation": {
            "en": "The second category of proofs assumes the use of smooth functions within neurons.",
            "zh": "第二类证明假设在神经元内使用平滑函数。"
        }
    },
    {
        "translation": {
            "en": "14.2   An illustration of the decision boundaries learned by different machine learning algorithms for three artificial datasets.",
            "zh": "14.2 不同机器学习算法对三个人工数据集学习的决策边界的图示。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.7",
            "zh": "图 6.7"
        }
    },
    {
        "translation": {
            "en": "FRACDEV_U/G/R/I/Z",
            "zh": "FRACDEV_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Instead, she needed enough information to understand the key pieces of equipment involved, the important aspects of the night sky objects that she would be classifying, and the key terminology involved.",
            "zh": "相反，她需要足够的信息来了解所涉及的关键设备、她将要分类的夜空天体的重要方面以及所涉及的关键术语。"
        }
    },
    {
        "translation": {
            "en": "(c) The descriptive features in this dataset are of different types.",
            "zh": "（c） 本数据集中的描述性特征属于不同类型。"
        }
    },
    {
        "translation": {
            "en": "Temporal-difference learning is based on calculating the error between a predicted value for the expected return from taking an action in a given state and the actual return that is earned when the agent takes that action (Equation (11.23)[655]).",
            "zh": "时间差分学习基于计算在给定状态下采取行动的预期回报的预测值与智能体采取该行动时获得的实际回报之间的误差（等式（11.23）[655]）。"
        }
    },
    {
        "translation": {
            "en": "Some of these probabilities are highlighted along the edges in Figure 11.3[648].",
            "zh": "其中一些概率在图11.3[648]的边缘突出显示。"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of a reduced version of the mobile phone customer dataset given in Table 10.1[604].",
            "zh": "（a） 表10.1[604]中给出的移动电话客户数据集的简化版本图。"
        }
    },
    {
        "translation": {
            "en": "An example validation set for the post-operative patient routing task.",
            "zh": "术后患者路由任务的示例验证集。"
        }
    },
    {
        "translation": {
            "en": "In more realistic scenarios, however, there are usually many more descriptive features, which means many more possible combinations.",
            "zh": "然而，在更现实的场景中，通常有更多的描述性特征，这意味着更多可能的组合。"
        }
    },
    {
        "translation": {
            "en": "Euclidean norm, 364",
            "zh": "欧几里得范数，364"
        }
    },
    {
        "translation": {
            "en": "Once we have used the backpropagation algorithm to solve the blame assignment problem for all the neurons in the network, we can then use the weight update rule from the gradient descent algorithm to update the weights for each of the neurons in the network.",
            "zh": "一旦我们使用反向传播算法解决了网络中所有神经元的归咎分配问题，我们就可以使用梯度下降算法中的权重更新规则来更新网络中每个神经元的权重。"
        }
    },
    {
        "translation": {
            "en": "44. As noted previously, in some texts, such as Goodfellow et al. (2016), the application of the activation function is treated as a separate step after the feature map has been generated by the application of the filter. In these scenarios, the raw scalar value would be stored in the feature map.",
            "zh": "44. 如前所述，在一些文本中，例如Goodfellow等人（2016年），在应用过滤器生成特征图之后，激活函数的应用被视为一个单独的步骤。在这些情况下，原始标量值将存储在特征图中。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the discounted return at time t = 0 on the basis of this sequence of rewards using a discounting factor of 0.72.",
            "zh": "（a） 使用贴现系数 0.72 根据这一奖励序列计算时间 t = 0 时的贴现回报。"
        }
    },
    {
        "translation": {
            "en": "4. Approaches taking this approach include policy gradient and evolutionary reinforcement learning approaches.",
            "zh": "4. 采用这种方法的方法包括政策梯度和进化强化学习方法。"
        }
    },
    {
        "translation": {
            "en": "ecological modeling, 135",
            "zh": "生态建模，135"
        }
    },
    {
        "translation": {
            "en": "II   PREDICTIVE DATA ANALYTICS",
            "zh": "II 预测性数据分析"
        }
    },
    {
        "translation": {
            "en": "conditional maximum entropy model, 357",
            "zh": "条件最大熵模型，357"
        }
    },
    {
        "translation": {
            "en": "C.2  Examples of continuous functions (shown as solid lines) and their derivatives (shown as dashed lines).",
            "zh": "C.2 连续函数（以实线表示）及其导数（以虚线表示）的例子。"
        }
    },
    {
        "translation": {
            "en": "4.2.3 Information Gain",
            "zh": "4.2.3 信息增益"
        }
    },
    {
        "translation": {
            "en": "where the values used are extracted from Table 3.3[57].",
            "zh": "其中使用的值是从表3.3[57]中提取的。"
        }
    },
    {
        "translation": {
            "en": "Lagrange multipliers, 363",
            "zh": "拉格朗日乘数，363"
        }
    },
    {
        "translation": {
            "en": "In many cases, this limits the creation of an accurate prediction model.",
            "zh": "在许多情况下，这限制了准确预测模型的创建。"
        }
    },
    {
        "translation": {
            "en": "proxy features, 33, 36",
            "zh": "代理功能， 33， 36"
        }
    },
    {
        "translation": {
            "en": "Just because the values of two features are correlated does not mean that an actual causal relationship exists between the two.",
            "zh": "仅仅因为两个特征的值是相关的，并不意味着两者之间存在实际的因果关系。"
        }
    },
    {
        "translation": {
            "en": "To address partition 𝒟7, first the algorithm computes the entropy of 𝒟7",
            "zh": "为了解决分区 D7，该算法首先计算 D7 的熵"
        }
    },
    {
        "translation": {
            "en": "A standard data preprocessing practice for neural networks is to normalize the descriptive features.",
            "zh": "神经网络的标准数据预处理实践是对描述性特征进行规范化。"
        }
    },
    {
        "translation": {
            "en": "10. Cumulative gain, lift, and cumulative lift are introduced in Section 9.4.3.3[565].",
            "zh": "10. 累积增益、升力和累积升力在第 9.4.3.3 节[565] 中介绍。"
        }
    },
    {
        "translation": {
            "en": "customer segmentation, 599",
            "zh": "客户细分，599"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for anti-clockwise spiral galaxy category",
            "zh": "逆时针螺旋星系类别的得票分数"
        }
    },
    {
        "translation": {
            "en": "8. This is much like the rank and prune approach to feature selection described in Section 5.4.6[223].",
            "zh": "8. 这很像第 5.4.6 节[223] 中描述的特征选择的等级和修剪方法。"
        }
    },
    {
        "translation": {
            "en": "In much of this chapter we discuss matrix representations and calculations, so it is worth noting here that a linear function can always be represented by a single matrix multiplication and that an affine transformation in m dimensions can always be represented as a linear function in m + 1 dimensions (as we have done here) and consequently as a single matrix multiplication in m + 1 dimensions.",
            "zh": "在本章的大部分内容中，我们将讨论矩阵表示和计算，因此这里值得注意的是，线性函数总是可以用单个矩阵乘法来表示，并且 m 维中的仿射变换总是可以表示为 m + 1 维的线性函数（正如我们在这里所做的那样），因此可以表示为 m + 1 维的单个矩阵乘法。"
        }
    },
    {
        "translation": {
            "en": "(b) What value would a weighted k-NN prediction model return for the CPI of Russia? Use k = 16 (i.e., the full dataset) and a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query.",
            "zh": "（b） 加权k-NN预测模型对俄罗斯消费物价指数的回报是多少？使用 k = 16（即完整数据集）和邻域和查询之间欧几里得距离平方的倒数的加权方案。"
        }
    },
    {
        "translation": {
            "en": "In Section 3.6.2[89] we explained two of the best known binning techniques, equal-width binning and equal-frequency binning, and discussed some of the general advantages and disadvantages of each technique.",
            "zh": "在第 3.6.2 节[89]中，我们解释了两种最著名的分档技术，等宽分档和等频分档，并讨论了每种技术的一些一般优点和缺点。"
        }
    },
    {
        "translation": {
            "en": "This is achieved by multiplying the values in the confusion matrix by the corresponding values in the profit matrix and summing the results.",
            "zh": "这是通过将混淆矩阵中的值乘以利润矩阵中的相应值并将结果相加来实现的。"
        }
    },
    {
        "translation": {
            "en": "Not surprisingly, neurons that use the leaky rectified linear function as their activation function are known as Leaky ReLUs.",
            "zh": "毫不奇怪，使用泄漏整流线性函数作为其激活函数的神经元被称为泄漏 ReLU。"
        }
    },
    {
        "translation": {
            "en": "Similarity-based approaches are particularly sensitive to the curse of dimensionality and can struggle to perform well for a dataset with large numbers of descriptive features.",
            "zh": "基于相似性的方法对维度的诅咒特别敏感，并且对于具有大量描述性特征的数据集可能难以表现良好。"
        }
    },
    {
        "translation": {
            "en": "For example, the dataset in Table 7.9[351] is based on an agricultural scenario and shows rainfall (in mm per day), RAIN, and resulting grass growth (in kilograms per acre per day), GROWTH, measured on a number of Irish farms during July 2012.",
            "zh": "例如，表7.9[351]中的数据集基于农业情景，显示了2012年7月在一些爱尔兰农场测量的降雨量（以毫米/天为单位）、降雨量和由此产生的草生长（以千克/英亩/天为单位）、生长量。"
        }
    },
    {
        "translation": {
            "en": "For example, if we have a categorical target feature, we may want to ensure that the sample has exactly the same distribution of the different levels of the target feature as the original dataset.",
            "zh": "例如，如果我们有一个分类目标特征，我们可能希望确保样本具有与原始数据集完全相同的目标特征不同级别的分布。"
        }
    },
    {
        "translation": {
            "en": "In essence, most of statistics, and in turn, analytics, is about describing and understanding variation.",
            "zh": "从本质上讲，大多数统计学，以及分析，都是关于描述和理解变化的。"
        }
    },
    {
        "translation": {
            "en": "CLAIM AMOUNT",
            "zh": "索赔金额"
        }
    },
    {
        "translation": {
            "en": "5. In fact, this is the error surface that results from the office rentals dataset when the descriptive features in the dataset are normalized to the range [−1, 1] using range normalization before being used. We discuss normalization subsequently in the chapter.",
            "zh": "5. 实际上，这是当数据集中的描述性特征在使用范围归一化之前使用范围归一化到范围 [−1， 1] 时产生的误差面。我们将在本章的后面讨论归一化。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.30[478] shows some examples of the images from the dataset.",
            "zh": "图 8.30[478] 显示了数据集中图像的一些示例。"
        }
    },
    {
        "translation": {
            "en": "For the purposes of this explanation we assume that the weights are initialized to random values close to zero (e.g., by sampling from a normal distribution with mean μ = 0.0 and σ = 0.1).",
            "zh": "出于本解释的目的，我们假设权重初始化为接近零的随机值（例如，通过从均值 μ = 0.0 且 σ = 0.1 的正态分布中采样）。"
        }
    },
    {
        "translation": {
            "en": "The leaky ReLU and parametric ReLU were developed to address this potential problem.",
            "zh": "泄漏 ReLU 和参数化 ReLU 就是为了解决这个潜在问题而开发的。"
        }
    },
    {
        "translation": {
            "en": "The question sets at the end of each chapter have been revised and expanded—this includes over 50 new questions.",
            "zh": "每章末尾的题集都经过了修订和扩展，其中包括 50 多个新问题。"
        }
    },
    {
        "translation": {
            "en": "He also applied the planned mapping of the REGIONTYPE values to a consistent labeling scheme: {s|suburb} suburb; {t|town} town; {missing|absent} missing.",
            "zh": "他还将 REGIONTYPE 值的计划映射应用于一致的标注方案：{s|suburb} suburb;{t|town} 镇;{missing|absent} 缺失。"
        }
    },
    {
        "translation": {
            "en": "To perform an audit, a tax inspector visits a company and spends a number of days scrutinizing the company’s accounts.",
            "zh": "为了进行审计，税务检查员会访问一家公司并花费几天时间仔细检查公司的账目。"
        }
    },
    {
        "translation": {
            "en": "J48, 169",
            "zh": "J48、169型"
        }
    },
    {
        "translation": {
            "en": "During learning, after completing an episode the agent will return to the initial state and start again.",
            "zh": "在学习过程中，完成一集后，智能体将返回初始状态并重新开始。"
        }
    },
    {
        "translation": {
            "en": "2. This is not to be confused with the probability chain rule discussed in Section B.3[762]. These are two completely different operations.",
            "zh": "2. 这不应与B.3[762]节中讨论的概率链规则相混淆。这是两个完全不同的操作。"
        }
    },
    {
        "translation": {
            "en": "This differential in the weight updates is apparent in Table 8.6[431], which is arranged so that ∂ℰ/∂wi,k terms for the weights on inputs to output layer (Neuron 8) are at the top of the table, and then as we move down the table, we move back through the network.",
            "zh": "权重更新的这种差异在表 8.6[431] 中很明显，表的排列方式是，输入到输出层 （Neuron 8） 的权重的 ∂E/∂wi，k 项位于表的顶部，然后当我们向下移动表时，我们通过网络向后移动。"
        }
    },
    {
        "translation": {
            "en": "This model is being used by the marketing department to determine who should be given the free gift.",
            "zh": "营销部门正在使用此模型来确定谁应该获得免费礼物。"
        }
    },
    {
        "translation": {
            "en": "Predictions are made for a query instance using the target level of the training instance defining the neighborhood in the feature space that contains the query.",
            "zh": "使用训练实例的目标级别对查询实例进行预测，该目标级别在包含查询的特征空间中定义邻域。"
        }
    },
    {
        "translation": {
            "en": "Clearly, the probability of a patient who has a headache and a fever having meningitis should be greater than zero.",
            "zh": "显然，头痛和发烧的患者患脑膜炎的概率应该大于零。"
        }
    },
    {
        "translation": {
            "en": "0.064314",
            "zh": "0.064314"
        }
    },
    {
        "translation": {
            "en": "We often reduce this categorization to just two data types: continuous (encompassing the numeric and interval types), and categorical (encompassing the categorical, ordinal, binary, and textual types).",
            "zh": "我们通常将此分类简化为两种数据类型：连续（包括数值和区间类型）和分类（包括分类、序数、二进制和文本类型）。"
        }
    },
    {
        "translation": {
            "en": "The most direct way of mitigating against the impact of noise in the dataset on a nearest neighbor algorithm is to dilute the dependency of the algorithm on individual (possibly noisy) instances.",
            "zh": "减轻数据集中的噪声对最近邻算法的影响的最直接方法是稀释算法对单个（可能是噪声）实例的依赖性。"
        }
    },
    {
        "translation": {
            "en": "These are merged into a new cluster, 13, as shown in Figure 10.12(d)[621].",
            "zh": "它们被合并到一个新的集群13中，如图10.12（d）[621]所示。"
        }
    },
    {
        "translation": {
            "en": "Proportion",
            "zh": "比例"
        }
    },
    {
        "translation": {
            "en": "Figure 4.12",
            "zh": "图 4.12"
        }
    },
    {
        "translation": {
            "en": "In this case, however, the number of inputs to the weighted sum calculation within a neuron during the backpropagation process is the number of neurons that the neuron propagated its activation to during the forward pass (see Equation 8.22[412]).",
            "zh": "然而，在这种情况下，在反向传播过程中，神经元内加权和计算的输入数是神经元在前向传递期间将其激活传播到的神经元数（参见等式 8.22[412]）。"
        }
    },
    {
        "translation": {
            "en": "Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2017. Mastering the game of go without human knowledge. Nature 550 (7676): 354.",
            "zh": "西尔弗、大卫、黄雅、克里斯·麦迪逊、亚瑟·盖兹、洛朗·西弗尔、乔治·范登德里什、朱利安·施里特维瑟、扬尼斯·安东诺格鲁、韦达维亚斯·潘内尔舍尔瓦姆、马克·兰克托、桑德·迪勒曼、多米尼克·格雷、约翰·纳姆、纳尔·卡尔奇布伦纳、伊利亚·萨茨克弗、蒂莫西·利利克拉普、玛德琳·利奇、科雷·卡武克库格鲁、索尔·格雷佩尔和德米斯·哈萨比斯。2017. 在人类不知情的情况下掌握围棋游戏。自然550（7676）：354。"
        }
    },
    {
        "translation": {
            "en": "single linkage: the distance between the most similar instances in two clusters is used as the overall distance between the clusters;",
            "zh": "单联动：以两个集群中最相似的实例之间的距离作为集群之间的总距离;"
        }
    },
    {
        "translation": {
            "en": "3. The dataset is empty. This can occur when, for a particular partition of the dataset, there are no instances that have a particular feature value. In this case we return a single leaf node tree with the majority target level of the dataset at the parent node that made the recursive call (Algorithm 1[134] Lines 5–6).",
            "zh": "3. 数据集为空。当数据集的特定分区没有具有特定特征值的实例时，可能会发生这种情况。在本例中，我们返回一个单叶节点树，其数据集的大多数目标级别位于进行递归调用的父节点（算法 1[134]，第 5-6 行）。"
        }
    },
    {
        "translation": {
            "en": "constrained quadratic optimization problem, 363",
            "zh": "约束二次优化问题， 363"
        }
    },
    {
        "translation": {
            "en": "Table 12.1",
            "zh": "表 12.1"
        }
    },
    {
        "translation": {
            "en": "In writing this book our target was to deliver an accessible, introductory text on the fundamentals of machine learning and the ways that machine learning is used in practice to solve predictive data analytics problems in business, science, and other organizational contexts. As such, the book goes beyond the standard topics covered in machine learning books and also covers the lifecycle of a predictive analytics project, data preparation, feature design, and model deployment.",
            "zh": "在撰写本书时，我们的目标是提供一份易于理解的介绍性文本，介绍机器学习的基础知识，以及机器学习在实践中用于解决商业、科学和其他组织环境中的预测性数据分析问题的方式。因此，本书超越了机器学习书籍中涵盖的标准主题，还涵盖了预测分析项目的生命周期、数据准备、功能设计和模型部署。"
        }
    },
    {
        "translation": {
            "en": "The ideas of reinforcement learning and Markov decision processes stem from early work by Howard (1960) and Bellman (1957a,b). One fascinating early example is by Michie (1961, 1963) who built an automated tic-tac-toe player based on ideas of reinforcement learning. Due to a lack of access to computing resources, however, this was built using over two hundred matchboxes filled with colored marbles rather than in software!",
            "zh": "强化学习和马尔可夫决策过程的思想源于Howard（1960）和Bellman（1957a，b）的早期工作。Michie（1961,1963）就是一个有趣的早期例子，他基于强化学习的思想构建了一个自动化井字游戏机。然而，由于缺乏对计算资源的访问，这是使用两百多个装满彩色弹珠的火柴盒而不是软件构建的！"
        }
    },
    {
        "translation": {
            "en": "one-row-per-subject, 29",
            "zh": "每个主题一行，29"
        }
    },
    {
        "translation": {
            "en": "confounding feature, 85",
            "zh": "混杂特征，85"
        }
    },
    {
        "translation": {
            "en": "This is useful because often in real-life applications it can be difficult to capture these values.",
            "zh": "这很有用，因为在实际应用中通常很难捕获这些值。"
        }
    },
    {
        "translation": {
            "en": "(short)” plan is also an ideal course plan for a short (one-week) professional training course.",
            "zh": "（short）“计划也是短期（一周）专业培训课程的理想课程计划。"
        }
    },
    {
        "translation": {
            "en": "The structure of the SDSS and Galaxy Zoo combined dataset.",
            "zh": "SDSS和Galaxy Zoo组合数据集的结构。"
        }
    },
    {
        "translation": {
            "en": "The value of taking the action in the state should decrease if the reward and/or future return are negative.",
            "zh": "如果奖励和/或未来回报为负数，则在状态下采取行动的价值应该降低。"
        }
    },
    {
        "translation": {
            "en": "The strong black line across the middle of the rectangle shows the median.",
            "zh": "横跨矩形中间的强黑线表示中位数。"
        }
    },
    {
        "translation": {
            "en": "0.109128",
            "zh": "0.109128"
        }
    },
    {
        "translation": {
            "en": "where is a dataset with a target feature t; levels(t) is the set of levels in the domain of the target feature; and P(t = l) is the probability of an instance of having the target level l. The Gini index can be understood as calculating how often the target levels of instances in a dataset would be misclassified if predictions were made on the sole basis of the distribution of the target levels in the dataset.",
            "zh": "其中 是具有目标特征 t 的数据集;levels（t） 是目标要素域中的一组级别;P（t = l） 是具有目标水平 l 的实例的概率。基尼系数可以理解为计算如果仅根据数据集中目标水平的分布进行预测，则数据集中实例的目标水平被错误分类的频率。"
        }
    },
    {
        "translation": {
            "en": "that tells the agent which action, at, to take when in a given state, st. We can also define a policy in probabilistic terms",
            "zh": "这告诉代理在给定状态下采取哪个操作，ST。我们还可以用概率术语来定义策略"
        }
    },
    {
        "translation": {
            "en": "Portions of the ABT for the motor insurance claims fraud detection problem discussed in Section 2.4.6[42].",
            "zh": "ABT中关于汽车保险索赔欺诈检测问题的部分内容，在第2.4.6节[42]中讨论。"
        }
    },
    {
        "translation": {
            "en": "cosine similarity, 216, 223, 231, 237",
            "zh": "余弦相似度， 216， 223， 231， 237"
        }
    },
    {
        "translation": {
            "en": "Manhattan distance, 185, 185, 231, 237, 577",
            "zh": "曼哈顿距离， 185， 185， 231， 237， 577"
        }
    },
    {
        "translation": {
            "en": "8.6 Further Reading",
            "zh": "8.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "D.4   Summary",
            "zh": "D.4 概述"
        }
    },
    {
        "translation": {
            "en": "We can calculate the Gini index for the dataset in Table 4.3[136]",
            "zh": "我们可以计算表4.3[136]中数据集的基尼系数"
        }
    },
    {
        "translation": {
            "en": "9.12   Confusion matrices for the set of predictions shown in Table 9.11[557] using (a) a prediction score threshold of 0.75 and (b) a prediction score threshold of 0.25.",
            "zh": "9.12 表9.11[557]所示的一组预测的混淆矩阵，使用（a）预测得分阈值为0.75，（b）预测得分阈值为0.25。"
        }
    },
    {
        "translation": {
            "en": "We can get an insight into how we should use this term to update weights by considering the case of a weight wi,k between an output neuron i that uses a logistic activation function and a hidden neuron k. If the output of the neuron i is too high (ai > ti), then δi will be positive because it will be the product of two positive terms:",
            "zh": "我们可以通过考虑使用逻辑激活函数的输出神经元 i 和隐藏神经元 k 之间的权重 wi，k 的情况来深入了解我们应该如何使用这个术语来更新权重。如果神经元 i 的输出太高 （ai > ti），那么 δi 将是正的，因为它将是两个正项的乘积："
        }
    },
    {
        "translation": {
            "en": "For example, we noted previously that in a fully connected feedforward network, if we set var(W(k)) = 1/nin(k), then the variance of the z values in layer k is dependent solely on the variance of the inputs to that layer; and if the inputs are standardized, then the variance of the z values will not be scaled for that layer.",
            "zh": "例如，我们之前提到，在全连接的前馈网络中，如果我们设置 var（W（k）） = 1/nin（k），则第 k 层中 z 值的方差仅取决于该层输入的方差;如果输入是标准化的，则不会缩放该层的 z 值方差。"
        }
    },
    {
        "translation": {
            "en": "Table 6.9",
            "zh": "表 6.9"
        }
    },
    {
        "translation": {
            "en": "Neural networks",
            "zh": "神经网络"
        }
    },
    {
        "translation": {
            "en": "The variant of the decision tree algorithm that should be used for a particular problem depends on the nature of the problem and the dataset being used.",
            "zh": "应用于特定问题的决策树算法的变体取决于问题的性质和所使用的数据集。"
        }
    },
    {
        "translation": {
            "en": "There is no outcome period, as the target feature is determined by whether the company is able to entice the customer to reconsider and, if so, the incentive that was required to do this.",
            "zh": "没有结果期，因为目标功能取决于公司是否能够吸引客户重新考虑，如果是，则取决于这样做所需的激励措施。"
        }
    },
    {
        "translation": {
            "en": "The function f(x) = (x2 + 1)2 (shown in Figure C.2(d)[767]) cannot be differentiated using the rules just described because it is a composite function—it is a function of a function. We can rewrite f(x) as f(x) = (g(x))2 where g(x) = x2 + 1. The differentiation chain rule allows us to differentiate functions of this kind.2 The chain rule is",
            "zh": "函数 f（x） = （x2 + 1）2（如图 C.2（d）[767] 所示）不能用刚才描述的规则来区分，因为它是一个复合函数——它是函数的函数。我们可以将 f（x） 改写为 f（x） = （g（x））2，其中 g（x） = x2 + 1。微分链法则允许我们区分这种函数.2 链法则是"
        }
    },
    {
        "translation": {
            "en": "20. Available from the UCI repository at https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant.",
            "zh": "20. 可从 UCI 存储库 https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant 获得。"
        }
    },
    {
        "translation": {
            "en": "(a) A generalized illustration of the Manhattan and Euclidean distances between two points; and (b) a plot of the Manhattan and Euclidean distances between instances d12 and d5, and between d12 and d17 from Table 5.2[183].",
            "zh": "（a） 两点之间曼哈顿距离和欧几里得距离的概括图示;（b）表5.2[183]中实例d12和d5之间以及d12和d17之间的曼哈顿和欧几里得距离图。"
        }
    },
    {
        "translation": {
            "en": "Continuous features will usually have a cardinality value close to the number of instances in the dataset.",
            "zh": "连续要素的基数值通常接近数据集中的实例数。"
        }
    },
    {
        "translation": {
            "en": "1.11",
            "zh": "1.11"
        }
    },
    {
        "translation": {
            "en": "An alternative strategy for using neural networks for regression is to use linear units in the output layer (i.e., units that do not use an activation function and simply output the weighted sum z as their activation).",
            "zh": "使用神经网络进行回归的另一种策略是在输出层中使用线性单元（即，不使用激活函数并简单地输出加权总和 z 作为其激活的单元）。"
        }
    },
    {
        "translation": {
            "en": "A multivariate logistic regression model has been built to diagnose breast cancer in patients on the basis of features extracted from tissue samples extracted by biopsy.27 The model uses three descriptive features—MITOSES, a measure of how fast cells are growing; CLUMPTHICKNESS, a measure of the amount of layering in cells; and BLANDCHROMATIN, a measure of the texture of cell nuclei—and predicts the status of a biopsy as either benign or malignant.",
            "zh": "已经建立了一个多变量逻辑回归模型，根据从活检提取的组织样本中提取的特征来诊断患者的乳腺癌.27 该模型使用三个描述性特征——有丝分裂，衡量细胞生长速度的指标;CLUMPTHICKNESS，细胞中分层量的量度;和BLANDCHROMATIN，一种衡量细胞核质地的指标，并预测活检的状态是良性还是恶性。"
        }
    },
    {
        "translation": {
            "en": "The density of a unit hypercube is equal to",
            "zh": "单位超立方体的密度等于"
        }
    },
    {
        "translation": {
            "en": "location parameter, 271",
            "zh": "位置参数，271"
        }
    },
    {
        "translation": {
            "en": "We use the convention that the first element in a probability distribution vector is the probability for a true value. For example, the probability distribution for a binary feature, A, with a probability of 0.4 of being true would be written P(A) = < 0.4, 0.6 >.",
            "zh": "我们使用概率分布向量中的第一个元素是真值的概率的约定。例如，二元特征 A 的概率分布为 0.4 为真，写成 P（A） = < 0.4， 0.6 >。"
        }
    },
    {
        "translation": {
            "en": "4.4.2 Handling Continuous Descriptive Features",
            "zh": "4.4.2 处理连续描述性特征"
        }
    },
    {
        "translation": {
            "en": "However, in order to use batch gradient descent, we must update Equation (8.28)[415] to accommodate updating a weight using the sum of the error gradients.",
            "zh": "但是，为了使用批量梯度下降，我们必须更新方程（8.28）[415]，以适应使用误差梯度之和更新权重。"
        }
    },
    {
        "translation": {
            "en": "The raw imaging data captured from the SDSS telescopes is passed through a processing pipeline that identifies individual night sky objects and extracts a number of properties for each object.",
            "zh": "从SDSS望远镜捕获的原始成像数据通过处理管道传递，该处理管道可识别单个夜空物体并提取每个物体的许多属性。"
        }
    },
    {
        "translation": {
            "en": "Table 6.17",
            "zh": "表 6.17"
        }
    },
    {
        "translation": {
            "en": "The most basic of these measures are true positive rate (TPR), true negative rate (TNR), false negative rate (FNR), and false positive rate (FPR), which convert the raw numbers from the confusion matrix into percentages.5 These measures are defined as follows:",
            "zh": "这些措施中最基本的是真阳性率 （TPR）、真阴性率 （TNR）、假阴性率 （FNR） 和假阳性率 （FPR），它们将混淆矩阵中的原始数字转换为百分比。5 这些措施定义如下："
        }
    },
    {
        "translation": {
            "en": "The manner in which these data resources should be combined must be designed and implemented by the analytics practitioner in collaboration with domain experts.",
            "zh": "这些数据资源的组合方式必须由分析从业者与领域专家合作设计和实施。"
        }
    },
    {
        "translation": {
            "en": "The algorithm then keeps iteratively applying the weight update rule until it converges on a stable set of weights beyond which little improvement in model accuracy is possible.",
            "zh": "然后，该算法不断迭代应用权重更新规则，直到它收敛到一组稳定的权重上，超过该权重后，模型精度的改进几乎是不可能的。"
        }
    },
    {
        "translation": {
            "en": "In this case we would calculate an error (or loss) only at the output at the end of the sequence.",
            "zh": "在这种情况下，我们只会在序列末尾的输出处计算误差（或损失）。"
        }
    },
    {
        "translation": {
            "en": "25. This action selection is required here to seed the first iteration of the loop beginning on Line 14[666].",
            "zh": "25. 这里需要这个动作选择来为从第 14 行开始的循环的第一次迭代设定种子[666]。"
        }
    },
    {
        "translation": {
            "en": "where x is any value, and μ and σ are parameters that define the shape of the distribution. Given a probability density function, we can plot the density curve associated with a distribution, which gives us a different way to visualize standard distributions like the normal. Figure 3.3[62] shows the density curves for a number of different normal distributions. The higher the curve for a particular value on the horizontal axis, the more likely that value is.",
            "zh": "其中 x 是任何值，μ 和 σ 是定义分布形状的参数。给定一个概率密度函数，我们可以绘制与分布相关的密度曲线，这为我们提供了一种不同的方法来可视化标准分布，如正态分布。图3.3[62]显示了许多不同正态分布的密度曲线。水平轴上特定值的曲线越高，该值的可能性就越大。"
        }
    },
    {
        "translation": {
            "en": "If the error on the validation starts to increase, then we should stop training.",
            "zh": "如果验证错误开始增加，那么我们应该停止训练。"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed, outline the type of data that would be required.",
            "zh": "（b） 对于您提出的每个分析解决方案，概述所需的数据类型。"
        }
    },
    {
        "translation": {
            "en": "feedforward network, 389",
            "zh": "前馈网络，389"
        }
    },
    {
        "translation": {
            "en": "Box plots are also better suited when the categorical feature has many levels—beyond four levels, small multiple histograms tend to be difficult to interpret.",
            "zh": "当分类特征具有多个级别时，箱形图也更适合 - 超过四个级别，较小的多个直方图往往难以解释。"
        }
    },
    {
        "translation": {
            "en": "Svolba, Gerhard. 2012. Data quality for analytics using SAS. SAS Institute.",
            "zh": "斯沃尔巴，格哈德。2012. 使用 SAS 进行分析的数据质量。SAS研究所。"
        }
    },
    {
        "translation": {
            "en": "A duck-billed platypus. This platypus image was created by Jan Gillbank, English for the Australian Curriculum website (www.e4ac.edu.au). Used under Creative Commons Attribution 3.0 license.",
            "zh": "鸭嘴兽。这张鸭嘴兽图片由Jan Gillbank为澳大利亚课程网站（www.e4ac.edu.au）创建。在知识共享署名 3.0 许可下使用。"
        }
    },
    {
        "translation": {
            "en": "As a result, CPI = high is the MAP CPI value for this query, and this is the prediction the model will return.",
            "zh": "因此，CPI = high 是此查询的 MAP CPI 值，这是模型将返回的预测。"
        }
    },
    {
        "translation": {
            "en": "Considering that all the immediate neighbors of this instance are associated with the yes target level, it is likely that either this instance has been incorrectly labeled and should have a target feature value of yes, or one of the descriptive features for this instance has an incorrect value and hence it is in the wrong location in the feature space.",
            "zh": "考虑到此实例的所有直接邻居都与 yes 目标级别相关联，很可能是此实例被错误标记，目标要素值应为 yes，或者此实例的某个描述性要素的值不正确，因此它在要素空间中的位置错误。"
        }
    },
    {
        "translation": {
            "en": "Correlation is a good measure of the relationship between two continuous features, but it is not by any means perfect.",
            "zh": "相关性是两个连续特征之间关系的一个很好的度量，但它绝不是完美的。"
        }
    },
    {
        "translation": {
            "en": "For example, for churn models, customers will either churn or not churn; for credit scoring models, customers will either repay their loans or not; and for models predicting athlete performance, athletes will either match expectations or not.",
            "zh": "例如，对于流失模型，客户要么流失，要么不流失;对于信用评分模型，客户要么偿还贷款，要么不偿还贷款;对于预测运动员表现的模型，运动员要么符合预期，要么不符合预期。"
        }
    },
    {
        "translation": {
            "en": "In fact, it is the introduction of a non-linearity into the input to output mapping defined by a neuron that enables an artificial neural network to learn complex non-linear mappings; indeed, it is this ability to learn these complex non-linear mappings that makes artificial neural networks such powerful models, in terms of their ability to be accurate on complex tasks.",
            "zh": "事实上，正是在神经元定义的输入到输出映射中引入了非线性，使人工神经网络能够学习复杂的非线性映射;事实上，正是这种学习这些复杂的非线性映射的能力使人工神经网络成为如此强大的模型，因为它们能够在复杂的任务上保持准确。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the posterior probability of LOAN AMOUNT = bin3 conditioned on FRAUD = true will be 0.0 and LOAN AMOUNT = bin3 conditioned FRAUD = false will be 1.0.",
            "zh": "因此，以 FRAUD = true 为条件的 LOAN AMOUNT = bin3 的后验概率为 0.0，以 FRAUD = false 为条件的 LOAN AMOUNT = bin3 的后验概率为 1.0。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.3",
            "zh": "图 1.3"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors for the final model was 2,913.5.10",
            "zh": "最终模型的平方误差之和为 2,913.5.10"
        }
    },
    {
        "translation": {
            "en": "The fact that we can implement the calculation of the weighted sums for an entire layer of neurons as one matrix multiplication operation can be generalized to implementing an entire network as a sequence of matrix multiplications (one per layer of the network).",
            "zh": "我们可以将整个神经元层的加权和计算实现为一个矩阵乘法运算，这一事实可以推广到将整个网络实现为矩阵乘法序列（每层网络一个）。"
        }
    },
    {
        "translation": {
            "en": "(b) 5 hidden layers with 2,000 neurons in each layer",
            "zh": "（b） 5 个隐藏层，每层有 2,000 个神经元"
        }
    },
    {
        "translation": {
            "en": "Figure 8.35[497] also shows that there may be multiple filters applied in parallel in a convolutional layer.",
            "zh": "图8.35[497]还显示，在一个卷积层中可能有多个滤波器并行应用。"
        }
    },
    {
        "translation": {
            "en": "9.4.6 Evaluating Models after Deployment",
            "zh": "9.4.6 部署后评估模型"
        }
    },
    {
        "translation": {
            "en": "This distinction between what generative and discriminative models try to learn is important because the class conditional densities, P(d|tl), can be very complex compared to the class posteriors, P(tl|d) (see Figure 14.1[734]). Consequently, generative models try to learn more complex solutions to the prediction problem than discriminative models.",
            "zh": "生成模型和判别模型试图学习的内容之间的这种区别很重要，因为与类后验 P（tl|d） 相比，类条件密度 P（d|tl） 可能非常复杂（参见图 14.1[734]）。因此，与判别模型相比，生成模型试图学习更复杂的预测问题解决方案。"
        }
    },
    {
        "translation": {
            "en": "The standard approach for handling continuous features in a Bayesian network is to use binning.",
            "zh": "在贝叶斯网络中处理连续特征的标准方法是使用分箱。"
        }
    },
    {
        "translation": {
            "en": "The complementary problems of exploding and vanishing gradients can be understood as examples of the more general challenge of unstable gradients",
            "zh": "梯度爆炸和消失的互补问题可以理解为不稳定梯度的更普遍挑战的例子"
        }
    },
    {
        "translation": {
            "en": "Figure 4.6",
            "zh": "图 4.6"
        }
    },
    {
        "translation": {
            "en": "Let’s return to the original question depicted in Figure 5.15[219]: Are B and C likely to be from the same population from which the dataset has been sampled? Focusing on Figure 5.15(c)[219], for this dataset it appears reasonable to conclude that instance C is a member of the dataset but that B is probably not. To confirm this intuition we can calculate the Mahalanobis distance between A and B and A and C using Equation (5.16)[219] as",
            "zh": "让我们回到图 5.15[219] 中描述的原始问题：B 和 C 是否可能来自从中抽取数据集的同一总体？从图5.15（c）[219]来看，对于这个数据集，似乎可以合理地得出结论，实例C是数据集的成员，但B可能不是。为了证实这一直觉，我们可以使用公式（5.16）[219]计算A和B以及A和C之间的马氏距离，如下所示"
        }
    },
    {
        "translation": {
            "en": "Parametric/",
            "zh": "参数/"
        }
    },
    {
        "translation": {
            "en": "Rob: No…",
            "zh": "Rob： 不..."
        }
    },
    {
        "translation": {
            "en": "3.3.2 Irregular Cardinality",
            "zh": "3.3.2 不规则基数"
        }
    },
    {
        "translation": {
            "en": "non-linear relationship, 368",
            "zh": "非线性关系，368"
        }
    },
    {
        "translation": {
            "en": "6.3   Plots of some well-known probability distributions.",
            "zh": "6.3 一些众所周知的概率分布图。"
        }
    },
    {
        "translation": {
            "en": "Example domain concepts for a motor insurance fraud prediction analytics solution.",
            "zh": "汽车保险欺诈预测分析解决方案的示例域概念。"
        }
    },
    {
        "translation": {
            "en": "The motivation behind using ensemble methods is that a committee of experts working together on a problem are more likely to solve it successfully than a single expert working alone.",
            "zh": "使用集成方法的动机是，与单个专家单独合作相比，共同解决问题的专家委员会更有可能成功解决问题。"
        }
    },
    {
        "translation": {
            "en": "We recommend the use of criteria that compare the error rate in the predictions made by a decision tree when a given subtree is included and when it is pruned.",
            "zh": "我们建议使用标准来比较决策树在包含给定子树和修剪子树时所做的预测中的错误率。"
        }
    },
    {
        "translation": {
            "en": "9.6   A confusion matrix for a naive Bayes model trained on a churn prediction problem.",
            "zh": "9.6 在流失预测问题上训练的朴素贝叶斯模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.7",
            "zh": "图 9.7"
        }
    },
    {
        "translation": {
            "en": "2. Compute P(b | a,C) by summing out C: P(b | a,C) = ∑i P(b | a,Ci)",
            "zh": "2. 通过求和 C 计算 P（b | a，C） = ∑i P（b | a，Ci）"
        }
    },
    {
        "translation": {
            "en": "The primary reason was that it had such a simple derivative.",
            "zh": "主要原因是它有如此简单的导数。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.14",
            "zh": "图 9.14"
        }
    },
    {
        "translation": {
            "en": "The final element of the equation is a column vector that is created in the same way as the row vector at the beginning of the equation—by subtracting each feature value from b from the corresponding feature value from a.",
            "zh": "等式的最后一个元素是列向量，其创建方式与等式开头的行向量相同，即从 a 的相应特征值中减去 b 中的每个特征值。"
        }
    },
    {
        "translation": {
            "en": "2   Data to Insights to Decisions",
            "zh": "2 从数据到洞察再到决策"
        }
    },
    {
        "translation": {
            "en": "This involves floating on your surfboard until a wave approaches and then paddling furiously to gain enough momentum for the wave to pick up both you and your board.",
            "zh": "这包括漂浮在冲浪板上，直到海浪接近，然后疯狂地划桨以获得足够的动力，让海浪将你和你的冲浪板都卷起来。"
        }
    },
    {
        "translation": {
            "en": "9.5   The division of data during the leave-one-out cross validation process. Black rectangles indicate instances in the test set, and white spaces indicate training data.",
            "zh": "9.5 在“留一”交叉验证过程中的数据划分。黑色矩形表示测试集中的实例，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "Consider the following business problem: in spite of having a fraud investigation team that investigates up to 30% of all claims made, a motor insurance company is still losing too much money due to fraudulent claims. The following predictive analytics solutions could be proposed to help address this business problem:",
            "zh": "考虑以下业务问题：尽管有一个欺诈调查小组，可以调查高达 30% 的索赔，但汽车保险公司仍然因欺诈性索赔而损失了太多钱。可以提出以下预测分析解决方案来帮助解决此业务问题："
        }
    },
    {
        "translation": {
            "en": "column of the data quality report in Table 3.3[57] shows that MARITAL STATUS and NUM.",
            "zh": "表3.3[57]中数据质量报告的列显示，婚姻状况和NUM."
        }
    },
    {
        "translation": {
            "en": "composite function, 768",
            "zh": "复合函数，768"
        }
    },
    {
        "translation": {
            "en": "This is different from the normalization we have looked at elsewhere in this chapter as it takes place within an instance rather than across all the values of a feature.",
            "zh": "这与我们在本章其他地方看到的规范化不同，因为它发生在一个实例中，而不是在一个特征的所有值中。"
        }
    },
    {
        "translation": {
            "en": "IV   CASE STUDIES AND CONCLUSIONS",
            "zh": "四、案例研究和结论"
        }
    },
    {
        "translation": {
            "en": "column of the data quality report, we can see that the cardinality of the INSURANCE TYPE feature is 1, an obvious data problem that needs investigation.",
            "zh": "数据质量报告的列中，我们可以看到 INSURANCE TYPE 特征的基数为 1，这是一个明显的数据问题，需要调查。"
        }
    },
    {
        "translation": {
            "en": "Consequently, adding depth to filters not only enables convolutional neural networks to process multi-dimensional input; it also enables the networks to apply multiple filters in parallel to the same input and for later layers in the network to integrate information from across these layers.",
            "zh": "因此，增加滤波器的深度不仅使卷积神经网络能够处理多维输入;它还使网络能够将多个滤波器并行应用于同一输入，并使网络中的后续层能够集成来自这些层的信息。"
        }
    },
    {
        "translation": {
            "en": "Sometimes in an organization, certain values will only have been collected after a certain date, and the data used to generate an ABT might cover time both before and after this date.",
            "zh": "有时，在组织中，某些值仅在特定日期之后收集，并且用于生成 ABT 的数据可能涵盖此日期之前和之后的时间。"
        }
    },
    {
        "translation": {
            "en": "SDSS scientists, however, were struggling to build rule-based systems that could accurately perform more fine-grained classifications.",
            "zh": "然而，SDSS的科学家们正在努力构建基于规则的系统，以准确执行更细粒度的分类。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.21",
            "zh": "图 5.21"
        }
    },
    {
        "translation": {
            "en": "The division of data during the ε0 bootstrap process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "ε0 引导过程中的数据划分。黑色矩形表示测试数据，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "The histogram heights fit the contour line to an extent, but there is a greater variance in the heights across the bins in this image.",
            "zh": "直方图高度在一定程度上符合等值线，但在此图像中，条柱之间的高度差异更大。"
        }
    },
    {
        "translation": {
            "en": "Wolpert David, H. 1996. The lack of a priori distinctions between learning algorithms. Neural Computation 8 (7): 1341–1390.",
            "zh": "沃尔珀特·大卫，H. 1996 年。学习算法之间缺乏先验的区别。神经计算 8 （7）：1341–1390。"
        }
    },
    {
        "translation": {
            "en": "Next, ∂ℰ/∂ak is multiplied by ∂ak/∂zk (which is calculated as previously described, by inputting the zk for the neuron into the derivative of its activation function).",
            "zh": "接下来，∂E/∂ak 乘以 ∂ak/∂zk（如前所述计算，通过将神经元的 zk 输入到其激活函数的导数中）。"
        }
    },
    {
        "translation": {
            "en": "12. The slightly strange name receiver operating characteristic comes from the fact that this approach was first used for tuning radar signals in World War II.",
            "zh": "12. 有点奇怪的名称接收机工作特性来自这样一个事实，即这种方法在第二次世界大战中首次用于调谐雷达信号。"
        }
    },
    {
        "translation": {
            "en": "This example is based on ecological modeling, an area of scientific research that applies statistical and analytical techniques to model ecological processes.",
            "zh": "这个例子基于生态建模，生态建模是一个应用统计和分析技术来模拟生态过程的科学研究领域。"
        }
    },
    {
        "translation": {
            "en": "The backpropagation of the δs and the summation of the error gradients across the examples in the mini-batch are done in the for loop from Line 15[420] to Line 27[420].",
            "zh": "在小批量中，δ 的反向传播和误差梯度的总和是在从第 15 行 [420] 到第 27 行 [420] 的 for 循环中完成的。"
        }
    },
    {
        "translation": {
            "en": "Remember, an analytics project is often iterative, with different stages of the project feeding back into later cycles.",
            "zh": "请记住，分析项目通常是迭代的，项目的不同阶段会反馈到以后的周期中。"
        }
    },
    {
        "translation": {
            "en": "3.5.2   Measuring Covariance and Correlation",
            "zh": "3.5.2 测量协方差和相关性"
        }
    },
    {
        "translation": {
            "en": "The path that the agent would take from the start state to the goal state following this policy is shown in Figure 11.5(f)[663].",
            "zh": "按照此策略，代理从开始状态到目标状态的路径如图 11.5（f）[663] 所示。"
        }
    },
    {
        "translation": {
            "en": "This means that there are 52 different scenarios that could occur if a player is in the PM-DH state and chooses the Twist action (the player is dealt one of 13 possible cards when their hand has one of 4 possible values, so 4 × 13 = 52).",
            "zh": "这意味着，如果玩家处于 PM-DH 状态并选择 Twist 动作，则可能会发生 52 种不同的情况（当玩家的手牌具有 4 个可能的值之一时，玩家将获得 13 张可能的牌中的一张，因此 4 × 13 = 52）。"
        }
    },
    {
        "translation": {
            "en": "Another simple variant of the basic bar plot orders the bars in descending order.6 Typically we use bar plots to discover the most frequent levels for a feature, and this ordering makes this more apparent. Figure A.5[753] shows example bar plots of all three types for the POSITION feature from the dataset in Table A.1[750]. We can see that guard is the most frequent level.",
            "zh": "基本条形图的另一个简单变体是按降序对条形进行排序.6 通常，我们使用条形图来发现特征的最常见级别，这种排序使这一点更加明显。图A.5[753]显示了表A.1[750]中数据集中所有三种类型的POSITION特征的条形图示例。我们可以看到，守卫是最常见的级别。"
        }
    },
    {
        "translation": {
            "en": "9.3   Using a validation set to avoid overfitting in iterative machine learning algorithms.",
            "zh": "9.3 使用验证集来避免迭代机器学习算法中的过度拟合。"
        }
    },
    {
        "translation": {
            "en": "So, which model is making the better prediction?",
            "zh": "那么，哪种模型的预测更好呢？"
        }
    },
    {
        "translation": {
            "en": "where count(f = l | t) is how often the event f = l occurs in the subset of rows in the dataset where the target level is t, count(f | t) is how often the feature, f, took any level in the subset of rows in the dataset where the target level is t, |Domain(f)| is the number of levels in the domain of the feature, and k is a predetermined parameter.",
            "zh": "其中 count（f = l | t） 是事件 f = l 在目标级别为 t 的数据集中行子集中发生的频率，count（f | t） 是特征 f 在目标级别为 t 的数据集中行子集中获取任何级别的频率， |域名（f）|是特征域中的级别数，k 是预定参数。"
        }
    },
    {
        "translation": {
            "en": "PETRORADERR_U/G/R/I/Z",
            "zh": "PETRORADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Applications of unsupervised learning are widespread, including customer segmentations (Berry and Linoff, 2004), anomaly detection (Chandola et al., 2009), and analyzing people’s movement patterns (Li et al., 2015).",
            "zh": "无监督学习的应用很普遍，包括客户细分（Berry and Linoff，2004），异常检测（Chandola et al.，2009）和分析人们的运动模式（Li et al.，2015）。"
        }
    },
    {
        "translation": {
            "en": "9. All values in Table 7.3[331], and similar subsequent tables, are reported at a precision of two places of decimal. Because of this, some error values and squared error values may appear inconsistent. This, however, is only due to rounding differences.",
            "zh": "9. 表7.3[331]中的所有值以及类似的后续表格均以小数点后两位的精度报告。因此，某些误差值和平方误差值可能看起来不一致。然而，这只是由于四舍五入的差异。"
        }
    },
    {
        "translation": {
            "en": "0.53",
            "zh": "0.53"
        }
    },
    {
        "translation": {
            "en": "-0.9394",
            "zh": "-0.9394"
        }
    },
    {
        "translation": {
            "en": "Although this sounds like a lot of probabilities considering the size of the example dataset, it is worth noting that these 22 probabilities would suffice no matter how many new instances are added to the dataset, be it hundreds of thousands, or even millions.",
            "zh": "尽管考虑到示例数据集的大小，这听起来像是很多概率，但值得注意的是，无论向数据集中添加多少新实例，无论是数十万还是数百万，这 22 个概率都足够了。"
        }
    },
    {
        "translation": {
            "en": "After going along to admire her work, Mr. Murphy congratulated his daughter on organizing the letters so well.",
            "zh": "在欣赏了她的作品之后，墨菲先生祝贺他的女儿把信件整理得如此出色。"
        }
    },
    {
        "translation": {
            "en": "Similarity-Based Learning",
            "zh": "基于相似性的学习"
        }
    },
    {
        "translation": {
            "en": "logit, xxvii, 464",
            "zh": "logit，二十七，464"
        }
    },
    {
        "translation": {
            "en": "Implementing features is often a process of approximation through which we attempt to express as much of each domain concept as possible from the data sources that are available to us.",
            "zh": "实现功能通常是一个近似过程，通过该过程，我们试图从可用的数据源中尽可能多地表达每个领域的概念。"
        }
    },
    {
        "translation": {
            "en": "The LOAN AMOUNT value for this query (8,000) is below the threshold for bin1. Consequently, the query LOAN AMOUNT feature will be treated as being equal to bin1 during prediction. Table 6.17[285] lists the calculations of the naive Bayes scores for the candidate predictions for this query: 0.000000462 for true and 0.000000633 for false. The target level false has the highest score and will be the prediction made by the model.",
            "zh": "此查询的 LOAN AMOUNT 值 （8,000） 低于 bin1 的阈值。因此，在预测期间，查询 LOAN AMOUNT 特征将被视为等于 bin1。表 6.17[285] 列出了此查询的候选预测的朴素贝叶斯分数的计算：0.000000462 表示 true，0.000000633 表示 false。目标级别 false 的得分最高，并且是模型做出的预测。"
        }
    },
    {
        "translation": {
            "en": "Finally, the third term in ct−1 is multiplied by an ft of 0.5, which results in the value of 0.5 in c‡.",
            "zh": "最后，将 ct−1 中的第三项乘以 0.5 的 ft，得出 c‡ 中的值为 0.5。"
        }
    },
    {
        "translation": {
            "en": "The initial cluster centroids for the three clusters 1, 2, and 3 are c1 = −0.929,−1.040,−0.831, c2 = −0.329,−1.099,0.377, and c3 = −0.672,−0.505, 0.110.",
            "zh": "三个聚类 1、2 和 3 的初始聚类质心为 c1 = −0.929、−1.040、−0.831、c2 = −0.329、−1.099、0.377 和 c3 = −0.672、−0.505、0.110。"
        }
    },
    {
        "translation": {
            "en": "A stability index value greater than 0.25 suggests that a significant change has occurred and corrective action is required.",
            "zh": "稳定性指数值大于 0.25 表示发生了重大变化，需要采取纠正措施。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn read a number of publications by the SDSS team6 before spending several sessions with Edwin discussing the work that he and his colleagues did.",
            "zh": "Jocelyn 阅读了 SDSS 团队的一些出版物6，然后与 Edwin 讨论了他和他的同事所做的工作。"
        }
    },
    {
        "translation": {
            "en": "CLAIMS, and NUM.",
            "zh": "CLAIMS 和 NUM."
        }
    },
    {
        "translation": {
            "en": "1.3   How Does Machine Learning Work?",
            "zh": "1.3 机器学习是如何工作的？"
        }
    },
    {
        "translation": {
            "en": "In Figure 6.6(b)[275] we can see the three normal distributions used to model the multimodal distribution in Figure 6.6(a)[275].",
            "zh": "在图6.6（b）[275]中，我们可以看到图6.6（a）[275]中用于模拟多峰分布的三个正态分布。"
        }
    },
    {
        "translation": {
            "en": "Deployment, 17, 20, 702, 727, 730",
            "zh": "部署、17、20、702、727、730"
        }
    },
    {
        "translation": {
            "en": "To calculate the expected return of taking action at from state st we can calculate a weighted sum across the expected returns that the agent could receive in every state, st+1, that the agent could reach after taking action at in state st.",
            "zh": "为了计算从状态 st 采取行动的预期回报，我们可以计算代理在每个状态 st+1 中可以获得的预期回报的加权总和，代理在状态 st 采取行动后可以达到该状态。"
        }
    },
    {
        "translation": {
            "en": "The replay memory is given a maximum size, N (usually greater than 10,000), and when it reaches this the oldest instances are dropped as new ones are added.",
            "zh": "重放内存的最大大小为 N（通常大于 10,000），当它达到此大小时，最旧的实例将在添加新实例时被丢弃。"
        }
    },
    {
        "translation": {
            "en": "The following images show histograms of the values of the four descriptive features both for the full dataset and when divided into the three clusters found.",
            "zh": "下图显示了四个描述性要素值的直方图，包括整个数据集和划分为三个聚类时的直方图。"
        }
    },
    {
        "translation": {
            "en": "By contrast, the model shown in Figure 1.3(c)[15], although consistent with the training instances, seems much more complicated than necessary.",
            "zh": "相比之下，图1.3（c）[15]所示的模型虽然与训练实例一致，但似乎比必要的要复杂得多。"
        }
    },
    {
        "translation": {
            "en": "Plots of some well-known probability distributions.",
            "zh": "一些众所周知的概率分布图。"
        }
    },
    {
        "translation": {
            "en": "Support vector machines have become a very popular approach to building predictive models in recent times. They can be quickly trained, are not overly susceptible to overfitting, and work well for high-dimensional data. In contrast to logistic regression models, however, they are not very interpretable, and, especially when kernel functions are used, it is very difficult to understand why a particular prediction has been made.",
            "zh": "最近，支持向量机已成为构建预测模型的一种非常流行的方法。它们可以快速训练，不太容易受到过度拟合的影响，并且适用于高维数据。然而，与逻辑回归模型相比，它们的可解释性不强，尤其是在使用核函数时，很难理解为什么要做出特定的预测。"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, the underlying data will exhibit non-linear relationships that we would like to capture in a model.",
            "zh": "但是，有时基础数据会表现出我们希望在模型中捕获的非线性关系。"
        }
    },
    {
        "translation": {
            "en": "embedding, 624, 626",
            "zh": "嵌入， 624， 626"
        }
    },
    {
        "translation": {
            "en": "In the standard version of the algorithm, the data structure used to store training data is a simple list.",
            "zh": "在标准版本的算法中，用于存储训练数据的数据结构是一个简单的列表。"
        }
    },
    {
        "translation": {
            "en": "31. We discuss the design of evaluation experiments in detail in Chapter 9[533].",
            "zh": "31. 我们在第9章[533]中详细讨论了评估实验的设计。"
        }
    },
    {
        "translation": {
            "en": "blame assignment, 404, 405, 413",
            "zh": "责备分配，404,405,413"
        }
    },
    {
        "translation": {
            "en": "Jocelyn implemented these derived features for inclusion in the final ABT.",
            "zh": "Jocelyn 实现了这些派生功能，以包含在最终的 ABT 中。"
        }
    },
    {
        "translation": {
            "en": "Framing the action-value function as a prediction problem.",
            "zh": "将动作值函数构建为预测问题。"
        }
    },
    {
        "translation": {
            "en": "(b) The area under the ROC curve (AUC) for Model 1 is 0.955 and for Model 2 is 0.851. Which model is performing best?",
            "zh": "（b） 模型1的ROC曲线下面积（AUC）为0.955，模型2为0.851。哪种型号性能最好？"
        }
    },
    {
        "translation": {
            "en": "In this section we describe approaches to visualizing the relationships between pairs of continuous features, pairs of categorical features, and pairs including one categorical and one continuous feature.",
            "zh": "在本节中，我们将介绍可视化连续特征对、分类特征对以及包含一个分类特征和一个连续特征的对之间的关系的方法。"
        }
    },
    {
        "translation": {
            "en": "Email spam filtering models often use a bag-of-words representation for emails.",
            "zh": "垃圾邮件筛选模型通常对电子邮件使用词袋表示形式。"
        }
    },
    {
        "translation": {
            "en": "There are other framings of the reinforcement learning problem under which different framings are used and extra components are added—for example, policy-based reinforcement learning and model-based reinforcement learning.",
            "zh": "强化学习问题还有其他框架，在这些框架下，使用不同的框架并添加额外的组件，例如，基于策略的强化学习和基于模型的强化学习。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.20",
            "zh": "图 5.20"
        }
    },
    {
        "translation": {
            "en": "sabremetrics, 183",
            "zh": "sabremetrics，183"
        }
    },
    {
        "translation": {
            "en": "This analysis explains the vanishing z values plotted in Figure 8.23(b)[453].",
            "zh": "该分析解释了图8.23（b）[453]中绘制的消失的z值。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5[392] illustrates how a neural network can be defined as a sequence of matrix multiplication operations, with an elementwise application of an activation function to the results of each multiplication.",
            "zh": "图 8.5[392] 说明了如何将神经网络定义为矩阵乘法运算序列，并将激活函数应用于每个乘法的结果。"
        }
    },
    {
        "translation": {
            "en": "Neither forward nor backward sequential selection consider the effect of adding or removing combinations of features, and as a result, they aren’t guaranteed to find the absolute optimal subset of features.",
            "zh": "前向和后向顺序选择都不会考虑添加或删除特征组合的影响，因此，它们不能保证找到绝对最优的特征子集。"
        }
    },
    {
        "translation": {
            "en": "It is clear that the clusterings shown in Figures 10.4(d)[606], 10.4(f)[606], and 10.4(h)[606] are quite different from the clustering found previously (shown in Figure 10.3(f)[602]) and are sub-optimal compared with the result we would intuitively expect from looking at the visualization of this dataset.",
            "zh": "很明显，图10.4（d）[606]、10.4（f）[606]和10.4（h）[606]中显示的聚类与之前发现的聚类有很大不同（如图10.3（f）[602]所示），并且与我们直观地期望的结果相比，这些聚类是次优的。"
        }
    },
    {
        "translation": {
            "en": "Table 9.12",
            "zh": "表 9.12"
        }
    },
    {
        "translation": {
            "en": "To use Mahalanobis distance in a nearest neighbor model, we simply use the model in exactly the same way as described previously but substitute Mahalanobis distance for Euclidean distance.",
            "zh": "为了在最近邻模型中使用马氏距离，我们只需以与前面描述完全相同的方式使用该模型，但用马氏距离代替欧几里得距离。"
        }
    },
    {
        "translation": {
            "en": "The next term in the equation, ∑−1, represents the inverse covariance matrix22 computed across all instances in the dataset.",
            "zh": "等式中的下一项 ∑−1 表示在数据集中所有实例中计算的逆协方差矩阵 22。"
        }
    },
    {
        "translation": {
            "en": "nearest neighbor algorithm, 181, 187, 231",
            "zh": "最近邻算法， 181， 187， 231"
        }
    },
    {
        "translation": {
            "en": "The model is using only the SALARY feature and is ignoring the AGE feature when it makes predictions.",
            "zh": "该模型仅使用 SALARY 特征，在进行预测时忽略 AGE 特征。"
        }
    },
    {
        "translation": {
            "en": "CLUMP",
            "zh": "丛"
        }
    },
    {
        "translation": {
            "en": "A common mistake made by many data analysts is to automatically default to modeling unimodally distributed data with a normal distribution.19 There are statistical tests (such as the Kolmogorov-Smirnov test) that can be used to check whether or not a feature is normally distributed, and in cases where the feature is not normally distributed, another unimodal distribution, such as the student-t distribution, may be a better fit.",
            "zh": "许多数据分析师常犯的一个错误是自动默认为使用正态分布对单峰分布数据进行建模。19 有一些统计检验（如 Kolmogorov-Smirnov 检验）可用于检查特征是否呈正态分布，如果特征不是正态分布，则使用另一种单峰分布， 比如 student-t 分布，可能更适合。"
        }
    },
    {
        "translation": {
            "en": "False Positive (FP): an instance in the test set that had a negative target feature value but that was predicted to have a positive target feature value",
            "zh": "误报 （FP）：测试集中具有负目标特征值但预测具有正目标特征值的实例"
        }
    },
    {
        "translation": {
            "en": "Similarity-based approaches to machine learning come from the idea that the best way to make predictions is to simply look at what has worked well in the past and predict the same thing again.",
            "zh": "基于相似性的机器学习方法来自这样一种想法，即进行预测的最佳方法是简单地查看过去行之有效的方法，然后再次预测同样的事情。"
        }
    },
    {
        "translation": {
            "en": "This indicates that Model 1 distinguishes between the target levels most effectively.",
            "zh": "这表明模型 1 最有效地区分了目标水平。"
        }
    },
    {
        "translation": {
            "en": "distance weighted k nearest neighbor, 194",
            "zh": "距离加权 k 最近邻，194"
        }
    },
    {
        "translation": {
            "en": "C.3  (a) A continuous function in two variables, x and y; (b) the partial derivative of this function with respect to x; and (c) the partial derivative of this function with respect to y.",
            "zh": "C.3 （a） x和y两个变量的连续函数;（b） 该函数相对于 x 的偏导数;（c）该函数相对于 y 的偏导数。"
        }
    },
    {
        "translation": {
            "en": "The plot of the derivative of the logistic function in Figure 8.13[410] illustrates that as the value of z approaches 0 (from either side), the slope of the logistic graph increases until it reaches its maximum value at z = 0.0; consequently, we can calculate the maximum value of the derivative of the logistic function using Equation (8.15)[408] by setting z = 0.08",
            "zh": "图 8.13[410] 中的逻辑函数导数图表明，当 z 的值接近 0（从任一侧）时，逻辑图的斜率增加，直到达到 z = 0.0 时的最大值;因此，我们可以使用方程 （8.15）[408] 通过设置 z = 0.08 来计算逻辑函数导数的最大值"
        }
    },
    {
        "translation": {
            "en": "Using Equation (7.5)[316], we can formally define this point on the error surface as the point at which",
            "zh": "使用方程（7.5）[316]，我们可以将误差曲面上的这个点正式定义为"
        }
    },
    {
        "translation": {
            "en": "We then iteratively make small adjustments to these weights based on the output of the error function, which leads to a journey down the error surface that eventually leads to the optimal set of weights.",
            "zh": "然后，我们根据误差函数的输出对这些权重进行迭代调整，这导致了误差表面的向下移动，最终导致最佳权重集。"
        }
    },
    {
        "translation": {
            "en": "The essence of the unsupervised scenario is that no ground truth exists—we don’t know what it is that we are looking for!",
            "zh": "无监督场景的本质是不存在基本事实——我们不知道我们在寻找什么！"
        }
    },
    {
        "translation": {
            "en": "8.13   Plots of the logistic function and its derivative.",
            "zh": "8.13 逻辑函数及其导数图。"
        }
    },
    {
        "translation": {
            "en": "An artificial neural network is built up by connecting lots of simple processing units, and therefore neural networks have a very flexible structure.",
            "zh": "人工神经网络是通过连接许多简单的处理单元来构建的，因此神经网络具有非常灵活的结构。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.6[325] shows a series of snapshots of the candidate models created at steps along this journey toward the best-fit model for this dataset.",
            "zh": "图 7.6[325] 显示了在为该数据集找到最佳拟合模型的过程中创建的候选模型的一系列快照。"
        }
    },
    {
        "translation": {
            "en": "They discovered neurons in the brains of cats that activated only when a visual feature appeared at specific locations in the visual field.",
            "zh": "他们发现猫大脑中的神经元只有在视野中的特定位置出现视觉特征时才会激活。"
        }
    },
    {
        "translation": {
            "en": "In all cases overall classification accuracy was used as the fitness function that drove the search.",
            "zh": "在所有情况下，总体分类准确性都被用作驱动搜索的适应度函数。"
        }
    },
    {
        "translation": {
            "en": "13.10   The confusion matrix for the 5-level two-stage model (classification accuracy: 79.410%, average class accuracy: 53.118%).",
            "zh": "13.10 五级两阶段模型的混淆矩阵（分类准确率：79.410%，平均类准确率：53.118%）。"
        }
    },
    {
        "translation": {
            "en": "A.1  The members of a school basketball team. The height of each player is listed below the player. The dashed gray line shows the arithmetic mean of the players’ heights.",
            "zh": "A.1 学校篮球队的成员。每个玩家的身高都列在玩家下方。灰色虚线表示球员身高的算术平均值。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.12",
            "zh": "图 5.12"
        }
    },
    {
        "translation": {
            "en": "In both of these diagrams, one path to an answer about the character on a card is 1 question long, one path is 2 questions long, and two paths are 3 questions long.",
            "zh": "在这两个图中，关于卡片上字符的答案的一条路径长 1 个问题，一条路径长 2 个问题，两条路径长 3 个问题。"
        }
    },
    {
        "translation": {
            "en": "3. P(q[1],…,q[m] | t = l), the conditional probability of the descriptive features of a query instance taking a specific set of values given that the target feature takes the level l",
            "zh": "3. P（q[1],...,q[m] | t = l），查询实例的描述性特征采用一组特定值的条件概率，假设目标特征的级别为 l"
        }
    },
    {
        "translation": {
            "en": "Done correctly, tailoring the architecture of a network can help the network to learn a particular task by guiding the network to learn useful functions for the target task.",
            "zh": "如果做得正确，定制网络的架构可以通过引导网络学习目标任务的有用功能来帮助网络学习特定任务。"
        }
    },
    {
        "translation": {
            "en": "one-class classification, 235",
            "zh": "一类分类，235"
        }
    },
    {
        "translation": {
            "en": "If we can find the global minimum of the error surface, we can find the set of weights defining the model that best fits the training dataset.",
            "zh": "如果我们能找到误差面的全局最小值，我们就可以找到定义最适合训练数据集的模型的权重集。"
        }
    },
    {
        "translation": {
            "en": "Theorem of Total Probability, 245, 249–251, 757, 763, 764",
            "zh": "总概率定理， 245， 249–251， 757， 763， 764"
        }
    },
    {
        "translation": {
            "en": "Sometimes a feature is actually continuous but in practice can assume only a small range of values—for example, the number of children a person has.",
            "zh": "有时，一个特征实际上是连续的，但实际上只能假设一个小范围的值，例如，一个人的孩子数量。"
        }
    },
    {
        "translation": {
            "en": "Recall that in Section 5.2.2[184] we defined four criteria that a metric must satisfy: non-negativity, identity, symmetry, and triangular inequality.",
            "zh": "回想一下，在第 5.2.2 节[184]中，我们定义了度量必须满足的四个标准：非负性、恒等性、对称性和三角不等式。"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the logistic function (Equation (7.25)[342]) for the range of values [−10, 10]; and (b) the logistic decision surface that results from training a model to represent the generators dataset given in Table 7.6[339] (note that the data has been normalized to the range [−1, 1]).",
            "zh": "（a） 值范围[−10,10]的逻辑函数图（等式（7.25）[342]）;（b）训练模型以表示表7.6[339]中给出的生成器数据集所得到的逻辑决策面（请注意，数据已归一化为范围[−1,1]）。"
        }
    },
    {
        "translation": {
            "en": "In this case there is nothing wrong, and the feature should be left alone.",
            "zh": "在这种情况下，没有任何问题，应该保留该功能。"
        }
    },
    {
        "translation": {
            "en": "The term we want to define is the rate of change of the error of a neuron (a model) with respect to its activation (output): ∂ℰ/∂ak. For this we need only the first term from the product in Equation (8.18)[410]10",
            "zh": "我们要定义的术语是神经元（模型）相对于其激活（输出）的误差变化率：∂E/∂ak。为此，我们只需要方程（8.18）[410]10中乘积的第一项"
        }
    },
    {
        "translation": {
            "en": "A predictive model can be trained to learn the action-value function",
            "zh": "可以训练预测模型来学习动作-价值函数"
        }
    },
    {
        "translation": {
            "en": "(b) The visualization below illustrates the relationship between the continuous BLANDCHROMATIN feature and the target feature CLASS.",
            "zh": "（b） 下面的可视化说明了连续 BLANDCHROMATIN 特征与目标特征 CLASS 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.5[324] shows the journey across the error surface that is taken by the gradient descent algorithm when training this model.",
            "zh": "图 7.5[324] 显示了梯度下降算法在训练该模型时穿越误差表面的过程。"
        }
    },
    {
        "translation": {
            "en": "A probability distribution is a data structure that describes the probability of each possible value a feature can take.",
            "zh": "概率分布是一种数据结构，用于描述要素可以采用的每个可能值的概率。"
        }
    },
    {
        "translation": {
            "en": "This is an example of a confounding feature, a feature that influences two others and so leads to the appearance of a causal relationship.",
            "zh": "这是一个混淆特征的例子，这个特征会影响另外两个特征，从而导致因果关系的出现。"
        }
    },
    {
        "translation": {
            "en": "Another way to address the problem of how to set k is to use a weighted k nearest neighbor approach.",
            "zh": "解决如何设置 k 问题的另一种方法是使用加权 k 最近邻方法。"
        }
    },
    {
        "translation": {
            "en": "This section describes the most important performance measures for evaluating the performance of models with categorical target features.",
            "zh": "本节介绍用于评估具有分类目标特征的模型性能的最重要性能度量。"
        }
    },
    {
        "translation": {
            "en": "2.3.1   Case Study: Motor Insurance Fraud",
            "zh": "2.3.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "4.5   The entropy of different sets of playing cards measured in bits.",
            "zh": "4.5 以比特为单位测量的不同扑克牌组的熵。"
        }
    },
    {
        "translation": {
            "en": "However, for the same example, the target one-hot encoding for Neuron 10 is 1, and so we use Equation (8.80)[469] to calculate the δ for neuron 10 in this example.",
            "zh": "然而，对于同一个例子，神经元 10 的目标单热编码是 1，因此我们使用公式 （8.80）[469] 来计算本例中神经元 10 的δ。"
        }
    },
    {
        "translation": {
            "en": "Consider the task of predicting the likelihood that a customer will buy a new product based on past shopping behavior: features describing the past shopping behavior are calculated over the observation period, while the outcome period is the time during which we observe whether the customer bought the product.",
            "zh": "考虑根据过去的购物行为预测客户购买新产品的可能性的任务：描述过去购物行为的特征是在观察期内计算的，而结果期是我们观察客户是否购买产品的时间。"
        }
    },
    {
        "translation": {
            "en": "DOSE1",
            "zh": "剂量1"
        }
    },
    {
        "translation": {
            "en": "0.4932",
            "zh": "0.4932"
        }
    },
    {
        "translation": {
            "en": "RMSE, 577",
            "zh": "RMSE，577"
        }
    },
    {
        "translation": {
            "en": "Using Equation (9.12)[552], we can calculate the average class accuracy for this problem:",
            "zh": "使用方程（9.12）[552]，我们可以计算出这个问题的平均类准确率："
        }
    },
    {
        "translation": {
            "en": "14.2   A taxonomy of models based on the parametric versus non-parametric and generative versus discriminative distinctions.",
            "zh": "14.2 基于参数与非参数以及生成与判别区别的模型分类。"
        }
    },
    {
        "translation": {
            "en": "The revenue commission currently selects companies for audit at random.",
            "zh": "收入委员会目前随机选择公司进行审计。"
        }
    },
    {
        "translation": {
            "en": "We define the separating hyperplane in the same way that we did at the beginning of the discussion of logistic regression",
            "zh": "我们定义分离超平面的方式与我们在讨论逻辑回归开始时所做的相同"
        }
    },
    {
        "translation": {
            "en": "2. The probability of a test-statistic value as big as or greater than the one computed being the result of chance is calculated. This probability is called a p-value.",
            "zh": "2. 计算检验统计量值等于或大于计算值的概率是偶然的结果。这种概率称为 p 值。"
        }
    },
    {
        "translation": {
            "en": "For example, in financial credit scoring, the Gini coefficient is almost always used to evaluate model performance.",
            "zh": "例如，在金融信用评分中，基尼系数几乎总是用于评估模型性能。"
        }
    },
    {
        "translation": {
            "en": "the more equal a society, the higher the investment that society will make in health and education, and this in turn results in a lower level of corruption",
            "zh": "一个社会越平等，社会在卫生和教育方面的投资就越高，这反过来又导致腐败程度降低"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering approach is to be applied to this dataset with k = 3 and using Euclidean distance.",
            "zh": "k-means 聚类方法将应用于 k = 3 并使用欧几里得距离的数据集。"
        }
    },
    {
        "translation": {
            "en": "3.5.1   Visualizing Relationships between Features",
            "zh": "3.5.1 可视化要素之间的关系"
        }
    },
    {
        "translation": {
            "en": "We saw some of these techniques in Section 7.4.1[332] when we examined the importance of the different descriptive features in a linear regression model through an analysis of the model weights.",
            "zh": "我们在第 7.4.1 节[332]中看到了其中一些技术，当时我们通过分析模型权重来检查线性回归模型中不同描述性特征的重要性。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.2",
            "zh": "图 11.2"
        }
    },
    {
        "translation": {
            "en": "6. See Appendix C[765].",
            "zh": "[6]见附录C[765]。"
        }
    },
    {
        "translation": {
            "en": "black box model, 739",
            "zh": "黑匣子模型，739"
        }
    },
    {
        "translation": {
            "en": "There is always one dimension for every descriptive feature in a dataset.",
            "zh": "数据集中的每个描述性特征始终有一个维度。"
        }
    },
    {
        "translation": {
            "en": "10.4   Information gain for each descriptive feature as a predictor of membership of each cluster based on the clustering of the mobile phone customer dataset in Table 10.1[604] found using k-means clustering (k = 3).",
            "zh": "10.4 根据表10.1[604]中移动电话客户数据集的聚类，使用k均值聚类（k = 3）找到每个描述性特征的信息增益，作为每个聚类成员的预测因子。"
        }
    },
    {
        "translation": {
            "en": "The proportion for each level is calculated by dividing the frequency count for that level by the total sample size.",
            "zh": "每个水平的比例是通过将该水平的频率计数除以总样本数量来计算的。"
        }
    },
    {
        "translation": {
            "en": "Ross’s next task was to fully assess the current situation within AT.",
            "zh": "罗斯的下一个任务是全面评估AT内部的现状。"
        }
    },
    {
        "translation": {
            "en": "For example, the joint probability distribution for the four binary features from Table 6.1[246] (HEADACHE, FEVER, VOMITING, and MENINGITIS) is written3",
            "zh": "例如，表 6.1[246]（头痛、发烧、呕吐和脑膜炎）中四个二元特征的联合概率分布如下3"
        }
    },
    {
        "translation": {
            "en": "Once the ∂ak/∂zk term has been calculated for a neuron, the other term needed to calculate the δ for a neuron k using Equation (8.14)[408] is the rate of change of the error of the network with respect to changes in the activation of the neuron: ∂ℰ/∂ak. As noted previously, the calculation of this term is different for output neurons and hidden neurons.",
            "zh": "一旦计算了神经元的 ∂ak/∂zk 项，使用公式 （8.14）[408] 计算神经元 k δ所需的另一个项是网络误差相对于神经元激活变化的变化率：∂E/∂ak。如前所述，对于输出神经元和隐藏神经元，该项的计算是不同的。"
        }
    },
    {
        "translation": {
            "en": "OUTCOME",
            "zh": "结果"
        }
    },
    {
        "translation": {
            "en": "30. If there are one or more zero entries in the CPTs, then the Markov chain may still be ergodic, but it is non-trivial to prove ergodicity in these cases.",
            "zh": "30. 如果 CPT 中有一个或多个零条目，那么马尔可夫链可能仍然是遍历的，但在这些情况下证明遍历性并非微不足道。"
        }
    },
    {
        "translation": {
            "en": "Finally, Equation (8.117)[512] ensures that the vector of activations that is propagated to the output layer is the same vector that is propagated to the next time-step as the LSTM hidden state.",
            "zh": "最后，方程（8.117）[512]确保传播到输出层的激活向量与传播到下一个时间步的向量与LSTM隐藏状态相同。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.5",
            "zh": "图 13.5"
        }
    },
    {
        "translation": {
            "en": "When agent decisions are allowed, leading to a Markov decision process (MDP), then the dynamics of an environment can be captured in a set of transition matrices, one for each action. For example",
            "zh": "当允许智能体决策时，导致马尔可夫决策过程 （MDP），则可以在一组转换矩阵中捕获环境的动态，每个操作一个。例如"
        }
    },
    {
        "translation": {
            "en": "A specific type of learning, called inductive learning, is used, where learning entails inducing a general rule from a set of specific instances.",
            "zh": "使用一种称为归纳学习的特定类型的学习，其中学习需要从一组特定实例中归纳出一般规则。"
        }
    },
    {
        "translation": {
            "en": "The information gain measure described in Section 4.2.3[127] uses entropy to judge the impurity of the partitions that result from splitting a dataset using a particular feature.",
            "zh": "第4.2.3节[127]中描述的信息增益度量使用熵来判断使用特定特征拆分数据集所导致的分区的杂质。"
        }
    },
    {
        "translation": {
            "en": "For example, if we want to model the behavior of a die using probability, we would begin by creating a random variable, let us call it X, that has a domain equal to the set of possible outcomes when we roll the die, namely, the set .",
            "zh": "例如，如果我们想使用概率对骰子的行为进行建模，我们将首先创建一个随机变量，我们称之为 X，它有一个域等于我们掷骰子时可能结果的集合，即集合。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15(a)[569] graphs the gain for each decile to produce a gain chart. We can see from this chart that the gain is higher for the lower deciles, which contain the instances with the highest scores. This is indicative of the fact that the model is performing reasonably well. Cumulative gain is calculated as the fraction of the total number of positive instances in a test set identified up to a particular decile (i.e., in that decile and all deciles below it):",
            "zh": "图9.15（a）[569]绘制了每个十分位数的增益，以生成增益图。从这张图表中我们可以看到，低十分位数的增益更高，其中包含得分最高的实例。这表明该模型的性能相当不错。累积增益计算为测试集中识别到特定十分位数（即在该十分位数及其以下的所有十分位数）的阳性实例总数的分数："
        }
    },
    {
        "translation": {
            "en": "the rate of change of the error of the network with respect to changes in the activation function (∂ℰ/∂ai).",
            "zh": "网络误差相对于激活函数变化的变化率 （∂E/∂ai）。"
        }
    },
    {
        "translation": {
            "en": "The t-statistic for this test is calculated as follows:",
            "zh": "此检验的 t 统计量计算如下："
        }
    },
    {
        "translation": {
            "en": "The set of assumptions that defines the model selection criteria of a machine learning algorithm is known as the inductive bias6 of the machine learning algorithm.",
            "zh": "定义机器学习算法模型选择标准的一组假设称为机器学习算法的归纳偏差6。"
        }
    },
    {
        "translation": {
            "en": "Both these speedups enable us to remove expensive for loops from the implementation and training of a network: the first removes a for loop over the neurons in a layer, and the second removes a for loop over the examples in a dataset.",
            "zh": "这两种加速都使我们能够从网络的实现和训练中消除昂贵的for循环：第一个删除了层中神经元上的for循环，第二个删除了数据集中示例上的for循环。"
        }
    },
    {
        "translation": {
            "en": "We start by discussing decision trees, the fundamental structure used in information-based machine learning, before presenting the fundamental measures of information content that are used: entropy and information gain.",
            "zh": "我们首先讨论决策树，即基于信息的机器学习中使用的基本结构，然后介绍所使用的信息内容的基本度量：熵和信息增益。"
        }
    },
    {
        "translation": {
            "en": "This idea of using a validation set to identify when overfitting occurs is illustrated in Figure 9.3[542] in Chapter 9[533] in which we discuss the use of a validation set in the general setting of designing a model evaluation experiment.",
            "zh": "第9章[533]的图9.3[542]说明了使用验证集来识别何时发生过拟合的想法，其中我们讨论了在设计模型评估实验的一般设置中使用验证集。"
        }
    },
    {
        "translation": {
            "en": "The three different arrangements of the magnetic letters made by the Murphy children on the Murphy family refrigerator.",
            "zh": "墨菲家冰箱上墨菲家冰箱上三种不同的磁性字母排列。"
        }
    },
    {
        "translation": {
            "en": "In this section we look at extensions and modifications of the k-means clustering algorithm that answer these questions and address these shortcomings.",
            "zh": "在本节中，我们将探讨 k 均值聚类算法的扩展和修改，以回答这些问题并解决这些缺点。"
        }
    },
    {
        "translation": {
            "en": "(b) Given this context, calculate the vector of error gradients with respect to the input hxt for the forget gate sigmoid layer.",
            "zh": "（b） 在此上下文中，计算相对于忘记门 S 形结肠层的输入 hxt 的误差梯度向量。"
        }
    },
    {
        "translation": {
            "en": "This experiment showed behavior uncharacteristic of X-rays, which Professor Blondlot interpreted to mean that another, different type of electromagnetic radiation must exist.",
            "zh": "该实验显示出X射线的特征，Blondlot教授将其解释为必须存在另一种不同类型的电磁辐射。"
        }
    },
    {
        "translation": {
            "en": "First, the spectrograph data collected by the SDSS telescopes was not nearly as extensive as the camera imaging data collected—while there was imaging data for millions of galaxies, there were spectrograms for only hundreds of thousands.",
            "zh": "首先，SDSS望远镜收集的光谱仪数据并不像收集的相机成像数据那么广泛 - 虽然有数百万个星系的成像数据，但只有数十万个星系的光谱图。"
        }
    },
    {
        "translation": {
            "en": "6.10   Definitions of some standard probability distributions.",
            "zh": "6.10 一些标准概率分布的定义。"
        }
    },
    {
        "translation": {
            "en": "A diagram of the CRISP-DM process that shows the six key phases and indicates the important relationships between them. This figure is based on Figure 2 of Wirth and Hipp (2000).",
            "zh": "CRISP-DM 过程的图表，显示了六个关键阶段并指出它们之间的重要关系。该数字基于Wirth和Hipp（2000）的图2。"
        }
    },
    {
        "translation": {
            "en": "What these examples demonstrate is that when we are trying to decide whether a query belongs to a group, we need to consider not only the central tendency of the group, but also how spread out the members in a group are.",
            "zh": "这些示例表明，当我们试图确定查询是否属于某个组时，我们不仅需要考虑该组的中心趋势，还需要考虑组中成员的分布程度。"
        }
    },
    {
        "translation": {
            "en": "(a) An equal-width binning using 5 bins.",
            "zh": "（a） 使用 5 个箱的等宽分箱。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn felt that the important domain concepts were likely to be the target (galaxy type), galaxy appearance measures (e.g., color), spectrography information (e.g., red shift), and position information (the position of each object in the night sky was also available from the SDSS pipeline).",
            "zh": "Jocelyn认为，重要的领域概念可能是目标（星系类型）、星系外观测量（例如，颜色）、光谱信息（例如，红移）和位置信息（每个物体在夜空中的位置也可以从SDSS管道获得）。"
        }
    },
    {
        "translation": {
            "en": "3.5   Advanced Data Exploration",
            "zh": "3.5 高级数据探索"
        }
    },
    {
        "translation": {
            "en": "Figure 4.6(b)[125] shows the impact of this.",
            "zh": "图4.6（b）[125]显示了这种影响。"
        }
    },
    {
        "translation": {
            "en": "The two steps in supervised machine learning: (a) learning and (b) predicting.",
            "zh": "监督机器学习的两个步骤：（a）学习和（b）预测。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15",
            "zh": "图 10.15"
        }
    },
    {
        "translation": {
            "en": "and the probability of a patient having meningitis given that we know that the patient has a headache is",
            "zh": "如果我们知道患者头痛，患者患脑膜炎的概率为"
        }
    },
    {
        "translation": {
            "en": "Multiplying a number by a number less than 1 makes the number smaller.",
            "zh": "将一个数字乘以小于 1 的数字会使该数字变小。"
        }
    },
    {
        "translation": {
            "en": "mini-batch gradient descent, 417, 671",
            "zh": "小批量梯度下降，417,671"
        }
    },
    {
        "translation": {
            "en": "As part of the process of agreeing on the solution to pursue, the analytics practitioner must agree with the business, as far as possible, on the goals that will define a successful model implementation. These goals could be specified in terms of the required accuracy of the model and/or the impact of the model on the business.",
            "zh": "作为就要追求的解决方案达成一致的过程的一部分，分析从业者必须尽可能与业务部门就定义成功模型实施的目标达成一致。这些目标可以根据模型所需的准确性和/或模型对业务的影响来指定。"
        }
    },
    {
        "translation": {
            "en": "The vector of weighted sums for a layer of neurons is denoted by z(k) where k identifies the layer.",
            "zh": "神经元层的加权和向量用 z（k） 表示，其中 k 表示该层。"
        }
    },
    {
        "translation": {
            "en": "So if a prediction model is trained to distinguish between lions, frogs, and ducks, the model will classify every query instance as being either a lion, a frog, or a duck—even if the query is actually a platypus.",
            "zh": "因此，如果训练预测模型来区分狮子、青蛙和鸭子，则该模型会将每个查询实例分类为狮子、青蛙或鸭子，即使查询实际上是鸭嘴兽。"
        }
    },
    {
        "translation": {
            "en": "However, not all the domain concepts in this scenario are time dependent.",
            "zh": "但是，并非此方案中的所有域概念都与时间相关。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the combination of the translations that would be applied by including bias terms in each layer can be replaced by applying a single translation (or single bias term) at the end of the processing.",
            "zh": "此外，通过在每一层中包含偏置项来应用的平移组合可以通过在处理结束时应用单个平移（或单个偏置项）来替换。"
        }
    },
    {
        "translation": {
            "en": "A data quality report for a subset of the features in the SDSS ABT.",
            "zh": "SDSS ABT 中要素子集的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "This figure shows the weights on each connection and for each neuron shows the weighted sum z calculated by that neuron (the number on the left of the neuron) and the activation z for the neuron (the number on the right of the neuron).",
            "zh": "该图显示了每个连接的权重，每个神经元显示了由该神经元计算的加权总和z（神经元左侧的数字）和神经元的激活z（神经元右侧的数字）。"
        }
    },
    {
        "translation": {
            "en": "This difference illustrates the effect of the metric used to select which feature to split on during tree construction.",
            "zh": "这种差异说明了用于选择在树构造期间要分割的要素的指标的影响。"
        }
    },
    {
        "translation": {
            "en": "The Q values of the actions available to the agent from state 0-2 are Q(0-2,up) = 0.223, Q(0-2,down) = 0.582, Q(0-2,left) = 0.672, and Q(0-2,right) = 0.084 (based on Table 11.3[661]).",
            "zh": "从状态 0-2 中，代理可用的操作的 Q 值为 Q（0-2，up） = 0.223、Q（0-2，down） = 0.582、Q（0-2，left） = 0.672 和 Q（0-2，right） = 0.084（基于表 11.3[661]）。"
        }
    },
    {
        "translation": {
            "en": "Again, we should smooth the resulting probabilities.",
            "zh": "同样，我们应该平滑得到的概率。"
        }
    },
    {
        "translation": {
            "en": "7.23   Different margins that satisfy the constraint in Equation (7.44)[364], the instances that define the margin are highlighted in each case; (b) shows the maximum margin and also shows two query instances represented as black dots.",
            "zh": "7.23 满足等式（7.44）[364]中约束条件的不同边距，定义边距的实例在每种情况下都突出显示;（b） 显示最大边距，并显示两个表示为黑点的查询实例。"
        }
    },
    {
        "translation": {
            "en": "The most common way to do this is to define an arbitrary order over the descriptive features before we begin building the tree.",
            "zh": "最常见的方法是在开始构建树之前，在描述性特征上定义任意顺序。"
        }
    },
    {
        "translation": {
            "en": "Assuming that we are training the LSTM network using backpropagation through time, then for each time-step, we calculate the update for each weight by multiplying the δ for the neuron that uses the weight by the input value that weight was applied to, and then we sum these weight updates across the time-steps. The weight is then updated using the summed weight update. For example, the update for the weights in W(f) would be calculated as follows:",
            "zh": "假设我们正在使用随时间反向传播来训练 LSTM 网络，那么对于每个时间步，我们通过将使用权重的神经元的δ乘以施加权重的输入值来计算每个权重的更新，然后我们将这些权重更新相加。然后使用总和的权重更新更新权重。例如，W（f） 中权重的更新将按如下方式计算："
        }
    },
    {
        "translation": {
            "en": "To build a predictive model, we need a large dataset of historical examples of the scenario for which we will make predictions.",
            "zh": "为了构建预测模型，我们需要一个大型数据集，其中包含我们将要进行预测的场景的历史示例。"
        }
    },
    {
        "translation": {
            "en": "1,800",
            "zh": "1,800"
        }
    },
    {
        "translation": {
            "en": "For example, f(x,y) = x2 − y2 + 2x + 4y − xy + 2 is a function defined in terms of two variables, x and y.",
            "zh": "例如，f（x，y） = x2 − y2 + 2x + 4y − xy + 2 是根据两个变量 x 和 y 定义的函数。"
        }
    },
    {
        "translation": {
            "en": "Often this measure of similarity is actually some form of distance measure.",
            "zh": "通常，这种相似性的度量实际上是某种形式的距离度量。"
        }
    },
    {
        "translation": {
            "en": "Multimodal distributions tend to occur when a feature contains a measurement made across a number of distinct groups.",
            "zh": "当要素包含对多个不同组进行的测量时，往往会发生多模态分布。"
        }
    },
    {
        "translation": {
            "en": "The test set with model predictions and scores from Table 9.11[557] extended to include deciles.",
            "zh": "具有表9.11[557]中的模型预测和分数的测试集扩展到包括十分位数。"
        }
    },
    {
        "translation": {
            "en": "Beyond Prediction: Unsupervised Learning",
            "zh": "超越预测：无监督学习"
        }
    },
    {
        "translation": {
            "en": "Interacting: by itself, an interacting descriptive feature is not informative about the value of the target feature. In conjunction with one or more other features, however, it becomes informative.",
            "zh": "交互：交互描述性特征本身并不能提供有关目标特征值的信息。但是，与一个或多个其他功能结合使用时，它变得信息丰富。"
        }
    },
    {
        "translation": {
            "en": "sample mean, 745",
            "zh": "样本均值，745"
        }
    },
    {
        "translation": {
            "en": "12.1   The descriptive features in the ABT developed for the Acme Telephonica churn prediction task.",
            "zh": "12.1 ABT 中为 Acme Telephonica 流失预测任务开发的描述性功能。"
        }
    },
    {
        "translation": {
            "en": "One way to understand how dropout helps is to recognize that because we use a different network on each training example, we are in effect training an ensemble of a very large number of smaller networks rather than training a single large model, and these smaller networks are less complex and so are less likely to overfit.",
            "zh": "理解辍学如何帮助的一种方法是认识到，由于我们在每个训练示例上使用不同的网络，因此我们实际上是在训练大量较小网络的集合，而不是训练单个大型模型，并且这些较小的网络不那么复杂，因此不太可能过度拟合。"
        }
    },
    {
        "translation": {
            "en": "All the simple linear regression and logistic regression models that we have looked at so far model a linear relationship between descriptive features and a target feature.",
            "zh": "到目前为止，我们研究的所有简单线性回归和逻辑回归模型都对描述性特征和目标特征之间的线性关系进行了建模。"
        }
    },
    {
        "translation": {
            "en": "0.2203",
            "zh": "0.2203"
        }
    },
    {
        "translation": {
            "en": "In teaching a technical topic, it is important to show the application of the concepts discussed to real-life problems.",
            "zh": "在教授技术主题时，重要的是要展示所讨论的概念在现实生活中的应用。"
        }
    },
    {
        "translation": {
            "en": "7.4   Extensions and Variations",
            "zh": "7.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Neural networks are a useful modeling approach to use for this prediction problem because, as long as a loss function can be formulated, we can use iterative approaches like the gradient descent algorithm27 to train them.",
            "zh": "神经网络是用于此预测问题的有用建模方法，因为只要可以制定损失函数，我们就可以使用梯度下降算法27 等迭代方法来训练它们。"
        }
    },
    {
        "translation": {
            "en": "Fanaee-T, Hadi, and Goao Gama. 2014. Event labeling combining ensemble detectors and background knowledge. Progress in Artifical Intelligence 2 (2-3): 113–127.",
            "zh": "Fanaee-T、Hadi 和 Goao Gama。2014. 结合集成检测器和背景知识的事件标记.人工智能进展2（2-3）：113-127。"
        }
    },
    {
        "translation": {
            "en": "Also, some of the unsupervised learning approaches described in Chapter 10[597] can be used to address the curse of dimensionality by learning new more compact representations.",
            "zh": "此外，第10章[597]中描述的一些无监督学习方法可用于通过学习新的更紧凑的表示来解决维度的诅咒。"
        }
    },
    {
        "translation": {
            "en": "A probability distribution is a data structure that describes the probability of a feature taking a value for all the possible values the feature can take.",
            "zh": "概率分布是一种数据结构，用于描述要素获取要素可以获取的所有可能值的值的概率。"
        }
    },
    {
        "translation": {
            "en": "Consequently, for a given example, a different set of neurons is dropped each time it is presented to the network (i.e., for each epoch).",
            "zh": "因此，对于给定的示例，每次向网络呈现时（即每个时期）都会丢弃一组不同的神经元。"
        }
    },
    {
        "translation": {
            "en": "and for instances below a separating hyperplane",
            "zh": "以及分离超平面下方的实例"
        }
    },
    {
        "translation": {
            "en": "For example, Figure A.4[749] shows the basketball team from Figure A.3[747] ordered by height. To calculate the 25th percentile, we first calculate index as . So, the 25th percentile is the second value in the ordered list, which is 123. To calculate the 80th percentile, we first calculate index as . Because index is not a whole number, we set index_w to the whole part of index, 6, and index_f to the fractional part, 0.4. Then we can calculate the 80th percentile as",
            "zh": "例如，图A.4[749]显示了图A.3[747]中按身高排序的篮球队。为了计算第 25 个百分位数，我们首先将指数计算为 。因此，第 25 个百分位数是有序列表中的第二个值，即 123。为了计算第 80 个百分位数，我们首先将指数计算为 。因为 index 不是整数，所以我们将 index_w 设置为索引 6 的整个部分，将 index_f 设置为小数部分 0.4。然后我们可以计算第 80 个百分位数为"
        }
    },
    {
        "translation": {
            "en": "Obviously, however, using programming languages also has its disadvantages.",
            "zh": "然而，显然，使用编程语言也有其缺点。"
        }
    },
    {
        "translation": {
            "en": "(a) Which of the descriptive features will the ID3 decision tree induction algorithm choose as the feature for the root node of the decision tree?",
            "zh": "（a） ID3决策树归纳算法将选择哪些描述性特征作为决策树根节点的特征？"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18",
            "zh": "图 5.18"
        }
    },
    {
        "translation": {
            "en": "We use d2 because the processing of this example has been highlighted in Figure 8.14[425], and so it will be easier to identify the relevant zk and ak values for each neuron for this example.",
            "zh": "我们之所以使用 d2，是因为图 8.14[425] 中突出显示了此示例的处理，因此更容易识别此示例中每个神经元的相关 zk 和 ak 值。"
        }
    },
    {
        "translation": {
            "en": "(1993) extended the universal approximation theorem to include networks with neurons using rectifier activation functions; however, Montúfar (2014) has shown that these networks can also require an exponential number of neurons in the hidden layer.",
            "zh": "（1993）扩展了通用近似定理，以包括使用整流器激活函数的神经元网络;然而，Montúfar（2014）已经表明，这些网络在隐藏层中也可能需要指数数量的神经元。"
        }
    },
    {
        "translation": {
            "en": "2.0499",
            "zh": "2.0499"
        }
    },
    {
        "translation": {
            "en": "Second, the selection process used to generate the original list of 10 million people was based on telephone directories.",
            "zh": "其次，用于生成1 000万人原始名单的甄选过程是以电话簿为基础的。"
        }
    },
    {
        "translation": {
            "en": "optimal control domain, 653",
            "zh": "最优控制域，653"
        }
    },
    {
        "translation": {
            "en": "This results in the model having a higher coverage with respect to the possible queries it can handle.",
            "zh": "这导致模型在它可以处理的可能查询方面具有更高的覆盖率。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(b)[74] shows a scatter plot for the SPONSORSHIP EARNINGS and AGE features from Table 3.7[73].",
            "zh": "图3.5（b）[74]显示了表3.7[73]中赞助收入和年龄特征的散点图。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.2",
            "zh": "图 13.2"
        }
    },
    {
        "translation": {
            "en": "We can use Bayes’ Theorem to answer both of these questions. To calculate the probability that the patient actually has the disease based on the evidence of the test result, P(d | t), we apply Bayes’ Theorem:",
            "zh": "我们可以用贝叶斯定理来回答这两个问题。为了根据测试结果的证据计算患者实际患有该疾病的概率，P（d | t），我们应用贝叶斯定理："
        }
    },
    {
        "translation": {
            "en": "CLUMPTHICKNESS: A measurae of the amount of layering in cells (1 to 10).",
            "zh": "团块厚度：细胞分层量的测量值（1 至 10）。"
        }
    },
    {
        "translation": {
            "en": "(b) The table below lists a set of instances from the house alarm domain. Using the data in this table, create the conditional probability tables (CPTs) for the network you created in the first part of this question, and round the probabilities to two places of decimal.",
            "zh": "（b） 下表列出了房屋报警域中的一组实例。使用此表中的数据，为您在本问题第一部分中创建的网络创建条件概率表 （CPT），并将概率四舍五入到小数点后两位。"
        }
    },
    {
        "translation": {
            "en": "Table 8.4",
            "zh": "表 8.4"
        }
    },
    {
        "translation": {
            "en": "4. the weighted sum calculated in Step (3) is passed through a non-linear activation function φ.",
            "zh": "4.在步骤（3）中计算的加权和通过非线性激活函数φ传递。"
        }
    },
    {
        "translation": {
            "en": "xi refers to the ith instance in a dataset.",
            "zh": "习 是指数据集中的第 i 个实例。"
        }
    },
    {
        "translation": {
            "en": "The action with the highest Q value from state 0-2 is therefore left and this is the one used in the update equation.",
            "zh": "因此，从状态 0-2 中具有最高 Q 值的动作被保留下来，这是更新方程中使用的动作。"
        }
    },
    {
        "translation": {
            "en": "GPUs, 394",
            "zh": "显卡，394"
        }
    },
    {
        "translation": {
            "en": "(a) P(VOMITING = true)",
            "zh": "（a） P（VOMITING = 真）"
        }
    },
    {
        "translation": {
            "en": "This is partly because naive Bayes models are able to make correct predictions even if the probabilities that they calculate are incorrect, so long as the error in the calculated probabilities does not affect the relative rankings of the different target levels.",
            "zh": "这在一定程度上是因为朴素贝叶斯模型能够做出正确的预测，即使它们计算的概率不正确，只要计算概率中的误差不影响不同目标水平的相对排名。"
        }
    },
    {
        "translation": {
            "en": "In summary, the inductive bias underpinning similarity-based machine learning algorithms is that things that are similar (i.e., instances that have similar descriptive features) also have the same target feature values.",
            "zh": "总之，基于相似性的机器学习算法的归纳偏差是相似的事物（即具有相似描述性特征的实例）也具有相同的目标特征值。"
        }
    },
    {
        "translation": {
            "en": "The features in an ABT can be of two types: raw features or derived features. Raw features are features that come directly from raw data sources. For example, customer age, customer gender, loan amount, or insurance claim type are all descriptive features that we would most likely be able to transfer directly from a raw data source to an ABT.",
            "zh": "ABT 中的特征可以分为两种类型：原始特征或派生特征。原始要素是直接来自原始数据源的要素。例如，客户年龄、客户性别、贷款金额或保险索赔类型都是描述性特征，我们很可能能够直接从原始数据源传输到 ABT。"
        }
    },
    {
        "translation": {
            "en": "The features place a particular emphasis on claims relating to soft tissue injuries (for example, whiplash) because it is understood within the insurance industry that these are frequently associated with fraudulent claims.",
            "zh": "这些特点特别强调与软组织损伤（例如挥鞭伤）相关的索赔，因为在保险业内，人们了解到这些索赔通常与欺诈性索赔有关。"
        }
    },
    {
        "translation": {
            "en": "We can think of the output of most unsupervised machine learning models as new generated features that can be appended to the original dataset to augment or enrich it.",
            "zh": "我们可以将大多数无监督机器学习模型的输出视为新生成的特征，这些特征可以附加到原始数据集中以增强或丰富它。"
        }
    },
    {
        "translation": {
            "en": "Brown, Noam, and Tuomas Sandholm. 2017. Libratus: The superhuman AI for no-limit poker. In Proceedings of the twenty-sixth international joint conference on artificial intelligence, IJCAI 2017, Melbourne, Australia, August 19–25, 2017, 5226–5228. doi:10.24963/ijcai.2017/772.",
            "zh": "布朗、诺姆和托马斯·桑德霍尔姆。2017. Libratus：无限扑克的超人 AI。2017年8月19-25日，澳大利亚墨尔本，IJCAI 2017，第26届国际人工智能联合会议论文集，第5226-5228页。doi：10.24963/ijcai.2017/772."
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] illustrates the expansion of the chain of products as the error gradient is propagated back through the network.",
            "zh": "公式 8.41[436] 说明了当误差梯度通过网络传播回时产品链的扩展。"
        }
    },
    {
        "translation": {
            "en": "batch, 327, 417",
            "zh": "批次， 327， 417"
        }
    },
    {
        "translation": {
            "en": "The dataset in Figure 5.15(a)[219] is equally distributed in all directions around A, and as a result, we can say that B and C are equally likely to be from the same population as the dataset.",
            "zh": "图 5.15（a）[219] 中的数据集在 A 周围的各个方向上均等分布，因此，我们可以说 B 和 C 与数据集来自同一总体的可能性相同。"
        }
    },
    {
        "translation": {
            "en": "[Member prediction] Data Requirements: This solution would not only require that a large collection of claims labeled as either fraudulent or non-fraudulent exist with all relevant details, but also that all claims and policies can be connected to an identifiable member.",
            "zh": "[会员预测]数据要求：此解决方案不仅要求存在大量标记为欺诈性或非欺诈性的声明，其中包含所有相关详细信息，而且还要求所有声明和保单都可以连接到可识别的成员。"
        }
    },
    {
        "translation": {
            "en": "Deep Learning",
            "zh": "深度学习"
        }
    },
    {
        "translation": {
            "en": "9.6   Further Reading",
            "zh": "9.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "3.3   (a) Three normal distributions with different means but identical standard deviations; and (b) three normal distributions with identical means but different standard deviations.",
            "zh": "3.3 （a） 均值不同但标准差相同的三种正态分布;（b）均值相同但标准差不同的三种正态分布。"
        }
    },
    {
        "translation": {
            "en": "13.4.2   Feature Selection",
            "zh": "13.4.2 功能选择"
        }
    },
    {
        "translation": {
            "en": "19. This is an example of an ensemble model like those described in Section 4.4.5[158].",
            "zh": "19. 这是第4.4.5节[158]中描述的集成模型的示例。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning an agent inhabiting an environment learns to perform a task by pursuing actions that achieve the highest cumulative reward, where a reward is immediate feedback that follows an action to indicate how successful it was. The main application of reinforcement learning is to learn control strategies, for example, in robotics.",
            "zh": "在强化学习中，居住在环境中的智能体通过追求获得最高累积奖励的行动来学习执行任务，其中奖励是行动之后的即时反馈，以表明它有多成功。强化学习的主要应用是学习控制策略，例如在机器人技术中。"
        }
    },
    {
        "translation": {
            "en": "17. This example is inspired by the research reported in Fanaee-T and Gama (2014). The dataset presented here is synthesized for this example; however, a real bike sharing dataset for this task is available through the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset.",
            "zh": "17. 这个例子的灵感来自Fanaee-T和Gama（2014年）报告的研究。此处提供的数据集是针对此示例合成的;但是，可以通过 archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset 的 UCI 机器学习存储库（Bache 和 Lichman，2013 年）获得此任务的真实自行车共享数据集。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.20",
            "zh": "图 4.20"
        }
    },
    {
        "translation": {
            "en": "Gross, Philip, Albert Boulanger, Marta Arias, David L. Waltz, Philip M. Long, Charles Lawson, Roger Anderson, Matthew Koenig, Mark Mastrocinque, William Fairechio, et al.. 2006. Predicting electricity distribution feeder failures using machine learning susceptibility analysis. In Proceedings of the twenty-first national conference on artificial intelligence (AAAI’06), 1705–1711. AAAI Press.",
            "zh": "格罗斯、菲利普、阿尔伯特·布兰格、玛尔塔·阿里亚斯、大卫·华尔兹、菲利普·朗、查尔斯·劳森、罗杰·安德森、马修·柯尼希、马克·马斯特罗辛克、威廉·费尔奇奥等。2006. 使用机器学习敏感性分析预测配电馈线故障.第二十一届全国人工智能会议 （AAAI'06） 会议记录，1705-1711 年。AAAI出版社。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.4",
            "zh": "图 3.4"
        }
    },
    {
        "translation": {
            "en": "14. This is the same as the batch gradient descent discussed in Chapter 7[311].",
            "zh": "14. 这与第7章[311]中讨论的批次梯度下降相同。"
        }
    },
    {
        "translation": {
            "en": "The decision tree for the post-operative patient routing task.",
            "zh": "术后患者路由任务的决策树。"
        }
    },
    {
        "translation": {
            "en": "13.3   Bar plots of the different galaxy types present in the full SDSS dataset for the 3-level and 5-level target features.",
            "zh": "13.3 完整SDSS数据集中3级和5级目标特征中不同星系类型的条形图。"
        }
    },
    {
        "translation": {
            "en": "The statement X is N(μ,σ) is often used as a shorthand for X is a normally distributed feature with mean μ and standard deviation σ.4 One important characteristic of the normal distribution is often described as the 68−95−99.7 rule.",
            "zh": "陈述 X 是 N（μ，σ） 通常用作 X 是具有均值μ和标准差σ的正态分布特征的简写.4 正态分布的一个重要特征通常被描述为 68−95−99.7 规则。"
        }
    },
    {
        "translation": {
            "en": "By offering these customers incentives now to prevent them from churning, AT would ensure that it received the full value from these customers in the future.",
            "zh": "通过现在为这些客户提供激励措施以防止他们流失，AT将确保将来从这些客户那里获得全部价值。"
        }
    },
    {
        "translation": {
            "en": "As a result, each bootstrap sample will be different, and this means that models trained on different bootstrap samples will also be different.26",
            "zh": "因此，每个 bootstrap 样本都会不同，这意味着在不同的 bootstrap 样本上训练的模型也会不同26。"
        }
    },
    {
        "translation": {
            "en": "For example, based on the confusion matrix in Table 13.5(c)[720], the misclassification rate for the elliptical target level is only 8.756%, while for the spiral target level, it is higher, at 18.693%, and for the other target level, it is a fairly dire 98.230%.",
            "zh": "例如，根据表13.5（c）[720]中的混淆矩阵，椭圆目标水平的错误分类率仅为8.756%，而螺旋目标水平的错误分类率更高，为18.693%，而对于其他目标水平，错误分类率为98.230%。"
        }
    },
    {
        "translation": {
            "en": "A much more important advantage, however, is that it can enable significant computational speedups in the training and application of a neural network.",
            "zh": "然而，一个更重要的优势是，它可以在神经网络的训练和应用中实现显着的计算加速。"
        }
    },
    {
        "translation": {
            "en": "In each practice episode, each one of the decisions Sarah made led to immediate feedback: either splashing into the river (negative feedback), landing successfully on the next stepping-stone (positive feedback), turning back on her tracks (very negative feedback), or landing on the far riverbank (very positive feedback).",
            "zh": "在每一集练习中，莎拉做出的每一个决定都会立即得到反馈：要么溅入河中（负面反馈），要么成功降落在下一个垫脚石上（正面反馈），要么回到原地（非常负面的反馈），要么降落在远处的河岸上（非常积极的反馈）。"
        }
    },
    {
        "translation": {
            "en": "This parameter is the degrees of freedom of the distribution.",
            "zh": "此参数是分布的自由度。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.17",
            "zh": "图 9.17"
        }
    },
    {
        "translation": {
            "en": "Calculate the sum of squared errors for this network on this example.",
            "zh": "在此示例中计算此网络的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, most data analytics packages and programming APIs provide functions that implement methods to fit a specified distribution to a given dataset.20",
            "zh": "幸运的是，大多数数据分析包和编程 API 都提供了实现方法的函数，以便将指定的分布拟合到给定的数据集20。"
        }
    },
    {
        "translation": {
            "en": "Modeling: In the Modeling phase of the CRISP-DM process, the machine learning work occurs. Different machine learning algorithms are used to build a range of prediction models from which the best model will be selected for deployment.",
            "zh": "建模：在 CRISP-DM 流程的建模阶段，将进行机器学习工作。不同的机器学习算法用于构建一系列预测模型，从中选择最佳模型进行部署。"
        }
    },
    {
        "translation": {
            "en": "Note that there is only a single δ per neuron, but typically there are many weights associated with each neuron, and so the δ for a neuron will often be used in the calculation of multiple weight error gradients, once for the weight on each connection into the neuron.",
            "zh": "请注意，每个神经元只有一个δ，但通常每个神经元都有许多权重，因此神经元的δ通常用于计算多个权重误差梯度，一次用于与神经元的每个连接上的权重。"
        }
    },
    {
        "translation": {
            "en": "The input vector has been augmented with the dummy feature d[0] = 1, which is stored in the top row of the vector.",
            "zh": "输入向量已使用虚拟特征 d[0] = 1 进行扩充，该特征存储在向量的顶行中。"
        }
    },
    {
        "translation": {
            "en": "Those solutions that are deemed feasible should then be presented to the business, and one or more should be selected for implementation.",
            "zh": "然后，应将那些被认为可行的解决方案提交给业务部门，并应选择一个或多个解决方案进行实施。"
        }
    },
    {
        "translation": {
            "en": "The stability index can be used for both categorical and continuous targets.",
            "zh": "稳定性指数可用于分类目标和连续目标。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, when the system makes a mistake, it is desirable that the system can be retrained immediately using the instance that generated the mistake.",
            "zh": "此外，当系统出错时，最好能够立即使用生成错误的实例对系统进行重新训练。"
        }
    },
    {
        "translation": {
            "en": "The set of weights used by a neuron determine the type of visual feature to which the neuron activates in response; consequently, these weight matrices are called filters because they filter the input by returning high activations for certain patterns of inputs and low activations for others.",
            "zh": "神经元使用的权重集决定了神经元响应激活的视觉特征类型;因此，这些权重矩阵被称为过滤器，因为它们通过返回某些输入模式的高激活和其他输入模式的低激活来过滤输入。"
        }
    },
    {
        "translation": {
            "en": "The adjacent instances in the ordering that have different target feature levels are then selected as possible threshold points.",
            "zh": "然后，选择排序中具有不同目标特征级别的相邻实例作为可能的阈值点。"
        }
    },
    {
        "translation": {
            "en": "—Edwin Powell Hubble",
            "zh": "——埃德温·鲍威尔·哈勃"
        }
    },
    {
        "translation": {
            "en": "3.3.4.4 The data quality plan Based on the analysis described in the preceding sections, the data quality plan shown in Table 3.5[68] was created. This records each of the data quality issues due to valid data that have been identified in the motor insurance fraud ABT. During the Modeling phase of the project, we will use this table as a reminder of data quality issues that could affect model training. At the end of the next section, we complete this table by adding potential handling strategies.",
            "zh": "3.3.4.4 数据质量计划 根据前几节所述的分析，创建了表 3.5[68] 所示的数据质量计划。这记录了由于汽车保险欺诈 ABT 中已识别的有效数据而导致的每个数据质量问题。在项目的建模阶段，我们将使用此表来提醒可能影响模型训练的数据质量问题。在下一节的末尾，我们通过添加可能的处理策略来完成此表。"
        }
    },
    {
        "translation": {
            "en": "For these distributions, the parameters are set using guided search techniques such as gradient descent.",
            "zh": "对于这些分布，参数是使用引导式搜索技术（如梯度下降）设置的。"
        }
    },
    {
        "translation": {
            "en": "First, supervised machine learning is based on the stationarity assumption, which states that the data doesn’t change—it remains stationary—over time.",
            "zh": "首先，监督机器学习基于平稳性假设，该假设指出数据不会随时间变化而改变——它保持静止。"
        }
    },
    {
        "translation": {
            "en": "Put more formally:",
            "zh": "更正式地说："
        }
    },
    {
        "translation": {
            "en": "Returning to our example query, in order to calculate P(h,f,¬v | m), the chain rule requires us to define three conditional probabilities, P(h | m), P(f | h,m), and P(¬v | f,h,m).",
            "zh": "回到我们的示例查询，为了计算 P（h，f，¬v | m），链式法则要求我们定义三个条件概率，P（h | m）、P（f | h，m） 和 P（¬v | f，h，m）。"
        }
    },
    {
        "translation": {
            "en": "Ideally the histogram heights should follow the dashed line.",
            "zh": "理想情况下，直方图高度应遵循虚线。"
        }
    },
    {
        "translation": {
            "en": "constraints, 363",
            "zh": "约束， 363"
        }
    },
    {
        "translation": {
            "en": "(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (α0 = 0.18, c = 10 ); and (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "（a） 使用学习率衰减时办公室租赁预测问题的误差面行程 （α0 = 0.18， c = 10 ）;（b）此旅程中误差平方和的变化图。"
        }
    },
    {
        "translation": {
            "en": "This model could be used to assign every newly arising claim a fraud likelihood, and those that are most likely to be fraudulent could be flagged for investigation by the insurance company’s claims investigators.",
            "zh": "该模型可用于为每个新出现的索赔分配欺诈可能性，而那些最有可能是欺诈的索赔可以被保险公司的索赔调查员标记进行调查。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.4[323] shows an error surface (defined over just two weights so that we can visualize the error surface) and some examples of the path down this surface that the gradient descent algorithm would take from different random starting positions.5",
            "zh": "图 7.4[323] 显示了一个误差面（仅定义两个权重，以便我们可以可视化误差面）以及梯度下降算法从不同随机起始位置沿该曲面向下的路径的一些示例5。"
        }
    },
    {
        "translation": {
            "en": "The exact implementation details of anti-discrimination law change, however, across the countries in the European Union.",
            "zh": "然而，反歧视法的确切实施细节在欧盟各国有所不同。"
        }
    },
    {
        "translation": {
            "en": "We have also provided an in-depth introduction to some of the most popular machine learning approaches with examples that illustrate how these algorithms work.",
            "zh": "我们还深入介绍了一些最流行的机器学习方法，并举例说明了这些算法的工作原理。"
        }
    },
    {
        "translation": {
            "en": "“Ever tried. Ever failed. No matter. Try again. Fail again. Fail better.”",
            "zh": "“试过了。曾经失败过。不管怎样。再试一次。再次失败。失败得更好。"
        }
    },
    {
        "translation": {
            "en": "This repeated multiplication of the error gradient can rapidly scale up the size of the gradient if a weight in Whh is > 1 (causing our weight updates to become too large and our training to become unstable) or cause the gradient to vanish if the weight is very small.",
            "zh": "如果以 Wh>h 为单位的权重为 1，则误差梯度的重复乘法可以迅速扩大梯度的大小（导致我们的权重更新变得太大，我们的训练变得不稳定），或者如果权重非常小，则会导致梯度消失。"
        }
    },
    {
        "translation": {
            "en": "2.4.5 Implementing Features",
            "zh": "2.4.5 实现功能"
        }
    },
    {
        "translation": {
            "en": "We hope that these additions and revisions will make the second edition of the book more useful and relevant than the first. We are indebted to all those people—readers, students, instructors, reviewers, colleagues, friends, and family—who gave us feedback on the first edition, which has helped us massively in designing this new edition.",
            "zh": "我们希望这些补充和修订将使本书的第二版比第一版更有用、更有意义。我们感谢所有读者、学生、教师、审稿人、同事、朋友和家人，他们为我们提供了第一版的反馈，这对我们设计新版有很大帮助。"
        }
    },
    {
        "translation": {
            "en": "This line illustrates a very simple linear function that maps AGE to INCOME.",
            "zh": "这条线说明了一个非常简单的线性函数，它将 AGE 映射到 INCOME。"
        }
    },
    {
        "translation": {
            "en": "Given that the agent started with no knowledge of the game and has learned playing strategy through maximization of cumulative reward alone in a simple state space, this is pretty impressive.22",
            "zh": "鉴于智能体一开始对游戏一无所知，并且通过在简单状态空间中仅通过最大化累积奖励来学习游戏策略，这令人印象深刻22。"
        }
    },
    {
        "translation": {
            "en": "SEX: The sex of the person screened, either male or female.",
            "zh": "性别：被筛查者的性别，男性或女性。"
        }
    },
    {
        "translation": {
            "en": "Looking first at Figure C.2(a)[767], the function here is very simple, f(x) = 2x + 3, which results in a straight diagonal line. A straight diagonal line gives us a constant rate of change (in this case an increase of 2 in the value of the function for every change of 1 in x), so the derivative of this function with respect to x is just a constant. This is represented by the horizontal dashed line.",
            "zh": "首先看图C.2（a）[767]，这里的函数非常简单，f（x） = 2x + 3，结果是一条直对角线。一条直对角线为我们提供了一个恒定的变化率（在这种情况下，x 中每变化 1，函数值就会增加 2），因此该函数相对于 x 的导数只是一个常数。这由水平虚线表示。"
        }
    },
    {
        "translation": {
            "en": "Machine learning, however, is made difficult because there is usually more than one model that is consistent with the training dataset—because of this, machine learning is often described as an ill-posed problem.",
            "zh": "然而，机器学习变得困难，因为通常有多个模型与训练数据集一致，因此，机器学习通常被描述为一个病态的问题。"
        }
    },
    {
        "translation": {
            "en": "where ||w|| is known as the Euclidean norm of w and is calculated",
            "zh": "其中 ||W||被称为 w 的欧几里得范数，经过计算"
        }
    },
    {
        "translation": {
            "en": "Images (b) and (c) show the car in other positions where other cars and barriers are sensed by the car, but other cars and barriers are out of range of the sensors.",
            "zh": "图像 （b） 和 （c） 显示汽车处于其他位置，汽车可以感应到其他汽车和障碍物，但其他汽车和障碍物超出了传感器的范围。"
        }
    },
    {
        "translation": {
            "en": "So, we must use the backpropagation algorithm to calculate the δ terms, and once this is done we can calculate the error gradients for each weight.",
            "zh": "因此，我们必须使用反向传播算法来计算δ项，一旦完成，我们就可以计算每个权重的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "HEALTHTYPE: The type of the health insurance policy (PlanA, PlanB, or PlanC)",
            "zh": "HEALTHTYPE：健康保险单的类型（PlanA、PlanB 或 PlanC）"
        }
    },
    {
        "translation": {
            "en": "4.5   Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset 𝒟7 in Figure 4.8[138].",
            "zh": "4.5 图4.8[138]中数据集D7的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "The target feature values for the instances in the mini-batch are generated as described in Algorithm 15[671].",
            "zh": "按照算法 15[671] 中的描述生成小批量中实例的目标特征值。"
        }
    },
    {
        "translation": {
            "en": "Note that we are assuming the neurons in the hidden layers are ReLUs and that the final layer is a softmax layer.",
            "zh": "请注意，我们假设隐藏层中的神经元是 ReLU，最后一层是 softmax 层。"
        }
    },
    {
        "translation": {
            "en": "This network is also a fully connected network because each of the neurons in the network is connected in such a way that it receives inputs from all the neurons in the preceding layer and passes its output activation to all the neurons in the next layer.",
            "zh": "这个网络也是一个完全连接的网络，因为网络中的每个神经元都以这样的方式连接，即它接收来自前一层所有神经元的输入，并将其输出激活传递给下一层的所有神经元。"
        }
    },
    {
        "translation": {
            "en": "4.2.2 Shannon’s Entropy Model",
            "zh": "4.2.2 香农熵模型"
        }
    },
    {
        "translation": {
            "en": "Using local receptive fields, neurons can learn to extract low-level features in the input (such as a segment or an oriented edge in an image), and these features can be passed on to neurons in later layers that combine these low-level features into more complex features.",
            "zh": "使用局部感受野，神经元可以学习提取输入中的低级特征（例如图像中的线段或定向边缘），并且这些特征可以传递给后面层的神经元，这些神经元将这些低级特征组合成更复杂的特征。"
        }
    },
    {
        "translation": {
            "en": "Dealing with an action-value table of this scale is computationally troublesome, but more important, such a large state space would most likely mean that any training process would inevitably leave much of the action-value table unexplored.",
            "zh": "处理这种规模的动作-价值表在计算上是很麻烦的，但更重要的是，如此大的状态空间很可能意味着任何训练过程都不可避免地会留下大部分动作-价值表的未被探索。"
        }
    },
    {
        "translation": {
            "en": "The inverse covariance matrix is the matrix such that when the covariance matrix is multiplied by its inverse, the result is the identity matrix: ∑ × ∑−1 = .",
            "zh": "逆协方差矩阵是这样的矩阵，当协方差矩阵乘以其逆矩阵时，结果是单位矩阵：∑ × ∑−1 = 。"
        }
    },
    {
        "translation": {
            "en": "For example, a simple modification to the ε-greedy policy is to reduce ε over time so that the amount of exploration that the agent performs reduces over time.",
            "zh": "例如，对贪婪ε策略的简单修改是随着时间的推移减少ε，以便代理执行的探索量随时间推移而减少。"
        }
    },
    {
        "translation": {
            "en": "To use supervised learning for these types of tasks would require an expert controler to operate the system in order to generate a dataset containing examples of correct behavior.",
            "zh": "要将监督学习用于这些类型的任务，需要专家控制者来操作系统，以便生成包含正确行为示例的数据集。"
        }
    },
    {
        "translation": {
            "en": "14.3 Beyond Prediction",
            "zh": "14.3 超越预测"
        }
    },
    {
        "translation": {
            "en": "14.4 Your Next Steps",
            "zh": "14.4 您的下一步"
        }
    },
    {
        "translation": {
            "en": "Often, in a collaboration between analytics experts and domain experts, we develop a hierarchy of domain concepts that starts from the analytics solution, proceeds through a small number of levels of abstraction to result in concrete descriptive features.",
            "zh": "通常，在分析专家和领域专家之间的合作中，我们开发了一个领域概念的层次结构，该层次结构从分析解决方案开始，通过少量的抽象级别进行，以产生具体的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "The identity matrix is a square matrix in which all the elements of the main diagonal are 1, and all other elements are 0.",
            "zh": "单位矩阵是一个正方形矩阵，其中主对角线的所有元素均为 1，所有其他元素均为 0。"
        }
    },
    {
        "translation": {
            "en": "14. Recall that sparse data, discussed in Section 5.4.5[211], refers to datasets where the majority of descriptive features have a value of zero.",
            "zh": "14. 回想一下，第 5.4.5 节[211] 中讨论的稀疏数据是指大多数描述性特征值为零的数据集。"
        }
    },
    {
        "translation": {
            "en": "Bar plots of these three sets of prediction frequencies are shown in the following images.",
            "zh": "这三组预测频率的条形图如下图所示。"
        }
    },
    {
        "translation": {
            "en": "normalization, 87, 181, 206, 231, 329, 332, 346, 421",
            "zh": "归一化， 87， 181， 206， 231， 329， 332， 346， 421"
        }
    },
    {
        "translation": {
            "en": "Figure 8.40[509] illustrates the internal structure of an LSTM unit.",
            "zh": "图 8.40[509] 说明了 LSTM 单元的内部结构。"
        }
    },
    {
        "translation": {
            "en": "2. For each descriptive feature, create the sets that result by partitioning the instances in the dataset using their feature values, and then sum the entropy scores of each of these sets. This gives a measure of the information that remains required to organize the instances into pure sets after we have split them using the descriptive feature.",
            "zh": "2. 对于每个描述性特征，通过使用数据集中的实例的特征值对实例进行分区来创建结果集，然后将每个集合的熵分数相加。这给出了在使用描述性特征将实例拆分为纯集后，将实例组织成纯集所需的信息的度量。"
        }
    },
    {
        "translation": {
            "en": "The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each possible target level.",
            "zh": "朴素贝叶斯预测模型需要表 6.3[264] 中的相关概率，以便对 CH = 付费、GC = 担保人、ACC = 免费的查询进行预测，并计算每个可能的目标水平的分数。"
        }
    },
    {
        "translation": {
            "en": "As a result, this sampling strategy is guaranteed to maintain the relative frequencies of the different levels of the stratification feature.",
            "zh": "因此，这种采样策略可以保证保持不同层次的分层特征的相对频率。"
        }
    },
    {
        "translation": {
            "en": "The previous process is then repeated, and the distances of each instance in to these updated cluster centroids are given in Table 10.1[604] in the columns labeled Cluster Distances Iter.",
            "zh": "然后重复上述过程，每个实例到这些更新的聚类质心的距离在表 10.1[604] 中标有 Cluster Distance Iter 的列中给出。"
        }
    },
    {
        "translation": {
            "en": "Next, it removes the feature d[best] from the set of features considered for testing later on this path in the tree; this enforces the constraint that a feature can be tested only once on any particular path in the tree (Line 11).",
            "zh": "接下来，它将特征 d[best] 从考虑稍后在树中的此路径上测试的特征集中删除;这强制执行了在树中的任何特定路径上只能测试一次特征的约束（第 11 行）。"
        }
    },
    {
        "translation": {
            "en": "In the case of bias terms, this second index is always equal to zero.",
            "zh": "在偏差项的情况下，第二个索引始终等于零。"
        }
    },
    {
        "translation": {
            "en": "This is a subtle difference but can lead to a change in the ordering of models compared to other performance measures.",
            "zh": "这是一个微妙的差异，但与其他性能度量相比，可能会导致模型顺序发生变化。"
        }
    },
    {
        "translation": {
            "en": "Both Edwin and Ted were surprised to see missing values in the data, as it was produced through a fully automated process.",
            "zh": "Edwin 和 Ted 都惊讶地发现数据中缺少值，因为它是通过完全自动化的过程生成的。"
        }
    },
    {
        "translation": {
            "en": "CMODELFLUXIVAR_U/G/R/I/Z",
            "zh": "CMODELFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 10.13",
            "zh": "图 10.13"
        }
    },
    {
        "translation": {
            "en": "3.2.1 The Normal Distribution",
            "zh": "3.2.1 正态分布"
        }
    },
    {
        "translation": {
            "en": "There are a number of factors to consider in the choice of the batch size, including16 (1) larger batches provide a more accurate estimate of the true gradient for the entire dataset, but (2) hardware constraints may necessitate the use of smaller batches; for example, if all the examples in a mini-batch are to be processed in parallel, then the larger the batch size, the larger is the memory requirement.",
            "zh": "在选择批量大小时需要考虑许多因素，包括 16 （1） 较大的批量可以更准确地估计整个数据集的真实梯度，但 （2） 硬件限制可能需要使用较小的批量;例如，如果要并行处理小批量中的所有示例，则批大小越大，内存要求就越大。"
        }
    },
    {
        "translation": {
            "en": "What is the business problem?",
            "zh": "业务问题是什么？"
        }
    },
    {
        "translation": {
            "en": "8.8   The logical AND and OR functions are linearly separable, but the XOR is not.",
            "zh": "8.8 逻辑 AND 和 OR 函数是线性可分离的，但 XOR 不是。"
        }
    },
    {
        "translation": {
            "en": "The cosine similarity between instances will be in the range [0,1], where 1 indicates maximum similarity and 0 indicates maximum dissimilarity.20 We can calculate the cosine similarity between d1 and d2 from Figure 5.14(a)[218] as",
            "zh": "实例之间的余弦相似度将在 [0,1] 范围内，其中 1 表示最大相似度，0 表示最大不相似度.20 我们可以从图 5.14（a）[218] 中计算出 d1 和 d2 之间的余弦相似度，如下所示"
        }
    },
    {
        "translation": {
            "en": "The standard approach to implementing a similarity-based prediction model is the nearest neighbor algorithm.",
            "zh": "实现基于相似性的预测模型的标准方法是最近邻算法。"
        }
    },
    {
        "translation": {
            "en": "These weights are necessary because the information read from the memory buffer is processed by the hidden neurons in the same way that each of the inputs is.",
            "zh": "这些权重是必要的，因为从内存缓冲区读取的信息由隐藏的神经元以与每个输入相同的方式进行处理。"
        }
    },
    {
        "translation": {
            "en": "These 0 and 1 values tell us which equation to use in order to calculate the corresponding δ (below) based on the corresponding softmax activation (above).",
            "zh": "这些 0 和 1 值告诉我们使用哪个方程来计算相应的 δ（下图），基于相应的 softmax 激活（上图）。"
        }
    },
    {
        "translation": {
            "en": "Although neither Edwin nor Ted could understand exactly how this had happened, they agreed that something had obviously gone wrong in the processing pipeline in those cases and that the − 9,999 values must refer to missing values.11 Complete case analysis was used to entirely remove any rows containing two or more − 9,999, or missing, values.",
            "zh": "尽管 Edwin 和 Ted 都无法确切地理解这是如何发生的，但他们一致认为，在这些情况下，处理管道中显然出现了一些问题，并且 − 9,999 值必须引用缺失值。11 完整的案例分析用于完全删除任何包含两个或更多行 − 9,999 或缺失的行。 值。"
        }
    },
    {
        "translation": {
            "en": "By analyzing the data quality report, we are able to understand the characteristics of the data in the ABT. We will return to the features that seemed to have slightly peculiar distributions.",
            "zh": "通过分析数据质量报告，我们能够了解 ABT 中数据的特征。我们将回到似乎具有略微特殊分布的特征。"
        }
    },
    {
        "translation": {
            "en": "Anyone who has learned a new sport will have had the sometimes painful experience of taking an error-based approach to learning.",
            "zh": "任何学习过一项新运动的人都会有一段痛苦的经历，即采用基于错误的学习方法。"
        }
    },
    {
        "translation": {
            "en": "Examples of the samples generated using Gibbs sampling.",
            "zh": "使用 Gibbs 采样生成的样本示例。"
        }
    },
    {
        "translation": {
            "en": "How will we continue to evaluate the model after deployment? How will the model be integrated into the organization?",
            "zh": "部署后，我们将如何继续评估模型？该模型将如何集成到组织中？"
        }
    },
    {
        "translation": {
            "en": "As the learning rate decays, however, the direction of the journey across the error surface moves back downward, and eventually the global minimum is reached.",
            "zh": "然而，随着学习率的衰减，穿越误差表面的行程方向会向下移动，最终达到全局最小值。"
        }
    },
    {
        "translation": {
            "en": "The central tendency of a sample refers to the value that is typical of the sample and therefore can be used to summarize it. Measures of central tendency are an approximation of this notional value. The arithmetic mean (or sample mean or just mean) is the best-known measure of central tendency. The arithmetic mean of a set of n values for a feature a is denoted by the symbol ā and is calculated as",
            "zh": "样本的中心趋势是指样本的典型值，因此可用于总结它。集中趋势的度量是该名义值的近似值。算术平均值（或样本平均值或只是平均值）是集中趋势的最著名的度量。要素 a 的一组 n 个值的算术平均值用符号 ā 表示，计算公式为"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.2(a)[119] we next ask, Is it a man?",
            "zh": "在图4.2（a）[119]中，我们接下来问，是男人吗？"
        }
    },
    {
        "translation": {
            "en": "Figure 12.3",
            "zh": "图 12.3"
        }
    },
    {
        "translation": {
            "en": "For example, Figure 5.19[228] illustrates a feature subset space for a dataset with three descriptive features: X, Y, and Z.",
            "zh": "例如，图 5.19[228] 说明了具有三个描述性特征的数据集的特征子集空间：X、Y 和 Z。"
        }
    },
    {
        "translation": {
            "en": "14.3   Beyond Prediction",
            "zh": "14.3 超越预测"
        }
    },
    {
        "translation": {
            "en": "When a company is formed, it registers with the company registrations office.",
            "zh": "公司成立后，在公司注册处注册。"
        }
    },
    {
        "translation": {
            "en": "Although the algorithm can still converge toward an area of the error surface close to the global minimum, there is a strong chance that the global minimum itself will be missed, and the algorithm will simply jump back and forth across it.",
            "zh": "尽管算法仍然可以收敛到接近全局最小值的误差面区域，但很有可能会错过全局最小值本身，并且算法只会在其上来回跳转。"
        }
    },
    {
        "translation": {
            "en": "9.15   The (a) gain and (b) cumulative gain at each decile for the email predictions given in Table 9.11[557].",
            "zh": "9.15 表9.11[557]中给出的电子邮件预测在每个十分位数的（a）增益和（b）累积增益。"
        }
    },
    {
        "translation": {
            "en": "Apart from making a model more compact, conditional independence and factorization also increase the coverage of a probability-based prediction model by allowing the model to calculate reasonable probabilities for queries with combinations of evidence that do not occur in the training dataset.",
            "zh": "除了使模型更紧凑之外，条件独立性和因式分解还允许模型计算具有训练数据集中未出现的证据组合的查询的合理概率，从而增加了基于概率的预测模型的覆盖范围。"
        }
    },
    {
        "translation": {
            "en": "In Section A.1[745] we talk about how measures of central tendency attempt to capture the average value of a list of numbers.",
            "zh": "在A.1[745]节中，我们讨论了集中趋势的度量如何试图捕获数字列表的平均值。"
        }
    },
    {
        "translation": {
            "en": "Implicitly, however, the algorithm is also creating a global prediction model based on the full dataset.",
            "zh": "然而，隐含地，该算法也在创建一个基于完整数据集的全局预测模型。"
        }
    },
    {
        "translation": {
            "en": "To my wife and family,",
            "zh": "致我的妻子和家人，"
        }
    },
    {
        "translation": {
            "en": "In this calculation Shannon’s model multiples the large probability of selecting a specific suit, P(suit = l), by a small negative number, log2(P(suit = l)), to return a relatively small negative number. The relatively small negative numbers associated with each suit are summed to result in a small negative number overall. Again, the sign of this number is inverted to result in a small positive value for the entropy of this much purer set.",
            "zh": "在此计算中，Shannon 的模型将选择特定花色的大概率 P（suit = l） 乘以一个小的负数 log2（P（suit = l）），以返回一个相对较小的负数。与每种花色相关的相对较小的负数相加，得出一个较小的负数。同样，这个数字的符号被颠倒，为这个更纯的集合的熵产生一个小的正值。"
        }
    },
    {
        "translation": {
            "en": "Markov blanket, 288",
            "zh": "马尔可夫毯子，288"
        }
    },
    {
        "translation": {
            "en": "52,000",
            "zh": "52,000"
        }
    },
    {
        "translation": {
            "en": "This figure is based on Figure 1.27 from Bishop (2006).",
            "zh": "这个数字是基于Bishop（2006）的图1.27。"
        }
    },
    {
        "translation": {
            "en": "These examples show two things.",
            "zh": "这些例子说明了两件事。"
        }
    },
    {
        "translation": {
            "en": "variational RNN, 507",
            "zh": "变分RNN，507"
        }
    },
    {
        "translation": {
            "en": "Recall that when we did an exact calculation for this query the probability of CPI = high was 0.2.",
            "zh": "回想一下，当我们对此查询进行精确计算时，CPI = 高的概率为 0.2。"
        }
    },
    {
        "translation": {
            "en": "Using a validation set to avoid overfitting in iterative machine learning algorithms.",
            "zh": "使用验证集来避免迭代机器学习算法中的过度拟合。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.11",
            "zh": "图 9.11"
        }
    },
    {
        "translation": {
            "en": "In this use case, unsupervised machine learning is used as one part of a larger machine learning pipeline.",
            "zh": "在此用例中，无监督机器学习被用作更大的机器学习管道的一部分。"
        }
    },
    {
        "translation": {
            "en": "The number of customer care calls made by the customer last month",
            "zh": "客户上个月拨打的客户服务电话数量"
        }
    },
    {
        "translation": {
            "en": "Learning both the topology of a Bayesian network and the parameters in the CPTs in the network is a difficult computational task.",
            "zh": "学习贝叶斯网络的拓扑结构和网络中 CPT 中的参数是一项艰巨的计算任务。"
        }
    },
    {
        "translation": {
            "en": "In other words, we choose the set of conditional probabilities that maximize the likelihood of the training data.",
            "zh": "换句话说，我们选择使训练数据的可能性最大化的条件概率集。"
        }
    },
    {
        "translation": {
            "en": "The mode is simply the most commonly occurring value in a sample (determined by counting the frequency with which each value occurs in the sample).",
            "zh": "该模式只是样本中最常出现的值（通过计算样本中每个值出现的频率来确定）。"
        }
    },
    {
        "translation": {
            "en": "We can apply almost the same approach that we used in the Guess Who game to make this decision.",
            "zh": "我们可以应用与猜猜谁游戏中几乎相同的方法来做出这个决定。"
        }
    },
    {
        "translation": {
            "en": "0.58",
            "zh": "0.58"
        }
    },
    {
        "translation": {
            "en": "When there are many continuous features, probability-based and information-based models can become complicated, but if all the features in a dataset are categorical, then information-based and probability-based models are appropriate.",
            "zh": "当存在许多连续特征时，基于概率和基于信息的模型可能会变得复杂，但如果数据集中的所有特征都是分类的，则基于信息和基于概率的模型是合适的。"
        }
    },
    {
        "translation": {
            "en": "This model is said to overfit the training data.",
            "zh": "据说该模型对训练数据进行了过度拟合。"
        }
    },
    {
        "translation": {
            "en": "In the credit scoring dataset given in Table 1.2[8], for example, a conservative estimate of the number of possible combinations of descriptive features is over 3.6 billion!",
            "zh": "例如，在表 1.2[8] 中给出的信用评分数据集中，对描述性特征的可能组合数量的保守估计超过 36 亿！"
        }
    },
    {
        "translation": {
            "en": "8.6   Further Reading",
            "zh": "8.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "This means that the training process is using its experience of the environment much more efficiently because each step is used in network training multiple times.",
            "zh": "这意味着训练过程可以更有效地利用其环境经验，因为每个步骤都在网络训练中多次使用。"
        }
    },
    {
        "translation": {
            "en": "Smoothing should be used in conjunction with binning to help with these extreme probabilities.",
            "zh": "平滑应与像素合并结合使用，以帮助处理这些极端概率。"
        }
    },
    {
        "translation": {
            "en": "The model, however, will actually return a prediction of yes, indicating that the customer should be contacted.",
            "zh": "但是，该模型实际上将返回“是”的预测，表示应联系客户。"
        }
    },
    {
        "translation": {
            "en": "Assuming that the set of training instances reaching a leaf node are indicative of the queries that will be labeled by the node, it makes sense to construct regression trees in a manner that reduces the variance in the target feature values of the set of training instances at each leaf node in the tree.",
            "zh": "假设到达叶节点的训练实例集指示该节点将标记的查询，则以减少树中每个叶节点上训练实例集的目标特征值方差的方式构造回归树是有意义的。"
        }
    },
    {
        "translation": {
            "en": "During the forward pass of an LSTM unit, there are three operations on activation vectors that are novel with respect to the other network architectures we have examined: forks in computational flow, elementwise products of vectors, and elementwise addition of vectors. To be able to backpropagate error gradients through an LSTM, we need to understand how the novel operations in the forward pass are handled in the backward pass.",
            "zh": "在 LSTM 单元的前向传递过程中，激活向量有三种操作，这些操作相对于我们研究过的其他网络架构来说是新颖的：计算流中的分叉、向量的逐元乘积和向量的逐元加法。为了能够通过 LSTM 反向传播误差梯度，我们需要了解如何在后向传递中处理前向传递中的新操作。"
        }
    },
    {
        "translation": {
            "en": "In many cases datasets will contain both categorical and continuous descriptive features.",
            "zh": "在许多情况下，数据集将同时包含分类和连续描述性特征。"
        }
    },
    {
        "translation": {
            "en": "Note that in Figure 2.6(b)[39] the month names have been abstracted and are now defined relative to the transition between the observation and outcome periods.",
            "zh": "请注意，在图2.6（b）[39]中，月份名称已被抽象化，现在相对于观察期和结果期之间的过渡进行了定义。"
        }
    },
    {
        "translation": {
            "en": "An image of the digit 2 and reconstructions of this image by the auto-encoder after various amounts of network training. The pixel values of the reconstructed images are shown alongside the images, as is the reconstruction error calculated by comparing these to the pixel values of the original image.",
            "zh": "数字 2 的图像以及自动编码器在经过不同数量的网络训练后对该图像的重建。重建图像的像素值与图像一起显示，通过将这些像素值与原始图像的像素值进行比较计算的重建误差也是如此。"
        }
    },
    {
        "translation": {
            "en": "Binary: A set of just two values (e.g., gender)",
            "zh": "二进制：仅包含两个值（例如性别）的集合"
        }
    },
    {
        "translation": {
            "en": "The CPT entries are essentially parameters on the network, and the more parameters a network has, the greater its ability to fit (or overfit) the data.",
            "zh": "CPT 条目本质上是网络上的参数，网络拥有的参数越多，其拟合（或过拟合）数据的能力就越强。"
        }
    },
    {
        "translation": {
            "en": "In a regression problem, in which the target is continuous, normalization is often applied to both the descriptive features and the target feature.",
            "zh": "在回归问题中，目标为连续的，规范化通常同时应用于描述性特征和目标特征。"
        }
    },
    {
        "translation": {
            "en": "This analysis also explains the exploding z values plotted in Figure 8.24[454].",
            "zh": "该分析还解释了图8.24[454]中绘制的爆炸z值。"
        }
    },
    {
        "translation": {
            "en": "Sarah is a young venture scout in training for her pioneering badge.",
            "zh": "莎拉是一名年轻的冒险球探，正在为她的开拓者徽章进行培训。"
        }
    },
    {
        "translation": {
            "en": "The table in the data quality report that describes categorical features should include a row for each feature in the ABT that contains the two most frequent levels for the feature (the mode and 2nd mode) and the frequency with which these appear (both as raw frequencies and as a proportion of the total number of instances in the dataset).",
            "zh": "数据质量报告中描述分类特征的表应包括 ABT 中每个特征的一行，其中包含特征的两个最常见级别（模式和第二模式）以及这些级别出现的频率（原始频率和数据集中实例总数的比例）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.17[434] illustrates how the sum of squared errors of the network changes during the training.",
            "zh": "图 8.17[434] 说明了网络误差的平方和在训练过程中是如何变化的。"
        }
    },
    {
        "translation": {
            "en": "Naive Bayes",
            "zh": "朴素贝叶斯"
        }
    },
    {
        "translation": {
            "en": "The magnitude of the maximum values for the FIBER2FLUXIVAR_U feature in comparison to the median and 3rd quartile value was unusual and suggested the presence of outliers.",
            "zh": "与中位数和第 3 个四分位数相比，FIBER2FLUXIVAR_U特征的最大值的大小是不寻常的，表明存在异常值。"
        }
    },
    {
        "translation": {
            "en": "1. learning the class conditional densities (i.e., the distribution of the data for each target level) P(d|tl) and the class priors P(tl);",
            "zh": "1. 学习类条件密度（即每个目标水平的数据分布）P（d|tl）和类先验P（tl）;"
        }
    },
    {
        "translation": {
            "en": "The variant of backpropagation used to train a recurrent neural network is called backpropagation through time.",
            "zh": "用于训练递归神经网络的反向传播变体称为随时间反向传播。"
        }
    },
    {
        "translation": {
            "en": "For those struggling to choose an appropriate performance measure, in the absence of other information, we recommend:",
            "zh": "对于那些在没有其他信息的情况下难以选择适当的绩效衡量标准的人，我们建议："
        }
    },
    {
        "translation": {
            "en": "Features from the ABT for the SDSS galaxy classification problem.",
            "zh": "来自 ABT 的 SDSS 星系分类问题的特征。"
        }
    },
    {
        "translation": {
            "en": "To test the two-stage classifier, Jocelyn extracted a small ABT containing only spiral galaxies from the original ABT.",
            "zh": "为了测试两级分类器，Jocelyn 从原始 ABT 中提取了一个仅包含螺旋星系的小型 ABT。"
        }
    },
    {
        "translation": {
            "en": "Given the complexity of exact probabilistic inference for Bayesian networks, a popular alternative is to approximate the probability distribution required for a prediction using Monte Carlo methods.29 Monte Carlo methods generate a large number of sample events and then use the relative frequency of an event in the set of generated samples as the approximation for the probability of that event in the real distribution.",
            "zh": "鉴于贝叶斯网络精确概率推理的复杂性，一种流行的替代方法是使用蒙特卡洛方法近似预测所需的概率分布.29 蒙特卡洛方法生成大量样本事件，然后使用生成的样本集中事件的相对频率作为该事件在实际分布中的概率的近似值。"
        }
    },
    {
        "translation": {
            "en": "(b) What prediction will the naive Bayes model return for the following query?",
            "zh": "（b） 朴素贝叶斯模型对以下查询将返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "Using normalization (see Section 3.6.1[87]) on the features can help avoid these large squared errors, and we do this in most examples from now on.",
            "zh": "对特征使用归一化（参见第 3.6.1 节 [87]）可以帮助避免这些大的平方误差，从现在开始，我们在大多数示例中都会这样做。"
        }
    },
    {
        "translation": {
            "en": "Using this data, perform the following tasks on the SCORE feature:",
            "zh": "使用此数据，对 SCORE 功能执行以下任务："
        }
    },
    {
        "translation": {
            "en": "rate parameter, 274",
            "zh": "rate 参数，274"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the bike rental dataset from Table 4.15[166].",
            "zh": "（a） 表4.15[166]中的自行车租赁数据集图。"
        }
    },
    {
        "translation": {
            "en": "A subset of a dataset is denoted by 𝒟 with a subscript to indicate the definition of the subset. For example, 𝒟f=l represents the subset of instances from the dataset 𝒟 where the feature f has the value l.",
            "zh": "数据集的子集用 D 表示，下标表示子集的定义。例如，Df=l 表示数据集 D 中实例的子集，其中特征 f 的值为 l。"
        }
    },
    {
        "translation": {
            "en": "The reason that we sample with replacement is that this will result in duplicates within each of the bootstrap samples, and consequently every bootstrap sample will be missing some of the instances from the dataset.",
            "zh": "我们使用替换进行采样的原因是，这将导致每个引导样本中出现重复，因此每个引导样本都将缺少数据集中的一些实例。"
        }
    },
    {
        "translation": {
            "en": "In Figures 3.10(a)[80] and 3.10(b)[80] we illustrate the multiple box plot approach using the AGE and POSITION features from the dataset in Table 3.7[73].",
            "zh": "在图3.10（a）[80]和图3.10（b）[80]中，我们使用表3.7[73]中数据集中的AGE和POSITION特征说明了多箱图方法。"
        }
    },
    {
        "translation": {
            "en": "These arise when there are no instances in the training data that match a specific combination of target feature and descriptive feature levels.",
            "zh": "当训练数据中没有与目标特征和描述性特征级别的特定组合匹配的实例时，就会出现这种情况。"
        }
    },
    {
        "translation": {
            "en": "Consequently, neurons using this set of weights can be thought of as rudimentary detectors for horizontal edges because they will have maximum activation if there is a horizontal line across the middle row of their inputs.",
            "zh": "因此，使用这组权重的神经元可以被认为是水平边缘的基本检测器，因为如果它们的输入中间有一行水平线，它们将具有最大的激活。"
        }
    },
    {
        "translation": {
            "en": "Organizations exist to do things like make more money, gain new customers, sell more products, or reduce losses from fraud.",
            "zh": "组织的存在是为了做一些事情，比如赚更多的钱、获得新客户、销售更多的产品或减少欺诈造成的损失。"
        }
    },
    {
        "translation": {
            "en": "profit matrix, 553, 592",
            "zh": "利润矩阵，553,592"
        }
    },
    {
        "translation": {
            "en": "4.21   (a) A plot of the bike rental dataset from Table 4.14[162]. (b) An illustration of the final ensemble model trained using the boosting algorithm. (c)–(e) A representation of the changing weights used to generate sample datasets for the first iterations of the boosting process.",
            "zh": "4.21 （a） 表4.14[162]中的自行车租赁数据集图。（b） 使用提升算法训练的最终集成模型的图示。（c）–（e） 用于为提升过程的第一次迭代生成样本数据集的变化权重的表示。"
        }
    },
    {
        "translation": {
            "en": "Once the analytics solution had been defined, the next step was to agree on the expected performance of the new analytics model.",
            "zh": "定义分析解决方案后，下一步就是就新分析模型的预期性能达成一致。"
        }
    },
    {
        "translation": {
            "en": "Consequently, in backpropagating through a max function, the entire error gradient is backpropagated to the neuron that propagated forward the max value, and the other neurons receive an error gradient of zero.",
            "zh": "因此，在通过最大函数反向传播时，整个误差梯度被反向传播到向前传播最大值的神经元，而其他神经元的误差梯度为零。"
        }
    },
    {
        "translation": {
            "en": "Markov chain, 298",
            "zh": "马尔可夫链，298"
        }
    },
    {
        "translation": {
            "en": "20.64",
            "zh": "20.64"
        }
    },
    {
        "translation": {
            "en": "The average number of call minutes used by the customer each month",
            "zh": "客户每月使用的平均通话分钟数"
        }
    },
    {
        "translation": {
            "en": "This section has provided an overview of the aspects of probability that readers need to understand in order to follow the other sections in this book.",
            "zh": "本节概述了读者需要了解的概率方面，以便了解本书的其他部分。"
        }
    },
    {
        "translation": {
            "en": "For example, it is not uncommon to see sizes of 128, 256, 512, and 1,024.",
            "zh": "例如，128、256、512 和 1,024 的大小并不少见。"
        }
    },
    {
        "translation": {
            "en": "The height of this rectangle, then, also shows the inter-quartile range.",
            "zh": "然后，这个矩形的高度也显示了四分位数间的范围。"
        }
    },
    {
        "translation": {
            "en": "C.2 The Chain Rule",
            "zh": "C.2 连锁法则"
        }
    },
    {
        "translation": {
            "en": "Table 6.7",
            "zh": "表 6.7"
        }
    },
    {
        "translation": {
            "en": "There are, in fact, multiple ways of mathematically defining a weighted sum calculation: we can use the ∑ symbol to reduce the length of the equation, or we can represent it as a dot product or as a matrix product",
            "zh": "事实上，有多种方法可以在数学上定义加权和计算：我们可以使用∑符号来缩短方程的长度，或者我们可以将其表示为点积或矩阵积"
        }
    },
    {
        "translation": {
            "en": "negative level, 537",
            "zh": "负水平，537"
        }
    },
    {
        "translation": {
            "en": "17. These are covered in Section 9.4.1[540].",
            "zh": "17. 这些内容详见第9.4.1节[540]。"
        }
    },
    {
        "translation": {
            "en": "For example, Table A.1[750] lists the position that each player on a school basketball team plays at, and the average training expenses accrued each month by each player on the team. Table A.2[750] shows the frequencies and proportions of the positions that players in the team play at, based on counts of the occurrences of the different levels of the POSITION feature in Table A.1[750]. We can see from this example that the guard level is the most frequent, followed by forward and center.",
            "zh": "例如，表A.1[750]列出了学校篮球队中每个球员所处的位置，以及该队中每个球员每月应计的平均训练费用。表A.2[750]根据表A.1[750]中不同级别的POSITION特征的出现次数，显示了球队中球员所处位置的频率和比例。从这个例子中我们可以看出，后卫级别是最常见的，其次是前锋和中锋。"
        }
    },
    {
        "translation": {
            "en": "Any function can be approximated by combining disconnected regions.",
            "zh": "任何函数都可以通过组合断开的区域来近似。"
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic curve, 558, 589",
            "zh": "接收机工作特性曲线，558、589"
        }
    },
    {
        "translation": {
            "en": "The derivative used to backpropagate δs through the rectifierparametric function is then defined as",
            "zh": "然后，用于通过整流器参数函数反向传播 δs 的导数定义为"
        }
    },
    {
        "translation": {
            "en": "This equation expands Equation (8.14)[408] using the difference − (t k − ak) as the value for ∂ℰ/∂ak.",
            "zh": "该方程扩展了方程（8.14）[408]，使用差值 − （t k − ak） 作为 ∂E/∂ak 的值。"
        }
    },
    {
        "translation": {
            "en": "In this case we can see that distributions of the levels of the SHOE SPONSOR feature are not the same for each position.",
            "zh": "在这种情况下，我们可以看到每个位置的 SHOE SPONSOR 功能级别的分布并不相同。"
        }
    },
    {
        "translation": {
            "en": "HANDSETPRICE",
            "zh": "手机价格"
        }
    },
    {
        "translation": {
            "en": "7.14   A scatter plot of the extended generators dataset given in Table 7.7[347], which results in instances with the different target levels overlapping each other. Instances representing good generators are shown as crosses, and those representing faulty generators as triangles.",
            "zh": "7.14 表7.7[347]中给出的扩展生成器数据集的散点图，导致不同目标水平相互重叠的实例。表示良好生成器的实例显示为十字形，表示故障生成器的实例显示为三角形。"
        }
    },
    {
        "translation": {
            "en": "If the prior and posterior probabilities are similar, then the information content in the observation was low.",
            "zh": "如果先验概率和后验概率相似，则观测中的信息含量较低。"
        }
    },
    {
        "translation": {
            "en": "This is a serious problem because the ability of a deep neural network to learn a useful representation of the inputs works by the earlier layers of the network extracting low-level features from the raw data and then the later layers learning to combine these features in useful ways (see Figure 8.10[402] for an illustration of this for a three-layer network).",
            "zh": "这是一个严重的问题，因为深度神经网络学习输入的有用表示的能力由网络的早期层工作，从原始数据中提取低级特征，然后后面的层学习以有用的方式组合这些特征（参见图 8.10[402] 了解三层网络的说明）。"
        }
    },
    {
        "translation": {
            "en": "Conversely, if we increased the dimension of our filter to a 4-by-4 filter, then we could cover the input with a 3-by-3 layer of neurons generating a 3-by-3 feature map.",
            "zh": "相反，如果我们将滤波器的维度增加到 4×4 滤波器，那么我们可以用 3×3 的神经元层覆盖输入，从而生成 3×3 的特征图。"
        }
    },
    {
        "translation": {
            "en": "The customer’s credit rating",
            "zh": "客户的信用评级"
        }
    },
    {
        "translation": {
            "en": "The profit matrix for the payday loan credit scoring problem.",
            "zh": "发薪日贷款信用评分问题的利润矩阵。"
        }
    },
    {
        "translation": {
            "en": "Generative Adversarial Networks, 523",
            "zh": "生成对抗网络，523"
        }
    },
    {
        "translation": {
            "en": "natural logarithm, 580",
            "zh": "自然对数，580"
        }
    },
    {
        "translation": {
            "en": "The change to the mechanism for selecting the best feature to split on (made on Line 1) and the introduction of an early stopping criterion (which replaces Line 1) are the only modifications we need to make to the ID3 algorithm (Algorithm 1[134]) to allow it to handle continuous target features.",
            "zh": "对选择要拆分的最佳特征的机制的更改（在第 1 行上进行）和引入提前停止标准（取代第 1 行）是我们需要对 ID3 算法（算法 1[134]）进行的唯一修改，以允许它处理连续的目标特征。"
        }
    },
    {
        "translation": {
            "en": "probability theory, 243, 757",
            "zh": "概率论， 243， 757"
        }
    },
    {
        "translation": {
            "en": "Klotz, Irving M. 1980. The n-ray affair. Scientific American 242 (5): 122–131.",
            "zh": "克洛茨，欧文 M. 1980 年。n射线事件。科学美国人242（5）：122-131。"
        }
    },
    {
        "translation": {
            "en": "Notice that ignoring the subscripts, the expression we are summing in Equation (6.4)[250] is identical to the numerator in Bayes’ Theorem. This gives us a way to calculate the posterior probability distribution over the possible assignment of values to the features in event X conditioned on the event Y, that is, P(X | Y), which avoids explicitly calculating P(Y). If we let",
            "zh": "请注意，忽略下标，我们在方程（6.4）[250]中求和的表达式与贝叶斯定理中的分子相同。这为我们提供了一种方法来计算以事件 Y 为条件的事件 X 中可能将值分配给特征的后验概率分布，即 P（X |Y），避免显式计算 P（Y）。如果我们让"
        }
    },
    {
        "translation": {
            "en": "All these chapters follow the same two-part structure:",
            "zh": "所有这些章节都遵循相同的两部分结构："
        }
    },
    {
        "translation": {
            "en": "calculate these missing distances in the preceding distance matrix (note that because this is a distance (or dissimilarity) matrix rather than a similarity matrix, the values shown are 1 − simJ(q,d)).",
            "zh": "在前面的距离矩阵中计算这些缺失的距离（请注意，由于这是距离（或不同度）矩阵而不是相似性矩阵，因此显示的值为 1 − simJ（q，d））。"
        }
    },
    {
        "translation": {
            "en": "8. Note that in this example, we have normalized the RENTAL PRICE and SIZE features to the range [−1, 1], so the error surfaces shown look slightly different from those shown in Figure 7.3[318] and Figure 7.5[329].",
            "zh": "8. 请注意，在本例中，我们已将 RENTAL PRICE 和 SIZE 特征归一化为 [−1， 1] 范围，因此显示的误差曲面看起来与图 7.3[318] 和图 7.5[329] 中显示的误差曲面略有不同。"
        }
    },
    {
        "translation": {
            "en": "As approaches 1, then the negative log of this probability approaches 0.",
            "zh": "当接近 1 时，则该概率的负对数接近 0。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the ROC index for this model using the trapezoidal method and the following set of thresholds: 1.0, 0.5, and 0.0.",
            "zh": "（a） 使用梯形方法和以下一组阈值计算该模型的 ROC 指数：1.0、0.5 和 0.0。"
        }
    },
    {
        "translation": {
            "en": "In early convolution networks, the activation of sub-sampling neurons was often the average of the values in the feature map covered by the local receptive field of the neuron.",
            "zh": "在早期的卷积网络中，子采样神经元的激活通常是神经元局部感受野所覆盖的特征图中值的平均值。"
        }
    },
    {
        "translation": {
            "en": "In this context, the neuron will apply a different 2-by-2 filter to each color channel: one 2-by-2 filter is applied to the red values of the pixels in the receptive field; another 2-by-2 filter is applied to the green values of the pixels in the receptive field; and the third 2-by-2 filter is applied to the blue values of the pixels in the receptive field.",
            "zh": "在这种情况下，神经元将对每个颜色通道应用不同的 2×2 滤光片：一个 2×2 滤光片应用于感受野中像素的红色值;另一个 2×2 滤光片应用于感受野中像素的绿色值;第三个 2×2 滤波器应用于感受野中像素的蓝色值。"
        }
    },
    {
        "translation": {
            "en": "(short) (deep)” plan is also an ideal course plan for a short (one-week) professional training course.",
            "zh": "（短）（深度）“计划也是短期（一周）专业培训课程的理想课程计划。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.25",
            "zh": "图 8.25"
        }
    },
    {
        "translation": {
            "en": "Figure 2.4[35] shows examples of these different data types.",
            "zh": "图 2.4[35] 显示了这些不同数据类型的示例。"
        }
    },
    {
        "translation": {
            "en": "The stability index is calculated as",
            "zh": "稳定性指数计算公式为"
        }
    },
    {
        "translation": {
            "en": "The columns in the table are labeled Prediction-positive and Prediction-negative and represent the predictions generated by a model, which is either positive or negative.",
            "zh": "表中的列标记为“预测正”和“预测负”，表示模型生成的预测，该预测为正或负。"
        }
    },
    {
        "translation": {
            "en": "3. The p-value is compared to a predefined significance threshold, and if the p-value is less than or equal to the threshold (i.e., the p-value is small), the null hypothesis is rejected. These thresholds are typically the standard statistical thresholds of 5% or 1%.",
            "zh": "3. 将 p 值与预定义的显著性阈值进行比较，如果 p 值小于或等于阈值（即 p 值较小），则拒绝原假设。这些阈值通常是 5% 或 1% 的标准统计阈值。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.27",
            "zh": "图 8.27"
        }
    },
    {
        "translation": {
            "en": "AVGDROPPEDCALLS",
            "zh": "AVGDROPPED呼叫"
        }
    },
    {
        "translation": {
            "en": "We can say that because of the purity of the splits that it makes, the SUSPICIOUS WORDS feature provides more information about the value of the target feature for an instance than the CONTAINS IMAGES feature, and so a tree that tests this descriptive feature at the root node is preferable.",
            "zh": "我们可以说，由于它所做的拆分的纯度，SUSPICIOUS WORDS 功能提供了比 CONTAINS IMAGES 功能更多关于实例的目标功能值的信息，因此在根节点测试此描述性功能的树是可取的。"
        }
    },
    {
        "translation": {
            "en": "The goal is to get across the river in the fewest steps possible without getting wet.",
            "zh": "目标是在不被淋湿的情况下以尽可能少的步骤过河。"
        }
    },
    {
        "translation": {
            "en": "Q_U/G/R/I/Z",
            "zh": "Q_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Our goal, however, is still to estimate the performance of a model after deployment.",
            "zh": "但是，我们的目标仍然是在部署后估计模型的性能。"
        }
    },
    {
        "translation": {
            "en": "The pixels from an 8-by-8 pixel image can be flattened into a single vector of 64 values to give an ABT in which each descriptive feature for an instance (an image) represents the grayscale value for a particular pixel in that image.",
            "zh": "8×8 像素图像中的像素可以展平为包含 64 个值的单个向量，以给出一个 ABT，其中实例（图像）的每个描述性特征表示该图像中特定像素的灰度值。"
        }
    },
    {
        "translation": {
            "en": "For example, for d1 the target one-hot encoding for Neuron 8 is 0, and as a result we use Equation (8.81)[469] to calculate the δ; this entails simply copying the softmax activation.",
            "zh": "例如，对于 d1，神经元 8 的目标单热编码为 0，因此我们使用方程 （8.81）[469] 来计算δ;这需要简单地复制 SoftMax 激活。"
        }
    },
    {
        "translation": {
            "en": "These contracts did not have a fixed time and were essentially renewed every month when a customer paid a fixed recurring charge for that month.",
            "zh": "这些合同没有固定的时间，基本上每个月都会续订，当客户支付当月的固定经常性费用。"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for merger category",
            "zh": "合并类别的票数分数"
        }
    },
    {
        "translation": {
            "en": "negatively covariant, 74",
            "zh": "负协变，74"
        }
    },
    {
        "translation": {
            "en": "Implementing a network as a sequence of matrix multiplications (1) speeds up the calculation of a weighted sum across each layer in the network, and (2) enables the network to parallelize the processing of examples.",
            "zh": "将网络实现为矩阵乘法序列 （1） 加快了网络中每一层加权和的计算速度，以及 （2） 使网络能够并行处理示例。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.98)[493] illustrates the structure of such a three-dimensional filter.",
            "zh": "方程（8.98）[493]说明了这种三维滤波器的结构。"
        }
    },
    {
        "translation": {
            "en": "The second important principle relates to data protection legislation, and in particular the rules surrounding the use of personal data.",
            "zh": "第二项重要原则涉及数据保护立法，特别是有关个人数据使用的规则。"
        }
    },
    {
        "translation": {
            "en": "Instead, the elliptical level was much more heavily represented than the others in both cases.",
            "zh": "相反，在这两种情况下，椭圆层的代表性都比其他水平高得多。"
        }
    },
    {
        "translation": {
            "en": "SYS. B.P.: The patient’s systolic blood pressure",
            "zh": "系统。B.P.：患者的收缩压"
        }
    },
    {
        "translation": {
            "en": "-0.3459",
            "zh": "-0.3459"
        }
    },
    {
        "translation": {
            "en": "Figure A.8(a)[756] shows the structure of a box plot.",
            "zh": "图A.8（a）[756]显示了箱形图的结构。"
        }
    },
    {
        "translation": {
            "en": "7.8   Details of the first two iterations when the gradient descent algorithm is used to train a logistic regression model for the extended generators dataset given in Table 7.7[347].",
            "zh": "7.8 使用梯度下降算法训练扩展生成器数据集的逻辑回归模型时前两次迭代的详细信息，如表 7.7[347] 所示。"
        }
    },
    {
        "translation": {
            "en": "03.21",
            "zh": "03.21"
        }
    },
    {
        "translation": {
            "en": "Boosting works by iteratively creating models and adding them to the ensemble. The iteration stops when a predefined number of models have been added. During each iteration the algorithm does the following:",
            "zh": "Boosting 的工作原理是迭代创建模型并将其添加到整体中。当添加了预定义数量的模型时，迭代将停止。在每次迭代期间，算法执行以下操作："
        }
    },
    {
        "translation": {
            "en": "For every possible value of the threshold, in the range [0,1], there are corresponding TPR and TNR values.",
            "zh": "对于阈值的每个可能值，在 [0,1] 范围内，都有相应的 TPR 和 TNR 值。"
        }
    },
    {
        "translation": {
            "en": "11.2.2   Fundamentals of Reinforcement Learning",
            "zh": "11.2.2 强化学习基础"
        }
    },
    {
        "translation": {
            "en": "-0.4768",
            "zh": "-0.4768"
        }
    },
    {
        "translation": {
            "en": "Hinton, G. E. 2005. What kind of graphical model is the brain? In Proceedings of the 19th international joint conference on artificial intelligence (IJCAI-05). IJCAI.",
            "zh": "Hinton， GE 2005 年。大脑是什么样的图形模型？第19届国际人工智能联合会议（IJCAI-05）论文集。IJCAI."
        }
    },
    {
        "translation": {
            "en": "mean imputation, 374",
            "zh": "平均插补，374"
        }
    },
    {
        "translation": {
            "en": "For similarity-based learning, the nice thing about the way feature spaces work is that if the values of the descriptive features of two or more instances in the dataset are the same, then these instances will be mapped to the same point in the feature space.",
            "zh": "对于基于相似性的学习，特征空间工作方式的好处是，如果数据集中两个或多个实例的描述性特征的值相同，则这些实例将被映射到特征空间中的同一点。"
        }
    },
    {
        "translation": {
            "en": "Sutton, Richard S., and Andrew G. Barto. 2018. Reinforcement learning: An introduction. MIT Press.",
            "zh": "萨顿、理查德 S. 和安德鲁 G. 巴托。2018. 强化学习：简介.麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "decision stumps, 165",
            "zh": "决策树桩，165"
        }
    },
    {
        "translation": {
            "en": "8.9   The per example prediction, error, and the sum of squared errors after training has converged to an SSE < 0.0001.",
            "zh": "8.9 训练后每个示例的预测、误差和误差平方和收敛到 SSE < 0.0001。"
        }
    },
    {
        "translation": {
            "en": "16. See Tijms (2012), or any good probability textbook, for an introduction to the gamma function.",
            "zh": "16. 参见 Tijms （2012） 或任何好的概率教科书，了解伽马函数的介绍。"
        }
    },
    {
        "translation": {
            "en": "Instead, feature selection algorithms often frame feature selection as a greedy local search problem, where each state in the search space specifies a subset of possible features.",
            "zh": "相反，特征选择算法通常将特征选择视为贪婪的局部搜索问题，其中搜索空间中的每个状态都指定了可能特征的子集。"
        }
    },
    {
        "translation": {
            "en": "naive Bayes model, 243, 261, 284, 308, 309, 556, 731, 732, 735, 736",
            "zh": "朴素贝叶斯模型， 243， 261， 284， 308， 309， 556， 731， 732， 735， 736"
        }
    },
    {
        "translation": {
            "en": "In many environments to which we would like to apply reinforcement learning, it becomes difficult to define a state representation that captures the nuances of the environment and does not lead to so many states as to become impossible to use with the tabular approaches described so far.",
            "zh": "在我们希望应用强化学习的许多环境中，很难定义一种状态表示，它捕获了环境的细微差别，并且不会导致如此多的状态，以至于无法与迄今为止描述的表格方法一起使用。"
        }
    },
    {
        "translation": {
            "en": "3. A credit card issuer has built two different credit scoring models that predict the propensity of customers to default on their loans. The outputs of the first model for a test dataset are shown in the table below.",
            "zh": "3. 一家信用卡发卡机构建立了两种不同的信用评分模型，用于预测客户拖欠贷款的倾向。下表显示了测试数据集的第一个模型的输出。"
        }
    },
    {
        "translation": {
            "en": "In order to build an ABT for such a problem, a historical dataset of application details and subsequent repayment behavior is required (this might stretch back over multiple years depending on the terms of the loans in question).",
            "zh": "为了针对此类问题构建 ABT，需要应用程序详细信息和后续还款行为的历史数据集（根据相关贷款的条款，这可能会追溯到多年）。"
        }
    },
    {
        "translation": {
            "en": "These outliers should be noted in the data quality plan for possible handling later in the project.",
            "zh": "这些异常值应在数据质量计划中注明，以便在项目后期进行处理。"
        }
    },
    {
        "translation": {
            "en": "The probabilities, from Table 6.13[281], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, and AB = 759.07, and the calculation of the scores for each candidate prediction.",
            "zh": "从表 6.13[281] 中可以看出，朴素贝叶斯预测模型对 CH = 付费、GC = 担保人、ACC = 免费和 AB = 759.07 的查询进行预测所需的概率，以及每个候选预测的分数计算。"
        }
    },
    {
        "translation": {
            "en": "8.4.4 Early Stopping and Dropout: Preventing Overfitting",
            "zh": "8.4.4 提前停止和退出：防止过拟合"
        }
    },
    {
        "translation": {
            "en": "This is misleading, however.",
            "zh": "然而，这是误导性的。"
        }
    },
    {
        "translation": {
            "en": "Ecological modelers can use information about the type of vegetation that grows in a region as a direct input into their animal species management and conservation programs because areas covered in different types of vegetation support different animal species.",
            "zh": "生态建模者可以使用有关某个地区生长的植被类型的信息作为其动物物种管理和保护计划的直接输入，因为不同类型的植被覆盖的区域支持不同的动物物种。"
        }
    },
    {
        "translation": {
            "en": "The dataset from the loan application fraud detection domain (from Table 6.2[263]) with two continuous descriptive features added: ACCOUNT BALANCE and LOAN AMOUNT.",
            "zh": "来自贷款申请欺诈检测域的数据集（来自表 6.2[263]），添加了两个连续的描述性特征：ACCOUNT BALANCE 和 LOAN AMOUNT。"
        }
    },
    {
        "translation": {
            "en": "Several parallels can be drawn between probability-based learning and the other approaches to machine learning that we present in this book. Intuitively, the prior probability of a nearest neighbor model predicting a particular target level is simply the relative frequency of that target level in the dataset. For this reason, in general it is wrong to artificially balance the dataset used by a nearest neighbor model,31 and doing so biases the target level priors used by the model.",
            "zh": "基于概率的学习和我们在本书中介绍的其他机器学习方法之间可以得出一些相似之处。直观地说，最近邻模型预测特定目标水平的先验概率只是该目标水平在数据集中的相对频率。出于这个原因，一般来说，人为地平衡最近邻模型使用的数据集是错误的，31 这样做会偏向模型使用的目标水平先验。"
        }
    },
    {
        "translation": {
            "en": "Table 7.6",
            "zh": "表 7.6"
        }
    },
    {
        "translation": {
            "en": "In backpropagating the error ℰt=2 we will calculate a single error gradient for each weight in Wyh and two error gradients for each weight in Whh and Whx; when we backpropagated the error for y1 we calculated one error gradient for each weight in each of the three weight matrices.",
            "zh": "在反向传播误差 Et=2 时，我们将计算 Wyh 中每个权重的单个误差梯度和 Whh 和 Whx 中每个权重的两个误差梯度;当我们反向传播 Y1 的误差时，我们计算了三个权重矩阵中每个权重的一个误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.19",
            "zh": "图 4.19"
        }
    },
    {
        "translation": {
            "en": "multi-feature, 319",
            "zh": "多功能， 319"
        }
    },
    {
        "translation": {
            "en": "Figure 5.1[184] is a scatter plot to illustrate the resulting feature space when we do this using the data in Table 5.2[183].",
            "zh": "图5.1[184]是一个散点图，用于说明当我们使用表5.2[183]中的数据时得到的特征空间。"
        }
    },
    {
        "translation": {
            "en": "In what ways could a predictive analytics model help to address the business problem?",
            "zh": "预测分析模型可以通过哪些方式帮助解决业务问题？"
        }
    },
    {
        "translation": {
            "en": "4.4.1   Alternative Feature Selection and Impurity Metrics",
            "zh": "4.4.1 替代特征选择和杂质指标"
        }
    },
    {
        "translation": {
            "en": "mean absolute error, 577, 578",
            "zh": "平均绝对误差，577,578"
        }
    },
    {
        "translation": {
            "en": "Figure 8.40",
            "zh": "图 8.40"
        }
    },
    {
        "translation": {
            "en": "Note that we use the notation c‡ to represent the vector of activations in the cell state in the interval between the update by the forget gate and the subsequent update by the input gate",
            "zh": "请注意，我们使用符号 c‡ 来表示在忘记门更新和输入门后续更新之间的间隔内，单元状态中的激活向量"
        }
    },
    {
        "translation": {
            "en": "13.4.1   Baseline Models",
            "zh": "13.4.1 基线模型"
        }
    },
    {
        "translation": {
            "en": "triangular inequality criterion, 184, 211",
            "zh": "三角不等式准则，184,211"
        }
    },
    {
        "translation": {
            "en": "(b) What target level would a k-NN model with k = 3 and using Euclidean distance return for the same query?",
            "zh": "（b） 对于同一查询，k = 3 并使用欧几里得距离的 k-NN 模型将返回什么目标水平？"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering algorithm is simple and reasonably effective, but this simple version leaves a number of questions unanswered—can we make the process more efficient, how are clusterings evaluated, how is k chosen, and how are clusters interpreted?—and it works only for clusterings of a certain underlying structure.",
            "zh": "k-means聚类算法简单且相当有效，但是这个简单的版本留下了许多未回答的问题——我们能否使这个过程更有效率，如何评估聚类，如何选择k，以及如何解释聚类？——它只适用于特定底层结构的聚类。"
        }
    },
    {
        "translation": {
            "en": "In fact, because the rectifier linear function is unbounded,26 it is often the case that smaller learning rates are necessary in training a ReLU network than in training a network with logistic units.",
            "zh": "事实上，由于整流器线性函数是无界的，26 因此，在训练 ReLU 网络时，通常需要比训练具有逻辑单元的网络更小的学习率。"
        }
    },
    {
        "translation": {
            "en": "The domain concepts were developed through a series of workshops with representatives of various parts of the AT business—in particular the retention team, but also sales and marketing and billing.",
            "zh": "领域概念是通过一系列研讨会开发的，这些研讨会是与AT业务各个部门的代表进行的，特别是保留团队，以及销售、营销和计费。"
        }
    },
    {
        "translation": {
            "en": "Real instances tend to cluster.",
            "zh": "真实实例倾向于聚类。"
        }
    },
    {
        "translation": {
            "en": "15. Note that in this example and in the examples that follow, a normalized version of the generators dataset is used (all descriptive features are normalized to the range [−1, 1] using range normalization), so the weights in Equation (7.27)[342] are different from those in Equation (7.23)[339]. If it were not for normalization, these two sets of weights would be the same.",
            "zh": "15. 请注意，在本例和随后的例例中，使用了生成器数据集的归一化版本（所有描述性特征都使用范围归一化将范围 [−1， 1] 归一化），因此等式 （7.27）[342] 中的权重与等式 （7.23）[339] 中的权重不同。如果不是归一化，这两组权重将是相同的。"
        }
    },
    {
        "translation": {
            "en": "edges, 286",
            "zh": "边缘， 286"
        }
    },
    {
        "translation": {
            "en": "Important application-based solutions for building predictive data analytics models include IBM SPSS, Knime Analytics Platform, RapidMiner Studio, SAS Enterprise Miner, and Weka.14 The tools by IBM and SAS are enterprise-wide solutions that integrate with the other offerings by these companies.",
            "zh": "用于构建预测性数据分析模型的重要基于应用程序的解决方案包括 IBM SPSS、Knime Analytics Platform、RapidMiner Studio、SAS Enterprise Miner 和 Weka.14 IBM 和 SAS 的工具是企业级解决方案，可与这些公司的其他产品集成。"
        }
    },
    {
        "translation": {
            "en": "However, for the sake of space, here we illustrate the backpropagation process for a single example.",
            "zh": "但是，为了篇幅有限，我们在这里举一个例子来说明反向传播过程。"
        }
    },
    {
        "translation": {
            "en": "Again the relevant performance measures are calculated on the test set and recorded.",
            "zh": "同样，在测试集上计算并记录相关的性能指标。"
        }
    },
    {
        "translation": {
            "en": "Although there remained some details left to agree on, the fact that the SDSS had defined their problem in terms of analytics meant that Jocelyn very easily completed the important step of converting a business problem into an analytics solution.",
            "zh": "尽管还有一些细节需要达成一致，但 SDSS 已经根据分析定义了他们的问题，这意味着 Jocelyn 非常轻松地完成了将业务问题转化为分析解决方案的重要步骤。"
        }
    },
    {
        "translation": {
            "en": "1,250",
            "zh": "1,250"
        }
    },
    {
        "translation": {
            "en": "(c) What target level will a naive Bayes model predict for the query document in Part (b) of this question, if Laplace smoothing with k = 10 and a vocabulary size of 6 is used?",
            "zh": "（c） 如果使用 k = 10 且词汇量为 6 的拉普拉斯平滑，朴素贝叶斯模型将预测本问题 （b） 部分中的查询文档的目标水平是多少？"
        }
    },
    {
        "translation": {
            "en": "12.4   The confusion matrix from the test of the AT churn prediction non-stratified hold-out test set.",
            "zh": "12.4 来自 AT 流失预测非分层保持测试集的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "There are two main ways in which causation can be mistakenly assumed.",
            "zh": "有两种主要方式可以错误地假设因果关系。"
        }
    },
    {
        "translation": {
            "en": "When the silhouette is used in this approach, it is often referred to as the silhouette method.",
            "zh": "当在这种方法中使用剪影时，它通常被称为剪影方法。"
        }
    },
    {
        "translation": {
            "en": "As with the techniques described in the previous section, sometimes these techniques are performed as part of the Data Preparation phase of CRISP-DM, but sometimes they are performed as part of the Modeling phase.",
            "zh": "与上一节中描述的技术一样，有时这些技术是作为 CRISP-DM 数据准备阶段的一部分执行的，但有时它们作为建模阶段的一部分执行。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.9",
            "zh": "图 4.9"
        }
    },
    {
        "translation": {
            "en": "1. the vector of cell activations ct is passed through a layer of tanh units to create a vector of candidate output activations;",
            "zh": "1. 细胞活化 CT 的载体通过一层 Tanh 单元以创建候选输出活化的载体;"
        }
    },
    {
        "translation": {
            "en": "A proportion of of the values in a sample take values equal to or lower than the ith percentile of that sample.",
            "zh": "样本中一定比例的值取的值等于或小于该样本的第 i 个百分位数。"
        }
    },
    {
        "translation": {
            "en": "9.7   Exercises",
            "zh": "9.7 练习"
        }
    },
    {
        "translation": {
            "en": "The second goal of data exploration is to determine whether or not the data in an ABT suffer from any data quality issues that could adversely affect the models that we build.",
            "zh": "数据探索的第二个目标是确定 ABT 中的数据是否存在任何可能对我们构建的模型产生不利影响的数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "To see how this revised algorithm can induce a decision tree, we use the example of predicting the number of bike rentals per day for a city bike sharing program based on the SEASON and whether it is a WORK DAY.",
            "zh": "为了了解这种修订后的算法如何诱导决策树，我们以预测城市自行车共享计划每天的自行车租赁数量为例，该示例基于季节以及它是否是工作日。"
        }
    },
    {
        "translation": {
            "en": "However, we can adjust this by offsetting the values input into the distribution.",
            "zh": "但是，我们可以通过偏移输入到分布中的值来调整这一点。"
        }
    },
    {
        "translation": {
            "en": "For example, when dealing with binary features, we need simply state the probability of each feature being true, and the false value is understood as 1 minus this probability.",
            "zh": "例如，在处理二进制特征时，我们只需要陈述每个特征为真的概率，而假值被理解为 1 减去这个概率。"
        }
    },
    {
        "translation": {
            "en": "CREDIT HISTORY captures the credit history of the applicant, and its levels are none (the applicant has no previous loans), paid (the applicant had loans previously and has paid them off), current (the applicant has existing loans and are current in repayments), and arrears (the applicant has existing loans and are in arrears in repayments).",
            "zh": "信用记录捕获申请人的信用记录，其级别为无（申请人以前没有贷款）、已支付（申请人以前有贷款并已还清）、当前（申请人已有贷款且当前还款）和欠款（申请人已有贷款并拖欠还款）。"
        }
    },
    {
        "translation": {
            "en": "They take a bootstrapping approach where estimates of action-value are iteratively improved on the basis of other estimates of action-value.",
            "zh": "他们采用引导方法，在行动价值的其他估计的基础上迭代改进行动价值的估计。"
        }
    },
    {
        "translation": {
            "en": "Each state is connected to all the other states that can be generated by adding or removing a single feature from that state.",
            "zh": "每个状态都连接到所有其他状态，这些状态可以通过在该状态中添加或移除单个要素来生成。"
        }
    },
    {
        "translation": {
            "en": "Lunar Lander, 668",
            "zh": "月球着陆器，668"
        }
    },
    {
        "translation": {
            "en": "(d) What is the probability that JIM went shopping given that WINE=true?",
            "zh": "（d） 在WINE=true的情况下，JIM去购物的概率是多少？"
        }
    },
    {
        "translation": {
            "en": "Propensity models inherently have a temporal element, and when this is the case, we must take time into account when designing the ABT.",
            "zh": "倾向模型本身就具有时间因素，在这种情况下，我们在设计 ABT 时必须考虑时间。"
        }
    },
    {
        "translation": {
            "en": "In this case, although the likelihood of suffering from a headache and vomiting is quite high when someone has meningitis, the prior probability of having meningitis is quite low.",
            "zh": "在这种情况下，虽然当有人患有脑膜炎时，头痛和呕吐的可能性相当高，但先前患脑膜炎的概率相当低。"
        }
    },
    {
        "translation": {
            "en": "(a) Define the topology of a Bayesian network that encodes these causal relationships between the following Boolean variables: JIM (Jim has done the shopping, true or false), MARTHA (Martha has done the shopping, true or false), WINE (wine has been purchased, true or false).",
            "zh": "（a） 定义贝叶斯网络的拓扑结构，该拓扑对以下布尔变量之间的因果关系进行编码：JIM（Jim 已购物，真或假）、MARTHA（Martha 已购物，真或假）、WINE（已购买葡萄酒，真或假）。"
        }
    },
    {
        "translation": {
            "en": "where |𝒜| refers to the size of the test set on which performance measures were originally calculated, |𝒜t=l| refers to the number of instances in the original test set for which the model made a prediction of level l for target t, |ℬ| and |ℬt=l| refer to the same measurements on the newly collected dataset, and loge is the natural logarithm.24 In general,",
            "zh": "其中 |A|指最初计算性能度量值的测试集的大小，|At=l|指原始测试集中模型对目标 t 进行 l 级预测的实例数，|B|和 |Bt=l|参考新收集的数据集上的相同测量值，loge 是自然对数.24 一般来说，"
        }
    },
    {
        "translation": {
            "en": "10.1 Big Idea",
            "zh": "10.1 大创意"
        }
    },
    {
        "translation": {
            "en": "To overcome this contradiction temporal-difference learning uses an approach known as bootstrapping.",
            "zh": "为了克服这一矛盾，时间差分学习使用了一种称为自举的方法。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.2[387] shows plots of some of the activation functions that have been popular in neural networks over the last few decades, including the threshold, logistic, tanh, and rectifier linear functions.",
            "zh": "图8.2[387]显示了过去几十年来在神经网络中流行的一些激活函数的图，包括阈值函数、逻辑函数、tanh函数和整流器线性函数。"
        }
    },
    {
        "translation": {
            "en": "However, if the error is sensitive to changes in the weight, then the error is dependent on the weight and accordingly the current weight is to blame for some portion of the error.",
            "zh": "但是，如果误差对权重的变化很敏感，则误差取决于权重，因此当前权重应归咎于误差的某些部分。"
        }
    },
    {
        "translation": {
            "en": "1. Full details of the SDSS project, which is fascinating, are available at www.sdss.org.",
            "zh": "1. SDSS项目的全部细节令人着迷，可在 www.sdss.org 上找到。"
        }
    },
    {
        "translation": {
            "en": "5. See Chapter 2[23].",
            "zh": "[5]见第2章[23]。"
        }
    },
    {
        "translation": {
            "en": "Hourly samples of ambient factors and full load electrical power output of a combined cycle power plant.",
            "zh": "联合循环电厂环境因素和满负荷电力输出的每小时样本。"
        }
    },
    {
        "translation": {
            "en": "Data exploration is a key part of both the Data Understanding and Data Preparation phases of CRISP-DM.",
            "zh": "数据探索是 CRISP-DM 数据理解和数据准备阶段的关键部分。"
        }
    },
    {
        "translation": {
            "en": "12.2   Data Understanding",
            "zh": "12.2 数据理解"
        }
    },
    {
        "translation": {
            "en": "—Claude Elwood Shannon",
            "zh": "——克劳德·埃尔伍德·香农"
        }
    },
    {
        "translation": {
            "en": "A similar analysis also explains the exploding δ values plotted in Figure 8.24(d)[454].",
            "zh": "类似的分析也解释了图8.24（d）[454]中绘制的爆炸δ值。"
        }
    },
    {
        "translation": {
            "en": "Alimoglu, Fevzi, and Ethem Alpaydin. 1996. Methods of combining multiple classifiers based on different representations for pen-based handwritten digit recognition. In Proceedings of the fifth Turkish artificial intelligence and artificial neural networks symposium (TAINN’96).",
            "zh": "Alimoglu、Fevzi 和 Ethem Alpaydin。1996. 基于不同表示的多个分类器组合方法，用于基于笔的手写数字识别。在第五届土耳其人工智能和人工神经网络研讨会（TAINN'96）的论文集上。"
        }
    },
    {
        "translation": {
            "en": "When we find data quality issues due to valid data during data exploration, we should note these issues in a data quality plan for potential handling later in the project.",
            "zh": "当我们在数据探索过程中发现由于有效数据而导致的数据质量问题时，我们应该在数据质量计划中记录这些问题，以便在项目后期进行可能的处理。"
        }
    },
    {
        "translation": {
            "en": "target hypersphere, 201",
            "zh": "目标超球体，201"
        }
    },
    {
        "translation": {
            "en": "Notice that each of the neurons in the output layer (Neurons 3, 4, and 5) are independent of each other; they receive no information from each other.",
            "zh": "请注意，输出层中的每个神经元（神经元 3、4 和 5）都是相互独立的;他们之间没有收到任何信息。"
        }
    },
    {
        "translation": {
            "en": "representation learning, 401, 599, 624, 629",
            "zh": "表示学习，401,599,624,629"
        }
    },
    {
        "translation": {
            "en": "The instances in this table have been sorted by these scores in ascending order; as a result, the thresholding on the scores to generate predictions is very much apparent.",
            "zh": "此表中的实例已按这些分数按升序排序;因此，生成预测的分数阈值非常明显。"
        }
    },
    {
        "translation": {
            "en": "The per example error after each weight has been updated once, the per example ∂ℰ/∂a8, and the sum of squared errors for the model.",
            "zh": "每个权重更新一次后的每个示例误差、每个示例 ∂E/∂a8 和模型的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "The boundary between d2 and d4 is",
            "zh": "d2 和 d4 之间的边界是"
        }
    },
    {
        "translation": {
            "en": "The first part of each chapter presents an informal introduction to the material presented in the chapter, followed by a detailed explanation of the fundamental technical concepts required to understand the material. Then it presents a standard machine learning algorithm used in that learning approach, along with a detailed worked example.",
            "zh": "每章的第一部分对本章中介绍的材料进行了非正式的介绍，然后详细解释了理解材料所需的基本技术概念。然后，它介绍了该学习方法中使用的标准机器学习算法，以及详细的工作示例。"
        }
    },
    {
        "translation": {
            "en": "non-negativity criterion, 184, 211",
            "zh": "非负性标准，184,211"
        }
    },
    {
        "translation": {
            "en": "None of this, however, yet explains how any actual learning takes place! This explanation appears subsequently, but before discussing reinforcement learning algorithms we will explain Markov decision processes, a useful mathematical framework into which we can place the key components of reinforcement learning to allow learning to take place.",
            "zh": "然而，这些都没有解释任何实际的学习是如何发生的！这个解释随后出现，但在讨论强化学习算法之前，我们将解释马尔可夫决策过程，这是一个有用的数学框架，我们可以将强化学习的关键组件放入其中，以便进行学习。"
        }
    },
    {
        "translation": {
            "en": "9.4.6   Evaluating Models after Deployment",
            "zh": "9.4.6 部署后评估模型"
        }
    },
    {
        "translation": {
            "en": "Beyond knowing the correct terminology to use, an analytics practitioner who is situationally fluent will have sufficient knowledge of the quirks of a particular domain to be able to competently build analytics solutions for that domain.",
            "zh": "除了知道要使用的正确术语之外，精通情境的分析从业者还将对特定领域的怪癖有足够的了解，以便能够胜任地为该领域构建分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "Let’s look at Bayes’ Theorem in a little more detail. Bayes’ Theorem is easily derived from the product rule.7 We know from the product rule and the logical symmetry of the and operation8 that",
            "zh": "让我们更详细地看一下贝叶斯定理。贝叶斯定理很容易从乘积法则推导出来.7 我们从乘积法则和 和 运算的逻辑对称性8 中知道"
        }
    },
    {
        "translation": {
            "en": "The features used at the top levels of both trees, and deemed most informative by the algorithm, were the same: AVGOVERBUNDLEMINS, BILLAMOUNTCHANGEPCT, and HANDSETAGE.",
            "zh": "在两棵树的顶层使用的特征是相同的，并且算法认为信息量最大：AVGOVERBUNDLEMINS、BILLAMOUNTCHANGEPCT 和 HANDSETAGE。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn generated histograms for all these features compared to the target feature—for example, Figure 13.7[718] shows the histograms for the EXPRAD_R feature.",
            "zh": "Jocelyn 为所有这些特征生成了与目标特征相比的直方图，例如，图 13.7[718] 显示了EXPRAD_R特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Although this is useful for a range of real-world predictive analytics problems, we are also interested in prediction problems with categorical target features.",
            "zh": "尽管这对于一系列实际的预测分析问题很有用，但我们也对具有分类目标特征的预测问题感兴趣。"
        }
    },
    {
        "translation": {
            "en": "8.28   The forward pass of the mini-batch of examples listed in Table 8.13[464] through the network in Figure 8.27[465].",
            "zh": "8.28 表8.13[464]中列出的小批量示例通过图8.27[465]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "First, in each case a model is used to make a prediction to help a person or organization make a decision.",
            "zh": "首先，在每种情况下，都使用模型进行预测，以帮助个人或组织做出决策。"
        }
    },
    {
        "translation": {
            "en": "A generalized way in which to do this is to introduce basis functions that transform the raw inputs to the model into non-linear representations but still keep the model itself linear in terms of the weights.",
            "zh": "实现此目的的一种通用方法是引入基函数，这些函数将模型的原始输入转换为非线性表示，但仍保持模型本身在权重方面的线性。"
        }
    },
    {
        "translation": {
            "en": "output gate, 508, 512",
            "zh": "输出栅极，508、512"
        }
    },
    {
        "translation": {
            "en": "As the number of descriptive features grows, the number of potential conditioning events grows.",
            "zh": "随着描述性特征数量的增加，潜在条件反射事件的数量也在增加。"
        }
    },
    {
        "translation": {
            "en": "This illustrates the big idea behind unsupervised learning.",
            "zh": "这说明了无监督学习背后的大概念。"
        }
    },
    {
        "translation": {
            "en": "For example, for every increase of a square foot in office size, we can expect the rental price to go up by 0.6270 Euro per month.",
            "zh": "例如，办公室面积每增加一平方英尺，我们可以预期租金价格每月上涨 0.6270 欧元。"
        }
    },
    {
        "translation": {
            "en": "For continuous features we should first examine the mean and standard deviation of each feature to get a sense of the central tendency and variation of the values within the dataset for the feature.",
            "zh": "对于连续特征，我们应首先检查每个特征的均值和标准差，以了解特征数据集中值的中心趋势和变化。"
        }
    },
    {
        "translation": {
            "en": "8.21   A plot showing how the sum of squared errors of the ReLU network changed during training when α = 0.1.",
            "zh": "8.21 当 α = 0.1 时，ReLU 网络的平方误差和在训练期间如何变化的图。"
        }
    },
    {
        "translation": {
            "en": "13. All datasets presented in this chapter have been structured as ABTs.",
            "zh": "13. 本章介绍的所有数据集均采用ABT结构。"
        }
    },
    {
        "translation": {
            "en": "It was confirmed by the business that the zeros in the INCOME feature actually represent missing values and that MARITAL STATUS and INCOME were collected together, leading to their both being missing for the same instances in the ABT.",
            "zh": "该业务证实，INCOME 特征中的零实际上代表缺失值，并且 MARITAL STATUS 和 INCOME 是一起收集的，导致它们在 ABT 中的相同实例中都缺失。"
        }
    },
    {
        "translation": {
            "en": "Using this notation and taking the second layer of neurons in a network as an example, if we name the matrix containing the weights on the edges into Layer 2 as W(2), the column vector of activations coming from the neurons in Layer 1 as a(1), and the column vector of weighted sums for the neurons in Layer 2 as z(2), then the order of the matrices in the multiplication operation that we use in this explanation is",
            "zh": "使用这种表示法，并以网络中的第二层神经元为例，如果我们将包含边缘权重的矩阵命名为 W（2），将来自第 1 层神经元的激活的列向量命名为 a（1），将第 2 层神经元的加权和的列向量命名为 z（2）， 那么我们在这个解释中使用的乘法运算中矩阵的顺序是"
        }
    },
    {
        "translation": {
            "en": "What is the predictive analytics target? What descriptive features will we include/exclude? How will we handle missing values? How will we normalize our features? How will we represent continuous features? What types of models will we create? How will we set the parameters of the learning algorithms? What evaluation process will we follow? What performance measures will we use?",
            "zh": "预测分析目标是什么？我们将包含/排除哪些描述性特征？我们将如何处理缺失值？我们将如何规范化我们的功能？我们将如何表示连续特征？我们将创建哪些类型的模型？我们将如何设置学习算法的参数？我们将遵循什么评估流程？我们将使用哪些绩效衡量标准？"
        }
    },
    {
        "translation": {
            "en": "Another commonly used measure of central tendency is the mode.",
            "zh": "另一个常用的集中趋势测量是模式。"
        }
    },
    {
        "translation": {
            "en": "Using this nearest neighbor model, the marketing department wants to decide whether they should contact a customer with the following profile: SALARY = 56,000 and AGE = 35.",
            "zh": "使用此最近邻模型，营销部门希望决定是否应联系具有以下配置文件的客户：SALARY = 56,000 和 AGE = 35。"
        }
    },
    {
        "translation": {
            "en": "(b) Twenty people flip a fair coin. What is the probability that exactly eight of them will get heads?",
            "zh": "（b） 二十个人掷一枚公平的硬币。他们中的八个人获得头部的概率是多少？"
        }
    },
    {
        "translation": {
            "en": "Activation Functions",
            "zh": "激活函数"
        }
    },
    {
        "translation": {
            "en": "Later studies (Zadnik et al., 2000; Gwiazda et al., 2000), however, could not replicate this link, and eventually a more plausible explanation for the correlation between night-light use and near-sightedness was uncovered.",
            "zh": "后来的研究（Zadnik等人，2000年;然而，Gwiazda et al.， 2000）无法复制这种联系，最终发现了对夜灯使用与近视之间相关性的更合理的解释。"
        }
    },
    {
        "translation": {
            "en": "An ABT, however, rarely comes directly from a single source already existing within an organization.",
            "zh": "然而，ABT 很少直接来自组织内已经存在的单一来源。"
        }
    },
    {
        "translation": {
            "en": "A selection of the logistic regression models developed during the gradient descent process for the machinery dataset from Table 7.6[339]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "表7.6[339]中机械数据集的梯度下降过程中开发的逻辑回归模型的选择。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions",
            "zh": "符号约定"
        }
    },
    {
        "translation": {
            "en": "8.4.5.2 Weight sharing and translation equivariant feature detection When a neuron applies a filter to its local receptive field, it is a local visual feature detector for which the visual feature is a pattern of input values.",
            "zh": "8.4.5.2 权重共享和平移等变特征检测 当神经元对其局部感受野施加滤波器时，它是一个局部视觉特征检测器，其视觉特征是输入值的模式。"
        }
    },
    {
        "translation": {
            "en": "Is the data required by the solution available, or could it be made available?",
            "zh": "解决方案所需的数据是否可用，或者是否可以提供？"
        }
    },
    {
        "translation": {
            "en": "The other sets in Figure 4.5[124] have entropy values between these two extremes.",
            "zh": "图4.5[124]中的其他集合的熵值介于这两个极端之间。"
        }
    },
    {
        "translation": {
            "en": "In many cases, if the environment is fully observable this function is a simple identity function because the observation fully defines the state.",
            "zh": "在许多情况下，如果环境是完全可观察的，则此函数是一个简单的标识函数，因为观察完全定义了状态。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have introduced two ways to represent the probabilities of events in a domain, a full joint probability distribution and a naive Bayes model.",
            "zh": "在本章中，我们介绍了两种表示域中事件概率的方法，一种是完全联合概率分布，另一种是朴素贝叶斯模型。"
        }
    },
    {
        "translation": {
            "en": "In fact, it looks very similar to a normal distribution, as shown in Figure 6.3(a)[270].",
            "zh": "事实上，它看起来与正态分布非常相似，如图6.3（a）[270]所示。"
        }
    },
    {
        "translation": {
            "en": "HANDSETAGE: Based on a customer’s latest handset entry, this feature captured the number of days that the customer had had his or her current handset.",
            "zh": "手机：根据客户最新的手机条目，此功能捕获客户拥有当前手机的天数。"
        }
    },
    {
        "translation": {
            "en": "The business has decided to use a nearest neighbor model to predict whether a current trial user whose free trial period is about to end is likely to sign up for the paid service. The query instance, q, describing this user is:",
            "zh": "该企业已决定使用最近邻模型来预测免费试用期即将结束的当前试用用户是否有可能注册付费服务。描述此用户的查询实例 q 为："
        }
    },
    {
        "translation": {
            "en": "(d) P(VOMITING = false | HEADACHE = true)",
            "zh": "（d） P（VOMITING = 假 |头痛 = 真）"
        }
    },
    {
        "translation": {
            "en": "In most cases, Ross confirmed with Kate and Grace that these were valid because the range of values that the features could take was naturally low.",
            "zh": "在大多数情况下，Ross 向 Kate 和 Grace 确认这些是有效的，因为这些特征可以采用的值范围自然很低。"
        }
    },
    {
        "translation": {
            "en": "Trying to compute the probability of P(h,f,¬v | m) directly from the data rather than using the chain rule also suffers from the same problem.",
            "zh": "尝试直接从数据中计算 P（h，f，¬v | m） 的概率而不是使用链式法则也会遇到同样的问题。"
        }
    },
    {
        "translation": {
            "en": "5.3   The distances (Dist.) between the query instance with SPEED = 6.75 and AGILITY = 3.00 and each instance in Table 5.2[183].",
            "zh": "5.3 SPEED = 6.75 且 AGILITY = 3.00 的查询实例与表 5.2[183] 中每个实例之间的距离（距离）。"
        }
    },
    {
        "translation": {
            "en": "The stepping-stone crossing challenge described in Section 11.1[637] nicely illustrates the intelligent agent approach that underpins reinforcement learning.",
            "zh": "第 11.1 节[637]中描述的垫脚石交叉挑战很好地说明了支持强化学习的智能代理方法。"
        }
    },
    {
        "translation": {
            "en": "where the terms y2 and 4y are treated as constants as they do not include x, and",
            "zh": "其中项 y2 和 4y 被视为常量，因为它们不包括 x，并且"
        }
    },
    {
        "translation": {
            "en": "To illustrate the use of an auto-encoder network for feature generation, we use a dataset of simple handwritten digits.14 This dataset contains a library of 1,797 small (8 pixels by 8 pixels) grayscale images of handwritten digits (0–9).",
            "zh": "为了说明使用自动编码器网络生成特征，我们使用了一个简单的手写数字数据集.14 该数据集包含 1,797 个手写数字 （0–9） 的小（8 像素 x 8 像素）灰度图像库。"
        }
    },
    {
        "translation": {
            "en": "Hold-out sampling is probably the simplest form of sampling that we can use and is most appropriate when we have very large datasets from which we can take samples.",
            "zh": "保持抽样可能是我们可以使用的最简单的抽样形式，当我们有非常大的数据集可以从中获取样本时，这是最合适的。"
        }
    },
    {
        "translation": {
            "en": "The other problem is that the network being used to generate targets is the actual network being trained.",
            "zh": "另一个问题是，用于生成目标的网络是正在训练的实际网络。"
        }
    },
    {
        "translation": {
            "en": "The logical AND and OR functions are linearly separable, but the XOR is not. This figure is Figure 4.2 of Kelleher (2019) and is used here with permission.",
            "zh": "逻辑 AND 和 OR 函数是线性可分离的，但 XOR 不是。此图是 Kelleher （2019） 的图 4.2，经许可在此处使用。"
        }
    },
    {
        "translation": {
            "en": "-0.004200",
            "zh": "-0.004200"
        }
    },
    {
        "translation": {
            "en": "Consequently, the model will return a price prediction that is the average price of these three neighbors:",
            "zh": "因此，模型将返回一个价格预测，即这三个邻居的平均价格："
        }
    },
    {
        "translation": {
            "en": "This poll put Obama ahead of Romney in the race to the White House.",
            "zh": "这项民意调查使奥巴马在白宫竞选中领先于罗姆尼。"
        }
    },
    {
        "translation": {
            "en": "Full joint probability distributions, however, grow at an exponential rate as new features or feature levels are added to the domain.",
            "zh": "但是，随着新特征或特征级别添加到域中，完全联合概率分布会以指数速度增长。"
        }
    },
    {
        "translation": {
            "en": "In this naive approach each instance presented to the network would be highly correlated with the previous instance presented (similar states would follow each other on the basis of actions taken) and independence would no longer be the case.",
            "zh": "在这种幼稚的方法中，呈现给网络的每个实例都将与呈现的前一个实例高度相关（相似的状态将根据所采取的行动相互跟随），并且独立性将不再如此。"
        }
    },
    {
        "translation": {
            "en": "16. This example is very much simplified for illustration purposes, but very interesting work is done on building prediction models from the output of EEG and fMRI scans—for example, Mitchell et al. (2008).",
            "zh": "16. 为了说明目的，这个例子被简化了很多，但是在根据脑电图和功能磁共振成像扫描的输出建立预测模型方面做了非常有趣的工作——例如，Mitchell等人（2008）。"
        }
    },
    {
        "translation": {
            "en": "H.R. DIFF.: The difference between the patient’s heart rate at this visit and at their last visit to the clinic",
            "zh": "HR 差异：患者在这次就诊时的心率与上次就诊时的心率之间的差异"
        }
    },
    {
        "translation": {
            "en": "MCR4_U/G/R/I/Z",
            "zh": "MCR4_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15(b)[569] shows a cumulative gain chart of this data.",
            "zh": "图9.15（b）[569]显示了该数据的累积增益图。"
        }
    },
    {
        "translation": {
            "en": "To do this we use the concept of a probability distribution.",
            "zh": "为此，我们使用概率分布的概念。"
        }
    },
    {
        "translation": {
            "en": "12. While the name CRISP-DM refers to data mining (a field that overlaps significantly with predictive data analytics), it is equally applicable to predictive analytics projects.",
            "zh": "12. 虽然 CRISP-DM 这个名称指的是数据挖掘（一个与预测性数据分析有很大重叠的领域），但它同样适用于预测性分析项目。"
        }
    },
    {
        "translation": {
            "en": "3.6.1 Normalization",
            "zh": "3.6.1 归一化"
        }
    },
    {
        "translation": {
            "en": "5. The silhouette (Rousseeuw, 1987) is just one example of how clusterings can be evaluated. Others include the cubic clustering criterion (Sarle, 1983) and the Dunn index (Dunn, 1974); however, these are based on very similar ideas to the silhouette.",
            "zh": "5. 轮廓（Rousseeuw，1987）只是如何评估聚类的一个例子。其他包括三次聚类准则（Sarle，1983）和Dunn指数（Dunn，1974）;然而，这些都是基于与剪影非常相似的想法。"
        }
    },
    {
        "translation": {
            "en": "Often multiple features are required to fully express a single domain concept.",
            "zh": "通常需要多个特征才能完全表达单个领域概念。"
        }
    },
    {
        "translation": {
            "en": "The predictions made by the decision tree model result in a higher profit than those made by the k-NN model.",
            "zh": "决策树模型的预测比 k-NN 模型的预测产生更高的利润。"
        }
    },
    {
        "translation": {
            "en": "To begin, imagine a car journey where we start out driving on a minor road at about 30mph and then move onto a highway, where we drive at about 80mph before noticing an accident and braking suddenly.",
            "zh": "首先，想象一下汽车之旅，我们开始在一条小路上以大约 30 英里/小时的速度行驶，然后驶入高速公路，在那里我们以大约 80 英里/小时的速度行驶，然后注意到发生事故并突然刹车。"
        }
    },
    {
        "translation": {
            "en": "If we keep in mind that the ultimate goal of an analytics solution is to build a predictive model that predicts a target feature from a set of descriptive features, domain concepts are the characteristics of the prediction subject that domain experts and analytics experts believe are likely to be useful in making this prediction.",
            "zh": "如果我们记住，分析解决方案的最终目标是构建一个预测模型，该模型从一组描述性特征中预测目标特征，则领域概念是领域专家和分析专家认为可能有助于进行此预测的预测主题的特征。"
        }
    },
    {
        "translation": {
            "en": "A.4.2    Histograms",
            "zh": "A.4.2 直方图"
        }
    },
    {
        "translation": {
            "en": "4.1   Big Idea",
            "zh": "4.1 大创意"
        }
    },
    {
        "translation": {
            "en": "If we compare this equation with Equation (7.24)[341], it is apparent that a perceptron network is identical to a multivariate linear regression model with a threshold applied to it.",
            "zh": "如果我们将这个方程与方程（7.24）[341]进行比较，很明显，感知器网络与应用了阈值的多元线性回归模型相同。"
        }
    },
    {
        "translation": {
            "en": "Deep learning (Chapter 8[381])",
            "zh": "深度学习（第8章[381]）"
        }
    },
    {
        "translation": {
            "en": "There are many other indexes and metrics we could have presented, for example, Tanimoto similarity (which is a generalization of the Jaccard similarity to non-binary data), and correlation-based approaches such as the Pearson correlation.",
            "zh": "我们还可以提出许多其他索引和指标，例如，谷本相似性（这是 Jaccard 相似性与非二进制数据的推广）和基于相关性的方法，例如 Pearson 相关性。"
        }
    },
    {
        "translation": {
            "en": "The reason is that the transfer of hidden neuron activations to the memory buffer is a simple copy operation.",
            "zh": "原因是将隐藏的神经元激活转移到内存缓冲区是一个简单的复制操作。"
        }
    },
    {
        "translation": {
            "en": "Figure 12.7[701] shows the stunted tree Ross generated for the churn problem, where the depth of the tree is limited to five layers.",
            "zh": "图 12.7[701] 显示了 Ross 为搅动问题生成的发育不良树，其中树的深度限制为五层。"
        }
    },
    {
        "translation": {
            "en": "Gaussian mixture model, 629",
            "zh": "高斯混合模型，629"
        }
    },
    {
        "translation": {
            "en": "where the value of the LIFE EXP feature is unknown for the country. This means that in the network, one of the parents of the target feature node, CPI, is unknown. Consequently, we need to sum out this feature for each level of the target. We can calculate the probability for CPI = high as follows:28",
            "zh": "其中 LIFE EXP 功能的价值在国家/地区未知。这意味着在网络中，目标特征节点 CPI 的父节点之一未知。因此，我们需要对目标的每个级别总结此功能。我们可以计算 CPI = 高的概率如下：28"
        }
    },
    {
        "translation": {
            "en": "In this chapter we discuss the ways in which concepts from information theory can be used to build prediction models.",
            "zh": "在本章中，我们将讨论信息论中的概念可用于构建预测模型的方法。"
        }
    },
    {
        "translation": {
            "en": "fraud detection, 262, 538",
            "zh": "欺诈检测，262,538"
        }
    },
    {
        "translation": {
            "en": "One of the most attractive features of the regression models discussed in this chapter is that they are based on a large body of research and best practice in statistics, a much older discipline than machine learning.",
            "zh": "本章讨论的回归模型最吸引人的特点之一是，它们基于统计学的大量研究和最佳实践，这是一门比机器学习更古老的学科。"
        }
    },
    {
        "translation": {
            "en": "A further benefit of implementing a neural network using matrix operations is that it enables the use of specialized hardware known as graphical processing units (GPUs).",
            "zh": "使用矩阵运算实现神经网络的另一个好处是，它允许使用称为图形处理单元 （GPU） 的专用硬件。"
        }
    },
    {
        "translation": {
            "en": "In this example the sample should represent the voting population—for example, there should be a representative proportion of males compared to females and of different age categories within the sample.",
            "zh": "在此示例中，样本应代表投票人口，例如，样本中男性与女性相比，以及不同年龄类别的代表性比例。"
        }
    },
    {
        "translation": {
            "en": "For example, consider a problem in which we are trying to predict whether a customer will default on a loan obligation.",
            "zh": "例如，考虑一个问题，我们试图预测客户是否会拖欠贷款义务。"
        }
    },
    {
        "translation": {
            "en": "The easiest way to implement this weighting scheme is to weight each neighbor by the reciprocal6 of the squared distance between the neighbor d and the query q:",
            "zh": "实现此加权方案的最简单方法是通过邻域 d 和查询 q 之间平方距离的倒数 6 对每个邻域进行加权："
        }
    },
    {
        "translation": {
            "en": "It is worth mentioning that to use profit as a performance measure, we don’t need to quantify the profit associated with each outcome as completely as we have done in this example.",
            "zh": "值得一提的是，要使用利润作为绩效衡量标准，我们不需要像在本例中那样完全量化与每个结果相关的利润。"
        }
    },
    {
        "translation": {
            "en": "Let’s consider an example.",
            "zh": "让我们考虑一个例子。"
        }
    },
    {
        "translation": {
            "en": "9.13   The K-S chart for the email classification predictions shown in Table 9.11[557].",
            "zh": "9.13 表9.11[557]所示的电子邮件分类预测的K-S图。"
        }
    },
    {
        "translation": {
            "en": "Note especially that we do not need to know the full dynamics of an MDP, in particular the state transition probabilities that are captured in a transition matrix.",
            "zh": "特别需要注意的是，我们不需要知道 MDP 的完整动态，特别是转换矩阵中捕获的状态转换概率。"
        }
    },
    {
        "translation": {
            "en": "Moon, Todd K. 1996. The expectation-maximization algorithm. IEEE Signal Processing Magazine 13 (6): 47–60.",
            "zh": "月亮，Todd K. 1996 年。期望最大化算法。IEEE信号处理杂志13（6）：47–60。"
        }
    },
    {
        "translation": {
            "en": "In the histogram we can see an unusual number of zero values for INCOME that seems set apart from the central tendency of the data, which appears to be at about 40,000.",
            "zh": "在直方图中，我们可以看到 INCOME 的零值数量不寻常，这似乎与数据的中心趋势不同，该趋势似乎约为 40,000。"
        }
    },
    {
        "translation": {
            "en": "(2000) generalized the AdaBoost algorithm and developed another popular boosting algorithm, the LogitBoost algorithm.",
            "zh": "（2000） 推广了 AdaBoost 算法，并开发了另一种流行的提升算法，即 LogitBoost 算法。"
        }
    },
    {
        "translation": {
            "en": "The value of the error function for every possible weight combination defines an error surface, similar to the one shown in Figure 7.24(a)[368]—for each combination of weight values, we get a point on the surface whose coordinates are the weight values, with an elevation defined by the error of the model using the weight values.",
            "zh": "每个可能的权重组合的误差函数值定义了一个误差面，类似于图 7.24（a）[368] 所示的误差面——对于每个权重值组合，我们在表面上得到一个点，其坐标是权重值，其高程由使用权重值的模型误差定义。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38",
            "zh": "图 8.38"
        }
    },
    {
        "translation": {
            "en": "7.3   Standard Approach: Multivariable Linear Regression with Gradient Descent",
            "zh": "7.3 标准方法：梯度下降的多变量线性回归"
        }
    },
    {
        "translation": {
            "en": "Applying the decision tree from Figure 4.4(a)[122] to this query, we see that the root node of this tree tests the CONTAINS IMAGES feature.",
            "zh": "将图4.4（a）[122]中的决策树应用于此查询，我们看到该树的根节点测试了CONTAINS IMAGES功能。"
        }
    },
    {
        "translation": {
            "en": "There are two related phenomena in Figure 8.33[484] that, in some instances, maybe undesirable consequences of how the receptive fields for the neurons have been defined.",
            "zh": "图8.33[484]中有两个相关的现象，在某些情况下，它们可能是神经元感受野定义方式的不良后果。"
        }
    },
    {
        "translation": {
            "en": "9.3 Standard Approach: Misclassification Rate on a Hold-Out Test Set",
            "zh": "9.3 标准方法：保持测试集的错误分类率"
        }
    },
    {
        "translation": {
            "en": "We use different notation for location and scale parameters, ϕ and ρ, than we do for mean and standard deviation parameters of the normal, μ and σ, because the values of these parameters are estimated using different techniques: generally, the location and scale parameters for distributions are fitted to the data using a guided search process.18 The student-t distribution, however, takes an extra parameter κ.",
            "zh": "我们对位置和尺度参数 φ 和 ρ 使用不同的符号，而不是对正态、μ 和 σ 的均值和标准差参数使用不同的符号，因为这些参数的值是使用不同的技术估计的：通常，分布的位置和尺度参数使用引导式搜索过程拟合到数据中.18 学生-t 分布， 但是，需要一个额外的参数 κ。"
        }
    },
    {
        "translation": {
            "en": "The most important part to the gradient descent algorithm is the line on which the weights are updated, Line 4[326].",
            "zh": "梯度下降算法最重要的部分是更新权重的线，即第 4 行[326]。"
        }
    },
    {
        "translation": {
            "en": "Features with a cardinality of 1 should first be investigated to ensure that the issue is not due to an ABT generation error.",
            "zh": "应首先调查基数为 1 的特征，以确保问题不是由 ABT 生成错误引起的。"
        }
    },
    {
        "translation": {
            "en": "The output layer was a fully connected layer with 4 outputs (one per action) using linear activations.",
            "zh": "输出层是一个全连接层，具有 4 个输出（每个动作一个），使用线性激活。"
        }
    },
    {
        "translation": {
            "en": "For example, if we assume that d2 was the first example processed21 and that we have set the learning rate hyper-parameter to α = 0.2, then we would update weight w7,5 as follows:",
            "zh": "例如，如果我们假设 d2 是第一个处理的示例21，并且我们已将学习率超参数设置为 α = 0.2，那么我们将更新权重 w7,5，如下所示："
        }
    },
    {
        "translation": {
            "en": "-0.62",
            "zh": "-0.62"
        }
    },
    {
        "translation": {
            "en": "Typically, we are not able to increase the number of instances in our dataset, and we face the scenario of a sparsely populated feature space,27 as illustrated in Figures 5.18(b)[226] and 5.18(c)[226].",
            "zh": "通常，我们无法增加数据集中的实例数量，并且我们面临着稀疏填充的特征空间27，如图5.18（b）[226]和5.18（c）[226]所示。"
        }
    },
    {
        "translation": {
            "en": "where the terms have the same meaning as before.",
            "zh": "其中术语的含义与以前相同。"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts by descending through the tree from the root node, taking the branch at each interior node that matches the value of the query for the feature tested at that node, until it comes to a leaf node (Line 3 of the algorithm).",
            "zh": "该算法首先从根节点下降到树中，在每个内部节点上获取与该节点上测试的特征的查询值匹配的分支，直到它到达叶节点（算法的第 3 行）。"
        }
    },
    {
        "translation": {
            "en": "Probability mass functions have two properties: (1) they always return a value between 0.0 and 1.0; and (2) the sum of the probabilities over the set of events covering all the possible assignments of values to features must equal 1.0. Formally these properties are defined as follows:",
            "zh": "概率质量函数有两个属性：（1）它们总是返回一个介于 0.0 和 1.0 之间的值;（2） 涵盖要素值所有可能赋值的事件集的概率之和必须等于 1.0。从形式上讲，这些属性定义如下："
        }
    },
    {
        "translation": {
            "en": "Jocelyn showed that even the SDSS scientists themselves disagreed on the types of certain galaxies.",
            "zh": "Jocelyn表明，即使是SDSS科学家自己也对某些星系的类型存在分歧。"
        }
    },
    {
        "translation": {
            "en": "The same result obtained by calculating the dot product of the descriptive features of a support vector and a query instance after having applied the basis functions can be obtained by applying a much less costly kernel function, kernel, to the original descriptive feature values of the support vector and the query.24 The prediction equation becomes",
            "zh": "在应用基函数后，通过计算支持向量和查询实例的描述性特征的点积而获得的结果与将成本低得多的核函数 kernel 应用于支持向量和查询的原始描述性特征值可以获得相同的结果.24 预测方程变为"
        }
    },
    {
        "translation": {
            "en": "The result of multiplying two matrices is another matrix whose dimensions are equal to the number of rows in the left matrix and the number of columns in the right matrix. For example, multiplying a 2 × 3 matrix by a 3 × 3 matrix results in a 2 × 3. Each value in the resulting matrix is calculated as follows, where i iterates over the columns in the first matrix (D) and the rows in the second matrix (E)",
            "zh": "两个矩阵相乘的结果是另一个矩阵，其维度等于左矩阵中的行数和右矩阵中的列数。例如，将 2 × 3 矩阵乘以 3 × 3 矩阵得到 2 × 3。结果矩阵中的每个值的计算方法如下，其中 i 遍历第一个矩阵 （D） 中的列和第二个矩阵 （E） 中的行"
        }
    },
    {
        "translation": {
            "en": "If the descriptive features in a dataset are binary, it is often a good idea to use a similarity index that defines similarity between instances specifically in terms of co-presence or co-absence of features, rather than an index based on distance.",
            "zh": "如果数据集中的描述性要素是二进制的，则通常最好使用相似性索引，该索引专门根据要素的共存或共缺来定义实例之间的相似性，而不是基于距离的索引。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, we use batch gradient descent for training and treat Table 8.1[422] as a batch.",
            "zh": "此外，我们使用批次梯度下降进行训练，并将表8.1[422]视为一个批次。"
        }
    },
    {
        "translation": {
            "en": "To illustrate how a decision tree works, we use the dataset listed in Table 4.2[121].",
            "zh": "为了说明决策树是如何工作的，我们使用了表4.2[121]中列出的数据集。"
        }
    },
    {
        "translation": {
            "en": "19. The Cohen’s kappa statistic was first described in Cohen (1960). Using the Cohen’s kappa statistic, a value of 1.0 indicates total agreement, while a value of 0.0 indicates agreement no better than chance. Values around 0.6 are typically understood to indicate an acceptable level of agreement, although the exact nature of what is and is not acceptable is very task dependent.",
            "zh": "19. Cohen's kappa 统计量最早是在 Cohen （1960） 中描述的。使用 Cohen 的 kappa 统计量，值 1.0 表示完全一致，而值 0.0 表示一致性不比偶然性好。0.6 左右的值通常被理解为表示可接受的一致性水平，尽管可接受和不可接受的确切性质在很大程度上取决于任务。"
        }
    },
    {
        "translation": {
            "en": "Evaluation: Before models can be deployed for use within an organization, it is important that they are fully evaluated and proved to be fit for the purpose. This phase of CRISP-DM covers all the evaluation tasks required to show that a prediction model will be able to make accurate predictions after being deployed and that it does not suffer from overfitting or underfitting.",
            "zh": "评估：在部署模型以在组织内使用之前，必须对模型进行全面评估并证明它们适合该目的。CRISP-DM 的这一阶段涵盖了所有必要的评估任务，以表明预测模型在部署后能够做出准确的预测，并且不会受到过度拟合或欠拟合的影响。"
        }
    },
    {
        "translation": {
            "en": "5.4.5.3 Mahalanobis distance The final measure of similarity that we will introduce is the Mahalanobis distance, which is a metric that can be used to measure the similarity between instances with continuous descriptive features.",
            "zh": "5.4.5.3 马氏距离 我们将介绍的相似性的最后一个度量是马氏距离，这是一个可用于测量具有连续描述性特征的实例之间的相似性的度量。"
        }
    },
    {
        "translation": {
            "en": "Until recently, spirits have been very high in the lab due to the discovery earlier the previous year of a new form of electromagnetic radiation called N rays (Blondlot, 1903).",
            "zh": "直到最近，由于前一年早些时候发现了一种称为N射线的新形式的电磁辐射（Blondlot，1903），实验室中的精神一直非常高涨。"
        }
    },
    {
        "translation": {
            "en": "A confusion matrix for a naive Bayes model trained on a churn prediction problem.",
            "zh": "在流失预测问题上训练的朴素贝叶斯模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "It would be almost impossible to ask the full voting population their voting intentions before an actual election—after all, that is what the actual election is for—so polling companies take a sample.",
            "zh": "在实际选举之前，几乎不可能询问所有投票人口的投票意向——毕竟，这就是实际选举的目的——所以民意调查公司会抽取样本。"
        }
    },
    {
        "translation": {
            "en": "There are two standard approaches to creating ensembles: bagging and boosting. The remainder of this section explains each of these basic approaches. Commonly used, high-performing extensions to both of the basic approaches are also described: random forests in the case of bagging and gradient boosting in the case of boosting.",
            "zh": "创建合奏有两种标准方法：装袋和提升。本节的其余部分将介绍这些基本方法中的每一种。还描述了两种基本方法的常用高性能扩展：袋装情况下的随机森林和提升情况下的梯度提升。"
        }
    },
    {
        "translation": {
            "en": "In the rare event that the player is dealt two aces, giving a total of 22, they are awarded a TwentyTwo and win regardless of the cards dealt to the dealer.",
            "zh": "在极少数情况下，玩家被发了两张A，总共有22张A，无论发给庄家的牌如何，他们都会获得二十二张牌并获胜。"
        }
    },
    {
        "translation": {
            "en": "This chapter begins by establishing the fundamental setup of the reinforcement learning scenario and then describes temporal-difference learning, a common approach to reinforcement learning.",
            "zh": "本章首先建立强化学习场景的基本设置，然后介绍时间差异学习，这是一种常见的强化学习方法。"
        }
    },
    {
        "translation": {
            "en": "A good way to build multinomial logistic regression models is to use a set of one-versus-all models.19 If we have r target levels, we create r one-versus-all logistic regression models.",
            "zh": "构建多项式逻辑回归模型的一个好方法是使用一组 one-versus-all 模型.19 如果我们有 r 个目标水平，我们创建 r 个 1-vsus-all 逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "On subsequent attempts, surfers will slowly reduce their error by slightly adjusting their position until they home in on the sweet spot at which they can keep their board perfectly balanced to allow a seamless transition to tickling the face of an awesome toob!",
            "zh": "在随后的尝试中，冲浪者会通过稍微调整他们的位置来慢慢减少他们的错误，直到他们回到最佳位置，他们可以保持他们的冲浪板完美平衡，从而无缝过渡到挠痒痒的脸！"
        }
    },
    {
        "translation": {
            "en": "where the newly added categorical features allow the original ENERGY RATING feature to be included. Everything else about using such a model is exactly the same as before.",
            "zh": "其中，新添加的分类特征允许包含原始的 ENERGY RATING 特征。使用这种模型的其他一切都与以前完全相同。"
        }
    },
    {
        "translation": {
            "en": "A dataset showing the positions and monthly training expenses of a school basketball team.",
            "zh": "显示学校篮球队的位置和每月训练费用的数据集。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.7[547] illustrates the process of out-of-time sampling.",
            "zh": "图9.7[547]说明了超时采样的过程。"
        }
    },
    {
        "translation": {
            "en": "The configuration of receptive fields in Figure 8.33[484] uses a horizontal and vertical stride of 1; this means that as we move from one neuron to the next horizontally, the corresponding receptive fields also move by one column in the input space.",
            "zh": "图 8.33[484] 中感受野的配置使用水平和垂直步幅 1;这意味着当我们从一个神经元水平移动到下一个神经元时，相应的感受野也会在输入空间中移动一列。"
        }
    },
    {
        "translation": {
            "en": "There are a few points worth noting about the product rule. First, it defines the probability of a joint event P(X,Y) in terms of a conditional (or posterior) probability P(X | Y) multiplied by an unconditional (or prior) probability P(Y). Second, the order of the events in the product rule is not important, and we can condition the calculation on any of the events listed in the and (in logic, the and operation is symmetric):",
            "zh": "关于产品规则，有几点值得注意。首先，它根据条件（或后验）概率 P（X |Y） 乘以无条件（或先验）概率 P（Y）。其次，乘积规则中事件的顺序并不重要，我们可以根据 and 中列出的任何事件来计算（在逻辑中，and 运算是对称的）："
        }
    },
    {
        "translation": {
            "en": "This burn-in time is to allow the Markov chain to settle into a state that is independent of the initial random state and that is a probable state for the distribution we are sampling from.",
            "zh": "这个老化时间是为了让马尔可夫链进入一个独立于初始随机状态的状态，这个状态是我们正在采样的分布的可能状态。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.36",
            "zh": "图 8.36"
        }
    },
    {
        "translation": {
            "en": "5.4.1   Handling Noisy Data",
            "zh": "5.4.1 处理嘈杂数据"
        }
    },
    {
        "translation": {
            "en": "A taxonomy of models based on the parametric versus non-parametric and generative versus discriminative distinctions.",
            "zh": "基于参数与非参数以及生成与判别区别的模型分类。"
        }
    },
    {
        "translation": {
            "en": "The ROC index is quite robust in the presence of imbalanced data, which makes it a common choice for practitioners, especially when multiple modeling techniques are being compared to one another.",
            "zh": "在数据不平衡的情况下，ROC指数非常稳健，这使其成为从业者的常见选择，尤其是在将多种建模技术相互比较时。"
        }
    },
    {
        "translation": {
            "en": "[Application prediction] Data Requirements: Again, a historical collection of claims marked as fraudulent or non-fraudulent along with all relevant details would be required.",
            "zh": "[应用预测]数据要求：同样，需要提供标记为欺诈性或非欺诈性索赔的历史集合以及所有相关详细信息。"
        }
    },
    {
        "translation": {
            "en": "Before attempting to build predictive models based on an ABT, it is important that we undertake some exploratory analysis, or data exploration, of the data contained in the ABT.",
            "zh": "在尝试构建基于 ABT 的预测模型之前，我们必须对 ABT 中包含的数据进行一些探索性分析或数据探索。"
        }
    },
    {
        "translation": {
            "en": "As the algorithm proceeds, the model that it is building will become more and more fitted to the nuances of the training data.",
            "zh": "随着算法的进行，它正在构建的模型将越来越适合训练数据的细微差别。"
        }
    },
    {
        "translation": {
            "en": "3.3.4.3 Outliers From an examination of the minimum and maximum values for each continuous feature in Table 3.3(a)[57], CLAIM AMOUNT jumps out as having an unusual minimum value of − 99,999.",
            "zh": "3.3.4.3 异常值 通过对表3.3（a）[57]中每个连续特征的最小值和最大值的检查，CLAIM AMOUNT跳出为具有异常的最小值-99,999。"
        }
    },
    {
        "translation": {
            "en": "(a) Using this dataset, construct the decision tree that would be generated by the ID3 algorithm, using entropy-based information gain.",
            "zh": "（a） 使用该数据集，使用基于熵的信息增益构建由 ID3 算法生成的决策树。"
        }
    },
    {
        "translation": {
            "en": "To test a new medicine, doctors typically assemble a group of patients who suffer from the problem that the medicine is designed to address.",
            "zh": "为了测试一种新药，医生通常会召集一群患有该药物旨在解决的问题的患者。"
        }
    },
    {
        "translation": {
            "en": "We can find the point at which overfitting begins to happen by comparing the performance of a model at making predictions for instances in the training dataset used to build it versus its ability to make predictions for instances in a validation dataset as the training process continues.",
            "zh": "随着训练过程的继续，我们可以通过比较模型在用于构建模型的训练数据集中对实例进行预测的性能与其对验证数据集中的实例进行预测的能力来找到过拟合开始发生的点。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have focused on using the data quality report to explore the data in an ABT.",
            "zh": "在本章中，我们将重点介绍如何使用数据质量报告来探索 ABT 中的数据。"
        }
    },
    {
        "translation": {
            "en": "One thing about evaluating unsupervised machine learning approaches that is a little easier than the supervised case is that we can do it without the need to divide a dataset into training, testing, and validation partitions. Although techniques such as k-fold cross validation can be useful in using external criteria for evaluation, in using internal criteria for evaluation we typically just use all the data both for generating the clustering and evaluating the clustering.",
            "zh": "评估无监督机器学习方法比有监督情况容易一点的一件事是，我们可以做到这一点，而无需将数据集划分为训练、测试和验证分区。尽管 k 折叠交叉验证等技术在使用外部标准进行评估时很有用，但在使用内部标准进行评估时，我们通常只使用所有数据来生成聚类和评估聚类。"
        }
    },
    {
        "translation": {
            "en": "FN, 537",
            "zh": "FN，537"
        }
    },
    {
        "translation": {
            "en": "There are several different ways to smooth probabilities. We will use Laplace smoothing. Note, that in general, it does not make sense to smooth the unconditional (prior) probabilities for the different target feature levels,15 so here we will focus on smoothing the conditional probabilities for the features. Laplace smoothing for conditional probabilities is defined as",
            "zh": "有几种不同的方法可以平滑概率。我们将使用拉普拉斯平滑。请注意，一般来说，平滑不同目标特征级别的无条件（先验）概率是没有意义的，15 因此，在这里我们将重点关注平滑特征的条件概率。条件概率的拉普拉斯平滑定义为"
        }
    },
    {
        "translation": {
            "en": "4.2   An email spam prediction dataset.",
            "zh": "4.2 垃圾邮件预测数据集。"
        }
    },
    {
        "translation": {
            "en": "We will explain in more detail why we need non-linear activation functions in neurons in Section 8.2.4[394].",
            "zh": "我们将在第 8.2.4 节[394]中更详细地解释为什么我们需要神经元中的非线性激活函数。"
        }
    },
    {
        "translation": {
            "en": "By including the bias term in the set of weights along with a dummy descriptive feature, the function implemented by multiplying the weights by the extended descriptive features is now an affine function.",
            "zh": "通过将偏置项与虚拟描述性特征一起包含在权重集中，通过将权重乘以扩展的描述性特征来实现的函数现在是仿射函数。"
        }
    },
    {
        "translation": {
            "en": "Murphy, Kevin P. 2012. Machine learning: A probabilistic perspective. MIT Press.",
            "zh": "墨菲，凯文 P. 2012 年。机器学习：概率视角。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "Using a mixture of Gaussians distribution assumes that all the subpopulations in the data are distributed following a normal distribution, but that each of these subpopulation normal distributions has a different mean and may also have a different standard deviation.",
            "zh": "使用高斯分布的混合假定数据中的所有子种群都沿正态分布分布，但这些子种群中的每一个正态分布都具有不同的均值，并且也可能具有不同的标准差。"
        }
    },
    {
        "translation": {
            "en": "The ROC index can be calculated as",
            "zh": "ROC指数可以计算为："
        }
    },
    {
        "translation": {
            "en": "83,000",
            "zh": "83,000"
        }
    },
    {
        "translation": {
            "en": "0.1   How the notation used in the book relates to the elements of a dataset.",
            "zh": "0.1 本书中使用的符号与数据集元素的关系。"
        }
    },
    {
        "translation": {
            "en": "2. Does the person wear glasses?",
            "zh": "2. 这个人戴眼镜吗？"
        }
    },
    {
        "translation": {
            "en": "This model has been used to make predictions for the instances in the training set above. These predictions, and the related calculations required for calculating error and errorDelta values are shown in the following table.",
            "zh": "此模型已用于对上述训练集中的实例进行预测。下表显示了这些预测以及计算 error 和 errorDelta 值所需的相关计算。"
        }
    },
    {
        "translation": {
            "en": "APERFLUX7IVAR_U/G/R/I/Z",
            "zh": "APERFLUX7IVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Model Scoring",
            "zh": "模型评分"
        }
    },
    {
        "translation": {
            "en": "Each activation vector is augmented with a new first row (filled in black) containing the dummy descriptive feature d[0] = 1.",
            "zh": "每个激活向量都增加了一个新的第一行（用黑色填充），其中包含虚拟描述性特征 d[0] = 1。"
        }
    },
    {
        "translation": {
            "en": "Figure 14.2",
            "zh": "图 14.2"
        }
    },
    {
        "translation": {
            "en": "When matching machine learning approaches to the characteristics of a dataset, it is important to remember that almost every approach can be made to work for both continuous and categorical descriptive and target features.",
            "zh": "在将机器学习方法与数据集的特征相匹配时，重要的是要记住，几乎每种方法都可以用于连续和分类的描述性和目标特征。"
        }
    },
    {
        "translation": {
            "en": "margin of error, 751",
            "zh": "误差幅度，751"
        }
    },
    {
        "translation": {
            "en": "First, only about a quarter of the people who were surveyed responded to the survey (2.4 million out of 10 million).",
            "zh": "首先，只有大约四分之一的受访者对调查做出了回应（1000万人中有240万人）。"
        }
    },
    {
        "translation": {
            "en": "For example, the weights connected to neurons that are dropped for an example do not receive updates on that example.",
            "zh": "例如，连接到某个示例中丢弃的神经元的权重不会接收该示例的更新。"
        }
    },
    {
        "translation": {
            "en": "The cell state is then updated by adding the vector generated by the elementwise produce of the tanh and sigmoid activations.",
            "zh": "然后通过添加由 tanh 和 sigmoid 激活的元素产生的向量来更新细胞状态。"
        }
    },
    {
        "translation": {
            "en": "C.2   The Chain Rule",
            "zh": "C.2 连锁法则"
        }
    },
    {
        "translation": {
            "en": "Reinforcement learning approaches have been used in automated game playing since TD-Gammon (Tesauro, 1994) was developed in the 1990s.",
            "zh": "自 1990 年代开发 TD-Gammon （Tesauro， 1994） 以来，强化学习方法一直用于自动化游戏。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10(a)[201] illustrates the first stage of the retrieval of the nearest neighbor.",
            "zh": "图5.10（a）[201]说明了检索最近邻的第一阶段。"
        }
    },
    {
        "translation": {
            "en": "If we divided by n, we would have a biased estimator that on average underestimates the variance.",
            "zh": "如果我们除以 n，我们将得到一个有偏差的估计器，平均低估方差。"
        }
    },
    {
        "translation": {
            "en": "In Table 4.14[162] the column labeled 0(d) shows the predictions made by this model.",
            "zh": "在表4.14[162]中，标记为0（d）的列显示了该模型所做的预测。"
        }
    },
    {
        "translation": {
            "en": "(a) Discuss the different issues that should be taken into account when evaluating the suitability of different machine learning approaches for use in this system.",
            "zh": "（a） 讨论在评估不同机器学习方法是否适合用于该系统时应考虑的不同问题。"
        }
    },
    {
        "translation": {
            "en": "The MIT Press",
            "zh": "麻省理工学院出版社"
        }
    },
    {
        "translation": {
            "en": "Somewhat surprisingly, people seem to be able to easily do this on the basis of intuition.",
            "zh": "令人惊讶的是，人们似乎能够根据直觉轻松做到这一点。"
        }
    },
    {
        "translation": {
            "en": "Doctorow, Corey. 2010. Little brother. Macmillan.",
            "zh": "多克托罗，科里。2010. 小弟弟.麦克米伦。"
        }
    },
    {
        "translation": {
            "en": "It is relatively easy to adapt the k nearest neighbor approach to handle continuous target features. To do this we simply change the approach to return a prediction of the average target value of the nearest neighbors, rather than the majority target level. The prediction for a continuous target feature by a k nearest neighbor model is therefore",
            "zh": "采用k个最近邻方法处理连续目标特征相对容易。为此，我们只需更改方法以返回最近邻的平均目标值的预测，而不是大多数目标水平。因此，k个最近邻模型对连续目标特征的预测是"
        }
    },
    {
        "translation": {
            "en": "Note that here we use the notation hx⊺ to write the transpose of the vector hx; we use transpose of the vector to ensure that this matrix and vector product is defined. We can illustrate the process of calculating a weight update for the weights in W(f) by using the context provided by the forward pass example shown in Figure 8.41[514]. For the purposes of this example, we assume that the following error gradients are already calculated:",
            "zh": "请注意，这里我们使用符号 hx⊺ 来写向量 hx 的转置;我们使用向量的转置来确保定义此矩阵和向量乘积。我们可以使用图 8.41[514] 所示的前向传递示例提供的上下文来说明计算 W（f） 中权重更新的过程。在本例中，我们假设已经计算了以下误差梯度："
        }
    },
    {
        "translation": {
            "en": "For the email classification dataset shown in Table 9.1[537], the F 1 measure (again assuming that the spam level is the positive level) is calculated as",
            "zh": "对于表 9.1[537] 中所示的电子邮件分类数据集，F 1 度量（再次假设垃圾邮件级别为正级别）计算为"
        }
    },
    {
        "translation": {
            "en": "Chapter 9[533]",
            "zh": "第9章[533]"
        }
    },
    {
        "translation": {
            "en": "For example, we use the matrix representation to present elements of the worked example in Section 8.3.5[421], in which we step through the training of a feedforward neural network using backpropagation.",
            "zh": "例如，我们使用矩阵表示来呈现第 8.3.5 节[421] 中工作示例的元素，其中我们逐步完成了使用反向传播的前馈神经网络的训练。"
        }
    },
    {
        "translation": {
            "en": "In this case, there are maximum grayscale values (255) across the middle row of the neurons receptive field, and as a result of the interaction between this input pattern and the weights in Equation (8.85)[480], this neuron has a very large activation for this input.",
            "zh": "在这种情况下，神经元感受野的中间一排有最大的灰度值（255），并且由于该输入模式与方程（8.85）[480]中的权重之间的相互作用，该神经元对该输入具有非常大的激活。"
        }
    },
    {
        "translation": {
            "en": "If we change the data too much, then the models that we build will not relate well to the original data sources when we deploy them.",
            "zh": "如果我们对数据进行过多的更改，那么我们构建的模型在部署它们时将无法很好地与原始数据源相关联。"
        }
    },
    {
        "translation": {
            "en": "The state of the decision tree after the 𝒟7 partition has been split using STREAM.",
            "zh": "使用 STREAM 拆分 D7 分区后的决策树状态。"
        }
    },
    {
        "translation": {
            "en": "Obviously the computational costs associated with non-parametric models and large datasets cannot be ignored.",
            "zh": "显然，与非参数模型和大型数据集相关的计算成本不容忽视。"
        }
    },
    {
        "translation": {
            "en": "Details of the first two iterations when the gradient descent algorithm is used to train a multivariable linear regression model for the office rentals dataset (using only the continuous descriptive features).",
            "zh": "当梯度下降算法用于训练办公室租赁数据集的多变量线性回归模型（仅使用连续描述性特征）时，前两次迭代的详细信息。"
        }
    },
    {
        "translation": {
            "en": "prior probability, 251, 759",
            "zh": "先验概率，251,759"
        }
    },
    {
        "translation": {
            "en": "The idea of a control group might be familiar to readers from reading about medical trials.",
            "zh": "读者可能在阅读有关医学试验的文章时熟悉对照组的概念。"
        }
    },
    {
        "translation": {
            "en": "The important thing to notice about this decision surface, in contrast to the decision surface in Figure 7.11(b)[341], is that there is a gentle transition from predictions of the faulty target level to predictions of the good generator target level.",
            "zh": "与图7.11（b）[341]中的决策面相比，这个决策面需要注意的重要一点是，从对错误目标水平的预测到对良好生成器目标水平的预测有一个温和的过渡。"
        }
    },
    {
        "translation": {
            "en": "As with the simple two-event version, the order of events in the chain rule is not important.",
            "zh": "与简单的双事件版本一样，链式规则中事件的顺序并不重要。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.5[607] shows a selection of sets of initial centroids selected by the k-means process.",
            "zh": "图10.5[607]显示了通过k-means过程选择的一组初始质心。"
        }
    },
    {
        "translation": {
            "en": "Illustration of the organization of a set of neurons that share weights (use the same filter) and their local receptive fields such that together the receptive fields cover the entirety of the input image.",
            "zh": "一组神经元的组织图示，这些神经元共享权重（使用相同的过滤器）及其局部感受野，使得感受野一起覆盖整个输入图像。"
        }
    },
    {
        "translation": {
            "en": "Table 9.17",
            "zh": "表 9.17"
        }
    },
    {
        "translation": {
            "en": "padding, 487",
            "zh": "填充物， 487"
        }
    },
    {
        "translation": {
            "en": "10.5   Distance matrices that detail the first three iterations of the AHC algorithm applied to the reduced version of the mobile phone customer dataset in Table 10.1[604].",
            "zh": "10.5 距离矩阵，详细说明了应用于表10.1[604]中移动电话客户数据集的简化版本的AHC算法的前三次迭代。"
        }
    },
    {
        "translation": {
            "en": "The information gain of the SUSPICIOUS WORDS feature is 1 bit.",
            "zh": "SUSPICIOUS WORDS 功能的信息增益为 1 位。"
        }
    },
    {
        "translation": {
            "en": "Sometimes patients are readmitted for a recurrence of the same problem for which they were originally hospitalized, but at other times readmission is for different problems.",
            "zh": "有时，患者因最初住院的相同问题复发而再次入院，但在其他时候，再次入院是针对不同的问题。"
        }
    },
    {
        "translation": {
            "en": "On the basis of the action it has taken, the agent now makes an update to Q(0-3,left) (Line 13[658]) using Equation (13)[658].",
            "zh": "根据它所采取的行动，代理现在使用公式 （13）[658] 对 Q（0-3，left）（第 13 行 [658]） 进行更新。"
        }
    },
    {
        "translation": {
            "en": "Count",
            "zh": "计数"
        }
    },
    {
        "translation": {
            "en": "As a result, convolutional networks can learn to identify, extract, and use multiple different features in the input.",
            "zh": "因此，卷积网络可以学习识别、提取和使用输入中的多个不同特征。"
        }
    },
    {
        "translation": {
            "en": "Le Cun, Yann, Léon Bottou, Yoshua Bengio, and Haffner Patrick. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86 (11): 2278–2324.",
            "zh": "Le Cun、Yann、Léon Bottou、Yoshua Bengio 和 Haffner Patrick。1998. 基于梯度的学习在文档识别中的应用.IEEE 会议记录 86 （11）：2278–2324。"
        }
    },
    {
        "translation": {
            "en": "We can see that increasing office size leads to increasing rental prices; that lower building floors lead to higher rental prices; and that rental prices increase with broadband rates.",
            "zh": "我们可以看到，办公室规模的增加导致租金价格上涨;较低的建筑楼层导致更高的租金价格;租金价格随着宽带费率的增加而增加。"
        }
    },
    {
        "translation": {
            "en": "So when calculating the overall majority vote across the k nearest neighbors, the votes of the neighbors that are close to the query get a lot of weight, and the votes of the neighbors that are farther away from the query get less weight.",
            "zh": "因此，在计算 k 个最近邻域的总体多数票数时，靠近查询的邻域的投票权重较大，而距离查询较远的邻域的投票权重较小。"
        }
    },
    {
        "translation": {
            "en": "Although it makes sense to do it, the rewards do not have to be so closely tied to the winnings within the game, and different reward structures could be designed to encourage different playing strategies—for example, more conservative or more aggressive play.",
            "zh": "虽然这样做是有道理的，但奖励不必与游戏中的奖金密切相关，并且可以设计不同的奖励结构来鼓励不同的游戏策略——例如，更保守或更激进的游戏。"
        }
    },
    {
        "translation": {
            "en": "and decreases the weights for the instances correctly classified by the model using30",
            "zh": "并降低模型正确分类的实例的权重 using 30"
        }
    },
    {
        "translation": {
            "en": "She did, however, explain to Edwin that because the categorization of galaxy morphologies is a somewhat subjective task (even human experts don’t always fully agree on the category that a night sky object should belong to), it was unlikely that classification accuracies beyond 90% would be achievable.",
            "zh": "然而，她确实向埃德温解释说，由于星系形态的分类是一项有点主观的任务（即使是人类专家也并不总是完全同意夜空物体应该属于哪个类别），因此不太可能实现超过90%的分类精度。"
        }
    },
    {
        "translation": {
            "en": "Including a ratio between two values can often be much more powerful in a predictive model than including the two values themselves.",
            "zh": "在预测模型中，包含两个值之间的比率通常比包含两个值本身要强大得多。"
        }
    },
    {
        "translation": {
            "en": "The height of the density curve defined by a PDF at a particular feature value gives us this, so we can avoid the effort of calculating the actual probability.",
            "zh": "PDF 在特定特征值下定义的密度曲线的高度为我们提供了这一点，因此我们可以避免计算实际概率的工作量。"
        }
    },
    {
        "translation": {
            "en": "6. The following image illustrates the topology of a feedforward neural network that has two sensing neurons (Neurons 1 and 2), two hidden processing neuron (Neurons 3, and 4), and two processing output neurons (Neurons 5 and 6).",
            "zh": "6. 下图说明了前馈神经网络的拓扑结构，该神经网络具有两个感知神经元（神经元 1 和 2）、两个隐藏处理神经元（神经元 3 和 4）和两个处理输出神经元（神经元 5 和 6）。"
        }
    },
    {
        "translation": {
            "en": "Similarly, the first row in the Activations Hidden Layer 1 matrix contains the activations for Neuron 3 (a3) for the d1, d2, d3, and d4, respectively.",
            "zh": "同样，激活隐藏层 1 矩阵中的第一行分别包含 d1、d2、d3 和 d4 的神经元 3 （a3） 激活。"
        }
    },
    {
        "translation": {
            "en": "where ai is a specific value of feature a, and lower and upper are the lower and upper thresholds.",
            "zh": "其中 AI 是要素 A 的特定值，下限和上限是阈值的下限和上限。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.95)[491] illustrates an extended version of the convolutional network that would implement the data processing illustrated in Equation (8.94)[490].",
            "zh": "等式（8.95）[491]说明了卷积网络的扩展版本，该版本将实现等式（8.94）[490]中所示的数据处理。"
        }
    },
    {
        "translation": {
            "en": "Second, within any small region or neighborhood of the feature space, real data tends to manifest a smooth correlation between changes in descriptive feature values and the values of the target feature.",
            "zh": "其次，在特征空间的任何小区域或邻域内，真实数据往往会表现出描述性特征值的变化与目标特征值之间的平滑相关性。"
        }
    },
    {
        "translation": {
            "en": "It was shown after two months that the churn rate within the sample for which the retention team used the new model to build their call list was approximately 7.4%, while for the group using the old model, it was over 10%.",
            "zh": "两个月后显示，保留团队使用新模型构建呼叫列表的样本中的流失率约为 7.4%，而使用旧模型的组的流失率超过 10%。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix resulting from this test is shown in Table 13.11[726].",
            "zh": "该测试产生的混淆矩阵如表13.11[726]所示。"
        }
    },
    {
        "translation": {
            "en": "Figure C.3",
            "zh": "图 C.3"
        }
    },
    {
        "translation": {
            "en": "6. Famously, an experiment in which doctors were asked this question about the probability of the patient’s having the disease showed that most of them got this question wrong (Casscells et al., 1978).",
            "zh": "6. 著名的是，一项实验中，医生被问到关于患者患病概率的问题，结果显示他们中的大多数人都弄错了这个问题（Casscells 等人，1978 年）。"
        }
    },
    {
        "translation": {
            "en": "For example, if we were building a model to predict the outcomes of soccer matches, we might consider including the attendance at the match as a descriptive feature.",
            "zh": "例如，如果我们要建立一个模型来预测足球比赛的结果，我们可能会考虑将比赛的出席率作为描述性特征。"
        }
    },
    {
        "translation": {
            "en": "weighted variance, 149",
            "zh": "加权方差，149"
        }
    },
    {
        "translation": {
            "en": "7.2.1 Simple Linear Regression",
            "zh": "7.2.1 简单线性回归"
        }
    },
    {
        "translation": {
            "en": "The brute-force search approach that was mentioned in Section 7.2.3[317] is not feasible either—especially as the number of descriptive features, and subsequently the number of weights, increases.",
            "zh": "第7.2.3节[317]中提到的暴力搜索方法也不可行，特别是随着描述性特征的数量以及随之而来的权重数量的增加。"
        }
    },
    {
        "translation": {
            "en": "Similar to the logistic function, the rectifier function saturates in part of its domain, and this can lead to a dying ReLU dynamic in which a unit does not activate for any of the training instances, and consequently the neuron is stuck in a dead non-active state.",
            "zh": "与逻辑函数类似，整流器函数在其部分域中饱和，这可能导致垂死的 ReLU 动态，其中单元不会为任何训练实例激活，因此神经元陷入死非活动状态。"
        }
    },
    {
        "translation": {
            "en": "In this section we describe Bayes’ Theorem and the important fundamentals of probability theory that are required to use it.",
            "zh": "在本节中，我们将介绍贝叶斯定理以及使用它所需的概率论的重要基础知识。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the processing neurons use a rectifier activation functions, that the input to the network is Neuron 1 = 0.3 and Neuron 2 = 0.6 and that the desired output for this input is Neuron 5 = 0.7 and Neuron 6 = 0.4:",
            "zh": "（b） 假设处理神经元使用整流器激活函数，网络的输入是神经元 1 = 0.3 和神经元 2 = 0.6，并且该输入的所需输出是神经元 5 = 0.7 和神经元 6 = 0.4："
        }
    },
    {
        "translation": {
            "en": "The learning approaches described in this chapter are value-based and model-free.",
            "zh": "本章中描述的学习方法是基于值且无模型的。"
        }
    },
    {
        "translation": {
            "en": "Chen, Tianqi, and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 785–794. ACM.",
            "zh": "陈天琪和卡洛斯·盖斯特林。2016. Xgboost：可扩展的树提升系统。在第 22 届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集中，785–794。ACM。"
        }
    },
    {
        "translation": {
            "en": "6. This is almost identical to the definition of Shannon’s entropy model given in Equation (4.1)[125]. We have extended the definition to include an explicit parameter for the dataset 𝒟 for which we are computing the entropy, and we have specified the base as 2.",
            "zh": "6. 这与方程（4.1）[125]中给出的香农熵模型的定义几乎相同。我们扩展了定义，以包含我们正在计算熵的数据集 D 的显式参数，并将基数指定为 2。"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are essentially a composition of a set of local models (recall our discussion on Voronoi tessellation) with the predictions made being a function of the target feature value of the instance in the dataset closest to the query.",
            "zh": "最近邻模型本质上是一组局部模型的组合（回想一下我们对 Voronoi 曲面细分的讨论），其预测是最接近查询的数据集中实例的目标特征值的函数。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, there is no guarantee that this instance will be the nearest neighbor, although it should be a good approximate neighbor for the query.",
            "zh": "遗憾的是，不能保证此实例将是最近邻，尽管它应该是查询的良好近似邻域。"
        }
    },
    {
        "translation": {
            "en": "Osowski, Stainslaw, Linh Tran Hoai, and T. Markiewicz. 2004. Support vector machine-based expert system for reliable heartbeat recognition. IEEE Transactions on Biomedical Engineering 51 (4): 582–589. doi:10.1109/TBME.2004.824138.",
            "zh": "Osowski、Stainslaw、Linh Tran Hoai 和 T. Markiewicz。2004. 支持基于矢量机的专家系统，实现可靠的心跳识别。IEEE生物医学工程学报51（4）：582–589。doi：10.1109/TBME.2004.824138."
        }
    },
    {
        "translation": {
            "en": "timing, 33",
            "zh": "时机，33"
        }
    },
    {
        "translation": {
            "en": "In some cases we might even remove a complete instance from a dataset based on the presence of an outlier.",
            "zh": "在某些情况下，我们甚至可能会根据异常值的存在从数据集中删除一个完整的实例。"
        }
    },
    {
        "translation": {
            "en": "10.4.3 Choosing the Number of Clusters",
            "zh": "10.4.3 选择集群数量"
        }
    },
    {
        "translation": {
            "en": "(c) Do you think that the model that you rejected in Part (a) of this question is overfitting or underfitting the data?",
            "zh": "（c） 你认为你在本问题（a）部分拒绝的模型是否对数据过度拟合或欠拟合？"
        }
    },
    {
        "translation": {
            "en": "The tanh activation function outputs values in the range [−1,+1].",
            "zh": "tanh 激活函数输出 [−1，+1] 范围内的值。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.13",
            "zh": "图 7.13"
        }
    },
    {
        "translation": {
            "en": "4.8   Dataset for predicting the vegetation in an area with a continuous ELEVATION feature (measured in feet).",
            "zh": "4.8 用于预测具有连续高程特征（以英尺为单位）的区域中的植被的数据集。"
        }
    },
    {
        "translation": {
            "en": "Cats don’t like storms either, and if there is a storm, they like to go inside.",
            "zh": "猫也不喜欢暴风雨，如果有暴风雨，它们喜欢进去。"
        }
    },
    {
        "translation": {
            "en": "However, an image processing system should be able to detect whether a visual feature occurs in an image irrespective of where in the image it occurs.",
            "zh": "但是，图像处理系统应该能够检测图像中是否出现视觉特征，而不管它出现在图像中的哪个位置。"
        }
    },
    {
        "translation": {
            "en": "Kohavi, Ron. 1996. Scaling up the accuracy of Naive-Bayes classifiers: A decision-tree hybrid. In Proceedings of the twenty-fifth ACM SIGKDD international conference on knowledge discovery and data mining KDD, 202–207.",
            "zh": "科哈维，罗恩。1996. 提高朴素贝叶斯分类器的准确性：决策树混合体。在第二十五届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集 KDD 中，202–207。"
        }
    },
    {
        "translation": {
            "en": "A.4.1 Bar Plots",
            "zh": "A.4.1 条形图"
        }
    },
    {
        "translation": {
            "en": "There are contexts, however, in which the focus of a course is not primarily on machine learning.",
            "zh": "然而，在某些情况下，课程的重点并不主要放在机器学习上。"
        }
    },
    {
        "translation": {
            "en": "Recall that the naive Bayes domain representation defines a conditional probability for each possible value in the domain of a descriptive feature for each level in the domain of the target.",
            "zh": "回想一下，朴素贝叶斯域表示为目标域中每个级别的描述性特征域中的每个可能值定义了一个条件概率。"
        }
    },
    {
        "translation": {
            "en": "Using Equation (8.67)[466] we can now calculate a loss for the network’s predictions over a set of exclusive categories.",
            "zh": "使用等式（8.67）[466]，我们现在可以计算一组排他性类别的网络预测的损失。"
        }
    },
    {
        "translation": {
            "en": "preference bias, 11",
            "zh": "偏好偏差，11"
        }
    },
    {
        "translation": {
            "en": "The vertical bar symbol can be read as given that.",
            "zh": "垂直条符号可以这样理解。"
        }
    },
    {
        "translation": {
            "en": "For example, DEVAB_R had a range as small as [0.05,1.00] while APERFLUX7IVAR_U had a range as large as [−265,862,15,274].",
            "zh": "例如，DEVAB_R 的范围小至 [0.05,1.00]，而APERFLUX7IVAR_U的范围大至 [−265,862,15,274]。"
        }
    },
    {
        "translation": {
            "en": "In the European Union the 1999 Treaty of Amsterdam6 prohibits discrimination on the basis of sex, racial or ethnic origin, religion or belief, disability, age, or sexual orientation.",
            "zh": "在欧洲联盟，1999年《阿姆斯特丹条约》6 禁止基于性别、种族或族裔、宗教或信仰、残疾、年龄或性取向的歧视。"
        }
    },
    {
        "translation": {
            "en": "Finally, the set shown in Figure 4.5(f)[124] has a large number of card types, each represented only once, which leads to the high entropy value of 3.58 bits.",
            "zh": "最后，图4.5（f）[124]所示的集合具有大量的卡类型，每种卡类型仅表示一次，这导致了3.58位的高熵值。"
        }
    },
    {
        "translation": {
            "en": "In many ways, the easy part of a predictive data analytics project is building the models.",
            "zh": "在许多方面，预测数据分析项目的简单部分是构建模型。"
        }
    },
    {
        "translation": {
            "en": "Outliers identified in this way are likely to be invalid outliers and should immediately be either corrected, if data sources allow this, or removed and marked as missing values if correction is not possible.",
            "zh": "以这种方式识别的异常值很可能是无效的异常值，如果数据源允许，应立即更正，如果无法更正，则应将其删除并标记为缺失值。"
        }
    },
    {
        "translation": {
            "en": "Table A.3",
            "zh": "表 A.3"
        }
    },
    {
        "translation": {
            "en": "6   Probability-Based Learning",
            "zh": "6 基于概率的学习"
        }
    },
    {
        "translation": {
            "en": "A data quality report includes tabular reports (one for continuous features and one for categorical features) that describe the characteristics of each feature in an ABT using standard statistical measures of central tendency and variation.",
            "zh": "数据质量报告包括表格报告（一个用于连续特征，一个用于分类特征），这些报告使用集中趋势和变异的标准统计度量来描述 ABT 中每个特征的特征。"
        }
    },
    {
        "translation": {
            "en": "The activation for Neuron B, however, was the maximum value for the local receptive field the neuron is in, and so the δ value for Neuron B is calculated as shown in Equation (8.97)[492].",
            "zh": "然而，神经元B的激活是神经元所在局部感受野的最大值，因此神经元B的δ值计算如公式（8.97）[492]所示。"
        }
    },
    {
        "translation": {
            "en": "In contrast, discriminative models learn the boundary between classes rather than the characteristics of the distributions of the different classes.",
            "zh": "相反，判别模型学习类之间的边界，而不是不同类分布的特征。"
        }
    },
    {
        "translation": {
            "en": "There are, however, alternatives to k-d trees.",
            "zh": "但是，k-d 树还有其他选择。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the error, ε, associated with the set of predictions made by the model 𝕄4 given in the table above.",
            "zh": "（a） 计算与上表中给出的模型M4所作的一组预测相关的误差ε。"
        }
    },
    {
        "translation": {
            "en": "A few key data manipulation operations are frequently used to calculate derived feature values: joining data sources, filtering rows in a data source, filtering fields in a data source, deriving new features by combining or transforming existing features, and aggregating data sources. Data manipulation operations are implemented in and performed by database management systems, data management tools, or data manipulation tools, and are often referred to as an extract-transform-load (ETL) process.",
            "zh": "一些关键的数据操作操作经常用于计算派生要素值：联接数据源、筛选数据源中的行、筛选数据源中的字段、通过组合或转换现有要素来派生新要素以及聚合数据源。数据操作在数据库管理系统、数据管理工具或数据操作工具中实现并由数据库操作工具执行，通常称为提取-转换-加载 （ETL） 过程。"
        }
    },
    {
        "translation": {
            "en": "Consequently, there are fewer output activations from a sub-sampling layer than there are inputs: one output per local receptive field and multiple inputs per field.",
            "zh": "因此，子采样层的输出激活少于输入：每个局部感受野一个输出，每个场多个输入。"
        }
    },
    {
        "translation": {
            "en": "experience replay, 671",
            "zh": "体验回放，671"
        }
    },
    {
        "translation": {
            "en": "In mathematics, the process of passing a function over a sequence of values is known as convolving a function, and by analogy a set of neurons that share a filter (and thereby each implements the same function) and that are organized such that together their receptive fields cover the input are convolving a function over the input.42",
            "zh": "在数学中，将函数传递到一系列值上的过程称为卷积函数，以此类推，一组神经元共享一个滤波器（因此每个神经元都实现相同的函数），并且它们的组织方式使它们的感受野一起覆盖输入，在输入上卷积一个函数42。"
        }
    },
    {
        "translation": {
            "en": "By doing this, we relax the requirement that, to avoid probabilities of zero, all the evidence events must hold in at least one instance for each value in the domain of the target.",
            "zh": "通过这样做，我们放宽了以下要求：为了避免概率为零，所有证据事件必须至少保存在一个实例中，用于目标域中的每个值。"
        }
    },
    {
        "translation": {
            "en": "There is the potential for features to go stale if something about the environment from which they are generated changes.",
            "zh": "如果生成功能的环境发生变化，则功能可能会过时。"
        }
    },
    {
        "translation": {
            "en": "The best advice we can give is that, based on empirical evidence, choosing random initial weights uniformly from the range [−0.2, 0.2] tends to work well.",
            "zh": "我们能给出的最好的建议是，根据经验证据，从[−0.2,0.2]范围内均匀选择随机初始权重往往效果很好。"
        }
    },
    {
        "translation": {
            "en": "4.10   The state of the decision tree after the 𝒟2 partition has been split using SLOPE.",
            "zh": "4.10 使用 SLOPE 拆分 D2 分区后的决策树状态。"
        }
    },
    {
        "translation": {
            "en": "Remember that each stratum will contain a different number of instances, so by sampling on a percentage basis from each stratum, the number of instances taken from each stratum will be proportional to the number of instances in each stratum.",
            "zh": "请记住，每个层将包含不同数量的实例，因此通过按百分比从每个层抽样，从每个层中获取的实例数将与每个层中的实例数成正比。"
        }
    },
    {
        "translation": {
            "en": "Two different Bayesian networks, each defining the same full joint probability distribution.",
            "zh": "两个不同的贝叶斯网络，每个网络都定义了相同的全联合概率分布。"
        }
    },
    {
        "translation": {
            "en": "We first use only the extra ACCOUNT BALANCE feature in the dataset (ignoring LOAN AMOUNT, which we return to later in this chapter) to demonstrate how PDFs allow us to include continuous features in a naive Bayes model.",
            "zh": "我们首先在数据集中仅使用额外的 ACCOUNT BALANCE 特征（忽略 LOAN AMOUNT，我们将在本章后面返回）来演示 PDF 如何允许我们在朴素贝叶斯模型中包含连续特征。"
        }
    },
    {
        "translation": {
            "en": "A bar plot includes a vertical bar for each level of a categorical feature.",
            "zh": "条形图包括用于分类要素的每个级别的垂直条形图。"
        }
    },
    {
        "translation": {
            "en": "In the next iteration of the AHC algorithm the distance between this new cluster and all other clusters is calculated.",
            "zh": "在 AHC 算法的下一次迭代中，将计算此新集群与所有其他集群之间的距离。"
        }
    },
    {
        "translation": {
            "en": "The δs for each of the neurons in the network for Example 2.",
            "zh": "示例 2 中网络中每个神经元的 δ。"
        }
    },
    {
        "translation": {
            "en": "Chapter 9 explains how to evaluate the performance of prediction models and presents a range of different evaluation metrics.",
            "zh": "第9章解释了如何评估预测模型的性能，并提出了一系列不同的评估指标。"
        }
    },
    {
        "translation": {
            "en": "As a second example, in Chapter 4[117] we introduce the Iterative Dichotomizer 3 (ID3) machine learning algorithm, which uses a restriction bias of considering only tree prediction models in which each branch encodes a sequence of checks on individual descriptive features but also uses a preference bias by considering shallower (less complex) trees over larger trees.",
            "zh": "作为第二个例子，在第 4 章[117]中，我们介绍了迭代二分法器 3 （ID3） 机器学习算法，该算法使用仅考虑树预测模型的限制偏差，其中每个分支对单个描述性特征的检查序列进行编码，但也通过考虑较浅（不太复杂）的树而不是较大的树来使用偏好偏差。"
        }
    },
    {
        "translation": {
            "en": "Even in cases where one of the target levels is very rare, it may not be appropriate to smooth the target level priors.",
            "zh": "即使在其中一个目标水平非常罕见的情况下，平滑目标水平先验也可能不合适。"
        }
    },
    {
        "translation": {
            "en": "Sarle, Warren S. 1983. Cubic clustering criterion, Technical Report SAS Technical Report A-108, SAS Institute.",
            "zh": "萨尔，沃伦 S. 1983 年。立方聚类准则，SAS技术报告A-108技术报告，SAS研究所。"
        }
    },
    {
        "translation": {
            "en": "Whenever the target one-hot encoding is a 0, we use Equation (8.81)[469] to calculate the δ; and whenever it is a 1, we use Equation (8.80)[469] to calculate the δ.",
            "zh": "每当目标单热编码为 0 时，我们使用公式 （8.81）[469] 来计算δ;每当它是 1 时，我们使用方程 （8.80）[469] 来计算δ。"
        }
    },
    {
        "translation": {
            "en": "Information-based machine learning algorithms use the same idea.",
            "zh": "基于信息的机器学习算法使用相同的思路。"
        }
    },
    {
        "translation": {
            "en": "Second, in the context of predicting categorical targets, supervised machine learning creates models that distinguish between the target levels that are present in the dataset from which they are induced.",
            "zh": "其次，在预测分类目标的背景下，监督机器学习创建模型，以区分诱导目标的数据集中存在的目标水平。"
        }
    },
    {
        "translation": {
            "en": "37.11°C",
            "zh": "37.11°摄氏度"
        }
    },
    {
        "translation": {
            "en": "A Bayesian network is a directed acyclical graph (there are no cycles in the graph) that is composed of three basic elements:",
            "zh": "贝叶斯网络是一个有向非循环图（图中没有循环），由三个基本元素组成："
        }
    },
    {
        "translation": {
            "en": "receiver operating characteristic space, 559",
            "zh": "接收机工作特性空间，559"
        }
    },
    {
        "translation": {
            "en": "As indicated by the third item in the list above, there is more to evaluation than measuring model performance. For a model to be successfully deployed, we must consider issues like how quickly the model makes predictions, how easy it easy for human analysts to understand the predictions made by a model, and how easy it is to retrain a model should it go stale over time. We return to these issues in the final section of this chapter.",
            "zh": "如上表第三项所示，评估不仅仅是衡量模型性能。为了成功部署模型，我们必须考虑模型做出预测的速度，人类分析师理解模型所做的预测的难易程度，以及如果模型随着时间的推移而过时，重新训练模型的难易程度。我们将在本章的最后一节中回到这些问题。"
        }
    },
    {
        "translation": {
            "en": "All are correct, although they focus on different characteristics of the letter magnets—color, case, and character.",
            "zh": "所有这些都是正确的，尽管它们侧重于字母磁铁的不同特征——颜色、外壳和字符。"
        }
    },
    {
        "translation": {
            "en": "5.2.2 Measuring Similarity Using Distance Metrics",
            "zh": "5.2.2 使用距离指标衡量相似性"
        }
    },
    {
        "translation": {
            "en": "In a mobile phone scenario, we might include three ratio features to indicate the mix between voice, data, and SMS services that a customer uses.",
            "zh": "在移动电话场景中，我们可能包括三个比率特征，以指示客户使用的语音、数据和短信服务之间的组合。"
        }
    },
    {
        "translation": {
            "en": "Because this vector of activations from the hidden layer is passed on to another layer for processing, it has to be augmented with the dummy feature d[0] = 1; this is represented by the label on the arrow linking the top row of operations with the bottom row.",
            "zh": "由于隐藏层的激活向量被传递到另一层进行处理，因此必须使用虚拟特征 d[0] = 1 对其进行增强;这由箭头上的标签表示，该标签将操作的顶行与底行连接起来。"
        }
    },
    {
        "translation": {
            "en": "product rule, 245, 249, 757, 762",
            "zh": "产品规则， 245， 249， 757， 762"
        }
    },
    {
        "translation": {
            "en": "We use the symbol δ to indicate the rate of change of the error of the network with respect to changes in the weighted sum calculated in a neuron.",
            "zh": "我们使用符号 δ 来表示网络误差相对于神经元中计算的加权和的变化率。"
        }
    },
    {
        "translation": {
            "en": "The machine learning algorithms tell us how to do this.",
            "zh": "机器学习算法告诉我们如何做到这一点。"
        }
    },
    {
        "translation": {
            "en": "3. Symmetry: metric(a,b) = metric(b,a)",
            "zh": "3. 对称性：metric（a，b） = metric（b，a）"
        }
    },
    {
        "translation": {
            "en": "Machine Learning for Predictive Data Analytics",
            "zh": "用于预测数据分析的机器学习"
        }
    },
    {
        "translation": {
            "en": "A simple grid world. The start position is annotated with an S and the goal with a G. The squares marked f denote fire, which is very damaging to an agent.",
            "zh": "一个简单的网格世界。起始位置用 S 标注，目标用 G 标注。标有 f 的方块表示火，这对特工的伤害非常大。"
        }
    },
    {
        "translation": {
            "en": "Zhou, Zhi-Hua. 2012. Ensemble methods: Foundations and algorithms. CRC Press.",
            "zh": "周， 华.2012. 集成方法：基础和算法.CRC出版社。"
        }
    },
    {
        "translation": {
            "en": "curse of dimensionality, 225, 232, 255, 262, 740, 762",
            "zh": "维度诅咒，225,232,255,262,740,762"
        }
    },
    {
        "translation": {
            "en": "Euler’s number, 342, 580",
            "zh": "欧拉数，342,580"
        }
    },
    {
        "translation": {
            "en": "Although there is a mixture in each of these sets, however, it seems to be the case that when UNKNOWN SENDER = true, the majority of emails are spam, and when UNKNOWN SENDER = false, the majority of emails are ham.",
            "zh": "然而，尽管这些集合中的每一个都存在混合，但似乎情况是，当 UNKNOWN SENDER = true 时，大多数电子邮件都是垃圾邮件，而当 UNKNOWN SENDER = false 时，大多数电子邮件都是 ham。"
        }
    },
    {
        "translation": {
            "en": "In the first iteration of the algorithm a dataset is sampled using this distribution, and the number of times each training instance is included in this sample is given in the Freq.",
            "zh": "在算法的第一次迭代中，使用此分布对数据集进行采样，并且每个训练实例包含在此样本中的次数在频率中给出。"
        }
    },
    {
        "translation": {
            "en": "In general, we recommend the use of complete case analysis only to remove instances that are missing the value of the target feature.",
            "zh": "通常，我们建议仅使用完整的案例分析来删除缺少目标特征值的实例。"
        }
    },
    {
        "translation": {
            "en": "2. The table below shows the policy type held by customers at a life insurance company.",
            "zh": "2. 下表显示客户在人寿保险公司持有的保单类型。"
        }
    },
    {
        "translation": {
            "en": "5.15   Scatter plots of three bivariate datasets with the same center point A and two queries B and C both equidistant from A; (a) a dataset uniformly spread around the center point; (b) a dataset with negative covariance; and (c) a dataset with positive covariance.",
            "zh": "5.15 中心点相同A的三个二元数据集的散点图，以及两个查询B和C都与A等距;（a） 均匀分布在中心点周围的数据集;（b） 具有负协方差的数据集;（c）具有正协方差的数据集。"
        }
    },
    {
        "translation": {
            "en": "This matrix multiplication generates the weighted sums for all neurons in the layer for all the examples in the mini-batch and stores the results in the matrix Z(l).",
            "zh": "此矩阵乘法为小批量中的所有示例生成层中所有神经元的加权和，并将结果存储在矩阵 Z（l） 中。"
        }
    },
    {
        "translation": {
            "en": "The fact that the tanh function has a range of [−1,+1] means that activations in the cell state can be both increased and decreased at each time-step.",
            "zh": "tanh 函数的范围为 [−1，+1] 这一事实意味着细胞状态的激活可以在每个时间步长增加和减少。"
        }
    },
    {
        "translation": {
            "en": "The heights of the players in this second team vary much more than those of the first team (see Figures A.1[746] and A.3[747]).",
            "zh": "第二支球队的球员身高变化比第一支球队大得多（见图A.1[746]和A.3[747]）。"
        }
    },
    {
        "translation": {
            "en": "This process of apportioning blame for the δs in one layer back to the neurons in the preceding layer and then summing the blame for each neuron in the preceding layer to calculate its δ is repeated until all the neurons in the first hidden layer of the network have a δ term.",
            "zh": "重复这一过程，将一层中 δ 的归咎分摊给前一层的神经元，然后将前一层中每个神经元的归咎相加以计算其δ，直到网络第一隐藏层中的所有神经元都具有δ项。"
        }
    },
    {
        "translation": {
            "en": "Equation (6.17)[286] can be generalized to the statement that for any network with N nodes, the probability of an event x1,…,xn, can be computed using the following formula:",
            "zh": "方程（6.17）[286]可以推广为以下语句：对于任何具有N个节点的网络，事件x1,...,xn的概率可以使用以下公式计算："
        }
    },
    {
        "translation": {
            "en": "4.14   A simple bicycle demand predictions dataset and the workings of the first three iterations of training an ensemble model using boosting to predict RENTALS given TEMP.",
            "zh": "4.14 一个简单的自行车需求预测数据集和训练集成模型的前三个迭代的工作原理，使用提升来预测给定温度的租赁。"
        }
    },
    {
        "translation": {
            "en": "where ps is a prediction score value, CP(positive, ps) is the cumulative probability distribution of positive value scores, and CP(negative, ps) is the cumulative probability distribution of negative value scores.",
            "zh": "其中 ps 是预测分数值，CP（positive， ps） 是正值分数的累积概率分布，CP（negative， ps） 是负值分数的累积概率分布。"
        }
    },
    {
        "translation": {
            "en": "The CPT associated with each node defines the probabilities of each feature taking a value given the value(s) of its parent node(s).",
            "zh": "与每个节点关联的 CPT 定义每个特征的概率，给定其父节点的值。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming the random forest model you have created uses majority voting, what prediction will it return for the following query:",
            "zh": "（b） 假设您创建的随机森林模型使用多数投票，它将为以下查询返回什么预测："
        }
    },
    {
        "translation": {
            "en": "Figure 10.1[598] shows how the three Murphy children organized the letters on the fridge.",
            "zh": "图10.1[598]显示了墨菲的三个孩子是如何整理冰箱上的信件的。"
        }
    },
    {
        "translation": {
            "en": "4. The log of a to the base b, written as logb(a), is the number to which we must raise b to get a. For example, log2(8) = 3 because 23 = 8 and log5(625) = 4 because 54 = 625.",
            "zh": "4. a 到基数 b 的对数，写成 logb（a），是我们必须将 b 提高到的数字才能得到 a。例如，log2（8） = 3 是因为 23 = 8，log5（625） = 4 是因为 54 = 625。"
        }
    },
    {
        "translation": {
            "en": "fully observable environment, 640, 640, 673",
            "zh": "完全可观测的环境，640、640、673"
        }
    },
    {
        "translation": {
            "en": "The distributions of predictions made by a model trained for the bacterial species identification problem for (a) the original evaluation test set, and for (b) and (c) two periods of time after model deployment; (d) shows how the stability index can be tracked over time to monitor for concept drift.",
            "zh": "为细菌物种识别问题训练的模型在 （a） 原始评估测试集以及 （b） 和 （c） 模型部署后的两个时间段内做出的预测分布;（d） 显示了如何随时间跟踪稳定性指数以监测概念漂移。"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the RPM and VIBRATION descriptive features from the generators dataset shown in Table 7.6[339], where good generators are shown as crosses, and faulty generators are shown as triangles; and (b) as decision boundary separating good generators (crosses) from faulty generators (triangles).",
            "zh": "（a） 表7.6[339]所示的发电机数据集中的RPM和VIBRATION描述性特征的散点图，其中好的发电机显示为十字形，故障发电机显示为三角形;（b）作为将良好发电机（十字架）与故障发电机（三角形）分开的决策边界。"
        }
    },
    {
        "translation": {
            "en": "2. We could also formulate the generative model as learning the joint distribution P(d,tl) directly and then computing the required posteriors from this distribution.",
            "zh": "2. 我们还可以将生成模型表述为直接学习联合分布 P（d，tl），然后从该分布中计算所需的后验。"
        }
    },
    {
        "translation": {
            "en": "This heuristic highlights the interaction between how we choose to initialize the weights in the network and how the error gradients flow during backpropagation.",
            "zh": "这种启发式方法突出了我们如何选择初始化网络中的权重与误差梯度在反向传播过程中如何流动之间的相互作用。"
        }
    },
    {
        "translation": {
            "en": "Notice that there is a chapparal leaf node at the end of the branch ELEVATION = low even though there are no instances in the dataset where ELEVATION = low and VEGETATION = chapparal. This leaf node is the result of an empty partition being generated when the partition at the ELEVATION node was split. This leaf node was assigned the target level chapparal because this was the majority target level in the partition at the ELEVATION node.",
            "zh": "请注意，即使数据集中没有 ELEVATION = low 且 VEGETATION = chapporal 的实例，分支 ELEVATION = low 的末尾也存在一个 chapparal 叶节点。此叶节点是拆分 ELEVATION 节点上的分区时生成空分区的结果。为此叶节点分配了目标级别 chapparal，因为这是 ELEVATION 节点处分区中的大多数目标级别。"
        }
    },
    {
        "translation": {
            "en": "This reflects that ELEVATION and STREAM have already been used on the path from the root node to each of these partitions and so cannot be used again.",
            "zh": "这反映出 ELEVATION 和 STREAM 已在从根节点到每个分区的路径上使用，因此不能再次使用。"
        }
    },
    {
        "translation": {
            "en": "A.3  The members of a rival school basketball team. Player heights are listed below each player. The dashed gray line shows the arithmetic mean of the players’ heights.",
            "zh": "A.3 敌对学校篮球队的成员。每个玩家下方列出了玩家的身高。灰色虚线表示球员身高的算术平均值。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, we have already discussed the solution to this problem.",
            "zh": "幸运的是，我们已经讨论了这个问题的解决方案。"
        }
    },
    {
        "translation": {
            "en": "The filter dimension hyper-parameter specifies the size of the filter in each dimension.",
            "zh": "过滤器维度超参数指定每个维度中过滤器的大小。"
        }
    },
    {
        "translation": {
            "en": "over-sampling, 93",
            "zh": "过采样，93"
        }
    },
    {
        "translation": {
            "en": "Usually small stacks of screenshots (e.g.",
            "zh": "通常是一小堆屏幕截图（例如"
        }
    },
    {
        "translation": {
            "en": "A plot of this function would pass through the origin because there is no y-intercept (or bias term) included in the calculation.",
            "zh": "此函数的图将通过原点，因为计算中不包含 y 截距（或偏置项）。"
        }
    },
    {
        "translation": {
            "en": "1. Non-negativity: metric(a,b) ≥ 0",
            "zh": "1. 非负性：指标（a，b）≥0"
        }
    },
    {
        "translation": {
            "en": "Decision trees also have difficulty with domains that have a large number of descriptive features, particularly if the number of instances in the training dataset is small. In these situations overfitting becomes very likely. The probability-based models discussed in Chapter 6[243] do a better job of handling high-dimensional data.",
            "zh": "对于具有大量描述性特征的域，决策树也存在困难，尤其是在训练数据集中的实例数量较少的情况下。在这些情况下，过拟合变得非常有可能。第6章[243]中讨论的基于概率的模型在处理高维数据方面做得更好。"
        }
    },
    {
        "translation": {
            "en": "Once the errorDelta(𝒟,w[j]) for a weight has been calculated, we can then update the weight using Equation (7.17)[327]. This weight update occurs on Line 4[326] of Algorithm 4[326]. The update involves multiplying the errorDelta(𝒟,w[j]) for a given weight by the learning rate and then adding this to the current weight to give a new, updated, weight. The new set of weights is labeled New Weights (after Iteration 1) in Table 7.3[331].",
            "zh": "一旦计算出权重的误差Delta（D，w[j]），我们就可以使用公式（7.17）[327]更新权重。此权重更新发生在算法 4[326] 的第 4 行 [326]。更新涉及将给定权重的 errorDelta（D，w[j]） 乘以学习率，然后将其添加到当前权重中以给出新的更新权重。在表7.3[331]中，新的权重集被标记为新权重（迭代1之后）。"
        }
    },
    {
        "translation": {
            "en": "Target network freezing makes the training process more stable and leads to faster convergence.",
            "zh": "目标网络冻结使训练过程更加稳定，并导致更快的收敛。"
        }
    },
    {
        "translation": {
            "en": "In clustering, unsupervised algorithms are used to partition the instances in a dataset into coherent groups.",
            "zh": "在聚类分析中，无监督算法用于将数据集中的实例划分为连贯的组。"
        }
    },
    {
        "translation": {
            "en": "Table 6.8[269] lists the prior and smoothed conditional probabilities for the fraud domain that are relevant to a naive Bayes model. Notice that there are no zero probabilities, so the model will be able to return a prediction for any query in this domain. We can illustrate the extended coverage of the model by returning to the query from the beginning of this section:",
            "zh": "表 6.8[269] 列出了与朴素贝叶斯模型相关的欺诈域的先验和平滑条件概率。请注意，没有零概率，因此模型将能够返回此域中任何查询的预测。我们可以通过返回本节开头的查询来说明模型的扩展覆盖范围："
        }
    },
    {
        "translation": {
            "en": "To illustrate these characteristics, we have created three artificial datasets and trained four different models on each of these datasets.",
            "zh": "为了说明这些特征，我们创建了三个人工数据集，并在每个数据集上训练了四个不同的模型。"
        }
    },
    {
        "translation": {
            "en": "These predictions do not solve business problems; rather, they provide insights that help the organization make better decisions to solve their business problems.",
            "zh": "这些预测并不能解决业务问题;相反，它们提供的见解可帮助组织做出更好的决策来解决其业务问题。"
        }
    },
    {
        "translation": {
            "en": "Table 4.1",
            "zh": "表 4.1"
        }
    },
    {
        "translation": {
            "en": "Consider, however, the dataset presented in Table 1.2[8], which shows a more complete representation of the same problem. This dataset lists more instances, and there are extra descriptive features describing the AMOUNT that a mortgage holder borrows, the mortgage holder’s SALARY, the type of PROPERTY that the mortgage relates to (which can be farm, house, or apartment), and the TYPE of mortgage (which can be ftb for first-time buyers or stb for second-time buyers).",
            "zh": "然而，考虑表1.2[8]中显示的数据集，它显示了同一问题的更完整表示。该数据集列出了更多实例，并且有额外的描述性特征描述了抵押贷款持有人借款的金额、抵押贷款持有人的工资、抵押贷款相关的财产类型（可以是农场、房屋或公寓）和抵押贷款类型（首次购房者可以是 ftb，第二次购房者可以是 stb）。"
        }
    },
    {
        "translation": {
            "en": "14. ROC curves are often plotted with sensitivity on the vertical axis and 1 − specificity on the horizontal axis. Recall that sensitivity is equal to TPR, and specificity is equal to TNR, so these are equivalent.",
            "zh": "14. ROC曲线通常在纵轴上具有灵敏度，在水平轴上具有1 −特异性。回想一下，灵敏度等于 TPR，特异性等于 TNR，因此它们是等效的。"
        }
    },
    {
        "translation": {
            "en": "Training a neural network involves finding a good set of values for these weights.",
            "zh": "训练神经网络涉及为这些权重找到一组好的值。"
        }
    },
    {
        "translation": {
            "en": "A depiction of the Markov blanket of a node. The gray nodes define the Markov blanket of the black node. The black node is conditionally independent of the white nodes given the state of the gray nodes.",
            "zh": "节点的马尔可夫毯的描述。灰色节点定义黑色节点的马尔可夫毯。给定灰色节点的状态，黑色节点有条件地独立于白色节点。"
        }
    },
    {
        "translation": {
            "en": "As a result, instructors using this book can plan their courses by simply selecting the sections of the book they wish to cover without worrying about dependencies between the sections.",
            "zh": "因此，使用本书的教师只需选择他们希望涵盖的书中的部分即可计划他们的课程，而不必担心各部分之间的依赖关系。"
        }
    },
    {
        "translation": {
            "en": "Similar to the way that we analyzed the questions in the Guess Who game, we measure the discriminatory power of a descriptive feature by analyzing the size and probability of each set of instances created when we test the value of the feature and how pure each set of instances is with respect to the target feature values of the instances it contains.",
            "zh": "与我们在“猜猜谁”游戏中分析问题的方式类似，我们通过分析在测试特征值时创建的每组实例的大小和概率以及每组实例相对于其包含的实例的目标特征值的纯度来衡量描述性特征的判别能力。"
        }
    },
    {
        "translation": {
            "en": "CBR, 234",
            "zh": "CBR，234"
        }
    },
    {
        "translation": {
            "en": "When making predictions about categorical targets, we need performance measures that capture how often the model makes correct predictions and the severity of the mistakes that the model makes when it is incorrect.",
            "zh": "在对分类目标进行预测时，我们需要性能度量来捕获模型做出正确预测的频率以及模型不正确时所犯错误的严重程度。"
        }
    },
    {
        "translation": {
            "en": "4. Bayes’ Theorem is named after the Reverend Thomas Bayes, who wrote an essay that described how to update beliefs as new information arises. After Thomas Bayes died, this essay was edited and published by the Reverend Richard Price (Bayes and Price, 1763). The modern mathematical form of Bayes’ Theorem, however, was developed by Simon Pierre Laplace.",
            "zh": "4. 贝叶斯定理以托马斯·贝叶斯牧师的名字命名，他写了一篇文章，描述了如何在新信息出现时更新信念。托马斯·贝叶斯去世后，这篇文章由理查德·普莱斯牧师编辑和出版（贝叶斯和普莱斯，1763 年）。然而，贝叶斯定理的现代数学形式是由西蒙·皮埃尔·拉普拉斯（Simon Pierre Laplace）开发的。"
        }
    },
    {
        "translation": {
            "en": "This assumption is important because these internal activation functions may be as complex as, or even more complex than, the target function that the network is attempting to represent.",
            "zh": "这个假设很重要，因为这些内部激活函数可能与网络试图表示的目标函数一样复杂，甚至更复杂。"
        }
    },
    {
        "translation": {
            "en": "This indicates a feature that has the same value for every instance and contains no information useful for building predictive models.",
            "zh": "这表示一个功能对每个实例都具有相同的值，并且不包含对构建预测模型有用的信息。"
        }
    },
    {
        "translation": {
            "en": "Kaiming initialization, 461",
            "zh": "开明初始化，461"
        }
    },
    {
        "translation": {
            "en": "EDUCATION, a categorical feature listing the highest education award achieved by the individual (high school, bachelors, doctorate);",
            "zh": "EDUCATION，一个分类特征，列出了个人获得的最高教育奖项（高中、学士、博士学位）;"
        }
    },
    {
        "translation": {
            "en": "mini-batches, 417",
            "zh": "小批量，417"
        }
    },
    {
        "translation": {
            "en": "For example, in our example network, if Neuron 8 is dead, the network will never converge on the training stop criterion, because no error gradients will be backpropagated to the earlier layers and so no training will occur.",
            "zh": "例如，在我们的示例网络中，如果 Neuron 8 是死的，则网络将永远不会收敛到训练停止标准上，因为没有误差梯度会反向传播到较早的层，因此不会发生训练。"
        }
    },
    {
        "translation": {
            "en": "input gate, 508, 511",
            "zh": "输入门， 508， 511"
        }
    },
    {
        "translation": {
            "en": "The descriptive features of the mysterious newly discovered animal are as follows:",
            "zh": "这种新发现的神秘动物的描述性特征如下："
        }
    },
    {
        "translation": {
            "en": "Modeling points in time using an observation period and an outcome period.",
            "zh": "使用观察期和结果期对时间点进行建模。"
        }
    },
    {
        "translation": {
            "en": "When mistakes are made, it would be useful for the production line operators to be able to query the model to understand why it made the prediction that led to a mistake.",
            "zh": "当出现错误时，生产线操作员能够查询模型以了解它为什么做出导致错误的预测会很有用。"
        }
    },
    {
        "translation": {
            "en": "Each row should also include the percentage of instances in the ABT that are missing a value for the feature and the cardinality of the feature.",
            "zh": "每行还应包括 ABT 中缺少特征值和特征基数的实例的百分比。"
        }
    },
    {
        "translation": {
            "en": "The candidate feature subset that leads to the best-performing model is then selected.",
            "zh": "然后选择导致性能最佳模型的候选特征子集。"
        }
    },
    {
        "translation": {
            "en": "discount rate, 642",
            "zh": "贴现率， 642"
        }
    },
    {
        "translation": {
            "en": "10. Because this is a higher-dimensional problem (three dimensions in the feature space and four dimensions in the weight space), it is not possible to draw the same graphs of the error surfaces that were shown for the previous examples.",
            "zh": "10. 由于这是一个更高维的问题（特征空间中的三维空间和权重空间中的四维），因此不可能绘制与前面示例相同的误差面图。"
        }
    },
    {
        "translation": {
            "en": "11. Understanding the probabilities associated with the dynamics of card games has a history stretching back to the origins of probability theory (Bernstein, 1996), through early applications of computing technology (Scarne, 1986), right to the modern day (Brown and Sandholm, 2017).",
            "zh": "11. 了解与纸牌游戏动力学相关的概率的历史可以追溯到概率论的起源（Bernstein，1996），通过计算技术的早期应用（Scarne，1986），一直到现代（Brown and Sandholm，2017）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.19",
            "zh": "图 8.19"
        }
    },
    {
        "translation": {
            "en": "The fact that the derivative of the rectifier function takes either a 0 or a 1 value means that during backpropagation for some neurons in a network, the δ value will be pushed to zero.",
            "zh": "整流器函数的导数采用 0 或 1 值这一事实意味着在网络中某些神经元的反向传播过程中，δ值将被推至零。"
        }
    },
    {
        "translation": {
            "en": "This is because the same inverse covariance matrix based on the entire dataset was used in each case.",
            "zh": "这是因为在每种情况下都使用了基于整个数据集的相同逆协方差矩阵。"
        }
    },
    {
        "translation": {
            "en": "One overarching point about reinforcement learning that is worth mentioning is that it comes at the cost of hugely increased computation. Training reinforcement learning agents for sophisticated tasks in complex, dynamic environments can required large computational resources for significant amounts of time. This is especially the case when approximate methods based on deep neural networks are used.",
            "zh": "关于强化学习，值得一提的一个总体点是，它是以大幅增加计算为代价的。在复杂、动态的环境中训练强化学习代理以完成复杂的任务可能需要大量的计算资源，持续很长时间。当使用基于深度神经网络的近似方法时，情况尤其如此。"
        }
    },
    {
        "translation": {
            "en": "database management systems, 42",
            "zh": "数据库管理系统，42"
        }
    },
    {
        "translation": {
            "en": "Furthermore, if we want to make a MAP prediction, we don’t necessarily have to calculate the actual probabilities for each level in the target domain; we simply need to know which of the levels in the target domain has the largest probability.",
            "zh": "此外，如果我们想进行 MAP 预测，我们不一定必须计算目标域中每个水平的实际概率;我们只需要知道目标域中哪个级别的概率最大。"
        }
    },
    {
        "translation": {
            "en": "The standard approach to addressing this problem is to use the independence and conditional independence relationships between the features in a domain to factorize the full joint distribution of the domain.",
            "zh": "解决此问题的标准方法是使用域中特征之间的独立性和条件独立性关系来分解域的完全联合分布。"
        }
    },
    {
        "translation": {
            "en": "In summary, neural networks with no hidden layer (i.e., perceptrons) cannot represent non-linearly separable functions.",
            "zh": "总之，没有隐藏层（即感知器）的神经网络不能表示非线性可分离的函数。"
        }
    },
    {
        "translation": {
            "en": "spam filtering, 262",
            "zh": "垃圾邮件过滤， 262"
        }
    },
    {
        "translation": {
            "en": "As the oft-quoted maxim states: correlation does not imply causation!",
            "zh": "正如经常被引用的格言所说：相关性并不意味着因果关系！"
        }
    },
    {
        "translation": {
            "en": "Once these tables have been created, for each weight we sum the ∂ℰ/∂wi,k for that weight across the tables.",
            "zh": "创建这些表后，对于每个权重，我们将该权重的 ∂E/∂wi，k 相加。"
        }
    },
    {
        "translation": {
            "en": "non-linear model, 311",
            "zh": "非线性模型，311"
        }
    },
    {
        "translation": {
            "en": "Edwin was assigned to Jocelyn as her key scientific contact from SDSS and was eager to answer any questions Jocelyn had as he saw real value in the model she was developing.",
            "zh": "Edwin 被指派给 Jocelyn 作为 SDSS 的主要科学联系人，并渴望回答 Jocelyn 的任何问题，因为他看到了她正在开发的模型的真正价值。"
        }
    },
    {
        "translation": {
            "en": "The different data sources typically combined to create an analytics base table.",
            "zh": "通常将不同的数据源组合在一起以创建分析基表。"
        }
    },
    {
        "translation": {
            "en": "In order to multiply one matrix by another, the number of columns in the matrix on the left of the product must equal the number of rows in the matrix on the right.",
            "zh": "为了将一个矩阵乘以另一个矩阵，乘积左侧矩阵中的列数必须等于右侧矩阵中的行数。"
        }
    },
    {
        "translation": {
            "en": "5. The following image illustrates the topology of a simple feedforward neural network that has a single sensing neuron (Neuron 1), three hidden processing neuron (Neurons 2, 3, and 4), and a single processing output neuron (Neuron 5).",
            "zh": "5. 下图说明了一个简单的前馈神经网络的拓扑结构，该网络具有单个传感神经元（神经元 1）、三个隐藏处理神经元（神经元 2、3 和 4）和一个处理输出神经元（神经元 5）。"
        }
    },
    {
        "translation": {
            "en": "Indeed, we have a situation where the posterior for a given prediction given the evidence is quite low (here P(m | h,¬f,v) = 0.3333), even though the likelihood of the evidence if we assume the prediction to be correct is quite high, P(h,¬f,v | m) = 0.6666.",
            "zh": "事实上，我们遇到这样一种情况，即给定证据的给定预测的后验非常低（这里 P（m | h，¬f，v） = 0.3333），即使如果我们假设预测是正确的，证据的可能性相当高，P（h，¬f，v | m） = 0.6666。"
        }
    },
    {
        "translation": {
            "en": "This can seem counterintuitive at first.",
            "zh": "乍一看，这似乎有悖常理。"
        }
    },
    {
        "translation": {
            "en": "This is an example of the compactness of a naive Bayes representation.",
            "zh": "这是朴素贝叶斯表示的紧凑性的一个例子。"
        }
    },
    {
        "translation": {
            "en": "8.4.2   Weight Initialization and Unstable Gradients",
            "zh": "8.4.2 权重初始化和不稳定梯度"
        }
    },
    {
        "translation": {
            "en": "In this figure, the imaginary pixels are shown in gray, and the valid (real) pixels are in the center of the matrix, shown in black.",
            "zh": "在此图中，虚像素以灰色显示，有效（实际）像素位于矩阵的中心，以黑色显示。"
        }
    },
    {
        "translation": {
            "en": "In contrast with supervised learning, there is no target feature that we build a model to predict; rather, we perform modeling to find structure within a set of instances defined by descriptive features alone.",
            "zh": "与监督学习相比，我们没有构建模型来预测的目标特征;相反，我们执行建模以在仅由描述性特征定义的一组实例中查找结构。"
        }
    },
    {
        "translation": {
            "en": "To determine the best value for k we can repeatedly cluster the data for all values of k within a given range, calculate a clustering performance measure for each clustering found, and then select the value of k that gives the clustering with the highest performance measure.",
            "zh": "为了确定 k 的最佳值，我们可以重复聚类给定范围内所有 k 值的数据，为找到的每个聚类计算聚类性能度量，然后选择 k 值，该值为具有最高性能度量的聚类提供聚类。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn discussed this model with Edwin, and they both agreed that the performance was not at the level required by the SDSS scientists for inclusion in the SDSS processing pipeline.",
            "zh": "Jocelyn 与 Edwin 讨论了这个模型，他们都同意该模型的性能没有达到 SDSS 科学家纳入 SDSS 处理管道所需的水平。"
        }
    },
    {
        "translation": {
            "en": "forget gate, 508",
            "zh": "忘记门，508"
        }
    },
    {
        "translation": {
            "en": "Rather, analytics projects are initiated in response to a business problem, and it is our job—as analytics practitioners—to decide how to address this business problem using analytics techniques.",
            "zh": "相反，分析项目是为了响应业务问题而启动的，作为分析从业者，我们的工作是决定如何使用分析技术解决此业务问题。"
        }
    },
    {
        "translation": {
            "en": "To train a naive Bayes model using this data, we need to compute the prior probabilities of the target feature taking each level in its domain, and the conditional probability of each feature taking each level in its domain conditioned for each level that the target can take.",
            "zh": "为了使用这些数据训练朴素贝叶斯模型，我们需要计算目标特征在其域中获取每个水平的先验概率，以及每个特征在其域中获取每个层次的条件概率，以目标可以获取的每个水平为条件。"
        }
    },
    {
        "translation": {
            "en": "1. Have gotten to know the features within the ABT, especially their central tendencies, variations, and distributions.",
            "zh": "1. 了解 ABT 中的特征，尤其是它们的中心趋势、变化和分布。"
        }
    },
    {
        "translation": {
            "en": "17. The data used in this question have been artificially generated for this book. This type of application of machine learning techniques, however, is common; for example, see Osowski et al. (2004).",
            "zh": "17. 本问题中使用的数据是为本书人为生成的。然而，机器学习技术的这种应用很常见;例如，参见Osowski et al. （2004） 。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.9[672] illustrates this architecture.",
            "zh": "图 11.9[672] 说明了这种架构。"
        }
    },
    {
        "translation": {
            "en": "Cybenko, George. 1988. Continuous valued neural networks with two hidden layers are sufficient, Technical report, Department of Computer Science, Tufts University.",
            "zh": "赛宾科，乔治。1988. 具有两个隐藏层的连续值神经网络就足够了，技术报告，塔夫茨大学计算机科学系。"
        }
    },
    {
        "translation": {
            "en": "The if statement on Line 8, which tests the distance between the query and the hyperplane defined by the current best node, is executed next.",
            "zh": "接下来执行第 8 行的 if 语句，该语句测试查询与当前最佳节点定义的超平面之间的距离。"
        }
    },
    {
        "translation": {
            "en": "We return to these kinds of evaluation experiments in Chapter 9[533].",
            "zh": "我们在第9章[533]中回到这些评估实验。"
        }
    },
    {
        "translation": {
            "en": "information gain ratio, 142, 174",
            "zh": "信息增益比，142,174"
        }
    },
    {
        "translation": {
            "en": "The distance between the query instance and the hyperplane defined by the node that indexes instance d21 is 0.75 (recall that because the hyperplane at this node is defined by the SPEED value of 6.75, we only compare this to the SPEED value of the query instance, 6.00).",
            "zh": "查询实例与索引实例 d21 的节点定义的超平面之间的距离为 0.75（回想一下，由于此节点上的超平面由 SPEED 值 6.75 定义，因此我们仅将其与查询实例的 SPEED 值 6.00 进行比较）。"
        }
    },
    {
        "translation": {
            "en": "The representational limitation of single-layer networks can be overcome by adding a single hidden layer to the network.",
            "zh": "单层网络的表示限制可以通过向网络添加单个隐藏层来克服。"
        }
    },
    {
        "translation": {
            "en": "Keeping all the weights in a network small helps to keep a model’s predictions relatively stable with respect to small changes in the input: if a model has some relatively large weights, then the model can be very sensitive to small changes in features to which these weights are applied.",
            "zh": "将网络中的所有权重保持在较小值有助于使模型的预测相对于输入中的微小变化保持相对稳定：如果模型具有一些相对较大的权重，则模型可以对应用这些权重的特征的微小变化非常敏感。"
        }
    },
    {
        "translation": {
            "en": "In this evaluation, Edwin and four of his colleagues independently examined 200 galaxy images randomly selected from the final test set and classified them as belonging to one of the three galaxy types.",
            "zh": "在这次评估中，埃德温和他的四位同事独立检查了从最终测试集中随机选择的200张星系图像，并将它们归类为属于三种星系类型之一。"
        }
    },
    {
        "translation": {
            "en": "density, 752, 753",
            "zh": "密度， 752， 753"
        }
    },
    {
        "translation": {
            "en": "For example, we might use a Euclidean distance metric to handle the continuous features in a dataset and the Jaccard similarity index to handle the categorical features.",
            "zh": "例如，我们可以使用欧几里得距离度量来处理数据集中的连续特征，并使用 Jaccard 相似性指数来处理分类特征。"
        }
    },
    {
        "translation": {
            "en": "Prediction Subject Details: Descriptive details of any aspect of the prediction subject.",
            "zh": "预测主题详细信息：预测主题任何方面的描述性详细信息。"
        }
    },
    {
        "translation": {
            "en": "We have already described the normal distribution, in some detail, in Section 3.2.1[61], so we won’t repeat that introduction here, but we will describe the other distributions in a little detail.",
            "zh": "我们已经在第 3.2.1 节[61]中详细描述了正态分布，因此我们不会在这里重复介绍，但我们将稍微详细描述其他分布。"
        }
    },
    {
        "translation": {
            "en": "11. These images were generated using equal-width binning. However, the points discussed in the text are also relevant to equal-frequency binning.",
            "zh": "11. 这些图像是使用等宽分箱生成的。但是，本文中讨论的要点也与等频合并有关。"
        }
    },
    {
        "translation": {
            "en": "So if we have a training dataset of m examples in stochastic gradient descent, it would take m iterations to complete a single epoch, and this epoch would involve m weight updates.",
            "zh": "因此，如果我们有一个随机梯度下降中 m 个样本的训练数据集，则需要 m 次迭代才能完成一个 epoch，而这个 epoch 将涉及 m 个权重更新。"
        }
    },
    {
        "translation": {
            "en": "12.2   (a)–(c) Histograms for the features from the AT ABT with irregular cardinality; (d)–(g) histograms for the features from the AT ABT that are potentially suffering from outliers.",
            "zh": "12.2 （a）–（c） 具有不规则基数的 AT ABT 特征的直方图;（d）–（g） 来自 AT ABT 的可能受到异常值影响的特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, the size of a joint probability distribution grows exponentially as the number of features and the number of values in the domains of the features grow.",
            "zh": "不幸的是，联合概率分布的大小随着特征的数量和特征域中的值数量的增长而呈指数增长。"
        }
    },
    {
        "translation": {
            "en": "Figure C.2",
            "zh": "图 C.2"
        }
    },
    {
        "translation": {
            "en": "Most of the time the technical distinction between a metric and an index is not that important; we simply focus on choosing the right measure of similarity for the type of instances we are comparing.",
            "zh": "大多数时候，指标和指数之间的技术区别并不那么重要;我们只是专注于为我们正在比较的实例类型选择正确的相似度量。"
        }
    },
    {
        "translation": {
            "en": "type I errors, 538",
            "zh": "I 类错误，538"
        }
    },
    {
        "translation": {
            "en": "hold-out sampling, 541, 547",
            "zh": "保持采样，541,547"
        }
    },
    {
        "translation": {
            "en": "This distance is less than the current best-distance (in Figure 5.11(a)[203], the hyperplane defined by the node that indexes instance d21 intersects with the target hypersphere).",
            "zh": "该距离小于当前最佳距离（在图 5.11（a）[203] 中，由索引实例 d21 的节点定义的超平面与目标超球相交）。"
        }
    },
    {
        "translation": {
            "en": "If power station administrators could predict upcoming generator failures before the generators actually fail, they could improve power station safety and save money on maintenance.11 Using this dataset, we would like to train a model to distinguish between properly operating power station generators and faulty generators using the RPM and VIBRATION measurements.",
            "zh": "如果发电站管理员能够在发电机实际发生故障之前预测即将到来的发电机故障，他们就可以提高发电站的安全性并节省维护费用.11 使用此数据集，我们想训练一个模型，使用 RPM 和 VIBRATION 测量来区分正常运行的发电站发电机和故障发电机。"
        }
    },
    {
        "translation": {
            "en": "AVGBILL",
            "zh": "AVGBILL公司"
        }
    },
    {
        "translation": {
            "en": "1.9   Exercises",
            "zh": "1.9 练习"
        }
    },
    {
        "translation": {
            "en": "14. Sometimes the task of predicting a continuous target is referred to as a regression task.",
            "zh": "14. 有时，预测连续目标的任务称为回归任务。"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D. 2016. Fundamentals of machine learning for neural machine translation. In Translating europe forum 2016: Focus on translation technologies. European Commission Directorate-General for Translation.",
            "zh": "凯莱赫，约翰 D. 2016 年。神经机器翻译的机器学习基础。2016年欧洲翻译论坛：聚焦翻译技术。欧盟委员会翻译总局。"
        }
    },
    {
        "translation": {
            "en": "The consultant generated the following data quality report from the ABT.",
            "zh": "顾问从ABT生成了以下数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Parametric ReLU, 445",
            "zh": "参数化 ReLU， 445"
        }
    },
    {
        "translation": {
            "en": "Calculate the reduction in the sum of squared error of the network for this example using the new weights, compared with using the original weights.",
            "zh": "与使用原始权重相比，使用新权重计算此示例中网络平方误差和的减少量。"
        }
    },
    {
        "translation": {
            "en": "7.2.2 Measuring Error",
            "zh": "7.2.2 测量误差"
        }
    },
    {
        "translation": {
            "en": "ε-greedy action selection policy, 656, 658, 674",
            "zh": "ε贪婪的行动选择策略，656、658、674"
        }
    },
    {
        "translation": {
            "en": "A statistical significance test works by stating a null hypothesis and then determining whether there is enough evidence to accept or reject this hypothesis. This accept/reject decision is carried out in three steps:",
            "zh": "统计显著性检验的工作原理是陈述一个原假设，然后确定是否有足够的证据来接受或拒绝该假设。此接受/拒绝决定分三个步骤执行："
        }
    },
    {
        "translation": {
            "en": "We illustrate the calculation of δs for neurons in a softmax output layer using the mini-batch of examples listed in Table 8.13[464] and the network architecture shown in Figure 8.27[465].",
            "zh": "我们使用表8.13[464]中列出的小批量示例和图8.27[465]中所示的网络架构来说明softmax输出层中神经元的δs计算。"
        }
    },
    {
        "translation": {
            "en": "By examining the data quality report, analytics practitioners can get a complete picture of the data that they will work with for the rest of an analytics project.",
            "zh": "通过检查数据质量报告，分析从业人员可以全面了解他们将在分析项目的其余部分使用的数据。"
        }
    },
    {
        "translation": {
            "en": "In particular, extending a loan to a borrower who turns out to be bad is a very costly mistake.",
            "zh": "特别是，向被证明是坏的借款人提供贷款是一个非常昂贵的错误。"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrix is shown in Table 13.9[724].",
            "zh": "由此产生的混淆矩阵如表13.9[724]所示。"
        }
    },
    {
        "translation": {
            "en": "Indeed, early stopping can also be understood as a regularization technique because it limits the number of updates to the weights in a model and by so doing keeps individual weights from getting too large.",
            "zh": "事实上，提前停止也可以理解为一种正则化技术，因为它限制了模型中权重的更新次数，从而防止单个权重变得太大。"
        }
    },
    {
        "translation": {
            "en": "Given the Markov assumption, we can write the probability of transitioning between two states",
            "zh": "给定马尔可夫假设，我们可以写出两种状态之间转换的概率"
        }
    },
    {
        "translation": {
            "en": "D   Introduction to Linear Algebra",
            "zh": "D 线性代数导论"
        }
    },
    {
        "translation": {
            "en": "Markov process, 644, 679, 681",
            "zh": "马尔可夫过程， 644， 679， 681"
        }
    },
    {
        "translation": {
            "en": "In Section 7.3[319] we described how a multivariable linear regression model trained using gradient descent can be used to make predictions for continuous target features.",
            "zh": "在第 7.3 节[319]中，我们描述了如何使用梯度下降训练的多变量线性回归模型来预测连续目标特征。"
        }
    },
    {
        "translation": {
            "en": "This is difficult, however, because when we design descriptive features, we tend not to know exactly which ones will be predictive and which ones will not.",
            "zh": "然而，这很困难，因为当我们设计描述性特征时，我们往往不知道哪些是预测性的，哪些不是。"
        }
    },
    {
        "translation": {
            "en": "B.4 Summary",
            "zh": "B.4 总结"
        }
    },
    {
        "translation": {
            "en": "Here, however, the focus is on covering a range of machine learning approaches, and again, evaluation is covered in detail.",
            "zh": "然而，这里的重点是涵盖一系列机器学习方法，并且再次详细介绍了评估。"
        }
    },
    {
        "translation": {
            "en": "Probability functions for categorical features are referred to as probability mass functions, while probability functions for continuous features are known as probability density functions.",
            "zh": "分类特征的概率函数称为概率质量函数，而连续特征的概率函数称为概率密度函数。"
        }
    },
    {
        "translation": {
            "en": "For illustrative purposes, in this instance we assume that the output neuron uses a logistic activation function and expand the definition of ∂ak/∂zk accordingly in the last two lines of the equation.",
            "zh": "为了便于说明，在本例中，我们假设输出神经元使用逻辑激活函数，并在等式的最后两行相应地扩展 ∂ak/∂zk 的定义。"
        }
    },
    {
        "translation": {
            "en": "The key decision making component of a reinforcement learning agent is referred to as a policy, π. A policy is simply a mapping from states to actions",
            "zh": "强化学习代理的关键决策组件被称为策略，π。策略只是从状态到操作的映射"
        }
    },
    {
        "translation": {
            "en": "This for loop iterates through the examples in the batch, and for each example the δs for the neurons are calculated and backpropagated.",
            "zh": "此 for 循环遍历批处理中的示例，并且对于每个示例，计算并反向传播神经元的 δ。"
        }
    },
    {
        "translation": {
            "en": "Also, an evenly connected network typically has a relatively short mixing time (for the size of the graph).",
            "zh": "此外，均匀连接的网络通常具有相对较短的混合时间（对于图形的大小）。"
        }
    },
    {
        "translation": {
            "en": "What is more interesting is that instances not actually on the decision boundary behave in a very regular way.",
            "zh": "更有趣的是，实际上不在决策边界上的实例以非常有规律的方式运行。"
        }
    },
    {
        "translation": {
            "en": "(a)–(d) Striking a balance between overfitting and underfitting in trying to predict income from age.",
            "zh": "（a）–（d） 在试图从年龄预测收入时，在过度拟合和欠拟合之间取得平衡。"
        }
    },
    {
        "translation": {
            "en": "Neural networks with two hidden layers and using smooth activation functions can represent any function and generally can do so using fewer neurons than networks with only a single hidden layer.",
            "zh": "具有两个隐藏层并使用平滑激活函数的神经网络可以表示任何函数，并且通常可以使用比只有一个隐藏层的网络更少的神经元来表示任何函数。"
        }
    },
    {
        "translation": {
            "en": "Data Quality Issue",
            "zh": "数据质量问题"
        }
    },
    {
        "translation": {
            "en": "Figure 5.4",
            "zh": "图 5.4"
        }
    },
    {
        "translation": {
            "en": "Artificial neural network models are composed of large numbers of simple processing units, called neurons, that typically are arranged into layers and are highly interconnected.",
            "zh": "人工神经网络模型由大量称为神经元的简单处理单元组成，这些单元通常排列成层并高度互连。"
        }
    },
    {
        "translation": {
            "en": "The sample dataset used in this section has been purposefully selected to include just two descriptive features so that the visualizations in Figure 10.3[602] could be easily shown.",
            "zh": "本节中使用的示例数据集经过特意选择，仅包含两个描述性特征，以便可以轻松显示图 10.3[602] 中的可视化效果。"
        }
    },
    {
        "translation": {
            "en": "To ensure a successful project outcome, we should inform the decisions that we make by",
            "zh": "为确保项目成功，我们应该通过以下方式为我们做出的决策提供信息"
        }
    },
    {
        "translation": {
            "en": "For example, consider Table A.3[751], which shows a set of results for polls run shortly before the 2012 United States presidential election, in which Mitt Romney and Barack Obama were the front-runners.3 In the first poll in the table, from Pew Research, we can see that a sample of just 2,709 likely voters4 was used.",
            "zh": "例如，考虑表 A.3[751]，它显示了 2012 年美国总统大选前不久进行的一组民意调查结果，其中米特·罗姆尼和巴拉克·奥巴马是领跑者。"
        }
    },
    {
        "translation": {
            "en": "4,000",
            "zh": "4,000"
        }
    },
    {
        "translation": {
            "en": "If the value of the stability index is between 0.1 and 0.25, then some change has occurred and further investigation may be useful.",
            "zh": "如果稳定性指数的值介于 0.1 和 0.25 之间，则发生了一些变化，进一步调查可能会有所帮助。"
        }
    },
    {
        "translation": {
            "en": "This process is illustrated in Figure 10.17[628].",
            "zh": "该过程如图10.17[628]所示。"
        }
    },
    {
        "translation": {
            "en": "For a data analytics practitioner, the key outcomes of the data exploration process (which straddles the Data Understanding and Data Preparation phases of CRISP-DM) are that the practitioner should",
            "zh": "对于数据分析从业者来说，数据探索过程（跨越CRISP-DM的数据理解和数据准备阶段）的关键结果是，从业者应该"
        }
    },
    {
        "translation": {
            "en": "The main advantages of normalizing descriptive feature values are that all weights become directly comparable with each other (as all descriptive features are on the same scale), and the behavior of the gradient descent algorithm used to train the model becomes much less sensitive to the learning rate and the initial weights.",
            "zh": "规范化描述性特征值的主要优点是，所有权重都变得彼此直接可比（因为所有描述性特征都在同一尺度上），并且用于训练模型的梯度下降算法的行为对学习率和初始权重的敏感度大大降低。"
        }
    },
    {
        "translation": {
            "en": "For ease of reference each of the neurons in the network has been labeled: 1,2,3,4,5,6,7.",
            "zh": "为了便于参考，网络中的每个神经元都被标记为：1,2,3,4,5,6,7。"
        }
    },
    {
        "translation": {
            "en": "20. Remember that for problems with more than two descriptive features, the decision boundary is a hyperplane rather than a line.",
            "zh": "20. 请记住，对于具有两个以上描述性特征的问题，决策边界是一个超平面而不是一条线。"
        }
    },
    {
        "translation": {
            "en": "For example, k-means is a special case of the Gaussian mixture model (Murphy, 2012) approach to clustering (assuming spherical distributions), which in turn has been extended into model-based clustering (Scrucca et al., 2016) algorithms, all of which can be very effective.",
            "zh": "例如，k-means是高斯混合模型（Murphy，2012）聚类方法（假设球面分布）的一个特例，而该方法又已扩展到基于模型的聚类（Scrucca et al.，2016）算法中，所有这些都非常有效。"
        }
    },
    {
        "translation": {
            "en": "These weight matrices are organized so that each row contains the weights for the connections coming into one neuron.",
            "zh": "这些权重矩阵被组织起来，以便每一行都包含进入一个神经元的连接的权重。"
        }
    },
    {
        "translation": {
            "en": "condensed nearest neighbor, 233",
            "zh": "凝聚的最近邻，233"
        }
    },
    {
        "translation": {
            "en": "For many years the logistic function was the default activation function used in neural networks.",
            "zh": "多年来，逻辑函数是神经网络中使用的默认激活函数。"
        }
    },
    {
        "translation": {
            "en": "The advantage of using a programming language for predictive data analytics projects is that it gives the data analyst huge flexibility.",
            "zh": "在预测数据分析项目中使用编程语言的优势在于，它为数据分析师提供了巨大的灵活性。"
        }
    },
    {
        "translation": {
            "en": "III   BEYOND PREDICTION",
            "zh": "三、超越预测"
        }
    },
    {
        "translation": {
            "en": "The third consideration is the longevity of any feature we design.",
            "zh": "第三个考虑因素是我们设计的任何功能的寿命。"
        }
    },
    {
        "translation": {
            "en": "; ACCIDENT REGION: REGION.",
            "zh": ";事故区域：区域。"
        }
    },
    {
        "translation": {
            "en": "They did spend some time, however, discussing the AVGOVERBUNDLEMINS.",
            "zh": "然而，他们确实花了一些时间讨论 AVGOVERBUNDLEMINS。"
        }
    },
    {
        "translation": {
            "en": "The absence of a large bar at − 99,999 in Figure 3.1(c)[58] confirms that there are not multiple occurrences of this value.",
            "zh": "图3.1（c）[58]中没有−99,999处的大柱线，这证实了该值没有多次出现。"
        }
    },
    {
        "translation": {
            "en": "8.3.5 A Worked Example: Using Backpropagation to Train a Feedforward Network for a Regression Task",
            "zh": "8.3.5 工作示例：使用反向传播为回归任务训练前馈网络"
        }
    },
    {
        "translation": {
            "en": "0.00",
            "zh": "0.00"
        }
    },
    {
        "translation": {
            "en": "First the expected return can be written as a sum across the expected returns of all possible actions at+1 that could be taken in state st+1",
            "zh": "首先，预期回报可以写成在状态 st+1 中可能采取的所有 +1 处可能操作的预期回报的总和"
        }
    },
    {
        "translation": {
            "en": "Following these explanations we present a worked example to show how the backpropagation and gradient descent algorithm can be used in partnership to train a neural network with hidden layers.",
            "zh": "根据这些解释，我们提供了一个工作示例来展示如何协同使用反向传播和梯度下降算法来训练具有隐藏层的神经网络。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.8[613] shows each of the clusterings found in the mobile phone customer dataset for values of k in [2,9] using k-means clustering, and their corresponding silhouettes (Figure 10.8(g)[613]).",
            "zh": "图10.8[613]显示了使用k-means聚类在[2,9]中k值的移动电话客户数据集中发现的每个聚类，以及它们相应的轮廓[图10.8（g）[613]）。"
        }
    },
    {
        "translation": {
            "en": "The relative frequency of an event is calculated as how often the event happened divided by how often it could have happened.",
            "zh": "事件的相对频率计算为事件发生的频率除以事件发生的频率。"
        }
    },
    {
        "translation": {
            "en": "linearly separable, 338, 354, 365, 396",
            "zh": "线性可分离， 338， 354， 365， 396"
        }
    },
    {
        "translation": {
            "en": "where the counts come from Table 9.21[581]. The stability index for New Sample 2, calculated in the same way, is 0.331. This suggests that at the point in time at which New Sample 1 was collected, the outputs produced by the model followed much the same distribution as when the model was originally evaluated, but that when New Sample 2 was collected, the distribution of the outputs produced by the model had changed significantly.",
            "zh": "其中计数来自表9.21[581]。以同样的方式计算，新样本 2 的稳定性指数为 0.331。这表明，在收集新样本 1 的时间点，模型产生的输出与最初评估模型时的分布大致相同，但是在收集新样本 2 时，模型产生的输出分布发生了重大变化。"
        }
    },
    {
        "translation": {
            "en": "With the addition of more neurons in each layer, the network could represent a function that maps to multiple disconnected convex regions and refines the shapes of these regions.",
            "zh": "随着每一层中增加更多的神经元，该网络可以表示一个映射到多个不相连的凸区域并细化这些区域形状的函数。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices for the models after feature selection.",
            "zh": "特征选择后模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "3. Termination Condition: This component determines when the search process should stop. Typically we stop when the subset selection component indicates that none of the feature subsets (search states) that can be generated from the current feature subset is more desirable than the current subset. Once the search process is terminated, the features in the dataset that are not members of the selected feature subset are pruned from the dataset before the prediction model is induced.",
            "zh": "3. 终止条件：此组件确定搜索过程何时停止。通常，当子集选择组件指示可以从当前特征子集生成的特征子集（搜索状态）都不比当前子集更理想时，我们会停止。搜索过程终止后，在诱导预测模型之前，将从数据集中修剪数据集中不属于所选特征子集成员的要素。"
        }
    },
    {
        "translation": {
            "en": "1.7 Predictive Data Analytics Tools",
            "zh": "1.7 预测数据分析工具"
        }
    },
    {
        "translation": {
            "en": "To understand the characteristics of a continuous feature, there are two things that are important to measure: the central tendency of the feature and the variation within the feature. These are the basic building blocks of everything else that will follow, so it is important to fully understand them.",
            "zh": "要理解连续特征的特征，有两件事很重要：特征的中心趋势和特征内的变化。这些是接下来其他一切的基本构建块，因此充分理解它们很重要。"
        }
    },
    {
        "translation": {
            "en": "This is why the activations of all neurons are recorded during the forward pass.",
            "zh": "这就是为什么在前向传递期间记录所有神经元的激活的原因。"
        }
    },
    {
        "translation": {
            "en": "Markov chain Monte Carlo, 298, 733",
            "zh": "马尔可夫链蒙特卡洛， 298， 733"
        }
    },
    {
        "translation": {
            "en": "Figure 8.38[504] is based on a figure from Kelleher (2016).",
            "zh": "图8.38[504]基于Kelleher（2016）的数据。"
        }
    },
    {
        "translation": {
            "en": "In a bag-of-words representation, the descriptive features that describe a document (in our case, an email) each represent how many times a particular word occurs in the document.",
            "zh": "在词袋表示中，描述文档（在我们的示例中为电子邮件）的描述性特征分别表示特定单词在文档中出现的次数。"
        }
    },
    {
        "translation": {
            "en": "This is done by organizing neurons into groups in which all the neurons in the group apply the same filter to their inputs.",
            "zh": "这是通过将神经元组织成组来完成的，其中组中的所有神经元对其输入应用相同的过滤器。"
        }
    },
    {
        "translation": {
            "en": "The examples throughout this book so far have focused on supervised machine learning methods for building predictive models.",
            "zh": "到目前为止，本书中的示例主要集中在用于构建预测模型的监督式机器学习方法上。"
        }
    },
    {
        "translation": {
            "en": "Well-designed evaluation experiments are the best way to find this balance (we discuss evaluation in detail in Chapter 9[533]).",
            "zh": "精心设计的评估实验是找到这种平衡的最佳方式（我们将在第9章[533]中详细讨论评估）。"
        }
    },
    {
        "translation": {
            "en": "Natural language is an example of this type of data: it is naturally sequential, one word follows the other, each sentence may have a different number of words (varying length), and it contains long-distance dependencies between elements.",
            "zh": "自然语言是这类数据的一个例子：它是自然顺序的，一个词跟着另一个词，每个句子可能有不同数量的单词（不同的长度），并且它包含元素之间的长距离依赖关系。"
        }
    },
    {
        "translation": {
            "en": "This often occurs in document classification problems, when a bag-of-words representation is used to represent documents as the frequency of occurrence of each word in a dictionary (the eponymous bag-of-words).",
            "zh": "这通常发生在文档分类问题中，当使用词袋表示法将文档表示为字典中每个单词的出现频率（同名词袋）时。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.8[718] shows small multiple box plots divided by galaxy type for a selection of features from the ABT.",
            "zh": "图13.8[718]显示了按星系类型划分的小多箱形图，用于ABT中的一些特征。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.7(b)[194] shows the decision boundary for a weighted k nearest neighbor model for the dataset in Table 5.4[191] with k = 21 (the size of the dataset) and weights computed using the reciprocal of the squared distance.",
            "zh": "图5.7（b）[194]显示了表5.4[191]中数据集的加权k最近邻模型的决策边界，其中k = 21（数据集的大小）和使用平方距离的倒数计算的权重。"
        }
    },
    {
        "translation": {
            "en": "unsupervised learning, xvi, 5, 20, 597, 598, 628, 674, 740",
            "zh": "无监督学习， xvi， 5， 20， 597， 598， 628， 674， 740"
        }
    },
    {
        "translation": {
            "en": "where ai and bi are values of features a and b for the ith instance in a dataset, and ā and b are the sample means of features a and b. Covariance values fall into the range [−∞,∞] where negative values indicate a negative relationship, positive values indicate a positive relationship, and values near zero indicate that there is little or no relationship between the features.",
            "zh": "其中 ai 和 bi 是数据集中第 i 个实例的特征 a 和 b 的值，ā 和 b 是特征 A 和 B 的样本均值。协方差值属于 [−∞，∞] 范围，其中负值表示负相关关系，正值表示正相关关系，接近零的值表示特征之间几乎没有关系或没有关系。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.4[543] illustrates how the available data is split during the k-fold cross validation process.",
            "zh": "图 9.4[543] 说明了在 k 折交叉验证过程中如何拆分可用数据。"
        }
    },
    {
        "translation": {
            "en": "Using Figure 3.14[92] to compare these two approaches to binning, we can see that by varying the width of the bins, equal-frequency binning uses bins to more accurately model the heavily populated areas of the range of values the continuous feature can take. The downside to this is that the resulting bins can appear slightly less intuitive because they are of varying sizes.",
            "zh": "使用图 3.14[92] 来比较这两种分箱方法，我们可以看到，通过改变条柱的宽度，等频分箱使用条柱来更准确地模拟连续特征可以采用的值范围的人口稠密区域。这样做的缺点是，生成的箱可能看起来不太直观，因为它们的大小各不相同。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.10(b)[201] illustrates the location of the query in the feature space (the ?",
            "zh": "图 5.10（b）[201] 说明了查询在特征空间中的位置（？"
        }
    },
    {
        "translation": {
            "en": "The distinction between stochastic gradient descent and batch gradient descent can be used to clarify the meanings of two related terms often used in neural network training: epoch and iteration.",
            "zh": "随机梯度下降和批量梯度下降之间的区别可以用来阐明神经网络训练中经常使用的两个相关术语的含义：纪元和迭代。"
        }
    },
    {
        "translation": {
            "en": "15. It is worth noting that the temporal-difference learning approach to reinforcement learning takes a very similar approach to the gradient descent algorithm described in Section 7.3[319].",
            "zh": "15. 值得注意的是，强化学习的时间差分学习方法与第 7.3 节[319]中描述的梯度下降算法非常相似。"
        }
    },
    {
        "translation": {
            "en": "Textual: Free-form, usually short, text data (e.g., name, address)",
            "zh": "文本：自由格式，通常很短的文本数据（例如，姓名、地址）"
        }
    },
    {
        "translation": {
            "en": "Table A.1",
            "zh": "表A.1"
        }
    },
    {
        "translation": {
            "en": "He would also like to thank his parents (John and Betty) and his sisters (Elizabeth and Marianne), without whose support he would not have gotten past long division and basic spelling.",
            "zh": "他还要感谢他的父母（约翰和贝蒂）和他的姐妹（伊丽莎白和玛丽安），没有他们的支持，他将无法通过长除法和基本拼写。"
        }
    },
    {
        "translation": {
            "en": "Alternatively, we may be dealing with a dataset where there is covariance between the descriptive features, in which case we should consider using the Mahalanobis distance as our measure of similarity.",
            "zh": "或者，我们可能正在处理描述性特征之间存在协方差的数据集，在这种情况下，我们应该考虑使用马氏距离作为相似性的度量。"
        }
    },
    {
        "translation": {
            "en": "In temporal-difference learning, the relevant value in the table is updated after each action that the agent takes.",
            "zh": "在时间差分学习中，表中的相关值在智能体执行的每个操作后都会更新。"
        }
    },
    {
        "translation": {
            "en": "Deep learning models can have millions of parameters, and this complexity makes them prone to overfitting. Two of the most commonly used methods to avoid overfitting in neural networks are early stopping and dropout (Srivastava et al., 2014).",
            "zh": "深度学习模型可能有数百万个参数，这种复杂性使它们容易出现过拟合。避免神经网络过拟合的两种最常用方法是早期停止和退出（Srivastava等人，2014）。"
        }
    },
    {
        "translation": {
            "en": "These measures place less emphasis on the performance of the model on the negative target level.",
            "zh": "这些措施不太强调模型在负目标水平上的性能。"
        }
    },
    {
        "translation": {
            "en": "Bishop, Christopher M. 1996. Neural networks for pattern recognition. Oxford University Press.",
            "zh": "主教，克里斯托弗 M. 1996 年。用于模式识别的神经网络。牛津大学出版社。"
        }
    },
    {
        "translation": {
            "en": "However, in data analytics a prediction is the assignment of a value to any unknown variable.",
            "zh": "然而，在数据分析中，预测是将值分配给任何未知变量。"
        }
    },
    {
        "translation": {
            "en": "We should also examine the minimum and maximum values to understand the range that is possible for each feature.",
            "zh": "我们还应该检查最小值和最大值，以了解每个特征的可能范围。"
        }
    },
    {
        "translation": {
            "en": "10.16   An image of the digit 2 and reconstructions of this image by the auto-encoder after various amounts of network training. The pixel values of the reconstructed images are shown alongside the images, as is the reconstruction error calculated by comparing these to the pixel values of the original image.",
            "zh": "10.16 数字 2 的图像，以及自动编码器在经过不同数量的网络训练后对该图像的重建。重建图像的像素值与图像一起显示，通过将这些像素值与原始图像的像素值进行比较计算的重建误差也是如此。"
        }
    },
    {
        "translation": {
            "en": "where levels(t) is the set of levels that the target feature, t, can assume; |levels(t)| is the size of this set; and recalll refers to the recall achieved by a model for level l.9 The average class accuracies for the model performances shown in Tables 9.5[551] and 9.6[551] are and respectively, which would indicate that the second model is actually a better performer than the first.",
            "zh": "其中 levels（t） 是目标要素 t 可以假定的一组级别; |levels（t）|是此集合的大小;9 表 9.5[551] 和 9.6[551] 所示模型性能的平均等级精度分别为 和 ，这表明第二个模型实际上比第一个模型表现更好。"
        }
    },
    {
        "translation": {
            "en": "complete linkage: the distance between the most dissimilar instances in two clusters is used as the overall distance between the clusters;",
            "zh": "完全联动：以两个集群中最不相干的实例之间的距离作为集群之间的总距离;"
        }
    },
    {
        "translation": {
            "en": "For a first example of how to evaluate the performance of a predictive model, let us assume that we are dealing with an email classification problem with a binary categorical target feature distinguishing between spam and ham emails.",
            "zh": "对于如何评估预测模型性能的第一个示例，让我们假设我们正在处理一个电子邮件分类问题，该问题具有区分垃圾邮件和业余电子邮件的二元分类目标特征。"
        }
    },
    {
        "translation": {
            "en": "The optimism associated with finding multimodally distributed data stems from the fact that, if we are lucky, the separate peaks in the distribution will be associated with the different target levels we are trying to predict.",
            "zh": "与寻找多模态分布数据相关的乐观情绪源于这样一个事实，即如果我们幸运的话，分布中的单独峰值将与我们试图预测的不同目标水平相关联。"
        }
    },
    {
        "translation": {
            "en": "Neural network models are especially effective in this use case, and the chapter presented an example of using an auto-encoder to learn a feature representation that could be used by a supervised machine learning model.",
            "zh": "神经网络模型在此用例中特别有效，本章介绍了一个使用自动编码器来学习可由监督机器学习模型使用的特征表示的示例。"
        }
    },
    {
        "translation": {
            "en": "Bache, K., and M. Lichman. 2013. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml.",
            "zh": "Bache， K. 和 M. Lichman。2013. UCI 机器学习存储库。http://archive.ics.uci.edu/ml。"
        }
    },
    {
        "translation": {
            "en": "As is always the case when a committee is working together, however, steps should be taken to guard against group think.",
            "zh": "然而，与委员会一起工作时的情况一样，应该采取措施防止群体思维。"
        }
    },
    {
        "translation": {
            "en": "Given that there are three target levels, a prediction probability of approximately 0.333 indicates that the prediction made by the model is really quite unsure.",
            "zh": "假设有三个目标水平，预测概率约为 0.333，表明模型做出的预测确实非常不确定。"
        }
    },
    {
        "translation": {
            "en": "The 7 and 8 partitions, however, contain instances with a mixture of target feature levels, so the algorithm needs to continue splitting these partitions.",
            "zh": "但是，7 和 8 分区包含混合了目标功能级别的实例，因此算法需要继续拆分这些分区。"
        }
    },
    {
        "translation": {
            "en": "The XOR example shows that a network with a single hidden layer can represent a non-linearly separable function.",
            "zh": "XOR 示例表明，具有单个隐藏层的网络可以表示非线性可分函数。"
        }
    },
    {
        "translation": {
            "en": "6.3   The probabilities needed by a naive Bayes prediction model, calculated from the data in Table 6.2[263].",
            "zh": "6.3 朴素贝叶斯预测模型所需的概率，根据表6.2[263]中的数据计算得出。"
        }
    },
    {
        "translation": {
            "en": "It is difficult to provide a detailed worked example of the DQN algorithm because the number of weights to be learned and steps required for anything interesting is too large for clear presentation.",
            "zh": "很难提供 DQN 算法的详细工作示例，因为要学习的权重数量和任何有趣的东西所需的步骤都太大，无法清晰地呈现。"
        }
    },
    {
        "translation": {
            "en": "9. This is not as extreme an assumption as it might sound, as cards in Blackjack are usually dealt from a shoe containing 6 to 8 standard playing card decks.",
            "zh": "9. 这并不像听起来那么极端，因为二十一点中的牌通常是从包含 6 到 8 副标准扑克牌的鞋子中发牌的。"
        }
    },
    {
        "translation": {
            "en": "If the feature occurs in the neuron’s local receptive field, then the neuron will have a high activation.",
            "zh": "如果该特征发生在神经元的局部感受野中，则神经元将具有高度激活。"
        }
    },
    {
        "translation": {
            "en": "We use bold notation to distinguish between a probability distribution, P(), and a probability function, P().",
            "zh": "我们使用粗体表示法来区分概率分布 P（） 和概率函数 P（）。"
        }
    },
    {
        "translation": {
            "en": "As a result, they designed a model of the neuron that would take in multiple inputs and then output either a high signal, a 1, or a low signal, a 0.",
            "zh": "因此，他们设计了一个神经元模型，该模型将接受多个输入，然后输出高信号（1）或低信号（0）。"
        }
    },
    {
        "translation": {
            "en": "Brian would like to thank his parents (Liam and Roisín) and family for all of their support on this book (and everything else). He would also like to thank all his colleagues and students at University College Dublin (and previously at the Dublin Institute of Technology)—especially Pádraig Cunningham and Sarah Jane Delany, who opened his eyes to machine learning.",
            "zh": "布莱恩要感谢他的父母（利亚姆和罗伊辛）和家人对这本书（以及其他一切）的所有支持。他还要感谢他在都柏林大学学院（以及之前在都柏林理工学院）的所有同事和学生，尤其是 Pádraig Cunningham 和 Sarah Jane Delany，他们让他对机器学习大开眼界。"
        }
    },
    {
        "translation": {
            "en": "Assuming that all the weights and the inputs are independent and identically distributed,34 then the products in the weighted sum can be considered uncorrelated and we can state the variance of z as follows:",
            "zh": "假设所有权重和输入都是独立的并且分布相同，34 那么加权和中的乘积可以被认为是不相关的，我们可以将 z 的方差表示如下："
        }
    },
    {
        "translation": {
            "en": "For example, the number of factors required by a naive Bayes model is only dependent on the number of features in the domain and is independent of the number of instances.",
            "zh": "例如，朴素贝叶斯模型所需的因子数仅取决于域中的特征数，而与实例数无关。"
        }
    },
    {
        "translation": {
            "en": "Rather, they will require the predictions made by a model to be explained and justified.",
            "zh": "相反，它们将要求对模型做出的预测进行解释和证明。"
        }
    },
    {
        "translation": {
            "en": "The resulting sets both contain a mixture of spam and ham instances.",
            "zh": "生成的集合都包含垃圾邮件和火腿实例的混合体。"
        }
    },
    {
        "translation": {
            "en": "On-policy temporal-difference learning is an alternative in which the behavior policy is used to select the next action at the update step.",
            "zh": "策略时间差异学习是一种替代方法，其中行为策略用于在更新步骤中选择下一个操作。"
        }
    },
    {
        "translation": {
            "en": "In particular, these case studies highlight how a range of issues and tasks beyond model building—such as business understanding, problem definition, data gathering and preparation, and communication of insight—are crucial to the success of a predictive analytics project.",
            "zh": "特别是，这些案例研究强调了模型构建之外的一系列问题和任务（例如业务理解、问题定义、数据收集和准备以及见解交流）对于预测分析项目的成功至关重要。"
        }
    },
    {
        "translation": {
            "en": "0.25",
            "zh": "0.25"
        }
    },
    {
        "translation": {
            "en": "This is exactly what we do to update the weights in our recurrent neural network.",
            "zh": "这正是我们更新递归神经网络中的权重所做的事情。"
        }
    },
    {
        "translation": {
            "en": "First, we would be able to understand how office size affects office rental price.",
            "zh": "首先，我们将能够了解办公室大小如何影响办公室租金价格。"
        }
    },
    {
        "translation": {
            "en": "PETROFLUX_U/G/R/I/Z",
            "zh": "PETROFLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "In fact, a large difference between the mean and median of a feature is an indication that there may be outliers among the feature values.",
            "zh": "事实上，特征的均值和中位数之间的较大差异表明特征值之间可能存在异常值。"
        }
    },
    {
        "translation": {
            "en": "0.2500",
            "zh": "0.2500"
        }
    },
    {
        "translation": {
            "en": "Note that this time we have separated w0 from the other weights, w, as this will make later equations simpler.21 Recall from Section 7.4.4[338] that for instances above a separating hyperplane",
            "zh": "请注意，这次我们已将 w0 与其他权重 w 分离，因为这将使后面的方程更简单.21 回想一下第 7.4.4 节[338]，对于分离超平面上方的实例"
        }
    },
    {
        "translation": {
            "en": "CHURN",
            "zh": "搅乳器"
        }
    },
    {
        "translation": {
            "en": "Error Gradients (Deltas) δ",
            "zh": "误差梯度 （Delta） δ"
        }
    },
    {
        "translation": {
            "en": "Second, once a feature has been tested, it is not considered for selection again along that path in the tree.",
            "zh": "其次，一旦测试了特征，就不会再考虑沿着树中的该路径进行选择。"
        }
    },
    {
        "translation": {
            "en": "(b) What will be the value of ct if",
            "zh": "（b） ct 的值是多少，如果"
        }
    },
    {
        "translation": {
            "en": "For this reason, there are a variety of different performance measures and no single approach that is appropriate for all scenarios.",
            "zh": "因此，有各种不同的性能度量，没有一种方法适合所有方案。"
        }
    },
    {
        "translation": {
            "en": "On each time-step, the information stored in the memory buffer is concatenated with the next input to each neuron.",
            "zh": "在每个时间步长上，存储在内存缓冲区中的信息与每个神经元的下一个输入连接起来。"
        }
    },
    {
        "translation": {
            "en": "The expected target values for a test set, the predictions made by a model, and the resulting errors based on these predictions for a blood-thinning drug dosage prediction problem.",
            "zh": "测试集的预期目标值、模型做出的预测以及基于这些预测的血液稀释药物剂量预测问题的结果误差。"
        }
    },
    {
        "translation": {
            "en": "This final formulation of the action-value function simply states that the expected return from taking action at in state st is the expected reward for taking that action plus the expected return from all of the subsequent actions that the agent will take as it moves between states if it continues to follow the policy π.",
            "zh": "行动价值函数的最终表述简单地指出，在状态 st 处采取行动的预期回报是采取该行动的预期回报，加上代理在继续遵循策略π时在状态之间移动时将采取的所有后续行动的预期回报。"
        }
    },
    {
        "translation": {
            "en": "10.2   Unsupervised machine learning as a single-step process.",
            "zh": "10.2 无监督机器学习作为单步过程。"
        }
    },
    {
        "translation": {
            "en": "The first is by mistaking the order of a causal relationship.",
            "zh": "第一种是弄错了因果关系的顺序。"
        }
    },
    {
        "translation": {
            "en": "10.4.4 Understanding Clustering Results",
            "zh": "10.4.4 了解聚类结果"
        }
    },
    {
        "translation": {
            "en": "When we first mentioned the ID3 algorithm, we stated that it tries to create the shallowest decision tree that is consistent with the data given.",
            "zh": "当我们第一次提到 ID3 算法时，我们说过它试图创建与给定数据一致的最浅决策树。"
        }
    },
    {
        "translation": {
            "en": "It is this selection of the best action, rather than one selected using the behavior policy, that makes Q-learning an off-policy approach.",
            "zh": "正是这种对最佳行动的选择，而不是使用行为策略选择的行动，使Q-learning成为一种非策略方法。"
        }
    },
    {
        "translation": {
            "en": "3. the summation of the results of these two dot products with the bias terms for the hidden layer neurons; and finally,",
            "zh": "3. 这两个点积的结果与隐藏层神经元的偏差项的总和;最后，"
        }
    },
    {
        "translation": {
            "en": "To do this we simply modify the algorithm to return the majority target level within the set of k nearest neighbors to the query q:",
            "zh": "为此，我们只需修改算法，即可返回查询 q 的 k 个最近邻集合中的多数目标水平："
        }
    },
    {
        "translation": {
            "en": "The ROC curve is drawn by plotting a point for every feasible threshold value and joining them.",
            "zh": "ROC 曲线是通过为每个可行的阈值绘制一个点并将它们连接起来来绘制的。"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature SEX and the target feature, CLASS.",
            "zh": "（c） 下面的可视化说明了分类特征 与目标特征 CLASS 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Instead, we need a more efficient way to find the best combination of weights.",
            "zh": "相反，我们需要一种更有效的方法来找到最佳的权重组合。"
        }
    },
    {
        "translation": {
            "en": "Approximate methods are an alternative to tabular approaches to reinforcement learning that learn a generalized version of the action-value function (or the value function) and can handle much larger state spaces than tabular methods.",
            "zh": "近似方法是表格强化学习方法的替代方法，它学习动作-价值函数（或价值函数）的广义版本，并且可以处理比表格方法大得多的状态空间。"
        }
    },
    {
        "translation": {
            "en": "To use a PDF to calculate a probability, we need to think in terms of the area under an interval of the PDF curve.",
            "zh": "要使用 PDF 来计算概率，我们需要考虑 PDF 曲线区间下的面积。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.9",
            "zh": "图 6.9"
        }
    },
    {
        "translation": {
            "en": "For each of the other neurons in the softmax output layer, their δ is simply their activation",
            "zh": "对于softmax输出层中的其他每个神经元，它们的δ只是它们的激活"
        }
    },
    {
        "translation": {
            "en": "8.9   (left) The XOR function implemented as a two-layer neural network. (right) The network processing the four possible input combinations.",
            "zh": "8.9（左）作为两层神经网络实现的 XOR 函数。（右）处理四种可能的输入组合的网络。"
        }
    },
    {
        "translation": {
            "en": "additive models, 165",
            "zh": "增材模型，165"
        }
    },
    {
        "translation": {
            "en": "To demonstrate how this process works, imagine that we were given the query email SUSPICIOUS WORDS = true, UNKNOWN SENDER = true, CONTAINS IMAGES = true, and asked to predict whether it is spam or ham.",
            "zh": "为了演示此过程的工作原理，假设我们收到查询电子邮件 SUSPICIOUS WORDS = true、UNKNOWN SENDER = true、CONTAINS IMAGES = true，并被要求预测它是垃圾邮件还是火腿。"
        }
    },
    {
        "translation": {
            "en": "The chain rule, however, doesn’t specify any constraints on which features in the domain we choose to condition on. We could just as easily have decomposed the probability of the joint event as follows:",
            "zh": "但是，链式规则并未指定任何约束，说明我们选择以域中的哪些特征为条件。我们可以很容易地分解联合事件的概率，如下所示："
        }
    },
    {
        "translation": {
            "en": "The term population is used in statistics to represent all possible measurements or outcomes that are of interest to us in a particular study or piece of analysis.",
            "zh": "人口一词在统计学中用于表示我们在特定研究或分析中感兴趣的所有可能的测量或结果。"
        }
    },
    {
        "translation": {
            "en": "-0.09089",
            "zh": "-0.09089"
        }
    },
    {
        "translation": {
            "en": "Table 6.13[281] shows the extended domain representation.",
            "zh": "表 6.13[281] 显示了扩展域表示。"
        }
    },
    {
        "translation": {
            "en": "Generally, the later layers of a convolutional network will include one or more fully connected layers (such as those shown in previous examples) with a softmax output layer if the model is being used for classification.",
            "zh": "通常，如果模型用于分类，卷积网络的后面层将包括一个或多个具有 softmax 输出层的全连接层（例如前面示例中所示的层）。"
        }
    },
    {
        "translation": {
            "en": "categorical data, 34",
            "zh": "分类数据，34"
        }
    },
    {
        "translation": {
            "en": "The path through the tree to make predictions for instances d2, d5, and d6 from the validation dataset leads to this subtree.",
            "zh": "通过树对验证数据集中的实例 d2、d5 和 d6 进行预测的路径指向此子树。"
        }
    },
    {
        "translation": {
            "en": "Ideally, we should use the threshold that results in the highest information gain when the feature is used to split the dataset.",
            "zh": "理想情况下，我们应该使用在使用特征拆分数据集时产生最高信息增益的阈值。"
        }
    },
    {
        "translation": {
            "en": "The SALARY and AGE section of Table 5.6[206] lists these distances and the ranking that the model applies to the instances in the dataset using them.",
            "zh": "表 5.6[206] 的 SALARY 和 AGE 部分列出了这些距离以及模型应用于数据集中使用它们的实例的排名。"
        }
    },
    {
        "translation": {
            "en": "In this section we introduce the concept of a feature space as a representation for a training dataset and then illustrate how we can compute measures of similarity between instances in a feature space.",
            "zh": "在本节中，我们将介绍特征空间的概念，作为训练数据集的表示形式，然后说明如何计算特征空间中实例之间的相似度量。"
        }
    },
    {
        "translation": {
            "en": "The major drawback of naive Bayes models is the inability of the model to handle the interactions between features.",
            "zh": "朴素贝叶斯模型的主要缺点是模型无法处理特征之间的交互。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.27[465] illustrates a fully connected feedforward neural network with a softmax output layer with three neurons for our three-level (low, medium and high) target feature; the dotted rectangle around the softmax layer highlights that the activation function φ normalizes the logit values across the neurons in the layer.",
            "zh": "图 8.27[465] 展示了一个完全连接的前馈神经网络，该网络具有一个 softmax 输出层，其中有三个神经元，用于我们的三级（低、中和高）目标特征;SoftMax 层周围的虚线矩形突出显示了激活函数φ对层中神经元的 logit 值进行归一化。"
        }
    },
    {
        "translation": {
            "en": "Later we add information on potential handling strategies for each data quality issue.",
            "zh": "稍后，我们将添加有关每个数据质量问题的潜在处理策略的信息。"
        }
    },
    {
        "translation": {
            "en": "11. We discuss exactly this type of visualization, a scatter plot, in detail in Chapter 3[53]. For this example it is sufficient to say that a point is shown for each person in the dataset, placed to represent the person’s age (horizontally) and salary (vertically).",
            "zh": "11. 我们在第3章[53]中详细讨论了这种类型的可视化，即散点图。对于此示例，只需说数据集中为每个人显示一个点就足够了，该点用于表示该人的年龄（水平）和薪水（垂直）。"
        }
    },
    {
        "translation": {
            "en": "23. The example of predicting where post-operative patients should be sent is inspired by the research reported in Woolery et al. (1991). A real dataset related to this research is available through the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Post-Operative+Patient/.",
            "zh": "23. 预测术后患者应被送往何处的例子是受到Woolery等人（1991年）报告的研究的启发。与这项研究相关的真实数据集可通过 archive.ics.uci.edu/ml/datasets/Post-Operative+Patient/ 的UCI机器学习存储库（Bache和Lichman，2013）获得。"
        }
    },
    {
        "translation": {
            "en": "As a result, comparing the covariance between pairs of features only makes sense if each pair of features is composed of the same mixture of units.",
            "zh": "因此，只有当每对特征都由相同的单元组合组成时，比较特征对之间的协方差才有意义。"
        }
    },
    {
        "translation": {
            "en": "Histograms, using a bin size of 250 units, and density curves for the ACCOUNT BALANCE feature: (a) the fraudulent instances overlaid with a fitted exponential distribution; and (b) the non-fraudulent instances overlaid with a fitted normal distribution.",
            "zh": "使用 250 个单位的箱大小的直方图和 ACCOUNT BALANCE 特征的密度曲线：（a） 用拟合指数分布叠加的欺诈实例;（b）非欺诈性实例与拟合正态分布叠加。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn used the information gain measure to rank the predictiveness of the different features in the dataset (for this analysis, missing values were simply omitted).",
            "zh": "Jocelyn 使用信息增益度量对数据集中不同特征的预测性进行排名（对于此分析，缺失值被简单地省略）。"
        }
    },
    {
        "translation": {
            "en": "7.4.7 Support Vector Machines",
            "zh": "7.4.7 支持向量机"
        }
    },
    {
        "translation": {
            "en": "A subtree is pruned if the error rate on the validation set of the decision tree with the subtree removed is no greater than the error rate of the decision tree when the subtree is included.",
            "zh": "如果删除了子树的决策树的验证集上的错误率不大于包含子树时决策树的错误率，则修剪子树。"
        }
    },
    {
        "translation": {
            "en": "This is one of the great arts of machine learning and something that we return to throughout this book.",
            "zh": "这是机器学习的伟大艺术之一，也是我们在本书中回归的东西。"
        }
    },
    {
        "translation": {
            "en": "The root mean squared error (RMSE) for a set of predictions made by a model on a test set is calculated as",
            "zh": "模型在测试集上进行的一组预测的均方根误差 （RMSE） 计算公式为"
        }
    },
    {
        "translation": {
            "en": "We have structured this presentation around five approaches to learning: information-based, similarity-based, probability-based, error-based, and deep learning.",
            "zh": "我们围绕五种学习方法构建了本次演讲：基于信息、基于相似性、基于概率、基于错误和深度学习。"
        }
    },
    {
        "translation": {
            "en": "8.3.1 Backpropagation: The General Structure of the Algorithm",
            "zh": "8.3.1 反向传播：算法的一般结构"
        }
    },
    {
        "translation": {
            "en": "There are a variety of different recurrent neural network architectures; in this section we introduce two of the most popular: simple recurrent networks (also known as Elman networks (Elman, 1990)), and long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, 1997).",
            "zh": "有各种不同的递归神经网络架构;在本节中，我们介绍了两种最流行的网络：简单递归网络（也称为Elman网络（Elman，1990））和长短期记忆（LSTM）网络（Hochreiter和Schmidhuber，1997）。"
        }
    },
    {
        "translation": {
            "en": "In this example, using a k-d tree saved us calculating the distance between the query node and 14 of the instances in the dataset.",
            "zh": "在此示例中，使用 k-d 树可以节省我们计算查询节点与数据集中 14 个实例之间的距离。"
        }
    },
    {
        "translation": {
            "en": "The fundamental building block of a neural network is a computational model known as an artificial neuron.",
            "zh": "神经网络的基本构建块是称为人工神经元的计算模型。"
        }
    },
    {
        "translation": {
            "en": "During landing the agent receives a reward of + 10 each time one of its legs touches the ground gently.",
            "zh": "在着陆过程中，每当它的一条腿轻轻接触地面时，代理就会获得 + 10 的奖励。"
        }
    },
    {
        "translation": {
            "en": "9. Whereas previously we referred to recall as something calculated only for the positive level, we can calculate recall for any level as the accuracy of the predictions made for that level.",
            "zh": "9. 以前我们把召回率称为只针对正水平计算的东西，我们可以计算任何水平的召回率，作为对该水平做出的预测的准确性。"
        }
    },
    {
        "translation": {
            "en": "First, chapparal is a type of evergreen shrubland that can be fire-prone.",
            "zh": "首先，chapparal 是一种常绿灌木，容易发生火灾。"
        }
    },
    {
        "translation": {
            "en": "25. Note that comparing the sum of squared errors for the logistic network in Table 8.4[426] with the sum of squared errors for the ReLU model in Table 8.10[441] is not useful, because both of these are errors for random networks.",
            "zh": "25. 请注意，将表8.4[426]中逻辑网络的平方误差总和与表8.10[441]中ReLU模型的平方误差总和进行比较是没有用的，因为这两个都是随机网络的误差。"
        }
    },
    {
        "translation": {
            "en": "In information theory, the meaning of the word information deliberately excludes the psychological aspects of the communication and should be understood as measuring the optimal encoding length of a message given the set of possible messages that could be sent within the communication.",
            "zh": "在信息论中，“信息”一词的含义故意排除了通信的心理方面，并且应该被理解为在给定通信中可能发送的一组可能消息的情况下测量消息的最佳编码长度。"
        }
    },
    {
        "translation": {
            "en": "There is one of these error gradients for each weight in the network.",
            "zh": "网络中每个权重都有一个这样的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Careful readers might note a contradiction in the paragraph above, however.",
            "zh": "然而，细心的读者可能会注意到上面段落中的矛盾之处。"
        }
    },
    {
        "translation": {
            "en": "For example, average customer purchases per month, loan-to-value ratios, or changes in usage frequencies for different periods are all descriptive features that could be useful in an ABT but that most likely need to be derived from multiple raw data sources.",
            "zh": "例如，每月的平均客户购买量、贷款价值比率或不同时期的使用频率变化都是描述性特征，这些特征在 ABT 中可能很有用，但很可能需要从多个原始数据源派生。"
        }
    },
    {
        "translation": {
            "en": "8. This algorithm was first published in Quinlan (1986).",
            "zh": "8. 该算法首次发表在Quinlan（1986）上。"
        }
    },
    {
        "translation": {
            "en": "Instead, we can simply return the target level that has the highest score from the numerator term.",
            "zh": "相反，我们可以简单地返回分子项中得分最高的目标水平。"
        }
    },
    {
        "translation": {
            "en": "The rule given in Equation (7.32)[345] assumes that only a single training instance exists. To modify this to take into account a full training dataset, we simply need to sum across all the training instances as we did before in Equation (7.17)[327]. This gives us the weight update rule for multivariable logistic regression:",
            "zh": "等式（7.32）[345]中给出的规则假设只存在一个训练实例。为了修改它以考虑完整的训练数据集，我们只需要像之前在等式（7.17）[327]中所做的那样对所有训练实例求和。这为我们提供了多变量逻辑回归的权重更新规则："
        }
    },
    {
        "translation": {
            "en": "(a) A set of instances on a continuous number line; (b), (c), and (d) depict some of the potential groupings that could be applied to these instances.",
            "zh": "（a） 连续数字线上的一组实例;（b）、（c）和（d）描述了可以应用于这些实例的一些潜在分组。"
        }
    },
    {
        "translation": {
            "en": "In other cases, particularly where data arises from manual entry, certain personally sensitive values (for example, salary, age, or weight) may be entered only for a small number of instances.",
            "zh": "在其他情况下，特别是当数据来自手动输入时，某些个人敏感值（例如，工资、年龄或体重）可能仅在少数情况下输入。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(c)[626] shows reconstructions of the same images after just five epochs of network training.",
            "zh": "图10.15（c）[626]显示了在仅仅五个网络训练周期后对相同图像的重建。"
        }
    },
    {
        "translation": {
            "en": "On the basis of this difference, the estimate for the action-value entry Qπ(st,at) is updated slightly.",
            "zh": "在此差异的基础上，动作值条目 Qπ（st，at） 的估计值略有更新。"
        }
    },
    {
        "translation": {
            "en": "For example, in the motor insurance fraud detection example that we used in this chapter, the claims in the ABT were all historical.",
            "zh": "例如，在我们在本章中使用的汽车保险欺诈检测示例中，ABT 中的索赔都是历史性的。"
        }
    },
    {
        "translation": {
            "en": "For the retail scenario, there are only three binary descriptive features, so there are 23 = 8 possible combinations of descriptive feature values.",
            "zh": "对于零售方案，只有三个二进制描述性特征，因此有 23 = 8 种描述性特征值的可能组合。"
        }
    },
    {
        "translation": {
            "en": "LIFE EXP measures life expectancy at birth.",
            "zh": "LIFE EXP衡量出生时的预期寿命。"
        }
    },
    {
        "translation": {
            "en": "Table 7.11[359] shows a sample from a dataset of mobile customers that includes details of customers’ shopping habits with a large national retail chain.",
            "zh": "表7.11[359]显示了来自移动客户数据集的样本，其中包括客户在大型全国零售连锁店的购物习惯的详细信息。"
        }
    },
    {
        "translation": {
            "en": "As with the regression examples in Chapter 7[311], the profile of this error reduction over the course of the training is sensitive to a number of factors, for example, the learning rate α and how it is updated throughout the training (see Section 7.3.3[328]).",
            "zh": "与第 7 章[311] 中的回归示例一样，在训练过程中，这种误差减少的概况对许多因素都很敏感，例如，学习率α以及在整个训练过程中的更新方式（参见第 7.3.3 节[328]）。"
        }
    },
    {
        "translation": {
            "en": "Classification: LCC Q325.5.K455 2020 | DDC 519.2/870285631–dc23",
            "zh": "中图分类号： LCC Q325.5.K455 2020 |DDC 519.2/870285631–DC23"
        }
    },
    {
        "translation": {
            "en": "To find these other types of clusterings, it can be more useful to use a clustering algorithm that is driven more by local relationships in a dataset than an expected global structure.",
            "zh": "要查找这些其他类型的聚类，使用聚类分析算法可能更有用，该算法更多地由数据集中的局部关系驱动，而不是预期的全局结构。"
        }
    },
    {
        "translation": {
            "en": "In many cases the primary requirement of a project is to create an accurate prediction model.",
            "zh": "在许多情况下，项目的主要要求是创建准确的预测模型。"
        }
    },
    {
        "translation": {
            "en": "Because it takes so long and relies on experienced, expert tax inspectors, performing an audit is an expensive exercise.",
            "zh": "由于审计时间很长，并且依赖于经验丰富的专业税务检查员，因此进行审计是一项昂贵的工作。"
        }
    },
    {
        "translation": {
            "en": "0.35",
            "zh": "0.35"
        }
    },
    {
        "translation": {
            "en": "This means that they understand enough about a business so that they can converse with partners in the business in a way that these business partners understand.",
            "zh": "这意味着他们对业务有足够的了解，以便他们可以以这些业务合作伙伴理解的方式与业务中的合作伙伴交谈。"
        }
    },
    {
        "translation": {
            "en": "The average number of calls received each month by the customer",
            "zh": "客户每月平均接到的电话数"
        }
    },
    {
        "translation": {
            "en": "Using a full joint probability distribution, we can do probabilistic inference by summing out the features we are not interested in.",
            "zh": "使用完全联合概率分布，我们可以通过总结我们不感兴趣的特征来进行概率推理。"
        }
    },
    {
        "translation": {
            "en": "10.2 Fundamentals",
            "zh": "10.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "This involves performing an evaluation experiment31 for each candidate feature subset, in which a model is induced using only the features in the subset, and its performance is evaluated.",
            "zh": "这涉及对每个候选特征子集执行评估实验31，其中仅使用子集中的特征诱导模型，并评估其性能。"
        }
    },
    {
        "translation": {
            "en": "There are, however, weights on the connections from the memory buffer to each of the neurons.",
            "zh": "然而，从记忆缓冲区到每个神经元的连接是有权重的。"
        }
    },
    {
        "translation": {
            "en": "parameterized model, 311, 312, 314",
            "zh": "参数化模型， 311， 312， 314"
        }
    },
    {
        "translation": {
            "en": "where Parents(xi) describes the set of nodes in the graph that directly link into node xi, and Children(xi) describes the set of nodes in the graph that xi directly links into. Applying this definition to the network in Figure 6.9(b)[287], we can calculate the probability of P(c | ¬a,b,d) as",
            "zh": "其中 Parents（习） 描述图中直接链接到节点 习 的节点集，Children（习） 描述图中 习 直接链接到的节点集。将这个定义应用于图6.9（b）[287]中的网络，我们可以计算出P（c | ¬a，b，d）的概率为"
        }
    },
    {
        "translation": {
            "en": "In processing a sequence, the network takes one input from the sequence at each time point.",
            "zh": "在处理序列时，网络从每个时间点的序列中获取一个输入。"
        }
    },
    {
        "translation": {
            "en": "Many machine learning tools will allow the maximum depth of a tree to be specified as a parameter, which allows for the creation of such stunted trees.",
            "zh": "许多机器学习工具将允许将树的最大深度指定为参数，从而允许创建此类发育不良的树。"
        }
    },
    {
        "translation": {
            "en": "The first δ we calculate is for Neuron 8: δ8. Neuron 8 is an output neuron and so we use the process illustrated in Equation (8.21)[411]. As shown by Equation (8.21)[411] and following Equation (8.20)[411], the term ∂ℰ/∂a is the error of the neuron multiplied by − 1, and so from Table 8.4[426] we see that for d2",
            "zh": "我们计算的第一个δ是神经元 8：δ8。神经元 8 是一个输出神经元，因此我们使用公式 （8.21）[411] 中所示的过程。如公式（8.21）[411]和公式（8.20）[411]所示，项∂E/∂a是神经元的误差乘以−1，因此从表8.4[426]中我们可以看出d2"
        }
    },
    {
        "translation": {
            "en": "The most easily calculated measure of variation is range. The range of a sample of n values for a feature a is calculated as",
            "zh": "最容易计算的变异度量是范围。要素 a 的 n 个值样本的范围计算为"
        }
    },
    {
        "translation": {
            "en": "Figure 8.16[430] shows the network from the worked example in a graph form with each of the neurons labeled with the δ for the neuron.",
            "zh": "图 8.16[430] 以图形形式显示了工作示例中的网络，其中每个神经元都标有神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "For example, the condensed nearest neighbor approach (Hart, 1968) was one of the earliest attempts at this and removes the instances not near target level boundaries in a feature space, as they are not required to make predictions.",
            "zh": "例如，浓缩最近邻方法（Hart，1968）是最早的尝试之一，它删除了特征空间中不靠近目标级边界的实例，因为它们不需要进行预测。"
        }
    },
    {
        "translation": {
            "en": "A dataset of mobile phone customers described by their average monthly data (DATA USAGE) and call (CALL VOLUME) usage. Details of the first two iterations of the k-means clustering algorithm are also shown. The clustering in the second iteration is actually the final clustering in this simple example.",
            "zh": "移动电话客户的数据集，由其平均每月数据（DATA USAGE）和通话量（CALL VOLUME）使用情况描述。还显示了 k-means 聚类算法的前两次迭代的详细信息。在这个简单示例中，第二次迭代中的聚类实际上是最终聚类。"
        }
    },
    {
        "translation": {
            "en": "Examining the histogram in Figure 3.1(c)[58] is useful in considering the impact of applying the clamp transformation using these thresholds.",
            "zh": "检查图3.1（c）[58]中的直方图有助于考虑使用这些阈值应用钳位变换的影响。"
        }
    },
    {
        "translation": {
            "en": "If all values in a sample occur with equal frequency, then there is no mode.",
            "zh": "如果样本中的所有值都以相同的频率出现，则不存在模式。"
        }
    },
    {
        "translation": {
            "en": "Table 4.11",
            "zh": "表 4.11"
        }
    },
    {
        "translation": {
            "en": "Although it might seem that we now have a good solution for building probability-based prediction models, we are not quite done yet. There is one fundamental flaw with the approach that we have developed. To illustrate this, we will consider a second query instance for the meningitis diagnosis problem, this time with descriptive feature values HEADACHE = true, FEVER = true, and VOMITING = false. The probability of MENINGITIS = true given this query is",
            "zh": "虽然我们现在似乎有一个很好的解决方案来构建基于概率的预测模型，但我们还没有完全完成。我们制定的方法存在一个根本缺陷。为了说明这一点，我们将考虑脑膜炎诊断问题的第二个查询实例，这次使用描述性特征值 HEADACHE = true、FEVER = true 和 VOMITING = false。给定此查询，脑膜炎 = true 的概率为"
        }
    },
    {
        "translation": {
            "en": "20. It is important to remember that for a prediction problem with four target levels, uniform random guessing will give an accuracy of just 25%.",
            "zh": "20. 重要的是要记住，对于具有四个目标水平的预测问题，统一随机猜测的准确率仅为 25%。"
        }
    },
    {
        "translation": {
            "en": "family",
            "zh": "家庭"
        }
    },
    {
        "translation": {
            "en": "logistic regression, 311, 338, 342, 368, 556, 719, 732, 733, 735, 736",
            "zh": "逻辑回归， 311， 338， 342， 368， 556， 719， 732， 733， 735， 736"
        }
    },
    {
        "translation": {
            "en": "Feature subset space for a dataset with three features X, Y, and Z.",
            "zh": "具有三个要素 X、Y 和 Z 的数据集的特征子集空间。"
        }
    },
    {
        "translation": {
            "en": "The density of this unit hypercube is (there are 10 instances inside the hypercube).",
            "zh": "这个单位超立方体的密度是（超立方体内有 10 个实例）。"
        }
    },
    {
        "translation": {
            "en": "1. Environments in which the state contains all information about the environment and any agents in it are known as fully observable environments. Environments in which this is not the case are known as partially observable environments. The use of a state generation function allows us to treat some partially observable environments as if they were fully observable and apply the mechanics of reinforcement learning where otherwise it would not be possible.",
            "zh": "1. 状态包含有关环境及其中任何代理的所有信息的环境称为完全可观察环境。并非如此的环境称为部分可观察环境。使用状态生成函数允许我们将一些部分可观察的环境视为完全可观察的环境，并在其他情况下应用强化学习的机制。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.11",
            "zh": "图 10.11"
        }
    },
    {
        "translation": {
            "en": "8.7   The calculation of Δw7,5 across our four examples.",
            "zh": "8.7 我们四个例子中 Δw7,5 的计算。"
        }
    },
    {
        "translation": {
            "en": "This dataset contains a set of training instances that can be used to build a model to predict whether emails are spam or ham (genuine).",
            "zh": "此数据集包含一组训练实例，可用于构建模型来预测电子邮件是垃圾邮件还是火腿（真实）。"
        }
    },
    {
        "translation": {
            "en": "If we take the partial derivative of this with respect to w[0], all the terms that do not contain w[0] are treated as constants, so",
            "zh": "如果我们对 w[0] 取此的偏导数，则所有不包含 w[0] 的项都被视为常数，因此"
        }
    },
    {
        "translation": {
            "en": "Personal data is defined as data that relates to an identified or identifiable individual, who is known as a data subject.",
            "zh": "个人数据被定义为与已识别或可识别的个人（称为数据主体）相关的数据。"
        }
    },
    {
        "translation": {
            "en": "1.1   What Is Predictive Data Analytics?",
            "zh": "1.1 什么是预测数据分析？"
        }
    },
    {
        "translation": {
            "en": "The data that the features in an ABT contain can be of a number of different types:",
            "zh": "ABT 中的要素包含的数据可以是多种不同的类型："
        }
    },
    {
        "translation": {
            "en": "It is possible to look at the probabilities for each descriptive feature and analyze how that value contributed to the final prediction.",
            "zh": "可以查看每个描述性特征的概率，并分析该值如何对最终预测做出贡献。"
        }
    },
    {
        "translation": {
            "en": "When this representation learning is successful, the mapping from the representation the output layer receives to the target output is simpler than the mapping from the original input features to the target feature, and this can result in the model’s being more accurate.",
            "zh": "当此制图表达学习成功时，从输出图层接收到的制图表达到目标输出的映射比从原始输入要素到目标特征的映射更简单，这可以使模型更加准确。"
        }
    },
    {
        "translation": {
            "en": "These methods offer two advantages over basic k-means: they can find initial centroids less likely to lead to sub-optimal clusterings, and they can select initial centroids that allow the algorithm to converge much more quickly than when seeds are randomly chosen.",
            "zh": "与基本 k 均值相比，这些方法具有两个优势：它们可以找到不太可能导致次优聚类的初始质心，并且它们可以选择初始质心，使算法比随机选择种子时收敛得更快。"
        }
    },
    {
        "translation": {
            "en": "These would act as baseline performance scores that she would try to improve upon.",
            "zh": "这些将作为她将尝试改进的基线绩效分数。"
        }
    },
    {
        "translation": {
            "en": "The second interesting observation about the division of the right-hand side of Bayes’ Theorem by P(Y) is that we can calculate P(Y) in two different ways. First, we can calculate P(Y) directly from a dataset as",
            "zh": "关于贝叶斯定理右侧除以 P（Y） 的第二个有趣的观察结果是，我们可以用两种不同的方式计算 P（Y）。首先，我们可以直接从数据集中计算 P（Y） 为"
        }
    },
    {
        "translation": {
            "en": "The members of the school basketball team from Figure A.1[746] with one very tall ringer added: (a) the dashed gray line shows the mean of the players’ heights; and (b) the dashed gray line shows the median of the players’ heights, with the players ordered by height.",
            "zh": "图A.1[746]中学校篮球队的成员，加上一个非常高的铃声：（a）灰色虚线表示球员身高的平均值;（b）灰色虚线显示球员身高的中位数，球员按身高排序。"
        }
    },
    {
        "translation": {
            "en": "(c)–(e) A representation of the changing weights used to generate sample datasets for the first iterations of the boosting process.",
            "zh": "（c）–（e） 用于为提升过程的第一次迭代生成样本数据集的变化权重的表示。"
        }
    },
    {
        "translation": {
            "en": "As we will see when we look at the machine learning algorithms covered in Chapters 4[117] to 7[311], the presence of different types of descriptive and target features can have a big impact on how an algorithm works.",
            "zh": "正如我们将看到，当我们查看第 4 章[117] 至 7[311] 中介绍的机器学习算法时，不同类型的描述性和目标特征的存在会对算法的工作方式产生重大影响。"
        }
    },
    {
        "translation": {
            "en": "pass",
            "zh": "通过"
        }
    },
    {
        "translation": {
            "en": "These processing steps are described mathematically in the following equations:",
            "zh": "这些处理步骤在以下公式中以数学方式描述："
        }
    },
    {
        "translation": {
            "en": "Apart from the grid nature of the inputs, the rest of the processing within the neuron is the same as previously described in this chapter: the result of a weighted sum of inputs is passed through a non-linear activation function.",
            "zh": "除了输入的网格性质外，神经元内的其余处理与本章前面描述的相同：输入加权和的结果通过非线性激活函数传递。"
        }
    },
    {
        "translation": {
            "en": "Based on these frequency counts and proportions, the mode of a categorical feature can be calculated. The mode is a measure of the central tendency of a categorical feature and is simply the most frequent level. Based on the counts in Table A.2[750], the mode of the POSITION feature is guard. We often also calculate a second mode, which is just the second most common level of a feature. In this example, the second mode is forward.",
            "zh": "根据这些频率计数和比例，可以计算分类特征的模式。该模式是分类特征的中心趋势的度量，并且只是最常见的水平。根据表 A.2[750] 中的计数，POSITION 特征的模式为 guard。我们通常还会计算第二种模式，这只是功能的第二常见级别。在此示例中，第二种模式是转发。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.5(c)[74] shows a scatter plot of the HEIGHT and AGE features.",
            "zh": "图3.5（c）[74]显示了HEIGHT和AGE特征的散点图。"
        }
    },
    {
        "translation": {
            "en": "where the terms x2 and 2x are treated as constants as they do not include y. Figures C.3(b)[769] and C.3(c)[769] show these partial derivatives.",
            "zh": "其中项 x2 和 2x 被视为常数，因为它们不包括 y。 图 C.3（b）[769] 和 C.3（c）[769] 显示了这些偏导数。"
        }
    },
    {
        "translation": {
            "en": "In the majority of ABTs there are multiple continuous features between which we would like to explore relationships.",
            "zh": "在大多数 ABT 中，有多个连续特征，我们想探索它们之间的关系。"
        }
    },
    {
        "translation": {
            "en": "This ensures that the training set and test set are sufficiently large to train an accurate model and fully evaluate the performance of that model.",
            "zh": "这可确保训练集和测试集足够大，可以训练准确的模型并全面评估该模型的性能。"
        }
    },
    {
        "translation": {
            "en": "From the feature map in Equation (8.94)[490] we can ascertain that a A = 0 and aB = 255.",
            "zh": "从等式（8.94）[490]中的特征图中，我们可以确定a A = 0，aB = 255。"
        }
    },
    {
        "translation": {
            "en": "Each feature takes one of two values, yes or no.",
            "zh": "每个要素采用两个值之一，即“是”或“否”。"
        }
    },
    {
        "translation": {
            "en": "Reading from left to right, the theorem shows us how to calculate the probability of an event given the evidence we have of that event in terms of the likelihood of the event causing this evidence. This is useful because reasoning from the evidence to events (inverse reasoning) is often much more difficult than reasoning from an event to the evidence it causes (forward reasoning). Bayes’ Theorem allows us to easily swap back and forth between these two types of reasoning.",
            "zh": "从左到右阅读，该定理向我们展示了如何根据事件导致该证据的可能性来计算事件的概率。这很有用，因为从证据到事件的推理（逆向推理）通常比从事件到它引起的证据（正向推理）要困难得多。贝叶斯定理允许我们轻松地在这两种推理之间来回切换。"
        }
    },
    {
        "translation": {
            "en": "Consequently, they are difficult to generate because of the curse of dimensionality: computing the probability for each cell in a joint probability table requires a set of instances and, because the number of cells grows exponentially as features and feature values are added, so does the size of the dataset required to generate the joint probability distribution.",
            "zh": "因此，由于维度的诅咒，它们很难生成：计算联合概率表中每个像元的概率需要一组实例，并且由于像元的数量随着特征和特征值的增加呈指数增长，因此生成联合概率分布所需的数据集的大小也随之增加。"
        }
    },
    {
        "translation": {
            "en": "Recall that this plot was generated using input data that had been standardized, and so var(d) = 1.",
            "zh": "回想一下，此图是使用已标准化的输入数据生成的，因此 var（d） = 1。"
        }
    },
    {
        "translation": {
            "en": "1.3   A simple retail dataset.",
            "zh": "1.3 一个简单的零售数据集。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, Cybenko (1988) proved that a network with at least three layers (two hidden and one output) using sigmoid activation functions can approximate any function (not just bounded continuous functions) with arbitrary accuracy.",
            "zh": "此外，Cybenko（1988）证明，使用sigmoid激活函数的至少三层（两个隐藏和一个输出）的网络可以任意精度近似任何函数（不仅仅是有界连续函数）。"
        }
    },
    {
        "translation": {
            "en": "3.8   Calculating covariance.",
            "zh": "3.8 计算协方差。"
        }
    },
    {
        "translation": {
            "en": "recurrent neural network, 434, 499",
            "zh": "递归神经网络，434,499"
        }
    },
    {
        "translation": {
            "en": "bimodal distribution, 60",
            "zh": "双峰分布，60"
        }
    },
    {
        "translation": {
            "en": "The weights used in this aggregation are the confidence factors associated with each model.",
            "zh": "此聚合中使用的权重是与每个模型关联的置信因子。"
        }
    },
    {
        "translation": {
            "en": "(a) A graph illustrating how the value of a binary log (the log to the base 2) of a probability changes across the range of probability values; and (b) the impact of multiplying these values by − 1.",
            "zh": "（a） 说明概率的二进制对数（以 2 为基数的对数）的值在概率值范围内如何变化的图表;（b）将这些值乘以−1的影响。"
        }
    },
    {
        "translation": {
            "en": "To calculate these error gradients we must backpropagate ∂ℰ/∂o‡ through a tanh layer and then merge the resulting gradients with the error gradients from the next time-step with respect to the current cell state.",
            "zh": "为了计算这些误差梯度，我们必须通过tanh层反向传播∂E/∂o‡，然后将得到的梯度与下一个时间步的误差梯度合并到当前单元状态。"
        }
    },
    {
        "translation": {
            "en": "How many new numbers the customer is frequently calling this month",
            "zh": "客户本月经常拨打多少个新号码"
        }
    },
    {
        "translation": {
            "en": "Cross validation approaches are generally preferred unless datasets are very large, in which case the likelihood of the lucky split becomes very low, and hold-out approaches can be used.",
            "zh": "交叉验证方法通常是首选，除非数据集非常大，在这种情况下，幸运分裂的可能性变得非常低，并且可以使用保留方法。"
        }
    },
    {
        "translation": {
            "en": "Cardano, Gerolamo, 243",
            "zh": "卡尔达诺，杰罗拉莫，243"
        }
    },
    {
        "translation": {
            "en": "It is extremely important that the system not in any way slow the production line and that the possibility of defective components being passed by the system be minimized as much as possible.",
            "zh": "极其重要的是，系统不能以任何方式减慢生产线的速度，并尽可能减少系统通过缺陷部件的可能性。"
        }
    },
    {
        "translation": {
            "en": "At the beginning of the first episode of the Q-learning process (Line 13[658]), the agent is placed in the starting cell in the grid world (s0 = 0-3).",
            "zh": "在 Q 学习过程的第一集（第 13 行[658]）开始时，智能体被放置在网格世界的起始单元中 （s0 = 0-3）。"
        }
    },
    {
        "translation": {
            "en": "Richter and Weber (2013) is a good introduction, and overview, to CBR.",
            "zh": "Richter and Weber （2013） 是对 CBR 的一个很好的介绍和概述。"
        }
    },
    {
        "translation": {
            "en": "Accuracy can often be related to the power of a machine learning algorithm to capture the interaction between descriptive features and the target feature.",
            "zh": "准确性通常与机器学习算法捕获描述性特征与目标特征之间的交互的能力有关。"
        }
    },
    {
        "translation": {
            "en": "Before going any further, Ross had to define the prediction subject for the ABT and the target feature. The goal was to develop a model that would predict whether a customer would churn in the coming months. This meant that the prediction subject in this case was a customer, so the ABT would need to be built to contain one row per customer.",
            "zh": "在继续之前，Ross 必须定义 ABT 的预测主题和目标特征。目标是开发一个模型来预测客户是否会在未来几个月内流失。这意味着在这种情况下，预测主体是客户，因此需要将 ABT 构建为包含每个客户一行。"
        }
    },
    {
        "translation": {
            "en": "WINE",
            "zh": "酒"
        }
    },
    {
        "translation": {
            "en": "The goal of the intelligent agent is to complete a task as successfully as possible. To frame the reinforcement learning problem, this needs to be more formally defined—what does it mean to successfully complete a task? The next section explores this.",
            "zh": "智能代理的目标是尽可能成功地完成任务。为了构建强化学习问题，需要更正式地定义这一点——成功完成任务意味着什么？下一节将对此进行探讨。"
        }
    },
    {
        "translation": {
            "en": "As a result, AGE is being virtually ignored by the metric.",
            "zh": "因此，该指标几乎忽略了 AGE。"
        }
    },
    {
        "translation": {
            "en": "A Markov chain is a system that has a set of finite states and a set of transition probabilities that define the likelihood of the system moving from one state to another.",
            "zh": "马尔可夫链是一个系统，它具有一组有限状态和一组转移概率，这些概率定义了系统从一个状态移动到另一个状态的可能性。"
        }
    },
    {
        "translation": {
            "en": "treatment group, 583",
            "zh": "治疗组，583"
        }
    },
    {
        "translation": {
            "en": "So the algorithm then searches the tree looking for instances that are closer to the query than the instance stored in best (Lines 4-11 of the algorithm control this search).",
            "zh": "因此，该算法随后搜索树，查找比存储在 best 中的实例更接近查询的实例（算法的第 4-11 行控制此搜索）。"
        }
    },
    {
        "translation": {
            "en": "If two events X and Y are independent, then",
            "zh": "如果两个事件 X 和 Y 是独立的，则"
        }
    },
    {
        "translation": {
            "en": "irrelevant features, 227",
            "zh": "不相关的功能，227"
        }
    },
    {
        "translation": {
            "en": "Figure 5.2",
            "zh": "图 5.2"
        }
    },
    {
        "translation": {
            "en": "10.4.4   Understanding Clustering Results",
            "zh": "10.4.4 了解聚类结果"
        }
    },
    {
        "translation": {
            "en": "Friedman, J., T. Hastie, and R. Tibshirani. 2001. The elements of statistical learning, Vol. 1. Springer.",
            "zh": "弗里德曼，J.，T.哈斯蒂和R.蒂布希拉尼。2001. 统计学习的要素，第 1 卷。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.37",
            "zh": "图 8.37"
        }
    },
    {
        "translation": {
            "en": "It is standard that hidden state h and the cell state c have the same size.",
            "zh": "隐藏状态 h 和单元状态 c 具有相同的大小是标准的。"
        }
    },
    {
        "translation": {
            "en": "The first thing we need to do is figure out how many different possible models actually exist for the scenario.",
            "zh": "我们需要做的第一件事是弄清楚该场景实际上存在多少种不同的可能模型。"
        }
    },
    {
        "translation": {
            "en": "This vertical concatenation operation is illustrated in Figure 8.6[393] with d[0] added to the activation matrix as it is propagated forward from one layer to the next.",
            "zh": "这种垂直串联操作如图8.6[393]所示，当激活矩阵从一层向前传播到下一层时，将d[0]添加到激活矩阵中。"
        }
    },
    {
        "translation": {
            "en": "The collection limitation principle states that personal data should only be obtained by lawful means with the knowledge and consent of a data subject.",
            "zh": "收集限制原则规定，个人数据只能在数据主体知情和同意的情况下通过合法方式获取。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5(b)[273] shows a histogram of the same dataset after some outliers have been added to the extreme right of the distribution.",
            "zh": "图 6.5（b）[273] 显示了将一些异常值添加到分布的最右侧后同一数据集的直方图。"
        }
    },
    {
        "translation": {
            "en": "The use of prior probabilities in Bayes’ Theorem is what distinguishes between Bayesian and maximum likelihood approaches to probability.",
            "zh": "在贝叶斯定理中使用先验概率是区分贝叶斯概率方法和最大似然方法的原因。"
        }
    },
    {
        "translation": {
            "en": "derivative, 765",
            "zh": "衍生物，765"
        }
    },
    {
        "translation": {
            "en": "LC record available at https://lccn.loc.gov/2020002998",
            "zh": "LC 记录可在 https://lccn.loc.gov/2020002998"
        }
    },
    {
        "translation": {
            "en": "The last step in deployment was to put in place an ongoing model validation plan to raise an alarm if evidence arose indicating that the deployed model had gone stale.",
            "zh": "部署的最后一步是制定一个持续的模型验证计划，以便在出现证据表明部署的模型已经过时时发出警报。"
        }
    },
    {
        "translation": {
            "en": "As with any other significant project, the chances of success for a predictive data analytics project are greatly increased if a standard process is used to manage the project through the project lifecycle.",
            "zh": "与任何其他重要项目一样，如果在整个项目生命周期中使用标准流程来管理项目，则预测性数据分析项目的成功机会将大大增加。"
        }
    },
    {
        "translation": {
            "en": "The backpropagation algorithm solves the blame assignment problem.",
            "zh": "反向传播算法解决了归咎分配问题。"
        }
    },
    {
        "translation": {
            "en": "When moving fast, the car moves forward two cells per time-step; when moving slowly the car moves forward one cell per time-step; and when stationary does not move forward at all.",
            "zh": "快速行驶时，汽车每时间步向前移动两个单元格;缓慢行驶时，汽车每时间步向前移动一个单元格;静止时根本不向前移动。"
        }
    },
    {
        "translation": {
            "en": "447.14",
            "zh": "447.14"
        }
    },
    {
        "translation": {
            "en": "The time it takes for the Markov chain to forget the initial random state is called the mixing time.",
            "zh": "马尔可夫链忘记初始随机状态所需的时间称为混合时间。"
        }
    },
    {
        "translation": {
            "en": "6.15   The LOAN AMOUNT continuous feature discretized into four equal-frequency bins.",
            "zh": "6.15 LOAN AMOUNT 连续特征离散化为四个等频箱。"
        }
    },
    {
        "translation": {
            "en": "This MDP captures the dynamics of the TwentyTwos game, and it also hints toward some strategies for successful play. For example, choosing to Stick when the value of the player’s hand is low and the value of the dealer’s hand is high, state PL-DH, rarely leads to the player winning, . The MDP alone, however, is not sufficient to describe optimal behavior for successfully playing the game. The next section describes how an MDP can be used as the basis for reasoning about optimal behavior.",
            "zh": "这个 MDP 捕捉了 TwentyTwos 游戏的动态，它还暗示了一些成功游戏的策略。例如，当玩家的手牌价值较低而庄家手牌的价值较高时选择坚持，状态PL-DH，很少会导致玩家获胜，。然而，仅靠 MDP 不足以描述成功玩游戏的最佳行为。下一节将介绍如何将 MDP 用作推理最佳行为的基础。"
        }
    },
    {
        "translation": {
            "en": "Recurrent networks also use weight sharing with the same weight matrices being reused at each time-step in a sequence.",
            "zh": "循环网络还使用权重共享，在序列中的每个时间步重用相同的权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "Mitchell, T. 1997. Machine learning. McGraw Hill.",
            "zh": "米切尔，T. 1997 年。机器学习。麦格劳·希尔。"
        }
    },
    {
        "translation": {
            "en": "An RGB image has three channels, and a grayscale image will have one channel.",
            "zh": "RGB 图像有三个通道，灰度图像将有一个通道。"
        }
    },
    {
        "translation": {
            "en": "The motivation for structuring these technical chapters in two parts is that it provides a natural break in the chapter material.",
            "zh": "将这些技术章节分为两部分的动机是，它为章节材料提供了一个自然的中断。"
        }
    },
    {
        "translation": {
            "en": "Black segments represent weights that have increased, and gray segments represent weights that have decreased (all segments for the distribution at the first iteration are white because they have done neither).",
            "zh": "黑色段表示已增加的权重，灰色段表示已减少的权重（第一次迭代时分布的所有段均为白色，因为它们两者都没有执行任何操作）。"
        }
    },
    {
        "translation": {
            "en": "CRISP-DM",
            "zh": "CRISP-DM型"
        }
    },
    {
        "translation": {
            "en": "fit, 315, 367",
            "zh": "适合， 315， 367"
        }
    },
    {
        "translation": {
            "en": "11.1   An agent behaving in an environment and the observation, reward, action cycle. The transition from observations of the environment to a state is shown by the state generation function, φ.",
            "zh": "11.1 智能体在环境中的行为以及观察、奖励、行动周期。从环境观察到状态的转变由状态生成函数 φ 表示。"
        }
    },
    {
        "translation": {
            "en": "AT already had a customer retention team proactively making interventions in an effort to reduce customer churn.",
            "zh": "AT已经有一个客户保留团队，积极主动地进行干预，以减少客户流失。"
        }
    },
    {
        "translation": {
            "en": "As a result, leaf nodes with small variance in the target feature values across the set of instances at the node are preferred over leaf nodes where the variance in the target feature values across the set of instances at the node is large.",
            "zh": "因此，节点上实例集的目标特征值方差较小的叶节点优先于节点上实例集的目标特征值方差较大的叶节点。"
        }
    },
    {
        "translation": {
            "en": "The agglomerative hierarchical clustering (AHC) algorithm is a simple, effective, bottom-up clustering approach that is driven by local structure within a dataset rather than a global expectation of what a cluster structure should be. A pseudocode description of the AHC algorithm is given in Algorithm 9[601].",
            "zh": "集聚分层聚类 （AHC） 算法是一种简单、有效、自下而上的聚类方法，它由数据集中的局部结构驱动，而不是对聚类结构的全局期望。AHC算法的伪代码描述在算法9[601]中给出。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we presented a range of measures of similarity, including distance metrics (such as the Euclidean, Manhattan, and Mahalanobis) and similarity indexes (such as the Russel-Rao, Sokal-Michener, Jaccard, and Cosine).",
            "zh": "在本章中，我们介绍了一系列相似度量，包括距离度量（如欧几里得、曼哈顿和马哈拉诺比斯）和相似性指数（如罗素-拉奥、索卡尔-米切纳、杰卡德和余弦）。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.26",
            "zh": "图 8.26"
        }
    },
    {
        "translation": {
            "en": "Notice that in this domain representation, we blend different approaches to continuous features: we are retaining the PDFs developed in Section 6.4.2[269] for the ACCOUNT BALANCE feature and extend the representation with the binned version of the LOAN AMOUNT feature, BINNED LOAN AMOUNT.",
            "zh": "请注意，在此域表示中，我们混合了连续功能的不同方法：我们保留了第 6.4.2 节中为 ACCOUNT BALANCE 功能开发的 PDF，并使用 LOAN AMOUNT 功能的 binned 版本 BINNED LOAN AMOUNT 扩展了表示。"
        }
    },
    {
        "translation": {
            "en": "These experiments were performed in Nancy and confirmed, to the satisfaction of everyone involved, that N rays did indeed exist.",
            "zh": "这些实验是在南锡进行的，并证实了N射线确实存在，这让所有参与者都感到满意。"
        }
    },
    {
        "translation": {
            "en": "A large set of historical labeled data is available for training the system.",
            "zh": "大量历史标记数据可用于训练系统。"
        }
    },
    {
        "translation": {
            "en": "Spercher, David A. 1965. On the structure of continuous functions of several variables. Transactions of teh American Mathematical Society 115 (3): 340–355.",
            "zh": "斯珀彻，大卫 A. 1965 年。关于几个变量的连续函数的结构。美国数学会学报 115 （3）：340–355。"
        }
    },
    {
        "translation": {
            "en": "To my family.",
            "zh": "给我的家人。"
        }
    },
    {
        "translation": {
            "en": "4. Have recorded any data quality issues due to valid data in a data quality plan along with potential handling strategies.",
            "zh": "4. 在数据质量计划中记录了由于有效数据而导致的任何数据质量问题以及可能的处理策略。"
        }
    },
    {
        "translation": {
            "en": "The observation period is the time before the claim event, across which the descriptive features capturing the claimant’s behavior are calculated, while the outcome period is the time immediately after the claim event, during which it will emerge whether the claim is fraudulent or genuine.",
            "zh": "观察期是索赔事件发生前的时间，在此期间计算捕获索赔人行为的描述性特征，而结果期是索赔事件发生后立即出现的时间，在此期间，索赔是欺诈性的还是真实的。"
        }
    },
    {
        "translation": {
            "en": "What is the overall lifetime value of a customer?",
            "zh": "客户的整体生命周期价值是多少？"
        }
    },
    {
        "translation": {
            "en": "The distribution defined by a Bayesian network doesn’t change during Gibbs sampling, so this requirement always holds in this context.",
            "zh": "贝叶斯网络定义的分布在吉布斯采样期间不会改变，因此此要求在此上下文中始终成立。"
        }
    },
    {
        "translation": {
            "en": "We can continue to build the tree by recursively extending each branch as we did in the previous decision tree examples.",
            "zh": "我们可以通过递归扩展每个分支来继续构建树，就像我们在前面的决策树示例中所做的那样。"
        }
    },
    {
        "translation": {
            "en": "For every possible combination of weights, w[0] and w[1], there is a corresponding sum of squared errors value.",
            "zh": "对于权重 w[0] 和 w[1] 的每个可能组合，都有一个相应的误差值的平方和。"
        }
    },
    {
        "translation": {
            "en": "In preparation for this campaign, the financial institution has decided to create a nearest neighbor model using a Euclidean distance metric to predict which customers are most likely to respond to direct marketing.",
            "zh": "为了准备此活动，该金融机构决定使用欧几里得距离度量创建一个最近邻模型，以预测哪些客户最有可能对直接营销做出反应。"
        }
    },
    {
        "translation": {
            "en": "Table 6.5[266] lists the relevant probabilities needed to make a prediction for this query, and the calculation of the scores for each of the possible target levels.",
            "zh": "表 6.5[266] 列出了对此查询进行预测所需的相关概率，以及每个可能的目标水平的分数计算。"
        }
    },
    {
        "translation": {
            "en": "9.4.3.2 Kolmogorov-Smirnov statistic The Kolmogorov-Smirnov statistic (K-S statistic) is another performance measure that captures the separation between the distribution of prediction scores for the different target levels in a classification problem. To calculate the K-S statistic, we first determine the cumulative probability distributions of the prediction scores for the positive and negative target levels. This is done as follows:",
            "zh": "9.4.3.2 Kolmogorov-Smirnov 统计量 Kolmogorov-Smirnov 统计量（K-S 统计量）是另一种性能度量，用于捕获分类问题中不同目标水平的预测分数分布之间的分离。为了计算 K-S 统计量，我们首先确定正负目标水平的预测分数的累积概率分布。具体操作如下："
        }
    },
    {
        "translation": {
            "en": "domain concept, 23, 30, 45, 688, 689, 707",
            "zh": "域概念， 23， 30， 45， 688， 689， 707"
        }
    },
    {
        "translation": {
            "en": "Table 4.6",
            "zh": "表 4.6"
        }
    },
    {
        "translation": {
            "en": "Categorical cross entropy is another loss function that is commonly used for classification models. Categorical cross entropy is defined as",
            "zh": "分类交叉熵是另一个常用于分类模型的损失函数。分类交叉熵定义为"
        }
    },
    {
        "translation": {
            "en": "Scaling a weight update using a learning rate works because the error derivative defines only the direction the weight update should take and not the update size; and, scaling by the learning rate changes only the step size and not the direction of the update.",
            "zh": "使用学习率缩放权重更新是有效的，因为误差导数仅定义权重更新应采取的方向，而不是更新大小;而且，按学习率缩放只会改变步长，而不会改变更新的方向。"
        }
    },
    {
        "translation": {
            "en": "Consequently, for a categorical feature with N levels, we need only N − 1 probabilities in each row, with the final probability being understood as equal to 1 minus the sum of the other N − 1 probabilities.",
            "zh": "因此，对于具有 N 个水平的分类特征，我们只需要每行 N − 1 个概率，最终概率被理解为等于 1 减去其他 N − 1 个概率的总和。"
        }
    },
    {
        "translation": {
            "en": "If we have sampled our weights from a distribution with mean 0, then E(W) = 0, and if the inputs have been standardized, then E(d) = 0, and so the Equation (8.56)[455] simplifies to",
            "zh": "如果我们从均值为 0 的分布中抽取权重，则 E（W） = 0，如果输入已标准化，则 E（d） = 0，因此方程 （8.56）[455] 简化为"
        }
    },
    {
        "translation": {
            "en": "Once a threshold has been set, the continuous feature can compete with the other categorical features for selection as the splitting feature at any node.",
            "zh": "设置阈值后，连续特征可以与其他分类特征竞争，以选择作为任何节点的分割特征。"
        }
    },
    {
        "translation": {
            "en": "SVM models are trained in a slightly different way than regression models, but the concepts underpinning both approaches are similar.",
            "zh": "SVM 模型的训练方式与回归模型略有不同，但支持这两种方法的概念是相似的。"
        }
    },
    {
        "translation": {
            "en": "6. Stoughton et al. (2002) provides an in-depth discussion of the data collected by the SDSS. A shorter overview is provided at skyserver.sdss3.org/dr9/en/sdss/data/data.asp.",
            "zh": "6. Stoughton等人（2002年）对SDSS收集的数据进行了深入讨论。skyserver.sdss3.org/dr9/en/sdss/data/data.asp 提供了较短的概述。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.20[358] shows three one-versus-all prediction models for a prediction problem with three target levels (these models are based on the dataset in Table 7.11[359] that is introduced subsequently in this section).",
            "zh": "图 7.20[358] 显示了具有三个目标水平的预测问题的三种一对一预测模型（这些模型基于表 7.11[359] 中的数据集，该数据集将在本节后面介绍）。"
        }
    },
    {
        "translation": {
            "en": "concept drift, 232, 578, 579, 657, 727",
            "zh": "概念漂移， 232， 578， 579， 657， 727"
        }
    },
    {
        "translation": {
            "en": "Another factor that can help us deal with the curse of dimensionality is that some learning algorithms have a natural resistance to the problem.",
            "zh": "另一个可以帮助我们应对维度诅咒的因素是，一些学习算法对这个问题有一种天然的抵抗力。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.6",
            "zh": "图 5.6"
        }
    },
    {
        "translation": {
            "en": "soft margin, 366",
            "zh": "软边距，366"
        }
    },
    {
        "translation": {
            "en": "15. The reuse of the term batch in mini-batch learning can lead to confusion. To clarify the distinctive meanings: the terms batch learning or batch gradient descent typically indicate that the entire training set is processed between each weight update, whereas the term batch can also be used to indicate a set of examples in a mini-batch training regime (as in a batch of examples), and the term batch size describes the number of examples in each batch (or mini-batch).",
            "zh": "15. 在小批量学习中重复使用术语“批处理”会导致混淆。为了阐明不同的含义：术语“批量学习”或“批量梯度下降”通常表示在每次权重更新之间处理整个训练集，而术语“批处理”也可用于表示小批量训练制度中的一组示例（如在一批示例中），术语“批量大小”描述了每个批次（或小批量）中的示例数量。"
        }
    },
    {
        "translation": {
            "en": "Breiman, Leo. 2001. Random forests. Machine Learning 45 (1): 5–32.",
            "zh": "布莱曼，狮子座。2001. 随机森林.机器学习 45 （1）：5–32。"
        }
    },
    {
        "translation": {
            "en": "FNR, 548",
            "zh": "FNR，548"
        }
    },
    {
        "translation": {
            "en": "3. The following table lists a sample of data from a census.38",
            "zh": "3. 下表列出了人口普查的数据样本38。"
        }
    },
    {
        "translation": {
            "en": "By convex we mean that the error surfaces are shaped like a bowl.",
            "zh": "我们所说的凸是指误差面的形状像一个碗。"
        }
    },
    {
        "translation": {
            "en": "5.21   A duck-billed platypus.",
            "zh": "5.21 鸭嘴兽。"
        }
    },
    {
        "translation": {
            "en": "The GUARANTOR/COAPPLICANT feature records whether the loan applicant has a guarantor or coapplicant associated with the application.",
            "zh": "担保人/共同申请人功能记录贷款申请人是否有与申请相关的担保人或共同申请人。"
        }
    },
    {
        "translation": {
            "en": "-0.1981",
            "zh": "-0.1981"
        }
    },
    {
        "translation": {
            "en": "Equation (8.21)[411] illustrates the calculation of δk for neuron k in the output layer.",
            "zh": "方程（8.21）[411]说明了输出层中神经元k的δk计算。"
        }
    },
    {
        "translation": {
            "en": "Once the model has been trained we do not use dropout. Using dropout during inference would introduce random noise to the inference process. Dropout is both simple and very effective, and applying dropout is standard practice in most deep learning research today. The ρ parameter is a hyper-parameter that is preset before training. Typical values for ρ are 0.8 for the input layer, and 0.5 for hidden layers (Goodfellow et al., 2016, p. 253).",
            "zh": "一旦模型被训练，我们就不会使用dropout。在推理过程中使用辍学会给推理过程带来随机噪声。辍学既简单又非常有效，应用辍学是当今大多数深度学习研究的标准做法。ρ 参数是在训练前预设的超参数。输入层的 ρ 典型值为 0.8，隐藏层的 ρ 值为 0.5（Goodfellow 等人，2016 年，第 253 页）。"
        }
    },
    {
        "translation": {
            "en": "(a) What is the prediction subject for the model that will be trained using this ABT?",
            "zh": "（a） 将使用此 ABT 训练的模型的预测主题是什么？"
        }
    },
    {
        "translation": {
            "en": "The impact of the clamp transformation should then be evaluated by comparing the performance of different models trained on datasets where the transformation has been applied and where it has not.",
            "zh": "然后，应通过比较在已应用和未应用转换的数据集上训练的不同模型的性能来评估钳位变换的影响。"
        }
    },
    {
        "translation": {
            "en": "However, even when we use a learning rate to scale updates, large weights can still result in exploding gradients, which in turn result in inappropriately large weight updates.",
            "zh": "然而，即使我们使用学习率来缩放更新，大权重仍然会导致梯度爆炸，进而导致不适当的大权重更新。"
        }
    },
    {
        "translation": {
            "en": "In some cases we wish to refer to the vector of δs for the neurons in a layer l; in these cases we write δ(l)",
            "zh": "在某些情况下，我们希望参考层 l 中神经元的 δs 向量;在这些情况下，我们写δ（l）"
        }
    },
    {
        "translation": {
            "en": "A grayscale image of a 4 after padding has been applied to the original 6-by-6 matrix representation, and the local receptive field of a neuron that includes both valid and padded pixels.",
            "zh": "填充后 4 的灰度图像已应用于原始 6×6 矩阵表示，以及包含有效像素和填充像素的神经元的局部感受野。"
        }
    },
    {
        "translation": {
            "en": "where CP(positive, ps) and CP(negative, ps) are as described above.",
            "zh": "其中 CP（正，ps）和 CP（负，ps）如上所述。"
        }
    },
    {
        "translation": {
            "en": "The techniques described in this chapter cover the Business Understanding, Data Understanding, and (partially) Data Preparation phases of the CRISP-DM process.",
            "zh": "本章中介绍的技术涵盖了 CRISP-DM 流程的业务理解、数据理解和（部分）数据准备阶段。"
        }
    },
    {
        "translation": {
            "en": "In this section we motivate and explain the key architectural characteristics of convolutional neural networks (or CNNs) which are primarily tailored to process grid like data, such as image data.",
            "zh": "在本节中，我们将激励和解释卷积神经网络（CNN）的关键架构特征，这些网络主要用于处理类似网格的数据，例如图像数据。"
        }
    },
    {
        "translation": {
            "en": "Everything else about the process was the same as before.",
            "zh": "关于该过程的其他一切都与以前相同。"
        }
    },
    {
        "translation": {
            "en": "Also, W(2) and W(1) can be replaced by the matrix that is generated by their product; letting W′ = W(2)W(1) we get",
            "zh": "此外，W（2） 和 W（1） 可以替换为由其乘积生成的矩阵;让 W′ = W（2）W（1） 我们得到"
        }
    },
    {
        "translation": {
            "en": "Figure 3.4[63] illustrates this rule.",
            "zh": "图3.4[63]说明了这一规则。"
        }
    },
    {
        "translation": {
            "en": "interacting features, 227",
            "zh": "交互功能，227"
        }
    },
    {
        "translation": {
            "en": "2.2   Assessing Feasibility",
            "zh": "2.2 评估可行性"
        }
    },
    {
        "translation": {
            "en": "Figure 7.23(b)[364] shows the position of two new query instances for this problem.",
            "zh": "图 7.23（b）[364] 显示了此问题的两个新查询实例的位置。"
        }
    },
    {
        "translation": {
            "en": "This ranking of the features by information gain mirrors the intuitions that we developed about the usefulness of these features during our previous discussion.",
            "zh": "这种按信息增益对特征进行排序的做法反映了我们在前面的讨论中对这些特征的有用性所形成的直觉。"
        }
    },
    {
        "translation": {
            "en": "In Figure 11.1[639] we show how the observations made about the environment at time-step t are converted into a state, st, using a state generation function, ϕ.",
            "zh": "在图11.1[639]中，我们展示了如何使用状态生成函数φ在时间步长t处对环境的观察转换为状态st。"
        }
    },
    {
        "translation": {
            "en": "7. The product rule is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "7. 产品规则详见附录B[757]第B.3[762]节。"
        }
    },
    {
        "translation": {
            "en": "Probability theory underpins a great deal of machine learning.",
            "zh": "概率论是大量机器学习的基础。"
        }
    },
    {
        "translation": {
            "en": "20. For example, the R language provides the fitdistr() method, as part of the MASS package, that implements a maximum-likelihood fitting of a number of univariate distributions to a given dataset.",
            "zh": "20. 例如，R 语言提供了 fitdistr（） 方法，作为 MASS 包的一部分，该方法实现了对给定数据集的多个单变量分布的最大似然拟合。"
        }
    },
    {
        "translation": {
            "en": "The direction and magnitude of the adjustment to be made to a weight is determined by the gradient of the error surface at the current position in the weight space.",
            "zh": "对权重进行调整的方向和幅度由权重空间中当前位置的误差曲面梯度决定。"
        }
    },
    {
        "translation": {
            "en": "(e) Calculate the information gain ratio (based on entropy) for EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "（e） 计算教育、婚姻状况和职业特征的信息增益比（基于熵）。"
        }
    },
    {
        "translation": {
            "en": "This is what makes auto-encoders useful for representation learning.",
            "zh": "这就是自动编码器对表示学习有用的原因。"
        }
    },
    {
        "translation": {
            "en": "27. The most common way to achieve this for the other model types covered in this book is to impute the missing values in the query instance using one of the techniques described in Section 3.4.1[69].",
            "zh": "27. 对于本书中介绍的其他模型类型，最常见的方法是使用第 3.4.1 节[69]中描述的技术之一插补查询实例中的缺失值。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.5",
            "zh": "图 9.5"
        }
    },
    {
        "translation": {
            "en": "As with everything else, there is an application-specific component to the selection of an experimental design—for example, out-of-time sampling is a good choice in scenarios where a time dimension is important.",
            "zh": "与其他所有事情一样，在选择实验设计时有一个特定于应用的组件，例如，在时间维度很重要的场景中，超时采样是一个不错的选择。"
        }
    },
    {
        "translation": {
            "en": "The following rules of thumb may be useful (although the usual caveats that all scenarios are slightly different apply).",
            "zh": "以下经验法则可能很有用（尽管所有方案都略有不同的通常警告适用）。"
        }
    },
    {
        "translation": {
            "en": "Rousseeuw, Peter J. 1987. Silhouettes: A graphical aid to the interpretation and validation of cluster analysis. Journal of computational and applied mathematics 20: 53–65.",
            "zh": "Rousseeuw，Peter J. 1987 年。Silhouettes：用于解释和验证聚类分析的图形辅助工具。计算与应用数学杂志 20：53-65。"
        }
    },
    {
        "translation": {
            "en": "To explain the relationship between the weighted sum calculation and the phenomena of vanishing and exploding z and δ values, we will analyze the relationship between the variance of z for a single neuron in the first hidden layer of a network and the variance of the weights used in calculating that z.",
            "zh": "为了解释加权和计算与z和δ值消失和爆炸现象之间的关系，我们将分析网络第一隐藏层中单个神经元的z方差与计算该z的权重方差之间的关系。"
        }
    },
    {
        "translation": {
            "en": "After selection of the initial cluster centroids, the next step step in the algorithm is to calculate the Euclidean distance from each instance in the dataset to each cluster centroid.",
            "zh": "选择初始聚类质心后，算法的下一步是计算数据集中每个实例到每个聚类质心的欧几里得距离。"
        }
    },
    {
        "translation": {
            "en": "This example network has two neurons in the input layer (Neurons 1 and 2), three neurons in the hidden layer (Neurons 3, 4, and 5), and two neurons in the output layer (Neurons 6 and 7).",
            "zh": "此示例网络在输入层中有两个神经元（神经元 1 和 2），在隐藏层中有三个神经元（神经元 3、4 和 5），在输出层中有两个神经元（神经元 6 和 7）。"
        }
    },
    {
        "translation": {
            "en": "In this way the limited claims investigation time could be targeted at the claims that are most likely to be fraudulent, thereby increasing the number of fraudulent claims detected and reducing the amount of money lost to fraud.",
            "zh": "这样一来，有限的索赔调查时间就可以针对最有可能是欺诈性的索赔，从而增加发现的欺诈性索赔数量，减少因欺诈而损失的金额。"
        }
    },
    {
        "translation": {
            "en": "For a well-performing model, the lift curve should start well above 1.0 and cross 1.0 at one of the lower deciles.",
            "zh": "对于性能良好的模型，提升曲线应从远高于 1.0 开始，并在较低的十分位数之一处越过 1.0。"
        }
    },
    {
        "translation": {
            "en": "Once the δs for Neurons 6 and 7 have been calculated, we are ready to propagate the error gradients back to the first hidden layer. The process used to calculate the δs for Neurons 3, 4, and 5 is the same as that used to calculate δ6 and δ7. Equation (8.35)[429] steps through this calculation for δ 3, Equation (8.36)[429] shows the calculation of δ4, and Equation (8.37)[429] lists the calculations of δ5",
            "zh": "一旦计算了神经元 6 和 7 的 δ，我们就可以将误差梯度传播回第一个隐藏层。用于计算神经元 3、4 和 5 的 δ 的过程与用于计算 δ6 和 δ7 的过程相同。方程（8.35）[429]逐步计算δ 3，方程（8.36）[429]显示了δ4的计算，方程（8.37）[429]列出了δ5的计算"
        }
    },
    {
        "translation": {
            "en": "10.4.1 Choosing Initial Cluster Centroids",
            "zh": "10.4.1 选择初始聚类质心"
        }
    },
    {
        "translation": {
            "en": "These cycles, or recurrent links, are the reason these networks are called recurrent networks.",
            "zh": "这些循环或循环链接是这些网络被称为循环网络的原因。"
        }
    },
    {
        "translation": {
            "en": "regression tree, 149, 165",
            "zh": "回归树， 149， 165"
        }
    },
    {
        "translation": {
            "en": "For example, all the bin3 values have a target feature value of false.",
            "zh": "例如，所有 bin3 值的目标特征值均为 false。"
        }
    },
    {
        "translation": {
            "en": "ETL, 42",
            "zh": "ETL，42"
        }
    },
    {
        "translation": {
            "en": "The network in Figure 6.9(a)[287] could be simplified in this way, and we will use this simplification for all networks drawn from now on.",
            "zh": "图6.9（a）[287]中的网络可以这样简化，我们将把这种简化用于从现在开始绘制的所有网络。"
        }
    },
    {
        "translation": {
            "en": "EXAMPLE",
            "zh": "例"
        }
    },
    {
        "translation": {
            "en": "The shape of the curve is determined by (a) the statistical distribution that is used to define the PDF, and (b) the values of the statistical distribution parameters.",
            "zh": "曲线的形状由 （a） 用于定义 PDF 的统计分布和 （b） 统计分布参数的值确定。"
        }
    },
    {
        "translation": {
            "en": "Boltzmann action selection, 658",
            "zh": "玻尔兹曼动作选择，658"
        }
    },
    {
        "translation": {
            "en": "-0.02990",
            "zh": "-0.02990"
        }
    },
    {
        "translation": {
            "en": "the rate of change of the weighted sum function with respect to changes in one of the weights (∂zi/∂wi,k);",
            "zh": "加权和函数相对于其中一个权重变化的变化率 （∂zi/∂wi，k）;"
        }
    },
    {
        "translation": {
            "en": "CLAIMS 3 MONTHS; AVERAGE CLAIMS PER YEAR BY CLAIMANT: AVG.",
            "zh": "索赔 3 个月;索赔人每年的平均索赔额：平均。"
        }
    },
    {
        "translation": {
            "en": "“When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.”",
            "zh": "“当我看到一只鸟走路像鸭子，像鸭子一样游泳，像鸭子一样嘎嘎叫时，我就称那只鸟为鸭子。”"
        }
    },
    {
        "translation": {
            "en": "As we mentioned previously, this is similar to the way the error gradients for shared weights in a convolutional neural network are summed, and then the weight is updated once using this summed gradient.",
            "zh": "正如我们之前提到的，这类似于卷积神经网络中共享权重的误差梯度求和的方式，然后使用此求和梯度更新权重。"
        }
    },
    {
        "translation": {
            "en": "The expectation is that a linear separating hyperplane will exist in this higher-dimensional space even though it does not in the original feature space.",
            "zh": "期望是线性分离超平面将存在于这个高维空间中，即使它不在原始特征空间中。"
        }
    },
    {
        "translation": {
            "en": "0.5520",
            "zh": "0.5520"
        }
    },
    {
        "translation": {
            "en": "The final model trained is",
            "zh": "训练的最终模型是"
        }
    },
    {
        "translation": {
            "en": "Public companies also must file public documents every year that outline how they have been performing, details of any changes in directorship, and so on.",
            "zh": "上市公司还必须每年提交公开文件，概述他们的表现、董事职位任何变化的细节等。"
        }
    },
    {
        "translation": {
            "en": "CALLMINUTESCHANGEPCT",
            "zh": "CALLMINUTESCHANGEPCT"
        }
    },
    {
        "translation": {
            "en": "It is a good idea to add suggestions for the best technique to handle each data quality issue in the data quality plan during data exploration as it will save time during modeling.",
            "zh": "在数据浏览期间，最好添加有关处理数据质量计划中每个数据质量问题的最佳技术的建议，因为这将节省建模期间的时间。"
        }
    },
    {
        "translation": {
            "en": "For an illustrative example of Bayes’ Theorem in action, imagine that after a yearly checkup, a doctor informs a patient that there is both bad news and good news.",
            "zh": "对于贝叶斯定理的一个说明性例子，想象一下，在每年一次的检查之后，医生告诉病人，既有坏消息也有好消息。"
        }
    },
    {
        "translation": {
            "en": "A binary dataset listing the behavior of two individuals on a website during a trial period and whether they subsequently signed up for the website.",
            "zh": "一个二进制数据集，列出了两个人在试用期间在网站上的行为，以及他们随后是否注册了该网站。"
        }
    },
    {
        "translation": {
            "en": "By using basis functions such as those given in the examples in this section, we relax the restriction on the algorithm to consider only linear models and instead allow more complex model types such as the higher-order polynomial models seen in these examples.",
            "zh": "通过使用本节示例中给出的基函数，我们放宽了对算法的限制，只考虑线性模型，而是允许更复杂的模型类型，例如这些示例中看到的高阶多项式模型。"
        }
    },
    {
        "translation": {
            "en": "We can also add instances to the tree after if has been created.",
            "zh": "我们还可以在创建 if 后将实例添加到树中。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the algorithm is sensitive to noise because any errors in the description or labeling of training data results in erroneous local models and hence incorrect predictions.",
            "zh": "因此，该算法对噪声很敏感，因为训练数据的描述或标记中的任何错误都会导致错误的局部模型，从而导致错误的预测。"
        }
    },
    {
        "translation": {
            "en": "5.7   The updated version of Table 5.6[206] once we have applied range normalization to the SALARY and AGE features in the dataset and to the query instance.",
            "zh": "5.7 表 5.6[206] 的更新版本，一旦我们将范围归一化应用于数据集中的 SALARY 和 AGE 特征以及查询实例。"
        }
    },
    {
        "translation": {
            "en": "Each time a node is updated, a new sample state has been generated.",
            "zh": "每次更新节点时，都会生成一个新的示例状态。"
        }
    },
    {
        "translation": {
            "en": "4.2   Fundamentals",
            "zh": "4.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "The new weights result in slightly more accurate predictions, evident from the slightly reduced sum of squared errors of 12.0262.",
            "zh": "新的权重导致预测更加准确，这从12.0262的平方误差总和略有减少中可以看出。"
        }
    },
    {
        "translation": {
            "en": "TN and FN are defined similarly.",
            "zh": "TN 和 FN 的定义类似。"
        }
    },
    {
        "translation": {
            "en": "Frequently, in discussing deep learning we use an elementwise product of two matrices, known as the Hadamard product. The symbol ⊙ denotes the Hadamard product, and the Hadamard product of two matrices D and E is written D ⊙ E. The Hadamard product assumes that both matrices have the same dimensions, and it produces a matrix with the same dimensions as the two inputs. Each value in the resulting matrix is the product of the corresponding cells in the two input matrices:",
            "zh": "在讨论深度学习时，我们经常使用两个矩阵的元素乘积，称为 Hadamard 积。符号 ⊙ 表示 Hadamard 乘积，两个矩阵 D 和 E 的 Hadamard 乘积写为 D ⊙ E。Hadamard 乘积假设两个矩阵具有相同的维度，并生成一个与两个输入具有相同维度的矩阵。结果矩阵中的每个值都是两个输入矩阵中相应单元格的乘积："
        }
    },
    {
        "translation": {
            "en": "Often, however, the observation period and outcome period will be measured over different dates for each prediction subject.",
            "zh": "然而，通常，观察期和结果期将在每个预测对象的不同日期进行测量。"
        }
    },
    {
        "translation": {
            "en": "As such, pruning can be viewed as a noise dampening mechanism that removes nodes that have been created because of a small set of noisy instances.",
            "zh": "因此，修剪可以被视为一种噪声抑制机制，它删除了由于一小组噪声实例而创建的节点。"
        }
    },
    {
        "translation": {
            "en": "The approach to training multivariable linear regression models described so far is more specifically known as batch gradient descent.",
            "zh": "到目前为止描述的训练多变量线性回归模型的方法更具体地称为批次梯度下降。"
        }
    },
    {
        "translation": {
            "en": "4.2.1   Decision Trees",
            "zh": "4.2.1 决策树"
        }
    },
    {
        "translation": {
            "en": "Spectral clustering (Ng et al., 2002) is another approach worth investigating, and for very large spatial datasets, the DBScan (Ester et al., 1996) can be a good approach.",
            "zh": "光谱聚类（Ng et al.， 2002）是另一种值得研究的方法，对于非常大的空间数据集，DBScan （Ester et al.， 1996）可能是一个很好的方法。"
        }
    },
    {
        "translation": {
            "en": "If the number of levels of one of the features being compared is small (we recommend no more than three), we can use stacked bar plots as an alternative to the small multiples bar plots approach.",
            "zh": "如果被比较的其中一个特征的层级数很小（我们建议不超过三个），我们可以使用堆积条形图作为小倍数条形图方法的替代方法。"
        }
    },
    {
        "translation": {
            "en": "One way of addressing this issue is to use information gain ratio instead of entropy.",
            "zh": "解决这个问题的一种方法是使用信息增益比而不是熵。"
        }
    },
    {
        "translation": {
            "en": "26. If we have a very large dataset, we may—for computational reasons—want to create bootstrap samples that are smaller than the original dataset. If this is the case, then sampling without replacement is preferred. This is known as subagging.",
            "zh": "26. 如果我们有一个非常大的数据集，出于计算原因，我们可能想要创建比原始数据集小的引导样本。如果是这种情况，则首选不更换的采样。这称为下坡。"
        }
    },
    {
        "translation": {
            "en": "1. We divide by n − 1 (as opposed to n) because we are calculating the variance using only a sample, and on average, dividing by n − 1 gives a better estimate of the population variance than using n.",
            "zh": "1. 我们除以 n − 1（而不是 n），因为我们只使用样本计算方差，平均而言，除以 n − 1 比使用 n 更好地估计总体方差。"
        }
    },
    {
        "translation": {
            "en": "Larger graphs will tend to have longer mixing times.",
            "zh": "较大的图形往往具有更长的混合时间。"
        }
    },
    {
        "translation": {
            "en": "The original baseline target frequencies are based on the predictions in Table 9.18[573] and are visualized in Figure 9.18(a)[582].",
            "zh": "原始基线目标频率基于表9.18[573]中的预测，并在图9.18（a）[582]中可视化。"
        }
    },
    {
        "translation": {
            "en": "The r one-versus-all logistic regression models used are trained in parallel, and the revised model outputs, ′wk(d), are used in calculating the sum of squared errors for each model during the training process.",
            "zh": "所使用的 r 一对全逻辑回归模型是并行训练的，修订后的模型输出 ′wk（d） 用于计算训练过程中每个模型的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "To perform binning, we define a series of ranges (called bins) for the continuous feature that correspond to the levels of the new categorical feature we are creating.",
            "zh": "为了执行分箱，我们为连续特征定义了一系列范围（称为条柱），这些范围对应于我们正在创建的新分类特征的级别。"
        }
    },
    {
        "translation": {
            "en": "The standard deviation of the heights of the players on the first basketball team is 7.945 and for the second team is 31.803. As these measures are in the same units as the heights, they afford us a more intuitive understanding of the data and make comparison easier. We can say that, on average, players on the first team vary by almost 8cm from the average of 149.375cm, while on the second team, they vary by approximately 32cm.",
            "zh": "第一篮球队球员身高的标准差为7.945，第二篮球队为31.803。由于这些度量与高度的单位相同，因此它们使我们能够更直观地理解数据，并使比较更容易。可以说，平均而言，一线队的球员与平均 149.375 厘米相差近 8 厘米，而在二队中，他们相差约 32 厘米。"
        }
    },
    {
        "translation": {
            "en": "(a) Three normal distributions with different means but identical standard deviations; and (b) three normal distributions with identical means but different standard deviations.",
            "zh": "（a） 均值不同但标准差相同的三种正态分布;（b）均值相同但标准差不同的三种正态分布。"
        }
    },
    {
        "translation": {
            "en": "Before this action Q(6-5,left) gave an expected return from the action-value table of − 0.267.",
            "zh": "在此操作之前，Q（6-5，左）从操作值表中给出了 − 0.267 的预期回报。"
        }
    },
    {
        "translation": {
            "en": "It is that simple!",
            "zh": "就是这么简单！"
        }
    },
    {
        "translation": {
            "en": "At this point Jocelyn was primarily interested in understanding the amount of data available, any issues that might arise from missing values, and the types of each column in the dataset.",
            "zh": "此时，Jocelyn 主要感兴趣的是了解可用数据量、缺失值可能引起的任何问题以及数据集中每列的类型。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the conditional independence assumption enables us to factorize the distribution of the domain, and consequently we need fewer probabilities with fewer constraints to represent the domain.",
            "zh": "此外，条件独立性假设使我们能够分解域的分布，因此我们需要更少的概率和更少的约束来表示域。"
        }
    },
    {
        "translation": {
            "en": "If the error rate at the subtree root node is less than or equal to the combined error rate at the leaves, the subtree is pruned.",
            "zh": "如果子树根节点处的错误率小于或等于叶子处的组合错误率，则修剪子树。"
        }
    },
    {
        "translation": {
            "en": "However, randomly sampling each mini-batch from a very large dataset may be impractical.",
            "zh": "但是，从非常大的数据集中随机抽样每个小批量可能是不切实际的。"
        }
    },
    {
        "translation": {
            "en": "A Markov chain is ergodic if every state is reachable from every other state and there are no cycles in the chain.",
            "zh": "如果每个状态都可以从其他每个状态到达并且链中没有循环，则马尔可夫链是遍历的。"
        }
    },
    {
        "translation": {
            "en": "Because of the size of the ABT, Jocelyn decided to split the dataset into a training set and a large hold-out test set.",
            "zh": "由于 ABT 的大小，Jocelyn 决定将数据集拆分为训练集和大型保持测试集。"
        }
    },
    {
        "translation": {
            "en": "Again, the error gradients for a weight are summed and then the weight is updated once.",
            "zh": "同样，将权重的误差梯度相加，然后对权重进行一次更新。"
        }
    },
    {
        "translation": {
            "en": "This chapter also adopts the two-part structure of standard approach followed by extensions and variations.",
            "zh": "本章还采用了标准方法的两部分结构，然后是扩展和变化。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.11(a)[341] illustrates the consistent relationship between Equation (7.23)[339] and the decision boundary by plotting the value of Equation (7.23)[339] for all values of RPM and VIBRATION.12",
            "zh": "图7.11（a）[341]通过绘制所有RPM和VIBRATION值的等式（7.23）[339]的值，说明了等式（7.23）[339]与决策边界之间的一致关系12。"
        }
    },
    {
        "translation": {
            "en": "At this point 𝒟8 is the only partition that is not a pure set. There are two descriptive features that can be used to split 𝒟8: STREAM and SLOPE. The decision regarding which of these features to use for the split is made by calculating which feature has the higher information gain for 𝒟8. The overall entropy for 𝒟8 is calculated",
            "zh": "此时，D8 是唯一不是纯集的分区。有两个描述性特征可用于拆分 D8：STREAM 和 SLOPE。通过计算哪个特征对 D8 具有更高的信息增益，可以决定使用这些特征中的哪一个进行拆分。计算 D8 的总熵"
        }
    },
    {
        "translation": {
            "en": "6.19   Examples of the samples generated using Gibbs sampling.",
            "zh": "6.19 使用吉布斯抽样生成的样本示例。"
        }
    },
    {
        "translation": {
            "en": "Regardless of the binning approach used, once the values for a continuous feature have been binned, the continuous feature is discarded and replaced by a categorical feature, which has a level for each bin—the bin numbers can be used, or a more meaningful label can be manually generated.",
            "zh": "无论使用何种分箱方法，一旦连续要素的值被分箱，连续要素将被丢弃并替换为分类要素，该分类要素对每个条柱都有一个级别 - 可以使用条柱编号，也可以手动生成更有意义的标注。"
        }
    },
    {
        "translation": {
            "en": "3. We use some simple elements of probability theory in this chapter. Readers unfamiliar with the way probabilities are calculated based on the relative frequencies of events should read the first section of Appendix B[757] before continuing with this chapter.",
            "zh": "3. 在本章中，我们使用了概率论的一些简单元素。不熟悉根据事件的相对频率计算概率的读者，在继续本章之前，应阅读附录B[757]的第一部分。"
        }
    },
    {
        "translation": {
            "en": "Using this model, the company could save on claims investigations and reduce the amount of money paid out on fraudulent claims.",
            "zh": "使用这种模式，公司可以节省索赔调查费用，并减少欺诈性索赔的金额。"
        }
    },
    {
        "translation": {
            "en": "These under-sampled groups are then combined to create the overall under-sampled dataset.",
            "zh": "然后将这些欠采样组组合在一起，以创建整体欠采样数据集。"
        }
    },
    {
        "translation": {
            "en": "heating load prediction, 371",
            "zh": "热负荷预测，371"
        }
    },
    {
        "translation": {
            "en": "This is why that ELEVATION feature is listed in both the partitions (7 and 8) shown in Figure 4.13[149].",
            "zh": "这就是为什么图 4.13[149] 所示的两个分区（7 和 8）中都列出了 ELEVATION 特征的原因。"
        }
    },
    {
        "translation": {
            "en": "error function, 312, 315, 315, 367, 409",
            "zh": "错误函数， 312， 315， 315， 367， 409"
        }
    },
    {
        "translation": {
            "en": "𝕄w(d) refers to the output of a model 𝕄 parameterized by parameters w for descriptive features d.",
            "zh": "Mw（d） 是指模型 M 的输出，由描述性特征 d 的参数 w 参数化。"
        }
    },
    {
        "translation": {
            "en": "For example:",
            "zh": "例如："
        }
    },
    {
        "translation": {
            "en": "In contrast with Table 5.6[206], where there was a close match between the SALARY and AGE distances and the SALARY only distances and related rankings, in Table 5.7[208] there is much more variation between the SALARY and AGE distances and the SALARY only distances.",
            "zh": "与表5.6[206]相比，SALARY 和 AGE 距离与仅 SALARY 距离和相关排名之间的匹配度非常接近，而在表 5.7[208] 中，SALARY 和 AGE 距离以及仅 SALARY 距离之间的差异要大得多。"
        }
    },
    {
        "translation": {
            "en": "9.4.1   Designing Evaluation Experiments",
            "zh": "9.4.1 设计评估实验"
        }
    },
    {
        "translation": {
            "en": "What makes this approach really attractive is that, although this new model stated in terms of basis functions captures the non-linear relationship between rainfall and grass growth, the model is still linear in terms of the weights and so can be trained using gradient descent without making any changes to the algorithm. Figure 7.17[354] shows the final non-linear model that results from this training process, along with a number of the interim steps on the way to this model. The final model is",
            "zh": "这种方法真正吸引人的是，尽管这个新模型在基函数方面捕获了降雨和草生长之间的非线性关系，但该模型在权重方面仍然是线性的，因此可以使用梯度下降进行训练，而无需对算法进行任何更改。图 7.17[354] 显示了该训练过程产生的最终非线性模型，以及通往该模型的一些过渡步骤。最终模型是"
        }
    },
    {
        "translation": {
            "en": "Organizations don’t exist to do predictive data analytics.",
            "zh": "组织不存在进行预测性数据分析。"
        }
    },
    {
        "translation": {
            "en": "The net effect of this is that instance d1 is now ranked as the nearest neighbor to the query—this is in line with the feature space representation in Figure 5.12(b)[205].",
            "zh": "这样做的最终结果是，实例 d1 现在被列为查询的最近邻域，这与图 5.12（b）[205] 中的特征空间表示一致。"
        }
    },
    {
        "translation": {
            "en": "The AND function returns TRUE if both inputs are TRUE and FALSE otherwise.",
            "zh": "如果两个输入均为 TRUE，则 AND 函数返回 TRUE，否则返回 FALSE。"
        }
    },
    {
        "translation": {
            "en": "perceptron learning rule, 342",
            "zh": "感知器学习规则，342"
        }
    },
    {
        "translation": {
            "en": "The computational speedups achieved by using matrix multiplications address the computational challenge of iterating through both a large number of neurons and a large number of examples.",
            "zh": "通过使用矩阵乘法实现的计算加速解决了通过大量神经元和大量示例进行迭代的计算挑战。"
        }
    },
    {
        "translation": {
            "en": "Notice that the error term ∂ℰ/∂ak is multiplied by two weights: wj,i and wk,j.",
            "zh": "请注意，误差项 ∂E/∂ak 乘以两个权重：wj，i 和 wk，j。"
        }
    },
    {
        "translation": {
            "en": "One implication of this assumption is that supervised machine learning assumes that new target levels—such as previously unknown animals—don’t suddenly appear in the data from which queries that are input to the model are sampled.",
            "zh": "这种假设的一个含义是，监督机器学习假设新的目标水平（例如以前未知的动物）不会突然出现在数据中，从中对输入到模型的查询进行采样。"
        }
    },
    {
        "translation": {
            "en": "Wirth, Rüdiger, and Jochen Hipp. 2000. CRISP-DM: Towards a standard process model for data mining. In Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining, 29–39. Citeseer.",
            "zh": "Wirth、Rüdiger 和 Jochen Hipp。2000. CRISP-DM：迈向数据挖掘的标准过程模型。第四届知识发现和数据挖掘实际应用国际会议论文集，第29-39页。Citeseer。"
        }
    },
    {
        "translation": {
            "en": "Put in subjective terms, Bayes’ Theorem tells us that by modifying our initial beliefs about what has happened (our prior beliefs about the world) proportionally with how our observations relate to their potential causes (inverse probability), we can update our beliefs regarding what has happened to cause our observations (forward probability).",
            "zh": "从主观的角度来看，贝叶斯定理告诉我们，通过修改我们对所发生的事情的初始信念（我们对世界的先前信念）与我们的观察结果与其潜在原因的关系（反向概率），我们可以更新我们对导致我们观察结果的所发生事件的信念（正向概率）。"
        }
    },
    {
        "translation": {
            "en": "The XOR function returns TRUE if either but not both of its inputs are TRUE.",
            "zh": "如果 XOR 函数的任一输入（但不是两个）均为 TRUE，则返回 TRUE。"
        }
    },
    {
        "translation": {
            "en": "7.4.2   Setting the Learning Rate Using Weight Decay",
            "zh": "7.4.2 使用权重衰减设置学习率"
        }
    },
    {
        "translation": {
            "en": "6.7   (a) The area under a density curve between the limits and (b) the approximation of this area computed by PDF (x) × ϵ; and (c) the error in the approximation is equal to the difference between area A, the area under the curve omitted from the approximation, and area B, the area above the curve erroneously included in the approximation. Both of these areas will get smaller as the width of the interval gets smaller, resulting in a smaller error in the approximation.",
            "zh": "6.7 （a） 极限之间的密度曲线下的面积，以及 （b） PDF （x） × ε 计算的该面积的近似值;（c）近似误差等于面积A（从近似中省略的曲线下面积）和面积B（曲线上方的面积错误地包含在近似值中）之间的差值。随着间隔宽度变小，这两个区域都会变小，从而导致近似误差变小。"
        }
    },
    {
        "translation": {
            "en": "gold, silver, or bronze) could be used as a proxy ground truth, and the ability of the clustering to separate the dataset into groups of the same tariff type could be used as a measure of the quality of the clustering.",
            "zh": "金、银或青铜）可以用作代理地面事实，聚类将数据集分成相同关税类型的组的能力可以用作聚类质量的度量。"
        }
    },
    {
        "translation": {
            "en": "Here unsupervised machine learning techniques are used to learn new sets of generated features to represent instance in a dataset.",
            "zh": "在这里，无监督机器学习技术用于学习生成的新特征集，以表示数据集中的实例。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning, the degree to which an agent has achieved a goal is measured only by the cumulative rewards it has received from each action taken in pursuit of that goal.",
            "zh": "在强化学习中，智能体实现目标的程度仅通过其为追求该目标而采取的每项行动中获得的累积奖励来衡量。"
        }
    },
    {
        "translation": {
            "en": "Recall that we use different equations to calculate the δ value for a neuron, depending on whether the neuron is an output neuron or a neuron in a hidden layer.",
            "zh": "回想一下，我们使用不同的方程来计算神经元的δ值，具体取决于该神经元是输出神经元还是隐藏层中的神经元。"
        }
    },
    {
        "translation": {
            "en": "The per example error of the ReLU network after the forward pass illustrated in Figure 8.18[440], the per example ∂ℰ/∂a 8, and the sum of squared errors for the ReLU model.",
            "zh": "图 8.18[440] 所示的前向传递后 ReLU 网络的每个示例误差、每个示例 ∂E/∂a 8 以及 ReLU 模型的平方误差总和。"
        }
    },
    {
        "translation": {
            "en": "By contrast, in most predictive analytics projects, our focus is on determining the best model for a specific problem.",
            "zh": "相比之下，在大多数预测分析项目中，我们的重点是确定特定问题的最佳模型。"
        }
    },
    {
        "translation": {
            "en": "The next step is to compute the entropy remaining after we split the dataset using each of the descriptive features. The computation for the SUSPICIOUS WORDS feature is7",
            "zh": "下一步是计算使用每个描述性特征拆分数据集后剩余的熵。SUSPICIOUS WORDS 特征的计算为 7"
        }
    },
    {
        "translation": {
            "en": "For each of these cases, what we wish to calculate during backpropagation is the rate of change of the error with respect to changes in each of the inputs to the product.",
            "zh": "对于这些情况中的每一种，我们希望在反向传播期间计算的是相对于乘积的每个输入变化的误差变化率。"
        }
    },
    {
        "translation": {
            "en": "New methods that expand on the ideas described in this section are being proposed all the time and some of the most promising are discussed in section 11.6[677].",
            "zh": "在本节中描述的想法的基础上，不断提出扩展的新方法，第11.6节[677]讨论了一些最有前途的方法。"
        }
    },
    {
        "translation": {
            "en": "Forks in the forward computation flow are handled in backpropagation by summing the derivatives that are flowing back along each of the fork branches.",
            "zh": "前向计算流中的分叉在反向传播中通过对沿每个分叉分支回流的导数求和来处理。"
        }
    },
    {
        "translation": {
            "en": "To show how reduced error pruning works, we consider the task of predicting whether a post-operative patient should be sent to an intensive care unit (ICU) or to a general ward for recovery.23 Hypothermia is a major concern for post-operative patients, so many of the descriptive features relevant to this domain relate to a patient’s body temperature.",
            "zh": "为了说明减少误差修剪是如何工作的，我们考虑了预测术后患者是否应该被送往重症监护病房（ICU）或普通病房进行康复的任务.23体温过低是术后患者的主要关注点，因此与该领域相关的许多描述性特征都与患者的体温有关。"
        }
    },
    {
        "translation": {
            "en": "14.2.2   Matching Machine Learning Approaches to Data",
            "zh": "14.2.2 将机器学习方法与数据相匹配"
        }
    },
    {
        "translation": {
            "en": "For clarity there are some extra notational conventions used in Chapter 6[243] on probability.",
            "zh": "为了清楚起见，在第6章[243]中关于概率使用了一些额外的符号约定。"
        }
    },
    {
        "translation": {
            "en": "These figures indicate that there is a strong positive relationship between the height and weight of a player, and a much smaller positive relationship between height and age. This supports the relationships suggested by the scatter plots of these pairs of features shown in Figures 3.5(a)[74] and 3.5(c)[74].",
            "zh": "这些数字表明，球员的身高和体重之间存在很强的正相关关系，而身高和年龄之间的正相关关系要小得多。这支持了图3.5（a）[74]和图3.5（c）[74]所示的这些特征对的散点图所暗示的关系。"
        }
    },
    {
        "translation": {
            "en": "This extra weight term allows the model to define lines that do not go through the origin of the input space: setting the w[0] to a value other than 0 translates the line defined by the model away from the origin of the input space, just as changing the value of the y-intercept in the equation of a line moves a line up and down the y-axis away from the origin.",
            "zh": "这个额外的权重项允许模型定义不经过输入空间原点的线：将 w[0] 设置为 0 以外的值会将模型定义的线从输入空间的原点转换，就像更改直线方程中的 y 截距值会使 y 轴上下移动一条线远离原点一样。"
        }
    },
    {
        "translation": {
            "en": "The activation (or output) of single neuron i is denoted by ai",
            "zh": "单个神经元 i 的激活（或输出）用 ai 表示"
        }
    },
    {
        "translation": {
            "en": "7.5   Summary",
            "zh": "7.5 小结"
        }
    },
    {
        "translation": {
            "en": "We knew when we began writing this book that it would take a huge amount of work to complete.",
            "zh": "当我们开始写这本书时，我们就知道需要大量的工作才能完成。"
        }
    },
    {
        "translation": {
            "en": "At each time-step a new input vector is presented to the network; this flows forward to the hidden layer.",
            "zh": "在每个时间步长，一个新的输入向量被呈现给网络;这向前流向隐藏层。"
        }
    },
    {
        "translation": {
            "en": "8.10   An illustration of how the representational capacity of a network increases as more layers are added to the network.",
            "zh": "8.10 说明随着网络中增加更多层，网络的代表能力如何增加。"
        }
    },
    {
        "translation": {
            "en": "The human brain is, of course, much more complex and sophisticated than even the most advanced deep learning models.",
            "zh": "当然，人脑甚至比最先进的深度学习模型要复杂得多。"
        }
    },
    {
        "translation": {
            "en": "DOSE2",
            "zh": "剂量2"
        }
    },
    {
        "translation": {
            "en": "The difference in the distribution between hidden layer 1 (HL1) and the other hidden layers is caused by the fact that there are only two inputs into each of the neurons in HL1 whereas there are 100 inputs into each of the neurons in the other hidden layers.",
            "zh": "隐藏层 1 （HL1） 和其他隐藏层之间分布的差异是由于 HL1 中每个神经元只有两个输入，而其他隐藏层中的每个神经元有 100 个输入。"
        }
    },
    {
        "translation": {
            "en": "In order to calculate the δs for the neurons in each of these layers, we must multiply these error gradients by the derivative of the activation function for the layer with respect to the inputs to the activation function (i.e., ∂a/∂z).",
            "zh": "为了计算每一层中神经元的δs，我们必须将这些误差梯度乘以该层的激活函数相对于激活函数输入的导数（即∂a/∂z）。"
        }
    },
    {
        "translation": {
            "en": "As a result, there is no error gradient with respect to the non-max values that the max function received.",
            "zh": "因此，max 函数接收到的非 max 值没有误差梯度。"
        }
    },
    {
        "translation": {
            "en": "The random action selected in this case is down.",
            "zh": "在这种情况下选择的随机操作为关闭。"
        }
    },
    {
        "translation": {
            "en": "Table 2.2",
            "zh": "表 2.2"
        }
    },
    {
        "translation": {
            "en": "With help from Grace to implement the actual data manipulation and data integration scripts using the tools available at AT, Ross populated an ABT containing all the features listed in Table 12.1[692].",
            "zh": "在 Grace 的帮助下，使用 AT 提供的工具实现实际的数据操作和数据集成脚本，Ross 填充了一个包含表 12.1[692] 中列出的所有功能的 ABT。"
        }
    },
    {
        "translation": {
            "en": "This always simply predicts the average value of the target feature from the dataset—in this case a rental demand of 1,287.1 bicycles.",
            "zh": "这始终只是简单地预测数据集中目标要素的平均值，在本例中为 1,287.1 辆自行车的租赁需求。"
        }
    },
    {
        "translation": {
            "en": "1. The image below shows a set of eight Scrabble pieces.",
            "zh": "1. 下图显示了一组八个拼字游戏。"
        }
    },
    {
        "translation": {
            "en": "“gambling for fun”",
            "zh": "“赌博好玩”"
        }
    },
    {
        "translation": {
            "en": "In the predictive analytics context, the standard approach is to use relative frequency, and we focus on this approach in this chapter.",
            "zh": "在预测分析上下文中，标准方法是使用相对频率，我们将在本章中重点介绍这种方法。"
        }
    },
    {
        "translation": {
            "en": "(a) The decision boundary using majority vote of the nearest 15 neighbors; and (b) the weighted k nearest neighbor model decision boundary (with k = 21).",
            "zh": "（a） 使用最近的15个邻国的多数票作出的决定边界;（b）加权k最近邻模型决策边界（k = 21）。"
        }
    },
    {
        "translation": {
            "en": "Not long afterward, however, Mr. Murphy’s son, Andrew, ran in to say that he had fixed the letters in the kitchen because they had been so badly organized.",
            "zh": "然而，不久之后，墨菲的儿子安德鲁跑进来，说他把这些信放在厨房里修好了，因为它们太糟糕了。"
        }
    },
    {
        "translation": {
            "en": "They are also the basis for a whole range of different performance measures that can highlight different aspects of the performance of a predictive model.",
            "zh": "它们也是一系列不同性能度量的基础，这些度量可以突出预测模型性能的不同方面。"
        }
    },
    {
        "translation": {
            "en": "The plot of the density curve for the exponential distribution (Figure 6.3(b)[270]) shows that it assigns a high probability to values near the left of the distribution and that the probability of a value occurring drops dramatically as we move to the right.",
            "zh": "指数分布的密度曲线图（图6.3（b）[270]）表明，它为分布左侧附近的值分配了高概率，并且当我们向右移动时，该值出现的概率急剧下降。"
        }
    },
    {
        "translation": {
            "en": "We can now complete the information gain calculation for each descriptive feature",
            "zh": "现在，我们可以完成每个描述性特征的信息增益计算"
        }
    },
    {
        "translation": {
            "en": "7. Assuming a fully connected feedforward network where all the neurons uses a linear activation function (i.e., ai = zi) and with the following topology:",
            "zh": "7. 假设一个完全连接的前馈网络，其中所有神经元都使用线性激活函数（即 ai = zi）并具有以下拓扑结构："
        }
    },
    {
        "translation": {
            "en": "Blackjack, 645",
            "zh": "二十一点，645"
        }
    },
    {
        "translation": {
            "en": "Based on her understanding of the SDSS process, Jocelyn sketched out the first draft of the domain concepts diagram for the galaxy classification problem shown in Figure 13.2[708].",
            "zh": "基于她对SDSS过程的理解，Jocelyn勾勒出图13.2[708]所示星系分类问题的领域概念图的初稿。"
        }
    },
    {
        "translation": {
            "en": "0.0904",
            "zh": "0.0904"
        }
    },
    {
        "translation": {
            "en": "11.7 Exercises",
            "zh": "11.7 练习"
        }
    },
    {
        "translation": {
            "en": "-0.47",
            "zh": "-0.47"
        }
    },
    {
        "translation": {
            "en": "Finally, as discussed in the Information Based Learning chapter, in which we discussed tree pruning to avoid overfitting, using the performance of the model on the validation set to decide when to stop the training and weight updates is nearly always the case in training a neural network.",
            "zh": "最后，正如在“基于信息的学习”一章中所讨论的，我们在其中讨论了树修剪以避免过度拟合，在训练神经网络时，使用模型在验证集上的性能来决定何时停止训练和权重更新几乎总是如此。"
        }
    },
    {
        "translation": {
            "en": "We will, however, leave this calculation to the interested reader (the result should still be 0.7).",
            "zh": "但是，我们将把这个计算留给感兴趣的读者（结果仍应为 0.7）。"
        }
    },
    {
        "translation": {
            "en": "U_U/G/R/I/Z",
            "zh": "U_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "4.20   The process of creating a model ensemble using bagging and subspace sampling.",
            "zh": "4.20 使用装袋和子空间采样创建模型集合的过程。"
        }
    },
    {
        "translation": {
            "en": "They found that on average, ensemble models and support vector machines were among the most accurate models.",
            "zh": "他们发现，平均而言，集成模型和支持向量机是最准确的模型之一。"
        }
    },
    {
        "translation": {
            "en": "(d) What value would a weighted k-NN prediction model—with k = 16 (i.e., the full dataset) and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query—return for the CPI of Russia when it is applied to the range-normalized data?",
            "zh": "（d） 当俄罗斯的 CPI 应用于范围归一化数据时，加权 k-NN 预测模型（k = 16（即完整数据集）并使用邻域和查询之间欧几里得距离平方的倒数加权方案）会返回什么值？"
        }
    },
    {
        "translation": {
            "en": "To address this issue, we can use average class accuracy7 instead of classification accuracy.8 The average class accuracy is calculated as",
            "zh": "为了解决这个问题，我们可以使用平均类准确率7而不是分类准确率8，平均类准确率的计算公式为"
        }
    },
    {
        "translation": {
            "en": "4. This kind of classification is not unusual because supermarket chains can collect huge amounts of data about customers’ shopping habits through a loyalty card scheme but find it expensive and time consuming to collect more personal data, such as demographic classifications. Demographic classifications, however, are extremely useful to marketing departments in designing special offers and other customer incentives.",
            "zh": "4. 这种分类并不罕见，因为连锁超市可以通过会员卡计划收集大量有关顾客购物习惯的数据，但发现收集更多个人数据（例如人口统计分类）既昂贵又耗时。然而，人口统计分类对于营销部门在设计特别优惠和其他客户激励措施时非常有用。"
        }
    },
    {
        "translation": {
            "en": "7.1   (a) A scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset; and (b) the scatter plot from (a) with a linear model relating RENTAL PRICE to SIZE overlaid.",
            "zh": "7.1 （a） 写字楼租赁数据集中 SIZE 和 RENTAL PRICE 特征的散点图;（b）来自（a）的散点图，其中叠加了与RENTAL PRICE和SIZE相关的线性模型。"
        }
    },
    {
        "translation": {
            "en": "The classification accuracy of 79.03% is well above the target agreed on with the business.",
            "zh": "79.03%的分类准确率远高于与业务商定的目标。"
        }
    },
    {
        "translation": {
            "en": "Table 6.14",
            "zh": "表 6.14"
        }
    },
    {
        "translation": {
            "en": "In this iteration, the error rate of the root node (1) is greater than the error rate of the three leaf nodes, (0 + 0 + 0 = 0), so the tree is left unchanged.",
            "zh": "在此迭代中，根节点 （1） 的错误率大于三个叶节点的错误率 （0 + 0 + 0 = 0），因此树保持不变。"
        }
    },
    {
        "translation": {
            "en": "We highlight this distinction by using different for loops for each of these conditions.",
            "zh": "我们通过对每个条件使用不同的 for 循环来强调这种区别。"
        }
    },
    {
        "translation": {
            "en": "The standard error for the overall model is calculated as follows:",
            "zh": "整个模型的标准误差计算如下："
        }
    },
    {
        "translation": {
            "en": "Accessing the results of the SDSS processing pipeline turned out to be reasonably straightforward, as it was already collected into a single large table in the SDSS data repository.",
            "zh": "访问 SDSS 处理管道的结果变得相当简单，因为它已经收集到 SDSS 数据存储库中的一个大表中。"
        }
    },
    {
        "translation": {
            "en": "To address these different project requirements, there is a spectrum of different approaches to measuring the performance of a model, and it is important to align the correct approach with a given modeling task.",
            "zh": "为了满足这些不同的项目要求，有一系列不同的方法来衡量模型的性能，并且必须使正确的方法与给定的建模任务保持一致。"
        }
    },
    {
        "translation": {
            "en": "The CRISP-DM process documentation (Chapman et al., 2000) is surprisingly readable, and adds a lot of extra detail to the tasks described in this chapter. For details on developing business concepts and designing features, Svolba (2007) is excellent (the approaches described can be applied to any tool, not just SAS, which is the focus of Svolba’s book).",
            "zh": "CRISP-DM过程文档（Chapman等人，2000）具有令人惊讶的可读性，并为本章中描述的任务增加了许多额外的细节。对于开发业务概念和设计功能的细节，Svolba （2007）非常出色（所描述的方法可以应用于任何工具，而不仅仅是SAS，这是Svolba书的重点）。"
        }
    },
    {
        "translation": {
            "en": "The threshold ≥4,175 has the highest information gain of any of the candidate thresholds (0.8631 bits), and this information gain is also higher than the information gain for either of the other two descriptive features.",
            "zh": "阈值 ≥4,175 在所有候选阈值 （0.8631 位） 中具有最高的信息增益，并且此信息增益也高于其他两个描述性特征中任一的信息增益。"
        }
    },
    {
        "translation": {
            "en": "This makes sense because if a model is performing accurately, we would expect negative instances to have low scores (close to 0.0) and positive instances to have high scores (close to 1.0).",
            "zh": "这是有道理的，因为如果模型执行准确，我们预计负实例的分数较低（接近 0.0），正实例的分数很高（接近 1.0）。"
        }
    },
    {
        "translation": {
            "en": "The learning rate, α, determines the size of the adjustments made to weights at each iteration of the algorithm and is discussed further in Section 7.3.3[328].",
            "zh": "α，学习率决定了算法每次迭代时对权重所做的调整大小，并在第 7.3.3 节[328]中进一步讨论。"
        }
    },
    {
        "translation": {
            "en": "In the trained model the value of w0 is 0.3074, and the values of the α parameters are ⟨7.1655,6.9060,2.0033,6.1144,5.9538⟩.",
            "zh": "在训练模型中，w0 的值为 0.3074，α参数的值为 ⟨7.1655、6.9060、2.0033、6.1144、5.9538⟩。"
        }
    },
    {
        "translation": {
            "en": "This is because the action is now selected using the ε-greedy policy, whereas the action used during the update was selected off-policy.",
            "zh": "这是因为现在使用ε贪婪策略选择操作，而更新期间使用的操作是在策略外选择的。"
        }
    },
    {
        "translation": {
            "en": "To highlight this change in activation functions between the layers, we have labeled the φ symbol in the figure with the name of the activation function it represents.",
            "zh": "为了突出显示层之间激活函数的这种变化，我们用它所代表的激活函数的名称标记了图中的φ符号。"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 10.12(c)[621], and Table 10.5(b)[620] shows an updated distance matrix including these new clusters.",
            "zh": "如图10.12（c）[621]所示，表10.5（b）[620]显示了包括这些新聚类在内的更新距离矩阵。"
        }
    },
    {
        "translation": {
            "en": "14. The Bellman Equations were first introduced by Richard Bellman in the 1950s (Bellman, 1957a,b) as part of very early work on reinforcement learning.",
            "zh": "14. 贝尔曼方程最早是由理查德·贝尔曼在1950年代提出的（贝尔曼，1957a，b），作为强化学习的早期工作的一部分。"
        }
    },
    {
        "translation": {
            "en": "As such, it balances the search goals of model accuracy and simplicity.",
            "zh": "因此，它平衡了模型准确性和简单性的搜索目标。"
        }
    },
    {
        "translation": {
            "en": "For consistency with the notation that we use in this book, we can rewrite the simple linear regression model",
            "zh": "为了与我们在本书中使用的符号保持一致，我们可以重写简单的线性回归模型"
        }
    },
    {
        "translation": {
            "en": "The statistical significance test we use to analyze the importance of a descriptive feature d[j] in a linear regression model is the t-test.",
            "zh": "我们用于分析描述性特征 d[j] 在线性回归模型中的重要性的统计显着性检验是 t 检验。"
        }
    },
    {
        "translation": {
            "en": "In this scenario, everything else being equal, the weight updates for the salary feature will generally be larger than those for the age feature because the weight updates are scaled by the feature values.",
            "zh": "在此方案中，在其他条件相同的情况下，工资要素的权重更新通常大于年龄要素的权重更新，因为权重更新是按要素值缩放的。"
        }
    },
    {
        "translation": {
            "en": "Table 12.4",
            "zh": "表 12.4"
        }
    },
    {
        "translation": {
            "en": "Table 4.4[137] shows the calculation of the information gain for each feature using this result.",
            "zh": "表4.4[137]显示了使用此结果计算每个特征的信息增益。"
        }
    },
    {
        "translation": {
            "en": "However, for the purpose of illustration it is worth noting that the model would return the class label with the highest probability for each example; hence the model would return a prediction of low for all four examples in the mini-batch.",
            "zh": "但是，出于说明目的，值得注意的是，该模型将返回每个示例概率最高的类标签;因此，该模型将返回小批量中所有四个示例的低预测值。"
        }
    },
    {
        "translation": {
            "en": "The final three dense layers had 4096 neurons each.",
            "zh": "最后三层密集层各有4096个神经元。"
        }
    },
    {
        "translation": {
            "en": "8.15   The calculation of the softmax activations for each of the neurons in the output layer for each example in the mini-batch, and the calculation of the δ for each neuron in the output layer for each example in the mini-batch.",
            "zh": "8.15 计算小批量中每个示例的输出层中每个神经元的 softmax 激活次数，以及计算小批量中每个示例的输出层中每个神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "We should always consider normalizing our data, but it is particularly important to do this when the descriptive features are measured in different units.",
            "zh": "我们应该始终考虑对数据进行归一化，但是当以不同的单位测量描述性特征时，这样做尤为重要。"
        }
    },
    {
        "translation": {
            "en": "A feature is any measure derived from a domain concept that can be directly included in an ABT for use by a machine learning algorithm.",
            "zh": "特征是从领域概念派生的任何度量，可以直接包含在 ABT 中以供机器学习算法使用。"
        }
    },
    {
        "translation": {
            "en": "This region exists because one of the no instances occurs far away from the rest of the instances with this target level.",
            "zh": "之所以存在此区域，是因为其中一个 no 实例远离具有此目标级别的其余实例。"
        }
    },
    {
        "translation": {
            "en": "Because we can expect the error surface to be convex and possess a global minimum, we can find the optimal weights at the point where the partial derivatives of the error surface with respect to w[0] and w[1] are equal to 0.",
            "zh": "因为我们可以预期误差曲面是凸的并且具有全局最小值，所以我们可以在误差曲面相对于 w[0] 和 w[1] 的偏导数等于 0 的点找到最佳权重。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, as is the case with the learning rate, there are no well-established, proven methods for choosing initial weights.",
            "zh": "不幸的是，与学习率一样，没有成熟的、行之有效的方法来选择初始权重。"
        }
    },
    {
        "translation": {
            "en": "The term iteration is used to refer to a single forward and backward pass plus weight update of the backpropagation algorithm.",
            "zh": "术语迭代用于指反向传播算法的单次正向和后向传递以及权重更新。"
        }
    },
    {
        "translation": {
            "en": "2.2 Assessing Feasibility",
            "zh": "2.2 评估可行性"
        }
    },
    {
        "translation": {
            "en": "8.31   A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a receptive field that covers the top-left corner of the image.",
            "zh": "8.31 4 灰度图像的 6×6 矩阵表示，以及具有覆盖图像左上角的感受野的神经元。"
        }
    },
    {
        "translation": {
            "en": "Illustration of how a mixture of Gaussians model is composed of a number of normal distributions. The curve plotted using a solid line is the mixture of Gaussians density curve, created using an appropriately weighted summation of the three normal curves, plotted using dashed and dotted lines.",
            "zh": "高斯模型的混合如何由许多正态分布组成的图示。使用实线绘制的曲线是高斯密度曲线的混合，使用使用虚线和虚线绘制的三条正态曲线的适当加权求和创建。"
        }
    },
    {
        "translation": {
            "en": "In this table, the instances in the dataset have been reordered in ascending order based on their LOAN AMOUNT values.",
            "zh": "在此表中，数据集中的实例已根据其 LOAN AMOUNT 值按升序重新排序。"
        }
    },
    {
        "translation": {
            "en": "Each weight is considered independently, and for each one a small adjustment is made by adding a small value, called a delta value, to the current weight, w[j].",
            "zh": "每个权重都是独立考虑的，对于每个权重，通过在当前权重 w[j] 上添加一个小值（称为增量值）来进行小调整。"
        }
    },
    {
        "translation": {
            "en": "To begin the gradient descent process, random starting values for the weights within the model, w[0],w[1],w[2], are selected. In this example, random values were selected from the range [−3, 3] to give w[0] = −2.9465, w[1] = −1.0147, and w[2] = 2.1610. Using these weights, a prediction is made for every instance in the training dataset, and the resulting sum of squared errors is calculated. The predictions made using these weights and the related error are shown in Table 7.8[348] under Iteration 1.",
            "zh": "要开始梯度下降过程，需要选择模型中权重的随机起始值 w[0]，w[1]，w[2]。在此示例中，从范围 [−3， 3] 中选择随机值，得出 w[0] = −2.9465、w[1] = −1.0147 和 w[2] = 2.1610。使用这些权重，对训练数据集中的每个实例进行预测，并计算结果的误差平方和。使用这些权重和相关误差进行的预测显示在迭代 1 下的表 7.8[348] 中。"
        }
    },
    {
        "translation": {
            "en": "where 𝕄Δ1 is the model trained to predict the errors made by the base model, 𝕄0.",
            "zh": "其中 MΔ1 是经过训练的模型，用于预测基础模型 M0 所犯的错误。"
        }
    },
    {
        "translation": {
            "en": "Other parts of the business that Ross spent significant time interviewing included the billing department, the sales and marketing team, and the network management.",
            "zh": "Ross 花了大量时间采访的其他业务部门包括计费部门、销售和营销团队以及网络管理。"
        }
    },
    {
        "translation": {
            "en": "MITOSES: A measure of how fast cells are growing (1 to 10).",
            "zh": "有丝分裂：衡量细胞生长速度的指标（1 到 10）。"
        }
    },
    {
        "translation": {
            "en": "During the training process, this is repeated multiple times.",
            "zh": "在训练过程中，这会重复多次。"
        }
    },
    {
        "translation": {
            "en": "While using profit might appear to be the ideal way to evaluate model performance for categorical targets, unfortunately, this is not the case.",
            "zh": "虽然使用利润似乎是评估分类目标的模型性能的理想方法，但不幸的是，情况并非如此。"
        }
    },
    {
        "translation": {
            "en": "identity matrix, 219",
            "zh": "单位矩阵，219"
        }
    },
    {
        "translation": {
            "en": "Finally, the nearest neighbor algorithm is what is known as a lazy learner.",
            "zh": "最后，最近邻算法就是所谓的懒惰学习者。"
        }
    },
    {
        "translation": {
            "en": "This was an iterative process in which Ross moved back and forth between Kate at the AT retention team, Grace, the CTO, and other parts of the business identified as having insight into the data associated with customer churn.",
            "zh": "这是一个迭代过程，Ross 在 AT 保留团队的 Kate、首席技术官 Grace 和其他业务部门之间来回移动，这些部门被认为能够洞察与客户流失相关的数据。"
        }
    },
    {
        "translation": {
            "en": "Notice that the indices in the weight subscripts are in reverse order from what might be expected: the first subscript is the index of the neuron to which the activation is flowing, and the second subscript is the index of the neuron that generated the activation.",
            "zh": "请注意，权重下标中的索引顺序与预期相反：第一个下标是激活流向的神经元的索引，第二个下标是生成激活的神经元的索引。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics can be used to build models that predict future customer actions on the basis of historical behavior.",
            "zh": "预测性数据分析可用于构建模型，根据历史行为预测未来的客户行为。"
        }
    },
    {
        "translation": {
            "en": "Irrelevant: an irrelevant descriptive feature does not provide information that is useful in estimating the value of the target feature.",
            "zh": "不相关：不相关的描述性特征不提供可用于估计目标特征值的信息。"
        }
    },
    {
        "translation": {
            "en": "The algorithm begins by choosing the best descriptive feature to test (i.e., the best question to ask first).",
            "zh": "该算法首先选择要测试的最佳描述性特征（即首先要问的最佳问题）。"
        }
    },
    {
        "translation": {
            "en": "A distinctive aspect of this book is that we have chosen to present machine learning in context.",
            "zh": "本书的一个独特之处在于，我们选择在上下文中呈现机器学习。"
        }
    },
    {
        "translation": {
            "en": "All these approaches are similar to k-d trees in that they are trying to set up indexes that enable efficient retrieval from a dataset.",
            "zh": "所有这些方法都类似于 k-d 树，因为它们都试图建立索引，以便从数据集中高效检索。"
        }
    },
    {
        "translation": {
            "en": "Probability-based prediction approaches are heavily based on Bayes’ Theorem, and the fundamentals section of this chapter introduces this important cornerstone of computer science after covering some other fundamentals of probability theory.",
            "zh": "基于概率的预测方法主要基于贝叶斯定理，本章的基础部分在介绍了概率论的其他一些基础知识之后，介绍了计算机科学的这一重要基石。"
        }
    },
    {
        "translation": {
            "en": "This can also be seen in the top left-hand image of Figure 7.15[350],which shows the candidate model corresponding to this initial set of weights.",
            "zh": "这也可以在图7.15[350]的左上角图像中看到，该图像显示了与该初始权重集相对应的候选模型。"
        }
    },
    {
        "translation": {
            "en": "We use Δwi,k to write the sum of error gradients calculated for the weight wi,k. We sum errors in this way during batch gradient descent with which we sum over the examples in the batch; see Equation (8.30)[416] and also in cases in which the weight is shared by a number of neurons, whether in a convolutional neural network or during backpropagation through time.",
            "zh": "我们使用 Δwi，k 来写出为权重 wi，k 计算的误差梯度之和。在批次梯度下降过程中，我们以这种方式对误差求和，我们对批次中的示例求和;参见方程（8.30）[416]，以及权重由多个神经元共享的情况，无论是在卷积神经网络中还是在随时间反向传播期间。"
        }
    },
    {
        "translation": {
            "en": "D.1 Basic Types",
            "zh": "D.1 基本类型"
        }
    },
    {
        "translation": {
            "en": "This could be predicting the price that something will be sold for in the future; alternatively, it could mean predicting the type of document.",
            "zh": "这可能是预测未来某物的售价;或者，这可能意味着预测文档的类型。"
        }
    },
    {
        "translation": {
            "en": "3.7 Summary",
            "zh": "3.7 小结"
        }
    },
    {
        "translation": {
            "en": "The first things to check the cardinality column for are features with a cardinality of 1.",
            "zh": "首先要检查基数列的是基数为 1 的要素。"
        }
    },
    {
        "translation": {
            "en": "This forward pass follows the set of operations illustrated in Figure 8.6[393].",
            "zh": "此前向传递遵循图 8.6[393] 所示的一组操作。"
        }
    },
    {
        "translation": {
            "en": "sampling without replacement, 159",
            "zh": "不更换的采样，159"
        }
    },
    {
        "translation": {
            "en": "Using one of these tools, it is possible to train, evaluate, and deploy a predictive data analytics model in less than an hour!",
            "zh": "使用这些工具之一，可以在不到一个小时的时间内训练、评估和部署预测性数据分析模型！"
        }
    },
    {
        "translation": {
            "en": "Instead, a reinforcement learning agent can be deployed into an environment and learn from experimenting within that environment.",
            "zh": "相反，可以将强化学习代理部署到环境中，并从该环境中的实验中学习。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the variance of the z values across for the neurons in the last hidden layer in the first iteration of training.",
            "zh": "（b） 计算第一次训练迭代中最后一个隐藏层中神经元的 z 值的方差。"
        }
    },
    {
        "translation": {
            "en": "A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a different receptive field from the neuron in Figure 8.31[480]. This figure was inspired by Figure 2 of Kelleher and Dobnik (2017).",
            "zh": "图 4 的灰度图像的 6×6 矩阵表示，以及与图 8.31 [480] 中神经元具有不同感受野的神经元。该图的灵感来自Kelleher和Dobnik（2017）的图2。"
        }
    },
    {
        "translation": {
            "en": "True Negative (TN): an instance in the test set that had a negative target feature value and that was predicted to have a negative target feature value",
            "zh": "真负 （TN）：测试集中具有负目标特征值且预测具有负目标特征值的实例"
        }
    },
    {
        "translation": {
            "en": "In order to use control groups in evaluation, we need to be able to divide a population into two groups, run two versions of a business process in parallel, and accurately measure the performance of the business process.",
            "zh": "为了在评估中使用对照组，我们需要能够将总体分为两组，并行运行两个版本的业务流程，并准确衡量业务流程的性能。"
        }
    },
    {
        "translation": {
            "en": "Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems, 5998–6008.",
            "zh": "瓦斯瓦尼、阿希什、诺姆·沙泽尔、尼基·帕尔马、雅各布·乌斯科雷特、利昂·琼斯、艾丹·戈麦斯、卢卡斯·凯撒和伊利亚·波洛苏欣。2017. 注意力就是你所需要的。在神经信息处理系统进展中，5998-6008。"
        }
    },
    {
        "translation": {
            "en": "termination condition, 229",
            "zh": "端接条件，229"
        }
    },
    {
        "translation": {
            "en": "Instead, this decision is made on a case-by-case basis and is dependent on the precision required in answering a question.",
            "zh": "相反，此决定是根据具体情况做出的，并且取决于回答问题所需的精确度。"
        }
    },
    {
        "translation": {
            "en": "The table below shows the frequencies of predictions of the three different levels made by the model for the original validation dataset at the time the model was built, for the month after deployment, and for a monthlong period six months after deployment.",
            "zh": "下表显示了模型在构建模型时、部署后一个月和部署后六个月内对原始验证数据集进行的三个不同级别的预测频率。"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_R_I",
            "zh": "PETROMAGDIFF_R_I"
        }
    },
    {
        "translation": {
            "en": "The remaining entropy for the CONTAINS IMAGES feature is",
            "zh": "CONTAINS IMAGES 特征的剩余熵为"
        }
    },
    {
        "translation": {
            "en": "action, 643, 676",
            "zh": "行动， 643， 676"
        }
    },
    {
        "translation": {
            "en": "Once a set of candidate analytics solutions that address a business problem have been defined, the next task is to evaluate the feasibility of each solution. This involves considering the following questions:",
            "zh": "一旦定义了一组解决业务问题的候选分析解决方案，下一个任务就是评估每个解决方案的可行性。这涉及考虑以下问题："
        }
    },
    {
        "translation": {
            "en": "Dick: What?",
            "zh": "迪克：什么？"
        }
    },
    {
        "translation": {
            "en": "The relevant smoothed probabilities, from Table 6.16[284], needed by the naive Bayes model to make a prediction for the query with CH = paid, GC = guarantor, ACC = free, AB = 759.07, and LA = 8,000, and the calculation of the scores for each candidate prediction.",
            "zh": "朴素贝叶斯模型需要从表 6.16[284] 中对 CH = 付费、GC = 担保人、ACC = 免费、AB = 759.07 和 LA = 8,000 的查询进行预测，并计算每个候选预测的分数。"
        }
    },
    {
        "translation": {
            "en": "By applying a set of basis functions (Section 7.4.5[351]) to descriptive features, models that represent non-linear relationships can be created.",
            "zh": "通过将一组基函数（第 7.4.5 节 [351]）应用于描述性特征，可以创建表示非线性关系的模型。"
        }
    },
    {
        "translation": {
            "en": "The transpose of a matrix flips the matrix on its main diagonal (the main diagonal of a matrix contain all the elements whose indices are equal, e.g., c1,1,c2,2, and so on). To create the transpose of a matrix, take the first row of the matrix and write it as the first column; then write the second row of the matrix and write it as the second column; and so on. For example:",
            "zh": "矩阵的转置在其主对角线上翻转矩阵（矩阵的主对角线包含索引相等的所有元素，例如 c1,1，c2,2 等）。要创建矩阵的转置，请取矩阵的第一行并将其写为第一列;然后写矩阵的第二行，写成第二列;等等。例如："
        }
    },
    {
        "translation": {
            "en": "Figure 8.14[425] illustrates the forward pass for the examples in Table 8.3[423] through the network in Figure 8.4[390].",
            "zh": "图8.14[425]说明了表8.3[423]中示例通过图8.4[390]中的网络的前向传递。"
        }
    },
    {
        "translation": {
            "en": "5.4.5 Other Measures of Similarity",
            "zh": "5.4.5 其他相似度衡量标准"
        }
    },
    {
        "translation": {
            "en": "For example, in the spam filtering problem described previously, all we need to use are the relative profits of classifying a ham email as spam, classifying a spam email as ham, and so on.",
            "zh": "例如，在前面描述的垃圾邮件过滤问题中，我们需要使用的只是将 ham 电子邮件归类为垃圾邮件、将垃圾邮件归类为 ham 等的相对利润。"
        }
    },
    {
        "translation": {
            "en": "(b) Propose an inductive bias that would enable a machine learning algorithm to make the same preference choice that you made in Part (a).",
            "zh": "（b） 提出一种归纳偏差，使机器学习算法能够做出与您在 （a） 部分中所做的相同的偏好选择。"
        }
    },
    {
        "translation": {
            "en": "5.4.5.2 Cosine similarity Cosine similarity is an index that can be used as a measure of the similarity between instances with continuous descriptive features. The cosine similarity between two instances is the cosine of the inner angle between the two vectors that extend from the origin of a feature space to each instance. Figure 5.14(a)[218] illustrates the inner angle, θ, between the vector from the origin to two instances in a feature space defined by two descriptive features, SMS and VOICE.",
            "zh": "5.4.5.2 余弦相似度 余弦相似度是一个索引，可以用来衡量具有连续描述性特征的实例之间的相似性。两个实例之间的余弦相似度是从特征空间的原点延伸到每个实例的两个向量之间内角的余弦。图 5.14（a）[218] 说明了由两个描述性特征 SMS 和 VOICE 定义的特征空间中从原点到两个实例的向量之间的内角 θ。"
        }
    },
    {
        "translation": {
            "en": "Typically we will use letters from the end of the alphabet (e.g., X, Y, Z) for this purpose.",
            "zh": "通常，我们将使用字母表末尾的字母（例如，X、Y、Z）来实现此目的。"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the updated instance distribution, w[5], based on the predictions made by 𝕄4.",
            "zh": "（c） 根据 M4 的预测计算更新的实例分布 w[5]。"
        }
    },
    {
        "translation": {
            "en": "The description of the support vector machine approach given in this section assumes that it is possible to separate the instances with the two different target feature levels with a linear hyperplane.",
            "zh": "本节中给出的支持向量机方法的描述假设可以使用线性超平面将具有两个不同目标特征级别的实例分开。"
        }
    },
    {
        "translation": {
            "en": "Bertin, Jacques. 2010. Semiology of graphics: Diagrams, networks, maps. ESRI Press.",
            "zh": "贝尔廷，雅克。2010. 图形符号学：图表、网络、地图.ESRI出版社。"
        }
    },
    {
        "translation": {
            "en": "TOTALINCOME",
            "zh": "总收入"
        }
    },
    {
        "translation": {
            "en": "The first step in defining the two PDFs is to decide which distribution we will use to define the PDFs for each target feature level.",
            "zh": "定义两个 PDF 的第一步是确定我们将使用哪个分发来定义每个目标功能级别的 PDF。"
        }
    },
    {
        "translation": {
            "en": "3.2   Getting to Know the Data",
            "zh": "3.2 了解数据"
        }
    },
    {
        "translation": {
            "en": "The first real model trained for this ensemble, Δ1, is then trained to predict these errors on the basis of the descriptive features in the training set.",
            "zh": "然后，为该集成训练的第一个真实模型 Δ1 被训练为根据训练集中的描述性特征预测这些误差。"
        }
    },
    {
        "translation": {
            "en": "However, as previously noted, these proofs assume that the neurons in the network include functions that are much more complex (or rougher) than the smooth activation functions used in most networks (such as the logistic functions).",
            "zh": "然而，如前所述，这些证明假设网络中的神经元包含比大多数网络中使用的平滑激活函数（例如逻辑函数）复杂得多（或更粗糙）的功能。"
        }
    },
    {
        "translation": {
            "en": "In scenarios that include a time dimension, this can be particularly effective and is often referred to as out-of-time sampling, because we use data from one period to build a training set and data out of another period to build a test set.",
            "zh": "在包含时间维度的方案中，这可能特别有效，通常称为时间外抽样，因为我们使用一个时期的数据来构建训练集，并使用另一个时期的数据来构建测试集。"
        }
    },
    {
        "translation": {
            "en": "During DQN training the size of the replay memory was 50,000 and the target action-value function network, , was replaced every 10,000 steps.",
            "zh": "在 DQN 训练期间，重放记忆的大小为 50,000，目标动作值函数网络 ，每 10,000 步更换一次。"
        }
    },
    {
        "translation": {
            "en": "Based on these results, Jocelyn determined that the logistic regression model trained using the reduced set of features was the best model to use for galaxy classification.",
            "zh": "基于这些结果，Jocelyn确定使用简化的特征集训练的逻辑回归模型是用于星系分类的最佳模型。"
        }
    },
    {
        "translation": {
            "en": "On top of a preference for caution in a final target policy, if training is being undertaken in the real world with potentially expensive equipment, SARSA might be favored over Q-Learning.",
            "zh": "除了在最终目标政策中谨慎行事之外，如果在现实世界中使用可能昂贵的设备进行培训，SARSA可能比Q-Learning更受青睐。"
        }
    },
    {
        "translation": {
            "en": "The representational capacity of a network is the set of functions (or mappings from inputs to outputs) that the network can implement as its weights are varied (Reed and Marks, 1999).",
            "zh": "网络的表征能力是网络在其权重变化时可以实现的一组函数（或从输入到输出的映射）（Reed and Marks，1999）。"
        }
    },
    {
        "translation": {
            "en": "If we wish to train a deep network, we want the behavior of the network, in terms of the variance of the layer’s z values, activations, and error gradients, to be similar across all the layers of the network.",
            "zh": "如果我们希望训练深度网络，我们希望网络的行为（就层的 z 值、激活和误差梯度的方差而言）在网络的所有层中都是相似的。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.18",
            "zh": "图 9.18"
        }
    },
    {
        "translation": {
            "en": "DEVRADERR_U/G/R/I/Z",
            "zh": "DEVRADERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "PSFMAGERR_U/G/R/I/Z",
            "zh": "PSFMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "10.11   (a)–(d) Different linkage methods that can be used to compare the distances between clusters in agglomerative hierarchical clustering. (Arrows for only some indicative distances are shown in the average linkage diagram (d).)",
            "zh": "10.11 （a）–（d） 可用于比较集聚分层聚类中聚类之间距离的不同链接方法。（平均连杆图 （d） 中仅显示一些指示距离的箭头。"
        }
    },
    {
        "translation": {
            "en": "Pascal, Blaise, 243",
            "zh": "帕斯卡，布莱斯，243"
        }
    },
    {
        "translation": {
            "en": "The main novelty in this scenario is that the neurons in the hidden layer of a simple recurrent neural network have two weight matrices associated with them: Whx and Whh.",
            "zh": "这个场景的主要新颖之处在于，简单循环神经网络隐藏层中的神经元有两个与之相关的权重矩阵：Whx 和 Whh。"
        }
    },
    {
        "translation": {
            "en": "The is why in Figure 8.42[516] both of the paths emerging from the elementwise summation are labeled with the same term as the input arrow: ∂ℰ/∂ct.",
            "zh": "这就是为什么在图 8.42[516] 中，从元素求和中出现的两条路径都用与输入箭头相同的项进行标记：∂E/∂ct。"
        }
    },
    {
        "translation": {
            "en": "Hence, an aggregate across multiple runs should still be used.",
            "zh": "因此，仍应使用跨多个运行的聚合。"
        }
    },
    {
        "translation": {
            "en": "1. Subset Generation: This component generates a set of candidate feature subsets that are successors of the current best feature subset.",
            "zh": "1. 子集生成：此组件生成一组候选特征子集，这些子集是当前最佳特征子集的继承者。"
        }
    },
    {
        "translation": {
            "en": "3.6.2 Binning",
            "zh": "3.6.2 像素合并"
        }
    },
    {
        "translation": {
            "en": "Doubt has begun to surround the phenomenon of N rays, however, as a number of international physicists have not been able to reproduce the results of the experiments that demonstrate their existence.",
            "zh": "然而，人们对N射线现象的怀疑已经开始，因为许多国际物理学家无法重现证明它们存在的实验结果。"
        }
    },
    {
        "translation": {
            "en": "(c) The following image provides a template diagram for the sequence of matrix operations that our neural network would use to process the input vector Neuron 1 = 0.7 and Neuron 2 = 0.3. Assuming that the processing neurons in the network use a ReLU activation function, fill in the diagram with the appropriate weights, bias terms, weighted sum values, and activations.",
            "zh": "（c） 下图提供了矩阵操作序列的模板图，我们的神经网络将用于处理输入向量神经元 1 = 0.7 和神经元 2 = 0.3。假设网络中的处理神经元使用 ReLU 激活函数，请在图中填写适当的权重、偏差项、加权总和值和激活。"
        }
    },
    {
        "translation": {
            "en": "(b) What would be the output from this neuron if the activation function φ is a threshold activation with θ = 1?",
            "zh": "（b） 如果激活函数φ是 θ = 1 的阈值激活，那么该神经元的输出是什么？"
        }
    },
    {
        "translation": {
            "en": "Topics covered include interpreting a linear regression model, using weight decay to set the learning rate, handling categorical descriptive and target features, using feature selection, using multivariable linear regression models to model non-linear relationships, and using support vector machines (SVMs) as an alternative to linear regression models.",
            "zh": "涵盖的主题包括解释线性回归模型、使用权重衰减设置学习率、处理分类描述性和目标特征、使用特征选择、使用多变量线性回归模型对非线性关系进行建模，以及使用支持向量机 （SVM） 作为线性回归模型的替代方案。"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C., and George C. Runger. 2010. Applied statistics and probability for engineers. Wiley.",
            "zh": "蒙哥马利、道格拉斯 C. 和乔治 C. 朗格。2010. 工程师应用统计与概率.威利。"
        }
    },
    {
        "translation": {
            "en": "TOP-10 INCOME, the percentage of the annual income of the country that goes to the top 10% of earners",
            "zh": "TOP-10 INCOME，该国年收入中收入最高的 10% 的百分比"
        }
    },
    {
        "translation": {
            "en": "This is due to the trade-offs between false positives and false negatives.",
            "zh": "这是由于误报和漏报之间的权衡。"
        }
    },
    {
        "translation": {
            "en": "Table 6.16[284] shows the Laplace smoothed (with k = 3) probabilities required by a naive Bayes prediction model calculated from the dataset in Table 6.11[278].",
            "zh": "表6.16[284]显示了从表6.11[278]中的数据集计算出的朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率。"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm uses a top-down, recursive, depth-first partitioning of the dataset to build a tree model beginning at the root node and finishing at the leaf nodes.",
            "zh": "ID3 算法使用自上而下的递归、深度优先的数据集分区来构建从根节点开始到叶节点结束的树模型。"
        }
    },
    {
        "translation": {
            "en": "When no relationship exists, the box plots should all appear similar.",
            "zh": "当不存在任何关系时，箱形图应全部显示为相似。"
        }
    },
    {
        "translation": {
            "en": "3.1.1 Case Study: Motor Insurance Fraud",
            "zh": "3.1.1 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated all these error gradients for a sequence, we then update each weight by summing all the error gradients for that weight and then using the summed error gradient to update the weight.",
            "zh": "一旦我们计算了一个序列的所有这些误差梯度，我们就会通过将该权重的所有误差梯度相加，然后使用总和的误差梯度来更新权重来更新每个权重。"
        }
    },
    {
        "translation": {
            "en": "When you first see the game played, because the dealer lays out the three cards so quickly, you think that there is no way to tell where the queen lands.",
            "zh": "当你第一次看到游戏时，因为庄家把三张牌摆得太快了，你以为没有办法分辨皇后落在哪里。"
        }
    },
    {
        "translation": {
            "en": "Others, however, arise because of perfectly valid data that may cause difficulty to some machine learning techniques.",
            "zh": "然而，其他问题则是因为完全有效的数据可能会给某些机器学习技术带来困难。"
        }
    },
    {
        "translation": {
            "en": "For example, in a medical diagnosis problem, we might confidently say that a false negative (telling a sick patient that they do not have a disease) is worse than a false positive (telling a healthy patient that they do have a disease), but it is unlikely that we will be able to quantify this as twice as bad, or four times as bad, or 10.75 times as bad.",
            "zh": "例如，在医学诊断问题中，我们可能会自信地说假阴性（告诉病人他们没有疾病）比假阳性（告诉健康患者他们确实有疾病）更糟糕，但我们不太可能将其量化为两倍的糟糕程度。 或四倍的坏，或十分七十五的坏。"
        }
    },
    {
        "translation": {
            "en": "15. The website kdnuggets.com runs a regular poll on the most popular programming languages for predictive data analytics, which R and Python regularly top, www.kdnuggets.com/polls/2013/languages-analytics-data-mining-data-science.html. For further details about R and Python, see www.r-project.org and www.python.org.",
            "zh": "15. 该网站 kdnuggets.com 对最流行的预测数据分析编程语言进行定期民意调查，其中 R 和 Python 经常名列前茅，www.kdnuggets.com/polls/2013/languages-analytics-data-mining-data-science.html。有关 R 和 Python 的更多详细信息，请参阅 www.r-project.org 和 www.python.org。"
        }
    },
    {
        "translation": {
            "en": "The advantage of using evaluation approaches based on comparing the distribution of a model’s output, such as the stability index, is that they do not require that the true targets for query instances become available shortly after predictions have been made.",
            "zh": "使用基于比较模型输出（如稳定性指数）分布的评估方法的优点是，它们不要求查询实例的真正目标在做出预测后不久就可用。"
        }
    },
    {
        "translation": {
            "en": "The updated cluster memberships based on these distances are shown in the rightmost column of Table 10.1[604].",
            "zh": "基于这些距离的更新的集群成员身份显示在表 10.1[604] 的最右边列中。"
        }
    },
    {
        "translation": {
            "en": "We will always use 2 as the base, s, when we calculate entropy, which means that we measure entropy in bits.5 Equation (4.1)[125] is the cornerstone of modern information theory and is an excellent measure of the impurity—heterogeneity—of a set.",
            "zh": "当我们计算熵时，我们总是使用 2 作为基数 s，这意味着我们以比特为单位测量熵.5 方程 （4.1）[125] 是现代信息论的基石，也是衡量集合的不纯性（异质性）的极好方法。"
        }
    },
    {
        "translation": {
            "en": "Table A.4",
            "zh": "表 A.4"
        }
    },
    {
        "translation": {
            "en": "When framed as a greedy local search problem, feature selection is defined in terms of an iterative process consisting of the following components:",
            "zh": "当被框定为贪婪的局部搜索问题时，特征选择是根据由以下组件组成的迭代过程来定义的："
        }
    },
    {
        "translation": {
            "en": "Over the course of this chapter, we look at the ways in which all these descriptive features can be used to train an error-based model to predict office rental prices.",
            "zh": "在本章中，我们将研究所有这些描述性特征可用于训练基于错误的模型来预测办公室租金价格的方法。"
        }
    },
    {
        "translation": {
            "en": "Using the definition of churn as a customer who had not made any calls or paid a bill for one month, Ross was able to identify churn events throughout this time period.",
            "zh": "使用流失的定义，即一个月没有拨打任何电话或支付账单的客户，Ross 能够识别整个时间段的流失事件。"
        }
    },
    {
        "translation": {
            "en": "critical value pruning, 155",
            "zh": "临界值修剪，155"
        }
    },
    {
        "translation": {
            "en": "Table 8.8",
            "zh": "表 8.8"
        }
    },
    {
        "translation": {
            "en": "This algorithm is very similar to the Q-learning algorithm in Algorithm 13[658].",
            "zh": "该算法与算法13[658]中的Q学习算法非常相似。"
        }
    },
    {
        "translation": {
            "en": "The logistic function14 is given by",
            "zh": "逻辑函数14由下式给出"
        }
    },
    {
        "translation": {
            "en": "PETROR90_U/G/R/I/Z",
            "zh": "PETROR90_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The algorithm stores the instance indexed by the leaf node in the best variable and sets the best-distance variable to the distance between the instance indexed by the leaf node and the query instance (Lines 5, 6, and 7).",
            "zh": "该算法将叶节点索引的实例存储在最佳变量中，并将最佳距离变量设置为叶节点索引的实例与查询实例之间的距离（第 5、6 和 7 行）。"
        }
    },
    {
        "translation": {
            "en": "THICKNESS",
            "zh": "厚度"
        }
    },
    {
        "translation": {
            "en": "LIFETIME",
            "zh": "辈子"
        }
    },
    {
        "translation": {
            "en": "The SDSS spectrographs perform this task for manually identified night sky objects and produce spectrograms across wavelengths from visible blue light to near-infrared light.",
            "zh": "SDSS光谱仪对手动识别的夜空物体执行此任务，并生成从可见蓝光到近红外光的波长的光谱图。"
        }
    },
    {
        "translation": {
            "en": "When datasets are small, a parametric model may perform well because the strong assumptions made by the model—if correct—can help the model to avoid overfitting.",
            "zh": "当数据集较小时，参数化模型可能表现良好，因为模型做出的强假设（如果正确）可以帮助模型避免过度拟合。"
        }
    },
    {
        "translation": {
            "en": "It is tempting to infer the relative importance of the different descriptive features in the model from the magnitude of the weights—that is, the descriptive features associated with higher weights are more predictive than those with lower weights.",
            "zh": "从权重的大小推断模型中不同描述性特征的相对重要性是很诱人的，也就是说，与较高权重相关的描述性特征比权重较低的描述性特征更具预测性。"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the distributions we wish to use, to define a PDF for a descriptive feature that is conditioned on a particular target, we fit the parameters of the selected distribution to the subset of the data where the target has that value.",
            "zh": "一旦我们选择了我们希望使用的分布，为以特定目标为条件的描述性特征定义 PDF，我们就会将所选分布的参数拟合到目标具有该值的数据子集。"
        }
    },
    {
        "translation": {
            "en": "One of the problems faced by ecological management practitioners is that it is often too expensive to do large-scale, high-resolution land surveys.",
            "zh": "生态管理从业者面临的问题之一是，进行大规模、高分辨率的土地调查往往成本太高。"
        }
    },
    {
        "translation": {
            "en": "However, in some instances we may wish to set bias terms to non-zero values; for example, ReLUs saturate when z < 0, and so to avoid dead ReLUs, the heuristic of initializing the bias terms for ReLU units to a small positive number (such as 0.1) is sometimes used (Goodfellow et al., 2016, pp.",
            "zh": "但是，在某些情况下，我们可能希望将偏差项设置为非零值;例如，当 z < 0 时，ReLU 会饱和，因此为了避免死 ReLU，有时会使用将 ReLU 单元的偏差项初始化为一个小正数（例如 0.1）的启发式方法（Goodfellow 等人，2016 年，第 1 页）。"
        }
    },
    {
        "translation": {
            "en": "By this time a clear optimal route through the graph has emerged running straight down from the top to the bottom, and we can say that the agent has learned to perform the navigation task.",
            "zh": "此时，图中出现了一条清晰的最佳路线，从上到下一直向下延伸，我们可以说代理已经学会了执行导航任务。"
        }
    },
    {
        "translation": {
            "en": "The prediction model could be easily integrated with AT’s current business processes. AT already had a retention team in place that was making proactive interventions to help prevent churn, albeit using a very simple system to identify which customers to contact. By creating a more sophisticated model to identify those customers, this existing process would be improved.",
            "zh": "预测模型可以很容易地与AT当前的业务流程集成。AT已经有一个保留团队，该团队正在采取积极的干预措施来帮助防止客户流失，尽管使用一个非常简单的系统来识别要联系的客户。通过创建一个更复杂的模型来识别这些客户，这个现有的流程将得到改进。"
        }
    },
    {
        "translation": {
            "en": "At this stage we simply record any data quality issues due to valid data in a data quality plan so that we remain aware of them and can handle them later if required.",
            "zh": "在此阶段，我们只需在数据质量计划中记录由于有效数据而导致的任何数据质量问题，以便我们随时了解这些问题，并在需要时稍后处理它们。"
        }
    },
    {
        "translation": {
            "en": "conditional probability tables: each node has a conditional probability table (CPT) associated with it. A CPT lists the probability distribution of the feature represented by the node conditioned on the features represented by the other nodes to which a node is connected by edges.",
            "zh": "条件概率表：每个节点都有一个与之关联的条件概率表（CPT）。CPT 列出节点所表示的特征的概率分布，该特征以节点通过边连接到的其他节点所表示的特征为条件。"
        }
    },
    {
        "translation": {
            "en": "7.1   Big Idea",
            "zh": "7.1 大创意"
        }
    },
    {
        "translation": {
            "en": "Data Preparation: Building predictive data analytics models requires specific kinds of data, organized in a specific kind of structure known as an analytics base table (ABT).13 This phase of CRISP-DM includes all the activities required to convert the disparate data sources that are available in an organization to a well-formed ABT from which machine learning models can be induced.",
            "zh": "数据准备：构建预测性数据分析模型需要特定类型的数据，这些数据以称为分析基表 （ABT） 的特定结构进行组织.13 CRISP-DM 的这一阶段包括将组织中可用的不同数据源转换为格式良好的 ABT 所需的所有活动，从中可以衍生出机器学习模型。"
        }
    },
    {
        "translation": {
            "en": "in all tables).",
            "zh": "在所有表中）。"
        }
    },
    {
        "translation": {
            "en": "The bold lines show the path taken to descend the tree from the root to a leaf node based on the values of the query instance (use Figure 5.9(a)[199] to trace this path in detail).",
            "zh": "粗体线显示了根据查询实例的值将树从根降到叶节点所采用的路径（使用图 5.9（a）[199] 详细跟踪此路径）。"
        }
    },
    {
        "translation": {
            "en": "false positive, 254, 537, 556",
            "zh": "误报， 254， 537， 556"
        }
    },
    {
        "translation": {
            "en": "Polynomial relationships allow multiplication of descriptive feature values by each other and raising of descriptive features to exponents.",
            "zh": "多项式关系允许描述性特征值相互相乘，并将描述性特征提升为指数。"
        }
    },
    {
        "translation": {
            "en": "However, if the representations become too sparse, then the performance of the network may deteriorate.",
            "zh": "但是，如果表示形式变得过于稀疏，则网络的性能可能会下降。"
        }
    },
    {
        "translation": {
            "en": "We explain subsequently why this is the case, but first we note that for ease of exposition in this discussion, we will ignore the bias terms in the weights of a neuron.",
            "zh": "我们随后解释了为什么会这样，但首先我们注意到，为了便于在本次讨论中阐述，我们将忽略神经元权重中的偏差项。"
        }
    },
    {
        "translation": {
            "en": "During this backward pass, an error gradient for each neuron is calculated.",
            "zh": "在此向后传递过程中，计算每个神经元的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "Boltzmann action selection is another commonly used alternative that uses the action-value function values, Q(st,at), for each possible action to build a softmax probability distribution, .",
            "zh": "玻尔兹曼动作选择是另一种常用的替代方法，它使用动作-值函数值 Q（st，at） 来构建软最大概率分布 。"
        }
    },
    {
        "translation": {
            "en": "The policy can be thought of as a simple lookup table that records the action that should be taken in every state, and reinforcement learning problems can be framed as an effort to learn this table directly.4 Policies can also be encoded as a rule used to choose an action from those available in a particular state, and this is the approach we focus on in this chapter.",
            "zh": "该策略可以被看作是一个简单的查找表，它记录了在每个状态下应该采取的行动，而强化学习问题可以被框定为直接学习这个表的努力。4 策略也可以编码为一个规则，用于从特定状态中可用的操作中选择一个操作， 这就是我们在本章中重点讨论的方法。"
        }
    },
    {
        "translation": {
            "en": "9.4.1 Designing Evaluation Experiments",
            "zh": "9.4.1 设计评估实验"
        }
    },
    {
        "translation": {
            "en": "deep Q learning, 677",
            "zh": "深度 Q 学习，677"
        }
    },
    {
        "translation": {
            "en": "What is the relationship between a measure of heterogeneity of a set and predictive analytics? If we can construct a sequence of tests that splits the training data into pure sets with respect to the target feature values, then we can label queries by applying the same sequence of tests to a query and labeling it with the target feature value of instances in the set in which it ends up.",
            "zh": "集合的异质性度量与预测分析之间有什么关系？如果我们可以构造一个测试序列，将训练数据拆分为相对于目标特征值的纯集，那么我们可以通过将相同的测试序列应用于查询并使用最终所在的集合中实例的目标特征值来标记查询。"
        }
    },
    {
        "translation": {
            "en": "Correlation7 is a normalized form of covariance that ranges between − 1 and + 1.",
            "zh": "Correlation7 是协方差的归一化形式，范围介于 − 1 和 + 1 之间。"
        }
    },
    {
        "translation": {
            "en": "12.3   Data Preparation",
            "zh": "12.3 数据准备"
        }
    },
    {
        "translation": {
            "en": "The Q-learning algorithm (Algorithm 13[658])) starts by randomly initializing the action-value table (Line 13[658]). In this example all entries have been initialized to random numbers in [−1,1]. There are 196 entries in the full action-value table—one for each of the four actions that can be taken in each of the 49 states that make up the grid world. Table 11.3[661] shows a portion of the action-value table.",
            "zh": "Q 学习算法（算法 13[658]））首先随机初始化动作值表（第 13 行[658]）。在此示例中，所有条目都已初始化为 [−1,1] 中的随机数。完整的操作值表中有 196 个条目，每个条目对应在构成网格世界的 49 个状态中每个状态中可以执行的四个操作。表 11.3[661] 显示了操作值表的一部分。"
        }
    },
    {
        "translation": {
            "en": "5.3.1   A Worked Example",
            "zh": "5.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "There is, therefore, a delicate balance that we need to strike between preparing the data so that it is appropriate for use with machine learning algorithms and keeping the data true to the underlying processes that generate it.",
            "zh": "因此，我们需要在准备数据以使其适合与机器学习算法一起使用和保持数据忠实于生成数据的底层过程之间取得微妙的平衡。"
        }
    },
    {
        "translation": {
            "en": "Xavier initialization, 458, 458, 459, 461",
            "zh": "Xavier 初始化、458、458、459、461"
        }
    },
    {
        "translation": {
            "en": "This is a very common scenario and a real thorn in the side of the predictive model builder—although there is often an almost endless amount of data available for training, little or none of it is labeled with the relevant target feature, making it effectively useless.",
            "zh": "这是一个非常常见的场景，也是预测模型构建器的真正难题——尽管通常有几乎无穷无尽的数据可用于训练，但很少有或根本没有用相关的目标特征标记，这使得它实际上毫无用处。"
        }
    },
    {
        "translation": {
            "en": "To make things manageable for this example, we aggressively discretize the representation of the value of the cards in the player’s and dealer’s hands. For the player’s hand, just three levels (low, medium, and high) are modeled",
            "zh": "为了使这个例子的事情易于管理，我们积极地离散了玩家和庄家手中的牌值的表示。对于玩家的手牌，只模拟了三个级别（低、中和高）"
        }
    },
    {
        "translation": {
            "en": "5.5   (a) The Voronoi tessellation of the feature space when the dataset has been updated to include the query instance; and (b) the updated decision boundary reflecting the addition of the query instance in the training set.",
            "zh": "5.5 （a） 当数据集更新为包含查询实例时，特征空间的 Voronoi 曲面细分;（b） 更新的决策边界，反映了在训练集中添加查询实例的情况。"
        }
    },
    {
        "translation": {
            "en": "EFFECTIVETAXRATE: The effective tax rate paid by the taxpayer (this is simply tax paid divided by total income).",
            "zh": "有效税率：纳税人支付的有效税率（这只是支付的税款除以总收入）。"
        }
    },
    {
        "translation": {
            "en": "For example, the derivative of speed with respect to time at time index 21 is the speed at time index 21 minus the speed at time index 20, which is 44.28 − 51.42 = 7.14.",
            "zh": "例如，速度相对于时间索引 21 的导数是时间索引 21 的速度减去时间索引 20 的速度，即 44.28 − 51.42 = 7.14。"
        }
    },
    {
        "translation": {
            "en": "List of Figures",
            "zh": "图表一览表"
        }
    },
    {
        "translation": {
            "en": "When 2,000 samples were generated, the relative frequency rose to 0.1975.",
            "zh": "当生成2,000个样本时，相对频率上升到0.1975。"
        }
    },
    {
        "translation": {
            "en": "Implementing a raw feature is simply a matter of copying the relevant raw value into the ABT.",
            "zh": "实现原始功能只需将相关的原始值复制到 ABT 中即可。"
        }
    },
    {
        "translation": {
            "en": "This stage of data exploration is mostly an information-gathering exercise, the output of which is just a better understanding of the contents of an ABT. It does, however, also present a good opportunity to discuss anything unusual that we notice about the central tendency and variation of features within the ABT. For example, a salary feature with a mean of 40 would seem unlikely (40,000 would seem more reasonable) and should be investigated.",
            "zh": "这一阶段的数据探索主要是信息收集活动，其输出只是更好地理解 ABT 的内容。然而，它也提供了一个很好的机会来讨论我们注意到的关于ABT中特征的中心趋势和变化的任何不寻常的事情。例如，平均值为 40 的工资特征似乎不太可能（40,000 似乎更合理），应该进行调查。"
        }
    },
    {
        "translation": {
            "en": "A credit scoring dataset.",
            "zh": "信用评分数据集。"
        }
    },
    {
        "translation": {
            "en": "1.8   The Road Ahead",
            "zh": "1.8 前方的道路"
        }
    },
    {
        "translation": {
            "en": "Predicting the number of bike rentals on a given day is useful because it can give the administrators of the bike sharing program an insight into the number of resources they need to have ready each day.",
            "zh": "预测给定日期的自行车租赁数量很有用，因为它可以让自行车共享计划的管理员深入了解他们每天需要准备的资源数量。"
        }
    },
    {
        "translation": {
            "en": "0.2491",
            "zh": "0.2491"
        }
    },
    {
        "translation": {
            "en": "If there is more time available, then “P.D.A.",
            "zh": "如果有更多时间，那么“P.D.A."
        }
    },
    {
        "translation": {
            "en": "Claude Shannon’s entropy model defines a computational measure of the impurity of the elements in a set.",
            "zh": "克劳德·香农（Claude Shannon）的熵模型定义了集合中元素杂质的计算度量。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.8",
            "zh": "图 9.8"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7[329] shows how different learning rates—0.002, 0.08, and 0.18—result in very different journeys across the error surface.8 The changing sum of squared errors that result from these journeys are also shown.",
            "zh": "图 7.7[329] 显示了不同的学习率（0.002、0.08 和 0.18）如何导致在误差面上截然不同的旅程8，还显示了这些旅程导致的平方误差的变化和。"
        }
    },
    {
        "translation": {
            "en": "To allow learning to take place in temporal-difference learning, we need to revisit the idea of a policy, and use policies that allow a balance of exploration and exploitation.",
            "zh": "为了让学习在时间差异学习中发生，我们需要重新审视政策的想法，并使用允许探索和利用平衡的政策。"
        }
    },
    {
        "translation": {
            "en": "training instance, 6",
            "zh": "训练实例，6"
        }
    },
    {
        "translation": {
            "en": "45. This omission of the sub-sampling layer is done simply to illustrate that it is optional.",
            "zh": "45. 省略子采样层只是为了说明它是可选的。"
        }
    },
    {
        "translation": {
            "en": "The problem, however, is that with a continuous feature, there is an infinite number of thresholds to choose from.",
            "zh": "然而，问题在于，对于连续特征，有无限数量的阈值可供选择。"
        }
    },
    {
        "translation": {
            "en": "Potential Handling Strategies",
            "zh": "可能的处理策略"
        }
    },
    {
        "translation": {
            "en": "To train the model, the institution has created a dataset from the results of previous marketing campaigns that list customer information—specifically the annual salary (SALARY) and age (AGE) of the customer—and whether the customer bought a product after they had been contacted via a direct marketing message (PURCH).",
            "zh": "为了训练该模型，该机构根据以前的营销活动的结果创建了一个数据集，其中列出了客户信息（特别是客户的年薪 （SALARY） 和年龄 （AGE），以及客户是否在通过直接营销消息 （PURCH） 联系后购买了产品。"
        }
    },
    {
        "translation": {
            "en": "This value can be seen in the dark shading of the cell corresponding to state 6-5 in the right grid in Figure 11.5(a)[663]. There are also some very lightly shaded cells in Figure 11.5(a)[663]—for example, cell 1-2 in the down panel—illustrating large negative values resulting from trips into the fiery cells and subsequent negative reward.",
            "zh": "该值可以在图11.5（a）[663]中右网格中与状态6-5相对应的单元格的深色阴影中看到。图11.5（a）[663]中还有一些非常浅色的单元格，例如，下图中的单元格1-2，说明了由于绊倒到炽热的单元格和随后的负奖励而产生的大负值。"
        }
    },
    {
        "translation": {
            "en": "The median is not as sensitive to outliers as the arithmetic mean and therefore can be a more accurate estimate of the central tendency of a set of values if outliers exist.",
            "zh": "中位数对异常值的敏感度不如算术平均值，因此如果存在异常值，则可以更准确地估计一组值的中心趋势。"
        }
    },
    {
        "translation": {
            "en": "frequency counts, 749",
            "zh": "频率计数，749"
        }
    },
    {
        "translation": {
            "en": "Gibbs sampling, 298",
            "zh": "吉布斯采样，298"
        }
    },
    {
        "translation": {
            "en": "The simplest performance measure we can use to assess how well this model has performed for this problem is the misclassification rate. The misclassification rate is the number of incorrect predictions made by the model divided by the total number of predictions made:",
            "zh": "我们可以用来评估该模型在这个问题上的表现如何的最简单的性能度量是错误分类率。错误分类率是模型做出的错误预测数除以做出的预测总数："
        }
    },
    {
        "translation": {
            "en": "6.4   Histograms of two unimodal datasets: (a) the distribution has light tails; and (b) the distribution has fat tails.",
            "zh": "6.4 两个单峰数据集的直方图：（a）分布有光尾;（b）分布有肥尾。"
        }
    },
    {
        "translation": {
            "en": "5.7   (a) The decision boundary using majority vote of the nearest 15 neighbors; and (b) the weighted k nearest neighbor model decision boundary (with k = 21).",
            "zh": "5.7 （a） 使用最近的15个相邻点的多数票作出的决定边界;（b）加权k最近邻模型决策边界（k = 21）。"
        }
    },
    {
        "translation": {
            "en": "We can see from this histogram that AGE follows a uniform distribution across a range from about 19 to about 35.",
            "zh": "从这个直方图中我们可以看到，AGE 在大约 19 到大约 35 的范围内遵循均匀分布。"
        }
    },
    {
        "translation": {
            "en": "D.2 Transpose",
            "zh": "D.2 转置"
        }
    },
    {
        "translation": {
            "en": "Code was then written to replace the previous simple rule about customer care contacts with the decision tree when retention call lists were generated.",
            "zh": "然后编写代码，在生成保留呼叫列表时，将之前关于客户服务联系人的简单规则替换为决策树。"
        }
    },
    {
        "translation": {
            "en": "column in the data quality report shows the number of distinct values present for a feature within an ABT.",
            "zh": "数据质量报告中的列显示 ABT 中要素存在的非重复值数。"
        }
    },
    {
        "translation": {
            "en": "Zhang, Nevin Lianwen, and David Poole. 1994. A simple approach to bayesian network computations. In Proceedings of the tenth biennial Canadian artificial intelligence conference, 171–178.",
            "zh": "Zhang、Nevin Lianwen 和 David Poole。1994. 贝叶斯网络计算的简单方法.第十届两年一度的加拿大人工智能会议论文集，171-178。"
        }
    },
    {
        "translation": {
            "en": "Data analytics practitioners can often be frustrated by legislation that stops them from including features that appear to be particularly well suited to an analytics solution in an ABT. Organizations must operate within the relevant legislation that is in place in the jurisdictions in which they operate, and it is important that models are not in breach of this. There are significant differences in legislation in different jurisdictions, but a couple of key relevant principles almost always apply.",
            "zh": "数据分析从业者通常会因立法而感到沮丧，这些立法阻止他们在 ABT 中包含似乎特别适合分析解决方案的功能。 组织必须在其运营所在司法管辖区的相关立法范围内运营，重要的是模型不违反这一点。不同司法管辖区的立法存在重大差异，但一些关键的相关原则几乎总是适用。"
        }
    },
    {
        "translation": {
            "en": "All state transition probabilities based on the Twist action can be calculated in a similar way.",
            "zh": "所有基于 Twist 动作的状态转换概率都可以用类似的方式计算。"
        }
    },
    {
        "translation": {
            "en": "Because an event defines a partition of a dataset (the rows from the dataset that match the event), then each Yi defines a set of rows from a dataset, and the set of data partitions defined by Y1 to Yk must cover the full dataset and not overlap with each other.",
            "zh": "因为一个事件定义了一个数据集的分区（数据集中与事件匹配的行），所以每个 Yi 定义了数据集中的一组行，而 Y1 到 Yk 定义的数据分区集必须覆盖整个数据集，并且不能相互重叠。"
        }
    },
    {
        "translation": {
            "en": "So, for example, the ROC index for the ROC curve shown in Figure 9.12(a)[562] is 0.798, and the ROC indices for Models 1 to 4 in Figure 9.12(b)[562] are 0.996, 0.887, 0.764, and 0.595 (as shown in the legend).",
            "zh": "例如，图9.12（a）[562]所示的ROC曲线的ROC指数为0.798，图9.12（b）[562]中模型1至4的ROC指数为0.996、0.887、0.764和0.595（如图所示）。"
        }
    },
    {
        "translation": {
            "en": "What is the capacity of the business to utilize the insights that the analytics solution will provide?",
            "zh": "企业利用分析解决方案将提供的见解的能力如何？"
        }
    },
    {
        "translation": {
            "en": "A.1 Descriptive Statistics for Continuous Features",
            "zh": "A.1 连续特征的描述性统计"
        }
    },
    {
        "translation": {
            "en": "In the bar plots in Figure 3.1[58], the different levels in the domain of each categorical feature, and how these levels are distributed, are obvious.",
            "zh": "在图3.1[58]的条形图中，每个分类特征域中的不同水平以及这些水平的分布方式是显而易见的。"
        }
    },
    {
        "translation": {
            "en": "This tells us not only something about how accurate the churn prediction model is but, more important, that using the model actually made a difference in the business problem that the company was trying to address.25",
            "zh": "这不仅告诉我们客户流失预测模型的准确性，更重要的是，使用该模型实际上对公司试图解决的业务问题产生了影响25。"
        }
    },
    {
        "translation": {
            "en": "Plots of the journeys made across the error surface for the simple office rentals prediction problem for different learning rates: (a) a very small learning rate (0.002); (b) a medium learning rate (0.08); and (c) a very large learning rate (0.18). The changing sum of squared errors are also shown.",
            "zh": "针对不同学习率的简单办公室租赁预测问题，在误差面上进行的旅程图：（a）非常小的学习率（0.002）;（b）中等学习率（0.08）;（c）非常高的学习率（0.18）。还显示了平方误差的变化和。"
        }
    },
    {
        "translation": {
            "en": "Models whose output changes drastically in response to small changes in the input are likely overfitting the data, because a small amount of noise in the input data can have a large effect on the outputs generated by the model.",
            "zh": "如果模型的输出会因输入中的微小变化而发生巨大变化，则可能是数据过度拟合，因为输入数据中的少量噪声会对模型生成的输出产生很大影响。"
        }
    },
    {
        "translation": {
            "en": "multimodal distribution, 60, 274",
            "zh": "多式联运配送， 60， 274"
        }
    },
    {
        "translation": {
            "en": "The existence of a high level of correlation between measurements indicated to Jocelyn that feature selection would be important later during the modeling phase as it had the potential to massively reduce the dimensionality of the dataset.",
            "zh": "测量值之间存在高度相关性，这向 Jocelyn 表明，特征选择在建模阶段的后期非常重要，因为它有可能大大降低数据集的维数。"
        }
    },
    {
        "translation": {
            "en": "The features included under this subconcept, all of which are derived features, are shown in Figure 2.10[44].",
            "zh": "该子概念下包含的特征，所有这些都是派生特征，如图2.10所示[44]。"
        }
    },
    {
        "translation": {
            "en": "Using the ground truth labels, calculate the squared error loss for each query instance (assume that benign = 0 and malignant = 1).",
            "zh": "使用真值标签，计算每个查询实例的平方误差损失（假设良性 = 0，恶性 = 1）。"
        }
    },
    {
        "translation": {
            "en": "7.3.4   A Worked Example",
            "zh": "7.3.4 工作示例"
        }
    },
    {
        "translation": {
            "en": "t represents the target feature.",
            "zh": "t 表示目标要素。"
        }
    },
    {
        "translation": {
            "en": "From calculus, the derivative of the natural log is",
            "zh": "从微积分来看，自然对数的导数是"
        }
    },
    {
        "translation": {
            "en": "3. Have corrected any data quality issues due to invalid data.",
            "zh": "3. 更正了因数据无效而导致的数据质量问题。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features in the SDSS dataset are primarily continuous. For this reason, Jocelyn considered trying a similarity-based model, the k nearest neighbor, and two error-based models, the logistic regression model and the support vector machine. Jocelyn began by constructing a simple baseline model using the 3-level target feature.",
            "zh": "SDSS 数据集中的描述性特征主要是连续的。出于这个原因，Jocelyn 考虑尝试一个基于相似性的模型，即 k 个最近邻，以及两个基于错误的模型，即逻辑回归模型和支持向量机。Jocelyn 首先使用 3 级目标特征构建了一个简单的基线模型。"
        }
    },
    {
        "translation": {
            "en": "Fit the parameters of the selected distribution to the feature values in the dataset.",
            "zh": "将所选分布的参数拟合到数据集中的要素值。"
        }
    },
    {
        "translation": {
            "en": "Figure 14.1",
            "zh": "图 14.1"
        }
    },
    {
        "translation": {
            "en": "Pearson, Karl, 82",
            "zh": "皮尔逊，卡尔，82 岁"
        }
    },
    {
        "translation": {
            "en": "Consequently, the weights used during the backpropagation of the δs plotted in Figure 8.24(d)[454] are sampled from a normal distribution with μ = 0.0 and σ = 0.2, which means that for all the layers var(W(k)) = σ2 = 0.22 = 0.04.",
            "zh": "因此，图8.24（d）[454]中绘制的δs反向传播过程中使用的权重是从μ = 0.0和σ = 0.2的正态分布中采样的，这意味着对于所有层，var（W（k）） = σ2 = 0.22 = 0.04。"
        }
    },
    {
        "translation": {
            "en": "We use P to write the true probability distribution over the categories of the target; to write the distribution over the target categories that the model has predicted; and to indicate the predicted probability for the true category.",
            "zh": "我们使用 P 来写出目标类别上的真实概率分布;写入模型预测的目标类别的分布;并指示真实类别的预测概率。"
        }
    },
    {
        "translation": {
            "en": "2. and then applying a decision rule over the class posteriors to return a target level.",
            "zh": "2. 然后对类后验应用决策规则以返回目标水平。"
        }
    },
    {
        "translation": {
            "en": "Table 3.1(b)[55] shows the structure of the table in a data quality report that describes categorical features.",
            "zh": "表3.1（b）[55]显示了描述分类特征的数据质量报告中的表格结构。"
        }
    },
    {
        "translation": {
            "en": "inter-annotator agreement, 726",
            "zh": "注释者间协议，726"
        }
    },
    {
        "translation": {
            "en": "11.1   Some episodes of games played by the TwentyTwos agent showing the cards dealt, as well as the states, actions, and rewards. Note that rewards are shown on the row indicating the action that led to them, not the state that followed that action.",
            "zh": "11.1 TwentyTwos特工玩的一些游戏片段显示了发牌，以及状态、行动和奖励。请注意，奖励显示在指示导致奖励的操作的行上，而不是该操作之后的状态。"
        }
    },
    {
        "translation": {
            "en": "8.3   The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places.",
            "zh": "8.3 联合循环电厂环境因素和满负荷电力输出的范围归一化小时样本，四舍五入到小数点后两位。"
        }
    },
    {
        "translation": {
            "en": "customer relationship management, 572",
            "zh": "客户关系管理，572"
        }
    },
    {
        "translation": {
            "en": "9.9   (a) The confusion matrix for a k-NN model trained on the payday loan credit scoring problem (average class accuracyHM = 83.824%); and (b) the confusion matrix for a decision tree model trained on the payday loan credit scoring problem (average class accuracyHM = 80.761%).",
            "zh": "9.9 （a） 在发薪日贷款信用评分问题上训练的 k-NN 模型的混淆矩阵（平均类准确率HM = 83.824%）;（b）在发薪日贷款信用评分问题上训练的决策树模型的混淆矩阵（平均类准确率HM = 80.761%）。"
        }
    },
    {
        "translation": {
            "en": "9.2 Fundamentals",
            "zh": "9.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "Figure 9.9[557] illustrates this: assuming that prediction scores are normally distributed, the distributions of the scores for the two target levels are shown for two different classification models.",
            "zh": "图 9.9[557] 说明了这一点：假设预测分数呈正态分布，则显示了两种不同分类模型的两个目标水平的分数分布。"
        }
    },
    {
        "translation": {
            "en": "AVGMINS",
            "zh": "AVGMINS的"
        }
    },
    {
        "translation": {
            "en": "email classification, 536",
            "zh": "电子邮件分类，536"
        }
    },
    {
        "translation": {
            "en": "Analysis of a subset of the features in the SDSS dataset.",
            "zh": "分析 SDSS 数据集中要素的子集。"
        }
    },
    {
        "translation": {
            "en": "The blindfold makes this quite challenging!",
            "zh": "眼罩使这非常具有挑战性！"
        }
    },
    {
        "translation": {
            "en": "For some Markov chains, mixing may require only a few iterations, but for others, it may require hundreds or thousands of iterations.",
            "zh": "对于某些马尔可夫链，混合可能只需要几次迭代，但对于其他马尔可夫链，可能需要数百或数千次迭代。"
        }
    },
    {
        "translation": {
            "en": "30. The architecture followed the architecture described by Mnih et al. (2013).",
            "zh": "30. 该架构遵循 Mnih 等人 （2013） 描述的架构。"
        }
    },
    {
        "translation": {
            "en": "3.9   A small sample of the HEIGHT and SPONSORSHIP EARNINGS features from the professional basketball team dataset in Table 3.7[73], showing the result of range normalization and standardization.",
            "zh": "3.9 表3.7[73]中职业篮球队数据集的HEIGHT和SPONSORSHIP EARNS特征的小样本，显示了范围标准化和标准化的结果。"
        }
    },
    {
        "translation": {
            "en": "9.4.6.1 Monitoring changes in performance measures The simplest way to get a signal that concept drift has occurred is to repeatedly evaluate models with the same performance measures used to evaluate them before deployment.",
            "zh": "9.4.6.1 监视性能度量的变化 要获得概念偏移已发生的信号，最简单的方法是在部署前使用与评估模型相同的性能度量来反复评估模型。"
        }
    },
    {
        "translation": {
            "en": "Throughout this section we use the terms similarity and distance almost interchangeably, because we often judge the similarity between two instances in terms of the distance between them in a feature space.",
            "zh": "在本节中，我们几乎可以互换使用术语“相似性”和“距离”，因为我们经常根据特征空间中两个实例之间的距离来判断它们之间的相似性。"
        }
    },
    {
        "translation": {
            "en": "It is not possible to know the actual return that will be earned by the agent across the entire episode until the episode is complete, and so it would not be possible to apply this update rule after early actions in the episode.",
            "zh": "在剧集完成之前，不可能知道代理在整个剧集中将获得的实际回报，因此在剧集中的早期操作之后，无法应用此更新规则。"
        }
    },
    {
        "translation": {
            "en": "network freezing, 671",
            "zh": "网络冻结，671"
        }
    },
    {
        "translation": {
            "en": "Figure 8.41[514] shows the dimensions of the different weight matrices in the unit where H = 2 and n = 1.",
            "zh": "图 8.41[514] 显示了 H = 2 且 n = 1 的单位中不同权重矩阵的维度。"
        }
    },
    {
        "translation": {
            "en": "The last issue to consider in relation to data when selecting machine learning approaches is the curse of dimensionality.",
            "zh": "在选择机器学习方法时，要考虑的最后一个与数据相关的问题是维度的诅咒。"
        }
    },
    {
        "translation": {
            "en": "8.4.6   Sequential Models: Recurrent Neural Networks and Long Short-Term Memory Networks",
            "zh": "8.4.6 顺序模型：递归神经网络和长短期记忆网络"
        }
    },
    {
        "translation": {
            "en": "4. Some might argue that the information on the application form summarizes an applicant’s entire life, so this constitutes the observation period in this case!",
            "zh": "4. 有人可能会争辩说，申请表上的信息概括了申请人的整个生活，所以这构成了本案的观察期！"
        }
    },
    {
        "translation": {
            "en": "lower quartile, 749, 755",
            "zh": "下四分位数， 749， 755"
        }
    },
    {
        "translation": {
            "en": "target level imbalance, 719",
            "zh": "目标水平不平衡，719"
        }
    },
    {
        "translation": {
            "en": "Figure 2.10",
            "zh": "图 2.10"
        }
    },
    {
        "translation": {
            "en": "pruning, 117, 170",
            "zh": "修剪， 117， 170"
        }
    },
    {
        "translation": {
            "en": "early stopping criteria, 152, 155",
            "zh": "提前停止标准，152,155"
        }
    },
    {
        "translation": {
            "en": "To conclude, the weaknesses of similarity-based learning approaches are that they are sensitive to the curse of dimensionality, they are slower than other models at making predictions (particularly with very large datasets), and they may not be able to achieve the same levels of accuracy as other learning approaches.",
            "zh": "总而言之，基于相似性的学习方法的弱点是它们对维度的诅咒很敏感，它们在进行预测方面比其他模型慢（特别是对于非常大的数据集），并且它们可能无法达到与其他学习方法相同的准确性水平。"
        }
    },
    {
        "translation": {
            "en": "Given a joint probability distribution, we can compute the probability of any event in the domain that it covers by summing over the cells in the distribution where that event is true.",
            "zh": "给定一个联合概率分布，我们可以通过对分布中该事件为真的单元格求和来计算它所覆盖的域中任何事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Consequently, for these matrices it is important to highlight the end of the connections the weights are applied to; we use a double subscript (similar to the subscript for a single weight), writing Whx for the weight matrix on the connections between the input (x) and the hidden layer (h).",
            "zh": "因此，对于这些矩阵，重要的是要突出显示施加权重的连接的末端;我们使用双下标（类似于单个权重的下标），在输入 （x） 和隐藏层 （h） 之间的连接上为权重矩阵写入 Whx。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have shown how k-d trees (Bentley, 1975; Friedman et al., 1977) can be used to speed up the retrieval of nearest neighbors.",
            "zh": "在本章中，我们展示了 k-d 树（Bentley，1975 年;Friedman等人，1977）可用于加速最近邻的检索。"
        }
    },
    {
        "translation": {
            "en": "gain chart, 567, 570",
            "zh": "增益图， 567， 570"
        }
    },
    {
        "translation": {
            "en": "The left side of Figure 8.5[392] presents a graph-based representation of a neural network; this network has a single hidden layer containing three neurons and an output layer with a single neuron in it.",
            "zh": "图 8.5[392] 的左侧显示了神经网络的基于图的表示;该网络有一个包含三个神经元的隐藏层和一个包含单个神经元的输出层。"
        }
    },
    {
        "translation": {
            "en": "The Sloan Digital Sky Survey (SDSS) is a landmark project that is cataloging the night sky in intricate detail and is facing exactly the problem described above.1 The SDSS telescopes collect over 175GB of data every night, and for the data collected to be fully exploited for science, each night sky object captured must be identified and cataloged within this data in almost real time.",
            "zh": "斯隆数字巡天 （SDSS） 是一个具有里程碑意义的项目，它以复杂的细节对夜空进行编目，并且正面临着上述问题.1 SDSS 望远镜每晚收集超过 175GB 的数据，为了充分利用收集到的数据用于科学，捕获的每个夜空物体都必须在这些数据中几乎实时地识别和编目。"
        }
    },
    {
        "translation": {
            "en": "2.4.4 Legal Issues",
            "zh": "2.4.4 法律问题"
        }
    },
    {
        "translation": {
            "en": "Ng, Andrew Y., Michael I. Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Advances in neural information processing systems, 849–856.",
            "zh": "吴恩达、安德鲁 Y.、迈克尔 I. 乔丹和亚尔·韦斯。2002. 关于光谱聚类：分析和算法.在神经信息处理系统进展中，849-856。"
        }
    },
    {
        "translation": {
            "en": "The animal species typically found in this vegetation include gray foxes, bobcats, skunks, and rabbits.",
            "zh": "通常在这种植被中发现的动物物种包括灰狐、山猫、臭鼬和兔子。"
        }
    },
    {
        "translation": {
            "en": "2.1   Converting Business Problems into Analytics Solutions",
            "zh": "2.1 将业务问题转化为分析解决方案"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with μ = 0.0 and σ = 0.2.",
            "zh": "图 8.22[450] 中网络的内部动力学，在第一次训练迭代期间，当权重使用 μ = 0.0 和 σ = 0.2 的正态分布进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "3. Provide complete worked examples. In this book we have presented complete workings for all examples, because this enables readers to check their understanding in detail.",
            "zh": "3. 提供完整的工作示例。在本书中，我们介绍了所有示例的完整工作原理，因为这使读者能够详细检查他们的理解。"
        }
    },
    {
        "translation": {
            "en": "ai refers to the value for feature a of the ith instance in a dataset.",
            "zh": "AI 是指数据集中第 i 个实例的特征 A 的值。"
        }
    },
    {
        "translation": {
            "en": "For example, for the sample mobile phone customer data used in this section, the type of tariff that customers had (e.g.",
            "zh": "例如，对于本节中使用的示例移动电话客户数据，客户拥有的资费类型（例如"
        }
    },
    {
        "translation": {
            "en": "The following table describes a set of students in terms of their grades out of 100 on two other modules (MODULE 1 and MODULE 2) and the GRADE they got in the lecturer’s module: first-class honors, second-class honors, pass, or fail.",
            "zh": "下表描述了一组学生在其他两个模块（模块 1 和模块 2）中的成绩（满分 100 分）以及他们在讲师模块中获得的成绩：一等荣誉、二等荣誉、通过或失败。"
        }
    },
    {
        "translation": {
            "en": "The Bayesian network models described in Chapter 6[243] are examples of generative models.1 Indeed, Markov chain Monte Carlo methods for estimating probabilities are based on the fact that we can run these models to generate data that approximate the distributions of the dataset from which the model was induced.",
            "zh": "第6章[243]中描述的贝叶斯网络模型是生成模型的例子.1事实上，用于估计概率的马尔可夫链蒙特卡洛方法基于这样一个事实，即我们可以运行这些模型来生成近似于模型所衍生的数据集分布的数据。"
        }
    },
    {
        "translation": {
            "en": "(d) What would be the output from this neuron if the activation function φ is the rectified linear function?",
            "zh": "（d） 如果激活函数φ是整流线性函数，那么这个神经元的输出会是什么？"
        }
    },
    {
        "translation": {
            "en": "Figure A.3[747] shows a rival school basketball team of that shown in Figure A.1[746].",
            "zh": "图A.3[747]显示了图A.1[746]所示的敌对学校篮球队。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13",
            "zh": "图 8.13"
        }
    },
    {
        "translation": {
            "en": "9.11   (a) The changing values of TPR and TNR for the test data shown in Table 9.13 [560] as the threshold is altered; and (b) points in ROC space for thresholds of 0.25, 0.5, and 0.75.",
            "zh": "9.11 （a） 表9.13 [560]所示测试数据的TPR和TNR值随着阈值的改变而变化;（b） ROC 空间中阈值为 0.25、0.5 和 0.75 的点。"
        }
    },
    {
        "translation": {
            "en": "The process of classifying an unknown animal by matching the features of the animal against the features of animals you have encountered before neatly encapsulates the big idea underpinning similarity-based learning: if you are trying to make a prediction for a current situation, then you should search your memory to find situations that are similar to the current one and make a prediction based on what was true for the most similar situation in your memory.",
            "zh": "通过将动物的特征与你之前遇到的动物的特征相匹配来对未知动物进行分类的过程，巧妙地概括了基于相似性学习的大概念：如果你试图对当前情况进行预测，那么你应该搜索你的记忆，找到与当前情况相似的情况，并根据你最相似的情况做出预测记忆。"
        }
    },
    {
        "translation": {
            "en": "global minimum, 318, 319",
            "zh": "全球最小值，318,319"
        }
    },
    {
        "translation": {
            "en": "We use the ⋆ symbol to indicate the index of the true category in the distribution.",
            "zh": "我们使用 ⋆ 符号来表示分布中真实类别的索引。"
        }
    },
    {
        "translation": {
            "en": "Subsequent centroids are then chosen randomly but following a distribution defined by the square of the distances between an instance and the nearest cluster centroid out of those found so far.",
            "zh": "然后随机选择后续质心，但遵循由实例与迄今为止发现的聚类质心之间的距离平方定义的分布。"
        }
    },
    {
        "translation": {
            "en": "For example, if we were trying to predict gender from a set of physiological measurements, height would most likely be a very predictive value, as it would separate people into male and female groups.",
            "zh": "例如，如果我们试图从一组生理测量中预测性别，身高很可能是一个非常具有预测性的值，因为它会将人们分为男性和女性群体。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.19(c)[158] illustrates the final iteration of the algorithm.",
            "zh": "图4.19（c）[158]说明了算法的最终迭代。"
        }
    },
    {
        "translation": {
            "en": "Stepping through Equation 8.104[501] we have the following four operations:",
            "zh": "通过方程 8.104[501]，我们有以下四个运算："
        }
    },
    {
        "translation": {
            "en": "In Line 5[420] the matrix of descriptive features for the examples in the mini-batch that is about to be processed is presented to the input layer of the network.",
            "zh": "在第 5 行 [420] 中，即将处理的小批量示例的描述性特征矩阵呈现给网络的输入层。"
        }
    },
    {
        "translation": {
            "en": "For example, we may be in a retail domain in which there are so many items that most people haven’t seen, listened to, bought, or visited the vast majority of them, and as a result, the majority of features will be co-absences.",
            "zh": "例如，我们可能处于一个零售领域，其中有太多的商品，大多数人没有看过、听过、买过或访问过其中的绝大多数，因此，大多数功能将同时缺席。"
        }
    },
    {
        "translation": {
            "en": "When we use a decision tree to make predictions for a continuous target, we refer to the tree as a regression tree.14 Typically, the value output by the leaf node of a regression tree is the mean of the target feature values of the instances from the training set that reached that node.",
            "zh": "当我们使用决策树对连续目标进行预测时，我们将该树称为回归树。14 通常，回归树的叶节点输出的值是到达该节点的训练集中实例的目标特征值的平均值。"
        }
    },
    {
        "translation": {
            "en": "In particular, the SDSS scientists wanted a system that could reliably classify galaxies into the important morphological (i.e., shape) types: elliptical galaxies and spiral galaxies.",
            "zh": "特别是，SDSS科学家想要一个能够可靠地将星系分类为重要的形态（即形状）类型的系统：椭圆星系和螺旋星系。"
        }
    },
    {
        "translation": {
            "en": "arithmetic mean, 550, 551, 577, 591, 745, 745",
            "zh": "算术平均值， 550， 551， 577， 591， 745， 745"
        }
    },
    {
        "translation": {
            "en": "The functioning of the output gate has a similar interpretation as the input gate: the tanh layer decides what information might be relevant to output from the current cell state, and the sigmoid layer uses the hxt vector to decide which activations are most relevant to output at this time-step.",
            "zh": "输出门的功能与输入门具有类似的解释：tanh 层决定哪些信息可能与当前单元状态的输出相关，而 sigmoid 层使用 hxt 向量来决定哪些激活与此时间步的输出最相关。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.7",
            "zh": "图 11.7"
        }
    },
    {
        "translation": {
            "en": "From these it is clear that instances from the dataset are being used as cluster centroids and that typically there is good diversity across the feature space in the centroids shown.",
            "zh": "从这些中可以清楚地看出，数据集中的实例被用作聚类质心，并且通常在所示质心的特征空间中具有良好的多样性。"
        }
    },
    {
        "translation": {
            "en": "second mode, 749",
            "zh": "第二模式，749"
        }
    },
    {
        "translation": {
            "en": "6.4.1 Smoothing",
            "zh": "6.4.1 平滑"
        }
    },
    {
        "translation": {
            "en": "Table 3.8",
            "zh": "表 3.8"
        }
    },
    {
        "translation": {
            "en": "Data quality issues due to valid data can arise for a range of domain-specific reasons (we discuss some of these later in this section), and we do not necessarily need to take any corrective action to address these issues.",
            "zh": "由于有效数据导致的数据质量问题可能由一系列特定领域的原因引起（我们将在本节后面讨论其中的一些原因），我们不一定需要采取任何纠正措施来解决这些问题。"
        }
    },
    {
        "translation": {
            "en": "A financial institution is planning a direct marketing campaign to sell a pension product to its customer base.",
            "zh": "一家金融机构正在计划开展直接营销活动，向其客户群销售养老金产品。"
        }
    },
    {
        "translation": {
            "en": "6.16   The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the data in Tables 6.11[278] and 6.15[283].",
            "zh": "6.16 朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表6.11[278]和表6.15[283]中的数据计算得出。"
        }
    },
    {
        "translation": {
            "en": "5.9   (a) The final k-d tree generated for the dataset in Table 5.4[191]; and (b) the partitioning of the feature space defined by this k-d tree.",
            "zh": "5.9 （a） 为表5.4[191]中的数据集生成的最终k-d树;（b）由该k-d树定义的特征空间的分区。"
        }
    },
    {
        "translation": {
            "en": "For most activation functions, avoiding saturation at initialization is achieved by avoiding large (positive or negative) z values, which in turn are avoided by initializing the weights to be close to 0.",
            "zh": "对于大多数激活函数，通过避免大（正或负）z 值来实现初始化时的饱和，而 z 值又通过初始化权重接近 0 来避免饱和。"
        }
    },
    {
        "translation": {
            "en": "The Laplace smoothed (with k = 3) probabilities needed by a naive Bayes prediction model, calculated from the dataset in Table 6.2[263].",
            "zh": "朴素贝叶斯预测模型所需的拉普拉斯平滑（k = 3）概率，根据表6.2[263]中的数据集计算得出。"
        }
    },
    {
        "translation": {
            "en": "1.3   (a)–(d) Striking a balance between overfitting and underfitting in trying to predict income from age.",
            "zh": "1.3 （a）–（d） 在试图从年龄预测收入时，在过度拟合和欠拟合之间取得平衡。"
        }
    },
    {
        "translation": {
            "en": "It is important that this is included at this stage because target features often need to be derived from multiple raw data sources, and the effort that will be involved in this should not be forgotten.",
            "zh": "在此阶段将其包括在内非常重要，因为目标特征通常需要从多个原始数据源派生，并且不应忘记其中涉及的工作。"
        }
    },
    {
        "translation": {
            "en": "Using box plots to visualize the relationships between categorical and continuous features from Table 3.7[73]: (a) and (b) show the relationship between the POSITION feature and the AGE feature; and (c) and (d) show the relationship between the POSITION feature and the HEIGHT feature.",
            "zh": "使用箱形图可视化表3.7[73]中的分类特征和连续特征之间的关系：（a）和（b）显示POSITION特征与AGE特征之间的关系;（c）和（d）显示了POSITION特征和HEIGHT特征之间的关系。"
        }
    },
    {
        "translation": {
            "en": "A duck, no matter how strange, is not a dangerous animal, so you tell the men to get ready for another expedition up the river the next day.",
            "zh": "鸭子，无论多么奇怪，都不是危险的动物，所以你告诉这些人准备第二天再去河上探险。"
        }
    },
    {
        "translation": {
            "en": "Although an MDP tells us everything we need to know about how an agent can take actions to move between states in an environment, it does not tell us anything about what actions the agent should take to be most successful.",
            "zh": "尽管 MDP 告诉我们有关代理如何采取措施在环境中的状态之间移动的所有信息，但它并没有告诉我们代理应该采取哪些操作才能最成功。"
        }
    },
    {
        "translation": {
            "en": "The corresponding calculation for P(¬m | h,¬f,v) is:",
            "zh": "P（¬m | h，¬f，v） 的相应计算为："
        }
    },
    {
        "translation": {
            "en": "C.3 Partial Derivatives",
            "zh": "C.3 偏导数"
        }
    },
    {
        "translation": {
            "en": "4.19   The iterations of reduced error pruning for the decision tree in Figure 4.18[156] using the validation set in Table 4.13[157]. The subtree that is being considered for pruning in each iteration is highlighted in black. The prediction returned by each non-leaf node is listed in square brackets. The error rate for each node is given in parantheses.",
            "zh": "4.19 使用表4.13[157]中的验证集，对图4.18[156]中的决策树进行减少误差修剪的迭代。在每次迭代中考虑修剪的子树以黑色突出显示。每个非叶节点返回的预测列在方括号中。每个节点的错误率以参数形式给出。"
        }
    },
    {
        "translation": {
            "en": "In fact, this figure could be reconfigured as three separate neurons, each receiving the same input vector.",
            "zh": "事实上，这个数字可以重新配置为三个独立的神经元，每个神经元接收相同的输入向量。"
        }
    },
    {
        "translation": {
            "en": "This set of domain concepts would have been determined through consultations between the analytics practitioner and domain experts within the business.",
            "zh": "这组领域概念是通过分析从业者和企业内部领域专家之间的协商来确定的。"
        }
    },
    {
        "translation": {
            "en": "standardization, 87, 101, 421, 450, 455",
            "zh": "标准化， 87， 101， 421， 450， 455"
        }
    },
    {
        "translation": {
            "en": "Rob: Autobiographical.”",
            "zh": "Rob：自传。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics models are reliant on the data that is used to build them—the analytics base table (ABT) is the key data resource in this regard.",
            "zh": "预测数据分析模型依赖于用于构建它们的数据，分析基表 （ABT） 是这方面的关键数据资源。"
        }
    },
    {
        "translation": {
            "en": "We use this handwritten digit recognition task as the basis for our examples in this section.",
            "zh": "我们将这个手写数字识别任务作为本节示例的基础。"
        }
    },
    {
        "translation": {
            "en": "The process then starts again using these new weights as the basis for the predictions and errors marked as Iteration 2 in Table 7.8[348].",
            "zh": "然后，该过程再次开始，使用这些新权重作为表7.8[348]中标记为迭代2的预测和误差的基础。"
        }
    },
    {
        "translation": {
            "en": "The if statement on line 8 will succeed, and the search process will descend down the other branch of the current node (Line 9), because there is possibly an instance closer than the current best instance stored down this branch.",
            "zh": "第 8 行的 if 语句将成功，搜索过程将下降到当前节点的另一个分支（第 9 行），因为可能有一个实例比存储在该分支下的当前最佳实例更接近。"
        }
    },
    {
        "translation": {
            "en": "3.7   Summary",
            "zh": "3.7 小结"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39",
            "zh": "图 8.39"
        }
    },
    {
        "translation": {
            "en": "She even occasionally made it all the way across the stream without stepping into the water and experienced the elation of landing on the grassy bank of the far side of the river.",
            "zh": "她甚至偶尔不踏入水中就一路穿过溪流，体验到降落在河对岸草地上的兴高采烈。"
        }
    },
    {
        "translation": {
            "en": "posterior probability, 759",
            "zh": "后验概率，759"
        }
    },
    {
        "translation": {
            "en": "sparse data, 215, 223, 225, 237, 262",
            "zh": "稀疏数据、215、223、225、237、262"
        }
    },
    {
        "translation": {
            "en": "To investigate outliers, we should always start by locating the instance in the dataset that contains the strange maximum or minimum values.",
            "zh": "要调查异常值，我们应该始终从在数据集中查找包含奇怪的最大值或最小值的实例开始。"
        }
    },
    {
        "translation": {
            "en": "Weighted Sums and Logits",
            "zh": "加权总和和对数"
        }
    },
    {
        "translation": {
            "en": "SOCIOECONOMIC BAND C",
            "zh": "社会经济等级 C"
        }
    },
    {
        "translation": {
            "en": "A grid for each action (up, down, left, and right) is shown where the shading in the grid illustrates the current estimate of the expected return of that action in the state corresponding to the grid cell position (darker shading indicates higher expected return with lighter shading indicating lower expected return).",
            "zh": "每个操作（向上、向下、向左和向右）的网格显示，其中网格中的底纹表示该操作在与网格像元位置相对应的状态下的预期回报的当前估计值（较深的阴影表示较高的预期回报，较浅的阴影表示较低的预期回报）。"
        }
    },
    {
        "translation": {
            "en": "5.4.2   Efficient Memory Search",
            "zh": "5.4.2 高效内存搜索"
        }
    },
    {
        "translation": {
            "en": "This kind of data is very common in real-world scenarios.",
            "zh": "这种数据在实际场景中很常见。"
        }
    },
    {
        "translation": {
            "en": "“We cannot solve our problems with the same thinking we used when we created them.”",
            "zh": "“我们不能用我们创造问题时使用的相同思维来解决我们的问题。”"
        }
    },
    {
        "translation": {
            "en": "2. Assigning a query a target value interpolated (for instance, by majority vote or average) from the target values of individual training instances that are near the query in the feature space.",
            "zh": "2. 为查询分配一个目标值，该目标值从特征空间中查询附近的单个训练实例的目标值中插值（例如，通过多数投票或平均值）。"
        }
    },
    {
        "translation": {
            "en": "2. Described in Section 5.2.2[184]. Although it is possible to use other distance measures, such as those described in Chapter 5[181], in k-means clustering this can break the guarantees that the algorithm makes about convergence. The k-medoids clustering algorithm (Kaufman and Rousseeuw, 1990) was developed to address these problems.",
            "zh": "2. 在第 5.2.2 节中描述[184]。尽管可以使用其他距离度量，例如第 5 章中描述的距离度量[181]，但在 k 均值聚类中，这可能会破坏算法对收敛性的保证。k-medoids聚类算法（Kaufman和Rousseeuw，1990）就是为了解决这些问题而开发的。"
        }
    },
    {
        "translation": {
            "en": "where the probabilities used in the calculation are read directly from the CPTs in Figure 6.9(a)[287].",
            "zh": "其中，计算中使用的概率直接从图6.9（a）中的CPT中读取[287]。"
        }
    },
    {
        "translation": {
            "en": "Consequently, unless care is taken, training a network can take an inordinately long time, compared with other machine learning models.",
            "zh": "因此，除非小心谨慎，否则与其他机器学习模型相比，训练网络可能需要非常长的时间。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix is a very quick way to explore the relationships within a whole set of continuous features. The effectiveness of scatter plot matrices, however, diminishes once the number of features in the set goes beyond 8 because the graphs become too small. Using interactive tools that aid data exploration can help overcome this limitation.",
            "zh": "散点图矩阵是探索一整套连续要素中关系的一种非常快速的方法。但是，一旦集合中的要素数量超过 8，散点图矩阵的有效性就会降低，因为图形变得太小。使用有助于数据探索的交互式工具可以帮助克服这一限制。"
        }
    },
    {
        "translation": {
            "en": "This is equivalent to the approach described in Section 3.5.1[72] for visually examining associations between descriptive features and a target feature, in which the cluster that instances belong to are used instead of an actual target feature.",
            "zh": "这相当于第 3.5.1 节[72]中描述的方法，用于直观地检查描述性特征与目标特征之间的关联，其中使用实例所属的集群而不是实际的目标特征。"
        }
    },
    {
        "translation": {
            "en": "The overall performance on this balanced dataset was not as good as the performance on the original dataset; however, balancing the training set did result in the performance on each target level being more equal.",
            "zh": "该平衡数据集的整体性能不如原始数据集的性能;然而，平衡训练集确实导致每个目标水平的表现更加平等。"
        }
    },
    {
        "translation": {
            "en": "So that we are consistent with the terminology throughout this book, in the rest of this chapter, we use the predictive analytics terms (feature, dataset, prediction, and event) rather than the traditional terms from probability.",
            "zh": "为了与本书中的术语保持一致，在本章的其余部分，我们使用预测分析术语（特征、数据集、预测和事件），而不是传统的概率术语。"
        }
    },
    {
        "translation": {
            "en": "Sometimes, however, a distinction is made that sampling bias affects the ability of a trained model to generalize appropriately beyond the sample training data to the rest of a population, whereas selection bias is more focused on the validity of similarities and differences found within the sample.",
            "zh": "然而，有时需要区分的是，抽样偏差会影响训练模型在样本训练数据之外适当地推广到总体其余部分的能力，而选择偏差则更侧重于样本中发现的相似性和差异性的有效性。"
        }
    },
    {
        "translation": {
            "en": "The second consideration is the timing with which data becomes available for inclusion in a feature.",
            "zh": "第二个考虑因素是数据可用于包含在功能中的时间。"
        }
    },
    {
        "translation": {
            "en": "The legal considerations surrounding predictive analytics are of growing importance and need to be seriously considered during the design of any analytics project. Although larger organizations have legal departments to whom proposed features can be handed over for assessment, in smaller organizations analysts are often required to make these assessments themselves, and consequently they need to be aware of the legal implications relating to their decisions.",
            "zh": "围绕预测分析的法律考虑因素越来越重要，在任何分析项目的设计过程中都需要认真考虑。尽管较大的组织有法律部门，可以将提议的功能移交给他们进行评估，但在较小的组织中，分析师通常需要自己进行这些评估，因此他们需要了解与其决策相关的法律影响。"
        }
    },
    {
        "translation": {
            "en": "SVM models are just one of a whole range of error-based approaches that are active areas for machine learning research, and new approaches are constantly being developed.",
            "zh": "SVM 模型只是一系列基于错误的方法之一，这些方法是机器学习研究的活跃领域，并且新方法正在不断开发中。"
        }
    },
    {
        "translation": {
            "en": "Table 11.4",
            "zh": "表 11.4"
        }
    },
    {
        "translation": {
            "en": "harmonic mean, 550, 551, 552, 554, 577, 586, 698",
            "zh": "谐波平均值，550、551、552、554、577、586、698"
        }
    },
    {
        "translation": {
            "en": "The labels on the rectangles indicate whether the rectangle represents the input layer xt, the hidden layer ht, the output layer yt, or the activation buffer that stores the activations of the hidden layer from the previous time-step ht−1.",
            "zh": "矩形上的标签指示矩形是表示输入层 xt、隐藏层 ht、输出层 yt，还是存储上一个时间步长 ht−1 中隐藏层激活的激活缓冲区。"
        }
    },
    {
        "translation": {
            "en": "tree pruning, 154, 169",
            "zh": "树木修剪， 154， 169"
        }
    },
    {
        "translation": {
            "en": "For example, some functions can be implemented exactly using a small neural network with two layers but require an infinite number of nodes to approximate with a single hidden layer (Makhoul et al., 1989; Reed and Marks, 1999).",
            "zh": "例如，某些函数可以使用具有两层的小型神经网络精确实现，但需要无限数量的节点才能近似于单个隐藏层（Makhoul et al.， 1989;Reed 和 Marks，1999 年）。"
        }
    },
    {
        "translation": {
            "en": "The K-S statistic is the maximum of these distances.",
            "zh": "K-S 统计量是这些距离的最大值。"
        }
    },
    {
        "translation": {
            "en": "This expansion in the number of terms arises from the fact that for all hidden neurons the δ term is calculated by a product of (1) ∂ℰ/∂ai, which itself is a product of the weighted sum of the δs backpropagated to the neuron; and (2) the derivative of the neuron’s activation function, that is, a term of the form ∂ak/∂zk (see Equation (8.23)[412]).",
            "zh": "项数的这种扩展源于这样一个事实，即对于所有隐藏神经元，δ项是由 （1） ∂E/∂ai 的乘积计算的，它本身是反向传播到神经元的 δs 加权和的乘积;（2）神经元激活函数的导数，即∂ak/∂zk形式的项（参见方程（8.23）[412]）。"
        }
    },
    {
        "translation": {
            "en": "Then, using the feature at the start of the list for the first split, we select the next feature in the list for each subsequent split.",
            "zh": "然后，使用列表开头的特征进行第一次拆分，我们为每个后续拆分选择列表中的下一个特征。"
        }
    },
    {
        "translation": {
            "en": "8.1 Big Idea",
            "zh": "8.1 大创意"
        }
    },
    {
        "translation": {
            "en": "interpretability of models, 739",
            "zh": "模型的可解释性，739"
        }
    },
    {
        "translation": {
            "en": "8.2   The minimum and maximum values for the AMBIENT TEMPERATURE, RELATIVE HUMIDITY, and ELECTRICAL OUTPUT features in the power plant dataset.",
            "zh": "8.2 电厂数据集中环境温度、相对湿度和电输出要素的最小值和最大值。"
        }
    },
    {
        "translation": {
            "en": "The figure also shows that the derivative is 0 (or near 0) for the saturated regions of the function: the logistic function saturates for large negative ( ≈ z < −2) or positive values (z > +2); this means that the rate of change of the output of the logistic function with respect to small changes in z, when z has a large negative or positive value, is 0 (or near 0).",
            "zh": "该图还显示，函数饱和区域的导数为 0（或接近 0）：对于大的负值 （ ≈ z < −2） 或正值 （z > +2），逻辑函数饱和;这意味着当 z 具有较大的负值或正值时，逻辑函数输出相对于 z 的微小变化的变化率为 0（或接近 0）。"
        }
    },
    {
        "translation": {
            "en": "Hence if the model assigns the maximum probability mass to an incorrect category, this will reduce and, as Figure (4.6)[125] illustrates, this will result in the negative log of the rapidly increasing.",
            "zh": "因此，如果模型将最大概率质量分配给不正确的类别，这将减少，并且如图（4.6）[125]所示，这将导致快速增加的负对数。"
        }
    },
    {
        "translation": {
            "en": "29. Feature selection is sometimes also known as variable selection.",
            "zh": "29. 特征选择有时也称为变量选择。"
        }
    },
    {
        "translation": {
            "en": "This is reflected in the stability index calculations in Table 9.21[581], which are determined using Equation (9.31)[580].",
            "zh": "这反映在表9.21[581]中的稳定性指数计算中，该计算使用公式（9.31）[580]确定。"
        }
    },
    {
        "translation": {
            "en": "missing values, 63, 64, 94, 231, 693",
            "zh": "缺少值、63、64、94、231、693"
        }
    },
    {
        "translation": {
            "en": "A simple linear regression model cannot handle this non-linear relationship. Figure 7.16(b)[352] shows the best simple linear regression model that can be trained for this prediction problem. This model is",
            "zh": "简单的线性回归模型无法处理这种非线性关系。图7.16（b）[352]显示了可以针对此预测问题训练的最佳简单线性回归模型。这个模型是"
        }
    },
    {
        "translation": {
            "en": "The sample space for a domain is the set of all possible combinations of assignments of values to features.",
            "zh": "域的样本空间是要素值赋值的所有可能组合的集合。"
        }
    },
    {
        "translation": {
            "en": "Score",
            "zh": "得分"
        }
    },
    {
        "translation": {
            "en": "The advantage of a local receptive field is that for a given neuron, the learning task is simplified to learning whether a particular feature occurs in a specific local region rather than learning to activate when one or more features occur anywhere in the visual field.",
            "zh": "局部感受野的优点是，对于给定的神经元，学习任务被简化为学习特定特征是否发生在特定的局部区域，而不是学习在视野中的任何位置出现一个或多个特征时激活。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.5",
            "zh": "图 6.5"
        }
    },
    {
        "translation": {
            "en": "2.4.6 Case Study: Motor Insurance Fraud",
            "zh": "2.4.6 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "In this appendix we introduce the fundamental statistical measures of central tendency and variation. We also introduce three of the most important and useful data visualization techniques that can be used to visualize a single feature: the bar plot, the histogram, and the box plot.",
            "zh": "在本附录中，我们介绍了集中趋势和变化的基本统计测量方法。我们还介绍了三种最重要和最有用的数据可视化技术，可用于可视化单个特征：条形图、直方图和箱形图。"
        }
    },
    {
        "translation": {
            "en": "9.4.2.1 Confusion matrix-based performance measures Confusion matrices are a convenient way to fully describe the performance of a predictive model when applied to a test set.",
            "zh": "9.4.2.1 基于混淆矩阵的性能测量 混淆矩阵是充分描述预测模型应用于测试集时性能的便捷方法。"
        }
    },
    {
        "translation": {
            "en": "We do not cover these techniques here, but they are covered in most standard linear algebra textbooks such as Anton and Rorres (2010).",
            "zh": "我们在这里不介绍这些技术，但它们在大多数标准线性代数教科书中都有所介绍，例如Anton和Rorres （2010）。"
        }
    },
    {
        "translation": {
            "en": "9. If data had been more scarce, pruning using a statistical test, such as χ2, would have been a more sensible route to take.",
            "zh": "9. 如果数据更加稀缺，使用统计检验（如χ2）进行修剪将是更明智的途径。"
        }
    },
    {
        "translation": {
            "en": "3.3.1 Missing Values",
            "zh": "3.3.1 缺失值"
        }
    },
    {
        "translation": {
            "en": "There are also situations, however, where we wish to change the size and/or the distributions of target values within the ABT.",
            "zh": "但是，在某些情况下，我们希望更改 ABT 中目标值的大小和/或分布。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features used by these models often can be automatically extracted from digitized maps, aerial photographs, or satellite imagery—for example, the elevation, steepness, color, and spectral reflection of the terrain and the presence or absence of features such as rivers, roads, or lakes.",
            "zh": "这些模型使用的描述性要素通常可以从数字化地图、航空照片或卫星影像中自动提取，例如，地形的高程、陡度、颜色和光谱反射，以及河流、道路或湖泊等要素的存在与否。"
        }
    },
    {
        "translation": {
            "en": "This loss function is called cross-entropy because in information theory cross-entropy is used to describe a measure of the difference in nats between two probability distributions over the same set of events.",
            "zh": "这种损失函数称为交叉熵，因为在信息论中，交叉熵用于描述同一组事件的两个概率分布之间的 nats 差异的度量。"
        }
    },
    {
        "translation": {
            "en": "Absolute rarity refers to scenarios in which there simply do not exist many examples of the minority target levels—for example, in automated inspection tasks on production lines, it is often the case that there are simply very few examples of defective products that can be used for training.",
            "zh": "绝对稀有性是指根本不存在少数目标水平的例子的场景——例如，在生产线上的自动化检测任务中，通常情况下，可用于培训的缺陷产品的例子很少。"
        }
    },
    {
        "translation": {
            "en": "To convert these information gain scores into information gain ratios, we need to compute the entropy of each feature and then divide the information gain scores by the respective entropy values. The entropy calculations for these descriptive features are",
            "zh": "为了将这些信息增益分数转换为信息增益比，我们需要计算每个特征的熵，然后将信息增益分数除以相应的熵值。这些描述性特征的熵计算是"
        }
    },
    {
        "translation": {
            "en": "The result is shown in Table 4.9[147].",
            "zh": "结果如表4.9[147]所示。"
        }
    },
    {
        "translation": {
            "en": "Only 2% of the values for the NUM.",
            "zh": "仅占 NUM 值的 2%。"
        }
    },
    {
        "translation": {
            "en": "Probability-based learning (Chapter 6[243])",
            "zh": "基于概率的学习（第6章[243]）"
        }
    },
    {
        "translation": {
            "en": "To start the search, the algorithm is given a seed network and then iteratively adapts this network by adding, removing, or reversing links (and/or adding and removing hidden nodes), accompanied by iterations of parameter learning after each network structure adaptation.",
            "zh": "为了开始搜索，算法被赋予一个种子网络，然后通过添加、删除或反转链接（和/或添加和删除隐藏节点）来迭代地适应这个网络，并在每个网络结构适应后进行参数学习的迭代。"
        }
    },
    {
        "translation": {
            "en": "AlphaGo, 677",
            "zh": "阿尔法围棋，677"
        }
    },
    {
        "translation": {
            "en": "Considering the distribution of the instances in the feature space as depicted in Figure 5.12(a)[205], the result that instance d6 is the nearest neighbor to the query is surprising. Several other instances appear to be much closer to the query, and importantly, several of these instances have a target level of no, for example, instance d1. Why do we get this strange result?",
            "zh": "考虑到图5.12（a）[205]中描述的实例在特征空间中的分布，实例d6是查询的最近邻的结果令人惊讶。其他几个实例似乎更接近查询，重要的是，其中一些实例的目标级别为 no，例如实例 d1。为什么我们会得到这个奇怪的结果？"
        }
    },
    {
        "translation": {
            "en": "(d) What target level will a naive Bayes model predict for the following query:",
            "zh": "（d） 朴素贝叶斯模型将预测以下查询的目标水平："
        }
    },
    {
        "translation": {
            "en": "The whiskers that emerge from the top and bottom of the main rectangle in a box plot are designed to show the range of the data. The top whisker extends to whichever is lower of the maximum value of the feature or the upper quartile plus 1.5 times the IQR. Similarly, the bottom whisker extends to whichever is higher of the minimum value of the feature or the lower quartile minus 1.5 times the IQR. Values that fall outside the whiskers are referred to as outliers and are shown as small circles.",
            "zh": "从箱形图中主矩形的顶部和底部出现的晶须旨在显示数据的范围。顶部胡须延伸到特征的最大值或上四分位数加上 IQR 的 1.5 倍的较低者。同样，底部晶须延伸到特征最小值或下四分位数减去 IQR 1.5 倍的较高者。位于胡须之外的值称为异常值，并显示为小圆圈。"
        }
    },
    {
        "translation": {
            "en": "2.4.1 Different Types of Data",
            "zh": "2.4.1 不同类型的数据"
        }
    },
    {
        "translation": {
            "en": "7.2.3   Error Surfaces",
            "zh": "7.2.3 错误面"
        }
    },
    {
        "translation": {
            "en": "Using this identity, we can define the first term in the product in Equation (8.72)[467]",
            "zh": "使用这个恒等式，我们可以在方程（8.72）[467]中定义乘积中的第一项"
        }
    },
    {
        "translation": {
            "en": "Figure 11.5(d)[663] shows the total cumulative reward (or return) earned by the agent for each of 350 learning episodes that the agent performs in this grid world environment (to make it easier to see the overall trend in this graph a rolling mean across 10 episodes is shown).",
            "zh": "图 11.5（d）[663] 显示了智能体在此网格世界环境中执行的 350 个学习事件中每个事件所获得的总累积奖励（或回报）（为了便于查看此图中的总体趋势，显示了 10 个事件的滚动平均值）。"
        }
    },
    {
        "translation": {
            "en": "The cardinality value indicates that every instance has the same value for this feature, ci.",
            "zh": "基数值表示每个实例对此功能 ci 具有相同的值。"
        }
    },
    {
        "translation": {
            "en": "Although monitoring changes in the performance of a model is the easiest way to tell whether it has gone stale, this method makes the rather large assumption that the correct target feature value for a query instance will be made available shortly after the query has been presented to a deployed model.",
            "zh": "尽管监视模型性能的变化是判断模型是否过时的最简单方法，但此方法做出了相当大的假设，即查询实例的正确目标特征值将在查询呈现给已部署的模型后不久可用。"
        }
    },
    {
        "translation": {
            "en": "This AHC algorithm requires two decisions to be made in order for it to be complete.",
            "zh": "此 AHC 算法需要做出两个决策才能完成。"
        }
    },
    {
        "translation": {
            "en": "Consequently, the gradients in this network will not be affected by saturated activation functions.29 Apart from adjusting the network architecture, we also increase the size of the training data to a sample of 100 examples, and we standardize30 all the features to have a mean of 0 and a standard deviation of 1.31",
            "zh": "因此，该网络中的梯度不会受到饱和激活函数的影响.29 除了调整网络架构外，我们还将训练数据的大小增加到 100 个样本，并将所有特征标准化 30，平均值为 0，标准差为 1.31"
        }
    },
    {
        "translation": {
            "en": "The Art of Machine Learning for Predictive Data Analytics",
            "zh": "预测数据分析的机器学习艺术"
        }
    },
    {
        "translation": {
            "en": "(c) Assuming that these models are part of an ensemble trained using boosting and that the confidence factors, α, for the models are as follows:",
            "zh": "（c） 假设这些模型是使用提升训练的集成的一部分，并且模型的置信因子α如下："
        }
    },
    {
        "translation": {
            "en": "The performance of the model measured using appropriate performance measures",
            "zh": "使用适当的性能度量衡量模型的性能"
        }
    },
    {
        "translation": {
            "en": "Consequently, a Bayesian network representation is generally more compact than a full joint distribution (because it can encode conditional independence relationships), yet it is not forced to assert a global conditional independence between all descriptive features.",
            "zh": "因此，贝叶斯网络表示通常比完全联合分布更紧凑（因为它可以编码条件独立关系），但它并不强制断言所有描述性特征之间的全局条件独立性。"
        }
    },
    {
        "translation": {
            "en": "As part of this type of broader evaluation, the use of comparative experiments that include a control group can be quite effective.",
            "zh": "作为这种更广泛评估的一部分，使用包括对照组在内的比较实验可能非常有效。"
        }
    },
    {
        "translation": {
            "en": "This states that the expected return of taking action at in state st is the immediate expected reward from taking that action plus the sum of discounted expected rewards that will arise if we continue to follow policy π.",
            "zh": "这表明，在状态下采取行动的预期回报是采取该行动的直接预期回报加上如果我们继续遵循政策π将产生的贴现预期回报的总和。"
        }
    },
    {
        "translation": {
            "en": "Neuron 8 is the only output neuron in the network, and so once δ8 has been calculated, we can then proceed to backpropagate the error gradient of the network for d2 and calculate the δs for Neurons 6 and 7. These are hidden neurons, so we use the Equation (8.23)[412] to calculate δ 6 and δ7; Equation (8.33)[428] steps through the calculation of δ6 and Equation (8.34)[428] steps through the calculation for δ7",
            "zh": "神经元 8 是网络中唯一的输出神经元，因此一旦计算了 δ8，我们就可以继续反向传播 d2 的网络误差梯度，并计算神经元 6 和 7 的 δ。这些是隐藏的神经元，所以我们使用方程（8.23）[412]来计算δ 6和δ7;方程（8.33）[428]逐步计算δ6，方程（8.34）[428]逐步计算δ7"
        }
    },
    {
        "translation": {
            "en": "9.5   A confusion matrix for a k-NN model trained on a churn prediction problem.",
            "zh": "9.5 基于流失预测问题训练的 k-NN 模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "In designing an ABT, the first decision an analytics practitioner needs to make is on the prediction subject for the model they are trying to build.",
            "zh": "在设计 ABT 时，分析从业者需要做出的第一个决定是他们试图构建的模型的预测主题。"
        }
    },
    {
        "translation": {
            "en": "The primary reason why we apply smoothing is to remove zero probabilities from a model’s representation of a domain, and in the vast majority of cases, all the unconditional target level probabilities will be non-zero (because there will be at least one instance with each target level in the training data).",
            "zh": "我们应用平滑的主要原因是从模型的域表示中删除零概率，并且在绝大多数情况下，所有无条件目标水平概率都将不为零（因为训练数据中每个目标水平至少有一个实例）。"
        }
    },
    {
        "translation": {
            "en": "In this instance the prediction subject is an insurance claim, and so the ABT for this problem will contain details of historical claims described by a set of descriptive features that capture likely indicators of fraud, and a target feature indicating whether a claim was ultimately considered fraudulent.",
            "zh": "在本例中，预测主题是保险索赔，因此此问题的 ABT 将包含由一组描述性特征描述的历史索赔的详细信息，这些特征捕获可能的欺诈指标，以及指示索赔最终是否被视为欺诈的目标特征。"
        }
    },
    {
        "translation": {
            "en": "Finally, the insurance company divides their operations into a number of geographic areas defined internally based on the location of their branches, and a feature is included that maps raw address data to these regions.",
            "zh": "最后，保险公司根据其分支机构的位置将其业务划分为内部定义的多个地理区域，并包含将原始地址数据映射到这些区域的功能。"
        }
    },
    {
        "translation": {
            "en": "equal-width binning, 89, 90, 102, 280",
            "zh": "等宽分档， 89， 90， 102， 280"
        }
    },
    {
        "translation": {
            "en": "Generative models tend to have a higher bias—they make more assumptions about the form of the distribution they are learning.",
            "zh": "生成模型往往具有更高的偏差——它们对正在学习的分布形式做出更多的假设。"
        }
    },
    {
        "translation": {
            "en": "becoming situationally fluent so that we can converse with experts in the application domain;",
            "zh": "变得情境流利，以便我们可以与应用领域的专家交谈;"
        }
    },
    {
        "translation": {
            "en": "Any measure of central tendency is, however, just an approximation, so we must be aware of the limitations of any measure that we use.",
            "zh": "然而，任何集中趋势的度量都只是一个近似值，因此我们必须意识到我们使用的任何度量的局限性。"
        }
    },
    {
        "translation": {
            "en": "3,800",
            "zh": "3,800"
        }
    },
    {
        "translation": {
            "en": "Once a δ has been calculated for every neuron in the network, the backward pass has completed (and in a sense so has the backpropagation algorithm, at least insofar as the algorithm is a solution to the blame assignment problem), and we are now ready to update the weights of the network using the δs as part of the gradient descent weight update rule.",
            "zh": "一旦计算了网络中每个神经元的δ，向后传递就完成了（从某种意义上说，反向传播算法也是如此，至少就该算法是归咎分配问题的解决方案而言），我们现在准备使用 δs 作为梯度下降权重更新规则的一部分来更新网络的权重。"
        }
    },
    {
        "translation": {
            "en": "Based on a set of descriptive features extracted from the loan application (e.g., AGE, OCCUPATION, and ASSETS), the model will classify potential borrowers as belonging to one of two groups: good borrowers, who will repay their loans in full; and bad borrowers, who will default on some portion of their loans.",
            "zh": "根据从贷款申请中提取的一组描述性特征（例如，年龄、职业和资产），该模型将潜在借款人分为两类：良好的借款人，他们将全额偿还贷款;以及不良借款人，他们将拖欠部分贷款。"
        }
    },
    {
        "translation": {
            "en": "Table 8.12[443] lists the predictions of the trained ReLU network for each of the examples and the calculation of the sum of squared errors once training has converged.",
            "zh": "表 8.12[443] 列出了每个示例的训练 ReLU 网络的预测，以及训练收敛后误差平方和的计算。"
        }
    },
    {
        "translation": {
            "en": "13   Case Study: Galaxy Classification",
            "zh": "13 案例研究：星系分类"
        }
    },
    {
        "translation": {
            "en": "Backward sequential selection terminates when no accessible feature subset is better than or as good as the current subset.",
            "zh": "当没有可访问的特征子集优于或与当前子集一样好时，向后顺序选择终止。"
        }
    },
    {
        "translation": {
            "en": "Palaniappan, Sellappan, and Rafiah Awang. 2008. Intelligent heart disease prediction system using data mining techniques. International Journal of Computer Science and Network Security 8 (8): 343–350.",
            "zh": "Palaniappan、Sellappan 和 Rafiah Awang。2008. 基于数据挖掘技术的智能心脏病预测系统.国际计算机科学与网络安全杂志 8 （8）：343–350。"
        }
    },
    {
        "translation": {
            "en": "Table 5.8",
            "zh": "表 5.8"
        }
    },
    {
        "translation": {
            "en": "There are many excellent books on linear algebra; one of the standard textbooks on the topic is (Strang, 2016).",
            "zh": "有许多关于线性代数的优秀书籍;关于该主题的标准教科书之一是（Strang，2016）。"
        }
    },
    {
        "translation": {
            "en": "Notice that the z values, activations, and δs have a relatively similar distribution across each of the layers of the network; that is, the training of the network is not suffering from either exploding z values (which would saturate activation functions if they were used) or exploding or vanishing δs.",
            "zh": "请注意，z 值、激活值和 δ 在网络的每个层中具有相对相似的分布;也就是说，网络的训练既不会受到爆炸 z 值（如果使用它们会使激活函数饱和）或爆炸或消失 δ 的影响。"
        }
    },
    {
        "translation": {
            "en": "In this simple example no cluster reassignments are made at the third iteration, and so the process is considered to have converged.",
            "zh": "在这个简单示例中，在第三次迭代时没有进行集群重新分配，因此该过程被视为已收敛。"
        }
    },
    {
        "translation": {
            "en": "We can intuitively see from Figure C.2(b)[767] for f(x) = x2 that the rate of change of the value of this function is likely to be high at the steep edges of the curve and low at the bottom (imagine a ball rolling around inside this shape!).",
            "zh": "我们可以从图 C.2（b）[767] 中直观地看到，当 f（x） = x2 时，该函数值的变化率可能在曲线的陡峭边缘很高，在底部很低（想象一个球在这个形状内滚动！"
        }
    },
    {
        "translation": {
            "en": "(c) What is the maximum possible entropy in bits for a set of eight Scrabble pieces?",
            "zh": "（c） 一组八个拼字游戏棋子的最大可能熵是多少？"
        }
    },
    {
        "translation": {
            "en": "Several important rules in probability theory allow us to compute new probabilities in terms of previously computed probabilities.",
            "zh": "概率论中的几个重要规则允许我们根据先前计算的概率来计算新的概率。"
        }
    },
    {
        "translation": {
            "en": "Caruana and Niculescu-Mizil (2006) and Caruana et al.",
            "zh": "Caruana和Niculescu-Mizil（2006年）和Caruana等人。"
        }
    },
    {
        "translation": {
            "en": "A multivariate linear regression model has been built to predict the heating load in a residential building on the basis of a set of descriptive features describing the characteristics of the building.",
            "zh": "建立了一个多元线性回归模型，根据一组描述建筑物特征的描述性特征来预测住宅建筑物的供热负荷。"
        }
    },
    {
        "translation": {
            "en": "Another advantage is that pruning often increases the accuracy of the trees when there is noise in the training dataset.",
            "zh": "另一个优点是，当训练数据集中存在噪声时，修剪通常会提高树木的准确性。"
        }
    },
    {
        "translation": {
            "en": "PDF, 269",
            "zh": "PDF格式， 269"
        }
    },
    {
        "translation": {
            "en": "The input to all three of these gates is the vector of hidden state activations propagated forward from the previous time-step ht−1 concatenated with the current input vector xt. In Figure 8.40[509] this concatenation is depicted by the intersection of the ht−1 and xt lines in the bottom-left corner of the figure. We use the term hxt to write the vector that is the result of concatenating ht−1 with xt. For example, if ht−1 = [a,b] and xt = [c,d], then hxt = [a,b,c,d].",
            "zh": "所有这三个门的输入都是从与当前输入向量 xt 连接的前一个时间步长 ht−1 向前传播的隐藏状态激活向量。在图8.40[509]中，这种串联由图左下角的ht−1和xt线的交点表示。我们使用术语 hxt 来编写向量，它是将 ht−1 与 xt 连接起来的结果。例如，如果 ht−1 = [a，b] 和 xt = [c，d]，则 hxt = [a，b，c，d]。"
        }
    },
    {
        "translation": {
            "en": "Given that consistency with the dataset is not an adequate criterion to select the best prediction model, which criteria should we use?",
            "zh": "鉴于与数据集的一致性不是选择最佳预测模型的充分标准，我们应该使用哪些标准？"
        }
    },
    {
        "translation": {
            "en": "EFFECTIVETAXRATE",
            "zh": "有效税率"
        }
    },
    {
        "translation": {
            "en": "This chapter covers a range of approaches for evaluating the performance of prediction models.",
            "zh": "本章介绍了评估预测模型性能的一系列方法。"
        }
    },
    {
        "translation": {
            "en": "The algorithm starts by initializing the Q values for every action in every state to the same values used before, shown in Table 11.3[661].",
            "zh": "该算法首先将每个状态下每个动作的 Q 值初始化为之前使用的相同值，如表 11.3[661] 所示。"
        }
    },
    {
        "translation": {
            "en": "CPI is the Corruption Perception Index (CPI), and it is the target feature. The CPI measures the perceived level of corruption in the public sector of a country and ranges from 0 (highly corrupt) to 100 (very clean).",
            "zh": "CPI 是清廉指数 （CPI），它是目标特征。CPI衡量一个国家公共部门的腐败程度，范围从0（高度腐败）到100（非常干净）。"
        }
    },
    {
        "translation": {
            "en": "Table 7.10",
            "zh": "表 7.10"
        }
    },
    {
        "translation": {
            "en": "However, the forward propagation through the network still occurs along an active path through Neuron 5.",
            "zh": "然而，通过网络的前向传播仍然沿着通过神经元 5 的活动路径发生。"
        }
    },
    {
        "translation": {
            "en": "This is done by assigning a portion of the δ of each output neuron to each of the hidden neurons connecting to it.",
            "zh": "这是通过将每个输出神经元的一部分δ分配给连接到它的每个隐藏神经元来完成的。"
        }
    },
    {
        "translation": {
            "en": "More challenging, there is the assumption that the company has the capacity to contact members based on this analysis and can design a way to discuss this issue with customers highlighted as likely to commit fraud without damaging the customer relationship so badly as to lose the customer.",
            "zh": "更具挑战性的是，假设公司有能力根据这种分析联系成员，并可以设计一种方法来与可能进行欺诈的客户讨论这个问题，而不会严重损害客户关系以致失去客户。"
        }
    },
    {
        "translation": {
            "en": "Let’s look at an example.",
            "zh": "让我们看一个例子。"
        }
    },
    {
        "translation": {
            "en": "Mappings: Mappings are used to convert continuous features into categorical features and are often used to reduce the number of unique values that a model will have to deal with. For example, rather than using a continuous feature measuring salary, we might instead map the salary values to low, medium, and high levels to create a categorical feature.",
            "zh": "映射：映射用于将连续特征转换为分类特征，通常用于减少模型必须处理的唯一值的数量。例如，我们可以将工资值映射到低、中和高级别，以创建分类特征，而不是使用连续特征来衡量工资。"
        }
    },
    {
        "translation": {
            "en": "We calculate the correlation between two features by dividing the covariance between the two features by the product of their standard deviations.",
            "zh": "我们通过将两个特征之间的协方差除以它们的标准差乘积来计算两个特征之间的相关性。"
        }
    },
    {
        "translation": {
            "en": "Over-sampling addresses the same issue as under-sampling but in the opposite way around.",
            "zh": "过采样与采样不足解决相同的问题，但方式相反。"
        }
    },
    {
        "translation": {
            "en": "—Albert Einstein",
            "zh": "——阿尔伯特·爱因斯坦"
        }
    },
    {
        "translation": {
            "en": "McCandlish, Sam, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. 2018. An empirical model of large-batch training. CoRR abs/1812.06162. http://arxiv.org/abs/1812.06162.",
            "zh": "McCandlish、Sam、Jared Kaplan、Dario Amodei 和 OpenAI Dota 团队。2018. 大批量训练的经验模型.CoRR abs/1812.06162。http://arxiv.org/abs/1812.06162。"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that if a neuron uses a logistic activation function, then we can train the neuron in the same way that we train a logistic regression function: using the gradient descent algorithm (introduced in Chapter 7[311]) and with the weight update rule defined in Equation (7.33)[346].",
            "zh": "这样做的一个结果是，如果神经元使用逻辑激活函数，那么我们可以用与训练逻辑回归函数相同的方式训练神经元：使用梯度下降算法（在第 7 章[311]中介绍）和方程 （7.33）[346] 中定义的权重更新规则。"
        }
    },
    {
        "translation": {
            "en": "The disadvantage of this, however, is that these types of measures by themselves are not sufficient to judge whether a model is making accurate predictions without deep knowledge of a domain.",
            "zh": "然而，这样做的缺点是，这些类型的度量本身不足以判断模型是否在没有深入了解领域的情况下做出准确的预测。"
        }
    },
    {
        "translation": {
            "en": "To intuitively understand the weight update rule given in Equation (7.17)[327], it helps to think in terms of what the weight update rule does to weights based on the error in the predictions made by the current candidate model:",
            "zh": "为了直观地理解等式（7.17）[327]中给出的权重更新规则，根据当前候选模型的预测误差，思考权重更新规则对权重的作用是有帮助的："
        }
    },
    {
        "translation": {
            "en": "This result is contrary to the conclusion drawn from classification accuracy but is more appropriate in this case due to the target level imbalance present in the data.",
            "zh": "这一结果与从分类准确性得出的结论相反，但在这种情况下更合适，因为数据中存在目标水平不平衡。"
        }
    },
    {
        "translation": {
            "en": "Imagine that we are dealers in rare whiskey, and we would like some assistance in setting the reserve price for bottles of whiskey that we are selling at auction.",
            "zh": "想象一下，我们是稀有威士忌的经销商，我们希望在为我们在拍卖会上出售的威士忌瓶设定底价方面得到一些帮助。"
        }
    },
    {
        "translation": {
            "en": "As we recommended the use of harmonic mean over arithmetic mean when calculating average class accuracy, we recommend the use of root mean squared error over mean absolute error because it is better to be pessimistic when estimating the performance of models.",
            "zh": "由于我们建议在计算平均类准确率时使用调和均值而不是算术平均值，因此我们建议使用均方根误差而不是平均绝对误差，因为在估计模型性能时最好保持悲观。"
        }
    },
    {
        "translation": {
            "en": "A model could be built to predict the overall value that AT was likely to receive from a particular customer over the person’s entire customer lifecycle.",
            "zh": "可以建立一个模型来预测AT在个人的整个客户生命周期中可能从特定客户那里获得的总体价值。"
        }
    },
    {
        "translation": {
            "en": "These are also the only two rows that fulfill the conditions of the second term in the chain sequence, P(f | h,m).",
            "zh": "这也是满足链序列中第二项条件的仅有的两行，P（f | h，m）。"
        }
    },
    {
        "translation": {
            "en": "Equations (7.11)[324] to (7.14)[324] step through the derivation of the rate of change of the error of a model (in that case, a linear regression model) for a single input example d with respect to changes in one of the model’s weights ∂L2(𝕄w, d)/∂w[j], resulting in",
            "zh": "方程（7.11）[324]至（7.14）[324]逐步推导了单个输入示例d的模型（在这种情况下，线性回归模型）的误差变化率，该模型相对于模型权重之一∂L2（Mw， d）/∂w[j]的变化，结果为："
        }
    },
    {
        "translation": {
            "en": "When performing data exploration, data visualization can help enormously. In this section we describe three important data visualization techniques that can be used to visualize the values in a single feature: the bar plot, the histogram, and the box plot. For the examples throughout this section, we will use the dataset in Table A.1[750], which lists the position that each player on a school basketball team plays at and the average training expenses they accrue each month.",
            "zh": "在执行数据探索时，数据可视化可以极大地帮助。在本节中，我们将介绍三种重要的数据可视化技术，这些技术可用于可视化单个要素中的值：条形图、直方图和箱形图。对于本节中的示例，我们将使用表 A.1[750] 中的数据集，该数据集列出了学校篮球队中每个球员所处的位置以及他们每月产生的平均训练费用。"
        }
    },
    {
        "translation": {
            "en": "5. The Theorem of Total Probability is explained in detail in Section B.3[762] of Appendix B[757].",
            "zh": "5. 总概率定理在附录B[757]的B.3[762]节中有详细解释。"
        }
    },
    {
        "translation": {
            "en": "These memberships are illustrated in Figure 10.3(c)[602].",
            "zh": "这些隶属关系如图10.3（c）[602]所示。"
        }
    },
    {
        "translation": {
            "en": "The year is 1904, and you are a research assistant working in the lab of physicist Professor René Blondlot, at the University of Nancy, in France.",
            "zh": "这一年是1904年，你是法国南锡大学物理学家René Blondlot教授实验室的一名研究助理。"
        }
    },
    {
        "translation": {
            "en": "Table 11.2[654] shows an example action-value table for the TwentyTwos playing agent discussed in Section 11.2.3[643].",
            "zh": "表 11.2[654] 显示了第 11.2.3 节[643] 中讨论的 TwentyTwos 游戏代理的示例操作值表。"
        }
    },
    {
        "translation": {
            "en": "At the end of the first episode the agent reached the goal cell, state 6-4, by moving left from state 6-5.",
            "zh": "在第一集结束时，智能体从状态 6-5 向左移动，到达目标单元格，状态 6-4。"
        }
    },
    {
        "translation": {
            "en": "variable selection, 227",
            "zh": "变量选择，227"
        }
    },
    {
        "translation": {
            "en": "A matrix of weighted sums calculations for a layer of neurons processing a batch of examples is denoted by Z(k) where k identifies the layer.",
            "zh": "处理一批样本的神经元层的加权和计算矩阵用 Z（k） 表示，其中 k 标识该层。"
        }
    },
    {
        "translation": {
            "en": "If two features are unrelated, then we would expect to see the same proportion of each level of the second feature within the bars for each level of the first.",
            "zh": "如果两个特征不相关，那么我们期望在条形图中看到第二个特征的每个级别的相同比例。"
        }
    },
    {
        "translation": {
            "en": "Working with Kate, Ross defined an active customer as a current customer who made at least five calls per week and who had been a customer for at least six months.4 This definition ensured that the non-churn instances in the dataset would include only customers with a relatively normal behavior profile and for which there was a long enough data history that realistic descriptive features could be calculated for them.",
            "zh": "Ross 与 Kate 合作，将活跃客户定义为每周至少拨打 5 个电话且成为客户至少 6 个月的当前客户。4 此定义确保数据集中的非流失实例仅包括具有相对正常行为配置文件的客户，并且具有足够长的数据历史记录，可以为他们计算实际的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "After feature selection, the classification accuracy of the models on the test set were 85.557%, 88.829%, and 87.188% for the k nearest neighbor, logistic regression, and support vector machine models respectively.",
            "zh": "特征选择后，k最近邻模型、逻辑回归模型和支持向量机模型在测试集上的分类准确率分别为85.557%、88.829%和87.188%。"
        }
    },
    {
        "translation": {
            "en": "Fortunately, because the hyperplanes created by the k-d tree are all axis-aligned, the algorithm can test for this condition quite easily.",
            "zh": "幸运的是，由于 k-d 树创建的超平面都是轴对齐的，因此该算法可以很容易地测试这种情况。"
        }
    },
    {
        "translation": {
            "en": "For further discussion of the legal issues surrounding data analytics, Tene and Polonetsky (2013) and Schwartz (2010) are useful. Chapter 2 of Siegel (2013) discusses the ethical issues surrounding predictive analytics.",
            "zh": "对于围绕数据分析的法律问题的进一步讨论，Tene and Polonetsky （2013） 和 Schwartz （2010） 是有用的。Siegel（2013）的第2章讨论了围绕预测分析的伦理问题。"
        }
    },
    {
        "translation": {
            "en": "We have also introduced decision tree models, which make predictions based on sequences of tests on the descriptive feature values of a query.",
            "zh": "我们还引入了决策树模型，该模型基于对查询的描述性特征值的测试序列进行预测。"
        }
    },
    {
        "translation": {
            "en": "7.21   A selection of the models developed during the gradient descent process for the customer group dataset from Table 7.11[359]. Squares represent instances with the single target level, triangles the business level, and crosses the family level. The bottom-right panel illustrates the overall decision boundaries between the three target levels.",
            "zh": "7.21 表7.11[359]中客户组数据集的梯度下降过程中开发的模型选择。正方形表示具有单个目标级别的实例，三角形表示业务级别，并跨系列级别。右下角的面板说明了三个目标级别之间的总体决策边界。"
        }
    },
    {
        "translation": {
            "en": "This phenomenon is often referred to as concept drift.",
            "zh": "这种现象通常被称为概念漂移。"
        }
    },
    {
        "translation": {
            "en": "If we allowed this to happen, then our model will be affected by accidental data collection factors, such as the units used to measure something.",
            "zh": "如果我们允许这种情况发生，那么我们的模型将受到意外数据收集因素的影响，例如用于测量某物的单位。"
        }
    },
    {
        "translation": {
            "en": "This approach to finding weights is known as least squares optimization.",
            "zh": "这种查找权重的方法称为最小二乘优化。"
        }
    },
    {
        "translation": {
            "en": "This will ensure that the agent never takes potentially dangerous random actions but limits the ability of an agent to continue to learn after being deployed, which could be useful if aspects of the environment changed over time.18",
            "zh": "这将确保代理永远不会采取具有潜在危险的随机操作，但会限制代理在部署后继续学习的能力，如果环境的各个方面随时间变化，这可能很有用18。"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the customer’s bill has changed from last month to this month",
            "zh": "客户账单从上个月到本月的变化百分比"
        }
    },
    {
        "translation": {
            "en": "The target level in square brackets at each interior node in the tree shows the majority target level for the data partition at that node.",
            "zh": "树中每个内部节点的方括号中的目标级别显示该节点上数据分区的多数目标级别。"
        }
    },
    {
        "translation": {
            "en": "Suggestions for further reading are given at the end of the chapter.",
            "zh": "本章末尾给出了进一步阅读的建议。"
        }
    },
    {
        "translation": {
            "en": "In the McCulloch and Pitts model the weights were manually set, but subsequently in this chapter we explain how these weights can be learned from data using backpropagation.",
            "zh": "在 McCulloch 和 Pitts 模型中，权重是手动设置的，但随后在本章中，我们将解释如何使用反向传播从数据中学习这些权重。"
        }
    },
    {
        "translation": {
            "en": "Based on a recent evaluation of historical performance, AT management believed at the time of this project that their current system for identifying likely churners had an accuracy of approximately 60%, so any newly developed system would have to perform considerably better than this to be deemed worthwhile.",
            "zh": "根据最近对历史性能的评估，AT管理层在进行该项目时认为，他们目前用于识别潜在流失者的系统准确率约为60%，因此任何新开发的系统都必须比这性能好得多，才被认为是值得的。"
        }
    },
    {
        "translation": {
            "en": "They give us a quick overview of all the levels in the domain of each categorical feature and the frequencies of these levels.",
            "zh": "它们为我们提供了每个分类特征域中的所有水平以及这些水平的频率的快速概述。"
        }
    },
    {
        "translation": {
            "en": "The second segment in Table 8.15[471] lists e raised to the power of the corresponding logit (eli) and also the per example sum of these values (∑ieli).",
            "zh": "表 8.15[471] 中的第二段列出了 e 的幂 logit （eli） 以及这些值 （∑ieli） 的每次示例总和。"
        }
    },
    {
        "translation": {
            "en": "The process of summing out is a key concept in probability-based prediction.",
            "zh": "总结过程是基于概率的预测中的一个关键概念。"
        }
    },
    {
        "translation": {
            "en": "9.16   Tabulating the workings required to calculate gain, cumulative gain, lift, and cumulative lift for the data given in Table 9.11[557].",
            "zh": "9.16 将计算表9.11[557]中给出的数据的增益、累积增益、升力和累积升力所需的工作制成表格。"
        }
    },
    {
        "translation": {
            "en": "The ABT for the motor insurance claims fraud detection solution.",
            "zh": "用于汽车保险索赔欺诈检测解决方案的 ABT。"
        }
    },
    {
        "translation": {
            "en": "There are just two continuous features in this dataset, DOSE1 and DOSE2 (both normalized to the range (−1,1) using range normalization), and two target levels, dangerous and safe.",
            "zh": "该数据集中只有两个连续特征，DOSE1 和 DOSE2（均使用范围归一化归一化归一化到范围 （−1,1），以及两个目标水平，危险和安全。"
        }
    },
    {
        "translation": {
            "en": "Throughout this book we discuss the many different ways we can use machine learning techniques to build predictive data analytics models. In these discussions we do not refer to specific tools or implementations of these techniques. There are, however, many different, easy-to-use options for implementing machine learning models that interested readers can use to follow along with the examples in this book.",
            "zh": "在本书中，我们讨论了使用机器学习技术构建预测性数据分析模型的多种不同方法。在这些讨论中，我们没有提到这些技术的具体工具或实现。但是，有许多不同的、易于使用的选项可用于实现机器学习模型，感兴趣的读者可以使用这些选项来遵循本书中的示例。"
        }
    },
    {
        "translation": {
            "en": "4.4   Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset in Table 4.3[136].",
            "zh": "4.4 表4.3[136]中数据集的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "hypercube, 224",
            "zh": "超立方体，224"
        }
    },
    {
        "translation": {
            "en": "Gwiazda, J., E. Ong, R. Held, and F. Thorn. 2000. Vision: Myopia and ambient night-time lighting. Nature 404 (6774): 144–144. http://dx.doi.org/10.1038/35004663.",
            "zh": "Gwiazda， J.， E. Ong， R. Held， 和 F. Thorn.2000. 视觉：近视和夜间环境照明。自然404（6774）：144-144。http://dx.doi.org/10.1038/35004663。"
        }
    },
    {
        "translation": {
            "en": "It has been shown that there is no particular inductive bias that on average is the best one to use.10 Also, in general, there is no way of knowing for a given predictive task which inductive bias will work best.",
            "zh": "10 此外，一般来说，对于给定的预测任务，没有办法知道哪种归纳偏差效果最好。"
        }
    },
    {
        "translation": {
            "en": "Recurrent neural networks (RNN) are designed to process this type of data.",
            "zh": "递归神经网络 （RNN） 旨在处理此类数据。"
        }
    },
    {
        "translation": {
            "en": "Or it may be that the features in the dataset are continuous—typically indicating that a Minkowski distance metric is appropriate—but that the majority of the descriptive features for each instance have zero values,25 in which case we may want to use a similarity index that ignores descriptive features with zero values in both features, for example, cosine similarity.",
            "zh": "或者，数据集中的特征可能是连续的（通常表示闵可夫斯基距离度量是合适的），但每个实例的大多数描述性特征的值为零，25在这种情况下，我们可能希望使用相似性指数，该指数忽略两个特征中值为零的描述性特征， 例如，余弦相似度。"
        }
    },
    {
        "translation": {
            "en": "Consequently, a model is likely to overfit the data for any query where one or more of the evidence events match the conditioned event of one of these zero probabilities.",
            "zh": "因此，对于任何查询，如果一个或多个证据事件与这些零概率之一的条件事件匹配，则模型可能会对数据进行过拟合。"
        }
    },
    {
        "translation": {
            "en": "This gradient is given by",
            "zh": "该梯度由下式给出"
        }
    },
    {
        "translation": {
            "en": "(a) A 3D surface plot and (b) a bird’s-eye view contour plot of the error surface generated by plotting the sum of squared errors for the office rentals training set for each possible combination of values for w[0] (from the range [−10,20]) and w[1] (from the range [−2,3]).",
            "zh": "（a） 3D 曲面图和 （b） 误差曲面的鸟瞰图，该图通过绘制 w[0]（范围 [−10,20]）和 w[1]（范围 [−2,3]）的每种可能值组合的办公室租赁训练集的平方误差总和生成。"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the following query instances.",
            "zh": "使用此模型对以下每个查询实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "The tree shown in Figure 12.5[699] is reasonably straightforward to interpret, but when taken out to other parts of the business, it may be hard for people to deal with this much information, so Ross decided to create a purposefully stunted version of the decision tree, with only a small number of levels shown for the presentation of the model to the business (although he intended to use the larger pruned tree for actual deployment).",
            "zh": "图 12.5[699] 中所示的树相当容易解释，但是当被带到业务的其他部分时，人们可能很难处理这么多信息，因此 Ross 决定创建决策树的故意发育不良版本，只显示少量级别以向业务部门展示模型（尽管他打算使用更大的修剪树来实际deployment）。"
        }
    },
    {
        "translation": {
            "en": "data analytics, 3",
            "zh": "数据分析， 3"
        }
    },
    {
        "translation": {
            "en": "3. This data has been artificially generated for this example.",
            "zh": "3. 此数据是针对此示例人工生成的。"
        }
    },
    {
        "translation": {
            "en": "7.3.3   Choosing Learning Rates and Initial Weights",
            "zh": "7.3.3 选择学习率和初始权重"
        }
    },
    {
        "translation": {
            "en": "9.21   Calculating the stability index for the bacterial species identification problem given new test data for two periods after model deployment.",
            "zh": "9.21 计算模型部署后两个时期的新测试数据下细菌物种识别问题的稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "1. Be aware of the relationships between features in an ABT.",
            "zh": "1. 注意 ABT 中特征之间的关系。"
        }
    },
    {
        "translation": {
            "en": "3. This is captured in Sutton’s reward hypothesis (Sutton and Barto, 2018): “That all of what we mean by goals and purposes can be well thought of as maximization of the expected value of the cumulative sum of a received scalar signal (reward).”",
            "zh": "3. 这在萨顿的奖励假设（萨顿和巴托，2018 年）中得到了体现：“我们所说的目标和目的的所有含义都可以很好地被认为是接收到的标量信号（奖励）的累积总和的期望值的最大化。"
        }
    },
    {
        "translation": {
            "en": "variational auto-encoders, 630",
            "zh": "变分自动编码器，630"
        }
    },
    {
        "translation": {
            "en": "For example, the United States Civil Rights Act of 19645 made it illegal to discriminate against a person on the basis of race, color, religion, national origin, or sex.",
            "zh": "例如，19645 年的《美国民权法案》规定，基于种族、肤色、宗教、国籍或性别歧视某人是非法的。"
        }
    },
    {
        "translation": {
            "en": "Hence a neuron that uses a logistic activation function is referred to as a logistic unit, and a unit that uses the rectifier function is known as a rectified linear unit or ReLU.",
            "zh": "因此，使用逻辑激活函数的神经元称为逻辑单元，使用整流器功能的单元称为整流线性单元或 ReLU。"
        }
    },
    {
        "translation": {
            "en": "The out-of-time sampling process.",
            "zh": "超时采样过程。"
        }
    },
    {
        "translation": {
            "en": "This structural information can bias the model in such as way as to help it avoid overfitting the data.",
            "zh": "这种结构信息可以使模型产生偏差，从而帮助模型避免过度拟合数据。"
        }
    },
    {
        "translation": {
            "en": "When we computed a conditional probability for the target feature using a naive Bayes model, we used the following calculation:",
            "zh": "当我们使用朴素贝叶斯模型计算目标特征的条件概率时，我们使用了以下计算："
        }
    },
    {
        "translation": {
            "en": "These predictions can then be compared to the predictions we expected the model to make.",
            "zh": "然后，可以将这些预测与我们期望模型做出的预测进行比较。"
        }
    },
    {
        "translation": {
            "en": "5.1   A feature space plot of the college athlete data in Table 5.2[183].",
            "zh": "5.1 表5.2[183]中大学运动员数据的特征空间图。"
        }
    },
    {
        "translation": {
            "en": "Notice how the orientation of the axes and the scaling of the distance contours are consistent across the figures.",
            "zh": "请注意，轴的方向和距离等值线的缩放在各图形中是一致的。"
        }
    },
    {
        "translation": {
            "en": "Each cell in a confusion matrix represents one of these outcomes (TP, TN, FP, FN) and counts the number of times this outcome occurred when the test dataset was presented to the model.",
            "zh": "混淆矩阵中的每个单元格表示这些结果之一（TP、TN、FP、FN），并计算将测试数据集呈现给模型时出现此结果的次数。"
        }
    },
    {
        "translation": {
            "en": "After taking the action, instead of performing a single step of stochastic gradient descent, the agent randomly selects a random sample of b instances from the replay memory, and performs an iteration of mini-batch gradient descent28 using this sample as the mini-batch.",
            "zh": "执行操作后，代理不会执行随机梯度下降的单个步骤，而是从回放内存中随机选择 b 实例的随机样本，并使用此样本作为小批量执行小批量梯度下降 28 的迭代。"
        }
    },
    {
        "translation": {
            "en": "This distinction between the processing paths is why the weight matrix in Equation (8.110)[511] has a † in the superscript (i.e., W(i†)) whereas the weight matrix in Equation (8.111)[511] has a ‡.",
            "zh": "处理路径之间的这种区别就是为什么方程（8.110）[511]中的权重矩阵在上标（即W（i†））中具有†，而方程（8.111）[511]中的权重矩阵具有‡。"
        }
    },
    {
        "translation": {
            "en": "As we backpropagate through each time-step in the unrolled network, we use the corresponding weighted sum z and activation a for a neuron at that time-step to backpropagate the error gradient for that neuron.",
            "zh": "当我们在展开的网络中的每个时间步中反向传播时，我们使用相应的加权总和 z 和激活该时间步的神经元来反向传播该神经元的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "“When my information changes, I alter my conclusions. What do you do, sir?When my information changes, I alter my conclusions. What do you do, sir?”",
            "zh": "“当我的信息发生变化时，我会改变我的结论。你是做什么的，先生？当我的信息发生变化时，我会改变我的结论。你是做什么的，先生？"
        }
    },
    {
        "translation": {
            "en": "3.5   The data quality plan for the motor insurance fraud prediction ABT.",
            "zh": "3.5 汽车保险欺诈预测ABT的数据质量计划。"
        }
    },
    {
        "translation": {
            "en": "root mean squared error, 577, 578",
            "zh": "均方根误差， 577， 578"
        }
    },
    {
        "translation": {
            "en": "The ID3 algorithm uses the information gain metric to choose the best feature to test at each node in the tree.",
            "zh": "ID3 算法使用信息增益指标来选择要在树中的每个节点上测试的最佳特征。"
        }
    },
    {
        "translation": {
            "en": "Using the δ values you have calculated in the preceding, calculate the sensitivity of the error of the network to changes in each of the weights of the network (i.e., ∂ℰ/∂w3,2, ∂ℰ/∂w3,0, ∂ℰ/∂w2,1, ∂ℰ/∂w2,0).",
            "zh": "使用您在前面计算的δ值，计算网络误差对网络每个权重变化的敏感性（即 ∂E/∂w3,2、∂E/∂w3,0、∂E/∂w2,1、∂E/∂w2,0）。"
        }
    },
    {
        "translation": {
            "en": "Russel-Rao index, 214, 231",
            "zh": "罗素-拉奥指数，214,231"
        }
    },
    {
        "translation": {
            "en": "To repurpose the gradient descent algorithm for training logistic regression models, the only change that needs to be made is in the error delta function, which is used in the weight update rule given on Line 4[326] of Algorithm 4[326]. To derive this new weight update rule, imagine that there is just a single training instance, (d,t), in our training dataset. The partial derivative of the error function, L2, is then",
            "zh": "为了重新利用梯度下降算法来训练逻辑回归模型，唯一需要做的更改是误差增量函数，该函数用于算法 4[326] 的第 4 行[326]中给出的权重更新规则。为了推导出这个新的权重更新规则，假设我们的训练数据集中只有一个训练实例 （d，t）。误差函数的偏导数 L2 为"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm is actually quite straightforward, and it is easiest to explain in the context of a prediction problem with a continuous target. Given a training dataset, 𝒟, made up of descriptive feature and target feature pairs, (d,t), the algorithm begins by training a very simple base model, 𝕄0. For problems with a continuous target, this model typically simply predicts the overall average target value from the training dataset",
            "zh": "梯度提升算法实际上非常简单，在具有连续目标的预测问题的上下文中最容易解释。给定一个由描述性特征和目标特征对 （d，t） 组成的训练数据集 D，该算法首先训练一个非常简单的基础模型 M0。对于具有连续目标的问题，此模型通常只是从训练数据集中预测总体平均目标值"
        }
    },
    {
        "translation": {
            "en": "This example illustrates the power of Bayesian networks. When complete knowledge of the state of all the nodes in the network is not available, we clamp the values of nodes that we do have knowledge of and sum out the unknown nodes. Furthermore, during these calculations, we only need to condition a node on its Markov blanket, which dramatically reduces the number of probabilities required by the network.",
            "zh": "这个例子说明了贝叶斯网络的强大功能。当无法完全了解网络中所有节点的状态时，我们钳制我们所知道的节点的值，并总结出未知节点。此外，在这些计算过程中，我们只需要在其马尔可夫毯上调节一个节点，这大大减少了网络所需的概率数量。"
        }
    },
    {
        "translation": {
            "en": "This is the benefit of using a k-d tree and becomes especially apparent when datasets are very large.",
            "zh": "这是使用 k-d 树的好处，当数据集非常大时，这一点尤其明显。"
        }
    },
    {
        "translation": {
            "en": "-0.1916",
            "zh": "-0.1916"
        }
    },
    {
        "translation": {
            "en": "Note that each line in Figure 8.40[509] represents a vector of activations, and the + symbol represents an elementwise vector addition and ⊙ represents an elementwise vector product.",
            "zh": "请注意，图 8.40[509] 中的每一行表示一个激活向量，+ 符号表示逐向量加法，⊙ 表示逐向量乘积。"
        }
    },
    {
        "translation": {
            "en": "First, she used a 5-target-level model to make predictions.",
            "zh": "首先，她使用5个目标级别的模型进行预测。"
        }
    },
    {
        "translation": {
            "en": "For example, in the loan scenario a ratio between salary and requested loan amount might have a much longer useful life span than the salary and loan amount values alone.",
            "zh": "例如，在贷款方案中，工资和请求的贷款金额之间的比率可能比单独的工资和贷款金额值具有更长的使用寿命。"
        }
    },
    {
        "translation": {
            "en": "7.9   (a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (α0 = 0.25, c = 100); (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "7.9 （a） 使用学习率衰减时，办公室租赁预测问题的误差面（α0 = 0.25，c = 100）;（b） 此旅程中误差平方和的变化图。"
        }
    },
    {
        "translation": {
            "en": "The weight matrices are arranged so that there is one row per set of weights per neuron in the layer.",
            "zh": "权重矩阵的排列方式是，层中每个神经元的每组权重都有一行。"
        }
    },
    {
        "translation": {
            "en": "It is important that once a model is deployed, we put in place an ongoing model validation scheme to monitor the model to catch the point at which it begins to go stale.",
            "zh": "重要的是，一旦部署了模型，我们就会实施一个持续的模型验证方案来监控模型，以捕捉它开始过时的点。"
        }
    },
    {
        "translation": {
            "en": "On the topic of converting business problems into analytics solutions, Davenport (2006) and Davenport and Kim (2013) are good business-focused sources. Levitt and Dubner (2005), Ayres (2008), Silver (2012), and Siegel (2013) all provide nice dicusssions of different applications of predictive data analytics.",
            "zh": "关于将业务问题转化为分析解决方案的主题，Davenport（2006）和Davenport和Kim（2013）是以业务为中心的良好来源。Levitt 和 Dubner （2005）、Ayres （2008）、Silver （2012） 和 Siegel （2013） 都对预测数据分析的不同应用进行了很好的讨论。"
        }
    },
    {
        "translation": {
            "en": "11.9   An illustration of the DQN algorithm including experience replay and target network freezing.",
            "zh": "11.9 DQN算法的图示，包括体验回放和目标网络冻结。"
        }
    },
    {
        "translation": {
            "en": "2.708",
            "zh": "2.708"
        }
    }
]
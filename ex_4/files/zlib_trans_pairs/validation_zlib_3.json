[
    {
        "translation": {
            "en": "The standard algorithm for training a deep neural network combines the backpropagation algorithm (which solves the blame assignment problem) with stochastic gradient descent (which we use to update the weights in the network after blame has been assigned to each neuron).",
            "zh": "è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„æ ‡å‡†ç®—æ³•å°†åå‘ä¼ æ’­ç®—æ³•ï¼ˆè§£å†³è´£å¤‡åˆ†é…é—®é¢˜ï¼‰ä¸éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆæˆ‘ä»¬ç”¨å®ƒæ¥åœ¨å°†è´£å¤‡åˆ†é…ç»™æ¯ä¸ªç¥ç»å…ƒåæ›´æ–°ç½‘ç»œä¸­çš„æƒé‡ï¼‰ç›¸ç»“åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The search process must now move to a new node (Lines 8, 9, 10, and 11). This move is determined by Line 8, which checks if the distance between the query and the hyperplane13 defined by the current node is less than the value of best-distance. In this case, however, the current node is a leaf node, so it does not define a hyperplane on the feature space. As a result, the condition checked in Line 8, fails and the search moves to the parent node of the current node (Line 11).",
            "zh": "æœç´¢è¿‡ç¨‹ç°åœ¨å¿…é¡»ç§»åŠ¨åˆ°æ–°èŠ‚ç‚¹ï¼ˆç¬¬ 8ã€9ã€10 å’Œ 11 è¡Œï¼‰ã€‚æ­¤ç§»åŠ¨ç”±ç¬¬ 8 è¡Œç¡®å®šï¼Œè¯¥è¡Œæ£€æŸ¥æŸ¥è¯¢ä¸å½“å‰èŠ‚ç‚¹å®šä¹‰çš„ hyperplane13 ä¹‹é—´çš„è·ç¦»æ˜¯å¦å°äº best-distance çš„å€¼ã€‚ä½†æ˜¯ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œå½“å‰èŠ‚ç‚¹æ˜¯å¶èŠ‚ç‚¹ï¼Œå› æ­¤å®ƒä¸ä¼šåœ¨ç‰¹å¾ç©ºé—´ä¸Šå®šä¹‰è¶…å¹³é¢ã€‚å› æ­¤ï¼Œåœ¨ç¬¬ 8 è¡Œä¸­æ£€æŸ¥çš„æ¡ä»¶å¤±è´¥ï¼Œæœç´¢å°†ç§»åŠ¨åˆ°å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼ˆç¬¬ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The number of handsets the customer has had in the past 3 years",
            "zh": "å®¢æˆ·åœ¨è¿‡å» 3 å¹´å†…æ‹¥æœ‰çš„æ‰‹æœºæ•°é‡"
        }
    },
    {
        "translation": {
            "en": "Blondlot, RenÃ©. 1903. Sur une nouvelle action produite par les rayons n et sur plusieurs fait relatifs Ã  ces radiations. Comptes Rendus de lâ€™AcadÃ©mie des Sciences de Paris 137: 166â€“169.",
            "zh": "é‡‘å‘å¥³éƒï¼Œå‹’å†…ã€‚1903. Sur une nouvelle action produite par les rayons n et sur plusieurs fait relatifs Ã  ces radiations.å·´é»ç§‘å­¦é™¢ 137ï¼š166-169ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, countries that are relatively equal and that have good education and high life expectancy are likely to have a low level of corruption.",
            "zh": "æ¢è¨€ä¹‹ï¼Œç›¸å¯¹å¹³ç­‰ã€å—è¿‡è‰¯å¥½æ•™è‚²å’Œé¢„æœŸå¯¿å‘½é«˜çš„å›½å®¶ï¼Œè…è´¥ç¨‹åº¦å¯èƒ½è¾ƒä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the more likely case that the set containing three elements contains the solution, however, you may have to ask two more questions to uniquely identify the answer.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨åŒ…å«ä¸‰ä¸ªå…ƒç´ çš„é›†åˆåŒ…å«è§£å†³æ–¹æ¡ˆçš„æ›´å¯èƒ½æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½éœ€è¦å†é—®ä¸¤ä¸ªé—®é¢˜æ‰èƒ½å”¯ä¸€åœ°æ ‡è¯†ç­”æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Verify that the answers calculated in Parts (i) and (ii) of this question would have been the same if the alternative approach (basis functions or the polynomial kernel function) had been used in each case.",
            "zh": "éªŒè¯å¦‚æœåœ¨æ¯ç§æƒ…å†µä¸‹éƒ½ä½¿ç”¨æ›¿ä»£æ–¹æ³•ï¼ˆåŸºå‡½æ•°æˆ–å¤šé¡¹å¼æ ¸å‡½æ•°ï¼‰ï¼Œåˆ™æœ¬é—®é¢˜ç¬¬ ï¼ˆiï¼‰ å’Œ ï¼ˆiiï¼‰ éƒ¨åˆ†ä¸­è®¡ç®—çš„ç­”æ¡ˆæ˜¯å¦ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Gini index, 145, 169, 174, 563",
            "zh": "åŸºå°¼ç³»æ•°ï¼Œ 145ï¼Œ 169ï¼Œ 174ï¼Œ 563"
        }
    },
    {
        "translation": {
            "en": "The key things to remember, however, are that it is important to choose a similarity metric or index that is appropriate for the properties of the dataset we are using (be it binary, non-binary, sparse, covariant, etc.)",
            "zh": "ç„¶è€Œï¼Œè¦è®°ä½çš„å…³é”®äº‹é¡¹æ˜¯ï¼Œé€‰æ‹©é€‚åˆæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨çš„æ•°æ®é›†å±æ€§ï¼ˆæ— è®ºæ˜¯äºŒè¿›åˆ¶ã€éäºŒè¿›åˆ¶ã€ç¨€ç–ã€åå˜ç­‰ï¼‰çš„ç›¸ä¼¼åº¦æŒ‡æ ‡æˆ–ç´¢å¼•éå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.23â€…â€…â€…The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with Î¼=0.0, Ïƒ=0.01.",
            "zh": "8.23 å›¾8.22[450]ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨Î¼=0.0ï¼ŒÏƒ=0.01çš„æ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The exponential distribution takes one parameter, Î», known as the rate.",
            "zh": "æŒ‡æ•°åˆ†å¸ƒé‡‡ç”¨ä¸€ä¸ªå‚æ•° Î»ï¼Œç§°ä¸ºé€Ÿç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Create a naive Bayes model that uses probability density functions to model the descriptive features in this dataset (assume that all the descriptive features are normally distributed).",
            "zh": "ï¼ˆaï¼‰ åˆ›å»ºä¸€ä¸ªæœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ¦‚ç‡å¯†åº¦å‡½æ•°å¯¹è¯¥æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼ˆå‡è®¾æ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½æ˜¯æ­£æ€åˆ†å¸ƒçš„ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fundamentals of Machine Learning for Predictive Data Analytics",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "Consequently, the predictions made by a nearest neighbor model are based on the full set of descriptive features in a dataset.",
            "zh": "å› æ­¤ï¼Œæœ€è¿‘é‚»æ¨¡å‹æ‰€åšçš„é¢„æµ‹åŸºäºæ•°æ®é›†ä¸­çš„å®Œæ•´æè¿°æ€§ç‰¹å¾é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "When this network is processing a set of external inputs, the inputs are presented to the network through sensing neurons in the input layer; this causes the neurons in the next layer to generate activation signals in response to these inputs; and these activations flow forward through the network until the output layer is reached, where the response of the network to the inputs is the activations of the neurons in this final output layer.",
            "zh": "å½“è¯¥ç½‘ç»œå¤„ç†ä¸€ç»„å¤–éƒ¨è¾“å…¥æ—¶ï¼Œè¿™äº›è¾“å…¥é€šè¿‡è¾“å…¥å±‚ä¸­çš„æ„Ÿåº”ç¥ç»å…ƒå‘ˆç°ç»™ç½‘ç»œ;è¿™å¯¼è‡´ä¸‹ä¸€å±‚çš„ç¥ç»å…ƒäº§ç”Ÿæ¿€æ´»ä¿¡å·ä»¥å“åº”è¿™äº›è¾“å…¥;è¿™äº›æ¿€æ´»é€šè¿‡ç½‘ç»œå‘å‰æµåŠ¨ï¼Œç›´åˆ°åˆ°è¾¾è¾“å‡ºå±‚ï¼Œå…¶ä¸­ç½‘ç»œå¯¹è¾“å…¥çš„å“åº”æ˜¯æœ€ç»ˆè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, INJURY TYPE has four levels.",
            "zh": "ä¾‹å¦‚ï¼ŒINJURY TYPE æœ‰å››ä¸ªçº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.2â€ƒEvaluating Clustering",
            "zh": "10.4.2 è¯„ä¼°èšç±»"
        }
    },
    {
        "translation": {
            "en": "These concepts allow us to understand the standard approach to building similarity-based models: the nearest neighbor algorithm.",
            "zh": "è¿™äº›æ¦‚å¿µä½¿æˆ‘ä»¬èƒ½å¤Ÿç†è§£æ„å»ºåŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹çš„æ ‡å‡†æ–¹æ³•ï¼šæœ€è¿‘é‚»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that throughout the rest of the chapter, we use uppercase letters to denote generic events where an unspecified feature (or set of features) is assigned a value (or set of values).",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤§å†™å­—æ¯æ¥è¡¨ç¤ºä¸ºæœªæŒ‡å®šçš„ç‰¹å¾ï¼ˆæˆ–ç‰¹å¾é›†ï¼‰åˆ†é…ä¸€ä¸ªå€¼ï¼ˆæˆ–ä¸€ç»„å€¼ï¼‰çš„é€šç”¨äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, Q(0-3,left) is updated to:",
            "zh": "å› æ­¤ï¼ŒQï¼ˆ0-3ï¼Œleftï¼‰ æ›´æ–°ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Bayesian prediction is a very intuitive approach to predicting categorical targets. In order to make a prediction, we have to learn two things:",
            "zh": "è´å¶æ–¯é¢„æµ‹æ˜¯ä¸€ç§éå¸¸ç›´è§‚çš„é¢„æµ‹åˆ†ç±»ç›®æ ‡çš„æ–¹æ³•ã€‚ä¸ºäº†åšå‡ºé¢„æµ‹ï¼Œæˆ‘ä»¬å¿…é¡»å­¦ä¹ ä¸¤ä»¶äº‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "In some cases they learn a hard boundary between the classes; in other casesâ€”such as logistic regressionâ€”they learn a soft boundary, which takes into account the distance from the boundary.",
            "zh": "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä»–ä»¬å­¦ä¹ äº†ç­çº§ä¹‹é—´çš„ç¡¬æ€§ç•Œé™;åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚é€»è¾‘å›å½’ï¼‰ï¼Œå®ƒä»¬ä¼šå­¦ä¹ ä¸€ä¸ªè½¯è¾¹ç•Œï¼Œè¯¥è¾¹ç•Œè€ƒè™‘äº†ä¸è¾¹ç•Œçš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.15[471] is split into five segments with each segment containing information on Neurons 8, 9, and 10, and the calculations flow from the top of the table to the bottom.",
            "zh": "è¡¨8.15[471]è¢«åˆ†æˆäº”ä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†åŒ…å«ç¥ç»å…ƒ8ã€9å’Œ10çš„ä¿¡æ¯ï¼Œè®¡ç®—ä»è¡¨æ ¼çš„é¡¶éƒ¨æµå‘åº•éƒ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 11.9[672].",
            "zh": "å¦‚å›¾11.9[672]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "However, larger and smaller filters are possible, and as filters become larger the number of neurons required to cover the input naturally gets smaller and vice versa.",
            "zh": "ç„¶è€Œï¼Œæ›´å¤§å’Œæ›´å°çš„è¿‡æ»¤å™¨æ˜¯å¯èƒ½çš„ï¼Œéšç€è¿‡æ»¤å™¨å˜å¤§ï¼Œè¦†ç›–è¾“å…¥æ‰€éœ€çš„ç¥ç»å…ƒæ•°é‡è‡ªç„¶ä¼šå˜å°ï¼Œåä¹‹äº¦ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, this team was already using data from within the organization to choose which customers to target for intervention, which suggested that the team members were in a position to use predictive data analytics models.",
            "zh": "æ­¤å¤–ï¼Œè¯¥å›¢é˜Ÿå·²ç»åœ¨ä½¿ç”¨æ¥è‡ªç»„ç»‡å†…éƒ¨çš„æ•°æ®æ¥é€‰æ‹©å¹²é¢„ç›®æ ‡å®¢æˆ·ï¼Œè¿™è¡¨æ˜å›¢é˜Ÿæˆå‘˜èƒ½å¤Ÿä½¿ç”¨é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature map 1 contains the 6 activations for the 6 neurons that applied Filter 1 to the input, and Feature map 2 contains the 6 activations for the 6 neurons that applied Filter 2 to the input.",
            "zh": "ç‰¹å¾å›¾ 1 åŒ…å«å°†è¿‡æ»¤å™¨ 1 åº”ç”¨äºè¾“å…¥çš„ 6 ä¸ªç¥ç»å…ƒçš„ 6 æ¬¡æ¿€æ´»ï¼Œç‰¹å¾å›¾ 2 åŒ…å«å°†è¿‡æ»¤å™¨ 2 åº”ç”¨äºè¾“å…¥çš„ 6 ä¸ªç¥ç»å…ƒçš„ 6 æ¬¡æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "There really isnâ€™t an observation period in this case, as all descriptive features will be based on information provided by the applicant on the application form, rather than on observing the applicantâ€™s behavior over time.4 The outcome period in this case is considered the period of the lifetime of the loan during which the applicant will have either fully repaid or defaulted on the loan.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®é™…ä¸Šæ²¡æœ‰è§‚å¯ŸæœŸï¼Œå› ä¸ºæ‰€æœ‰æè¿°æ€§ç‰¹å¾éƒ½å°†åŸºäºç”³è¯·äººåœ¨ç”³è¯·è¡¨ä¸Šæä¾›çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯è§‚å¯Ÿç”³è¯·äººéšæ—¶é—´æ¨ç§»çš„è¡Œä¸º.4 åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç»“æœæœŸè¢«è®¤ä¸ºæ˜¯ç”³è¯·äººå°†å…¨é¢å¿è¿˜æˆ–æ‹–æ¬ è´·æ¬¾çš„è´·æ¬¾æœŸé™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Japkowicz, Nathalie, and Mohak Shah. 2011. Evaluating learning algorithms: A classification perspective. Cambridge University Press.",
            "zh": "Japkowiczã€Nathalie å’Œ Mohak Shahã€‚2011. è¯„ä¼°å­¦ä¹ ç®—æ³•ï¼šåˆ†ç±»è§†è§’.å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some features are particularly important in defining membership of certain clusters but not important for defining membership of others.",
            "zh": "æŸäº›åŠŸèƒ½åœ¨å®šä¹‰æŸäº›é›†ç¾¤çš„æˆå‘˜èµ„æ ¼æ—¶ç‰¹åˆ«é‡è¦ï¼Œä½†å¯¹äºå®šä¹‰å…¶ä»–é›†ç¾¤çš„æˆå‘˜èµ„æ ¼å¹¶ä¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Caruana, Rich, Nikos Karampatziakis, and Ainur Yessenalina. 2008. An empirical evaluation of supervised learning in high dimensions. In Proceedings of the 25th international conference on machine learning, 96â€“103. ACM.",
            "zh": "å¡é²é˜¿çº³ã€é‡Œå¥‡ã€å°¼ç§‘æ–¯Â·å¡å…°å¸•é½äºšåŸºæ–¯å’Œé˜¿ä¼ŠåŠªå°”Â·å¶å¡çº³åˆ©å¨œã€‚2008. é«˜ç»´ç›‘ç£å­¦ä¹ çš„å®è¯è¯„ä¼°.åœ¨ç¬¬ 25 å±Šæœºå™¨å­¦ä¹ å›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œ96â€“103ã€‚ACMã€‚"
        }
    },
    {
        "translation": {
            "en": "The forward propagation of the activations through a simple recurrent network is defined as follows (where the subscript t denotes the time-step of the system; and there is one input per time-stepâ€”although this input may be a vector of valuesâ€”and so the subscript t also defines the index in the input sequence of the current input):",
            "zh": "é€šè¿‡ç®€å•çš„å¾ªç¯ç½‘ç»œçš„æ¿€æ´»çš„å‰å‘ä¼ æ’­å®šä¹‰å¦‚ä¸‹ï¼ˆå…¶ä¸­ä¸‹æ ‡ t è¡¨ç¤ºç³»ç»Ÿçš„æ—¶é—´æ­¥é•¿;æ¯ä¸ªæ—¶é—´æ­¥é•¿æœ‰ä¸€ä¸ªè¾“å…¥â€”â€”å°½ç®¡è¿™ä¸ªè¾“å…¥å¯èƒ½æ˜¯å€¼çš„å‘é‡â€”â€”å› æ­¤ä¸‹æ ‡ t è¿˜å®šä¹‰äº†å½“å‰è¾“å…¥çš„è¾“å…¥åºåˆ—ä¸­çš„ç´¢å¼•ï¼‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.2(b)[119] we reverse this order.",
            "zh": "åœ¨å›¾4.2ï¼ˆbï¼‰[119]ä¸­ï¼Œæˆ‘ä»¬é¢ å€’äº†è¿™ä¸ªé¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "statistical significance test, 333",
            "zh": "ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "Figure 8.15",
            "zh": "å›¾ 8.15"
        }
    },
    {
        "translation": {
            "en": "1.5â€…â€…â€…What Can Go Wrong with Machine Learning?",
            "zh": "1.5 æœºå™¨å­¦ä¹ ä¼šå‡ºä»€ä¹ˆé—®é¢˜ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "13.5â€…â€…â€…SPLOM diagrams of (a) the EXPRAD; and (b) DEVRAD measurements from the raw SDSS dataset. Each SPLOM shows the measure across the five different photometric bands captured by the SDSS telescope (u, g, r, i, and z).",
            "zh": "13.5 ï¼ˆaï¼‰ EXPRAD çš„ SPLOM å›¾;ï¼ˆbï¼‰æ¥è‡ªåŸå§‹SDSSæ•°æ®é›†çš„DEVRADæµ‹é‡å€¼ã€‚æ¯ä¸ªSPLOMéƒ½æ˜¾ç¤ºäº†SDSSæœ›è¿œé•œæ•è·çš„äº”ä¸ªä¸åŒå…‰åº¦æ³¢æ®µï¼ˆuï¼Œgï¼Œrï¼Œiå’Œzï¼‰çš„æµ‹é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Features (both descriptive and target) are concrete numeric or symbolic representations of domain concepts.",
            "zh": "ç‰¹å¾ï¼ˆæè¿°æ€§å’Œç›®æ ‡æ€§ï¼‰æ˜¯é¢†åŸŸæ¦‚å¿µçš„å…·ä½“æ•°å­—æˆ–ç¬¦å·è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "15. For convenience, we repeat Equation (3.7)[87] for range normalization",
            "zh": "15. ä¸ºæ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬é‡å¤æ–¹ç¨‹ï¼ˆ3.7ï¼‰[87]è¿›è¡ŒèŒƒå›´å½’ä¸€åŒ–"
        }
    },
    {
        "translation": {
            "en": "The data quality report in Table 3.3[57] and in Figure 3.1[58] allows us to very quickly become familiar with the central tendency and variation of each feature in the ABT.",
            "zh": "è¡¨3.3[57]å’Œå›¾3.1[58]ä¸­çš„æ•°æ®è´¨é‡æŠ¥å‘Šä½¿æˆ‘ä»¬èƒ½å¤Ÿéå¸¸å¿«é€Ÿåœ°ç†Ÿæ‚‰ABTä¸­æ¯ä¸ªç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first column in each weight matrix contains the weights for the bias terms, and so these columns have no label.",
            "zh": "æ¯ä¸ªæƒé‡çŸ©é˜µä¸­çš„ç¬¬ä¸€åˆ—åŒ…å«åå·®é¡¹çš„æƒé‡ï¼Œå› æ­¤è¿™äº›åˆ—æ²¡æœ‰æ ‡ç­¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn was surprised that none of the columns had any missing values.",
            "zh": "Jocelyn æƒŠè®¶åœ°å‘ç°ï¼Œæ²¡æœ‰ä¸€åˆ—æœ‰ä»»ä½•ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This can be made more obvious by including the correlation coefficients in SPLOMs in the cells above the diagonal.",
            "zh": "é€šè¿‡åœ¨å¯¹è§’çº¿ä¸Šæ–¹çš„å•å…ƒæ ¼ä¸­åŒ…æ‹¬ SPLOM ä¸­çš„ç›¸å…³ç³»æ•°ï¼Œå¯ä»¥ä½¿è¿™ä¸€ç‚¹æ›´åŠ æ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hebbâ€™s Postulate, 404",
            "zh": "èµ«å¸ƒå‡è®¾ï¼Œ404"
        }
    },
    {
        "translation": {
            "en": "multi-label classification, 742",
            "zh": "å¤šæ ‡ç­¾åˆ†ç±»ï¼Œ742"
        }
    },
    {
        "translation": {
            "en": "These revised likelihoods are shown in Figure 6.2(b)[245].",
            "zh": "è¿™äº›ä¿®æ­£çš„å¯èƒ½æ€§å¦‚å›¾6.2ï¼ˆbï¼‰[245]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Herculano-Houzel, Suzana. 2009. The human brain in numbers: A linearly scaled-up primate brain. Frontiers in Human Neuroscience 3: 31. doi:10.3389/neuro.09.031.2009.",
            "zh": "èµ«åº“æ‹‰è¯º-èƒ¡æ³½å°”ï¼Œè‹çŠå¨œã€‚2009. æ•°å­—ä¸­çš„äººç±»å¤§è„‘ï¼šçº¿æ€§æ”¾å¤§çš„çµé•¿ç±»åŠ¨ç‰©å¤§è„‘.äººç±»ç¥ç»ç§‘å­¦å‰æ²¿ 3ï¼š31ã€‚doiï¼š10.3389/neuro.09.031.2009."
        }
    },
    {
        "translation": {
            "en": "6.2.3â€ƒConditional Independence and Factorization",
            "zh": "6.2.3 æ¡ä»¶ç‹¬ç«‹æ€§å’Œå› å¼åˆ†è§£"
        }
    },
    {
        "translation": {
            "en": "22. This is very similar to the difference between Euclidean distance and Manhattan distance discussed in Section 5.2.2[184].",
            "zh": "22. è¿™ä¸ç¬¬5.2.2èŠ‚[184]ä¸­è®¨è®ºçš„æ¬§å‡ é‡Œå¾—è·ç¦»å’Œæ›¼å“ˆé¡¿è·ç¦»ä¹‹é—´çš„å·®å¼‚éå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mangasarian, Olvi L., and William H. Wolberg. 1990. Cancer diagnosis via linear programming. SIAM News 23 (5): 1â€“18.",
            "zh": "Mangasarianã€Olvi L. å’Œ William H. Wolbergã€‚1990. é€šè¿‡çº¿æ€§è§„åˆ’è¿›è¡Œç™Œç—‡è¯Šæ–­.æš¹ç½—æ–°é—»23ï¼ˆ5ï¼‰ï¼š1-18ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are many other action-selection policies that can be used together with temporal-difference learning.",
            "zh": "è¿˜æœ‰è®¸å¤šå…¶ä»–è¡ŒåŠ¨é€‰æ‹©ç­–ç•¥å¯ä»¥ä¸æ—¶é—´å·®å¼‚å­¦ä¹ ä¸€èµ·ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A convolutional neural network was used as the action-value network.",
            "zh": "ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œä½œä¸ºåŠ¨ä½œå€¼ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 7[476] provides a pseudocode definition of how the forward and backward passes of the backpropagation algorithm are modified to include inverted dropout.",
            "zh": "ç®—æ³• 7[476] æä¾›äº†ä¸€ä¸ªä¼ªä»£ç å®šä¹‰ï¼Œè¯´æ˜å¦‚ä½•ä¿®æ”¹åå‘ä¼ æ’­ç®—æ³•çš„å‰å‘å’Œåå‘ä¼ é€’ä»¥åŒ…æ‹¬åå‘ä¸¢å¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.4",
            "zh": "è¡¨ 10.4"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering approach is to be applied to this dataset with k = 2 and using Euclidean distance.",
            "zh": "k-means èšç±»æ–¹æ³•å°†åº”ç”¨äº k = 2 å¹¶ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A confusion matrix and the misclassification rate",
            "zh": "ï¼ˆaï¼‰ æ··æ·†çŸ©é˜µå’Œé”™è¯¯åˆ†ç±»ç‡"
        }
    },
    {
        "translation": {
            "en": "where c1 to ck are the centers of the k clusters, referred to as cluster centroids; and Dist is a distance measure used to compare instances to centroids. Algorithm 9[601] provides a pseudocode definition of the k-means clustering algorithm.1",
            "zh": "å…¶ä¸­ c1 åˆ° ck æ˜¯ k ä¸ªç°‡çš„ä¸­å¿ƒï¼Œç§°ä¸ºç°‡è´¨å¿ƒ;Dist æ˜¯ä¸€ç§è·ç¦»åº¦é‡ï¼Œç”¨äºå°†å®ä¾‹ä¸è´¨å¿ƒè¿›è¡Œæ¯”è¾ƒã€‚ç®—æ³•9[601]æä¾›äº†k-meansèšç±»ç®—æ³•çš„ä¼ªä»£ç å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "which gives an average of 1.3743. Based on these two average distances, ğ’3 is the closest other cluster to d1 and so b(i) = 1.3743, as shown in Table 10.2[611]. The silhouette width for d1 is then calculated using Equation (10.2)[610]",
            "zh": "å¹³å‡å€¼ä¸º 1.3743ã€‚åŸºäºè¿™ä¸¤ä¸ªå¹³å‡è·ç¦»ï¼ŒC3æ˜¯æœ€æ¥è¿‘d1çš„å…¶ä»–èšç±»ï¼Œå› æ­¤bï¼ˆiï¼‰= 1.3743ï¼Œå¦‚è¡¨10.2[611]æ‰€ç¤ºã€‚ç„¶åä½¿ç”¨å…¬å¼ï¼ˆ10.2ï¼‰[610]è®¡ç®—d1çš„è½®å»“å®½åº¦"
        }
    },
    {
        "translation": {
            "en": "This is the clearest indication so far of the hierarchical nature of AHC, as a cluster created at a previous iteration of the algorithm will be merged into a larger cluster.",
            "zh": "è¿™æ˜¯è¿„ä»Šä¸ºæ­¢AHCå±‚æ¬¡ç»“æ„æ€§è´¨çš„æœ€æ˜ç¡®æŒ‡ç¤ºï¼Œå› ä¸ºåœ¨ç®—æ³•çš„ä¸Šä¸€æ¬¡è¿­ä»£ä¸­åˆ›å»ºçš„é›†ç¾¤å°†è¢«åˆå¹¶åˆ°æ›´å¤§çš„é›†ç¾¤ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "A set of scatter plots illustrating the curse of dimensionality. Across (a), (b), and (c), the number of instances remains the same, so the density of the marked unit hypercubes decreases as the number of dimensions increases; (d) and (e) illustrate the cost we must incur, in terms of the number of extra instances required, if we wish to maintain the density of the instances in the feature space as its dimensionality increases.",
            "zh": "ä¸€ç»„æ•£ç‚¹å›¾ï¼Œè¯´æ˜ç»´åº¦çš„è¯…å’’ã€‚åœ¨ ï¼ˆaï¼‰ã€ï¼ˆbï¼‰ å’Œ ï¼ˆcï¼‰ ä¸­ï¼Œå®ä¾‹æ•°ä¿æŒä¸å˜ï¼Œå› æ­¤æ ‡è®°å•å…ƒè¶…ç«‹æ–¹ä½“çš„å¯†åº¦éšç€ç»´æ•°çš„å¢åŠ è€Œé™ä½;ï¼ˆdï¼‰ å’Œ ï¼ˆeï¼‰ è¯´æ˜äº†å¦‚æœæˆ‘ä»¬å¸Œæœ›åœ¨ç‰¹å¾ç©ºé—´çš„ç»´æ•°å¢åŠ æ—¶ä¿æŒç‰¹å¾ç©ºé—´ä¸­å®ä¾‹çš„å¯†åº¦ï¼Œæˆ‘ä»¬å¿…é¡»æ‰¿æ‹…çš„æˆæœ¬ï¼Œå³æ‰€éœ€çš„é¢å¤–å®ä¾‹æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.4â€…â€…â€…The Bellman Equations",
            "zh": "11.2.4 è´å°”æ›¼æ–¹ç¨‹"
        }
    },
    {
        "translation": {
            "en": "Potential prediction models (a) before and (b) after training data becomes available.",
            "zh": "æ½œåœ¨çš„é¢„æµ‹æ¨¡å‹ ï¼ˆaï¼‰ åœ¨è®­ç»ƒæ•°æ®å¯ç”¨ä¹‹å‰å’Œ ï¼ˆbï¼‰ ä¹‹åã€‚"
        }
    },
    {
        "translation": {
            "en": "For a given neuron to react, a specific visual feature had to occur at a particular location in the visual field; if the feature was moved to a different location in the visual field, then the neuron did not activate, nor did it activate if a different feature occurred at its target location.",
            "zh": "ä¸ºäº†è®©ç»™å®šçš„ç¥ç»å…ƒåšå‡ºååº”ï¼Œç‰¹å®šçš„è§†è§‰ç‰¹å¾å¿…é¡»å‡ºç°åœ¨è§†é‡ä¸­çš„ç‰¹å®šä½ç½®;å¦‚æœå°†ç‰¹å¾ç§»åŠ¨åˆ°è§†é‡ä¸­çš„ä¸åŒä½ç½®ï¼Œåˆ™ç¥ç»å…ƒä¸ä¼šæ¿€æ´»ï¼Œå¦‚æœåœ¨å…¶ç›®æ ‡ä½ç½®å‡ºç°ä¸åŒçš„ç‰¹å¾ï¼Œå®ƒä¹Ÿä¸ä¼šæ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can calculate the value of taking a particular action in a given state as the expected reward for taking the action plus the value of the state that the agent arrives in after taking that action.",
            "zh": "æˆ‘ä»¬å¯ä»¥è®¡ç®—åœ¨ç»™å®šçŠ¶æ€ä¸‹é‡‡å–ç‰¹å®šè¡ŒåŠ¨çš„ä»·å€¼ï¼Œä½œä¸ºé‡‡å–è¯¥è¡ŒåŠ¨çš„é¢„æœŸå¥–åŠ±åŠ ä¸Šä»£ç†åœ¨é‡‡å–è¯¥è¡ŒåŠ¨ååˆ°è¾¾çš„çŠ¶æ€çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "maximum entropy model, 357",
            "zh": "æœ€å¤§ç†µæ¨¡å‹ï¼Œ357"
        }
    },
    {
        "translation": {
            "en": "This parallelization of the processing of a number of examples by the network is particularly useful because the standard practice to train a network is to present batches of examples to the network, rather than to present examples one at a time.",
            "zh": "ç½‘ç»œå¯¹å¤šä¸ªç¤ºä¾‹çš„å¹¶è¡Œå¤„ç†ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºè®­ç»ƒç½‘ç»œçš„æ ‡å‡†åšæ³•æ˜¯å‘ç½‘ç»œå‘ˆç°æˆæ‰¹çš„ç¤ºä¾‹ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å‘ˆç°ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "16. The data in this question has been artificially created but is inspired by the Human Activity Recognition Using Smartphones Dataset first described by Anguita et al. (2013) and available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "16. æœ¬é—®é¢˜ä¸­çš„æ•°æ®æ˜¯äººä¸ºåˆ›å»ºçš„ï¼Œä½†å—åˆ° Anguita ç­‰äººï¼ˆ2013 å¹´ï¼‰é¦–æ¬¡æè¿°çš„ä½¿ç”¨æ™ºèƒ½æ‰‹æœºè¿›è¡Œäººç±»æ´»åŠ¨è¯†åˆ«æ•°æ®é›†çš„å¯å‘ï¼Œå¯ä» UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBache å’Œ Lichmanï¼Œ2013 å¹´ï¼‰è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Likewise, the number of weights used in a linear regression model is defined by the number of descriptive features and is independent of the number of instances in the training data.",
            "zh": "åŒæ ·ï¼Œçº¿æ€§å›å½’æ¨¡å‹ä¸­ä½¿ç”¨çš„æƒé‡æ•°ç”±æè¿°æ€§ç‰¹å¾çš„æ•°é‡å®šä¹‰ï¼Œå¹¶ä¸”ä¸è®­ç»ƒæ•°æ®ä¸­çš„å®ä¾‹æ•°æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "En masse all the questions that must be answered to successfully complete a predictive data analytics project can seem overwhelming. This is why we recommend using the CRISP-DM process to manage a project through its lifecycle. Table 14.1[730] shows the alignment between the phases of CRISP-DM, some of the key questions that must be answered during a predictive data analytics project, and the chapters in this book dealing with these questions.",
            "zh": "è¦æˆåŠŸå®Œæˆé¢„æµ‹æ€§æ•°æ®åˆ†æé¡¹ç›®ï¼Œå¿…é¡»å›ç­”çš„æ‰€æœ‰é—®é¢˜ä¼¼ä¹éƒ½è®©äººä¸çŸ¥æ‰€æªã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å»ºè®®ä½¿ç”¨ CRISP-DM æµç¨‹æ¥ç®¡ç†é¡¹ç›®çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸã€‚è¡¨14.1[730]æ˜¾ç¤ºäº†CRISP-DMå„é˜¶æ®µä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œé¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä¸­å¿…é¡»å›ç­”çš„ä¸€äº›å…³é”®é—®é¢˜ï¼Œä»¥åŠæœ¬ä¹¦ä¸­å¤„ç†è¿™äº›é—®é¢˜çš„ç« èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Covariance is measured in the same units as the features that it measures.",
            "zh": "åæ–¹å·®çš„åº¦é‡å•ä½ä¸åæ–¹å·®æ‰€æµ‹å®šçš„ç‰¹å¾ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] showed how the chain of products used to backpropagate an error gradient through a network of three neurons (i, j, and k) expands.",
            "zh": "å…¬å¼ 8.41[436] æ˜¾ç¤ºäº†ç”¨äºé€šè¿‡ä¸‰ä¸ªç¥ç»å…ƒï¼ˆiã€j å’Œ kï¼‰ç½‘ç»œåå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦çš„äº§ç‰©é“¾å¦‚ä½•æ‰©å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we need a formal measure of how well a descriptive feature discriminates between the levels of the target feature.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ­£å¼çš„åº¦é‡ï¼Œæ¥è¡¡é‡æè¿°æ€§ç‰¹å¾åœ¨ç›®æ ‡ç‰¹å¾çº§åˆ«ä¹‹é—´çš„åŒºåˆ†ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is not true of all prediction models.",
            "zh": "å¹¶éæ‰€æœ‰é¢„æµ‹æ¨¡å‹éƒ½æ˜¯å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a parametric model the size of the domain representation (i.e., the number of parameters) is independent of the number of instances in the dataset.",
            "zh": "åœ¨å‚æ•°åŒ–æ¨¡å‹ä¸­ï¼ŒåŸŸè¡¨ç¤ºçš„å¤§å°ï¼ˆå³å‚æ•°æ•°ï¼‰ä¸æ•°æ®é›†ä¸­çš„å®ä¾‹æ•°æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the weights in the network were sampled from a normal distribution with Î¼ = 0.0 and Ïƒ = 0.01, and therefore the weights in each layer have a variance of var(W) = Ïƒ2 = 0.012 = 0.0001.",
            "zh": "æ­¤å¤–ï¼Œç½‘ç»œä¸­çš„æƒé‡æ˜¯ä» Î¼ = 0.0 å’Œ Ïƒ = 0.01 çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œå› æ­¤æ¯å±‚ä¸­çš„æƒé‡å…·æœ‰ varï¼ˆWï¼‰ = Ïƒ2 = 0.012 = 0.0001 çš„æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, in 1969 Marvin Minsky and Seymour Papert published a book entitled Perceptrons that was highly critical of neural networks and in particular focused on the fact that single-layer networks (perceptrons) were not able to represent non-linearly separable functions (Minsky and Papert, 1969).",
            "zh": "ç„¶è€Œï¼Œåœ¨1969å¹´ï¼ŒMarvin Minskyå’ŒSeymour Papertå‡ºç‰ˆäº†ä¸€æœ¬åä¸ºã€Šæ„ŸçŸ¥å™¨ã€‹çš„ä¹¦ï¼Œè¯¥ä¹¦å¯¹ç¥ç»ç½‘ç»œæå‡ºäº†é«˜åº¦æ‰¹è¯„ï¼Œå¹¶ç‰¹åˆ«å…³æ³¨äº†å•å±‚ç½‘ç»œï¼ˆæ„ŸçŸ¥å™¨ï¼‰æ— æ³•è¡¨ç¤ºéçº¿æ€§å¯åˆ†ç¦»å‡½æ•°çš„äº‹å®ï¼ˆMinskyå’ŒPapertï¼Œ1969ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "When missing indicator features are used, the original feature is usually discarded.",
            "zh": "å½“ä½¿ç”¨ç¼ºå°‘æŒ‡æ ‡ç‰¹å¾æ—¶ï¼Œé€šå¸¸ä¼šä¸¢å¼ƒåŸå§‹ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For clarity, some additional notational conventions are used in Chapter 8[381] on deep learning.",
            "zh": "ä¸ºäº†æ¸…æ¥šèµ·è§ï¼Œåœ¨å…³äºæ·±åº¦å­¦ä¹ çš„ç¬¬8ç« [381]ä¸­ä½¿ç”¨äº†ä¸€äº›é¢å¤–çš„ç¬¦å·çº¦å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "LNLDEV_U/G/R/I/Z",
            "zh": "LNLDEV_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "11. This dataset has been artificially created for this book, but machine learning has been used for this task, for example, by Mishne and Glance (2006).",
            "zh": "11. è¿™ä¸ªæ•°æ®é›†æ˜¯ä¸ºæœ¬ä¹¦äººä¸ºåˆ›å»ºçš„ï¼Œä½†æœºå™¨å­¦ä¹ å·²è¢«ç”¨äºè¿™é¡¹ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼ŒMishne å’Œ Glance ï¼ˆ2006ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The depth of a network is measured by the number of layers of neurons within the network.",
            "zh": "ç½‘ç»œçš„æ·±åº¦æ˜¯é€šè¿‡ç½‘ç»œå†…ç¥ç»å…ƒçš„å±‚æ•°æ¥è¡¡é‡çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we proceed through the steps of calculating the Î´s for each of the neurons, we will need to calculate the âˆ‚a/âˆ‚z term for each neuron, and so for ease of reference, Table 8.5[428] lists this value for each neuron; for space and convenience considerations we have rounded these values to four decimal places and used the rounded values in our calculations.",
            "zh": "å½“æˆ‘ä»¬ç»§ç»­è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„ Î´s æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„ âˆ‚a/âˆ‚z é¡¹ï¼Œå› æ­¤ä¸ºäº†ä¾¿äºå‚è€ƒï¼Œè¡¨ 8.5[428] åˆ—å‡ºäº†æ¯ä¸ªç¥ç»å…ƒçš„æ­¤å€¼;å‡ºäºç©ºé—´å’Œæ–¹ä¾¿çš„è€ƒè™‘ï¼Œæˆ‘ä»¬å°†è¿™äº›å€¼å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼Œå¹¶åœ¨è®¡ç®—ä¸­ä½¿ç”¨å››èˆäº”å…¥çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.15â€…â€…â€…A simple bicycle demand predictions dataset and the workings of the first iterations of training a gradient boosting model.",
            "zh": "4.15 ä¸€ä¸ªç®€å•çš„è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®é›†å’Œè®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹çš„ç¬¬ä¸€æ¬¡è¿­ä»£çš„å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.6â€…â€…â€…A selection of the simple linear regression models developed during the gradient descent process for the office rentals dataset. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.6 åœ¨åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹çš„é€‰æ‹©ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "feature selection, 94, 181, 227, 227, 232, 614, 722, 740",
            "zh": "ç‰¹å¾é€‰æ‹©ã€94ã€181ã€227ã€227ã€232ã€614ã€722ã€740"
        }
    },
    {
        "translation": {
            "en": "This last term illustrates an intermediate behavior in the forget gate in which the original cell state is half-forgotten/half-retained.",
            "zh": "æœ€åä¸€é¡¹è¯´æ˜äº†é—å¿˜é—¨ä¸­çš„ä¸€ç§ä¸­é—´è¡Œä¸ºï¼Œå…¶ä¸­åŸå§‹ç»†èƒçŠ¶æ€è¢«åŠé—å¿˜/åŠä¿ç•™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Usually the outputs from the unsupervised work are consumed in a supervised machine learning task, or another unsupervised machine learning task.",
            "zh": "é€šå¸¸ï¼Œæ— ç›‘ç£å·¥ä½œçš„è¾“å‡ºåœ¨æœ‰ç›‘ç£çš„æœºå™¨å­¦ä¹ ä»»åŠ¡æˆ–å…¶ä»–æ— ç›‘ç£çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the model assumes that a convergence criterion has been specified.17 Early stopping is the most popular strategy used to define a convergence criterion; we explain the early stopping algorithm in Section 8.4.4[472].",
            "zh": "æœ€åï¼Œè¯¥æ¨¡å‹å‡è®¾å·²ç»æŒ‡å®šäº†æ”¶æ•›æ ‡å‡†.17 æå‰åœæ­¢æ˜¯ç”¨äºå®šä¹‰æ”¶æ•›æ ‡å‡†çš„æœ€æµè¡Œç­–ç•¥;æˆ‘ä»¬åœ¨ç¬¬8.4.4èŠ‚[472]ä¸­è§£é‡Šäº†æ—©æœŸåœæ­¢ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.19[574] shows the associated confusion matrix for these predictions, including measures of precision and recall.",
            "zh": "è¡¨9.19[574]æ˜¾ç¤ºäº†è¿™äº›é¢„æµ‹çš„ç›¸å…³æ··æ·†çŸ©é˜µï¼ŒåŒ…æ‹¬ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„æµ‹é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions for a bacterial species identification problem.",
            "zh": "å…·æœ‰ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜çš„æ¨¡å‹é¢„æµ‹çš„æ ·æœ¬æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Over time, we can expect the table to converge toward optimal values.",
            "zh": "éšç€æ—¶é—´çš„æµé€ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸè¯¥è¡¨å°†æ”¶æ•›åˆ°æœ€ä½³å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.3â€ƒStandard Approach: The Nearest Neighbor Algorithm",
            "zh": "5.3 æ ‡å‡†æ–¹æ³•ï¼šæœ€è¿‘é‚»ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "We use range normalization to convert a feature value into the range [low, high] as follows:",
            "zh": "æˆ‘ä»¬ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–å°†ç‰¹å¾å€¼è½¬æ¢ä¸ºèŒƒå›´ [lowï¼Œ high]ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "The following table shows summary statistics of the four descriptive features for each of the three clusters found.",
            "zh": "ä¸‹è¡¨æ˜¾ç¤ºäº†æ‰¾åˆ°çš„ä¸‰ä¸ªèšç±»ä¸­æ¯ä¸ªèšç±»çš„å››ä¸ªæè¿°æ€§ç‰¹å¾çš„æ±‡æ€»ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision tree models can be used for datasets that contain both categorical and continuous descriptive features.",
            "zh": "å†³ç­–æ ‘æ¨¡å‹å¯ç”¨äºåŒæ—¶åŒ…å«åˆ†ç±»å’Œè¿ç»­æè¿°æ€§ç‰¹å¾çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most common form of polynomial relationship is the second order polynomial, also known as the quadratic function, which takes the general form a = bx + cx2.",
            "zh": "å¤šé¡¹å¼å…³ç³»æœ€å¸¸è§çš„å½¢å¼æ˜¯äºŒé˜¶å¤šé¡¹å¼ï¼Œä¹Ÿç§°ä¸ºäºŒæ¬¡å‡½æ•°ï¼Œå…¶ä¸€èˆ¬å½¢å¼ä¸º a = bx + cx2."
        }
    },
    {
        "translation": {
            "en": "upper quartile, 749, 755",
            "zh": "ä¸Šå››åˆ†ä½æ•°ï¼Œ 749ï¼Œ 755"
        }
    },
    {
        "translation": {
            "en": "However, once we introduce one or more hidden layers into a network, it becomes more difficult to use the gradient descent algorithm to train the network.",
            "zh": "ç„¶è€Œï¼Œä¸€æ—¦æˆ‘ä»¬åœ¨ç½‘ç»œä¸­å¼•å…¥ä¸€ä¸ªæˆ–å¤šä¸ªéšè—å±‚ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥è®­ç»ƒç½‘ç»œå°±å˜å¾—æ›´åŠ å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Techniques such as the k-d tree can help with this issue by creating a fast index at the cost of some preprocessing.",
            "zh": "åƒ k-d æ ‘è¿™æ ·çš„æŠ€æœ¯å¯ä»¥é€šè¿‡ä»¥ä¸€äº›é¢„å¤„ç†ä¸ºä»£ä»·åˆ›å»ºä¸€ä¸ªå¿«é€Ÿç´¢å¼•æ¥å¸®åŠ©è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use âŠ™ to denote an elementwise product. This operation is sometimes called the Hadamard product.",
            "zh": "æˆ‘ä»¬ç”¨âŠ™æ¥è¡¨ç¤ºä¸€ä¸ªå…ƒç´ ä¹˜ç§¯ã€‚æ­¤æ“ä½œæœ‰æ—¶ç§°ä¸º Hadamard äº§å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, at the end of the processing of the mini-batch (i.e., when the algorithm exits the for loop from Line 15[420] to Line 27[420]), Î”w i,k will contain the weight updates for weight wi,k summed across all the examples in the mini-batch.",
            "zh": "å› æ­¤ï¼Œåœ¨å°æ‰¹é‡å¤„ç†ç»“æŸæ—¶ï¼ˆå³ï¼Œå½“ç®—æ³•é€€å‡ºä»ç¬¬ 15 è¡Œ [420] åˆ°ç¬¬ 27 è¡Œ [420] çš„ for å¾ªç¯æ—¶ï¼‰ï¼ŒÎ”w iï¼Œk å°†åŒ…å«å°æ‰¹é‡ä¸­æ‰€æœ‰ç¤ºä¾‹çš„æƒé‡ wiï¼Œk çš„æƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. This size of margin of error is common for these types of election polls.",
            "zh": "5. è¿™ç§è¯¯å·®å¹…åº¦å¯¹äºè¿™äº›ç±»å‹çš„é€‰ä¸¾æ°‘æ„è°ƒæŸ¥å¾ˆå¸¸è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset is visualized in Figure 4.21(a)[163].",
            "zh": "æ•°æ®é›†å¦‚å›¾4.21ï¼ˆaï¼‰[163]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "10.3â€ƒStandard Approach: The k-Means Clustering Algorithm",
            "zh": "10.3 æ ‡å‡†æ–¹æ³•ï¼šk-Means èšç±»ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "P(q[1],â€¦,q[m]) can be calculated as the relative frequency in a dataset of the joint event that the descriptive features of an instance take on the values q[1],â€¦,q[m].",
            "zh": "Pï¼ˆq[1],...,q[m]ï¼‰ å¯ä»¥è®¡ç®—ä¸ºå®ä¾‹çš„æè¿°æ€§ç‰¹å¾å¯¹å€¼ q[1],...,q[m] çš„è”åˆäº‹ä»¶æ•°æ®é›†ä¸­çš„ç›¸å¯¹é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "model ensemble, xvi, 158, 170, 178, 476, 733",
            "zh": "æ¨¡å‹åˆå¥ï¼Œ xviï¼Œ 158ï¼Œ 170ï¼Œ 178ï¼Œ 476ï¼Œ 733"
        }
    },
    {
        "translation": {
            "en": "13.1â€…â€…â€…The structure of the SDSS and Galaxy Zoo combined dataset.",
            "zh": "13.1 SDSSå’ŒGalaxy Zooç»„åˆæ•°æ®é›†çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The averageclassaccuracyHM performance measure can be applied to multinomial prediction problems and is an effective option for measuring performance.",
            "zh": "averageclassaccuracyHM æ€§èƒ½åº¦é‡å¯åº”ç”¨äºå¤šé¡¹å¼é¢„æµ‹é—®é¢˜ï¼Œæ˜¯è¡¡é‡æ€§èƒ½çš„æœ‰æ•ˆé€‰é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "D.3â€…â€…â€…Multiplication",
            "zh": "D.3 ä¹˜æ³•"
        }
    },
    {
        "translation": {
            "en": "Shannon, Claude E., and Warren Weaver. 1949. The mathematical theory of communication. University of Illinois Press.",
            "zh": "é¦™å†œã€å…‹åŠ³å¾· E. å’Œæ²ƒä¼¦éŸ¦å¼—ã€‚1949. é€šä¿¡çš„æ•°å­¦ç†è®ºã€‚ä¼Šåˆ©è¯ºä¼Šå¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´ term for a neuron describes the rate of change of the error (i.e., the error gradient) of the network with respect to changes in the weighted sum calculated by the neuron. Using â„° to represent the error of the network at the output layer, and zk to denote the weighted sum calculation in neuron k, the Î´ for a neuron k can be mathematically defined",
            "zh": "ç¥ç»å…ƒçš„Î´æœ¯è¯­æè¿°äº†ç½‘ç»œè¯¯å·®ï¼ˆå³è¯¯å·®æ¢¯åº¦ï¼‰ç›¸å¯¹äºç¥ç»å…ƒè®¡ç®—çš„åŠ æƒå’Œå˜åŒ–çš„å˜åŒ–ç‡ã€‚ä½¿ç”¨ E è¡¨ç¤ºè¾“å‡ºå±‚ç½‘ç»œçš„è¯¯å·®ï¼Œä½¿ç”¨ zk è¡¨ç¤ºç¥ç»å…ƒ k ä¸­çš„åŠ æƒå’Œè®¡ç®—ï¼Œå¯ä»¥ç”¨æ•°å­¦æ–¹å¼å®šä¹‰ç¥ç»å…ƒ k çš„Î´"
        }
    },
    {
        "translation": {
            "en": "7.15â€…â€…â€…A selection of the logistic regression models developed during the gradient descent process for the extended generators dataset in Table 7.7[347]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.15 è¡¨7.7[347]ä¸­æ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„é€»è¾‘å›å½’æ¨¡å‹çš„é€‰æ‹©ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Box plots, however, can be placed side by side, and in Section 3.5.1.2[74] we see that the ability to place multiple box plots side by side is the main advantage box plots have over histograms.",
            "zh": "ç„¶è€Œï¼Œç®±å½¢å›¾å¯ä»¥å¹¶æ’æ”¾ç½®ï¼Œåœ¨ç¬¬ 3.5.1.2 èŠ‚[74]ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å¹¶æ’æ”¾ç½®å¤šä¸ªç®±å½¢å›¾çš„èƒ½åŠ›æ˜¯ç®±å½¢å›¾ç›¸å¯¹äºç›´æ–¹å›¾çš„ä¸»è¦ä¼˜åŠ¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The variance of a sample is a more useful measure of variation. Variance measures the average difference between each value in a sample and the mean of that sample. The variance of the n values of a feature a is denoted var(a) and is calculated as",
            "zh": "æ ·æœ¬çš„æ–¹å·®æ˜¯æ›´æœ‰ç”¨çš„å˜å¼‚åº¦é‡ã€‚æ–¹å·®æµ‹é‡æ ·æœ¬ä¸­æ¯ä¸ªå€¼ä¸è¯¥æ ·æœ¬çš„å¹³å‡å€¼ä¹‹é—´çš„å¹³å‡å·®å€¼ã€‚ç‰¹å¾ a çš„ n ä¸ªå€¼çš„æ–¹å·®è¡¨ç¤ºä¸º varï¼ˆaï¼‰ï¼Œè®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "Figure 5.9(a)[199] shows the complete k-d tree generated for the dataset, and Figure 5.9(b)[199] shows the partitioning of the feature space as defined by the k-d tree.",
            "zh": "å›¾5.9ï¼ˆaï¼‰[199]æ˜¾ç¤ºäº†ä¸ºæ•°æ®é›†ç”Ÿæˆçš„å®Œæ•´k-dæ ‘ï¼Œå›¾5.9ï¼ˆbï¼‰[199]æ˜¾ç¤ºäº†k-dæ ‘å®šä¹‰çš„ç‰¹å¾ç©ºé—´çš„åˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "7.5â€…â€…â€…The office rentals dataset from Table 7.1[313] adjusted to handle the categorical ENERGY RATING descriptive feature in linear regression models.",
            "zh": "7.5 å¯¹è¡¨7.1[313]ä¸­çš„å†™å­—æ¥¼ç§Ÿèµæ•°æ®é›†è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥å¤„ç†çº¿æ€§å›å½’æ¨¡å‹ä¸­çš„åˆ†ç±»ENERGY RATINGæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. Select one of the predictive analytics models that you proposed in your answer to Question 2 about the revenue commission for exploration of the design of its analytics base table (ABT).",
            "zh": "4. é€‰æ‹©æ‚¨åœ¨å›ç­”æœ‰å…³æ”¶å…¥ä½£é‡‘çš„é—®é¢˜ 2 æ—¶æå‡ºçš„é¢„æµ‹åˆ†ææ¨¡å‹ä¹‹ä¸€ï¼Œä»¥æ¢ç´¢å…¶åˆ†æåŸºè¡¨ ï¼ˆABTï¼‰ çš„è®¾è®¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure a Ïƒ represents a layer of neurons that use a sigmoid activation function, a T represents a layer of neurons that use a tanh activation function, the âŠ™ symbols represent elementwise vector multiplication (i.e., the Hadamard product), and + represents an elementwise vector addition operation.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼ŒÏƒ è¡¨ç¤ºä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒå±‚ï¼ŒT è¡¨ç¤ºä½¿ç”¨ tanh æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒå±‚ï¼ŒâŠ™ ç¬¦å·è¡¨ç¤ºå…ƒç´ å‘é‡ä¹˜æ³•ï¼ˆå³ Hadamard ç§¯ï¼‰ï¼Œ+ è¡¨ç¤ºå…ƒç´ å‘é‡åŠ æ³•è¿ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "paperclip maximizer, 677",
            "zh": "å›å½¢é’ˆæœ€å¤§åŒ–å™¨ï¼Œ677"
        }
    },
    {
        "translation": {
            "en": "When the algorithm was used to generate 500 samples, the relative frequency of CPI = high was 0.196.",
            "zh": "å½“è¯¥ç®—æ³•ç”Ÿæˆ500ä¸ªæ ·æœ¬æ—¶ï¼ŒCPI=é«˜çš„ç›¸å¯¹é¢‘ç‡ä¸º0.196ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can also use the confusion matrix to begin to investigate the kinds of mistakes that the prediction model is making.",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ··æ·†çŸ©é˜µå¼€å§‹ç ”ç©¶é¢„æµ‹æ¨¡å‹æ‰€çŠ¯çš„é”™è¯¯ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This discussion highlights that entropy is essentially a measure of the heterogeneity of a set. As the composition of the sets changed from the set with only one type of element (Figure 4.5(a)[124]) to a set with many different types of elements, each with an equal likelihood of being selected (Figure 4.5(f)[124]), the entropy score for the sets increased.",
            "zh": "è¿™ä¸ªè®¨è®ºå¼ºè°ƒç†µæœ¬è´¨ä¸Šæ˜¯å¯¹é›†åˆå¼‚è´¨æ€§çš„åº¦é‡ã€‚éšç€é›†åˆçš„ç»„æˆä»åªæœ‰ä¸€ç§å…ƒç´ çš„é›†åˆï¼ˆå›¾4.5ï¼ˆaï¼‰[124]ï¼‰å˜ä¸ºå…·æœ‰è®¸å¤šä¸åŒç±»å‹å…ƒç´ çš„é›†åˆï¼Œæ¯ä¸ªå…ƒç´ è¢«é€‰ä¸­çš„å¯èƒ½æ€§ç›¸ç­‰ï¼ˆå›¾4.5ï¼ˆfï¼‰[124]ï¼‰ï¼Œé›†åˆçš„ç†µå¾—åˆ†å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.4â€ƒPredicting Continuous Targets",
            "zh": "5.4.4 é¢„æµ‹è¿ç»­ç›®æ ‡"
        }
    },
    {
        "translation": {
            "en": "k-means clustering, 597, 600, 601, 624, 629, 631, 636, 740",
            "zh": "k å‡å€¼èšç±»ï¼Œ 597ï¼Œ 600ï¼Œ 601ï¼Œ 624ï¼Œ 629ï¼Œ 631ï¼Œ 636ï¼Œ 740"
        }
    },
    {
        "translation": {
            "en": "So, for example, if we are trying to predict whether or not insurance claims are fraudulent, we require a large dataset of historical insurance claims, and for each one we must know whether or not that claim was found to be fraudulent.",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¯•å›¾é¢„æµ‹ä¿é™©ç´¢èµ”æ˜¯å¦å…·æœ‰æ¬ºè¯ˆæ€§ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¤§å‹çš„å†å²ä¿é™©ç´¢èµ”æ•°æ®é›†ï¼Œå¯¹äºæ¯ä¸ªç´¢èµ”ï¼Œæˆ‘ä»¬å¿…é¡»çŸ¥é“è¯¥ç´¢èµ”æ˜¯å¦è¢«å‘ç°æ˜¯æ¬ºè¯ˆæ€§çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This contrasts with the hold-out sampling design, in which we simply deploy the model that has been evaluated.",
            "zh": "è¿™ä¸ä¿æŒæŠ½æ ·è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåœ¨ä¿ç•™æŠ½æ ·è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬åªéœ€éƒ¨ç½²å·²è¯„ä¼°çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "rectifier, 386",
            "zh": "æ•´æµå™¨ï¼Œ386"
        }
    },
    {
        "translation": {
            "en": "brute-force search, 318",
            "zh": "æš´åŠ›æœç´¢ï¼Œ318"
        }
    },
    {
        "translation": {
            "en": "This advantage should not be underestimated.",
            "zh": "è¿™ä¸€ä¼˜åŠ¿ä¸å®¹å°è§‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "A domain concept is a high-level abstraction that describes some characteristic of the prediction subject from which we derive a set of concrete features that will be included in an ABT.",
            "zh": "é¢†åŸŸæ¦‚å¿µæ˜¯ä¸€ä¸ªé«˜çº§æŠ½è±¡ï¼Œå®ƒæè¿°äº†é¢„æµ‹ä¸»é¢˜çš„æŸäº›ç‰¹å¾ï¼Œæˆ‘ä»¬ä»ä¸­æ¨å¯¼å‡ºä¸€ç»„å°†åŒ…å«åœ¨ ABT ä¸­çš„å…·ä½“ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that its activation does not flow forward through the network, and hence it has no effect on the output of the model.",
            "zh": "è¿™æ„å‘³ç€å®ƒçš„æ¿€æ´»ä¸ä¼šé€šè¿‡ç½‘ç»œå‘å‰æµåŠ¨ï¼Œå› æ­¤å®ƒå¯¹æ¨¡å‹çš„è¾“å‡ºæ²¡æœ‰å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the raw data, customers who did not churn outnumber those who churned at a ratio of over 10 to 1.",
            "zh": "åœ¨åŸå§‹æ•°æ®ä¸­ï¼Œæ²¡æœ‰æµå¤±çš„å®¢æˆ·æ•°é‡è¶…è¿‡äº†æµå¤±çš„å®¢æˆ·æ•°é‡ï¼Œæ¯”ä¾‹è¶…è¿‡ 10ï¼š1ã€‚"
        }
    },
    {
        "translation": {
            "en": "scatter plot matrix, 74, 84, 103",
            "zh": "æ•£ç‚¹å›¾çŸ©é˜µï¼Œ74ã€84ã€103"
        }
    },
    {
        "translation": {
            "en": "On other occasions she would take a series of successful steps but then experience a sinking feeling realizing that she had turned back on herself and arrived back on the starting bank.",
            "zh": "åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå¥¹ä¼šé‡‡å–ä¸€ç³»åˆ—æˆåŠŸçš„æ­¥éª¤ï¼Œä½†éšåä¼šç»å†ä¸€ç§æ²‰æ²¦çš„æ„Ÿè§‰ï¼Œæ„è¯†åˆ°å¥¹å·²ç»èƒŒå¼ƒäº†è‡ªå·±ï¼Œå›åˆ°äº†èµ·ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.72)[467] uses the chain rule to make this explicit by defining Î´k as the product of the rate of change of the negative natural log of the predicted probability of the true category with respect to changes in that probability and the rate of change of the predicted probability of the true category with respect to changes in the logit (we encountered this expansion step previously in a different guise; recall that âˆ‚â„°/âˆ‚zk = âˆ‚â„°/âˆ‚ak Ã— âˆ‚ak/âˆ‚zk).",
            "zh": "æ–¹ç¨‹ï¼ˆ8.72ï¼‰[467]ä½¿ç”¨é“¾å¼æ³•åˆ™æ¥æ˜ç¡®è¿™ä¸€ç‚¹ï¼Œå°†Î´kå®šä¹‰ä¸ºçœŸå®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡çš„è´Ÿè‡ªç„¶å¯¹æ•°ç›¸å¯¹äºè¯¥æ¦‚ç‡å˜åŒ–çš„å˜åŒ–ç‡çš„ä¹˜ç§¯ï¼Œä»¥åŠçœŸå®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ç›¸å¯¹äºlogitå˜åŒ–çš„å˜åŒ–ç‡ï¼ˆæˆ‘ä»¬ä»¥å‰ä»¥ä¸åŒçš„å½¢å¼é‡åˆ°è¿‡è¿™ä¸ªæ‰©å±•æ­¥éª¤;å›æƒ³ä¸€ä¸‹âˆ‚E/âˆ‚zk = âˆ‚E/âˆ‚ak Ã— âˆ‚ak/âˆ‚zkï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each row represents a fold in the process, in which the black rectangles indicate the instance that is used for testing while the white spaces indicate the data used for training.",
            "zh": "æ¯è¡Œè¡¨ç¤ºæµç¨‹ä¸­çš„ä¸€ä¸ªæŠ˜å ï¼Œå…¶ä¸­é»‘è‰²çŸ©å½¢è¡¨ç¤ºç”¨äºæµ‹è¯•çš„å®ä¾‹ï¼Œè€Œç©ºç™½è¡¨ç¤ºç”¨äºè®­ç»ƒçš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The alternative is to define active customers as any customer in the AT data that was active at some point.",
            "zh": "å¦ä¸€ç§æ–¹æ³•æ˜¯å°†æ´»åŠ¨å®¢æˆ·å®šä¹‰ä¸º AT æ•°æ®ä¸­åœ¨æŸä¸ªæ—¶é—´ç‚¹å¤„äºæ´»åŠ¨çŠ¶æ€çš„ä»»ä½•å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.1(b)[314] shows the same scatter plot as shown in Figure 7.1(a)[314] with a simple linear model added to capture the relationship between office sizes and office rental prices.",
            "zh": "å›¾7.1ï¼ˆbï¼‰[314]æ˜¾ç¤ºäº†ä¸å›¾7.1ï¼ˆaï¼‰[314]ç›¸åŒçš„æ•£ç‚¹å›¾ï¼Œå¹¶æ·»åŠ äº†ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹æ¥æ•æ‰åŠå…¬å®¤è§„æ¨¡ä¸åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "descriptive features, 5, 19, 23, 28, 598, 688",
            "zh": "æè¿°æ€§ç‰¹å¾ï¼Œ 5ï¼Œ 19ï¼Œ 23ï¼Œ 28ï¼Œ 598ï¼Œ 688"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6(a)[275] illustrates the profile typical of data with multiple subpopulations.",
            "zh": "å›¾6.6ï¼ˆaï¼‰[275]è¯´æ˜äº†å…·æœ‰å¤šä¸ªå­ç¾¤ä½“çš„æ•°æ®çš„å…¸å‹æ¦‚å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.36[498] provides a worked example of data processing and flow through a convolutional network similar in structure to the architecture blueprint shown in Figure 8.35[497].",
            "zh": "å›¾ 8.36[498] æä¾›äº†ä¸€ä¸ªé€šè¿‡å·ç§¯ç½‘ç»œè¿›è¡Œæ•°æ®å¤„ç†å’ŒæµåŠ¨çš„å·¥ä½œç¤ºä¾‹ï¼Œå…¶ç»“æ„ç±»ä¼¼äºå›¾ 8.35[497] æ‰€ç¤ºçš„æ¶æ„è“å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Retaining the Markov assumption that only the current time-step is required to model what will happen next, the probability of transitioning to a particular state depends only on the current state and the action just taken. Each transition to a new state based on a particular action now also carries with it a reward",
            "zh": "ä¿ç•™é©¬å°”å¯å¤«å‡è®¾ï¼Œå³åªéœ€è¦å½“å‰æ—¶é—´æ­¥é•¿æ¥æ¨¡æ‹Ÿæ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œè¿‡æ¸¡åˆ°ç‰¹å®šçŠ¶æ€çš„æ¦‚ç‡ä»…å–å†³äºå½“å‰çŠ¶æ€å’Œåˆšåˆšé‡‡å–çš„è¡ŒåŠ¨ã€‚ç°åœ¨ï¼Œæ¯æ¬¡åŸºäºç‰¹å®šæ“ä½œè¿‡æ¸¡åˆ°æ–°çŠ¶æ€æ—¶ï¼Œéƒ½ä¼šå¸¦æ¥å¥–åŠ±"
        }
    },
    {
        "translation": {
            "en": "In Section 8.2.5[395] we discuss how the depth of a neural network affects the ability of the network to represent and learn functions at different levels of complexity.",
            "zh": "åœ¨ç¬¬ 8.2.5 èŠ‚[395]ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ç¥ç»ç½‘ç»œçš„æ·±åº¦å¦‚ä½•å½±å“ç½‘ç»œåœ¨ä¸åŒå¤æ‚ç¨‹åº¦ä¸‹è¡¨ç¤ºå’Œå­¦ä¹ å‡½æ•°çš„èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rubin, Daniel J. 2015. Hospital readmission of patients with diabetes. Current Diabetes Reports 15 (4): 17.",
            "zh": "é²å®¾ï¼Œä¸¹å°¼å°” J. 2015 å¹´ã€‚ç³–å°¿ç—…æ‚£è€…å†å…¥é™¢ã€‚å½“å‰ç³–å°¿ç—…æŠ¥å‘Š15ï¼ˆ4ï¼‰ï¼š17ã€‚"
        }
    },
    {
        "translation": {
            "en": "hamming distance, 240",
            "zh": "æ±‰æ˜è·ç¦»ï¼Œ240"
        }
    },
    {
        "translation": {
            "en": "area under the curve, 561, 590",
            "zh": "æ›²çº¿ä¸‹é¢ç§¯ï¼Œ561,590"
        }
    },
    {
        "translation": {
            "en": "6.6â€…â€…â€…Further Reading",
            "zh": "6.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "As with the schematic on the left of Figure 8.37[502], this figure abstracts over some of the details of the network.",
            "zh": "ä¸å›¾8.37[502]å·¦ä¾§çš„åŸç†å›¾ä¸€æ ·ï¼Œè¯¥å›¾æŠ½è±¡äº†ç½‘ç»œçš„ä¸€äº›ç»†èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects use machine learning to build models that capture the relationships in large datasets between descriptive features and a target feature.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥æ„å»ºæ¨¡å‹ï¼Œä»¥æ•è·å¤§å‹æ•°æ®é›†ä¸­æè¿°æ€§è¦ç´ ä¸ç›®æ ‡è¦ç´ ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Distance matrices that detail the first three iterations of the AHC algorithm applied to the reduced version of the mobile phone customer dataset in Table 10.1[604].",
            "zh": "è¯¦ç»†æè¿°AHCç®—æ³•å‰ä¸‰æ¬¡è¿­ä»£çš„è·ç¦»çŸ©é˜µï¼Œåº”ç”¨äºè¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ç²¾ç®€ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "citizen science, 708",
            "zh": "å…¬æ°‘ç§‘å­¦ï¼Œ708"
        }
    },
    {
        "translation": {
            "en": "Information-based learning (Chapter 4[117])",
            "zh": "ä¿¡æ¯åŒ–å­¦ä¹ ï¼ˆç¬¬4ç« [117]ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Other, more sophisticated sampling methods can be used to ensure that a sample maintains relationships that exist in a population.",
            "zh": "å¯ä»¥ä½¿ç”¨å…¶ä»–æ›´å¤æ‚çš„æŠ½æ ·æ–¹æ³•æ¥ç¡®ä¿æ ·æœ¬ä¿æŒæ€»ä½“ä¸­å­˜åœ¨çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(short)â€ defines a one-semester course.",
            "zh": "ï¼ˆçŸ­ï¼‰â€œå®šä¹‰äº†ä¸€ä¸ªå­¦æœŸçš„è¯¾ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is very similar to the hard threshold function given in Equation (7.24)[341], except that it has a soft boundary.",
            "zh": "è¿™ä¸å…¬å¼ï¼ˆ7.24ï¼‰[341]ä¸­ç»™å‡ºçš„ç¡¬é˜ˆå€¼å‡½æ•°éå¸¸ç›¸ä¼¼ï¼Œåªæ˜¯å®ƒæœ‰ä¸€ä¸ªè½¯è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The first step in building the decision tree is to determine which of the three descriptive features is the best one to split the dataset on at the root node. The algorithm does this by computing the information gain for each feature. The total entropy for this dataset, which is required to calculate information gain, is computed",
            "zh": "æ„å»ºå†³ç­–æ ‘çš„ç¬¬ä¸€æ­¥æ˜¯ç¡®å®šä¸‰ä¸ªæè¿°æ€§ç‰¹å¾ä¸­çš„å“ªä¸€ä¸ªæœ€é€‚åˆåœ¨æ ¹èŠ‚ç‚¹ä¸Šæ‹†åˆ†æ•°æ®é›†ã€‚è¯¥ç®—æ³•é€šè¿‡è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¥å®ç°æ­¤ç›®çš„ã€‚è®¡ç®—æ­¤æ•°æ®é›†çš„æ€»ç†µï¼ˆè®¡ç®—ä¿¡æ¯å¢ç›Šæ‰€éœ€çš„ç†µï¼‰"
        }
    },
    {
        "translation": {
            "en": "1,450,500",
            "zh": "1,450,500"
        }
    },
    {
        "translation": {
            "en": "simple random sample, 751",
            "zh": "ç®€å•éšæœºæ ·æœ¬ï¼Œ751"
        }
    },
    {
        "translation": {
            "en": "Each of these historical examples must contain sufficient data to describe the scenario and the outcome that we are interested in predicting.",
            "zh": "è¿™äº›å†å²ç¤ºä¾‹ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¿…é¡»åŒ…å«è¶³å¤Ÿçš„æ•°æ®æ¥æè¿°æˆ‘ä»¬æœ‰å…´è¶£é¢„æµ‹çš„åœºæ™¯å’Œç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix for a simple prediction task with two target levels is shown in Table 9.2[538].",
            "zh": "å…·æœ‰ä¸¤ä¸ªç›®æ ‡æ°´å¹³çš„ç®€å•é¢„æµ‹ä»»åŠ¡çš„æ··æ·†çŸ©é˜µç»“æ„å¦‚è¡¨9.2[538]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.16[568] shows the cumulative lift for each decile for the predictions shown in Table 9.11[557] for the email classification problem, and these values are plotted in a cumulative lift curve in Figure 9.16(b)[570].",
            "zh": "è¡¨9.16[568]æ˜¾ç¤ºäº†è¡¨9.11[557]ä¸­é’ˆå¯¹ç”µå­é‚®ä»¶åˆ†ç±»é—®é¢˜çš„é¢„æµ‹ï¼Œæ¯ä¸ªååˆ†ä½æ•°çš„ç´¯ç§¯æå‡ï¼Œè¿™äº›å€¼ç»˜åˆ¶åœ¨å›¾9.16ï¼ˆbï¼‰[570]ä¸­çš„ç´¯ç§¯æå‡æ›²çº¿ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2â€…â€…â€…Fundamentals",
            "zh": "11.2 åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "Consequently, if we are designing a filter to process a color image, with three color channels (red, green, and blue), we can vary the height and width dimensions of the filter, but the depth dimension must be 3.",
            "zh": "å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬è®¾è®¡ä¸€ä¸ªæ»¤é•œæ¥å¤„ç†å½©è‰²å›¾åƒï¼Œå…·æœ‰ä¸‰ä¸ªé¢œè‰²é€šé“ï¼ˆçº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ”¹å˜æ»¤é•œçš„é«˜åº¦å’Œå®½åº¦å°ºå¯¸ï¼Œä½†æ·±åº¦ç»´åº¦å¿…é¡»ä¸º 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "Or three payments in a six-month period?",
            "zh": "è¿˜æ˜¯åœ¨å…­ä¸ªæœˆå†…æ”¯ä»˜ä¸‰ç¬”æ¬¾é¡¹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "10.13â€…â€…â€…(a) A plot of the hierarchical grouping of the instances in the mobile phone customer dataset from Table 10.1[604] found by the AHC algorithm (using Euclidean distance and single linkage). (b) The clustering returned when the tree is cut at k = 3. (c) The clustering returned when the tree is cut at k = 6.",
            "zh": "10.13 ï¼ˆaï¼‰ AHCç®—æ³•ï¼ˆä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»å’Œå•é“¾æ¥ï¼‰æ‰¾åˆ°çš„è¡¨10.1[604]ä¸­ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­å®ä¾‹çš„åˆ†å±‚å›¾ã€‚ï¼ˆbï¼‰ å½“æ ‘æœ¨åœ¨k = 3æ—¶è¢«ç ä¼æ—¶è¿”å›çš„èšç±»ã€‚ï¼ˆcï¼‰ åœ¨k = 6æ—¶ç ä¼æ ‘æœ¨æ—¶è¿”å›çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, Neuron B has the highest activation for any of the neurons in the local receptive field of Neuron C. This means that Î´A = 0 because Neuron A did not have the maximum value in the local receptive field of the sub-sampling neuron to which it is connected.",
            "zh": "äº‹å®ä¸Šï¼Œç¥ç»å…ƒ B åœ¨ç¥ç»å…ƒ C çš„å±€éƒ¨æ„Ÿå—é‡ä¸­å…·æœ‰æœ€é«˜çš„æ¿€æ´»åº¦ã€‚è¿™æ„å‘³ç€ Î´A = 0ï¼Œå› ä¸ºç¥ç»å…ƒ A åœ¨å®ƒæ‰€è¿æ¥çš„å­é‡‡æ ·ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ä¸­æ²¡æœ‰æœ€å¤§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean is defined as follows:",
            "zh": "è°æ³¢å‡å€¼å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Because the same process is used to calculate âˆ‚ak/âˆ‚zk for all neurons we describe this process first, and then we describe how the âˆ‚â„°/âˆ‚ak term is calculated for output neurons and then for hidden neurons.",
            "zh": "ç”±äºä½¿ç”¨ç›¸åŒçš„è¿‡ç¨‹æ¥è®¡ç®—æ‰€æœ‰ç¥ç»å…ƒçš„ âˆ‚ak/âˆ‚zkï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆæè¿°æ­¤è¿‡ç¨‹ï¼Œç„¶åæè¿°å¦‚ä½•è®¡ç®—è¾“å‡ºç¥ç»å…ƒçš„ âˆ‚E/âˆ‚ak é¡¹ï¼Œç„¶åè®¡ç®—éšè—ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for a weighted sum calculation over two inputs we require two predefined weights.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºä¸¤ä¸ªè¾“å…¥çš„åŠ æƒå’Œè®¡ç®—ï¼Œæˆ‘ä»¬éœ€è¦ä¸¤ä¸ªé¢„å®šä¹‰çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.69)[467] is a restatement of Equation (8.13)[408], which provides the general definition of the Î´ for a neuron k as the partial derivative for the error (or loss) of the network with respect to the weighted sum of neuron k: âˆ‚â„°/âˆ‚zk.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.69ï¼‰[467]æ˜¯æ–¹ç¨‹ï¼ˆ8.13ï¼‰[408]çš„é‡è¿°ï¼Œå®ƒæä¾›äº†ç¥ç»å…ƒkçš„Î´çš„ä¸€èˆ¬å®šä¹‰ï¼Œå³ç½‘ç»œç›¸å¯¹äºç¥ç»å…ƒkåŠ æƒå’Œçš„è¯¯å·®ï¼ˆæˆ–æŸå¤±ï¼‰çš„åå¯¼æ•°ï¼šâˆ‚E/âˆ‚zkã€‚"
        }
    },
    {
        "translation": {
            "en": "data manipulation, 42",
            "zh": "æ•°æ®æ“ä½œï¼Œ42"
        }
    },
    {
        "translation": {
            "en": "An agentâ€™s current state is often modeled as a random variable, St. We therefore often describe the probability that an agent is in a specific state, s, at time t as P(St = s).",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬ç»å¸¸å°†æ™ºèƒ½ä½“åœ¨æ—¶é—´ t å¤„äºç‰¹å®šçŠ¶æ€ s çš„æ¦‚ç‡æè¿°ä¸º Pï¼ˆSt = sï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For a longer two-semester machine learning course (â€œM.L.",
            "zh": "å¯¹äºæ›´é•¿çš„ä¸¤å­¦æœŸæœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼ˆâ€œM.L."
        }
    },
    {
        "translation": {
            "en": "8.7â€…â€…â€…A single-layer network.",
            "zh": "8.7 å•å±‚ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "There are also extensions to handle categorical descriptive features (similar to the approach described in Section 7.4.3[336]) and continuous target features.",
            "zh": "è¿˜æœ‰ä¸€äº›æ‰©å±•ç”¨äºå¤„ç†åˆ†ç±»æè¿°æ€§ç‰¹å¾ï¼ˆç±»ä¼¼äºç¬¬ 7.4.3 èŠ‚[336] ä¸­æè¿°çš„æ–¹æ³•ï¼‰å’Œè¿ç»­ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically, the level that is of most interest is referred to as the positive level.",
            "zh": "é€šå¸¸ï¼Œæœ€æ„Ÿå…´è¶£çš„æ°´å¹³ç§°ä¸ºæ­£æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The revised domain concepts diagram for the galaxy classification task.",
            "zh": "æ˜Ÿç³»åˆ†ç±»ä»»åŠ¡çš„ä¿®è®¢åŸŸæ¦‚å¿µå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.13(b)[623] shows the tree cut for three clusters and the resultant clustering, and Figure 10.13(c)[623] shows the same illustrations for six clusters.",
            "zh": "å›¾10.13ï¼ˆbï¼‰[623]æ˜¾ç¤ºäº†ä¸‰ä¸ªèšç±»çš„ç ä¼å’Œç”±æ­¤äº§ç”Ÿçš„èšç±»ï¼Œå›¾10.13ï¼ˆcï¼‰[623]æ˜¾ç¤ºäº†å…­ä¸ªèšç±»çš„ç›¸åŒå›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "In Section 7.2.3[317] we said that the best-fit set of weights for a linear regression model can be found at the global minimum of the error surface defined by the weight space associated with the relevant training dataset.",
            "zh": "åœ¨ç¬¬ 7.2.3 èŠ‚[317]ä¸­ï¼Œæˆ‘ä»¬è¯´è¿‡ï¼Œçº¿æ€§å›å½’æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆæƒé‡é›†å¯ä»¥åœ¨è¯¯å·®é¢çš„å…¨å±€æœ€å°å€¼å¤„æ‰¾åˆ°ï¼Œè¯¥è¯¯å·®é¢ç”±ä¸ç›¸å…³è®­ç»ƒæ•°æ®é›†å…³è”çš„æƒé‡ç©ºé—´å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use the median value as the splitting threshold because it is less susceptible to the influence of outliers than the mean, and this helps keep the tree as balanced as possibleâ€”having a balanced tree helps with the efficiency in retrieval.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ä¸­å€¼ä½œä¸ºæ‹†åˆ†é˜ˆå€¼ï¼Œå› ä¸ºå®ƒæ¯”å‡å€¼æ›´ä¸å®¹æ˜“å—åˆ°å¼‚å¸¸å€¼çš„å½±å“ï¼Œè¿™æœ‰åŠ©äºå°½å¯èƒ½ä¿æŒæ ‘çš„å¹³è¡¡â€”â€”æ‹¥æœ‰å¹³è¡¡çš„æ ‘æœ‰åŠ©äºæé«˜æ£€ç´¢æ•ˆç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.6",
            "zh": "å›¾ 13.6"
        }
    },
    {
        "translation": {
            "en": "irregular cardinality, 63, 65, 94",
            "zh": "ä¸è§„åˆ™åŸºæ•°ï¼Œ63,65,94"
        }
    },
    {
        "translation": {
            "en": "This threshold is nothing more than a number that is selected by the designer of the artificial neuron.",
            "zh": "è¿™ä¸ªé˜ˆå€¼åªä¸è¿‡æ˜¯äººå·¥ç¥ç»å…ƒè®¾è®¡è€…é€‰æ‹©çš„ä¸€ä¸ªæ•°å­—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.8",
            "zh": "å›¾ 7.8"
        }
    },
    {
        "translation": {
            "en": "We can insert these probabilities into the application of Bayesâ€™ Theorem to give",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ¦‚ç‡ä»£å…¥è´å¶æ–¯å®šç†çš„åº”ç”¨ä¸­ï¼Œä»¥ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "The calculations in the input gate are defined by the following equations:",
            "zh": "è¾“å…¥é—¨ä¸­çš„è®¡ç®—ç”±ä»¥ä¸‹å…¬å¼å®šä¹‰ï¼š"
        }
    },
    {
        "translation": {
            "en": "Table 5.1",
            "zh": "è¡¨ 5.1"
        }
    },
    {
        "translation": {
            "en": "8.7â€…â€…â€…Exercises",
            "zh": "8.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "The values above zero seem to follow something close to a wide normal distribution, and the large number of, albeit valid, zero values account for the unusual minimum, 1st quartile, and median values.",
            "zh": "é«˜äºé›¶çš„å€¼ä¼¼ä¹éµå¾ªæ¥è¿‘å®½æ­£æ€åˆ†å¸ƒçš„ä¸œè¥¿ï¼Œå¹¶ä¸”å¤§é‡ï¼ˆå°½ç®¡æœ‰æ•ˆï¼‰é›¶å€¼è§£é‡Šäº†ä¸å¯»å¸¸çš„æœ€å°å€¼ã€ç¬¬ä¸€ä¸ªå››åˆ†ä½æ•°å’Œä¸­ä½æ•°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The optimal decision boundary and associated support vectors for the example we have been following are shown in Figure 7.23(b)[364].",
            "zh": "å›¾7.23ï¼ˆbï¼‰[364]æ˜¾ç¤ºäº†æˆ‘ä»¬æ‰€éµå¾ªçš„ç¤ºä¾‹çš„æœ€ä½³å†³ç­–è¾¹ç•Œå’Œç›¸å…³æ”¯æŒå‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "astronomy, 703",
            "zh": "å¤©æ–‡å­¦ï¼Œ703"
        }
    },
    {
        "translation": {
            "en": "The fact that the SDSS and Galaxy Zoo make all their data available for free online is a massive contribution to global science.",
            "zh": "äº‹å®ä¸Šï¼ŒSDSSå’Œé“¶æ²³åŠ¨ç‰©å›­å…è´¹åœ¨çº¿æä¾›æ‰€æœ‰æ•°æ®ï¼Œè¿™æ˜¯å¯¹å…¨çƒç§‘å­¦çš„å·¨å¤§è´¡çŒ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4[16] also illustrates the flow between each of these phases and emphasizes that data is at the heart of the process.",
            "zh": "å›¾ 1.4[16] è¿˜è¯´æ˜äº†æ¯ä¸ªé˜¶æ®µä¹‹é—´çš„æµç¨‹ï¼Œå¹¶å¼ºè°ƒæ•°æ®æ˜¯è¯¥è¿‡ç¨‹çš„æ ¸å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for the drug dosage prediction problem, the root mean squared error value is 1.380 for the regression model and 2.096 for the nearest neighbor model.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºè¯ç‰©å‰‚é‡é¢„æµ‹é—®é¢˜ï¼Œå›å½’æ¨¡å‹çš„å‡æ–¹æ ¹è¯¯å·®å€¼ä¸º 1.380ï¼Œæœ€è¿‘é‚»æ¨¡å‹çš„å‡æ–¹æ ¹è¯¯å·®å€¼ä¸º 2.096ã€‚"
        }
    },
    {
        "translation": {
            "en": "Third, the algorithm chooses which node it should move to next: the parent of the node or a node in the subtree under the other branch of the node (Lines 8, 9, 10, and 11).",
            "zh": "ç¬¬ä¸‰ï¼Œç®—æ³•é€‰æ‹©æ¥ä¸‹æ¥åº”è¯¥ç§»åŠ¨åˆ°å“ªä¸ªèŠ‚ç‚¹ï¼šèŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹æˆ–èŠ‚ç‚¹å¦ä¸€ä¸ªåˆ†æ”¯ä¸‹çš„å­æ ‘ä¸­çš„èŠ‚ç‚¹ï¼ˆç¬¬ 8ã€9ã€10 å’Œ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.14â€…â€…â€…A series of charts for different model performance on the same large email classification test set used to generate the ROC curves in Figure 9.12(b)[562]. Each column from top to bottom: a histogram of the ham scores predicted by the model, a histogram of the spam scores predicted by the model, and the K-S chart.",
            "zh": "9.14 åœ¨å›¾9.12ï¼ˆbï¼‰ä¸­ç”¨äºç”ŸæˆROCæ›²çº¿çš„åŒä¸€å¤§å‹ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†ä¸Šä¸åŒæ¨¡å‹æ€§èƒ½çš„ä¸€ç³»åˆ—å›¾è¡¨[562]ã€‚æ¯åˆ—ä»ä¸Šåˆ°ä¸‹ï¼šæ¨¡å‹é¢„æµ‹çš„ç«è…¿åˆ†æ•°çš„ç›´æ–¹å›¾ã€æ¨¡å‹é¢„æµ‹çš„åƒåœ¾é‚®ä»¶åˆ†æ•°çš„ç›´æ–¹å›¾ä»¥åŠ K-S æ§åˆ¶å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The definition of these neighborhoods is based on similarity within the feature space to the labeled training instances.",
            "zh": "è¿™äº›é‚»åŸŸçš„å®šä¹‰åŸºäºç‰¹å¾ç©ºé—´å†…ä¸æ ‡è®°çš„è®­ç»ƒå®ä¾‹çš„ç›¸ä¼¼æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use a k nearest neighbor model to predict the likely sale price of a bottle of whiskey based on the prices achieved by similar bottles at previous auctions.16 Table 5.8[209] lists a dataset of whiskeys described by the RATING they were given in a popular whiskey enthusiasts magazine and their AGE (in years).",
            "zh": "16 è¡¨ 5.8[209] åˆ—å‡ºäº†ä¸€ä¸ªå¨å£«å¿Œæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”±æµè¡Œçš„å¨å£«å¿Œçˆ±å¥½è€…æ‚å¿—ç»™å‡ºçš„ RATING åŠå…¶ AGEï¼ˆä»¥å¹´ä¸ºå•ä½ï¼‰æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A vector is an ordered list, so the mechanism for matching a probability in the vector with a particular value in the domain is just to look up the position of the probability within the vector.",
            "zh": "å‘é‡æ˜¯ä¸€ä¸ªæœ‰åºåˆ—è¡¨ï¼Œå› æ­¤å°†å‘é‡ä¸­çš„æ¦‚ç‡ä¸åŸŸä¸­çš„ç‰¹å®šå€¼ç›¸åŒ¹é…çš„æœºåˆ¶åªæ˜¯æŸ¥æ‰¾å‘é‡ä¸­æ¦‚ç‡çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The output of the action-value function is referred to as the expected return of pursuing action at in state st. We will see that the action-value function formulation of expected return is the more useful of these two.",
            "zh": "åŠ¨ä½œå€¼å‡½æ•°çš„è¾“å‡ºç§°ä¸ºåœ¨çŠ¶æ€ st å¤„è¿½æ±‚åŠ¨ä½œçš„é¢„æœŸå›æŠ¥ã€‚æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œé¢„æœŸå›æŠ¥çš„è¡ŒåŠ¨-ä»·å€¼å‡½æ•°å…¬å¼æ˜¯è¿™ä¸¤è€…ä¸­æ›´æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "DIA. B.P.: The patientâ€™s diastolic blood pressure",
            "zh": "DIA. B.P.ï¼šæ‚£è€…çš„èˆ’å¼ å‹"
        }
    },
    {
        "translation": {
            "en": "For example, W(k) is the weight matrix for the neurons in layer k. In an LSTM network we treat the neurons in the sigmoid and tanh layers within each gate as a separate layer of neurons, and so we write W(f) for the weight matrix for the neurons in the forget gate, and so on for the weight matrices of the other neuron layers in the other gates.",
            "zh": "ä¾‹å¦‚ï¼ŒWï¼ˆkï¼‰ æ˜¯ç¬¬ k å±‚ç¥ç»å…ƒçš„æƒé‡çŸ©é˜µã€‚åœ¨ LSTM ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªé—¨å†… sigmoid å’Œ tanh å±‚ä¸­çš„ç¥ç»å…ƒè§†ä¸ºå•ç‹¬çš„ç¥ç»å…ƒå±‚ï¼Œå› æ­¤æˆ‘ä»¬ä¸ºé—å¿˜é—¨ä¸­ç¥ç»å…ƒçš„æƒé‡çŸ©é˜µç¼–å†™ Wï¼ˆfï¼‰ï¼Œä¸ºå…¶ä»–é—¨ä¸­å…¶ä»–ç¥ç»å…ƒå±‚çš„æƒé‡çŸ©é˜µç¼–å†™ Wï¼ˆfï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "k = â‹†), then adjusting logit k changes both the numerator and the denominator in the softmax for the calculation of , whereas in the case that the logit with respect to which we are taking the derivative is for a neuron corresponding to another category, changing the logit changes only the denominator of the softmax.",
            "zh": "k = â‹†ï¼‰ï¼Œåˆ™è°ƒæ•´ logit k ä¼šåŒæ—¶æ”¹å˜ softmax ä¸­çš„åˆ†å­å’Œåˆ†æ¯ï¼Œä»¥ä¾¿è®¡ç®— ï¼Œè€Œå¦‚æœæˆ‘ä»¬å–å¯¼æ•°çš„ logit æ˜¯é’ˆå¯¹å¯¹åº”äºå¦ä¸€ä¸ªç±»åˆ«çš„ç¥ç»å…ƒï¼Œåˆ™æ›´æ”¹ logit ä»…æ›´æ”¹ softmax çš„åˆ†æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, whether we compute the likelihood term for this example using the chain rule or directly from the dataset, we will end up with a probability of zero, or worse, an undefined probability. This is because there are no instances in the dataset where a patient who had meningitis was suffering from a headache and had a fever but wasnâ€™t vomiting. Consequently, the probability for the MENINGITIS feature being true given the evidence in the query using this dataset was zero.",
            "zh": "æ€»ä¹‹ï¼Œæ— è®ºæˆ‘ä»¬æ˜¯ä½¿ç”¨é“¾å¼æ³•åˆ™è¿˜æ˜¯ç›´æ¥ä»æ•°æ®é›†è®¡ç®—æ­¤ç¤ºä¾‹çš„ä¼¼ç„¶é¡¹ï¼Œæˆ‘ä»¬æœ€ç»ˆéƒ½ä¼šå¾—åˆ°é›¶çš„æ¦‚ç‡ï¼Œæˆ–è€…æ›´ç³Ÿçš„æ˜¯ï¼Œä¸€ä¸ªæœªå®šä¹‰çš„æ¦‚ç‡ã€‚è¿™æ˜¯å› ä¸ºæ•°æ®é›†ä¸­æ²¡æœ‰è„‘è†œç‚æ‚£è€…å¤´ç—›ã€å‘çƒ§ä½†æ²¡æœ‰å‘•åçš„å®ä¾‹ã€‚å› æ­¤ï¼Œé‰´äºä½¿ç”¨æ­¤æ•°æ®é›†çš„æŸ¥è¯¢ä¸­çš„è¯æ®ï¼Œè„‘è†œç‚ç‰¹å¾ä¸ºçœŸçš„æ¦‚ç‡ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "decision boundary, 189, 338, 359, 396, 736",
            "zh": "å†³ç­–è¾¹ç•Œï¼Œ189ã€338ã€359ã€396ã€736"
        }
    },
    {
        "translation": {
            "en": "Although this example is just two dimensional, the k-d tree algorithm can work in a many dimensional feature space, so we will use the term target hypersphere12 to denote the region around the query that is inside the best-distance.",
            "zh": "å°½ç®¡æ­¤ç¤ºä¾‹åªæ˜¯äºŒç»´çš„ï¼Œä½† k-d æ ‘ç®—æ³•å¯ä»¥åœ¨å¤šç»´ç‰¹å¾ç©ºé—´ä¸­å·¥ä½œï¼Œå› æ­¤æˆ‘ä»¬å°†ä½¿ç”¨æœ¯è¯­ target hypersphere12 æ¥è¡¨ç¤ºæŸ¥è¯¢å‘¨å›´ä½äºæœ€ä½³è·ç¦»å†…çš„åŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "where P(t = i) is the probability that the outcome of randomly selecting an element t is the type i; l is the number of different types of things in the set; and s is an arbitrary logarithmic base.",
            "zh": "å…¶ä¸­ Pï¼ˆt = iï¼‰ æ˜¯éšæœºé€‰æ‹©å…ƒç´  t çš„ç»“æœä¸ºç±»å‹ i çš„æ¦‚ç‡;l æ˜¯é›†åˆä¸­ä¸åŒç±»å‹äº‹ç‰©çš„æ•°é‡;s æ˜¯ä»»æ„å¯¹æ•°åŸºæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is one neuron in an output softmax layer per target feature level, and so the softmax function returns one probability per level.",
            "zh": "æ¯ä¸ªç›®æ ‡ç‰¹å¾çº§åˆ«åœ¨è¾“å‡º softmax å±‚ä¸­æœ‰ä¸€ä¸ªç¥ç»å…ƒï¼Œå› æ­¤ softmax å‡½æ•°ä¸ºæ¯ä¸ªçº§åˆ«è¿”å›ä¸€ä¸ªæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The actual values in a profit matrix are determined through domain expertise.",
            "zh": "åˆ©æ¶¦çŸ©é˜µä¸­çš„å®é™…å€¼æ˜¯é€šè¿‡é¢†åŸŸä¸“ä¸šçŸ¥è¯†ç¡®å®šçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.5â€…â€…â€…Summary",
            "zh": "10.5 æ€»ç»“"
        }
    },
    {
        "translation": {
            "en": "linear algebra, xvi, 771",
            "zh": "çº¿æ€§ä»£æ•°ï¼Œåå…­ï¼Œ771"
        }
    },
    {
        "translation": {
            "en": "The fundamental reason to add layers to a network is to increase the representational capacity of the network.",
            "zh": "å‘ç½‘ç»œæ·»åŠ å±‚çš„æ ¹æœ¬åŸå› æ˜¯å¢åŠ ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "It may be somewhat surprising, but although the XOR function is very simple, a perceptron cannot represent it because it is not linearly separable.",
            "zh": "è¿™å¯èƒ½æœ‰ç‚¹ä»¤äººæƒŠè®¶ï¼Œä½†å°½ç®¡ XOR å‡½æ•°éå¸¸ç®€å•ï¼Œä½†æ„ŸçŸ¥å™¨æ— æ³•è¡¨ç¤ºå®ƒï¼Œå› ä¸ºå®ƒä¸æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the beginning of the boosting process the sampling distribution is initialized so that each instance has an equal weight of (represented by the equal segments for each instance in the visualization in Figure 4.21(b)[163]).",
            "zh": "åœ¨æå‡è¿‡ç¨‹å¼€å§‹æ—¶ï¼Œå¯¹é‡‡æ ·åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–ï¼Œä»¥ä¾¿æ¯ä¸ªå®ä¾‹å…·æœ‰ç›¸ç­‰çš„æƒé‡ï¼ˆç”±å›¾4.21ï¼ˆbï¼‰[163]ä¸­å¯è§†åŒ–ä¸­æ¯ä¸ªå®ä¾‹çš„ç›¸ç­‰æ®µè¡¨ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some of the machine learning approaches we have discussed in the preceding chapters perform better when a balanced sample is used to train them, and this is why Ross created an ABT with equal numbers of instances with each target level.5",
            "zh": "æˆ‘ä»¬åœ¨å‰å‡ ç« ä¸­è®¨è®ºè¿‡çš„ä¸€äº›æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨ä½¿ç”¨å¹³è¡¡æ ·æœ¬è¿›è¡Œè®­ç»ƒæ—¶è¡¨ç°æ›´å¥½ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆ Ross åˆ›å»ºäº†ä¸€ä¸ª ABTï¼Œæ¯ä¸ªç›®æ ‡çº§åˆ«éƒ½æœ‰ç›¸åŒæ•°é‡çš„å®ä¾‹5ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´s for the other neurons in the first layer will either be 0 (if they, like Neuron A, did not produce the maximum value in the local receptive field of the sub-sampling neuron to which they connect) or can be calculated in a similar way to Neuron B. Once the Î´ for each of the neurons in this layer has been calculated, the weight updates for each weight in the filter can be calculated by summing weight updates across the neuron in the layer, per Equation (8.89)[483].",
            "zh": "ç¬¬ä¸€å±‚ä¸­å…¶ä»–ç¥ç»å…ƒçš„ Î´ è¦ä¹ˆä¸º 0ï¼ˆå¦‚æœå®ƒä»¬ä¸ç¥ç»å…ƒ A ä¸€æ ·ï¼Œåœ¨å®ƒä»¬æ‰€è¿æ¥çš„å­é‡‡æ ·ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ä¸­æ²¡æœ‰äº§ç”Ÿæœ€å¤§å€¼ï¼‰ï¼Œè¦ä¹ˆå¯ä»¥é‡‡ç”¨ä¸ç¥ç»å…ƒ B ç±»ä¼¼çš„æ–¹å¼è®¡ç®—ã€‚ä¸€æ—¦è®¡ç®—äº†è¯¥å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ï¼Œå°±å¯ä»¥æ ¹æ®å…¬å¼ï¼ˆ8.89ï¼‰[483]ï¼Œé€šè¿‡å¯¹è¯¥å±‚ä¸­ç¥ç»å…ƒçš„æƒé‡æ›´æ–°æ±‚å’Œæ¥è®¡ç®—è¿‡æ»¤å™¨ä¸­æ¯ä¸ªæƒé‡çš„æƒé‡æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "An experiment whose outcome has been already been recorded is a row in the dataset. Each row in Table B.1[757] records the outcome of a previous experiment.",
            "zh": "å·²è®°å½•ç»“æœçš„å®éªŒæ˜¯æ•°æ®é›†ä¸­çš„ä¸€è¡Œã€‚è¡¨B.1[757]ä¸­çš„æ¯ä¸€è¡Œéƒ½è®°å½•äº†å…ˆå‰å®éªŒçš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "We say that temporal-difference learning is tabular because an action-value table is used to store estimates of the expected return from taking each available action, at, in each possible state, stâ€”the value of QÏ€(st,at).",
            "zh": "æˆ‘ä»¬è¯´æ—¶é—´å·®åˆ†å­¦ä¹ æ˜¯è¡¨æ ¼å¼çš„ï¼Œå› ä¸ºæ“ä½œå€¼è¡¨ç”¨äºå­˜å‚¨å¯¹é‡‡å–æ¯ä¸ªå¯ç”¨æ“ä½œçš„é¢„æœŸå›æŠ¥çš„ä¼°è®¡å€¼ï¼Œåœ¨æ¯ç§å¯èƒ½çš„çŠ¶æ€ä¸‹ï¼Œstâ€”â€”QÏ€ï¼ˆstï¼Œatï¼‰çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "A final advantage of the naive Bayes model is how simple it is to train.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æœ€åä¸€ä¸ªä¼˜ç‚¹æ˜¯è®­ç»ƒéå¸¸ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are an obvious example of a non-parametric model.",
            "zh": "æœ€è¿‘é‚»æ¨¡å‹æ˜¯éå‚æ•°æ¨¡å‹çš„ä¸€ä¸ªæ˜æ˜¾ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This contrasts with eager learners, such as the information-based (Chapter 4[117]), probability-based (Chapter 6[243]), and error-based (Chapter 7[311]) approaches to machine learning described in other chapters in this book.",
            "zh": "è¿™ä¸çƒ­åˆ‡çš„å­¦ä¹ è€…å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œä¾‹å¦‚æœ¬ä¹¦å…¶ä»–ç« èŠ‚ä¸­æè¿°çš„åŸºäºä¿¡æ¯ï¼ˆç¬¬ 4 ç« [117]ï¼‰ã€åŸºäºæ¦‚ç‡ï¼ˆç¬¬ 6 ç« [243]ï¼‰å’ŒåŸºäºé”™è¯¯ï¼ˆç¬¬ 7 ç« [311]ï¼‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature selection excludes redundant and irrelevant features from the induction process and by doing so alleviates the curse of dimensionality.",
            "zh": "ç‰¹å¾é€‰æ‹©ä»å½’çº³è¿‡ç¨‹ä¸­æ’é™¤äº†å†—ä½™å’Œä¸ç›¸å…³çš„ç‰¹å¾ï¼Œä»è€Œå‡è½»äº†ç»´åº¦çš„è¯…å’’ã€‚"
        }
    },
    {
        "translation": {
            "en": "To construct a k-d tree, we first pick a feature and split the data into two partitions using the median value of this feature.10 We then recursively split each of the two new partitions, stopping the recursion when there are fewer than two instances in a partition.",
            "zh": "ä¸ºäº†æ„é€ ä¸€ä¸ªk-dæ ‘ï¼Œæˆ‘ä»¬é¦–å…ˆé€‰æ‹©ä¸€ä¸ªç‰¹å¾ï¼Œå¹¶ä½¿ç”¨è¿™ä¸ªç‰¹å¾çš„ä¸­å€¼å°†æ•°æ®æ‹†åˆ†ä¸ºä¸¤ä¸ªåˆ†åŒº.10ç„¶åï¼Œæˆ‘ä»¬é€’å½’åœ°æ‹†åˆ†ä¸¤ä¸ªæ–°åˆ†åŒºä¸­çš„æ¯ä¸€ä¸ªï¼Œå½“ä¸€ä¸ªåˆ†åŒºä¸­çš„å®ä¾‹å°‘äºä¸¤ä¸ªæ—¶åœæ­¢é€’å½’ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. Also known as the loss function or cost function.",
            "zh": "9.ä¹Ÿç§°ä¸ºæŸå¤±å‡½æ•°æˆ–æˆæœ¬å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.7â€…â€…â€…Smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature conditioned on FRAUD = false.",
            "zh": "6.7 å¹³æ»‘ä»¥ FRAUD = false ä¸ºæ¡ä»¶çš„ GUARANTOR/COAPPLICANT ç‰¹å¾çš„åéªŒæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. It is important to remember for this discussion that all the data from which we construct an ABT for training and evaluating a model will be historical data.",
            "zh": "3. åœ¨æœ¬æ¬¡è®¨è®ºä¸­ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œæˆ‘ä»¬æ„å»ºç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹çš„ ABT çš„æ‰€æœ‰æ•°æ®éƒ½å°†æ˜¯å†å²æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "MNIST, 477",
            "zh": "MNISTï¼Œ477"
        }
    },
    {
        "translation": {
            "en": "However, for ease of explanation in this section, we have simply used a threshold of SSE < 0.0001 as our convergence criterion.",
            "zh": "ä½†æ˜¯ï¼Œä¸ºäº†ä¾¿äºè§£é‡Šï¼Œæˆ‘ä»¬ç®€å•åœ°ä½¿ç”¨SSEé˜ˆå€¼<0.0001ä½œä¸ºæ”¶æ•›æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.3â€…â€…â€…(a) A plot of the mobile phone customer dataset given in Table 10.1[604]. (b)â€“(f) The progress of the k-means clustering algorithm, working on the simple customer segmentation dataset. The large symbols represent cluster centroids, and the smaller symbols represent cluster assignments.",
            "zh": "10.3 ï¼ˆaï¼‰ è¡¨10.1[604]ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†å›¾ã€‚ï¼ˆbï¼‰â€“ï¼ˆfï¼‰ k-meansèšç±»ç®—æ³•åœ¨ç®€å•å®¢æˆ·ç»†åˆ†æ•°æ®é›†ä¸Šçš„ç ”ç©¶è¿›å±•ã€‚å¤§ç¬¦å·è¡¨ç¤ºèšç±»è´¨å¿ƒï¼Œè¾ƒå°çš„ç¬¦å·è¡¨ç¤ºèšç±»åˆ†é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final output of the network is generated by a single ReLU that is fully connected to both Feature map 3 and Feature map 4.",
            "zh": "ç½‘ç»œçš„æœ€ç»ˆè¾“å‡ºç”±å®Œå…¨è¿æ¥åˆ°ç‰¹å¾å›¾ 3 å’Œç‰¹å¾å›¾ 4 çš„å•ä¸ª ReLU ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "It can be shown that the optimal threshold value must lie at one of the boundaries between adjacent instances with different target levels.",
            "zh": "å¯ä»¥çœ‹å‡ºï¼Œæœ€ä½³é˜ˆå€¼å¿…é¡»ä½äºå…·æœ‰ä¸åŒç›®æ ‡çº§åˆ«çš„ç›¸é‚»å®ä¾‹ä¹‹é—´çš„è¾¹ç•Œä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13[410] shows that the maximum value of the derivative of the logistic function is 0.25.",
            "zh": "å›¾ 8.13[410] æ˜¾ç¤ºé€»è¾‘å‡½æ•°å¯¼æ•°çš„æœ€å¤§å€¼ä¸º 0.25ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we first need to create a profit matrix that records these.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ªè®°å½•è¿™äº›çš„åˆ©æ¶¦çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.11",
            "zh": "å›¾ 8.11"
        }
    },
    {
        "translation": {
            "en": "co-presence, 212, 213",
            "zh": "å…±å­˜ï¼Œ 212ï¼Œ 213"
        }
    },
    {
        "translation": {
            "en": "As with filter size and stride length, the selection of whether to use padding or not is task dependent and is often based on trial and error.",
            "zh": "ä¸è¿‡æ»¤å™¨å¤§å°å’Œæ­¥å¹…é•¿åº¦ä¸€æ ·ï¼Œæ˜¯å¦ä½¿ç”¨å¡«å……çš„é€‰æ‹©å–å†³äºä»»åŠ¡ï¼Œå¹¶ä¸”é€šå¸¸åŸºäºåå¤è¯•éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Last, a strategy needed to be put in place to monitor the performance of the models over time so that any concept drift that might take place could be flagged. Jocelyn agreed with Ted to put in place an alert system using the stability index. This would raise an alert whenever the stability index went above 0.25 so that someone could consider retraining the model.",
            "zh": "æœ€åï¼Œéœ€è¦åˆ¶å®šä¸€ç§ç­–ç•¥æ¥ç›‘æ§æ¨¡å‹éšæ—¶é—´æ¨ç§»çš„æ€§èƒ½ï¼Œä»¥ä¾¿å¯ä»¥æ ‡è®°å¯èƒ½å‘ç”Ÿçš„ä»»ä½•æ¦‚å¿µæ¼‚ç§»ã€‚Jocelyn åŒæ„ Ted ä½¿ç”¨ç¨³å®šæ€§æŒ‡æ•°å»ºç«‹ä¸€ä¸ªè­¦æŠ¥ç³»ç»Ÿã€‚æ¯å½“ç¨³å®šæ€§æŒ‡æ•°é«˜äº 0.25 æ—¶ï¼Œéƒ½ä¼šå‘å‡ºè­¦æŠ¥ï¼Œä»¥ä¾¿æœ‰äººå¯ä»¥è€ƒè™‘é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Jocelyn took this first domain concept draft along to a meeting with Ted, the SDSS chief data architect, to discuss the data resources that would be available for model building.",
            "zh": "Jocelyn å¸¦ç€è¿™ä¸ªç¬¬ä¸€ä¸ªé¢†åŸŸæ¦‚å¿µè‰æ¡ˆä¸ SDSS é¦–å¸­æ•°æ®æ¶æ„å¸ˆ Ted ä¼šé¢ï¼Œè®¨è®ºå¯ç”¨äºæ¨¡å‹æ„å»ºçš„æ•°æ®èµ„æºã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate this we return to the spam dataset given in Table 4.2[121].",
            "zh": "ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å›åˆ°è¡¨4.2[121]ä¸­ç»™å‡ºçš„åƒåœ¾é‚®ä»¶æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Example scatter plots for pairs of features from the dataset in Table 3.7[73], showing (a) the strong positive covariance between HEIGHT and WEIGHT; (b) the strong negative covariance between SPONSORSHIP EARNINGS and AGE; and (c) the lack of strong covariance between HEIGHT and AGE.",
            "zh": "è¡¨3.7[73]ä¸­æ•°æ®é›†ä¸­ç‰¹å¾å¯¹çš„ç¤ºä¾‹æ•£ç‚¹å›¾ï¼Œæ˜¾ç¤ºï¼ˆaï¼‰èº«é«˜å’Œä½“é‡ä¹‹é—´çš„å¼ºæ­£åæ–¹å·®;ï¼ˆbï¼‰èµåŠ©æ”¶å…¥ä¸å¹´é¾„ä¹‹é—´çš„å¼ºè´Ÿåæ–¹å·®;ï¼ˆcï¼‰èº«é«˜å’Œå¹´é¾„ä¹‹é—´ç¼ºä¹å¼ºåæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.7â€…â€…â€…Predictive Data Analytics Tools",
            "zh": "1.7 é¢„æµ‹æ•°æ®åˆ†æå·¥å…·"
        }
    },
    {
        "translation": {
            "en": "Information can flow forward from one subsequence to the next by using the hidden state of the network at the end of processing one subsequence to initialize the activation buffer at the start of the next subsequence.",
            "zh": "é€šè¿‡åœ¨å¤„ç†ä¸€ä¸ªå­åºåˆ—ç»“æŸæ—¶ä½¿ç”¨ç½‘ç»œçš„éšè—çŠ¶æ€ï¼Œåœ¨ä¸‹ä¸€ä¸ªå­åºåˆ—çš„å¼€å¤´åˆå§‹åŒ–æ¿€æ´»ç¼“å†²åŒºï¼Œä¿¡æ¯å¯ä»¥ä»ä¸€ä¸ªå­åºåˆ—å‘å‰æµåŠ¨åˆ°ä¸‹ä¸€ä¸ªå­åºåˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 2.7[39] illustrates this scenario.",
            "zh": "å›¾ 2.7[39] è¯´æ˜äº†è¿™ç§æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the infinite number of possible combinations of values for the weights will result in a model that fits, to some extent, the relationship present in the training data between the descriptive features and the target feature.",
            "zh": "æƒé‡å€¼çš„æ— é™æ•°é‡çš„å¯èƒ½ç»„åˆä¸­çš„æ¯ä¸€ä¸ªéƒ½å°†äº§ç”Ÿä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨æŸç§ç¨‹åº¦ä¸Šæ‹Ÿåˆäº†æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.5",
            "zh": "è¡¨ 8.5"
        }
    },
    {
        "translation": {
            "en": "overlap metric, 240",
            "zh": "é‡å å…¬åˆ¶ï¼Œ240"
        }
    },
    {
        "translation": {
            "en": "The derivative we use to backpropagate a Î´ through the rectifierleaky function is",
            "zh": "æˆ‘ä»¬ç”¨æ¥é€šè¿‡æ•´æµå™¨æ³„æ¼å‡½æ•°åå‘ä¼ æ’­Î´çš„å¯¼æ•°æ˜¯"
        }
    },
    {
        "translation": {
            "en": "For example, a feature might record gender using 1 for female and 0 for male.",
            "zh": "ä¾‹å¦‚ï¼Œè¦ç´ å¯èƒ½ä½¿ç”¨ 1 è¡¨ç¤ºå¥³æ€§ï¼Œä½¿ç”¨ 0 è¡¨ç¤ºç”·æ€§æ¥è®°å½•æ€§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.1â€…â€…â€…Visualizations of the continuous and categorical features in the motor insurance claims fraud detection ABT in Table 3.2[56].",
            "zh": "3.1 è¡¨3.2[56]ä¸­æ±½è½¦ä¿é™©ç†èµ”æ¬ºè¯ˆæ£€æµ‹ABTä¸­è¿ç»­å’Œåˆ†ç±»ç‰¹å¾çš„å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because ROC curves are discrete and stepped in nature, finding their integrals is actually very easily done using the trapezoidal method.",
            "zh": "ç”±äº ROC æ›²çº¿æœ¬è´¨ä¸Šæ˜¯ç¦»æ•£çš„å’Œé˜¶è·ƒçš„ï¼Œå› æ­¤ä½¿ç”¨æ¢¯å½¢æ–¹æ³•å®é™…ä¸Šå¾ˆå®¹æ˜“æ‰¾åˆ°å®ƒä»¬çš„ç§¯åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "PETRORATIO_I",
            "zh": "PETRORATIO_I"
        }
    },
    {
        "translation": {
            "en": "Table 8.3",
            "zh": "è¡¨ 8.3"
        }
    },
    {
        "translation": {
            "en": "Vapnik, Vladimir. 2000. The nature of statistical learning theory. Springer.",
            "zh": "ç“¦æ™®å°¼å…‹ï¼Œå¼—æ‹‰åŸºç±³å°”ã€‚2000. ç»Ÿè®¡å­¦ä¹ ç†è®ºçš„æœ¬è´¨.æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.1â€…â€…â€…Big Idea",
            "zh": "10.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "where the training dataset is composed of n training instances (di,ti); ğ•„w(di) is the prediction made by a model ğ•„w for a training instance with descriptive features di; and the model ğ•„w is defined by the weight vector w.",
            "zh": "å…¶ä¸­ï¼Œè®­ç»ƒæ•°æ®é›†ç”± n ä¸ªè®­ç»ƒå®ä¾‹ ï¼ˆdiï¼Œtiï¼‰ ç»„æˆ;Mwï¼ˆdiï¼‰ æ˜¯æ¨¡å‹ Mw å¯¹å…·æœ‰æè¿°æ€§ç‰¹å¾ di çš„è®­ç»ƒå®ä¾‹æ‰€åšçš„é¢„æµ‹;æ¨¡å‹ Mw ç”±æƒé‡å‘é‡ w å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Berk, Richard A., and Justin Bleich. 2013. Statistical procedures for forecasting criminal behavior. Criminology & Public Policy 12 (3): 513â€“544.",
            "zh": "ä¼¯å…‹ã€ç†æŸ¥å¾· A. å’Œè´¾æ–¯æ±€Â·å¸ƒè±å¥‡ã€‚2013. é¢„æµ‹çŠ¯ç½ªè¡Œä¸ºçš„ç»Ÿè®¡ç¨‹åº.çŠ¯ç½ªå­¦ä¸å…¬å…±æ”¿ç­–12ï¼ˆ3ï¼‰ï¼š513-544ã€‚"
        }
    },
    {
        "translation": {
            "en": "P_DK",
            "zh": "P_DK"
        }
    },
    {
        "translation": {
            "en": "Moreover, if k is set to a value larger than 15, the majority target level dominates the entire feature space.",
            "zh": "æ­¤å¤–ï¼Œå¦‚æœå°† k è®¾ç½®ä¸ºå¤§äº 15 çš„å€¼ï¼Œåˆ™å¤šæ•°ç›®æ ‡çº§åˆ«å°†ä¸»å¯¼æ•´ä¸ªç‰¹å¾ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "These distance contours were calculated using the inverse covariance matrix for the dataset and point A as the origin.",
            "zh": "è¿™äº›è·ç¦»ç­‰å€¼çº¿æ˜¯ä½¿ç”¨æ•°æ®é›†çš„é€†åæ–¹å·®çŸ©é˜µè®¡ç®—çš„ï¼Œå¹¶ä»¥ A ç‚¹ä¸ºåŸç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For more recent advances at the junction of reinforcement learning and deep learning, Sejnowski (2018) gives a nice overview of some key application areas and recent developments, and again, Sutton and Barto (2018) provides a good overview.",
            "zh": "å¯¹äºå¼ºåŒ–å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ äº¤ç•Œå¤„çš„æœ€æ–°è¿›å±•ï¼ŒSejnowski ï¼ˆ2018ï¼‰ å¯¹ä¸€äº›å…³é”®åº”ç”¨é¢†åŸŸå’Œæœ€æ–°å‘å±•è¿›è¡Œäº†å¾ˆå¥½çš„æ¦‚è¿°ï¼ŒSutton å’Œ Barto ï¼ˆ2018ï¼‰ å†æ¬¡æä¾›äº†å¾ˆå¥½çš„æ¦‚è¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "cross-correlation, 485",
            "zh": "äº’ç›¸å…³ï¼Œ485"
        }
    },
    {
        "translation": {
            "en": "Using the data quality report in Table 3.3[57] and Figure 3.1[58] together with the ABT extract in Table 3.2[56], we can perform an analysis of this ABT for data quality issues. We do this by describing separately missing values, irregular cardinality, and outliers.",
            "zh": "ä½¿ç”¨è¡¨3.3[57]å’Œå›¾3.1[58]ä¸­çš„æ•°æ®è´¨é‡æŠ¥å‘Šä»¥åŠè¡¨3.2[56]ä¸­çš„ABTæå–ç‰©ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹è¯¥ABTçš„æ•°æ®è´¨é‡é—®é¢˜è¿›è¡Œåˆ†æã€‚æˆ‘ä»¬é€šè¿‡åˆ†åˆ«æè¿°ç¼ºå¤±å€¼ã€ä¸è§„åˆ™åŸºæ•°å’Œå¼‚å¸¸å€¼æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Technically, the inclusion of the bias parameter as an extra weight in this operation changes the function from a linear function on the inputs to an affine function.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œåœ¨æ­¤æ“ä½œä¸­åŒ…å«åç½®å‚æ•°ä½œä¸ºé¢å¤–æƒé‡ä¼šå°†å‡½æ•°ä»è¾“å…¥ä¸Šçš„çº¿æ€§å‡½æ•°æ›´æ”¹ä¸ºä»¿å°„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that w C,B = 1.",
            "zh": "è¯·æ³¨æ„ï¼Œw Cï¼ŒB = 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, support vector machines are an example of a non-parametric model that, to a large extent, avoids this problem.",
            "zh": "ç„¶è€Œï¼Œæ”¯æŒå‘é‡æœºæ˜¯éå‚æ•°æ¨¡å‹çš„ä¸€ä¸ªä¾‹å­ï¼Œå®ƒåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šé¿å…äº†è¿™ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "customer churn, 48",
            "zh": "å®¢æˆ·æµå¤±ç‡ï¼Œ48"
        }
    },
    {
        "translation": {
            "en": "3. Subtract the remaining entropy value (computed in step 2) from the original entropy value (computed in step 1) to give the information gain.",
            "zh": "3. ä»åŸå§‹ç†µå€¼ï¼ˆåœ¨æ­¥éª¤ 1 ä¸­è®¡ç®—ï¼‰ä¸­å‡å»å‰©ä½™çš„ç†µå€¼ï¼ˆåœ¨æ­¥éª¤ 2 ä¸­è®¡ç®—ï¼‰ä»¥ç»™å‡ºä¿¡æ¯å¢ç›Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Voronoi region, 189",
            "zh": "æ²ƒç½—è¯ºä¼Šåœ°åŒºï¼Œ189"
        }
    },
    {
        "translation": {
            "en": "Bagging is simpler to implement and parallelize than boosting, so it may be better with respect to ease of use and training time.",
            "zh": "ä¸æå‡ç›¸æ¯”ï¼ŒBagging æ›´æ˜“äºå®ç°å’Œå¹¶è¡ŒåŒ–ï¼Œå› æ­¤åœ¨æ˜“ç”¨æ€§å’Œè®­ç»ƒæ—¶é—´æ–¹é¢å¯èƒ½æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, after every C steps the current action-value target network is replaced with a copy of the action-value behavior network.",
            "zh": "å› æ­¤ï¼Œåœ¨æ¯ä¸ª C æ­¥éª¤ä¹‹åï¼Œå½“å‰çš„åŠ¨ä½œå€¼ç›®æ ‡ç½‘ç»œå°†æ›¿æ¢ä¸ºåŠ¨ä½œå€¼è¡Œä¸ºç½‘ç»œçš„å‰¯æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. The correlation coefficient presented here is more fully known as the Pearson product-moment correlation coefficient or Pearsonâ€™s r and is named after Karl Pearson, one of the giants of statistics.",
            "zh": "7. è¿™é‡Œä»‹ç»çš„ç›¸å…³ç³»æ•°æ›´å…¨é¢åœ°ç§°ä¸ºçš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°æˆ–çš®å°”é€Šçš„ rï¼Œå¹¶ä»¥ç»Ÿè®¡å­¦å·¨äººä¹‹ä¸€å¡å°”Â·çš®å°”é€Šçš„åå­—å‘½åã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the symbol Î¸ to denote the threshold, the second stage of processing in the McCulloch and Pitts model can be defined",
            "zh": "ä½¿ç”¨ç¬¦å· Î¸ è¡¨ç¤ºé˜ˆå€¼ï¼Œå¯ä»¥å®šä¹‰ McCulloch å’Œ Pitts æ¨¡å‹ä¸­çš„ç¬¬äºŒé˜¶æ®µå¤„ç†"
        }
    },
    {
        "translation": {
            "en": "cumulative lift chart, 570",
            "zh": "ç´¯è®¡æå‡å›¾ï¼Œ570"
        }
    },
    {
        "translation": {
            "en": "Similarly, the bottom left cell in the matrix, labeled FP, shows the number of instances in a test set that have a negative target feature value that were in fact predicted by the model to have a positive target feature value.",
            "zh": "åŒæ ·ï¼ŒçŸ©é˜µä¸­æ ‡è®°ä¸º FP çš„å·¦ä¸‹è§’å•å…ƒæ ¼æ˜¾ç¤ºäº†æµ‹è¯•é›†ä¸­å…·æœ‰è´Ÿç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹æ•°ï¼Œè€Œæ¨¡å‹å®é™…ä¸Šé¢„æµ‹è¿™äº›å®ä¾‹å…·æœ‰æ­£ç›®æ ‡ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Describe the domain concepts for this ABT.",
            "zh": "ï¼ˆbï¼‰ æè¿°æœ¬ ABT çš„é¢†åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "We have already met the minimum description length principle in the more general form of Occamâ€™s razor.",
            "zh": "æˆ‘ä»¬å·²ç»æ»¡è¶³äº†å¥¥å¡å§†å‰ƒåˆ€æ›´ä¸€èˆ¬å½¢å¼çš„æœ€å°æè¿°é•¿åº¦åŸåˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Building on this idea, the early stopping algorithm uses the performance of the model on a validation dataset to determine when to stop training the model.",
            "zh": "åŸºäºè¿™ä¸ªæƒ³æ³•ï¼Œæ—©æœŸåœæ­¢ç®—æ³•ä½¿ç”¨æ¨¡å‹åœ¨éªŒè¯æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ¥ç¡®å®šä½•æ—¶åœæ­¢è®­ç»ƒæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.4â€ƒModeling",
            "zh": "12.4 å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "presence-absence (PA), how often a true value occurred in the query data q when a false value occurred in the data for the comparison user (d1 or d2) for the same feature",
            "zh": "presence-absence ï¼ˆPAï¼‰ï¼Œå½“åŒä¸€è¦ç´ çš„æ¯”è¾ƒç”¨æˆ·ï¼ˆd1 æˆ– d2ï¼‰çš„æ•°æ®ä¸­å‡ºç°å‡å€¼æ—¶ï¼ŒæŸ¥è¯¢æ•°æ® q ä¸­å‡ºç°çœŸå€¼çš„é¢‘ç‡"
        }
    },
    {
        "translation": {
            "en": "These two PDFs do not have to be defined using the same distribution.",
            "zh": "è¿™ä¸¤ä¸ª PDF ä¸å¿…ä½¿ç”¨ç›¸åŒçš„åˆ†å‘æ¥å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Opinions vary widely on when transformations like the clamp transformation should be used to handle outliers in data.",
            "zh": "å…³äºä½•æ—¶åº”ä½¿ç”¨é’³ä½å˜æ¢ç­‰å˜æ¢æ¥å¤„ç†æ•°æ®ä¸­çš„å¼‚å¸¸å€¼ï¼Œæ„è§åˆ†æ­§å¾ˆå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, direct comparison of the weights tells us little about their relative importance.",
            "zh": "å› æ­¤ï¼Œæƒé‡çš„ç›´æ¥æ¯”è¾ƒå‡ ä¹ä¸èƒ½å‘Šè¯‰æˆ‘ä»¬å®ƒä»¬çš„ç›¸å¯¹é‡è¦æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "For these reasons, Ross designed the following descriptive features:",
            "zh": "å‡ºäºè¿™äº›åŸå› ï¼ŒRoss è®¾è®¡äº†ä»¥ä¸‹æè¿°æ€§åŠŸèƒ½ï¼š"
        }
    },
    {
        "translation": {
            "en": "approximate methods, 668, 676",
            "zh": "è¿‘ä¼¼æ–¹æ³•ï¼Œ668,676"
        }
    },
    {
        "translation": {
            "en": "where s1 to sn are n different states. A Markov process can be fully characterized by the set of states, S, and the transition matrix, ğ’«.",
            "zh": "å…¶ä¸­ s1 åˆ° sn æ˜¯ n ä¸ªä¸åŒçš„çŠ¶æ€ã€‚é©¬å°”å¯å¤«è¿‡ç¨‹å¯ä»¥å®Œå…¨ç”±ä¸€ç»„çŠ¶æ€ S å’Œè·ƒè¿çŸ©é˜µ P æ¥è¡¨å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The height of each player is listed below the player, and the dashed gray line shows the arithmetic mean of the playersâ€™ heights, which is 149.375, the same as for the original team.",
            "zh": "æ¯ä¸ªçƒå‘˜çš„èº«é«˜éƒ½åˆ—åœ¨çƒå‘˜çš„ä¸‹æ–¹ï¼Œç°è‰²è™šçº¿æ˜¾ç¤ºçƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ï¼Œå³ 149.375ï¼Œä¸åŸå§‹çƒé˜Ÿç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "Using learning rate decay can even address the problem of inappropriately large error rates causing the sum of squared errors to increase rather than decrease.",
            "zh": "ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ç”šè‡³å¯ä»¥è§£å†³é”™è¯¯ç‡è¿‡å¤§å¯¼è‡´å¹³æ–¹è¯¯å·®æ€»å’Œå¢åŠ è€Œä¸æ˜¯å‡å°‘çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "A lecturer is about to leave for the airport to go on vacation when they find a script for a student they forgot to mark.",
            "zh": "ä¸€ä½è®²å¸ˆæ­£è¦å»æœºåœºåº¦å‡æ—¶ï¼Œä»–ä»¬å‘ç°äº†ä¸€ä¸ªä»–ä»¬å¿˜è®°æ‰¹æ”¹çš„å­¦ç”Ÿçš„å‰§æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ideally, each mini-batch should be created by random sampling from the dataset.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œæ¯ä¸ªå°æ‰¹é‡éƒ½åº”é€šè¿‡ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·æ¥åˆ›å»ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Inspired by these results, neural network research started to design networks in which neurons in one layer received input only from a localized subset of neurons in the preceding layer, that is, each neuron had a local receptive field in the preceding layer.",
            "zh": "å—è¿™äº›ç»“æœçš„å¯å‘ï¼Œç¥ç»ç½‘ç»œç ”ç©¶å¼€å§‹è®¾è®¡ç½‘ç»œï¼Œå…¶ä¸­ä¸€å±‚ä¸­çš„ç¥ç»å…ƒä»…æ¥æ”¶æ¥è‡ªå‰ä¸€å±‚ä¸­å±€éƒ¨ç¥ç»å…ƒå­é›†çš„è¾“å…¥ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªç¥ç»å…ƒåœ¨å‰ä¸€å±‚ä¸­éƒ½æœ‰ä¸€ä¸ªå±€éƒ¨æ„Ÿå—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This combination ensures that the output from a layer of neurons applying a filter across an image has the same dimensions as the input image.",
            "zh": "è¿™ç§ç»„åˆå¯ç¡®ä¿åœ¨å›¾åƒä¸Šåº”ç”¨æ»¤æ³¢å™¨çš„ç¥ç»å…ƒå±‚çš„è¾“å‡ºä¸è¾“å…¥å›¾åƒå…·æœ‰ç›¸åŒçš„å°ºå¯¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "where w[j] is any weight, Î± is a constant learning rate, ti is the expected target feature value for the ith training instance, ğ•„w(di) is the prediction made for this training instance by the current candidate model defined by the weight vector w, and di[j] is the jth descriptive feature of the ith training instance and corresponds with weight w[j] in the regression model.",
            "zh": "å…¶ä¸­ w[j] æ˜¯ä»»ä½•æƒé‡ï¼ŒÎ± æ˜¯æ’å®šçš„å­¦ä¹ ç‡ï¼Œti æ˜¯ç¬¬ i ä¸ªè®­ç»ƒå®ä¾‹çš„é¢„æœŸç›®æ ‡ç‰¹å¾å€¼ï¼ŒMwï¼ˆdiï¼‰ æ˜¯ç”±æƒé‡å‘é‡ w å®šä¹‰çš„å½“å‰å€™é€‰æ¨¡å‹å¯¹æ­¤è®­ç»ƒå®ä¾‹åšå‡ºçš„é¢„æµ‹ï¼Œdi[j] æ˜¯ç¬¬ i ä¸ªè®­ç»ƒå®ä¾‹çš„ç¬¬ j ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œä¸å›å½’æ¨¡å‹ä¸­çš„æƒé‡ w[j] ç›¸å¯¹åº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.2",
            "zh": "è¡¨ 6.2"
        }
    },
    {
        "translation": {
            "en": "These questions are relevant when building any prediction model, and the answer to each one introduces a specific bias. Often we are forced to answer these questions, and others like them, based on intuition, experience, and experimentation. This is what makes machine learning something of an art, rather than strictly a science. But it is also what makes machine learning such a fascinating and rewarding area in which to work.",
            "zh": "è¿™äº›é—®é¢˜åœ¨æ„å»ºä»»ä½•é¢„æµ‹æ¨¡å‹æ—¶éƒ½æ˜¯ç›¸å…³çš„ï¼Œæ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆéƒ½ä¼šå¼•å…¥ç‰¹å®šçš„åå·®ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬è¢«è¿«æ ¹æ®ç›´è§‰ã€ç»éªŒå’Œå®éªŒæ¥å›ç­”è¿™äº›é—®é¢˜ä»¥åŠå…¶ä»–ç±»ä¼¼çš„é—®é¢˜ã€‚è¿™å°±æ˜¯ä½¿æœºå™¨å­¦ä¹ æˆä¸ºä¸€é—¨è‰ºæœ¯çš„åŸå› ï¼Œè€Œä¸æ˜¯ä¸¥æ ¼æ„ä¹‰ä¸Šçš„ä¸€é—¨ç§‘å­¦ã€‚ä½†è¿™ä¹Ÿæ˜¯ä½¿æœºå™¨å­¦ä¹ æˆä¸ºä¸€ä¸ªå¦‚æ­¤è¿·äººå’Œæœ‰ç›Šçš„å·¥ä½œé¢†åŸŸçš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Member prediction] A model could be built to predict the propensity of a member1 to commit fraud in the near future. This model could be run every quarter to identify those members most likely to commit fraud, and the insurance company could take a risk-mitigation action ranging from contacting the member with some kind of warning to canceling the memberâ€™s policies. By identifying members likely to make fraudulent claims before they make them, the company could save significant amounts of money.",
            "zh": "[ä¼šå‘˜é¢„æµ‹]å¯ä»¥å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹æˆå‘˜1åœ¨ä¸ä¹…çš„å°†æ¥å®æ–½æ¬ºè¯ˆçš„å€¾å‘ã€‚è¯¥æ¨¡å‹å¯ä»¥æ¯å­£åº¦è¿è¡Œä¸€æ¬¡ï¼Œä»¥è¯†åˆ«æœ€æœ‰å¯èƒ½è¿›è¡Œæ¬ºè¯ˆçš„æˆå‘˜ï¼Œä¿é™©å…¬å¸å¯ä»¥é‡‡å–é£é™©ç¼“è§£æªæ–½ï¼Œä»è”ç³»æˆå‘˜å‘å‡ºæŸç§è­¦å‘Šåˆ°å–æ¶ˆæˆå‘˜çš„ä¿å•ã€‚é€šè¿‡åœ¨æˆå‘˜æå‡ºæ¬ºè¯ˆæ€§ç´¢èµ”ä¹‹å‰è¯†åˆ«ä»–ä»¬å¯èƒ½æå‡ºæ¬ºè¯ˆæ€§ç´¢èµ”ï¼Œè¯¥å…¬å¸å¯ä»¥èŠ‚çœå¤§é‡èµ„é‡‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Which pieces of the network infrastructure were likely to fail in the near future? Using information about network loads, network usage, and equipment diagnostics, a predictive model could be built to flag upcoming equipment failures so that pre-emptive action could be taken. Network outages are a driver of customer dissatisfaction and ultimately customer churn, so reducing these could have a positive impact on churn rates.",
            "zh": "åœ¨ä¸ä¹…çš„å°†æ¥ï¼Œå“ªäº›ç½‘ç»œåŸºç¡€è®¾æ–½å¯èƒ½ä¼šå‡ºç°æ•…éšœï¼Ÿä½¿ç”¨æœ‰å…³ç½‘ç»œè´Ÿè½½ã€ç½‘ç»œä½¿ç”¨æƒ…å†µå’Œè®¾å¤‡è¯Šæ–­çš„ä¿¡æ¯ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹æ¥æ ‡è®°å³å°†å‘ç”Ÿçš„è®¾å¤‡æ•…éšœï¼Œä»¥ä¾¿é‡‡å–å…ˆå‘åˆ¶äººçš„æªæ–½ã€‚ç½‘ç»œä¸­æ–­æ˜¯å®¢æˆ·ä¸æ»¡å¹¶æœ€ç»ˆå¯¼è‡´å®¢æˆ·æµå¤±çš„é©±åŠ¨å› ç´ ï¼Œå› æ­¤å‡å°‘è¿™äº›ä¸­æ–­å¯èƒ½ä¼šå¯¹å®¢æˆ·æµå¤±ç‡äº§ç”Ÿç§¯æå½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Section 9.4.6[578] and Chapters 12[685] and 13[703]",
            "zh": "ç¬¬9.4.6èŠ‚[578]ä»¥åŠç¬¬12ç« [685]å’Œç¬¬13ç« [703]"
        }
    },
    {
        "translation": {
            "en": "Although neuroscience has discovered a lot about the neural structure of the brain, neuroscientists are still working on understanding how learning happens in the brain and how high-level human behavior arises from the processing of neurons.",
            "zh": "å°½ç®¡ç¥ç»ç§‘å­¦å·²ç»å‘ç°äº†å¾ˆå¤šå…³äºå¤§è„‘ç¥ç»ç»“æ„çš„ä¿¡æ¯ï¼Œä½†ç¥ç»ç§‘å­¦å®¶ä»åœ¨åŠªåŠ›äº†è§£å­¦ä¹ æ˜¯å¦‚ä½•åœ¨å¤§è„‘ä¸­å‘ç”Ÿçš„ï¼Œä»¥åŠé«˜çº§äººç±»è¡Œä¸ºæ˜¯å¦‚ä½•ä»ç¥ç»å…ƒçš„å¤„ç†ä¸­äº§ç”Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the errors in these predictions, the delta contributions, labeled as errorDelta(,w[0]), errorDelta(,w[1]) and errorDelta(,w[2]) in Table 7.8[348], from each training instance are calculated according to Equation (7.31)[345].",
            "zh": "æ ¹æ®è¿™äº›é¢„æµ‹ä¸­çš„è¯¯å·®ï¼Œæ ¹æ®å…¬å¼ï¼ˆ7.31ï¼‰[345]è®¡ç®—æ¯ä¸ªè®­ç»ƒå®ä¾‹çš„å¢é‡è´¡çŒ®ï¼Œåœ¨è¡¨7.8[348]ä¸­æ ‡è®°ä¸ºerrorDeltaï¼ˆï¼Œw[0]ï¼‰ã€errorDeltaï¼ˆï¼Œw[1]ï¼‰å’ŒerrorDeltaï¼ˆï¼Œw[2]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In situations where we have a larger dataset, however, we could perform evaluation experiments17 to see which value of k leads to the best-performing model.",
            "zh": "ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬æœ‰æ›´å¤§æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œè¯„ä¼°å®éªŒ17ï¼Œçœ‹çœ‹kçš„å“ªä¸ªå€¼ä¼šå¯¼è‡´æ€§èƒ½æœ€å¥½çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A schematic of a feedforward artificial neural network.",
            "zh": "å‰é¦ˆäººå·¥ç¥ç»ç½‘ç»œç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "inverse reasoning, 248",
            "zh": "é€†æ¨ç†ï¼Œ248"
        }
    },
    {
        "translation": {
            "en": "One final point: remember that the empty partition in Figure 4.10[140] (ğ’Ÿ 18) has been converted into a leaf node that returns the chapparal target level. The reason is that chapparal is the majority target level in the partition at the parent node (ğ’Ÿ8) of this leaf node. Consequently, this tree will return a prediction of VEGETATION = chapparal for the following query:",
            "zh": "æœ€åä¸€ç‚¹ï¼šè¯·è®°ä½ï¼Œå›¾ 4.10[140] ï¼ˆD 18ï¼‰ ä¸­çš„ç©ºåˆ†åŒºå·²è½¬æ¢ä¸ºè¿”å› chapparal ç›®æ ‡çº§åˆ«çš„å¶èŠ‚ç‚¹ã€‚åŸå› æ˜¯ chapparal æ˜¯æ­¤å¶èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ ï¼ˆD8ï¼‰ åˆ†åŒºä¸­çš„å¤§å¤šæ•°ç›®æ ‡çº§åˆ«ã€‚å› æ­¤ï¼Œæ­¤æ ‘å°†è¿”å›ä»¥ä¸‹æŸ¥è¯¢çš„ VEGETATION = chapparal çš„é¢„æµ‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "encoder, 624",
            "zh": "ç¼–ç å™¨ï¼Œ624"
        }
    },
    {
        "translation": {
            "en": "on-line gradient descent, 415",
            "zh": "åœ¨çº¿æ¢¯åº¦ä¸‹é™ï¼Œ415"
        }
    },
    {
        "translation": {
            "en": "Furthermore, for each subsequent layer that the Î´s are backpropagated through, the variance will increase by a factor of 4, and it is this scaling that causes the exploding gradients evident in Figure 8.24(d)[454].",
            "zh": "æ­¤å¤–ï¼Œå¯¹äºÎ´såå‘ä¼ æ’­çš„æ¯ä¸ªåç»­å±‚ï¼Œæ–¹å·®å°†å¢åŠ 4å€ï¼Œæ­£æ˜¯è¿™ç§ç¼©æ”¾å¯¼è‡´äº†å›¾8.24ï¼ˆdï¼‰[454]ä¸­æ˜æ˜¾çš„çˆ†ç‚¸æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Even with modern computational power and with processing examples in parallel, this can take a long time and ultimately result in network training taking a long time.",
            "zh": "å³ä½¿ä½¿ç”¨ç°ä»£è®¡ç®—èƒ½åŠ›å¹¶è¡Œå¤„ç†ç¤ºä¾‹ï¼Œè¿™ä¹Ÿå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œå¹¶æœ€ç»ˆå¯¼è‡´ç½‘ç»œè®­ç»ƒéœ€è¦å¾ˆé•¿æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "local receptive field, 479",
            "zh": "å±€éƒ¨æ„Ÿå—é‡ï¼Œ479"
        }
    },
    {
        "translation": {
            "en": "In error-based machine learning, we perform a search for a set of parameters for a parameterized model that minimizes the total error across the predictions made by that model with respect to a set of training instances.",
            "zh": "åœ¨åŸºäºé”™è¯¯çš„æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä¸ºå‚æ•°åŒ–æ¨¡å‹æœç´¢ä¸€ç»„å‚æ•°ï¼Œä»¥æœ€å°åŒ–è¯¥æ¨¡å‹å¯¹ä¸€ç»„è®­ç»ƒå®ä¾‹æ‰€åšçš„é¢„æµ‹çš„æ€»è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, if the inverse covariance matrix is the identity matrix , then no scaling or rotation occurs.",
            "zh": "å› æ­¤ï¼Œå¦‚æœé€†åæ–¹å·®çŸ©é˜µæ˜¯å•ä½çŸ©é˜µï¼Œåˆ™ä¸ä¼šå‘ç”Ÿç¼©æ”¾æˆ–æ—‹è½¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.3â€…â€…â€…(a) A stacked bar plot for the REGIONTYPE feature; and (b) histograms for the AVGOVERBUNDLEMINS feature by target feature value.",
            "zh": "12.3 ï¼ˆaï¼‰ REGIONTYPE ç‰¹å¾çš„å †ç§¯æ¡å½¢å›¾;ä»¥åŠ ï¼ˆbï¼‰ æŒ‰ç›®æ ‡ç‰¹å¾å€¼åˆ’åˆ†çš„ AVGOVERBUNDLEMINS ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Larger values of p place more emphasis on large differences between feature values than smaller values of p because all differences are raised to the power of p. Consequently, the Euclidean distance (with p = 2) is more strongly influenced by a single large difference in one feature than the Manhattan distance (with p = 1).3",
            "zh": "è¾ƒå¤§çš„ p å€¼æ¯”è¾ƒå°çš„ p å€¼æ›´å¼ºè°ƒç‰¹å¾å€¼ä¹‹é—´çš„è¾ƒå¤§å·®å¼‚ï¼Œå› ä¸ºæ‰€æœ‰å·®å¼‚éƒ½æé«˜åˆ° p çš„å¹‚ã€‚å› æ­¤ï¼Œä¸æ›¼å“ˆé¡¿è·ç¦»ï¼ˆp = 1ï¼‰ç›¸æ¯”ï¼Œæ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆp = 2ï¼‰å—ä¸€ä¸ªç‰¹å¾çš„å•ä¸ªå¤§å·®å¼‚çš„å½±å“æ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term can be computed using metrics such as the Bayesian score or the K2 score.23 The search space for these algorithms is exponential in the number of features.",
            "zh": "å¯ä»¥ä½¿ç”¨è´å¶æ–¯åˆ†æ•°æˆ– K2 åˆ†æ•°ç­‰æŒ‡æ ‡æ¥è®¡ç®—è¯¥æœ¯è¯­ã€‚23 è¿™äº›ç®—æ³•çš„æœç´¢ç©ºé—´åœ¨ç‰¹å¾æ•°é‡ä¸Šå‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Entropy-based information gain, however, does have some drawbacks.",
            "zh": "ç„¶è€Œï¼ŒåŸºäºç†µçš„ä¿¡æ¯å¢ç›Šç¡®å®æœ‰ä¸€äº›ç¼ºç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "give the weight in the sampling distribution for each training instance, and the columns labeled Freq.",
            "zh": "ç»™å‡ºæ¯ä¸ªè®­ç»ƒå®ä¾‹çš„æŠ½æ ·åˆ†å¸ƒä¸­çš„æƒé‡ï¼Œä»¥åŠæ ‡è®°ä¸º Freq çš„åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "To see the impact of this, we can build a multivariable logistic regression model for the dataset in Table 7.6[339]. After the training process (which uses a slightly modified version of the gradient descent algorithm, which we will explain shortly), the resulting logistic regression model is15",
            "zh": "ä¸ºäº†äº†è§£å…¶å½±å“ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºè¡¨7.6[339]ä¸­çš„æ•°æ®é›†æ„å»ºä¸€ä¸ªå¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¹‹åï¼ˆä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•çš„ç•¥å¾®ä¿®æ”¹ç‰ˆæœ¬ï¼Œæˆ‘ä»¬ç¨åå°†è§£é‡Šï¼‰ï¼Œç”Ÿæˆçš„é€»è¾‘å›å½’æ¨¡å‹ä¸º15"
        }
    },
    {
        "translation": {
            "en": "For example, consider the following query:",
            "zh": "ä¾‹å¦‚ï¼Œè¯·è€ƒè™‘ä»¥ä¸‹æŸ¥è¯¢ï¼š"
        }
    },
    {
        "translation": {
            "en": "The descriptive features used by the model are the age of the customer, the socioeconomic band to which the customer belongs (a, b, or c), the average amount of money the customer spends on each visit to the shop, and the average number of visits the customer makes to the shop per week.",
            "zh": "è¯¥æ¨¡å‹ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾åŒ…æ‹¬å®¢æˆ·çš„å¹´é¾„ã€å®¢æˆ·æ‰€å±çš„ç¤¾ä¼šç»æµé˜¶å±‚ï¼ˆaã€b æˆ– cï¼‰ã€å®¢æˆ·æ¯æ¬¡è®¿é—®å•†åº—çš„å¹³å‡é‡‘é¢ä»¥åŠå®¢æˆ·æ¯å‘¨è®¿é—®å•†åº—çš„å¹³å‡æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It seems, from this data, that customers are most likely to churn when their bill changes dramatically, when they begin to exceed the bundled minutes in their call package, or when they have had a handset for a long time and are considering changing to something newer.",
            "zh": "ä»è¿™äº›æ•°æ®æ¥çœ‹ï¼Œå½“å®¢æˆ·çš„è´¦å•å‘ç”Ÿå·¨å¤§å˜åŒ–æ—¶ï¼Œå½“ä»–ä»¬å¼€å§‹è¶…è¿‡é€šè¯å¥—é¤ä¸­çš„æ†ç»‘åˆ†é’Ÿæ•°æ—¶ï¼Œæˆ–è€…å½“ä»–ä»¬å·²ç»æ‹¥æœ‰æ‰‹æœºå¾ˆé•¿æ—¶é—´å¹¶æ­£åœ¨è€ƒè™‘æ›´æ¢ä¸ºæ–°æ‰‹æœºæ—¶ï¼Œå®¢æˆ·æœ€æœ‰å¯èƒ½æµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "By the time the original error gradient term âˆ‚â„°/âˆ‚ak is propagated back to Î´i it is multiplied by two weights, wj,i and wk,j, and three times by the derivative of the activation function of a neuron with respect to the weighted sum of the neuron: âˆ‚ak/âˆ‚zk, âˆ‚aj/âˆ‚zj, âˆ‚ai/âˆ‚zi.",
            "zh": "å½“åŸå§‹è¯¯å·®æ¢¯åº¦é¡¹ âˆ‚E/âˆ‚ak ä¼ æ’­å› Î´i æ—¶ï¼Œå®ƒä¼šä¹˜ä»¥ä¸¤ä¸ªæƒé‡ wjï¼Œi å’Œ wkï¼Œjï¼Œå¹¶ä¹˜ä»¥ç¥ç»å…ƒæ¿€æ´»å‡½æ•°ç›¸å¯¹äºç¥ç»å…ƒåŠ æƒå’Œçš„å¯¼æ•°çš„ä¸‰å€ï¼šâˆ‚ak/âˆ‚zkã€âˆ‚aj/âˆ‚zjã€âˆ‚ai/âˆ‚ziã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3â€…â€…â€…Identifying Data Quality Issues",
            "zh": "3.3 è¯†åˆ«æ•°æ®è´¨é‡é—®é¢˜"
        }
    },
    {
        "translation": {
            "en": "This is also apparent in the final panel in Figure 7.6[325], which shows how the sum of squared errors decreases as the model becomes more accurate.",
            "zh": "è¿™åœ¨å›¾7.6[325]çš„æœ€åä¸€ä¸ªé¢æ¿ä¸­ä¹Ÿå¾ˆæ˜æ˜¾ï¼Œè¯¥å›¾æ˜¾ç¤ºäº†éšç€æ¨¡å‹å˜å¾—æ›´åŠ ç²¾ç¡®ï¼Œå¹³æ–¹è¯¯å·®çš„æ€»å’Œå¦‚ä½•å‡å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Mean and median",
            "zh": "ï¼ˆbï¼‰ å¹³å‡å€¼å’Œä¸­ä½æ•°"
        }
    },
    {
        "translation": {
            "en": "7.2â€…â€…â€…Fundamentals",
            "zh": "7.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "This chapter introduced reinforcement learning, an alternative approach to supervised or unsupervised machine learning.",
            "zh": "æœ¬ç« ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ ï¼Œè¿™æ˜¯ç›‘ç£æˆ–æ— ç›‘ç£æœºå™¨å­¦ä¹ çš„æ›¿ä»£æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "These bar plots show that the distribution of target levels for New Sample 1 is similar to the original test set, but that the distribution of target levels for New Sample 2 is quite different.",
            "zh": "è¿™äº›æ¡å½¢å›¾æ˜¾ç¤ºï¼Œæ–°æ ·æœ¬ 1 çš„ç›®æ ‡æ°´å¹³åˆ†å¸ƒä¸åŸå§‹æµ‹è¯•é›†ç›¸ä¼¼ï¼Œä½†æ–°æ ·æœ¬ 2 çš„ç›®æ ‡æ°´å¹³åˆ†å¸ƒå´å¤§ä¸ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The tabular reports are accompanied by data visualizations that illustrate the distribution of the values in each feature in an ABT.",
            "zh": "è¡¨æ ¼æŠ¥å‘Šé™„æœ‰æ•°æ®å¯è§†åŒ–ï¼Œç”¨äºè¯´æ˜ ABT ä¸­æ¯ä¸ªè¦ç´ ä¸­å€¼çš„åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The structure of a box plot; and (b) a box plot for the TRAINING EXPENSES feature from the basketball team dataset in Table A.1[750].",
            "zh": "ï¼ˆaï¼‰ ç®±å½¢åœ°å—çš„ç»“æ„;ï¼ˆbï¼‰è¡¨A.1[750]ä¸­ç¯®çƒé˜Ÿæ•°æ®é›†çš„è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„ç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are two types of neurons in this network: sensing neurons and processing neurons.",
            "zh": "è¯¥ç½‘ç»œä¸­æœ‰ä¸¤ç§ç±»å‹çš„ç¥ç»å…ƒï¼šæ„ŸçŸ¥ç¥ç»å…ƒå’Œå¤„ç†ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "There is only one neuron in the output layer, and so there is only one row in this weight matrix.",
            "zh": "è¾“å‡ºå±‚ä¸­åªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼Œå› æ­¤æ­¤æƒé‡çŸ©é˜µä¸­åªæœ‰ä¸€è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Naturally, when our patience runs out, we roll back training to the version of the model that produced the lowest validation set error.",
            "zh": "å½“ç„¶ï¼Œå½“æˆ‘ä»¬çš„è€å¿ƒè€—å°½æ—¶ï¼Œæˆ‘ä»¬ä¼šå°†è®­ç»ƒå›æ»šåˆ°äº§ç”Ÿæœ€ä½éªŒè¯é›†è¯¯å·®çš„æ¨¡å‹ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "This network has a depth of three, and so it has three weight matrices.",
            "zh": "è¯¥ç½‘ç»œçš„æ·±åº¦ä¸º 3ï¼Œå› æ­¤å®ƒæœ‰ä¸‰ä¸ªæƒé‡çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "2.2â€…â€…â€…The hierarchical relationship between an analytics solution, domain concepts, and descriptive features.",
            "zh": "2.2 åˆ†æè§£å†³æ–¹æ¡ˆã€é¢†åŸŸæ¦‚å¿µå’Œæè¿°æ€§ç‰¹å¾ä¹‹é—´çš„å±‚æ¬¡ç»“æ„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is interesting here is that no matter what question you ask, the answer is always either yes or no, but, on average, an answer to Question 1 seems to carry more information than an answer to Question 2.",
            "zh": "æœ‰è¶£çš„æ˜¯ï¼Œæ— è®ºä½ é—®ä»€ä¹ˆé—®é¢˜ï¼Œç­”æ¡ˆæ€»æ˜¯â€œæ˜¯â€æˆ–â€œå¦â€ï¼Œä½†å¹³å‡è€Œè¨€ï¼Œé—®é¢˜ 1 çš„ç­”æ¡ˆä¼¼ä¹æ¯”é—®é¢˜ 2 çš„ç­”æ¡ˆåŒ…å«æ›´å¤šçš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we can catch this point, we can take appropriate action.",
            "zh": "å¦‚æœæˆ‘ä»¬èƒ½æŠ“ä½è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°±å¯ä»¥é‡‡å–é€‚å½“çš„è¡ŒåŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The target level imbalance in the SDSS dataset arises through relative rarity.15 In the large SDSS dataset, there are plenty of galaxies in the other and spiral categories; there are just many more in the elliptical category.",
            "zh": "15 åœ¨å¤§å‹ SDSS æ•°æ®é›†ä¸­ï¼Œå…¶ä»–æ˜Ÿç³»å’Œèºæ—‹æ˜Ÿç³»ç±»åˆ«ä¸­æœ‰å¾ˆå¤šæ˜Ÿç³»;æ¤­åœ†æœºç±»åˆ«ä¸­è¿˜æœ‰æ›´å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "conditional independence, 256, 256, 261, 302",
            "zh": "æœ‰æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œ256ã€256ã€261ã€302"
        }
    },
    {
        "translation": {
            "en": "As the process has arrived at a leaf node, it terminates, and the target level indicated by the leaf node, spam, is predicted for the query instance.",
            "zh": "å½“è¿›ç¨‹åˆ°è¾¾å¶èŠ‚ç‚¹æ—¶ï¼Œå®ƒå°†ç»ˆæ­¢ï¼Œå¹¶ä¸”ä¸ºæŸ¥è¯¢å®ä¾‹é¢„æµ‹å¶èŠ‚ç‚¹æŒ‡ç¤ºçš„ç›®æ ‡çº§åˆ« spamã€‚"
        }
    },
    {
        "translation": {
            "en": "The point to note in this equation is that the calculation does not involve a weight term.",
            "zh": "åœ¨è¿™ä¸ªç­‰å¼ä¸­éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œè®¡ç®—ä¸æ¶‰åŠæƒé‡é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3â€…â€…â€…Data Exploration",
            "zh": "3 æ•°æ®æ¢ç´¢"
        }
    },
    {
        "translation": {
            "en": "Figure 9.13[564] shows the K-S chart for the test set predictions shown in Table 9.11[557].",
            "zh": "å›¾9.13[564]æ˜¾ç¤ºäº†è¡¨9.11[557]æ‰€ç¤ºçš„æµ‹è¯•é›†é¢„æµ‹çš„K-Så›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate gradient boosting, we use another modified version of the bike rentals dataset used in Section 4.4.3[149]. This will again predict the expected rental demand on the basis of a single descriptive feature, the forecasted temperature for a day. The first columns of Table 4.15[166] detail a small sample dataset giving temperatures, TEMP, and rental demand, RENTALS (this time as actual numeric values), for 10 days. A visualization of the dataset is provided in Figure 4.22(a)[167].",
            "zh": "ä¸ºäº†è¯´æ˜æ¢¯åº¦æå‡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç¬¬ 4.4.3 èŠ‚ä¸­ä½¿ç”¨çš„è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®é›†çš„å¦ä¸€ä¸ªä¿®æ”¹ç‰ˆæœ¬[149]ã€‚è¿™å°†å†æ¬¡æ ¹æ®å•ä¸ªæè¿°æ€§ç‰¹å¾ï¼ˆå³ä¸€å¤©çš„é¢„æµ‹æ¸©åº¦ï¼‰é¢„æµ‹é¢„æœŸçš„ç§Ÿèµéœ€æ±‚ã€‚è¡¨ 4.15[166] çš„ç¬¬ä¸€åˆ—è¯¦ç»†ä»‹ç»äº†ä¸€ä¸ªå°å‹æ ·æœ¬æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç»™å‡ºäº† 10 å¤©çš„æ¸©åº¦ã€æ¸©åº¦å’Œç§Ÿèµéœ€æ±‚ã€ç§Ÿé‡‘ï¼ˆè¿™æ¬¡æ˜¯å®é™…æ•°å€¼ï¼‰ã€‚å›¾4.22ï¼ˆaï¼‰[167]æä¾›äº†æ•°æ®é›†çš„å¯è§†åŒ–æ•ˆæœã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the probabilities (to four places of decimal) that a naive Bayes classifier would use to represent this domain.",
            "zh": "ï¼ˆaï¼‰ è®¡ç®—æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ç”¨æ¥è¡¨ç¤ºè¯¥åŸŸçš„æ¦‚ç‡ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹åå››ä½ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Aoife would like to thank her parents (Michael and Mairead) and family, and all the people who have supported her throughout her careerâ€”especially the much-valued customers of Krisolis who give her data to play with!",
            "zh": "Aoife è¦æ„Ÿè°¢å¥¹çš„çˆ¶æ¯ï¼ˆMichael å’Œ Maireadï¼‰å’Œå®¶äººï¼Œä»¥åŠæ‰€æœ‰åœ¨å¥¹æ•´ä¸ªèŒä¸šç”Ÿæ¶¯ä¸­æ”¯æŒå¥¹çš„äººâ€”â€”å°¤å…¶æ˜¯ Krisolis çš„å°Šè´µå®¢æˆ·ï¼Œä»–ä»¬ä¸ºå¥¹æä¾›äº†æ•°æ®ï¼"
        }
    },
    {
        "translation": {
            "en": "(a) What will be the value of ct if",
            "zh": "ï¼ˆaï¼‰ ct çš„å€¼æ˜¯å¤šå°‘ï¼Œå¦‚æœ"
        }
    },
    {
        "translation": {
            "en": "entropy, 43, 117, 120, 125, 149, 172, 173, 611, 731",
            "zh": "ç†µï¼Œ 43ï¼Œ 117ï¼Œ 120ï¼Œ 125ï¼Œ 149ï¼Œ 172ï¼Œ 173ï¼Œ 611ï¼Œ 731"
        }
    },
    {
        "translation": {
            "en": "We donâ€™t have to use decision trees.",
            "zh": "æˆ‘ä»¬ä¸å¿…ä½¿ç”¨å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Which approach should we use?",
            "zh": "æˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªç§æ–¹æ³•ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Health and education directly affect corruption, so there is a directed arc from LIFE EXP and from SCHOOL YEARS to CPI.",
            "zh": "å¥åº·å’Œæ•™è‚²ç›´æ¥å½±å“è…è´¥ï¼Œå› æ­¤ä» LIFE EXP å’Œä» SCHOOL YEARS åˆ° CPI æœ‰ä¸€æ¡å®šå‘å¼§çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "14. The logistic function is a real workhorse of mathematical modeling and is used in a huge range of different applications. For example, the logistic function has been used to model how new words enter a language over time, first used very infrequently before moving through a tipping point to become widespread in a language.",
            "zh": "14. é€»è¾‘å‡½æ•°æ˜¯æ•°å­¦å»ºæ¨¡çš„çœŸæ­£ä¸»åŠ›å†›ï¼Œç”¨äºå„ç§ä¸åŒçš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œé€»è¾‘å‡½æ•°å·²è¢«ç”¨äºæ¨¡æ‹Ÿæ–°è¯å¦‚ä½•éšç€æ—¶é—´çš„æ¨ç§»è¿›å…¥ä¸€ç§è¯­è¨€ï¼Œåœ¨é€šè¿‡ä¸´ç•Œç‚¹åœ¨è¯­è¨€ä¸­å¹¿æ³›ä½¿ç”¨ä¹‹å‰ï¼Œæœ€åˆå¾ˆå°‘ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In summary, ensembles, support vector machines, neural networks, and Bayesian networks are, in general, more powerful machine learning approaches than the others we have presented.",
            "zh": "æ€»ä¹‹ï¼Œé›†æˆã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œå’Œè´å¶æ–¯ç½‘ç»œé€šå¸¸æ˜¯æ¯”æˆ‘ä»¬ä»‹ç»çš„å…¶ä»–æ–¹æ³•æ›´å¼ºå¤§çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, we have had to sacrifice coverage of some aspects of machine learning in order to include other topics and worked examples.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬ä¸å¾—ä¸ç‰ºç‰²å¯¹æœºå™¨å­¦ä¹ æŸäº›æ–¹é¢çš„è¦†ç›–ï¼Œä»¥åŒ…æ‹¬å…¶ä»–ä¸»é¢˜å’Œå·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These are abstract concepts that are understood to be likely important factors in making predictions.",
            "zh": "è¿™äº›æ˜¯æŠ½è±¡çš„æ¦‚å¿µï¼Œè¢«ç†è§£ä¸ºåšå‡ºé¢„æµ‹çš„é‡è¦å› ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can put these components together to define the standard approach to similarity-based learning: the nearest neighbor algorithm.",
            "zh": "æˆ‘ä»¬å¯ä»¥å°†è¿™äº›ç»„ä»¶æ”¾åœ¨ä¸€èµ·æ¥å®šä¹‰åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ çš„æ ‡å‡†æ–¹æ³•ï¼šæœ€è¿‘é‚»ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are a number of performance measures based on the idea of comparing prediction score distributions that attempt to cater to the peculiarities of real data.",
            "zh": "æœ‰è®¸å¤šåŸºäºæ¯”è¾ƒé¢„æµ‹åˆ†æ•°åˆ†å¸ƒçš„ç»©æ•ˆåº¦é‡ï¼Œè¯•å›¾è¿åˆçœŸå®æ•°æ®çš„ç‰¹æ®Šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was clear that the performance of the models trained using the SDSS data was severely affected by the target level imbalance in the dataâ€”there were many more examples of the elliptical target level than either the spiral or, especially, the other target level.",
            "zh": "å¾ˆæ˜æ˜¾ï¼Œä½¿ç”¨SDSSæ•°æ®è®­ç»ƒçš„æ¨¡å‹çš„æ€§èƒ½å—åˆ°æ•°æ®ä¸­ç›®æ ‡æ°´å¹³ä¸å¹³è¡¡çš„ä¸¥é‡å½±å“â€”â€”æ¤­åœ†ç›®æ ‡æ°´å¹³çš„ä¾‹å­æ¯”èºæ—‹ç›®æ ‡æ°´å¹³æˆ–ç‰¹åˆ«æ˜¯å…¶ä»–ç›®æ ‡æ°´å¹³çš„ä¾‹å­è¦å¤šå¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "B.2â€ƒProbability Distributions and Summing Out",
            "zh": "B.2 æ¦‚ç‡åˆ†å¸ƒå’Œæ±‚å’Œ"
        }
    },
    {
        "translation": {
            "en": "k-means++, 605, 607, 624",
            "zh": "k-å‡å€¼++ï¼Œ 605ï¼Œ 607ï¼Œ 624"
        }
    },
    {
        "translation": {
            "en": "If we use the symbol Ï† to represent the activation function of a neuron, we can mathematically define an artificial neuron as follows:",
            "zh": "å¦‚æœæˆ‘ä»¬ä½¿ç”¨ç¬¦å· Ï† æ¥è¡¨ç¤ºç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ•°å­¦ä¸Šå®šä¹‰äººå·¥ç¥ç»å…ƒå¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "exploration, 655, 656",
            "zh": "å‹˜æ¢ï¼Œ 655ï¼Œ 656"
        }
    },
    {
        "translation": {
            "en": "There are two ways to reason with probabilities forward and inverse.",
            "zh": "æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¯¹æ¦‚ç‡è¿›è¡Œæ­£å‘æ¨ç†å’Œé€†å‘æ¨ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.15",
            "zh": "å›¾ 5.15"
        }
    },
    {
        "translation": {
            "en": "Subsets of the training set would be also used for validation during the model building process.",
            "zh": "åœ¨æ¨¡å‹æ„å»ºè¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒé›†çš„å­é›†ä¹Ÿå°†ç”¨äºéªŒè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Reinforcement learning is built upon the framework of an intelligent agent.",
            "zh": "å¼ºåŒ–å­¦ä¹ å»ºç«‹åœ¨æ™ºèƒ½ä»£ç†çš„æ¡†æ¶ä¹‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The following table lists a dataset of five individuals described via a set of stroke risk factors and their probability of suffering a stroke in the next five years.",
            "zh": "ä¸‹è¡¨åˆ—å‡ºäº†é€šè¿‡ä¸€ç»„ä¸­é£é£é™©å› ç´ æè¿°çš„äº”ä¸ªäººçš„æ•°æ®é›†ï¼Œä»¥åŠä»–ä»¬åœ¨æœªæ¥äº”å¹´å†…æ‚£ä¸­é£çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. In this discussion, when we categorize models as being generative or discriminative, we are speaking in the general case. In fact, all models can be trained in either a generative or a discriminative manner. However, some models lend themselves to generative training and others to discriminative training, and it is this perspective that we use in this discussion.",
            "zh": "1. åœ¨æœ¬æ¬¡è®¨è®ºä¸­ï¼Œå½“æˆ‘ä»¬å°†æ¨¡å‹å½’ç±»ä¸ºç”Ÿæˆæ€§æˆ–åˆ¤åˆ«æ€§æ—¶ï¼Œæˆ‘ä»¬æ˜¯åœ¨ä¸€èˆ¬æƒ…å†µä¸‹å‘è¨€ã€‚äº‹å®ä¸Šï¼Œæ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥ä»¥ç”Ÿæˆæˆ–åˆ¤åˆ«æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œæœ‰äº›æ¨¡å‹é€‚åˆç”Ÿæˆæ€§è®­ç»ƒï¼Œè€Œå¦ä¸€äº›æ¨¡å‹åˆ™é€‚åˆæ­§è§†æ€§è®­ç»ƒï¼Œæˆ‘ä»¬åœ¨æœ¬æ¬¡è®¨è®ºä¸­ä½¿ç”¨çš„æ­£æ˜¯è¿™ç§è§‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This example illustrates that the variance also captures the intuition that the heights of the players in the second team vary much more than those in the first team.",
            "zh": "è¿™ä¸ªä¾‹å­è¯´æ˜ï¼Œæ–¹å·®è¿˜æ•æ‰åˆ°äº†ä¸€ç§ç›´è§‰ï¼Œå³äºŒé˜Ÿçƒå‘˜çš„èº«é«˜å˜åŒ–æ¯”ä¸€é˜Ÿçƒå‘˜çš„èº«é«˜å˜åŒ–å¤§å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "0.56",
            "zh": "0.56"
        }
    },
    {
        "translation": {
            "en": "These correlation values are much more useful than the covariances calculated previously because they are on a normalized scale, which allows us to compare the strength of the relationships to each other. There is a strong positive correlation between HEIGHT and WEIGHT features, but very little correlation between HEIGHT and AGE.",
            "zh": "è¿™äº›ç›¸å…³å€¼æ¯”ä¹‹å‰è®¡ç®—çš„åæ–¹å·®æœ‰ç”¨å¾—å¤šï¼Œå› ä¸ºå®ƒä»¬å¤„äºå½’ä¸€åŒ–å°ºåº¦ä¸Šï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¯”è¾ƒå…³ç³»çš„å¼ºåº¦ã€‚èº«é«˜å’Œä½“é‡ç‰¹å¾ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„æ­£ç›¸å…³å…³ç³»ï¼Œä½†èº«é«˜å’Œå¹´é¾„ä¹‹é—´çš„ç›¸å…³æ€§å¾ˆå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "frequency table, 749",
            "zh": "é¢‘ç‡è¡¨ï¼Œ749"
        }
    },
    {
        "translation": {
            "en": "Discuss the relationships shown in each visualizations.",
            "zh": "è®¨è®ºæ¯ä¸ªå¯è§†åŒ–ä¸­æ˜¾ç¤ºçš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Again, we have overlaid the histogram with plots of the curves for a normal and a student-t distribution that have been fitted to the updated dataset.",
            "zh": "åŒæ ·ï¼Œæˆ‘ä»¬åœ¨ç›´æ–¹å›¾ä¸Šè¦†ç›–äº†å·²æ‹Ÿåˆåˆ°æ›´æ–°æ•°æ®é›†çš„æ­£æ€åˆ†å¸ƒå’Œ student-t åˆ†å¸ƒçš„æ›²çº¿å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SARSA and Q-learning approaches are both tabular methods which are limited in terms of the size of state space they can handle.",
            "zh": "SARSA å’Œ Q-learning æ–¹æ³•éƒ½æ˜¯è¡¨æ ¼æ–¹æ³•ï¼Œå®ƒä»¬åœ¨å¯ä»¥å¤„ç†çš„çŠ¶æ€ç©ºé—´å¤§å°æ–¹é¢å—åˆ°é™åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of this partâ€™s first five chapters presents a different approach to machine learning: Chapter 4, learning through information gathering; Chapter 5, learning through analogy; Chapter 6, learning by predicting probable outcomes; Chapter 7, learning by searching for solutions that minimize error; and Chapter 8, learning new representations using deep neural networks.",
            "zh": "æœ¬éƒ¨åˆ†çš„å‰äº”ç« ä¸­çš„æ¯ä¸€ç« éƒ½ä»‹ç»äº†ä¸€ç§ä¸åŒçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼šç¬¬ 4 ç« ï¼Œé€šè¿‡ä¿¡æ¯æ”¶é›†è¿›è¡Œå­¦ä¹ ;ç¬¬5ç« ï¼Œç±»æ¯”å­¦ä¹ ;ç¬¬ 6 ç« ï¼Œé€šè¿‡é¢„æµ‹å¯èƒ½çš„ç»“æœæ¥å­¦ä¹ ;ç¬¬ 7 ç« ï¼Œé€šè¿‡å¯»æ‰¾æœ€å¤§é™åº¦åœ°å‡å°‘é”™è¯¯çš„è§£å†³æ–¹æ¡ˆæ¥å­¦ä¹ ;ç¬¬ 8 ç« ï¼Œä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå­¦ä¹ æ–°è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The target feature, SIGNUP, indicates whether the customers ultimately signed up to the paid service or not (yes or no).",
            "zh": "ç›®æ ‡åŠŸèƒ½ SIGNUP æŒ‡ç¤ºå®¢æˆ·æœ€ç»ˆæ˜¯å¦æ³¨å†Œäº†ä»˜è´¹æœåŠ¡ï¼ˆæ˜¯æˆ–å¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic structure in which we capture these historical datasets is the analytics base table (ABT), a schematic of which is shown in Table 2.1[29]. An analytics base table is a simple, flat, tabular data structure made up of rows and columns. The columns are divided into a set of descriptive features and a single target feature. Each row contains a value for each descriptive feature and the target feature and represents an instance about which a prediction can be made.",
            "zh": "æˆ‘ä»¬æ•è·è¿™äº›å†å²æ•°æ®é›†çš„åŸºæœ¬ç»“æ„æ˜¯åˆ†æåŸºè¡¨ï¼ˆABTï¼‰ï¼Œå…¶ç¤ºæ„å›¾å¦‚è¡¨2.1æ‰€ç¤º[29]ã€‚åˆ†æåŸºè¡¨æ˜¯ä¸€ç§ç®€å•ã€æ‰å¹³çš„è¡¨æ ¼æ•°æ®ç»“æ„ï¼Œç”±è¡Œå’Œåˆ—ç»„æˆã€‚è¿™äº›åˆ—åˆ†ä¸ºä¸€ç»„æè¿°æ€§ç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡ç‰¹å¾ã€‚æ¯è¡ŒåŒ…å«æ¯ä¸ªæè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾çš„å€¼ï¼Œå¹¶è¡¨ç¤ºå¯ä»¥å¯¹å…¶è¿›è¡Œé¢„æµ‹çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the dataset of training instances considered at each of the interior nodes in the tree is not the complete dataset; rather, it is the subset of instances considered at its parent node that had the relevant feature value for the branch from the parent to the current node.",
            "zh": "é¦–å…ˆï¼Œæ ‘ä¸­æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹æ‰€è€ƒè™‘çš„è®­ç»ƒå®ä¾‹æ•°æ®é›†ä¸æ˜¯å®Œæ•´çš„æ•°æ®é›†;ç›¸åï¼Œå®ƒæ˜¯åœ¨å…¶çˆ¶èŠ‚ç‚¹ä¸Šè€ƒè™‘çš„å®ä¾‹å­é›†ï¼Œè¯¥å­é›†å…·æœ‰ä»çˆ¶èŠ‚ç‚¹åˆ°å½“å‰èŠ‚ç‚¹çš„åˆ†æ”¯çš„ç›¸å…³ç‰¹å¾å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 1[134] lists a pseudocode description of the ID3 algorithm. Although the algorithm looks quite complex, it essentially does one of two things each time it is invoked: either it stops growing the current path in the tree by adding a leaf node to the tree, Lines 1â€“6, or it extends the current path by adding an interior node to the tree and growing the branches of this node by repeatedly rerunning the algorithm, Lines 7â€“13.",
            "zh": "ç®—æ³• 1[134] åˆ—å‡ºäº† ID3 ç®—æ³•çš„ä¼ªä»£ç æè¿°ã€‚å°½ç®¡è¯¥ç®—æ³•çœ‹èµ·æ¥å¾ˆå¤æ‚ï¼Œä½†å®ƒåœ¨æ¯æ¬¡è°ƒç”¨æ—¶åŸºæœ¬ä¸Šéƒ½ä¼šæ‰§è¡Œä»¥ä¸‹ä¸¤ä»¶äº‹ä¹‹ä¸€ï¼šè¦ä¹ˆé€šè¿‡å‘æ ‘æ·»åŠ å¶èŠ‚ç‚¹ï¼ˆç¬¬ 1-6 è¡Œï¼‰æ¥åœæ­¢æ ‘ä¸­çš„å½“å‰è·¯å¾„å¢é•¿ï¼Œè¦ä¹ˆé€šè¿‡å‘æ ‘æ·»åŠ å†…éƒ¨èŠ‚ç‚¹å¹¶é€šè¿‡é‡å¤é‡æ–°è¿è¡Œç®—æ³•æ¥æ‰©å±•è¯¥èŠ‚ç‚¹çš„åˆ†æ”¯æ¥æ‰©å±•å½“å‰è·¯å¾„ï¼Œ ç¬¬ 7-13 è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the weight update for each weight in the filter: w0,w1,w2,w3.",
            "zh": "ï¼ˆcï¼‰ è®¡ç®—è¿‡æ»¤å™¨ä¸­æ¯ä¸ªç ç çš„é‡é‡æ›´æ–°ï¼šw0ï¼Œw1ï¼Œw2ï¼Œw3ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the scales of the axes must always be kept consistent, as should the order of the bars in the individual bar plots.",
            "zh": "ä¾‹å¦‚ï¼Œè½´çš„åˆ»åº¦å¿…é¡»å§‹ç»ˆä¿æŒä¸€è‡´ï¼Œå„ä¸ªæ¡å½¢å›¾ä¸­æ¡å½¢çš„é¡ºåºä¹Ÿåº”ä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather, FRAUD FLAG is a categorical feature that just happens to use 0 and 1 as its category labels, which has led to its being treated as continuous in the ABT.",
            "zh": "ç›¸åï¼ŒFRAUD FLAG æ˜¯ä¸€ä¸ªåˆ†ç±»ç‰¹å¾ï¼Œæ°å¥½ä½¿ç”¨ 0 å’Œ 1 ä½œä¸ºå…¶ç±»åˆ«æ ‡ç­¾ï¼Œè¿™å¯¼è‡´å®ƒåœ¨ ABT ä¸­è¢«è§†ä¸ºè¿ç»­çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Generally, there is not an optimal set of intervals for a given feature.",
            "zh": "é€šå¸¸ï¼Œç»™å®šè¦ç´ æ²¡æœ‰ä¸€ç»„æœ€ä½³é—´éš”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The other cluster centroids are updated similarly, so that c1 = âŸ¨âˆ’0.5727,âˆ’0.0706âŸ©, c2 = âŸ¨0.8866,âˆ’0.7912âŸ©, and c3 = âŸ¨âˆ’0.3367,0.6123âŸ©. These are illustrated in Figure 10.3(d)[602].",
            "zh": "å…¶ä»–èšç±»è´¨å¿ƒçš„æ›´æ–°ç±»ä¼¼ï¼Œå› æ­¤ c1 = âŸ¨âˆ’0.5727ï¼Œâˆ’0.0706âŸ©ï¼Œc2 = âŸ¨0.8866ï¼Œâˆ’0.7912âŸ©ï¼Œc3 = âŸ¨âˆ’0.3367,0.6123âŸ©ã€‚è¿™äº›å¦‚å›¾10.3ï¼ˆdï¼‰[602]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using Xavier initialization.",
            "zh": "å›¾ 8.22[450] ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨ Xavier åˆå§‹åŒ–è¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "That intelligent behavior can be driven by the singular goal of maximizing return is a bold statementâ€”it is often argued that it is very ambitious to expect sophisticated, long-term behavior to emerge from simple accumulation of instantaneous rewards.",
            "zh": "æ™ºèƒ½è¡Œä¸ºå¯ä»¥ç”±æœ€å¤§åŒ–å›æŠ¥çš„å•ä¸€ç›®æ ‡é©±åŠ¨ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§èƒ†çš„å£°æ˜â€”â€”äººä»¬ç»å¸¸è®¤ä¸ºï¼ŒæœŸæœ›ä»ç®€å•çš„å³æ—¶å¥–åŠ±ç§¯ç´¯ä¸­äº§ç”Ÿå¤æ‚çš„é•¿æœŸè¡Œä¸ºæ˜¯éå¸¸é›„å¿ƒå‹ƒå‹ƒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, individually, the 7 probabilities have fewer constraints on them than the 16 in the full joint probability distribution.",
            "zh": "é¦–å…ˆï¼Œå•ç‹¬æ¥çœ‹ï¼Œåœ¨å®Œå…¨è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­ï¼Œ7 ä¸ªæ¦‚ç‡å¯¹å®ƒä»¬çš„çº¦æŸå°‘äº 16 ä¸ªæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For fr the probability P(ACC = free | fr) causes the problem, and for Â¬fr the probability P(GC = guarantor | Â¬fr) is the offender.",
            "zh": "å¯¹äº frï¼Œæ¦‚ç‡ Pï¼ˆACC = free | frï¼‰ å¯¼è‡´é—®é¢˜ï¼Œè€Œå¯¹äº Â¬frï¼Œæ¦‚ç‡ Pï¼ˆGC = æ‹…ä¿äºº | Â¬frï¼‰ æ˜¯è¿è§„è€…ã€‚"
        }
    },
    {
        "translation": {
            "en": "The feature UNKNOWN SENDER has an information gain of 0.0817 bits.",
            "zh": "UNKNOWN SENDER åŠŸèƒ½çš„ä¿¡æ¯å¢ç›Šä¸º 0.0817 ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "From the disorganized letters at the beginning, Abigail divided the letters into six different-colored groups, Andrew organized them into a lowercase group and an uppercase group, and Sarah made a group for each letter of the alphabet.",
            "zh": "ä»ä¸€å¼€å§‹æ‚ä¹±æ— ç« çš„å­—æ¯å¼€å§‹ï¼Œé˜¿æ¯”ç›–å°”å°†å­—æ¯åˆ†æˆå…­ä¸ªä¸åŒé¢œè‰²çš„ç»„ï¼Œå®‰å¾·é²å°†å®ƒä»¬ç»„ç»‡æˆå°å†™ç»„å’Œå¤§å†™ç»„ï¼Œèæ‹‰ä¸ºå­—æ¯è¡¨çš„æ¯ä¸ªå­—æ¯ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.1â€…â€…â€…A simple dataset for a MENINGITIS diagnosis with descriptive features that describe the presence or absence of three common symptoms of the disease: HEADACHE, FEVER, and VOMITING.",
            "zh": "6.1 ç”¨äºè„‘è†œç‚è¯Šæ–­çš„ç®€å•æ•°æ®é›†ï¼Œå…·æœ‰æè¿°æ€§ç‰¹å¾ï¼Œæè¿°æ˜¯å¦å­˜åœ¨è¯¥ç–¾ç—…çš„ä¸‰ç§å¸¸è§ç—‡çŠ¶ï¼šå¤´ç—›ã€å‘çƒ§å’Œå‘•åã€‚"
        }
    },
    {
        "translation": {
            "en": "Using unsupervised learning to generate feature representations that could be used in later supervised models (e.g., Hinton et al.",
            "zh": "ä½¿ç”¨æ— ç›‘ç£å­¦ä¹ æ¥ç”Ÿæˆå¯ç”¨äºä»¥åç›‘ç£æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼ŒHinton et al."
        }
    },
    {
        "translation": {
            "en": "statistics, 369",
            "zh": "ç»Ÿè®¡ï¼Œ 369"
        }
    },
    {
        "translation": {
            "en": "7.4.6â€ƒMultinomial Logistic Regression",
            "zh": "7.4.6 å¤šé¡¹å¼é€»è¾‘å›å½’"
        }
    },
    {
        "translation": {
            "en": "Subset Selection: This component selects the feature subset from the set of candidate feature subsets generated by the subset generation component that is the most desirable for the search process to move to.",
            "zh": "å­é›†é€‰æ‹©ï¼šæ­¤ç»„ä»¶ä»å­é›†ç”Ÿæˆç»„ä»¶ç”Ÿæˆçš„å€™é€‰ç‰¹å¾å­é›†é›†ä¸­é€‰æ‹©æœç´¢è¿‡ç¨‹æœ€ç†æƒ³çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of Î± = 0.1, calculate the updated values for each of the weights in the network (w3,2,w3,0,,w2,1,w2,0,) after the processing of this single training example.",
            "zh": "å‡è®¾å­¦ä¹ ç‡ä¸º Î± = 0.1ï¼Œåœ¨å¤„ç†å®Œæ­¤è®­ç»ƒç¤ºä¾‹åï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªæƒé‡ ï¼ˆw3,2ï¼Œw3,0ï¼Œï¼Œw2,1ï¼Œw2,0ï¼Œï¼‰ çš„æ›´æ–°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks have been successfully applied across a range of fields, including medical diagnosis, object recognition, and natural language understanding.",
            "zh": "è´å¶æ–¯ç½‘ç»œå·²æˆåŠŸåº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬åŒ»å­¦è¯Šæ–­ã€å¯¹è±¡è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€ç†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "For each partition a branch is grown from the node.",
            "zh": "å¯¹äºæ¯ä¸ªåˆ†åŒºï¼Œéƒ½ä¼šä»èŠ‚ç‚¹ä¸­ç”Ÿé•¿ä¸€ä¸ªåˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of us has also been fortunate to have the support of close friends and family, which was invaluable in completing the book.",
            "zh": "æˆ‘ä»¬æ¯ä¸ªäººéƒ½å¾ˆå¹¸è¿åœ°å¾—åˆ°äº†äº²å¯†æœ‹å‹å’Œå®¶äººçš„æ”¯æŒï¼Œè¿™å¯¹å®Œæˆè¿™æœ¬ä¹¦æ¥è¯´æ˜¯æ— ä»·çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.12(b)[205], however, both axes range from 0 to 1.",
            "zh": "ç„¶è€Œï¼Œåœ¨å›¾5.12ï¼ˆbï¼‰[205]ä¸­ï¼Œä¸¤ä¸ªè½´çš„èŒƒå›´ä»0åˆ°1ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, to make predictions on the outcome of loans granted by a bank, we might use the borrowerâ€™s salary as a descriptive feature.",
            "zh": "ä¾‹å¦‚ï¼Œä¸ºäº†é¢„æµ‹é“¶è¡Œå‘æ”¾çš„è´·æ¬¾ç»“æœï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨å€Ÿæ¬¾äººçš„å·¥èµ„ä½œä¸ºæè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In backpropagation, the error gradient with respect to an input to a product of two terms is the error gradient with respect to the result of the product multiplied by the other input to the product.",
            "zh": "åœ¨åå‘ä¼ æ’­ä¸­ï¼Œç›¸å¯¹äºä¸¤ä¸ªé¡¹çš„ä¹˜ç§¯çš„è¾“å…¥çš„è¯¯å·®æ¢¯åº¦æ˜¯ç›¸å¯¹äºä¹˜ç§¯ç»“æœä¹˜ä»¥ä¹˜ç§¯çš„å¦ä¸€ä¸ªè¾“å…¥çš„è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this in the decision boundaries shown in the bottom-right panel of Figure 7.21[360].",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å›¾ 7.21[360] å³ä¸‹è§’é¢æ¿æ‰€ç¤ºçš„å†³ç­–è¾¹ç•Œä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4â€…â€…â€…(a)â€“(h) Different clusterings (all with k = 3) that can be found for the mobile phone customer dataset given in Table 10.1[604] when different initial cluster centroids are used.",
            "zh": "10.4 ï¼ˆaï¼‰â€“ï¼ˆhï¼‰ å½“ä½¿ç”¨ä¸åŒçš„åˆå§‹èšç±»è´¨å¿ƒæ—¶ï¼Œå¯¹äºè¡¨ 10.1[604] ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ï¼Œå¯ä»¥æ‰¾åˆ°ä¸åŒçš„èšç±»ï¼ˆå‡ä¸º k = 3ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, converting a business problem into an analytics solution involves answering the following key questions:",
            "zh": "é€šå¸¸ï¼Œå°†ä¸šåŠ¡é—®é¢˜è½¬æ¢ä¸ºåˆ†æè§£å†³æ–¹æ¡ˆæ¶‰åŠå›ç­”ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š"
        }
    },
    {
        "translation": {
            "en": "The analytics consultant has generated an ABT to be used to train this model.17 The descriptive features in this dataset are defined as follows:",
            "zh": "åˆ†æé¡¾é—®å·²ç”Ÿæˆç”¨äºè®­ç»ƒæ­¤æ¨¡å‹çš„ ABTã€‚17 æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "If a prediction task is affected by concept drift, an eager learner may not be appropriate because the abstraction induced during training will go out of date, and the model will need to be retrained at regular intervals, a costly exercise.",
            "zh": "å¦‚æœé¢„æµ‹ä»»åŠ¡å—åˆ°æ¦‚å¿µæ¼‚ç§»çš„å½±å“ï¼Œé‚£ä¹ˆçƒ­åˆ‡çš„å­¦ä¹ è€…å¯èƒ½ä¸é€‚åˆï¼Œå› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¯±å¯¼çš„æŠ½è±¡å°†è¿‡æ—¶ï¼Œå¹¶ä¸”æ¨¡å‹éœ€è¦å®šæœŸé‡æ–°è®­ç»ƒï¼Œè¿™æ˜¯ä¸€é¡¹ä»£ä»·é«˜æ˜‚çš„å·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "These error gradients are used to update the weights of the network.",
            "zh": "è¿™äº›è¯¯å·®æ¢¯åº¦ç”¨äºæ›´æ–°ç½‘ç»œçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A summary of the tasks in the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process.",
            "zh": "CRISP-DM æµç¨‹çš„ä¸šåŠ¡ç†è§£ã€æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡é˜¶æ®µçš„ä»»åŠ¡æ‘˜è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Inspecting the right-hand column of this table and comparing the magnitude of the âˆ‚â„°/âˆ‚wi,k terms, the most significant digit in the âˆ‚â„°/âˆ‚wi,k terms for weights on inputs to Neuron 8 are at 10âˆ’2; by comparison the most significant digit for the âˆ‚â„°/âˆ‚wi,k terms for the weights on inputs to Neurons 3, 4, and 5 (the first hidden layer) are at 10âˆ’4.",
            "zh": "æ£€æŸ¥è¯¥è¡¨çš„å³åˆ—å¹¶æ¯”è¾ƒ âˆ‚E/âˆ‚wiï¼Œk é¡¹çš„å¤§å°ï¼Œâˆ‚E/âˆ‚wiï¼Œk é¡¹ä¸­ç¥ç»å…ƒ 8 è¾“å…¥æƒé‡çš„æœ€æœ‰æ•ˆæ•°å­—ä¸º 10âˆ’2;ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¥ç»å…ƒ 3ã€4 å’Œ 5ï¼ˆç¬¬ä¸€ä¸ªéšè—å±‚ï¼‰è¾“å…¥æƒé‡çš„ âˆ‚E/âˆ‚wiï¼Œk é¡¹çš„æœ€é«˜æœ‰æ•ˆæ•°å­—ä¸º 10âˆ’4ã€‚"
        }
    },
    {
        "translation": {
            "en": "UERR_U/G/R/I/Z",
            "zh": "UERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 4.18",
            "zh": "å›¾ 4.18"
        }
    },
    {
        "translation": {
            "en": "The second convolutional layer had 256 filters, and also used a ReLU non-linearity and max pooling.",
            "zh": "ç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰ 256 ä¸ªæ»¤æ³¢å™¨ï¼Œå¹¶ä¸”è¿˜ä½¿ç”¨äº† ReLU éçº¿æ€§å’Œæœ€å¤§æ± åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "probability mass, 266, 758",
            "zh": "æ¦‚ç‡è´¨é‡ï¼Œ266,758"
        }
    },
    {
        "translation": {
            "en": "TNR, 548",
            "zh": "TNRï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "However, today the most popular choice of function for an activation function is the rectified linear activation function or rectifier",
            "zh": "ç„¶è€Œï¼Œä»Šå¤©æœ€æµè¡Œçš„æ¿€æ´»å‡½æ•°é€‰æ‹©æ˜¯æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°æˆ–æ•´æµå™¨"
        }
    },
    {
        "translation": {
            "en": "In the sets shown in Figures 4.5(b)[124] and 4.5(c)[124], there is a mixture of two different types of cards, so that these have higher entropy valuesâ€”in these instances, 0.81 bits and 1.00 bit.",
            "zh": "åœ¨å›¾4.5ï¼ˆbï¼‰[124]å’Œå›¾4.5ï¼ˆcï¼‰[124]æ‰€ç¤ºçš„é›†åˆä¸­ï¼Œæ··åˆäº†ä¸¤ç§ä¸åŒç±»å‹çš„å¡ï¼Œå› æ­¤å®ƒä»¬å…·æœ‰æ›´é«˜çš„ç†µå€¼ - åœ¨è¿™äº›å®ä¾‹ä¸­ä¸º0.81ä½å’Œ1.00ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Decision trees are also considered non-parametric models.",
            "zh": "å†³ç­–æ ‘ä¹Ÿè¢«è§†ä¸ºéå‚æ•°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "anti-discrimination legislation, 40",
            "zh": "åæ­§è§†ç«‹æ³•ï¼Œ40"
        }
    },
    {
        "translation": {
            "en": "This compares favorably to a random player that will expect to lose on average $197 Â± 25 out of 1,000 hands.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œéšæœºç©å®¶é¢„è®¡åœ¨ 1,000 æ‰‹ç‰Œä¸­å¹³å‡è¾“æ‰ 197 Â± 25 ç¾å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "1.9â€ƒExercises",
            "zh": "1.9 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "In this case the logistic regression model used for the 3-level target feature would first be used, and then a model trained to distinguish only between different spiral galaxy types (clockwise, anti-clockwise, and edge-on) would be used to further classify those galaxy objects classified as spiral by the first stage.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå°†é¦–å…ˆä½¿ç”¨ç”¨äº 3 çº§ç›®æ ‡ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹ï¼Œç„¶åä½¿ç”¨ç»è¿‡è®­ç»ƒä»¥ä»…åŒºåˆ†ä¸åŒèºæ—‹æ˜Ÿç³»ç±»å‹ï¼ˆé¡ºæ—¶é’ˆã€é€†æ—¶é’ˆå’Œè¾¹ç¼˜ï¼‰çš„æ¨¡å‹å°†ç”¨äºè¿›ä¸€æ­¥åˆ†ç±»é‚£äº›æŒ‰ç¬¬ä¸€é˜¶æ®µå½’ç±»ä¸ºèºæ—‹æ˜Ÿç³»çš„æ˜Ÿç³»å¤©ä½“ã€‚"
        }
    },
    {
        "translation": {
            "en": "BIC, 292",
            "zh": "BICï¼Œ292"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9",
            "zh": "å›¾ 3.9"
        }
    },
    {
        "translation": {
            "en": "gamma function, 271",
            "zh": "ä¼½é©¬å‡½æ•°ï¼Œ271"
        }
    },
    {
        "translation": {
            "en": "For example, this allows us to use the probability of a patient having a fever given that the patient has meningitis, rather than the more constrained conditional probability of the patient having a fever given that the patient has meningitis and is suffering from a headache.",
            "zh": "ä¾‹å¦‚ï¼Œè¿™å…è®¸æˆ‘ä»¬ä½¿ç”¨æ‚£è€…å‘çƒ§çš„æ¦‚ç‡ï¼Œå› ä¸ºæ‚£è€…æ‚£æœ‰è„‘è†œç‚ï¼Œè€Œä¸æ˜¯æ‚£è€…å‘çƒ§çš„æ¡ä»¶æ¦‚ç‡ï¼Œå› ä¸ºæ‚£è€…æ‚£æœ‰è„‘è†œç‚å¹¶ä¸”æ‚£æœ‰å¤´ç—›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Strang, Gilbert. 2019. Linear algebra and learning from data. Wellesley-Cambridge Press.",
            "zh": "æ–¯ç‰¹æœ—ï¼Œå‰å°”ä¼¯ç‰¹ã€‚2019. çº¿æ€§ä»£æ•°ä¸æ•°æ®å­¦ä¹ .éŸ¦å°”æ–¯åˆ©-å‰‘æ¡¥å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) If the analyst was using a distance weighted averaging function rather than a simple average for his or her predictions, would this have made the analystâ€™s idea any more useful?",
            "zh": "ï¼ˆbï¼‰ å¦‚æœåˆ†æå‘˜ä½¿ç”¨è·ç¦»åŠ æƒå¹³å‡å‡½æ•°è€Œä¸æ˜¯ç®€å•å¹³å‡å€¼è¿›è¡Œé¢„æµ‹ï¼Œè¿™ä¼šä½¿åˆ†æå‘˜çš„æƒ³æ³•æ›´æœ‰ç”¨å—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "As a result, a naive Bayes model can be trained relatively quickly compared to many other prediction models.",
            "zh": "å› æ­¤ï¼Œä¸è®¸å¤šå…¶ä»–é¢„æµ‹æ¨¡å‹ç›¸æ¯”ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹å¯ä»¥ç›¸å¯¹å¿«é€Ÿåœ°è¿›è¡Œè®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "This type of learning illustrates one of the real strengths of the Bayesian network framework, namely, that it provides an approach to learning that naturally accommodates human expert information.",
            "zh": "è¿™ç§ç±»å‹çš„å­¦ä¹ è¯´æ˜äº†è´å¶æ–¯ç½‘ç»œæ¡†æ¶çš„çœŸæ­£ä¼˜åŠ¿ä¹‹ä¸€ï¼Œå³å®ƒæä¾›äº†ä¸€ç§è‡ªç„¶é€‚åº”äººç±»ä¸“å®¶ä¿¡æ¯çš„å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices showing the performance of models on the under-sampled training set.",
            "zh": "æ··æ·†çŸ©é˜µæ˜¾ç¤ºæ¨¡å‹åœ¨æ¬ é‡‡æ ·è®­ç»ƒé›†ä¸Šçš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Averaging across these localized values gives an overall measure of the overall quality of the clustering. The silhouette for a clustering will always be in the range from âˆ’ 1 to 1. A value near 1 suggests a good clustering, while a value near âˆ’ 1 suggests a poor clustering (with the caveat that these scores are based on the assumption about desired characteristics of a clustering described previously).",
            "zh": "å¯¹è¿™äº›å±€éƒ¨åŒ–å€¼è¿›è¡Œå¹³å‡å¯ä»¥æ€»ä½“è¡¡é‡èšç±»çš„æ•´ä½“è´¨é‡ã€‚èšç±»çš„è½®å»“å°†å§‹ç»ˆåœ¨ âˆ’ 1 åˆ° 1 çš„èŒƒå›´å†…ã€‚æ¥è¿‘ 1 çš„å€¼è¡¨ç¤ºèšç±»è‰¯å¥½ï¼Œè€Œæ¥è¿‘ âˆ’ 1 çš„å€¼è¡¨ç¤ºèšç±»è¾ƒå·®ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›åˆ†æ•°åŸºäºå‰é¢æè¿°çš„èšç±»æ‰€éœ€ç‰¹å¾çš„å‡è®¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We underestimated, however, the amount of support we would need and receive from other people.",
            "zh": "ç„¶è€Œï¼Œæˆ‘ä»¬ä½ä¼°äº†æˆ‘ä»¬éœ€è¦å’Œä»å…¶ä»–äººé‚£é‡Œå¾—åˆ°çš„æ”¯æŒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The observation period is the time prior to the claim event, over which the descriptive features capturing the claimantâ€™s behavior are calculated, and the outcome period is the time immediately after the claim event, during which it will emerge whether the claim is fraudulent or genuine.",
            "zh": "è§‚å¯ŸæœŸæ˜¯ç´¢èµ”äº‹ä»¶å‘ç”Ÿå‰çš„æ—¶é—´ï¼Œåœ¨è¯¥æ—¶é—´å†…è®¡ç®—æ•è·ç´¢èµ”äººè¡Œä¸ºçš„æè¿°æ€§ç‰¹å¾ï¼Œç»“æœæœŸæ˜¯ç´¢èµ”äº‹ä»¶å‘ç”Ÿåç«‹å³å‡ºç°çš„æ—¶é—´ï¼Œåœ¨æ­¤æœŸé—´ï¼Œç´¢èµ”æ˜¯æ¬ºè¯ˆæ€§çš„è¿˜æ˜¯çœŸå®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "GENDER: The patientâ€™s gender (male or female)",
            "zh": "æ€§åˆ«ï¼šæ‚£è€…çš„æ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Skew is simply a tendency toward very high (right skew as seen in Figure 3.2(c)[60]) or very low (left skew as seen in Figure 3.2(d)[60]) values.",
            "zh": "åæ–œåªæ˜¯è¶‹å‘äºéå¸¸é«˜ï¼ˆå›¾ 3.2ï¼ˆcï¼‰[60] æ‰€ç¤ºçš„å³åæ–œï¼‰æˆ–éå¸¸ä½ï¼ˆå›¾ 3.2ï¼ˆdï¼‰[60] æ‰€ç¤ºçš„å·¦åæ–œï¼‰å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "To calculate a probability using the Generalized Bayesâ€™ Theorem, we need to calculate three probabilities:",
            "zh": "è¦ä½¿ç”¨å¹¿ä¹‰è´å¶æ–¯å®šç†è®¡ç®—æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ä¸‰ä¸ªæ¦‚ç‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "To measure the color of night sky objects, the flux measured in different photometric bands is compared.",
            "zh": "ä¸ºäº†æµ‹é‡å¤œç©ºç‰©ä½“çš„é¢œè‰²ï¼Œæ¯”è¾ƒäº†åœ¨ä¸åŒå…‰åº¦æ³¢æ®µæµ‹é‡çš„é€šé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bar plots of the different galaxy types present in the full SDSS dataset for the 3-level and 5-level target features.",
            "zh": "å®Œæ•´ SDSS æ•°æ®é›†ä¸­ 3 çº§å’Œ 5 çº§ç›®æ ‡è¦ç´ ä¸­ä¸åŒæ˜Ÿç³»ç±»å‹çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Outliers (high)",
            "zh": "å¼‚å¸¸å€¼ï¼ˆé«˜ï¼‰"
        }
    },
    {
        "translation": {
            "en": "One of the most striking things about this plot is that the top-right region of the feature space again belongs to the no region.",
            "zh": "è¿™ä¸ªå›¾æœ€å¼•äººæ³¨ç›®çš„åœ°æ–¹ä¹‹ä¸€æ˜¯ï¼Œç‰¹å¾ç©ºé—´çš„å³ä¸Šè§’åŒºåŸŸå†æ¬¡å±äºæ— åŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "In this iteration the subtree underneath the root node of the decision tree (the CORE-TEMP node) is considered for pruning (i.e., the full decision tree).",
            "zh": "åœ¨æ­¤è¿­ä»£ä¸­ï¼Œè€ƒè™‘å¯¹å†³ç­–æ ‘æ ¹èŠ‚ç‚¹ï¼ˆCORE-TEMP èŠ‚ç‚¹ï¼‰ä¸‹çš„å­æ ‘è¿›è¡Œä¿®å‰ªï¼ˆå³å®Œæ•´çš„å†³ç­–æ ‘ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the customerâ€™s peak calls to off-peak calls ratio has changed from last month to this month",
            "zh": "ä»ä¸Šä¸ªæœˆåˆ°æœ¬æœˆï¼Œå®¢æˆ·çš„é«˜å³°å‘¼å«ä¸éé«˜å³°å‘¼å«æ¯”ç‡çš„ç™¾åˆ†æ¯”å‘ç”Ÿäº†å˜åŒ–"
        }
    },
    {
        "translation": {
            "en": "Kronecker delta, 192, 195",
            "zh": "å…‹ç½—å†…å…‹ä¸‰è§’æ´²ï¼Œ 192ï¼Œ 195"
        }
    },
    {
        "translation": {
            "en": "However, we do not need to change anything with regard to the calculation of the Î´s for the hidden neurons; once we have updated the calculation of the Î´s for the output neurons, then the error gradients can flow back through the network as previously.",
            "zh": "ç„¶è€Œï¼Œæˆ‘ä»¬ä¸éœ€è¦æ”¹å˜éšè—ç¥ç»å…ƒçš„Î´sçš„è®¡ç®—;ä¸€æ—¦æˆ‘ä»¬æ›´æ–°äº†è¾“å‡ºç¥ç»å…ƒçš„ Î´ è®¡ç®—ï¼Œé‚£ä¹ˆè¯¯å·®æ¢¯åº¦å°±å¯ä»¥åƒä»¥å‰ä¸€æ ·æµå›ç½‘ç»œã€‚"
        }
    },
    {
        "translation": {
            "en": "Throughout this chapter, named features will be denoted by the uppercase initial letters of their namesâ€”for example, a feature named MENINGITIS will be denoted by M. Also, where a named feature is binary, we will use the lowercase initial letter of the feature name to denote the event where the feature is true and the lowercase initial letter preceded by the Â¬ symbol to denote the event where it is false.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œå‘½åçš„ç‰¹å¾å°†ç”¨å…¶åç§°çš„å¤§å†™é¦–å­—æ¯è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼Œåä¸ºè„‘è†œç‚çš„ç‰¹å¾å°†ç”¨ M è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œå¦‚æœå‘½åç‰¹å¾æ˜¯äºŒè¿›åˆ¶çš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç‰¹å¾åç§°çš„å°å†™é¦–å­—æ¯æ¥è¡¨ç¤ºç‰¹å¾ä¸ºçœŸçš„äº‹ä»¶ï¼Œå¹¶ä½¿ç”¨å°å†™çš„é¦–å­—æ¯å‰é¢åŠ ä¸Š Â¬ ç¬¦å·æ¥è¡¨ç¤ºå®ƒä¸ºå‡çš„äº‹ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "23. These values are recommended by Sutton and Barto (2018) but can be tuned through experimentation.",
            "zh": "23. è¿™äº›å€¼æ˜¯ Sutton å’Œ Barto ï¼ˆ2018ï¼‰ æ¨èçš„ï¼Œä½†å¯ä»¥é€šè¿‡å®éªŒè¿›è¡Œè°ƒæ•´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The normal and the student-t distributions are both very similar, and both do a good job of matching the shape of the density histogram.",
            "zh": "æ­£æ€åˆ†å¸ƒå’Œ student-t åˆ†å¸ƒéƒ½éå¸¸ç›¸ä¼¼ï¼Œå¹¶ä¸”éƒ½å¾ˆå¥½åœ°åŒ¹é…äº†å¯†åº¦ç›´æ–¹å›¾çš„å½¢çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process that the AT retention team had in place at the beginning of the project to identify customers likely to churn took a single feature approach to this identificationâ€”they looked only at how many calls a customer had made to the AT customer support service.",
            "zh": "AT ä¿ç•™å›¢é˜Ÿåœ¨é¡¹ç›®å¼€å§‹æ—¶ä¸ºè¯†åˆ«å¯èƒ½æµå¤±çš„å®¢æˆ·è€Œåˆ¶å®šçš„æµç¨‹é‡‡ç”¨äº†å•ä¸€åŠŸèƒ½æ–¹æ³•æ¥è¯†åˆ«æ­¤è¯†åˆ«â€”â€”ä»–ä»¬åªæŸ¥çœ‹å®¢æˆ·å‘ AT å®¢æˆ·æ”¯æŒæœåŠ¡æ‹¨æ‰“äº†å¤šå°‘ç”µè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This raises the question of when to use which machine learning approach.",
            "zh": "è¿™å°±æå‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼Œå³ä½•æ—¶ä½¿ç”¨å“ªç§æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have covered three architectures in this chapter: feedforward networks are appropriate if the descriptive features are in a fixed-sized vector; if the input data has a grid-like structure, then consider a convolutional neural network; and if the input may be a variable length sequence, then a recurrent neural network or LSTM network will be most appropriate.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸‰ç§æ¶æ„ï¼šå¦‚æœæè¿°æ€§ç‰¹å¾ä½äºå›ºå®šå¤§å°çš„å‘é‡ä¸­ï¼Œåˆ™å‰é¦ˆç½‘ç»œæ˜¯åˆé€‚çš„;å¦‚æœè¾“å…¥æ•°æ®å…·æœ‰ç±»ä¼¼ç½‘æ ¼çš„ç»“æ„ï¼Œåˆ™è€ƒè™‘å·ç§¯ç¥ç»ç½‘ç»œ;å¦‚æœè¾“å…¥å¯èƒ½æ˜¯å¯å˜é•¿åº¦åºåˆ—ï¼Œåˆ™é€’å½’ç¥ç»ç½‘ç»œæˆ– LSTM ç½‘ç»œå°†æ˜¯æœ€åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the generation process proves to be error-free, then features with a cardinality of 1, although valid, should be removed from an ABT because they will not be of any value in building predictive models.",
            "zh": "å¦‚æœç”Ÿæˆè¿‡ç¨‹è¢«è¯æ˜æ˜¯æ— é”™è¯¯çš„ï¼Œåˆ™åŸºæ•°ä¸º 1 çš„ç‰¹å¾è™½ç„¶æœ‰æ•ˆï¼Œä½†åº”ä» ABT ä¸­åˆ é™¤ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ„å»ºé¢„æµ‹æ¨¡å‹æ–¹é¢æ²¡æœ‰ä»»ä½•ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "If you lie too far forward on your board, you will begin to make great progress before the surfboard tilts nose down into the water and launches you head over heels into the air.",
            "zh": "å¦‚æœä½ åœ¨å†²æµªæ¿ä¸Šèººå¾—å¤ªé å‰ï¼Œä½ ä¼šåœ¨å†²æµªæ¿å°†é¼»å­å‘ä¸‹å€¾æ–œåˆ°æ°´ä¸­å¹¶å°†ä½ å¤´é¡¶åˆ°ç©ºä¸­ä¹‹å‰å¼€å§‹å–å¾—å¾ˆå¤§çš„è¿›æ­¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Edwin helped Jocelyn align the columns in the raw SDSS dataset with the different domain concepts, which generated a good set of descriptive features within each domain concept.",
            "zh": "Edwin å¸®åŠ© Jocelyn å°†åŸå§‹ SDSS æ•°æ®é›†ä¸­çš„åˆ—ä¸ä¸åŒçš„é¢†åŸŸæ¦‚å¿µå¯¹é½ï¼Œä»è€Œåœ¨æ¯ä¸ªé¢†åŸŸæ¦‚å¿µä¸­ç”Ÿæˆäº†ä¸€ç»„å¾ˆå¥½çš„æè¿°æ€§ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If new instances were added to the dataset and we rebuilt the tree, it is likely that we would end up with a (potentially very) different tree.",
            "zh": "å¦‚æœå°†æ–°å®ä¾‹æ·»åŠ åˆ°æ•°æ®é›†ä¸­å¹¶é‡æ–°æ„å»ºæ ‘ï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½æœ€ç»ˆä¼šå¾—åˆ°ä¸€æ£µï¼ˆå¯èƒ½éå¸¸ï¼‰ä¸åŒçš„æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is relatively straightforward to fit the parameters, Î¼ and Ïƒ, of the normal distribution to a dataset by using the sample mean and standard deviation of the feature values in a dataset as estimates of Î¼ and Ïƒ respectively.",
            "zh": "é€šè¿‡ä½¿ç”¨æ•°æ®é›†ä¸­ç‰¹å¾å€¼çš„æ ·æœ¬å‡å€¼å’Œæ ‡å‡†å·®åˆ†åˆ«ä½œä¸º Î¼ å’Œ Ïƒ çš„ä¼°è®¡å€¼ï¼Œå°†æ­£æ€åˆ†å¸ƒçš„å‚æ•° Î¼ å’Œ Ïƒ æ‹Ÿåˆåˆ°æ•°æ®é›†ç›¸å¯¹ç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This will allow Conor to make good choices based on his current knowledge, but also to explore new items and learn about the rewards associated with them.",
            "zh": "è¿™å°†ä½¿åº·çº³èƒ½å¤Ÿæ ¹æ®ä»–ç›®å‰çš„çŸ¥è¯†åšå‡ºæ­£ç¡®çš„é€‰æ‹©ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥æ¢ç´¢æ–°ç‰©å“å¹¶äº†è§£ä¸ä¹‹ç›¸å…³çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "24. The name SARSA comes from the terms st, at, rt, st+1, and at+1 used in the algorithm and the order in which they appear.",
            "zh": "24. SARSA çš„åç§°æ¥æºäºç®—æ³•ä¸­ä½¿ç”¨çš„æœ¯è¯­ stã€atã€rtã€st+1 å’Œ at+1 ä»¥åŠå®ƒä»¬å‡ºç°çš„é¡ºåºã€‚"
        }
    },
    {
        "translation": {
            "en": "If we were to use a model that includes salary values over an extended period (for example, 10 years) the salary values used to initially train the model may have no relationship to the values that would be presented to the model later on.",
            "zh": "å¦‚æœæˆ‘ä»¬è¦ä½¿ç”¨åŒ…å«è¾ƒé•¿æ—¶é—´ï¼ˆä¾‹å¦‚ï¼Œ10 å¹´ï¼‰çš„å·¥èµ„å€¼çš„æ¨¡å‹ï¼Œåˆ™ç”¨äºåˆå§‹è®­ç»ƒæ¨¡å‹çš„å·¥èµ„å€¼å¯èƒ½ä¸ä»¥åå°†å‘ˆç°ç»™æ¨¡å‹çš„å€¼æ²¡æœ‰å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "forward sequential selection, 229",
            "zh": "å‰å‘é¡ºåºé€‰æ‹©ï¼Œ229"
        }
    },
    {
        "translation": {
            "en": "NEWFREQUENTNUMBERS",
            "zh": "æ–°é¢‘æ•°"
        }
    },
    {
        "translation": {
            "en": "We now understand the standard nearest neighbor algorithm. The algorithm, as presented, can work well with clean, reasonably sized datasets containing continuous descriptive features. Often, however, datasets are noisy, very large, and may contain a mixture of different data types. As a result, a lot of extensions and variations of the algorithm have been developed to address these issues. In this section we describe the most important of these.",
            "zh": "æˆ‘ä»¬ç°åœ¨äº†è§£äº†æ ‡å‡†çš„æœ€è¿‘é‚»ç®—æ³•ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œè¯¥ç®—æ³•å¯ä»¥å¾ˆå¥½åœ°å¤„ç†åŒ…å«è¿ç»­æè¿°æ€§ç‰¹å¾çš„å¹²å‡€ã€åˆç†å¤§å°çš„æ•°æ®é›†ã€‚ä½†æ˜¯ï¼Œæ•°æ®é›†é€šå¸¸å¾ˆå˜ˆæ‚ï¼Œéå¸¸å¤§ï¼Œå¹¶ä¸”å¯èƒ½åŒ…å«ä¸åŒæ•°æ®ç±»å‹çš„æ··åˆã€‚å› æ­¤ï¼Œå·²ç»å¼€å‘äº†è®¸å¤šç®—æ³•çš„æ‰©å±•å’Œå˜ä½“æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å…¶ä¸­æœ€é‡è¦çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Approaches that do this are referred to as approximate methods.",
            "zh": "æ‰§è¡Œæ­¤æ“ä½œçš„æ–¹æ³•ç§°ä¸ºè¿‘ä¼¼æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "use limitation principle, 41",
            "zh": "ä½¿ç”¨é™åˆ¶åŸåˆ™ï¼Œ41"
        }
    },
    {
        "translation": {
            "en": "We should take care when using standardization as it assumes that data is normally distributed.",
            "zh": "åœ¨ä½¿ç”¨æ ‡å‡†åŒ–æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°å¿ƒï¼Œå› ä¸ºå®ƒå‡è®¾æ•°æ®æ˜¯æ­£æ€åˆ†å¸ƒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can modify Equation (11.3)[641] to define discounted return",
            "zh": "æˆ‘ä»¬å¯ä»¥ä¿®æ”¹ç­‰å¼ï¼ˆ11.3ï¼‰[641]æ¥å®šä¹‰è´´ç°å›æŠ¥"
        }
    },
    {
        "translation": {
            "en": "Many of these states, however, or not significantly different from each other and so it makes sense to discretize the hand representation so as to have a smaller number of states.",
            "zh": "ç„¶è€Œï¼Œè¿™äº›çŠ¶æ€ä¸­çš„è®¸å¤šçŠ¶æ€æˆ–å½¼æ­¤ä¹‹é—´æ²¡æœ‰æ˜¾ç€å·®å¼‚ï¼Œå› æ­¤ç¦»æ•£åŒ–æ‰‹è¡¨ç¤ºä»¥å…·æœ‰è¾ƒå°‘æ•°é‡çš„çŠ¶æ€æ˜¯æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Reading from left to right, the first term in this product is the rate of change of the error gradient of the network with respect to changes in the activation (or output) of a neuron i; the second term is the rate of change of the activation of neuron i with respect to changes in zi (the weighted sum for neuron i); and the third term is the rate of change of zi with respect to changes in the weight wi,k.",
            "zh": "ä»å·¦åˆ°å³é˜…è¯»ï¼Œæœ¬äº§å“ä¸­çš„ç¬¬ä¸€ä¸ªé¡¹æ˜¯ç½‘ç»œè¯¯å·®æ¢¯åº¦ç›¸å¯¹äºç¥ç»å…ƒ i æ¿€æ´»ï¼ˆæˆ–è¾“å‡ºï¼‰å˜åŒ–çš„å˜åŒ–ç‡;ç¬¬äºŒé¡¹æ˜¯ç¥ç»å…ƒ I æ¿€æ´»ç›¸å¯¹äº zi å˜åŒ–çš„å˜åŒ–ç‡ï¼ˆç¥ç»å…ƒ i çš„åŠ æƒå’Œï¼‰;ç¬¬ä¸‰é¡¹æ˜¯ zi ç›¸å¯¹äºæƒé‡ wiï¼Œk å˜åŒ–çš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this challenge the scout begins at the edge of the bank on one side of the stream and has to make a series of steps to get to the other side.",
            "zh": "åœ¨è¿™ä¸ªæŒ‘æˆ˜ä¸­ï¼Œä¾¦å¯Ÿå‘˜ä»æºªæµä¸€ä¾§çš„æ²³å²¸è¾¹ç¼˜å¼€å§‹ï¼Œå¿…é¡»é‡‡å–ä¸€ç³»åˆ—æ­¥éª¤æ‰èƒ½åˆ°è¾¾å¦ä¸€ä¾§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the gradient boosting approach is most easily explained in the context of predicting continuous targets, it can also be easily adapted to work with categorical targets.",
            "zh": "å°½ç®¡æ¢¯åº¦æå‡æ–¹æ³•åœ¨é¢„æµ‹è¿ç»­ç›®æ ‡çš„ä¸Šä¸‹æ–‡ä¸­æœ€å®¹æ˜“è§£é‡Šï¼Œä½†å®ƒä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°é€‚åº”åˆ†ç±»ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distribution of INSURANCE TYPE is a little strange, as it displays only one level.",
            "zh": "INSURANCE TYPEçš„åˆ†å¸ƒæœ‰ç‚¹å¥‡æ€ªï¼Œå› ä¸ºå®ƒåªæ˜¾ç¤ºä¸€ä¸ªçº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "The naive Bayes model can also be easily adapted to handle missing feature values: we simply drop the conditional probabilities for the evidence events that specify features taking values that are not in the data from the product of the evidence events. Obviously, doing this may have a negative effect on the accuracy of posterior probabilities computed by the model, but again this may not translate directly into prediction errors.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹ä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°é€‚åº”å¤„ç†ç¼ºå¤±çš„ç‰¹å¾å€¼ï¼šæˆ‘ä»¬åªéœ€ä»è¯æ®äº‹ä»¶çš„ä¹˜ç§¯ä¸­å»é™¤è¯æ®äº‹ä»¶çš„æ¡ä»¶æ¦‚ç‡ï¼Œè¿™äº›äº‹ä»¶æŒ‡å®šç‰¹å¾é‡‡ç”¨ä¸åœ¨æ•°æ®ä¸­çš„å€¼ã€‚æ˜¾ç„¶ï¼Œè¿™æ ·åšå¯èƒ½ä¼šå¯¹æ¨¡å‹è®¡ç®—çš„åéªŒæ¦‚ç‡çš„å‡†ç¡®æ€§äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä½†è¿™å¯èƒ½ä¸ä¼šç›´æ¥è½¬åŒ–ä¸ºé¢„æµ‹è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.5253",
            "zh": "-0.5253"
        }
    },
    {
        "translation": {
            "en": "Information provided at registration includes the type of industry the company is involved in, details of the directors of the company, and where the company is located.",
            "zh": "æ³¨å†Œæ—¶æä¾›çš„ä¿¡æ¯åŒ…æ‹¬å…¬å¸æ‰€ä»äº‹çš„è¡Œä¸šç±»å‹ã€å…¬å¸è‘£äº‹çš„è¯¦ç»†ä¿¡æ¯ä»¥åŠå…¬å¸æ‰€åœ¨åœ°ã€‚"
        }
    },
    {
        "translation": {
            "en": "17. The features selected were SKYIVAR_U, PETROFLUXIVAR_I, PETROR50ERR_G, DEVRAD_G, DEVRADERR_R, DEVRADERR_I, DEVAB_G, EXPFLUX_Z, APERFLUX7_Z, APERFLUX7IVAR_R, and MODELMAGDIFF_I_Z.",
            "zh": "17. é€‰å®šçš„ç‰¹å¾æ˜¯SKYIVAR_Uã€PETROFLUXIVAR_Iã€PETROR50ERR_Gã€DEVRAD_Gã€DEVRADERR_Rã€DEVRADERR_Iã€DEVAB_Gã€EXPFLUX_Zã€APERFLUX7_Zã€APERFLUX7IVAR_Rå’ŒMODELMAGDIFF_I_Zã€‚"
        }
    },
    {
        "translation": {
            "en": "We can convert a histogram to a probability distribution by dividing the count for each interval by the total number of observations in the dataset multiplied by the width of the interval.",
            "zh": "æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ¯ä¸ªåŒºé—´çš„è®¡æ•°é™¤ä»¥æ•°æ®é›†ä¸­çš„è§‚æµ‹å€¼æ€»æ•°ä¹˜ä»¥åŒºé—´å®½åº¦æ¥å°†ç›´æ–¹å›¾è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Jaccard index, 215, 231",
            "zh": "æ°å¡å¾·ç´¢å¼•ï¼Œ215,231"
        }
    },
    {
        "translation": {
            "en": "For example, if a customer who really was not a churn risk is classified as likely to churn, the cost incurred by the company because of this mistake is the cost of a small bonus offer that would be given to the customer to entice the customer to stay with the company.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªçœŸæ­£æ²¡æœ‰æµå¤±é£é™©çš„å®¢æˆ·è¢«å½’ç±»ä¸ºå¯èƒ½æµå¤±ï¼Œé‚£ä¹ˆå…¬å¸å› è¿™ä¸ªé”™è¯¯è€Œäº§ç”Ÿçš„æˆæœ¬æ˜¯å‘å®¢æˆ·æä¾›å°é¢å¥–é‡‘çš„æˆæœ¬ï¼Œä»¥å¸å¼•å®¢æˆ·ç•™åœ¨å…¬å¸ã€‚"
        }
    },
    {
        "translation": {
            "en": "By combining measures in this way, we can apply nearest neighbor models to any dataset.",
            "zh": "é€šè¿‡ä»¥è¿™ç§æ–¹å¼ç»„åˆåº¦é‡ï¼Œæˆ‘ä»¬å¯ä»¥å°†æœ€è¿‘é‚»æ¨¡å‹åº”ç”¨äºä»»ä½•æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The sets shown in Figures 4.5(d)[124] and 4.5(e)[124] both have three types of cards.",
            "zh": "å›¾4.5ï¼ˆdï¼‰[124]å’Œå›¾4.5ï¼ˆeï¼‰[124]æ‰€ç¤ºçš„ç‰Œç»„éƒ½æœ‰ä¸‰ç§ç±»å‹çš„ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean results in a more pessimistic view of model performance than an arithmetic mean.",
            "zh": "ä¸ç®—æœ¯å‡å€¼ç›¸æ¯”ï¼Œè°æ³¢å‡å€¼å¯¼è‡´å¯¹æ¨¡å‹æ€§èƒ½çš„çœ‹æ³•æ›´æ‚²è§‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these situations, as k increases, the majority target level begins to dominate the feature space.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œéšç€ k çš„å¢åŠ ï¼Œå¤šæ•°ç›®æ ‡çº§åˆ«å¼€å§‹ä¸»å¯¼ç‰¹å¾ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "We see in subsequent examples that designing good state representations is one of the arts of reinforcement learning.",
            "zh": "åœ¨éšåçš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°è®¾è®¡è‰¯å¥½çš„çŠ¶æ€è¡¨ç¤ºæ˜¯å¼ºåŒ–å­¦ä¹ çš„è‰ºæœ¯ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Checking for features with a low cardinality will highlight these features.",
            "zh": "æ£€æŸ¥å…·æœ‰ä½åŸºæ•°çš„è¦ç´ å°†çªå‡ºæ˜¾ç¤ºè¿™äº›è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tesauro, Gerald. 1994. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Computation 6 (2): 215â€“219.",
            "zh": "ç‰¹ç´¢ç½—ï¼Œæ°æ‹‰å°”å¾·ã€‚1994. TD-gammonï¼Œä¸€ä¸ªè‡ªå­¦çš„è¥¿æ´‹åŒé™†æ£‹é¡¹ç›®ï¼Œå®ç°äº†å¤§å¸ˆçº§æ¸¸æˆã€‚ç¥ç»è®¡ç®—6ï¼ˆ2ï¼‰ï¼š215-219ã€‚"
        }
    },
    {
        "translation": {
            "en": "The distinctive characteristic of deep learning models is that they are deeper and larger than older neural networks.",
            "zh": "æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ˜¾ç€ç‰¹å¾æ˜¯å®ƒä»¬æ¯”æ—§çš„ç¥ç»ç½‘ç»œæ›´æ·±ã€æ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The new value for the selected node is drawn from the distribution for the node (the CPT), conditioned on the current state of all the other nodes in the network.",
            "zh": "æ‰€é€‰èŠ‚ç‚¹çš„æ–°å€¼æ˜¯ä»èŠ‚ç‚¹çš„åˆ†å¸ƒ ï¼ˆCPTï¼‰ ä¸­æå–çš„ï¼Œä»¥ç½‘ç»œä¸­æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹çš„å½“å‰çŠ¶æ€ä¸ºæ¡ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.11â€…â€…â€…(a) A Bayesian network representation of the conditional independence asserted by a naive Bayes model between the descriptive features given knowledge of the target feature; and (b) a Bayesian network representation of the conditional independence assumption for the naive Bayes model in the fraud example.",
            "zh": "6.11 ï¼ˆaï¼‰ æœ´ç´ è´å¶æ–¯æ¨¡å‹åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œåœ¨æè¿°æ€§ç‰¹å¾ä¹‹é—´æ–­è¨€æ¡ä»¶ç‹¬ç«‹æ€§çš„è´å¶æ–¯ç½‘ç»œè¡¨ç¤º;ï¼ˆbï¼‰æ¬ºè¯ˆç¤ºä¾‹ä¸­æœ´ç´ è´å¶æ–¯æ¨¡å‹çš„æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾çš„è´å¶æ–¯ç½‘ç»œè¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "A relevant point from that discussion was that large weight updates could result in the error actually increasing (see Figure 7.9[336]).",
            "zh": "è¯¥è®¨è®ºçš„ä¸€ä¸ªç›¸å…³è§‚ç‚¹æ˜¯ï¼Œè¾ƒå¤§çš„æƒé‡æ›´æ–°å¯èƒ½å¯¼è‡´è¯¯å·®å®é™…å¢åŠ ï¼ˆå‚è§å›¾7.9[336]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weight of a component in the sum determines the contribution of the component to the overall density of the resulting mixture.",
            "zh": "æ€»å’Œä¸­ç»„åˆ†çš„é‡é‡å†³å®šäº†ç»„åˆ†å¯¹æ‰€å¾—æ··åˆç‰©æ€»å¯†åº¦çš„è´¡çŒ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Information gain has the advantage that it is computationally less expensive than information gain ratio.",
            "zh": "ä¿¡æ¯å¢ç›Šçš„ä¼˜ç‚¹æ˜¯å®ƒåœ¨è®¡ç®—ä¸Šæ¯”ä¿¡æ¯å¢ç›Šæ¯”ä¾¿å®œã€‚"
        }
    },
    {
        "translation": {
            "en": "The predictions using the k = 3 nearest neighbor model and the weighted k nearest neighbor model with k set to the size of the dataset are quite similar: 168.33 and 163.71.",
            "zh": "ä½¿ç”¨ k = 3 æœ€è¿‘é‚»æ¨¡å‹å’Œå°† k è®¾ç½®ä¸ºæ•°æ®é›†å¤§å°çš„åŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹çš„é¢„æµ‹éå¸¸ç›¸ä¼¼ï¼š168.33 å’Œ 163.71ã€‚"
        }
    },
    {
        "translation": {
            "en": "Compare the amount of computation required to calculate the output of the support vector machine using the polynomial kernel function with the amount required to calculate the output of the support vector machine using the basis functions.",
            "zh": "æ¯”è¾ƒä½¿ç”¨å¤šé¡¹å¼æ ¸å‡½æ•°è®¡ç®—æ”¯æŒå‘é‡æœºè¾“å‡ºæ‰€éœ€çš„è®¡ç®—é‡ä¸ä½¿ç”¨åŸºå‡½æ•°è®¡ç®—æ”¯æŒå‘é‡æœºè¾“å‡ºæ‰€éœ€çš„è®¡ç®—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the other hand, if you ask Question 1 first, there is only one sequence of questions with which to follow it. This sequence is shown in Figure 4.3[120]. Irrespective of the answers to the questions, you always have to follow a path through this sequence that is 2 questions long to reach an answer about the character on a card. This means that if you always ask Question 1 first, the average number of questions you have to ask per game is",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæ‚¨å…ˆé—®é—®é¢˜ 1ï¼Œåˆ™åªæœ‰ä¸€ç»„é—®é¢˜å¯ä»¥ç´§éšå…¶åã€‚è¯¥åºåˆ—å¦‚å›¾4.3[120]æ‰€ç¤ºã€‚æ— è®ºé—®é¢˜çš„ç­”æ¡ˆå¦‚ä½•ï¼Œæ‚¨å§‹ç»ˆå¿…é¡»éµå¾ªæ­¤åºåˆ—çš„è·¯å¾„ï¼Œè¯¥è·¯å¾„é•¿è¾¾ 2 ä¸ªé—®é¢˜ï¼Œæ‰èƒ½è·å¾—æœ‰å…³å¡ç‰‡ä¸Šè§’è‰²çš„ç­”æ¡ˆã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæ‚¨æ€»æ˜¯å…ˆé—®é—®é¢˜ 1ï¼Œé‚£ä¹ˆæ¯åœºæ¯”èµ›æ‚¨å¿…é¡»é—®çš„å¹³å‡é—®é¢˜æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "2. then using Bayesâ€™ Theorem to compute the class posterior probabilities P(tl|d);2",
            "zh": "2.ç„¶åä½¿ç”¨è´å¶æ–¯å®šç†è®¡ç®—ç±»åéªŒæ¦‚ç‡Pï¼ˆtl|dï¼‰;2"
        }
    },
    {
        "translation": {
            "en": "Table 6.10",
            "zh": "è¡¨ 6.10"
        }
    },
    {
        "translation": {
            "en": "Consequently, it is standard to use a patience parameter to control early stopping.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨è€å¿ƒå‚æ•°æ¥æ§åˆ¶æå‰åœæ­¢æ˜¯æ ‡å‡†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "D.3â€ƒMultiplication",
            "zh": "D.3 ä¹˜æ³•"
        }
    },
    {
        "translation": {
            "en": "Tabulating the workings required to calculate gain, cumulative gain, lift, and cumulative lift for the data given in Table 9.11[557].",
            "zh": "å°†è®¡ç®—è¡¨9.11[557]ä¸­ç»™å‡ºçš„æ•°æ®çš„å¢ç›Šã€ç´¯ç§¯å¢ç›Šã€å‡åŠ›å’Œç´¯ç§¯å‡åŠ›æ‰€éœ€çš„å·¥ä½œåˆ¶æˆè¡¨æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using partial derivatives offers us an easy way to calculate the derivative of a function like this.",
            "zh": "ä½¿ç”¨åå¯¼æ•°ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥è®¡ç®—è¿™æ ·çš„å‡½æ•°çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was an important step in gaining credibility for the model.",
            "zh": "è¿™æ˜¯è·å¾—è¯¥æ¨¡å‹å¯ä¿¡åº¦çš„é‡è¦ä¸€æ­¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.1.3â€ƒVisualizing a categorical feature and a continuous featureâ€ƒThe best way to visualize the relationship between a continuous feature and a categorical feature is to use a small multiples approach, drawing a density histogram of the values of the continuous feature for each level of the categorical feature.",
            "zh": "3.5.1.3 å¯è§†åŒ–åˆ†ç±»ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ å¯è§†åŒ–è¿ç»­ç‰¹å¾å’Œåˆ†ç±»ç‰¹å¾ä¹‹é—´å…³ç³»çš„æœ€ä½³æ–¹æ³•æ˜¯ä½¿ç”¨å°å€æ•°æ–¹æ³•ï¼Œä¸ºåˆ†ç±»ç‰¹å¾çš„æ¯ä¸ªçº§åˆ«ç»˜åˆ¶è¿ç»­ç‰¹å¾å€¼çš„å¯†åº¦ç›´æ–¹å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The details of a professional basketball team.",
            "zh": "èŒä¸šç¯®çƒé˜Ÿçš„ç»†èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was likely to continue to be the case, so any solution that relied on spectrographic data as well as imaging data to classify galaxy types would work for only a fraction of the observations made by the SDSS telescopes.",
            "zh": "è¿™ç§æƒ…å†µå¯èƒ½ä¼šç»§ç»­ä¸‹å»ï¼Œå› æ­¤ä»»ä½•ä¾é å…‰è°±æ•°æ®å’Œæˆåƒæ•°æ®å¯¹æ˜Ÿç³»ç±»å‹è¿›è¡Œåˆ†ç±»çš„è§£å†³æ–¹æ¡ˆéƒ½åªé€‚ç”¨äºSDSSæœ›è¿œé•œè§‚æµ‹çš„ä¸€å°éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.3â€ƒChoosing Learning Rates and Initial Weights",
            "zh": "7.3.3 é€‰æ‹©å­¦ä¹ ç‡å’Œåˆå§‹æƒé‡"
        }
    },
    {
        "translation": {
            "en": "This domain subconcept captures the variety of claim types made by the claimant in the past, as these might provide evidence of possible fraud.",
            "zh": "è¯¥åŸŸå­æ¦‚å¿µæ•è·äº†ç´¢èµ”äººè¿‡å»æå‡ºçš„å„ç§ç´¢èµ”ç±»å‹ï¼Œå› ä¸ºè¿™äº›ç´¢èµ”ç±»å‹å¯èƒ½æä¾›å¯èƒ½çš„æ¬ºè¯ˆè¯æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, the Theorem of Total Probability defines the unconditional probability for any event X as",
            "zh": "æœ€åï¼Œæ€»æ¦‚ç‡å®šç†å°†ä»»ä½•äº‹ä»¶ X çš„æ— æ¡ä»¶æ¦‚ç‡å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "4.4.4â€ƒTree Pruning",
            "zh": "4.4.4 æ ‘æœ¨ä¿®å‰ª"
        }
    },
    {
        "translation": {
            "en": "As a result of this recursive summing out, the distribution over a node is dependent on knowledge of the ancestors of any of its parent nodes.22 For example, in Figure 6.9(b)[287], if the status of node C is not known, then node B becomes dependent on node D. For example, to compute P(b | a,d) we would do the following calculations:",
            "zh": "22 ä¾‹å¦‚ï¼Œåœ¨å›¾ 6.9ï¼ˆbï¼‰[287] ä¸­ï¼Œå¦‚æœèŠ‚ç‚¹ C çš„çŠ¶æ€æœªçŸ¥ï¼Œåˆ™èŠ‚ç‚¹ B å°†ä¾èµ–äºèŠ‚ç‚¹ Dã€‚ä¾‹å¦‚ï¼Œä¸ºäº†è®¡ç®— Pï¼ˆb | aï¼Œdï¼‰ï¼Œæˆ‘ä»¬å°†è¿›è¡Œä»¥ä¸‹è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "The obvious way to do this is to have the model return the target level that has the highest posterior probability given the state of the descriptive features in the query.",
            "zh": "æ‰§è¡Œæ­¤æ“ä½œçš„æ˜æ˜¾æ–¹æ³•æ˜¯è®©æ¨¡å‹è¿”å›ç»™å®šæŸ¥è¯¢ä¸­æè¿°æ€§ç‰¹å¾çŠ¶æ€æ—¶å…·æœ‰æœ€é«˜åéªŒæ¦‚ç‡çš„ç›®æ ‡çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "softmax function, 463, 658",
            "zh": "softmaxå‡½æ•°ï¼Œ463,658"
        }
    },
    {
        "translation": {
            "en": "This finding is notorious in the history of neural networks.",
            "zh": "è¿™ä¸€å‘ç°åœ¨ç¥ç»ç½‘ç»œçš„å†å²ä¸Šæ˜¯è‡­åæ˜­è‘—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once Jocelyn felt that she was suitably fluent with the SDSS situation, she proceeded to the Data Understanding phase of the CRISP-DM process so as to better understand the data available.",
            "zh": "ä¸€æ—¦ Jocelyn è®¤ä¸ºå¥¹å¯¹ SDSS æƒ…å†µéå¸¸æµåˆ©ï¼Œå¥¹å°±è¿›å…¥äº† CRISP-DM æµç¨‹çš„æ•°æ®ç†è§£é˜¶æ®µï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å¯ç”¨æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from the test of the AT churn prediction stratified hold-out test set using the pruned decision tree in Figure 12.5[699].",
            "zh": "ä½¿ç”¨å›¾ 12.5 [699] ä¸­ä¿®å‰ªåçš„å†³ç­–æ ‘ï¼Œæ¥è‡ª AT æµå¤±é¢„æµ‹åˆ†å±‚ä¿æŒæµ‹è¯•é›†çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "1. All the instances in the dataset have the same target feature level. In this situation, the algorithm returns a single leaf node tree with that target level as its label (Algorithm 1[134] Lines 1â€“2).",
            "zh": "1. æ•°æ®é›†ä¸­çš„æ‰€æœ‰å®ä¾‹éƒ½å…·æœ‰ç›¸åŒçš„ç›®æ ‡ç‰¹å¾çº§åˆ«ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç®—æ³•è¿”å›ä¸€ä¸ªä»¥è¯¥ç›®æ ‡çº§åˆ«ä¸ºæ ‡ç­¾çš„å•å¶èŠ‚ç‚¹æ ‘ï¼ˆç®—æ³• 1[134] ç¬¬ 1-2 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Eager learners abstract away from the data during training and use this abstraction to make predictions, rather than directly comparing queries with instances in the dataset.",
            "zh": "çƒ­å¿ƒå­¦ä¹ è€…åœ¨è®­ç»ƒæœŸé—´ä»æ•°æ®ä¸­æŠ½è±¡å‡ºæ¥ï¼Œå¹¶ä½¿ç”¨è¿™ç§æŠ½è±¡æ¥åšå‡ºé¢„æµ‹ï¼Œè€Œä¸æ˜¯ç›´æ¥å°†æŸ¥è¯¢ä¸æ•°æ®é›†ä¸­çš„å®ä¾‹è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the distances of each instance to these new cluster centers and perform another clustering iteration.",
            "zh": "ï¼ˆcï¼‰ è®¡ç®—æ¯ä¸ªå®ä¾‹åˆ°è¿™äº›æ–°èšç±»ä¸­å¿ƒçš„è·ç¦»ï¼Œå¹¶æ‰§è¡Œå¦ä¸€æ¬¡èšç±»è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "These sub-optimal clusterings are rareâ€”for this dataset the vast majority of initial centroid choices will lead to the clustering in Figure 10.3(f)[602]â€”but they can occur. In large multivariate datasets they are more common, and the algorithm can very easily arrive in oneâ€”we donâ€™t have the luxury of simply visualizing high-dimensional datasets to check against an intuitive clustering.",
            "zh": "è¿™äº›æ¬¡ä¼˜èšç±»å¾ˆå°‘è§â€”â€”å¯¹äºè¿™ä¸ªæ•°æ®é›†ï¼Œç»å¤§å¤šæ•°åˆå§‹è´¨å¿ƒé€‰æ‹©å°†å¯¼è‡´å›¾10.3ï¼ˆfï¼‰[602]ä¸­çš„èšç±»â€”â€”ä½†å®ƒä»¬å¯èƒ½ä¼šå‘ç”Ÿã€‚åœ¨å¤§å‹å¤šå˜é‡æ•°æ®é›†ä¸­ï¼Œå®ƒä»¬æ›´ä¸ºå¸¸è§ï¼Œå¹¶ä¸”è¯¥ç®—æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ°è¾¾ä¸€ä¸ªæ•°æ®é›†ä¸­â€”â€”æˆ‘ä»¬æ²¡æœ‰ç®€å•åœ°å¯è§†åŒ–é«˜ç»´æ•°æ®é›†æ¥æ£€æŸ¥ç›´è§‚çš„èšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "13. We direct the interested reader to http://skyserver.sdss3.org/dr9/en/sdss/data/data.asp for a overview of what these features represent.",
            "zh": "13. æˆ‘ä»¬å¼•å¯¼æ„Ÿå…´è¶£çš„è¯»è€… http://skyserver.sdss3.org/dr9/en/sdss/data/data.aspï¼Œä»¥æ¦‚è¿°è¿™äº›åŠŸèƒ½æ‰€ä»£è¡¨çš„å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "discounted return, 642",
            "zh": "æŠ˜æ‰£é€€è´§ï¼Œ642"
        }
    },
    {
        "translation": {
            "en": "These random samples are known as bootstrap samples, and one model is induced from each bootstrap sample.",
            "zh": "è¿™äº›éšæœºæ ·æœ¬ç§°ä¸º bootstrap æ ·æœ¬ï¼Œæ¯ä¸ª bootstrap æ ·æœ¬éƒ½å½’å‡ºä¸€ä¸ªæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "to convince the business for whom a model is being developed that the model will meet their needs",
            "zh": "è¯´æœæ­£åœ¨ä¸ºå…¶å¼€å‘æ¨¡å‹çš„ä¼ä¸šï¼Œè¯¥æ¨¡å‹å°†æ»¡è¶³ä»–ä»¬çš„éœ€æ±‚"
        }
    },
    {
        "translation": {
            "en": "Calculating the silhouette for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3). The overall silhouette index value is 0.66.",
            "zh": "è®¡ç®—ä½¿ç”¨ k å‡å€¼ç®—æ³•ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†æœ€ç»ˆèšç±»çš„è½®å»“ï¼ˆè¡¨ 10.1[604]ï¼‰ã€‚æ•´ä½“è½®å»“æŒ‡æ•°å€¼ä¸º 0.66ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second thing that is apparent from the images in Figure 14.2[737] is that some of the models do a better job of representing the underlying decision boundaries than others.",
            "zh": "ä»å›¾14.2[737]ä¸­çš„å›¾åƒä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºçš„ç¬¬äºŒä»¶äº‹æ˜¯ï¼Œä¸€äº›æ¨¡å‹åœ¨è¡¨ç¤ºåŸºç¡€å†³ç­–è¾¹ç•Œæ–¹é¢æ¯”å…¶ä»–æ¨¡å‹åšå¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using this new ABT, Jocelyn trained a logistic regression model to distinguish between the three spiral galaxy types (spiral_cw, spiral_acw, and spiral_eo).",
            "zh": "ä½¿ç”¨è¿™ä¸ªæ–°çš„ABTï¼ŒJocelynè®­ç»ƒäº†ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹æ¥åŒºåˆ†ä¸‰ç§èºæ—‹æ˜Ÿç³»ç±»å‹ï¼ˆspiral_cwã€spiral_acwå’Œspiral_eoï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Identity: metric(a,b) = 0â‡â‡’a = b",
            "zh": "2. æ ‡è¯†ï¼šmetricï¼ˆaï¼Œbï¼‰ = 0â‡â‡’a = b"
        }
    },
    {
        "translation": {
            "en": "â€œmoney, money, moneyâ€",
            "zh": "â€œé’±ï¼Œé’±ï¼Œé’±â€"
        }
    },
    {
        "translation": {
            "en": "To apply early stopping, we first set aside a portion of the training data as a validation set.",
            "zh": "ä¸ºäº†åº”ç”¨æå‰åœæ­¢ï¼Œæˆ‘ä»¬é¦–å…ˆç•™å‡ºä¸€éƒ¨åˆ†è®­ç»ƒæ•°æ®ä½œä¸ºéªŒè¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first columns of Table 4.14[162] detail a small sample dataset giving temperatures, TEMP, and rental demand, RENTALS (which can be either Low or High), for 10 days.",
            "zh": "è¡¨ 4.14[162] çš„ç¬¬ä¸€åˆ—è¯¦ç»†ä»‹ç»äº†ä¸€ä¸ªå°å‹æ ·æœ¬æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç»™å‡ºäº† 10 å¤©çš„æ¸©åº¦ã€æ¸©åº¦å’Œç§Ÿèµéœ€æ±‚ã€ç§Ÿèµï¼ˆå¯ä»¥æ˜¯ä½æˆ–é«˜ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although we have an infinite number of Minkowski-based distance metrics to choose from, Euclidean distance and Manhattan distance are the most commonly used of these.",
            "zh": "å°½ç®¡æˆ‘ä»¬æœ‰æ— æ•°ä¸ªåŸºäºé—µå¯å¤«æ–¯åŸºçš„è·ç¦»åº¦é‡å¯ä¾›é€‰æ‹©ï¼Œä½†æ¬§å‡ é‡Œå¾—è·ç¦»å’Œæ›¼å“ˆé¡¿è·ç¦»æ˜¯å…¶ä¸­æœ€å¸¸ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "So what would be a reasonable policy for Conor to use to order his dinner each evening?",
            "zh": "é‚£ä¹ˆï¼Œåº·çº³æ¯å¤©æ™šä¸Šç”¨ä»€ä¹ˆåˆç†çš„æ”¿ç­–æ¥ç‚¹æ™šé¤å‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "8.3.5â€…â€…â€…A Worked Example: Using Backpropagation to Train a Feedforward Network for a Regression Task",
            "zh": "8.3.5 å·¥ä½œç¤ºä¾‹ï¼šä½¿ç”¨åå‘ä¼ æ’­ä¸ºå›å½’ä»»åŠ¡è®­ç»ƒå‰é¦ˆç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "Extending this example, if we wanted to study the behavior of two dice, we would create two random variables, we might call them Dice1 and Dice2, each having the domain .",
            "zh": "æ‰©å±•è¿™ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ç ”ç©¶ä¸¤ä¸ªéª°å­çš„è¡Œä¸ºï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸¤ä¸ªéšæœºå˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥ç§°å®ƒä»¬ä¸º Dice1 å’Œ Dice2ï¼Œæ¯ä¸ªå˜é‡éƒ½æœ‰åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, 1026â€“1034.",
            "zh": "ä½•å‡¯æ˜ï¼Œå¼ ç¿”å®‡ï¼Œä»»å°‘å¿å’Œå­™å¥. 2015.æ·±å…¥ç ”ç©¶æ•´æµå™¨ï¼šåœ¨å›¾åƒç½‘ç»œåˆ†ç±»æ–¹é¢è¶…è¶Šäººç±»æ°´å¹³çš„æ€§èƒ½ã€‚IEEEè®¡ç®—æœºè§†è§‰å›½é™…ä¼šè®®è®ºæ–‡é›†ï¼Œ1026-1034ã€‚"
        }
    },
    {
        "translation": {
            "en": "This increased variation is mirrored in the fact that the rankings based on the distances calculated using the SALARY and AGE features are quite different from the rankings based on the distances calculated using SALARY only.",
            "zh": "è¿™ç§å¢åŠ çš„å˜åŒ–åæ˜ åœ¨ä»¥ä¸‹äº‹å®ä¸­ï¼šåŸºäºä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾è®¡ç®—çš„è·ç¦»çš„æ’åä¸åŸºäºä»…ä½¿ç”¨ SALARY è®¡ç®—çš„è·ç¦»çš„æ’åæœ‰å¾ˆå¤§ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "So we have two different definitions of Bayesâ€™ Theorem (Equation (6.2)[248] and Equation (6.7)[250]), but which one should we use?",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬å¯¹è´å¶æ–¯å®šç†æœ‰ä¸¤ç§ä¸åŒçš„å®šä¹‰ï¼ˆæ–¹ç¨‹ï¼ˆ6.2ï¼‰[248]å’Œæ–¹ç¨‹ï¼ˆ6.7ï¼‰[250]ï¼‰ï¼Œä½†æ˜¯æˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªä¸€ä¸ªå‘¢ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Just 11 features from the full set were selected.17 The resulting classification accuracy on the best performing model that Jocelyn could build was 77.528% (with an average class accuracy of 43.018%).",
            "zh": "17 åœ¨ Jocelyn å¯ä»¥æ„å»ºçš„æœ€ä½³æ€§èƒ½æ¨¡å‹ä¸Šï¼Œæœ€ç»ˆçš„åˆ†ç±»å‡†ç¡®ç‡ä¸º 77.528%ï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡ä¸º 43.018%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "To manually learn this model by examining the data is almost impossible. For a machine learning algorithm, however, this is simple. When we want to build prediction models from large datasets with multiple features, machine learning is the solution.",
            "zh": "é€šè¿‡æ£€æŸ¥æ•°æ®æ¥æ‰‹åŠ¨å­¦ä¹ è¿™ä¸ªæ¨¡å‹å‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚ç„¶è€Œï¼Œå¯¹äºæœºå™¨å­¦ä¹ ç®—æ³•æ¥è¯´ï¼Œè¿™å¾ˆç®€å•ã€‚å½“æˆ‘ä»¬æƒ³ä»å…·æœ‰å¤šä¸ªç‰¹å¾çš„å¤§å‹æ•°æ®é›†æ„å»ºé¢„æµ‹æ¨¡å‹æ—¶ï¼Œæœºå™¨å­¦ä¹ æ˜¯è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Sing, Tobias, Oliver Sander, Niko Beerenwinkel, and Thomas Lengauer. 2005. ROCR: Visualizing classifier performance in R. Bioinformatics 21 (20): 3940â€“3941.",
            "zh": "Singã€Tobiasã€Oliver Sanderã€Niko Beerenwinkel å’Œ Thomas Lengauerã€‚2005. ROCRï¼šåœ¨ R. ç”Ÿç‰©ä¿¡æ¯å­¦ 21 ï¼ˆ20ï¼‰ï¼š 3940â€“3941 ä¸­å¯è§†åŒ–åˆ†ç±»å™¨æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the Cohenâ€™s kappa19 measure of inter-annotator agreement to measure how closely the manual classifications matched each other, Jocelyn calculated a measure of 0.6.",
            "zh": "ä½¿ç”¨ Cohen çš„ kappa19 æ³¨é‡Šè€…é—´ä¸€è‡´æ€§åº¦é‡æ¥æµ‹é‡æ‰‹åŠ¨åˆ†ç±»ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ï¼ŒJocelyn è®¡ç®—å‡ºçš„åº¦é‡å€¼ä¸º 0.6ã€‚"
        }
    },
    {
        "translation": {
            "en": "diabetes, 51",
            "zh": "ç³–å°¿ç—…ï¼Œ51"
        }
    },
    {
        "translation": {
            "en": "Using this representation with the following set of basis functions will give the learning process the flexibility to find the non-linear decision boundary required to successfully separate the different types of images in the EEG dataset:17",
            "zh": "å°†è¿™ç§è¡¨ç¤ºä¸ä»¥ä¸‹ä¸€ç»„åŸºå‡½æ•°ä¸€èµ·ä½¿ç”¨å°†ä½¿å­¦ä¹ è¿‡ç¨‹èƒ½å¤Ÿçµæ´»åœ°æ‰¾åˆ°æˆåŠŸåˆ†ç¦»è„‘ç”µå›¾æ•°æ®é›†ä¸­ä¸åŒç±»å‹çš„å›¾åƒæ‰€éœ€çš„éçº¿æ€§å†³ç­–è¾¹ç•Œï¼š17"
        }
    },
    {
        "translation": {
            "en": "CLAIMS, NUM.",
            "zh": "ç´¢èµ”ï¼Œç¼–å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if a neuron is applying a 2-by-2-by-3 filter, then its local receptive field will have the same dimensions (this is why the depth of the filter must match the depth of the input).",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªç¥ç»å…ƒæ­£åœ¨åº”ç”¨ä¸€ä¸ª 2Ã—2Ã—3 çš„æ»¤æ³¢å™¨ï¼Œé‚£ä¹ˆå®ƒçš„å±€éƒ¨æ„Ÿå—é‡å°†å…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ»¤æ³¢å™¨çš„æ·±åº¦å¿…é¡»ä¸è¾“å…¥çš„æ·±åº¦ç›¸åŒ¹é…ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.8â€…â€…â€…(a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (Î±0 = 0.18, c = 10 ); and (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "7.8 ï¼ˆaï¼‰ ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡æ—¶ï¼ŒåŠå…¬å®¤ç§Ÿèµé¢„æµ‹é—®é¢˜çš„è¯¯å·®é¢å†ç¨‹ ï¼ˆÎ±0 = 0.18ï¼Œ c = 10 ï¼‰;ï¼ˆbï¼‰æ­¤æ—…ç¨‹ä¸­è¯¯å·®å¹³æ–¹å’Œçš„å˜åŒ–å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this section we cover two important extensions to the temporal-difference learning approach introduced in the previous section. The first is the SARSA on-policy modification to temporal-difference learning. The second is an extension that uses a predictive machine learning model to replace the action-value table to accommodate environments in which the state-action space is too large for tabular methods to work. Specifically we present the deep Q network (DQN) algorithm.",
            "zh": "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸Šä¸€èŠ‚ä¸­ä»‹ç»çš„æ—¶é—´å·®åˆ†å­¦ä¹ æ–¹æ³•çš„ä¸¤ä¸ªé‡è¦æ‰©å±•ã€‚é¦–å…ˆæ˜¯SARSAå¯¹æ—¶é—´å·®å¼‚å­¦ä¹ çš„æ”¿ç­–ä¿®æ”¹ã€‚ç¬¬äºŒä¸ªæ˜¯ä½¿ç”¨é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹æ›¿æ¢æ“ä½œå€¼è¡¨çš„æ‰©å±•ï¼Œä»¥é€‚åº”çŠ¶æ€æ“ä½œç©ºé—´å¤ªå¤§è€Œè¡¨æ ¼æ–¹æ³•æ— æ³•å·¥ä½œçš„ç¯å¢ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.1.2â€…â€…â€…â€…Variation",
            "zh": "A.1.2 å˜åŒ–"
        }
    },
    {
        "translation": {
            "en": "While the sample of 2,709 voters out of a population of 240,926,957 might appear quite small, we can also see from the table that the margin of error for the poll is given as Â± 2.2%.",
            "zh": "è™½ç„¶åœ¨240,926,957äººå£ä¸­ï¼Œæœ‰2,709åé€‰æ°‘çš„æ ·æœ¬å¯èƒ½çœ‹èµ·æ¥å¾ˆå°ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ä»è¡¨ä¸­çœ‹åˆ°ï¼Œæ°‘æ„è°ƒæŸ¥çš„è¯¯å·®å¹…åº¦Â±2.2%ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is known as statistical inference.",
            "zh": "æ­¤è¿‡ç¨‹ç§°ä¸ºç»Ÿè®¡æ¨æ–­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.3",
            "zh": "è¡¨ 1.3"
        }
    },
    {
        "translation": {
            "en": "This gives us a clue as to how we should define a computational model of entropy. We can transform the probabilities3 of the different possible outcomes when we randomly select an element from a set to entropy values. An outcome with a large probability should map to a low entropy value, and an outcome with a small probability should map to a large entropy value. The mathematical logarithm, or log, function4 does almost exactly the transformation that we need.",
            "zh": "è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å¦‚ä½•å®šä¹‰ç†µçš„è®¡ç®—æ¨¡å‹çš„çº¿ç´¢ã€‚å½“æˆ‘ä»¬ä»ä¸€ç»„å…ƒç´ ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå…ƒç´ åˆ°ç†µå€¼æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è½¬æ¢ä¸åŒå¯èƒ½ç»“æœçš„æ¦‚ç‡3ã€‚æ¦‚ç‡è¾ƒå¤§çš„ç»“æœåº”æ˜ å°„åˆ°ä½ç†µå€¼ï¼Œæ¦‚ç‡è¾ƒå°çš„ç»“æœåº”æ˜ å°„åˆ°è¾ƒå¤§çš„ç†µå€¼ã€‚æ•°å­¦å¯¹æ•°å‡½æ•° function4 å‡ ä¹å®Œå…¨ç¬¦åˆæˆ‘ä»¬çš„è¦æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Week",
            "zh": "å‘¨"
        }
    },
    {
        "translation": {
            "en": "The final results of the clustering are the cluster centroid values of c1 = âŸ¨âˆ’1.012,âˆ’0.131âŸ©, c2 = âŸ¨0.8912,âˆ’0.7273âŸ©, and c3 = âŸ¨âˆ’0.0491,0.7022âŸ©; and the cluster assignments of",
            "zh": "èšç±»çš„æœ€ç»ˆç»“æœæ˜¯ c1 = âŸ¨âˆ’1.012ï¼Œâˆ’0.131âŸ©ã€c2 = âŸ¨0.8912ã€âˆ’0.7273âŸ© å’Œ c3 = âŸ¨âˆ’0.0491,0.7022âŸ©;ä»¥åŠ"
        }
    },
    {
        "translation": {
            "en": "confidence factor, 161, 178",
            "zh": "ç½®ä¿¡å› å­ï¼Œ 161ï¼Œ 178"
        }
    },
    {
        "translation": {
            "en": "absence-presence, 214",
            "zh": "ç¼ºå¸­-å­˜åœ¨ï¼Œ214"
        }
    },
    {
        "translation": {
            "en": "The k-d tree,8 which is short for k-dimensional tree, is one of the best known of these indices. A k-d tree is a balanced binary tree9 in which each of the nodes in the tree (both interior and leaf nodes) index one of the instances in a training dataset. The tree is constructed so that nodes that are nearby in the tree index training instances that are nearby in the feature space.",
            "zh": "k-d æ ‘ 8 æ˜¯ k ç»´æ ‘çš„ç¼©å†™ï¼Œæ˜¯è¿™äº›æŒ‡æ•°ä¸­æœ€è‘—åçš„æŒ‡æ ‡ä¹‹ä¸€ã€‚k-d æ ‘æ˜¯ä¸€ç§å¹³è¡¡çš„äºŒå‰æ ‘9ï¼Œå…¶ä¸­æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ï¼ˆå†…éƒ¨èŠ‚ç‚¹å’Œå¶èŠ‚ç‚¹ï¼‰éƒ½ä¸ºè®­ç»ƒæ•°æ®é›†ä¸­çš„ä¸€ä¸ªå®ä¾‹ç¼–åˆ¶ç´¢å¼•ã€‚æ ‘çš„æ„é€ ä½¿æ ‘ç´¢å¼•è®­ç»ƒå®ä¾‹ä¸­é™„è¿‘çš„èŠ‚ç‚¹åœ¨ç‰¹å¾ç©ºé—´ä¸­é™„è¿‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.1â€…â€…â€…Intelligent Agents",
            "zh": "11.2.1 æ™ºèƒ½ä»£ç†"
        }
    },
    {
        "translation": {
            "en": "We can calculate P(h,V = ?, M = ?",
            "zh": "æˆ‘ä»¬å¯ä»¥è®¡ç®— Pï¼ˆhï¼ŒV = ï¼Ÿï¼Œ M = ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "16. The data listed in this table is real and was amalgamated from a number of reports that were retrieved from Gapminder (www.gapminder.org). The EDUCATION data is based on a report from the World Bank (data.worldbank.org/indicator/SE.XPD.PRIM.PC.ZS); the HEALTH and HEALTHUSD data are based on reports from the World Health Organization (www.who.int); all the other features are based on reports created by Gapminder.",
            "zh": "16. æœ¬è¡¨æ‰€åˆ—æ•°æ®æ˜¯çœŸå®çš„ï¼Œæ˜¯ä»Gapminderï¼ˆwww.gapminder.orgï¼‰æ£€ç´¢åˆ°çš„è‹¥å¹²æŠ¥å‘Šä¸­åˆå¹¶è€Œæˆçš„ã€‚æ•™è‚²æ•°æ®åŸºäºä¸–ç•Œé“¶è¡Œï¼ˆdata.worldbank.org/indicator/SE.XPD.PRIM.PC.ZSï¼‰çš„ä¸€ä»½æŠ¥å‘Š;HEALTH å’Œ HEALTHUSD æ•°æ®åŸºäºä¸–ç•Œå«ç”Ÿç»„ç»‡ ï¼ˆwww.who.intï¼‰ çš„æŠ¥å‘Š;æ‰€æœ‰å…¶ä»–åŠŸèƒ½éƒ½åŸºäº Gapminder åˆ›å»ºçš„æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Some of the Error and Squared Error values are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "ï¼ˆbï¼‰ ä¸Šè¡¨ä¸­ç¼ºå°‘ä¸€äº›â€œè¯¯å·®â€å’Œâ€œå¹³æ–¹è¯¯å·®â€å€¼ï¼ˆæ ‡æœ‰ ï¼Ÿï¼‰ã€‚è®¡ç®—è¿™äº›ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.5.1â€ƒBasic measures of errorâ€ƒIn Section 7.2.2[315], when covering error-based learning, we discussed the basis of the most common performance measure for continuous targets: sum of squared errors. The sum of squared errors function, L2, for a set of predictions made by a model, ğ•„, is defined as",
            "zh": "9.4.5.1 è¯¯å·®çš„åŸºæœ¬åº¦é‡ åœ¨ç¬¬ 7.2.2 èŠ‚[315]ä¸­ï¼Œåœ¨ä»‹ç»åŸºäºé”™è¯¯çš„å­¦ä¹ æ—¶ï¼Œæˆ‘ä»¬è®¨è®ºäº†è¿ç»­ç›®æ ‡æœ€å¸¸è§çš„ç»©æ•ˆåº¦é‡çš„åŸºç¡€ï¼šè¯¯å·®çš„å¹³æ–¹å’Œã€‚æ¨¡å‹åšå‡ºçš„ä¸€ç»„é¢„æµ‹çš„å¹³æ–¹è¯¯å·®å‡½æ•° L2 çš„å¹³æ–¹å’Œå®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "To ensure maximum exploration Conor could randomly pick one of the menu items each evening.",
            "zh": "ä¸ºäº†ç¡®ä¿æœ€å¤§çš„æ¢ç´¢ï¼Œåº·çº³æ¯å¤©æ™šä¸Šéƒ½å¯ä»¥éšæœºé€‰æ‹©ä¸€ä¸ªèœå•é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.6.4â€ƒBackpropagating through an LSTM cellâ€ƒFigure 8.42[516] illustrates the flow of error gradients through an LSTM during backpropagation. In this figure the error gradients flow from right to left. The backpropagation process within an LSTM begins with three vectors of error gradients",
            "zh": "8.4.6.4 é€šè¿‡LSTMå•å…ƒçš„åå‘ä¼ æ’­ å›¾8.42[516]è¯´æ˜äº†åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­é€šè¿‡LSTMçš„è¯¯å·®æ¢¯åº¦æµåŠ¨ã€‚åœ¨æ­¤å›¾ä¸­ï¼Œè¯¯å·®æ¢¯åº¦ä»å³å‘å·¦æµåŠ¨ã€‚LSTM ä¸­çš„åå‘ä¼ æ’­è¿‡ç¨‹ä»ä¸‰ä¸ªè¯¯å·®æ¢¯åº¦å‘é‡å¼€å§‹"
        }
    },
    {
        "translation": {
            "en": "Berry, Michael J. A, and Gordon S. Linoff. 2004. Data mining techniques: for marketing, sales, and customer relationship management. Wiley.",
            "zh": "è´ç‘ï¼Œè¿ˆå…‹å°” J.Aå’ŒGordon S. Linoffã€‚2004. æ•°æ®æŒ–æ˜æŠ€æœ¯ï¼šç”¨äºè¥é”€ã€é”€å”®å’Œå®¢æˆ·å…³ç³»ç®¡ç†ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.14",
            "zh": "è¡¨ 4.14"
        }
    },
    {
        "translation": {
            "en": "Discounting makes intuitive sense, makes some of the mathematics associated with reinforcement learning more straightforward, and avoids any issues with circular paths through states that can arise in some scenarios. Discounted return is widely used in reinforcement learning.",
            "zh": "è´´ç°å…·æœ‰ç›´è§‚æ„ä¹‰ï¼Œä½¿ä¸å¼ºåŒ–å­¦ä¹ ç›¸å…³çš„ä¸€äº›æ•°å­¦è¿ç®—æ›´åŠ ç®€å•ï¼Œå¹¶é¿å…äº†åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½å‡ºç°çš„å¾ªç¯è·¯å¾„é€šè¿‡çŠ¶æ€çš„ä»»ä½•é—®é¢˜ã€‚è´´ç°å›æŠ¥åœ¨å¼ºåŒ–å­¦ä¹ ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Confounding features are a common explanation of mistaken conclusions about causal relationships.",
            "zh": "æ··æ‚ç‰¹å¾æ˜¯å…³äºå› æœå…³ç³»çš„é”™è¯¯ç»“è®ºçš„å¸¸è§è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The ability to automatically learn useful representations (features) from data is one of the reasons why deep networks have proven to be so successful on so many tasks.",
            "zh": "ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ æœ‰ç”¨çš„è¡¨ç¤ºï¼ˆç‰¹å¾ï¼‰çš„èƒ½åŠ›æ˜¯æ·±åº¦ç½‘ç»œåœ¨è®¸å¤šä»»åŠ¡ä¸Šè¢«è¯æ˜å¦‚æ­¤æˆåŠŸçš„åŸå› ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross did stress to AT management that until he actually examined the data, he could not know how useful a model he would be able to build.",
            "zh": "Ross ç¡®å®å‘ AT ç®¡ç†å±‚å¼ºè°ƒï¼Œåœ¨ä»–çœŸæ­£æ£€æŸ¥æ•°æ®ä¹‹å‰ï¼Œä»–æ— æ³•çŸ¥é“ä»–èƒ½å¤Ÿæ„å»ºä¸€ä¸ªå¤šä¹ˆæœ‰ç”¨çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Remembering that the perfect model will appear in the very top left-hand corner of ROC space, it is fairly intuitive that curves with higher areas will be closer to this maximum possible value.",
            "zh": "è¯·è®°ä½ï¼Œå®Œç¾çš„æ¨¡å‹å°†å‡ºç°åœ¨ ROC ç©ºé—´çš„å·¦ä¸Šè§’ï¼Œå› æ­¤ç›¸å½“ç›´è§‚çš„æ˜¯ï¼Œå…·æœ‰è¾ƒé«˜åŒºåŸŸçš„æ›²çº¿å°†æ›´æ¥è¿‘æ­¤æœ€å¤§å¯èƒ½å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The human brain is an incredibly powerful learning system. Thanks to neuroscience we now know quite a bit about the structure of the brain. For example, we know that the brain works by propagating electrical signals through a massive network of interconnected cells, known as neurons. In fact, it is estimated that the human brain contains around 100 billion interconnected neurons (Herculano-Houzel, 2009).",
            "zh": "äººè„‘æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„å­¦ä¹ ç³»ç»Ÿã€‚å¤šäºäº†ç¥ç»ç§‘å­¦ï¼Œæˆ‘ä»¬ç°åœ¨å¯¹å¤§è„‘çš„ç»“æ„æœ‰äº†ç›¸å½“å¤šçš„äº†è§£ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çŸ¥é“å¤§è„‘çš„å·¥ä½œåŸç†æ˜¯é€šè¿‡ä¸€ä¸ªç”±ç›¸äº’è¿æ¥çš„ç»†èƒç»„æˆçš„åºå¤§ç½‘ç»œï¼ˆç§°ä¸ºç¥ç»å…ƒï¼‰ä¼ æ’­ç”µä¿¡å·ã€‚äº‹å®ä¸Šï¼Œæ®ä¼°è®¡ï¼Œäººè„‘åŒ…å«å¤§çº¦1000äº¿ä¸ªç›¸äº’è¿æ¥çš„ç¥ç»å…ƒï¼ˆHerculano-Houzelï¼Œ2009ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.5590",
            "zh": "0.5590"
        }
    },
    {
        "translation": {
            "en": "Table 10.3",
            "zh": "è¡¨ 10.3"
        }
    },
    {
        "translation": {
            "en": "reward, 639, 643, 676",
            "zh": "å¥–åŠ±ï¼Œ 639ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Fortunately, the derivative of the logistic function is well known:",
            "zh": "å¹¸è¿çš„æ˜¯ï¼Œé€»è¾‘å‡½æ•°çš„å¯¼æ•°æ˜¯ä¼—æ‰€å‘¨çŸ¥çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "The simple multivariable linear regression model that we presented at the beginning of this chapter can be extended in many ways, and we presented some of the most important of these. Logistic regression models (Section 7.4.4[338]) allow us to predict categorical targets rather than continuous ones by placing a threshold on the output of the simple multivariable linear regression model using the logistic function.",
            "zh": "æˆ‘ä»¬åœ¨æœ¬ç« å¼€å¤´ä»‹ç»çš„ç®€å•å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è¿›è¡Œæ‰©å±•ï¼Œæˆ‘ä»¬ä»‹ç»äº†å…¶ä¸­æœ€é‡è¦çš„ä¸€äº›ã€‚é€»è¾‘å›å½’æ¨¡å‹ï¼ˆç¬¬ 7.4.4 èŠ‚ [338]ï¼‰å…è®¸æˆ‘ä»¬é€šè¿‡ä½¿ç”¨é€»è¾‘å‡½æ•°å¯¹ç®€å•å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„è¾“å‡ºè®¾ç½®é˜ˆå€¼æ¥é¢„æµ‹åˆ†ç±»ç›®æ ‡è€Œä¸æ˜¯è¿ç»­ç›®æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset describing grass growth on Irish farms in July 2012.",
            "zh": "æè¿°2012å¹´7æœˆçˆ±å°”å…°å†œåœºç‰§è‰ç”Ÿé•¿æƒ…å†µçš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The feature of the ID3 algorithm that biases it toward shallow trees is the mechanism that it uses to determine which descriptive feature is the most informative one to test at a new node.",
            "zh": "ID3 ç®—æ³•åå‘æµ…æ ‘çš„ç‰¹å¾æ˜¯å®ƒç”¨æ¥ç¡®å®šå“ªä¸ªæè¿°æ€§ç‰¹å¾æ˜¯åœ¨æ–°èŠ‚ç‚¹ä¸Šæµ‹è¯•çš„ä¿¡æ¯é‡æœ€å¤§çš„ç‰¹å¾çš„æœºåˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, saturated activation functions are problematic for gradient-descentâ€“based algorithms (such as backpropagation) because these algorithms work by iteratively adjusting the weights using small increments that are scaled by the derivative of the activation function.",
            "zh": "å› æ­¤ï¼Œé¥±å’Œæ¿€æ´»å‡½æ•°å¯¹äºåŸºäºæ¢¯åº¦ä¸‹é™çš„ç®—æ³•ï¼ˆä¾‹å¦‚åå‘ä¼ æ’­ï¼‰æ¥è¯´æ˜¯æœ‰é—®é¢˜çš„ï¼Œå› ä¸ºè¿™äº›ç®—æ³•çš„å·¥ä½œåŸç†æ˜¯ä½¿ç”¨ç”±æ¿€æ´»å‡½æ•°çš„å¯¼æ•°ç¼©æ”¾çš„å°å¢é‡è¿­ä»£è°ƒæ•´æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The RPM and VIBRATION measurements come from the day before the generators proved to be operational or faulty.",
            "zh": "RPM å’Œ VIBRATION æµ‹é‡å€¼æ¥è‡ªå‘ç”µæœºè¢«è¯æ˜è¿è¡Œæˆ–æ•…éšœçš„å‰ä¸€å¤©ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are, of course, many different weight matrices that could be defined, each of which would cause a neuron to activate in response to a different visual pattern in the neuronâ€™s local receptive field.",
            "zh": "å½“ç„¶ï¼Œå¯ä»¥å®šä¹‰è®¸å¤šä¸åŒçš„æƒé‡çŸ©é˜µï¼Œæ¯ä¸ªçŸ©é˜µéƒ½ä¼šå¯¼è‡´ç¥ç»å…ƒæ¿€æ´»ï¼Œä»¥å“åº”ç¥ç»å…ƒå±€éƒ¨æ„Ÿå—é‡ä¸­çš„ä¸åŒè§†è§‰æ¨¡å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although this algorithm works quite well as presented, it assumes categorical features and clean data.",
            "zh": "å°½ç®¡æ­¤ç®—æ³•å¦‚æ‰€ä»‹ç»çš„é‚£æ ·å·¥ä½œå¾—å¾ˆå¥½ï¼Œä½†å®ƒå‡å®šäº†åˆ†ç±»ç‰¹å¾å’Œå¹²å‡€çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before the scout attempts a step, the blindfold is made transparent for 0.5 seconds to give the scout a quick view of their environment so that they make a decision about which direction they will step in and how far.",
            "zh": "åœ¨ä¾¦å¯Ÿå…µå°è¯•è¸æ­¥ä¹‹å‰ï¼Œçœ¼ç½©ä¼šé€æ˜ 0.5 ç§’ï¼Œä»¥ä¾¿ä¾¦å¯Ÿå…µå¿«é€ŸæŸ¥çœ‹ä»–ä»¬çš„ç¯å¢ƒï¼Œä»¥ä¾¿ä»–ä»¬å†³å®šå°†è¸å…¥å“ªä¸ªæ–¹å‘å’Œå¤šè¿œã€‚"
        }
    },
    {
        "translation": {
            "en": "Simply through eyeballing the data, Jocelyn uncovered the fact that, in almost all cases, when one suspect âˆ’ 9,999 value was present in a row in the dataset, that row contained a number of suspect âˆ’ 9,999 values (this was the case for 2% of the rows in the dataset).",
            "zh": "ä»…ä»…é€šè¿‡è§‚å¯Ÿæ•°æ®ï¼ŒJocelyn å°±å‘ç°äº†è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³åœ¨å‡ ä¹æ‰€æœ‰æƒ…å†µä¸‹ï¼Œå½“æ•°æ®é›†ä¸­çš„ä¸€è¡Œä¸­å­˜åœ¨ä¸€ä¸ªå¯ç–‘å€¼ - 9,999 å€¼æ—¶ï¼Œè¯¥è¡ŒåŒ…å«è®¸å¤šå¯ç–‘å€¼ - 9,999 å€¼ï¼ˆæ•°æ®é›†ä¸­ 2% çš„è¡Œå°±æ˜¯è¿™ç§æƒ…å†µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. This data has been artificially generated for this example.",
            "zh": "2. æ­¤æ•°æ®æ˜¯é’ˆå¯¹æ­¤ç¤ºä¾‹äººå·¥ç”Ÿæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "They retain some instances from the datasetâ€”potentially all of them, although in practice, relatively fewâ€”as part of the domain representation.",
            "zh": "å®ƒä»¬ä¿ç•™äº†æ•°æ®é›†ä¸­çš„ä¸€äº›å®ä¾‹ï¼ˆå¯èƒ½æ˜¯æ‰€æœ‰å®ä¾‹ï¼Œä½†å®é™…ä¸Šç›¸å¯¹è¾ƒå°‘ï¼‰ä½œä¸ºåŸŸè¡¨ç¤ºçš„ä¸€éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Or two payments in a five-month period?",
            "zh": "è¿˜æ˜¯åœ¨äº”ä¸ªæœˆå†…æ”¯ä»˜ä¸¤ç¬”æ¬¾é¡¹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "1,750,000",
            "zh": "1,750,000"
        }
    },
    {
        "translation": {
            "en": "This network is changing frequently during the training process, which can cause the training to oscillate wildly.",
            "zh": "æ­¤ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢‘ç¹å˜åŒ–ï¼Œè¿™å¯èƒ½å¯¼è‡´è®­ç»ƒå‰§çƒˆæŒ¯è¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This approach, however, has not proved particularly successful, and churn has been steadily increasing over the last five years.",
            "zh": "ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¹¶æ²¡æœ‰è¢«è¯æ˜æ˜¯ç‰¹åˆ«æˆåŠŸï¼Œè€Œä¸”åœ¨è¿‡å»äº”å¹´ä¸­ï¼Œå®¢æˆ·æµå¤±ç‡ä¸€ç›´åœ¨ç¨³æ­¥ä¸Šå‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross then developed a full data quality report for the ABT including a range of data visualizations.",
            "zh": "ç„¶åï¼ŒRoss ä¸º ABT å¼€å‘äº†ä¸€ä»½å®Œæ•´çš„æ•°æ®è´¨é‡æŠ¥å‘Šï¼ŒåŒ…æ‹¬ä¸€ç³»åˆ—æ•°æ®å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A range normalization that generates data in the range (0,1)",
            "zh": "ï¼ˆaï¼‰ ç”ŸæˆèŒƒå›´ ï¼ˆ0,1ï¼‰ ä¸­æ•°æ®çš„èŒƒå›´å½’ä¸€åŒ–"
        }
    },
    {
        "translation": {
            "en": "11.3.1â€…â€…â€…A Worked Example",
            "zh": "11.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "11.3â€ƒStandard Approach: Q-Learning, Off-Policy Temporal-Difference Learning",
            "zh": "11.3 æ ‡å‡†æ–¹æ³•ï¼šQ-å­¦ä¹ ã€éæ”¿ç­–æ—¶é—´å·®å¼‚å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "causal graphs, 293",
            "zh": "å› æœå›¾ï¼Œ293"
        }
    },
    {
        "translation": {
            "en": "CLMNTS.",
            "zh": "CLMNTSçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22",
            "zh": "å›¾ 7.22"
        }
    },
    {
        "translation": {
            "en": "It is worth noting that this ability is diminished if pre-pruning is employed, as pre-pruning may stop subtrees that capture descriptive feature interactions from forming.",
            "zh": "å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœé‡‡ç”¨é¢„ä¿®å‰ªï¼Œè¿™ç§èƒ½åŠ›ä¼šå‡å¼±ï¼Œå› ä¸ºé¢„ä¿®å‰ªå¯èƒ½ä¼šé˜»æ­¢æ•è·æè¿°æ€§ç‰¹å¾äº¤äº’çš„å­æ ‘å½¢æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "relative rarity, 720",
            "zh": "ç›¸å¯¹ç¨€æœ‰åº¦ï¼Œ720"
        }
    },
    {
        "translation": {
            "en": "(b) At the first iteration of the AHC algorithm the first pair of instances is combined into a cluster, 10.",
            "zh": "ï¼ˆbï¼‰ åœ¨AHCç®—æ³•çš„ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œç¬¬ä¸€å¯¹å®ä¾‹è¢«ç»„åˆæˆä¸€ä¸ªé›†ç¾¤ï¼Œ10ã€‚"
        }
    },
    {
        "translation": {
            "en": "To add a new instance to the tree, we start at the root node and descend to a leaf node, taking the left or right branch of each node depending on whether the value of the instanceâ€™s feature is less than or greater than the splitting value used at the node.",
            "zh": "ä¸ºäº†å°†æ–°å®ä¾‹æ·»åŠ åˆ°æ ‘ä¸­ï¼Œæˆ‘ä»¬ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œä¸‹é™åˆ°å¶èŠ‚ç‚¹ï¼Œæ ¹æ®å®ä¾‹çš„ç‰¹å¾å€¼æ˜¯å°äºè¿˜æ˜¯å¤§äºèŠ‚ç‚¹ä¸Šä½¿ç”¨çš„æ‹†åˆ†å€¼ï¼Œå–æ¯ä¸ªèŠ‚ç‚¹çš„å·¦åˆ†æ”¯æˆ–å³åˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "One day, after an expedition up the river has returned to the ship, one of the men from the expedition tells you that he saw a strange animal near the river.",
            "zh": "æœ‰ä¸€å¤©ï¼Œåœ¨æ²¿æ²³è€Œä¸Šçš„æ¢é™©é˜Ÿè¿”å›èˆ¹ä¸Šåï¼Œæ¢é™©é˜Ÿçš„ä¸€åç”·å­å‘Šè¯‰ä½ ï¼Œä»–åœ¨æ²³è¾¹çœ‹åˆ°äº†ä¸€åªå¥‡æ€ªçš„åŠ¨ç‰©ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Table 5.6[206], if we compare the rankings based on SALARY and AGE with the rankings based solely on SALARY, we see that the values in these two columns are identical.",
            "zh": "åœ¨è¡¨5.6[206]ä¸­ï¼Œå¦‚æœæˆ‘ä»¬å°†åŸºäºSALAå’ŒAGEçš„æ’åä¸ä»…åŸºäºSALARYçš„æ’åè¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°è¿™ä¸¤åˆ—ä¸­çš„å€¼æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this instance, to find out which model is best, we would really need to put the bottle of whiskey up for auction and see which model predicted the closest price.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¦æ‰¾å‡ºå“ªç§å‹å·æœ€å¥½ï¼Œæˆ‘ä»¬çœŸçš„éœ€è¦å°†ä¸€ç“¶å¨å£«å¿Œæ‹å–ï¼Œçœ‹çœ‹å“ªä¸ªå‹å·é¢„æµ‹çš„ä»·æ ¼æœ€æ¥è¿‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "policy gradient, 641",
            "zh": "ç­–ç•¥æ¢¯åº¦ï¼Œ641"
        }
    },
    {
        "translation": {
            "en": "However, the same process is used to calculate the term âˆ‚ak/âˆ‚zk in the product irrespective of whether the neuron is an output neuron or a hidden neuron.",
            "zh": "ä½†æ˜¯ï¼Œæ— è®ºç¥ç»å…ƒæ˜¯è¾“å‡ºç¥ç»å…ƒè¿˜æ˜¯éšè—ç¥ç»å…ƒï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„è¿‡ç¨‹æ¥è®¡ç®—ä¹˜ç§¯ä¸­çš„æœ¯è¯­ âˆ‚ak/âˆ‚zkã€‚"
        }
    },
    {
        "translation": {
            "en": "The larger the size of the hidden state, the larger the representational capacity of the LSTM.",
            "zh": "éšè—çŠ¶æ€çš„å¤§å°è¶Šå¤§ï¼ŒLSTM çš„è¡¨ç¤ºèƒ½åŠ›å°±è¶Šå¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.4â€…â€…â€…The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for a query with CH = paid, GC = none, and ACC = rent, and the calculation of the scores for each target level.",
            "zh": "6.4 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹å¯¹ CH = paidã€GC = none å’Œ ACC = rent çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ï¼Œä»¥åŠæ¯ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can think about all these error values joined to make a surface defined by the weight combinations, as shown in Figure 7.3(a)[318].",
            "zh": "æˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†æ‰€æœ‰è¿™äº›è¯¯å·®å€¼è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªç”±æƒé‡ç»„åˆå®šä¹‰çš„æ›²é¢ï¼Œå¦‚å›¾7.3ï¼ˆaï¼‰[318]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.3â€…â€…â€…Performance Measures: Prediction Scores",
            "zh": "9.4.3 ç»©æ•ˆæŒ‡æ ‡ï¼šé¢„æµ‹åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "When we view a Bayesian network as a Markov chain, a state is a complete assignment of values to all the nodes in the network (for example, GINI COEF = high, SCHOOL YEARS = low, LIFE EXP = high, CPI = high would be a state in the Markov chain defined by the network in Figure 6.13[296]), and the CPTs of the network provide a distributed representation of the transition probabilities of the Markov chain.",
            "zh": "å½“æˆ‘ä»¬å°†è´å¶æ–¯ç½‘ç»œè§†ä¸ºé©¬å°”å¯å¤«é“¾æ—¶ï¼ŒçŠ¶æ€æ˜¯å°†å€¼å®Œå…¨åˆ†é…ç»™ç½‘ç»œä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ï¼ŒGINI COEF = é«˜ï¼ŒSCHOOL YEARS = ä½ï¼ŒLIFE EXP = é«˜ï¼ŒCPI = é«˜å°†æ˜¯å›¾ 6.13[296] ä¸­ç½‘ç»œå®šä¹‰çš„é©¬å°”å¯å¤«é“¾ä¸­çš„çŠ¶æ€ï¼‰ï¼Œç½‘ç»œçš„ CPT æä¾›äº†é©¬å°”å¯å¤«é“¾è½¬ç§»æ¦‚ç‡çš„åˆ†å¸ƒå¼è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The discussion in this section, and in the rest of this chapter, assumes that you have a basic understanding of differentiation, in particular, what a derivative is, how to calculate a derivative for a continuous function, the chain rule for differentiation, and what a partial derivative is.",
            "zh": "æœ¬èŠ‚ä»¥åŠæœ¬ç« å…¶ä½™éƒ¨åˆ†çš„è®¨è®ºå‡å®šæ‚¨å¯¹å¾®åˆ†æœ‰åŸºæœ¬çš„äº†è§£ï¼Œç‰¹åˆ«æ˜¯ä»€ä¹ˆæ˜¯å¯¼æ•°ã€å¦‚ä½•è®¡ç®—è¿ç»­å‡½æ•°çš„å¯¼æ•°ã€å¾®åˆ†çš„é“¾å¼æ³•åˆ™ä»¥åŠä»€ä¹ˆæ˜¯åå¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "25. This question is inspired by Tsanas and Xifara (2012), and although the data used is artificially generated, it is based on the Energy Efficiency Dataset available from the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Energy+efficiency/.",
            "zh": "25. è¿™ä¸ªé—®é¢˜çš„çµæ„Ÿæ¥è‡ª Tsanas å’Œ Xifara ï¼ˆ2012ï¼‰ï¼Œè™½ç„¶ä½¿ç”¨çš„æ•°æ®æ˜¯äººå·¥ç”Ÿæˆçš„ï¼Œä½†å®ƒæ˜¯åŸºäº UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBache å’Œ Lichmanï¼Œ2013 å¹´ï¼‰æä¾›çš„èƒ½æºæ•ˆç‡æ•°æ®é›†ï¼Œarchive.ics.uci.edu/ml/datasets/Energy+efficiency/ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if we had 10,000 instances in our dataset and we wish to have 10 bins, then bin 1 would contain the 1,000 instances with the lowest values for the feature, and so on, up to bin 10, which would contain the 1,000 instances with the highest feature values.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çš„æ•°æ®é›†ä¸­æœ‰ 10,000 ä¸ªå®ä¾‹ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›æœ‰ 10 ä¸ª binï¼Œåˆ™ bin 1 å°†åŒ…å«å…·æœ‰æœ€ä½ç‰¹å¾å€¼çš„ 1,000 ä¸ªå®ä¾‹ï¼Œä¾æ­¤ç±»æ¨ï¼Œæœ€å¤šåŒ…å« bin 10ï¼Œå®ƒå°†åŒ…å«å…·æœ‰æœ€é«˜ç‰¹å¾å€¼çš„ 1,000 ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The SSDS imaging camera captures images in five distinct photometric bands:7 ultra-violet (u), green (g), red (r), far-red (i), and near infrared (z).",
            "zh": "SSDS æˆåƒç›¸æœºä»¥äº”ä¸ªä¸åŒçš„å…‰åº¦æ³¢æ®µæ•è·å›¾åƒï¼š7 ç´«å¤– ï¼ˆuï¼‰ã€ç»¿è‰² ï¼ˆgï¼‰ã€çº¢è‰² ï¼ˆrï¼‰ã€è¿œçº¢å¤– ï¼ˆiï¼‰ å’Œè¿‘çº¢å¤– ï¼ˆzï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "14â€…â€…â€…The Art of Machine Learning for Predictive Data Analytics",
            "zh": "14 é¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ è‰ºæœ¯"
        }
    },
    {
        "translation": {
            "en": "0.80",
            "zh": "0.80"
        }
    },
    {
        "translation": {
            "en": "After deployment, the analytics team at the supermarket chain uses the stability index to monitor the performance of this model.",
            "zh": "éƒ¨ç½²åï¼Œè¿é”è¶…å¸‚çš„åˆ†æå›¢é˜Ÿä½¿ç”¨ç¨³å®šæ€§æŒ‡æ•°æ¥ç›‘æ§æ­¤æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "relative frequency, 245, 757, 759",
            "zh": "ç›¸å¯¹é¢‘ç‡ï¼Œ245ã€757ã€759"
        }
    },
    {
        "translation": {
            "en": "The best-performing model was the 3-level logistic regression model after feature selection (the performance of this model is shown in Table 13.7(b)[723]).",
            "zh": "è¡¨ç°æœ€å¥½çš„æ¨¡å‹æ˜¯ç‰¹å¾é€‰æ‹©åçš„3çº§é€»è¾‘å›å½’æ¨¡å‹ï¼ˆè¯¥æ¨¡å‹çš„æ€§èƒ½å¦‚è¡¨13.7ï¼ˆbï¼‰[723]æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The scientists at SDSS wanted Jocelyn to build a machine learning model that could examine sky objects that their current rule-based system had flagged as being galaxies and categorize them as belonging to the appropriate morphological group.",
            "zh": "SDSSçš„ç§‘å­¦å®¶ä»¬å¸Œæœ›Jocelynå»ºç«‹ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ£€æŸ¥ä»–ä»¬å½“å‰åŸºäºè§„åˆ™çš„ç³»ç»Ÿæ ‡è®°ä¸ºæ˜Ÿç³»çš„å¤©ç©ºç‰©ä½“ï¼Œå¹¶å°†å®ƒä»¬å½’ç±»ä¸ºå±äºé€‚å½“çš„å½¢æ€ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "These figures show that, on average, fewer customers churn when the churn prediction model is used to select which customers to call.",
            "zh": "è¿™äº›æ•°å­—è¡¨æ˜ï¼Œå¹³å‡è€Œè¨€ï¼Œå½“ä½¿ç”¨å®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹æ¥é€‰æ‹©è¦å‘¼å«çš„å®¢æˆ·æ—¶ï¼Œå®¢æˆ·æµå¤±çš„æ¬¡æ•°ä¼šå‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "A linear regression model, for example, assumes that the relationship between the descriptive features and the target is linear (this is a strong assumption about the distribution in the domain).",
            "zh": "ä¾‹å¦‚ï¼Œçº¿æ€§å›å½’æ¨¡å‹å‡è®¾æè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ä¹‹é—´çš„å…³ç³»æ˜¯çº¿æ€§çš„ï¼ˆè¿™æ˜¯å…³äºåŸŸä¸­åˆ†å¸ƒçš„å¼ºå‡è®¾ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The top segment of Table 8.15[471] lists the logit values for Neurons 8, 9, and 10 for each of the examples in the mini-batch (these logits are taken directly from Figure 8.28[470]).",
            "zh": "è¡¨ 8.15[471] çš„é¡¶éƒ¨éƒ¨åˆ†åˆ—å‡ºäº†å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„ç¥ç»å…ƒ 8ã€9 å’Œ 10 çš„ logit å€¼ï¼ˆè¿™äº› logit ç›´æ¥å–è‡ªå›¾ 8.28[470]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We explain covariance matrices in Section 3.5.2[81].",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬3.5.2èŠ‚[81]ä¸­è§£é‡Šäº†åæ–¹å·®çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.104)[501] defines how the activations for the hidden layer for input t are generated.",
            "zh": "ç­‰å¼ï¼ˆ8.104ï¼‰[501]å®šä¹‰äº†å¦‚ä½•ç”Ÿæˆè¾“å…¥tçš„éšè—å±‚çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although there is some blurring around the edges, these look remarkably similar to the original images.",
            "zh": "è™½ç„¶è¾¹ç¼˜æœ‰äº›æ¨¡ç³Šï¼Œä½†è¿™äº›çœ‹èµ·æ¥ä¸åŸå§‹å›¾åƒéå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "spectral clustering, 629",
            "zh": "å…‰è°±èšç±»ï¼Œ629"
        }
    },
    {
        "translation": {
            "en": "In the email classification example we have been following, the misclassification rate would be",
            "zh": "åœ¨æˆ‘ä»¬ä¸€ç›´å…³æ³¨çš„ç”µå­é‚®ä»¶åˆ†ç±»ç¤ºä¾‹ä¸­ï¼Œé”™è¯¯åˆ†ç±»ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "Examples of typical data quality issues include an instance that is missing values for one or more descriptive features, an instance that has an extremely high value for a feature, or an instance that has an inappropriate level for a feature.",
            "zh": "å…¸å‹æ•°æ®è´¨é‡é—®é¢˜çš„ç¤ºä¾‹åŒ…æ‹¬ç¼ºå°‘ä¸€ä¸ªæˆ–å¤šä¸ªæè¿°æ€§ç‰¹å¾å€¼çš„å®ä¾‹ã€å…·æœ‰æé«˜ç‰¹å¾å€¼çš„å®ä¾‹æˆ–å…·æœ‰ä¸é€‚å½“ç‰¹å¾çº§åˆ«çš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For an auto-encoder network to be able to reproduce the feature values for a query instance that are presented at its input layer at its output layer, the low-dimensional representation at the middle bottleneck layer needs to capture almost all the useful information contained in the original input features.",
            "zh": "ä¸ºäº†ä½¿è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œèƒ½å¤Ÿé‡ç°æŸ¥è¯¢å®ä¾‹çš„ç‰¹å¾å€¼ï¼Œè¿™äº›ç‰¹å¾å€¼åœ¨å…¶è¾“å…¥å±‚çš„è¾“å‡ºå±‚å‘ˆç°ï¼Œä¸­é—´ç“¶é¢ˆå±‚çš„ä½ç»´è¡¨ç¤ºéœ€è¦æ•è·åŸå§‹è¾“å…¥ç‰¹å¾ä¸­åŒ…å«çš„å‡ ä¹æ‰€æœ‰æœ‰ç”¨ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "CUSTOMERCARECALLS",
            "zh": "å®¢æˆ·æœåŠ¡ç”µè¯"
        }
    },
    {
        "translation": {
            "en": "Some episodes of games played by the TwentyTwos agent showing the cards dealt, as well as the states, actions, and rewards. Note that rewards are shown on the row indicating the action that led to them, not the state that followed that action.",
            "zh": "TwentyTwosç‰¹å·¥ç©çš„ä¸€äº›æ¸¸æˆæƒ…èŠ‚æ˜¾ç¤ºäº†å‘ç‰Œï¼Œä»¥åŠçŠ¶æ€ï¼Œè¡ŒåŠ¨å’Œå¥–åŠ±ã€‚è¯·æ³¨æ„ï¼Œå¥–åŠ±æ˜¾ç¤ºåœ¨æŒ‡ç¤ºå¯¼è‡´å¥–åŠ±çš„æ“ä½œçš„è¡Œä¸Šï¼Œè€Œä¸æ˜¯è¯¥æ“ä½œä¹‹åçš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.4[616] shows that membership of clusters 1 and 2 is most associated with DATA USAGE, whereas membership of 3 is most associated with CALL VOLUME.",
            "zh": "è¡¨ 10.4[616] æ˜¾ç¤ºï¼Œé›†ç¾¤ 1 å’Œ 2 çš„æˆå‘˜èµ„æ ¼ä¸ DATA USAGE æœ€ç›¸å…³ï¼Œè€Œ 3 çš„æˆå‘˜èµ„æ ¼ä¸ CALL VOLUME å…³è”æœ€å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "The first tree constructed achieved an average class accuracy7 of 74.873% on the hold-out test set, which was reasonably encouraging.",
            "zh": "æ„å»ºçš„ç¬¬ä¸€æ£µæ ‘åœ¨ä¿æŒæµ‹è¯•é›†ä¸Šè¾¾åˆ°äº† 74.873% çš„å¹³å‡ç±»å‡†ç¡®ç‡7ï¼Œè¿™æ˜¯ç›¸å½“ä»¤äººé¼“èˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.1.4â€ƒBootstrappingâ€ƒThe next sampling method we will look at is bootstrapping, and in particular the Îµ0 bootstrap.",
            "zh": "9.4.1.4 è‡ªä¸¾ æˆ‘ä»¬å°†ç ”ç©¶çš„ä¸‹ä¸€ä¸ªé‡‡æ ·æ–¹æ³•æ˜¯è‡ªä¸¾ï¼Œç‰¹åˆ«æ˜¯ Îµ0 è‡ªä¸¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the forward propagation of d2 through the network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "d2 åœ¨ç½‘ç»œä¸­å‰å‘ä¼ æ’­çš„å›¾ç¤ºæ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ï¼Œä»¥åŠç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒå’Œ z å’Œæ¿€æ´»å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, the probability of an agent in the PM-DH state remaining in that state after choosing the Twist action: .",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘åœ¨é€‰æ‹© Twist æ“ä½œåå¤„äº PM-DH çŠ¶æ€çš„ä»£ç†ä¿æŒè¯¥çŠ¶æ€çš„æ¦‚ç‡ï¼šã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.1",
            "zh": "å›¾ 13.1"
        }
    },
    {
        "translation": {
            "en": "0.55",
            "zh": "0.55"
        }
    },
    {
        "translation": {
            "en": "The subset selection component in forward sequential selection can use any of the approaches described above and moves the search process to a new feature subset.",
            "zh": "å‰å‘é¡ºåºé€‰æ‹©ä¸­çš„å­é›†é€‰æ‹©ç»„ä»¶å¯ä»¥ä½¿ç”¨ä¸Šè¿°ä»»ä½•æ–¹æ³•ï¼Œå¹¶å°†æœç´¢è¿‡ç¨‹ç§»åŠ¨åˆ°æ–°çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We would like to thank our colleagues and students for the help and patience they extended to us over the last few years.",
            "zh": "æˆ‘ä»¬è¦æ„Ÿè°¢æˆ‘ä»¬çš„åŒäº‹å’Œå­¦ç”Ÿåœ¨è¿‡å»å‡ å¹´ä¸­ç»™äºˆæˆ‘ä»¬çš„å¸®åŠ©å’Œè€å¿ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.9[615] shows the distributions of each feature for the full population and for each cluster so that the differences can be compared.",
            "zh": "å›¾10.9[615]æ˜¾ç¤ºäº†æ¯ä¸ªç‰¹å¾åœ¨å…¨ç§ç¾¤å’Œæ¯ä¸ªèšç±»ä¸­çš„åˆ†å¸ƒï¼Œä»¥ä¾¿æ¯”è¾ƒå·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(b)[626] shows examples of the reconstructions generated by the auto-encoder network before it has been trained for the digits shown in Figure 10.15(a)[626].",
            "zh": "å›¾10.15ï¼ˆbï¼‰[626]æ˜¾ç¤ºäº†è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œåœ¨é’ˆå¯¹å›¾10.15ï¼ˆaï¼‰[626]æ‰€ç¤ºçš„æ•°å­—è¿›è¡Œè®­ç»ƒä¹‹å‰ç”Ÿæˆçš„é‡å»ºç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Before performing this operation, however, Jocelyn first checked that the percentage of missing values was approximately 2% in each of the 3 levels (and in each of the levels in the 5-level model) to ensure that there was no relationship between missing values and galaxy type.",
            "zh": "ç„¶è€Œï¼Œåœ¨æ‰§è¡Œæ­¤æ“ä½œä¹‹å‰ï¼ŒJocelyn é¦–å…ˆæ£€æŸ¥äº† 3 ä¸ªçº§åˆ«ä¸­æ¯ä¸ªçº§åˆ«ï¼ˆä»¥åŠ 5 çº§åˆ«æ¨¡å‹ä¸­çš„æ¯ä¸ªçº§åˆ«ï¼‰ç¼ºå¤±å€¼çš„ç™¾åˆ†æ¯”çº¦ä¸º 2%ï¼Œä»¥ç¡®ä¿ç¼ºå¤±å€¼ä¸æ˜Ÿç³»ç±»å‹ä¹‹é—´æ²¡æœ‰å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Quinlan (1986) originally described the ID3 algorithm, and Quinlan (1993) and Breiman (1993) are two of the best-known books on decision trees. Loh (2011) provides a good overview of more recent developments in tree induction algorithms.",
            "zh": "Quinlan ï¼ˆ1986ï¼‰ æœ€åˆæè¿°äº† ID3 ç®—æ³•ï¼ŒQuinlan ï¼ˆ1993ï¼‰ å’Œ Breiman ï¼ˆ1993ï¼‰ æ˜¯å…³äºå†³ç­–æ ‘çš„ä¸¤æœ¬æœ€è‘—åçš„ä¹¦ç±ã€‚Lohï¼ˆ2011ï¼‰å¾ˆå¥½åœ°æ¦‚è¿°äº†æ ‘è¯±å¯¼ç®—æ³•çš„æœ€æ–°å‘å±•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(a)[329] shows the impact of a very small learning rate.",
            "zh": "å›¾7.7ï¼ˆaï¼‰[329]æ˜¾ç¤ºäº†éå¸¸å°çš„å­¦ä¹ ç‡çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "28. In the following calculations we have abbreviated feature names as follows: GC = GINI COEF, LE = LIFE EXP, and SY = SCHOOL YEARS.",
            "zh": "28. åœ¨ä»¥ä¸‹è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å¯¹ç‰¹å¾åç§°è¿›è¡Œäº†å¦‚ä¸‹ç¼©å†™ï¼šGC = GINI COEFï¼ŒLE = LIFE EXPï¼ŒSY = å­¦å¹´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The most common approach to error-based machine learning for predictive analytics is to use multivariable linear regression with gradient descent to train a best-fit model for a given training dataset. This section explains how this works. First, we describe how we extend the simple linear regression model described in the previous section to handle multiple descriptive features, and then we describe the gradient descent algorithm.",
            "zh": "ç”¨äºé¢„æµ‹åˆ†æçš„åŸºäºé”™è¯¯çš„æœºå™¨å­¦ä¹ çš„æœ€å¸¸è§æ–¹æ³•æ˜¯ä½¿ç”¨å…·æœ‰æ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’æ¥ä¸ºç»™å®šçš„è®­ç»ƒæ•°æ®é›†è®­ç»ƒæœ€ä½³æ‹Ÿåˆæ¨¡å‹ã€‚æœ¬èŠ‚å°†ä»‹ç»å…¶å·¥ä½œåŸç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•æ‰©å±•ä¸Šä¸€èŠ‚ä¸­æè¿°çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ä»¥å¤„ç†å¤šä¸ªæè¿°æ€§ç‰¹å¾ï¼Œç„¶åæˆ‘ä»¬æè¿°äº†æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the calculation of these error gradients involves the Î´ terms.",
            "zh": "ä½†æ˜¯ï¼Œè¿™äº›è¯¯å·®æ¢¯åº¦çš„è®¡ç®—æ¶‰åŠÎ´é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This could be problematic: a model trained on this data might ignore seasonal effects such as Christmas.",
            "zh": "è¿™å¯èƒ½æ˜¯æœ‰é—®é¢˜çš„ï¼šæ ¹æ®è¿™äº›æ•°æ®è®­ç»ƒçš„æ¨¡å‹å¯èƒ½ä¼šå¿½ç•¥å­£èŠ‚æ€§å½±å“ï¼Œä¾‹å¦‚åœ£è¯èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.2â€ƒMeasuring Covariance and Correlation",
            "zh": "3.5.2 æµ‹é‡åæ–¹å·®å’Œç›¸å…³æ€§"
        }
    },
    {
        "translation": {
            "en": "We use a lowercase w to indicate a single weight on a connection between two neurons. We use a double subscript to indicate the neurons that are connected, with the convention that the first subscript is the neuron the connection goes to, and the second subscript is the neuron the connection is from. For example, wi,k is the weight on the connection from neuron k to neuron i.",
            "zh": "æˆ‘ä»¬ä½¿ç”¨å°å†™çš„ w æ¥è¡¨ç¤ºä¸¤ä¸ªç¥ç»å…ƒä¹‹é—´è¿æ¥ä¸Šçš„å•ä¸ªæƒé‡ã€‚æˆ‘ä»¬ä½¿ç”¨åŒä¸‹æ ‡æ¥è¡¨ç¤ºè¿æ¥çš„ç¥ç»å…ƒï¼Œçº¦å®šç¬¬ä¸€ä¸ªä¸‹æ ‡æ˜¯è¿æ¥æ‰€è¦å»çš„ç¥ç»å…ƒï¼Œç¬¬äºŒä¸ªä¸‹æ ‡æ˜¯è¿æ¥æ‰€æ¥è‡ªçš„ç¥ç»å…ƒã€‚ä¾‹å¦‚ï¼Œwiï¼Œk æ˜¯ä»ç¥ç»å…ƒ k åˆ°ç¥ç»å…ƒ i çš„è¿æ¥æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For probabilities near 0, the negative log returns a large number, and for probabilities near 1 the negative log returns a value near 0.",
            "zh": "å¯¹äºæ¥è¿‘ 0 çš„æ¦‚ç‡ï¼Œè´Ÿå¯¹æ•°è¿”å›ä¸€ä¸ªå¤§æ•°ï¼Œå¯¹äºæ¥è¿‘ 1 çš„æ¦‚ç‡ï¼Œè´Ÿå¯¹æ•°è¿”å›æ¥è¿‘ 0 çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is reflected in a further decrease in the sampling density.",
            "zh": "è¿™åæ˜ åœ¨é‡‡æ ·å¯†åº¦çš„è¿›ä¸€æ­¥é™ä½ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "A real advantage of the decision tree approach is that it has the ability to model the interactions between descriptive features.",
            "zh": "å†³ç­–æ ‘æ–¹æ³•çš„çœŸæ­£ä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿå¯¹æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„äº¤äº’è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ted organized a full download of the SDSS photo imaging data repository for all the objects for which Galaxy Zoo labels existed.",
            "zh": "Tedç»„ç»‡äº†SDSSç…§ç‰‡æˆåƒæ•°æ®å­˜å‚¨åº“çš„å®Œæ•´ä¸‹è½½ï¼Œå…¶ä¸­åŒ…å«Galaxy Zooæ ‡ç­¾çš„æ‰€æœ‰å¯¹è±¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "inductive learning, 11, 729",
            "zh": "å½’çº³å­¦ä¹ ï¼Œ11,729"
        }
    },
    {
        "translation": {
            "en": "The length of DropMask should be equal to the number of neurons in the layer (see Line 7[476]).",
            "zh": "DropMask çš„é•¿åº¦åº”ç­‰äºå±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡ï¼ˆå‚è§ç¬¬ 7 è¡Œ[476]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of model induction with feature selection.",
            "zh": "å…·æœ‰ç‰¹å¾é€‰æ‹©çš„æ¨¡å‹å½’çº³è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a programming language for advanced analytics has a significantly steeper learning curve than using an application-based solution.",
            "zh": "ä½¿ç”¨ç¼–ç¨‹è¯­è¨€è¿›è¡Œé«˜çº§åˆ†æçš„å­¦ä¹ æ›²çº¿æ¯”ä½¿ç”¨åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆè¦é™¡å³­å¾—å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "In Line 1[420] the data is split into mini-batches where X(i) is a matrix that contains the descriptive features for each of the examples in mini-batch i, with one column per example, and Y(i) is a matrix (or vector) containing the corresponding labels for the examples in mini-batch i.",
            "zh": "åœ¨ç¬¬ 1 è¡Œ[420]ä¸­ï¼Œæ•°æ®è¢«æ‹†åˆ†ä¸ºå°æ‰¹é‡ï¼Œå…¶ä¸­ Xï¼ˆiï¼‰ æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­åŒ…å«å°æ‰¹é‡ i ä¸­æ¯ä¸ªç¤ºä¾‹çš„æè¿°æ€§ç‰¹å¾ï¼Œæ¯ä¸ªç¤ºä¾‹ä¸€åˆ—ï¼ŒYï¼ˆiï¼‰ æ˜¯ä¸€ä¸ªçŸ©é˜µï¼ˆæˆ–å‘é‡ï¼‰ï¼Œå…¶ä¸­åŒ…å«å°æ‰¹é‡ i ä¸­ç¤ºä¾‹çš„ç›¸åº”æ ‡ç­¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "and second, experimentation is always required to determine which measure of similarity will be most effective for a specific prediction model.",
            "zh": "å…¶æ¬¡ï¼Œå§‹ç»ˆéœ€è¦è¿›è¡Œå®éªŒæ¥ç¡®å®šå“ªç§ç›¸ä¼¼æ€§åº¦é‡å¯¹ç‰¹å®šé¢„æµ‹æ¨¡å‹æœ€æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes (MDPs) are an extremely useful mathematical tool for framing reinforcement learning problems; these are covered next.",
            "zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ ï¼ˆMDPï¼‰ æ˜¯æ„å»ºå¼ºåŒ–å­¦ä¹ é—®é¢˜çš„éå¸¸æœ‰ç”¨çš„æ•°å­¦å·¥å…·;ä¸‹é¢å°†ä»‹ç»è¿™äº›å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "[Claim prediction] Data Requirements: This solution would require that a large collection of historical claims marked as fraudulent and non-fraudulent exist.",
            "zh": "[ç´¢èµ”é¢„æµ‹]æ•°æ®è¦æ±‚ï¼šæ­¤è§£å†³æ–¹æ¡ˆè¦æ±‚å­˜åœ¨å¤§é‡æ ‡è®°ä¸ºæ¬ºè¯ˆæ€§å’Œéæ¬ºè¯ˆæ€§çš„å†å²å£°æ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "HEART RATE: The patientâ€™s heart rate",
            "zh": "å¿ƒç‡ï¼šæ‚£è€…çš„å¿ƒç‡"
        }
    },
    {
        "translation": {
            "en": "A prediction model could be trained to identify the customers from the AT customer base who were most likely to churn in the near future.",
            "zh": "å¯ä»¥è®­ç»ƒä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œä»¥è¯†åˆ«ATå®¢æˆ·ç¾¤ä¸­æœ€æœ‰å¯èƒ½åœ¨ä¸ä¹…çš„å°†æ¥æµå¤±çš„å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the conclusion of the leave-one-out cross validation process, a performance measure will have been calculated for every instance in the dataset. In the same way as we saw in Table 9.4[544] for k-fold cross validation, these performance measures are aggregated across all the folds to arrive at an overall measure of model performance.",
            "zh": "åœ¨â€œç•™ä¸€â€äº¤å‰éªŒè¯è¿‡ç¨‹ç»“æŸæ—¶ï¼Œå°†ä¸ºæ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹è®¡ç®—æ€§èƒ½åº¦é‡ã€‚ä¸æˆ‘ä»¬åœ¨è¡¨ 9.4[544] ä¸­çœ‹åˆ°çš„ k å€äº¤å‰éªŒè¯ç›¸åŒï¼Œè¿™äº›æ€§èƒ½æµ‹é‡è¢«æ±‡æ€»åˆ°æ‰€æœ‰æŠ˜å ä¸­ï¼Œä»¥å¾—å‡ºæ¨¡å‹æ€§èƒ½çš„æ•´ä½“åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, consider the symptoms of meningitis.",
            "zh": "ä¾‹å¦‚ï¼Œè€ƒè™‘è„‘è†œç‚çš„ç—‡çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "model-based clustering, 629",
            "zh": "åŸºäºæ¨¡å‹çš„èšç±»ï¼Œ629"
        }
    },
    {
        "translation": {
            "en": "The fundamental element in the design of these networks was to remove the repeated multiplication of error gradients by weight matrices during backpropagation through time.",
            "zh": "è¿™äº›ç½‘ç»œè®¾è®¡çš„åŸºæœ¬è¦ç´ æ˜¯åœ¨æ—¶é—´åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¶ˆé™¤è¯¯å·®æ¢¯åº¦ä¹˜ä»¥æƒé‡çŸ©é˜µçš„é‡å¤ä¹˜æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "multivariable linear regression with gradient descent, 11, 311, 731",
            "zh": "æ¢¯åº¦ä¸‹é™çš„å¤šå˜é‡çº¿æ€§å›å½’ï¼Œ 11ï¼Œ 311ï¼Œ 731"
        }
    },
    {
        "translation": {
            "en": "The first is the distance measure, Dist, to be used to compare instances and clusters.",
            "zh": "ç¬¬ä¸€ä¸ªæ˜¯è·ç¦»åº¦é‡ Distï¼Œç”¨äºæ¯”è¾ƒå®ä¾‹å’Œé›†ç¾¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "raw features, 34, 41, 45",
            "zh": "åŸå§‹ç‰¹å¾ï¼Œ 34ï¼Œ 41ï¼Œ 45"
        }
    },
    {
        "translation": {
            "en": "(a) A complete ROC curve for the email classification example; and (b) a selection of ROC curves for different models trained on the same prediction task.",
            "zh": "ï¼ˆaï¼‰ ç”µå­é‚®ä»¶åˆ†ç±»ç¤ºä¾‹çš„å®Œæ•´ ROC æ›²çº¿;ï¼ˆbï¼‰ä¸ºåœ¨åŒä¸€é¢„æµ‹ä»»åŠ¡ä¸Šè®­ç»ƒçš„ä¸åŒæ¨¡å‹é€‰æ‹©ROCæ›²çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the time available to the project, Jocelyn did not pursue this avenue and, in consultation with Edwin, decided to continue with just the 3-level model.",
            "zh": "æ ¹æ®è¯¥é¡¹ç›®çš„å¯ç”¨æ—¶é—´ï¼ŒJocelyn æ²¡æœ‰é‡‡ç”¨è¿™æ¡é€”å¾„ï¼Œåœ¨ä¸ Edwin åå•†åï¼Œå†³å®šç»§ç»­ä½¿ç”¨ 3 çº§æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.18",
            "zh": "0.18"
        }
    },
    {
        "translation": {
            "en": "0.30",
            "zh": "0.30"
        }
    },
    {
        "translation": {
            "en": "In Chapter 1 we introduce machine learning and explain its role within a standard data analytics project lifecycle.",
            "zh": "åœ¨ç¬¬ 1 ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†æœºå™¨å­¦ä¹ ï¼Œå¹¶è§£é‡Šäº†å®ƒåœ¨æ ‡å‡†æ•°æ®åˆ†æé¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸­çš„ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, we can stop creating subtrees when the number of instances in a partition falls below a threshold, when the information gain (or whatever other feature selection metric is being used) measured at a node is not deemed to be sufficient to make partitioning the data worthwhile,20 or when the depth of the tree goes beyond a predefined limit.",
            "zh": "ä¾‹å¦‚ï¼Œå½“åˆ†åŒºä¸­çš„å®ä¾‹æ•°ä½äºé˜ˆå€¼æ—¶ï¼Œå½“åœ¨èŠ‚ç‚¹ä¸Šæµ‹é‡çš„ä¿¡æ¯å¢ç›Šï¼ˆæˆ–æ­£åœ¨ä½¿ç”¨çš„ä»»ä½•å…¶ä»–ç‰¹å¾é€‰æ‹©æŒ‡æ ‡ï¼‰è¢«è®¤ä¸ºä¸è¶³ä»¥ä½¿æ•°æ®åˆ†åŒºå€¼å¾—æ—¶ï¼Œ20 æˆ–è€…å½“æ ‘çš„æ·±åº¦è¶…è¿‡é¢„å®šä¹‰çš„é™åˆ¶æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åœæ­¢åˆ›å»ºå­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "There are many different approaches to binning.",
            "zh": "æœ‰è®¸å¤šä¸åŒçš„åˆ†ç®±æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The hierarchical relationship between an analytics solution, domain concepts, and descriptive features.",
            "zh": "åˆ†æè§£å†³æ–¹æ¡ˆã€é¢†åŸŸæ¦‚å¿µå’Œæè¿°æ€§åŠŸèƒ½ä¹‹é—´çš„å±‚æ¬¡ç»“æ„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The average number of out-of-bundle minutes used by the customer each month",
            "zh": "å®¢æˆ·æ¯æœˆä½¿ç”¨çš„å¹³å‡æ†ç»‘å¤–åˆ†é’Ÿæ•°"
        }
    },
    {
        "translation": {
            "en": "TN, 537",
            "zh": "ç”°çº³è¥¿å·ï¼Œ537"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset ğ’Ÿ7 in Figure 4.8[138].",
            "zh": "å›¾4.8[138]ä¸­æ•°æ®é›†D7çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second error gradient is the rate of change of the network error with respect to changes in the weights of the network.",
            "zh": "ç¬¬äºŒä¸ªè¯¯å·®æ¢¯åº¦æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç½‘ç»œæƒé‡å˜åŒ–çš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second things to check for in the cardinality column are categorical features incorrectly labeled as continuous.",
            "zh": "åœ¨åŸºæ•°åˆ—ä¸­è¦æ£€æŸ¥çš„ç¬¬äºŒä»¶äº‹æ˜¯é”™è¯¯åœ°æ ‡è®°ä¸ºè¿ç»­çš„åˆ†ç±»è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Models trained by reducing the sum of squared errors, for example, linear regression, are the most natural fit for making predictions for continuous target features.",
            "zh": "é€šè¿‡å‡å°‘å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼ˆä¾‹å¦‚çº¿æ€§å›å½’ï¼‰æ¥è®­ç»ƒçš„æ¨¡å‹æ˜¯é¢„æµ‹è¿ç»­ç›®æ ‡ç‰¹å¾çš„æœ€è‡ªç„¶çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These Î´s are the rate of change of the network error with respect to the weighted sum of a neuron.",
            "zh": "è¿™äº› Î´ æ˜¯ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒåŠ æƒå’Œçš„å˜åŒ–ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although learning rate decay almost always leads to better performance than a fixed learning rate, it still does require that problem-dependent values are chosen for Î±0 and c.",
            "zh": "å°½ç®¡å­¦ä¹ ç‡è¡°å‡å‡ ä¹æ€»æ˜¯æ¯”å›ºå®šå­¦ä¹ ç‡å¸¦æ¥æ›´å¥½çš„æ€§èƒ½ï¼Œä½†å®ƒä»ç„¶éœ€è¦ä¸º Î±0 å’Œ c é€‰æ‹©ä¸é—®é¢˜ç›¸å…³çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.17â€…â€…â€…The effect of using a Mahalanobis versus Euclidean distance. A marks the central tendency of the dataset in Figure 5.15(c)[219]. The ellipses plot the Mahalanobis distance contours from A that B and C lie on. In Euclidean terms, B and C are equidistant from A; however, using the Mahalanobis distance, C is much closer to A than B.",
            "zh": "5.17 ä½¿ç”¨é©¬æ°è·ç¦»ä¸æ¬§å‡ é‡Œå¾—è·ç¦»çš„å½±å“ã€‚Aåœ¨å›¾5.15ï¼ˆcï¼‰ä¸­æ ‡è®°äº†æ•°æ®é›†çš„ä¸­å¿ƒè¶‹åŠ¿[219]ã€‚æ¤­åœ†ç»˜åˆ¶äº† B å’Œ C æ‰€åœ¨çš„ A çš„é©¬æ°è·ç¦»ç­‰å€¼çº¿ã€‚åœ¨æ¬§å‡ é‡Œå¾—æœ¯è¯­ä¸­ï¼ŒB å’Œ C ä¸ A ç­‰è·;ç„¶è€Œï¼Œä½¿ç”¨é©¬æ°è·ç¦»ï¼ŒC æ¯” B æ›´æ¥è¿‘ Aã€‚"
        }
    },
    {
        "translation": {
            "en": "The danger of this is that any analysis or modeling we perform on this sample will not be relevant to the overall dataset.",
            "zh": "è¿™æ ·åšçš„å±é™©åœ¨äºï¼Œæˆ‘ä»¬å¯¹è¿™ä¸ªæ ·æœ¬æ‰§è¡Œçš„ä»»ä½•åˆ†ææˆ–å»ºæ¨¡éƒ½ä¸æ•´ä¸ªæ•°æ®é›†æ— å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The location of the peak value is defined by the parameter Î¼ (pronounced mu), which denotes the population mean (in other words, the mean value of the feature if we had access to every value that could possibly occur).",
            "zh": "å³°å€¼çš„ä½ç½®ç”±å‚æ•° Î¼ï¼ˆå‘éŸ³ä¸º muï¼‰å®šä¹‰ï¼Œè¯¥å‚æ•°è¡¨ç¤ºæ€»ä½“å‡å€¼ï¼ˆæ¢å¥è¯è¯´ï¼Œå¦‚æœæˆ‘ä»¬å¯ä»¥è®¿é—®å¯èƒ½å‡ºç°çš„æ¯ä¸ªå€¼ï¼Œåˆ™è¡¨ç¤ºç‰¹å¾çš„å¹³å‡å€¼ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The result is that instance C is much closer to A than B and so should be considered a member of the same population as this dataset.",
            "zh": "ç»“æœæ˜¯å®ä¾‹ C æ¯” B æ›´æ¥è¿‘ Aï¼Œå› æ­¤åº”è¢«è§†ä¸ºä¸è¯¥æ•°æ®é›†ç›¸åŒçš„æ€»ä½“æˆå‘˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "random sampling, 92",
            "zh": "éšæœºæŠ½æ ·ï¼Œ92"
        }
    },
    {
        "translation": {
            "en": "8.24â€…â€…â€…The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with Î¼ = 0.0 and Ïƒ = 0.2.",
            "zh": "8.24 å›¾8.22[450]ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨Î¼ = 0.0å’ŒÏƒ = 0.2çš„æ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.2â€ƒWhat Is Machine Learning?",
            "zh": "1.2 ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the ReLU network changed during training when Î± = 0.1.",
            "zh": "è¯¥å›¾æ˜¾ç¤ºäº†å½“ Î± = 0.1 æ—¶ï¼ŒReLU ç½‘ç»œçš„å¹³æ–¹è¯¯å·®æ€»å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The following table40 lists a dataset containing the details of five participants in a heart disease study, and a target feature RISK, which describes their risk of heart disease. Each patient is described in terms of four binary descriptive features",
            "zh": "5. ä¸‹è¡¨40åˆ—å‡ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¿ƒè„ç—…ç ”ç©¶ä¸­äº”åå‚ä¸è€…çš„è¯¦ç»†ä¿¡æ¯ï¼Œä»¥åŠæè¿°ä»–ä»¬æ‚£å¿ƒè„ç—…é£é™©çš„ç›®æ ‡ç‰¹å¾RISKã€‚æ¯ä¸ªæ‚£è€…éƒ½ç”¨å››ä¸ªäºŒå…ƒæè¿°æ€§ç‰¹å¾æ¥æè¿°"
        }
    },
    {
        "translation": {
            "en": "(b) The image below shows a scatter plot matrix of the continuous features from this dataset (the correlation between LIFEEXPECTANCY and INFANTMORTALITY has been omitted). Discuss the relationships between the features in the dataset that this scatter plot highlights.",
            "zh": "ï¼ˆbï¼‰ ä¸‹å›¾æ˜¾ç¤ºäº†è¯¥æ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾çš„æ•£ç‚¹å›¾çŸ©é˜µï¼ˆçœç•¥äº†é¢„æœŸå¯¿å‘½å’Œå©´å„¿æ­»äº¡ç‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼‰ã€‚è®¨è®ºæ­¤æ•£ç‚¹å›¾çªå‡ºæ˜¾ç¤ºçš„æ•°æ®é›†ä¸­è¦ç´ ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Summary statistics for the three clusters found in the mobile phone customer dataset in Table 10.1[604] using k-means clustering (k = 3). Note, that the % missing and cardinality columns usually used are omitted here for legibility as these data quality issues will not arise in this simple example. They could be included when this approach is used on real datasets.",
            "zh": "ä½¿ç”¨k-meansèšç±»ï¼ˆk = 3ï¼‰åœ¨è¡¨10.1[604]çš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸­æ‰¾åˆ°çš„ä¸‰ä¸ªèšç±»çš„æ±‡æ€»ç»Ÿè®¡ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†ä¾¿äºé˜…è¯»ï¼Œæ­¤å¤„çœç•¥äº†é€šå¸¸ä½¿ç”¨çš„ç¼ºå¤±ç™¾åˆ†æ¯”å’ŒåŸºæ•°åˆ—ï¼Œå› ä¸ºåœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ä¸ä¼šå‡ºç°è¿™äº›æ•°æ®è´¨é‡é—®é¢˜ã€‚å½“è¿™ç§æ–¹æ³•ç”¨äºå®é™…æ•°æ®é›†æ—¶ï¼Œå¯ä»¥åŒ…æ‹¬å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of these properties is that a model learned by induction is not guaranteed to be correct.",
            "zh": "å…¶ä¸­ä¸€ä¸ªç‰¹æ€§æ˜¯ï¼Œé€šè¿‡å½’çº³å­¦ä¹ çš„æ¨¡å‹ä¸èƒ½ä¿è¯æ˜¯æ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This uses the entropy measure that is discussed in Section 4.2[120] as it does a good job of capturing in a single number the variety in a set of objects.",
            "zh": "è¿™ä½¿ç”¨äº†ç¬¬4.2èŠ‚[120]ä¸­è®¨è®ºçš„ç†µåº¦é‡ï¼Œå› ä¸ºå®ƒå¯ä»¥å¾ˆå¥½åœ°åœ¨å•ä¸ªæ•°å­—ä¸­æ•è·ä¸€ç»„å¯¹è±¡çš„å¤šæ ·æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.1â€ƒMultivariable Linear Regression",
            "zh": "7.3.1 å¤šå˜é‡çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "Card suits have no impact on the game (for example, 10 is equivalent to 10 ) and because there is an infinite deck, tracking the actual cards that have been dealt gives no advantage to the player.",
            "zh": "èŠ±è‰²å¯¹æ¸¸æˆæ²¡æœ‰å½±å“ï¼ˆä¾‹å¦‚ï¼Œ10 ç›¸å½“äº 10ï¼‰ï¼Œå¹¶ä¸”å› ä¸ºæœ‰ä¸€å‰¯æ— é™çš„ç‰Œç»„ï¼Œè·Ÿè¸ªå®é™…å‘çš„ç‰Œå¯¹ç©å®¶æ²¡æœ‰ä»»ä½•å¥½å¤„ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, most deep networks have many more than two hidden layers.",
            "zh": "ç„¶è€Œï¼Œå¤§å¤šæ•°æ·±åº¦ç½‘ç»œéƒ½æœ‰ä¸¤ä¸ªä»¥ä¸Šçš„éšè—å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, P(DICE1 = ) will return the likelihood of the event DICE1 = , and P(DICE1 = , DICE2 = ) will return the likelihood of the event where DICE1 = and DICE2 = .",
            "zh": "ä¾‹å¦‚ï¼ŒPï¼ˆDICE1 = ï¼‰ å°†è¿”å›äº‹ä»¶ DICE1 = çš„ä¼¼ç„¶ï¼ŒPï¼ˆDICE1 = ï¼Œ DICE2 = ï¼‰ å°†è¿”å› DICE1 = å’Œ DICE2 = çš„äº‹ä»¶çš„ä¼¼ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.12â€…â€…â€…The backpropagation of the Î´ values during the backward pass of the backpropagation algorithm.",
            "zh": "8.12 åå‘ä¼ æ’­ç®—æ³•å‘åä¼ é€’è¿‡ç¨‹ä¸­Î´å€¼çš„åå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "To ensure that we arrive at the optimal set of weights at the end of this journey across the error surface, we need to ensure that each step we take moves downward on the error surface. We do this by directing our steps according to the gradient of the error surface at each step. This is the gradient descent algorithm, which is one of the most important algorithms in all of computer science, let alone machine learning.",
            "zh": "ä¸ºäº†ç¡®ä¿æˆ‘ä»¬åœ¨ç©¿è¶Šè¯¯å·®è¡¨é¢çš„æ—…ç¨‹ç»“æŸæ—¶è¾¾åˆ°æœ€ä½³æƒé‡é›†ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æˆ‘ä»¬é‡‡å–çš„æ¯ä¸€æ­¥éƒ½åœ¨è¯¯å·®è¡¨é¢ä¸Šå‘ä¸‹ç§»åŠ¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ ¹æ®æ¯ä¸ªæ­¥éª¤çš„è¯¯å·®è¡¨é¢æ¢¯åº¦æ¥æŒ‡å¯¼æˆ‘ä»¬çš„æ­¥éª¤ã€‚è¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œå®ƒæ˜¯æ‰€æœ‰è®¡ç®—æœºç§‘å­¦ä¸­æœ€é‡è¦çš„ç®—æ³•ä¹‹ä¸€ï¼Œæ›´ä¸ç”¨è¯´æœºå™¨å­¦ä¹ äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent always starts in the start cell marked with an S. To demonstrate the workings of the Q-learning algorithm, we examine the process of using it to train an agent to navigate this environment.",
            "zh": "ä»£ç†å§‹ç»ˆåœ¨æ ‡æœ‰ S çš„èµ·å§‹å•å…ƒæ ¼ä¸­å¯åŠ¨ã€‚ä¸ºäº†æ¼”ç¤º Q å­¦ä¹ ç®—æ³•çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä½¿ç”¨å®ƒæ¥è®­ç»ƒæ™ºèƒ½ä½“æ¥å¯¼èˆªæ­¤ç¯å¢ƒçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For large problems like this, instead of implementing the action-value function,QÏ€(st,at), as a table storing the value of every action in every state, it would be better to learn a generalized version of the action-value function from observation of a small number of state and action pairs.",
            "zh": "å¯¹äºè¿™æ ·çš„å¤§é—®é¢˜ï¼Œä¸å…¶å°†åŠ¨ä½œå€¼å‡½æ•° QÏ€ï¼ˆstï¼Œatï¼‰ å®ç°ä¸ºå­˜å‚¨æ¯ä¸ªçŠ¶æ€ä¸‹æ¯ä¸ªåŠ¨ä½œå€¼çš„è¡¨ï¼Œä¸å¦‚é€šè¿‡è§‚å¯Ÿå°‘é‡çŠ¶æ€å’ŒåŠ¨ä½œå¯¹æ¥å­¦ä¹ åŠ¨ä½œå€¼å‡½æ•°çš„å¹¿ä¹‰ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although there are different approaches in the literature, a good approach is to use the following decay schedule:",
            "zh": "å°½ç®¡æ–‡çŒ®ä¸­æœ‰ä¸åŒçš„æ–¹æ³•ï¼Œä½†ä¸€ä¸ªå¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä»¥ä¸‹è¡°å‡æ—¶é—´è¡¨ï¼š"
        }
    },
    {
        "translation": {
            "en": "In fact, the final part of Equation (11.18)[652] is almost identical to Equation (11.16)[651] except for the explicit reference to an action in the latter.",
            "zh": "äº‹å®ä¸Šï¼Œç­‰å¼ï¼ˆ11.18ï¼‰[652]çš„æœ€åä¸€éƒ¨åˆ†ä¸ç­‰å¼ï¼ˆ11.16ï¼‰[651]å‡ ä¹ç›¸åŒï¼Œåªæ˜¯åœ¨åè€…ä¸­æ˜ç¡®å¼•ç”¨äº†ä¸€ä¸ªåŠ¨ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of using a decision tree to make a prediction for a query instance starts with testing the value of the descriptive feature at the root node of the tree. The result of this test determines which of the root nodeâ€™s children the process should then descend to. These two steps of testing the value of a descriptive feature and descending a level in the tree are then repeated until the process comes to a leaf node at which a prediction can be made.",
            "zh": "ä½¿ç”¨å†³ç­–æ ‘å¯¹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹çš„è¿‡ç¨‹é¦–å…ˆè¦æµ‹è¯•æ ‘æ ¹èŠ‚ç‚¹ä¸Šçš„æè¿°æ€§ç‰¹å¾çš„å€¼ã€‚æ­¤æµ‹è¯•çš„ç»“æœå†³å®šäº†è¿›ç¨‹éšååº”ä¸‹é™åˆ°æ ¹èŠ‚ç‚¹çš„å“ªä¸ªå­èŠ‚ç‚¹ã€‚ç„¶åé‡å¤è¿™ä¸¤ä¸ªæ­¥éª¤ï¼Œå³æµ‹è¯•æè¿°æ€§ç‰¹å¾çš„å€¼å’Œåœ¨æ ‘ä¸­ä¸‹é™ä¸€ä¸ªçº§åˆ«ï¼Œç›´åˆ°è¯¥è¿‡ç¨‹åˆ°è¾¾å¯ä»¥è¿›è¡Œé¢„æµ‹çš„å¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "One slight complication of this approach is that during training, the error of a model can fluctuate even without the occurrence of overfitting, for example if the learning rate is too high; therefore, applying a strict rule of stopping training immediately after the first time the validation error increases can be too conservative a criterion for stopping.",
            "zh": "è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªè½»å¾®å¤æ‚æ€§æ˜¯ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå³ä½¿æ²¡æœ‰å‘ç”Ÿè¿‡æ‹Ÿåˆï¼Œæ¨¡å‹çš„è¯¯å·®ä¹Ÿä¼šæ³¢åŠ¨ï¼Œä¾‹å¦‚ï¼Œå¦‚æœå­¦ä¹ ç‡å¤ªé«˜;å› æ­¤ï¼Œåœ¨éªŒè¯è¯¯å·®é¦–æ¬¡å¢åŠ åç«‹å³åœæ­¢è®­ç»ƒçš„ä¸¥æ ¼è§„åˆ™å¯èƒ½è¿‡äºä¿å®ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This flexibility in the network design space can be exploited to tailor a network to process different types of data.",
            "zh": "å¯ä»¥åˆ©ç”¨ç½‘ç»œè®¾è®¡ç©ºé—´çš„è¿™ç§çµæ´»æ€§æ¥å®šåˆ¶ç½‘ç»œä»¥å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the example in Table 9.1[537], 20 predictions are made in total, and out of these, 5 are incorrect (instances d1, d2, d12, d17, and d20). Therefore, the misclassification rate is calculated as , which is usually expressed as a percentage: 25%. This tells us that the model is incorrect about a quarter of the time. Misclassification rate can assume values in the range [0,1], and lower values indicate better performance.",
            "zh": "åœ¨è¡¨ 9.1[537] çš„ç¤ºä¾‹ä¸­ï¼Œæ€»å…±è¿›è¡Œäº† 20 ä¸ªé¢„æµ‹ï¼Œå…¶ä¸­ 5 ä¸ªä¸æ­£ç¡®ï¼ˆå®ä¾‹ d1ã€d2ã€d12ã€d17 å’Œ d20ï¼‰ã€‚å› æ­¤ï¼Œé”™è¯¯åˆ†ç±»ç‡è®¡ç®—ä¸º ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºç™¾åˆ†æ¯”ï¼š25%ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬ï¼Œæ¨¡å‹å¤§çº¦æœ‰å››åˆ†ä¹‹ä¸€çš„æ—¶é—´æ˜¯ä¸æ­£ç¡®çš„ã€‚è¯¯åˆ†ç±»ç‡å¯ä»¥å‡è®¾å€¼åœ¨ [0,1] èŒƒå›´å†…ï¼Œå€¼è¶Šä½è¡¨ç¤ºæ€§èƒ½è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The leftmost element in each row (filled in black) is the bias term weight.",
            "zh": "æ¯è¡Œä¸­æœ€å·¦è¾¹çš„å…ƒç´ ï¼ˆä»¥é»‘è‰²å¡«å……ï¼‰æ˜¯åç½®é¡¹æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "model parameters, 314",
            "zh": "æ¨¡å‹å‚æ•°ï¼Œ 314"
        }
    },
    {
        "translation": {
            "en": "Calculating this measure for each neuron in a network is known as the blame assignment problem.",
            "zh": "è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„åº¦é‡ç§°ä¸ºå½’å’åˆ†é…é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The node returned by the recursive call to the algorithm may be the root of a subtree or a leaf node.",
            "zh": "å¯¹ç®—æ³•çš„é€’å½’è°ƒç”¨è¿”å›çš„èŠ‚ç‚¹å¯ä»¥æ˜¯å­æ ‘çš„æ ¹ï¼Œä¹Ÿå¯ä»¥æ˜¯å¶èŠ‚ç‚¹çš„æ ¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. In an interesting example of the persistence of good solutions using older technology, the data captured by the telescopes at the SDSS site in New Mexico is recorded onto magnetic tapes that are then couriered to the Feynman Computing Center at Fermilab in Illinois, over 1,000 miles away. This is the most effective way to transport the massive volumes of data involved!",
            "zh": "4. åœ¨ä¸€ä¸ªæœ‰è¶£çš„ä¾‹å­ä¸­ï¼Œä½¿ç”¨æ—§æŠ€æœ¯åšæŒä½¿ç”¨è‰¯å¥½çš„è§£å†³æ–¹æ¡ˆï¼Œæ–°å¢¨è¥¿å“¥å· SDSS ç«™ç‚¹çš„æœ›è¿œé•œæ•è·çš„æ•°æ®è¢«è®°å½•åœ¨ç£å¸¦ä¸Šï¼Œç„¶åå¿«é€’åˆ° 1,000 å¤šè‹±é‡Œå¤–çš„ä¼Šåˆ©è¯ºä¼Šå·è´¹ç±³å®éªŒå®¤çš„è´¹æ›¼è®¡ç®—ä¸­å¿ƒã€‚è¿™æ˜¯ä¼ è¾“æ‰€æ¶‰åŠçš„å¤§é‡æ•°æ®çš„æœ€æœ‰æ•ˆæ–¹æ³•ï¼"
        }
    },
    {
        "translation": {
            "en": "learning rate decay, 334",
            "zh": "å­¦ä¹ ç‡è¡°å‡ï¼Œ334"
        }
    },
    {
        "translation": {
            "en": "Figure 10.2[599] illustrates this.",
            "zh": "å›¾10.2[599]è¯´æ˜äº†è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.6â€…â€…â€…Further Reading",
            "zh": "10.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "The approach of avoiding overfitting by modifying the learning algorithm in order to generate models that are stable with respect to changes in the input is generally known as regularization.",
            "zh": "é€šè¿‡ä¿®æ”¹å­¦ä¹ ç®—æ³•æ¥é¿å…è¿‡æ‹Ÿåˆï¼Œä»¥ç”Ÿæˆç›¸å¯¹äºè¾“å…¥å˜åŒ–ç¨³å®šçš„æ¨¡å‹çš„æ–¹æ³•é€šå¸¸ç§°ä¸ºæ­£åˆ™åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Draw a domain concept diagram for the ABT.",
            "zh": "ï¼ˆcï¼‰ ç»˜åˆ¶ABTçš„é¢†åŸŸæ¦‚å¿µå›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mode is more frequently useful for categorical features than for continuous ones, but it can be useful for continuous features when the sample is large enough.",
            "zh": "æ¨¡å¼é€šå¸¸ç”¨äºåˆ†ç±»ç‰¹å¾è€Œä¸æ˜¯è¿ç»­ç‰¹å¾ï¼Œä½†å½“æ ·æœ¬è¶³å¤Ÿå¤§æ—¶ï¼Œå®ƒå¯¹è¿ç»­ç‰¹å¾å¯èƒ½å¾ˆæœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data quality report should also include a histogram for each continuous feature in an ABT. For continuous features with cardinality less than 10, we use bar plots instead of histograms as this usually produces more informative data visualization. For each categorical feature in an ABT, a bar plot should be included in the data quality report.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šè¿˜åº”åŒ…æ‹¬ ABT ä¸­æ¯ä¸ªè¿ç»­ç‰¹å¾çš„ç›´æ–¹å›¾ã€‚å¯¹äºåŸºæ•°å°äº 10 çš„è¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¡å½¢å›¾è€Œä¸æ˜¯ç›´æ–¹å›¾ï¼Œå› ä¸ºè¿™é€šå¸¸ä¼šäº§ç”Ÿä¿¡æ¯é‡æ›´å¤§çš„æ•°æ®å¯è§†åŒ–ã€‚å¯¹äº ABT ä¸­çš„æ¯ä¸ªåˆ†ç±»ç‰¹å¾ï¼Œæ•°æ®è´¨é‡æŠ¥å‘Šä¸­åº”åŒ…å«æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.4â€ƒExtensions and Variations",
            "zh": "4.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "For example, we could represent state using a vector storing the position of the spaceship (in x and y coordinates), the velocity of the spaceship (again in x and y directions), the angular velocity of the spaceship, the spaceshipâ€™s altitude above the surface, and the slope of the line connecting the spaceship to the landing pad.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå‘é‡æ¥è¡¨ç¤ºçŠ¶æ€ï¼Œè¯¥å‘é‡å­˜å‚¨äº†å®‡å®™é£èˆ¹çš„ä½ç½®ï¼ˆåœ¨ x å’Œ y åæ ‡ä¸­ï¼‰ã€å®‡å®™é£èˆ¹çš„é€Ÿåº¦ï¼ˆåŒæ ·åœ¨ x å’Œ y æ–¹å‘ä¸Šï¼‰ã€å®‡å®™é£èˆ¹çš„è§’é€Ÿåº¦ã€å®‡å®™é£èˆ¹åœ¨è¡¨é¢ä¸Šçš„é«˜åº¦ä»¥åŠè¿æ¥å®‡å®™é£èˆ¹å’Œç€é™†å°çš„çº¿çš„æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. The following image shows an artificial neuron that takes three inputs",
            "zh": "1. ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªæ¥å—ä¸‰ä¸ªè¾“å…¥çš„äººå·¥ç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "The figure below illustrates a layer of a convolutional neural network that is processing a one-dimensional input.",
            "zh": "ä¸‹å›¾æ˜¾ç¤ºäº†å¤„ç†ä¸€ç»´è¾“å…¥çš„å·ç§¯ç¥ç»ç½‘ç»œå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The next chapter will describe the data understanding and data preparation techniques mentioned briefly in this chapter in much more detail.",
            "zh": "ä¸‹ä¸€ç« å°†æ›´è¯¦ç»†åœ°ä»‹ç»æœ¬ç« ä¸­ç®€è¦æåˆ°çš„æ•°æ®ç†è§£å’Œæ•°æ®å‡†å¤‡æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, the loss of the model reduces as the modelâ€™s predictions improve.",
            "zh": "æ¢å¥è¯è¯´ï¼Œéšç€æ¨¡å‹é¢„æµ‹çš„æ”¹è¿›ï¼Œæ¨¡å‹çš„æŸå¤±ä¼šå‡å°‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The entropy of different sets of playing cards measured in bits.",
            "zh": "ä»¥æ¯”ç‰¹ä¸ºå•ä½æµ‹é‡çš„ä¸åŒæ‰‘å…‹ç‰Œç»„çš„ç†µã€‚"
        }
    },
    {
        "translation": {
            "en": "Matching animals you remember to the features of the unknown animal described by the sailor.",
            "zh": "å°†æ‚¨è®°å¿†ä¸­çš„åŠ¨ç‰©ä¸æ°´æ‰‹æè¿°çš„æœªçŸ¥åŠ¨ç‰©çš„ç‰¹å¾ç›¸åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.13â€…â€…â€…A sample test set with prediction scores and resulting predictions based on different threshold values.",
            "zh": "9.13 å…·æœ‰é¢„æµ‹åˆ†æ•°å’ŒåŸºäºä¸åŒé˜ˆå€¼çš„é¢„æµ‹ç»“æœçš„æ ·æœ¬æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning we often describe an agent at time t taking an action, at, to move from its current state, st, to the next state, st+1.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸æè¿°ä¸€ä¸ªæ™ºèƒ½ä½“åœ¨æ—¶é—´té‡‡å–ä¸€ä¸ªåŠ¨ä½œï¼Œä»å…¶å½“å‰çŠ¶æ€stç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€st+1ã€‚"
        }
    },
    {
        "translation": {
            "en": "We compute the cosine similarity between two instances as the normalized dot product of the descriptive feature values of the instances. The dot product is normalized by the product of the lengths of the descriptive feature value vectors.19 The dot product of two instances, a and b, defined by m descriptive features is",
            "zh": "æˆ‘ä»¬å°†ä¸¤ä¸ªå®ä¾‹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ä¸ºå®ä¾‹æè¿°æ€§ç‰¹å¾å€¼çš„å½’ä¸€åŒ–ç‚¹ç§¯ã€‚ç‚¹ç§¯ç”±æè¿°æ€§ç‰¹å¾å€¼å‘é‡çš„é•¿åº¦ä¹˜ç§¯å½’ä¸€åŒ–ã€‚19 ç”± m ä¸ªæè¿°æ€§ç‰¹å¾å®šä¹‰çš„ä¸¤ä¸ªå®ä¾‹ a å’Œ b çš„ç‚¹ç§¯ä¸º"
        }
    },
    {
        "translation": {
            "en": "epoch, 416, 418",
            "zh": "çºªå…ƒï¼Œ 416ï¼Œ 418"
        }
    },
    {
        "translation": {
            "en": "J48 is an open-source implementation of the C4.5 algorithm that is used in many data analytics toolkits.",
            "zh": "J48 æ˜¯ C4.5 ç®—æ³•çš„å¼€æºå®ç°ï¼Œç”¨äºè®¸å¤šæ•°æ®åˆ†æå·¥å…·åŒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed for the hospital group, outline the type of data that would be required.",
            "zh": "ï¼ˆbï¼‰ å¯¹äºæ‚¨ä¸ºåŒ»é™¢é›†å›¢æå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°æ‰€éœ€çš„æ•°æ®ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is often very time consuming and expensive to generate.",
            "zh": "è¿™é€šå¸¸éå¸¸è€—æ—¶ä¸”ç”Ÿæˆæˆæœ¬é«˜æ˜‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This occurs twice in an LSTM: (1) the cell state ct vector flows forward into the next time-step and is also passed through a tanh layer as part of the output layer; and (2) the vector of output activations ot flows forward to both the output layer and the next time-step (as the propagated hidden state ht).",
            "zh": "è¿™åœ¨ LSTM ä¸­å‘ç”Ÿä¸¤æ¬¡ï¼šï¼ˆ1ï¼‰ ç»†èƒçŠ¶æ€ ct å‘é‡å‘å‰æµå…¥ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼Œå¹¶ä¸”ä½œä¸ºè¾“å‡ºå±‚çš„ä¸€éƒ¨åˆ†ä¹Ÿé€šè¿‡ tanh å±‚;ï¼ˆ2ï¼‰è¾“å‡ºæ¿€æ´»çš„å‘é‡OTå‘å‰æµå‘è¾“å‡ºå±‚å’Œä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼ˆä½œä¸ºä¼ æ’­çš„éšè—çŠ¶æ€HTï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This led to a large positive reward of 50.",
            "zh": "è¿™å¯¼è‡´äº† 50 çš„å¤§å¹…æ­£å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "If all the inputs to the network have been standardized to have a mean value of 0 and a standard deviation of 1, and the initial weights for the network are sampled from a normal distribution with mean 0.0 and standard deviation of Ïƒ = 0.01, then:",
            "zh": "å¦‚æœç½‘ç»œçš„æ‰€æœ‰è¾“å…¥éƒ½å·²æ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ï¼Œå¹¶ä¸”ç½‘ç»œçš„åˆå§‹æƒé‡æ˜¯ä»å‡å€¼ä¸º 0.0ã€æ ‡å‡†å·®ä¸º Ïƒ = 0.01 çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œåˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "This could be used to identify customers who currently did not look valuable but that were likely to be valuable customers later in their customer lifecycles (college students often fall into this category).",
            "zh": "è¿™å¯ç”¨äºè¯†åˆ«å½“å‰çœ‹èµ·æ¥ä¸æœ‰ä»·å€¼çš„å®¢æˆ·ï¼Œä½†åœ¨å…¶å®¢æˆ·ç”Ÿå‘½å‘¨æœŸçš„åæœŸå¯èƒ½æˆä¸ºæœ‰ä»·å€¼çš„å®¢æˆ·ï¼ˆå¤§å­¦ç”Ÿé€šå¸¸å±äºè¿™ä¸€ç±»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. Whh containing the weights for the connections between the memory buffer and the hidden layer. This matrix has the subscript hh because in actuality these weights are applied to recurrent connections from the hidden layer back to the hidden layer.",
            "zh": "3. åŒ…å«å†…å­˜ç¼“å†²åŒºå’Œéšè—å±‚ä¹‹é—´è¿æ¥çš„æƒé‡ã€‚è¯¥çŸ©é˜µå…·æœ‰ä¸‹æ ‡ hhï¼Œå› ä¸ºå®é™…ä¸Šè¿™äº›æƒé‡åº”ç”¨äºä»éšè—å±‚åˆ°éšè—å±‚çš„å¾ªç¯è¿æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. the rate of change of the error of the network with respect to changes in the activation of the neuron: âˆ‚â„°/âˆ‚ak; and",
            "zh": "1.ç½‘ç»œè¯¯å·®ç›¸å¯¹äºç¥ç»å…ƒæ¿€æ´»å˜åŒ–çš„å˜åŒ–ç‡ï¼šâˆ‚E/âˆ‚ak;å’Œ"
        }
    },
    {
        "translation": {
            "en": "This is a mistake, however, when the descriptive features themselves have varying scales.",
            "zh": "ç„¶è€Œï¼Œå½“æè¿°æ€§ç‰¹å¾æœ¬èº«å…·æœ‰ä¸åŒçš„å°ºåº¦æ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªé”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "A consistent finding in both of these experiments, however, was the fact that for some domains, these more powerful models performed quite poorly, and other models, that in other domains were quite weak, achieved the best results.",
            "zh": "ç„¶è€Œï¼Œåœ¨è¿™ä¸¤ä¸ªå®éªŒä¸­ï¼Œä¸€ä¸ªä¸€è‡´çš„å‘ç°æ˜¯ï¼Œå¯¹äºæŸäº›é¢†åŸŸï¼Œè¿™äº›æ›´å¼ºå¤§çš„æ¨¡å‹è¡¨ç°å¾—ç›¸å½“ç³Ÿç³•ï¼Œè€Œå…¶ä»–é¢†åŸŸç›¸å½“å¼±çš„æ¨¡å‹åˆ™å–å¾—äº†æœ€å¥½çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "Two clustering techniques were presented in detail: k-means clustering and agglomerative hierarchical clustering (AHC).",
            "zh": "è¯¦ç»†ä»‹ç»äº†ä¸¤ç§èšç±»æŠ€æœ¯ï¼šk-meansèšç±»å’Œèšé›†åˆ†å±‚èšç±»ï¼ˆAHCï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2.2â€…â€…â€…Bayesian Prediction",
            "zh": "6.2.2 è´å¶æ–¯é¢„æµ‹"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for edge-on disk galaxy category",
            "zh": "è¾¹ç¼˜ç£ç›˜æ˜Ÿç³»ç±»åˆ«çš„å¾—ç¥¨åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "Index",
            "zh": "æŒ‡æ•°"
        }
    },
    {
        "translation": {
            "en": "action-value behavior network, 672",
            "zh": "è¡ŒåŠ¨-ä»·å€¼è¡Œä¸ºç½‘ç»œï¼Œ672"
        }
    },
    {
        "translation": {
            "en": "convolutional auto-encoders, 630",
            "zh": "å·ç§¯è‡ªåŠ¨ç¼–ç å™¨ï¼Œ630"
        }
    },
    {
        "translation": {
            "en": "Figure 3.13",
            "zh": "å›¾ 3.13"
        }
    },
    {
        "translation": {
            "en": "In order to handle categorical target features with more than two levels, that is multinomial prediction problems, we need to use a one-versus-all approach in which multiple models are trained.",
            "zh": "ä¸ºäº†å¤„ç†å…·æœ‰ä¸¤ä¸ªä»¥ä¸Šçº§åˆ«çš„åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼Œå³å¤šé¡¹å¼é¢„æµ‹é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ç§è®­ç»ƒå¤šä¸ªæ¨¡å‹çš„ä¸€å¯¹ä¸€æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.3.3â€ƒBackpropagation: Updating the Weights in a Network",
            "zh": "8.3.3 åå‘ä¼ æ’­ï¼šæ›´æ–°ç½‘ç»œä¸­çš„æƒé‡"
        }
    },
    {
        "translation": {
            "en": "For example, for a robot deployed within a hospital to deliver equipment to operating theaters, the state might include the robotâ€™s position in the environment, the positions of people nearby, whether the robot is on the way to collect items or to deliver them, and the current levels of the robotâ€™s batteries.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºéƒ¨ç½²åœ¨åŒ»é™¢å†…ä»¥å°†è®¾å¤‡è¿é€åˆ°æ‰‹æœ¯å®¤çš„æœºå™¨äººï¼ŒçŠ¶æ€å¯èƒ½åŒ…æ‹¬æœºå™¨äººåœ¨ç¯å¢ƒä¸­çš„ä½ç½®ã€é™„è¿‘äººå‘˜çš„ä½ç½®ã€æœºå™¨äººæ˜¯åœ¨æ”¶é›†ç‰©å“è¿˜æ˜¯è¿é€ç‰©å“çš„é€”ä¸­ï¼Œä»¥åŠæœºå™¨äººç”µæ± çš„å½“å‰æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "33. Specifically, the calculation of the term âˆ‚â„°/âˆ‚ak (see Equation 8.22[412]).",
            "zh": "33. å…·ä½“è€Œè¨€ï¼Œæœ¯è¯­âˆ‚E/âˆ‚akçš„è®¡ç®—ï¼ˆè§å…¬å¼8.22[412]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "There was no fraud involved in the work at the Nancy lab.",
            "zh": "å—å¸Œå®éªŒå®¤çš„å·¥ä½œæ²¡æœ‰æ¶‰åŠæ¬ºè¯ˆè¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "This is particularly important in this case because FRAUD FLAG is the target feature, and as we will see in upcoming chapters, the type of the target feature has a big impact on how we apply machine learning techniques.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™ä¸€ç‚¹å°¤ä¸ºé‡è¦ï¼Œå› ä¸º FRAUD FLAG æ˜¯ç›®æ ‡ç‰¹å¾ï¼Œæ­£å¦‚æˆ‘ä»¬å°†åœ¨åé¢çš„ç« èŠ‚ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œç›®æ ‡ç‰¹å¾çš„ç±»å‹å¯¹æˆ‘ä»¬å¦‚ä½•åº”ç”¨æœºå™¨å­¦ä¹ æŠ€æœ¯æœ‰å¾ˆå¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. the hxt vector is passed through a layer of sigmoid units to generate a vector mask that in this instance will control which of the activations within the candidate output vector will actually be propagated to the output layer; and",
            "zh": "2. HXT å‘é‡é€šè¿‡ S å½¢ç»“æ™¶å•å…ƒå±‚ä»¥ç”Ÿæˆå‘é‡æ©ç ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ©ç å°†æ§åˆ¶å€™é€‰è¾“å‡ºå‘é‡ä¸­çš„å“ªäº›æ¿€æ´»å°†å®é™…ä¼ æ’­åˆ°è¾“å‡ºå±‚;å’Œ"
        }
    },
    {
        "translation": {
            "en": "Following the rules of standard matrix multiplication, the result of multiplying a 1 Ã— 3 matrix by a 3 Ã— 1 matrix is a 1 Ã— 1 matrix (a matrix with a single value, i.e., a scalar).",
            "zh": "æŒ‰ç…§æ ‡å‡†çŸ©é˜µä¹˜æ³•çš„è§„åˆ™ï¼Œå°† 1 Ã— 3 çŸ©é˜µä¹˜ä»¥ 3 Ã— 1 çŸ©é˜µçš„ç»“æœæ˜¯ 1 Ã— 1 çŸ©é˜µï¼ˆå…·æœ‰å•ä¸ªå€¼çš„çŸ©é˜µï¼Œå³æ ‡é‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the first target feature, just three levels were used: elliptical (P_EL majority), spiral (P_CW, P_ACW, or P_EDGE majority), and other (P_MG or P_DK majority).",
            "zh": "åœ¨ç¬¬ä¸€ä¸ªç›®æ ‡ç‰¹å¾ä¸­ï¼Œä»…ä½¿ç”¨äº†ä¸‰ä¸ªçº§åˆ«ï¼šæ¤­åœ†ï¼ˆP_ELå¤šæ•°ï¼‰ã€èºæ—‹ï¼ˆP_CWã€P_ACWæˆ–P_EDGEå¤šæ•°ï¼‰å’Œå…¶ä»–ï¼ˆP_MGæˆ–P_DKå¤šæ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "18. This example and dataset is based on the Combined Cycle Power Plant dataset available from the UCI repository at https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant and originally collected for the work reported in TÃ¼fekci (2014)",
            "zh": "18. æœ¬ç¤ºä¾‹å’Œæ•°æ®é›†åŸºäº https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant UCI å­˜å‚¨åº“ä¸­æä¾›çš„è”åˆå¾ªç¯ç”µå‚æ•°æ®é›†ï¼Œæœ€åˆæ˜¯ä¸º TÃ¼fekci ï¼ˆ2014ï¼‰ æŠ¥å‘Šçš„å·¥ä½œæ”¶é›†çš„"
        }
    },
    {
        "translation": {
            "en": "Any values beyond the 1st quartile value plus 2.5 times the inter-quartile range were reduced to this value.",
            "zh": "ä»»ä½•è¶…è¿‡ç¬¬ä¸€ä¸ªå››åˆ†ä½æ•°å€¼åŠ ä¸Šå››åˆ†ä½æ•°é—´èŒƒå›´ 2.5 å€çš„å€¼éƒ½å‡å°‘åˆ°æ­¤å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 2.2[46] illustrates the structure of the final ABT that was designed for the motor insurance claims fraud detection solution.8 The table contains more descriptive features than the ones we have discussed in this section.9 The table also shows the first four instances.",
            "zh": "è¡¨ 2.2[46] è¯´æ˜äº†ä¸ºæ±½è½¦ä¿é™©ç´¢èµ”æ¬ºè¯ˆæ£€æµ‹è§£å†³æ–¹æ¡ˆè®¾è®¡çš„æœ€ç»ˆ ABT çš„ç»“æ„ã€‚8 è¯¥è¡¨åŒ…å«çš„æè¿°æ€§ç‰¹å¾æ¯”æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­è®¨è®ºçš„ç‰¹å¾æ›´å¤šã€‚9 è¯¥è¡¨è¿˜æ˜¾ç¤ºäº†å‰å››ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4â€…â€…â€…The division of data during the k-fold cross validation process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "9.4 kæŠ˜äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•æ•°æ®ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The for loop on lines 16[420] to 18[420] contains the calculations of the Î´s for neurons in the output layer, and the for loop on lines 19[420] to 23[420] is the calculation of the Î´s for neurons in the hidden layers.",
            "zh": "ç¬¬ 16[420] è¡Œè‡³ 18[420] ä¸Šçš„ for å¾ªç¯åŒ…å«è¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„ Î´s è®¡ç®—ï¼Œç¬¬ 19[420] è¡Œè‡³ 23[420] ä¸Šçš„ for å¾ªç¯æ˜¯éšè—å±‚ä¸­ç¥ç»å…ƒçš„ Î´ è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.6â€ƒFurther Reading",
            "zh": "11.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "linear relationship, 312, 351, 368",
            "zh": "çº¿æ€§å…³ç³»ï¼Œ 312ï¼Œ 351ï¼Œ 368"
        }
    },
    {
        "translation": {
            "en": "A large hospital group has collected a cancer screening dataset for possible use with machine learning that contains features extracted from tissue samples extracted by biopsy from adults presenting for screening.",
            "zh": "ä¸€å®¶å¤§å‹åŒ»é™¢é›†å›¢æ”¶é›†äº†ä¸€ä¸ªç™Œç—‡ç­›æŸ¥æ•°æ®é›†ï¼Œå¯èƒ½ç”¨äºæœºå™¨å­¦ä¹ ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä»å‰æ¥æ¥å—ç­›æŸ¥çš„æˆå¹´äººé€šè¿‡æ´»æ£€æå–çš„ç»„ç»‡æ ·æœ¬ä¸­æå–çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.6â€…â€…â€…Representation Learning with Auto-Encoders",
            "zh": "10.4.6 ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨è¿›è¡Œè¡¨ç¤ºå­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Another benefit of the reduced representation of the model is that the behavior of the model is relatively easy to interpret.",
            "zh": "æ¨¡å‹ç®€åŒ–è¡¨ç¤ºçš„å¦ä¸€ä¸ªå¥½å¤„æ˜¯æ¨¡å‹çš„è¡Œä¸ºç›¸å¯¹å®¹æ˜“è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Still, throughout her training Sarah would occasionally still step into the water and experience the disappointing feeling of soggy feet, which reminded her to be more careful about her decisions next time.",
            "zh": "å°½ç®¡å¦‚æ­¤ï¼Œåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œèæ‹‰å¶å°”è¿˜æ˜¯ä¼šè¸å…¥æ°´ä¸­ï¼Œä½“éªŒåˆ°è„šæ¹¿é€çš„ä»¤äººå¤±æœ›çš„æ„Ÿè§‰ï¼Œè¿™æé†’å¥¹ä¸‹æ¬¡è¦æ›´åŠ å°å¿ƒè‡ªå·±çš„å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(c) The evolution of the entries in the action-value table over episodes of Q-learning off-policy temporal-difference learning across the grid world. (d) The cumulative reward earned from each episode. (e) An illustration of the target policy learned by the agent after 350 episodes. The arrows show the direction with the highest entry in the action-value table for each state. (f) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ è¡ŒåŠ¨-ä»·å€¼è¡¨ä¸­æ¡ç›®åœ¨æ•´ä¸ªç½‘æ ¼ä¸–ç•Œçš„ Q å­¦ä¹ ã€æ”¿ç­–å¤–æ—¶é—´å·®å¼‚å­¦ä¹ äº‹ä»¶ä¸­çš„æ¼”å˜ã€‚ï¼ˆdï¼‰ æ¯é›†çš„ç´¯ç§¯å¥–åŠ±ã€‚ï¼ˆeï¼‰ ä»£ç†äººåœ¨350é›†åäº†è§£åˆ°çš„ç›®æ ‡æ”¿ç­–çš„è¯´æ˜ã€‚ç®­å¤´æ˜¾ç¤ºæ¯ä¸ªçŠ¶æ€çš„åŠ¨ä½œå€¼è¡¨ä¸­æ¡ç›®æœ€å¤šçš„æ–¹å‘ã€‚ï¼ˆfï¼‰ å½“è´ªå©ªåœ°éµå¾ªç›®æ ‡ç­–ç•¥æ—¶ï¼Œä»£ç†ä»å¼€å§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both techniques focus on transforming an individual feature in some way.",
            "zh": "è¿™ä¸¤ç§æŠ€æœ¯éƒ½ä¾§é‡äºä»¥æŸç§æ–¹å¼è½¬æ¢å•ä¸ªç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Although this case study is based on real data downloaded from the SDSS, the case study itself is entirely fictitious and developed only for the purposes of this book. Very similar work to that described in this section has, however, actually been undertaken, and details of representative examples are given in Section 13.6[727].",
            "zh": "2. è™½ç„¶æœ¬æ¡ˆä¾‹ç ”ç©¶åŸºäºä» SDSS ä¸‹è½½çš„çœŸå®æ•°æ®ï¼Œä½†æ¡ˆä¾‹ç ”ç©¶æœ¬èº«å®Œå…¨æ˜¯è™šæ„çš„ï¼Œä»…ä¸ºæœ¬ä¹¦çš„ç›®çš„è€Œå¼€å‘ã€‚ç„¶è€Œï¼Œå®é™…ä¸Šå·²ç»è¿›è¡Œäº†ä¸æœ¬èŠ‚æ‰€è¿°éå¸¸ç›¸ä¼¼çš„å·¥ä½œï¼Œç¬¬13.6èŠ‚[727]ç»™å‡ºäº†ä»£è¡¨æ€§ç¤ºä¾‹çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.8â€…â€…â€…Further Reading",
            "zh": "3.8 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "Mean absolute errors are in the same units as the predictions themselves, so we can say that, based on mean absolute error, we can expect the regression model to make errors of approximately 0.9575mg in each of its predictions and the nearest neighbor model to be out by approximately 4.020mg.",
            "zh": "å¹³å‡ç»å¯¹è¯¯å·®ä¸é¢„æµ‹æœ¬èº«çš„å•ä½ç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è¯´ï¼ŒåŸºäºå¹³å‡ç»å¯¹è¯¯å·®ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸå›å½’æ¨¡å‹åœ¨å…¶æ¯ä¸ªé¢„æµ‹ä¸­äº§ç”Ÿå¤§çº¦ 0.9575mg çš„è¯¯å·®ï¼Œè€Œæœ€è¿‘é‚»æ¨¡å‹çš„è¯¯å·®çº¦ä¸º 4.020mgã€‚"
        }
    },
    {
        "translation": {
            "en": "FIBER2FLUX_U/G/R/I/Z",
            "zh": "FIBER2FLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Japkowicz and Shah (2011) also discusses the issue of performing statistical significance tests to compare the performance of multiple models.",
            "zh": "Japkowiczå’ŒShahï¼ˆ2011ï¼‰è¿˜è®¨è®ºäº†æ‰§è¡Œç»Ÿè®¡æ˜¾ç€æ€§æ£€éªŒä»¥æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½çš„é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to make a prediction, a model must compute the probability for a target event in the context where some other events are known (the evidence) and where there are potentially one or more hidden features.",
            "zh": "ä¸ºäº†è¿›è¡Œé¢„æµ‹ï¼Œæ¨¡å‹å¿…é¡»åœ¨å·²çŸ¥å…¶ä»–ä¸€äº›äº‹ä»¶ï¼ˆè¯æ®ï¼‰ä¸”å¯èƒ½å­˜åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªéšè—ç‰¹å¾çš„ä¸Šä¸‹æ–‡ä¸­è®¡ç®—ç›®æ ‡äº‹ä»¶çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a hold-out test set avoids the issue of peeking, which arises when the performance of a model is evaluated on the same data used to train it; because the data was used in the training process, the model has already seen this data, so it is probable that it will perform very well when evaluated on this data.",
            "zh": "ä½¿ç”¨ä¿æŒæµ‹è¯•é›†å¯ä»¥é¿å…çª¥è§†é—®é¢˜ï¼Œå½“ä½¿ç”¨ç”¨äºè®­ç»ƒæ¨¡å‹çš„ç›¸åŒæ•°æ®è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½æ—¶ï¼Œä¼šå‡ºç°çª¥è§†é—®é¢˜;ç”±äºæ•°æ®æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„ï¼Œå› æ­¤æ¨¡å‹å·²ç»çœ‹åˆ°äº†è¿™äº›æ•°æ®ï¼Œå› æ­¤åœ¨è¯„ä¼°è¿™äº›æ•°æ®æ—¶ï¼Œå®ƒå¯èƒ½ä¼šè¡¨ç°å¾—éå¸¸å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The stability index is just one measure of the difference between two different distributions, and there are many other options that can be used.",
            "zh": "ç¨³å®šæ€§æŒ‡æ•°åªæ˜¯è¡¡é‡ä¸¤ç§ä¸åŒåˆ†å¸ƒä¹‹é—´å·®å¼‚çš„ä¸€ç§æŒ‡æ ‡ï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–é€‰é¡¹å¯ä»¥ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Rather than a 50:50 split of churners to non-churners, the actual underlying ratio is, in fact, closer to 10:90.",
            "zh": "äº‹å®ä¸Šï¼Œå®é™…çš„åŸºæœ¬æ¯”ä¾‹æ›´æ¥è¿‘ 10ï¼š90ï¼Œè€Œä¸æ˜¯æµå¤±è€…ä¸éæµå¤±è€…çš„ 50ï¼š50 æ¯”ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "1,315",
            "zh": "1,315"
        }
    },
    {
        "translation": {
            "en": "Figure 8.20[443] illustrates how the sum of squared errors of the ReLU network changes during the training of the network.",
            "zh": "å›¾ 8.20[443] è¯´æ˜äº† ReLU ç½‘ç»œçš„å¹³æ–¹è¯¯å·®å’Œåœ¨ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•å˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "positively covariant, 74",
            "zh": "æ­£åå˜ï¼Œ74"
        }
    },
    {
        "translation": {
            "en": "One type of artificial neural network can be built by connecting layers of logistic regression models, but there are many other network topologies used in practice.",
            "zh": "ä¸€ç§ç±»å‹çš„äººå·¥ç¥ç»ç½‘ç»œå¯ä»¥é€šè¿‡è¿æ¥é€»è¾‘å›å½’æ¨¡å‹çš„å±‚æ¥æ„å»ºï¼Œä½†åœ¨å®è·µä¸­è¿˜ä½¿ç”¨äº†è®¸å¤šå…¶ä»–ç½‘ç»œæ‹“æ‰‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Introduction to Linear Algebra",
            "zh": "çº¿æ€§ä»£æ•°å¯¼è®º"
        }
    },
    {
        "translation": {
            "en": "(b) Reviewing the spread of marks for the other two modules, the lecturer notices that there is a larger variance across students in the marks for Module 2 than there is for Module 1. So, the lecturer decides to update the k-nearest neighbor model to use the Mahalanobis distance instead of Euclidean distance as its similarity measure. Assuming that the inverse covariance matrix for the Module 1 and Module 2 results is",
            "zh": "ï¼ˆbï¼‰ åœ¨å®¡æŸ¥å…¶ä»–ä¸¤ä¸ªå•å…ƒçš„åˆ†æ•°åˆ†å¸ƒæ—¶ï¼Œè®²å¸ˆæ³¨æ„åˆ°ï¼Œå­¦ç”Ÿåœ¨å•å…ƒ2çš„åˆ†æ•°å·®å¼‚å¤§äºæ¨¡å—1çš„å·®å¼‚ã€‚å› æ­¤ï¼Œè®²å¸ˆå†³å®šæ›´æ–° k æœ€è¿‘é‚»æ¨¡å‹ï¼Œä»¥ä½¿ç”¨é©¬æ°è·ç¦»è€Œä¸æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»ä½œä¸ºå…¶ç›¸ä¼¼åº¦åº¦é‡ã€‚å‡è®¾æ¨¡å— 1 å’Œæ¨¡å— 2 ç»“æœçš„é€†åæ–¹å·®çŸ©é˜µä¸º"
        }
    },
    {
        "translation": {
            "en": "For example, for categorical targets, the Ï‡2 statistic is often used, and for continuous targets, the K-S statistic can also be used.",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºåˆ†ç±»ç›®æ ‡ï¼Œé€šå¸¸ä½¿ç”¨ Ï‡2 ç»Ÿè®¡é‡ï¼Œå¯¹äºè¿ç»­ç›®æ ‡ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ K-S ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the decision boundaries learned by different machine learning algorithms for three artificial datasets.",
            "zh": "ä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•å¯¹ä¸‰ä¸ªäººå·¥æ•°æ®é›†å­¦ä¹ çš„å†³ç­–è¾¹ç•Œçš„å›¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "matrix, 771",
            "zh": "çŸ©é˜µï¼Œ771"
        }
    },
    {
        "translation": {
            "en": "2. You have been hired by the European Space Agency to build a model that predicts the amount of oxygen that an astronaut consumes when performing five minutes of intense physical work. The descriptive features for the model will be the age of the astronaut and their average heart rate throughout the work. The regression model is",
            "zh": "2. æ‚¨å—é›‡äºæ¬§æ´²èˆªå¤©å±€ï¼Œè´Ÿè´£æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥é¢„æµ‹å®‡èˆªå‘˜åœ¨è¿›è¡Œäº”åˆ†é’Ÿçš„é«˜å¼ºåº¦ä½“åŠ›åŠ³åŠ¨æ—¶æ¶ˆè€—çš„æ°§æ°”é‡ã€‚è¯¥æ¨¡å‹çš„æè¿°æ€§ç‰¹å¾å°†æ˜¯å®‡èˆªå‘˜çš„å¹´é¾„å’Œä»–ä»¬åœ¨æ•´ä¸ªå·¥ä½œè¿‡ç¨‹ä¸­çš„å¹³å‡å¿ƒç‡ã€‚å›å½’æ¨¡å‹ä¸º"
        }
    },
    {
        "translation": {
            "en": "r-trees, 233",
            "zh": "R-æ ‘ï¼Œ233"
        }
    },
    {
        "translation": {
            "en": "Even though the separation between the instances with the different levels of the target feature in this case is not particularly well defined, a logistic regression model can be trained to distinguish between the two types of generator.",
            "zh": "å°½ç®¡åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå…·æœ‰ä¸åŒç›®æ ‡ç‰¹å¾çº§åˆ«çš„å®ä¾‹ä¹‹é—´çš„åˆ†ç¦»ä¸æ˜¯ç‰¹åˆ«æ˜ç¡®ï¼Œä½†å¯ä»¥è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹æ¥åŒºåˆ†ä¸¤ç§ç±»å‹çš„ç”Ÿæˆå™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this example, there are only two descriptive features, so the feature space is two-dimensional.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œåªæœ‰ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾ï¼Œå› æ­¤ç‰¹å¾ç©ºé—´æ˜¯äºŒç»´çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason that this simplification is so important is that it allows us to simplify the calculations in Bayesâ€™ Theorem, under the assumption of conditional independence between the descriptive features, given the level l of the target feature, from",
            "zh": "è¿™ç§ç®€åŒ–ä¹‹æ‰€ä»¥å¦‚æ­¤é‡è¦ï¼Œæ˜¯å› ä¸ºå®ƒå…è®¸æˆ‘ä»¬ç®€åŒ–è´å¶æ–¯å®šç†ä¸­çš„è®¡ç®—ï¼Œå‡è®¾æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œç»™å®šç›®æ ‡ç‰¹å¾çš„æ°´å¹³ lï¼Œä»"
        }
    },
    {
        "translation": {
            "en": "1. P(t = l), the prior probability of the target feature t taking the level l",
            "zh": "1. Pï¼ˆt = lï¼‰ï¼Œç›®æ ‡ç‰¹å¾ t å–æ°´å¹³ l çš„å…ˆéªŒæ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "It was important that the model Jocelyn deployed not add a large delay to data becoming available to scientists.",
            "zh": "é‡è¦çš„æ˜¯ï¼ŒJocelyn éƒ¨ç½²çš„æ¨¡å‹ä¸ä¼šç»™ç§‘å­¦å®¶å¯ç”¨çš„æ•°æ®å¢åŠ å¾ˆå¤§çš„å»¶è¿Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "We then describe a number of strategies for handling data quality issues and when it is appropriate to use them.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬æè¿°äº†ä¸€äº›å¤„ç†æ•°æ®è´¨é‡é—®é¢˜çš„ç­–ç•¥ï¼Œä»¥åŠä½•æ—¶é€‚åˆä½¿ç”¨å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "From this we can again conclude that guards are more likely to have a shoe sponsor than players in the other positions.",
            "zh": "ç”±æ­¤æˆ‘ä»¬å¯ä»¥å†æ¬¡å¾—å‡ºç»“è®ºï¼Œåå«æ¯”å…¶ä»–ä½ç½®çš„çƒå‘˜æ›´æœ‰å¯èƒ½æ‹¥æœ‰é‹å­èµåŠ©å•†ã€‚"
        }
    },
    {
        "translation": {
            "en": "We then explain how a neural network can be modified and trained to handle categorical target features, using a softmax output layer and the cross-entropy loss function.",
            "zh": "ç„¶åï¼Œæˆ‘ä»¬è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨softmaxè¾“å‡ºå±‚å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°æ¥ä¿®æ”¹å’Œè®­ç»ƒç¥ç»ç½‘ç»œä»¥å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the end of this process, you decide that the unknown animal is most similar to a duck, so that is what it must be.",
            "zh": "åœ¨è¿™ä¸ªè¿‡ç¨‹çš„æœ€åï¼Œä½ å†³å®šæœªçŸ¥çš„åŠ¨ç‰©ä¸é¸­å­æœ€ç›¸ä¼¼ï¼Œæ‰€ä»¥å®ƒå¿…é¡»å¦‚æ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Name",
            "zh": "åå­—"
        }
    },
    {
        "translation": {
            "en": "1. The table below shows the age of each employee at a cardboard box factory.",
            "zh": "1. ä¸‹è¡¨æ˜¾ç¤ºäº†çº¸æ¿ç®±å‚æ¯ä½å‘˜å·¥çš„å¹´é¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Features explicitly named in the text are denoted by the uppercase initial letters of their names. For example, a feature named MENINGITIS is denoted by M.",
            "zh": "æ–‡æœ¬ä¸­æ˜ç¡®å‘½åçš„è¦ç´ ç”±å…¶åç§°çš„å¤§å†™é¦–å­—æ¯è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼Œåä¸ºè„‘è†œç‚çš„ç‰¹å¾ç”¨ M è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature Names and Feature Values",
            "zh": "åŠŸèƒ½åç§°å’ŒåŠŸèƒ½å€¼"
        }
    },
    {
        "translation": {
            "en": "It is important to note here that we use control groups not to evaluate the predictive power of the models themselves, but rather to evaluate how good they are at helping with the business problem when they are deployed.",
            "zh": "è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨å¯¹ç…§ç»„ä¸æ˜¯ä¸ºäº†è¯„ä¼°æ¨¡å‹æœ¬èº«çš„é¢„æµ‹èƒ½åŠ›ï¼Œè€Œæ˜¯ä¸ºäº†è¯„ä¼°å®ƒä»¬åœ¨éƒ¨ç½²æ—¶åœ¨å¸®åŠ©è§£å†³ä¸šåŠ¡é—®é¢˜æ–¹é¢çš„è¡¨ç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The connections that exist between key objects in the data model. For example, in a banking scenario is it possible to connect the multiple accounts that a single customer might own? Similarly, in an insurance scenario is it possible to connect the information from a policy application with the details (e.g., claims, payments, etc.) of the resulting policy itself?",
            "zh": "æ•°æ®æ¨¡å‹ä¸­çš„å…³é”®å¯¹è±¡ä¹‹é—´å­˜åœ¨çš„è¿æ¥ã€‚ä¾‹å¦‚ï¼Œåœ¨é“¶è¡Œä¸šåŠ¡åœºæ™¯ä¸­ï¼Œæ˜¯å¦å¯ä»¥è¿æ¥å•ä¸ªå®¢æˆ·å¯èƒ½æ‹¥æœ‰çš„å¤šä¸ªå¸æˆ·ï¼ŸåŒæ ·ï¼Œåœ¨ä¿é™©åœºæ™¯ä¸­ï¼Œæ˜¯å¦å¯ä»¥å°†ä¿å•åº”ç”¨ç¨‹åºä¸­çš„ä¿¡æ¯ä¸æœ€ç»ˆä¿å•æœ¬èº«çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œç´¢èµ”ã€ä»˜æ¬¾ç­‰ï¼‰è”ç³»èµ·æ¥ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The basic structure of an analytics base tableâ€”descriptive features and a target feature.",
            "zh": "åˆ†æåŸºè¡¨çš„åŸºæœ¬ç»“æ„ - æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Fully processed data from the SDSS pipeline is available to scientists approximately one week after images of night sky objects are captured by the SDSS telescopes.4 The system that Jocelyn built would be added to the end of this pipeline because it would require outputs from existing data processing steps.",
            "zh": "åœ¨SDSSæœ›è¿œé•œæ•è·å¤œç©ºå¤©ä½“å›¾åƒå¤§çº¦ä¸€å‘¨åï¼Œç§‘å­¦å®¶å¯ä»¥è·å¾—æ¥è‡ªSDSSç®¡é“çš„å®Œå…¨å¤„ç†æ•°æ®.4 Jocelynæ„å»ºçš„ç³»ç»Ÿå°†è¢«æ·»åŠ åˆ°è¯¥ç®¡é“çš„æœ«å°¾ï¼Œå› ä¸ºå®ƒéœ€è¦ç°æœ‰æ•°æ®å¤„ç†æ­¥éª¤çš„è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "These activations are stored in the matrix A(l).",
            "zh": "è¿™äº›æ¿€æ´»å­˜å‚¨åœ¨çŸ©é˜µ Aï¼ˆlï¼‰ ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, to avoid zero probabilities, we require only that for each value in the domain of the target feature, there be at least one instance in the dataset where each event in the evidence holds.",
            "zh": "ç›¸åï¼Œä¸ºäº†é¿å…é›¶æ¦‚ç‡ï¼Œæˆ‘ä»¬åªè¦æ±‚å¯¹äºç›®æ ‡ç‰¹å¾åŸŸä¸­çš„æ¯ä¸ªå€¼ï¼Œæ•°æ®é›†ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå®ä¾‹ï¼Œå…¶ä¸­è¯æ®ä¸­çš„æ¯ä¸ªäº‹ä»¶éƒ½æˆç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature conditioned on FRAUD = false.",
            "zh": "å¹³æ»‘ä»¥ FRAUD = false ä¸ºæ¡ä»¶çš„ GUARANTOR/COAPPLICANT ç‰¹å¾çš„åéªŒæ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "In these models the value for w[0] is kept constant at 6.47, and the values for w[1] are set to 0.4, 0.5, 0.62, 0.7, and 0.8 from top to bottom.",
            "zh": "åœ¨è¿™äº›æ¨¡å‹ä¸­ï¼Œw[0] çš„å€¼ä¿æŒä¸å˜ä¸º 6.47ï¼Œw[1] çš„å€¼ä»ä¸Šåˆ°ä¸‹è®¾ç½®ä¸º 0.4ã€0.5ã€0.62ã€0.7 å’Œ 0.8ã€‚"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, choosing learning rates is not a well-defined science. Although there are some algorithmic approaches, most practitioners use rules of thumb and trial and error. A typical range for learning rates is [0.00001, 10], and practitioners will usually try out higher values and observe the resulting learning graph. If the graph looks too much like Figure 7.7(f)[329], a smaller value will be tested until something approaching Figure 7.7(e)[329] is found.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œé€‰æ‹©å­¦ä¹ ç‡å¹¶ä¸æ˜¯ä¸€é—¨å®šä¹‰æ˜ç¡®çš„ç§‘å­¦ã€‚å°½ç®¡æœ‰ä¸€äº›ç®—æ³•æ–¹æ³•ï¼Œä½†å¤§å¤šæ•°ä»ä¸šè€…ä½¿ç”¨ç»éªŒæ³•åˆ™å’Œè¯•é”™æ³•åˆ™ã€‚å­¦ä¹ ç‡çš„å…¸å‹èŒƒå›´æ˜¯ [0.00001ï¼Œ 10]ï¼Œä»ä¸šè€…é€šå¸¸ä¼šå°è¯•æ›´é«˜çš„å€¼å¹¶è§‚å¯Ÿç”±æ­¤äº§ç”Ÿçš„å­¦ä¹ å›¾ã€‚å¦‚æœå›¾å½¢çœ‹èµ·æ¥å¤ªåƒå›¾7.7ï¼ˆfï¼‰[329]ï¼Œåˆ™å°†æµ‹è¯•è¾ƒå°çš„å€¼ï¼Œç›´åˆ°æ‰¾åˆ°æ¥è¿‘å›¾7.7ï¼ˆeï¼‰[329]çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "When an agent in state st takes action at, the difference between the current estimated return in the action-value table for that action in that state, QÏ€(st,at), and the actual return received after taking the action is calculated.",
            "zh": "å½“å¤„äºçŠ¶æ€ st çš„ä»£ç†åœ¨ t æ—¶æ‰§è¡Œæ“ä½œæ—¶ï¼Œå°†è®¡ç®—è¯¥æ“ä½œåœ¨è¯¥çŠ¶æ€ä¸‹çš„æ“ä½œå€¼è¡¨ä¸­çš„å½“å‰ä¼°è®¡å›æŠ¥ QÏ€ï¼ˆstï¼Œatï¼‰ ä¸æ‰§è¡Œè¯¥æ“ä½œåæ”¶åˆ°çš„å®é™…è¿”å›ä¹‹é—´çš„å·®å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term âˆ‚ak/âˆ‚zk represents the rate of change of the neuronâ€™s activation function with respect to changes in the weighted sum z (i.e., with respect to the input to the activation function). Because this âˆ‚ak/âˆ‚zk term is required in order to calculate the Î´ for a neuron, the backpropagation algorithm assumes that the neurons in the network use differentiable activation functions. The logistic function (see Equation (7.25)[342]) has a very well-known and relatively simple derivative7",
            "zh": "æœ¯è¯­ âˆ‚ak/âˆ‚zk è¡¨ç¤ºç¥ç»å…ƒæ¿€æ´»å‡½æ•°ç›¸å¯¹äºåŠ æƒæ€»å’Œ z å˜åŒ–çš„å˜åŒ–ç‡ï¼ˆå³ç›¸å¯¹äºæ¿€æ´»å‡½æ•°çš„è¾“å…¥ï¼‰ã€‚ç”±äºéœ€è¦æ­¤ âˆ‚ak/âˆ‚zk é¡¹æ¥è®¡ç®—ç¥ç»å…ƒçš„Î´ï¼Œå› æ­¤åå‘ä¼ æ’­ç®—æ³•å‡å®šç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨å¯å¾®æ¿€æ´»å‡½æ•°ã€‚é€»è¾‘å‡½æ•°ï¼ˆå‚è§æ–¹ç¨‹ï¼ˆ7.25ï¼‰[342]ï¼‰æœ‰ä¸€ä¸ªéå¸¸è‘—åä¸”ç›¸å¯¹ç®€å•çš„å¯¼æ•°7"
        }
    },
    {
        "translation": {
            "en": "The total value of the initial two cards dealt to the player can range from 4 (for example, 2 and 2 ) to 22 (for example, A and A ), giving 19 unique values.",
            "zh": "å‘ç»™ç©å®¶çš„æœ€åˆä¸¤å¼ ç‰Œçš„æ€»ä»·å€¼å¯ä»¥ä» 4ï¼ˆä¾‹å¦‚ï¼Œ2 å’Œ 2ï¼‰åˆ° 22ï¼ˆä¾‹å¦‚ï¼ŒA å’Œ Aï¼‰ï¼Œç»™å‡º 19 ä¸ªå”¯ä¸€å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.2.2â€…â€…â€…Measuring Similarity Using Distance Metrics",
            "zh": "5.2.2 ä½¿ç”¨è·ç¦»æŒ‡æ ‡è¡¡é‡ç›¸ä¼¼æ€§"
        }
    },
    {
        "translation": {
            "en": "(b) Agglomerative hierarchical clustering (AHC) can easily be applied to this distance matrix. If single linkage is used with AHC, which agglomerations will be made in the first three iterations of the algorithm?",
            "zh": "ï¼ˆbï¼‰èšé›†åˆ†å±‚èšç±»ï¼ˆAHCï¼‰å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºè¯¥è·ç¦»çŸ©é˜µã€‚å¦‚æœAHCä½¿ç”¨å•è”åŠ¨ï¼Œåˆ™åœ¨ç®—æ³•çš„å‰ä¸‰æ¬¡è¿­ä»£ä¸­å°†è¿›è¡Œå“ªäº›å›¢èšï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This section has presented a basic approach to evaluating prediction models. The most important things to take away from this example are:",
            "zh": "æœ¬èŠ‚ä»‹ç»äº†è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„åŸºæœ¬æ–¹æ³•ã€‚ä»è¿™ä¸ªä¾‹å­ä¸­å¯ä»¥çœ‹å‡ºçš„æœ€é‡è¦çš„äº‹æƒ…æ˜¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "The box labeled h0 represents that state of the activation memory buffer when the model is initialized.",
            "zh": "æ ‡è®°ä¸º h0 çš„æ¡†è¡¨ç¤ºåˆå§‹åŒ–æ¨¡å‹æ—¶æ¿€æ´»å†…å­˜ç¼“å†²åŒºçš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, she used a two-stage model.",
            "zh": "å…¶æ¬¡ï¼Œå¥¹ä½¿ç”¨äº†ä¸¤é˜¶æ®µæ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Wilcoxon-Mann-Whitney statistic, 563",
            "zh": "Wilcoxon-Mann-Whitney ç»Ÿè®¡ï¼Œ563"
        }
    },
    {
        "translation": {
            "en": "The multiple peaks in the density curve arise from the different subpopulations (a distribution with multiple peaks is called multimodal).",
            "zh": "å¯†åº¦æ›²çº¿ä¸­çš„å¤šä¸ªå³°æ¥è‡ªä¸åŒçš„äºšç¾¤ï¼ˆå…·æœ‰å¤šä¸ªå³°çš„åˆ†å¸ƒç§°ä¸ºå¤šå³°åˆ†å¸ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.7â€…â€…â€…Exercises",
            "zh": "10.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "(d) Calculate information gain (based on entropy) for the EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "ï¼ˆdï¼‰ è®¡ç®—æ•™è‚²ã€å©šå§»çŠ¶å†µå’ŒèŒä¸šç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼ˆåŸºäºç†µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Interpretability, however, was not particularly important for the SDSS scenario (the model built would be added to the existing SDSS pipeline and process thousands of galaxy objects per day), so standardization was appropriate.",
            "zh": "ç„¶è€Œï¼Œå¯è§£é‡Šæ€§å¯¹äºSDSSæƒ…æ™¯æ¥è¯´å¹¶ä¸æ˜¯ç‰¹åˆ«é‡è¦ï¼ˆæ‰€å»ºç«‹çš„æ¨¡å‹å°†è¢«æ·»åŠ åˆ°ç°æœ‰çš„SDSSç®¡é“ä¸­ï¼Œæ¯å¤©å¤„ç†æ•°åƒä¸ªæ˜Ÿç³»å¤©ä½“ï¼‰ï¼Œå› æ­¤æ ‡å‡†åŒ–æ˜¯åˆé€‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "22. These parameters are formally known as Lagrange multipliers.",
            "zh": "22. è¿™äº›å‚æ•°çš„æ­£å¼åç§°ä¸ºæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.11â€…â€…â€…A binary dataset listing the behavior of two individuals on a website during a trial period and whether they subsequently signed up for the website.",
            "zh": "5.11 ä¸€ä¸ªäºŒè¿›åˆ¶æ•°æ®é›†ï¼Œåˆ—å‡ºä¸¤ä¸ªäººåœ¨è¯•ç”¨æœŸé—´åœ¨ç½‘ç«™ä¸Šçš„è¡Œä¸ºï¼Œä»¥åŠä»–ä»¬éšåæ˜¯å¦æ³¨å†Œäº†è¯¥ç½‘ç«™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, in order to isolate the effect of weight initialization on training dynamics from the problem of saturated activation functions, the neurons in this network use a linear activation function that outputs the same value that it receives as input: ai = zi.",
            "zh": "æ­¤å¤–ï¼Œä¸ºäº†å°†æƒé‡åˆå§‹åŒ–å¯¹è®­ç»ƒåŠ¨åŠ›å­¦çš„å½±å“ä¸é¥±å’Œæ¿€æ´»å‡½æ•°é—®é¢˜éš”ç¦»å¼€æ¥ï¼Œè¯¥ç½‘ç»œä¸­çš„ç¥ç»å…ƒä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œè¯¥å‡½æ•°è¾“å‡ºä¸è¾“å…¥ç›¸åŒçš„å€¼ï¼šai = ziã€‚"
        }
    },
    {
        "translation": {
            "en": "As discussed in the previous section, it can also be calculated using the Theorem of Total Probability (in this instance, summing over all the target levels âˆ‘kâˆˆlevels(t) P(q[1],â€¦,q[m] | t = k)P(t = k)), or replaced entirely with a normalization constant, Î·.",
            "zh": "å¦‚ä¸Šä¸€èŠ‚æ‰€è¿°ï¼Œå®ƒä¹Ÿå¯ä»¥ä½¿ç”¨æ€»æ¦‚ç‡å®šç†è¿›è¡Œè®¡ç®—ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œå°†æ‰€æœ‰ç›®æ ‡æ°´å¹³ç›¸åŠ âˆ‘kâˆˆæ°´å¹³ï¼ˆtï¼‰ Pï¼ˆq[1],...,q[m] | t = kï¼‰Pï¼ˆt = kï¼‰ï¼‰ï¼Œæˆ–å®Œå…¨æ›¿æ¢ä¸ºå½’ä¸€åŒ–å¸¸æ•° Î·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that decision trees are very sensitive to changes in the dataset: a small change in the dataset can result in a different feature being selected to split the dataset at the root or high in the tree, and this can have a ripple effect throughout the subtrees under this node.",
            "zh": "åŸå› æ˜¯å†³ç­–æ ‘å¯¹æ•°æ®é›†çš„å˜åŒ–éå¸¸æ•æ„Ÿï¼šæ•°æ®é›†ä¸­çš„å¾®å°å˜åŒ–å¯èƒ½ä¼šå¯¼è‡´é€‰æ‹©ä¸åŒçš„ç‰¹å¾æ¥æ‹†åˆ†æ ‘ä¸­æ ¹éƒ¨æˆ–é«˜å¤„çš„æ•°æ®é›†ï¼Œè¿™å¯èƒ½ä¼šå¯¹è¯¥èŠ‚ç‚¹ä¸‹çš„å­æ ‘äº§ç”Ÿè¿é”ååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "The region around the car is divided into cells that can be empty, occupied by another car, or occupied by a barrier.",
            "zh": "æ±½è½¦å‘¨å›´çš„åŒºåŸŸè¢«åˆ’åˆ†ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œè¿™äº›å•å…ƒæ ¼å¯ä»¥æ˜¯ç©ºçš„ï¼Œä¹Ÿå¯ä»¥è¢«å¦ä¸€è¾†è½¦å æ®ï¼Œä¹Ÿå¯ä»¥è¢«éšœç¢ç‰©å æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the most famous examples of sampling bias was in the 1936 U.S. presidential election, which pitted Franklin D. Roosevelt, the incumbent president, against Alfred Landon, the Republican governor of Kansas.",
            "zh": "æŠ½æ ·åå·®æœ€è‘—åçš„ä¾‹å­ä¹‹ä¸€æ˜¯1936å¹´çš„ç¾å›½æ€»ç»Ÿå¤§é€‰ï¼Œç°ä»»æ€»ç»Ÿå¯Œå…°å…‹æ—Â·ç½—æ–¯ç¦ï¼ˆFranklin D. Rooseveltï¼‰ä¸å ªè¨æ–¯å·å…±å’Œå…šå·é•¿é˜¿å°”å¼—é›·å¾·Â·å…°ç™»ï¼ˆAlfred Landonï¼‰å¯¹å†³ã€‚"
        }
    },
    {
        "translation": {
            "en": "stochastic, 415",
            "zh": "éšæœºæŒ¯è¡æŒ‡æ ‡ï¼Œ415"
        }
    },
    {
        "translation": {
            "en": "31.41",
            "zh": "31.41"
        }
    },
    {
        "translation": {
            "en": "This is because the maximum difference between d12 and d17 for any single feature is 7 units (for AGILITY), whereas the maximum difference between d12 and d5 on any single feature is just 5 units (for AGILITY).",
            "zh": "è¿™æ˜¯å› ä¸ºä»»ä½•å•ä¸ªç‰¹å¾çš„ d12 å’Œ d17 ä¹‹é—´çš„æœ€å¤§å·®å¼‚ä¸º 7 ä¸ªå•ä½ï¼ˆå¯¹äºæ•æ·æ€§ï¼‰ï¼Œè€Œä»»ä½•å•ä¸ªç‰¹å¾çš„ d12 å’Œ d5 ä¹‹é—´çš„æœ€å¤§å·®å¼‚ä»…ä¸º 5 ä¸ªå•ä½ï¼ˆå¯¹äºæ•æ·æ€§ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The precision value tells us how likely it is that a genuine ham email could be marked as spam and, presumably, deleted: 25% (1 âˆ’ precision).",
            "zh": "ç²¾åº¦å€¼å‘Šè¯‰æˆ‘ä»¬ï¼ŒçœŸæ­£çš„ä¸šä½™ç”µå­é‚®ä»¶è¢«æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶å¹¶å¯èƒ½è¢«åˆ é™¤çš„å¯èƒ½æ€§æœ‰å¤šå¤§ï¼š25%ï¼ˆ1 - ç²¾åº¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.1â€…â€…â€…The three different arrangements of the magnetic letters made by the Murphy children on the Murphy family refrigerator.",
            "zh": "10.1 å¢¨è²å®¶å†°ç®±ä¸Šå¢¨è²å®¶å†°ç®±ä¸Šç£æ€§å­—æ¯çš„ä¸‰ç§ä¸åŒæ’åˆ—æ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.13",
            "zh": "å›¾ 6.13"
        }
    },
    {
        "translation": {
            "en": "These simplifications aside, the processing and flow of data through Figure 8.36[498] is representative of the flow through a multi-layer, multi-filter convolutional neural network.",
            "zh": "æ’‡å¼€è¿™äº›ç®€åŒ–ä¸è°ˆï¼Œé€šè¿‡å›¾8.36[498]å¤„ç†å’Œæ•°æ®æµä»£è¡¨äº†é€šè¿‡å¤šå±‚ã€å¤šæ»¤æ³¢å™¨å·ç§¯ç¥ç»ç½‘ç»œçš„æµã€‚"
        }
    },
    {
        "translation": {
            "en": "A data quality report for the Acme Telephonica ABT.",
            "zh": "Acme Telephonica ABT çš„æ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent can only stay in the PM-DH state if they have a hand value of 15 and are dealt a 2 or a 3; or if they have a hand value of 16 and are dealt a 2.",
            "zh": "åªæœ‰å½“ä»£ç†çš„æ‰‹å€¼ä¸º 15 å¹¶ä¸”è¢«å‘ç»™ 2 æˆ– 3 æ—¶ï¼Œä»£ç†æ‰èƒ½ä¿æŒåœ¨ PM-DH çŠ¶æ€;æˆ–è€…å¦‚æœä»–ä»¬çš„æ‰‹ç‰Œå€¼ä¸º 16 å¹¶ä¸”è¢«å‘ç»™ 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tracing d2 through the logistic activation function, the activation for Neuron 3 for d2 is a3 = 0.4990.",
            "zh": "é€šè¿‡é€»è¾‘æ¿€æ´»å‡½æ•°è·Ÿè¸ª d2ï¼Œd2 çš„ç¥ç»å…ƒ 3 çš„æ¿€æ´»ä¸º a3 = 0.4990ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVMAG_U/G/R/I/Z",
            "zh": "DEVMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "(long)â€) we suggest covering data preparation (Section 3.6), all the machine learning chapters, and the evaluation chapter.",
            "zh": "ï¼ˆlongï¼‰â€œï¼‰ï¼Œæˆ‘ä»¬å»ºè®®æ¶µç›–æ•°æ®å‡†å¤‡ï¼ˆç¬¬ 3.6 èŠ‚ï¼‰ã€æ‰€æœ‰æœºå™¨å­¦ä¹ ç« èŠ‚å’Œè¯„ä¼°ç« èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This was a decision made based on the data available and Rossâ€™s expectation that anything farther back than this was likely to have little impact on predicting churn.",
            "zh": "è¿™æ˜¯æ ¹æ®ç°æœ‰æ•°æ®åšå‡ºçš„å†³å®šï¼Œä»¥åŠ Ross çš„é¢„æœŸï¼Œå³ä»»ä½•æ¯”è¿™æ›´ä¹…è¿œçš„äº‹æƒ…éƒ½å¯èƒ½å¯¹é¢„æµ‹å®¢æˆ·æµå¤±äº§ç”Ÿå¾ˆå°å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each row and column represent the feature named in the cells along the diagonal.",
            "zh": "æ¯ä¸€è¡Œå’Œæ¯ä¸€åˆ—è¡¨ç¤ºæ²¿å¯¹è§’çº¿çš„å•å…ƒæ ¼ä¸­å‘½åçš„è¦ç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of the information in this report, all continuous features were normalized using range normalization, and any missing values were replaced using mean imputation for continuous features and mode imputation for categorical features. After applying these data preparation operations, a multivariate logistic regression model was trained to give the weights shown in the following table.",
            "zh": "æ ¹æ®æœ¬æŠ¥å‘Šä¸­çš„ä¿¡æ¯ï¼Œä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–å¯¹æ‰€æœ‰è¿ç»­ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶ä½¿ç”¨è¿ç»­ç‰¹å¾çš„å¹³å‡æ’è¡¥å’Œåˆ†ç±»ç‰¹å¾çš„ä¼—æ•°æ’è¡¥æ›¿æ¢ä»»ä½•ç¼ºå¤±å€¼ã€‚åœ¨åº”ç”¨è¿™äº›æ•°æ®å‡†å¤‡æ“ä½œåï¼Œè®­ç»ƒäº†ä¸€ä¸ªå¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹ï¼Œä»¥ç»™å‡ºä¸‹è¡¨ä¸­æ‰€ç¤ºçš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "An important feature of this equation is that the support vectors are a component of the equation.",
            "zh": "è¯¥æ–¹ç¨‹çš„ä¸€ä¸ªé‡è¦ç‰¹å¾æ˜¯æ”¯æŒå‘é‡æ˜¯æ–¹ç¨‹çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "TwentyTwos, 645, 647, 680",
            "zh": "äºŒåäºŒï¼Œ645,647,680"
        }
    },
    {
        "translation": {
            "en": "This is why, as Figure 8.11[406] shows, the activation for each neuron is stored during the forward pass of the algorithm; these activations are used to update the weights on the connections along which they are propagated. We now know how to calculate the sensitivity of the network error with respect to changes in a weight: âˆ‚â„°/âˆ‚wi,k. How do we use this term to update a weight?",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆï¼Œå¦‚å›¾8.11[406]æ‰€ç¤ºï¼Œæ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»éƒ½æ˜¯åœ¨ç®—æ³•çš„å‰å‘ä¼ é€’æœŸé—´å­˜å‚¨çš„;è¿™äº›æ¿€æ´»ç”¨äºæ›´æ–°å®ƒä»¬ä¼ æ’­çš„è¿æ¥ä¸Šçš„æƒé‡ã€‚æˆ‘ä»¬ç°åœ¨çŸ¥é“å¦‚ä½•è®¡ç®—ç½‘ç»œè¯¯å·®å¯¹æƒé‡å˜åŒ–çš„çµæ•åº¦ï¼šâˆ‚E/âˆ‚wiï¼Œkã€‚æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨è¿™ä¸ªæœ¯è¯­æ¥æ›´æ–°æƒé‡ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Using this idea and Equation (11.19)[652] the Bellman optimality equation for action-value functions can be written",
            "zh": "åˆ©ç”¨è¿™ä¸ªæƒ³æ³•å’Œæ–¹ç¨‹ï¼ˆ11.19ï¼‰[652]ï¼Œå¯ä»¥å†™å‡ºåŠ¨ä½œ-ä»·å€¼å‡½æ•°çš„è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹"
        }
    },
    {
        "translation": {
            "en": "Gauss, Carl Friedrich, 317",
            "zh": "é«˜æ–¯ï¼Œå¡å°”Â·å¼—é‡Œå¾·é‡Œå¸Œï¼Œ317"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the rate of change of zi with respect to the activation of neuron k (ak) is the weight on the connection from neuron k to neuron i: wi,k.",
            "zh": "æ­¤å¤–ï¼Œzi ç›¸å¯¹äºç¥ç»å…ƒ k ï¼ˆakï¼‰ æ¿€æ´»çš„å˜åŒ–ç‡æ˜¯ä»ç¥ç»å…ƒ k åˆ°ç¥ç»å…ƒ i çš„è¿æ¥ä¸Šçš„æƒé‡ï¼šwiï¼Œkã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Sokal-Michener for our online services example q, is judged to be more similar to instance d2 than instance d1:",
            "zh": "å°† Sokal-Michener ç”¨äºæˆ‘ä»¬çš„åœ¨çº¿æœåŠ¡ç¤ºä¾‹ qï¼Œåˆ¤æ–­ä¸ºä¸å®ä¾‹ d2 æ¯”å®ä¾‹ d1 æ›´ç›¸ä¼¼ï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, in the office rentals dataset, the values of the SIZE feature range from 500 to 1,000, whereas the values for the FLOOR feature range from only 4 to 14.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†ä¸­ï¼ŒSIZE è¦ç´ çš„å€¼èŒƒå›´ä¸º 500 åˆ° 1,000ï¼Œè€Œ FLOOR è¦ç´ çš„å€¼èŒƒå›´ä»…ä¸º 4 åˆ° 14ã€‚"
        }
    },
    {
        "translation": {
            "en": "From then on, the sum of squared errors of the network continues to slowly reduce until it reaches the convergence criterion of SSE < 0.0001.",
            "zh": "ä»é‚£æ—¶èµ·ï¼Œç½‘ç»œçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œç»§ç»­ç¼“æ…¢å‡å°ï¼Œç›´åˆ°è¾¾åˆ° SSE < 0.0001 çš„æ”¶æ•›å‡†åˆ™ã€‚"
        }
    },
    {
        "translation": {
            "en": "The division of data during the k-fold cross validation process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "k æŠ˜å äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­çš„æ•°æ®åˆ’åˆ†ã€‚é»‘è‰²çŸ©å½¢è¡¨ç¤ºæµ‹è¯•æ•°æ®ï¼Œç™½è‰²ç©ºæ ¼è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The search will then move to a new node (Lines 8, 9, 10, and 11).",
            "zh": "ç„¶åï¼Œæœç´¢å°†ç§»åŠ¨åˆ°æ–°èŠ‚ç‚¹ï¼ˆç¬¬ 8ã€9ã€10 å’Œ 11 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Daelemans, W., and A. van den Bosch. 2005. Memory-based language processing. Studies in natural language processing. Cambridge University Press.",
            "zh": "Daelemansï¼Œ W. å’Œ A. van den Boschã€‚2005. åŸºäºè®°å¿†çš„è¯­è¨€å¤„ç†.è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2217",
            "zh": "0.2217"
        }
    },
    {
        "translation": {
            "en": "pruning dataset, 155",
            "zh": "ä¿®å‰ªæ•°æ®é›†ï¼Œ155"
        }
    },
    {
        "translation": {
            "en": "Just over a week later, you are very disappointed to read an article published by Wood in the journal Nature (Wood, 1904) that completely refutes the existence of N rays.",
            "zh": "ä»…ä»…ä¸€ä¸ªå¤šæ˜ŸæœŸåï¼Œä½ éå¸¸å¤±æœ›åœ°è¯»åˆ°ä¼å¾·åœ¨ã€Šè‡ªç„¶ã€‹ï¼ˆWoodï¼Œ1904ï¼‰æ‚å¿—ä¸Šå‘è¡¨çš„ä¸€ç¯‡æ–‡ç« ï¼Œè¯¥æ–‡ç« å®Œå…¨é©³æ–¥äº†Nå°„çº¿çš„å­˜åœ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to do this, we have included topics that are not covered in many machine learning books, including discussions on business understanding, data exploration and preparation, and case studies.",
            "zh": "ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬çº³å…¥äº†è®¸å¤šæœºå™¨å­¦ä¹ ä¹¦ç±ä¸­æ²¡æœ‰æ¶‰åŠçš„ä¸»é¢˜ï¼ŒåŒ…æ‹¬å…³äºä¸šåŠ¡ç†è§£ã€æ•°æ®æ¢ç´¢å’Œå‡†å¤‡ä»¥åŠæ¡ˆä¾‹ç ”ç©¶çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors function can be used to measure how well any combination of weights fits the instances in a training dataset. The next section explains how the values of an error function for many different potential models can be combined to form an error surface across which we can search for the optimal weights with the minimum sum of squared errors.3",
            "zh": "å¹³æ–¹è¯¯å·®æ€»å’Œå‡½æ•°å¯ç”¨äºè¡¡é‡ä»»ä½•æƒé‡ç»„åˆä¸è®­ç»ƒæ•°æ®é›†ä¸­å®ä¾‹çš„æ‹Ÿåˆç¨‹åº¦ã€‚ä¸‹ä¸€èŠ‚å°†è§£é‡Šå¦‚ä½•ç»„åˆè®¸å¤šä¸åŒæ½œåœ¨æ¨¡å‹çš„è¯¯å·®å‡½æ•°å€¼ä»¥å½¢æˆä¸€ä¸ªè¯¯å·®æ›²é¢ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¯¥æ›²é¢ä¸Šæœç´¢è¯¯å·®æœ€å°å¹³æ–¹å’Œçš„æœ€ä½³æƒé‡3ã€‚"
        }
    },
    {
        "translation": {
            "en": "softmax output layer, 434, 463, 463, 495",
            "zh": "softmax è¾“å‡ºå±‚ï¼Œ 434ï¼Œ 463ï¼Œ 463ï¼Œ 495"
        }
    },
    {
        "translation": {
            "en": "Differentiation is a part of calculus, which is a large and very important field of mathematics.",
            "zh": "å¾®åˆ†æ˜¯å¾®ç§¯åˆ†çš„ä¸€éƒ¨åˆ†ï¼Œå¾®ç§¯åˆ†æ˜¯æ•°å­¦ä¸­ä¸€ä¸ªåºå¤§è€Œéå¸¸é‡è¦çš„é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "MAP, 254",
            "zh": "åœ°å›¾ï¼Œ 254"
        }
    },
    {
        "translation": {
            "en": "These shapes relate to well-known standard probability distributions,3 and recognizing that the distribution of the values in an ABT for a feature closely matches one of these standard distributions can help us when building machine learning models.",
            "zh": "è¿™äº›å½¢çŠ¶ä¸ä¼—æ‰€å‘¨çŸ¥çš„æ ‡å‡†æ¦‚ç‡åˆ†å¸ƒæœ‰å…³ï¼Œ3 å¹¶ä¸”è®¤è¯†åˆ°ç‰¹å¾çš„ ABT ä¸­å€¼çš„åˆ†å¸ƒä¸è¿™äº›æ ‡å‡†åˆ†å¸ƒä¹‹ä¸€éå¸¸åŒ¹é…ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of these error gradients is calculated for each neuron in the network.",
            "zh": "ä¸ºç½‘ç»œä¸­çš„æ¯ä¸ªç¥ç»å…ƒè®¡ç®—å…¶ä¸­ä¸€ä¸ªè¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. See Section 2.4.3[36].",
            "zh": "2. å‚è§ç¬¬ 2.4.3 èŠ‚[36]ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the set shown in Figure 4.5(a)[124], all the cards are identical.",
            "zh": "åœ¨å›¾4.5ï¼ˆaï¼‰[124]æ‰€ç¤ºçš„é›†åˆä¸­ï¼Œæ‰€æœ‰å¡ç‰‡éƒ½æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "data visualization, 99, 752",
            "zh": "æ•°æ®å¯è§†åŒ–ï¼Œ 99ï¼Œ 752"
        }
    },
    {
        "translation": {
            "en": "4. The words multivariable and multi-feature are equivalent. The use of multivariable is a sign of the origins of regression in statistics rather than machine learning.",
            "zh": "4. å¤šå˜é‡å’Œå¤šç‰¹å¾è¿™ä¸¤ä¸ªè¯æ˜¯ç­‰ä»·çš„ã€‚å¤šå˜é‡çš„ä½¿ç”¨æ˜¯ç»Ÿè®¡å­¦è€Œä¸æ˜¯æœºå™¨å­¦ä¹ ä¸­å›å½’èµ·æºçš„æ ‡å¿—ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that, again like our mountain climber, the gradient descent algorithm can use the direction of the slope of the error surface at the current location in the weight space.",
            "zh": "è¿™æ„å‘³ç€ï¼Œå°±åƒæˆ‘ä»¬çš„ç™»å±±è€…ä¸€æ ·ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•å¯ä»¥ä½¿ç”¨æƒé‡ç©ºé—´ä¸­å½“å‰ä½ç½®çš„è¯¯å·®è¡¨é¢çš„æ–œç‡æ–¹å‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The main disadvantages of using basis functions are, first, that we must manually decide what set of basis functions to use; and second, that the number of weights in a model using basis functions is usually far greater than the number of descriptive features, so finding the optimal set of weights involves a search across a much larger set of possibilitiesâ€”that is, a much larger weight space.",
            "zh": "ä½¿ç”¨åŸºå‡½æ•°çš„ä¸»è¦ç¼ºç‚¹æ˜¯ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»æ‰‹åŠ¨å†³å®šä½¿ç”¨å“ªä¸€ç»„åŸºå‡½æ•°;å…¶æ¬¡ï¼Œä½¿ç”¨åŸºå‡½æ•°çš„æ¨¡å‹ä¸­çš„æƒé‡æ•°é€šå¸¸è¿œè¿œå¤§äºæè¿°æ€§ç‰¹å¾çš„æ•°é‡ï¼Œå› æ­¤è¦æ‰¾åˆ°æœ€ä½³æƒé‡é›†ï¼Œéœ€è¦æœç´¢æ›´å¤§çš„å¯èƒ½æ€§é›†ï¼Œå³æ›´å¤§çš„æƒé‡ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "1.2â€…â€…â€…A more complex credit scoring dataset.",
            "zh": "1.2 æ›´å¤æ‚çš„ä¿¡ç”¨è¯„åˆ†æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Any values outside these thresholds would be converted to the threshold values.",
            "zh": "è¶…å‡ºè¿™äº›é˜ˆå€¼çš„ä»»ä½•å€¼éƒ½å°†è½¬æ¢ä¸ºé˜ˆå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The preceding analysis highlighted that the variance of output of a weighted sum is dependent on the number of inputs to the weighted sum (be it nin during forward propagation or nout during backward propagation).",
            "zh": "å‰é¢çš„åˆ†æå¼ºè°ƒï¼ŒåŠ æƒå’Œçš„è¾“å‡ºæ–¹å·®å–å†³äºåŠ æƒå’Œçš„è¾“å…¥æ•°é‡ï¼ˆæ— è®ºæ˜¯å‰å‘ä¼ æ’­æœŸé—´çš„ nin è¿˜æ˜¯åå‘ä¼ æ’­æœŸé—´çš„ noutï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(d)[620] shows the distance matrix after this new cluster has been created.",
            "zh": "è¡¨10.5ï¼ˆdï¼‰[620]æ˜¾ç¤ºäº†åˆ›å»ºæ­¤æ–°èšç±»åçš„è·ç¦»çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPABERR_U/G/R/I/Z",
            "zh": "EXPABERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Kingma, Diederik P., and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.",
            "zh": "Kingmaã€Diederik P. å’Œ Jimmy Baã€‚2014. Adamï¼šä¸€ç§éšæœºä¼˜åŒ–æ–¹æ³•ã€‚arXiv é¢„å°æœ¬ arXivï¼š1412.6980ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.1â€…â€…â€…Different Perspectives on Prediction Models",
            "zh": "14.1 é¢„æµ‹æ¨¡å‹çš„ä¸åŒè§†è§’"
        }
    },
    {
        "translation": {
            "en": "7.18â€…â€…â€…A scatter plot of the P20 and P45 features from the EEG dataset. Instances representing positive images are shown as crosses, and those representing negative images as triangles.",
            "zh": "7.18 EEG æ•°æ®é›†ä¸­ P20 å’Œ P45 ç‰¹å¾çš„æ•£ç‚¹å›¾ã€‚è¡¨ç¤ºæ­£å›¾åƒçš„å®ä¾‹æ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œè¡¨ç¤ºè´Ÿå›¾åƒçš„å®ä¾‹æ˜¾ç¤ºä¸ºä¸‰è§’å½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, full joint distributions are not tractable for any domain of reasonable complexity.",
            "zh": "å› æ­¤ï¼Œå¯¹äºä»»ä½•å…·æœ‰åˆç†å¤æ‚æ€§çš„é¢†åŸŸï¼Œå®Œå…¨è”åˆåˆ†å¸ƒéƒ½æ˜¯ä¸å¯å¤„ç†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hubel, D. H., and T. N. Wiesel. 1962. Receptive fields, binocular interation and functional architecture in the catâ€™s visual cortex. Journal of Physiology 160: 106â€“154.",
            "zh": "Hubelï¼Œ DH å’Œ TN Wieselã€‚1962. çŒ«è§†è§‰çš®å±‚ä¸­çš„æ„Ÿå—é‡ã€åŒçœ¼äº¤äº’å’ŒåŠŸèƒ½ç»“æ„ã€‚ç”Ÿç†å­¦æ‚å¿—160ï¼š106-154ã€‚"
        }
    },
    {
        "translation": {
            "en": "John would like to thank Lorraine Byrne, Simon Dobnik, Dietmar Frey, Ionella Longo, Alan Mc Donnell, Josef van Genabith, Mary van Genabith, his colleagues and students at Technological University Dublin and in the ADAPT Centre, and all his friends from basketball for their help and encouragement.",
            "zh": "John è¦æ„Ÿè°¢ Lorraine Byrneã€Simon Dobnikã€Dietmar Freyã€Ionella Longoã€Alan Mc Donnellã€Josef van Genabithã€Mary van Genabithã€ä»–åœ¨éƒ½æŸæ—ç†å·¥å¤§å­¦å’Œ ADAPT ä¸­å¿ƒçš„åŒäº‹å’Œå­¦ç”Ÿï¼Œä»¥åŠä»–æ‰€æœ‰ç¯®çƒç•Œçš„æœ‹å‹ä»¬çš„å¸®åŠ©å’Œé¼“åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "MSE, 575",
            "zh": "MSEï¼Œ575"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the distributions, the next step is to fit the distributions to the data.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†åˆ†å¸ƒï¼Œä¸‹ä¸€æ­¥å°±æ˜¯å°†åˆ†å¸ƒæ‹Ÿåˆåˆ°æ•°æ®ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, even using the variable elimination algorithm, calculating exact probabilities from a Bayesian network when descriptive feature values are missing is prohibitively complex.",
            "zh": "ç„¶è€Œï¼Œå³ä½¿ä½¿ç”¨å˜é‡æ¶ˆå…ƒç®—æ³•ï¼Œåœ¨ç¼ºå°‘æè¿°æ€§ç‰¹å¾å€¼æ—¶ä»è´å¶æ–¯ç½‘ç»œè®¡ç®—ç²¾ç¡®æ¦‚ç‡ä¹Ÿæ˜¯éå¸¸å¤æ‚çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "For these reasons, the inclusion of more complex functions with the neurons of the network or the inclusion of more neurons within the hidden layer of the network makes the learning task more difficult.",
            "zh": "ç”±äºè¿™äº›åŸå› ï¼Œåœ¨ç½‘ç»œçš„ç¥ç»å…ƒä¸­åŒ…å«æ›´å¤æ‚çš„å‡½æ•°æˆ–åœ¨ç½‘ç»œçš„éšè—å±‚ä¸­åŒ…å«æ›´å¤šçš„ç¥ç»å…ƒä¼šä½¿å­¦ä¹ ä»»åŠ¡æ›´åŠ å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To do this we must adjust the derivatives used in the calculation of the Î´s for the output neurons because we have changed the activation function used by these neurons.",
            "zh": "ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¿…é¡»è°ƒæ•´ç”¨äºè®¡ç®—è¾“å‡ºç¥ç»å…ƒçš„Î´çš„å¯¼æ•°ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ”¹å˜äº†è¿™äº›ç¥ç»å…ƒä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have presented this discussion on the context of episodic, model-free, policy-based reinforcement learning.",
            "zh": "æˆ‘ä»¬åœ¨æƒ…èŠ‚æ€§ã€æ— æ¨¡å‹ã€åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ çš„èƒŒæ™¯ä¸‹è¿›è¡Œäº†è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The bottleneck layer contains six units, and this is the dimensionality of the new representation, or embedding, generated.",
            "zh": "ç“¶é¢ˆå±‚åŒ…å«å…­ä¸ªå•å…ƒï¼Œè¿™æ˜¯ç”Ÿæˆçš„æ–°è¡¨ç¤ºæˆ–åµŒå…¥çš„ç»´åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dick: Not alphabeticalâ€¦",
            "zh": "è¿ªå…‹ï¼šä¸æ˜¯æŒ‰å­—æ¯é¡ºåºæ’åˆ—çš„......"
        }
    },
    {
        "translation": {
            "en": "Table 7.4",
            "zh": "è¡¨ 7.4"
        }
    },
    {
        "translation": {
            "en": "The value of the DRAFT feature is indicated by the shape representing each instance as a point in the feature space: triangles for no and crosses for yes.",
            "zh": "DRAFT ç‰¹å¾çš„å€¼ç”±å°†æ¯ä¸ªå®ä¾‹è¡¨ç¤ºä¸ºç‰¹å¾ç©ºé—´ä¸­ä¸€ä¸ªç‚¹çš„å½¢çŠ¶è¡¨ç¤ºï¼šä¸‰è§’å½¢è¡¨ç¤ºå¦ï¼Œåå­—è¡¨ç¤ºæ˜¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the early 1960s Hubel and Wiesel carried out a series of experiments in which they used probes to track the neural activity in the brains of sedated cats while simple visual features such as horizontal or vertical lines of light were projected onto different locations on a dark screen (Hubel and Wiesel, 1962).",
            "zh": "åœ¨ 1960 å¹´ä»£åˆæœŸï¼ŒHubel å’Œ Wiesel è¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒï¼Œä»–ä»¬ä½¿ç”¨æ¢é’ˆè·Ÿè¸ªé•‡é™çŒ«å¤§è„‘ä¸­çš„ç¥ç»æ´»åŠ¨ï¼ŒåŒæ—¶å°†ç®€å•çš„è§†è§‰ç‰¹å¾ï¼ˆä¾‹å¦‚æ°´å¹³æˆ–å‚ç›´çº¿ï¼‰æŠ•å°„åˆ°æš—å±å¹•ä¸Šçš„ä¸åŒä½ç½®ï¼ˆHubel å’Œ Wieselï¼Œ1962 å¹´ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Level",
            "zh": "æ°´å¹³"
        }
    },
    {
        "translation": {
            "en": "MaxEnt model, 357",
            "zh": "MaxEnt å‹å·ï¼Œ357"
        }
    },
    {
        "translation": {
            "en": "The calculation of an error derivative with respect to a weight is valid only for small changes in that weight.",
            "zh": "ç›¸å¯¹äºæƒé‡çš„è¯¯å·®å¯¼æ•°çš„è®¡ç®—ä»…å¯¹è¯¥æƒé‡çš„å¾®å°å˜åŒ–æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "analytics solution, 23, 24",
            "zh": "åˆ†æè§£å†³æ–¹æ¡ˆï¼Œ 23ï¼Œ 24"
        }
    },
    {
        "translation": {
            "en": "This does not affect the generality of the discussion because, as we discussed earlier, a weighted sum that includes a bias term as a weight implements an affine transformation composed of first applying a linear function to the inputs and then translating the result by a bias.",
            "zh": "è¿™å¹¶ä¸å½±å“è®¨è®ºçš„ä¸€èˆ¬æ€§ï¼Œå› ä¸ºæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è®¨è®ºçš„ï¼ŒåŒ…å«åç½®é¡¹ä½œä¸ºæƒé‡çš„åŠ æƒå’Œå®ç°äº†ä»¿å°„å˜æ¢ï¼Œè¯¥å˜æ¢ç”±é¦–å…ˆå¯¹è¾“å…¥åº”ç”¨çº¿æ€§å‡½æ•°ï¼Œç„¶åé€šè¿‡åå·®è½¬æ¢ç»“æœç»„æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The assumption of conditional independence between the features in the evidence given the level of the target feature also makes the naive Bayes model relatively robust to data fragmentation and the curse of dimensionality. This is particularly important in scenarios with small datasets or with sparse data.14 One application domain where sparse data is the norm rather than the exception is in text analytics (for example, spam filtering), and naive Bayes models are often successful in this domain.",
            "zh": "ç»™å®šç›®æ ‡ç‰¹å¾çš„æ°´å¹³ï¼Œå‡è®¾è¯æ®ä¸­çš„ç‰¹å¾ä¹‹é—´å­˜åœ¨æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œè¿™ä¹Ÿä½¿æœ´ç´ è´å¶æ–¯æ¨¡å‹å¯¹æ•°æ®ç¢ç‰‡å’Œç»´æ•°è¯…å’’ç›¸å¯¹é²æ£’ã€‚è¿™åœ¨æ•°æ®é›†è¾ƒå°æˆ–æ•°æ®ç¨€ç–çš„åœºæ™¯ä¸­å°¤ä¸ºé‡è¦ã€‚14 åœ¨æ–‡æœ¬åˆ†æï¼ˆä¾‹å¦‚ï¼Œåƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼‰ä¸­ï¼Œç¨€ç–æ•°æ®æ˜¯å¸¸æ€è€Œä¸æ˜¯ä¾‹å¤–çš„ä¸€ä¸ªåº”ç”¨åŸŸï¼Œè€Œæœ´ç´ çš„è´å¶æ–¯æ¨¡å‹é€šå¸¸åœ¨æ­¤é¢†åŸŸå–å¾—æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The table in a data quality report that describes continuous features should include a row containing the minimum, 1st quartile, mean, median, 3rd quartile, maximum, and standard deviation statistics for that feature as well as the total number of instances in the ABT, the percentage of instances in the ABT that are missing a value for each feature and the cardinality of each feature, (cardinality measures the number of distinct values present in the ABT for a feature).",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­æè¿°è¿ç»­è¦ç´ çš„è¡¨åº”åŒ…æ‹¬ä¸€è¡Œï¼Œå…¶ä¸­åŒ…å«è¯¥è¦ç´ çš„æœ€å°å€¼ã€ç¬¬ 1 ä¸ªå››åˆ†ä½æ•°ã€å¹³å‡å€¼ã€ä¸­ä½æ•°ã€ç¬¬ 3 ä¸ªå››åˆ†ä½æ•°ã€æœ€å¤§å€¼å’Œæ ‡å‡†å·®ç»Ÿè®¡æ•°æ®ï¼Œä»¥åŠ ABT ä¸­çš„å®ä¾‹æ€»æ•°ã€ABT ä¸­ç¼ºå°‘æ¯ä¸ªç‰¹å¾å€¼çš„å®ä¾‹ç™¾åˆ†æ¯”ä»¥åŠæ¯ä¸ªç‰¹å¾çš„åŸºæ•°ï¼Œ ï¼ˆåŸºæ•°æµ‹é‡ç‰¹å¾çš„ ABT ä¸­å­˜åœ¨çš„éé‡å¤å€¼çš„æ•°é‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Suggested course syllabi.",
            "zh": "å»ºè®®çš„è¯¾ç¨‹å¤§çº²ã€‚"
        }
    },
    {
        "translation": {
            "en": "In our suggested course we have chosen to cover all of Chapters 4 (Information-Based Learning) and 7 (Error-Based Learning).",
            "zh": "åœ¨æˆ‘ä»¬æ¨èçš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©æ¶µç›–ç¬¬ 4 ç« ï¼ˆåŸºäºä¿¡æ¯çš„å­¦ä¹ ï¼‰å’Œç¬¬ 7 ç« ï¼ˆåŸºäºé”™è¯¯çš„å­¦ä¹ ï¼‰çš„æ‰€æœ‰å†…å®¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.10â€…â€…â€…Prediction score distributions for the (a) spam and (b) ham target levels based on the data in Table 9.11[557].",
            "zh": "9.10 æ ¹æ®è¡¨9.11[557]ä¸­çš„æ•°æ®ï¼Œï¼ˆaï¼‰åƒåœ¾é‚®ä»¶å’Œï¼ˆbï¼‰ç«è…¿ç›®æ ‡æ°´å¹³çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 13.3[710] shows bar plots of the frequencies of the 3-level and the 5-level target features.",
            "zh": "å›¾13.3[710]æ˜¾ç¤ºäº†3çº§å’Œ5çº§ç›®æ ‡ç‰¹å¾çš„é¢‘ç‡æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "error surface, 311, 317",
            "zh": "è¯¯å·®é¢ï¼Œ311,317"
        }
    },
    {
        "translation": {
            "en": "The parameters of the models learned for the three final decision boundaries in Figure 7.21[360] are",
            "zh": "å›¾7.21[360]ä¸­ä¸‰ä¸ªæœ€ç»ˆå†³ç­–è¾¹ç•Œçš„æ¨¡å‹å‚æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of the extended generators dataset given in Table 7.7[347], which results in instances with the different target levels overlapping each other. Instances representing good generators are shown as crosses, and those representing faulty generators as triangles.",
            "zh": "è¡¨ 7.7[347] ä¸­ç»™å‡ºçš„æ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„æ•£ç‚¹å›¾ï¼Œè¿™å¯¼è‡´ä¸åŒç›®æ ‡æ°´å¹³ç›¸äº’é‡å çš„å®ä¾‹ã€‚è¡¨ç¤ºè‰¯å¥½ç”Ÿæˆå™¨çš„å®ä¾‹æ˜¾ç¤ºä¸ºåå­—å½¢ï¼Œè¡¨ç¤ºæ•…éšœç”Ÿæˆå™¨çš„å®ä¾‹æ˜¾ç¤ºä¸ºä¸‰è§’å½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "A recurrent neural network is deliberately designed so that when the network processes an input at time t in a sequence, the output generated is dependent not only on input t but also on the previous inputs in the sequence.",
            "zh": "å¾ªç¯ç¥ç»ç½‘ç»œç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œå½“ç½‘ç»œåœ¨åºåˆ—ä¸­çš„æ—¶é—´ t å¤„ç†è¾“å…¥æ—¶ï¼Œç”Ÿæˆçš„è¾“å‡ºä¸ä»…ä¾èµ–äºè¾“å…¥ tï¼Œè¿˜ä¾èµ–äºåºåˆ—ä¸­çš„å…ˆå‰è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "He decided that the observation period, during which he would collect data on customer behavior, would stretch back for 12 months.",
            "zh": "ä»–å†³å®šå°†æ”¶é›†å®¢æˆ·è¡Œä¸ºæ•°æ®çš„è§‚å¯ŸæœŸå»¶é•¿ 12 ä¸ªæœˆã€‚"
        }
    },
    {
        "translation": {
            "en": "A difficulty with training a deep network with backpropagation and gradient descent is unstable gradients (either vanishing or exploding gradients).",
            "zh": "è®­ç»ƒå…·æœ‰åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™çš„æ·±åº¦ç½‘ç»œçš„ä¸€ä¸ªå›°éš¾æ˜¯ä¸ç¨³å®šçš„æ¢¯åº¦ï¼ˆæ¶ˆå¤±æˆ–çˆ†ç‚¸æ¢¯åº¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "London, England",
            "zh": "è‹±å›½ä¼¦æ•¦"
        }
    },
    {
        "translation": {
            "en": "By examining the data for this feature more closely, they eventually explained this shape by the fact that most customers did not go over the number of minutes in their bundle, which accounts for the large bar for 0 in this histogram.",
            "zh": "é€šè¿‡æ›´ä»”ç»†åœ°æ£€æŸ¥æ­¤åŠŸèƒ½çš„æ•°æ®ï¼Œä»–ä»¬æœ€ç»ˆé€šè¿‡å¤§å¤šæ•°å®¢æˆ·æ²¡æœ‰è¶…è¿‡å…¶æ†ç»‘åŒ…ä¸­çš„åˆ†é’Ÿæ•°è¿™ä¸€äº‹å®æ¥è§£é‡Šè¿™ç§å½¢çŠ¶ï¼Œè¿™è§£é‡Šäº†è¯¥ç›´æ–¹å›¾ä¸­ 0 çš„å¤§æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the playersâ€™ heights given in Figure A.3[747], the mean is also 149.375, so the variance can be calculated as",
            "zh": "å¯¹äºå›¾A.3[747]ä¸­ç»™å‡ºçš„çƒå‘˜èº«é«˜ï¼Œå¹³å‡å€¼ä¹Ÿæ˜¯149.375ï¼Œå› æ­¤æ–¹å·®å¯ä»¥è®¡ç®—ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Table 5.3[189] shows the distances between our query instance and each instance from Table 5.2[183] ranked from lowest to highest.",
            "zh": "è¡¨ 5.3[189] æ˜¾ç¤ºäº†æˆ‘ä»¬çš„æŸ¥è¯¢å®ä¾‹ä¸è¡¨ 5.2[183] ä¸­æ¯ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»ï¼Œä»ä½åˆ°é«˜æ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "8.36â€…â€…â€…Worked example illustrating the dataflow through a multilayer, multifilter CNN.",
            "zh": "8.36 å·¥ä½œç¤ºä¾‹è¯´æ˜äº†é€šè¿‡å¤šå±‚ã€å¤šæ»¤æ³¢å™¨ CNN çš„æ•°æ®æµã€‚"
        }
    },
    {
        "translation": {
            "en": "loss function, 168, 315, 409, 670",
            "zh": "æŸå¤±å‡½æ•°ï¼Œ 168ï¼Œ 315ï¼Œ 409ï¼Œ 670"
        }
    },
    {
        "translation": {
            "en": "Each of these recursive calls uses the partition it is called on as the dataset it considers and is restricted to selecting from the set of features that have not been tested so far on the path from the root node.",
            "zh": "è¿™äº›é€’å½’è°ƒç”¨ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä½¿ç”¨å®ƒè¢«è°ƒç”¨çš„åˆ†åŒºä½œä¸ºå®ƒè€ƒè™‘çš„æ•°æ®é›†ï¼Œå¹¶ä¸”ä»…é™äºä»æ ¹èŠ‚ç‚¹è·¯å¾„ä¸Šè¿„ä»Šä¸ºæ­¢å°šæœªæµ‹è¯•çš„åŠŸèƒ½é›†ä¸­è¿›è¡Œé€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Guided search techniques, such as the gradient descent algorithm, are used for this task.",
            "zh": "å¼•å¯¼å¼æœç´¢æŠ€æœ¯ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼‰ç”¨äºæ­¤ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.1[6] lists a set of historical instances, or dataset, of mortgages that a bank has granted in the past.2 This dataset includes descriptive features that describe the mortgage, and a target feature that indicates whether the mortgage applicant ultimately defaulted on the loan or paid it back in full.",
            "zh": "è¡¨1.1[6]åˆ—å‡ºäº†ä¸€ç»„é“¶è¡Œè¿‡å»å‘æ”¾çš„æŠµæŠ¼è´·æ¬¾çš„å†å²å®ä¾‹æˆ–æ•°æ®é›†.2è¯¥æ•°æ®é›†åŒ…æ‹¬æè¿°æŠµæŠ¼è´·æ¬¾çš„æè¿°æ€§ç‰¹å¾ï¼Œä»¥åŠæŒ‡ç¤ºæŠµæŠ¼è´·æ¬¾ç”³è¯·äººæœ€ç»ˆæ˜¯æ‹–æ¬ è´·æ¬¾è¿˜æ˜¯å…¨é¢å¿è¿˜çš„ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although all the factors relating to data that were considered during the feasibility assessment of the analytics solution2 are still relevant, three key data considerations are particularly important when we are designing features.",
            "zh": "å°½ç®¡åœ¨åˆ†æè§£å†³æ–¹æ¡ˆ2çš„å¯è¡Œæ€§è¯„ä¼°æœŸé—´è€ƒè™‘çš„ä¸æ•°æ®ç›¸å…³çš„æ‰€æœ‰å› ç´ ä»ç„¶ç›¸å…³ï¼Œä½†åœ¨è®¾è®¡åŠŸèƒ½æ—¶ï¼Œä¸‰ä¸ªå…³é”®æ•°æ®è€ƒè™‘å› ç´ å°¤ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "AGE: The age of the taxpayer.",
            "zh": "å¹´é¾„ï¼šçº³ç¨äººçš„å¹´é¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the formulation given in Equation (11.7)[642] expected future rewards are considered to be as valuable as the immediate reward that the agent will receive from taking the next immediate action, at.",
            "zh": "åœ¨ç­‰å¼ï¼ˆ11.7ï¼‰[642]ä¸­ç»™å‡ºçš„å…¬å¼ä¸­ï¼Œé¢„æœŸçš„æœªæ¥å¥–åŠ±è¢«è®¤ä¸ºä¸æ™ºèƒ½ä½“ä»é‡‡å–ä¸‹ä¸€ä¸ªç«‹å³è¡ŒåŠ¨ä¸­è·å¾—çš„å³æ—¶å¥–åŠ±ä¸€æ ·æœ‰ä»·å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although rank and prune approaches using filters are computationally efficient, they suffer from the fact that the predictiveness of each feature is evaluated in isolation from the other features in the dataset. This leads to the undesirable result that ranking and pruning can exclude interacting features and include redundant features.",
            "zh": "å°½ç®¡ä½¿ç”¨è¿‡æ»¤å™¨çš„ç§©å’Œä¿®å‰ªæ–¹æ³•åœ¨è®¡ç®—ä¸Šæ˜¯æœ‰æ•ˆçš„ï¼Œä½†å®ƒä»¬å—åˆ°ä»¥ä¸‹äº‹å®çš„å½±å“ï¼šæ¯ä¸ªç‰¹å¾çš„é¢„æµ‹æ€§éƒ½æ˜¯ä¸æ•°æ®é›†ä¸­çš„å…¶ä»–ç‰¹å¾éš”ç¦»è¯„ä¼°çš„ã€‚è¿™ä¼šå¯¼è‡´ä¸è‰¯ç»“æœï¼Œå³æ’åºå’Œä¿®å‰ªå¯ä»¥æ’é™¤äº¤äº’ç‰¹å¾å¹¶åŒ…å«å†—ä½™ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bringing all the LSTM equations together specifies the sequence of calculations that occur in the forward pass of an LSTM",
            "zh": "å°†æ‰€æœ‰ LSTM æ–¹ç¨‹æ”¾åœ¨ä¸€èµ·æŒ‡å®šäº†åœ¨ LSTM çš„å‰å‘ä¼ é€’ä¸­å‘ç”Ÿçš„è®¡ç®—é¡ºåº"
        }
    },
    {
        "translation": {
            "en": "(f) On the basis of the changes made to the TwentyTwos playing agentâ€™s action-value table following the two actions taken in the previous parts of this question, how has the agentâ€™s target policy changed?",
            "zh": "ï¼ˆfï¼‰ æ ¹æ®æœ¬é—®é¢˜å‰å‡ éƒ¨åˆ†é‡‡å–çš„ä¸¤æ¬¡è¡ŒåŠ¨ä¹‹åï¼Œå¯¹äºŒåäºŒæ¸¸æˆä»£ç†äººçš„è¡ŒåŠ¨ä»·å€¼è¡¨æ‰€åšçš„æ›´æ”¹ï¼Œä»£ç†äººçš„ç›®æ ‡æ”¿ç­–å‘ç”Ÿäº†æ€æ ·çš„å˜åŒ–ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "For example, as we discussed in Chapter 6[243] on probability, generative models encode independence assumptions about the descriptive features in d. This may sound like another problem for generative models.",
            "zh": "ä¾‹å¦‚ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬ 6 ç« [243]ä¸­è®¨è®ºçš„æ¦‚ç‡ï¼Œç”Ÿæˆæ¨¡å‹ç¼–ç äº†å…³äº d ä¸­æè¿°æ€§ç‰¹å¾çš„ç‹¬ç«‹æ€§å‡è®¾ã€‚å¯¹äºç”Ÿæˆæ¨¡å‹æ¥è¯´ï¼Œè¿™å¬èµ·æ¥åƒæ˜¯å¦ä¸€ä¸ªé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Western Electric rules, 579",
            "zh": "è¥¿éƒ¨ç”µæ°”è§„åˆ™ï¼Œ579"
        }
    },
    {
        "translation": {
            "en": "The first path of information processing in the input gate decides which elements of the cell state should be updated.",
            "zh": "è¾“å…¥é—¨ä¸­ä¿¡æ¯å¤„ç†çš„ç¬¬ä¸€æ¡è·¯å¾„å†³å®šäº†å•å…ƒçŠ¶æ€çš„å“ªäº›å…ƒç´ åº”è¯¥æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Names: Kelleher, John D., 1974- author. |",
            "zh": "åˆåï¼š Kelleherï¼Œ John D.ï¼Œ 1974- author.|"
        }
    },
    {
        "translation": {
            "en": "Other than changing the weight update rule, we donâ€™t need to make any other changes to the model training process presented for multivariable linear regression models. To further illustrate this process, the next section presents a worked example of training a multivariable logistic regression model for an extended version of the generators dataset.",
            "zh": "é™¤äº†æ›´æ”¹æƒé‡æ›´æ–°è§„åˆ™å¤–ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¯¹å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹çš„æ¨¡å‹è®­ç»ƒè¿‡ç¨‹è¿›è¡Œä»»ä½•å…¶ä»–æ›´æ”¹ã€‚ä¸ºäº†è¿›ä¸€æ­¥è¯´æ˜è¿™ä¸€è¿‡ç¨‹ï¼Œä¸‹ä¸€èŠ‚å°†ä»‹ç»ä¸€ä¸ªä¸ºç”Ÿæˆå™¨æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬è®­ç»ƒå¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹çš„å·¥ä½œç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset of whiskeys listing the age (in years), the rating (between 1 and 5, with 5 being the best), and the bottle price of each whiskey.",
            "zh": "å¨å£«å¿Œæ•°æ®é›†ï¼Œåˆ—å‡ºæ¯ç§å¨å£«å¿Œçš„å¹´é¾„ï¼ˆä»¥å¹´ä¸ºå•ä½ï¼‰ã€è¯„çº§ï¼ˆåœ¨ 1 åˆ° 5 ä¹‹é—´ï¼Œå…¶ä¸­ 5 æ˜¯æœ€å¥½çš„ï¼‰å’Œç“¶ä»·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason why the error surface always has these properties is that its overall shape is determined by the linearity of the model, rather than the properties of the data.",
            "zh": "è¯¯å·®æ›²é¢å§‹ç»ˆå…·æœ‰è¿™äº›å±æ€§çš„åŸå› æ˜¯ï¼Œå…¶æ•´ä½“å½¢çŠ¶ç”±æ¨¡å‹çš„çº¿æ€§åº¦å†³å®šï¼Œè€Œä¸æ˜¯æ•°æ®çš„å±æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Anscombe, Francis J. 1973. Graphs in statistical analysis. American Statistician 27 (1): 17â€“21.",
            "zh": "Anscombeï¼Œå¼—æœ—è¥¿æ–¯ J. 1973 å¹´ã€‚ç»Ÿè®¡åˆ†æä¸­çš„å›¾è¡¨ã€‚ç¾å›½ç»Ÿè®¡å­¦å®¶27ï¼ˆ1ï¼‰ï¼š17-21ã€‚"
        }
    },
    {
        "translation": {
            "en": "control group, 583",
            "zh": "å¯¹ç…§ç»„ï¼Œ583"
        }
    },
    {
        "translation": {
            "en": "A consequence of this layer-wise transformation of the input data into new representations is that as the network becomes deeper, the ability of the network to represent more complex relationships between descriptive and target features is increased.",
            "zh": "å°†è¾“å…¥æ•°æ®é€å±‚è½¬æ¢ä¸ºæ–°è¡¨ç¤ºçš„ç»“æœæ˜¯ï¼Œéšç€ç½‘ç»œçš„æ·±åº¦ï¼Œç½‘ç»œè¡¨ç¤ºæè¿°æ€§å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´æ›´å¤æ‚å…³ç³»çš„èƒ½åŠ›ä¼šå¢å¼ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, it is better to choose a number of different approaches and to run experiments to evaluate which is best for the particular project.",
            "zh": "ç›¸åï¼Œæœ€å¥½é€‰æ‹©è®¸å¤šä¸åŒçš„æ–¹æ³•å¹¶è¿è¡Œå®éªŒæ¥è¯„ä¼°å“ªç§æ–¹æ³•æœ€é€‚åˆç‰¹å®šé¡¹ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "average linkage: the average of the distances between all pairs of instances in two clusters is used as the overall distance between the clusters; and",
            "zh": "å¹³å‡è”åŠ¨ï¼šä»¥ä¸¤ä¸ªé›†ç¾¤ä¸­æ‰€æœ‰å®ä¾‹å¯¹ä¹‹é—´çš„è·ç¦»å¹³å‡å€¼ä½œä¸ºé›†ç¾¤ä¹‹é—´çš„æ€»è·ç¦»;å’Œ"
        }
    },
    {
        "translation": {
            "en": "| f) from P(H,F,V,M) by summing the values in all the cells where h and f are the case (the top four cells in the first column).",
            "zh": "|fï¼‰ ä» Pï¼ˆHï¼ŒFï¼ŒVï¼ŒMï¼‰ ä¸­ï¼Œå°† h å’Œ f æ‰€åœ¨çš„æ‰€æœ‰å•å…ƒæ ¼ï¼ˆç¬¬ä¸€åˆ—ä¸­çš„å‰å››ä¸ªå•å…ƒæ ¼ï¼‰ä¸­çš„å€¼ç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The agent does not need to know anything about the dynamics of the environment in which it is acting.",
            "zh": "æ™ºèƒ½ä½“ä¸éœ€è¦çŸ¥é“å®ƒæ‰€å¤„ç¯å¢ƒçš„åŠ¨æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this approach the features are ranked using a measure of their predictiveness, and any feature outside the top X% of the features in the list is pruned.",
            "zh": "åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œä½¿ç”¨å…¶é¢„æµ‹æ€§çš„åº¦é‡å¯¹ç‰¹å¾è¿›è¡Œæ’åï¼Œå¹¶ä¸”å°†ä¿®å‰ªåˆ—è¡¨ä¸­å‰ X% ç‰¹å¾ä¹‹å¤–çš„ä»»ä½•ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "13. A hard threshold can be used fairly successfully to train prediction models for categorical targets using the perceptron learning rule, although we do not cover that in this book.",
            "zh": "13. ç¡¬é˜ˆå€¼å¯ä»¥ç›¸å½“æˆåŠŸåœ°ç”¨äºä½¿ç”¨æ„ŸçŸ¥å™¨å­¦ä¹ è§„åˆ™æ¥è®­ç»ƒåˆ†ç±»ç›®æ ‡çš„é¢„æµ‹æ¨¡å‹ï¼Œå°½ç®¡æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­æ²¡æœ‰ä»‹ç»å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "affine function, 385",
            "zh": "ä»¿å°„å‡½æ•°ï¼Œ385"
        }
    },
    {
        "translation": {
            "en": "One of the most common applications of clustering is customer segmentation with which organizations attempt to discover meaningful groupings into which they can group their customers so that targeted offers or treatments can be designed.",
            "zh": "èšç±»æœ€å¸¸è§çš„åº”ç”¨ä¹‹ä¸€æ˜¯å®¢æˆ·ç»†åˆ†ï¼Œç»„ç»‡è¯•å›¾é€šè¿‡å®ƒå‘ç°æœ‰æ„ä¹‰çš„åˆ†ç»„ï¼Œä»–ä»¬å¯ä»¥å°†å®¢æˆ·åˆ†ç»„åˆ°è¿™äº›åˆ†ç»„ä¸­ï¼Œä»¥ä¾¿è®¾è®¡æœ‰é’ˆå¯¹æ€§çš„ä¼˜æƒ æˆ–æ²»ç–—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.5",
            "zh": "å›¾ 10.5"
        }
    },
    {
        "translation": {
            "en": "There are, in fact, mathematical proofs that show that neural networks with a single hidden layer are universal approximators; i.e., they can exactly represent any continuous function of multiple inputs.",
            "zh": "äº‹å®ä¸Šï¼Œæœ‰æ•°å­¦è¯æ˜è¡¨æ˜ï¼Œå…·æœ‰å•ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œæ˜¯é€šç”¨è¿‘ä¼¼å™¨;ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬å¯ä»¥ç²¾ç¡®åœ°è¡¨ç¤ºå¤šä¸ªè¾“å…¥çš„ä»»ä½•è¿ç»­å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that we have dropped the subscript on w because every wi is sampled from the same distribution and hence has the same expected value and variance: E(W) is the expected value of a weight (i.e., the probabilistic average, or mean value, of the weights), and var(W) is the shared scaler variance of all the weights.",
            "zh": "è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åˆ é™¤äº† w ä¸Šçš„ä¸‹æ ‡ï¼Œå› ä¸ºæ¯ä¸ª wi éƒ½æ˜¯ä»ç›¸åŒçš„åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œå› æ­¤å…·æœ‰ç›¸åŒçš„æœŸæœ›å€¼å’Œæ–¹å·®ï¼šEï¼ˆWï¼‰ æ˜¯æƒé‡çš„æœŸæœ›å€¼ï¼ˆå³æƒé‡çš„æ¦‚ç‡å¹³å‡å€¼æˆ–å¹³å‡å€¼ï¼‰ï¼Œvarï¼ˆWï¼‰ æ˜¯æ‰€æœ‰æƒé‡çš„å…±äº«æ ‡åº¦æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "LU decomposition, 220",
            "zh": "LUåˆ†è§£ï¼Œ220"
        }
    },
    {
        "translation": {
            "en": "13.4â€ƒModeling",
            "zh": "13.4 å»ºæ¨¡"
        }
    },
    {
        "translation": {
            "en": "For this type of network, it is common to use rectified linear activation functions in the units in all layers except for the final output layer, at which either sigmoid or linear activation functions are usually used.12 Loss in auto-encoder networks is typically measured using mean squared error loss,13 rather than the loss functions more commonly used for classification problems.",
            "zh": "å¯¹äºè¿™ç§ç±»å‹çš„ç½‘ç»œï¼Œé€šå¸¸åœ¨æ‰€æœ‰å±‚çš„å•å…ƒä¸­ä½¿ç”¨æ ¡æ­£çš„çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œä½†æœ€ç»ˆè¾“å‡ºå±‚é™¤å¤–ï¼Œé€šå¸¸ä½¿ç”¨sigmoidæˆ–çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚12 è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œä¸­çš„æŸè€—é€šå¸¸ä½¿ç”¨å‡æ–¹è¯¯å·®æŸè€—13æ¥æµ‹é‡ï¼Œè€Œä¸æ˜¯æ›´å¸¸ç”¨äºåˆ†ç±»é—®é¢˜çš„æŸè€—å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Focusing on the input gate, the gradients for each of the inputs to the elementwise product can now be calculated as follows:",
            "zh": "ä»¥è¾“å…¥é—¨ä¸ºé‡ç‚¹ï¼Œç°åœ¨å¯ä»¥æŒ‰å…ƒç´ ä¹˜ç§¯è®¡ç®—æ¯ä¸ªè¾“å…¥çš„æ¢¯åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "A.3â€…â€…â€…Populations and Samples",
            "zh": "A.3 ç§ç¾¤å’Œæ ·æœ¬"
        }
    },
    {
        "translation": {
            "en": "Although there are some well-known sets of functionsâ€”for example, different order polynomial functionsâ€”this can be a considerable challenge.",
            "zh": "å°½ç®¡æœ‰ä¸€äº›ä¼—æ‰€å‘¨çŸ¥çš„å‡½æ•°é›†ï¼ˆä¾‹å¦‚ï¼Œä¸åŒé˜¶å¤šé¡¹å¼å‡½æ•°ï¼‰ï¼Œä½†è¿™å¯èƒ½æ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„æŒ‘æˆ˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "What has happened is that asserting conditional independence has allowed the evidence of the individual symptoms to be taken into account, rather than requiring an exact match across all the symptoms taken together.",
            "zh": "å®é™…æƒ…å†µæ˜¯ï¼Œä¸»å¼ æœ‰æ¡ä»¶çš„ç‹¬ç«‹æ€§å…è®¸è€ƒè™‘ä¸ªä½“ç—‡çŠ¶çš„è¯æ®ï¼Œè€Œä¸æ˜¯è¦æ±‚æ‰€æœ‰ç—‡çŠ¶å®Œå…¨åŒ¹é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Whether deep learning is applied to regression or classification, the size and complexity of deep learning models make them susceptible to overfitting, and so in Section 8.4.4[472] we cover the two most popular extensions to backpropagation that are used to try to avoid overfitting: early stopping and dropout.",
            "zh": "æ— è®ºæ·±åº¦å­¦ä¹ æ˜¯åº”ç”¨äºå›å½’è¿˜æ˜¯åˆ†ç±»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è§„æ¨¡å’Œå¤æ‚æ€§éƒ½ä½¿å®ƒä»¬å®¹æ˜“å—åˆ°è¿‡æ‹Ÿåˆçš„å½±å“ï¼Œå› æ­¤åœ¨ç¬¬ 8.4.4 èŠ‚[472]ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ä¸ªæœ€æµè¡Œçš„åå‘ä¼ æ’­æ‰©å±•ï¼Œç”¨äºé¿å…è¿‡åº¦æ‹Ÿåˆï¼šæå‰åœæ­¢å’Œè¾å­¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This formulation of temporal-difference learning that performs an action-value table update after every action is known as TD(0).",
            "zh": "è¿™ç§åœ¨æ¯æ¬¡æ“ä½œåæ‰§è¡ŒåŠ¨ä½œå€¼è¡¨æ›´æ–°çš„æ—¶é—´å·®åˆ†å­¦ä¹ å…¬å¼ç§°ä¸º TDï¼ˆ0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, if there were two target levels with equal likelihood in a dataset, then the expected rate of misclassification would be 0.5, and if there were four target levels with equal likelihood, then the expected rate of misclassification would be 0.75.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæ•°æ®é›†ä¸­æœ‰ä¸¤ä¸ªå¯èƒ½æ€§ç›¸ç­‰çš„ç›®æ ‡æ°´å¹³ï¼Œåˆ™é¢„æœŸé”™è¯¯åˆ†ç±»ç‡ä¸º 0.5ï¼Œå¦‚æœæœ‰å››ä¸ªå¯èƒ½æ€§ç›¸ç­‰çš„ç›®æ ‡æ°´å¹³ï¼Œåˆ™é¢„æœŸé”™è¯¯åˆ†ç±»ç‡ä¸º 0.75ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the original test set and the two new test sets, referred to as New Sample 1 and New Sample 2, the count and percentage for each target value is given (note that the tests sets do not have to be the same size because relative distributions are used).",
            "zh": "å¯¹äºåŸå§‹æµ‹è¯•é›†å’Œä¸¤ä¸ªæ–°æµ‹è¯•é›†ï¼ˆç§°ä¸ºæ–°æ ·æœ¬ 1 å’Œæ–°æ ·æœ¬ 2ï¼‰ï¼Œå°†ç»™å‡ºæ¯ä¸ªç›®æ ‡å€¼çš„è®¡æ•°å’Œç™¾åˆ†æ¯”ï¼ˆè¯·æ³¨æ„ï¼Œæµ‹è¯•é›†çš„å¤§å°ä¸å¿…ç›¸åŒï¼Œå› ä¸ºä½¿ç”¨äº†ç›¸å¯¹åˆ†å¸ƒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the last function, f(x) = 3x3 + 2x2 âˆ’ xâˆ’ 2 (Figure C.2(c)[767]), we first apply Rule 3 to divide this into four parts: 3x3, 2x2, x, and 2. Applying Rule 2 to each of the first three parts gives 9x2, 4x, and âˆ’ 1. The final part, 2, is a constant and so differentiates to zero. The derivative of this function then is .",
            "zh": "å¯¹äºæœ€åä¸€ä¸ªå‡½æ•°ï¼Œfï¼ˆxï¼‰ = 3x3 + 2x2 âˆ’ xâˆ’ 2 ï¼ˆå›¾ C.2ï¼ˆcï¼‰[767]ï¼‰ï¼Œæˆ‘ä»¬é¦–å…ˆåº”ç”¨è§„åˆ™ 3 å°†å…¶åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼š3x3ã€2x2ã€x å’Œ 2ã€‚ å°†è§„åˆ™ 2 åº”ç”¨äºå‰ä¸‰ä¸ªéƒ¨åˆ†ï¼Œå¾—åˆ° 9x2ã€4x å’Œ âˆ’ 1ã€‚æœ€åä¸€éƒ¨åˆ† 2 æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œå› æ­¤å¾®åˆ†ä¸ºé›¶ã€‚åˆ™è¯¥å‡½æ•°çš„å¯¼æ•°ä¸º ã€‚"
        }
    },
    {
        "translation": {
            "en": "An epoch is a single pass through all the examples in the training dataset.",
            "zh": "çºªå…ƒæ˜¯è®­ç»ƒæ•°æ®é›†ä¸­æ‰€æœ‰ç¤ºä¾‹çš„å•æ¬¡ä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "14.2.1â€…â€…â€…Matching Machine Learning Approaches to Projects",
            "zh": "14.2.1 å°†æœºå™¨å­¦ä¹ æ–¹æ³•ä¸é¡¹ç›®ç›¸åŒ¹é…"
        }
    },
    {
        "translation": {
            "en": "It also uses post-pruning to help with overfitting.",
            "zh": "å®ƒè¿˜ä½¿ç”¨åä¿®å‰ªæ¥å¸®åŠ©è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although this algorithm works quite well as presented, it assumes categorical features with no missing values and clean data.",
            "zh": "å°½ç®¡æ­¤ç®—æ³•çš„å·¥ä½œæ•ˆæœå¾ˆå¥½ï¼Œä½†å®ƒå‡å®šäº†æ²¡æœ‰ç¼ºå¤±å€¼å’Œå¹²å‡€æ•°æ®çš„åˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a)â€“(d) Different linkage methods that can be used to compare the distances between clusters in agglomerative hierarchical clustering. (Arrows for only some indicative distances are shown in the average linkage diagram (d).)",
            "zh": "ï¼ˆaï¼‰â€“ï¼ˆdï¼‰ å¯ç”¨äºæ¯”è¾ƒé›†èšåˆ†å±‚èšç±»ä¸­èšç±»ä¹‹é—´è·ç¦»çš„ä¸åŒé“¾æ¥æ–¹æ³•ã€‚ï¼ˆå¹³å‡è¿æ†å›¾ ï¼ˆdï¼‰ ä¸­ä»…æ˜¾ç¤ºä¸€äº›æŒ‡ç¤ºè·ç¦»çš„ç®­å¤´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Both features follow a broadly exponential distribution, however, which means that the methods described for setting the thresholds of the clamp will not work especially well (both methods work best for normally distributed data).",
            "zh": "ç„¶è€Œï¼Œè¿™ä¸¤ç§ç‰¹å¾éƒ½éµå¾ªå¹¿æ³›çš„æŒ‡æ•°åˆ†å¸ƒï¼Œè¿™æ„å‘³ç€æ‰€æè¿°çš„ç”¨äºè®¾ç½®é’³ä½é˜ˆå€¼çš„æ–¹æ³•ä¸ä¼šç‰¹åˆ«æœ‰æ•ˆï¼ˆè¿™ä¸¤ç§æ–¹æ³•éƒ½é€‚ç”¨äºæ­£æ€åˆ†å¸ƒæ•°æ®ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The actions that the car can take are to (1) maintain its current speed, (2) increase its speed (move up one level in the speed categories stationary, slow, and fast), (3) decrease its speed (move down one level in the speed categories), (4) move to the left, and (5) move to the right.",
            "zh": "æ±½è½¦å¯ä»¥é‡‡å–çš„è¡ŒåŠ¨æ˜¯ ï¼ˆ1ï¼‰ ä¿æŒå…¶å½“å‰é€Ÿåº¦ï¼Œï¼ˆ2ï¼‰ æé«˜é€Ÿåº¦ï¼ˆåœ¨é™æ­¢ã€æ…¢é€Ÿå’Œå¿«é€Ÿé€Ÿåº¦ç±»åˆ«ä¸­ä¸Šå‡ä¸€çº§ï¼‰ï¼Œï¼ˆ3ï¼‰ é™ä½é€Ÿåº¦ï¼ˆåœ¨é€Ÿåº¦ç±»åˆ«ä¸­å‘ä¸‹ç§»åŠ¨ä¸€çº§ï¼‰ï¼Œï¼ˆ4ï¼‰ å‘å·¦ç§»åŠ¨ï¼Œä»¥åŠ ï¼ˆ5ï¼‰ å‘å³ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.8â€…â€…â€…Surfaces generated by calculating (a) the arithmetic mean and (b) the harmonic mean of all combinations of features A and B that range from 0 to 100.",
            "zh": "9.8 é€šè¿‡è®¡ç®— ï¼ˆaï¼‰ 0 åˆ° 100 èŒƒå›´å†…çš„æ‰€æœ‰è¦ç´  A å’Œ B ç»„åˆçš„ç®—æœ¯å¹³å‡å€¼å’Œ ï¼ˆbï¼‰ è°æ³¢å¹³å‡å€¼ç”Ÿæˆçš„æ›²é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the simplest case, this might be calculated by subtracting the activation of each neuron in the output layer from the target output specified in the dataset.",
            "zh": "åœ¨æœ€ç®€å•çš„æƒ…å†µä¸‹ï¼Œè¿™å¯ä»¥é€šè¿‡ä»æ•°æ®é›†ä¸­æŒ‡å®šçš„ç›®æ ‡è¾“å‡ºä¸­å‡å»è¾“å‡ºå±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»æ¥è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although, in our example, increasing the set of neighbors from 1 to 3 removed the noise issue, k = 3 does not work for every dataset.",
            "zh": "å°½ç®¡åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œå°†é‚»å±…é›†ä» 1 å¢åŠ åˆ° 3 æ¶ˆé™¤äº†å™ªå£°é—®é¢˜ï¼Œä½† k = 3 å¹¶ä¸é€‚ç”¨äºæ¯ä¸ªæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "These features are strongly negatively covariant.",
            "zh": "è¿™äº›ç‰¹å¾å…·æœ‰å¾ˆå¼ºçš„è´Ÿåå˜æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "normalized mutual information, 611",
            "zh": "è§„èŒƒåŒ–äº’ä¿¡æ¯ï¼Œ611"
        }
    },
    {
        "translation": {
            "en": "Table 5.11",
            "zh": "è¡¨ 5.11"
        }
    },
    {
        "translation": {
            "en": "8. Full details of the Galaxy Zoo project and the data released by it are described in Lintott et al. (2008, 2011). The Galaxy Zoo (www.galaxyzoo.org) project referred to in this example is Galaxy Zoo I.",
            "zh": "8. Lintott et al. ï¼ˆ2008ï¼Œ 2011ï¼‰ æè¿°äº†é“¶æ²³åŠ¨ç‰©å›­é¡¹ç›®åŠå…¶å‘å¸ƒçš„æ•°æ®çš„å…¨éƒ¨ç»†èŠ‚ã€‚æ­¤ç¤ºä¾‹ä¸­æåˆ°çš„ Galaxy Zoo ï¼ˆwww.galaxyzoo.orgï¼‰ é¡¹ç›®æ˜¯ Galaxy Zoo Iã€‚"
        }
    },
    {
        "translation": {
            "en": "In this extended context, an experiment involves rolling the two dice, and the sample space defines the set of all possible outcomes for this experiment (see Figure B.1[757]).",
            "zh": "åœ¨è¿™ä¸ªæ‰©å±•çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œä¸€ä¸ªå®éªŒæ¶‰åŠæ·ä¸¤ä¸ªéª°å­ï¼Œæ ·æœ¬ç©ºé—´å®šä¹‰äº†è¯¥å®éªŒçš„æ‰€æœ‰å¯èƒ½ç»“æœçš„é›†åˆï¼ˆè§å›¾B.1[757]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hubble, E. 1936. The realm of the nebulÃ¦. Yale University Press.",
            "zh": "å“ˆå‹ƒï¼ŒE. 1936 å¹´ã€‚æ˜Ÿäº‘çš„é¢†åŸŸã€‚è€¶é²å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Splitting 7 creates two new partitions (10 and 11).",
            "zh": "æ‹†åˆ† 7 ä¼šåˆ›å»ºä¸¤ä¸ªæ–°åˆ†åŒºï¼ˆ10 å’Œ 11ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this is the case, then the error should be corrected, and the ABT should be regenerated.",
            "zh": "å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œåˆ™åº”çº æ­£é”™è¯¯ï¼Œå¹¶é‡æ–°ç”Ÿæˆ ABTã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.10",
            "zh": "è¡¨ 4.10"
        }
    },
    {
        "translation": {
            "en": "MacKay, David J. C. 2003. Information theory, inference and learning algorithms. Cambridge University Press.",
            "zh": "éº¦å‡¯ï¼Œå¤§å« JC 2003 å¹´ã€‚ä¿¡æ¯è®ºã€æ¨ç†å’Œå­¦ä¹ ç®—æ³•ã€‚å‰‘æ¡¥å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "All these courses include Chapter 1 (Machine Learning for Predictive Data Analytics) and Chapter 14 (The Art of Machine Learning for Predictive Data Analytics).",
            "zh": "æ‰€æœ‰è¿™äº›è¯¾ç¨‹éƒ½åŒ…æ‹¬ç¬¬ 1 ç« ï¼ˆé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ ï¼‰å’Œç¬¬ 14 ç« ï¼ˆé¢„æµ‹æ•°æ®åˆ†æçš„æœºå™¨å­¦ä¹ è‰ºæœ¯ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the slope of the line is 0.62 and the y-intercept is 6.47.",
            "zh": "å…¶ä¸­ï¼Œç›´çº¿çš„æ–œç‡ä¸º 0.62ï¼Œy æˆªè·ä¸º 6.47ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.50",
            "zh": "0.50"
        }
    },
    {
        "translation": {
            "en": "Also, as Figure 8.10 illustrates, as layers are added to a network, neurons in subsequent layers are able to use the representations learned by the preceding layer as building blocks to construct more complex functions.",
            "zh": "æ­¤å¤–ï¼Œå¦‚å›¾ 8.10 æ‰€ç¤ºï¼Œéšç€å±‚è¢«æ·»åŠ åˆ°ç½‘ç»œä¸­ï¼Œåç»­å±‚ä¸­çš„ç¥ç»å…ƒèƒ½å¤Ÿä½¿ç”¨å‰ä¸€å±‚å­¦ä¹ çš„è¡¨ç¤ºä½œä¸ºæ„å»ºå—æ¥æ„å»ºæ›´å¤æ‚çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "So far we have discussed and used the Minkowski-based Euclidean and Manhattan distance metrics to compute the similarity between instances in a dataset. There are, however, many other ways in which the similarity between instances can be measured. In this section we introduce some alternative measures of similarity and discuss when it is appropriate to use them. Any of these measures of similarity can simply replace the Euclidean measure we used in our demonstrations of the nearest neighbor algorithm.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºå¹¶ä½¿ç”¨åŸºäºé—µå¯å¤«æ–¯åŸºçš„æ¬§å‡ é‡Œå¾—å’Œæ›¼å“ˆé¡¿è·ç¦»åº¦é‡æ¥è®¡ç®—æ•°æ®é›†ä¸­å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ç„¶è€Œï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–æ–¹æ³•å¯ä»¥è¡¡é‡å®ä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›æ›¿ä»£çš„ç›¸ä¼¼åº¦é‡ï¼Œå¹¶è®¨è®ºä½•æ—¶é€‚åˆä½¿ç”¨å®ƒä»¬ã€‚è¿™äº›ç›¸ä¼¼åº¦é‡ä¸­çš„ä»»ä½•ä¸€ä¸ªéƒ½å¯ä»¥ç®€å•åœ°æ›¿æ¢æˆ‘ä»¬åœ¨æ¼”ç¤ºæœ€è¿‘é‚»ç®—æ³•æ—¶ä½¿ç”¨çš„æ¬§å‡ é‡Œå¾—åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This type of probability, where we take one or more events to already hold, is known as a posterior probability, because it is calculated after other events have happened.",
            "zh": "è¿™ç§ç±»å‹çš„æ¦‚ç‡ï¼Œå³æˆ‘ä»¬å‡è®¾ä¸€ä¸ªæˆ–å¤šä¸ªäº‹ä»¶å·²ç»æˆç«‹ï¼Œè¢«ç§°ä¸ºåéªŒæ¦‚ç‡ï¼Œå› ä¸ºå®ƒæ˜¯åœ¨å…¶ä»–äº‹ä»¶å‘ç”Ÿåè®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) What value will this network output?",
            "zh": "ï¼ˆç”²ï¼‰è¿™ä¸ªç½‘ç»œèƒ½è¾“å‡ºä»€ä¹ˆä»·å€¼ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D., and Simon Dobnik. 2017. What is not where: The challenge of integrating spatial representations into deep learning architectures. In Proceedings of the conference on logic and machine learning in natural language (LaML 17). Vol. 1 of Clasp papers in computational linguistics, 41â€“52.",
            "zh": "å‡¯è±èµ«ã€çº¦ç¿° D. å’Œè¥¿è’™Â·å¤šå¸ƒå°¼å…‹ã€‚2017. What is not whereï¼šå°†ç©ºé—´è¡¨ç¤ºé›†æˆåˆ°æ·±åº¦å­¦ä¹ æ¶æ„ä¸­çš„æŒ‘æˆ˜ã€‚åœ¨è‡ªç„¶è¯­è¨€é€»è¾‘å’Œæœºå™¨å­¦ä¹ ä¼šè®®è®ºæ–‡é›† ï¼ˆLaML 17ï¼‰ ä¸­ã€‚è®¡ç®—è¯­è¨€å­¦ Clasp è®ºæ–‡ç¬¬ 1 å·ï¼Œç¬¬ 41-52 é¡µã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an important detail of model deployment that is sometimes overlooked, which can lead to strange model performance.",
            "zh": "è¿™æ˜¯æ¨¡å‹éƒ¨ç½²çš„ä¸€ä¸ªé‡è¦ç»†èŠ‚ï¼Œæœ‰æ—¶ä¼šè¢«å¿½è§†ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´å¥‡æ€ªçš„æ¨¡å‹æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "CPI, 294",
            "zh": "æ¶ˆè´¹è€…ç‰©ä»·æŒ‡æ•°ï¼Œ 294"
        }
    },
    {
        "translation": {
            "en": "It would also be necessary to be able to connect these claims back to the policies to which they belong and to the application details provided when the member first applied.",
            "zh": "è¿˜å¿…é¡»èƒ½å¤Ÿå°†è¿™äº›ç´¢èµ”ä¸å®ƒä»¬æ‰€å±çš„ä¿å•ä»¥åŠæˆå‘˜é¦–æ¬¡ç”³è¯·æ—¶æä¾›çš„ç”³è¯·è¯¦ç»†ä¿¡æ¯è”ç³»èµ·æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The performance measures used for classification problems described in Chapter 9[533] can be used for thisâ€”for example, the F1 measure is commonly used.",
            "zh": "ç¬¬ 9 ç« [533] ä¸­æè¿°çš„ç”¨äºåˆ†ç±»é—®é¢˜çš„æ€§èƒ½åº¦é‡å¯ç”¨äºæ­¤ç›®çš„ï¼Œä¾‹å¦‚ï¼Œé€šå¸¸ä½¿ç”¨ F1 åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.18",
            "zh": "å›¾ 8.18"
        }
    },
    {
        "translation": {
            "en": "-0.6600",
            "zh": "-0.6600"
        }
    },
    {
        "translation": {
            "en": "1.81Â°C",
            "zh": "1.81Â°æ‘„æ°åº¦"
        }
    },
    {
        "translation": {
            "en": "There are other, more complex approaches to imputation. For example, we can actually build a predictive model that estimates a replacement for a missing value based on the feature values that are present in a dataset for a given instance. We recommend, however, using simple approaches first and turning to more complex ones only if required.",
            "zh": "è¿˜æœ‰å…¶ä»–æ›´å¤æ‚çš„å½’å› æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥æ„å»ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ ¹æ®ç»™å®šå®ä¾‹çš„æ•°æ®é›†ä¸­å­˜åœ¨çš„ç‰¹å¾å€¼æ¥ä¼°è®¡ç¼ºå¤±å€¼çš„æ›¿æ¢å€¼ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å»ºè®®é¦–å…ˆä½¿ç”¨ç®€å•çš„æ–¹æ³•ï¼Œåªæœ‰åœ¨éœ€è¦æ—¶æ‰ä½¿ç”¨æ›´å¤æ‚çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "This model can be trained using gradient descent to find the optimal decision boundary between the two different types of images.",
            "zh": "å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥è®­ç»ƒè¯¥æ¨¡å‹ï¼Œä»¥æ‰¾åˆ°ä¸¤ç§ä¸åŒç±»å‹çš„å›¾åƒä¹‹é—´çš„æœ€ä½³å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Using the support vector âŸ¨d[1], d[2]âŸ© and the query instance âŸ¨q[1], q[2]âŸ© as examples, show that applying a polynomial kernel with p = 2, kernel(d,q) = (d Â· q + 1)2, is equivalent to calculating the dot product of the support vector and query instance after applying the following set of basis functions:",
            "zh": "ï¼ˆaï¼‰ ä»¥æ”¯æŒå‘é‡ âŸ¨d[1]ã€d[2]âŸ© å’ŒæŸ¥è¯¢å®ä¾‹ âŸ¨q[1]ï¼Œ q[2]âŸ©ä¸ºä¾‹ï¼Œè¡¨æ˜åº”ç”¨ p = 2ï¼Œ kernelï¼ˆdï¼Œqï¼‰ = ï¼ˆd Â· q + 1ï¼‰2 çš„å¤šé¡¹å¼æ ¸ï¼Œç­‰ä»·äºåº”ç”¨ä»¥ä¸‹ä¸€ç»„åŸºå‡½æ•°åè®¡ç®—æ”¯æŒå‘é‡å’ŒæŸ¥è¯¢å®ä¾‹çš„ç‚¹ç§¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "At Line 14[666] the agent selects the first action25 using the Îµ-greedy policy.",
            "zh": "åœ¨ç¬¬ 14 è¡Œ[666]ï¼Œä»£ç†ä½¿ç”¨Îµè´ªå©ªç­–ç•¥é€‰æ‹©ç¬¬ä¸€ä¸ªæ“ä½œ25ã€‚"
        }
    },
    {
        "translation": {
            "en": "This progress comes at a cost, however, as all this data must be labeled, tagged, and cataloged.",
            "zh": "ç„¶è€Œï¼Œè¿™ä¸€è¿›å±•æ˜¯æœ‰ä»£ä»·çš„ï¼Œå› ä¸ºæ‰€æœ‰è¿™äº›æ•°æ®éƒ½å¿…é¡»è¿›è¡Œæ ‡è®°ã€æ ‡è®°å’Œç¼–ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The bias term is also updated in the same way that any other weight would be updated.",
            "zh": "åå·®é¡¹çš„æ›´æ–°æ–¹å¼ä¹Ÿä¸ä»»ä½•å…¶ä»–æƒé‡çš„æ›´æ–°æ–¹å¼ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "11. In Chapter 7[311] we discussed dropping the minus sign from the front of âˆ’d[j]; compare Equation (7.15)[326] with Equation (7.16)[327].",
            "zh": "11. åœ¨ç¬¬ 7 ç« [311]ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä» âˆ’d[j] å‰é¢å»æ‰å‡å·;æ¯”è¾ƒç­‰å¼ï¼ˆ7.15ï¼‰[326]å’Œç­‰å¼ï¼ˆ7.16ï¼‰[327]ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.1â€…â€…â€…The basic structure of an analytics base tableâ€”descriptive features and a target feature.",
            "zh": "2.1 åˆ†æåŸºè¡¨çš„åŸºæœ¬ç»“æ„ â€” æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "To try to capture the HANDSET INFORMATION domain concept, Ross designed three descriptive features:",
            "zh": "ä¸ºäº†å°è¯•æ•æ‰HANDSET INFORMATIONé¢†åŸŸçš„æ¦‚å¿µï¼ŒRossè®¾è®¡äº†ä¸‰ä¸ªæè¿°æ€§ç‰¹å¾ï¼š"
        }
    },
    {
        "translation": {
            "en": "(a) The k-d tree generated for the dataset in Table 5.4[191] after the initial split using the SPEED feature with a threshold of 4.5; (b) the partitioning of the feature space by the k-d tree in (a); (c) the k-d tree after the dataset at the left child of the root has been split using the AGILITY feature with a threshold of 5.5; and (d) the partitioning of the feature space by the k-d tree in (c).",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨é˜ˆå€¼ä¸º4.5çš„SPEEDç‰¹å¾è¿›è¡Œåˆå§‹æ‹†åˆ†åï¼Œä¸ºè¡¨5.4[191]ä¸­çš„æ•°æ®é›†ç”Ÿæˆçš„k-dæ ‘;ï¼ˆbï¼‰åœ¨ï¼ˆaï¼‰ä¸­ç”¨k-dæ ‘å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ’åˆ†;ï¼ˆcï¼‰ ä½¿ç”¨é˜ˆå€¼ä¸º 5.5 çš„æ•æ·ç‰¹å¾æ‹†åˆ†æ ¹å·¦ä¾§å­é¡¹æ•°æ®é›†åçš„ k-d æ ‘;ï¼ˆdï¼‰åœ¨ï¼ˆcï¼‰ä¸­ç”¨k-dæ ‘å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "For a detailed discussion of the issues associated with evaluating models for categorical prediction problems (and model evaluation in general), Japkowicz and Shah (2011) is excellent.",
            "zh": "å¯¹äºä¸è¯„ä¼°åˆ†ç±»é¢„æµ‹é—®é¢˜æ¨¡å‹ï¼ˆä»¥åŠä¸€èˆ¬æ¨¡å‹è¯„ä¼°ï¼‰ç›¸å…³çš„é—®é¢˜çš„è¯¦ç»†è®¨è®ºï¼ŒJapkowicz å’Œ Shah ï¼ˆ2011ï¼‰ éå¸¸å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "ill-posed problem, 7, 10, 19, 21, 22, 145",
            "zh": "ç—…æ€é—®é¢˜ï¼Œ 7ï¼Œ 10ï¼Œ 19ï¼Œ 21ï¼Œ 22ï¼Œ 145"
        }
    },
    {
        "translation": {
            "en": "The median of a set of values can be calculated by ordering the values from lowest to highest and selecting the middle value.",
            "zh": "ä¸€ç»„å€¼çš„ä¸­ä½æ•°å¯ä»¥é€šè¿‡å°†å€¼ä»ä½åˆ°é«˜æ’åºå¹¶é€‰æ‹©ä¸­é—´å€¼æ¥è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Given that the decision boundary is generated by aggregating the Voronoi regions, it is not surprising that the query is on the side of the decision boundary representing the yes target level.",
            "zh": "é‰´äºå†³ç­–è¾¹ç•Œæ˜¯é€šè¿‡èšåˆ Voronoi åŒºåŸŸç”Ÿæˆçš„ï¼Œå› æ­¤æŸ¥è¯¢ä½äºè¡¨ç¤ºâ€œæ˜¯â€ç›®æ ‡çº§åˆ«çš„å†³ç­–è¾¹ç•Œä¸€ä¾§ä¹Ÿå°±ä¸è¶³ä¸ºå¥‡äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.5â€…â€…â€…Summary",
            "zh": "6.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Reinforcement Learning",
            "zh": "å¼ºåŒ–å­¦ä¹ çš„ç¬¦å·çº¦å®š"
        }
    },
    {
        "translation": {
            "en": "(2017) for a computer architecture perspective on deep learning.",
            "zh": "ï¼ˆ2017ï¼‰ ä»è®¡ç®—æœºä½“ç³»ç»“æ„çš„è§’åº¦æ¥çœ‹æ·±åº¦å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Understanding how a neural network can be represented and implemented as a sequence of matrix multiplications has important implications in terms of training time speedups.",
            "zh": "äº†è§£å¦‚ä½•å°†ç¥ç»ç½‘ç»œè¡¨ç¤ºå’Œå®ç°ä¸ºçŸ©é˜µä¹˜æ³•åºåˆ—ï¼Œåœ¨è®­ç»ƒæ—¶é—´åŠ é€Ÿæ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œLive. Die. Repeat.â€",
            "zh": "â€œæ´»ç€ã€‚æ­»ã€‚é‡å¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figures 10.4(a)[606] and 10.4(b)[606], a very different seed from that shown in Figure 10.3(b)[602] is shown to lead to the same clustering found previously (Figure 10.3(f)[602]), whereas in Figures 10.4(a)[606] to 10.4(h)[606], seeds that lead to very different clusterings are shown.",
            "zh": "åœ¨å›¾10.4ï¼ˆaï¼‰[606]å’Œ10.4ï¼ˆbï¼‰[606]ä¸­ï¼Œä¸å›¾10.3ï¼ˆbï¼‰[602]æ‰€ç¤ºçš„ç§å­æˆªç„¶ä¸åŒçš„ç§å­è¢«æ˜¾ç¤ºä¸ºå¯¼è‡´å…ˆå‰å‘ç°çš„ç›¸åŒç°‡ï¼ˆå›¾10.3ï¼ˆfï¼‰[602]ï¼‰ï¼Œè€Œåœ¨å›¾10.4ï¼ˆaï¼‰[606]è‡³10.4ï¼ˆhï¼‰[606]ä¸­ï¼Œæ˜¾ç¤ºäº†å¯¼è‡´éå¸¸ä¸åŒçš„ç°‡çš„ç§å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3â€…â€…â€…Details of the first two iterations when the gradient descent algorithm is used to train a multivariable linear regression model for the office rentals dataset (using only the continuous descriptive features).",
            "zh": "7.3 å½“ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•è®­ç»ƒåŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹ï¼ˆä»…ä½¿ç”¨è¿ç»­æè¿°æ€§ç‰¹å¾ï¼‰æ—¶ï¼Œå‰ä¸¤æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "This plot shows that the reduction in the error achieved by each weight update (one per epoch) is initially quite small.",
            "zh": "è¯¥å›¾æ˜¾ç¤ºï¼Œæ¯æ¬¡æƒé‡æ›´æ–°ï¼ˆæ¯ä¸ªå‘¨æœŸä¸€æ¬¡ï¼‰å®ç°çš„è¯¯å·®å‡å°‘æœ€åˆéå¸¸å°ã€‚"
        }
    },
    {
        "translation": {
            "en": "domain representation, 732",
            "zh": "åŸŸè¡¨ç¤ºï¼Œ732"
        }
    },
    {
        "translation": {
            "en": "This matrix contains two neurons that are fully connected to the sub-sampling layer; that is, each neuron in this layer receives inputs from all the neurons in the sub-sampling layer.",
            "zh": "è¯¥çŸ©é˜µåŒ…å«ä¸¤ä¸ªå®Œå…¨è¿æ¥åˆ°å­é‡‡æ ·å±‚çš„ç¥ç»å…ƒ;ä¹Ÿå°±æ˜¯è¯´ï¼Œè¯¥å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½æ¥æ”¶æ¥è‡ªå­é‡‡æ ·å±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Table 0.1 we have listed a number of suggested course plans targeting different contexts.",
            "zh": "åœ¨è¡¨0.1ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†ä¸€äº›é’ˆå¯¹ä¸åŒæƒ…å†µçš„å»ºè®®è¯¾ç¨‹è®¡åˆ’ã€‚"
        }
    },
    {
        "translation": {
            "en": "The AlexNet architecture included five convolutional layers, followed by three fully connected (dense) layers.",
            "zh": "AlexNet æ¶æ„åŒ…æ‹¬äº”ä¸ªå·ç§¯å±‚ï¼Œç„¶åæ˜¯ä¸‰ä¸ªå®Œå…¨è¿æ¥ï¼ˆå¯†é›†ï¼‰å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vector of activations for a layer of neurons is denoted by a(k) where k identifies the layer.",
            "zh": "ç¥ç»å…ƒå±‚çš„æ¿€æ´»å‘é‡ç”¨ aï¼ˆkï¼‰ è¡¨ç¤ºï¼Œå…¶ä¸­ k æ ‡è¯†è¯¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.",
            "zh": "ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚æœªç»å‡ºç‰ˆå•†ä¹¦é¢è®¸å¯ï¼Œä¸å¾—ä»¥ä»»ä½•ç”µå­æˆ–æœºæ¢°æ–¹å¼ï¼ˆåŒ…æ‹¬å½±å°ã€å½•éŸ³æˆ–ä¿¡æ¯å­˜å‚¨å’Œæ£€ç´¢ï¼‰ä»¥ä»»ä½•å½¢å¼å¤åˆ¶æœ¬ä¹¦çš„ä»»ä½•éƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Initially the analyst uses a simple average of the target variables for the k nearest neighbors in order to make a new prediction. After experimenting with values for k in the range 0âˆ’10, it occurs to the analyst that they might get very good results if they set k to the total number of instances in the training set. Do you think that the analyst is likely to get good results using this value for k?",
            "zh": "ï¼ˆaï¼‰ æœ€åˆï¼Œåˆ†æäººå‘˜å¯¹kä¸ªæœ€è¿‘é‚»ä½¿ç”¨ç›®æ ‡å˜é‡çš„ç®€å•å¹³å‡å€¼ï¼Œä»¥ä¾¿åšå‡ºæ–°çš„é¢„æµ‹ã€‚åœ¨å¯¹ 0âˆ’10 èŒƒå›´å†…çš„ k å€¼è¿›è¡Œè¯•éªŒåï¼Œåˆ†æå¸ˆä¼šæƒ³åˆ°ï¼Œå¦‚æœä»–ä»¬å°† k è®¾ç½®ä¸ºè®­ç»ƒé›†ä¸­çš„å®ä¾‹æ€»æ•°ï¼Œä»–ä»¬å¯èƒ½ä¼šå¾—åˆ°éå¸¸å¥½çš„ç»“æœã€‚æ‚¨è®¤ä¸ºåˆ†æå¸ˆä½¿ç”¨æ­¤å€¼ k å¯èƒ½ä¼šè·å¾—è‰¯å¥½çš„ç»“æœå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "subspace sampling, 159",
            "zh": "å­ç©ºé—´é‡‡æ ·ï¼Œ159"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(a)[60] shows a histogram exhibiting a uniform distribution. A uniform distribution indicates that a feature is equally likely to take a value in any of the ranges present. Sometimes a uniform distribution is indicative of a descriptive feature that contains an ID rather than a measure of something more interesting.",
            "zh": "å›¾3.2ï¼ˆaï¼‰[60]æ˜¾ç¤ºäº†ä¸€ä¸ªå‘ˆç°å‡åŒ€åˆ†å¸ƒçš„ç›´æ–¹å›¾ã€‚å‡åŒ€åˆ†å¸ƒè¡¨ç¤ºè¦ç´ åœ¨å­˜åœ¨çš„ä»»ä½•èŒƒå›´å†…å–å€¼çš„å¯èƒ½æ€§ç›¸åŒã€‚æœ‰æ—¶ï¼Œå‡åŒ€åˆ†å¸ƒè¡¨ç¤ºåŒ…å« ID çš„æè¿°æ€§ç‰¹å¾ï¼Œè€Œä¸æ˜¯å¯¹æ›´æœ‰è¶£çš„äº‹ç‰©çš„åº¦é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.3â€ƒStandard Approach: The ID3 Algorithm",
            "zh": "4.3 æ ‡å‡†æ–¹æ³•ï¼šID3 ç®—æ³•"
        }
    },
    {
        "translation": {
            "en": "Bayesâ€™ Theorem4 is so elegant and intuitive that it can be stated in one sentence of plain English:",
            "zh": "è´å¶æ–¯å®šç†4æ˜¯å¦‚æ­¤ä¼˜é›…å’Œç›´è§‚ï¼Œå¯ä»¥ç”¨ä¸€å¥é€šä¿—æ˜“æ‡‚çš„è‹±è¯­æ¥è¡¨è¿°ï¼š"
        }
    },
    {
        "translation": {
            "en": "In mini-batch gradient descent, the dataset is split into multiple subsets called mini-batches or batches.15",
            "zh": "åœ¨å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ä¸­ï¼Œæ•°æ®é›†è¢«æ‹†åˆ†ä¸ºå¤šä¸ªå­é›†ï¼Œç§°ä¸ºå°æ‰¹é‡æˆ–æ‰¹æ¬¡15ã€‚"
        }
    },
    {
        "translation": {
            "en": "Line 9[420] is the matrix multiplication of the layerâ€™s weights by the activations from the preceding layer.",
            "zh": "ç¬¬ 9 è¡Œ[420] æ˜¯å±‚æƒé‡ä¹˜ä»¥å‰ä¸€å±‚æ¿€æ´»çš„çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "depth of a filter, 492",
            "zh": "è¿‡æ»¤å™¨æ·±åº¦ï¼Œ492"
        }
    },
    {
        "translation": {
            "en": "Intuitively, this theorem makes sense because each algorithm encodes a distinct set of assumptions (i.e., the inductive bias of the learning algorithm), and a set of assumptions that are appropriate in one domain may not be appropriate in another domain.",
            "zh": "ç›´è§‚åœ°è¯´ï¼Œè¿™ä¸ªå®šç†æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºæ¯ä¸ªç®—æ³•éƒ½ç¼–ç äº†ä¸€ç»„ä¸åŒçš„å‡è®¾ï¼ˆå³å­¦ä¹ ç®—æ³•çš„å½’çº³åå·®ï¼‰ï¼Œè€Œä¸€ç»„åœ¨ä¸€ä¸ªé¢†åŸŸä¸­é€‚ç”¨çš„å‡è®¾å¯èƒ½ä¸é€‚åˆåœ¨å¦ä¸€ä¸ªé¢†åŸŸä¸­é€‚ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, as shown in Figure 7.10(b)[340], we can draw a straight line across the scatter plot that perfectly separates the good generators from the faulty ones.",
            "zh": "äº‹å®ä¸Šï¼Œå¦‚å›¾ 7.10ï¼ˆbï¼‰[340] æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ•£ç‚¹å›¾ä¸Šç”»ä¸€æ¡ç›´çº¿ï¼Œå®Œç¾åœ°å°†å¥½çš„å‘ç”µæœºå’Œæœ‰æ•…éšœçš„å‘ç”µæœºåŒºåˆ†å¼€æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the conditional probability of a node xi in a graph with n nodes can be defined as",
            "zh": "å› æ­¤ï¼Œåœ¨å…·æœ‰ n ä¸ªèŠ‚ç‚¹çš„å›¾ä¸­ï¼ŒèŠ‚ç‚¹ ä¹  çš„æ¡ä»¶æ¦‚ç‡å¯ä»¥å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "So, when we choose to use one machine learning algorithm instead of another, we are, in effect, choosing to use one model selection criterion instead of another.",
            "zh": "å› æ­¤ï¼Œå½“æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨ä¸€ç§æœºå™¨å­¦ä¹ ç®—æ³•è€Œä¸æ˜¯å¦ä¸€ç§æœºå™¨å­¦ä¹ ç®—æ³•æ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨é€‰æ‹©ä½¿ç”¨ä¸€ç§æ¨¡å‹é€‰æ‹©æ ‡å‡†è€Œä¸æ˜¯å¦ä¸€ç§æ¨¡å‹é€‰æ‹©æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The partial derivatives of the error surface with respect to w[0] and w[1] measure the slope of the error surface at the point w[0] and w[1].",
            "zh": "è¯¯å·®æ›²é¢ç›¸å¯¹äº w[0] å’Œ w[1] çš„åå¯¼æ•°æµ‹é‡è¯¯å·®æ›²é¢åœ¨ç‚¹ w[0] å’Œ w[1] å¤„çš„æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the 3-level target feature as her initial focus, Jocelyn began to look at the different descriptive features in the data downloaded from the SDSS repository that might be useful in building a model to predict galaxy morphology.",
            "zh": "Jocelyn ä»¥ 3 çº§ç›®æ ‡ç‰¹å¾ä¸ºåˆå§‹å…³æ³¨ç‚¹ï¼Œå¼€å§‹ç ”ç©¶ä» SDSS å­˜å‚¨åº“ä¸‹è½½çš„æ•°æ®ä¸­çš„ä¸åŒæè¿°æ€§ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯èƒ½æœ‰åŠ©äºæ„å»ºé¢„æµ‹æ˜Ÿç³»å½¢æ€çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similar to the input gate, the output gate has two paths of processing, one involving a sigmoid layer and the other involving a tanh layer.",
            "zh": "ä¸è¾“å…¥é—¨ç±»ä¼¼ï¼Œè¾“å‡ºé—¨æœ‰ä¸¤æ¡å¤„ç†è·¯å¾„ï¼Œä¸€æ¡æ¶‰åŠ S å½¢å›¾å±‚ï¼Œå¦ä¸€æ¡æ¶‰åŠ tanh å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "GENDER: The customerâ€™s gender (male or female)",
            "zh": "æ€§åˆ«ï¼šå®¢æˆ·çš„æ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Frank, Eibe. 2000. Pruning decision trees and lists. PhD dissertation, Department of Computer Science, University of Waikato.",
            "zh": "å¼—å…°å…‹ï¼Œè‰¾è´ã€‚2000. ä¿®å‰ªå†³ç­–æ ‘å’Œåˆ—è¡¨ã€‚æ€€å¡æ‰˜å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»åšå£«è®ºæ–‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A more realistic example of the complexity and scale of a modern convolutional network is the AlexNet network (Krizhevsky et al., 2012).",
            "zh": "ç°ä»£å·ç§¯ç½‘ç»œçš„å¤æ‚æ€§å’Œè§„æ¨¡çš„ä¸€ä¸ªæ›´ç°å®çš„ä¾‹å­æ˜¯AlexNetç½‘ç»œï¼ˆKrizhevskyç­‰äººï¼Œ2012ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This version of the algorithm is for mini-batch training, and so we know that we will need to sum the error gradients for each weight across the examples in the mini-batch.",
            "zh": "æ­¤ç‰ˆæœ¬çš„ç®—æ³•ç”¨äºå°æ‰¹é‡è®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬éœ€è¦å¯¹å°æ‰¹é‡ä¸­ç¤ºä¾‹ä¸­æ¯ä¸ªæƒé‡çš„è¯¯å·®æ¢¯åº¦æ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, how can we judge whether a drug dosage prediction model that has a root mean squared error of 1.38mg is actually making accurate predictions without also understanding the domain of drug dosage prediction.",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¦‚ä½•åˆ¤æ–­ä¸€ä¸ªå‡æ–¹æ ¹è¯¯å·®ä¸º1.38mgçš„è¯ç‰©å‰‚é‡é¢„æµ‹æ¨¡å‹æ˜¯å¦çœŸçš„åœ¨ä¸äº†è§£è¯ç‰©å‰‚é‡é¢„æµ‹é¢†åŸŸçš„æƒ…å†µä¸‹åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.22(f)[167] shows the model output after 20 iterations of model training have been completed.",
            "zh": "å›¾ 4.22ï¼ˆfï¼‰[167] æ˜¾ç¤ºäº†å®Œæˆ 20 æ¬¡æ¨¡å‹è®­ç»ƒè¿­ä»£åçš„æ¨¡å‹è¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "standard deviation, 54, 748",
            "zh": "æ ‡å‡†å·®ï¼Œ 54ï¼Œ 748"
        }
    },
    {
        "translation": {
            "en": "Also assuming that each weight wi is independent of the corresponding input di, then variance of each of these products is given:35",
            "zh": "æ­¤å¤–ï¼Œå‡è®¾æ¯ä¸ªæƒé‡ wi ä¸ç›¸åº”çš„è¾“å…¥ di æ— å…³ï¼Œåˆ™ç»™å‡ºæ¯ä¸ªä¹˜ç§¯çš„æ–¹å·®ï¼š35"
        }
    },
    {
        "translation": {
            "en": "5. We use Q here to be consistent with the framing of Q-learning later in this chapter.",
            "zh": "5. æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ Q æ˜¯ä¸ºäº†ä¸æœ¬ç« åé¢çš„ Q å­¦ä¹ æ¡†æ¶ä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have not covered artificial neural networks, another popular error-based approach to learning that is a very active research area.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä»‹ç»äººå·¥ç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯å¦ä¸€ç§æµè¡Œçš„åŸºäºé”™è¯¯çš„å­¦ä¹ æ–¹æ³•ï¼Œæ˜¯ä¸€ä¸ªéå¸¸æ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "The lesson to be learned here is that before causation is concluded based on a strong correlation between two features, in-depth studies involving domain experts are requiredâ€”correlation alone is just not enough.",
            "zh": "è¿™é‡Œè¦å¸å–çš„æ•™è®­æ˜¯ï¼Œåœ¨åŸºäºä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„å¼ºç›¸å…³æ€§å¾—å‡ºå› æœå…³ç³»ä¹‹å‰ï¼Œéœ€è¦æ¶‰åŠé¢†åŸŸä¸“å®¶çš„æ·±å…¥ç ”ç©¶â€”â€”ä»…é ç›¸å…³æ€§æ˜¯ä¸å¤Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The margin of error takes into account the fact that this is just a sample from a much larger population.5 All the other polls in the table were conducted with similar-sized samples.",
            "zh": "5 è¡¨ä¸­çš„æ‰€æœ‰å…¶ä»–æ°‘æ„è°ƒæŸ¥éƒ½æ˜¯ç”¨ç±»ä¼¼å¤§å°çš„æ ·æœ¬è¿›è¡Œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each day is described in terms of six descriptive features that are generated from different sensors at the plant.",
            "zh": "æ¯ä¸€å¤©éƒ½ç”¨å·¥å‚ä¸åŒä¼ æ„Ÿå™¨ç”Ÿæˆçš„å…­ä¸ªæè¿°æ€§ç‰¹å¾æ¥æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Based on the evaluation measures calculated, which model do you think is performing better for this dataset?",
            "zh": "ï¼ˆbï¼‰ æ ¹æ®è®¡ç®—å‡ºçš„è¯„ä¼°æªæ–½ï¼Œæ‚¨è®¤ä¸ºå“ªä¸ªæ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸­è¡¨ç°æ›´å¥½ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "5.19â€…â€…â€…Feature subset space for a dataset with three features X, Y, and Z.",
            "zh": "5.19 å…·æœ‰ä¸‰ä¸ªç‰¹å¾ Xã€Y å’Œ Z çš„æ•°æ®é›†çš„ç‰¹å¾å­é›†ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "This defines one point on the error surface.",
            "zh": "è¿™åœ¨é”™è¯¯æ›²é¢ä¸Šå®šä¹‰äº†ä¸€ä¸ªç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dietterich, Thomas G. 2000. Ensemble methods in machine learning. In International workshop on multiple classifier systems, 1â€“15. Springer.",
            "zh": "è¿ªç‰¹é‡Œå¸Œï¼Œæ‰˜é©¬æ–¯ G. 2000 å¹´ã€‚æœºå™¨å­¦ä¹ ä¸­çš„é›†æˆæ–¹æ³•ã€‚åœ¨å¤šåˆ†ç±»å™¨ç³»ç»Ÿå›½é™…ç ”è®¨ä¼šä¸Šï¼Œ1-15ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that the update applied to a weight wi,k is always scaled by the ak term (both in the stochastic setting, Equation (8.28)[415], and the batch setting, Equation (8.29)[416]).",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œåº”ç”¨äºæƒé‡ wiï¼Œk çš„æ›´æ–°å§‹ç»ˆæŒ‰ ak é¡¹ç¼©æ”¾ï¼ˆåœ¨éšæœºè®¾ç½®ä¸­ï¼Œæ–¹ç¨‹ ï¼ˆ8.28ï¼‰[415] å’Œæ‰¹å¤„ç†è®¾ç½®ï¼Œæ–¹ç¨‹ ï¼ˆ8.29ï¼‰[416]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using Equation (B.4)[762], we can provide a second definition for the probability of a joint event, which is known as the product rule:",
            "zh": "ä½¿ç”¨æ–¹ç¨‹ï¼ˆB.4ï¼‰[762]ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºè”åˆäº‹ä»¶çš„æ¦‚ç‡æä¾›ç¬¬äºŒä¸ªå®šä¹‰ï¼Œå³ä¹˜ç§¯è§„åˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "6.10â€…â€…â€…A depiction of the Markov blanket of a node. The gray nodes define the Markov blanket of the black node. The black node is conditionally independent of the white nodes given the state of the gray nodes.",
            "zh": "6.10 èŠ‚ç‚¹é©¬å°”å¯å¤«æ¯¯çš„æè¿°ã€‚ç°è‰²èŠ‚ç‚¹å®šä¹‰é»‘è‰²èŠ‚ç‚¹çš„é©¬å°”å¯å¤«æ¯¯ã€‚ç»™å®šç°è‰²èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œé»‘è‰²èŠ‚ç‚¹æœ‰æ¡ä»¶åœ°ç‹¬ç«‹äºç™½è‰²èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we are using stochastic gradient descent, in which we update the weights after each example has been presented to the network, then to update a weight in the network we first calculate a âˆ‚â„°/âˆ‚wi,k term for the weight similarly to the calculations shown in Table 8.6[431] for d2 and then plug the âˆ‚â„°/âˆ‚wi,k value for the weight into Equation (8.28)[415].",
            "zh": "å¦‚æœæˆ‘ä»¬ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼Œåœ¨å°†æ¯ä¸ªç¤ºä¾‹å‘ˆç°ç»™ç½‘ç»œåæ›´æ–°æƒé‡ï¼Œé‚£ä¹ˆè¦æ›´æ–°ç½‘ç»œä¸­çš„æƒé‡ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—æƒé‡çš„ âˆ‚E/âˆ‚wiï¼Œk é¡¹ï¼Œç±»ä¼¼äºè¡¨ 8.6[431] ä¸­æ‰€ç¤ºçš„ d2 çš„è®¡ç®—ï¼Œç„¶åæ’å…¥ âˆ‚E/âˆ‚wiï¼Œæ–¹ç¨‹ï¼ˆ8.28ï¼‰[415]ä¸­æƒé‡çš„kå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Judea Pearl is recognized as one of the key pioneers in developing the use of Bayesian networks in the field of artificial intelligence, and his books (Pearl, 1988, 2000) are accessible and provide good introductions to the theory and methods of Bayesian networks, as well as the more general field of graphical models.",
            "zh": "Judea Pearlè¢«å…¬è®¤ä¸ºåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¼€å‘è´å¶æ–¯ç½‘ç»œä½¿ç”¨çš„ä¸»è¦å…ˆé©±ä¹‹ä¸€ï¼Œä»–çš„è‘—ä½œï¼ˆPearlï¼Œ1988,2000ï¼‰æ˜“äºè®¿é—®ï¼Œå¹¶å¾ˆå¥½åœ°ä»‹ç»äº†è´å¶æ–¯ç½‘ç»œçš„ç†è®ºå’Œæ–¹æ³•ï¼Œä»¥åŠæ›´ä¸€èˆ¬çš„å›¾å½¢æ¨¡å‹é¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Following this strategy, for a fully connected three-layer ReLU network with 100 inputs, 80 neurons in the first hidden layer, 50 neurons in the second hidden layer, and 5 neurons in the output layer, the weight matrix for each layer would be initialized as shown in Equation (8.64)[461], where the notation W(k) âˆ½ (Î¼,Ïƒ) indicates that the values in the weight matrix for layer k should be sampled from a normal distribution with mean Î¼ and standard deviation Ïƒ.",
            "zh": "æŒ‰ç…§è¿™ç§ç­–ç•¥ï¼Œå¯¹äºå…·æœ‰ 100 ä¸ªè¾“å…¥ã€ç¬¬ä¸€éšè—å±‚æœ‰ 80 ä¸ªç¥ç»å…ƒã€ç¬¬äºŒéšè—å±‚æœ‰ 50 ä¸ªç¥ç»å…ƒã€è¾“å‡ºå±‚æœ‰ 5 ä¸ªç¥ç»å…ƒçš„å…¨è¿æ¥ä¸‰å±‚ ReLU ç½‘ç»œï¼Œæ¯å±‚çš„æƒé‡çŸ©é˜µå°†åˆå§‹åŒ–ï¼Œå¦‚å…¬å¼ ï¼ˆ8.64ï¼‰[461] æ‰€ç¤ºï¼Œå…¶ä¸­ç¬¦å· Wï¼ˆkï¼‰ âˆ½ ï¼ˆÎ¼ï¼ŒÏƒï¼‰ è¡¨ç¤ºå±‚ k çš„æƒé‡çŸ©é˜µä¸­çš„å€¼åº”ä»å‡å€¼Î¼å’Œæ ‡å‡†å·®Ïƒçš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The terms sensitivity and specificity are often used for true positive rate and true negative rate.",
            "zh": "5. æœ¯è¯­æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§é€šå¸¸ç”¨äºçœŸé˜³æ€§ç‡å’ŒçœŸé˜´æ€§ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the query instances shown in the following table.",
            "zh": "ä½¿ç”¨æ­¤æ¨¡å‹å¯¹ä¸‹è¡¨ä¸­æ˜¾ç¤ºçš„æ¯ä¸ªæŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The location of the query customer in the feature space is indicated by the ?.",
            "zh": "æŸ¥è¯¢å®¢æˆ·åœ¨åŠŸèƒ½ç©ºé—´ä¸­çš„ä½ç½®ç”± ï¼Ÿ."
        }
    },
    {
        "translation": {
            "en": "It is only in very rare scenarios that we can accurately fill in a profit matrix for a prediction problem.",
            "zh": "åªæœ‰åœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ‰èƒ½å‡†ç¡®åœ°å¡«å……é¢„æµ‹é—®é¢˜çš„åˆ©æ¶¦çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "11â€…â€…â€…Beyond Prediction: Reinforcement Learning",
            "zh": "11 è¶…è¶Šé¢„æµ‹ï¼šå¼ºåŒ–å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Figure 7.1",
            "zh": "å›¾ 7.1"
        }
    },
    {
        "translation": {
            "en": "The arrows connecting the neurons in the network indicate the flow of information through the network.",
            "zh": "è¿æ¥ç½‘ç»œä¸­ç¥ç»å…ƒçš„ç®­å¤´è¡¨ç¤ºé€šè¿‡ç½‘ç»œçš„ä¿¡æ¯æµã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the particular choice of which variant of ReLU to use is network- and task-dependent, and, similarly to most hyper-parameters, needs to be decided upon through experimentation.",
            "zh": "ç„¶è€Œï¼Œä½¿ç”¨å“ªç§ ReLU å˜ä½“çš„ç‰¹å®šé€‰æ‹©å–å†³äºç½‘ç»œå’Œä»»åŠ¡ï¼Œå¹¶ä¸”ä¸å¤§å¤šæ•°è¶…å‚æ•°ç±»ä¼¼ï¼Œéœ€è¦é€šè¿‡å®éªŒæ¥å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "We can introduce a preference for decision trees that use fewer testsâ€”in other words, trees that are on average shallower.2 This is the primary inductive bias that a machine learning algorithm taking an information-based approach encodes.",
            "zh": "æˆ‘ä»¬å¯ä»¥å¼•å…¥å¯¹ä½¿ç”¨è¾ƒå°‘æµ‹è¯•çš„å†³ç­–æ ‘çš„åå¥½ï¼Œæ¢å¥è¯è¯´ï¼Œå¹³å‡è€Œè¨€ï¼Œæ ‘çš„ä¼˜å…ˆçº§è¾ƒä½.2 è¿™æ˜¯é‡‡ç”¨åŸºäºä¿¡æ¯çš„æ–¹æ³•çš„æœºå™¨å­¦ä¹ ç®—æ³•ç¼–ç çš„ä¸»è¦å½’çº³åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Spectrography also allows measurement of redshift, which is used to determine the distance of night sky objects from the viewer.",
            "zh": "å…‰è°±å­¦è¿˜å¯ä»¥æµ‹é‡çº¢ç§»ï¼Œçº¢ç§»ç”¨äºç¡®å®šå¤œç©ºç‰©ä½“ä¸è§‚å¯Ÿè€…çš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reduced error pruning, a decision tree is built to completion and then the tree is searched in an iterative, bottom-up, left-to-right manner for subtrees that can be pruned.",
            "zh": "åœ¨å‡å°‘è¯¯å·®ä¿®å‰ªä¸­ï¼Œæ„å»ºå†³ç­–æ ‘ç›´è‡³å®Œæˆï¼Œç„¶åä»¥è¿­ä»£ã€è‡ªä¸‹è€Œä¸Šã€ä»å·¦åˆ°å³çš„æ–¹å¼æœç´¢è¯¥æ ‘ä»¥æŸ¥æ‰¾å¯ä¿®å‰ªçš„å­æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we use a PDF to represent the probability distribution of a descriptive feature in a naive Bayes model, however, we donâ€™t actually need to calculate exact probabilities.",
            "zh": "ç„¶è€Œï¼Œå½“æˆ‘ä»¬ä½¿ç”¨ PDF æ¥è¡¨ç¤ºæœ´ç´ è´å¶æ–¯æ¨¡å‹ä¸­æè¿°æ€§ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒæ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¹¶ä¸éœ€è¦è®¡ç®—ç²¾ç¡®çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.3729",
            "zh": "0.3729"
        }
    },
    {
        "translation": {
            "en": "13. One consequence of this, however, is that a naive Bayes model is not a good approach for predicting a continuous target, because errors in calculating posterior probabilities do directly affect the accuracy of the model. This is the only modeling approach covered in this book for which we will not present a way to predict both continuous and categorical target features.",
            "zh": "13. ç„¶è€Œï¼Œè¿™æ ·åšçš„ä¸€ä¸ªåæœæ˜¯ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹ä¸æ˜¯é¢„æµ‹è¿ç»­ç›®æ ‡çš„å¥½æ–¹æ³•ï¼Œå› ä¸ºè®¡ç®—åéªŒæ¦‚ç‡æ—¶çš„é”™è¯¯ç¡®å®ç›´æ¥å½±å“æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚è¿™æ˜¯æœ¬ä¹¦ä¸­ä»‹ç»çš„å”¯ä¸€å»ºæ¨¡æ–¹æ³•ï¼Œæˆ‘ä»¬ä¸ä¼šä»‹ç»ä¸€ç§é¢„æµ‹è¿ç»­å’Œåˆ†ç±»ç›®æ ‡ç‰¹å¾çš„æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that when we train a decision tree from data, we do not assume a fixed set of parameters prior to training that define the tree.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œå½“æˆ‘ä»¬ä»æ•°æ®è®­ç»ƒå†³ç­–æ ‘æ—¶ï¼Œæˆ‘ä»¬ä¸ä¼šåœ¨è®­ç»ƒä¹‹å‰å‡è®¾ä¸€ç»„å›ºå®šçš„å‚æ•°æ¥å®šä¹‰å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "The architecture of an auto-encoder network made up of an encoder and a decoder connected by a bottleneck layer.",
            "zh": "ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆçš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œçš„ä½“ç³»ç»“æ„ï¼Œé€šè¿‡ç“¶é¢ˆå±‚è¿æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The illustration in Figure 8.33[484] assumes that the neurons are using a two-dimensional 3-by-3 (height by width) filter.",
            "zh": "å›¾ 8.33[484] ä¸­çš„æ’å›¾å‡è®¾ç¥ç»å…ƒä½¿ç”¨äºŒç»´ 3Ã—3ï¼ˆé«˜å®½ï¼‰æ»¤æ³¢å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basis of most of these approaches is measuring how well the distributions of scores produced by the model for different target levels are separated.",
            "zh": "å¤§å¤šæ•°è¿™äº›æ–¹æ³•çš„åŸºç¡€æ˜¯æµ‹é‡æ¨¡å‹ä¸ºä¸åŒç›®æ ‡æ°´å¹³ç”Ÿæˆçš„åˆ†æ•°åˆ†å¸ƒçš„åˆ†ç¦»ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The vector v, created on Line 7[420], is the vector of bias inputs, and it is as wide as the number of neurons in the layer (we use the subscript m here as shorthand for the number of neurons in the layer).",
            "zh": "åœ¨ç¬¬ 7 è¡Œ[420]ä¸Šåˆ›å»ºçš„å‘é‡ v æ˜¯åç½®è¾“å…¥çš„å‘é‡ï¼Œå®ƒä¸å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡ä¸€æ ·å®½ï¼ˆæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ä¸‹æ ‡ m ä½œä¸ºå±‚ä¸­ç¥ç»å…ƒæ•°é‡çš„ç®€å†™ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "He did explain, however, that Jocelynâ€™s suggestion of using position information was very unlikely to be useful, so that was removed from the set of domain concepts.",
            "zh": "ç„¶è€Œï¼Œä»–ç¡®å®è§£é‡Šè¯´ï¼ŒJocelyn å…³äºä½¿ç”¨ä½ç½®ä¿¡æ¯çš„å»ºè®®ä¸å¤ªå¯èƒ½æœ‰ç”¨ï¼Œå› æ­¤å°†å…¶ä»é¢†åŸŸæ¦‚å¿µé›†ä¸­åˆ é™¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "next-best-offer model, 37",
            "zh": "æ¬¡ä¼˜æŠ¥ä»·æ¨¡å‹ï¼Œ37"
        }
    },
    {
        "translation": {
            "en": "This implementation works on a layer-by-layer basis.",
            "zh": "æ­¤å®ç°æ˜¯é€å±‚å·¥ä½œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A wrapper evaluates a feature subset in terms of the potential performance of the models that can be induced using that subset.",
            "zh": "åŒ…è£…å™¨æ ¹æ®å¯ä»¥ä½¿ç”¨è¯¥å­é›†è¯±å¯¼çš„æ¨¡å‹çš„æ½œåœ¨æ€§èƒ½æ¥è¯„ä¼°ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Domain concepts cover the different aspects of a scenario that are likely to be important in the modeling task at hand.",
            "zh": "é¢†åŸŸæ¦‚å¿µæ¶µç›–äº†æ–¹æ¡ˆçš„ä¸åŒæ–¹é¢ï¼Œè¿™äº›æ–¹é¢åœ¨æ‰‹å¤´çš„å»ºæ¨¡ä»»åŠ¡ä¸­å¯èƒ½å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Through conversations with Edwin, Jocelyn became aware of a parallel project to the SDSS that offered an intriguing solution to her problem.",
            "zh": "é€šè¿‡ä¸ Edwin çš„å¯¹è¯ï¼ŒJocelyn æ„è¯†åˆ°ä¸€ä¸ªä¸ SDSS å¹³è¡Œçš„é¡¹ç›®ä¸ºå¥¹çš„é—®é¢˜æä¾›äº†ä¸€ä¸ªæœ‰è¶£çš„è§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Feature map 3 and Feature map 4 contain the activations of the neurons in each of these two layers.",
            "zh": "ç‰¹å¾å›¾ 3 å’Œç‰¹å¾å›¾ 4 åŒ…å«è¿™ä¸¤å±‚ä¸­æ¯ä¸€å±‚ä¸­ç¥ç»å…ƒçš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. In a fully connected network, all the neurons in one layer receive activations from all the neurons in the preceding layer; and, because all the neurons in a layer receive the same vector of activations as inputs, we can calculate the weighted sum calculations for all of these neurons using a single vector by matrix multiplication.",
            "zh": "1.åœ¨å…¨è¿æ¥ç½‘ç»œä¸­ï¼Œä¸€å±‚ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½æ¥æ”¶æ¥è‡ªå‰ä¸€å±‚ä¸­æ‰€æœ‰ç¥ç»å…ƒçš„æ¿€æ´»;è€Œä¸”ï¼Œç”±äºä¸€å±‚ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½æ¥æ”¶åˆ°ä¸è¾“å…¥ç›¸åŒçš„æ¿€æ´»å‘é‡ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çŸ©é˜µä¹˜æ³•çš„å•ä¸ªå‘é‡æ¥è®¡ç®—æ‰€æœ‰è¿™äº›ç¥ç»å…ƒçš„åŠ æƒå’Œè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Spreading out the weight updates means that the weight will in general remain smaller.",
            "zh": "åˆ†æ•£é‡é‡æ›´æ–°æ„å‘³ç€é‡é‡é€šå¸¸å°†ä¿æŒè¾ƒå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is likely that the data required for this solution would stretch back over many years, as the time between making a policy application and making a claim could cover decades.",
            "zh": "è¯¥è§£å†³æ–¹æ¡ˆæ‰€éœ€çš„æ•°æ®å¯èƒ½ä¼šè¿½æº¯åˆ°å¾ˆå¤šå¹´å‰ï¼Œå› ä¸ºä»æå‡ºä¿å•ç”³è¯·åˆ°æå‡ºç´¢èµ”ä¹‹é—´çš„æ—¶é—´å¯èƒ½é•¿è¾¾æ•°åå¹´ã€‚"
        }
    },
    {
        "translation": {
            "en": "From this plot, it is clear that there is a strong linear relationship between these two features: as SIZE increases so does RENTAL PRICE by a similar amount.",
            "zh": "ä»è¿™å¼ å›¾ä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œè¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„çº¿æ€§å…³ç³»ï¼šéšç€ SIZE çš„å¢åŠ ï¼ŒRENTAL PRICE ä¹Ÿä¼šå¢åŠ ç›¸ä¼¼çš„é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.15â€…â€…â€…(a) A set of instances on a continuous number line; (b), (c), and (d) depict some of the potential groupings that could be applied to these instances.",
            "zh": "4.15 ï¼ˆaï¼‰ è¿ç»­æ•°çº¿ä¸Šçš„ä¸€ç»„å®ä¾‹;ï¼ˆbï¼‰ã€ï¼ˆcï¼‰å’Œï¼ˆdï¼‰æè¿°äº†å¯ä»¥åº”ç”¨äºè¿™äº›å®ä¾‹çš„ä¸€äº›æ½œåœ¨åˆ†ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9. In this section we have primarily considered the population we are sampling from to be a population of people, but sampling bias can also arise for any population of predictive subjects, be they insurance policies, holidays, cars, or anything else.",
            "zh": "9. åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å°†æˆ‘ä»¬ä»ä¸­æŠ½æ ·çš„äººç¾¤è§†ä¸ºäººç¾¤ï¼Œä½†å¯¹äºä»»ä½•é¢„æµ‹å¯¹è±¡äººç¾¤ï¼Œæ— è®ºæ˜¯ä¿é™©å•ã€å‡æœŸã€æ±½è½¦è¿˜æ˜¯å…¶ä»–ä»»ä½•ä¸œè¥¿ï¼Œéƒ½å¯èƒ½å‡ºç°æŠ½æ ·åå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "24. Note that as with the worked example, to keep the number of decimal points required to represent the calculations through this forward pass manageable, the outputs of the activation function (in this instance the rectified linear function) for each layer have been rounded to four decimal places, and these rounded activations were the activations used in the subsequent calculations.",
            "zh": "24. è¯·æ³¨æ„ï¼Œä¸å·¥ä½œç¤ºä¾‹ä¸€æ ·ï¼Œä¸ºäº†ä¿æŒé€šè¿‡æ­¤å‰å‘ä¼ é€’è¡¨ç¤ºè®¡ç®—æ‰€éœ€çš„å°æ•°ç‚¹æ•°å¯ç®¡ç†ï¼Œæ¯å±‚çš„æ¿€æ´»å‡½æ•°ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæ ¡æ­£çº¿æ€§å‡½æ•°ï¼‰çš„è¾“å‡ºå·²å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åå››ä½ï¼Œè¿™äº›å››èˆäº”å…¥çš„æ¿€æ´»æ˜¯åç»­è®¡ç®—ä¸­ä½¿ç”¨çš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is due to the use of the squared term in the mean squared error calculation but can easily be addressed by using root mean squared error instead.",
            "zh": "è¿™æ˜¯ç”±äºåœ¨å‡æ–¹è¯¯å·®è®¡ç®—ä¸­ä½¿ç”¨äº†å¹³æ–¹é¡¹ï¼Œä½†å¯ä»¥é€šè¿‡ä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®è½»æ¾è§£å†³ã€‚"
        }
    },
    {
        "translation": {
            "en": "On completion of each action the agent receives an immediate scalar reward indicating whether the outcome of the action was positive or negative and to what degree.",
            "zh": "å®Œæˆæ¯ä¸ªæ“ä½œåï¼Œæ™ºèƒ½ä½“ä¼šç«‹å³æ”¶åˆ°æ ‡é‡å¥–åŠ±ï¼ŒæŒ‡ç¤ºæ“ä½œçš„ç»“æœæ˜¯ç§¯æçš„è¿˜æ˜¯æ¶ˆæçš„ï¼Œä»¥åŠç¨‹åº¦å¦‚ä½•ã€‚"
        }
    },
    {
        "translation": {
            "en": "As new instances are added to the feature space, the size of the modelâ€™s representation of the domain increases.",
            "zh": "éšç€æ–°å®ä¾‹æ·»åŠ åˆ°ç‰¹å¾ç©ºé—´ä¸­ï¼Œæ¨¡å‹è¡¨ç¤ºåŸŸçš„å¤§å°ä¹Ÿä¼šå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplest form of data visualization we can use for data exploration is the bar plot.",
            "zh": "æˆ‘ä»¬å¯ç”¨äºæ•°æ®æ¢ç´¢çš„æœ€ç®€å•çš„æ•°æ®å¯è§†åŒ–å½¢å¼æ˜¯æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "5. The table below shows the scores achieved by a group of students on an exam.",
            "zh": "5. ä¸‹è¡¨æ˜¾ç¤ºäº†ä¸€ç»„å­¦ç”Ÿåœ¨è€ƒè¯•ä¸­å–å¾—çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.12â€…â€…â€…Two different Bayesian networks, each defining the same full joint probability distribution.",
            "zh": "6.12 ä¸¤ä¸ªä¸åŒçš„è´å¶æ–¯ç½‘ç»œï¼Œæ¯ä¸ªç½‘ç»œéƒ½å®šä¹‰äº†ç›¸åŒçš„å…¨è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the best-known distance metrics is Euclidean distance, which computes the length of the straight line between two points. Euclidean distance between two instances a and b in an m-dimensional feature space is defined as",
            "zh": "æœ€è‘—åçš„è·ç¦»æŒ‡æ ‡ä¹‹ä¸€æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œå®ƒè®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„ç›´çº¿é•¿åº¦ã€‚åœ¨ m ç»´ç‰¹å¾ç©ºé—´ä¸­ï¼Œä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "This multivariable model allows us to include all but one of the descriptive features in Table 7.2[317] in a regression model to predict office rental prices (we will see how to include the categorical ENERGY RATING in the model in Section 7.4.3[336]). The resulting multivariable regression model equation is",
            "zh": "è¿™ä¸ªå¤šå˜é‡æ¨¡å‹å…è®¸æˆ‘ä»¬åœ¨å›å½’æ¨¡å‹ä¸­åŒ…æ‹¬è¡¨7.2[317]ä¸­é™¤ä¸€ä¸ªæè¿°æ€§ç‰¹å¾ä¹‹å¤–çš„æ‰€æœ‰æè¿°æ€§ç‰¹å¾ï¼Œä»¥é¢„æµ‹åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼ï¼ˆæˆ‘ä»¬å°†åœ¨ç¬¬7.4.3èŠ‚[336]ä¸­çœ‹åˆ°å¦‚ä½•åœ¨æ¨¡å‹ä¸­åŒ…å«åˆ†ç±»èƒ½æºè¯„çº§ï¼‰ã€‚å¾—åˆ°çš„å¤šå˜é‡å›å½’æ¨¡å‹æ–¹ç¨‹ä¸º"
        }
    },
    {
        "translation": {
            "en": "In this histogram the width of each bar indicates the extent of the interval the bar represents, and the height of each bar is based on the number of instances in the dataset that have a value inside the interval.",
            "zh": "åœ¨æ­¤ç›´æ–¹å›¾ä¸­ï¼Œæ¯ä¸ªæ¡å½¢çš„å®½åº¦è¡¨ç¤ºæ¡å½¢æ‰€è¡¨ç¤ºçš„åŒºé—´èŒƒå›´ï¼Œæ¯ä¸ªæ¡å½¢çš„é«˜åº¦åŸºäºæ•°æ®é›†ä¸­åœ¨åŒºé—´å†…å…·æœ‰å€¼çš„å®ä¾‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The instance nearest the decision boundary, based on perpendicular distance, is highlighted.",
            "zh": "åŸºäºå‚ç›´è·ç¦»ï¼Œå°†çªå‡ºæ˜¾ç¤ºæœ€æ¥è¿‘å†³ç­–è¾¹ç•Œçš„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "All machine learning algorithms assume that a dataset is available for training; and in Chapter 3 we explain how to design, construct, and quality check a dataset before using it to build a prediction model.",
            "zh": "æ‰€æœ‰æœºå™¨å­¦ä¹ ç®—æ³•éƒ½å‡è®¾æ•°æ®é›†å¯ç”¨äºè®­ç»ƒ;åœ¨ç¬¬ 3 ç« ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šäº†å¦‚ä½•åœ¨ä½¿ç”¨æ•°æ®é›†æ„å»ºé¢„æµ‹æ¨¡å‹ä¹‹å‰å¯¹å…¶è¿›è¡Œè®¾è®¡ã€æ„å»ºå’Œè´¨é‡æ£€æŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) P(HEADACHE = false)",
            "zh": "ï¼ˆbï¼‰ Pï¼ˆå¤´ç—› = å‡ï¼‰"
        }
    },
    {
        "translation": {
            "en": "BILLAMOUNTCHANGEPCT: Derived from the raw call data, this feature captured the amount by which a customerâ€™s bill had changed that month compared to previous month.",
            "zh": "BILLAMOUNTCHANGEPCTï¼šæ­¤åŠŸèƒ½æºè‡ªåŸå§‹å‘¼å«æ•°æ®ï¼Œæ•è·äº†å®¢æˆ·å½“æœˆè´¦å•ä¸ä¸Šä¸ªæœˆç›¸æ¯”çš„å˜åŒ–é‡‘é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "; NUMBER OF CLAIMS IN CLAIMANT LIFETIME: NUM.",
            "zh": ";ç´¢èµ”äººç”Ÿå‘½å‘¨æœŸå†…çš„ç´¢èµ”æ•°é‡ï¼šæ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Wooldridge, Michael, and Nicholas R. Jennings. 1995. Intelligent agents: Theory and practice. The Knowledge Engineering Review 10 (2): 115â€“152.",
            "zh": "ä¼å°”å¾·é‡Œå¥‡ã€è¿ˆå…‹å°”å’Œå°¼å¤æ‹‰æ–¯ R. è©¹å®æ–¯ã€‚1995. æ™ºèƒ½ä»£ç†ï¼šç†è®ºä¸å®è·µ.çŸ¥è¯†å·¥ç¨‹è¯„è®º10ï¼ˆ2ï¼‰ï¼š115-152ã€‚"
        }
    },
    {
        "translation": {
            "en": "First, the signs of the weights indicate whether different descriptive features have a positive or a negative impact on the prediction.",
            "zh": "é¦–å…ˆï¼Œæƒé‡çš„ç¬¦å·è¡¨æ˜ä¸åŒçš„æè¿°æ€§ç‰¹å¾å¯¹é¢„æµ‹æœ‰ç§¯æå½±å“è¿˜æ˜¯æ¶ˆæå½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "The error rate resulting from predictions for the instances in the validation dataset made at the root node of each subtree is compared to the error rate resulting from predictions made at the leaves of the subtree.",
            "zh": "å°†éªŒè¯æ•°æ®é›†ä¸­åœ¨æ¯ä¸ªå­æ ‘çš„æ ¹èŠ‚ç‚¹ä¸Šè¿›è¡Œçš„å®ä¾‹é¢„æµ‹äº§ç”Ÿçš„é”™è¯¯ç‡ä¸åœ¨å­æ ‘å¶ä¸Šè¿›è¡Œçš„é¢„æµ‹äº§ç”Ÿçš„é”™è¯¯ç‡è¿›è¡Œæ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "12.1â€…â€…â€…The set of domain concepts for the Acme Telephonica customer churn prediction problem.",
            "zh": "12.1 Acme Telephonica å®¢æˆ·æµå¤±é¢„æµ‹é—®é¢˜çš„åŸŸæ¦‚å¿µé›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For long sequences of inputs it can become cumbersome and also computationally expensive to keep track of all the error gradients for all the different weights in the unrolled network.",
            "zh": "å¯¹äºé•¿åºåˆ—çš„è¾“å…¥ï¼Œè·Ÿè¸ªå±•å¼€ç½‘ç»œä¸­æ‰€æœ‰ä¸åŒæƒé‡çš„æ‰€æœ‰è¯¯å·®æ¢¯åº¦å¯èƒ½ä¼šå˜å¾—å¾ˆéº»çƒ¦ï¼Œè€Œä¸”è®¡ç®—æˆæœ¬ä¹Ÿå¾ˆé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "and for the Stick action the structure of the state transition matrix, ğ’«Stick, is",
            "zh": "å¯¹äº Stick æ“ä½œï¼ŒçŠ¶æ€è½¬æ¢çŸ©é˜µ PStick çš„ç»“æ„ä¸º"
        }
    },
    {
        "translation": {
            "en": "For example, the predictions made by decision tree models are based on the subset of descriptive features tested on the path from the root of the tree to the leaf node that specifies the prediction.",
            "zh": "ä¾‹å¦‚ï¼Œå†³ç­–æ ‘æ¨¡å‹æ‰€åšçš„é¢„æµ‹åŸºäºåœ¨ä»æ ‘æ ¹åˆ°æŒ‡å®šé¢„æµ‹çš„å¶èŠ‚ç‚¹çš„è·¯å¾„ä¸Šæµ‹è¯•çš„æè¿°æ€§ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the probability of actually having the disease, in spite of the positive test result, is less than 1%. This is why the doctor said the rarity of the disease was such good news. One of the important characteristics of Bayesâ€™ Theorem is its explicit inclusion of the prior probability of an event when calculating the likelihood of that event based on evidence.6",
            "zh": "å› æ­¤ï¼Œå°½ç®¡æ£€æµ‹ç»“æœå‘ˆé˜³æ€§ï¼Œä½†å®é™…æ‚£ç—…çš„æ¦‚ç‡ä¸åˆ° 1%ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåŒ»ç”Ÿè¯´è¿™ç§ç–¾ç—…çš„ç½•è§æ€§æ˜¯ä¸ªå¥½æ¶ˆæ¯ã€‚è´å¶æ–¯å®šç†çš„ä¸€ä¸ªé‡è¦ç‰¹å¾æ˜¯ï¼Œåœ¨æ ¹æ®è¯æ®è®¡ç®—äº‹ä»¶çš„å¯èƒ½æ€§æ—¶ï¼Œå®ƒæ˜ç¡®åœ°åŒ…æ‹¬äº†äº‹ä»¶çš„å…ˆéªŒæ¦‚ç‡6ã€‚"
        }
    },
    {
        "translation": {
            "en": "An experiment whose outcome we do not yet know but would like to predict is the prediction task for which we are building a model.",
            "zh": "ä¸€ä¸ªæˆ‘ä»¬è¿˜ä¸çŸ¥é“ä½†æƒ³è¦é¢„æµ‹ç»“æœçš„å®éªŒæ˜¯æˆ‘ä»¬æ­£åœ¨æ„å»ºæ¨¡å‹çš„é¢„æµ‹ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.6.2â€ƒBackpropagation through timeâ€ƒThe fact that a recurrent neural network is fundamentally an augmented feedforward network means that training a network using backpropagation is quite similar to training a normal feedforward network.",
            "zh": "8.4.6.2 éšæ—¶é—´çš„åå‘ä¼ æ’­ å¾ªç¯ç¥ç»ç½‘ç»œä»æ ¹æœ¬ä¸Šè¯´æ˜¯ä¸€ä¸ªå¢å¼ºçš„å‰é¦ˆç½‘ç»œï¼Œè¿™æ„å‘³ç€ä½¿ç”¨åå‘ä¼ æ’­è®­ç»ƒç½‘ç»œä¸è®­ç»ƒæ­£å¸¸çš„å‰é¦ˆç½‘ç»œéå¸¸ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is important for Conor to have a good meal each evening so that he is ready for work again the next day, and he is worried about getting things he doesnâ€™t like in the hotel restaurant.",
            "zh": "å¯¹äºåº·çº³æ¥è¯´ï¼Œæ¯å¤©æ™šä¸Šåƒä¸€é¡¿å¥½é¥­å¾ˆé‡è¦ï¼Œè¿™æ ·ä»–å°±å¯ä»¥ä¸ºç¬¬äºŒå¤©çš„å·¥ä½œåšå¥½å‡†å¤‡ï¼Œè€Œä¸”ä»–æ‹…å¿ƒåœ¨é…’åº—é¤å…é‡Œä¹°åˆ°ä»–ä¸å–œæ¬¢çš„ä¸œè¥¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The total error of the network is then the sum of these individual errors.",
            "zh": "ç½‘ç»œçš„æ€»è¯¯å·®å°±æ˜¯è¿™äº›å•ä¸ªè¯¯å·®çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "SHAPEUNIFORMITY: A measure of the variation in shape of cells in the tissue samples, higher values indicate more uniform shapes (1 to 10).",
            "zh": "å½¢çŠ¶å‡åŒ€æ€§ï¼šç»„ç»‡æ ·æœ¬ä¸­ç»†èƒå½¢çŠ¶å˜åŒ–çš„é‡åº¦ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºå½¢çŠ¶è¶Šå‡åŒ€ï¼ˆ1 åˆ° 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where LCE is the cross-entropy loss; t is the target feature represented using one-hot encoding (the target distribution over the categories); is the distribution over the categories that the model has predicted; ln is the natural logarithm function; and j is an index over both the target distribution t and the predicted distribution .",
            "zh": "å…¶ä¸­LCEæ˜¯äº¤å‰ç†µæŸå¤±;t æ˜¯ä½¿ç”¨ one-hot ç¼–ç è¡¨ç¤ºçš„ç›®æ ‡ç‰¹å¾ï¼ˆç±»åˆ«ä¸Šçš„ç›®æ ‡åˆ†å¸ƒï¼‰;æ˜¯æ¨¡å‹é¢„æµ‹çš„ç±»åˆ«çš„åˆ†å¸ƒæƒ…å†µ;ln æ˜¯è‡ªç„¶å¯¹æ•°å‡½æ•°;j æ˜¯ç›®æ ‡åˆ†å¸ƒ t å’Œé¢„æµ‹åˆ†å¸ƒçš„ç´¢å¼•ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result of this multiplication for any neuron whose activation in the forward pass was set to 0 by the multiplication with DropMask, the Î´ value of the neuron will also be set to 0.",
            "zh": "å¯¹äºä»»ä½•ç¥ç»å…ƒçš„ä¹˜æ³•ï¼Œå…¶å‰å‘ä¼ é€’ä¸­çš„æ¿€æ´»é€šè¿‡ DropMask çš„ä¹˜æ³•è®¾ç½®ä¸º 0ï¼Œå› æ­¤ç¥ç»å…ƒçš„Î´å€¼ä¹Ÿå°†è®¾ç½®ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "A consequence of this is that the network has a memory over past activations (and hence past inputs that contributed to these activations).",
            "zh": "è¿™æ ·åšçš„ç»“æœæ˜¯ï¼Œç½‘ç»œå¯¹è¿‡å»çš„æ¿€æ´»ï¼ˆä»¥åŠå¯¼è‡´è¿™äº›æ¿€æ´»çš„è¿‡å»è¾“å…¥ï¼‰å…·æœ‰è®°å¿†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In contrast, acceleration has modest positive values when we are taking off initially and slightly larger positive values when we increase speed on reaching the highway.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œå½“æˆ‘ä»¬æœ€åˆèµ·é£æ—¶ï¼ŒåŠ é€Ÿåº¦å…·æœ‰é€‚åº¦çš„æ­£å€¼ï¼Œè€Œå½“æˆ‘ä»¬åœ¨åˆ°è¾¾é«˜é€Ÿå…¬è·¯æ—¶æé«˜é€Ÿåº¦æ—¶ï¼ŒåŠ é€Ÿåº¦çš„æ­£å€¼ç•¥å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Taking these factors into account helps to ensure that we develop analytics solutions that are effective and fit for purpose.",
            "zh": "è€ƒè™‘è¿™äº›å› ç´ æœ‰åŠ©äºç¡®ä¿æˆ‘ä»¬å¼€å‘æœ‰æ•ˆä¸”é€‚åˆç›®çš„çš„åˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "This gives multiple box plots that offer an easy comparison of how the central tendency and variation of the continuous feature change for the different levels of the categorical feature.",
            "zh": "è¿™ç»™å‡ºäº†å¤šä¸ªç®±å½¢å›¾ï¼Œè¿™äº›ç®±å½¢å›¾æä¾›äº†å¯¹è¿ç»­ç‰¹å¾çš„ä¸­å¿ƒè¶‹åŠ¿å’Œå˜åŒ–åœ¨åˆ†ç±»ç‰¹å¾çš„ä¸åŒæ°´å¹³ä¸‹å¦‚ä½•å˜åŒ–çš„ç®€å•æ¯”è¾ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of prediction models, there is always a tension between the need to fully understand the performance of the model and the need to reduce model performance to a single measure that can be used to rank models by performance.",
            "zh": "åœ¨è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½æ—¶ï¼Œåœ¨å……åˆ†äº†è§£æ¨¡å‹æ€§èƒ½çš„éœ€æ±‚ä¸å°†æ¨¡å‹æ€§èƒ½é™ä½åˆ°å¯ç”¨äºæŒ‰æ€§èƒ½å¯¹æ¨¡å‹è¿›è¡Œæ’åçš„å•ä¸€åº¦é‡ä¹‹é—´å§‹ç»ˆå­˜åœ¨ç´§å¼ å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Clearly, large portions of the yes region are now on the wrong side of the decision boundary.",
            "zh": "æ˜¾ç„¶ï¼Œâ€œæ˜¯â€åŒºåŸŸçš„å¾ˆå¤§ä¸€éƒ¨åˆ†ç°åœ¨éƒ½å¤„äºå†³ç­–è¾¹ç•Œçš„é”™è¯¯ä¸€ä¾§ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the Gini index for this dataset.",
            "zh": "ï¼ˆbï¼‰ è®¡ç®—è¯¥æ•°æ®é›†çš„åŸºå°¼ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is particularly attractive for problems in which automated systems are to be trained to perform a control taskâ€”for example, robotics or automated game playing.",
            "zh": "è¿™å¯¹äºéœ€è¦è®­ç»ƒè‡ªåŠ¨åŒ–ç³»ç»Ÿä»¥æ‰§è¡Œæ§åˆ¶ä»»åŠ¡çš„é—®é¢˜ç‰¹åˆ«æœ‰å¸å¼•åŠ›ï¼Œä¾‹å¦‚ï¼Œæœºå™¨äººæˆ–è‡ªåŠ¨æ¸¸æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "right skew, 59",
            "zh": "å³æ–œï¼Œ59"
        }
    },
    {
        "translation": {
            "en": "Even when using equal-frequency binning, there is still chance that the partitioning of the data will give rise to extreme conditional probabilities.",
            "zh": "å³ä½¿ä½¿ç”¨ç­‰é¢‘åˆ†ç®±ï¼Œæ•°æ®çš„åˆ†åŒºä»æœ‰å¯èƒ½äº§ç”Ÿæç«¯çš„æ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "We cover artificial neural networks and deep learning in detail in Chapter 8[381].",
            "zh": "æˆ‘ä»¬å°†åœ¨ç¬¬8ç« [381]ä¸­è¯¦ç»†ä»‹ç»äººå·¥ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "Technically, if an event involves more than one feature, it can be considered to be composed of several simple events.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œå¦‚æœä¸€ä¸ªäº‹ä»¶æ¶‰åŠå¤šä¸ªç‰¹å¾ï¼Œåˆ™å¯ä»¥è®¤ä¸ºå®ƒç”±å‡ ä¸ªç®€å•äº‹ä»¶ç»„æˆã€‚"
        }
    },
    {
        "translation": {
            "en": "A system was put in place in the SDSS processing pipeline to flag for manual review any galaxies given low probability predictions.",
            "zh": "åœ¨SDSSå¤„ç†ç®¡é“ä¸­å»ºç«‹äº†ä¸€ä¸ªç³»ç»Ÿï¼Œä»¥æ ‡è®°ä»»ä½•ç»™å®šä½æ¦‚ç‡é¢„æµ‹çš„æ˜Ÿç³»ä»¥ä¾›æ‰‹åŠ¨å®¡æŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customerâ€™s occupation",
            "zh": "å®¢æˆ·çš„èŒä¸š"
        }
    },
    {
        "translation": {
            "en": "The requirement that networks with a single hidden layer and using smooth activation functions have very wide hidden layers is a serious shortcoming: it may result in the requirement that the network has at least one hidden unit for each input configuration that is being distinguished (Goodfellow et al., 2016).",
            "zh": "è¦æ±‚å…·æœ‰å•ä¸ªéšè—å±‚å¹¶ä½¿ç”¨å¹³æ»‘æ¿€æ´»å‡½æ•°çš„ç½‘ç»œå…·æœ‰éå¸¸å®½çš„éšè—å±‚æ˜¯ä¸€ä¸ªä¸¥é‡çš„ç¼ºç‚¹ï¼šå®ƒå¯èƒ½å¯¼è‡´è¦æ±‚ç½‘ç»œå¯¹æ¯ä¸ªè¢«åŒºåˆ†çš„è¾“å…¥é…ç½®è‡³å°‘æœ‰ä¸€ä¸ªéšè—å•å…ƒï¼ˆGoodfellowç­‰äººï¼Œ2016ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "24,000",
            "zh": "24,000"
        }
    },
    {
        "translation": {
            "en": "The target feature, OUTCOME, is set to either default or repay.",
            "zh": "ç›®æ ‡åŠŸèƒ½ OUTCOME è®¾ç½®ä¸ºé»˜è®¤æˆ–å¿è¿˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "At this point we can expect the algorithm to have found the global minimum of the error surface and, as a result, the most accurate predictive model possible.",
            "zh": "åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸè¯¥ç®—æ³•å·²ç»æ‰¾åˆ°äº†è¯¯å·®é¢çš„å…¨å±€æœ€å°å€¼ï¼Œä»è€Œæ‰¾åˆ°äº†æœ€å‡†ç¡®çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "placebo, 584",
            "zh": "å®‰æ…°å‰‚ï¼Œ584"
        }
    },
    {
        "translation": {
            "en": "The way to solve this problem is by smoothing the probabilities used by the model. We know from the definition of probability that the sum of the probabilities of a feature taking each of its possible levels should equal 1.0:",
            "zh": "è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•æ˜¯å¯¹æ¨¡å‹ä½¿ç”¨çš„æ¦‚ç‡è¿›è¡Œå¹³æ»‘å¤„ç†ã€‚æˆ‘ä»¬ä»æ¦‚ç‡çš„å®šä¹‰ä¸­çŸ¥é“ï¼Œå–æ¯ä¸ªå¯èƒ½æ°´å¹³çš„ç‰¹å¾çš„æ¦‚ç‡ä¹‹å’Œåº”ç­‰äº 1.0ï¼š"
        }
    },
    {
        "translation": {
            "en": "Deep learning is currently attracting a huge amount of attention within the machine learning community.",
            "zh": "æ·±åº¦å­¦ä¹ ç›®å‰åœ¨æœºå™¨å­¦ä¹ ç¤¾åŒºä¸­å¼•èµ·äº†æå¤§çš„å…³æ³¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For Models 3 and 4, we need to go as far as 60% and 75% respectively.",
            "zh": "å¯¹äºæ¨¡å‹ 3 å’Œ 4ï¼Œæˆ‘ä»¬éœ€è¦åˆ†åˆ«è¾¾åˆ° 60% å’Œ 75%ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability has a longer history, and broader applicability, than predictive analytics. Consequently, the standard language of probability has developed some esoteric terminology, including terms such as sample space, experiment, outcome, event, and random variable. So we will begin by first explaining this terminology and aligning it with the more familiar terminology of predictive analytics.",
            "zh": "ä¸é¢„æµ‹åˆ†æç›¸æ¯”ï¼Œæ¦‚ç‡å…·æœ‰æ›´é•¿çš„å†å²å’Œæ›´å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚å› æ­¤ï¼Œæ¦‚ç‡çš„æ ‡å‡†è¯­è¨€å·²ç»å‘å±•å‡ºä¸€äº›æ·±å¥¥çš„æœ¯è¯­ï¼ŒåŒ…æ‹¬æ ·æœ¬ç©ºé—´ã€å®éªŒã€ç»“æœã€äº‹ä»¶å’Œéšæœºå˜é‡ç­‰æœ¯è¯­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†é¦–å…ˆè§£é‡Šè¿™ä¸ªæœ¯è¯­ï¼Œå¹¶å°†å…¶ä¸æ›´ç†Ÿæ‚‰çš„é¢„æµ‹åˆ†ææœ¯è¯­ä¿æŒä¸€è‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "These cluster assignments are also shown in the rightmost column of Table 10.1[604] (as cluster assignments did not change after the second iteration of the algorithm) in context with the original dataset. A set of cluster assignments is usually referred to as a clustering.",
            "zh": "è¿™äº›èšç±»åˆ†é…ä¹Ÿæ˜¾ç¤ºåœ¨è¡¨ 10.1[604] çš„æœ€å³è¾¹åˆ—ä¸­ï¼ˆå› ä¸ºèšç±»åˆ†é…åœ¨ç®—æ³•ç¬¬äºŒæ¬¡è¿­ä»£åæ²¡æœ‰æ›´æ”¹ï¼‰ä¸åŸå§‹æ•°æ®é›†çš„ä¸Šä¸‹æ–‡ä¸­ã€‚ä¸€ç»„èšç±»åˆ†é…é€šå¸¸ç§°ä¸ºèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "case-based reasoning, 234",
            "zh": "åŸºäºæ¡ˆä¾‹çš„æ¨ç†ï¼Œ234"
        }
    },
    {
        "translation": {
            "en": "1. Partitioning the feature space into regions based on clusters of training instances with the same target value, and assigning a query located in a region the target value of the cluster that defines that region.",
            "zh": "1. æ ¹æ®å…·æœ‰ç›¸åŒç›®æ ‡å€¼çš„è®­ç»ƒå®ä¾‹é›†ç¾¤å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸï¼Œå¹¶ä¸ºä½äºæŸä¸ªåŒºåŸŸçš„æŸ¥è¯¢åˆ†é…å®šä¹‰è¯¥åŒºåŸŸçš„é›†ç¾¤çš„ç›®æ ‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The original version of Xavier initialization considered both the forward activation through the network and the backward propagation of gradients, and so the calculation of the variance of the distribution from which the weights for a layer are sampled takes both the inputs to a layer nin(k) and the number of outputs from a layer nout(k) into account; it is calculated as follows:",
            "zh": "Xavier åˆå§‹åŒ–çš„åŸå§‹ç‰ˆæœ¬åŒæ—¶è€ƒè™‘äº†é€šè¿‡ç½‘ç»œçš„å‰å‘æ¿€æ´»å’Œæ¢¯åº¦çš„å‘åä¼ æ’­ï¼Œå› æ­¤ï¼Œä»ä¸­é‡‡æ ·å±‚æƒé‡çš„åˆ†å¸ƒæ–¹å·®çš„è®¡ç®—åŒæ—¶è€ƒè™‘äº†å±‚ ninï¼ˆkï¼‰ çš„è¾“å…¥å’Œå±‚ noutï¼ˆkï¼‰ çš„è¾“å‡ºæ•°é‡;è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "Figure 3.10",
            "zh": "å›¾ 3.10"
        }
    },
    {
        "translation": {
            "en": "This dominance of the distance computation by a feature based solely on the fact that it has a larger range of values than other features is not a good thing.",
            "zh": "ä»…åŸºäºç‰¹å¾å…·æœ‰æ¯”å…¶ä»–ç‰¹å¾æ›´å¤§çš„å€¼èŒƒå›´è¿™ä¸€äº‹å®æ¥ä¸»å¯¼è·ç¦»è®¡ç®—å¹¶ä¸æ˜¯ä¸€ä»¶å¥½äº‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "AdaBoost, 171",
            "zh": "AdaBoostï¼Œ171"
        }
    },
    {
        "translation": {
            "en": "Wisconsin breast cancer dataset, 109, 377",
            "zh": "å¨æ–¯åº·æ˜Ÿå·ä¹³è…ºç™Œæ•°æ®é›†ï¼Œ109,377"
        }
    },
    {
        "translation": {
            "en": "The first half of an auto-encoder, up to the output of the narrowest layer in the middle, is known as an encoder, and the second half of the network is known as a decoder.",
            "zh": "è‡ªåŠ¨ç¼–ç å™¨çš„å‰åŠéƒ¨åˆ†ï¼Œç›´åˆ°ä¸­é—´æœ€çª„å±‚çš„è¾“å‡ºï¼Œç§°ä¸ºç¼–ç å™¨ï¼Œç½‘ç»œçš„ååŠéƒ¨åˆ†ç§°ä¸ºè§£ç å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are now ready to take on Bayesâ€™ Theorem!",
            "zh": "æˆ‘ä»¬ç°åœ¨å·²ç»å‡†å¤‡å¥½æ¥å—è´å¶æ–¯å®šç†äº†ï¼"
        }
    },
    {
        "translation": {
            "en": "In the naive approach described in Algorithm 15[671] the network being trained is also being used to generate target feature values (Line 15).",
            "zh": "åœ¨ç®—æ³• 15[671] ä¸­æè¿°çš„æœ´ç´ æ–¹æ³•ä¸­ï¼Œæ­£åœ¨è®­ç»ƒçš„ç½‘ç»œä¹Ÿç”¨äºç”Ÿæˆç›®æ ‡ç‰¹å¾å€¼ï¼ˆç¬¬ 15 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we are processing a batch of examples, we need to do the backpropagation of the Î´s for each example.",
            "zh": "å½“æˆ‘ä»¬å¤„ç†ä¸€æ‰¹ç¤ºä¾‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªç¤ºä¾‹è¿›è¡Œ Î´ çš„åå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "30. Updating the weights using Equations (4.12)[161] and (4.13)[161] ensures that the weights always sum to 1.",
            "zh": "30. ä½¿ç”¨æ–¹ç¨‹ï¼ˆ4.12ï¼‰[161]å’Œï¼ˆ4.13ï¼‰[161]æ›´æ–°æƒé‡ï¼Œç¡®ä¿æƒé‡æ€»å’Œå§‹ç»ˆä¸º1ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that some of the errors will be positive and some will be negative.",
            "zh": "è¿™æ„å‘³ç€æœ‰äº›è¯¯å·®æ˜¯æ­£çš„ï¼Œæœ‰äº›æ˜¯è´Ÿçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.7â€…â€…â€…The structure of a profit matrix.",
            "zh": "9.7 åˆ©æ¶¦çŸ©é˜µçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.9â€…â€…â€…The whiskey dataset after the descriptive features have been normalized.",
            "zh": "5.9 æè¿°æ€§ç‰¹å¾å½’ä¸€åŒ–åçš„å¨å£«å¿Œæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, each of the neurons in each group only inspected a local region of the visual field for a single feature, and these local regions became known as local receptive fields.",
            "zh": "ç„¶è€Œï¼Œæ¯ç»„ä¸­çš„æ¯ä¸ªç¥ç»å…ƒåªæ£€æŸ¥è§†é‡çš„å±€éƒ¨åŒºåŸŸä»¥è·å–å•ä¸ªç‰¹å¾ï¼Œè¿™äº›å±€éƒ¨åŒºåŸŸè¢«ç§°ä¸ºå±€éƒ¨æ„Ÿå—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated the âˆ‚â„°/âˆ‚Î»i term, we update Î»i using the following update rule:27",
            "zh": "ä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº† âˆ‚E/âˆ‚Î»i é¡¹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ›´æ–°è§„åˆ™æ›´æ–° Î»iï¼š27"
        }
    },
    {
        "translation": {
            "en": "linear function, 766",
            "zh": "çº¿æ€§å‡½æ•°ï¼Œ766"
        }
    },
    {
        "translation": {
            "en": "Table 11.1",
            "zh": "è¡¨ 11.1"
        }
    },
    {
        "translation": {
            "en": "You decide to do this by thinking about the animals you can remember coming across before and comparing the features of these animals with the features the sailor described to you.",
            "zh": "ä½ å†³å®šé€šè¿‡æ€è€ƒä½ ä»¥å‰èƒ½è®°å¾—é‡åˆ°çš„åŠ¨ç‰©ï¼Œå¹¶å°†è¿™äº›åŠ¨ç‰©çš„ç‰¹å¾ä¸æ°´æ‰‹å‘ä½ æè¿°çš„ç‰¹å¾è¿›è¡Œæ¯”è¾ƒæ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.11[213] lists a small binary dataset that a nearest neighbor model could use to make predictions for this scenario. The descriptive features in this dataset are all binary and record the following information about the behavior of past customers:",
            "zh": "è¡¨5.11[213]åˆ—å‡ºäº†ä¸€ä¸ªå°å‹äºŒè¿›åˆ¶æ•°æ®é›†ï¼Œæœ€è¿‘é‚»æ¨¡å‹å¯ä»¥ä½¿ç”¨è¯¥æ•°æ®é›†å¯¹è¿™ç§æƒ…å†µè¿›è¡Œé¢„æµ‹ã€‚æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾éƒ½æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå¹¶è®°å½•äº†æœ‰å…³è¿‡å»å®¢æˆ·è¡Œä¸ºçš„ä»¥ä¸‹ä¿¡æ¯ï¼š"
        }
    },
    {
        "translation": {
            "en": "Section 4.4.5 has been revised to cover ensemble models in more detail than in the first edition and includes a new description of gradient boosting methods.",
            "zh": "ç¬¬ 4.4.5 èŠ‚ç»è¿‡ä¿®è®¢ï¼Œæ¯”ç¬¬ä¸€ç‰ˆæ›´è¯¦ç»†åœ°æ¶µç›–äº†é›†æˆæ¨¡å‹ï¼Œå¹¶åŒ…æ‹¬å¯¹æ¢¯åº¦æå‡æ–¹æ³•çš„æ–°æè¿°ã€‚"
        }
    },
    {
        "translation": {
            "en": "B.1â€ƒProbability Basics",
            "zh": "B.1 æ¦‚ç‡åŸºç¡€"
        }
    },
    {
        "translation": {
            "en": "He initialization, 461",
            "zh": "ä»–åˆå§‹åŒ–ï¼Œ461"
        }
    },
    {
        "translation": {
            "en": "predictive features, 227",
            "zh": "é¢„æµ‹ç‰¹å¾ï¼Œ 227"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that the hospital would need in order to use the analytics-based insight that your solution would provide.",
            "zh": "ï¼ˆcï¼‰ å¯¹äºæ‚¨æå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°åŒ»é™¢éœ€è¦çš„å®¹é‡ï¼Œä»¥ä¾¿ä½¿ç”¨æ‚¨çš„è§£å†³æ–¹æ¡ˆå°†æä¾›çš„åŸºäºåˆ†æçš„è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.10",
            "zh": "å›¾ 4.10"
        }
    },
    {
        "translation": {
            "en": "For galaxy classification, the most important properties extracted from the images are brightness, color, and shape.",
            "zh": "å¯¹äºæ˜Ÿç³»åˆ†ç±»ï¼Œä»å›¾åƒä¸­æå–çš„æœ€é‡è¦çš„å±æ€§æ˜¯äº®åº¦ã€é¢œè‰²å’Œå½¢çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this context, V and M are examples of hidden features.",
            "zh": "åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ï¼ŒV å’Œ M æ˜¯éšè—ç‰¹å¾çš„ç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 7.21",
            "zh": "å›¾ 7.21"
        }
    },
    {
        "translation": {
            "en": "This causes the algorithm to cluster instances with similar target feature values.",
            "zh": "è¿™ä¼šå¯¼è‡´ç®—æ³•å¯¹å…·æœ‰ç›¸ä¼¼ç›®æ ‡ç‰¹å¾å€¼çš„å®ä¾‹è¿›è¡Œèšç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A second evaluation experiment is then performed using the data in the 2nd fold as the test set and the data in the remaining k âˆ’ 1 folds as the training set.",
            "zh": "ç„¶åä½¿ç”¨ç¬¬ 2 å€çš„æ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼Œå°†å‰©ä½™çš„ k âˆ’ 1 å€çš„æ•°æ®ä½œä¸ºè®­ç»ƒé›†è¿›è¡Œç¬¬äºŒæ¬¡è¯„ä¼°å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The data in an ABT is historical data from the disparate data sources within an organization.",
            "zh": "ABT ä¸­çš„æ•°æ®æ˜¯æ¥è‡ªç»„ç»‡å†…ä¸åŒæ•°æ®æºçš„å†å²æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in a network using ReLUs, Xavier initialization (Equation (8.62)[459]) could be used to define the variance for the weights in the first layer, because the rectified function has not been applied to the inputs, and then He initialization (Equation (8.63)[461]) could then be used for the later layers in the network (He et al., 2015).",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨ä½¿ç”¨ ReLU çš„ç½‘ç»œä¸­ï¼ŒXavier åˆå§‹åŒ–ï¼ˆç­‰å¼ ï¼ˆ8.62ï¼‰[459]ï¼‰å¯ç”¨äºå®šä¹‰ç¬¬ä¸€å±‚æƒé‡çš„æ–¹å·®ï¼Œå› ä¸ºæ ¡æ­£å‡½æ•°å°šæœªåº”ç”¨äºè¾“å…¥ï¼Œç„¶å He åˆå§‹åŒ–ï¼ˆç­‰å¼ ï¼ˆ8.63ï¼‰[461]ï¼‰å¯ç”¨äºç½‘ç»œä¸­çš„åå‡ å±‚ï¼ˆHe et al.ï¼Œ 2015)."
        }
    },
    {
        "translation": {
            "en": "2.7â€…â€…â€…Modeling points in time for a scenario with no real outcome period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.7 å¯¹æ²¡æœ‰å®é™…ç»“æœæœŸçš„åœºæ™¯çš„æ—¶é—´ç‚¹è¿›è¡Œå»ºæ¨¡ï¼ˆæ¯æ¡çº¿ä»£è¡¨ä¸€ä¸ªå®¢æˆ·ï¼Œæ˜Ÿæ˜Ÿè¡¨ç¤ºäº‹ä»¶ï¼‰ã€‚ï¼ˆaï¼‰ æ˜¾ç¤ºå®é™…æ•°æ®ï¼Œï¼ˆbï¼‰ æ˜¾ç¤ºäº‹ä»¶å¯¹é½æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The player wins $2 in the event of a TwentyTwo (two aces), wins $1 if they beat the dealer in the normal way, neither wins nor loses anything if the game is tied, and loses $1 if the dealer wins.10 Table 11.1[647] shows some episodes of the TwentyTwos game being played including the the playerâ€™s hand, the dealerâ€™s hand, the actions the player takes, and the rewards earned by the player.",
            "zh": "å¦‚æœç©å®¶æœ‰äºŒåäºŒï¼ˆä¸¤ä¸ªAï¼‰ï¼Œåˆ™èµ¢å¾—2ç¾å…ƒï¼Œå¦‚æœä»–ä»¬ä»¥æ­£å¸¸æ–¹å¼å‡»è´¥åº„å®¶ï¼Œåˆ™èµ¢å¾—1ç¾å…ƒï¼Œå¦‚æœæ¸¸æˆæ‰“æˆå¹³å±€ï¼Œåˆ™æ—¢ä¸èµ¢ä¹Ÿä¸è¾“ï¼Œå¦‚æœåº„å®¶èµ¢äº†ï¼Œåˆ™æŸå¤±1ç¾å…ƒ.10è¡¨11.1[647]æ˜¾ç¤ºäº†æ­£åœ¨è¿›è¡Œçš„äºŒåäºŒæ¸¸æˆçš„ä¸€äº›æƒ…èŠ‚ï¼ŒåŒ…æ‹¬ç©å®¶çš„æ‰‹ç‰Œï¼Œ åº„å®¶çš„æ‰‹ç‰Œï¼Œç©å®¶é‡‡å–çš„è¡ŒåŠ¨ï¼Œä»¥åŠç©å®¶è·å¾—çš„å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.6",
            "zh": "å›¾ A.6"
        }
    },
    {
        "translation": {
            "en": "Figure 8.12[407] illustrates the backward pass of the algorithm. Before describing the backward pass of the algorithm, we will distinguish between two types of error gradients that are calculated when we are training a neural network using backpropagation:",
            "zh": "å›¾ 8.12[407] è¯´æ˜äº†ç®—æ³•çš„å‘åä¼ é€’ã€‚åœ¨æè¿°ç®—æ³•çš„å‘åä¼ é€’ä¹‹å‰ï¼Œæˆ‘ä»¬å°†åŒºåˆ†ä¸¤ç§ç±»å‹çš„è¯¯å·®æ¢¯åº¦ï¼Œå®ƒä»¬æ˜¯åœ¨ä½¿ç”¨åå‘ä¼ æ’­è®­ç»ƒç¥ç»ç½‘ç»œæ—¶è®¡ç®—çš„ï¼š"
        }
    },
    {
        "translation": {
            "en": "SIZEUNIFORMITY: A measure of the variation in size of cells in the tissue samples, higher values indicate more uniform sizes (1 to 10).",
            "zh": "å¤§å°å‡åŒ€æ€§ï¼šç»„ç»‡æ ·æœ¬ä¸­ç»†èƒå¤§å°å˜åŒ–çš„é‡åº¦ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºå¤§å°è¶Šå‡åŒ€ï¼ˆ1 åˆ° 10ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In a famous example of this, an article was published in the prestigious journal Nature outlining a causal relationship between young children sleeping with a night-light turned on and these children developing near-sightedness in later life (Quinn et al., 1999).",
            "zh": "åœ¨ä¸€ä¸ªè‘—åçš„ä¾‹å­ä¸­ï¼Œä¸€ç¯‡å‘è¡¨åœ¨è‘—åæœŸåˆŠã€Šè‡ªç„¶ã€‹ä¸Šçš„æ–‡ç« æ¦‚è¿°äº†å¹¼å„¿å¼€ç€å¤œç¯ç¡è§‰ä¸è¿™äº›å­©å­åœ¨ä»¥åçš„ç”Ÿæ´»ä¸­å‘å±•è¿‘è§†ä¹‹é—´çš„å› æœå…³ç³»ï¼ˆQuinnç­‰äººï¼Œ1999ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The rewards are shown as the large numbers beside some states.",
            "zh": "å¥–åŠ±æ˜¾ç¤ºä¸ºæŸäº›å·æ—è¾¹çš„å¤§æ•°å­—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reward for moving between any two normal cells is âˆ’ 1, the reward for arriving at the goal is 50, and the reward for entering a fiery cell is âˆ’ 20.",
            "zh": "åœ¨ä»»æ„ä¸¤ä¸ªæ­£å¸¸ç»†èƒä¹‹é—´ç§»åŠ¨çš„å¥–åŠ±æ˜¯-1ï¼Œè¾¾åˆ°ç›®æ ‡çš„å¥–åŠ±æ˜¯50ï¼Œè¿›å…¥ç«çƒ­ç»†èƒçš„å¥–åŠ±æ˜¯-20ã€‚"
        }
    },
    {
        "translation": {
            "en": "Davies, E. R. 2005. Machine vision: Theory, algorithms, practicalities, 3rd ed. Elsevier.",
            "zh": "æˆ´ç»´æ–¯ï¼ŒERï¼Œ2005 å¹´ã€‚æœºå™¨è§†è§‰ï¼šç†è®ºã€ç®—æ³•ã€å®ç”¨æ€§ï¼Œç¬¬ 3 ç‰ˆï¼Œçˆ±æ€å”¯å°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the network in Figure 6.12(b)[291], the calculation would be",
            "zh": "ä½¿ç”¨å›¾6.12ï¼ˆbï¼‰[291]ä¸­çš„ç½‘ç»œï¼Œè®¡ç®—ç»“æœä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "That is, a good clustering minimizes intra-cluster distances and maximizes inter-cluster distances.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼Œè‰¯å¥½çš„èšç±»å¯ä»¥æœ€å°åŒ–èšç±»å†…è·ç¦»ï¼Œå¹¶æœ€å¤§åŒ–èšç±»é—´è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Through his discussions with the AT management team, Kate, and Grace, he had learned a lot about the mobile phone industry.",
            "zh": "é€šè¿‡ä¸ATç®¡ç†å›¢é˜Ÿã€Kateå’ŒGraceçš„è®¨è®ºï¼Œä»–å­¦åˆ°äº†å¾ˆå¤šå…³äºæ‰‹æœºè¡Œä¸šçš„çŸ¥è¯†ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Confucius",
            "zh": "â€”â€”å­”å­"
        }
    },
    {
        "translation": {
            "en": "For example, to compute the probability of P(h) in the domain specified by the joint probability distribution P(H,F,V,M), we simply sum the values in the cells containing h (the cells in the first column).",
            "zh": "ä¾‹å¦‚ï¼Œè¦è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒ Pï¼ˆHï¼ŒFï¼ŒVï¼ŒMï¼‰ æŒ‡å®šçš„åŸŸä¸­ Pï¼ˆhï¼‰ çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬åªéœ€å¯¹åŒ…å« h çš„å•å…ƒæ ¼ï¼ˆç¬¬ä¸€åˆ—ä¸­çš„å•å…ƒæ ¼ï¼‰ä¸­çš„å€¼æ±‚å’Œå³å¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Part IV the link between the broader business context and machine learning is shown very clearly in the case studies presented in Chapters 12 (predicting customer churn) and 13 (galaxy classification).",
            "zh": "åœ¨ç¬¬å››éƒ¨åˆ†ä¸­ï¼Œç¬¬12ç« ï¼ˆé¢„æµ‹å®¢æˆ·æµå¤±ï¼‰å’Œç¬¬13ç« ï¼ˆæ˜Ÿç³»åˆ†ç±»ï¼‰ä¸­ä»‹ç»çš„æ¡ˆä¾‹ç ”ç©¶éå¸¸æ¸…æ¥šåœ°æ˜¾ç¤ºäº†æ›´å¹¿æ³›çš„ä¸šåŠ¡ç¯å¢ƒä¸æœºå™¨å­¦ä¹ ä¹‹é—´çš„è”ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Davenport, Thomas H., and Jinho Kim. 2013. Keeping up with the quants: Your guide to understanding and using analytics. Harvard Business Press Books.",
            "zh": "è¾¾æ–‡æ³¢ç‰¹ã€æ‰˜é©¬æ–¯ H. å’Œé‡‘é•‡æµ©ã€‚2013. è·Ÿä¸Šé‡åŒ–è¶‹åŠ¿ï¼šç†è§£å’Œä½¿ç”¨åˆ†æçš„æŒ‡å—ã€‚å“ˆä½›å•†ä¸šå‡ºç‰ˆç¤¾å›¾ä¹¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, the matrix product ED is not defined because the number of columns in E (3) is not equal to the number of rows in D (2).",
            "zh": "ä½†æ˜¯ï¼Œç”±äº E ï¼ˆ3ï¼‰ ä¸­çš„åˆ—æ•°ä¸ç­‰äº D ï¼ˆ2ï¼‰ ä¸­çš„è¡Œæ•°ï¼Œå› æ­¤æœªå®šä¹‰çŸ©é˜µä¹˜ç§¯ EDã€‚"
        }
    },
    {
        "translation": {
            "en": "One way to extend the longevity of a feature is to use a derived ratio instead of a raw feature.",
            "zh": "å»¶é•¿ç‰¹å¾å¯¿å‘½çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨æ´¾ç”Ÿæ¯”ç‡è€Œä¸æ˜¯åŸå§‹ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, in Sections 8.4.1[434] and 8.4.2[447] we explain and motivate the current standard approaches to deciding on two of the most important hyper-parameter decisions for keeping error gradients stable: the selection of the activation function, and the initialization of the weights.",
            "zh": "å› æ­¤ï¼Œåœ¨ç¬¬ 8.4.1[434] å’Œ 8.4.2[447] èŠ‚ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šå¹¶æ¿€åŠ±äº†å½“å‰çš„æ ‡å‡†æ–¹æ³•ï¼Œä»¥å†³å®šä¸¤ä¸ªæœ€é‡è¦çš„è¶…å‚æ•°å†³ç­–ï¼Œä»¥ä¿æŒè¯¯å·®æ¢¯åº¦ç¨³å®šï¼šæ¿€æ´»å‡½æ•°çš„é€‰æ‹©å’Œæƒé‡çš„åˆå§‹åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "When evaluating models against a particular deployment scenario, model accuracy is not the only issue we need to consider. In order to successfully address a business problem, a model must be accurate, but it must also meet the other requirements of the business scenario. Three issues are important to consider:",
            "zh": "åœ¨é’ˆå¯¹ç‰¹å®šéƒ¨ç½²æ–¹æ¡ˆè¯„ä¼°æ¨¡å‹æ—¶ï¼Œæ¨¡å‹å‡†ç¡®æ€§å¹¶ä¸æ˜¯æˆ‘ä»¬éœ€è¦è€ƒè™‘çš„å”¯ä¸€é—®é¢˜ã€‚ä¸ºäº†æˆåŠŸè§£å†³ä¸šåŠ¡é—®é¢˜ï¼Œæ¨¡å‹å¿…é¡»å‡†ç¡®ï¼Œä½†ä¹Ÿå¿…é¡»æ»¡è¶³ä¸šåŠ¡åœºæ™¯çš„å…¶ä»–è¦æ±‚ã€‚æœ‰ä¸‰ä¸ªé—®é¢˜éœ€è¦è€ƒè™‘ï¼š"
        }
    },
    {
        "translation": {
            "en": "eager learner, 232",
            "zh": "æ¸´æœ›å­¦ä¹ ï¼Œ232"
        }
    },
    {
        "translation": {
            "en": "In this simple example it is easy to imagine collecting a training instance to match every possible combination of descriptive features; because there are only three binary descriptive features, there are only 23 = 8 combinations.",
            "zh": "åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œå¾ˆå®¹æ˜“æƒ³è±¡æ”¶é›†ä¸€ä¸ªè®­ç»ƒå®ä¾‹æ¥åŒ¹é…æè¿°æ€§ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½ç»„åˆ;å› ä¸ºåªæœ‰ä¸‰ä¸ªäºŒè¿›åˆ¶æè¿°æ€§ç‰¹å¾ï¼Œæ‰€ä»¥åªæœ‰ 23 = 8 ä¸ªç»„åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "Wooldridge and Jennings (1995) remains a key introduction to the field and the more recent Wooldridge (2009) adds useful information about systems where multiple agents compete or cooperate is very useful.",
            "zh": "Wooldridge å’Œ Jennings ï¼ˆ1995ï¼‰ ä»ç„¶æ˜¯è¯¥é¢†åŸŸçš„å…³é”®ä»‹ç»ï¼Œæœ€è¿‘çš„ Wooldridge ï¼ˆ2009ï¼‰ å¢åŠ äº†æœ‰å…³å¤šä¸ªæ™ºèƒ½ä½“ç«äº‰æˆ–åˆä½œçš„ç³»ç»Ÿçš„æœ‰ç”¨ä¿¡æ¯éå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "EDUCATION: Spending per primary student as a percentage of GDP",
            "zh": "æ•™è‚²ï¼šå°å­¦ç”Ÿäººå‡æ”¯å‡ºå GDPçš„ç™¾åˆ†æ¯”"
        }
    },
    {
        "translation": {
            "en": "This means that weights for these neurons will not be updated for this example.",
            "zh": "è¿™æ„å‘³ç€åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè¿™äº›ç¥ç»å…ƒçš„æƒé‡ä¸ä¼šæ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A visualization of the final action-value table for an agent trained using SARSA on-policy temporal-difference learning across the grid world after 350 episodes. (b) The cumulative reward earned from each episode. (c) An illustration of the target policy learned by the agent after 350 episodes. The arrows show the direction with the highest entry in the action-value table for each state. (d) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "ï¼ˆaï¼‰ åœ¨350é›†åï¼Œä½¿ç”¨SARSAæ”¿ç­–æ—¶é—´å·®åˆ†å­¦ä¹ è®­ç»ƒçš„æ™ºèƒ½ä½“çš„æœ€ç»ˆè¡ŒåŠ¨å€¼è¡¨çš„å¯è§†åŒ–ã€‚ï¼ˆbï¼‰ æ¯é›†æ‰€è·å¾—çš„ç´¯ç§¯å¥–åŠ±ã€‚ï¼ˆcï¼‰ ä»£ç†äººåœ¨350é›†åäº†è§£åˆ°çš„ç›®æ ‡æ”¿ç­–çš„è¯´æ˜ã€‚ç®­å¤´æ˜¾ç¤ºæ¯ä¸ªçŠ¶æ€çš„åŠ¨ä½œå€¼è¡¨ä¸­æ¡ç›®æœ€å¤šçš„æ–¹å‘ã€‚ï¼ˆdï¼‰ å½“è´ªå©ªåœ°éµå¾ªç›®æ ‡ç­–ç•¥æ—¶ï¼Œä»£ç†ä»å¼€å§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In situations where a letter, for example, X, denotes a joint event, then âˆ‘iP(Xi) should be interpreted as summing over all the possible combinations of value assignments to the features in X.",
            "zh": "åœ¨å­—æ¯ï¼ˆä¾‹å¦‚ Xï¼‰è¡¨ç¤ºè”åˆäº‹ä»¶çš„æƒ…å†µä¸‹ï¼Œâˆ‘iPï¼ˆä¹ ï¼‰ åº”è§£é‡Šä¸º X ä¸­ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½å€¼èµ‹å€¼ç»„åˆçš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "David Hand has also written extensively on the appropriateness of different evaluation measures and is always worth reading.",
            "zh": "å¤§å«Â·æ±‰å¾·ï¼ˆDavid Handï¼‰è¿˜æ’°å†™äº†å¤§é‡å…³äºä¸åŒè¯„ä¼°æªæ–½çš„é€‚å½“æ€§çš„æ–‡ç« ï¼Œæ€»æ˜¯å€¼å¾—ä¸€è¯»ã€‚"
        }
    },
    {
        "translation": {
            "en": "A typical size for a subsequence might be 20 inputs.",
            "zh": "å­åºåˆ—çš„å…¸å‹å¤§å°å¯èƒ½æ˜¯ 20 ä¸ªè¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the purpose of illustration, let us assume that the neuron shown in Figure 8.31[480] uses the set of weights listed in Equation (8.85)[480]",
            "zh": "ä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œæˆ‘ä»¬å‡è®¾å›¾8.31[480]æ‰€ç¤ºçš„ç¥ç»å…ƒä½¿ç”¨ç­‰å¼ï¼ˆ8.85ï¼‰[480]ä¸­åˆ—å‡ºçš„æƒé‡é›†"
        }
    },
    {
        "translation": {
            "en": "In neither of these rows is f the case, so the conditional probability for P(f | h,m) is 0.",
            "zh": "åœ¨è¿™ä¸¤è¡Œä¸­éƒ½ä¸æ˜¯ f çš„æƒ…å†µï¼Œå› æ­¤ Pï¼ˆf | hï¼Œmï¼‰ çš„æ¡ä»¶æ¦‚ç‡ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "co-absence, 212, 213",
            "zh": "å…±åŒç¼ºå¸­ï¼Œ212,213"
        }
    },
    {
        "translation": {
            "en": "Furthermore, during the backward pass of the algorithm the derivative of the rectified linear function for Neuron 4 is zero for all four examples, causing the error gradient to be pushed to zero for all four examples, and so the weights on connections into Neuron 4 receive no updates.",
            "zh": "æ­¤å¤–ï¼Œåœ¨ç®—æ³•çš„å‘åä¼ é€’è¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰å››ä¸ªç¤ºä¾‹ä¸­ Neuron 4 çš„æ ¡æ­£çº¿æ€§å‡½æ•°çš„å¯¼æ•°å‡ä¸ºé›¶ï¼Œå¯¼è‡´æ‰€æœ‰å››ä¸ªç¤ºä¾‹çš„è¯¯å·®æ¢¯åº¦å‡ä¸ºé›¶ï¼Œå› æ­¤è¿æ¥åˆ° Neuron 4 çš„æƒé‡ä¸ä¼šæ”¶åˆ°ä»»ä½•æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.8â€…â€…â€…Histograms, using a bin size of 250 units, and density curves for the ACCOUNT BALANCE feature: (a) the fraudulent instances overlaid with a fitted exponential distribution; and (b) the non-fraudulent instances overlaid with a fitted normal distribution.",
            "zh": "6.8 ç›´æ–¹å›¾ï¼Œä½¿ç”¨250ä¸ªå•ä½çš„ç®±å¤§å°ï¼Œä»¥åŠè´¦æˆ·ä½™é¢ç‰¹å¾çš„å¯†åº¦æ›²çº¿ï¼šï¼ˆaï¼‰ç”¨æ‹ŸåˆæŒ‡æ•°åˆ†å¸ƒå åŠ çš„æ¬ºè¯ˆå®ä¾‹;ï¼ˆbï¼‰éæ¬ºè¯ˆæ€§å®ä¾‹ä¸æ‹Ÿåˆæ­£æ€åˆ†å¸ƒå åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic assumption behind both gain and lift is that if we were to rank the instances in a test set in descending order of the prediction scores assigned to them by a well-performing model, we would expect the majority of the positive instances to be toward the top of this ranking. The gain and lift measures attempt to measure to what extent a set of predictions made by a model meet this assumption.",
            "zh": "å¢ç›Šå’Œæå‡èƒŒåçš„åŸºæœ¬å‡è®¾æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬è¦æŒ‰ç…§è¡¨ç°è‰¯å¥½çš„æ¨¡å‹åˆ†é…ç»™å®ƒä»¬çš„é¢„æµ‹åˆ†æ•°çš„é™åºå¯¹æµ‹è¯•é›†ä¸­çš„å®ä¾‹è¿›è¡Œæ’åï¼Œæˆ‘ä»¬é¢„è®¡å¤§å¤šæ•°æ­£å®ä¾‹éƒ½ä½äºè¯¥æ’åçš„é¡¶éƒ¨ã€‚å¢ç›Šå’Œæå‡åº¦é‡è¯•å›¾è¡¡é‡æ¨¡å‹æ‰€åšçš„ä¸€ç»„é¢„æµ‹åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ»¡è¶³æ­¤å‡è®¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "linear annealing, 674",
            "zh": "çº¿æ€§é€€ç«ï¼Œ674"
        }
    },
    {
        "translation": {
            "en": "Cumulative gain is especially useful in customer relationship management (CRM) applications such as cross-sell and upsell models. The cumulative gain tells us how many customers we need to contact in order to reach a particular percentage of those who are likely to respond to an offer, which is an incredibly useful piece of information to know when planning customer contact budgets.",
            "zh": "ç´¯ç§¯æ”¶ç›Šåœ¨å®¢æˆ·å…³ç³»ç®¡ç† ï¼ˆCRMï¼‰ åº”ç”¨ç¨‹åºï¼ˆå¦‚äº¤å‰é”€å”®å’Œè¿½åŠ é”€å”®æ¨¡å‹ï¼‰ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚ç´¯ç§¯æ”¶ç›Šå‘Šè¯‰æˆ‘ä»¬éœ€è¦è”ç³»å¤šå°‘å®¢æˆ·æ‰èƒ½æ¥è§¦åˆ°å¯èƒ½å“åº”æŠ¥ä»·çš„ç‰¹å®šç™¾åˆ†æ¯”çš„å®¢æˆ·ï¼Œè¿™æ˜¯åœ¨è§„åˆ’å®¢æˆ·è”ç³»é¢„ç®—æ—¶äº†è§£çš„éå¸¸æœ‰ç”¨çš„ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Algorithm 13[658] shows the algorithm for the Q-learning approach to temporal-difference learning.",
            "zh": "ç®—æ³•13[658]æ˜¾ç¤ºäº†ç”¨äºæ—¶é—´å·®åˆ†å­¦ä¹ çš„Qå­¦ä¹ æ–¹æ³•çš„ç®—æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.3â€…â€…â€…Neural Networks as Matrix Operations",
            "zh": "8.2.3 ä½œä¸ºçŸ©é˜µæ“ä½œçš„ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "Figure 10.7",
            "zh": "å›¾ 10.7"
        }
    },
    {
        "translation": {
            "en": "Table 4.9",
            "zh": "è¡¨ 4.9"
        }
    },
    {
        "translation": {
            "en": "Decision tree induction algorithms are particularly well suited to use with bagging.",
            "zh": "å†³ç­–æ ‘å½’çº³ç®—æ³•ç‰¹åˆ«é€‚åˆä¸è£…è¢‹ä¸€èµ·ä½¿ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of models, it would be useful to be able to take into account the costs of different outcomes.",
            "zh": "åœ¨è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½æ—¶ï¼Œèƒ½å¤Ÿè€ƒè™‘åˆ°ä¸åŒç»“æœçš„æˆæœ¬å°†æ˜¯æœ‰ç”¨çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73] with correlation coefficients included.",
            "zh": "ä¸€ä¸ªæ•£ç‚¹å›¾çŸ©é˜µï¼Œæ˜¾ç¤ºäº†è¡¨3.7[73]ä¸­èŒä¸šç¯®çƒé˜Ÿæ•°æ®é›†ä¸­è¿ç»­ç‰¹å¾çš„æ•£ç‚¹å›¾ï¼ŒåŒ…æ‹¬ç›¸å…³ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Training a support vector machine involves searching for the decision boundary, or separating hyperplane,20 that leads to the maximum margin because this will best separate the levels of the target feature.",
            "zh": "è®­ç»ƒæ”¯æŒå‘é‡æœºæ¶‰åŠæœç´¢å†³ç­–è¾¹ç•Œï¼Œæˆ–åˆ†ç¦»è¶…å¹³é¢ï¼Œ20 è¿™ä¼šå¯¼è‡´æœ€å¤§è¾¹é™…ï¼Œå› ä¸ºè¿™å°†æœ€å¥½åœ°åˆ†ç¦»ç›®æ ‡ç‰¹å¾çš„çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the network changed during training.",
            "zh": "æ˜¾ç¤ºç½‘ç»œçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œåœ¨è®­ç»ƒæœŸé—´å¦‚ä½•å˜åŒ–çš„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.2â€…â€…â€…Data Understanding",
            "zh": "13.2 æ•°æ®ç†è§£"
        }
    },
    {
        "translation": {
            "en": "For example, if in an ABT containing 1,000 instances, one value is missing for a particular feature, it would be pretty extreme to remove that whole feature.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœåœ¨åŒ…å« 1,000 ä¸ªå®ä¾‹çš„ ABT ä¸­ï¼ŒæŸä¸ªç‰¹å®šåŠŸèƒ½ç¼ºå°‘ä¸€ä¸ªå€¼ï¼Œåˆ™åˆ é™¤æ•´ä¸ªåŠŸèƒ½å°†æ˜¯éå¸¸æç«¯çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Learning generalized functions from a small training dataset is exactly what predictive modeling does, and we can use predictive models, trained using a combination of ideas form supervised machine learning and reinforcement learning, for this task!",
            "zh": "ä»å°å‹è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ å¹¿ä¹‰å‡½æ•°æ­£æ˜¯é¢„æµ‹å»ºæ¨¡æ‰€åšçš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„æµ‹æ¨¡å‹ï¼Œä½¿ç”¨ç›‘ç£æœºå™¨å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„æ€æƒ³ç»„åˆè¿›è¡Œè®­ç»ƒï¼Œä»¥å®Œæˆè¿™é¡¹ä»»åŠ¡ï¼"
        }
    },
    {
        "translation": {
            "en": "textual data, 34",
            "zh": "æ–‡æœ¬æ•°æ®ï¼Œ34"
        }
    },
    {
        "translation": {
            "en": "The next section describes how the weights can be determined using the gradient descent algorithm.",
            "zh": "ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ç¡®å®šæƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7. For an excellent overview of the different types of biases that affect machine learning and the potential harms these can cause, we recommend Kate Crawfordâ€™s The Trouble with Bias keynote from the NeurIPS 2017 conference (Crawford, 2017). Videos of this talk are freely available online.",
            "zh": "7. ä¸ºäº†å¾ˆå¥½åœ°æ¦‚è¿°å½±å“æœºå™¨å­¦ä¹ çš„ä¸åŒç±»å‹çš„åè§ä»¥åŠè¿™äº›åè§å¯èƒ½é€ æˆçš„æ½œåœ¨å±å®³ï¼Œæˆ‘ä»¬æ¨è Kate Crawford åœ¨ NeurIPS 2017 ä¼šè®®ä¸Šå‘è¡¨çš„ The Trouble with Bias ä¸»é¢˜æ¼”è®²ï¼ˆCrawfordï¼Œ2017 å¹´ï¼‰ã€‚æœ¬æ¬¡æ¼”è®²çš„è§†é¢‘å¯åœ¨çº¿å…è´¹è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The first convolutional layer had 96 different filters and used a ReLU non-linearity and max pooling.",
            "zh": "ç¬¬ä¸€ä¸ªå·ç§¯å±‚æœ‰ 96 ä¸ªä¸åŒçš„æ»¤æ³¢å™¨ï¼Œå¹¶ä½¿ç”¨ ReLU éçº¿æ€§å’Œæœ€å¤§æ± åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Adding the five terminal statesâ€”BUST, LOSE, TIE, WIN, and TWENTYTWOâ€”gives 11 states in total.",
            "zh": "å°†äº”ä¸ªç»ˆç«¯çŠ¶æ€ï¼ˆBUSTã€LOSEã€TIEã€WIN å’Œ TWENTYTWOï¼‰ç›¸åŠ ï¼Œæ€»å…±æœ‰ 11 ä¸ªçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "misses, 538",
            "zh": "å¤±è¯¯ï¼Œ538"
        }
    },
    {
        "translation": {
            "en": "In each case there is an intuitive clustering that we can observe in the visualizationsâ€”for the blobs dataset there are three clusters, one for each blob; for the circles dataset there are two clusters, one for each ring; and for the half-moons dataset there are two clusters, one for each half-moon shape.",
            "zh": "åœ¨æ¯ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥åœ¨å¯è§†åŒ–æ•ˆæœä¸­è§‚å¯Ÿåˆ°ä¸€ä¸ªç›´è§‚çš„èšç±» - å¯¹äº blob æ•°æ®é›†ï¼Œæœ‰ä¸‰ä¸ªèšç±»ï¼Œæ¯ä¸ªèšç±»ä¸€ä¸ª;å¯¹äºåœ†æ•°æ®é›†ï¼Œæœ‰ä¸¤ä¸ªèšç±»ï¼Œæ¯ä¸ªç¯ä¸€ä¸ªèšç±»;å¯¹äºåŠæœˆæ•°æ®é›†ï¼Œæœ‰ä¸¤ä¸ªèšç±»ï¼Œæ¯ä¸ªåŠæœˆå½¢çŠ¶ä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3.1â€…â€…â€…Missing Values",
            "zh": "3.3.1 ç¼ºå¤±å€¼"
        }
    },
    {
        "translation": {
            "en": "(c) Assuming a learning rate of 0.000002, calculate the weights at the next iteration of the gradient descent algorithm.",
            "zh": "ï¼ˆcï¼‰ å‡è®¾å­¦ä¹ ç‡ä¸º 0.000002ï¼Œè®¡ç®—æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸‹ä¸€æ¬¡è¿­ä»£æ—¶çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "C.1â€…â€…(a) The speed of a car during a journey along a minor road before joining a highway and finally coming to a sudden halt; and (b) the acceleration, the derivative of speed with respect to time, for this journey.",
            "zh": "C.1 ï¼ˆaï¼‰ æ±½è½¦åœ¨è¿›å…¥é«˜é€Ÿå…¬è·¯ä¹‹å‰æ²¿ä¸€æ¡å°è·¯è¡Œé©¶å¹¶æœ€ç»ˆçªç„¶åœä¸‹æ¥çš„é€Ÿåº¦;ï¼ˆbï¼‰åŠ é€Ÿåº¦ï¼Œå³é€Ÿåº¦ç›¸å¯¹äºæ—¶é—´çš„å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.6â€ƒFurther Reading",
            "zh": "2.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor algorithm creates an implicit global predictive model by aggregating local models, or neighborhoods.",
            "zh": "æœ€è¿‘é‚»ç®—æ³•é€šè¿‡èšåˆå±€éƒ¨æ¨¡å‹æˆ–é‚»åŸŸæ¥åˆ›å»ºéšå¼å…¨å±€é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. and then applying a decision rule over the class posteriors to return a target level.",
            "zh": "3. ç„¶åå¯¹ç±»åéªŒåº”ç”¨å†³ç­–è§„åˆ™ä»¥è¿”å›ç›®æ ‡æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "The fourth segment of the table lists the per example one-hot encoding of the target for each example in the mini-batch.",
            "zh": "è¯¥è¡¨çš„ç¬¬å››æ®µåˆ—å‡ºäº†å°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹çš„ç›®æ ‡çš„æ¯ä¸ªç¤ºä¾‹çš„å•çƒ­ç¼–ç ã€‚"
        }
    },
    {
        "translation": {
            "en": "seeds, 600",
            "zh": "ç§å­ï¼Œ600"
        }
    },
    {
        "translation": {
            "en": "The bottom two segments of the table illustrate the calculation of the Î´s for each neuron for each example.",
            "zh": "è¯¥è¡¨çš„åº•éƒ¨ä¸¤æ®µè¯´æ˜äº†æ¯ä¸ªç¤ºä¾‹ä¸­æ¯ä¸ªç¥ç»å…ƒçš„ Î´ çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.6â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "2.4.6 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "1. learning the class posterior probability P(tl|d) directly from the data,",
            "zh": "1. ç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ ç±»åéªŒæ¦‚ç‡ Pï¼ˆtl|dï¼‰ï¼Œ"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(a)[151] depicts a set of instances on the continuous number line.",
            "zh": "å›¾4.15ï¼ˆaï¼‰[151]æç»˜äº†è¿ç»­æ•°å­—çº¿ä¸Šçš„ä¸€ç»„å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we have seen, using a joint probability distribution, a model can carry out this calculation by simply conditioning on the evidence features and summing out the hidden features.",
            "zh": "æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œä½¿ç”¨è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œæ¨¡å‹å¯ä»¥é€šè¿‡ç®€å•åœ°å¯¹è¯æ®ç‰¹å¾è¿›è¡Œæ¡ä»¶åå°„å¹¶æ€»ç»“éšè—ç‰¹å¾æ¥æ‰§è¡Œæ­¤è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.28",
            "zh": "å›¾ 8.28"
        }
    },
    {
        "translation": {
            "en": "There are a number of perspectives on understanding how dropout helps with overfitting.",
            "zh": "å…³äºç†è§£è¾å­¦å¦‚ä½•å¸®åŠ©è¿‡æ‹Ÿåˆï¼Œæœ‰è®¸å¤šè§‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Blondlot, RenÃ©, 533",
            "zh": "å¸ƒéš†æ´›ç‰¹ï¼Œå‹’å†…ï¼Œ533"
        }
    },
    {
        "translation": {
            "en": "First, Jocelyn calculated an average class accuracy by comparing the predictions made by her model for the same 200 galaxies with the manual classifications made by the SDSS scientists.",
            "zh": "é¦–å…ˆï¼ŒJocelyné€šè¿‡å°†å¥¹çš„æ¨¡å‹å¯¹ç›¸åŒ200ä¸ªæ˜Ÿç³»çš„é¢„æµ‹ä¸SDSSç§‘å­¦å®¶çš„æ‰‹åŠ¨åˆ†ç±»è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—äº†å¹³å‡åˆ†ç±»ç²¾åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "If a sample is not representative, we say that the sample is biased.",
            "zh": "å¦‚æœæ ·æœ¬ä¸å…·æœ‰ä»£è¡¨æ€§ï¼Œæˆ‘ä»¬è¯´æ ·æœ¬æ˜¯æœ‰åå·®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second part of the book covers the Modeling and Evaluation phase of CRISP-DM. We consider five main families of machine learning algorithm:",
            "zh": "æœ¬ä¹¦çš„ç¬¬äºŒéƒ¨åˆ†ä»‹ç»äº† CRISP-DM çš„å»ºæ¨¡å’Œè¯„ä¼°é˜¶æ®µã€‚æˆ‘ä»¬è€ƒè™‘äº†æœºå™¨å­¦ä¹ ç®—æ³•çš„äº”ä¸ªä¸»è¦ç³»åˆ—ï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, in the single screenshot of the Lunar Lander environment in Figure 11.7[669], it is not possible to tell at what velocity the spaceship is moving.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å›¾11.7[669]ä¸­æœˆçƒç€é™†å™¨ç¯å¢ƒçš„å•ä¸ªå±å¹•æˆªå›¾ä¸­ï¼Œæ— æ³•åˆ¤æ–­å®‡å®™é£èˆ¹ä»¥ä»€ä¹ˆé€Ÿåº¦ç§»åŠ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Salaries, however, change all the time based on inflation and other socioeconomic factors.",
            "zh": "ç„¶è€Œï¼Œå·¥èµ„ä¸€ç›´åœ¨æ ¹æ®é€šè´§è†¨èƒ€å’Œå…¶ä»–ç¤¾ä¼šç»æµå› ç´ è€Œå˜åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.",
            "zh": "æœºå™¨å­¦ä¹ ç®—æ³•çš„å·¥ä½œåŸç†æ˜¯æœç´¢ä¸€ç»„å¯èƒ½çš„é¢„æµ‹æ¨¡å‹ï¼Œä»¥å¯»æ‰¾æœ€èƒ½æ•è·æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4â€ƒDesigning and Implementing Features",
            "zh": "2.4 è®¾è®¡å’Œå®ç°åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "We can see in Figure 5.10(b)[201] that instance d12 is not the true nearest neighbor to the queryâ€”several other instances are inside the target hypersphere.",
            "zh": "æˆ‘ä»¬å¯ä»¥åœ¨å›¾ 5.10ï¼ˆbï¼‰[201] ä¸­çœ‹åˆ°ï¼Œå®ä¾‹ d12 ä¸æ˜¯æŸ¥è¯¢çš„çœŸæ­£æœ€è¿‘é‚»ï¼Œè€Œæ˜¯å…¶ä»–å‡ ä¸ªå®ä¾‹åœ¨ç›®æ ‡è¶…çƒä½“å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, after approximately 5,000 epochs, the rate of decrease of the error increases dramatically until it flattens out again around 6,000 epochs.",
            "zh": "ç„¶è€Œï¼Œåœ¨å¤§çº¦ 5,000 ä¸ªå‘¨æœŸä¹‹åï¼Œè¯¯å·®çš„ä¸‹é™ç‡æ€¥å‰§å¢åŠ ï¼Œç›´åˆ°åœ¨ 6,000 ä¸ªå‘¨æœŸå·¦å³å†æ¬¡è¶‹äºå¹³ç¼“ã€‚"
        }
    },
    {
        "translation": {
            "en": "A range of performance measures use this ability of a model, to rank instances that should get predictions of one target level higher than the other, to better assess how well a prediction model is performing.",
            "zh": "ä¸€ç³»åˆ—æ€§èƒ½åº¦é‡åˆ©ç”¨æ¨¡å‹çš„è¿™ç§èƒ½åŠ›ï¼Œå¯¹åº”è·å¾—ä¸€ä¸ªç›®æ ‡çº§åˆ«çš„é¢„æµ‹é«˜äºå¦ä¸€ä¸ªç›®æ ‡çº§åˆ«çš„å®ä¾‹è¿›è¡Œæ’åï¼Œä»¥æ›´å¥½åœ°è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Like lots of other families, the Murphys have a set of magnetic letters on the refrigerator in their kitchen.",
            "zh": "åƒè®¸å¤šå…¶ä»–å®¶åº­ä¸€æ ·ï¼Œå¢¨è²ä¸€å®¶åœ¨å¨æˆ¿çš„å†°ç®±ä¸Šæœ‰ä¸€å¥—ç£æ€§å­—æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the SDSS has been able to put in place algorithmic solutions to identifying certain objects within the images collected, there have been a number of difficulties.",
            "zh": "å°½ç®¡SDSSå·²ç»èƒ½å¤Ÿå®æ–½ç®—æ³•è§£å†³æ–¹æ¡ˆæ¥è¯†åˆ«æ‰€æ”¶é›†å›¾åƒä¸­çš„æŸäº›ç‰©ä½“ï¼Œä½†ä»å­˜åœ¨è®¸å¤šå›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, after beginning with the feature subset including no features, the forward sequential search process generates three feature subsets, each containing just one of X, Y, or Z (shown in the second column of Figure 5.19[228]).",
            "zh": "ä¾‹å¦‚ï¼Œä»ä¸åŒ…å«ç‰¹å¾çš„ç‰¹å¾å­é›†å¼€å§‹ï¼Œå‰å‘é¡ºåºæœç´¢è¿‡ç¨‹ä¼šç”Ÿæˆä¸‰ä¸ªç‰¹å¾å­é›†ï¼Œæ¯ä¸ªå­é›†ä»…åŒ…å« Xã€Y æˆ– Z ä¸­çš„ä¸€ä¸ªï¼ˆå¦‚å›¾ 5.19[228] çš„ç¬¬äºŒåˆ—æ‰€ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.2",
            "zh": "å›¾ A.2"
        }
    },
    {
        "translation": {
            "en": "If a descriptive feature is found to have a significant impact on the model, this indicates that there is a significant linear relationship between it and the target feature.",
            "zh": "å¦‚æœå‘ç°æè¿°æ€§ç‰¹å¾å¯¹æ¨¡å‹æœ‰æ˜¾è‘—å½±å“ï¼Œåˆ™è¡¨æ˜å®ƒä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„çº¿æ€§å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Information-Based Learning",
            "zh": "ä¿¡æ¯åŒ–å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "This means that, similar to the thresholded multivariate linear regression models, a perceptron is able to represent a function that distinguishes between two classes of inputs if these two classes are linearly separable.",
            "zh": "è¿™æ„å‘³ç€ï¼Œä¸é˜ˆå€¼å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹ç±»ä¼¼ï¼Œå¦‚æœä¸¤ç±»è¾“å…¥æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ï¼Œåˆ™æ„ŸçŸ¥å™¨èƒ½å¤Ÿè¡¨ç¤ºåŒºåˆ†ä¸¤ç±»è¾“å…¥çš„å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.2318",
            "zh": "-0.2318"
        }
    },
    {
        "translation": {
            "en": "After getting to know the data, the second goal of data exploration is to identify any data quality issues in an ABT. A data quality issue is loosely defined as anything unusual about the data in an ABT. The most common data quality issues, however, are missing values, irregular cardinality problems, and outliers. In this section we describe each of these data quality issues and outline how the data quality report can be used to identify them.",
            "zh": "äº†è§£æ•°æ®åï¼Œæ•°æ®æ¢ç´¢çš„ç¬¬äºŒä¸ªç›®æ ‡æ˜¯è¯†åˆ« ABT ä¸­çš„ä»»ä½•æ•°æ®è´¨é‡é—®é¢˜ã€‚æ•°æ®è´¨é‡é—®é¢˜è¢«æ¾æ•£åœ°å®šä¹‰ä¸º ABT ä¸­æ•°æ®çš„ä»»ä½•å¼‚å¸¸æƒ…å†µã€‚ç„¶è€Œï¼Œæœ€å¸¸è§çš„æ•°æ®è´¨é‡é—®é¢˜æ˜¯ç¼ºå¤±å€¼ã€ä¸è§„åˆ™åŸºæ•°é—®é¢˜å’Œå¼‚å¸¸å€¼ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é€ä¸€ä»‹ç»è¿™äº›æ•°æ®è´¨é‡é—®é¢˜ï¼Œå¹¶æ¦‚è¿°å¦‚ä½•ä½¿ç”¨æ•°æ®è´¨é‡æŠ¥å‘Šæ¥è¯†åˆ«è¿™äº›é—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The type of vegetation in an area is stored in the target feature, VEGETATION.",
            "zh": "åŒºåŸŸä¸­çš„æ¤è¢«ç±»å‹å­˜å‚¨åœ¨ç›®æ ‡è¦ç´  VEGETATION ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "When we weight the contribution to a prediction of each of the neighbors by the reciprocal of the distance to the query, we can actually set k to be equal to the size of the training set and therefore include all the training instances in the prediction process. The issue of losing the true pattern of the data is less acute now because the training instances that are very far away from the query naturally wonâ€™t have much of an effect on the prediction.",
            "zh": "å½“æˆ‘ä»¬é€šè¿‡æŸ¥è¯¢è·ç¦»çš„å€’æ•°æ¥åŠ æƒå¯¹æ¯ä¸ªé‚»å±…çš„é¢„æµ‹çš„è´¡çŒ®æ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥å°† k è®¾ç½®ä¸ºç­‰äºè®­ç»ƒé›†çš„å¤§å°ï¼Œä»è€Œåœ¨é¢„æµ‹è¿‡ç¨‹ä¸­åŒ…æ‹¬æ‰€æœ‰è®­ç»ƒå®ä¾‹ã€‚ç°åœ¨ï¼Œä¸¢å¤±æ•°æ®çœŸå®æ¨¡å¼çš„é—®é¢˜å·²ç»ä¸é‚£ä¹ˆä¸¥é‡äº†ï¼Œå› ä¸ºç¦»æŸ¥è¯¢å¾ˆè¿œçš„è®­ç»ƒå®ä¾‹è‡ªç„¶ä¸ä¼šå¯¹é¢„æµ‹äº§ç”Ÿå¤ªå¤§å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated the Î´s for the neurons in these layers, we have two further sets of calculations to perform in order to complete the backpropagation through the LSTM. First, we need to calculate the updates for each weight in each of these layers; and second, we need to calculate the vector of gradients âˆ‚â„°t/âˆ‚htâˆ’1 that are backpropagated to the previous time-step.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†è¿™äº›å±‚ä¸­ç¥ç»å…ƒçš„Î´sï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸¤ç»„è®¡ç®—è¦æ‰§è¡Œï¼Œä»¥å®Œæˆé€šè¿‡LSTMçš„åå‘ä¼ æ’­ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€å±‚ä¸­æ¯ä¸ªæƒé‡çš„æ›´æ–°;å…¶æ¬¡ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—åå‘ä¼ æ’­åˆ°å‰ä¸€ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦ âˆ‚Et/âˆ‚htâˆ’1 çš„å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "clustering, 597, 599, 603, 629",
            "zh": "èšç±»ï¼Œ 597ï¼Œ 599ï¼Œ 603ï¼Œ 629"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions and scores.",
            "zh": "å…·æœ‰æ¨¡å‹é¢„æµ‹å’Œåˆ†æ•°çš„ç¤ºä¾‹æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "To use discounted return in the action-value function it is restated",
            "zh": "ä¸ºäº†åœ¨è¡ŒåŠ¨ä»·å€¼å‡½æ•°ä¸­ä½¿ç”¨è´´ç°å›æŠ¥ï¼Œå®ƒè¢«é‡è¿°"
        }
    },
    {
        "translation": {
            "en": "That is, they optimize the action-value function and do not rely on having a model of how the world behaves.",
            "zh": "ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬ä¼˜åŒ–äº†è¡ŒåŠ¨ä»·å€¼å‡½æ•°ï¼Œå¹¶ä¸”ä¸ä¾èµ–äºä¸–ç•Œè¡Œä¸ºçš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The performance measures for each fold (in this case, a confusion matrix and a class accuracy measure) can be aggregated into summary performance measures that capture the overall performance across the 5 folds.",
            "zh": "æ¯ä¸ªæŠ˜å çš„æ€§èƒ½åº¦é‡ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæ··æ·†çŸ©é˜µå’Œç±»å‡†ç¡®åº¦é‡ï¼‰å¯ä»¥èšåˆä¸ºæ±‡æ€»æ€§èƒ½åº¦é‡ï¼Œä»¥æ•è· 5 ä¸ªæŠ˜å çš„æ•´ä½“æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "central tendency, 54, 550, 745",
            "zh": "ä¸­å¿ƒè¶‹åŠ¿ï¼Œ 54ï¼Œ 550ï¼Œ 745"
        }
    },
    {
        "translation": {
            "en": "polynomial kernel, 366",
            "zh": "å¤šé¡¹å¼æ ¸ï¼Œ366"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature DIA. B.P. and the target feature, TACHYCARDIA.",
            "zh": "ï¼ˆaï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†è¿ç»­ç‰¹å¾ DIA. BP ä¸ç›®æ ‡ç‰¹å¾ TAWCARDIA ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.4016",
            "zh": "0.4016"
        }
    },
    {
        "translation": {
            "en": "2.4.2â€…â€…â€…Different Types of Features",
            "zh": "2.4.2 ä¸åŒç±»å‹çš„åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "Furthermore, basis functions work for both simple multivariable linear regression models that predict a continuous target feature and multivariable logistic regression models that predict a categorical target feature.",
            "zh": "æ­¤å¤–ï¼ŒåŸºå‡½æ•°æ—¢é€‚ç”¨äºé¢„æµ‹è¿ç»­ç›®æ ‡ç‰¹å¾çš„ç®€å•å¤šå˜é‡çº¿æ€§å›å½’æ¨¡å‹ï¼Œä¹Ÿé€‚ç”¨äºé¢„æµ‹åˆ†ç±»ç›®æ ‡ç‰¹å¾çš„å¤šå˜é‡é€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4â€…â€…â€…Extensions and Variations",
            "zh": "10.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Another consequence of the normal distribution having light tails is that it is sensitive to outliers in the data.",
            "zh": "å…·æœ‰å…‰å°¾çš„æ­£æ€åˆ†å¸ƒçš„å¦ä¸€ä¸ªç»“æœæ˜¯å®ƒå¯¹æ•°æ®ä¸­çš„å¼‚å¸¸å€¼å¾ˆæ•æ„Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "28. See Chapter 8[319].",
            "zh": "[28]è§ç¬¬8ç« [319]ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) Feature distributions",
            "zh": "ï¼ˆdï¼‰ ç‰¹å¾åˆ†å¸ƒ"
        }
    },
    {
        "translation": {
            "en": "The majority target level predicted at the root node of this subtree (the GENDER node) gives a correct prediction of icu for each of the three instances, so the error rate on the validation set for the root node of the subtree is 0.",
            "zh": "åœ¨æ­¤å­æ ‘çš„æ ¹èŠ‚ç‚¹ï¼ˆGENDER èŠ‚ç‚¹ï¼‰é¢„æµ‹çš„å¤šæ•°ç›®æ ‡çº§åˆ«ç»™å‡ºäº†ä¸‰ä¸ªå®ä¾‹ä¸­æ¯ä¸ªå®ä¾‹çš„ icu çš„æ­£ç¡®é¢„æµ‹ï¼Œå› æ­¤å­æ ‘æ ¹èŠ‚ç‚¹çš„éªŒè¯é›†çš„é”™è¯¯ç‡ä¸º 0ã€‚"
        }
    },
    {
        "translation": {
            "en": "So we would expect that the model would predict no and that the customer would not be contacted.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬æœŸæœ›æ¨¡å‹å°†é¢„æµ‹å¦ï¼Œå¹¶ä¸”ä¸ä¼šè”ç³»å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "A final useful tool is to rank the importance of each descriptive feature in defining membership of each cluster.",
            "zh": "æœ€åä¸€ä¸ªæœ‰ç”¨çš„å·¥å…·æ˜¯åœ¨å®šä¹‰æ¯ä¸ªé›†ç¾¤çš„æˆå‘˜èµ„æ ¼æ—¶å¯¹æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„é‡è¦æ€§è¿›è¡Œæ’åºã€‚"
        }
    },
    {
        "translation": {
            "en": "This indicates that this binning does not accurately represent the real distribution of values in the underlying continuous feature.",
            "zh": "è¿™è¡¨æ˜æ­¤åˆ†ç®±ä¸èƒ½å‡†ç¡®è¡¨ç¤ºåŸºç¡€è¿ç»­è¦ç´ ä¸­å€¼çš„å®é™…åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5(d)[124] shows one card type to be more present than the others, so the overall entropy is slightly lower, 1.50 bits.",
            "zh": "å›¾4.5ï¼ˆdï¼‰[124]æ˜¾ç¤ºä¸€ç§å¡ç±»å‹æ¯”å…¶ä»–å¡ç±»å‹æ›´å¸¸è§ï¼Œå› æ­¤æ•´ä½“ç†µç•¥ä½ï¼Œä¸º1.50ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The density of the marked hypercube is .",
            "zh": "æ ‡è®°çš„è¶…ç«‹æ–¹ä½“çš„å¯†åº¦ä¸º ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.10",
            "zh": "0.10"
        }
    },
    {
        "translation": {
            "en": "We discussed the problem of large weight updates in Chapter 7[311] Section 7.4.2[334], in which we compared the effect of different learning rates and introduced the idea of using learning rate decay.",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬ 7 ç« [311] ç¬¬ 7.4.2 èŠ‚[334] ä¸­è®¨è®ºäº†å¤§é‡æƒé‡æ›´æ–°çš„é—®é¢˜ï¼Œå…¶ä¸­æˆ‘ä»¬æ¯”è¾ƒäº†ä¸åŒå­¦ä¹ ç‡çš„å½±å“ï¼Œå¹¶å¼•å…¥äº†ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡çš„æ€æƒ³ã€‚"
        }
    },
    {
        "translation": {
            "en": "When a customer used up all the call time in his or her bundle, subsequent call time was referred to as over bundle minutes.",
            "zh": "å½“å®¢æˆ·ç”¨å®Œäº†ä»–æˆ–å¥¹çš„æ†ç»‘åŒ…ä¸­çš„æ‰€æœ‰å‘¼å«æ—¶é—´æ—¶ï¼Œéšåçš„å‘¼å«æ—¶é—´ç§°ä¸ºè¶…è¿‡æ†ç»‘åˆ†é’Ÿæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "1. It is appropriate to use a game involving gambling to introduce probability-based machine learning. The origins of probability theory come from attempts to understand gambling and games of chance, in particular, the work of Gerolamo Cardano and the later work of Pierre de Fermat and Blaise Pascal.",
            "zh": "1. ä½¿ç”¨æ¶‰åŠèµŒåšçš„æ¸¸æˆæ¥å¼•å…¥åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ æ˜¯åˆé€‚çš„ã€‚æ¦‚ç‡è®ºçš„èµ·æºæ¥è‡ªå¯¹èµŒåšå’Œæœºä¼šæ¸¸æˆçš„ç†è§£ï¼Œç‰¹åˆ«æ˜¯æ°ç½—æ‹‰è«Â·å¡å°”è¾¾è¯ºï¼ˆGerolamo Cardanoï¼‰çš„å·¥ä½œä»¥åŠçš®åŸƒå°”Â·å¾·Â·è´¹é©¬ï¼ˆPierre de Fermatï¼‰å’Œå¸ƒè±æ–¯Â·å¸•æ–¯å¡ï¼ˆBlaise Pascalï¼‰çš„åæœŸå·¥ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C. 2012. Design and analysis of experiments. Wiley.",
            "zh": "è’™å“¥é©¬åˆ©ï¼Œé“æ ¼æ‹‰æ–¯ C. 2012 å¹´ã€‚å®éªŒçš„è®¾è®¡å’Œåˆ†æã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39[506] illustrates the path taken by the error gradients as each error for each time-step is backpropagated through the network.",
            "zh": "å›¾8.39[506]è¯´æ˜äº†è¯¯å·®æ¢¯åº¦æ‰€é‡‡ç”¨çš„è·¯å¾„ï¼Œå› ä¸ºæ¯ä¸ªæ—¶é—´æ­¥é•¿çš„æ¯ä¸ªè¯¯å·®éƒ½é€šè¿‡ç½‘ç»œåå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "These tended to be more expensive than the minutes included as part of a customerâ€™s bundle.",
            "zh": "è¿™äº›å¾€å¾€æ¯”å®¢æˆ·æ†ç»‘åŒ…ä¸­åŒ…å«çš„åˆ†é’Ÿæ•°æ›´æ˜‚è´µã€‚"
        }
    },
    {
        "translation": {
            "en": "where At and St are random variables that can be assigned specific states and actions; and the policy, Ï€, returns a probability distribution across the possible actions that an agent can take in a given state.",
            "zh": "å…¶ä¸­ At å’Œ St æ˜¯éšæœºå˜é‡ï¼Œå¯ä»¥åˆ†é…ç‰¹å®šçš„çŠ¶æ€å’ŒåŠ¨ä½œ;ç­–ç•¥ Ï€ è¿”å›ä»£ç†åœ¨ç»™å®šçŠ¶æ€ä¸‹å¯ä»¥é‡‡å–çš„å¯èƒ½æ“ä½œçš„æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The fact that similarity-based models attempt to mimic a way of reasoning that is natural to humans makes them easy to interpret and understand.",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„æ¨¡å‹è¯•å›¾æ¨¡ä»¿äººç±»è‡ªç„¶çš„æ¨ç†æ–¹å¼ï¼Œè¿™ä¸€äº‹å®ä½¿å®ƒä»¬æ˜“äºè§£é‡Šå’Œç†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.19(a)[158] the pruning algorithm considers the subtree under the GENDER node for pruning.",
            "zh": "åœ¨å›¾4.19ï¼ˆaï¼‰[158]ä¸­ï¼Œä¿®å‰ªç®—æ³•è€ƒè™‘äº†GENDERèŠ‚ç‚¹ä¸‹çš„å­æ ‘è¿›è¡Œä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "continuous function, 766",
            "zh": "è¿ç»­åŠŸèƒ½ï¼Œ766"
        }
    },
    {
        "translation": {
            "en": "Special Usage: How often a user or customer used services that an organization considers special in some way in the recent past (for example, has a customer called a customer complaints department in the last month?).",
            "zh": "ç‰¹æ®Šç”¨é€”ï¼šç”¨æˆ·æˆ–å®¢æˆ·åœ¨æœ€è¿‘ä½¿ç”¨ç»„ç»‡ä»¥æŸç§æ–¹å¼è®¤ä¸ºç‰¹æ®Šçš„æœåŠ¡çš„é¢‘ç‡ï¼ˆä¾‹å¦‚ï¼Œå®¢æˆ·åœ¨ä¸Šä¸ªæœˆæ˜¯å¦è‡´ç”µå®¢æˆ·æŠ•è¯‰éƒ¨é—¨ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The calculations for the probabilities for the ACCOUNT BALANCE feature are made using the equations for the normal and exponential distributions in Table 6.10[271]. The result is that FRAUD = false still has the highest score and will be returned as the prediction for this query.",
            "zh": "ä½¿ç”¨è¡¨6.10[271]ä¸­çš„æ­£æ€åˆ†å¸ƒå’ŒæŒ‡æ•°åˆ†å¸ƒæ–¹ç¨‹è®¡ç®—è´¦æˆ·ä½™é¢ç‰¹å¾çš„æ¦‚ç‡ã€‚ç»“æœæ˜¯ FRAUD = false ä»ç„¶å…·æœ‰æœ€é«˜åˆ†ï¼Œå¹¶å°†ä½œä¸ºæ­¤æŸ¥è¯¢çš„é¢„æµ‹è¿”å›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.22",
            "zh": "å›¾ 4.22"
        }
    },
    {
        "translation": {
            "en": "high risk",
            "zh": "é«˜é£é™©"
        }
    },
    {
        "translation": {
            "en": "The clustering in Figure 10.4(h)[606] is particularly unlucky, as one of the clusters has remained empty!4",
            "zh": "å›¾10.4ï¼ˆhï¼‰[606]ä¸­çš„èšç±»ç‰¹åˆ«ä¸èµ°è¿ï¼Œå› ä¸ºå…¶ä¸­ä¸€ä¸ªèšç±»ä»ç„¶æ˜¯ç©ºçš„ï¼4"
        }
    },
    {
        "translation": {
            "en": "However, to do this summing out, we must know the distribution for the unknown parent, which in turn requires us to sum out the parents of the parent, and so on if necessary.",
            "zh": "ä½†æ˜¯ï¼Œè¦è¿›è¡Œè¿™ç§æ±‚å’Œï¼Œæˆ‘ä»¬å¿…é¡»çŸ¥é“æœªçŸ¥çˆ¶é¡¹çš„åˆ†å¸ƒï¼Œè¿™åè¿‡æ¥åˆè¦æ±‚æˆ‘ä»¬æ±‚å’Œçˆ¶é¡¹çš„äº²é¡¹ï¼Œå¿…è¦æ—¶ä¾æ­¤ç±»æ¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "This, however, can result in massive, and frequently needless, loss of data.",
            "zh": "ä½†æ˜¯ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´å¤§é‡ä¸”ç»å¸¸ä¸å¿…è¦çš„æ•°æ®ä¸¢å¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bibliography",
            "zh": "ä¹¦ç›®"
        }
    },
    {
        "translation": {
            "en": "The reduction from 16 to 7 probabilities to represent this domain may not seem to achieve much, but there are two things to bear in mind.",
            "zh": "ä» 16 ä¸ªæ¦‚ç‡å‡å°‘åˆ° 7 ä¸ªæ¦‚ç‡æ¥è¡¨ç¤ºè¿™ä¸ªé¢†åŸŸä¼¼ä¹å¹¶æ²¡æœ‰å–å¾—å¤šå¤§æˆå°±ï¼Œä½†æœ‰ä¸¤ä»¶äº‹éœ€è¦ç‰¢è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The appropriate kernel function for a particular prediction model should be selected by experimenting with different options. It is best to start with a simple linear or low-degree polynomial kernel function and move to more complex kernel functions only if good performance cannot be achieved with this.",
            "zh": "åº”é€šè¿‡è¯•éªŒä¸åŒçš„é€‰é¡¹æ¥é€‰æ‹©ç‰¹å®šé¢„æµ‹æ¨¡å‹çš„é€‚å½“æ ¸å‡½æ•°ã€‚æœ€å¥½ä»ç®€å•çš„çº¿æ€§æˆ–ä½é˜¶å¤šé¡¹å¼æ ¸å‡½æ•°å¼€å§‹ï¼Œåªæœ‰åœ¨æ— æ³•å®ç°è‰¯å¥½æ€§èƒ½æ—¶æ‰è½¬å‘æ›´å¤æ‚çš„æ ¸å‡½æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "ğ’Ÿ denotes a dataset.",
            "zh": "D è¡¨ç¤ºæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "SS-IN measures the solids coming into the plant per day; SED-IN measures the sediment coming into the plant per day; COND-IN measures the electrical conductivity of the water coming into the plant.34 The features SS-OUT, SED-OUT, and COND-OUT are the corresponding measurements for the water flowing out of the plant.",
            "zh": "SS-INæµ‹é‡æ¯å¤©è¿›å…¥å·¥å‚çš„å›ºä½“;SED-INæµ‹é‡æ¯å¤©è¿›å…¥å·¥å‚çš„æ²‰ç§¯ç‰©;COND-INæµ‹é‡è¿›å…¥å·¥å‚çš„æ°´çš„ç”µå¯¼ç‡.34 SS-OUTã€SED-OUT å’Œ COND-OUT åŠŸèƒ½æ˜¯æµå‡ºå·¥å‚çš„æ°´çš„ç›¸åº”æµ‹é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bellman, R. E. 1957b. A markov decision process. Journal of Mathematical Mechanics 6: 679â€“684.",
            "zh": "è´å°”æ›¼ï¼Œ R. E. 1957b.é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ã€‚æ•°å­¦åŠ›å­¦æ‚å¿— 6ï¼š679â€“684ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, in the vast majority of machine learning projects, the training set represents only a small sample of the possible set of instances in the domain.",
            "zh": "å…¶æ¬¡ï¼Œåœ¨ç»å¤§å¤šæ•°æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­ï¼Œè®­ç»ƒé›†ä»…ä»£è¡¨åŸŸä¸­å¯èƒ½å®ä¾‹é›†çš„ä¸€å°éƒ¨åˆ†æ ·æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "invalid data, 63, 94",
            "zh": "æ— æ•ˆæ•°æ®ï¼Œ 63ï¼Œ 94"
        }
    },
    {
        "translation": {
            "en": "A dataset showing participantsâ€™ responses to viewing positive and negative images measured on the EEG P20 and P45 potentials.",
            "zh": "ä¸€ä¸ªæ•°æ®é›†ï¼Œæ˜¾ç¤ºå‚ä¸è€…å¯¹è§‚çœ‹åœ¨ EEG P20 å’Œ P45 ç”µä½ä¸Šæµ‹é‡çš„æ­£è´Ÿå›¾åƒçš„ååº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Goldberg, Yoav. 2017. Neural network methods for natural language processing. Synthesis lectures on human language technology. Morgan and Claypool.",
            "zh": "æˆˆå¾·å ¡ï¼Œçº¦å¤«ã€‚2017. è‡ªç„¶è¯­è¨€å¤„ç†çš„ç¥ç»ç½‘ç»œæ–¹æ³•.å…³äºäººç±»è¯­è¨€æŠ€æœ¯çš„ç»¼åˆè®²åº§ã€‚æ‘©æ ¹å’Œå…‹è±æ™®å°”ã€‚"
        }
    },
    {
        "translation": {
            "en": "replay memory, 671",
            "zh": "é‡æ’­è®°å¿†ï¼Œ671"
        }
    },
    {
        "translation": {
            "en": "An analytics consultant has been hired by a major hospital to build a predictive model that predicts the likelihood that a patient at a heart disease clinic will suffer from tachycardia in the month following a visit to the clinic.",
            "zh": "ä¸€å®¶å¤§åŒ»é™¢è˜è¯·äº†ä¸€ååˆ†æé¡¾é—®æ¥å»ºç«‹ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥é¢„æµ‹å¿ƒè„ç—…è¯Šæ‰€çš„æ‚£è€…åœ¨å°±è¯Šåçš„ä¸€ä¸ªæœˆå†…æ‚£å¿ƒåŠ¨è¿‡é€Ÿçš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, Wyh was involved once in the generation of y3 whereas Whh and Whx were involved three times.",
            "zh": "ä¾‹å¦‚ï¼ŒWyh å‚ä¸äº† y3 çš„ç”Ÿæˆï¼Œè€Œ Whh å’Œ Whx å‚ä¸äº†ä¸‰æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This would make the training process likely to become stuck in something approaching a local minimum.",
            "zh": "è¿™å°†ä½¿è®­ç»ƒè¿‡ç¨‹å¯èƒ½ä¼šé™·å…¥æ¥è¿‘å±€éƒ¨æœ€å°å€¼çš„èŒƒå›´å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.5â€…â€…â€…Summary",
            "zh": "11.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "1.4â€…â€…â€…A diagram of the CRISP-DM process that shows the six key phases and indicates the important relationships between them.",
            "zh": "1.4 CRISP-DMè¿‡ç¨‹å›¾ï¼Œæ˜¾ç¤ºäº†å…­ä¸ªå…³é”®é˜¶æ®µï¼Œå¹¶æŒ‡å‡ºäº†å®ƒä»¬ä¹‹é—´çš„é‡è¦å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Table 9.17[572] we have included precision and recall measures for each target level. Precision and recall are calculated in almost exactly the same way for multinomial problems as for binary problems. Abandoning the notion of positive and negative target levels, we get",
            "zh": "åœ¨è¡¨9.17[572]ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†æ¯ä¸ªç›®æ ‡æ°´å¹³çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡æªæ–½ã€‚å¤šé¡¹å¼é—®é¢˜çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„è®¡ç®—æ–¹å¼ä¸äºŒå…ƒé—®é¢˜å‡ ä¹å®Œå…¨ç›¸åŒã€‚æ‘’å¼ƒæ­£è´Ÿç›®æ ‡æ°´å¹³çš„æ¦‚å¿µï¼Œæˆ‘ä»¬å¾—åˆ°"
        }
    },
    {
        "translation": {
            "en": "YEARSINCURRENTEMPLOYMENT",
            "zh": "å¹´é™åœ¨èŒ"
        }
    },
    {
        "translation": {
            "en": "3. The predictive task in this question is to predict the level of corruption in a country based on a range of macroeconomic and social features. The table below lists some countries described by the following descriptive features:",
            "zh": "3. æœ¬é—®é¢˜çš„é¢„æµ‹ä»»åŠ¡æ˜¯æ ¹æ®ä¸€ç³»åˆ—å®è§‚ç»æµå’Œç¤¾ä¼šç‰¹å¾é¢„æµ‹ä¸€ä¸ªå›½å®¶çš„è…è´¥ç¨‹åº¦ã€‚ä¸‹è¡¨åˆ—å‡ºäº†ä»¥ä¸‹æè¿°æ€§ç‰¹å¾æ‰€æè¿°çš„ä¸€äº›å›½å®¶/åœ°åŒºï¼š"
        }
    },
    {
        "translation": {
            "en": "AlexNet is one of the most famous convolutional networks in the history of deep learning.",
            "zh": "AlexNetæ˜¯æ·±åº¦å­¦ä¹ å²ä¸Šæœ€è‘—åçš„å·ç§¯ç½‘ç»œä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The relevant smoothed probabilities, from Table 6.8[269], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each target levels.",
            "zh": "æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹éœ€è¦è¡¨ 6.8[269] ä¸­çš„ç›¸å…³å¹³æ»‘æ¦‚ç‡ï¼Œä»¥ä¾¿å¯¹ CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, letâ€™s return to the example query instance for the meningitis diagnosis problem, where HEADACHE = true, FEVER = true, and VOMITING = false.",
            "zh": "ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬å›åˆ°è„‘è†œç‚è¯Šæ–­é—®é¢˜çš„ç¤ºä¾‹æŸ¥è¯¢å®ä¾‹ï¼Œå…¶ä¸­ HEADACHE = trueï¼ŒFEVER = trueï¼ŒVOMITING = falseã€‚"
        }
    },
    {
        "translation": {
            "en": "These are the descriptive features in this dataset, and the target feature, TYPE, indicates whether the subject was viewing a positive or a negative image.",
            "zh": "è¿™äº›æ˜¯æ­¤æ•°æ®é›†ä¸­çš„æè¿°æ€§ç‰¹å¾ï¼Œç›®æ ‡ç‰¹å¾ TYPE æŒ‡ç¤ºå—è¯•è€…æ˜¯æŸ¥çœ‹æ­£å›¾åƒè¿˜æ˜¯è´Ÿå›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places, and with the (binned) target feature represented using one-hot encoding.",
            "zh": "è”åˆå¾ªç¯ç”µå‚çš„ç¯å¢ƒå› å­å’Œæ»¡è´Ÿè·ç”µåŠ›è¾“å‡ºçš„èŒƒå›´å½’ä¸€åŒ–å°æ—¶æ ·æœ¬ï¼Œå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼Œå¹¶ä½¿ç”¨å•çƒ­ç¼–ç è¡¨ç¤ºï¼ˆåˆ†æ¡£ï¼‰ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of a profit matrix.",
            "zh": "åˆ©æ¶¦çŸ©é˜µçš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The updated version of Table 5.6[206] once we have applied range normalization to the SALARY and AGE features in the dataset and to the query instance.",
            "zh": "è¡¨ 5.6[206] çš„æ›´æ–°ç‰ˆæœ¬ï¼Œä¸€æ—¦æˆ‘ä»¬å°†èŒƒå›´å½’ä¸€åŒ–åº”ç”¨äºæ•°æ®é›†ä¸­çš„ SALARY å’Œ AGE ç‰¹å¾ä»¥åŠæŸ¥è¯¢å®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross confirmed with Grace and Kate that these were valid outliersâ€”for example, some handsets are given away for free, and some customers just make a lot of calls.",
            "zh": "ç½—æ–¯å‘æ ¼è•¾ä¸å’Œå‡¯ç‰¹è¯å®ï¼Œè¿™äº›éƒ½æ˜¯æœ‰æ•ˆçš„å¼‚å¸¸å€¼â€”â€”ä¾‹å¦‚ï¼Œä¸€äº›æ‰‹æœºæ˜¯å…è´¹èµ é€çš„ï¼Œæœ‰äº›å®¢æˆ·åªæ˜¯æ‰“äº†å¾ˆå¤šç”µè¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of this dataset is shown in Figure 7.14[349], in which the overlap between the different types of generator in this dataset is clearly visible.",
            "zh": "è¯¥æ•°æ®é›†çš„æ•£ç‚¹å›¾å¦‚å›¾ 7.14[349] æ‰€ç¤ºï¼Œå…¶ä¸­è¯¥æ•°æ®é›†ä¸­ä¸åŒç±»å‹çš„ç”Ÿæˆå™¨ä¹‹é—´çš„é‡å æ¸…æ™°å¯è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Weight",
            "zh": "é‡é‡"
        }
    },
    {
        "translation": {
            "en": "Ross strongly considered removing these features entirely.",
            "zh": "Ross å¼ºçƒˆè€ƒè™‘å®Œå…¨åˆ é™¤è¿™äº›åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The difference in how âˆ‚â„°/âˆ‚ak is calculated for output and hidden neurons is how Equation (8.14)[408] generalizes over all the neurons in the network.",
            "zh": "è¾“å‡ºç¥ç»å…ƒå’Œéšè—ç¥ç»å…ƒçš„ âˆ‚E/âˆ‚ak è®¡ç®—æ–¹å¼çš„å·®å¼‚åœ¨äºæ–¹ç¨‹ ï¼ˆ8.14ï¼‰[408] å¦‚ä½•æ¨å¹¿ç½‘ç»œä¸­çš„æ‰€æœ‰ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "We use subscripts on uppercase letters to iterate over events. So, âˆ‘iP(Xi) should be interpreted as summing over the set of events that are a complete assignment to the features in X (i.e., all the possible combinations of value assignments to the features in X).",
            "zh": "æˆ‘ä»¬åœ¨å¤§å†™å­—æ¯ä¸Šä½¿ç”¨ä¸‹æ ‡æ¥è¿­ä»£äº‹ä»¶ã€‚å› æ­¤ï¼Œâˆ‘iPï¼ˆä¹ ï¼‰ åº”è¯¥è¢«è§£é‡Šä¸ºå¯¹ X ä¸­ç‰¹å¾çš„å®Œæ•´èµ‹å€¼ï¼ˆå³å¯¹ X ä¸­ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½å€¼èµ‹å€¼ç»„åˆï¼‰çš„äº‹ä»¶é›†æ±‚å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "filter dimension, 486",
            "zh": "è¿‡æ»¤å™¨å°ºå¯¸ï¼Œ486"
        }
    },
    {
        "translation": {
            "en": "This property of weighted sum calculations can result in unstable dynamics in both the forward and backward pass of the backpropagation algorithm because weighted sum calculations are used in both these phases; in the forward pass the calculation of the z value for each neuron is done using a weighted sum, and in the backward pass the calculation of a Î´ for a neuron includes the calculation of the term âˆ‚â„°/âˆ‚ak which is a weighted sum of the Î´s backpropagated to that neuron (see Equation 8.22[412]).",
            "zh": "åŠ æƒå’Œè®¡ç®—çš„è¿™ç§ç‰¹æ€§å¯èƒ½å¯¼è‡´åå‘ä¼ æ’­ç®—æ³•çš„å‰å‘å’Œåå‘ä¼ é€’éƒ½ä¸ç¨³å®šçš„åŠ¨æ€ï¼Œå› ä¸ºåœ¨è¿™ä¸¤ä¸ªé˜¶æ®µéƒ½ä½¿ç”¨äº†åŠ æƒå’Œè®¡ç®—;åœ¨å‰å‘ä¼ é€’ä¸­ï¼Œä½¿ç”¨åŠ æƒå’Œè®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„ z å€¼ï¼Œåœ¨å‘åä¼ é€’ä¸­ï¼Œç¥ç»å…ƒçš„Î´è®¡ç®—åŒ…æ‹¬é¡¹ âˆ‚E/âˆ‚ak çš„è®¡ç®—ï¼Œå®ƒæ˜¯åå‘ä¼ æ’­åˆ°è¯¥ç¥ç»å…ƒçš„ Î´s çš„åŠ æƒå’Œï¼ˆå‚è§ç­‰å¼ 8.22[412]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. Have identified any data quality issues within the ABT, in particular, missing values, irregular cardinality, and outliers.",
            "zh": "2. å·²å‘ç° ABT ä¸­çš„ä»»ä½•æ•°æ®è´¨é‡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ç¼ºå¤±å€¼ã€ä¸è§„åˆ™åŸºæ•°å’Œå¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "From the histograms in Figure 3.1[58], we see that all the continuous features except for INCOME and FRAUD FLAG seem to follow an exponential distribution pretty closely. INCOME is interesting as it seems to follow what looks like a normal distribution except that there is one large bar at about 0. The distribution of the FRAUD FLAG feature that can be seen in its histogram is not typical of a continuous feature.",
            "zh": "ä»å›¾ 3.1[58] ä¸­çš„ç›´æ–¹å›¾ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°é™¤äº† INCOME å’Œ FRAUD FLAG ä¹‹å¤–çš„æ‰€æœ‰è¿ç»­ç‰¹å¾ä¼¼ä¹éƒ½éå¸¸æ¥è¿‘åœ°éµå¾ªæŒ‡æ•°åˆ†å¸ƒã€‚INCOME å¾ˆæœ‰è¶£ï¼Œå› ä¸ºå®ƒä¼¼ä¹éµå¾ªçœ‹èµ·æ¥åƒæ­£æ€åˆ†å¸ƒçš„ä¸œè¥¿ï¼Œé™¤äº†åœ¨å¤§çº¦ 0 å¤„æœ‰ä¸€ä¸ªå¤§æŸ±ã€‚åœ¨å…¶ç›´æ–¹å›¾ä¸­å¯ä»¥çœ‹åˆ°çš„ FRAUD FLAG ç‰¹å¾çš„åˆ†å¸ƒä¸æ˜¯å…¸å‹çš„è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features tell us three pieces of information about the mortgage: the OCCUPATION (which can be professional or industrial) and AGE of the applicant and the ratio between the applicantâ€™s salary and the amount borrowed (LOAN-SALARY RATIO).",
            "zh": "æè¿°æ€§ç‰¹å¾å‘Šè¯‰æˆ‘ä»¬æœ‰å…³æŠµæŠ¼è´·æ¬¾çš„ä¸‰æ¡ä¿¡æ¯ï¼šç”³è¯·äººçš„èŒä¸šï¼ˆå¯ä»¥æ˜¯ä¸“ä¸šæˆ–å·¥ä¸šï¼‰å’Œå¹´é¾„ï¼Œä»¥åŠç”³è¯·äººçš„å·¥èµ„ä¸å€Ÿæ¬¾é‡‘é¢ä¹‹é—´çš„æ¯”ç‡ï¼ˆè´·æ¬¾-å·¥èµ„æ¯”ç‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the subset generation component of forward sequential selection, the successors of the current best feature subset are the set of feature subsets that can be generated from the current best subset by adding just a single extra feature.",
            "zh": "åœ¨å‰å‘é¡ºåºé€‰æ‹©çš„å­é›†ç”Ÿæˆç»„ä»¶ä¸­ï¼Œå½“å‰æœ€ä½³ç‰¹å¾å­é›†çš„åç»§è€…æ˜¯ä¸€ç»„ç‰¹å¾å­é›†ï¼Œåªéœ€æ·»åŠ ä¸€ä¸ªé¢å¤–ç‰¹å¾å³å¯ä»å½“å‰æœ€ä½³å­é›†ç”Ÿæˆã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, when wrapper-based feature selection techniques are used, a validation set is required in order to evaluate the performance of the different feature subsets on data not used in training.",
            "zh": "ä¾‹å¦‚ï¼Œå½“ä½¿ç”¨åŸºäºåŒ…è£…å™¨çš„ç‰¹å¾é€‰æ‹©æŠ€æœ¯æ—¶ï¼Œéœ€è¦éªŒè¯é›†æ¥è¯„ä¼°ä¸åŒç‰¹å¾å­é›†å¯¹è®­ç»ƒä¸­æœªä½¿ç”¨çš„æ•°æ®çš„æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.1â€ƒBig Idea",
            "zh": "9.1 å¤§åˆ›æ„"
        }
    },
    {
        "translation": {
            "en": "The points in this scatter plot are arranged in a broadly linear pattern diagonally across the scatter plot.",
            "zh": "æ­¤æ•£ç‚¹å›¾ä¸­çš„ç‚¹åœ¨æ•£ç‚¹å›¾ä¸­ä»¥å¤§è‡´çš„çº¿æ€§æ¨¡å¼å¯¹è§’çº¿æ’åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Chandola, Varun, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys (CSUR) 41 (3): 15.",
            "zh": "é’±å¤šæ‹‰ã€ç“¦ä¼¦ã€é˜¿æ—ä¸¹Â·ç­çº³å‰å’Œç»´å¹³Â·åº“é©¬å°”ã€‚2009. å¼‚å¸¸æ£€æµ‹ï¼šä¸€é¡¹è°ƒæŸ¥ã€‚ACM è®¡ç®—è°ƒæŸ¥ ï¼ˆCSURï¼‰ 41 ï¼ˆ3ï¼‰ï¼š 15."
        }
    },
    {
        "translation": {
            "en": "This differential means that the neurons in the first hidden layer will learn more slowly than the neurons output layer.",
            "zh": "è¿™ç§å·®å¼‚æ„å‘³ç€ç¬¬ä¸€ä¸ªéšè—å±‚ä¸­çš„ç¥ç»å…ƒå°†æ¯”ç¥ç»å…ƒè¾“å‡ºå±‚å­¦ä¹ å¾—æ›´æ…¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can use exactly the same idea to evaluate the impact of predictive models.",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æƒ³æ³•æ¥è¯„ä¼°é¢„æµ‹æ¨¡å‹çš„å½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.2",
            "zh": "è¡¨ 4.2"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the target output for time tt = [0,1], calculate the Î´ value for each neuron in the network.",
            "zh": "ï¼ˆbï¼‰ å‡è®¾æ—¶é—´ tt = [0,1] çš„ç›®æ ‡è¾“å‡ºï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "independence, 256, 302",
            "zh": "ç‹¬ç«‹ï¼Œ 256ï¼Œ 302"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, in more realistic datasets, finding a feature as powerful as the SUSPICIOUS WORDS feature is very rare.",
            "zh": "ä¸å¹¸çš„æ˜¯ï¼Œåœ¨æ›´ç°å®çš„æ•°æ®é›†ä¸­ï¼Œæ‰¾åˆ°åƒ SUSPICIOUS WORDS åŠŸèƒ½è¿™æ ·å¼ºå¤§çš„åŠŸèƒ½éå¸¸ç½•è§ã€‚"
        }
    },
    {
        "translation": {
            "en": "The customer billing records stored in the AT billing database, where records stretch back over a time horizon of five years",
            "zh": "å­˜å‚¨åœ¨ AT è®¡è´¹æ•°æ®åº“ä¸­çš„å®¢æˆ·è®¡è´¹è®°å½•ï¼Œå…¶ä¸­è®°å½•å¯ä»¥è¿½æº¯åˆ°äº”å¹´çš„æ—¶é—´èŒƒå›´"
        }
    },
    {
        "translation": {
            "en": "MOTORINS: Whether the customer holds a motor insurance policy with the company (yes or no)",
            "zh": "MOTORINSï¼šå®¢æˆ·æ˜¯å¦æŒæœ‰å…¬å¸çš„æ±½è½¦ä¿é™©å•ï¼ˆæ˜¯æˆ–å¦ï¼‰"
        }
    },
    {
        "translation": {
            "en": "21. This assumption of treating d2 as the first example permits us to use the original w7,5 = âˆ’0.09 in our example calculation rather than the updated value for the weight that would be used if d1 had already been processed and the weights updated accordingly.",
            "zh": "21. å°† d2 è§†ä¸ºç¬¬ä¸€ä¸ªç¤ºä¾‹çš„å‡è®¾å…è®¸æˆ‘ä»¬åœ¨ç¤ºä¾‹è®¡ç®—ä¸­ä½¿ç”¨åŸå§‹ w7,5 = âˆ’0.09ï¼Œè€Œä¸æ˜¯åœ¨ d1 å·²ç»å¤„ç†å¹¶ç›¸åº”æ›´æ–°æƒé‡æ—¶å°†ä½¿ç”¨çš„æƒé‡æ›´æ–°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examples of parametric models include the naive Bayes and Bayesian network models in Chapter 6[243] and the simple linear and logistic regression models in Chapter 7[311].",
            "zh": "å‚æ•°æ¨¡å‹çš„ä¾‹å­åŒ…æ‹¬ç¬¬6ç« [243]ä¸­çš„æœ´ç´ è´å¶æ–¯å’Œè´å¶æ–¯ç½‘ç»œæ¨¡å‹ï¼Œä»¥åŠç¬¬7ç« [311]ä¸­çš„ç®€å•çº¿æ€§å’Œé€»è¾‘å›å½’æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The domain concepts in this instance will be concepts from within the insurance domain that are likely to be important in determining whether a claim is fraudulent.",
            "zh": "æœ¬ä¾‹ä¸­çš„åŸŸæ¦‚å¿µæ˜¯ä¿é™©åŸŸå†…çš„æ¦‚å¿µï¼Œè¿™äº›æ¦‚å¿µå¯¹äºç¡®å®šç´¢èµ”æ˜¯å¦å…·æœ‰æ¬ºè¯ˆæ€§å¯èƒ½å¾ˆé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix for a multinomial prediction problem with l target levels.",
            "zh": "å…·æœ‰ l ä¸ªç›®æ ‡æ°´å¹³çš„å¤šé¡¹å¼é¢„æµ‹é—®é¢˜çš„æ··æ·†çŸ©é˜µç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The histogram for this feature has an unusual shape that results in the unusual minimum, 1st quartile, and median values (see Figure 12.2(g)[695]).",
            "zh": "è¯¥ç‰¹å¾çš„ç›´æ–¹å›¾å…·æœ‰ä¸å¯»å¸¸çš„å½¢çŠ¶ï¼Œå¯¼è‡´ä¸å¯»å¸¸çš„æœ€å°å€¼ã€ç¬¬ä¸€å››åˆ†ä½æ•°å’Œä¸­å€¼ï¼ˆå‚è§å›¾ 12.2ï¼ˆgï¼‰[695]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "p-value, 333",
            "zh": "p å€¼ï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "10.12â€…â€…â€…(a) A plot of a reduced version of the mobile phone customer dataset given in Table 10.1[604]. (b)â€“(d) show details of several iterations of the AHC algorithm.",
            "zh": "10.12 ï¼ˆaï¼‰ è¡¨10.1[604]ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†çš„ç®€åŒ–ç‰ˆå›¾ã€‚ï¼ˆbï¼‰â€“ï¼ˆdï¼‰ æ˜¾ç¤ºäº† AHC ç®—æ³•çš„å‡ æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.18â€…â€…â€…A sample test set with model predictions for a bacterial species identification problem.",
            "zh": "9.18 å…·æœ‰ç»†èŒç‰©ç§è¯†åˆ«é—®é¢˜æ¨¡å‹é¢„æµ‹çš„æ ·æœ¬æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the logistic regression model that distinguished between only the spiral galaxy types (classification accuracy: 68.225%, average class accuracy: 56.621%).",
            "zh": "ä»…åŒºåˆ†èºæ—‹æ˜Ÿç³»ç±»å‹çš„é€»è¾‘å›å½’æ¨¡å‹çš„æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»å‡†ç¡®ç‡ï¼š68.225%ï¼Œå¹³å‡åˆ†ç±»å‡†ç¡®ç‡ï¼š56.621%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "26. The data used in this question has been artificially generated for this book. Mac Namee et al. (2002) is, however, a good example of prediction models used to help doctors select correct drug dosages.",
            "zh": "26. æœ¬é—®é¢˜ä¸­ä½¿ç”¨çš„æ•°æ®æ˜¯ä¸ºæœ¬ä¹¦äººä¸ºç”Ÿæˆçš„ã€‚ç„¶è€Œï¼ŒMac Nameeç­‰äººï¼ˆ2002ï¼‰æ˜¯ç”¨äºå¸®åŠ©åŒ»ç”Ÿé€‰æ‹©æ­£ç¡®è¯ç‰©å‰‚é‡çš„é¢„æµ‹æ¨¡å‹çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Historic call and bill records as well as customer demographic information were stored in a data warehouse.",
            "zh": "å†å²é€šè¯å’Œè´¦å•è®°å½•ä»¥åŠå®¢æˆ·äººå£ç»Ÿè®¡ä¿¡æ¯å­˜å‚¨åœ¨æ•°æ®ä»“åº“ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6(c)[275] overlays the multimodal density curve on top of the three weighted normals.",
            "zh": "å›¾6.6ï¼ˆcï¼‰[275]å°†å¤šæ¨¡æ€å¯†åº¦æ›²çº¿å åŠ åœ¨ä¸‰ä¸ªåŠ æƒæ­£çº¿ä¹‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Preface to the 2nd Edition",
            "zh": "ç¬¬äºŒç‰ˆå‰è¨€"
        }
    },
    {
        "translation": {
            "en": "The minimal amount of information we need is the relative profit associated with each of the different outcomes (TP, TN, FP, or FN) that can arise when a model makes a prediction.",
            "zh": "æˆ‘ä»¬éœ€è¦çš„æœ€å°‘ä¿¡æ¯é‡æ˜¯æ¨¡å‹è¿›è¡Œé¢„æµ‹æ—¶å¯èƒ½äº§ç”Ÿçš„ä¸æ¯ä¸ªä¸åŒç»“æœï¼ˆTPã€TNã€FP æˆ– FNï¼‰ç›¸å…³çš„ç›¸å¯¹åˆ©æ¶¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "The calculation of Î”w7,5 across our four examples.",
            "zh": "åœ¨æˆ‘ä»¬çš„å››ä¸ªç¤ºä¾‹ä¸­è®¡ç®— Î”w7,5ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.3.1â€ƒReceiver operating characteristic curvesâ€ƒThe receiver operating characteristic index (ROC index), which is based on the receiver operating characteristic curve (ROC curve),12 is a widely used performance measure that is calculated using prediction scores.",
            "zh": "9.4.3.1 å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ å—è¯•è€…å·¥ä½œç‰¹å¾æŒ‡æ•°ï¼ˆROCæŒ‡æ•°ï¼‰ä»¥å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ï¼ˆROCæ›²çº¿ï¼‰ä¸ºåŸºç¡€ï¼Œ12æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ€§èƒ½æŒ‡æ ‡ï¼Œä½¿ç”¨é¢„æµ‹åˆ†æ•°è¿›è¡Œè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of these errors is then backpropagated through the unrolled network.",
            "zh": "ç„¶åï¼Œè¿™äº›é”™è¯¯ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä¼šé€šè¿‡å±•å¼€çš„ç½‘ç»œè¿›è¡Œåå‘ä¼ æ’­ã€‚"
        }
    },
    {
        "translation": {
            "en": "10. The paradox of the false positive states that in order to make predictions about a rare event, the model has to be at least as accurate as the event is rare (i.e., the probability of the model making an error has to be less than the probability of the rare event occurring) or there is a significant chance of false positive predictions (i.e., predicting the event when it is not the case). Doctorow (2010) provides an interesting discussion of this phenomenon.",
            "zh": "10. è¯¯æŠ¥çš„æ‚–è®ºæŒ‡å‡ºï¼Œä¸ºäº†å¯¹ç½•è§äº‹ä»¶è¿›è¡Œé¢„æµ‹ï¼Œæ¨¡å‹å¿…é¡»è‡³å°‘ä¸äº‹ä»¶çš„å‡†ç¡®æ€§ä¸€æ ·å‡†ç¡®ï¼ˆå³ï¼Œæ¨¡å‹å‡ºé”™çš„æ¦‚ç‡å¿…é¡»å°äºç½•è§äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ï¼‰ï¼Œæˆ–è€…å­˜åœ¨è¯¯æŠ¥é¢„æµ‹çš„å¾ˆå¤§å‡ ç‡ï¼ˆå³ åœ¨äº‹å®å¹¶éå¦‚æ­¤æ—¶é¢„æµ‹äº‹ä»¶ï¼‰ã€‚Doctorowï¼ˆ2010ï¼‰å¯¹è¿™ç§ç°è±¡è¿›è¡Œäº†æœ‰è¶£çš„è®¨è®ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting histogram is called a density histogram because the height of each bar represents how densely the instances in the dataset that fall within the interval are packed into the area of the bar.",
            "zh": "ç”Ÿæˆçš„ç›´æ–¹å›¾ç§°ä¸ºå¯†åº¦ç›´æ–¹å›¾ï¼Œå› ä¸ºæ¯ä¸ªæ¡å½¢çš„é«˜åº¦è¡¨ç¤ºæ•°æ®é›†ä¸­å±äºåŒºé—´å†…çš„å®ä¾‹å¡«å……åˆ°æ¡å½¢åŒºåŸŸä¸­çš„å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tree pruning identifies and removes subtrees within a decision tree that are likely to be due to noise and sample variance in the training set used to induce it.",
            "zh": "æ ‘ä¿®å‰ªè¯†åˆ«å¹¶åˆ é™¤å†³ç­–æ ‘ä¸­çš„å­æ ‘ï¼Œè¿™äº›å­æ ‘å¯èƒ½æ˜¯ç”±äºç”¨äºè¯±å¯¼å†³ç­–æ ‘çš„è®­ç»ƒé›†ä¸­çš„å™ªå£°å’Œæ ·æœ¬æ–¹å·®é€ æˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "scalar, 771",
            "zh": "æ ‡é‡ï¼Œ771"
        }
    },
    {
        "translation": {
            "en": "In this example, Model 1 approaches perfect performance, Model 4 is barely better than random guessing, and Models 2 and 3 sit somewhere in between these two extremes.",
            "zh": "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ¨¡å‹ 1 æ¥è¿‘å®Œç¾æ€§èƒ½ï¼Œæ¨¡å‹ 4 ä»…æ¯”éšæœºçŒœæµ‹å¥½ä¸€ç‚¹ï¼Œè€Œæ¨¡å‹ 2 å’Œ 3 ä»‹äºè¿™ä¸¤ä¸ªæç«¯ä¹‹é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "where St and St+1 are random variables to which the states at time t and t + 1 are assigned. The full dynamics of a Markov process can be captured in a transition matrix",
            "zh": "å…¶ä¸­ St å’Œ St+1 æ˜¯éšæœºå˜é‡ï¼Œå°†æ—¶é—´ t å’Œ t + 1 çš„çŠ¶æ€åˆ†é…ç»™å®ƒä»¬ã€‚é©¬å°”å¯å¤«è¿‡ç¨‹çš„å…¨éƒ¨åŠ¨åŠ›å­¦å¯ä»¥åœ¨è·ƒè¿çŸ©é˜µä¸­æ•è·"
        }
    },
    {
        "translation": {
            "en": "In probability a domain of interest is represented by a set of random variables.",
            "zh": "åœ¨æ¦‚ç‡ä¸­ï¼Œæ„Ÿå…´è¶£çš„åŸŸç”±ä¸€ç»„éšæœºå˜é‡è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "5.4.6â€ƒFeature Selection",
            "zh": "5.4.6 åŠŸèƒ½é€‰æ‹©"
        }
    },
    {
        "translation": {
            "en": "joint probability distribution, 247, 761",
            "zh": "è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œ247,761"
        }
    },
    {
        "translation": {
            "en": "In the second iteration of the algorithm, the subtree under the STABLE-TEMP node is considered for pruning (highlighted in Figure 4.19(b)[158]).",
            "zh": "åœ¨ç®—æ³•çš„ç¬¬äºŒæ¬¡è¿­ä»£ä¸­ï¼Œè€ƒè™‘å¯¹ STABLE-TEMP èŠ‚ç‚¹ä¸‹çš„å­æ ‘è¿›è¡Œä¿®å‰ªï¼ˆåœ¨å›¾ 4.19ï¼ˆbï¼‰[158] ä¸­çªå‡ºæ˜¾ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "value-based reinforcement learning, 676",
            "zh": "åŸºäºä»·å€¼çš„å¼ºåŒ–å­¦ä¹ ï¼Œ676"
        }
    },
    {
        "translation": {
            "en": "In this situation, knowing that someone has meningitis makes the events of them having a headache and having a fever independent of each other.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒçŸ¥é“æŸäººæ‚£æœ‰è„‘è†œç‚ä¼šä½¿ä»–ä»¬å¤´ç—›å’Œå‘çƒ§çš„äº‹ä»¶å½¼æ­¤ç‹¬ç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "For these reasons we felt the time was right for a second edition of the book.",
            "zh": "å‡ºäºè¿™äº›åŸå› ï¼Œæˆ‘ä»¬è§‰å¾—ç°åœ¨æ˜¯å‡ºç‰ˆè¿™æœ¬ä¹¦ç¬¬äºŒç‰ˆçš„å¥½æ—¶æœºã€‚"
        }
    },
    {
        "translation": {
            "en": "This is unfeasible, however, as for d features, there are 2d different possible feature subsets, which is far too many to evaluate unless d is very small.",
            "zh": "è¿™æ˜¯ä¸å¯è¡Œçš„ï¼Œä½†æ˜¯ï¼Œå¯¹äº d ç‰¹å¾ï¼Œå­˜åœ¨ 2d ä¸åŒçš„å¯èƒ½ç‰¹å¾å­é›†ï¼Œé™¤é d éå¸¸å°ï¼Œå¦åˆ™æ— æ³•è¯„ä¼°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The process of using an unsupervised auto-encoder network to generate a feature representation used to train a supervised model.",
            "zh": "ä½¿ç”¨æ— ç›‘ç£è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œç”Ÿæˆç”¨äºè®­ç»ƒç›‘ç£æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ability of the model to distinguish between clockwise (spiral_cw) and anti-clockwise (spiral_acw) spiral galaxies, however, is extremely poor.",
            "zh": "ç„¶è€Œï¼Œè¯¥æ¨¡å‹åŒºåˆ†é¡ºæ—¶é’ˆï¼ˆspiral_cwï¼‰å’Œé€†æ—¶é’ˆï¼ˆspiral_acwï¼‰èºæ—‹æ˜Ÿç³»çš„èƒ½åŠ›æå·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.5 and that the desired output for this input is 0.9:",
            "zh": "ï¼ˆaï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.5ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æœŸæœ›è¾“å‡ºæ˜¯ 0.9ï¼š"
        }
    },
    {
        "translation": {
            "en": "Datasets",
            "zh": "æ•°æ®"
        }
    },
    {
        "translation": {
            "en": "Table 4.8",
            "zh": "è¡¨ 4.8"
        }
    },
    {
        "translation": {
            "en": "This algorithm can also handle continuous target features.",
            "zh": "æ­¤ç®—æ³•è¿˜å¯ä»¥å¤„ç†è¿ç»­ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Loh, Wei-Yin. 2011. Classification and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1 (1): 14â€“23.",
            "zh": "Lohï¼Œ Wei-Yin.2011. åˆ†ç±»å’Œå›å½’æ ‘.Wileyè·¨å­¦ç§‘è¯„è®ºï¼šæ•°æ®æŒ–æ˜å’ŒçŸ¥è¯†å‘ç°1ï¼ˆ1ï¼‰ï¼š14-23ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this figure, A indicates the central tendency of the dataset in Figure 5.15(c)[219], and the ellipses plot the Mahalanobis distance contours that the distances from A to the instances B and C lie on.",
            "zh": "åœ¨è¯¥å›¾ä¸­ï¼ŒA è¡¨ç¤ºå›¾ 5.15ï¼ˆcï¼‰[219] ä¸­æ•°æ®é›†çš„ä¸­å¿ƒè¶‹åŠ¿ï¼Œæ¤­åœ†ç»˜åˆ¶äº†ä» A åˆ°å®ä¾‹ B å’Œ C çš„è·ç¦»æ‰€åœ¨çš„é©¬æ°è·ç¦»ç­‰å€¼çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "720,000",
            "zh": "720,000"
        }
    },
    {
        "translation": {
            "en": "Ideally, we want to descend the true error gradient for the entire dataset.",
            "zh": "ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›é™ä½æ•´ä¸ªæ•°æ®é›†çš„çœŸå®è¯¯å·®æ¢¯åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "factorization, 256, 302",
            "zh": "å› å¼åˆ†è§£ï¼Œ 256ï¼Œ 302"
        }
    },
    {
        "translation": {
            "en": "sample space, 246, 757, 758",
            "zh": "æ ·æœ¬ç©ºé—´ï¼Œ 246ï¼Œ 757ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "standard normal distribution, 62",
            "zh": "æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œ62"
        }
    },
    {
        "translation": {
            "en": "This operation is used in the input gate to update the cell state (see Equation (8.113)[511]).",
            "zh": "æ­¤æ“ä½œåœ¨è¾“å…¥é—¨ä¸­ç”¨äºæ›´æ–°å•å…ƒçŠ¶æ€ï¼ˆå‚è§å…¬å¼ï¼ˆ8.113ï¼‰[511]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "11.2.5â€…â€…â€…Temporal-Difference Learning",
            "zh": "11.2.5 æ—¶å·®å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "FIBERMAG_U/G/R/I/Z",
            "zh": "FIBERMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The agent then updates its current state (Line 13[658]), s 0 = s1 = 0-2, and returns to the beginning of the algorithm to choose the next action according to the policy.",
            "zh": "ç„¶åï¼Œä»£ç†æ›´æ–°å…¶å½“å‰çŠ¶æ€ï¼ˆç¬¬ 13 è¡Œ[658]ï¼‰ï¼Œs 0 = s1 = 0-2ï¼Œå¹¶è¿”å›ç®—æ³•çš„å¼€å¤´ä»¥æ ¹æ®ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ªæ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "8.33â€…â€…â€…Illustration of the organization of a set of neurons that share weights (use the same filter) and their local receptive fields such that together the receptive fields cover the entirety of the input image.",
            "zh": "8.33 è¯´æ˜ä¸€ç»„ç¥ç»å…ƒçš„ç»„ç»‡ï¼Œè¿™äº›ç¥ç»å…ƒå…±äº«æƒé‡ï¼ˆä½¿ç”¨ç›¸åŒçš„æ»¤æ³¢å™¨ï¼‰åŠå…¶å±€éƒ¨æ„Ÿå—é‡ï¼Œä½¿å¾—æ„Ÿå—é‡ä¸€èµ·è¦†ç›–æ•´ä¸ªè¾“å…¥å›¾åƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that in Figure 8.38[504] we have shown the network generating an output for each input it receives.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨å›¾8.38[504]ä¸­ï¼Œæˆ‘ä»¬æ˜¾ç¤ºäº†ç½‘ç»œä¸ºå®ƒæ¥æ”¶çš„æ¯ä¸ªè¾“å…¥ç”Ÿæˆè¾“å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "18. One note of caution: the Jaccard similarity index is undefined for pairs of instances in which all the features manifest co-absence, because this leads to a division by zero.",
            "zh": "18. éœ€è¦æ³¨æ„çš„æ˜¯ï¼šå¯¹äºæ‰€æœ‰ç‰¹å¾éƒ½è¡¨ç°å‡ºå…±ç¼ºçš„å®ä¾‹å¯¹ï¼ŒJaccard ç›¸ä¼¼æ€§æŒ‡æ•°æ˜¯æœªå®šä¹‰çš„ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´é™¤ä»¥é›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the naive Bayes model produces probabilities that are converted into categorical predictions using the maximum a posteriori probability approach, and logistic regression models produce a probability for the positive target level that is converted into a categorical prediction using a threshold.",
            "zh": "ä¾‹å¦‚ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹ç”Ÿæˆçš„æ¦‚ç‡ä½¿ç”¨æœ€å¤§åéªŒæ¦‚ç‡æ–¹æ³•è½¬æ¢ä¸ºåˆ†ç±»é¢„æµ‹ï¼Œé€»è¾‘å›å½’æ¨¡å‹ç”Ÿæˆæ­£ç›®æ ‡æ°´å¹³çš„æ¦‚ç‡ï¼Œè¯¥æ¦‚ç‡ä½¿ç”¨é˜ˆå€¼è½¬æ¢ä¸ºåˆ†ç±»é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "grid world, 659",
            "zh": "ç½‘æ ¼ä¸–ç•Œï¼Œ659"
        }
    },
    {
        "translation": {
            "en": "Near-sighted parents, because of their poor night vision, tend to favor the use of night-lights to help them find their way around their childrenâ€™s bedrooms at night.",
            "zh": "è¿‘è§†çš„çˆ¶æ¯ï¼Œç”±äºä»–ä»¬çš„å¤œè§†èƒ½åŠ›å·®ï¼Œå¾€å¾€å€¾å‘äºä½¿ç”¨å¤œç¯æ¥å¸®åŠ©ä»–ä»¬åœ¨æ™šä¸Šæ‰¾åˆ°å­©å­å§å®¤çš„è·¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "redundant features, 227",
            "zh": "å†—ä½™åŠŸèƒ½ï¼Œ227"
        }
    },
    {
        "translation": {
            "en": "Based on his assessment of the current situation within AT, Ross developed a list of ways that predictive analytics could help address the customer churn problem at AT. These included finding answers to the following questions:",
            "zh": "æ ¹æ®å¯¹ AT å½“å‰æƒ…å†µçš„è¯„ä¼°ï¼ŒRoss åˆ—å‡ºäº†é¢„æµ‹åˆ†æå¯ä»¥å¸®åŠ©è§£å†³ AT å®¢æˆ·æµå¤±é—®é¢˜çš„æ–¹æ³•ã€‚å…¶ä¸­åŒ…æ‹¬å¯»æ‰¾ä»¥ä¸‹é—®é¢˜çš„ç­”æ¡ˆï¼š"
        }
    },
    {
        "translation": {
            "en": "However, recurrent networks are quite flexible and can be deployed in different scenarios.",
            "zh": "ä½†æ˜¯ï¼Œå¾ªç¯ç½‘ç»œéå¸¸çµæ´»ï¼Œå¯ä»¥éƒ¨ç½²åœ¨ä¸åŒçš„åœºæ™¯ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Tene, Omer, and Jules Polonetsky. 2013. Big data for all: Privacy and user control in the age of analytics. Northwestern Journal of Technology and Intellectual Property 11 (5): 239â€“247.",
            "zh": "Teneã€Omer å’Œ Jules Polonetskyã€‚2013. äººäººäº«æœ‰å¤§æ•°æ®ï¼šåˆ†ææ—¶ä»£çš„éšç§å’Œç”¨æˆ·æ§åˆ¶ã€‚è¥¿åŒ—æŠ€æœ¯ä¸çŸ¥è¯†äº§æƒæ‚å¿— 11 ï¼ˆ5ï¼‰ï¼š 239â€“247."
        }
    },
    {
        "translation": {
            "en": "(e) Inter-quartile range",
            "zh": "ï¼ˆeï¼‰ å››åˆ†ä½è·"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the EEG dataset from Table 7.10[355]. The final panel shows the decision surface generated.",
            "zh": "è¡¨7.10[355]ä¸­è„‘ç”µå›¾æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚æœ€åä¸€ä¸ªé¢æ¿æ˜¾ç¤ºç”Ÿæˆçš„å†³ç­–é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "41. We are using this smaller 6-by-6 image rather than the full 28-by-28 MNIST digit image dimensions to simplify the illustration.",
            "zh": "41. æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªè¾ƒå°çš„ 6 x 6 å›¾åƒï¼Œè€Œä¸æ˜¯å®Œæ•´çš„ 28 x 28 MNIST æ•°å­—å›¾åƒå°ºå¯¸æ¥ç®€åŒ–æ’å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "McCulloch, Warren S., and Walter Pitts. 1943. A logical calculus of the ideas immanent in the nervous system. Bulletin of Mathematical Biophysics 5: 115â€“133.",
            "zh": "McCullochã€Warren S. å’Œ Walter Pittsã€‚1943. ç¥ç»ç³»ç»Ÿå†…åœ¨æ€æƒ³çš„é€»è¾‘æ¼”ç®—.æ•°å­¦ç”Ÿç‰©ç‰©ç†å­¦é€šæŠ¥5ï¼š115-133ã€‚"
        }
    },
    {
        "translation": {
            "en": "The outputs of the final layer in the encoder, the bottleneck layer, can be used as a new transformed representation of the original dataset.",
            "zh": "ç¼–ç å™¨ä¸­æœ€åä¸€ä¸ªå±‚ï¼ˆç“¶é¢ˆå±‚ï¼‰çš„è¾“å‡ºå¯ç”¨ä½œåŸå§‹æ•°æ®é›†çš„æ–°å˜æ¢è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) 10 neurons in the output layer",
            "zh": "ï¼ˆcï¼‰ è¾“å‡ºå±‚ä¸­æœ‰ 10 ä¸ªç¥ç»å…ƒ"
        }
    },
    {
        "translation": {
            "en": "Instead, it is only possible to see the ground at her feet to within about a three-foot radius.",
            "zh": "ç›¸åï¼Œåªèƒ½çœ‹åˆ°å¥¹è„šä¸‹çš„åœ°é¢ï¼ŒåŠå¾„åœ¨å¤§çº¦ä¸‰è‹±å°ºä»¥å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "hyperplane, 197, 197, 362",
            "zh": "è¶…å¹³é¢ï¼Œ 197ï¼Œ 197ï¼Œ 362"
        }
    },
    {
        "translation": {
            "en": "8.3.3â€…â€…â€…Backpropagation: Updating the Weights in a Network",
            "zh": "8.3.3 åå‘ä¼ æ’­ï¼šæ›´æ–°ç½‘ç»œä¸­çš„æƒé‡"
        }
    },
    {
        "translation": {
            "en": "This would give a total of 195 different states.",
            "zh": "è¿™å°†æ€»å…±æä¾› 195 ä¸ªä¸åŒçš„å·ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.00730080",
            "zh": "0.00730080"
        }
    },
    {
        "translation": {
            "en": "A spectrograph is a device that disperses the light emitted by an object into different wavelengths and measures the intensity of the emission of each wavelengthâ€”this set of measures is referred to as a spectrogram.",
            "zh": "å…‰è°±ä»ªæ˜¯ä¸€ç§å°†ç‰©ä½“å‘å‡ºçš„å…‰åˆ†æ•£åˆ°ä¸åŒæ³¢é•¿å¹¶æµ‹é‡æ¯ä¸ªæ³¢é•¿çš„å‘å°„å¼ºåº¦çš„è£…ç½®â€”â€”è¿™ç»„æµ‹é‡ç§°ä¸ºå…‰è°±å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "numeric data, 34",
            "zh": "æ•°å€¼æ•°æ®ï¼Œ 34"
        }
    },
    {
        "translation": {
            "en": "The reason we multiply by the Kronecker delta function is to ensure that in calculating the score for each of the candidate target levels, we include only the weights for the instances whose target feature value matches that level.",
            "zh": "æˆ‘ä»¬ä¹˜ä»¥ Kronecker delta å‡½æ•°çš„åŸå› æ˜¯ç¡®ä¿åœ¨è®¡ç®—æ¯ä¸ªå€™é€‰ç›®æ ‡çº§åˆ«çš„åˆ†æ•°æ—¶ï¼Œæˆ‘ä»¬ä»…åŒ…æ‹¬ç›®æ ‡ç‰¹å¾å€¼ä¸è¯¥çº§åˆ«åŒ¹é…çš„å®ä¾‹çš„æƒé‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, a process was put in place that allowed manual review by SDSS experts to be included in the galaxy classification process.",
            "zh": "ç¬¬äºŒï¼Œå»ºç«‹äº†ä¸€ä¸ªç¨‹åºï¼Œå…è®¸SDSSä¸“å®¶çš„äººå·¥å®¡æŸ¥çº³å…¥æ˜Ÿç³»åˆ†ç±»è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "These recurrent models use a feedback loop to maintain, evolve, and propagate a representation of the pertinent information within the sequence history.",
            "zh": "è¿™äº›å¾ªç¯æ¨¡å‹ä½¿ç”¨åé¦ˆå›è·¯æ¥ç»´æŠ¤ã€å‘å±•å’Œä¼ æ’­åºåˆ—å†å²ä¸­ç›¸å…³ä¿¡æ¯çš„è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Literary Digest never recovered from the reputational damage this error in prediction caused and went out of business soon afterward.",
            "zh": "ã€Šæ–‡å­¦æ–‡æ‘˜ã€‹ä»æœªä»è¿™ä¸€é¢„æµ‹é”™è¯¯é€ æˆçš„å£°èª‰æŸå®³ä¸­æ¢å¤è¿‡æ¥ï¼Œä¸ä¹…åå°±å€’é—­äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "By contrast in a network using logistic activation functions, the vast majority of neurons will be active for all inputs.",
            "zh": "ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨ä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°çš„ç½‘ç»œä¸­ï¼Œç»å¤§å¤šæ•°ç¥ç»å…ƒå°†å¯¹æ‰€æœ‰è¾“å…¥éƒ½å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bootstrapping approaches are preferred over cross validation approaches in contexts with very small datasets (approximately fewer than 300 instances).",
            "zh": "åœ¨æ•°æ®é›†éå¸¸å°ï¼ˆå¤§çº¦å°‘äº 300 ä¸ªå®ä¾‹ï¼‰çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå¼•å¯¼æ–¹æ³•ä¼˜äºäº¤å‰éªŒè¯æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "trapezoidal method, 562, 593",
            "zh": "æ¢¯å½¢æ³•ï¼Œ 562ï¼Œ 593"
        }
    },
    {
        "translation": {
            "en": "Equation (8.68)[466] shows that all the terms that involve a 0 element from t disappear, and the loss simplifies to the negative log of the predicted probability for the true class.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.68ï¼‰[466]è¡¨æ˜ï¼Œæ‰€æœ‰æ¶‰åŠtçš„0å…ƒç´ çš„é¡¹éƒ½æ¶ˆå¤±äº†ï¼Œå¹¶ä¸”æŸå¤±ç®€åŒ–ä¸ºçœŸå®ç±»çš„é¢„æµ‹æ¦‚ç‡çš„è´Ÿå¯¹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.10â€…â€…â€…Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) for the candidate ELEVATION thresholds:â‰¥ 750, â‰¥1,350, â‰¥2,250 and â‰¥4,175.",
            "zh": "4.10 å€™é€‰ ELEVATION é˜ˆå€¼çš„åˆ†åŒºé›† ï¼ˆPart.ï¼‰ã€ç†µã€ä½™æ•° ï¼ˆRem.ï¼‰ å’Œä¿¡æ¯å¢ç›Š ï¼ˆInfo. Gainï¼‰ï¼šâ‰¥ 750ã€â‰¥1,350ã€â‰¥2,250 å’Œ â‰¥4,175ã€‚"
        }
    },
    {
        "translation": {
            "en": "group think, 158",
            "zh": "ç¾¤ä½“æ€è€ƒï¼Œ158"
        }
    },
    {
        "translation": {
            "en": "An interesting alternative to using an application-based solution for building predictive data analytics models is to use a programming language. Two of the most commonly used programming languages for predictive data analytics are R and Python.15 Building predictive data analytics models using a language like R or Python is not especially difficult. For example, the following simple lines of code use the R language to build a predictive model for a simple task:",
            "zh": "ä½¿ç”¨åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆæ¥æ„å»ºé¢„æµ‹æ€§æ•°æ®åˆ†ææ¨¡å‹çš„ä¸€ä¸ªæœ‰è¶£çš„æ›¿ä»£æ–¹æ³•æ˜¯ä½¿ç”¨ç¼–ç¨‹è¯­è¨€ã€‚é¢„æµ‹æ•°æ®åˆ†ææœ€å¸¸ç”¨çš„ä¸¤ç§ç¼–ç¨‹è¯­è¨€æ˜¯ R å’Œ Python.15 ä½¿ç”¨ R æˆ– Python ç­‰è¯­è¨€æ„å»ºé¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹å¹¶ä¸æ˜¯ç‰¹åˆ«å›°éš¾ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ç®€å•çš„ä»£ç è¡Œä½¿ç”¨ R è¯­è¨€ä¸ºç®€å•ä»»åŠ¡ç”Ÿæˆé¢„æµ‹æ¨¡å‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "4.8â€…â€…â€…The decision tree after the data has been split using ELEVATION.",
            "zh": "4.8 ä½¿ç”¨ ELEVATION æ‹†åˆ†æ•°æ®åçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "Popular batch sizes include 32, 64, 128, and even 256 examples.",
            "zh": "æµè¡Œçš„æ‰¹é‡å¤§å°åŒ…æ‹¬ 32ã€64ã€128 ç”šè‡³ 256 ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In other words, this is the rate of change of the softmax calculation for the activation of the output neuron for the true class with respect to the logits of a neuron in the output layer.",
            "zh": "æ¢è¨€ä¹‹ï¼Œè¿™æ˜¯ softmax è®¡ç®—çš„ softmax è®¡ç®—å€¼ç›¸å¯¹äºè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„å¯¹æ•°ï¼Œç”¨äºæ¿€æ´»çœŸç±»çš„è¾“å‡ºç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 1.4[10] illustrates this; the blanked-out columns in the table indicate the models that are not consistent with the training data.",
            "zh": "è¡¨1.4[10]è¯´æ˜äº†è¿™ä¸€ç‚¹;è¡¨ä¸­çš„ç©ºç™½åˆ—è¡¨ç¤ºä¸è®­ç»ƒæ•°æ®ä¸ä¸€è‡´çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "activation function, 386",
            "zh": "æ¿€æ´»å‡½æ•°ï¼Œ386"
        }
    },
    {
        "translation": {
            "en": "8.6â€…â€…â€…The âˆ‚â„°/âˆ‚wi,k calculations for d2 for every weight in the network. We use the neuron index 0 to denote the bias input for each neuron.",
            "zh": "8.6 ç½‘ç»œä¸­æ¯ä¸ªæƒé‡çš„ d2 çš„ âˆ‚E/âˆ‚wiï¼Œk è®¡ç®—ã€‚æˆ‘ä»¬ä½¿ç”¨ç¥ç»å…ƒç´¢å¼• 0 æ¥è¡¨ç¤ºæ¯ä¸ªç¥ç»å…ƒçš„åå·®è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "Each node in a k-d tree defines a boundary that partitions the feature space along the median value of the feature the data was split on at that node.",
            "zh": "k-d æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½å®šä¹‰äº†ä¸€ä¸ªè¾¹ç•Œï¼Œè¯¥è¾¹ç•Œæ²¿åœ¨è¯¥èŠ‚ç‚¹ä¸Šåˆ†å‰²æ•°æ®çš„ç‰¹å¾çš„ä¸­å€¼åˆ’åˆ†ç‰¹å¾ç©ºé—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "The data used in this case study can be accessed by performing a simple SQL query at skyserver.sdss3.org/dr9/en/tools/search/sql.asp.",
            "zh": "æœ¬æ¡ˆä¾‹ç ”ç©¶ä¸­ä½¿ç”¨çš„æ•°æ®å¯ä»¥é€šè¿‡åœ¨ skyserver.sdss3.org/dr9/en/tools/search/sql.asp æ‰§è¡Œç®€å•çš„ SQL æŸ¥è¯¢æ¥è®¿é—®ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we assume the two predefined weights are w1 = 0.5 and w2 = 3 and the two inputs are input1 = 6 and input2 = 7, then the weighted sum calculation would proceed as follows:",
            "zh": "å¦‚æœæˆ‘ä»¬å‡è®¾ä¸¤ä¸ªé¢„å®šä¹‰çš„æƒé‡æ˜¯ w1 = 0.5 å’Œ w2 = 3ï¼Œå¹¶ä¸”ä¸¤ä¸ªè¾“å…¥æ˜¯ input1 = 6 å’Œ input2 = 7ï¼Œé‚£ä¹ˆåŠ æƒå’Œè®¡ç®—å°†æŒ‰å¦‚ä¸‹æ–¹å¼è¿›è¡Œï¼š"
        }
    },
    {
        "translation": {
            "en": "5.10â€…â€…â€…The calculations for the weighted k nearest neighbor prediction.",
            "zh": "5.10 åŠ æƒkæœ€è¿‘é‚»é¢„æµ‹çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes (MDPs) are an attractive mathematical framework within which to reason about decision making scenarios in which outcomes are partly under the control of a decision maker, but also partly random. This has made them an attractive framework for applications ranging from financial modeling, to robot control, to modeling the flow of human conversation. This also makes them ideal for reasoning about reinforcement learning.",
            "zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ ï¼ˆMDPï¼‰ æ˜¯ä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„æ•°å­¦æ¡†æ¶ï¼Œå¯ä»¥åœ¨å…¶ä¸­æ¨ç†å†³ç­–åœºæ™¯ï¼Œå…¶ä¸­ç»“æœéƒ¨åˆ†ç”±å†³ç­–è€…æ§åˆ¶ï¼Œä½†ä¹Ÿéƒ¨åˆ†éšæœºã€‚è¿™ä½¿å®ƒä»¬æˆä¸ºä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„æ¡†æ¶ï¼Œé€‚ç”¨äºä»é‡‘èå»ºæ¨¡åˆ°æœºå™¨äººæ§åˆ¶ï¼Œå†åˆ°äººç±»å¯¹è¯æµç¨‹å»ºæ¨¡ç­‰å„ç§åº”ç”¨ã€‚è¿™ä¹Ÿä½¿å®ƒä»¬æˆä¸ºæ¨ç†å¼ºåŒ–å­¦ä¹ çš„ç†æƒ³é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Working with Edwin, Jocelyn reviewed the relevant literature and discovered a number of very informative articles discussing descriptive features that were likely to be useful in classifying galaxy morphologies.12 In particular, a number of interesting features that could be derived from the flux and magnitude measurements already in the SDSS dataset were described in the literature.",
            "zh": "Jocelynä¸Edwinåˆä½œï¼Œå›é¡¾äº†ç›¸å…³æ–‡çŒ®ï¼Œå¹¶å‘ç°äº†è®¸å¤šå†…å®¹ä¸°å¯Œçš„æ–‡ç« ï¼Œè¿™äº›æ–‡ç« è®¨è®ºäº†å¯èƒ½æœ‰åŠ©äºå¯¹æ˜Ÿç³»å½¢æ€è¿›è¡Œåˆ†ç±»çš„æè¿°æ€§ç‰¹å¾.12ç‰¹åˆ«æ˜¯ï¼Œæ–‡çŒ®ä¸­æè¿°äº†è®¸å¤šæœ‰è¶£çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯ä»¥ä»SDSSæ•°æ®é›†ä¸­å·²æœ‰çš„é€šé‡å’Œæ˜Ÿç­‰æµ‹é‡ä¸­å¾—å‡ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian optimal classifier, 254",
            "zh": "è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨ï¼Œ254"
        }
    },
    {
        "translation": {
            "en": "FIBERMAGERR_U/G/R/I/Z",
            "zh": "FIBERMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The use limitation principle adds that collected data should not subsequently be used for purposes other than those stated at the time of collection.",
            "zh": "ä½¿ç”¨é™åˆ¶åŸåˆ™è¡¥å……è¯´ï¼Œæ‰€æ”¶é›†çš„æ•°æ®éšåä¸åº”ç”¨äºæ”¶é›†æ—¶æ‰€è¿°ç›®çš„ä»¥å¤–çš„ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the prediction stage, when the model is used to make predictions for new query instances, the distance in the feature space between the query instance and each instance in memory is computed, and the prediction returned by the model is the target feature level of the instance that is nearest to the query in the feature space.",
            "zh": "åœ¨é¢„æµ‹é˜¶æ®µï¼Œå½“æ¨¡å‹ç”¨äºå¯¹æ–°çš„æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹æ—¶ï¼Œè®¡ç®—æŸ¥è¯¢å®ä¾‹ä¸å†…å­˜ä¸­æ¯ä¸ªå®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„è·ç¦»ï¼Œæ¨¡å‹è¿”å›çš„é¢„æµ‹æ˜¯è¯¥å®ä¾‹åœ¨ç‰¹å¾ç©ºé—´ä¸­æœ€æ¥è¿‘æŸ¥è¯¢çš„ç›®æ ‡ç‰¹å¾çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "Plots for activation functions that have been popular in the history of neural networks.",
            "zh": "åœ¨ç¥ç»ç½‘ç»œå†å²ä¸Šæµè¡Œçš„æ¿€æ´»å‡½æ•°å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once we get to a leaf node, we simply add the new instance as either the left or the right child of the leaf node.",
            "zh": "ä¸€æ—¦æˆ‘ä»¬åˆ°è¾¾å¶èŠ‚ç‚¹ï¼Œæˆ‘ä»¬åªéœ€å°†æ–°å®ä¾‹æ·»åŠ ä¸ºå¶èŠ‚ç‚¹çš„å·¦å­èŠ‚ç‚¹æˆ–å³å­èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "820,000",
            "zh": "820,000"
        }
    },
    {
        "translation": {
            "en": "The hyperplane boundary bisecting a node is defined by the value used to split the descriptive feature at the node.",
            "zh": "å°†èŠ‚ç‚¹ä¸€åˆ†ä¸ºäºŒçš„è¶…å¹³é¢è¾¹ç•Œç”±ç”¨äºåˆ†å‰²èŠ‚ç‚¹å¤„çš„æè¿°æ€§ç‰¹å¾çš„å€¼å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Reed, Russell D., and Robert J. Marks. 1999. Neural smithing: Supervised learning in feedforward artificial networks. MIT Press.",
            "zh": "é‡Œå¾·ã€ç½—ç´  D. å’Œç½—ä¼¯ç‰¹ J. é©¬å…‹æ–¯ã€‚1999. ç¥ç»é”»é€ ï¼šå‰é¦ˆäººå·¥ç½‘ç»œä¸­çš„ç›‘ç£å­¦ä¹ ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is repeated for k iterations, and the average of the individual performance measures, the titular Îµ0, gives the overall performance of the model.",
            "zh": "æ­¤è¿‡ç¨‹é‡å¤ k æ¬¡è¿­ä»£ï¼Œå„ä¸ªæ€§èƒ½åº¦é‡å€¼çš„å¹³å‡å€¼ï¼ˆåä¹‰ Îµ0ï¼‰ç»™å‡ºäº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, the full dataset is divided into 5 folds (each containing 200 instances), and five evaluation experiments are performed using 1 fold as the test set and the remaining folds as the training set.",
            "zh": "å› æ­¤ï¼Œå°†å®Œæ•´æ•°æ®é›†åˆ†ä¸º 5 ä¸ªæŠ˜å ï¼ˆæ¯ä¸ªæŠ˜å åŒ…å« 200 ä¸ªå®ä¾‹ï¼‰ï¼Œå¹¶ä½¿ç”¨ 1 ä¸ªæŠ˜å ä½œä¸ºæµ‹è¯•é›†ï¼Œå…¶ä½™æŠ˜å ä½œä¸ºè®­ç»ƒé›†è¿›è¡Œ 5 ä¸ªè¯„ä¼°å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, the relative frequency of the event DICE1 = is simply the count of all the rows in the dataset where DICE1 has a value of divided by the number of rows in the dataset.",
            "zh": "ä¾‹å¦‚ï¼Œäº‹ä»¶ DICE1 = çš„ç›¸å¯¹é¢‘ç‡åªæ˜¯æ•°æ®é›†ä¸­æ‰€æœ‰è¡Œçš„è®¡æ•°ï¼Œå…¶ä¸­ DICE1 çš„å€¼é™¤ä»¥æ•°æ®é›†ä¸­çš„è¡Œæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 7.2[317] shows the calculation of the sum of squared errors for the candidate model with w[0] = 6.47 and w[1] = 0.62. In this case, the sum of squared errors is equal to 2,837.08.",
            "zh": "è¡¨ 7.2[317] æ˜¾ç¤ºäº† w[0] = 6.47 å’Œ w[1] = 0.62 çš„å€™é€‰æ¨¡å‹çš„å¹³æ–¹è¯¯å·®å’Œçš„è®¡ç®—ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œè¯¯å·®çš„å¹³æ–¹å’Œç­‰äº 2,837.08ã€‚"
        }
    },
    {
        "translation": {
            "en": "One way in which to do this is to calculate the profit or loss that arises from each prediction we make and to use these to determine the overall performance of a model.",
            "zh": "ä¸€ç§æ–¹æ³•æ˜¯è®¡ç®—æˆ‘ä»¬æ‰€åšçš„æ¯ä¸ªé¢„æµ‹äº§ç”Ÿçš„åˆ©æ¶¦æˆ–æŸå¤±ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ¥ç¡®å®šæ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "OBESE, are they overweight",
            "zh": "OBESEï¼Œä»–ä»¬è¶…é‡äº†å—"
        }
    },
    {
        "translation": {
            "en": "The rule states that approximately 68% of the values in a sample that follows a normal distribution will be within one Ïƒ of Î¼, 95% of the values will be within two Ïƒ of Î¼, and 99.7% of values will be within three Ïƒ of Î¼.",
            "zh": "è¯¥è§„åˆ™æŒ‡å‡ºï¼Œéµå¾ªæ­£æ€åˆ†å¸ƒçš„æ ·æœ¬ä¸­å¤§çº¦ 68% çš„å€¼å°†åœ¨ Î¼ çš„ 1 Ïƒ ä»¥å†…ï¼Œ95% çš„å€¼å°†åœ¨ Î¼ çš„ä¸¤Ïƒä»¥å†…ï¼Œ99.7% çš„å€¼å°†åœ¨ Î¼ çš„ä¸‰Ïƒä»¥å†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "This identity permits us to rewrite the variance of z in our case study neuron",
            "zh": "è¿™ä¸ªæ’ç­‰å¼å…è®¸æˆ‘ä»¬åœ¨æ¡ˆä¾‹ç ”ç©¶ç¥ç»å…ƒä¸­é‡å†™ z çš„æ–¹å·®"
        }
    },
    {
        "translation": {
            "en": "To address the finer grained 5-level (elliptical, spiral_cw, spiral_acw, spiral_eo, and other) classification task, Jocelyn attempted two approaches.",
            "zh": "ä¸ºäº†è§£å†³æ›´ç»†ç²’åº¦çš„ 5 çº§ï¼ˆæ¤­åœ†ã€spiral_cwã€spiral_acwã€spiral_eoç­‰ï¼‰åˆ†ç±»ä»»åŠ¡ï¼ŒJocelyn å°è¯•äº†ä¸¤ç§æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "Schapire, Robert E. 1990. The strength of weak learnability. Machine Learning 5 (2): 197â€“227.",
            "zh": "å¤çš®å°”ï¼Œç½—ä¼¯ç‰¹ E. 1990 å¹´ã€‚å­¦ä¹ èƒ½åŠ›å¼±çš„ä¼˜åŠ¿ã€‚æœºå™¨å­¦ä¹  5 ï¼ˆ2ï¼‰ï¼š197â€“227ã€‚"
        }
    },
    {
        "translation": {
            "en": "model residuals, 164",
            "zh": "æ¨¡å‹æ®‹å·®ï¼Œ164"
        }
    },
    {
        "translation": {
            "en": "In a fully connected network nin is the same for all the neurons in a layer, and so for these networks we can set the variance of the distribution from which the weights are sampled on a layer-by-layer basis.",
            "zh": "åœ¨å®Œå…¨è¿æ¥çš„ç½‘ç»œä¸­ï¼Œnin å¯¹äºä¸€å±‚ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤å¯¹äºè¿™äº›ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥é€å±‚è®¾ç½®æƒé‡é‡‡æ ·çš„åˆ†å¸ƒæ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Euclidean coordinate space, 185",
            "zh": "æ¬§å‡ é‡Œå¾—åæ ‡ç©ºé—´ï¼Œ185"
        }
    },
    {
        "translation": {
            "en": "sampling density, 224",
            "zh": "é‡‡æ ·å¯†åº¦ï¼Œ224"
        }
    },
    {
        "translation": {
            "en": "deciles, 567, 582",
            "zh": "ååˆ†ä½æ•°ï¼Œ567,582"
        }
    },
    {
        "translation": {
            "en": "In this second path of processing hxt is passed through a layer of tanh units.",
            "zh": "åœ¨ç¬¬äºŒæ¡å¤„ç†è·¯å¾„ä¸­ï¼Œhxt é€šè¿‡ä¸€å±‚ tanh å•å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The blindfold, however, is electronic and controlled by the scout leader administering the test.",
            "zh": "ç„¶è€Œï¼Œçœ¼ç½©æ˜¯ç”µå­çš„ï¼Œç”±ç®¡ç†æµ‹è¯•çš„ä¾¦å¯Ÿé˜Ÿé•¿æ§åˆ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic process for evaluating the effectiveness of predictive models is simple.",
            "zh": "è¯„ä¼°é¢„æµ‹æ¨¡å‹æœ‰æ•ˆæ€§çš„åŸºæœ¬è¿‡ç¨‹å¾ˆç®€å•ã€‚"
        }
    },
    {
        "translation": {
            "en": "(e) P(MENINGITIS | FEVER = true,VOMITING = false)",
            "zh": "ï¼ˆeï¼‰ Pï¼ˆè„‘è†œç‚ |FEVER = çœŸï¼ŒVOMITING = å‡ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for donâ€™t know category",
            "zh": "ä¸çŸ¥é“ç±»åˆ«çš„æŠ•ç¥¨åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "By using a predictive model that requires only features from maps, the ecological modelers can avoid expensive ground-based or aerial surveys.",
            "zh": "é€šè¿‡ä½¿ç”¨åªéœ€è¦åœ°å›¾è¦ç´ çš„é¢„æµ‹æ¨¡å‹ï¼Œç”Ÿæ€å»ºæ¨¡äººå‘˜å¯ä»¥é¿å…æ˜‚è´µçš„åœ°é¢æˆ–èˆªç©ºè°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.4.5.3â€ƒFilter hyper-parameters: Dimension, stride, and paddingâ€ƒThe dimensionality of a feature map generated by applying a filter to an input is determined by the number of neurons used to process the input (each element in a feature map corresponds to the output of one neuron).",
            "zh": "8.4.5.3 è¿‡æ»¤å™¨è¶…å‚æ•°ï¼šå°ºå¯¸ã€æ­¥å¹…å’Œå¡«å…… é€šè¿‡å¯¹è¾“å…¥åº”ç”¨è¿‡æ»¤å™¨ç”Ÿæˆçš„ç‰¹å¾å›¾çš„ç»´æ•°ç”±ç”¨äºå¤„ç†è¾“å…¥çš„ç¥ç»å…ƒæ•°é‡å†³å®šï¼ˆç‰¹å¾å›¾ä¸­çš„æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is an aspect of probability theory with which beginners sometimes struggle.",
            "zh": "è¿™æ˜¯æ¦‚ç‡è®ºçš„ä¸€ä¸ªæ–¹é¢ï¼Œåˆå­¦è€…æœ‰æ—¶ä¼šé‡åˆ°å›°éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.7â€ƒExercises",
            "zh": "2.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "These softmax activations are also shown in Figure 8.28[470].",
            "zh": "è¿™äº›softmaxæ¿€æ´»ä¹Ÿå¦‚å›¾8.28[470]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 3.1",
            "zh": "è¡¨ 3.1"
        }
    },
    {
        "translation": {
            "en": "The simplest early stopping criterion is to stop partitioning the dataset if the number of training instances in the partition at the node we are processing is less than some threshold, usually around 5% of the overall dataset size.16 This early stopping criterion replaces the base case on Line 1 of the ID3 algorithm.",
            "zh": "æœ€ç®€å•çš„æ—©æœŸåœæ­¢æ ‡å‡†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æ­£åœ¨å¤„ç†çš„èŠ‚ç‚¹ä¸Šçš„åˆ†åŒºä¸­çš„è®­ç»ƒå®ä¾‹æ•°å°äºæŸä¸ªé˜ˆå€¼ï¼Œé€šå¸¸çº¦ä¸ºæ•´ä¸ªæ•°æ®é›†å¤§å°çš„ 5%ï¼Œåˆ™åœæ­¢å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºã€‚16 æ­¤æ—©æœŸåœæ­¢æ ‡å‡†å–ä»£äº† ID3 ç®—æ³•ç¬¬ 1 è¡Œçš„åŸºæœ¬æƒ…å†µã€‚"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that a feature with a low information gain at the root node (when the full dataset is considered) may have a high information gain score at one of the interior nodes because it is predictive on the subset of instances that are considered at that interior node.",
            "zh": "è¿™æ ·åšçš„ä¸€ä¸ªç»“æœæ˜¯ï¼Œåœ¨æ ¹èŠ‚ç‚¹ä¸Šå…·æœ‰ä½ä¿¡æ¯å¢ç›Šçš„ç‰¹å¾ï¼ˆå½“è€ƒè™‘å®Œæ•´æ•°æ®é›†æ—¶ï¼‰å¯èƒ½åœ¨å…¶ä¸­ä¸€ä¸ªå†…éƒ¨èŠ‚ç‚¹ä¸Šå…·æœ‰è¾ƒé«˜çš„ä¿¡æ¯å¢ç›Šåˆ†æ•°ï¼Œå› ä¸ºå®ƒå¯¹åœ¨è¯¥å†…éƒ¨èŠ‚ç‚¹ä¸Šè€ƒè™‘çš„å®ä¾‹å­é›†å…·æœ‰é¢„æµ‹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.2â€…â€…â€…Histograms for six different sets of data, each of which exhibit well-known, common characteristics.",
            "zh": "3.2 å…­ç»„ä¸åŒæ•°æ®é›†çš„ç›´æ–¹å›¾ï¼Œæ¯ç»„æ•°æ®éƒ½å…·æœ‰ä¼—æ‰€å‘¨çŸ¥çš„å…±åŒç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Markov chain defined by a Bayesian network is ergodic if there are no zero entries in any of the CPTs.30 The third requirement is that the generated states should be independent of each other.",
            "zh": "å¦‚æœåœ¨ä»»ä½• CPT ä¸­æ²¡æœ‰é›¶æ¡ç›®ï¼Œåˆ™ç”±è´å¶æ–¯ç½‘ç»œå®šä¹‰çš„é©¬å°”å¯å¤«é“¾æ˜¯éå†çš„.30 ç¬¬ä¸‰ä¸ªè¦æ±‚æ˜¯ç”Ÿæˆçš„çŠ¶æ€åº”è¯¥å½¼æ­¤ç‹¬ç«‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cumulative gain, lift, and cumulative lift charts for four different models for the extended email classification test set.",
            "zh": "æ‰©å±•ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†çš„å››ç§ä¸åŒæ¨¡å‹çš„ç´¯è®¡å¢ç›Šã€æå‡å’Œç´¯ç§¯æå‡å›¾è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "The structure of a data quality plan.",
            "zh": "æ•°æ®è´¨é‡è®¡åˆ’çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.2â€ƒDescriptive Statistics for Categorical Features",
            "zh": "A.2 åˆ†ç±»ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡"
        }
    },
    {
        "translation": {
            "en": "We can now combine the three probabilities just calculated to calculate the overall probability of the target feature taking the level true given the query instance",
            "zh": "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆåˆšåˆšè®¡ç®—çš„ä¸‰ä¸ªæ¦‚ç‡æ¥è®¡ç®—ç»™å®šæŸ¥è¯¢å®ä¾‹çš„ç›®æ ‡ç‰¹å¾å–çº§ä¸º true çš„æ€»ä½“æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "In this network, Convolutional layer 1 includes Filters 1 and 2 and so generates two feature maps.",
            "zh": "åœ¨æ­¤ç½‘ç»œä¸­ï¼Œå·ç§¯å±‚ 1 åŒ…æ‹¬æ»¤æ³¢å™¨ 1 å’Œ 2ï¼Œå› æ­¤ç”Ÿæˆä¸¤ä¸ªç‰¹å¾å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The extra piece of evidence means that you need to revise your belief about the likelihoods of where the queen will be once again.",
            "zh": "é¢å¤–çš„è¯æ®æ„å‘³ç€ä½ éœ€è¦ä¿®æ”¹ä½ å¯¹å¥³ç‹å†æ¬¡å‡ºç°çš„å¯èƒ½æ€§çš„çœ‹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "support vector machine, 311, 332, 361, 369, 373, 719, 732, 733, 735",
            "zh": "æ”¯æŒå‘é‡æœºï¼Œ 311ï¼Œ 332ï¼Œ 361ï¼Œ 369ï¼Œ 373ï¼Œ 719ï¼Œ 732ï¼Œ 733ï¼Œ 735"
        }
    },
    {
        "translation": {
            "en": "The type of probabilities we have calculated so far are known as prior probabilities or unconditional probabilities.",
            "zh": "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¡ç®—çš„æ¦‚ç‡ç±»å‹ç§°ä¸ºå…ˆéªŒæ¦‚ç‡æˆ–æ— æ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "OCC: The customerâ€™s occupation",
            "zh": "OCCï¼šå®¢æˆ·çš„èŒä¸š"
        }
    },
    {
        "translation": {
            "en": "The selection of which non-evidence node to change can be random or follow a predefined list through which the algorithm iterates.",
            "zh": "é€‰æ‹©è¦æ›´æ”¹çš„éè¯æ®èŠ‚ç‚¹å¯ä»¥æ˜¯éšæœºçš„ï¼Œä¹Ÿå¯ä»¥éµå¾ªç®—æ³•è¿­ä»£çš„é¢„å®šä¹‰åˆ—è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "They donâ€™t have time to manually grade the script before the flight, so they decide to use a k-nearest neighbor model to grade it instead.",
            "zh": "ä»–ä»¬æ²¡æœ‰æ—¶é—´åœ¨é£è¡Œå‰æ‰‹åŠ¨å¯¹è„šæœ¬è¿›è¡Œè¯„åˆ†ï¼Œå› æ­¤ä»–ä»¬å†³å®šä½¿ç”¨ k æœ€è¿‘é‚»æ¨¡å‹æ¥å¯¹å…¶è¿›è¡Œè¯„åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "15. If an ROC curve appears below the diagonal random reference line, this means that the model is consistently making predictions of the positive level for instances that should receive predictions of the negative level and vice versa, and that it could actually be quite a powerful model. This usually arises when a transcription error of some kind has been made and should be investigated.",
            "zh": "15. å¦‚æœ ROC æ›²çº¿å‡ºç°åœ¨å¯¹è§’çº¿éšæœºå‚è€ƒçº¿ä¸‹æ–¹ï¼Œè¿™æ„å‘³ç€è¯¥æ¨¡å‹å§‹ç»ˆå¦‚ä¸€åœ°å¯¹åº”è¯¥æ¥æ”¶è´Ÿæ°´å¹³é¢„æµ‹çš„å®ä¾‹è¿›è¡Œæ­£æ°´å¹³é¢„æµ‹ï¼Œåä¹‹äº¦ç„¶ï¼Œå¹¶ä¸”å®ƒå®é™…ä¸Šå¯èƒ½æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„æ¨¡å‹ã€‚è¿™é€šå¸¸å‘ç”Ÿåœ¨å‡ºç°æŸç§è½¬å½•é”™è¯¯æ—¶ï¼Œåº”è¯¥è¿›è¡Œè°ƒæŸ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "LNLEXP_U/G/R/I/Z",
            "zh": "LNLEXP_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "For this reason, instance d460 was removed from the ABT.",
            "zh": "å› æ­¤ï¼Œå®ä¾‹ d460 å·²ä» ABT ä¸­åˆ é™¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.21",
            "zh": "è¡¨ 9.21"
        }
    },
    {
        "translation": {
            "en": "The student-t distribution is symmetric around a single peak.",
            "zh": "student-t åˆ†å¸ƒå›´ç»•å•ä¸ªå³°æ˜¯å¯¹ç§°çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have included the bias term w0 in this filter in order to highlight that although the filter now has three dimensions, there is still only one bias term.",
            "zh": "æˆ‘ä»¬åœ¨æ­¤æ»¤æ³¢å™¨ä¸­åŒ…å«äº†åç½®é¡¹ w0ï¼Œä»¥å¼ºè°ƒå°½ç®¡æ»¤æ³¢å™¨ç°åœ¨å…·æœ‰ä¸‰ä¸ªç»´åº¦ï¼Œä½†ä»ç„¶åªæœ‰ä¸€ä¸ªåç½®é¡¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "From a prediction perspective, the Voronoi region belonging to a training instance defines the set of queries for which the prediction will be determined by that training instance.",
            "zh": "ä»é¢„æµ‹çš„è§’åº¦æ¥çœ‹ï¼Œå±äºè®­ç»ƒå®ä¾‹çš„ Voronoi åŒºåŸŸå®šä¹‰äº†ä¸€ç»„æŸ¥è¯¢ï¼Œè¯¥è®­ç»ƒå®ä¾‹å°†ç¡®å®šé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is why we use a learning rate Î± to scale the weight updates.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨å­¦ä¹ ç‡Î±æ¥ç¼©æ”¾æƒé‡æ›´æ–°çš„åŸå› ã€‚"
        }
    },
    {
        "translation": {
            "en": "âˆ’0.00556710",
            "zh": "âˆ’0.00556710"
        }
    },
    {
        "translation": {
            "en": "When a neuron uses a logistic function as its activation function, then the maximum value the derivative can take is 0.25.",
            "zh": "å½“ç¥ç»å…ƒä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºå…¶æ¿€æ´»å‡½æ•°æ—¶ï¼Œå¯¼æ•°å¯ä»¥å–çš„æœ€å¤§å€¼ä¸º 0.25ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) A support vector machine model has been trained to distinguish between dosages of two drugs that cause a dangerous interaction and those that interact safely. This model uses just two continuous features, DOSE1 and DOSE2, and two target levels, dangerous (the positive level, + 1) and safe (the negative level, âˆ’ 1). The support vectors in the trained model are shown in the following table.",
            "zh": "ï¼ˆbï¼‰ å·²ç»è®­ç»ƒäº†ä¸€ç§æ”¯æŒå‘é‡æœºæ¨¡å‹ï¼Œä»¥åŒºåˆ†å¼•èµ·å±é™©ç›¸äº’ä½œç”¨çš„ä¸¤ç§è¯ç‰©çš„å‰‚é‡å’Œå®‰å…¨ç›¸äº’ä½œç”¨çš„è¯ç‰©ã€‚è¯¥æ¨¡å‹ä»…ä½¿ç”¨ä¸¤ä¸ªè¿ç»­ç‰¹å¾ï¼Œå³ DOSE1 å’Œ DOSE2ï¼Œä»¥åŠä¸¤ä¸ªç›®æ ‡æ°´å¹³ï¼Œå±é™©ï¼ˆæ­£æ°´å¹³ï¼Œ+ 1ï¼‰å’Œå®‰å…¨ï¼ˆè´Ÿæ°´å¹³ï¼Œâˆ’ 1ï¼‰ã€‚è®­ç»ƒæ¨¡å‹ä¸­çš„æ”¯æŒå‘é‡å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The final for loop in each epoch is where the weights of the network are updated (Lines 28[420] to 30[420]).",
            "zh": "æ¯ä¸ªçºªå…ƒçš„æœ€åä¸€ä¸ª for å¾ªç¯æ˜¯æ›´æ–°ç½‘ç»œæƒé‡çš„åœ°æ–¹ï¼ˆç¬¬ 28[420] è¡Œè‡³ç¬¬ 30 è¡Œ[420]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The retention teamâ€™s simple transactional database, containing all the contacts they had made with customers, and the outcomes of these contacts, stretching back to a time horizon of 12 months",
            "zh": "ä¿ç•™å›¢é˜Ÿçš„ç®€å•äº‹åŠ¡æ•°æ®åº“ï¼ŒåŒ…å«ä»–ä»¬ä¸å®¢æˆ·å»ºç«‹çš„æ‰€æœ‰è”ç³»ï¼Œä»¥åŠè¿™äº›è”ç³»çš„ç»“æœï¼Œå¯ä»¥è¿½æº¯åˆ° 12 ä¸ªæœˆçš„æ—¶é—´èŒƒå›´"
        }
    },
    {
        "translation": {
            "en": "(c) Is the training dynamic of this network stable, or is it suffering from vanishing or exploding gradients?",
            "zh": "ï¼ˆcï¼‰ è¯¥ç½‘ç»œçš„è®­ç»ƒåŠ¨æ€æ˜¯ç¨³å®šçš„ï¼Œè¿˜æ˜¯å—åˆ°æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸çš„å½±å“ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "0.81",
            "zh": "0.81"
        }
    },
    {
        "translation": {
            "en": "11.4â€…â€…â€…A simple grid world. The start position is annotated with an S and the goal with a G. The squares marked f denote fire, which is very damaging to an agent.",
            "zh": "11.4 ä¸€ä¸ªç®€å•çš„ç½‘æ ¼ä¸–ç•Œã€‚èµ·å§‹ä½ç½®ç”¨ S æ ‡æ³¨ï¼Œç›®æ ‡ç”¨ G æ ‡æ³¨ã€‚æ ‡æœ‰ f çš„æ–¹å—è¡¨ç¤ºç«ï¼Œè¿™å¯¹ç‰¹å·¥çš„ä¼¤å®³éå¸¸å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "We have now calculated the Î´s for all the neurons in the network for d2.",
            "zh": "æˆ‘ä»¬ç°åœ¨å·²ç»è®¡ç®—äº† d2 ç½‘ç»œä¸­æ‰€æœ‰ç¥ç»å…ƒçš„ Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is because as we progress along the sequence of conditional probabilities specified by the chain rule, the size of the set of conditioning events for each term increases.",
            "zh": "è¿™æ˜¯å› ä¸ºéšç€æˆ‘ä»¬æ²¿ç€é“¾å¼è§„åˆ™æŒ‡å®šçš„æ¡ä»¶æ¦‚ç‡åºåˆ—å‰è¿›ï¼Œæ¯ä¸ªé¡¹çš„æ¡ä»¶äº‹ä»¶é›†çš„å¤§å°ä¼šå¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.07",
            "zh": "0.07"
        }
    },
    {
        "translation": {
            "en": "In a slight variation of the bar plot, we can show densities rather than frequencies by dividing each frequency by the total number of values in the dataset.",
            "zh": "åœ¨æ¡å½¢å›¾çš„è½»å¾®å˜åŒ–ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ¯ä¸ªé¢‘ç‡é™¤ä»¥æ•°æ®é›†ä¸­çš„å€¼æ€»æ•°æ¥æ˜¾ç¤ºå¯†åº¦è€Œä¸æ˜¯é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.18[573] shows the expected targets and a set of model predictions for a multinomial prediction problem in which the species of a bacteria present in a sample is determined using the results of spectrography performed on the sample.19 In this example, we are trying to distinguish between four species of the bacterial genus Fructobacillus, namely, durionis, ficulneus, fructosus, and pseudoficulneus (abbreviated as pseudo.",
            "zh": "è¡¨9.18[573]æ˜¾ç¤ºäº†å¤šé¡¹å¼é¢„æµ‹é—®é¢˜çš„é¢„æœŸç›®æ ‡å’Œä¸€ç»„æ¨¡å‹é¢„æµ‹ï¼Œå…¶ä¸­æ ·å“ä¸­å­˜åœ¨çš„ç»†èŒç§ç±»æ˜¯ä½¿ç”¨å¯¹æ ·å“è¿›è¡Œçš„å…‰è°±ç»“æœç¡®å®šçš„.19åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è¯•å›¾åŒºåˆ†ç»†èŒå±æœç³–æ†èŒçš„å››ä¸ªç‰©ç§ï¼Œ å³durionisã€ficulneusã€fructosuså’Œpseudoficulneusï¼ˆç¼©å†™ä¸ºpseudo."
        }
    },
    {
        "translation": {
            "en": "This interpretability is very important in some domains.",
            "zh": "è¿™ç§å¯è§£é‡Šæ€§åœ¨æŸäº›é¢†åŸŸéå¸¸é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.9â€…â€…â€…The relevant smoothed probabilities, from Table 6.8[269], needed by the naÃ¯ve Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each target levels.",
            "zh": "6.9 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹éœ€è¦è¡¨6.8[269]ä¸­çš„ç›¸å…³å¹³æ»‘æ¦‚ç‡ï¼Œä»¥ä¾¿å¯¹CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç›®æ ‡æ°´å¹³çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hospital management are concerned that the cause of the high readmittance rate for diabetes patients might be that they are discharged too early or that their care plans while in the hospital are not addressing all their needs.",
            "zh": "åŒ»é™¢ç®¡ç†å±‚æ‹…å¿ƒï¼Œç³–å°¿ç—…æ‚£è€…å†å…¥é™¢ç‡é«˜çš„åŸå› å¯èƒ½æ˜¯ä»–ä»¬å‡ºé™¢å¾—å¤ªæ—©ï¼Œæˆ–è€…ä»–ä»¬åœ¨åŒ»é™¢æœŸé—´çš„æŠ¤ç†è®¡åˆ’æ²¡æœ‰æ»¡è¶³ä»–ä»¬çš„æ‰€æœ‰éœ€æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Redundant: a descriptive feature is redundant if it has a strong correlation with another descriptive feature.",
            "zh": "å†—ä½™ï¼šå¦‚æœæè¿°æ€§ç‰¹å¾ä¸å¦ä¸€ä¸ªæè¿°æ€§ç‰¹å¾å…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œåˆ™è¯¥ç‰¹å¾æ˜¯å¤šä½™çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In spite of these difficulties, for machine learning purposes, correlation is a very good measure of the relationship between two continuous features.9",
            "zh": "å°½ç®¡å­˜åœ¨è¿™äº›å›°éš¾ï¼Œä½†å‡ºäºæœºå™¨å­¦ä¹ çš„ç›®çš„ï¼Œç›¸å…³æ€§æ˜¯ä¸¤ä¸ªè¿ç»­ç‰¹å¾ä¹‹é—´å…³ç³»çš„ä¸€ä¸ªå¾ˆå¥½çš„åº¦é‡9ã€‚"
        }
    },
    {
        "translation": {
            "en": "where denotes the network graph, D is the training data, is the set of entries in the CPTs of , d is the number of parameters of (i.e., how many entries in the CPTs of ), and n is the number of instances in D. This metric contains a term describing how well the model predicts the data as well as a term that punishes complex models .",
            "zh": "å…¶ä¸­è¡¨ç¤ºç½‘ç»œå›¾ï¼ŒD æ˜¯è®­ç»ƒæ•°æ®ï¼Œæ˜¯ çš„ CPT ä¸­çš„æ¡ç›®é›†ï¼Œd æ˜¯ çš„å‚æ•°ä¸ªæ•°ï¼ˆå³ çš„ ä¸ªæ¡ç›®æ•°ï¼‰ï¼Œn æ˜¯ çš„å®ä¾‹æ•°ã€‚è¯¥æŒ‡æ ‡åŒ…å«ä¸€ä¸ªæè¿°æ¨¡å‹é¢„æµ‹æ•°æ®çš„æœ¯è¯­ï¼Œä»¥åŠä¸€ä¸ªæƒ©ç½šå¤æ‚æ¨¡å‹çš„æœ¯è¯­ã€‚"
        }
    },
    {
        "translation": {
            "en": "prediction, 4, 758",
            "zh": "é¢„æµ‹ï¼Œ4,758"
        }
    },
    {
        "translation": {
            "en": "(b) The number of prior criminal convictions held by people given prison sentences in a city district over the course of a full year.",
            "zh": "ï¼ˆbï¼‰ åœ¨ä¸€æ•´å¹´çš„æ—¶é—´é‡Œï¼Œåœ¨ä¸€ä¸ªåŸå¸‚åœ°åŒºè¢«åˆ¤åˆ‘çš„äººæ‰€æŒæœ‰çš„å…ˆå‰çš„åˆ‘äº‹å®šç½ªçš„æ¬¡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, the final model trained provides the overall output of the ensemble as it implicitly combines the outputs of all models trainedâ€”recall Equation (4.18)[165].",
            "zh": "ç›¸åï¼Œè®­ç»ƒçš„æœ€ç»ˆæ¨¡å‹æä¾›äº†é›†åˆçš„æ•´ä½“è¾“å‡ºï¼Œå› ä¸ºå®ƒéšå¼åœ°ç»„åˆäº†æ‰€æœ‰è®­ç»ƒæ¨¡å‹çš„è¾“å‡ºâ€”â€”å›æƒ³æ–¹ç¨‹ï¼ˆ4.18ï¼‰[165]ã€‚"
        }
    },
    {
        "translation": {
            "en": "We say that the estimate is unbiased if its variance, on average, equals that of the population variance.",
            "zh": "æˆ‘ä»¬è¯´ï¼Œå¦‚æœä¼°è®¡å€¼çš„æ–¹å·®å¹³å‡ç­‰äºæ€»ä½“æ–¹å·®çš„æ–¹å·®ï¼Œåˆ™è¯¥ä¼°è®¡å€¼æ˜¯æ— åçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Worldwide breast cancer is the most common form of cancer for women, and the second most common form of cancer overall.18 Reliable, population-wide screening is one tool that can be used to reduce the impact of breast cancer, and there is an opportunity for machine learning to be used for this.",
            "zh": "åœ¨ä¸–ç•ŒèŒƒå›´å†…ï¼Œä¹³è…ºç™Œæ˜¯å¥³æ€§æœ€å¸¸è§çš„ç™Œç—‡å½¢å¼ï¼Œä¹Ÿæ˜¯ç¬¬äºŒå¸¸è§çš„ç™Œç—‡å½¢å¼.18å¯é çš„å…¨äººç¾¤ç­›æŸ¥æ˜¯ä¸€ç§å¯ç”¨äºå‡å°‘ä¹³è…ºç™Œå½±å“çš„å·¥å…·ï¼Œå¹¶ä¸”æœ‰æœºä¼šå°†æœºå™¨å­¦ä¹ ç”¨äºæ­¤ã€‚"
        }
    },
    {
        "translation": {
            "en": "non-parametric model, 732",
            "zh": "éå‚æ•°æ¨¡å‹ï¼Œ732"
        }
    },
    {
        "translation": {
            "en": "Ross used the ABT to train, tune, and test a series of decision trees to predict churn given the set of descriptive features.",
            "zh": "Ross ä½¿ç”¨ ABT æ¥è®­ç»ƒã€è°ƒæ•´å’Œæµ‹è¯•ä¸€ç³»åˆ—å†³ç­–æ ‘ï¼Œä»¥æ ¹æ®ä¸€ç»„æè¿°æ€§ç‰¹å¾é¢„æµ‹å®¢æˆ·æµå¤±ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.12â€…â€…â€…The similarity between the current trial user, q, and the two users in the dataset, d1 and d2, in terms of co-presence (CP), co-absence (CA), presence-absence (PA), and absence-presence (AP).",
            "zh": "5.12 å½“å‰è¯•éªŒç”¨æˆ· q ä¸æ•°æ®é›†ä¸­çš„ä¸¤ä¸ªç”¨æˆ· d1 å’Œ d2 åœ¨å…±å­˜ ï¼ˆCPï¼‰ã€å…±ç¼º ï¼ˆCAï¼‰ã€ç¼ºå‹¤-ç¼ºå‹¤ ï¼ˆPAï¼‰ å’Œç¼ºå‹¤-å­˜åœ¨ ï¼ˆAPï¼‰ æ–¹é¢çš„ç›¸ä¼¼æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C. 2004. Introduction to statistical quality control. Wiley.",
            "zh": "è’™å“¥é©¬åˆ©ï¼Œé“æ ¼æ‹‰æ–¯ C. 2004 å¹´ã€‚ç»Ÿè®¡è´¨é‡æ§åˆ¶å¯¼è®ºã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Dataset for predicting the vegetation in an area with a continuous ELEVATION feature (measured in feet).",
            "zh": "ç”¨äºé¢„æµ‹å…·æœ‰è¿ç»­ ELEVATION è¦ç´ ï¼ˆä»¥è‹±å°ºä¸ºå•ä½ï¼‰çš„åŒºåŸŸä¸­çš„æ¤è¢«çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) On the basis of this sequence of states, calculate a transition matrix that gives the probability of moving between each of the three states.",
            "zh": "ï¼ˆaï¼‰ æ ¹æ®è¿™ä¸€ç³»åˆ—çŠ¶æ€ï¼Œè®¡ç®—ä¸€ä¸ªè¿‡æ¸¡çŸ©é˜µï¼Œè¯¥çŸ©é˜µç»™å‡ºäº†åœ¨ä¸‰ç§çŠ¶æ€ä¸­çš„æ¯ä¸€ä¸ªçŠ¶æ€ä¹‹é—´ç§»åŠ¨çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Makhoul, John, Amro El-Jaroudi, and Richard Schwartz. 1989. Formation of disconnected decision regions with a single hidden layer. In Proceedings of the international joint conference on neural networks, Vol. 1, 455â€“460. IEEE.",
            "zh": "Makhoulã€Johnã€Amro El-Jaroudi å’Œ Richard Schwartzã€‚1989. å…·æœ‰å•ä¸ªéšè—å±‚çš„æ–­å¼€è¿æ¥å†³ç­–åŒºåŸŸçš„å½¢æˆã€‚åœ¨ç¥ç»ç½‘ç»œå›½é™…è”åˆä¼šè®®è®ºæ–‡é›†ï¼Œç¬¬ 1 å·ï¼Œ455â€“460ã€‚IEEEçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Common manipulations used in this process include aggregates, flags, ratios, and mappings, although any manipulation is valid.",
            "zh": "æ­¤è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å¸¸è§æ“ä½œåŒ…æ‹¬èšåˆã€æ ‡å¿—ã€æ¯”ç‡å’Œæ˜ å°„ï¼Œå°½ç®¡ä»»ä½•æ“ä½œéƒ½æ˜¯æœ‰æ•ˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is another example of a data quality issue due to invalid data.",
            "zh": "è¿™æ˜¯ç”±äºæ— æ•ˆæ•°æ®å¯¼è‡´çš„æ•°æ®è´¨é‡é—®é¢˜çš„å¦ä¸€ä¸ªç¤ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the episode proceeds through time-steps t = 1,â€¦,e. At each time-step the agent makes an observation, ot, of the environment, takes an action, at, and receives a reward, rt, based on that action. This cycle is illustrated in Figure 11.1[639].",
            "zh": "å…¶ä¸­ï¼Œå‰§é›†é€šè¿‡æ—¶é—´æ­¥é•¿ t = 1,...,e è¿›è¡Œã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸­ï¼Œæ™ºèƒ½ä½“å¯¹ç¯å¢ƒè¿›è¡Œè§‚å¯Ÿï¼Œé‡‡å–è¡ŒåŠ¨ï¼Œå¹¶æ ¹æ®è¯¥è¡ŒåŠ¨è·å¾—å¥–åŠ±rtã€‚å›¾11.1[639]è¯´æ˜äº†è¿™ä¸ªå¾ªç¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "The descriptive features measure whether a customer buys baby food, BBY; alcohol, ALC; or organic vegetable products, ORG.",
            "zh": "æè¿°æ€§ç‰¹å¾è¡¡é‡å®¢æˆ·æ˜¯å¦è´­ä¹°å©´å„¿é£Ÿå“ï¼ŒBBY;é…’ç²¾ï¼ŒALC;æˆ–æœ‰æœºè”¬èœäº§å“ï¼ŒORGã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability-Based Learning",
            "zh": "åŸºäºæ¦‚ç‡çš„å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Transformer, 523",
            "zh": "å˜å‹å™¨ï¼Œ523"
        }
    },
    {
        "translation": {
            "en": "Based on analysis of the associated data and capacity requirements, the analytics practitioner can assess the feasibility of each predictive analytics solution proposed to address a business problem.",
            "zh": "åŸºäºå¯¹ç›¸å…³æ•°æ®å’Œå®¹é‡è¦æ±‚çš„åˆ†æï¼Œåˆ†æä»ä¸šäººå‘˜å¯ä»¥è¯„ä¼°ä¸ºè§£å†³ä¸šåŠ¡é—®é¢˜è€Œæå‡ºçš„æ¯ä¸ªé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Generic Events",
            "zh": "é€šç”¨äº‹ä»¶"
        }
    },
    {
        "translation": {
            "en": "5.8â€…â€…â€…(a) The k-d tree generated for the dataset in Table 5.4[191] after the initial split; (b) the partitioning of the feature space by the k-d tree in (a); (c) the k-d tree after the dataset at the left child of the root has been split; and (d) the partitioning of the feature space by the k-d tree in (c).",
            "zh": "5.8 ï¼ˆaï¼‰ åˆå§‹æ‹†åˆ†åä¸ºè¡¨5.4[191]ä¸­çš„æ•°æ®é›†ç”Ÿæˆçš„k-dæ ‘;ï¼ˆbï¼‰åœ¨ï¼ˆaï¼‰ä¸­ç”¨k-dæ ‘å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ’åˆ†;ï¼ˆcï¼‰ æ ¹å·¦ä¾§å­é¡¹çš„æ•°æ®é›†è¢«æ‹†åˆ†åçš„ k-d æ ‘;ï¼ˆdï¼‰åœ¨ï¼ˆcï¼‰ä¸­ç”¨k-dæ ‘å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ†åŒºã€‚"
        }
    },
    {
        "translation": {
            "en": "0.071",
            "zh": "0.071"
        }
    },
    {
        "translation": {
            "en": "Sutton and Bartoâ€™s textbook has been the definitive work on reinforcement learning since it was first published in (Sutton and Barto, 1998), and their recent 2nd edition (Sutton and Barto, 2018) is an excellent update.",
            "zh": "Sutton å’Œ Barto çš„æ•™ç§‘ä¹¦è‡ª ï¼ˆSutton and Bartoï¼Œ 1998ï¼‰ é¦–æ¬¡å‡ºç‰ˆä»¥æ¥ä¸€ç›´æ˜¯å…³äºå¼ºåŒ–å­¦ä¹ çš„æƒå¨è‘—ä½œï¼Œä»–ä»¬æœ€è¿‘çš„ç¬¬ 2 ç‰ˆï¼ˆSutton and Bartoï¼Œ 2018ï¼‰æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ›´æ–°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Within the continuous features, only AGE stood out with 11.47% of values missing.",
            "zh": "åœ¨è¿ç»­ç‰¹å¾ä¸­ï¼Œåªæœ‰ AGE è„±é¢–è€Œå‡ºï¼Œç¼ºå°‘ 11.47% çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "She used step-wise sequential feature selection again, and this time 32 features were chosen.18 This model was able to achieve a classification accuracy of 68.225% (with an average class accuracy of 56.621%).",
            "zh": "å¥¹å†æ¬¡ä½¿ç”¨é€æ­¥é¡ºåºç‰¹å¾é€‰æ‹©ï¼Œè¿™æ¬¡é€‰æ‹©äº† 32 ä¸ªç‰¹å¾.18 è¯¥æ¨¡å‹èƒ½å¤Ÿå®ç° 68.225% çš„åˆ†ç±»å‡†ç¡®ç‡ï¼ˆå¹³å‡ç±»å‡†ç¡®ç‡ä¸º 56.621%ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "After discussion with the AT executive team, it was decided that the analytics solution most appropriate to focus on was predicting which customers are most likely to churn in the near future. There were a number of reasons this project was selected:",
            "zh": "åœ¨ä¸ AT æ‰§è¡Œå›¢é˜Ÿè®¨è®ºåï¼Œå†³å®šæœ€åˆé€‚çš„åˆ†æè§£å†³æ–¹æ¡ˆæ˜¯é¢„æµ‹å“ªäº›å®¢æˆ·åœ¨ä¸ä¹…çš„å°†æ¥æœ€æœ‰å¯èƒ½æµå¤±ã€‚é€‰æ‹©è¿™ä¸ªé¡¹ç›®çš„åŸå› æœ‰å¾ˆå¤šï¼š"
        }
    },
    {
        "translation": {
            "en": "The probabilities associated with each Twist transition shown in Figure 11.3[648] have been calculated based on what can happen in a game of TwentyTwos, under the assumption of an infinite deck from which cards are dealt.",
            "zh": "å›¾ 11.3[648] æ‰€ç¤ºçš„æ¯ä¸ª Twist è½¬æ¢ç›¸å…³çš„æ¦‚ç‡æ˜¯æ ¹æ® TwentyTwo æ¸¸æˆä¸­å¯èƒ½å‘ç”Ÿçš„æƒ…å†µè®¡ç®—çš„ï¼Œå‡è®¾ä»ä¸­å‘ç‰Œçš„æ— é™å¥—ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "8. That is, a and b = b and a.",
            "zh": "8. ä¹Ÿå°±æ˜¯è¯´ï¼Œa å’Œ b = b å’Œ aã€‚"
        }
    },
    {
        "translation": {
            "en": "However, this may not always be the case, because some weight updates may move in an orthogonal direction to the true gradient or even cause the error to increase; this can slow down the training of the network.",
            "zh": "ç„¶è€Œï¼Œæƒ…å†µå¯èƒ½å¹¶éæ€»æ˜¯å¦‚æ­¤ï¼Œå› ä¸ºæŸäº›æƒé‡æ›´æ–°å¯èƒ½ä¼šæ²¿æ­£äº¤æ–¹å‘ç§»åŠ¨åˆ°çœŸå®æ¢¯åº¦ï¼Œç”šè‡³å¯¼è‡´è¯¯å·®å¢åŠ ;è¿™å¯èƒ½ä¼šå‡æ…¢ç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is shown in the bar plot in Figure 6.1(c)[244], which shows an equal likelihood for each position.",
            "zh": "å¦‚å›¾6.1ï¼ˆcï¼‰[244]ä¸­çš„æ¡å½¢å›¾æ‰€ç¤ºï¼Œå›¾ä¸­æ˜¾ç¤ºäº†æ¯ä¸ªä»“ä½çš„ç›¸ç­‰ä¼¼ç„¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "These z and a values will be found in the corresponding gray boxes in Figure 8.18[440].",
            "zh": "è¿™äº› z å’Œ a å€¼å¯ä»¥åœ¨å›¾ 8.18[440] çš„ç›¸åº”ç°è‰²æ¡†ä¸­æ‰¾åˆ°ã€‚"
        }
    },
    {
        "translation": {
            "en": "early stopping, 418, 432, 434, 472, 472, 477",
            "zh": "æå‰åœæ­¢ï¼Œ 418ï¼Œ 432ï¼Œ 434ï¼Œ 472ï¼Œ 472ï¼Œ 477"
        }
    },
    {
        "translation": {
            "en": "Some of the descriptive features were simply copies of available raw data.",
            "zh": "ä¸€äº›æè¿°æ€§ç‰¹å¾åªæ˜¯å¯ç”¨åŸå§‹æ•°æ®çš„å‰¯æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "expected return, 642, 643, 676",
            "zh": "é¢„æœŸå›æŠ¥ï¼Œ 642ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo8 is a crowdsourced, citizen science effort in which people can log on to a website and categorize images of galaxiesâ€”taken from the SDSSâ€”into different groups.",
            "zh": "Galaxy Zoo8 æ˜¯ä¸€é¡¹ä¼—åŒ…çš„å…¬æ°‘ç§‘å­¦é¡¹ç›®ï¼Œäººä»¬å¯ä»¥ç™»å½•ç½‘ç«™å¹¶å°†ä» SDSS æ‹æ‘„çš„æ˜Ÿç³»å›¾åƒåˆ†ç±»ä¸ºä¸åŒçš„ç»„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The action-value table is still fairly sparse after the first iteration with most combinations having changed little from their randomly initialized values.",
            "zh": "åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¹‹åï¼Œæ“ä½œå€¼è¡¨ä»ç„¶ç›¸å½“ç¨€ç–ï¼Œå¤§å¤šæ•°ç»„åˆä¸å…¶éšæœºåˆå§‹åŒ–çš„å€¼ç›¸æ¯”å˜åŒ–ä¸å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.2478",
            "zh": "0.2478"
        }
    },
    {
        "translation": {
            "en": "Elementwise Product",
            "zh": "Elementwise äº§å“"
        }
    },
    {
        "translation": {
            "en": "We know from our earlier calculations that the entropy for this dataset is 1.5567 bits (see Equation (4.5)[137]) and that the information gain for the categorical features are IG(STREAM, ) = 0.3060 and IG(SLOPE, ) = 0.5774 (see Table 4.4[137]).",
            "zh": "æˆ‘ä»¬ä»å‰é¢çš„è®¡ç®—ä¸­çŸ¥é“ï¼Œè¯¥æ•°æ®é›†çš„ç†µä¸º1.5567ä½ï¼ˆå‚è§å…¬å¼ï¼ˆ4.5ï¼‰[137]ï¼‰ï¼Œåˆ†ç±»ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šä¸ºIGï¼ˆSTREAMï¼Œ ï¼‰ = 0.3060å’ŒIGï¼ˆSLOPEï¼Œ ï¼‰ = 0.5774ï¼ˆå‚è§è¡¨4.4[137]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Based on the new likelihoods, you guess that the queen is in the center position, and happily, this turns out to be correct (see Figure 6.2(c)[245]).",
            "zh": "æ ¹æ®æ–°çš„å¯èƒ½æ€§ï¼Œä½ çŒœåˆ°å¥³ç‹å¤„äºä¸­å¿ƒä½ç½®ï¼Œä»¤äººé«˜å…´çš„æ˜¯ï¼Œç»“æœè¯æ˜è¿™æ˜¯æ­£ç¡®çš„ï¼ˆè§å›¾6.2ï¼ˆcï¼‰[245]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "GPUs are designed to carry out matrix operations very quickly.",
            "zh": "GPU æ—¨åœ¨éå¸¸å¿«é€Ÿåœ°æ‰§è¡ŒçŸ©é˜µè¿ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "composition, 401",
            "zh": "ç»„æˆï¼Œ401"
        }
    },
    {
        "translation": {
            "en": "9.1â€…â€…â€…The process of building and evaluating a model using a hold-out test set.",
            "zh": "9.1 ä½¿ç”¨ä¿æŒæµ‹è¯•é›†æ„å»ºå’Œè¯„ä¼°æ¨¡å‹çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.7â€…â€…â€…The confusion matrices for the models after feature selection.",
            "zh": "13.7 ç‰¹å¾é€‰æ‹©åæ¨¡å‹çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "If we could capture this relationship in a model, we would be able to do two important things.",
            "zh": "å¦‚æœæˆ‘ä»¬èƒ½åœ¨æ¨¡å‹ä¸­æ•æ‰åˆ°è¿™ç§å…³ç³»ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿåšä¸¤ä»¶é‡è¦çš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is the output of this layer of neurons that generates the feature map in Equation (8.94)[490].",
            "zh": "æ­£æ˜¯è¿™å±‚ç¥ç»å…ƒçš„è¾“å‡ºç”Ÿæˆäº†ç­‰å¼ï¼ˆ8.94ï¼‰[490]ä¸­çš„ç‰¹å¾å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "YEARSINCURRENTEMPLOYMENT: The number of years that the taxpayer has been in their current job.",
            "zh": "YEARSINCURRENTEMPLOYMENTï¼šçº³ç¨äººä»äº‹å½“å‰å·¥ä½œçš„å¹´æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "ergodic Markov chain, 299",
            "zh": "éå†é©¬å°”å¯å¤«é“¾ï¼Œ299"
        }
    },
    {
        "translation": {
            "en": "In this first path of processing hxt is passed through a layer of sigmoid units that is the same width as the cell state.",
            "zh": "åœ¨ç¬¬ä¸€ä¸ªå¤„ç†è·¯å¾„ä¸­ï¼Œhxt é€šè¿‡ä¸å•å…ƒçŠ¶æ€å®½åº¦ç›¸åŒçš„ sigmoid å•å…ƒå±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The following table lists the scores returned by the same prediction model for a new test set of 12 examples.",
            "zh": "ï¼ˆbï¼‰ ä¸‹è¡¨åˆ—å‡ºäº†åŒä¸€é¢„æµ‹æ¨¡å‹å¯¹12ä¸ªæ ·æœ¬çš„æ–°æµ‹è¯•é›†è¿”å›çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Through our years of teaching this material, we have developed an understanding of what is a reasonable amount of material to cover in a one-semester introductory module and in a two-semester more advanced module.",
            "zh": "é€šè¿‡æˆ‘ä»¬å¤šå¹´çš„æ•™å­¦ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº†ä¸€å­¦æœŸçš„å…¥é—¨æ¨¡å—å’Œä¸¤ä¸ªå­¦æœŸçš„é«˜çº§æ¨¡å—ä¸­åº”è¯¥æ¶µç›–çš„åˆç†æ•°é‡çš„ææ–™ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 10.2",
            "zh": "è¡¨ 10.2"
        }
    },
    {
        "translation": {
            "en": "The process of building and evaluating a model using a hold-out test set.",
            "zh": "ä½¿ç”¨ä¿æŒæµ‹è¯•é›†æ„å»ºå’Œè¯„ä¼°æ¨¡å‹çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It has been shown repeatedly, however, that it is in fact possible to learn sophisticated, long-term behaviors using the maximization of cumulative reward alone.",
            "zh": "ç„¶è€Œï¼Œäº‹å®ä¸€å†è¡¨æ˜ï¼Œäº‹å®ä¸Šï¼Œä»…ä½¿ç”¨ç´¯ç§¯å¥–åŠ±çš„æœ€å¤§åŒ–ï¼Œå°±å¯ä»¥å­¦ä¹ å¤æ‚çš„é•¿æœŸè¡Œä¸ºã€‚"
        }
    },
    {
        "translation": {
            "en": "feature subset space, 228",
            "zh": "ç‰¹å¾å­é›†ç©ºé—´ï¼Œ228"
        }
    },
    {
        "translation": {
            "en": "3.4.2â€…â€…â€…Handling Outliers",
            "zh": "3.4.2 å¤„ç†å¼‚å¸¸å€¼"
        }
    },
    {
        "translation": {
            "en": "The player loses in all other cases.",
            "zh": "åœ¨æ‰€æœ‰å…¶ä»–æƒ…å†µä¸‹ï¼Œç©å®¶éƒ½è¾“äº†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because the error rate for the leaf nodes is higher than the error rate for the root node of the subtree, this subtree is pruned and replaced by a leaf node.",
            "zh": "ç”±äºå¶èŠ‚ç‚¹çš„é”™è¯¯ç‡é«˜äºå­æ ‘çš„æ ¹èŠ‚ç‚¹çš„é”™è¯¯ç‡ï¼Œå› æ­¤å°†ä¿®å‰ªæ­¤å­æ ‘å¹¶å°†å…¶æ›¿æ¢ä¸ºå¶èŠ‚ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall that the receptive fields of the neurons in the sub-sampling layer do not overlap.",
            "zh": "å›æƒ³ä¸€ä¸‹ï¼Œå­é‡‡æ ·å±‚ä¸­ç¥ç»å…ƒçš„æ„Ÿå—é‡ä¸é‡å ã€‚"
        }
    },
    {
        "translation": {
            "en": "We are now in a position to build a linear regression model that uses all the continuous descriptive features in the office rentals dataset in Table 7.1[313] (i.e., all features except for ENERGY RATING). The general structure of the model is",
            "zh": "æˆ‘ä»¬ç°åœ¨èƒ½å¤Ÿå»ºç«‹ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨è¡¨7.1[313]ä¸­åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†ä¸­çš„æ‰€æœ‰è¿ç»­æè¿°æ€§ç‰¹å¾ï¼ˆå³é™¤ENERGY RATINGä»¥å¤–çš„æ‰€æœ‰ç‰¹å¾ï¼‰ã€‚æ¨¡å‹çš„ä¸€èˆ¬ç»“æ„æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The structures of the tables included in a data quality report to describe (a) continuous features and (b) categorical features.",
            "zh": "æ•°æ®è´¨é‡æŠ¥å‘Šä¸­åŒ…å«çš„è¡¨çš„ç»“æ„ï¼Œç”¨äºæè¿° ï¼ˆaï¼‰ è¿ç»­ç‰¹å¾å’Œ ï¼ˆbï¼‰ åˆ†ç±»ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The weight matrix is again organized with one row of weights per neuron and with the bias term weight as the first element in the row (shown in black).",
            "zh": "æƒé‡çŸ©é˜µå†æ¬¡ç”±æ¯ä¸ªç¥ç»å…ƒçš„ä¸€è¡Œæƒé‡ç»„ç»‡ï¼Œå¹¶å°†åå·®é¡¹æƒé‡ä½œä¸ºè¡Œä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆä»¥é»‘è‰²æ˜¾ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. sub-sampling (pooling).",
            "zh": "3. å­é‡‡æ ·ï¼ˆæ± åŒ–ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Long after it was first proposed, k-means remains a commonly used clustering algorithm; however, there have been many modifications and alternatives proposed over the years.",
            "zh": "åœ¨é¦–æ¬¡æå‡ºå¾ˆä¹…ä¹‹åï¼Œk-means ä»ç„¶æ˜¯ä¸€ç§å¸¸ç”¨çš„èšç±»ç®—æ³•;ç„¶è€Œï¼Œå¤šå¹´æ¥å·²ç»æå‡ºäº†è®¸å¤šä¿®æ”¹å’Œæ›¿ä»£æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "centroid linkage, 619",
            "zh": "è´¨å¿ƒè¿æ†ï¼Œ619"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5",
            "zh": "å›¾ 8.5"
        }
    },
    {
        "translation": {
            "en": "19. The data in this question have been artificially created but were inspired by the famous Wisconsin breast cancer dataset first described by Mangasarian and Wolberg (1990), and available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "19. æœ¬é—®é¢˜ä¸­çš„æ•°æ®æ˜¯äººå·¥åˆ›å»ºçš„ï¼Œä½†çµæ„Ÿæ¥è‡ªè‘—åçš„å¨æ–¯åº·æ˜Ÿå·ä¹³è…ºç™Œæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”± Mangasarian å’Œ Wolberg ï¼ˆ1990ï¼‰ é¦–æ¬¡æè¿°ï¼Œå¯ä» UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ï¼ˆBache å’Œ Lichmanï¼Œ2013 å¹´ï¼‰è·å¾—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Node A has no parents, so the CPT just lists the unconditional probability distribution for A.",
            "zh": "èŠ‚ç‚¹ A æ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œå› æ­¤ CPT ä»…åˆ—å‡º A çš„æ— æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "The sales teamâ€™s transactional database, containing details of phone handsets issued to customers",
            "zh": "é”€å”®å›¢é˜Ÿçš„äº¤æ˜“æ•°æ®åº“ï¼ŒåŒ…å«å‘ç»™å®¢æˆ·çš„ç”µè¯å¬ç­’çš„è¯¦ç»†ä¿¡æ¯"
        }
    },
    {
        "translation": {
            "en": "11.6â€…â€…â€…Further Reading",
            "zh": "11.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "AMOUNT RECEIVED",
            "zh": "æ”¶åˆ°çš„é‡‘é¢"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18[226] provides a graphical insight into the relationship between the number of descriptive features in a dataset and the sampling density of the feature space.",
            "zh": "å›¾ 5.18[226] æä¾›äº†æ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾æ•°é‡ä¸ç‰¹å¾ç©ºé—´é‡‡æ ·å¯†åº¦ä¹‹é—´å…³ç³»çš„å›¾å½¢è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "COUNTRY: The name of the country",
            "zh": "å›½å®¶/åœ°åŒºï¼šå›½å®¶/åœ°åŒºåç§°"
        }
    },
    {
        "translation": {
            "en": "A linear regression model for the problem uses only two weights, w[0] and w[1].",
            "zh": "è¯¥é—®é¢˜çš„çº¿æ€§å›å½’æ¨¡å‹ä»…ä½¿ç”¨ä¸¤ä¸ªæƒé‡ï¼Œw[0] å’Œ w[1]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability is the branch of mathematics that deals with measuring the likelihood (or uncertainty) around events.",
            "zh": "æ¦‚ç‡æ˜¯æ•°å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œç”¨äºæµ‹é‡äº‹ä»¶çš„å¯èƒ½æ€§ï¼ˆæˆ–ä¸ç¡®å®šæ€§ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The (a) lift and (b) cumulative lift at each decile for the email predictions given in Table 9.11[557].",
            "zh": "è¡¨9.11[557]ä¸­ç»™å‡ºçš„ç”µå­é‚®ä»¶é¢„æµ‹çš„æ¯ä¸ªååˆ†ä½æ•°çš„ï¼ˆaï¼‰æå‡å’Œï¼ˆbï¼‰ç´¯ç§¯æå‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Li, Deren, Shuliang Wang, and Deyi Li. 2015. Spatial data mining. Springer.",
            "zh": "Liï¼Œ Derenï¼Œ Shuliang Wangï¼Œ and Deyi Li. 2015.ç©ºé—´æ•°æ®æŒ–æ˜ã€‚æ–¯æ™®æ—æ ¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.1",
            "zh": "å›¾ 9.1"
        }
    },
    {
        "translation": {
            "en": "These are shown in the column labeled t âˆ’ 0 in Table 4.15[166 they are simply the difference between the values predicted by the initial model and the target feature value for each instance in the dataset.",
            "zh": "è¿™äº›æ˜¾ç¤ºåœ¨è¡¨ 4.15 ä¸­æ ‡è®°ä¸º t âˆ’ 0 çš„åˆ—ä¸­[166]ï¼Œå®ƒä»¬åªæ˜¯åˆå§‹æ¨¡å‹é¢„æµ‹çš„å€¼ä¸æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹çš„ç›®æ ‡ç‰¹å¾å€¼ä¹‹é—´çš„å·®å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conveniently, this also determined the subset of the SDSS dataset (those galaxies used in the Galaxy Zoo project) that Jocelyn would use for this project.",
            "zh": "æ–¹ä¾¿çš„æ˜¯ï¼Œè¿™ä¹Ÿå†³å®šäº†Jocelynå°†ç”¨äºè¯¥é¡¹ç›®çš„SDSSæ•°æ®é›†ï¼ˆGalaxy Zooé¡¹ç›®ä¸­ä½¿ç”¨çš„æ˜Ÿç³»ï¼‰çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Once the Î´s for all the neurons in the network for an example have been calculated, then for each weight in the network the error gradients are accumulated (Lines 24[420] to 26[420]).",
            "zh": "ä¾‹å¦‚ï¼Œä¸€æ—¦è®¡ç®—äº†ç½‘ç»œä¸­æ‰€æœ‰ç¥ç»å…ƒçš„Î´ï¼Œé‚£ä¹ˆå¯¹äºç½‘ç»œä¸­çš„æ¯ä¸ªæƒé‡ï¼Œè¯¯å·®æ¢¯åº¦å°±ä¼šç´¯ç§¯ï¼ˆç¬¬24è¡Œ[420]è‡³26è¡Œ[420]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Mishne, Gilad, and Natalie S. Glance. 2006. Predicting movie sales from blogger sentiment. In AAAI spring symposium: Computational approaches to analyzing weblogs, 155â€“158.",
            "zh": "Mishneã€Gilad å’Œ Natalie S. Glanceã€‚2006. ä»åšä¸»æƒ…ç»ªé¢„æµ‹ç”µå½±é”€å”®.åœ¨AAAIæ˜¥å­£ç ”è®¨ä¼šä¸Šï¼šåˆ†æåšå®¢çš„è®¡ç®—æ–¹æ³•ï¼Œ155-158ã€‚"
        }
    },
    {
        "translation": {
            "en": "bias term, 480, 493",
            "zh": "åç½®é¡¹ï¼Œ480,493"
        }
    },
    {
        "translation": {
            "en": "We can also use a weighted k nearest neighbor model to make predictions for continuous targets that take into account the distance from the query instance to the neighbors (just like we did for categorical target features in Section 5.4.1[191]). To do this, the model prediction equation in Equation (5.7)[208] is changed to",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨åŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹å¯¹è¿ç»­ç›®æ ‡è¿›è¡Œé¢„æµ‹ï¼Œè¿™äº›ç›®æ ‡è€ƒè™‘äº†ä»æŸ¥è¯¢å®ä¾‹åˆ°é‚»å±…çš„è·ç¦»ï¼ˆå°±åƒæˆ‘ä»¬åœ¨ç¬¬ 5.4.1[191] èŠ‚ä¸­å¯¹åˆ†ç±»ç›®æ ‡ç‰¹å¾æ‰€åšçš„é‚£æ ·ï¼‰ã€‚ä¸ºæ­¤ï¼Œå°†å…¬å¼ï¼ˆ5.7ï¼‰[208]ä¸­çš„æ¨¡å‹é¢„æµ‹æ–¹ç¨‹æ›´æ”¹ä¸º"
        }
    },
    {
        "translation": {
            "en": "This equivalence is true no matter how many hidden layers we introduce into the network.",
            "zh": "æ— è®ºæˆ‘ä»¬åœ¨ç½‘ç»œä¸­å¼•å…¥å¤šå°‘éšè—å±‚ï¼Œè¿™ç§ç­‰ä»·æ€§éƒ½æ˜¯æ­£ç¡®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The plot shows that the initial sum of squared errors of the network is just under 0.6, and this drops to < 0.2 after the first epoch.",
            "zh": "è¯¥å›¾æ˜¾ç¤ºï¼Œç½‘ç»œçš„åˆå§‹å¹³æ–¹è¯¯å·®ä¹‹å’Œç•¥ä½äº 0.6ï¼Œåœ¨ç¬¬ä¸€ä¸ªçºªå…ƒä¹‹åé™è‡³ 0.2 <ã€‚"
        }
    },
    {
        "translation": {
            "en": "Importantly, the resulting data was skewed even though the surveys were large.",
            "zh": "é‡è¦çš„æ˜¯ï¼Œå³ä½¿è°ƒæŸ¥è§„æ¨¡å¾ˆå¤§ï¼Œç»“æœæ•°æ®ä¹Ÿæ˜¯æœ‰åå·®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.6â€…â€…Bar plot of the continuous TRAINING EXPENSES feature from Table A.1[750].",
            "zh": "A.6 è¡¨A.1[750]ä¸­è¿ç»­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, for New Sample 1, the stability index is",
            "zh": "ä¾‹å¦‚ï¼Œå¯¹äºæ–°æ ·æœ¬ 1ï¼Œç¨³å®šæ€§æŒ‡æ•°ä¸º"
        }
    },
    {
        "translation": {
            "en": "This has been the case in the recent deep reinforcement learning successes at games like go, chess, and poker at which reinforcement learning agents are playing at world class level and use play strategies that are a total surprise to human players.",
            "zh": "æœ€è¿‘åœ¨å›´æ£‹ã€å›½é™…è±¡æ£‹å’Œæ‰‘å…‹ç­‰æ¸¸æˆä¸­çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æˆåŠŸå°±æ˜¯è¿™ç§æƒ…å†µï¼Œåœ¨è¿™äº›æ¸¸æˆä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ä»£ç†æ­£åœ¨å‘æŒ¥ä¸–ç•Œçº§æ°´å¹³ï¼Œå¹¶ä½¿ç”¨çš„ç©æ³•ç­–ç•¥è®©äººç±»ç©å®¶å®Œå…¨æ„Ÿåˆ°æƒŠè®¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "If there is variation across the number of values in the domain of the descriptive features in a dataset, however, information gain ratio may be a better option.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæ•°æ®é›†ä¸­æè¿°æ€§ç‰¹å¾åŸŸä¸­çš„å€¼æ•°é‡å­˜åœ¨å·®å¼‚ï¼Œåˆ™ä¿¡æ¯å¢ç›Šæ¯”å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "PREV. TACHY.: Has the patient suffered from tachycardia before?",
            "zh": "ä¸Šä¸€é¡µ å¿ƒåŠ¨è¿‡é€Ÿï¼šæ‚£è€…ä»¥å‰æœ‰å¿ƒåŠ¨è¿‡é€Ÿå—ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "This is done by stacking the feature maps together.",
            "zh": "è¿™æ˜¯é€šè¿‡å°†ç‰¹å¾å›¾å †å åœ¨ä¸€èµ·æ¥å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "An information gain score this low suggests that although splitting on this feature provides some information, it is not particularly useful.",
            "zh": "ä¿¡æ¯å¢ç›Šå¾—åˆ†å¦‚æ­¤ä¹‹ä½è¡¨æ˜ï¼Œå°½ç®¡æ‹†åˆ†æ­¤åŠŸèƒ½æä¾›äº†ä¸€äº›ä¿¡æ¯ï¼Œä½†å®ƒå¹¶ä¸æ˜¯ç‰¹åˆ«æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4â€…â€…â€…The density calculation for the TRAINING EXPENSES feature from Table A.1[750] using (a) ten 200-unit intervals and (b) four 500-unit intervals.",
            "zh": "A.4 ä½¿ç”¨ï¼ˆaï¼‰10ä¸ª200å•ä½çš„é—´éš”å’Œï¼ˆbï¼‰4ä¸ª500å•ä½çš„é—´éš”è®¡ç®—è¡¨A.1[750]ä¸­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„å¯†åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Next, on Line 10[420], the activation function Ï† is applied in turn to each element of Z(l) to generate the activations for each neuron in the layer for each example in the mini-batch.",
            "zh": "æ¥ä¸‹æ¥ï¼Œåœ¨ç¬¬ 10 è¡Œ[420]ä¸Šï¼Œæ¿€æ´»å‡½æ•° Ï† ä¾æ¬¡åº”ç”¨äº Zï¼ˆlï¼‰ çš„æ¯ä¸ªå…ƒç´ ï¼Œä»¥ç”Ÿæˆå°æ‰¹é‡ä¸­æ¯ä¸ªç¤ºä¾‹å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Arithmetic means are susceptible to influence of large outliers, which can inflate the apparent performance of a model.",
            "zh": "ç®—æœ¯å‡å€¼å®¹æ˜“å—åˆ°å¤§å¼‚å¸¸å€¼çš„å½±å“ï¼Œè¿™å¯èƒ½ä¼šå¤¸å¤§æ¨¡å‹çš„è¡¨è§‚æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature AGE and the target feature, PREFCHANNEL.",
            "zh": "ï¼ˆaï¼‰ ä¸‹é¢çš„å¯è§†åŒ–å›¾è¯´æ˜äº†è¿ç»­ç‰¹å¾ AGE ä¸ç›®æ ‡ç‰¹å¾ PREFCHANNEL ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, in the insurance industry, insurance policyholders are usually referred to as members rather than customers.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨ä¿é™©ä¸šï¼ŒæŠ•ä¿äººé€šå¸¸è¢«ç§°ä¸ºä¼šå‘˜è€Œä¸æ˜¯å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "12.6â€…â€…â€…Deployment",
            "zh": "12.6 éƒ¨ç½²"
        }
    },
    {
        "translation": {
            "en": "For example, an insurance company might collect data on customersâ€™ travel behaviors through their travel insurance policy and then use this data in a model that predicts personalized prices for life insurance.",
            "zh": "ä¾‹å¦‚ï¼Œä¿é™©å…¬å¸å¯èƒ½ä¼šé€šè¿‡å…¶æ—…è¡Œä¿é™©å•æ”¶é›†æœ‰å…³å®¢æˆ·æ—…è¡Œè¡Œä¸ºçš„æ•°æ®ï¼Œç„¶ååœ¨é¢„æµ‹äººå¯¿ä¿é™©ä¸ªæ€§åŒ–ä»·æ ¼çš„æ¨¡å‹ä¸­ä½¿ç”¨è¿™äº›æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "A next-best-offer model is used to determine the least expensive incentive that needs to be offered to a customer who is considering canceling a service, for example, a mobile phone contract, in order to make them reconsider and stay.",
            "zh": "æ¬¡ä¼˜æŠ¥ä»·æ¨¡å‹ç”¨äºç¡®å®šéœ€è¦å‘æ­£åœ¨è€ƒè™‘å–æ¶ˆæœåŠ¡ï¼ˆä¾‹å¦‚ç§»åŠ¨ç”µè¯åˆåŒï¼‰çš„å®¢æˆ·æä¾›çš„æœ€ä¾¿å®œçš„æ¿€åŠ±æªæ–½ï¼Œä»¥ä¾¿ä»–ä»¬é‡æ–°è€ƒè™‘å¹¶ç•™ä¸‹æ¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "experiment, 246, 757, 758",
            "zh": "å®éªŒï¼Œ 246ï¼Œ 757ï¼Œ 758"
        }
    },
    {
        "translation": {
            "en": "10.10â€…â€…â€…(a)â€“(i) A plot of the blobs, circles, and half-moons datasets and the clusterings achieved by the k-means clustering and agglomerative hierarchical clustering algorithms (where k is set to 3, 2, and 2, respectively).",
            "zh": "10.10 ï¼ˆaï¼‰â€“ï¼ˆiï¼‰ æ–‘ç‚¹ã€åœ†åœˆå’ŒåŠæœˆæ•°æ®é›†çš„å›¾ï¼Œä»¥åŠé€šè¿‡ k å‡å€¼èšç±»å’Œèšé›†åˆ†å±‚èšç±»ç®—æ³•å®ç°çš„èšç±»ï¼ˆå…¶ä¸­ k åˆ†åˆ«è®¾ç½®ä¸º 3ã€2 å’Œ 2ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The output activation for this neuron would be calculated as follows:",
            "zh": "è¯¥ç¥ç»å…ƒçš„è¾“å‡ºæ¿€æ´»å°†æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—ï¼š"
        }
    },
    {
        "translation": {
            "en": "The R2 coefficient, however, has the advantage that it allows assessment of model performance in a domain-independent way.",
            "zh": "ç„¶è€Œï¼ŒR2 ç³»æ•°çš„ä¼˜ç‚¹æ˜¯å®ƒå…è®¸ä»¥ä¸é¢†åŸŸæ— å…³çš„æ–¹å¼è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.8(b)[756] shows a box plot for the TRAINING EXPENSES feature from the dataset in Table A.1[750].",
            "zh": "å›¾A.8ï¼ˆbï¼‰[756]æ˜¾ç¤ºäº†è¡¨A.1[750]ä¸­æ•°æ®é›†ä¸­è®­ç»ƒè´¹ç”¨ç‰¹å¾çš„ç®±å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second detail that Jocelyn needed to agree on with Edwin was the target accuracy that would be required by the system she would build in order for it to be of use to scientists at SDSS.",
            "zh": "Jocelyn éœ€è¦ä¸ Edwin è¾¾æˆä¸€è‡´çš„ç¬¬äºŒä¸ªç»†èŠ‚æ˜¯å¥¹å°†è¦æ„å»ºçš„ç³»ç»Ÿæ‰€éœ€çš„ç›®æ ‡ç²¾åº¦ï¼Œä»¥ä¾¿å®ƒå¯¹ SDSS çš„ç§‘å­¦å®¶æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "For the playersâ€™ heights given in Figure A.1[746], the mean is 149.375, so the variance can be calculated as",
            "zh": "å¯¹äºå›¾A.1[746]ä¸­ç»™å‡ºçš„çƒå‘˜èº«é«˜ï¼Œå¹³å‡å€¼ä¸º149.375ï¼Œå› æ­¤æ–¹å·®å¯ä»¥è®¡ç®—ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "Iterative Dichotomizer 3, 11, 117, 133, 133, 169, 173, 176, 541, 731",
            "zh": "è¿­ä»£äºŒåˆ†æ³•å™¨ 3ã€11ã€117ã€133ã€133ã€169ã€173ã€176ã€541ã€731"
        }
    },
    {
        "translation": {
            "en": "No other data source existed from which these features could be populated, so it was decided to remove both of them from the ABT.",
            "zh": "æ²¡æœ‰å…¶ä»–æ•°æ®æºå¯ä»¥å¡«å……è¿™äº›åŠŸèƒ½ï¼Œå› æ­¤å†³å®šä» ABT ä¸­åˆ é™¤å®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second use case we described for unsupervised learning in Section 10.2[598] was representation learning.",
            "zh": "æˆ‘ä»¬åœ¨ç¬¬ 10.2 èŠ‚[598]ä¸­æè¿°çš„æ— ç›‘ç£å­¦ä¹ çš„ç¬¬äºŒä¸ªç”¨ä¾‹æ˜¯è¡¨ç¤ºå­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.11â€…â€…â€…(a) The target hypersphere after instance d21 has been stored as best, and best-distance has been updated; and (b) the extent of the search process.",
            "zh": "5.11 ï¼ˆaï¼‰ å®ä¾‹d21ä¹‹åçš„ç›®æ ‡è¶…çƒä½“å·²å­˜å‚¨ä¸ºæœ€ä½³ï¼Œæœ€ä½³è·ç¦»å·²æ›´æ–°;ä»¥åŠï¼ˆbï¼‰æ£€ç´¢è¿‡ç¨‹çš„èŒƒå›´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.7",
            "zh": "è¡¨ 4.7"
        }
    },
    {
        "translation": {
            "en": "To illustrate this approach using a simple example, Table 10.3[614] shows a data quality report for each cluster found using k-means clustering (with k = 3) on the mobile phone customer dataset (see Table 10.1[604]).",
            "zh": "ä¸ºäº†ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜è¿™ç§æ–¹æ³•ï¼Œè¡¨10.3[614]æ˜¾ç¤ºäº†åœ¨ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†ä¸Šä½¿ç”¨k-meansèšç±»ï¼ˆk = 3ï¼‰æ‰¾åˆ°çš„æ¯ä¸ªèšç±»çš„æ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆè§è¡¨10.1[604]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.1",
            "zh": "è¡¨ 13.1"
        }
    },
    {
        "translation": {
            "en": "the Î´ for neuron i connects the zi value for i to the error of the network â„°.",
            "zh": "ç¥ç»å…ƒ i çš„ Î´ å°† i çš„ zi å€¼è¿æ¥åˆ°ç½‘ç»œ E çš„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notice that the denominator in Equation (6.10)[254] is not dependent on the target feature, so it is functioning as a normalization constant.",
            "zh": "è¯·æ³¨æ„ï¼Œç­‰å¼ï¼ˆ6.10ï¼‰[254]ä¸­çš„åˆ†æ¯ä¸ä¾èµ–äºç›®æ ‡ç‰¹å¾ï¼Œå› æ­¤å®ƒå……å½“å½’ä¸€åŒ–å¸¸æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that the revenue commission would need in order to utilize the analytics-based insight that your solution would provide.",
            "zh": "ï¼ˆcï¼‰ å¯¹äºæ‚¨æå‡ºçš„æ¯ä¸ªåˆ†æè§£å†³æ–¹æ¡ˆï¼Œæ¦‚è¿°æ”¶å…¥å§”å‘˜ä¼šéœ€è¦çš„èƒ½åŠ›ï¼Œä»¥ä¾¿åˆ©ç”¨æ‚¨çš„è§£å†³æ–¹æ¡ˆå°†æä¾›çš„åŸºäºåˆ†æçš„è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Some data quality issues arise due to invalid data and will be corrected as soon as we discover them.",
            "zh": "ä¸€äº›æ•°æ®è´¨é‡é—®é¢˜æ˜¯ç”±æ— æ•ˆæ•°æ®å¼•èµ·çš„ï¼Œä¸€æ—¦æˆ‘ä»¬å‘ç°ï¼Œå°±ä¼šç«‹å³çº æ­£ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the RAIN and GROWTH feature from the grass growth dataset; and (b) the same plot with a simple linear regression model trained to capture the relationship between the grass growth and rainfall.",
            "zh": "ï¼ˆaï¼‰ è‰ç”Ÿé•¿æ•°æ®é›†ä¸­é›¨æ°´å’Œç”Ÿé•¿ç‰¹å¾çš„æ•£ç‚¹å›¾;ï¼ˆbï¼‰ä½¿ç”¨ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹è®­ç»ƒç›¸åŒçš„å›¾ï¼Œä»¥æ•æ‰è‰ç”Ÿé•¿å’Œé™é›¨ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we examine the table closely, we see a number of strange values (for example, âˆ’ 99,999) and a number of missing values.",
            "zh": "å¦‚æœæˆ‘ä»¬ä»”ç»†æ£€æŸ¥è¯¥è¡¨ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°è®¸å¤šå¥‡æ€ªçš„å€¼ï¼ˆä¾‹å¦‚ï¼Œâˆ’ 99,999ï¼‰å’Œä¸€äº›ç¼ºå¤±å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "what GRADE would the k-nearest neighbor model assign the student?",
            "zh": "k æœ€è¿‘é‚»æ¨¡å‹ä¼šç»™å­¦ç”Ÿåˆ†é…ä»€ä¹ˆæˆç»©ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "From the perspective of searching for a consistent model, the most important property of a prediction model is that it defines a mapping from every possible combination of descriptive feature values to a prediction for the target feature.",
            "zh": "ä»æœç´¢ä¸€è‡´æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œé¢„æµ‹æ¨¡å‹æœ€é‡è¦çš„å±æ€§æ˜¯å®ƒå®šä¹‰äº†ä»æè¿°æ€§ç‰¹å¾å€¼çš„æ¯ä¸ªå¯èƒ½ç»„åˆåˆ°ç›®æ ‡ç‰¹å¾é¢„æµ‹çš„æ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.13[211] shows the neighborhood that this defines around the query instance.",
            "zh": "å›¾ 5.13[211] æ˜¾ç¤ºäº†å®ƒå›´ç»•æŸ¥è¯¢å®ä¾‹å®šä¹‰çš„é‚»åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Dealer Low (DL): 2 âˆ’ 7",
            "zh": "ç»é”€å•†ä½ä»· ï¼ˆDLï¼‰ï¼š 2 âˆ’ 7"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature PREV. TACHY. and the target feature, TACHYCARDIA.",
            "zh": "ï¼ˆcï¼‰ ä¸‹é¢çš„å¯è§†åŒ–è¯´æ˜äº†åˆ†ç±»ç‰¹å¾ PREV. TACHY ä¹‹é—´çš„å…³ç³»ã€‚å’Œç›®æ ‡ç‰¹å¾ï¼Œå¿ƒåŠ¨è¿‡é€Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "In general, standard k nearest neighbor models and weighted k nearest neighbor models will produce very similar results when a feature space is well populated.",
            "zh": "é€šå¸¸ï¼Œå½“ç‰¹å¾ç©ºé—´å¡«å……è‰¯å¥½æ—¶ï¼Œæ ‡å‡† k æœ€è¿‘é‚»æ¨¡å‹å’ŒåŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹å°†äº§ç”Ÿéå¸¸ç›¸ä¼¼çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "2. When listing a joint event, we use a comma , to denote logical and.",
            "zh": "2.åœ¨åˆ—å‡ºä¸€ä¸ªè”åˆäº‹ä»¶æ—¶ï¼Œæˆ‘ä»¬ç”¨é€—å·æ¥è¡¨ç¤ºé€»è¾‘å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "The third, fourth, and fifth convolutional layers had 384, 384, and 256 filters, respectively, and none of these layers included a non-linearity or a max pooling operation.",
            "zh": "ç¬¬ä¸‰å±‚ã€ç¬¬å››å±‚å’Œç¬¬äº”å·ç§¯å±‚åˆ†åˆ«æœ‰ 384ã€384 å’Œ 256 ä¸ªæ»¤æ³¢å™¨ï¼Œè¿™äº›å±‚éƒ½ä¸åŒ…å«éçº¿æ€§æˆ–æœ€å¤§æ± åŒ–æ“ä½œã€‚"
        }
    },
    {
        "translation": {
            "en": "Data to Insights to Decisions",
            "zh": "ä»æ•°æ®åˆ°æ´å¯Ÿå†åˆ°å†³ç­–"
        }
    },
    {
        "translation": {
            "en": "(b) How many levels does each categorical, binary, or ordinal feature have?",
            "zh": "ï¼ˆä¹™ï¼‰æ¯ä¸ªåˆ†ç±»ã€äºŒå…ƒæˆ–æœ‰åºç‰¹å¾æœ‰å¤šå°‘çº§ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "16. An alternative TD(Î») uses an approach known as eligibility traces to take account of the actual rewards received from multiple actions.",
            "zh": "16. å¦ä¸€ç§TDï¼ˆÎ»ï¼‰ä½¿ç”¨ä¸€ç§ç§°ä¸ºèµ„æ ¼è·Ÿè¸ªçš„æ–¹æ³•ï¼Œä»¥è€ƒè™‘ä»å¤šä¸ªæ“ä½œä¸­è·å¾—çš„å®é™…å¥–åŠ±ã€‚"
        }
    },
    {
        "translation": {
            "en": "The previous section of the chapter (Section 3.6[87]) focused on data preparation techniques that we can use on the data in an ABT.",
            "zh": "æœ¬ç« çš„ä¸Šä¸€èŠ‚ï¼ˆç¬¬ 3.6 èŠ‚[87]ï¼‰é‡ç‚¹ä»‹ç»äº†æˆ‘ä»¬å¯ä»¥åœ¨ ABT ä¸­å¯¹æ•°æ®ä½¿ç”¨çš„æ•°æ®å‡†å¤‡æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) The following are the ground truth labels for the query instances from Part (a).",
            "zh": "ï¼ˆbï¼‰ ä»¥ä¸‹æ˜¯ ï¼ˆaï¼‰ éƒ¨åˆ†ä¸­æŸ¥è¯¢å®ä¾‹çš„åŸºæœ¬å®å†µæ ‡ç­¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "McCulloch and Pitts were trying to develop a model of the activity in the human brain based on propositional logic.",
            "zh": "McCullochå’ŒPittsè¯•å›¾å¼€å‘ä¸€ä¸ªåŸºäºå‘½é¢˜é€»è¾‘çš„äººè„‘æ´»åŠ¨æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The algorithm, however, proceeds in exactly the same way for larger datasets and usually converges after tens of iterations.",
            "zh": "ç„¶è€Œï¼Œå¯¹äºè¾ƒå¤§çš„æ•°æ®é›†ï¼Œè¯¥ç®—æ³•ä»¥å®Œå…¨ç›¸åŒçš„æ–¹å¼è¿›è¡Œï¼Œå¹¶ä¸”é€šå¸¸åœ¨æ•°åæ¬¡è¿­ä»£åæ”¶æ•›ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.2â€…â€…â€…(a) The set of cards after the wind blows over the one on the right; (b) the revised likelihoods for the position of the queen based on this new evidence; and (c) the final positions of the cards in the game.",
            "zh": "6.2 ï¼ˆaï¼‰ é£å¹è¿‡å³è¾¹çš„é‚£å¥—ç‰Œ;ï¼ˆbï¼‰ æ ¹æ®è¿™äº›æ–°è¯æ®ä¿®è®¢å¥³ç‹èŒä½çš„å¯èƒ½æ€§;åŠï¼ˆcï¼‰ç‰Œåœ¨æ¸¸æˆä¸­çš„æœ€ç»ˆä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using the training dataset from Table 1.3[9], a machine learning algorithm will reduce the full set of 6,561 possible prediction models for this scenario to only those that are consistent with the training instances.",
            "zh": "ä½¿ç”¨è¡¨ 1.3[9] ä¸­çš„è®­ç»ƒæ•°æ®é›†ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•ä¼šå°†æ­¤åœºæ™¯çš„ 6,561 ä¸ªå¯èƒ½çš„é¢„æµ‹æ¨¡å‹çš„å…¨é›†å‡å°‘åˆ°ä»…ä¸è®­ç»ƒå®ä¾‹ä¸€è‡´çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "population standard deviation, 61",
            "zh": "æ€»ä½“æ ‡å‡†å·®ï¼Œ61"
        }
    },
    {
        "translation": {
            "en": "The cross-entropy error (or loss) function is generally used in contexts in which the output of a network can be interpreted as a probability distribution over a set of exclusive categories. In the general scenario of a model predicting a distribution over a set of categories, the cross-entropy loss function is defined as",
            "zh": "äº¤å‰ç†µè¯¯å·®ï¼ˆæˆ–æŸå¤±ï¼‰å‡½æ•°é€šå¸¸ç”¨äºå°†ç½‘ç»œçš„è¾“å‡ºè§£é‡Šä¸ºä¸€ç»„æ’ä»–ç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒçš„ä¸Šä¸‹æ–‡ä¸­ã€‚åœ¨æ¨¡å‹é¢„æµ‹ä¸€ç»„ç±»åˆ«åˆ†å¸ƒçš„ä¸€èˆ¬åœºæ™¯ä¸­ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "To use basis functions, we recast the simple linear regression model (see Equation (7.9)[320]) as follows:",
            "zh": "ä¸ºäº†ä½¿ç”¨åŸºå‡½æ•°ï¼Œæˆ‘ä»¬é‡æ–°è½¬æ¢äº†ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ï¼ˆå‚è§å…¬å¼ï¼ˆ7.9ï¼‰[320]ï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "For example, we could experiment with using a 2-by-2-by-3 filter (height by width by depth).",
            "zh": "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨ 2Ã—2Ã—3 æ»¤é•œï¼ˆé«˜å®½é™¤æ·±ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The frequency count of each level2 of a categorical feature is calculated by counting the number of times that level appears in the sample.",
            "zh": "åˆ†ç±»ç‰¹å¾çš„æ¯ä¸ªçº§åˆ«2çš„é¢‘ç‡è®¡æ•°æ˜¯é€šè¿‡è®¡ç®—è¯¥çº§åˆ«åœ¨æ ·æœ¬ä¸­å‡ºç°çš„æ¬¡æ•°æ¥è®¡ç®—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450], using ReLUs, during the first training iteration when the weights were initialized using He initialization.",
            "zh": "å›¾ 8.22[450] ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œä½¿ç”¨ ReLU åœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“æƒé‡ä½¿ç”¨ He åˆå§‹åŒ–è¿›è¡Œåˆå§‹åŒ–æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Typically k takes small values such as 1, 2, or 3.",
            "zh": "é€šå¸¸ï¼Œk å–å°å€¼ï¼Œä¾‹å¦‚ 1ã€2 æˆ– 3ã€‚"
        }
    },
    {
        "translation": {
            "en": "standard error, 333",
            "zh": "æ ‡å‡†è¯¯å·®ï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "The requirements for this model were that it be accurate, that it be capable of being integrated into the wider AT processes, and, possibly, that it act as a source of insight into the reasons people might churn.",
            "zh": "è¯¥æ¨¡å‹çš„è¦æ±‚æ˜¯å‡†ç¡®ï¼Œèƒ½å¤Ÿé›†æˆåˆ°æ›´å¹¿æ³›çš„ AT æµç¨‹ä¸­ï¼Œå¹¶ä¸”å¯èƒ½ä½œä¸ºæ´å¯Ÿäººä»¬å¯èƒ½æµå¤±çš„åŸå› çš„æ¥æºã€‚"
        }
    },
    {
        "translation": {
            "en": "Although the data quality report is just a collection of simple descriptive statistics and visualizations of the features in an analytics base table, it is a very powerful tool and the key to achieving the outcomes listed above.",
            "zh": "å°½ç®¡æ•°æ®è´¨é‡æŠ¥å‘Šåªæ˜¯åˆ†æåŸºè¡¨ä¸­ç‰¹å¾çš„ç®€å•æè¿°æ€§ç»Ÿè®¡å’Œå¯è§†åŒ–çš„é›†åˆï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„å·¥å…·ï¼Œä¹Ÿæ˜¯å®ç°ä¸Šè¿°ç»“æœçš„å…³é”®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cross Industry Standard Process for Data Mining, 16, 22, 28, 46, 53, 94, 534, 600, 730",
            "zh": "æ•°æ®æŒ–æ˜çš„è·¨è¡Œä¸šæ ‡å‡†æµç¨‹ï¼Œ16ã€22ã€28ã€46ã€53ã€94ã€534ã€600ã€730"
        }
    },
    {
        "translation": {
            "en": "Often it will take multiple features to express a domain concept.",
            "zh": "é€šå¸¸ï¼Œéœ€è¦å¤šä¸ªç‰¹å¾æ¥è¡¨è¾¾ä¸€ä¸ªé¢†åŸŸæ¦‚å¿µã€‚"
        }
    },
    {
        "translation": {
            "en": "Now consider what happens to the weights on connections from the input layer to the first hidden layer if there are large differences in the values taken by different descriptive features.",
            "zh": "ç°åœ¨è€ƒè™‘ä»è¾“å…¥å±‚åˆ°ç¬¬ä¸€ä¸ªéšè—å±‚çš„è¿æ¥ä¸Šçš„æƒé‡ä¼šå‘ç”Ÿä»€ä¹ˆæƒ…å†µï¼Œå¦‚æœä¸åŒæè¿°æ€§ç‰¹å¾æ‰€é‡‡ç”¨çš„å€¼å­˜åœ¨è¾ƒå¤§å·®å¼‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "A dataset listing the number of bike rentals per day.",
            "zh": "åˆ—å‡ºæ¯å¤©è‡ªè¡Œè½¦ç§Ÿèµæ¬¡æ•°çš„æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A selection of the simple linear regression models developed during the gradient descent process for the office rentals dataset. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "åœ¨åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹çš„ç²¾é€‰ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Before the churn model was put in place, every week the company would randomly select 1,000 customers from their customer base and have their customer contact center call these customers to discuss how satisfied they were with the networkâ€™s performance and offer assistance with any issues.",
            "zh": "åœ¨å®¢æˆ·æµå¤±æ¨¡å‹å®æ–½ä¹‹å‰ï¼Œè¯¥å…¬å¸æ¯å‘¨éƒ½ä¼šä»å…¶å®¢æˆ·ç¾¤ä¸­éšæœºé€‰æ‹© 1,000 åå®¢æˆ·ï¼Œå¹¶è®©å…¶å®¢æˆ·è”ç»œä¸­å¿ƒè‡´ç”µè¿™äº›å®¢æˆ·ï¼Œè®¨è®ºä»–ä»¬å¯¹ç½‘ç»œæ€§èƒ½çš„æ»¡æ„åº¦ï¼Œå¹¶å°±ä»»ä½•é—®é¢˜æä¾›å¸®åŠ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bray, Freddie, Jacques Ferlay, Isabelle Soerjomataram, Rebecca L. Siegel, Lindsey A. Torre, and Ahmedin Jemal. 2018. Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. CA: A Cancer Journal for Clinicians 68 (6): 394â€“424. doi:10.3322/caac.21492.",
            "zh": "Brayã€Freddieã€Jacques Ferlayã€Isabelle Soerjomataramã€Rebecca L. Siegelã€Lindsey A. Torre å’Œ Ahmedin Jemalã€‚2018. 2018 å¹´å…¨çƒç™Œç—‡ç»Ÿè®¡ï¼šGlobocan ä¼°è®¡å…¨çƒ 185 ä¸ªå›½å®¶/åœ°åŒº 36 ç§ç™Œç—‡çš„å‘ç—…ç‡å’Œæ­»äº¡ç‡ã€‚CAï¼šä¸´åºŠåŒ»ç”Ÿç™Œç—‡æ‚å¿— 68 ï¼ˆ6ï¼‰ï¼š394â€“424ã€‚doiï¼š10.3322/caac.21492."
        }
    },
    {
        "translation": {
            "en": "The main advantages of SVM models are that they are robust to overfitting and perform well for very high-dimensional problems.",
            "zh": "SVM æ¨¡å‹çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å®ƒä»¬å¯¹è¿‡æ‹Ÿåˆå…·æœ‰é²æ£’æ€§ï¼Œå¹¶ä¸”åœ¨å¤„ç†éå¸¸é«˜ç»´çš„é—®é¢˜æ—¶è¡¨ç°è‰¯å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "positive level, 537, 538",
            "zh": "æ­£ç”µå¹³ï¼Œ537,538"
        }
    },
    {
        "translation": {
            "en": "For example, at the bottom of the hierarchy the vertical gaps between clusterings are very small because the clusters are very close, and as we move farther up the hierarchy, the gaps get larger as clusters that are farther apart are merged.",
            "zh": "ä¾‹å¦‚ï¼Œåœ¨å±‚æ¬¡ç»“æ„çš„åº•éƒ¨ï¼Œèšç±»ä¹‹é—´çš„å‚ç›´é—´éš™éå¸¸å°ï¼Œå› ä¸ºèšç±»éå¸¸æ¥è¿‘ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬åœ¨å±‚æ¬¡ç»“æ„ä¸­å‘ä¸Šç§»åŠ¨ï¼Œéšç€ç›¸è·è¾ƒè¿œçš„èšç±»åˆå¹¶ï¼Œé—´éš™ä¼šå˜å¾—æ›´å¤§ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. This also means that we no longer use the dummy descriptive feature, d[0], which we previously always set to 1; see Equation (7.9)[320].",
            "zh": "21. è¿™ä¹Ÿæ„å‘³ç€æˆ‘ä»¬ä¸å†ä½¿ç”¨è™šæ‹Ÿæè¿°æ€§ç‰¹å¾ d[0]ï¼Œæˆ‘ä»¬ä»¥å‰æ€»æ˜¯å°†å…¶è®¾ç½®ä¸º 1;è§ç­‰å¼ï¼ˆ7.9ï¼‰[320]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Conor could take the approach of always pointing to sicÃ­n on the menu, as he knows what this is and he likes chicken.",
            "zh": "åº·çº³å¯ä»¥é‡‡å–æ€»æ˜¯åœ¨èœå•ä¸ŠæŒ‡ç€ sicÃ­n çš„æ–¹æ³•ï¼Œå› ä¸ºä»–çŸ¥é“è¿™æ˜¯ä»€ä¹ˆï¼Œè€Œä¸”ä»–å–œæ¬¢é¸¡è‚‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for the following query instances:",
            "zh": "ä½¿ç”¨æ­¤æ¨¡å‹å¯¹ä»¥ä¸‹æŸ¥è¯¢å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "In this discussion on local receptive fields, the filters we have presented are hand designed for the purpose of illustration.",
            "zh": "åœ¨å…³äºå±€éƒ¨æ„Ÿå—é‡çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬ä»‹ç»çš„æ»¤æ³¢å™¨æ˜¯æ‰‹å·¥è®¾è®¡çš„ï¼Œç”¨äºè¯´æ˜ç›®çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.94)[490] illustrates the result of applying max pooling to the feature map from Equation (8.93)[489] using non-overlapping local receptive fields with a dimensionality of 2-by-2.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.94ï¼‰[490]è¯´æ˜äº†ä½¿ç”¨ç»´æ•°ä¸º2Ã—2çš„éé‡å å±€éƒ¨æ„Ÿå—é‡å¯¹ç­‰å¼ï¼ˆ8.93ï¼‰[489]ä¸­çš„ç‰¹å¾å›¾åº”ç”¨æœ€å¤§æ± åŒ–çš„ç»“æœã€‚"
        }
    },
    {
        "translation": {
            "en": "directed acyclic graph, 499",
            "zh": "æœ‰å‘æ— ç¯å›¾ï¼Œ499"
        }
    },
    {
        "translation": {
            "en": "These businesses often try to predict the likelihood that users coming to the end of the trial period will accept the upsell offer to move to the paid service.",
            "zh": "è¿™äº›ä¼ä¸šç»å¸¸è¯•å›¾é¢„æµ‹è¯•ç”¨æœŸç»“æŸæ—¶çš„ç”¨æˆ·æ¥å—è¿½åŠ é”€å”®ä¼˜æƒ ä»¥è½¬å‘ä»˜è´¹æœåŠ¡çš„å¯èƒ½æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "4. A common modification to k-means clustering in which actual instances are chosen as initial centroids, rather than random points in the feature space, easily stops this from happening.",
            "zh": "4. å¯¹ k å‡å€¼èšç±»çš„å¸¸è§ä¿®æ”¹ï¼Œå³é€‰æ‹©å®é™…å®ä¾‹ä½œä¸ºåˆå§‹è´¨å¿ƒï¼Œè€Œä¸æ˜¯ç‰¹å¾ç©ºé—´ä¸­çš„éšæœºç‚¹ï¼Œå¾ˆå®¹æ˜“é˜»æ­¢è¿™ç§æƒ…å†µçš„å‘ç”Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "An illustration of the forward propagation of d2 through the ReLU network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "d2 é€šè¿‡ ReLU ç½‘ç»œå‘å‰ä¼ æ’­çš„å›¾ç¤ºï¼Œæ˜¾ç¤ºäº†æ¯ä¸ªè¿æ¥ä¸Šçš„æƒé‡ï¼Œä»¥åŠç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒæ€»å’Œ z å’Œæ¿€æ´»å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure A.1[746] shows a group of players on a school basketball team and their heights. Using Equation (A.1)[745] we can calculate the arithmetic mean of these playersâ€™ heights as",
            "zh": "å›¾A.1[746]æ˜¾ç¤ºäº†å­¦æ ¡ç¯®çƒé˜Ÿçš„ä¸€ç»„çƒå‘˜å’Œä»–ä»¬çš„èº«é«˜ã€‚ä½¿ç”¨å…¬å¼ï¼ˆA.1ï¼‰[745]ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºè¿™äº›çƒå‘˜èº«é«˜çš„ç®—æœ¯å¹³å‡å€¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "48,000",
            "zh": "48,000"
        }
    },
    {
        "translation": {
            "en": "As such, they generally work well in domains in which there are large numbers of input features (such as image, speech, or language processing), and for which there are very large datasets available for training.",
            "zh": "å› æ­¤ï¼Œå®ƒä»¬é€šå¸¸é€‚ç”¨äºå…·æœ‰å¤§é‡è¾“å…¥ç‰¹å¾ï¼ˆä¾‹å¦‚å›¾åƒã€è¯­éŸ³æˆ–è¯­è¨€å¤„ç†ï¼‰çš„é¢†åŸŸï¼Œå¹¶ä¸”æœ‰éå¸¸å¤§çš„æ•°æ®é›†å¯ç”¨äºè®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Introduction to Probability for Machine Learning",
            "zh": "æœºå™¨å­¦ä¹ æ¦‚ç‡ç®€ä»‹"
        }
    },
    {
        "translation": {
            "en": "(c) Show that the single-layer network using the weight matrix you calculated in Part 2 generates the same output as the network for the input vector: Neuron 1 = 0.9, Neuron 2 = 0.5.",
            "zh": "ï¼ˆcï¼‰ æ˜¾ç¤ºä½¿ç”¨æ‚¨åœ¨ç¬¬ 2 éƒ¨åˆ†ä¸­è®¡ç®—çš„æƒé‡çŸ©é˜µçš„å•å±‚ç½‘ç»œç”Ÿæˆçš„è¾“å‡ºä¸è¾“å…¥å‘é‡çš„ç½‘ç»œç›¸åŒï¼šç¥ç»å…ƒ 1 = 0.9ï¼Œç¥ç»å…ƒ 2 = 0.5ã€‚"
        }
    },
    {
        "translation": {
            "en": "PSFFLUXIVAR_U/G/R/I/Z",
            "zh": "PSFFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The idea behind this was that stunting the tree made it more interpretable.",
            "zh": "è¿™èƒŒåçš„æƒ³æ³•æ˜¯ï¼Œä½¿æ ‘å‘è‚²è¿Ÿç¼“ä½¿å…¶æ›´å…·å¯è§£é‡Šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this instance the weights in the network were sampled from a normal distribution with Î¼ = 0.0 and Ïƒ = 0.2, which means that for all k: var(W(k)) = Ïƒ2 = 0.22 = 0.04.",
            "zh": "åœ¨æœ¬ä¾‹ä¸­ï¼Œç½‘ç»œä¸­çš„æƒé‡æ˜¯ä» Î¼ = 0.0 å’Œ Ïƒ = 0.2 çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œè¿™æ„å‘³ç€å¯¹äºæ‰€æœ‰ kï¼švarï¼ˆWï¼ˆkï¼‰ï¼‰ = Ïƒ2 = 0.22 = 0.04ã€‚"
        }
    },
    {
        "translation": {
            "en": "We use a specific typography when referring to a feature by name in the text (e.g., POSITION, CREDITRATING, and CLAIM AMOUNT).",
            "zh": "åœ¨æ–‡æœ¬ä¸­æŒ‰åç§°æåŠåŠŸèƒ½æ—¶ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ç‰¹å®šçš„æ’ç‰ˆï¼ˆä¾‹å¦‚ï¼ŒPOSITIONã€CREDITRATING å’Œ CLAIM AMOUNTï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If this condition does not hold, then the product of the two matrices is not defined.",
            "zh": "å¦‚æœæ­¤æ¡ä»¶ä¸æˆç«‹ï¼Œåˆ™ä¸ä¼šå®šä¹‰ä¸¤ä¸ªçŸ©é˜µçš„ä¹˜ç§¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hirschowitz, Anton. 2001. Closing the CRM loop: The 21st century marketerâ€™s challenge: Transforming customer insight into customer value. Journal of Targeting, Measurement and Analysis for Marketing 10 (2): 168â€“178.",
            "zh": "èµ«è‚–ç»´èŒ¨ï¼Œå®‰ä¸œã€‚2001. å…³é—­ CRM å¾ªç¯ï¼š21 ä¸–çºªè¥é”€äººå‘˜çš„æŒ‘æˆ˜ï¼šå°†å®¢æˆ·æ´å¯Ÿè½¬åŒ–ä¸ºå®¢æˆ·ä»·å€¼ã€‚è¥é”€ç›®æ ‡ï¼Œæµ‹é‡å’Œåˆ†ææ‚å¿—10ï¼ˆ2ï¼‰ï¼š168-178ã€‚"
        }
    },
    {
        "translation": {
            "en": "Visualizations of the continuous and categorical features in the motor insurance claims fraud detection ABT in Table 3.2[56].",
            "zh": "è¡¨3.2[56]ä¸­æ±½è½¦ä¿é™©ç†èµ”æ¬ºè¯ˆæ£€æµ‹ABTä¸­è¿ç»­å’Œåˆ†ç±»ç‰¹å¾çš„å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) Some of the errorDelta values are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "ï¼ˆcï¼‰ ä¸Šè¡¨ä¸­ç¼ºå°‘ä¸€äº› errorDelta å€¼ï¼ˆæ ‡æœ‰ ï¼Ÿï¼‰ã€‚è®¡ç®—è¿™äº›ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.11",
            "zh": "è¡¨ 9.11"
        }
    },
    {
        "translation": {
            "en": "10.4.6â€ƒRepresentation Learning with Auto-Encoders",
            "zh": "10.4.6 ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨è¿›è¡Œè¡¨ç¤ºå­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "Both of these things would be of great use to real estate agents trying to make decisions about the rental prices they should set for new rental properties.",
            "zh": "è¿™ä¸¤ä»¶äº‹å¯¹äºè¯•å›¾å†³å®šä»–ä»¬åº”è¯¥ä¸ºæ–°å‡ºç§Ÿç‰©ä¸šè®¾å®šçš„ç§Ÿé‡‘ä»·æ ¼çš„æˆ¿åœ°äº§ç»çºªäººæ¥è¯´éƒ½éå¸¸æœ‰ç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "27. See Section 7.3[319].",
            "zh": "27. å‚è§ç¬¬ 7.3 èŠ‚[319]ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 5.12",
            "zh": "è¡¨ 5.12"
        }
    },
    {
        "translation": {
            "en": "3. The following table shows the action-value table for a reinforcement learning agent learning to play the TwentyTwos game after 20 episodes of training have elapsed.",
            "zh": "3. ä¸‹è¡¨æ˜¾ç¤ºäº†å¼ºåŒ–å­¦ä¹ ä»£ç†åœ¨ç»è¿‡ 20 é›†è®­ç»ƒåå­¦ä¹ ç© TwentyTwos æ¸¸æˆçš„åŠ¨ä½œå€¼è¡¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity is also an appropriate similarity index for sparse data with non-binary features (i.e., datasets with lots of zero values) because the dot product will essentially ignore co-absences in its computation (0 Ã— 0 = 0).",
            "zh": "ä½™å¼¦ç›¸ä¼¼åº¦ä¹Ÿæ˜¯å…·æœ‰éäºŒå…ƒç‰¹å¾çš„ç¨€ç–æ•°æ®ï¼ˆå³å…·æœ‰å¤§é‡é›¶å€¼çš„æ•°æ®é›†ï¼‰çš„åˆé€‚ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œå› ä¸ºç‚¹ç§¯åœ¨å…¶è®¡ç®—ä¸­åŸºæœ¬ä¸Šä¼šå¿½ç•¥å…±ç¼º ï¼ˆ0 Ã— 0 = 0ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Deep Learning",
            "zh": "æ·±åº¦å­¦ä¹ çš„ç¬¦å·çº¦å®š"
        }
    },
    {
        "translation": {
            "en": "Indeed, the activations of the neurons in a set provide a map of where in the input the relevant visual feature occurred, and for this reason the set of activations for a set of neurons that share a filter is called a feature map.",
            "zh": "äº‹å®ä¸Šï¼Œä¸€ç»„ç¥ç»å…ƒçš„æ¿€æ´»æä¾›äº†ç›¸å…³è§†è§‰ç‰¹å¾åœ¨è¾“å…¥ä¸­å‘ç”Ÿçš„ä½ç½®çš„æ˜ å°„ï¼Œå› æ­¤ï¼Œå…±äº«è¿‡æ»¤å™¨çš„ä¸€ç»„ç¥ç»å…ƒçš„æ¿€æ´»é›†ç§°ä¸ºç‰¹å¾æ˜ å°„ã€‚"
        }
    },
    {
        "translation": {
            "en": "episode, 639",
            "zh": "ç¬¬639é›†"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE are the only features with an obvious problem with missing values.",
            "zh": "SOFT TISSUE æ˜¯å”¯ä¸€å…·æœ‰æ˜æ˜¾ç¼ºå¤±å€¼é—®é¢˜çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process repeats until convergence occursâ€”where convergence is defined as having occurred when no cluster memberships change on an iteration of the algorithm and therefore the cluster centroids are stable. Once the algorithm has completed, its two outputs are a vector of assignments of each instance in the dataset to one of the clusters, ğ’1 to ğ’k, and the k cluster centroids, c1 to ck. This first output can be used to enrich the original dataset with a new generated feature, the cluster memberships.",
            "zh": "æ­¤è¿‡ç¨‹ä¼šé‡å¤ï¼Œç›´åˆ°æ”¶æ•›å‘ç”Ÿï¼Œå…¶ä¸­æ”¶æ•›å®šä¹‰ä¸ºåœ¨ç®—æ³•è¿­ä»£ä¸­æ²¡æœ‰èšç±»æˆå‘˜èº«ä»½æ›´æ”¹æ—¶å‘ç”Ÿï¼Œå› æ­¤èšç±»è´¨å¿ƒæ˜¯ç¨³å®šçš„ã€‚ç®—æ³•å®Œæˆåï¼Œå…¶ä¸¤ä¸ªè¾“å‡ºæ˜¯æ•°æ®é›†ä¸­æ¯ä¸ªå®ä¾‹åˆ†é…ç»™å…¶ä¸­ä¸€ä¸ªèšç±»ï¼ˆC1 åˆ° Ckï¼‰å’Œ k ä¸ªèšç±»è´¨å¿ƒï¼ˆc1 åˆ° ckï¼‰çš„å‘é‡ã€‚ç¬¬ä¸€ä¸ªè¾“å‡ºå¯ç”¨äºä½¿ç”¨æ–°ç”Ÿæˆçš„ç‰¹å¾ï¼ˆé›†ç¾¤æˆå‘˜èº«ä»½ï¼‰æ¥ä¸°å¯ŒåŸå§‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming that the model uses Euclidean distance to find the nearest neighbor, what prediction will the model return for each of the following query instances?",
            "zh": "å‡è®¾æ¨¡å‹ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»æ¥æŸ¥æ‰¾æœ€è¿‘é‚»ï¼Œåˆ™æ¨¡å‹å°†ä¸ºä»¥ä¸‹æ¯ä¸ªæŸ¥è¯¢å®ä¾‹è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Using a max function requires that the backward pass in the backpropagation algorithm be updated slightly.",
            "zh": "ä½¿ç”¨ max å‡½æ•°éœ€è¦ç¨å¾®æ›´æ–°åå‘ä¼ æ’­ç®—æ³•ä¸­çš„å‘åä¼ é€’ã€‚"
        }
    },
    {
        "translation": {
            "en": "This extreme partitioning of the dataset into sets of single instances can happen if there are a lot of descriptive features in the dataset or if there are one or more continuous descriptive features that the algorithm is allowed to split on repeatedly.",
            "zh": "å¦‚æœæ•°æ®é›†ä¸­æœ‰å¾ˆå¤šæè¿°æ€§ç‰¹å¾ï¼Œæˆ–è€…å…è®¸ç®—æ³•é‡å¤æ‹†åˆ†ä¸€ä¸ªæˆ–å¤šä¸ªè¿ç»­çš„æè¿°æ€§ç‰¹å¾ï¼Œåˆ™å¯èƒ½ä¼šå°†æ•°æ®é›†åˆ’åˆ†ä¸ºå•ä¸ªå®ä¾‹é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) The LDL cholesterol values for a large group of patients, including smokers and non-smokers.",
            "zh": "ï¼ˆcï¼‰ ä¸€å¤§ç¾¤æ‚£è€…ï¼ˆåŒ…æ‹¬å¸çƒŸè€…å’Œéå¸çƒŸè€…ï¼‰çš„ä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "training set, 6, 541, 719",
            "zh": "è®­ç»ƒé›†ï¼Œ 6ï¼Œ 541ï¼Œ 719"
        }
    },
    {
        "translation": {
            "en": "7.22â€…â€…â€…A small sample of the generators dataset with two features, RPM and VIBRATION, and two target levels, good (shown as crosses) and faulty (shown as triangles): (a) a decision boundary with a very small margin; and (b) a decision boundary with a much larger margin. In both cases, the instances along the margins are highlighted.",
            "zh": "7.22 ç”Ÿæˆå™¨æ•°æ®é›†çš„ä¸€ä¸ªå°æ ·æœ¬ï¼Œå…·æœ‰ä¸¤ä¸ªç‰¹å¾ï¼Œå³RPMå’ŒVIBRATIONï¼Œä»¥åŠä¸¤ä¸ªç›®æ ‡æ°´å¹³ï¼Œå³è‰¯å¥½ï¼ˆæ˜¾ç¤ºä¸ºåå­—ï¼‰å’Œé”™è¯¯ï¼ˆæ˜¾ç¤ºä¸ºä¸‰è§’å½¢ï¼‰ï¼šï¼ˆaï¼‰ä½™é‡éå¸¸å°çš„å†³ç­–è¾¹ç•Œ;ï¼ˆbï¼‰å…·æœ‰æ›´å¤§ä½™åœ°çš„å†³ç­–è¾¹ç•Œã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œè¾¹è·ä¸Šçš„å®ä¾‹éƒ½ä¼šçªå‡ºæ˜¾ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "The boundary between d1 and d5 is",
            "zh": "d1 å’Œ d5 ä¹‹é—´çš„è¾¹ç•Œæ˜¯"
        }
    },
    {
        "translation": {
            "en": "Next, in Line 7[476] each element in new activation vector a(l)â€² is divided by the parameter Ï.",
            "zh": "æ¥ä¸‹æ¥ï¼Œåœ¨ç¬¬ 7 è¡Œ[476] ä¸­ï¼Œæ–°æ¿€æ´»å‘é‡ aï¼ˆlï¼‰â€² ä¸­çš„æ¯ä¸ªå…ƒç´ é™¤ä»¥å‚æ•° Ïã€‚"
        }
    },
    {
        "translation": {
            "en": "The overall profit for the k-NN model is $560, while it is $1,540 for the decision tree model.",
            "zh": "k-NN æ¨¡å‹çš„æ€»åˆ©æ¶¦ä¸º 560 ç¾å…ƒï¼Œè€Œå†³ç­–æ ‘æ¨¡å‹çš„æ€»åˆ©æ¶¦ä¸º 1,540 ç¾å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "22. In the context of decision tree pruning, the validation set is often referred to as the pruning dataset.",
            "zh": "22. åœ¨å†³ç­–æ ‘ä¿®å‰ªçš„èƒŒæ™¯ä¸‹ï¼ŒéªŒè¯é›†é€šå¸¸è¢«ç§°ä¸ºä¿®å‰ªæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "F1 measure, 548, 549, 549â€“551, 611",
            "zh": "F1 æµ‹é‡ï¼Œ548ã€549ã€549â€“551ã€611"
        }
    },
    {
        "translation": {
            "en": "6.3.1â€ƒA Worked Example",
            "zh": "6.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "sigmoid, 625, 626",
            "zh": "ä¹™çŠ¶ç»“è‚ ï¼Œ625,626"
        }
    },
    {
        "translation": {
            "en": "In particular, the hyperplane at a node defines the boundary between the instances stored on each of the subtrees below the node.",
            "zh": "å…·ä½“è€Œè¨€ï¼ŒèŠ‚ç‚¹ä¸Šçš„è¶…å¹³é¢å®šä¹‰äº†å­˜å‚¨åœ¨èŠ‚ç‚¹ä¸‹æ¯ä¸ªå­æ ‘ä¸Šçš„å®ä¾‹ä¹‹é—´çš„è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Because the adjustments are made in the direction of the error surface gradient, this new point will be closer to the overall global minimum.",
            "zh": "ç”±äºè°ƒæ•´æ˜¯åœ¨è¯¯å·®æ›²é¢æ¢¯åº¦æ–¹å‘ä¸Šè¿›è¡Œçš„ï¼Œå› æ­¤æ­¤æ–°ç‚¹å°†æ›´æ¥è¿‘æ•´ä½“å…¨å±€æœ€å°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "What is the prediction subject? What are the domain concepts? What is the target feature? What descriptive features will be used?",
            "zh": "é¢„æµ‹ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿé¢†åŸŸæ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿç›®æ ‡åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå°†ä½¿ç”¨å“ªäº›æè¿°æ€§ç‰¹å¾ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "5.3â€…â€…â€…A feature space plot of the data in Table 5.2[183], with the position in the feature space of the query represented by the ? marker.",
            "zh": "5.3 è¡¨5.2[183]ä¸­æ•°æ®çš„ç‰¹å¾ç©ºé—´å›¾ï¼ŒæŸ¥è¯¢åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„ä½ç½®ç”¨ ï¼Ÿæ ‡è®°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Allowing the network to learn the filter weights means that the network is able to learn which visual patterns are useful to extract from the visual input in order to be successful at the prediction task on which it is being trained.",
            "zh": "å…è®¸ç½‘ç»œå­¦ä¹ æ»¤æ³¢å™¨æƒé‡æ„å‘³ç€ç½‘ç»œèƒ½å¤Ÿäº†è§£å“ªäº›è§†è§‰æ¨¡å¼å¯ç”¨äºä»è§†è§‰è¾“å…¥ä¸­æå–ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå®ƒçš„é¢„æµ‹ä»»åŠ¡ä¸­å–å¾—æˆåŠŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.6[140] details the calculation of the information gain for each descriptive feature in ğ’Ÿ8 using this result. It is clear from the information in Table 4.6[140] that in the context of ğ’Ÿ 8, SLOPE has a higher information gain than STREAM.",
            "zh": "è¡¨4.6[140]è¯¦ç»†è¯´æ˜äº†ä½¿ç”¨è¯¥ç»“æœè®¡ç®—D8ä¸­æ¯ä¸ªæè¿°æ€§ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šã€‚ä»è¡¨4.6[140]ä¸­çš„ä¿¡æ¯å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œåœ¨D 8çš„ä¸Šä¸‹æ–‡ä¸­ï¼ŒSLOPEçš„ä¿¡æ¯å¢ç›Šé«˜äºSTREAMã€‚"
        }
    },
    {
        "translation": {
            "en": "It is worth emphasizing that the scores calculated are not the actual posterior probabilities for each target level given the query evidence (to get the actual probabilities we would need to normalize these scores), but they do give us enough information to rank the different target levels based on the relative posterior probabilities.",
            "zh": "å€¼å¾—å¼ºè°ƒçš„æ˜¯ï¼Œè®¡ç®—å‡ºçš„åˆ†æ•°å¹¶ä¸æ˜¯ç»™å®šæŸ¥è¯¢è¯æ®çš„æ¯ä¸ªç›®æ ‡æ°´å¹³çš„å®é™…åéªŒæ¦‚ç‡ï¼ˆä¸ºäº†è·å¾—å®é™…æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™äº›åˆ†æ•°è¿›è¡Œå½’ä¸€åŒ–ï¼‰ï¼Œä½†å®ƒä»¬ç¡®å®ä¸ºæˆ‘ä»¬æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œå¯ä»¥æ ¹æ®ç›¸å¯¹åéªŒæ¦‚ç‡å¯¹ä¸åŒçš„ç›®æ ‡æ°´å¹³è¿›è¡Œæ’åã€‚"
        }
    },
    {
        "translation": {
            "en": "For instances along the margin extents, abs(w0 + w Â·d) = 1 (according to Equation (7.44)[364]). So, the distance from any instance along the margin extents to the decision boundary is , and because the margin is symmetrical to either side of the decision boundary, the size of the margin is . The goal when training a support vector machine is to maximize subject to the constraint expressed in Equation (7.44)[364].",
            "zh": "å¯¹äºæ²¿è¾¹è·èŒƒå›´çš„å®ä¾‹ï¼Œabsï¼ˆw0 + w Â·dï¼‰ = 1ï¼ˆæ ¹æ®å…¬å¼ ï¼ˆ7.44ï¼‰[364]ï¼‰ã€‚å› æ­¤ï¼Œæ²¿è¾¹è·èŒƒå›´çš„ä»»ä½•å®ä¾‹åˆ°å†³ç­–è¾¹ç•Œçš„è·ç¦»ä¸º ï¼Œå¹¶ä¸”ç”±äºè¾¹è·ä¸å†³ç­–è¾¹ç•Œçš„ä»»ä¸€ä¾§å¯¹ç§°ï¼Œå› æ­¤è¾¹è·çš„å¤§å°ä¸º ã€‚è®­ç»ƒæ”¯æŒå‘é‡æœºæ—¶çš„ç›®æ ‡æ˜¯åœ¨æ–¹ç¨‹ï¼ˆ7.44ï¼‰[364]ä¸­è¡¨ç¤ºçš„çº¦æŸä¸‹å®ç°æœ€å¤§åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "The final decision tree induced from the dataset in Table 4.11[152]. To illustrate how the tree generates predictions, this tree lists the instances that ended up at each leaf node and the prediction (PRED.) made by each leaf node.",
            "zh": "ä»è¡¨4.11[152]ä¸­çš„æ•°æ®é›†ä¸­å¾—å‡ºçš„æœ€ç»ˆå†³ç­–æ ‘ã€‚ä¸ºäº†è¯´æ˜æ ‘å¦‚ä½•ç”Ÿæˆé¢„æµ‹ï¼Œæ­¤æ ‘åˆ—å‡ºäº†æœ€ç»ˆå‡ºç°åœ¨æ¯ä¸ªå¶èŠ‚ç‚¹ä¸Šçš„å®ä¾‹ä»¥åŠæ¯ä¸ªå¶èŠ‚ç‚¹æ‰€åšçš„é¢„æµ‹ ï¼ˆPRED.ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "jackknifing, 545",
            "zh": "åƒæ–¤é¡¶ï¼Œ545"
        }
    },
    {
        "translation": {
            "en": "This means that the error for the output at time t is also dependent on the states of the network for all the previous inputs in the sequence (tâˆ’1, tâˆ’2, and so on) back to the start of the sequence.",
            "zh": "è¿™æ„å‘³ç€ï¼Œæ—¶é—´ t å¤„çš„è¾“å‡ºè¯¯å·®è¿˜å–å†³äºåºåˆ—ä¸­æ‰€æœ‰å…ˆå‰è¾“å…¥ï¼ˆtâˆ’1ã€tâˆ’2 ç­‰ï¼‰å›åˆ°åºåˆ—èµ·ç‚¹çš„ç½‘ç»œçŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15",
            "zh": "å›¾ 9.15"
        }
    },
    {
        "translation": {
            "en": "These features are not strongly covariant either positively or negatively.",
            "zh": "è¿™äº›ç‰¹å¾ä¸æ˜¯æ­£å‘æˆ–è´Ÿå‘çš„å¼ºåå˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.79)[469] states that Î´ for the neuron in the softmax output layer whose activation is the predicted probability for the correct category as specified by a 1 in the one-hot encoded target vector using the cross-entropy loss function is",
            "zh": "æ–¹ç¨‹ï¼ˆ8.79ï¼‰[469]æŒ‡å‡ºï¼Œsoftmaxè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒçš„Î´ï¼Œå…¶æ¿€æ´»æ˜¯ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°çš„ä¸€çƒ­ç¼–ç ç›®æ ‡å‘é‡ä¸­ç”±1æŒ‡å®šçš„æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ä¸º"
        }
    },
    {
        "translation": {
            "en": "multinomial model, 311, 369, 572",
            "zh": "å¤šé¡¹å¼æ¨¡å‹ï¼Œ 311ï¼Œ 369ï¼Œ 572"
        }
    },
    {
        "translation": {
            "en": "Equation (13)[658] is used to perform the update as follows:",
            "zh": "å…¬å¼ï¼ˆ13ï¼‰[658]ç”¨äºæ‰§è¡Œæ›´æ–°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
        }
    },
    {
        "translation": {
            "en": "On the basis of the predictions made by this model, the first set of errors can be calculated.",
            "zh": "æ ¹æ®è¯¥æ¨¡å‹åšå‡ºçš„é¢„æµ‹ï¼Œå¯ä»¥è®¡ç®—å‡ºç¬¬ä¸€ç»„è¯¯å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is the point at which we say overfitting has begun to occur (this is shown by the vertical dashed line, at Training Iteration = 100, in Figure 9.3[542]).",
            "zh": "è¿™å°±æ˜¯æˆ‘ä»¬è¯´è¿‡æ‹Ÿåˆå·²ç»å¼€å§‹å‘ç”Ÿçš„ç‚¹ï¼ˆè¿™åœ¨å›¾ 9.3[542] ä¸­ç”±è®­ç»ƒè¿­ä»£ = 100 å¤„çš„å‚ç›´è™šçº¿è¡¨ç¤ºï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "the tree generated using information gain ratio (Figure 4.12[144]) will return VEGETATION = riparian, whereas the tree generated using information gain (Figure 4.11[141]) will return VEGETATION = conifer.",
            "zh": "ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ¯”ç”Ÿæˆçš„æ ‘ï¼ˆå›¾ 4.12[144]ï¼‰å°†è¿”å› VEGETATION = æ²³å²¸ï¼Œè€Œä½¿ç”¨ä¿¡æ¯å¢ç›Šç”Ÿæˆçš„æ ‘ï¼ˆå›¾ 4.11[141]ï¼‰å°†è¿”å› VEGETATION = é’ˆå¶æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "For completeness, it is worth noting that classification accuracy is the opposite of misclassification rate. Again, using the confusion matrix, classification accuracy is defined as",
            "zh": "ä¸ºäº†å®Œæ•´æ€§ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåˆ†ç±»å‡†ç¡®ç‡ä¸é”™è¯¯åˆ†ç±»ç‡ç›¸åã€‚åŒæ ·ï¼Œä½¿ç”¨æ··æ·†çŸ©é˜µï¼Œåˆ†ç±»ç²¾åº¦å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.2 and that the desired output for this input is 0.7:",
            "zh": "ï¼ˆaï¼‰ å‡è®¾å¤„ç†ç¥ç»å…ƒä½¿ç”¨é€»è¾‘æ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯ç¥ç»å…ƒ 1 = 0.2ï¼Œå¹¶ä¸”è¯¥è¾“å…¥çš„æœŸæœ›è¾“å‡ºæ˜¯ 0.7ï¼š"
        }
    },
    {
        "translation": {
            "en": "0.2855",
            "zh": "0.2855"
        }
    },
    {
        "translation": {
            "en": "Table 13.2",
            "zh": "è¡¨ 13.2"
        }
    },
    {
        "translation": {
            "en": "Bellman, R. E. 1957a. Dynamic programming. Princeton University Press.",
            "zh": "Bellmanï¼Œ R. E. 1957a. åŠ¨æ€è§„åˆ’ã€‚æ™®æ—æ–¯é¡¿å¤§å­¦å‡ºç‰ˆç¤¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "where TP(l) refers to the number of instances correctly given a prediction of the target level l, FP(l) refers to the number of instances that are incorrectly given a prediction of target level l, and FN(l) refers to the number of instances that should have been given a prediction of target level l but were given some other prediction.",
            "zh": "å…¶ä¸­ TPï¼ˆlï¼‰ æ˜¯æŒ‡æ­£ç¡®ç»™å‡ºç›®æ ‡æ°´å¹³ l é¢„æµ‹çš„å®ä¾‹æ•°ï¼ŒFPï¼ˆlï¼‰ æ˜¯æŒ‡é”™è¯¯åœ°é¢„æµ‹ç›®æ ‡æ°´å¹³ l çš„å®ä¾‹æ•°ï¼ŒFNï¼ˆlï¼‰ æ˜¯æŒ‡æœ¬åº”ç»™å‡ºç›®æ ‡æ°´å¹³ l é¢„æµ‹ä½†è¢«ç»™äºˆå…¶ä»–é¢„æµ‹çš„å®ä¾‹æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation (8.29)[416] defines how Î”w i,k is calculated for a training dataset containing m examples.",
            "zh": "æ–¹ç¨‹ï¼ˆ8.29ï¼‰[416]å®šä¹‰äº†å¦‚ä½•è®¡ç®—åŒ…å«mä¸ªæ ·æœ¬çš„è®­ç»ƒæ•°æ®é›†çš„Î”w iï¼Œkã€‚"
        }
    },
    {
        "translation": {
            "en": "The cross-entropy loss measures the dissimilarity between the true distribution t and the predicted distribution . In situations where the true distribution t is encoded as a one-hot vector, the cross-entropy loss function can be simplified to:",
            "zh": "äº¤å‰ç†µæŸå¤±åº¦é‡çœŸå®åˆ†å¸ƒ t ä¸é¢„æµ‹åˆ†å¸ƒä¹‹é—´çš„ä¸ç›¸å¼‚æ€§ã€‚åœ¨çœŸå®åˆ†å¸ƒ t ç¼–ç ä¸ºå•çƒ­å‘é‡çš„æƒ…å†µä¸‹ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°å¯ä»¥ç®€åŒ–ä¸ºï¼š"
        }
    },
    {
        "translation": {
            "en": "â€”James Whitcomb Riley",
            "zh": "â€”â€”è©¹å§†æ–¯Â·æƒ ç‰¹ç§‘å§†Â·è±åˆ©"
        }
    },
    {
        "translation": {
            "en": "This means that the current trial user is judged to be more similar to the customer represented by instance d1 than the customer represented by instance d2.",
            "zh": "è¿™æ„å‘³ç€ï¼Œå½“å‰è¯•ç”¨ç”¨æˆ·è¢«åˆ¤æ–­ä¸ºä¸å®ä¾‹ d1 æ‰€ä»£è¡¨çš„å®¢æˆ·æ¯”å®ä¾‹ d2 æ‰€ä»£è¡¨çš„å®¢æˆ·æ›´ç›¸ä¼¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The softmax function will always return a positive value for every neuron because ez is always positive, even if z is negative.",
            "zh": "softmax å‡½æ•°å°†å§‹ç»ˆä¸ºæ¯ä¸ªç¥ç»å…ƒè¿”å›ä¸€ä¸ªæ­£å€¼ï¼Œå› ä¸º ez å§‹ç»ˆä¸ºæ­£å€¼ï¼Œå³ä½¿ z ä¸ºè´Ÿæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "This may indicate that the model is doing a better job of modeling the transition between the different target levels.",
            "zh": "è¿™å¯èƒ½è¡¨æ˜è¯¥æ¨¡å‹åœ¨å¯¹ä¸åŒç›®æ ‡æ°´å¹³ä¹‹é—´çš„è¿‡æ¸¡è¿›è¡Œå»ºæ¨¡æ–¹é¢åšå¾—æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "k = 4) provide enough information to capture the state.",
            "zh": "k = 4ï¼‰ æä¾›è¶³å¤Ÿçš„ä¿¡æ¯æ¥æ•è·çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.7",
            "zh": "å›¾ 8.7"
        }
    },
    {
        "translation": {
            "en": "This error is shared back (backpropagated) through the network on a layer-by-layer basis until the input layer is reached.",
            "zh": "æ­¤é”™è¯¯é€šè¿‡ç½‘ç»œé€å±‚å…±äº«ï¼ˆåå‘ä¼ æ’­ï¼‰ï¼Œç›´åˆ°åˆ°è¾¾è¾“å…¥å±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "This kind of model would be useful to architects or engineers when designing a new building.25 The trained model is",
            "zh": "è¿™ç§æ¨¡å‹åœ¨è®¾è®¡æ–°å»ºç­‘æ—¶å¯¹å»ºç­‘å¸ˆæˆ–å·¥ç¨‹å¸ˆå¾ˆæœ‰ç”¨.25 ç»è¿‡è®­ç»ƒçš„æ¨¡å‹æ˜¯"
        }
    },
    {
        "translation": {
            "en": "The dimensions of this input are 3-by-2-by-2, and so all the filters in the second layer have a depth of 2.",
            "zh": "æ­¤è¾“å…¥çš„å°ºå¯¸ä¸º 3Ã—2Ã—2ï¼Œå› æ­¤ç¬¬äºŒå±‚ä¸­çš„æ‰€æœ‰æ»¤æ³¢å™¨çš„æ·±åº¦ä¸º 2ã€‚"
        }
    },
    {
        "translation": {
            "en": "test statistic, 333",
            "zh": "æ£€éªŒç»Ÿè®¡é‡ï¼Œ333"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy performance measure can be effective in these cases.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå¹³å‡ç±»å‡†ç¡®æ€§æ€§èƒ½æµ‹é‡å¯èƒ½å¾ˆæœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "7.19â€…â€…â€…A selection of the models developed during the gradient descent process for the EEG dataset from Table 7.10[355]. The final panel shows the decision surface generated.",
            "zh": "7.19 è¡¨7.10[355]ä¸­è„‘ç”µå›¾æ•°æ®é›†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„æ¨¡å‹é€‰æ‹©ã€‚æœ€åä¸€ä¸ªé¢æ¿æ˜¾ç¤ºç”Ÿæˆçš„å†³ç­–é¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "QERR_U/G/R/I/Z",
            "zh": "QERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Table 4.10[148] shows the computation of information gain for a split using each of these thresholds.",
            "zh": "è¡¨4.10[148]æ˜¾ç¤ºäº†ä½¿ç”¨è¿™äº›é˜ˆå€¼ä¸­çš„æ¯ä¸€ä¸ªè¿›è¡Œæ‹†åˆ†çš„ä¿¡æ¯å¢ç›Šè®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "The differences between Figures 7.7(f)[329] and 7.8(b)[335] most clearly show the impact of learning rate decay as the initial learning rates are the same in these two instances.",
            "zh": "å›¾7.7ï¼ˆfï¼‰[329]å’Œå›¾7.8ï¼ˆbï¼‰[335]ä¹‹é—´çš„å·®å¼‚æœ€æ¸…æ¥šåœ°è¡¨æ˜äº†å­¦ä¹ ç‡è¡°å‡çš„å½±å“ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªå®ä¾‹çš„åˆå§‹å­¦ä¹ ç‡æ˜¯ç›¸åŒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "In the middle of the graph, at the bottom of the curve, the rate of change is zero.",
            "zh": "åœ¨å›¾è¡¨çš„ä¸­é—´ï¼Œåœ¨æ›²çº¿çš„åº•éƒ¨ï¼Œå˜åŒ–ç‡ä¸ºé›¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Second, we would be able to fill in the gaps in the dataset to predict office rental prices for office sizes that we have never actually seen in the historical dataâ€”for example, how much would we expect a 730-square-foot office to rent for?",
            "zh": "å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿå¡«è¡¥æ•°æ®é›†ä¸­çš„ç©ºç™½ï¼Œä»¥é¢„æµ‹æˆ‘ä»¬åœ¨å†å²æ•°æ®ä¸­ä»æœªè§è¿‡çš„åŠå…¬å®¤è§„æ¨¡çš„åŠå…¬å®¤ç§Ÿé‡‘ä»·æ ¼â€”â€”ä¾‹å¦‚ï¼Œæˆ‘ä»¬é¢„è®¡ä¸€ä¸ª 730 å¹³æ–¹è‹±å°ºçš„åŠå…¬å®¤ç§Ÿé‡‘æ˜¯å¤šå°‘ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "For continuous prediction problems, use the R2 coefficient.",
            "zh": "å¯¹äºè¿ç»­é¢„æµ‹é—®é¢˜ï¼Œè¯·ä½¿ç”¨ R2 ç³»æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVAB_U/G/R/I/Z",
            "zh": "DEVAB_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "8.25â€…â€…â€…The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using Xavier initialization.",
            "zh": "8.25 å›¾ 8.22[450] ä¸­ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ä½¿ç”¨ Xavier åˆå§‹åŒ–æƒé‡æ—¶ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "covariance matrix, 83, 219",
            "zh": "åæ–¹å·®çŸ©é˜µï¼Œ 83ï¼Œ 219"
        }
    },
    {
        "translation": {
            "en": "Examples of domain concepts include customer value, behavioral change, product usage mix, and customer lifecycle stage.",
            "zh": "é¢†åŸŸæ¦‚å¿µçš„ç¤ºä¾‹åŒ…æ‹¬å®¢æˆ·ä»·å€¼ã€è¡Œä¸ºå˜åŒ–ã€äº§å“ä½¿ç”¨ç»„åˆå’Œå®¢æˆ·ç”Ÿå‘½å‘¨æœŸé˜¶æ®µã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to find the optimal set of weights, we need some way to measure how well a model defined using a candidate set of weights fits a training dataset.",
            "zh": "ä¸ºäº†æ‰¾åˆ°æœ€ä½³æƒé‡é›†ï¼Œæˆ‘ä»¬éœ€è¦æŸç§æ–¹æ³•æ¥è¡¡é‡ä½¿ç”¨å€™é€‰æƒé‡é›†å®šä¹‰çš„æ¨¡å‹ä¸è®­ç»ƒæ•°æ®é›†çš„æ‹Ÿåˆç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.9â€…â€…â€…A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.9 æ±½è½¦ä¿é™©æ¬ºè¯ˆé¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆçš„é¢†åŸŸæ¦‚å¿µå’Œç›¸å…³åŠŸèƒ½çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this calculation, for each possible card Shannonâ€™s model multiplies a small probability, P(card) = i, by a large negative number, log2(P(card) = i), resulting in a relatively large negative number. The individual relatively large negative numbers calculated for all the cards are then summed to return one large negative number. The sign of this is inverted to give a large positive value for the entropy of this very impure set.",
            "zh": "åœ¨æ­¤è®¡ç®—ä¸­ï¼Œå¯¹äºæ¯ä¸ªå¯èƒ½çš„å¡ï¼ŒShannon æ¨¡å‹å°†ä¸€ä¸ªå°æ¦‚ç‡ Pï¼ˆcardï¼‰ = i ä¹˜ä»¥ä¸€ä¸ªå¤§çš„è´Ÿæ•° log2ï¼ˆPï¼ˆcardï¼‰ = iï¼‰ï¼Œå¾—åˆ°ä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„è´Ÿæ•°ã€‚ç„¶åï¼Œå°†è®¡ç®—å‡ºçš„å•ä¸ªç›¸å¯¹è¾ƒå¤§çš„è´Ÿæ•°ç›¸åŠ ï¼Œè¿”å›ä¸€ä¸ªå¤§çš„è´Ÿæ•°ã€‚è¿™ä¸ªç¬¦å·æ˜¯é¢ å€’çš„ï¼Œä¸ºè¿™ä¸ªéå¸¸ä¸çº¯çš„é›†åˆçš„ç†µç»™å‡ºäº†ä¸€ä¸ªå¾ˆå¤§çš„æ­£å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Using a classification threshold of 0.5, and assuming that true is the positive target level, construct a confusion matrix for each of the models.",
            "zh": "ï¼ˆaï¼‰ ä½¿ç”¨0.5çš„åˆ†ç±»é˜ˆå€¼ï¼Œå¹¶å‡è®¾çœŸä¸ºæ­£ç›®æ ‡æ°´å¹³ï¼Œä¸ºæ¯ä¸ªæ¨¡å‹æ„å»ºä¸€ä¸ªæ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "Certain phases in CRISP-DM are more closely linked together than others.",
            "zh": "CRISP-DMä¸­çš„æŸäº›é˜¶æ®µæ¯”å…¶ä»–é˜¶æ®µæ›´ç´§å¯†åœ°è”ç³»åœ¨ä¸€èµ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can get a hint about what is happening by comparing the distances computed using both the SALARY and AGE features with the distances computed using the SALARY feature only, that listed in the SALARY Only section of Table 5.6[206].",
            "zh": "é€šè¿‡æ¯”è¾ƒä½¿ç”¨ SALARY å’Œ AGE ç‰¹å¾è®¡ç®—çš„è·ç¦»ä¸ä»…ä½¿ç”¨ SALARY ç‰¹å¾è®¡ç®—çš„è·ç¦»ï¼ˆåœ¨è¡¨ 5.6[206] çš„ SALARY éƒ¨åˆ†ä¸­åˆ—å‡ºçš„è·ç¦»ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ‰å…³æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…çš„æç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "All the other choices that we make, such as the data to use, the descriptive features to use, and the way in which we deploy a model, bias the outcome of the overall process, and this is something that we need to be keenly aware of.",
            "zh": "æˆ‘ä»¬åšå‡ºçš„æ‰€æœ‰å…¶ä»–é€‰æ‹©ï¼Œä¾‹å¦‚è¦ä½¿ç”¨çš„æ•°æ®ã€è¦ä½¿ç”¨çš„æè¿°æ€§ç‰¹å¾ä»¥åŠæˆ‘ä»¬éƒ¨ç½²æ¨¡å‹çš„æ–¹å¼ï¼Œéƒ½ä¼šå¯¹æ•´ä¸ªè¿‡ç¨‹çš„ç»“æœäº§ç”Ÿåè§ï¼Œè¿™æ˜¯æˆ‘ä»¬éœ€è¦æ•é”åœ°æ„è¯†åˆ°çš„äº‹æƒ…ã€‚"
        }
    },
    {
        "translation": {
            "en": "MARTHA",
            "zh": "é©¬å¤§"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_G_R",
            "zh": "DEREDDIFF_G_R"
        }
    },
    {
        "translation": {
            "en": "For datasets containing more that 4,000 features, random forest ensembles (based on bagging) performed better.",
            "zh": "å¯¹äºåŒ…å«è¶…è¿‡ 4,000 ä¸ªç‰¹å¾çš„æ•°æ®é›†ï¼Œéšæœºæ£®æ—é›†åˆï¼ˆåŸºäºè£…è¢‹ï¼‰è¡¨ç°æ›´å¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The model that best fits the training data is the model corresponding to the lowest point on the error surface.",
            "zh": "æœ€é€‚åˆè®­ç»ƒæ•°æ®çš„æ¨¡å‹æ˜¯ä¸è¯¯å·®æ›²é¢ä¸Šçš„æœ€ä½ç‚¹å¯¹åº”çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Branches that are deemed likely to be due to overfitting are pruned.",
            "zh": "ä¿®å‰ªå¯èƒ½ç”±äºè¿‡åº¦æ‹Ÿåˆè€Œå¯¼è‡´çš„åˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. The following table shows details of two different clusterings of the dataset from Question 1â€”one with k = 2 and one with k = 3â€”and partial workings to calculate the silhouette for the clusterings.",
            "zh": "2. ä¸‹è¡¨æ˜¾ç¤ºäº†é—®é¢˜ 1 ä¸­æ•°æ®é›†çš„ä¸¤ä¸ªä¸åŒèšç±»çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä¸€ä¸ªæ˜¯ k = 2ï¼Œå¦ä¸€ä¸ªæ˜¯ k = 3ï¼‰ï¼Œä»¥åŠè®¡ç®—èšç±»è½®å»“çš„éƒ¨åˆ†å·¥ä½œåŸç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.6679",
            "zh": "0.6679"
        }
    },
    {
        "translation": {
            "en": "A basic operation on vectors and matrices to the transpose. The transpose of a vector converts a column vector to a row vector, and vice versa. If a is a vector, then we write aâŠº for the transpose of a. For example:",
            "zh": "å¯¹å‘é‡å’ŒçŸ©é˜µè¿›è¡Œè½¬ç½®çš„åŸºæœ¬æ“ä½œã€‚å‘é‡çš„è½¬ç½®å°†åˆ—å‘é‡è½¬æ¢ä¸ºè¡Œå‘é‡ï¼Œåä¹‹äº¦ç„¶ã€‚å¦‚æœ a æ˜¯å‘é‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å†™ aâŠº ä½œä¸º a çš„è½¬ç½®ã€‚ä¾‹å¦‚ï¼š"
        }
    },
    {
        "translation": {
            "en": "We use the â†’ notation to represent an agent transitioning from one state to another. Therefore, the probability of an agent moving from state s1 to state s2 can be written",
            "zh": "æˆ‘ä»¬ä½¿ç”¨ â†’ è¡¨ç¤ºæ³•æ¥è¡¨ç¤ºä»ä¸€ç§çŠ¶æ€è½¬æ¢åˆ°å¦ä¸€ç§çŠ¶æ€çš„ä»£ç†ã€‚å› æ­¤ï¼Œå¯ä»¥å†™å…¥æ™ºèƒ½ä½“ä»çŠ¶æ€ s1 ç§»åŠ¨åˆ°çŠ¶æ€ s2 çš„æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "We also include the GENDER of the patient (male or female).",
            "zh": "æˆ‘ä»¬è¿˜åŒ…æ‹¬æ‚£è€…çš„æ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.4.4â€ƒHandling Categorical Target Features: Logistic Regression",
            "zh": "7.4.4 å¤„ç†åˆ†ç±»ç›®æ ‡ç‰¹å¾ï¼šé€»è¾‘å›å½’"
        }
    },
    {
        "translation": {
            "en": "We start by outlining the fundamental goals of evaluation before describing the standard approach of measuring the misclassification rate for a model on a hold-out test set.",
            "zh": "æˆ‘ä»¬é¦–å…ˆæ¦‚è¿°äº†è¯„ä¼°çš„åŸºæœ¬ç›®æ ‡ï¼Œç„¶åæè¿°äº†åœ¨ä¿æŒæµ‹è¯•é›†ä¸Šæµ‹é‡æ¨¡å‹é”™è¯¯åˆ†ç±»ç‡çš„æ ‡å‡†æ–¹æ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "During the backward pass of the algorithm, we calculate a separate weight update for each neuron that uses the weight, and then the final weight update that is applied is the sum of these separate weight updates.",
            "zh": "åœ¨ç®—æ³•çš„å‘åä¼ é€’è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ºä½¿ç”¨æƒé‡çš„æ¯ä¸ªç¥ç»å…ƒè®¡ç®—å•ç‹¬çš„æƒé‡æ›´æ–°ï¼Œç„¶ååº”ç”¨çš„æœ€ç»ˆæƒé‡æ›´æ–°æ˜¯è¿™äº›å•ç‹¬æƒé‡æ›´æ–°çš„æ€»å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Therefore, using control groups is not suitable in all scenarios, but when it is applicable, it adds an extra dimension to our evaluations that takes into account not just how well a model can make predictions, but also how much the predictive model helps to address the original business problem.",
            "zh": "å› æ­¤ï¼Œä½¿ç”¨æ§åˆ¶ç»„å¹¶ä¸é€‚åˆæ‰€æœ‰åœºæ™¯ï¼Œä½†æ˜¯å½“å®ƒé€‚ç”¨æ—¶ï¼Œå®ƒä¼šä¸ºæˆ‘ä»¬çš„è¯„ä¼°å¢åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ï¼Œè¯¥ç»´åº¦ä¸ä»…è€ƒè™‘äº†æ¨¡å‹è¿›è¡Œé¢„æµ‹çš„èƒ½åŠ›ï¼Œè¿˜è€ƒè™‘äº†é¢„æµ‹æ¨¡å‹å¯¹è§£å†³åŸå§‹ä¸šåŠ¡é—®é¢˜çš„å¸®åŠ©ç¨‹åº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming again that the same random number as before (0.0728) that is less than Îµ is generated, random action selection will be used and a1 = down will again be selected.",
            "zh": "å†æ¬¡å‡è®¾ç”Ÿæˆä¸ä¹‹å‰ç›¸åŒçš„éšæœºæ•° ï¼ˆ0.0728ï¼‰ ä¸”å°äº Îµï¼Œå°†ä½¿ç”¨éšæœºæ“ä½œé€‰æ‹©å¹¶å†æ¬¡é€‰æ‹© a1 = downã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5â€ƒAdvanced Data Exploration",
            "zh": "3.5 é«˜çº§æ•°æ®æ¢ç´¢"
        }
    },
    {
        "translation": {
            "en": "multivariable linear regression, 319, 319, 575",
            "zh": "å¤šå˜é‡çº¿æ€§å›å½’ï¼Œ 319ï¼Œ 319ï¼Œ 575"
        }
    },
    {
        "translation": {
            "en": "(c) What prediction would a naive Bayes classifier return for the above book?",
            "zh": "ï¼ˆä¸™ï¼‰ä¸€ä¸ªæœ´ç´ çš„è´å¶æ–¯åˆ†ç±»å™¨ä¼šä¸ºä¸Šè¿°ä¹¦è¿”å›ä»€ä¹ˆé¢„æµ‹ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "However, this is not necessarily a problem: if we consider the backpropagation process as error gradients, Î´s, flowing through a layer of neurons then, although for some neurons in the layer the Î´s will go to zero, for others the gradients will pass through unscaled.",
            "zh": "ç„¶è€Œï¼Œè¿™å¹¶ä¸ä¸€å®šæ˜¯ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æœæˆ‘ä»¬å°†åå‘ä¼ æ’­è¿‡ç¨‹è§†ä¸ºæµç»ä¸€å±‚ç¥ç»å…ƒçš„è¯¯å·®æ¢¯åº¦ Î´sï¼Œé‚£ä¹ˆï¼Œå°½ç®¡å¯¹äºè¯¥å±‚ä¸­çš„æŸäº›ç¥ç»å…ƒï¼ŒÎ´s å°†å˜ä¸ºé›¶ï¼Œè€Œå¯¹äºå…¶ä»–ç¥ç»å…ƒï¼Œæ¢¯åº¦å°†é€šè¿‡æœªç¼©æ”¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we use n out to denote this number, then for the neurons in the last hidden layer nout(HL5) = 1 because there is only a single neuron in the output layer, and for the neurons in all the other layers in the network nout = 100.",
            "zh": "å¦‚æœæˆ‘ä»¬ç”¨ n out æ¥è¡¨ç¤ºè¿™ä¸ªæ•°å­—ï¼Œé‚£ä¹ˆå¯¹äºæœ€åä¸€ä¸ªéšè—å±‚ä¸­çš„ç¥ç»å…ƒï¼Œnoutï¼ˆHL5ï¼‰ = 1ï¼Œå› ä¸ºè¾“å‡ºå±‚ä¸­åªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼Œè€Œå¯¹äºç½‘ç»œä¸­æ‰€æœ‰å…¶ä»–å±‚ä¸­çš„ç¥ç»å…ƒï¼Œnout = 100ã€‚"
        }
    },
    {
        "translation": {
            "en": "This is not because of the literal message in the answer (either yes or no).",
            "zh": "è¿™ä¸æ˜¯å› ä¸ºç­”æ¡ˆä¸­çš„å­—é¢ä¿¡æ¯ï¼ˆæ˜¯æˆ–å¦ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4â€…â€…â€…The structure of a data quality plan.",
            "zh": "3.4 æ•°æ®è´¨é‡è®¡åˆ’çš„ç»“æ„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset ğ’Ÿ8 in Figure 4.9[139].",
            "zh": "å›¾4.9[139]ä¸­æ•°æ®é›†D8çš„åˆ†åŒºé›†ï¼ˆéƒ¨åˆ†ï¼‰ã€ç†µã€ä½™æ•°ï¼ˆRem.ï¼‰å’Œä¿¡æ¯å¢ç›Šï¼ˆInfo.Gainï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Recall, on the other hand, tells us how likely it is that a spam email will be missed by the system and end up in our in-box: 33.333% (1 âˆ’ recall).",
            "zh": "å¦ä¸€æ–¹é¢ï¼Œå¬å›å‘Šè¯‰æˆ‘ä»¬ç³»ç»Ÿé—æ¼åƒåœ¾é‚®ä»¶å¹¶æœ€ç»ˆè¿›å…¥æˆ‘ä»¬çš„æ”¶ä»¶ç®±çš„å¯èƒ½æ€§ï¼š33.333%ï¼ˆ1 - å¬å›ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "If the model is asked to make a prediction about an instance that was used to train it, the model will find as the nearest neighbor, for this instance, the instance itself.",
            "zh": "å¦‚æœè¦æ±‚æ¨¡å‹å¯¹ç”¨äºè®­ç»ƒå®ƒçš„å®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œåˆ™æ¨¡å‹å°†æ‰¾åˆ°å®ä¾‹æœ¬èº«ä½œä¸ºæœ€è¿‘é‚»ã€‚"
        }
    },
    {
        "translation": {
            "en": "MINI-BATCH",
            "zh": "å°æ‰¹é‡"
        }
    },
    {
        "translation": {
            "en": "To fit the exponential distribution, we compute the sample mean of the ACCOUNT BALANCE feature in the set of instances where FRAUD = true and set the Î» parameter equal to 1 divided by this value.",
            "zh": "ä¸ºäº†æ‹ŸåˆæŒ‡æ•°åˆ†å¸ƒï¼Œæˆ‘ä»¬è®¡ç®—äº† FRAUD = true çš„ä¸€ç»„å®ä¾‹ä¸­ ACCOUNT BALANCE ç‰¹å¾çš„æ ·æœ¬å‡å€¼ï¼Œå¹¶å°† Î» å‚æ•°è®¾ç½®ä¸ºç­‰äº 1 é™¤ä»¥è¯¥å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "2. the prior probability of that target level P(t)",
            "zh": "2. è¯¥ç›®æ ‡æ°´å¹³ Pï¼ˆtï¼‰ çš„å…ˆéªŒæ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "(b) On the basis of the completed table, calculate the silhouette for each clustering.",
            "zh": "ï¼ˆbï¼‰ æ ¹æ®å®Œæˆçš„è¡¨æ ¼ï¼Œè®¡ç®—æ¯ä¸ªèšç±»çš„è½®å»“ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can also use summing out to compute conditional probabilities from a joint probability distribution.",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ±‚å’Œä»è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­è®¡ç®—æ¡ä»¶æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "logarithm, 124",
            "zh": "å¯¹æ•°ï¼Œ124"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrix is shown in Table 13.10[725].",
            "zh": "ç”±æ­¤äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.10[725]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21(d)[163] illustrates the new distribution that arises from these changes, in which the weight of the segments highlighted in black have increased, and those in gray have decreased. The details of the next iteration of the boosting process are also detailed in Table 4.14[162] and Figure 4.21(e)[163].",
            "zh": "å›¾4.21ï¼ˆdï¼‰[163]æ˜¾ç¤ºäº†è¿™äº›å˜åŒ–äº§ç”Ÿçš„æ–°åˆ†å¸ƒï¼Œå…¶ä¸­é»‘è‰²çªå‡ºæ˜¾ç¤ºçš„çº¿æ®µçš„æƒé‡å¢åŠ ï¼Œç°è‰²çº¿æ®µçš„æƒé‡å‡å°‘ã€‚è¡¨4.14[162]å’Œå›¾4.21ï¼ˆeï¼‰[163]ä¸­ä¹Ÿè¯¦ç»†ä»‹ç»äº†æå‡è¿‡ç¨‹çš„ä¸‹ä¸€æ¬¡è¿­ä»£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating the sum of squared errors for the candidate model (with w[0] = 6.47 and w[1] = 0.62) to make predictions for the office rentals dataset.",
            "zh": "è®¡ç®—å€™é€‰æ¨¡å‹çš„å¹³æ–¹è¯¯å·®æ€»å’Œï¼ˆw[0] = 6.47 å’Œ w[1] = 0.62ï¼‰ï¼Œä»¥å¯¹åŠå…¬å®¤ç§Ÿèµæ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In order to use a PDF to represent the probability of a continuous feature taking different values, we need to choose these parameters to fit the characteristics of the data.",
            "zh": "ä¸ºäº†ä½¿ç”¨ PDF æ¥è¡¨ç¤ºè¿ç»­ç‰¹å¾å–ä¸åŒå€¼çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©è¿™äº›å‚æ•°æ¥æ‹Ÿåˆæ•°æ®çš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, as noted earlier, decision tree induction is, relatively, robust to noise in the dataset if pruning is used.",
            "zh": "æœ€åï¼Œå¦‚å‰æ‰€è¿°ï¼Œå¦‚æœä½¿ç”¨ä¿®å‰ªï¼Œå†³ç­–æ ‘å½’çº³å¯¹æ•°æ®é›†ä¸­çš„å™ªå£°ç›¸å¯¹é²æ£’ã€‚"
        }
    },
    {
        "translation": {
            "en": "On the basis of these constraints, the algorithm defines three situations where the recursion stops and a leaf node is constructed:",
            "zh": "åŸºäºè¿™äº›çº¦æŸï¼Œè¯¥ç®—æ³•å®šä¹‰äº†é€’å½’åœæ­¢å¹¶æ„é€ å¶èŠ‚ç‚¹çš„ä¸‰ç§æƒ…å†µï¼š"
        }
    },
    {
        "translation": {
            "en": "(d) Calculate the sum of squared errors for a set of predictions generated using the new set of weights calculated in Part (c).",
            "zh": "ï¼ˆdï¼‰ è®¡ç®—ä½¿ç”¨ï¼ˆcï¼‰éƒ¨åˆ†è®¡ç®—çš„æ–°æƒé‡ç»„ç”Ÿæˆçš„ä¸€ç»„é¢„æµ‹çš„å¹³æ–¹è¯¯å·®å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.10(c)[675] shows the changing cumulative reward for the DQN agent as it learns to play the Lunar Lander game. The steady increase of return clearly shows that the agent was improving its performance over time. Figure 11.10(a)[675] shows a series of screens from an episode early in the training process in which the agent performed quite poorly. This can be compared to the screens in Figure 11.10(b)[675] which are from an episode much later in training at which the agent is performing quite well.",
            "zh": "å›¾11.10ï¼ˆcï¼‰[675]æ˜¾ç¤ºäº†DQNæ™ºèƒ½ä½“åœ¨å­¦ä¹ ç©æœˆçƒç€é™†å™¨æ¸¸æˆæ—¶ä¸æ–­å˜åŒ–çš„ç´¯ç§¯å¥–åŠ±ã€‚å›æŠ¥çš„ç¨³æ­¥å¢é•¿æ¸…æ¥šåœ°è¡¨æ˜ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œä»£ç†æ­£åœ¨æ”¹å–„å…¶æ€§èƒ½ã€‚å›¾ 11.10ï¼ˆaï¼‰[675] æ˜¾ç¤ºäº†è®­ç»ƒè¿‡ç¨‹æ—©æœŸçš„ä¸€ç³»åˆ—å±å¹•ï¼Œå…¶ä¸­ä»£ç†çš„è¡¨ç°ç›¸å½“ç³Ÿç³•ã€‚è¿™å¯ä»¥ä¸å›¾11.10ï¼ˆbï¼‰[675]ä¸­çš„å±å¹•è¿›è¡Œæ¯”è¾ƒï¼Œè¿™äº›å±å¹•æ¥è‡ªè®­ç»ƒåæœŸçš„ä¸€é›†ï¼Œä»£ç†åœ¨è®­ç»ƒä¸­è¡¨ç°ç›¸å½“ä¸é”™ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, if a weight is shared by m different neurons, then the weight update after processing a single example is defined as follows:",
            "zh": "å› æ­¤ï¼Œå¦‚æœä¸€ä¸ªæƒé‡ç”± m ä¸ªä¸åŒçš„ç¥ç»å…ƒå…±äº«ï¼Œé‚£ä¹ˆå¤„ç†å•ä¸ªç¤ºä¾‹åçš„æƒé‡æ›´æ–°å®šä¹‰å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "â€œThe history of astronomy is a history of receding horizons.â€",
            "zh": "â€œå¤©æ–‡å­¦çš„å†å²æ˜¯ä¸€éƒ¨åœ°å¹³çº¿åé€€çš„å†å²ã€‚â€"
        }
    },
    {
        "translation": {
            "en": "Notation",
            "zh": "è¡¨ç¤ºæ³•"
        }
    },
    {
        "translation": {
            "en": "After estimating the performance of a deployed model using k-fold cross validation, we typically train the model that will be deployed using all of the available data.",
            "zh": "åœ¨ä½¿ç”¨ k æŠ˜å äº¤å‰éªŒè¯ä¼°è®¡å·²éƒ¨ç½²æ¨¡å‹çš„æ€§èƒ½åï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®æ¥è®­ç»ƒå°†è¦éƒ¨ç½²çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "In looking at the summary statistics and visualizations with these priorities in mind, it is clear that the customers in 1 are characterized most strongly by their low Data Usage, customers in 2 by their high Data Usage, and customers in 3 by their high Call Volume.",
            "zh": "åœ¨è€ƒè™‘è¿™äº›ä¼˜å…ˆçº§çš„æ±‡æ€»ç»Ÿè®¡æ•°æ®å’Œå¯è§†åŒ–æ—¶ï¼Œå¾ˆæ˜æ˜¾ï¼Œ1 ä¸­çš„å®¢æˆ·æœ€å¼ºçƒˆçš„ç‰¹å¾æ˜¯æ•°æ®ä½¿ç”¨ç‡ä½ï¼Œ2 ä¸­çš„å®¢æˆ·æ•°æ®ä½¿ç”¨ç‡é«˜ï¼Œ3 ä¸­çš„å®¢æˆ·å‘¼å«é‡é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The outputs of this model are combined with the 1 predictions to give the full model for this step in the ensemble building process, 2.",
            "zh": "è¯¥æ¨¡å‹çš„è¾“å‡ºä¸ 1 ä¸ªé¢„æµ‹ç›¸ç»“åˆï¼Œä¸ºé›†æˆæ„å»ºè¿‡ç¨‹ä¸­çš„è¿™ä¸€æ­¥ 2 æä¾›äº†å®Œæ•´çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is possible, however, to determine the slope of the error surface by determining the derivative of the function used to generate it, and then calculating the value of this derivative at the random point selected in the weight space.",
            "zh": "ä½†æ˜¯ï¼Œå¯ä»¥é€šè¿‡ç¡®å®šç”¨äºç”Ÿæˆè¯¯å·®é¢çš„å‡½æ•°çš„å¯¼æ•°ï¼Œç„¶ååœ¨æƒé‡ç©ºé—´ä¸­é€‰æ‹©çš„éšæœºç‚¹è®¡ç®—è¯¥å¯¼æ•°çš„å€¼æ¥ç¡®å®šè¯¯å·®æ›²é¢çš„æ–œç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.2.3â€ƒError Surfaces",
            "zh": "7.2.3 é”™è¯¯é¢"
        }
    },
    {
        "translation": {
            "en": "Collecting spectrographic information involves a much more complicated process than capturing imaging data, so it is done for a much smaller portion of the sky.",
            "zh": "æ”¶é›†å…‰è°±ä¿¡æ¯æ¶‰åŠæ¯”æ•è·æˆåƒæ•°æ®å¤æ‚å¾—å¤šçš„è¿‡ç¨‹ï¼Œå› æ­¤å®ƒæ˜¯é’ˆå¯¹å¤©ç©ºçš„ä¸€å°éƒ¨åˆ†å®Œæˆçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEVABERR_U/G/R/I/Z",
            "zh": "DEVABERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "As a result, it is typically easier to collect the data required to calculate these probabilities.",
            "zh": "å› æ­¤ï¼Œé€šå¸¸æ›´å®¹æ˜“æ”¶é›†è®¡ç®—è¿™äº›æ¦‚ç‡æ‰€éœ€çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "At AT, all calls were classified as either peak time calls or off-peak time calls.",
            "zh": "åœ¨ ATï¼Œæ‰€æœ‰å‘¼å«éƒ½è¢«å½’ç±»ä¸ºé«˜å³°æ—¶æ®µå‘¼å«æˆ–éé«˜å³°æ—¶æ®µå‘¼å«ã€‚"
        }
    },
    {
        "translation": {
            "en": "maximum a posteriori, 254, 261, 556",
            "zh": "æœ€å¤§ A åéªŒï¼Œ254ã€261ã€556"
        }
    },
    {
        "translation": {
            "en": "The unrolling of the network through time during the forward pass means that some neurons49 will occur multiple times in the unrolled network, and we store the weighted sum z value and activation value a of each neuron at each time-step.",
            "zh": "åœ¨å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­ï¼Œç½‘ç»œéšæ—¶é—´å±•å¼€æ„å‘³ç€ä¸€äº›ç¥ç»å…ƒ49å°†åœ¨å±•å¼€çš„ç½‘ç»œä¸­å¤šæ¬¡å‡ºç°ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿å­˜å‚¨æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒæ€»å’Œzå€¼å’Œæ¿€æ´»å€¼aã€‚"
        }
    },
    {
        "translation": {
            "en": "where k is the number of instances inside the hypercube, and m is the number of dimensions of the feature space.",
            "zh": "å…¶ä¸­ k æ˜¯è¶…ç«‹æ–¹ä½“å†…çš„å®ä¾‹æ•°ï¼Œm æ˜¯ç‰¹å¾ç©ºé—´çš„ç»´æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Often, choosing the number of bins comes down to intuition and a process of trial and error experimentation.",
            "zh": "é€šå¸¸ï¼Œé€‰æ‹©ç®±å­çš„æ•°é‡å½’ç»“ä¸ºç›´è§‰å’Œè¯•é”™å®éªŒçš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The advantage of this is that, except for introducing the mechanism of basis functions, we do not need to make any other changes to the approach we have presented so far.",
            "zh": "è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œé™¤äº†å¼•å…¥åŸºå‡½æ•°çš„æœºåˆ¶å¤–ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¯¹è¿„ä»Šä¸ºæ­¢æå‡ºçš„æ–¹æ³•è¿›è¡Œä»»ä½•å…¶ä»–æ›´æ”¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The K-S chart for the email classification predictions shown in Table 9.11[557].",
            "zh": "è¡¨ 9.11[557] ä¸­æ‰€ç¤ºçš„ç”µå­é‚®ä»¶åˆ†ç±»é¢„æµ‹çš„ K-S å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "which states that the maximum cumulative return following an action at taken in a state st is earned by continuing to take the action that will return the maximum return.",
            "zh": "å®ƒæŒ‡å‡ºï¼Œåœ¨çŠ¶æ€ ST ä¸­é‡‡å–çš„è¡ŒåŠ¨åçš„æœ€å¤§ç´¯ç§¯å›æŠ¥æ˜¯é€šè¿‡ç»§ç»­é‡‡å–å°†è¿”å›æœ€å¤§å›æŠ¥çš„è¡ŒåŠ¨æ¥è·å¾—çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a standard t-statistic look-up table, we can then determine the p-value associated with this test (this is a two tailed t-test with degrees of freedom set to the number of instances in the training set minus 2).",
            "zh": "ç„¶åï¼Œä½¿ç”¨æ ‡å‡†çš„ t ç»Ÿè®¡é‡æŸ¥æ‰¾è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šä¸æ­¤æ£€éªŒç›¸å…³çš„ p å€¼ï¼ˆè¿™æ˜¯ä¸€ä¸ªåŒå°¾ t æ£€éªŒï¼Œå…¶è‡ªç”±åº¦è®¾ç½®ä¸ºè®­ç»ƒé›†ä¸­çš„å®ä¾‹æ•°å‡å» 2ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The only drawback to standardization is that the models become less interpretable.",
            "zh": "æ ‡å‡†åŒ–çš„å”¯ä¸€ç¼ºç‚¹æ˜¯æ¨¡å‹å˜å¾—ä¸é‚£ä¹ˆå¯è§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Both precision and recall can assume values in the range [0,1], and higher values in both cases indicate better model performance.",
            "zh": "ç²¾ç¡®åº¦å’Œå¬å›ç‡éƒ½å¯ä»¥å‡å®šå€¼åœ¨ [0,1] èŒƒå›´å†…ï¼Œè¿™ä¸¤ç§æƒ…å†µä¸‹çš„å€¼è¶Šé«˜è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 8.15[471] steps through the calculations that bring us from the logits for each of the neurons for each example to the corresponding softmax activations and then to the Î´s for each neuron for each example.",
            "zh": "è¡¨ 8.15[471] é€æ­¥å®Œæˆè®¡ç®—ï¼Œä»æ¯ä¸ªç¤ºä¾‹çš„æ¯ä¸ªç¥ç»å…ƒçš„å¯¹æ•°åˆ°ç›¸åº”çš„ softmax æ¿€æ´»ï¼Œç„¶ååˆ°æ¯ä¸ªç¤ºä¾‹çš„æ¯ä¸ªç¥ç»å…ƒçš„ Î´sã€‚"
        }
    },
    {
        "translation": {
            "en": "The key difference, however, is that reinforcement learning does not require a labeled dataset containing examples of correct behavior to learn from.",
            "zh": "ç„¶è€Œï¼Œå…³é”®çš„åŒºåˆ«åœ¨äºï¼Œå¼ºåŒ–å­¦ä¹ ä¸éœ€è¦åŒ…å«æ­£ç¡®è¡Œä¸ºç¤ºä¾‹çš„æ ‡è®°æ•°æ®é›†æ¥å­¦ä¹ ã€‚"
        }
    },
    {
        "translation": {
            "en": "TPR, 548",
            "zh": "TPRï¼Œ548"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks combine local receptive fields, weight sharing, and sub-sampling.",
            "zh": "å·ç§¯ç¥ç»ç½‘ç»œç»“åˆäº†å±€éƒ¨æ„Ÿå—é‡ã€æƒé‡å…±äº«å’Œå­é‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "While this is an improvement over raw classification accuracy, many people prefer to use a harmonic mean10 instead of an arithmetic mean when calculating average class accuracy.",
            "zh": "è™½ç„¶è¿™æ˜¯å¯¹åŸå§‹åˆ†ç±»å‡†ç¡®æ€§çš„æ”¹è¿›ï¼Œä½†åœ¨è®¡ç®—å¹³å‡ç±»å‡†ç¡®åº¦æ—¶ï¼Œè®¸å¤šäººæ›´å–œæ¬¢ä½¿ç”¨è°æ³¢å¹³å‡å€¼10è€Œä¸æ˜¯ç®—æœ¯å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "This puts an extra burden on developers to implement these supports themselves.",
            "zh": "è¿™ç»™å¼€å‘äººå‘˜å¸¦æ¥äº†é¢å¤–çš„è´Ÿæ‹…ï¼Œè®©ä»–ä»¬è‡ªå·±å®ç°è¿™äº›æ”¯æŒã€‚"
        }
    },
    {
        "translation": {
            "en": "This distribution contained 16 entries.",
            "zh": "æ­¤å‘è¡Œç‰ˆåŒ…å« 16 ä¸ªæ¡ç›®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Lehmann, Thomas Martin, Mark Oliver GÃ¼ld, Daniel Keysers, Henning Schubert, Michael Kohnen, and Berthold B. Wein. 2003. Determining the view of chest radiographs. Journal of Digital Imaging 16 (3): 280â€“291.",
            "zh": "è±æ›¼ã€æ‰˜é©¬æ–¯Â·é©¬ä¸ã€é©¬å…‹Â·å¥¥åˆ©å¼—Â·å±…å°”å¾·ã€ä¸¹å°¼å°”Â·å‡¯ç‘Ÿæ–¯ã€äº¨å®Â·èˆ’ä¼¯ç‰¹ã€è¿ˆå…‹å°”Â·ç§‘å®å’Œè´ç‰¹éœå°”å¾·Â·æ¸©ã€‚2003. ç¡®å®šèƒ¸ç‰‡çš„è§†å›¾ã€‚æ•°å­—æˆåƒæ‚å¿— 16 ï¼ˆ3ï¼‰ï¼š280â€“291ã€‚"
        }
    },
    {
        "translation": {
            "en": "5.5â€ƒSummary",
            "zh": "5.5 å°ç»“"
        }
    },
    {
        "translation": {
            "en": "PEAKOFFPEAKRATIO",
            "zh": "å³°å€¼å…³é—­å³°å€¼æ¯”ç‡"
        }
    },
    {
        "translation": {
            "en": "Consequently, this neuron will use nin weights in its weighted sum w =< w1,â€¦wnin >",
            "zh": "å› æ­¤ï¼Œè¯¥ç¥ç»å…ƒå°†åœ¨å…¶åŠ æƒå’Œ w =< w1 ä¸­ä½¿ç”¨ nin æƒé‡,...WNIN >"
        }
    },
    {
        "translation": {
            "en": "12.3â€ƒData Preparation",
            "zh": "12.3 æ•°æ®å‡†å¤‡"
        }
    },
    {
        "translation": {
            "en": "13.8â€…â€…â€…(a)â€“(c) Small multiple box plots (split by the target feature) of some of the features from the SDSS ABT.",
            "zh": "13.8 ï¼ˆaï¼‰â€“ï¼ˆcï¼‰ SDSS ABTä¸­ä¸€äº›ç‰¹å¾çš„å°å¤šç®±å½¢å›¾ï¼ˆæŒ‰ç›®æ ‡ç‰¹å¾åˆ’åˆ†ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Model ensembles combining bagging, subspace sampling, and decision trees are known as random forest models.",
            "zh": "ç»“åˆè£…è¢‹ã€å­ç©ºé—´é‡‡æ ·å’Œå†³ç­–æ ‘çš„æ¨¡å‹é›†æˆç§°ä¸ºéšæœºæ£®æ—æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes model addresses this problem by naively assuming that each of the descriptive features in a domain is conditionally independent of all the other descriptive features, given the state of the target feature. This assumption, although often wrong, enables the naive Bayes model to maximally factorize the representation that it uses of the domainâ€”in other words, to use the smallest possible number of probabilities to represent the domain.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹é€šè¿‡å¤©çœŸåœ°å‡è®¾åŸŸä¸­çš„æ¯ä¸ªæè¿°æ€§ç‰¹å¾åœ¨ç»™å®šç›®æ ‡ç‰¹å¾çš„çŠ¶æ€ä¸‹æœ‰æ¡ä»¶åœ°ç‹¬ç«‹äºæ‰€æœ‰å…¶ä»–æè¿°æ€§ç‰¹å¾æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿™ä¸ªå‡è®¾è™½ç„¶ç»å¸¸æ˜¯é”™è¯¯çš„ï¼Œä½†å®ƒä½¿æœ´ç´ è´å¶æ–¯æ¨¡å‹èƒ½å¤Ÿæœ€å¤§é™åº¦åœ°åˆ†è§£å®ƒä½¿ç”¨çš„åŸŸè¡¨ç¤ºï¼Œæ¢å¥è¯è¯´ï¼Œä½¿ç”¨å°½å¯èƒ½å°‘çš„æ¦‚ç‡æ¥è¡¨ç¤ºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "If there are a large number of descriptive features, then we will need a large training dataset.",
            "zh": "å¦‚æœæœ‰å¤§é‡çš„æè¿°æ€§ç‰¹å¾ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†éœ€è¦ä¸€ä¸ªå¤§å‹è®­ç»ƒæ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, given the following query:",
            "zh": "ä¾‹å¦‚ï¼Œç»™å®šä»¥ä¸‹æŸ¥è¯¢ï¼š"
        }
    },
    {
        "translation": {
            "en": "Features have been extracted from these biopsies by lab technicians who rate samples across a number of cagegories on a scale of 1 to 10.",
            "zh": "å®éªŒå®¤æŠ€æœ¯äººå‘˜ä»è¿™äº›æ´»æ£€ä¸­æå–äº†ç‰¹å¾ï¼Œä»–ä»¬ä»¥ 1 åˆ° 10 çš„ç­‰çº§å¯¹å¤šä¸ªç¬¼å­çš„æ ·æœ¬è¿›è¡Œè¯„åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "This means that there is no uncertainty about the result when a selection is made from this set.",
            "zh": "è¿™æ„å‘³ç€ä»æ­¤é›†åˆä¸­è¿›è¡Œé€‰æ‹©æ—¶ï¼Œç»“æœæ²¡æœ‰ä¸ç¡®å®šæ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Technically these boundaries are hyperplanes11 and, as we shall see, play an important role when we are using the k-d tree to find the nearest neighbor for a query.",
            "zh": "ä»æŠ€æœ¯ä¸Šè®²ï¼Œè¿™äº›è¾¹ç•Œæ˜¯è¶…å¹³é¢11ï¼Œæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨ k-d æ ‘æŸ¥æ‰¾æŸ¥è¯¢çš„æœ€è¿‘é‚»æ—¶ï¼Œå®ƒä»¬èµ·ç€é‡è¦ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "20. If either vector used to calculate a cosine similarity contains negative feature values, then the cosine similarity will actually be in the range [âˆ’1,1]. As previously, 1 indicates high similarity, and 0 indicates dissimilarity, but it can be difficult to interpret negative similarity scores. Negative similarity values can be avoided, however, if we use range normalization (see Section 3.6.1[87]) to ensure that descriptive feature values always remain positive.",
            "zh": "20. å¦‚æœç”¨äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çš„ä»»ä¸€å‘é‡éƒ½åŒ…å«è´Ÿç‰¹å¾å€¼ï¼Œåˆ™ä½™å¼¦ç›¸ä¼¼åº¦å®é™…ä¸Šå°†åœ¨ [âˆ’1,1] èŒƒå›´å†…ã€‚å¦‚å‰æ‰€è¿°ï¼Œ1 è¡¨ç¤ºé«˜ç›¸ä¼¼æ€§ï¼Œ0 è¡¨ç¤ºä¸ç›¸ä¼¼æ€§ï¼Œä½†å¯èƒ½å¾ˆéš¾è§£é‡Šè´Ÿç›¸ä¼¼æ€§åˆ†æ•°ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–ï¼ˆå‚è§ç¬¬ 3.6.1 èŠ‚[87]ï¼‰æ¥ç¡®ä¿æè¿°æ€§ç‰¹å¾å€¼å§‹ç»ˆä¿æŒæ­£å€¼ï¼Œåˆ™å¯ä»¥é¿å…è´Ÿç›¸ä¼¼æ€§å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "To overcome this, sequences of the last k screenshots stacked together can be used as the state representation.",
            "zh": "ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥å°†æœ€å k ä¸ªå±å¹•æˆªå›¾å †å åœ¨ä¸€èµ·çš„åºåˆ—ç”¨ä½œçŠ¶æ€è¡¨ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Anscombeâ€™s quartet. For all four samples, the correlation measure returns the same value (0.816) even though the relationship between the features is very different in each case.",
            "zh": "å®‰æ–¯ç§‘å§†çš„å››é‡å¥ã€‚å¯¹äºæ‰€æœ‰å››ä¸ªæ ·æœ¬ï¼Œç›¸å…³åº¦é‡è¿”å›ç›¸åŒçš„å€¼ ï¼ˆ0.816ï¼‰ï¼Œå°½ç®¡æ¯ç§æƒ…å†µä¸‹ç‰¹å¾ä¹‹é—´çš„å…³ç³»éƒ½éå¸¸ä¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "A well-known algorithm that focuses on this approach to reducing the complexity is the variable elimination algorithm (Zhang and Poole, 1994).",
            "zh": "ä¸€ä¸ªè‘—åçš„ç®—æ³•ä¸“æ³¨äºé™ä½å¤æ‚æ€§çš„æ–¹æ³•ï¼Œæ˜¯å˜é‡æ¶ˆé™¤ç®—æ³•ï¼ˆZhangå’ŒPooleï¼Œ1994ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€”Samuel Beckett",
            "zh": "â€”â€”å¡ç¼ªå°”Â·è´å…‹ç‰¹"
        }
    },
    {
        "translation": {
            "en": "However, if we then add the bias term (the y-intercept) to the results of the linear function, we are translating the results of the linear function away from the origin.",
            "zh": "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬éšåå°†åç½®é¡¹ï¼ˆy æˆªè·ï¼‰æ·»åŠ åˆ°çº¿æ€§å‡½æ•°çš„ç»“æœä¸­ï¼Œæˆ‘ä»¬å°†çº¿æ€§å‡½æ•°çš„ç»“æœä»åŸç‚¹è½¬æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "where ğ•„(q) is the prediction made by the model for the query q, levels(t) is the set of levels in the domain of the target feature t, and BayesianNetwork(t = l,q) returns the probability computed by the network for the event t = l given the evidence specified in the query q.",
            "zh": "å…¶ä¸­ Mï¼ˆqï¼‰ æ˜¯æ¨¡å‹å¯¹æŸ¥è¯¢ q æ‰€åšçš„é¢„æµ‹ï¼Œlevelsï¼ˆtï¼‰ æ˜¯ç›®æ ‡è¦ç´  t åŸŸä¸­çš„æ°´å¹³é›†ï¼ŒBayesianNetworkï¼ˆt = lï¼Œqï¼‰ è¿”å›ç½‘ç»œåœ¨ç»™å®šæŸ¥è¯¢ q ä¸­æŒ‡å®šçš„è¯æ®çš„æƒ…å†µä¸‹ä¸ºäº‹ä»¶ t = l è®¡ç®—çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 9.17[571] shows cumulative gain, lift, and cumulative lift charts (the gain chart is not shown as it is essentially the same as the lift chart) for four different sets of model predictions for the larger version of the email classification test set (these are the same predictions for which ROC charts and K-S charts were plotted in Figures 9.12(b)[562] and 9.14[566]).",
            "zh": "å›¾ 9.17[571] æ˜¾ç¤ºäº†è¾ƒå¤§ç‰ˆæœ¬çš„ç”µå­é‚®ä»¶åˆ†ç±»æµ‹è¯•é›†çš„å››ç»„ä¸åŒæ¨¡å‹é¢„æµ‹çš„ç´¯ç§¯å¢ç›Šã€æå‡å’Œç´¯ç§¯æå‡å›¾ï¼ˆå¢ç›Šå›¾æœªæ˜¾ç¤ºï¼Œå› ä¸ºå®ƒä¸æå‡å›¾åŸºæœ¬ç›¸åŒï¼‰ï¼ˆè¿™äº›é¢„æµ‹ä¸å›¾ 9.12ï¼ˆbï¼‰[562] å’Œ 9.14[566] ä¸­ç»˜åˆ¶çš„ ROC å›¾å’Œ K-S å›¾ç›¸åŒï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "13.1.1â€ƒSituational Fluency",
            "zh": "13.1.1 æƒ…å¢ƒæµç•…æ€§"
        }
    },
    {
        "translation": {
            "en": "The Outcome column of Table 9.1[537] shows the category to which each prediction made by the model belongs. One thing worth keeping in mind is that there are two ways in which the prediction made by a model can be correctâ€”true positive or true negativeâ€”and two ways in which the prediction made by a model can be incorrectâ€”false positive or false negative.2 The confusion matrix allows us to capture these different types of correct and incorrect predictions made by the model.",
            "zh": "è¡¨9.1[537]çš„â€œç»“æœâ€åˆ—æ˜¾ç¤ºäº†æ¨¡å‹æ‰€åšçš„æ¯ä¸ªé¢„æµ‹æ‰€å±çš„ç±»åˆ«ã€‚å€¼å¾—è®°ä½çš„ä¸€ä»¶äº‹æ˜¯ï¼Œæ¨¡å‹åšå‡ºçš„é¢„æµ‹å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼æ­£ç¡®ï¼ˆçœŸæ­£æˆ–çœŸé˜´ï¼‰ï¼Œä»¥åŠæ¨¡å‹åšå‡ºçš„é¢„æµ‹å¯èƒ½ä¸æ­£ç¡®çš„ä¸¤ç§æ–¹å¼ï¼ˆå‡é˜³æ€§æˆ–å‡é˜´æ€§ï¼‰.2 æ··æ·†çŸ©é˜µå…è®¸æˆ‘ä»¬æ•è·æ¨¡å‹åšå‡ºçš„è¿™äº›ä¸åŒç±»å‹çš„æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 6.5",
            "zh": "è¡¨ 6.5"
        }
    },
    {
        "translation": {
            "en": "Throughout the chapter we return to a case study that demonstrates how these approaches are used in practice.",
            "zh": "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å›åˆ°ä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†è¿™äº›æ–¹æ³•åœ¨å®è·µä¸­çš„ä½¿ç”¨æ–¹å¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "To avoid this kind of extreme partitioning, we introduce an early stopping criterion into the algorithm for building regression trees.",
            "zh": "ä¸ºäº†é¿å…è¿™ç§æç«¯çš„åˆ†åŒºï¼Œæˆ‘ä»¬åœ¨æ„å»ºå›å½’æ ‘çš„ç®—æ³•ä¸­å¼•å…¥äº†ä¸€ä¸ªæ—©æœŸåœæ­¢æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A mixture of Gaussians distribution is defined by three parameters for each component: a mean, Î¼, a standard deviation, Ïƒ, and a weight, Ï‰.",
            "zh": "é«˜æ–¯åˆ†å¸ƒçš„æ··åˆç”±æ¯ä¸ªåˆ†é‡çš„ä¸‰ä¸ªå‚æ•°å®šä¹‰ï¼šå‡å€¼ã€Î¼ã€æ ‡å‡†å·® Ïƒ å’Œæƒé‡ Ï‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the sum of squared errors is computed using Equation (9.25)[575], and the total sum of squares is given by",
            "zh": "å…¶ä¸­ï¼Œè¯¯å·®çš„å¹³æ–¹å’Œä½¿ç”¨å…¬å¼ï¼ˆ9.25ï¼‰[575]è®¡ç®—ï¼Œå¹³æ–¹å’Œçš„æ€»å’Œç”±ä¸‹å¼ç»™å‡º"
        }
    },
    {
        "translation": {
            "en": "This means that we only need to test whether the difference between the value for this feature for the query instance and the value for this feature that defines the hyperplane is less than the best-distance (Line 8).",
            "zh": "è¿™æ„å‘³ç€æˆ‘ä»¬åªéœ€è¦æµ‹è¯•æŸ¥è¯¢å®ä¾‹çš„æ­¤åŠŸèƒ½å€¼ä¸å®šä¹‰è¶…å¹³é¢çš„æ­¤åŠŸèƒ½å€¼ä¹‹é—´çš„å·®å€¼æ˜¯å¦å°äºæœ€ä½³è·ç¦»ï¼ˆç¬¬ 8 è¡Œï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The more interesting descriptive features were ones that had to be derived from the raw data sources.",
            "zh": "æ›´æœ‰è¶£çš„æè¿°æ€§ç‰¹å¾æ˜¯å¿…é¡»ä»åŸå§‹æ•°æ®æºæ´¾ç”Ÿçš„ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "under-sampling, 93, 720",
            "zh": "æ¬ é‡‡æ ·ï¼Œ 93ï¼Œ 720"
        }
    },
    {
        "translation": {
            "en": "7.20â€…â€…â€…An illustration of three different one-versus-all prediction models for the customer type dataset in Table 7.11[359], with three target levels: (a) single (squares), (b) business (triangles), and (c) family (crosses).",
            "zh": "7.20 è¡¨7.11[359]ä¸­å®¢æˆ·ç±»å‹æ•°æ®é›†çš„ä¸‰ç§ä¸åŒçš„ä¸€å¯¹ä¸€é¢„æµ‹æ¨¡å‹çš„å›¾ç¤ºï¼Œå…·æœ‰ä¸‰ä¸ªç›®æ ‡æ°´å¹³ï¼šï¼ˆaï¼‰å•ï¼ˆæ­£æ–¹å½¢ï¼‰ï¼Œï¼ˆbï¼‰ä¸šåŠ¡ï¼ˆä¸‰è§’å½¢ï¼‰å’Œï¼ˆcï¼‰ç³»åˆ—ï¼ˆåå­—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Support vector machines are also non-parametric models.",
            "zh": "æ”¯æŒå‘é‡æœºä¹Ÿæ˜¯éå‚æ•°æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "This complexity and the excessive depth of the tree suggest overfitting.",
            "zh": "è¿™ç§å¤æ‚æ€§å’Œæ ‘çš„è¿‡æ·±è¡¨æ˜è¿‡åº¦æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "As with our previous calculations, the posterior probabilities for meningitis, calculated under the assumption of conditional independence of the evidence, indicates that the patient probably does not have meningitis, and consequently, a MAP Bayesian model would return MENINGITIS = false as the prediction for this query instance.",
            "zh": "ä¸æˆ‘ä»¬ä¹‹å‰çš„è®¡ç®—ä¸€æ ·ï¼Œåœ¨è¯æ®æ¡ä»¶ç‹¬ç«‹æ€§çš„å‡è®¾ä¸‹è®¡ç®—çš„è„‘è†œç‚åéªŒæ¦‚ç‡è¡¨æ˜æ‚£è€…å¯èƒ½æ²¡æœ‰è„‘è†œç‚ï¼Œå› æ­¤ï¼ŒMAP è´å¶æ–¯æ¨¡å‹å°†è¿”å›è„‘è†œç‚ = false ä½œä¸ºæ­¤æŸ¥è¯¢å®ä¾‹çš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "If there is no relationship, then we should expect that the levels of the first feature will be evenly distributed among the instances having the different levels of the second feature, so all bar plots will look much the same.",
            "zh": "å¦‚æœæ²¡æœ‰å…³ç³»ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥æœŸæœ›ç¬¬ä¸€ä¸ªç‰¹å¾çš„çº§åˆ«å°†å‡åŒ€åˆ†å¸ƒåœ¨å…·æœ‰ç¬¬äºŒä¸ªç‰¹å¾ä¸åŒçº§åˆ«çš„å®ä¾‹ä¸­ï¼Œå› æ­¤æ‰€æœ‰æ¡å½¢å›¾çœ‹èµ·æ¥éƒ½å·®ä¸å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection is a good approach if we expect lots of irrelevant features in the dataset, because typically it results in a lower overall computational cost for feature selection due to the fact that on average it generates smaller feature subsets.",
            "zh": "å¦‚æœæˆ‘ä»¬æœŸæœ›æ•°æ®é›†ä¸­æœ‰å¾ˆå¤šä¸ç›¸å…³çš„ç‰¹å¾ï¼Œé‚£ä¹ˆå‰å‘é¡ºåºé€‰æ‹©æ˜¯ä¸€ç§å¾ˆå¥½çš„æ–¹æ³•ï¼Œå› ä¸ºé€šå¸¸å®ƒä¼šå¯¼è‡´ç‰¹å¾é€‰æ‹©çš„æ€»ä½“è®¡ç®—æˆæœ¬é™ä½ï¼Œå› ä¸ºå®ƒå¹³å‡ç”Ÿæˆè¾ƒå°çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is a range of different criteria that can be used, from a very simple threshold on the number of instances at a node in the tree, to statistical significance texts like Ï‡2.",
            "zh": "å¯ä»¥ä½¿ç”¨ä¸€ç³»åˆ—ä¸åŒçš„æ ‡å‡†ï¼Œä»æ ‘ä¸­èŠ‚ç‚¹å¤„å®ä¾‹æ•°çš„éå¸¸ç®€å•çš„é˜ˆå€¼ï¼Œåˆ°åƒ Ï‡2 è¿™æ ·çš„ç»Ÿè®¡æ˜¾è‘—æ€§æ–‡æœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "The choice, however, is arbitrary.",
            "zh": "ç„¶è€Œï¼Œé€‰æ‹©æ˜¯ä»»æ„çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "21. Because of the random nature of state transitions in TwentyTwos, a lot of episodes are needed for learning to converge.",
            "zh": "21. ç”±äº TwentyTwo ä¸­çŠ¶æ€è½¬æ¢çš„éšæœºæ€§ï¼Œéœ€è¦å¾ˆå¤šæƒ…èŠ‚æ‰èƒ½å­¦ä¼šæ”¶æ•›ã€‚"
        }
    },
    {
        "translation": {
            "en": "This line is known as a decision boundary, and because we can draw this line, this dataset is said to be linearly separable in terms of the two descriptive features used.",
            "zh": "è¿™æ¡çº¿è¢«ç§°ä¸ºå†³ç­–è¾¹ç•Œï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ç”»è¿™æ¡çº¿ï¼Œæ‰€ä»¥è¿™ä¸ªæ•°æ®é›†åœ¨ä½¿ç”¨çš„ä¸¤ä¸ªæè¿°æ€§ç‰¹å¾æ–¹é¢æ˜¯çº¿æ€§å¯åˆ†ç¦»çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "The average target value for the drug dosage prediction test set given in Table 9.20[576] is 11.132.",
            "zh": "è¡¨9.20[576]ä¸­ç»™å‡ºçš„è¯ç‰©å‰‚é‡é¢„æµ‹æµ‹è¯•é›†çš„å¹³å‡ç›®æ ‡å€¼ä¸º11.132ã€‚"
        }
    },
    {
        "translation": {
            "en": "Bayesian MAP prediction model, 254",
            "zh": "è´å¶æ–¯MAPé¢„æµ‹æ¨¡å‹ï¼Œ254"
        }
    },
    {
        "translation": {
            "en": "Second, the larger the correlation between two features, the less weight they contribute to the distance.",
            "zh": "å…¶æ¬¡ï¼Œä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§è¶Šå¤§ï¼Œå®ƒä»¬å¯¹è·ç¦»çš„è´¡çŒ®å°±è¶Šå°ã€‚"
        }
    },
    {
        "translation": {
            "en": "4â€…â€…â€…Information-Based Learning",
            "zh": "4 ä¿¡æ¯åŒ–å­¦ä¹ "
        }
    },
    {
        "translation": {
            "en": "This illustrates the big idea underlying probability-based machine learning. We can use estimates of likelihoods to determine the most likely predictions that should be made. Most important, though, we revise these predictions based on data we collect and whenever extra evidence becomes available.",
            "zh": "è¿™è¯´æ˜äº†åŸºäºæ¦‚ç‡çš„æœºå™¨å­¦ä¹ èƒŒåçš„å¤§æ¦‚å¿µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¯èƒ½æ€§çš„ä¼°è®¡æ¥ç¡®å®šåº”è¯¥åšå‡ºçš„æœ€å¯èƒ½çš„é¢„æµ‹ã€‚ä½†æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬ä¼šæ ¹æ®æ”¶é›†çš„æ•°æ®ä»¥åŠæ¯å½“æœ‰é¢å¤–è¯æ®å¯ç”¨æ—¶ä¿®æ”¹è¿™äº›é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, for example, backpropagating the error gradient âˆ‚â„°/âˆ‚ot through the elementwise vector product in the output gate (see Equation (8.116)[512]) produces the following two error gradient vectors:",
            "zh": "å› æ­¤ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡è¾“å‡ºé—¨ä¸­çš„é€å…ƒå‘é‡ç§¯åå‘ä¼ æ’­è¯¯å·®æ¢¯åº¦ âˆ‚E/âˆ‚otï¼ˆå‚è§å…¬å¼ ï¼ˆ8.116ï¼‰[512]ï¼‰ä¼šäº§ç”Ÿä»¥ä¸‹ä¸¤ä¸ªè¯¯å·®æ¢¯åº¦å‘é‡ï¼š"
        }
    },
    {
        "translation": {
            "en": "The dealerâ€™s play strictly follows these rules and so we can say that the dealer does not make any decisions during the game.",
            "zh": "åº„å®¶çš„æ¯”èµ›ä¸¥æ ¼éµå¾ªè¿™äº›è§„åˆ™ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è¯´åº„å®¶åœ¨æ¸¸æˆä¸­ä¸ä¼šåšå‡ºä»»ä½•å†³å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "3.3â€…â€…â€…A data quality report for the motor insurance claims fraud detection ABT displayed in Table 3.2[56].",
            "zh": "3.3 è¡¨3.2[56]æ‰€ç¤ºçš„æ±½è½¦ä¿é™©ç†èµ”æ¬ºè¯ˆæ£€æµ‹ABTæ•°æ®è´¨é‡æŠ¥å‘Šã€‚"
        }
    },
    {
        "translation": {
            "en": "Then for the next example we randomly choose a new set of nodes to drop and then do backpropagation as usual for this new example, but this time on the new reduced version of the network.",
            "zh": "ç„¶åï¼Œå¯¹äºä¸‹ä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬éšæœºé€‰æ‹©ä¸€ç»„è¦ä¸¢å¼ƒçš„æ–°èŠ‚ç‚¹ï¼Œç„¶ååƒå¾€å¸¸ä¸€æ ·å¯¹è¿™ä¸ªæ–°ç¤ºä¾‹è¿›è¡Œåå‘ä¼ æ’­ï¼Œä½†è¿™æ¬¡æ˜¯åœ¨æ–°çš„ç®€åŒ–ç‰ˆæœ¬çš„ç½‘ç»œä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "1. Remember that in insurance we donâ€™t refer to customers!",
            "zh": "1. è¯·è®°ä½ï¼Œåœ¨ä¿é™©ä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯æŒ‡å®¢æˆ·ï¼"
        }
    },
    {
        "translation": {
            "en": "If, however, it is in fact the case that HEADACHE, FEVER, and VOMITING are conditionally independent of each other given MENINGITIS, then we would need to store only four factors: P(M), P(H | M), P(F | M), and P(V | M).",
            "zh": "ç„¶è€Œï¼Œå¦‚æœäº‹å®ä¸Šï¼Œåœ¨è„‘è†œç‚çš„æƒ…å†µä¸‹ï¼Œå¤´ç—›ã€å‘çƒ§å’Œå‘•åæ˜¯æœ‰æ¡ä»¶åœ°ç›¸äº’ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬åªéœ€è¦å­˜å‚¨å››ä¸ªå› å­ï¼šPï¼ˆMï¼‰ã€Pï¼ˆH |Mï¼‰ã€Pï¼ˆF |Mï¼‰ å’Œ Pï¼ˆV |M)."
        }
    },
    {
        "translation": {
            "en": "One challenge is that bias in a sample can arise in indirect and non-obvious ways.",
            "zh": "ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œæ ·æœ¬ä¸­çš„åå·®å¯èƒ½ä»¥é—´æ¥å’Œä¸æ˜æ˜¾çš„æ–¹å¼å‡ºç°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 3.9(b)[79] and 3.9(d)[79] show a second example, this time for the HEIGHT and POSITION features.",
            "zh": "å›¾ 3.9ï¼ˆbï¼‰[79] å’Œ 3.9ï¼ˆdï¼‰[79] æ˜¾ç¤ºäº†ç¬¬äºŒä¸ªç¤ºä¾‹ï¼Œè¿™æ¬¡æ˜¯ HEIGHT å’Œ POSITION ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The decision tree after the data has been split using ELEVATION.",
            "zh": "ä½¿ç”¨ ELEVATION æ‹†åˆ†æ•°æ®åçš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can extend this algorithm to retrieve the k nearest neighbors by modifying the search to use distance of the kth closest instance found as best-distance.",
            "zh": "æˆ‘ä»¬å¯ä»¥æ‰©å±•æ­¤ç®—æ³•ï¼Œé€šè¿‡ä¿®æ”¹æœç´¢ä»¥ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ k ä¸ªæœ€è¿‘å®ä¾‹çš„è·ç¦»ä½œä¸ºæœ€ä½³è·ç¦»æ¥æ£€ç´¢ k ä¸ªæœ€è¿‘é‚»ã€‚"
        }
    },
    {
        "translation": {
            "en": "To use the extended domain representation of the model to make a prediction for a query, we calculate the product of the relevant descriptive feature probabilities and the priors for the different target levels as before, but using PDFs to calculate the probabilities for the continuous feature. Table 6.14[282] shows how a prediction is made for the following query:",
            "zh": "ä¸ºäº†ä½¿ç”¨æ¨¡å‹çš„æ‰©å±•åŸŸè¡¨ç¤ºæ¥å¯¹æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼Œæˆ‘ä»¬åƒä»¥å‰ä¸€æ ·è®¡ç®—ç›¸å…³æè¿°æ€§ç‰¹å¾æ¦‚ç‡å’Œä¸åŒç›®æ ‡çº§åˆ«çš„å…ˆéªŒçš„ä¹˜ç§¯ï¼Œä½†ä½¿ç”¨ PDF æ¥è®¡ç®—è¿ç»­ç‰¹å¾çš„æ¦‚ç‡ã€‚è¡¨ 6.14[282] æ˜¾ç¤ºäº†å¦‚ä½•å¯¹ä»¥ä¸‹æŸ¥è¯¢è¿›è¡Œé¢„æµ‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "EXERCISE, how regularly do they exercise",
            "zh": "é”»ç‚¼ï¼Œä»–ä»¬å¤šä¹…é”»ç‚¼ä¸€æ¬¡"
        }
    },
    {
        "translation": {
            "en": "The large adjustments made to the weights during gradient descent cause it to jump completely from one side of the error surface to the other.",
            "zh": "åœ¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¯¹æƒé‡è¿›è¡Œçš„å¤§å¹…è°ƒæ•´ä½¿å…¶å®Œå…¨ä»è¯¯å·®æ›²é¢çš„ä¸€ä¾§è·³åˆ°å¦ä¸€ä¾§ã€‚"
        }
    },
    {
        "translation": {
            "en": "out-of-time sampling, 546, 586",
            "zh": "è¶…æ—¶é‡‡æ ·ï¼Œ546,586"
        }
    },
    {
        "translation": {
            "en": "3.2.2â€…â€…â€…Case Study: Motor Insurance Fraud",
            "zh": "3.2.2 æ¡ˆä¾‹ç ”ç©¶ï¼šæ±½è½¦ä¿é™©æ¬ºè¯ˆ"
        }
    },
    {
        "translation": {
            "en": "This reflects the extension of the yes region due to the inclusion of the new instance.",
            "zh": "è¿™åæ˜ äº†ç”±äºåŒ…å«æ–°å®ä¾‹è€Œæ‰©å±•çš„ yes åŒºåŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, we have dropped the subscript from d because we are assuming that the inputs have been standardized to have a mean of 0 and a standard deviation of 1, and so all the inputs have the same mean and variance: E(d) is the mean value of an input, and var(d) is the shared scaler variance of all the inputs.",
            "zh": "ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬ä» d ä¸­åˆ é™¤äº†ä¸‹æ ‡ï¼Œå› ä¸ºæˆ‘ä»¬å‡è®¾è¾“å…¥å·²è¢«æ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ï¼Œå› æ­¤æ‰€æœ‰è¾“å…¥éƒ½å…·æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ï¼šEï¼ˆdï¼‰ æ˜¯è¾“å…¥çš„å¹³å‡å€¼ï¼Œvarï¼ˆdï¼‰ æ˜¯æ‰€æœ‰è¾“å…¥çš„å…±äº«æ ‡åº¦æ–¹å·®ã€‚"
        }
    },
    {
        "translation": {
            "en": "The training set consisted of 30% of the data in the ABT (approximately 200,000 instances), and the test set consisted of the remaining 70% (approximately 450,000 instances).14 Using the training set, Jocelyn performed a 10-fold cross validation experiment on models trained to use the full set of descriptive features to predict the 3-level target.",
            "zh": "è®­ç»ƒé›†ç”± ABT ä¸­ 30% çš„æ•°æ®ï¼ˆçº¦ 200,000 ä¸ªå®ä¾‹ï¼‰ç»„æˆï¼Œæµ‹è¯•é›†ç”±å…¶ä½™ 70%ï¼ˆçº¦ 450,000 ä¸ªå®ä¾‹ï¼‰ç»„æˆã€‚14 ä½¿ç”¨è®­ç»ƒé›†ï¼ŒJocelyn å¯¹è®­ç»ƒä¸ºä½¿ç”¨å…¨å¥—æè¿°æ€§ç‰¹å¾æ¥é¢„æµ‹ 3 çº§ç›®æ ‡çš„æ¨¡å‹è¿›è¡Œäº† 10 å€äº¤å‰éªŒè¯å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "longevity, 33",
            "zh": "é•¿å¯¿ï¼Œ33"
        }
    },
    {
        "translation": {
            "en": "The binary target feature, FRAUD, tells us whether the loan application turned out to be fraudulent (true or false).",
            "zh": "äºŒè¿›åˆ¶ç›®æ ‡ç‰¹å¾ FRAUD å‘Šè¯‰æˆ‘ä»¬è´·æ¬¾ç”³è¯·æ˜¯å¦è¢«è¯æ˜æ˜¯æ¬ºè¯ˆæ€§çš„ï¼ˆçœŸæˆ–å‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "The activation function, Ï†, is then applied to each of the elements in z(1) to generate the activations for each of the neurons in the hidden layer.",
            "zh": "ç„¶åå°†æ¿€æ´»å‡½æ•° Ï† åº”ç”¨äº zï¼ˆ1ï¼‰ ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä»¥ç”Ÿæˆéšè—å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Error-based and deep learning models are less suitable in this case as they require categorical features to be converted into sets of binary features, which causes an increase in dimensionality.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŸºäºé”™è¯¯å’Œæ·±åº¦å­¦ä¹ çš„æ¨¡å‹ä¸å¤ªåˆé€‚ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦å°†åˆ†ç±»ç‰¹å¾è½¬æ¢ä¸ºäºŒè¿›åˆ¶ç‰¹å¾é›†ï¼Œè¿™ä¼šå¯¼è‡´ç»´åº¦å¢åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "The second disadvantage is that in using a programming language, we have very little of the infrastructural support, such as data management, offered with the application-based solutions available to us.",
            "zh": "ç¬¬äºŒä¸ªç¼ºç‚¹æ˜¯ï¼Œåœ¨ä½¿ç”¨ç¼–ç¨‹è¯­è¨€æ—¶ï¼Œæˆ‘ä»¬å‡ ä¹æ²¡æœ‰å¯ç”¨çš„åŸºäºåº”ç”¨ç¨‹åºçš„è§£å†³æ–¹æ¡ˆæä¾›çš„åŸºç¡€è®¾æ–½æ”¯æŒï¼Œä¾‹å¦‚æ•°æ®ç®¡ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A.4â€…â€…â€…Data Visualization",
            "zh": "A.4 æ•°æ®å¯è§†åŒ–"
        }
    },
    {
        "translation": {
            "en": "the rate of change of the activation function with respect to changes in the weighted sum (âˆ‚ai/âˆ‚zi); and",
            "zh": "æ¿€æ´»å‡½æ•°ç›¸å¯¹äºåŠ æƒå’Œï¼ˆâˆ‚ai/âˆ‚ziï¼‰å˜åŒ–çš„å˜åŒ–ç‡;å’Œ"
        }
    },
    {
        "translation": {
            "en": "This is done in the same way as the previous examples (a weighted summation of inputs followed by the application of a non-linear activation function).",
            "zh": "è¿™ä¸å‰é¢çš„ç¤ºä¾‹ç›¸åŒï¼ˆè¾“å…¥çš„åŠ æƒæ±‚å’Œï¼Œç„¶ååº”ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Probability of an Event",
            "zh": "äº‹ä»¶çš„æ¦‚ç‡"
        }
    },
    {
        "translation": {
            "en": "In Figure 8.31[480], the key thing to note about this figure is that the neuron receives inputs only from a small predefined region of the input; in other words, the neuron receives inputs only from the pixels in its local receptive field.",
            "zh": "åœ¨å›¾8.31[480]ä¸­ï¼Œå…³äºè¯¥å›¾éœ€è¦æ³¨æ„çš„å…³é”®æ˜¯ï¼Œç¥ç»å…ƒä»…ä»è¾“å…¥çš„ä¸€ä¸ªå°é¢„å®šä¹‰åŒºåŸŸæ¥æ”¶è¾“å…¥;æ¢å¥è¯è¯´ï¼Œç¥ç»å…ƒä»…æ¥æ”¶æ¥è‡ªå…¶å±€éƒ¨æ„Ÿå—é‡ä¸­çš„åƒç´ çš„è¾“å…¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "polynomial relationship, 352",
            "zh": "å¤šé¡¹å¼å…³ç³»ï¼Œ352"
        }
    },
    {
        "translation": {
            "en": "Table 9.4",
            "zh": "è¡¨ 9.4"
        }
    },
    {
        "translation": {
            "en": "The prediction model in this case becomes",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢„æµ‹æ¨¡å‹å˜ä¸º"
        }
    },
    {
        "translation": {
            "en": "4.9â€…â€…â€…The state of the decision tree after the ğ’Ÿ1 partition has been split using STREAM.",
            "zh": "4.9 ä½¿ç”¨ STREAM æ‹†åˆ† D1 åˆ†åŒºåçš„å†³ç­–æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "The evolution of the decision boundary for each model is shown.",
            "zh": "å›¾ä¸­æ˜¾ç¤ºäº†æ¯ä¸ªæ¨¡å‹çš„å†³ç­–è¾¹ç•Œçš„æ¼”å˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "convolving a function, 485",
            "zh": "å·ç§¯å‡½æ•°ï¼Œ485"
        }
    },
    {
        "translation": {
            "en": "Similarly, the calculations of the activations for the second layer can be expressed",
            "zh": "åŒæ ·ï¼Œç¬¬äºŒå±‚çš„æ¿€æ´»è®¡ç®—å¯ä»¥è¡¨ç¤ºä¸º"
        }
    },
    {
        "translation": {
            "en": "5.3.1â€ƒA Worked Example",
            "zh": "5.3.1 å·¥ä½œç¤ºä¾‹"
        }
    },
    {
        "translation": {
            "en": "(b) How many of these potential models would be consistent with this sample of data?",
            "zh": "ï¼ˆbï¼‰ è¿™äº›å¯èƒ½çš„æ¨¡å‹ä¸­æœ‰å¤šå°‘ä¸è¿™äº›æ•°æ®æ ·æœ¬ä¸€è‡´ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Also, as subsequently discussed (and similar to the training regime used for regression models in Chapter 7[311]), neural networks are trained by iteratively running the network on examples sampled from large datasets.",
            "zh": "æ­¤å¤–ï¼Œæ­£å¦‚éšåæ‰€è®¨è®ºçš„ï¼ˆç±»ä¼¼äºç¬¬ 7 ç« [311]ä¸­ç”¨äºå›å½’æ¨¡å‹çš„è®­ç»ƒæœºåˆ¶ï¼‰ï¼Œç¥ç»ç½‘ç»œæ˜¯é€šè¿‡åœ¨ä»å¤§å‹æ•°æ®é›†ä¸­é‡‡æ ·çš„ç¤ºä¾‹ä¸Šè¿­ä»£è¿è¡Œç½‘ç»œæ¥è®­ç»ƒçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the mobile phone customer dataset given in Table 10.1[604]. (b)â€“(f) The progress of the k-means clustering algorithm, working on the simple customer segmentation dataset. The large symbols represent cluster centroids, and the smaller symbols represent cluster assignments.",
            "zh": "ï¼ˆaï¼‰ è¡¨10.1[604]ä¸­ç»™å‡ºçš„ç§»åŠ¨ç”µè¯å®¢æˆ·æ•°æ®é›†å›¾ã€‚ï¼ˆbï¼‰â€“ï¼ˆfï¼‰ k-meansèšç±»ç®—æ³•åœ¨ç®€å•å®¢æˆ·ç»†åˆ†æ•°æ®é›†ä¸Šçš„ç ”ç©¶è¿›å±•ã€‚å¤§ç¬¦å·è¡¨ç¤ºèšç±»è´¨å¿ƒï¼Œè¾ƒå°çš„ç¬¦å·è¡¨ç¤ºèšç±»åˆ†é…ã€‚"
        }
    },
    {
        "translation": {
            "en": "Note that in Equation (8.95)[491] each symbol in a matrix represents a neuron in a layer, rather than a data point.",
            "zh": "è¯·æ³¨æ„ï¼Œåœ¨ç­‰å¼ï¼ˆ8.95ï¼‰[491]ä¸­ï¼ŒçŸ©é˜µä¸­çš„æ¯ä¸ªç¬¦å·ä»£è¡¨å±‚ä¸­çš„ç¥ç»å…ƒï¼Œè€Œä¸æ˜¯æ•°æ®ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "AT is always looking for new ways to address the churn issue and in 2008 founded a customer retention team.",
            "zh": "ATä¸€ç›´åœ¨å¯»æ‰¾è§£å†³å®¢æˆ·æµå¤±é—®é¢˜çš„æ–°æ–¹æ³•ï¼Œå¹¶äº2008å¹´æˆç«‹äº†ä¸€ä¸ªå®¢æˆ·ä¿ç•™å›¢é˜Ÿã€‚"
        }
    },
    {
        "translation": {
            "en": "The scientists at SDSS listed two key galaxy morphologies of interest: elliptical and spiral.",
            "zh": "SDSSçš„ç§‘å­¦å®¶ä»¬åˆ—å‡ºäº†ä¸¤ä¸ªæ„Ÿå…´è¶£çš„å…³é”®æ˜Ÿç³»å½¢æ€ï¼šæ¤­åœ†å½¢å’Œèºæ—‹å½¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a receptive field that covers the top-left corner of the image. This figure was inspired by Figure 2 of Kelleher and Dobnik (2017).",
            "zh": "4 çš„ç°åº¦å›¾åƒçš„ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠå…·æœ‰è¦†ç›–å›¾åƒå·¦ä¸Šè§’çš„æ„Ÿå—é‡çš„ç¥ç»å…ƒã€‚è¯¥å›¾çš„çµæ„Ÿæ¥è‡ªKelleherå’ŒDobnikï¼ˆ2017ï¼‰çš„å›¾2ã€‚"
        }
    },
    {
        "translation": {
            "en": "On Line 32[420] the mini-batch sequence is shuffled between epochs.",
            "zh": "åœ¨ç¬¬ 32 è¡Œ[420]ä¸Šï¼Œå°æ‰¹é‡åºåˆ—åœ¨å„ä¸ªæ—¶æœŸä¹‹é—´è¿›è¡Œæ´—ç‰Œã€‚"
        }
    },
    {
        "translation": {
            "en": "In the matrix multiplication, each element in a row in the matrix on the left is multiplied by the corresponding element in each column in the matrix on the right, and then the results of these multiplications are summed.",
            "zh": "åœ¨çŸ©é˜µä¹˜æ³•ä¸­ï¼Œå°†å·¦è¾¹çŸ©é˜µä¸­ä¸€è¡Œä¸­çš„æ¯ä¸ªå…ƒç´ ä¹˜ä»¥å³è¾¹çŸ©é˜µä¸­æ¯åˆ—ä¸­å¯¹åº”çš„å…ƒç´ ï¼Œç„¶åå°†è¿™äº›ä¹˜æ³•çš„ç»“æœç›¸åŠ ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can also extend the product rule to define the joint probability of more than two events. When we generalize the rule in this way, it is known as the probability chain rule:",
            "zh": "æˆ‘ä»¬è¿˜å¯ä»¥æ‰©å±•ä¹˜ç§¯è§„åˆ™æ¥å®šä¹‰ä¸¤ä¸ªä»¥ä¸Šäº‹ä»¶çš„è”åˆæ¦‚ç‡ã€‚å½“æˆ‘ä»¬ä»¥è¿™ç§æ–¹å¼æ¨å¹¿è§„åˆ™æ—¶ï¼Œå®ƒè¢«ç§°ä¸ºæ¦‚ç‡é“¾è§„åˆ™ï¼š"
        }
    },
    {
        "translation": {
            "en": "Implementing a neural network as a sequence of matrix operations and then running the network on GPUs is now standard in deep learning.",
            "zh": "å°†ç¥ç»ç½‘ç»œå®ç°ä¸ºä¸€ç³»åˆ—çŸ©é˜µè¿ç®—ï¼Œç„¶ååœ¨ GPU ä¸Šè¿è¡Œç½‘ç»œç°åœ¨æ˜¯æ·±åº¦å­¦ä¹ çš„æ ‡å‡†ã€‚"
        }
    },
    {
        "translation": {
            "en": "More advanced approaches to pre-pruning use statistical significance tests to determine the importance of subtrees, for example, Ï‡2 pruning (pronounced chi-squared).21",
            "zh": "æ›´é«˜çº§çš„é¢„ä¿®å‰ªæ–¹æ³•ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒæ¥ç¡®å®šå­æ ‘çš„é‡è¦æ€§ï¼Œä¾‹å¦‚ï¼ŒÏ‡2 ä¿®å‰ªï¼ˆå‘éŸ³ä¸º Ïƒ-squaredï¼‰21ã€‚"
        }
    },
    {
        "translation": {
            "en": "A neuron is structurally equivalent to a logistic regression model: comparing Equation (8.5)[387] and Equation (7.26)[342] makes it apparent that both models calculate a weighted sum over an input vector and then pass the weighted sum value through a non-linear function.",
            "zh": "ç¥ç»å…ƒåœ¨ç»“æ„ä¸Šç­‰ä»·äºé€»è¾‘å›å½’æ¨¡å‹ï¼šæ¯”è¾ƒæ–¹ç¨‹ï¼ˆ8.5ï¼‰[387]å’Œæ–¹ç¨‹ï¼ˆ7.26ï¼‰[342]å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹éƒ½è®¡ç®—è¾“å…¥å‘é‡çš„åŠ æƒå’Œï¼Œç„¶åé€šè¿‡éçº¿æ€§å‡½æ•°ä¼ é€’åŠ æƒå’Œå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "The task of the input gate is to decide, on the basis of the current input and the propagated hidden state (hxt), which elements of the cell state, câ€¡, should be updated and how these elements should be updated.",
            "zh": "è¾“å…¥é—¨çš„ä»»åŠ¡æ˜¯æ ¹æ®å½“å‰è¾“å…¥å’Œä¼ æ’­çš„éšè—çŠ¶æ€ ï¼ˆhxtï¼‰ æ¥å†³å®šå•å…ƒçŠ¶æ€ câ€¡ çš„å“ªäº›å…ƒç´ åº”è¯¥æ›´æ–°ï¼Œä»¥åŠå¦‚ä½•æ›´æ–°è¿™äº›å…ƒç´ ã€‚"
        }
    },
    {
        "translation": {
            "en": "All these measures can have values in the range [0,1]. Higher values of TPR and TNR indicate better model performance, while the opposite is the case for FNR and FPR. Confusion matrices are often presented containing these measures rather than the raw counts, although we recommend using raw counts so that the number of instances with each of the different levels of the target feature remains apparent.",
            "zh": "æ‰€æœ‰è¿™äº›åº¦é‡å€¼çš„å€¼éƒ½å¯ä»¥åœ¨ [0,1] èŒƒå›´å†…ã€‚TPR å’Œ TNR å€¼è¶Šé«˜è¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ï¼Œè€Œ FNR å’Œ FPR çš„æƒ…å†µæ­£å¥½ç›¸åã€‚æ··æ·†çŸ©é˜µé€šå¸¸åŒ…å«è¿™äº›åº¦é‡å€¼ï¼Œè€Œä¸æ˜¯åŸå§‹è®¡æ•°ï¼Œå°½ç®¡æˆ‘ä»¬å»ºè®®ä½¿ç”¨åŸå§‹è®¡æ•°ï¼Œä»¥ä¾¿å…·æœ‰ç›®æ ‡ç‰¹å¾çš„æ¯ä¸ªä¸åŒçº§åˆ«çš„å®ä¾‹æ•°ä¿æŒæ˜æ˜¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "The notion of situational fluency5 is especially important when dealing with scientific scenarios.",
            "zh": "åœ¨å¤„ç†ç§‘å­¦æƒ…æ™¯æ—¶ï¼Œæƒ…å¢ƒæµç•…æ€§çš„æ¦‚å¿µ5å°¤ä¸ºé‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figures 5.18(d)[226] and 5.18(e)[226] illustrate the cost we would have to incur in extra instances if we wished to maintain the sampling density in the dataset in line with each increase in the dimensionality of the feature space.",
            "zh": "å›¾5.18ï¼ˆdï¼‰[226]å’Œå›¾5.18ï¼ˆeï¼‰[226]è¯´æ˜äº†å¦‚æœæˆ‘ä»¬å¸Œæœ›ä¿æŒæ•°æ®é›†ä¸­çš„é‡‡æ ·å¯†åº¦ä¸ç‰¹å¾ç©ºé—´ç»´æ•°çš„å¢åŠ ä¿æŒä¸€è‡´ï¼Œé‚£ä¹ˆåœ¨é¢å¤–å®ä¾‹ä¸­æˆ‘ä»¬å¿…é¡»æ‰¿æ‹…çš„æˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "A more common approach is to use a wrapper.",
            "zh": "æ›´å¸¸è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨åŒ…è£…å™¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, a naive Bayes model is often a good model to begin with: it is easy to train and has the potential to provide both a baseline accuracy score and some insight into the problem structure.",
            "zh": "å› æ­¤ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹é€šå¸¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ¨¡å‹ï¼šå®ƒæ˜“äºè®­ç»ƒï¼Œå¹¶ä¸”æœ‰å¯èƒ½æä¾›åŸºçº¿å‡†ç¡®æ€§åˆ†æ•°å’Œå¯¹é—®é¢˜ç»“æ„çš„ä¸€äº›è§è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "A restriction bias constrains the set of models that the algorithm will consider during the learning process.",
            "zh": "é™åˆ¶åå·®é™åˆ¶äº†ç®—æ³•åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å°†è€ƒè™‘çš„æ¨¡å‹é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another simple and very effective technique to stop overfitting is called dropout.",
            "zh": "å¦ä¸€ç§ç®€å•ä¸”éå¸¸æœ‰æ•ˆçš„åœæ­¢è¿‡æ‹Ÿåˆçš„æŠ€æœ¯ç§°ä¸º dropoutã€‚"
        }
    },
    {
        "translation": {
            "en": "The alignment between the phases of CRISP-DM, key questions for analytics projects, and the chapters and sections of this book.",
            "zh": "CRISP-DM å„ä¸ªé˜¶æ®µä¹‹é—´çš„ä¸€è‡´æ€§ã€åˆ†æé¡¹ç›®çš„å…³é”®é—®é¢˜ä»¥åŠæœ¬ä¹¦çš„ç« èŠ‚å’Œéƒ¨åˆ†ã€‚"
        }
    },
    {
        "translation": {
            "en": "6. The F1 measure is often also referred to as the F measure, F score, or F1 score.",
            "zh": "6. F1 åº¦é‡é€šå¸¸ä¹Ÿç§°ä¸º F åº¦é‡ã€F åˆ†æ•°æˆ– F1 åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "See Bishop (2006, pp.",
            "zh": "è§Bishopï¼ˆ2006å¹´ï¼Œç¬¬1é¡µï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "One of the most commonly used measures for this is the stability index.",
            "zh": "æœ€å¸¸ç”¨çš„è¡¡é‡æ ‡å‡†ä¹‹ä¸€æ˜¯ç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "If for the purposes of this discussion we naively assume that the variance of the Î´ values backpropagated to the neurons in HL5 is equal to 1, then we can expect the variance of the Î´s backpropagated to HL4 to be equal to 100 Ã— 0.04 Ã— 1 = 4.",
            "zh": "å¦‚æœå‡ºäºæœ¬è®¨è®ºçš„ç›®çš„ï¼Œæˆ‘ä»¬å¤©çœŸåœ°å‡è®¾åå‘ä¼ æ’­åˆ° HL5 ä¸­ç¥ç»å…ƒçš„ Î´ å€¼çš„æ–¹å·®ç­‰äº 1ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é¢„æœŸåå‘ä¼ æ’­åˆ° HL4 çš„ Î´ çš„æ–¹å·®ç­‰äº 100 Ã— 0.04 Ã— 1 = 4ã€‚"
        }
    },
    {
        "translation": {
            "en": "At the next time-step, these new activations are then fed back to the hidden neurons in parallel with the new input.",
            "zh": "åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ï¼Œè¿™äº›æ–°çš„æ¿€æ´»ä¸æ–°è¾“å…¥å¹¶è¡Œåé¦ˆåˆ°éšè—çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "To further explore the entropy, we can return to look at the entropy values of each set of cards shown in Figure 4.5[124].",
            "zh": "ä¸ºäº†è¿›ä¸€æ­¥æ¢ç´¢ç†µï¼Œæˆ‘ä»¬å¯ä»¥å›è¿‡å¤´æ¥æŸ¥çœ‹å›¾4.5[124]æ‰€ç¤ºçš„æ¯ç»„å¡ç‰‡çš„ç†µå€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although we usually delay handling noise issues until the modeling phase of a project (different predictive model types require different levels of noise handling, and we should in general do as little noise handling as we can), in this section we describe the most common techniques used to handle missing values and outliers.",
            "zh": "å°½ç®¡æˆ‘ä»¬é€šå¸¸ä¼šå°†å¤„ç†å™ªå£°é—®é¢˜æ¨è¿Ÿåˆ°é¡¹ç›®çš„å»ºæ¨¡é˜¶æ®µï¼ˆä¸åŒçš„é¢„æµ‹æ¨¡å‹ç±»å‹éœ€è¦ä¸åŒçº§åˆ«çš„å™ªå£°å¤„ç†ï¼Œå¹¶ä¸”æˆ‘ä»¬é€šå¸¸åº”è¯¥å°½å¯èƒ½å°‘åœ°å¤„ç†å™ªå£°ï¼‰ï¼Œä½†åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”¨äºå¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼çš„æœ€å¸¸è§æŠ€æœ¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example",
            "zh": "ä¾‹å¦‚"
        }
    },
    {
        "translation": {
            "en": "Figure 10.4",
            "zh": "å›¾ 10.4"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(b)[60] shows a shape indicative of a normal distribution.",
            "zh": "å›¾3.2ï¼ˆbï¼‰[60]æ˜¾ç¤ºäº†æŒ‡ç¤ºæ­£æ€åˆ†å¸ƒçš„å½¢çŠ¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Modeling",
            "zh": "å»º æ¨¡"
        }
    },
    {
        "translation": {
            "en": "One especially creative example of feature design was when a large retailer wanted to use the level of activity at a competitorâ€™s stores as a descriptive feature in one of their analytics solutions.",
            "zh": "åŠŸèƒ½è®¾è®¡çš„ä¸€ä¸ªç‰¹åˆ«æœ‰åˆ›æ„çš„ä¾‹å­æ˜¯ï¼Œå½“ä¸€å®¶å¤§å‹é›¶å”®å•†å¸Œæœ›åœ¨å…¶åˆ†æè§£å†³æ–¹æ¡ˆä¹‹ä¸€ä¸­ä½¿ç”¨ç«äº‰å¯¹æ‰‹å•†åº—çš„æ´»åŠ¨æ°´å¹³ä½œä¸ºæè¿°æ€§ç‰¹å¾æ—¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "where dist(q,di) is the distance between the query instance and its ith nearest neighbor. This is a weighted average of the target values of the k nearest neighbors, as opposed to the simple average in Equation (5.7)[208].",
            "zh": "å…¶ä¸­ distï¼ˆqï¼Œdiï¼‰ æ˜¯æŸ¥è¯¢å®ä¾‹ä¸å…¶ç¬¬ i ä¸ªæœ€è¿‘é‚»åŸŸä¹‹é—´çš„è·ç¦»ã€‚è¿™æ˜¯kä¸ªæœ€è¿‘é‚»çš„ç›®æ ‡å€¼çš„åŠ æƒå¹³å‡å€¼ï¼Œè€Œä¸æ˜¯ç­‰å¼ï¼ˆ5.7ï¼‰[208]ä¸­çš„ç®€å•å¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Flux is another measure that attempts to standardize measures of brightness, taking into account how far away different objects are from the telescope.",
            "zh": "é€šé‡æ˜¯å¦ä¸€ç§è¯•å›¾æ ‡å‡†åŒ–äº®åº¦æµ‹é‡çš„æªæ–½ï¼Œè€ƒè™‘åˆ°ä¸åŒç‰©ä½“ä¸æœ›è¿œé•œçš„è·ç¦»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ball, N. M., J. Loveday, M. Fukugita, O. Nakamura, S. Okamura, J. Brinkmann, and R. J. Brunner. 2004. Galaxy types in the sloan digital sky survey using supervised artificial neural networks. Monthly Notices of the Royal Astronomical Society 348 (3): 1038â€“1046. doi:10.1111/j.1365-2966.2004.07429.x. http://mnras.oxfordjournals.org/content/348/3/1038.abstract.",
            "zh": "é²å°”ã€NMã€J. Lovedayã€M. Fukugitaã€O. Nakamuraã€S. Okamuraã€J. Brinkmann å’Œ RJ Brunnerã€‚2004. ä½¿ç”¨ç›‘ç£äººå·¥ç¥ç»ç½‘ç»œçš„æ–¯éš†æ•°å­—å·¡å¤©ä¸­çš„æ˜Ÿç³»ç±»å‹.çš‡å®¶å¤©æ–‡å­¦ä¼šæœˆåˆŠ 348 ï¼ˆ3ï¼‰ï¼š1038â€“1046ã€‚doiï¼š10.1111/j.1365-2966.2004.07429.x.http://mnras.oxfordjournals.org/content/348/3/1038.abstractã€‚"
        }
    },
    {
        "translation": {
            "en": "The weights in the trained model are shown in the following table.",
            "zh": "è®­ç»ƒæ¨¡å‹ä¸­çš„æƒé‡å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "5.6â€…â€…â€…The decision boundary using majority vote of the nearest 3 and 5 instances.",
            "zh": "5.6 ä½¿ç”¨æœ€æ¥è¿‘çš„ 3 ä¸ªå’Œ 5 ä¸ªå®ä¾‹çš„å¤šæ•°ç¥¨çš„å†³ç­–è¾¹ç•Œã€‚"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes model returns a MAP prediction where the posterior probabilities for the levels of the target feature are computed under the assumption of conditional independence between the descriptive features in an instance given a target feature level. More formally, the naive Bayes model is defined as",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹è¿”å›ä¸€ä¸ª MAP é¢„æµ‹ï¼Œå…¶ä¸­ç›®æ ‡ç‰¹å¾æ°´å¹³çš„åéªŒæ¦‚ç‡æ˜¯åœ¨ç»™å®šç›®æ ‡ç‰¹å¾æ°´å¹³çš„å®ä¾‹ä¸­æè¿°æ€§ç‰¹å¾ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§çš„å‡è®¾ä¸‹è®¡ç®—çš„ã€‚æ›´æ­£å¼åœ°è¯´ï¼Œæœ´ç´ è´å¶æ–¯æ¨¡å‹å®šä¹‰ä¸º"
        }
    },
    {
        "translation": {
            "en": "left skew, 59",
            "zh": "å·¦æ­ªï¼Œ59"
        }
    },
    {
        "translation": {
            "en": "It is likely that outliers found using the second approach are valid outliers, so they are a data quality issue due to valid data. Some machine learning techniques do not perform well in the presence of outliers, so we should note these in the data quality plan for possible handling later in the project.",
            "zh": "ä½¿ç”¨ç¬¬äºŒç§æ–¹æ³•æ‰¾åˆ°çš„å¼‚å¸¸å€¼å¾ˆå¯èƒ½æ˜¯æœ‰æ•ˆçš„å¼‚å¸¸å€¼ï¼Œå› æ­¤ç”±äºæ•°æ®æœ‰æ•ˆï¼Œå®ƒä»¬å­˜åœ¨æ•°æ®è´¨é‡é—®é¢˜ã€‚æŸäº›æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨å­˜åœ¨å¼‚å¸¸å€¼çš„æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥åœ¨æ•°æ®è´¨é‡è®¡åˆ’ä¸­æ³¨æ˜è¿™äº›æŠ€æœ¯ï¼Œä»¥ä¾¿åœ¨é¡¹ç›®åæœŸè¿›è¡Œå¤„ç†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A national revenue commission performs audits on public companies to find and fine tax defaulters.",
            "zh": "å›½å®¶ç¨æ”¶å§”å‘˜ä¼šå¯¹ä¸Šå¸‚å…¬å¸è¿›è¡Œå®¡è®¡ï¼Œä»¥å‘ç°å’Œç½šæ¬¾æ‹–æ¬ ç¨æ¬¾çš„äººã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2â€ƒFundamentals",
            "zh": "8.2 åŸºç¡€çŸ¥è¯†"
        }
    },
    {
        "translation": {
            "en": "Consequently, we can still use the gradient descent process to train them.",
            "zh": "å› æ­¤ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹æ¥è®­ç»ƒå®ƒä»¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "Differentiation is the set of techniques from calculus (the branch of mathematics that deals with how things change) that allows us to calculate derivatives.",
            "zh": "å¾®åˆ†æ˜¯å¾®ç§¯åˆ†ï¼ˆå¤„ç†äº‹ç‰©å¦‚ä½•å˜åŒ–çš„æ•°å­¦åˆ†æ”¯ï¼‰çš„ä¸€ç»„æŠ€æœ¯ï¼Œå…è®¸æˆ‘ä»¬è®¡ç®—å¯¼æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross had decided, again in consultation with the business, that a simple classification accuracy rate was the most appropriate evaluation measure for this task.",
            "zh": "Ross å†æ¬¡ä¸ä¸šåŠ¡éƒ¨é—¨åå•†åå†³å®šï¼Œç®€å•çš„åˆ†ç±»å‡†ç¡®ç‡æ˜¯è¿™é¡¹ä»»åŠ¡æœ€åˆé€‚çš„è¯„ä¼°æªæ–½ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason why depth is important is that by introducing multiple layers into a network, the network is able to learn a hierarchy of features with later layers in the network building on the features that previous layers have learned to extract from the raw input.",
            "zh": "æ·±åº¦ä¹‹æ‰€ä»¥é‡è¦ï¼Œæ˜¯å› ä¸ºé€šè¿‡åœ¨ç½‘ç»œä¸­å¼•å…¥å¤šä¸ªå±‚ï¼Œç½‘ç»œèƒ½å¤Ÿå­¦ä¹ ç‰¹å¾çš„å±‚æ¬¡ç»“æ„ï¼Œç½‘ç»œä¸­çš„åç»­å±‚å»ºç«‹åœ¨å‰å‡ å±‚å·²ç»å­¦ä¼šä»åŸå§‹è¾“å…¥ä¸­æå–çš„ç‰¹å¾ä¹‹ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "This figure highlights the calculation of the weighted sum at each neuron (e.g., z3 represents the weighted sum calculation at Neuron 3), and the activations for each neuron (e.g., a3 represents the activation generated by Neuron 3).",
            "zh": "è¯¥å›¾çªå‡ºæ˜¾ç¤ºäº†æ¯ä¸ªç¥ç»å…ƒçš„åŠ æƒå’Œçš„è®¡ç®—ï¼ˆä¾‹å¦‚ï¼Œz3 è¡¨ç¤ºç¥ç»å…ƒ 3 å¤„çš„åŠ æƒå’Œè®¡ç®—ï¼‰ï¼Œä»¥åŠæ¯ä¸ªç¥ç»å…ƒçš„æ¿€æ´»ï¼ˆä¾‹å¦‚ï¼Œa3 è¡¨ç¤ºç¥ç»å…ƒ 3 äº§ç”Ÿçš„æ¿€æ´»ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "To find the ideal subset of descriptive features to use to train a model, we could attempt to build a model using every possible subset, evaluate the performance of all these models, and select the feature subset that leads to the best model.",
            "zh": "ä¸ºäº†æ‰¾åˆ°ç”¨äºè®­ç»ƒæ¨¡å‹çš„æè¿°æ€§ç‰¹å¾çš„ç†æƒ³å­é›†ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨æ¯ä¸ªå¯èƒ½çš„å­é›†æ„å»ºæ¨¡å‹ï¼Œè¯„ä¼°æ‰€æœ‰è¿™äº›æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶é€‰æ‹©å¯¼è‡´æœ€ä½³æ¨¡å‹çš„ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "Be aware, however, that if new descriptive features were added to the dataset, then the number of probabilities required would grow by |domain of target|Ã—|domain of new feature|, and, furthermore, if an extra value were added to the domain of the target, then the number of probabilities would grow exponentially.",
            "zh": "ä½†æ˜¯è¯·æ³¨æ„ï¼Œå¦‚æœå°†æ–°çš„æè¿°æ€§ç‰¹å¾æ·»åŠ åˆ°æ•°æ®é›†ä¸­ï¼Œåˆ™æ‰€éœ€çš„æ¦‚ç‡æ•°å°†æŒ‰ |target åŸŸ|Ã—|æ–°ç‰¹å¾åŸŸ|å¢é•¿ï¼Œæ­¤å¤–ï¼Œå¦‚æœå°†é¢å¤–çš„å€¼æ·»åŠ åˆ°ç›®æ ‡åŸŸä¸­ï¼Œåˆ™æ¦‚ç‡æ•°å°†å‘ˆæŒ‡æ•°å¢é•¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "The Î´s for the output neurons are then shared back to the neurons in the last hidden layer.",
            "zh": "ç„¶åï¼Œè¾“å‡ºç¥ç»å…ƒçš„ Î´ è¢«å…±äº«å›æœ€åä¸€ä¸ªéšè—å±‚ä¸­çš„ç¥ç»å…ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Post-pruning using an error rate criterion is probably the most popular way to prune decision trees.24 One of the advantages of pruning decision trees is that it keeps trees smaller, which in turn makes them easier to interpret.",
            "zh": "24 ä¿®å‰ªå†³ç­–æ ‘çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯å®ƒä½¿æ ‘æ›´å°ï¼Œè¿™åè¿‡æ¥åˆä½¿å®ƒä»¬æ›´æ˜“äºè§£é‡Šã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4â€ƒExtensions and Variations",
            "zh": "10.4 æ‰©å±•å’Œå˜ä½“"
        }
    },
    {
        "translation": {
            "en": "Decision tree models are ideal for these scenarios.",
            "zh": "å†³ç­–æ ‘æ¨¡å‹æ˜¯è¿™äº›åœºæ™¯çš„ç†æƒ³é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The basic process is the same as for categorical targets.",
            "zh": "åŸºæœ¬è¿‡ç¨‹ä¸åˆ†ç±»ç›®æ ‡ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "hidden features, 762",
            "zh": "éšè—åŠŸèƒ½ï¼Œ 762"
        }
    },
    {
        "translation": {
            "en": "Jurafsky, Daniel, and James H. Martin. 2008. Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition, 2nd ed. Prentice Hall.",
            "zh": "Jurafskyã€Daniel å’Œ James H. Martinã€‚2008. è¯­éŸ³å’Œè¯­è¨€å¤„ç†ï¼šè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—è¯­è¨€å­¦å’Œè¯­éŸ³è¯†åˆ«ç®€ä»‹ï¼Œç¬¬ 2 ç‰ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "0.54",
            "zh": "0.54"
        }
    },
    {
        "translation": {
            "en": "decisions, 3",
            "zh": "å†³å®šï¼Œ 3"
        }
    },
    {
        "translation": {
            "en": "This is why the indices on weights in Figure 8.4[390] were reversed: if we store all the weights for each neuron in a layer in a row in the weight matrix for the layer, then the weights are in the correct position when the weight matrix is multiplied by a column vector of activations from the previous layer.",
            "zh": "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå›¾8.4[390]ä¸­çš„æƒé‡æŒ‡æ•°è¢«é¢ å€’çš„åŸå› ï¼šå¦‚æœæˆ‘ä»¬å°†æ¯ä¸ªç¥ç»å…ƒçš„æ‰€æœ‰æƒé‡è¿ç»­å­˜å‚¨åœ¨è¯¥å±‚çš„æƒé‡çŸ©é˜µä¸­ï¼Œé‚£ä¹ˆå½“æƒé‡çŸ©é˜µä¹˜ä»¥æ¥è‡ªå‰ä¸€å±‚çš„æ¿€æ´»åˆ—å‘é‡æ—¶ï¼Œæƒé‡å¤„äºæ­£ç¡®çš„ä½ç½®ã€‚"
        }
    },
    {
        "translation": {
            "en": "An extended version of this dataset was used to build a model that can determine the type of a customer based on a few weeks of shopping behavior data.",
            "zh": "è¯¥æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ç”¨äºæ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®å‡ å‘¨çš„è´­ç‰©è¡Œä¸ºæ•°æ®ç¡®å®šå®¢æˆ·ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We take a dataset for which we know the predictions that we expect the model to make, referred to as a test set, present the instances in this dataset to a trained model, and record the predictions that the model makes.",
            "zh": "æˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬æœŸæœ›æ¨¡å‹åšå‡ºçš„é¢„æµ‹çš„æ•°æ®é›†ï¼Œç§°ä¸ºæµ‹è¯•é›†ï¼Œå°†æ­¤æ•°æ®é›†ä¸­çš„å®ä¾‹å‘ˆç°ç»™ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶è®°å½•æ¨¡å‹åšå‡ºçš„é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) A surface showing the value of Equation (7.23)[339] for all values of RPM and VIBRATION, with the decision boundary given in Equation (7.23)[339] highlighted; and (b) the same surface linearly thresholded at zero to operate as a predictor.",
            "zh": "ï¼ˆaï¼‰ æ˜¾ç¤ºæ‰€æœ‰RPMå’ŒVIBRATIONå€¼çš„ç­‰å¼ï¼ˆ7.23ï¼‰[339]å€¼çš„æ›²é¢ï¼Œå¹¶çªå‡ºæ˜¾ç¤ºç­‰å¼ï¼ˆ7.23ï¼‰[339]ä¸­ç»™å‡ºçš„å†³ç­–è¾¹ç•Œ;ï¼ˆbï¼‰åŒä¸€æ›²é¢çº¿æ€§é˜ˆå€¼ä¸ºé›¶ï¼Œå¯ä½œä¸ºé¢„æµ‹å˜é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ï‡2 statistic, 583",
            "zh": "Ï‡2 ç»Ÿè®¡é‡ï¼Œ583"
        }
    },
    {
        "translation": {
            "en": "There is no hard and fast rule for deciding on interval size.",
            "zh": "å†³å®šé—´éš”å¤§å°æ²¡æœ‰ç¡¬æ€§è§„å®šã€‚"
        }
    },
    {
        "translation": {
            "en": "Intuitively, adding more descriptive features to a dataset provides more information about each instance and should result in more accurate predictive models.",
            "zh": "ç›´è§‚åœ°è¯´ï¼Œå‘æ•°æ®é›†æ·»åŠ æ›´å¤šæè¿°æ€§ç‰¹å¾å¯æä¾›æœ‰å…³æ¯ä¸ªå®ä¾‹çš„æ›´å¤šä¿¡æ¯ï¼Œå¹¶åº”ç”Ÿæˆæ›´å‡†ç¡®çš„é¢„æµ‹æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The differences between the three box plots in each plot gives an indication of the likely predictiveness of each feature.",
            "zh": "æ¯ä¸ªå›¾ä¸­ä¸‰ä¸ªç®±å½¢å›¾ä¹‹é—´çš„å·®å¼‚è¡¨æ˜äº†æ¯ä¸ªç‰¹å¾çš„å¯èƒ½é¢„æµ‹æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "Take surfing, for example.",
            "zh": "ä»¥å†²æµªä¸ºä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equal-frequency binning first sorts the continuous feature values into ascending order and then places an equal number of instances into each bin, starting with bin 1.",
            "zh": "ç­‰é¢‘åˆ†ç®±é¦–å…ˆå°†è¿ç»­ç‰¹å¾å€¼æŒ‰å‡åºæ’åºï¼Œç„¶åä»ç®± 1 å¼€å§‹å°†ç›¸åŒæ•°é‡çš„å®ä¾‹æ”¾å…¥æ¯ä¸ªç®±ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_I_Z",
            "zh": "DEREDDIFF_I_Z"
        }
    },
    {
        "translation": {
            "en": "second order polynomial function, 352, 766",
            "zh": "äºŒé˜¶å¤šé¡¹å¼å‡½æ•°ï¼Œ 352ï¼Œ 766"
        }
    },
    {
        "translation": {
            "en": "A retail supermarket chain has built a prediction model that recognizes the household that a customer comes from as being one of single, business, or family.",
            "zh": "ä¸€å®¶é›¶å”®è¿é”è¶…å¸‚å»ºç«‹äº†ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å°†å®¢æˆ·æ¥è‡ªçš„å®¶åº­è¯†åˆ«ä¸ºå•èº«ã€ä¼ä¸šæˆ–å®¶åº­ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "When weights are initialized in this way, we can control the initial scale of the weights by controlling the variance of the normal distribution.",
            "zh": "å½“ä»¥è¿™ç§æ–¹å¼åˆå§‹åŒ–æƒé‡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ§åˆ¶æ­£æ€åˆ†å¸ƒçš„æ–¹å·®æ¥æ§åˆ¶æƒé‡çš„åˆå§‹å°ºåº¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "In this case the task was to categorize galaxies according to morphology, and therefore galaxy made sense as the prediction subject.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»»åŠ¡æ˜¯æ ¹æ®å½¢æ€å¯¹æ˜Ÿç³»è¿›è¡Œåˆ†ç±»ï¼Œå› æ­¤æ˜Ÿç³»ä½œä¸ºé¢„æµ‹å¯¹è±¡æ˜¯æœ‰æ„ä¹‰çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4â€…â€…â€…Sample descriptive feature data illustrating numeric, binary, ordinal, interval, categorical, and textual types.",
            "zh": "2.4 è¯´æ˜æ•°å­—ã€äºŒè¿›åˆ¶ã€åºæ•°ã€åŒºé—´ã€åˆ†ç±»å’Œæ–‡æœ¬ç±»å‹çš„ç¤ºä¾‹æè¿°æ€§ç‰¹å¾æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "F score, 549",
            "zh": "F åˆ†æ•°ï¼Œ549"
        }
    },
    {
        "translation": {
            "en": "In other cases, however, a categorical feature will have been developed to use numbers to indicate categories and might be mistakenly identified as a continuous feature in a data quality report.",
            "zh": "ä½†æ˜¯ï¼Œåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå°†å¼€å‘åˆ†ç±»ç‰¹å¾ä»¥ä½¿ç”¨æ•°å­—æ¥æŒ‡ç¤ºç±»åˆ«ï¼Œå¹¶ä¸”å¯èƒ½ä¼šè¢«é”™è¯¯åœ°è¯†åˆ«ä¸ºæ•°æ®è´¨é‡æŠ¥å‘Šä¸­çš„è¿ç»­ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ross had AT generate a second data sample (which did not overlap with the sample taken previously) that was not stratified according to the target feature values. The confusion matrix illustrating the performance of the prediction model on this test set is shown in Table 12.4[700].",
            "zh": "Ross è®© AT ç”Ÿæˆç¬¬äºŒä¸ªæ•°æ®æ ·æœ¬ï¼ˆä¸ä¹‹å‰é‡‡é›†çš„æ ·æœ¬ä¸é‡å ï¼‰ï¼Œè¯¥æ ·æœ¬æœªæ ¹æ®ç›®æ ‡ç‰¹å¾å€¼è¿›è¡Œåˆ†å±‚ã€‚è¡¨12.4[700]æ˜¾ç¤ºäº†é¢„æµ‹æ¨¡å‹åœ¨è¯¥æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½çš„æ··æ·†çŸ©é˜µã€‚"
        }
    },
    {
        "translation": {
            "en": "The Card.",
            "zh": "å¡ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "delta value, 323",
            "zh": "å¢é‡å€¼ï¼Œ323"
        }
    },
    {
        "translation": {
            "en": "In these scenarios, this approach to ongoing model validation simply doesnâ€™t work.",
            "zh": "åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè¿™ç§æŒç»­æ¨¡å‹éªŒè¯çš„æ–¹æ³•æ ¹æœ¬ä¸èµ·ä½œç”¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.12[153] illustrates the computation of the weighted variance that results from partitioning the data by SEASON and WORK DAY. It is evident from Table 4.12[153] that partitioning the data using SEASON results in a lower weighted variance than partitioning by WORK DAY. This tells us that splitting by SEASON results in a better clustering of the target data than splitting by WORK DAY. Figure 4.16[153] illustrates the state of the decision tree after the root node has been created using SEASON.",
            "zh": "è¡¨ 4.12[153] è¯´æ˜äº†æŒ‰ SEASON å’Œ WORK DAY å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºæ‰€å¾—çš„åŠ æƒæ–¹å·®çš„è®¡ç®—æ–¹æ³•ã€‚ä»è¡¨4.12[153]ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œä½¿ç”¨SEASONå¯¹æ•°æ®è¿›è¡Œåˆ†åŒºæ¯”æŒ‰WORK DAYè¿›è¡Œåˆ†åŒºçš„åŠ æƒæ–¹å·®æ›´ä½ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬ï¼ŒæŒ‰ SEASON æ‹†åˆ†æ¯”æŒ‰ WORK DAY æ‹†åˆ†å¯ä»¥æ›´å¥½åœ°èšç±»ç›®æ ‡æ•°æ®ã€‚å›¾ 4.16[153] è¯´æ˜äº†ä½¿ç”¨ SEASON åˆ›å»ºæ ¹èŠ‚ç‚¹åå†³ç­–æ ‘çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 13.6",
            "zh": "è¡¨ 13.6"
        }
    },
    {
        "translation": {
            "en": "This distance is 0.576, which is the K-S statistic for this example.",
            "zh": "æ­¤è·ç¦»ä¸º 0.576ï¼Œè¿™æ˜¯æ­¤ç¤ºä¾‹çš„ K-S ç»Ÿè®¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.8[138] shows the state of the tree after the dataset is split using ELEVATION.",
            "zh": "å›¾ 4.8[138] æ˜¾ç¤ºäº†ä½¿ç”¨ ELEVATION æ‹†åˆ†æ•°æ®é›†åçš„æ ‘çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics models are often used as tools for process quality control and fault detection.",
            "zh": "é¢„æµ‹æ•°æ®åˆ†ææ¨¡å‹é€šå¸¸ç”¨ä½œè¿‡ç¨‹è´¨é‡æ§åˆ¶å’Œæ•…éšœæ£€æµ‹çš„å·¥å…·ã€‚"
        }
    },
    {
        "translation": {
            "en": "This rewriting shows that (1) the backpropagation algorithm is in fact an implementation of the chain rule from calculus and the product used to calculate the Î´ terms follows the chain rule; and (2) that we can calculate âˆ‚â„°/âˆ‚wi,k (the term we need to update a weight wi,k) by multiplying the Î´ for a neuron i by the rate of change of the weighted sum calculation for neuron i with respect to changes in the weight wi,k.",
            "zh": "è¿™ç§æ”¹å†™è¡¨æ˜ï¼šï¼ˆ1ï¼‰åå‘ä¼ æ’­ç®—æ³•å®é™…ä¸Šæ˜¯å¾®ç§¯åˆ†é“¾å¼æ³•åˆ™çš„å®ç°ï¼Œç”¨äºè®¡ç®—Î´é¡¹çš„ä¹˜ç§¯éµå¾ªé“¾å¼æ³•åˆ™;ï¼ˆ2ï¼‰æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†ç¥ç»å…ƒiçš„Î´ä¹˜ä»¥ç¥ç»å…ƒiçš„åŠ æƒå’Œè®¡ç®—ç›¸å¯¹äºæƒé‡wiï¼Œkçš„å˜åŒ–ç‡æ¥è®¡ç®—âˆ‚E/âˆ‚wiï¼Œkï¼ˆæˆ‘ä»¬éœ€è¦æ›´æ–°æƒé‡wiï¼Œkçš„é¡¹ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the deeper the network becomes, the slower the earlier layers learn (because the learning signal, the error gradient, attenuates as it is backpropagated through the layers).",
            "zh": "æ­¤å¤–ï¼Œç½‘ç»œè¶Šæ·±ï¼Œæ—©æœŸå±‚çš„å­¦ä¹ é€Ÿåº¦å°±è¶Šæ…¢ï¼ˆå› ä¸ºå­¦ä¹ ä¿¡å·ï¼Œå³è¯¯å·®æ¢¯åº¦ï¼Œåœ¨é€šè¿‡å±‚çš„åå‘ä¼ æ’­æ—¶ä¼šè¡°å‡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "(a) Given this context, calculate .",
            "zh": "ï¼ˆaï¼‰ é‰´äºæ­¤ä¸Šä¸‹æ–‡ï¼Œè®¡ç®— ."
        }
    },
    {
        "translation": {
            "en": "In terms of rows in a dataset, this computation is simply the number of rows where the set of assignments listed in the joint event holds divided by the total number of rows in the dataset.",
            "zh": "å°±æ•°æ®é›†ä¸­çš„è¡Œæ•°è€Œè¨€ï¼Œæ­¤è®¡ç®—åªæ˜¯å°†è”åˆäº‹ä»¶ä¸­åˆ—å‡ºçš„åˆ†é…é›†æ‰€åœ¨çš„è¡Œæ•°é™¤ä»¥æ•°æ®é›†ä¸­çš„æ€»è¡Œæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "The ACCOMMODATION feature refers to the applicantâ€™s current accommodation, and the levels are own (the applicant owns their accommodation), rent (the applicant rents their accommodation), and free (the applicant has free accommodation).",
            "zh": "ä½å®¿åŠŸèƒ½æ˜¯æŒ‡ç”³è¯·äººå½“å‰çš„ä½å®¿ï¼Œçº§åˆ«æ˜¯è‡ªæœ‰çš„ï¼ˆç”³è¯·äººæ‹¥æœ‰è‡ªå·±çš„ä½å®¿ï¼‰ã€ç§Ÿé‡‘ï¼ˆç”³è¯·äººç§Ÿç”¨ä»–ä»¬çš„ä½å®¿ï¼‰å’Œå…è´¹ï¼ˆç”³è¯·äººæœ‰å…è´¹ä½å®¿ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A pruned decision tree built for the AT churn prediction problem. Gray leaf nodes indicate a churn prediction, and clear leaf nodes indicate a non-churn prediction. For space reasons, we show only the features tested at the top-level nodes.",
            "zh": "é’ˆå¯¹ AT æµå¤±é¢„æµ‹é—®é¢˜æ„å»ºçš„ä¿®å‰ªå†³ç­–æ ‘ã€‚ç°å¶èŠ‚ç‚¹è¡¨ç¤ºæµå¤±é¢„æµ‹ï¼Œæ¸…é™¤å¶èŠ‚ç‚¹è¡¨ç¤ºéæµå¤±é¢„æµ‹ã€‚ç”±äºç¯‡å¹…åŸå› ï¼Œæˆ‘ä»¬åªæ˜¾ç¤ºåœ¨é¡¶çº§èŠ‚ç‚¹ä¸Šæµ‹è¯•çš„åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Sokal-Michener index, 214, 231",
            "zh": "Sokal-MicheneræŒ‡æ•°ï¼Œ214,231"
        }
    },
    {
        "translation": {
            "en": "rectified linear activation function, 386, 625, 626, 674",
            "zh": "æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œ 386ï¼Œ 625ï¼Œ 626ï¼Œ 674"
        }
    },
    {
        "translation": {
            "en": "Figure 8.26[462] illustrates the internal dynamics of the network in Figure 8.22[450] during the first training iteration when ReLUs are used and the weights for neurons in HL1 are sampled using Xavier initialization and the weights for the neurons in the later layers are sampled using He initialization.",
            "zh": "å›¾ 8.26[462] è¯´æ˜äº†å›¾ 8.22[450] ä¸­ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ï¼Œå½“ä½¿ç”¨ ReLU æ—¶ï¼ŒHL1 ä¸­ç¥ç»å…ƒçš„æƒé‡ä½¿ç”¨ Xavier åˆå§‹åŒ–è¿›è¡Œé‡‡æ ·ï¼Œåé¢å±‚ä¸­ç¥ç»å…ƒçš„æƒé‡ä½¿ç”¨ He åˆå§‹åŒ–è¿›è¡Œé‡‡æ ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "When predicting a continuous target, every error in the calculation of a probability is reflected in reduced model performance.",
            "zh": "åœ¨é¢„æµ‹è¿ç»­ç›®æ ‡æ—¶ï¼Œæ¦‚ç‡è®¡ç®—ä¸­çš„æ¯ä¸ªé”™è¯¯éƒ½ä¼šåæ˜ åœ¨æ¨¡å‹æ€§èƒ½é™ä½ä¸Šã€‚"
        }
    },
    {
        "translation": {
            "en": "2.4.5â€…â€…â€…Implementing Features",
            "zh": "2.4.5 å®ç°åŠŸèƒ½"
        }
    },
    {
        "translation": {
            "en": "In order to allow for the fact that some of the differences between values and the mean will be positive and some will be negative, we square each difference.1",
            "zh": "ä¸ºäº†è€ƒè™‘åˆ°å€¼å’Œå‡å€¼ä¹‹é—´çš„ä¸€äº›å·®å¼‚æ˜¯æ­£çš„ï¼Œè€Œå¦ä¸€äº›æ˜¯è´Ÿçš„ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªå·®å¼‚è¿›è¡Œå¹³æ–¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "ReLU, 386",
            "zh": "é²ï¼Œ386"
        }
    },
    {
        "translation": {
            "en": "5.7â€ƒEpilogue",
            "zh": "5.7 ç»“è¯­"
        }
    },
    {
        "translation": {
            "en": "By adding an explicit reference to action at+1, we can arrive at a very elegant recursive definition of the action-value function.",
            "zh": "é€šè¿‡æ·»åŠ å¯¹ action at+1 çš„æ˜¾å¼å¼•ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡º action-value å‡½æ•°çš„éå¸¸ä¼˜é›…çš„é€’å½’å®šä¹‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "10.4.5â€ƒAgglomerative Hierarchical Clustering",
            "zh": "10.4.5 é›†èšåˆ†å±‚èšç±»"
        }
    },
    {
        "translation": {
            "en": "Every time we partition the data, we add a node with two branches to the k-d tree. The node indexes the instance that had the median value of the feature, the left branch holds all the instances that had values less than the median, and the right branch holds all the instances that had values greater than the median. The recursive partitioning then grows each of these branches in a depth-first manner.",
            "zh": "æ¯æ¬¡å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºæ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šå‘ k-d æ ‘æ·»åŠ ä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªåˆ†æ”¯çš„èŠ‚ç‚¹ã€‚èŠ‚ç‚¹ç´¢å¼•å…·æœ‰ç‰¹å¾ä¸­ä½æ•°å€¼çš„å®ä¾‹ï¼Œå·¦ä¾§åˆ†æ”¯ä¿å­˜å€¼å°äºä¸­ä½æ•°çš„æ‰€æœ‰å®ä¾‹ï¼Œå³ä¾§åˆ†æ”¯ä¿å­˜å€¼å¤§äºä¸­ä½æ•°çš„æ‰€æœ‰å®ä¾‹ã€‚ç„¶åï¼Œé€’å½’åˆ†åŒºä»¥æ·±åº¦ä¼˜å…ˆçš„æ–¹å¼å¢é•¿è¿™äº›åˆ†æ”¯ä¸­çš„æ¯ä¸€ä¸ªã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7",
            "zh": "å›¾ 3.7"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15",
            "zh": "å›¾ 4.15"
        }
    },
    {
        "translation": {
            "en": "34. The conductivity of water is affected by inorganic dissolved solids and organic compounds, such as oil. Consequently, water conductivity is a useful measure of water purity.",
            "zh": "34.æ°´çš„ç”µå¯¼ç‡å—æ— æœºæº¶è§£å›ºä½“å’Œæœ‰æœºåŒ–åˆç‰©ï¼ˆå¦‚æ²¹ï¼‰çš„å½±å“ã€‚å› æ­¤ï¼Œæ°´çš„ç”µå¯¼ç‡æ˜¯è¡¡é‡æ°´çº¯åº¦çš„æœ‰ç”¨æŒ‡æ ‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3. This data is taken from the collection at Real Clear Politics: www.realclearpolitics.com/epolls/2012/president/us/general_election_romney_vs_obama-1171.html.",
            "zh": "3. æ­¤æ•°æ®å–è‡ª Real Clear Politicsï¼š www.realclearpolitics.com/epolls/2012/president/us/general_election_romney_vs_obama-1171.html çš„é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The most popular and straightforward approach to feature selection is to rank and prune.",
            "zh": "æœ€æµè¡Œå’Œæœ€ç›´æ¥çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•æ˜¯æ’åå’Œä¿®å‰ªã€‚"
        }
    },
    {
        "translation": {
            "en": "If the hiker looks at the slope of the ground at her feet, she will notice that in some directions, the ground slopes up, and in other directions, the ground slopes down.",
            "zh": "å¦‚æœå¾’æ­¥æ—…è¡Œè€…è§‚å¯Ÿå¥¹è„šä¸‹çš„åœ°é¢å¡åº¦ï¼Œå¥¹ä¼šæ³¨æ„åˆ°åœ¨æŸäº›æ–¹å‘ä¸Šï¼Œåœ°é¢å‘ä¸Šå€¾æ–œï¼Œè€Œåœ¨å…¶ä»–æ–¹å‘ä¸Šï¼Œåœ°é¢å‘ä¸‹å€¾æ–œã€‚"
        }
    },
    {
        "translation": {
            "en": "Set Size",
            "zh": "æœºèº«å°ºå¯¸"
        }
    },
    {
        "translation": {
            "en": "Svolba, Gerhard. 2007. Data preparation for analytics using SAS. SAS Institute.",
            "zh": "æ–¯æ²ƒå°”å·´ï¼Œæ ¼å“ˆå¾·ã€‚2007. ä½¿ç”¨ SAS è¿›è¡Œåˆ†æçš„æ•°æ®å‡†å¤‡ã€‚SASç ”ç©¶æ‰€ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, Table 9.11[557] shows the underlying scores that the predictions shown in Table 9.1[537] were based on, assuming a threshold of 0.5â€”that is, instances with a prediction score greater than or equal to 0.5 were given predictions of the spam (positive) level, and those with prediction scores less than 0.5 were given predictions of the ham (negative) level.",
            "zh": "ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œè¡¨ 9.11[557] æ˜¾ç¤ºäº†è¡¨ 9.1[537] ä¸­æ‰€ç¤ºçš„é¢„æµ‹æ‰€åŸºäºçš„åŸºæœ¬åˆ†æ•°ï¼Œå‡è®¾é˜ˆå€¼ä¸º 0.5ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œé¢„æµ‹åˆ†æ•°å¤§äºæˆ–ç­‰äº 0.5 çš„å®ä¾‹è¢«é¢„æµ‹ä¸ºåƒåœ¾é‚®ä»¶ï¼ˆé˜³æ€§ï¼‰çº§åˆ«ï¼Œé¢„æµ‹åˆ†æ•°å°äº 0.5 çš„å®ä¾‹è¢«é¢„æµ‹ä¸º hamï¼ˆè´Ÿï¼‰æ°´å¹³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.1",
            "zh": "å›¾ 4.1"
        }
    },
    {
        "translation": {
            "en": "Finally, in Lines 12 and 13, the algorithm grows a branch in the tree for each of the values in the domain of d[best] by recursively calling itself for each of the partitions created at Line 10.",
            "zh": "æœ€åï¼Œåœ¨ç¬¬ 12 è¡Œå’Œç¬¬ 13 è¡Œä¸­ï¼Œè¯¥ç®—æ³•é€šè¿‡é€’å½’åœ°ä¸ºç¬¬ 10 è¡Œåˆ›å»ºçš„æ¯ä¸ªåˆ†åŒºè°ƒç”¨è‡ªèº«ï¼Œä¸º d[best] åŸŸä¸­çš„æ¯ä¸ªå€¼åœ¨æ ‘ä¸­ç”Ÿé•¿ä¸€ä¸ªåˆ†æ”¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "0.5432",
            "zh": "0.5432"
        }
    },
    {
        "translation": {
            "en": "8.37â€…â€…â€…Schematic of the simple recurrent neural architecture.",
            "zh": "8.37 ç®€å•é€’å½’ç¥ç»æ¶æ„ç¤ºæ„å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Although this differential between the target levels in the dataset may not seem substantial, it does have an impact as k increases.",
            "zh": "å°½ç®¡æ•°æ®é›†ä¸­ç›®æ ‡æ°´å¹³ä¹‹é—´çš„è¿™ç§å·®å¼‚å¯èƒ½çœ‹èµ·æ¥å¹¶ä¸å¤§ï¼Œä½†éšç€ k çš„å¢åŠ ï¼Œå®ƒç¡®å®ä¼šäº§ç”Ÿå½±å“ã€‚"
        }
    },
    {
        "translation": {
            "en": "It was likely that a machine learning model that looked at multiple features would do a better job of identifying customers likely to churn.",
            "zh": "ä¸€ä¸ªç€çœ¼äºå¤šä¸ªç‰¹å¾çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½ä¼šæ›´å¥½åœ°è¯†åˆ«å¯èƒ½æµå¤±çš„å®¢æˆ·ã€‚"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm proceeds by adding more and more models where each model is trained to improve the predictions of the previous ones. Equation (4.16)[164] can be generalized to capture this",
            "zh": "æ¢¯åº¦æå‡ç®—æ³•é€šè¿‡æ·»åŠ è¶Šæ¥è¶Šå¤šçš„æ¨¡å‹æ¥ç»§ç»­ï¼Œå…¶ä¸­æ¯ä¸ªæ¨¡å‹éƒ½ç»è¿‡è®­ç»ƒä»¥æ”¹è¿›å¯¹å‰ä¸€ä¸ªæ¨¡å‹çš„é¢„æµ‹ã€‚æ–¹ç¨‹ï¼ˆ4.16ï¼‰[164]å¯ä»¥æ¨å¹¿åˆ°è¿™ä¸€ç‚¹"
        }
    },
    {
        "translation": {
            "en": "Returning to the email classification example, and assuming again that spam emails are the positive level, precision measures how often the emails marked as spam actually are spam, whereas recall measures how often the spam messages in the test set were actually marked as spam. The precision and recall measures for the email classification data shown in Table 9.1[537] are",
            "zh": "å›åˆ°ç”µå­é‚®ä»¶åˆ†ç±»ç¤ºä¾‹ï¼Œå¹¶å†æ¬¡å‡è®¾åƒåœ¾é‚®ä»¶æ˜¯æ­£æ•°çº§åˆ«ï¼Œç²¾åº¦è¡¡é‡æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶çš„ç”µå­é‚®ä»¶å®é™…ä¸Šæ˜¯åƒåœ¾é‚®ä»¶çš„é¢‘ç‡ï¼Œè€Œå¬å›ç‡è¡¡é‡æµ‹è¯•é›†ä¸­çš„åƒåœ¾é‚®ä»¶å®é™…è¢«æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶çš„é¢‘ç‡ã€‚è¡¨9.1[537]æ‰€ç¤ºçš„ç”µå­é‚®ä»¶åˆ†ç±»æ•°æ®çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡æªæ–½å¦‚ä¸‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "As Î» gets larger, the peak of the distribution (on the left) gets larger, and the drop-off in density gets steeper.",
            "zh": "éšç€Î»å˜å¤§ï¼Œåˆ†å¸ƒçš„å³°å€¼ï¼ˆå·¦ä¾§ï¼‰å˜å¤§ï¼Œå¯†åº¦ä¸‹é™å˜é™¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Analysts need to balance the needs of their applicationâ€”for example, in the mobile phone customer scenario, how many customer groups could the organization usefully make decisions about?â€”with the ability of an algorithm to find meaningful groupings within a given dataset.",
            "zh": "åˆ†æå¸ˆéœ€è¦å¹³è¡¡å…¶åº”ç”¨ç¨‹åºçš„éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç§»åŠ¨ç”µè¯å®¢æˆ·åœºæ™¯ä¸­ï¼Œç»„ç»‡å¯ä»¥æœ‰æ•ˆåœ°åšå‡ºå†³ç­–çš„å®¢æˆ·ç»„æ•°é‡ï¼Ÿï¼‰ä¸ç®—æ³•åœ¨ç»™å®šæ•°æ®é›†ä¸­æŸ¥æ‰¾æœ‰æ„ä¹‰çš„åˆ†ç»„çš„èƒ½åŠ›ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that SUSPICIOUS WORDS, the descriptive feature tested at the root node of the tree in Figure 4.4(b)[122], perfectly splits the data into a pure group of spam emails and a pure group of ham emails.",
            "zh": "è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œåœ¨å›¾4.4ï¼ˆbï¼‰[122]ä¸­æ ‘çš„æ ¹èŠ‚ç‚¹ä¸Šæµ‹è¯•çš„æè¿°æ€§ç‰¹å¾SUSPICIOUS WORDSå®Œç¾åœ°å°†æ•°æ®æ‹†åˆ†ä¸ºä¸€ç»„çº¯åƒåœ¾é‚®ä»¶å’Œä¸€ç»„çº¯ä¸šä½™é‚®ä»¶ã€‚"
        }
    },
    {
        "translation": {
            "en": "Because relative distributions are used, the bars in the second bar plot cover the full range of the space availableâ€”these are often referred to as 100% stacked bar plots.",
            "zh": "ç”±äºä½¿ç”¨äº†ç›¸å¯¹åˆ†å¸ƒï¼Œå› æ­¤ç¬¬äºŒä¸ªæ¡å½¢å›¾ä¸­çš„æ¡å½¢è¦†ç›–äº†å¯ç”¨ç©ºé—´çš„æ•´ä¸ªèŒƒå›´ï¼Œè¿™äº›ç©ºé—´é€šå¸¸ç§°ä¸º 100% å †å æ¡å½¢å›¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 4.3 lists an example dataset from the ecological modeling domain.11 In this example, the prediction task is to classify the type of vegetation that is likely to be growing in areas of land on the sole basis of descriptive features extracted from maps of the areas.",
            "zh": "è¡¨ 4.3 åˆ—å‡ºäº†ç”Ÿæ€å»ºæ¨¡åŸŸä¸­çš„ä¸€ä¸ªç¤ºä¾‹æ•°æ®é›†ã€‚11 åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œé¢„æµ‹ä»»åŠ¡æ˜¯ä»…æ ¹æ®ä»åŒºåŸŸåœ°å›¾ä¸­æå–çš„æè¿°æ€§ç‰¹å¾å¯¹å¯èƒ½åœ¨é™†åœ°åŒºåŸŸä¸­ç”Ÿé•¿çš„æ¤è¢«ç±»å‹è¿›è¡Œåˆ†ç±»ã€‚"
        }
    },
    {
        "translation": {
            "en": "The R2 coefficient is a domain independent measure of model performance that is frequently used for prediction problems with a continuous target. The R2 coefficient compares the performance of a model on a test set with the performance of an imaginary model that always predicts the average values from the test set. The R2 coefficient is calculated as",
            "zh": "R2 ç³»æ•°æ˜¯æ¨¡å‹æ€§èƒ½çš„åŸŸç‹¬ç«‹åº¦é‡ï¼Œç»å¸¸ç”¨äºè¿ç»­ç›®æ ‡çš„é¢„æµ‹é—®é¢˜ã€‚R2 ç³»æ•°å°†æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ä¸å§‹ç»ˆé¢„æµ‹æµ‹è¯•é›†å¹³å‡å€¼çš„è™šæ„æ¨¡å‹çš„æ€§èƒ½è¿›è¡Œæ¯”è¾ƒã€‚R2 ç³»æ•°è®¡ç®—å…¬å¼ä¸º"
        }
    },
    {
        "translation": {
            "en": "Ross then turned his attention to examining the data visualizations of the relationship between each descriptive feature and the target feature.",
            "zh": "ç„¶åï¼ŒRoss å°†æ³¨æ„åŠ›è½¬å‘æ£€æŸ¥æ¯ä¸ªæè¿°æ€§ç‰¹å¾ä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´å…³ç³»çš„æ•°æ®å¯è§†åŒ–ã€‚"
        }
    },
    {
        "translation": {
            "en": "Interested readers are directed to the suggestions for further reading presented in Section 11.6[677], in which these alternatives are discussed.",
            "zh": "æœ‰å…´è¶£çš„è¯»è€…å¯ä»¥å‚è€ƒç¬¬11.6[677]èŠ‚ä¸­æå‡ºçš„è¿›ä¸€æ­¥é˜…è¯»å»ºè®®ï¼Œå…¶ä¸­è®¨è®ºäº†è¿™äº›æ›¿ä»£æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROR90ERR_U/G/R/I/Z",
            "zh": "PETROR90ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Cover, T. M., and J. A. Thomas. 1991. Elements of information theory. Wiley.",
            "zh": "å°é¢ï¼ŒTM å’Œ JA æ‰˜é©¬æ–¯ã€‚1991. ä¿¡æ¯è®ºçš„è¦ç´ .å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.33",
            "zh": "å›¾ 8.33"
        }
    },
    {
        "translation": {
            "en": "13.6â€ƒDeployment",
            "zh": "13.6 éƒ¨ç½²"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification dataset.",
            "zh": "æ¤è¢«åˆ†ç±»æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dataset presented in Table 1.3[9] is referred to as a labeled dataset because it includes values for the target feature.",
            "zh": "è¡¨1.3[9]ä¸­æ˜¾ç¤ºçš„æ•°æ®é›†ç§°ä¸ºæ ‡è®°æ•°æ®é›†ï¼Œå› ä¸ºå®ƒåŒ…å«ç›®æ ‡ç‰¹å¾çš„å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, to calculate a probability using a PDF, we need to first decide on the interval we wish to calculate the probability for, and then calculate the area under the density curve for that interval to give the probability of a value from that interval occurring.",
            "zh": "å› æ­¤ï¼Œè¦ä½¿ç”¨ PDF è®¡ç®—æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆç¡®å®šæˆ‘ä»¬å¸Œæœ›è®¡ç®—æ¦‚ç‡çš„åŒºé—´ï¼Œç„¶åè®¡ç®—è¯¥åŒºé—´çš„å¯†åº¦æ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œä»¥ç»™å‡ºè¯¥åŒºé—´ä¸­æŸä¸ªå€¼å‘ç”Ÿçš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "ratio features, 35",
            "zh": "æ¯”ç‡ç‰¹å¾ï¼Œ35"
        }
    },
    {
        "translation": {
            "en": "2. Statisticians will often refer to false positives as type I errors and false negatives as type II errors. Similarly, false positives are often also referred to as false alarms, true positives as hits, and false negatives as misses.",
            "zh": "2. ç»Ÿè®¡å­¦å®¶é€šå¸¸å°†å‡é˜³æ€§ç§°ä¸º I ç±»é”™è¯¯ï¼Œå°†å‡é˜´æ€§ç§°ä¸º II ç±»é”™è¯¯ã€‚åŒæ ·ï¼Œè¯¯æŠ¥é€šå¸¸ä¹Ÿç§°ä¸ºè¯¯æŠ¥ï¼ŒçœŸé˜³æ€§ç§°ä¸ºå‘½ä¸­ï¼Œè¯¯æŠ¥ç§°ä¸ºæœªå‘½ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Hinton, G. E., S. Osindero, and Y. W. Teh. 2006. A fast learning algorithm for deep belief nets. Neural Computing 18: 1527â€“1554.",
            "zh": "Hintonã€GEã€S. Osindero å’Œ Y. W. Tehã€‚2006. ä¸€ç§ç”¨äºæ·±åº¦ä¿¡å¿µç½‘ç»œçš„å¿«é€Ÿå­¦ä¹ ç®—æ³•.ç¥ç»è®¡ç®— 18ï¼š1527â€“1554ã€‚"
        }
    },
    {
        "translation": {
            "en": "As we did with predictive modeling we can capture the mathematical foundations of these further approaches to machine learning in two key equations: the function minimized by the k-means clustering algorithm (Equation (14.6)[741]) and the action-value function update rule used in Q-learning (Equation (14.7)[741]).",
            "zh": "æ­£å¦‚æˆ‘ä»¬åœ¨é¢„æµ‹å»ºæ¨¡ä¸­æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸¤ä¸ªå…³é”®æ–¹ç¨‹ä¸­æ•è·è¿™äº›æœºå™¨å­¦ä¹ è¿›ä¸€æ­¥æ–¹æ³•çš„æ•°å­¦åŸºç¡€ï¼šé€šè¿‡k-meansèšç±»ç®—æ³•æœ€å°åŒ–çš„å‡½æ•°ï¼ˆæ–¹ç¨‹ï¼ˆ14.6ï¼‰[741]ï¼‰å’ŒQ-learningä¸­ä½¿ç”¨çš„åŠ¨ä½œ-å€¼å‡½æ•°æ›´æ–°è§„åˆ™ï¼ˆæ–¹ç¨‹ï¼ˆ14.7ï¼‰[741]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "We strongly believe that the best way to keep an analytics project focused, and to improve the likelihood of a successful conclusion, is to adopt a structured project lifecycle, such as CRISP-DM, and we recommend its use.",
            "zh": "æˆ‘ä»¬åšä¿¡ï¼Œä¿æŒåˆ†æé¡¹ç›®ä¸“æ³¨å¹¶æé«˜æˆåŠŸç»“è®ºçš„å¯èƒ½æ€§çš„æœ€ä½³æ–¹æ³•æ˜¯é‡‡ç”¨ç»“æ„åŒ–çš„é¡¹ç›®ç”Ÿå‘½å‘¨æœŸï¼Œä¾‹å¦‚ CRISP-DMï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å®ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "Partitioning the dataset based on the value of the target feature and fitting the parameters of a statistical distribution to model the ACCOUNT BALANCE feature in each partition.",
            "zh": "æ ¹æ®ç›®æ ‡ç‰¹å¾çš„å€¼å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºï¼Œå¹¶æ‹Ÿåˆç»Ÿè®¡åˆ†å¸ƒçš„å‚æ•°ï¼Œä»¥å¯¹æ¯ä¸ªåˆ†åŒºä¸­çš„ ACCOUNT BALANCE ç‰¹å¾è¿›è¡Œå»ºæ¨¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "It is worth reflecting for a moment that the agent has learned to navigate this grid world without any knowledge of the overall structure of the environment or indication about what it should do. Rather, the agentâ€”equipped with only knowledge of the states in the world and the actions that it can takeâ€”was able to learn a long-term strategy to complete a somewhat sophisticated task using only the instantaneous rewards that is received for each move that it made.",
            "zh": "å€¼å¾—åæ€çš„æ˜¯ï¼Œæ™ºèƒ½ä½“å·²ç»å­¦ä¼šäº†åœ¨è¿™ä¸ªç½‘æ ¼ä¸–ç•Œä¸­å¯¼èˆªï¼Œè€Œå¯¹ç¯å¢ƒçš„æ•´ä½“ç»“æ„ä¸€æ— æ‰€çŸ¥ï¼Œä¹Ÿä¸çŸ¥é“å®ƒåº”è¯¥åšä»€ä¹ˆã€‚ç›¸åï¼Œæ™ºèƒ½ä½“â€”â€”åªå…·å¤‡å¯¹ä¸–ç•ŒçŠ¶æ€å’Œå®ƒå¯ä»¥é‡‡å–çš„è¡ŒåŠ¨çš„äº†è§£â€”â€”èƒ½å¤Ÿå­¦ä¹ ä¸€ç§é•¿æœŸç­–ç•¥ï¼Œåªä½¿ç”¨å®ƒæ‰€åšçš„æ¯ä¸€æ­¥æ‰€è·å¾—çš„å³æ—¶å¥–åŠ±æ¥å®Œæˆä¸€é¡¹æœ‰ç‚¹å¤æ‚çš„ä»»åŠ¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "These distances are then ranked from lowest to highest to find the nearest neighbor.",
            "zh": "ç„¶åå°†è¿™äº›è·ç¦»ä»ä½åˆ°é«˜è¿›è¡Œæ’åï¼Œä»¥æ‰¾åˆ°æœ€è¿‘çš„é‚»å±…ã€‚"
        }
    },
    {
        "translation": {
            "en": "performance measure, 535, 540",
            "zh": "ç»©æ•ˆè¡¡é‡ï¼Œ 535ï¼Œ 540"
        }
    },
    {
        "translation": {
            "en": "Figure 4.4[122] shows two decision trees that are consistent with the spam dataset.",
            "zh": "å›¾ 4.4[122] æ˜¾ç¤ºäº†ä¸¤ä¸ªä¸åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸€è‡´çš„å†³ç­–æ ‘ã€‚"
        }
    },
    {
        "translation": {
            "en": "where the term Î· explicitly represents a normalization constant. Because Bayesâ€™ Theorem can be calculated in this way, it is sometimes written as",
            "zh": "å…¶ä¸­ï¼Œæœ¯è¯­ Î· æ˜¾å¼è¡¨ç¤ºè§„èŒƒåŒ–å¸¸æ•°ã€‚å› ä¸ºè´å¶æ–¯å®šç†å¯ä»¥è¿™æ ·è®¡ç®—ï¼Œæ‰€ä»¥å®ƒæœ‰æ—¶å†™æˆ"
        }
    },
    {
        "translation": {
            "en": "The variety of derived features that we might wish to use is limitless.",
            "zh": "æˆ‘ä»¬å¯èƒ½å¸Œæœ›ä½¿ç”¨çš„æ´¾ç”ŸåŠŸèƒ½ç§ç±»ç¹å¤šã€‚"
        }
    },
    {
        "translation": {
            "en": "Each of the hidden layer neurons receives both the input vector and a vector containing the information stored in the memory buffer at the same time.",
            "zh": "æ¯ä¸ªéšè—å±‚ç¥ç»å…ƒåŒæ—¶æ¥æ”¶è¾“å…¥å‘é‡å’ŒåŒ…å«å­˜å‚¨åœ¨å†…å­˜ç¼“å†²åŒºä¸­çš„ä¿¡æ¯çš„å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A more systematic approach is to use learning rate decay, which allows the learning rate to start at a large value and then decay over time according to a predefined schedule.",
            "zh": "ä¸€ç§æ›´ç³»ç»Ÿçš„æ–¹æ³•æ˜¯ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ï¼Œå®ƒå…è®¸å­¦ä¹ ç‡ä»å¤§å€¼å¼€å§‹ï¼Œç„¶åæ ¹æ®é¢„å®šä¹‰çš„æ—¶é—´è¡¨éšç€æ—¶é—´çš„æ¨ç§»è€Œè¡°å‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "If we look for an instance in the dataset in Table 6.2[263] that matches all the descriptive feature values in the query, we wonâ€™t find one.",
            "zh": "å¦‚æœæˆ‘ä»¬åœ¨è¡¨ 6.2[263] ä¸­çš„æ•°æ®é›†ä¸­æŸ¥æ‰¾ä¸æŸ¥è¯¢ä¸­æ‰€æœ‰æè¿°æ€§ç‰¹å¾å€¼åŒ¹é…çš„å®ä¾‹ï¼Œæˆ‘ä»¬å°†æ‰¾ä¸åˆ°ä¸€ä¸ªå®ä¾‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see this if we highlight the decision boundary within the feature space.",
            "zh": "å¦‚æœæˆ‘ä»¬çªå‡ºæ˜¾ç¤ºç‰¹å¾ç©ºé—´ä¸­çš„å†³ç­–è¾¹ç•Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Instead, we will simply note that the appropriate choice of generative versus discriminative model is context-dependent, and evaluating a range of different types of models is the safest option.",
            "zh": "ç›¸åï¼Œæˆ‘ä»¬åªä¼šæ³¨æ„åˆ°ï¼Œç”Ÿæˆæ¨¡å‹ä¸åˆ¤åˆ«æ¨¡å‹çš„é€‚å½“é€‰æ‹©å–å†³äºä¸Šä¸‹æ–‡ï¼Œè¯„ä¼°ä¸€ç³»åˆ—ä¸åŒç±»å‹çš„æ¨¡å‹æ˜¯æœ€å®‰å…¨çš„é€‰æ‹©ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.22â€…â€…â€…The number of customers who left the mobile phone network operator each week during the comparative experiment from both the control group (random selection) and the treatment group (model selection).",
            "zh": "9.22 å¯¹ç…§ç»„ï¼ˆéšæœºé€‰æ‹©ï¼‰å’Œæ²»ç–—ç»„ï¼ˆæ¨¡å‹é€‰æ‹©ï¼‰åœ¨æ¯”è¾ƒå®éªŒæœŸé—´æ¯å‘¨ç¦»å¼€ç§»åŠ¨ç”µè¯ç½‘ç»œè¿è¥å•†çš„å®¢æˆ·æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "This assumes that we should expect the clustering to find groups with similar tariff types, an assumption that could be based only on detailed knowledge of the domain.",
            "zh": "è¿™å‡è®¾æˆ‘ä»¬åº”è¯¥æœŸæœ›èšç±»æ‰¾åˆ°å…·æœ‰ç›¸ä¼¼èµ„è´¹ç±»å‹çš„ç»„ï¼Œè¿™ä¸€å‡è®¾åªèƒ½åŸºäºå¯¹è¯¥é¢†åŸŸçš„è¯¦ç»†äº†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of Î± = 0.1, calculate the updated values for each of the weights in the network (w5,4, w5,3, w5,0, w4,2, w4,0, w3,2, w3,0,, w2,1, w2,0,) after the processing of this single training example.",
            "zh": "å‡è®¾å­¦ä¹ ç‡ä¸º Î± = 0.1ï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªæƒé‡ï¼ˆw5,4ã€w5,3ã€w5,0ã€w4,2ã€w4,0ã€w3,2ã€w3,0ã€w2,1ã€w2,0ï¼Œï¼‰çš„æ›´æ–°å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "To further illustrate the difference between arithmetic mean and harmonic mean, Figure 9.8[553] shows the arithmetic mean and the harmonic mean of all combinations of two features A and B that range from 0 to 100.",
            "zh": "ä¸ºäº†è¿›ä¸€æ­¥è¯´æ˜ç®—æœ¯å¹³å‡å€¼å’Œè°å’Œå¹³å‡å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå›¾9.8[553]æ˜¾ç¤ºäº†ä»0åˆ°100çš„ä¸¤ä¸ªç‰¹å¾Aå’ŒBçš„æ‰€æœ‰ç»„åˆçš„ç®—æœ¯å¹³å‡å€¼å’Œè°å’Œå¹³å‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "weight space, 317, 321, 338, 369",
            "zh": "é‡é‡ç©ºé—´ï¼Œ317,321,338,369"
        }
    },
    {
        "translation": {
            "en": "The low cardinality for the NUM.",
            "zh": "NUM çš„ä½åŸºæ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.1â€…â€…â€…A sample test set with model predictions.",
            "zh": "9.1 å…·æœ‰æ¨¡å‹é¢„æµ‹çš„æ ·æœ¬æµ‹è¯•é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "In such instances a model is essentially reduced to guessing predictions.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹åŸºæœ¬ä¸Šè¢«ç®€åŒ–ä¸ºçŒœæµ‹é¢„æµ‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The term âˆ‚â„°/âˆ‚ct describes the vector of error gradients that are backpropagated through this operation.",
            "zh": "æœ¯è¯­ âˆ‚E/âˆ‚ct æè¿°äº†é€šè¿‡æ­¤æ“ä½œåå‘ä¼ æ’­çš„è¯¯å·®æ¢¯åº¦å‘é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Eco, Umberto. 1999. Kant and the platypus. Vintage U.K. Random House.",
            "zh": "ç”Ÿæ€ï¼Œç¿è´æ‰˜ã€‚1999. åº·å¾·ä¸é¸­å˜´å…½.å¤å¤è‹±å›½å…°ç™»ä¹¦å±‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The simplest way to measure the similarity between two instances, a and b, in a dataset is to measure the distance between the instances in a feature space. We can use a distance metric to do this: metric(a,b) is a function that returns the distance between two instances a and b. Mathematically, a metric must conform to the following four criteria:",
            "zh": "æµ‹é‡æ•°æ®é›†ä¸­ä¸¤ä¸ªå®ä¾‹ï¼ˆa å’Œ bï¼‰ä¹‹é—´çš„ç›¸ä¼¼åº¦çš„æœ€ç®€å•æ–¹æ³•æ˜¯æµ‹é‡è¦ç´ ç©ºé—´ä¸­å®ä¾‹ä¹‹é—´çš„è·ç¦»ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è·ç¦»åº¦é‡æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼šmetricï¼ˆaï¼Œbï¼‰ æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒè¿”å›ä¸¤ä¸ªå®ä¾‹ a å’Œ b ä¹‹é—´çš„è·ç¦»ã€‚ä»æ•°å­¦ä¸Šè®²ï¼ŒæŒ‡æ ‡å¿…é¡»ç¬¦åˆä»¥ä¸‹å››ä¸ªæ ‡å‡†ï¼š"
        }
    },
    {
        "translation": {
            "en": "Kuncheva, Ludmila I. 2004. Combining pattern classifiers: Methods and algorithms. Wiley.",
            "zh": "Kunchevaï¼Œ Ludmila I. 2004.ç»„åˆæ¨¡å¼åˆ†ç±»å™¨ï¼šæ–¹æ³•å’Œç®—æ³•ã€‚å¨åˆ©ã€‚"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrices are shown in Table 13.7[723].",
            "zh": "ç”±æ­¤äº§ç”Ÿçš„æ··æ·†çŸ©é˜µå¦‚è¡¨13.7[723]æ‰€ç¤ºã€‚"
        }
    },
    {
        "translation": {
            "en": "Often descriptive features that are likely to be very useful cannot be implemented due to the unavailability of data.",
            "zh": "é€šå¸¸ï¼Œç”±äºæ•°æ®ä¸å¯ç”¨ï¼Œå¯èƒ½æ— æ³•å®ç°å¯èƒ½éå¸¸æœ‰ç”¨çš„æè¿°æ€§åŠŸèƒ½ã€‚"
        }
    },
    {
        "translation": {
            "en": "29. See Chapter 8[381].",
            "zh": "29. è§ç¬¬8ç« [381]ã€‚"
        }
    },
    {
        "translation": {
            "en": "9.18â€…â€…â€…The distributions of predictions made by a model trained for the bacterial species identification problem for (a) the original evaluation test set, and for (b) and (c) two periods of time after model deployment; (d) shows how the stability index can be tracked over time to monitor for concept drift.",
            "zh": "9.18 ä¸ºç»†èŒç§ç±»è¯†åˆ«é—®é¢˜è®­ç»ƒçš„æ¨¡å‹åœ¨ï¼ˆaï¼‰åŸå§‹è¯„ä¼°æµ‹è¯•é›†ä»¥åŠï¼ˆbï¼‰å’Œï¼ˆcï¼‰æ¨¡å‹éƒ¨ç½²åä¸¤ä¸ªæ—¶é—´æ®µå†…æ‰€ä½œé¢„æµ‹çš„åˆ†å¸ƒ;ï¼ˆdï¼‰ æ˜¾ç¤ºäº†å¦‚ä½•éšæ—¶é—´è·Ÿè¸ªç¨³å®šæ€§æŒ‡æ•°ä»¥ç›‘æµ‹æ¦‚å¿µæ¼‚ç§»ã€‚"
        }
    },
    {
        "translation": {
            "en": "(d) What will be the value of ct if",
            "zh": "ï¼ˆdï¼‰ ct çš„å€¼æ˜¯å¤šå°‘ï¼Œå¦‚æœ"
        }
    },
    {
        "translation": {
            "en": "We recommend only applying the clamp transformation in cases where it is suspected that a model is performing poorly due to the presence of outliers.",
            "zh": "æˆ‘ä»¬å»ºè®®ä»…åœ¨æ€€ç–‘æ¨¡å‹ç”±äºå­˜åœ¨å¼‚å¸¸å€¼è€Œè¡¨ç°ä¸ä½³çš„æƒ…å†µä¸‹åº”ç”¨é’³ä½å˜æ¢ã€‚"
        }
    },
    {
        "translation": {
            "en": "8.2.3â€ƒNeural Networks as Matrix Operations",
            "zh": "8.2.3 ä½œä¸ºçŸ©é˜µæ“ä½œçš„ç¥ç»ç½‘ç»œ"
        }
    },
    {
        "translation": {
            "en": "The assignment of each instance in a dataset to one of these groups is the output of the clustering process, and a generated feature capturing these assignments can be appended to the original dataset.",
            "zh": "å°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªå®ä¾‹åˆ†é…ç»™å…¶ä¸­ä¸€ä¸ªç»„æ˜¯èšç±»è¿‡ç¨‹çš„è¾“å‡ºï¼Œæ•è·è¿™äº›åˆ†é…çš„ç”Ÿæˆç‰¹å¾å¯ä»¥è¿½åŠ åˆ°åŸå§‹æ•°æ®é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "The forget gate is the leftmost gate in Figure 8.40[509], and it is the first gate to process the inputs to the time-step.",
            "zh": "é—å¿˜é—¨æ˜¯å›¾8.40[509]ä¸­æœ€å·¦è¾¹çš„é—¨ï¼Œå®ƒæ˜¯å¤„ç†æ—¶é—´æ­¥é•¿è¾“å…¥çš„ç¬¬ä¸€ä¸ªé—¨ã€‚"
        }
    },
    {
        "translation": {
            "en": "In Chapter 2 we provide a framework for designing and constructing a predictive analytics solution based on machine learning that meets a business need.",
            "zh": "åœ¨ç¬¬ 2 ç« ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºè®¾è®¡å’Œæ„å»ºåŸºäºæœºå™¨å­¦ä¹ çš„é¢„æµ‹åˆ†æè§£å†³æ–¹æ¡ˆï¼Œä»¥æ»¡è¶³ä¸šåŠ¡éœ€æ±‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "We also discussed how tree pruning can be used to help with the problem of overfitting.",
            "zh": "æˆ‘ä»¬è¿˜è®¨è®ºäº†å¦‚ä½•ä½¿ç”¨æ ‘æœ¨ä¿®å‰ªæ¥å¸®åŠ©è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "The reason is that the max function does not apply weights to its inputs or, to put it another way, all the inputs have a weight of 1.",
            "zh": "åŸå› æ˜¯ max å‡½æ•°ä¸å¯¹å…¶è¾“å…¥åº”ç”¨æƒé‡ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œæ‰€æœ‰è¾“å…¥çš„æƒé‡å‡ä¸º 1ã€‚"
        }
    },
    {
        "translation": {
            "en": "This process is essentially the same as the decision tree post-pruning process described in Section 4.4.4[153].",
            "zh": "æ­¤è¿‡ç¨‹ä¸ç¬¬ 4.4.4 èŠ‚[153] ä¸­æè¿°çš„å†³ç­–æ ‘åä¿®å‰ªè¿‡ç¨‹åŸºæœ¬ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "To update the weights, we must first calculate the delta value for each weight.",
            "zh": "è¦æ›´æ–°æƒé‡ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—æ¯ä¸ªæƒé‡çš„å¢é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "(Random Selection)",
            "zh": "ï¼ˆéšæœºé€‰æ‹©ï¼‰"
        }
    },
    {
        "translation": {
            "en": "Breiman (1996) developed the use of bagging for prediction, and Breiman (2001) introduced random forests.",
            "zh": "Breimanï¼ˆ1996ï¼‰å¼€å‘äº†ä½¿ç”¨è¢‹è£…è¿›è¡Œé¢„æµ‹çš„æ–¹æ³•ï¼ŒBreimanï¼ˆ2001ï¼‰å¼•å…¥äº†éšæœºæ£®æ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "About halfway through the training process, however, the performance of the model on the validation set begins to disimprove.",
            "zh": "ç„¶è€Œï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹è¿›è¡Œåˆ°ä¸€åŠæ—¶ï¼Œæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½å¼€å§‹ä¸‹é™ã€‚"
        }
    },
    {
        "translation": {
            "en": "universal approximators, 400",
            "zh": "é€šç”¨è¿‘ä¼¼å™¨ï¼Œ400"
        }
    },
    {
        "translation": {
            "en": "Despite this limitless variety, however, there are a number of common derived feature types:",
            "zh": "ç„¶è€Œï¼Œå°½ç®¡æœ‰æ— é™çš„å¤šæ ·æ€§ï¼Œä½†ä»æœ‰è®¸å¤šå¸¸è§çš„æ´¾ç”Ÿç‰¹å¾ç±»å‹ï¼š"
        }
    },
    {
        "translation": {
            "en": "During normalization, the values of the descriptive features are mapped to a standard range, for example [âˆ’1,+1] or [0,1], using range normalization (see Equation (3.7)[87]), or standardized in order to have a mean of 0 and a standard deviation of 1 (see Equation (3.8)[88]).",
            "zh": "åœ¨å½’ä¸€åŒ–è¿‡ç¨‹ä¸­ï¼Œæè¿°æ€§ç‰¹å¾çš„å€¼è¢«æ˜ å°„åˆ°ä¸€ä¸ªæ ‡å‡†èŒƒå›´ï¼Œä¾‹å¦‚[âˆ’1ï¼Œ+1]æˆ–[0,1]ï¼Œä½¿ç”¨èŒƒå›´å½’ä¸€åŒ–ï¼ˆå‚è§ç­‰å¼ï¼ˆ3.7ï¼‰[87]ï¼‰ï¼Œæˆ–æ ‡å‡†åŒ–ä»¥ä½¿å¹³å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼ˆè§ç­‰å¼ï¼ˆ3.8ï¼‰[88]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "You carefully prepare the apparatus for these experiments, and on the 21st of September 1904, you spend three hours assisting Professor Blondlot in demonstrating them to Professor Wood.",
            "zh": "1904 å¹´ 9 æœˆ 21 æ—¥ï¼Œä½ ç²¾å¿ƒå‡†å¤‡äº†è¿™äº›å®éªŒçš„ä»ªå™¨ï¼ŒèŠ±äº†ä¸‰ä¸ªå°æ—¶ååŠ©å¸ƒéš†å¾·æ´›ç‰¹æ•™æˆå‘ä¼å¾·æ•™æˆæ¼”ç¤ºè¿™äº›å®éªŒã€‚"
        }
    },
    {
        "translation": {
            "en": "The mode is not particularly effective in this case at measuring the central tendency of the values.",
            "zh": "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å¼åœ¨æµ‹é‡å€¼çš„ä¸­å¿ƒè¶‹åŠ¿æ–¹é¢ä¸æ˜¯ç‰¹åˆ«æœ‰æ•ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_I_Z",
            "zh": "PETROMAGDIFF_I_Z"
        }
    },
    {
        "translation": {
            "en": "6.6â€ƒFurther Reading",
            "zh": "6.6 å»¶ä¼¸é˜…è¯»"
        }
    },
    {
        "translation": {
            "en": "13. See Section 7.3.3[328] for further discussions on the role of the learning rate, and Section 7.4.2[334] for a discussion on different approaches to setting the learning rate.",
            "zh": "13. å…³äºå­¦ä¹ ç‡ä½œç”¨çš„è¿›ä¸€æ­¥è®¨è®ºï¼Œè§ç¬¬7.3.3[328]èŠ‚ï¼Œå…³äºè®¾å®šå­¦ä¹ ç‡çš„ä¸åŒæ–¹æ³•çš„è®¨è®ºï¼Œè§ç¬¬7.4.2[334]èŠ‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 4.17",
            "zh": "å›¾ 4.17"
        }
    },
    {
        "translation": {
            "en": "7.12â€…â€…â€…(a) A plot of the logistic function (Equation (7.25)[342]) for the range of values [â€“10,10]; and (b) the logistic decision surface that results from training a model to represent the generators dataset given in Table 7.6[339] (note that the data has been normalized to the range [â€“1,1]).",
            "zh": "7.12 ï¼ˆaï¼‰ å€¼èŒƒå›´[â€“10,10]çš„é€»è¾‘å‡½æ•°å›¾ï¼ˆç­‰å¼ï¼ˆ7.25ï¼‰[342]ï¼‰;ï¼ˆbï¼‰é€šè¿‡è®­ç»ƒæ¨¡å‹æ¥è¡¨ç¤ºè¡¨7.6[339]ä¸­ç»™å‡ºçš„ç”Ÿæˆå™¨æ•°æ®é›†è€Œäº§ç”Ÿçš„é€»è¾‘å†³ç­–é¢ï¼ˆè¯·æ³¨æ„ï¼Œæ•°æ®å·²å½’ä¸€åŒ–ä¸ºèŒƒå›´[â€“1,1]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Business Understanding: Predictive data analytics projects never start out with the goal of building a prediction model. Instead, they focus on things like gaining new customers, selling more products, and adding efficiencies to a process. So, during the first phase in any analytics project, the primary goal of the data analyst is to fully understand the business (or organizational) problem that is being addressed and then to design a data analytics solution for it.",
            "zh": "ä¸šåŠ¡ç†è§£ï¼šé¢„æµ‹æ•°æ®åˆ†æé¡¹ç›®ä»æ¥éƒ½ä¸æ˜¯ä»¥æ„å»ºé¢„æµ‹æ¨¡å‹ä¸ºç›®æ ‡å¼€å§‹çš„ã€‚ç›¸åï¼Œä»–ä»¬ä¸“æ³¨äºè·å¾—æ–°å®¢æˆ·ã€é”€å”®æ›´å¤šäº§å“ä»¥åŠæé«˜æµç¨‹æ•ˆç‡ç­‰äº‹æƒ…ã€‚å› æ­¤ï¼Œåœ¨ä»»ä½•åˆ†æé¡¹ç›®çš„ç¬¬ä¸€é˜¶æ®µï¼Œæ•°æ®åˆ†æå¸ˆçš„ä¸»è¦ç›®æ ‡æ˜¯å……åˆ†äº†è§£æ­£åœ¨è§£å†³çš„ä¸šåŠ¡ï¼ˆæˆ–ç»„ç»‡ï¼‰é—®é¢˜ï¼Œç„¶åä¸ºå…¶è®¾è®¡æ•°æ®åˆ†æè§£å†³æ–¹æ¡ˆã€‚"
        }
    },
    {
        "translation": {
            "en": "9.4.3â€ƒPerformance Measures: Prediction Scores",
            "zh": "9.4.3 ç»©æ•ˆæŒ‡æ ‡ï¼šé¢„æµ‹åˆ†æ•°"
        }
    },
    {
        "translation": {
            "en": "At this stage we do not worry too much about exactly how a domain concept will be converted into a concrete feature, but rather try to enumerate the different areas from which features will arise.",
            "zh": "åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å¹¶ä¸å¤ªæ‹…å¿ƒå¦‚ä½•å°†é¢†åŸŸæ¦‚å¿µè½¬æ¢ä¸ºå…·ä½“ç‰¹å¾ï¼Œè€Œæ˜¯å°è¯•åˆ—ä¸¾ç‰¹å¾äº§ç”Ÿçš„ä¸åŒé¢†åŸŸã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 5.3",
            "zh": "å›¾ 5.3"
        }
    },
    {
        "translation": {
            "en": "The performance measures from the five individual evaluation experiments and an overall aggregate from the 5-fold cross validation performed on the chest X-ray classification dataset.",
            "zh": "æ¥è‡ªäº”ä¸ªå•ç‹¬è¯„ä¼°å®éªŒçš„æ€§èƒ½æµ‹é‡å’Œå¯¹èƒ¸éƒ¨ X å°„çº¿åˆ†ç±»æ•°æ®é›†è¿›è¡Œçš„ 5 å€äº¤å‰éªŒè¯çš„æ€»ä½“æ±‡æ€»ã€‚"
        }
    },
    {
        "translation": {
            "en": "â€œmachine learning for fun, fun, funâ€",
            "zh": "â€œæœºå™¨å­¦ä¹ çš„ä¹è¶£ï¼Œä¹è¶£ï¼Œä¹è¶£â€"
        }
    },
    {
        "translation": {
            "en": "discriminative model, 733",
            "zh": "åˆ¤åˆ«æ¨¡å‹ï¼Œ733"
        }
    },
    {
        "translation": {
            "en": "This type of representation is often referred to as an embedding because the original features have been embedded into a new lower-dimensional space.",
            "zh": "è¿™ç§ç±»å‹çš„è¡¨ç¤ºé€šå¸¸ç§°ä¸ºåµŒå…¥ï¼Œå› ä¸ºåŸå§‹ç‰¹å¾å·²åµŒå…¥åˆ°æ–°çš„ä½ç»´ç©ºé—´ä¸­ã€‚"
        }
    },
    {
        "translation": {
            "en": "Standardizing the descriptive feature in this way was likely to improve the accuracy of the final predictive models.",
            "zh": "ä»¥è¿™ç§æ–¹å¼æ ‡å‡†åŒ–æè¿°æ€§ç‰¹å¾å¯èƒ½ä¼šæé«˜æœ€ç»ˆé¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "6.5â€…â€…â€…The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each possible target level.",
            "zh": "6.5 æœ´ç´ è´å¶æ–¯é¢„æµ‹æ¨¡å‹å¯¹ CH = ä»˜è´¹ã€GC = æ‹…ä¿äººã€ACC = å…è´¹çš„æŸ¥è¯¢è¿›è¡Œé¢„æµ‹æ‰€éœ€çš„ç›¸å…³æ¦‚ç‡ï¼Œä»¥åŠè®¡ç®—æ¯ä¸ªå¯èƒ½çš„ç›®æ ‡æ°´å¹³çš„åˆ†æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "To illustrate MDPs in a little more detail we develop an MDP representation for an agent designed to play the card game TwentyTwos, a simplified version of the popular game Blackjack, that has been invented for this example.",
            "zh": "ä¸ºäº†æ›´è¯¦ç»†åœ°è¯´æ˜ MDPï¼Œæˆ‘ä»¬ä¸ºä¸€ä¸ªä»£ç†å¼€å‘äº†ä¸€ä¸ª MDP è¡¨ç¤ºï¼Œè¯¥ä»£ç†æ—¨åœ¨ç©çº¸ç‰Œæ¸¸æˆ TwentyTwosï¼Œè¿™æ˜¯ä¸ºæ­¤ç¤ºä¾‹å‘æ˜çš„æµè¡Œæ¸¸æˆ Blackjack çš„ç®€åŒ–ç‰ˆæœ¬ã€‚"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning the degree to which an agent has achieved a goal is measured only by the cumulative rewards it has received from each action taken in pursuit of that goal.",
            "zh": "åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“å®ç°ç›®æ ‡çš„ç¨‹åº¦ä»…é€šè¿‡å…¶ä¸ºè¿½æ±‚è¯¥ç›®æ ‡è€Œé‡‡å–çš„æ¯é¡¹è¡ŒåŠ¨ä¸­è·å¾—çš„ç´¯ç§¯å¥–åŠ±æ¥è¡¡é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "With Edwinâ€™s help, Jocelyn investigated the actual data in the ABT to determine whether the extreme values in the features displaying significant skew or the presence of outliers were due to valid outliers or invalid outliers.",
            "zh": "åœ¨ Edwin çš„å¸®åŠ©ä¸‹ï¼ŒJocelyn ç ”ç©¶äº† ABT ä¸­çš„å®é™…æ•°æ®ï¼Œä»¥ç¡®å®šæ˜¾ç¤ºæ˜¾è‘—åæ–œæˆ–å¼‚å¸¸å€¼å­˜åœ¨çš„è¦ç´ ä¸­çš„æå€¼æ˜¯ç”±äºæœ‰æ•ˆçš„å¼‚å¸¸å€¼è¿˜æ˜¯æ— æ•ˆçš„å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Similarly, if we changed the threshold from 0.5 to 0.25, the predictions for instances d14, d5, and d1 would change from ham to spam, resulting in their outcomes changing to FP, FP, and TP respectively. This would mean that the confusion matrix would change to that shown in Table 9.12(b)[559] and, in turn, that the TPR and TNR measures would change to 0.777 and 0.636 respectively.",
            "zh": "åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬å°†é˜ˆå€¼ä» 0.5 æ›´æ”¹ä¸º 0.25ï¼Œåˆ™å¯¹å®ä¾‹ d14ã€d5 å’Œ d1 çš„é¢„æµ‹å°†ä» ham æ›´æ”¹ä¸º spamï¼Œä»è€Œå¯¼è‡´å…¶ç»“æœåˆ†åˆ«æ›´æ”¹ä¸º FPã€FP å’Œ TPã€‚è¿™æ„å‘³ç€æ··æ·†çŸ©é˜µå°†æ›´æ”¹ä¸ºè¡¨9.12ï¼ˆbï¼‰[559]æ‰€ç¤ºçš„çŸ©é˜µï¼Œåè¿‡æ¥ï¼ŒTPRå’ŒTNRæµ‹é‡å€¼å°†åˆ†åˆ«æ›´æ”¹ä¸º0.777å’Œ0.636ã€‚"
        }
    },
    {
        "translation": {
            "en": "18. Based on data from Bray et al. (2018).",
            "zh": "18. åŸºäº Bray ç­‰äººï¼ˆ2018 å¹´ï¼‰çš„æ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "(c) What would be the output from this neuron if the activation function Ï† is the logistic function?",
            "zh": "ï¼ˆcï¼‰å¦‚æœæ¿€æ´»å‡½æ•°Ï†æ˜¯é€»è¾‘å‡½æ•°ï¼Œé‚£ä¹ˆè¿™ä¸ªç¥ç»å…ƒçš„è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "The classifier accurately predicts the type of galaxies with the elliptical target level and, to a lesser extent, with the spiral_eo target level.",
            "zh": "åˆ†ç±»å™¨ä»¥æ¤­åœ†ç›®æ ‡æ°´å¹³å‡†ç¡®é¢„æµ‹æ˜Ÿç³»ç±»å‹ï¼Œå¹¶åœ¨è¾ƒå°ç¨‹åº¦ä¸Šä»¥spiral_eoç›®æ ‡æ°´å¹³å‡†ç¡®é¢„æµ‹æ˜Ÿç³»ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "And why is the rarity of the disease good news given that the patient has tested positive for it?",
            "zh": "é‰´äºæ‚£è€…çš„æ£€æµ‹ç»“æœå‘ˆé˜³æ€§ï¼Œä¸ºä»€ä¹ˆè¿™ç§ç–¾ç—…çš„ç½•è§æ€§æ˜¯ä¸ªå¥½æ¶ˆæ¯ï¼Ÿ"
        }
    },
    {
        "translation": {
            "en": "Figure 13.4",
            "zh": "å›¾ 13.4"
        }
    },
    {
        "translation": {
            "en": "The value calculated is not terribly different from the value calculated before.",
            "zh": "è®¡ç®—çš„å€¼ä¸ä¹‹å‰è®¡ç®—çš„å€¼æ²¡æœ‰å¤ªå¤§åŒºåˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "EXPAB_U/G/R/I/Z",
            "zh": "EXPAB_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, Brian, author. |",
            "zh": "Mac Nameeï¼ŒBrianï¼Œä½œè€…ã€‚|"
        }
    },
    {
        "translation": {
            "en": "column in Table 4.14[162].",
            "zh": "è¡¨4.14[162]ä¸­çš„åˆ—ã€‚"
        }
    },
    {
        "translation": {
            "en": "A set of weights that capture this relationship well are said to fit the training data.",
            "zh": "æ®è¯´ä¸€ç»„èƒ½å¾ˆå¥½åœ°æ•æ‰è¿™ç§å…³ç³»çš„æƒé‡é€‚åˆè®­ç»ƒæ•°æ®ã€‚"
        }
    },
    {
        "translation": {
            "en": "Paying the recurring charge entitled a customer to a bundle of minutes of call time that were offered at a reduction to the standard call rate.",
            "zh": "æ”¯ä»˜ç»å¸¸æ€§è´¹ç”¨åï¼Œå®¢æˆ·æœ‰æƒè·å¾—ä»¥ä½äºæ ‡å‡†é€šè¯è´¹ç‡çš„é€šè¯æ—¶é—´æä¾›çš„é€šè¯æ—¶é—´ã€‚"
        }
    },
    {
        "translation": {
            "en": "decision surface, 341",
            "zh": "å†³ç­–é¢ï¼Œ341"
        }
    },
    {
        "translation": {
            "en": "Conversely, if we set k too high, we run the risk of losing the true pattern of the data and underfitting.",
            "zh": "ç›¸åï¼Œå¦‚æœæˆ‘ä»¬å°† k è®¾ç½®å¾—å¤ªé«˜ï¼Œæˆ‘ä»¬å°±æœ‰å¯èƒ½ä¸¢å¤±æ•°æ®çš„çœŸå®æ¨¡å¼å’Œæ¬ æ‹Ÿåˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The naive Bayes model leverages conditional independence to the extreme by assuming conditional independence between the assignment of all the descriptive feature values given the target level.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹é€šè¿‡å‡è®¾ç»™å®šç›®æ ‡çº§åˆ«çš„æ‰€æœ‰æè¿°æ€§ç‰¹å¾å€¼çš„èµ‹å€¼ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œå°†æ¡ä»¶ç‹¬ç«‹æ€§å‘æŒ¥åˆ°æè‡´ã€‚"
        }
    },
    {
        "translation": {
            "en": "Calculating the inverse of a matrix involves solving systems of linear equations and requires the use of techniques from linear algebra such as Gauss-Jordan elimination or LU decomposition.",
            "zh": "è®¡ç®—çŸ©é˜µçš„é€†æ¶‰åŠæ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ï¼Œå¹¶ä¸”éœ€è¦ä½¿ç”¨çº¿æ€§ä»£æ•°ä¸­çš„æŠ€æœ¯ï¼Œä¾‹å¦‚é«˜æ–¯-ä¹”ä¸¹æ¶ˆå…ƒæ³•æˆ– LU åˆ†è§£ã€‚"
        }
    },
    {
        "translation": {
            "en": "Ï‡2 pruning, 155",
            "zh": "Ï‡2 ä¿®å‰ªï¼Œ155"
        }
    },
    {
        "translation": {
            "en": "1. It is crucial to use data to evaluate a model that has not been used to train the model.",
            "zh": "1. ä½¿ç”¨æ•°æ®æ¥è¯„ä¼°å°šæœªç”¨äºè®­ç»ƒæ¨¡å‹çš„æ¨¡å‹è‡³å…³é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "For example, applying Equation (7.23)[339] to the instance RPM = 810, VIBRATION = 495, which is above the decision boundary in Figure 7.10(b)[340], gives the following result:",
            "zh": "ä¾‹å¦‚ï¼Œå°†å…¬å¼ï¼ˆ7.23ï¼‰[339]åº”ç”¨äºRPM = 810ï¼ŒVIBRATION = 495ï¼ˆé«˜äºå›¾7.10ï¼ˆbï¼‰[340]ä¸­çš„å†³ç­–è¾¹ç•Œï¼‰å®ä¾‹ï¼Œå¾—å‡ºä»¥ä¸‹ç»“æœï¼š"
        }
    },
    {
        "translation": {
            "en": "The third part of the book also deals with Modeling, but in this case it looks at modeling approaches beyond prediction. As described previously in this chapter, supervised machine learning is one of three main machine learning paradigms. The other two are unsupervised learning and reinforcement learning. Chapters 10[597] and 11[637] describe these two other approaches as a counterpoint to the descriptions of supervised learning in the rest of the book.",
            "zh": "æœ¬ä¹¦çš„ç¬¬ä¸‰éƒ¨åˆ†ä¹Ÿæ¶‰åŠå»ºæ¨¡ï¼Œä½†åœ¨æœ¬ä¾‹ä¸­ï¼Œå®ƒç€çœ¼äºé¢„æµ‹ä¹‹å¤–çš„å»ºæ¨¡æ–¹æ³•ã€‚å¦‚æœ¬ç« å‰é¢æ‰€è¿°ï¼Œç›‘ç£å¼æœºå™¨å­¦ä¹ æ˜¯ä¸‰ç§ä¸»è¦çš„æœºå™¨å­¦ä¹ èŒƒå¼ä¹‹ä¸€ã€‚å¦å¤–ä¸¤ä¸ªæ˜¯æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚ç¬¬10ç« [597]å’Œç¬¬11ç« [637]æè¿°äº†å¦å¤–ä¸¤ç§æ–¹æ³•ï¼Œä¸æœ¬ä¹¦å…¶ä½™éƒ¨åˆ†å¯¹ç›‘ç£å­¦ä¹ çš„æè¿°ç›¸å¯¹åº”ã€‚"
        }
    },
    {
        "translation": {
            "en": "Friedman et al.",
            "zh": "å¼—é‡Œå¾·æ›¼ç­‰äººã€‚"
        }
    },
    {
        "translation": {
            "en": "REGIONTYPE",
            "zh": "åŒºåŸŸç±»å‹"
        }
    },
    {
        "translation": {
            "en": "Table 8.7",
            "zh": "è¡¨ 8.7"
        }
    },
    {
        "translation": {
            "en": "This experiment showed the AT executive team that the new decision tree model could significantly reduce churn rates within the AT customer base.",
            "zh": "è¯¥å®éªŒå‘ATæ‰§è¡Œå›¢é˜Ÿè¡¨æ˜ï¼Œæ–°çš„å†³ç­–æ ‘æ¨¡å‹å¯ä»¥æ˜¾è‘—é™ä½ATå®¢æˆ·ç¾¤çš„æµå¤±ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.5.1.2â€ƒVisualizing pairs of categorical featuresâ€ƒThe simplest way to visualize the relationship between two categorical features is to use a collection of bar plots.",
            "zh": "3.5.1.2 å¯è§†åŒ–åˆ†ç±»ç‰¹å¾å¯¹ å¯è§†åŒ–ä¸¤ä¸ªåˆ†ç±»ç‰¹å¾ä¹‹é—´å…³ç³»çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨æ¡å½¢å›¾é›†åˆã€‚"
        }
    },
    {
        "translation": {
            "en": "The % Miss.",
            "zh": "æœªå‘½ä¸­ç™¾åˆ†æ¯”ã€‚"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming the target output for this input is 1, calculate the Î´ for each neuron in the network.",
            "zh": "ï¼ˆbï¼‰ å‡è®¾æ­¤è¾“å…¥çš„ç›®æ ‡è¾“å‡ºä¸º 1ï¼Œè®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„Î´ã€‚"
        }
    },
    {
        "translation": {
            "en": "An obvious criteria for driving this search is to look for models that are consistent with the data.",
            "zh": "é©±åŠ¨æ­¤æœç´¢çš„ä¸€ä¸ªæ˜æ˜¾æ ‡å‡†æ˜¯æŸ¥æ‰¾ä¸æ•°æ®ä¸€è‡´çš„æ¨¡å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is no limit to the kinds of functions that can be used as basis functions, and as we have seen in the previous example, the basis functions for different descriptive features in a dataset can be quite different.",
            "zh": "å¯ç”¨ä½œåŸºå‡½æ•°çš„å‡½æ•°ç§ç±»æ²¡æœ‰é™åˆ¶ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨å‰é¢çš„ç¤ºä¾‹ä¸­çœ‹åˆ°çš„ï¼Œæ•°æ®é›†ä¸­ä¸åŒæè¿°æ€§ç‰¹å¾çš„åŸºæœ¬å‡½æ•°å¯èƒ½å¤§ä¸ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "-0.1764",
            "zh": "-0.1764"
        }
    },
    {
        "translation": {
            "en": "It is likely that people who respond to a survey are systematically different from people who donâ€™t, and so when the response rate within a population is very low, it is likely that the resulting sample underrepresents particular groups in the population.",
            "zh": "å¯¹è°ƒæŸ¥åšå‡ºå›åº”çš„äººå¾ˆå¯èƒ½ä¸ä¸å›ç­”è°ƒæŸ¥çš„äººåœ¨ç³»ç»Ÿä¸Šæœ‰æ‰€ä¸åŒï¼Œå› æ­¤ï¼Œå½“äººç¾¤ä¸­çš„å›å¤ç‡éå¸¸ä½æ—¶ï¼Œç»“æœæ ·æœ¬å¾ˆå¯èƒ½ä½ä¼°äº†äººç¾¤ä¸­ç‰¹å®šç¾¤ä½“çš„ä»£è¡¨æ€§ã€‚"
        }
    },
    {
        "translation": {
            "en": "So, for a conditional independence, we need to take into account not only the parents of a node but also the state of its children and their parents.",
            "zh": "å› æ­¤ï¼Œå¯¹äºæœ‰æ¡ä»¶çš„ç‹¬ç«‹æ€§ï¼Œæˆ‘ä»¬ä¸ä»…éœ€è¦è€ƒè™‘èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼Œè¿˜éœ€è¦è€ƒè™‘èŠ‚ç‚¹å­èŠ‚ç‚¹åŠå…¶çˆ¶èŠ‚ç‚¹çš„çŠ¶æ€ã€‚"
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] shows that during backpropagation the error gradient is repeatedly multiplied by a derivative of activation functions, one multiplication for each neuron that the error gradient is backpropagated through.",
            "zh": "æ–¹ç¨‹ 8.41[436] è¡¨æ˜ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè¯¯å·®æ¢¯åº¦è¢«æ¿€æ´»å‡½æ•°çš„å¯¼æ•°åå¤ä¹˜ä»¥ï¼Œè¯¯å·®æ¢¯åº¦åå‘ä¼ æ’­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¹˜ä»¥ä¸€æ¬¡ã€‚"
        }
    },
    {
        "translation": {
            "en": "The dictionary is typically defined as the complete set of words that occur in the training dataset.",
            "zh": "å­—å…¸é€šå¸¸å®šä¹‰ä¸ºè®­ç»ƒæ•°æ®é›†ä¸­å‡ºç°çš„å®Œæ•´å•è¯é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "4.7â€…â€…â€…Exercises",
            "zh": "4.7 ç»ƒä¹ "
        }
    },
    {
        "translation": {
            "en": "For example, based on correlations tests alone, we might conclude that the presence of swallows cause hot weather, that spinning windmills cause wind, and that playing basketball causes people to be tall.",
            "zh": "ä¾‹å¦‚ï¼Œä»…æ ¹æ®ç›¸å…³æ€§æ£€éªŒï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œç‡•å­çš„å­˜åœ¨ä¼šå¯¼è‡´ç‚çƒ­çš„å¤©æ°”ï¼Œæ—‹è½¬çš„é£è½¦ä¼šå¯¼è‡´é£ï¼Œæ‰“ç¯®çƒä¼šå¯¼è‡´äººé•¿é«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "As a result, the values in column 6 are identical to the values in the error column.",
            "zh": "å› æ­¤ï¼Œç¬¬ 6 åˆ—ä¸­çš„å€¼ä¸é”™è¯¯åˆ—ä¸­çš„å€¼ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "As the experience of moving left from state 0-3 to state 0-2 has not led to a large positive reward or opened up the potential for a new action that will give significant positive return, the value of this action in this state has been reduced.",
            "zh": "ç”±äºä»çŠ¶æ€ 0-3 å‘å·¦ç§»åŠ¨åˆ°çŠ¶æ€ 0-2 çš„ç»éªŒå¹¶æ²¡æœ‰å¸¦æ¥å·¨å¤§çš„æ­£å¥–åŠ±ï¼Œä¹Ÿæ²¡æœ‰ä¸ºå°†å¸¦æ¥æ˜¾ç€æ­£å›æŠ¥çš„æ–°è¡ŒåŠ¨å¼€è¾Ÿäº†æ½œåŠ›ï¼Œå› æ­¤è¯¥è¡ŒåŠ¨åœ¨è¿™ç§çŠ¶æ€ä¸‹çš„ä»·å€¼å·²ç»é™ä½ã€‚"
        }
    },
    {
        "translation": {
            "en": "Table 9.14",
            "zh": "è¡¨ 9.14"
        }
    },
    {
        "translation": {
            "en": "Intuitively we can see that this grouping is, as Goldilocks put it, just right and is the type of grouping we are trying to generate when we use a variance measure to select the splitting point.",
            "zh": "ç›´è§‚åœ°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ­£å¦‚ Goldilocks æ‰€è¯´ï¼Œè¿™ç§åˆ†ç»„æ°åˆ°å¥½å¤„ï¼Œå¹¶ä¸”æ˜¯æˆ‘ä»¬åœ¨ä½¿ç”¨æ–¹å·®åº¦é‡é€‰æ‹©åˆ†å‰²ç‚¹æ—¶å°è¯•ç”Ÿæˆçš„åˆ†ç»„ç±»å‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "The origins used for the figures were (a) (50,50), (b) (63,71), and (c) (42,35).",
            "zh": "è¿™äº›æ•°å­—çš„æ¥æºæ˜¯ï¼ˆaï¼‰ï¼ˆ50,50ï¼‰ï¼Œï¼ˆbï¼‰ï¼ˆ63,71ï¼‰å’Œï¼ˆcï¼‰ï¼ˆ42,35ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows a selection of the transition probabilities between states in the TwentyTwos MDP (only a selection of probabilities are shown to make the graph less cluttered).",
            "zh": "å›¾ 11.3[648] æ˜¾ç¤ºäº† TwentyTwos MDP ä¸­çŠ¶æ€ä¹‹é—´çš„è½¬ç§»æ¦‚ç‡é€‰æ‹©ï¼ˆä»…æ˜¾ç¤ºä¸€äº›æ¦‚ç‡ä»¥ä½¿å›¾å½¢ä¸é‚£ä¹ˆæ··ä¹±ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "rectified linear unit, 386",
            "zh": "æ•´æµçº¿æ€§å•å…ƒï¼Œ386"
        }
    },
    {
        "translation": {
            "en": "Table 9.15",
            "zh": "è¡¨ 9.15"
        }
    },
    {
        "translation": {
            "en": "An inappropriate inductive bias, however, can lead to mistakes.",
            "zh": "ç„¶è€Œï¼Œä¸é€‚å½“çš„å½’çº³åå·®ä¼šå¯¼è‡´é”™è¯¯ã€‚"
        }
    },
    {
        "translation": {
            "en": "Individuals will most likely remain in the INFECTED state for some time, P(I I) = 0.50, but will transition eventually to the RECOVERED state, P(I R) = 0.50.",
            "zh": "ä¸ªä½“å¾ˆå¯èƒ½ä¼šåœ¨ä¸€æ®µæ—¶é—´å†…ä¿æŒæ„ŸæŸ“çŠ¶æ€ï¼ŒPï¼ˆI Iï¼‰ = 0.50ï¼Œä½†æœ€ç»ˆä¼šè¿‡æ¸¡åˆ°æ¢å¤çŠ¶æ€ï¼ŒPï¼ˆI Rï¼‰ = 0.50ã€‚"
        }
    },
    {
        "translation": {
            "en": "The state of the cell after the update gate is the cell state that is propagated forward to the next time-step, and so after this update the cell state is now ct (rather than câ€¡).",
            "zh": "æ›´æ–°é—¨ä¹‹åçš„å•å…ƒçŠ¶æ€æ˜¯å‘å‰ä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„å•å…ƒçŠ¶æ€ï¼Œå› æ­¤åœ¨æ­¤æ›´æ–°ä¹‹åï¼Œå•å…ƒçŠ¶æ€ç°åœ¨æ˜¯ ctï¼ˆè€Œä¸æ˜¯ câ€¡ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "A collection of possible simple linear regression models capturing the relationship between these two features are also shown.",
            "zh": "è¿˜æ˜¾ç¤ºäº†ä¸€ç»„å¯èƒ½çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œç”¨äºæ•è·è¿™ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "In fact, if inappropriately large learning rates are used, the jumps from one side of the error surface to the other can cause the sum of squared errors to repeatedly increase rather than decrease, leading to a process that will never converge.",
            "zh": "äº‹å®ä¸Šï¼Œå¦‚æœä½¿ç”¨ä¸æ°å½“çš„å¤§å­¦ä¹ ç‡ï¼Œä»è¯¯å·®è¡¨é¢çš„ä¸€ä¾§è·³åˆ°å¦ä¸€ä¾§ä¼šå¯¼è‡´å¹³æ–¹è¯¯å·®çš„æ€»å’Œåå¤å¢åŠ è€Œä¸æ˜¯å‡å°‘ï¼Œä»è€Œå¯¼è‡´ä¸€ä¸ªæ°¸è¿œä¸ä¼šæ”¶æ•›çš„è¿‡ç¨‹ã€‚"
        }
    },
    {
        "translation": {
            "en": "Classification accuracy can assume values in the range [0,1], and higher values indicate better performance. For the email classification task, classification accuracy would be",
            "zh": "åˆ†ç±»ç²¾åº¦å¯ä»¥å‡å®šå€¼åœ¨ [0,1] èŒƒå›´å†…ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºæ€§èƒ½è¶Šå¥½ã€‚å¯¹äºç”µå­é‚®ä»¶åˆ†ç±»ä»»åŠ¡ï¼Œåˆ†ç±»ç²¾åº¦ä¸º"
        }
    },
    {
        "translation": {
            "en": "Dua, Dheeru, and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml.",
            "zh": "Duaã€Dheeru å’Œ Casey Graffã€‚2017. UCI æœºå™¨å­¦ä¹ å­˜å‚¨åº“ã€‚http://archive.ics.uci.edu/mlã€‚"
        }
    },
    {
        "translation": {
            "en": "8.34â€…â€…â€…A grayscale image of a 4 after padding has been applied to the original 6-by-6 matrix representation, and the local receptive field of a neuron that includes both valid and padded pixels.",
            "zh": "8.34 å¡«å……å 4 çš„ç°åº¦å›¾åƒå·²åº”ç”¨äºåŸå§‹çš„ 6Ã—6 çŸ©é˜µè¡¨ç¤ºï¼Œä»¥åŠåŒ…æ‹¬æœ‰æ•ˆåƒç´ å’Œå¡«å……åƒç´ çš„ç¥ç»å…ƒçš„å±€éƒ¨æ„Ÿå—é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "A one-versus-all model distinguishes between one level of the target feature and all the others.",
            "zh": "ä¸€å¯¹ä¸€æ¨¡å‹åŒºåˆ†ç›®æ ‡è¦ç´ çš„ä¸€ä¸ªçº§åˆ«å’Œæ‰€æœ‰å…¶ä»–çº§åˆ«ã€‚"
        }
    },
    {
        "translation": {
            "en": "SPLOM diagrams of (a) the EXPRAD; and (b) DEVRAD measurements from the raw SDSS dataset. Each SPLOM shows the measure across the five different photometric bands captured by the SDSS telescope (u, g, r, i, and z).",
            "zh": "ï¼ˆaï¼‰ EXPRAD çš„ SPLOM å›¾;ï¼ˆbï¼‰æ¥è‡ªåŸå§‹SDSSæ•°æ®é›†çš„DEVRADæµ‹é‡å€¼ã€‚æ¯ä¸ªSPLOMéƒ½æ˜¾ç¤ºäº†SDSSæœ›è¿œé•œæ•è·çš„äº”ä¸ªä¸åŒå…‰åº¦æ³¢æ®µï¼ˆuï¼Œgï¼Œrï¼Œiå’Œzï¼‰çš„æµ‹é‡å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "Figure 8.25[460] illustrates the internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights of each layer in the network are sampled from a normal distribution with a mean of 0 and a variance calculated using Equation (8.62)[459].",
            "zh": "å›¾8.25[460]è¯´æ˜äº†å›¾8.22[450]ä¸­ç¬¬ä¸€æ¬¡è®­ç»ƒè¿­ä»£æœŸé—´ç½‘ç»œçš„å†…éƒ¨åŠ¨åŠ›å­¦ï¼Œå½“æ—¶ç½‘ç»œä¸­æ¯ä¸€å±‚çš„æƒé‡æ˜¯ä»å‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼Œæ–¹å·®ä½¿ç”¨å…¬å¼ï¼ˆ8.62ï¼‰[459]è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "In each case we have overlaid the coordinate system defined by the Mahalanobis distance from a different origin.",
            "zh": "åœ¨æ¯ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½è¦†ç›–äº†ç”±æ¥è‡ªä¸åŒåŸç‚¹çš„é©¬æ°è·ç¦»å®šä¹‰çš„åæ ‡ç³»ã€‚"
        }
    },
    {
        "translation": {
            "en": "Examples of using stacked bar plot visualizations to illustrate the relationship between two categorical features: (a) CAREER STAGE and SHOE SPONSOR features; and (b) POSITION and SHOE SPONSOR features, all from Table 3.7[73].",
            "zh": "ä½¿ç”¨å †ç§¯æ¡å½¢å›¾å¯è§†åŒ–æ¥è¯´æ˜ä¸¤ä¸ªåˆ†ç±»ç‰¹å¾ä¹‹é—´å…³ç³»çš„ç¤ºä¾‹ï¼šï¼ˆaï¼‰ CAREER STAGE å’Œ SHOE SPONSOR ç‰¹å¾;ï¼ˆbï¼‰POSITIONå’ŒSHOE SPONSORç‰¹å¾ï¼Œå‡æ¥è‡ªè¡¨3.7[73]ã€‚"
        }
    },
    {
        "translation": {
            "en": "To help align the elements of the weight matrices shown in Figure 8.14[425] with the connections in the graph representation of the network in Figure 8.4[390], the rows and columns of the weight matrices are labeled using the neuron identifiers from Figure 8.4[390] (the labels are the numbers inside circles).",
            "zh": "ä¸ºäº†å¸®åŠ©å°†å›¾8.14[425]æ‰€ç¤ºçš„æƒé‡çŸ©é˜µçš„å…ƒç´ ä¸å›¾8.4[390]ä¸­ç½‘ç»œå›¾è¡¨ç¤ºä¸­çš„è¿æ¥å¯¹é½ï¼Œä½¿ç”¨å›¾8.4[390]ä¸­çš„ç¥ç»å…ƒæ ‡è¯†ç¬¦æ ‡è®°æƒé‡çŸ©é˜µçš„è¡Œå’Œåˆ—ï¼ˆæ ‡ç­¾æ˜¯åœ†åœˆå†…çš„æ•°å­—ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "Observing a multimodal distribution is cause for both caution and optimism.",
            "zh": "è§‚å¯Ÿå¤šå³°åˆ†å¸ƒæ—¢è¦è°¨æ…åˆè¦ä¹è§‚ã€‚"
        }
    },
    {
        "translation": {
            "en": "Also, peculiarities in a dataset can affect the calculation of the correlation between two features.",
            "zh": "æ­¤å¤–ï¼Œæ•°æ®é›†ä¸­çš„ç‰¹æ®Šæ€§å¯èƒ½ä¼šå½±å“ä¸¤ä¸ªè¦ç´ ä¹‹é—´ç›¸å…³æ€§çš„è®¡ç®—ã€‚"
        }
    },
    {
        "translation": {
            "en": "Consequently, decision trees overfit by splitting the data on irrelevant features that appear relevant only because of noise or sampling variance in the training data.",
            "zh": "å› æ­¤ï¼Œå†³ç­–æ ‘é€šè¿‡æ‹†åˆ†ä¸ç›¸å…³ç‰¹å¾ä¸Šçš„æ•°æ®æ¥è¿‡åº¦æ‹Ÿåˆï¼Œè¿™äº›ç‰¹å¾ä»…å› è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°æˆ–é‡‡æ ·æ–¹å·®è€Œæ˜¾å¾—ç›¸å…³ã€‚"
        }
    },
    {
        "translation": {
            "en": "To monitor models for the occurrence of concept drift, it is important that the stability index be continuously tracked over time.",
            "zh": "ä¸ºäº†ç›‘æ§æ¨¡å‹æ˜¯å¦å‘ç”Ÿæ¦‚å¿µæ¼‚ç§»ï¼Œå¿…é¡»éšæ—¶é—´æŒç»­è·Ÿè¸ªç¨³å®šæ€§æŒ‡æ•°ã€‚"
        }
    },
    {
        "translation": {
            "en": "A nearest neighbor algorithm can be updated without retraining.",
            "zh": "å¯ä»¥æ›´æ–°æœ€è¿‘é‚»ç®—æ³•ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚"
        }
    },
    {
        "translation": {
            "en": "In reality, these filters are learned by the convolutional network in the same way that weights are learned in a fully connected feedforward network.",
            "zh": "å®é™…ä¸Šï¼Œå·ç§¯ç½‘ç»œå­¦ä¹ è¿™äº›æ»¤æ³¢å™¨çš„æ–¹å¼ä¸åœ¨å®Œå…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œä¸­å­¦ä¹ æƒé‡çš„æ–¹å¼ç›¸åŒã€‚"
        }
    },
    {
        "translation": {
            "en": "We can see in this figure that the query is inside a Voronoi region defined by an instance with a target level of yes.",
            "zh": "åœ¨æ­¤å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æŸ¥è¯¢ä½äºç”±ç›®æ ‡çº§åˆ«ä¸º yes çš„å®ä¾‹å®šä¹‰çš„ Voronoi åŒºåŸŸå†…ã€‚"
        }
    },
    {
        "translation": {
            "en": "How the instances in the spam dataset split when we partition using each of the different descriptive features from the spam dataset in Table 4.2[121].",
            "zh": "å½“æˆ‘ä»¬ä½¿ç”¨è¡¨ 4.2[121] ä¸­åƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„æ¯ä¸ªä¸åŒæè¿°æ€§ç‰¹å¾è¿›è¡Œåˆ†åŒºæ—¶ï¼Œåƒåœ¾é‚®ä»¶æ•°æ®é›†ä¸­çš„å®ä¾‹æ˜¯å¦‚ä½•æ‹†åˆ†çš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "Another extension allows support vector machines to handle multinomial target features using a one-versus-all approach similar to that described in Section 7.4.6[357].",
            "zh": "å¦ä¸€ä¸ªæ‰©å±•å…è®¸æ”¯æŒå‘é‡æœºä½¿ç”¨ç±»ä¼¼äºç¬¬ 7.4.6 èŠ‚[357]ä¸­æè¿°çš„ä¸€å¯¹ä¸€æ–¹æ³•å¤„ç†å¤šé¡¹å¼ç›®æ ‡ç‰¹å¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "Idiom",
            "zh": "æˆè¯­"
        }
    },
    {
        "translation": {
            "en": "leaky ReLU, 445",
            "zh": "æ³„æ¼çš„ ReLUï¼Œ445"
        }
    },
    {
        "translation": {
            "en": "0.00157020",
            "zh": "0.00157020"
        }
    },
    {
        "translation": {
            "en": "For example, if we were to measure the heights of a randomly selected group of Irish men and women, we would expect a bimodal distribution with a peak at around 1.635m for women and 1.775m for men.",
            "zh": "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦æµ‹é‡ä¸€ç»„éšæœºé€‰æ‹©çš„çˆ±å°”å…°ç”·æ€§å’Œå¥³æ€§çš„èº«é«˜ï¼Œæˆ‘ä»¬é¢„è®¡ä¼šå‡ºç°åŒå³°åˆ†å¸ƒï¼Œå¥³æ€§çš„å³°å€¼çº¦ä¸º 1.635 ç±³ï¼Œç”·æ€§çº¦ä¸º 1.775 ç±³ã€‚"
        }
    },
    {
        "translation": {
            "en": "Following the same approach as in earlier models, Jocelyn performed feature selection using a step-wise sequential search to find the best subset of features for this model.",
            "zh": "éµå¾ªä¸æ—©æœŸæ¨¡å‹ç›¸åŒçš„æ–¹æ³•ï¼ŒJocelyn ä½¿ç”¨é€æ­¥é¡ºåºæœç´¢æ‰§è¡Œç‰¹å¾é€‰æ‹©ï¼Œä»¥æ‰¾åˆ°è¯¥æ¨¡å‹çš„æœ€ä½³ç‰¹å¾å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "However, we know that using an appropriately defined PDF, we can approximate the probability of the feature taking any value in its domain.",
            "zh": "ä½†æ˜¯ï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œä½¿ç”¨é€‚å½“å®šä¹‰çš„ PDFï¼Œæˆ‘ä»¬å¯ä»¥è¿‘ä¼¼åœ°è®¡ç®—ç‰¹å¾åœ¨å…¶åŸŸä¸­è·å–ä»»ä½•å€¼çš„æ¦‚ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Finally, it is worth mentioning two situations where this weighted k nearest neighbor approach can be problematic. The first is if the dataset is very imbalanced, then even with a weighting applied to the contribution of the training instances, the majority target level may dominate. The second is when the dataset is very large, which means that computing the reciprocal of squared distance between the query and all the training instances can become too computationally expensive to be feasible.",
            "zh": "æœ€åï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨ä¸¤ç§æƒ…å†µä¸‹ï¼Œè¿™ç§åŠ æƒ k æœ€è¿‘é‚»æ–¹æ³•å¯èƒ½ä¼šæœ‰é—®é¢˜ã€‚ç¬¬ä¸€ç§æƒ…å†µæ˜¯ï¼Œå¦‚æœæ•°æ®é›†éå¸¸ä¸å¹³è¡¡ï¼Œé‚£ä¹ˆå³ä½¿å¯¹è®­ç»ƒå®ä¾‹çš„è´¡çŒ®æ–½åŠ äº†åŠ æƒï¼Œå¤šæ•°ç›®æ ‡æ°´å¹³ä¹Ÿå¯èƒ½å ä¸»å¯¼åœ°ä½ã€‚ç¬¬äºŒç§æƒ…å†µæ˜¯æ•°æ®é›†éå¸¸å¤§ï¼Œè¿™æ„å‘³ç€è®¡ç®—æŸ¥è¯¢å’Œæ‰€æœ‰è®­ç»ƒå®ä¾‹ä¹‹é—´çš„å¹³æ–¹è·ç¦»çš„å€’æ•°å¯èƒ½ä¼šå˜å¾—è¿‡äºæ˜‚è´µè€Œä¸å¯è¡Œã€‚"
        }
    },
    {
        "translation": {
            "en": "We can represent these cards using the dataset given in Table 4.1[118].",
            "zh": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¡¨4.1[118]ä¸­ç»™å‡ºçš„æ•°æ®é›†æ¥è¡¨ç¤ºè¿™äº›å¡ç‰‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Here we see that the SARSA agent favors staying away from any possibility of falling into one of the dangerous cells rather than taking the more direct route.",
            "zh": "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°SARSAç‰¹å·¥å€¾å‘äºè¿œç¦»ä»»ä½•è½å…¥å±é™©ç‰¢æˆ¿ä¹‹ä¸€çš„å¯èƒ½æ€§ï¼Œè€Œä¸æ˜¯é‡‡å–æ›´ç›´æ¥çš„è·¯çº¿ã€‚"
        }
    },
    {
        "translation": {
            "en": "small multiples, 75, 77",
            "zh": "å°å€æ•°ï¼Œ75,77"
        }
    },
    {
        "translation": {
            "en": "7.2.1â€…â€…â€…Simple Linear Regression",
            "zh": "7.2.1 ç®€å•çº¿æ€§å›å½’"
        }
    },
    {
        "translation": {
            "en": "Table 0.1",
            "zh": "è¡¨0.1"
        }
    },
    {
        "translation": {
            "en": "Precision captures how often, when a model makes a positive prediction, this prediction turns out to be correct.",
            "zh": "ç²¾åº¦æ•è·å½“æ¨¡å‹åšå‡ºç§¯æé¢„æµ‹æ—¶ï¼Œè¯¥é¢„æµ‹è¢«è¯æ˜æ˜¯æ­£ç¡®çš„é¢‘ç‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "Naive Bayes and k nearest neighbor models are good examples of the former type, while decision trees and regression models are good examples of the latter.",
            "zh": "æœ´ç´ è´å¶æ–¯æ¨¡å‹å’Œ k æœ€è¿‘é‚»æ¨¡å‹æ˜¯å‰ä¸€ç§ç±»å‹çš„å¾ˆå¥½çš„ä¾‹å­ï¼Œè€Œå†³ç­–æ ‘å’Œå›å½’æ¨¡å‹æ˜¯åè€…çš„å¥½ä¾‹å­ã€‚"
        }
    },
    {
        "translation": {
            "en": "goal, 639, 643, 676",
            "zh": "è¿›çƒæ•°ï¼Œ 639ï¼Œ 643ï¼Œ 676"
        }
    },
    {
        "translation": {
            "en": "After we have covered the fundamentals of the models, we explain how these artificial neural networks can be understood as sequences of matrix multiplications (see Section 8.2.3[390]).",
            "zh": "åœ¨ä»‹ç»äº†æ¨¡å‹çš„åŸºç¡€çŸ¥è¯†ä¹‹åï¼Œæˆ‘ä»¬è§£é‡Šäº†å¦‚ä½•å°†è¿™äº›äººå·¥ç¥ç»ç½‘ç»œç†è§£ä¸ºçŸ©é˜µä¹˜æ³•åºåˆ—ï¼ˆå‚è§ç¬¬ 8.2.3 èŠ‚[390]ï¼‰ã€‚"
        }
    },
    {
        "translation": {
            "en": "For our three-level categorical feature we might decide that 1,0,0 indicates low, 0,1,0 indicates medium, and 0,0,1 indicates high.",
            "zh": "å¯¹äºæˆ‘ä»¬çš„ä¸‰çº§åˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®š 1,0,0 è¡¨ç¤ºä½ï¼Œ0,1,0 è¡¨ç¤ºä¸­ç­‰ï¼Œ0,0,1 è¡¨ç¤ºé«˜ã€‚"
        }
    },
    {
        "translation": {
            "en": "Using a weighted k nearest neighbor model does not require that we set k equal to the size of the dataset, as we did in this example. It may be possible to find a value for kâ€”using evaluation experimentsâ€”that eliminates, or further reduces, the effect of the noise on the model. As is so often the case in machine learning, fitting the parameters of a model is as important as selecting which model to use.",
            "zh": "ä½¿ç”¨åŠ æƒ k æœ€è¿‘é‚»æ¨¡å‹ä¸éœ€è¦å°† k è®¾ç½®ä¸ºç­‰äºæ•°æ®é›†çš„å¤§å°ï¼Œå°±åƒæˆ‘ä»¬åœ¨æ­¤ç¤ºä¾‹ä¸­æ‰€åšçš„é‚£æ ·ã€‚ä½¿ç”¨è¯„ä¼°å®éªŒï¼Œå¯ä»¥æ‰¾åˆ°ä¸€ä¸ª k å€¼ï¼Œè¯¥å€¼å¯ä»¥æ¶ˆé™¤æˆ–è¿›ä¸€æ­¥å‡å°‘å™ªå£°å¯¹æ¨¡å‹çš„å½±å“ã€‚æ­£å¦‚æœºå™¨å­¦ä¹ ä¸­ç»å¸¸å‡ºç°çš„æƒ…å†µä¸€æ ·ï¼Œæ‹Ÿåˆæ¨¡å‹çš„å‚æ•°ä¸é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ä¸€æ ·é‡è¦ã€‚"
        }
    },
    {
        "translation": {
            "en": "There is more likelihood of Q-Learning choosing actions that do damage to equipment as random action selections made by a behavior policy coupled with a target policy favoring risky states could lead to the occasional disaster.",
            "zh": "Q-Learning æ›´æœ‰å¯èƒ½é€‰æ‹©å¯¹è®¾å¤‡é€ æˆæŸå®³çš„è¡ŒåŠ¨ï¼Œå› ä¸ºè¡Œä¸ºç­–ç•¥åšå‡ºçš„éšæœºè¡ŒåŠ¨é€‰æ‹©åŠ ä¸Šæœ‰åˆ©äºé£é™©çŠ¶æ€çš„ç›®æ ‡ç­–ç•¥å¯èƒ½ä¼šå¯¼è‡´å¶å°”çš„ç¾éš¾ã€‚"
        }
    },
    {
        "translation": {
            "en": "7.3.2â€ƒGradient Descent",
            "zh": "7.3.2 æ¢¯åº¦ä¸‹é™"
        }
    },
    {
        "translation": {
            "en": "13.2â€…â€…â€…Analysis of a subset of the features in the SDSS dataset.",
            "zh": "13.2 åˆ†æSDSSæ•°æ®é›†ä¸­ç‰¹å¾çš„å­é›†ã€‚"
        }
    },
    {
        "translation": {
            "en": "A selection of the logistic regression models developed during the gradient descent process for the extended generators dataset in Table 7.7[347]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "è¡¨7.7[347]ä¸­æ‰©å±•ç”Ÿæˆå™¨æ•°æ®é›†çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å¼€å‘çš„é€»è¾‘å›å½’æ¨¡å‹çš„é€‰æ‹©ã€‚å³ä¸‹è§’çš„é¢æ¿æ˜¾ç¤ºäº†æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚"
        }
    },
    {
        "translation": {
            "en": "Each time we add a link to a network, we increase the number of CPT entries in the network.",
            "zh": "æ¯æ¬¡æˆ‘ä»¬å‘ç½‘ç»œæ·»åŠ é“¾æ¥æ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šå¢åŠ ç½‘ç»œä¸­ CPT æ¡ç›®çš„æ•°é‡ã€‚"
        }
    },
    {
        "translation": {
            "en": "12. Note that in this figure, both the RPM and VIBRATION features have been normalized to the range [âˆ’1, 1] (using range normalization as described in Section 3.6.1[87]). It is standard practice to normalize descriptive features whenever we are using regression models to predict a categorical target feature.",
            "zh": "12. è¯·æ³¨æ„ï¼Œåœ¨æ­¤å›¾ä¸­ï¼ŒRPM å’Œ VIBRATION ç‰¹å¾éƒ½å·²å½’ä¸€åŒ–ä¸ºèŒƒå›´ [âˆ’1ï¼Œ 1]ï¼ˆä½¿ç”¨ç¬¬ 3.6.1 èŠ‚[87] ä¸­æè¿°çš„èŒƒå›´å½’ä¸€åŒ–ï¼‰ã€‚æ¯å½“æˆ‘ä»¬ä½¿ç”¨å›å½’æ¨¡å‹é¢„æµ‹åˆ†ç±»ç›®æ ‡ç‰¹å¾æ—¶ï¼Œè§„èŒƒåŒ–æè¿°æ€§ç‰¹å¾æ˜¯æ ‡å‡†åšæ³•ã€‚"
        }
    },
    {
        "translation": {
            "en": "In talking about reinforcement learning policies, it is worthwhile to distinguish between a behavior policy that an agent uses during learning and a target policy that an agent will use when deployed into the world after learning has taken place.",
            "zh": "åœ¨è®¨è®ºå¼ºåŒ–å­¦ä¹ ç­–ç•¥æ—¶ï¼Œæœ‰å¿…è¦åŒºåˆ†æ™ºèƒ½ä½“åœ¨å­¦ä¹ æœŸé—´ä½¿ç”¨çš„è¡Œä¸ºç­–ç•¥å’Œæ™ºèƒ½ä½“åœ¨å­¦ä¹ å‘ç”Ÿåéƒ¨ç½²åˆ°ä¸–ç•Œæ—¶å°†ä½¿ç”¨çš„ç›®æ ‡ç­–ç•¥ã€‚"
        }
    },
    {
        "translation": {
            "en": "For ease of reference, we have explicitly labeled a number of neurons in this architecture A, B, C, D, and E",
            "zh": "ä¸ºäº†ä¾¿äºå‚è€ƒï¼Œæˆ‘ä»¬åœ¨æ­¤æ¶æ„ä¸­æ˜ç¡®æ ‡è®°äº†è®¸å¤šç¥ç»å…ƒ Aã€Bã€Cã€D å’Œ E"
        }
    },
    {
        "translation": {
            "en": "In all cases, a prediction score (or scores) is produced, and a threshold process is used to convert this score into one of the levels of the target feature.",
            "zh": "åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œéƒ½ä¼šç”Ÿæˆä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰é¢„æµ‹åˆ†æ•°ï¼Œå¹¶ä½¿ç”¨é˜ˆå€¼è¿‡ç¨‹å°†æ­¤åˆ†æ•°è½¬æ¢ä¸ºç›®æ ‡è¦ç´ çš„çº§åˆ«ä¹‹ä¸€ã€‚"
        }
    },
    {
        "translation": {
            "en": "similarity-based learning, 19, 181",
            "zh": "åŸºäºç›¸ä¼¼æ€§çš„å­¦ä¹ ï¼Œ19,181"
        }
    },
    {
        "translation": {
            "en": "The difference between the mean and median values for the SKYIVAR_R feature also suggested the presence of outliers.",
            "zh": "SKYIVAR_Rç‰¹å¾çš„å¹³å‡å€¼å’Œä¸­ä½æ•°ä¹‹é—´çš„å·®å¼‚ä¹Ÿè¡¨æ˜å­˜åœ¨å¼‚å¸¸å€¼ã€‚"
        }
    },
    {
        "translation": {
            "en": "3.4.2â€ƒHandling Outliers",
            "zh": "3.4.2 å¤„ç†å¼‚å¸¸å€¼"
        }
    },
    {
        "translation": {
            "en": "One of the best known of these weight initialization regimes is called Xavier initialization.36 There are a number of variants of Xavier initialization used in practice, but the original version of Xavier initialization was designed for fully connected feedforward networks and worked on a layer-by-layer basis.",
            "zh": "36 åœ¨å®è·µä¸­ä½¿ç”¨äº†è®¸å¤š Xavier åˆå§‹åŒ–å˜ä½“ï¼Œä½† Xavier åˆå§‹åŒ–çš„åŸå§‹ç‰ˆæœ¬æ˜¯ä¸ºå®Œå…¨è¿æ¥çš„å‰é¦ˆç½‘ç»œè®¾è®¡çš„ï¼Œå¹¶ä¸”æ˜¯é€å±‚å·¥ä½œçš„ã€‚"
        }
    },
    {
        "translation": {
            "en": "This suggests that there is a strong, positive, linear relationship between the HEIGHT and WEIGHT featuresâ€”as height increases, so does weight.",
            "zh": "è¿™è¡¨æ˜ HEIGHT å’Œ WEIGHT ç‰¹å¾ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„æ­£çº¿æ€§å…³ç³»â€”â€”éšç€èº«é«˜çš„å¢åŠ ï¼Œä½“é‡ä¹Ÿä¼šå¢åŠ ã€‚"
        }
    }
]
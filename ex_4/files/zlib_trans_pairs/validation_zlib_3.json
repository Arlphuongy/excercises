[
    {
        "translation": {
            "en": "The standard algorithm for training a deep neural network combines the backpropagation algorithm (which solves the blame assignment problem) with stochastic gradient descent (which we use to update the weights in the network after blame has been assigned to each neuron).",
            "zh": "训练深度神经网络的标准算法将反向传播算法（解决责备分配问题）与随机梯度下降（我们用它来在将责备分配给每个神经元后更新网络中的权重）相结合。"
        }
    },
    {
        "translation": {
            "en": "The search process must now move to a new node (Lines 8, 9, 10, and 11). This move is determined by Line 8, which checks if the distance between the query and the hyperplane13 defined by the current node is less than the value of best-distance. In this case, however, the current node is a leaf node, so it does not define a hyperplane on the feature space. As a result, the condition checked in Line 8, fails and the search moves to the parent node of the current node (Line 11).",
            "zh": "搜索过程现在必须移动到新节点（第 8、9、10 和 11 行）。此移动由第 8 行确定，该行检查查询与当前节点定义的 hyperplane13 之间的距离是否小于 best-distance 的值。但是，在本例中，当前节点是叶节点，因此它不会在特征空间上定义超平面。因此，在第 8 行中检查的条件失败，搜索将移动到当前节点的父节点（第 11 行）。"
        }
    },
    {
        "translation": {
            "en": "The number of handsets the customer has had in the past 3 years",
            "zh": "客户在过去 3 年内拥有的手机数量"
        }
    },
    {
        "translation": {
            "en": "Blondlot, René. 1903. Sur une nouvelle action produite par les rayons n et sur plusieurs fait relatifs à ces radiations. Comptes Rendus de l’Académie des Sciences de Paris 137: 166–169.",
            "zh": "金发女郎，勒内。1903. Sur une nouvelle action produite par les rayons n et sur plusieurs fait relatifs à ces radiations.巴黎科学院 137：166-169。"
        }
    },
    {
        "translation": {
            "en": "In other words, countries that are relatively equal and that have good education and high life expectancy are likely to have a low level of corruption.",
            "zh": "换言之，相对平等、受过良好教育和预期寿命高的国家，腐败程度可能较低。"
        }
    },
    {
        "translation": {
            "en": "In the more likely case that the set containing three elements contains the solution, however, you may have to ask two more questions to uniquely identify the answer.",
            "zh": "但是，在包含三个元素的集合包含解决方案的更可能情况下，您可能需要再问两个问题才能唯一地标识答案。"
        }
    },
    {
        "translation": {
            "en": "Verify that the answers calculated in Parts (i) and (ii) of this question would have been the same if the alternative approach (basis functions or the polynomial kernel function) had been used in each case.",
            "zh": "验证如果在每种情况下都使用替代方法（基函数或多项式核函数），则本问题第 （i） 和 （ii） 部分中计算的答案是否相同。"
        }
    },
    {
        "translation": {
            "en": "Gini index, 145, 169, 174, 563",
            "zh": "基尼系数， 145， 169， 174， 563"
        }
    },
    {
        "translation": {
            "en": "The key things to remember, however, are that it is important to choose a similarity metric or index that is appropriate for the properties of the dataset we are using (be it binary, non-binary, sparse, covariant, etc.)",
            "zh": "然而，要记住的关键事项是，选择适合我们正在使用的数据集属性（无论是二进制、非二进制、稀疏、协变等）的相似度指标或索引非常重要。"
        }
    },
    {
        "translation": {
            "en": "8.23   The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with μ=0.0, σ=0.01.",
            "zh": "8.23 图8.22[450]中网络的内部动力学，在第一次训练迭代期间，当权重使用μ=0.0，σ=0.01的正态分布进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "The exponential distribution takes one parameter, λ, known as the rate.",
            "zh": "指数分布采用一个参数 λ，称为速率。"
        }
    },
    {
        "translation": {
            "en": "(a) Create a naive Bayes model that uses probability density functions to model the descriptive features in this dataset (assume that all the descriptive features are normally distributed).",
            "zh": "（a） 创建一个朴素贝叶斯模型，该模型使用概率密度函数对该数据集中的描述性特征进行建模（假设所有描述性特征都是正态分布的）。"
        }
    },
    {
        "translation": {
            "en": "Fundamentals of Machine Learning for Predictive Data Analytics",
            "zh": "预测数据分析的机器学习基础知识"
        }
    },
    {
        "translation": {
            "en": "Consequently, the predictions made by a nearest neighbor model are based on the full set of descriptive features in a dataset.",
            "zh": "因此，最近邻模型所做的预测基于数据集中的完整描述性特征集。"
        }
    },
    {
        "translation": {
            "en": "When this network is processing a set of external inputs, the inputs are presented to the network through sensing neurons in the input layer; this causes the neurons in the next layer to generate activation signals in response to these inputs; and these activations flow forward through the network until the output layer is reached, where the response of the network to the inputs is the activations of the neurons in this final output layer.",
            "zh": "当该网络处理一组外部输入时，这些输入通过输入层中的感应神经元呈现给网络;这导致下一层的神经元产生激活信号以响应这些输入;这些激活通过网络向前流动，直到到达输出层，其中网络对输入的响应是最终输出层中神经元的激活。"
        }
    },
    {
        "translation": {
            "en": "For example, INJURY TYPE has four levels.",
            "zh": "例如，INJURY TYPE 有四个级别。"
        }
    },
    {
        "translation": {
            "en": "10.4.2 Evaluating Clustering",
            "zh": "10.4.2 评估聚类"
        }
    },
    {
        "translation": {
            "en": "These concepts allow us to understand the standard approach to building similarity-based models: the nearest neighbor algorithm.",
            "zh": "这些概念使我们能够理解构建基于相似性的模型的标准方法：最近邻算法。"
        }
    },
    {
        "translation": {
            "en": "Note that throughout the rest of the chapter, we use uppercase letters to denote generic events where an unspecified feature (or set of features) is assigned a value (or set of values).",
            "zh": "请注意，在本章的其余部分，我们使用大写字母来表示为未指定的特征（或特征集）分配一个值（或一组值）的通用事件。"
        }
    },
    {
        "translation": {
            "en": "So, Q(0-3,left) is updated to:",
            "zh": "因此，Q（0-3，left） 更新为："
        }
    },
    {
        "translation": {
            "en": "Bayesian prediction is a very intuitive approach to predicting categorical targets. In order to make a prediction, we have to learn two things:",
            "zh": "贝叶斯预测是一种非常直观的预测分类目标的方法。为了做出预测，我们必须学习两件事："
        }
    },
    {
        "translation": {
            "en": "In some cases they learn a hard boundary between the classes; in other cases—such as logistic regression—they learn a soft boundary, which takes into account the distance from the boundary.",
            "zh": "在某些情况下，他们学习了班级之间的硬性界限;在其他情况下（例如逻辑回归），它们会学习一个软边界，该边界考虑了与边界的距离。"
        }
    },
    {
        "translation": {
            "en": "Table 8.15[471] is split into five segments with each segment containing information on Neurons 8, 9, and 10, and the calculations flow from the top of the table to the bottom.",
            "zh": "表8.15[471]被分成五个部分，每个部分包含神经元8、9和10的信息，计算从表格的顶部流向底部。"
        }
    },
    {
        "translation": {
            "en": "This is illustrated in Figure 11.9[672].",
            "zh": "如图11.9[672]所示。"
        }
    },
    {
        "translation": {
            "en": "However, larger and smaller filters are possible, and as filters become larger the number of neurons required to cover the input naturally gets smaller and vice versa.",
            "zh": "然而，更大和更小的过滤器是可能的，随着过滤器变大，覆盖输入所需的神经元数量自然会变小，反之亦然。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, this team was already using data from within the organization to choose which customers to target for intervention, which suggested that the team members were in a position to use predictive data analytics models.",
            "zh": "此外，该团队已经在使用来自组织内部的数据来选择干预目标客户，这表明团队成员能够使用预测数据分析模型。"
        }
    },
    {
        "translation": {
            "en": "Feature map 1 contains the 6 activations for the 6 neurons that applied Filter 1 to the input, and Feature map 2 contains the 6 activations for the 6 neurons that applied Filter 2 to the input.",
            "zh": "特征图 1 包含将过滤器 1 应用于输入的 6 个神经元的 6 次激活，特征图 2 包含将过滤器 2 应用于输入的 6 个神经元的 6 次激活。"
        }
    },
    {
        "translation": {
            "en": "There really isn’t an observation period in this case, as all descriptive features will be based on information provided by the applicant on the application form, rather than on observing the applicant’s behavior over time.4 The outcome period in this case is considered the period of the lifetime of the loan during which the applicant will have either fully repaid or defaulted on the loan.",
            "zh": "在这种情况下，实际上没有观察期，因为所有描述性特征都将基于申请人在申请表上提供的信息，而不是观察申请人随时间推移的行为.4 在这种情况下，结果期被认为是申请人将全额偿还或拖欠贷款的贷款期限。"
        }
    },
    {
        "translation": {
            "en": "Japkowicz, Nathalie, and Mohak Shah. 2011. Evaluating learning algorithms: A classification perspective. Cambridge University Press.",
            "zh": "Japkowicz、Nathalie 和 Mohak Shah。2011. 评估学习算法：分类视角.剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "Some features are particularly important in defining membership of certain clusters but not important for defining membership of others.",
            "zh": "某些功能在定义某些集群的成员资格时特别重要，但对于定义其他集群的成员资格并不重要。"
        }
    },
    {
        "translation": {
            "en": "Caruana, Rich, Nikos Karampatziakis, and Ainur Yessenalina. 2008. An empirical evaluation of supervised learning in high dimensions. In Proceedings of the 25th international conference on machine learning, 96–103. ACM.",
            "zh": "卡鲁阿纳、里奇、尼科斯·卡兰帕齐亚基斯和阿伊努尔·叶塞纳利娜。2008. 高维监督学习的实证评估.在第 25 届机器学习国际会议论文集，96–103。ACM。"
        }
    },
    {
        "translation": {
            "en": "The forward propagation of the activations through a simple recurrent network is defined as follows (where the subscript t denotes the time-step of the system; and there is one input per time-step—although this input may be a vector of values—and so the subscript t also defines the index in the input sequence of the current input):",
            "zh": "通过简单的循环网络的激活的前向传播定义如下（其中下标 t 表示系统的时间步长;每个时间步长有一个输入——尽管这个输入可能是值的向量——因此下标 t 还定义了当前输入的输入序列中的索引）："
        }
    },
    {
        "translation": {
            "en": "In Figure 4.2(b)[119] we reverse this order.",
            "zh": "在图4.2（b）[119]中，我们颠倒了这个顺序。"
        }
    },
    {
        "translation": {
            "en": "statistical significance test, 333",
            "zh": "统计显著性检验，333"
        }
    },
    {
        "translation": {
            "en": "Figure 8.15",
            "zh": "图 8.15"
        }
    },
    {
        "translation": {
            "en": "1.5   What Can Go Wrong with Machine Learning?",
            "zh": "1.5 机器学习会出什么问题？"
        }
    },
    {
        "translation": {
            "en": "13.5   SPLOM diagrams of (a) the EXPRAD; and (b) DEVRAD measurements from the raw SDSS dataset. Each SPLOM shows the measure across the five different photometric bands captured by the SDSS telescope (u, g, r, i, and z).",
            "zh": "13.5 （a） EXPRAD 的 SPLOM 图;（b）来自原始SDSS数据集的DEVRAD测量值。每个SPLOM都显示了SDSS望远镜捕获的五个不同光度波段（u，g，r，i和z）的测量值。"
        }
    },
    {
        "translation": {
            "en": "Features (both descriptive and target) are concrete numeric or symbolic representations of domain concepts.",
            "zh": "特征（描述性和目标性）是领域概念的具体数字或符号表示。"
        }
    },
    {
        "translation": {
            "en": "15. For convenience, we repeat Equation (3.7)[87] for range normalization",
            "zh": "15. 为方便起见，我们重复方程（3.7）[87]进行范围归一化"
        }
    },
    {
        "translation": {
            "en": "The data quality report in Table 3.3[57] and in Figure 3.1[58] allows us to very quickly become familiar with the central tendency and variation of each feature in the ABT.",
            "zh": "表3.3[57]和图3.1[58]中的数据质量报告使我们能够非常快速地熟悉ABT中每个特征的中心趋势和变化。"
        }
    },
    {
        "translation": {
            "en": "The first column in each weight matrix contains the weights for the bias terms, and so these columns have no label.",
            "zh": "每个权重矩阵中的第一列包含偏差项的权重，因此这些列没有标签。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn was surprised that none of the columns had any missing values.",
            "zh": "Jocelyn 惊讶地发现，没有一列有任何缺失值。"
        }
    },
    {
        "translation": {
            "en": "This can be made more obvious by including the correlation coefficients in SPLOMs in the cells above the diagonal.",
            "zh": "通过在对角线上方的单元格中包括 SPLOM 中的相关系数，可以使这一点更加明显。"
        }
    },
    {
        "translation": {
            "en": "Hebb’s Postulate, 404",
            "zh": "赫布假设，404"
        }
    },
    {
        "translation": {
            "en": "multi-label classification, 742",
            "zh": "多标签分类，742"
        }
    },
    {
        "translation": {
            "en": "These revised likelihoods are shown in Figure 6.2(b)[245].",
            "zh": "这些修正的可能性如图6.2（b）[245]所示。"
        }
    },
    {
        "translation": {
            "en": "Herculano-Houzel, Suzana. 2009. The human brain in numbers: A linearly scaled-up primate brain. Frontiers in Human Neuroscience 3: 31. doi:10.3389/neuro.09.031.2009.",
            "zh": "赫库拉诺-胡泽尔，苏珊娜。2009. 数字中的人类大脑：线性放大的灵长类动物大脑.人类神经科学前沿 3：31。doi：10.3389/neuro.09.031.2009."
        }
    },
    {
        "translation": {
            "en": "6.2.3 Conditional Independence and Factorization",
            "zh": "6.2.3 条件独立性和因式分解"
        }
    },
    {
        "translation": {
            "en": "22. This is very similar to the difference between Euclidean distance and Manhattan distance discussed in Section 5.2.2[184].",
            "zh": "22. 这与第5.2.2节[184]中讨论的欧几里得距离和曼哈顿距离之间的差异非常相似。"
        }
    },
    {
        "translation": {
            "en": "Mangasarian, Olvi L., and William H. Wolberg. 1990. Cancer diagnosis via linear programming. SIAM News 23 (5): 1–18.",
            "zh": "Mangasarian、Olvi L. 和 William H. Wolberg。1990. 通过线性规划进行癌症诊断.暹罗新闻23（5）：1-18。"
        }
    },
    {
        "translation": {
            "en": "There are many other action-selection policies that can be used together with temporal-difference learning.",
            "zh": "还有许多其他行动选择策略可以与时间差异学习一起使用。"
        }
    },
    {
        "translation": {
            "en": "A convolutional neural network was used as the action-value network.",
            "zh": "使用卷积神经网络作为动作值网络。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 7[476] provides a pseudocode definition of how the forward and backward passes of the backpropagation algorithm are modified to include inverted dropout.",
            "zh": "算法 7[476] 提供了一个伪代码定义，说明如何修改反向传播算法的前向和后向传递以包括反向丢失。"
        }
    },
    {
        "translation": {
            "en": "Table 10.4",
            "zh": "表 10.4"
        }
    },
    {
        "translation": {
            "en": "The k-means clustering approach is to be applied to this dataset with k = 2 and using Euclidean distance.",
            "zh": "k-means 聚类方法将应用于 k = 2 并使用欧几里得距离的数据集。"
        }
    },
    {
        "translation": {
            "en": "(a) A confusion matrix and the misclassification rate",
            "zh": "（a） 混淆矩阵和错误分类率"
        }
    },
    {
        "translation": {
            "en": "where c1 to ck are the centers of the k clusters, referred to as cluster centroids; and Dist is a distance measure used to compare instances to centroids. Algorithm 9[601] provides a pseudocode definition of the k-means clustering algorithm.1",
            "zh": "其中 c1 到 ck 是 k 个簇的中心，称为簇质心;Dist 是一种距离度量，用于将实例与质心进行比较。算法9[601]提供了k-means聚类算法的伪代码定义。"
        }
    },
    {
        "translation": {
            "en": "which gives an average of 1.3743. Based on these two average distances, 𝒞3 is the closest other cluster to d1 and so b(i) = 1.3743, as shown in Table 10.2[611]. The silhouette width for d1 is then calculated using Equation (10.2)[610]",
            "zh": "平均值为 1.3743。基于这两个平均距离，C3是最接近d1的其他聚类，因此b（i）= 1.3743，如表10.2[611]所示。然后使用公式（10.2）[610]计算d1的轮廓宽度"
        }
    },
    {
        "translation": {
            "en": "This is the clearest indication so far of the hierarchical nature of AHC, as a cluster created at a previous iteration of the algorithm will be merged into a larger cluster.",
            "zh": "这是迄今为止AHC层次结构性质的最明确指示，因为在算法的上一次迭代中创建的集群将被合并到更大的集群中。"
        }
    },
    {
        "translation": {
            "en": "A set of scatter plots illustrating the curse of dimensionality. Across (a), (b), and (c), the number of instances remains the same, so the density of the marked unit hypercubes decreases as the number of dimensions increases; (d) and (e) illustrate the cost we must incur, in terms of the number of extra instances required, if we wish to maintain the density of the instances in the feature space as its dimensionality increases.",
            "zh": "一组散点图，说明维度的诅咒。在 （a）、（b） 和 （c） 中，实例数保持不变，因此标记单元超立方体的密度随着维数的增加而降低;（d） 和 （e） 说明了如果我们希望在特征空间的维数增加时保持特征空间中实例的密度，我们必须承担的成本，即所需的额外实例数量。"
        }
    },
    {
        "translation": {
            "en": "11.2.4   The Bellman Equations",
            "zh": "11.2.4 贝尔曼方程"
        }
    },
    {
        "translation": {
            "en": "Potential prediction models (a) before and (b) after training data becomes available.",
            "zh": "潜在的预测模型 （a） 在训练数据可用之前和 （b） 之后。"
        }
    },
    {
        "translation": {
            "en": "For a given neuron to react, a specific visual feature had to occur at a particular location in the visual field; if the feature was moved to a different location in the visual field, then the neuron did not activate, nor did it activate if a different feature occurred at its target location.",
            "zh": "为了让给定的神经元做出反应，特定的视觉特征必须出现在视野中的特定位置;如果将特征移动到视野中的不同位置，则神经元不会激活，如果在其目标位置出现不同的特征，它也不会激活。"
        }
    },
    {
        "translation": {
            "en": "We can calculate the value of taking a particular action in a given state as the expected reward for taking the action plus the value of the state that the agent arrives in after taking that action.",
            "zh": "我们可以计算在给定状态下采取特定行动的价值，作为采取该行动的预期奖励加上代理在采取该行动后到达的状态的值。"
        }
    },
    {
        "translation": {
            "en": "maximum entropy model, 357",
            "zh": "最大熵模型，357"
        }
    },
    {
        "translation": {
            "en": "This parallelization of the processing of a number of examples by the network is particularly useful because the standard practice to train a network is to present batches of examples to the network, rather than to present examples one at a time.",
            "zh": "网络对多个示例的并行处理特别有用，因为训练网络的标准做法是向网络呈现成批的示例，而不是一次呈现一个示例。"
        }
    },
    {
        "translation": {
            "en": "16. The data in this question has been artificially created but is inspired by the Human Activity Recognition Using Smartphones Dataset first described by Anguita et al. (2013) and available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "16. 本问题中的数据是人为创建的，但受到 Anguita 等人（2013 年）首次描述的使用智能手机进行人类活动识别数据集的启发，可从 UCI 机器学习存储库（Bache 和 Lichman，2013 年）获得。"
        }
    },
    {
        "translation": {
            "en": "Likewise, the number of weights used in a linear regression model is defined by the number of descriptive features and is independent of the number of instances in the training data.",
            "zh": "同样，线性回归模型中使用的权重数由描述性特征的数量定义，并且与训练数据中的实例数无关。"
        }
    },
    {
        "translation": {
            "en": "En masse all the questions that must be answered to successfully complete a predictive data analytics project can seem overwhelming. This is why we recommend using the CRISP-DM process to manage a project through its lifecycle. Table 14.1[730] shows the alignment between the phases of CRISP-DM, some of the key questions that must be answered during a predictive data analytics project, and the chapters in this book dealing with these questions.",
            "zh": "要成功完成预测性数据分析项目，必须回答的所有问题似乎都让人不知所措。这就是为什么我们建议使用 CRISP-DM 流程来管理项目的整个生命周期。表14.1[730]显示了CRISP-DM各阶段之间的一致性，预测数据分析项目中必须回答的一些关键问题，以及本书中处理这些问题的章节。"
        }
    },
    {
        "translation": {
            "en": "Covariance is measured in the same units as the features that it measures.",
            "zh": "协方差的度量单位与协方差所测定的特征相同。"
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] showed how the chain of products used to backpropagate an error gradient through a network of three neurons (i, j, and k) expands.",
            "zh": "公式 8.41[436] 显示了用于通过三个神经元（i、j 和 k）网络反向传播误差梯度的产物链如何扩展。"
        }
    },
    {
        "translation": {
            "en": "To do this we need a formal measure of how well a descriptive feature discriminates between the levels of the target feature.",
            "zh": "为此，我们需要一个正式的度量，来衡量描述性特征在目标特征级别之间的区分程度。"
        }
    },
    {
        "translation": {
            "en": "This is not true of all prediction models.",
            "zh": "并非所有预测模型都是如此。"
        }
    },
    {
        "translation": {
            "en": "In a parametric model the size of the domain representation (i.e., the number of parameters) is independent of the number of instances in the dataset.",
            "zh": "在参数化模型中，域表示的大小（即参数数）与数据集中的实例数无关。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the weights in the network were sampled from a normal distribution with μ = 0.0 and σ = 0.01, and therefore the weights in each layer have a variance of var(W) = σ2 = 0.012 = 0.0001.",
            "zh": "此外，网络中的权重是从 μ = 0.0 和 σ = 0.01 的正态分布中采样的，因此每层中的权重具有 var（W） = σ2 = 0.012 = 0.0001 的方差。"
        }
    },
    {
        "translation": {
            "en": "However, in 1969 Marvin Minsky and Seymour Papert published a book entitled Perceptrons that was highly critical of neural networks and in particular focused on the fact that single-layer networks (perceptrons) were not able to represent non-linearly separable functions (Minsky and Papert, 1969).",
            "zh": "然而，在1969年，Marvin Minsky和Seymour Papert出版了一本名为《感知器》的书，该书对神经网络提出了高度批评，并特别关注了单层网络（感知器）无法表示非线性可分离函数的事实（Minsky和Papert，1969）。"
        }
    },
    {
        "translation": {
            "en": "When missing indicator features are used, the original feature is usually discarded.",
            "zh": "当使用缺少指标特征时，通常会丢弃原始特征。"
        }
    },
    {
        "translation": {
            "en": "For clarity, some additional notational conventions are used in Chapter 8[381] on deep learning.",
            "zh": "为了清楚起见，在关于深度学习的第8章[381]中使用了一些额外的符号约定。"
        }
    },
    {
        "translation": {
            "en": "LNLDEV_U/G/R/I/Z",
            "zh": "LNLDEV_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "11. This dataset has been artificially created for this book, but machine learning has been used for this task, for example, by Mishne and Glance (2006).",
            "zh": "11. 这个数据集是为本书人为创建的，但机器学习已被用于这项任务，例如，Mishne 和 Glance （2006）。"
        }
    },
    {
        "translation": {
            "en": "The depth of a network is measured by the number of layers of neurons within the network.",
            "zh": "网络的深度是通过网络内神经元的层数来衡量的。"
        }
    },
    {
        "translation": {
            "en": "As we proceed through the steps of calculating the δs for each of the neurons, we will need to calculate the ∂a/∂z term for each neuron, and so for ease of reference, Table 8.5[428] lists this value for each neuron; for space and convenience considerations we have rounded these values to four decimal places and used the rounded values in our calculations.",
            "zh": "当我们继续计算每个神经元的 δs 时，我们需要计算每个神经元的 ∂a/∂z 项，因此为了便于参考，表 8.5[428] 列出了每个神经元的此值;出于空间和方便的考虑，我们将这些值四舍五入到小数点后四位，并在计算中使用四舍五入的值。"
        }
    },
    {
        "translation": {
            "en": "4.15   A simple bicycle demand predictions dataset and the workings of the first iterations of training a gradient boosting model.",
            "zh": "4.15 一个简单的自行车需求预测数据集和训练梯度提升模型的第一次迭代的工作原理。"
        }
    },
    {
        "translation": {
            "en": "7.6   A selection of the simple linear regression models developed during the gradient descent process for the office rentals dataset. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.6 在办公室租赁数据集的梯度下降过程中开发的简单线性回归模型的选择。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "feature selection, 94, 181, 227, 227, 232, 614, 722, 740",
            "zh": "特征选择、94、181、227、227、232、614、722、740"
        }
    },
    {
        "translation": {
            "en": "This last term illustrates an intermediate behavior in the forget gate in which the original cell state is half-forgotten/half-retained.",
            "zh": "最后一项说明了遗忘门中的一种中间行为，其中原始细胞状态被半遗忘/半保留。"
        }
    },
    {
        "translation": {
            "en": "Usually the outputs from the unsupervised work are consumed in a supervised machine learning task, or another unsupervised machine learning task.",
            "zh": "通常，无监督工作的输出在有监督的机器学习任务或其他无监督的机器学习任务中使用。"
        }
    },
    {
        "translation": {
            "en": "Finally, the model assumes that a convergence criterion has been specified.17 Early stopping is the most popular strategy used to define a convergence criterion; we explain the early stopping algorithm in Section 8.4.4[472].",
            "zh": "最后，该模型假设已经指定了收敛标准.17 提前停止是用于定义收敛标准的最流行策略;我们在第8.4.4节[472]中解释了早期停止算法。"
        }
    },
    {
        "translation": {
            "en": "Table 9.19[574] shows the associated confusion matrix for these predictions, including measures of precision and recall.",
            "zh": "表9.19[574]显示了这些预测的相关混淆矩阵，包括精确度和召回率的测量。"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions for a bacterial species identification problem.",
            "zh": "具有细菌物种识别问题的模型预测的样本测试集。"
        }
    },
    {
        "translation": {
            "en": "Over time, we can expect the table to converge toward optimal values.",
            "zh": "随着时间的流逝，我们可以预期该表将收敛到最佳值。"
        }
    },
    {
        "translation": {
            "en": "5.3 Standard Approach: The Nearest Neighbor Algorithm",
            "zh": "5.3 标准方法：最近邻算法"
        }
    },
    {
        "translation": {
            "en": "We use range normalization to convert a feature value into the range [low, high] as follows:",
            "zh": "我们使用范围归一化将特征值转换为范围 [low， high]，如下所示："
        }
    },
    {
        "translation": {
            "en": "The following table shows summary statistics of the four descriptive features for each of the three clusters found.",
            "zh": "下表显示了找到的三个聚类中每个聚类的四个描述性特征的汇总统计量。"
        }
    },
    {
        "translation": {
            "en": "Decision tree models can be used for datasets that contain both categorical and continuous descriptive features.",
            "zh": "决策树模型可用于同时包含分类和连续描述性特征的数据集。"
        }
    },
    {
        "translation": {
            "en": "The most common form of polynomial relationship is the second order polynomial, also known as the quadratic function, which takes the general form a = bx + cx2.",
            "zh": "多项式关系最常见的形式是二阶多项式，也称为二次函数，其一般形式为 a = bx + cx2."
        }
    },
    {
        "translation": {
            "en": "upper quartile, 749, 755",
            "zh": "上四分位数， 749， 755"
        }
    },
    {
        "translation": {
            "en": "However, once we introduce one or more hidden layers into a network, it becomes more difficult to use the gradient descent algorithm to train the network.",
            "zh": "然而，一旦我们在网络中引入一个或多个隐藏层，使用梯度下降算法来训练网络就变得更加困难。"
        }
    },
    {
        "translation": {
            "en": "Techniques such as the k-d tree can help with this issue by creating a fast index at the cost of some preprocessing.",
            "zh": "像 k-d 树这样的技术可以通过以一些预处理为代价创建一个快速索引来帮助解决这个问题。"
        }
    },
    {
        "translation": {
            "en": "We use ⊙ to denote an elementwise product. This operation is sometimes called the Hadamard product.",
            "zh": "我们用⊙来表示一个元素乘积。此操作有时称为 Hadamard 产品。"
        }
    },
    {
        "translation": {
            "en": "Consequently, at the end of the processing of the mini-batch (i.e., when the algorithm exits the for loop from Line 15[420] to Line 27[420]), Δw i,k will contain the weight updates for weight wi,k summed across all the examples in the mini-batch.",
            "zh": "因此，在小批量处理结束时（即，当算法退出从第 15 行 [420] 到第 27 行 [420] 的 for 循环时），Δw i，k 将包含小批量中所有示例的权重 wi，k 的权重更新。"
        }
    },
    {
        "translation": {
            "en": "5. This size of margin of error is common for these types of election polls.",
            "zh": "5. 这种误差幅度对于这些类型的选举民意调查很常见。"
        }
    },
    {
        "translation": {
            "en": "The dataset is visualized in Figure 4.21(a)[163].",
            "zh": "数据集如图4.21（a）[163]所示。"
        }
    },
    {
        "translation": {
            "en": "10.3 Standard Approach: The k-Means Clustering Algorithm",
            "zh": "10.3 标准方法：k-Means 聚类算法"
        }
    },
    {
        "translation": {
            "en": "P(q[1],…,q[m]) can be calculated as the relative frequency in a dataset of the joint event that the descriptive features of an instance take on the values q[1],…,q[m].",
            "zh": "P（q[1],...,q[m]） 可以计算为实例的描述性特征对值 q[1],...,q[m] 的联合事件数据集中的相对频率。"
        }
    },
    {
        "translation": {
            "en": "model ensemble, xvi, 158, 170, 178, 476, 733",
            "zh": "模型合奏， xvi， 158， 170， 178， 476， 733"
        }
    },
    {
        "translation": {
            "en": "13.1   The structure of the SDSS and Galaxy Zoo combined dataset.",
            "zh": "13.1 SDSS和Galaxy Zoo组合数据集的结构。"
        }
    },
    {
        "translation": {
            "en": "The averageclassaccuracyHM performance measure can be applied to multinomial prediction problems and is an effective option for measuring performance.",
            "zh": "averageclassaccuracyHM 性能度量可应用于多项式预测问题，是衡量性能的有效选项。"
        }
    },
    {
        "translation": {
            "en": "D.3   Multiplication",
            "zh": "D.3 乘法"
        }
    },
    {
        "translation": {
            "en": "Shannon, Claude E., and Warren Weaver. 1949. The mathematical theory of communication. University of Illinois Press.",
            "zh": "香农、克劳德 E. 和沃伦韦弗。1949. 通信的数学理论。伊利诺伊大学出版社。"
        }
    },
    {
        "translation": {
            "en": "The δ term for a neuron describes the rate of change of the error (i.e., the error gradient) of the network with respect to changes in the weighted sum calculated by the neuron. Using ℰ to represent the error of the network at the output layer, and zk to denote the weighted sum calculation in neuron k, the δ for a neuron k can be mathematically defined",
            "zh": "神经元的δ术语描述了网络误差（即误差梯度）相对于神经元计算的加权和变化的变化率。使用 E 表示输出层网络的误差，使用 zk 表示神经元 k 中的加权和计算，可以用数学方式定义神经元 k 的δ"
        }
    },
    {
        "translation": {
            "en": "7.15   A selection of the logistic regression models developed during the gradient descent process for the extended generators dataset in Table 7.7[347]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "7.15 表7.7[347]中扩展生成器数据集的梯度下降过程中开发的逻辑回归模型的选择。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Box plots, however, can be placed side by side, and in Section 3.5.1.2[74] we see that the ability to place multiple box plots side by side is the main advantage box plots have over histograms.",
            "zh": "然而，箱形图可以并排放置，在第 3.5.1.2 节[74]中，我们看到并排放置多个箱形图的能力是箱形图相对于直方图的主要优势。"
        }
    },
    {
        "translation": {
            "en": "The variance of a sample is a more useful measure of variation. Variance measures the average difference between each value in a sample and the mean of that sample. The variance of the n values of a feature a is denoted var(a) and is calculated as",
            "zh": "样本的方差是更有用的变异度量。方差测量样本中每个值与该样本的平均值之间的平均差值。特征 a 的 n 个值的方差表示为 var（a），计算公式为"
        }
    },
    {
        "translation": {
            "en": "Figure 5.9(a)[199] shows the complete k-d tree generated for the dataset, and Figure 5.9(b)[199] shows the partitioning of the feature space as defined by the k-d tree.",
            "zh": "图5.9（a）[199]显示了为数据集生成的完整k-d树，图5.9（b）[199]显示了k-d树定义的特征空间的分区。"
        }
    },
    {
        "translation": {
            "en": "7.5   The office rentals dataset from Table 7.1[313] adjusted to handle the categorical ENERGY RATING descriptive feature in linear regression models.",
            "zh": "7.5 对表7.1[313]中的写字楼租赁数据集进行了调整，以处理线性回归模型中的分类ENERGY RATING描述性特征。"
        }
    },
    {
        "translation": {
            "en": "4. Select one of the predictive analytics models that you proposed in your answer to Question 2 about the revenue commission for exploration of the design of its analytics base table (ABT).",
            "zh": "4. 选择您在回答有关收入佣金的问题 2 时提出的预测分析模型之一，以探索其分析基表 （ABT） 的设计。"
        }
    },
    {
        "translation": {
            "en": "In this figure a σ represents a layer of neurons that use a sigmoid activation function, a T represents a layer of neurons that use a tanh activation function, the ⊙ symbols represent elementwise vector multiplication (i.e., the Hadamard product), and + represents an elementwise vector addition operation.",
            "zh": "在此图中，σ 表示使用 sigmoid 激活函数的神经元层，T 表示使用 tanh 激活函数的神经元层，⊙ 符号表示元素向量乘法（即 Hadamard 积），+ 表示元素向量加法运算。"
        }
    },
    {
        "translation": {
            "en": "paperclip maximizer, 677",
            "zh": "回形针最大化器，677"
        }
    },
    {
        "translation": {
            "en": "When the algorithm was used to generate 500 samples, the relative frequency of CPI = high was 0.196.",
            "zh": "当该算法生成500个样本时，CPI=高的相对频率为0.196。"
        }
    },
    {
        "translation": {
            "en": "We can also use the confusion matrix to begin to investigate the kinds of mistakes that the prediction model is making.",
            "zh": "我们还可以使用混淆矩阵开始研究预测模型所犯的错误类型。"
        }
    },
    {
        "translation": {
            "en": "This discussion highlights that entropy is essentially a measure of the heterogeneity of a set. As the composition of the sets changed from the set with only one type of element (Figure 4.5(a)[124]) to a set with many different types of elements, each with an equal likelihood of being selected (Figure 4.5(f)[124]), the entropy score for the sets increased.",
            "zh": "这个讨论强调熵本质上是对集合异质性的度量。随着集合的组成从只有一种元素的集合（图4.5（a）[124]）变为具有许多不同类型元素的集合，每个元素被选中的可能性相等（图4.5（f）[124]），集合的熵得分增加。"
        }
    },
    {
        "translation": {
            "en": "5.4.4 Predicting Continuous Targets",
            "zh": "5.4.4 预测连续目标"
        }
    },
    {
        "translation": {
            "en": "k-means clustering, 597, 600, 601, 624, 629, 631, 636, 740",
            "zh": "k 均值聚类， 597， 600， 601， 624， 629， 631， 636， 740"
        }
    },
    {
        "translation": {
            "en": "So, for example, if we are trying to predict whether or not insurance claims are fraudulent, we require a large dataset of historical insurance claims, and for each one we must know whether or not that claim was found to be fraudulent.",
            "zh": "因此，例如，如果我们试图预测保险索赔是否具有欺诈性，我们需要一个大型的历史保险索赔数据集，对于每个索赔，我们必须知道该索赔是否被发现是欺诈性的。"
        }
    },
    {
        "translation": {
            "en": "This contrasts with the hold-out sampling design, in which we simply deploy the model that has been evaluated.",
            "zh": "这与保持抽样设计形成鲜明对比，在保留抽样设计中，我们只需部署已评估的模型。"
        }
    },
    {
        "translation": {
            "en": "rectifier, 386",
            "zh": "整流器，386"
        }
    },
    {
        "translation": {
            "en": "brute-force search, 318",
            "zh": "暴力搜索，318"
        }
    },
    {
        "translation": {
            "en": "This advantage should not be underestimated.",
            "zh": "这一优势不容小觑。"
        }
    },
    {
        "translation": {
            "en": "A domain concept is a high-level abstraction that describes some characteristic of the prediction subject from which we derive a set of concrete features that will be included in an ABT.",
            "zh": "领域概念是一个高级抽象，它描述了预测主题的某些特征，我们从中推导出一组将包含在 ABT 中的具体特征。"
        }
    },
    {
        "translation": {
            "en": "This means that its activation does not flow forward through the network, and hence it has no effect on the output of the model.",
            "zh": "这意味着它的激活不会通过网络向前流动，因此它对模型的输出没有影响。"
        }
    },
    {
        "translation": {
            "en": "In the raw data, customers who did not churn outnumber those who churned at a ratio of over 10 to 1.",
            "zh": "在原始数据中，没有流失的客户数量超过了流失的客户数量，比例超过 10：1。"
        }
    },
    {
        "translation": {
            "en": "scatter plot matrix, 74, 84, 103",
            "zh": "散点图矩阵，74、84、103"
        }
    },
    {
        "translation": {
            "en": "On other occasions she would take a series of successful steps but then experience a sinking feeling realizing that she had turned back on herself and arrived back on the starting bank.",
            "zh": "在其他情况下，她会采取一系列成功的步骤，但随后会经历一种沉沦的感觉，意识到她已经背弃了自己，回到了起点。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.72)[467] uses the chain rule to make this explicit by defining δk as the product of the rate of change of the negative natural log of the predicted probability of the true category with respect to changes in that probability and the rate of change of the predicted probability of the true category with respect to changes in the logit (we encountered this expansion step previously in a different guise; recall that ∂ℰ/∂zk = ∂ℰ/∂ak × ∂ak/∂zk).",
            "zh": "方程（8.72）[467]使用链式法则来明确这一点，将δk定义为真实类别的预测概率的负自然对数相对于该概率变化的变化率的乘积，以及真实类别的预测概率相对于logit变化的变化率（我们以前以不同的形式遇到过这个扩展步骤;回想一下∂E/∂zk = ∂E/∂ak × ∂ak/∂zk）。"
        }
    },
    {
        "translation": {
            "en": "Each row represents a fold in the process, in which the black rectangles indicate the instance that is used for testing while the white spaces indicate the data used for training.",
            "zh": "每行表示流程中的一个折叠，其中黑色矩形表示用于测试的实例，而空白表示用于训练的数据。"
        }
    },
    {
        "translation": {
            "en": "The alternative is to define active customers as any customer in the AT data that was active at some point.",
            "zh": "另一种方法是将活动客户定义为 AT 数据中在某个时间点处于活动状态的任何客户。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.1(b)[314] shows the same scatter plot as shown in Figure 7.1(a)[314] with a simple linear model added to capture the relationship between office sizes and office rental prices.",
            "zh": "图7.1（b）[314]显示了与图7.1（a）[314]相同的散点图，并添加了一个简单的线性模型来捕捉办公室规模与办公室租金价格之间的关系。"
        }
    },
    {
        "translation": {
            "en": "descriptive features, 5, 19, 23, 28, 598, 688",
            "zh": "描述性特征， 5， 19， 23， 28， 598， 688"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6(a)[275] illustrates the profile typical of data with multiple subpopulations.",
            "zh": "图6.6（a）[275]说明了具有多个子群体的数据的典型概况。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.36[498] provides a worked example of data processing and flow through a convolutional network similar in structure to the architecture blueprint shown in Figure 8.35[497].",
            "zh": "图 8.36[498] 提供了一个通过卷积网络进行数据处理和流动的工作示例，其结构类似于图 8.35[497] 所示的架构蓝图。"
        }
    },
    {
        "translation": {
            "en": "Retaining the Markov assumption that only the current time-step is required to model what will happen next, the probability of transitioning to a particular state depends only on the current state and the action just taken. Each transition to a new state based on a particular action now also carries with it a reward",
            "zh": "保留马尔可夫假设，即只需要当前时间步长来模拟接下来会发生什么，过渡到特定状态的概率仅取决于当前状态和刚刚采取的行动。现在，每次基于特定操作过渡到新状态时，都会带来奖励"
        }
    },
    {
        "translation": {
            "en": "In Section 8.2.5[395] we discuss how the depth of a neural network affects the ability of the network to represent and learn functions at different levels of complexity.",
            "zh": "在第 8.2.5 节[395]中，我们讨论了神经网络的深度如何影响网络在不同复杂程度下表示和学习函数的能力。"
        }
    },
    {
        "translation": {
            "en": "Rubin, Daniel J. 2015. Hospital readmission of patients with diabetes. Current Diabetes Reports 15 (4): 17.",
            "zh": "鲁宾，丹尼尔 J. 2015 年。糖尿病患者再入院。当前糖尿病报告15（4）：17。"
        }
    },
    {
        "translation": {
            "en": "hamming distance, 240",
            "zh": "汉明距离，240"
        }
    },
    {
        "translation": {
            "en": "area under the curve, 561, 590",
            "zh": "曲线下面积，561,590"
        }
    },
    {
        "translation": {
            "en": "6.6   Further Reading",
            "zh": "6.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "As with the schematic on the left of Figure 8.37[502], this figure abstracts over some of the details of the network.",
            "zh": "与图8.37[502]左侧的原理图一样，该图抽象了网络的一些细节。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics projects use machine learning to build models that capture the relationships in large datasets between descriptive features and a target feature.",
            "zh": "预测数据分析项目使用机器学习来构建模型，以捕获大型数据集中描述性要素与目标要素之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Distance matrices that detail the first three iterations of the AHC algorithm applied to the reduced version of the mobile phone customer dataset in Table 10.1[604].",
            "zh": "详细描述AHC算法前三次迭代的距离矩阵，应用于表10.1[604]中移动电话客户数据集的精简版本。"
        }
    },
    {
        "translation": {
            "en": "citizen science, 708",
            "zh": "公民科学，708"
        }
    },
    {
        "translation": {
            "en": "Information-based learning (Chapter 4[117])",
            "zh": "信息化学习（第4章[117]）"
        }
    },
    {
        "translation": {
            "en": "Other, more sophisticated sampling methods can be used to ensure that a sample maintains relationships that exist in a population.",
            "zh": "可以使用其他更复杂的抽样方法来确保样本保持总体中存在的关系。"
        }
    },
    {
        "translation": {
            "en": "(short)” defines a one-semester course.",
            "zh": "（短）“定义了一个学期的课程。"
        }
    },
    {
        "translation": {
            "en": "This is very similar to the hard threshold function given in Equation (7.24)[341], except that it has a soft boundary.",
            "zh": "这与公式（7.24）[341]中给出的硬阈值函数非常相似，只是它有一个软边界。"
        }
    },
    {
        "translation": {
            "en": "The first step in building the decision tree is to determine which of the three descriptive features is the best one to split the dataset on at the root node. The algorithm does this by computing the information gain for each feature. The total entropy for this dataset, which is required to calculate information gain, is computed",
            "zh": "构建决策树的第一步是确定三个描述性特征中的哪一个最适合在根节点上拆分数据集。该算法通过计算每个特征的信息增益来实现此目的。计算此数据集的总熵（计算信息增益所需的熵）"
        }
    },
    {
        "translation": {
            "en": "1,450,500",
            "zh": "1,450,500"
        }
    },
    {
        "translation": {
            "en": "simple random sample, 751",
            "zh": "简单随机样本，751"
        }
    },
    {
        "translation": {
            "en": "Each of these historical examples must contain sufficient data to describe the scenario and the outcome that we are interested in predicting.",
            "zh": "这些历史示例中的每一个都必须包含足够的数据来描述我们有兴趣预测的场景和结果。"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix for a simple prediction task with two target levels is shown in Table 9.2[538].",
            "zh": "具有两个目标水平的简单预测任务的混淆矩阵结构如表9.2[538]所示。"
        }
    },
    {
        "translation": {
            "en": "Table 9.16[568] shows the cumulative lift for each decile for the predictions shown in Table 9.11[557] for the email classification problem, and these values are plotted in a cumulative lift curve in Figure 9.16(b)[570].",
            "zh": "表9.16[568]显示了表9.11[557]中针对电子邮件分类问题的预测，每个十分位数的累积提升，这些值绘制在图9.16（b）[570]中的累积提升曲线中。"
        }
    },
    {
        "translation": {
            "en": "11.2   Fundamentals",
            "zh": "11.2 基础"
        }
    },
    {
        "translation": {
            "en": "Consequently, if we are designing a filter to process a color image, with three color channels (red, green, and blue), we can vary the height and width dimensions of the filter, but the depth dimension must be 3.",
            "zh": "因此，如果我们设计一个滤镜来处理彩色图像，具有三个颜色通道（红色、绿色和蓝色），我们可以改变滤镜的高度和宽度尺寸，但深度维度必须为 3。"
        }
    },
    {
        "translation": {
            "en": "Or three payments in a six-month period?",
            "zh": "还是在六个月内支付三笔款项？"
        }
    },
    {
        "translation": {
            "en": "10.13   (a) A plot of the hierarchical grouping of the instances in the mobile phone customer dataset from Table 10.1[604] found by the AHC algorithm (using Euclidean distance and single linkage). (b) The clustering returned when the tree is cut at k = 3. (c) The clustering returned when the tree is cut at k = 6.",
            "zh": "10.13 （a） AHC算法（使用欧几里得距离和单链接）找到的表10.1[604]中移动电话客户数据集中实例的分层图。（b） 当树木在k = 3时被砍伐时返回的聚类。（c） 在k = 6时砍伐树木时返回的聚类。"
        }
    },
    {
        "translation": {
            "en": "In fact, Neuron B has the highest activation for any of the neurons in the local receptive field of Neuron C. This means that δA = 0 because Neuron A did not have the maximum value in the local receptive field of the sub-sampling neuron to which it is connected.",
            "zh": "事实上，神经元 B 在神经元 C 的局部感受野中具有最高的激活度。这意味着 δA = 0，因为神经元 A 在它所连接的子采样神经元的局部感受野中没有最大值。"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean is defined as follows:",
            "zh": "谐波均值定义如下："
        }
    },
    {
        "translation": {
            "en": "Because the same process is used to calculate ∂ak/∂zk for all neurons we describe this process first, and then we describe how the ∂ℰ/∂ak term is calculated for output neurons and then for hidden neurons.",
            "zh": "由于使用相同的过程来计算所有神经元的 ∂ak/∂zk，因此我们首先描述此过程，然后描述如何计算输出神经元的 ∂E/∂ak 项，然后计算隐藏神经元。"
        }
    },
    {
        "translation": {
            "en": "For example, for a weighted sum calculation over two inputs we require two predefined weights.",
            "zh": "例如，对于两个输入的加权和计算，我们需要两个预定义的权重。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.69)[467] is a restatement of Equation (8.13)[408], which provides the general definition of the δ for a neuron k as the partial derivative for the error (or loss) of the network with respect to the weighted sum of neuron k: ∂ℰ/∂zk.",
            "zh": "方程（8.69）[467]是方程（8.13）[408]的重述，它提供了神经元k的δ的一般定义，即网络相对于神经元k加权和的误差（或损失）的偏导数：∂E/∂zk。"
        }
    },
    {
        "translation": {
            "en": "data manipulation, 42",
            "zh": "数据操作，42"
        }
    },
    {
        "translation": {
            "en": "An agent’s current state is often modeled as a random variable, St. We therefore often describe the probability that an agent is in a specific state, s, at time t as P(St = s).",
            "zh": "因此，我们经常将智能体在时间 t 处于特定状态 s 的概率描述为 P（St = s）。"
        }
    },
    {
        "translation": {
            "en": "For a longer two-semester machine learning course (“M.L.",
            "zh": "对于更长的两学期机器学习课程（“M.L."
        }
    },
    {
        "translation": {
            "en": "8.7   A single-layer network.",
            "zh": "8.7 单层网络。"
        }
    },
    {
        "translation": {
            "en": "There are also extensions to handle categorical descriptive features (similar to the approach described in Section 7.4.3[336]) and continuous target features.",
            "zh": "还有一些扩展用于处理分类描述性特征（类似于第 7.4.3 节[336] 中描述的方法）和连续目标特征。"
        }
    },
    {
        "translation": {
            "en": "Typically, the level that is of most interest is referred to as the positive level.",
            "zh": "通常，最感兴趣的水平称为正水平。"
        }
    },
    {
        "translation": {
            "en": "The revised domain concepts diagram for the galaxy classification task.",
            "zh": "星系分类任务的修订域概念图。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.13(b)[623] shows the tree cut for three clusters and the resultant clustering, and Figure 10.13(c)[623] shows the same illustrations for six clusters.",
            "zh": "图10.13（b）[623]显示了三个聚类的砍伐和由此产生的聚类，图10.13（c）[623]显示了六个聚类的相同图示。"
        }
    },
    {
        "translation": {
            "en": "In Section 7.2.3[317] we said that the best-fit set of weights for a linear regression model can be found at the global minimum of the error surface defined by the weight space associated with the relevant training dataset.",
            "zh": "在第 7.2.3 节[317]中，我们说过，线性回归模型的最佳拟合权重集可以在误差面的全局最小值处找到，该误差面由与相关训练数据集关联的权重空间定义。"
        }
    },
    {
        "translation": {
            "en": "We use the median value as the splitting threshold because it is less susceptible to the influence of outliers than the mean, and this helps keep the tree as balanced as possible—having a balanced tree helps with the efficiency in retrieval.",
            "zh": "我们使用中值作为拆分阈值，因为它比均值更不容易受到异常值的影响，这有助于尽可能保持树的平衡——拥有平衡的树有助于提高检索效率。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.6",
            "zh": "图 13.6"
        }
    },
    {
        "translation": {
            "en": "irregular cardinality, 63, 65, 94",
            "zh": "不规则基数，63,65,94"
        }
    },
    {
        "translation": {
            "en": "This threshold is nothing more than a number that is selected by the designer of the artificial neuron.",
            "zh": "这个阈值只不过是人工神经元设计者选择的一个数字。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.8",
            "zh": "图 7.8"
        }
    },
    {
        "translation": {
            "en": "We can insert these probabilities into the application of Bayes’ Theorem to give",
            "zh": "我们可以将这些概率代入贝叶斯定理的应用中，以给出"
        }
    },
    {
        "translation": {
            "en": "The calculations in the input gate are defined by the following equations:",
            "zh": "输入门中的计算由以下公式定义："
        }
    },
    {
        "translation": {
            "en": "Table 5.1",
            "zh": "表 5.1"
        }
    },
    {
        "translation": {
            "en": "8.7   Exercises",
            "zh": "8.7 练习"
        }
    },
    {
        "translation": {
            "en": "The values above zero seem to follow something close to a wide normal distribution, and the large number of, albeit valid, zero values account for the unusual minimum, 1st quartile, and median values.",
            "zh": "高于零的值似乎遵循接近宽正态分布的东西，并且大量（尽管有效）零值解释了不寻常的最小值、第一个四分位数和中位数值。"
        }
    },
    {
        "translation": {
            "en": "The optimal decision boundary and associated support vectors for the example we have been following are shown in Figure 7.23(b)[364].",
            "zh": "图7.23（b）[364]显示了我们所遵循的示例的最佳决策边界和相关支持向量。"
        }
    },
    {
        "translation": {
            "en": "astronomy, 703",
            "zh": "天文学，703"
        }
    },
    {
        "translation": {
            "en": "The fact that the SDSS and Galaxy Zoo make all their data available for free online is a massive contribution to global science.",
            "zh": "事实上，SDSS和银河动物园免费在线提供所有数据，这是对全球科学的巨大贡献。"
        }
    },
    {
        "translation": {
            "en": "Figure 1.4[16] also illustrates the flow between each of these phases and emphasizes that data is at the heart of the process.",
            "zh": "图 1.4[16] 还说明了每个阶段之间的流程，并强调数据是该过程的核心。"
        }
    },
    {
        "translation": {
            "en": "For example, for the drug dosage prediction problem, the root mean squared error value is 1.380 for the regression model and 2.096 for the nearest neighbor model.",
            "zh": "例如，对于药物剂量预测问题，回归模型的均方根误差值为 1.380，最近邻模型的均方根误差值为 2.096。"
        }
    },
    {
        "translation": {
            "en": "Third, the algorithm chooses which node it should move to next: the parent of the node or a node in the subtree under the other branch of the node (Lines 8, 9, 10, and 11).",
            "zh": "第三，算法选择接下来应该移动到哪个节点：节点的父节点或节点另一个分支下的子树中的节点（第 8、9、10 和 11 行）。"
        }
    },
    {
        "translation": {
            "en": "9.14   A series of charts for different model performance on the same large email classification test set used to generate the ROC curves in Figure 9.12(b)[562]. Each column from top to bottom: a histogram of the ham scores predicted by the model, a histogram of the spam scores predicted by the model, and the K-S chart.",
            "zh": "9.14 在图9.12（b）中用于生成ROC曲线的同一大型电子邮件分类测试集上不同模型性能的一系列图表[562]。每列从上到下：模型预测的火腿分数的直方图、模型预测的垃圾邮件分数的直方图以及 K-S 控制图。"
        }
    },
    {
        "translation": {
            "en": "The definition of these neighborhoods is based on similarity within the feature space to the labeled training instances.",
            "zh": "这些邻域的定义基于特征空间内与标记的训练实例的相似性。"
        }
    },
    {
        "translation": {
            "en": "We can use a k nearest neighbor model to predict the likely sale price of a bottle of whiskey based on the prices achieved by similar bottles at previous auctions.16 Table 5.8[209] lists a dataset of whiskeys described by the RATING they were given in a popular whiskey enthusiasts magazine and their AGE (in years).",
            "zh": "16 表 5.8[209] 列出了一个威士忌数据集，该数据集由流行的威士忌爱好者杂志给出的 RATING 及其 AGE（以年为单位）描述。"
        }
    },
    {
        "translation": {
            "en": "A vector is an ordered list, so the mechanism for matching a probability in the vector with a particular value in the domain is just to look up the position of the probability within the vector.",
            "zh": "向量是一个有序列表，因此将向量中的概率与域中的特定值相匹配的机制只是查找向量中概率的位置。"
        }
    },
    {
        "translation": {
            "en": "The output of the action-value function is referred to as the expected return of pursuing action at in state st. We will see that the action-value function formulation of expected return is the more useful of these two.",
            "zh": "动作值函数的输出称为在状态 st 处追求动作的预期回报。我们将看到，预期回报的行动-价值函数公式是这两者中更有用的。"
        }
    },
    {
        "translation": {
            "en": "DIA. B.P.: The patient’s diastolic blood pressure",
            "zh": "DIA. B.P.：患者的舒张压"
        }
    },
    {
        "translation": {
            "en": "For example, W(k) is the weight matrix for the neurons in layer k. In an LSTM network we treat the neurons in the sigmoid and tanh layers within each gate as a separate layer of neurons, and so we write W(f) for the weight matrix for the neurons in the forget gate, and so on for the weight matrices of the other neuron layers in the other gates.",
            "zh": "例如，W（k） 是第 k 层神经元的权重矩阵。在 LSTM 网络中，我们将每个门内 sigmoid 和 tanh 层中的神经元视为单独的神经元层，因此我们为遗忘门中神经元的权重矩阵编写 W（f），为其他门中其他神经元层的权重矩阵编写 W（f）。"
        }
    },
    {
        "translation": {
            "en": "k = ⋆), then adjusting logit k changes both the numerator and the denominator in the softmax for the calculation of , whereas in the case that the logit with respect to which we are taking the derivative is for a neuron corresponding to another category, changing the logit changes only the denominator of the softmax.",
            "zh": "k = ⋆），则调整 logit k 会同时改变 softmax 中的分子和分母，以便计算 ，而如果我们取导数的 logit 是针对对应于另一个类别的神经元，则更改 logit 仅更改 softmax 的分母。"
        }
    },
    {
        "translation": {
            "en": "In summary, whether we compute the likelihood term for this example using the chain rule or directly from the dataset, we will end up with a probability of zero, or worse, an undefined probability. This is because there are no instances in the dataset where a patient who had meningitis was suffering from a headache and had a fever but wasn’t vomiting. Consequently, the probability for the MENINGITIS feature being true given the evidence in the query using this dataset was zero.",
            "zh": "总之，无论我们是使用链式法则还是直接从数据集计算此示例的似然项，我们最终都会得到零的概率，或者更糟的是，一个未定义的概率。这是因为数据集中没有脑膜炎患者头痛、发烧但没有呕吐的实例。因此，鉴于使用此数据集的查询中的证据，脑膜炎特征为真的概率为零。"
        }
    },
    {
        "translation": {
            "en": "decision boundary, 189, 338, 359, 396, 736",
            "zh": "决策边界，189、338、359、396、736"
        }
    },
    {
        "translation": {
            "en": "Although this example is just two dimensional, the k-d tree algorithm can work in a many dimensional feature space, so we will use the term target hypersphere12 to denote the region around the query that is inside the best-distance.",
            "zh": "尽管此示例只是二维的，但 k-d 树算法可以在多维特征空间中工作，因此我们将使用术语 target hypersphere12 来表示查询周围位于最佳距离内的区域。"
        }
    },
    {
        "translation": {
            "en": "where P(t = i) is the probability that the outcome of randomly selecting an element t is the type i; l is the number of different types of things in the set; and s is an arbitrary logarithmic base.",
            "zh": "其中 P（t = i） 是随机选择元素 t 的结果为类型 i 的概率;l 是集合中不同类型事物的数量;s 是任意对数基数。"
        }
    },
    {
        "translation": {
            "en": "There is one neuron in an output softmax layer per target feature level, and so the softmax function returns one probability per level.",
            "zh": "每个目标特征级别在输出 softmax 层中有一个神经元，因此 softmax 函数为每个级别返回一个概率。"
        }
    },
    {
        "translation": {
            "en": "The actual values in a profit matrix are determined through domain expertise.",
            "zh": "利润矩阵中的实际值是通过领域专业知识确定的。"
        }
    },
    {
        "translation": {
            "en": "10.5   Summary",
            "zh": "10.5 总结"
        }
    },
    {
        "translation": {
            "en": "linear algebra, xvi, 771",
            "zh": "线性代数，十六，771"
        }
    },
    {
        "translation": {
            "en": "The fundamental reason to add layers to a network is to increase the representational capacity of the network.",
            "zh": "向网络添加层的根本原因是增加网络的表示能力。"
        }
    },
    {
        "translation": {
            "en": "It may be somewhat surprising, but although the XOR function is very simple, a perceptron cannot represent it because it is not linearly separable.",
            "zh": "这可能有点令人惊讶，但尽管 XOR 函数非常简单，但感知器无法表示它，因为它不是线性可分离的。"
        }
    },
    {
        "translation": {
            "en": "At the beginning of the boosting process the sampling distribution is initialized so that each instance has an equal weight of (represented by the equal segments for each instance in the visualization in Figure 4.21(b)[163]).",
            "zh": "在提升过程开始时，对采样分布进行初始化，以便每个实例具有相等的权重（由图4.21（b）[163]中可视化中每个实例的相等段表示）。"
        }
    },
    {
        "translation": {
            "en": "Some of the machine learning approaches we have discussed in the preceding chapters perform better when a balanced sample is used to train them, and this is why Ross created an ABT with equal numbers of instances with each target level.5",
            "zh": "我们在前几章中讨论过的一些机器学习方法在使用平衡样本进行训练时表现更好，这就是为什么 Ross 创建了一个 ABT，每个目标级别都有相同数量的实例5。"
        }
    },
    {
        "translation": {
            "en": "The δs for the other neurons in the first layer will either be 0 (if they, like Neuron A, did not produce the maximum value in the local receptive field of the sub-sampling neuron to which they connect) or can be calculated in a similar way to Neuron B. Once the δ for each of the neurons in this layer has been calculated, the weight updates for each weight in the filter can be calculated by summing weight updates across the neuron in the layer, per Equation (8.89)[483].",
            "zh": "第一层中其他神经元的 δ 要么为 0（如果它们与神经元 A 一样，在它们所连接的子采样神经元的局部感受野中没有产生最大值），要么可以采用与神经元 B 类似的方式计算。一旦计算了该层中每个神经元的δ，就可以根据公式（8.89）[483]，通过对该层中神经元的权重更新求和来计算过滤器中每个权重的权重更新。"
        }
    },
    {
        "translation": {
            "en": "An experiment whose outcome has been already been recorded is a row in the dataset. Each row in Table B.1[757] records the outcome of a previous experiment.",
            "zh": "已记录结果的实验是数据集中的一行。表B.1[757]中的每一行都记录了先前实验的结果。"
        }
    },
    {
        "translation": {
            "en": "We say that temporal-difference learning is tabular because an action-value table is used to store estimates of the expected return from taking each available action, at, in each possible state, st—the value of Qπ(st,at).",
            "zh": "我们说时间差分学习是表格式的，因为操作值表用于存储对采取每个可用操作的预期回报的估计值，在每种可能的状态下，st——Qπ（st，at）的值。"
        }
    },
    {
        "translation": {
            "en": "A final advantage of the naive Bayes model is how simple it is to train.",
            "zh": "朴素贝叶斯模型的最后一个优点是训练非常简单。"
        }
    },
    {
        "translation": {
            "en": "Nearest neighbor models are an obvious example of a non-parametric model.",
            "zh": "最近邻模型是非参数模型的一个明显示例。"
        }
    },
    {
        "translation": {
            "en": "This contrasts with eager learners, such as the information-based (Chapter 4[117]), probability-based (Chapter 6[243]), and error-based (Chapter 7[311]) approaches to machine learning described in other chapters in this book.",
            "zh": "这与热切的学习者形成鲜明对比，例如本书其他章节中描述的基于信息（第 4 章[117]）、基于概率（第 6 章[243]）和基于错误（第 7 章[311]）的机器学习方法。"
        }
    },
    {
        "translation": {
            "en": "Feature selection excludes redundant and irrelevant features from the induction process and by doing so alleviates the curse of dimensionality.",
            "zh": "特征选择从归纳过程中排除了冗余和不相关的特征，从而减轻了维度的诅咒。"
        }
    },
    {
        "translation": {
            "en": "To construct a k-d tree, we first pick a feature and split the data into two partitions using the median value of this feature.10 We then recursively split each of the two new partitions, stopping the recursion when there are fewer than two instances in a partition.",
            "zh": "为了构造一个k-d树，我们首先选择一个特征，并使用这个特征的中值将数据拆分为两个分区.10然后，我们递归地拆分两个新分区中的每一个，当一个分区中的实例少于两个时停止递归。"
        }
    },
    {
        "translation": {
            "en": "9. Also known as the loss function or cost function.",
            "zh": "9.也称为损失函数或成本函数。"
        }
    },
    {
        "translation": {
            "en": "6.7   Smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature conditioned on FRAUD = false.",
            "zh": "6.7 平滑以 FRAUD = false 为条件的 GUARANTOR/COAPPLICANT 特征的后验概率。"
        }
    },
    {
        "translation": {
            "en": "3. It is important to remember for this discussion that all the data from which we construct an ABT for training and evaluating a model will be historical data.",
            "zh": "3. 在本次讨论中，重要的是要记住，我们构建用于训练和评估模型的 ABT 的所有数据都将是历史数据。"
        }
    },
    {
        "translation": {
            "en": "MNIST, 477",
            "zh": "MNIST，477"
        }
    },
    {
        "translation": {
            "en": "However, for ease of explanation in this section, we have simply used a threshold of SSE < 0.0001 as our convergence criterion.",
            "zh": "但是，为了便于解释，我们简单地使用SSE阈值<0.0001作为收敛标准。"
        }
    },
    {
        "translation": {
            "en": "10.3   (a) A plot of the mobile phone customer dataset given in Table 10.1[604]. (b)–(f) The progress of the k-means clustering algorithm, working on the simple customer segmentation dataset. The large symbols represent cluster centroids, and the smaller symbols represent cluster assignments.",
            "zh": "10.3 （a） 表10.1[604]中给出的移动电话客户数据集图。（b）–（f） k-means聚类算法在简单客户细分数据集上的研究进展。大符号表示聚类质心，较小的符号表示聚类分配。"
        }
    },
    {
        "translation": {
            "en": "The final output of the network is generated by a single ReLU that is fully connected to both Feature map 3 and Feature map 4.",
            "zh": "网络的最终输出由完全连接到特征图 3 和特征图 4 的单个 ReLU 生成。"
        }
    },
    {
        "translation": {
            "en": "It can be shown that the optimal threshold value must lie at one of the boundaries between adjacent instances with different target levels.",
            "zh": "可以看出，最佳阈值必须位于具有不同目标级别的相邻实例之间的边界之一。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.13[410] shows that the maximum value of the derivative of the logistic function is 0.25.",
            "zh": "图 8.13[410] 显示逻辑函数导数的最大值为 0.25。"
        }
    },
    {
        "translation": {
            "en": "To do this we first need to create a profit matrix that records these.",
            "zh": "为此，我们首先需要创建一个记录这些的利润矩阵。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.11",
            "zh": "图 8.11"
        }
    },
    {
        "translation": {
            "en": "co-presence, 212, 213",
            "zh": "共存， 212， 213"
        }
    },
    {
        "translation": {
            "en": "As with filter size and stride length, the selection of whether to use padding or not is task dependent and is often based on trial and error.",
            "zh": "与过滤器大小和步幅长度一样，是否使用填充的选择取决于任务，并且通常基于反复试验。"
        }
    },
    {
        "translation": {
            "en": "Last, a strategy needed to be put in place to monitor the performance of the models over time so that any concept drift that might take place could be flagged. Jocelyn agreed with Ted to put in place an alert system using the stability index. This would raise an alert whenever the stability index went above 0.25 so that someone could consider retraining the model.",
            "zh": "最后，需要制定一种策略来监控模型随时间推移的性能，以便可以标记可能发生的任何概念漂移。Jocelyn 同意 Ted 使用稳定性指数建立一个警报系统。每当稳定性指数高于 0.25 时，都会发出警报，以便有人可以考虑重新训练模型。"
        }
    },
    {
        "translation": {
            "en": "Jocelyn took this first domain concept draft along to a meeting with Ted, the SDSS chief data architect, to discuss the data resources that would be available for model building.",
            "zh": "Jocelyn 带着这个第一个领域概念草案与 SDSS 首席数据架构师 Ted 会面，讨论可用于模型构建的数据资源。"
        }
    },
    {
        "translation": {
            "en": "To illustrate this we return to the spam dataset given in Table 4.2[121].",
            "zh": "为了说明这一点，我们回到表4.2[121]中给出的垃圾邮件数据集。"
        }
    },
    {
        "translation": {
            "en": "Example scatter plots for pairs of features from the dataset in Table 3.7[73], showing (a) the strong positive covariance between HEIGHT and WEIGHT; (b) the strong negative covariance between SPONSORSHIP EARNINGS and AGE; and (c) the lack of strong covariance between HEIGHT and AGE.",
            "zh": "表3.7[73]中数据集中特征对的示例散点图，显示（a）身高和体重之间的强正协方差;（b）赞助收入与年龄之间的强负协方差;（c）身高和年龄之间缺乏强协方差。"
        }
    },
    {
        "translation": {
            "en": "1.7   Predictive Data Analytics Tools",
            "zh": "1.7 预测数据分析工具"
        }
    },
    {
        "translation": {
            "en": "Information can flow forward from one subsequence to the next by using the hidden state of the network at the end of processing one subsequence to initialize the activation buffer at the start of the next subsequence.",
            "zh": "通过在处理一个子序列结束时使用网络的隐藏状态，在下一个子序列的开头初始化激活缓冲区，信息可以从一个子序列向前流动到下一个子序列。"
        }
    },
    {
        "translation": {
            "en": "Figure 2.7[39] illustrates this scenario.",
            "zh": "图 2.7[39] 说明了这种情况。"
        }
    },
    {
        "translation": {
            "en": "Each of the infinite number of possible combinations of values for the weights will result in a model that fits, to some extent, the relationship present in the training data between the descriptive features and the target feature.",
            "zh": "权重值的无限数量的可能组合中的每一个都将产生一个模型，该模型在某种程度上拟合了描述性特征和目标特征之间训练数据中存在的关系。"
        }
    },
    {
        "translation": {
            "en": "Table 8.5",
            "zh": "表 8.5"
        }
    },
    {
        "translation": {
            "en": "overlap metric, 240",
            "zh": "重叠公制，240"
        }
    },
    {
        "translation": {
            "en": "The derivative we use to backpropagate a δ through the rectifierleaky function is",
            "zh": "我们用来通过整流器泄漏函数反向传播δ的导数是"
        }
    },
    {
        "translation": {
            "en": "For example, a feature might record gender using 1 for female and 0 for male.",
            "zh": "例如，要素可能使用 1 表示女性，使用 0 表示男性来记录性别。"
        }
    },
    {
        "translation": {
            "en": "3.1   Visualizations of the continuous and categorical features in the motor insurance claims fraud detection ABT in Table 3.2[56].",
            "zh": "3.1 表3.2[56]中汽车保险理赔欺诈检测ABT中连续和分类特征的可视化。"
        }
    },
    {
        "translation": {
            "en": "Because ROC curves are discrete and stepped in nature, finding their integrals is actually very easily done using the trapezoidal method.",
            "zh": "由于 ROC 曲线本质上是离散的和阶跃的，因此使用梯形方法实际上很容易找到它们的积分。"
        }
    },
    {
        "translation": {
            "en": "PETRORATIO_I",
            "zh": "PETRORATIO_I"
        }
    },
    {
        "translation": {
            "en": "Table 8.3",
            "zh": "表 8.3"
        }
    },
    {
        "translation": {
            "en": "Vapnik, Vladimir. 2000. The nature of statistical learning theory. Springer.",
            "zh": "瓦普尼克，弗拉基米尔。2000. 统计学习理论的本质.斯普林格。"
        }
    },
    {
        "translation": {
            "en": "10.1   Big Idea",
            "zh": "10.1 大创意"
        }
    },
    {
        "translation": {
            "en": "where the training dataset is composed of n training instances (di,ti); 𝕄w(di) is the prediction made by a model 𝕄w for a training instance with descriptive features di; and the model 𝕄w is defined by the weight vector w.",
            "zh": "其中，训练数据集由 n 个训练实例 （di，ti） 组成;Mw（di） 是模型 Mw 对具有描述性特征 di 的训练实例所做的预测;模型 Mw 由权重向量 w 定义。"
        }
    },
    {
        "translation": {
            "en": "Berk, Richard A., and Justin Bleich. 2013. Statistical procedures for forecasting criminal behavior. Criminology & Public Policy 12 (3): 513–544.",
            "zh": "伯克、理查德 A. 和贾斯汀·布莱奇。2013. 预测犯罪行为的统计程序.犯罪学与公共政策12（3）：513-544。"
        }
    },
    {
        "translation": {
            "en": "P_DK",
            "zh": "P_DK"
        }
    },
    {
        "translation": {
            "en": "Moreover, if k is set to a value larger than 15, the majority target level dominates the entire feature space.",
            "zh": "此外，如果将 k 设置为大于 15 的值，则多数目标级别将主导整个特征空间。"
        }
    },
    {
        "translation": {
            "en": "These distance contours were calculated using the inverse covariance matrix for the dataset and point A as the origin.",
            "zh": "这些距离等值线是使用数据集的逆协方差矩阵计算的，并以 A 点为原点。"
        }
    },
    {
        "translation": {
            "en": "For more recent advances at the junction of reinforcement learning and deep learning, Sejnowski (2018) gives a nice overview of some key application areas and recent developments, and again, Sutton and Barto (2018) provides a good overview.",
            "zh": "对于强化学习和深度学习交界处的最新进展，Sejnowski （2018） 对一些关键应用领域和最新发展进行了很好的概述，Sutton 和 Barto （2018） 再次提供了很好的概述。"
        }
    },
    {
        "translation": {
            "en": "cross-correlation, 485",
            "zh": "互相关，485"
        }
    },
    {
        "translation": {
            "en": "Using the data quality report in Table 3.3[57] and Figure 3.1[58] together with the ABT extract in Table 3.2[56], we can perform an analysis of this ABT for data quality issues. We do this by describing separately missing values, irregular cardinality, and outliers.",
            "zh": "使用表3.3[57]和图3.1[58]中的数据质量报告以及表3.2[56]中的ABT提取物，我们可以对该ABT的数据质量问题进行分析。我们通过分别描述缺失值、不规则基数和异常值来做到这一点。"
        }
    },
    {
        "translation": {
            "en": "Technically, the inclusion of the bias parameter as an extra weight in this operation changes the function from a linear function on the inputs to an affine function.",
            "zh": "从技术上讲，在此操作中包含偏置参数作为额外权重会将函数从输入上的线性函数更改为仿射函数。"
        }
    },
    {
        "translation": {
            "en": "Notice that w C,B = 1.",
            "zh": "请注意，w C，B = 1。"
        }
    },
    {
        "translation": {
            "en": "However, support vector machines are an example of a non-parametric model that, to a large extent, avoids this problem.",
            "zh": "然而，支持向量机是非参数模型的一个例子，它在很大程度上避免了这个问题。"
        }
    },
    {
        "translation": {
            "en": "customer churn, 48",
            "zh": "客户流失率，48"
        }
    },
    {
        "translation": {
            "en": "3. Subtract the remaining entropy value (computed in step 2) from the original entropy value (computed in step 1) to give the information gain.",
            "zh": "3. 从原始熵值（在步骤 1 中计算）中减去剩余的熵值（在步骤 2 中计算）以给出信息增益。"
        }
    },
    {
        "translation": {
            "en": "Voronoi region, 189",
            "zh": "沃罗诺伊地区，189"
        }
    },
    {
        "translation": {
            "en": "Bagging is simpler to implement and parallelize than boosting, so it may be better with respect to ease of use and training time.",
            "zh": "与提升相比，Bagging 更易于实现和并行化，因此在易用性和训练时间方面可能更好。"
        }
    },
    {
        "translation": {
            "en": "Therefore, after every C steps the current action-value target network is replaced with a copy of the action-value behavior network.",
            "zh": "因此，在每个 C 步骤之后，当前的动作值目标网络将替换为动作值行为网络的副本。"
        }
    },
    {
        "translation": {
            "en": "7. The correlation coefficient presented here is more fully known as the Pearson product-moment correlation coefficient or Pearson’s r and is named after Karl Pearson, one of the giants of statistics.",
            "zh": "7. 这里介绍的相关系数更全面地称为皮尔逊积矩相关系数或皮尔逊的 r，并以统计学巨人之一卡尔·皮尔逊的名字命名。"
        }
    },
    {
        "translation": {
            "en": "Using the symbol θ to denote the threshold, the second stage of processing in the McCulloch and Pitts model can be defined",
            "zh": "使用符号 θ 表示阈值，可以定义 McCulloch 和 Pitts 模型中的第二阶段处理"
        }
    },
    {
        "translation": {
            "en": "cumulative lift chart, 570",
            "zh": "累计提升图，570"
        }
    },
    {
        "translation": {
            "en": "Similarly, the bottom left cell in the matrix, labeled FP, shows the number of instances in a test set that have a negative target feature value that were in fact predicted by the model to have a positive target feature value.",
            "zh": "同样，矩阵中标记为 FP 的左下角单元格显示了测试集中具有负目标特征值的实例数，而模型实际上预测这些实例具有正目标特征值。"
        }
    },
    {
        "translation": {
            "en": "(b) Describe the domain concepts for this ABT.",
            "zh": "（b） 描述本 ABT 的领域概念。"
        }
    },
    {
        "translation": {
            "en": "We have already met the minimum description length principle in the more general form of Occam’s razor.",
            "zh": "我们已经满足了奥卡姆剃刀更一般形式的最小描述长度原则。"
        }
    },
    {
        "translation": {
            "en": "Building on this idea, the early stopping algorithm uses the performance of the model on a validation dataset to determine when to stop training the model.",
            "zh": "基于这个想法，早期停止算法使用模型在验证数据集上的性能来确定何时停止训练模型。"
        }
    },
    {
        "translation": {
            "en": "12.4 Modeling",
            "zh": "12.4 建模"
        }
    },
    {
        "translation": {
            "en": "presence-absence (PA), how often a true value occurred in the query data q when a false value occurred in the data for the comparison user (d1 or d2) for the same feature",
            "zh": "presence-absence （PA），当同一要素的比较用户（d1 或 d2）的数据中出现假值时，查询数据 q 中出现真值的频率"
        }
    },
    {
        "translation": {
            "en": "These two PDFs do not have to be defined using the same distribution.",
            "zh": "这两个 PDF 不必使用相同的分发来定义。"
        }
    },
    {
        "translation": {
            "en": "Opinions vary widely on when transformations like the clamp transformation should be used to handle outliers in data.",
            "zh": "关于何时应使用钳位变换等变换来处理数据中的异常值，意见分歧很大。"
        }
    },
    {
        "translation": {
            "en": "So, direct comparison of the weights tells us little about their relative importance.",
            "zh": "因此，权重的直接比较几乎不能告诉我们它们的相对重要性。"
        }
    },
    {
        "translation": {
            "en": "For these reasons, Ross designed the following descriptive features:",
            "zh": "出于这些原因，Ross 设计了以下描述性功能："
        }
    },
    {
        "translation": {
            "en": "approximate methods, 668, 676",
            "zh": "近似方法，668,676"
        }
    },
    {
        "translation": {
            "en": "where s1 to sn are n different states. A Markov process can be fully characterized by the set of states, S, and the transition matrix, 𝒫.",
            "zh": "其中 s1 到 sn 是 n 个不同的状态。马尔可夫过程可以完全由一组状态 S 和跃迁矩阵 P 来表征。"
        }
    },
    {
        "translation": {
            "en": "The height of each player is listed below the player, and the dashed gray line shows the arithmetic mean of the players’ heights, which is 149.375, the same as for the original team.",
            "zh": "每个球员的身高都列在球员的下方，灰色虚线显示球员身高的算术平均值，即 149.375，与原始球队相同。"
        }
    },
    {
        "translation": {
            "en": "Using learning rate decay can even address the problem of inappropriately large error rates causing the sum of squared errors to increase rather than decrease.",
            "zh": "使用学习率衰减甚至可以解决错误率过大导致平方误差总和增加而不是减少的问题。"
        }
    },
    {
        "translation": {
            "en": "A lecturer is about to leave for the airport to go on vacation when they find a script for a student they forgot to mark.",
            "zh": "一位讲师正要去机场度假时，他们发现了一个他们忘记批改的学生的剧本。"
        }
    },
    {
        "translation": {
            "en": "Ideally, each mini-batch should be created by random sampling from the dataset.",
            "zh": "理想情况下，每个小批量都应通过从数据集中随机抽样来创建。"
        }
    },
    {
        "translation": {
            "en": "Inspired by these results, neural network research started to design networks in which neurons in one layer received input only from a localized subset of neurons in the preceding layer, that is, each neuron had a local receptive field in the preceding layer.",
            "zh": "受这些结果的启发，神经网络研究开始设计网络，其中一层中的神经元仅接收来自前一层中局部神经元子集的输入，也就是说，每个神经元在前一层中都有一个局部感受野。"
        }
    },
    {
        "translation": {
            "en": "This combination ensures that the output from a layer of neurons applying a filter across an image has the same dimensions as the input image.",
            "zh": "这种组合可确保在图像上应用滤波器的神经元层的输出与输入图像具有相同的尺寸。"
        }
    },
    {
        "translation": {
            "en": "where w[j] is any weight, α is a constant learning rate, ti is the expected target feature value for the ith training instance, 𝕄w(di) is the prediction made for this training instance by the current candidate model defined by the weight vector w, and di[j] is the jth descriptive feature of the ith training instance and corresponds with weight w[j] in the regression model.",
            "zh": "其中 w[j] 是任何权重，α 是恒定的学习率，ti 是第 i 个训练实例的预期目标特征值，Mw（di） 是由权重向量 w 定义的当前候选模型对此训练实例做出的预测，di[j] 是第 i 个训练实例的第 j 个描述性特征，与回归模型中的权重 w[j] 相对应。"
        }
    },
    {
        "translation": {
            "en": "Table 6.2",
            "zh": "表 6.2"
        }
    },
    {
        "translation": {
            "en": "These questions are relevant when building any prediction model, and the answer to each one introduces a specific bias. Often we are forced to answer these questions, and others like them, based on intuition, experience, and experimentation. This is what makes machine learning something of an art, rather than strictly a science. But it is also what makes machine learning such a fascinating and rewarding area in which to work.",
            "zh": "这些问题在构建任何预测模型时都是相关的，每个问题的答案都会引入特定的偏差。通常，我们被迫根据直觉、经验和实验来回答这些问题以及其他类似的问题。这就是使机器学习成为一门艺术的原因，而不是严格意义上的一门科学。但这也是使机器学习成为一个如此迷人和有益的工作领域的原因。"
        }
    },
    {
        "translation": {
            "en": "[Member prediction] A model could be built to predict the propensity of a member1 to commit fraud in the near future. This model could be run every quarter to identify those members most likely to commit fraud, and the insurance company could take a risk-mitigation action ranging from contacting the member with some kind of warning to canceling the member’s policies. By identifying members likely to make fraudulent claims before they make them, the company could save significant amounts of money.",
            "zh": "[会员预测]可以建立一个模型来预测成员1在不久的将来实施欺诈的倾向。该模型可以每季度运行一次，以识别最有可能进行欺诈的成员，保险公司可以采取风险缓解措施，从联系成员发出某种警告到取消成员的保单。通过在成员提出欺诈性索赔之前识别他们可能提出欺诈性索赔，该公司可以节省大量资金。"
        }
    },
    {
        "translation": {
            "en": "Which pieces of the network infrastructure were likely to fail in the near future? Using information about network loads, network usage, and equipment diagnostics, a predictive model could be built to flag upcoming equipment failures so that pre-emptive action could be taken. Network outages are a driver of customer dissatisfaction and ultimately customer churn, so reducing these could have a positive impact on churn rates.",
            "zh": "在不久的将来，哪些网络基础设施可能会出现故障？使用有关网络负载、网络使用情况和设备诊断的信息，可以构建一个预测模型来标记即将发生的设备故障，以便采取先发制人的措施。网络中断是客户不满并最终导致客户流失的驱动因素，因此减少这些中断可能会对客户流失率产生积极影响。"
        }
    },
    {
        "translation": {
            "en": "Section 9.4.6[578] and Chapters 12[685] and 13[703]",
            "zh": "第9.4.6节[578]以及第12章[685]和第13章[703]"
        }
    },
    {
        "translation": {
            "en": "Although neuroscience has discovered a lot about the neural structure of the brain, neuroscientists are still working on understanding how learning happens in the brain and how high-level human behavior arises from the processing of neurons.",
            "zh": "尽管神经科学已经发现了很多关于大脑神经结构的信息，但神经科学家仍在努力了解学习是如何在大脑中发生的，以及高级人类行为是如何从神经元的处理中产生的。"
        }
    },
    {
        "translation": {
            "en": "Based on the errors in these predictions, the delta contributions, labeled as errorDelta(,w[0]), errorDelta(,w[1]) and errorDelta(,w[2]) in Table 7.8[348], from each training instance are calculated according to Equation (7.31)[345].",
            "zh": "根据这些预测中的误差，根据公式（7.31）[345]计算每个训练实例的增量贡献，在表7.8[348]中标记为errorDelta（，w[0]）、errorDelta（，w[1]）和errorDelta（，w[2]）。"
        }
    },
    {
        "translation": {
            "en": "In situations where we have a larger dataset, however, we could perform evaluation experiments17 to see which value of k leads to the best-performing model.",
            "zh": "然而，在我们有更大数据集的情况下，我们可以执行评估实验17，看看k的哪个值会导致性能最好的模型。"
        }
    },
    {
        "translation": {
            "en": "A schematic of a feedforward artificial neural network.",
            "zh": "前馈人工神经网络示意图。"
        }
    },
    {
        "translation": {
            "en": "inverse reasoning, 248",
            "zh": "逆推理，248"
        }
    },
    {
        "translation": {
            "en": "One final point: remember that the empty partition in Figure 4.10[140] (𝒟 18) has been converted into a leaf node that returns the chapparal target level. The reason is that chapparal is the majority target level in the partition at the parent node (𝒟8) of this leaf node. Consequently, this tree will return a prediction of VEGETATION = chapparal for the following query:",
            "zh": "最后一点：请记住，图 4.10[140] （D 18） 中的空分区已转换为返回 chapparal 目标级别的叶节点。原因是 chapparal 是此叶节点的父节点 （D8） 分区中的大多数目标级别。因此，此树将返回以下查询的 VEGETATION = chapparal 的预测："
        }
    },
    {
        "translation": {
            "en": "encoder, 624",
            "zh": "编码器，624"
        }
    },
    {
        "translation": {
            "en": "on-line gradient descent, 415",
            "zh": "在线梯度下降，415"
        }
    },
    {
        "translation": {
            "en": "Furthermore, for each subsequent layer that the δs are backpropagated through, the variance will increase by a factor of 4, and it is this scaling that causes the exploding gradients evident in Figure 8.24(d)[454].",
            "zh": "此外，对于δs反向传播的每个后续层，方差将增加4倍，正是这种缩放导致了图8.24（d）[454]中明显的爆炸梯度。"
        }
    },
    {
        "translation": {
            "en": "Even with modern computational power and with processing examples in parallel, this can take a long time and ultimately result in network training taking a long time.",
            "zh": "即使使用现代计算能力并行处理示例，这也可能需要很长时间，并最终导致网络训练需要很长时间。"
        }
    },
    {
        "translation": {
            "en": "local receptive field, 479",
            "zh": "局部感受野，479"
        }
    },
    {
        "translation": {
            "en": "In error-based machine learning, we perform a search for a set of parameters for a parameterized model that minimizes the total error across the predictions made by that model with respect to a set of training instances.",
            "zh": "在基于错误的机器学习中，我们为参数化模型搜索一组参数，以最小化该模型对一组训练实例所做的预测的总误差。"
        }
    },
    {
        "translation": {
            "en": "So, if the inverse covariance matrix is the identity matrix , then no scaling or rotation occurs.",
            "zh": "因此，如果逆协方差矩阵是单位矩阵，则不会发生缩放或旋转。"
        }
    },
    {
        "translation": {
            "en": "12.3   (a) A stacked bar plot for the REGIONTYPE feature; and (b) histograms for the AVGOVERBUNDLEMINS feature by target feature value.",
            "zh": "12.3 （a） REGIONTYPE 特征的堆积条形图;以及 （b） 按目标特征值划分的 AVGOVERBUNDLEMINS 特征的直方图。"
        }
    },
    {
        "translation": {
            "en": "Larger values of p place more emphasis on large differences between feature values than smaller values of p because all differences are raised to the power of p. Consequently, the Euclidean distance (with p = 2) is more strongly influenced by a single large difference in one feature than the Manhattan distance (with p = 1).3",
            "zh": "较大的 p 值比较小的 p 值更强调特征值之间的较大差异，因为所有差异都提高到 p 的幂。因此，与曼哈顿距离（p = 1）相比，欧几里得距离（p = 2）受一个特征的单个大差异的影响更大。"
        }
    },
    {
        "translation": {
            "en": "The term can be computed using metrics such as the Bayesian score or the K2 score.23 The search space for these algorithms is exponential in the number of features.",
            "zh": "可以使用贝叶斯分数或 K2 分数等指标来计算该术语。23 这些算法的搜索空间在特征数量上呈指数级增长。"
        }
    },
    {
        "translation": {
            "en": "Entropy-based information gain, however, does have some drawbacks.",
            "zh": "然而，基于熵的信息增益确实有一些缺点。"
        }
    },
    {
        "translation": {
            "en": "give the weight in the sampling distribution for each training instance, and the columns labeled Freq.",
            "zh": "给出每个训练实例的抽样分布中的权重，以及标记为 Freq 的列。"
        }
    },
    {
        "translation": {
            "en": "To see the impact of this, we can build a multivariable logistic regression model for the dataset in Table 7.6[339]. After the training process (which uses a slightly modified version of the gradient descent algorithm, which we will explain shortly), the resulting logistic regression model is15",
            "zh": "为了了解其影响，我们可以为表7.6[339]中的数据集构建一个多变量逻辑回归模型。在训练过程之后（使用梯度下降算法的略微修改版本，我们稍后将解释），生成的逻辑回归模型为15"
        }
    },
    {
        "translation": {
            "en": "For example, consider the following query:",
            "zh": "例如，请考虑以下查询："
        }
    },
    {
        "translation": {
            "en": "The descriptive features used by the model are the age of the customer, the socioeconomic band to which the customer belongs (a, b, or c), the average amount of money the customer spends on each visit to the shop, and the average number of visits the customer makes to the shop per week.",
            "zh": "该模型使用的描述性特征包括客户的年龄、客户所属的社会经济阶层（a、b 或 c）、客户每次访问商店的平均金额以及客户每周访问商店的平均次数。"
        }
    },
    {
        "translation": {
            "en": "It seems, from this data, that customers are most likely to churn when their bill changes dramatically, when they begin to exceed the bundled minutes in their call package, or when they have had a handset for a long time and are considering changing to something newer.",
            "zh": "从这些数据来看，当客户的账单发生巨大变化时，当他们开始超过通话套餐中的捆绑分钟数时，或者当他们已经拥有手机很长时间并正在考虑更换为新手机时，客户最有可能流失。"
        }
    },
    {
        "translation": {
            "en": "By the time the original error gradient term ∂ℰ/∂ak is propagated back to δi it is multiplied by two weights, wj,i and wk,j, and three times by the derivative of the activation function of a neuron with respect to the weighted sum of the neuron: ∂ak/∂zk, ∂aj/∂zj, ∂ai/∂zi.",
            "zh": "当原始误差梯度项 ∂E/∂ak 传播回 δi 时，它会乘以两个权重 wj，i 和 wk，j，并乘以神经元激活函数相对于神经元加权和的导数的三倍：∂ak/∂zk、∂aj/∂zj、∂ai/∂zi。"
        }
    },
    {
        "translation": {
            "en": "3.3   Identifying Data Quality Issues",
            "zh": "3.3 识别数据质量问题"
        }
    },
    {
        "translation": {
            "en": "This is also apparent in the final panel in Figure 7.6[325], which shows how the sum of squared errors decreases as the model becomes more accurate.",
            "zh": "这在图7.6[325]的最后一个面板中也很明显，该图显示了随着模型变得更加精确，平方误差的总和如何减小。"
        }
    },
    {
        "translation": {
            "en": "(b) Mean and median",
            "zh": "（b） 平均值和中位数"
        }
    },
    {
        "translation": {
            "en": "7.2   Fundamentals",
            "zh": "7.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "This chapter introduced reinforcement learning, an alternative approach to supervised or unsupervised machine learning.",
            "zh": "本章介绍了强化学习，这是监督或无监督机器学习的替代方法。"
        }
    },
    {
        "translation": {
            "en": "These bar plots show that the distribution of target levels for New Sample 1 is similar to the original test set, but that the distribution of target levels for New Sample 2 is quite different.",
            "zh": "这些条形图显示，新样本 1 的目标水平分布与原始测试集相似，但新样本 2 的目标水平分布却大不相同。"
        }
    },
    {
        "translation": {
            "en": "The tabular reports are accompanied by data visualizations that illustrate the distribution of the values in each feature in an ABT.",
            "zh": "表格报告附有数据可视化，用于说明 ABT 中每个要素中值的分布。"
        }
    },
    {
        "translation": {
            "en": "(a) The structure of a box plot; and (b) a box plot for the TRAINING EXPENSES feature from the basketball team dataset in Table A.1[750].",
            "zh": "（a） 箱形地块的结构;（b）表A.1[750]中篮球队数据集的训练费用特征的箱形图。"
        }
    },
    {
        "translation": {
            "en": "There are two types of neurons in this network: sensing neurons and processing neurons.",
            "zh": "该网络中有两种类型的神经元：感知神经元和处理神经元。"
        }
    },
    {
        "translation": {
            "en": "There is only one neuron in the output layer, and so there is only one row in this weight matrix.",
            "zh": "输出层中只有一个神经元，因此此权重矩阵中只有一行。"
        }
    },
    {
        "translation": {
            "en": "Naturally, when our patience runs out, we roll back training to the version of the model that produced the lowest validation set error.",
            "zh": "当然，当我们的耐心耗尽时，我们会将训练回滚到产生最低验证集误差的模型版本。"
        }
    },
    {
        "translation": {
            "en": "This network has a depth of three, and so it has three weight matrices.",
            "zh": "该网络的深度为 3，因此它有三个权重矩阵。"
        }
    },
    {
        "translation": {
            "en": "2.2   The hierarchical relationship between an analytics solution, domain concepts, and descriptive features.",
            "zh": "2.2 分析解决方案、领域概念和描述性特征之间的层次结构关系。"
        }
    },
    {
        "translation": {
            "en": "What is interesting here is that no matter what question you ask, the answer is always either yes or no, but, on average, an answer to Question 1 seems to carry more information than an answer to Question 2.",
            "zh": "有趣的是，无论你问什么问题，答案总是“是”或“否”，但平均而言，问题 1 的答案似乎比问题 2 的答案包含更多的信息。"
        }
    },
    {
        "translation": {
            "en": "If we can catch this point, we can take appropriate action.",
            "zh": "如果我们能抓住这一点，我们就可以采取适当的行动。"
        }
    },
    {
        "translation": {
            "en": "The target level imbalance in the SDSS dataset arises through relative rarity.15 In the large SDSS dataset, there are plenty of galaxies in the other and spiral categories; there are just many more in the elliptical category.",
            "zh": "15 在大型 SDSS 数据集中，其他星系和螺旋星系类别中有很多星系;椭圆机类别中还有更多。"
        }
    },
    {
        "translation": {
            "en": "conditional independence, 256, 256, 261, 302",
            "zh": "有条件独立性，256、256、261、302"
        }
    },
    {
        "translation": {
            "en": "As the process has arrived at a leaf node, it terminates, and the target level indicated by the leaf node, spam, is predicted for the query instance.",
            "zh": "当进程到达叶节点时，它将终止，并且为查询实例预测叶节点指示的目标级别 spam。"
        }
    },
    {
        "translation": {
            "en": "The point to note in this equation is that the calculation does not involve a weight term.",
            "zh": "在这个等式中需要注意的一点是，计算不涉及权重项。"
        }
    },
    {
        "translation": {
            "en": "3   Data Exploration",
            "zh": "3 数据探索"
        }
    },
    {
        "translation": {
            "en": "Figure 9.13[564] shows the K-S chart for the test set predictions shown in Table 9.11[557].",
            "zh": "图9.13[564]显示了表9.11[557]所示的测试集预测的K-S图。"
        }
    },
    {
        "translation": {
            "en": "To illustrate gradient boosting, we use another modified version of the bike rentals dataset used in Section 4.4.3[149]. This will again predict the expected rental demand on the basis of a single descriptive feature, the forecasted temperature for a day. The first columns of Table 4.15[166] detail a small sample dataset giving temperatures, TEMP, and rental demand, RENTALS (this time as actual numeric values), for 10 days. A visualization of the dataset is provided in Figure 4.22(a)[167].",
            "zh": "为了说明梯度提升，我们使用了第 4.4.3 节中使用的自行车租赁数据集的另一个修改版本[149]。这将再次根据单个描述性特征（即一天的预测温度）预测预期的租赁需求。表 4.15[166] 的第一列详细介绍了一个小型样本数据集，该数据集给出了 10 天的温度、温度和租赁需求、租金（这次是实际数值）。图4.22（a）[167]提供了数据集的可视化效果。"
        }
    },
    {
        "translation": {
            "en": "(a) Calculate the probabilities (to four places of decimal) that a naive Bayes classifier would use to represent this domain.",
            "zh": "（a） 计算朴素贝叶斯分类器用来表示该域的概率（精确到小数点后四位）。"
        }
    },
    {
        "translation": {
            "en": "Aoife would like to thank her parents (Michael and Mairead) and family, and all the people who have supported her throughout her career—especially the much-valued customers of Krisolis who give her data to play with!",
            "zh": "Aoife 要感谢她的父母（Michael 和 Mairead）和家人，以及所有在她整个职业生涯中支持她的人——尤其是 Krisolis 的尊贵客户，他们为她提供了数据！"
        }
    },
    {
        "translation": {
            "en": "(a) What will be the value of ct if",
            "zh": "（a） ct 的值是多少，如果"
        }
    },
    {
        "translation": {
            "en": "entropy, 43, 117, 120, 125, 149, 172, 173, 611, 731",
            "zh": "熵， 43， 117， 120， 125， 149， 172， 173， 611， 731"
        }
    },
    {
        "translation": {
            "en": "We don’t have to use decision trees.",
            "zh": "我们不必使用决策树。"
        }
    },
    {
        "translation": {
            "en": "Which approach should we use?",
            "zh": "我们应该使用哪种方法？"
        }
    },
    {
        "translation": {
            "en": "Health and education directly affect corruption, so there is a directed arc from LIFE EXP and from SCHOOL YEARS to CPI.",
            "zh": "健康和教育直接影响腐败，因此从 LIFE EXP 和从 SCHOOL YEARS 到 CPI 有一条定向弧线。"
        }
    },
    {
        "translation": {
            "en": "14. The logistic function is a real workhorse of mathematical modeling and is used in a huge range of different applications. For example, the logistic function has been used to model how new words enter a language over time, first used very infrequently before moving through a tipping point to become widespread in a language.",
            "zh": "14. 逻辑函数是数学建模的真正主力军，用于各种不同的应用。例如，逻辑函数已被用于模拟新词如何随着时间的推移进入一种语言，在通过临界点在语言中广泛使用之前，最初很少使用。"
        }
    },
    {
        "translation": {
            "en": "In summary, ensembles, support vector machines, neural networks, and Bayesian networks are, in general, more powerful machine learning approaches than the others we have presented.",
            "zh": "总之，集成、支持向量机、神经网络和贝叶斯网络通常是比我们介绍的其他方法更强大的机器学习方法。"
        }
    },
    {
        "translation": {
            "en": "As a result, we have had to sacrifice coverage of some aspects of machine learning in order to include other topics and worked examples.",
            "zh": "因此，我们不得不牺牲对机器学习某些方面的覆盖，以包括其他主题和工作示例。"
        }
    },
    {
        "translation": {
            "en": "These are abstract concepts that are understood to be likely important factors in making predictions.",
            "zh": "这些是抽象的概念，被理解为做出预测的重要因素。"
        }
    },
    {
        "translation": {
            "en": "We can put these components together to define the standard approach to similarity-based learning: the nearest neighbor algorithm.",
            "zh": "我们可以将这些组件放在一起来定义基于相似性的学习的标准方法：最近邻算法。"
        }
    },
    {
        "translation": {
            "en": "There are a number of performance measures based on the idea of comparing prediction score distributions that attempt to cater to the peculiarities of real data.",
            "zh": "有许多基于比较预测分数分布的绩效度量，试图迎合真实数据的特殊性。"
        }
    },
    {
        "translation": {
            "en": "It was clear that the performance of the models trained using the SDSS data was severely affected by the target level imbalance in the data—there were many more examples of the elliptical target level than either the spiral or, especially, the other target level.",
            "zh": "很明显，使用SDSS数据训练的模型的性能受到数据中目标水平不平衡的严重影响——椭圆目标水平的例子比螺旋目标水平或特别是其他目标水平的例子要多得多。"
        }
    },
    {
        "translation": {
            "en": "B.2 Probability Distributions and Summing Out",
            "zh": "B.2 概率分布和求和"
        }
    },
    {
        "translation": {
            "en": "k-means++, 605, 607, 624",
            "zh": "k-均值++， 605， 607， 624"
        }
    },
    {
        "translation": {
            "en": "If we use the symbol φ to represent the activation function of a neuron, we can mathematically define an artificial neuron as follows:",
            "zh": "如果我们使用符号 φ 来表示神经元的激活函数，我们可以在数学上定义人工神经元如下："
        }
    },
    {
        "translation": {
            "en": "exploration, 655, 656",
            "zh": "勘探， 655， 656"
        }
    },
    {
        "translation": {
            "en": "There are two ways to reason with probabilities forward and inverse.",
            "zh": "有两种方法可以对概率进行正向推理和逆向推理。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.15",
            "zh": "图 5.15"
        }
    },
    {
        "translation": {
            "en": "Subsets of the training set would be also used for validation during the model building process.",
            "zh": "在模型构建过程中，训练集的子集也将用于验证。"
        }
    },
    {
        "translation": {
            "en": "Reinforcement learning is built upon the framework of an intelligent agent.",
            "zh": "强化学习建立在智能代理的框架之上。"
        }
    },
    {
        "translation": {
            "en": "The following table lists a dataset of five individuals described via a set of stroke risk factors and their probability of suffering a stroke in the next five years.",
            "zh": "下表列出了通过一组中风风险因素描述的五个人的数据集，以及他们在未来五年内患中风的概率。"
        }
    },
    {
        "translation": {
            "en": "1. In this discussion, when we categorize models as being generative or discriminative, we are speaking in the general case. In fact, all models can be trained in either a generative or a discriminative manner. However, some models lend themselves to generative training and others to discriminative training, and it is this perspective that we use in this discussion.",
            "zh": "1. 在本次讨论中，当我们将模型归类为生成性或判别性时，我们是在一般情况下发言。事实上，所有模型都可以以生成或判别方式进行训练。然而，有些模型适合生成性训练，而另一些模型则适合歧视性训练，我们在本次讨论中使用的正是这种观点。"
        }
    },
    {
        "translation": {
            "en": "This example illustrates that the variance also captures the intuition that the heights of the players in the second team vary much more than those in the first team.",
            "zh": "这个例子说明，方差还捕捉到了一种直觉，即二队球员的身高变化比一队球员的身高变化大得多。"
        }
    },
    {
        "translation": {
            "en": "0.56",
            "zh": "0.56"
        }
    },
    {
        "translation": {
            "en": "These correlation values are much more useful than the covariances calculated previously because they are on a normalized scale, which allows us to compare the strength of the relationships to each other. There is a strong positive correlation between HEIGHT and WEIGHT features, but very little correlation between HEIGHT and AGE.",
            "zh": "这些相关值比之前计算的协方差有用得多，因为它们处于归一化尺度上，这使我们能够比较关系的强度。身高和体重特征之间存在很强的正相关关系，但身高和年龄之间的相关性很小。"
        }
    },
    {
        "translation": {
            "en": "frequency table, 749",
            "zh": "频率表，749"
        }
    },
    {
        "translation": {
            "en": "Discuss the relationships shown in each visualizations.",
            "zh": "讨论每个可视化中显示的关系。"
        }
    },
    {
        "translation": {
            "en": "Again, we have overlaid the histogram with plots of the curves for a normal and a student-t distribution that have been fitted to the updated dataset.",
            "zh": "同样，我们在直方图上覆盖了已拟合到更新数据集的正态分布和 student-t 分布的曲线图。"
        }
    },
    {
        "translation": {
            "en": "The SARSA and Q-learning approaches are both tabular methods which are limited in terms of the size of state space they can handle.",
            "zh": "SARSA 和 Q-learning 方法都是表格方法，它们在可以处理的状态空间大小方面受到限制。"
        }
    },
    {
        "translation": {
            "en": "Each of this part’s first five chapters presents a different approach to machine learning: Chapter 4, learning through information gathering; Chapter 5, learning through analogy; Chapter 6, learning by predicting probable outcomes; Chapter 7, learning by searching for solutions that minimize error; and Chapter 8, learning new representations using deep neural networks.",
            "zh": "本部分的前五章中的每一章都介绍了一种不同的机器学习方法：第 4 章，通过信息收集进行学习;第5章，类比学习;第 6 章，通过预测可能的结果来学习;第 7 章，通过寻找最大限度地减少错误的解决方案来学习;第 8 章，使用深度神经网络学习新表示。"
        }
    },
    {
        "translation": {
            "en": "The target feature, SIGNUP, indicates whether the customers ultimately signed up to the paid service or not (yes or no).",
            "zh": "目标功能 SIGNUP 指示客户最终是否注册了付费服务（是或否）。"
        }
    },
    {
        "translation": {
            "en": "The basic structure in which we capture these historical datasets is the analytics base table (ABT), a schematic of which is shown in Table 2.1[29]. An analytics base table is a simple, flat, tabular data structure made up of rows and columns. The columns are divided into a set of descriptive features and a single target feature. Each row contains a value for each descriptive feature and the target feature and represents an instance about which a prediction can be made.",
            "zh": "我们捕获这些历史数据集的基本结构是分析基表（ABT），其示意图如表2.1所示[29]。分析基表是一种简单、扁平的表格数据结构，由行和列组成。这些列分为一组描述性特征和一个目标特征。每行包含每个描述性特征和目标特征的值，并表示可以对其进行预测的实例。"
        }
    },
    {
        "translation": {
            "en": "First, the dataset of training instances considered at each of the interior nodes in the tree is not the complete dataset; rather, it is the subset of instances considered at its parent node that had the relevant feature value for the branch from the parent to the current node.",
            "zh": "首先，树中每个内部节点所考虑的训练实例数据集不是完整的数据集;相反，它是在其父节点上考虑的实例子集，该子集具有从父节点到当前节点的分支的相关特征值。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 1[134] lists a pseudocode description of the ID3 algorithm. Although the algorithm looks quite complex, it essentially does one of two things each time it is invoked: either it stops growing the current path in the tree by adding a leaf node to the tree, Lines 1–6, or it extends the current path by adding an interior node to the tree and growing the branches of this node by repeatedly rerunning the algorithm, Lines 7–13.",
            "zh": "算法 1[134] 列出了 ID3 算法的伪代码描述。尽管该算法看起来很复杂，但它在每次调用时基本上都会执行以下两件事之一：要么通过向树添加叶节点（第 1-6 行）来停止树中的当前路径增长，要么通过向树添加内部节点并通过重复重新运行算法来扩展该节点的分支来扩展当前路径， 第 7-13 行。"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the weight update for each weight in the filter: w0,w1,w2,w3.",
            "zh": "（c） 计算过滤器中每个砝码的重量更新：w0，w1，w2，w3。"
        }
    },
    {
        "translation": {
            "en": "For example, the scales of the axes must always be kept consistent, as should the order of the bars in the individual bar plots.",
            "zh": "例如，轴的刻度必须始终保持一致，各个条形图中条形的顺序也应保持一致。"
        }
    },
    {
        "translation": {
            "en": "Rather, FRAUD FLAG is a categorical feature that just happens to use 0 and 1 as its category labels, which has led to its being treated as continuous in the ABT.",
            "zh": "相反，FRAUD FLAG 是一个分类特征，恰好使用 0 和 1 作为其类别标签，这导致它在 ABT 中被视为连续的。"
        }
    },
    {
        "translation": {
            "en": "Generally, there is not an optimal set of intervals for a given feature.",
            "zh": "通常，给定要素没有一组最佳间隔。"
        }
    },
    {
        "translation": {
            "en": "The other cluster centroids are updated similarly, so that c1 = ⟨−0.5727,−0.0706⟩, c2 = ⟨0.8866,−0.7912⟩, and c3 = ⟨−0.3367,0.6123⟩. These are illustrated in Figure 10.3(d)[602].",
            "zh": "其他聚类质心的更新类似，因此 c1 = ⟨−0.5727，−0.0706⟩，c2 = ⟨0.8866，−0.7912⟩，c3 = ⟨−0.3367,0.6123⟩。这些如图10.3（d）[602]所示。"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using Xavier initialization.",
            "zh": "图 8.22[450] 中网络的内部动力学，在第一次训练迭代期间，当权重使用 Xavier 初始化进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "That intelligent behavior can be driven by the singular goal of maximizing return is a bold statement—it is often argued that it is very ambitious to expect sophisticated, long-term behavior to emerge from simple accumulation of instantaneous rewards.",
            "zh": "智能行为可以由最大化回报的单一目标驱动，这是一个大胆的声明——人们经常认为，期望从简单的即时奖励积累中产生复杂的长期行为是非常雄心勃勃的。"
        }
    },
    {
        "translation": {
            "en": "First, individually, the 7 probabilities have fewer constraints on them than the 16 in the full joint probability distribution.",
            "zh": "首先，单独来看，在完全联合概率分布中，7 个概率对它们的约束少于 16 个概率。"
        }
    },
    {
        "translation": {
            "en": "For fr the probability P(ACC = free | fr) causes the problem, and for ¬fr the probability P(GC = guarantor | ¬fr) is the offender.",
            "zh": "对于 fr，概率 P（ACC = free | fr） 导致问题，而对于 ¬fr，概率 P（GC = 担保人 | ¬fr） 是违规者。"
        }
    },
    {
        "translation": {
            "en": "The feature UNKNOWN SENDER has an information gain of 0.0817 bits.",
            "zh": "UNKNOWN SENDER 功能的信息增益为 0.0817 位。"
        }
    },
    {
        "translation": {
            "en": "From the disorganized letters at the beginning, Abigail divided the letters into six different-colored groups, Andrew organized them into a lowercase group and an uppercase group, and Sarah made a group for each letter of the alphabet.",
            "zh": "从一开始杂乱无章的字母开始，阿比盖尔将字母分成六个不同颜色的组，安德鲁将它们组织成小写组和大写组，莎拉为字母表的每个字母组。"
        }
    },
    {
        "translation": {
            "en": "6.1   A simple dataset for a MENINGITIS diagnosis with descriptive features that describe the presence or absence of three common symptoms of the disease: HEADACHE, FEVER, and VOMITING.",
            "zh": "6.1 用于脑膜炎诊断的简单数据集，具有描述性特征，描述是否存在该疾病的三种常见症状：头痛、发烧和呕吐。"
        }
    },
    {
        "translation": {
            "en": "Using unsupervised learning to generate feature representations that could be used in later supervised models (e.g., Hinton et al.",
            "zh": "使用无监督学习来生成可用于以后监督模型的特征表示（例如，Hinton et al."
        }
    },
    {
        "translation": {
            "en": "statistics, 369",
            "zh": "统计， 369"
        }
    },
    {
        "translation": {
            "en": "7.4.6 Multinomial Logistic Regression",
            "zh": "7.4.6 多项式逻辑回归"
        }
    },
    {
        "translation": {
            "en": "Subset Selection: This component selects the feature subset from the set of candidate feature subsets generated by the subset generation component that is the most desirable for the search process to move to.",
            "zh": "子集选择：此组件从子集生成组件生成的候选特征子集集中选择搜索过程最理想的特征子集。"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of α = 0.1, calculate the updated values for each of the weights in the network (w3,2,w3,0,,w2,1,w2,0,) after the processing of this single training example.",
            "zh": "假设学习率为 α = 0.1，在处理完此训练示例后，计算网络中每个权重 （w3,2，w3,0，，w2,1，w2,0，） 的更新值。"
        }
    },
    {
        "translation": {
            "en": "Bayesian networks have been successfully applied across a range of fields, including medical diagnosis, object recognition, and natural language understanding.",
            "zh": "贝叶斯网络已成功应用于多个领域，包括医学诊断、对象识别和自然语言理解。"
        }
    },
    {
        "translation": {
            "en": "For each partition a branch is grown from the node.",
            "zh": "对于每个分区，都会从节点中生长一个分支。"
        }
    },
    {
        "translation": {
            "en": "Each of us has also been fortunate to have the support of close friends and family, which was invaluable in completing the book.",
            "zh": "我们每个人都很幸运地得到了亲密朋友和家人的支持，这对完成这本书来说是无价的。"
        }
    },
    {
        "translation": {
            "en": "In Figure 5.12(b)[205], however, both axes range from 0 to 1.",
            "zh": "然而，在图5.12（b）[205]中，两个轴的范围从0到1。"
        }
    },
    {
        "translation": {
            "en": "For example, to make predictions on the outcome of loans granted by a bank, we might use the borrower’s salary as a descriptive feature.",
            "zh": "例如，为了预测银行发放的贷款结果，我们可能会使用借款人的工资作为描述性特征。"
        }
    },
    {
        "translation": {
            "en": "In backpropagation, the error gradient with respect to an input to a product of two terms is the error gradient with respect to the result of the product multiplied by the other input to the product.",
            "zh": "在反向传播中，相对于两个项的乘积的输入的误差梯度是相对于乘积结果乘以乘积的另一个输入的误差梯度。"
        }
    },
    {
        "translation": {
            "en": "We can see this in the decision boundaries shown in the bottom-right panel of Figure 7.21[360].",
            "zh": "我们可以在图 7.21[360] 右下角面板所示的决策边界中看到这一点。"
        }
    },
    {
        "translation": {
            "en": "10.4   (a)–(h) Different clusterings (all with k = 3) that can be found for the mobile phone customer dataset given in Table 10.1[604] when different initial cluster centroids are used.",
            "zh": "10.4 （a）–（h） 当使用不同的初始聚类质心时，对于表 10.1[604] 中给出的移动电话客户数据集，可以找到不同的聚类（均为 k = 3）。"
        }
    },
    {
        "translation": {
            "en": "In general, converting a business problem into an analytics solution involves answering the following key questions:",
            "zh": "通常，将业务问题转换为分析解决方案涉及回答以下关键问题："
        }
    },
    {
        "translation": {
            "en": "The analytics consultant has generated an ABT to be used to train this model.17 The descriptive features in this dataset are defined as follows:",
            "zh": "分析顾问已生成用于训练此模型的 ABT。17 此数据集中的描述性特征定义如下："
        }
    },
    {
        "translation": {
            "en": "If a prediction task is affected by concept drift, an eager learner may not be appropriate because the abstraction induced during training will go out of date, and the model will need to be retrained at regular intervals, a costly exercise.",
            "zh": "如果预测任务受到概念漂移的影响，那么热切的学习者可能不适合，因为在训练过程中诱导的抽象将过时，并且模型需要定期重新训练，这是一项代价高昂的工作。"
        }
    },
    {
        "translation": {
            "en": "These error gradients are used to update the weights of the network.",
            "zh": "这些误差梯度用于更新网络的权重。"
        }
    },
    {
        "translation": {
            "en": "A summary of the tasks in the Business Understanding, Data Understanding, and Data Preparation phases of the CRISP-DM process.",
            "zh": "CRISP-DM 流程的业务理解、数据理解和数据准备阶段的任务摘要。"
        }
    },
    {
        "translation": {
            "en": "Inspecting the right-hand column of this table and comparing the magnitude of the ∂ℰ/∂wi,k terms, the most significant digit in the ∂ℰ/∂wi,k terms for weights on inputs to Neuron 8 are at 10−2; by comparison the most significant digit for the ∂ℰ/∂wi,k terms for the weights on inputs to Neurons 3, 4, and 5 (the first hidden layer) are at 10−4.",
            "zh": "检查该表的右列并比较 ∂E/∂wi，k 项的大小，∂E/∂wi，k 项中神经元 8 输入权重的最有效数字为 10−2;相比之下，神经元 3、4 和 5（第一个隐藏层）输入权重的 ∂E/∂wi，k 项的最高有效数字为 10−4。"
        }
    },
    {
        "translation": {
            "en": "UERR_U/G/R/I/Z",
            "zh": "UERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Figure 4.18",
            "zh": "图 4.18"
        }
    },
    {
        "translation": {
            "en": "The second convolutional layer had 256 filters, and also used a ReLU non-linearity and max pooling.",
            "zh": "第二个卷积层有 256 个滤波器，并且还使用了 ReLU 非线性和最大池化。"
        }
    },
    {
        "translation": {
            "en": "probability mass, 266, 758",
            "zh": "概率质量，266,758"
        }
    },
    {
        "translation": {
            "en": "TNR, 548",
            "zh": "TNR，548"
        }
    },
    {
        "translation": {
            "en": "However, today the most popular choice of function for an activation function is the rectified linear activation function or rectifier",
            "zh": "然而，今天最流行的激活函数选择是整流线性激活函数或整流器"
        }
    },
    {
        "translation": {
            "en": "In the sets shown in Figures 4.5(b)[124] and 4.5(c)[124], there is a mixture of two different types of cards, so that these have higher entropy values—in these instances, 0.81 bits and 1.00 bit.",
            "zh": "在图4.5（b）[124]和图4.5（c）[124]所示的集合中，混合了两种不同类型的卡，因此它们具有更高的熵值 - 在这些实例中为0.81位和1.00位。"
        }
    },
    {
        "translation": {
            "en": "Decision trees are also considered non-parametric models.",
            "zh": "决策树也被视为非参数模型。"
        }
    },
    {
        "translation": {
            "en": "anti-discrimination legislation, 40",
            "zh": "反歧视立法，40"
        }
    },
    {
        "translation": {
            "en": "This compares favorably to a random player that will expect to lose on average $197 ± 25 out of 1,000 hands.",
            "zh": "相比之下，随机玩家预计在 1,000 手牌中平均输掉 197 ± 25 美元。"
        }
    },
    {
        "translation": {
            "en": "1.9 Exercises",
            "zh": "1.9 练习"
        }
    },
    {
        "translation": {
            "en": "In this case the logistic regression model used for the 3-level target feature would first be used, and then a model trained to distinguish only between different spiral galaxy types (clockwise, anti-clockwise, and edge-on) would be used to further classify those galaxy objects classified as spiral by the first stage.",
            "zh": "在这种情况下，将首先使用用于 3 级目标特征的逻辑回归模型，然后使用经过训练以仅区分不同螺旋星系类型（顺时针、逆时针和边缘）的模型将用于进一步分类那些按第一阶段归类为螺旋星系的星系天体。"
        }
    },
    {
        "translation": {
            "en": "BIC, 292",
            "zh": "BIC，292"
        }
    },
    {
        "translation": {
            "en": "Figure 3.9",
            "zh": "图 3.9"
        }
    },
    {
        "translation": {
            "en": "gamma function, 271",
            "zh": "伽马函数，271"
        }
    },
    {
        "translation": {
            "en": "For example, this allows us to use the probability of a patient having a fever given that the patient has meningitis, rather than the more constrained conditional probability of the patient having a fever given that the patient has meningitis and is suffering from a headache.",
            "zh": "例如，这允许我们使用患者发烧的概率，因为患者患有脑膜炎，而不是患者发烧的条件概率，因为患者患有脑膜炎并且患有头痛。"
        }
    },
    {
        "translation": {
            "en": "Strang, Gilbert. 2019. Linear algebra and learning from data. Wellesley-Cambridge Press.",
            "zh": "斯特朗，吉尔伯特。2019. 线性代数与数据学习.韦尔斯利-剑桥出版社。"
        }
    },
    {
        "translation": {
            "en": "(b) If the analyst was using a distance weighted averaging function rather than a simple average for his or her predictions, would this have made the analyst’s idea any more useful?",
            "zh": "（b） 如果分析员使用距离加权平均函数而不是简单平均值进行预测，这会使分析员的想法更有用吗？"
        }
    },
    {
        "translation": {
            "en": "As a result, a naive Bayes model can be trained relatively quickly compared to many other prediction models.",
            "zh": "因此，与许多其他预测模型相比，朴素贝叶斯模型可以相对快速地进行训练。"
        }
    },
    {
        "translation": {
            "en": "This type of learning illustrates one of the real strengths of the Bayesian network framework, namely, that it provides an approach to learning that naturally accommodates human expert information.",
            "zh": "这种类型的学习说明了贝叶斯网络框架的真正优势之一，即它提供了一种自然适应人类专家信息的学习方法。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrices showing the performance of models on the under-sampled training set.",
            "zh": "混淆矩阵显示模型在欠采样训练集上的性能。"
        }
    },
    {
        "translation": {
            "en": "Averaging across these localized values gives an overall measure of the overall quality of the clustering. The silhouette for a clustering will always be in the range from − 1 to 1. A value near 1 suggests a good clustering, while a value near − 1 suggests a poor clustering (with the caveat that these scores are based on the assumption about desired characteristics of a clustering described previously).",
            "zh": "对这些局部化值进行平均可以总体衡量聚类的整体质量。聚类的轮廓将始终在 − 1 到 1 的范围内。接近 1 的值表示聚类良好，而接近 − 1 的值表示聚类较差（需要注意的是，这些分数基于前面描述的聚类所需特征的假设）。"
        }
    },
    {
        "translation": {
            "en": "We underestimated, however, the amount of support we would need and receive from other people.",
            "zh": "然而，我们低估了我们需要和从其他人那里得到的支持量。"
        }
    },
    {
        "translation": {
            "en": "The observation period is the time prior to the claim event, over which the descriptive features capturing the claimant’s behavior are calculated, and the outcome period is the time immediately after the claim event, during which it will emerge whether the claim is fraudulent or genuine.",
            "zh": "观察期是索赔事件发生前的时间，在该时间内计算捕获索赔人行为的描述性特征，结果期是索赔事件发生后立即出现的时间，在此期间，索赔是欺诈性的还是真实的。"
        }
    },
    {
        "translation": {
            "en": "GENDER: The patient’s gender (male or female)",
            "zh": "性别：患者的性别（男性或女性）"
        }
    },
    {
        "translation": {
            "en": "Skew is simply a tendency toward very high (right skew as seen in Figure 3.2(c)[60]) or very low (left skew as seen in Figure 3.2(d)[60]) values.",
            "zh": "偏斜只是趋向于非常高（图 3.2（c）[60] 所示的右偏斜）或非常低（图 3.2（d）[60] 所示的左偏斜）值。"
        }
    },
    {
        "translation": {
            "en": "To calculate a probability using the Generalized Bayes’ Theorem, we need to calculate three probabilities:",
            "zh": "要使用广义贝叶斯定理计算概率，我们需要计算三个概率："
        }
    },
    {
        "translation": {
            "en": "To measure the color of night sky objects, the flux measured in different photometric bands is compared.",
            "zh": "为了测量夜空物体的颜色，比较了在不同光度波段测量的通量。"
        }
    },
    {
        "translation": {
            "en": "Bar plots of the different galaxy types present in the full SDSS dataset for the 3-level and 5-level target features.",
            "zh": "完整 SDSS 数据集中 3 级和 5 级目标要素中不同星系类型的条形图。"
        }
    },
    {
        "translation": {
            "en": "Outliers (high)",
            "zh": "异常值（高）"
        }
    },
    {
        "translation": {
            "en": "One of the most striking things about this plot is that the top-right region of the feature space again belongs to the no region.",
            "zh": "这个图最引人注目的地方之一是，特征空间的右上角区域再次属于无区域。"
        }
    },
    {
        "translation": {
            "en": "In this iteration the subtree underneath the root node of the decision tree (the CORE-TEMP node) is considered for pruning (i.e., the full decision tree).",
            "zh": "在此迭代中，考虑对决策树根节点（CORE-TEMP 节点）下的子树进行修剪（即完整的决策树）。"
        }
    },
    {
        "translation": {
            "en": "The percentage by which the customer’s peak calls to off-peak calls ratio has changed from last month to this month",
            "zh": "从上个月到本月，客户的高峰呼叫与非高峰呼叫比率的百分比发生了变化"
        }
    },
    {
        "translation": {
            "en": "Kronecker delta, 192, 195",
            "zh": "克罗内克三角洲， 192， 195"
        }
    },
    {
        "translation": {
            "en": "However, we do not need to change anything with regard to the calculation of the δs for the hidden neurons; once we have updated the calculation of the δs for the output neurons, then the error gradients can flow back through the network as previously.",
            "zh": "然而，我们不需要改变隐藏神经元的δs的计算;一旦我们更新了输出神经元的 δ 计算，那么误差梯度就可以像以前一样流回网络。"
        }
    },
    {
        "translation": {
            "en": "Throughout this chapter, named features will be denoted by the uppercase initial letters of their names—for example, a feature named MENINGITIS will be denoted by M. Also, where a named feature is binary, we will use the lowercase initial letter of the feature name to denote the event where the feature is true and the lowercase initial letter preceded by the ¬ symbol to denote the event where it is false.",
            "zh": "在本章中，命名的特征将用其名称的大写首字母表示，例如，名为脑膜炎的特征将用 M 表示。此外，如果命名特征是二进制的，我们将使用特征名称的小写首字母来表示特征为真的事件，并使用小写的首字母前面加上 ¬ 符号来表示它为假的事件。"
        }
    },
    {
        "translation": {
            "en": "23. These values are recommended by Sutton and Barto (2018) but can be tuned through experimentation.",
            "zh": "23. 这些值是 Sutton 和 Barto （2018） 推荐的，但可以通过实验进行调整。"
        }
    },
    {
        "translation": {
            "en": "The normal and the student-t distributions are both very similar, and both do a good job of matching the shape of the density histogram.",
            "zh": "正态分布和 student-t 分布都非常相似，并且都很好地匹配了密度直方图的形状。"
        }
    },
    {
        "translation": {
            "en": "The process that the AT retention team had in place at the beginning of the project to identify customers likely to churn took a single feature approach to this identification—they looked only at how many calls a customer had made to the AT customer support service.",
            "zh": "AT 保留团队在项目开始时为识别可能流失的客户而制定的流程采用了单一功能方法来识别此识别——他们只查看客户向 AT 客户支持服务拨打了多少电话。"
        }
    },
    {
        "translation": {
            "en": "This raises the question of when to use which machine learning approach.",
            "zh": "这就提出了一个问题，即何时使用哪种机器学习方法。"
        }
    },
    {
        "translation": {
            "en": "We have covered three architectures in this chapter: feedforward networks are appropriate if the descriptive features are in a fixed-sized vector; if the input data has a grid-like structure, then consider a convolutional neural network; and if the input may be a variable length sequence, then a recurrent neural network or LSTM network will be most appropriate.",
            "zh": "在本章中，我们介绍了三种架构：如果描述性特征位于固定大小的向量中，则前馈网络是合适的;如果输入数据具有类似网格的结构，则考虑卷积神经网络;如果输入可能是可变长度序列，则递归神经网络或 LSTM 网络将是最合适的。"
        }
    },
    {
        "translation": {
            "en": "If the generation process proves to be error-free, then features with a cardinality of 1, although valid, should be removed from an ABT because they will not be of any value in building predictive models.",
            "zh": "如果生成过程被证明是无错误的，则基数为 1 的特征虽然有效，但应从 ABT 中删除，因为它们在构建预测模型方面没有任何价值。"
        }
    },
    {
        "translation": {
            "en": "If you lie too far forward on your board, you will begin to make great progress before the surfboard tilts nose down into the water and launches you head over heels into the air.",
            "zh": "如果你在冲浪板上躺得太靠前，你会在冲浪板将鼻子向下倾斜到水中并将你头顶到空中之前开始取得很大的进步。"
        }
    },
    {
        "translation": {
            "en": "Edwin helped Jocelyn align the columns in the raw SDSS dataset with the different domain concepts, which generated a good set of descriptive features within each domain concept.",
            "zh": "Edwin 帮助 Jocelyn 将原始 SDSS 数据集中的列与不同的领域概念对齐，从而在每个领域概念中生成了一组很好的描述性特征。"
        }
    },
    {
        "translation": {
            "en": "If new instances were added to the dataset and we rebuilt the tree, it is likely that we would end up with a (potentially very) different tree.",
            "zh": "如果将新实例添加到数据集中并重新构建树，我们很可能最终会得到一棵（可能非常）不同的树。"
        }
    },
    {
        "translation": {
            "en": "It is relatively straightforward to fit the parameters, μ and σ, of the normal distribution to a dataset by using the sample mean and standard deviation of the feature values in a dataset as estimates of μ and σ respectively.",
            "zh": "通过使用数据集中特征值的样本均值和标准差分别作为 μ 和 σ 的估计值，将正态分布的参数 μ 和 σ 拟合到数据集相对简单。"
        }
    },
    {
        "translation": {
            "en": "This will allow Conor to make good choices based on his current knowledge, but also to explore new items and learn about the rewards associated with them.",
            "zh": "这将使康纳能够根据他目前的知识做出正确的选择，同时也可以探索新物品并了解与之相关的奖励。"
        }
    },
    {
        "translation": {
            "en": "24. The name SARSA comes from the terms st, at, rt, st+1, and at+1 used in the algorithm and the order in which they appear.",
            "zh": "24. SARSA 的名称来源于算法中使用的术语 st、at、rt、st+1 和 at+1 以及它们出现的顺序。"
        }
    },
    {
        "translation": {
            "en": "If we were to use a model that includes salary values over an extended period (for example, 10 years) the salary values used to initially train the model may have no relationship to the values that would be presented to the model later on.",
            "zh": "如果我们要使用包含较长时间（例如，10 年）的工资值的模型，则用于初始训练模型的工资值可能与以后将呈现给模型的值没有关系。"
        }
    },
    {
        "translation": {
            "en": "forward sequential selection, 229",
            "zh": "前向顺序选择，229"
        }
    },
    {
        "translation": {
            "en": "NEWFREQUENTNUMBERS",
            "zh": "新频数"
        }
    },
    {
        "translation": {
            "en": "We now understand the standard nearest neighbor algorithm. The algorithm, as presented, can work well with clean, reasonably sized datasets containing continuous descriptive features. Often, however, datasets are noisy, very large, and may contain a mixture of different data types. As a result, a lot of extensions and variations of the algorithm have been developed to address these issues. In this section we describe the most important of these.",
            "zh": "我们现在了解了标准的最近邻算法。如上所述，该算法可以很好地处理包含连续描述性特征的干净、合理大小的数据集。但是，数据集通常很嘈杂，非常大，并且可能包含不同数据类型的混合。因此，已经开发了许多算法的扩展和变体来解决这些问题。在本节中，我们将介绍其中最重要的内容。"
        }
    },
    {
        "translation": {
            "en": "Approaches that do this are referred to as approximate methods.",
            "zh": "执行此操作的方法称为近似方法。"
        }
    },
    {
        "translation": {
            "en": "use limitation principle, 41",
            "zh": "使用限制原则，41"
        }
    },
    {
        "translation": {
            "en": "We should take care when using standardization as it assumes that data is normally distributed.",
            "zh": "在使用标准化时，我们应该小心，因为它假设数据是正态分布的。"
        }
    },
    {
        "translation": {
            "en": "We can modify Equation (11.3)[641] to define discounted return",
            "zh": "我们可以修改等式（11.3）[641]来定义贴现回报"
        }
    },
    {
        "translation": {
            "en": "Many of these states, however, or not significantly different from each other and so it makes sense to discretize the hand representation so as to have a smaller number of states.",
            "zh": "然而，这些状态中的许多状态或彼此之间没有显着差异，因此离散化手表示以具有较少数量的状态是有意义的。"
        }
    },
    {
        "translation": {
            "en": "Reading from left to right, the first term in this product is the rate of change of the error gradient of the network with respect to changes in the activation (or output) of a neuron i; the second term is the rate of change of the activation of neuron i with respect to changes in zi (the weighted sum for neuron i); and the third term is the rate of change of zi with respect to changes in the weight wi,k.",
            "zh": "从左到右阅读，本产品中的第一个项是网络误差梯度相对于神经元 i 激活（或输出）变化的变化率;第二项是神经元 I 激活相对于 zi 变化的变化率（神经元 i 的加权和）;第三项是 zi 相对于权重 wi，k 变化的变化率。"
        }
    },
    {
        "translation": {
            "en": "In this challenge the scout begins at the edge of the bank on one side of the stream and has to make a series of steps to get to the other side.",
            "zh": "在这个挑战中，侦察员从溪流一侧的河岸边缘开始，必须采取一系列步骤才能到达另一侧。"
        }
    },
    {
        "translation": {
            "en": "Although the gradient boosting approach is most easily explained in the context of predicting continuous targets, it can also be easily adapted to work with categorical targets.",
            "zh": "尽管梯度提升方法在预测连续目标的上下文中最容易解释，但它也可以很容易地适应分类目标。"
        }
    },
    {
        "translation": {
            "en": "The distribution of INSURANCE TYPE is a little strange, as it displays only one level.",
            "zh": "INSURANCE TYPE的分布有点奇怪，因为它只显示一个级别。"
        }
    },
    {
        "translation": {
            "en": "The naive Bayes model can also be easily adapted to handle missing feature values: we simply drop the conditional probabilities for the evidence events that specify features taking values that are not in the data from the product of the evidence events. Obviously, doing this may have a negative effect on the accuracy of posterior probabilities computed by the model, but again this may not translate directly into prediction errors.",
            "zh": "朴素贝叶斯模型也可以很容易地适应处理缺失的特征值：我们只需从证据事件的乘积中去除证据事件的条件概率，这些事件指定特征采用不在数据中的值。显然，这样做可能会对模型计算的后验概率的准确性产生负面影响，但这可能不会直接转化为预测误差。"
        }
    },
    {
        "translation": {
            "en": "-0.5253",
            "zh": "-0.5253"
        }
    },
    {
        "translation": {
            "en": "Information provided at registration includes the type of industry the company is involved in, details of the directors of the company, and where the company is located.",
            "zh": "注册时提供的信息包括公司所从事的行业类型、公司董事的详细信息以及公司所在地。"
        }
    },
    {
        "translation": {
            "en": "17. The features selected were SKYIVAR_U, PETROFLUXIVAR_I, PETROR50ERR_G, DEVRAD_G, DEVRADERR_R, DEVRADERR_I, DEVAB_G, EXPFLUX_Z, APERFLUX7_Z, APERFLUX7IVAR_R, and MODELMAGDIFF_I_Z.",
            "zh": "17. 选定的特征是SKYIVAR_U、PETROFLUXIVAR_I、PETROR50ERR_G、DEVRAD_G、DEVRADERR_R、DEVRADERR_I、DEVAB_G、EXPFLUX_Z、APERFLUX7_Z、APERFLUX7IVAR_R和MODELMAGDIFF_I_Z。"
        }
    },
    {
        "translation": {
            "en": "We can convert a histogram to a probability distribution by dividing the count for each interval by the total number of observations in the dataset multiplied by the width of the interval.",
            "zh": "我们可以通过将每个区间的计数除以数据集中的观测值总数乘以区间宽度来将直方图转换为概率分布。"
        }
    },
    {
        "translation": {
            "en": "Jaccard index, 215, 231",
            "zh": "杰卡德索引，215,231"
        }
    },
    {
        "translation": {
            "en": "For example, if a customer who really was not a churn risk is classified as likely to churn, the cost incurred by the company because of this mistake is the cost of a small bonus offer that would be given to the customer to entice the customer to stay with the company.",
            "zh": "例如，如果一个真正没有流失风险的客户被归类为可能流失，那么公司因这个错误而产生的成本是向客户提供小额奖金的成本，以吸引客户留在公司。"
        }
    },
    {
        "translation": {
            "en": "By combining measures in this way, we can apply nearest neighbor models to any dataset.",
            "zh": "通过以这种方式组合度量，我们可以将最近邻模型应用于任何数据集。"
        }
    },
    {
        "translation": {
            "en": "The sets shown in Figures 4.5(d)[124] and 4.5(e)[124] both have three types of cards.",
            "zh": "图4.5（d）[124]和图4.5（e）[124]所示的牌组都有三种类型的牌。"
        }
    },
    {
        "translation": {
            "en": "The harmonic mean results in a more pessimistic view of model performance than an arithmetic mean.",
            "zh": "与算术均值相比，谐波均值导致对模型性能的看法更悲观。"
        }
    },
    {
        "translation": {
            "en": "In these situations, as k increases, the majority target level begins to dominate the feature space.",
            "zh": "在这些情况下，随着 k 的增加，多数目标级别开始主导特征空间。"
        }
    },
    {
        "translation": {
            "en": "We see in subsequent examples that designing good state representations is one of the arts of reinforcement learning.",
            "zh": "在随后的示例中，我们看到设计良好的状态表示是强化学习的艺术之一。"
        }
    },
    {
        "translation": {
            "en": "Checking for features with a low cardinality will highlight these features.",
            "zh": "检查具有低基数的要素将突出显示这些要素。"
        }
    },
    {
        "translation": {
            "en": "Tesauro, Gerald. 1994. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Computation 6 (2): 215–219.",
            "zh": "特索罗，杰拉尔德。1994. TD-gammon，一个自学的西洋双陆棋项目，实现了大师级游戏。神经计算6（2）：215-219。"
        }
    },
    {
        "translation": {
            "en": "The distinctive characteristic of deep learning models is that they are deeper and larger than older neural networks.",
            "zh": "深度学习模型的显着特征是它们比旧的神经网络更深、更大。"
        }
    },
    {
        "translation": {
            "en": "The new value for the selected node is drawn from the distribution for the node (the CPT), conditioned on the current state of all the other nodes in the network.",
            "zh": "所选节点的新值是从节点的分布 （CPT） 中提取的，以网络中所有其他节点的当前状态为条件。"
        }
    },
    {
        "translation": {
            "en": "6.11   (a) A Bayesian network representation of the conditional independence asserted by a naive Bayes model between the descriptive features given knowledge of the target feature; and (b) a Bayesian network representation of the conditional independence assumption for the naive Bayes model in the fraud example.",
            "zh": "6.11 （a） 朴素贝叶斯模型在给定目标特征知识的情况下，在描述性特征之间断言条件独立性的贝叶斯网络表示;（b）欺诈示例中朴素贝叶斯模型的条件独立性假设的贝叶斯网络表示。"
        }
    },
    {
        "translation": {
            "en": "A relevant point from that discussion was that large weight updates could result in the error actually increasing (see Figure 7.9[336]).",
            "zh": "该讨论的一个相关观点是，较大的权重更新可能导致误差实际增加（参见图7.9[336]）。"
        }
    },
    {
        "translation": {
            "en": "The weight of a component in the sum determines the contribution of the component to the overall density of the resulting mixture.",
            "zh": "总和中组分的重量决定了组分对所得混合物总密度的贡献。"
        }
    },
    {
        "translation": {
            "en": "Information gain has the advantage that it is computationally less expensive than information gain ratio.",
            "zh": "信息增益的优点是它在计算上比信息增益比便宜。"
        }
    },
    {
        "translation": {
            "en": "The predictions using the k = 3 nearest neighbor model and the weighted k nearest neighbor model with k set to the size of the dataset are quite similar: 168.33 and 163.71.",
            "zh": "使用 k = 3 最近邻模型和将 k 设置为数据集大小的加权 k 最近邻模型的预测非常相似：168.33 和 163.71。"
        }
    },
    {
        "translation": {
            "en": "Compare the amount of computation required to calculate the output of the support vector machine using the polynomial kernel function with the amount required to calculate the output of the support vector machine using the basis functions.",
            "zh": "比较使用多项式核函数计算支持向量机输出所需的计算量与使用基函数计算支持向量机输出所需的计算量。"
        }
    },
    {
        "translation": {
            "en": "On the other hand, if you ask Question 1 first, there is only one sequence of questions with which to follow it. This sequence is shown in Figure 4.3[120]. Irrespective of the answers to the questions, you always have to follow a path through this sequence that is 2 questions long to reach an answer about the character on a card. This means that if you always ask Question 1 first, the average number of questions you have to ask per game is",
            "zh": "另一方面，如果您先问问题 1，则只有一组问题可以紧随其后。该序列如图4.3[120]所示。无论问题的答案如何，您始终必须遵循此序列的路径，该路径长达 2 个问题，才能获得有关卡片上角色的答案。这意味着，如果您总是先问问题 1，那么每场比赛您必须问的平均问题数为"
        }
    },
    {
        "translation": {
            "en": "2. then using Bayes’ Theorem to compute the class posterior probabilities P(tl|d);2",
            "zh": "2.然后使用贝叶斯定理计算类后验概率P（tl|d）;2"
        }
    },
    {
        "translation": {
            "en": "Table 6.10",
            "zh": "表 6.10"
        }
    },
    {
        "translation": {
            "en": "Consequently, it is standard to use a patience parameter to control early stopping.",
            "zh": "因此，使用耐心参数来控制提前停止是标准的。"
        }
    },
    {
        "translation": {
            "en": "D.3 Multiplication",
            "zh": "D.3 乘法"
        }
    },
    {
        "translation": {
            "en": "Tabulating the workings required to calculate gain, cumulative gain, lift, and cumulative lift for the data given in Table 9.11[557].",
            "zh": "将计算表9.11[557]中给出的数据的增益、累积增益、升力和累积升力所需的工作制成表格。"
        }
    },
    {
        "translation": {
            "en": "Using partial derivatives offers us an easy way to calculate the derivative of a function like this.",
            "zh": "使用偏导数为我们提供了一种简单的方法来计算这样的函数的导数。"
        }
    },
    {
        "translation": {
            "en": "This was an important step in gaining credibility for the model.",
            "zh": "这是获得该模型可信度的重要一步。"
        }
    },
    {
        "translation": {
            "en": "3.5.1.3 Visualizing a categorical feature and a continuous feature The best way to visualize the relationship between a continuous feature and a categorical feature is to use a small multiples approach, drawing a density histogram of the values of the continuous feature for each level of the categorical feature.",
            "zh": "3.5.1.3 可视化分类特征和连续特征 可视化连续特征和分类特征之间关系的最佳方法是使用小倍数方法，为分类特征的每个级别绘制连续特征值的密度直方图。"
        }
    },
    {
        "translation": {
            "en": "The details of a professional basketball team.",
            "zh": "职业篮球队的细节。"
        }
    },
    {
        "translation": {
            "en": "This was likely to continue to be the case, so any solution that relied on spectrographic data as well as imaging data to classify galaxy types would work for only a fraction of the observations made by the SDSS telescopes.",
            "zh": "这种情况可能会继续下去，因此任何依靠光谱数据和成像数据对星系类型进行分类的解决方案都只适用于SDSS望远镜观测的一小部分。"
        }
    },
    {
        "translation": {
            "en": "7.3.3 Choosing Learning Rates and Initial Weights",
            "zh": "7.3.3 选择学习率和初始权重"
        }
    },
    {
        "translation": {
            "en": "This domain subconcept captures the variety of claim types made by the claimant in the past, as these might provide evidence of possible fraud.",
            "zh": "该域子概念捕获了索赔人过去提出的各种索赔类型，因为这些索赔类型可能提供可能的欺诈证据。"
        }
    },
    {
        "translation": {
            "en": "Finally, the Theorem of Total Probability defines the unconditional probability for any event X as",
            "zh": "最后，总概率定理将任何事件 X 的无条件概率定义为"
        }
    },
    {
        "translation": {
            "en": "4.4.4 Tree Pruning",
            "zh": "4.4.4 树木修剪"
        }
    },
    {
        "translation": {
            "en": "As a result of this recursive summing out, the distribution over a node is dependent on knowledge of the ancestors of any of its parent nodes.22 For example, in Figure 6.9(b)[287], if the status of node C is not known, then node B becomes dependent on node D. For example, to compute P(b | a,d) we would do the following calculations:",
            "zh": "22 例如，在图 6.9（b）[287] 中，如果节点 C 的状态未知，则节点 B 将依赖于节点 D。例如，为了计算 P（b | a，d），我们将进行以下计算："
        }
    },
    {
        "translation": {
            "en": "The obvious way to do this is to have the model return the target level that has the highest posterior probability given the state of the descriptive features in the query.",
            "zh": "执行此操作的明显方法是让模型返回给定查询中描述性特征状态时具有最高后验概率的目标级别。"
        }
    },
    {
        "translation": {
            "en": "softmax function, 463, 658",
            "zh": "softmax函数，463,658"
        }
    },
    {
        "translation": {
            "en": "This finding is notorious in the history of neural networks.",
            "zh": "这一发现在神经网络的历史上是臭名昭著的。"
        }
    },
    {
        "translation": {
            "en": "Once Jocelyn felt that she was suitably fluent with the SDSS situation, she proceeded to the Data Understanding phase of the CRISP-DM process so as to better understand the data available.",
            "zh": "一旦 Jocelyn 认为她对 SDSS 情况非常流利，她就进入了 CRISP-DM 流程的数据理解阶段，以便更好地理解可用数据。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix from the test of the AT churn prediction stratified hold-out test set using the pruned decision tree in Figure 12.5[699].",
            "zh": "使用图 12.5 [699] 中修剪后的决策树，来自 AT 流失预测分层保持测试集的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "1. All the instances in the dataset have the same target feature level. In this situation, the algorithm returns a single leaf node tree with that target level as its label (Algorithm 1[134] Lines 1–2).",
            "zh": "1. 数据集中的所有实例都具有相同的目标特征级别。在这种情况下，算法返回一个以该目标级别为标签的单叶节点树（算法 1[134] 第 1-2 行）。"
        }
    },
    {
        "translation": {
            "en": "Eager learners abstract away from the data during training and use this abstraction to make predictions, rather than directly comparing queries with instances in the dataset.",
            "zh": "热心学习者在训练期间从数据中抽象出来，并使用这种抽象来做出预测，而不是直接将查询与数据集中的实例进行比较。"
        }
    },
    {
        "translation": {
            "en": "(c) Calculate the distances of each instance to these new cluster centers and perform another clustering iteration.",
            "zh": "（c） 计算每个实例到这些新聚类中心的距离，并执行另一次聚类迭代。"
        }
    },
    {
        "translation": {
            "en": "These sub-optimal clusterings are rare—for this dataset the vast majority of initial centroid choices will lead to the clustering in Figure 10.3(f)[602]—but they can occur. In large multivariate datasets they are more common, and the algorithm can very easily arrive in one—we don’t have the luxury of simply visualizing high-dimensional datasets to check against an intuitive clustering.",
            "zh": "这些次优聚类很少见——对于这个数据集，绝大多数初始质心选择将导致图10.3（f）[602]中的聚类——但它们可能会发生。在大型多变量数据集中，它们更为常见，并且该算法可以很容易地到达一个数据集中——我们没有简单地可视化高维数据集来检查直观的聚类。"
        }
    },
    {
        "translation": {
            "en": "13. We direct the interested reader to http://skyserver.sdss3.org/dr9/en/sdss/data/data.asp for a overview of what these features represent.",
            "zh": "13. 我们引导感兴趣的读者 http://skyserver.sdss3.org/dr9/en/sdss/data/data.asp，以概述这些功能所代表的内容。"
        }
    },
    {
        "translation": {
            "en": "discounted return, 642",
            "zh": "折扣退货，642"
        }
    },
    {
        "translation": {
            "en": "These random samples are known as bootstrap samples, and one model is induced from each bootstrap sample.",
            "zh": "这些随机样本称为 bootstrap 样本，每个 bootstrap 样本都归出一个模型。"
        }
    },
    {
        "translation": {
            "en": "to convince the business for whom a model is being developed that the model will meet their needs",
            "zh": "说服正在为其开发模型的企业，该模型将满足他们的需求"
        }
    },
    {
        "translation": {
            "en": "Calculating the silhouette for the final clustering of the mobile phone customer dataset (Table 10.1[604]) found using the k-means algorithm (with k = 3). The overall silhouette index value is 0.66.",
            "zh": "计算使用 k 均值算法（k = 3）找到的移动电话客户数据集最终聚类的轮廓（表 10.1[604]）。整体轮廓指数值为 0.66。"
        }
    },
    {
        "translation": {
            "en": "The second thing that is apparent from the images in Figure 14.2[737] is that some of the models do a better job of representing the underlying decision boundaries than others.",
            "zh": "从图14.2[737]中的图像中可以明显看出的第二件事是，一些模型在表示基础决策边界方面比其他模型做得更好。"
        }
    },
    {
        "translation": {
            "en": "Using this new ABT, Jocelyn trained a logistic regression model to distinguish between the three spiral galaxy types (spiral_cw, spiral_acw, and spiral_eo).",
            "zh": "使用这个新的ABT，Jocelyn训练了一个逻辑回归模型来区分三种螺旋星系类型（spiral_cw、spiral_acw和spiral_eo）。"
        }
    },
    {
        "translation": {
            "en": "2. Identity: metric(a,b) = 0⇐⇒a = b",
            "zh": "2. 标识：metric（a，b） = 0⇐⇒a = b"
        }
    },
    {
        "translation": {
            "en": "“money, money, money”",
            "zh": "“钱，钱，钱”"
        }
    },
    {
        "translation": {
            "en": "To apply early stopping, we first set aside a portion of the training data as a validation set.",
            "zh": "为了应用提前停止，我们首先留出一部分训练数据作为验证集。"
        }
    },
    {
        "translation": {
            "en": "The first columns of Table 4.14[162] detail a small sample dataset giving temperatures, TEMP, and rental demand, RENTALS (which can be either Low or High), for 10 days.",
            "zh": "表 4.14[162] 的第一列详细介绍了一个小型样本数据集，该数据集给出了 10 天的温度、温度和租赁需求、租赁（可以是低或高）。"
        }
    },
    {
        "translation": {
            "en": "Although we have an infinite number of Minkowski-based distance metrics to choose from, Euclidean distance and Manhattan distance are the most commonly used of these.",
            "zh": "尽管我们有无数个基于闵可夫斯基的距离度量可供选择，但欧几里得距离和曼哈顿距离是其中最常用的。"
        }
    },
    {
        "translation": {
            "en": "So what would be a reasonable policy for Conor to use to order his dinner each evening?",
            "zh": "那么，康纳每天晚上用什么合理的政策来点晚餐呢？"
        }
    },
    {
        "translation": {
            "en": "8.3.5   A Worked Example: Using Backpropagation to Train a Feedforward Network for a Regression Task",
            "zh": "8.3.5 工作示例：使用反向传播为回归任务训练前馈网络"
        }
    },
    {
        "translation": {
            "en": "Extending this example, if we wanted to study the behavior of two dice, we would create two random variables, we might call them Dice1 and Dice2, each having the domain .",
            "zh": "扩展这个例子，如果我们想研究两个骰子的行为，我们将创建两个随机变量，我们可以称它们为 Dice1 和 Dice2，每个变量都有域。"
        }
    },
    {
        "translation": {
            "en": "He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, 1026–1034.",
            "zh": "何凯明，张翔宇，任少卿和孙健. 2015.深入研究整流器：在图像网络分类方面超越人类水平的性能。IEEE计算机视觉国际会议论文集，1026-1034。"
        }
    },
    {
        "translation": {
            "en": "This increased variation is mirrored in the fact that the rankings based on the distances calculated using the SALARY and AGE features are quite different from the rankings based on the distances calculated using SALARY only.",
            "zh": "这种增加的变化反映在以下事实中：基于使用 SALARY 和 AGE 特征计算的距离的排名与基于仅使用 SALARY 计算的距离的排名有很大不同。"
        }
    },
    {
        "translation": {
            "en": "So we have two different definitions of Bayes’ Theorem (Equation (6.2)[248] and Equation (6.7)[250]), but which one should we use?",
            "zh": "因此，我们对贝叶斯定理有两种不同的定义（方程（6.2）[248]和方程（6.7）[250]），但是我们应该使用哪一个呢？"
        }
    },
    {
        "translation": {
            "en": "Just 11 features from the full set were selected.17 The resulting classification accuracy on the best performing model that Jocelyn could build was 77.528% (with an average class accuracy of 43.018%).",
            "zh": "17 在 Jocelyn 可以构建的最佳性能模型上，最终的分类准确率为 77.528%（平均类准确率为 43.018%）。"
        }
    },
    {
        "translation": {
            "en": "To manually learn this model by examining the data is almost impossible. For a machine learning algorithm, however, this is simple. When we want to build prediction models from large datasets with multiple features, machine learning is the solution.",
            "zh": "通过检查数据来手动学习这个模型几乎是不可能的。然而，对于机器学习算法来说，这很简单。当我们想从具有多个特征的大型数据集构建预测模型时，机器学习是解决方案。"
        }
    },
    {
        "translation": {
            "en": "Sing, Tobias, Oliver Sander, Niko Beerenwinkel, and Thomas Lengauer. 2005. ROCR: Visualizing classifier performance in R. Bioinformatics 21 (20): 3940–3941.",
            "zh": "Sing、Tobias、Oliver Sander、Niko Beerenwinkel 和 Thomas Lengauer。2005. ROCR：在 R. 生物信息学 21 （20）： 3940–3941 中可视化分类器性能。"
        }
    },
    {
        "translation": {
            "en": "Using the Cohen’s kappa19 measure of inter-annotator agreement to measure how closely the manual classifications matched each other, Jocelyn calculated a measure of 0.6.",
            "zh": "使用 Cohen 的 kappa19 注释者间一致性度量来测量手动分类之间的匹配程度，Jocelyn 计算出的度量值为 0.6。"
        }
    },
    {
        "translation": {
            "en": "diabetes, 51",
            "zh": "糖尿病，51"
        }
    },
    {
        "translation": {
            "en": "Using this representation with the following set of basis functions will give the learning process the flexibility to find the non-linear decision boundary required to successfully separate the different types of images in the EEG dataset:17",
            "zh": "将这种表示与以下一组基函数一起使用将使学习过程能够灵活地找到成功分离脑电图数据集中不同类型的图像所需的非线性决策边界：17"
        }
    },
    {
        "translation": {
            "en": "CLAIMS, NUM.",
            "zh": "索赔，编号。"
        }
    },
    {
        "translation": {
            "en": "For example, if a neuron is applying a 2-by-2-by-3 filter, then its local receptive field will have the same dimensions (this is why the depth of the filter must match the depth of the input).",
            "zh": "例如，如果一个神经元正在应用一个 2×2×3 的滤波器，那么它的局部感受野将具有相同的维度（这就是为什么滤波器的深度必须与输入的深度相匹配）。"
        }
    },
    {
        "translation": {
            "en": "7.8   (a) The journey across the error surface for the office rentals prediction problem when learning rate decay is used (α0 = 0.18, c = 10 ); and (b) a plot of the changing sum of squared errors during this journey.",
            "zh": "7.8 （a） 使用学习率衰减时，办公室租赁预测问题的误差面历程 （α0 = 0.18， c = 10 ）;（b）此旅程中误差平方和的变化图。"
        }
    },
    {
        "translation": {
            "en": "In this section we cover two important extensions to the temporal-difference learning approach introduced in the previous section. The first is the SARSA on-policy modification to temporal-difference learning. The second is an extension that uses a predictive machine learning model to replace the action-value table to accommodate environments in which the state-action space is too large for tabular methods to work. Specifically we present the deep Q network (DQN) algorithm.",
            "zh": "在本节中，我们将介绍上一节中介绍的时间差分学习方法的两个重要扩展。首先是SARSA对时间差异学习的政策修改。第二个是使用预测机器学习模型替换操作值表的扩展，以适应状态操作空间太大而表格方法无法工作的环境。具体来说，我们提出了深度Q网络（DQN）算法。"
        }
    },
    {
        "translation": {
            "en": "A.1.2    Variation",
            "zh": "A.1.2 变化"
        }
    },
    {
        "translation": {
            "en": "While the sample of 2,709 voters out of a population of 240,926,957 might appear quite small, we can also see from the table that the margin of error for the poll is given as ± 2.2%.",
            "zh": "虽然在240,926,957人口中，有2,709名选民的样本可能看起来很小，但我们也可以从表中看到，民意调查的误差幅度±2.2%。"
        }
    },
    {
        "translation": {
            "en": "This process is known as statistical inference.",
            "zh": "此过程称为统计推断。"
        }
    },
    {
        "translation": {
            "en": "Table 1.3",
            "zh": "表 1.3"
        }
    },
    {
        "translation": {
            "en": "This gives us a clue as to how we should define a computational model of entropy. We can transform the probabilities3 of the different possible outcomes when we randomly select an element from a set to entropy values. An outcome with a large probability should map to a low entropy value, and an outcome with a small probability should map to a large entropy value. The mathematical logarithm, or log, function4 does almost exactly the transformation that we need.",
            "zh": "这为我们提供了如何定义熵的计算模型的线索。当我们从一组元素中随机选择一个元素到熵值时，我们可以转换不同可能结果的概率3。概率较大的结果应映射到低熵值，概率较小的结果应映射到较大的熵值。数学对数函数 function4 几乎完全符合我们的要求。"
        }
    },
    {
        "translation": {
            "en": "Week",
            "zh": "周"
        }
    },
    {
        "translation": {
            "en": "The final results of the clustering are the cluster centroid values of c1 = ⟨−1.012,−0.131⟩, c2 = ⟨0.8912,−0.7273⟩, and c3 = ⟨−0.0491,0.7022⟩; and the cluster assignments of",
            "zh": "聚类的最终结果是 c1 = ⟨−1.012，−0.131⟩、c2 = ⟨0.8912、−0.7273⟩ 和 c3 = ⟨−0.0491,0.7022⟩;以及"
        }
    },
    {
        "translation": {
            "en": "confidence factor, 161, 178",
            "zh": "置信因子， 161， 178"
        }
    },
    {
        "translation": {
            "en": "absence-presence, 214",
            "zh": "缺席-存在，214"
        }
    },
    {
        "translation": {
            "en": "The k-d tree,8 which is short for k-dimensional tree, is one of the best known of these indices. A k-d tree is a balanced binary tree9 in which each of the nodes in the tree (both interior and leaf nodes) index one of the instances in a training dataset. The tree is constructed so that nodes that are nearby in the tree index training instances that are nearby in the feature space.",
            "zh": "k-d 树 8 是 k 维树的缩写，是这些指数中最著名的指标之一。k-d 树是一种平衡的二叉树9，其中树中的每个节点（内部节点和叶节点）都为训练数据集中的一个实例编制索引。树的构造使树索引训练实例中附近的节点在特征空间中附近。"
        }
    },
    {
        "translation": {
            "en": "11.2.1   Intelligent Agents",
            "zh": "11.2.1 智能代理"
        }
    },
    {
        "translation": {
            "en": "We can calculate P(h,V = ?, M = ?",
            "zh": "我们可以计算 P（h，V = ？， M = ？"
        }
    },
    {
        "translation": {
            "en": "16. The data listed in this table is real and was amalgamated from a number of reports that were retrieved from Gapminder (www.gapminder.org). The EDUCATION data is based on a report from the World Bank (data.worldbank.org/indicator/SE.XPD.PRIM.PC.ZS); the HEALTH and HEALTHUSD data are based on reports from the World Health Organization (www.who.int); all the other features are based on reports created by Gapminder.",
            "zh": "16. 本表所列数据是真实的，是从Gapminder（www.gapminder.org）检索到的若干报告中合并而成的。教育数据基于世界银行（data.worldbank.org/indicator/SE.XPD.PRIM.PC.ZS）的一份报告;HEALTH 和 HEALTHUSD 数据基于世界卫生组织 （www.who.int） 的报告;所有其他功能都基于 Gapminder 创建的报告。"
        }
    },
    {
        "translation": {
            "en": "(b) Some of the Error and Squared Error values are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "（b） 上表中缺少一些“误差”和“平方误差”值（标有 ？）。计算这些。"
        }
    },
    {
        "translation": {
            "en": "9.4.5.1 Basic measures of error In Section 7.2.2[315], when covering error-based learning, we discussed the basis of the most common performance measure for continuous targets: sum of squared errors. The sum of squared errors function, L2, for a set of predictions made by a model, 𝕄, is defined as",
            "zh": "9.4.5.1 误差的基本度量 在第 7.2.2 节[315]中，在介绍基于错误的学习时，我们讨论了连续目标最常见的绩效度量的基础：误差的平方和。模型做出的一组预测的平方误差函数 L2 的平方和定义为"
        }
    },
    {
        "translation": {
            "en": "To ensure maximum exploration Conor could randomly pick one of the menu items each evening.",
            "zh": "为了确保最大的探索，康纳每天晚上都可以随机选择一个菜单项。"
        }
    },
    {
        "translation": {
            "en": "8.4.6.4 Backpropagating through an LSTM cell Figure 8.42[516] illustrates the flow of error gradients through an LSTM during backpropagation. In this figure the error gradients flow from right to left. The backpropagation process within an LSTM begins with three vectors of error gradients",
            "zh": "8.4.6.4 通过LSTM单元的反向传播 图8.42[516]说明了在反向传播过程中通过LSTM的误差梯度流动。在此图中，误差梯度从右向左流动。LSTM 中的反向传播过程从三个误差梯度向量开始"
        }
    },
    {
        "translation": {
            "en": "Berry, Michael J. A, and Gordon S. Linoff. 2004. Data mining techniques: for marketing, sales, and customer relationship management. Wiley.",
            "zh": "贝瑞，迈克尔 J.A和Gordon S. Linoff。2004. 数据挖掘技术：用于营销、销售和客户关系管理。威利。"
        }
    },
    {
        "translation": {
            "en": "Table 4.14",
            "zh": "表 4.14"
        }
    },
    {
        "translation": {
            "en": "Discounting makes intuitive sense, makes some of the mathematics associated with reinforcement learning more straightforward, and avoids any issues with circular paths through states that can arise in some scenarios. Discounted return is widely used in reinforcement learning.",
            "zh": "贴现具有直观意义，使与强化学习相关的一些数学运算更加简单，并避免了在某些情况下可能出现的循环路径通过状态的任何问题。贴现回报在强化学习中被广泛使用。"
        }
    },
    {
        "translation": {
            "en": "Confounding features are a common explanation of mistaken conclusions about causal relationships.",
            "zh": "混杂特征是关于因果关系的错误结论的常见解释。"
        }
    },
    {
        "translation": {
            "en": "The ability to automatically learn useful representations (features) from data is one of the reasons why deep networks have proven to be so successful on so many tasks.",
            "zh": "从数据中自动学习有用的表示（特征）的能力是深度网络在许多任务上被证明如此成功的原因之一。"
        }
    },
    {
        "translation": {
            "en": "Ross did stress to AT management that until he actually examined the data, he could not know how useful a model he would be able to build.",
            "zh": "Ross 确实向 AT 管理层强调，在他真正检查数据之前，他无法知道他能够构建一个多么有用的模型。"
        }
    },
    {
        "translation": {
            "en": "Remembering that the perfect model will appear in the very top left-hand corner of ROC space, it is fairly intuitive that curves with higher areas will be closer to this maximum possible value.",
            "zh": "请记住，完美的模型将出现在 ROC 空间的左上角，因此相当直观的是，具有较高区域的曲线将更接近此最大可能值。"
        }
    },
    {
        "translation": {
            "en": "The human brain is an incredibly powerful learning system. Thanks to neuroscience we now know quite a bit about the structure of the brain. For example, we know that the brain works by propagating electrical signals through a massive network of interconnected cells, known as neurons. In fact, it is estimated that the human brain contains around 100 billion interconnected neurons (Herculano-Houzel, 2009).",
            "zh": "人脑是一个非常强大的学习系统。多亏了神经科学，我们现在对大脑的结构有了相当多的了解。例如，我们知道大脑的工作原理是通过一个由相互连接的细胞组成的庞大网络（称为神经元）传播电信号。事实上，据估计，人脑包含大约1000亿个相互连接的神经元（Herculano-Houzel，2009）。"
        }
    },
    {
        "translation": {
            "en": "0.5590",
            "zh": "0.5590"
        }
    },
    {
        "translation": {
            "en": "Table 10.3",
            "zh": "表 10.3"
        }
    },
    {
        "translation": {
            "en": "reward, 639, 643, 676",
            "zh": "奖励， 639， 643， 676"
        }
    },
    {
        "translation": {
            "en": "Fortunately, the derivative of the logistic function is well known:",
            "zh": "幸运的是，逻辑函数的导数是众所周知的："
        }
    },
    {
        "translation": {
            "en": "The simple multivariable linear regression model that we presented at the beginning of this chapter can be extended in many ways, and we presented some of the most important of these. Logistic regression models (Section 7.4.4[338]) allow us to predict categorical targets rather than continuous ones by placing a threshold on the output of the simple multivariable linear regression model using the logistic function.",
            "zh": "我们在本章开头介绍的简单多变量线性回归模型可以通过多种方式进行扩展，我们介绍了其中最重要的一些。逻辑回归模型（第 7.4.4 节 [338]）允许我们通过使用逻辑函数对简单多变量线性回归模型的输出设置阈值来预测分类目标而不是连续目标。"
        }
    },
    {
        "translation": {
            "en": "A dataset describing grass growth on Irish farms in July 2012.",
            "zh": "描述2012年7月爱尔兰农场牧草生长情况的数据集。"
        }
    },
    {
        "translation": {
            "en": "The feature of the ID3 algorithm that biases it toward shallow trees is the mechanism that it uses to determine which descriptive feature is the most informative one to test at a new node.",
            "zh": "ID3 算法偏向浅树的特征是它用来确定哪个描述性特征是在新节点上测试的信息量最大的特征的机制。"
        }
    },
    {
        "translation": {
            "en": "Consequently, saturated activation functions are problematic for gradient-descent–based algorithms (such as backpropagation) because these algorithms work by iteratively adjusting the weights using small increments that are scaled by the derivative of the activation function.",
            "zh": "因此，饱和激活函数对于基于梯度下降的算法（例如反向传播）来说是有问题的，因为这些算法的工作原理是使用由激活函数的导数缩放的小增量迭代调整权重。"
        }
    },
    {
        "translation": {
            "en": "The RPM and VIBRATION measurements come from the day before the generators proved to be operational or faulty.",
            "zh": "RPM 和 VIBRATION 测量值来自发电机被证明运行或故障的前一天。"
        }
    },
    {
        "translation": {
            "en": "There are, of course, many different weight matrices that could be defined, each of which would cause a neuron to activate in response to a different visual pattern in the neuron’s local receptive field.",
            "zh": "当然，可以定义许多不同的权重矩阵，每个矩阵都会导致神经元激活，以响应神经元局部感受野中的不同视觉模式。"
        }
    },
    {
        "translation": {
            "en": "Although this algorithm works quite well as presented, it assumes categorical features and clean data.",
            "zh": "尽管此算法如所介绍的那样工作得很好，但它假定了分类特征和干净的数据。"
        }
    },
    {
        "translation": {
            "en": "Before the scout attempts a step, the blindfold is made transparent for 0.5 seconds to give the scout a quick view of their environment so that they make a decision about which direction they will step in and how far.",
            "zh": "在侦察兵尝试踏步之前，眼罩会透明 0.5 秒，以便侦察兵快速查看他们的环境，以便他们决定将踏入哪个方向和多远。"
        }
    },
    {
        "translation": {
            "en": "Simply through eyeballing the data, Jocelyn uncovered the fact that, in almost all cases, when one suspect − 9,999 value was present in a row in the dataset, that row contained a number of suspect − 9,999 values (this was the case for 2% of the rows in the dataset).",
            "zh": "仅仅通过观察数据，Jocelyn 就发现了这样一个事实，即在几乎所有情况下，当数据集中的一行中存在一个可疑值 - 9,999 值时，该行包含许多可疑值 - 9,999 值（数据集中 2% 的行就是这种情况）。"
        }
    },
    {
        "translation": {
            "en": "2. This data has been artificially generated for this example.",
            "zh": "2. 此数据是针对此示例人工生成的。"
        }
    },
    {
        "translation": {
            "en": "They retain some instances from the dataset—potentially all of them, although in practice, relatively few—as part of the domain representation.",
            "zh": "它们保留了数据集中的一些实例（可能是所有实例，但实际上相对较少）作为域表示的一部分。"
        }
    },
    {
        "translation": {
            "en": "Or two payments in a five-month period?",
            "zh": "还是在五个月内支付两笔款项？"
        }
    },
    {
        "translation": {
            "en": "1,750,000",
            "zh": "1,750,000"
        }
    },
    {
        "translation": {
            "en": "This network is changing frequently during the training process, which can cause the training to oscillate wildly.",
            "zh": "此网络在训练过程中频繁变化，这可能导致训练剧烈振荡。"
        }
    },
    {
        "translation": {
            "en": "This approach, however, has not proved particularly successful, and churn has been steadily increasing over the last five years.",
            "zh": "然而，这种方法并没有被证明是特别成功，而且在过去五年中，客户流失率一直在稳步上升。"
        }
    },
    {
        "translation": {
            "en": "Ross then developed a full data quality report for the ABT including a range of data visualizations.",
            "zh": "然后，Ross 为 ABT 开发了一份完整的数据质量报告，包括一系列数据可视化。"
        }
    },
    {
        "translation": {
            "en": "(a) A range normalization that generates data in the range (0,1)",
            "zh": "（a） 生成范围 （0,1） 中数据的范围归一化"
        }
    },
    {
        "translation": {
            "en": "11.3.1   A Worked Example",
            "zh": "11.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "11.3 Standard Approach: Q-Learning, Off-Policy Temporal-Difference Learning",
            "zh": "11.3 标准方法：Q-学习、非政策时间差异学习"
        }
    },
    {
        "translation": {
            "en": "causal graphs, 293",
            "zh": "因果图，293"
        }
    },
    {
        "translation": {
            "en": "CLMNTS.",
            "zh": "CLMNTS的。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.22",
            "zh": "图 7.22"
        }
    },
    {
        "translation": {
            "en": "It is worth noting that this ability is diminished if pre-pruning is employed, as pre-pruning may stop subtrees that capture descriptive feature interactions from forming.",
            "zh": "值得注意的是，如果采用预修剪，这种能力会减弱，因为预修剪可能会阻止捕获描述性特征交互的子树形成。"
        }
    },
    {
        "translation": {
            "en": "relative rarity, 720",
            "zh": "相对稀有度，720"
        }
    },
    {
        "translation": {
            "en": "(b) At the first iteration of the AHC algorithm the first pair of instances is combined into a cluster, 10.",
            "zh": "（b） 在AHC算法的第一次迭代中，第一对实例被组合成一个集群，10。"
        }
    },
    {
        "translation": {
            "en": "To add a new instance to the tree, we start at the root node and descend to a leaf node, taking the left or right branch of each node depending on whether the value of the instance’s feature is less than or greater than the splitting value used at the node.",
            "zh": "为了将新实例添加到树中，我们从根节点开始，下降到叶节点，根据实例的特征值是小于还是大于节点上使用的拆分值，取每个节点的左分支或右分支。"
        }
    },
    {
        "translation": {
            "en": "One day, after an expedition up the river has returned to the ship, one of the men from the expedition tells you that he saw a strange animal near the river.",
            "zh": "有一天，在沿河而上的探险队返回船上后，探险队的一名男子告诉你，他在河边看到了一只奇怪的动物。"
        }
    },
    {
        "translation": {
            "en": "In Table 5.6[206], if we compare the rankings based on SALARY and AGE with the rankings based solely on SALARY, we see that the values in these two columns are identical.",
            "zh": "在表5.6[206]中，如果我们将基于SALA和AGE的排名与仅基于SALARY的排名进行比较，我们会看到这两列中的值是相同的。"
        }
    },
    {
        "translation": {
            "en": "In this instance, to find out which model is best, we would really need to put the bottle of whiskey up for auction and see which model predicted the closest price.",
            "zh": "在这种情况下，要找出哪种型号最好，我们真的需要将一瓶威士忌拍卖，看看哪个型号预测的价格最接近。"
        }
    },
    {
        "translation": {
            "en": "policy gradient, 641",
            "zh": "策略梯度，641"
        }
    },
    {
        "translation": {
            "en": "However, the same process is used to calculate the term ∂ak/∂zk in the product irrespective of whether the neuron is an output neuron or a hidden neuron.",
            "zh": "但是，无论神经元是输出神经元还是隐藏神经元，都使用相同的过程来计算乘积中的术语 ∂ak/∂zk。"
        }
    },
    {
        "translation": {
            "en": "The larger the size of the hidden state, the larger the representational capacity of the LSTM.",
            "zh": "隐藏状态的大小越大，LSTM 的表示能力就越大。"
        }
    },
    {
        "translation": {
            "en": "6.4   The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for a query with CH = paid, GC = none, and ACC = rent, and the calculation of the scores for each target level.",
            "zh": "6.4 朴素贝叶斯预测模型对 CH = paid、GC = none 和 ACC = rent 的查询进行预测所需的相关概率，以及每个目标水平的分数计算。"
        }
    },
    {
        "translation": {
            "en": "We can think about all these error values joined to make a surface defined by the weight combinations, as shown in Figure 7.3(a)[318].",
            "zh": "我们可以考虑将所有这些误差值连接起来，形成一个由权重组合定义的曲面，如图7.3（a）[318]所示。"
        }
    },
    {
        "translation": {
            "en": "9.4.3   Performance Measures: Prediction Scores",
            "zh": "9.4.3 绩效指标：预测分数"
        }
    },
    {
        "translation": {
            "en": "When we view a Bayesian network as a Markov chain, a state is a complete assignment of values to all the nodes in the network (for example, GINI COEF = high, SCHOOL YEARS = low, LIFE EXP = high, CPI = high would be a state in the Markov chain defined by the network in Figure 6.13[296]), and the CPTs of the network provide a distributed representation of the transition probabilities of the Markov chain.",
            "zh": "当我们将贝叶斯网络视为马尔可夫链时，状态是将值完全分配给网络中的所有节点（例如，GINI COEF = 高，SCHOOL YEARS = 低，LIFE EXP = 高，CPI = 高将是图 6.13[296] 中网络定义的马尔可夫链中的状态），网络的 CPT 提供了马尔可夫链转移概率的分布式表示。"
        }
    },
    {
        "translation": {
            "en": "The discussion in this section, and in the rest of this chapter, assumes that you have a basic understanding of differentiation, in particular, what a derivative is, how to calculate a derivative for a continuous function, the chain rule for differentiation, and what a partial derivative is.",
            "zh": "本节以及本章其余部分的讨论假定您对微分有基本的了解，特别是什么是导数、如何计算连续函数的导数、微分的链式法则以及什么是偏导数。"
        }
    },
    {
        "translation": {
            "en": "25. This question is inspired by Tsanas and Xifara (2012), and although the data used is artificially generated, it is based on the Energy Efficiency Dataset available from the UCI Machine Learning Repository (Bache and Lichman, 2013) at archive.ics.uci.edu/ml/datasets/Energy+efficiency/.",
            "zh": "25. 这个问题的灵感来自 Tsanas 和 Xifara （2012），虽然使用的数据是人工生成的，但它是基于 UCI 机器学习存储库（Bache 和 Lichman，2013 年）提供的能源效率数据集，archive.ics.uci.edu/ml/datasets/Energy+efficiency/。"
        }
    },
    {
        "translation": {
            "en": "For example, if we had 10,000 instances in our dataset and we wish to have 10 bins, then bin 1 would contain the 1,000 instances with the lowest values for the feature, and so on, up to bin 10, which would contain the 1,000 instances with the highest feature values.",
            "zh": "例如，如果我们的数据集中有 10,000 个实例，并且我们希望有 10 个 bin，则 bin 1 将包含具有最低特征值的 1,000 个实例，依此类推，最多包含 bin 10，它将包含具有最高特征值的 1,000 个实例。"
        }
    },
    {
        "translation": {
            "en": "The SSDS imaging camera captures images in five distinct photometric bands:7 ultra-violet (u), green (g), red (r), far-red (i), and near infrared (z).",
            "zh": "SSDS 成像相机以五个不同的光度波段捕获图像：7 紫外 （u）、绿色 （g）、红色 （r）、远红外 （i） 和近红外 （z）。"
        }
    },
    {
        "translation": {
            "en": "14   The Art of Machine Learning for Predictive Data Analytics",
            "zh": "14 预测数据分析的机器学习艺术"
        }
    },
    {
        "translation": {
            "en": "0.80",
            "zh": "0.80"
        }
    },
    {
        "translation": {
            "en": "After deployment, the analytics team at the supermarket chain uses the stability index to monitor the performance of this model.",
            "zh": "部署后，连锁超市的分析团队使用稳定性指数来监控此模型的性能。"
        }
    },
    {
        "translation": {
            "en": "relative frequency, 245, 757, 759",
            "zh": "相对频率，245、757、759"
        }
    },
    {
        "translation": {
            "en": "The best-performing model was the 3-level logistic regression model after feature selection (the performance of this model is shown in Table 13.7(b)[723]).",
            "zh": "表现最好的模型是特征选择后的3级逻辑回归模型（该模型的性能如表13.7（b）[723]所示）。"
        }
    },
    {
        "translation": {
            "en": "The scientists at SDSS wanted Jocelyn to build a machine learning model that could examine sky objects that their current rule-based system had flagged as being galaxies and categorize them as belonging to the appropriate morphological group.",
            "zh": "SDSS的科学家们希望Jocelyn建立一个机器学习模型，该模型可以检查他们当前基于规则的系统标记为星系的天空物体，并将它们归类为属于适当的形态组。"
        }
    },
    {
        "translation": {
            "en": "These figures show that, on average, fewer customers churn when the churn prediction model is used to select which customers to call.",
            "zh": "这些数字表明，平均而言，当使用客户流失预测模型来选择要呼叫的客户时，客户流失的次数会减少。"
        }
    },
    {
        "translation": {
            "en": "A linear regression model, for example, assumes that the relationship between the descriptive features and the target is linear (this is a strong assumption about the distribution in the domain).",
            "zh": "例如，线性回归模型假设描述性特征与目标之间的关系是线性的（这是关于域中分布的强假设）。"
        }
    },
    {
        "translation": {
            "en": "The top segment of Table 8.15[471] lists the logit values for Neurons 8, 9, and 10 for each of the examples in the mini-batch (these logits are taken directly from Figure 8.28[470]).",
            "zh": "表 8.15[471] 的顶部部分列出了小批量中每个示例的神经元 8、9 和 10 的 logit 值（这些 logit 直接取自图 8.28[470]）。"
        }
    },
    {
        "translation": {
            "en": "We explain covariance matrices in Section 3.5.2[81].",
            "zh": "我们在第3.5.2节[81]中解释了协方差矩阵。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.104)[501] defines how the activations for the hidden layer for input t are generated.",
            "zh": "等式（8.104）[501]定义了如何生成输入t的隐藏层的激活。"
        }
    },
    {
        "translation": {
            "en": "Although there is some blurring around the edges, these look remarkably similar to the original images.",
            "zh": "虽然边缘有些模糊，但这些看起来与原始图像非常相似。"
        }
    },
    {
        "translation": {
            "en": "spectral clustering, 629",
            "zh": "光谱聚类，629"
        }
    },
    {
        "translation": {
            "en": "In the email classification example we have been following, the misclassification rate would be",
            "zh": "在我们一直关注的电子邮件分类示例中，错误分类率为"
        }
    },
    {
        "translation": {
            "en": "Examples of typical data quality issues include an instance that is missing values for one or more descriptive features, an instance that has an extremely high value for a feature, or an instance that has an inappropriate level for a feature.",
            "zh": "典型数据质量问题的示例包括缺少一个或多个描述性特征值的实例、具有极高特征值的实例或具有不适当特征级别的实例。"
        }
    },
    {
        "translation": {
            "en": "For an auto-encoder network to be able to reproduce the feature values for a query instance that are presented at its input layer at its output layer, the low-dimensional representation at the middle bottleneck layer needs to capture almost all the useful information contained in the original input features.",
            "zh": "为了使自动编码器网络能够重现查询实例的特征值，这些特征值在其输入层的输出层呈现，中间瓶颈层的低维表示需要捕获原始输入特征中包含的几乎所有有用信息。"
        }
    },
    {
        "translation": {
            "en": "CUSTOMERCARECALLS",
            "zh": "客户服务电话"
        }
    },
    {
        "translation": {
            "en": "Some episodes of games played by the TwentyTwos agent showing the cards dealt, as well as the states, actions, and rewards. Note that rewards are shown on the row indicating the action that led to them, not the state that followed that action.",
            "zh": "TwentyTwos特工玩的一些游戏情节显示了发牌，以及状态，行动和奖励。请注意，奖励显示在指示导致奖励的操作的行上，而不是该操作之后的状态。"
        }
    },
    {
        "translation": {
            "en": "Table 10.4[616] shows that membership of clusters 1 and 2 is most associated with DATA USAGE, whereas membership of 3 is most associated with CALL VOLUME.",
            "zh": "表 10.4[616] 显示，集群 1 和 2 的成员资格与 DATA USAGE 最相关，而 3 的成员资格与 CALL VOLUME 关联最多。"
        }
    },
    {
        "translation": {
            "en": "The first tree constructed achieved an average class accuracy7 of 74.873% on the hold-out test set, which was reasonably encouraging.",
            "zh": "构建的第一棵树在保持测试集上达到了 74.873% 的平均类准确率7，这是相当令人鼓舞的。"
        }
    },
    {
        "translation": {
            "en": "9.4.1.4 Bootstrapping The next sampling method we will look at is bootstrapping, and in particular the ε0 bootstrap.",
            "zh": "9.4.1.4 自举 我们将研究的下一个采样方法是自举，特别是 ε0 自举。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the forward propagation of d2 through the network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "d2 在网络中前向传播的图示显示了每个连接上的权重，以及网络中每个神经元的加权和 z 和激活值。"
        }
    },
    {
        "translation": {
            "en": "Consider, for example, the probability of an agent in the PM-DH state remaining in that state after choosing the Twist action: .",
            "zh": "例如，考虑在选择 Twist 操作后处于 PM-DH 状态的代理保持该状态的概率：。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.1",
            "zh": "图 13.1"
        }
    },
    {
        "translation": {
            "en": "0.55",
            "zh": "0.55"
        }
    },
    {
        "translation": {
            "en": "The subset selection component in forward sequential selection can use any of the approaches described above and moves the search process to a new feature subset.",
            "zh": "前向顺序选择中的子集选择组件可以使用上述任何方法，并将搜索过程移动到新的特征子集。"
        }
    },
    {
        "translation": {
            "en": "We would like to thank our colleagues and students for the help and patience they extended to us over the last few years.",
            "zh": "我们要感谢我们的同事和学生在过去几年中给予我们的帮助和耐心。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.9[615] shows the distributions of each feature for the full population and for each cluster so that the differences can be compared.",
            "zh": "图10.9[615]显示了每个特征在全种群和每个聚类中的分布，以便比较差异。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.15(b)[626] shows examples of the reconstructions generated by the auto-encoder network before it has been trained for the digits shown in Figure 10.15(a)[626].",
            "zh": "图10.15（b）[626]显示了自动编码器网络在针对图10.15（a）[626]所示的数字进行训练之前生成的重建示例。"
        }
    },
    {
        "translation": {
            "en": "Before performing this operation, however, Jocelyn first checked that the percentage of missing values was approximately 2% in each of the 3 levels (and in each of the levels in the 5-level model) to ensure that there was no relationship between missing values and galaxy type.",
            "zh": "然而，在执行此操作之前，Jocelyn 首先检查了 3 个级别中每个级别（以及 5 级别模型中的每个级别）缺失值的百分比约为 2%，以确保缺失值与星系类型之间没有关系。"
        }
    },
    {
        "translation": {
            "en": "Quinlan (1986) originally described the ID3 algorithm, and Quinlan (1993) and Breiman (1993) are two of the best-known books on decision trees. Loh (2011) provides a good overview of more recent developments in tree induction algorithms.",
            "zh": "Quinlan （1986） 最初描述了 ID3 算法，Quinlan （1993） 和 Breiman （1993） 是关于决策树的两本最著名的书籍。Loh（2011）很好地概述了树诱导算法的最新发展。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.7(a)[329] shows the impact of a very small learning rate.",
            "zh": "图7.7（a）[329]显示了非常小的学习率的影响。"
        }
    },
    {
        "translation": {
            "en": "28. In the following calculations we have abbreviated feature names as follows: GC = GINI COEF, LE = LIFE EXP, and SY = SCHOOL YEARS.",
            "zh": "28. 在以下计算中，我们对特征名称进行了如下缩写：GC = GINI COEF，LE = LIFE EXP，SY = 学年。"
        }
    },
    {
        "translation": {
            "en": "The most common approach to error-based machine learning for predictive analytics is to use multivariable linear regression with gradient descent to train a best-fit model for a given training dataset. This section explains how this works. First, we describe how we extend the simple linear regression model described in the previous section to handle multiple descriptive features, and then we describe the gradient descent algorithm.",
            "zh": "用于预测分析的基于错误的机器学习的最常见方法是使用具有梯度下降的多变量线性回归来为给定的训练数据集训练最佳拟合模型。本节将介绍其工作原理。首先，我们描述了如何扩展上一节中描述的简单线性回归模型以处理多个描述性特征，然后我们描述了梯度下降算法。"
        }
    },
    {
        "translation": {
            "en": "However, the calculation of these error gradients involves the δ terms.",
            "zh": "但是，这些误差梯度的计算涉及δ项。"
        }
    },
    {
        "translation": {
            "en": "This could be problematic: a model trained on this data might ignore seasonal effects such as Christmas.",
            "zh": "这可能是有问题的：根据这些数据训练的模型可能会忽略季节性影响，例如圣诞节。"
        }
    },
    {
        "translation": {
            "en": "3.5.2 Measuring Covariance and Correlation",
            "zh": "3.5.2 测量协方差和相关性"
        }
    },
    {
        "translation": {
            "en": "We use a lowercase w to indicate a single weight on a connection between two neurons. We use a double subscript to indicate the neurons that are connected, with the convention that the first subscript is the neuron the connection goes to, and the second subscript is the neuron the connection is from. For example, wi,k is the weight on the connection from neuron k to neuron i.",
            "zh": "我们使用小写的 w 来表示两个神经元之间连接上的单个权重。我们使用双下标来表示连接的神经元，约定第一个下标是连接所要去的神经元，第二个下标是连接所来自的神经元。例如，wi，k 是从神经元 k 到神经元 i 的连接权重。"
        }
    },
    {
        "translation": {
            "en": "For probabilities near 0, the negative log returns a large number, and for probabilities near 1 the negative log returns a value near 0.",
            "zh": "对于接近 0 的概率，负对数返回一个大数，对于接近 1 的概率，负对数返回接近 0 的值。"
        }
    },
    {
        "translation": {
            "en": "This is reflected in a further decrease in the sampling density.",
            "zh": "这反映在采样密度的进一步降低上。"
        }
    },
    {
        "translation": {
            "en": "A real advantage of the decision tree approach is that it has the ability to model the interactions between descriptive features.",
            "zh": "决策树方法的真正优势在于它能够对描述性特征之间的交互进行建模。"
        }
    },
    {
        "translation": {
            "en": "Ted organized a full download of the SDSS photo imaging data repository for all the objects for which Galaxy Zoo labels existed.",
            "zh": "Ted组织了SDSS照片成像数据存储库的完整下载，其中包含Galaxy Zoo标签的所有对象。"
        }
    },
    {
        "translation": {
            "en": "inductive learning, 11, 729",
            "zh": "归纳学习，11,729"
        }
    },
    {
        "translation": {
            "en": "The length of DropMask should be equal to the number of neurons in the layer (see Line 7[476]).",
            "zh": "DropMask 的长度应等于层中的神经元数量（参见第 7 行[476]）。"
        }
    },
    {
        "translation": {
            "en": "The process of model induction with feature selection.",
            "zh": "具有特征选择的模型归纳过程。"
        }
    },
    {
        "translation": {
            "en": "Using a programming language for advanced analytics has a significantly steeper learning curve than using an application-based solution.",
            "zh": "使用编程语言进行高级分析的学习曲线比使用基于应用程序的解决方案要陡峭得多。"
        }
    },
    {
        "translation": {
            "en": "In Line 1[420] the data is split into mini-batches where X(i) is a matrix that contains the descriptive features for each of the examples in mini-batch i, with one column per example, and Y(i) is a matrix (or vector) containing the corresponding labels for the examples in mini-batch i.",
            "zh": "在第 1 行[420]中，数据被拆分为小批量，其中 X（i） 是一个矩阵，其中包含小批量 i 中每个示例的描述性特征，每个示例一列，Y（i） 是一个矩阵（或向量），其中包含小批量 i 中示例的相应标签。"
        }
    },
    {
        "translation": {
            "en": "and second, experimentation is always required to determine which measure of similarity will be most effective for a specific prediction model.",
            "zh": "其次，始终需要进行实验来确定哪种相似性度量对特定预测模型最有效。"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes (MDPs) are an extremely useful mathematical tool for framing reinforcement learning problems; these are covered next.",
            "zh": "马尔可夫决策过程 （MDP） 是构建强化学习问题的非常有用的数学工具;下面将介绍这些内容。"
        }
    },
    {
        "translation": {
            "en": "[Claim prediction] Data Requirements: This solution would require that a large collection of historical claims marked as fraudulent and non-fraudulent exist.",
            "zh": "[索赔预测]数据要求：此解决方案要求存在大量标记为欺诈性和非欺诈性的历史声明。"
        }
    },
    {
        "translation": {
            "en": "HEART RATE: The patient’s heart rate",
            "zh": "心率：患者的心率"
        }
    },
    {
        "translation": {
            "en": "A prediction model could be trained to identify the customers from the AT customer base who were most likely to churn in the near future.",
            "zh": "可以训练一个预测模型，以识别AT客户群中最有可能在不久的将来流失的客户。"
        }
    },
    {
        "translation": {
            "en": "At the conclusion of the leave-one-out cross validation process, a performance measure will have been calculated for every instance in the dataset. In the same way as we saw in Table 9.4[544] for k-fold cross validation, these performance measures are aggregated across all the folds to arrive at an overall measure of model performance.",
            "zh": "在“留一”交叉验证过程结束时，将为数据集中的每个实例计算性能度量。与我们在表 9.4[544] 中看到的 k 倍交叉验证相同，这些性能测量被汇总到所有折叠中，以得出模型性能的整体度量。"
        }
    },
    {
        "translation": {
            "en": "For example, consider the symptoms of meningitis.",
            "zh": "例如，考虑脑膜炎的症状。"
        }
    },
    {
        "translation": {
            "en": "model-based clustering, 629",
            "zh": "基于模型的聚类，629"
        }
    },
    {
        "translation": {
            "en": "The fundamental element in the design of these networks was to remove the repeated multiplication of error gradients by weight matrices during backpropagation through time.",
            "zh": "这些网络设计的基本要素是在时间反向传播过程中消除误差梯度乘以权重矩阵的重复乘法。"
        }
    },
    {
        "translation": {
            "en": "multivariable linear regression with gradient descent, 11, 311, 731",
            "zh": "梯度下降的多变量线性回归， 11， 311， 731"
        }
    },
    {
        "translation": {
            "en": "The first is the distance measure, Dist, to be used to compare instances and clusters.",
            "zh": "第一个是距离度量 Dist，用于比较实例和集群。"
        }
    },
    {
        "translation": {
            "en": "raw features, 34, 41, 45",
            "zh": "原始特征， 34， 41， 45"
        }
    },
    {
        "translation": {
            "en": "(a) A complete ROC curve for the email classification example; and (b) a selection of ROC curves for different models trained on the same prediction task.",
            "zh": "（a） 电子邮件分类示例的完整 ROC 曲线;（b）为在同一预测任务上训练的不同模型选择ROC曲线。"
        }
    },
    {
        "translation": {
            "en": "Based on the time available to the project, Jocelyn did not pursue this avenue and, in consultation with Edwin, decided to continue with just the 3-level model.",
            "zh": "根据该项目的可用时间，Jocelyn 没有采用这条途径，在与 Edwin 协商后，决定继续使用 3 级模型。"
        }
    },
    {
        "translation": {
            "en": "0.18",
            "zh": "0.18"
        }
    },
    {
        "translation": {
            "en": "0.30",
            "zh": "0.30"
        }
    },
    {
        "translation": {
            "en": "In Chapter 1 we introduce machine learning and explain its role within a standard data analytics project lifecycle.",
            "zh": "在第 1 章中，我们介绍了机器学习，并解释了它在标准数据分析项目生命周期中的作用。"
        }
    },
    {
        "translation": {
            "en": "For example, we can stop creating subtrees when the number of instances in a partition falls below a threshold, when the information gain (or whatever other feature selection metric is being used) measured at a node is not deemed to be sufficient to make partitioning the data worthwhile,20 or when the depth of the tree goes beyond a predefined limit.",
            "zh": "例如，当分区中的实例数低于阈值时，当在节点上测量的信息增益（或正在使用的任何其他特征选择指标）被认为不足以使数据分区值得时，20 或者当树的深度超过预定义的限制时，我们可以停止创建子树。"
        }
    },
    {
        "translation": {
            "en": "There are many different approaches to binning.",
            "zh": "有许多不同的分箱方法。"
        }
    },
    {
        "translation": {
            "en": "The hierarchical relationship between an analytics solution, domain concepts, and descriptive features.",
            "zh": "分析解决方案、领域概念和描述性功能之间的层次结构关系。"
        }
    },
    {
        "translation": {
            "en": "The average number of out-of-bundle minutes used by the customer each month",
            "zh": "客户每月使用的平均捆绑外分钟数"
        }
    },
    {
        "translation": {
            "en": "TN, 537",
            "zh": "田纳西州，537"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset 𝒟7 in Figure 4.8[138].",
            "zh": "图4.8[138]中数据集D7的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "The second error gradient is the rate of change of the network error with respect to changes in the weights of the network.",
            "zh": "第二个误差梯度是网络误差相对于网络权重变化的变化率。"
        }
    },
    {
        "translation": {
            "en": "The second things to check for in the cardinality column are categorical features incorrectly labeled as continuous.",
            "zh": "在基数列中要检查的第二件事是错误地标记为连续的分类要素。"
        }
    },
    {
        "translation": {
            "en": "Models trained by reducing the sum of squared errors, for example, linear regression, are the most natural fit for making predictions for continuous target features.",
            "zh": "通过减少平方误差之和（例如线性回归）来训练的模型是预测连续目标特征的最自然的模型。"
        }
    },
    {
        "translation": {
            "en": "These δs are the rate of change of the network error with respect to the weighted sum of a neuron.",
            "zh": "这些 δ 是网络误差相对于神经元加权和的变化率。"
        }
    },
    {
        "translation": {
            "en": "Although learning rate decay almost always leads to better performance than a fixed learning rate, it still does require that problem-dependent values are chosen for α0 and c.",
            "zh": "尽管学习率衰减几乎总是比固定学习率带来更好的性能，但它仍然需要为 α0 和 c 选择与问题相关的值。"
        }
    },
    {
        "translation": {
            "en": "5.17   The effect of using a Mahalanobis versus Euclidean distance. A marks the central tendency of the dataset in Figure 5.15(c)[219]. The ellipses plot the Mahalanobis distance contours from A that B and C lie on. In Euclidean terms, B and C are equidistant from A; however, using the Mahalanobis distance, C is much closer to A than B.",
            "zh": "5.17 使用马氏距离与欧几里得距离的影响。A在图5.15（c）中标记了数据集的中心趋势[219]。椭圆绘制了 B 和 C 所在的 A 的马氏距离等值线。在欧几里得术语中，B 和 C 与 A 等距;然而，使用马氏距离，C 比 B 更接近 A。"
        }
    },
    {
        "translation": {
            "en": "The danger of this is that any analysis or modeling we perform on this sample will not be relevant to the overall dataset.",
            "zh": "这样做的危险在于，我们对这个样本执行的任何分析或建模都与整个数据集无关。"
        }
    },
    {
        "translation": {
            "en": "The location of the peak value is defined by the parameter μ (pronounced mu), which denotes the population mean (in other words, the mean value of the feature if we had access to every value that could possibly occur).",
            "zh": "峰值的位置由参数 μ（发音为 mu）定义，该参数表示总体均值（换句话说，如果我们可以访问可能出现的每个值，则表示特征的平均值）。"
        }
    },
    {
        "translation": {
            "en": "The result is that instance C is much closer to A than B and so should be considered a member of the same population as this dataset.",
            "zh": "结果是实例 C 比 B 更接近 A，因此应被视为与该数据集相同的总体成员。"
        }
    },
    {
        "translation": {
            "en": "random sampling, 92",
            "zh": "随机抽样，92"
        }
    },
    {
        "translation": {
            "en": "8.24   The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using a normal distribution with μ = 0.0 and σ = 0.2.",
            "zh": "8.24 图8.22[450]中网络的内部动力学，在第一次训练迭代期间，当权重使用μ = 0.0和σ = 0.2的正态分布进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "1.2 What Is Machine Learning?",
            "zh": "1.2 什么是机器学习？"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the ReLU network changed during training when α = 0.1.",
            "zh": "该图显示了当 α = 0.1 时，ReLU 网络的平方误差总和在训练期间如何变化。"
        }
    },
    {
        "translation": {
            "en": "5. The following table40 lists a dataset containing the details of five participants in a heart disease study, and a target feature RISK, which describes their risk of heart disease. Each patient is described in terms of four binary descriptive features",
            "zh": "5. 下表40列出了一个数据集，其中包含心脏病研究中五名参与者的详细信息，以及描述他们患心脏病风险的目标特征RISK。每个患者都用四个二元描述性特征来描述"
        }
    },
    {
        "translation": {
            "en": "(b) The image below shows a scatter plot matrix of the continuous features from this dataset (the correlation between LIFEEXPECTANCY and INFANTMORTALITY has been omitted). Discuss the relationships between the features in the dataset that this scatter plot highlights.",
            "zh": "（b） 下图显示了该数据集中连续特征的散点图矩阵（省略了预期寿命和婴儿死亡率之间的相关性）。讨论此散点图突出显示的数据集中要素之间的关系。"
        }
    },
    {
        "translation": {
            "en": "Summary statistics for the three clusters found in the mobile phone customer dataset in Table 10.1[604] using k-means clustering (k = 3). Note, that the % missing and cardinality columns usually used are omitted here for legibility as these data quality issues will not arise in this simple example. They could be included when this approach is used on real datasets.",
            "zh": "使用k-means聚类（k = 3）在表10.1[604]的移动电话客户数据集中找到的三个聚类的汇总统计。请注意，为了便于阅读，此处省略了通常使用的缺失百分比和基数列，因为在这个简单示例中不会出现这些数据质量问题。当这种方法用于实际数据集时，可以包括它们。"
        }
    },
    {
        "translation": {
            "en": "One of these properties is that a model learned by induction is not guaranteed to be correct.",
            "zh": "其中一个特性是，通过归纳学习的模型不能保证是正确的。"
        }
    },
    {
        "translation": {
            "en": "This uses the entropy measure that is discussed in Section 4.2[120] as it does a good job of capturing in a single number the variety in a set of objects.",
            "zh": "这使用了第4.2节[120]中讨论的熵度量，因为它可以很好地在单个数字中捕获一组对象的多样性。"
        }
    },
    {
        "translation": {
            "en": "7.3.1 Multivariable Linear Regression",
            "zh": "7.3.1 多变量线性回归"
        }
    },
    {
        "translation": {
            "en": "Card suits have no impact on the game (for example, 10 is equivalent to 10 ) and because there is an infinite deck, tracking the actual cards that have been dealt gives no advantage to the player.",
            "zh": "花色对游戏没有影响（例如，10 相当于 10），并且因为有一副无限的牌组，跟踪实际发的牌对玩家没有任何好处。"
        }
    },
    {
        "translation": {
            "en": "However, most deep networks have many more than two hidden layers.",
            "zh": "然而，大多数深度网络都有两个以上的隐藏层。"
        }
    },
    {
        "translation": {
            "en": "For example, P(DICE1 = ) will return the likelihood of the event DICE1 = , and P(DICE1 = , DICE2 = ) will return the likelihood of the event where DICE1 = and DICE2 = .",
            "zh": "例如，P（DICE1 = ） 将返回事件 DICE1 = 的似然，P（DICE1 = ， DICE2 = ） 将返回 DICE1 = 和 DICE2 = 的事件的似然。"
        }
    },
    {
        "translation": {
            "en": "8.12   The backpropagation of the δ values during the backward pass of the backpropagation algorithm.",
            "zh": "8.12 反向传播算法向后传递过程中δ值的反向传播。"
        }
    },
    {
        "translation": {
            "en": "To ensure that we arrive at the optimal set of weights at the end of this journey across the error surface, we need to ensure that each step we take moves downward on the error surface. We do this by directing our steps according to the gradient of the error surface at each step. This is the gradient descent algorithm, which is one of the most important algorithms in all of computer science, let alone machine learning.",
            "zh": "为了确保我们在穿越误差表面的旅程结束时达到最佳权重集，我们需要确保我们采取的每一步都在误差表面上向下移动。为此，我们根据每个步骤的误差表面梯度来指导我们的步骤。这就是梯度下降算法，它是所有计算机科学中最重要的算法之一，更不用说机器学习了。"
        }
    },
    {
        "translation": {
            "en": "The agent always starts in the start cell marked with an S. To demonstrate the workings of the Q-learning algorithm, we examine the process of using it to train an agent to navigate this environment.",
            "zh": "代理始终在标有 S 的起始单元格中启动。为了演示 Q 学习算法的工作原理，我们研究了使用它来训练智能体来导航此环境的过程。"
        }
    },
    {
        "translation": {
            "en": "For large problems like this, instead of implementing the action-value function,Qπ(st,at), as a table storing the value of every action in every state, it would be better to learn a generalized version of the action-value function from observation of a small number of state and action pairs.",
            "zh": "对于这样的大问题，与其将动作值函数 Qπ（st，at） 实现为存储每个状态下每个动作值的表，不如通过观察少量状态和动作对来学习动作值函数的广义版本。"
        }
    },
    {
        "translation": {
            "en": "Although there are different approaches in the literature, a good approach is to use the following decay schedule:",
            "zh": "尽管文献中有不同的方法，但一个好的方法是使用以下衰减时间表："
        }
    },
    {
        "translation": {
            "en": "In fact, the final part of Equation (11.18)[652] is almost identical to Equation (11.16)[651] except for the explicit reference to an action in the latter.",
            "zh": "事实上，等式（11.18）[652]的最后一部分与等式（11.16）[651]几乎相同，只是在后者中明确引用了一个动作。"
        }
    },
    {
        "translation": {
            "en": "The process of using a decision tree to make a prediction for a query instance starts with testing the value of the descriptive feature at the root node of the tree. The result of this test determines which of the root node’s children the process should then descend to. These two steps of testing the value of a descriptive feature and descending a level in the tree are then repeated until the process comes to a leaf node at which a prediction can be made.",
            "zh": "使用决策树对查询实例进行预测的过程首先要测试树根节点上的描述性特征的值。此测试的结果决定了进程随后应下降到根节点的哪个子节点。然后重复这两个步骤，即测试描述性特征的值和在树中下降一个级别，直到该过程到达可以进行预测的叶节点。"
        }
    },
    {
        "translation": {
            "en": "One slight complication of this approach is that during training, the error of a model can fluctuate even without the occurrence of overfitting, for example if the learning rate is too high; therefore, applying a strict rule of stopping training immediately after the first time the validation error increases can be too conservative a criterion for stopping.",
            "zh": "这种方法的一个轻微复杂性是，在训练过程中，即使没有发生过拟合，模型的误差也会波动，例如，如果学习率太高;因此，在验证误差首次增加后立即停止训练的严格规则可能过于保守。"
        }
    },
    {
        "translation": {
            "en": "This flexibility in the network design space can be exploited to tailor a network to process different types of data.",
            "zh": "可以利用网络设计空间的这种灵活性来定制网络以处理不同类型的数据。"
        }
    },
    {
        "translation": {
            "en": "In the example in Table 9.1[537], 20 predictions are made in total, and out of these, 5 are incorrect (instances d1, d2, d12, d17, and d20). Therefore, the misclassification rate is calculated as , which is usually expressed as a percentage: 25%. This tells us that the model is incorrect about a quarter of the time. Misclassification rate can assume values in the range [0,1], and lower values indicate better performance.",
            "zh": "在表 9.1[537] 的示例中，总共进行了 20 个预测，其中 5 个不正确（实例 d1、d2、d12、d17 和 d20）。因此，错误分类率计算为 ，通常表示为百分比：25%。这告诉我们，模型大约有四分之一的时间是不正确的。误分类率可以假设值在 [0,1] 范围内，值越低表示性能越好。"
        }
    },
    {
        "translation": {
            "en": "The leftmost element in each row (filled in black) is the bias term weight.",
            "zh": "每行中最左边的元素（以黑色填充）是偏置项权重。"
        }
    },
    {
        "translation": {
            "en": "model parameters, 314",
            "zh": "模型参数， 314"
        }
    },
    {
        "translation": {
            "en": "Calculating this measure for each neuron in a network is known as the blame assignment problem.",
            "zh": "计算网络中每个神经元的度量称为归咎分配问题。"
        }
    },
    {
        "translation": {
            "en": "The node returned by the recursive call to the algorithm may be the root of a subtree or a leaf node.",
            "zh": "对算法的递归调用返回的节点可以是子树的根，也可以是叶节点的根。"
        }
    },
    {
        "translation": {
            "en": "4. In an interesting example of the persistence of good solutions using older technology, the data captured by the telescopes at the SDSS site in New Mexico is recorded onto magnetic tapes that are then couriered to the Feynman Computing Center at Fermilab in Illinois, over 1,000 miles away. This is the most effective way to transport the massive volumes of data involved!",
            "zh": "4. 在一个有趣的例子中，使用旧技术坚持使用良好的解决方案，新墨西哥州 SDSS 站点的望远镜捕获的数据被记录在磁带上，然后快递到 1,000 多英里外的伊利诺伊州费米实验室的费曼计算中心。这是传输所涉及的大量数据的最有效方法！"
        }
    },
    {
        "translation": {
            "en": "learning rate decay, 334",
            "zh": "学习率衰减，334"
        }
    },
    {
        "translation": {
            "en": "Figure 10.2[599] illustrates this.",
            "zh": "图10.2[599]说明了这一点。"
        }
    },
    {
        "translation": {
            "en": "10.6   Further Reading",
            "zh": "10.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "The approach of avoiding overfitting by modifying the learning algorithm in order to generate models that are stable with respect to changes in the input is generally known as regularization.",
            "zh": "通过修改学习算法来避免过拟合，以生成相对于输入变化稳定的模型的方法通常称为正则化。"
        }
    },
    {
        "translation": {
            "en": "(c) Draw a domain concept diagram for the ABT.",
            "zh": "（c） 绘制ABT的领域概念图。"
        }
    },
    {
        "translation": {
            "en": "Mode is more frequently useful for categorical features than for continuous ones, but it can be useful for continuous features when the sample is large enough.",
            "zh": "模式通常用于分类特征而不是连续特征，但当样本足够大时，它对连续特征可能很有用。"
        }
    },
    {
        "translation": {
            "en": "The data quality report should also include a histogram for each continuous feature in an ABT. For continuous features with cardinality less than 10, we use bar plots instead of histograms as this usually produces more informative data visualization. For each categorical feature in an ABT, a bar plot should be included in the data quality report.",
            "zh": "数据质量报告还应包括 ABT 中每个连续特征的直方图。对于基数小于 10 的连续特征，我们使用条形图而不是直方图，因为这通常会产生信息量更大的数据可视化。对于 ABT 中的每个分类特征，数据质量报告中应包含条形图。"
        }
    },
    {
        "translation": {
            "en": "4.4 Extensions and Variations",
            "zh": "4.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "For example, we could represent state using a vector storing the position of the spaceship (in x and y coordinates), the velocity of the spaceship (again in x and y directions), the angular velocity of the spaceship, the spaceship’s altitude above the surface, and the slope of the line connecting the spaceship to the landing pad.",
            "zh": "例如，我们可以使用一个向量来表示状态，该向量存储了宇宙飞船的位置（在 x 和 y 坐标中）、宇宙飞船的速度（同样在 x 和 y 方向上）、宇宙飞船的角速度、宇宙飞船在表面上的高度以及连接宇宙飞船和着陆台的线的斜率。"
        }
    },
    {
        "translation": {
            "en": "1. The following image shows an artificial neuron that takes three inputs",
            "zh": "1. 下图显示了一个接受三个输入的人工神经元"
        }
    },
    {
        "translation": {
            "en": "The figure below illustrates a layer of a convolutional neural network that is processing a one-dimensional input.",
            "zh": "下图显示了处理一维输入的卷积神经网络层。"
        }
    },
    {
        "translation": {
            "en": "The next chapter will describe the data understanding and data preparation techniques mentioned briefly in this chapter in much more detail.",
            "zh": "下一章将更详细地介绍本章中简要提到的数据理解和数据准备技术。"
        }
    },
    {
        "translation": {
            "en": "In other words, the loss of the model reduces as the model’s predictions improve.",
            "zh": "换句话说，随着模型预测的改进，模型的损失会减少。"
        }
    },
    {
        "translation": {
            "en": "The entropy of different sets of playing cards measured in bits.",
            "zh": "以比特为单位测量的不同扑克牌组的熵。"
        }
    },
    {
        "translation": {
            "en": "Matching animals you remember to the features of the unknown animal described by the sailor.",
            "zh": "将您记忆中的动物与水手描述的未知动物的特征相匹配。"
        }
    },
    {
        "translation": {
            "en": "9.13   A sample test set with prediction scores and resulting predictions based on different threshold values.",
            "zh": "9.13 具有预测分数和基于不同阈值的预测结果的样本测试集。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning we often describe an agent at time t taking an action, at, to move from its current state, st, to the next state, st+1.",
            "zh": "在强化学习中，我们经常描述一个智能体在时间t采取一个动作，从其当前状态st移动到下一个状态st+1。"
        }
    },
    {
        "translation": {
            "en": "We compute the cosine similarity between two instances as the normalized dot product of the descriptive feature values of the instances. The dot product is normalized by the product of the lengths of the descriptive feature value vectors.19 The dot product of two instances, a and b, defined by m descriptive features is",
            "zh": "我们将两个实例之间的余弦相似度计算为实例描述性特征值的归一化点积。点积由描述性特征值向量的长度乘积归一化。19 由 m 个描述性特征定义的两个实例 a 和 b 的点积为"
        }
    },
    {
        "translation": {
            "en": "epoch, 416, 418",
            "zh": "纪元， 416， 418"
        }
    },
    {
        "translation": {
            "en": "J48 is an open-source implementation of the C4.5 algorithm that is used in many data analytics toolkits.",
            "zh": "J48 是 C4.5 算法的开源实现，用于许多数据分析工具包。"
        }
    },
    {
        "translation": {
            "en": "(b) For each analytics solution you have proposed for the hospital group, outline the type of data that would be required.",
            "zh": "（b） 对于您为医院集团提出的每个分析解决方案，概述所需的数据类型。"
        }
    },
    {
        "translation": {
            "en": "This is often very time consuming and expensive to generate.",
            "zh": "这通常非常耗时且生成成本高昂。"
        }
    },
    {
        "translation": {
            "en": "This occurs twice in an LSTM: (1) the cell state ct vector flows forward into the next time-step and is also passed through a tanh layer as part of the output layer; and (2) the vector of output activations ot flows forward to both the output layer and the next time-step (as the propagated hidden state ht).",
            "zh": "这在 LSTM 中发生两次：（1） 细胞状态 ct 向量向前流入下一个时间步长，并且作为输出层的一部分也通过 tanh 层;（2）输出激活的向量OT向前流向输出层和下一个时间步长（作为传播的隐藏状态HT）。"
        }
    },
    {
        "translation": {
            "en": "This led to a large positive reward of 50.",
            "zh": "这导致了 50 的大幅正奖励。"
        }
    },
    {
        "translation": {
            "en": "If all the inputs to the network have been standardized to have a mean value of 0 and a standard deviation of 1, and the initial weights for the network are sampled from a normal distribution with mean 0.0 and standard deviation of σ = 0.01, then:",
            "zh": "如果网络的所有输入都已标准化为均值为 0，标准差为 1，并且网络的初始权重是从均值为 0.0、标准差为 σ = 0.01 的正态分布中采样的，则："
        }
    },
    {
        "translation": {
            "en": "This could be used to identify customers who currently did not look valuable but that were likely to be valuable customers later in their customer lifecycles (college students often fall into this category).",
            "zh": "这可用于识别当前看起来不有价值的客户，但在其客户生命周期的后期可能成为有价值的客户（大学生通常属于这一类）。"
        }
    },
    {
        "translation": {
            "en": "3. Whh containing the weights for the connections between the memory buffer and the hidden layer. This matrix has the subscript hh because in actuality these weights are applied to recurrent connections from the hidden layer back to the hidden layer.",
            "zh": "3. 包含内存缓冲区和隐藏层之间连接的权重。该矩阵具有下标 hh，因为实际上这些权重应用于从隐藏层到隐藏层的循环连接。"
        }
    },
    {
        "translation": {
            "en": "1. the rate of change of the error of the network with respect to changes in the activation of the neuron: ∂ℰ/∂ak; and",
            "zh": "1.网络误差相对于神经元激活变化的变化率：∂E/∂ak;和"
        }
    },
    {
        "translation": {
            "en": "This is a mistake, however, when the descriptive features themselves have varying scales.",
            "zh": "然而，当描述性特征本身具有不同的尺度时，这是一个错误。"
        }
    },
    {
        "translation": {
            "en": "A consistent finding in both of these experiments, however, was the fact that for some domains, these more powerful models performed quite poorly, and other models, that in other domains were quite weak, achieved the best results.",
            "zh": "然而，在这两个实验中，一个一致的发现是，对于某些领域，这些更强大的模型表现得相当糟糕，而其他领域相当弱的模型则取得了最好的结果。"
        }
    },
    {
        "translation": {
            "en": "Two clustering techniques were presented in detail: k-means clustering and agglomerative hierarchical clustering (AHC).",
            "zh": "详细介绍了两种聚类技术：k-means聚类和聚集分层聚类（AHC）。"
        }
    },
    {
        "translation": {
            "en": "6.2.2   Bayesian Prediction",
            "zh": "6.2.2 贝叶斯预测"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for edge-on disk galaxy category",
            "zh": "边缘磁盘星系类别的得票分数"
        }
    },
    {
        "translation": {
            "en": "Index",
            "zh": "指数"
        }
    },
    {
        "translation": {
            "en": "action-value behavior network, 672",
            "zh": "行动-价值行为网络，672"
        }
    },
    {
        "translation": {
            "en": "convolutional auto-encoders, 630",
            "zh": "卷积自动编码器，630"
        }
    },
    {
        "translation": {
            "en": "Figure 3.13",
            "zh": "图 3.13"
        }
    },
    {
        "translation": {
            "en": "In order to handle categorical target features with more than two levels, that is multinomial prediction problems, we need to use a one-versus-all approach in which multiple models are trained.",
            "zh": "为了处理具有两个以上级别的分类目标特征，即多项式预测问题，我们需要使用一种训练多个模型的一对一方法。"
        }
    },
    {
        "translation": {
            "en": "8.3.3 Backpropagation: Updating the Weights in a Network",
            "zh": "8.3.3 反向传播：更新网络中的权重"
        }
    },
    {
        "translation": {
            "en": "For example, for a robot deployed within a hospital to deliver equipment to operating theaters, the state might include the robot’s position in the environment, the positions of people nearby, whether the robot is on the way to collect items or to deliver them, and the current levels of the robot’s batteries.",
            "zh": "例如，对于部署在医院内以将设备运送到手术室的机器人，状态可能包括机器人在环境中的位置、附近人员的位置、机器人是在收集物品还是运送物品的途中，以及机器人电池的当前水平。"
        }
    },
    {
        "translation": {
            "en": "33. Specifically, the calculation of the term ∂ℰ/∂ak (see Equation 8.22[412]).",
            "zh": "33. 具体而言，术语∂E/∂ak的计算（见公式8.22[412]）。"
        }
    },
    {
        "translation": {
            "en": "There was no fraud involved in the work at the Nancy lab.",
            "zh": "南希实验室的工作没有涉及欺诈行为。"
        }
    },
    {
        "translation": {
            "en": "This is particularly important in this case because FRAUD FLAG is the target feature, and as we will see in upcoming chapters, the type of the target feature has a big impact on how we apply machine learning techniques.",
            "zh": "在这种情况下，这一点尤为重要，因为 FRAUD FLAG 是目标特征，正如我们将在后面的章节中看到的那样，目标特征的类型对我们如何应用机器学习技术有很大影响。"
        }
    },
    {
        "translation": {
            "en": "2. the hxt vector is passed through a layer of sigmoid units to generate a vector mask that in this instance will control which of the activations within the candidate output vector will actually be propagated to the output layer; and",
            "zh": "2. HXT 向量通过 S 形结晶单元层以生成向量掩码，在这种情况下，该掩码将控制候选输出向量中的哪些激活将实际传播到输出层;和"
        }
    },
    {
        "translation": {
            "en": "Following the rules of standard matrix multiplication, the result of multiplying a 1 × 3 matrix by a 3 × 1 matrix is a 1 × 1 matrix (a matrix with a single value, i.e., a scalar).",
            "zh": "按照标准矩阵乘法的规则，将 1 × 3 矩阵乘以 3 × 1 矩阵的结果是 1 × 1 矩阵（具有单个值的矩阵，即标量）。"
        }
    },
    {
        "translation": {
            "en": "In the first target feature, just three levels were used: elliptical (P_EL majority), spiral (P_CW, P_ACW, or P_EDGE majority), and other (P_MG or P_DK majority).",
            "zh": "在第一个目标特征中，仅使用了三个级别：椭圆（P_EL多数）、螺旋（P_CW、P_ACW或P_EDGE多数）和其他（P_MG或P_DK多数）。"
        }
    },
    {
        "translation": {
            "en": "18. This example and dataset is based on the Combined Cycle Power Plant dataset available from the UCI repository at https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant and originally collected for the work reported in Tüfekci (2014)",
            "zh": "18. 本示例和数据集基于 https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant UCI 存储库中提供的联合循环电厂数据集，最初是为 Tüfekci （2014） 报告的工作收集的"
        }
    },
    {
        "translation": {
            "en": "Any values beyond the 1st quartile value plus 2.5 times the inter-quartile range were reduced to this value.",
            "zh": "任何超过第一个四分位数值加上四分位数间范围 2.5 倍的值都减少到此值。"
        }
    },
    {
        "translation": {
            "en": "Table 2.2[46] illustrates the structure of the final ABT that was designed for the motor insurance claims fraud detection solution.8 The table contains more descriptive features than the ones we have discussed in this section.9 The table also shows the first four instances.",
            "zh": "表 2.2[46] 说明了为汽车保险索赔欺诈检测解决方案设计的最终 ABT 的结构。8 该表包含的描述性特征比我们在本节中讨论的特征更多。9 该表还显示了前四个实例。"
        }
    },
    {
        "translation": {
            "en": "9.4   The division of data during the k-fold cross validation process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "9.4 k折交叉验证过程中的数据划分。黑色矩形表示测试数据，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "The for loop on lines 16[420] to 18[420] contains the calculations of the δs for neurons in the output layer, and the for loop on lines 19[420] to 23[420] is the calculation of the δs for neurons in the hidden layers.",
            "zh": "第 16[420] 行至 18[420] 上的 for 循环包含输出层中神经元的 δs 计算，第 19[420] 行至 23[420] 上的 for 循环是隐藏层中神经元的 δ 计算。"
        }
    },
    {
        "translation": {
            "en": "11.6 Further Reading",
            "zh": "11.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "linear relationship, 312, 351, 368",
            "zh": "线性关系， 312， 351， 368"
        }
    },
    {
        "translation": {
            "en": "A large hospital group has collected a cancer screening dataset for possible use with machine learning that contains features extracted from tissue samples extracted by biopsy from adults presenting for screening.",
            "zh": "一家大型医院集团收集了一个癌症筛查数据集，可能用于机器学习，该数据集包含从前来接受筛查的成年人通过活检提取的组织样本中提取的特征。"
        }
    },
    {
        "translation": {
            "en": "10.4.6   Representation Learning with Auto-Encoders",
            "zh": "10.4.6 使用自动编码器进行表示学习"
        }
    },
    {
        "translation": {
            "en": "Another benefit of the reduced representation of the model is that the behavior of the model is relatively easy to interpret.",
            "zh": "模型简化表示的另一个好处是模型的行为相对容易解释。"
        }
    },
    {
        "translation": {
            "en": "Still, throughout her training Sarah would occasionally still step into the water and experience the disappointing feeling of soggy feet, which reminded her to be more careful about her decisions next time.",
            "zh": "尽管如此，在整个训练过程中，莎拉偶尔还是会踏入水中，体验到脚湿透的令人失望的感觉，这提醒她下次要更加小心自己的决定。"
        }
    },
    {
        "translation": {
            "en": "(a)–(c) The evolution of the entries in the action-value table over episodes of Q-learning off-policy temporal-difference learning across the grid world. (d) The cumulative reward earned from each episode. (e) An illustration of the target policy learned by the agent after 350 episodes. The arrows show the direction with the highest entry in the action-value table for each state. (f) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "（a）–（c） 行动-价值表中条目在整个网格世界的 Q 学习、政策外时间差异学习事件中的演变。（d） 每集的累积奖励。（e） 代理人在350集后了解到的目标政策的说明。箭头显示每个状态的动作值表中条目最多的方向。（f） 当贪婪地遵循目标策略时，代理从开始状态到目标状态的路径。"
        }
    },
    {
        "translation": {
            "en": "Both techniques focus on transforming an individual feature in some way.",
            "zh": "这两种技术都侧重于以某种方式转换单个特征。"
        }
    },
    {
        "translation": {
            "en": "2. Although this case study is based on real data downloaded from the SDSS, the case study itself is entirely fictitious and developed only for the purposes of this book. Very similar work to that described in this section has, however, actually been undertaken, and details of representative examples are given in Section 13.6[727].",
            "zh": "2. 虽然本案例研究基于从 SDSS 下载的真实数据，但案例研究本身完全是虚构的，仅为本书的目的而开发。然而，实际上已经进行了与本节所述非常相似的工作，第13.6节[727]给出了代表性示例的详细信息。"
        }
    },
    {
        "translation": {
            "en": "3.8   Further Reading",
            "zh": "3.8 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "Mean absolute errors are in the same units as the predictions themselves, so we can say that, based on mean absolute error, we can expect the regression model to make errors of approximately 0.9575mg in each of its predictions and the nearest neighbor model to be out by approximately 4.020mg.",
            "zh": "平均绝对误差与预测本身的单位相同，因此我们可以说，基于平均绝对误差，我们可以预期回归模型在其每个预测中产生大约 0.9575mg 的误差，而最近邻模型的误差约为 4.020mg。"
        }
    },
    {
        "translation": {
            "en": "FIBER2FLUX_U/G/R/I/Z",
            "zh": "FIBER2FLUX_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Japkowicz and Shah (2011) also discusses the issue of performing statistical significance tests to compare the performance of multiple models.",
            "zh": "Japkowicz和Shah（2011）还讨论了执行统计显着性检验以比较多个模型的性能的问题。"
        }
    },
    {
        "translation": {
            "en": "In order to make a prediction, a model must compute the probability for a target event in the context where some other events are known (the evidence) and where there are potentially one or more hidden features.",
            "zh": "为了进行预测，模型必须在已知其他一些事件（证据）且可能存在一个或多个隐藏特征的上下文中计算目标事件的概率。"
        }
    },
    {
        "translation": {
            "en": "Using a hold-out test set avoids the issue of peeking, which arises when the performance of a model is evaluated on the same data used to train it; because the data was used in the training process, the model has already seen this data, so it is probable that it will perform very well when evaluated on this data.",
            "zh": "使用保持测试集可以避免窥视问题，当使用用于训练模型的相同数据评估模型的性能时，会出现窥视问题;由于数据是在训练过程中使用的，因此模型已经看到了这些数据，因此在评估这些数据时，它可能会表现得非常好。"
        }
    },
    {
        "translation": {
            "en": "The stability index is just one measure of the difference between two different distributions, and there are many other options that can be used.",
            "zh": "稳定性指数只是衡量两种不同分布之间差异的一种指标，还有许多其他选项可以使用。"
        }
    },
    {
        "translation": {
            "en": "Rather than a 50:50 split of churners to non-churners, the actual underlying ratio is, in fact, closer to 10:90.",
            "zh": "事实上，实际的基本比例更接近 10：90，而不是流失者与非流失者的 50：50 比例。"
        }
    },
    {
        "translation": {
            "en": "1,315",
            "zh": "1,315"
        }
    },
    {
        "translation": {
            "en": "Figure 8.20[443] illustrates how the sum of squared errors of the ReLU network changes during the training of the network.",
            "zh": "图 8.20[443] 说明了 ReLU 网络的平方误差和在网络训练过程中如何变化。"
        }
    },
    {
        "translation": {
            "en": "positively covariant, 74",
            "zh": "正协变，74"
        }
    },
    {
        "translation": {
            "en": "One type of artificial neural network can be built by connecting layers of logistic regression models, but there are many other network topologies used in practice.",
            "zh": "一种类型的人工神经网络可以通过连接逻辑回归模型的层来构建，但在实践中还使用了许多其他网络拓扑。"
        }
    },
    {
        "translation": {
            "en": "Introduction to Linear Algebra",
            "zh": "线性代数导论"
        }
    },
    {
        "translation": {
            "en": "(b) Reviewing the spread of marks for the other two modules, the lecturer notices that there is a larger variance across students in the marks for Module 2 than there is for Module 1. So, the lecturer decides to update the k-nearest neighbor model to use the Mahalanobis distance instead of Euclidean distance as its similarity measure. Assuming that the inverse covariance matrix for the Module 1 and Module 2 results is",
            "zh": "（b） 在审查其他两个单元的分数分布时，讲师注意到，学生在单元2的分数差异大于模块1的差异。因此，讲师决定更新 k 最近邻模型，以使用马氏距离而不是欧几里得距离作为其相似度度量。假设模块 1 和模块 2 结果的逆协方差矩阵为"
        }
    },
    {
        "translation": {
            "en": "For example, for categorical targets, the χ2 statistic is often used, and for continuous targets, the K-S statistic can also be used.",
            "zh": "例如，对于分类目标，通常使用 χ2 统计量，对于连续目标，也可以使用 K-S 统计量。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the decision boundaries learned by different machine learning algorithms for three artificial datasets.",
            "zh": "不同机器学习算法对三个人工数据集学习的决策边界的图示。"
        }
    },
    {
        "translation": {
            "en": "matrix, 771",
            "zh": "矩阵，771"
        }
    },
    {
        "translation": {
            "en": "2. You have been hired by the European Space Agency to build a model that predicts the amount of oxygen that an astronaut consumes when performing five minutes of intense physical work. The descriptive features for the model will be the age of the astronaut and their average heart rate throughout the work. The regression model is",
            "zh": "2. 您受雇于欧洲航天局，负责构建一个模型，该模型可以预测宇航员在进行五分钟的高强度体力劳动时消耗的氧气量。该模型的描述性特征将是宇航员的年龄和他们在整个工作过程中的平均心率。回归模型为"
        }
    },
    {
        "translation": {
            "en": "r-trees, 233",
            "zh": "R-树，233"
        }
    },
    {
        "translation": {
            "en": "Even though the separation between the instances with the different levels of the target feature in this case is not particularly well defined, a logistic regression model can be trained to distinguish between the two types of generator.",
            "zh": "尽管在这种情况下，具有不同目标特征级别的实例之间的分离不是特别明确，但可以训练逻辑回归模型来区分两种类型的生成器。"
        }
    },
    {
        "translation": {
            "en": "In this example, there are only two descriptive features, so the feature space is two-dimensional.",
            "zh": "在此示例中，只有两个描述性特征，因此特征空间是二维的。"
        }
    },
    {
        "translation": {
            "en": "The reason that this simplification is so important is that it allows us to simplify the calculations in Bayes’ Theorem, under the assumption of conditional independence between the descriptive features, given the level l of the target feature, from",
            "zh": "这种简化之所以如此重要，是因为它允许我们简化贝叶斯定理中的计算，假设描述性特征之间的条件独立性，给定目标特征的水平 l，从"
        }
    },
    {
        "translation": {
            "en": "1. P(t = l), the prior probability of the target feature t taking the level l",
            "zh": "1. P（t = l），目标特征 t 取水平 l 的先验概率"
        }
    },
    {
        "translation": {
            "en": "It was important that the model Jocelyn deployed not add a large delay to data becoming available to scientists.",
            "zh": "重要的是，Jocelyn 部署的模型不会给科学家可用的数据增加很大的延迟。"
        }
    },
    {
        "translation": {
            "en": "We then describe a number of strategies for handling data quality issues and when it is appropriate to use them.",
            "zh": "然后，我们描述了一些处理数据质量问题的策略，以及何时适合使用它们。"
        }
    },
    {
        "translation": {
            "en": "From this we can again conclude that guards are more likely to have a shoe sponsor than players in the other positions.",
            "zh": "由此我们可以再次得出结论，后卫比其他位置的球员更有可能拥有鞋子赞助商。"
        }
    },
    {
        "translation": {
            "en": "We then explain how a neural network can be modified and trained to handle categorical target features, using a softmax output layer and the cross-entropy loss function.",
            "zh": "然后，我们解释了如何使用softmax输出层和交叉熵损失函数来修改和训练神经网络以处理分类目标特征。"
        }
    },
    {
        "translation": {
            "en": "At the end of this process, you decide that the unknown animal is most similar to a duck, so that is what it must be.",
            "zh": "在这个过程的最后，你决定未知的动物与鸭子最相似，所以它必须如此。"
        }
    },
    {
        "translation": {
            "en": "Name",
            "zh": "名字"
        }
    },
    {
        "translation": {
            "en": "1. The table below shows the age of each employee at a cardboard box factory.",
            "zh": "1. 下表显示了纸板箱厂每位员工的年龄。"
        }
    },
    {
        "translation": {
            "en": "Features explicitly named in the text are denoted by the uppercase initial letters of their names. For example, a feature named MENINGITIS is denoted by M.",
            "zh": "文本中明确命名的要素由其名称的大写首字母表示。例如，名为脑膜炎的特征用 M 表示。"
        }
    },
    {
        "translation": {
            "en": "Feature Names and Feature Values",
            "zh": "功能名称和功能值"
        }
    },
    {
        "translation": {
            "en": "It is important to note here that we use control groups not to evaluate the predictive power of the models themselves, but rather to evaluate how good they are at helping with the business problem when they are deployed.",
            "zh": "这里需要注意的是，我们使用对照组不是为了评估模型本身的预测能力，而是为了评估它们在部署时在帮助解决业务问题方面的表现。"
        }
    },
    {
        "translation": {
            "en": "The connections that exist between key objects in the data model. For example, in a banking scenario is it possible to connect the multiple accounts that a single customer might own? Similarly, in an insurance scenario is it possible to connect the information from a policy application with the details (e.g., claims, payments, etc.) of the resulting policy itself?",
            "zh": "数据模型中的关键对象之间存在的连接。例如，在银行业务场景中，是否可以连接单个客户可能拥有的多个帐户？同样，在保险场景中，是否可以将保单应用程序中的信息与最终保单本身的详细信息（例如，索赔、付款等）联系起来？"
        }
    },
    {
        "translation": {
            "en": "The basic structure of an analytics base table—descriptive features and a target feature.",
            "zh": "分析基表的基本结构 - 描述性特征和目标特征。"
        }
    },
    {
        "translation": {
            "en": "Fully processed data from the SDSS pipeline is available to scientists approximately one week after images of night sky objects are captured by the SDSS telescopes.4 The system that Jocelyn built would be added to the end of this pipeline because it would require outputs from existing data processing steps.",
            "zh": "在SDSS望远镜捕获夜空天体图像大约一周后，科学家可以获得来自SDSS管道的完全处理数据.4 Jocelyn构建的系统将被添加到该管道的末尾，因为它需要现有数据处理步骤的输出。"
        }
    },
    {
        "translation": {
            "en": "These activations are stored in the matrix A(l).",
            "zh": "这些激活存储在矩阵 A（l） 中。"
        }
    },
    {
        "translation": {
            "en": "Instead, to avoid zero probabilities, we require only that for each value in the domain of the target feature, there be at least one instance in the dataset where each event in the evidence holds.",
            "zh": "相反，为了避免零概率，我们只要求对于目标特征域中的每个值，数据集中至少有一个实例，其中证据中的每个事件都成立。"
        }
    },
    {
        "translation": {
            "en": "Smoothing the posterior probabilities for the GUARANTOR/COAPPLICANT feature conditioned on FRAUD = false.",
            "zh": "平滑以 FRAUD = false 为条件的 GUARANTOR/COAPPLICANT 特征的后验概率。"
        }
    },
    {
        "translation": {
            "en": "In these models the value for w[0] is kept constant at 6.47, and the values for w[1] are set to 0.4, 0.5, 0.62, 0.7, and 0.8 from top to bottom.",
            "zh": "在这些模型中，w[0] 的值保持不变为 6.47，w[1] 的值从上到下设置为 0.4、0.5、0.62、0.7 和 0.8。"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, choosing learning rates is not a well-defined science. Although there are some algorithmic approaches, most practitioners use rules of thumb and trial and error. A typical range for learning rates is [0.00001, 10], and practitioners will usually try out higher values and observe the resulting learning graph. If the graph looks too much like Figure 7.7(f)[329], a smaller value will be tested until something approaching Figure 7.7(e)[329] is found.",
            "zh": "不幸的是，选择学习率并不是一门定义明确的科学。尽管有一些算法方法，但大多数从业者使用经验法则和试错法则。学习率的典型范围是 [0.00001， 10]，从业者通常会尝试更高的值并观察由此产生的学习图。如果图形看起来太像图7.7（f）[329]，则将测试较小的值，直到找到接近图7.7（e）[329]的值。"
        }
    },
    {
        "translation": {
            "en": "When an agent in state st takes action at, the difference between the current estimated return in the action-value table for that action in that state, Qπ(st,at), and the actual return received after taking the action is calculated.",
            "zh": "当处于状态 st 的代理在 t 时执行操作时，将计算该操作在该状态下的操作值表中的当前估计回报 Qπ（st，at） 与执行该操作后收到的实际返回之间的差值。"
        }
    },
    {
        "translation": {
            "en": "The term ∂ak/∂zk represents the rate of change of the neuron’s activation function with respect to changes in the weighted sum z (i.e., with respect to the input to the activation function). Because this ∂ak/∂zk term is required in order to calculate the δ for a neuron, the backpropagation algorithm assumes that the neurons in the network use differentiable activation functions. The logistic function (see Equation (7.25)[342]) has a very well-known and relatively simple derivative7",
            "zh": "术语 ∂ak/∂zk 表示神经元激活函数相对于加权总和 z 变化的变化率（即相对于激活函数的输入）。由于需要此 ∂ak/∂zk 项来计算神经元的δ，因此反向传播算法假定网络中的神经元使用可微激活函数。逻辑函数（参见方程（7.25）[342]）有一个非常著名且相对简单的导数7"
        }
    },
    {
        "translation": {
            "en": "The total value of the initial two cards dealt to the player can range from 4 (for example, 2 and 2 ) to 22 (for example, A and A ), giving 19 unique values.",
            "zh": "发给玩家的最初两张牌的总价值可以从 4（例如，2 和 2）到 22（例如，A 和 A），给出 19 个唯一值。"
        }
    },
    {
        "translation": {
            "en": "5.2.2   Measuring Similarity Using Distance Metrics",
            "zh": "5.2.2 使用距离指标衡量相似性"
        }
    },
    {
        "translation": {
            "en": "(b) Agglomerative hierarchical clustering (AHC) can easily be applied to this distance matrix. If single linkage is used with AHC, which agglomerations will be made in the first three iterations of the algorithm?",
            "zh": "（b）聚集分层聚类（AHC）可以很容易地应用于该距离矩阵。如果AHC使用单联动，则在算法的前三次迭代中将进行哪些团聚？"
        }
    },
    {
        "translation": {
            "en": "This section has presented a basic approach to evaluating prediction models. The most important things to take away from this example are:",
            "zh": "本节介绍了评估预测模型的基本方法。从这个例子中可以看出的最重要的事情是："
        }
    },
    {
        "translation": {
            "en": "The box labeled h0 represents that state of the activation memory buffer when the model is initialized.",
            "zh": "标记为 h0 的框表示初始化模型时激活内存缓冲区的状态。"
        }
    },
    {
        "translation": {
            "en": "Second, she used a two-stage model.",
            "zh": "其次，她使用了两阶段模型。"
        }
    },
    {
        "translation": {
            "en": "Wilcoxon-Mann-Whitney statistic, 563",
            "zh": "Wilcoxon-Mann-Whitney 统计，563"
        }
    },
    {
        "translation": {
            "en": "The multiple peaks in the density curve arise from the different subpopulations (a distribution with multiple peaks is called multimodal).",
            "zh": "密度曲线中的多个峰来自不同的亚群（具有多个峰的分布称为多峰分布）。"
        }
    },
    {
        "translation": {
            "en": "10.7   Exercises",
            "zh": "10.7 练习"
        }
    },
    {
        "translation": {
            "en": "(d) Calculate information gain (based on entropy) for the EDUCATION, MARITAL STATUS, and OCCUPATION features.",
            "zh": "（d） 计算教育、婚姻状况和职业特征的信息增益（基于熵）。"
        }
    },
    {
        "translation": {
            "en": "Interpretability, however, was not particularly important for the SDSS scenario (the model built would be added to the existing SDSS pipeline and process thousands of galaxy objects per day), so standardization was appropriate.",
            "zh": "然而，可解释性对于SDSS情景来说并不是特别重要（所建立的模型将被添加到现有的SDSS管道中，每天处理数千个星系天体），因此标准化是合适的。"
        }
    },
    {
        "translation": {
            "en": "22. These parameters are formally known as Lagrange multipliers.",
            "zh": "22. 这些参数的正式名称为拉格朗日乘数。"
        }
    },
    {
        "translation": {
            "en": "5.11   A binary dataset listing the behavior of two individuals on a website during a trial period and whether they subsequently signed up for the website.",
            "zh": "5.11 一个二进制数据集，列出两个人在试用期间在网站上的行为，以及他们随后是否注册了该网站。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, in order to isolate the effect of weight initialization on training dynamics from the problem of saturated activation functions, the neurons in this network use a linear activation function that outputs the same value that it receives as input: ai = zi.",
            "zh": "此外，为了将权重初始化对训练动力学的影响与饱和激活函数问题隔离开来，该网络中的神经元使用线性激活函数，该函数输出与输入相同的值：ai = zi。"
        }
    },
    {
        "translation": {
            "en": "As discussed in the previous section, it can also be calculated using the Theorem of Total Probability (in this instance, summing over all the target levels ∑k∈levels(t) P(q[1],…,q[m] | t = k)P(t = k)), or replaced entirely with a normalization constant, η.",
            "zh": "如上一节所述，它也可以使用总概率定理进行计算（在本例中，将所有目标水平相加∑k∈水平（t） P（q[1],...,q[m] | t = k）P（t = k）），或完全替换为归一化常数 η。"
        }
    },
    {
        "translation": {
            "en": "The reason is that decision trees are very sensitive to changes in the dataset: a small change in the dataset can result in a different feature being selected to split the dataset at the root or high in the tree, and this can have a ripple effect throughout the subtrees under this node.",
            "zh": "原因是决策树对数据集的变化非常敏感：数据集中的微小变化可能会导致选择不同的特征来拆分树中根部或高处的数据集，这可能会对该节点下的子树产生连锁反应。"
        }
    },
    {
        "translation": {
            "en": "The region around the car is divided into cells that can be empty, occupied by another car, or occupied by a barrier.",
            "zh": "汽车周围的区域被划分为多个单元格，这些单元格可以是空的，也可以被另一辆车占据，也可以被障碍物占据。"
        }
    },
    {
        "translation": {
            "en": "One of the most famous examples of sampling bias was in the 1936 U.S. presidential election, which pitted Franklin D. Roosevelt, the incumbent president, against Alfred Landon, the Republican governor of Kansas.",
            "zh": "抽样偏差最著名的例子之一是1936年的美国总统大选，现任总统富兰克林·罗斯福（Franklin D. Roosevelt）与堪萨斯州共和党州长阿尔弗雷德·兰登（Alfred Landon）对决。"
        }
    },
    {
        "translation": {
            "en": "stochastic, 415",
            "zh": "随机振荡指标，415"
        }
    },
    {
        "translation": {
            "en": "31.41",
            "zh": "31.41"
        }
    },
    {
        "translation": {
            "en": "This is because the maximum difference between d12 and d17 for any single feature is 7 units (for AGILITY), whereas the maximum difference between d12 and d5 on any single feature is just 5 units (for AGILITY).",
            "zh": "这是因为任何单个特征的 d12 和 d17 之间的最大差异为 7 个单位（对于敏捷性），而任何单个特征的 d12 和 d5 之间的最大差异仅为 5 个单位（对于敏捷性）。"
        }
    },
    {
        "translation": {
            "en": "The precision value tells us how likely it is that a genuine ham email could be marked as spam and, presumably, deleted: 25% (1 − precision).",
            "zh": "精度值告诉我们，真正的业余电子邮件被标记为垃圾邮件并可能被删除的可能性有多大：25%（1 - 精度）。"
        }
    },
    {
        "translation": {
            "en": "10.1   The three different arrangements of the magnetic letters made by the Murphy children on the Murphy family refrigerator.",
            "zh": "10.1 墨菲家冰箱上墨菲家冰箱上磁性字母的三种不同排列方式。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.13",
            "zh": "图 6.13"
        }
    },
    {
        "translation": {
            "en": "These simplifications aside, the processing and flow of data through Figure 8.36[498] is representative of the flow through a multi-layer, multi-filter convolutional neural network.",
            "zh": "撇开这些简化不谈，通过图8.36[498]处理和数据流代表了通过多层、多滤波器卷积神经网络的流。"
        }
    },
    {
        "translation": {
            "en": "A data quality report for the Acme Telephonica ABT.",
            "zh": "Acme Telephonica ABT 的数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "The agent can only stay in the PM-DH state if they have a hand value of 15 and are dealt a 2 or a 3; or if they have a hand value of 16 and are dealt a 2.",
            "zh": "只有当代理的手值为 15 并且被发给 2 或 3 时，代理才能保持在 PM-DH 状态;或者如果他们的手牌值为 16 并且被发给 2。"
        }
    },
    {
        "translation": {
            "en": "Tracing d2 through the logistic activation function, the activation for Neuron 3 for d2 is a3 = 0.4990.",
            "zh": "通过逻辑激活函数跟踪 d2，d2 的神经元 3 的激活为 a3 = 0.4990。"
        }
    },
    {
        "translation": {
            "en": "DEVMAG_U/G/R/I/Z",
            "zh": "DEVMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "(long)”) we suggest covering data preparation (Section 3.6), all the machine learning chapters, and the evaluation chapter.",
            "zh": "（long）“），我们建议涵盖数据准备（第 3.6 节）、所有机器学习章节和评估章节。"
        }
    },
    {
        "translation": {
            "en": "This was a decision made based on the data available and Ross’s expectation that anything farther back than this was likely to have little impact on predicting churn.",
            "zh": "这是根据现有数据做出的决定，以及 Ross 的预期，即任何比这更久远的事情都可能对预测客户流失产生很小影响。"
        }
    },
    {
        "translation": {
            "en": "Each row and column represent the feature named in the cells along the diagonal.",
            "zh": "每一行和每一列表示沿对角线的单元格中命名的要素。"
        }
    },
    {
        "translation": {
            "en": "On the basis of the information in this report, all continuous features were normalized using range normalization, and any missing values were replaced using mean imputation for continuous features and mode imputation for categorical features. After applying these data preparation operations, a multivariate logistic regression model was trained to give the weights shown in the following table.",
            "zh": "根据本报告中的信息，使用范围归一化对所有连续特征进行归一化，并使用连续特征的平均插补和分类特征的众数插补替换任何缺失值。在应用这些数据准备操作后，训练了一个多变量逻辑回归模型，以给出下表中所示的权重。"
        }
    },
    {
        "translation": {
            "en": "An important feature of this equation is that the support vectors are a component of the equation.",
            "zh": "该方程的一个重要特征是支持向量是方程的一个组成部分。"
        }
    },
    {
        "translation": {
            "en": "TwentyTwos, 645, 647, 680",
            "zh": "二十二，645,647,680"
        }
    },
    {
        "translation": {
            "en": "This is why, as Figure 8.11[406] shows, the activation for each neuron is stored during the forward pass of the algorithm; these activations are used to update the weights on the connections along which they are propagated. We now know how to calculate the sensitivity of the network error with respect to changes in a weight: ∂ℰ/∂wi,k. How do we use this term to update a weight?",
            "zh": "这就是为什么，如图8.11[406]所示，每个神经元的激活都是在算法的前向传递期间存储的;这些激活用于更新它们传播的连接上的权重。我们现在知道如何计算网络误差对权重变化的灵敏度：∂E/∂wi，k。我们如何使用这个术语来更新权重？"
        }
    },
    {
        "translation": {
            "en": "Using this idea and Equation (11.19)[652] the Bellman optimality equation for action-value functions can be written",
            "zh": "利用这个想法和方程（11.19）[652]，可以写出动作-价值函数的贝尔曼最优方程"
        }
    },
    {
        "translation": {
            "en": "Gauss, Carl Friedrich, 317",
            "zh": "高斯，卡尔·弗里德里希，317"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the rate of change of zi with respect to the activation of neuron k (ak) is the weight on the connection from neuron k to neuron i: wi,k.",
            "zh": "此外，zi 相对于神经元 k （ak） 激活的变化率是从神经元 k 到神经元 i 的连接上的权重：wi，k。"
        }
    },
    {
        "translation": {
            "en": "Using Sokal-Michener for our online services example q, is judged to be more similar to instance d2 than instance d1:",
            "zh": "将 Sokal-Michener 用于我们的在线服务示例 q，判断为与实例 d2 比实例 d1 更相似："
        }
    },
    {
        "translation": {
            "en": "For example, in the office rentals dataset, the values of the SIZE feature range from 500 to 1,000, whereas the values for the FLOOR feature range from only 4 to 14.",
            "zh": "例如，在办公室租赁数据集中，SIZE 要素的值范围为 500 到 1,000，而 FLOOR 要素的值范围仅为 4 到 14。"
        }
    },
    {
        "translation": {
            "en": "From then on, the sum of squared errors of the network continues to slowly reduce until it reaches the convergence criterion of SSE < 0.0001.",
            "zh": "从那时起，网络的平方误差之和继续缓慢减小，直到达到 SSE < 0.0001 的收敛准则。"
        }
    },
    {
        "translation": {
            "en": "The division of data during the k-fold cross validation process. Black rectangles indicate test data, and white spaces indicate training data.",
            "zh": "k 折叠交叉验证过程中的数据划分。黑色矩形表示测试数据，白色空格表示训练数据。"
        }
    },
    {
        "translation": {
            "en": "The search will then move to a new node (Lines 8, 9, 10, and 11).",
            "zh": "然后，搜索将移动到新节点（第 8、9、10 和 11 行）。"
        }
    },
    {
        "translation": {
            "en": "Daelemans, W., and A. van den Bosch. 2005. Memory-based language processing. Studies in natural language processing. Cambridge University Press.",
            "zh": "Daelemans， W. 和 A. van den Bosch。2005. 基于记忆的语言处理.自然语言处理研究。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "0.2217",
            "zh": "0.2217"
        }
    },
    {
        "translation": {
            "en": "pruning dataset, 155",
            "zh": "修剪数据集，155"
        }
    },
    {
        "translation": {
            "en": "Just over a week later, you are very disappointed to read an article published by Wood in the journal Nature (Wood, 1904) that completely refutes the existence of N rays.",
            "zh": "仅仅一个多星期后，你非常失望地读到伍德在《自然》（Wood，1904）杂志上发表的一篇文章，该文章完全驳斥了N射线的存在。"
        }
    },
    {
        "translation": {
            "en": "In order to do this, we have included topics that are not covered in many machine learning books, including discussions on business understanding, data exploration and preparation, and case studies.",
            "zh": "为了做到这一点，我们纳入了许多机器学习书籍中没有涉及的主题，包括关于业务理解、数据探索和准备以及案例研究的讨论。"
        }
    },
    {
        "translation": {
            "en": "The sum of squared errors function can be used to measure how well any combination of weights fits the instances in a training dataset. The next section explains how the values of an error function for many different potential models can be combined to form an error surface across which we can search for the optimal weights with the minimum sum of squared errors.3",
            "zh": "平方误差总和函数可用于衡量任何权重组合与训练数据集中实例的拟合程度。下一节将解释如何组合许多不同潜在模型的误差函数值以形成一个误差曲面，我们可以在该曲面上搜索误差最小平方和的最佳权重3。"
        }
    },
    {
        "translation": {
            "en": "softmax output layer, 434, 463, 463, 495",
            "zh": "softmax 输出层， 434， 463， 463， 495"
        }
    },
    {
        "translation": {
            "en": "Differentiation is a part of calculus, which is a large and very important field of mathematics.",
            "zh": "微分是微积分的一部分，微积分是数学中一个庞大而非常重要的领域。"
        }
    },
    {
        "translation": {
            "en": "MAP, 254",
            "zh": "地图， 254"
        }
    },
    {
        "translation": {
            "en": "These shapes relate to well-known standard probability distributions,3 and recognizing that the distribution of the values in an ABT for a feature closely matches one of these standard distributions can help us when building machine learning models.",
            "zh": "这些形状与众所周知的标准概率分布有关，3 并且认识到特征的 ABT 中值的分布与这些标准分布之一非常匹配，可以帮助我们构建机器学习模型。"
        }
    },
    {
        "translation": {
            "en": "One of these error gradients is calculated for each neuron in the network.",
            "zh": "为网络中的每个神经元计算其中一个误差梯度。"
        }
    },
    {
        "translation": {
            "en": "2. See Section 2.4.3[36].",
            "zh": "2. 参见第 2.4.3 节[36]。"
        }
    },
    {
        "translation": {
            "en": "In the set shown in Figure 4.5(a)[124], all the cards are identical.",
            "zh": "在图4.5（a）[124]所示的集合中，所有卡片都是相同的。"
        }
    },
    {
        "translation": {
            "en": "data visualization, 99, 752",
            "zh": "数据可视化， 99， 752"
        }
    },
    {
        "translation": {
            "en": "4. The words multivariable and multi-feature are equivalent. The use of multivariable is a sign of the origins of regression in statistics rather than machine learning.",
            "zh": "4. 多变量和多特征这两个词是等价的。多变量的使用是统计学而不是机器学习中回归起源的标志。"
        }
    },
    {
        "translation": {
            "en": "This means that, again like our mountain climber, the gradient descent algorithm can use the direction of the slope of the error surface at the current location in the weight space.",
            "zh": "这意味着，就像我们的登山者一样，梯度下降算法可以使用权重空间中当前位置的误差表面的斜率方向。"
        }
    },
    {
        "translation": {
            "en": "The main disadvantages of using basis functions are, first, that we must manually decide what set of basis functions to use; and second, that the number of weights in a model using basis functions is usually far greater than the number of descriptive features, so finding the optimal set of weights involves a search across a much larger set of possibilities—that is, a much larger weight space.",
            "zh": "使用基函数的主要缺点是，首先，我们必须手动决定使用哪一组基函数;其次，使用基函数的模型中的权重数通常远远大于描述性特征的数量，因此要找到最佳权重集，需要搜索更大的可能性集，即更大的权重空间。"
        }
    },
    {
        "translation": {
            "en": "1.2   A more complex credit scoring dataset.",
            "zh": "1.2 更复杂的信用评分数据集。"
        }
    },
    {
        "translation": {
            "en": "Any values outside these thresholds would be converted to the threshold values.",
            "zh": "超出这些阈值的任何值都将转换为阈值。"
        }
    },
    {
        "translation": {
            "en": "The preceding analysis highlighted that the variance of output of a weighted sum is dependent on the number of inputs to the weighted sum (be it nin during forward propagation or nout during backward propagation).",
            "zh": "前面的分析强调，加权和的输出方差取决于加权和的输入数量（无论是前向传播期间的 nin 还是后向传播期间的 nout）。"
        }
    },
    {
        "translation": {
            "en": "Table 10.5(d)[620] shows the distance matrix after this new cluster has been created.",
            "zh": "表10.5（d）[620]显示了创建此新聚类后的距离矩阵。"
        }
    },
    {
        "translation": {
            "en": "EXPABERR_U/G/R/I/Z",
            "zh": "EXPABERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Kingma, Diederik P., and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.",
            "zh": "Kingma、Diederik P. 和 Jimmy Ba。2014. Adam：一种随机优化方法。arXiv 预印本 arXiv：1412.6980。"
        }
    },
    {
        "translation": {
            "en": "14.1   Different Perspectives on Prediction Models",
            "zh": "14.1 预测模型的不同视角"
        }
    },
    {
        "translation": {
            "en": "7.18   A scatter plot of the P20 and P45 features from the EEG dataset. Instances representing positive images are shown as crosses, and those representing negative images as triangles.",
            "zh": "7.18 EEG 数据集中 P20 和 P45 特征的散点图。表示正图像的实例显示为十字形，表示负图像的实例显示为三角形。"
        }
    },
    {
        "translation": {
            "en": "As a result, full joint distributions are not tractable for any domain of reasonable complexity.",
            "zh": "因此，对于任何具有合理复杂性的领域，完全联合分布都是不可处理的。"
        }
    },
    {
        "translation": {
            "en": "Hubel, D. H., and T. N. Wiesel. 1962. Receptive fields, binocular interation and functional architecture in the cat’s visual cortex. Journal of Physiology 160: 106–154.",
            "zh": "Hubel， DH 和 TN Wiesel。1962. 猫视觉皮层中的感受野、双眼交互和功能结构。生理学杂志160：106-154。"
        }
    },
    {
        "translation": {
            "en": "John would like to thank Lorraine Byrne, Simon Dobnik, Dietmar Frey, Ionella Longo, Alan Mc Donnell, Josef van Genabith, Mary van Genabith, his colleagues and students at Technological University Dublin and in the ADAPT Centre, and all his friends from basketball for their help and encouragement.",
            "zh": "John 要感谢 Lorraine Byrne、Simon Dobnik、Dietmar Frey、Ionella Longo、Alan Mc Donnell、Josef van Genabith、Mary van Genabith、他在都柏林理工大学和 ADAPT 中心的同事和学生，以及他所有篮球界的朋友们的帮助和鼓励。"
        }
    },
    {
        "translation": {
            "en": "MSE, 575",
            "zh": "MSE，575"
        }
    },
    {
        "translation": {
            "en": "Once we have selected the distributions, the next step is to fit the distributions to the data.",
            "zh": "一旦我们选择了分布，下一步就是将分布拟合到数据中。"
        }
    },
    {
        "translation": {
            "en": "However, even using the variable elimination algorithm, calculating exact probabilities from a Bayesian network when descriptive feature values are missing is prohibitively complex.",
            "zh": "然而，即使使用变量消元算法，在缺少描述性特征值时从贝叶斯网络计算精确概率也是非常复杂的。"
        }
    },
    {
        "translation": {
            "en": "For these reasons, the inclusion of more complex functions with the neurons of the network or the inclusion of more neurons within the hidden layer of the network makes the learning task more difficult.",
            "zh": "由于这些原因，在网络的神经元中包含更复杂的函数或在网络的隐藏层中包含更多的神经元会使学习任务更加困难。"
        }
    },
    {
        "translation": {
            "en": "To do this we must adjust the derivatives used in the calculation of the δs for the output neurons because we have changed the activation function used by these neurons.",
            "zh": "为此，我们必须调整用于计算输出神经元的δ的导数，因为我们已经改变了这些神经元使用的激活函数。"
        }
    },
    {
        "translation": {
            "en": "We have presented this discussion on the context of episodic, model-free, policy-based reinforcement learning.",
            "zh": "我们在情节性、无模型、基于策略的强化学习的背景下进行了讨论。"
        }
    },
    {
        "translation": {
            "en": "The bottleneck layer contains six units, and this is the dimensionality of the new representation, or embedding, generated.",
            "zh": "瓶颈层包含六个单元，这是生成的新表示或嵌入的维度。"
        }
    },
    {
        "translation": {
            "en": "Dick: Not alphabetical…",
            "zh": "迪克：不是按字母顺序排列的......"
        }
    },
    {
        "translation": {
            "en": "Table 7.4",
            "zh": "表 7.4"
        }
    },
    {
        "translation": {
            "en": "The value of the DRAFT feature is indicated by the shape representing each instance as a point in the feature space: triangles for no and crosses for yes.",
            "zh": "DRAFT 特征的值由将每个实例表示为特征空间中一个点的形状表示：三角形表示否，十字表示是。"
        }
    },
    {
        "translation": {
            "en": "In the early 1960s Hubel and Wiesel carried out a series of experiments in which they used probes to track the neural activity in the brains of sedated cats while simple visual features such as horizontal or vertical lines of light were projected onto different locations on a dark screen (Hubel and Wiesel, 1962).",
            "zh": "在 1960 年代初期，Hubel 和 Wiesel 进行了一系列实验，他们使用探针跟踪镇静猫大脑中的神经活动，同时将简单的视觉特征（例如水平或垂直线）投射到暗屏幕上的不同位置（Hubel 和 Wiesel，1962 年）。"
        }
    },
    {
        "translation": {
            "en": "Level",
            "zh": "水平"
        }
    },
    {
        "translation": {
            "en": "MaxEnt model, 357",
            "zh": "MaxEnt 型号，357"
        }
    },
    {
        "translation": {
            "en": "The calculation of an error derivative with respect to a weight is valid only for small changes in that weight.",
            "zh": "相对于权重的误差导数的计算仅对该权重的微小变化有效。"
        }
    },
    {
        "translation": {
            "en": "analytics solution, 23, 24",
            "zh": "分析解决方案， 23， 24"
        }
    },
    {
        "translation": {
            "en": "This does not affect the generality of the discussion because, as we discussed earlier, a weighted sum that includes a bias term as a weight implements an affine transformation composed of first applying a linear function to the inputs and then translating the result by a bias.",
            "zh": "这并不影响讨论的一般性，因为正如我们之前所讨论的，包含偏置项作为权重的加权和实现了仿射变换，该变换由首先对输入应用线性函数，然后通过偏差转换结果组成。"
        }
    },
    {
        "translation": {
            "en": "The assumption of conditional independence between the features in the evidence given the level of the target feature also makes the naive Bayes model relatively robust to data fragmentation and the curse of dimensionality. This is particularly important in scenarios with small datasets or with sparse data.14 One application domain where sparse data is the norm rather than the exception is in text analytics (for example, spam filtering), and naive Bayes models are often successful in this domain.",
            "zh": "给定目标特征的水平，假设证据中的特征之间存在条件独立性，这也使朴素贝叶斯模型对数据碎片和维数诅咒相对鲁棒。这在数据集较小或数据稀疏的场景中尤为重要。14 在文本分析（例如，垃圾邮件过滤）中，稀疏数据是常态而不是例外的一个应用域，而朴素的贝叶斯模型通常在此领域取得成功。"
        }
    },
    {
        "translation": {
            "en": "The table in a data quality report that describes continuous features should include a row containing the minimum, 1st quartile, mean, median, 3rd quartile, maximum, and standard deviation statistics for that feature as well as the total number of instances in the ABT, the percentage of instances in the ABT that are missing a value for each feature and the cardinality of each feature, (cardinality measures the number of distinct values present in the ABT for a feature).",
            "zh": "数据质量报告中描述连续要素的表应包括一行，其中包含该要素的最小值、第 1 个四分位数、平均值、中位数、第 3 个四分位数、最大值和标准差统计数据，以及 ABT 中的实例总数、ABT 中缺少每个特征值的实例百分比以及每个特征的基数， （基数测量特征的 ABT 中存在的非重复值的数量）。"
        }
    },
    {
        "translation": {
            "en": "Suggested course syllabi.",
            "zh": "建议的课程大纲。"
        }
    },
    {
        "translation": {
            "en": "In our suggested course we have chosen to cover all of Chapters 4 (Information-Based Learning) and 7 (Error-Based Learning).",
            "zh": "在我们推荐的课程中，我们选择涵盖第 4 章（基于信息的学习）和第 7 章（基于错误的学习）的所有内容。"
        }
    },
    {
        "translation": {
            "en": "9.10   Prediction score distributions for the (a) spam and (b) ham target levels based on the data in Table 9.11[557].",
            "zh": "9.10 根据表9.11[557]中的数据，（a）垃圾邮件和（b）火腿目标水平的预测分数分布。"
        }
    },
    {
        "translation": {
            "en": "Figure 13.3[710] shows bar plots of the frequencies of the 3-level and the 5-level target features.",
            "zh": "图13.3[710]显示了3级和5级目标特征的频率条形图。"
        }
    },
    {
        "translation": {
            "en": "error surface, 311, 317",
            "zh": "误差面，311,317"
        }
    },
    {
        "translation": {
            "en": "The parameters of the models learned for the three final decision boundaries in Figure 7.21[360] are",
            "zh": "图7.21[360]中三个最终决策边界的模型参数为"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of the extended generators dataset given in Table 7.7[347], which results in instances with the different target levels overlapping each other. Instances representing good generators are shown as crosses, and those representing faulty generators as triangles.",
            "zh": "表 7.7[347] 中给出的扩展生成器数据集的散点图，这导致不同目标水平相互重叠的实例。表示良好生成器的实例显示为十字形，表示故障生成器的实例显示为三角形。"
        }
    },
    {
        "translation": {
            "en": "A recurrent neural network is deliberately designed so that when the network processes an input at time t in a sequence, the output generated is dependent not only on input t but also on the previous inputs in the sequence.",
            "zh": "循环神经网络经过精心设计，当网络在序列中的时间 t 处理输入时，生成的输出不仅依赖于输入 t，还依赖于序列中的先前输入。"
        }
    },
    {
        "translation": {
            "en": "He decided that the observation period, during which he would collect data on customer behavior, would stretch back for 12 months.",
            "zh": "他决定将收集客户行为数据的观察期延长 12 个月。"
        }
    },
    {
        "translation": {
            "en": "A difficulty with training a deep network with backpropagation and gradient descent is unstable gradients (either vanishing or exploding gradients).",
            "zh": "训练具有反向传播和梯度下降的深度网络的一个困难是不稳定的梯度（消失或爆炸梯度）。"
        }
    },
    {
        "translation": {
            "en": "London, England",
            "zh": "英国伦敦"
        }
    },
    {
        "translation": {
            "en": "By examining the data for this feature more closely, they eventually explained this shape by the fact that most customers did not go over the number of minutes in their bundle, which accounts for the large bar for 0 in this histogram.",
            "zh": "通过更仔细地检查此功能的数据，他们最终通过大多数客户没有超过其捆绑包中的分钟数这一事实来解释这种形状，这解释了该直方图中 0 的大条形图。"
        }
    },
    {
        "translation": {
            "en": "For the players’ heights given in Figure A.3[747], the mean is also 149.375, so the variance can be calculated as",
            "zh": "对于图A.3[747]中给出的球员身高，平均值也是149.375，因此方差可以计算为："
        }
    },
    {
        "translation": {
            "en": "Table 5.3[189] shows the distances between our query instance and each instance from Table 5.2[183] ranked from lowest to highest.",
            "zh": "表 5.3[189] 显示了我们的查询实例与表 5.2[183] 中每个实例之间的距离，从低到高排序。"
        }
    },
    {
        "translation": {
            "en": "8.36   Worked example illustrating the dataflow through a multilayer, multifilter CNN.",
            "zh": "8.36 工作示例说明了通过多层、多滤波器 CNN 的数据流。"
        }
    },
    {
        "translation": {
            "en": "loss function, 168, 315, 409, 670",
            "zh": "损失函数， 168， 315， 409， 670"
        }
    },
    {
        "translation": {
            "en": "Each of these recursive calls uses the partition it is called on as the dataset it considers and is restricted to selecting from the set of features that have not been tested so far on the path from the root node.",
            "zh": "这些递归调用中的每一个都使用它被调用的分区作为它考虑的数据集，并且仅限于从根节点路径上迄今为止尚未测试的功能集中进行选择。"
        }
    },
    {
        "translation": {
            "en": "Guided search techniques, such as the gradient descent algorithm, are used for this task.",
            "zh": "引导式搜索技术（如梯度下降算法）用于此任务。"
        }
    },
    {
        "translation": {
            "en": "Table 1.1[6] lists a set of historical instances, or dataset, of mortgages that a bank has granted in the past.2 This dataset includes descriptive features that describe the mortgage, and a target feature that indicates whether the mortgage applicant ultimately defaulted on the loan or paid it back in full.",
            "zh": "表1.1[6]列出了一组银行过去发放的抵押贷款的历史实例或数据集.2该数据集包括描述抵押贷款的描述性特征，以及指示抵押贷款申请人最终是拖欠贷款还是全额偿还的目标特征。"
        }
    },
    {
        "translation": {
            "en": "Although all the factors relating to data that were considered during the feasibility assessment of the analytics solution2 are still relevant, three key data considerations are particularly important when we are designing features.",
            "zh": "尽管在分析解决方案2的可行性评估期间考虑的与数据相关的所有因素仍然相关，但在设计功能时，三个关键数据考虑因素尤为重要。"
        }
    },
    {
        "translation": {
            "en": "AGE: The age of the taxpayer.",
            "zh": "年龄：纳税人的年龄。"
        }
    },
    {
        "translation": {
            "en": "In the formulation given in Equation (11.7)[642] expected future rewards are considered to be as valuable as the immediate reward that the agent will receive from taking the next immediate action, at.",
            "zh": "在等式（11.7）[642]中给出的公式中，预期的未来奖励被认为与智能体从采取下一个立即行动中获得的即时奖励一样有价值。"
        }
    },
    {
        "translation": {
            "en": "Although rank and prune approaches using filters are computationally efficient, they suffer from the fact that the predictiveness of each feature is evaluated in isolation from the other features in the dataset. This leads to the undesirable result that ranking and pruning can exclude interacting features and include redundant features.",
            "zh": "尽管使用过滤器的秩和修剪方法在计算上是有效的，但它们受到以下事实的影响：每个特征的预测性都是与数据集中的其他特征隔离评估的。这会导致不良结果，即排序和修剪可以排除交互特征并包含冗余特征。"
        }
    },
    {
        "translation": {
            "en": "Bringing all the LSTM equations together specifies the sequence of calculations that occur in the forward pass of an LSTM",
            "zh": "将所有 LSTM 方程放在一起指定了在 LSTM 的前向传递中发生的计算顺序"
        }
    },
    {
        "translation": {
            "en": "(f) On the basis of the changes made to the TwentyTwos playing agent’s action-value table following the two actions taken in the previous parts of this question, how has the agent’s target policy changed?",
            "zh": "（f） 根据本问题前几部分采取的两次行动之后，对二十二游戏代理人的行动价值表所做的更改，代理人的目标政策发生了怎样的变化？"
        }
    },
    {
        "translation": {
            "en": "For example, as we discussed in Chapter 6[243] on probability, generative models encode independence assumptions about the descriptive features in d. This may sound like another problem for generative models.",
            "zh": "例如，正如我们在第 6 章[243]中讨论的概率，生成模型编码了关于 d 中描述性特征的独立性假设。对于生成模型来说，这听起来像是另一个问题。"
        }
    },
    {
        "translation": {
            "en": "Western Electric rules, 579",
            "zh": "西部电气规则，579"
        }
    },
    {
        "translation": {
            "en": "The first path of information processing in the input gate decides which elements of the cell state should be updated.",
            "zh": "输入门中信息处理的第一条路径决定了单元状态的哪些元素应该更新。"
        }
    },
    {
        "translation": {
            "en": "Names: Kelleher, John D., 1974- author. |",
            "zh": "又名： Kelleher， John D.， 1974- author.|"
        }
    },
    {
        "translation": {
            "en": "Other than changing the weight update rule, we don’t need to make any other changes to the model training process presented for multivariable linear regression models. To further illustrate this process, the next section presents a worked example of training a multivariable logistic regression model for an extended version of the generators dataset.",
            "zh": "除了更改权重更新规则外，我们不需要对多变量线性回归模型的模型训练过程进行任何其他更改。为了进一步说明这一过程，下一节将介绍一个为生成器数据集的扩展版本训练多变量逻辑回归模型的工作示例。"
        }
    },
    {
        "translation": {
            "en": "A dataset of whiskeys listing the age (in years), the rating (between 1 and 5, with 5 being the best), and the bottle price of each whiskey.",
            "zh": "威士忌数据集，列出每种威士忌的年龄（以年为单位）、评级（在 1 到 5 之间，其中 5 是最好的）和瓶价。"
        }
    },
    {
        "translation": {
            "en": "The reason why the error surface always has these properties is that its overall shape is determined by the linearity of the model, rather than the properties of the data.",
            "zh": "误差曲面始终具有这些属性的原因是，其整体形状由模型的线性度决定，而不是数据的属性。"
        }
    },
    {
        "translation": {
            "en": "Anscombe, Francis J. 1973. Graphs in statistical analysis. American Statistician 27 (1): 17–21.",
            "zh": "Anscombe，弗朗西斯 J. 1973 年。统计分析中的图表。美国统计学家27（1）：17-21。"
        }
    },
    {
        "translation": {
            "en": "control group, 583",
            "zh": "对照组，583"
        }
    },
    {
        "translation": {
            "en": "A consequence of this layer-wise transformation of the input data into new representations is that as the network becomes deeper, the ability of the network to represent more complex relationships between descriptive and target features is increased.",
            "zh": "将输入数据逐层转换为新表示的结果是，随着网络的深度，网络表示描述性和目标特征之间更复杂关系的能力会增强。"
        }
    },
    {
        "translation": {
            "en": "Instead, it is better to choose a number of different approaches and to run experiments to evaluate which is best for the particular project.",
            "zh": "相反，最好选择许多不同的方法并运行实验来评估哪种方法最适合特定项目。"
        }
    },
    {
        "translation": {
            "en": "average linkage: the average of the distances between all pairs of instances in two clusters is used as the overall distance between the clusters; and",
            "zh": "平均联动：以两个集群中所有实例对之间的距离平均值作为集群之间的总距离;和"
        }
    },
    {
        "translation": {
            "en": "| f) from P(H,F,V,M) by summing the values in all the cells where h and f are the case (the top four cells in the first column).",
            "zh": "|f） 从 P（H，F，V，M） 中，将 h 和 f 所在的所有单元格（第一列中的前四个单元格）中的值相加。"
        }
    },
    {
        "translation": {
            "en": "The agent does not need to know anything about the dynamics of the environment in which it is acting.",
            "zh": "智能体不需要知道它所处环境的动态。"
        }
    },
    {
        "translation": {
            "en": "In this approach the features are ranked using a measure of their predictiveness, and any feature outside the top X% of the features in the list is pruned.",
            "zh": "在这种方法中，使用其预测性的度量对特征进行排名，并且将修剪列表中前 X% 特征之外的任何特征。"
        }
    },
    {
        "translation": {
            "en": "13. A hard threshold can be used fairly successfully to train prediction models for categorical targets using the perceptron learning rule, although we do not cover that in this book.",
            "zh": "13. 硬阈值可以相当成功地用于使用感知器学习规则来训练分类目标的预测模型，尽管我们在本书中没有介绍它。"
        }
    },
    {
        "translation": {
            "en": "affine function, 385",
            "zh": "仿射函数，385"
        }
    },
    {
        "translation": {
            "en": "One of the most common applications of clustering is customer segmentation with which organizations attempt to discover meaningful groupings into which they can group their customers so that targeted offers or treatments can be designed.",
            "zh": "聚类最常见的应用之一是客户细分，组织试图通过它发现有意义的分组，他们可以将客户分组到这些分组中，以便设计有针对性的优惠或治疗。"
        }
    },
    {
        "translation": {
            "en": "Figure 10.5",
            "zh": "图 10.5"
        }
    },
    {
        "translation": {
            "en": "There are, in fact, mathematical proofs that show that neural networks with a single hidden layer are universal approximators; i.e., they can exactly represent any continuous function of multiple inputs.",
            "zh": "事实上，有数学证明表明，具有单个隐藏层的神经网络是通用近似器;也就是说，它们可以精确地表示多个输入的任何连续函数。"
        }
    },
    {
        "translation": {
            "en": "Note that we have dropped the subscript on w because every wi is sampled from the same distribution and hence has the same expected value and variance: E(W) is the expected value of a weight (i.e., the probabilistic average, or mean value, of the weights), and var(W) is the shared scaler variance of all the weights.",
            "zh": "请注意，我们删除了 w 上的下标，因为每个 wi 都是从相同的分布中采样的，因此具有相同的期望值和方差：E（W） 是权重的期望值（即权重的概率平均值或平均值），var（W） 是所有权重的共享标度方差。"
        }
    },
    {
        "translation": {
            "en": "LU decomposition, 220",
            "zh": "LU分解，220"
        }
    },
    {
        "translation": {
            "en": "13.4 Modeling",
            "zh": "13.4 建模"
        }
    },
    {
        "translation": {
            "en": "For this type of network, it is common to use rectified linear activation functions in the units in all layers except for the final output layer, at which either sigmoid or linear activation functions are usually used.12 Loss in auto-encoder networks is typically measured using mean squared error loss,13 rather than the loss functions more commonly used for classification problems.",
            "zh": "对于这种类型的网络，通常在所有层的单元中使用校正的线性激活函数，但最终输出层除外，通常使用sigmoid或线性激活函数。12 自动编码器网络中的损耗通常使用均方误差损耗13来测量，而不是更常用于分类问题的损耗函数。"
        }
    },
    {
        "translation": {
            "en": "Focusing on the input gate, the gradients for each of the inputs to the elementwise product can now be calculated as follows:",
            "zh": "以输入门为重点，现在可以按元素乘积计算每个输入的梯度，如下所示："
        }
    },
    {
        "translation": {
            "en": "A.3   Populations and Samples",
            "zh": "A.3 种群和样本"
        }
    },
    {
        "translation": {
            "en": "Although there are some well-known sets of functions—for example, different order polynomial functions—this can be a considerable challenge.",
            "zh": "尽管有一些众所周知的函数集（例如，不同阶多项式函数），但这可能是一个相当大的挑战。"
        }
    },
    {
        "translation": {
            "en": "What has happened is that asserting conditional independence has allowed the evidence of the individual symptoms to be taken into account, rather than requiring an exact match across all the symptoms taken together.",
            "zh": "实际情况是，主张有条件的独立性允许考虑个体症状的证据，而不是要求所有症状完全匹配。"
        }
    },
    {
        "translation": {
            "en": "Whether deep learning is applied to regression or classification, the size and complexity of deep learning models make them susceptible to overfitting, and so in Section 8.4.4[472] we cover the two most popular extensions to backpropagation that are used to try to avoid overfitting: early stopping and dropout.",
            "zh": "无论深度学习是应用于回归还是分类，深度学习模型的规模和复杂性都使它们容易受到过拟合的影响，因此在第 8.4.4 节[472]中，我们介绍了两个最流行的反向传播扩展，用于避免过度拟合：提前停止和辍学。"
        }
    },
    {
        "translation": {
            "en": "This formulation of temporal-difference learning that performs an action-value table update after every action is known as TD(0).",
            "zh": "这种在每次操作后执行动作值表更新的时间差分学习公式称为 TD（0）。"
        }
    },
    {
        "translation": {
            "en": "For example, if there were two target levels with equal likelihood in a dataset, then the expected rate of misclassification would be 0.5, and if there were four target levels with equal likelihood, then the expected rate of misclassification would be 0.75.",
            "zh": "例如，如果数据集中有两个可能性相等的目标水平，则预期错误分类率为 0.5，如果有四个可能性相等的目标水平，则预期错误分类率为 0.75。"
        }
    },
    {
        "translation": {
            "en": "For the original test set and the two new test sets, referred to as New Sample 1 and New Sample 2, the count and percentage for each target value is given (note that the tests sets do not have to be the same size because relative distributions are used).",
            "zh": "对于原始测试集和两个新测试集（称为新样本 1 和新样本 2），将给出每个目标值的计数和百分比（请注意，测试集的大小不必相同，因为使用了相对分布）。"
        }
    },
    {
        "translation": {
            "en": "For the last function, f(x) = 3x3 + 2x2 − x− 2 (Figure C.2(c)[767]), we first apply Rule 3 to divide this into four parts: 3x3, 2x2, x, and 2. Applying Rule 2 to each of the first three parts gives 9x2, 4x, and − 1. The final part, 2, is a constant and so differentiates to zero. The derivative of this function then is .",
            "zh": "对于最后一个函数，f（x） = 3x3 + 2x2 − x− 2 （图 C.2（c）[767]），我们首先应用规则 3 将其分为四个部分：3x3、2x2、x 和 2。 将规则 2 应用于前三个部分，得到 9x2、4x 和 − 1。最后一部分 2 是一个常数，因此微分为零。则该函数的导数为 。"
        }
    },
    {
        "translation": {
            "en": "An epoch is a single pass through all the examples in the training dataset.",
            "zh": "纪元是训练数据集中所有示例的单次传递。"
        }
    },
    {
        "translation": {
            "en": "14.2.1   Matching Machine Learning Approaches to Projects",
            "zh": "14.2.1 将机器学习方法与项目相匹配"
        }
    },
    {
        "translation": {
            "en": "It also uses post-pruning to help with overfitting.",
            "zh": "它还使用后修剪来帮助解决过拟合问题。"
        }
    },
    {
        "translation": {
            "en": "Although this algorithm works quite well as presented, it assumes categorical features with no missing values and clean data.",
            "zh": "尽管此算法的工作效果很好，但它假定了没有缺失值和干净数据的分类特征。"
        }
    },
    {
        "translation": {
            "en": "(a)–(d) Different linkage methods that can be used to compare the distances between clusters in agglomerative hierarchical clustering. (Arrows for only some indicative distances are shown in the average linkage diagram (d).)",
            "zh": "（a）–（d） 可用于比较集聚分层聚类中聚类之间距离的不同链接方法。（平均连杆图 （d） 中仅显示一些指示距离的箭头。"
        }
    },
    {
        "translation": {
            "en": "Both features follow a broadly exponential distribution, however, which means that the methods described for setting the thresholds of the clamp will not work especially well (both methods work best for normally distributed data).",
            "zh": "然而，这两种特征都遵循广泛的指数分布，这意味着所描述的用于设置钳位阈值的方法不会特别有效（这两种方法都适用于正态分布数据）。"
        }
    },
    {
        "translation": {
            "en": "The actions that the car can take are to (1) maintain its current speed, (2) increase its speed (move up one level in the speed categories stationary, slow, and fast), (3) decrease its speed (move down one level in the speed categories), (4) move to the left, and (5) move to the right.",
            "zh": "汽车可以采取的行动是 （1） 保持其当前速度，（2） 提高速度（在静止、慢速和快速速度类别中上升一级），（3） 降低速度（在速度类别中向下移动一级），（4） 向左移动，以及 （5） 向右移动。"
        }
    },
    {
        "translation": {
            "en": "9.8   Surfaces generated by calculating (a) the arithmetic mean and (b) the harmonic mean of all combinations of features A and B that range from 0 to 100.",
            "zh": "9.8 通过计算 （a） 0 到 100 范围内的所有要素 A 和 B 组合的算术平均值和 （b） 谐波平均值生成的曲面。"
        }
    },
    {
        "translation": {
            "en": "In the simplest case, this might be calculated by subtracting the activation of each neuron in the output layer from the target output specified in the dataset.",
            "zh": "在最简单的情况下，这可以通过从数据集中指定的目标输出中减去输出层中每个神经元的激活来计算。"
        }
    },
    {
        "translation": {
            "en": "Although, in our example, increasing the set of neighbors from 1 to 3 removed the noise issue, k = 3 does not work for every dataset.",
            "zh": "尽管在我们的示例中，将邻居集从 1 增加到 3 消除了噪声问题，但 k = 3 并不适用于每个数据集。"
        }
    },
    {
        "translation": {
            "en": "These features are strongly negatively covariant.",
            "zh": "这些特征具有很强的负协变性。"
        }
    },
    {
        "translation": {
            "en": "normalized mutual information, 611",
            "zh": "规范化互信息，611"
        }
    },
    {
        "translation": {
            "en": "Table 5.11",
            "zh": "表 5.11"
        }
    },
    {
        "translation": {
            "en": "8. Full details of the Galaxy Zoo project and the data released by it are described in Lintott et al. (2008, 2011). The Galaxy Zoo (www.galaxyzoo.org) project referred to in this example is Galaxy Zoo I.",
            "zh": "8. Lintott et al. （2008， 2011） 描述了银河动物园项目及其发布的数据的全部细节。此示例中提到的 Galaxy Zoo （www.galaxyzoo.org） 项目是 Galaxy Zoo I。"
        }
    },
    {
        "translation": {
            "en": "In this extended context, an experiment involves rolling the two dice, and the sample space defines the set of all possible outcomes for this experiment (see Figure B.1[757]).",
            "zh": "在这个扩展的上下文中，一个实验涉及掷两个骰子，样本空间定义了该实验的所有可能结果的集合（见图B.1[757]）。"
        }
    },
    {
        "translation": {
            "en": "Hubble, E. 1936. The realm of the nebulæ. Yale University Press.",
            "zh": "哈勃，E. 1936 年。星云的领域。耶鲁大学出版社。"
        }
    },
    {
        "translation": {
            "en": "Splitting 7 creates two new partitions (10 and 11).",
            "zh": "拆分 7 会创建两个新分区（10 和 11）。"
        }
    },
    {
        "translation": {
            "en": "If this is the case, then the error should be corrected, and the ABT should be regenerated.",
            "zh": "如果是这种情况，则应纠正错误，并重新生成 ABT。"
        }
    },
    {
        "translation": {
            "en": "Table 4.10",
            "zh": "表 4.10"
        }
    },
    {
        "translation": {
            "en": "MacKay, David J. C. 2003. Information theory, inference and learning algorithms. Cambridge University Press.",
            "zh": "麦凯，大卫 JC 2003 年。信息论、推理和学习算法。剑桥大学出版社。"
        }
    },
    {
        "translation": {
            "en": "All these courses include Chapter 1 (Machine Learning for Predictive Data Analytics) and Chapter 14 (The Art of Machine Learning for Predictive Data Analytics).",
            "zh": "所有这些课程都包括第 1 章（预测数据分析的机器学习）和第 14 章（预测数据分析的机器学习艺术）。"
        }
    },
    {
        "translation": {
            "en": "where the slope of the line is 0.62 and the y-intercept is 6.47.",
            "zh": "其中，直线的斜率为 0.62，y 截距为 6.47。"
        }
    },
    {
        "translation": {
            "en": "0.50",
            "zh": "0.50"
        }
    },
    {
        "translation": {
            "en": "Also, as Figure 8.10 illustrates, as layers are added to a network, neurons in subsequent layers are able to use the representations learned by the preceding layer as building blocks to construct more complex functions.",
            "zh": "此外，如图 8.10 所示，随着层被添加到网络中，后续层中的神经元能够使用前一层学习的表示作为构建块来构建更复杂的功能。"
        }
    },
    {
        "translation": {
            "en": "So far we have discussed and used the Minkowski-based Euclidean and Manhattan distance metrics to compute the similarity between instances in a dataset. There are, however, many other ways in which the similarity between instances can be measured. In this section we introduce some alternative measures of similarity and discuss when it is appropriate to use them. Any of these measures of similarity can simply replace the Euclidean measure we used in our demonstrations of the nearest neighbor algorithm.",
            "zh": "到目前为止，我们已经讨论并使用基于闵可夫斯基的欧几里得和曼哈顿距离度量来计算数据集中实例之间的相似性。然而，还有许多其他方法可以衡量实例之间的相似性。在本节中，我们将介绍一些替代的相似度量，并讨论何时适合使用它们。这些相似度量中的任何一个都可以简单地替换我们在演示最近邻算法时使用的欧几里得度量。"
        }
    },
    {
        "translation": {
            "en": "This type of probability, where we take one or more events to already hold, is known as a posterior probability, because it is calculated after other events have happened.",
            "zh": "这种类型的概率，即我们假设一个或多个事件已经成立，被称为后验概率，因为它是在其他事件发生后计算的。"
        }
    },
    {
        "translation": {
            "en": "(a) What value will this network output?",
            "zh": "（甲）这个网络能输出什么价值？"
        }
    },
    {
        "translation": {
            "en": "Kelleher, John D., and Simon Dobnik. 2017. What is not where: The challenge of integrating spatial representations into deep learning architectures. In Proceedings of the conference on logic and machine learning in natural language (LaML 17). Vol. 1 of Clasp papers in computational linguistics, 41–52.",
            "zh": "凯莱赫、约翰 D. 和西蒙·多布尼克。2017. What is not where：将空间表示集成到深度学习架构中的挑战。在自然语言逻辑和机器学习会议论文集 （LaML 17） 中。计算语言学 Clasp 论文第 1 卷，第 41-52 页。"
        }
    },
    {
        "translation": {
            "en": "This is an important detail of model deployment that is sometimes overlooked, which can lead to strange model performance.",
            "zh": "这是模型部署的一个重要细节，有时会被忽视，这可能会导致奇怪的模型性能。"
        }
    },
    {
        "translation": {
            "en": "CPI, 294",
            "zh": "消费者物价指数， 294"
        }
    },
    {
        "translation": {
            "en": "It would also be necessary to be able to connect these claims back to the policies to which they belong and to the application details provided when the member first applied.",
            "zh": "还必须能够将这些索赔与它们所属的保单以及成员首次申请时提供的申请详细信息联系起来。"
        }
    },
    {
        "translation": {
            "en": "The performance measures used for classification problems described in Chapter 9[533] can be used for this—for example, the F1 measure is commonly used.",
            "zh": "第 9 章[533] 中描述的用于分类问题的性能度量可用于此目的，例如，通常使用 F1 度量。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.18",
            "zh": "图 8.18"
        }
    },
    {
        "translation": {
            "en": "-0.6600",
            "zh": "-0.6600"
        }
    },
    {
        "translation": {
            "en": "1.81°C",
            "zh": "1.81°摄氏度"
        }
    },
    {
        "translation": {
            "en": "There are other, more complex approaches to imputation. For example, we can actually build a predictive model that estimates a replacement for a missing value based on the feature values that are present in a dataset for a given instance. We recommend, however, using simple approaches first and turning to more complex ones only if required.",
            "zh": "还有其他更复杂的归因方法。例如，我们实际上可以构建一个预测模型，该模型根据给定实例的数据集中存在的特征值来估计缺失值的替换值。但是，我们建议首先使用简单的方法，只有在需要时才使用更复杂的方法。"
        }
    },
    {
        "translation": {
            "en": "This model can be trained using gradient descent to find the optimal decision boundary between the two different types of images.",
            "zh": "可以使用梯度下降来训练该模型，以找到两种不同类型的图像之间的最佳决策边界。"
        }
    },
    {
        "translation": {
            "en": "(a) Using the support vector ⟨d[1], d[2]⟩ and the query instance ⟨q[1], q[2]⟩ as examples, show that applying a polynomial kernel with p = 2, kernel(d,q) = (d · q + 1)2, is equivalent to calculating the dot product of the support vector and query instance after applying the following set of basis functions:",
            "zh": "（a） 以支持向量 ⟨d[1]、d[2]⟩ 和查询实例 ⟨q[1]， q[2]⟩为例，表明应用 p = 2， kernel（d，q） = （d · q + 1）2 的多项式核，等价于应用以下一组基函数后计算支持向量和查询实例的点积："
        }
    },
    {
        "translation": {
            "en": "At Line 14[666] the agent selects the first action25 using the ε-greedy policy.",
            "zh": "在第 14 行[666]，代理使用ε贪婪策略选择第一个操作25。"
        }
    },
    {
        "translation": {
            "en": "This progress comes at a cost, however, as all this data must be labeled, tagged, and cataloged.",
            "zh": "然而，这一进展是有代价的，因为所有这些数据都必须进行标记、标记和编目。"
        }
    },
    {
        "translation": {
            "en": "The bias term is also updated in the same way that any other weight would be updated.",
            "zh": "偏差项的更新方式也与任何其他权重的更新方式相同。"
        }
    },
    {
        "translation": {
            "en": "11. In Chapter 7[311] we discussed dropping the minus sign from the front of −d[j]; compare Equation (7.15)[326] with Equation (7.16)[327].",
            "zh": "11. 在第 7 章[311]中，我们讨论了从 −d[j] 前面去掉减号;比较等式（7.15）[326]和等式（7.16）[327]。"
        }
    },
    {
        "translation": {
            "en": "2.1   The basic structure of an analytics base table—descriptive features and a target feature.",
            "zh": "2.1 分析基表的基本结构 — 描述性特征和目标特征。"
        }
    },
    {
        "translation": {
            "en": "To try to capture the HANDSET INFORMATION domain concept, Ross designed three descriptive features:",
            "zh": "为了尝试捕捉HANDSET INFORMATION领域的概念，Ross设计了三个描述性特征："
        }
    },
    {
        "translation": {
            "en": "(a) The k-d tree generated for the dataset in Table 5.4[191] after the initial split using the SPEED feature with a threshold of 4.5; (b) the partitioning of the feature space by the k-d tree in (a); (c) the k-d tree after the dataset at the left child of the root has been split using the AGILITY feature with a threshold of 5.5; and (d) the partitioning of the feature space by the k-d tree in (c).",
            "zh": "（a） 使用阈值为4.5的SPEED特征进行初始拆分后，为表5.4[191]中的数据集生成的k-d树;（b）在（a）中用k-d树对特征空间进行划分;（c） 使用阈值为 5.5 的敏捷特征拆分根左侧子项数据集后的 k-d 树;（d）在（c）中用k-d树对特征空间进行分区。"
        }
    },
    {
        "translation": {
            "en": "For a detailed discussion of the issues associated with evaluating models for categorical prediction problems (and model evaluation in general), Japkowicz and Shah (2011) is excellent.",
            "zh": "对于与评估分类预测问题模型（以及一般模型评估）相关的问题的详细讨论，Japkowicz 和 Shah （2011） 非常好。"
        }
    },
    {
        "translation": {
            "en": "ill-posed problem, 7, 10, 19, 21, 22, 145",
            "zh": "病态问题， 7， 10， 19， 21， 22， 145"
        }
    },
    {
        "translation": {
            "en": "The median of a set of values can be calculated by ordering the values from lowest to highest and selecting the middle value.",
            "zh": "一组值的中位数可以通过将值从低到高排序并选择中间值来计算。"
        }
    },
    {
        "translation": {
            "en": "Given that the decision boundary is generated by aggregating the Voronoi regions, it is not surprising that the query is on the side of the decision boundary representing the yes target level.",
            "zh": "鉴于决策边界是通过聚合 Voronoi 区域生成的，因此查询位于表示“是”目标级别的决策边界一侧也就不足为奇了。"
        }
    },
    {
        "translation": {
            "en": "6.5   Summary",
            "zh": "6.5 小结"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Reinforcement Learning",
            "zh": "强化学习的符号约定"
        }
    },
    {
        "translation": {
            "en": "(2017) for a computer architecture perspective on deep learning.",
            "zh": "（2017） 从计算机体系结构的角度来看深度学习。"
        }
    },
    {
        "translation": {
            "en": "Understanding how a neural network can be represented and implemented as a sequence of matrix multiplications has important implications in terms of training time speedups.",
            "zh": "了解如何将神经网络表示和实现为矩阵乘法序列，在训练时间加速方面具有重要意义。"
        }
    },
    {
        "translation": {
            "en": "“Live. Die. Repeat.”",
            "zh": "“活着。死。重复。"
        }
    },
    {
        "translation": {
            "en": "In Figures 10.4(a)[606] and 10.4(b)[606], a very different seed from that shown in Figure 10.3(b)[602] is shown to lead to the same clustering found previously (Figure 10.3(f)[602]), whereas in Figures 10.4(a)[606] to 10.4(h)[606], seeds that lead to very different clusterings are shown.",
            "zh": "在图10.4（a）[606]和10.4（b）[606]中，与图10.3（b）[602]所示的种子截然不同的种子被显示为导致先前发现的相同簇（图10.3（f）[602]），而在图10.4（a）[606]至10.4（h）[606]中，显示了导致非常不同的簇的种子。"
        }
    },
    {
        "translation": {
            "en": "7.3   Details of the first two iterations when the gradient descent algorithm is used to train a multivariable linear regression model for the office rentals dataset (using only the continuous descriptive features).",
            "zh": "7.3 当使用梯度下降算法训练办公室租赁数据集的多变量线性回归模型（仅使用连续描述性特征）时，前两次迭代的详细信息。"
        }
    },
    {
        "translation": {
            "en": "This plot shows that the reduction in the error achieved by each weight update (one per epoch) is initially quite small.",
            "zh": "该图显示，每次权重更新（每个周期一次）实现的误差减少最初非常小。"
        }
    },
    {
        "translation": {
            "en": "domain representation, 732",
            "zh": "域表示，732"
        }
    },
    {
        "translation": {
            "en": "This matrix contains two neurons that are fully connected to the sub-sampling layer; that is, each neuron in this layer receives inputs from all the neurons in the sub-sampling layer.",
            "zh": "该矩阵包含两个完全连接到子采样层的神经元;也就是说，该层中的每个神经元都接收来自子采样层中所有神经元的输入。"
        }
    },
    {
        "translation": {
            "en": "In Table 0.1 we have listed a number of suggested course plans targeting different contexts.",
            "zh": "在表0.1中，我们列出了一些针对不同情况的建议课程计划。"
        }
    },
    {
        "translation": {
            "en": "The AlexNet architecture included five convolutional layers, followed by three fully connected (dense) layers.",
            "zh": "AlexNet 架构包括五个卷积层，然后是三个完全连接（密集）层。"
        }
    },
    {
        "translation": {
            "en": "The vector of activations for a layer of neurons is denoted by a(k) where k identifies the layer.",
            "zh": "神经元层的激活向量用 a（k） 表示，其中 k 标识该层。"
        }
    },
    {
        "translation": {
            "en": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.",
            "zh": "保留所有权利。未经出版商书面许可，不得以任何电子或机械方式（包括影印、录音或信息存储和检索）以任何形式复制本书的任何部分。"
        }
    },
    {
        "translation": {
            "en": "(a) Initially the analyst uses a simple average of the target variables for the k nearest neighbors in order to make a new prediction. After experimenting with values for k in the range 0−10, it occurs to the analyst that they might get very good results if they set k to the total number of instances in the training set. Do you think that the analyst is likely to get good results using this value for k?",
            "zh": "（a） 最初，分析人员对k个最近邻使用目标变量的简单平均值，以便做出新的预测。在对 0−10 范围内的 k 值进行试验后，分析师会想到，如果他们将 k 设置为训练集中的实例总数，他们可能会得到非常好的结果。您认为分析师使用此值 k 可能会获得良好的结果吗？"
        }
    },
    {
        "translation": {
            "en": "subspace sampling, 159",
            "zh": "子空间采样，159"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(a)[60] shows a histogram exhibiting a uniform distribution. A uniform distribution indicates that a feature is equally likely to take a value in any of the ranges present. Sometimes a uniform distribution is indicative of a descriptive feature that contains an ID rather than a measure of something more interesting.",
            "zh": "图3.2（a）[60]显示了一个呈现均匀分布的直方图。均匀分布表示要素在存在的任何范围内取值的可能性相同。有时，均匀分布表示包含 ID 的描述性特征，而不是对更有趣的事物的度量。"
        }
    },
    {
        "translation": {
            "en": "4.3 Standard Approach: The ID3 Algorithm",
            "zh": "4.3 标准方法：ID3 算法"
        }
    },
    {
        "translation": {
            "en": "Bayes’ Theorem4 is so elegant and intuitive that it can be stated in one sentence of plain English:",
            "zh": "贝叶斯定理4是如此优雅和直观，可以用一句通俗易懂的英语来表述："
        }
    },
    {
        "translation": {
            "en": "In mini-batch gradient descent, the dataset is split into multiple subsets called mini-batches or batches.15",
            "zh": "在小批量梯度下降中，数据集被拆分为多个子集，称为小批量或批次15。"
        }
    },
    {
        "translation": {
            "en": "Line 9[420] is the matrix multiplication of the layer’s weights by the activations from the preceding layer.",
            "zh": "第 9 行[420] 是层权重乘以前一层激活的矩阵。"
        }
    },
    {
        "translation": {
            "en": "depth of a filter, 492",
            "zh": "过滤器深度，492"
        }
    },
    {
        "translation": {
            "en": "Intuitively, this theorem makes sense because each algorithm encodes a distinct set of assumptions (i.e., the inductive bias of the learning algorithm), and a set of assumptions that are appropriate in one domain may not be appropriate in another domain.",
            "zh": "直观地说，这个定理是有道理的，因为每个算法都编码了一组不同的假设（即学习算法的归纳偏差），而一组在一个领域中适用的假设可能不适合在另一个领域中适用。"
        }
    },
    {
        "translation": {
            "en": "In fact, as shown in Figure 7.10(b)[340], we can draw a straight line across the scatter plot that perfectly separates the good generators from the faulty ones.",
            "zh": "事实上，如图 7.10（b）[340] 所示，我们可以在散点图上画一条直线，完美地将好的发电机和有故障的发电机区分开来。"
        }
    },
    {
        "translation": {
            "en": "So, the conditional probability of a node xi in a graph with n nodes can be defined as",
            "zh": "因此，在具有 n 个节点的图中，节点 习 的条件概率可以定义为"
        }
    },
    {
        "translation": {
            "en": "So, when we choose to use one machine learning algorithm instead of another, we are, in effect, choosing to use one model selection criterion instead of another.",
            "zh": "因此，当我们选择使用一种机器学习算法而不是另一种机器学习算法时，我们实际上是在选择使用一种模型选择标准而不是另一种模型选择标准。"
        }
    },
    {
        "translation": {
            "en": "The partial derivatives of the error surface with respect to w[0] and w[1] measure the slope of the error surface at the point w[0] and w[1].",
            "zh": "误差曲面相对于 w[0] 和 w[1] 的偏导数测量误差曲面在点 w[0] 和 w[1] 处的斜率。"
        }
    },
    {
        "translation": {
            "en": "Using the 3-level target feature as her initial focus, Jocelyn began to look at the different descriptive features in the data downloaded from the SDSS repository that might be useful in building a model to predict galaxy morphology.",
            "zh": "Jocelyn 以 3 级目标特征为初始关注点，开始研究从 SDSS 存储库下载的数据中的不同描述性特征，这些特征可能有助于构建预测星系形态的模型。"
        }
    },
    {
        "translation": {
            "en": "Similar to the input gate, the output gate has two paths of processing, one involving a sigmoid layer and the other involving a tanh layer.",
            "zh": "与输入门类似，输出门有两条处理路径，一条涉及 S 形图层，另一条涉及 tanh 层。"
        }
    },
    {
        "translation": {
            "en": "GENDER: The customer’s gender (male or female)",
            "zh": "性别：客户的性别（男性或女性）"
        }
    },
    {
        "translation": {
            "en": "Frank, Eibe. 2000. Pruning decision trees and lists. PhD dissertation, Department of Computer Science, University of Waikato.",
            "zh": "弗兰克，艾贝。2000. 修剪决策树和列表。怀卡托大学计算机科学系博士论文。"
        }
    },
    {
        "translation": {
            "en": "A more realistic example of the complexity and scale of a modern convolutional network is the AlexNet network (Krizhevsky et al., 2012).",
            "zh": "现代卷积网络的复杂性和规模的一个更现实的例子是AlexNet网络（Krizhevsky等人，2012）。"
        }
    },
    {
        "translation": {
            "en": "This version of the algorithm is for mini-batch training, and so we know that we will need to sum the error gradients for each weight across the examples in the mini-batch.",
            "zh": "此版本的算法用于小批量训练，因此我们知道我们需要对小批量中示例中每个权重的误差梯度求和。"
        }
    },
    {
        "translation": {
            "en": "For example, how can we judge whether a drug dosage prediction model that has a root mean squared error of 1.38mg is actually making accurate predictions without also understanding the domain of drug dosage prediction.",
            "zh": "例如，我们如何判断一个均方根误差为1.38mg的药物剂量预测模型是否真的在不了解药物剂量预测领域的情况下做出准确的预测。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.22(f)[167] shows the model output after 20 iterations of model training have been completed.",
            "zh": "图 4.22（f）[167] 显示了完成 20 次模型训练迭代后的模型输出。"
        }
    },
    {
        "translation": {
            "en": "standard deviation, 54, 748",
            "zh": "标准差， 54， 748"
        }
    },
    {
        "translation": {
            "en": "Also assuming that each weight wi is independent of the corresponding input di, then variance of each of these products is given:35",
            "zh": "此外，假设每个权重 wi 与相应的输入 di 无关，则给出每个乘积的方差：35"
        }
    },
    {
        "translation": {
            "en": "5. We use Q here to be consistent with the framing of Q-learning later in this chapter.",
            "zh": "5. 我们在这里使用 Q 是为了与本章后面的 Q 学习框架保持一致。"
        }
    },
    {
        "translation": {
            "en": "In this chapter we have not covered artificial neural networks, another popular error-based approach to learning that is a very active research area.",
            "zh": "在本章中，我们没有介绍人工神经网络，这是另一种流行的基于错误的学习方法，是一个非常活跃的研究领域。"
        }
    },
    {
        "translation": {
            "en": "The lesson to be learned here is that before causation is concluded based on a strong correlation between two features, in-depth studies involving domain experts are required—correlation alone is just not enough.",
            "zh": "这里要吸取的教训是，在基于两个特征之间的强相关性得出因果关系之前，需要涉及领域专家的深入研究——仅靠相关性是不够的。"
        }
    },
    {
        "translation": {
            "en": "The margin of error takes into account the fact that this is just a sample from a much larger population.5 All the other polls in the table were conducted with similar-sized samples.",
            "zh": "5 表中的所有其他民意调查都是用类似大小的样本进行的。"
        }
    },
    {
        "translation": {
            "en": "Each day is described in terms of six descriptive features that are generated from different sensors at the plant.",
            "zh": "每一天都用工厂不同传感器生成的六个描述性特征来描述。"
        }
    },
    {
        "translation": {
            "en": "(b) Based on the evaluation measures calculated, which model do you think is performing better for this dataset?",
            "zh": "（b） 根据计算出的评估措施，您认为哪个模型在该数据集中表现更好？"
        }
    },
    {
        "translation": {
            "en": "5.19   Feature subset space for a dataset with three features X, Y, and Z.",
            "zh": "5.19 具有三个特征 X、Y 和 Z 的数据集的特征子集空间。"
        }
    },
    {
        "translation": {
            "en": "This defines one point on the error surface.",
            "zh": "这在错误曲面上定义了一个点。"
        }
    },
    {
        "translation": {
            "en": "Dietterich, Thomas G. 2000. Ensemble methods in machine learning. In International workshop on multiple classifier systems, 1–15. Springer.",
            "zh": "迪特里希，托马斯 G. 2000 年。机器学习中的集成方法。在多分类器系统国际研讨会上，1-15。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "Recall that the update applied to a weight wi,k is always scaled by the ak term (both in the stochastic setting, Equation (8.28)[415], and the batch setting, Equation (8.29)[416]).",
            "zh": "回想一下，应用于权重 wi，k 的更新始终按 ak 项缩放（在随机设置中，方程 （8.28）[415] 和批处理设置，方程 （8.29）[416]）。"
        }
    },
    {
        "translation": {
            "en": "Using Equation (B.4)[762], we can provide a second definition for the probability of a joint event, which is known as the product rule:",
            "zh": "使用方程（B.4）[762]，我们可以为联合事件的概率提供第二个定义，即乘积规则："
        }
    },
    {
        "translation": {
            "en": "6.10   A depiction of the Markov blanket of a node. The gray nodes define the Markov blanket of the black node. The black node is conditionally independent of the white nodes given the state of the gray nodes.",
            "zh": "6.10 节点马尔可夫毯的描述。灰色节点定义黑色节点的马尔可夫毯。给定灰色节点的状态，黑色节点有条件地独立于白色节点。"
        }
    },
    {
        "translation": {
            "en": "If we are using stochastic gradient descent, in which we update the weights after each example has been presented to the network, then to update a weight in the network we first calculate a ∂ℰ/∂wi,k term for the weight similarly to the calculations shown in Table 8.6[431] for d2 and then plug the ∂ℰ/∂wi,k value for the weight into Equation (8.28)[415].",
            "zh": "如果我们使用随机梯度下降，在将每个示例呈现给网络后更新权重，那么要更新网络中的权重，我们首先计算权重的 ∂E/∂wi，k 项，类似于表 8.6[431] 中所示的 d2 的计算，然后插入 ∂E/∂wi，方程（8.28）[415]中权重的k值。"
        }
    },
    {
        "translation": {
            "en": "Judea Pearl is recognized as one of the key pioneers in developing the use of Bayesian networks in the field of artificial intelligence, and his books (Pearl, 1988, 2000) are accessible and provide good introductions to the theory and methods of Bayesian networks, as well as the more general field of graphical models.",
            "zh": "Judea Pearl被公认为在人工智能领域开发贝叶斯网络使用的主要先驱之一，他的著作（Pearl，1988,2000）易于访问，并很好地介绍了贝叶斯网络的理论和方法，以及更一般的图形模型领域。"
        }
    },
    {
        "translation": {
            "en": "Following this strategy, for a fully connected three-layer ReLU network with 100 inputs, 80 neurons in the first hidden layer, 50 neurons in the second hidden layer, and 5 neurons in the output layer, the weight matrix for each layer would be initialized as shown in Equation (8.64)[461], where the notation W(k) ∽ (μ,σ) indicates that the values in the weight matrix for layer k should be sampled from a normal distribution with mean μ and standard deviation σ.",
            "zh": "按照这种策略，对于具有 100 个输入、第一隐藏层有 80 个神经元、第二隐藏层有 50 个神经元、输出层有 5 个神经元的全连接三层 ReLU 网络，每层的权重矩阵将初始化，如公式 （8.64）[461] 所示，其中符号 W（k） ∽ （μ，σ） 表示层 k 的权重矩阵中的值应从均值μ和标准差σ的正态分布中采样。"
        }
    },
    {
        "translation": {
            "en": "5. The terms sensitivity and specificity are often used for true positive rate and true negative rate.",
            "zh": "5. 术语敏感性和特异性通常用于真阳性率和真阴性率。"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for each of the query instances shown in the following table.",
            "zh": "使用此模型对下表中显示的每个查询实例进行预测。"
        }
    },
    {
        "translation": {
            "en": "The location of the query customer in the feature space is indicated by the ?.",
            "zh": "查询客户在功能空间中的位置由 ？."
        }
    },
    {
        "translation": {
            "en": "It is only in very rare scenarios that we can accurately fill in a profit matrix for a prediction problem.",
            "zh": "只有在极少数情况下，我们才能准确地填充预测问题的利润矩阵。"
        }
    },
    {
        "translation": {
            "en": "11   Beyond Prediction: Reinforcement Learning",
            "zh": "11 超越预测：强化学习"
        }
    },
    {
        "translation": {
            "en": "Figure 7.1",
            "zh": "图 7.1"
        }
    },
    {
        "translation": {
            "en": "The arrows connecting the neurons in the network indicate the flow of information through the network.",
            "zh": "连接网络中神经元的箭头表示通过网络的信息流。"
        }
    },
    {
        "translation": {
            "en": "However, the particular choice of which variant of ReLU to use is network- and task-dependent, and, similarly to most hyper-parameters, needs to be decided upon through experimentation.",
            "zh": "然而，使用哪种 ReLU 变体的特定选择取决于网络和任务，并且与大多数超参数类似，需要通过实验来决定。"
        }
    },
    {
        "translation": {
            "en": "We can introduce a preference for decision trees that use fewer tests—in other words, trees that are on average shallower.2 This is the primary inductive bias that a machine learning algorithm taking an information-based approach encodes.",
            "zh": "我们可以引入对使用较少测试的决策树的偏好，换句话说，平均而言，树的优先级较低.2 这是采用基于信息的方法的机器学习算法编码的主要归纳偏差。"
        }
    },
    {
        "translation": {
            "en": "Spectrography also allows measurement of redshift, which is used to determine the distance of night sky objects from the viewer.",
            "zh": "光谱学还可以测量红移，红移用于确定夜空物体与观察者的距离。"
        }
    },
    {
        "translation": {
            "en": "In reduced error pruning, a decision tree is built to completion and then the tree is searched in an iterative, bottom-up, left-to-right manner for subtrees that can be pruned.",
            "zh": "在减少误差修剪中，构建决策树直至完成，然后以迭代、自下而上、从左到右的方式搜索该树以查找可修剪的子树。"
        }
    },
    {
        "translation": {
            "en": "When we use a PDF to represent the probability distribution of a descriptive feature in a naive Bayes model, however, we don’t actually need to calculate exact probabilities.",
            "zh": "然而，当我们使用 PDF 来表示朴素贝叶斯模型中描述性特征的概率分布时，我们实际上并不需要计算精确的概率。"
        }
    },
    {
        "translation": {
            "en": "0.3729",
            "zh": "0.3729"
        }
    },
    {
        "translation": {
            "en": "13. One consequence of this, however, is that a naive Bayes model is not a good approach for predicting a continuous target, because errors in calculating posterior probabilities do directly affect the accuracy of the model. This is the only modeling approach covered in this book for which we will not present a way to predict both continuous and categorical target features.",
            "zh": "13. 然而，这样做的一个后果是，朴素贝叶斯模型不是预测连续目标的好方法，因为计算后验概率时的错误确实直接影响模型的准确性。这是本书中介绍的唯一建模方法，我们不会介绍一种预测连续和分类目标特征的方法。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that when we train a decision tree from data, we do not assume a fixed set of parameters prior to training that define the tree.",
            "zh": "这样做的原因是，当我们从数据训练决策树时，我们不会在训练之前假设一组固定的参数来定义决策树。"
        }
    },
    {
        "translation": {
            "en": "The architecture of an auto-encoder network made up of an encoder and a decoder connected by a bottleneck layer.",
            "zh": "由编码器和解码器组成的自动编码器网络的体系结构，通过瓶颈层连接。"
        }
    },
    {
        "translation": {
            "en": "The illustration in Figure 8.33[484] assumes that the neurons are using a two-dimensional 3-by-3 (height by width) filter.",
            "zh": "图 8.33[484] 中的插图假设神经元使用二维 3×3（高宽）滤波器。"
        }
    },
    {
        "translation": {
            "en": "The basis of most of these approaches is measuring how well the distributions of scores produced by the model for different target levels are separated.",
            "zh": "大多数这些方法的基础是测量模型为不同目标水平生成的分数分布的分离程度。"
        }
    },
    {
        "translation": {
            "en": "The vector v, created on Line 7[420], is the vector of bias inputs, and it is as wide as the number of neurons in the layer (we use the subscript m here as shorthand for the number of neurons in the layer).",
            "zh": "在第 7 行[420]上创建的向量 v 是偏置输入的向量，它与层中的神经元数量一样宽（我们在这里使用下标 m 作为层中神经元数量的简写）。"
        }
    },
    {
        "translation": {
            "en": "He did explain, however, that Jocelyn’s suggestion of using position information was very unlikely to be useful, so that was removed from the set of domain concepts.",
            "zh": "然而，他确实解释说，Jocelyn 关于使用位置信息的建议不太可能有用，因此将其从领域概念集中删除。"
        }
    },
    {
        "translation": {
            "en": "next-best-offer model, 37",
            "zh": "次优报价模型，37"
        }
    },
    {
        "translation": {
            "en": "This implementation works on a layer-by-layer basis.",
            "zh": "此实现是逐层工作的。"
        }
    },
    {
        "translation": {
            "en": "A wrapper evaluates a feature subset in terms of the potential performance of the models that can be induced using that subset.",
            "zh": "包装器根据可以使用该子集诱导的模型的潜在性能来评估特征子集。"
        }
    },
    {
        "translation": {
            "en": "Domain concepts cover the different aspects of a scenario that are likely to be important in the modeling task at hand.",
            "zh": "领域概念涵盖了方案的不同方面，这些方面在手头的建模任务中可能很重要。"
        }
    },
    {
        "translation": {
            "en": "Through conversations with Edwin, Jocelyn became aware of a parallel project to the SDSS that offered an intriguing solution to her problem.",
            "zh": "通过与 Edwin 的对话，Jocelyn 意识到一个与 SDSS 平行的项目为她的问题提供了一个有趣的解决方案。"
        }
    },
    {
        "translation": {
            "en": "Feature map 3 and Feature map 4 contain the activations of the neurons in each of these two layers.",
            "zh": "特征图 3 和特征图 4 包含这两层中每一层中神经元的激活。"
        }
    },
    {
        "translation": {
            "en": "1. In a fully connected network, all the neurons in one layer receive activations from all the neurons in the preceding layer; and, because all the neurons in a layer receive the same vector of activations as inputs, we can calculate the weighted sum calculations for all of these neurons using a single vector by matrix multiplication.",
            "zh": "1.在全连接网络中，一层中的所有神经元都接收来自前一层中所有神经元的激活;而且，由于一层中的所有神经元都接收到与输入相同的激活向量，因此我们可以使用矩阵乘法的单个向量来计算所有这些神经元的加权和计算。"
        }
    },
    {
        "translation": {
            "en": "Spreading out the weight updates means that the weight will in general remain smaller.",
            "zh": "分散重量更新意味着重量通常将保持较小。"
        }
    },
    {
        "translation": {
            "en": "It is likely that the data required for this solution would stretch back over many years, as the time between making a policy application and making a claim could cover decades.",
            "zh": "该解决方案所需的数据可能会追溯到很多年前，因为从提出保单申请到提出索赔之间的时间可能长达数十年。"
        }
    },
    {
        "translation": {
            "en": "From this plot, it is clear that there is a strong linear relationship between these two features: as SIZE increases so does RENTAL PRICE by a similar amount.",
            "zh": "从这张图中可以清楚地看出，这两个特征之间存在很强的线性关系：随着 SIZE 的增加，RENTAL PRICE 也会增加相似的量。"
        }
    },
    {
        "translation": {
            "en": "4.15   (a) A set of instances on a continuous number line; (b), (c), and (d) depict some of the potential groupings that could be applied to these instances.",
            "zh": "4.15 （a） 连续数线上的一组实例;（b）、（c）和（d）描述了可以应用于这些实例的一些潜在分组。"
        }
    },
    {
        "translation": {
            "en": "9. In this section we have primarily considered the population we are sampling from to be a population of people, but sampling bias can also arise for any population of predictive subjects, be they insurance policies, holidays, cars, or anything else.",
            "zh": "9. 在本节中，我们主要将我们从中抽样的人群视为人群，但对于任何预测对象人群，无论是保险单、假期、汽车还是其他任何东西，都可能出现抽样偏差。"
        }
    },
    {
        "translation": {
            "en": "24. Note that as with the worked example, to keep the number of decimal points required to represent the calculations through this forward pass manageable, the outputs of the activation function (in this instance the rectified linear function) for each layer have been rounded to four decimal places, and these rounded activations were the activations used in the subsequent calculations.",
            "zh": "24. 请注意，与工作示例一样，为了保持通过此前向传递表示计算所需的小数点数可管理，每层的激活函数（在本例中为校正线性函数）的输出已四舍五入到小数点后四位，这些四舍五入的激活是后续计算中使用的激活。"
        }
    },
    {
        "translation": {
            "en": "This is due to the use of the squared term in the mean squared error calculation but can easily be addressed by using root mean squared error instead.",
            "zh": "这是由于在均方误差计算中使用了平方项，但可以通过使用均方根误差轻松解决。"
        }
    },
    {
        "translation": {
            "en": "On completion of each action the agent receives an immediate scalar reward indicating whether the outcome of the action was positive or negative and to what degree.",
            "zh": "完成每个操作后，智能体会立即收到标量奖励，指示操作的结果是积极的还是消极的，以及程度如何。"
        }
    },
    {
        "translation": {
            "en": "As new instances are added to the feature space, the size of the model’s representation of the domain increases.",
            "zh": "随着新实例添加到特征空间中，模型表示域的大小也会增加。"
        }
    },
    {
        "translation": {
            "en": "The simplest form of data visualization we can use for data exploration is the bar plot.",
            "zh": "我们可用于数据探索的最简单的数据可视化形式是条形图。"
        }
    },
    {
        "translation": {
            "en": "5. The table below shows the scores achieved by a group of students on an exam.",
            "zh": "5. 下表显示了一组学生在考试中取得的分数。"
        }
    },
    {
        "translation": {
            "en": "6.12   Two different Bayesian networks, each defining the same full joint probability distribution.",
            "zh": "6.12 两个不同的贝叶斯网络，每个网络都定义了相同的全联合概率分布。"
        }
    },
    {
        "translation": {
            "en": "One of the best-known distance metrics is Euclidean distance, which computes the length of the straight line between two points. Euclidean distance between two instances a and b in an m-dimensional feature space is defined as",
            "zh": "最著名的距离指标之一是欧几里得距离，它计算两点之间的直线长度。在 m 维特征空间中，两个实例 a 和 b 之间的欧几里得距离定义为"
        }
    },
    {
        "translation": {
            "en": "This multivariable model allows us to include all but one of the descriptive features in Table 7.2[317] in a regression model to predict office rental prices (we will see how to include the categorical ENERGY RATING in the model in Section 7.4.3[336]). The resulting multivariable regression model equation is",
            "zh": "这个多变量模型允许我们在回归模型中包括表7.2[317]中除一个描述性特征之外的所有描述性特征，以预测办公室租金价格（我们将在第7.4.3节[336]中看到如何在模型中包含分类能源评级）。得到的多变量回归模型方程为"
        }
    },
    {
        "translation": {
            "en": "In this histogram the width of each bar indicates the extent of the interval the bar represents, and the height of each bar is based on the number of instances in the dataset that have a value inside the interval.",
            "zh": "在此直方图中，每个条形的宽度表示条形所表示的区间范围，每个条形的高度基于数据集中在区间内具有值的实例数。"
        }
    },
    {
        "translation": {
            "en": "The instance nearest the decision boundary, based on perpendicular distance, is highlighted.",
            "zh": "基于垂直距离，将突出显示最接近决策边界的实例。"
        }
    },
    {
        "translation": {
            "en": "All machine learning algorithms assume that a dataset is available for training; and in Chapter 3 we explain how to design, construct, and quality check a dataset before using it to build a prediction model.",
            "zh": "所有机器学习算法都假设数据集可用于训练;在第 3 章中，我们解释了如何在使用数据集构建预测模型之前对其进行设计、构建和质量检查。"
        }
    },
    {
        "translation": {
            "en": "(b) P(HEADACHE = false)",
            "zh": "（b） P（头痛 = 假）"
        }
    },
    {
        "translation": {
            "en": "BILLAMOUNTCHANGEPCT: Derived from the raw call data, this feature captured the amount by which a customer’s bill had changed that month compared to previous month.",
            "zh": "BILLAMOUNTCHANGEPCT：此功能源自原始呼叫数据，捕获了客户当月账单与上个月相比的变化金额。"
        }
    },
    {
        "translation": {
            "en": "; NUMBER OF CLAIMS IN CLAIMANT LIFETIME: NUM.",
            "zh": ";索赔人生命周期内的索赔数量：数量。"
        }
    },
    {
        "translation": {
            "en": "Wooldridge, Michael, and Nicholas R. Jennings. 1995. Intelligent agents: Theory and practice. The Knowledge Engineering Review 10 (2): 115–152.",
            "zh": "伍尔德里奇、迈克尔和尼古拉斯 R. 詹宁斯。1995. 智能代理：理论与实践.知识工程评论10（2）：115-152。"
        }
    },
    {
        "translation": {
            "en": "First, the signs of the weights indicate whether different descriptive features have a positive or a negative impact on the prediction.",
            "zh": "首先，权重的符号表明不同的描述性特征对预测有积极影响还是消极影响。"
        }
    },
    {
        "translation": {
            "en": "The error rate resulting from predictions for the instances in the validation dataset made at the root node of each subtree is compared to the error rate resulting from predictions made at the leaves of the subtree.",
            "zh": "将验证数据集中在每个子树的根节点上进行的实例预测产生的错误率与在子树叶上进行的预测产生的错误率进行比较。"
        }
    },
    {
        "translation": {
            "en": "12.1   The set of domain concepts for the Acme Telephonica customer churn prediction problem.",
            "zh": "12.1 Acme Telephonica 客户流失预测问题的域概念集。"
        }
    },
    {
        "translation": {
            "en": "For long sequences of inputs it can become cumbersome and also computationally expensive to keep track of all the error gradients for all the different weights in the unrolled network.",
            "zh": "对于长序列的输入，跟踪展开网络中所有不同权重的所有误差梯度可能会变得很麻烦，而且计算成本也很高。"
        }
    },
    {
        "translation": {
            "en": "and for the Stick action the structure of the state transition matrix, 𝒫Stick, is",
            "zh": "对于 Stick 操作，状态转换矩阵 PStick 的结构为"
        }
    },
    {
        "translation": {
            "en": "For example, the predictions made by decision tree models are based on the subset of descriptive features tested on the path from the root of the tree to the leaf node that specifies the prediction.",
            "zh": "例如，决策树模型所做的预测基于在从树根到指定预测的叶节点的路径上测试的描述性特征子集。"
        }
    },
    {
        "translation": {
            "en": "So, the probability of actually having the disease, in spite of the positive test result, is less than 1%. This is why the doctor said the rarity of the disease was such good news. One of the important characteristics of Bayes’ Theorem is its explicit inclusion of the prior probability of an event when calculating the likelihood of that event based on evidence.6",
            "zh": "因此，尽管检测结果呈阳性，但实际患病的概率不到 1%。这就是为什么医生说这种疾病的罕见性是个好消息。贝叶斯定理的一个重要特征是，在根据证据计算事件的可能性时，它明确地包括了事件的先验概率6。"
        }
    },
    {
        "translation": {
            "en": "An experiment whose outcome we do not yet know but would like to predict is the prediction task for which we are building a model.",
            "zh": "一个我们还不知道但想要预测结果的实验是我们正在构建模型的预测任务。"
        }
    },
    {
        "translation": {
            "en": "8.4.6.2 Backpropagation through time The fact that a recurrent neural network is fundamentally an augmented feedforward network means that training a network using backpropagation is quite similar to training a normal feedforward network.",
            "zh": "8.4.6.2 随时间的反向传播 循环神经网络从根本上说是一个增强的前馈网络，这意味着使用反向传播训练网络与训练正常的前馈网络非常相似。"
        }
    },
    {
        "translation": {
            "en": "It is important for Conor to have a good meal each evening so that he is ready for work again the next day, and he is worried about getting things he doesn’t like in the hotel restaurant.",
            "zh": "对于康纳来说，每天晚上吃一顿好饭很重要，这样他就可以为第二天的工作做好准备，而且他担心在酒店餐厅里买到他不喜欢的东西。"
        }
    },
    {
        "translation": {
            "en": "The total error of the network is then the sum of these individual errors.",
            "zh": "网络的总误差就是这些单个误差的总和。"
        }
    },
    {
        "translation": {
            "en": "SHAPEUNIFORMITY: A measure of the variation in shape of cells in the tissue samples, higher values indicate more uniform shapes (1 to 10).",
            "zh": "形状均匀性：组织样本中细胞形状变化的量度，值越高表示形状越均匀（1 到 10）。"
        }
    },
    {
        "translation": {
            "en": "where LCE is the cross-entropy loss; t is the target feature represented using one-hot encoding (the target distribution over the categories); is the distribution over the categories that the model has predicted; ln is the natural logarithm function; and j is an index over both the target distribution t and the predicted distribution .",
            "zh": "其中LCE是交叉熵损失;t 是使用 one-hot 编码表示的目标特征（类别上的目标分布）;是模型预测的类别的分布情况;ln 是自然对数函数;j 是目标分布 t 和预测分布的索引。"
        }
    },
    {
        "translation": {
            "en": "As a result of this multiplication for any neuron whose activation in the forward pass was set to 0 by the multiplication with DropMask, the δ value of the neuron will also be set to 0.",
            "zh": "对于任何神经元的乘法，其前向传递中的激活通过 DropMask 的乘法设置为 0，因此神经元的δ值也将设置为 0。"
        }
    },
    {
        "translation": {
            "en": "A consequence of this is that the network has a memory over past activations (and hence past inputs that contributed to these activations).",
            "zh": "这样做的结果是，网络对过去的激活（以及导致这些激活的过去输入）具有记忆。"
        }
    },
    {
        "translation": {
            "en": "In contrast, acceleration has modest positive values when we are taking off initially and slightly larger positive values when we increase speed on reaching the highway.",
            "zh": "相比之下，当我们最初起飞时，加速度具有适度的正值，而当我们在到达高速公路时提高速度时，加速度的正值略大。"
        }
    },
    {
        "translation": {
            "en": "Taking these factors into account helps to ensure that we develop analytics solutions that are effective and fit for purpose.",
            "zh": "考虑这些因素有助于确保我们开发有效且适合目的的分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "This gives multiple box plots that offer an easy comparison of how the central tendency and variation of the continuous feature change for the different levels of the categorical feature.",
            "zh": "这给出了多个箱形图，这些箱形图提供了对连续特征的中心趋势和变化在分类特征的不同水平下如何变化的简单比较。"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of prediction models, there is always a tension between the need to fully understand the performance of the model and the need to reduce model performance to a single measure that can be used to rank models by performance.",
            "zh": "在评估预测模型的性能时，在充分了解模型性能的需求与将模型性能降低到可用于按性能对模型进行排名的单一度量之间始终存在紧张关系。"
        }
    },
    {
        "translation": {
            "en": "Clearly, large portions of the yes region are now on the wrong side of the decision boundary.",
            "zh": "显然，“是”区域的很大一部分现在都处于决策边界的错误一侧。"
        }
    },
    {
        "translation": {
            "en": "(b) Calculate the Gini index for this dataset.",
            "zh": "（b） 计算该数据集的基尼系数。"
        }
    },
    {
        "translation": {
            "en": "This is particularly attractive for problems in which automated systems are to be trained to perform a control task—for example, robotics or automated game playing.",
            "zh": "这对于需要训练自动化系统以执行控制任务的问题特别有吸引力，例如，机器人或自动游戏。"
        }
    },
    {
        "translation": {
            "en": "right skew, 59",
            "zh": "右斜，59"
        }
    },
    {
        "translation": {
            "en": "Even when using equal-frequency binning, there is still chance that the partitioning of the data will give rise to extreme conditional probabilities.",
            "zh": "即使使用等频分箱，数据的分区仍有可能产生极端的条件概率。"
        }
    },
    {
        "translation": {
            "en": "We cover artificial neural networks and deep learning in detail in Chapter 8[381].",
            "zh": "我们将在第8章[381]中详细介绍人工神经网络和深度学习。"
        }
    },
    {
        "translation": {
            "en": "Technically, if an event involves more than one feature, it can be considered to be composed of several simple events.",
            "zh": "从技术上讲，如果一个事件涉及多个特征，则可以认为它由几个简单事件组成。"
        }
    },
    {
        "translation": {
            "en": "A system was put in place in the SDSS processing pipeline to flag for manual review any galaxies given low probability predictions.",
            "zh": "在SDSS处理管道中建立了一个系统，以标记任何给定低概率预测的星系以供手动审查。"
        }
    },
    {
        "translation": {
            "en": "The customer’s occupation",
            "zh": "客户的职业"
        }
    },
    {
        "translation": {
            "en": "The requirement that networks with a single hidden layer and using smooth activation functions have very wide hidden layers is a serious shortcoming: it may result in the requirement that the network has at least one hidden unit for each input configuration that is being distinguished (Goodfellow et al., 2016).",
            "zh": "要求具有单个隐藏层并使用平滑激活函数的网络具有非常宽的隐藏层是一个严重的缺点：它可能导致要求网络对每个被区分的输入配置至少有一个隐藏单元（Goodfellow等人，2016）。"
        }
    },
    {
        "translation": {
            "en": "24,000",
            "zh": "24,000"
        }
    },
    {
        "translation": {
            "en": "The target feature, OUTCOME, is set to either default or repay.",
            "zh": "目标功能 OUTCOME 设置为默认或偿还。"
        }
    },
    {
        "translation": {
            "en": "At this point we can expect the algorithm to have found the global minimum of the error surface and, as a result, the most accurate predictive model possible.",
            "zh": "在这一点上，我们可以预期该算法已经找到了误差面的全局最小值，从而找到了最准确的预测模型。"
        }
    },
    {
        "translation": {
            "en": "placebo, 584",
            "zh": "安慰剂，584"
        }
    },
    {
        "translation": {
            "en": "The way to solve this problem is by smoothing the probabilities used by the model. We know from the definition of probability that the sum of the probabilities of a feature taking each of its possible levels should equal 1.0:",
            "zh": "解决此问题的方法是对模型使用的概率进行平滑处理。我们从概率的定义中知道，取每个可能水平的特征的概率之和应等于 1.0："
        }
    },
    {
        "translation": {
            "en": "Deep learning is currently attracting a huge amount of attention within the machine learning community.",
            "zh": "深度学习目前在机器学习社区中引起了极大的关注。"
        }
    },
    {
        "translation": {
            "en": "For Models 3 and 4, we need to go as far as 60% and 75% respectively.",
            "zh": "对于模型 3 和 4，我们需要分别达到 60% 和 75%。"
        }
    },
    {
        "translation": {
            "en": "Probability has a longer history, and broader applicability, than predictive analytics. Consequently, the standard language of probability has developed some esoteric terminology, including terms such as sample space, experiment, outcome, event, and random variable. So we will begin by first explaining this terminology and aligning it with the more familiar terminology of predictive analytics.",
            "zh": "与预测分析相比，概率具有更长的历史和更广泛的适用性。因此，概率的标准语言已经发展出一些深奥的术语，包括样本空间、实验、结果、事件和随机变量等术语。因此，我们将首先解释这个术语，并将其与更熟悉的预测分析术语保持一致。"
        }
    },
    {
        "translation": {
            "en": "These cluster assignments are also shown in the rightmost column of Table 10.1[604] (as cluster assignments did not change after the second iteration of the algorithm) in context with the original dataset. A set of cluster assignments is usually referred to as a clustering.",
            "zh": "这些聚类分配也显示在表 10.1[604] 的最右边列中（因为聚类分配在算法第二次迭代后没有更改）与原始数据集的上下文中。一组聚类分配通常称为聚类。"
        }
    },
    {
        "translation": {
            "en": "case-based reasoning, 234",
            "zh": "基于案例的推理，234"
        }
    },
    {
        "translation": {
            "en": "1. Partitioning the feature space into regions based on clusters of training instances with the same target value, and assigning a query located in a region the target value of the cluster that defines that region.",
            "zh": "1. 根据具有相同目标值的训练实例集群将特征空间划分为多个区域，并为位于某个区域的查询分配定义该区域的集群的目标值。"
        }
    },
    {
        "translation": {
            "en": "The original version of Xavier initialization considered both the forward activation through the network and the backward propagation of gradients, and so the calculation of the variance of the distribution from which the weights for a layer are sampled takes both the inputs to a layer nin(k) and the number of outputs from a layer nout(k) into account; it is calculated as follows:",
            "zh": "Xavier 初始化的原始版本同时考虑了通过网络的前向激活和梯度的向后传播，因此，从中采样层权重的分布方差的计算同时考虑了层 nin（k） 的输入和层 nout（k） 的输出数量;计算方法如下："
        }
    },
    {
        "translation": {
            "en": "Figure 3.10",
            "zh": "图 3.10"
        }
    },
    {
        "translation": {
            "en": "This dominance of the distance computation by a feature based solely on the fact that it has a larger range of values than other features is not a good thing.",
            "zh": "仅基于特征具有比其他特征更大的值范围这一事实来主导距离计算并不是一件好事。"
        }
    },
    {
        "translation": {
            "en": "AdaBoost, 171",
            "zh": "AdaBoost，171"
        }
    },
    {
        "translation": {
            "en": "Wisconsin breast cancer dataset, 109, 377",
            "zh": "威斯康星州乳腺癌数据集，109,377"
        }
    },
    {
        "translation": {
            "en": "The first half of an auto-encoder, up to the output of the narrowest layer in the middle, is known as an encoder, and the second half of the network is known as a decoder.",
            "zh": "自动编码器的前半部分，直到中间最窄层的输出，称为编码器，网络的后半部分称为解码器。"
        }
    },
    {
        "translation": {
            "en": "We are now ready to take on Bayes’ Theorem!",
            "zh": "我们现在已经准备好接受贝叶斯定理了！"
        }
    },
    {
        "translation": {
            "en": "In the naive approach described in Algorithm 15[671] the network being trained is also being used to generate target feature values (Line 15).",
            "zh": "在算法 15[671] 中描述的朴素方法中，正在训练的网络也用于生成目标特征值（第 15 行）。"
        }
    },
    {
        "translation": {
            "en": "When we are processing a batch of examples, we need to do the backpropagation of the δs for each example.",
            "zh": "当我们处理一批示例时，我们需要对每个示例进行 δ 的反向传播。"
        }
    },
    {
        "translation": {
            "en": "30. Updating the weights using Equations (4.12)[161] and (4.13)[161] ensures that the weights always sum to 1.",
            "zh": "30. 使用方程（4.12）[161]和（4.13）[161]更新权重，确保权重总和始终为1。"
        }
    },
    {
        "translation": {
            "en": "This means that some of the errors will be positive and some will be negative.",
            "zh": "这意味着有些误差是正的，有些是负的。"
        }
    },
    {
        "translation": {
            "en": "9.7   The structure of a profit matrix.",
            "zh": "9.7 利润矩阵的结构。"
        }
    },
    {
        "translation": {
            "en": "5.9   The whiskey dataset after the descriptive features have been normalized.",
            "zh": "5.9 描述性特征归一化后的威士忌数据集。"
        }
    },
    {
        "translation": {
            "en": "However, each of the neurons in each group only inspected a local region of the visual field for a single feature, and these local regions became known as local receptive fields.",
            "zh": "然而，每组中的每个神经元只检查视野的局部区域以获取单个特征，这些局部区域被称为局部感受野。"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated the ∂ℰ/∂λi term, we update λi using the following update rule:27",
            "zh": "一旦我们计算了 ∂E/∂λi 项，我们使用以下更新规则更新 λi：27"
        }
    },
    {
        "translation": {
            "en": "linear function, 766",
            "zh": "线性函数，766"
        }
    },
    {
        "translation": {
            "en": "Table 11.1",
            "zh": "表 11.1"
        }
    },
    {
        "translation": {
            "en": "You decide to do this by thinking about the animals you can remember coming across before and comparing the features of these animals with the features the sailor described to you.",
            "zh": "你决定通过思考你以前能记得遇到的动物，并将这些动物的特征与水手向你描述的特征进行比较来做到这一点。"
        }
    },
    {
        "translation": {
            "en": "Table 5.11[213] lists a small binary dataset that a nearest neighbor model could use to make predictions for this scenario. The descriptive features in this dataset are all binary and record the following information about the behavior of past customers:",
            "zh": "表5.11[213]列出了一个小型二进制数据集，最近邻模型可以使用该数据集对这种情况进行预测。此数据集中的描述性特征都是二进制的，并记录了有关过去客户行为的以下信息："
        }
    },
    {
        "translation": {
            "en": "Section 4.4.5 has been revised to cover ensemble models in more detail than in the first edition and includes a new description of gradient boosting methods.",
            "zh": "第 4.4.5 节经过修订，比第一版更详细地涵盖了集成模型，并包括对梯度提升方法的新描述。"
        }
    },
    {
        "translation": {
            "en": "B.1 Probability Basics",
            "zh": "B.1 概率基础"
        }
    },
    {
        "translation": {
            "en": "He initialization, 461",
            "zh": "他初始化，461"
        }
    },
    {
        "translation": {
            "en": "predictive features, 227",
            "zh": "预测特征， 227"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that the hospital would need in order to use the analytics-based insight that your solution would provide.",
            "zh": "（c） 对于您提出的每个分析解决方案，概述医院需要的容量，以便使用您的解决方案将提供的基于分析的见解。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.10",
            "zh": "图 4.10"
        }
    },
    {
        "translation": {
            "en": "For galaxy classification, the most important properties extracted from the images are brightness, color, and shape.",
            "zh": "对于星系分类，从图像中提取的最重要的属性是亮度、颜色和形状。"
        }
    },
    {
        "translation": {
            "en": "In this context, V and M are examples of hidden features.",
            "zh": "在此上下文中，V 和 M 是隐藏特征的示例。"
        }
    },
    {
        "translation": {
            "en": "Figure 7.21",
            "zh": "图 7.21"
        }
    },
    {
        "translation": {
            "en": "This causes the algorithm to cluster instances with similar target feature values.",
            "zh": "这会导致算法对具有相似目标特征值的实例进行聚类。"
        }
    },
    {
        "translation": {
            "en": "A second evaluation experiment is then performed using the data in the 2nd fold as the test set and the data in the remaining k − 1 folds as the training set.",
            "zh": "然后使用第 2 倍的数据作为测试集，将剩余的 k − 1 倍的数据作为训练集进行第二次评估实验。"
        }
    },
    {
        "translation": {
            "en": "The data in an ABT is historical data from the disparate data sources within an organization.",
            "zh": "ABT 中的数据是来自组织内不同数据源的历史数据。"
        }
    },
    {
        "translation": {
            "en": "For example, in a network using ReLUs, Xavier initialization (Equation (8.62)[459]) could be used to define the variance for the weights in the first layer, because the rectified function has not been applied to the inputs, and then He initialization (Equation (8.63)[461]) could then be used for the later layers in the network (He et al., 2015).",
            "zh": "例如，在使用 ReLU 的网络中，Xavier 初始化（等式 （8.62）[459]）可用于定义第一层权重的方差，因为校正函数尚未应用于输入，然后 He 初始化（等式 （8.63）[461]）可用于网络中的后几层（He et al.， 2015)."
        }
    },
    {
        "translation": {
            "en": "2.7   Modeling points in time for a scenario with no real outcome period (each line represents a customer, and stars signify events). (a) shows the actual data, and (b) shows the event-aligned data.",
            "zh": "2.7 对没有实际结果期的场景的时间点进行建模（每条线代表一个客户，星星表示事件）。（a） 显示实际数据，（b） 显示事件对齐数据。"
        }
    },
    {
        "translation": {
            "en": "The player wins $2 in the event of a TwentyTwo (two aces), wins $1 if they beat the dealer in the normal way, neither wins nor loses anything if the game is tied, and loses $1 if the dealer wins.10 Table 11.1[647] shows some episodes of the TwentyTwos game being played including the the player’s hand, the dealer’s hand, the actions the player takes, and the rewards earned by the player.",
            "zh": "如果玩家有二十二（两个A），则赢得2美元，如果他们以正常方式击败庄家，则赢得1美元，如果游戏打成平局，则既不赢也不输，如果庄家赢了，则损失1美元.10表11.1[647]显示了正在进行的二十二游戏的一些情节，包括玩家的手牌， 庄家的手牌，玩家采取的行动，以及玩家获得的奖励。"
        }
    },
    {
        "translation": {
            "en": "Figure A.6",
            "zh": "图 A.6"
        }
    },
    {
        "translation": {
            "en": "Figure 8.12[407] illustrates the backward pass of the algorithm. Before describing the backward pass of the algorithm, we will distinguish between two types of error gradients that are calculated when we are training a neural network using backpropagation:",
            "zh": "图 8.12[407] 说明了算法的向后传递。在描述算法的向后传递之前，我们将区分两种类型的误差梯度，它们是在使用反向传播训练神经网络时计算的："
        }
    },
    {
        "translation": {
            "en": "SIZEUNIFORMITY: A measure of the variation in size of cells in the tissue samples, higher values indicate more uniform sizes (1 to 10).",
            "zh": "大小均匀性：组织样本中细胞大小变化的量度，值越高表示大小越均匀（1 到 10）。"
        }
    },
    {
        "translation": {
            "en": "In a famous example of this, an article was published in the prestigious journal Nature outlining a causal relationship between young children sleeping with a night-light turned on and these children developing near-sightedness in later life (Quinn et al., 1999).",
            "zh": "在一个著名的例子中，一篇发表在著名期刊《自然》上的文章概述了幼儿开着夜灯睡觉与这些孩子在以后的生活中发展近视之间的因果关系（Quinn等人，1999）。"
        }
    },
    {
        "translation": {
            "en": "The rewards are shown as the large numbers beside some states.",
            "zh": "奖励显示为某些州旁边的大数字。"
        }
    },
    {
        "translation": {
            "en": "The reward for moving between any two normal cells is − 1, the reward for arriving at the goal is 50, and the reward for entering a fiery cell is − 20.",
            "zh": "在任意两个正常细胞之间移动的奖励是-1，达到目标的奖励是50，进入火热细胞的奖励是-20。"
        }
    },
    {
        "translation": {
            "en": "Davies, E. R. 2005. Machine vision: Theory, algorithms, practicalities, 3rd ed. Elsevier.",
            "zh": "戴维斯，ER，2005 年。机器视觉：理论、算法、实用性，第 3 版，爱思唯尔。"
        }
    },
    {
        "translation": {
            "en": "Using the network in Figure 6.12(b)[291], the calculation would be",
            "zh": "使用图6.12（b）[291]中的网络，计算结果为："
        }
    },
    {
        "translation": {
            "en": "That is, a good clustering minimizes intra-cluster distances and maximizes inter-cluster distances.",
            "zh": "也就是说，良好的聚类可以最小化聚类内距离，并最大化聚类间距离。"
        }
    },
    {
        "translation": {
            "en": "Through his discussions with the AT management team, Kate, and Grace, he had learned a lot about the mobile phone industry.",
            "zh": "通过与AT管理团队、Kate和Grace的讨论，他学到了很多关于手机行业的知识。"
        }
    },
    {
        "translation": {
            "en": "—Confucius",
            "zh": "——孔子"
        }
    },
    {
        "translation": {
            "en": "For example, to compute the probability of P(h) in the domain specified by the joint probability distribution P(H,F,V,M), we simply sum the values in the cells containing h (the cells in the first column).",
            "zh": "例如，要计算联合概率分布 P（H，F，V，M） 指定的域中 P（h） 的概率，我们只需对包含 h 的单元格（第一列中的单元格）中的值求和即可。"
        }
    },
    {
        "translation": {
            "en": "In Part IV the link between the broader business context and machine learning is shown very clearly in the case studies presented in Chapters 12 (predicting customer churn) and 13 (galaxy classification).",
            "zh": "在第四部分中，第12章（预测客户流失）和第13章（星系分类）中介绍的案例研究非常清楚地显示了更广泛的业务环境与机器学习之间的联系。"
        }
    },
    {
        "translation": {
            "en": "Davenport, Thomas H., and Jinho Kim. 2013. Keeping up with the quants: Your guide to understanding and using analytics. Harvard Business Press Books.",
            "zh": "达文波特、托马斯 H. 和金镇浩。2013. 跟上量化趋势：理解和使用分析的指南。哈佛商业出版社图书。"
        }
    },
    {
        "translation": {
            "en": "However, the matrix product ED is not defined because the number of columns in E (3) is not equal to the number of rows in D (2).",
            "zh": "但是，由于 E （3） 中的列数不等于 D （2） 中的行数，因此未定义矩阵乘积 ED。"
        }
    },
    {
        "translation": {
            "en": "One way to extend the longevity of a feature is to use a derived ratio instead of a raw feature.",
            "zh": "延长特征寿命的一种方法是使用派生比率而不是原始特征。"
        }
    },
    {
        "translation": {
            "en": "Consequently, in Sections 8.4.1[434] and 8.4.2[447] we explain and motivate the current standard approaches to deciding on two of the most important hyper-parameter decisions for keeping error gradients stable: the selection of the activation function, and the initialization of the weights.",
            "zh": "因此，在第 8.4.1[434] 和 8.4.2[447] 节中，我们解释并激励了当前的标准方法，以决定两个最重要的超参数决策，以保持误差梯度稳定：激活函数的选择和权重的初始化。"
        }
    },
    {
        "translation": {
            "en": "When evaluating models against a particular deployment scenario, model accuracy is not the only issue we need to consider. In order to successfully address a business problem, a model must be accurate, but it must also meet the other requirements of the business scenario. Three issues are important to consider:",
            "zh": "在针对特定部署方案评估模型时，模型准确性并不是我们需要考虑的唯一问题。为了成功解决业务问题，模型必须准确，但也必须满足业务场景的其他要求。有三个问题需要考虑："
        }
    },
    {
        "translation": {
            "en": "eager learner, 232",
            "zh": "渴望学习，232"
        }
    },
    {
        "translation": {
            "en": "In this simple example it is easy to imagine collecting a training instance to match every possible combination of descriptive features; because there are only three binary descriptive features, there are only 23 = 8 combinations.",
            "zh": "在这个简单的例子中，很容易想象收集一个训练实例来匹配描述性特征的所有可能组合;因为只有三个二进制描述性特征，所以只有 23 = 8 个组合。"
        }
    },
    {
        "translation": {
            "en": "Wooldridge and Jennings (1995) remains a key introduction to the field and the more recent Wooldridge (2009) adds useful information about systems where multiple agents compete or cooperate is very useful.",
            "zh": "Wooldridge 和 Jennings （1995） 仍然是该领域的关键介绍，最近的 Wooldridge （2009） 增加了有关多个智能体竞争或合作的系统的有用信息非常有用。"
        }
    },
    {
        "translation": {
            "en": "EDUCATION: Spending per primary student as a percentage of GDP",
            "zh": "教育：小学生人均支出占GDP的百分比"
        }
    },
    {
        "translation": {
            "en": "This means that weights for these neurons will not be updated for this example.",
            "zh": "这意味着在此示例中，这些神经元的权重不会更新。"
        }
    },
    {
        "translation": {
            "en": "(a) A visualization of the final action-value table for an agent trained using SARSA on-policy temporal-difference learning across the grid world after 350 episodes. (b) The cumulative reward earned from each episode. (c) An illustration of the target policy learned by the agent after 350 episodes. The arrows show the direction with the highest entry in the action-value table for each state. (d) The path the agent will take from the start state to the goal state when greedily following the target policy.",
            "zh": "（a） 在350集后，使用SARSA政策时间差分学习训练的智能体的最终行动值表的可视化。（b） 每集所获得的累积奖励。（c） 代理人在350集后了解到的目标政策的说明。箭头显示每个状态的动作值表中条目最多的方向。（d） 当贪婪地遵循目标策略时，代理从开始状态到目标状态的路径。"
        }
    },
    {
        "translation": {
            "en": "In situations where a letter, for example, X, denotes a joint event, then ∑iP(Xi) should be interpreted as summing over all the possible combinations of value assignments to the features in X.",
            "zh": "在字母（例如 X）表示联合事件的情况下，∑iP（习） 应解释为 X 中特征的所有可能值赋值组合的总和。"
        }
    },
    {
        "translation": {
            "en": "David Hand has also written extensively on the appropriateness of different evaluation measures and is always worth reading.",
            "zh": "大卫·汉德（David Hand）还撰写了大量关于不同评估措施的适当性的文章，总是值得一读。"
        }
    },
    {
        "translation": {
            "en": "A typical size for a subsequence might be 20 inputs.",
            "zh": "子序列的典型大小可能是 20 个输入。"
        }
    },
    {
        "translation": {
            "en": "For the purpose of illustration, let us assume that the neuron shown in Figure 8.31[480] uses the set of weights listed in Equation (8.85)[480]",
            "zh": "为了便于说明，我们假设图8.31[480]所示的神经元使用等式（8.85）[480]中列出的权重集"
        }
    },
    {
        "translation": {
            "en": "In neither of these rows is f the case, so the conditional probability for P(f | h,m) is 0.",
            "zh": "在这两行中都不是 f 的情况，因此 P（f | h，m） 的条件概率为 0。"
        }
    },
    {
        "translation": {
            "en": "co-absence, 212, 213",
            "zh": "共同缺席，212,213"
        }
    },
    {
        "translation": {
            "en": "Furthermore, during the backward pass of the algorithm the derivative of the rectified linear function for Neuron 4 is zero for all four examples, causing the error gradient to be pushed to zero for all four examples, and so the weights on connections into Neuron 4 receive no updates.",
            "zh": "此外，在算法的向后传递过程中，所有四个示例中 Neuron 4 的校正线性函数的导数均为零，导致所有四个示例的误差梯度均为零，因此连接到 Neuron 4 的权重不会收到任何更新。"
        }
    },
    {
        "translation": {
            "en": "6.8   Histograms, using a bin size of 250 units, and density curves for the ACCOUNT BALANCE feature: (a) the fraudulent instances overlaid with a fitted exponential distribution; and (b) the non-fraudulent instances overlaid with a fitted normal distribution.",
            "zh": "6.8 直方图，使用250个单位的箱大小，以及账户余额特征的密度曲线：（a）用拟合指数分布叠加的欺诈实例;（b）非欺诈性实例与拟合正态分布叠加。"
        }
    },
    {
        "translation": {
            "en": "The basic assumption behind both gain and lift is that if we were to rank the instances in a test set in descending order of the prediction scores assigned to them by a well-performing model, we would expect the majority of the positive instances to be toward the top of this ranking. The gain and lift measures attempt to measure to what extent a set of predictions made by a model meet this assumption.",
            "zh": "增益和提升背后的基本假设是，如果我们要按照表现良好的模型分配给它们的预测分数的降序对测试集中的实例进行排名，我们预计大多数正实例都位于该排名的顶部。增益和提升度量试图衡量模型所做的一组预测在多大程度上满足此假设。"
        }
    },
    {
        "translation": {
            "en": "linear annealing, 674",
            "zh": "线性退火，674"
        }
    },
    {
        "translation": {
            "en": "Cumulative gain is especially useful in customer relationship management (CRM) applications such as cross-sell and upsell models. The cumulative gain tells us how many customers we need to contact in order to reach a particular percentage of those who are likely to respond to an offer, which is an incredibly useful piece of information to know when planning customer contact budgets.",
            "zh": "累积收益在客户关系管理 （CRM） 应用程序（如交叉销售和追加销售模型）中特别有用。累积收益告诉我们需要联系多少客户才能接触到可能响应报价的特定百分比的客户，这是在规划客户联系预算时了解的非常有用的信息。"
        }
    },
    {
        "translation": {
            "en": "Algorithm 13[658] shows the algorithm for the Q-learning approach to temporal-difference learning.",
            "zh": "算法13[658]显示了用于时间差分学习的Q学习方法的算法。"
        }
    },
    {
        "translation": {
            "en": "8.2.3   Neural Networks as Matrix Operations",
            "zh": "8.2.3 作为矩阵操作的神经网络"
        }
    },
    {
        "translation": {
            "en": "Figure 10.7",
            "zh": "图 10.7"
        }
    },
    {
        "translation": {
            "en": "Table 4.9",
            "zh": "表 4.9"
        }
    },
    {
        "translation": {
            "en": "Decision tree induction algorithms are particularly well suited to use with bagging.",
            "zh": "决策树归纳算法特别适合与装袋一起使用。"
        }
    },
    {
        "translation": {
            "en": "When evaluating the performance of models, it would be useful to be able to take into account the costs of different outcomes.",
            "zh": "在评估模型的性能时，能够考虑到不同结果的成本将是有用的。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot matrix showing scatter plots of the continuous features from the professional basketball team dataset in Table 3.7[73] with correlation coefficients included.",
            "zh": "一个散点图矩阵，显示了表3.7[73]中职业篮球队数据集中连续特征的散点图，包括相关系数。"
        }
    },
    {
        "translation": {
            "en": "Training a support vector machine involves searching for the decision boundary, or separating hyperplane,20 that leads to the maximum margin because this will best separate the levels of the target feature.",
            "zh": "训练支持向量机涉及搜索决策边界，或分离超平面，20 这会导致最大边际，因为这将最好地分离目标特征的级别。"
        }
    },
    {
        "translation": {
            "en": "A plot showing how the sum of squared errors of the network changed during training.",
            "zh": "显示网络的平方误差之和在训练期间如何变化的图。"
        }
    },
    {
        "translation": {
            "en": "13.2   Data Understanding",
            "zh": "13.2 数据理解"
        }
    },
    {
        "translation": {
            "en": "For example, if in an ABT containing 1,000 instances, one value is missing for a particular feature, it would be pretty extreme to remove that whole feature.",
            "zh": "例如，如果在包含 1,000 个实例的 ABT 中，某个特定功能缺少一个值，则删除整个功能将是非常极端的。"
        }
    },
    {
        "translation": {
            "en": "Learning generalized functions from a small training dataset is exactly what predictive modeling does, and we can use predictive models, trained using a combination of ideas form supervised machine learning and reinforcement learning, for this task!",
            "zh": "从小型训练数据集中学习广义函数正是预测建模所做的，我们可以使用预测模型，使用监督机器学习和强化学习的思想组合进行训练，以完成这项任务！"
        }
    },
    {
        "translation": {
            "en": "textual data, 34",
            "zh": "文本数据，34"
        }
    },
    {
        "translation": {
            "en": "The next section describes how the weights can be determined using the gradient descent algorithm.",
            "zh": "下一节将介绍如何使用梯度下降算法确定权重。"
        }
    },
    {
        "translation": {
            "en": "7. For an excellent overview of the different types of biases that affect machine learning and the potential harms these can cause, we recommend Kate Crawford’s The Trouble with Bias keynote from the NeurIPS 2017 conference (Crawford, 2017). Videos of this talk are freely available online.",
            "zh": "7. 为了很好地概述影响机器学习的不同类型的偏见以及这些偏见可能造成的潜在危害，我们推荐 Kate Crawford 在 NeurIPS 2017 会议上发表的 The Trouble with Bias 主题演讲（Crawford，2017 年）。本次演讲的视频可在线免费获得。"
        }
    },
    {
        "translation": {
            "en": "The first convolutional layer had 96 different filters and used a ReLU non-linearity and max pooling.",
            "zh": "第一个卷积层有 96 个不同的滤波器，并使用 ReLU 非线性和最大池化。"
        }
    },
    {
        "translation": {
            "en": "Adding the five terminal states—BUST, LOSE, TIE, WIN, and TWENTYTWO—gives 11 states in total.",
            "zh": "将五个终端状态（BUST、LOSE、TIE、WIN 和 TWENTYTWO）相加，总共有 11 个状态。"
        }
    },
    {
        "translation": {
            "en": "misses, 538",
            "zh": "失误，538"
        }
    },
    {
        "translation": {
            "en": "In each case there is an intuitive clustering that we can observe in the visualizations—for the blobs dataset there are three clusters, one for each blob; for the circles dataset there are two clusters, one for each ring; and for the half-moons dataset there are two clusters, one for each half-moon shape.",
            "zh": "在每种情况下，我们都可以在可视化效果中观察到一个直观的聚类 - 对于 blob 数据集，有三个聚类，每个聚类一个;对于圆数据集，有两个聚类，每个环一个聚类;对于半月数据集，有两个聚类，每个半月形状一个。"
        }
    },
    {
        "translation": {
            "en": "3.3.1   Missing Values",
            "zh": "3.3.1 缺失值"
        }
    },
    {
        "translation": {
            "en": "(c) Assuming a learning rate of 0.000002, calculate the weights at the next iteration of the gradient descent algorithm.",
            "zh": "（c） 假设学习率为 0.000002，计算梯度下降算法下一次迭代时的权重。"
        }
    },
    {
        "translation": {
            "en": "C.1  (a) The speed of a car during a journey along a minor road before joining a highway and finally coming to a sudden halt; and (b) the acceleration, the derivative of speed with respect to time, for this journey.",
            "zh": "C.1 （a） 汽车在进入高速公路之前沿一条小路行驶并最终突然停下来的速度;（b）加速度，即速度相对于时间的导数。"
        }
    },
    {
        "translation": {
            "en": "2.6 Further Reading",
            "zh": "2.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "The nearest neighbor algorithm creates an implicit global predictive model by aggregating local models, or neighborhoods.",
            "zh": "最近邻算法通过聚合局部模型或邻域来创建隐式全局预测模型。"
        }
    },
    {
        "translation": {
            "en": "3. and then applying a decision rule over the class posteriors to return a target level.",
            "zh": "3. 然后对类后验应用决策规则以返回目标水平。"
        }
    },
    {
        "translation": {
            "en": "The fourth segment of the table lists the per example one-hot encoding of the target for each example in the mini-batch.",
            "zh": "该表的第四段列出了小批量中每个示例的目标的每个示例的单热编码。"
        }
    },
    {
        "translation": {
            "en": "seeds, 600",
            "zh": "种子，600"
        }
    },
    {
        "translation": {
            "en": "The bottom two segments of the table illustrate the calculation of the δs for each neuron for each example.",
            "zh": "该表的底部两段说明了每个示例中每个神经元的 δ 的计算。"
        }
    },
    {
        "translation": {
            "en": "2.4.6   Case Study: Motor Insurance Fraud",
            "zh": "2.4.6 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "1. learning the class posterior probability P(tl|d) directly from the data,",
            "zh": "1. 直接从数据中学习类后验概率 P（tl|d），"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15(a)[151] depicts a set of instances on the continuous number line.",
            "zh": "图4.15（a）[151]描绘了连续数字线上的一组实例。"
        }
    },
    {
        "translation": {
            "en": "As we have seen, using a joint probability distribution, a model can carry out this calculation by simply conditioning on the evidence features and summing out the hidden features.",
            "zh": "正如我们所看到的，使用联合概率分布，模型可以通过简单地对证据特征进行条件反射并总结隐藏特征来执行此计算。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.28",
            "zh": "图 8.28"
        }
    },
    {
        "translation": {
            "en": "There are a number of perspectives on understanding how dropout helps with overfitting.",
            "zh": "关于理解辍学如何帮助过拟合，有许多观点。"
        }
    },
    {
        "translation": {
            "en": "Blondlot, René, 533",
            "zh": "布隆洛特，勒内，533"
        }
    },
    {
        "translation": {
            "en": "First, Jocelyn calculated an average class accuracy by comparing the predictions made by her model for the same 200 galaxies with the manual classifications made by the SDSS scientists.",
            "zh": "首先，Jocelyn通过将她的模型对相同200个星系的预测与SDSS科学家的手动分类进行比较，计算了平均分类精度。"
        }
    },
    {
        "translation": {
            "en": "If a sample is not representative, we say that the sample is biased.",
            "zh": "如果样本不具有代表性，我们说样本是有偏差的。"
        }
    },
    {
        "translation": {
            "en": "The second part of the book covers the Modeling and Evaluation phase of CRISP-DM. We consider five main families of machine learning algorithm:",
            "zh": "本书的第二部分介绍了 CRISP-DM 的建模和评估阶段。我们考虑了机器学习算法的五个主要系列："
        }
    },
    {
        "translation": {
            "en": "For example, in the single screenshot of the Lunar Lander environment in Figure 11.7[669], it is not possible to tell at what velocity the spaceship is moving.",
            "zh": "例如，在图11.7[669]中月球着陆器环境的单个屏幕截图中，无法判断宇宙飞船以什么速度移动。"
        }
    },
    {
        "translation": {
            "en": "Salaries, however, change all the time based on inflation and other socioeconomic factors.",
            "zh": "然而，工资一直在根据通货膨胀和其他社会经济因素而变化。"
        }
    },
    {
        "translation": {
            "en": "Machine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.",
            "zh": "机器学习算法的工作原理是搜索一组可能的预测模型，以寻找最能捕获数据集中描述性特征和目标特征之间关系的模型。"
        }
    },
    {
        "translation": {
            "en": "2.4 Designing and Implementing Features",
            "zh": "2.4 设计和实现功能"
        }
    },
    {
        "translation": {
            "en": "We can see in Figure 5.10(b)[201] that instance d12 is not the true nearest neighbor to the query—several other instances are inside the target hypersphere.",
            "zh": "我们可以在图 5.10（b）[201] 中看到，实例 d12 不是查询的真正最近邻，而是其他几个实例在目标超球体内。"
        }
    },
    {
        "translation": {
            "en": "However, after approximately 5,000 epochs, the rate of decrease of the error increases dramatically until it flattens out again around 6,000 epochs.",
            "zh": "然而，在大约 5,000 个周期之后，误差的下降率急剧增加，直到在 6,000 个周期左右再次趋于平缓。"
        }
    },
    {
        "translation": {
            "en": "A range of performance measures use this ability of a model, to rank instances that should get predictions of one target level higher than the other, to better assess how well a prediction model is performing.",
            "zh": "一系列性能度量利用模型的这种能力，对应获得一个目标级别的预测高于另一个目标级别的实例进行排名，以更好地评估预测模型的性能。"
        }
    },
    {
        "translation": {
            "en": "Like lots of other families, the Murphys have a set of magnetic letters on the refrigerator in their kitchen.",
            "zh": "像许多其他家庭一样，墨菲一家在厨房的冰箱上有一套磁性字母。"
        }
    },
    {
        "translation": {
            "en": "Although the SDSS has been able to put in place algorithmic solutions to identifying certain objects within the images collected, there have been a number of difficulties.",
            "zh": "尽管SDSS已经能够实施算法解决方案来识别所收集图像中的某些物体，但仍存在许多困难。"
        }
    },
    {
        "translation": {
            "en": "For example, after beginning with the feature subset including no features, the forward sequential search process generates three feature subsets, each containing just one of X, Y, or Z (shown in the second column of Figure 5.19[228]).",
            "zh": "例如，从不包含特征的特征子集开始，前向顺序搜索过程会生成三个特征子集，每个子集仅包含 X、Y 或 Z 中的一个（如图 5.19[228] 的第二列所示）。"
        }
    },
    {
        "translation": {
            "en": "Figure A.2",
            "zh": "图 A.2"
        }
    },
    {
        "translation": {
            "en": "If a descriptive feature is found to have a significant impact on the model, this indicates that there is a significant linear relationship between it and the target feature.",
            "zh": "如果发现描述性特征对模型有显著影响，则表明它与目标特征之间存在显著的线性关系。"
        }
    },
    {
        "translation": {
            "en": "Information-Based Learning",
            "zh": "信息化学习"
        }
    },
    {
        "translation": {
            "en": "This means that, similar to the thresholded multivariate linear regression models, a perceptron is able to represent a function that distinguishes between two classes of inputs if these two classes are linearly separable.",
            "zh": "这意味着，与阈值多变量线性回归模型类似，如果两类输入是线性可分离的，则感知器能够表示区分两类输入的函数。"
        }
    },
    {
        "translation": {
            "en": "-0.2318",
            "zh": "-0.2318"
        }
    },
    {
        "translation": {
            "en": "After getting to know the data, the second goal of data exploration is to identify any data quality issues in an ABT. A data quality issue is loosely defined as anything unusual about the data in an ABT. The most common data quality issues, however, are missing values, irregular cardinality problems, and outliers. In this section we describe each of these data quality issues and outline how the data quality report can be used to identify them.",
            "zh": "了解数据后，数据探索的第二个目标是识别 ABT 中的任何数据质量问题。数据质量问题被松散地定义为 ABT 中数据的任何异常情况。然而，最常见的数据质量问题是缺失值、不规则基数问题和异常值。在本节中，我们将逐一介绍这些数据质量问题，并概述如何使用数据质量报告来识别这些问题。"
        }
    },
    {
        "translation": {
            "en": "The type of vegetation in an area is stored in the target feature, VEGETATION.",
            "zh": "区域中的植被类型存储在目标要素 VEGETATION 中。"
        }
    },
    {
        "translation": {
            "en": "When we weight the contribution to a prediction of each of the neighbors by the reciprocal of the distance to the query, we can actually set k to be equal to the size of the training set and therefore include all the training instances in the prediction process. The issue of losing the true pattern of the data is less acute now because the training instances that are very far away from the query naturally won’t have much of an effect on the prediction.",
            "zh": "当我们通过查询距离的倒数来加权对每个邻居的预测的贡献时，我们实际上可以将 k 设置为等于训练集的大小，从而在预测过程中包括所有训练实例。现在，丢失数据真实模式的问题已经不那么严重了，因为离查询很远的训练实例自然不会对预测产生太大影响。"
        }
    },
    {
        "translation": {
            "en": "Once we have calculated the δs for the neurons in these layers, we have two further sets of calculations to perform in order to complete the backpropagation through the LSTM. First, we need to calculate the updates for each weight in each of these layers; and second, we need to calculate the vector of gradients ∂ℰt/∂ht−1 that are backpropagated to the previous time-step.",
            "zh": "一旦我们计算了这些层中神经元的δs，我们还有两组计算要执行，以完成通过LSTM的反向传播。首先，我们需要计算每一层中每个权重的更新;其次，我们需要计算反向传播到前一个时间步的梯度 ∂Et/∂ht−1 的向量。"
        }
    },
    {
        "translation": {
            "en": "clustering, 597, 599, 603, 629",
            "zh": "聚类， 597， 599， 603， 629"
        }
    },
    {
        "translation": {
            "en": "A sample test set with model predictions and scores.",
            "zh": "具有模型预测和分数的示例测试集。"
        }
    },
    {
        "translation": {
            "en": "To use discounted return in the action-value function it is restated",
            "zh": "为了在行动价值函数中使用贴现回报，它被重述"
        }
    },
    {
        "translation": {
            "en": "That is, they optimize the action-value function and do not rely on having a model of how the world behaves.",
            "zh": "也就是说，它们优化了行动价值函数，并且不依赖于世界行为的模型。"
        }
    },
    {
        "translation": {
            "en": "The performance measures for each fold (in this case, a confusion matrix and a class accuracy measure) can be aggregated into summary performance measures that capture the overall performance across the 5 folds.",
            "zh": "每个折叠的性能度量（在本例中为混淆矩阵和类准确度量）可以聚合为汇总性能度量，以捕获 5 个折叠的整体性能。"
        }
    },
    {
        "translation": {
            "en": "central tendency, 54, 550, 745",
            "zh": "中心趋势， 54， 550， 745"
        }
    },
    {
        "translation": {
            "en": "polynomial kernel, 366",
            "zh": "多项式核，366"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature DIA. B.P. and the target feature, TACHYCARDIA.",
            "zh": "（a） 下面的可视化说明了连续特征 DIA. BP 与目标特征 TAWCARDIA 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "0.4016",
            "zh": "0.4016"
        }
    },
    {
        "translation": {
            "en": "2.4.2   Different Types of Features",
            "zh": "2.4.2 不同类型的功能"
        }
    },
    {
        "translation": {
            "en": "Furthermore, basis functions work for both simple multivariable linear regression models that predict a continuous target feature and multivariable logistic regression models that predict a categorical target feature.",
            "zh": "此外，基函数既适用于预测连续目标特征的简单多变量线性回归模型，也适用于预测分类目标特征的多变量逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "10.4   Extensions and Variations",
            "zh": "10.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Another consequence of the normal distribution having light tails is that it is sensitive to outliers in the data.",
            "zh": "具有光尾的正态分布的另一个结果是它对数据中的异常值很敏感。"
        }
    },
    {
        "translation": {
            "en": "28. See Chapter 8[319].",
            "zh": "[28]见第8章[319]。"
        }
    },
    {
        "translation": {
            "en": "(d) Feature distributions",
            "zh": "（d） 特征分布"
        }
    },
    {
        "translation": {
            "en": "The majority target level predicted at the root node of this subtree (the GENDER node) gives a correct prediction of icu for each of the three instances, so the error rate on the validation set for the root node of the subtree is 0.",
            "zh": "在此子树的根节点（GENDER 节点）预测的多数目标级别给出了三个实例中每个实例的 icu 的正确预测，因此子树根节点的验证集的错误率为 0。"
        }
    },
    {
        "translation": {
            "en": "So we would expect that the model would predict no and that the customer would not be contacted.",
            "zh": "因此，我们期望模型将预测否，并且不会联系客户。"
        }
    },
    {
        "translation": {
            "en": "A final useful tool is to rank the importance of each descriptive feature in defining membership of each cluster.",
            "zh": "最后一个有用的工具是在定义每个集群的成员资格时对每个描述性特征的重要性进行排序。"
        }
    },
    {
        "translation": {
            "en": "This indicates that this binning does not accurately represent the real distribution of values in the underlying continuous feature.",
            "zh": "这表明此分箱不能准确表示基础连续要素中值的实际分布。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.5(d)[124] shows one card type to be more present than the others, so the overall entropy is slightly lower, 1.50 bits.",
            "zh": "图4.5（d）[124]显示一种卡类型比其他卡类型更常见，因此整体熵略低，为1.50位。"
        }
    },
    {
        "translation": {
            "en": "The density of the marked hypercube is .",
            "zh": "标记的超立方体的密度为 。"
        }
    },
    {
        "translation": {
            "en": "0.10",
            "zh": "0.10"
        }
    },
    {
        "translation": {
            "en": "We discussed the problem of large weight updates in Chapter 7[311] Section 7.4.2[334], in which we compared the effect of different learning rates and introduced the idea of using learning rate decay.",
            "zh": "我们在第 7 章[311] 第 7.4.2 节[334] 中讨论了大量权重更新的问题，其中我们比较了不同学习率的影响，并引入了使用学习率衰减的思想。"
        }
    },
    {
        "translation": {
            "en": "When a customer used up all the call time in his or her bundle, subsequent call time was referred to as over bundle minutes.",
            "zh": "当客户用完了他或她的捆绑包中的所有呼叫时间时，随后的呼叫时间称为超过捆绑分钟数。"
        }
    },
    {
        "translation": {
            "en": "1. It is appropriate to use a game involving gambling to introduce probability-based machine learning. The origins of probability theory come from attempts to understand gambling and games of chance, in particular, the work of Gerolamo Cardano and the later work of Pierre de Fermat and Blaise Pascal.",
            "zh": "1. 使用涉及赌博的游戏来引入基于概率的机器学习是合适的。概率论的起源来自对赌博和机会游戏的理解，特别是杰罗拉莫·卡尔达诺（Gerolamo Cardano）的工作以及皮埃尔·德·费马（Pierre de Fermat）和布莱斯·帕斯卡（Blaise Pascal）的后期工作。"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C. 2012. Design and analysis of experiments. Wiley.",
            "zh": "蒙哥马利，道格拉斯 C. 2012 年。实验的设计和分析。威利。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.39[506] illustrates the path taken by the error gradients as each error for each time-step is backpropagated through the network.",
            "zh": "图8.39[506]说明了误差梯度所采用的路径，因为每个时间步长的每个误差都通过网络反向传播。"
        }
    },
    {
        "translation": {
            "en": "These tended to be more expensive than the minutes included as part of a customer’s bundle.",
            "zh": "这些往往比客户捆绑包中包含的分钟数更昂贵。"
        }
    },
    {
        "translation": {
            "en": "where At and St are random variables that can be assigned specific states and actions; and the policy, π, returns a probability distribution across the possible actions that an agent can take in a given state.",
            "zh": "其中 At 和 St 是随机变量，可以分配特定的状态和动作;策略 π 返回代理在给定状态下可以采取的可能操作的概率分布。"
        }
    },
    {
        "translation": {
            "en": "The fact that similarity-based models attempt to mimic a way of reasoning that is natural to humans makes them easy to interpret and understand.",
            "zh": "基于相似性的模型试图模仿人类自然的推理方式，这一事实使它们易于解释和理解。"
        }
    },
    {
        "translation": {
            "en": "In Figure 4.19(a)[158] the pruning algorithm considers the subtree under the GENDER node for pruning.",
            "zh": "在图4.19（a）[158]中，修剪算法考虑了GENDER节点下的子树进行修剪。"
        }
    },
    {
        "translation": {
            "en": "continuous function, 766",
            "zh": "连续功能，766"
        }
    },
    {
        "translation": {
            "en": "Special Usage: How often a user or customer used services that an organization considers special in some way in the recent past (for example, has a customer called a customer complaints department in the last month?).",
            "zh": "特殊用途：用户或客户在最近使用组织以某种方式认为特殊的服务的频率（例如，客户在上个月是否致电客户投诉部门？"
        }
    },
    {
        "translation": {
            "en": "The calculations for the probabilities for the ACCOUNT BALANCE feature are made using the equations for the normal and exponential distributions in Table 6.10[271]. The result is that FRAUD = false still has the highest score and will be returned as the prediction for this query.",
            "zh": "使用表6.10[271]中的正态分布和指数分布方程计算账户余额特征的概率。结果是 FRAUD = false 仍然具有最高分，并将作为此查询的预测返回。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.22",
            "zh": "图 4.22"
        }
    },
    {
        "translation": {
            "en": "high risk",
            "zh": "高风险"
        }
    },
    {
        "translation": {
            "en": "The clustering in Figure 10.4(h)[606] is particularly unlucky, as one of the clusters has remained empty!4",
            "zh": "图10.4（h）[606]中的聚类特别不走运，因为其中一个聚类仍然是空的！4"
        }
    },
    {
        "translation": {
            "en": "However, to do this summing out, we must know the distribution for the unknown parent, which in turn requires us to sum out the parents of the parent, and so on if necessary.",
            "zh": "但是，要进行这种求和，我们必须知道未知父项的分布，这反过来又要求我们求和父项的亲项，必要时依此类推。"
        }
    },
    {
        "translation": {
            "en": "This, however, can result in massive, and frequently needless, loss of data.",
            "zh": "但是，这可能会导致大量且经常不必要的数据丢失。"
        }
    },
    {
        "translation": {
            "en": "Bibliography",
            "zh": "书目"
        }
    },
    {
        "translation": {
            "en": "The reduction from 16 to 7 probabilities to represent this domain may not seem to achieve much, but there are two things to bear in mind.",
            "zh": "从 16 个概率减少到 7 个概率来表示这个领域似乎并没有取得多大成就，但有两件事需要牢记。"
        }
    },
    {
        "translation": {
            "en": "The appropriate kernel function for a particular prediction model should be selected by experimenting with different options. It is best to start with a simple linear or low-degree polynomial kernel function and move to more complex kernel functions only if good performance cannot be achieved with this.",
            "zh": "应通过试验不同的选项来选择特定预测模型的适当核函数。最好从简单的线性或低阶多项式核函数开始，只有在无法实现良好性能时才转向更复杂的核函数。"
        }
    },
    {
        "translation": {
            "en": "𝒟 denotes a dataset.",
            "zh": "D 表示数据集。"
        }
    },
    {
        "translation": {
            "en": "SS-IN measures the solids coming into the plant per day; SED-IN measures the sediment coming into the plant per day; COND-IN measures the electrical conductivity of the water coming into the plant.34 The features SS-OUT, SED-OUT, and COND-OUT are the corresponding measurements for the water flowing out of the plant.",
            "zh": "SS-IN测量每天进入工厂的固体;SED-IN测量每天进入工厂的沉积物;COND-IN测量进入工厂的水的电导率.34 SS-OUT、SED-OUT 和 COND-OUT 功能是流出工厂的水的相应测量值。"
        }
    },
    {
        "translation": {
            "en": "Bellman, R. E. 1957b. A markov decision process. Journal of Mathematical Mechanics 6: 679–684.",
            "zh": "贝尔曼， R. E. 1957b.马尔可夫决策过程。数学力学杂志 6：679–684。"
        }
    },
    {
        "translation": {
            "en": "Second, in the vast majority of machine learning projects, the training set represents only a small sample of the possible set of instances in the domain.",
            "zh": "其次，在绝大多数机器学习项目中，训练集仅代表域中可能实例集的一小部分样本。"
        }
    },
    {
        "translation": {
            "en": "invalid data, 63, 94",
            "zh": "无效数据， 63， 94"
        }
    },
    {
        "translation": {
            "en": "A dataset showing participants’ responses to viewing positive and negative images measured on the EEG P20 and P45 potentials.",
            "zh": "一个数据集，显示参与者对观看在 EEG P20 和 P45 电位上测量的正负图像的反应。"
        }
    },
    {
        "translation": {
            "en": "Goldberg, Yoav. 2017. Neural network methods for natural language processing. Synthesis lectures on human language technology. Morgan and Claypool.",
            "zh": "戈德堡，约夫。2017. 自然语言处理的神经网络方法.关于人类语言技术的综合讲座。摩根和克莱普尔。"
        }
    },
    {
        "translation": {
            "en": "replay memory, 671",
            "zh": "重播记忆，671"
        }
    },
    {
        "translation": {
            "en": "An analytics consultant has been hired by a major hospital to build a predictive model that predicts the likelihood that a patient at a heart disease clinic will suffer from tachycardia in the month following a visit to the clinic.",
            "zh": "一家大医院聘请了一名分析顾问来建立一个预测模型，该模型可以预测心脏病诊所的患者在就诊后的一个月内患心动过速的可能性。"
        }
    },
    {
        "translation": {
            "en": "For example, Wyh was involved once in the generation of y3 whereas Whh and Whx were involved three times.",
            "zh": "例如，Wyh 参与了 y3 的生成，而 Whh 和 Whx 参与了三次。"
        }
    },
    {
        "translation": {
            "en": "This would make the training process likely to become stuck in something approaching a local minimum.",
            "zh": "这将使训练过程可能会陷入接近局部最小值的范围内。"
        }
    },
    {
        "translation": {
            "en": "11.5   Summary",
            "zh": "11.5 小结"
        }
    },
    {
        "translation": {
            "en": "1.4   A diagram of the CRISP-DM process that shows the six key phases and indicates the important relationships between them.",
            "zh": "1.4 CRISP-DM过程图，显示了六个关键阶段，并指出了它们之间的重要关系。"
        }
    },
    {
        "translation": {
            "en": "In Table 9.17[572] we have included precision and recall measures for each target level. Precision and recall are calculated in almost exactly the same way for multinomial problems as for binary problems. Abandoning the notion of positive and negative target levels, we get",
            "zh": "在表9.17[572]中，我们列出了每个目标水平的精确度和召回率措施。多项式问题的精确度和召回率的计算方式与二元问题几乎完全相同。摒弃正负目标水平的概念，我们得到"
        }
    },
    {
        "translation": {
            "en": "YEARSINCURRENTEMPLOYMENT",
            "zh": "年限在职"
        }
    },
    {
        "translation": {
            "en": "3. The predictive task in this question is to predict the level of corruption in a country based on a range of macroeconomic and social features. The table below lists some countries described by the following descriptive features:",
            "zh": "3. 本问题的预测任务是根据一系列宏观经济和社会特征预测一个国家的腐败程度。下表列出了以下描述性特征所描述的一些国家/地区："
        }
    },
    {
        "translation": {
            "en": "AlexNet is one of the most famous convolutional networks in the history of deep learning.",
            "zh": "AlexNet是深度学习史上最著名的卷积网络之一。"
        }
    },
    {
        "translation": {
            "en": "The relevant smoothed probabilities, from Table 6.8[269], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each target levels.",
            "zh": "朴素贝叶斯预测模型需要表 6.8[269] 中的相关平滑概率，以便对 CH = 付费、GC = 担保人、ACC = 免费的查询进行预测，并计算每个目标水平的分数。"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, let’s return to the example query instance for the meningitis diagnosis problem, where HEADACHE = true, FEVER = true, and VOMITING = false.",
            "zh": "为了说明这一点，让我们回到脑膜炎诊断问题的示例查询实例，其中 HEADACHE = true，FEVER = true，VOMITING = false。"
        }
    },
    {
        "translation": {
            "en": "These are the descriptive features in this dataset, and the target feature, TYPE, indicates whether the subject was viewing a positive or a negative image.",
            "zh": "这些是此数据集中的描述性特征，目标特征 TYPE 指示受试者是查看正图像还是负图像。"
        }
    },
    {
        "translation": {
            "en": "The range-normalized hourly samples of ambient factors and full load electrical power output of a combined cycle power plant, rounded to two decimal places, and with the (binned) target feature represented using one-hot encoding.",
            "zh": "联合循环电厂的环境因子和满负荷电力输出的范围归一化小时样本，四舍五入到小数点后两位，并使用单热编码表示（分档）目标特征。"
        }
    },
    {
        "translation": {
            "en": "The structure of a profit matrix.",
            "zh": "利润矩阵的结构。"
        }
    },
    {
        "translation": {
            "en": "The updated version of Table 5.6[206] once we have applied range normalization to the SALARY and AGE features in the dataset and to the query instance.",
            "zh": "表 5.6[206] 的更新版本，一旦我们将范围归一化应用于数据集中的 SALARY 和 AGE 特征以及查询实例。"
        }
    },
    {
        "translation": {
            "en": "Ross confirmed with Grace and Kate that these were valid outliers—for example, some handsets are given away for free, and some customers just make a lot of calls.",
            "zh": "罗斯向格蕾丝和凯特证实，这些都是有效的异常值——例如，一些手机是免费赠送的，有些客户只是打了很多电话。"
        }
    },
    {
        "translation": {
            "en": "A scatter plot of this dataset is shown in Figure 7.14[349], in which the overlap between the different types of generator in this dataset is clearly visible.",
            "zh": "该数据集的散点图如图 7.14[349] 所示，其中该数据集中不同类型的生成器之间的重叠清晰可见。"
        }
    },
    {
        "translation": {
            "en": "Weight",
            "zh": "重量"
        }
    },
    {
        "translation": {
            "en": "Ross strongly considered removing these features entirely.",
            "zh": "Ross 强烈考虑完全删除这些功能。"
        }
    },
    {
        "translation": {
            "en": "The difference in how ∂ℰ/∂ak is calculated for output and hidden neurons is how Equation (8.14)[408] generalizes over all the neurons in the network.",
            "zh": "输出神经元和隐藏神经元的 ∂E/∂ak 计算方式的差异在于方程 （8.14）[408] 如何推广网络中的所有神经元。"
        }
    },
    {
        "translation": {
            "en": "We use subscripts on uppercase letters to iterate over events. So, ∑iP(Xi) should be interpreted as summing over the set of events that are a complete assignment to the features in X (i.e., all the possible combinations of value assignments to the features in X).",
            "zh": "我们在大写字母上使用下标来迭代事件。因此，∑iP（习） 应该被解释为对 X 中特征的完整赋值（即对 X 中特征的所有可能值赋值组合）的事件集求和。"
        }
    },
    {
        "translation": {
            "en": "filter dimension, 486",
            "zh": "过滤器尺寸，486"
        }
    },
    {
        "translation": {
            "en": "This property of weighted sum calculations can result in unstable dynamics in both the forward and backward pass of the backpropagation algorithm because weighted sum calculations are used in both these phases; in the forward pass the calculation of the z value for each neuron is done using a weighted sum, and in the backward pass the calculation of a δ for a neuron includes the calculation of the term ∂ℰ/∂ak which is a weighted sum of the δs backpropagated to that neuron (see Equation 8.22[412]).",
            "zh": "加权和计算的这种特性可能导致反向传播算法的前向和后向传递都不稳定的动态，因为在这两个阶段都使用了加权和计算;在前向传递中，使用加权和计算每个神经元的 z 值，在向后传递中，神经元的δ计算包括项 ∂E/∂ak 的计算，它是反向传播到该神经元的 δs 的加权和（参见等式 8.22[412]）。"
        }
    },
    {
        "translation": {
            "en": "2. Have identified any data quality issues within the ABT, in particular, missing values, irregular cardinality, and outliers.",
            "zh": "2. 已发现 ABT 中的任何数据质量问题，特别是缺失值、不规则基数和异常值。"
        }
    },
    {
        "translation": {
            "en": "From the histograms in Figure 3.1[58], we see that all the continuous features except for INCOME and FRAUD FLAG seem to follow an exponential distribution pretty closely. INCOME is interesting as it seems to follow what looks like a normal distribution except that there is one large bar at about 0. The distribution of the FRAUD FLAG feature that can be seen in its histogram is not typical of a continuous feature.",
            "zh": "从图 3.1[58] 中的直方图中，我们看到除了 INCOME 和 FRAUD FLAG 之外的所有连续特征似乎都非常接近地遵循指数分布。INCOME 很有趣，因为它似乎遵循看起来像正态分布的东西，除了在大约 0 处有一个大柱。在其直方图中可以看到的 FRAUD FLAG 特征的分布不是典型的连续特征。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features tell us three pieces of information about the mortgage: the OCCUPATION (which can be professional or industrial) and AGE of the applicant and the ratio between the applicant’s salary and the amount borrowed (LOAN-SALARY RATIO).",
            "zh": "描述性特征告诉我们有关抵押贷款的三条信息：申请人的职业（可以是专业或工业）和年龄，以及申请人的工资与借款金额之间的比率（贷款-工资比率）。"
        }
    },
    {
        "translation": {
            "en": "In the subset generation component of forward sequential selection, the successors of the current best feature subset are the set of feature subsets that can be generated from the current best subset by adding just a single extra feature.",
            "zh": "在前向顺序选择的子集生成组件中，当前最佳特征子集的后继者是一组特征子集，只需添加一个额外特征即可从当前最佳子集生成。"
        }
    },
    {
        "translation": {
            "en": "For example, when wrapper-based feature selection techniques are used, a validation set is required in order to evaluate the performance of the different feature subsets on data not used in training.",
            "zh": "例如，当使用基于包装器的特征选择技术时，需要验证集来评估不同特征子集对训练中未使用的数据的性能。"
        }
    },
    {
        "translation": {
            "en": "9.1 Big Idea",
            "zh": "9.1 大创意"
        }
    },
    {
        "translation": {
            "en": "The points in this scatter plot are arranged in a broadly linear pattern diagonally across the scatter plot.",
            "zh": "此散点图中的点在散点图中以大致的线性模式对角线排列。"
        }
    },
    {
        "translation": {
            "en": "Chandola, Varun, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys (CSUR) 41 (3): 15.",
            "zh": "钱多拉、瓦伦、阿林丹·班纳吉和维平·库马尔。2009. 异常检测：一项调查。ACM 计算调查 （CSUR） 41 （3）： 15."
        }
    },
    {
        "translation": {
            "en": "This differential means that the neurons in the first hidden layer will learn more slowly than the neurons output layer.",
            "zh": "这种差异意味着第一个隐藏层中的神经元将比神经元输出层学习得更慢。"
        }
    },
    {
        "translation": {
            "en": "We can use exactly the same idea to evaluate the impact of predictive models.",
            "zh": "我们可以使用完全相同的想法来评估预测模型的影响。"
        }
    },
    {
        "translation": {
            "en": "Table 4.2",
            "zh": "表 4.2"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming that the target output for time tt = [0,1], calculate the δ value for each neuron in the network.",
            "zh": "（b） 假设时间 tt = [0,1] 的目标输出，计算网络中每个神经元的δ值。"
        }
    },
    {
        "translation": {
            "en": "independence, 256, 302",
            "zh": "独立， 256， 302"
        }
    },
    {
        "translation": {
            "en": "Unfortunately, in more realistic datasets, finding a feature as powerful as the SUSPICIOUS WORDS feature is very rare.",
            "zh": "不幸的是，在更现实的数据集中，找到像 SUSPICIOUS WORDS 功能这样强大的功能非常罕见。"
        }
    },
    {
        "translation": {
            "en": "The customer billing records stored in the AT billing database, where records stretch back over a time horizon of five years",
            "zh": "存储在 AT 计费数据库中的客户计费记录，其中记录可以追溯到五年的时间范围"
        }
    },
    {
        "translation": {
            "en": "MOTORINS: Whether the customer holds a motor insurance policy with the company (yes or no)",
            "zh": "MOTORINS：客户是否持有公司的汽车保险单（是或否）"
        }
    },
    {
        "translation": {
            "en": "21. This assumption of treating d2 as the first example permits us to use the original w7,5 = −0.09 in our example calculation rather than the updated value for the weight that would be used if d1 had already been processed and the weights updated accordingly.",
            "zh": "21. 将 d2 视为第一个示例的假设允许我们在示例计算中使用原始 w7,5 = −0.09，而不是在 d1 已经处理并相应更新权重时将使用的权重更新值。"
        }
    },
    {
        "translation": {
            "en": "Examples of parametric models include the naive Bayes and Bayesian network models in Chapter 6[243] and the simple linear and logistic regression models in Chapter 7[311].",
            "zh": "参数模型的例子包括第6章[243]中的朴素贝叶斯和贝叶斯网络模型，以及第7章[311]中的简单线性和逻辑回归模型。"
        }
    },
    {
        "translation": {
            "en": "The domain concepts in this instance will be concepts from within the insurance domain that are likely to be important in determining whether a claim is fraudulent.",
            "zh": "本例中的域概念是保险域内的概念，这些概念对于确定索赔是否具有欺诈性可能很重要。"
        }
    },
    {
        "translation": {
            "en": "The structure of a confusion matrix for a multinomial prediction problem with l target levels.",
            "zh": "具有 l 个目标水平的多项式预测问题的混淆矩阵结构。"
        }
    },
    {
        "translation": {
            "en": "The histogram for this feature has an unusual shape that results in the unusual minimum, 1st quartile, and median values (see Figure 12.2(g)[695]).",
            "zh": "该特征的直方图具有不寻常的形状，导致不寻常的最小值、第一四分位数和中值（参见图 12.2（g）[695]）。"
        }
    },
    {
        "translation": {
            "en": "p-value, 333",
            "zh": "p 值，333"
        }
    },
    {
        "translation": {
            "en": "10.12   (a) A plot of a reduced version of the mobile phone customer dataset given in Table 10.1[604]. (b)–(d) show details of several iterations of the AHC algorithm.",
            "zh": "10.12 （a） 表10.1[604]中给出的移动电话客户数据集的简化版图。（b）–（d） 显示了 AHC 算法的几次迭代的详细信息。"
        }
    },
    {
        "translation": {
            "en": "9.18   A sample test set with model predictions for a bacterial species identification problem.",
            "zh": "9.18 具有细菌物种识别问题模型预测的样本测试集。"
        }
    },
    {
        "translation": {
            "en": "The confusion matrix for the logistic regression model that distinguished between only the spiral galaxy types (classification accuracy: 68.225%, average class accuracy: 56.621%).",
            "zh": "仅区分螺旋星系类型的逻辑回归模型的混淆矩阵（分类准确率：68.225%，平均分类准确率：56.621%）。"
        }
    },
    {
        "translation": {
            "en": "26. The data used in this question has been artificially generated for this book. Mac Namee et al. (2002) is, however, a good example of prediction models used to help doctors select correct drug dosages.",
            "zh": "26. 本问题中使用的数据是为本书人为生成的。然而，Mac Namee等人（2002）是用于帮助医生选择正确药物剂量的预测模型的一个很好的例子。"
        }
    },
    {
        "translation": {
            "en": "Historic call and bill records as well as customer demographic information were stored in a data warehouse.",
            "zh": "历史通话和账单记录以及客户人口统计信息存储在数据仓库中。"
        }
    },
    {
        "translation": {
            "en": "Figure 6.6(c)[275] overlays the multimodal density curve on top of the three weighted normals.",
            "zh": "图6.6（c）[275]将多模态密度曲线叠加在三个加权正线之上。"
        }
    },
    {
        "translation": {
            "en": "Preface to the 2nd Edition",
            "zh": "第二版前言"
        }
    },
    {
        "translation": {
            "en": "The minimal amount of information we need is the relative profit associated with each of the different outcomes (TP, TN, FP, or FN) that can arise when a model makes a prediction.",
            "zh": "我们需要的最少信息量是模型进行预测时可能产生的与每个不同结果（TP、TN、FP 或 FN）相关的相对利润。"
        }
    },
    {
        "translation": {
            "en": "The calculation of Δw7,5 across our four examples.",
            "zh": "在我们的四个示例中计算 Δw7,5。"
        }
    },
    {
        "translation": {
            "en": "9.4.3.1 Receiver operating characteristic curves The receiver operating characteristic index (ROC index), which is based on the receiver operating characteristic curve (ROC curve),12 is a widely used performance measure that is calculated using prediction scores.",
            "zh": "9.4.3.1 受试者工作特征曲线 受试者工作特征指数（ROC指数）以受试者工作特征曲线（ROC曲线）为基础，12是一种广泛使用的性能指标，使用预测分数进行计算。"
        }
    },
    {
        "translation": {
            "en": "Each of these errors is then backpropagated through the unrolled network.",
            "zh": "然后，这些错误中的每一个都会通过展开的网络进行反向传播。"
        }
    },
    {
        "translation": {
            "en": "10. The paradox of the false positive states that in order to make predictions about a rare event, the model has to be at least as accurate as the event is rare (i.e., the probability of the model making an error has to be less than the probability of the rare event occurring) or there is a significant chance of false positive predictions (i.e., predicting the event when it is not the case). Doctorow (2010) provides an interesting discussion of this phenomenon.",
            "zh": "10. 误报的悖论指出，为了对罕见事件进行预测，模型必须至少与事件的准确性一样准确（即，模型出错的概率必须小于罕见事件发生的概率），或者存在误报预测的很大几率（即 在事实并非如此时预测事件）。Doctorow（2010）对这种现象进行了有趣的讨论。"
        }
    },
    {
        "translation": {
            "en": "The resulting histogram is called a density histogram because the height of each bar represents how densely the instances in the dataset that fall within the interval are packed into the area of the bar.",
            "zh": "生成的直方图称为密度直方图，因为每个条形的高度表示数据集中属于区间内的实例填充到条形区域中的密度。"
        }
    },
    {
        "translation": {
            "en": "Tree pruning identifies and removes subtrees within a decision tree that are likely to be due to noise and sample variance in the training set used to induce it.",
            "zh": "树修剪识别并删除决策树中的子树，这些子树可能是由于用于诱导决策树的训练集中的噪声和样本方差造成的。"
        }
    },
    {
        "translation": {
            "en": "scalar, 771",
            "zh": "标量，771"
        }
    },
    {
        "translation": {
            "en": "In this example, Model 1 approaches perfect performance, Model 4 is barely better than random guessing, and Models 2 and 3 sit somewhere in between these two extremes.",
            "zh": "在此示例中，模型 1 接近完美性能，模型 4 仅比随机猜测好一点，而模型 2 和 3 介于这两个极端之间。"
        }
    },
    {
        "translation": {
            "en": "where St and St+1 are random variables to which the states at time t and t + 1 are assigned. The full dynamics of a Markov process can be captured in a transition matrix",
            "zh": "其中 St 和 St+1 是随机变量，将时间 t 和 t + 1 的状态分配给它们。马尔可夫过程的全部动力学可以在跃迁矩阵中捕获"
        }
    },
    {
        "translation": {
            "en": "In probability a domain of interest is represented by a set of random variables.",
            "zh": "在概率中，感兴趣的域由一组随机变量表示。"
        }
    },
    {
        "translation": {
            "en": "5.4.6 Feature Selection",
            "zh": "5.4.6 功能选择"
        }
    },
    {
        "translation": {
            "en": "joint probability distribution, 247, 761",
            "zh": "联合概率分布，247,761"
        }
    },
    {
        "translation": {
            "en": "In the second iteration of the algorithm, the subtree under the STABLE-TEMP node is considered for pruning (highlighted in Figure 4.19(b)[158]).",
            "zh": "在算法的第二次迭代中，考虑对 STABLE-TEMP 节点下的子树进行修剪（在图 4.19（b）[158] 中突出显示）。"
        }
    },
    {
        "translation": {
            "en": "value-based reinforcement learning, 676",
            "zh": "基于价值的强化学习，676"
        }
    },
    {
        "translation": {
            "en": "In this situation, knowing that someone has meningitis makes the events of them having a headache and having a fever independent of each other.",
            "zh": "在这种情况下，知道某人患有脑膜炎会使他们头痛和发烧的事件彼此独立。"
        }
    },
    {
        "translation": {
            "en": "For these reasons we felt the time was right for a second edition of the book.",
            "zh": "出于这些原因，我们觉得现在是出版这本书第二版的好时机。"
        }
    },
    {
        "translation": {
            "en": "This is unfeasible, however, as for d features, there are 2d different possible feature subsets, which is far too many to evaluate unless d is very small.",
            "zh": "这是不可行的，但是，对于 d 特征，存在 2d 不同的可能特征子集，除非 d 非常小，否则无法评估。"
        }
    },
    {
        "translation": {
            "en": "The process of using an unsupervised auto-encoder network to generate a feature representation used to train a supervised model.",
            "zh": "使用无监督自动编码器网络生成用于训练监督模型的特征表示的过程。"
        }
    },
    {
        "translation": {
            "en": "The ability of the model to distinguish between clockwise (spiral_cw) and anti-clockwise (spiral_acw) spiral galaxies, however, is extremely poor.",
            "zh": "然而，该模型区分顺时针（spiral_cw）和逆时针（spiral_acw）螺旋星系的能力极差。"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.5 and that the desired output for this input is 0.9:",
            "zh": "（a） 假设处理神经元使用逻辑激活函数，网络的输入是神经元 1 = 0.5，并且该输入的期望输出是 0.9："
        }
    },
    {
        "translation": {
            "en": "Datasets",
            "zh": "数据"
        }
    },
    {
        "translation": {
            "en": "Table 4.8",
            "zh": "表 4.8"
        }
    },
    {
        "translation": {
            "en": "This algorithm can also handle continuous target features.",
            "zh": "此算法还可以处理连续目标特征。"
        }
    },
    {
        "translation": {
            "en": "Loh, Wei-Yin. 2011. Classification and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1 (1): 14–23.",
            "zh": "Loh， Wei-Yin.2011. 分类和回归树.Wiley跨学科评论：数据挖掘和知识发现1（1）：14-23。"
        }
    },
    {
        "translation": {
            "en": "In this figure, A indicates the central tendency of the dataset in Figure 5.15(c)[219], and the ellipses plot the Mahalanobis distance contours that the distances from A to the instances B and C lie on.",
            "zh": "在该图中，A 表示图 5.15（c）[219] 中数据集的中心趋势，椭圆绘制了从 A 到实例 B 和 C 的距离所在的马氏距离等值线。"
        }
    },
    {
        "translation": {
            "en": "720,000",
            "zh": "720,000"
        }
    },
    {
        "translation": {
            "en": "Ideally, we want to descend the true error gradient for the entire dataset.",
            "zh": "理想情况下，我们希望降低整个数据集的真实误差梯度。"
        }
    },
    {
        "translation": {
            "en": "factorization, 256, 302",
            "zh": "因式分解， 256， 302"
        }
    },
    {
        "translation": {
            "en": "sample space, 246, 757, 758",
            "zh": "样本空间， 246， 757， 758"
        }
    },
    {
        "translation": {
            "en": "standard normal distribution, 62",
            "zh": "标准正态分布，62"
        }
    },
    {
        "translation": {
            "en": "This operation is used in the input gate to update the cell state (see Equation (8.113)[511]).",
            "zh": "此操作在输入门中用于更新单元状态（参见公式（8.113）[511]）。"
        }
    },
    {
        "translation": {
            "en": "11.2.5   Temporal-Difference Learning",
            "zh": "11.2.5 时差学习"
        }
    },
    {
        "translation": {
            "en": "FIBERMAG_U/G/R/I/Z",
            "zh": "FIBERMAG_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The agent then updates its current state (Line 13[658]), s 0 = s1 = 0-2, and returns to the beginning of the algorithm to choose the next action according to the policy.",
            "zh": "然后，代理更新其当前状态（第 13 行[658]），s 0 = s1 = 0-2，并返回算法的开头以根据策略选择下一个操作。"
        }
    },
    {
        "translation": {
            "en": "8.33   Illustration of the organization of a set of neurons that share weights (use the same filter) and their local receptive fields such that together the receptive fields cover the entirety of the input image.",
            "zh": "8.33 说明一组神经元的组织，这些神经元共享权重（使用相同的滤波器）及其局部感受野，使得感受野一起覆盖整个输入图像。"
        }
    },
    {
        "translation": {
            "en": "Note that in Figure 8.38[504] we have shown the network generating an output for each input it receives.",
            "zh": "请注意，在图8.38[504]中，我们显示了网络为它接收的每个输入生成输出。"
        }
    },
    {
        "translation": {
            "en": "18. One note of caution: the Jaccard similarity index is undefined for pairs of instances in which all the features manifest co-absence, because this leads to a division by zero.",
            "zh": "18. 需要注意的是：对于所有特征都表现出共缺的实例对，Jaccard 相似性指数是未定义的，因为这会导致除以零。"
        }
    },
    {
        "translation": {
            "en": "For example, the naive Bayes model produces probabilities that are converted into categorical predictions using the maximum a posteriori probability approach, and logistic regression models produce a probability for the positive target level that is converted into a categorical prediction using a threshold.",
            "zh": "例如，朴素贝叶斯模型生成的概率使用最大后验概率方法转换为分类预测，逻辑回归模型生成正目标水平的概率，该概率使用阈值转换为分类预测。"
        }
    },
    {
        "translation": {
            "en": "grid world, 659",
            "zh": "网格世界，659"
        }
    },
    {
        "translation": {
            "en": "Near-sighted parents, because of their poor night vision, tend to favor the use of night-lights to help them find their way around their children’s bedrooms at night.",
            "zh": "近视的父母，由于他们的夜视能力差，往往倾向于使用夜灯来帮助他们在晚上找到孩子卧室的路。"
        }
    },
    {
        "translation": {
            "en": "redundant features, 227",
            "zh": "冗余功能，227"
        }
    },
    {
        "translation": {
            "en": "Based on his assessment of the current situation within AT, Ross developed a list of ways that predictive analytics could help address the customer churn problem at AT. These included finding answers to the following questions:",
            "zh": "根据对 AT 当前情况的评估，Ross 列出了预测分析可以帮助解决 AT 客户流失问题的方法。其中包括寻找以下问题的答案："
        }
    },
    {
        "translation": {
            "en": "However, recurrent networks are quite flexible and can be deployed in different scenarios.",
            "zh": "但是，循环网络非常灵活，可以部署在不同的场景中。"
        }
    },
    {
        "translation": {
            "en": "Tene, Omer, and Jules Polonetsky. 2013. Big data for all: Privacy and user control in the age of analytics. Northwestern Journal of Technology and Intellectual Property 11 (5): 239–247.",
            "zh": "Tene、Omer 和 Jules Polonetsky。2013. 人人享有大数据：分析时代的隐私和用户控制。西北技术与知识产权杂志 11 （5）： 239–247."
        }
    },
    {
        "translation": {
            "en": "(e) Inter-quartile range",
            "zh": "（e） 四分位距"
        }
    },
    {
        "translation": {
            "en": "A selection of the models developed during the gradient descent process for the EEG dataset from Table 7.10[355]. The final panel shows the decision surface generated.",
            "zh": "表7.10[355]中脑电图数据集的梯度下降过程中开发的模型选择。最后一个面板显示生成的决策面。"
        }
    },
    {
        "translation": {
            "en": "41. We are using this smaller 6-by-6 image rather than the full 28-by-28 MNIST digit image dimensions to simplify the illustration.",
            "zh": "41. 我们使用这个较小的 6 x 6 图像，而不是完整的 28 x 28 MNIST 数字图像尺寸来简化插图。"
        }
    },
    {
        "translation": {
            "en": "McCulloch, Warren S., and Walter Pitts. 1943. A logical calculus of the ideas immanent in the nervous system. Bulletin of Mathematical Biophysics 5: 115–133.",
            "zh": "McCulloch、Warren S. 和 Walter Pitts。1943. 神经系统内在思想的逻辑演算.数学生物物理学通报5：115-133。"
        }
    },
    {
        "translation": {
            "en": "The outputs of the final layer in the encoder, the bottleneck layer, can be used as a new transformed representation of the original dataset.",
            "zh": "编码器中最后一个层（瓶颈层）的输出可用作原始数据集的新变换表示。"
        }
    },
    {
        "translation": {
            "en": "(c) 10 neurons in the output layer",
            "zh": "（c） 输出层中有 10 个神经元"
        }
    },
    {
        "translation": {
            "en": "Instead, it is only possible to see the ground at her feet to within about a three-foot radius.",
            "zh": "相反，只能看到她脚下的地面，半径在大约三英尺以内。"
        }
    },
    {
        "translation": {
            "en": "hyperplane, 197, 197, 362",
            "zh": "超平面， 197， 197， 362"
        }
    },
    {
        "translation": {
            "en": "8.3.3   Backpropagation: Updating the Weights in a Network",
            "zh": "8.3.3 反向传播：更新网络中的权重"
        }
    },
    {
        "translation": {
            "en": "This would give a total of 195 different states.",
            "zh": "这将总共提供 195 个不同的州。"
        }
    },
    {
        "translation": {
            "en": "0.00730080",
            "zh": "0.00730080"
        }
    },
    {
        "translation": {
            "en": "A spectrograph is a device that disperses the light emitted by an object into different wavelengths and measures the intensity of the emission of each wavelength—this set of measures is referred to as a spectrogram.",
            "zh": "光谱仪是一种将物体发出的光分散到不同波长并测量每个波长的发射强度的装置——这组测量称为光谱图。"
        }
    },
    {
        "translation": {
            "en": "numeric data, 34",
            "zh": "数值数据， 34"
        }
    },
    {
        "translation": {
            "en": "The reason we multiply by the Kronecker delta function is to ensure that in calculating the score for each of the candidate target levels, we include only the weights for the instances whose target feature value matches that level.",
            "zh": "我们乘以 Kronecker delta 函数的原因是确保在计算每个候选目标级别的分数时，我们仅包括目标特征值与该级别匹配的实例的权重。"
        }
    },
    {
        "translation": {
            "en": "Second, a process was put in place that allowed manual review by SDSS experts to be included in the galaxy classification process.",
            "zh": "第二，建立了一个程序，允许SDSS专家的人工审查纳入星系分类过程。"
        }
    },
    {
        "translation": {
            "en": "These recurrent models use a feedback loop to maintain, evolve, and propagate a representation of the pertinent information within the sequence history.",
            "zh": "这些循环模型使用反馈回路来维护、发展和传播序列历史中相关信息的表示。"
        }
    },
    {
        "translation": {
            "en": "Literary Digest never recovered from the reputational damage this error in prediction caused and went out of business soon afterward.",
            "zh": "《文学文摘》从未从这一预测错误造成的声誉损害中恢复过来，不久后就倒闭了。"
        }
    },
    {
        "translation": {
            "en": "By contrast in a network using logistic activation functions, the vast majority of neurons will be active for all inputs.",
            "zh": "相比之下，在使用逻辑激活函数的网络中，绝大多数神经元将对所有输入都处于活动状态。"
        }
    },
    {
        "translation": {
            "en": "Bootstrapping approaches are preferred over cross validation approaches in contexts with very small datasets (approximately fewer than 300 instances).",
            "zh": "在数据集非常小（大约少于 300 个实例）的上下文中，引导方法优于交叉验证方法。"
        }
    },
    {
        "translation": {
            "en": "trapezoidal method, 562, 593",
            "zh": "梯形法， 562， 593"
        }
    },
    {
        "translation": {
            "en": "Equation (8.68)[466] shows that all the terms that involve a 0 element from t disappear, and the loss simplifies to the negative log of the predicted probability for the true class.",
            "zh": "方程（8.68）[466]表明，所有涉及t的0元素的项都消失了，并且损失简化为真实类的预测概率的负对数。"
        }
    },
    {
        "translation": {
            "en": "4.10   Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) for the candidate ELEVATION thresholds:≥ 750, ≥1,350, ≥2,250 and ≥4,175.",
            "zh": "4.10 候选 ELEVATION 阈值的分区集 （Part.）、熵、余数 （Rem.） 和信息增益 （Info. Gain）：≥ 750、≥1,350、≥2,250 和 ≥4,175。"
        }
    },
    {
        "translation": {
            "en": "group think, 158",
            "zh": "群体思考，158"
        }
    },
    {
        "translation": {
            "en": "An interesting alternative to using an application-based solution for building predictive data analytics models is to use a programming language. Two of the most commonly used programming languages for predictive data analytics are R and Python.15 Building predictive data analytics models using a language like R or Python is not especially difficult. For example, the following simple lines of code use the R language to build a predictive model for a simple task:",
            "zh": "使用基于应用程序的解决方案来构建预测性数据分析模型的一个有趣的替代方法是使用编程语言。预测数据分析最常用的两种编程语言是 R 和 Python.15 使用 R 或 Python 等语言构建预测数据分析模型并不是特别困难。例如，以下简单的代码行使用 R 语言为简单任务生成预测模型："
        }
    },
    {
        "translation": {
            "en": "4.8   The decision tree after the data has been split using ELEVATION.",
            "zh": "4.8 使用 ELEVATION 拆分数据后的决策树。"
        }
    },
    {
        "translation": {
            "en": "Popular batch sizes include 32, 64, 128, and even 256 examples.",
            "zh": "流行的批量大小包括 32、64、128 甚至 256 个示例。"
        }
    },
    {
        "translation": {
            "en": "In other words, this is the rate of change of the softmax calculation for the activation of the output neuron for the true class with respect to the logits of a neuron in the output layer.",
            "zh": "换言之，这是 softmax 计算的 softmax 计算值相对于输出层中神经元的对数，用于激活真类的输出神经元。"
        }
    },
    {
        "translation": {
            "en": "Table 1.4[10] illustrates this; the blanked-out columns in the table indicate the models that are not consistent with the training data.",
            "zh": "表1.4[10]说明了这一点;表中的空白列表示与训练数据不一致的模型。"
        }
    },
    {
        "translation": {
            "en": "activation function, 386",
            "zh": "激活函数，386"
        }
    },
    {
        "translation": {
            "en": "8.6   The ∂ℰ/∂wi,k calculations for d2 for every weight in the network. We use the neuron index 0 to denote the bias input for each neuron.",
            "zh": "8.6 网络中每个权重的 d2 的 ∂E/∂wi，k 计算。我们使用神经元索引 0 来表示每个神经元的偏差输入。"
        }
    },
    {
        "translation": {
            "en": "Each node in a k-d tree defines a boundary that partitions the feature space along the median value of the feature the data was split on at that node.",
            "zh": "k-d 树中的每个节点都定义了一个边界，该边界沿在该节点上分割数据的特征的中值划分特征空间。"
        }
    },
    {
        "translation": {
            "en": "The data used in this case study can be accessed by performing a simple SQL query at skyserver.sdss3.org/dr9/en/tools/search/sql.asp.",
            "zh": "本案例研究中使用的数据可以通过在 skyserver.sdss3.org/dr9/en/tools/search/sql.asp 执行简单的 SQL 查询来访问。"
        }
    },
    {
        "translation": {
            "en": "If we assume the two predefined weights are w1 = 0.5 and w2 = 3 and the two inputs are input1 = 6 and input2 = 7, then the weighted sum calculation would proceed as follows:",
            "zh": "如果我们假设两个预定义的权重是 w1 = 0.5 和 w2 = 3，并且两个输入是 input1 = 6 和 input2 = 7，那么加权和计算将按如下方式进行："
        }
    },
    {
        "translation": {
            "en": "5.10   The calculations for the weighted k nearest neighbor prediction.",
            "zh": "5.10 加权k最近邻预测的计算。"
        }
    },
    {
        "translation": {
            "en": "Markov decision processes (MDPs) are an attractive mathematical framework within which to reason about decision making scenarios in which outcomes are partly under the control of a decision maker, but also partly random. This has made them an attractive framework for applications ranging from financial modeling, to robot control, to modeling the flow of human conversation. This also makes them ideal for reasoning about reinforcement learning.",
            "zh": "马尔可夫决策过程 （MDP） 是一个有吸引力的数学框架，可以在其中推理决策场景，其中结果部分由决策者控制，但也部分随机。这使它们成为一个有吸引力的框架，适用于从金融建模到机器人控制，再到人类对话流程建模等各种应用。这也使它们成为推理强化学习的理想选择。"
        }
    },
    {
        "translation": {
            "en": "Working with Edwin, Jocelyn reviewed the relevant literature and discovered a number of very informative articles discussing descriptive features that were likely to be useful in classifying galaxy morphologies.12 In particular, a number of interesting features that could be derived from the flux and magnitude measurements already in the SDSS dataset were described in the literature.",
            "zh": "Jocelyn与Edwin合作，回顾了相关文献，并发现了许多内容丰富的文章，这些文章讨论了可能有助于对星系形态进行分类的描述性特征.12特别是，文献中描述了许多有趣的特征，这些特征可以从SDSS数据集中已有的通量和星等测量中得出。"
        }
    },
    {
        "translation": {
            "en": "Bayesian optimal classifier, 254",
            "zh": "贝叶斯最优分类器，254"
        }
    },
    {
        "translation": {
            "en": "FIBERMAGERR_U/G/R/I/Z",
            "zh": "FIBERMAGERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The use limitation principle adds that collected data should not subsequently be used for purposes other than those stated at the time of collection.",
            "zh": "使用限制原则补充说，所收集的数据随后不应用于收集时所述目的以外的目的。"
        }
    },
    {
        "translation": {
            "en": "In the prediction stage, when the model is used to make predictions for new query instances, the distance in the feature space between the query instance and each instance in memory is computed, and the prediction returned by the model is the target feature level of the instance that is nearest to the query in the feature space.",
            "zh": "在预测阶段，当模型用于对新的查询实例进行预测时，计算查询实例与内存中每个实例在特征空间中的距离，模型返回的预测是该实例在特征空间中最接近查询的目标特征级别。"
        }
    },
    {
        "translation": {
            "en": "Plots for activation functions that have been popular in the history of neural networks.",
            "zh": "在神经网络历史上流行的激活函数图。"
        }
    },
    {
        "translation": {
            "en": "Once we get to a leaf node, we simply add the new instance as either the left or the right child of the leaf node.",
            "zh": "一旦我们到达叶节点，我们只需将新实例添加为叶节点的左子节点或右子节点。"
        }
    },
    {
        "translation": {
            "en": "820,000",
            "zh": "820,000"
        }
    },
    {
        "translation": {
            "en": "The hyperplane boundary bisecting a node is defined by the value used to split the descriptive feature at the node.",
            "zh": "将节点一分为二的超平面边界由用于分割节点处的描述性特征的值定义。"
        }
    },
    {
        "translation": {
            "en": "Reed, Russell D., and Robert J. Marks. 1999. Neural smithing: Supervised learning in feedforward artificial networks. MIT Press.",
            "zh": "里德、罗素 D. 和罗伯特 J. 马克斯。1999. 神经锻造：前馈人工网络中的监督学习。麻省理工学院出版社。"
        }
    },
    {
        "translation": {
            "en": "This process is repeated for k iterations, and the average of the individual performance measures, the titular ε0, gives the overall performance of the model.",
            "zh": "此过程重复 k 次迭代，各个性能度量值的平均值（名义 ε0）给出了模型的整体性能。"
        }
    },
    {
        "translation": {
            "en": "So, the full dataset is divided into 5 folds (each containing 200 instances), and five evaluation experiments are performed using 1 fold as the test set and the remaining folds as the training set.",
            "zh": "因此，将完整数据集分为 5 个折叠（每个折叠包含 200 个实例），并使用 1 个折叠作为测试集，其余折叠作为训练集进行 5 个评估实验。"
        }
    },
    {
        "translation": {
            "en": "For example, the relative frequency of the event DICE1 = is simply the count of all the rows in the dataset where DICE1 has a value of divided by the number of rows in the dataset.",
            "zh": "例如，事件 DICE1 = 的相对频率只是数据集中所有行的计数，其中 DICE1 的值除以数据集中的行数。"
        }
    },
    {
        "translation": {
            "en": "Table 7.2[317] shows the calculation of the sum of squared errors for the candidate model with w[0] = 6.47 and w[1] = 0.62. In this case, the sum of squared errors is equal to 2,837.08.",
            "zh": "表 7.2[317] 显示了 w[0] = 6.47 和 w[1] = 0.62 的候选模型的平方误差和的计算。在本例中，误差的平方和等于 2,837.08。"
        }
    },
    {
        "translation": {
            "en": "One way in which to do this is to calculate the profit or loss that arises from each prediction we make and to use these to determine the overall performance of a model.",
            "zh": "一种方法是计算我们所做的每个预测产生的利润或损失，并使用这些来确定模型的整体性能。"
        }
    },
    {
        "translation": {
            "en": "OBESE, are they overweight",
            "zh": "OBESE，他们超重了吗"
        }
    },
    {
        "translation": {
            "en": "The rule states that approximately 68% of the values in a sample that follows a normal distribution will be within one σ of μ, 95% of the values will be within two σ of μ, and 99.7% of values will be within three σ of μ.",
            "zh": "该规则指出，遵循正态分布的样本中大约 68% 的值将在 μ 的 1 σ 以内，95% 的值将在 μ 的两σ以内，99.7% 的值将在 μ 的三σ以内。"
        }
    },
    {
        "translation": {
            "en": "This identity permits us to rewrite the variance of z in our case study neuron",
            "zh": "这个恒等式允许我们在案例研究神经元中重写 z 的方差"
        }
    },
    {
        "translation": {
            "en": "To address the finer grained 5-level (elliptical, spiral_cw, spiral_acw, spiral_eo, and other) classification task, Jocelyn attempted two approaches.",
            "zh": "为了解决更细粒度的 5 级（椭圆、spiral_cw、spiral_acw、spiral_eo等）分类任务，Jocelyn 尝试了两种方法。"
        }
    },
    {
        "translation": {
            "en": "Schapire, Robert E. 1990. The strength of weak learnability. Machine Learning 5 (2): 197–227.",
            "zh": "夏皮尔，罗伯特 E. 1990 年。学习能力弱的优势。机器学习 5 （2）：197–227。"
        }
    },
    {
        "translation": {
            "en": "model residuals, 164",
            "zh": "模型残差，164"
        }
    },
    {
        "translation": {
            "en": "In a fully connected network nin is the same for all the neurons in a layer, and so for these networks we can set the variance of the distribution from which the weights are sampled on a layer-by-layer basis.",
            "zh": "在完全连接的网络中，nin 对于一层中的所有神经元都是相同的，因此对于这些网络，我们可以逐层设置权重采样的分布方差。"
        }
    },
    {
        "translation": {
            "en": "Euclidean coordinate space, 185",
            "zh": "欧几里得坐标空间，185"
        }
    },
    {
        "translation": {
            "en": "sampling density, 224",
            "zh": "采样密度，224"
        }
    },
    {
        "translation": {
            "en": "deciles, 567, 582",
            "zh": "十分位数，567,582"
        }
    },
    {
        "translation": {
            "en": "In this second path of processing hxt is passed through a layer of tanh units.",
            "zh": "在第二条处理路径中，hxt 通过一层 tanh 单元。"
        }
    },
    {
        "translation": {
            "en": "The blindfold, however, is electronic and controlled by the scout leader administering the test.",
            "zh": "然而，眼罩是电子的，由管理测试的侦察队长控制。"
        }
    },
    {
        "translation": {
            "en": "The basic process for evaluating the effectiveness of predictive models is simple.",
            "zh": "评估预测模型有效性的基本过程很简单。"
        }
    },
    {
        "translation": {
            "en": "(e) P(MENINGITIS | FEVER = true,VOMITING = false)",
            "zh": "（e） P（脑膜炎 |FEVER = 真，VOMITING = 假）"
        }
    },
    {
        "translation": {
            "en": "Fraction of votes for don’t know category",
            "zh": "不知道类别的投票分数"
        }
    },
    {
        "translation": {
            "en": "By using a predictive model that requires only features from maps, the ecological modelers can avoid expensive ground-based or aerial surveys.",
            "zh": "通过使用只需要地图要素的预测模型，生态建模人员可以避免昂贵的地面或航空调查。"
        }
    },
    {
        "translation": {
            "en": "8.4.5.3 Filter hyper-parameters: Dimension, stride, and padding The dimensionality of a feature map generated by applying a filter to an input is determined by the number of neurons used to process the input (each element in a feature map corresponds to the output of one neuron).",
            "zh": "8.4.5.3 过滤器超参数：尺寸、步幅和填充 通过对输入应用过滤器生成的特征图的维数由用于处理输入的神经元数量决定（特征图中的每个元素对应一个神经元的输出）。"
        }
    },
    {
        "translation": {
            "en": "This is an aspect of probability theory with which beginners sometimes struggle.",
            "zh": "这是概率论的一个方面，初学者有时会遇到困难。"
        }
    },
    {
        "translation": {
            "en": "2.7 Exercises",
            "zh": "2.7 练习"
        }
    },
    {
        "translation": {
            "en": "These softmax activations are also shown in Figure 8.28[470].",
            "zh": "这些softmax激活也如图8.28[470]所示。"
        }
    },
    {
        "translation": {
            "en": "Table 3.1",
            "zh": "表 3.1"
        }
    },
    {
        "translation": {
            "en": "The simplest early stopping criterion is to stop partitioning the dataset if the number of training instances in the partition at the node we are processing is less than some threshold, usually around 5% of the overall dataset size.16 This early stopping criterion replaces the base case on Line 1 of the ID3 algorithm.",
            "zh": "最简单的早期停止标准是，如果我们正在处理的节点上的分区中的训练实例数小于某个阈值，通常约为整个数据集大小的 5%，则停止对数据集进行分区。16 此早期停止标准取代了 ID3 算法第 1 行的基本情况。"
        }
    },
    {
        "translation": {
            "en": "One consequence of this is that a feature with a low information gain at the root node (when the full dataset is considered) may have a high information gain score at one of the interior nodes because it is predictive on the subset of instances that are considered at that interior node.",
            "zh": "这样做的一个结果是，在根节点上具有低信息增益的特征（当考虑完整数据集时）可能在其中一个内部节点上具有较高的信息增益分数，因为它对在该内部节点上考虑的实例子集具有预测性。"
        }
    },
    {
        "translation": {
            "en": "3.2   Histograms for six different sets of data, each of which exhibit well-known, common characteristics.",
            "zh": "3.2 六组不同数据集的直方图，每组数据都具有众所周知的共同特征。"
        }
    },
    {
        "translation": {
            "en": "The Markov chain defined by a Bayesian network is ergodic if there are no zero entries in any of the CPTs.30 The third requirement is that the generated states should be independent of each other.",
            "zh": "如果在任何 CPT 中没有零条目，则由贝叶斯网络定义的马尔可夫链是遍历的.30 第三个要求是生成的状态应该彼此独立。"
        }
    },
    {
        "translation": {
            "en": "Cumulative gain, lift, and cumulative lift charts for four different models for the extended email classification test set.",
            "zh": "扩展电子邮件分类测试集的四种不同模型的累计增益、提升和累积提升图表。"
        }
    },
    {
        "translation": {
            "en": "The structure of a data quality plan.",
            "zh": "数据质量计划的结构。"
        }
    },
    {
        "translation": {
            "en": "A.2 Descriptive Statistics for Categorical Features",
            "zh": "A.2 分类特征的描述性统计"
        }
    },
    {
        "translation": {
            "en": "We can now combine the three probabilities just calculated to calculate the overall probability of the target feature taking the level true given the query instance",
            "zh": "现在，我们可以结合刚刚计算的三个概率来计算给定查询实例的目标特征取级为 true 的总体概率"
        }
    },
    {
        "translation": {
            "en": "In this network, Convolutional layer 1 includes Filters 1 and 2 and so generates two feature maps.",
            "zh": "在此网络中，卷积层 1 包括滤波器 1 和 2，因此生成两个特征图。"
        }
    },
    {
        "translation": {
            "en": "The extra piece of evidence means that you need to revise your belief about the likelihoods of where the queen will be once again.",
            "zh": "额外的证据意味着你需要修改你对女王再次出现的可能性的看法。"
        }
    },
    {
        "translation": {
            "en": "support vector machine, 311, 332, 361, 369, 373, 719, 732, 733, 735",
            "zh": "支持向量机， 311， 332， 361， 369， 373， 719， 732， 733， 735"
        }
    },
    {
        "translation": {
            "en": "The type of probabilities we have calculated so far are known as prior probabilities or unconditional probabilities.",
            "zh": "到目前为止，我们计算的概率类型称为先验概率或无条件概率。"
        }
    },
    {
        "translation": {
            "en": "OCC: The customer’s occupation",
            "zh": "OCC：客户的职业"
        }
    },
    {
        "translation": {
            "en": "The selection of which non-evidence node to change can be random or follow a predefined list through which the algorithm iterates.",
            "zh": "选择要更改的非证据节点可以是随机的，也可以遵循算法迭代的预定义列表。"
        }
    },
    {
        "translation": {
            "en": "They don’t have time to manually grade the script before the flight, so they decide to use a k-nearest neighbor model to grade it instead.",
            "zh": "他们没有时间在飞行前手动对脚本进行评分，因此他们决定使用 k 最近邻模型来对其进行评分。"
        }
    },
    {
        "translation": {
            "en": "15. If an ROC curve appears below the diagonal random reference line, this means that the model is consistently making predictions of the positive level for instances that should receive predictions of the negative level and vice versa, and that it could actually be quite a powerful model. This usually arises when a transcription error of some kind has been made and should be investigated.",
            "zh": "15. 如果 ROC 曲线出现在对角线随机参考线下方，这意味着该模型始终如一地对应该接收负水平预测的实例进行正水平预测，反之亦然，并且它实际上可能是一个非常强大的模型。这通常发生在出现某种转录错误时，应该进行调查。"
        }
    },
    {
        "translation": {
            "en": "LNLEXP_U/G/R/I/Z",
            "zh": "LNLEXP_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "For this reason, instance d460 was removed from the ABT.",
            "zh": "因此，实例 d460 已从 ABT 中删除。"
        }
    },
    {
        "translation": {
            "en": "Table 9.21",
            "zh": "表 9.21"
        }
    },
    {
        "translation": {
            "en": "The student-t distribution is symmetric around a single peak.",
            "zh": "student-t 分布围绕单个峰是对称的。"
        }
    },
    {
        "translation": {
            "en": "We have included the bias term w0 in this filter in order to highlight that although the filter now has three dimensions, there is still only one bias term.",
            "zh": "我们在此滤波器中包含了偏置项 w0，以强调尽管滤波器现在具有三个维度，但仍然只有一个偏置项。"
        }
    },
    {
        "translation": {
            "en": "From a prediction perspective, the Voronoi region belonging to a training instance defines the set of queries for which the prediction will be determined by that training instance.",
            "zh": "从预测的角度来看，属于训练实例的 Voronoi 区域定义了一组查询，该训练实例将确定预测。"
        }
    },
    {
        "translation": {
            "en": "This is why we use a learning rate α to scale the weight updates.",
            "zh": "这就是为什么我们使用学习率α来缩放权重更新的原因。"
        }
    },
    {
        "translation": {
            "en": "−0.00556710",
            "zh": "−0.00556710"
        }
    },
    {
        "translation": {
            "en": "When a neuron uses a logistic function as its activation function, then the maximum value the derivative can take is 0.25.",
            "zh": "当神经元使用逻辑函数作为其激活函数时，导数可以取的最大值为 0.25。"
        }
    },
    {
        "translation": {
            "en": "(b) A support vector machine model has been trained to distinguish between dosages of two drugs that cause a dangerous interaction and those that interact safely. This model uses just two continuous features, DOSE1 and DOSE2, and two target levels, dangerous (the positive level, + 1) and safe (the negative level, − 1). The support vectors in the trained model are shown in the following table.",
            "zh": "（b） 已经训练了一种支持向量机模型，以区分引起危险相互作用的两种药物的剂量和安全相互作用的药物。该模型仅使用两个连续特征，即 DOSE1 和 DOSE2，以及两个目标水平，危险（正水平，+ 1）和安全（负水平，− 1）。训练模型中的支持向量如下表所示。"
        }
    },
    {
        "translation": {
            "en": "The final for loop in each epoch is where the weights of the network are updated (Lines 28[420] to 30[420]).",
            "zh": "每个纪元的最后一个 for 循环是更新网络权重的地方（第 28[420] 行至第 30 行[420]）。"
        }
    },
    {
        "translation": {
            "en": "The retention team’s simple transactional database, containing all the contacts they had made with customers, and the outcomes of these contacts, stretching back to a time horizon of 12 months",
            "zh": "保留团队的简单事务数据库，包含他们与客户建立的所有联系，以及这些联系的结果，可以追溯到 12 个月的时间范围"
        }
    },
    {
        "translation": {
            "en": "(c) Is the training dynamic of this network stable, or is it suffering from vanishing or exploding gradients?",
            "zh": "（c） 该网络的训练动态是稳定的，还是受到梯度消失或爆炸的影响？"
        }
    },
    {
        "translation": {
            "en": "0.81",
            "zh": "0.81"
        }
    },
    {
        "translation": {
            "en": "11.4   A simple grid world. The start position is annotated with an S and the goal with a G. The squares marked f denote fire, which is very damaging to an agent.",
            "zh": "11.4 一个简单的网格世界。起始位置用 S 标注，目标用 G 标注。标有 f 的方块表示火，这对特工的伤害非常大。"
        }
    },
    {
        "translation": {
            "en": "We have now calculated the δs for all the neurons in the network for d2.",
            "zh": "我们现在已经计算了 d2 网络中所有神经元的 δ。"
        }
    },
    {
        "translation": {
            "en": "This is because as we progress along the sequence of conditional probabilities specified by the chain rule, the size of the set of conditioning events for each term increases.",
            "zh": "这是因为随着我们沿着链式规则指定的条件概率序列前进，每个项的条件事件集的大小会增加。"
        }
    },
    {
        "translation": {
            "en": "0.07",
            "zh": "0.07"
        }
    },
    {
        "translation": {
            "en": "In a slight variation of the bar plot, we can show densities rather than frequencies by dividing each frequency by the total number of values in the dataset.",
            "zh": "在条形图的轻微变化中，我们可以通过将每个频率除以数据集中的值总数来显示密度而不是频率。"
        }
    },
    {
        "translation": {
            "en": "Table 9.18[573] shows the expected targets and a set of model predictions for a multinomial prediction problem in which the species of a bacteria present in a sample is determined using the results of spectrography performed on the sample.19 In this example, we are trying to distinguish between four species of the bacterial genus Fructobacillus, namely, durionis, ficulneus, fructosus, and pseudoficulneus (abbreviated as pseudo.",
            "zh": "表9.18[573]显示了多项式预测问题的预期目标和一组模型预测，其中样品中存在的细菌种类是使用对样品进行的光谱结果确定的.19在这个例子中，我们试图区分细菌属果糖杆菌的四个物种， 即durionis、ficulneus、fructosus和pseudoficulneus（缩写为pseudo."
        }
    },
    {
        "translation": {
            "en": "This interpretability is very important in some domains.",
            "zh": "这种可解释性在某些领域非常重要。"
        }
    },
    {
        "translation": {
            "en": "6.9   The relevant smoothed probabilities, from Table 6.8[269], needed by the naïve Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each target levels.",
            "zh": "6.9 朴素贝叶斯预测模型需要表6.8[269]中的相关平滑概率，以便对CH = 付费、GC = 担保人、ACC = 免费的查询进行预测，并计算每个目标水平的分数。"
        }
    },
    {
        "translation": {
            "en": "Hospital management are concerned that the cause of the high readmittance rate for diabetes patients might be that they are discharged too early or that their care plans while in the hospital are not addressing all their needs.",
            "zh": "医院管理层担心，糖尿病患者再入院率高的原因可能是他们出院得太早，或者他们在医院期间的护理计划没有满足他们的所有需求。"
        }
    },
    {
        "translation": {
            "en": "Redundant: a descriptive feature is redundant if it has a strong correlation with another descriptive feature.",
            "zh": "冗余：如果描述性特征与另一个描述性特征具有很强的相关性，则该特征是多余的。"
        }
    },
    {
        "translation": {
            "en": "In spite of these difficulties, for machine learning purposes, correlation is a very good measure of the relationship between two continuous features.9",
            "zh": "尽管存在这些困难，但出于机器学习的目的，相关性是两个连续特征之间关系的一个很好的度量9。"
        }
    },
    {
        "translation": {
            "en": "where denotes the network graph, D is the training data, is the set of entries in the CPTs of , d is the number of parameters of (i.e., how many entries in the CPTs of ), and n is the number of instances in D. This metric contains a term describing how well the model predicts the data as well as a term that punishes complex models .",
            "zh": "其中表示网络图，D 是训练数据，是 的 CPT 中的条目集，d 是 的参数个数（即 的 个条目数），n 是 的实例数。该指标包含一个描述模型预测数据的术语，以及一个惩罚复杂模型的术语。"
        }
    },
    {
        "translation": {
            "en": "prediction, 4, 758",
            "zh": "预测，4,758"
        }
    },
    {
        "translation": {
            "en": "(b) The number of prior criminal convictions held by people given prison sentences in a city district over the course of a full year.",
            "zh": "（b） 在一整年的时间里，在一个城市地区被判刑的人所持有的先前的刑事定罪的次数。"
        }
    },
    {
        "translation": {
            "en": "Instead, the final model trained provides the overall output of the ensemble as it implicitly combines the outputs of all models trained—recall Equation (4.18)[165].",
            "zh": "相反，训练的最终模型提供了集合的整体输出，因为它隐式地组合了所有训练模型的输出——回想方程（4.18）[165]。"
        }
    },
    {
        "translation": {
            "en": "We say that the estimate is unbiased if its variance, on average, equals that of the population variance.",
            "zh": "我们说，如果估计值的方差平均等于总体方差的方差，则该估计值是无偏的。"
        }
    },
    {
        "translation": {
            "en": "Worldwide breast cancer is the most common form of cancer for women, and the second most common form of cancer overall.18 Reliable, population-wide screening is one tool that can be used to reduce the impact of breast cancer, and there is an opportunity for machine learning to be used for this.",
            "zh": "在世界范围内，乳腺癌是女性最常见的癌症形式，也是第二常见的癌症形式.18可靠的全人群筛查是一种可用于减少乳腺癌影响的工具，并且有机会将机器学习用于此。"
        }
    },
    {
        "translation": {
            "en": "non-parametric model, 732",
            "zh": "非参数模型，732"
        }
    },
    {
        "translation": {
            "en": "Ross used the ABT to train, tune, and test a series of decision trees to predict churn given the set of descriptive features.",
            "zh": "Ross 使用 ABT 来训练、调整和测试一系列决策树，以根据一组描述性特征预测客户流失。"
        }
    },
    {
        "translation": {
            "en": "5.12   The similarity between the current trial user, q, and the two users in the dataset, d1 and d2, in terms of co-presence (CP), co-absence (CA), presence-absence (PA), and absence-presence (AP).",
            "zh": "5.12 当前试验用户 q 与数据集中的两个用户 d1 和 d2 在共存 （CP）、共缺 （CA）、缺勤-缺勤 （PA） 和缺勤-存在 （AP） 方面的相似性。"
        }
    },
    {
        "translation": {
            "en": "Montgomery, Douglas C. 2004. Introduction to statistical quality control. Wiley.",
            "zh": "蒙哥马利，道格拉斯 C. 2004 年。统计质量控制导论。威利。"
        }
    },
    {
        "translation": {
            "en": "Dataset for predicting the vegetation in an area with a continuous ELEVATION feature (measured in feet).",
            "zh": "用于预测具有连续 ELEVATION 要素（以英尺为单位）的区域中的植被的数据集。"
        }
    },
    {
        "translation": {
            "en": "(a) On the basis of this sequence of states, calculate a transition matrix that gives the probability of moving between each of the three states.",
            "zh": "（a） 根据这一系列状态，计算一个过渡矩阵，该矩阵给出了在三种状态中的每一个状态之间移动的概率。"
        }
    },
    {
        "translation": {
            "en": "Makhoul, John, Amro El-Jaroudi, and Richard Schwartz. 1989. Formation of disconnected decision regions with a single hidden layer. In Proceedings of the international joint conference on neural networks, Vol. 1, 455–460. IEEE.",
            "zh": "Makhoul、John、Amro El-Jaroudi 和 Richard Schwartz。1989. 具有单个隐藏层的断开连接决策区域的形成。在神经网络国际联合会议论文集，第 1 卷，455–460。IEEE的。"
        }
    },
    {
        "translation": {
            "en": "Common manipulations used in this process include aggregates, flags, ratios, and mappings, although any manipulation is valid.",
            "zh": "此过程中使用的常见操作包括聚合、标志、比率和映射，尽管任何操作都是有效的。"
        }
    },
    {
        "translation": {
            "en": "This is another example of a data quality issue due to invalid data.",
            "zh": "这是由于无效数据导致的数据质量问题的另一个示例。"
        }
    },
    {
        "translation": {
            "en": "where the episode proceeds through time-steps t = 1,…,e. At each time-step the agent makes an observation, ot, of the environment, takes an action, at, and receives a reward, rt, based on that action. This cycle is illustrated in Figure 11.1[639].",
            "zh": "其中，剧集通过时间步长 t = 1,...,e 进行。在每个时间步中，智能体对环境进行观察，采取行动，并根据该行动获得奖励rt。图11.1[639]说明了这个循环。"
        }
    },
    {
        "translation": {
            "en": "The descriptive features measure whether a customer buys baby food, BBY; alcohol, ALC; or organic vegetable products, ORG.",
            "zh": "描述性特征衡量客户是否购买婴儿食品，BBY;酒精，ALC;或有机蔬菜产品，ORG。"
        }
    },
    {
        "translation": {
            "en": "Probability-Based Learning",
            "zh": "基于概率的学习"
        }
    },
    {
        "translation": {
            "en": "Transformer, 523",
            "zh": "变压器，523"
        }
    },
    {
        "translation": {
            "en": "Based on analysis of the associated data and capacity requirements, the analytics practitioner can assess the feasibility of each predictive analytics solution proposed to address a business problem.",
            "zh": "基于对相关数据和容量要求的分析，分析从业人员可以评估为解决业务问题而提出的每个预测分析解决方案的可行性。"
        }
    },
    {
        "translation": {
            "en": "Generic Events",
            "zh": "通用事件"
        }
    },
    {
        "translation": {
            "en": "5.8   (a) The k-d tree generated for the dataset in Table 5.4[191] after the initial split; (b) the partitioning of the feature space by the k-d tree in (a); (c) the k-d tree after the dataset at the left child of the root has been split; and (d) the partitioning of the feature space by the k-d tree in (c).",
            "zh": "5.8 （a） 初始拆分后为表5.4[191]中的数据集生成的k-d树;（b）在（a）中用k-d树对特征空间进行划分;（c） 根左侧子项的数据集被拆分后的 k-d 树;（d）在（c）中用k-d树对特征空间进行分区。"
        }
    },
    {
        "translation": {
            "en": "0.071",
            "zh": "0.071"
        }
    },
    {
        "translation": {
            "en": "Sutton and Barto’s textbook has been the definitive work on reinforcement learning since it was first published in (Sutton and Barto, 1998), and their recent 2nd edition (Sutton and Barto, 2018) is an excellent update.",
            "zh": "Sutton 和 Barto 的教科书自 （Sutton and Barto， 1998） 首次出版以来一直是关于强化学习的权威著作，他们最近的第 2 版（Sutton and Barto， 2018）是一个很好的更新。"
        }
    },
    {
        "translation": {
            "en": "Within the continuous features, only AGE stood out with 11.47% of values missing.",
            "zh": "在连续特征中，只有 AGE 脱颖而出，缺少 11.47% 的值。"
        }
    },
    {
        "translation": {
            "en": "She used step-wise sequential feature selection again, and this time 32 features were chosen.18 This model was able to achieve a classification accuracy of 68.225% (with an average class accuracy of 56.621%).",
            "zh": "她再次使用逐步顺序特征选择，这次选择了 32 个特征.18 该模型能够实现 68.225% 的分类准确率（平均类准确率为 56.621%）。"
        }
    },
    {
        "translation": {
            "en": "After discussion with the AT executive team, it was decided that the analytics solution most appropriate to focus on was predicting which customers are most likely to churn in the near future. There were a number of reasons this project was selected:",
            "zh": "在与 AT 执行团队讨论后，决定最合适的分析解决方案是预测哪些客户在不久的将来最有可能流失。选择这个项目的原因有很多："
        }
    },
    {
        "translation": {
            "en": "The probabilities associated with each Twist transition shown in Figure 11.3[648] have been calculated based on what can happen in a game of TwentyTwos, under the assumption of an infinite deck from which cards are dealt.",
            "zh": "图 11.3[648] 所示的每个 Twist 转换相关的概率是根据 TwentyTwo 游戏中可能发生的情况计算的，假设从中发牌的无限套牌。"
        }
    },
    {
        "translation": {
            "en": "8. That is, a and b = b and a.",
            "zh": "8. 也就是说，a 和 b = b 和 a。"
        }
    },
    {
        "translation": {
            "en": "However, this may not always be the case, because some weight updates may move in an orthogonal direction to the true gradient or even cause the error to increase; this can slow down the training of the network.",
            "zh": "然而，情况可能并非总是如此，因为某些权重更新可能会沿正交方向移动到真实梯度，甚至导致误差增加;这可能会减慢网络的训练速度。"
        }
    },
    {
        "translation": {
            "en": "This is shown in the bar plot in Figure 6.1(c)[244], which shows an equal likelihood for each position.",
            "zh": "如图6.1（c）[244]中的条形图所示，图中显示了每个仓位的相等似然。"
        }
    },
    {
        "translation": {
            "en": "These z and a values will be found in the corresponding gray boxes in Figure 8.18[440].",
            "zh": "这些 z 和 a 值可以在图 8.18[440] 的相应灰色框中找到。"
        }
    },
    {
        "translation": {
            "en": "early stopping, 418, 432, 434, 472, 472, 477",
            "zh": "提前停止， 418， 432， 434， 472， 472， 477"
        }
    },
    {
        "translation": {
            "en": "Some of the descriptive features were simply copies of available raw data.",
            "zh": "一些描述性特征只是可用原始数据的副本。"
        }
    },
    {
        "translation": {
            "en": "expected return, 642, 643, 676",
            "zh": "预期回报， 642， 643， 676"
        }
    },
    {
        "translation": {
            "en": "Galaxy Zoo8 is a crowdsourced, citizen science effort in which people can log on to a website and categorize images of galaxies—taken from the SDSS—into different groups.",
            "zh": "Galaxy Zoo8 是一项众包的公民科学项目，人们可以登录网站并将从 SDSS 拍摄的星系图像分类为不同的组。"
        }
    },
    {
        "translation": {
            "en": "The action-value table is still fairly sparse after the first iteration with most combinations having changed little from their randomly initialized values.",
            "zh": "在第一次迭代之后，操作值表仍然相当稀疏，大多数组合与其随机初始化的值相比变化不大。"
        }
    },
    {
        "translation": {
            "en": "0.2478",
            "zh": "0.2478"
        }
    },
    {
        "translation": {
            "en": "Elementwise Product",
            "zh": "Elementwise 产品"
        }
    },
    {
        "translation": {
            "en": "We know from our earlier calculations that the entropy for this dataset is 1.5567 bits (see Equation (4.5)[137]) and that the information gain for the categorical features are IG(STREAM, ) = 0.3060 and IG(SLOPE, ) = 0.5774 (see Table 4.4[137]).",
            "zh": "我们从前面的计算中知道，该数据集的熵为1.5567位（参见公式（4.5）[137]），分类特征的信息增益为IG（STREAM， ） = 0.3060和IG（SLOPE， ） = 0.5774（参见表4.4[137]）。"
        }
    },
    {
        "translation": {
            "en": "Based on the new likelihoods, you guess that the queen is in the center position, and happily, this turns out to be correct (see Figure 6.2(c)[245]).",
            "zh": "根据新的可能性，你猜到女王处于中心位置，令人高兴的是，结果证明这是正确的（见图6.2（c）[245]）。"
        }
    },
    {
        "translation": {
            "en": "GPUs are designed to carry out matrix operations very quickly.",
            "zh": "GPU 旨在非常快速地执行矩阵运算。"
        }
    },
    {
        "translation": {
            "en": "composition, 401",
            "zh": "组成，401"
        }
    },
    {
        "translation": {
            "en": "9.1   The process of building and evaluating a model using a hold-out test set.",
            "zh": "9.1 使用保持测试集构建和评估模型的过程。"
        }
    },
    {
        "translation": {
            "en": "13.7   The confusion matrices for the models after feature selection.",
            "zh": "13.7 特征选择后模型的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "If we could capture this relationship in a model, we would be able to do two important things.",
            "zh": "如果我们能在模型中捕捉到这种关系，我们将能够做两件重要的事情。"
        }
    },
    {
        "translation": {
            "en": "It is the output of this layer of neurons that generates the feature map in Equation (8.94)[490].",
            "zh": "正是这层神经元的输出生成了等式（8.94）[490]中的特征图。"
        }
    },
    {
        "translation": {
            "en": "YEARSINCURRENTEMPLOYMENT: The number of years that the taxpayer has been in their current job.",
            "zh": "YEARSINCURRENTEMPLOYMENT：纳税人从事当前工作的年数。"
        }
    },
    {
        "translation": {
            "en": "ergodic Markov chain, 299",
            "zh": "遍历马尔可夫链，299"
        }
    },
    {
        "translation": {
            "en": "In this first path of processing hxt is passed through a layer of sigmoid units that is the same width as the cell state.",
            "zh": "在第一个处理路径中，hxt 通过与单元状态宽度相同的 sigmoid 单元层。"
        }
    },
    {
        "translation": {
            "en": "(b) The following table lists the scores returned by the same prediction model for a new test set of 12 examples.",
            "zh": "（b） 下表列出了同一预测模型对12个样本的新测试集返回的分数。"
        }
    },
    {
        "translation": {
            "en": "Through our years of teaching this material, we have developed an understanding of what is a reasonable amount of material to cover in a one-semester introductory module and in a two-semester more advanced module.",
            "zh": "通过我们多年的教学，我们已经了解了一学期的入门模块和两个学期的高级模块中应该涵盖的合理数量的材料。"
        }
    },
    {
        "translation": {
            "en": "Table 10.2",
            "zh": "表 10.2"
        }
    },
    {
        "translation": {
            "en": "The process of building and evaluating a model using a hold-out test set.",
            "zh": "使用保持测试集构建和评估模型的过程。"
        }
    },
    {
        "translation": {
            "en": "It has been shown repeatedly, however, that it is in fact possible to learn sophisticated, long-term behaviors using the maximization of cumulative reward alone.",
            "zh": "然而，事实一再表明，事实上，仅使用累积奖励的最大化，就可以学习复杂的长期行为。"
        }
    },
    {
        "translation": {
            "en": "feature subset space, 228",
            "zh": "特征子集空间，228"
        }
    },
    {
        "translation": {
            "en": "3.4.2   Handling Outliers",
            "zh": "3.4.2 处理异常值"
        }
    },
    {
        "translation": {
            "en": "The player loses in all other cases.",
            "zh": "在所有其他情况下，玩家都输了。"
        }
    },
    {
        "translation": {
            "en": "Because the error rate for the leaf nodes is higher than the error rate for the root node of the subtree, this subtree is pruned and replaced by a leaf node.",
            "zh": "由于叶节点的错误率高于子树的根节点的错误率，因此将修剪此子树并将其替换为叶节点。"
        }
    },
    {
        "translation": {
            "en": "Recall that the receptive fields of the neurons in the sub-sampling layer do not overlap.",
            "zh": "回想一下，子采样层中神经元的感受野不重叠。"
        }
    },
    {
        "translation": {
            "en": "We are now in a position to build a linear regression model that uses all the continuous descriptive features in the office rentals dataset in Table 7.1[313] (i.e., all features except for ENERGY RATING). The general structure of the model is",
            "zh": "我们现在能够建立一个线性回归模型，该模型使用表7.1[313]中办公室租赁数据集中的所有连续描述性特征（即除ENERGY RATING以外的所有特征）。模型的一般结构是"
        }
    },
    {
        "translation": {
            "en": "The structures of the tables included in a data quality report to describe (a) continuous features and (b) categorical features.",
            "zh": "数据质量报告中包含的表的结构，用于描述 （a） 连续特征和 （b） 分类特征。"
        }
    },
    {
        "translation": {
            "en": "The weight matrix is again organized with one row of weights per neuron and with the bias term weight as the first element in the row (shown in black).",
            "zh": "权重矩阵再次由每个神经元的一行权重组织，并将偏差项权重作为行中的第一个元素（以黑色显示）。"
        }
    },
    {
        "translation": {
            "en": "3. sub-sampling (pooling).",
            "zh": "3. 子采样（池化）。"
        }
    },
    {
        "translation": {
            "en": "Long after it was first proposed, k-means remains a commonly used clustering algorithm; however, there have been many modifications and alternatives proposed over the years.",
            "zh": "在首次提出很久之后，k-means 仍然是一种常用的聚类算法;然而，多年来已经提出了许多修改和替代方案。"
        }
    },
    {
        "translation": {
            "en": "centroid linkage, 619",
            "zh": "质心连杆，619"
        }
    },
    {
        "translation": {
            "en": "Figure 8.5",
            "zh": "图 8.5"
        }
    },
    {
        "translation": {
            "en": "19. The data in this question have been artificially created but were inspired by the famous Wisconsin breast cancer dataset first described by Mangasarian and Wolberg (1990), and available from the UCI Machine Learning Repository (Bache and Lichman, 2013).",
            "zh": "19. 本问题中的数据是人工创建的，但灵感来自著名的威斯康星州乳腺癌数据集，该数据集由 Mangasarian 和 Wolberg （1990） 首次描述，可从 UCI 机器学习存储库（Bache 和 Lichman，2013 年）获得。"
        }
    },
    {
        "translation": {
            "en": "Node A has no parents, so the CPT just lists the unconditional probability distribution for A.",
            "zh": "节点 A 没有父节点，因此 CPT 仅列出 A 的无条件概率分布。"
        }
    },
    {
        "translation": {
            "en": "The sales team’s transactional database, containing details of phone handsets issued to customers",
            "zh": "销售团队的交易数据库，包含发给客户的电话听筒的详细信息"
        }
    },
    {
        "translation": {
            "en": "11.6   Further Reading",
            "zh": "11.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "AMOUNT RECEIVED",
            "zh": "收到的金额"
        }
    },
    {
        "translation": {
            "en": "Figure 5.18[226] provides a graphical insight into the relationship between the number of descriptive features in a dataset and the sampling density of the feature space.",
            "zh": "图 5.18[226] 提供了数据集中描述性特征数量与特征空间采样密度之间关系的图形见解。"
        }
    },
    {
        "translation": {
            "en": "COUNTRY: The name of the country",
            "zh": "国家/地区：国家/地区名称"
        }
    },
    {
        "translation": {
            "en": "A linear regression model for the problem uses only two weights, w[0] and w[1].",
            "zh": "该问题的线性回归模型仅使用两个权重，w[0] 和 w[1]。"
        }
    },
    {
        "translation": {
            "en": "Probability is the branch of mathematics that deals with measuring the likelihood (or uncertainty) around events.",
            "zh": "概率是数学的一个分支，用于测量事件的可能性（或不确定性）。"
        }
    },
    {
        "translation": {
            "en": "The (a) lift and (b) cumulative lift at each decile for the email predictions given in Table 9.11[557].",
            "zh": "表9.11[557]中给出的电子邮件预测的每个十分位数的（a）提升和（b）累积提升。"
        }
    },
    {
        "translation": {
            "en": "Li, Deren, Shuliang Wang, and Deyi Li. 2015. Spatial data mining. Springer.",
            "zh": "Li， Deren， Shuliang Wang， and Deyi Li. 2015.空间数据挖掘。斯普林格。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.1",
            "zh": "图 9.1"
        }
    },
    {
        "translation": {
            "en": "These are shown in the column labeled t − 0 in Table 4.15[166 they are simply the difference between the values predicted by the initial model and the target feature value for each instance in the dataset.",
            "zh": "这些显示在表 4.15 中标记为 t − 0 的列中[166]，它们只是初始模型预测的值与数据集中每个实例的目标特征值之间的差值。"
        }
    },
    {
        "translation": {
            "en": "Conveniently, this also determined the subset of the SDSS dataset (those galaxies used in the Galaxy Zoo project) that Jocelyn would use for this project.",
            "zh": "方便的是，这也决定了Jocelyn将用于该项目的SDSS数据集（Galaxy Zoo项目中使用的星系）的子集。"
        }
    },
    {
        "translation": {
            "en": "Once the δs for all the neurons in the network for an example have been calculated, then for each weight in the network the error gradients are accumulated (Lines 24[420] to 26[420]).",
            "zh": "例如，一旦计算了网络中所有神经元的δ，那么对于网络中的每个权重，误差梯度就会累积（第24行[420]至26行[420]）。"
        }
    },
    {
        "translation": {
            "en": "Mishne, Gilad, and Natalie S. Glance. 2006. Predicting movie sales from blogger sentiment. In AAAI spring symposium: Computational approaches to analyzing weblogs, 155–158.",
            "zh": "Mishne、Gilad 和 Natalie S. Glance。2006. 从博主情绪预测电影销售.在AAAI春季研讨会上：分析博客的计算方法，155-158。"
        }
    },
    {
        "translation": {
            "en": "bias term, 480, 493",
            "zh": "偏置项，480,493"
        }
    },
    {
        "translation": {
            "en": "We can also use a weighted k nearest neighbor model to make predictions for continuous targets that take into account the distance from the query instance to the neighbors (just like we did for categorical target features in Section 5.4.1[191]). To do this, the model prediction equation in Equation (5.7)[208] is changed to",
            "zh": "我们还可以使用加权 k 最近邻模型对连续目标进行预测，这些目标考虑了从查询实例到邻居的距离（就像我们在第 5.4.1[191] 节中对分类目标特征所做的那样）。为此，将公式（5.7）[208]中的模型预测方程更改为"
        }
    },
    {
        "translation": {
            "en": "This equivalence is true no matter how many hidden layers we introduce into the network.",
            "zh": "无论我们在网络中引入多少隐藏层，这种等价性都是正确的。"
        }
    },
    {
        "translation": {
            "en": "The plot shows that the initial sum of squared errors of the network is just under 0.6, and this drops to < 0.2 after the first epoch.",
            "zh": "该图显示，网络的初始平方误差之和略低于 0.6，在第一个纪元之后降至 0.2 <。"
        }
    },
    {
        "translation": {
            "en": "Importantly, the resulting data was skewed even though the surveys were large.",
            "zh": "重要的是，即使调查规模很大，结果数据也是有偏差的。"
        }
    },
    {
        "translation": {
            "en": "A.6  Bar plot of the continuous TRAINING EXPENSES feature from Table A.1[750].",
            "zh": "A.6 表A.1[750]中连续训练费用特征的条形图。"
        }
    },
    {
        "translation": {
            "en": "For example, for New Sample 1, the stability index is",
            "zh": "例如，对于新样本 1，稳定性指数为"
        }
    },
    {
        "translation": {
            "en": "This has been the case in the recent deep reinforcement learning successes at games like go, chess, and poker at which reinforcement learning agents are playing at world class level and use play strategies that are a total surprise to human players.",
            "zh": "最近在围棋、国际象棋和扑克等游戏中的深度强化学习成功就是这种情况，在这些游戏中，强化学习代理正在发挥世界级水平，并使用的玩法策略让人类玩家完全感到惊讶。"
        }
    },
    {
        "translation": {
            "en": "If there is variation across the number of values in the domain of the descriptive features in a dataset, however, information gain ratio may be a better option.",
            "zh": "但是，如果数据集中描述性特征域中的值数量存在差异，则信息增益比可能是更好的选择。"
        }
    },
    {
        "translation": {
            "en": "PREV. TACHY.: Has the patient suffered from tachycardia before?",
            "zh": "上一页 心动过速：患者以前有心动过速吗？"
        }
    },
    {
        "translation": {
            "en": "This is done by stacking the feature maps together.",
            "zh": "这是通过将特征图堆叠在一起来完成的。"
        }
    },
    {
        "translation": {
            "en": "An information gain score this low suggests that although splitting on this feature provides some information, it is not particularly useful.",
            "zh": "信息增益得分如此之低表明，尽管拆分此功能提供了一些信息，但它并不是特别有用。"
        }
    },
    {
        "translation": {
            "en": "A.4   The density calculation for the TRAINING EXPENSES feature from Table A.1[750] using (a) ten 200-unit intervals and (b) four 500-unit intervals.",
            "zh": "A.4 使用（a）10个200单位的间隔和（b）4个500单位的间隔计算表A.1[750]中训练费用特征的密度。"
        }
    },
    {
        "translation": {
            "en": "Next, on Line 10[420], the activation function φ is applied in turn to each element of Z(l) to generate the activations for each neuron in the layer for each example in the mini-batch.",
            "zh": "接下来，在第 10 行[420]上，激活函数 φ 依次应用于 Z（l） 的每个元素，以生成小批量中每个示例层中每个神经元的激活。"
        }
    },
    {
        "translation": {
            "en": "Arithmetic means are susceptible to influence of large outliers, which can inflate the apparent performance of a model.",
            "zh": "算术均值容易受到大异常值的影响，这可能会夸大模型的表观性能。"
        }
    },
    {
        "translation": {
            "en": "(a) The visualization below illustrates the relationship between the continuous feature AGE and the target feature, PREFCHANNEL.",
            "zh": "（a） 下面的可视化图说明了连续特征 AGE 与目标特征 PREFCHANNEL 之间的关系。"
        }
    },
    {
        "translation": {
            "en": "For example, in the insurance industry, insurance policyholders are usually referred to as members rather than customers.",
            "zh": "例如，在保险业，投保人通常被称为会员而不是客户。"
        }
    },
    {
        "translation": {
            "en": "12.6   Deployment",
            "zh": "12.6 部署"
        }
    },
    {
        "translation": {
            "en": "For example, an insurance company might collect data on customers’ travel behaviors through their travel insurance policy and then use this data in a model that predicts personalized prices for life insurance.",
            "zh": "例如，保险公司可能会通过其旅行保险单收集有关客户旅行行为的数据，然后在预测人寿保险个性化价格的模型中使用这些数据。"
        }
    },
    {
        "translation": {
            "en": "A next-best-offer model is used to determine the least expensive incentive that needs to be offered to a customer who is considering canceling a service, for example, a mobile phone contract, in order to make them reconsider and stay.",
            "zh": "次优报价模型用于确定需要向正在考虑取消服务（例如移动电话合同）的客户提供的最便宜的激励措施，以便他们重新考虑并留下来。"
        }
    },
    {
        "translation": {
            "en": "experiment, 246, 757, 758",
            "zh": "实验， 246， 757， 758"
        }
    },
    {
        "translation": {
            "en": "10.10   (a)–(i) A plot of the blobs, circles, and half-moons datasets and the clusterings achieved by the k-means clustering and agglomerative hierarchical clustering algorithms (where k is set to 3, 2, and 2, respectively).",
            "zh": "10.10 （a）–（i） 斑点、圆圈和半月数据集的图，以及通过 k 均值聚类和聚集分层聚类算法实现的聚类（其中 k 分别设置为 3、2 和 2）。"
        }
    },
    {
        "translation": {
            "en": "The output activation for this neuron would be calculated as follows:",
            "zh": "该神经元的输出激活将按如下方式计算："
        }
    },
    {
        "translation": {
            "en": "The R2 coefficient, however, has the advantage that it allows assessment of model performance in a domain-independent way.",
            "zh": "然而，R2 系数的优点是它允许以与领域无关的方式评估模型性能。"
        }
    },
    {
        "translation": {
            "en": "Figure A.8(b)[756] shows a box plot for the TRAINING EXPENSES feature from the dataset in Table A.1[750].",
            "zh": "图A.8（b）[756]显示了表A.1[750]中数据集中训练费用特征的箱形图。"
        }
    },
    {
        "translation": {
            "en": "The second detail that Jocelyn needed to agree on with Edwin was the target accuracy that would be required by the system she would build in order for it to be of use to scientists at SDSS.",
            "zh": "Jocelyn 需要与 Edwin 达成一致的第二个细节是她将要构建的系统所需的目标精度，以便它对 SDSS 的科学家有用。"
        }
    },
    {
        "translation": {
            "en": "For the players’ heights given in Figure A.1[746], the mean is 149.375, so the variance can be calculated as",
            "zh": "对于图A.1[746]中给出的球员身高，平均值为149.375，因此方差可以计算为："
        }
    },
    {
        "translation": {
            "en": "Iterative Dichotomizer 3, 11, 117, 133, 133, 169, 173, 176, 541, 731",
            "zh": "迭代二分法器 3、11、117、133、133、169、173、176、541、731"
        }
    },
    {
        "translation": {
            "en": "No other data source existed from which these features could be populated, so it was decided to remove both of them from the ABT.",
            "zh": "没有其他数据源可以填充这些功能，因此决定从 ABT 中删除它们。"
        }
    },
    {
        "translation": {
            "en": "The second use case we described for unsupervised learning in Section 10.2[598] was representation learning.",
            "zh": "我们在第 10.2 节[598]中描述的无监督学习的第二个用例是表示学习。"
        }
    },
    {
        "translation": {
            "en": "5.11   (a) The target hypersphere after instance d21 has been stored as best, and best-distance has been updated; and (b) the extent of the search process.",
            "zh": "5.11 （a） 实例d21之后的目标超球体已存储为最佳，最佳距离已更新;以及（b）检索过程的范围。"
        }
    },
    {
        "translation": {
            "en": "Table 4.7",
            "zh": "表 4.7"
        }
    },
    {
        "translation": {
            "en": "To illustrate this approach using a simple example, Table 10.3[614] shows a data quality report for each cluster found using k-means clustering (with k = 3) on the mobile phone customer dataset (see Table 10.1[604]).",
            "zh": "为了用一个简单的例子来说明这种方法，表10.3[614]显示了在移动电话客户数据集上使用k-means聚类（k = 3）找到的每个聚类的数据质量报告（见表10.1[604]）。"
        }
    },
    {
        "translation": {
            "en": "Table 13.1",
            "zh": "表 13.1"
        }
    },
    {
        "translation": {
            "en": "the δ for neuron i connects the zi value for i to the error of the network ℰ.",
            "zh": "神经元 i 的 δ 将 i 的 zi 值连接到网络 E 的误差。"
        }
    },
    {
        "translation": {
            "en": "Notice that the denominator in Equation (6.10)[254] is not dependent on the target feature, so it is functioning as a normalization constant.",
            "zh": "请注意，等式（6.10）[254]中的分母不依赖于目标特征，因此它充当归一化常数。"
        }
    },
    {
        "translation": {
            "en": "(c) For each analytics solution you have proposed, outline the capacity that the revenue commission would need in order to utilize the analytics-based insight that your solution would provide.",
            "zh": "（c） 对于您提出的每个分析解决方案，概述收入委员会需要的能力，以便利用您的解决方案将提供的基于分析的见解。"
        }
    },
    {
        "translation": {
            "en": "Some data quality issues arise due to invalid data and will be corrected as soon as we discover them.",
            "zh": "一些数据质量问题是由无效数据引起的，一旦我们发现，就会立即纠正。"
        }
    },
    {
        "translation": {
            "en": "(a) A scatter plot of the RAIN and GROWTH feature from the grass growth dataset; and (b) the same plot with a simple linear regression model trained to capture the relationship between the grass growth and rainfall.",
            "zh": "（a） 草生长数据集中雨水和生长特征的散点图;（b）使用简单的线性回归模型训练相同的图，以捕捉草生长和降雨之间的关系。"
        }
    },
    {
        "translation": {
            "en": "If we examine the table closely, we see a number of strange values (for example, − 99,999) and a number of missing values.",
            "zh": "如果我们仔细检查该表，我们会看到许多奇怪的值（例如，− 99,999）和一些缺失值。"
        }
    },
    {
        "translation": {
            "en": "what GRADE would the k-nearest neighbor model assign the student?",
            "zh": "k 最近邻模型会给学生分配什么成绩？"
        }
    },
    {
        "translation": {
            "en": "From the perspective of searching for a consistent model, the most important property of a prediction model is that it defines a mapping from every possible combination of descriptive feature values to a prediction for the target feature.",
            "zh": "从搜索一致模型的角度来看，预测模型最重要的属性是它定义了从描述性特征值的每个可能组合到目标特征预测的映射。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.13[211] shows the neighborhood that this defines around the query instance.",
            "zh": "图 5.13[211] 显示了它围绕查询实例定义的邻域。"
        }
    },
    {
        "translation": {
            "en": "Dealer Low (DL): 2 − 7",
            "zh": "经销商低价 （DL）： 2 − 7"
        }
    },
    {
        "translation": {
            "en": "(c) The visualization below illustrates the relationship between the categorical feature PREV. TACHY. and the target feature, TACHYCARDIA.",
            "zh": "（c） 下面的可视化说明了分类特征 PREV. TACHY 之间的关系。和目标特征，心动过速。"
        }
    },
    {
        "translation": {
            "en": "In general, standard k nearest neighbor models and weighted k nearest neighbor models will produce very similar results when a feature space is well populated.",
            "zh": "通常，当特征空间填充良好时，标准 k 最近邻模型和加权 k 最近邻模型将产生非常相似的结果。"
        }
    },
    {
        "translation": {
            "en": "2. When listing a joint event, we use a comma , to denote logical and.",
            "zh": "2.在列出一个联合事件时，我们用逗号来表示逻辑和。"
        }
    },
    {
        "translation": {
            "en": "The third, fourth, and fifth convolutional layers had 384, 384, and 256 filters, respectively, and none of these layers included a non-linearity or a max pooling operation.",
            "zh": "第三层、第四层和第五卷积层分别有 384、384 和 256 个滤波器，这些层都不包含非线性或最大池化操作。"
        }
    },
    {
        "translation": {
            "en": "Data to Insights to Decisions",
            "zh": "从数据到洞察再到决策"
        }
    },
    {
        "translation": {
            "en": "(b) How many levels does each categorical, binary, or ordinal feature have?",
            "zh": "（乙）每个分类、二元或有序特征有多少级？"
        }
    },
    {
        "translation": {
            "en": "16. An alternative TD(λ) uses an approach known as eligibility traces to take account of the actual rewards received from multiple actions.",
            "zh": "16. 另一种TD（λ）使用一种称为资格跟踪的方法，以考虑从多个操作中获得的实际奖励。"
        }
    },
    {
        "translation": {
            "en": "The previous section of the chapter (Section 3.6[87]) focused on data preparation techniques that we can use on the data in an ABT.",
            "zh": "本章的上一节（第 3.6 节[87]）重点介绍了我们可以在 ABT 中对数据使用的数据准备技术。"
        }
    },
    {
        "translation": {
            "en": "(b) The following are the ground truth labels for the query instances from Part (a).",
            "zh": "（b） 以下是 （a） 部分中查询实例的基本实况标签。"
        }
    },
    {
        "translation": {
            "en": "McCulloch and Pitts were trying to develop a model of the activity in the human brain based on propositional logic.",
            "zh": "McCulloch和Pitts试图开发一个基于命题逻辑的人脑活动模型。"
        }
    },
    {
        "translation": {
            "en": "The algorithm, however, proceeds in exactly the same way for larger datasets and usually converges after tens of iterations.",
            "zh": "然而，对于较大的数据集，该算法以完全相同的方式进行，并且通常在数十次迭代后收敛。"
        }
    },
    {
        "translation": {
            "en": "6.2   (a) The set of cards after the wind blows over the one on the right; (b) the revised likelihoods for the position of the queen based on this new evidence; and (c) the final positions of the cards in the game.",
            "zh": "6.2 （a） 风吹过右边的那套牌;（b） 根据这些新证据修订女王职位的可能性;及（c）牌在游戏中的最终位置。"
        }
    },
    {
        "translation": {
            "en": "Using the training dataset from Table 1.3[9], a machine learning algorithm will reduce the full set of 6,561 possible prediction models for this scenario to only those that are consistent with the training instances.",
            "zh": "使用表 1.3[9] 中的训练数据集，机器学习算法会将此场景的 6,561 个可能的预测模型的全集减少到仅与训练实例一致的模型。"
        }
    },
    {
        "translation": {
            "en": "population standard deviation, 61",
            "zh": "总体标准差，61"
        }
    },
    {
        "translation": {
            "en": "The cross-entropy error (or loss) function is generally used in contexts in which the output of a network can be interpreted as a probability distribution over a set of exclusive categories. In the general scenario of a model predicting a distribution over a set of categories, the cross-entropy loss function is defined as",
            "zh": "交叉熵误差（或损失）函数通常用于将网络的输出解释为一组排他类别的概率分布的上下文中。在模型预测一组类别分布的一般场景中，交叉熵损失函数定义为"
        }
    },
    {
        "translation": {
            "en": "To use basis functions, we recast the simple linear regression model (see Equation (7.9)[320]) as follows:",
            "zh": "为了使用基函数，我们重新转换了简单的线性回归模型（参见公式（7.9）[320]），如下所示："
        }
    },
    {
        "translation": {
            "en": "For example, we could experiment with using a 2-by-2-by-3 filter (height by width by depth).",
            "zh": "例如，我们可以尝试使用 2×2×3 滤镜（高宽除深）。"
        }
    },
    {
        "translation": {
            "en": "The frequency count of each level2 of a categorical feature is calculated by counting the number of times that level appears in the sample.",
            "zh": "分类特征的每个级别2的频率计数是通过计算该级别在样本中出现的次数来计算的。"
        }
    },
    {
        "translation": {
            "en": "The internal dynamics of the network in Figure 8.22[450], using ReLUs, during the first training iteration when the weights were initialized using He initialization.",
            "zh": "图 8.22[450] 中网络的内部动力学，使用 ReLU 在第一次训练迭代期间，当权重使用 He 初始化进行初始化时。"
        }
    },
    {
        "translation": {
            "en": "Typically k takes small values such as 1, 2, or 3.",
            "zh": "通常，k 取小值，例如 1、2 或 3。"
        }
    },
    {
        "translation": {
            "en": "standard error, 333",
            "zh": "标准误差，333"
        }
    },
    {
        "translation": {
            "en": "The requirements for this model were that it be accurate, that it be capable of being integrated into the wider AT processes, and, possibly, that it act as a source of insight into the reasons people might churn.",
            "zh": "该模型的要求是准确，能够集成到更广泛的 AT 流程中，并且可能作为洞察人们可能流失的原因的来源。"
        }
    },
    {
        "translation": {
            "en": "Although the data quality report is just a collection of simple descriptive statistics and visualizations of the features in an analytics base table, it is a very powerful tool and the key to achieving the outcomes listed above.",
            "zh": "尽管数据质量报告只是分析基表中特征的简单描述性统计和可视化的集合，但它是一个非常强大的工具，也是实现上述结果的关键。"
        }
    },
    {
        "translation": {
            "en": "Cross Industry Standard Process for Data Mining, 16, 22, 28, 46, 53, 94, 534, 600, 730",
            "zh": "数据挖掘的跨行业标准流程，16、22、28、46、53、94、534、600、730"
        }
    },
    {
        "translation": {
            "en": "Often it will take multiple features to express a domain concept.",
            "zh": "通常，需要多个特征来表达一个领域概念。"
        }
    },
    {
        "translation": {
            "en": "Now consider what happens to the weights on connections from the input layer to the first hidden layer if there are large differences in the values taken by different descriptive features.",
            "zh": "现在考虑从输入层到第一个隐藏层的连接上的权重会发生什么情况，如果不同描述性特征所采用的值存在较大差异。"
        }
    },
    {
        "translation": {
            "en": "A dataset listing the number of bike rentals per day.",
            "zh": "列出每天自行车租赁次数的数据集。"
        }
    },
    {
        "translation": {
            "en": "A selection of the simple linear regression models developed during the gradient descent process for the office rentals dataset. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "在办公室租赁数据集的梯度下降过程中开发的简单线性回归模型的精选。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Before the churn model was put in place, every week the company would randomly select 1,000 customers from their customer base and have their customer contact center call these customers to discuss how satisfied they were with the network’s performance and offer assistance with any issues.",
            "zh": "在客户流失模型实施之前，该公司每周都会从其客户群中随机选择 1,000 名客户，并让其客户联络中心致电这些客户，讨论他们对网络性能的满意度，并就任何问题提供帮助。"
        }
    },
    {
        "translation": {
            "en": "Bray, Freddie, Jacques Ferlay, Isabelle Soerjomataram, Rebecca L. Siegel, Lindsey A. Torre, and Ahmedin Jemal. 2018. Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. CA: A Cancer Journal for Clinicians 68 (6): 394–424. doi:10.3322/caac.21492.",
            "zh": "Bray、Freddie、Jacques Ferlay、Isabelle Soerjomataram、Rebecca L. Siegel、Lindsey A. Torre 和 Ahmedin Jemal。2018. 2018 年全球癌症统计：Globocan 估计全球 185 个国家/地区 36 种癌症的发病率和死亡率。CA：临床医生癌症杂志 68 （6）：394–424。doi：10.3322/caac.21492."
        }
    },
    {
        "translation": {
            "en": "The main advantages of SVM models are that they are robust to overfitting and perform well for very high-dimensional problems.",
            "zh": "SVM 模型的主要优点是它们对过拟合具有鲁棒性，并且在处理非常高维的问题时表现良好。"
        }
    },
    {
        "translation": {
            "en": "positive level, 537, 538",
            "zh": "正电平，537,538"
        }
    },
    {
        "translation": {
            "en": "For example, at the bottom of the hierarchy the vertical gaps between clusterings are very small because the clusters are very close, and as we move farther up the hierarchy, the gaps get larger as clusters that are farther apart are merged.",
            "zh": "例如，在层次结构的底部，聚类之间的垂直间隙非常小，因为聚类非常接近，并且随着我们在层次结构中向上移动，随着相距较远的聚类合并，间隙会变得更大。"
        }
    },
    {
        "translation": {
            "en": "21. This also means that we no longer use the dummy descriptive feature, d[0], which we previously always set to 1; see Equation (7.9)[320].",
            "zh": "21. 这也意味着我们不再使用虚拟描述性特征 d[0]，我们以前总是将其设置为 1;见等式（7.9）[320]。"
        }
    },
    {
        "translation": {
            "en": "Conor could take the approach of always pointing to sicín on the menu, as he knows what this is and he likes chicken.",
            "zh": "康纳可以采取总是在菜单上指着 sicín 的方法，因为他知道这是什么，而且他喜欢鸡肉。"
        }
    },
    {
        "translation": {
            "en": "Use this model to make predictions for the following query instances:",
            "zh": "使用此模型对以下查询实例进行预测："
        }
    },
    {
        "translation": {
            "en": "In this discussion on local receptive fields, the filters we have presented are hand designed for the purpose of illustration.",
            "zh": "在关于局部感受野的讨论中，我们介绍的滤波器是手工设计的，用于说明目的。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.94)[490] illustrates the result of applying max pooling to the feature map from Equation (8.93)[489] using non-overlapping local receptive fields with a dimensionality of 2-by-2.",
            "zh": "方程（8.94）[490]说明了使用维数为2×2的非重叠局部感受野对等式（8.93）[489]中的特征图应用最大池化的结果。"
        }
    },
    {
        "translation": {
            "en": "directed acyclic graph, 499",
            "zh": "有向无环图，499"
        }
    },
    {
        "translation": {
            "en": "These businesses often try to predict the likelihood that users coming to the end of the trial period will accept the upsell offer to move to the paid service.",
            "zh": "这些企业经常试图预测试用期结束时的用户接受追加销售优惠以转向付费服务的可能性。"
        }
    },
    {
        "translation": {
            "en": "4. A common modification to k-means clustering in which actual instances are chosen as initial centroids, rather than random points in the feature space, easily stops this from happening.",
            "zh": "4. 对 k 均值聚类的常见修改，即选择实际实例作为初始质心，而不是特征空间中的随机点，很容易阻止这种情况的发生。"
        }
    },
    {
        "translation": {
            "en": "An illustration of the forward propagation of d2 through the ReLU network showing the weights on each connection, and the weighted sum z and activation a value for each neuron in the network.",
            "zh": "d2 通过 ReLU 网络向前传播的图示，显示了每个连接上的权重，以及网络中每个神经元的加权总和 z 和激活值。"
        }
    },
    {
        "translation": {
            "en": "Figure A.1[746] shows a group of players on a school basketball team and their heights. Using Equation (A.1)[745] we can calculate the arithmetic mean of these players’ heights as",
            "zh": "图A.1[746]显示了学校篮球队的一组球员和他们的身高。使用公式（A.1）[745]，我们可以计算出这些球员身高的算术平均值为"
        }
    },
    {
        "translation": {
            "en": "48,000",
            "zh": "48,000"
        }
    },
    {
        "translation": {
            "en": "As such, they generally work well in domains in which there are large numbers of input features (such as image, speech, or language processing), and for which there are very large datasets available for training.",
            "zh": "因此，它们通常适用于具有大量输入特征（例如图像、语音或语言处理）的领域，并且有非常大的数据集可用于训练。"
        }
    },
    {
        "translation": {
            "en": "Introduction to Probability for Machine Learning",
            "zh": "机器学习概率简介"
        }
    },
    {
        "translation": {
            "en": "(c) Show that the single-layer network using the weight matrix you calculated in Part 2 generates the same output as the network for the input vector: Neuron 1 = 0.9, Neuron 2 = 0.5.",
            "zh": "（c） 显示使用您在第 2 部分中计算的权重矩阵的单层网络生成的输出与输入向量的网络相同：神经元 1 = 0.9，神经元 2 = 0.5。"
        }
    },
    {
        "translation": {
            "en": "PSFFLUXIVAR_U/G/R/I/Z",
            "zh": "PSFFLUXIVAR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "The idea behind this was that stunting the tree made it more interpretable.",
            "zh": "这背后的想法是，使树发育迟缓使其更具可解释性。"
        }
    },
    {
        "translation": {
            "en": "In this instance the weights in the network were sampled from a normal distribution with μ = 0.0 and σ = 0.2, which means that for all k: var(W(k)) = σ2 = 0.22 = 0.04.",
            "zh": "在本例中，网络中的权重是从 μ = 0.0 和 σ = 0.2 的正态分布中采样的，这意味着对于所有 k：var（W（k）） = σ2 = 0.22 = 0.04。"
        }
    },
    {
        "translation": {
            "en": "We use a specific typography when referring to a feature by name in the text (e.g., POSITION, CREDITRATING, and CLAIM AMOUNT).",
            "zh": "在文本中按名称提及功能时，我们会使用特定的排版（例如，POSITION、CREDITRATING 和 CLAIM AMOUNT）。"
        }
    },
    {
        "translation": {
            "en": "If this condition does not hold, then the product of the two matrices is not defined.",
            "zh": "如果此条件不成立，则不会定义两个矩阵的乘积。"
        }
    },
    {
        "translation": {
            "en": "Hirschowitz, Anton. 2001. Closing the CRM loop: The 21st century marketer’s challenge: Transforming customer insight into customer value. Journal of Targeting, Measurement and Analysis for Marketing 10 (2): 168–178.",
            "zh": "赫肖维茨，安东。2001. 关闭 CRM 循环：21 世纪营销人员的挑战：将客户洞察转化为客户价值。营销目标，测量和分析杂志10（2）：168-178。"
        }
    },
    {
        "translation": {
            "en": "Visualizations of the continuous and categorical features in the motor insurance claims fraud detection ABT in Table 3.2[56].",
            "zh": "表3.2[56]中汽车保险理赔欺诈检测ABT中连续和分类特征的可视化。"
        }
    },
    {
        "translation": {
            "en": "(c) Some of the errorDelta values are missing in the preceding table (marked with a ?). Calculate these.",
            "zh": "（c） 上表中缺少一些 errorDelta 值（标有 ？）。计算这些。"
        }
    },
    {
        "translation": {
            "en": "Table 9.11",
            "zh": "表 9.11"
        }
    },
    {
        "translation": {
            "en": "10.4.6 Representation Learning with Auto-Encoders",
            "zh": "10.4.6 使用自动编码器进行表示学习"
        }
    },
    {
        "translation": {
            "en": "Both of these things would be of great use to real estate agents trying to make decisions about the rental prices they should set for new rental properties.",
            "zh": "这两件事对于试图决定他们应该为新出租物业设定的租金价格的房地产经纪人来说都非常有用。"
        }
    },
    {
        "translation": {
            "en": "27. See Section 7.3[319].",
            "zh": "27. 参见第 7.3 节[319]。"
        }
    },
    {
        "translation": {
            "en": "Table 5.12",
            "zh": "表 5.12"
        }
    },
    {
        "translation": {
            "en": "3. The following table shows the action-value table for a reinforcement learning agent learning to play the TwentyTwos game after 20 episodes of training have elapsed.",
            "zh": "3. 下表显示了强化学习代理在经过 20 集训练后学习玩 TwentyTwos 游戏的动作值表。"
        }
    },
    {
        "translation": {
            "en": "Cosine similarity is also an appropriate similarity index for sparse data with non-binary features (i.e., datasets with lots of zero values) because the dot product will essentially ignore co-absences in its computation (0 × 0 = 0).",
            "zh": "余弦相似度也是具有非二元特征的稀疏数据（即具有大量零值的数据集）的合适相似性指数，因为点积在其计算中基本上会忽略共缺 （0 × 0 = 0）。"
        }
    },
    {
        "translation": {
            "en": "Notational Conventions for Deep Learning",
            "zh": "深度学习的符号约定"
        }
    },
    {
        "translation": {
            "en": "Indeed, the activations of the neurons in a set provide a map of where in the input the relevant visual feature occurred, and for this reason the set of activations for a set of neurons that share a filter is called a feature map.",
            "zh": "事实上，一组神经元的激活提供了相关视觉特征在输入中发生的位置的映射，因此，共享过滤器的一组神经元的激活集称为特征映射。"
        }
    },
    {
        "translation": {
            "en": "episode, 639",
            "zh": "第639集"
        }
    },
    {
        "translation": {
            "en": "SOFT TISSUE are the only features with an obvious problem with missing values.",
            "zh": "SOFT TISSUE 是唯一具有明显缺失值问题的特征。"
        }
    },
    {
        "translation": {
            "en": "This process repeats until convergence occurs—where convergence is defined as having occurred when no cluster memberships change on an iteration of the algorithm and therefore the cluster centroids are stable. Once the algorithm has completed, its two outputs are a vector of assignments of each instance in the dataset to one of the clusters, 𝒞1 to 𝒞k, and the k cluster centroids, c1 to ck. This first output can be used to enrich the original dataset with a new generated feature, the cluster memberships.",
            "zh": "此过程会重复，直到收敛发生，其中收敛定义为在算法迭代中没有聚类成员身份更改时发生，因此聚类质心是稳定的。算法完成后，其两个输出是数据集中每个实例分配给其中一个聚类（C1 到 Ck）和 k 个聚类质心（c1 到 ck）的向量。第一个输出可用于使用新生成的特征（集群成员身份）来丰富原始数据集。"
        }
    },
    {
        "translation": {
            "en": "Assuming that the model uses Euclidean distance to find the nearest neighbor, what prediction will the model return for each of the following query instances?",
            "zh": "假设模型使用欧几里得距离来查找最近邻，则模型将为以下每个查询实例返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "Using a max function requires that the backward pass in the backpropagation algorithm be updated slightly.",
            "zh": "使用 max 函数需要稍微更新反向传播算法中的向后传递。"
        }
    },
    {
        "translation": {
            "en": "This extreme partitioning of the dataset into sets of single instances can happen if there are a lot of descriptive features in the dataset or if there are one or more continuous descriptive features that the algorithm is allowed to split on repeatedly.",
            "zh": "如果数据集中有很多描述性特征，或者允许算法重复拆分一个或多个连续的描述性特征，则可能会将数据集划分为单个实例集。"
        }
    },
    {
        "translation": {
            "en": "(c) The LDL cholesterol values for a large group of patients, including smokers and non-smokers.",
            "zh": "（c） 一大群患者（包括吸烟者和非吸烟者）的低密度脂蛋白胆固醇值。"
        }
    },
    {
        "translation": {
            "en": "training set, 6, 541, 719",
            "zh": "训练集， 6， 541， 719"
        }
    },
    {
        "translation": {
            "en": "7.22   A small sample of the generators dataset with two features, RPM and VIBRATION, and two target levels, good (shown as crosses) and faulty (shown as triangles): (a) a decision boundary with a very small margin; and (b) a decision boundary with a much larger margin. In both cases, the instances along the margins are highlighted.",
            "zh": "7.22 生成器数据集的一个小样本，具有两个特征，即RPM和VIBRATION，以及两个目标水平，即良好（显示为十字）和错误（显示为三角形）：（a）余量非常小的决策边界;（b）具有更大余地的决策边界。在这两种情况下，边距上的实例都会突出显示。"
        }
    },
    {
        "translation": {
            "en": "The boundary between d1 and d5 is",
            "zh": "d1 和 d5 之间的边界是"
        }
    },
    {
        "translation": {
            "en": "Next, in Line 7[476] each element in new activation vector a(l)′ is divided by the parameter ρ.",
            "zh": "接下来，在第 7 行[476] 中，新激活向量 a（l）′ 中的每个元素除以参数 ρ。"
        }
    },
    {
        "translation": {
            "en": "The overall profit for the k-NN model is $560, while it is $1,540 for the decision tree model.",
            "zh": "k-NN 模型的总利润为 560 美元，而决策树模型的总利润为 1,540 美元。"
        }
    },
    {
        "translation": {
            "en": "22. In the context of decision tree pruning, the validation set is often referred to as the pruning dataset.",
            "zh": "22. 在决策树修剪的背景下，验证集通常被称为修剪数据集。"
        }
    },
    {
        "translation": {
            "en": "F1 measure, 548, 549, 549–551, 611",
            "zh": "F1 测量，548、549、549–551、611"
        }
    },
    {
        "translation": {
            "en": "6.3.1 A Worked Example",
            "zh": "6.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "sigmoid, 625, 626",
            "zh": "乙状结肠，625,626"
        }
    },
    {
        "translation": {
            "en": "In particular, the hyperplane at a node defines the boundary between the instances stored on each of the subtrees below the node.",
            "zh": "具体而言，节点上的超平面定义了存储在节点下每个子树上的实例之间的边界。"
        }
    },
    {
        "translation": {
            "en": "Because the adjustments are made in the direction of the error surface gradient, this new point will be closer to the overall global minimum.",
            "zh": "由于调整是在误差曲面梯度方向上进行的，因此此新点将更接近整体全局最小值。"
        }
    },
    {
        "translation": {
            "en": "What is the prediction subject? What are the domain concepts? What is the target feature? What descriptive features will be used?",
            "zh": "预测主题是什么？领域概念是什么？目标功能是什么？将使用哪些描述性特征？"
        }
    },
    {
        "translation": {
            "en": "5.3   A feature space plot of the data in Table 5.2[183], with the position in the feature space of the query represented by the ? marker.",
            "zh": "5.3 表5.2[183]中数据的特征空间图，查询在特征空间中的位置用 ？标记。"
        }
    },
    {
        "translation": {
            "en": "Allowing the network to learn the filter weights means that the network is able to learn which visual patterns are useful to extract from the visual input in order to be successful at the prediction task on which it is being trained.",
            "zh": "允许网络学习滤波器权重意味着网络能够了解哪些视觉模式可用于从视觉输入中提取，以便在训练它的预测任务中取得成功。"
        }
    },
    {
        "translation": {
            "en": "Table 4.6[140] details the calculation of the information gain for each descriptive feature in 𝒟8 using this result. It is clear from the information in Table 4.6[140] that in the context of 𝒟 8, SLOPE has a higher information gain than STREAM.",
            "zh": "表4.6[140]详细说明了使用该结果计算D8中每个描述性特征的信息增益。从表4.6[140]中的信息可以清楚地看出，在D 8的上下文中，SLOPE的信息增益高于STREAM。"
        }
    },
    {
        "translation": {
            "en": "It is worth emphasizing that the scores calculated are not the actual posterior probabilities for each target level given the query evidence (to get the actual probabilities we would need to normalize these scores), but they do give us enough information to rank the different target levels based on the relative posterior probabilities.",
            "zh": "值得强调的是，计算出的分数并不是给定查询证据的每个目标水平的实际后验概率（为了获得实际概率，我们需要对这些分数进行归一化），但它们确实为我们提供了足够的信息，可以根据相对后验概率对不同的目标水平进行排名。"
        }
    },
    {
        "translation": {
            "en": "For instances along the margin extents, abs(w0 + w ·d) = 1 (according to Equation (7.44)[364]). So, the distance from any instance along the margin extents to the decision boundary is , and because the margin is symmetrical to either side of the decision boundary, the size of the margin is . The goal when training a support vector machine is to maximize subject to the constraint expressed in Equation (7.44)[364].",
            "zh": "对于沿边距范围的实例，abs（w0 + w ·d） = 1（根据公式 （7.44）[364]）。因此，沿边距范围的任何实例到决策边界的距离为 ，并且由于边距与决策边界的任一侧对称，因此边距的大小为 。训练支持向量机时的目标是在方程（7.44）[364]中表示的约束下实现最大化。"
        }
    },
    {
        "translation": {
            "en": "The final decision tree induced from the dataset in Table 4.11[152]. To illustrate how the tree generates predictions, this tree lists the instances that ended up at each leaf node and the prediction (PRED.) made by each leaf node.",
            "zh": "从表4.11[152]中的数据集中得出的最终决策树。为了说明树如何生成预测，此树列出了最终出现在每个叶节点上的实例以及每个叶节点所做的预测 （PRED.）。"
        }
    },
    {
        "translation": {
            "en": "jackknifing, 545",
            "zh": "千斤顶，545"
        }
    },
    {
        "translation": {
            "en": "This means that the error for the output at time t is also dependent on the states of the network for all the previous inputs in the sequence (t−1, t−2, and so on) back to the start of the sequence.",
            "zh": "这意味着，时间 t 处的输出误差还取决于序列中所有先前输入（t−1、t−2 等）回到序列起点的网络状态。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.15",
            "zh": "图 9.15"
        }
    },
    {
        "translation": {
            "en": "These features are not strongly covariant either positively or negatively.",
            "zh": "这些特征不是正向或负向的强协变。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.79)[469] states that δ for the neuron in the softmax output layer whose activation is the predicted probability for the correct category as specified by a 1 in the one-hot encoded target vector using the cross-entropy loss function is",
            "zh": "方程（8.79）[469]指出，softmax输出层中神经元的δ，其激活是使用交叉熵损失函数的一热编码目标向量中由1指定的正确类别的预测概率为"
        }
    },
    {
        "translation": {
            "en": "multinomial model, 311, 369, 572",
            "zh": "多项式模型， 311， 369， 572"
        }
    },
    {
        "translation": {
            "en": "Equation (13)[658] is used to perform the update as follows:",
            "zh": "公式（13）[658]用于执行更新，如下所示："
        }
    },
    {
        "translation": {
            "en": "On the basis of the predictions made by this model, the first set of errors can be calculated.",
            "zh": "根据该模型做出的预测，可以计算出第一组误差。"
        }
    },
    {
        "translation": {
            "en": "This is the point at which we say overfitting has begun to occur (this is shown by the vertical dashed line, at Training Iteration = 100, in Figure 9.3[542]).",
            "zh": "这就是我们说过拟合已经开始发生的点（这在图 9.3[542] 中由训练迭代 = 100 处的垂直虚线表示）。"
        }
    },
    {
        "translation": {
            "en": "the tree generated using information gain ratio (Figure 4.12[144]) will return VEGETATION = riparian, whereas the tree generated using information gain (Figure 4.11[141]) will return VEGETATION = conifer.",
            "zh": "使用信息增益比生成的树（图 4.12[144]）将返回 VEGETATION = 河岸，而使用信息增益生成的树（图 4.11[141]）将返回 VEGETATION = 针叶树。"
        }
    },
    {
        "translation": {
            "en": "For completeness, it is worth noting that classification accuracy is the opposite of misclassification rate. Again, using the confusion matrix, classification accuracy is defined as",
            "zh": "为了完整性，值得注意的是，分类准确率与错误分类率相反。同样，使用混淆矩阵，分类精度定义为"
        }
    },
    {
        "translation": {
            "en": "(a) Assuming that the processing neurons use logistic activation functions, that the input to the network is Neuron 1 = 0.2 and that the desired output for this input is 0.7:",
            "zh": "（a） 假设处理神经元使用逻辑激活函数，网络的输入是神经元 1 = 0.2，并且该输入的期望输出是 0.7："
        }
    },
    {
        "translation": {
            "en": "0.2855",
            "zh": "0.2855"
        }
    },
    {
        "translation": {
            "en": "Table 13.2",
            "zh": "表 13.2"
        }
    },
    {
        "translation": {
            "en": "Bellman, R. E. 1957a. Dynamic programming. Princeton University Press.",
            "zh": "Bellman， R. E. 1957a. 动态规划。普林斯顿大学出版社。"
        }
    },
    {
        "translation": {
            "en": "where TP(l) refers to the number of instances correctly given a prediction of the target level l, FP(l) refers to the number of instances that are incorrectly given a prediction of target level l, and FN(l) refers to the number of instances that should have been given a prediction of target level l but were given some other prediction.",
            "zh": "其中 TP（l） 是指正确给出目标水平 l 预测的实例数，FP（l） 是指错误地预测目标水平 l 的实例数，FN（l） 是指本应给出目标水平 l 预测但被给予其他预测的实例数。"
        }
    },
    {
        "translation": {
            "en": "Equation (8.29)[416] defines how Δw i,k is calculated for a training dataset containing m examples.",
            "zh": "方程（8.29）[416]定义了如何计算包含m个样本的训练数据集的Δw i，k。"
        }
    },
    {
        "translation": {
            "en": "The cross-entropy loss measures the dissimilarity between the true distribution t and the predicted distribution . In situations where the true distribution t is encoded as a one-hot vector, the cross-entropy loss function can be simplified to:",
            "zh": "交叉熵损失度量真实分布 t 与预测分布之间的不相异性。在真实分布 t 编码为单热向量的情况下，交叉熵损失函数可以简化为："
        }
    },
    {
        "translation": {
            "en": "—James Whitcomb Riley",
            "zh": "——詹姆斯·惠特科姆·莱利"
        }
    },
    {
        "translation": {
            "en": "This means that the current trial user is judged to be more similar to the customer represented by instance d1 than the customer represented by instance d2.",
            "zh": "这意味着，当前试用用户被判断为与实例 d1 所代表的客户比实例 d2 所代表的客户更相似。"
        }
    },
    {
        "translation": {
            "en": "The softmax function will always return a positive value for every neuron because ez is always positive, even if z is negative.",
            "zh": "softmax 函数将始终为每个神经元返回一个正值，因为 ez 始终为正值，即使 z 为负数。"
        }
    },
    {
        "translation": {
            "en": "This may indicate that the model is doing a better job of modeling the transition between the different target levels.",
            "zh": "这可能表明该模型在对不同目标水平之间的过渡进行建模方面做得更好。"
        }
    },
    {
        "translation": {
            "en": "k = 4) provide enough information to capture the state.",
            "zh": "k = 4） 提供足够的信息来捕获状态。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.7",
            "zh": "图 8.7"
        }
    },
    {
        "translation": {
            "en": "This error is shared back (backpropagated) through the network on a layer-by-layer basis until the input layer is reached.",
            "zh": "此错误通过网络逐层共享（反向传播），直到到达输入层。"
        }
    },
    {
        "translation": {
            "en": "This kind of model would be useful to architects or engineers when designing a new building.25 The trained model is",
            "zh": "这种模型在设计新建筑时对建筑师或工程师很有用.25 经过训练的模型是"
        }
    },
    {
        "translation": {
            "en": "The dimensions of this input are 3-by-2-by-2, and so all the filters in the second layer have a depth of 2.",
            "zh": "此输入的尺寸为 3×2×2，因此第二层中的所有滤波器的深度为 2。"
        }
    },
    {
        "translation": {
            "en": "test statistic, 333",
            "zh": "检验统计量，333"
        }
    },
    {
        "translation": {
            "en": "The average class accuracy performance measure can be effective in these cases.",
            "zh": "在这些情况下，平均类准确性性能测量可能很有效。"
        }
    },
    {
        "translation": {
            "en": "7.19   A selection of the models developed during the gradient descent process for the EEG dataset from Table 7.10[355]. The final panel shows the decision surface generated.",
            "zh": "7.19 表7.10[355]中脑电图数据集梯度下降过程中开发的模型选择。最后一个面板显示生成的决策面。"
        }
    },
    {
        "translation": {
            "en": "QERR_U/G/R/I/Z",
            "zh": "QERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Table 4.10[148] shows the computation of information gain for a split using each of these thresholds.",
            "zh": "表4.10[148]显示了使用这些阈值中的每一个进行拆分的信息增益计算。"
        }
    },
    {
        "translation": {
            "en": "The differences between Figures 7.7(f)[329] and 7.8(b)[335] most clearly show the impact of learning rate decay as the initial learning rates are the same in these two instances.",
            "zh": "图7.7（f）[329]和图7.8（b）[335]之间的差异最清楚地表明了学习率衰减的影响，因为这两个实例的初始学习率是相同的。"
        }
    },
    {
        "translation": {
            "en": "In the middle of the graph, at the bottom of the curve, the rate of change is zero.",
            "zh": "在图表的中间，在曲线的底部，变化率为零。"
        }
    },
    {
        "translation": {
            "en": "Second, we would be able to fill in the gaps in the dataset to predict office rental prices for office sizes that we have never actually seen in the historical data—for example, how much would we expect a 730-square-foot office to rent for?",
            "zh": "其次，我们将能够填补数据集中的空白，以预测我们在历史数据中从未见过的办公室规模的办公室租金价格——例如，我们预计一个 730 平方英尺的办公室租金是多少？"
        }
    },
    {
        "translation": {
            "en": "For continuous prediction problems, use the R2 coefficient.",
            "zh": "对于连续预测问题，请使用 R2 系数。"
        }
    },
    {
        "translation": {
            "en": "DEVAB_U/G/R/I/Z",
            "zh": "DEVAB_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "8.25   The internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights were initialized using Xavier initialization.",
            "zh": "8.25 图 8.22[450] 中第一次训练迭代期间使用 Xavier 初始化权重时网络的内部动力学。"
        }
    },
    {
        "translation": {
            "en": "covariance matrix, 83, 219",
            "zh": "协方差矩阵， 83， 219"
        }
    },
    {
        "translation": {
            "en": "Examples of domain concepts include customer value, behavioral change, product usage mix, and customer lifecycle stage.",
            "zh": "领域概念的示例包括客户价值、行为变化、产品使用组合和客户生命周期阶段。"
        }
    },
    {
        "translation": {
            "en": "In order to find the optimal set of weights, we need some way to measure how well a model defined using a candidate set of weights fits a training dataset.",
            "zh": "为了找到最佳权重集，我们需要某种方法来衡量使用候选权重集定义的模型与训练数据集的拟合程度。"
        }
    },
    {
        "translation": {
            "en": "2.9   A subset of the domain concepts and related features for a motor insurance fraud prediction analytics solution.",
            "zh": "2.9 汽车保险欺诈预测分析解决方案的领域概念和相关功能的子集。"
        }
    },
    {
        "translation": {
            "en": "In this calculation, for each possible card Shannon’s model multiplies a small probability, P(card) = i, by a large negative number, log2(P(card) = i), resulting in a relatively large negative number. The individual relatively large negative numbers calculated for all the cards are then summed to return one large negative number. The sign of this is inverted to give a large positive value for the entropy of this very impure set.",
            "zh": "在此计算中，对于每个可能的卡，Shannon 模型将一个小概率 P（card） = i 乘以一个大的负数 log2（P（card） = i），得到一个相对较大的负数。然后，将计算出的单个相对较大的负数相加，返回一个大的负数。这个符号是颠倒的，为这个非常不纯的集合的熵给出了一个很大的正值。"
        }
    },
    {
        "translation": {
            "en": "(a) Using a classification threshold of 0.5, and assuming that true is the positive target level, construct a confusion matrix for each of the models.",
            "zh": "（a） 使用0.5的分类阈值，并假设真为正目标水平，为每个模型构建一个混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "Certain phases in CRISP-DM are more closely linked together than others.",
            "zh": "CRISP-DM中的某些阶段比其他阶段更紧密地联系在一起。"
        }
    },
    {
        "translation": {
            "en": "We can get a hint about what is happening by comparing the distances computed using both the SALARY and AGE features with the distances computed using the SALARY feature only, that listed in the SALARY Only section of Table 5.6[206].",
            "zh": "通过比较使用 SALARY 和 AGE 特征计算的距离与仅使用 SALARY 特征计算的距离（在表 5.6[206] 的 SALARY 部分中列出的距离），我们可以得到有关正在发生的事情的提示。"
        }
    },
    {
        "translation": {
            "en": "All the other choices that we make, such as the data to use, the descriptive features to use, and the way in which we deploy a model, bias the outcome of the overall process, and this is something that we need to be keenly aware of.",
            "zh": "我们做出的所有其他选择，例如要使用的数据、要使用的描述性特征以及我们部署模型的方式，都会对整个过程的结果产生偏见，这是我们需要敏锐地意识到的事情。"
        }
    },
    {
        "translation": {
            "en": "MARTHA",
            "zh": "马大"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_G_R",
            "zh": "DEREDDIFF_G_R"
        }
    },
    {
        "translation": {
            "en": "For datasets containing more that 4,000 features, random forest ensembles (based on bagging) performed better.",
            "zh": "对于包含超过 4,000 个特征的数据集，随机森林集合（基于装袋）表现更好。"
        }
    },
    {
        "translation": {
            "en": "The model that best fits the training data is the model corresponding to the lowest point on the error surface.",
            "zh": "最适合训练数据的模型是与误差曲面上的最低点对应的模型。"
        }
    },
    {
        "translation": {
            "en": "Branches that are deemed likely to be due to overfitting are pruned.",
            "zh": "修剪可能由于过度拟合而导致的分支。"
        }
    },
    {
        "translation": {
            "en": "2. The following table shows details of two different clusterings of the dataset from Question 1—one with k = 2 and one with k = 3—and partial workings to calculate the silhouette for the clusterings.",
            "zh": "2. 下表显示了问题 1 中数据集的两个不同聚类的详细信息（一个是 k = 2，另一个是 k = 3），以及计算聚类轮廓的部分工作原理。"
        }
    },
    {
        "translation": {
            "en": "0.6679",
            "zh": "0.6679"
        }
    },
    {
        "translation": {
            "en": "A basic operation on vectors and matrices to the transpose. The transpose of a vector converts a column vector to a row vector, and vice versa. If a is a vector, then we write a⊺ for the transpose of a. For example:",
            "zh": "对向量和矩阵进行转置的基本操作。向量的转置将列向量转换为行向量，反之亦然。如果 a 是向量，那么我们写 a⊺ 作为 a 的转置。例如："
        }
    },
    {
        "translation": {
            "en": "We use the → notation to represent an agent transitioning from one state to another. Therefore, the probability of an agent moving from state s1 to state s2 can be written",
            "zh": "我们使用 → 表示法来表示从一种状态转换到另一种状态的代理。因此，可以写入智能体从状态 s1 移动到状态 s2 的概率"
        }
    },
    {
        "translation": {
            "en": "We also include the GENDER of the patient (male or female).",
            "zh": "我们还包括患者的性别（男性或女性）。"
        }
    },
    {
        "translation": {
            "en": "7.4.4 Handling Categorical Target Features: Logistic Regression",
            "zh": "7.4.4 处理分类目标特征：逻辑回归"
        }
    },
    {
        "translation": {
            "en": "We start by outlining the fundamental goals of evaluation before describing the standard approach of measuring the misclassification rate for a model on a hold-out test set.",
            "zh": "我们首先概述了评估的基本目标，然后描述了在保持测试集上测量模型错误分类率的标准方法。"
        }
    },
    {
        "translation": {
            "en": "During the backward pass of the algorithm, we calculate a separate weight update for each neuron that uses the weight, and then the final weight update that is applied is the sum of these separate weight updates.",
            "zh": "在算法的向后传递过程中，我们为使用权重的每个神经元计算单独的权重更新，然后应用的最终权重更新是这些单独权重更新的总和。"
        }
    },
    {
        "translation": {
            "en": "Therefore, using control groups is not suitable in all scenarios, but when it is applicable, it adds an extra dimension to our evaluations that takes into account not just how well a model can make predictions, but also how much the predictive model helps to address the original business problem.",
            "zh": "因此，使用控制组并不适合所有场景，但是当它适用时，它会为我们的评估增加一个额外的维度，该维度不仅考虑了模型进行预测的能力，还考虑了预测模型对解决原始业务问题的帮助程度。"
        }
    },
    {
        "translation": {
            "en": "Assuming again that the same random number as before (0.0728) that is less than ε is generated, random action selection will be used and a1 = down will again be selected.",
            "zh": "再次假设生成与之前相同的随机数 （0.0728） 且小于 ε，将使用随机操作选择并再次选择 a1 = down。"
        }
    },
    {
        "translation": {
            "en": "3.5 Advanced Data Exploration",
            "zh": "3.5 高级数据探索"
        }
    },
    {
        "translation": {
            "en": "multivariable linear regression, 319, 319, 575",
            "zh": "多变量线性回归， 319， 319， 575"
        }
    },
    {
        "translation": {
            "en": "(c) What prediction would a naive Bayes classifier return for the above book?",
            "zh": "（丙）一个朴素的贝叶斯分类器会为上述书返回什么预测？"
        }
    },
    {
        "translation": {
            "en": "However, this is not necessarily a problem: if we consider the backpropagation process as error gradients, δs, flowing through a layer of neurons then, although for some neurons in the layer the δs will go to zero, for others the gradients will pass through unscaled.",
            "zh": "然而，这并不一定是一个问题：如果我们将反向传播过程视为流经一层神经元的误差梯度 δs，那么，尽管对于该层中的某些神经元，δs 将变为零，而对于其他神经元，梯度将通过未缩放。"
        }
    },
    {
        "translation": {
            "en": "If we use n out to denote this number, then for the neurons in the last hidden layer nout(HL5) = 1 because there is only a single neuron in the output layer, and for the neurons in all the other layers in the network nout = 100.",
            "zh": "如果我们用 n out 来表示这个数字，那么对于最后一个隐藏层中的神经元，nout（HL5） = 1，因为输出层中只有一个神经元，而对于网络中所有其他层中的神经元，nout = 100。"
        }
    },
    {
        "translation": {
            "en": "This is not because of the literal message in the answer (either yes or no).",
            "zh": "这不是因为答案中的字面信息（是或否）。"
        }
    },
    {
        "translation": {
            "en": "3.4   The structure of a data quality plan.",
            "zh": "3.4 数据质量计划的结构。"
        }
    },
    {
        "translation": {
            "en": "Partition sets (Part.), entropy, remainder (Rem.), and information gain (Info. Gain) by feature for the dataset 𝒟8 in Figure 4.9[139].",
            "zh": "图4.9[139]中数据集D8的分区集（部分）、熵、余数（Rem.）和信息增益（Info.Gain）。"
        }
    },
    {
        "translation": {
            "en": "Recall, on the other hand, tells us how likely it is that a spam email will be missed by the system and end up in our in-box: 33.333% (1 − recall).",
            "zh": "另一方面，召回告诉我们系统遗漏垃圾邮件并最终进入我们的收件箱的可能性：33.333%（1 - 召回）。"
        }
    },
    {
        "translation": {
            "en": "If the model is asked to make a prediction about an instance that was used to train it, the model will find as the nearest neighbor, for this instance, the instance itself.",
            "zh": "如果要求模型对用于训练它的实例进行预测，则模型将找到实例本身作为最近邻。"
        }
    },
    {
        "translation": {
            "en": "MINI-BATCH",
            "zh": "小批量"
        }
    },
    {
        "translation": {
            "en": "To fit the exponential distribution, we compute the sample mean of the ACCOUNT BALANCE feature in the set of instances where FRAUD = true and set the λ parameter equal to 1 divided by this value.",
            "zh": "为了拟合指数分布，我们计算了 FRAUD = true 的一组实例中 ACCOUNT BALANCE 特征的样本均值，并将 λ 参数设置为等于 1 除以该值。"
        }
    },
    {
        "translation": {
            "en": "2. the prior probability of that target level P(t)",
            "zh": "2. 该目标水平 P（t） 的先验概率"
        }
    },
    {
        "translation": {
            "en": "(b) On the basis of the completed table, calculate the silhouette for each clustering.",
            "zh": "（b） 根据完成的表格，计算每个聚类的轮廓。"
        }
    },
    {
        "translation": {
            "en": "We can also use summing out to compute conditional probabilities from a joint probability distribution.",
            "zh": "我们还可以使用求和从联合概率分布中计算条件概率。"
        }
    },
    {
        "translation": {
            "en": "logarithm, 124",
            "zh": "对数，124"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrix is shown in Table 13.10[725].",
            "zh": "由此产生的混淆矩阵如表13.10[725]所示。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.21(d)[163] illustrates the new distribution that arises from these changes, in which the weight of the segments highlighted in black have increased, and those in gray have decreased. The details of the next iteration of the boosting process are also detailed in Table 4.14[162] and Figure 4.21(e)[163].",
            "zh": "图4.21（d）[163]显示了这些变化产生的新分布，其中黑色突出显示的线段的权重增加，灰色线段的权重减少。表4.14[162]和图4.21（e）[163]中也详细介绍了提升过程的下一次迭代。"
        }
    },
    {
        "translation": {
            "en": "Calculating the sum of squared errors for the candidate model (with w[0] = 6.47 and w[1] = 0.62) to make predictions for the office rentals dataset.",
            "zh": "计算候选模型的平方误差总和（w[0] = 6.47 和 w[1] = 0.62），以对办公室租赁数据集进行预测。"
        }
    },
    {
        "translation": {
            "en": "In order to use a PDF to represent the probability of a continuous feature taking different values, we need to choose these parameters to fit the characteristics of the data.",
            "zh": "为了使用 PDF 来表示连续特征取不同值的概率，我们需要选择这些参数来拟合数据的特征。"
        }
    },
    {
        "translation": {
            "en": "Finally, as noted earlier, decision tree induction is, relatively, robust to noise in the dataset if pruning is used.",
            "zh": "最后，如前所述，如果使用修剪，决策树归纳对数据集中的噪声相对鲁棒。"
        }
    },
    {
        "translation": {
            "en": "On the basis of these constraints, the algorithm defines three situations where the recursion stops and a leaf node is constructed:",
            "zh": "基于这些约束，该算法定义了递归停止并构造叶节点的三种情况："
        }
    },
    {
        "translation": {
            "en": "(d) Calculate the sum of squared errors for a set of predictions generated using the new set of weights calculated in Part (c).",
            "zh": "（d） 计算使用（c）部分计算的新权重组生成的一组预测的平方误差和。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.10(c)[675] shows the changing cumulative reward for the DQN agent as it learns to play the Lunar Lander game. The steady increase of return clearly shows that the agent was improving its performance over time. Figure 11.10(a)[675] shows a series of screens from an episode early in the training process in which the agent performed quite poorly. This can be compared to the screens in Figure 11.10(b)[675] which are from an episode much later in training at which the agent is performing quite well.",
            "zh": "图11.10（c）[675]显示了DQN智能体在学习玩月球着陆器游戏时不断变化的累积奖励。回报的稳步增长清楚地表明，随着时间的推移，代理正在改善其性能。图 11.10（a）[675] 显示了训练过程早期的一系列屏幕，其中代理的表现相当糟糕。这可以与图11.10（b）[675]中的屏幕进行比较，这些屏幕来自训练后期的一集，代理在训练中表现相当不错。"
        }
    },
    {
        "translation": {
            "en": "So, if a weight is shared by m different neurons, then the weight update after processing a single example is defined as follows:",
            "zh": "因此，如果一个权重由 m 个不同的神经元共享，那么处理单个示例后的权重更新定义如下："
        }
    },
    {
        "translation": {
            "en": "“The history of astronomy is a history of receding horizons.”",
            "zh": "“天文学的历史是一部地平线后退的历史。”"
        }
    },
    {
        "translation": {
            "en": "Notation",
            "zh": "表示法"
        }
    },
    {
        "translation": {
            "en": "After estimating the performance of a deployed model using k-fold cross validation, we typically train the model that will be deployed using all of the available data.",
            "zh": "在使用 k 折叠交叉验证估计已部署模型的性能后，我们通常会使用所有可用数据来训练将要部署的模型。"
        }
    },
    {
        "translation": {
            "en": "In looking at the summary statistics and visualizations with these priorities in mind, it is clear that the customers in 1 are characterized most strongly by their low Data Usage, customers in 2 by their high Data Usage, and customers in 3 by their high Call Volume.",
            "zh": "在考虑这些优先级的汇总统计数据和可视化时，很明显，1 中的客户最强烈的特征是数据使用率低，2 中的客户数据使用率高，3 中的客户呼叫量高。"
        }
    },
    {
        "translation": {
            "en": "The outputs of this model are combined with the 1 predictions to give the full model for this step in the ensemble building process, 2.",
            "zh": "该模型的输出与 1 个预测相结合，为集成构建过程中的这一步 2 提供了完整的模型。"
        }
    },
    {
        "translation": {
            "en": "It is possible, however, to determine the slope of the error surface by determining the derivative of the function used to generate it, and then calculating the value of this derivative at the random point selected in the weight space.",
            "zh": "但是，可以通过确定用于生成误差面的函数的导数，然后在权重空间中选择的随机点计算该导数的值来确定误差曲面的斜率。"
        }
    },
    {
        "translation": {
            "en": "7.2.3 Error Surfaces",
            "zh": "7.2.3 错误面"
        }
    },
    {
        "translation": {
            "en": "Collecting spectrographic information involves a much more complicated process than capturing imaging data, so it is done for a much smaller portion of the sky.",
            "zh": "收集光谱信息涉及比捕获成像数据复杂得多的过程，因此它是针对天空的一小部分完成的。"
        }
    },
    {
        "translation": {
            "en": "DEVABERR_U/G/R/I/Z",
            "zh": "DEVABERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "As a result, it is typically easier to collect the data required to calculate these probabilities.",
            "zh": "因此，通常更容易收集计算这些概率所需的数据。"
        }
    },
    {
        "translation": {
            "en": "At AT, all calls were classified as either peak time calls or off-peak time calls.",
            "zh": "在 AT，所有呼叫都被归类为高峰时段呼叫或非高峰时段呼叫。"
        }
    },
    {
        "translation": {
            "en": "maximum a posteriori, 254, 261, 556",
            "zh": "最大 A 后验，254、261、556"
        }
    },
    {
        "translation": {
            "en": "The unrolling of the network through time during the forward pass means that some neurons49 will occur multiple times in the unrolled network, and we store the weighted sum z value and activation value a of each neuron at each time-step.",
            "zh": "在前向传递过程中，网络随时间展开意味着一些神经元49将在展开的网络中多次出现，我们在每个时间步长存储每个神经元的加权总和z值和激活值a。"
        }
    },
    {
        "translation": {
            "en": "where k is the number of instances inside the hypercube, and m is the number of dimensions of the feature space.",
            "zh": "其中 k 是超立方体内的实例数，m 是特征空间的维数。"
        }
    },
    {
        "translation": {
            "en": "Often, choosing the number of bins comes down to intuition and a process of trial and error experimentation.",
            "zh": "通常，选择箱子的数量归结为直觉和试错实验的过程。"
        }
    },
    {
        "translation": {
            "en": "The advantage of this is that, except for introducing the mechanism of basis functions, we do not need to make any other changes to the approach we have presented so far.",
            "zh": "这样做的好处是，除了引入基函数的机制外，我们不需要对迄今为止提出的方法进行任何其他更改。"
        }
    },
    {
        "translation": {
            "en": "The K-S chart for the email classification predictions shown in Table 9.11[557].",
            "zh": "表 9.11[557] 中所示的电子邮件分类预测的 K-S 图。"
        }
    },
    {
        "translation": {
            "en": "which states that the maximum cumulative return following an action at taken in a state st is earned by continuing to take the action that will return the maximum return.",
            "zh": "它指出，在状态 ST 中采取的行动后的最大累积回报是通过继续采取将返回最大回报的行动来获得的。"
        }
    },
    {
        "translation": {
            "en": "Using a standard t-statistic look-up table, we can then determine the p-value associated with this test (this is a two tailed t-test with degrees of freedom set to the number of instances in the training set minus 2).",
            "zh": "然后，使用标准的 t 统计量查找表，我们可以确定与此检验相关的 p 值（这是一个双尾 t 检验，其自由度设置为训练集中的实例数减去 2）。"
        }
    },
    {
        "translation": {
            "en": "The only drawback to standardization is that the models become less interpretable.",
            "zh": "标准化的唯一缺点是模型变得不那么可解释。"
        }
    },
    {
        "translation": {
            "en": "Both precision and recall can assume values in the range [0,1], and higher values in both cases indicate better model performance.",
            "zh": "精确度和召回率都可以假定值在 [0,1] 范围内，这两种情况下的值越高表示模型性能越好。"
        }
    },
    {
        "translation": {
            "en": "Table 8.15[471] steps through the calculations that bring us from the logits for each of the neurons for each example to the corresponding softmax activations and then to the δs for each neuron for each example.",
            "zh": "表 8.15[471] 逐步完成计算，从每个示例的每个神经元的对数到相应的 softmax 激活，然后到每个示例的每个神经元的 δs。"
        }
    },
    {
        "translation": {
            "en": "The key difference, however, is that reinforcement learning does not require a labeled dataset containing examples of correct behavior to learn from.",
            "zh": "然而，关键的区别在于，强化学习不需要包含正确行为示例的标记数据集来学习。"
        }
    },
    {
        "translation": {
            "en": "TPR, 548",
            "zh": "TPR，548"
        }
    },
    {
        "translation": {
            "en": "Convolutional neural networks combine local receptive fields, weight sharing, and sub-sampling.",
            "zh": "卷积神经网络结合了局部感受野、权重共享和子采样。"
        }
    },
    {
        "translation": {
            "en": "While this is an improvement over raw classification accuracy, many people prefer to use a harmonic mean10 instead of an arithmetic mean when calculating average class accuracy.",
            "zh": "虽然这是对原始分类准确性的改进，但在计算平均类准确度时，许多人更喜欢使用谐波平均值10而不是算术平均值。"
        }
    },
    {
        "translation": {
            "en": "This puts an extra burden on developers to implement these supports themselves.",
            "zh": "这给开发人员带来了额外的负担，让他们自己实现这些支持。"
        }
    },
    {
        "translation": {
            "en": "This distribution contained 16 entries.",
            "zh": "此发行版包含 16 个条目。"
        }
    },
    {
        "translation": {
            "en": "Lehmann, Thomas Martin, Mark Oliver Güld, Daniel Keysers, Henning Schubert, Michael Kohnen, and Berthold B. Wein. 2003. Determining the view of chest radiographs. Journal of Digital Imaging 16 (3): 280–291.",
            "zh": "莱曼、托马斯·马丁、马克·奥利弗·居尔德、丹尼尔·凯瑟斯、亨宁·舒伯特、迈克尔·科宁和贝特霍尔德·温。2003. 确定胸片的视图。数字成像杂志 16 （3）：280–291。"
        }
    },
    {
        "translation": {
            "en": "5.5 Summary",
            "zh": "5.5 小结"
        }
    },
    {
        "translation": {
            "en": "PEAKOFFPEAKRATIO",
            "zh": "峰值关闭峰值比率"
        }
    },
    {
        "translation": {
            "en": "Consequently, this neuron will use nin weights in its weighted sum w =< w1,…wnin >",
            "zh": "因此，该神经元将在其加权和 w =< w1 中使用 nin 权重,...WNIN >"
        }
    },
    {
        "translation": {
            "en": "12.3 Data Preparation",
            "zh": "12.3 数据准备"
        }
    },
    {
        "translation": {
            "en": "13.8   (a)–(c) Small multiple box plots (split by the target feature) of some of the features from the SDSS ABT.",
            "zh": "13.8 （a）–（c） SDSS ABT中一些特征的小多箱形图（按目标特征划分）。"
        }
    },
    {
        "translation": {
            "en": "Model ensembles combining bagging, subspace sampling, and decision trees are known as random forest models.",
            "zh": "结合装袋、子空间采样和决策树的模型集成称为随机森林模型。"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes model addresses this problem by naively assuming that each of the descriptive features in a domain is conditionally independent of all the other descriptive features, given the state of the target feature. This assumption, although often wrong, enables the naive Bayes model to maximally factorize the representation that it uses of the domain—in other words, to use the smallest possible number of probabilities to represent the domain.",
            "zh": "朴素贝叶斯模型通过天真地假设域中的每个描述性特征在给定目标特征的状态下有条件地独立于所有其他描述性特征来解决这个问题。这个假设虽然经常是错误的，但它使朴素贝叶斯模型能够最大限度地分解它使用的域表示，换句话说，使用尽可能少的概率来表示域。"
        }
    },
    {
        "translation": {
            "en": "If there are a large number of descriptive features, then we will need a large training dataset.",
            "zh": "如果有大量的描述性特征，那么我们将需要一个大型训练数据集。"
        }
    },
    {
        "translation": {
            "en": "For example, given the following query:",
            "zh": "例如，给定以下查询："
        }
    },
    {
        "translation": {
            "en": "Features have been extracted from these biopsies by lab technicians who rate samples across a number of cagegories on a scale of 1 to 10.",
            "zh": "实验室技术人员从这些活检中提取了特征，他们以 1 到 10 的等级对多个笼子的样本进行评分。"
        }
    },
    {
        "translation": {
            "en": "This means that there is no uncertainty about the result when a selection is made from this set.",
            "zh": "这意味着从此集合中进行选择时，结果没有不确定性。"
        }
    },
    {
        "translation": {
            "en": "Technically these boundaries are hyperplanes11 and, as we shall see, play an important role when we are using the k-d tree to find the nearest neighbor for a query.",
            "zh": "从技术上讲，这些边界是超平面11，正如我们将看到的，当我们使用 k-d 树查找查询的最近邻时，它们起着重要作用。"
        }
    },
    {
        "translation": {
            "en": "20. If either vector used to calculate a cosine similarity contains negative feature values, then the cosine similarity will actually be in the range [−1,1]. As previously, 1 indicates high similarity, and 0 indicates dissimilarity, but it can be difficult to interpret negative similarity scores. Negative similarity values can be avoided, however, if we use range normalization (see Section 3.6.1[87]) to ensure that descriptive feature values always remain positive.",
            "zh": "20. 如果用于计算余弦相似度的任一向量都包含负特征值，则余弦相似度实际上将在 [−1,1] 范围内。如前所述，1 表示高相似性，0 表示不相似性，但可能很难解释负相似性分数。但是，如果我们使用范围归一化（参见第 3.6.1 节[87]）来确保描述性特征值始终保持正值，则可以避免负相似性值。"
        }
    },
    {
        "translation": {
            "en": "To overcome this, sequences of the last k screenshots stacked together can be used as the state representation.",
            "zh": "为了克服这个问题，可以将最后 k 个屏幕截图堆叠在一起的序列用作状态表示。"
        }
    },
    {
        "translation": {
            "en": "Anscombe’s quartet. For all four samples, the correlation measure returns the same value (0.816) even though the relationship between the features is very different in each case.",
            "zh": "安斯科姆的四重奏。对于所有四个样本，相关度量返回相同的值 （0.816），尽管每种情况下特征之间的关系都非常不同。"
        }
    },
    {
        "translation": {
            "en": "A well-known algorithm that focuses on this approach to reducing the complexity is the variable elimination algorithm (Zhang and Poole, 1994).",
            "zh": "一个著名的算法专注于降低复杂性的方法，是变量消除算法（Zhang和Poole，1994）。"
        }
    },
    {
        "translation": {
            "en": "—Samuel Beckett",
            "zh": "——塞缪尔·贝克特"
        }
    },
    {
        "translation": {
            "en": "However, if we then add the bias term (the y-intercept) to the results of the linear function, we are translating the results of the linear function away from the origin.",
            "zh": "但是，如果我们随后将偏置项（y 截距）添加到线性函数的结果中，我们将线性函数的结果从原点转换。"
        }
    },
    {
        "translation": {
            "en": "where 𝕄(q) is the prediction made by the model for the query q, levels(t) is the set of levels in the domain of the target feature t, and BayesianNetwork(t = l,q) returns the probability computed by the network for the event t = l given the evidence specified in the query q.",
            "zh": "其中 M（q） 是模型对查询 q 所做的预测，levels（t） 是目标要素 t 域中的水平集，BayesianNetwork（t = l，q） 返回网络在给定查询 q 中指定的证据的情况下为事件 t = l 计算的概率。"
        }
    },
    {
        "translation": {
            "en": "Figure 9.17[571] shows cumulative gain, lift, and cumulative lift charts (the gain chart is not shown as it is essentially the same as the lift chart) for four different sets of model predictions for the larger version of the email classification test set (these are the same predictions for which ROC charts and K-S charts were plotted in Figures 9.12(b)[562] and 9.14[566]).",
            "zh": "图 9.17[571] 显示了较大版本的电子邮件分类测试集的四组不同模型预测的累积增益、提升和累积提升图（增益图未显示，因为它与提升图基本相同）（这些预测与图 9.12（b）[562] 和 9.14[566] 中绘制的 ROC 图和 K-S 图相同）。"
        }
    },
    {
        "translation": {
            "en": "13.1.1 Situational Fluency",
            "zh": "13.1.1 情境流畅性"
        }
    },
    {
        "translation": {
            "en": "The Outcome column of Table 9.1[537] shows the category to which each prediction made by the model belongs. One thing worth keeping in mind is that there are two ways in which the prediction made by a model can be correct—true positive or true negative—and two ways in which the prediction made by a model can be incorrect—false positive or false negative.2 The confusion matrix allows us to capture these different types of correct and incorrect predictions made by the model.",
            "zh": "表9.1[537]的“结果”列显示了模型所做的每个预测所属的类别。值得记住的一件事是，模型做出的预测可以通过两种方式正确（真正或真阴），以及模型做出的预测可能不正确的两种方式（假阳性或假阴性）.2 混淆矩阵允许我们捕获模型做出的这些不同类型的正确和错误预测。"
        }
    },
    {
        "translation": {
            "en": "Table 6.5",
            "zh": "表 6.5"
        }
    },
    {
        "translation": {
            "en": "Throughout the chapter we return to a case study that demonstrates how these approaches are used in practice.",
            "zh": "在本章中，我们将回到一个案例研究，该案例研究展示了这些方法在实践中的使用方式。"
        }
    },
    {
        "translation": {
            "en": "To avoid this kind of extreme partitioning, we introduce an early stopping criterion into the algorithm for building regression trees.",
            "zh": "为了避免这种极端的分区，我们在构建回归树的算法中引入了一个早期停止标准。"
        }
    },
    {
        "translation": {
            "en": "A mixture of Gaussians distribution is defined by three parameters for each component: a mean, μ, a standard deviation, σ, and a weight, ω.",
            "zh": "高斯分布的混合由每个分量的三个参数定义：均值、μ、标准差 σ 和权重 ω。"
        }
    },
    {
        "translation": {
            "en": "where the sum of squared errors is computed using Equation (9.25)[575], and the total sum of squares is given by",
            "zh": "其中，误差的平方和使用公式（9.25）[575]计算，平方和的总和由下式给出"
        }
    },
    {
        "translation": {
            "en": "This means that we only need to test whether the difference between the value for this feature for the query instance and the value for this feature that defines the hyperplane is less than the best-distance (Line 8).",
            "zh": "这意味着我们只需要测试查询实例的此功能值与定义超平面的此功能值之间的差值是否小于最佳距离（第 8 行）。"
        }
    },
    {
        "translation": {
            "en": "The more interesting descriptive features were ones that had to be derived from the raw data sources.",
            "zh": "更有趣的描述性特征是必须从原始数据源派生的特征。"
        }
    },
    {
        "translation": {
            "en": "under-sampling, 93, 720",
            "zh": "欠采样， 93， 720"
        }
    },
    {
        "translation": {
            "en": "7.20   An illustration of three different one-versus-all prediction models for the customer type dataset in Table 7.11[359], with three target levels: (a) single (squares), (b) business (triangles), and (c) family (crosses).",
            "zh": "7.20 表7.11[359]中客户类型数据集的三种不同的一对一预测模型的图示，具有三个目标水平：（a）单（正方形），（b）业务（三角形）和（c）系列（十字）。"
        }
    },
    {
        "translation": {
            "en": "Support vector machines are also non-parametric models.",
            "zh": "支持向量机也是非参数模型。"
        }
    },
    {
        "translation": {
            "en": "This complexity and the excessive depth of the tree suggest overfitting.",
            "zh": "这种复杂性和树的过深表明过度拟合。"
        }
    },
    {
        "translation": {
            "en": "As with our previous calculations, the posterior probabilities for meningitis, calculated under the assumption of conditional independence of the evidence, indicates that the patient probably does not have meningitis, and consequently, a MAP Bayesian model would return MENINGITIS = false as the prediction for this query instance.",
            "zh": "与我们之前的计算一样，在证据条件独立性的假设下计算的脑膜炎后验概率表明患者可能没有脑膜炎，因此，MAP 贝叶斯模型将返回脑膜炎 = false 作为此查询实例的预测。"
        }
    },
    {
        "translation": {
            "en": "If there is no relationship, then we should expect that the levels of the first feature will be evenly distributed among the instances having the different levels of the second feature, so all bar plots will look much the same.",
            "zh": "如果没有关系，那么我们应该期望第一个特征的级别将均匀分布在具有第二个特征不同级别的实例中，因此所有条形图看起来都差不多。"
        }
    },
    {
        "translation": {
            "en": "Forward sequential selection is a good approach if we expect lots of irrelevant features in the dataset, because typically it results in a lower overall computational cost for feature selection due to the fact that on average it generates smaller feature subsets.",
            "zh": "如果我们期望数据集中有很多不相关的特征，那么前向顺序选择是一种很好的方法，因为通常它会导致特征选择的总体计算成本降低，因为它平均生成较小的特征子集。"
        }
    },
    {
        "translation": {
            "en": "There is a range of different criteria that can be used, from a very simple threshold on the number of instances at a node in the tree, to statistical significance texts like χ2.",
            "zh": "可以使用一系列不同的标准，从树中节点处实例数的非常简单的阈值，到像 χ2 这样的统计显著性文本。"
        }
    },
    {
        "translation": {
            "en": "The choice, however, is arbitrary.",
            "zh": "然而，选择是任意的。"
        }
    },
    {
        "translation": {
            "en": "21. Because of the random nature of state transitions in TwentyTwos, a lot of episodes are needed for learning to converge.",
            "zh": "21. 由于 TwentyTwo 中状态转换的随机性，需要很多情节才能学会收敛。"
        }
    },
    {
        "translation": {
            "en": "This line is known as a decision boundary, and because we can draw this line, this dataset is said to be linearly separable in terms of the two descriptive features used.",
            "zh": "这条线被称为决策边界，因为我们可以画这条线，所以这个数据集在使用的两个描述性特征方面是线性可分离的。"
        }
    },
    {
        "translation": {
            "en": "The average target value for the drug dosage prediction test set given in Table 9.20[576] is 11.132.",
            "zh": "表9.20[576]中给出的药物剂量预测测试集的平均目标值为11.132。"
        }
    },
    {
        "translation": {
            "en": "Bayesian MAP prediction model, 254",
            "zh": "贝叶斯MAP预测模型，254"
        }
    },
    {
        "translation": {
            "en": "Second, the larger the correlation between two features, the less weight they contribute to the distance.",
            "zh": "其次，两个特征之间的相关性越大，它们对距离的贡献就越小。"
        }
    },
    {
        "translation": {
            "en": "4   Information-Based Learning",
            "zh": "4 信息化学习"
        }
    },
    {
        "translation": {
            "en": "This illustrates the big idea underlying probability-based machine learning. We can use estimates of likelihoods to determine the most likely predictions that should be made. Most important, though, we revise these predictions based on data we collect and whenever extra evidence becomes available.",
            "zh": "这说明了基于概率的机器学习背后的大概念。我们可以使用可能性的估计来确定应该做出的最可能的预测。但最重要的是，我们会根据收集的数据以及每当有额外证据可用时修改这些预测。"
        }
    },
    {
        "translation": {
            "en": "So, for example, backpropagating the error gradient ∂ℰ/∂ot through the elementwise vector product in the output gate (see Equation (8.116)[512]) produces the following two error gradient vectors:",
            "zh": "因此，例如，通过输出门中的逐元向量积反向传播误差梯度 ∂E/∂ot（参见公式 （8.116）[512]）会产生以下两个误差梯度向量："
        }
    },
    {
        "translation": {
            "en": "The dealer’s play strictly follows these rules and so we can say that the dealer does not make any decisions during the game.",
            "zh": "庄家的比赛严格遵循这些规则，因此我们可以说庄家在游戏中不会做出任何决定。"
        }
    },
    {
        "translation": {
            "en": "3.3   A data quality report for the motor insurance claims fraud detection ABT displayed in Table 3.2[56].",
            "zh": "3.3 表3.2[56]所示的汽车保险理赔欺诈检测ABT数据质量报告。"
        }
    },
    {
        "translation": {
            "en": "Then for the next example we randomly choose a new set of nodes to drop and then do backpropagation as usual for this new example, but this time on the new reduced version of the network.",
            "zh": "然后，对于下一个示例，我们随机选择一组要丢弃的新节点，然后像往常一样对这个新示例进行反向传播，但这次是在新的简化版本的网络上。"
        }
    },
    {
        "translation": {
            "en": "1. Remember that in insurance we don’t refer to customers!",
            "zh": "1. 请记住，在保险中，我们不是指客户！"
        }
    },
    {
        "translation": {
            "en": "If, however, it is in fact the case that HEADACHE, FEVER, and VOMITING are conditionally independent of each other given MENINGITIS, then we would need to store only four factors: P(M), P(H | M), P(F | M), and P(V | M).",
            "zh": "然而，如果事实上，在脑膜炎的情况下，头痛、发烧和呕吐是有条件地相互独立的，那么我们只需要存储四个因子：P（M）、P（H |M）、P（F |M） 和 P（V |M)."
        }
    },
    {
        "translation": {
            "en": "One challenge is that bias in a sample can arise in indirect and non-obvious ways.",
            "zh": "一个挑战是，样本中的偏差可能以间接和不明显的方式出现。"
        }
    },
    {
        "translation": {
            "en": "Figures 3.9(b)[79] and 3.9(d)[79] show a second example, this time for the HEIGHT and POSITION features.",
            "zh": "图 3.9（b）[79] 和 3.9（d）[79] 显示了第二个示例，这次是 HEIGHT 和 POSITION 特征。"
        }
    },
    {
        "translation": {
            "en": "The decision tree after the data has been split using ELEVATION.",
            "zh": "使用 ELEVATION 拆分数据后的决策树。"
        }
    },
    {
        "translation": {
            "en": "We can extend this algorithm to retrieve the k nearest neighbors by modifying the search to use distance of the kth closest instance found as best-distance.",
            "zh": "我们可以扩展此算法，通过修改搜索以使用找到的第 k 个最近实例的距离作为最佳距离来检索 k 个最近邻。"
        }
    },
    {
        "translation": {
            "en": "To use the extended domain representation of the model to make a prediction for a query, we calculate the product of the relevant descriptive feature probabilities and the priors for the different target levels as before, but using PDFs to calculate the probabilities for the continuous feature. Table 6.14[282] shows how a prediction is made for the following query:",
            "zh": "为了使用模型的扩展域表示来对查询进行预测，我们像以前一样计算相关描述性特征概率和不同目标级别的先验的乘积，但使用 PDF 来计算连续特征的概率。表 6.14[282] 显示了如何对以下查询进行预测："
        }
    },
    {
        "translation": {
            "en": "EXERCISE, how regularly do they exercise",
            "zh": "锻炼，他们多久锻炼一次"
        }
    },
    {
        "translation": {
            "en": "The large adjustments made to the weights during gradient descent cause it to jump completely from one side of the error surface to the other.",
            "zh": "在梯度下降过程中对权重进行的大幅调整使其完全从误差曲面的一侧跳到另一侧。"
        }
    },
    {
        "translation": {
            "en": "out-of-time sampling, 546, 586",
            "zh": "超时采样，546,586"
        }
    },
    {
        "translation": {
            "en": "3.2.2   Case Study: Motor Insurance Fraud",
            "zh": "3.2.2 案例研究：汽车保险欺诈"
        }
    },
    {
        "translation": {
            "en": "This reflects the extension of the yes region due to the inclusion of the new instance.",
            "zh": "这反映了由于包含新实例而扩展的 yes 区域。"
        }
    },
    {
        "translation": {
            "en": "Similarly, we have dropped the subscript from d because we are assuming that the inputs have been standardized to have a mean of 0 and a standard deviation of 1, and so all the inputs have the same mean and variance: E(d) is the mean value of an input, and var(d) is the shared scaler variance of all the inputs.",
            "zh": "类似地，我们从 d 中删除了下标，因为我们假设输入已被标准化为均值为 0，标准差为 1，因此所有输入都具有相同的均值和方差：E（d） 是输入的平均值，var（d） 是所有输入的共享标度方差。"
        }
    },
    {
        "translation": {
            "en": "The training set consisted of 30% of the data in the ABT (approximately 200,000 instances), and the test set consisted of the remaining 70% (approximately 450,000 instances).14 Using the training set, Jocelyn performed a 10-fold cross validation experiment on models trained to use the full set of descriptive features to predict the 3-level target.",
            "zh": "训练集由 ABT 中 30% 的数据（约 200,000 个实例）组成，测试集由其余 70%（约 450,000 个实例）组成。14 使用训练集，Jocelyn 对训练为使用全套描述性特征来预测 3 级目标的模型进行了 10 倍交叉验证实验。"
        }
    },
    {
        "translation": {
            "en": "longevity, 33",
            "zh": "长寿，33"
        }
    },
    {
        "translation": {
            "en": "The binary target feature, FRAUD, tells us whether the loan application turned out to be fraudulent (true or false).",
            "zh": "二进制目标特征 FRAUD 告诉我们贷款申请是否被证明是欺诈性的（真或假）。"
        }
    },
    {
        "translation": {
            "en": "The activation function, φ, is then applied to each of the elements in z(1) to generate the activations for each of the neurons in the hidden layer.",
            "zh": "然后将激活函数 φ 应用于 z（1） 中的每个元素，以生成隐藏层中每个神经元的激活。"
        }
    },
    {
        "translation": {
            "en": "Error-based and deep learning models are less suitable in this case as they require categorical features to be converted into sets of binary features, which causes an increase in dimensionality.",
            "zh": "在这种情况下，基于错误和深度学习的模型不太合适，因为它们需要将分类特征转换为二进制特征集，这会导致维度增加。"
        }
    },
    {
        "translation": {
            "en": "The second disadvantage is that in using a programming language, we have very little of the infrastructural support, such as data management, offered with the application-based solutions available to us.",
            "zh": "第二个缺点是，在使用编程语言时，我们几乎没有可用的基于应用程序的解决方案提供的基础设施支持，例如数据管理。"
        }
    },
    {
        "translation": {
            "en": "A.4   Data Visualization",
            "zh": "A.4 数据可视化"
        }
    },
    {
        "translation": {
            "en": "the rate of change of the activation function with respect to changes in the weighted sum (∂ai/∂zi); and",
            "zh": "激活函数相对于加权和（∂ai/∂zi）变化的变化率;和"
        }
    },
    {
        "translation": {
            "en": "This is done in the same way as the previous examples (a weighted summation of inputs followed by the application of a non-linear activation function).",
            "zh": "这与前面的示例相同（输入的加权求和，然后应用非线性激活函数）。"
        }
    },
    {
        "translation": {
            "en": "Probability of an Event",
            "zh": "事件的概率"
        }
    },
    {
        "translation": {
            "en": "In Figure 8.31[480], the key thing to note about this figure is that the neuron receives inputs only from a small predefined region of the input; in other words, the neuron receives inputs only from the pixels in its local receptive field.",
            "zh": "在图8.31[480]中，关于该图需要注意的关键是，神经元仅从输入的一个小预定义区域接收输入;换句话说，神经元仅接收来自其局部感受野中的像素的输入。"
        }
    },
    {
        "translation": {
            "en": "polynomial relationship, 352",
            "zh": "多项式关系，352"
        }
    },
    {
        "translation": {
            "en": "Table 9.4",
            "zh": "表 9.4"
        }
    },
    {
        "translation": {
            "en": "The prediction model in this case becomes",
            "zh": "在这种情况下，预测模型变为"
        }
    },
    {
        "translation": {
            "en": "4.9   The state of the decision tree after the 𝒟1 partition has been split using STREAM.",
            "zh": "4.9 使用 STREAM 拆分 D1 分区后的决策树状态。"
        }
    },
    {
        "translation": {
            "en": "The evolution of the decision boundary for each model is shown.",
            "zh": "图中显示了每个模型的决策边界的演变。"
        }
    },
    {
        "translation": {
            "en": "convolving a function, 485",
            "zh": "卷积函数，485"
        }
    },
    {
        "translation": {
            "en": "Similarly, the calculations of the activations for the second layer can be expressed",
            "zh": "同样，第二层的激活计算可以表示为"
        }
    },
    {
        "translation": {
            "en": "5.3.1 A Worked Example",
            "zh": "5.3.1 工作示例"
        }
    },
    {
        "translation": {
            "en": "(b) How many of these potential models would be consistent with this sample of data?",
            "zh": "（b） 这些可能的模型中有多少与这些数据样本一致？"
        }
    },
    {
        "translation": {
            "en": "Also, as subsequently discussed (and similar to the training regime used for regression models in Chapter 7[311]), neural networks are trained by iteratively running the network on examples sampled from large datasets.",
            "zh": "此外，正如随后所讨论的（类似于第 7 章[311]中用于回归模型的训练机制），神经网络是通过在从大型数据集中采样的示例上迭代运行网络来训练的。"
        }
    },
    {
        "translation": {
            "en": "(a) A plot of the mobile phone customer dataset given in Table 10.1[604]. (b)–(f) The progress of the k-means clustering algorithm, working on the simple customer segmentation dataset. The large symbols represent cluster centroids, and the smaller symbols represent cluster assignments.",
            "zh": "（a） 表10.1[604]中给出的移动电话客户数据集图。（b）–（f） k-means聚类算法在简单客户细分数据集上的研究进展。大符号表示聚类质心，较小的符号表示聚类分配。"
        }
    },
    {
        "translation": {
            "en": "Note that in Equation (8.95)[491] each symbol in a matrix represents a neuron in a layer, rather than a data point.",
            "zh": "请注意，在等式（8.95）[491]中，矩阵中的每个符号代表层中的神经元，而不是数据点。"
        }
    },
    {
        "translation": {
            "en": "AT is always looking for new ways to address the churn issue and in 2008 founded a customer retention team.",
            "zh": "AT一直在寻找解决客户流失问题的新方法，并于2008年成立了一个客户保留团队。"
        }
    },
    {
        "translation": {
            "en": "The scientists at SDSS listed two key galaxy morphologies of interest: elliptical and spiral.",
            "zh": "SDSS的科学家们列出了两个感兴趣的关键星系形态：椭圆形和螺旋形。"
        }
    },
    {
        "translation": {
            "en": "A 6-by-6 matrix representation of a grayscale image of a 4, and a neuron with a receptive field that covers the top-left corner of the image. This figure was inspired by Figure 2 of Kelleher and Dobnik (2017).",
            "zh": "4 的灰度图像的 6×6 矩阵表示，以及具有覆盖图像左上角的感受野的神经元。该图的灵感来自Kelleher和Dobnik（2017）的图2。"
        }
    },
    {
        "translation": {
            "en": "On Line 32[420] the mini-batch sequence is shuffled between epochs.",
            "zh": "在第 32 行[420]上，小批量序列在各个时期之间进行洗牌。"
        }
    },
    {
        "translation": {
            "en": "In the matrix multiplication, each element in a row in the matrix on the left is multiplied by the corresponding element in each column in the matrix on the right, and then the results of these multiplications are summed.",
            "zh": "在矩阵乘法中，将左边矩阵中一行中的每个元素乘以右边矩阵中每列中对应的元素，然后将这些乘法的结果相加。"
        }
    },
    {
        "translation": {
            "en": "We can also extend the product rule to define the joint probability of more than two events. When we generalize the rule in this way, it is known as the probability chain rule:",
            "zh": "我们还可以扩展乘积规则来定义两个以上事件的联合概率。当我们以这种方式推广规则时，它被称为概率链规则："
        }
    },
    {
        "translation": {
            "en": "Implementing a neural network as a sequence of matrix operations and then running the network on GPUs is now standard in deep learning.",
            "zh": "将神经网络实现为一系列矩阵运算，然后在 GPU 上运行网络现在是深度学习的标准。"
        }
    },
    {
        "translation": {
            "en": "More advanced approaches to pre-pruning use statistical significance tests to determine the importance of subtrees, for example, χ2 pruning (pronounced chi-squared).21",
            "zh": "更高级的预修剪方法使用统计显著性检验来确定子树的重要性，例如，χ2 修剪（发音为 σ-squared）21。"
        }
    },
    {
        "translation": {
            "en": "A neuron is structurally equivalent to a logistic regression model: comparing Equation (8.5)[387] and Equation (7.26)[342] makes it apparent that both models calculate a weighted sum over an input vector and then pass the weighted sum value through a non-linear function.",
            "zh": "神经元在结构上等价于逻辑回归模型：比较方程（8.5）[387]和方程（7.26）[342]可以明显看出，这两个模型都计算输入向量的加权和，然后通过非线性函数传递加权和值。"
        }
    },
    {
        "translation": {
            "en": "The task of the input gate is to decide, on the basis of the current input and the propagated hidden state (hxt), which elements of the cell state, c‡, should be updated and how these elements should be updated.",
            "zh": "输入门的任务是根据当前输入和传播的隐藏状态 （hxt） 来决定单元状态 c‡ 的哪些元素应该更新，以及如何更新这些元素。"
        }
    },
    {
        "translation": {
            "en": "All these measures can have values in the range [0,1]. Higher values of TPR and TNR indicate better model performance, while the opposite is the case for FNR and FPR. Confusion matrices are often presented containing these measures rather than the raw counts, although we recommend using raw counts so that the number of instances with each of the different levels of the target feature remains apparent.",
            "zh": "所有这些度量值的值都可以在 [0,1] 范围内。TPR 和 TNR 值越高表示模型性能越好，而 FNR 和 FPR 的情况正好相反。混淆矩阵通常包含这些度量值，而不是原始计数，尽管我们建议使用原始计数，以便具有目标特征的每个不同级别的实例数保持明显。"
        }
    },
    {
        "translation": {
            "en": "The notion of situational fluency5 is especially important when dealing with scientific scenarios.",
            "zh": "在处理科学情景时，情境流畅性的概念5尤为重要。"
        }
    },
    {
        "translation": {
            "en": "Figures 5.18(d)[226] and 5.18(e)[226] illustrate the cost we would have to incur in extra instances if we wished to maintain the sampling density in the dataset in line with each increase in the dimensionality of the feature space.",
            "zh": "图5.18（d）[226]和图5.18（e）[226]说明了如果我们希望保持数据集中的采样密度与特征空间维数的增加保持一致，那么在额外实例中我们必须承担的成本。"
        }
    },
    {
        "translation": {
            "en": "A more common approach is to use a wrapper.",
            "zh": "更常见的方法是使用包装器。"
        }
    },
    {
        "translation": {
            "en": "Consequently, a naive Bayes model is often a good model to begin with: it is easy to train and has the potential to provide both a baseline accuracy score and some insight into the problem structure.",
            "zh": "因此，朴素贝叶斯模型通常是一个很好的模型：它易于训练，并且有可能提供基线准确性分数和对问题结构的一些见解。"
        }
    },
    {
        "translation": {
            "en": "A restriction bias constrains the set of models that the algorithm will consider during the learning process.",
            "zh": "限制偏差限制了算法在学习过程中将考虑的模型集。"
        }
    },
    {
        "translation": {
            "en": "Another simple and very effective technique to stop overfitting is called dropout.",
            "zh": "另一种简单且非常有效的停止过拟合的技术称为 dropout。"
        }
    },
    {
        "translation": {
            "en": "The alignment between the phases of CRISP-DM, key questions for analytics projects, and the chapters and sections of this book.",
            "zh": "CRISP-DM 各个阶段之间的一致性、分析项目的关键问题以及本书的章节和部分。"
        }
    },
    {
        "translation": {
            "en": "6. The F1 measure is often also referred to as the F measure, F score, or F1 score.",
            "zh": "6. F1 度量通常也称为 F 度量、F 分数或 F1 分数。"
        }
    },
    {
        "translation": {
            "en": "See Bishop (2006, pp.",
            "zh": "见Bishop（2006年，第1页）。"
        }
    },
    {
        "translation": {
            "en": "One of the most commonly used measures for this is the stability index.",
            "zh": "最常用的衡量标准之一是稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "If for the purposes of this discussion we naively assume that the variance of the δ values backpropagated to the neurons in HL5 is equal to 1, then we can expect the variance of the δs backpropagated to HL4 to be equal to 100 × 0.04 × 1 = 4.",
            "zh": "如果出于本讨论的目的，我们天真地假设反向传播到 HL5 中神经元的 δ 值的方差等于 1，那么我们可以预期反向传播到 HL4 的 δ 的方差等于 100 × 0.04 × 1 = 4。"
        }
    },
    {
        "translation": {
            "en": "At the next time-step, these new activations are then fed back to the hidden neurons in parallel with the new input.",
            "zh": "在下一个时间步中，这些新的激活与新输入并行反馈到隐藏的神经元。"
        }
    },
    {
        "translation": {
            "en": "To further explore the entropy, we can return to look at the entropy values of each set of cards shown in Figure 4.5[124].",
            "zh": "为了进一步探索熵，我们可以回过头来查看图4.5[124]所示的每组卡片的熵值。"
        }
    },
    {
        "translation": {
            "en": "Although we usually delay handling noise issues until the modeling phase of a project (different predictive model types require different levels of noise handling, and we should in general do as little noise handling as we can), in this section we describe the most common techniques used to handle missing values and outliers.",
            "zh": "尽管我们通常会将处理噪声问题推迟到项目的建模阶段（不同的预测模型类型需要不同级别的噪声处理，并且我们通常应该尽可能少地处理噪声），但在本节中，我们将介绍用于处理缺失值和异常值的最常见技术。"
        }
    },
    {
        "translation": {
            "en": "For example",
            "zh": "例如"
        }
    },
    {
        "translation": {
            "en": "Figure 10.4",
            "zh": "图 10.4"
        }
    },
    {
        "translation": {
            "en": "Figure 3.2(b)[60] shows a shape indicative of a normal distribution.",
            "zh": "图3.2（b）[60]显示了指示正态分布的形状。"
        }
    },
    {
        "translation": {
            "en": "Modeling",
            "zh": "建 模"
        }
    },
    {
        "translation": {
            "en": "One especially creative example of feature design was when a large retailer wanted to use the level of activity at a competitor’s stores as a descriptive feature in one of their analytics solutions.",
            "zh": "功能设计的一个特别有创意的例子是，当一家大型零售商希望在其分析解决方案之一中使用竞争对手商店的活动水平作为描述性特征时。"
        }
    },
    {
        "translation": {
            "en": "where dist(q,di) is the distance between the query instance and its ith nearest neighbor. This is a weighted average of the target values of the k nearest neighbors, as opposed to the simple average in Equation (5.7)[208].",
            "zh": "其中 dist（q，di） 是查询实例与其第 i 个最近邻域之间的距离。这是k个最近邻的目标值的加权平均值，而不是等式（5.7）[208]中的简单平均值。"
        }
    },
    {
        "translation": {
            "en": "Flux is another measure that attempts to standardize measures of brightness, taking into account how far away different objects are from the telescope.",
            "zh": "通量是另一种试图标准化亮度测量的措施，考虑到不同物体与望远镜的距离。"
        }
    },
    {
        "translation": {
            "en": "Ball, N. M., J. Loveday, M. Fukugita, O. Nakamura, S. Okamura, J. Brinkmann, and R. J. Brunner. 2004. Galaxy types in the sloan digital sky survey using supervised artificial neural networks. Monthly Notices of the Royal Astronomical Society 348 (3): 1038–1046. doi:10.1111/j.1365-2966.2004.07429.x. http://mnras.oxfordjournals.org/content/348/3/1038.abstract.",
            "zh": "鲍尔、NM、J. Loveday、M. Fukugita、O. Nakamura、S. Okamura、J. Brinkmann 和 RJ Brunner。2004. 使用监督人工神经网络的斯隆数字巡天中的星系类型.皇家天文学会月刊 348 （3）：1038–1046。doi：10.1111/j.1365-2966.2004.07429.x.http://mnras.oxfordjournals.org/content/348/3/1038.abstract。"
        }
    },
    {
        "translation": {
            "en": "The weights in the trained model are shown in the following table.",
            "zh": "训练模型中的权重如下表所示。"
        }
    },
    {
        "translation": {
            "en": "5.6   The decision boundary using majority vote of the nearest 3 and 5 instances.",
            "zh": "5.6 使用最接近的 3 个和 5 个实例的多数票的决策边界。"
        }
    },
    {
        "translation": {
            "en": "A naive Bayes model returns a MAP prediction where the posterior probabilities for the levels of the target feature are computed under the assumption of conditional independence between the descriptive features in an instance given a target feature level. More formally, the naive Bayes model is defined as",
            "zh": "朴素贝叶斯模型返回一个 MAP 预测，其中目标特征水平的后验概率是在给定目标特征水平的实例中描述性特征之间的条件独立性的假设下计算的。更正式地说，朴素贝叶斯模型定义为"
        }
    },
    {
        "translation": {
            "en": "left skew, 59",
            "zh": "左歪，59"
        }
    },
    {
        "translation": {
            "en": "It is likely that outliers found using the second approach are valid outliers, so they are a data quality issue due to valid data. Some machine learning techniques do not perform well in the presence of outliers, so we should note these in the data quality plan for possible handling later in the project.",
            "zh": "使用第二种方法找到的异常值很可能是有效的异常值，因此由于数据有效，它们存在数据质量问题。某些机器学习技术在存在异常值的情况下表现不佳，因此我们应该在数据质量计划中注明这些技术，以便在项目后期进行处理。"
        }
    },
    {
        "translation": {
            "en": "A national revenue commission performs audits on public companies to find and fine tax defaulters.",
            "zh": "国家税收委员会对上市公司进行审计，以发现和罚款拖欠税款的人。"
        }
    },
    {
        "translation": {
            "en": "8.2 Fundamentals",
            "zh": "8.2 基础知识"
        }
    },
    {
        "translation": {
            "en": "Consequently, we can still use the gradient descent process to train them.",
            "zh": "因此，我们仍然可以使用梯度下降过程来训练它们。"
        }
    },
    {
        "translation": {
            "en": "Differentiation is the set of techniques from calculus (the branch of mathematics that deals with how things change) that allows us to calculate derivatives.",
            "zh": "微分是微积分（处理事物如何变化的数学分支）的一组技术，允许我们计算导数。"
        }
    },
    {
        "translation": {
            "en": "Ross had decided, again in consultation with the business, that a simple classification accuracy rate was the most appropriate evaluation measure for this task.",
            "zh": "Ross 再次与业务部门协商后决定，简单的分类准确率是这项任务最合适的评估措施。"
        }
    },
    {
        "translation": {
            "en": "The reason why depth is important is that by introducing multiple layers into a network, the network is able to learn a hierarchy of features with later layers in the network building on the features that previous layers have learned to extract from the raw input.",
            "zh": "深度之所以重要，是因为通过在网络中引入多个层，网络能够学习特征的层次结构，网络中的后续层建立在前几层已经学会从原始输入中提取的特征之上。"
        }
    },
    {
        "translation": {
            "en": "This figure highlights the calculation of the weighted sum at each neuron (e.g., z3 represents the weighted sum calculation at Neuron 3), and the activations for each neuron (e.g., a3 represents the activation generated by Neuron 3).",
            "zh": "该图突出显示了每个神经元的加权和的计算（例如，z3 表示神经元 3 处的加权和计算），以及每个神经元的激活（例如，a3 表示神经元 3 产生的激活）。"
        }
    },
    {
        "translation": {
            "en": "To find the ideal subset of descriptive features to use to train a model, we could attempt to build a model using every possible subset, evaluate the performance of all these models, and select the feature subset that leads to the best model.",
            "zh": "为了找到用于训练模型的描述性特征的理想子集，我们可以尝试使用每个可能的子集构建模型，评估所有这些模型的性能，并选择导致最佳模型的特征子集。"
        }
    },
    {
        "translation": {
            "en": "Be aware, however, that if new descriptive features were added to the dataset, then the number of probabilities required would grow by |domain of target|×|domain of new feature|, and, furthermore, if an extra value were added to the domain of the target, then the number of probabilities would grow exponentially.",
            "zh": "但是请注意，如果将新的描述性特征添加到数据集中，则所需的概率数将按 |target 域|×|新特征域|增长，此外，如果将额外的值添加到目标域中，则概率数将呈指数增长。"
        }
    },
    {
        "translation": {
            "en": "The δs for the output neurons are then shared back to the neurons in the last hidden layer.",
            "zh": "然后，输出神经元的 δ 被共享回最后一个隐藏层中的神经元。"
        }
    },
    {
        "translation": {
            "en": "Post-pruning using an error rate criterion is probably the most popular way to prune decision trees.24 One of the advantages of pruning decision trees is that it keeps trees smaller, which in turn makes them easier to interpret.",
            "zh": "24 修剪决策树的优点之一是它使树更小，这反过来又使它们更易于解释。"
        }
    },
    {
        "translation": {
            "en": "10.4 Extensions and Variations",
            "zh": "10.4 扩展和变体"
        }
    },
    {
        "translation": {
            "en": "Decision tree models are ideal for these scenarios.",
            "zh": "决策树模型是这些场景的理想选择。"
        }
    },
    {
        "translation": {
            "en": "The basic process is the same as for categorical targets.",
            "zh": "基本过程与分类目标相同。"
        }
    },
    {
        "translation": {
            "en": "hidden features, 762",
            "zh": "隐藏功能， 762"
        }
    },
    {
        "translation": {
            "en": "Jurafsky, Daniel, and James H. Martin. 2008. Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition, 2nd ed. Prentice Hall.",
            "zh": "Jurafsky、Daniel 和 James H. Martin。2008. 语音和语言处理：自然语言处理、计算语言学和语音识别简介，第 2 版。"
        }
    },
    {
        "translation": {
            "en": "0.54",
            "zh": "0.54"
        }
    },
    {
        "translation": {
            "en": "decisions, 3",
            "zh": "决定， 3"
        }
    },
    {
        "translation": {
            "en": "This is why the indices on weights in Figure 8.4[390] were reversed: if we store all the weights for each neuron in a layer in a row in the weight matrix for the layer, then the weights are in the correct position when the weight matrix is multiplied by a column vector of activations from the previous layer.",
            "zh": "这就是为什么图8.4[390]中的权重指数被颠倒的原因：如果我们将每个神经元的所有权重连续存储在该层的权重矩阵中，那么当权重矩阵乘以来自前一层的激活列向量时，权重处于正确的位置。"
        }
    },
    {
        "translation": {
            "en": "An extended version of this dataset was used to build a model that can determine the type of a customer based on a few weeks of shopping behavior data.",
            "zh": "该数据集的扩展版本用于构建一个模型，该模型可以根据几周的购物行为数据确定客户类型。"
        }
    },
    {
        "translation": {
            "en": "We take a dataset for which we know the predictions that we expect the model to make, referred to as a test set, present the instances in this dataset to a trained model, and record the predictions that the model makes.",
            "zh": "我们采用一个我们知道我们期望模型做出的预测的数据集，称为测试集，将此数据集中的实例呈现给经过训练的模型，并记录模型做出的预测。"
        }
    },
    {
        "translation": {
            "en": "(a) A surface showing the value of Equation (7.23)[339] for all values of RPM and VIBRATION, with the decision boundary given in Equation (7.23)[339] highlighted; and (b) the same surface linearly thresholded at zero to operate as a predictor.",
            "zh": "（a） 显示所有RPM和VIBRATION值的等式（7.23）[339]值的曲面，并突出显示等式（7.23）[339]中给出的决策边界;（b）同一曲面线性阈值为零，可作为预测变量。"
        }
    },
    {
        "translation": {
            "en": "χ2 statistic, 583",
            "zh": "χ2 统计量，583"
        }
    },
    {
        "translation": {
            "en": "There is no hard and fast rule for deciding on interval size.",
            "zh": "决定间隔大小没有硬性规定。"
        }
    },
    {
        "translation": {
            "en": "Intuitively, adding more descriptive features to a dataset provides more information about each instance and should result in more accurate predictive models.",
            "zh": "直观地说，向数据集添加更多描述性特征可提供有关每个实例的更多信息，并应生成更准确的预测模型。"
        }
    },
    {
        "translation": {
            "en": "The differences between the three box plots in each plot gives an indication of the likely predictiveness of each feature.",
            "zh": "每个图中三个箱形图之间的差异表明了每个特征的可能预测性。"
        }
    },
    {
        "translation": {
            "en": "Take surfing, for example.",
            "zh": "以冲浪为例。"
        }
    },
    {
        "translation": {
            "en": "Equal-frequency binning first sorts the continuous feature values into ascending order and then places an equal number of instances into each bin, starting with bin 1.",
            "zh": "等频分箱首先将连续特征值按升序排序，然后从箱 1 开始将相同数量的实例放入每个箱中。"
        }
    },
    {
        "translation": {
            "en": "DEREDDIFF_I_Z",
            "zh": "DEREDDIFF_I_Z"
        }
    },
    {
        "translation": {
            "en": "second order polynomial function, 352, 766",
            "zh": "二阶多项式函数， 352， 766"
        }
    },
    {
        "translation": {
            "en": "A retail supermarket chain has built a prediction model that recognizes the household that a customer comes from as being one of single, business, or family.",
            "zh": "一家零售连锁超市建立了一个预测模型，该模型可以将客户来自的家庭识别为单身、企业或家庭之一。"
        }
    },
    {
        "translation": {
            "en": "When weights are initialized in this way, we can control the initial scale of the weights by controlling the variance of the normal distribution.",
            "zh": "当以这种方式初始化权重时，我们可以通过控制正态分布的方差来控制权重的初始尺度。"
        }
    },
    {
        "translation": {
            "en": "In this case the task was to categorize galaxies according to morphology, and therefore galaxy made sense as the prediction subject.",
            "zh": "在这种情况下，任务是根据形态对星系进行分类，因此星系作为预测对象是有意义的。"
        }
    },
    {
        "translation": {
            "en": "2.4   Sample descriptive feature data illustrating numeric, binary, ordinal, interval, categorical, and textual types.",
            "zh": "2.4 说明数字、二进制、序数、区间、分类和文本类型的示例描述性特征数据。"
        }
    },
    {
        "translation": {
            "en": "F score, 549",
            "zh": "F 分数，549"
        }
    },
    {
        "translation": {
            "en": "In other cases, however, a categorical feature will have been developed to use numbers to indicate categories and might be mistakenly identified as a continuous feature in a data quality report.",
            "zh": "但是，在其他情况下，将开发分类特征以使用数字来指示类别，并且可能会被错误地识别为数据质量报告中的连续特征。"
        }
    },
    {
        "translation": {
            "en": "Ross had AT generate a second data sample (which did not overlap with the sample taken previously) that was not stratified according to the target feature values. The confusion matrix illustrating the performance of the prediction model on this test set is shown in Table 12.4[700].",
            "zh": "Ross 让 AT 生成第二个数据样本（与之前采集的样本不重叠），该样本未根据目标特征值进行分层。表12.4[700]显示了预测模型在该测试集上的性能的混淆矩阵。"
        }
    },
    {
        "translation": {
            "en": "The Card.",
            "zh": "卡片。"
        }
    },
    {
        "translation": {
            "en": "delta value, 323",
            "zh": "增量值，323"
        }
    },
    {
        "translation": {
            "en": "In these scenarios, this approach to ongoing model validation simply doesn’t work.",
            "zh": "在这些情况下，这种持续模型验证的方法根本不起作用。"
        }
    },
    {
        "translation": {
            "en": "Table 4.12[153] illustrates the computation of the weighted variance that results from partitioning the data by SEASON and WORK DAY. It is evident from Table 4.12[153] that partitioning the data using SEASON results in a lower weighted variance than partitioning by WORK DAY. This tells us that splitting by SEASON results in a better clustering of the target data than splitting by WORK DAY. Figure 4.16[153] illustrates the state of the decision tree after the root node has been created using SEASON.",
            "zh": "表 4.12[153] 说明了按 SEASON 和 WORK DAY 对数据进行分区所得的加权方差的计算方法。从表4.12[153]中可以明显看出，使用SEASON对数据进行分区比按WORK DAY进行分区的加权方差更低。这告诉我们，按 SEASON 拆分比按 WORK DAY 拆分可以更好地聚类目标数据。图 4.16[153] 说明了使用 SEASON 创建根节点后决策树的状态。"
        }
    },
    {
        "translation": {
            "en": "Table 13.6",
            "zh": "表 13.6"
        }
    },
    {
        "translation": {
            "en": "This distance is 0.576, which is the K-S statistic for this example.",
            "zh": "此距离为 0.576，这是此示例的 K-S 统计量。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.8[138] shows the state of the tree after the dataset is split using ELEVATION.",
            "zh": "图 4.8[138] 显示了使用 ELEVATION 拆分数据集后的树状态。"
        }
    },
    {
        "translation": {
            "en": "Predictive data analytics models are often used as tools for process quality control and fault detection.",
            "zh": "预测数据分析模型通常用作过程质量控制和故障检测的工具。"
        }
    },
    {
        "translation": {
            "en": "This rewriting shows that (1) the backpropagation algorithm is in fact an implementation of the chain rule from calculus and the product used to calculate the δ terms follows the chain rule; and (2) that we can calculate ∂ℰ/∂wi,k (the term we need to update a weight wi,k) by multiplying the δ for a neuron i by the rate of change of the weighted sum calculation for neuron i with respect to changes in the weight wi,k.",
            "zh": "这种改写表明：（1）反向传播算法实际上是微积分链式法则的实现，用于计算δ项的乘积遵循链式法则;（2）我们可以通过将神经元i的δ乘以神经元i的加权和计算相对于权重wi，k的变化率来计算∂E/∂wi，k（我们需要更新权重wi，k的项）。"
        }
    },
    {
        "translation": {
            "en": "Furthermore, the deeper the network becomes, the slower the earlier layers learn (because the learning signal, the error gradient, attenuates as it is backpropagated through the layers).",
            "zh": "此外，网络越深，早期层的学习速度就越慢（因为学习信号，即误差梯度，在通过层的反向传播时会衰减）。"
        }
    },
    {
        "translation": {
            "en": "(a) Given this context, calculate .",
            "zh": "（a） 鉴于此上下文，计算 ."
        }
    },
    {
        "translation": {
            "en": "In terms of rows in a dataset, this computation is simply the number of rows where the set of assignments listed in the joint event holds divided by the total number of rows in the dataset.",
            "zh": "就数据集中的行数而言，此计算只是将联合事件中列出的分配集所在的行数除以数据集中的总行数。"
        }
    },
    {
        "translation": {
            "en": "The ACCOMMODATION feature refers to the applicant’s current accommodation, and the levels are own (the applicant owns their accommodation), rent (the applicant rents their accommodation), and free (the applicant has free accommodation).",
            "zh": "住宿功能是指申请人当前的住宿，级别是自有的（申请人拥有自己的住宿）、租金（申请人租用他们的住宿）和免费（申请人有免费住宿）。"
        }
    },
    {
        "translation": {
            "en": "A pruned decision tree built for the AT churn prediction problem. Gray leaf nodes indicate a churn prediction, and clear leaf nodes indicate a non-churn prediction. For space reasons, we show only the features tested at the top-level nodes.",
            "zh": "针对 AT 流失预测问题构建的修剪决策树。灰叶节点表示流失预测，清除叶节点表示非流失预测。由于篇幅原因，我们只显示在顶级节点上测试的功能。"
        }
    },
    {
        "translation": {
            "en": "Sokal-Michener index, 214, 231",
            "zh": "Sokal-Michener指数，214,231"
        }
    },
    {
        "translation": {
            "en": "rectified linear activation function, 386, 625, 626, 674",
            "zh": "整流线性激活函数， 386， 625， 626， 674"
        }
    },
    {
        "translation": {
            "en": "Figure 8.26[462] illustrates the internal dynamics of the network in Figure 8.22[450] during the first training iteration when ReLUs are used and the weights for neurons in HL1 are sampled using Xavier initialization and the weights for the neurons in the later layers are sampled using He initialization.",
            "zh": "图 8.26[462] 说明了图 8.22[450] 中网络的内部动力学，在第一次训练迭代期间，当使用 ReLU 时，HL1 中神经元的权重使用 Xavier 初始化进行采样，后面层中神经元的权重使用 He 初始化进行采样。"
        }
    },
    {
        "translation": {
            "en": "When predicting a continuous target, every error in the calculation of a probability is reflected in reduced model performance.",
            "zh": "在预测连续目标时，概率计算中的每个错误都会反映在模型性能降低上。"
        }
    },
    {
        "translation": {
            "en": "2.4.5   Implementing Features",
            "zh": "2.4.5 实现功能"
        }
    },
    {
        "translation": {
            "en": "In order to allow for the fact that some of the differences between values and the mean will be positive and some will be negative, we square each difference.1",
            "zh": "为了考虑到值和均值之间的一些差异是正的，而另一些是负的，我们对每个差异进行平方。"
        }
    },
    {
        "translation": {
            "en": "ReLU, 386",
            "zh": "鲁，386"
        }
    },
    {
        "translation": {
            "en": "5.7 Epilogue",
            "zh": "5.7 结语"
        }
    },
    {
        "translation": {
            "en": "By adding an explicit reference to action at+1, we can arrive at a very elegant recursive definition of the action-value function.",
            "zh": "通过添加对 action at+1 的显式引用，我们可以得出 action-value 函数的非常优雅的递归定义。"
        }
    },
    {
        "translation": {
            "en": "10.4.5 Agglomerative Hierarchical Clustering",
            "zh": "10.4.5 集聚分层聚类"
        }
    },
    {
        "translation": {
            "en": "Every time we partition the data, we add a node with two branches to the k-d tree. The node indexes the instance that had the median value of the feature, the left branch holds all the instances that had values less than the median, and the right branch holds all the instances that had values greater than the median. The recursive partitioning then grows each of these branches in a depth-first manner.",
            "zh": "每次对数据进行分区时，我们都会向 k-d 树添加一个具有两个分支的节点。节点索引具有特征中位数值的实例，左侧分支保存值小于中位数的所有实例，右侧分支保存值大于中位数的所有实例。然后，递归分区以深度优先的方式增长这些分支中的每一个。"
        }
    },
    {
        "translation": {
            "en": "Figure 3.7",
            "zh": "图 3.7"
        }
    },
    {
        "translation": {
            "en": "Figure 4.15",
            "zh": "图 4.15"
        }
    },
    {
        "translation": {
            "en": "34. The conductivity of water is affected by inorganic dissolved solids and organic compounds, such as oil. Consequently, water conductivity is a useful measure of water purity.",
            "zh": "34.水的电导率受无机溶解固体和有机化合物（如油）的影响。因此，水的电导率是衡量水纯度的有用指标。"
        }
    },
    {
        "translation": {
            "en": "3. This data is taken from the collection at Real Clear Politics: www.realclearpolitics.com/epolls/2012/president/us/general_election_romney_vs_obama-1171.html.",
            "zh": "3. 此数据取自 Real Clear Politics： www.realclearpolitics.com/epolls/2012/president/us/general_election_romney_vs_obama-1171.html 的集合。"
        }
    },
    {
        "translation": {
            "en": "The most popular and straightforward approach to feature selection is to rank and prune.",
            "zh": "最流行和最直接的特征选择方法是排名和修剪。"
        }
    },
    {
        "translation": {
            "en": "If the hiker looks at the slope of the ground at her feet, she will notice that in some directions, the ground slopes up, and in other directions, the ground slopes down.",
            "zh": "如果徒步旅行者观察她脚下的地面坡度，她会注意到在某些方向上，地面向上倾斜，而在其他方向上，地面向下倾斜。"
        }
    },
    {
        "translation": {
            "en": "Set Size",
            "zh": "机身尺寸"
        }
    },
    {
        "translation": {
            "en": "Svolba, Gerhard. 2007. Data preparation for analytics using SAS. SAS Institute.",
            "zh": "斯沃尔巴，格哈德。2007. 使用 SAS 进行分析的数据准备。SAS研究所。"
        }
    },
    {
        "translation": {
            "en": "To illustrate this, Table 9.11[557] shows the underlying scores that the predictions shown in Table 9.1[537] were based on, assuming a threshold of 0.5—that is, instances with a prediction score greater than or equal to 0.5 were given predictions of the spam (positive) level, and those with prediction scores less than 0.5 were given predictions of the ham (negative) level.",
            "zh": "为了说明这一点，表 9.11[557] 显示了表 9.1[537] 中所示的预测所基于的基本分数，假设阈值为 0.5，也就是说，预测分数大于或等于 0.5 的实例被预测为垃圾邮件（阳性）级别，预测分数小于 0.5 的实例被预测为 ham（负）水平。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.1",
            "zh": "图 4.1"
        }
    },
    {
        "translation": {
            "en": "Finally, in Lines 12 and 13, the algorithm grows a branch in the tree for each of the values in the domain of d[best] by recursively calling itself for each of the partitions created at Line 10.",
            "zh": "最后，在第 12 行和第 13 行中，该算法通过递归地为第 10 行创建的每个分区调用自身，为 d[best] 域中的每个值在树中生长一个分支。"
        }
    },
    {
        "translation": {
            "en": "0.5432",
            "zh": "0.5432"
        }
    },
    {
        "translation": {
            "en": "8.37   Schematic of the simple recurrent neural architecture.",
            "zh": "8.37 简单递归神经架构示意图。"
        }
    },
    {
        "translation": {
            "en": "Although this differential between the target levels in the dataset may not seem substantial, it does have an impact as k increases.",
            "zh": "尽管数据集中目标水平之间的这种差异可能看起来并不大，但随着 k 的增加，它确实会产生影响。"
        }
    },
    {
        "translation": {
            "en": "It was likely that a machine learning model that looked at multiple features would do a better job of identifying customers likely to churn.",
            "zh": "一个着眼于多个特征的机器学习模型可能会更好地识别可能流失的客户。"
        }
    },
    {
        "translation": {
            "en": "The gradient boosting algorithm proceeds by adding more and more models where each model is trained to improve the predictions of the previous ones. Equation (4.16)[164] can be generalized to capture this",
            "zh": "梯度提升算法通过添加越来越多的模型来继续，其中每个模型都经过训练以改进对前一个模型的预测。方程（4.16）[164]可以推广到这一点"
        }
    },
    {
        "translation": {
            "en": "Returning to the email classification example, and assuming again that spam emails are the positive level, precision measures how often the emails marked as spam actually are spam, whereas recall measures how often the spam messages in the test set were actually marked as spam. The precision and recall measures for the email classification data shown in Table 9.1[537] are",
            "zh": "回到电子邮件分类示例，并再次假设垃圾邮件是正数级别，精度衡量标记为垃圾邮件的电子邮件实际上是垃圾邮件的频率，而召回率衡量测试集中的垃圾邮件实际被标记为垃圾邮件的频率。表9.1[537]所示的电子邮件分类数据的精确度和召回率措施如下："
        }
    },
    {
        "translation": {
            "en": "As λ gets larger, the peak of the distribution (on the left) gets larger, and the drop-off in density gets steeper.",
            "zh": "随着λ变大，分布的峰值（左侧）变大，密度下降变陡。"
        }
    },
    {
        "translation": {
            "en": "Analysts need to balance the needs of their application—for example, in the mobile phone customer scenario, how many customer groups could the organization usefully make decisions about?—with the ability of an algorithm to find meaningful groupings within a given dataset.",
            "zh": "分析师需要平衡其应用程序的需求（例如，在移动电话客户场景中，组织可以有效地做出决策的客户组数量？）与算法在给定数据集中查找有意义的分组的能力。"
        }
    },
    {
        "translation": {
            "en": "The reason for this is that SUSPICIOUS WORDS, the descriptive feature tested at the root node of the tree in Figure 4.4(b)[122], perfectly splits the data into a pure group of spam emails and a pure group of ham emails.",
            "zh": "这样做的原因是，在图4.4（b）[122]中树的根节点上测试的描述性特征SUSPICIOUS WORDS完美地将数据拆分为一组纯垃圾邮件和一组纯业余邮件。"
        }
    },
    {
        "translation": {
            "en": "Because relative distributions are used, the bars in the second bar plot cover the full range of the space available—these are often referred to as 100% stacked bar plots.",
            "zh": "由于使用了相对分布，因此第二个条形图中的条形覆盖了可用空间的整个范围，这些空间通常称为 100% 堆叠条形图。"
        }
    },
    {
        "translation": {
            "en": "Table 4.3 lists an example dataset from the ecological modeling domain.11 In this example, the prediction task is to classify the type of vegetation that is likely to be growing in areas of land on the sole basis of descriptive features extracted from maps of the areas.",
            "zh": "表 4.3 列出了生态建模域中的一个示例数据集。11 在此示例中，预测任务是仅根据从区域地图中提取的描述性特征对可能在陆地区域中生长的植被类型进行分类。"
        }
    },
    {
        "translation": {
            "en": "The R2 coefficient is a domain independent measure of model performance that is frequently used for prediction problems with a continuous target. The R2 coefficient compares the performance of a model on a test set with the performance of an imaginary model that always predicts the average values from the test set. The R2 coefficient is calculated as",
            "zh": "R2 系数是模型性能的域独立度量，经常用于连续目标的预测问题。R2 系数将模型在测试集上的性能与始终预测测试集平均值的虚构模型的性能进行比较。R2 系数计算公式为"
        }
    },
    {
        "translation": {
            "en": "Ross then turned his attention to examining the data visualizations of the relationship between each descriptive feature and the target feature.",
            "zh": "然后，Ross 将注意力转向检查每个描述性特征与目标特征之间关系的数据可视化。"
        }
    },
    {
        "translation": {
            "en": "Interested readers are directed to the suggestions for further reading presented in Section 11.6[677], in which these alternatives are discussed.",
            "zh": "有兴趣的读者可以参考第11.6[677]节中提出的进一步阅读建议，其中讨论了这些替代方案。"
        }
    },
    {
        "translation": {
            "en": "PETROR90ERR_U/G/R/I/Z",
            "zh": "PETROR90ERR_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Cover, T. M., and J. A. Thomas. 1991. Elements of information theory. Wiley.",
            "zh": "封面，TM 和 JA 托马斯。1991. 信息论的要素.威利。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.33",
            "zh": "图 8.33"
        }
    },
    {
        "translation": {
            "en": "13.6 Deployment",
            "zh": "13.6 部署"
        }
    },
    {
        "translation": {
            "en": "The vegetation classification dataset.",
            "zh": "植被分类数据集。"
        }
    },
    {
        "translation": {
            "en": "The dataset presented in Table 1.3[9] is referred to as a labeled dataset because it includes values for the target feature.",
            "zh": "表1.3[9]中显示的数据集称为标记数据集，因为它包含目标特征的值。"
        }
    },
    {
        "translation": {
            "en": "Consequently, to calculate a probability using a PDF, we need to first decide on the interval we wish to calculate the probability for, and then calculate the area under the density curve for that interval to give the probability of a value from that interval occurring.",
            "zh": "因此，要使用 PDF 计算概率，我们需要首先确定我们希望计算概率的区间，然后计算该区间的密度曲线下的面积，以给出该区间中某个值发生的概率。"
        }
    },
    {
        "translation": {
            "en": "ratio features, 35",
            "zh": "比率特征，35"
        }
    },
    {
        "translation": {
            "en": "2. Statisticians will often refer to false positives as type I errors and false negatives as type II errors. Similarly, false positives are often also referred to as false alarms, true positives as hits, and false negatives as misses.",
            "zh": "2. 统计学家通常将假阳性称为 I 类错误，将假阴性称为 II 类错误。同样，误报通常也称为误报，真阳性称为命中，误报称为未命中。"
        }
    },
    {
        "translation": {
            "en": "Hinton, G. E., S. Osindero, and Y. W. Teh. 2006. A fast learning algorithm for deep belief nets. Neural Computing 18: 1527–1554.",
            "zh": "Hinton、GE、S. Osindero 和 Y. W. Teh。2006. 一种用于深度信念网络的快速学习算法.神经计算 18：1527–1554。"
        }
    },
    {
        "translation": {
            "en": "As we did with predictive modeling we can capture the mathematical foundations of these further approaches to machine learning in two key equations: the function minimized by the k-means clustering algorithm (Equation (14.6)[741]) and the action-value function update rule used in Q-learning (Equation (14.7)[741]).",
            "zh": "正如我们在预测建模中所做的那样，我们可以在两个关键方程中捕获这些机器学习进一步方法的数学基础：通过k-means聚类算法最小化的函数（方程（14.6）[741]）和Q-learning中使用的动作-值函数更新规则（方程（14.7）[741]）。"
        }
    },
    {
        "translation": {
            "en": "We strongly believe that the best way to keep an analytics project focused, and to improve the likelihood of a successful conclusion, is to adopt a structured project lifecycle, such as CRISP-DM, and we recommend its use.",
            "zh": "我们坚信，保持分析项目专注并提高成功结论的可能性的最佳方法是采用结构化的项目生命周期，例如 CRISP-DM，我们建议使用它。"
        }
    },
    {
        "translation": {
            "en": "Partitioning the dataset based on the value of the target feature and fitting the parameters of a statistical distribution to model the ACCOUNT BALANCE feature in each partition.",
            "zh": "根据目标特征的值对数据集进行分区，并拟合统计分布的参数，以对每个分区中的 ACCOUNT BALANCE 特征进行建模。"
        }
    },
    {
        "translation": {
            "en": "It is worth reflecting for a moment that the agent has learned to navigate this grid world without any knowledge of the overall structure of the environment or indication about what it should do. Rather, the agent—equipped with only knowledge of the states in the world and the actions that it can take—was able to learn a long-term strategy to complete a somewhat sophisticated task using only the instantaneous rewards that is received for each move that it made.",
            "zh": "值得反思的是，智能体已经学会了在这个网格世界中导航，而对环境的整体结构一无所知，也不知道它应该做什么。相反，智能体——只具备对世界状态和它可以采取的行动的了解——能够学习一种长期策略，只使用它所做的每一步所获得的即时奖励来完成一项有点复杂的任务。"
        }
    },
    {
        "translation": {
            "en": "These distances are then ranked from lowest to highest to find the nearest neighbor.",
            "zh": "然后将这些距离从低到高进行排名，以找到最近的邻居。"
        }
    },
    {
        "translation": {
            "en": "performance measure, 535, 540",
            "zh": "绩效衡量， 535， 540"
        }
    },
    {
        "translation": {
            "en": "Figure 4.4[122] shows two decision trees that are consistent with the spam dataset.",
            "zh": "图 4.4[122] 显示了两个与垃圾邮件数据集一致的决策树。"
        }
    },
    {
        "translation": {
            "en": "where the term η explicitly represents a normalization constant. Because Bayes’ Theorem can be calculated in this way, it is sometimes written as",
            "zh": "其中，术语 η 显式表示规范化常数。因为贝叶斯定理可以这样计算，所以它有时写成"
        }
    },
    {
        "translation": {
            "en": "The variety of derived features that we might wish to use is limitless.",
            "zh": "我们可能希望使用的派生功能种类繁多。"
        }
    },
    {
        "translation": {
            "en": "Each of the hidden layer neurons receives both the input vector and a vector containing the information stored in the memory buffer at the same time.",
            "zh": "每个隐藏层神经元同时接收输入向量和包含存储在内存缓冲区中的信息的向量。"
        }
    },
    {
        "translation": {
            "en": "A more systematic approach is to use learning rate decay, which allows the learning rate to start at a large value and then decay over time according to a predefined schedule.",
            "zh": "一种更系统的方法是使用学习率衰减，它允许学习率从大值开始，然后根据预定义的时间表随着时间的推移而衰减。"
        }
    },
    {
        "translation": {
            "en": "If we look for an instance in the dataset in Table 6.2[263] that matches all the descriptive feature values in the query, we won’t find one.",
            "zh": "如果我们在表 6.2[263] 中的数据集中查找与查询中所有描述性特征值匹配的实例，我们将找不到一个实例。"
        }
    },
    {
        "translation": {
            "en": "We can see this if we highlight the decision boundary within the feature space.",
            "zh": "如果我们突出显示特征空间中的决策边界，我们可以看到这一点。"
        }
    },
    {
        "translation": {
            "en": "Instead, we will simply note that the appropriate choice of generative versus discriminative model is context-dependent, and evaluating a range of different types of models is the safest option.",
            "zh": "相反，我们只会注意到，生成模型与判别模型的适当选择取决于上下文，评估一系列不同类型的模型是最安全的选择。"
        }
    },
    {
        "translation": {
            "en": "9.22   The number of customers who left the mobile phone network operator each week during the comparative experiment from both the control group (random selection) and the treatment group (model selection).",
            "zh": "9.22 对照组（随机选择）和治疗组（模型选择）在比较实验期间每周离开移动电话网络运营商的客户数量。"
        }
    },
    {
        "translation": {
            "en": "This assumes that we should expect the clustering to find groups with similar tariff types, an assumption that could be based only on detailed knowledge of the domain.",
            "zh": "这假设我们应该期望聚类找到具有相似资费类型的组，这一假设只能基于对该领域的详细了解。"
        }
    },
    {
        "translation": {
            "en": "Assuming a learning rate of α = 0.1, calculate the updated values for each of the weights in the network (w5,4, w5,3, w5,0, w4,2, w4,0, w3,2, w3,0,, w2,1, w2,0,) after the processing of this single training example.",
            "zh": "假设学习率为 α = 0.1，计算网络中每个权重（w5,4、w5,3、w5,0、w4,2、w4,0、w3,2、w3,0、w2,1、w2,0，）的更新值。"
        }
    },
    {
        "translation": {
            "en": "To further illustrate the difference between arithmetic mean and harmonic mean, Figure 9.8[553] shows the arithmetic mean and the harmonic mean of all combinations of two features A and B that range from 0 to 100.",
            "zh": "为了进一步说明算术平均值和谐和平均值之间的差异，图9.8[553]显示了从0到100的两个特征A和B的所有组合的算术平均值和谐和平均值。"
        }
    },
    {
        "translation": {
            "en": "weight space, 317, 321, 338, 369",
            "zh": "重量空间，317,321,338,369"
        }
    },
    {
        "translation": {
            "en": "The low cardinality for the NUM.",
            "zh": "NUM 的低基数。"
        }
    },
    {
        "translation": {
            "en": "9.1   A sample test set with model predictions.",
            "zh": "9.1 具有模型预测的样本测试集。"
        }
    },
    {
        "translation": {
            "en": "In such instances a model is essentially reduced to guessing predictions.",
            "zh": "在这种情况下，模型基本上被简化为猜测预测。"
        }
    },
    {
        "translation": {
            "en": "The term ∂ℰ/∂ct describes the vector of error gradients that are backpropagated through this operation.",
            "zh": "术语 ∂E/∂ct 描述了通过此操作反向传播的误差梯度向量。"
        }
    },
    {
        "translation": {
            "en": "Eco, Umberto. 1999. Kant and the platypus. Vintage U.K. Random House.",
            "zh": "生态，翁贝托。1999. 康德与鸭嘴兽.复古英国兰登书屋。"
        }
    },
    {
        "translation": {
            "en": "The simplest way to measure the similarity between two instances, a and b, in a dataset is to measure the distance between the instances in a feature space. We can use a distance metric to do this: metric(a,b) is a function that returns the distance between two instances a and b. Mathematically, a metric must conform to the following four criteria:",
            "zh": "测量数据集中两个实例（a 和 b）之间的相似度的最简单方法是测量要素空间中实例之间的距离。我们可以使用距离度量来做到这一点：metric（a，b） 是一个函数，它返回两个实例 a 和 b 之间的距离。从数学上讲，指标必须符合以下四个标准："
        }
    },
    {
        "translation": {
            "en": "Kuncheva, Ludmila I. 2004. Combining pattern classifiers: Methods and algorithms. Wiley.",
            "zh": "Kuncheva， Ludmila I. 2004.组合模式分类器：方法和算法。威利。"
        }
    },
    {
        "translation": {
            "en": "The resulting confusion matrices are shown in Table 13.7[723].",
            "zh": "由此产生的混淆矩阵如表13.7[723]所示。"
        }
    },
    {
        "translation": {
            "en": "Often descriptive features that are likely to be very useful cannot be implemented due to the unavailability of data.",
            "zh": "通常，由于数据不可用，可能无法实现可能非常有用的描述性功能。"
        }
    },
    {
        "translation": {
            "en": "29. See Chapter 8[381].",
            "zh": "29. 见第8章[381]。"
        }
    },
    {
        "translation": {
            "en": "9.18   The distributions of predictions made by a model trained for the bacterial species identification problem for (a) the original evaluation test set, and for (b) and (c) two periods of time after model deployment; (d) shows how the stability index can be tracked over time to monitor for concept drift.",
            "zh": "9.18 为细菌种类识别问题训练的模型在（a）原始评估测试集以及（b）和（c）模型部署后两个时间段内所作预测的分布;（d） 显示了如何随时间跟踪稳定性指数以监测概念漂移。"
        }
    },
    {
        "translation": {
            "en": "(d) What will be the value of ct if",
            "zh": "（d） ct 的值是多少，如果"
        }
    },
    {
        "translation": {
            "en": "We recommend only applying the clamp transformation in cases where it is suspected that a model is performing poorly due to the presence of outliers.",
            "zh": "我们建议仅在怀疑模型由于存在异常值而表现不佳的情况下应用钳位变换。"
        }
    },
    {
        "translation": {
            "en": "8.2.3 Neural Networks as Matrix Operations",
            "zh": "8.2.3 作为矩阵操作的神经网络"
        }
    },
    {
        "translation": {
            "en": "The assignment of each instance in a dataset to one of these groups is the output of the clustering process, and a generated feature capturing these assignments can be appended to the original dataset.",
            "zh": "将数据集中的每个实例分配给其中一个组是聚类过程的输出，捕获这些分配的生成特征可以追加到原始数据集。"
        }
    },
    {
        "translation": {
            "en": "The forget gate is the leftmost gate in Figure 8.40[509], and it is the first gate to process the inputs to the time-step.",
            "zh": "遗忘门是图8.40[509]中最左边的门，它是处理时间步长输入的第一个门。"
        }
    },
    {
        "translation": {
            "en": "In Chapter 2 we provide a framework for designing and constructing a predictive analytics solution based on machine learning that meets a business need.",
            "zh": "在第 2 章中，我们提供了一个框架，用于设计和构建基于机器学习的预测分析解决方案，以满足业务需求。"
        }
    },
    {
        "translation": {
            "en": "We also discussed how tree pruning can be used to help with the problem of overfitting.",
            "zh": "我们还讨论了如何使用树木修剪来帮助解决过拟合问题。"
        }
    },
    {
        "translation": {
            "en": "The reason is that the max function does not apply weights to its inputs or, to put it another way, all the inputs have a weight of 1.",
            "zh": "原因是 max 函数不对其输入应用权重，或者换句话说，所有输入的权重均为 1。"
        }
    },
    {
        "translation": {
            "en": "This process is essentially the same as the decision tree post-pruning process described in Section 4.4.4[153].",
            "zh": "此过程与第 4.4.4 节[153] 中描述的决策树后修剪过程基本相同。"
        }
    },
    {
        "translation": {
            "en": "To update the weights, we must first calculate the delta value for each weight.",
            "zh": "要更新权重，我们必须首先计算每个权重的增量值。"
        }
    },
    {
        "translation": {
            "en": "(Random Selection)",
            "zh": "（随机选择）"
        }
    },
    {
        "translation": {
            "en": "Breiman (1996) developed the use of bagging for prediction, and Breiman (2001) introduced random forests.",
            "zh": "Breiman（1996）开发了使用袋装进行预测的方法，Breiman（2001）引入了随机森林。"
        }
    },
    {
        "translation": {
            "en": "About halfway through the training process, however, the performance of the model on the validation set begins to disimprove.",
            "zh": "然而，在训练过程进行到一半时，模型在验证集上的性能开始下降。"
        }
    },
    {
        "translation": {
            "en": "universal approximators, 400",
            "zh": "通用近似器，400"
        }
    },
    {
        "translation": {
            "en": "Despite this limitless variety, however, there are a number of common derived feature types:",
            "zh": "然而，尽管有无限的多样性，但仍有许多常见的派生特征类型："
        }
    },
    {
        "translation": {
            "en": "During normalization, the values of the descriptive features are mapped to a standard range, for example [−1,+1] or [0,1], using range normalization (see Equation (3.7)[87]), or standardized in order to have a mean of 0 and a standard deviation of 1 (see Equation (3.8)[88]).",
            "zh": "在归一化过程中，描述性特征的值被映射到一个标准范围，例如[−1，+1]或[0,1]，使用范围归一化（参见等式（3.7）[87]），或标准化以使平均值为0，标准差为1（见等式（3.8）[88]）。"
        }
    },
    {
        "translation": {
            "en": "You carefully prepare the apparatus for these experiments, and on the 21st of September 1904, you spend three hours assisting Professor Blondlot in demonstrating them to Professor Wood.",
            "zh": "1904 年 9 月 21 日，你精心准备了这些实验的仪器，花了三个小时协助布隆德洛特教授向伍德教授演示这些实验。"
        }
    },
    {
        "translation": {
            "en": "The mode is not particularly effective in this case at measuring the central tendency of the values.",
            "zh": "在这种情况下，该模式在测量值的中心趋势方面不是特别有效。"
        }
    },
    {
        "translation": {
            "en": "PETROMAGDIFF_I_Z",
            "zh": "PETROMAGDIFF_I_Z"
        }
    },
    {
        "translation": {
            "en": "6.6 Further Reading",
            "zh": "6.6 延伸阅读"
        }
    },
    {
        "translation": {
            "en": "13. See Section 7.3.3[328] for further discussions on the role of the learning rate, and Section 7.4.2[334] for a discussion on different approaches to setting the learning rate.",
            "zh": "13. 关于学习率作用的进一步讨论，见第7.3.3[328]节，关于设定学习率的不同方法的讨论，见第7.4.2[334]节。"
        }
    },
    {
        "translation": {
            "en": "Figure 4.17",
            "zh": "图 4.17"
        }
    },
    {
        "translation": {
            "en": "7.12   (a) A plot of the logistic function (Equation (7.25)[342]) for the range of values [–10,10]; and (b) the logistic decision surface that results from training a model to represent the generators dataset given in Table 7.6[339] (note that the data has been normalized to the range [–1,1]).",
            "zh": "7.12 （a） 值范围[–10,10]的逻辑函数图（等式（7.25）[342]）;（b）通过训练模型来表示表7.6[339]中给出的生成器数据集而产生的逻辑决策面（请注意，数据已归一化为范围[–1,1]）。"
        }
    },
    {
        "translation": {
            "en": "Business Understanding: Predictive data analytics projects never start out with the goal of building a prediction model. Instead, they focus on things like gaining new customers, selling more products, and adding efficiencies to a process. So, during the first phase in any analytics project, the primary goal of the data analyst is to fully understand the business (or organizational) problem that is being addressed and then to design a data analytics solution for it.",
            "zh": "业务理解：预测数据分析项目从来都不是以构建预测模型为目标开始的。相反，他们专注于获得新客户、销售更多产品以及提高流程效率等事情。因此，在任何分析项目的第一阶段，数据分析师的主要目标是充分了解正在解决的业务（或组织）问题，然后为其设计数据分析解决方案。"
        }
    },
    {
        "translation": {
            "en": "9.4.3 Performance Measures: Prediction Scores",
            "zh": "9.4.3 绩效指标：预测分数"
        }
    },
    {
        "translation": {
            "en": "At this stage we do not worry too much about exactly how a domain concept will be converted into a concrete feature, but rather try to enumerate the different areas from which features will arise.",
            "zh": "在这个阶段，我们并不太担心如何将领域概念转换为具体特征，而是尝试列举特征产生的不同领域。"
        }
    },
    {
        "translation": {
            "en": "Figure 5.3",
            "zh": "图 5.3"
        }
    },
    {
        "translation": {
            "en": "The performance measures from the five individual evaluation experiments and an overall aggregate from the 5-fold cross validation performed on the chest X-ray classification dataset.",
            "zh": "来自五个单独评估实验的性能测量和对胸部 X 射线分类数据集进行的 5 倍交叉验证的总体汇总。"
        }
    },
    {
        "translation": {
            "en": "“machine learning for fun, fun, fun”",
            "zh": "“机器学习的乐趣，乐趣，乐趣”"
        }
    },
    {
        "translation": {
            "en": "discriminative model, 733",
            "zh": "判别模型，733"
        }
    },
    {
        "translation": {
            "en": "This type of representation is often referred to as an embedding because the original features have been embedded into a new lower-dimensional space.",
            "zh": "这种类型的表示通常称为嵌入，因为原始特征已嵌入到新的低维空间中。"
        }
    },
    {
        "translation": {
            "en": "Standardizing the descriptive feature in this way was likely to improve the accuracy of the final predictive models.",
            "zh": "以这种方式标准化描述性特征可能会提高最终预测模型的准确性。"
        }
    },
    {
        "translation": {
            "en": "6.5   The relevant probabilities, from Table 6.3[264], needed by the naive Bayes prediction model to make a prediction for the query with CH = paid, GC = guarantor, and ACC = free, and the calculation of the scores for each possible target level.",
            "zh": "6.5 朴素贝叶斯预测模型对 CH = 付费、GC = 担保人、ACC = 免费的查询进行预测所需的相关概率，以及计算每个可能的目标水平的分数。"
        }
    },
    {
        "translation": {
            "en": "To illustrate MDPs in a little more detail we develop an MDP representation for an agent designed to play the card game TwentyTwos, a simplified version of the popular game Blackjack, that has been invented for this example.",
            "zh": "为了更详细地说明 MDP，我们为一个代理开发了一个 MDP 表示，该代理旨在玩纸牌游戏 TwentyTwos，这是为此示例发明的流行游戏 Blackjack 的简化版本。"
        }
    },
    {
        "translation": {
            "en": "In reinforcement learning the degree to which an agent has achieved a goal is measured only by the cumulative rewards it has received from each action taken in pursuit of that goal.",
            "zh": "在强化学习中，智能体实现目标的程度仅通过其为追求该目标而采取的每项行动中获得的累积奖励来衡量。"
        }
    },
    {
        "translation": {
            "en": "With Edwin’s help, Jocelyn investigated the actual data in the ABT to determine whether the extreme values in the features displaying significant skew or the presence of outliers were due to valid outliers or invalid outliers.",
            "zh": "在 Edwin 的帮助下，Jocelyn 研究了 ABT 中的实际数据，以确定显示显著偏斜或异常值存在的要素中的极值是由于有效的异常值还是无效的异常值。"
        }
    },
    {
        "translation": {
            "en": "Similarly, if we changed the threshold from 0.5 to 0.25, the predictions for instances d14, d5, and d1 would change from ham to spam, resulting in their outcomes changing to FP, FP, and TP respectively. This would mean that the confusion matrix would change to that shown in Table 9.12(b)[559] and, in turn, that the TPR and TNR measures would change to 0.777 and 0.636 respectively.",
            "zh": "同样，如果我们将阈值从 0.5 更改为 0.25，则对实例 d14、d5 和 d1 的预测将从 ham 更改为 spam，从而导致其结果分别更改为 FP、FP 和 TP。这意味着混淆矩阵将更改为表9.12（b）[559]所示的矩阵，反过来，TPR和TNR测量值将分别更改为0.777和0.636。"
        }
    },
    {
        "translation": {
            "en": "18. Based on data from Bray et al. (2018).",
            "zh": "18. 基于 Bray 等人（2018 年）的数据。"
        }
    },
    {
        "translation": {
            "en": "(c) What would be the output from this neuron if the activation function φ is the logistic function?",
            "zh": "（c）如果激活函数φ是逻辑函数，那么这个神经元的输出是什么？"
        }
    },
    {
        "translation": {
            "en": "The classifier accurately predicts the type of galaxies with the elliptical target level and, to a lesser extent, with the spiral_eo target level.",
            "zh": "分类器以椭圆目标水平准确预测星系类型，并在较小程度上以spiral_eo目标水平准确预测星系类型。"
        }
    },
    {
        "translation": {
            "en": "And why is the rarity of the disease good news given that the patient has tested positive for it?",
            "zh": "鉴于患者的检测结果呈阳性，为什么这种疾病的罕见性是个好消息？"
        }
    },
    {
        "translation": {
            "en": "Figure 13.4",
            "zh": "图 13.4"
        }
    },
    {
        "translation": {
            "en": "The value calculated is not terribly different from the value calculated before.",
            "zh": "计算的值与之前计算的值没有太大区别。"
        }
    },
    {
        "translation": {
            "en": "EXPAB_U/G/R/I/Z",
            "zh": "EXPAB_U/G/R/I/Z"
        }
    },
    {
        "translation": {
            "en": "Mac Namee, Brian, author. |",
            "zh": "Mac Namee，Brian，作者。|"
        }
    },
    {
        "translation": {
            "en": "column in Table 4.14[162].",
            "zh": "表4.14[162]中的列。"
        }
    },
    {
        "translation": {
            "en": "A set of weights that capture this relationship well are said to fit the training data.",
            "zh": "据说一组能很好地捕捉这种关系的权重适合训练数据。"
        }
    },
    {
        "translation": {
            "en": "Paying the recurring charge entitled a customer to a bundle of minutes of call time that were offered at a reduction to the standard call rate.",
            "zh": "支付经常性费用后，客户有权获得以低于标准通话费率的通话时间提供的通话时间。"
        }
    },
    {
        "translation": {
            "en": "decision surface, 341",
            "zh": "决策面，341"
        }
    },
    {
        "translation": {
            "en": "Conversely, if we set k too high, we run the risk of losing the true pattern of the data and underfitting.",
            "zh": "相反，如果我们将 k 设置得太高，我们就有可能丢失数据的真实模式和欠拟合。"
        }
    },
    {
        "translation": {
            "en": "The naive Bayes model leverages conditional independence to the extreme by assuming conditional independence between the assignment of all the descriptive feature values given the target level.",
            "zh": "朴素贝叶斯模型通过假设给定目标级别的所有描述性特征值的赋值之间的条件独立性，将条件独立性发挥到极致。"
        }
    },
    {
        "translation": {
            "en": "Calculating the inverse of a matrix involves solving systems of linear equations and requires the use of techniques from linear algebra such as Gauss-Jordan elimination or LU decomposition.",
            "zh": "计算矩阵的逆涉及求解线性方程组，并且需要使用线性代数中的技术，例如高斯-乔丹消元法或 LU 分解。"
        }
    },
    {
        "translation": {
            "en": "χ2 pruning, 155",
            "zh": "χ2 修剪，155"
        }
    },
    {
        "translation": {
            "en": "1. It is crucial to use data to evaluate a model that has not been used to train the model.",
            "zh": "1. 使用数据来评估尚未用于训练模型的模型至关重要。"
        }
    },
    {
        "translation": {
            "en": "For example, applying Equation (7.23)[339] to the instance RPM = 810, VIBRATION = 495, which is above the decision boundary in Figure 7.10(b)[340], gives the following result:",
            "zh": "例如，将公式（7.23）[339]应用于RPM = 810，VIBRATION = 495（高于图7.10（b）[340]中的决策边界）实例，得出以下结果："
        }
    },
    {
        "translation": {
            "en": "The third part of the book also deals with Modeling, but in this case it looks at modeling approaches beyond prediction. As described previously in this chapter, supervised machine learning is one of three main machine learning paradigms. The other two are unsupervised learning and reinforcement learning. Chapters 10[597] and 11[637] describe these two other approaches as a counterpoint to the descriptions of supervised learning in the rest of the book.",
            "zh": "本书的第三部分也涉及建模，但在本例中，它着眼于预测之外的建模方法。如本章前面所述，监督式机器学习是三种主要的机器学习范式之一。另外两个是无监督学习和强化学习。第10章[597]和第11章[637]描述了另外两种方法，与本书其余部分对监督学习的描述相对应。"
        }
    },
    {
        "translation": {
            "en": "Friedman et al.",
            "zh": "弗里德曼等人。"
        }
    },
    {
        "translation": {
            "en": "REGIONTYPE",
            "zh": "区域类型"
        }
    },
    {
        "translation": {
            "en": "Table 8.7",
            "zh": "表 8.7"
        }
    },
    {
        "translation": {
            "en": "This experiment showed the AT executive team that the new decision tree model could significantly reduce churn rates within the AT customer base.",
            "zh": "该实验向AT执行团队表明，新的决策树模型可以显著降低AT客户群的流失率。"
        }
    },
    {
        "translation": {
            "en": "3.5.1.2 Visualizing pairs of categorical features The simplest way to visualize the relationship between two categorical features is to use a collection of bar plots.",
            "zh": "3.5.1.2 可视化分类特征对 可视化两个分类特征之间关系的最简单方法是使用条形图集合。"
        }
    },
    {
        "translation": {
            "en": "The % Miss.",
            "zh": "未命中百分比。"
        }
    },
    {
        "translation": {
            "en": "(b) Assuming the target output for this input is 1, calculate the δ for each neuron in the network.",
            "zh": "（b） 假设此输入的目标输出为 1，计算网络中每个神经元的δ。"
        }
    },
    {
        "translation": {
            "en": "An obvious criteria for driving this search is to look for models that are consistent with the data.",
            "zh": "驱动此搜索的一个明显标准是查找与数据一致的模型。"
        }
    },
    {
        "translation": {
            "en": "There is no limit to the kinds of functions that can be used as basis functions, and as we have seen in the previous example, the basis functions for different descriptive features in a dataset can be quite different.",
            "zh": "可用作基函数的函数种类没有限制，正如我们在前面的示例中看到的，数据集中不同描述性特征的基本函数可能大不相同。"
        }
    },
    {
        "translation": {
            "en": "-0.1764",
            "zh": "-0.1764"
        }
    },
    {
        "translation": {
            "en": "It is likely that people who respond to a survey are systematically different from people who don’t, and so when the response rate within a population is very low, it is likely that the resulting sample underrepresents particular groups in the population.",
            "zh": "对调查做出回应的人很可能与不回答调查的人在系统上有所不同，因此，当人群中的回复率非常低时，结果样本很可能低估了人群中特定群体的代表性。"
        }
    },
    {
        "translation": {
            "en": "So, for a conditional independence, we need to take into account not only the parents of a node but also the state of its children and their parents.",
            "zh": "因此，对于有条件的独立性，我们不仅需要考虑节点的父节点，还需要考虑节点子节点及其父节点的状态。"
        }
    },
    {
        "translation": {
            "en": "Equation 8.41[436] shows that during backpropagation the error gradient is repeatedly multiplied by a derivative of activation functions, one multiplication for each neuron that the error gradient is backpropagated through.",
            "zh": "方程 8.41[436] 表明，在反向传播过程中，误差梯度被激活函数的导数反复乘以，误差梯度反向传播的每个神经元都乘以一次。"
        }
    },
    {
        "translation": {
            "en": "The dictionary is typically defined as the complete set of words that occur in the training dataset.",
            "zh": "字典通常定义为训练数据集中出现的完整单词集。"
        }
    },
    {
        "translation": {
            "en": "4.7   Exercises",
            "zh": "4.7 练习"
        }
    },
    {
        "translation": {
            "en": "For example, based on correlations tests alone, we might conclude that the presence of swallows cause hot weather, that spinning windmills cause wind, and that playing basketball causes people to be tall.",
            "zh": "例如，仅根据相关性检验，我们可以得出结论，燕子的存在会导致炎热的天气，旋转的风车会导致风，打篮球会导致人长高。"
        }
    },
    {
        "translation": {
            "en": "As a result, the values in column 6 are identical to the values in the error column.",
            "zh": "因此，第 6 列中的值与错误列中的值相同。"
        }
    },
    {
        "translation": {
            "en": "As the experience of moving left from state 0-3 to state 0-2 has not led to a large positive reward or opened up the potential for a new action that will give significant positive return, the value of this action in this state has been reduced.",
            "zh": "由于从状态 0-3 向左移动到状态 0-2 的经验并没有带来巨大的正奖励，也没有为将带来显着正回报的新行动开辟了潜力，因此该行动在这种状态下的价值已经降低。"
        }
    },
    {
        "translation": {
            "en": "Table 9.14",
            "zh": "表 9.14"
        }
    },
    {
        "translation": {
            "en": "Intuitively we can see that this grouping is, as Goldilocks put it, just right and is the type of grouping we are trying to generate when we use a variance measure to select the splitting point.",
            "zh": "直观地，我们可以看到，正如 Goldilocks 所说，这种分组恰到好处，并且是我们在使用方差度量选择分割点时尝试生成的分组类型。"
        }
    },
    {
        "translation": {
            "en": "The origins used for the figures were (a) (50,50), (b) (63,71), and (c) (42,35).",
            "zh": "这些数字的来源是（a）（50,50），（b）（63,71）和（c）（42,35）。"
        }
    },
    {
        "translation": {
            "en": "Figure 11.3[648] shows a selection of the transition probabilities between states in the TwentyTwos MDP (only a selection of probabilities are shown to make the graph less cluttered).",
            "zh": "图 11.3[648] 显示了 TwentyTwos MDP 中状态之间的转移概率选择（仅显示一些概率以使图形不那么混乱）。"
        }
    },
    {
        "translation": {
            "en": "rectified linear unit, 386",
            "zh": "整流线性单元，386"
        }
    },
    {
        "translation": {
            "en": "Table 9.15",
            "zh": "表 9.15"
        }
    },
    {
        "translation": {
            "en": "An inappropriate inductive bias, however, can lead to mistakes.",
            "zh": "然而，不适当的归纳偏差会导致错误。"
        }
    },
    {
        "translation": {
            "en": "Individuals will most likely remain in the INFECTED state for some time, P(I I) = 0.50, but will transition eventually to the RECOVERED state, P(I R) = 0.50.",
            "zh": "个体很可能会在一段时间内保持感染状态，P（I I） = 0.50，但最终会过渡到恢复状态，P（I R） = 0.50。"
        }
    },
    {
        "translation": {
            "en": "The state of the cell after the update gate is the cell state that is propagated forward to the next time-step, and so after this update the cell state is now ct (rather than c‡).",
            "zh": "更新门之后的单元状态是向前传播到下一个时间步的单元状态，因此在此更新之后，单元状态现在是 ct（而不是 c‡）。"
        }
    },
    {
        "translation": {
            "en": "A collection of possible simple linear regression models capturing the relationship between these two features are also shown.",
            "zh": "还显示了一组可能的简单线性回归模型，用于捕获这两个特征之间的关系。"
        }
    },
    {
        "translation": {
            "en": "In fact, if inappropriately large learning rates are used, the jumps from one side of the error surface to the other can cause the sum of squared errors to repeatedly increase rather than decrease, leading to a process that will never converge.",
            "zh": "事实上，如果使用不恰当的大学习率，从误差表面的一侧跳到另一侧会导致平方误差的总和反复增加而不是减少，从而导致一个永远不会收敛的过程。"
        }
    },
    {
        "translation": {
            "en": "Classification accuracy can assume values in the range [0,1], and higher values indicate better performance. For the email classification task, classification accuracy would be",
            "zh": "分类精度可以假定值在 [0,1] 范围内，值越高表示性能越好。对于电子邮件分类任务，分类精度为"
        }
    },
    {
        "translation": {
            "en": "Dua, Dheeru, and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml.",
            "zh": "Dua、Dheeru 和 Casey Graff。2017. UCI 机器学习存储库。http://archive.ics.uci.edu/ml。"
        }
    },
    {
        "translation": {
            "en": "8.34   A grayscale image of a 4 after padding has been applied to the original 6-by-6 matrix representation, and the local receptive field of a neuron that includes both valid and padded pixels.",
            "zh": "8.34 填充后 4 的灰度图像已应用于原始的 6×6 矩阵表示，以及包括有效像素和填充像素的神经元的局部感受野。"
        }
    },
    {
        "translation": {
            "en": "A one-versus-all model distinguishes between one level of the target feature and all the others.",
            "zh": "一对一模型区分目标要素的一个级别和所有其他级别。"
        }
    },
    {
        "translation": {
            "en": "SPLOM diagrams of (a) the EXPRAD; and (b) DEVRAD measurements from the raw SDSS dataset. Each SPLOM shows the measure across the five different photometric bands captured by the SDSS telescope (u, g, r, i, and z).",
            "zh": "（a） EXPRAD 的 SPLOM 图;（b）来自原始SDSS数据集的DEVRAD测量值。每个SPLOM都显示了SDSS望远镜捕获的五个不同光度波段（u，g，r，i和z）的测量值。"
        }
    },
    {
        "translation": {
            "en": "Figure 8.25[460] illustrates the internal dynamics of the network in Figure 8.22[450] during the first training iteration when the weights of each layer in the network are sampled from a normal distribution with a mean of 0 and a variance calculated using Equation (8.62)[459].",
            "zh": "图8.25[460]说明了图8.22[450]中第一次训练迭代期间网络的内部动力学，当时网络中每一层的权重是从均值为0的正态分布中采样的，方差使用公式（8.62）[459]计算。"
        }
    },
    {
        "translation": {
            "en": "In each case we have overlaid the coordinate system defined by the Mahalanobis distance from a different origin.",
            "zh": "在每种情况下，我们都覆盖了由来自不同原点的马氏距离定义的坐标系。"
        }
    },
    {
        "translation": {
            "en": "Examples of using stacked bar plot visualizations to illustrate the relationship between two categorical features: (a) CAREER STAGE and SHOE SPONSOR features; and (b) POSITION and SHOE SPONSOR features, all from Table 3.7[73].",
            "zh": "使用堆积条形图可视化来说明两个分类特征之间关系的示例：（a） CAREER STAGE 和 SHOE SPONSOR 特征;（b）POSITION和SHOE SPONSOR特征，均来自表3.7[73]。"
        }
    },
    {
        "translation": {
            "en": "To help align the elements of the weight matrices shown in Figure 8.14[425] with the connections in the graph representation of the network in Figure 8.4[390], the rows and columns of the weight matrices are labeled using the neuron identifiers from Figure 8.4[390] (the labels are the numbers inside circles).",
            "zh": "为了帮助将图8.14[425]所示的权重矩阵的元素与图8.4[390]中网络图表示中的连接对齐，使用图8.4[390]中的神经元标识符标记权重矩阵的行和列（标签是圆圈内的数字）。"
        }
    },
    {
        "translation": {
            "en": "Observing a multimodal distribution is cause for both caution and optimism.",
            "zh": "观察多峰分布既要谨慎又要乐观。"
        }
    },
    {
        "translation": {
            "en": "Also, peculiarities in a dataset can affect the calculation of the correlation between two features.",
            "zh": "此外，数据集中的特殊性可能会影响两个要素之间相关性的计算。"
        }
    },
    {
        "translation": {
            "en": "Consequently, decision trees overfit by splitting the data on irrelevant features that appear relevant only because of noise or sampling variance in the training data.",
            "zh": "因此，决策树通过拆分不相关特征上的数据来过度拟合，这些特征仅因训练数据中的噪声或采样方差而显得相关。"
        }
    },
    {
        "translation": {
            "en": "To monitor models for the occurrence of concept drift, it is important that the stability index be continuously tracked over time.",
            "zh": "为了监控模型是否发生概念漂移，必须随时间持续跟踪稳定性指数。"
        }
    },
    {
        "translation": {
            "en": "A nearest neighbor algorithm can be updated without retraining.",
            "zh": "可以更新最近邻算法，而无需重新训练。"
        }
    },
    {
        "translation": {
            "en": "In reality, these filters are learned by the convolutional network in the same way that weights are learned in a fully connected feedforward network.",
            "zh": "实际上，卷积网络学习这些滤波器的方式与在完全连接的前馈网络中学习权重的方式相同。"
        }
    },
    {
        "translation": {
            "en": "We can see in this figure that the query is inside a Voronoi region defined by an instance with a target level of yes.",
            "zh": "在此图中，我们可以看到查询位于由目标级别为 yes 的实例定义的 Voronoi 区域内。"
        }
    },
    {
        "translation": {
            "en": "How the instances in the spam dataset split when we partition using each of the different descriptive features from the spam dataset in Table 4.2[121].",
            "zh": "当我们使用表 4.2[121] 中垃圾邮件数据集中的每个不同描述性特征进行分区时，垃圾邮件数据集中的实例是如何拆分的。"
        }
    },
    {
        "translation": {
            "en": "Another extension allows support vector machines to handle multinomial target features using a one-versus-all approach similar to that described in Section 7.4.6[357].",
            "zh": "另一个扩展允许支持向量机使用类似于第 7.4.6 节[357]中描述的一对一方法处理多项式目标特征。"
        }
    },
    {
        "translation": {
            "en": "Idiom",
            "zh": "成语"
        }
    },
    {
        "translation": {
            "en": "leaky ReLU, 445",
            "zh": "泄漏的 ReLU，445"
        }
    },
    {
        "translation": {
            "en": "0.00157020",
            "zh": "0.00157020"
        }
    },
    {
        "translation": {
            "en": "For example, if we were to measure the heights of a randomly selected group of Irish men and women, we would expect a bimodal distribution with a peak at around 1.635m for women and 1.775m for men.",
            "zh": "例如，如果我们要测量一组随机选择的爱尔兰男性和女性的身高，我们预计会出现双峰分布，女性的峰值约为 1.635 米，男性约为 1.775 米。"
        }
    },
    {
        "translation": {
            "en": "Following the same approach as in earlier models, Jocelyn performed feature selection using a step-wise sequential search to find the best subset of features for this model.",
            "zh": "遵循与早期模型相同的方法，Jocelyn 使用逐步顺序搜索执行特征选择，以找到该模型的最佳特征子集。"
        }
    },
    {
        "translation": {
            "en": "However, we know that using an appropriately defined PDF, we can approximate the probability of the feature taking any value in its domain.",
            "zh": "但是，我们知道，使用适当定义的 PDF，我们可以近似地计算特征在其域中获取任何值的概率。"
        }
    },
    {
        "translation": {
            "en": "Finally, it is worth mentioning two situations where this weighted k nearest neighbor approach can be problematic. The first is if the dataset is very imbalanced, then even with a weighting applied to the contribution of the training instances, the majority target level may dominate. The second is when the dataset is very large, which means that computing the reciprocal of squared distance between the query and all the training instances can become too computationally expensive to be feasible.",
            "zh": "最后，值得一提的是，在两种情况下，这种加权 k 最近邻方法可能会有问题。第一种情况是，如果数据集非常不平衡，那么即使对训练实例的贡献施加了加权，多数目标水平也可能占主导地位。第二种情况是数据集非常大，这意味着计算查询和所有训练实例之间的平方距离的倒数可能会变得过于昂贵而不可行。"
        }
    },
    {
        "translation": {
            "en": "We can represent these cards using the dataset given in Table 4.1[118].",
            "zh": "我们可以使用表4.1[118]中给出的数据集来表示这些卡片。"
        }
    },
    {
        "translation": {
            "en": "Here we see that the SARSA agent favors staying away from any possibility of falling into one of the dangerous cells rather than taking the more direct route.",
            "zh": "在这里，我们看到SARSA特工倾向于远离任何落入危险牢房之一的可能性，而不是采取更直接的路线。"
        }
    },
    {
        "translation": {
            "en": "small multiples, 75, 77",
            "zh": "小倍数，75,77"
        }
    },
    {
        "translation": {
            "en": "7.2.1   Simple Linear Regression",
            "zh": "7.2.1 简单线性回归"
        }
    },
    {
        "translation": {
            "en": "Table 0.1",
            "zh": "表0.1"
        }
    },
    {
        "translation": {
            "en": "Precision captures how often, when a model makes a positive prediction, this prediction turns out to be correct.",
            "zh": "精度捕获当模型做出积极预测时，该预测被证明是正确的频率。"
        }
    },
    {
        "translation": {
            "en": "Naive Bayes and k nearest neighbor models are good examples of the former type, while decision trees and regression models are good examples of the latter.",
            "zh": "朴素贝叶斯模型和 k 最近邻模型是前一种类型的很好的例子，而决策树和回归模型是后者的好例子。"
        }
    },
    {
        "translation": {
            "en": "goal, 639, 643, 676",
            "zh": "进球数， 639， 643， 676"
        }
    },
    {
        "translation": {
            "en": "After we have covered the fundamentals of the models, we explain how these artificial neural networks can be understood as sequences of matrix multiplications (see Section 8.2.3[390]).",
            "zh": "在介绍了模型的基础知识之后，我们解释了如何将这些人工神经网络理解为矩阵乘法序列（参见第 8.2.3 节[390]）。"
        }
    },
    {
        "translation": {
            "en": "For our three-level categorical feature we might decide that 1,0,0 indicates low, 0,1,0 indicates medium, and 0,0,1 indicates high.",
            "zh": "对于我们的三级分类特征，我们可以确定 1,0,0 表示低，0,1,0 表示中等，0,0,1 表示高。"
        }
    },
    {
        "translation": {
            "en": "Using a weighted k nearest neighbor model does not require that we set k equal to the size of the dataset, as we did in this example. It may be possible to find a value for k—using evaluation experiments—that eliminates, or further reduces, the effect of the noise on the model. As is so often the case in machine learning, fitting the parameters of a model is as important as selecting which model to use.",
            "zh": "使用加权 k 最近邻模型不需要将 k 设置为等于数据集的大小，就像我们在此示例中所做的那样。使用评估实验，可以找到一个 k 值，该值可以消除或进一步减少噪声对模型的影响。正如机器学习中经常出现的情况一样，拟合模型的参数与选择要使用的模型一样重要。"
        }
    },
    {
        "translation": {
            "en": "There is more likelihood of Q-Learning choosing actions that do damage to equipment as random action selections made by a behavior policy coupled with a target policy favoring risky states could lead to the occasional disaster.",
            "zh": "Q-Learning 更有可能选择对设备造成损害的行动，因为行为策略做出的随机行动选择加上有利于风险状态的目标策略可能会导致偶尔的灾难。"
        }
    },
    {
        "translation": {
            "en": "7.3.2 Gradient Descent",
            "zh": "7.3.2 梯度下降"
        }
    },
    {
        "translation": {
            "en": "13.2   Analysis of a subset of the features in the SDSS dataset.",
            "zh": "13.2 分析SDSS数据集中特征的子集。"
        }
    },
    {
        "translation": {
            "en": "A selection of the logistic regression models developed during the gradient descent process for the extended generators dataset in Table 7.7[347]. The bottom-right panel shows the sums of squared errors generated during the gradient descent process.",
            "zh": "表7.7[347]中扩展生成器数据集的梯度下降过程中开发的逻辑回归模型的选择。右下角的面板显示了梯度下降过程中产生的平方误差之和。"
        }
    },
    {
        "translation": {
            "en": "Each time we add a link to a network, we increase the number of CPT entries in the network.",
            "zh": "每次我们向网络添加链接时，我们都会增加网络中 CPT 条目的数量。"
        }
    },
    {
        "translation": {
            "en": "12. Note that in this figure, both the RPM and VIBRATION features have been normalized to the range [−1, 1] (using range normalization as described in Section 3.6.1[87]). It is standard practice to normalize descriptive features whenever we are using regression models to predict a categorical target feature.",
            "zh": "12. 请注意，在此图中，RPM 和 VIBRATION 特征都已归一化为范围 [−1， 1]（使用第 3.6.1 节[87] 中描述的范围归一化）。每当我们使用回归模型预测分类目标特征时，规范化描述性特征是标准做法。"
        }
    },
    {
        "translation": {
            "en": "In talking about reinforcement learning policies, it is worthwhile to distinguish between a behavior policy that an agent uses during learning and a target policy that an agent will use when deployed into the world after learning has taken place.",
            "zh": "在讨论强化学习策略时，有必要区分智能体在学习期间使用的行为策略和智能体在学习发生后部署到世界时将使用的目标策略。"
        }
    },
    {
        "translation": {
            "en": "For ease of reference, we have explicitly labeled a number of neurons in this architecture A, B, C, D, and E",
            "zh": "为了便于参考，我们在此架构中明确标记了许多神经元 A、B、C、D 和 E"
        }
    },
    {
        "translation": {
            "en": "In all cases, a prediction score (or scores) is produced, and a threshold process is used to convert this score into one of the levels of the target feature.",
            "zh": "在所有情况下，都会生成一个（或多个）预测分数，并使用阈值过程将此分数转换为目标要素的级别之一。"
        }
    },
    {
        "translation": {
            "en": "similarity-based learning, 19, 181",
            "zh": "基于相似性的学习，19,181"
        }
    },
    {
        "translation": {
            "en": "The difference between the mean and median values for the SKYIVAR_R feature also suggested the presence of outliers.",
            "zh": "SKYIVAR_R特征的平均值和中位数之间的差异也表明存在异常值。"
        }
    },
    {
        "translation": {
            "en": "3.4.2 Handling Outliers",
            "zh": "3.4.2 处理异常值"
        }
    },
    {
        "translation": {
            "en": "One of the best known of these weight initialization regimes is called Xavier initialization.36 There are a number of variants of Xavier initialization used in practice, but the original version of Xavier initialization was designed for fully connected feedforward networks and worked on a layer-by-layer basis.",
            "zh": "36 在实践中使用了许多 Xavier 初始化变体，但 Xavier 初始化的原始版本是为完全连接的前馈网络设计的，并且是逐层工作的。"
        }
    },
    {
        "translation": {
            "en": "This suggests that there is a strong, positive, linear relationship between the HEIGHT and WEIGHT features—as height increases, so does weight.",
            "zh": "这表明 HEIGHT 和 WEIGHT 特征之间存在强烈的正线性关系——随着身高的增加，体重也会增加。"
        }
    }
]